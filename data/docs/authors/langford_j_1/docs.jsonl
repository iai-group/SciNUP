{"id": "0705.2357", "contents": "Title: The inevitable nonlinearity of quantum gravity falsifies the many-worlds\n  interpretation of quantum mechanics Abstract: There are fundamental reasons as to why there should exist a reformulation of\nquantum mechanics which does not refer to a classical spacetime manifold. It\nfollows as a consequence that quantum mechanics as we know it is a limiting\ncase of a more general nonlinear quantum theory, with the nonlinearity becoming\nsignificant at the Planck mass/energy scale. This nonlinearity is responsible\nfor a dynamically induced collapse of the wave-function, during a quantum\nmeasurement, and it hence falsifies the many-worlds interpretation of quantum\nmechanics. We illustrate this conclusion using a mathematical model based on a\ngeneralized Doebner-Goldin equation. The non-Hermitian part of the Hamiltonian\nin this norm-preserving, nonlinear, Schrodinger equation dominates during a\nquantum measurement, and leads to a breakdown of linear superposition. \n\n"}
{"id": "0705.4566", "contents": "Title: Loop corrections for message passing algorithms in continuous variable\n  models Abstract: In this paper we derive the equations for Loop Corrected Belief Propagation\non a continuous variable Gaussian model. Using the exactness of the averages\nfor belief propagation for Gaussian models, a different way of obtaining the\ncovariances is found, based on Belief Propagation on cavity graphs. We discuss\nthe relation of this loop correction algorithm to Expectation Propagation\nalgorithms for the case in which the model is no longer Gaussian, but slightly\nperturbed by nonlinear terms. \n\n"}
{"id": "0707.0535", "contents": "Title: Measuring a Parity Violation Signature in the Early Universe via\n  Ground-based Laser Interferometers Abstract: We show that pairs of widely separated interferometers are advantageous for\nmeasuring the Stokes parameter V of a stochastic background of gravitational\nwaves. This parameter characterizes asymmetry of amplitudes of right- and\nleft-handed waves and generation of the asymmetry is closely related to parity\nviolation in the early universe. The advantageous pairs include\nLIGO(Livingston)-LCGT and AIGO-Virgo that are relatively insensitive to\nOmega_GW (the simple intensity of the background). Using at least three\ndetectors, information of the intensity Omega_GW and the degree of asymmetry V\ncan be separately measured. \n\n"}
{"id": "0707.3558", "contents": "Title: Brane-World Black Hole Solutions via a Confining Potential Abstract: Using a confining potential, we consider spherically symmetric vacuum (static\nblack hole) solutions in a brane-world scenario. Working with a constant\ncurvature bulk, two interesting cases/solutions are studied. A Schwarzschild-de\nSitter black hole solution similar to the standard solution in the presence of\na cosmological constant is obtained which confirms the idea that an extra term\nin the field equations on the brane can play the role of a positive\ncosmological constant and may be used to account for the accelerated expansion\nof the universe. The other solution is one in which we can have a proper\npotential to explain the galaxy rotation curves without assuming the existence\nof dark matter and without working with new modified theories (modified\nNewtonian dynamics). \n\n"}
{"id": "0709.1619", "contents": "Title: Vector modes generated by primordial density fluctuations Abstract: While vector modes are usually ignored in cosmology since they are not\nproduced during inflation they are inevitably produced from the interaction of\ndensity fluctuations of differing wavelengths. This effect may be calculated\nvia a second-order perturbative expansion. We investigate this effect during\nthe radiation era. We discuss the generation mechanism by investigating two\nscalar modes interacting, and we calculate the power of vector modes generated\nby a power-law spectrum of density perturbations on all scales. \n\n"}
{"id": "0711.2278", "contents": "Title: Antisymmetric Tensor Fields, 4-Vector Fields, Indefinite Metrics and\n  Normalization Abstract: On the basis of our recent modifications of the Dirac formalism we generalize\nthe Bargmann-Wigner formalism for higher spins to be compatible with other\nformalisms for bosons. Relations with dual electrodynamics, with the\nOgievetskii-Polubarinov notoph and the Weinberg 2(2J+1) theory are found. Next,\nwe introduce the dual analogues of the Riemann tensor and derive corresponding\ndynamical equations in the Minkowski space. Relations with the Marques-Spehler\nchiral gravity theory are discussed. The problem of indefinite metrics,\nparticularly, in quantization of 4-vector fields is clarified. \n\n"}
{"id": "0801.4233", "contents": "Title: Effects of the interaction between dark energy and dark matter on\n  cosmological parameters Abstract: We examine the effects of possible phenomenological interactions between dark\nenergy and dark matter on cosmological parameters and their efficiency in\nsolving the coincidence problem. We work with two simple parameterizations of\nthe dynamical dark energy equation of state and the constant dark energy\nequation of state. Using observational data coming from the new 182 Gold type\nIa supernova samples, the shift parameter of the Cosmic Microwave Background\ngiven by the three-year Wilkinson Microwave Anisotropy Probe observations, and\nthe baryon acoustic oscillation measurement from the Sloan Digital Sky Survey,\nwe perform a statistical joint analysis of different forms of phenomenological\ninteractions between dark energy and dark matter. \n\n"}
{"id": "0803.3203", "contents": "Title: Conserved Quantities for Interacting Four Valent Braids in Quantum\n  Gravity Abstract: We derive conservation laws from interactions of actively-interacting\nbraid-like excitations of embedded framed spin networks in Quantum Gravity.\nAdditionally we demonstrate that actively-interacting braid-like excitations\ninteract in such a way that the product of interactions involving two\nactively-interacting braid-like excitations produces a resulting\nactively-interacting form. \n\n"}
{"id": "0809.3170", "contents": "Title: A New Framework of Multistage Hypothesis Tests Abstract: In this paper, we have established a general framework of multistage\nhypothesis tests which applies to arbitrarily many mutually exclusive and\nexhaustive composite hypotheses. Within the new framework, we have constructed\nspecific multistage tests which rigorously control the risk of committing\ndecision errors and are more efficient than previous tests in terms of average\nsample number and the number of sampling operations. Without truncation, the\nsample numbers of our testing plans are absolutely bounded. \n\n"}
{"id": "0812.4870", "contents": "Title: Gravitational wave burst search in the Virgo C7 data Abstract: A search for gravitational wave burst events has been performed with the\nVirgo C7 commissioning run data that have been acquired in September 2005 over\nfive days. It focused on un-modeled short duration signals in the frequency\nrange 150 Hz to 2 kHz. A search aimed at detecting the GW emission from the\nmerger and ringdown phases of binary black hole coalescences was also carried\nout. An extensive understanding of the data was required to be able to handle a\nburst search using the output of only one detector. A 90% confidence level\nupper limit on the number of expected events given the Virgo C7 sensitivity\ncurve has been derived as a function of the signal strength, for un-modeled\ngravitational wave search. The sensitivity of the analysis presented is, in\nterms of the root sum square strain amplitude, $h_{rss} \\simeq 10^{-20} /\n\\sqrt{Hz}$. This can be interpreted in terms of a frequentist upper limit on\nthe rate ${\\cal{R}}_{90%}$ of detectable gravitational wave bursts at the level\nof 1.1 events per day at 90% confidence level. From the binary black hole\nsearch, we obtained the distance reach at 50% and 90% efficiency as a function\nof the total mass of the final black hole. The maximal detection distance for\nnon-spinning high and equal mass black hole binary system obtained by this\nanalysis in C7 data is $\\simeq$ 2.9 $\\pm$ 0.1 Mpc for a detection efficiency of\n50% for a binary of total mass $80 M_{\\odot}$. \n\n"}
{"id": "0901.3202", "contents": "Title: Model-Consistent Sparse Estimation through the Bootstrap Abstract: We consider the least-square linear regression problem with regularization by\nthe $\\ell^1$-norm, a problem usually referred to as the Lasso. In this paper,\nwe first present a detailed asymptotic analysis of model consistency of the\nLasso in low-dimensional settings. For various decays of the regularization\nparameter, we compute asymptotic equivalents of the probability of correct\nmodel selection. For a specific rate decay, we show that the Lasso selects all\nthe variables that should enter the model with probability tending to one\nexponentially fast, while it selects all other variables with strictly positive\nprobability. We show that this property implies that if we run the Lasso for\nseveral bootstrapped replications of a given sample, then intersecting the\nsupports of the Lasso bootstrap estimates leads to consistent model selection.\nThis novel variable selection procedure, referred to as the Bolasso, is\nextended to high-dimensional settings by a provably consistent two-step\nprocedure. \n\n"}
{"id": "0902.0928", "contents": "Title: Chaplygin inflation in loop quantum cosmology Abstract: In this paper we discuss the inflationary universe in the context of a\nChaplygin gas equation of state within the framework of the effective theory of\nloop quantum cosmology. Under the slow-roll approximation, we calculate the\nprimordial perturbations for this model. We give the general expressions of the\nscalar spectral index, its running, and the tensor-to-scalar ratio, etc. For\nthe chaotic inflation with a quadratic potential, using the WMAP 5-year\nresults, we determine the parameters of the Chaplygin inflation model in loop\nquantum cosmology. The results are consistent with the WMAP observations. \n\n"}
{"id": "0903.2882", "contents": "Title: Intermittency in the photosphere and corona above an active region Abstract: Recent studies undoubtedly demonstrate that the magnetic field in the\nphotosphere and corona is an intermittent structure, which offers new views on\nthe underlying physics. In particular, such problems as the existence in the\ncorona of localized areas with extremely strong resistivity (required to\nexplain magnetic reconnection of all scales) and the interchange between small\nand large scales (required in study of the photosphere/corona coupling), to\nname a few, can be easily captured by the concept of intermittency. This study\nis focused on simultaneous time variations of intermittency properties derived\nin the photosphere, chromosphere and corona. We analyzed data for NOAA AR 10930\nacquired between Dec 08, 2006 12:00 UT and Dec 13, 2006 18:45 UT. Photospheric\nintermittency was inferred from Hinode magnetic field measurements, while\nintermittency in the transition region and corona was derived from Nobeyama 9\nGHz radio polarization measurements, high cadence Hinode/XRT/Be-thin data as\nwell as GOES 1-8\\AA flux. Photospheric dynamics and its possible relationship\nwith the intermittency variations were also analyzed by calculating the kinetic\nvorticity. For this case study we found the following chain of events.\nIntermittency of the photospheric magnetic field peaked after the specific\nkinetic vorticity of plasma flows in the AR reached its maximum level (4 hour\ntime delay). In turn, gradual increase of coronal intermittency occurred after\nthe peak of the photospheric intermittency. The time delay between the peak of\nphotospheric intermittency and the occurrence of the first strong (X3.4) flare\nwas approximately 1.3 days. Our analysis seems to suggest that the enhancement\nof intermittency/complexity first occurs in the photosphere and is later\ntransported toward the corona. \n\n"}
{"id": "0904.1507", "contents": "Title: Active Galactic Nuclei with Starbursts: Sources for Ultra High Energy\n  Cosmic Rays Abstract: Ultra high energy cosmic ray events presently show a spectrum, which we\ninterpret here as galactic cosmic rays due to a starburst in the radio galaxy\nCen A pushed up in energy by the shock of a relativistic jet. The knee feature\nand the particles with energy immediately higher in galactic cosmic rays then\nturn into the bulk of ultra high energy cosmic rays. This entails that all\nultra high energy cosmic rays are heavy nuclei. This picture is viable if the\nmajority of the observed ultra high energy events come from the radio galaxy\nCen A, and are scattered by intergalactic magnetic fields across most of the\nsky. \n\n"}
{"id": "0904.1851", "contents": "Title: Standing gravitational waves from domain walls Abstract: We construct a plane symmetric, standing gravitational wave for a domain wall\nplus a massless scalar field. The scalar field can be associated with a fluid\nwhich has the properties of `stiff' matter, i.e. matter in which the speed of\nsound equals the speed of light. Although domain walls are observationally\nruled out in the present era the solution has interesting features which might\nshed light on the character of exact non-linear wave solutions to Einstein's\nequations. Additionally this solution may act as a template for higher\ndimensional 'brane-world' model standing waves. \n\n"}
{"id": "0904.2037", "contents": "Title: Boosting through Optimization of Margin Distributions Abstract: Boosting has attracted much research attention in the past decade. The\nsuccess of boosting algorithms may be interpreted in terms of the margin\ntheory. Recently it has been shown that generalization error of classifiers can\nbe obtained by explicitly taking the margin distribution of the training data\ninto account. Most of the current boosting algorithms in practice usually\noptimizes a convex loss function and do not make use of the margin\ndistribution. In this work we design a new boosting algorithm, termed\nmargin-distribution boosting (MDBoost), which directly maximizes the average\nmargin and minimizes the margin variance simultaneously. This way the margin\ndistribution is optimized. A totally-corrective optimization algorithm based on\ncolumn generation is proposed to implement MDBoost. Experiments on UCI datasets\nshow that MDBoost outperforms AdaBoost and LPBoost in most cases. \n\n"}
{"id": "0905.0666", "contents": "Title: The Geometrical Modelling of Fluids Abstract: The paper considers the nonlinear electrodynamics type model and its relation\nwith relativistic hydrodynamics with no dissipation (including string and\nmembrane hydrodynamics). We are able to convert arbitrary flux of fluid to the\nfamily of geodesics by the conformal transformation of metric. The conditions\nof transformation of nonlinear electrodynamics solution to linear\nelectrodynamics solution by changing of metric are presented. \n\n"}
{"id": "0905.1929", "contents": "Title: Atom interferometry tests of local Lorentz invariance in gravity and\n  electrodynamics Abstract: We present atom-interferometer tests of the local Lorentz invariance of\npost-Newtonian gravity. An experiment probing for anomalous vertical gravity on\nEarth, which has already been performed by us, uses the highest-resolution\natomic gravimeter so far. The influence of Lorentz violation in electrodynamics\nis also taken into account, resulting in combined bounds on Lorentz violation\nin gravity and electrodynamics. Expressed within the standard model extension\nor Nordtvedt's anisotropic universe model, we limit twelve linear combinations\nof seven coefficients for Lorentz violation at the part per billion level, from\nwhich we derive limits on six coefficients (and seven when taking into account\nadditional data from lunar laser ranging). We also discuss the use of\nhorizontal interferometers, including atom-chip or guided-atom devices, which\npotentially allow the use of longer coherence times in order to achieve higher\nsensitivity. \n\n"}
{"id": "0907.4647", "contents": "Title: Foamy structure of spacetime Abstract: We examine spectrum of the physical volume operator within the non-standard\nloop quantum cosmology. The spectrum is discrete with equally distant levels\ndefining a quantum of the volume. The discreteness may imply a foamy structure\nof spacetime at semi-classical level which may be detected in astro-cosmo\nobservations. \n\n"}
{"id": "0908.0661", "contents": "Title: Topological Black Holes of (n+1)-dimensional Einstein-Yang-Mills Gravity Abstract: We present the topological solutions of Einstein gravity in the presence of a\nnon-Abelian Yang-Mills field. In ($n+1$) dimensions, we consider the\n$So(n(n-1)/2-1,1)$ semisimple group as the Yang-Mills gauge group, and\nintroduce the black hole solutions with hyperbolic horizon. We argue that the\n4-dimensional solution is exactly the same as the 4-dimensional solution of\nEinstein-Maxwell gravity, while the higher-dimensional solutions are new. We\ninvestigate the properties of the higher-dimensional solutions and find that\nthese solutions in 5 dimensions have the same properties as the topological\n5-dimensional solution of Einstein-Maxwell (EM) theory although the metric\nfunction in 5 dimensions is different. But in 6 and higher dimensions, the\ntopological solutions of EYM and EM gravities with non-negative mass have\ndifferent properties. First, the singularity of EYM solution does not present a\nnaked singularity and is spacelike, while the singularity of topological\nReissner-Nordstrom solution is timelike. Second, there are no extreme 6 or\nhigher-dimensional black holes in EYM gravity with non-negative mass, while\nthese kinds of solutions exist in EM gravity. Furthermore, EYM theory has no\nstatic asymptotically de Sitter solution with non-negative mass, while EM\ngravity has. \n\n"}
{"id": "0910.3784", "contents": "Title: Universe on Extremely Small Spacetime Scales: Quantum Geometrodynamical\n  Approach Abstract: The semi-classical approach to the quantum geometrodynamical model is used\nfor the description of the properties of the universe on extremely small\nspacetime scales. Quantum theory for a homogeneous, isotropic and closed\nuniverse is constructed on the basis of a Hamiltonian formalism with the use of\nmaterial reference system as a dynamical system defined by macroscopic\nrelativistic matter. The equations of the model are reduced to the form of the\nEinstein-type equations in which the matter energy density has two components\nof quantum nature, which behave as antigravitating fluids. The first component\ndoes not vanish in the limit h -> 0 and can be associated with dark energy. The\nsecond component is described by extremely rigid equation of state and goes to\nzero after the transition to large spacetime scales. On small spacetime scales\nthis quantum correction determines the geometry of the universe. This geometry\nis conformal to a unit four-sphere embedded in a five-dimensional Euclidean\nflat space. When reaching the post-Planck era, the geometry of the universe\nchanges into the geometry conformal to a unit four-hyperboloid in a\nfive-dimensional Lorentz-signatured flat space. Near the boundary between two\nregions the universe undergoes almost an exponential expansion which passes\nsmoothly into the expansion under the action of radiation dominating over\nmatter which is described by the standard cosmological model. \n\n"}
{"id": "1005.3579", "contents": "Title: Graph-Structured Multi-task Regression and an Efficient Optimization\n  Method for General Fused Lasso Abstract: We consider the problem of learning a structured multi-task regression, where\nthe output consists of multiple responses that are related by a graph and the\ncorrelated response variables are dependent on the common inputs in a sparse\nbut synergistic manner. Previous methods such as l1/l2-regularized multi-task\nregression assume that all of the output variables are equally related to the\ninputs, although in many real-world problems, outputs are related in a complex\nmanner. In this paper, we propose graph-guided fused lasso (GFlasso) for\nstructured multi-task regression that exploits the graph structure over the\noutput variables. We introduce a novel penalty function based on fusion penalty\nto encourage highly correlated outputs to share a common set of relevant\ninputs. In addition, we propose a simple yet efficient proximal-gradient method\nfor optimizing GFlasso that can also be applied to any optimization problems\nwith a convex smooth loss and the general class of fusion penalty defined on\narbitrary graph structures. By exploiting the structure of the non-smooth\n''fusion penalty'', our method achieves a faster convergence rate than the\nstandard first-order method, sub-gradient method, and is significantly more\nscalable than the widely adopted second-order cone-programming and\nquadratic-programming formulations. In addition, we provide an analysis of the\nconsistency property of the GFlasso model. Experimental results not only\ndemonstrate the superiority of GFlasso over the standard lasso but also show\nthe efficiency and scalability of our proximal-gradient method. \n\n"}
{"id": "1007.2790", "contents": "Title: Phenomenology of the Equivalence Principle with Light Scalars Abstract: Light scalar particles with couplings of sub-gravitational strength, which\ncan generically be called 'dilatons', can produce violations of the equivalence\nprinciple. However, in order to understand experimental sensitivities one must\nknow the coupling of these scalars to atomic systems. We report here on a study\nof the required couplings. We give a general Lagrangian with five independent\ndilaton parameters and calculate the \"dilaton charge\" of atomic systems for\neach of these. Two combinations are particularly important. One is due to the\nvariations in the nuclear binding energy, with a sensitivity scaling with the\natomic number as $A^{-1/3}$. The other is due to electromagnetism. We compare\nlimits on the dilaton parameters from existing experiments. \n\n"}
{"id": "1012.1194", "contents": "Title: Does an atom interferometer test the gravitational redshift at the\n  Compton frequency ? Abstract: Atom interferometers allow the measurement of the acceleration of freely\nfalling atoms with respect to an experimental platform at rest on Earth's\nsurface. Such experiments have been used to test the universality of free fall\nby comparing the acceleration of the atoms to that of a classical freely\nfalling object. In a recent paper, M\\\"uller, Peters and Chu [Nature {\\bf 463},\n926-929 (2010)] argued that atom interferometers also provide a very accurate\ntest of the gravitational redshift when considering the atom as a clock\noperating at the Compton frequency associated with the rest mass. We analyze\nthis claim in the frame of general relativity and of different alternative\ntheories. We show that the difference of \"Compton phases\" between the two paths\nof the interferometer is actually zero in a large class of theories, including\ngeneral relativity, all metric theories of gravity, most non-metric theories\nand most theoretical frameworks used to interpret the violations of the\nequivalence principle. Therefore, in most plausible theoretical frameworks,\nthere is no redshift effect and atom interferometers only test the universality\nof free fall. We also show that frameworks in which atom interferometers would\ntest the redshift pose serious problems, such as (i) violation of the Schiff\nconjecture, (ii) violation of the Feynman path integral formulation of quantum\nmechanics and of the principle of least action for matter waves, (iii)\nviolation of energy conservation, and more generally (iv) violation of the\nparticle-wave duality in quantum mechanics. Standard quantum mechanics is no\nlonger valid in such frameworks, so that a consistent interpretation of the\nexperiment would require an alternative formulation of quantum mechanics. As\nsuch an alternative has not been proposed to date, we conclude that the\ninterpretation of atom interferometers as testing the gravitational redshift is\nunsound. \n\n"}
{"id": "1012.2646", "contents": "Title: Constraints on scalar-tensor theories of gravity from observations Abstract: In spite of their original discrepancy, both dark energy and modified theory\nof gravity can be parameterized by the effective equation of state (EOS)\n$\\omega$ for the expansion history of the Universe. A useful model independent\napproach to the EOS of them can be given by so-called\nChevallier-Polarski-Linder (CPL) parametrization where two parameters of it\n($\\omega_{0}$ and $\\omega_{a}$) can be constrained by the geometrical\nobservations which suffer from degeneracies between models. The linear growth\nof large scale structure is usually used to remove these degeneracies. This\ngrowth can be described by the growth index parameter $\\gamma$ and it can be\nparameterized by $\\gamma_{0} + \\gamma_{a} (1 - a)$ in general. We use the\nscalar-tensor theories of gravity (STG) and show that the discernment between\nmodels is possible only when $\\gamma_a$ is not negligible. We show that the\nlinear density perturbation of the matter component as a function of redshift\nseverely constrains the viable subclasses of STG in terms of $\\omega$ and\n$\\gamma$. From this method, we can rule out or prove the viable STG in future\nobservations. When we use $Z(\\phi) =1$, $F$ shows the convex shape of evolution\nin a viable STG model. The viable STG models with $Z(\\phi) = 1$ are not\ndistinguishable from dark energy models when we strongly limit the solar system\nconstraint. \n\n"}
{"id": "1012.4617", "contents": "Title: Contribution of the hybrid inflation waterfall to the primordial\n  curvature perturbation Abstract: A contribution $\\zeta_\\chi$ to the curvature perturbation will be generated\nduring the waterfall that ends hybrid inflation, that may be significant on\nsmall scales. In particular, it may lead to excessive black hole formation. We\nhere consider standard hybrid inflation, where the tachyonic mass of the\nwaterfall field is much bigger than the Hubble parameter. We calculate\n$\\zeta_\\chi$ in the simplest case, and see why earlier calculations of\n$\\zeta_\\chi$ are incorrect. \n\n"}
{"id": "1102.0059", "contents": "Title: Statistical methods for tissue array images - algorithmic scoring and\n  co-training Abstract: Recent advances in tissue microarray technology have allowed\nimmunohistochemistry to become a powerful medium-to-high throughput analysis\ntool, particularly for the validation of diagnostic and prognostic biomarkers.\nHowever, as study size grows, the manual evaluation of these assays becomes a\nprohibitive limitation; it vastly reduces throughput and greatly increases\nvariability and expense. We propose an algorithm - Tissue Array Co-Occurrence\nMatrix Analysis (TACOMA) - for quantifying cellular phenotypes based on\ntextural regularity summarized by local inter-pixel relationships. The\nalgorithm can be easily trained for any staining pattern, is absent of\nsensitive tuning parameters and has the ability to report salient pixels in an\nimage that contribute to its score. Pathologists' input via informative\ntraining patches is an important aspect of the algorithm that allows the\ntraining for any specific marker or cell type. With co-training, the error rate\nof TACOMA can be reduced substantially for a very small training sample (e.g.,\nwith size 30). We give theoretical insights into the success of co-training via\nthinning of the feature set in a high-dimensional setting when there is\n\"sufficient\" redundancy among the features. TACOMA is flexible, transparent and\nprovides a scoring process that can be evaluated with clarity and confidence.\nIn a study based on an estrogen receptor (ER) marker, we show that TACOMA is\ncomparable to, or outperforms, pathologists' performance in terms of accuracy\nand repeatability. \n\n"}
{"id": "1102.1182", "contents": "Title: Phase transition in the detection of modules in sparse networks Abstract: We present an asymptotically exact analysis of the problem of detecting\ncommunities in sparse random networks. Our results are also applicable to\ndetection of functional modules, partitions, and colorings in noisy planted\nmodels. Using a cavity method analysis, we unveil a phase transition from a\nregion where the original group assignment is undetectable to one where\ndetection is possible. In some cases, the detectable region splits into an\nalgorithmically hard region and an easy one. Our approach naturally translates\ninto a practical algorithm for detecting modules in sparse networks, and\nlearning the parameters of the underlying model. \n\n"}
{"id": "1107.1491", "contents": "Title: Holographic Dual of de Sitter Universe with AdS Bubbles Abstract: We study the proposal that a de Sitter (dS) universe with an Anti-de Sitter\n(AdS) bubble can be replaced by a dS universe with a boundary CFT. To explore\nthis duality, we consider incident gravitons coming from the dS universe\nthrough the bubble wall into the AdS bubble in the original picture. In the\ndual picture, this process has to be identified with the absorption of\ngravitons by CFT matter. We have obtained a general formula for the absorption\nprobability in general $d+1$ spacetime dimensions. The result shows the\ndifferent behavior depending on whether spacetime dimensions are even or odd.\nWe find that the absorption process of gravitons from the dS universe by CFT\nmatter is controlled by localized gravitons (massive bound state modes in the\nKaluza-Klein decomposition) in the dS universe. The absorption probability is\ndetermined by the effective degrees of freedom of the CFT matter and the\neffective gravitational coupling constant which encodes information of\nlocalized gravitons. We speculate that the dual of $d+1$ dimensional dS\nuniverse with an AdS bubble is also dual to a $d$ dimensional dS universe with\nCFT matter. \n\n"}
{"id": "1107.2021", "contents": "Title: Multi-Instance Learning with Any Hypothesis Class Abstract: In the supervised learning setting termed Multiple-Instance Learning (MIL),\nthe examples are bags of instances, and the bag label is a function of the\nlabels of its instances. Typically, this function is the Boolean OR. The\nlearner observes a sample of bags and the bag labels, but not the instance\nlabels that determine the bag labels. The learner is then required to emit a\nclassification rule for bags based on the sample. MIL has numerous\napplications, and many heuristic algorithms have been used successfully on this\nproblem, each adapted to specific settings or applications. In this work we\nprovide a unified theoretical analysis for MIL, which holds for any underlying\nhypothesis class, regardless of a specific application or problem domain. We\nshow that the sample complexity of MIL is only poly-logarithmically dependent\non the size of the bag, for any underlying hypothesis class. In addition, we\nintroduce a new PAC-learning algorithm for MIL, which uses a regular supervised\nlearning algorithm as an oracle. We prove that efficient PAC-learning for MIL\ncan be generated from any efficient non-MIL supervised learning algorithm that\nhandles one-sided error. The computational complexity of the resulting\nalgorithm is only polynomially dependent on the bag size. \n\n"}
{"id": "1109.4540", "contents": "Title: Manifold estimation and singular deconvolution under Hausdorff loss Abstract: We find lower and upper bounds for the risk of estimating a manifold in\nHausdorff distance under several models. We also show that there are close\nconnections between manifold estimation and the problem of deconvolving a\nsingular measure. \n\n"}
{"id": "1109.4979", "contents": "Title: Latent Semantic Learning with Structured Sparse Representation for Human\n  Action Recognition Abstract: This paper proposes a novel latent semantic learning method for extracting\nhigh-level features (i.e. latent semantics) from a large vocabulary of abundant\nmid-level features (i.e. visual keywords) with structured sparse\nrepresentation, which can help to bridge the semantic gap in the challenging\ntask of human action recognition. To discover the manifold structure of\nmidlevel features, we develop a spectral embedding approach to latent semantic\nlearning based on L1-graph, without the need to tune any parameter for graph\nconstruction as a key step of manifold learning. More importantly, we construct\nthe L1-graph with structured sparse representation, which can be obtained by\nstructured sparse coding with its structured sparsity ensured by novel L1-norm\nhypergraph regularization over mid-level features. In the new embedding space,\nwe learn latent semantics automatically from abundant mid-level features\nthrough spectral clustering. The learnt latent semantics can be readily used\nfor human action recognition with SVM by defining a histogram intersection\nkernel. Different from the traditional latent semantic analysis based on topic\nmodels, our latent semantic learning method can explore the manifold structure\nof mid-level features in both L1-graph construction and spectral embedding,\nwhich results in compact but discriminative high-level features. The\nexperimental results on the commonly used KTH action dataset and unconstrained\nYouTube action dataset show the superior performance of our method. \n\n"}
{"id": "1110.2177", "contents": "Title: Halo Scale Predictions of Symmetron Modified Gravity Abstract: We offer predictions of symmetron modified gravity in the neighborhood of\nrealistic dark matter halos. The predictions for the fifth force are obtained\nby solving the nonlinear symmetron equation of motion in the spherical NFW\napproximation. In addition, we compare the three major known screening\nmechanisms: Vainshtein, Chameleon, and Symmetron around such dark matter\nsources, emphasizing the significant differences between them and highlighting\nobservational tests which exploit these differences. Finally, we demonstrate\nthe host halo environmental screening effect (\"blanket screening\") on smaller\nsatellite halos by solving for the modified forces around a density profile\nwhich is the sum of satellite and approximate host components. \n\n"}
{"id": "1111.6853", "contents": "Title: The future of cosmology and the role of non-linear perturbations Abstract: Cosmological perturbation theory is a key tool to study the universe. The\nlinear or first order theory is well understood, however, developing and\napplying the theory beyond linear order is at the cutting edge of current\nresearch in theoretical cosmology. In this article, I will describe some\nsignatures of non-linear perturbation theory that do not exist at linear order,\nfocusing on vorticity generation at second order. In doing so, we discuss why\nthis, among other features such as induced gravitational waves and\nnon-Gaussianities, shows that cosmological perturbation theory is crucial for\ntesting models of the universe. \n\n"}
{"id": "1202.4177", "contents": "Title: $Q$- and $A$-Learning Methods for Estimating Optimal Dynamic Treatment\n  Regimes Abstract: In clinical practice, physicians make a series of treatment decisions over\nthe course of a patient's disease based on his/her baseline and evolving\ncharacteristics. A dynamic treatment regime is a set of sequential decision\nrules that operationalizes this process. Each rule corresponds to a decision\npoint and dictates the next treatment action based on the accrued information.\nUsing existing data, a key goal is estimating the optimal regime, that, if\nfollowed by the patient population, would yield the most favorable outcome on\naverage. Q- and A-learning are two main approaches for this purpose. We provide\na detailed account of these methods, study their performance, and illustrate\nthem using data from a depression study. \n\n"}
{"id": "1203.6130", "contents": "Title: Spectral dimensionality reduction for HMMs Abstract: Hidden Markov Models (HMMs) can be accurately approximated using\nco-occurrence frequencies of pairs and triples of observations by using a fast\nspectral method in contrast to the usual slow methods like EM or Gibbs\nsampling. We provide a new spectral method which significantly reduces the\nnumber of model parameters that need to be estimated, and generates a sample\ncomplexity that does not depend on the size of the observation vocabulary. We\npresent an elementary proof giving bounds on the relative accuracy of\nprobability estimates from our model. (Correlaries show our bounds can be\nweakened to provide either L1 bounds or KL bounds which provide easier direct\ncomparisons to previous work.) Our theorem uses conditions that are checkable\nfrom the data, instead of putting conditions on the unobservable Markov\ntransition matrix. \n\n"}
{"id": "1204.6435", "contents": "Title: Fast Scramblers, Horizons and Expander Graphs Abstract: We propose that local quantum systems defined on expander graphs provide a\nsimple microscopic model for thermalization on quantum horizons. Such systems\nare automatically fast scramblers and are motivated from the membrane paradigm\nby a conformal transformation to the so-called optical metric. \n\n"}
{"id": "1205.4481", "contents": "Title: Stochastic Smoothing for Nonsmooth Minimizations: Accelerating SGD by\n  Exploiting Structure Abstract: In this work we consider the stochastic minimization of nonsmooth convex loss\nfunctions, a central problem in machine learning. We propose a novel algorithm\ncalled Accelerated Nonsmooth Stochastic Gradient Descent (ANSGD), which\nexploits the structure of common nonsmooth loss functions to achieve optimal\nconvergence rates for a class of problems including SVMs. It is the first\nstochastic algorithm that can achieve the optimal O(1/t) rate for minimizing\nnonsmooth loss functions (with strong convexity). The fast rates are confirmed\nby empirical comparisons, in which ANSGD significantly outperforms previous\nsubgradient descent algorithms including SGD. \n\n"}
{"id": "1206.0333", "contents": "Title: Sparse Trace Norm Regularization Abstract: We study the problem of estimating multiple predictive functions from a\ndictionary of basis functions in the nonparametric regression setting. Our\nestimation scheme assumes that each predictive function can be estimated in the\nform of a linear combination of the basis functions. By assuming that the\ncoefficient matrix admits a sparse low-rank structure, we formulate the\nfunction estimation problem as a convex program regularized by the trace norm\nand the $\\ell_1$-norm simultaneously. We propose to solve the convex program\nusing the accelerated gradient (AG) method and the alternating direction method\nof multipliers (ADMM) respectively; we also develop efficient algorithms to\nsolve the key components in both AG and ADMM. In addition, we conduct\ntheoretical analysis on the proposed function estimation scheme: we derive a\nkey property of the optimal solution to the convex program; based on an\nassumption on the basis functions, we establish a performance bound of the\nproposed function estimation scheme (via the composite regularization).\nSimulation studies demonstrate the effectiveness and efficiency of the proposed\nalgorithms. \n\n"}
{"id": "1206.2348", "contents": "Title: Structure formation in Multiple Dark Matter cosmologies with long-range\n  scalar interactions Abstract: (Abridged) An interaction between Cold Dark Matter (CDM) and a classical\nscalar field playing the role of the cosmic dark energy (DE) might provide\nlong-range dark interactions without conflicting with solar system bounds.\nAlthough presently available observations allow to constrain such interactions\nto a few percent of the gravitational strength, some recent studies have shown\nthat if CDM is composed by two different particle species having opposite\ncouplings to the DE field, such tight constraints can be considerably relaxed,\nallowing for long-range scalar forces of order gravity without significantly\naffecting observations both at the background and at the linear perturbations\nlevel. In the present work, we extend the investigation of such Multiple Dark\nMatter scenarios to the nonlinear regime of structure formation, by presenting\nthe first N-body simulations ever performed for these cosmologies. Our results\nhighlight some characteristic footprints of long-range scalar forces that arise\nonly in the nonlinear regime for specific models that would be otherwise\npractically indistinguishable from the standard LCDM scenario both in the\nbackground and in the growth of linear density perturbations. Among these\neffects, the formation of \"mirror\" cosmic structures in the two CDM species,\nthe suppression of the nonlinear matter power spectrum at k > 1 h/Mpc, and the\nfragmentation of collapsed halos, represent peculiar features that might\nprovide a direct way to constrain this class of cosmological models. \n\n"}
{"id": "1207.0099", "contents": "Title: Density-Difference Estimation Abstract: We address the problem of estimating the difference between two probability\ndensities. A naive approach is a two-step procedure of first estimating two\ndensities separately and then computing their difference. However, such a\ntwo-step procedure does not necessarily work well because the first step is\nperformed without regard to the second step and thus a small error incurred in\nthe first stage can cause a big error in the second stage. In this paper, we\npropose a single-shot procedure for directly estimating the density difference\nwithout separately estimating two densities. We derive a non-parametric\nfinite-sample error bound for the proposed single-shot density-difference\nestimator and show that it achieves the optimal convergence rate. The\nusefulness of the proposed method is also demonstrated experimentally. \n\n"}
{"id": "1207.3100", "contents": "Title: Set-valued dynamic treatment regimes for competing outcomes Abstract: Dynamic treatment regimes operationalize the clinical decision process as a\nsequence of functions, one for each clinical decision, where each function\ntakes as input up-to-date patient information and gives as output a single\nrecommended treatment. Current methods for estimating optimal dynamic treatment\nregimes, for example Q-learning, require the specification of a single outcome\nby which the `goodness' of competing dynamic treatment regimes are measured.\nHowever, this is an over-simplification of the goal of clinical decision\nmaking, which aims to balance several potentially competing outcomes. For\nexample, often a balance must be struck between treatment effectiveness and\nside-effect burden. We propose a method for constructing dynamic treatment\nregimes that accommodates competing outcomes by recommending sets of treatments\nat each decision point. Formally, we construct a sequence of set-valued\nfunctions that take as input up-to-date patient information and give as output\na recommended subset of the possible treatments. For a given patient history,\nthe recommended set of treatments contains all treatments that are not inferior\naccording to any of the competing outcomes. When there is more than one\ndecision point, constructing these set-valued functions requires solving a\nnon-trivial enumeration problem. We offer an exact enumeration algorithm by\nrecasting the problem as a linear mixed integer program. The proposed methods\nare illustrated using data from a depression study and the CATIE schizophrenia\nstudy. \n\n"}
{"id": "1207.3772", "contents": "Title: Surrogate Losses in Passive and Active Learning Abstract: Active learning is a type of sequential design for supervised machine\nlearning, in which the learning algorithm sequentially requests the labels of\nselected instances from a large pool of unlabeled data points. The objective is\nto produce a classifier of relatively low risk, as measured under the 0-1 loss,\nideally using fewer label requests than the number of random labeled data\npoints sufficient to achieve the same. This work investigates the potential\nuses of surrogate loss functions in the context of active learning.\nSpecifically, it presents an active learning algorithm based on an arbitrary\nclassification-calibrated surrogate loss function, along with an analysis of\nthe number of label requests sufficient for the classifier returned by the\nalgorithm to achieve a given risk under the 0-1 loss. Interestingly, these\nresults cannot be obtained by simply optimizing the surrogate risk via active\nlearning to an extent sufficient to provide a guarantee on the 0-1 loss, as is\ncommon practice in the analysis of surrogate losses for passive learning. Some\nof the results have additional implications for the use of surrogate losses in\npassive learning. \n\n"}
{"id": "1207.6791", "contents": "Title: On the quasinormal modes of the de Sitter spacetime Abstract: Modifying a method by Horowitz and Hubeny for asymptotically anti-de Sitter\nblack holes, we establish the classical stability of the quasinormal modes of\nthe de Sitter spacetime. Furthermore using a straightforward method we\ncalculate the de Sitter quasinormal frequencies of the gravitational\nperturbations and discuss some properties of the radial functions of these\nquasinormal modes. \n\n"}
{"id": "1208.2015", "contents": "Title: Sharp analysis of low-rank kernel matrix approximations Abstract: We consider supervised learning problems within the positive-definite kernel\nframework, such as kernel ridge regression, kernel logistic regression or the\nsupport vector machine. With kernels leading to infinite-dimensional feature\nspaces, a common practical limiting difficulty is the necessity of computing\nthe kernel matrix, which most frequently leads to algorithms with running time\nat least quadratic in the number of observations n, i.e., O(n^2). Low-rank\napproximations of the kernel matrix are often considered as they allow the\nreduction of running time complexities to O(p^2 n), where p is the rank of the\napproximation. The practicality of such methods thus depends on the required\nrank p. In this paper, we show that in the context of kernel ridge regression,\nfor approximations based on a random subset of columns of the original kernel\nmatrix, the rank p may be chosen to be linear in the degrees of freedom\nassociated with the problem, a quantity which is classically used in the\nstatistical analysis of such methods, and is often seen as the implicit number\nof parameters of non-parametric estimators. This result enables simple\nalgorithms that have sub-quadratic running time complexity, but provably\nexhibit the same predictive performance than existing algorithms, for any given\nproblem instance, and not only for worst-case situations. \n\n"}
{"id": "1209.2139", "contents": "Title: Fused Multiple Graphical Lasso Abstract: In this paper, we consider the problem of estimating multiple graphical\nmodels simultaneously using the fused lasso penalty, which encourages adjacent\ngraphs to share similar structures. A motivating example is the analysis of\nbrain networks of Alzheimer's disease using neuroimaging data. Specifically, we\nmay wish to estimate a brain network for the normal controls (NC), a brain\nnetwork for the patients with mild cognitive impairment (MCI), and a brain\nnetwork for Alzheimer's patients (AD). We expect the two brain networks for NC\nand MCI to share common structures but not to be identical to each other;\nsimilarly for the two brain networks for MCI and AD. The proposed formulation\ncan be solved using a second-order method. Our key technical contribution is to\nestablish the necessary and sufficient condition for the graphs to be\ndecomposable. Based on this key property, a simple screening rule is presented,\nwhich decomposes the large graphs into small subgraphs and allows an efficient\nestimation of multiple independent (small) subgraphs, dramatically reducing the\ncomputational cost. We perform experiments on both synthetic and real data; our\nresults demonstrate the effectiveness and efficiency of the proposed approach. \n\n"}
{"id": "1209.2271", "contents": "Title: Removing the Big Bang Singularity: The role of the generalized\n  uncertainty principle in quantum gravity Abstract: The possibility of avoiding the big bang singularity by means of a\ngeneralized uncertainty principle is investigated. In relation with this\nmatter, the statistical mechanics of a free-particle system obeying the\ngeneralized uncertainty principle is studied and it is shown that the entropy\nof the system has a finite value in the infinite temperature limit. It is then\nargued that negative temperatures and negative pressures are possible in this\nsystem. Finally, it is shown that this model can remove the big bang\nsingularity. \n\n"}
{"id": "1209.2860", "contents": "Title: Non-AdS holography in 3-dimensional higher spin gravity - General recipe\n  and example Abstract: We present the general algorithm to establish the classical and quantum\nasymptotic symmetry algebra for non-AdS higher spin gravity and implement it\nfor the specific example of spin-3 gravity in the non-principal embedding with\nLobachevsky (H^2xR) boundary conditions. The asymptotic symmetry algebra for\nthis example consists of a quantum W_3^2 (Polyakov-Bershadsky) and an affine\nu(1) algebra. We show that unitary representations of the quantum W_3^2 algebra\nexist only for two values of its central charge, the trivial c=0 \"theory\" and\nthe simple c=1 theory. \n\n"}
{"id": "1211.2304", "contents": "Title: Probabilistic Combination of Classifier and Cluster Ensembles for\n  Non-transductive Learning Abstract: Unsupervised models can provide supplementary soft constraints to help\nclassify new target data under the assumption that similar objects in the\ntarget set are more likely to share the same class label. Such models can also\nhelp detect possible differences between training and target distributions,\nwhich is useful in applications where concept drift may take place. This paper\ndescribes a Bayesian framework that takes as input class labels from existing\nclassifiers (designed based on labeled data from the source domain), as well as\ncluster labels from a cluster ensemble operating solely on the target data to\nbe classified, and yields a consensus labeling of the target data. This\nframework is particularly useful when the statistics of the target data drift\nor change from those of the training data. We also show that the proposed\nframework is privacy-aware and allows performing distributed learning when\ndata/models have sharing restrictions. Experiments show that our framework can\nyield superior results to those provided by applying classifier ensembles only. \n\n"}
{"id": "1212.5637", "contents": "Title: Random Spanning Trees and the Prediction of Weighted Graphs Abstract: We investigate the problem of sequentially predicting the binary labels on\nthe nodes of an arbitrary weighted graph. We show that, under a suitable\nparametrization of the problem, the optimal number of prediction mistakes can\nbe characterized (up to logarithmic factors) by the cutsize of a random\nspanning tree of the graph. The cutsize is induced by the unknown adversarial\nlabeling of the graph nodes. In deriving our characterization, we obtain a\nsimple randomized algorithm achieving in expectation the optimal mistake bound\non any polynomially connected weighted graph. Our algorithm draws a random\nspanning tree of the original graph and then predicts the nodes of this tree in\nconstant expected amortized time and linear space. Experiments on real-world\ndatasets show that our method compares well to both global (Perceptron) and\nlocal (label propagation) methods, while being generally faster in practice. \n\n"}
{"id": "1212.5701", "contents": "Title: ADADELTA: An Adaptive Learning Rate Method Abstract: We present a novel per-dimension learning rate method for gradient descent\ncalled ADADELTA. The method dynamically adapts over time using only first order\ninformation and has minimal computational overhead beyond vanilla stochastic\ngradient descent. The method requires no manual tuning of a learning rate and\nappears robust to noisy gradient information, different model architecture\nchoices, various data modalities and selection of hyperparameters. We show\npromising results compared to other methods on the MNIST digit classification\ntask using a single machine and on a large scale voice dataset in a distributed\ncluster environment. \n\n"}
{"id": "1301.2683", "contents": "Title: BliStr: The Blind Strategymaker Abstract: BliStr is a system that automatically develops strategies for E prover on a\nlarge set of problems. The main idea is to interleave (i) iterated\nlow-timelimit local search for new strategies on small sets of similar easy\nproblems with (ii) higher-timelimit evaluation of the new strategies on all\nproblems. The accumulated results of the global higher-timelimit runs are used\nto define and evolve the notion of \"similar easy problems\", and to control the\nselection of the next strategy to be improved. The technique was used to\nsignificantly strengthen the set of E strategies used by the MaLARea, PS-E,\nE-MaLeS, and E systems in the CASC@Turing 2012 competition, particularly in the\nMizar division. Similar improvement was obtained on the problems created from\nthe Flyspeck corpus. \n\n"}
{"id": "1301.3627", "contents": "Title: Two SVDs produce more focal deep learning representations Abstract: A key characteristic of work on deep learning and neural networks in general\nis that it relies on representations of the input that support generalization,\nrobust inference, domain adaptation and other desirable functionalities. Much\nrecent progress in the field has focused on efficient and effective methods for\ncomputing representations. In this paper, we propose an alternative method that\nis more efficient than prior work and produces representations that have a\nproperty we call focality -- a property we hypothesize to be important for\nneural network representations. The method consists of a simple application of\ntwo consecutive SVDs and is inspired by Anandkumar (2012). \n\n"}
{"id": "1301.4083", "contents": "Title: Knowledge Matters: Importance of Prior Information for Optimization Abstract: We explore the effect of introducing prior information into the intermediate\nlevel of neural networks for a learning task on which all the state-of-the-art\nmachine learning algorithms tested failed to learn. We motivate our work from\nthe hypothesis that humans learn such intermediate concepts from other\nindividuals via a form of supervision or guidance using a curriculum. The\nexperiments we have conducted provide positive evidence in favor of this\nhypothesis. In our experiments, a two-tiered MLP architecture is trained on a\ndataset with 64x64 binary inputs images, each image with three sprites. The\nfinal task is to decide whether all the sprites are the same or one of them is\ndifferent. Sprites are pentomino tetris shapes and they are placed in an image\nwith different locations using scaling and rotation transformations. The first\npart of the two-tiered MLP is pre-trained with intermediate-level targets being\nthe presence of sprites at each location, while the second part takes the\noutput of the first part as input and predicts the final task's target binary\nevent. The two-tiered MLP architecture, with a few tens of thousand examples,\nwas able to learn the task perfectly, whereas all other algorithms (include\nunsupervised pre-training, but also traditional algorithms like SVMs, decision\ntrees and boosting) all perform no better than chance. We hypothesize that the\noptimization difficulty involved when the intermediate pre-training is not\nperformed is due to the {\\em composition} of two highly non-linear tasks. Our\nfindings are also consistent with hypotheses on cultural learning inspired by\nthe observations of optimization problems with deep learning, presumably\nbecause of effective local minima. \n\n"}
{"id": "1302.1271", "contents": "Title: Squeezed primordial bispectrum from general vacuum state Abstract: We study the general relation between the power spectrum and the squeezed\nlimit of the bispectrum of the comoving curvature perturbation produced during\nsingle-field slow-roll inflation when the initial state is a general vacuum.\nAssuming the scale invariance of the power spectrum, we derive a formula for\nthe squeezed limit of the bispectrum, represented by the parameter fNL, which\nis not slow-roll suppressed and is found to contain a single free parameter for\na given amplitude of the power spectrum. Then we derive the conditions for\nachieving a scale-invariant fNL, and discuss a few examples. \n\n"}
{"id": "1302.2576", "contents": "Title: The trace norm constrained matrix-variate Gaussian process for multitask\n  bipartite ranking Abstract: We propose a novel hierarchical model for multitask bipartite ranking. The\nproposed approach combines a matrix-variate Gaussian process with a generative\nmodel for task-wise bipartite ranking. In addition, we employ a novel trace\nconstrained variational inference approach to impose low rank structure on the\nposterior matrix-variate Gaussian process. The resulting posterior covariance\nfunction is derived in closed form, and the posterior mean function is the\nsolution to a matrix-variate regression with a novel spectral elastic net\nregularizer. Further, we show that variational inference for the trace\nconstrained matrix-variate Gaussian process combined with maximum likelihood\nparameter estimation for the bipartite ranking model is jointly convex. Our\nmotivating application is the prioritization of candidate disease genes. The\ngoal of this task is to aid the identification of unobserved associations\nbetween human genes and diseases using a small set of observed associations as\nwell as kernels induced by gene-gene interaction networks and disease\nontologies. Our experimental results illustrate the performance of the proposed\nmodel on real world datasets. Moreover, we find that the resulting low rank\nsolution improves the computational scalability of training and testing as\ncompared to baseline models. \n\n"}
{"id": "1302.2671", "contents": "Title: Latent Self-Exciting Point Process Model for Spatial-Temporal Networks Abstract: We propose a latent self-exciting point process model that describes\ngeographically distributed interactions between pairs of entities. In contrast\nto most existing approaches that assume fully observable interactions, here we\nconsider a scenario where certain interaction events lack information about\nparticipants. Instead, this information needs to be inferred from the available\nobservations. We develop an efficient approximate algorithm based on\nvariational expectation-maximization to infer unknown participants in an event\ngiven the location and the time of the event. We validate the model on\nsynthetic as well as real-world data, and obtain very promising results on the\nidentity-inference task. We also use our model to predict the timing and\nparticipants of future events, and demonstrate that it compares favorably with\nbaseline approaches. \n\n"}
{"id": "1302.4549", "contents": "Title: Breaking the Small Cluster Barrier of Graph Clustering Abstract: This paper investigates graph clustering in the planted cluster model in the\npresence of {\\em small clusters}. Traditional results dictate that for an\nalgorithm to provably correctly recover the clusters, {\\em all} clusters must\nbe sufficiently large (in particular, $\\tilde{\\Omega}(\\sqrt{n})$ where $n$ is\nthe number of nodes of the graph). We show that this is not really a\nrestriction: by a more refined analysis of the trace-norm based recovery\napproach proposed in Jalali et al. (2011) and Chen et al. (2012), we prove that\nsmall clusters, under certain mild assumptions, do not hinder recovery of large\nones.\n  Based on this result, we further devise an iterative algorithm to recover\n{\\em almost all clusters} via a \"peeling strategy\", i.e., recover large\nclusters first, leading to a reduced problem, and repeat this procedure. These\nresults are extended to the {\\em partial observation} setting, in which only a\n(chosen) part of the graph is observed.The peeling strategy gives rise to an\nactive learning algorithm, in which edges adjacent to smaller clusters are\nqueried more often as large clusters are learned (and removed).\n  From a high level, this paper sheds novel insights on high-dimensional\nstatistics and learning structured data, by presenting a structured matrix\nlearning problem for which a one shot convex relaxation approach necessarily\nfails, but a carefully constructed sequence of convex relaxationsdoes the job. \n\n"}
{"id": "1304.6934", "contents": "Title: Towards a double-scaling limit for tensor models: probing sub-dominant\n  orders Abstract: The definition of a double-scaling limit represents an important goal in the\ndevelopment of tensor models. We take the first steps towards this goal by\nextracting and analysing the next-to-leading order contributions, in the 1/N\nexpansion, for the IID tensor models. We show that the radius of convergence of\nthe NLO series coincides with that of the leading order melonic sector.\nMeanwhile, the value of the susceptibility exponent at NLO is 3/2, signaling a\ndeparture from the leading order behaviour. Both pieces of information provide\nclues for a non-trivial double-scaling limit, for which we put forward some\nprecise conjecture. \n\n"}
{"id": "1306.0908", "contents": "Title: Partially massless gravitons do not destroy general relativity black\n  holes Abstract: Recent nonlinear completions of Fierz-Pauli theory for a massive spin-2 field\ninclude nonlinear massive gravity and bimetric theories. The spectrum of\nblack-hole solutions in these theories is rich, and comprises the same vacuum\nsolutions of Einstein's gravity enlarged to include a cosmological constant. It\nwas recently shown that Schwarzschild (de Sitter) black holes in these theories\nare generically unstable against spherical perturbations. Here we show that a\nnotable exception is partially massless gravity, where the mass of the graviton\nis fixed in terms of the cosmological constant by \\mu^2=2\\Lambda/3 and a new\ngauge invariance emerges. We find that general-relativity black holes are\nstable in this limit. Remarkably, the spectrum of massive gravitational\nperturbations is isospectral. \n\n"}
{"id": "1306.3876", "contents": "Title: Dark matter and Wigner's third positive-energy representation class Abstract: The almost 7 decades lasting futile attempts to understand the possible\nphysical content of the third Wigner representation class (the infinite spin\nclass) came to a partial solution with the 2006 discovery of existence of\nstring-localized spacetime covariantizations . This has led to a still ongoing\nvast generalization of renormalizability to fields with arbitrary high spin and\na better understanding of the origin of partial invisibility as observed in the\nconfinement of gluons and quarks. The present note explains the total\n(non-gravitational) invisibility of fields associated to the third Wigner\nrepresentation class. The last section presents a critical look at the\npossibility that third class Wigner matter may play a role in dark matter\nformation. \n\n"}
{"id": "1306.5362", "contents": "Title: A Statistical Perspective on Algorithmic Leveraging Abstract: One popular method for dealing with large-scale data sets is sampling. For\nexample, by using the empirical statistical leverage scores as an importance\nsampling distribution, the method of algorithmic leveraging samples and\nrescales rows/columns of data matrices to reduce the data size before\nperforming computations on the subproblem. This method has been successful in\nimproving computational efficiency of algorithms for matrix problems such as\nleast-squares approximation, least absolute deviations approximation, and\nlow-rank matrix approximation. Existing work has focused on algorithmic issues\nsuch as worst-case running times and numerical issues associated with providing\nhigh-quality implementations, but none of it addresses statistical aspects of\nthis method.\n  In this paper, we provide a simple yet effective framework to evaluate the\nstatistical properties of algorithmic leveraging in the context of estimating\nparameters in a linear regression model with a fixed number of predictors. We\nshow that from the statistical perspective of bias and variance, neither\nleverage-based sampling nor uniform sampling dominates the other. This result\nis particularly striking, given the well-known result that, from the\nalgorithmic perspective of worst-case analysis, leverage-based sampling\nprovides uniformly superior worst-case algorithmic results, when compared with\nuniform sampling. Based on these theoretical results, we propose and analyze\ntwo new leveraging algorithms. A detailed empirical evaluation of existing\nleverage-based methods as well as these two new methods is carried out on both\nsynthetic and real data sets. The empirical results indicate that our theory is\na good predictor of practical performance of existing and new leverage-based\nalgorithms and that the new algorithms achieve improved performance. \n\n"}
{"id": "1306.6111", "contents": "Title: Understanding the Predictive Power of Computational Mechanics and Echo\n  State Networks in Social Media Abstract: There is a large amount of interest in understanding users of social media in\norder to predict their behavior in this space. Despite this interest, user\npredictability in social media is not well-understood. To examine this\nquestion, we consider a network of fifteen thousand users on Twitter over a\nseven week period. We apply two contrasting modeling paradigms: computational\nmechanics and echo state networks. Both methods attempt to model the behavior\nof users on the basis of their past behavior. We demonstrate that the behavior\nof users on Twitter can be well-modeled as processes with self-feedback. We\nfind that the two modeling approaches perform very similarly for most users,\nbut that they differ in performance on a small subset of the users. By\nexploring the properties of these performance-differentiated users, we\nhighlight the challenges faced in applying predictive models to dynamic social\ndata. \n\n"}
{"id": "1307.5191", "contents": "Title: Prompt merger collapse and the maximum mass of neutron stars Abstract: We perform hydrodynamical simulations of neutron-star mergers for a large\nsample of temperature-dependent, nuclear equations of state, and determine the\nthreshold mass above which the merger remnant promptly collapses to form a\nblack hole. We find that, depending on the equation of state, the threshold\nmass is larger than the maximum mass of a non-rotating star in isolation by\nbetween 30 and 70 per cent. Our simulations also show that the ratio between\nthe threshold mass and maximum mass is tightly correlated with the compactness\nof the non-rotating maximum-mass configuration. We speculate on how this\nrelation can be used to derive constraints on neutron-star properties from\nfuture observations. \n\n"}
{"id": "1308.0988", "contents": "Title: Binary systems in Palatini-f(R) gravity Abstract: We consider compact binary systems in f(R) gravity theories in the Palatini\napproach and calculate the post-Newtonian parameters to the 1.5PN order using\nthe method of Direct Integration of the Relaxed Einstein equations (DIRE). The\nPalatini-type modifications of gravity can be formulated as Einsteins gravity\nwith modified response to matter sources, and it is shown in detail how to\ntreat these correctly within the DIRE formalism. Our results explicitly confirm\nthe expectation that for binary black holes the new effects can be absorbed\ninto redefinitions of the binary masses, rendering such systems observationally\nidentical to general relativity. \n\n"}
{"id": "1308.1475", "contents": "Title: The effect of Dark Matter and Dark Energy interactions on the peculiar\n  velocity field and the kinetic Sunyaev-Zel'dovich effect Abstract: The interaction between Dark Matter and Dark Energy has been proposed as a\nmechanism to alleviate the coincidence problem. We analyze the effect of the\ninteraction on the evolution of the gravitational field and propose two new\nobservables based on its effect on the matter peculiar velocity field. We find\nthat for different model parameters the matter peculiar velocity could be\nfactor 2 times larger or 5 times smaller than the amplitude of velocity\nperturbations in the concordance LCDM cosmological model at the same scales. We\ncompare the effect on the peculiar velocities with those on the Integrated\nSachs-Wolfe effect and we show that velocities can potentially provide\nconstraints on the strength of the interaction stronger than those currently\navailable. We show that the current upper limits on the amplitude of the\nkinetic Sunyaev-Zel'dovich power spectrum provide constraints on the coupling\nwithin the dark sectors that are consistent with those obtained previously from\nthe CMB and galaxy clusters. In particular, we show that current upper limits\nfrom the Atacama Cosmology Telescope and the South Pole Telescope favor Dark\nEnergy decaying into Dark Matter, as required to solve the coincidence problem. \n\n"}
{"id": "1308.4016", "contents": "Title: Strings in compact cosmological spaces Abstract: We confront the problem of giving a fundamental definition to perturbative\nstring theory in spacetimes with totally compact space (taken to be a torus for\nsimplicity, though the nature of the problem is very general) and non-compact\ntime. Due to backreaction induced by the presence of even a single string\nquantum, the usual formulation of perturbative string theory in a fixed\nclassical background is infrared-divergent at all subleading orders in the\nstring coupling, and needs to be amended. The problem can be seen as a closed\nstring analogue of D0-brane recoil under an impact by closed strings (a\nsituation displaying extremely similar infrared divergences). Inspired by the\ncollective coordinate treatment of the D0-brane recoil, whereby the\ntranslational modes of the D0-brane are introduced as explicit dynamical\nvariables in the path integral, we construct a similar formalism for the case\nof string-induced gravitational backreaction, in which the spatially uniform\nmodes of the background fields on the compact space are quantized explicitly.\nThe formalism can equally well be seen as an ultraviolet completion of a\nminisuperspace quantum cosmology with string degrees of freedom. We consider\nthe amplitudes for the universe to have two cross-sections with specified\nspatial properties and string contents, and show (at the first non-trivial\norder) that they are finite within our formalism. \n\n"}
{"id": "1309.0003", "contents": "Title: Concentration Inequalities for Bounded Random Vectors Abstract: We derive simple concentration inequalities for bounded random vectors, which\ngeneralize Hoeffding's inequalities for bounded scalar random variables. As\napplications, we apply the general results to multinomial and Dirichlet\ndistributions to obtain multivariate concentration inequalities. \n\n"}
{"id": "1309.0671", "contents": "Title: BayesOpt: A Library for Bayesian optimization with Robotics Applications Abstract: The purpose of this paper is twofold. On one side, we present a general\nframework for Bayesian optimization and we compare it with some related fields\nin active learning and Bayesian numerical analysis. On the other hand, Bayesian\noptimization and related problems (bandits, sequential experimental design) are\nhighly dependent on the surrogate model that is selected. However, there is no\nclear standard in the literature. Thus, we present a fast and flexible toolbox\nthat allows to test and combine different models and criteria with little\neffort. It includes most of the state-of-the-art contributions, algorithms and\nmodels. Its speed also removes part of the stigma that Bayesian optimization\nmethods are only good for \"expensive functions\". The software is free and it\ncan be used in many operating systems and computer languages. \n\n"}
{"id": "1309.2074", "contents": "Title: Learning Transformations for Clustering and Classification Abstract: A low-rank transformation learning framework for subspace clustering and\nclassification is here proposed. Many high-dimensional data, such as face\nimages and motion sequences, approximately lie in a union of low-dimensional\nsubspaces. The corresponding subspace clustering problem has been extensively\nstudied in the literature to partition such high-dimensional data into clusters\ncorresponding to their underlying low-dimensional subspaces. However,\nlow-dimensional intrinsic structures are often violated for real-world\nobservations, as they can be corrupted by errors or deviate from ideal models.\nWe propose to address this by learning a linear transformation on subspaces\nusing matrix rank, via its convex surrogate nuclear norm, as the optimization\ncriteria. The learned linear transformation restores a low-rank structure for\ndata from the same subspace, and, at the same time, forces a a maximally\nseparated structure for data from different subspaces. In this way, we reduce\nvariations within subspaces, and increase separation between subspaces for a\nmore robust subspace clustering. This proposed learned robust subspace\nclustering framework significantly enhances the performance of existing\nsubspace clustering methods. Basic theoretical results here presented help to\nfurther support the underlying framework. To exploit the low-rank structures of\nthe transformed subspaces, we further introduce a fast subspace clustering\ntechnique, which efficiently combines robust PCA with sparse modeling. When\nclass labels are present at the training stage, we show this low-rank\ntransformation framework also significantly enhances classification\nperformance. Extensive experiments using public datasets are presented, showing\nthat the proposed approach significantly outperforms state-of-the-art methods\nfor subspace clustering and classification. \n\n"}
{"id": "1309.6707", "contents": "Title: Distributed Online Learning in Social Recommender Systems Abstract: In this paper, we consider decentralized sequential decision making in\ndistributed online recommender systems, where items are recommended to users\nbased on their search query as well as their specific background including\nhistory of bought items, gender and age, all of which comprise the context\ninformation of the user. In contrast to centralized recommender systems, in\nwhich there is a single centralized seller who has access to the complete\ninventory of items as well as the complete record of sales and user\ninformation, in decentralized recommender systems each seller/learner only has\naccess to the inventory of items and user information for its own products and\nnot the products and user information of other sellers, but can get commission\nif it sells an item of another seller. Therefore the sellers must distributedly\nfind out for an incoming user which items to recommend (from the set of own\nitems or items of another seller), in order to maximize the revenue from own\nsales and commissions. We formulate this problem as a cooperative contextual\nbandit problem, analytically bound the performance of the sellers compared to\nthe best recommendation strategy given the complete realization of user\narrivals and the inventory of items, as well as the context-dependent purchase\nprobabilities of each item, and verify our results via numerical examples on a\ndistributed data set adapted based on Amazon data. We evaluate the dependence\nof the performance of a seller on the inventory of items the seller has, the\nnumber of connections it has with the other sellers, and the commissions which\nthe seller gets by selling items of other sellers to its users. \n\n"}
{"id": "1309.7380", "contents": "Title: Entanglement entropy of a scalar field across a spherical boundary in\n  the Einstein universe Abstract: A scalar field in the ground state, when partially hidden from observation by\na spherical boundary, acquires entanglement entropy $S$ proportional to the\narea of the surface. This area law is well established in flat space, where it\nfollows almost directly from dimensional arguments. We study its validity in an\nEinstein universe, whose curvature provides an additional physical parameter on\nwhich the entropy could, in principle, depend. The surprisingly simple result\nis that the entanglement entropy still scales linearly with the area. This is\nsupported by other observations to the effect that the entanglement entropy\narises mostly from degrees of freedom near the boundary, making it insensitive\nto the large-scale geometry of the background space. \n\n"}
{"id": "1310.1949", "contents": "Title: Least Squares Revisited: Scalable Approaches for Multi-class Prediction Abstract: This work provides simple algorithms for multi-class (and multi-label)\nprediction in settings where both the number of examples n and the data\ndimension d are relatively large. These robust and parameter free algorithms\nare essentially iterative least-squares updates and very versatile both in\ntheory and in practice. On the theoretical front, we present several variants\nwith convergence guarantees. Owing to their effective use of second-order\nstructure, these algorithms are substantially better than first-order methods\nin many practical scenarios. On the empirical side, we present a scalable\nstagewise variant of our approach, which achieves dramatic computational\nspeedups over popular optimization packages such as Liblinear and Vowpal Wabbit\non standard datasets (MNIST and CIFAR-10), while attaining state-of-the-art\naccuracies. \n\n"}
{"id": "1311.2547", "contents": "Title: Learning Mixtures of Linear Classifiers Abstract: We consider a discriminative learning (regression) problem, whereby the\nregression function is a convex combination of k linear classifiers. Existing\napproaches are based on the EM algorithm, or similar techniques, without\nprovable guarantees. We develop a simple method based on spectral techniques\nand a `mirroring' trick, that discovers the subspace spanned by the\nclassifiers' parameter vectors. Under a probabilistic assumption on the feature\nvector distribution, we prove that this approach has nearly optimal statistical\nefficiency. \n\n"}
{"id": "1311.4803", "contents": "Title: Beating the Minimax Rate of Active Learning with Prior Knowledge Abstract: Active learning refers to the learning protocol where the learner is allowed\nto choose a subset of instances for labeling. Previous studies have shown that,\ncompared with passive learning, active learning is able to reduce the label\ncomplexity exponentially if the data are linearly separable or satisfy the\nTsybakov noise condition with parameter $\\kappa=1$. In this paper, we propose a\nnovel active learning algorithm using a convex surrogate loss, with the goal to\nbroaden the cases for which active learning achieves an exponential\nimprovement. We make use of a convex loss not only because it reduces the\ncomputational cost, but more importantly because it leads to a tight bound for\nthe empirical process (i.e., the difference between the empirical estimation\nand the expectation) when the current solution is close to the optimal one.\nUnder the assumption that the norm of the optimal classifier that minimizes the\nconvex risk is available, our analysis shows that the introduction of the\nconvex surrogate loss yields an exponential reduction in the label complexity\neven when the parameter $\\kappa$ of the Tsybakov noise is larger than $1$. To\nthe best of our knowledge, this is the first work that improves the minimax\nrate of active learning by utilizing certain priori knowledge. \n\n"}
{"id": "1311.5022", "contents": "Title: Extended Formulations for Online Linear Bandit Optimization Abstract: On-line linear optimization on combinatorial action sets (d-dimensional\nactions) with bandit feedback, is known to have complexity in the order of the\ndimension of the problem. The exponential weighted strategy achieves the best\nknown regret bound that is of the order of $d^{2}\\sqrt{n}$ (where $d$ is the\ndimension of the problem, $n$ is the time horizon). However, such strategies\nare provably suboptimal or computationally inefficient. The complexity is\nattributed to the combinatorial structure of the action set and the dearth of\nefficient exploration strategies of the set. Mirror descent with entropic\nregularization function comes close to solving this problem by enforcing a\nmeticulous projection of weights with an inherent boundary condition. Entropic\nregularization in mirror descent is the only known way of achieving a\nlogarithmic dependence on the dimension. Here, we argue otherwise and recover\nthe original intuition of exponential weighting by borrowing a technique from\ndiscrete optimization and approximation algorithms called `extended\nformulation'. Such formulations appeal to the underlying geometry of the set\nwith a guaranteed logarithmic dependence on the dimension underpinned by an\ninformation theoretic entropic analysis. \n\n"}
{"id": "1311.7539", "contents": "Title: A Hamiltonian Monte Carlo method for Bayesian Inference of Supermassive\n  Black Hole Binaries Abstract: We investigate the use of a Hamiltonian Monte Carlo to map out the posterior\ndensity function for supermassive black hole binaries. While previous Markov\nChain Monte Carlo (MCMC) methods, such as Metropolis-Hastings MCMC, have been\nsuccessfully employed for a number of different gravitational wave sources,\nthese methods are essentially random walk algorithms. The Hamiltonian Monte\nCarlo treats the inverse likelihood surface as a \"gravitational potential\" and\nby introducing canonical positions and momenta, dynamically evolves the Markov\nchain by solving Hamilton's equations of motion. We present an implementation\nof the Hamiltonian Markov Chain that is faster, and more efficient by a factor\nof approximately the dimension of the parameter space, than the standard MCMC. \n\n"}
{"id": "1312.1289", "contents": "Title: On incorporating post-Newtonian effects in N-body dynamics Abstract: The increasing role of general relativity in the dynamics of stellar systems\nwith central massive black holes and in the evolution of hierarchical triple\nsystems inspires a close examination of how post-Newtonian effects are\nincorporated into N-body dynamics. The majority of approaches incorporate\nrelativity by adding to the Newtonian N-body equations the standard two-body\npost-Newtonian terms for a given star around the black hole or for the close\nbinary in a triple system. We argue that, for calculating the evolution of such\nsystems over timescales comparable to the relativistic pericenter advance\ntimescale, it is essential to include \"cross terms\" in the equations of motion.\nThese are post-Newtonian terms that represent a coupling between the potential\nof the central black hole and the potential due to other stars in the system.\nFor hierarchical triple systems, these are couplings between the potential of\nthe inner binary and that of the distant third body. Over pericenter precession\ntimescales, the effects of such terms can actually be \"boosted\" to amplitudes\nof Newtonian order. We write down the post-Newtonian N-body equations of motion\nincluding a central black hole in a truncated form that includes all the\nrelevant cross terms, in a format ready to use for numerical implementation. We\ndo the same for hierarchical triple systems, and illustrate explicitly the\neffects of cross terms on the orbit-averaged equations of evolution for the\norbit elements of the inner binary for the special case where the third body is\non a circular orbit. We also describe the inspiration for this investigation:\nthe motion of a test body about a central body with a Newtonian quadrupole\nmoment, including the relativistic pericenter advance, whose correct solution\nfor the conserved total Newtonian energy requires including PN cross terms\nbetween the mass monopole and quadrupole potentials. \n\n"}
{"id": "1312.3429", "contents": "Title: Unsupervised learning of depth and motion Abstract: We present a model for the joint estimation of disparity and motion. The\nmodel is based on learning about the interrelations between images from\nmultiple cameras, multiple frames in a video, or the combination of both. We\nshow that learning depth and motion cues, as well as their combinations, from\ndata is possible within a single type of architecture and a single type of\nlearning algorithm, by using biologically inspired \"complex cell\" like units,\nwhich encode correlations between the pixels across image pairs. Our\nexperimental results show that the learning of depth and motion makes it\npossible to achieve state-of-the-art performance in 3-D activity analysis, and\nto outperform existing hand-engineered 3-D motion features by a very large\nmargin. \n\n"}
{"id": "1312.5697", "contents": "Title: Using Web Co-occurrence Statistics for Improving Image Categorization Abstract: Object recognition and localization are important tasks in computer vision.\nThe focus of this work is the incorporation of contextual information in order\nto improve object recognition and localization. For instance, it is natural to\nexpect not to see an elephant to appear in the middle of an ocean. We consider\na simple approach to encapsulate such common sense knowledge using\nco-occurrence statistics from web documents. By merely counting the number of\ntimes nouns (such as elephants, sharks, oceans, etc.) co-occur in web\ndocuments, we obtain a good estimate of expected co-occurrences in visual data.\nWe then cast the problem of combining textual co-occurrence statistics with the\npredictions of image-based classifiers as an optimization problem. The\nresulting optimization problem serves as a surrogate for our inference\nprocedure. Albeit the simplicity of the resulting optimization problem, it is\neffective in improving both recognition and localization accuracy. Concretely,\nwe observe significant improvements in recognition and localization rates for\nboth ImageNet Detection 2012 and Sun 2012 datasets. \n\n"}
{"id": "1312.5847", "contents": "Title: Deep learning for neuroimaging: a validation study Abstract: Deep learning methods have recently made notable advances in the tasks of\nclassification and representation learning. These tasks are important for brain\nimaging and neuroscience discovery, making the methods attractive for porting\nto a neuroimager's toolbox. Success of these methods is, in part, explained by\nthe flexibility of deep learning models. However, this flexibility makes the\nprocess of porting to new areas a difficult parameter optimization problem. In\nthis work we demonstrate our results (and feasible parameter ranges) in\napplication of deep learning methods to structural and functional brain imaging\ndata. We also describe a novel constraint-based approach to visualizing high\ndimensional data. We use it to analyze the effect of parameter choices on data\ntransformations. Our results show that deep learning methods are able to learn\nphysiologically important representations and detect latent relations in\nneuroimaging data. \n\n"}
{"id": "1312.6229", "contents": "Title: OverFeat: Integrated Recognition, Localization and Detection using\n  Convolutional Networks Abstract: We present an integrated framework for using Convolutional Networks for\nclassification, localization and detection. We show how a multiscale and\nsliding window approach can be efficiently implemented within a ConvNet. We\nalso introduce a novel deep learning approach to localization by learning to\npredict object boundaries. Bounding boxes are then accumulated rather than\nsuppressed in order to increase detection confidence. We show that different\ntasks can be learned simultaneously using a single shared network. This\nintegrated framework is the winner of the localization task of the ImageNet\nLarge Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very\ncompetitive results for the detection and classifications tasks. In\npost-competition work, we establish a new state of the art for the detection\ntask. Finally, we release a feature extractor from our best model called\nOverFeat. \n\n"}
{"id": "1312.6885", "contents": "Title: Deep learning for class-generic object detection Abstract: We investigate the use of deep neural networks for the novel task of class\ngeneric object detection. We show that neural networks originally designed for\nimage recognition can be trained to detect objects within images, regardless of\ntheir class, including objects for which no bounding box labels have been\nprovided. In addition, we show that bounding box labels yield a 1% performance\nincrease on the ImageNet recognition challenge. \n\n"}
{"id": "1312.7853", "contents": "Title: Communication Efficient Distributed Optimization using an Approximate\n  Newton-type Method Abstract: We present a novel Newton-type method for distributed optimization, which is\nparticularly well suited for stochastic optimization and learning problems. For\nquadratic objectives, the method enjoys a linear rate of convergence which\nprovably \\emph{improves} with the data size, requiring an essentially constant\nnumber of iterations under reasonable assumptions. We provide theoretical and\nempirical evidence of the advantages of our method compared to other\napproaches, such as one-shot parameter averaging and ADMM. \n\n"}
{"id": "1401.0514", "contents": "Title: Structured Generative Models of Natural Source Code Abstract: We study the problem of building generative models of natural source code\n(NSC); that is, source code written and understood by humans. Our primary\ncontribution is to describe a family of generative models for NSC that have\nthree key properties: First, they incorporate both sequential and hierarchical\nstructure. Second, we learn a distributed representation of source code\nelements. Finally, they integrate closely with a compiler, which allows\nleveraging compiler logic and abstractions when building structure into the\nmodel. We also develop an extension that includes more complex structure,\nrefining how the model generates identifier tokens based on what variables are\ncurrently in scope. Our models can be learned efficiently, and we show\nempirically that including appropriate structure greatly improves the models,\nmeasured by the probability of generating test programs. \n\n"}
{"id": "1402.0265", "contents": "Title: Existence of Magnetic Compressible Fluid Stars Abstract: The existence of magnetic star solutions which are axi-symmetric stationary\nsolutions for the Euler-Poisson system of compressible fluids coupled to a\nmagnetic field is proved in this paper by a variational method. Our method of\nproof consists of deriving an elliptic equation for the magnetic potential in\ncylindrical coordinates in $\\mathbb{R}^3$, and obtaining the estimates of the\nGreen's function for this elliptic equation by transforming it to 5-Laplacian. \n\n"}
{"id": "1402.0555", "contents": "Title: Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits Abstract: We present a new algorithm for the contextual bandit learning problem, where\nthe learner repeatedly takes one of $K$ actions in response to the observed\ncontext, and observes the reward only for that chosen action. Our method\nassumes access to an oracle for solving fully supervised cost-sensitive\nclassification problems and achieves the statistically optimal regret guarantee\nwith only $\\tilde{O}(\\sqrt{KT/\\log N})$ oracle calls across all $T$ rounds,\nwhere $N$ is the number of policies in the policy class we compete against. By\ndoing so, we obtain the most practical contextual bandit learning algorithm\namongst approaches that work for general policy classes. We further conduct a\nproof-of-concept experiment which demonstrates the excellent computational and\nprediction performance of (an online variant of) our algorithm relative to\nseveral baselines. \n\n"}
{"id": "1402.1958", "contents": "Title: Better Optimism By Bayes: Adaptive Planning with Rich Models Abstract: The computational costs of inference and planning have confined Bayesian\nmodel-based reinforcement learning to one of two dismal fates: powerful\nBayes-adaptive planning but only for simplistic models, or powerful, Bayesian\nnon-parametric models but using simple, myopic planning strategies such as\nThompson sampling. We ask whether it is feasible and truly beneficial to\ncombine rich probabilistic models with a closer approximation to fully Bayesian\nplanning. First, we use a collection of counterexamples to show formal problems\nwith the over-optimism inherent in Thompson sampling. Then we leverage\nstate-of-the-art techniques in efficient Bayes-adaptive planning and\nnon-parametric Bayesian methods to perform qualitatively better than both\nexisting conventional algorithms and Thompson sampling on two contextual\nbandit-like problems. \n\n"}
{"id": "1402.2333", "contents": "Title: Modeling sequential data using higher-order relational features and\n  predictive training Abstract: Bi-linear feature learning models, like the gated autoencoder, were proposed\nas a way to model relationships between frames in a video. By minimizing\nreconstruction error of one frame, given the previous frame, these models learn\n\"mapping units\" that encode the transformations inherent in a sequence, and\nthereby learn to encode motion. In this work we extend bi-linear models by\nintroducing \"higher-order mapping units\" that allow us to encode\ntransformations between frames and transformations between transformations.\n  We show that this makes it possible to encode temporal structure that is more\ncomplex and longer-range than the structure captured within standard bi-linear\nmodels. We also show that a natural way to train the model is by replacing the\ncommonly used reconstruction objective with a prediction objective which forces\nthe model to correctly predict the evolution of the input multiple steps into\nthe future. Learning can be achieved by back-propagating the multi-step\nprediction through time. We test the model on various temporal prediction\ntasks, and show that higher-order mappings and predictive training both yield a\nsignificant improvement over bi-linear models in terms of prediction accuracy. \n\n"}
{"id": "1402.2594", "contents": "Title: Online Nonparametric Regression Abstract: We establish optimal rates for online regression for arbitrary classes of\nregression functions in terms of the sequential entropy introduced in (Rakhlin,\nSridharan, Tewari, 2010). The optimal rates are shown to exhibit a phase\ntransition analogous to the i.i.d./statistical learning case, studied in\n(Rakhlin, Sridharan, Tsybakov 2013). In the frequently encountered situation\nwhen sequential entropy and i.i.d. empirical entropy match, our results point\nto the interesting phenomenon that the rates for statistical learning with\nsquared loss and online nonparametric regression are the same.\n  In addition to a non-algorithmic study of minimax regret, we exhibit a\ngeneric forecaster that enjoys the established optimal rates. We also provide a\nrecipe for designing online regression algorithms that can be computationally\nefficient. We illustrate the techniques by deriving existing and new\nforecasters for the case of finite experts and for online linear regression. \n\n"}
{"id": "1402.4102", "contents": "Title: Stochastic Gradient Hamiltonian Monte Carlo Abstract: Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for\ndefining distant proposals with high acceptance probabilities in a\nMetropolis-Hastings framework, enabling more efficient exploration of the state\nspace than standard random-walk proposals. The popularity of such methods has\ngrown significantly in recent years. However, a limitation of HMC methods is\nthe required gradient computation for simulation of the Hamiltonian dynamical\nsystem-such computation is infeasible in problems involving a large sample size\nor streaming data. Instead, we must rely on a noisy gradient estimate computed\nfrom a subset of the data. In this paper, we explore the properties of such a\nstochastic gradient HMC approach. Surprisingly, the natural implementation of\nthe stochastic approximation can be arbitrarily bad. To address this problem we\nintroduce a variant that uses second-order Langevin dynamics with a friction\nterm that counteracts the effects of the noisy gradient, maintaining the\ndesired target distribution as the invariant distribution. Results on simulated\ndata validate our theory. We also provide an application of our methods to a\nclassification task using neural networks and to online Bayesian matrix\nfactorization. \n\n"}
{"id": "1402.4354", "contents": "Title: Hybrid SRL with Optimization Modulo Theories Abstract: Generally speaking, the goal of constructive learning could be seen as, given\nan example set of structured objects, to generate novel objects with similar\nproperties. From a statistical-relational learning (SRL) viewpoint, the task\ncan be interpreted as a constraint satisfaction problem, i.e. the generated\nobjects must obey a set of soft constraints, whose weights are estimated from\nthe data. Traditional SRL approaches rely on (finite) First-Order Logic (FOL)\nas a description language, and on MAX-SAT solvers to perform inference. Alas,\nFOL is unsuited for con- structive problems where the objects contain a mixture\nof Boolean and numerical variables. It is in fact difficult to implement, e.g.\nlinear arithmetic constraints within the language of FOL. In this paper we\npropose a novel class of hybrid SRL methods that rely on Satisfiability Modulo\nTheories, an alternative class of for- mal languages that allow to describe,\nand reason over, mixed Boolean-numerical objects and constraints. The resulting\nmethods, which we call Learning Mod- ulo Theories, are formulated within the\nstructured output SVM framework, and employ a weighted SMT solver as an\noptimization oracle to perform efficient in- ference and discriminative max\nmargin weight learning. We also present a few examples of constructive learning\napplications enabled by our method. \n\n"}
{"id": "1402.6779", "contents": "Title: Resourceful Contextual Bandits Abstract: We study contextual bandits with ancillary constraints on resources, which\nare common in real-world applications such as choosing ads or dynamic pricing\nof items. We design the first algorithm for solving these problems that handles\nconstrained resources other than time, and improves over a trivial reduction to\nthe non-contextual case. We consider very general settings for both contextual\nbandits (arbitrary policy sets, e.g. Dudik et al. (UAI'11)) and bandits with\nresource constraints (bandits with knapsacks, Badanidiyuru et al. (FOCS'13)),\nand prove a regret guarantee with near-optimal statistical properties. \n\n"}
{"id": "1403.3269", "contents": "Title: The Minimal Volkov - Akulov - Starobinsky Supergravity Abstract: We construct a supergravity model whose scalar degrees of freedom arise from\na chiral superfield and are solely a scalaron and an axion that is very heavy\nduring the inflationary phase. The model includes a second chiral superfield\n$X$, which is subject however to the constraint $X^2=0$ so that it describes\nonly a Volkov - Akulov goldstino and an auxiliary field. We also construct the\ndual higher - derivative model, which rests on a chiral scalar curvature\nsuperfield ${\\cal R}$ subject to the constraint ${\\cal R}^2=0$, where the\ngoldstino dual arises from the gauge - invariant gravitino field strength as\n$\\gamma^{mn} {\\cal D}_m \\psi_n$. The final bosonic action is an $R+R^2$ theory\ninvolving an axial vector $A_m$ that only propagates a physical pseudoscalar\nmode. \n\n"}
{"id": "1403.6396", "contents": "Title: Viability of the matter bounce scenario in Loop Quantum Cosmology from\n  BICEP2 last data Abstract: The CMB map provided by the Planck project constrains the value of the ratio\nof tensor-to-scalar perturbations, namely $r$, to be smaller than $0.11$ (95%\nCL). This bound rules out the simplest models of inflation. However, recent\ndata from BICEP2 is in strong tension with this constrain, as it finds a value\n$r=0.20^{+0.07}_{-0.05}$ with $r=0$ disfavored at $7.0 \\sigma$, which allows\nthese simplest inflationary models to survive. The remarkable fact is that,\neven though the BICEP2 experiment was conceived to search for evidence of\ninflation, its experimental data matches correctly theoretical results coming\nfrom the matter bounce scenario (the alternative model to the inflationary\nparadigm). More precisely, most bouncing cosmologies do not pass Planck's\nconstrains due to the smallness of the value of the tensor/scalar ratio $r\\leq\n0.11$, but with new BICEP2 data some of them fit well with experimental data.\nThis is the case with the matter bounce scenario in the teleparallel version of\nLoop Quantum Cosmology. \n\n"}
{"id": "1404.1282", "contents": "Title: Hierarchical Dirichlet Scaling Process Abstract: We present the \\textit{hierarchical Dirichlet scaling process} (HDSP), a\nBayesian nonparametric mixed membership model. The HDSP generalizes the\nhierarchical Dirichlet process (HDP) to model the correlation structure between\nmetadata in the corpus and mixture components. We construct the HDSP based on\nthe normalized gamma representation of the Dirichlet process, and this\nconstruction allows incorporating a scaling function that controls the\nmembership probabilities of the mixture components. We develop two scaling\nmethods to demonstrate that different modeling assumptions can be expressed in\nthe HDSP. We also derive the corresponding approximate posterior inference\nalgorithms using variational Bayes. Through experiments on datasets of\nnewswire, medical journal articles, conference proceedings, and product\nreviews, we show that the HDSP results in a better predictive performance than\nlabeled LDA, partially labeled LDA, and author topic model and a better\nnegative review classification performance than the supervised topic model and\nSVM. \n\n"}
{"id": "1404.1504", "contents": "Title: A Compression Technique for Analyzing Disagreement-Based Active Learning Abstract: We introduce a new and improved characterization of the label complexity of\ndisagreement-based active learning, in which the leading quantity is the\nversion space compression set size. This quantity is defined as the size of the\nsmallest subset of the training data that induces the same version space. We\nshow various applications of the new characterization, including a tight\nanalysis of CAL and refined label complexity bounds for linear separators under\nmixtures of Gaussians and axis-aligned rectangles under product densities. The\nversion space compression set size, as well as the new characterization of the\nlabel complexity, can be naturally extended to agnostic learning problems, for\nwhich we show new speedup results for two well known active learning\nalgorithms. \n\n"}
{"id": "1405.0349", "contents": "Title: Probing the primordial Universe from the low-multipole CMB data Abstract: Since the temperature fluctuations in cosmic microwave background (CMB) on\nlarge-angular scales probe length scales that were super-horizon sized at\nphoton decoupling and hence insensitive to microphysical processes, the\nlow-multipole CMB data are supposed to be a good probe to the physics of the\nprimordial Universe. In this letter we will constrain the cosmological\nparameters in the base $\\Lambda$CDM model with tensor perturbations by only\nusing low-multipole CMB data, including Background Imaging of Cosmic\nExtragalactic Polarization (B2), Planck released in 2013 (P13) and Wilkinson\nMicrowaves Anisotropy Probe 9-year data (W9). We find that a red tilted power\nspectrum of relic gravitational waves is compatible with the data, but a blue\ntilted power spectrum of scalar perturbations on the large scales is preferred\nat around $2\\sigma$ confidence level. \n\n"}
{"id": "1405.2798", "contents": "Title: Two-Stage Metric Learning Abstract: In this paper, we present a novel two-stage metric learning algorithm. We\nfirst map each learning instance to a probability distribution by computing its\nsimilarities to a set of fixed anchor points. Then, we define the distance in\nthe input data space as the Fisher information distance on the associated\nstatistical manifold. This induces in the input data space a new family of\ndistance metric with unique properties. Unlike kernelized metric learning, we\ndo not require the similarity measure to be positive semi-definite. Moreover,\nit can also be interpreted as a local metric learning algorithm with well\ndefined distance approximation. We evaluate its performance on a number of\ndatasets. It outperforms significantly other metric learning methods and SVM. \n\n"}
{"id": "1405.4053", "contents": "Title: Distributed Representations of Sentences and Documents Abstract: Many machine learning algorithms require the input to be represented as a\nfixed-length feature vector. When it comes to texts, one of the most common\nfixed-length features is bag-of-words. Despite their popularity, bag-of-words\nfeatures have two major weaknesses: they lose the ordering of the words and\nthey also ignore semantics of the words. For example, \"powerful,\" \"strong\" and\n\"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an\nunsupervised algorithm that learns fixed-length feature representations from\nvariable-length pieces of texts, such as sentences, paragraphs, and documents.\nOur algorithm represents each document by a dense vector which is trained to\npredict words in the document. Its construction gives our algorithm the\npotential to overcome the weaknesses of bag-of-words models. Empirical results\nshow that Paragraph Vectors outperform bag-of-words models as well as other\ntechniques for text representations. Finally, we achieve new state-of-the-art\nresults on several text classification and sentiment analysis tasks. \n\n"}
{"id": "1406.0156", "contents": "Title: $l_1$-regularized Outlier Isolation and Regression Abstract: This paper proposed a new regression model called $l_1$-regularized outlier\nisolation and regression (LOIRE) and a fast algorithm based on block coordinate\ndescent to solve this model. Besides, assuming outliers are gross errors\nfollowing a Bernoulli process, this paper also presented a Bernoulli estimate\nmodel which, in theory, should be very accurate and robust due to its complete\nelimination of affections caused by outliers. Though this Bernoulli estimate is\nhard to solve, it could be approximately achieved through a process which takes\nLOIRE as an important intermediate step. As a result, the approximate Bernoulli\nestimate is a good combination of Bernoulli estimate's accuracy and LOIRE\nregression's efficiency with several simulations conducted to strongly verify\nthis point. Moreover, LOIRE can be further extended to realize robust rank\nfactorization which is powerful in recovering low-rank component from massive\ncorruptions. Extensive experimental results showed that the proposed method\noutperforms state-of-the-art methods like RPCA and GoDec in the aspect of\ncomputation speed with a competitive performance. \n\n"}
{"id": "1406.6475", "contents": "Title: Thermodynamic phase transition in the rainbow Schwarzschild black hole Abstract: We study the thermodynamic phase transition in the rainbow Schwarzschild\nblack hole where the metric depends on the energy of the test particle.\nIdentifying the black hole temperature with the energy from the modified\ndispersion relation, we obtain the modified entropy and thermodynamic energy\nalong with the modified local temperature in the cavity to provide well defined\nblack hole states. It is found that apart from the conventional critical\ntemperature related to Hawking-Page phase transition there appears an\nadditional critical temperature which is of relevance to the existence of a\nlocally stable tiny black hole; however, the off-shell free energy tells us\nthat this black hole should eventually tunnel into the stable large black hole.\nFinally, we discuss the reason why the temperature near the horizon is finite\nin the rainbow black hole by employing the running gravitational coupling\nconstant, whereas it is divergent near the horizon in the ordinary\nSchwarzschild black hole. \n\n"}
{"id": "1406.7758", "contents": "Title: Theoretical Analysis of Bayesian Optimisation with Unknown Gaussian\n  Process Hyper-Parameters Abstract: Bayesian optimisation has gained great popularity as a tool for optimising\nthe parameters of machine learning algorithms and models. Somewhat ironically,\nsetting up the hyper-parameters of Bayesian optimisation methods is notoriously\nhard. While reasonable practical solutions have been advanced, they can often\nfail to find the best optima. Surprisingly, there is little theoretical\nanalysis of this crucial problem in the literature. To address this, we derive\na cumulative regret bound for Bayesian optimisation with Gaussian processes and\nunknown kernel hyper-parameters in the stochastic setting. The bound, which\napplies to the expected improvement acquisition function and sub-Gaussian\nobservation noise, provides us with guidelines on how to design hyper-parameter\nestimation methods. A simple simulation demonstrates the importance of\nfollowing these guidelines. \n\n"}
{"id": "1407.0749", "contents": "Title: Projecting Ising Model Parameters for Fast Mixing Abstract: Inference in general Ising models is difficult, due to high treewidth making\ntree-based algorithms intractable. Moreover, when interactions are strong,\nGibbs sampling may take exponential time to converge to the stationary\ndistribution. We present an algorithm to project Ising model parameters onto a\nparameter set that is guaranteed to be fast mixing, under several divergences.\nWe find that Gibbs sampling using the projected parameters is more accurate\nthan with the original parameters when interaction strengths are strong and\nwhen limited time is available for sampling. \n\n"}
{"id": "1407.0951", "contents": "Title: Accelerated expansion in the effective field theory of a radiation\n  dominated universe Abstract: We construct the effective field theory of a perfect fluid in the early\nuniverse. Focusing on the case where the fluid has the equation of state of\nradiation, we show that it may lead to corrections to the background dynamics\nthat can dominate over those of an effective field theory of gravity alone. We\ndescribe the periods of accelerated expansion, in the form of inflationary and\nbounce solutions, that arise in the background dynamics and discuss their\nregime of validity within EFT. \n\n"}
{"id": "1407.1640", "contents": "Title: WordRep: A Benchmark for Research on Learning Word Representations Abstract: WordRep is a benchmark collection for the research on learning distributed\nword representations (or word embeddings), released by Microsoft Research. In\nthis paper, we describe the details of the WordRep collection and show how to\nuse it in different types of machine learning research related to word\nembedding. Specifically, we describe how the evaluation tasks in WordRep are\nselected, how the data are sampled, and how the evaluation tool is built. We\nthen compare several state-of-the-art word representations on WordRep, report\ntheir evaluation performance, and make discussions on the results. After that,\nwe discuss new potential research topics that can be supported by WordRep, in\naddition to algorithm comparison. We hope that this paper can help people gain\ndeeper understanding of WordRep, and enable more interesting research on\nlearning distributed word representations and related topics. \n\n"}
{"id": "1407.2657", "contents": "Title: Beyond Disagreement-based Agnostic Active Learning Abstract: We study agnostic active learning, where the goal is to learn a classifier in\na pre-specified hypothesis class interactively with as few label queries as\npossible, while making no assumptions on the true function generating the\nlabels. The main algorithms for this problem are {\\em{disagreement-based active\nlearning}}, which has a high label requirement, and {\\em{margin-based active\nlearning}}, which only applies to fairly restricted settings. A major challenge\nis to find an algorithm which achieves better label complexity, is consistent\nin an agnostic setting, and applies to general classification problems.\n  In this paper, we provide such an algorithm. Our solution is based on two\nnovel contributions -- a reduction from consistent active learning to\nconfidence-rated prediction with guaranteed error, and a novel confidence-rated\npredictor. \n\n"}
{"id": "1409.1556", "contents": "Title: Very Deep Convolutional Networks for Large-Scale Image Recognition Abstract: In this work we investigate the effect of the convolutional network depth on\nits accuracy in the large-scale image recognition setting. Our main\ncontribution is a thorough evaluation of networks of increasing depth using an\narchitecture with very small (3x3) convolution filters, which shows that a\nsignificant improvement on the prior-art configurations can be achieved by\npushing the depth to 16-19 weight layers. These findings were the basis of our\nImageNet Challenge 2014 submission, where our team secured the first and the\nsecond places in the localisation and classification tracks respectively. We\nalso show that our representations generalise well to other datasets, where\nthey achieve state-of-the-art results. We have made our two best-performing\nConvNet models publicly available to facilitate further research on the use of\ndeep visual representations in computer vision. \n\n"}
{"id": "1409.2620", "contents": "Title: Learning Machines Implemented on Non-Deterministic Hardware Abstract: This paper highlights new opportunities for designing large-scale machine\nlearning systems as a consequence of blurring traditional boundaries that have\nallowed algorithm designers and application-level practitioners to stay -- for\nthe most part -- oblivious to the details of the underlying hardware-level\nimplementations. The hardware/software co-design methodology advocated here\nhinges on the deployment of compute-intensive machine learning kernels onto\ncompute platforms that trade-off determinism in the computation for improvement\nin speed and/or energy efficiency. To achieve this, we revisit digital\nstochastic circuits for approximating matrix computations that are ubiquitous\nin machine learning algorithms. Theoretical and empirical evaluation is\nundertaken to assess the impact of the hardware-induced computational noise on\nalgorithm performance. As a proof-of-concept, a stochastic hardware simulator\nis employed for training deep neural networks for image recognition problems. \n\n"}
{"id": "1409.3768", "contents": "Title: Optimization Methods for Sparse Pseudo-Likelihood Graphical Model\n  Selection Abstract: Sparse high dimensional graphical model selection is a popular topic in\ncontemporary machine learning. To this end, various useful approaches have been\nproposed in the context of $\\ell_1$-penalized estimation in the Gaussian\nframework. Though many of these inverse covariance estimation approaches are\ndemonstrably scalable and have leveraged recent advances in convex\noptimization, they still depend on the Gaussian functional form. To address\nthis gap, a convex pseudo-likelihood based partial correlation graph estimation\nmethod (CONCORD) has been recently proposed. This method uses coordinate-wise\nminimization of a regression based pseudo-likelihood, and has been shown to\nhave robust model selection properties in comparison with the Gaussian\napproach. In direct contrast to the parallel work in the Gaussian setting\nhowever, this new convex pseudo-likelihood framework has not leveraged the\nextensive array of methods that have been proposed in the machine learning\nliterature for convex optimization. In this paper, we address this crucial gap\nby proposing two proximal gradient methods (CONCORD-ISTA and CONCORD-FISTA) for\nperforming $\\ell_1$-regularized inverse covariance matrix estimation in the\npseudo-likelihood framework. We present timing comparisons with coordinate-wise\nminimization and demonstrate that our approach yields tremendous payoffs for\n$\\ell_1$-penalized partial correlation graph estimation outside the Gaussian\nsetting, thus yielding the fastest and most scalable approach for such\nproblems. We undertake a theoretical analysis of our approach and rigorously\ndemonstrate convergence, and also derive rates thereof. \n\n"}
{"id": "1409.8327", "contents": "Title: Bayesian and regularization approaches to multivariable linear system\n  identification: the role of rank penalties Abstract: Recent developments in linear system identification have proposed the use of\nnon-parameteric methods, relying on regularization strategies, to handle the\nso-called bias/variance trade-off. This paper introduces an impulse response\nestimator which relies on an $\\ell_2$-type regularization including a\nrank-penalty derived using the log-det heuristic as a smooth approximation to\nthe rank function. This allows to account for different properties of the\nestimated impulse response (e.g. smoothness and stability) while also\npenalizing high-complexity models. This also allows to account and enforce\ncoupling between different input-output channels in MIMO systems. According to\nthe Bayesian paradigm, the parameters defining the relative weight of the two\nregularization terms as well as the structure of the rank penalty are estimated\noptimizing the marginal likelihood. Once these hyperameters have been\nestimated, the impulse response estimate is available in closed form.\nExperiments show that the proposed method is superior to the estimator relying\non the \"classic\" $\\ell_2$-regularization alone as well as those based in atomic\nand nuclear norm. \n\n"}
{"id": "1410.0203", "contents": "Title: Signatures of primordial black hole dark matter Abstract: The nonbaryonic dark matter of the Universe is assumed to consist of new\nstable forms of matter. Their stability reflects symmetry of micro world and\nmechanisms of its symmetry breaking. In the early Universe heavy metastable\nparticles can dominate, leaving primordial black holes (PBHs) after their\ndecay, as well as the structure of particle symmetry breaking gives rise to\ncosmological phase transitions, from which massive black holes and/or their\nclusters can originate. PBHs can be formed in such transitions within a narrow\ninterval of masses about $10^{17}$g and, avoiding severe observational\nconstraints on PBHs, can be a candidate for the dominant form of dark matter.\nPBHs in this range of mass can give solution of the problem of reionization in\nthe Universe at the redshift $z\\sim 5... 10$. Clusters of massive PBHs can\nserve as a nonlinear seeds for galaxy formation, while PBHs evaporating in such\nclusters can provide an interesting interpretation for the observations of\npoint-like gamma-ray sources. Analysis of possible PBH signatures represents a\nuniversal probe for super-high energy physics in the early Universe in studies\nof indirect effects of the dark matter. \n\n"}
{"id": "1410.0736", "contents": "Title: HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale\n  Visual Recognition Abstract: In image classification, visual separability between different object\ncategories is highly uneven, and some categories are more difficult to\ndistinguish than others. Such difficult categories demand more dedicated\nclassifiers. However, existing deep convolutional neural networks (CNN) are\ntrained as flat N-way classifiers, and few efforts have been made to leverage\nthe hierarchical structure of categories. In this paper, we introduce\nhierarchical deep CNNs (HD-CNNs) by embedding deep CNNs into a category\nhierarchy. An HD-CNN separates easy classes using a coarse category classifier\nwhile distinguishing difficult classes using fine category classifiers. During\nHD-CNN training, component-wise pretraining is followed by global finetuning\nwith a multinomial logistic loss regularized by a coarse category consistency\nterm. In addition, conditional executions of fine category classifiers and\nlayer parameter compression make HD-CNNs scalable for large-scale visual\nrecognition. We achieve state-of-the-art results on both CIFAR100 and\nlarge-scale ImageNet 1000-class benchmark datasets. In our experiments, we\nbuild up three different HD-CNNs and they lower the top-1 error of the standard\nCNNs by 2.65%, 3.1% and 1.1%, respectively. \n\n"}
{"id": "1410.1090", "contents": "Title: Explain Images with Multimodal Recurrent Neural Networks Abstract: In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model\nfor generating novel sentence descriptions to explain the content of images. It\ndirectly models the probability distribution of generating a word given\nprevious words and the image. Image descriptions are generated by sampling from\nthis distribution. The model consists of two sub-networks: a deep recurrent\nneural network for sentences and a deep convolutional network for images. These\ntwo sub-networks interact with each other in a multimodal layer to form the\nwhole m-RNN model. The effectiveness of our model is validated on three\nbenchmark datasets (IAPR TC-12, Flickr 8K, and Flickr 30K). Our model\noutperforms the state-of-the-art generative method. In addition, the m-RNN\nmodel can be applied to retrieval tasks for retrieving images or sentences, and\nachieves significant performance improvement over the state-of-the-art methods\nwhich directly optimize the ranking objective function for retrieval. \n\n"}
{"id": "1410.1462", "contents": "Title: Top Rank Optimization in Linear Time Abstract: Bipartite ranking aims to learn a real-valued ranking function that orders\npositive instances before negative instances. Recent efforts of bipartite\nranking are focused on optimizing ranking accuracy at the top of the ranked\nlist. Most existing approaches are either to optimize task specific metrics or\nto extend the ranking loss by emphasizing more on the error associated with the\ntop ranked instances, leading to a high computational cost that is super-linear\nin the number of training instances. We propose a highly efficient approach,\ntitled TopPush, for optimizing accuracy at the top that has computational\ncomplexity linear in the number of training instances. We present a novel\nanalysis that bounds the generalization error for the top ranked instances for\nthe proposed approach. Empirical study shows that the proposed approach is\nhighly competitive to the state-of-the-art approaches and is 10-100 times\nfaster. \n\n"}
{"id": "1410.3916", "contents": "Title: Memory Networks Abstract: We describe a new class of learning models called memory networks. Memory\nnetworks reason with inference components combined with a long-term memory\ncomponent; they learn how to use these jointly. The long-term memory can be\nread and written to, with the goal of using it for prediction. We investigate\nthese models in the context of question answering (QA) where the long-term\nmemory effectively acts as a (dynamic) knowledge base, and the output is a\ntextual response. We evaluate them on a large-scale QA task, and a smaller, but\nmore complex, toy task generated from a simulated world. In the latter, we show\nthe reasoning power of such models by chaining multiple supporting sentences to\nanswer questions that require understanding the intension of verbs. \n\n"}
{"id": "1410.4984", "contents": "Title: Gaussian Process Models with Parallelization and GPU acceleration Abstract: In this work, we present an extension of Gaussian process (GP) models with\nsophisticated parallelization and GPU acceleration. The parallelization scheme\narises naturally from the modular computational structure w.r.t. datapoints in\nthe sparse Gaussian process formulation. Additionally, the computational\nbottleneck is implemented with GPU acceleration for further speed up. Combining\nboth techniques allows applying Gaussian process models to millions of\ndatapoints. The efficiency of our algorithm is demonstrated with a synthetic\ndataset. Its source code has been integrated into our popular software library\nGPy. \n\n"}
{"id": "1410.5785", "contents": "Title: Electromagnetic partner of the gravitational signal during accretion\n  onto black holes Abstract: We investigate the generation of electromagnetic and gravitational radiation\nin the vicinity of a perturbed Schwarzschild black hole. The gravitational\nperturbations and the electromagnetic field are studied by solving the\nTeukolsky master equation with sources, which we take to be locally charged,\nradially infalling, matter. Our results show that, in addition to the\ngravitational wave generated as the matter falls into the black hole, there is\nalso a burst of electromagnetic radiation. This electromagnetic field has a\ncharacteristic set of quasinormal frequencies, and the gravitational radiation\nhas the quasinormal frequencies of a Schwarzschild black hole. This scenario\nallows us to compare the gravitational and electromagnetic signals that are\ngenerated by a common source. \n\n"}
{"id": "1411.0023", "contents": "Title: Validation of Matching Abstract: We introduce a technique to compute probably approximately correct (PAC)\nbounds on precision and recall for matching algorithms. The bounds require some\nverified matches, but those matches may be used to develop the algorithms. The\nbounds can be applied to network reconciliation or entity resolution\nalgorithms, which identify nodes in different networks or values in a data set\nthat correspond to the same entity. For network reconciliation, the bounds do\nnot require knowledge of the network generation process. \n\n"}
{"id": "1411.0591", "contents": "Title: Bayesian feature selection with strongly-regularizing priors maps to the\n  Ising Model Abstract: Identifying small subsets of features that are relevant for prediction and/or\nclassification tasks is a central problem in machine learning and statistics.\nThe feature selection task is especially important, and computationally\ndifficult, for modern datasets where the number of features can be comparable\nto, or even exceed, the number of samples. Here, we show that feature selection\nwith Bayesian inference takes a universal form and reduces to calculating the\nmagnetizations of an Ising model, under some mild conditions. Our results\nexploit the observation that the evidence takes a universal form for\nstrongly-regularizing priors --- priors that have a large effect on the\nposterior probability even in the infinite data limit. We derive explicit\nexpressions for feature selection for generalized linear models, a large class\nof statistical techniques that include linear and logistic regression. We\nillustrate the power of our approach by analyzing feature selection in a\nlogistic regression-based classifier trained to distinguish between the letters\nB and D in the notMNIST dataset. \n\n"}
{"id": "1411.2066", "contents": "Title: Learning Theory for Distribution Regression Abstract: We focus on the distribution regression problem: regressing to vector-valued\noutputs from probability measures. Many important machine learning and\nstatistical tasks fit into this framework, including multi-instance learning\nand point estimation problems without analytical solution (such as\nhyperparameter or entropy estimation). Despite the large number of available\nheuristics in the literature, the inherent two-stage sampled nature of the\nproblem makes the theoretical analysis quite challenging, since in practice\nonly samples from sampled distributions are observable, and the estimates have\nto rely on similarities computed between sets of points. To the best of our\nknowledge, the only existing technique with consistency guarantees for\ndistribution regression requires kernel density estimation as an intermediate\nstep (which often performs poorly in practice), and the domain of the\ndistributions to be compact Euclidean. In this paper, we study a simple,\nanalytically computable, ridge regression-based alternative to distribution\nregression, where we embed the distributions to a reproducing kernel Hilbert\nspace, and learn the regressor from the embeddings to the outputs. Our main\ncontribution is to prove that this scheme is consistent in the two-stage\nsampled setup under mild conditions (on separable topological domains enriched\nwith kernels): we present an exact computational-statistical efficiency\ntrade-off analysis showing that our estimator is able to match the one-stage\nsampled minimax optimal rate [Caponnetto and De Vito, 2007; Steinwart et al.,\n2009]. This result answers a 17-year-old open question, establishing the\nconsistency of the classical set kernel [Haussler, 1999; Gaertner et. al, 2002]\nin regression. We also cover consistency for more recent kernels on\ndistributions, including those due to [Christmann and Steinwart, 2010]. \n\n"}
{"id": "1411.3436", "contents": "Title: SelfieBoost: A Boosting Algorithm for Deep Learning Abstract: We describe and analyze a new boosting algorithm for deep learning called\nSelfieBoost. Unlike other boosting algorithms, like AdaBoost, which construct\nensembles of classifiers, SelfieBoost boosts the accuracy of a single network.\nWe prove a $\\log(1/\\epsilon)$ convergence rate for SelfieBoost under some \"SGD\nsuccess\" assumption which seems to hold in practice. \n\n"}
{"id": "1411.4503", "contents": "Title: Outlier-Robust Convex Segmentation Abstract: We derive a convex optimization problem for the task of segmenting sequential\ndata, which explicitly treats presence of outliers. We describe two algorithms\nfor solving this problem, one exact and one a top-down novel approach, and we\nderive a consistency results for the case of two segments and no outliers.\nRobustness to outliers is evaluated on two real-world tasks related to speech\nsegmentation. Our algorithms outperform baseline segmentation algorithms. \n\n"}
{"id": "1411.5988", "contents": "Title: Clustering evolving data using kernel-based methods Abstract: In this thesis, we propose several modelling strategies to tackle evolving\ndata in different contexts. In the framework of static clustering, we start by\nintroducing a soft kernel spectral clustering (SKSC) algorithm, which can\nbetter deal with overlapping clusters with respect to kernel spectral\nclustering (KSC) and provides more interpretable outcomes. Afterwards, a whole\nstrategy based upon KSC for community detection of static networks is proposed,\nwhere the extraction of a high quality training sub-graph, the choice of the\nkernel function, the model selection and the applicability to large-scale data\nare key aspects. This paves the way for the development of a novel clustering\nalgorithm for the analysis of evolving networks called kernel spectral\nclustering with memory effect (MKSC), where the temporal smoothness between\nclustering results in successive time steps is incorporated at the level of the\nprimal optimization problem, by properly modifying the KSC formulation. Later\non, an application of KSC to fault detection of an industrial machine is\npresented. Here, a smart pre-processing of the data by means of a proper\nwindowing operation is necessary to catch the ongoing degradation process\naffecting the machine. In this way, in a genuinely unsupervised manner, it is\npossible to raise an early warning when necessary, in an online fashion.\nFinally, we propose a new algorithm called incremental kernel spectral\nclustering (IKSC) for online learning of non-stationary data. This ambitious\nchallenge is faced by taking advantage of the out-of-sample property of kernel\nspectral clustering (KSC) to adapt the initial model, in order to tackle\nmerging, splitting or drifting of clusters across time. Real-world applications\nconsidered in this thesis include image segmentation, time-series clustering,\ncommunity detection of static and evolving networks. \n\n"}
{"id": "1411.6699", "contents": "Title: One Vector is Not Enough: Entity-Augmented Distributional Semantics for\n  Discourse Relations Abstract: Discourse relations bind smaller linguistic units into coherent texts.\nHowever, automatically identifying discourse relations is difficult, because it\nrequires understanding the semantics of the linked arguments. A more subtle\nchallenge is that it is not enough to represent the meaning of each argument of\na discourse relation, because the relation may depend on links between\nlower-level components, such as entity mentions. Our solution computes\ndistributional meaning representations by composition up the syntactic parse\ntree. A key difference from previous work on compositional distributional\nsemantics is that we also compute representations for entity mentions, using a\nnovel downward compositional pass. Discourse relations are predicted from the\ndistributional representations of the arguments, and also of their coreferent\nentity mentions. The resulting system obtains substantial improvements over the\nprevious state-of-the-art in predicting implicit discourse relations in the\nPenn Discourse Treebank. \n\n"}
{"id": "1412.4093", "contents": "Title: Generalized gravitational entropy without replica symmetry Abstract: We explore several extensions of the generalized entropy construction of\nLewkowycz and Maldacena, including a formulation that does not rely on\npreserving replica symmetry in the bulk. We show that an appropriately general\nansatz for the analytically continued replica metric gives us the flexibility\nneeded to solve the gravitational field equations beyond general relativity. As\nan application of this observation we study Einstein-Gauss-Bonnet gravity with\na small Gauss-Bonnet coupling and derive the condition that the holographic\nentanglement entropy must be evaluated on a surface which extremizes the\nJacobson-Myers entropy. We find that in both general relativity and\nEinstein-Gauss-Bonnet gravity replica symmetry breaking terms are permitted by\nthe field equations, suggesting that they do not generically vanish. \n\n"}
{"id": "1412.6452", "contents": "Title: Algorithmic Robustness for Learning via $(\\epsilon, \\gamma, \\tau)$-Good\n  Similarity Functions Abstract: The notion of metric plays a key role in machine learning problems such as\nclassification, clustering or ranking. However, it is worth noting that there\nis a severe lack of theoretical guarantees that can be expected on the\ngeneralization capacity of the classifier associated to a given metric. The\ntheoretical framework of $(\\epsilon, \\gamma, \\tau)$-good similarity functions\n(Balcan et al., 2008) has been one of the first attempts to draw a link between\nthe properties of a similarity function and those of a linear classifier making\nuse of it. In this paper, we extend and complete this theory by providing a new\ngeneralization bound for the associated classifier based on the algorithmic\nrobustness framework. \n\n"}
{"id": "1412.6980", "contents": "Title: Adam: A Method for Stochastic Optimization Abstract: We introduce Adam, an algorithm for first-order gradient-based optimization\nof stochastic objective functions, based on adaptive estimates of lower-order\nmoments. The method is straightforward to implement, is computationally\nefficient, has little memory requirements, is invariant to diagonal rescaling\nof the gradients, and is well suited for problems that are large in terms of\ndata and/or parameters. The method is also appropriate for non-stationary\nobjectives and problems with very noisy and/or sparse gradients. The\nhyper-parameters have intuitive interpretations and typically require little\ntuning. Some connections to related algorithms, on which Adam was inspired, are\ndiscussed. We also analyze the theoretical convergence properties of the\nalgorithm and provide a regret bound on the convergence rate that is comparable\nto the best known results under the online convex optimization framework.\nEmpirical results demonstrate that Adam works well in practice and compares\nfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,\na variant of Adam based on the infinity norm. \n\n"}
{"id": "1501.00263", "contents": "Title: Communication-Efficient Distributed Optimization of Self-Concordant\n  Empirical Loss Abstract: We consider distributed convex optimization problems originated from sample\naverage approximation of stochastic optimization, or empirical risk\nminimization in machine learning. We assume that each machine in the\ndistributed computing system has access to a local empirical loss function,\nconstructed with i.i.d. data sampled from a common distribution. We propose a\ncommunication-efficient distributed algorithm to minimize the overall empirical\nloss, which is the average of the local empirical losses. The algorithm is\nbased on an inexact damped Newton method, where the inexact Newton steps are\ncomputed by a distributed preconditioned conjugate gradient method. We analyze\nits iteration complexity and communication efficiency for minimizing\nself-concordant empirical loss functions, and discuss the results for\ndistributed ridge regression, logistic regression and binary classification\nwith a smoothed hinge loss. In a standard setting for supervised learning, the\nrequired number of communication rounds of the algorithm does not increase with\nthe sample size, and only grows slowly with the number of machines. \n\n"}
{"id": "1501.03302", "contents": "Title: Hard to Cheat: A Turing Test based on Answering Questions about Images Abstract: Progress in language and image understanding by machines has sparkled the\ninterest of the research community in more open-ended, holistic tasks, and\nrefueled an old AI dream of building intelligent machines. We discuss a few\nprominent challenges that characterize such holistic tasks and argue for\n\"question answering about images\" as a particular appealing instance of such a\nholistic task. In particular, we point out that it is a version of a Turing\nTest that is likely to be more robust to over-interpretations and contrast it\nwith tasks like grounding and generation of descriptions. Finally, we discuss\ntools to measure progress in this field. \n\n"}
{"id": "1502.01176", "contents": "Title: Learning Local Invariant Mahalanobis Distances Abstract: For many tasks and data types, there are natural transformations to which the\ndata should be invariant or insensitive. For instance, in visual recognition,\nnatural images should be insensitive to rotation and translation. This\nrequirement and its implications have been important in many machine learning\napplications, and tolerance for image transformations was primarily achieved by\nusing robust feature vectors. In this paper we propose a novel and\ncomputationally efficient way to learn a local Mahalanobis metric per datum,\nand show how we can learn a local invariant metric to any transformation in\norder to improve performance. \n\n"}
{"id": "1502.01418", "contents": "Title: RELEAF: An Algorithm for Learning and Exploiting Relevance Abstract: Recommender systems, medical diagnosis, network security, etc., require\non-going learning and decision-making in real time. These -- and many others --\nrepresent perfect examples of the opportunities and difficulties presented by\nBig Data: the available information often arrives from a variety of sources and\nhas diverse features so that learning from all the sources may be valuable but\nintegrating what is learned is subject to the curse of dimensionality. This\npaper develops and analyzes algorithms that allow efficient learning and\ndecision-making while avoiding the curse of dimensionality. We formalize the\ninformation available to the learner/decision-maker at a particular time as a\ncontext vector which the learner should consider when taking actions. In\ngeneral the context vector is very high dimensional, but in many settings, the\nmost relevant information is embedded into only a few relevant dimensions. If\nthese relevant dimensions were known in advance, the problem would be simple --\nbut they are not. Moreover, the relevant dimensions may be different for\ndifferent actions. Our algorithm learns the relevant dimensions for each\naction, and makes decisions based in what it has learned. Formally, we build on\nthe structure of a contextual multi-armed bandit by adding and exploiting a\nrelevance relation. We prove a general regret bound for our algorithm whose\ntime order depends only on the maximum number of relevant dimensions among all\nthe actions, which in the special case where the relevance relation is\nsingle-valued (a function), reduces to $\\tilde{O}(T^{2(\\sqrt{2}-1)})$; in the\nabsence of a relevance relation, the best known contextual bandit algorithms\nachieve regret $\\tilde{O}(T^{(D+1)/(D+2)})$, where $D$ is the full dimension of\nthe context vector. \n\n"}
{"id": "1502.03167", "contents": "Title: Batch Normalization: Accelerating Deep Network Training by Reducing\n  Internal Covariate Shift Abstract: Training Deep Neural Networks is complicated by the fact that the\ndistribution of each layer's inputs changes during training, as the parameters\nof the previous layers change. This slows down the training by requiring lower\nlearning rates and careful parameter initialization, and makes it notoriously\nhard to train models with saturating nonlinearities. We refer to this\nphenomenon as internal covariate shift, and address the problem by normalizing\nlayer inputs. Our method draws its strength from making normalization a part of\nthe model architecture and performing the normalization for each training\nmini-batch. Batch Normalization allows us to use much higher learning rates and\nbe less careful about initialization. It also acts as a regularizer, in some\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\nclassification model, Batch Normalization achieves the same accuracy with 14\ntimes fewer training steps, and beats the original model by a significant\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\nbest published result on ImageNet classification: reaching 4.9% top-5\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters. \n\n"}
{"id": "1502.05890", "contents": "Title: Contextual Semibandits via Supervised Learning Oracles Abstract: We study an online decision making problem where on each round a learner\nchooses a list of items based on some side information, receives a scalar\nfeedback value for each individual item, and a reward that is linearly related\nto this feedback. These problems, known as contextual semibandits, arise in\ncrowdsourcing, recommendation, and many other domains. This paper reduces\ncontextual semibandits to supervised learning, allowing us to leverage powerful\nsupervised learning methods in this partial-feedback setting. Our first\nreduction applies when the mapping from feedback to reward is known and leads\nto a computationally efficient algorithm with near-optimal regret. We show that\nthis algorithm outperforms state-of-the-art approaches on real-world\nlearning-to-rank datasets, demonstrating the advantage of oracle-based\nalgorithms. Our second reduction applies to the previously unstudied setting\nwhen the linear mapping from feedback to reward is unknown. Our regret\nguarantees are superior to prior techniques that ignore the feedback. \n\n"}
{"id": "1502.06132", "contents": "Title: Universal Memory Architectures for Autonomous Machines Abstract: We propose a self-organizing memory architecture for perceptual experience,\ncapable of supporting autonomous learning and goal-directed problem solving in\nthe absence of any prior information about the agent's environment. The\narchitecture is simple enough to ensure (1) a quadratic bound (in the number of\navailable sensors) on space requirements, and (2) a quadratic bound on the\ntime-complexity of the update-execute cycle. At the same time, it is\nsufficiently complex to provide the agent with an internal representation which\nis (3) minimal among all representations of its class which account for every\nsensory equivalence class subject to the agent's belief state; (4) capable, in\nprinciple, of recovering the homotopy type of the system's state space; (5)\nlearnable with arbitrary precision through a random application of the\navailable actions. The provable properties of an effectively trained memory\nstructure exploit a duality between weak poc sets -- a symbolic (discrete)\nrepresentation of subset nesting relations -- and non-positively curved cubical\ncomplexes, whose rich convexity theory underlies the planning cycle of the\nproposed architecture. \n\n"}
{"id": "1503.00693", "contents": "Title: Bayesian Optimization of Text Representations Abstract: When applying machine learning to problems in NLP, there are many choices to\nmake about how to represent input texts. These choices can have a big effect on\nperformance, but they are often uninteresting to researchers or practitioners\nwho simply need a module that performs well. We propose an approach to\noptimizing over this space of choices, formulating the problem as global\noptimization. We apply a sequential model-based optimization technique and show\nthat our method makes standard linear models competitive with more\nsophisticated, expensive state-of-the-art methods based on latent variable\nmodels or neural networks on various topic classification and sentiment\nanalysis problems. Our approach is a first step towards black-box NLP systems\nthat work with raw text and do not require manual tuning. \n\n"}
{"id": "1503.01596", "contents": "Title: Large-Scale Distributed Bayesian Matrix Factorization using Stochastic\n  Gradient MCMC Abstract: Despite having various attractive qualities such as high prediction accuracy\nand the ability to quantify uncertainty and avoid over-fitting, Bayesian Matrix\nFactorization has not been widely adopted because of the prohibitive cost of\ninference. In this paper, we propose a scalable distributed Bayesian matrix\nfactorization algorithm using stochastic gradient MCMC. Our algorithm, based on\nDistributed Stochastic Gradient Langevin Dynamics, can not only match the\nprediction accuracy of standard MCMC methods like Gibbs sampling, but at the\nsame time is as fast and simple as stochastic gradient descent. In our\nexperiments, we show that our algorithm can achieve the same level of\nprediction accuracy as Gibbs sampling an order of magnitude faster. We also\nshow that our method reduces the prediction error as fast as distributed\nstochastic gradient descent, achieving a 4.1% improvement in RMSE for the\nNetflix dataset and an 1.8% for the Yahoo music dataset. \n\n"}
{"id": "1503.01910", "contents": "Title: Sequential Relevance Maximization with Binary Feedback Abstract: Motivated by online settings where users can provide explicit feedback about\nthe relevance of products that are sequentially presented to them, we look at\nthe recommendation process as a problem of dynamically optimizing this\nrelevance feedback. Such an algorithm optimizes the fine tradeoff between\npresenting the products that are most likely to be relevant, and learning the\npreferences of the user so that more relevant recommendations can be made in\nthe future.\n  We assume a standard predictive model inspired by collaborative filtering, in\nwhich a user is sampled from a distribution over a set of possible types. For\nevery product category, each type has an associated relevance feedback that is\nassumed to be binary: the category is either relevant or irrelevant. Assuming\nthat the user stays for each additional recommendation opportunity with\nprobability $\\beta$ independent of the past, the problem is to find a policy\nthat maximizes the expected number of recommendations that are deemed relevant\nin a session.\n  We analyze this problem and prove key structural properties of the optimal\npolicy. Based on these properties, we first present an algorithm that strikes a\nbalance between recursion and dynamic programming to compute this policy. We\nfurther propose and analyze two heuristic policies: a `farsighted' greedy\npolicy that attains at least $1-\\beta$ factor of the optimal payoff, and a\nnaive greedy policy that attains at least $\\frac{1-\\beta}{1+\\beta}$ factor of\nthe optimal payoff in the worst case. Extensive simulations show that these\nheuristics are very close to optimal in practice. \n\n"}
{"id": "1503.02834", "contents": "Title: Doubly Robust Policy Evaluation and Optimization Abstract: We study sequential decision making in environments where rewards are only\npartially observed, but can be modeled as a function of observed contexts and\nthe chosen action by the decision maker. This setting, known as contextual\nbandits, encompasses a wide variety of applications such as health care,\ncontent recommendation and Internet advertising. A central task is evaluation\nof a new policy given historic data consisting of contexts, actions and\nreceived rewards. The key challenge is that the past data typically does not\nfaithfully represent proportions of actions taken by a new policy. Previous\napproaches rely either on models of rewards or models of the past policy. The\nformer are plagued by a large bias whereas the latter have a large variance. In\nthis work, we leverage the strengths and overcome the weaknesses of the two\napproaches by applying the doubly robust estimation technique to the problems\nof policy evaluation and optimization. We prove that this approach yields\naccurate value estimates when we have either a good (but not necessarily\nconsistent) model of rewards or a good (but not necessarily consistent) model\nof past policy. Extensive empirical comparison demonstrates that the doubly\nrobust estimation uniformly improves over existing techniques, achieving both\nlower variance in value estimation and better policies. As such, we expect the\ndoubly robust approach to become common practice in policy evaluation and\noptimization. \n\n"}
{"id": "1503.05479", "contents": "Title: Interpolating Convex and Non-Convex Tensor Decompositions via the\n  Subspace Norm Abstract: We consider the problem of recovering a low-rank tensor from its noisy\nobservation. Previous work has shown a recovery guarantee with signal to noise\nratio $O(n^{\\lceil K/2 \\rceil /2})$ for recovering a $K$th order rank one\ntensor of size $n\\times \\cdots \\times n$ by recursive unfolding. In this paper,\nwe first improve this bound to $O(n^{K/4})$ by a much simpler approach, but\nwith a more careful analysis. Then we propose a new norm called the subspace\nnorm, which is based on the Kronecker products of factors obtained by the\nproposed simple estimator. The imposed Kronecker structure allows us to show a\nnearly ideal $O(\\sqrt{n}+\\sqrt{H^{K-1}})$ bound, in which the parameter $H$\ncontrols the blend from the non-convex estimator to mode-wise nuclear norm\nminimization. Furthermore, we empirically demonstrate that the subspace norm\nachieves the nearly ideal denoising performance even with $H=O(1)$. \n\n"}
{"id": "1503.07211", "contents": "Title: Universal Approximation of Markov Kernels by Shallow Stochastic\n  Feedforward Networks Abstract: We establish upper bounds for the minimal number of hidden units for which a\nbinary stochastic feedforward network with sigmoid activation probabilities and\na single hidden layer is a universal approximator of Markov kernels. We show\nthat each possible probabilistic assignment of the states of $n$ output units,\ngiven the states of $k\\geq1$ input units, can be approximated arbitrarily well\nby a network with $2^{k-1}(2^{n-1}-1)$ hidden units. \n\n"}
{"id": "1503.07240", "contents": "Title: Regularized Minimax Conditional Entropy for Crowdsourcing Abstract: There is a rapidly increasing interest in crowdsourcing for data labeling. By\ncrowdsourcing, a large number of labels can be often quickly gathered at low\ncost. However, the labels provided by the crowdsourcing workers are usually not\nof high quality. In this paper, we propose a minimax conditional entropy\nprinciple to infer ground truth from noisy crowdsourced labels. Under this\nprinciple, we derive a unique probabilistic labeling model jointly\nparameterized by worker ability and item difficulty. We also propose an\nobjective measurement principle, and show that our method is the only method\nwhich satisfies this objective measurement principle. We validate our method\nthrough a variety of real crowdsourcing datasets with binary, multiclass or\nordinal labels. \n\n"}
{"id": "1504.00325", "contents": "Title: Microsoft COCO Captions: Data Collection and Evaluation Server Abstract: In this paper we describe the Microsoft COCO Caption dataset and evaluation\nserver. When completed, the dataset will contain over one and a half million\ncaptions describing over 330,000 images. For the training and validation\nimages, five independent human generated captions will be provided. To ensure\nconsistency in evaluation of automatic caption generation algorithms, an\nevaluation server is used. The evaluation server receives candidate captions\nand scores them using several popular metrics, including BLEU, METEOR, ROUGE\nand CIDEr. Instructions for using the evaluation server are provided. \n\n"}
{"id": "1504.02147", "contents": "Title: Unwrapping ADMM: Efficient Distributed Computing via Transpose Reduction Abstract: Recent approaches to distributed model fitting rely heavily on consensus\nADMM, where each node solves small sub-problems using only local data. We\npropose iterative methods that solve {\\em global} sub-problems over an entire\ndistributed dataset. This is possible using transpose reduction strategies that\nallow a single node to solve least-squares over massive datasets without\nputting all the data in one place. This results in simple iterative methods\nthat avoid the expensive inner loops required for consensus methods. To\ndemonstrate the efficiency of this approach, we fit linear classifiers and\nsparse linear models to datasets over 5 Tb in size using a distributed\nimplementation with over 7000 cores in far less time than previous approaches. \n\n"}
{"id": "1504.04788", "contents": "Title: Compressing Neural Networks with the Hashing Trick Abstract: As deep nets are increasingly used in applications suited for mobile devices,\na fundamental dilemma becomes apparent: the trend in deep learning is to grow\nmodels to absorb ever-increasing data set sizes; however mobile devices are\ndesigned with very little memory and cannot store such large models. We present\na novel network architecture, HashedNets, that exploits inherent redundancy in\nneural networks to achieve drastic reductions in model sizes. HashedNets uses a\nlow-cost hash function to randomly group connection weights into hash buckets,\nand all connections within the same hash bucket share a single parameter value.\nThese parameters are tuned to adjust to the HashedNets weight sharing\narchitecture with standard backprop during training. Our hashing procedure\nintroduces no additional memory overhead, and we demonstrate on several\nbenchmark data sets that HashedNets shrink the storage requirements of neural\nnetworks substantially while mostly preserving generalization performance. \n\n"}
{"id": "1505.00387", "contents": "Title: Highway Networks Abstract: There is plenty of theoretical and empirical evidence that depth of neural\nnetworks is a crucial ingredient for their success. However, network training\nbecomes more difficult with increasing depth and training of very deep networks\nremains an open problem. In this extended abstract, we introduce a new\narchitecture designed to ease gradient-based training of very deep networks. We\nrefer to networks with this architecture as highway networks, since they allow\nunimpeded information flow across several layers on \"information highways\". The\narchitecture is characterized by the use of gating units which learn to\nregulate the flow of information through a network. Highway networks with\nhundreds of layers can be trained directly using stochastic gradient descent\nand with a variety of activation functions, opening up the possibility of\nstudying extremely deep and efficient architectures. \n\n"}
{"id": "1505.00387", "contents": "Title: Highway Networks Abstract: There is plenty of theoretical and empirical evidence that depth of neural\nnetworks is a crucial ingredient for their success. However, network training\nbecomes more difficult with increasing depth and training of very deep networks\nremains an open problem. In this extended abstract, we introduce a new\narchitecture designed to ease gradient-based training of very deep networks. We\nrefer to networks with this architecture as highway networks, since they allow\nunimpeded information flow across several layers on \"information highways\". The\narchitecture is characterized by the use of gating units which learn to\nregulate the flow of information through a network. Highway networks with\nhundreds of layers can be trained directly using stochastic gradient descent\nand with a variety of activation functions, opening up the possibility of\nstudying extremely deep and efficient architectures. \n\n"}
{"id": "1505.02250", "contents": "Title: Newton Sketch: A Linear-time Optimization Algorithm with\n  Linear-Quadratic Convergence Abstract: We propose a randomized second-order method for optimization known as the\nNewton Sketch: it is based on performing an approximate Newton step using a\nrandomly projected or sub-sampled Hessian. For self-concordant functions, we\nprove that the algorithm has super-linear convergence with exponentially high\nprobability, with convergence and complexity guarantees that are independent of\ncondition numbers and related problem-dependent quantities. Given a suitable\ninitialization, similar guarantees also hold for strongly convex and smooth\nobjectives without self-concordance. When implemented using randomized\nprojections based on a sub-sampled Hadamard basis, the algorithm typically has\nsubstantially lower complexity than Newton's method. We also describe\nextensions of our methods to programs involving convex constraints that are\nequipped with self-concordant barriers. We discuss and illustrate applications\nto linear programs, quadratic programs with convex constraints, logistic\nregression and other generalized linear models, as well as semidefinite\nprograms. \n\n"}
{"id": "1505.03410", "contents": "Title: Mind the duality gap: safer rules for the Lasso Abstract: Screening rules allow to early discard irrelevant variables from the\noptimization in Lasso problems, or its derivatives, making solvers faster. In\nthis paper, we propose new versions of the so-called $\\textit{safe rules}$ for\nthe Lasso. Based on duality gap considerations, our new rules create safe test\nregions whose diameters converge to zero, provided that one relies on a\nconverging solver. This property helps screening out more variables, for a\nwider range of regularization parameter values. In addition to faster\nconvergence, we prove that we correctly identify the active sets (supports) of\nthe solutions in finite time. While our proposed strategy can cope with any\nsolver, its performance is demonstrated using a coordinate descent algorithm\nparticularly adapted to machine learning use cases. Significant computing time\nreductions are obtained with respect to previous safe rules. \n\n"}
{"id": "1505.04252", "contents": "Title: Global Convergence of Unmodified 3-Block ADMM for a Class of Convex\n  Minimization Problems Abstract: The alternating direction method of multipliers (ADMM) has been successfully\napplied to solve structured convex optimization problems due to its superior\npractical performance. The convergence properties of the 2-block ADMM have been\nstudied extensively in the literature. Specifically, it has been proven that\nthe 2-block ADMM globally converges for any penalty parameter $\\gamma>0$. In\nthis sense, the 2-block ADMM allows the parameter to be free, i.e., there is no\nneed to restrict the value for the parameter when implementing this algorithm\nin order to ensure convergence. However, for the 3-block ADMM, Chen \\etal\n\\cite{Chen-admm-failure-2013} recently constructed a counter-example showing\nthat it can diverge if no further condition is imposed. The existing results on\nstudying further sufficient conditions on guaranteeing the convergence of the\n3-block ADMM usually require $\\gamma$ to be smaller than a certain bound, which\nis usually either difficult to compute or too small to make it a practical\nalgorithm. In this paper, we show that the 3-block ADMM still globally\nconverges with any penalty parameter $\\gamma>0$ if the third function $f_3$ in\nthe objective is smooth and strongly convex, and its condition number is in\n$[1,1.0798)$, besides some other mild conditions. This requirement covers an\nimportant class of problems to be called regularized least squares\ndecomposition (RLSD) in this paper. \n\n"}
{"id": "1505.04732", "contents": "Title: Layered Adaptive Importance Sampling Abstract: Monte Carlo methods represent the \"de facto\" standard for approximating\ncomplicated integrals involving multidimensional target distributions. In order\nto generate random realizations from the target distribution, Monte Carlo\ntechniques use simpler proposal probability densities to draw candidate\nsamples. The performance of any such method is strictly related to the\nspecification of the proposal distribution, such that unfortunate choices\neasily wreak havoc on the resulting estimators. In this work, we introduce a\nlayered (i.e., hierarchical) procedure to generate samples employed within a\nMonte Carlo scheme. This approach ensures that an appropriate equivalent\nproposal density is always obtained automatically (thus eliminating the risk of\na catastrophic performance), although at the expense of a moderate increase in\nthe complexity. Furthermore, we provide a general unified importance sampling\n(IS) framework, where multiple proposal densities are employed and several IS\nschemes are introduced by applying the so-called deterministic mixture\napproach. Finally, given these schemes, we also propose a novel class of\nadaptive importance samplers using a population of proposals, where the\nadaptation is driven by independent parallel or interacting Markov Chain Monte\nCarlo (MCMC) chains. The resulting algorithms efficiently combine the benefits\nof both IS and MCMC methods. \n\n"}
{"id": "1505.05770", "contents": "Title: Variational Inference with Normalizing Flows Abstract: The choice of approximate posterior distribution is one of the core problems\nin variational inference. Most applications of variational inference employ\nsimple families of posterior approximations in order to allow for efficient\ninference, focusing on mean-field or other simple structured approximations.\nThis restriction has a significant impact on the quality of inferences made\nusing variational methods. We introduce a new approach for specifying flexible,\narbitrarily complex and scalable approximate posterior distributions. Our\napproximations are distributions constructed through a normalizing flow,\nwhereby a simple initial density is transformed into a more complex one by\napplying a sequence of invertible transformations until a desired level of\ncomplexity is attained. We use this view of normalizing flows to develop\ncategories of finite and infinitesimal flows and provide a unified view of\napproaches for constructing rich posterior approximations. We demonstrate that\nthe theoretical advantages of having posteriors that better match the true\nposterior, combined with the scalability of amortized variational approaches,\nprovides a clear improvement in performance and applicability of variational\ninference. \n\n"}
{"id": "1505.06999", "contents": "Title: Some Open Problems in Optimal AdaBoost and Decision Stumps Abstract: The significance of the study of the theoretical and practical properties of\nAdaBoost is unquestionable, given its simplicity, wide practical use, and\neffectiveness on real-world datasets. Here we present a few open problems\nregarding the behavior of \"Optimal AdaBoost,\" a term coined by Rudin,\nDaubechies, and Schapire in 2004 to label the simple version of the standard\nAdaBoost algorithm in which the weak learner that AdaBoost uses always outputs\nthe weak classifier with lowest weighted error among the respective hypothesis\nclass of weak classifiers implicit in the weak learner. We concentrate on the\nstandard, \"vanilla\" version of Optimal AdaBoost for binary classification that\nresults from using an exponential-loss upper bound on the misclassification\ntraining error. We present two types of open problems. One deals with general\nweak hypotheses. The other deals with the particular case of decision stumps,\nas often and commonly used in practice. Answers to the open problems can have\nimmediate significant impact to (1) cementing previously established results on\nasymptotic convergence properties of Optimal AdaBoost, for finite datasets,\nwhich in turn can be the start to any convergence-rate analysis; (2)\nunderstanding the weak-hypotheses class of effective decision stumps generated\nfrom data, which we have empirically observed to be significantly smaller than\nthe typically obtained class, as well as the effect on the weak learner's\nrunning time and previously established improved bounds on the generalization\nperformance of Optimal AdaBoost classifiers; and (3) shedding some light on the\n\"self control\" that AdaBoost tends to exhibit in practice. \n\n"}
{"id": "1506.00195", "contents": "Title: Recurrent Neural Networks with External Memory for Language\n  Understanding Abstract: Recurrent Neural Networks (RNNs) have become increasingly popular for the\ntask of language understanding. In this task, a semantic tagger is deployed to\nassociate a semantic label to each word in an input sequence. The success of\nRNN may be attributed to its ability to memorize long-term dependence that\nrelates the current-time semantic label prediction to the observations many\ntime instances away. However, the memory capacity of simple RNNs is limited\nbecause of the gradient vanishing and exploding problem. We propose to use an\nexternal memory to improve memorization capability of RNNs. We conducted\nexperiments on the ATIS dataset, and observed that the proposed model was able\nto achieve the state-of-the-art results. We compare our proposed model with\nalternative models and report analysis results that may provide insights for\nfuture research. \n\n"}
{"id": "1506.02080", "contents": "Title: Local Nonstationarity for Efficient Bayesian Optimization Abstract: Bayesian optimization has shown to be a fundamental global optimization\nalgorithm in many applications: ranging from automatic machine learning,\nrobotics, reinforcement learning, experimental design, simulations, etc. The\nmost popular and effective Bayesian optimization relies on a surrogate model in\nthe form of a Gaussian process due to its flexibility to represent a prior over\nfunction. However, many algorithms and setups relies on the stationarity\nassumption of the Gaussian process. In this paper, we present a novel\nnonstationary strategy for Bayesian optimization that is able to outperform the\nstate of the art in Bayesian optimization both in stationary and nonstationary\nproblems. \n\n"}
{"id": "1506.02428", "contents": "Title: Robust Regression via Hard Thresholding Abstract: We study the problem of Robust Least Squares Regression (RLSR) where several\nresponse variables can be adversarially corrupted. More specifically, for a\ndata matrix X \\in R^{p x n} and an underlying model w*, the response vector is\ngenerated as y = X'w* + b where b \\in R^n is the corruption vector supported\nover at most C.n coordinates. Existing exact recovery results for RLSR focus\nsolely on L1-penalty based convex formulations and impose relatively strict\nmodel assumptions such as requiring the corruptions b to be selected\nindependently of X.\n  In this work, we study a simple hard-thresholding algorithm called TORRENT\nwhich, under mild conditions on X, can recover w* exactly even if b corrupts\nthe response variables in an adversarial manner, i.e. both the support and\nentries of b are selected adversarially after observing X and w*. Our results\nhold under deterministic assumptions which are satisfied if X is sampled from\nany sub-Gaussian distribution. Finally unlike existing results that apply only\nto a fixed w*, generated independently of X, our results are universal and hold\nfor any w* \\in R^p.\n  Next, we propose gradient descent-based extensions of TORRENT that can scale\nefficiently to large scale problems, such as high dimensional sparse recovery\nand prove similar recovery guarantees for these extensions. Empirically we find\nTORRENT, and more so its extensions, offering significantly faster recovery\nthan the state-of-the-art L1 solvers. For instance, even on moderate-sized\ndatasets (with p = 50K) with around 40% corrupted responses, a variant of our\nproposed method called TORRENT-HYB is more than 20x faster than the best L1\nsolver. \n\n"}
{"id": "1506.02649", "contents": "Title: Faster SGD Using Sketched Conditioning Abstract: We propose a novel method for speeding up stochastic optimization algorithms\nvia sketching methods, which recently became a powerful tool for accelerating\nalgorithms for numerical linear algebra. We revisit the method of conditioning\nfor accelerating first-order methods and suggest the use of sketching methods\nfor constructing a cheap conditioner that attains a significant speedup with\nrespect to the Stochastic Gradient Descent (SGD) algorithm. While our\ntheoretical guarantees assume convexity, we discuss the applicability of our\nmethod to deep neural networks, and experimentally demonstrate its merits. \n\n"}
{"id": "1506.03693", "contents": "Title: Optimization Monte Carlo: Efficient and Embarrassingly Parallel\n  Likelihood-Free Inference Abstract: We describe an embarrassingly parallel, anytime Monte Carlo method for\nlikelihood-free models. The algorithm starts with the view that the\nstochasticity of the pseudo-samples generated by the simulator can be\ncontrolled externally by a vector of random numbers u, in such a way that the\noutcome, knowing u, is deterministic. For each instantiation of u we run an\noptimization procedure to minimize the distance between summary statistics of\nthe simulator and the data. After reweighing these samples using the prior and\nthe Jacobian (accounting for the change of volume in transforming from the\nspace of summary statistics to the space of parameters) we show that this\nweighted ensemble represents a Monte Carlo estimate of the posterior\ndistribution. The procedure can be run embarrassingly parallel (each node\nhandling one sample) and anytime (by allocating resources to the worst\nperforming sample). The procedure is validated on six experiments. \n\n"}
{"id": "1506.04359", "contents": "Title: Multi-class SVMs: From Tighter Data-Dependent Generalization Bounds to\n  Novel Algorithms Abstract: This paper studies the generalization performance of multi-class\nclassification algorithms, for which we obtain, for the first time, a\ndata-dependent generalization error bound with a logarithmic dependence on the\nclass size, substantially improving the state-of-the-art linear dependence in\nthe existing data-dependent generalization analysis. The theoretical analysis\nmotivates us to introduce a new multi-class classification machine based on\n$\\ell_p$-norm regularization, where the parameter $p$ controls the complexity\nof the corresponding bounds. We derive an efficient optimization algorithm\nbased on Fenchel duality theory. Benchmarks on several real-world datasets show\nthat the proposed algorithm can achieve significant accuracy gains over the\nstate of the art. \n\n"}
{"id": "1506.08230", "contents": "Title: Convolutional networks and learning invariant to homogeneous\n  multiplicative scalings Abstract: The conventional classification schemes -- notably multinomial logistic\nregression -- used in conjunction with convolutional networks (convnets) are\nclassical in statistics, designed without consideration for the usual coupling\nwith convnets, stochastic gradient descent, and backpropagation. In the\nspecific application to supervised learning for convnets, a simple\nscale-invariant classification stage turns out to be more robust than\nmultinomial logistic regression, appears to result in slightly lower errors on\nseveral standard test sets, has similar computational costs, and features\nprecise control over the actual rate of learning. \"Scale-invariant\" means that\nmultiplying the input values by any nonzero scalar leaves the output unchanged. \n\n"}
{"id": "1506.08473", "contents": "Title: Beating the Perils of Non-Convexity: Guaranteed Training of Neural\n  Networks using Tensor Methods Abstract: Training neural networks is a challenging non-convex optimization problem,\nand backpropagation or gradient descent can get stuck in spurious local optima.\nWe propose a novel algorithm based on tensor decomposition for guaranteed\ntraining of two-layer neural networks. We provide risk bounds for our proposed\nmethod, with a polynomial sample complexity in the relevant parameters, such as\ninput dimension and number of neurons. While learning arbitrary target\nfunctions is NP-hard, we provide transparent conditions on the function and the\ninput for learnability. Our training method is based on tensor decomposition,\nwhich provably converges to the global optimum, under a set of mild\nnon-degeneracy conditions. It consists of simple embarrassingly parallel linear\nand multi-linear operations, and is competitive with standard stochastic\ngradient descent (SGD), in terms of computational complexity. Thus, we propose\na computationally efficient method with guaranteed risk bounds for training\nneural networks with one hidden layer. \n\n"}
{"id": "1507.00300", "contents": "Title: Bootstrapped Thompson Sampling and Deep Exploration Abstract: This technical note presents a new approach to carrying out the kind of\nexploration achieved by Thompson sampling, but without explicitly maintaining\nor sampling from posterior distributions. The approach is based on a bootstrap\ntechnique that uses a combination of observed and artificially generated data.\nThe latter serves to induce a prior distribution which, as we will demonstrate,\nis critical to effective exploration. We explain how the approach can be\napplied to multi-armed bandit and reinforcement learning problems and how it\nrelates to Thompson sampling. The approach is particularly well-suited for\ncontexts in which exploration is coupled with deep learning, since in these\nsettings, maintaining or generating samples from a posterior distribution\nbecomes computationally infeasible. \n\n"}
{"id": "1507.00438", "contents": "Title: DC Proximal Newton for Non-Convex Optimization Problems Abstract: We introduce a novel algorithm for solving learning problems where both the\nloss function and the regularizer are non-convex but belong to the class of\ndifference of convex (DC) functions. Our contribution is a new general purpose\nproximal Newton algorithm that is able to deal with such a situation. The\nalgorithm consists in obtaining a descent direction from an approximation of\nthe loss function and then in performing a line search to ensure sufficient\ndescent. A theoretical analysis is provided showing that the iterates of the\nproposed algorithm {admit} as limit points stationary points of the DC\nobjective function. Numerical experiments show that our approach is more\nefficient than current state of the art for a problem with a convex loss\nfunctions and non-convex regularizer. We have also illustrated the benefit of\nour algorithm in high-dimensional transductive learning problem where both loss\nfunction and regularizers are non-convex. \n\n"}
{"id": "1507.01193", "contents": "Title: Dependency Recurrent Neural Language Models for Sentence Completion Abstract: Recent work on language modelling has shifted focus from count-based models\nto neural models. In these works, the words in each sentence are always\nconsidered in a left-to-right order. In this paper we show how we can improve\nthe performance of the recurrent neural network (RNN) language model by\nincorporating the syntactic dependencies of a sentence, which have the effect\nof bringing relevant contexts closer to the word being predicted. We evaluate\nour approach on the Microsoft Research Sentence Completion Challenge and show\nthat the dependency RNN proposed improves over the RNN by about 10 points in\naccuracy. Furthermore, we achieve results comparable with the state-of-the-art\nmodels on this task. \n\n"}
{"id": "1507.02216", "contents": "Title: Robust Sparse Blind Source Separation Abstract: Blind Source Separation is a widely used technique to analyze multichannel\ndata. In many real-world applications, its results can be significantly\nhampered by the presence of unknown outliers. In this paper, a novel algorithm\ncoined rGMCA (robust Generalized Morphological Component Analysis) is\nintroduced to retrieve sparse sources in the presence of outliers. It\nexplicitly estimates the sources, the mixing matrix, and the outliers. It also\ntakes advantage of the estimation of the outliers to further implement a\nweighting scheme, which provides a highly robust separation procedure.\nNumerical experiments demonstrate the efficiency of rGMCA to estimate the\nmixing matrix in comparison with standard BSS techniques. \n\n"}
{"id": "1507.02268", "contents": "Title: Optimal approximate matrix product in terms of stable rank Abstract: We prove, using the subspace embedding guarantee in a black box way, that one\ncan achieve the spectral norm guarantee for approximate matrix multiplication\nwith a dimensionality-reducing map having $m = O(\\tilde{r}/\\varepsilon^2)$\nrows. Here $\\tilde{r}$ is the maximum stable rank, i.e. squared ratio of\nFrobenius and operator norms, of the two matrices being multiplied. This is a\nquantitative improvement over previous work of [MZ11, KVZ14], and is also\noptimal for any oblivious dimensionality-reducing map. Furthermore, due to the\nblack box reliance on the subspace embedding property in our proofs, our\ntheorem can be applied to a much more general class of sketching matrices than\nwhat was known before, in addition to achieving better bounds. For example, one\ncan apply our theorem to efficient subspace embeddings such as the Subsampled\nRandomized Hadamard Transform or sparse subspace embeddings, or even with\nsubspace embedding constructions that may be developed in the future.\n  Our main theorem, via connections with spectral error matrix multiplication\nshown in prior work, implies quantitative improvements for approximate least\nsquares regression and low rank approximation. Our main result has also already\nbeen applied to improve dimensionality reduction guarantees for $k$-means\nclustering [CEMMP14], and implies new results for nonparametric regression\n[YPW15].\n  We also separately point out that the proof of the \"BSS\" deterministic\nrow-sampling result of [BSS12] can be modified to show that for any matrices\n$A, B$ of stable rank at most $\\tilde{r}$, one can achieve the spectral norm\nguarantee for approximate matrix multiplication of $A^T B$ by deterministically\nsampling $O(\\tilde{r}/\\varepsilon^2)$ rows that can be found in polynomial\ntime. The original result of [BSS12] was for rank instead of stable rank. Our\nobservation leads to a stronger version of a main theorem of [KMST10]. \n\n"}
{"id": "1507.04734", "contents": "Title: Variational Gram Functions: Convex Analysis and Optimization Abstract: We propose a new class of convex penalty functions, called \\emph{variational\nGram functions} (VGFs), that can promote pairwise relations, such as\northogonality, among a set of vectors in a vector space. These functions can\nserve as regularizers in convex optimization problems arising from hierarchical\nclassification, multitask learning, and estimating vectors with disjoint\nsupports, among other applications. We study convexity for VGFs, and give\nefficient characterizations for their convex conjugates, subdifferentials, and\nproximal operators. We discuss efficient optimization algorithms for\nregularized loss minimization problems where the loss admits a common, yet\nsimple, variational representation and the regularizer is a VGF. These\nalgorithms enjoy a simple kernel trick, an efficient line search, as well as\ncomputational advantages over first order methods based on the subdifferential\nor proximal maps. We also establish a general representer theorem for such\nlearning problems. Lastly, numerical experiments on a hierarchical\nclassification problem are presented to demonstrate the effectiveness of VGFs\nand the associated optimization algorithms. \n\n"}
{"id": "1508.02119", "contents": "Title: Plasma-wave generation in a dynamic spacetime Abstract: We propose a new electromagnetic-emission mechanism in magnetized, force-free\nplasma, which is driven by the evolution of the underlying dynamic spacetime.\nIn particular, the emission power and angular distribution of the emitted\nfast-magnetosonic and Alfv\\'en waves are separately determined. Previous\nnumerical simulations of binary black hole mergers occurring within magnetized\nplasma have recorded copious amounts of electromagnetic radiation that, in\naddition to collimated jets, include an unexplained, isotropic component which\nbecomes dominant close to merger. This raises the possibility of multimessenger\ngravitational-wave and electromagnetic observations on binary black hole\nsystems. The mechanism proposed here provides a candidate analytical\ncharacterization of the numerical results, and when combined with previously\nunderstood mechanisms such as the Blandford-Znajek process and\nkinetic-motion-driven radiation, allows us to construct a classification of\ndifferent electromagnetic radiation components seen in the inspiral stage of\ncompact-binary coalescences. \n\n"}
{"id": "1508.05170", "contents": "Title: Adaptive Online Learning Abstract: We propose a general framework for studying adaptive regret bounds in the\nonline learning framework, including model selection bounds and data-dependent\nbounds. Given a data- or model-dependent bound we ask, \"Does there exist some\nalgorithm achieving this bound?\" We show that modifications to recently\nintroduced sequential complexity measures can be used to answer this question\nby providing sufficient conditions under which adaptive rates can be achieved.\nIn particular each adaptive rate induces a set of so-called offset complexity\nmeasures, and obtaining small upper bounds on these quantities is sufficient to\ndemonstrate achievability. A cornerstone of our analysis technique is the use\nof one-sided tail inequalities to bound suprema of offset random processes.\n  Our framework recovers and improves a wide variety of adaptive bounds\nincluding quantile bounds, second-order data-dependent bounds, and small loss\nbounds. In addition we derive a new type of adaptive bound for online linear\noptimization based on the spectral norm, as well as a new online PAC-Bayes\ntheorem that holds for countably infinite sets. \n\n"}
{"id": "1508.05550", "contents": "Title: MultiView Diffusion Maps Abstract: In this paper, we address the challenging task of achieving multi-view\ndimensionality reduction. The goal is to effectively use the availability of\nmultiple views for extracting a coherent low-dimensional representation of the\ndata. The proposed method exploits the intrinsic relation within each view, as\nwell as the mutual relations between views. The multi-view dimensionality\nreduction is achieved by defining a cross-view model in which an implied random\nwalk process is restrained to hop between objects in the different views. The\nmethod is robust to scaling and insensitive to small structural changes in the\ndata. We define new diffusion distances and analyze the spectra of the proposed\nkernel. We show that the proposed framework is useful for various machine\nlearning applications such as clustering, classification, and manifold\nlearning. Finally, by fusing multi-sensor seismic data we present a method for\nautomatic identification of seismic events. \n\n"}
{"id": "1508.07439", "contents": "Title: Local free-fall Temperature of modified Schwarzschild black hole in\n  rainbow spacetime Abstract: We obtain a (5+1)-dimensional global flat embedding of modified Schwarzschild\nblack hole in rainbow gravity. We show that local free-fall temperature in\nrainbow gravity, which depends on different energy $\\omega$ of a test particle,\nis finite at the event horizon for a freely falling observer, while local\ntemperature is divergent at the event horizon for a fiducial observer.\nMoreover, these temperatures in rainbow gravity satisfy similar relations to\nthose of the Schwarzschild black hole except overall factor $g(\\omega)$, which\nplays a key role of rainbow functions in this embedding approach. \n\n"}
{"id": "1509.01770", "contents": "Title: Theoretical and Experimental Analyses of Tensor-Based Regression and\n  Classification Abstract: We theoretically and experimentally investigate tensor-based regression and\nclassification. Our focus is regularization with various tensor norms,\nincluding the overlapped trace norm, the latent trace norm, and the scaled\nlatent trace norm. We first give dual optimization methods using the\nalternating direction method of multipliers, which is computationally efficient\nwhen the number of training samples is moderate. We then theoretically derive\nan excess risk bound for each tensor norm and clarify their behavior. Finally,\nwe perform extensive experiments using simulated and real data and demonstrate\nthe superiority of tensor-based learning methods over vector- and matrix-based\nlearning methods. \n\n"}
{"id": "1509.03005", "contents": "Title: Compatible Value Gradients for Reinforcement Learning of Continuous Deep\n  Policies Abstract: This paper proposes GProp, a deep reinforcement learning algorithm for\ncontinuous policies with compatible function approximation. The algorithm is\nbased on two innovations. Firstly, we present a temporal-difference based\nmethod for learning the gradient of the value-function. Secondly, we present\nthe deviator-actor-critic (DAC) model, which comprises three neural networks\nthat estimate the value function, its gradient, and determine the actor's\npolicy respectively. We evaluate GProp on two challenging tasks: a contextual\nbandit problem constructed from nonparametric regression datasets that is\ndesigned to probe the ability of reinforcement learning algorithms to\naccurately estimate gradients; and the octopus arm, a challenging reinforcement\nlearning benchmark. GProp is competitive with fully supervised methods on the\nbandit task and achieves the best performance to date on the octopus arm. \n\n"}
{"id": "1509.06664", "contents": "Title: Reasoning about Entailment with Neural Attention Abstract: While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset. \n\n"}
{"id": "1509.08772", "contents": "Title: Bounce Inflation Cosmology with Standard Model Higgs Boson Abstract: It is of great interest to connect cosmology in the early universe to the\nStandard Model of particle physics. In this paper, we try to construct a bounce\ninflation model with the standard model Higgs boson, where the one loop\ncorrection is taken into account in the effective potential of Higgs field. In\nthis model, a Galileon term has been introduced to eliminate the ghost mode\nwhen bounce happens. Moreover, due to the fact that the Fermion loop correction\ncan make part of the Higgs potential negative, one naturally obtains a large\nequation of state(EoS) parameter in the contracting phase, which can eliminate\nthe anisotropy problem. After the bounce, the model can drive the universe into\nthe standard higgs inflation phase, which can generate nearly scale-invariant\npower spectrum. \n\n"}
{"id": "1509.09002", "contents": "Title: Convergence of Stochastic Gradient Descent for PCA Abstract: We consider the problem of principal component analysis (PCA) in a streaming\nstochastic setting, where our goal is to find a direction of approximate\nmaximal variance, based on a stream of i.i.d. data points in $\\reals^d$. A\nsimple and computationally cheap algorithm for this is stochastic gradient\ndescent (SGD), which incrementally updates its estimate based on each new data\npoint. However, due to the non-convex nature of the problem, analyzing its\nperformance has been a challenge. In particular, existing guarantees rely on a\nnon-trivial eigengap assumption on the covariance matrix, which is intuitively\nunnecessary. In this paper, we provide (to the best of our knowledge) the first\neigengap-free convergence guarantees for SGD in the context of PCA. This also\npartially resolves an open problem posed in \\cite{hardt2014noisy}. Moreover,\nunder an eigengap assumption, we show that the same techniques lead to new SGD\nconvergence guarantees with better dependence on the eigengap. \n\n"}
{"id": "1509.09010", "contents": "Title: Discrete quantum spectrum of black holes Abstract: The quantum genesis of Hawking radiation is a long-standing puzzle in black\nhole physics. Semi-classically one can argue that the spectrum of radiation\nemitted by a black hole look very much sparse unlike what is expected from a\nthermal object. It was demonstrated through a simple quantum model that a\nquantum black hole will retain a discrete profile, at least in the weak energy\nregime. However, it was suggested that this discreteness might be an artifact\nof the simplicity of eigen-spectrum of the model considered. Different quantum\ntheories can, in principle, give rise to different complicated spectra and make\nthe radiation from black hole dense enough in transition lines, to make them\nlook continuous in profile. We show that such a hope from a geometry-quantized\nblack hole is not realized as long as large enough black holes are dubbed with\na classical mass area relation in any gravity theory ranging from GR,\nLanczos-Lovelock to f(R) gravity. We show that the smallest frequency of\nemission from black hole in any quantum description, is bounded from below, to\nbe of the order of its inverse mass. That leaves the emission with only two\npossibilities. It can either be non-thermal, or it can be thermal only with the\ntemperature being much larger than 1/M. \n\n"}
{"id": "1510.02173", "contents": "Title: Data-Efficient Learning of Feedback Policies from Image Pixels using\n  Deep Dynamical Models Abstract: Data-efficient reinforcement learning (RL) in continuous state-action spaces\nusing very high-dimensional observations remains a key challenge in developing\nfully autonomous systems. We consider a particularly important instance of this\nchallenge, the pixels-to-torques problem, where an RL agent learns a\nclosed-loop control policy (\"torques\") from pixel information only. We\nintroduce a data-efficient, model-based reinforcement learning algorithm that\nlearns such a closed-loop policy directly from pixel information. The key\ningredient is a deep dynamical model for learning a low-dimensional feature\nembedding of images jointly with a predictive model in this low-dimensional\nfeature space. Joint learning is crucial for long-term predictions, which lie\nat the core of the adaptive nonlinear model predictive control strategy that we\nuse for closed-loop control. Compared to state-of-the-art RL methods for\ncontinuous states and actions, our approach learns quickly, scales to\nhigh-dimensional state spaces, is lightweight and an important step toward\nfully autonomous end-to-end learning from pixels to torques. \n\n"}
{"id": "1510.02558", "contents": "Title: Functional Frank-Wolfe Boosting for General Loss Functions Abstract: Boosting is a generic learning method for classification and regression. Yet,\nas the number of base hypotheses becomes larger, boosting can lead to a\ndeterioration of test performance. Overfitting is an important and ubiquitous\nphenomenon, especially in regression settings. To avoid overfitting, we\nconsider using $l_1$ regularization. We propose a novel Frank-Wolfe type\nboosting algorithm (FWBoost) applied to general loss functions. By using\nexponential loss, the FWBoost algorithm can be rewritten as a variant of\nAdaBoost for binary classification. FWBoost algorithms have exactly the same\nform as existing boosting methods, in terms of making calls to a base learning\nalgorithm with different weights update. This direct connection between\nboosting and Frank-Wolfe yields a new algorithm that is as practical as\nexisting boosting methods but with new guarantees and rates of convergence.\nExperimental results show that the test performance of FWBoost is not degraded\nwith larger rounds in boosting, which is consistent with the theoretical\nanalysis. \n\n"}
{"id": "1510.03508", "contents": "Title: Robust predictions for the large-scale cosmological power deficit from\n  primordial quantum nonequilibrium Abstract: The de Broglie-Bohm pilot-wave formulation of quantum theory allows the\nexistence of physical states that violate the Born probability rule. Recent\nwork has shown that in pilot-wave field theory on expanding space relaxation to\nthe Born rule is suppressed for long-wavelength field modes, resulting in a\nlarge-scale power deficit {\\xi}(k) which for a radiation-dominated expansion is\nfound to have an approximate inverse-tangent dependence on k (assuming that the\nwidth of the initial distribution is smaller than the width of the initial\nBorn-rule distribution and that the initial quantum states are evenly-weighted\nsuperpositions of energy states). In this paper we show that the functional\nform of {\\xi}(k) is robust under changes in the initial nonequilibrium\ndistribution -- subject to the limitation of a subquantum width -- as well as\nunder the addition of an inflationary era at the end of the radiation-dominated\nphase. In both cases the predicted deficit {\\xi}(k) remains an inverse-tangent\nfunction of k. Furthermore, with the inflationary phase the dependence of the\nfitting parameters on the number of superposed pre-inflationary energy states\nis comparable to that found previously. Our results indicate that, for the\nassumed broad class of initial conditions, an inverse-tangent power deficit is\nlikely to be a fairly general and robust signature of quantum relaxation in the\nearly universe. \n\n"}
{"id": "1510.04822", "contents": "Title: SGD with Variance Reduction beyond Empirical Risk Minimization Abstract: We introduce a doubly stochastic proximal gradient algorithm for optimizing a\nfinite average of smooth convex functions, whose gradients depend on\nnumerically expensive expectations. Our main motivation is the acceleration of\nthe optimization of the regularized Cox partial-likelihood (the core model used\nin survival analysis), but our algorithm can be used in different settings as\nwell. The proposed algorithm is doubly stochastic in the sense that gradient\nsteps are done using stochastic gradient descent (SGD) with variance reduction,\nwhere the inner expectations are approximated by a Monte-Carlo Markov-Chain\n(MCMC) algorithm. We derive conditions on the MCMC number of iterations\nguaranteeing convergence, and obtain a linear rate of convergence under strong\nconvexity and a sublinear rate without this assumption. We illustrate the fact\nthat our algorithm improves the state-of-the-art solver for regularized Cox\npartial-likelihood on several datasets from survival analysis. \n\n"}
{"id": "1511.02872", "contents": "Title: Visual Language Modeling on CNN Image Representations Abstract: Measuring the naturalness of images is important to generate realistic images\nor to detect unnatural regions in images. Additionally, a method to measure\nnaturalness can be complementary to Convolutional Neural Network (CNN) based\nfeatures, which are known to be insensitive to the naturalness of images.\nHowever, most probabilistic image models have insufficient capability of\nmodeling the complex and abstract naturalness that we feel because they are\nbuilt directly on raw image pixels. In this work, we assume that naturalness\ncan be measured by the predictability on high-level features during eye\nmovement. Based on this assumption, we propose a novel method to evaluate the\nnaturalness by building a variant of Recurrent Neural Network Language Models\non pre-trained CNN representations. Our method is applied to two tasks,\ndemonstrating that 1) using our method as a regularizer enables us to generate\nmore understandable images from image features than existing approaches, and 2)\nunnaturalness maps produced by our method achieve state-of-the-art eye fixation\nprediction performance on two well-studied datasets. \n\n"}
{"id": "1511.02995", "contents": "Title: Incorporating Knowledge into Structural Equation Models using Auxiliary\n  Variables Abstract: In this paper, we extend graph-based identification methods by allowing\nbackground knowledge in the form of non-zero parameter values. Such information\ncould be obtained, for example, from a previously conducted randomized\nexperiment, from substantive understanding of the domain, or even an\nidentification technique. To incorporate such information systematically, we\npropose the addition of auxiliary variables to the model, which are constructed\nso that certain paths will be conveniently cancelled. This cancellation allows\nthe auxiliary variables to help conventional methods of identification (e.g.,\nsingle-door criterion, instrumental variables, half-trek criterion), as well as\nmodel testing (e.g., d-separation, over-identification). Moreover, by\niteratively alternating steps of identification and adding auxiliary variables,\nwe can improve the power of existing identification methods via a bootstrapping\napproach that does not require external knowledge. We operationalize this\nmethod for simple instrumental sets (a generalization of instrumental\nvariables) and show that the resulting method is able to identify at least as\nmany models as the most general identification method for linear systems known\nto date. We further discuss the application of auxiliary variables to the tasks\nof model testing and z-identification. \n\n"}
{"id": "1511.05042", "contents": "Title: An Exploration of Softmax Alternatives Belonging to the Spherical Loss\n  Family Abstract: In a multi-class classification problem, it is standard to model the output\nof a neural network as a categorical distribution conditioned on the inputs.\nThe output must therefore be positive and sum to one, which is traditionally\nenforced by a softmax. This probabilistic mapping allows to use the maximum\nlikelihood principle, which leads to the well-known log-softmax loss. However\nthe choice of the softmax function seems somehow arbitrary as there are many\nother possible normalizing functions. It is thus unclear why the log-softmax\nloss would perform better than other loss alternatives. In particular Vincent\net al. (2015) recently introduced a class of loss functions, called the\nspherical family, for which there exists an efficient algorithm to compute the\nupdates of the output weights irrespective of the output size. In this paper,\nwe explore several loss functions from this family as possible alternatives to\nthe traditional log-softmax. In particular, we focus our investigation on\nspherical bounds of the log-softmax loss and on two spherical log-likelihood\nlosses, namely the log-Spherical Softmax suggested by Vincent et al. (2015) and\nthe log-Taylor Softmax that we introduce. Although these alternatives do not\nyield as good results as the log-softmax loss on two language modeling tasks,\nthey surprisingly outperform it in our experiments on MNIST and CIFAR-10,\nsuggesting that they might be relevant in a broad range of applications. \n\n"}
{"id": "1511.05118", "contents": "Title: Random sampling of bandlimited signals on graphs Abstract: We study the problem of sampling k-bandlimited signals on graphs. We propose\ntwo sampling strategies that consist in selecting a small subset of nodes at\nrandom. The first strategy is non-adaptive, i.e., independent of the graph\nstructure, and its performance depends on a parameter called the graph\ncoherence. On the contrary, the second strategy is adaptive but yields optimal\nresults. Indeed, no more than O(k log(k)) measurements are sufficient to ensure\nan accurate and stable recovery of all k-bandlimited signals. This second\nstrategy is based on a careful choice of the sampling distribution, which can\nbe estimated quickly. Then, we propose a computationally efficient decoder to\nreconstruct k-bandlimited signals from their samples. We prove that it yields\naccurate reconstructions and that it is also stable to noise. Finally, we\nconduct several experiments to test these techniques. \n\n"}
{"id": "1511.06379", "contents": "Title: Dynamic Adaptive Network Intelligence Abstract: Accurate representational learning of both the explicit and implicit\nrelationships within data is critical to the ability of machines to perform\nmore complex and abstract reasoning tasks. We describe the efficient weakly\nsupervised learning of such inferences by our Dynamic Adaptive Network\nIntelligence (DANI) model. We report state-of-the-art results for DANI over\nquestion answering tasks in the bAbI dataset that have proved difficult for\ncontemporary approaches to learning representation (Weston et al., 2015). \n\n"}
{"id": "1511.06397", "contents": "Title: Compressing Word Embeddings Abstract: Recent methods for learning vector space representations of words have\nsucceeded in capturing fine-grained semantic and syntactic regularities using\nvector arithmetic. However, these vector space representations (created through\nlarge-scale text analysis) are typically stored verbatim, since their internal\nstructure is opaque. Using word-analogy tests to monitor the level of detail\nstored in compressed re-representations of the same vector space, the\ntrade-offs between the reduction in memory usage and expressiveness are\ninvestigated. A simple scheme is outlined that can reduce the memory footprint\nof a state-of-the-art embedding by a factor of 10, with only minimal impact on\nperformance. Then, using the same `bit budget', a binary (approximate)\nfactorisation of the same space is also explored, with the aim of creating an\nequivalent representation with better interpretability. \n\n"}
{"id": "1511.06653", "contents": "Title: Recurrent Semi-supervised Classification and Constrained Adversarial\n  Generation with Motion Capture Data Abstract: We explore recurrent encoder multi-decoder neural network architectures for\nsemi-supervised sequence classification and reconstruction. We find that the\nuse of multiple reconstruction modules helps models generalize in a\nclassification task when only a small amount of labeled data is available,\nwhich is often the case in practice. Such models provide useful high-level\nrepresentations of motions allowing clustering, searching and faster labeling\nof new sequences. We also propose a new, realistic partitioning of a\nwell-known, high quality motion-capture dataset for better evaluations. We\nfurther explore a novel formulation for future-predicting decoders based on\nconditional recurrent generative adversarial networks, for which we propose\nboth soft and hard constraints for transition generation derived from desired\nphysical properties of synthesized future movements and desired animation\ngoals. We find that using such constraints allow to stabilize the training of\nrecurrent adversarial architectures for animation generation. \n\n"}
{"id": "1511.07340", "contents": "Title: Modular Autoencoders for Ensemble Feature Extraction Abstract: We introduce the concept of a Modular Autoencoder (MAE), capable of learning\na set of diverse but complementary representations from unlabelled data, that\ncan later be used for supervised tasks. The learning of the representations is\ncontrolled by a trade off parameter, and we show on six benchmark datasets the\noptimum lies between two extremes: a set of smaller, independent autoencoders\neach with low capacity, versus a single monolithic encoding, outperforming an\nappropriate baseline. In the present paper we explore the special case of\nlinear MAE, and derive an SVD-based algorithm which converges several orders of\nmagnitude faster than gradient descent. \n\n"}
{"id": "1511.08732", "contents": "Title: Scalar-Tensor Quintessence with a linear potential: Avoiding the Big\n  Crunch cosmic doomsday Abstract: All quintessence potentials that are either monotonic with negative interval\nor have a minimum at negative values of the potential, generically predict a\nfuture collapse of the scale factor to a \"doomsday\" singularity. We show that\nthis doomsday is generically avoided in models with a proper non-minimal\ncoupling of the quintessence scalar field to the curvature scalar $R$. For\nsimplicity we consider linear quintessence potential $V=-s\\phi$ and linear\nnon-minimal coupling $F=1-\\lambda \\phi$. However our result is generic and is\ndue to the fact that the non-minimal coupling modifies the effective potential\nthat determines the dynamics of the scalar field. Thus for each positive value\nof the parameter $s$ we find a critical value $\\lambda_{crit}(s)$ such that for\n$\\lambda>\\lambda_{crit}(s)$ the negative potential energy does not dominate the\nuniverse and the cosmic doomsday Big Crunch singularity is avoided because the\nscalar field eventually rolls up its potential. We find that\n$\\lambda_{crit}(s)$ increases approximately linearly with $s$. For\n$\\lambda>\\lambda_{crit}(s)$ the potential energy of the scalar field becomes\npositive and it eventually dominates while the dark energy equation of state\nparameter tends to $w=-1$ leading to a deSitter Universe. \n\n"}
{"id": "1511.08842", "contents": "Title: Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) - The\n  $\\ell_0$ Method Abstract: The sparsity of natural signals and images in a transform domain or\ndictionary has been extensively exploited in several applications such as\ncompression, denoising and inverse problems. More recently, data-driven\nadaptation of synthesis dictionaries has shown promise in many applications\ncompared to fixed or analytical dictionary models. However, dictionary learning\nproblems are typically non-convex and NP-hard, and the usual alternating\nminimization approaches for these problems are often computationally expensive,\nwith the computations dominated by the NP-hard synthesis sparse coding step. In\nthis work, we investigate an efficient method for $\\ell_{0}$ \"norm\"-based\ndictionary learning by first approximating the training data set with a sum of\nsparse rank-one matrices and then using a block coordinate descent approach to\nestimate the unknowns. The proposed block coordinate descent algorithm involves\nefficient closed-form solutions. In particular, the sparse coding step involves\na simple form of thresholding. We provide a convergence analysis for the\nproposed block coordinate descent approach. Our numerical experiments show the\npromising performance and significant speed-ups provided by our method over the\nclassical K-SVD scheme in sparse signal representation and image denoising. \n\n"}
{"id": "1511.08963", "contents": "Title: Learning Directed Acyclic Graphs with Penalized Neighbourhood Regression Abstract: We study a family of regularized score-based estimators for learning the\nstructure of a directed acyclic graph (DAG) for a multivariate normal\ndistribution from high-dimensional data with $p\\gg n$. Our main results\nestablish support recovery guarantees and deviation bounds for a family of\npenalized least-squares estimators under concave regularization without\nassuming prior knowledge of a variable ordering. These results apply to a\nvariety of practical situations that allow for arbitrary nondegenerate\ncovariance structures as well as many popular regularizers including the MCP,\nSCAD, $\\ell_{0}$ and $\\ell_{1}$. The proof relies on interpreting a DAG as a\nrecursive linear structural equation model, which reduces the estimation\nproblem to a series of neighbourhood regressions. We provide a novel\nstatistical analysis of these neighbourhood problems, establishing uniform\ncontrol over the superexponential family of neighbourhoods associated with a\nGaussian distribution. We then apply these results to study the statistical\nproperties of score-based DAG estimators, learning causal DAGs, and inferring\nconditional independence relations via graphical models. Our results\nyield---for the first time---finite-sample guarantees for structure learning of\nGaussian DAGs in high-dimensions via score-based estimation. \n\n"}
{"id": "1512.01629", "contents": "Title: Risk-Constrained Reinforcement Learning with Percentile Risk Criteria Abstract: In many sequential decision-making problems one is interested in minimizing\nan expected cumulative cost while taking into account \\emph{risk}, i.e.,\nincreased awareness of events of small probability and high consequences.\nAccordingly, the objective of this paper is to present efficient reinforcement\nlearning algorithms for risk-constrained Markov decision processes (MDPs),\nwhere risk is represented via a chance constraint or a constraint on the\nconditional value-at-risk (CVaR) of the cumulative cost. We collectively refer\nto such problems as percentile risk-constrained MDPs.\n  Specifically, we first derive a formula for computing the gradient of the\nLagrangian function for percentile risk-constrained MDPs. Then, we devise\npolicy gradient and actor-critic algorithms that (1) estimate such gradient,\n(2) update the policy in the descent direction, and (3) update the Lagrange\nmultiplier in the ascent direction. For these algorithms we prove convergence\nto locally optimal policies. Finally, we demonstrate the effectiveness of our\nalgorithms in an optimal stopping problem and an online marketing application. \n\n"}
{"id": "1512.02831", "contents": "Title: Bigger Buffer k-d Trees on Multi-Many-Core Systems Abstract: A buffer k-d tree is a k-d tree variant for massively-parallel nearest\nneighbor search. While providing valuable speed-ups on modern many-core devices\nin case both a large number of reference and query points are given, buffer k-d\ntrees are limited by the amount of points that can fit on a single device. In\nthis work, we show how to modify the original data structure and the associated\nworkflow to make the overall approach capable of dealing with massive data\nsets. We further provide a simple yet efficient way of using multiple devices\ngiven in a single workstation. The applicability of the modified framework is\ndemonstrated in the context of astronomy, a field that is faced with huge\namounts of data. \n\n"}
{"id": "1512.03385", "contents": "Title: Deep Residual Learning for Image Recognition Abstract: Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation. \n\n"}
{"id": "1512.07095", "contents": "Title: Scaling Laws in Gravitational Collapse Abstract: This paper presents two interesting scaling laws, which relate some critical\nexponents in the critical behavior of spherically symmetric gravitational\ncollapses. These scaling laws are independent of the details of gravity theory\nunder consideration and share similar forms as those in thermodynamic and\ngeometrical phase transitions in condensed matter system. The properties of the\nscaling laws are discussed and some numerical checks are given. \n\n"}
{"id": "1512.07679", "contents": "Title: Deep Reinforcement Learning in Large Discrete Action Spaces Abstract: Being able to reason in an environment with a large number of discrete\nactions is essential to bringing reinforcement learning to a larger class of\nproblems. Recommender systems, industrial plants and language models are only\nsome of the many real-world tasks involving large numbers of discrete actions\nfor which current methods are difficult or even often impossible to apply. An\nability to generalize over the set of actions as well as sub-linear complexity\nrelative to the size of the set are both necessary to handle such tasks.\nCurrent approaches are not able to provide both of these, which motivates the\nwork in this paper. Our proposed approach leverages prior information about the\nactions to embed them in a continuous space upon which it can generalize.\nAdditionally, approximate nearest-neighbor methods allow for logarithmic-time\nlookup complexity relative to the number of actions, which is necessary for\ntime-wise tractable training. This combined approach allows reinforcement\nlearning methods to be applied to large-scale learning problems previously\nintractable with current methods. We demonstrate our algorithm's abilities on a\nseries of tasks having up to one million actions. \n\n"}
{"id": "1512.07839", "contents": "Title: Implementing a Bayes Filter in a Neural Circuit: The Case of Unknown\n  Stimulus Dynamics Abstract: In order to interact intelligently with objects in the world, animals must\nfirst transform neural population responses into estimates of the dynamic,\nunknown stimuli which caused them. The Bayesian solution to this problem is\nknown as a Bayes filter, which applies Bayes' rule to combine population\nresponses with the predictions of an internal model. In this paper we present a\nmethod for learning to approximate a Bayes filter when the stimulus dynamics\nare unknown. To do this we use the inferential properties of probabilistic\npopulation codes to compute Bayes' rule, and train a neural network to compute\napproximate predictions by the method of maximum likelihood. In particular, we\nperform stochastic gradient descent on the negative log-likelihood with a novel\napproximation of the gradient. We demonstrate our methods on a finite-state, a\nlinear, and a nonlinear filtering problem, and show how the hidden layer of the\nneural network develops tuning curves which are consistent with findings in\nexperimental neuroscience. \n\n"}
{"id": "1512.08949", "contents": "Title: Simple, Robust and Optimal Ranking from Pairwise Comparisons Abstract: We consider data in the form of pairwise comparisons of n items, with the\ngoal of precisely identifying the top k items for some value of k < n, or\nalternatively, recovering a ranking of all the items. We analyze the Copeland\ncounting algorithm that ranks the items in order of the number of pairwise\ncomparisons won, and show it has three attractive features: (a) its\ncomputational efficiency leads to speed-ups of several orders of magnitude in\ncomputation time as compared to prior work; (b) it is robust in that\ntheoretical guarantees impose no conditions on the underlying matrix of\npairwise-comparison probabilities, in contrast to some prior work that applies\nonly to the BTL parametric model; and (c) it is an optimal method up to\nconstant factors, meaning that it achieves the information-theoretic limits for\nrecovering the top k-subset. We extend our results to obtain sharp guarantees\nfor approximate recovery under the Hamming distortion metric, and more\ngenerally, to any arbitrary error requirement that satisfies a simple and\nnatural monotonicity condition. \n\n"}
{"id": "1601.02828", "contents": "Title: Learning Hidden Unit Contributions for Unsupervised Acoustic Model\n  Adaptation Abstract: This work presents a broad study on the adaptation of neural network acoustic\nmodels by means of learning hidden unit contributions (LHUC) -- a method that\nlinearly re-combines hidden units in a speaker- or environment-dependent manner\nusing small amounts of unsupervised adaptation data. We also extend LHUC to a\nspeaker adaptive training (SAT) framework that leads to a more adaptable DNN\nacoustic model, working both in a speaker-dependent and a speaker-independent\nmanner, without the requirements to maintain auxiliary speaker-dependent\nfeature extractors or to introduce significant speaker-dependent changes to the\nDNN structure. Through a series of experiments on four different speech\nrecognition benchmarks (TED talks, Switchboard, AMI meetings, and Aurora4)\ncomprising 270 test speakers, we show that LHUC in both its test-only and SAT\nvariants results in consistent word error rate reductions ranging from 5% to\n23% relative depending on the task and the degree of mismatch between training\nand test data. In addition, we have investigated the effect of the amount of\nadaptation data per speaker, the quality of unsupervised adaptation targets,\nthe complementarity to other adaptation techniques, one-shot adaptation, and an\nextension to adapting DNNs trained in a sequence discriminative manner. \n\n"}
{"id": "1602.01895", "contents": "Title: Generate Image Descriptions based on Deep RNN and Memory Cells for\n  Images Features Abstract: Generating natural language descriptions for images is a challenging task.\nThe traditional way is to use the convolutional neural network (CNN) to extract\nimage features, followed by recurrent neural network (RNN) to generate\nsentences. In this paper, we present a new model that added memory cells to\ngate the feeding of image features to the deep neural network. The intuition is\nenabling our model to memorize how much information from images should be fed\nat each stage of the RNN. Experiments on Flickr8K and Flickr30K datasets showed\nthat our model outperforms other state-of-the-art models with higher BLEU\nscores. \n\n"}
{"id": "1602.02823", "contents": "Title: Poor starting points in machine learning Abstract: Poor (even random) starting points for learning/training/optimization are\ncommon in machine learning. In many settings, the method of Robbins and Monro\n(online stochastic gradient descent) is known to be optimal for good starting\npoints, but may not be optimal for poor starting points -- indeed, for poor\nstarting points Nesterov acceleration can help during the initial iterations,\neven though Nesterov methods not designed for stochastic approximation could\nhurt during later iterations. The common practice of training with nontrivial\nminibatches enhances the advantage of Nesterov acceleration. \n\n"}
{"id": "1602.03600", "contents": "Title: Data-Driven Online Decision Making with Costly Information Acquisition Abstract: In most real-world settings such as recommender systems, finance, and\nhealthcare, collecting useful information is costly and requires an active\nchoice on the part of the decision maker. The decision-maker needs to learn\nsimultaneously what observations to make and what actions to take. This paper\nincorporates the information acquisition decision into an online learning\nframework. We propose two different algorithms for this dual learning problem:\nSim-OOS and Seq-OOS where observations are made simultaneously and\nsequentially, respectively. We prove that both algorithms achieve a regret that\nis sublinear in time. The developed framework and algorithms can be used in\nmany applications including medical informatics, recommender systems and\nactionable intelligence in transportation, finance, cyber-security etc., in\nwhich collecting information prior to making decisions is costly. We validate\nour algorithms in a breast cancer example setting in which we show substantial\nperformance gains for our proposed algorithms. \n\n"}
{"id": "1602.03619", "contents": "Title: Optimal Inference in Crowdsourced Classification via Belief Propagation Abstract: Crowdsourcing systems are popular for solving large-scale labelling tasks\nwith low-paid workers. We study the problem of recovering the true labels from\nthe possibly erroneous crowdsourced labels under the popular Dawid-Skene model.\nTo address this inference problem, several algorithms have recently been\nproposed, but the best known guarantee is still significantly larger than the\nfundamental limit. We close this gap by introducing a tighter lower bound on\nthe fundamental limit and proving that Belief Propagation (BP) exactly matches\nthis lower bound. The guaranteed optimality of BP is the strongest in the sense\nthat it is information-theoretically impossible for any other algorithm to\ncorrectly label a larger fraction of the tasks. Experimental results suggest\nthat BP is close to optimal for all regimes considered and improves upon\ncompeting state-of-the-art algorithms. \n\n"}
{"id": "1602.04963", "contents": "Title: Simulations of coalescing black holes Abstract: We describe the methods and results of numerical simulations of coalescing\nblack holes. The simulation in dynamical spacetime covers the inspiral, merger,\nand ringdown phases. We analyze the emission of gravitational waves and\nproperties of a black hole being the merger product. We discuss the results in\nthe context of astrophysical environment of black holes that exist in the\nUniverse. \n\n"}
{"id": "1602.06566", "contents": "Title: Interactive Storytelling over Document Collections Abstract: Storytelling algorithms aim to 'connect the dots' between disparate documents\nby linking starting and ending documents through a series of intermediate\ndocuments. Existing storytelling algorithms are based on notions of coherence\nand connectivity, and thus the primary way by which users can steer the story\nconstruction is via design of suitable similarity functions. We present an\nalternative approach to storytelling wherein the user can interactively and\niteratively provide 'must use' constraints to preferentially support the\nconstruction of some stories over others. The three innovations in our approach\nare distance measures based on (inferred) topic distributions, the use of\nconstraints to define sets of linear inequalities over paths, and the\nintroduction of slack and surplus variables to condition the topic distribution\nto preferentially emphasize desired terms over others. We describe experimental\nresults to illustrate the effectiveness of our interactive storytelling\napproach over multiple text datasets. \n\n"}
{"id": "1602.06662", "contents": "Title: Recurrent Orthogonal Networks and Long-Memory Tasks Abstract: Although RNNs have been shown to be powerful tools for processing sequential\ndata, finding architectures or optimization strategies that allow them to model\nvery long term dependencies is still an active area of research. In this work,\nwe carefully analyze two synthetic datasets originally outlined in (Hochreiter\nand Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store\ninformation over many time steps. We explicitly construct RNN solutions to\nthese problems, and using these constructions, illuminate both the problems\nthemselves and the way in which RNNs store different types of information in\ntheir hidden states. These constructions furthermore explain the success of\nrecent methods that specify unitary initializations or constraints on the\ntransition matrices. \n\n"}
{"id": "1602.07857", "contents": "Title: Modeling cumulative biological phenomena with Suppes-Bayes Causal\n  Networks Abstract: Several diseases related to cell proliferation are characterized by the\naccumulation of somatic DNA changes, with respect to wildtype conditions.\nCancer and HIV are two common examples of such diseases, where the mutational\nload in the cancerous/viral population increases over time. In these cases,\nselective pressures are often observed along with competition, cooperation and\nparasitism among distinct cellular clones. Recently, we presented a\nmathematical framework to model these phenomena, based on a combination of\nBayesian inference and Suppes' theory of probabilistic causation, depicted in\ngraphical structures dubbed Suppes-Bayes Causal Networks (SBCNs). SBCNs are\ngenerative probabilistic graphical models that recapitulate the potential\nordering of accumulation of such DNA changes during the progression of the\ndisease. Such models can be inferred from data by exploiting likelihood-based\nmodel-selection strategies with regularization. In this paper we discuss the\ntheoretical foundations of our approach and we investigate in depth the\ninfluence on the model-selection task of: (i) the poset based on Suppes' theory\nand (ii) different regularization strategies. Furthermore, we provide an\nexample of application of our framework to HIV genetic data highlighting the\nvaluable insights provided by the inferred. \n\n"}
{"id": "1602.08007", "contents": "Title: Practical Riemannian Neural Networks Abstract: We provide the first experimental results on non-synthetic datasets for the\nquasi-diagonal Riemannian gradient descents for neural networks introduced in\n[Ollivier, 2015]. These include the MNIST, SVHN, and FACE datasets as well as a\npreviously unpublished electroencephalogram dataset. The quasi-diagonal\nRiemannian algorithms consistently beat simple stochastic gradient gradient\ndescents by a varying margin. The computational overhead with respect to simple\nbackpropagation is around a factor $2$. Perhaps more interestingly, these\nmethods also reach their final performance quickly, thus requiring fewer\ntraining epochs and a smaller total computation time.\n  We also present an implementation guide to these Riemannian gradient descents\nfor neural networks, showing how the quasi-diagonal versions can be implemented\nwith minimal effort on top of existing routines which compute gradients. \n\n"}
{"id": "1603.00223", "contents": "Title: Segmental Recurrent Neural Networks for End-to-end Speech Recognition Abstract: We study the segmental recurrent neural network for end-to-end acoustic\nmodelling. This model connects the segmental conditional random field (CRF)\nwith a recurrent neural network (RNN) used for feature extraction. Compared to\nmost previous CRF-based acoustic models, it does not rely on an external system\nto provide features or segmentation boundaries. Instead, this model\nmarginalises out all the possible segmentations, and features are extracted\nfrom the RNN trained together with the segmental CRF. In essence, this model is\nself-contained and can be trained end-to-end. In this paper, we discuss\npractical training and decoding issues as well as the method to speed up the\ntraining in the context of speech recognition. We performed experiments on the\nTIMIT dataset. We achieved 17.3 phone error rate (PER) from the first-pass\ndecoding --- the best reported result using CRFs, despite the fact that we only\nused a zeroth-order CRF and without using any language model. \n\n"}
{"id": "1603.00748", "contents": "Title: Continuous Deep Q-Learning with Model-based Acceleration Abstract: Model-free reinforcement learning has been successfully applied to a range of\nchallenging problems, and has recently been extended to handle large neural\nnetwork policies and value functions. However, the sample complexity of\nmodel-free algorithms, particularly when using high-dimensional function\napproximators, tends to limit their applicability to physical systems. In this\npaper, we explore algorithms and representations to reduce the sample\ncomplexity of deep reinforcement learning for continuous control tasks. We\npropose two complementary techniques for improving the efficiency of such\nalgorithms. First, we derive a continuous variant of the Q-learning algorithm,\nwhich we call normalized adantage functions (NAF), as an alternative to the\nmore commonly used policy gradient and actor-critic methods. NAF representation\nallows us to apply Q-learning with experience replay to continuous tasks, and\nsubstantially improves performance on a set of simulated robotic control tasks.\nTo further improve the efficiency of our approach, we explore the use of\nlearned models for accelerating model-free reinforcement learning. We show that\niteratively refitted local linear models are especially effective for this, and\ndemonstrate substantially faster learning on domains where such models are\napplicable. \n\n"}
{"id": "1603.02185", "contents": "Title: Distributed Multi-Task Learning with Shared Representation Abstract: We study the problem of distributed multi-task learning with shared\nrepresentation, where each machine aims to learn a separate, but related, task\nin an unknown shared low-dimensional subspaces, i.e. when the predictor matrix\nhas low rank. We consider a setting where each task is handled by a different\nmachine, with samples for the task available locally on the machine, and study\ncommunication-efficient methods for exploiting the shared structure. \n\n"}
{"id": "1603.02752", "contents": "Title: Best-of-K Bandits Abstract: This paper studies the Best-of-K Bandit game: At each time the player chooses\na subset S among all N-choose-K possible options and observes reward max(X(i) :\ni in S) where X is a random vector drawn from a joint distribution. The\nobjective is to identify the subset that achieves the highest expected reward\nwith high probability using as few queries as possible. We present\ndistribution-dependent lower bounds based on a particular construction which\nforce a learner to consider all N-choose-K subsets, and match naive extensions\nof known upper bounds in the bandit setting obtained by treating each subset as\na separate arm. Nevertheless, we present evidence that exhaustive search may be\navoided for certain, favorable distributions because the influence of\nhigh-order order correlations may be dominated by lower order statistics.\nFinally, we present an algorithm and analysis for independent arms, which\nmitigates the surprising non-trivial information occlusion that occurs due to\nonly observing the max in the subset. This may inform strategies for more\ngeneral dependent measures, and we complement these result with independent-arm\nlower bounds. \n\n"}
{"id": "1603.04119", "contents": "Title: Exploratory Gradient Boosting for Reinforcement Learning in Complex\n  Domains Abstract: High-dimensional observations and complex real-world dynamics present major\nchallenges in reinforcement learning for both function approximation and\nexploration. We address both of these challenges with two complementary\ntechniques: First, we develop a gradient-boosting style, non-parametric\nfunction approximator for learning on $Q$-function residuals. And second, we\npropose an exploration strategy inspired by the principles of state abstraction\nand information acquisition under uncertainty. We demonstrate the empirical\neffectiveness of these techniques, first, as a preliminary check, on two\nstandard tasks (Blackjack and $n$-Chain), and then on two much larger and more\nrealistic tasks with high-dimensional observation spaces. Specifically, we\nintroduce two benchmarks built within the game Minecraft where the observations\nare pixel arrays of the agent's visual field. A combination of our two\nalgorithmic techniques performs competitively on the standard\nreinforcement-learning tasks while consistently and substantially outperforming\nbaselines on the two tasks with high-dimensional observation spaces. The new\nfunction approximator, exploration strategy, and evaluation benchmarks are each\nof independent interest in the pursuit of reinforcement-learning methods that\nscale to real-world domains. \n\n"}
{"id": "1603.05642", "contents": "Title: Optimal Black-Box Reductions Between Optimization Objectives Abstract: The diverse world of machine learning applications has given rise to a\nplethora of algorithms and optimization methods, finely tuned to the specific\nregression or classification task at hand. We reduce the complexity of\nalgorithm design for machine learning by reductions: we develop reductions that\ntake a method developed for one setting and apply it to the entire spectrum of\nsmoothness and strong-convexity in applications.\n  Furthermore, unlike existing results, our new reductions are OPTIMAL and more\nPRACTICAL. We show how these new reductions give rise to new and faster running\ntimes on training linear classifiers for various families of loss functions,\nand conclude with experiments showing their successes also in practice. \n\n"}
{"id": "1603.06147", "contents": "Title: A Character-Level Decoder without Explicit Segmentation for Neural\n  Machine Translation Abstract: The existing machine translation systems, whether phrase-based or neural,\nhave relied almost exclusively on word-level modelling with explicit\nsegmentation. In this paper, we ask a fundamental question: can neural machine\ntranslation generate a character sequence without any explicit segmentation? To\nanswer this question, we evaluate an attention-based encoder-decoder with a\nsubword-level encoder and a character-level decoder on four language\npairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15.\nOur experiments show that the models with a character-level decoder outperform\nthe ones with a subword-level decoder on all of the four language pairs.\nFurthermore, the ensembles of neural models with a character-level decoder\noutperform the state-of-the-art non-neural machine translation systems on\nEn-Cs, En-De and En-Fi and perform comparably on En-Ru. \n\n"}
{"id": "1603.06653", "contents": "Title: Information Theoretic-Learning Auto-Encoder Abstract: We propose Information Theoretic-Learning (ITL) divergence measures for\nvariational regularization of neural networks. We also explore ITL-regularized\nautoencoders as an alternative to variational autoencoding bayes, adversarial\nautoencoders and generative adversarial networks for randomly generating sample\ndata without explicitly defining a partition function. This paper also\nformalizes, generative moment matching networks under the ITL framework. \n\n"}
{"id": "1603.08561", "contents": "Title: Shuffle and Learn: Unsupervised Learning using Temporal Order\n  Verification Abstract: In this paper, we present an approach for learning a visual representation\nfrom the raw spatiotemporal signals in videos. Our representation is learned\nwithout supervision from semantic labels. We formulate our method as an\nunsupervised sequential verification task, i.e., we determine whether a\nsequence of frames from a video is in the correct temporal order. With this\nsimple task and no semantic labels, we learn a powerful visual representation\nusing a Convolutional Neural Network (CNN). The representation contains\ncomplementary information to that learned from supervised image datasets like\nImageNet. Qualitative results show that our method captures information that is\ntemporally varying, such as human pose. When used as pre-training for action\nrecognition, our method gives significant gains over learning without external\ndata on benchmark datasets like UCF101 and HMDB51. To demonstrate its\nsensitivity to human pose, we show results for pose estimation on the FLIC and\nMPII datasets that are competitive, or better than approaches using\nsignificantly more supervision. Our method can be combined with supervised\nrepresentations to provide an additional boost in accuracy. \n\n"}
{"id": "1603.08988", "contents": "Title: Towards Practical Bayesian Parameter and State Estimation Abstract: Joint state and parameter estimation is a core problem for dynamic Bayesian\nnetworks. Although modern probabilistic inference toolkits make it relatively\neasy to specify large and practically relevant probabilistic models, the silver\nbullet---an efficient and general online inference algorithm for such\nproblems---remains elusive, forcing users to write special-purpose code for\neach application. We propose a novel blackbox algorithm -- a hybrid of particle\nfiltering for state variables and assumed density filtering for parameter\nvariables. It has following advantages: (a) it is efficient due to its online\nnature, and (b) it is applicable to both discrete and continuous parameter\nspaces . On a variety of toy and real models, our system is able to generate\nmore accurate results within a fixed computation budget. This preliminary\nevidence indicates that the proposed approach is likely to be of practical use. \n\n"}
{"id": "1603.09382", "contents": "Title: Deep Networks with Stochastic Depth Abstract: Very deep convolutional networks with hundreds of layers have led to\nsignificant reductions in error on competitive benchmarks. Although the\nunmatched expressiveness of the many layers can be highly desirable at test\ntime, training very deep networks comes with its own set of challenges. The\ngradients can vanish, the forward flow often diminishes, and the training time\ncan be painfully slow. To address these problems, we propose stochastic depth,\na training procedure that enables the seemingly contradictory setup to train\nshort networks and use deep networks at test time. We start with very deep\nnetworks but during training, for each mini-batch, randomly drop a subset of\nlayers and bypass them with the identity function. This simple approach\ncomplements the recent success of residual networks. It reduces training time\nsubstantially and improves the test error significantly on almost all data sets\nthat we used for evaluation. With stochastic depth we can increase the depth of\nresidual networks even beyond 1200 layers and still yield meaningful\nimprovements in test error (4.91% on CIFAR-10). \n\n"}
{"id": "1604.01785", "contents": "Title: Safe Probability Abstract: We formalize the idea of probability distributions that lead to reliable\npredictions about some, but not all aspects of a domain. The resulting notion\nof `safety' provides a fresh perspective on foundational issues in statistics,\nproviding a middle ground between imprecise probability and multiple-prior\nmodels on the one hand and strictly Bayesian approaches on the other. It also\nallows us to formalize fiducial distributions in terms of the set of random\nvariables that they can safely predict, thus taking some of the sting out of\nthe fiducial idea. By restricting probabilistic inference to safe uses, one\nalso automatically avoids paradoxes such as the Monty Hall problem. Safety\ncomes in a variety of degrees, such as \"validity\" (the strongest notion),\n\"calibration\", \"confidence safety\" and \"unbiasedness\" (almost the weakest\nnotion). \n\n"}
{"id": "1604.02492", "contents": "Title: Challenges in Bayesian Adaptive Data Analysis Abstract: Traditional statistical analysis requires that the analysis process and data\nare independent. By contrast, the new field of adaptive data analysis hopes to\nunderstand and provide algorithms and accuracy guarantees for research as it is\ncommonly performed in practice, as an iterative process of interacting\nrepeatedly with the same data set, such as repeated tests against a holdout\nset. Previous work has defined a model with a rather strong lower bound on\nsample complexity in terms of the number of queries, $n\\sim\\sqrt q$, arguing\nthat adaptive data analysis is much harder than static data analysis, where\n$n\\sim\\log q$ is possible. Instead, we argue that those strong lower bounds\npoint to a limitation of the previous model in that it must consider wildly\nasymmetric scenarios which do not hold in typical applications.\n  To better understand other difficulties of adaptivity, we propose a new\nBayesian version of the problem that mandates symmetry. Since the other lower\nbound techniques are ruled out, we can more effectively see difficulties that\nmight otherwise be overshadowed. As a first contribution to this model, we\nproduce a new problem using error-correcting codes on which a large family of\nmethods, including all previously proposed algorithms, require roughly\n$n\\sim\\sqrt[4]q$. These early results illustrate new difficulties in adaptive\ndata analysis regarding slightly correlated queries on problems with\nconcentrated uncertainty. \n\n"}
{"id": "1604.05091", "contents": "Title: End-to-End Tracking and Semantic Segmentation Using Recurrent Neural\n  Networks Abstract: In this work we present a novel end-to-end framework for tracking and\nclassifying a robot's surroundings in complex, dynamic and only partially\nobservable real-world environments. The approach deploys a recurrent neural\nnetwork to filter an input stream of raw laser measurements in order to\ndirectly infer object locations, along with their identity in both visible and\noccluded areas. To achieve this we first train the network using unsupervised\nDeep Tracking, a recently proposed theoretical framework for end-to-end space\noccupancy prediction. We show that by learning to track on a large amount of\nunsupervised data, the network creates a rich internal representation of its\nenvironment which we in turn exploit through the principle of inductive\ntransfer of knowledge to perform the task of it's semantic classification. As a\nresult, we show that only a small amount of labelled data suffices to steer the\nnetwork towards mastering this additional task. Furthermore we propose a novel\nrecurrent neural network architecture specifically tailored to tracking and\nsemantic classification in real-world robotics applications. We demonstrate the\ntracking and classification performance of the method on real-world data\ncollected at a busy road junction. Our evaluation shows that the proposed\nend-to-end framework compares favourably to a state-of-the-art, model-free\ntracking solution and that it outperforms a conventional one-shot training\nscheme for semantic classification. \n\n"}
{"id": "1604.06635", "contents": "Title: Bridging LSTM Architecture and the Neural Dynamics during Reading Abstract: Recently, the long short-term memory neural network (LSTM) has attracted wide\ninterest due to its success in many tasks. LSTM architecture consists of a\nmemory cell and three gates, which looks similar to the neuronal networks in\nthe brain. However, there still lacks the evidence of the cognitive\nplausibility of LSTM architecture as well as its working mechanism. In this\npaper, we study the cognitive plausibility of LSTM by aligning its internal\narchitecture with the brain activity observed via fMRI when the subjects read a\nstory. Experiment results show that the artificial memory vector in LSTM can\naccurately predict the observed sequential brain activities, indicating the\ncorrelation between LSTM architecture and the cognitive process of story\nreading. \n\n"}
{"id": "1605.01335", "contents": "Title: Learning from the memory of Atari 2600 Abstract: We train a number of neural networks to play games Bowling, Breakout and\nSeaquest using information stored in the memory of a video game console Atari\n2600. We consider four models of neural networks which differ in size and\narchitecture: two networks which use only information contained in the RAM and\ntwo mixed networks which use both information in the RAM and information from\nthe screen. As the benchmark we used the convolutional model proposed in NIPS\nand received comparable results in all considered games. Quite surprisingly, in\nthe case of Seaquest we were able to train RAM-only agents which behave better\nthan the benchmark screen-only agent. Mixing screen and RAM did not lead to an\nimproved performance comparing to screen-only and RAM-only agents. \n\n"}
{"id": "1605.04465", "contents": "Title: Monotone Retargeting for Unsupervised Rank Aggregation with Object\n  Features Abstract: Learning the true ordering between objects by aggregating a set of expert\nopinion rank order lists is an important and ubiquitous problem in many\napplications ranging from social choice theory to natural language processing\nand search aggregation. We study the problem of unsupervised rank aggregation\nwhere no ground truth ordering information in available, neither about the true\npreference ordering between any set of objects nor about the quality of\nindividual rank lists. Aggregating the often inconsistent and poor quality rank\nlists in such an unsupervised manner is a highly challenging problem, and\nstandard consensus-based methods are often ill-defined, and difficult to solve.\nIn this manuscript we propose a novel framework to bypass these issues by using\nobject attributes to augment the standard rank aggregation framework. We design\nalgorithms that learn joint models on both rank lists and object features to\nobtain an aggregated rank ordering that is more accurate and robust, and also\nhelps weed out rank lists of dubious validity. We validate our techniques on\nsynthetic datasets where our algorithm is able to estimate the true rank\nordering even when the rank lists are corrupted. Experiments on three real\ndatasets, MQ2008, MQ2008 and OHSUMED, show that using object features can\nresult in significant improvement in performance over existing rank aggregation\nmethods that do not use object information. Furthermore, when at least some of\nthe rank lists are of high quality, our methods are able to effectively exploit\ntheir high expertise to output an aggregated rank ordering of great accuracy. \n\n"}
{"id": "1605.05223", "contents": "Title: On the boosting ability of top-down decision tree learning algorithm for\n  multiclass classification Abstract: We analyze the performance of the top-down multiclass classification\nalgorithm for decision tree learning called LOMtree, recently proposed in the\nliterature Choromanska and Langford (2014) for solving efficiently\nclassification problems with very large number of classes. The algorithm online\noptimizes the objective function which simultaneously controls the depth of the\ntree and its statistical accuracy. We prove important properties of this\nobjective and explore its connection to three well-known entropy-based decision\ntree objectives, i.e. Shannon entropy, Gini-entropy and its modified version,\nfor which instead online optimization schemes were not yet developed. We show,\nvia boosting-type guarantees, that maximizing the considered objective leads\nalso to the reduction of all of these entropy-based objectives. The bounds we\nobtain critically depend on the strong-concavity properties of the\nentropy-based criteria, where the mildest dependence on the number of classes\n(only logarithmic) corresponds to the Shannon entropy. \n\n"}
{"id": "1605.06619", "contents": "Title: Make Workers Work Harder: Decoupled Asynchronous Proximal Stochastic\n  Gradient Descent Abstract: Asynchronous parallel optimization algorithms for solving large-scale machine\nlearning problems have drawn significant attention from academia to industry\nrecently. This paper proposes a novel algorithm, decoupled asynchronous\nproximal stochastic gradient descent (DAP-SGD), to minimize an objective\nfunction that is the composite of the average of multiple empirical losses and\na regularization term. Unlike the traditional asynchronous proximal stochastic\ngradient descent (TAP-SGD) in which the master carries much of the computation\nload, the proposed algorithm off-loads the majority of computation tasks from\nthe master to workers, and leaves the master to conduct simple addition\noperations. This strategy yields an easy-to-parallelize algorithm, whose\nperformance is justified by theoretical convergence analyses. To be specific,\nDAP-SGD achieves an $O(\\log T/T)$ rate when the step-size is diminishing and an\nergodic $O(1/\\sqrt{T})$ rate when the step-size is constant, where $T$ is the\nnumber of total iterations. \n\n"}
{"id": "1605.06636", "contents": "Title: Deep Transfer Learning with Joint Adaptation Networks Abstract: Deep networks have been successfully applied to learn transferable features\nfor adapting models from a source domain to a different target domain. In this\npaper, we present joint adaptation networks (JAN), which learn a transfer\nnetwork by aligning the joint distributions of multiple domain-specific layers\nacross domains based on a joint maximum mean discrepancy (JMMD) criterion.\nAdversarial training strategy is adopted to maximize JMMD such that the\ndistributions of the source and target domains are made more distinguishable.\nLearning can be performed by stochastic gradient descent with the gradients\ncomputed by back-propagation in linear-time. Experiments testify that our model\nyields state of the art results on standard datasets. \n\n"}
{"id": "1605.06855", "contents": "Title: Smart broadcasting: Do you want to be seen? Abstract: Many users in online social networks are constantly trying to gain attention\nfrom their followers by broadcasting posts to them. These broadcasters are\nlikely to gain greater attention if their posts can remain visible for a longer\nperiod of time among their followers' most recent feeds. Then when to post? In\nthis paper, we study the problem of smart broadcasting using the framework of\ntemporal point processes, where we model users feeds and posts as discrete\nevents occurring in continuous time. Based on such continuous-time model, then\nchoosing a broadcasting strategy for a user becomes a problem of designing the\nconditional intensity of her posting events. We derive a novel formula which\nlinks this conditional intensity with the visibility of the user in her\nfollowers' feeds. Furthermore, by exploiting this formula, we develop an\nefficient convex optimization framework for the when-to-post problem. Our\nmethod can find broadcasting strategies that reach a desired visibility level\nwith provable guarantees. We experimented with data gathered from Twitter, and\nshow that our framework can consistently make broadcasters' post more visible\nthan alternatives. \n\n"}
{"id": "1605.07057", "contents": "Title: Bayesian Model Selection of Stochastic Block Models Abstract: A central problem in analyzing networks is partitioning them into modules or\ncommunities. One of the best tools for this is the stochastic block model,\nwhich clusters vertices into blocks with statistically homogeneous pattern of\nlinks. Despite its flexibility and popularity, there has been a lack of\nprincipled statistical model selection criteria for the stochastic block model.\nHere we propose a Bayesian framework for choosing the number of blocks as well\nas comparing it to the more elaborate degree- corrected block models,\nultimately leading to a universal model selection framework capable of\ncomparing multiple modeling combinations. We will also investigate its\nconnection to the minimum description length principle. \n\n"}
{"id": "1605.07157", "contents": "Title: Unsupervised Learning for Physical Interaction through Video Prediction Abstract: A core challenge for an agent learning to interact with the world is to\npredict how its actions affect objects in its environment. Many existing\nmethods for learning the dynamics of physical interactions require labeled\nobject information. However, to scale real-world interaction learning to a\nvariety of scenes and objects, acquiring labeled data becomes increasingly\nimpractical. To learn about physical object motion without labels, we develop\nan action-conditioned video prediction model that explicitly models pixel\nmotion, by predicting a distribution over pixel motion from previous frames.\nBecause our model explicitly predicts motion, it is partially invariant to\nobject appearance, enabling it to generalize to previously unseen objects. To\nexplore video prediction for real-world interactive agents, we also introduce a\ndataset of 59,000 robot interactions involving pushing motions, including a\ntest set with novel objects. In this dataset, accurate prediction of videos\nconditioned on the robot's future actions amounts to learning a \"visual\nimagination\" of different futures based on different courses of action. Our\nexperiments show that our proposed method produces more accurate video\npredictions both quantitatively and qualitatively, when compared to prior\nmethods. \n\n"}
{"id": "1605.07571", "contents": "Title: Sequential Neural Models with Stochastic Layers Abstract: How can we efficiently propagate uncertainty in a latent state representation\nwith recurrent neural networks? This paper introduces stochastic recurrent\nneural networks which glue a deterministic recurrent neural network and a state\nspace model together to form a stochastic and sequential neural generative\nmodel. The clear separation of deterministic and stochastic layers allows a\nstructured variational inference network to track the factorization of the\nmodel's posterior distribution. By retaining both the nonlinear recursive\nstructure of a recurrent neural network and averaging over the uncertainty in a\nlatent path, like a state space model, we improve the state of the art results\non the Blizzard and TIMIT speech modeling data sets by a large margin, while\nachieving comparable performances to competing methods on polyphonic music\nmodeling. \n\n"}
{"id": "1605.07717", "contents": "Title: Deep Structured Energy Based Models for Anomaly Detection Abstract: In this paper, we attack the anomaly detection problem by directly modeling\nthe data distribution with deep architectures. We propose deep structured\nenergy based models (DSEBMs), where the energy function is the output of a\ndeterministic deep neural network with structure. We develop novel model\narchitectures to integrate EBMs with different types of data such as static\ndata, sequential data, and spatial data, and apply appropriate model\narchitectures to adapt to the data structure. Our training algorithm is built\nupon the recent development of score matching \\cite{sm}, which connects an EBM\nwith a regularized autoencoder, eliminating the need for complicated sampling\nmethod. Statistically sound decision criterion can be derived for anomaly\ndetection purpose from the perspective of the energy landscape of the data\ndistribution. We investigate two decision criteria for performing anomaly\ndetection: the energy score and the reconstruction error. Extensive empirical\nstudies on benchmark tasks demonstrate that our proposed model consistently\nmatches or outperforms all the competing methods. \n\n"}
{"id": "1605.08283", "contents": "Title: Discrete Deep Feature Extraction: A Theory and New Architectures Abstract: First steps towards a mathematical theory of deep convolutional neural\nnetworks for feature extraction were made---for the continuous-time case---in\nMallat, 2012, and Wiatowski and B\\\"olcskei, 2015. This paper considers the\ndiscrete case, introduces new convolutional neural network architectures, and\nproposes a mathematical framework for their analysis. Specifically, we\nestablish deformation and translation sensitivity results of local and global\nnature, and we investigate how certain structural properties of the input\nsignal are reflected in the corresponding feature vectors. Our theory applies\nto general filters and general Lipschitz-continuous non-linearities and pooling\noperators. Experiments on handwritten digit classification and facial landmark\ndetection---including feature importance evaluation---complement the\ntheoretical findings. \n\n"}
{"id": "1605.09080", "contents": "Title: Spectral Methods for Correlated Topic Models Abstract: In this paper, we propose guaranteed spectral methods for learning a broad\nrange of topic models, which generalize the popular Latent Dirichlet Allocation\n(LDA). We overcome the limitation of LDA to incorporate arbitrary topic\ncorrelations, by assuming that the hidden topic proportions are drawn from a\nflexible class of Normalized Infinitely Divisible (NID) distributions. NID\ndistributions are generated through the process of normalizing a family of\nindependent Infinitely Divisible (ID) random variables. The Dirichlet\ndistribution is a special case obtained by normalizing a set of Gamma random\nvariables. We prove that this flexible topic model class can be learned via\nspectral methods using only moments up to the third order, with (low order)\npolynomial sample and computational complexity. The proof is based on a key new\ntechnique derived here that allows us to diagonalize the moments of the NID\ndistribution through an efficient procedure that requires evaluating only\nunivariate integrals, despite the fact that we are handling high dimensional\nmultivariate moments. In order to assess the performance of our proposed Latent\nNID topic model, we use two real datasets of articles collected from New York\nTimes and Pubmed. Our experiments yield improved perplexity on both datasets\ncompared with the baseline. \n\n"}
{"id": "1606.00776", "contents": "Title: Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation Abstract: We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure. \n\n"}
{"id": "1606.01190", "contents": "Title: Distributed stochastic optimization via matrix exponential learning Abstract: In this paper, we investigate a distributed learning scheme for a broad class\nof stochastic optimization problems and games that arise in signal processing\nand wireless communications. The proposed algorithm relies on the method of\nmatrix exponential learning (MXL) and only requires locally computable gradient\nobservations that are possibly imperfect and/or obsolete. To analyze it, we\nintroduce the notion of a stable Nash equilibrium and we show that the\nalgorithm is globally convergent to such equilibria - or locally convergent\nwhen an equilibrium is only locally stable. We also derive an explicit linear\nbound for the algorithm's convergence speed, which remains valid under\nmeasurement errors and uncertainty of arbitrarily high variance. To validate\nour theoretical analysis, we test the algorithm in realistic\nmulti-carrier/multiple-antenna wireless scenarios where several users seek to\nmaximize their energy efficiency. Our results show that learning allows users\nto attain a net increase between 100% and 500% in energy efficiency, even under\nvery high uncertainty. \n\n"}
{"id": "1606.01868", "contents": "Title: Unifying Count-Based Exploration and Intrinsic Motivation Abstract: We consider an agent's uncertainty about its environment and the problem of\ngeneralizing this uncertainty across observations. Specifically, we focus on\nthe problem of exploration in non-tabular reinforcement learning. Drawing\ninspiration from the intrinsic motivation literature, we use density models to\nmeasure uncertainty, and propose a novel algorithm for deriving a pseudo-count\nfrom an arbitrary density model. This technique enables us to generalize\ncount-based exploration algorithms to the non-tabular case. We apply our ideas\nto Atari 2600 games, providing sensible pseudo-counts from raw pixels. We\ntransform these pseudo-counts into intrinsic rewards and obtain significantly\nimproved exploration in a number of hard games, including the infamously\ndifficult Montezuma's Revenge. \n\n"}
{"id": "1606.02404", "contents": "Title: Clustering with Same-Cluster Queries Abstract: We propose a framework for Semi-Supervised Active Clustering framework\n(SSAC), where the learner is allowed to interact with a domain expert, asking\nwhether two given instances belong to the same cluster or not. We study the\nquery and computational complexity of clustering in this framework. We consider\na setting where the expert conforms to a center-based clustering with a notion\nof margin. We show that there is a trade off between computational complexity\nand query complexity; We prove that for the case of $k$-means clustering (i.e.,\nwhen the expert conforms to a solution of $k$-means), having access to\nrelatively few such queries allows efficient solutions to otherwise NP hard\nproblems.\n  In particular, we provide a probabilistic polynomial-time (BPP) algorithm for\nclustering in this setting that asks $O\\big(k^2\\log k + k\\log n)$ same-cluster\nqueries and runs with time complexity $O\\big(kn\\log n)$ (where $k$ is the\nnumber of clusters and $n$ is the number of instances). The algorithm succeeds\nwith high probability for data satisfying margin conditions under which,\nwithout queries, we show that the problem is NP hard. We also prove a lower\nbound on the number of queries needed to have a computationally efficient\nclustering algorithm in this setting. \n\n"}
{"id": "1606.02838", "contents": "Title: Sketching for Large-Scale Learning of Mixture Models Abstract: Learning parameters from voluminous data can be prohibitive in terms of\nmemory and computational requirements. We propose a \"compressive learning\"\nframework where we estimate model parameters from a sketch of the training\ndata. This sketch is a collection of generalized moments of the underlying\nprobability distribution of the data. It can be computed in a single pass on\nthe training set, and is easily computable on streams or distributed datasets.\nThe proposed framework shares similarities with compressive sensing, which aims\nat drastically reducing the dimension of high-dimensional signals while\npreserving the ability to reconstruct them. To perform the estimation task, we\nderive an iterative algorithm analogous to sparse reconstruction algorithms in\nthe context of linear inverse problems. We exemplify our framework with the\ncompressive estimation of a Gaussian Mixture Model (GMM), providing heuristics\non the choice of the sketching procedure and theoretical guarantees of\nreconstruction. We experimentally show on synthetic data that the proposed\nalgorithm yields results comparable to the classical Expectation-Maximization\n(EM) technique while requiring significantly less memory and fewer computations\nwhen the number of database elements is large. We further demonstrate the\npotential of the approach on real large-scale data (over 10 8 training samples)\nfor the task of model-based speaker verification. Finally, we draw some\nconnections between the proposed framework and approximate Hilbert space\nembedding of probability distributions using random features. We show that the\nproposed sketching operator can be seen as an innovative method to design\ntranslation-invariant kernels adapted to the analysis of GMMs. We also use this\ntheoretical framework to derive information preservation guarantees, in the\nspirit of infinite-dimensional compressive sensing. \n\n"}
{"id": "1606.03667", "contents": "Title: Deep Reinforcement Learning with a Combinatorial Action Space for\n  Predicting Popular Reddit Threads Abstract: We introduce an online popularity prediction and tracking task as a benchmark\ntask for reinforcement learning with a combinatorial, natural language action\nspace. A specified number of discussion threads predicted to be popular are\nrecommended, chosen from a fixed window of recent comments to track. Novel deep\nreinforcement learning architectures are studied for effective modeling of the\nvalue function associated with actions comprised of interdependent sub-actions.\nThe proposed model, which represents dependence between sub-actions through a\nbi-directional LSTM, gives the best performance across different experimental\nconfigurations and domains, and it also generalizes well with varying numbers\nof recommendation requests. \n\n"}
{"id": "1606.03841", "contents": "Title: Efficient Learning with a Family of Nonconvex Regularizers by\n  Redistributing Nonconvexity Abstract: The use of convex regularizers allows for easy optimization, though they\noften produce biased estimation and inferior prediction performance. Recently,\nnonconvex regularizers have attracted a lot of attention and outperformed\nconvex ones. However, the resultant optimization problem is much harder. In\nthis paper, for a large class of nonconvex regularizers, we propose to move the\nnonconvexity from the regularizer to the loss. The nonconvex regularizer is\nthen transformed to a familiar convex regularizer, while the resultant loss\nfunction can still be guaranteed to be smooth. Learning with the convexified\nregularizer can be performed by existing efficient algorithms originally\ndesigned for convex regularizers (such as the proximal algorithm, Frank-Wolfe\nalgorithm, alternating direction method of multipliers and stochastic gradient\ndescent). Extensions are made when the convexified regularizer does not have\nclosed-form proximal step, and when the loss function is nonconvex, nonsmooth.\nExtensive experiments on a variety of machine learning application scenarios\nshow that optimizing the transformed problem is much faster than running the\nstate-of-the-art on the original problem. \n\n"}
{"id": "1606.03864", "contents": "Title: Neural Associative Memory for Dual-Sequence Modeling Abstract: Many important NLP problems can be posed as dual-sequence or\nsequence-to-sequence modeling tasks. Recent advances in building end-to-end\nneural architectures have been highly successful in solving such tasks. In this\nwork we propose a new architecture for dual-sequence modeling that is based on\nassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)\nwhich augments generic recurrent neural networks (RNN). This architecture is\nextended to the Dual AM-RNN which operates on two AMs at once. Our models\nachieve very competitive results on textual entailment. A qualitative analysis\ndemonstrates that long range dependencies between source and target-sequence\ncan be bridged effectively using Dual AM-RNNs. However, an initial experiment\non auto-encoding reveals that these benefits are not exploited by the system\nwhen learning to solve sequence-to-sequence tasks which indicates that\nadditional supervision or regularization is needed. \n\n"}
{"id": "1606.03966", "contents": "Title: Making Contextual Decisions with Low Technical Debt Abstract: Applications and systems are constantly faced with decisions that require\npicking from a set of actions based on contextual information.\nReinforcement-based learning algorithms such as contextual bandits can be very\neffective in these settings, but applying them in practice is fraught with\ntechnical debt, and no general system exists that supports them completely. We\naddress this and create the first general system for contextual learning,\ncalled the Decision Service.\n  Existing systems often suffer from technical debt that arises from issues\nlike incorrect data collection and weak debuggability, issues we systematically\naddress through our ML methodology and system abstractions. The Decision\nService enables all aspects of contextual bandit learning using four system\nabstractions which connect together in a loop: explore (the decision space),\nlog, learn, and deploy. Notably, our new explore and log abstractions ensure\nthe system produces correct, unbiased data, which our learner uses for online\nlearning and to enable real-time safeguards, all in a fully reproducible\nmanner.\n  The Decision Service has a simple user interface and works with a variety of\napplications: we present two live production deployments for content\nrecommendation that achieved click-through improvements of 25-30%, another with\n18% revenue lift in the landing page, and ongoing applications in tech support\nand machine failure handling. The service makes real-time decisions and learns\ncontinuously and scalably, while significantly lowering technical debt. \n\n"}
{"id": "1606.03976", "contents": "Title: Estimating individual treatment effect: generalization bounds and\n  algorithms Abstract: There is intense interest in applying machine learning to problems of causal\ninference in fields such as healthcare, economics and education. In particular,\nindividual-level causal inference has important applications such as precision\nmedicine. We give a new theoretical analysis and family of algorithms for\npredicting individual treatment effect (ITE) from observational data, under the\nassumption known as strong ignorability. The algorithms learn a \"balanced\"\nrepresentation such that the induced treated and control distributions look\nsimilar. We give a novel, simple and intuitive generalization-error bound\nshowing that the expected ITE estimation error of a representation is bounded\nby a sum of the standard generalization-error of that representation and the\ndistance between the treated and control distributions induced by the\nrepresentation. We use Integral Probability Metrics to measure distances\nbetween distributions, deriving explicit bounds for the Wasserstein and Maximum\nMean Discrepancy (MMD) distances. Experiments on real and simulated data show\nthe new algorithms match or outperform the state-of-the-art. \n\n"}
{"id": "1606.04130", "contents": "Title: Modeling Missing Data in Clinical Time Series with RNNs Abstract: We demonstrate a simple strategy to cope with missing data in sequential\ninputs, addressing the task of multilabel classification of diagnoses given\nclinical time series. Collected from the pediatric intensive care unit (PICU)\nat Children's Hospital Los Angeles, our data consists of multivariate time\nseries of observations. The measurements are irregularly spaced, leading to\nmissingness patterns in temporally discretized sequences. While these artifacts\nare typically handled by imputation, we achieve superior predictive performance\nby treating the artifacts as features. Unlike linear models, recurrent neural\nnetworks can realize this improvement using only simple binary indicators of\nmissingness. For linear models, we show an alternative strategy to capture this\nsignal. Training models on missingness patterns only, we show that for some\ndiseases, what tests are run can be as predictive as the results themselves. \n\n"}
{"id": "1606.04934", "contents": "Title: Improving Variational Inference with Inverse Autoregressive Flow Abstract: The framework of normalizing flows provides a general strategy for flexible\nvariational inference of posteriors over latent variables. We propose a new\ntype of normalizing flow, inverse autoregressive flow (IAF), that, in contrast\nto earlier published flows, scales well to high-dimensional latent spaces. The\nproposed flow consists of a chain of invertible transformations, where each\ntransformation is based on an autoregressive neural network. In experiments, we\nshow that IAF significantly improves upon diagonal Gaussian approximate\nposteriors. In addition, we demonstrate that a novel type of variational\nautoencoder, coupled with IAF, is competitive with neural autoregressive models\nin terms of attained log-likelihood on natural images, while allowing\nsignificantly faster synthesis. \n\n"}
{"id": "1606.05228", "contents": "Title: How many faces can be recognized? Performance extrapolation for\n  multi-class classification Abstract: The difficulty of multi-class classification generally increases with the\nnumber of classes. Using data from a subset of the classes, can we predict how\nwell a classifier will scale with an increased number of classes? Under the\nassumption that the classes are sampled exchangeably, and under the assumption\nthat the classifier is generative (e.g. QDA or Naive Bayes), we show that the\nexpected accuracy when the classifier is trained on $k$ classes is the $k-1$st\nmoment of a \\emph{conditional accuracy distribution}, which can be estimated\nfrom data. This provides the theoretical foundation for performance\nextrapolation based on pseudolikelihood, unbiased estimation, and\nhigh-dimensional asymptotics. We investigate the robustness of our methods to\nnon-generative classifiers in simulations and one optical character recognition\nexample. \n\n"}
{"id": "1606.06121", "contents": "Title: Quantifying and Reducing Stereotypes in Word Embeddings Abstract: Machine learning algorithms are optimized to model statistical properties of\nthe training data. If the input data reflects stereotypes and biases of the\nbroader society, then the output of the learning algorithm also captures these\nstereotypes. In this paper, we initiate the study of gender stereotypes in {\\em\nword embedding}, a popular framework to represent text data. As their use\nbecomes increasingly common, applications can inadvertently amplify unwanted\nstereotypes. We show across multiple datasets that the embeddings contain\nsignificant gender stereotypes, especially with regard to professions. We\ncreated a novel gender analogy task and combined it with crowdsourcing to\nsystematically quantify the gender bias in a given embedding. We developed an\nefficient algorithm that reduces gender stereotype using just a handful of\ntraining examples while preserving the useful geometric properties of the\nembedding. We evaluated our algorithm on several metrics. While we focus on\nmale/female stereotypes, our framework may be applicable to other types of\nembedding biases. \n\n"}
{"id": "1606.06357", "contents": "Title: Complex Embeddings for Simple Link Prediction Abstract: In statistical relational learning, the link prediction problem is key to\nautomatically understand the structure of large knowledge bases. As in previous\nstudies, we propose to solve this problem through latent factorization.\nHowever, here we make use of complex valued embeddings. The composition of\ncomplex embeddings can handle a large variety of binary relations, among them\nsymmetric and antisymmetric relations. Compared to state-of-the-art models such\nas Neural Tensor Network and Holographic Embeddings, our approach based on\ncomplex embeddings is arguably simpler, as it only uses the Hermitian dot\nproduct, the complex counterpart of the standard dot product between real\nvectors. Our approach is scalable to large datasets as it remains linear in\nboth space and time, while consistently outperforming alternative approaches on\nstandard link prediction benchmarks. \n\n"}
{"id": "1606.06545", "contents": "Title: Geodesic Motion in the Spacetime Of a SU(2)-Colored (A)dS Black Hole in\n  Conformal Gravity Abstract: In this paper, we study the geodesic motion in the spacetime of a\nSU(2)-colored (A)dS black hole in conformal gravity, and also we investigate\nspacetime features, such as light spheres and horizons. Moreover, we derive the\nanalytical solutions for the equation of motion of test particles and light\nrays using Weierstrass elliptic and Kleinian sigma functions. Depending on the\nparticle energy levels and angular momentums, we classify the solutions of the\ngeodesic equations. Furthermore, several examples of possible types of orbits\nillustrate the results \n\n"}
{"id": "1606.07286", "contents": "Title: Importance sampling strategy for non-convex randomized block-coordinate\n  descent Abstract: As the number of samples and dimensionality of optimization problems related\nto statistics an machine learning explode, block coordinate descent algorithms\nhave gained popularity since they reduce the original problem to several\nsmaller ones. Coordinates to be optimized are usually selected randomly\naccording to a given probability distribution. We introduce an importance\nsampling strategy that helps randomized coordinate descent algorithms to focus\non blocks that are still far from convergence. The framework applies to\nproblems composed of the sum of two possibly non-convex terms, one being\nseparable and non-smooth. We have compared our algorithm to a full gradient\nproximal approach as well as to a randomized block coordinate algorithm that\nconsiders uniform sampling and cyclic block coordinate descent. Experimental\nevidences show the clear benefit of using an importance sampling strategy. \n\n"}
{"id": "1606.07659", "contents": "Title: Hybrid Recommender System based on Autoencoders Abstract: A standard model for Recommender Systems is the Matrix Completion setting:\ngiven partially known matrix of ratings given by users (rows) to items\n(columns), infer the unknown ratings. In the last decades, few attempts where\ndone to handle that objective with Neural Networks, but recently an\narchitecture based on Autoencoders proved to be a promising approach. In\ncurrent paper, we enhanced that architecture (i) by using a loss function\nadapted to input data with missing values, and (ii) by incorporating side\ninformation. The experiments demonstrate that while side information only\nslightly improve the test error averaged on all users/items, it has more impact\non cold users/items. \n\n"}
{"id": "1607.00410", "contents": "Title: Domain Adaptation for Neural Networks by Parameter Augmentation Abstract: We propose a simple domain adaptation method for neural networks in a\nsupervised setting. Supervised domain adaptation is a way of improving the\ngeneralization performance on the target domain by using the source domain\ndataset, assuming that both of the datasets are labeled. Recently, recurrent\nneural networks have been shown to be successful on a variety of NLP tasks such\nas caption generation; however, the existing domain adaptation techniques are\nlimited to (1) tune the model parameters by the target dataset after the\ntraining by the source dataset, or (2) design the network to have dual output,\none for the source domain and the other for the target domain. Reformulating\nthe idea of the domain adaptation technique proposed by Daume (2007), we\npropose a simple domain adaptation method, which can be applied to neural\nnetworks trained with a cross-entropy loss. On captioning datasets, we show\nperformance improvements over other domain adaptation methods. \n\n"}
{"id": "1607.01097", "contents": "Title: AdaNet: Adaptive Structural Learning of Artificial Neural Networks Abstract: We present new algorithms for adaptively learning artificial neural networks.\nOur algorithms (AdaNet) adaptively learn both the structure of the network and\nits weights. They are based on a solid theoretical analysis, including\ndata-dependent generalization guarantees that we prove and discuss in detail.\nWe report the results of large-scale experiments with one of our algorithms on\nseveral binary classification tasks extracted from the CIFAR-10 dataset. The\nresults demonstrate that our algorithm can automatically learn network\nstructures with very competitive performance accuracies when compared with\nthose achieved for neural networks found by standard approaches. \n\n"}
{"id": "1607.02793", "contents": "Title: On Faster Convergence of Cyclic Block Coordinate Descent-type Methods\n  for Strongly Convex Minimization Abstract: The cyclic block coordinate descent-type (CBCD-type) methods, which performs\niterative updates for a few coordinates (a block) simultaneously throughout the\nprocedure, have shown remarkable computational performance for solving strongly\nconvex minimization problems. Typical applications include many popular\nstatistical machine learning methods such as elastic-net regression, ridge\npenalized logistic regression, and sparse additive regression. Existing\noptimization literature has shown that for strongly convex minimization, the\nCBCD-type methods attain iteration complexity of\n$\\mathcal{O}(p\\log(1/\\epsilon))$, where $\\epsilon$ is a pre-specified accuracy\nof the objective value, and $p$ is the number of blocks. However, such\niteration complexity explicitly depends on $p$, and therefore is at least $p$\ntimes worse than the complexity $\\mathcal{O}(\\log(1/\\epsilon))$ of gradient\ndescent (GD) methods. To bridge this theoretical gap, we propose an improved\nconvergence analysis for the CBCD-type methods. In particular, we first show\nthat for a family of quadratic minimization problems, the iteration complexity\n$\\mathcal{O}(\\log^2(p)\\cdot\\log(1/\\epsilon))$ of the CBCD-type methods matches\nthat of the GD methods in term of dependency on $p$, up to a $\\log^2 p$ factor.\nThus our complexity bounds are sharper than the existing bounds by at least a\nfactor of $p/\\log^2(p)$. We also provide a lower bound to confirm that our\nimproved complexity bounds are tight (up to a $\\log^2 (p)$ factor), under the\nassumption that the largest and smallest eigenvalues of the Hessian matrix do\nnot scale with $p$. Finally, we generalize our analysis to other strongly\nconvex minimization problems beyond quadratic ones. \n\n"}
{"id": "1607.03516", "contents": "Title: Deep Reconstruction-Classification Networks for Unsupervised Domain\n  Adaptation Abstract: In this paper, we propose a novel unsupervised domain adaptation algorithm\nbased on deep learning for visual object recognition. Specifically, we design a\nnew model called Deep Reconstruction-Classification Network (DRCN), which\njointly learns a shared encoding representation for two tasks: i) supervised\nclassification of labeled source data, and ii) unsupervised reconstruction of\nunlabeled target data.In this way, the learnt representation not only preserves\ndiscriminability, but also encodes useful information from the target domain.\nOur new DRCN model can be optimized by using backpropagation similarly as the\nstandard neural networks.\n  We evaluate the performance of DRCN on a series of cross-domain object\nrecognition tasks, where DRCN provides a considerable improvement (up to ~8% in\naccuracy) over the prior state-of-the-art algorithms. Interestingly, we also\nobserve that the reconstruction pipeline of DRCN transforms images from the\nsource domain into images whose appearance resembles the target dataset. This\nsuggests that DRCN's performance is due to constructing a single composite\nrepresentation that encodes information about both the structure of target\nimages and the classification of source images. Finally, we provide a formal\nanalysis to justify the algorithm's objective in domain adaptation context. \n\n"}
{"id": "1607.05241", "contents": "Title: Imitation Learning with Recurrent Neural Networks Abstract: We present a novel view that unifies two frameworks that aim to solve\nsequential prediction problems: learning to search (L2S) and recurrent neural\nnetworks (RNN). We point out equivalences between elements of the two\nframeworks. By complementing what is missing from one framework comparing to\nthe other, we introduce a more advanced imitation learning framework that, on\none hand, augments L2S s notion of search space and, on the other hand,\nenhances RNNs training procedure to be more robust to compounding errors\narising from training on highly correlated examples. \n\n"}
{"id": "1607.08723", "contents": "Title: Cognitive Science in the era of Artificial Intelligence: A roadmap for\n  reverse-engineering the infant language-learner Abstract: During their first years of life, infants learn the language(s) of their\nenvironment at an amazing speed despite large cross cultural variations in\namount and complexity of the available language input. Understanding this\nsimple fact still escapes current cognitive and linguistic theories. Recently,\nspectacular progress in the engineering science, notably, machine learning and\nwearable technology, offer the promise of revolutionizing the study of\ncognitive development. Machine learning offers powerful learning algorithms\nthat can achieve human-like performance on many linguistic tasks. Wearable\nsensors can capture vast amounts of data, which enable the reconstruction of\nthe sensory experience of infants in their natural environment. The project of\n'reverse engineering' language development, i.e., of building an effective\nsystem that mimics infant's achievements appears therefore to be within reach.\nHere, we analyze the conditions under which such a project can contribute to\nour scientific understanding of early language development. We argue that\ninstead of defining a sub-problem or simplifying the data, computational models\nshould address the full complexity of the learning situation, and take as input\nthe raw sensory signals available to infants. This implies that (1) accessible\nbut privacy-preserving repositories of home data be setup and widely shared,\nand (2) models be evaluated at different linguistic levels through a benchmark\nof psycholinguist tests that can be passed by machines and humans alike, (3)\nlinguistically and psychologically plausible learning architectures be scaled\nup to real data using probabilistic/optimization principles from machine\nlearning. We discuss the feasibility of this approach and present preliminary\nresults. \n\n"}
{"id": "1608.00528", "contents": "Title: Impartial Predictive Modeling and the Use of Proxy Variables Abstract: Fairness aware data mining (FADM) aims to prevent algorithms from\ndiscriminating against protected groups. The literature has come to an impasse\nas to what constitutes explainable variability as opposed to discrimination.\nThis distinction hinges on a rigorous understanding of the role of proxy\nvariables; i.e., those variables which are associated both the protected\nfeature and the outcome of interest. We demonstrate that fairness is achieved\nby ensuring impartiality with respect to sensitive characteristics and provide\na framework for impartiality by accounting for different perspectives on the\ndata generating process. In particular, fairness can only be precisely defined\nin a full-data scenario in which all covariates are observed. We then analyze\nhow these models may be conservatively estimated via regression in partial-data\nsettings. Decomposing the regression estimates provides insights into\npreviously unexplored distinctions between explainable variability and\ndiscrimination that illuminate the use of proxy variables in fairness aware\ndata mining. \n\n"}
{"id": "1608.02582", "contents": "Title: Approximate Universal Relations for Neutron Stars and Quark Stars Abstract: Neutron stars and quark stars are ideal laboratories to study fundamental\nphysics at supra nuclear densities and strong gravitational fields.\nAstrophysical observables, however, depend strongly on the star's internal\nstructure, which is currently unknown due to uncertainties in the equation of\nstate. Universal relations, however, exist among certain stellar observables\nthat do not depend sensitively on the star's internal structure. One such set\nof relations is between the star's moment of inertia ($I$), its tidal Love\nnumber (Love) and its quadrupole moment ($Q$), the so-called I-Love-Q\nrelations. Similar relations hold among the star's multipole moments, which\nresemble the well-known black hole no-hair theorems. Universal relations break\ndegeneracies among astrophysical observables, leading to a variety of\napplications: (i) X-ray measurements of the nuclear matter equation of state,\n(ii) gravitational wave measurements of the intrinsic spin of inspiraling\ncompact objects, and (iii) gravitational and astrophysical tests of General\nRelativity that are independent of the equation of state. We here review how\nthe universal relations come about and all the applications that have been\ndevised to date. \n\n"}
{"id": "1608.02893", "contents": "Title: Syntactically Informed Text Compression with Recurrent Neural Networks Abstract: We present a self-contained system for constructing natural language models\nfor use in text compression. Our system improves upon previous neural network\nbased models by utilizing recent advances in syntactic parsing -- Google's\nSyntaxNet -- to augment character-level recurrent neural networks. RNNs have\nproven exceptional in modeling sequence data such as text, as their\narchitecture allows for modeling of long-term contextual information. \n\n"}
{"id": "1608.03902", "contents": "Title: Rapid Classification of Crisis-Related Data on Social Networks using\n  Convolutional Neural Networks Abstract: The role of social media, in particular microblogging platforms such as\nTwitter, as a conduit for actionable and tactical information during disasters\nis increasingly acknowledged. However, time-critical analysis of big crisis\ndata on social media streams brings challenges to machine learning techniques,\nespecially the ones that use supervised learning. The Scarcity of labeled data,\nparticularly in the early hours of a crisis, delays the machine learning\nprocess. The current state-of-the-art classification methods require a\nsignificant amount of labeled data specific to a particular event for training\nplus a lot of feature engineering to achieve best results. In this work, we\nintroduce neural network based classification methods for binary and\nmulti-class tweet classification task. We show that neural network based models\ndo not require any feature engineering and perform better than state-of-the-art\nmethods. In the early hours of a disaster when no labeled data is available,\nour proposed method makes the best use of the out-of-event data and achieves\ngood results. \n\n"}
{"id": "1608.04689", "contents": "Title: A Shallow High-Order Parametric Approach to Data Visualization and\n  Compression Abstract: Explicit high-order feature interactions efficiently capture essential\nstructural knowledge about the data of interest and have been used for\nconstructing generative models. We present a supervised discriminative\nHigh-Order Parametric Embedding (HOPE) approach to data visualization and\ncompression. Compared to deep embedding models with complicated deep\narchitectures, HOPE generates more effective high-order feature mapping through\nan embarrassingly simple shallow model. Furthermore, two approaches to\ngenerating a small number of exemplars conveying high-order interactions to\nrepresent large-scale data sets are proposed. These exemplars in combination\nwith the feature mapping learned by HOPE effectively capture essential data\nvariations. Moreover, through HOPE, these exemplars are employed to increase\nthe computational efficiency of kNN classification for fast information\nretrieval by thousands of times. For classification in two-dimensional\nembedding space on MNIST and USPS datasets, our shallow method HOPE with simple\nSigmoid transformations significantly outperforms state-of-the-art supervised\ndeep embedding models based on deep neural networks, and even achieved\nhistorically low test error rate of 0.65% in two-dimensional space on MNIST,\nwhich demonstrates the representational efficiency and power of supervised\nshallow models with high-order feature interactions. \n\n"}
{"id": "1608.07005", "contents": "Title: Multi-View Fuzzy Clustering with Minimax Optimization for Effective\n  Clustering of Data from Multiple Sources Abstract: Multi-view data clustering refers to categorizing a data set by making good\nuse of related information from multiple representations of the data. It\nbecomes important nowadays because more and more data can be collected in a\nvariety of ways, in different settings and from different sources, so each data\nset can be represented by different sets of features to form different views of\nit. Many approaches have been proposed to improve clustering performance by\nexploring and integrating heterogeneous information underlying different views.\nIn this paper, we propose a new multi-view fuzzy clustering approach called\nMinimaxFCM by using minimax optimization based on well-known Fuzzy c means. In\nMinimaxFCM the consensus clustering results are generated based on minimax\noptimization in which the maximum disagreements of different weighted views are\nminimized. Moreover, the weight of each view can be learned automatically in\nthe clustering process. In addition, there is only one parameter to be set\nbesides the fuzzifier. The detailed problem formulation, updating rules\nderivation, and the in-depth analysis of the proposed MinimaxFCM are provided\nhere. Experimental studies on nine multi-view data sets including real world\nimage and document data sets have been conducted. We observed that MinimaxFCM\noutperforms related multi-view clustering approaches in terms of clustering\naccuracy, demonstrating the great potential of MinimaxFCM for multi-view data\nanalysis. \n\n"}
{"id": "1609.00222", "contents": "Title: Ternary Neural Networks for Resource-Efficient AI Applications Abstract: The computation and storage requirements for Deep Neural Networks (DNNs) are\nusually high. This issue limits their deployability on ubiquitous computing\ndevices such as smart phones, wearables and autonomous drones. In this paper,\nwe propose ternary neural networks (TNNs) in order to make deep learning more\nresource-efficient. We train these TNNs using a teacher-student approach based\non a novel, layer-wise greedy methodology. Thanks to our two-stage training\nprocedure, the teacher network is still able to use state-of-the-art methods\nsuch as dropout and batch normalization to increase accuracy and reduce\ntraining time. Using only ternary weights and activations, the student ternary\nnetwork learns to mimic the behavior of its teacher network without using any\nmultiplication. Unlike its -1,1 binary counterparts, a ternary neural network\ninherently prunes the smaller weights by setting them to zero during training.\nThis makes them sparser and thus more energy-efficient. We design a\npurpose-built hardware architecture for TNNs and implement it on FPGA and ASIC.\nWe evaluate TNNs on several benchmark datasets and demonstrate up to 3.1x\nbetter energy efficiency with respect to the state of the art while also\nimproving accuracy. \n\n"}
{"id": "1609.01284", "contents": "Title: Testing the imprint of non-standard cosmologies on void profiles using\n  Monte Carlo random walks Abstract: Using a Monte Carlo random walks of a log-normal distribution, we show how to\nqualitatively study void properties for non-standard cosmologies. We apply this\nmethod to an f(R) modified gravity model and recover the N-body simulation\nresults of (Achitouv et al. 2016) for the void profiles and their deviation\nfrom GR. This method can potentially be extended to study other properties of\nthe large scale structures such as the abundance of voids or overdense\nenvironments. We also introduce a new way to identify voids in the cosmic web,\nusing only a few measurements of the density fluctuations around random\npositions. This algorithm allows to select voids with specific profiles and\nradii. As a consequence, we can target classes of voids with higher differences\nbetween f(R) and standard gravity void profiles. Finally we apply our void\ncriteria to galaxy mock catalogues and discuss how the flexibility of our void\nfinder can be used to reduce systematics errors when probing the growth rate in\nthe galaxy-void correlation function. \n\n"}
{"id": "1609.02116", "contents": "Title: Ask the GRU: Multi-Task Learning for Deep Text Recommendations Abstract: In a variety of application domains the content to be recommended to users is\nassociated with text. This includes research papers, movies with associated\nplot summaries, news articles, blog posts, etc. Recommendation approaches based\non latent factor models can be extended naturally to leverage text by employing\nan explicit mapping from text to factors. This enables recommendations for new,\nunseen content, and may generalize better, since the factors for all items are\nproduced by a compactly-parametrized model. Previous work has used topic models\nor averages of word embeddings for this mapping. In this paper we present a\nmethod leveraging deep recurrent neural networks to encode the text sequence\ninto a latent vector, specifically gated recurrent units (GRUs) trained\nend-to-end on the collaborative filtering task. For the task of scientific\npaper recommendation, this yields models with significantly higher accuracy. In\ncold-start scenarios, we beat the previous state-of-the-art, all of which\nignore word order. Performance is further improved by multi-task learning,\nwhere the text encoder network is trained for a combination of content\nrecommendation and item metadata prediction. This regularizes the collaborative\nfiltering model, ameliorating the problem of sparsity of the observed rating\nmatrix. \n\n"}
{"id": "1609.05374", "contents": "Title: Online Learning of Combinatorial Objects via Extended Formulation Abstract: The standard techniques for online learning of combinatorial objects perform\nmultiplicative updates followed by projections into the convex hull of all the\nobjects. However, this methodology can be expensive if the convex hull contains\nmany facets. For example, the convex hull of $n$-symbol Huffman trees is known\nto have exponentially many facets (Maurras et al., 2010). We get around this\ndifficulty by exploiting extended formulations (Kaibel, 2011), which encode the\npolytope of combinatorial objects in a higher dimensional \"extended\" space with\nonly polynomially many facets. We develop a general framework for converting\nextended formulations into efficient online algorithms with good relative loss\nbounds. We present applications of our framework to online learning of Huffman\ntrees and permutations. The regret bounds of the resulting algorithms are\nwithin a factor of $O(\\sqrt{\\log(n)})$ of the state-of-the-art specialized\nalgorithms for permutations, and depending on the loss regimes, improve on or\nmatch the state-of-the-art for Huffman trees. Our method is general and can be\napplied to other combinatorial objects. \n\n"}
{"id": "1609.06557", "contents": "Title: New Bi-Gravities Abstract: We show that the problem of ghosts in critical gravity and its higher\ndimensional extensions can be resolved by giving dynamics to the symmetric rank\ntwo auxiliary field existing in the action of these theories. These New\nBi-Gravities, at linear level around the AdS vacuum, are free of Boulware-Deser\nghost, kinetic ghost and tachyonic instability within the particular range of\nparameters. Moreover, we show that the energy and entropy of AdS-Schwarzschild\nblack hole solutions of these new models are positive in the same range of\nparameters. This may be the sign that these new models are also free of ghost\ninstabilities at the non-linear level. \n\n"}
{"id": "1610.02391", "contents": "Title: Grad-CAM: Visual Explanations from Deep Networks via Gradient-based\n  Localization Abstract: We propose a technique for producing \"visual explanations\" for decisions from\na large class of CNN-based models, making them more transparent. Our approach -\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of\nany target concept, flowing into the final convolutional layer to produce a\ncoarse localization map highlighting important regions in the image for\npredicting the concept. Grad-CAM is applicable to a wide variety of CNN\nmodel-families: (1) CNNs with fully-connected layers, (2) CNNs used for\nstructured outputs, (3) CNNs used in tasks with multimodal inputs or\nreinforcement learning, without any architectural changes or re-training. We\ncombine Grad-CAM with fine-grained visualizations to create a high-resolution\nclass-discriminative visualization and apply it to off-the-shelf image\nclassification, captioning, and visual question answering (VQA) models,\nincluding ResNet-based architectures. In the context of image classification\nmodels, our visualizations (a) lend insights into their failure modes, (b) are\nrobust to adversarial images, (c) outperform previous methods on localization,\n(d) are more faithful to the underlying model and (e) help achieve\ngeneralization by identifying dataset bias. For captioning and VQA, we show\nthat even non-attention based models can localize inputs. We devise a way to\nidentify important neurons through Grad-CAM and combine it with neuron names to\nprovide textual explanations for model decisions. Finally, we design and\nconduct human studies to measure if Grad-CAM helps users establish appropriate\ntrust in predictions from models and show that Grad-CAM helps untrained users\nsuccessfully discern a 'stronger' nodel from a 'weaker' one even when both make\nidentical predictions. Our code is available at\nhttps://github.com/ramprs/grad-cam/, along with a demo at\nhttp://gradcam.cloudcv.org, and a video at youtu.be/COjUB9Izk6E. \n\n"}
{"id": "1610.03295", "contents": "Title: Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving Abstract: Autonomous driving is a multi-agent setting where the host vehicle must apply\nsophisticated negotiation skills with other road users when overtaking, giving\nway, merging, taking left and right turns and while pushing ahead in\nunstructured urban roadways. Since there are many possible scenarios, manually\ntackling all possible cases will likely yield a too simplistic policy.\nMoreover, one must balance between unexpected behavior of other\ndrivers/pedestrians and at the same time not to be too defensive so that normal\ntraffic flow is maintained.\n  In this paper we apply deep reinforcement learning to the problem of forming\nlong term driving strategies. We note that there are two major challenges that\nmake autonomous driving different from other robotic tasks. First, is the\nnecessity for ensuring functional safety - something that machine learning has\ndifficulty with given that performance is optimized at the level of an\nexpectation over many instances. Second, the Markov Decision Process model\noften used in robotics is problematic in our case because of unpredictable\nbehavior of other agents in this multi-agent scenario. We make three\ncontributions in our work. First, we show how policy gradient iterations can be\nused without Markovian assumptions. Second, we decompose the problem into a\ncomposition of a Policy for Desires (which is to be learned) and trajectory\nplanning with hard constraints (which is not learned). The goal of Desires is\nto enable comfort of driving, while hard constraints guarantees the safety of\ndriving. Third, we introduce a hierarchical temporal abstraction we call an\n\"Option Graph\" with a gating mechanism that significantly reduces the effective\nhorizon and thereby reducing the variance of the gradient estimation even\nfurther. \n\n"}
{"id": "1610.08401", "contents": "Title: Universal adversarial perturbations Abstract: Given a state-of-the-art deep neural network classifier, we show the\nexistence of a universal (image-agnostic) and very small perturbation vector\nthat causes natural images to be misclassified with high probability. We\npropose a systematic algorithm for computing universal perturbations, and show\nthat state-of-the-art deep neural networks are highly vulnerable to such\nperturbations, albeit being quasi-imperceptible to the human eye. We further\nempirically analyze these universal perturbations and show, in particular, that\nthey generalize very well across neural networks. The surprising existence of\nuniversal perturbations reveals important geometric correlations among the\nhigh-dimensional decision boundary of classifiers. It further outlines\npotential security breaches with the existence of single directions in the\ninput space that adversaries can possibly exploit to break a classifier on most\nnatural images. \n\n"}
{"id": "1610.09120", "contents": "Title: Scalar-tensor linear inflation Abstract: We investigate two approaches to non minimally coupled gravity theories which\npresent linear inflation as attractor solution: a) the scalar-tensor theory\napproach, where we look for a scalar-tensor theory that would restore results\nof linear inflation in the strong coupling limit for any form of the\nnon-minimal coupling to gravity of the form of $f(\\varphi)R/2$; b) the particle\nphysics approach, where we motivate the form of the Jordan frame potential by\nthe loop corrections to the inflaton field. In both cases the Jordan frame\npotentials are modifications of the induced inflation, but instead of the\nStarobinsky attractor they lead to the linear inflation in the strong coupling\nlimit. \n\n"}
{"id": "1611.00938", "contents": "Title: Fast Eigenspace Approximation using Random Signals Abstract: We focus in this work on the estimation of the first $k$ eigenvectors of any\ngraph Laplacian using filtering of Gaussian random signals. We prove that we\nonly need $k$ such signals to be able to exactly recover as many of the\nsmallest eigenvectors, regardless of the number of nodes in the graph. In\naddition, we address key issues in implementing the theoretical concepts in\npractice using accurate approximated methods. We also propose fast algorithms\nboth for eigenspace approximation and for the determination of the $k$th\nsmallest eigenvalue $\\lambda_k$. The latter proves to be extremely efficient\nunder the assumption of locally uniform distribution of the eigenvalue over the\nspectrum. Finally, we present experiments which show the validity of our method\nin practice and compare it to state-of-the-art methods for clustering and\nvisualization both on synthetic small-scale datasets and larger real-world\nproblems of millions of nodes. We show that our method allows a better scaling\nwith the number of nodes than all previous methods while achieving an almost\nperfect reconstruction of the eigenspace formed by the first $k$ eigenvectors. \n\n"}
{"id": "1611.01688", "contents": "Title: Oracle-Efficient Online Learning and Auction Design Abstract: We consider the design of computationally efficient online learning\nalgorithms in an adversarial setting in which the learner has access to an\noffline optimization oracle. We present an algorithm called Generalized\nFollow-the-Perturbed-Leader and provide conditions under which it is\noracle-efficient while achieving vanishing regret. Our results make significant\nprogress on an open problem raised by Hazan and Koren, who showed that\noracle-efficient algorithms do not exist in general and asked whether one can\nidentify properties under which oracle-efficient online learning may be\npossible.\n  Our auction-design framework considers an auctioneer learning an optimal\nauction for a sequence of adversarially selected valuations with the goal of\nachieving revenue that is almost as good as the optimal auction in hindsight,\namong a class of auctions. We give oracle-efficient learning results for: (1)\nVCG auctions with bidder-specific reserves in single-parameter settings, (2)\nenvy-free item pricing in multi-item auctions, and (3) s-level auctions of\nMorgenstern and Roughgarden for single-item settings. The last result leads to\nan approximation of the overall optimal Myerson auction when bidders'\nvaluations are drawn according to a fast-mixing Markov process, extending prior\nwork that only gave such guarantees for the i.i.d. setting.\n  Finally, we derive various extensions, including: (1) oracle-efficient\nalgorithms for the contextual learning setting in which the learner has access\nto side information (such as bidder demographics), (2) learning with\napproximate oracles such as those based on Maximal-in-Range algorithms, and (3)\nno-regret bidding in simultaneous auctions, resolving an open problem of\nDaskalakis and Syrgkanis. \n\n"}
{"id": "1611.02854", "contents": "Title: Lie-Access Neural Turing Machines Abstract: External neural memory structures have recently become a popular tool for\nalgorithmic deep learning (Graves et al. 2014, Weston et al. 2014). These\nmodels generally utilize differentiable versions of traditional discrete\nmemory-access structures (random access, stacks, tapes) to provide the storage\nnecessary for computational tasks. In this work, we argue that these neural\nmemory systems lack specific structure important for relative indexing, and\npropose an alternative model, Lie-access memory, that is explicitly designed\nfor the neural setting. In this paradigm, memory is accessed using a continuous\nhead in a key-space manifold. The head is moved via Lie group actions, such as\nshifts or rotations, generated by a controller, and memory access is performed\nby linear smoothing in key space. We argue that Lie groups provide a natural\ngeneralization of discrete memory structures, such as Turing machines, as they\nprovide inverse and identity operators while maintaining differentiability. To\nexperiment with this approach, we implement a simplified Lie-access neural\nTuring machine (LANTM) with different Lie groups. We find that this approach is\nable to perform well on a range of algorithmic tasks. \n\n"}
{"id": "1611.03852", "contents": "Title: A Connection between Generative Adversarial Networks, Inverse\n  Reinforcement Learning, and Energy-Based Models Abstract: Generative adversarial networks (GANs) are a recently proposed class of\ngenerative models in which a generator is trained to optimize a cost function\nthat is being simultaneously learned by a discriminator. While the idea of\nlearning cost functions is relatively new to the field of generative modeling,\nlearning costs has long been studied in control and reinforcement learning (RL)\ndomains, typically for imitation learning from demonstrations. In these fields,\nlearning cost function underlying observed behavior is known as inverse\nreinforcement learning (IRL) or inverse optimal control. While at first the\nconnection between cost learning in RL and cost learning in generative modeling\nmay appear to be a superficial one, we show in this paper that certain IRL\nmethods are in fact mathematically equivalent to GANs. In particular, we\ndemonstrate an equivalence between a sample-based algorithm for maximum entropy\nIRL and a GAN in which the generator's density can be evaluated and is provided\nas an additional input to the discriminator. Interestingly, maximum entropy IRL\nis a special case of an energy-based model. We discuss the interpretation of\nGANs as an algorithm for training energy-based models, and relate this\ninterpretation to other recent work that seeks to connect GANs and EBMs. By\nformally highlighting the connection between GANs, IRL, and EBMs, we hope that\nresearchers in all three communities can better identify and apply transferable\nideas from one domain to another, particularly for developing more stable and\nscalable algorithms: a major challenge in all three domains. \n\n"}
{"id": "1611.04199", "contents": "Title: Realistic risk-mitigating recommendations via inverse classification Abstract: Inverse classification, the process of making meaningful perturbations to a\ntest point such that it is more likely to have a desired classification, has\npreviously been addressed using data from a single static point in time. Such\nan approach yields inflated probability estimates, stemming from an implicitly\nmade assumption that recommendations are implemented instantaneously. We\npropose using longitudinal data to alleviate such issues in two ways. First, we\nuse past outcome probabilities as features in the present. Use of such past\nprobabilities ties historical behavior to the present, allowing for more\ninformation to be taken into account when making initial probability estimates\nand subsequently performing inverse classification. Secondly, following inverse\nclassification application, optimized instances' unchangeable features\n(e.g.,~age) are updated using values from the next longitudinal time period.\nOptimized test instance probabilities are then reassessed. Updating the\nunchangeable features in this manner reflects the notion that improvements in\noutcome likelihood, which result from following the inverse classification\nrecommendations, do not materialize instantaneously. As our experiments\ndemonstrate, more realistic estimates of probability can be obtained by\nfactoring in such considerations. \n\n"}
{"id": "1611.04231", "contents": "Title: Identity Matters in Deep Learning Abstract: An emerging design principle in deep learning is that each layer of a deep\nartificial neural network should be able to easily express the identity\ntransformation. This idea not only motivated various normalization techniques,\nsuch as \\emph{batch normalization}, but was also key to the immense success of\n\\emph{residual networks}.\n  In this work, we put the principle of \\emph{identity parameterization} on a\nmore solid theoretical footing alongside further empirical progress. We first\ngive a strikingly simple proof that arbitrarily deep linear residual networks\nhave no spurious local optima. The same result for linear feed-forward networks\nin their standard parameterization is substantially more delicate. Second, we\nshow that residual networks with ReLu activations have universal finite-sample\nexpressivity in the sense that the network can represent any function of its\nsample provided that the model has more parameters than the sample size.\n  Directly inspired by our theory, we experiment with a radically simple\nresidual architecture consisting of only residual convolutional layers and ReLu\nactivations, but no batch normalization, dropout, or max pool. Our model\nimproves significantly on previous all-convolutional networks on the CIFAR10,\nCIFAR100, and ImageNet classification benchmarks. \n\n"}
{"id": "1611.04361", "contents": "Title: Attending to Characters in Neural Sequence Labeling Models Abstract: Sequence labeling architectures use word embeddings for capturing similarity,\nbut suffer when handling previously unseen or rare words. We investigate\ncharacter-level extensions to such models and propose a novel architecture for\ncombining alternative word representations. By using an attention mechanism,\nthe model is able to dynamically decide how much information to use from a\nword- or character-level component. We evaluated different architectures on a\nrange of sequence labeling datasets, and character-level extensions were found\nto improve performance on every benchmark. In addition, the proposed\nattention-based architecture delivered the best results even with a smaller\nnumber of trainable parameters. \n\n"}
{"id": "1611.04535", "contents": "Title: Learning-Theoretic Foundations of Algorithm Configuration for\n  Combinatorial Partitioning Problems Abstract: Max-cut, clustering, and many other partitioning problems that are of\nsignificant importance to machine learning and other scientific fields are\nNP-hard, a reality that has motivated researchers to develop a wealth of\napproximation algorithms and heuristics. Although the best algorithm to use\ntypically depends on the specific application domain, a worst-case analysis is\noften used to compare algorithms. This may be misleading if worst-case\ninstances occur infrequently, and thus there is a demand for optimization\nmethods which return the algorithm configuration best suited for the given\napplication's typical inputs. We address this problem for clustering, max-cut,\nand other partitioning problems, such as integer quadratic programming, by\ndesigning computationally efficient and sample efficient learning algorithms\nwhich receive samples from an application-specific distribution over problem\ninstances and learn a partitioning algorithm with high expected performance.\nOur algorithms learn over common integer quadratic programming and clustering\nalgorithm families: SDP rounding algorithms and agglomerative clustering\nalgorithms with dynamic programming. For our sample complexity analysis, we\nprovide tight bounds on the pseudodimension of these algorithm classes, and\nshow that surprisingly, even for classes of algorithms parameterized by a\nsingle parameter, the pseudo-dimension is superconstant. In this way, our work\nboth contributes to the foundations of algorithm configuration and pushes the\nboundaries of learning theory, since the algorithm classes we analyze consist\nof multi-stage optimization procedures and are significantly more complex than\nclasses typically studied in learning theory. \n\n"}
{"id": "1611.05321", "contents": "Title: A Semi-supervised Framework for Image Captioning Abstract: State-of-the-art approaches for image captioning require supervised training\ndata consisting of captions with paired image data. These methods are typically\nunable to use unsupervised data such as textual data with no corresponding\nimages, which is a much more abundant commodity. We here propose a novel way of\nusing such textual data by artificially generating missing visual information.\nWe evaluate this learning approach on a newly designed model that detects\nvisual concepts present in an image and feed them to a reviewer-decoder\narchitecture with an attention mechanism. Unlike previous approaches that\nencode visual concepts using word embeddings, we instead suggest using regional\nimage features which capture more intrinsic information. The main benefit of\nthis architecture is that it synthesizes meaningful thought vectors that\ncapture salient image properties and then applies a soft attentive decoder to\ndecode the thought vectors and generate image captions. We evaluate our model\non both Microsoft COCO and Flickr30K datasets and demonstrate that this model\ncombined with our semi-supervised learning method can largely improve\nperformance and help the model to generate more accurate and diverse captions. \n\n"}
{"id": "1611.06221", "contents": "Title: Foundations of Structural Causal Models with Cycles and Latent Variables Abstract: Structural causal models (SCMs), also known as (nonparametric) structural\nequation models (SEMs), are widely used for causal modeling purposes. In\nparticular, acyclic SCMs, also known as recursive SEMs, form a well-studied\nsubclass of SCMs that generalize causal Bayesian networks to allow for latent\nconfounders. In this paper, we investigate SCMs in a more general setting,\nallowing for the presence of both latent confounders and cycles. We show that\nin the presence of cycles, many of the convenient properties of acyclic SCMs do\nnot hold in general: they do not always have a solution; they do not always\ninduce unique observational, interventional and counterfactual distributions; a\nmarginalization does not always exist, and if it exists the marginal model does\nnot always respect the latent projection; they do not always satisfy a Markov\nproperty; and their graphs are not always consistent with their causal\nsemantics. We prove that for SCMs in general each of these properties does hold\nunder certain solvability conditions. Our work generalizes results for SCMs\nwith cycles that were only known for certain special cases so far. We introduce\nthe class of simple SCMs that extends the class of acyclic SCMs to the cyclic\nsetting, while preserving many of the convenient properties of acyclic SCMs.\nWith this paper we aim to provide the foundations for a general theory of\nstatistical causal modeling with SCMs. \n\n"}
{"id": "1611.06321", "contents": "Title: Learning the Number of Neurons in Deep Networks Abstract: Nowadays, the number of layers and of neurons in each layer of a deep network\nare typically set manually. While very deep and wide networks have proven\neffective in general, they come at a high memory and computation cost, thus\nmaking them impractical for constrained platforms. These networks, however, are\nknown to have many redundant parameters, and could thus, in principle, be\nreplaced by more compact architectures. In this paper, we introduce an approach\nto automatically determining the number of neurons in each layer of a deep\nnetwork during learning. To this end, we propose to make use of structured\nsparsity during learning. More precisely, we use a group sparsity regularizer\non the parameters of the network, where each group is defined to act on a\nsingle neuron. Starting from an overcomplete network, we show that our approach\ncan reduce the number of parameters by up to 80\\% while retaining or even\nimproving the network accuracy. \n\n"}
{"id": "1611.06759", "contents": "Title: Emergence of Compositional Representations in Restricted Boltzmann\n  Machines Abstract: Extracting automatically the complex set of features composing real\nhigh-dimensional data is crucial for achieving high performance in\nmachine--learning tasks. Restricted Boltzmann Machines (RBM) are empirically\nknown to be efficient for this purpose, and to be able to generate distributed\nand graded representations of the data. We characterize the structural\nconditions (sparsity of the weights, low effective temperature, nonlinearities\nin the activation functions of hidden units, and adaptation of fields\nmaintaining the activity in the visible layer) allowing RBM to operate in such\na compositional phase. Evidence is provided by the replica analysis of an\nadequate statistical ensemble of random RBMs and by RBM trained on the\nhandwritten digits dataset MNIST. \n\n"}
{"id": "1611.08108", "contents": "Title: Dynamic Key-Value Memory Networks for Knowledge Tracing Abstract: Knowledge Tracing (KT) is a task of tracing evolving knowledge state of\nstudents with respect to one or more concepts as they engage in a sequence of\nlearning activities. One important purpose of KT is to personalize the practice\nsequence to help students learn knowledge concepts efficiently. However,\nexisting methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing\neither model knowledge state for each predefined concept separately or fail to\npinpoint exactly which concepts a student is good at or unfamiliar with. To\nsolve these problems, this work introduces a new model called Dynamic Key-Value\nMemory Networks (DKVMN) that can exploit the relationships between underlying\nconcepts and directly output a student's mastery level of each concept. Unlike\nstandard memory-augmented neural networks that facilitate a single memory\nmatrix or two static memory matrices, our model has one static matrix called\nkey, which stores the knowledge concepts and the other dynamic matrix called\nvalue, which stores and updates the mastery levels of corresponding concepts.\nExperiments show that our model consistently outperforms the state-of-the-art\nmodel in a range of KT datasets. Moreover, the DKVMN model can automatically\ndiscover underlying concepts of exercises typically performed by human\nannotations and depict the changing knowledge state of a student. \n\n"}
{"id": "1611.08737", "contents": "Title: Structural Correspondence Learning for Cross-lingual Sentiment\n  Classification with One-to-many Mappings Abstract: Structural correspondence learning (SCL) is an effective method for\ncross-lingual sentiment classification. This approach uses unlabeled documents\nalong with a word translation oracle to automatically induce task specific,\ncross-lingual correspondences. It transfers knowledge through identifying\nimportant features, i.e., pivot features. For simplicity, however, it assumes\nthat the word translation oracle maps each pivot feature in source language to\nexactly only one word in target language. This one-to-one mapping between words\nin different languages is too strict. Also the context is not considered at\nall. In this paper, we propose a cross-lingual SCL based on distributed\nrepresentation of words; it can learn meaningful one-to-many mappings for pivot\nwords using large amounts of monolingual data and a small dictionary. We\nconduct experiments on NLP\\&CC 2013 cross-lingual sentiment analysis dataset,\nemploying English as source language, and Chinese as target language. Our\nmethod does not rely on the parallel corpora and the experimental results show\nthat our approach is more competitive than the state-of-the-art methods in\ncross-lingual sentiment classification. \n\n"}
{"id": "1611.08903", "contents": "Title: Should I use TensorFlow Abstract: Google's Machine Learning framework TensorFlow was open-sourced in November\n2015 [1] and has since built a growing community around it. TensorFlow is\nsupposed to be flexible for research purposes while also allowing its models to\nbe deployed productively. This work is aimed towards people with experience in\nMachine Learning considering whether they should use TensorFlow in their\nenvironment. Several aspects of the framework important for such a decision are\nexamined, such as the heterogenity, extensibility and its computation graph. A\npure Python implementation of linear classification is compared with an\nimplementation utilizing TensorFlow. I also contrast TensorFlow to other\npopular frameworks with respect to modeling capability, deployment and\nperformance and give a brief description of the current adaption of the\nframework. \n\n"}
{"id": "1611.09340", "contents": "Title: Diet Networks: Thin Parameters for Fat Genomics Abstract: Learning tasks such as those involving genomic data often poses a serious\nchallenge: the number of input features can be orders of magnitude larger than\nthe number of training examples, making it difficult to avoid overfitting, even\nwhen using the known regularization techniques. We focus here on tasks in which\nthe input is a description of the genetic variation specific to a patient, the\nsingle nucleotide polymorphisms (SNPs), yielding millions of ternary inputs.\nImproving the ability of deep learning to handle such datasets could have an\nimportant impact in precision medicine, where high-dimensional data regarding a\nparticular patient is used to make predictions of interest. Even though the\namount of data for such tasks is increasing, this mismatch between the number\nof examples and the number of inputs remains a concern. Naive implementations\nof classifier neural networks involve a huge number of free parameters in their\nfirst layer: each input feature is associated with as many parameters as there\nare hidden units. We propose a novel neural network parametrization which\nconsiderably reduces the number of free parameters. It is based on the idea\nthat we can first learn or provide a distributed representation for each input\nfeature (e.g. for each position in the genome where variations are observed),\nand then learn (with another neural network called the parameter prediction\nnetwork) how to map a feature's distributed representation to the vector of\nparameters specific to that feature in the classifier neural network (the\nweights which link the value of the feature to each of the hidden units). We\nshow experimentally on a population stratification task of interest to medical\nstudies that the proposed approach can significantly reduce both the number of\nparameters and the error rate of the classifier. \n\n"}
{"id": "1611.09810", "contents": "Title: Phenomenology with fluctuating quantum geometries in loop quantum\n  cosmology Abstract: The goal of this paper is to probe phenomenological implications of large\nfluctuations of quantum geometry in the Planck era, using cosmology of the\nearly universe. For the background (Friedmann, Lema\\^{i}tre, Robertson, Walker)\n\\emph{quantum} geometry, we allow `widely spread' states in which the\n\\emph{relative} dispersions are as large as $168\\%$ in the Planck regime. By\nintroducing suitable methods to overcome the ensuing conceptual and\ncomputational issues, we calculate the power spectrum $P_{\\mathcal{R}}(k)$ and\nthe spectral index $n_s(k)$ of primordial curvature perturbations. These\nresults generalize the previous work in loop quantum cosmology which focused on\nthose states which were known to remain sharply peaked throughout the Planck\nregime. Surprisingly, even though the fluctuations we now consider are large,\ntheir presence does not add new features to the final $P_{\\mathcal{R}}(k)$ and\n$n_s(k)$: Within observational error bars, their effect is degenerate with a\ndifferent freedom in the theory, namely the number of \\emph{pre-inflationary}\ne-folds $N_{{\\rm B}\\,\\star}$ between the bounce and the onset of inflation.\nTherefore, with regard to observational consequences, one can simulate the\nfreedom in the choice of states with large fluctuations in the Planck era using\nthe simpler, sharply peaked states, simply by allowing for different values of\n$N_{{\\rm B}\\,\\star}$. \n\n"}
{"id": "1612.00913", "contents": "Title: End-to-End Joint Learning of Natural Language Understanding and Dialogue\n  Manager Abstract: Natural language understanding and dialogue policy learning are both\nessential in conversational systems that predict the next system actions in\nresponse to a current user utterance. Conventional approaches aggregate\nseparate models of natural language understanding (NLU) and system action\nprediction (SAP) as a pipeline that is sensitive to noisy outputs of\nerror-prone NLU. To address the issues, we propose an end-to-end deep recurrent\nneural network with limited contextual dialogue memory by jointly training NLU\nand SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our\nproposed model significantly outperforms the state-of-the-art pipeline models\nfor both NLU and SAP, which indicates that our joint model is capable of\nmitigating the affects of noisy NLU outputs, and NLU model can be refined by\nerror flows backpropagating from the extra supervised signals of system\nactions. \n\n"}
{"id": "1612.01020", "contents": "Title: Hypothesis Transfer Learning via Transformation Functions Abstract: We consider the Hypothesis Transfer Learning (HTL) problem where one\nincorporates a hypothesis trained on the source domain into the learning\nprocedure of the target domain. Existing theoretical analysis either only\nstudies specific algorithms or only presents upper bounds on the generalization\nerror but not on the excess risk. In this paper, we propose a unified\nalgorithm-dependent framework for HTL through a novel notion of transformation\nfunction, which characterizes the relation between the source and the target\ndomains. We conduct a general risk analysis of this framework and in\nparticular, we show for the first time, if two domains are related, HTL enjoys\nfaster convergence rates of excess risks for Kernel Smoothing and Kernel Ridge\nRegression than those of the classical non-transfer learning settings.\nExperiments on real world data demonstrate the effectiveness of our framework. \n\n"}
{"id": "1612.01086", "contents": "Title: Deep Learning of Robotic Tasks without a Simulator using Strong and Weak\n  Human Supervision Abstract: We propose a scheme for training a computerized agent to perform complex\nhuman tasks such as highway steering. The scheme is designed to follow a\nnatural learning process whereby a human instructor teaches a computerized\ntrainee. The learning process consists of five elements: (i) unsupervised\nfeature learning; (ii) supervised imitation learning; (iii) supervised reward\ninduction; (iv) supervised safety module construction; and (v) reinforcement\nlearning. We implemented the last four elements of the scheme using deep\nconvolutional networks and applied it to successfully create a computerized\nagent capable of autonomous highway steering over the well-known racing game\nAssetto Corsa. We demonstrate that the use of the last four elements is\nessential to effectively carry out the steering task using vision alone,\nwithout access to a driving simulator internals, and operating in wall-clock\ntime. This is made possible also through the introduction of a safety network,\na novel way for preventing the agent from performing catastrophic mistakes\nduring the reinforcement learning stage. \n\n"}
{"id": "1612.01158", "contents": "Title: Properties and Bayesian fitting of restricted Boltzmann machines Abstract: A restricted Boltzmann machine (RBM) is an undirected graphical model\nconstructed for discrete or continuous random variables, with two layers, one\nhidden and one visible, and no conditional dependency within a layer. In recent\nyears, RBMs have risen to prominence due to their connection to deep learning.\nBy treating a hidden layer of one RBM as the visible layer in a second RBM, a\ndeep architecture can be created. RBMs are thought to thereby have the ability\nto encode very complex and rich structures in data, making them attractive for\nsupervised learning. However, the generative behavior of RBMs is largely\nunexplored and typical fitting methodology does not easily allow for\nuncertainty quantification in addition to point estimates. In this paper, we\ndiscuss the relationship between RBM parameter specification in the binary case\nand model properties such as degeneracy, instability and uninterpretability. We\nalso describe the associated difficulties that can arise with likelihood-based\ninference and further discuss the potential Bayes fitting of such (highly\nflexible) models, especially as Gibbs sampling (quasi-Bayes) methods are often\nadvocated for the RBM model structure. \n\n"}
{"id": "1612.01228", "contents": "Title: On uniqueness of static black hole with conformal scalar hair Abstract: We discuss the uniqueness of the static black hole in the Einstein gravity\nwith a conformally coupled scalar field. In particular, we prove the uniqueness\nof the region outside of the photon surface, not event horizon. \n\n"}
{"id": "1612.01663", "contents": "Title: Efficient Non-oblivious Randomized Reduction for Risk Minimization with\n  Improved Excess Risk Guarantee Abstract: In this paper, we address learning problems for high dimensional data.\nPreviously, oblivious random projection based approaches that project high\ndimensional features onto a random subspace have been used in practice for\ntackling high-dimensionality challenge in machine learning. Recently, various\nnon-oblivious randomized reduction methods have been developed and deployed for\nsolving many numerical problems such as matrix product approximation, low-rank\nmatrix approximation, etc. However, they are less explored for the machine\nlearning tasks, e.g., classification. More seriously, the theoretical analysis\nof excess risk bounds for risk minimization, an important measure of\ngeneralization performance, has not been established for non-oblivious\nrandomized reduction methods. It therefore remains an open problem what is the\nbenefit of using them over previous oblivious random projection based\napproaches. To tackle these challenges, we propose an algorithmic framework for\nemploying non-oblivious randomized reduction method for general empirical risk\nminimizing in machine learning tasks, where the original high-dimensional\nfeatures are projected onto a random subspace that is derived from the data\nwith a small matrix approximation error. We then derive the first excess risk\nbound for the proposed non-oblivious randomized reduction approach without\nrequiring strong assumptions on the training data. The established excess risk\nbound exhibits that the proposed approach provides much better generalization\nperformance and it also sheds more insights about different randomized\nreduction approaches. Finally, we conduct extensive experiments on both\nsynthetic and real-world benchmark datasets, whose dimension scales to\n$O(10^7)$, to demonstrate the efficacy of our proposed approach. \n\n"}
{"id": "1612.02879", "contents": "Title: Learning Representations by Stochastic Meta-Gradient Descent in Neural\n  Networks Abstract: Representations are fundamental to artificial intelligence. The performance\nof a learning system depends on the type of representation used for\nrepresenting the data. Typically, these representations are hand-engineered\nusing domain knowledge. More recently, the trend is to learn these\nrepresentations through stochastic gradient descent in multi-layer neural\nnetworks, which is called backprop. Learning the representations directly from\nthe incoming data stream reduces the human labour involved in designing a\nlearning system. More importantly, this allows in scaling of a learning system\nfor difficult tasks. In this paper, we introduce a new incremental learning\nalgorithm called crossprop, which learns incoming weights of hidden units based\non the meta-gradient descent approach, that was previously introduced by Sutton\n(1992) and Schraudolph (1999) for learning step-sizes. The final update\nequation introduces an additional memory parameter for each of these weights\nand generalizes the backprop update equation. From our experiments, we show\nthat crossprop learns and reuses its feature representation while tackling new\nand unseen tasks whereas backprop relearns a new feature representation. \n\n"}
{"id": "1612.03211", "contents": "Title: DeepCancer: Detecting Cancer through Gene Expressions via Deep\n  Generative Learning Abstract: Transcriptional profiling on microarrays to obtain gene expressions has been\nused to facilitate cancer diagnosis. We propose a deep generative machine\nlearning architecture (called DeepCancer) that learn features from unlabeled\nmicroarray data. These models have been used in conjunction with conventional\nclassifiers that perform classification of the tissue samples as either being\ncancerous or non-cancerous. The proposed model has been tested on two different\nclinical datasets. The evaluation demonstrates that DeepCancer model achieves a\nvery high precision score, while significantly controlling the false positive\nand false negative scores. \n\n"}
{"id": "1612.03226", "contents": "Title: Active Learning for Speech Recognition: the Power of Gradients Abstract: In training speech recognition systems, labeling audio clips can be\nexpensive, and not all data is equally valuable. Active learning aims to label\nonly the most informative samples to reduce cost. For speech recognition,\nconfidence scores and other likelihood-based active learning methods have been\nshown to be effective. Gradient-based active learning methods, however, are\nstill not well-understood. This work investigates the Expected Gradient Length\n(EGL) approach in active learning for end-to-end speech recognition. We justify\nEGL from a variance reduction perspective, and observe that EGL's measure of\ninformativeness picks novel samples uncorrelated with confidence scores.\nExperimentally, we show that EGL can reduce word errors by 11\\%, or\nalternatively, reduce the number of samples to label by 50\\%, when compared to\nrandom sampling. \n\n"}
{"id": "1612.04022", "contents": "Title: Distributed Multi-Task Relationship Learning Abstract: Multi-task learning aims to learn multiple tasks jointly by exploiting their\nrelatedness to improve the generalization performance for each task.\nTraditionally, to perform multi-task learning, one needs to centralize data\nfrom all the tasks to a single machine. However, in many real-world\napplications, data of different tasks may be geo-distributed over different\nlocal machines. Due to heavy communication caused by transmitting the data and\nthe issue of data privacy and security, it is impossible to send data of\ndifferent task to a master machine to perform multi-task learning. Therefore,\nin this paper, we propose a distributed multi-task learning framework that\nsimultaneously learns predictive models for each task as well as task\nrelationships between tasks alternatingly in the parameter server paradigm. In\nour framework, we first offer a general dual form for a family of regularized\nmulti-task relationship learning methods. Subsequently, we propose a\ncommunication-efficient primal-dual distributed optimization algorithm to solve\nthe dual problem by carefully designing local subproblems to make the dual\nproblem decomposable. Moreover, we provide a theoretical convergence analysis\nfor the proposed algorithm, which is specific for distributed multi-task\nrelationship learning. We conduct extensive experiments on both synthetic and\nreal-world datasets to evaluate our proposed framework in terms of\neffectiveness and convergence. \n\n"}
{"id": "1612.06246", "contents": "Title: Corralling a Band of Bandit Algorithms Abstract: We study the problem of combining multiple bandit algorithms (that is, online\nlearning algorithms with partial feedback) with the goal of creating a master\nalgorithm that performs almost as well as the best base algorithm if it were to\nbe run on its own. The main challenge is that when run with a master, base\nalgorithms unavoidably receive much less feedback and it is thus critical that\nthe master not starve a base algorithm that might perform uncompetitively\ninitially but would eventually outperform others if given enough feedback. We\naddress this difficulty by devising a version of Online Mirror Descent with a\nspecial mirror map together with a sophisticated learning rate scheme. We show\nthat this approach manages to achieve a more delicate balance between\nexploiting and exploring base algorithms than previous works yielding superior\nregret bounds.\n  Our results are applicable to many settings, such as multi-armed bandits,\ncontextual bandits, and convex bandits. As examples, we present two main\napplications. The first is to create an algorithm that enjoys worst-case\nrobustness while at the same time performing much better when the environment\nis relatively easy. The second is to create an algorithm that works\nsimultaneously under different assumptions of the environment, such as\ndifferent priors or different loss structures. \n\n"}
{"id": "1612.06676", "contents": "Title: Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault\n  Detection Using an LSTM-based Predictive Data Model Abstract: We adopted an approach based on an LSTM neural network to monitor and detect\nfaults in industrial multivariate time series data. To validate the approach we\ncreated a Modelica model of part of a real gasoil plant. By introducing hacks\ninto the logic of the Modelica model, we were able to generate both the roots\nand causes of fault behavior in the plant. Having a self-consistent data set\nwith labeled faults, we used an LSTM architecture with a forecasting error\nthreshold to obtain precision and recall quality metrics. The dependency of the\nquality metric on the threshold level is considered. An appropriate mechanism\nsuch as \"one handle\" was introduced for filtering faults that are outside of\nthe plant operator field of interest. \n\n"}
{"id": "1612.06890", "contents": "Title: CLEVR: A Diagnostic Dataset for Compositional Language and Elementary\n  Visual Reasoning Abstract: When building artificial intelligence systems that can reason and answer\nquestions about visual data, we need diagnostic tests to analyze our progress\nand discover shortcomings. Existing benchmarks for visual question answering\ncan help, but have strong biases that models can exploit to correctly answer\nquestions without reasoning. They also conflate multiple sources of error,\nmaking it hard to pinpoint model weaknesses. We present a diagnostic dataset\nthat tests a range of visual reasoning abilities. It contains minimal biases\nand has detailed annotations describing the kind of reasoning each question\nrequires. We use this dataset to analyze a variety of modern visual reasoning\nsystems, providing novel insights into their abilities and limitations. \n\n"}
{"id": "1612.07401", "contents": "Title: Microstructure Representation and Reconstruction of Heterogeneous\n  Materials via Deep Belief Network for Computational Material Design Abstract: Integrated Computational Materials Engineering (ICME) aims to accelerate\noptimal design of complex material systems by integrating material science and\ndesign automation. For tractable ICME, it is required that (1) a structural\nfeature space be identified to allow reconstruction of new designs, and (2) the\nreconstruction process be property-preserving. The majority of existing\nstructural presentation schemes rely on the designer's understanding of\nspecific material systems to identify geometric and statistical features, which\ncould be biased and insufficient for reconstructing physically meaningful\nmicrostructures of complex material systems. In this paper, we develop a\nfeature learning mechanism based on convolutional deep belief network to\nautomate a two-way conversion between microstructures and their\nlower-dimensional feature representations, and to achieves a 1000-fold\ndimension reduction from the microstructure space. The proposed model is\napplied to a wide spectrum of heterogeneous material systems with distinct\nmicrostructural features including Ti-6Al-4V alloy, Pb63-Sn37 alloy,\nFontainebleau sandstone, and Spherical colloids, to produce material\nreconstructions that are close to the original samples with respect to 2-point\ncorrelation functions and mean critical fracture strength. This capability is\nnot achieved by existing synthesis methods that rely on the Markovian\nassumption of material microstructures. \n\n"}
{"id": "1612.07896", "contents": "Title: A Base Camp for Scaling AI Abstract: Modern statistical machine learning (SML) methods share a major limitation\nwith the early approaches to AI: there is no scalable way to adapt them to new\ndomains. Human learning solves this in part by leveraging a rich, shared,\nupdateable world model. Such scalability requires modularity: updating part of\nthe world model should not impact unrelated parts. We have argued that such\nmodularity will require both \"correctability\" (so that errors can be corrected\nwithout introducing new errors) and \"interpretability\" (so that we can\nunderstand what components need correcting).\n  To achieve this, one could attempt to adapt state of the art SML systems to\nbe interpretable and correctable; or one could see how far the simplest\npossible interpretable, correctable learning methods can take us, and try to\ncontrol the limitations of SML methods by applying them only where needed. Here\nwe focus on the latter approach and we investigate two main ideas: \"Teacher\nAssisted Learning\", which leverages crowd sourcing to learn language; and\n\"Factored Dialog Learning\", which factors the process of application\ndevelopment into roles where the language competencies needed are isolated,\nenabling non-experts to quickly create new applications.\n  We test these ideas in an \"Automated Personal Assistant\" (APA) setting, with\ntwo scenarios: that of detecting user intent from a user-APA dialog; and that\nof creating a class of event reminder applications, where a non-expert\n\"teacher\" can then create specific apps. For the intent detection task, we use\na dataset of a thousand labeled utterances from user dialogs with Cortana, and\nwe show that our approach matches state of the art SML methods, but in addition\nprovides full transparency: the whole (editable) model can be summarized on one\nhuman-readable page. For the reminder app task, we ran small user studies to\nverify the efficacy of the approach. \n\n"}
{"id": "1612.08354", "contents": "Title: Image-Text Multi-Modal Representation Learning by Adversarial\n  Backpropagation Abstract: We present novel method for image-text multi-modal representation learning.\nIn our knowledge, this work is the first approach of applying adversarial\nlearning concept to multi-modal learning and not exploiting image-text pair\ninformation to learn multi-modal feature. We only use category information in\ncontrast with most previous methods using image-text pair information for\nmulti-modal embedding. In this paper, we show that multi-modal feature can be\nachieved without image-text pair information and our method makes more similar\ndistribution with image and text in multi-modal feature space than other\nmethods which use image-text pair information. And we show our multi-modal\nfeature has universal semantic information, even though it was trained for\ncategory prediction. Our model is end-to-end backpropagation, intuitive and\neasily extended to other multi-modal learning work. \n\n"}
{"id": "1612.08633", "contents": "Title: A Sparse Nonlinear Classifier Design Using AUC Optimization Abstract: AUC (Area under the ROC curve) is an important performance measure for\napplications where the data is highly imbalanced. Learning to maximize AUC\nperformance is thus an important research problem. Using a max-margin based\nsurrogate loss function, AUC optimization problem can be approximated as a\npairwise rankSVM learning problem. Batch learning methods for solving the\nkernelized version of this problem suffer from scalability and may not result\nin sparse classifiers. Recent years have witnessed an increased interest in the\ndevelopment of online or single-pass online learning algorithms that design a\nclassifier by maximizing the AUC performance. The AUC performance of nonlinear\nclassifiers, designed using online methods, is not comparable with that of\nnonlinear classifiers designed using batch learning algorithms on many\nreal-world datasets. Motivated by these observations, we design a scalable\nalgorithm for maximizing AUC performance by greedily adding the required number\nof basis functions into the classifier model. The resulting sparse classifiers\nperform faster inference. Our experimental results show that the level of\nsparsity achievable can be order of magnitude smaller than the Kernel RankSVM\nmodel without affecting the AUC performance much. \n\n"}
{"id": "1612.09007", "contents": "Title: A Deep Learning Approach To Multiple Kernel Fusion Abstract: Kernel fusion is a popular and effective approach for combining multiple\nfeatures that characterize different aspects of data. Traditional approaches\nfor Multiple Kernel Learning (MKL) attempt to learn the parameters for\ncombining the kernels through sophisticated optimization procedures. In this\npaper, we propose an alternative approach that creates dense embeddings for\ndata using the kernel similarities and adopts a deep neural network\narchitecture for fusing the embeddings. In order to improve the effectiveness\nof this network, we introduce the kernel dropout regularization strategy\ncoupled with the use of an expanded set of composition kernels. Experiment\nresults on a real-world activity recognition dataset show that the proposed\narchitecture is effective in fusing kernels and achieves state-of-the-art\nperformance. \n\n"}
{"id": "1701.03577", "contents": "Title: Kernel Approximation Methods for Speech Recognition Abstract: We study large-scale kernel methods for acoustic modeling in speech\nrecognition and compare their performance to deep neural networks (DNNs). We\nperform experiments on four speech recognition datasets, including the TIMIT\nand Broadcast News benchmark tasks, and compare these two types of models on\nframe-level performance metrics (accuracy, cross-entropy), as well as on\nrecognition metrics (word/character error rate). In order to scale kernel\nmethods to these large datasets, we use the random Fourier feature method of\nRahimi and Recht (2007). We propose two novel techniques for improving the\nperformance of kernel acoustic models. First, in order to reduce the number of\nrandom features required by kernel models, we propose a simple but effective\nmethod for feature selection. The method is able to explore a large number of\nnon-linear features while maintaining a compact model more efficiently than\nexisting approaches. Second, we present a number of frame-level metrics which\ncorrelate very strongly with recognition performance when computed on the\nheldout set; we take advantage of these correlations by monitoring these\nmetrics during training in order to decide when to stop learning. This\ntechnique can noticeably improve the recognition performance of both DNN and\nkernel models, while narrowing the gap between them. Additionally, we show that\nthe linear bottleneck method of Sainath et al. (2013) improves the performance\nof our kernel models significantly, in addition to speeding up training and\nmaking the models more compact. Together, these three methods dramatically\nimprove the performance of kernel acoustic models, making their performance\ncomparable to DNNs on the tasks we explored. \n\n"}
{"id": "1701.04222", "contents": "Title: Achieving Privacy in the Adversarial Multi-Armed Bandit Abstract: In this paper, we improve the previously best known regret bound to achieve\n$\\epsilon$-differential privacy in oblivious adversarial bandits from\n$\\mathcal{O}{(T^{2/3}/\\epsilon)}$ to $\\mathcal{O}{(\\sqrt{T} \\ln T /\\epsilon)}$.\nThis is achieved by combining a Laplace Mechanism with EXP3. We show that\nthough EXP3 is already differentially private, it leaks a linear amount of\ninformation in $T$. However, we can improve this privacy by relying on its\nintrinsic exponential mechanism for selecting actions. This allows us to reach\n$\\mathcal{O}{(\\sqrt{\\ln T})}$-DP, with a regret of $\\mathcal{O}{(T^{2/3})}$\nthat holds against an adaptive adversary, an improvement from the best known of\n$\\mathcal{O}{(T^{3/4})}$. This is done by using an algorithm that run EXP3 in a\nmini-batch loop. Finally, we run experiments that clearly demonstrate the\nvalidity of our theoretical analysis. \n\n"}
{"id": "1701.05265", "contents": "Title: Online Structure Learning for Sum-Product Networks with Gaussian Leaves Abstract: Sum-product networks have recently emerged as an attractive representation\ndue to their dual view as a special type of deep neural network with clear\nsemantics and a special type of probabilistic graphical model for which\ninference is always tractable. Those properties follow from some conditions\n(i.e., completeness and decomposability) that must be respected by the\nstructure of the network. As a result, it is not easy to specify a valid\nsum-product network by hand and therefore structure learning techniques are\ntypically used in practice. This paper describes the first online structure\nlearning technique for continuous SPNs with Gaussian leaves. We also introduce\nan accompanying new parameter learning technique. \n\n"}
{"id": "1701.06106", "contents": "Title: Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a\n  Changing World Abstract: In this paper, we focus on online representation learning in non-stationary\nenvironments which may require continuous adaptation of model architecture. We\npropose a novel online dictionary-learning (sparse-coding) framework which\nincorporates the addition and deletion of hidden units (dictionary elements),\nand is inspired by the adult neurogenesis phenomenon in the dentate gyrus of\nthe hippocampus, known to be associated with improved cognitive function and\nadaptation to new environments. In the online learning setting, where new input\ninstances arrive sequentially in batches, the neuronal-birth is implemented by\nadding new units with random initial weights (random dictionary elements); the\nnumber of new units is determined by the current performance (representation\nerror) of the dictionary, higher error causing an increase in the birth rate.\nNeuronal-death is implemented by imposing l1/l2-regularization (group sparsity)\non the dictionary within the block-coordinate descent optimization at each\niteration of our online alternating minimization scheme, which iterates between\nthe code and dictionary updates. Finally, hidden unit connectivity adaptation\nis facilitated by introducing sparsity in dictionary elements. Our empirical\nevaluation on several real-life datasets (images and language) as well as on\nsynthetic data demonstrates that the proposed approach can considerably\noutperform the state-of-art fixed-size (nonadaptive) online sparse coding of\nMairal et al. (2009) in the presence of nonstationary data. Moreover, we\nidentify certain properties of the data (e.g., sparse inputs with nearly\nnon-overlapping supports) and of the model (e.g., dictionary sparsity)\nassociated with such improvements. \n\n"}
{"id": "1701.08974", "contents": "Title: Towards Adversarial Retinal Image Synthesis Abstract: Synthesizing images of the eye fundus is a challenging task that has been\npreviously approached by formulating complex models of the anatomy of the eye.\nNew images can then be generated by sampling a suitable parameter space. In\nthis work, we propose a method that learns to synthesize eye fundus images\ndirectly from data. For that, we pair true eye fundus images with their\nrespective vessel trees, by means of a vessel segmentation technique. These\npairs are then used to learn a mapping from a binary vessel tree to a new\nretinal image. For this purpose, we use a recent image-to-image translation\ntechnique, based on the idea of adversarial learning. Experimental results show\nthat the original and the generated images are visually different in terms of\ntheir global appearance, in spite of sharing the same vessel tree.\nAdditionally, a quantitative quality analysis of the synthetic retinal images\nconfirms that the produced images retain a high proportion of the true image\nset quality. \n\n"}
{"id": "1702.00833", "contents": "Title: Recurrent Neural Networks for anomaly detection in the Post-Mortem time\n  series of LHC superconducting magnets Abstract: This paper presents a model based on Deep Learning algorithms of LSTM and GRU\nfor facilitating an anomaly detection in Large Hadron Collider superconducting\nmagnets. We used high resolution data available in Post Mortem database to\ntrain a set of models and chose the best possible set of their\nhyper-parameters. Using Deep Learning approach allowed to examine a vast body\nof data and extract the fragments which require further experts examination and\nare regarded as anomalies. The presented method does not require tedious manual\nthreshold setting and operator attention at the stage of the system setup.\nInstead, the automatic approach is proposed, which achieves according to our\nexperiments accuracy of 99%. This is reached for the largest dataset of 302 MB\nand the following architecture of the network: single layer LSTM, 128 cells, 20\nepochs of training, look_back=16, look_ahead=128, grid=100 and optimizer Adam.\nAll the experiments were run on GPU Nvidia Tesla K80 \n\n"}
{"id": "1702.00953", "contents": "Title: Deep Learning with Low Precision by Half-wave Gaussian Quantization Abstract: The problem of quantizing the activations of a deep neural network is\nconsidered. An examination of the popular binary quantization approach shows\nthat this consists of approximating a classical non-linearity, the hyperbolic\ntangent, by two functions: a piecewise constant sign function, which is used in\nfeedforward network computations, and a piecewise linear hard tanh function,\nused in the backpropagation step during network learning. The problem of\napproximating the ReLU non-linearity, widely used in the recent deep learning\nliterature, is then considered. An half-wave Gaussian quantizer (HWGQ) is\nproposed for forward approximation and shown to have efficient implementation,\nby exploiting the statistics of of network activations and batch normalization\noperations commonly used in the literature. To overcome the problem of gradient\nmismatch, due to the use of different forward and backward approximations,\nseveral piece-wise backward approximators are then investigated. The\nimplementation of the resulting quantized network, denoted as HWGQ-Net, is\nshown to achieve much closer performance to full precision networks, such as\nAlexNet, ResNet, GoogLeNet and VGG-Net, than previously available low-precision\nnetworks, with 1-bit binary weights and 2-bit quantized activations. \n\n"}
{"id": "1702.01334", "contents": "Title: An Experimental Study of Deep Convolutional Features For Iris\n  Recognition Abstract: Iris is one of the popular biometrics that is widely used for identity\nauthentication. Different features have been used to perform iris recognition\nin the past. Most of them are based on hand-crafted features designed by\nbiometrics experts. Due to tremendous success of deep learning in computer\nvision problems, there has been a lot of interest in applying features learned\nby convolutional neural networks on general image recognition to other tasks\nsuch as segmentation, face recognition, and object detection. In this paper, we\nhave investigated the application of deep features extracted from VGG-Net for\niris recognition. The proposed scheme has been tested on two well-known iris\ndatabases, and has shown promising results with the best accuracy rate of\n99.4\\%, which outperforms the previous best result. \n\n"}
{"id": "1702.01991", "contents": "Title: Representations of language in a model of visually grounded speech\n  signal Abstract: We present a visually grounded model of speech perception which projects\nspoken utterances and images to a joint semantic space. We use a multi-layer\nrecurrent highway network to model the temporal nature of spoken speech, and\nshow that it learns to extract both form and meaning-based linguistic knowledge\nfrom the input signal. We carry out an in-depth analysis of the representations\nused by different components of the trained model and show that encoding of\nsemantic aspects tends to become richer as we go up the hierarchy of layers,\nwhereas encoding of form-related aspects of the language input tends to\ninitially increase and then plateau or decrease. \n\n"}
{"id": "1702.03920", "contents": "Title: Cognitive Mapping and Planning for Visual Navigation Abstract: We introduce a neural architecture for navigation in novel environments. Our\nproposed architecture learns to map from first-person views and plans a\nsequence of actions towards goals in the environment. The Cognitive Mapper and\nPlanner (CMP) is based on two key ideas: a) a unified joint architecture for\nmapping and planning, such that the mapping is driven by the needs of the task,\nand b) a spatial memory with the ability to plan given an incomplete set of\nobservations about the world. CMP constructs a top-down belief map of the world\nand applies a differentiable neural net planner to produce the next action at\neach time step. The accumulated belief of the world enables the agent to track\nvisited regions of the environment. We train and test CMP on navigation\nproblems in simulation environments derived from scans of real world buildings.\nOur experiments demonstrate that CMP outperforms alternate learning-based\narchitectures, as well as, classical mapping and path planning approaches in\nmany cases. Furthermore, it naturally extends to semantically specified goals,\nsuch as 'going to a chair'. We also deploy CMP on physical robots in indoor\nenvironments, where it achieves reasonable performance, even though it is\ntrained entirely in simulation. \n\n"}
{"id": "1702.04521", "contents": "Title: Frustratingly Short Attention Spans in Neural Language Modeling Abstract: Neural language models predict the next token using a latent representation\nof the immediate token history. Recently, various methods for augmenting neural\nlanguage models with an attention mechanism over a differentiable memory have\nbeen proposed. For predicting the next token, these models query information\nfrom a memory of the recent history which can facilitate learning mid- and\nlong-range dependencies. However, conventional attention mechanisms used in\nmemory-augmented neural language models produce a single output vector per time\nstep. This vector is used both for predicting the next token as well as for the\nkey and value of a differentiable memory of a token history. In this paper, we\npropose a neural language model with a key-value attention mechanism that\noutputs separate representations for the key and value of a differentiable\nmemory, as well as for encoding the next-word distribution. This model\noutperforms existing memory-augmented neural language models on two corpora.\nYet, we found that our method mainly utilizes a memory of the five most recent\noutput representations. This led to the unexpected main finding that a much\nsimpler model based only on the concatenation of recent output representations\nfrom previous time steps is on par with more sophisticated memory-augmented\nneural language models. \n\n"}
{"id": "1702.04782", "contents": "Title: Precise Recovery of Latent Vectors from Generative Adversarial Networks Abstract: Generative adversarial networks (GANs) transform latent vectors into visually\nplausible images. It is generally thought that the original GAN formulation\ngives no out-of-the-box method to reverse the mapping, projecting images back\ninto latent space. We introduce a simple, gradient-based technique called\nstochastic clipping. In experiments, for images generated by the GAN, we\nprecisely recover their latent vector pre-images 100% of the time. Additional\nexperiments demonstrate that this method is robust to noise. Finally, we show\nthat even for unseen images, our method appears to recover unique encodings. \n\n"}
{"id": "1702.07450", "contents": "Title: Strongly-Typed Agents are Guaranteed to Interact Safely Abstract: As artificial agents proliferate, it is becoming increasingly important to\nensure that their interactions with one another are well-behaved. In this\npaper, we formalize a common-sense notion of when algorithms are well-behaved:\nan algorithm is safe if it does no harm. Motivated by recent progress in deep\nlearning, we focus on the specific case where agents update their actions\naccording to gradient descent. The paper shows that that gradient descent\nconverges to a Nash equilibrium in safe games. The main contribution is to\ndefine strongly-typed agents and show they are guaranteed to interact safely,\nthereby providing sufficient conditions to guarantee safe interactions. A\nseries of examples show that strong-typing generalizes certain key features of\nconvexity, is closely related to blind source separation, and introduces a new\nperspective on classical multilinear games based on tensor decomposition. \n\n"}
{"id": "1702.08530", "contents": "Title: Semi-parametric Network Structure Discovery Models Abstract: We propose a network structure discovery model for continuous observations\nthat generalizes linear causal models by incorporating a Gaussian process (GP)\nprior on a network-independent component, and random sparsity and weight\nmatrices as the network-dependent parameters. This approach provides flexible\nmodeling of network-independent trends in the observations as well as\nuncertainty quantification around the discovered network structure. We\nestablish a connection between our model and multi-task GPs and develop an\nefficient stochastic variational inference algorithm for it. Furthermore, we\nformally show that our approach is numerically stable and in fact numerically\neasy to carry out almost everywhere on the support of the random variables\ninvolved. Finally, we evaluate our model on three applications, showing that it\noutperforms previous approaches. We provide a qualitative and quantitative\nanalysis of the structures discovered for domains such as the study of the full\ngenome regulation of the yeast Saccharomyces cerevisiae. \n\n"}
{"id": "1702.08567", "contents": "Title: Optimal Experiment Design for Causal Discovery from Fixed Number of\n  Experiments Abstract: We study the problem of causal structure learning over a set of random\nvariables when the experimenter is allowed to perform at most $M$ experiments\nin a non-adaptive manner. We consider the optimal learning strategy in terms of\nminimizing the portions of the structure that remains unknown given the limited\nnumber of experiments in both Bayesian and minimax setting. We characterize the\ntheoretical optimal solution and propose an algorithm, which designs the\nexperiments efficiently in terms of time complexity. We show that for bounded\ndegree graphs, in the minimax case and in the Bayesian case with uniform\npriors, our proposed algorithm is a $\\rho$-approximation algorithm, where\n$\\rho$ is independent of the order of the underlying graph. Simulations on both\nsynthetic and real data show that the performance of our algorithm is very\nclose to the optimal solution. \n\n"}
{"id": "1702.08591", "contents": "Title: The Shattered Gradients Problem: If resnets are the answer, then what is\n  the question? Abstract: A long-standing obstacle to progress in deep learning is the problem of\nvanishing and exploding gradients. Although, the problem has largely been\novercome via carefully constructed initializations and batch normalization,\narchitectures incorporating skip-connections such as highway and resnets\nperform much better than standard feedforward architectures despite well-chosen\ninitialization and batch normalization. In this paper, we identify the\nshattered gradients problem. Specifically, we show that the correlation between\ngradients in standard feedforward networks decays exponentially with depth\nresulting in gradients that resemble white noise whereas, in contrast, the\ngradients in architectures with skip-connections are far more resistant to\nshattering, decaying sublinearly. Detailed empirical evidence is presented in\nsupport of the analysis, on both fully-connected networks and convnets.\nFinally, we present a new \"looks linear\" (LL) initialization that prevents\nshattering, with preliminary experiments showing the new initialization allows\nto train very deep networks without the addition of skip-connections. \n\n"}
{"id": "1703.00119", "contents": "Title: Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to\n  Non-smooth Concave Maximization Abstract: Iterative Hard Thresholding (IHT) is a class of projected gradient descent\nmethods for optimizing sparsity-constrained minimization models, with the best\nknown efficiency and scalability in practice. As far as we know, the existing\nIHT-style methods are designed for sparse minimization in primal form. It\nremains open to explore duality theory and algorithms in such a non-convex and\nNP-hard problem setting. In this paper, we bridge this gap by establishing a\nduality theory for sparsity-constrained minimization with $\\ell_2$-regularized\nloss function and proposing an IHT-style algorithm for dual maximization. Our\nsparse duality theory provides a set of sufficient and necessary conditions\nunder which the original NP-hard/non-convex problem can be equivalently solved\nin a dual formulation. The proposed dual IHT algorithm is a super-gradient\nmethod for maximizing the non-smooth dual objective. An interesting finding is\nthat the sparse recovery performance of dual IHT is invariant to the Restricted\nIsometry Property (RIP), which is required by virtually all the existing primal\nIHT algorithms without sparsity relaxation. Moreover, a stochastic variant of\ndual IHT is proposed for large-scale stochastic optimization. Numerical results\ndemonstrate the superiority of dual IHT algorithms to the state-of-the-art\nprimal IHT-style algorithms in model estimation accuracy and computational\nefficiency. \n\n"}
{"id": "1703.00439", "contents": "Title: Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for\n  Regularized Empirical Risk Minimization Abstract: In this paper, we develop a new accelerated stochastic gradient method for\nefficiently solving the convex regularized empirical risk minimization problem\nin mini-batch settings. The use of mini-batches is becoming a golden standard\nin the machine learning community, because mini-batch settings stabilize the\ngradient estimate and can easily make good use of parallel computing. The core\nof our proposed method is the incorporation of our new \"double acceleration\"\ntechnique and variance reduction technique. We theoretically analyze our\nproposed method and show that our method much improves the mini-batch\nefficiencies of previous accelerated stochastic methods, and essentially only\nneeds size $\\sqrt{n}$ mini-batches for achieving the optimal iteration\ncomplexities for both non-strongly and strongly convex objectives, where $n$ is\nthe training set size. Further, we show that even in non-mini-batch settings,\nour method achieves the best known convergence rate for both non-strongly and\nstrongly convex objectives. \n\n"}
{"id": "1703.00757", "contents": "Title: Predicting Rankings of Software Verification Competitions Abstract: Software verification competitions, such as the annual SV-COMP, evaluate\nsoftware verification tools with respect to their effectivity and efficiency.\nTypically, the outcome of a competition is a (possibly category-specific)\nranking of the tools. For many applications, such as building portfolio\nsolvers, it would be desirable to have an idea of the (relative) performance of\nverification tools on a given verification task beforehand, i.e., prior to\nactually running all tools on the task.\n  In this paper, we present a machine learning approach to predicting rankings\nof tools on verification tasks. The method builds upon so-called label ranking\nalgorithms, which we complement with appropriate kernels providing a similarity\nmeasure for verification tasks. Our kernels employ a graph representation for\nsoftware source code that mixes elements of control flow and program dependence\ngraphs with abstract syntax trees. Using data sets from SV-COMP, we demonstrate\nour rank prediction technique to generalize well and achieve a rather high\npredictive accuracy. In particular, our method outperforms a recently proposed\nfeature-based approach of Demyanova et al. (when applied to rank predictions). \n\n"}
{"id": "1703.00810", "contents": "Title: Opening the Black Box of Deep Neural Networks via Information Abstract: Despite their great success, there is still no comprehensive theoretical\nunderstanding of learning with Deep Neural Networks (DNNs) or their inner\norganization. Previous work proposed to analyze DNNs in the \\textit{Information\nPlane}; i.e., the plane of the Mutual Information values that each layer\npreserves on the input and output variables. They suggested that the goal of\nthe network is to optimize the Information Bottleneck (IB) tradeoff between\ncompression and prediction, successively, for each layer.\n  In this work we follow up on this idea and demonstrate the effectiveness of\nthe Information-Plane visualization of DNNs. Our main results are: (i) most of\nthe training epochs in standard DL are spent on {\\emph compression} of the\ninput to efficient representation and not on fitting the training labels. (ii)\nThe representation compression phase begins when the training errors becomes\nsmall and the Stochastic Gradient Decent (SGD) epochs change from a fast drift\nto smaller training error into a stochastic relaxation, or random diffusion,\nconstrained by the training error value. (iii) The converged layers lie on or\nvery close to the Information Bottleneck (IB) theoretical bound, and the maps\nfrom the input to any hidden layer and from this hidden layer to the output\nsatisfy the IB self-consistent equations. This generalization through noise\nmechanism is unique to Deep Neural Networks and absent in one layer networks.\n(iv) The training time is dramatically reduced when adding more hidden layers.\nThus the main advantage of the hidden layers is computational. This can be\nexplained by the reduced relaxation time, as this it scales super-linearly\n(exponentially for simple diffusion) with the information compression from the\nprevious layer. \n\n"}
{"id": "1703.01014", "contents": "Title: Active Learning for Cost-Sensitive Classification Abstract: We design an active learning algorithm for cost-sensitive multiclass\nclassification: problems where different errors have different costs. Our\nalgorithm, COAL, makes predictions by regressing to each label's cost and\npredicting the smallest. On a new example, it uses a set of regressors that\nperform well on past data to estimate possible costs for each label. It queries\nonly the labels that could be the best, ignoring the sure losers. We prove COAL\ncan be efficiently implemented for any regression family that admits squared\nloss optimization; it also enjoys strong guarantees with respect to predictive\nperformance and labeling effort. We empirically compare COAL to passive\nlearning and several active learning baselines, showing significant\nimprovements in labeling effort and test cost on real-world datasets. \n\n"}
{"id": "1703.01014", "contents": "Title: Active Learning for Cost-Sensitive Classification Abstract: We design an active learning algorithm for cost-sensitive multiclass\nclassification: problems where different errors have different costs. Our\nalgorithm, COAL, makes predictions by regressing to each label's cost and\npredicting the smallest. On a new example, it uses a set of regressors that\nperform well on past data to estimate possible costs for each label. It queries\nonly the labels that could be the best, ignoring the sure losers. We prove COAL\ncan be efficiently implemented for any regression family that admits squared\nloss optimization; it also enjoys strong guarantees with respect to predictive\nperformance and labeling effort. We empirically compare COAL to passive\nlearning and several active learning baselines, showing significant\nimprovements in labeling effort and test cost on real-world datasets. \n\n"}
{"id": "1703.02914", "contents": "Title: Dropout Inference in Bayesian Neural Networks with Alpha-divergences Abstract: To obtain uncertainty estimates with real-world Bayesian deep learning\nmodels, practical inference approximations are needed. Dropout variational\ninference (VI) for example has been used for machine vision and medical\napplications, but VI can severely underestimates model uncertainty.\nAlpha-divergences are alternative divergences to VI's KL objective, which are\nable to avoid VI's uncertainty underestimation. But these are hard to use in\npractice: existing techniques can only use Gaussian approximating\ndistributions, and require existing models to be changed radically, thus are of\nlimited use for practitioners. We propose a re-parametrisation of the\nalpha-divergence objectives, deriving a simple inference technique which,\ntogether with dropout, can be easily implemented with existing models by simply\nchanging the loss of the model. We demonstrate improved uncertainty estimates\nand accuracy compared to VI in dropout networks. We study our model's epistemic\nuncertainty far away from the data using adversarial images, showing that these\ncan be distinguished from non-adversarial images by examining our model's\nuncertainty. \n\n"}
{"id": "1703.03074", "contents": "Title: Efficient computational strategies to learn the structure of\n  probabilistic graphical models of cumulative phenomena Abstract: Structural learning of Bayesian Networks (BNs) is a NP-hard problem, which is\nfurther complicated by many theoretical issues, such as the I-equivalence among\ndifferent structures. In this work, we focus on a specific subclass of BNs,\nnamed Suppes-Bayes Causal Networks (SBCNs), which include specific structural\nconstraints based on Suppes' probabilistic causation to efficiently model\ncumulative phenomena. Here we compare the performance, via extensive\nsimulations, of various state-of-the-art search strategies, such as local\nsearch techniques and Genetic Algorithms, as well as of distinct regularization\nmethods. The assessment is performed on a large number of simulated datasets\nfrom topologies with distinct levels of complexity, various sample size and\ndifferent rates of errors in the data. Among the main results, we show that the\nintroduction of Suppes' constraints dramatically improve the inference\naccuracy, by reducing the solution space and providing a temporal ordering on\nthe variables. We also report on trade-offs among different search techniques\nthat can be efficiently employed in distinct experimental settings. This\nmanuscript is an extended version of the paper \"Structural Learning of\nProbabilistic Graphical Models of Cumulative Phenomena\" presented at the 2018\nInternational Conference on Computational Science. \n\n"}
{"id": "1703.03454", "contents": "Title: Sample Efficient Feature Selection for Factored MDPs Abstract: In reinforcement learning, the state of the real world is often represented\nby feature vectors. However, not all of the features may be pertinent for\nsolving the current task. We propose Feature Selection Explore and Exploit\n(FS-EE), an algorithm that automatically selects the necessary features while\nlearning a Factored Markov Decision Process, and prove that under mild\nassumptions, its sample complexity scales with the in-degree of the dynamics of\njust the necessary features, rather than the in-degree of all features. This\ncan result in a much better sample complexity when the in-degree of the\nnecessary features is smaller than the in-degree of all features. \n\n"}
{"id": "1703.03862", "contents": "Title: Joint Embedding of Graphs Abstract: Feature extraction and dimension reduction for networks is critical in a wide\nvariety of domains. Efficiently and accurately learning features for multiple\ngraphs has important applications in statistical inference on graphs. We\npropose a method to jointly embed multiple undirected graphs. Given a set of\ngraphs, the joint embedding method identifies a linear subspace spanned by rank\none symmetric matrices and projects adjacency matrices of graphs into this\nsubspace. The projection coefficients can be treated as features of the graphs,\nwhile the embedding components can represent vertex features. We also propose a\nrandom graph model for multiple graphs that generalizes other classical models\nfor graphs. We show through theory and numerical experiments that under the\nmodel, the joint embedding method produces estimates of parameters with small\nerrors. Via simulation experiments, we demonstrate that the joint embedding\nmethod produces features which lead to state of the art performance in\nclassifying graphs. Applying the joint embedding method to human brain graphs,\nwe find it extracts interpretable features with good prediction accuracy in\ndifferent tasks. \n\n"}
{"id": "1703.04730", "contents": "Title: Understanding Black-box Predictions via Influence Functions Abstract: How can we explain the predictions of a black-box model? In this paper, we\nuse influence functions -- a classic technique from robust statistics -- to\ntrace a model's prediction through the learning algorithm and back to its\ntraining data, thereby identifying training points most responsible for a given\nprediction. To scale up influence functions to modern machine learning\nsettings, we develop a simple, efficient implementation that requires only\noracle access to gradients and Hessian-vector products. We show that even on\nnon-convex and non-differentiable models where the theory breaks down,\napproximations to influence functions can still provide valuable information.\nOn linear models and convolutional neural networks, we demonstrate that\ninfluence functions are useful for multiple purposes: understanding model\nbehavior, debugging models, detecting dataset errors, and even creating\nvisually-indistinguishable training-set attacks. \n\n"}
{"id": "1703.04785", "contents": "Title: Distributed Dual Coordinate Ascent in General Tree Networks and\n  Communication Network Effect on Synchronous Machine Learning Abstract: Due to the big size of data and limited data storage volume of a single\ncomputer or a single server, data are often stored in a distributed manner.\nThus, performing large-scale machine learning operations with the distributed\ndatasets through communication networks is often required. In this paper, we\nstudy the convergence rate of the distributed dual coordinate ascent for\ndistributed machine learning problems in a general tree-structured network.\nSince a tree network model can be understood as the generalization of a star\nnetwork model, our algorithm can be thought of as the generalization of the\ndistributed dual coordinate ascent in a star network model. We provide the\nconvergence rate of the distributed dual coordinate ascent over a general tree\nnetwork in a recursive manner and analyze the network effect on the convergence\nrate. Secondly, by considering network communication delays, we optimize the\ndistributed dual coordinate ascent algorithm to maximize its convergence speed.\nFrom our analytical result, we can choose the optimal number of local\niterations depending on the communication delay severity to achieve the fastest\nconvergence speed. In numerical experiments, we consider machine learning\nscenarios over communication networks, where local workers cannot directly\nreach to a central node due to constraints in communication, and demonstrate\nthat the usability of our distributed dual coordinate ascent algorithm in tree\nnetworks. Additionally, we show that adapting number of local and global\niterations to network communication delays in the distributed dual coordinated\nascent algorithm can improve its convergence speed. \n\n"}
{"id": "1703.05449", "contents": "Title: Minimax Regret Bounds for Reinforcement Learning Abstract: We consider the problem of provably optimal exploration in reinforcement\nlearning for finite horizon MDPs. We show that an optimistic modification to\nvalue iteration achieves a regret bound of $\\tilde{O}( \\sqrt{HSAT} +\nH^2S^2A+H\\sqrt{T})$ where $H$ is the time horizon, $S$ the number of states,\n$A$ the number of actions and $T$ the number of time-steps. This result\nimproves over the best previous known bound $\\tilde{O}(HS \\sqrt{AT})$ achieved\nby the UCRL2 algorithm of Jaksch et al., 2010. The key significance of our new\nresults is that when $T\\geq H^3S^3A$ and $SA\\geq H$, it leads to a regret of\n$\\tilde{O}(\\sqrt{HSAT})$ that matches the established lower bound of\n$\\Omega(\\sqrt{HSAT})$ up to a logarithmic factor. Our analysis contains two key\ninsights. We use careful application of concentration inequalities to the\noptimal value function as a whole, rather than to the transitions probabilities\n(to improve scaling in $S$), and we define Bernstein-based \"exploration\nbonuses\" that use the empirical variance of the estimated values at the next\nstates (to improve scaling in $H$). \n\n"}
{"id": "1703.06857", "contents": "Title: On the Limitation of Convolutional Neural Networks in Recognizing\n  Negative Images Abstract: Convolutional Neural Networks (CNNs) have achieved state-of-the-art\nperformance on a variety of computer vision tasks, particularly visual\nclassification problems, where new algorithms reported to achieve or even\nsurpass the human performance. In this paper, we examine whether CNNs are\ncapable of learning the semantics of training data. To this end, we evaluate\nCNNs on negative images, since they share the same structure and semantics as\nregular images and humans can classify them correctly. Our experimental results\nindicate that when training on regular images and testing on negative images,\nthe model accuracy is significantly lower than when it is tested on regular\nimages. This leads us to the conjecture that current training methods do not\neffectively train models to generalize the concepts. We then introduce the\nnotion of semantic adversarial examples - transformed inputs that semantically\nrepresent the same objects, but the model does not classify them correctly -\nand present negative images as one class of such inputs. \n\n"}
{"id": "1703.06898", "contents": "Title: De Sitter Stability and Coarse Graining Abstract: We present a 4-dimensional back reaction analysis of de Sitter space for a\nconformally coupled scalar field in the presence of vacuum energy initialized\nin the Bunch-Davies vacuum. In contrast to the usual semi-classical\nprescription, as the source term in the Friedmann equations we use expectation\nvalues where the unobservable information hidden by the cosmological event\nhorizon has been neglected i.e. coarse grained over. It is shown that in this\napproach the energy-momentum is precisely thermal with constant temperature\ndespite the dilution from the expansion of space due to a flux of energy\nradiated from the horizon. This leads to a self-consistent solution for the\nHubble rate, which is gradually evolving and at late times deviates\nsignificantly from de Sitter. Our results hence imply de Sitter space to be\nunstable in this prescription. The solution also suggests dynamical vacuum\nenergy: the continuous flux of energy is balanced by the generation of negative\nvacuum energy, which accumulatively decreases the overall contribution.\nFinally, we show that our results admit a thermodynamic interpretation which\nprovides a simple alternate derivation of the mechanism. For very long times\nthe solutions coincide with flat space. \n\n"}
{"id": "1703.07022", "contents": "Title: Recurrent Topic-Transition GAN for Visual Paragraph Generation Abstract: A natural image usually conveys rich semantic content and can be viewed from\ndifferent angles. Existing image description methods are largely restricted by\nsmall sets of biased visual paragraph annotations, and fail to cover rich\nunderlying semantics. In this paper, we investigate a semi-supervised paragraph\ngenerative framework that is able to synthesize diverse and semantically\ncoherent paragraph descriptions by reasoning over local semantic regions and\nexploiting linguistic knowledge. The proposed Recurrent Topic-Transition\nGenerative Adversarial Network (RTT-GAN) builds an adversarial framework\nbetween a structured paragraph generator and multi-level paragraph\ndiscriminators. The paragraph generator generates sentences recurrently by\nincorporating region-based visual and language attention mechanisms at each\nstep. The quality of generated paragraph sentences is assessed by multi-level\nadversarial discriminators from two aspects, namely, plausibility at sentence\nlevel and topic-transition coherence at paragraph level. The joint adversarial\ntraining of RTT-GAN drives the model to generate realistic paragraphs with\nsmooth logical transition between sentence topics. Extensive quantitative\nexperiments on image and video paragraph datasets demonstrate the effectiveness\nof our RTT-GAN in both supervised and semi-supervised settings. Qualitative\nresults on telling diverse stories for an image also verify the\ninterpretability of RTT-GAN. \n\n"}
{"id": "1703.07608", "contents": "Title: Deep Exploration via Randomized Value Functions Abstract: We study the use of randomized value functions to guide deep exploration in\nreinforcement learning. This offers an elegant means for synthesizing\nstatistically and computationally efficient exploration with common practical\napproaches to value function learning. We present several reinforcement\nlearning algorithms that leverage randomized value functions and demonstrate\ntheir efficacy through computational studies. We also prove a regret bound that\nestablishes statistical efficiency with a tabular representation. \n\n"}
{"id": "1703.09207", "contents": "Title: Fairness in Criminal Justice Risk Assessments: The State of the Art Abstract: Objectives: Discussions of fairness in criminal justice risk assessments\ntypically lack conceptual precision. Rhetoric too often substitutes for careful\nanalysis. In this paper, we seek to clarify the tradeoffs between different\nkinds of fairness and between fairness and accuracy.\n  Methods: We draw on the existing literatures in criminology, computer science\nand statistics to provide an integrated examination of fairness and accuracy in\ncriminal justice risk assessments. We also provide an empirical illustration\nusing data from arraignments.\n  Results: We show that there are at least six kinds of fairness, some of which\nare incompatible with one another and with accuracy.\n  Conclusions: Except in trivial cases, it is impossible to maximize accuracy\nand fairness at the same time, and impossible simultaneously to satisfy all\nkinds of fairness. In practice, a major complication is different base rates\nacross different legally protected groups. There is a need to consider\nchallenging tradeoffs. \n\n"}
{"id": "1703.09938", "contents": "Title: Grouped Convolutional Neural Networks for Multivariate Time Series Abstract: Analyzing multivariate time series data is important for many applications\nsuch as automated control, fault diagnosis and anomaly detection. One of the\nkey challenges is to learn latent features automatically from dynamically\nchanging multivariate input. In visual recognition tasks, convolutional neural\nnetworks (CNNs) have been successful to learn generalized feature extractors\nwith shared parameters over the spatial domain. However, when high-dimensional\nmultivariate time series is given, designing an appropriate CNN model structure\nbecomes challenging because the kernels may need to be extended through the\nfull dimension of the input volume. To address this issue, we present two\nstructure learning algorithms for deep CNN models. Our algorithms exploit the\ncovariance structure over multiple time series to partition input volume into\ngroups. The first algorithm learns the group CNN structures explicitly by\nclustering individual input sequences. The second algorithm learns the group\nCNN structures implicitly from the error backpropagation. In experiments with\ntwo real-world datasets, we demonstrate that our group CNNs outperform existing\nCNN based regression methods. \n\n"}
{"id": "1703.10444", "contents": "Title: On Fundamental Limits of Robust Learning Abstract: We consider the problems of robust PAC learning from distributed and\nstreaming data, which may contain malicious errors and outliers, and analyze\ntheir fundamental complexity questions. In particular, we establish lower\nbounds on the communication complexity for distributed robust learning\nperformed on multiple machines, and on the space complexity for robust learning\nfrom streaming data on a single machine. These results demonstrate that gaining\nrobustness of learning algorithms is usually at the expense of increased\ncomplexities. As far as we know, this work gives the first complexity results\nfor distributed and online robust PAC learning. \n\n"}
{"id": "1703.10571", "contents": "Title: Bootstrapping Labelled Dataset Construction for Cow Tracking and\n  Behavior Analysis Abstract: This paper introduces a new approach to the long-term tracking of an object\nin a challenging environment. The object is a cow and the environment is an\nenclosure in a cowshed. Some of the key challenges in this domain are a\ncluttered background, low contrast and high similarity between moving objects\nwhich greatly reduces the efficiency of most existing approaches, including\nthose based on background subtraction. Our approach is split into object\nlocalization, instance segmentation, learning and tracking stages. Our solution\nis compared to a range of semi-supervised object tracking algorithms and we\nshow that the performance is strong and well suited to subsequent analysis. We\npresent our solution as a first step towards broader tracking and behavior\nmonitoring for cows in precision agriculture with the ultimate objective of\nearly detection of lameness. \n\n"}
{"id": "1703.10931", "contents": "Title: Sentence Simplification with Deep Reinforcement Learning Abstract: Sentence simplification aims to make sentences easier to read and understand.\nMost recent approaches draw on insights from machine translation to learn\nsimplification rewrites from monolingual corpora of complex and simple\nsentences. We address the simplification problem with an encoder-decoder model\ncoupled with a deep reinforcement learning framework. Our model, which we call\n{\\sc Dress} (as shorthand for {\\bf D}eep {\\bf RE}inforcement {\\bf S}entence\n{\\bf S}implification), explores the space of possible simplifications while\nlearning to optimize a reward function that encourages outputs which are\nsimple, fluent, and preserve the meaning of the input. Experiments on three\ndatasets demonstrate that our model outperforms competitive simplification\nsystems. \n\n"}
{"id": "1704.00637", "contents": "Title: Semi-Supervised Generation with Cluster-aware Generative Models Abstract: Deep generative models trained with large amounts of unlabelled data have\nproven to be powerful within the domain of unsupervised learning. Many real\nlife data sets contain a small amount of labelled data points, that are\ntypically disregarded when training generative models. We propose the\nCluster-aware Generative Model, that uses unlabelled information to infer a\nlatent representation that models the natural clustering of the data, and\nadditional labelled data points to refine this clustering. The generative\nperformances of the model significantly improve when labelled information is\nexploited, obtaining a log-likelihood of -79.38 nats on permutation invariant\nMNIST, while also achieving competitive semi-supervised classification\naccuracies. The model can also be trained fully unsupervised, and still improve\nthe log-likelihood performance with respect to related methods. \n\n"}
{"id": "1704.01858", "contents": "Title: An Online Hierarchical Algorithm for Extreme Clustering Abstract: Many modern clustering methods scale well to a large number of data items, N,\nbut not to a large number of clusters, K. This paper introduces PERCH, a new\nnon-greedy algorithm for online hierarchical clustering that scales to both\nmassive N and K--a problem setting we term extreme clustering. Our algorithm\nefficiently routes new data points to the leaves of an incrementally-built\ntree. Motivated by the desire for both accuracy and speed, our approach\nperforms tree rotations for the sake of enhancing subtree purity and\nencouraging balancedness. We prove that, under a natural separability\nassumption, our non-greedy algorithm will produce trees with perfect dendrogram\npurity regardless of online data arrival order. Our experiments demonstrate\nthat PERCH constructs more accurate trees than other tree-building clustering\nalgorithms and scales well with both N and K, achieving a higher quality\nclustering than the strongest flat clustering competitor in nearly half the\ntime. \n\n"}
{"id": "1704.02958", "contents": "Title: On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel\n  Methods and Neural Networks Abstract: Empirical risk minimization (ERM) is ubiquitous in machine learning and\nunderlies most supervised learning methods. While there has been a large body\nof work on algorithms for various ERM problems, the exact computational\ncomplexity of ERM is still not understood. We address this issue for multiple\npopular ERM problems including kernel SVMs, kernel ridge regression, and\ntraining the final layer of a neural network. In particular, we give\nconditional hardness results for these problems based on complexity-theoretic\nassumptions such as the Strong Exponential Time Hypothesis. Under these\nassumptions, we show that there are no algorithms that solve the aforementioned\nERM problems to high accuracy in sub-quadratic time. We also give similar\nhardness results for computing the gradient of the empirical loss, which is the\nmain computational burden in many non-convex learning tasks. \n\n"}
{"id": "1704.05147", "contents": "Title: O$^2$TD: (Near)-Optimal Off-Policy TD Learning Abstract: Temporal difference learning and Residual Gradient methods are the most\nwidely used temporal difference based learning algorithms; however, it has been\nshown that none of their objective functions is optimal w.r.t approximating the\ntrue value function $V$. Two novel algorithms are proposed to approximate the\ntrue value function $V$. This paper makes the following contributions: (1) A\nbatch algorithm that can help find the approximate optimal off-policy\nprediction of the true value function $V$. (2) A linear computational cost (per\nstep) near-optimal algorithm that can learn from a collection of off-policy\nsamples. (3) A new perspective of the emphatic temporal difference learning\nwhich bridges the gap between off-policy optimality and off-policy stability. \n\n"}
{"id": "1704.05420", "contents": "Title: Diagonal RNNs in Symbolic Music Modeling Abstract: In this paper, we propose a new Recurrent Neural Network (RNN) architecture.\nThe novelty is simple: We use diagonal recurrent matrices instead of full. This\nresults in better test likelihood and faster convergence compared to regular\nfull RNNs in most of our experiments. We show the benefits of using diagonal\nrecurrent matrices with popularly used LSTM and GRU architectures as well as\nwith the vanilla RNN architecture, on four standard symbolic music datasets. \n\n"}
{"id": "1704.05963", "contents": "Title: Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds Abstract: Monte Carlo Tree Search (MCTS), most famously used in game-play artificial\nintelligence (e.g., the game of Go), is a well-known strategy for constructing\napproximate solutions to sequential decision problems. Its primary innovation\nis the use of a heuristic, known as a default policy, to obtain Monte Carlo\nestimates of downstream values for states in a decision tree. This information\nis used to iteratively expand the tree towards regions of states and actions\nthat an optimal policy might visit. However, to guarantee convergence to the\noptimal action, MCTS requires the entire tree to be expanded asymptotically. In\nthis paper, we propose a new technique called Primal-Dual MCTS that utilizes\nsampled information relaxation upper bounds on potential actions, creating the\npossibility of \"ignoring\" parts of the tree that stem from highly suboptimal\nchoices. This allows us to prove that despite converging to a partial decision\ntree in the limit, the recommended action from Primal-Dual MCTS is optimal. The\nnew approach shows significant promise when used to optimize the behavior of a\nsingle driver navigating a graph while operating on a ride-sharing platform.\nNumerical experiments on a real dataset of 7,000 trips in New Jersey suggest\nthat Primal-Dual MCTS improves upon standard MCTS by producing deeper decision\ntrees and exhibits a reduced sensitivity to the size of the action space. \n\n"}
{"id": "1704.06498", "contents": "Title: Time Series Prediction for Graphs in Kernel and Dissimilarity Spaces Abstract: Graph models are relevant in many fields, such as distributed computing,\nintelligent tutoring systems or social network analysis. In many cases, such\nmodels need to take changes in the graph structure into account, i.e. a varying\nnumber of nodes or edges. Predicting such changes within graphs can be expected\nto yield important insight with respect to the underlying dynamics, e.g. with\nrespect to user behaviour. However, predictive techniques in the past have\nalmost exclusively focused on single edges or nodes. In this contribution, we\nattempt to predict the future state of a graph as a whole. We propose to phrase\ntime series prediction as a regression problem and apply dissimilarity- or\nkernel-based regression techniques, such as 1-nearest neighbor, kernel\nregression and Gaussian process regression, which can be applied to graphs via\ngraph kernels. The output of the regression is a point embedded in a\npseudo-Euclidean space, which can be analyzed using subsequent dissimilarity-\nor kernel-based processing methods. We discuss strategies to speed up Gaussian\nProcesses regression from cubic to linear time and evaluate our approach on two\nwell-established theoretical models of graph evolution as well as two real data\nsets from the domain of intelligent tutoring systems. We find that simple\nregression methods, such as kernel regression, are sufficient to capture the\ndynamics in the theoretical models, but that Gaussian process regression\nsignificantly improves the prediction error for real-world data. \n\n"}
{"id": "1704.08305", "contents": "Title: Limits of End-to-End Learning Abstract: End-to-end learning refers to training a possibly complex learning system by\napplying gradient-based learning to the system as a whole. End-to-end learning\nsystem is specifically designed so that all modules are differentiable. In\neffect, not only a central learning machine, but also all \"peripheral\" modules\nlike representation learning and memory formation are covered by a holistic\nlearning process. The power of end-to-end learning has been demonstrated on\nmany tasks, like playing a whole array of Atari video games with a single\narchitecture. While pushing for solutions to more challenging tasks, network\narchitectures keep growing more and more complex.\n  In this paper we ask the question whether and to what extent end-to-end\nlearning is a future-proof technique in the sense of scaling to complex and\ndiverse data processing architectures. We point out potential inefficiencies,\nand we argue in particular that end-to-end learning does not make optimal use\nof the modular design of present neural networks. Our surprisingly simple\nexperiments demonstrate these inefficiencies, up to the complete breakdown of\nlearning. \n\n"}
{"id": "1704.09011", "contents": "Title: Mostly Exploration-Free Algorithms for Contextual Bandits Abstract: The contextual bandit literature has traditionally focused on algorithms that\naddress the exploration-exploitation tradeoff. In particular, greedy algorithms\nthat exploit current estimates without any exploration may be sub-optimal in\ngeneral. However, exploration-free greedy algorithms are desirable in practical\nsettings where exploration may be costly or unethical (e.g., clinical trials).\nSurprisingly, we find that a simple greedy algorithm can be rate optimal\n(achieves asymptotically optimal regret) if there is sufficient randomness in\nthe observed contexts (covariates). We prove that this is always the case for a\ntwo-armed bandit under a general class of context distributions that satisfy a\ncondition we term covariate diversity. Furthermore, even absent this condition,\nwe show that a greedy algorithm can be rate optimal with positive probability.\nThus, standard bandit algorithms may unnecessarily explore. Motivated by these\nresults, we introduce Greedy-First, a new algorithm that uses only observed\ncontexts and rewards to determine whether to follow a greedy algorithm or to\nexplore. We prove that this algorithm is rate optimal without any additional\nassumptions on the context distribution or the number of arms. Extensive\nsimulations demonstrate that Greedy-First successfully reduces exploration and\noutperforms existing (exploration-based) contextual bandit algorithms such as\nThompson sampling or upper confidence bound (UCB). \n\n"}
{"id": "1705.00557", "contents": "Title: Discourse-Based Objectives for Fast Unsupervised Sentence Representation\n  Learning Abstract: This work presents a novel objective function for the unsupervised training\nof neural network sentence encoders. It exploits signals from paragraph-level\ndiscourse coherence to train these models to understand text. Our objective is\npurely discriminative, allowing us to train models many times faster than was\npossible under prior methods, and it yields models which perform well in\nextrinsic evaluations. \n\n"}
{"id": "1705.01015", "contents": "Title: Deep Learning for Tumor Classification in Imaging Mass Spectrometry Abstract: Motivation: Tumor classification using Imaging Mass Spectrometry (IMS) data\nhas a high potential for future applications in pathology. Due to the\ncomplexity and size of the data, automated feature extraction and\nclassification steps are required to fully process the data. Deep learning\noffers an approach to learn feature extraction and classification combined in a\nsingle model. Commonly these steps are handled separately in IMS data analysis,\nhence deep learning offers an alternative strategy worthwhile to explore.\nResults: Methodologically, we propose an adapted architecture based on deep\nconvolutional networks to handle the characteristics of mass spectrometry data,\nas well as a strategy to interpret the learned model in the spectral domain\nbased on a sensitivity analysis. The proposed methods are evaluated on two\nchallenging tumor classification tasks and compared to a baseline approach.\nCompetitiveness of the proposed methods are shown on both tasks by studying the\nperformance via cross-validation. Moreover, the learned models are analyzed by\nthe proposed sensitivity analysis revealing biologically plausible effects as\nwell as confounding factors of the considered task. Thus, this study may serve\nas a starting point for further development of deep learning approaches in IMS\nclassification tasks. \n\n"}
{"id": "1705.02394", "contents": "Title: Learning Representations of Emotional Speech with Deep Convolutional\n  Generative Adversarial Networks Abstract: Automatically assessing emotional valence in human speech has historically\nbeen a difficult task for machine learning algorithms. The subtle changes in\nthe voice of the speaker that are indicative of positive or negative emotional\nstates are often \"overshadowed\" by voice characteristics relating to emotional\nintensity or emotional activation. In this work we explore a representation\nlearning approach that automatically derives discriminative representations of\nemotional speech. In particular, we investigate two machine learning strategies\nto improve classifier performance: (1) utilization of unlabeled data using a\ndeep convolutional generative adversarial network (DCGAN), and (2) multitask\nlearning. Within our extensive experiments we leverage a multitask annotated\nemotional corpus as well as a large unlabeled meeting corpus (around 100\nhours). Our speaker-independent classification experiments show that in\nparticular the use of unlabeled data in our investigations improves performance\nof the classifiers and both fully supervised baseline approaches are\noutperformed considerably. We improve the classification of emotional valence\non a discrete 5-point scale to 43.88% and on a 3-point scale to 49.80%, which\nis competitive to state-of-the-art performance. \n\n"}
{"id": "1705.02553", "contents": "Title: Experimental results : Reinforcement Learning of POMDPs using Spectral\n  Methods Abstract: We propose a new reinforcement learning algorithm for partially observable\nMarkov decision processes (POMDP) based on spectral decomposition methods.\nWhile spectral methods have been previously employed for consistent learning of\n(passive) latent variable models such as hidden Markov models, POMDPs are more\nchallenging since the learner interacts with the environment and possibly\nchanges the future observations in the process. We devise a learning algorithm\nrunning through epochs, in each epoch we employ spectral techniques to learn\nthe POMDP parameters from a trajectory generated by a fixed policy. At the end\nof the epoch, an optimization oracle returns the optimal memoryless planning\npolicy which maximizes the expected reward based on the estimated POMDP model.\nWe prove an order-optimal regret bound with respect to the optimal memoryless\npolicy and efficient scaling with respect to the dimensionality of observation\nand action spaces. \n\n"}
{"id": "1705.02583", "contents": "Title: A Design Methodology for Efficient Implementation of Deconvolutional\n  Neural Networks on an FPGA Abstract: In recent years deep learning algorithms have shown extremely high\nperformance on machine learning tasks such as image classification and speech\nrecognition. In support of such applications, various FPGA accelerator\narchitectures have been proposed for convolutional neural networks (CNNs) that\nenable high performance for classification tasks at lower power than CPU and\nGPU processors. However, to date, there has been little research on the use of\nFPGA implementations of deconvolutional neural networks (DCNNs). DCNNs, also\nknown as generative CNNs, encode high-dimensional probability distributions and\nhave been widely used for computer vision applications such as scene\ncompletion, scene segmentation, image creation, image denoising, and\nsuper-resolution imaging. We propose an FPGA architecture for deconvolutional\nnetworks built around an accelerator which effectively handles the complex\nmemory access patterns needed to perform strided deconvolutions, and that\nsupports convolution as well. We also develop a three-step design optimization\nmethod that systematically exploits statistical analysis, design space\nexploration and VLSI optimization. To verify our FPGA deconvolutional\naccelerator design methodology we train DCNNs offline on two representative\ndatasets using the generative adversarial network method (GAN) run on\nTensorflow, and then map these DCNNs to an FPGA DCNN-plus-accelerator\nimplementation to perform generative inference on a Xilinx Zynq-7000 FPGA. Our\nDCNN implementation achieves a peak performance density of 0.012 GOPs/DSP. \n\n"}
{"id": "1705.03290", "contents": "Title: Improving drug sensitivity predictions in precision medicine through\n  active expert knowledge elicitation Abstract: Predicting the efficacy of a drug for a given individual, using\nhigh-dimensional genomic measurements, is at the core of precision medicine.\nHowever, identifying features on which to base the predictions remains a\nchallenge, especially when the sample size is small. Incorporating expert\nknowledge offers a promising alternative to improve a prediction model, but\ncollecting such knowledge is laborious to the expert if the number of candidate\nfeatures is very large. We introduce a probabilistic model that can incorporate\nexpert feedback about the impact of genomic measurements on the sensitivity of\na cancer cell for a given drug. We also present two methods to intelligently\ncollect this feedback from the expert, using experimental design and\nmulti-armed bandit models. In a multiple myeloma blood cancer data set (n=51),\nexpert knowledge decreased the prediction error by 8%. Furthermore, the\nintelligent approaches can be used to reduce the workload of feedback\ncollection to less than 30% on average compared to a naive approach. \n\n"}
{"id": "1705.04379", "contents": "Title: The Network Nullspace Property for Compressed Sensing of Big Data over\n  Networks Abstract: We present a novel condition, which we term the net- work nullspace property,\nwhich ensures accurate recovery of graph signals representing massive\nnetwork-structured datasets from few signal values. The network nullspace\nproperty couples the cluster structure of the underlying network-structure with\nthe geometry of the sampling set. Our results can be used to design efficient\nsampling strategies based on the network topology. \n\n"}
{"id": "1705.07461", "contents": "Title: Shallow Updates for Deep Reinforcement Learning Abstract: Deep reinforcement learning (DRL) methods such as the Deep Q-Network (DQN)\nhave achieved state-of-the-art results in a variety of challenging,\nhigh-dimensional domains. This success is mainly attributed to the power of\ndeep neural networks to learn rich domain representations for approximating the\nvalue function or policy. Batch reinforcement learning methods with linear\nrepresentations, on the other hand, are more stable and require less hyper\nparameter tuning. Yet, substantial feature engineering is necessary to achieve\ngood results. In this work we propose a hybrid approach -- the Least Squares\nDeep Q-Network (LS-DQN), which combines rich feature representations learned by\na DRL algorithm with the stability of a linear least squares method. We do this\nby periodically re-training the last hidden layer of a DRL network with a batch\nleast squares update. Key to our approach is a Bayesian regularization term for\nthe least squares update, which prevents over-fitting to the more recent data.\nWe tested LS-DQN on five Atari games and demonstrate significant improvement\nover vanilla DQN and Double-DQN. We also investigated the reasons for the\nsuperior performance of our method. Interestingly, we found that the\nperformance improvement can be attributed to the large batch size used by the\nLS method when optimizing the last layer. \n\n"}
{"id": "1705.08551", "contents": "Title: Safe Model-based Reinforcement Learning with Stability Guarantees Abstract: Reinforcement learning is a powerful paradigm for learning optimal policies\nfrom experimental data. However, to find optimal policies, most reinforcement\nlearning algorithms explore all possible actions, which may be harmful for\nreal-world systems. As a consequence, learning algorithms are rarely applied on\nsafety-critical systems in the real world. In this paper, we present a learning\nalgorithm that explicitly considers safety, defined in terms of stability\nguarantees. Specifically, we extend control-theoretic results on Lyapunov\nstability verification and show how to use statistical models of the dynamics\nto obtain high-performance control policies with provable stability\ncertificates. Moreover, under additional regularity assumptions in terms of a\nGaussian process prior, we prove that one can effectively and safely collect\ndata in order to learn about the dynamics and thus both improve control\nperformance and expand the safe region of the state space. In our experiments,\nwe show how the resulting algorithm can safely optimize a neural network policy\non a simulated inverted pendulum, without the pendulum ever falling down. \n\n"}
{"id": "1705.08557", "contents": "Title: Grounded Recurrent Neural Networks Abstract: In this work, we present the Grounded Recurrent Neural Network (GRNN), a\nrecurrent neural network architecture for multi-label prediction which\nexplicitly ties labels to specific dimensions of the recurrent hidden state (we\ncall this process \"grounding\"). The approach is particularly well-suited for\nextracting large numbers of concepts from text. We apply the new model to\naddress an important problem in healthcare of understanding what medical\nconcepts are discussed in clinical text. Using a publicly available dataset\nderived from Intensive Care Units, we learn to label a patient's diagnoses and\nprocedures from their discharge summary. Our evaluation shows a clear advantage\nto using our proposed architecture over a variety of strong baselines. \n\n"}
{"id": "1705.08804", "contents": "Title: Beyond Parity: Fairness Objectives for Collaborative Filtering Abstract: We study fairness in collaborative-filtering recommender systems, which are\nsensitive to discrimination that exists in historical data. Biased data can\nlead collaborative-filtering methods to make unfair predictions for users from\nminority groups. We identify the insufficiency of existing fairness metrics and\npropose four new metrics that address different forms of unfairness. These\nfairness metrics can be optimized by adding fairness terms to the learning\nobjective. Experiments on synthetic and real data show that our new metrics can\nbetter measure fairness than the baseline, and that the fairness objectives\neffectively help reduce unfairness. \n\n"}
{"id": "1705.09552", "contents": "Title: Classification regions of deep neural networks Abstract: The goal of this paper is to analyze the geometric properties of deep neural\nnetwork classifiers in the input space. We specifically study the topology of\nclassification regions created by deep networks, as well as their associated\ndecision boundary. Through a systematic empirical investigation, we show that\nstate-of-the-art deep nets learn connected classification regions, and that the\ndecision boundary in the vicinity of datapoints is flat along most directions.\nWe further draw an essential connection between two seemingly unrelated\nproperties of deep networks: their sensitivity to additive perturbations in the\ninputs, and the curvature of their decision boundary. The directions where the\ndecision boundary is curved in fact remarkably characterize the directions to\nwhich the classifier is the most vulnerable. We finally leverage a fundamental\nasymmetry in the curvature of the decision boundary of deep nets, and propose a\nmethod to discriminate between original images, and images perturbed with small\nadversarial examples. We show the effectiveness of this purely geometric\napproach for detecting small adversarial perturbations in images, and for\nrecovering the labels of perturbed images. \n\n"}
{"id": "1705.09700", "contents": "Title: Multi-scale Online Learning and its Applications to Online Auctions Abstract: We consider revenue maximization in online auction/pricing problems. A seller\nsells an identical item in each period to a new buyer, or a new set of buyers.\nFor the online posted pricing problem, we show regret bounds that scale with\nthe best fixed price, rather than the range of the values. We also show regret\nbounds that are almost scale free, and match the offline sample complexity,\nwhen comparing to a benchmark that requires a lower bound on the market share.\nThese results are obtained by generalizing the classical learning from experts\nand multi-armed bandit problems to their multi-scale versions. In this version,\nthe reward of each action is in a different range, and the regret w.r.t. a\ngiven action scales with its own range, rather than the maximum range. \n\n"}
{"id": "1705.10301", "contents": "Title: Contextual Explanation Networks Abstract: Modern learning algorithms excel at producing accurate but complex models of\nthe data. However, deploying such models in the real-world requires extra care:\nwe must ensure their reliability, robustness, and absence of undesired biases.\nThis motivates the development of models that are equally accurate but can be\nalso easily inspected and assessed beyond their predictive performance. To this\nend, we introduce contextual explanation networks (CEN)---a class of\narchitectures that learn to predict by generating and utilizing intermediate,\nsimplified probabilistic models. Specifically, CENs generate parameters for\nintermediate graphical models which are further used for prediction and play\nthe role of explanations. Contrary to the existing post-hoc model-explanation\ntools, CENs learn to predict and to explain simultaneously. Our approach offers\ntwo major advantages: (i) for each prediction valid, instance-specific\nexplanation is generated with no computational overhead and (ii) prediction via\nexplanation acts as a regularizer and boosts performance in data-scarce\nsettings. We analyze the proposed framework theoretically and experimentally.\nOur results on image and text classification and survival analysis tasks\ndemonstrate that CENs are not only competitive with the state-of-the-art\nmethods but also offer additional insights behind each prediction, that can be\nvaluable for decision support. We also show that while post-hoc methods may\nproduce misleading explanations in certain cases, CENs are consistent and allow\nto detect such cases systematically. \n\n"}
{"id": "1705.10342", "contents": "Title: Deep Learning for Ontology Reasoning Abstract: In this work, we present a novel approach to ontology reasoning that is based\non deep learning rather than logic-based formal reasoning. To this end, we\nintroduce a new model for statistical relational learning that is built upon\ndeep recursive neural networks, and give experimental evidence that it can\neasily compete with, or even outperform, existing logic-based reasoners on the\ntask of ontology reasoning. More precisely, we compared our implemented system\nwith one of the best logic-based ontology reasoners at present, RDFox, on a\nnumber of large standard benchmark datasets, and found that our system attained\nhigh reasoning quality, while being up to two orders of magnitude faster. \n\n"}
{"id": "1705.10694", "contents": "Title: Deep Learning is Robust to Massive Label Noise Abstract: Deep neural networks trained on large supervised datasets have led to\nimpressive results in image classification and other tasks. However,\nwell-annotated datasets can be time-consuming and expensive to collect, lending\nincreased interest to larger but noisy datasets that are more easily obtained.\nIn this paper, we show that deep neural networks are capable of generalizing\nfrom training data for which true labels are massively outnumbered by incorrect\nlabels. We demonstrate remarkably high test performance after training on\ncorrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain\ntest accuracy above 90 percent even after each clean training example has been\ndiluted with 100 randomly-labeled examples. Such behavior holds across multiple\npatterns of label noise, even when erroneous labels are biased towards\nconfusing classes. We show that training in this regime requires a significant\nbut manageable increase in dataset size that is related to the factor by which\ncorrect labels have been diluted. Finally, we provide an analysis of our\nresults that shows how increasing noise decreases the effective batch size. \n\n"}
{"id": "1705.11041", "contents": "Title: Greedy Algorithms for Cone Constrained Optimization with Convergence\n  Guarantees Abstract: Greedy optimization methods such as Matching Pursuit (MP) and Frank-Wolfe\n(FW) algorithms regained popularity in recent years due to their simplicity,\neffectiveness and theoretical guarantees. MP and FW address optimization over\nthe linear span and the convex hull of a set of atoms, respectively. In this\npaper, we consider the intermediate case of optimization over the convex cone,\nparametrized as the conic hull of a generic atom set, leading to the first\nprincipled definitions of non-negative MP algorithms for which we give explicit\nconvergence rates and demonstrate excellent empirical performance. In\nparticular, we derive sublinear ($\\mathcal{O}(1/t)$) convergence on general\nsmooth and convex objectives, and linear convergence ($\\mathcal{O}(e^{-t})$) on\nstrongly convex objectives, in both cases for general sets of atoms.\nFurthermore, we establish a clear correspondence of our algorithms to known\nalgorithms from the MP and FW literature. Our novel algorithms and analyses\ntarget general atom sets and general objective functions, and hence are\ndirectly applicable to a large variety of learning settings. \n\n"}
{"id": "1706.00038", "contents": "Title: Toward Robustness against Label Noise in Training Deep Discriminative\n  Neural Networks Abstract: Collecting large training datasets, annotated with high-quality labels, is\ncostly and time-consuming. This paper proposes a novel framework for training\ndeep convolutional neural networks from noisy labeled datasets that can be\nobtained cheaply. The problem is formulated using an undirected graphical model\nthat represents the relationship between noisy and clean labels, trained in a\nsemi-supervised setting. In our formulation, the inference over latent clean\nlabels is tractable and is regularized during training using auxiliary sources\nof information. The proposed model is applied to the image labeling problem and\nis shown to be effective in labeling unseen images as well as reducing label\nnoise in training on CIFAR-10 and MS COCO datasets. \n\n"}
{"id": "1706.03256", "contents": "Title: Progressive Neural Networks for Transfer Learning in Emotion Recognition Abstract: Many paralinguistic tasks are closely related and thus representations\nlearned in one domain can be leveraged for another. In this paper, we\ninvestigate how knowledge can be transferred between three paralinguistic\ntasks: speaker, emotion, and gender recognition. Further, we extend this\nproblem to cross-dataset tasks, asking how knowledge captured in one emotion\ndataset can be transferred to another. We focus on progressive neural networks\nand compare these networks to the conventional deep learning method of\npre-training and fine-tuning. Progressive neural networks provide a way to\ntransfer knowledge and avoid the forgetting effect present when pre-training\nneural networks on different tasks. Our experiments demonstrate that: (1)\nemotion recognition can benefit from using representations originally learned\nfor different paralinguistic tasks and (2) transfer learning can effectively\nleverage additional datasets to improve the performance of emotion recognition\nsystems. \n\n"}
{"id": "1706.03446", "contents": "Title: Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for\n  Electronic Health Record (EHR) Analysis Abstract: The past decade has seen an explosion in the amount of digital information\nstored in electronic health records (EHR). While primarily designed for\narchiving patient clinical information and administrative healthcare tasks,\nmany researchers have found secondary use of these records for various clinical\ninformatics tasks. Over the same period, the machine learning community has\nseen widespread advances in deep learning techniques, which also have been\nsuccessfully applied to the vast amount of EHR data. In this paper, we review\nthese deep EHR systems, examining architectures, technical aspects, and\nclinical applications. We also identify shortcomings of current techniques and\ndiscuss avenues of future research for EHR-based deep learning. \n\n"}
{"id": "1706.03815", "contents": "Title: Encoding of phonology in a recurrent neural model of grounded speech Abstract: We study the representation and encoding of phonemes in a recurrent neural\nnetwork model of grounded speech. We use a model which processes images and\ntheir spoken descriptions, and projects the visual and auditory representations\ninto the same semantic space. We perform a number of analyses on how\ninformation about individual phonemes is encoded in the MFCC features extracted\nfrom the speech signal, and the activations of the layers of the model. Via\nexperiments with phoneme decoding and phoneme discrimination we show that\nphoneme representations are most salient in the lower layers of the model,\nwhere low-level signals are processed at a fine-grained level, although a large\namount of phonological information is retain at the top recurrent layer. We\nfurther find out that the attention mechanism following the top recurrent layer\nsignificantly attenuates encoding of phonology and makes the utterance\nembeddings much more invariant to synonymy. Moreover, a hierarchical clustering\nof phoneme representations learned by the network shows an organizational\nstructure of phonemes similar to those proposed in linguistics. \n\n"}
{"id": "1706.04601", "contents": "Title: Provable benefits of representation learning Abstract: There is general consensus that learning representations is useful for a\nvariety of reasons, e.g. efficient use of labeled data (semi-supervised\nlearning), transfer learning and understanding hidden structure of data.\nPopular techniques for representation learning include clustering, manifold\nlearning, kernel-learning, autoencoders, Boltzmann machines, etc.\n  To study the relative merits of these techniques, it's essential to formalize\nthe definition and goals of representation learning, so that they are all\nbecome instances of the same definition. This paper introduces such a formal\nframework that also formalizes the utility of learning the representation. It\nis related to previous Bayesian notions, but with some new twists. We show the\nusefulness of our framework by exhibiting simple and natural settings -- linear\nmixture models and loglinear models, where the power of representation learning\ncan be formally shown. In these examples, representation learning can be\nperformed provably and efficiently under plausible assumptions (despite being\nNP-hard), and furthermore: (i) it greatly reduces the need for labeled data\n(semi-supervised learning) and (ii) it allows solving classification tasks when\nsimpler approaches like nearest neighbors require too much data (iii) it is\nmore powerful than manifold learning methods. \n\n"}
{"id": "1706.04638", "contents": "Title: Proximal Backpropagation Abstract: We propose proximal backpropagation (ProxProp) as a novel algorithm that\ntakes implicit instead of explicit gradient steps to update the network\nparameters during neural network training. Our algorithm is motivated by the\nstep size limitation of explicit gradient descent, which poses an impediment\nfor optimization. ProxProp is developed from a general point of view on the\nbackpropagation algorithm, currently the most common technique to train neural\nnetworks via stochastic gradient descent and variants thereof. Specifically, we\nshow that backpropagation of a prediction error is equivalent to sequential\ngradient descent steps on a quadratic penalty energy, which comprises the\nnetwork activations as variables of the optimization. We further analyze\ntheoretical properties of ProxProp and in particular prove that the algorithm\nyields a descent direction in parameter space and can therefore be combined\nwith a wide variety of convergent algorithms. Finally, we devise an efficient\nnumerical implementation that integrates well with popular deep learning\nframeworks. We conclude by demonstrating promising numerical results and show\nthat ProxProp can be effectively combined with common first order optimizers\nsuch as Adam. \n\n"}
{"id": "1706.04902", "contents": "Title: A Survey Of Cross-lingual Word Embedding Models Abstract: Cross-lingual representations of words enable us to reason about word meaning\nin multilingual contexts and are a key facilitator of cross-lingual transfer\nwhen developing natural language processing models for low-resource languages.\nIn this survey, we provide a comprehensive typology of cross-lingual word\nembedding models. We compare their data requirements and objective functions.\nThe recurring theme of the survey is that many of the models presented in the\nliterature optimize for the same objectives, and that seemingly different\nmodels are often equivalent modulo optimization strategies, hyper-parameters,\nand such. We also discuss the different ways cross-lingual word embeddings are\nevaluated, as well as future challenges and research horizons. \n\n"}
{"id": "1706.05744", "contents": "Title: Learning Hierarchical Information Flow with Recurrent Neural Modules Abstract: We propose ThalNet, a deep learning model inspired by neocortical\ncommunication via the thalamus. Our model consists of recurrent neural modules\nthat send features through a routing center, endowing the modules with the\nflexibility to share features over multiple time steps. We show that our model\nlearns to route information hierarchically, processing input data by a chain of\nmodules. We observe common architectures, such as feed forward neural networks\nand skip connections, emerging as special cases of our architecture, while\nnovel connectivity patterns are learned for the text8 compression task. Our\nmodel outperforms standard recurrent neural networks on several sequential\nbenchmarks. \n\n"}
{"id": "1706.06714", "contents": "Title: Neural-based Natural Language Generation in Dialogue using RNN\n  Encoder-Decoder with Semantic Aggregation Abstract: Natural language generation (NLG) is an important component in spoken\ndialogue systems. This paper presents a model called Encoder-Aggregator-Decoder\nwhich is an extension of an Recurrent Neural Network based Encoder-Decoder\narchitecture. The proposed Semantic Aggregator consists of two components: an\nAligner and a Refiner. The Aligner is a conventional attention calculated over\nthe encoded input information, while the Refiner is another attention or gating\nmechanism stacked over the attentive Aligner in order to further select and\naggregate the semantic elements. The proposed model can be jointly trained both\nsentence planning and surface realization to produce natural language\nutterances. The model was extensively assessed on four different NLG domains,\nin which the experimental results showed that the proposed generator\nconsistently outperforms the previous methods on all the NLG domains. \n\n"}
{"id": "1706.08224", "contents": "Title: Do GANs actually learn the distribution? An empirical study Abstract: Do GANS (Generative Adversarial Nets) actually learn the target distribution?\nThe foundational paper of (Goodfellow et al 2014) suggested they do, if they\nwere given sufficiently large deep nets, sample size, and computation time. A\nrecent theoretical analysis in Arora et al (to appear at ICML 2017) raised\ndoubts whether the same holds when discriminator has finite size. It showed\nthat the training objective can approach its optimum value even if the\ngenerated distribution has very low support ---in other words, the training\nobjective is unable to prevent mode collapse. The current note reports\nexperiments suggesting that such problems are not merely theoretical. It\npresents empirical evidence that well-known GANs approaches do learn\ndistributions of fairly low support, and thus presumably are not learning the\ntarget distribution. The main technical contribution is a new proposed test,\nbased upon the famous birthday paradox, for estimating the support size of the\ngenerated distribution. \n\n"}
{"id": "1706.09516", "contents": "Title: CatBoost: unbiased boosting with categorical features Abstract: This paper presents the key algorithmic techniques behind CatBoost, a new\ngradient boosting toolkit. Their combination leads to CatBoost outperforming\nother publicly available boosting implementations in terms of quality on a\nvariety of datasets. Two critical algorithmic advances introduced in CatBoost\nare the implementation of ordered boosting, a permutation-driven alternative to\nthe classic algorithm, and an innovative algorithm for processing categorical\nfeatures. Both techniques were created to fight a prediction shift caused by a\nspecial kind of target leakage present in all currently existing\nimplementations of gradient boosting algorithms. In this paper, we provide a\ndetailed analysis of this problem and demonstrate that proposed algorithms\nsolve it effectively, leading to excellent empirical results. \n\n"}
{"id": "1706.09520", "contents": "Title: Neural SLAM: Learning to Explore with External Memory Abstract: We present an approach for agents to learn representations of a global map\nfrom sensor data, to aid their exploration in new environments. To achieve\nthis, we embed procedures mimicking that of traditional Simultaneous\nLocalization and Mapping (SLAM) into the soft attention based addressing of\nexternal memory architectures, in which the external memory acts as an internal\nrepresentation of the environment. This structure encourages the evolution of\nSLAM-like behaviors inside a completely differentiable deep neural network. We\nshow that this approach can help reinforcement learning agents to successfully\nexplore new environments where long-term memory is essential. We validate our\napproach in both challenging grid-world environments and preliminary Gazebo\nexperiments. A video of our experiments can be found at: https://goo.gl/G2Vu5y. \n\n"}
{"id": "1707.00117", "contents": "Title: SAM: Semantic Attribute Modulation for Language Modeling and Style\n  Variation Abstract: This paper presents a Semantic Attribute Modulation (SAM) for language\nmodeling and style variation. The semantic attribute modulation includes\nvarious document attributes, such as titles, authors, and document categories.\nWe consider two types of attributes, (title attributes and category\nattributes), and a flexible attribute selection scheme by automatically scoring\nthem via an attribute attention mechanism. The semantic attributes are embedded\ninto the hidden semantic space as the generation inputs. With the attributes\nproperly harnessed, our proposed SAM can generate interpretable texts with\nregard to the input attributes. Qualitative analysis, including word semantic\nanalysis and attention values, shows the interpretability of SAM. On several\ntypical text datasets, we empirically demonstrate the superiority of the\nSemantic Attribute Modulated language model with different combinations of\ndocument attributes. Moreover, we present a style variation for the lyric\ngeneration using SAM, which shows a strong connection between the style\nvariation and the semantic attributes. \n\n"}
{"id": "1707.02038", "contents": "Title: A Tutorial on Thompson Sampling Abstract: Thompson sampling is an algorithm for online decision problems where actions\nare taken sequentially in a manner that must balance between exploiting what is\nknown to maximize immediate performance and investing to accumulate new\ninformation that may improve future performance. The algorithm addresses a\nbroad range of problems in a computationally efficient manner and is therefore\nenjoying wide use. This tutorial covers the algorithm and its application,\nillustrating concepts through a range of examples, including Bernoulli bandit\nproblems, shortest path problems, product recommendation, assortment, active\nlearning with neural networks, and reinforcement learning in Markov decision\nprocesses. Most of these problems involve complex information structures, where\ninformation revealed by taking an action informs beliefs about other actions.\nWe will also discuss when and why Thompson sampling is or is not effective and\nrelations to alternative algorithms. \n\n"}
{"id": "1707.02669", "contents": "Title: First low-frequency Einstein@Home all-sky search for continuous\n  gravitational waves in Advanced LIGO data Abstract: We report results of a deep all-sky search for periodic gravitational waves\nfrom isolated neutron stars in data from the first Advanced LIGO observing run.\nThis search investigates the low frequency range of Advanced LIGO data, between\n20 and 100 Hz, much of which was not explored in initial LIGO. The search was\nmade possible by the computing power provided by the volunteers of the\nEinstein@Home project. We find no significant signal candidate and set the most\nstringent upper limits to date on the amplitude of gravitational wave signals\nfrom the target population, corresponding to a sensitivity depth of 48.7\n[1/$\\sqrt{{\\textrm{Hz}}}$]. At the frequency of best strain sensitivity, near\n100 Hz, we set 90% confidence upper limits of $1.8 \\times 10^{-25}$. At the low\nend of our frequency range, 20 Hz, we achieve upper limits of $3.9 \\times\n10^{-24}$. At 55 Hz we can exclude sources with ellipticities greater than\n$10^{-5}$ within 100 pc of Earth with fiducial value of the principal moment of\ninertia of $10^{38} \\textrm{kg m}^2$. \n\n"}
{"id": "1707.02711", "contents": "Title: Topology Reduction in Deep Convolutional Feature Extraction Networks Abstract: Deep convolutional neural networks (CNNs) used in practice employ potentially\nhundreds of layers and $10$,$000$s of nodes. Such network sizes entail\nsignificant computational complexity due to the large number of convolutions\nthat need to be carried out; in addition, a large number of parameters needs to\nbe learned and stored. Very deep and wide CNNs may therefore not be well suited\nto applications operating under severe resource constraints as is the case,\ne.g., in low-power embedded and mobile platforms. This paper aims at\nunderstanding the impact of CNN topology, specifically depth and width, on the\nnetwork's feature extraction capabilities. We address this question for the\nclass of scattering networks that employ either Weyl-Heisenberg filters or\nwavelets, the modulus non-linearity, and no pooling. The exponential feature\nmap energy decay results in Wiatowski et al., 2017, are generalized to\n$\\mathcal{O}(a^{-N})$, where an arbitrary decay factor $a>1$ can be realized\nthrough suitable choice of the Weyl-Heisenberg prototype function or the mother\nwavelet. We then show how networks of fixed (possibly small) depth $N$ can be\ndesigned to guarantee that $((1-\\varepsilon)\\cdot 100)\\%$ of the input signal's\nenergy are contained in the feature vector. Based on the notion of\noperationally significant nodes, we characterize, partly rigorously and partly\nheuristically, the topology-reducing effects of (effectively) band-limited\ninput signals, band-limited filters, and feature map symmetries. Finally, for\nnetworks based on Weyl-Heisenberg filters, we determine the prototype function\nbandwidth that minimizes---for fixed network depth $N$---the average number of\noperationally significant nodes per layer. \n\n"}
{"id": "1707.02920", "contents": "Title: Vision-Based Multi-Task Manipulation for Inexpensive Robots Using\n  End-To-End Learning from Demonstration Abstract: We propose a technique for multi-task learning from demonstration that trains\nthe controller of a low-cost robotic arm to accomplish several complex picking\nand placing tasks, as well as non-prehensile manipulation. The controller is a\nrecurrent neural network using raw images as input and generating robot arm\ntrajectories, with the parameters shared across the tasks. The controller also\ncombines VAE-GAN-based reconstruction with autoregressive multimodal action\nprediction. Our results demonstrate that it is possible to learn complex\nmanipulation tasks, such as picking up a towel, wiping an object, and\ndepositing the towel to its previous position, entirely from raw images with\ndirect behavior cloning. We show that weight sharing and reconstruction-based\nregularization substantially improve generalization and robustness, and\ntraining on multiple tasks simultaneously increases the success rate on all\ntasks. \n\n"}
{"id": "1707.02975", "contents": "Title: On Study of the Reliable Fully Convolutional Networks with Tree Arranged\n  Outputs (TAO-FCN) for Handwritten String Recognition Abstract: The handwritten string recognition is still a challengeable task, though the\npowerful deep learning tools were introduced. In this paper, based on TAO-FCN,\nwe proposed an end-to-end system for handwritten string recognition. Compared\nwith the conventional methods, there is no preprocess nor manually designed\nrules employed. With enough labelled data, it is easy to apply the proposed\nmethod to different applications. Although the performance of the proposed\nmethod may not be comparable with the state-of-the-art approaches, it's\nusability and robustness are more meaningful for practical applications. \n\n"}
{"id": "1707.03141", "contents": "Title: A Simple Neural Attentive Meta-Learner Abstract: Deep neural networks excel in regimes with large amounts of data, but tend to\nstruggle when data is scarce or when they need to adapt quickly to changes in\nthe task. In response, recent work in meta-learning proposes training a\nmeta-learner on a distribution of similar tasks, in the hopes of generalization\nto novel but related tasks by learning a high-level strategy that captures the\nessence of the problem it is asked to solve. However, many recent meta-learning\napproaches are extensively hand-designed, either using architectures\nspecialized to a particular application, or hard-coding algorithmic components\nthat constrain how the meta-learner solves the task. We propose a class of\nsimple and generic meta-learner architectures that use a novel combination of\ntemporal convolutions and soft attention; the former to aggregate information\nfrom past experience and the latter to pinpoint specific pieces of information.\nIn the most extensive set of meta-learning experiments to date, we evaluate the\nresulting Simple Neural AttentIve Learner (or SNAIL) on several\nheavily-benchmarked tasks. On all tasks, in both supervised and reinforcement\nlearning, SNAIL attains state-of-the-art performance by significant margins. \n\n"}
{"id": "1707.03167", "contents": "Title: RegNet: Multimodal Sensor Registration Using Deep Neural Networks Abstract: In this paper, we present RegNet, the first deep convolutional neural network\n(CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between\nmultimodal sensors, exemplified using a scanning LiDAR and a monocular camera.\nCompared to existing approaches, RegNet casts all three conventional\ncalibration steps (feature extraction, feature matching and global regression)\ninto a single real-time capable CNN. Our method does not require any human\ninteraction and bridges the gap between classical offline and target-less\nonline calibration approaches as it provides both a stable initial estimation\nas well as a continuous online correction of the extrinsic parameters. During\ntraining we randomly decalibrate our system in order to train RegNet to infer\nthe correspondence between projected depth measurements and RGB image and\nfinally regress the extrinsic calibration. Additionally, with an iterative\nexecution of multiple CNNs, that are trained on different magnitudes of\ndecalibration, our approach compares favorably to state-of-the-art methods in\nterms of a mean calibration error of 0.28 degrees for the rotational and 6 cm\nfor the translation components even for large decalibrations up to 1.5 m and 20\ndegrees. \n\n"}
{"id": "1707.03340", "contents": "Title: Deep Learning for Real Time Crime Forecasting Abstract: Accurate real time crime prediction is a fundamental issue for public safety,\nbut remains a challenging problem for the scientific community. Crime\noccurrences depend on many complex factors. Compared to many predictable\nevents, crime is sparse. At different spatio-temporal scales, crime\ndistributions display dramatically different patterns. These distributions are\nof very low regularity in both space and time. In this work, we adapt the\nstate-of-the-art deep learning spatio-temporal predictor, ST-ResNet [Zhang et\nal, AAAI, 2017], to collectively predict crime distribution over the Los\nAngeles area. Our models are two staged. First, we preprocess the raw crime\ndata. This includes regularization in both space and time to enhance\npredictable signals. Second, we adapt hierarchical structures of residual\nconvolutional units to train multi-factor crime prediction models. Experiments\nover a half year period in Los Angeles reveal highly accurate predictive power\nof our models. \n\n"}
{"id": "1707.03502", "contents": "Title: Deep Learning for Sensor-based Activity Recognition: A Survey Abstract: Sensor-based activity recognition seeks the profound high-level knowledge\nabout human activities from multitudes of low-level sensor readings.\nConventional pattern recognition approaches have made tremendous progress in\nthe past years. However, those methods often heavily rely on heuristic\nhand-crafted feature extraction, which could hinder their generalization\nperformance. Additionally, existing methods are undermined for unsupervised and\nincremental learning tasks. Recently, the recent advancement of deep learning\nmakes it possible to perform automatic high-level feature extraction thus\nachieves promising performance in many areas. Since then, deep learning based\nmethods have been widely adopted for the sensor-based activity recognition\ntasks. This paper surveys the recent advance of deep learning based\nsensor-based activity recognition. We summarize existing literature from three\naspects: sensor modality, deep model, and application. We also present detailed\ninsights on existing work and propose grand challenges for future research. \n\n"}
{"id": "1707.03548", "contents": "Title: Discriminative Block-Diagonal Representation Learning for Image\n  Recognition Abstract: Existing block-diagonal representation researches mainly focuses on casting\nblock-diagonal regularization on training data, while only little attention is\ndedicated to concurrently learning both block-diagonal representations of\ntraining and test data. In this paper, we propose a discriminative\nblock-diagonal low-rank representation (BDLRR) method for recognition. In\nparticular, the elaborate BDLRR is formulated as a joint optimization problem\nof shrinking the unfavorable representation from off-block-diagonal elements\nand strengthening the compact block-diagonal representation under the\nsemi-supervised framework of low-rank representation. To this end, we first\nimpose penalty constraints on the negative representation to eliminate the\ncorrelation between different classes such that the incoherence criterion of\nthe extra-class representation is boosted. Moreover, a constructed subspace\nmodel is developed to enhance the self-expressive power of training samples and\nfurther build the representation bridge between the training and test samples,\nsuch that the coherence of the learned intra-class representation is\nconsistently heightened. Finally, the resulting optimization problem is solved\nelegantly by employing an alternative optimization strategy, and a simple\nrecognition algorithm on the learned representation is utilized for final\nprediction. Extensive experimental results demonstrate that the proposed method\nachieves superb recognition results on four face image datasets, three\ncharacter datasets, and the fifteen scene multi-categories dataset. It not only\nshows superior potential on image recognition but also outperforms\nstate-of-the-art methods. \n\n"}
{"id": "1707.03569", "contents": "Title: Multitask Learning for Fine-Grained Twitter Sentiment Analysis Abstract: Traditional sentiment analysis approaches tackle problems like ternary\n(3-category) and fine-grained (5-category) classification by learning the tasks\nseparately. We argue that such classification tasks are correlated and we\npropose a multitask approach based on a recurrent neural network that benefits\nby jointly learning them. Our study demonstrates the potential of multitask\nmodels on this type of problems and improves the state-of-the-art results in\nthe fine-grained sentiment classification problem. \n\n"}
{"id": "1707.03595", "contents": "Title: Spins of primordial black holes formed in the matter-dominated phase of\n  the Universe Abstract: Angular momentum plays very important roles in the formation of PBHs in the\nmatter-dominated phase if it lasts sufficiently long. In fact, most collapsing\nmasses are bounced back due to centrifugal force, since angular momentum\nsignificantly grows before collapse. As a consequence, most of the formed PBHs\nare rapidly rotating near the extreme value $a_{*}=1$, where $a_{*}$ is the\nnondimensional Kerr parameter at their formation. The smaller the density\nfluctuation $\\sigma_{H}$ at horizon entry is, the stronger the tendency towards\nthe extreme rotation. Combining the effect of angular momentum with that of\nanisotropy, we estimate the black hole production rate. We find that the\nproduction rate suffers from suppression dominantly due to angular momentum for\na smaller value of $\\sigma_{H}$, while due to anisotrpopy for a larger value of\n$\\sigma_{H}$. We argue that matter domination significantly enhances the\nproduction of PBHs despite the suppression. If the matter-dominated phase does\nnot last so long, the effect of the finite duration significantly suppresses\nPBH formation and weakens the tendency towards large spins. (abridged) \n\n"}
{"id": "1707.03804", "contents": "Title: Source-Target Inference Models for Spatial Instruction Understanding Abstract: Models that can execute natural language instructions for situated robotic\ntasks such as assembly and navigation have several useful applications in\nhomes, offices, and remote scenarios. We study the semantics of\nspatially-referred configuration and arrangement instructions, based on the\nchallenging Bisk-2016 blank-labeled block dataset. This task involves finding a\nsource block and moving it to the target position (mentioned via a reference\nblock and offset), where the blocks have no names or colors and are just\nreferred to via spatial location features. We present novel models for the\nsubtasks of source block classification and target position regression, based\non joint-loss language and spatial-world representation learning, as well as\nCNN-based and dual attention models to compute the alignment between the world\nblocks and the instruction phrases. For target position prediction, we compare\ntwo inference approaches: annealed sampling via policy gradient versus\nexpectation inference via supervised regression. Our models achieve the new\nstate-of-the-art on this task, with an improvement of 47% on source block\naccuracy and 22% on target position distance. \n\n"}
{"id": "1707.03821", "contents": "Title: Process Monitoring on Sequences of System Call Count Vectors Abstract: We introduce a methodology for efficient monitoring of processes running on\nhosts in a corporate network. The methodology is based on collecting streams of\nsystem calls produced by all or selected processes on the hosts, and sending\nthem over the network to a monitoring server, where machine learning algorithms\nare used to identify changes in process behavior due to malicious activity,\nhardware failures, or software errors. The methodology uses a sequence of\nsystem call count vectors as the data format which can handle large and varying\nvolumes of data.\n  Unlike previous approaches, the methodology introduced in this paper is\nsuitable for distributed collection and processing of data in large corporate\nnetworks. We evaluate the methodology both in a laboratory setting on a\nreal-life setup and provide statistics characterizing performance and accuracy\nof the methodology. \n\n"}
{"id": "1707.03938", "contents": "Title: Representation Learning for Grounded Spatial Reasoning Abstract: The interpretation of spatial references is highly contextual, requiring\njoint inference over both language and the environment. We consider the task of\nspatial reasoning in a simulated environment, where an agent can act and\nreceive rewards. The proposed model learns a representation of the world\nsteered by instruction text. This design allows for precise alignment of local\nneighborhoods with corresponding verbalizations, while also handling global\nreferences in the instructions. We train our model with reinforcement learning\nusing a variant of generalized value iteration. The model outperforms\nstate-of-the-art approaches on several metrics, yielding a 45% reduction in\ngoal localization error. \n\n"}
{"id": "1707.04347", "contents": "Title: Weakly Submodular Maximization Beyond Cardinality Constraints: Does\n  Randomization Help Greedy? Abstract: Submodular functions are a broad class of set functions, which naturally\narise in diverse areas. Many algorithms have been suggested for the\nmaximization of these functions. Unfortunately, once the function deviates from\nsubmodularity, the known algorithms may perform arbitrarily poorly. Amending\nthis issue, by obtaining approximation results for set functions generalizing\nsubmodular functions, has been the focus of recent works.\n  One such class, known as weakly submodular functions, has received a lot of\nattention. A key result proved by Das and Kempe (2011) showed that the\napproximation ratio of the greedy algorithm for weakly submodular maximization\nsubject to a cardinality constraint degrades smoothly with the distance from\nsubmodularity. However, no results have been obtained for maximization subject\nto constraints beyond cardinality. In particular, it is not known whether the\ngreedy algorithm achieves any non-trivial approximation ratio for such\nconstraints.\n  In this paper, we prove that a randomized version of the greedy algorithm\n(previously used by Buchbinder et al. (2014) for a different problem) achieves\nan approximation ratio of $(1 + 1/\\gamma)^{-2}$ for the maximization of a\nweakly submodular function subject to a general matroid constraint, where\n$\\gamma$ is a parameter measuring the distance of the function from\nsubmodularity. Moreover, we also experimentally compare the performance of this\nversion of the greedy algorithm on real world problems against natural\nbenchmarks, and show that the algorithm we study performs well also in\npractice. To the best of our knowledge, this is the first algorithm with a\nnon-trivial approximation guarantee for maximizing a weakly submodular function\nsubject to a constraint other than the simple cardinality constraint. In\nparticular, it is the first algorithm with such a guarantee for the important\nand broad class of matroid constraints. \n\n"}
{"id": "1707.04626", "contents": "Title: Simplified Long Short-term Memory Recurrent Neural Networks: part III Abstract: This is part III of three-part work. In parts I and II, we have presented\neight variants for simplified Long Short Term Memory (LSTM) recurrent neural\nnetworks (RNNs). It is noted that fast computation, specially in constrained\ncomputing resources, are an important factor in processing big time-sequence\ndata. In this part III paper, we present and evaluate two new LSTM model\nvariants which dramatically reduce the computational load while retaining\ncomparable performance to the base (standard) LSTM RNNs. In these new variants,\nwe impose (Hadamard) pointwise state multiplications in the cell-memory network\nin addition to the gating signal networks. \n\n"}
{"id": "1707.05173", "contents": "Title: Trial without Error: Towards Safe Reinforcement Learning via Human\n  Intervention Abstract: AI systems are increasingly applied to complex tasks that involve interaction\nwith humans. During training, such systems are potentially dangerous, as they\nhaven't yet learned to avoid actions that could cause serious harm. How can an\nAI system explore and learn without making a single mistake that harms humans\nor otherwise causes serious damage? For model-free reinforcement learning,\nhaving a human \"in the loop\" and ready to intervene is currently the only way\nto prevent all catastrophes. We formalize human intervention for RL and show\nhow to reduce the human labor required by training a supervised learner to\nimitate the human's intervention decisions. We evaluate this scheme on Atari\ngames, with a Deep RL agent being overseen by a human for four hours. When the\nclass of catastrophes is simple, we are able to prevent all catastrophes\nwithout affecting the agent's learning (whereas an RL baseline fails due to\ncatastrophic forgetting). However, this scheme is less successful when\ncatastrophes are more complex: it reduces but does not eliminate catastrophes\nand the supervised learner fails on adversarial examples found by the agent.\nExtrapolating to more challenging environments, we show that our implementation\nwould not scale (due to the infeasible amount of human labor required). We\noutline extensions of the scheme that are necessary if we are to train\nmodel-free agents without a single catastrophe. \n\n"}
{"id": "1707.06065", "contents": "Title: Dynamic Layer Normalization for Adaptive Neural Acoustic Modeling in\n  Speech Recognition Abstract: Layer normalization is a recently introduced technique for normalizing the\nactivities of neurons in deep neural networks to improve the training speed and\nstability. In this paper, we introduce a new layer normalization technique\ncalled Dynamic Layer Normalization (DLN) for adaptive neural acoustic modeling\nin speech recognition. By dynamically generating the scaling and shifting\nparameters in layer normalization, DLN adapts neural acoustic models to the\nacoustic variability arising from various factors such as speakers, channel\nnoises, and environments. Unlike other adaptive acoustic models, our proposed\napproach does not require additional adaptation data or speaker information\nsuch as i-vectors. Moreover, the model size is fixed as it dynamically\ngenerates adaptation parameters. We apply our proposed DLN to deep\nbidirectional LSTM acoustic models and evaluate them on two benchmark datasets\nfor large vocabulary ASR experiments: WSJ and TED-LIUM release 2. The\nexperimental results show that our DLN improves neural acoustic models in terms\nof transcription accuracy by dynamically adapting to various speakers and\nenvironments. \n\n"}
{"id": "1707.06613", "contents": "Title: Decoupled classifiers for fair and efficient machine learning Abstract: When it is ethical and legal to use a sensitive attribute (such as gender or\nrace) in machine learning systems, the question remains how to do so. We show\nthat the naive application of machine learning algorithms using sensitive\nfeatures leads to an inherent tradeoff in accuracy between groups. We provide a\nsimple and efficient decoupling technique, that can be added on top of any\nblack-box machine learning algorithm, to learn different classifiers for\ndifferent groups. Transfer learning is used to mitigate the problem of having\ntoo little data on any one group.\n  The method can apply to a range of fairness criteria. In particular, we\nrequire the application designer to specify as joint loss function that makes\nexplicit the trade-off between fairness and accuracy. Our reduction is shown to\nefficiently find the minimum loss as long as the objective has a certain\nnatural monotonicity property which may be of independent interest in the study\nof fairness in algorithms. \n\n"}
{"id": "1707.07341", "contents": "Title: Prediction-Constrained Training for Semi-Supervised Mixture and Topic\n  Models Abstract: Supervisory signals have the potential to make low-dimensional data\nrepresentations, like those learned by mixture and topic models, more\ninterpretable and useful. We propose a framework for training latent variable\nmodels that explicitly balances two goals: recovery of faithful generative\nexplanations of high-dimensional data, and accurate prediction of associated\nsemantic labels. Existing approaches fail to achieve these goals due to an\nincomplete treatment of a fundamental asymmetry: the intended application is\nalways predicting labels from data, not data from labels. Our\nprediction-constrained objective for training generative models coherently\nintegrates loss-based supervisory signals while enabling effective\nsemi-supervised learning from partially labeled data. We derive learning\nalgorithms for semi-supervised mixture and topic models using stochastic\ngradient descent with automatic differentiation. We demonstrate improved\nprediction quality compared to several previous supervised topic models,\nachieving predictions competitive with high-dimensional logistic regression on\ntext sentiment analysis and electronic health records tasks while\nsimultaneously learning interpretable topics. \n\n"}
{"id": "1707.08214", "contents": "Title: Dual Rectified Linear Units (DReLUs): A Replacement for Tanh Activation\n  Functions in Quasi-Recurrent Neural Networks Abstract: In this paper, we introduce a novel type of Rectified Linear Unit (ReLU),\ncalled a Dual Rectified Linear Unit (DReLU). A DReLU, which comes with an\nunbounded positive and negative image, can be used as a drop-in replacement for\na tanh activation function in the recurrent step of Quasi-Recurrent Neural\nNetworks (QRNNs) (Bradbury et al. (2017)). Similar to ReLUs, DReLUs are less\nprone to the vanishing gradient problem, they are noise robust, and they induce\nsparse activations.\n  We independently reproduce the QRNN experiments of Bradbury et al. (2017) and\ncompare our DReLU-based QRNNs with the original tanh-based QRNNs and Long\nShort-Term Memory networks (LSTMs) on sentiment classification and word-level\nlanguage modeling. Additionally, we evaluate on character-level language\nmodeling, showing that we are able to stack up to eight QRNN layers with\nDReLUs, thus making it possible to improve the current state-of-the-art in\ncharacter-level language modeling over shallow architectures based on LSTMs. \n\n"}
{"id": "1707.08352", "contents": "Title: General Latent Feature Modeling for Data Exploration Tasks Abstract: This paper introduces a general Bayesian non- parametric latent feature model\nsuitable to per- form automatic exploratory analysis of heterogeneous datasets,\nwhere the attributes describing each object can be either discrete, continuous\nor mixed variables. The proposed model presents several important properties.\nFirst, it accounts for heterogeneous data while can be inferred in linear time\nwith respect to the number of objects and attributes. Second, its Bayesian\nnonparametric nature allows us to automatically infer the model complexity from\nthe data, i.e., the number of features necessary to capture the latent\nstructure in the data. Third, the latent features in the model are\nbinary-valued variables, easing the interpretability of the obtained latent\nfeatures in data exploration tasks. \n\n"}
{"id": "1707.09157", "contents": "Title: Efficient Algorithms for Non-convex Isotonic Regression through\n  Submodular Optimization Abstract: We consider the minimization of submodular functions subject to ordering\nconstraints. We show that this optimization problem can be cast as a convex\noptimization problem on a space of uni-dimensional measures, with ordering\nconstraints corresponding to first-order stochastic dominance. We propose new\ndiscretization schemes that lead to simple and efficient algorithms based on\nzero-th, first, or higher order oracles; these algorithms also lead to\nimprovements without isotonic constraints. Finally, our experiments show that\nnon-convex loss functions can be much more robust to outliers for isotonic\nregression, while still leading to an efficient optimization problem. \n\n"}
{"id": "1708.00308", "contents": "Title: SenGen: Sentence Generating Neural Variational Topic Model Abstract: We present a new topic model that generates documents by sampling a topic for\none whole sentence at a time, and generating the words in the sentence using an\nRNN decoder that is conditioned on the topic of the sentence. We argue that\nthis novel formalism will help us not only visualize and model the topical\ndiscourse structure in a document better, but also potentially lead to more\ninterpretable topics since we can now illustrate topics by sampling\nrepresentative sentences instead of bag of words or phrases. We present a\nvariational auto-encoder approach for learning in which we use a factorized\nvariational encoder that independently models the posterior over topical\nmixture vectors of documents using a feed-forward network, and the posterior\nover topic assignments to sentences using an RNN. Our preliminary experiments\non two different datasets indicate early promise, but also expose many\nchallenges that remain to be addressed. \n\n"}
{"id": "1708.02190", "contents": "Title: Intrinsically Motivated Goal Exploration Processes with Automatic\n  Curriculum Learning Abstract: Intrinsically motivated spontaneous exploration is a key enabler of\nautonomous developmental learning in human children. It enables the discovery\nof skill repertoires through autotelic learning, i.e. the self-generation,\nself-selection, self-ordering and self-experimentation of learning goals. We\npresent an algorithmic approach called Intrinsically Motivated Goal Exploration\nProcesses (IMGEP) to enable similar properties of autonomous learning in\nmachines. The IMGEP architecture relies on several principles: 1)\nself-generation of goals, generalized as parameterized fitness functions; 2)\nselection of goals based on intrinsic rewards; 3) exploration with incremental\ngoal-parameterized policy search and exploitation with a batch learning\nalgorithm; 4) systematic reuse of information acquired when targeting a goal\nfor improving towards other goals. We present a particularly efficient form of\nIMGEP, called AMB, that uses a population-based policy and an object-centered\nspatio-temporal modularity. We provide several implementations of this\narchitecture and demonstrate their ability to automatically generate a learning\ncurriculum within several experimental setups. One of these experiments\nincludes a real humanoid robot exploring multiple spaces of goals with several\nhundred continuous dimensions and with distractors. While no particular target\ngoal is provided to these autotelic agents, this curriculum allows the\ndiscovery of diverse skills that act as stepping stones for learning more\ncomplex skills, e.g. nested tool use. \n\n"}
{"id": "1708.04781", "contents": "Title: Racing Thompson: an Efficient Algorithm for Thompson Sampling with\n  Non-conjugate Priors Abstract: Thompson sampling has impressive empirical performance for many multi-armed\nbandit problems. But current algorithms for Thompson sampling only work for the\ncase of conjugate priors since these algorithms require to infer the posterior,\nwhich is often computationally intractable when the prior is not conjugate. In\nthis paper, we propose a novel algorithm for Thompson sampling which only\nrequires to draw samples from a tractable distribution, so our algorithm is\nefficient even when the prior is non-conjugate. To do this, we reformulate\nThompson sampling as an optimization problem via the Gumbel-Max trick. After\nthat we construct a set of random variables and our goal is to identify the one\nwith highest mean. Finally, we solve it with techniques in best arm\nidentification. \n\n"}
{"id": "1708.05446", "contents": "Title: Robust Contextual Bandit via the Capped-$\\ell_{2}$ norm Abstract: This paper considers the actor-critic contextual bandit for the mobile health\n(mHealth) intervention. The state-of-the-art decision-making methods in mHealth\ngenerally assume that the noise in the dynamic system follows the Gaussian\ndistribution. Those methods use the least-square-based algorithm to estimate\nthe expected reward, which is prone to the existence of outliers. To deal with\nthe issue of outliers, we propose a novel robust actor-critic contextual bandit\nmethod for the mHealth intervention. In the critic updating, the\ncapped-$\\ell_{2}$ norm is used to measure the approximation error, which\nprevents outliers from dominating our objective. A set of weights could be\nachieved from the critic updating. Considering them gives a weighted objective\nfor the actor updating. It provides the badly noised sample in the critic\nupdating with zero weights for the actor updating. As a result, the robustness\nof both actor-critic updating is enhanced. There is a key parameter in the\ncapped-$\\ell_{2}$ norm. We provide a reliable method to properly set it by\nmaking use of one of the most fundamental definitions of outliers in\nstatistics. Extensive experiment results demonstrate that our method can\nachieve almost identical results compared with the state-of-the-art methods on\nthe dataset without outliers and dramatically outperform them on the datasets\nnoised by outliers. \n\n"}
{"id": "1708.06742", "contents": "Title: Twin Networks: Matching the Future for Sequence Generation Abstract: We propose a simple technique for encouraging generative RNNs to plan ahead.\nWe train a \"backward\" recurrent network to generate a given sequence in reverse\norder, and we encourage states of the forward model to predict cotemporal\nstates of the backward model. The backward network is used only during\ntraining, and plays no role during sampling or inference. We hypothesize that\nour approach eases modeling of long-term dependencies by implicitly forcing the\nforward states to hold information about the longer-term future (as contained\nin the backward states). We show empirically that our approach achieves 9%\nrelative improvement for a speech recognition task, and achieves significant\nimprovement on a COCO caption generation task. \n\n"}
{"id": "1708.07347", "contents": "Title: An LSTM-Based Dynamic Customer Model for Fashion Recommendation Abstract: Online fashion sales present a challenging use case for personalized\nrecommendation: Stores offer a huge variety of items in multiple sizes. Small\nstocks, high return rates, seasonality, and changing trends cause continuous\nturnover of articles for sale on all time scales. Customers tend to shop\nrarely, but often buy multiple items at once. We report on backtest experiments\nwith sales data of 100k frequent shoppers at Zalando, Europe's leading online\nfashion platform. To model changing customer and store environments, our\nrecommendation method employs a pair of neural networks: To overcome the cold\nstart problem, a feedforward network generates article embeddings in \"fashion\nspace,\" which serve as input to a recurrent neural network that predicts a\nstyle vector in this space for each client, based on their past purchase\nsequence. We compare our results with a static collaborative filtering\napproach, and a popularity ranking baseline. \n\n"}
{"id": "1708.07975", "contents": "Title: Plausible Deniability for Privacy-Preserving Data Synthesis Abstract: Releasing full data records is one of the most challenging problems in data\nprivacy. On the one hand, many of the popular techniques such as data\nde-identification are problematic because of their dependence on the background\nknowledge of adversaries. On the other hand, rigorous methods such as the\nexponential mechanism for differential privacy are often computationally\nimpractical to use for releasing high dimensional data or cannot preserve high\nutility of original data due to their extensive data perturbation.\n  This paper presents a criterion called plausible deniability that provides a\nformal privacy guarantee, notably for releasing sensitive datasets: an output\nrecord can be released only if a certain amount of input records are\nindistinguishable, up to a privacy parameter. This notion does not depend on\nthe background knowledge of an adversary. Also, it can efficiently be checked\nby privacy tests. We present mechanisms to generate synthetic datasets with\nsimilar statistical properties to the input data and the same format. We study\nthis technique both theoretically and experimentally. A key theoretical result\nshows that, with proper randomization, the plausible deniability mechanism\ngenerates differentially private synthetic data. We demonstrate the efficiency\nof this generative technique on a large dataset; it is shown to preserve the\nutility of original data with respect to various statistical analysis and\nmachine learning measures. \n\n"}
{"id": "1708.08487", "contents": "Title: On denoising autoencoders trained to minimise binary cross-entropy Abstract: Denoising autoencoders (DAEs) are powerful deep learning models used for\nfeature extraction, data generation and network pre-training. DAEs consist of\nan encoder and decoder which may be trained simultaneously to minimise a loss\n(function) between an input and the reconstruction of a corrupted version of\nthe input. There are two common loss functions used for training autoencoders,\nthese include the mean-squared error (MSE) and the binary cross-entropy (BCE).\nWhen training autoencoders on image data a natural choice of loss function is\nBCE, since pixel values may be normalised to take values in [0,1] and the\ndecoder model may be designed to generate samples that take values in (0,1). We\nshow theoretically that DAEs trained to minimise BCE may be used to take\ngradient steps in the data space towards regions of high probability under the\ndata-generating distribution. Previously this had only been shown for DAEs\ntrained using MSE. As a consequence of the theory, iterative application of a\ntrained DAE moves a data sample from regions of low probability to regions of\nhigher probability under the data-generating distribution. Firstly, we validate\nthe theory by showing that novel data samples, consistent with the training\ndata, may be synthesised when the initial data samples are random noise.\nSecondly, we motivate the theory by showing that initial data samples\nsynthesised via other methods may be improved via iterative application of a\ntrained DAE to those initial samples. \n\n"}
{"id": "1709.02753", "contents": "Title: Privacy Loss in Apple's Implementation of Differential Privacy on MacOS\n  10.12 Abstract: In June 2016, Apple announced that it will deploy differential privacy for\nsome user data collection in order to ensure privacy of user data, even from\nApple. The details of Apple's approach remained sparse. Although several\npatents have since appeared hinting at the algorithms that may be used to\nachieve differential privacy, they did not include a precise explanation of the\napproach taken to privacy parameter choice. Such choice and the overall\napproach to privacy budget use and management are key questions for\nunderstanding the privacy protections provided by any deployment of\ndifferential privacy.\n  In this work, through a combination of experiments, static and dynamic code\nanalysis of macOS Sierra (Version 10.12) implementation, we shed light on the\nchoices Apple made for privacy budget management. We discover and describe\nApple's set-up for differentially private data processing, including the\noverall data pipeline, the parameters used for differentially private\nperturbation of each piece of data, and the frequency with which such data is\nsent to Apple's servers.\n  We find that although Apple's deployment ensures that the (differential)\nprivacy loss per each datum submitted to its servers is $1$ or $2$, the overall\nprivacy loss permitted by the system is significantly higher, as high as $16$\nper day for the four initially announced applications of Emojis, New words,\nDeeplinks and Lookup Hints. Furthermore, Apple renews the privacy budget\navailable every day, which leads to a possible privacy loss of 16 times the\nnumber of days since user opt-in to differentially private data collection for\nthose four applications.\n  We advocate that in order to claim the full benefits of differentially\nprivate data collection, Apple must give full transparency of its\nimplementation, enable user choice in areas related to privacy loss, and set\nmeaningful defaults on the privacy loss permitted. \n\n"}
{"id": "1709.02909", "contents": "Title: A Simple Analysis for Exp-concave Empirical Minimization with Arbitrary\n  Convex Regularizer Abstract: In this paper, we present a simple analysis of {\\bf fast rates} with {\\it\nhigh probability} of {\\bf empirical minimization} for {\\it stochastic composite\noptimization} over a finite-dimensional bounded convex set with exponential\nconcave loss functions and an arbitrary convex regularization. To the best of\nour knowledge, this result is the first of its kind. As a byproduct, we can\ndirectly obtain the fast rate with {\\it high probability} for exponential\nconcave empirical risk minimization with and without any convex regularization,\nwhich not only extends existing results of empirical risk minimization but also\nprovides a unified framework for analyzing exponential concave empirical risk\nminimization with and without {\\it any} convex regularization. Our proof is\nvery simple only exploiting the covering number of a finite-dimensional bounded\nset and a concentration inequality of random vectors. \n\n"}
{"id": "1709.03153", "contents": "Title: MBMF: Model-Based Priors for Model-Free Reinforcement Learning Abstract: Reinforcement Learning is divided in two main paradigms: model-free and\nmodel-based. Each of these two paradigms has strengths and limitations, and has\nbeen successfully applied to real world domains that are appropriate to its\ncorresponding strengths. In this paper, we present a new approach aimed at\nbridging the gap between these two paradigms. We aim to take the best of the\ntwo paradigms and combine them in an approach that is at the same time\ndata-efficient and cost-savvy. We do so by learning a probabilistic dynamics\nmodel and leveraging it as a prior for the intertwined model-free optimization.\nAs a result, our approach can exploit the generality and structure of the\ndynamics model, but is also capable of ignoring its inevitable inaccuracies, by\ndirectly incorporating the evidence provided by the direct observation of the\ncost. Preliminary results demonstrate that our approach outperforms purely\nmodel-based and model-free approaches, as well as the approach of simply\nswitching from a model-based to a model-free setting. \n\n"}
{"id": "1709.04057", "contents": "Title: Parallelizing Linear Recurrent Neural Nets Over Sequence Length Abstract: Recurrent neural networks (RNNs) are widely used to model sequential data but\ntheir non-linear dependencies between sequence elements prevent parallelizing\ntraining over sequence length. We show the training of RNNs with only linear\nsequential dependencies can be parallelized over the sequence length using the\nparallel scan algorithm, leading to rapid training on long sequences even with\nsmall minibatch size. We develop a parallel linear recurrence CUDA kernel and\nshow that it can be applied to immediately speed up training and inference of\nseveral state of the art RNN architectures by up to 9x. We abstract recent work\non linear RNNs into a new framework of linear surrogate RNNs and develop a\nlinear surrogate model for the long short-term memory unit, the GILR-LSTM, that\nutilizes parallel linear recurrence. We extend sequence learning to new\nextremely long sequence regimes that were previously out of reach by\nsuccessfully training a GILR-LSTM on a synthetic sequence classification task\nwith a one million timestep dependency. \n\n"}
{"id": "1709.04781", "contents": "Title: Causal Fermion Systems: A Primer for Lorentzian Geometers Abstract: We give a brief introduction to causal fermion systems with a focus on the\ngeometric structures in space-time. \n\n"}
{"id": "1709.05750", "contents": "Title: Adaptive Laplace Mechanism: Differential Privacy Preservation in Deep\n  Learning Abstract: In this paper, we focus on developing a novel mechanism to preserve\ndifferential privacy in deep neural networks, such that: (1) The privacy budget\nconsumption is totally independent of the number of training steps; (2) It has\nthe ability to adaptively inject noise into features based on the contribution\nof each to the output; and (3) It could be applied in a variety of different\ndeep neural networks. To achieve this, we figure out a way to perturb affine\ntransformations of neurons, and loss functions used in deep neural networks. In\naddition, our mechanism intentionally adds \"more noise\" into features which are\n\"less relevant\" to the model output, and vice-versa. Our theoretical analysis\nfurther derives the sensitivities and error bounds of our mechanism. Rigorous\nexperiments conducted on MNIST and CIFAR-10 datasets show that our mechanism is\nhighly effective and outperforms existing solutions. \n\n"}
{"id": "1709.06075", "contents": "Title: Deep Graph Attention Model Abstract: Graph classification is a problem with practical applications in many\ndifferent domains. Most of the existing methods take the entire graph into\naccount when calculating graph features. In a graphlet-based approach, for\ninstance, the entire graph is processed to get the total count of different\ngraphlets or sub-graphs. In the real-world, however, graphs can be both large\nand noisy with discriminative patterns confined to certain regions in the graph\nonly. In this work, we study the problem of attentional processing for graph\nclassification. The use of attention allows us to focus on small but\ninformative parts of the graph, avoiding noise in the rest of the graph. We\npresent a novel RNN model, called the Graph Attention Model (GAM), that\nprocesses only a portion of the graph by adaptively selecting a sequence of\n\"interesting\" nodes. The model is equipped with an external memory component\nwhich allows it to integrate information gathered from different parts of the\ngraph. We demonstrate the effectiveness of the model through various\nexperiments. \n\n"}
{"id": "1709.06636", "contents": "Title: An Attention-based Collaboration Framework for Multi-View Network\n  Representation Learning Abstract: Learning distributed node representations in networks has been attracting\nincreasing attention recently due to its effectiveness in a variety of\napplications. Existing approaches usually study networks with a single type of\nproximity between nodes, which defines a single view of a network. However, in\nreality there usually exists multiple types of proximities between nodes,\nyielding networks with multiple views. This paper studies learning node\nrepresentations for networks with multiple views, which aims to infer robust\nnode representations across different views. We propose a multi-view\nrepresentation learning approach, which promotes the collaboration of different\nviews and lets them vote for the robust representations. During the voting\nprocess, an attention mechanism is introduced, which enables each node to focus\non the most informative views. Experimental results on real-world networks show\nthat the proposed approach outperforms existing state-of-the-art approaches for\nnetwork representation learning with a single view and other competitive\napproaches with multiple views. \n\n"}
{"id": "1709.07172", "contents": "Title: SpectralLeader: Online Spectral Learning for Single Topic Models Abstract: We study the problem of learning a latent variable model from a stream of\ndata. Latent variable models are popular in practice because they can explain\nobserved data in terms of unobserved concepts. These models have been\ntraditionally studied in the offline setting. In the online setting, on the\nother hand, the online EM is arguably the most popular algorithm for learning\nlatent variable models. Although the online EM is computationally efficient, it\ntypically converges to a local optimum. In this work, we develop a new online\nlearning algorithm for latent variable models, which we call SpectralLeader.\nSpectralLeader always converges to the global optimum, and we derive a\nsublinear upper bound on its $n$-step regret in the bag-of-words model. In both\nsynthetic and real-world experiments, we show that SpectralLeader performs\nsimilarly to or better than the online EM with tuned hyper-parameters. \n\n"}
{"id": "1709.07417", "contents": "Title: Neural Optimizer Search with Reinforcement Learning Abstract: We present an approach to automate the process of discovering optimization\nmethods, with a focus on deep learning architectures. We train a Recurrent\nNeural Network controller to generate a string in a domain specific language\nthat describes a mathematical update equation based on a list of primitive\nfunctions, such as the gradient, running average of the gradient, etc. The\ncontroller is trained with Reinforcement Learning to maximize the performance\nof a model after a few epochs. On CIFAR-10, our method discovers several update\nrules that are better than many commonly used optimizers, such as Adam,\nRMSProp, or SGD with and without Momentum on a ConvNet model. We introduce two\nnew optimizers, named PowerSign and AddSign, which we show transfer well and\nimprove training on a variety of different tasks and architectures, including\nImageNet classification and Google's neural machine translation system. \n\n"}
{"id": "1709.08480", "contents": "Title: J-MOD$^{2}$: Joint Monocular Obstacle Detection and Depth Estimation Abstract: In this work, we propose an end-to-end deep architecture that jointly learns\nto detect obstacles and estimate their depth for MAV flight applications. Most\nof the existing approaches either rely on Visual SLAM systems or on depth\nestimation models to build 3D maps and detect obstacles. However, for the task\nof avoiding obstacles this level of complexity is not required. Recent works\nhave proposed multi task architectures to both perform scene understanding and\ndepth estimation. We follow their track and propose a specific architecture to\njointly estimate depth and obstacles, without the need to compute a global map,\nbut maintaining compatibility with a global SLAM system if needed. The network\narchitecture is devised to exploit the joint information of the obstacle\ndetection task, that produces more reliable bounding boxes, with the depth\nestimation one, increasing the robustness of both to scenario changes. We call\nthis architecture J-MOD$^{2}$. We test the effectiveness of our approach with\nexperiments on sequences with different appearance and focal lengths and\ncompare it to SotA multi task methods that jointly perform semantic\nsegmentation and depth estimation. In addition, we show the integration in a\nfull system using a set of simulated navigation experiments where a MAV\nexplores an unknown scenario and plans safe trajectories by using our detection\nmodel. \n\n"}
{"id": "1709.08519", "contents": "Title: Enhanced Quantum Synchronization via Quantum Machine Learning Abstract: We study the quantum synchronization between a pair of two-level systems\ninside two coupled cavities. By using a digital-analog decomposition of the\nmaster equation that rules the system dynamics, we show that this approach\nleads to quantum synchronization between both two-level systems. Moreover, we\ncan identify in this digital-analog block decomposition the fundamental\nelements of a quantum machine learning protocol, in which the agent and the\nenvironment (learning units) interact through a mediating system, namely, the\nregister. If we can additionally equip this algorithm with a classical feedback\nmechanism, which consists of projective measurements in the register,\nreinitialization of the register state and local conditional operations on the\nagent and environment subspace, a powerful and flexible quantum machine\nlearning protocol emerges. Indeed, numerical simulations show that this\nprotocol enhances the synchronization process, even when every subsystem\nexperience different loss/decoherence mechanisms, and give us the flexibility\nto choose the synchronization state. Finally, we propose an implementation\nbased on current technologies in superconducting circuits. \n\n"}
{"id": "1709.09929", "contents": "Title: SUBIC: A Supervised Bi-Clustering Approach for Precision Medicine Abstract: Traditional medicine typically applies one-size-fits-all treatment for the\nentire patient population whereas precision medicine develops tailored\ntreatment schemes for different patient subgroups. The fact that some factors\nmay be more significant for a specific patient subgroup motivates clinicians\nand medical researchers to develop new approaches to subgroup detection and\nanalysis, which is an effective strategy to personalize treatment. In this\nstudy, we propose a novel patient subgroup detection method, called Supervised\nBiclustring (SUBIC) using convex optimization and apply our approach to detect\npatient subgroups and prioritize risk factors for hypertension (HTN) in a\nvulnerable demographic subgroup (African-American). Our approach not only finds\npatient subgroups with guidance of a clinically relevant target variable but\nalso identifies and prioritizes risk factors by pursuing sparsity of the input\nvariables and encouraging similarity among the input variables and between the\ninput and target variables \n\n"}
{"id": "1709.10459", "contents": "Title: Improving image generative models with human interactions Abstract: GANs provide a framework for training generative models which mimic a data\ndistribution. However, in many cases we wish to train these generative models\nto optimize some auxiliary objective function within the data it generates,\nsuch as making more aesthetically pleasing images. In some cases, these\nobjective functions are difficult to evaluate, e.g. they may require human\ninteraction. Here, we develop a system for efficiently improving a GAN to\ntarget an objective involving human interaction, specifically generating images\nthat increase rates of positive user interactions. To improve the generative\nmodel, we build a model of human behavior in the targeted domain from a\nrelatively small set of interactions, and then use this behavioral model as an\nauxiliary loss function to improve the generative model. We show that this\nsystem is successful at improving positive interaction rates, at least on\nsimulated data, and characterize some of the factors that affect its\nperformance. \n\n"}
{"id": "1710.00892", "contents": "Title: R\\'enyi Differential Privacy Mechanisms for Posterior Sampling Abstract: Using a recently proposed privacy definition of R\\'enyi Differential Privacy\n(RDP), we re-examine the inherent privacy of releasing a single sample from a\nposterior distribution. We exploit the impact of the prior distribution in\nmitigating the influence of individual data points. In particular, we focus on\nsampling from an exponential family and specific generalized linear models,\nsuch as logistic regression. We propose novel RDP mechanisms as well as\noffering a new RDP analysis for an existing method in order to add value to the\nRDP framework. Each method is capable of achieving arbitrary RDP privacy\nguarantees, and we offer experimental results of their efficacy. \n\n"}
{"id": "1710.02254", "contents": "Title: Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency\n  for Sequence Modeling Abstract: Recurrent neural networks have shown remarkable success in modeling\nsequences. However low resource situations still adversely affect the\ngeneralizability of these models. We introduce a new family of models, called\nLattice Recurrent Units (LRU), to address the challenge of learning deep\nmulti-layer recurrent models with limited resources. LRU models achieve this\ngoal by creating distinct (but coupled) flow of information inside the units: a\nfirst flow along time dimension and a second flow along depth dimension. It\nalso offers a symmetry in how information can flow horizontally and vertically.\nWe analyze the effects of decoupling three different components of our LRU\nmodel: Reset Gate, Update Gate and Projected State. We evaluate this family on\nnew LRU models on computational convergence rates and statistical efficiency.\nOur experiments are performed on four publicly-available datasets, comparing\nwith Grid-LSTM and Recurrent Highway networks. Our results show that LRU has\nbetter empirical computational convergence rates and statistical efficiency\nvalues, along with learning more accurate language models. \n\n"}
{"id": "1710.04908", "contents": "Title: Graph Convolutional Networks for Classification with a Structured Label\n  Space Abstract: It is a usual practice to ignore any structural information underlying\nclasses in multi-class classification. In this paper, we propose a graph\nconvolutional network (GCN) augmented neural network classifier to exploit a\nknown, underlying graph structure of labels. The proposed approach resembles an\n(approximate) inference procedure in, for instance, a conditional random field\n(CRF). We evaluate the proposed approach on document classification and object\nrecognition and report both accuracies and graph-theoretic metrics that\ncorrespond to the consistency of the model's prediction. The experiment results\nreveal that the proposed model outperforms a baseline method which ignores the\ngraph structures of a label space in terms of graph-theoretic metrics. \n\n"}
{"id": "1710.06081", "contents": "Title: Boosting Adversarial Attacks with Momentum Abstract: Deep neural networks are vulnerable to adversarial examples, which poses\nsecurity concerns on these algorithms due to the potentially severe\nconsequences. Adversarial attacks serve as an important surrogate to evaluate\nthe robustness of deep learning models before they are deployed. However, most\nof existing adversarial attacks can only fool a black-box model with a low\nsuccess rate. To address this issue, we propose a broad class of momentum-based\niterative algorithms to boost adversarial attacks. By integrating the momentum\nterm into the iterative process for attacks, our methods can stabilize update\ndirections and escape from poor local maxima during the iterations, resulting\nin more transferable adversarial examples. To further improve the success rates\nfor black-box attacks, we apply momentum iterative algorithms to an ensemble of\nmodels, and show that the adversarially trained models with a strong defense\nability are also vulnerable to our black-box attacks. We hope that the proposed\nmethods will serve as a benchmark for evaluating the robustness of various deep\nmodels and defense methods. With this method, we won the first places in NIPS\n2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack\ncompetitions. \n\n"}
{"id": "1710.06422", "contents": "Title: Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from\n  Simulation Abstract: Learning-based approaches to robotic manipulation are limited by the\nscalability of data collection and accessibility of labels. In this paper, we\npresent a multi-task domain adaptation framework for instance grasping in\ncluttered scenes by utilizing simulated robot experiments. Our neural network\ntakes monocular RGB images and the instance segmentation mask of a specified\ntarget object as inputs, and predicts the probability of successfully grasping\nthe specified object for each candidate motor command. The proposed transfer\nlearning framework trains a model for instance grasping in simulation and uses\na domain-adversarial loss to transfer the trained model to real robots using\nindiscriminate grasping data, which is available both in simulation and the\nreal world. We evaluate our model in real-world robot experiments, comparing it\nwith alternative model architectures as well as an indiscriminate grasping\nbaseline. \n\n"}
{"id": "1710.06952", "contents": "Title: Asynchronous Decentralized Parallel Stochastic Gradient Descent Abstract: Most commonly used distributed machine learning systems are either\nsynchronous or centralized asynchronous. Synchronous algorithms like\nAllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous\nalgorithms using a parameter server suffer from 1) communication bottleneck at\nparameter servers when workers are many, and 2) significantly worse convergence\nwhen the traffic to parameter server is congested. Can we design an algorithm\nthat is robust in a heterogeneous environment, while being communication\nefficient and maintaining the best-possible convergence rate? In this paper, we\npropose an asynchronous decentralized stochastic gradient decent algorithm\n(AD-PSGD) satisfying all above expectations. Our theoretical analysis shows\nAD-PSGD converges at the optimal $O(1/\\sqrt{K})$ rate as SGD and has linear\nspeedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of\ndecentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and\nstandard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a\nheterogeneous environment. When training ResNet-50 on ImageNet with up to 128\nGPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each\nepoch can be up to 4-8X faster than its synchronous counterparts in a\nnetwork-sharing HPC environment. To the best of our knowledge, AD-PSGD is the\nfirst asynchronous algorithm that achieves a similar epoch-wise convergence\nrate as AllReduce-SGD, at an over 100-GPU scale. \n\n"}
{"id": "1710.07462", "contents": "Title: Tracking the gradients using the Hessian: A new look at variance\n  reducing stochastic methods Abstract: Our goal is to improve variance reducing stochastic methods through better\ncontrol variates. We first propose a modification of SVRG which uses the\nHessian to track gradients over time, rather than to recondition, increasing\nthe correlation of the control variates and leading to faster theoretical\nconvergence close to the optimum. We then propose accurate and computationally\nefficient approximations to the Hessian, both using a diagonal and a low-rank\nmatrix. Finally, we demonstrate the effectiveness of our method on a wide range\nof problems. \n\n"}
{"id": "1710.08177", "contents": "Title: Progressive Learning for Systematic Design of Large Neural Networks Abstract: We develop an algorithm for systematic design of a large artificial neural\nnetwork using a progression property. We find that some non-linear functions,\nsuch as the rectifier linear unit and its derivatives, hold the property. The\nsystematic design addresses the choice of network size and regularization of\nparameters. The number of nodes and layers in network increases in progression\nwith the objective of consistently reducing an appropriate cost. Each layer is\noptimized at a time, where appropriate parameters are learned using convex\noptimization. Regularization parameters for convex optimization do not need a\nsignificant manual effort for tuning. We also use random instances for some\nweight matrices, and that helps to reduce the number of parameters we learn.\nThe developed network is expected to show good generalization power due to\nappropriate regularization and use of random weights in the layers. This\nexpectation is verified by extensive experiments for classification and\nregression problems, using standard databases. \n\n"}
{"id": "1710.08878", "contents": "Title: Classification on Large Networks: A Quantitative Bound via Motifs and\n  Graphons Abstract: When each data point is a large graph, graph statistics such as densities of\ncertain subgraphs (motifs) can be used as feature vectors for machine learning.\nWhile intuitive, motif counts are expensive to compute and difficult to work\nwith theoretically. Via graphon theory, we give an explicit quantitative bound\nfor the ability of motif homomorphisms to distinguish large networks under both\ngenerative and sampling noise. Furthermore, we give similar bounds for the\ngraph spectrum and connect it to homomorphism densities of cycles. This results\nin an easily computable classifier on graph data with theoretical performance\nguarantee. Our method yields competitive results on classification tasks for\nthe autoimmune disease Lupus Erythematosus. \n\n"}
{"id": "1710.09471", "contents": "Title: Inductive Representation Learning in Large Attributed Graphs Abstract: Graphs (networks) are ubiquitous and allow us to model entities (nodes) and\nthe dependencies (edges) between them. Learning a useful feature representation\nfrom graph data lies at the heart and success of many machine learning tasks\nsuch as classification, anomaly detection, link prediction, among many others.\nMany existing techniques use random walks as a basis for learning features or\nestimating the parameters of a graph model for a downstream prediction task.\nExamples include recent node embedding methods such as DeepWalk, node2vec, as\nwell as graph-based deep learning algorithms. However, the simple random walk\nused by these methods is fundamentally tied to the identity of the node. This\nhas three main disadvantages. First, these approaches are inherently\ntransductive and do not generalize to unseen nodes and other graphs. Second,\nthey are not space-efficient as a feature vector is learned for each node which\nis impractical for large graphs. Third, most of these approaches lack support\nfor attributed graphs.\n  To make these methods more generally applicable, we propose a framework for\ninductive network representation learning based on the notion of attributed\nrandom walk that is not tied to node identity and is instead based on learning\na function $\\Phi : \\mathrm{\\rm \\bf x} \\rightarrow w$ that maps a node attribute\nvector $\\mathrm{\\rm \\bf x}$ to a type $w$. This framework serves as a basis for\ngeneralizing existing methods such as DeepWalk, node2vec, and many other\nprevious methods that leverage traditional random walks. \n\n"}
{"id": "1710.09553", "contents": "Title: Rethinking generalization requires revisiting old ideas: statistical\n  mechanics approaches and complex learning behavior Abstract: We describe an approach to understand the peculiar and counterintuitive\ngeneralization properties of deep neural networks. The approach involves going\nbeyond worst-case theoretical capacity control frameworks that have been\npopular in machine learning in recent years to revisit old ideas in the\nstatistical mechanics of neural networks. Within this approach, we present a\nprototypical Very Simple Deep Learning (VSDL) model, whose behavior is\ncontrolled by two control parameters, one describing an effective amount of\ndata, or load, on the network (that decreases when noise is added to the\ninput), and one with an effective temperature interpretation (that increases\nwhen algorithms are early stopped). Using this model, we describe how a very\nsimple application of ideas from the statistical mechanics theory of\ngeneralization provides a strong qualitative description of recently-observed\nempirical results regarding the inability of deep neural networks not to\noverfit training data, discontinuous learning and sharp transitions in the\ngeneralization properties of learning algorithms, etc. \n\n"}
{"id": "1710.10467", "contents": "Title: Generalized End-to-End Loss for Speaker Verification Abstract: In this paper, we propose a new loss function called generalized end-to-end\n(GE2E) loss, which makes the training of speaker verification models more\nefficient than our previous tuple-based end-to-end (TE2E) loss function. Unlike\nTE2E, the GE2E loss function updates the network in a way that emphasizes\nexamples that are difficult to verify at each step of the training process.\nAdditionally, the GE2E loss does not require an initial stage of example\nselection. With these properties, our model with the new loss function\ndecreases speaker verification EER by more than 10%, while reducing the\ntraining time by 60% at the same time. We also introduce the MultiReader\ntechnique, which allows us to do domain adaptation - training a more accurate\nmodel that supports multiple keywords (i.e. \"OK Google\" and \"Hey Google\") as\nwell as multiple dialects. \n\n"}
{"id": "1710.10784", "contents": "Title: How deep learning works --The geometry of deep learning Abstract: Why and how that deep learning works well on different tasks remains a\nmystery from a theoretical perspective. In this paper we draw a geometric\npicture of the deep learning system by finding its analogies with two existing\ngeometric structures, the geometry of quantum computations and the geometry of\nthe diffeomorphic template matching. In this framework, we give the geometric\nstructures of different deep learning systems including convolutional neural\nnetworks, residual networks, recursive neural networks, recurrent neural\nnetworks and the equilibrium prapagation framework. We can also analysis the\nrelationship between the geometrical structures and their performance of\ndifferent networks in an algorithmic level so that the geometric framework may\nguide the design of the structures and algorithms of deep learning systems. \n\n"}
{"id": "1710.11417", "contents": "Title: TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep\n  Reinforcement Learning Abstract: Combining deep model-free reinforcement learning with on-line planning is a\npromising approach to building on the successes of deep RL. On-line planning\nwith look-ahead trees has proven successful in environments where transition\nmodels are known a priori. However, in complex environments where transition\nmodels need to be learned from data, the deficiencies of learned models have\nlimited their utility for planning. To address these challenges, we propose\nTreeQN, a differentiable, recursive, tree-structured model that serves as a\ndrop-in replacement for any value function network in deep RL with discrete\nactions. TreeQN dynamically constructs a tree by recursively applying a\ntransition model in a learned abstract state space and then aggregating\npredicted rewards and state-values using a tree backup to estimate Q-values. We\nalso propose ATreeC, an actor-critic variant that augments TreeQN with a\nsoftmax layer to form a stochastic policy network. Both approaches are trained\nend-to-end, such that the learned model is optimised for its actual use in the\ntree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a\nbox-pushing task, as well as n-step DQN and value prediction networks (Oh et\nal. 2017) on multiple Atari games. Furthermore, we present ablation studies\nthat demonstrate the effect of different auxiliary losses on learning\ntransition models. \n\n"}
{"id": "1711.00137", "contents": "Title: Pomegranate: fast and flexible probabilistic modeling in python Abstract: We present pomegranate, an open source machine learning package for\nprobabilistic modeling in Python. Probabilistic modeling encompasses a wide\nrange of methods that explicitly describe uncertainty using probability\ndistributions. Three widely used probabilistic models implemented in\npomegranate are general mixture models, hidden Markov models, and Bayesian\nnetworks. A primary focus of pomegranate is to abstract away the complexities\nof training models from their definition. This allows users to focus on\nspecifying the correct model for their application instead of being limited by\ntheir understanding of the underlying algorithms. An aspect of this focus\ninvolves the collection of additive sufficient statistics from data sets as a\nstrategy for training models. This approach trivially enables many useful\nlearning strategies, such as out-of-core learning, minibatch learning, and\nsemi-supervised learning, without requiring the user to consider how to\npartition data or modify the algorithms to handle these tasks themselves.\npomegranate is written in Cython to speed up calculations and releases the\nglobal interpreter lock to allow for built-in multithreaded parallelism, making\nit competitive with---or outperform---other implementations of similar\nalgorithms. This paper presents an overview of the design choices in\npomegranate, and how they have enabled complex features to be supported by\nsimple code. \n\n"}
{"id": "1711.02038", "contents": "Title: An efficient quantum algorithm for generative machine learning Abstract: A central task in the field of quantum computing is to find applications\nwhere quantum computer could provide exponential speedup over any classical\ncomputer. Machine learning represents an important field with broad\napplications where quantum computer may offer significant speedup. Several\nquantum algorithms for discriminative machine learning have been found based on\nefficient solving of linear algebraic problems, with potential exponential\nspeedup in runtime under the assumption of effective input from a quantum\nrandom access memory. In machine learning, generative models represent another\nlarge class which is widely used for both supervised and unsupervised learning.\nHere, we propose an efficient quantum algorithm for machine learning based on a\nquantum generative model. We prove that our proposed model is exponentially\nmore powerful to represent probability distributions compared with classical\ngenerative models and has exponential speedup in training and inference at\nleast for some instances under a reasonable assumption in computational\ncomplexity theory. Our result opens a new direction for quantum machine\nlearning and offers a remarkable example in which a quantum algorithm shows\nexponential improvement over any classical algorithm in an important\napplication field. \n\n"}
{"id": "1711.02326", "contents": "Title: Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent\n  Networks Abstract: A major drawback of backpropagation through time (BPTT) is the difficulty of\nlearning long-term dependencies, coming from having to propagate credit\ninformation backwards through every single step of the forward computation.\nThis makes BPTT both computationally impractical and biologically implausible.\nFor this reason, full backpropagation through time is rarely used on long\nsequences, and truncated backpropagation through time is used as a heuristic.\nHowever, this usually leads to biased estimates of the gradient in which longer\nterm dependencies are ignored. Addressing this issue, we propose an alternative\nalgorithm, Sparse Attentive Backtracking, which might also be related to\nprinciples used by brains to learn long-term dependencies. Sparse Attentive\nBacktracking learns an attention mechanism over the hidden states of the past\nand selectively backpropagates through paths with high attention weights. This\nallows the model to learn long term dependencies while only backtracking for a\nsmall number of time steps, not just from the recent past but also from\nattended relevant past states. \n\n"}
{"id": "1711.02810", "contents": "Title: Deep Fault Analysis and Subset Selection in Solar Power Grids Abstract: Non-availability of reliable and sustainable electric power is a major\nproblem in the developing world. Renewable energy sources like solar are not\nvery lucrative in the current stage due to various uncertainties like weather,\nstorage, land use among others. There also exists various other issues like\nmis-commitment of power, absence of intelligent fault analysis, congestion,\netc. In this paper, we propose a novel deep learning-based system for\npredicting faults and selecting power generators optimally so as to reduce\ncosts and ensure higher reliability in solar power systems. The results are\nhighly encouraging and they suggest that the approaches proposed in this paper\nhave the potential to be applied successfully in the developing world. \n\n"}
{"id": "1711.03656", "contents": "Title: p-FP: Extraction, Classification, and Prediction of Website Fingerprints\n  with Deep Learning Abstract: Recent advances in learning Deep Neural Network (DNN) architectures have\nreceived a great deal of attention due to their ability to outperform\nstate-of-the-art classifiers across a wide range of applications, with little\nor no feature engineering. In this paper, we broadly study the applicability of\ndeep learning to website fingerprinting. We show that unsupervised DNNs can be\nused to extract low-dimensional feature vectors that improve the performance of\nstate-of-the-art website fingerprinting attacks. When used as classifiers, we\nshow that they can match or exceed performance of existing attacks across a\nrange of application scenarios, including fingerprinting Tor website traces,\nfingerprinting search engine queries over Tor, defeating fingerprinting\ndefenses, and fingerprinting TLS-encrypted websites. Finally, we show that DNNs\ncan be used to predict the fingerprintability of a website based on its\ncontents, achieving 99% accuracy on a data set of 4500 website downloads. \n\n"}
{"id": "1711.03953", "contents": "Title: Breaking the Softmax Bottleneck: A High-Rank RNN Language Model Abstract: We formulate language modeling as a matrix factorization problem, and show\nthat the expressiveness of Softmax-based models (including the majority of\nneural language models) is limited by a Softmax bottleneck. Given that natural\nlanguage is highly context-dependent, this further implies that in practice\nSoftmax with distributed word embeddings does not have enough capacity to model\nnatural language. We propose a simple and effective method to address this\nissue, and improve the state-of-the-art perplexities on Penn Treebank and\nWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on\nthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 points\nin perplexity. \n\n"}
{"id": "1711.04094", "contents": "Title: Enhancing Network Embedding with Auxiliary Information: An Explicit\n  Matrix Factorization Perspective Abstract: Recent advances in the field of network embedding have shown the\nlow-dimensional network representation is playing a critical role in network\nanalysis. However, most of the existing principles of network embedding do not\nincorporate auxiliary information such as content and labels of nodes flexibly.\nIn this paper, we take a matrix factorization perspective of network embedding,\nand incorporate structure, content and label information of the network\nsimultaneously. For structure, we validate that the matrix we construct\npreserves high-order proximities of the network. Label information can be\nfurther integrated into the matrix via the process of random walk sampling to\nenhance the quality of embedding in an unsupervised manner, i.e., without\nleveraging downstream classifiers. In addition, we generalize the Skip-Gram\nNegative Sampling model to integrate the content of the network in a matrix\nfactorization framework. As a consequence, network embedding can be learned in\na unified framework integrating network structure and node content as well as\nlabel information simultaneously. We demonstrate the efficacy of the proposed\nmodel with the tasks of semi-supervised node classification and link prediction\non a variety of real-world benchmark network datasets. \n\n"}
{"id": "1711.05144", "contents": "Title: Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup\n  Fairness Abstract: The most prevalent notions of fairness in machine learning are statistical\ndefinitions: they fix a small collection of pre-defined groups, and then ask\nfor parity of some statistic of the classifier across these groups. Constraints\nof this form are susceptible to intentional or inadvertent \"fairness\ngerrymandering\", in which a classifier appears to be fair on each individual\ngroup, but badly violates the fairness constraint on one or more structured\nsubgroups defined over the protected attributes. We propose instead to demand\nstatistical notions of fairness across exponentially (or infinitely) many\nsubgroups, defined by a structured class of functions over the protected\nattributes. This interpolates between statistical definitions of fairness and\nrecently proposed individual notions of fairness, but raises several\ncomputational challenges. It is no longer clear how to audit a fixed classifier\nto see if it satisfies such a strong definition of fairness. We prove that the\ncomputational problem of auditing subgroup fairness for both equality of false\npositive rates and statistical parity is equivalent to the problem of weak\nagnostic learning, which means it is computationally hard in the worst case,\neven for simple structured subclasses.\n  We then derive two algorithms that provably converge to the best fair\nclassifier, given access to oracles which can solve the agnostic learning\nproblem. The algorithms are based on a formulation of subgroup fairness as a\ntwo-player zero-sum game between a Learner and an Auditor. Our first algorithm\nprovably converges in a polynomial number of steps. Our second algorithm enjoys\nonly provably asymptotic convergence, but has the merit of simplicity and\nfaster per-step computation. We implement the simpler algorithm using linear\nregression as a heuristic oracle, and show that we can effectively both audit\nand learn fair classifiers on real datasets. \n\n"}
{"id": "1711.05374", "contents": "Title: Optimizing Kernel Machines using Deep Learning Abstract: Building highly non-linear and non-parametric models is central to several\nstate-of-the-art machine learning systems. Kernel methods form an important\nclass of techniques that induce a reproducing kernel Hilbert space (RKHS) for\ninferring non-linear models through the construction of similarity functions\nfrom data. These methods are particularly preferred in cases where the training\ndata sizes are limited and when prior knowledge of the data similarities is\navailable. Despite their usefulness, they are limited by the computational\ncomplexity and their inability to support end-to-end learning with a\ntask-specific objective. On the other hand, deep neural networks have become\nthe de facto solution for end-to-end inference in several learning paradigms.\nIn this article, we explore the idea of using deep architectures to perform\nkernel machine optimization, for both computational efficiency and end-to-end\ninferencing. To this end, we develop the DKMO (Deep Kernel Machine\nOptimization) framework, that creates an ensemble of dense embeddings using\nNystrom kernel approximations and utilizes deep learning to generate\ntask-specific representations through the fusion of the embeddings.\nIntuitively, the filters of the network are trained to fuse information from an\nensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel\ndropout regularization to enable improved training convergence. Finally, we\nextend this framework to the multiple kernel case, by coupling a global fusion\nlayer with pre-trained deep kernel machines for each of the constituent\nkernels. Using case studies with limited training data, and lack of explicit\nfeature sources, we demonstrate the effectiveness of our framework over\nconventional model inferencing techniques. \n\n"}
{"id": "1711.05391", "contents": "Title: Semiblind subgraph reconstruction in Gaussian graphical models Abstract: Consider a social network where only a few nodes (agents) have meaningful\ninteractions in the sense that the conditional dependency graph over node\nattribute variables (behaviors) is sparse. A company that can only observe the\ninteractions between its own customers will generally not be able to accurately\nestimate its customers' dependency subgraph: it is blinded to any external\ninteractions of its customers and this blindness creates false edges in its\nsubgraph. In this paper we address the semiblind scenario where the company has\naccess to a noisy summary of the complementary subgraph connecting external\nagents, e.g., provided by a consolidator. The proposed framework applies to\nother applications as well, including field estimation from a network of awake\nand sleeping sensors and privacy-constrained information sharing over social\nsubnetworks. We propose a penalized likelihood approach in the context of a\ngraph signal obeying a Gaussian graphical models (GGM). We use a convex-concave\niterative optimization algorithm to maximize the penalized likelihood. \n\n"}
{"id": "1711.05697", "contents": "Title: Motif-based Convolutional Neural Network on Graphs Abstract: This paper introduces a generalization of Convolutional Neural Networks\n(CNNs) to graphs with irregular linkage structures, especially heterogeneous\ngraphs with typed nodes and schemas. We propose a novel spatial convolution\noperation to model the key properties of local connectivity and translation\ninvariance, using high-order connection patterns or motifs. We develop a novel\ndeep architecture Motif-CNN that employs an attention model to combine the\nfeatures extracted from multiple patterns, thus effectively capturing\nhigh-order structural and feature information. Our experiments on\nsemi-supervised node classification on real-world social networks and multiple\nrepresentative heterogeneous graph datasets indicate significant gains of 6-21%\nover existing graph CNNs and other state-of-the-art techniques. \n\n"}
{"id": "1711.06288", "contents": "Title: Language-Based Image Editing with Recurrent Attentive Models Abstract: We investigate the problem of Language-Based Image Editing (LBIE). Given a\nsource image and a natural language description, we want to generate a target\nimage by editing the source image based on the description. We propose a\ngeneric modeling framework for two sub-tasks of LBIE: language-based image\nsegmentation and image colorization. The framework uses recurrent attentive\nmodels to fuse image and language features. Instead of using a fixed step size,\nwe introduce for each region of the image a termination gate to dynamically\ndetermine after each inference step whether to continue extrapolating\nadditional information from the textual description. The effectiveness of the\nframework is validated on three datasets. First, we introduce a synthetic\ndataset, called CoSaL, to evaluate the end-to-end performance of our LBIE\nsystem. Second, we show that the framework leads to state-of-the-art\nperformance on image segmentation on the ReferIt dataset. Third, we present the\nfirst language-based colorization result on the Oxford-102 Flowers dataset. \n\n"}
{"id": "1711.07033", "contents": "Title: Decentralized High-Dimensional Bayesian Optimization with Factor Graphs Abstract: This paper presents a novel decentralized high-dimensional Bayesian\noptimization (DEC-HBO) algorithm that, in contrast to existing HBO algorithms,\ncan exploit the interdependent effects of various input components on the\noutput of the unknown objective function f for boosting the BO performance and\nstill preserve scalability in the number of input dimensions without requiring\nprior knowledge or the existence of a low (effective) dimension of the input\nspace. To realize this, we propose a sparse yet rich factor graph\nrepresentation of f to be exploited for designing an acquisition function that\ncan be similarly represented by a sparse factor graph and hence be efficiently\noptimized in a decentralized manner using distributed message passing. Despite\nrichly characterizing the interdependent effects of the input components on the\noutput of f with a factor graph, DEC-HBO can still guarantee no-regret\nperformance asymptotically. Empirical evaluation on synthetic and real-world\nexperiments (e.g., sparse Gaussian process model with 1811 hyperparameters)\nshows that DEC-HBO outperforms the state-of-the-art HBO algorithms. \n\n"}
{"id": "1711.07364", "contents": "Title: Classification with Costly Features using Deep Reinforcement Learning Abstract: We study a classification problem where each feature can be acquired for a\ncost and the goal is to optimize a trade-off between the expected\nclassification error and the feature cost. We revisit a former approach that\nhas framed the problem as a sequential decision-making problem and solved it by\nQ-learning with a linear approximation, where individual actions are either\nrequests for feature values or terminate the episode by providing a\nclassification decision. On a set of eight problems, we demonstrate that by\nreplacing the linear approximation with neural networks the approach becomes\ncomparable to the state-of-the-art algorithms developed specifically for this\nproblem. The approach is flexible, as it can be improved with any new\nreinforcement learning enhancement, it allows inclusion of pre-trained\nhigh-performance classifier, and unlike prior art, its performance is robust\nacross all evaluated datasets. \n\n"}
{"id": "1711.07478", "contents": "Title: Implementing the Deep Q-Network Abstract: The Deep Q-Network proposed by Mnih et al. [2015] has become a benchmark and\nbuilding point for much deep reinforcement learning research. However,\nreplicating results for complex systems is often challenging since original\nscientific publications are not always able to describe in detail every\nimportant parameter setting and software engineering solution. In this paper,\nwe present results from our work reproducing the results of the DQN paper. We\nhighlight key areas in the implementation that were not covered in great detail\nin the original paper to make it easier for researchers to replicate these\nresults, including termination conditions and gradient descent algorithms.\nFinally, we discuss methods for improving the computational performance and\nprovide our own implementation that is designed to work with a range of\ndomains, and not just the original Arcade Learning Environment [Bellemare et\nal., 2013]. \n\n"}
{"id": "1711.07479", "contents": "Title: Teaching a Machine to Read Maps with Deep Reinforcement Learning Abstract: The ability to use a 2D map to navigate a complex 3D environment is quite\nremarkable, and even difficult for many humans. Localization and navigation is\nalso an important problem in domains such as robotics, and has recently become\na focus of the deep reinforcement learning community. In this paper we teach a\nreinforcement learning agent to read a map in order to find the shortest way\nout of a random maze it has never seen before. Our system combines several\nstate-of-the-art methods such as A3C and incorporates novel elements such as a\nrecurrent localization cell. Our agent learns to localize itself based on 3D\nfirst person images and an approximate orientation angle. The agent generalizes\nwell to bigger mazes, showing that it learned useful localization and\nnavigation capabilities. \n\n"}
{"id": "1711.07839", "contents": "Title: Application of generative autoencoder in de novo molecular design Abstract: A major challenge in computational chemistry is the generation of novel\nmolecular structures with desirable pharmacological and physiochemical\nproperties. In this work, we investigate the potential use of autoencoder, a\ndeep learning methodology, for de novo molecular design. Various generative\nautoencoders were used to map molecule structures into a continuous latent\nspace and vice versa and their performance as structure generator was assessed.\nOur results show that the latent space preserves chemical similarity principle\nand thus can be used for the generation of analogue structures. Furthermore,\nthe latent space created by autoencoders were searched systematically to\ngenerate novel compounds with predicted activity against dopamine receptor type\n2 and compounds similar to known active compounds not included in the training\nset were identified. \n\n"}
{"id": "1711.08534", "contents": "Title: Safer Classification by Synthesis Abstract: The discriminative approach to classification using deep neural networks has\nbecome the de-facto standard in various fields. Complementing recent\nreservations about safety against adversarial examples, we show that\nconventional discriminative methods can easily be fooled to provide incorrect\nlabels with very high confidence to out of distribution examples. We posit that\na generative approach is the natural remedy for this problem, and propose a\nmethod for classification using generative models. At training time, we learn a\ngenerative model for each class, while at test time, given an example to\nclassify, we query each generator for its most similar generation, and select\nthe class corresponding to the most similar one. Our approach is general and\ncan be used with expressive models such as GANs and VAEs. At test time, our\nmethod accurately \"knows when it does not know,\" and provides resilience to out\nof distribution examples while maintaining competitive performance for standard\nexamples. \n\n"}
{"id": "1711.09176", "contents": "Title: Selling to a No-Regret Buyer Abstract: We consider the problem of a single seller repeatedly selling a single item\nto a single buyer (specifically, the buyer has a value drawn fresh from known\ndistribution $D$ in every round). Prior work assumes that the buyer is fully\nrational and will perfectly reason about how their bids today affect the\nseller's decisions tomorrow. In this work we initiate a different direction:\nthe buyer simply runs a no-regret learning algorithm over possible bids. We\nprovide a fairly complete characterization of optimal auctions for the seller\nin this domain. Specifically:\n  - If the buyer bids according to EXP3 (or any \"mean-based\" learning\nalgorithm), then the seller can extract expected revenue arbitrarily close to\nthe expected welfare. This auction is independent of the buyer's valuation $D$,\nbut somewhat unnatural as it is sometimes in the buyer's interest to overbid. -\nThere exists a learning algorithm $\\mathcal{A}$ such that if the buyer bids\naccording to $\\mathcal{A}$ then the optimal strategy for the seller is simply\nto post the Myerson reserve for $D$ every round. - If the buyer bids according\nto EXP3 (or any \"mean-based\" learning algorithm), but the seller is restricted\nto \"natural\" auction formats where overbidding is dominated (e.g. Generalized\nFirst-Price or Generalized Second-Price), then the optimal strategy for the\nseller is a pay-your-bid format with decreasing reserves over time. Moreover,\nthe seller's optimal achievable revenue is characterized by a linear program,\nand can be unboundedly better than the best truthful auction yet simultaneously\nunboundedly worse than the expected welfare. \n\n"}
{"id": "1711.10589", "contents": "Title: Contextual Outlier Interpretation Abstract: Outlier detection plays an essential role in many data-driven applications to\nidentify isolated instances that are different from the majority. While many\nstatistical learning and data mining techniques have been used for developing\nmore effective outlier detection algorithms, the interpretation of detected\noutliers does not receive much attention. Interpretation is becoming\nincreasingly important to help people trust and evaluate the developed models\nthrough providing intrinsic reasons why the certain outliers are chosen. It is\ndifficult, if not impossible, to simply apply feature selection for explaining\noutliers due to the distinct characteristics of various detection models,\ncomplicated structures of data in certain applications, and imbalanced\ndistribution of outliers and normal instances. In addition, the role of\ncontrastive contexts where outliers locate, as well as the relation between\noutliers and contexts, are usually overlooked in interpretation. To tackle the\nissues above, in this paper, we propose a novel Contextual Outlier\nINterpretation (COIN) method to explain the abnormality of existing outliers\nspotted by detectors. The interpretability for an outlier is achieved from\nthree aspects: outlierness score, attributes that contribute to the\nabnormality, and contextual description of its neighborhoods. Experimental\nresults on various types of datasets demonstrate the flexibility and\neffectiveness of the proposed framework compared with existing interpretation\napproaches. \n\n"}
{"id": "1711.11244", "contents": "Title: Strong field tests of gravity with PSR J1141-6545 Abstract: The initial results from timing observations of PSR J1141-6545, a\nrelativistic pulsar white-dwarf binary system, are presented. Predictions from\nthe timing baseline hint at the most stringent test of gravity by an asymmetric\nbinary yet. The timing precision has been hindered by the dramatic variations\nof the pulse profile due to geodetic precession, a pulsar glitch and red timing\nnoise. Methods to overcome such timing irregularities are briefly presented\nalong with preliminary results from the test of the General Theory of\nRelativity (GR) from this pulsar \n\n"}
{"id": "1712.01193", "contents": "Title: A dual framework for low-rank tensor completion Abstract: One of the popular approaches for low-rank tensor completion is to use the\nlatent trace norm regularization. However, most existing works in this\ndirection learn a sparse combination of tensors. In this work, we fill this gap\nby proposing a variant of the latent trace norm that helps in learning a\nnon-sparse combination of tensors. We develop a dual framework for solving the\nlow-rank tensor completion problem. We first show a novel characterization of\nthe dual solution space with an interesting factorization of the optimal\nsolution. Overall, the optimal solution is shown to lie on a Cartesian product\nof Riemannian manifolds. Furthermore, we exploit the versatile Riemannian\noptimization framework for proposing computationally efficient trust region\nalgorithm. The experiments illustrate the efficacy of the proposed algorithm on\nseveral real-world datasets across applications. \n\n"}
{"id": "1712.01252", "contents": "Title: An Equivalence of Fully Connected Layer and Convolutional Layer Abstract: This article demonstrates that convolutional operation can be converted to\nmatrix multiplication, which has the same calculation way with fully connected\nlayer. The article is helpful for the beginners of the neural network to\nunderstand how fully connected layer and the convolutional layer work in the\nbackend. To be concise and to make the article more readable, we only consider\nthe linear case. It can be extended to the non-linear case easily through\nplugging in a non-linear encapsulation to the values like this $\\sigma(x)$\ndenoted as $x^{\\prime}$. \n\n"}
{"id": "1712.01262", "contents": "Title: Compatibility Family Learning for Item Recommendation and Generation Abstract: Compatibility between items, such as clothes and shoes, is a major factor\namong customer's purchasing decisions. However, learning \"compatibility\" is\nchallenging due to (1) broader notions of compatibility than those of\nsimilarity, (2) the asymmetric nature of compatibility, and (3) only a small\nset of compatible and incompatible items are observed. We propose an end-to-end\ntrainable system to embed each item into a latent vector and project a query\nitem into K compatible prototypes in the same space. These prototypes reflect\nthe broad notions of compatibility. We refer to both the embedding and\nprototypes as \"Compatibility Family\". In our learned space, we introduce a\nnovel Projected Compatibility Distance (PCD) function which is differentiable\nand ensures diversity by aiming for at least one prototype to be close to a\ncompatible item, whereas none of the prototypes are close to an incompatible\nitem. We evaluate our system on a toy dataset, two Amazon product datasets, and\nPolyvore outfit dataset. Our method consistently achieves state-of-the-art\nperformance. Finally, we show that we can visualize the candidate compatible\nprototypes using a Metric-regularized Conditional Generative Adversarial\nNetwork (MrCGAN), where the input is a projected prototype and the output is a\ngenerated image of a compatible item. We ask human evaluators to judge the\nrelative compatibility between our generated images and images generated by\nCGANs conditioned directly on query items. Our generated images are\nsignificantly preferred, with roughly twice the number of votes as others. \n\n"}
{"id": "1712.01378", "contents": "Title: Linearly-Recurrent Autoencoder Networks for Learning Dynamics Abstract: This paper describes a method for learning low-dimensional approximations of\nnonlinear dynamical systems, based on neural-network approximations of the\nunderlying Koopman operator. Extended Dynamic Mode Decomposition (EDMD)\nprovides a useful data-driven approximation of the Koopman operator for\nanalyzing dynamical systems. This paper addresses a fundamental problem\nassociated with EDMD: a trade-off between representational capacity of the\ndictionary and over-fitting due to insufficient data. A new neural network\narchitecture combining an autoencoder with linear recurrent dynamics in the\nencoded state is used to learn a low-dimensional and highly informative\nKoopman-invariant subspace of observables. A method is also presented for\nbalanced model reduction of over-specified EDMD systems in feature space.\nNonlinear reconstruction using partially linear multi-kernel regression aims to\nimprove reconstruction accuracy from the low-dimensional state when the data\nhas complex but intrinsically low-dimensional structure. The techniques\ndemonstrate the ability to identify Koopman eigenfunctions of the unforced\nDuffing equation, create accurate low-dimensional models of an unstable\ncylinder wake flow, and make short-time predictions of the chaotic\nKuramoto-Sivashinsky equation. \n\n"}
{"id": "1712.01727", "contents": "Title: OL\\'E: Orthogonal Low-rank Embedding, A Plug and Play Geometric Loss for\n  Deep Learning Abstract: Deep neural networks trained using a softmax layer at the top and the\ncross-entropy loss are ubiquitous tools for image classification. Yet, this\ndoes not naturally enforce intra-class similarity nor inter-class margin of the\nlearned deep representations. To simultaneously achieve these two goals,\ndifferent solutions have been proposed in the literature, such as the pairwise\nor triplet losses. However, such solutions carry the extra task of selecting\npairs or triplets, and the extra computational burden of computing and learning\nfor many combinations of them. In this paper, we propose a plug-and-play loss\nterm for deep networks that explicitly reduces intra-class variance and\nenforces inter-class margin simultaneously, in a simple and elegant geometric\nmanner. For each class, the deep features are collapsed into a learned linear\nsubspace, or union of them, and inter-class subspaces are pushed to be as\northogonal as possible. Our proposed Orthogonal Low-rank Embedding (OL\\'E) does\nnot require carefully crafting pairs or triplets of samples for training, and\nworks standalone as a classification loss, being the first reported deep metric\nlearning framework of its kind. Because of the improved margin between features\nof different classes, the resulting deep networks generalize better, are more\ndiscriminative, and more robust. We demonstrate improved classification\nperformance in general object recognition, plugging the proposed loss term into\nexisting off-the-shelf architectures. In particular, we show the advantage of\nthe proposed loss in the small data/model scenario, and we significantly\nadvance the state-of-the-art on the Stanford STL-10 benchmark. \n\n"}
{"id": "1712.01943", "contents": "Title: On stability of a neutron star system in Palatini gravity Abstract: We formulate the generalized Tolman-Oppenheimer-Volkoff equations for the\n$f(\\hat{R})$ Palatini gravity in the case of static and spherical symmetric\ngeometry. We also show that a neutron star is a stable system independently of\nthe form of the functional $f(\\hat{R})$ \n\n"}
{"id": "1712.02838", "contents": "Title: End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy\n  Gradient Abstract: Learning a goal-oriented dialog policy is generally performed offline with\nsupervised learning algorithms or online with reinforcement learning (RL).\nAdditionally, as companies accumulate massive quantities of dialog transcripts\nbetween customers and trained human agents, encoder-decoder methods have gained\npopularity as agent utterances can be directly treated as supervision without\nthe need for utterance-level annotations. However, one potential drawback of\nsuch approaches is that they myopically generate the next agent utterance\nwithout regard for dialog-level considerations. To resolve this concern, this\npaper describes an offline RL method for learning from unannotated corpora that\ncan optimize a goal-oriented policy at both the utterance and dialog level. We\nintroduce a novel reward function and use both on-policy and off-policy policy\ngradient to learn a policy offline without requiring online user interaction or\nan explicit state space definition. \n\n"}
{"id": "1712.03390", "contents": "Title: NAG: Network for Adversary Generation Abstract: Adversarial perturbations can pose a serious threat for deploying machine\nlearning systems. Recent works have shown existence of image-agnostic\nperturbations that can fool classifiers over most natural images. Existing\nmethods present optimization approaches that solve for a fooling objective with\nan imperceptibility constraint to craft the perturbations. However, for a given\nclassifier, they generate one perturbation at a time, which is a single\ninstance from the manifold of adversarial perturbations. Also, in order to\nbuild robust models, it is essential to explore the manifold of adversarial\nperturbations. In this paper, we propose for the first time, a generative\napproach to model the distribution of adversarial perturbations. The\narchitecture of the proposed model is inspired from that of GANs and is trained\nusing fooling and diversity objectives. Our trained generator network attempts\nto capture the distribution of adversarial perturbations for a given classifier\nand readily generates a wide variety of such perturbations. Our experimental\nevaluation demonstrates that perturbations crafted by our model (i) achieve\nstate-of-the-art fooling rates, (ii) exhibit wide variety and (iii) deliver\nexcellent cross model generalizability. Our work can be deemed as an important\nstep in the process of inferring about the complex manifolds of adversarial\nperturbations. \n\n"}
{"id": "1712.03890", "contents": "Title: DeepConfig: Automating Data Center Network Topologies Management with\n  Machine Learning Abstract: In recent years, many techniques have been developed to improve the\nperformance and efficiency of data center networks. While these techniques\nprovide high accuracy, they are often designed using heuristics that leverage\ndomain-specific properties of the workload or hardware.\n  In this vision paper, we argue that many data center networking techniques,\ne.g., routing, topology augmentation, energy savings, with diverse goals\nactually share design and architectural similarity. We present a design for\ndeveloping general intermediate representations of network topologies using\ndeep learning that is amenable to solving classes of data center problems. We\ndevelop a framework, DeepConfig, that simplifies the processing of configuring\nand training deep learning agents that use the intermediate representation to\nlearns different tasks. To illustrate the strength of our approach, we\nconfigured, implemented, and evaluated a DeepConfig-Agent that tackles the data\ncenter topology augmentation problem. Our initial results are promising ---\nDeepConfig performs comparably to the optimal. \n\n"}
{"id": "1712.04567", "contents": "Title: Practical Bayesian optimization in the presence of outliers Abstract: Inference in the presence of outliers is an important field of research as\noutliers are ubiquitous and may arise across a variety of problems and domains.\nBayesian optimization is method that heavily relies on probabilistic inference.\nThis allows outstanding sample efficiency because the probabilistic machinery\nprovides a memory of the whole optimization process. However, that virtue\nbecomes a disadvantage when the memory is populated with outliers, inducing\nbias in the estimation. In this paper, we present an empirical evaluation of\nBayesian optimization methods in the presence of outliers. The empirical\nevidence shows that Bayesian optimization with robust regression often produces\nsuboptimal results. We then propose a new algorithm which combines robust\nregression (a Gaussian process with Student-t likelihood) with outlier\ndiagnostics to classify data points as outliers or inliers. By using an\nscheduler for the classification of outliers, our method is more efficient and\nhas better convergence over the standard robust regression. Furthermore, we\nshow that even in controlled situations with no expected outliers, our method\nis able to produce better results. \n\n"}
{"id": "1712.05690", "contents": "Title: Sockeye: A Toolkit for Neural Machine Translation Abstract: We describe Sockeye (version 1.12), an open-source sequence-to-sequence\ntoolkit for Neural Machine Translation (NMT). Sockeye is a production-ready\nframework for training and applying models as well as an experimental platform\nfor researchers. Written in Python and built on MXNet, the toolkit offers\nscalable training and inference for the three most prominent encoder-decoder\narchitectures: attentional recurrent neural networks, self-attentional\ntransformers, and fully convolutional networks. Sockeye also supports a wide\nrange of optimizers, normalization and regularization techniques, and inference\nimprovements from current NMT literature. Users can easily run standard\ntraining recipes, explore different model settings, and incorporate new ideas.\nIn this paper, we highlight Sockeye's features and benchmark it against other\nNMT toolkits on two language arcs from the 2017 Conference on Machine\nTranslation (WMT): English-German and Latvian-English. We report competitive\nBLEU scores across all three architectures, including an overall best score for\nSockeye's transformer implementation. To facilitate further comparison, we\nrelease all system outputs and training scripts used in our experiments. The\nSockeye toolkit is free software released under the Apache 2.0 license. \n\n"}
{"id": "1712.06541", "contents": "Title: Size-Independent Sample Complexity of Neural Networks Abstract: We study the sample complexity of learning neural networks, by providing new\nbounds on their Rademacher complexity assuming norm constraints on the\nparameter matrix of each layer. Compared to previous work, these complexity\nbounds have improved dependence on the network depth, and under some additional\nassumptions, are fully independent of the network size (both depth and width).\nThese results are derived using some novel techniques, which may be of\nindependent interest. \n\n"}
{"id": "1712.07066", "contents": "Title: Nonlocal gravity. Conceptual aspects and cosmological predictions Abstract: Even if the fundamental action of gravity is local, the corresponding quantum\neffective action, that includes the effect of quantum fluctuations, is a\nnonlocal object. These nonlocalities are well understood in the ultraviolet\nregime but much less in the infrared, where they could in principle give rise\nto important cosmological effects. Here we systematize and extend previous work\nof our group, in which it is assumed that a mass scale $\\Lambda$ is dynamically\ngenerated in the infrared, giving rise to nonlocal terms in the quantum\neffective action of gravity. We give a detailed discussion of conceptual\naspects related to nonlocal gravity and of the cosmological consequences of\nthese models. The requirement of providing a viable cosmological evolution\nseverely restricts the form of the nonlocal terms, and selects a model (the\nso-called RR model) that corresponds to a dynamical mass generation for the\nconformal mode. For such a model: (1) there is a FRW background evolution,\nwhere the nonlocal term acts as an effective dark energy with a phantom\nequation of state, providing accelerated expansion without a cosmological\nconstant. (2) Cosmological perturbations are well behaved. (3) Implementing the\nmodel in a Boltzmann code and comparing with observations we find that the RR\nmodel fits the CMB, BAO, SNe, structure formation data and local $H_0$\nmeasurements at a level statistically equivalent to $\\Lambda$CDM. (4) Bayesian\nparameter estimation shows that the value of $H_0$ obtained in the RR model is\nhigher than in $\\Lambda$CDM, reducing to $2.0\\sigma$ the tension with the value\nfrom local measurements. (5) The RR model provides a prediction for the sum of\nneutrino masses that falls within the limits set by oscillation and terrestrial\nexperiments. (6) Gravitational waves propagate at the speed of light, complying\nwith the limit from GW170817/GRB 170817A. \n\n"}
{"id": "1712.07113", "contents": "Title: Query-Efficient Black-box Adversarial Examples (superceded) Abstract: Note that this paper is superceded by \"Black-Box Adversarial Attacks with\nLimited Queries and Information.\"\n  Current neural network-based image classifiers are susceptible to adversarial\nexamples, even in the black-box setting, where the attacker is limited to query\naccess without access to gradients. Previous methods --- substitute networks\nand coordinate-based finite-difference methods --- are either unreliable or\nquery-inefficient, making these methods impractical for certain problems.\n  We introduce a new method for reliably generating adversarial examples under\nmore restricted, practical black-box threat models. First, we apply natural\nevolution strategies to perform black-box attacks using two to three orders of\nmagnitude fewer queries than previous methods. Second, we introduce a new\nalgorithm to perform targeted adversarial attacks in the partial-information\nsetting, where the attacker only has access to a limited number of target\nclasses. Using these techniques, we successfully perform the first targeted\nadversarial attack against a commercially deployed machine learning system, the\nGoogle Cloud Vision API, in the partial information setting. \n\n"}
{"id": "1712.08259", "contents": "Title: Linear centralization classifier Abstract: A classification algorithm, called the Linear Centralization Classifier\n(LCC), is introduced. The algorithm seeks to find a transformation that best\nmaps instances from the feature space to a space where they concentrate towards\nthe center of their own classes, while maximimizing the distance between class\ncenters. We formulate the classifier as a quadratic program with quadratic\nconstraints. We then simplify this formulation to a linear program that can be\nsolved effectively using a linear programming solver (e.g., simplex-dual). We\nextend the formulation for LCC to enable the use of kernel functions for\nnon-linear classification applications. We compare our method with two standard\nclassification methods (support vector machine and linear discriminant\nanalysis) and four state-of-the-art classification methods when they are\napplied to eight standard classification datasets. Our experimental results\nshow that LCC is able to classify instances more accurately (based on the area\nunder the receiver operating characteristic) in comparison to other tested\nmethods on the chosen datasets. We also report the results for LCC with a\nparticular kernel to solve for synthetic non-linear classification problems. \n\n"}
{"id": "1712.08968", "contents": "Title: Spurious Local Minima are Common in Two-Layer ReLU Neural Networks Abstract: We consider the optimization problem associated with training simple ReLU\nneural networks of the form $\\mathbf{x}\\mapsto\n\\sum_{i=1}^{k}\\max\\{0,\\mathbf{w}_i^\\top \\mathbf{x}\\}$ with respect to the\nsquared loss. We provide a computer-assisted proof that even if the input\ndistribution is standard Gaussian, even if the dimension is arbitrarily large,\nand even if the target values are generated by such a network, with orthonormal\nparameter vectors, the problem can still have spurious local minima once $6\\le\nk\\le 20$. By a concentration of measure argument, this implies that in high\ninput dimensions, \\emph{nearly all} target networks of the relevant sizes lead\nto spurious local minima. Moreover, we conduct experiments which show that the\nprobability of hitting such local minima is quite high, and increasing with the\nnetwork size. On the positive side, mild over-parameterization appears to\ndrastically reduce such local minima, indicating that an over-parameterization\nassumption is necessary to get a positive result in this setting. \n\n"}
{"id": "1712.10062", "contents": "Title: Multi-timescale memory dynamics in a reinforcement learning network with\n  attention-gated memory Abstract: Learning and memory are intertwined in our brain and their relationship is at\nthe core of several recent neural network models. In particular, the\nAttention-Gated MEmory Tagging model (AuGMEnT) is a reinforcement learning\nnetwork with an emphasis on biological plausibility of memory dynamics and\nlearning. We find that the AuGMEnT network does not solve some hierarchical\ntasks, where higher-level stimuli have to be maintained over a long time, while\nlower-level stimuli need to be remembered and forgotten over a shorter\ntimescale. To overcome this limitation, we introduce hybrid AuGMEnT, with leaky\nor short-timescale and non-leaky or long-timescale units in memory, that allow\nto exchange lower-level information while maintaining higher-level one, thus\nsolving both hierarchical and distractor tasks. \n\n"}
{"id": "1712.10285", "contents": "Title: SBEED: Convergent Reinforcement Learning with Nonlinear Function\n  Approximation Abstract: When function approximation is used, solving the Bellman optimality equation\nwith stability guarantees has remained a major open problem in reinforcement\nlearning for decades. The fundamental difficulty is that the Bellman operator\nmay become an expansion in general, resulting in oscillating and even divergent\nbehavior of popular algorithms like Q-learning. In this paper, we revisit the\nBellman equation, and reformulate it into a novel primal-dual optimization\nproblem using Nesterov's smoothing technique and the Legendre-Fenchel\ntransformation. We then develop a new algorithm, called Smoothed Bellman Error\nEmbedding, to solve this optimization problem where any differentiable function\nclass may be used. We provide what we believe to be the first convergence\nguarantee for general nonlinear function approximation, and analyze the\nalgorithm's sample complexity. Empirically, our algorithm compares favorably to\nstate-of-the-art baselines in several benchmark control problems. \n\n"}
{"id": "1801.00101", "contents": "Title: Parameter-free online learning via model selection Abstract: We introduce an efficient algorithmic framework for model selection in online\nlearning, also known as parameter-free online learning. Departing from previous\nwork, which has focused on highly structured function classes such as nested\nballs in Hilbert space, we propose a generic meta-algorithm framework that\nachieves online model selection oracle inequalities under minimal structural\nassumptions. We give the first computationally efficient parameter-free\nalgorithms that work in arbitrary Banach spaces under mild smoothness\nassumptions; previous results applied only to Hilbert spaces. We further derive\nnew oracle inequalities for matrix classes, non-nested convex sets, and\n$\\mathbb{R}^{d}$ with generic regularizers. Finally, we generalize these\nresults by providing oracle inequalities for arbitrary non-linear classes in\nthe online supervised learning model. These results are all derived through a\nunified meta-algorithm scheme using a novel \"multi-scale\" algorithm for\nprediction with expert advice based on random playout, which may be of\nindependent interest. \n\n"}
{"id": "1801.00723", "contents": "Title: Deep Learning for Identifying Potential Conceptual Shifts for\n  Co-creative Drawing Abstract: We present a system for identifying conceptual shifts between visual\ncategories, which will form the basis for a co-creative drawing system to help\nusers draw more creative sketches. The system recognizes human sketches and\nmatches them to structurally similar sketches from categories to which they do\nnot belong. This would allow a co-creative drawing system to produce an\nambiguous sketch that blends features from both categories. \n\n"}
{"id": "1801.00823", "contents": "Title: MVG Mechanism: Differential Privacy under Matrix-Valued Query Abstract: Differential privacy mechanism design has traditionally been tailored for a\nscalar-valued query function. Although many mechanisms such as the Laplace and\nGaussian mechanisms can be extended to a matrix-valued query function by adding\ni.i.d. noise to each element of the matrix, this method is often suboptimal as\nit forfeits an opportunity to exploit the structural characteristics typically\nassociated with matrix analysis. To address this challenge, we propose a novel\ndifferential privacy mechanism called the Matrix-Variate Gaussian (MVG)\nmechanism, which adds a matrix-valued noise drawn from a matrix-variate\nGaussian distribution, and we rigorously prove that the MVG mechanism preserves\n$(\\epsilon,\\delta)$-differential privacy. Furthermore, we introduce the concept\nof directional noise made possible by the design of the MVG mechanism.\nDirectional noise allows the impact of the noise on the utility of the\nmatrix-valued query function to be moderated. Finally, we experimentally\ndemonstrate the performance of our mechanism using three matrix-valued queries\non three privacy-sensitive datasets. We find that the MVG mechanism notably\noutperforms four previous state-of-the-art approaches, and provides comparable\nutility to the non-private baseline. \n\n"}
{"id": "1801.03132", "contents": "Title: Robust Propensity Score Computation Method based on Machine Learning\n  with Label-corrupted Data Abstract: In biostatistics, propensity score is a common approach to analyze the\nimbalance of covariate and process confounding covariates to eliminate\ndifferences between groups. While there are an abundant amount of methods to\ncompute propensity score, a common issue of them is the corrupted labels in the\ndataset. For example, the data collected from the patients could contain\nsamples that are treated mistakenly, and the computing methods could\nincorporate them as a misleading information. In this paper, we propose a\nMachine Learning-based method to handle the problem. Specifically, we utilize\nthe fact that the majority of sample should be labeled with the correct\ninstance and design an approach to first cluster the data with spectral\nclustering and then sample a new dataset with a distribution processed from the\nclustering results. The propensity score is computed by Xgboost, and a\nmathematical justification of our method is provided in this paper. The\nexperimental results illustrate that xgboost propensity scores computing with\nthe data processed by our method could outperform the same method with original\ndata, and the advantages of our method increases as we add some artificial\ncorruptions to the dataset. Meanwhile, the implementation of xgboost to compute\npropensity score for multiple treatments is also a pioneering work in the area. \n\n"}
{"id": "1801.03265", "contents": "Title: More Adaptive Algorithms for Adversarial Bandits Abstract: We develop a novel and generic algorithm for the adversarial multi-armed\nbandit problem (or more generally the combinatorial semi-bandit problem). When\ninstantiated differently, our algorithm achieves various new data-dependent\nregret bounds improving previous work. Examples include: 1) a regret bound\ndepending on the variance of only the best arm; 2) a regret bound depending on\nthe first-order path-length of only the best arm; 3) a regret bound depending\non the sum of first-order path-lengths of all arms as well as an important\nnegative term, which together lead to faster convergence rates for some normal\nform games with partial feedback; 4) a regret bound that simultaneously implies\nsmall regret when the best arm has small loss and logarithmic regret when there\nexists an arm whose expected loss is always smaller than those of others by a\nfixed gap (e.g. the classic i.i.d. setting). In some cases, such as the last\ntwo results, our algorithm is completely parameter-free.\n  The main idea of our algorithm is to apply the optimism and adaptivity\ntechniques to the well-known Online Mirror Descent framework with a special\nlog-barrier regularizer. The challenges are to come up with appropriate\noptimistic predictions and correction terms in this framework. Some of our\nresults also crucially rely on using a sophisticated increasing learning rate\nschedule. \n\n"}
{"id": "1801.03749", "contents": "Title: Improved asynchronous parallel optimization analysis for stochastic\n  incremental methods Abstract: As datasets continue to increase in size and multi-core computer\narchitectures are developed, asynchronous parallel optimization algorithms\nbecome more and more essential to the field of Machine Learning. Unfortunately,\nconducting the theoretical analysis asynchronous methods is difficult, notably\ndue to the introduction of delay and inconsistency in inherently sequential\nalgorithms. Handling these issues often requires resorting to simplifying but\nunrealistic assumptions. Through a novel perspective, we revisit and clarify a\nsubtle but important technical issue present in a large fraction of the recent\nconvergence rate proofs for asynchronous parallel optimization algorithms, and\npropose a simplification of the recently introduced \"perturbed iterate\"\nframework that resolves it. We demonstrate the usefulness of our new framework\nby analyzing three distinct asynchronous parallel incremental optimization\nalgorithms: Hogwild (asynchronous SGD), KROMAGNON (asynchronous SVRG) and\nASAGA, a novel asynchronous parallel version of the incremental gradient\nalgorithm SAGA that enjoys fast linear convergence rates. We are able to both\nremove problematic assumptions and obtain better theoretical results. Notably,\nwe prove that ASAGA and KROMAGNON can obtain a theoretical linear speedup on\nmulti-core systems even without sparsity assumptions. We present results of an\nimplementation on a 40-core architecture illustrating the practical speedups as\nwell as the hardware overhead. Finally, we investigate the overlap constant, an\nill-understood but central quantity for the theoretical analysis of\nasynchronous parallel algorithms. We find that it encompasses much more\ncomplexity than suggested in previous work, and often is order-of-magnitude\nbigger than traditionally thought. \n\n"}
{"id": "1801.03851", "contents": "Title: Autoencoders and Probabilistic Inference with Missing Data: An Exact\n  Solution for The Factor Analysis Case Abstract: Latent variable models can be used to probabilistically \"fill-in\" missing\ndata entries. The variational autoencoder architecture (Kingma and Welling,\n2014; Rezende et al., 2014) includes a \"recognition\" or \"encoder\" network that\ninfers the latent variables given the data variables. However, it is not clear\nhow to handle missing data variables in this network. The factor analysis (FA)\nmodel is a basic autoencoder, using linear encoder and decoder networks. We\nshow how to calculate exactly the latent posterior distribution for the factor\nanalysis (FA) model in the presence of missing data, and note that this\nsolution implies that a different encoder network is required for each pattern\nof missingness. We also discuss various approximations to the exact solution.\nExperiments compare the effectiveness of various approaches to filling in the\nmissing data. \n\n"}
{"id": "1801.04354", "contents": "Title: Black-box Generation of Adversarial Text Sequences to Evade Deep\n  Learning Classifiers Abstract: Although various techniques have been proposed to generate adversarial\nsamples for white-box attacks on text, little attention has been paid to\nblack-box attacks, which are more realistic scenarios. In this paper, we\npresent a novel algorithm, DeepWordBug, to effectively generate small text\nperturbations in a black-box setting that forces a deep-learning classifier to\nmisclassify a text input. We employ novel scoring strategies to identify the\ncritical tokens that, if modified, cause the classifier to make an incorrect\nprediction. Simple character-level transformations are applied to the\nhighest-ranked tokens in order to minimize the edit distance of the\nperturbation, yet change the original classification. We evaluated DeepWordBug\non eight real-world text datasets, including text classification, sentiment\nanalysis, and spam detection. We compare the result of DeepWordBug with two\nbaselines: Random (Black-box) and Gradient (White-box). Our experimental\nresults indicate that DeepWordBug reduces the prediction accuracy of current\nstate-of-the-art deep-learning models, including a decrease of 68\\% on average\nfor a Word-LSTM model and 48\\% on average for a Char-CNN model. \n\n"}
{"id": "1801.05931", "contents": "Title: Faster Learning by Reduction of Data Access Time Abstract: Nowadays, the major challenge in machine learning is the Big Data challenge.\nThe big data problems due to large number of data points or large number of\nfeatures in each data point, or both, the training of models have become very\nslow. The training time has two major components: Time to access the data and\ntime to process (learn from) the data. So far, the research has focused only on\nthe second part, i.e., learning from the data. In this paper, we have proposed\none possible solution to handle the big data problems in machine learning. The\nidea is to reduce the training time through reducing data access time by\nproposing systematic sampling and cyclic/sequential sampling to select\nmini-batches from the dataset. To prove the effectiveness of proposed sampling\ntechniques, we have used Empirical Risk Minimization, which is commonly used\nmachine learning problem, for strongly convex and smooth case. The problem has\nbeen solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each\nusing two step determination techniques, namely, constant step size and\nbacktracking line search method. Theoretical results prove the same convergence\nfor systematic sampling, cyclic sampling and the widely used random sampling\ntechnique, in expectation. Experimental results with bench marked datasets\nprove the efficacy of the proposed sampling techniques and show up to six times\nfaster training. \n\n"}
{"id": "1801.06146", "contents": "Title: Universal Language Model Fine-tuning for Text Classification Abstract: Inductive transfer learning has greatly impacted computer vision, but\nexisting approaches in NLP still require task-specific modifications and\ntraining from scratch. We propose Universal Language Model Fine-tuning\n(ULMFiT), an effective transfer learning method that can be applied to any task\nin NLP, and introduce techniques that are key for fine-tuning a language model.\nOur method significantly outperforms the state-of-the-art on six text\nclassification tasks, reducing the error by 18-24% on the majority of datasets.\nFurthermore, with only 100 labeled examples, it matches the performance of\ntraining from scratch on 100x more data. We open-source our pretrained models\nand code. \n\n"}
{"id": "1801.07353", "contents": "Title: Flexible Deep Neural Network Processing Abstract: The recent success of Deep Neural Networks (DNNs) has drastically improved\nthe state of the art for many application domains. While achieving high\naccuracy performance, deploying state-of-the-art DNNs is a challenge since they\ntypically require billions of expensive arithmetic computations. In addition,\nDNNs are typically deployed in ensemble to boost accuracy performance, which\nfurther exacerbates the system requirements. This computational overhead is an\nissue for many platforms, e.g. data centers and embedded systems, with tight\nlatency and energy budgets. In this article, we introduce flexible DNNs\nensemble processing technique, which achieves large reduction in average\ninference latency while incurring small to negligible accuracy drop. Our\ntechnique is flexible in that it allows for dynamic adaptation between quality\nof results (QoR) and execution runtime. We demonstrate the effectiveness of the\ntechnique on AlexNet and ResNet-50 using the ImageNet dataset. This technique\ncan also easily handle other types of networks. \n\n"}
{"id": "1801.09797", "contents": "Title: Discrete Autoencoders for Sequence Models Abstract: Recurrent models for sequences have been recently successful at many tasks,\nespecially for language modeling and machine translation. Nevertheless, it\nremains challenging to extract good representations from these models. For\ninstance, even though language has a clear hierarchical structure going from\ncharacters through words to sentences, it is not apparent in current language\nmodels. We propose to improve the representation in sequence models by\naugmenting current approaches with an autoencoder that is forced to compress\nthe sequence through an intermediate discrete latent space. In order to\npropagate gradients though this discrete representation we introduce an\nimproved semantic hashing technique. We show that this technique performs well\non a newly proposed quantitative efficiency measure. We also analyze latent\ncodes produced by the model showing how they correspond to words and phrases.\nFinally, we present an application of the autoencoder-augmented model to\ngenerating diverse translations. \n\n"}
{"id": "1801.10459", "contents": "Title: Pretraining Deep Actor-Critic Reinforcement Learning Algorithms With\n  Expert Demonstrations Abstract: Pretraining with expert demonstrations have been found useful in speeding up\nthe training process of deep reinforcement learning algorithms since less\nonline simulation data is required. Some people use supervised learning to\nspeed up the process of feature learning, others pretrain the policies by\nimitating expert demonstrations. However, these methods are unstable and not\nsuitable for actor-critic reinforcement learning algorithms. Also, some\nexisting methods rely on the global optimum assumption, which is not true in\nmost scenarios. In this paper, we employ expert demonstrations in a\nactor-critic reinforcement learning framework, and meanwhile ensure that the\nperformance is not affected by the fact that expert demonstrations are not\nglobal optimal. We theoretically derive a method for computing policy gradients\nand value estimators with only expert demonstrations. Our method is\ntheoretically plausible for actor-critic reinforcement learning algorithms that\npretrains both policy and value functions. We apply our method to two of the\ntypical actor-critic reinforcement learning algorithms, DDPG and ACER, and\ndemonstrate with experiments that our method not only outperforms the RL\nalgorithms without pretraining process, but also is more simulation efficient. \n\n"}
{"id": "1802.03501", "contents": "Title: Path Consistency Learning in Tsallis Entropy Regularized MDPs Abstract: We study the sparse entropy-regularized reinforcement learning (ERL) problem\nin which the entropy term is a special form of the Tsallis entropy. The optimal\npolicy of this formulation is sparse, i.e.,~at each state, it has non-zero\nprobability for only a small number of actions. This addresses the main\ndrawback of the standard Shannon entropy-regularized RL (soft ERL) formulation,\nin which the optimal policy is softmax, and thus, may assign a non-negligible\nprobability mass to non-optimal actions. This problem is aggravated as the\nnumber of actions is increased. In this paper, we follow the work of Nachum et\nal. (2017) in the soft ERL setting, and propose a class of novel path\nconsistency learning (PCL) algorithms, called {\\em sparse PCL}, for the sparse\nERL problem that can work with both on-policy and off-policy data. We first\nderive a {\\em sparse consistency} equation that specifies a relationship\nbetween the optimal value function and policy of the sparse ERL along any\nsystem trajectory. Crucially, a weak form of the converse is also true, and we\nquantify the sub-optimality of a policy which satisfies sparse consistency, and\nshow that as we increase the number of actions, this sub-optimality is better\nthan that of the soft ERL optimal policy. We then use this result to derive the\nsparse PCL algorithms. We empirically compare sparse PCL with its soft\ncounterpart, and show its advantage, especially in problems with a large number\nof actions. \n\n"}
{"id": "1802.04034", "contents": "Title: Lipschitz-Margin Training: Scalable Certification of Perturbation\n  Invariance for Deep Neural Networks Abstract: High sensitivity of neural networks against malicious perturbations on inputs\ncauses security concerns. To take a steady step towards robust classifiers, we\naim to create neural network models provably defended from perturbations. Prior\ncertification work requires strong assumptions on network structures and\nmassive computational costs, and thus the range of their applications was\nlimited. From the relationship between the Lipschitz constants and prediction\nmargins, we present a computationally efficient calculation technique to\nlower-bound the size of adversarial perturbations that can deceive networks,\nand that is widely applicable to various complicated networks. Moreover, we\npropose an efficient training procedure that robustifies networks and\nsignificantly improves the provably guarded areas around data points. In\nexperimental evaluations, our method showed its ability to provide a\nnon-trivial guarantee and enhance robustness for even large networks. \n\n"}
{"id": "1802.04064", "contents": "Title: A Contextual Bandit Bake-off Abstract: Contextual bandit algorithms are essential for solving many real-world\ninteractive machine learning problems. Despite multiple recent successes on\nstatistically and computationally efficient methods, the practical behavior of\nthese algorithms is still poorly understood. We leverage the availability of\nlarge numbers of supervised learning datasets to empirically evaluate\ncontextual bandit algorithms, focusing on practical methods that learn by\nrelying on optimization oracles from supervised learning. We find that a recent\nmethod (Foster et al., 2018) using optimism under uncertainty works the best\noverall. A surprisingly close second is a simple greedy baseline that only\nexplores implicitly through the diversity of contexts, followed by a variant of\nOnline Cover (Agarwal et al., 2014) which tends to be more conservative but\nrobust to problem specification by design. Along the way, we also evaluate\nvarious components of contextual bandit algorithm design such as loss\nestimators. Overall, this is a thorough study and review of contextual bandit\nmethodology. \n\n"}
{"id": "1802.04416", "contents": "Title: Neural Tensor Factorization Abstract: Neural collaborative filtering (NCF) and recurrent recommender systems (RRN)\nhave been successful in modeling user-item relational data. However, they are\nalso limited in their assumption of static or sequential modeling of relational\ndata as they do not account for evolving users' preference over time as well as\nchanges in the underlying factors that drive the change in user-item\nrelationship over time. We address these limitations by proposing a Neural\nTensor Factorization (NTF) model for predictive tasks on dynamic relational\ndata. The NTF model generalizes conventional tensor factorization from two\nperspectives: First, it leverages the long short-term memory architecture to\ncharacterize the multi-dimensional temporal interactions on relational data.\nSecond, it incorporates the multi-layer perceptron structure for learning the\nnon-linearities between different latent factors. Our extensive experiments\ndemonstrate the significant improvement in rating prediction and link\nprediction on dynamic relational data by our NTF model over both neural network\nbased factorization models and other traditional methods. \n\n"}
{"id": "1802.04712", "contents": "Title: Attention-based Deep Multiple Instance Learning Abstract: Multiple instance learning (MIL) is a variation of supervised learning where\na single class label is assigned to a bag of instances. In this paper, we state\nthe MIL problem as learning the Bernoulli distribution of the bag label where\nthe bag label probability is fully parameterized by neural networks.\nFurthermore, we propose a neural network-based permutation-invariant\naggregation operator that corresponds to the attention mechanism. Notably, an\napplication of the proposed attention-based operator provides insight into the\ncontribution of each instance to the bag label. We show empirically that our\napproach achieves comparable performance to the best MIL methods on benchmark\nMIL datasets and it outperforms other methods on a MNIST-based MIL dataset and\ntwo real-life histopathology datasets without sacrificing interpretability. \n\n"}
{"id": "1802.04821", "contents": "Title: Evolved Policy Gradients Abstract: We propose a metalearning approach for learning gradient-based reinforcement\nlearning (RL) algorithms. The idea is to evolve a differentiable loss function,\nsuch that an agent, which optimizes its policy to minimize this loss, will\nachieve high rewards. The loss is parametrized via temporal convolutions over\nthe agent's experience. Because this loss is highly flexible in its ability to\ntake into account the agent's history, it enables fast task learning. Empirical\nresults show that our evolved policy gradient algorithm (EPG) achieves faster\nlearning on several randomized environments compared to an off-the-shelf policy\ngradient method. We also demonstrate that EPG's learned loss can generalize to\nout-of-distribution test time tasks, and exhibits qualitatively different\nbehavior from other popular metalearning algorithms. \n\n"}
{"id": "1802.04834", "contents": "Title: Challenging Images For Minds and Machines Abstract: There is no denying the tremendous leap in the performance of machine\nlearning methods in the past half-decade. Some might even say that specific\nsub-fields in pattern recognition, such as machine-vision, are as good as\nsolved, reaching human and super-human levels. Arguably, lack of training data\nand computation power are all that stand between us and solving the remaining\nones. In this position paper we underline cases in vision which are challenging\nto machines and even to human observers. This is to show limitations of\ncontemporary models that are hard to ameliorate by following the current trend\nto increase training data, network capacity or computational power. Moreover,\nwe claim that attempting to do so is in principle a suboptimal approach. We\nprovide a taster of such examples in hope to encourage and challenge the\nmachine learning community to develop new directions to solve the said\ndifficulties. \n\n"}
{"id": "1802.05380", "contents": "Title: Active Feature Acquisition with Supervised Matrix Completion Abstract: Feature missing is a serious problem in many applications, which may lead to\nlow quality of training data and further significantly degrade the learning\nperformance. While feature acquisition usually involves special devices or\ncomplex process, it is expensive to acquire all feature values for the whole\ndataset. On the other hand, features may be correlated with each other, and\nsome values may be recovered from the others. It is thus important to decide\nwhich features are most informative for recovering the other features as well\nas improving the learning performance. In this paper, we try to train an\neffective classification model with least acquisition cost by jointly\nperforming active feature querying and supervised matrix completion. When\ncompleting the feature matrix, a novel target function is proposed to\nsimultaneously minimize the reconstruction error on observed entries and the\nsupervised loss on training data. When querying the feature value, the most\nuncertain entry is actively selected based on the variance of previous\niterations. In addition, a bi-objective optimization method is presented for\ncost-aware active selection when features bear different acquisition costs. The\neffectiveness of the proposed approach is well validated by both theoretical\nanalysis and experimental study. \n\n"}
{"id": "1802.05844", "contents": "Title: A Unified View of Causal and Non-causal Feature Selection Abstract: In this paper, we aim to develop a unified view of causal and non-causal\nfeature selection methods. The unified view will fill in the gap in the\nresearch of the relation between the two types of methods. Based on the\nBayesian network framework and information theory, we first show that causal\nand non-causal feature selection methods share the same objective. That is to\nfind the Markov blanket of a class attribute, the theoretically optimal feature\nset for classification. We then examine the assumptions made by causal and\nnon-causal feature selection methods when searching for the optimal feature\nset, and unify the assumptions by mapping them to the restrictions on the\nstructure of the Bayesian network model of the studied problem. We further\nanalyze in detail how the structural assumptions lead to the different levels\nof approximations employed by the methods in their search, which then result in\nthe approximations in the feature sets found by the methods with respect to the\noptimal feature set. With the unified view, we are able to interpret the output\nof non-causal methods from a causal perspective and derive the error bounds of\nboth types of methods. Finally, we present practical understanding of the\nrelation between causal and non-causal methods using extensive experiments with\nsynthetic data and various types of real-word data. \n\n"}
{"id": "1802.06832", "contents": "Title: Deep Learning for Joint Source-Channel Coding of Text Abstract: We consider the problem of joint source and channel coding of structured data\nsuch as natural language over a noisy channel. The typical approach to this\nproblem in both theory and practice involves performing source coding to first\ncompress the text and then channel coding to add robustness for the\ntransmission across the channel. This approach is optimal in terms of\nminimizing end-to-end distortion with arbitrarily large block lengths of both\nthe source and channel codes when transmission is over discrete memoryless\nchannels. However, the optimality of this approach is no longer ensured for\ndocuments of finite length and limitations on the length of the encoding. We\nwill show in this scenario that we can achieve lower word error rates by\ndeveloping a deep learning based encoder and decoder. While the approach of\nseparate source and channel coding would minimize bit error rates, our approach\npreserves semantic information of sentences by first embedding sentences in a\nsemantic space where sentences closer in meaning are located closer together,\nand then performing joint source and channel coding on these embeddings. \n\n"}
{"id": "1802.07028", "contents": "Title: High-Dimensional Bayesian Optimization via Additive Models with\n  Overlapping Groups Abstract: Bayesian optimization (BO) is a popular technique for sequential black-box\nfunction optimization, with applications including parameter tuning, robotics,\nenvironmental monitoring, and more. One of the most important challenges in BO\nis the development of algorithms that scale to high dimensions, which remains a\nkey open problem despite recent progress. In this paper, we consider the\napproach of Kandasamy et al. (2015), in which the high-dimensional function\ndecomposes as a sum of lower-dimensional functions on subsets of the underlying\nvariables. In particular, we significantly generalize this approach by lifting\nthe assumption that the subsets are disjoint, and consider additive models with\narbitrary overlap among the subsets. By representing the dependencies via a\ngraph, we deduce an efficient message passing algorithm for optimizing the\nacquisition function. In addition, we provide an algorithm for learning the\ngraph from samples based on Gibbs sampling. We empirically demonstrate the\neffectiveness of our methods on both synthetic and real-world data. \n\n"}
{"id": "1802.08054", "contents": "Title: VBALD - Variational Bayesian Approximation of Log Determinants Abstract: Evaluating the log determinant of a positive definite matrix is ubiquitous in\nmachine learning. Applications thereof range from Gaussian processes,\nminimum-volume ellipsoids, metric learning, kernel learning, Bayesian neural\nnetworks, Determinental Point Processes, Markov random fields to partition\nfunctions of discrete graphical models. In order to avoid the canonical, yet\nprohibitive, Cholesky $\\mathcal{O}(n^{3})$ computational cost, we propose a\nnovel approach, with complexity $\\mathcal{O}(n^{2})$, based on a constrained\nvariational Bayes algorithm. We compare our method to Taylor, Chebyshev and\nLanczos approaches and show state of the art performance on both synthetic and\nreal-world datasets. \n\n"}
{"id": "1802.08087", "contents": "Title: On Quantum Cosmology in Teleparallel Gravity Abstract: A quantum cosmology in teleparallel gravity is presented in this article.\nTeleparallel gravity is used to perform such an analysis once in General\nRelativity (GR) the concept of gravitational energy is misleading preventing\nthe establishment of a concise quantum cosmology. The Wheeler-DeWitt like\nequation is obtained using the Weyl quantization and the teleparallel\nexpression of energy. \n\n"}
{"id": "1802.08674", "contents": "Title: An Algorithmic Framework to Control Bias in Bandit-based Personalization Abstract: Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue. \n\n"}
{"id": "1802.09098", "contents": "Title: SAFFRON: an adaptive algorithm for online control of the false discovery\n  rate Abstract: In the online false discovery rate (FDR) problem, one observes a possibly\ninfinite sequence of $p$-values $P_1,P_2,\\dots$, each testing a different null\nhypothesis, and an algorithm must pick a sequence of rejection thresholds\n$\\alpha_1,\\alpha_2,\\dots$ in an online fashion, effectively rejecting the\n$k$-th null hypothesis whenever $P_k \\leq \\alpha_k$. Importantly, $\\alpha_k$\nmust be a function of the past, and cannot depend on $P_k$ or any of the later\nunseen $p$-values, and must be chosen to guarantee that for any time $t$, the\nFDR up to time $t$ is less than some pre-determined quantity $\\alpha \\in\n(0,1)$. In this work, we present a powerful new framework for online FDR\ncontrol that we refer to as SAFFRON. Like older alpha-investing (AI)\nalgorithms, SAFFRON starts off with an error budget, called alpha-wealth, that\nit intelligently allocates to different tests over time, earning back some\nwealth on making a new discovery. However, unlike older methods, SAFFRON's\nthreshold sequence is based on a novel estimate of the alpha fraction that it\nallocates to true null hypotheses. In the offline setting, algorithms that\nemploy an estimate of the proportion of true nulls are called adaptive methods,\nand SAFFRON can be seen as an online analogue of the famous offline Storey-BH\nadaptive procedure. Just as Storey-BH is typically more powerful than the\nBenjamini-Hochberg (BH) procedure under independence, we demonstrate that\nSAFFRON is also more powerful than its non-adaptive counterparts, such as LORD\nand other generalized alpha-investing algorithms. Further, a monotone version\nof the original AI algorithm is recovered as a special case of SAFFRON, that is\noften more stable and powerful than the original. Lastly, the derivation of\nSAFFRON provides a novel template for deriving new online FDR rules. \n\n"}
{"id": "1802.09660", "contents": "Title: Computational Red Teaming in a Sudoku Solving Context: Neural Network\n  Based Skill Representation and Acquisition Abstract: In this paper we provide an insight into the skill representation, where\nskill representation is seen as an essential part of the skill assessment stage\nin the Computational Red Teaming process. Skill representation is demonstrated\nin the context of Sudoku puzzle, for which the real human skills used in Sudoku\nsolving, along with their acquisition, are represented computationally in a\ncognitively plausible manner, by using feed-forward neural networks with\nback-propagation, and supervised learning. The neural network based skills are\nthen coupled with a hard-coded constraint propagation computational Sudoku\nsolver, in which the solving sequence is kept hard-coded, and the skills are\nrepresented through neural networks. The paper demonstrates that the modified\nsolver can achieve different levels of proficiency, depending on the amount of\nskills acquired through the neural networks. Results are encouraging for\ndeveloping more complex skill and skill acquisition models usable in general\nframeworks related to the skill assessment aspect of Computational Red Teaming. \n\n"}
{"id": "1802.09729", "contents": "Title: Network-Clustered Multi-Modal Bug Localization Abstract: Developers often spend much effort and resources to debug a program. To help\nthe developers debug, numerous information retrieval (IR)-based and\nspectrum-based bug localization techniques have been devised. IR-based\ntechniques process textual information in bug reports, while spectrum-based\ntechniques process program spectra (i.e., a record of which program elements\nare executed for each test case). While both techniques ultimately generate a\nranked list of program elements that likely contain a bug, they only consider\none source of information--either bug reports or program spectra--which is not\noptimal. In light of this deficiency, this paper presents a new approach dubbed\nNetwork-clustered Multi-modal Bug Localization (NetML), which utilizes\nmulti-modal information from both bug reports and program spectra to localize\nbugs. NetML facilitates an effective bug localization by carrying out a joint\noptimization of bug localization error and clustering of both bug reports and\nprogram elements (i.e., methods). The clustering is achieved through the\nincorporation of network Lasso regularization, which incentivizes the model\nparameters of similar bug reports and similar program elements to be close\ntogether. To estimate the model parameters of both bug reports and methods,\nNetML employs an adaptive learning procedure based on Newton method that\nupdates the parameters on a per-feature basis. Extensive experiments on 355\nreal bugs from seven software systems have been conducted to benchmark NetML\nagainst various state-of-the-art localization methods. The results show that\nNetML surpasses the best-performing baseline by 31.82%, 22.35%, 19.72%, and\n19.24%, in terms of the number of bugs successfully localized when a developer\ninspects the top 1, 5, and 10 methods and Mean Average Precision (MAP),\nrespectively. \n\n"}
{"id": "1802.10463", "contents": "Title: DiGrad: Multi-Task Reinforcement Learning with Shared Actions Abstract: Most reinforcement learning algorithms are inefficient for learning multiple\ntasks in complex robotic systems, where different tasks share a set of actions.\nIn such environments a compound policy may be learnt with shared neural network\nparameters, which performs multiple tasks concurrently. However such compound\npolicy may get biased towards a task or the gradients from different tasks\nnegate each other, making the learning unstable and sometimes less data\nefficient. In this paper, we propose a new approach for simultaneous training\nof multiple tasks sharing a set of common actions in continuous action spaces,\nwhich we call as DiGrad (Differential Policy Gradient). The proposed framework\nis based on differential policy gradients and can accommodate multi-task\nlearning in a single actor-critic network. We also propose a simple heuristic\nin the differential policy gradient update to further improve the learning. The\nproposed architecture was tested on 8 link planar manipulator and 27 degrees of\nfreedom(DoF) Humanoid for learning multi-goal reachability tasks for 3 and 2\nend effectors respectively. We show that our approach supports efficient\nmulti-task learning in complex robotic systems, outperforming related methods\nin continuous action spaces. \n\n"}
{"id": "1803.00886", "contents": "Title: Deep factorization for speech signal Abstract: Various informative factors mixed in speech signals, leading to great\ndifficulty when decoding any of the factors. An intuitive idea is to factorize\neach speech frame into individual informative factors, though it turns out to\nbe highly difficult. Recently, we found that speaker traits, which were assumed\nto be long-term distributional properties, are actually short-time patterns,\nand can be learned by a carefully designed deep neural network (DNN). This\ndiscovery motivated a cascade deep factorization (CDF) framework that will be\npresented in this paper. The proposed framework infers speech factors in a\nsequential way, where factors previously inferred are used as conditional\nvariables when inferring other factors. We will show that this approach can\neffectively factorize speech signals, and using these factors, the original\nspeech spectrum can be recovered with a high accuracy. This factorization and\nreconstruction approach provides potential values for many speech processing\ntasks, e.g., speaker recognition and emotion recognition, as will be\ndemonstrated in the paper. \n\n"}
{"id": "1803.00916", "contents": "Title: Deep Learning for Signal Authentication and Security in Massive Internet\n  of Things Systems Abstract: Secure signal authentication is arguably one of the most challenging problems\nin the Internet of Things (IoT) environment, due to the large-scale nature of\nthe system and its susceptibility to man-in-the-middle and eavesdropping\nattacks. In this paper, a novel deep learning method is proposed for dynamic\nauthentication of IoT signals to detect cyber attacks. The proposed learning\nframework, based on a long short-term memory (LSTM) structure, enables the IoT\ndevices (IoTDs) to extract a set of stochastic features from their generated\nsignal and dynamically watermark these features into the signal. This method\nenables the cloud, which collects signals from the IoT devices, to effectively\nauthenticate the reliability of the signals. Moreover, in massive IoT\nscenarios, since the cloud cannot authenticate all the IoTDs simultaneously due\nto computational limitations, a game-theoretic framework is proposed to improve\nthe cloud's decision making process by predicting vulnerable IoTDs. The\nmixed-strategy Nash equilibrium (MSNE) for this game is derived and the\nuniqueness of the expected utility at the equilibrium is proven. In the massive\nIoT system, due to a large set of available actions for the cloud, it is shown\nthat analytically deriving the MSNE is challenging and, thus, a learning\nalgorithm proposed that converges to the MSNE. Moreover, in order to cope with\nthe incomplete information case in which the cloud cannot access the state of\nthe unauthenticated IoTDs, a deep reinforcement learning algorithm is proposed\nto dynamically predict the state of unauthenticated IoTDs and allow the cloud\nto decide on which IoTDs to authenticate. Simulation results show that, with an\nattack detection delay of under 1 second the messages can be transmitted from\nIoT devices with an almost 100% reliability. \n\n"}
{"id": "1803.01257", "contents": "Title: Nonnegative Matrix Factorization for Signal and Data Analytics:\n  Identifiability, Algorithms, and Applications Abstract: Nonnegative matrix factorization (NMF) has become a workhorse for signal and\ndata analytics, triggered by its model parsimony and interpretability. Perhaps\na bit surprisingly, the understanding to its model identifiability---the major\nreason behind the interpretability in many applications such as topic mining\nand hyperspectral imaging---had been rather limited until recent years.\nBeginning from the 2010s, the identifiability research of NMF has progressed\nconsiderably: Many interesting and important results have been discovered by\nthe signal processing (SP) and machine learning (ML) communities. NMF\nidentifiability has a great impact on many aspects in practice, such as\nill-posed formulation avoidance and performance-guaranteed algorithm design. On\nthe other hand, there is no tutorial paper that introduces NMF from an\nidentifiability viewpoint. In this paper, we aim at filling this gap by\noffering a comprehensive and deep tutorial on model identifiability of NMF as\nwell as the connections to algorithms and applications. This tutorial will help\nresearchers and graduate students grasp the essence and insights of NMF,\nthereby avoiding typical `pitfalls' that are often times due to unidentifiable\nNMF formulations. This paper will also help practitioners pick/design suitable\nfactorization tools for their own problems. \n\n"}
{"id": "1803.01420", "contents": "Title: Detecting Correlations with Little Memory and Communication Abstract: We study the problem of identifying correlations in multivariate data, under\ninformation constraints: Either on the amount of memory that can be used by the\nalgorithm, or the amount of communication when the data is distributed across\nseveral machines. We prove a tight trade-off between the memory/communication\ncomplexity and the sample complexity, implying (for example) that to detect\npairwise correlations with optimal sample complexity, the number of required\nmemory/communication bits is at least quadratic in the dimension. Our results\nsubstantially improve those of Shamir [2014], which studied a similar question\nin a much more restricted setting. To the best of our knowledge, these are the\nfirst provable sample/memory/communication trade-offs for a practical\nestimation problem, using standard distributions, and in the natural regime\nwhere the memory/communication budget is larger than the size of a single data\npoint. To derive our theorems, we prove a new information-theoretic result,\nwhich may be relevant for studying other information-constrained learning\nproblems. \n\n"}
{"id": "1803.01814", "contents": "Title: Norm matters: efficient and accurate normalization schemes in deep\n  networks Abstract: Over the past few years, Batch-Normalization has been commonly used in deep\nnetworks, allowing faster training and high performance for a wide variety of\napplications. However, the reasons behind its merits remained unanswered, with\nseveral shortcomings that hindered its use for certain tasks. In this work, we\npresent a novel view on the purpose and function of normalization methods and\nweight-decay, as tools to decouple weights' norm from the underlying optimized\nobjective. This property highlights the connection between practices such as\nnormalization, weight decay and learning-rate adjustments. We suggest several\nalternatives to the widely used $L^2$ batch-norm, using normalization in $L^1$\nand $L^\\infty$ spaces that can substantially improve numerical stability in\nlow-precision implementations as well as provide computational and memory\nbenefits. We demonstrate that such methods enable the first batch-norm\nalternative to work for half-precision implementations. Finally, we suggest a\nmodification to weight-normalization, which improves its performance on\nlarge-scale tasks. \n\n"}
{"id": "1803.01834", "contents": "Title: Conducting Credit Assignment by Aligning Local Representations Abstract: Using back-propagation and its variants to train deep networks is often\nproblematic for new users. Issues such as exploding gradients, vanishing\ngradients, and high sensitivity to weight initialization strategies often make\nnetworks difficult to train, especially when users are experimenting with new\narchitectures. Here, we present Local Representation Alignment (LRA), a\ntraining procedure that is much less sensitive to bad initializations, does not\nrequire modifications to the network architecture, and can be adapted to\nnetworks with highly nonlinear and discrete-valued activation functions.\nFurthermore, we show that one variation of LRA can start with a null\ninitialization of network weights and still successfully train networks with a\nwide variety of nonlinearities, including tanh, ReLU-6, softplus, signum and\nothers that may draw their inspiration from biology.\n  A comprehensive set of experiments on MNIST and the much harder Fashion MNIST\ndata sets show that LRA can be used to train networks robustly and effectively,\nsucceeding even when back-propagation fails and outperforming other alternative\nlearning algorithms, such as target propagation and feedback alignment. \n\n"}
{"id": "1803.02108", "contents": "Title: HexaConv Abstract: The effectiveness of Convolutional Neural Networks stems in large part from\ntheir ability to exploit the translation invariance that is inherent in many\nlearning problems. Recently, it was shown that CNNs can exploit other\ninvariances, such as rotation invariance, by using group convolutions instead\nof planar convolutions. However, for reasons of performance and ease of\nimplementation, it has been necessary to limit the group convolution to\ntransformations that can be applied to the filters without interpolation. Thus,\nfor images with square pixels, only integer translations, rotations by\nmultiples of 90 degrees, and reflections are admissible.\n  Whereas the square tiling provides a 4-fold rotational symmetry, a hexagonal\ntiling of the plane has a 6-fold rotational symmetry. In this paper we show how\none can efficiently implement planar convolution and group convolution over\nhexagonal lattices, by re-using existing highly optimized convolution routines.\nWe find that, due to the reduced anisotropy of hexagonal filters, planar\nHexaConv provides better accuracy than planar convolution with square filters,\ngiven a fixed parameter budget. Furthermore, we find that the increased degree\nof symmetry of the hexagonal grid increases the effectiveness of group\nconvolutions, by allowing for more parameter sharing. We show that our method\nsignificantly outperforms conventional CNNs on the AID aerial scene\nclassification dataset, even outperforming ImageNet pre-trained models. \n\n"}
{"id": "1803.02544", "contents": "Title: Visual Explanations From Deep 3D Convolutional Neural Networks for\n  Alzheimer's Disease Classification Abstract: We develop three efficient approaches for generating visual explanations from\n3D convolutional neural networks (3D-CNNs) for Alzheimer's disease\nclassification. One approach conducts sensitivity analysis on hierarchical 3D\nimage segmentation, and the other two visualize network activations on a\nspatial map. Visual checks and a quantitative localization benchmark indicate\nthat all approaches identify important brain parts for Alzheimer's disease\ndiagnosis. Comparative analysis show that the sensitivity analysis based\napproach has difficulty handling loosely distributed cerebral cortex, and\napproaches based on visualization of activations are constrained by the\nresolution of the convolutional layer. The complementarity of these methods\nimproves the understanding of 3D-CNNs in Alzheimer's disease classification\nfrom different perspectives. \n\n"}
{"id": "1803.02603", "contents": "Title: Gaussian Process Latent Variable Alignment Learning Abstract: We present a model that can automatically learn alignments between\nhigh-dimensional data in an unsupervised manner. Our proposed method casts\nalignment learning in a framework where both alignment and data are modelled\nsimultaneously. Further, we automatically infer groupings of different types of\nsequences within the same dataset. We derive a probabilistic model built on\nnon-parametric priors that allows for flexible warps while at the same time\nproviding means to specify interpretable constraints. We demonstrate the\nefficacy of our approach with superior quantitative performance to the\nstate-of-the-art approaches and provide examples to illustrate the versatility\nof our model in automatic inference of sequence groupings, absent from previous\napproaches, as well as easy specification of high level priors for different\nmodalities of data. \n\n"}
{"id": "1803.02780", "contents": "Title: Transfer Learning with Neural AutoML Abstract: We reduce the computational cost of Neural AutoML with transfer learning.\nAutoML relieves human effort by automating the design of ML algorithms. Neural\nAutoML has become popular for the design of deep learning architectures,\nhowever, this method has a high computation cost. To address this we propose\nTransfer Neural AutoML that uses knowledge from prior tasks to speed up network\ndesign. We extend RL-based architecture search methods to support parallel\ntraining on multiple tasks and then transfer the search strategy to new tasks.\nOn language and image classification tasks, Transfer Neural AutoML reduces\nconvergence time over single-task training by over an order of magnitude on\nmany tasks. \n\n"}
{"id": "1803.03772", "contents": "Title: Generalization and Expressivity for Deep Nets Abstract: Along with the rapid development of deep learning in practice, the\ntheoretical explanations for its success become urgent. Generalization and\nexpressivity are two widely used measurements to quantify theoretical behaviors\nof deep learning. The expressivity focuses on finding functions expressible by\ndeep nets but cannot be approximated by shallow nets with the similar number of\nneurons. It usually implies the large capacity. The generalization aims at\nderiving fast learning rate for deep nets. It usually requires small capacity\nto reduce the variance. Different from previous studies on deep learning,\npursuing either expressivity or generalization, we take both factors into\naccount to explore the theoretical advantages of deep nets. For this purpose,\nwe construct a deep net with two hidden layers possessing excellent\nexpressivity in terms of localized and sparse approximation. Then, utilizing\nthe well known covering number to measure the capacity, we find that deep nets\npossess excellent expressive power (measured by localized and sparse\napproximation) without enlarging the capacity of shallow nets. As a\nconsequence, we derive near optimal learning rates for implementing empirical\nrisk minimization (ERM) on the constructed deep nets. These results\ntheoretically exhibit the advantage of deep nets from learning theory\nviewpoints. \n\n"}
{"id": "1803.04008", "contents": "Title: Multi-Armed Bandits for Correlated Markovian Environments with Smoothed\n  Reward Feedback Abstract: We study a multi-armed bandit problem in a dynamic environment where arm\nrewards evolve in a correlated fashion according to a Markov chain. Different\nthan much of the work on related problems, in our formulation a learning\nalgorithm does not have access to either a priori information or observations\nof the state of the Markov chain and only observes smoothed reward feedback\nfollowing time intervals we refer to as epochs. We demonstrate that existing\nmethods such as UCB and $\\varepsilon$-greedy can suffer linear regret in such\nan environment. Employing mixing-time bounds on Markov chains, we develop\nalgorithms called EpochUCB and EpochGreedy that draw inspiration from the\naforementioned methods, yet which admit sublinear regret guarantees for the\nproblem formulation. Our proposed algorithms proceed in epochs in which an arm\nis played repeatedly for a number of iterations that grows linearly as a\nfunction of the number of times an arm has been played in the past. We analyze\nthese algorithms under two types of smoothed reward feedback at the end of each\nepoch: a reward that is the discount-average of the discounted rewards within\nan epoch, and a reward that is the time-average of the rewards within an epoch. \n\n"}
{"id": "1803.04223", "contents": "Title: Leveraging Crowdsourcing Data For Deep Active Learning - An Application:\n  Learning Intents in Alexa Abstract: This paper presents a generic Bayesian framework that enables any deep\nlearning model to actively learn from targeted crowds. Our framework inherits\nfrom recent advances in Bayesian deep learning, and extends existing work by\nconsidering the targeted crowdsourcing approach, where multiple annotators with\nunknown expertise contribute an uncontrolled amount (often limited) of\nannotations. Our framework leverages the low-rank structure in annotations to\nlearn individual annotator expertise, which then helps to infer the true labels\nfrom noisy and sparse annotations. It provides a unified Bayesian model to\nsimultaneously infer the true labels and train the deep learning model in order\nto reach an optimal learning efficacy. Finally, our framework exploits the\nuncertainty of the deep learning model during prediction as well as the\nannotators' estimated expertise to minimize the number of required annotations\nand annotators for optimally training the deep learning model.\n  We evaluate the effectiveness of our framework for intent classification in\nAlexa (Amazon's personal assistant), using both synthetic and real-world\ndatasets. Experiments show that our framework can accurately learn annotator\nexpertise, infer true labels, and effectively reduce the amount of annotations\nin model training as compared to state-of-the-art approaches. We further\ndiscuss the potential of our proposed framework in bridging machine learning\nand crowdsourcing towards improved human-in-the-loop systems. \n\n"}
{"id": "1803.05752", "contents": "Title: Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement\n  Learning Abstract: Rearranging objects on a tabletop surface by means of nonprehensile\nmanipulation is a task which requires skillful interaction with the physical\nworld. Usually, this is achieved by precisely modeling physical properties of\nthe objects, robot, and the environment for explicit planning. In contrast, as\nexplicitly modeling the physical environment is not always feasible and\ninvolves various uncertainties, we learn a nonprehensile rearrangement strategy\nwith deep reinforcement learning based on only visual feedback. For this, we\nmodel the task with rewards and train a deep Q-network. Our potential\nfield-based heuristic exploration strategy reduces the amount of collisions\nwhich lead to suboptimal outcomes and we actively balance the training set to\navoid bias towards poor examples. Our training process leads to quicker\nlearning and better performance on the task as compared to uniform exploration\nand standard experience replay. We demonstrate empirical evidence from\nsimulation that our method leads to a success rate of 85%, show that our system\ncan cope with sudden changes of the environment, and compare our performance\nwith human level performance. \n\n"}
{"id": "1803.06773", "contents": "Title: Composable Deep Reinforcement Learning for Robotic Manipulation Abstract: Model-free deep reinforcement learning has been shown to exhibit good\nperformance in domains ranging from video games to simulated robotic\nmanipulation and locomotion. However, model-free methods are known to perform\npoorly when the interaction time with the environment is limited, as is the\ncase for most real-world robotic tasks. In this paper, we study how maximum\nentropy policies trained using soft Q-learning can be applied to real-world\nrobotic manipulation. The application of this method to real-world manipulation\nis facilitated by two important features of soft Q-learning. First, soft\nQ-learning can learn multimodal exploration strategies by learning policies\nrepresented by expressive energy-based models. Second, we show that policies\nlearned with soft Q-learning can be composed to create new policies, and that\nthe optimality of the resulting policy can be bounded in terms of the\ndivergence between the composed policies. This compositionality provides an\nespecially valuable tool for real-world manipulation, where constructing new\npolicies by composing existing skills can provide a large gain in efficiency\nover training from scratch. Our experimental evaluation demonstrates that soft\nQ-learning is substantially more sample efficient than prior model-free deep\nreinforcement learning methods, and that compositionality can be performed for\nboth simulated and real-world tasks. \n\n"}
{"id": "1803.07225", "contents": "Title: Monte Carlo Information Geometry: The dually flat case Abstract: Exponential families and mixture families are parametric probability models\nthat can be geometrically studied as smooth statistical manifolds with respect\nto any statistical divergence like the Kullback-Leibler (KL) divergence or the\nHellinger divergence. When equipping a statistical manifold with the KL\ndivergence, the induced manifold structure is dually flat, and the KL\ndivergence between distributions amounts to an equivalent Bregman divergence on\ntheir corresponding parameters. In practice, the corresponding Bregman\ngenerators of mixture/exponential families require to perform definite integral\ncalculus that can either be too time-consuming (for exponentially large\ndiscrete support case) or even do not admit closed-form formula (for continuous\nsupport case). In these cases, the dually flat construction remains theoretical\nand cannot be used by information-geometric algorithms. To bypass this problem,\nwe consider performing stochastic Monte Carlo (MC) estimation of those\nintegral-based mixture/exponential family Bregman generators. We show that,\nunder natural assumptions, these MC generators are almost surely Bregman\ngenerators. We define a series of dually flat information geometries, termed\nMonte Carlo Information Geometries, that increasingly-finely approximate the\nuntractable geometry. The advantage of this MCIG is that it allows a practical\nuse of the Bregman algorithmic toolbox on a wide range of probability\ndistribution families. We demonstrate our approach with a clustering task on a\nmixture family manifold. \n\n"}
{"id": "1803.07348", "contents": "Title: Frank-Wolfe with Subsampling Oracle Abstract: We analyze two novel randomized variants of the Frank-Wolfe (FW) or\nconditional gradient algorithm. While classical FW algorithms require solving a\nlinear minimization problem over the domain at each iteration, the proposed\nmethod only requires to solve a linear minimization problem over a small\n\\emph{subset} of the original domain. The first algorithm that we propose is a\nrandomized variant of the original FW algorithm and achieves a\n$\\mathcal{O}(1/t)$ sublinear convergence rate as in the deterministic\ncounterpart. The second algorithm is a randomized variant of the Away-step FW\nalgorithm, and again as its deterministic counterpart, reaches linear (i.e.,\nexponential) convergence rate making it the first provably convergent\nrandomized variant of Away-step FW. In both cases, while subsampling reduces\nthe convergence rate by a constant factor, the linear minimization step can be\na fraction of the cost of that of the deterministic versions, especially when\nthe data is streamed. We illustrate computational gains of the algorithms on\nregression problems, involving both $\\ell_1$ and latent group lasso penalties. \n\n"}
{"id": "1803.07819", "contents": "Title: Some Theoretical Properties of GANs Abstract: Generative Adversarial Networks (GANs) are a class of generative algorithms\nthat have been shown to produce state-of-the art samples, especially in the\ndomain of image creation. The fundamental principle of GANs is to approximate\nthe unknown distribution of a given data set by optimizing an objective\nfunction through an adversarial game between a family of generators and a\nfamily of discriminators. In this paper, we offer a better theoretical\nunderstanding of GANs by analyzing some of their mathematical and statistical\nproperties. We study the deep connection between the adversarial principle\nunderlying GANs and the Jensen-Shannon divergence, together with some\noptimality characteristics of the problem. An analysis of the role of the\ndiscriminator family via approximation arguments is also provided. In addition,\ntaking a statistical point of view, we study the large sample properties of the\nestimated distribution and prove in particular a central limit theorem. Some of\nour results are illustrated with simulated examples. \n\n"}
{"id": "1803.07848", "contents": "Title: Non-perturbative spectrum of non-local gravity Abstract: We investigate the non-perturbative degrees of freedom of a class of weakly\nnon-local gravitational theories that have been proposed as an ultraviolet\ncompletion of general relativity. At the perturbative level, it is known that\nthe degrees of freedom of non-local gravity are the same of the\nEinstein--Hilbert theory around any maximally symmetric spacetime. We prove\nthat, at the non-perturbative level, the degrees of freedom are actually eight\nin four dimensions, contrary to what one might guess on the basis of the\n\"infinite number of derivatives\" present in the action. It is shown that six of\nthese degrees of freedom do not propagate on Minkowski spacetime, but they\nmight play a role at large scales on curved backgrounds. We also propose a\ncriterion to select the form factor almost uniquely. \n\n"}
{"id": "1803.08287", "contents": "Title: Learning-based Model Predictive Control for Safe Exploration Abstract: Learning-based methods have been successful in solving complex control tasks\nwithout significant prior knowledge about the system. However, these methods\ntypically do not provide any safety guarantees, which prevents their use in\nsafety-critical, real-world applications. In this paper, we present a\nlearning-based model predictive control scheme that can provide provable\nhigh-probability safety guarantees. To this end, we exploit regularity\nassumptions on the dynamics in terms of a Gaussian process prior to construct\nprovably accurate confidence intervals on predicted trajectories. Unlike\nprevious approaches, we do not assume that model uncertainties are independent.\nBased on these predictions, we guarantee that trajectories satisfy safety\nconstraints. Moreover, we use a terminal set constraint to recursively\nguarantee the existence of safe control actions at every iteration. In our\nexperiments, we show that the resulting algorithm can be used to safely and\nefficiently explore and learn about dynamic systems. \n\n"}
{"id": "1803.09017", "contents": "Title: Style Tokens: Unsupervised Style Modeling, Control and Transfer in\n  End-to-End Speech Synthesis Abstract: In this work, we propose \"global style tokens\" (GSTs), a bank of embeddings\nthat are jointly trained within Tacotron, a state-of-the-art end-to-end speech\nsynthesis system. The embeddings are trained with no explicit labels, yet learn\nto model a large range of acoustic expressiveness. GSTs lead to a rich set of\nsignificant results. The soft interpretable \"labels\" they generate can be used\nto control synthesis in novel ways, such as varying speed and speaking style -\nindependently of the text content. They can also be used for style transfer,\nreplicating the speaking style of a single audio clip across an entire\nlong-form text corpus. When trained on noisy, unlabeled found data, GSTs learn\nto factorize noise and speaker identity, providing a path towards highly\nscalable but robust speech synthesis. \n\n"}
{"id": "1803.09353", "contents": "Title: Stochastic bandits robust to adversarial corruptions Abstract: We introduce a new model of stochastic bandits with adversarial corruptions\nwhich aims to capture settings where most of the input follows a stochastic\npattern but some fraction of it can be adversarially changed to trick the\nalgorithm, e.g., click fraud, fake reviews and email spam. The goal of this\nmodel is to encourage the design of bandit algorithms that (i) work well in\nmixed adversarial and stochastic models, and (ii) whose performance\ndeteriorates gracefully as we move from fully stochastic to fully adversarial\nmodels.\n  In our model, the rewards for all arms are initially drawn from a\ndistribution and are then altered by an adaptive adversary. We provide a simple\nalgorithm whose performance gracefully degrades with the total corruption the\nadversary injected in the data, measured by the sum across rounds of the\nbiggest alteration the adversary made in the data in that round; this total\ncorruption is denoted by $C$. Our algorithm provides a guarantee that retains\nthe optimal guarantee (up to a logarithmic term) if the input is stochastic and\nwhose performance degrades linearly to the amount of corruption $C$, while\ncrucially being agnostic to it. We also provide a lower bound showing that this\nlinear degradation is necessary if the algorithm achieves optimal performance\nin the stochastic setting (the lower bound works even for a known amount of\ncorruption, a special case in which our algorithm achieves optimal performance\nwithout the extra logarithm). \n\n"}
{"id": "1803.09733", "contents": "Title: Domain transfer convolutional attribute embedding Abstract: In this paper, we study the problem of transfer learning with the attribute\ndata. In the transfer learning problem, we want to leverage the data of the\nauxiliary and the target domains to build an effective model for the\nclassification problem in the target domain. Meanwhile, the attributes are\nnaturally stable cross different domains. This strongly motives us to learn\neffective domain transfer attribute representations. To this end, we proposed\nto embed the attributes of the data to a common space by using the powerful\nconvolutional neural network (CNN) model. The convolutional representations of\nthe data points are mapped to the corresponding attributes so that they can be\neffective embedding of the attributes. We also represent the data of different\ndomains by a domain-independent CNN, ant a domain-specific CNN, and combine\ntheir outputs with the attribute embedding to build the classification model.\nAn joint learning framework is constructed to minimize the classification\nerrors, the attribute mapping error, the mismatching of the domain-independent\nrepresentations cross different domains, and to encourage the the neighborhood\nsmoothness of representations in the target domain. The minimization problem is\nsolved by an iterative algorithm based on gradient descent. Experiments over\nbenchmark data sets of person re-identification, bankruptcy prediction, and\nspam email detection, show the effectiveness of the proposed method. \n\n"}
{"id": "1803.10228", "contents": "Title: Demystifying Differentiable Programming: Shift/Reset the Penultimate\n  Backpropagator Abstract: Deep learning has seen tremendous success over the past decade in computer\nvision, machine translation, and gameplay. This success rests in crucial ways\non gradient-descent optimization and the ability to learn parameters of a\nneural network by backpropagating observed errors. However, neural network\narchitectures are growing increasingly sophisticated and diverse, which\nmotivates an emerging quest for even more general forms of differentiable\nprogramming, where arbitrary parameterized computations can be trained by\ngradient descent. In this paper, we take a fresh look at automatic\ndifferentiation (AD) techniques, and especially aim to demystify the\nreverse-mode form of AD that generalizes backpropagation in neural networks.\n  We uncover a tight connection between reverse-mode AD and delimited\ncontinuations, which permits implementing reverse-mode AD purely via operator\noverloading and without any auxiliary data structures. We further show how this\nformulation of AD can be fruitfully combined with multi-stage programming\n(staging), leading to a highly efficient implementation that combines the\nperformance benefits of deep learning frameworks based on explicit reified\ncomputation graphs (e.g., TensorFlow) with the expressiveness of pure library\napproaches (e.g., PyTorch). \n\n"}
{"id": "1803.11080", "contents": "Title: 3D Consistent Biventricular Myocardial Segmentation Using Deep Learning\n  for Mesh Generation Abstract: We present a novel automated method to segment the myocardium of both left\nand right ventricles in MRI volumes. The segmentation is consistent in 3D\nacross the slices such that it can be directly used for mesh generation. Two\nspecific neural networks with multi-scale coarse-to-fine prediction structure\nare proposed to cope with the small training dataset and trained using an\noriginal loss function. The former segments a slice in the middle of the\nvolume. Then the latter iteratively propagates the slice segmentations towards\nthe base and the apex, in a spatially consistent way. We perform 5-fold\ncross-validation on the 15 cases from STACOM to validate the method. For\ntraining, we use real cases and their synthetic variants generated by combining\nmotion simulation and image synthesis. Accurate and consistent testing results\nare obtained. \n\n"}
{"id": "1804.00097", "contents": "Title: Adversarial Attacks and Defences Competition Abstract: To accelerate research on adversarial examples and robustness of machine\nlearning classifiers, Google Brain organized a NIPS 2017 competition that\nencouraged researchers to develop new methods to generate adversarial examples\nas well as to develop new ways to defend against them. In this chapter, we\ndescribe the structure and organization of the competition and the solutions\ndeveloped by several of the top-placing teams. \n\n"}
{"id": "1804.00236", "contents": "Title: Recognizing Challenging Handwritten Annotations with Fully Convolutional\n  Networks Abstract: This paper introduces a very challenging dataset of historic German documents\nand evaluates Fully Convolutional Neural Network (FCNN) based methods to locate\nhandwritten annotations of any kind in these documents. The handwritten\nannotations can appear in form of underlines and text by using various writing\ninstruments, e.g., the use of pencils makes the data more challenging. We train\nand evaluate various end-to-end semantic segmentation approaches and report the\nresults. The task is to classify the pixels of documents into two classes:\nbackground and handwritten annotation. The best model achieves a mean\nIntersection over Union (IoU) score of 95.6% on the test documents of the\npresented dataset. We also present a comparison of different strategies used\nfor data augmentation and training on our presented dataset. For evaluation, we\nuse the Layout Analysis Evaluator for the ICDAR 2017 Competition on Layout\nAnalysis for Challenging Medieval Manuscripts. \n\n"}
{"id": "1804.00499", "contents": "Title: Semantic Adversarial Examples Abstract: Deep neural networks are known to be vulnerable to adversarial examples,\ni.e., images that are maliciously perturbed to fool the model. Generating\nadversarial examples has been mostly limited to finding small perturbations\nthat maximize the model prediction error. Such images, however, contain\nartificial perturbations that make them somewhat distinguishable from natural\nimages. This property is used by several defense methods to counter adversarial\nexamples by applying denoising filters or training the model to be robust to\nsmall perturbations.\n  In this paper, we introduce a new class of adversarial examples, namely\n\"Semantic Adversarial Examples,\" as images that are arbitrarily perturbed to\nfool the model, but in such a way that the modified image semantically\nrepresents the same object as the original image. We formulate the problem of\ngenerating such images as a constrained optimization problem and develop an\nadversarial transformation based on the shape bias property of human cognitive\nsystem. In our method, we generate adversarial images by first converting the\nRGB image into the HSV (Hue, Saturation and Value) color space and then\nrandomly shifting the Hue and Saturation components, while keeping the Value\ncomponent the same. Our experimental results on CIFAR10 dataset show that the\naccuracy of VGG16 network on adversarial color-shifted images is 5.7%. \n\n"}
{"id": "1804.00925", "contents": "Title: Correlated discrete data generation using adversarial training Abstract: Generative Adversarial Networks (GAN) have shown great promise in tasks like\nsynthetic image generation, image inpainting, style transfer, and anomaly\ndetection. However, generating discrete data is a challenge. This work presents\nan adversarial training based correlated discrete data (CDD) generation model.\nIt also details an approach for conditional CDD generation. The results of our\napproach are presented over two datasets; job-seeking candidates skill set\n(private dataset) and MNIST (public dataset). From quantitative and qualitative\nanalysis of these results, we show that our model performs better as it\nleverages inherent correlation in the data, than an existing model that\noverlooks correlation. \n\n"}
{"id": "1804.01756", "contents": "Title: The Kanerva Machine: A Generative Distributed Memory Abstract: We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train. \n\n"}
{"id": "1804.02528", "contents": "Title: ANNETT-O: An Ontology for Describing Artificial Neural Network\n  Evaluation, Topology and Training Abstract: Deep learning models, while effective and versatile, are becoming\nincreasingly complex, often including multiple overlapping networks of\narbitrary depths, multiple objectives and non-intuitive training methodologies.\nThis makes it increasingly difficult for researchers and practitioners to\ndesign, train and understand them. In this paper we present ANNETT-O, a\nmuch-needed, generic and computer-actionable vocabulary for researchers and\npractitioners to describe their deep learning configurations, training\nprocedures and experiments. The proposed ontology focuses on topological,\ntraining and evaluation aspects of complex deep neural configurations, while\nkeeping peripheral entities more succinct. Knowledge bases implementing\nANNETT-O can support a wide variety of queries, providing relevant insights to\nusers. In addition to a detailed description of the ontology, we demonstrate\nits suitability to the task via a number of hypothetical use-cases of\nincreasing complexity. \n\n"}
{"id": "1804.03515", "contents": "Title: Hyperparameters and Tuning Strategies for Random Forest Abstract: The random forest algorithm (RF) has several hyperparameters that have to be\nset by the user, e.g., the number of observations drawn randomly for each tree\nand whether they are drawn with or without replacement, the number of variables\ndrawn randomly for each split, the splitting rule, the minimum number of\nsamples that a node must contain and the number of trees. In this paper, we\nfirst provide a literature review on the parameters' influence on the\nprediction performance and on variable importance measures.\n  It is well known that in most cases RF works reasonably well with the default\nvalues of the hyperparameters specified in software packages. Nevertheless,\ntuning the hyperparameters can improve the performance of RF. In the second\npart of this paper, after a brief overview of tuning strategies we demonstrate\nthe application of one of the most established tuning strategies, model-based\noptimization (MBO). To make it easier to use, we provide the tuneRanger R\npackage that tunes RF with MBO automatically. In a benchmark study on several\ndatasets, we compare the prediction performance and runtime of tuneRanger with\nother tuning implementations in R and RF with default hyperparameters. \n\n"}
{"id": "1804.04205", "contents": "Title: Learning Topics using Semantic Locality Abstract: The topic modeling discovers the latent topic probability of the given text\ndocuments. To generate the more meaningful topic that better represents the\ngiven document, we proposed a new feature extraction technique which can be\nused in the data preprocessing stage. The method consists of three steps.\nFirst, it generates the word/word-pair from every single document. Second, it\napplies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.\nThird, it uses the K-means algorithm to merge the word pairs that have the\nsimilar semantic meaning.\n  Experiments are carried out on the Open Movie Database (OMDb), Reuters\nDataset and 20NewsGroup Dataset. The mean Average Precision score is used as\nthe evaluation metric. Comparing our results with other state-of-the-art topic\nmodels, such as Latent Dirichlet allocation and traditional Restricted\nBoltzmann Machines. Our proposed data preprocessing can improve the generated\ntopic accuracy by up to 12.99\\%. \n\n"}
{"id": "1804.04368", "contents": "Title: Regularisation of Neural Networks by Enforcing Lipschitz Continuity Abstract: We investigate the effect of explicitly enforcing the Lipschitz continuity of\nneural networks with respect to their inputs. To this end, we provide a simple\ntechnique for computing an upper bound to the Lipschitz constant---for multiple\n$p$-norms---of a feed forward neural network composed of commonly used layer\ntypes. Our technique is then used to formulate training a neural network with a\nbounded Lipschitz constant as a constrained optimisation problem that can be\nsolved using projected stochastic gradient methods. Our evaluation study shows\nthat the performance of the resulting models exceeds that of models trained\nwith other common regularisers. We also provide evidence that the\nhyperparameters are intuitive to tune, demonstrate how the choice of norm for\ncomputing the Lipschitz constant impacts the resulting model, and show that the\nperformance gains provided by our method are particularly noticeable when only\na small amount of training data is available. \n\n"}
{"id": "1804.04950", "contents": "Title: DeepFM: An End-to-End Wide & Deep Learning Framework for CTR Prediction Abstract: Learning sophisticated feature interactions behind user behaviors is critical\nin maximizing CTR for recommender systems. Despite great progress, existing\nmethods have a strong bias towards low- or high-order interactions, or rely on\nexpertise feature engineering. In this paper, we show that it is possible to\nderive an end-to-end learning model that emphasizes both low- and high-order\nfeature interactions. The proposed framework, DeepFM, combines the power of\nfactorization machines for recommendation and deep learning for feature\nlearning in a new neural network architecture. Compared to the latest Wide &\nDeep model from Google, DeepFM has a shared raw feature input to both its\n\"wide\" and \"deep\" components, with no need of feature engineering besides raw\nfeatures. DeepFM, as a general learning framework, can incorporate various\nnetwork architectures in its deep component. In this paper, we study two\ninstances of DeepFM where its \"deep\" component is DNN and PNN respectively, for\nwhich we denote as DeepFM-D and DeepFM-P. Comprehensive experiments are\nconducted to demonstrate the effectiveness of DeepFM-D and DeepFM-P over the\nexisting models for CTR prediction, on both benchmark data and commercial data.\nWe conduct online A/B test in Huawei App Market, which reveals that DeepFM-D\nleads to more than 10% improvement of click-through rate in the production\nenvironment, compared to a well-engineered LR model. We also covered related\npractice in deploying our framework in Huawei App Market. \n\n"}
{"id": "1804.05929", "contents": "Title: UCBoost: A Boosting Approach to Tame Complexity and Optimality for\n  Stochastic Bandits Abstract: In this work, we address the open problem of finding low-complexity\nnear-optimal multi-armed bandit algorithms for sequential decision making\nproblems. Existing bandit algorithms are either sub-optimal and computationally\nsimple (e.g., UCB1) or optimal and computationally complex (e.g., kl-UCB). We\npropose a boosting approach to Upper Confidence Bound based algorithms for\nstochastic bandits, that we call UCBoost. Specifically, we propose two types of\nUCBoost algorithms. We show that UCBoost($D$) enjoys $O(1)$ complexity for each\narm per round as well as regret guarantee that is $1/e$-close to that of the\nkl-UCB algorithm. We propose an approximation-based UCBoost algorithm,\nUCBoost($\\epsilon$), that enjoys a regret guarantee $\\epsilon$-close to that of\nkl-UCB as well as $O(\\log(1/\\epsilon))$ complexity for each arm per round.\nHence, our algorithms provide practitioners a practical way to trade optimality\nwith computational complexity. Finally, we present numerical results which show\nthat UCBoost($\\epsilon$) can achieve the same regret performance as the\nstandard kl-UCB while incurring only $1\\%$ of the computational cost of kl-UCB. \n\n"}
{"id": "1804.06218", "contents": "Title: Hierarchical correlation reconstruction with missing data, for example\n  for biology-inspired neuron Abstract: Machine learning often needs to model density from a multidimensional data\nsample, including correlations between coordinates. Additionally, we often have\nmissing data case: that data points can miss values for some of coordinates.\nThis article adapts rapid parametric density estimation approach for this\npurpose: modelling density as a linear combination of orthonormal functions,\nfor which $L^2$ optimization says that (independently) estimated coefficient\nfor a given function is just average over the sample of value of this function.\nHierarchical correlation reconstruction first models probability density for\neach separate coordinate using all its appearances in data sample, then adds\ncorrections from independently modelled pairwise correlations using all samples\nhaving both coordinates, and so on independently adding correlations for\ngrowing numbers of variables using often decreasing evidence in data sample. A\nbasic application of such modelled multidimensional density can be imputation\nof missing coordinates: by inserting known coordinates to the density, and\ntaking expected values for the missing coordinates, or even their entire joint\nprobability distribution. Presented method can be compared with cascade\ncorrelations approach, offering several advantages in flexibility and accuracy.\nIt can be also used as artificial neuron: maximizing prediction capabilities\nfor only local behavior - modelling and predicting local connections. \n\n"}
{"id": "1804.06620", "contents": "Title: Visualizing the Feature Importance for Black Box Models Abstract: In recent years, a large amount of model-agnostic methods to improve the\ntransparency, trustability and interpretability of machine learning models have\nbeen developed. We introduce local feature importance as a local version of a\nrecent model-agnostic global feature importance method. Based on local feature\nimportance, we propose two visual tools: partial importance (PI) and individual\nconditional importance (ICI) plots which visualize how changes in a feature\naffect the model performance on average, as well as for individual\nobservations. Our proposed methods are related to partial dependence (PD) and\nindividual conditional expectation (ICE) plots, but visualize the expected\n(conditional) feature importance instead of the expected (conditional)\nprediction. Furthermore, we show that averaging ICI curves across observations\nyields a PI curve, and integrating the PI curve with respect to the\ndistribution of the considered feature results in the global feature\nimportance. Another contribution of our paper is the Shapley feature\nimportance, which fairly distributes the overall performance of a model among\nthe features according to the marginal contributions and which can be used to\ncompare the feature importance across different models. \n\n"}
{"id": "1804.07353", "contents": "Title: Unsupervised Representation Adversarial Learning Network: from\n  Reconstruction to Generation Abstract: A good representation for arbitrarily complicated data should have the\ncapability of semantic generation, clustering and reconstruction. Previous\nresearch has already achieved impressive performance on either one. This paper\naims at learning a disentangled representation effective for all of them in an\nunsupervised way. To achieve all the three tasks together, we learn the forward\nand inverse mapping between data and representation on the basis of a symmetric\nadversarial process. In theory, we minimize the upper bound of the two\nconditional entropy loss between the latent variables and the observations\ntogether to achieve the cycle consistency. The newly proposed RepGAN is tested\non MNIST, fashionMNIST, CelebA, and SVHN datasets to perform unsupervised\nclassification, generation and reconstruction tasks. The result demonstrates\nthat RepGAN is able to learn a useful and competitive representation. To the\nauthor's knowledge, our work is the first one to achieve both a high\nunsupervised classification accuracy and low reconstruction error on MNIST.\nCodes are available at https://github.com/yzhouas/RepGAN-tensorflow. \n\n"}
{"id": "1804.08130", "contents": "Title: Sparse Travel Time Estimation from Streaming Data Abstract: We address two shortcomings in online travel time estimation methods for\ncongested urban traffic. The first shortcoming is related to the determination\nof the number of mixture modes, which can change dynamically, within day and\nfrom day to day. The second shortcoming is the wide-spread use of Gaussian\nprobability densities as mixture components. Gaussian densities fail to capture\nthe positive skew in travel time distributions and, consequently, large numbers\nof mixture components are needed for reasonable fitting accuracy when applied\nas mixture components. They also assign positive probabilities to negative\ntravel times. To address these issues, this paper derives a mixture\ndistribution with Gamma component densities, which are asymmetric and supported\non the positive numbers. We use sparse estimation techniques to ensure\nparsimonious models and propose a generalization of Gamma mixture densities\nusing Mittag-Leffler functions, which provides enhanced fitting flexibility and\nimproved parsimony. In order to accommodate within-day variability and allow\nfor online implementation of the proposed methodology (i.e., fast computations\non streaming travel time data), we introduce a recursive algorithm which\nefficiently updates the fitted distribution whenever new data become available.\nExperimental results using real-world travel time data illustrate the efficacy\nof the proposed methods. \n\n"}
{"id": "1804.08219", "contents": "Title: Adaptive Performance Assessment For Drivers Through Behavioral Advantage Abstract: The potential positive impact of autonomous driving and driver assistance\ntechnolo- gies have been a major impetus over the last decade. On the flip\nside, it has been a challenging problem to analyze the performance of human\ndrivers or autonomous driving agents quantitatively. In this work, we propose a\ngeneric method that compares the performance of drivers or autonomous driving\nagents even if the environmental conditions are different, by using the driver\nbehavioral advantage instead of absolute metrics, which efficiently removes the\nenvironmental factors. A concrete application of the method is also presented,\nwhere the performance of more than 100 truck drivers was evaluated and ranked\nin terms of fuel efficiency, covering more than 90,000 trips spanning an\naverage of 300 miles in a variety of driving conditions and environments. \n\n"}
{"id": "1804.08597", "contents": "Title: Towards Symbolic Reinforcement Learning with Common Sense Abstract: Deep Reinforcement Learning (deep RL) has made several breakthroughs in\nrecent years in applications ranging from complex control tasks in unmanned\nvehicles to game playing. Despite their success, deep RL still lacks several\nimportant capacities of human intelligence, such as transfer learning,\nabstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)\nseeks to incorporate such capacities to deep Q-networks (DQN) by learning a\nrelevant symbolic representation prior to using Q-learning. In this paper, we\npropose a novel extension of DSRL, which we call Symbolic Reinforcement\nLearning with Common Sense (SRL+CS), offering a better balance between\ngeneralization and specialization, inspired by principles of common sense when\nassigning rewards and aggregating Q-values. Experiments reported in this paper\nshow that SRL+CS learns consistently faster than Q-learning and DSRL, achieving\nalso a higher accuracy. In the hardest case, where agents were trained in a\ndeterministic environment and tested in a random environment, SRL+CS achieves\nnearly 100% average accuracy compared to DSRL's 70% and DQN's 50% accuracy. To\nthe best of our knowledge, this is the first case of near perfect zero-shot\ntransfer learning using Reinforcement Learning. \n\n"}
{"id": "1804.08794", "contents": "Title: Towards Dependable Deep Convolutional Neural Networks (CNNs) with\n  Out-distribution Learning Abstract: Detection and rejection of adversarial examples in security sensitive and\nsafety-critical systems using deep CNNs is essential. In this paper, we propose\nan approach to augment CNNs with out-distribution learning in order to reduce\nmisclassification rate by rejecting adversarial examples. We empirically show\nthat our augmented CNNs can either reject or classify correctly most\nadversarial examples generated using well-known methods ( >95% for MNIST and\n>75% for CIFAR-10 on average). Furthermore, we achieve this without requiring\nto train using any specific type of adversarial examples and without\nsacrificing the accuracy of models on clean samples significantly (< 4%). \n\n"}
{"id": "1804.09148", "contents": "Title: Automated Detection of Adverse Drug Reactions in the Biomedical\n  Literature Using Convolutional Neural Networks and Biomedical Word Embeddings Abstract: Monitoring the biomedical literature for cases of Adverse Drug Reactions\n(ADRs) is a critically important and time consuming task in pharmacovigilance.\nThe development of computer assisted approaches to aid this process in\ndifferent forms has been the subject of many recent works. One particular area\nthat has shown promise is the use of Deep Neural Networks, in particular,\nConvolutional Neural Networks (CNNs), for the detection of ADR relevant\nsentences. Using token-level convolutions and general purpose word embeddings,\nthis architecture has shown good performance relative to more traditional\nmodels as well as Long Short Term Memory (LSTM) models. In this work, we\nevaluate and compare two different CNN architectures using the ADE corpus. In\naddition, we show that by de-duplicating the ADR relevant sentences, we can\ngreatly reduce overoptimism in the classification results. Finally, we evaluate\nthe use of word embeddings specifically developed for biomedical text and show\nthat they lead to a better performance in this task. \n\n"}
{"id": "1804.09154", "contents": "Title: DOOM Level Generation using Generative Adversarial Networks Abstract: We applied Generative Adversarial Networks (GANs) to learn a model of DOOM\nlevels from human-designed content. Initially, we analysed the levels and\nextracted several topological features. Then, for each level, we extracted a\nset of images identifying the occupied area, the height map, the walls, and the\nposition of game objects. We trained two GANs: one using plain level images,\none using both the images and some of the features extracted during the\npreliminary analysis. We used the two networks to generate new levels and\ncompared the results to assess whether the network trained using also the\ntopological features could generate levels more similar to human-designed ones.\nOur results show that GANs can capture intrinsic structure of DOOM levels and\nappears to be a promising approach to level generation in first person shooter\ngames. \n\n"}
{"id": "1804.10279", "contents": "Title: Adaptive Sensing for Learning Nonstationary Environment Models Abstract: Most environmental phenomena, such as wind profiles, ozone concentration and\nsunlight distribution under a forest canopy, exhibit nonstationary dynamics\ni.e. phenomenon variation change depending on the location and time of\noccurrence. Non-stationary dynamics pose both theoretical and practical\nchallenges to statistical machine learning algorithms aiming to accurately\ncapture the complexities governing the evolution of such processes. In this\npaper, we address the sampling aspects of the problem of learning nonstationary\nspatio-temporal models, and propose an efficient yet simple algorithm - LISAL.\nThe core idea in LISAL is to learn two models using Gaussian processes (GPs)\nwherein the first is a nonstationary GP directly modeling the phenomenon. The\nsecond model uses a stationary GP representing a latent space corresponding to\nchanges in dynamics, or the nonstationarity characteristics of the first model.\nLISAL involves adaptively sampling the latent space dynamics using information\ntheory quantities to reduce the computational cost during the learning phase.\nThe relevance of LISAL is extensively validated using multiple real world\ndatasets. \n\n"}
{"id": "1804.11067", "contents": "Title: Staircase Network: structural language identification via hierarchical\n  attentive units Abstract: Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin. \n\n"}
{"id": "1804.11237", "contents": "Title: Deep learning improved by biological activation functions Abstract: `Biologically inspired' activation functions, such as the logistic sigmoid,\nhave been instrumental in the historical advancement of machine learning.\nHowever in the field of deep learning, they have been largely displaced by\nrectified linear units (ReLU) or similar functions, such as its exponential\nlinear unit (ELU) variant, to mitigate the effects of vanishing gradients\nassociated with error back-propagation. The logistic sigmoid however does not\nrepresent the true input-output relation in neuronal cells under physiological\nconditions. Here, bionodal root unit (BRU) activation functions are introduced,\nexhibiting input-output non-linearities that are substantially more\nbiologically plausible since their functional form is based on known\nbiophysical properties of neuronal cells.\n  In order to evaluate the learning performance of BRU activations, deep\nnetworks are constructed with identical architectures except differing in their\ntransfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked\nauto-encoders, and convolutional networks are used to test supervised and\nunsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons\nof learning performance, quantified using loss and error measurements,\ndemonstrate that bionodal networks both train faster than their ReLU and ELU\ncounterparts and result in the best generalised models even in the absence of\nformal regularisation. These results therefore suggest that revisiting the\ndetailed properties of biological neurones and their circuitry might prove\ninvaluable in the field of deep learning for the future. \n\n"}
{"id": "1805.00165", "contents": "Title: Convolutional Neural Network Architectures for Signals Supported on\n  Graphs Abstract: Two architectures that generalize convolutional neural networks (CNNs) for\nthe processing of signals supported on graphs are introduced. We start with the\nselection graph neural network (GNN), which replaces linear time invariant\nfilters with linear shift invariant graph filters to generate convolutional\nfeatures and reinterprets pooling as a possibly nonlinear subsampling stage\nwhere nearby nodes pool their information in a set of preselected sample nodes.\nA key component of the architecture is to remember the position of sampled\nnodes to permit computation of convolutional features at deeper layers. The\nsecond architecture, dubbed aggregation GNN, diffuses the signal through the\ngraph and stores the sequence of diffused components observed by a designated\nnode. This procedure effectively aggregates all components into a stream of\ninformation having temporal structure to which the convolution and pooling\nstages of regular CNNs can be applied. A multinode version of aggregation GNNs\nis further introduced for operation in large scale graphs. An important\nproperty of selection and aggregation GNNs is that they reduce to conventional\nCNNs when particularized to time signals reinterpreted as graph signals in a\ncirculant graph. Comparative numerical analyses are performed in a source\nlocalization application over synthetic and real-world networks. Performance is\nalso evaluated for an authorship attribution problem and text category\nclassification. Multinode aggregation GNNs are consistently the best performing\nGNN architecture. \n\n"}
{"id": "1805.00361", "contents": "Title: Ultra Power-Efficient CNN Domain Specific Accelerator with 9.3TOPS/Watt\n  for Mobile and Embedded Applications Abstract: Computer vision performances have been significantly improved in recent years\nby Convolutional Neural Networks(CNN). Currently, applications using CNN\nalgorithms are deployed mainly on general purpose hardwares, such as CPUs, GPUs\nor FPGAs. However, power consumption, speed, accuracy, memory footprint, and\ndie size should all be taken into consideration for mobile and embedded\napplications. Domain Specific Architecture (DSA) for CNN is the efficient and\npractical solution for CNN deployment and implementation. We designed and\nproduced a 28nm Two-Dimensional CNN-DSA accelerator with an ultra\npower-efficient performance of 9.3TOPS/Watt and with all processing done in the\ninternal memory instead of outside DRAM. It classifies 224x224 RGB image inputs\nat more than 140fps with peak power consumption at less than 300mW and an\naccuracy comparable to the VGG benchmark. The CNN-DSA accelerator is\nreconfigurable to support CNN model coefficients of various layer sizes and\nlayer types, including convolution, depth-wise convolution, short-cut\nconnections, max pooling, and ReLU. Furthermore, in order to better support\nreal-world deployment for various application scenarios, especially with\nlow-end mobile and embedded platforms and MCUs (Microcontroller Units), we also\ndesigned algorithms to fully utilize the CNN-DSA accelerator efficiently by\nreducing the dependency on external accelerator computation resources,\nincluding implementation of Fully-Connected (FC) layers within the accelerator\nand compression of extracted features from the CNN-DSA accelerator. Live demos\nwith our CNN-DSA accelerator on mobile and embedded systems show its\ncapabilities to be widely and practically applied in the real world. \n\n"}
{"id": "1805.00915", "contents": "Title: Trainability and Accuracy of Neural Networks: An Interacting Particle\n  System Approach Abstract: Neural networks, a central tool in machine learning, have demonstrated\nremarkable, high fidelity performance on image recognition and classification\ntasks. These successes evince an ability to accurately represent high\ndimensional functions, but rigorous results about the approximation error of\nneural networks after training are few. Here we establish conditions for global\nconvergence of the standard optimization algorithm used in machine learning\napplications, stochastic gradient descent (SGD), and quantify the scaling of\nits error with the size of the network. This is done by reinterpreting SGD as\nthe evolution of a particle system with interactions governed by a potential\nrelated to the objective or \"loss\" function used to train the network. We show\nthat, when the number $n$ of units is large, the empirical distribution of the\nparticles descends on a convex landscape towards the global minimum at a rate\nindependent of $n$, with a resulting approximation error that universally\nscales as $O(n^{-1})$. These properties are established in the form of a Law of\nLarge Numbers and a Central Limit Theorem for the empirical distribution. Our\nanalysis also quantifies the scale and nature of the noise introduced by SGD\nand provides guidelines for the step size and batch size to use when training a\nneural network. We illustrate our findings on examples in which we train neural\nnetworks to learn the energy function of the continuous 3-spin model on the\nsphere. The approximation error scales as our analysis predicts in as high a\ndimension as $d=25$. \n\n"}
{"id": "1805.00979", "contents": "Title: modAL: A modular active learning framework for Python Abstract: modAL is a modular active learning framework for Python, aimed to make active\nlearning research and practice simpler. Its distinguishing features are (i)\nclear and modular object oriented design (ii) full compatibility with\nscikit-learn models and workflows. These features make fast prototyping and\neasy extensibility possible, aiding the development of real-life active\nlearning pipelines and novel algorithms as well. modAL is fully open source,\nhosted on GitHub at https://github.com/cosmic-cortex/modAL. To assure code\nquality, extensive unit tests are provided and continuous integration is\napplied. In addition, a detailed documentation with several tutorials are also\navailable for ease of use. The framework is available in PyPI and distributed\nunder the MIT license. \n\n"}
{"id": "1805.01532", "contents": "Title: Lifted Neural Networks Abstract: We describe a novel family of models of multi- layer feedforward neural\nnetworks in which the activation functions are encoded via penalties in the\ntraining problem. Our approach is based on representing a non-decreasing\nactivation function as the argmin of an appropriate convex optimiza- tion\nproblem. The new framework allows for algo- rithms such as block-coordinate\ndescent methods to be applied, in which each step is composed of a simple (no\nhidden layer) supervised learning problem that is parallelizable across data\npoints and/or layers. Experiments indicate that the pro- posed models provide\nexcellent initial guesses for weights for standard neural networks. In addi-\ntion, the model provides avenues for interesting extensions, such as robustness\nagainst noisy in- puts and optimizing over parameters in activation functions. \n\n"}
{"id": "1805.01907", "contents": "Title: Exploration by Distributional Reinforcement Learning Abstract: We propose a framework based on distributional reinforcement learning and\nrecent attempts to combine Bayesian parameter updates with deep reinforcement\nlearning. We show that our proposed framework conceptually unifies multiple\nprevious methods in exploration. We also derive a practical algorithm that\nachieves efficient exploration on challenging control tasks. \n\n"}
{"id": "1805.01930", "contents": "Title: Enhancing the Regularization Effect of Weight Pruning in Artificial\n  Neural Networks Abstract: Artificial neural networks (ANNs) may not be worth their computational/memory\ncosts when used in mobile phones or embedded devices. Parameter-pruning\nalgorithms combat these costs, with some algorithms capable of removing over\n90% of an ANN's weights without harming the ANN's performance. Removing weights\nfrom an ANN is a form of regularization, but existing pruning algorithms do not\nsignificantly improve generalization error. We show that pruning ANNs can\nimprove generalization if pruning targets large weights instead of small\nweights. Applying our pruning algorithm to an ANN leads to a higher image\nclassification accuracy on CIFAR-10 data than applying the popular regularizer\ndropout. The pruning couples this higher accuracy with an 85% reduction of the\nANN's parameter count. \n\n"}
{"id": "1805.02306", "contents": "Title: Semi-orthogonal Non-negative Matrix Factorization with an Application in\n  Text Mining Abstract: Emergency Department (ED) crowding is a worldwide issue that affects the\nefficiency of hospital management and the quality of patient care. This occurs\nwhen the request for an admit ward-bed to receive a patient is delayed until an\nadmission decision is made by a doctor. To reduce the overcrowding and waiting\ntime of ED, we build a classifier to predict the disposition of patients using\nmanually-typed nurse notes collected during triage, thereby allowing hospital\nstaff to begin necessary preparation beforehand. However, these triage notes\ninvolve high dimensional, noisy, and also sparse text data which makes model\nfitting and interpretation difficult. To address this issue, we propose the\nsemi-orthogonal non-negative matrix factorization (SONMF) for both continuous\nand binary design matrices to first bi-cluster the patients and words into a\nreduced number of topics. The subjects can then be interpreted as a\nnon-subtractive linear combination of orthogonal basis topic vectors. These\ngenerated topic vectors provide the hospital with a direct understanding of the\ncause of admission. We show that by using a transformation of basis, the\nclassification accuracy can be further increased compared to the conventional\nbag-of-words model and alternative matrix factorization approaches. Through\nsimulated data experiments, we also demonstrate that the proposed method\noutperforms other non-negative matrix factorization (NMF) methods in terms of\nfactorization accuracy, rate of convergence, and degree of orthogonality. \n\n"}
{"id": "1805.02722", "contents": "Title: Detecting Compressed Cleartext Traffic from Consumer Internet of Things\n  Devices Abstract: Data encryption is the primary method of protecting the privacy of consumer\ndevice Internet communications from network observers. The ability to\nautomatically detect unencrypted data in network traffic is therefore an\nessential tool for auditing Internet-connected devices. Existing methods\nidentify network packets containing cleartext but cannot differentiate packets\ncontaining encrypted data from packets containing compressed unencrypted data,\nwhich can be easily recovered by reversing the compression algorithm. This\nmakes it difficult for consumer protection advocates to identify devices that\nrisk user privacy by sending sensitive data in a compressed unencrypted format.\nHere, we present the first technique to automatically distinguish encrypted\nfrom compressed unencrypted network transmissions on a per-packet basis. We\napply three machine learning models and achieve a maximum 66.9% accuracy with a\nconvolutional neural network trained on raw packet data. This result is a\nbaseline for this previously unstudied machine learning problem, which we hope\nwill motivate further attention and accuracy improvements. To facilitate\ncontinuing research on this topic, we have made our training and test datasets\navailable to the public. \n\n"}
{"id": "1805.02855", "contents": "Title: Tile2Vec: Unsupervised representation learning for spatially distributed\n  data Abstract: Geospatial analysis lacks methods like the word vector representations and\npre-trained networks that significantly boost performance across a wide range\nof natural language and computer vision tasks. To fill this gap, we introduce\nTile2Vec, an unsupervised representation learning algorithm that extends the\ndistributional hypothesis from natural language -- words appearing in similar\ncontexts tend to have similar meanings -- to spatially distributed data. We\ndemonstrate empirically that Tile2Vec learns semantically meaningful\nrepresentations on three datasets. Our learned representations significantly\nimprove performance in downstream classification tasks and, similar to word\nvectors, visual analogies can be obtained via simple arithmetic in the latent\nspace. \n\n"}
{"id": "1805.03379", "contents": "Title: Opinion Fraud Detection via Neural Autoencoder Decision Forest Abstract: Online reviews play an important role in influencing buyers' daily purchase\ndecisions. However, fake and meaningless reviews, which cannot reflect users'\ngenuine purchase experience and opinions, widely exist on the Web and pose\ngreat challenges for users to make right choices. Therefore,it is desirable to\nbuild a fair model that evaluates the quality of products by distinguishing\nspamming reviews. We present an end-to-end trainable unified model to leverage\nthe appealing properties from Autoencoder and random forest. A stochastic\ndecision tree model is implemented to guide the global parameter learning\nprocess. Extensive experiments were conducted on a large Amazon review dataset.\nThe proposed model consistently outperforms a series of compared methods. \n\n"}
{"id": "1805.03551", "contents": "Title: A Unified Framework of Deep Neural Networks by Capsules Abstract: With the growth of deep learning, how to describe deep neural networks\nunifiedly is becoming an important issue. We first formalize neural networks\nmathematically with their directed graph representations, and prove a\ngeneration theorem about the induced networks of connected directed acyclic\ngraphs. Then, we set up a unified framework for deep learning with capsule\nnetworks. This capsule framework could simplify the description of existing\ndeep neural networks, and provide a theoretical basis of graphic designing and\nprogramming techniques for deep learning models, thus would be of great\nsignificance to the advancement of deep learning. \n\n"}
{"id": "1805.03644", "contents": "Title: Improving GAN Training via Binarized Representation Entropy (BRE)\n  Regularization Abstract: We propose a novel regularizer to improve the training of Generative\nAdversarial Networks (GANs). The motivation is that when the discriminator D\nspreads out its model capacity in the right way, the learning signals given to\nthe generator G are more informative and diverse. These in turn help G to\nexplore better and discover the real data manifold while avoiding large\nunstable jumps due to the erroneous extrapolation made by D. Our regularizer\nguides the rectifier discriminator D to better allocate its model capacity, by\nencouraging the binary activation patterns on selected internal layers of D to\nhave a high joint entropy. Experimental results on both synthetic data and real\ndatasets demonstrate improvements in stability and convergence speed of the GAN\ntraining, as well as higher sample quality. The approach also leads to higher\nclassification accuracies in semi-supervised learning. \n\n"}
{"id": "1805.04688", "contents": "Title: Gaussian Mixture Latent Vector Grammars Abstract: We introduce Latent Vector Grammars (LVeGs), a new framework that extends\nlatent variable grammars such that each nonterminal symbol is associated with a\ncontinuous vector space representing the set of (infinitely many) subtypes of\nthe nonterminal. We show that previous models such as latent variable grammars\nand compositional vector grammars can be interpreted as special cases of LVeGs.\nWe then present Gaussian Mixture LVeGs (GM-LVeGs), a new special case of LVeGs\nthat uses Gaussian mixtures to formulate the weights of production rules over\nsubtypes of nonterminals. A major advantage of using Gaussian mixtures is that\nthe partition function and the expectations of subtype rules can be computed\nusing an extension of the inside-outside algorithm, which enables efficient\ninference and learning. We apply GM-LVeGs to part-of-speech tagging and\nconstituency parsing and show that GM-LVeGs can achieve competitive accuracies.\nOur code is available at https://github.com/zhaoyanpeng/lveg. \n\n"}
{"id": "1805.05396", "contents": "Title: Confidence Scoring Using Whitebox Meta-models with Linear Classifier\n  Probes Abstract: We propose a novel confidence scoring mechanism for deep neural networks\nbased on a two-model paradigm involving a base model and a meta-model. The\nconfidence score is learned by the meta-model observing the base model\nsucceeding/failing at its task. As features to the meta-model, we investigate\nlinear classifier probes inserted between the various layers of the base model.\nOur experiments demonstrate that this approach outperforms various baselines in\na filtering task, i.e., task of rejecting samples with low confidence.\nExperimental results are presented using CIFAR-10 and CIFAR-100 dataset with\nand without added noise. We discuss the importance of confidence scoring to\nbridge the gap between experimental and real-world applications. \n\n"}
{"id": "1805.06061", "contents": "Title: SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines Abstract: Recurrent and convolutional neural networks comprise two distinct families of\nmodels that have proven to be useful for encoding natural language utterances.\nIn this paper we present SoPa, a new model that aims to bridge these two\napproaches. SoPa combines neural representation learning with weighted\nfinite-state automata (WFSAs) to learn a soft version of traditional surface\npatterns. We show that SoPa is an extension of a one-layer CNN, and that such\nCNNs are equivalent to a restricted version of SoPa, and accordingly, to a\nrestricted form of WFSA. Empirically, on three text classification tasks, SoPa\nis comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline,\nand is particularly useful in small data settings. \n\n"}
{"id": "1805.06201", "contents": "Title: Contextual Augmentation: Data Augmentation by Words with Paradigmatic\n  Relations Abstract: We propose a novel data augmentation for labeled sentences called contextual\naugmentation. We assume an invariance that sentences are natural even if the\nwords in the sentences are replaced with other words with paradigmatic\nrelations. We stochastically replace words with other words that are predicted\nby a bi-directional language model at the word positions. Words predicted\naccording to a context are numerous but appropriate for the augmentation of the\noriginal words. Furthermore, we retrofit a language model with a\nlabel-conditional architecture, which allows the model to augment sentences\nwithout breaking the label-compatibility. Through the experiments for six\nvarious different text classification tasks, we demonstrate that the proposed\nmethod improves classifiers based on the convolutional or recurrent neural\nnetworks. \n\n"}
{"id": "1805.06297", "contents": "Title: A robust self-learning method for fully unsupervised cross-lingual\n  mappings of word embeddings Abstract: Recent work has managed to learn cross-lingual word embeddings without\nparallel data by mapping monolingual embeddings to a shared space through\nadversarial training. However, their evaluation has focused on favorable\nconditions, using comparable corpora or closely-related languages, and we show\nthat they often fail in more realistic scenarios. This work proposes an\nalternative approach based on a fully unsupervised initialization that\nexplicitly exploits the structural similarity of the embeddings, and a robust\nself-learning algorithm that iteratively improves this solution. Our method\nsucceeds in all tested scenarios and obtains the best published results in\nstandard datasets, even surpassing previous supervised systems. Our\nimplementation is released as an open source project at\nhttps://github.com/artetxem/vecmap \n\n"}
{"id": "1805.07732", "contents": "Title: Nonlinear Distributional Gradient Temporal-Difference Learning Abstract: We devise a distributional variant of gradient temporal-difference (TD)\nlearning. Distributional reinforcement learning has been demonstrated to\noutperform the regular one in the recent study\n\\citep{bellemare2017distributional}. In the policy evaluation setting, we\ndesign two new algorithms called distributional GTD2 and distributional TDC\nusing the Cram{\\'e}r distance on the distributional version of the Bellman\nerror objective function, which inherits advantages of both the nonlinear\ngradient TD algorithms and the distributional RL approach. In the control\nsetting, we propose the distributional Greedy-GQ using the similar derivation.\nWe prove the asymptotic almost-sure convergence of distributional GTD2 and TDC\nto a local optimal solution for general smooth function approximators, which\nincludes neural networks that have been widely used in recent study to solve\nthe real-life RL problems. In each step, the computational complexities of\nabove three algorithms are linear w.r.t.\\ the number of the parameters of the\nfunction approximator, thus can be implemented efficiently for neural networks. \n\n"}
{"id": "1805.07857", "contents": "Title: Parallel Transport Convolution: A New Tool for Convolutional Neural\n  Networks on Manifolds Abstract: Convolution has been playing a prominent role in various applications in\nscience and engineering for many years. It is the most important operation in\nconvolutional neural networks. There has been a recent growth of interests of\nresearch in generalizing convolutions on curved domains such as manifolds and\ngraphs. However, existing approaches cannot preserve all the desirable\nproperties of Euclidean convolutions, namely compactly supported filters,\ndirectionality, transferability across different manifolds. In this paper we\ndevelop a new generalization of the convolution operation, referred to as\nparallel transport convolution (PTC), on Riemannian manifolds and their\ndiscrete counterparts. PTC is designed based on the parallel transportation\nwhich is able to translate information along a manifold and to intrinsically\npreserve directionality. PTC allows for the construction of compactly supported\nfilters and is also robust to manifold deformations. This enables us to preform\nwavelet-like operations and to define deep convolutional neural networks on\ncurved domains. \n\n"}
{"id": "1805.07909", "contents": "Title: Quickshift++: Provably Good Initializations for Sample-Based Mean Shift Abstract: We provide initial seedings to the Quick Shift clustering algorithm, which\napproximate the locally high-density regions of the data. Such seedings act as\nmore stable and expressive cluster-cores than the singleton modes found by\nQuick Shift. We establish statistical consistency guarantees for this\nmodification. We then show strong clustering performance on real datasets as\nwell as promising applications to image segmentation. \n\n"}
{"id": "1805.08052", "contents": "Title: Online Learning in Kernelized Markov Decision Processes Abstract: We consider online learning for minimizing regret in unknown, episodic Markov\ndecision processes (MDPs) with continuous states and actions. We develop\nvariants of the UCRL and posterior sampling algorithms that employ\nnonparametric Gaussian process priors to generalize across the state and action\nspaces. When the transition and reward functions of the true MDP are members of\nthe associated Reproducing Kernel Hilbert Spaces of functions induced by\nsymmetric psd kernels (frequentist setting), we show that the algorithms enjoy\nsublinear regret bounds. The bounds are in terms of explicit structural\nparameters of the kernels, namely a novel generalization of the information\ngain metric from kernelized bandit, and highlight the influence of transition\nand reward function structure on the learning performance. Our results are\napplicable to multidimensional state and action spaces with composite kernel\nstructures, and generalize results from the literature on kernelized bandits,\nand the adaptive control of parametric linear dynamical systems with quadratic\ncosts. \n\n"}
{"id": "1805.08322", "contents": "Title: Teaching Multiple Concepts to a Forgetful Learner Abstract: How can we help a forgetful learner learn multiple concepts within a limited\ntime frame? While there have been extensive studies in designing optimal\nschedules for teaching a single concept given a learner's memory model,\nexisting approaches for teaching multiple concepts are typically based on\nheuristic scheduling techniques without theoretical guarantees. In this paper,\nwe look at the problem from the perspective of discrete optimization and\nintroduce a novel algorithmic framework for teaching multiple concepts with\nstrong performance guarantees. Our framework is both generic, allowing the\ndesign of teaching schedules for different memory models, and also interactive,\nallowing the teacher to adapt the schedule to the underlying forgetting\nmechanisms of the learner. Furthermore, for a well-known memory model, we are\nable to identify a regime of model parameters where our framework is guaranteed\nto achieve high performance. We perform extensive evaluations using simulations\nalong with real user studies in two concrete applications: (i) an educational\napp for online vocabulary teaching; and (ii) an app for teaching novices how to\nrecognize animal species from images. Our results demonstrate the effectiveness\nof our algorithm compared to popular heuristic approaches. \n\n"}
{"id": "1805.08743", "contents": "Title: CascadeCNN: Pushing the performance limits of quantisation Abstract: This work presents CascadeCNN, an automated toolflow that pushes the\nquantisation limits of any given CNN model, to perform high-throughput\ninference by exploiting the computation time-accuracy trade-off. Without the\nneed for retraining, a two-stage architecture tailored for any given FPGA\ndevice is generated, consisting of a low- and a high-precision unit. A\nconfidence evaluation unit is employed between them to identify misclassified\ncases at run time and forward them to the high-precision unit or terminate\ncomputation. Experiments demonstrate that CascadeCNN achieves a performance\nboost of up to 55% for VGG-16 and 48% for AlexNet over the baseline design for\nthe same resource budget and accuracy. \n\n"}
{"id": "1805.08808", "contents": "Title: Deformable Part Networks Abstract: In this paper we propose novel Deformable Part Networks (DPNs) to learn {\\em\npose-invariant} representations for 2D object recognition. In contrast to the\nstate-of-the-art pose-aware networks such as CapsNet \\cite{sabour2017dynamic}\nand STN \\cite{jaderberg2015spatial}, DPNs can be naturally {\\em interpreted} as\nan efficient solver for a challenging detection problem, namely Localized\nDeformable Part Models (LDPMs) where localization is introduced to DPMs as\nanother latent variable for searching for the best poses of objects over all\npixels and (predefined) scales. In particular we construct DPNs as sequences of\nsuch LDPM units to model the semantic and spatial relations among the\ndeformable parts as hierarchical composition and spatial parsing trees.\nEmpirically our 17-layer DPN can outperform both CapsNets and STNs\nsignificantly on affNIST \\cite{sabour2017dynamic}, for instance, by 19.19\\% and\n12.75\\%, respectively, with better generalization and better tolerance to\naffine transformations. \n\n"}
{"id": "1805.08930", "contents": "Title: Analysis of Thompson Sampling for Graphical Bandits Without the Graphs Abstract: We study multi-armed bandit problems with graph feedback, in which the\ndecision maker is allowed to observe the neighboring actions of the chosen\naction, in a setting where the graph may vary over time and is never fully\nrevealed to the decision maker. We show that when the feedback graphs are\nundirected, the original Thompson Sampling achieves the optimal (within\nlogarithmic factors) regret $\\tilde{O}\\left(\\sqrt{\\beta_0(G)T}\\right)$ over\ntime horizon $T$, where $\\beta_0(G)$ is the average independence number of the\nlatent graphs. To the best of our knowledge, this is the first result showing\nthat the original Thompson Sampling is optimal for graphical bandits in the\nundirected setting. A slightly weaker regret bound of Thompson Sampling in the\ndirected setting is also presented. To fill this gap, we propose a variant of\nThompson Sampling, that attains the optimal regret in the directed setting\nwithin a logarithmic factor. Both algorithms can be implemented efficiently and\ndo not require the knowledge of the feedback graphs at any time. \n\n"}
{"id": "1805.09365", "contents": "Title: Learning Contextual Bandits in a Non-stationary Environment Abstract: Multi-armed bandit algorithms have become a reference solution for handling\nthe explore/exploit dilemma in recommender systems, and many other important\nreal-world problems, such as display advertisement. However, such algorithms\nusually assume a stationary reward distribution, which hardly holds in practice\nas users' preferences are dynamic. This inevitably costs a recommender system\nconsistent suboptimal performance. In this paper, we consider the situation\nwhere the underlying distribution of reward remains unchanged over (possibly\nshort) epochs and shifts at unknown time instants. In accordance, we propose a\ncontextual bandit algorithm that detects possible changes of environment based\non its reward estimation confidence and updates its arm selection strategy\nrespectively. Rigorous upper regret bound analysis of the proposed algorithm\ndemonstrates its learning effectiveness in such a non-trivial environment.\nExtensive empirical evaluations on both synthetic and real-world datasets for\nrecommendation confirm its practical utility in a changing environment. \n\n"}
{"id": "1805.09501", "contents": "Title: AutoAugment: Learning Augmentation Policies from Data Abstract: Data augmentation is an effective technique for improving the accuracy of\nmodern image classifiers. However, current data augmentation implementations\nare manually designed. In this paper, we describe a simple procedure called\nAutoAugment to automatically search for improved data augmentation policies. In\nour implementation, we have designed a search space where a policy consists of\nmany sub-policies, one of which is randomly chosen for each image in each\nmini-batch. A sub-policy consists of two operations, each operation being an\nimage processing function such as translation, rotation, or shearing, and the\nprobabilities and magnitudes with which the functions are applied. We use a\nsearch algorithm to find the best policy such that the neural network yields\nthe highest validation accuracy on a target dataset. Our method achieves\nstate-of-the-art accuracy on CIFAR-10, CIFAR-100, SVHN, and ImageNet (without\nadditional data). On ImageNet, we attain a Top-1 accuracy of 83.5% which is\n0.4% better than the previous record of 83.1%. On CIFAR-10, we achieve an error\nrate of 1.5%, which is 0.6% better than the previous state-of-the-art.\nAugmentation policies we find are transferable between datasets. The policy\nlearned on ImageNet transfers well to achieve significant improvements on other\ndatasets, such as Oxford Flowers, Caltech-101, Oxford-IIT Pets, FGVC Aircraft,\nand Stanford Cars. \n\n"}
{"id": "1805.10043", "contents": "Title: struc2gauss: Structural Role Preserving Network Embedding via Gaussian\n  Embedding Abstract: Network embedding (NE) is playing a principal role in network mining, due to\nits ability to map nodes into efficient low-dimensional embedding vectors.\nHowever, two major limitations exist in state-of-the-art NE methods: role\npreservation and uncertainty modeling. Almost all previous methods represent a\nnode into a point in space and focus on local structural information, i.e.,\nneighborhood information. However, neighborhood information does not capture\nglobal structural information and point vector representation fails in modeling\nthe uncertainty of node representations. In this paper, we propose a new NE\nframework, struc2gauss, which learns node representations in the space of\nGaussian distributions and performs network embedding based on global\nstructural information. struc2gauss first employs a given node similarity\nmetric to measure the global structural information, then generates structural\ncontext for nodes and finally learns node representations via Gaussian\nembedding. Different structural similarity measures of networks and energy\nfunctions of Gaussian embedding are investigated. Experiments conducted on\nreal-world networks demonstrate that struc2gauss effectively captures global\nstructural information while state-of-the-art network embedding methods fail\nto, outperforms other methods on the structure-based clustering and\nclassification task and provides more information on uncertainties of node\nrepresentations. \n\n"}
{"id": "1805.10842", "contents": "Title: Approximating Real-Time Recurrent Learning with Random Kronecker Factors Abstract: Despite all the impressive advances of recurrent neural networks, sequential\ndata is still in need of better modelling. Truncated backpropagation through\ntime (TBPTT), the learning algorithm most widely used in practice, suffers from\nthe truncation bias, which drastically limits its ability to learn long-term\ndependencies.The Real-Time Recurrent Learning algorithm (RTRL) addresses this\nissue, but its high computational requirements make it infeasible in practice.\nThe Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRL\nwith a smaller runtime and memory cost, but with the disadvantage of obtaining\nnoisy gradients that also limit its practical applicability. In this paper we\npropose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kronecker\nproduct decomposition to approximate the gradients for a large class of RNNs.\nWe show that KF-RTRL is an unbiased and memory efficient online learning\nalgorithm. Our theoretical analysis shows that, under reasonable assumptions,\nthe noise introduced by our algorithm is not only stable over time but also\nasymptotically much smaller than the one of the UORO algorithm. We also confirm\nthese theoretical results experimentally. Further, we show empirically that the\nKF-RTRL algorithm captures long-term dependencies and almost matches the\nperformance of TBPTT on real world tasks by training Recurrent Highway Networks\non a synthetic string memorization task and on the Penn TreeBank task,\nrespectively. These results indicate that RTRL based approaches might be a\npromising future alternative to TBPTT. \n\n"}
{"id": "1805.10927", "contents": "Title: Scalable and Robust Community Detection with Randomized Sketching Abstract: This article explores and analyzes the unsupervised clustering of large\npartially observed graphs. We propose a scalable and provable randomized\nframework for clustering graphs generated from the stochastic block model. The\nclustering is first applied to a sub-matrix of the graph's adjacency matrix\nassociated with a reduced graph sketch constructed using random sampling. Then,\nthe clusters of the full graph are inferred based on the clusters extracted\nfrom the sketch using a correlation-based retrieval step. Uniform random node\nsampling is shown to improve the computational complexity over clustering of\nthe full graph when the cluster sizes are balanced. A new random degree-based\nnode sampling algorithm is presented which significantly improves upon the\nperformance of the clustering algorithm even when clusters are unbalanced. This\nframework improves the phase transitions for matrix-decomposition-based\nclustering with regard to computational complexity and minimum cluster size,\nwhich are shown to be nearly dimension-free in the low inter-cluster\nconnectivity regime. A third sampling technique is shown to improve balance by\nrandomly sampling nodes based on spatial distribution. We provide analysis and\nnumerical results using a convex clustering algorithm based on matrix\ncompletion. \n\n"}
{"id": "1805.11016", "contents": "Title: Memory Augmented Self-Play Abstract: Self-play is an unsupervised training procedure which enables the\nreinforcement learning agents to explore the environment without requiring any\nexternal rewards. We augment the self-play setting by providing an external\nmemory where the agent can store experience from the previous tasks. This\nenables the agent to come up with more diverse self-play tasks resulting in\nfaster exploration of the environment. The agent pretrained in the memory\naugmented self-play setting easily outperforms the agent pretrained in\nno-memory self-play setting. \n\n"}
{"id": "1805.11063", "contents": "Title: Theory and Experiments on Vector Quantized Autoencoders Abstract: Deep neural networks with discrete latent variables offer the promise of\nbetter symbolic reasoning, and learning abstractions that are more useful to\nnew tasks. There has been a surge in interest in discrete latent variable\nmodels, however, despite several recent improvements, the training of discrete\nlatent variable models has remained challenging and their performance has\nmostly failed to match their continuous counterparts. Recent work on vector\nquantized autoencoders (VQ-VAE) has made substantial progress in this\ndirection, with its perplexity almost matching that of a VAE on datasets such\nas CIFAR-10. In this work, we investigate an alternate training technique for\nVQ-VAE, inspired by its connection to the Expectation Maximization (EM)\nalgorithm. Training the discrete bottleneck with EM helps us achieve better\nimage generation results on CIFAR-10, and together with knowledge distillation,\nallows us to develop a non-autoregressive machine translation model whose\naccuracy almost matches a strong greedy autoregressive baseline Transformer,\nwhile being 3.3 times faster at inference. \n\n"}
{"id": "1805.11233", "contents": "Title: Retraining-Based Iterative Weight Quantization for Deep Neural Networks Abstract: Model compression has gained a lot of attention due to its ability to reduce\nhardware resource requirements significantly while maintaining accuracy of\nDNNs. Model compression is especially useful for memory-intensive recurrent\nneural networks because smaller memory footprint is crucial not only for\nreducing storage requirement but also for fast inference operations.\nQuantization is known to be an effective model compression method and\nresearchers are interested in minimizing the number of bits to represent\nparameters. In this work, we introduce an iterative technique to apply\nquantization, presenting high compression ratio without any modifications to\nthe training algorithm. In the proposed technique, weight quantization is\nfollowed by retraining the model with full precision weights. We show that\niterative retraining generates new sets of weights which can be quantized with\ndecreasing quantization loss at each iteration. We also show that quantization\nis efficiently able to leverage pruning, another effective model compression\nmethod. Implementation issues on combining the two methods are also addressed.\nOur experimental results demonstrate that an LSTM model using 1-bit quantized\nweights is sufficient for PTB dataset without any accuracy degradation while\nprevious methods demand at least 2-4 bits for quantized weights. \n\n"}
{"id": "1805.11328", "contents": "Title: Hamiltonian Variational Auto-Encoder Abstract: Variational Auto-Encoders (VAEs) have become very popular techniques to\nperform inference and learning in latent variable models as they allow us to\nleverage the rich representational power of neural networks to obtain flexible\napproximations of the posterior of latent variables as well as tight evidence\nlower bounds (ELBOs). Combined with stochastic variational inference, this\nprovides a methodology scaling to large datasets. However, for this methodology\nto be practically efficient, it is necessary to obtain low-variance unbiased\nestimators of the ELBO and its gradients with respect to the parameters of\ninterest. While the use of Markov chain Monte Carlo (MCMC) techniques such as\nHamiltonian Monte Carlo (HMC) has been previously suggested to achieve this\n[23, 26], the proposed methods require specifying reverse kernels which have a\nlarge impact on performance. Additionally, the resulting unbiased estimator of\nthe ELBO for most MCMC kernels is typically not amenable to the\nreparameterization trick. We show here how to optimally select reverse kernels\nin this setting and, by building upon Hamiltonian Importance Sampling (HIS)\n[17], we obtain a scheme that provides low-variance unbiased estimators of the\nELBO and its gradients using the reparameterization trick. This allows us to\ndevelop a Hamiltonian Variational Auto-Encoder (HVAE). This method can be\nreinterpreted as a target-informed normalizing flow [20] which, within our\ncontext, only requires a few evaluations of the gradient of the sampled\nlikelihood and trivial Jacobian calculations at each iteration. \n\n"}
{"id": "1805.12313", "contents": "Title: Conformation Clustering of Long MD Protein Dynamics with an Adversarial\n  Autoencoder Abstract: Recent developments in specialized computer hardware have greatly accelerated\natomic level Molecular Dynamics (MD) simulations. A single GPU-attached cluster\nis capable of producing microsecond-length trajectories in reasonable amounts\nof time. Multiple protein states and a large number of microstates associated\nwith folding and with the function of the protein can be observed as\nconformations sampled in the trajectories. Clustering those conformations,\nhowever, is needed for identifying protein states, evaluating transition rates\nand understanding protein behavior. In this paper, we propose a novel\ndata-driven generative conformation clustering method based on the adversarial\nautoencoder (AAE) and provide the associated software implementation Cong. The\nmethod was tested using a 208 microseconds MD simulation of the fast-folding\npeptide Trp-Cage (20 residues) obtained from the D.E. Shaw Research Group. The\nproposed clustering algorithm identifies many of the salient features of the\nfolding process by grouping a large number of conformations that share common\nfeatures not easily identifiable in the trajectory. \n\n"}
{"id": "1805.12316", "contents": "Title: Greedy Attack and Gumbel Attack: Generating Adversarial Examples for\n  Discrete Data Abstract: We present a probabilistic framework for studying adversarial attacks on\ndiscrete data. Based on this framework, we derive a perturbation-based method,\nGreedy Attack, and a scalable learning-based method, Gumbel Attack, that\nillustrate various tradeoffs in the design of attacks. We demonstrate the\neffectiveness of these methods using both quantitative metrics and human\nevaluation on various state-of-the-art models for text classification,\nincluding a word-based CNN, a character-based CNN and an LSTM. As as example of\nour results, we show that the accuracy of character-based convolutional\nnetworks drops to the level of random selection by modifying only five\ncharacters through Greedy Attack. \n\n"}
{"id": "1805.12514", "contents": "Title: Scaling provable adversarial defenses Abstract: Recent work has developed methods for learning deep network classifiers that\nare provably robust to norm-bounded adversarial perturbation; however, these\nmethods are currently only possible for relatively small feedforward networks.\nIn this paper, in an effort to scale these approaches to substantially larger\nmodels, we extend previous work in three main directions. First, we present a\ntechnique for extending these training procedures to much more general\nnetworks, with skip connections (such as ResNets) and general nonlinearities;\nthe approach is fully modular, and can be implemented automatically (analogous\nto automatic differentiation). Second, in the specific case of $\\ell_\\infty$\nadversarial perturbations and networks with ReLU nonlinearities, we adopt a\nnonlinear random projection for training, which scales linearly in the number\nof hidden units (previous approaches scaled quadratically). Third, we show how\nto further improve robust error through cascade models. On both MNIST and CIFAR\ndata sets, we train classifiers that improve substantially on the state of the\nart in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST\n(with $\\ell_\\infty$ perturbations of $\\epsilon=0.1$), and from 80% to 36.4% on\nCIFAR (with $\\ell_\\infty$ perturbations of $\\epsilon=2/255$). Code for all\nexperiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial/. \n\n"}
{"id": "1805.12573", "contents": "Title: Learning a Prior over Intent via Meta-Inverse Reinforcement Learning Abstract: A significant challenge for the practical application of reinforcement\nlearning in the real world is the need to specify an oracle reward function\nthat correctly defines a task. Inverse reinforcement learning (IRL) seeks to\navoid this challenge by instead inferring a reward function from expert\nbehavior. While appealing, it can be impractically expensive to collect\ndatasets of demonstrations that cover the variation common in the real world\n(e.g. opening any type of door). Thus in practice, IRL must commonly be\nperformed with only a limited set of demonstrations where it can be exceedingly\ndifficult to unambiguously recover a reward function. In this work, we exploit\nthe insight that demonstrations from other tasks can be used to constrain the\nset of possible reward functions by learning a \"prior\" that is specifically\noptimized for the ability to infer expressive reward functions from limited\nnumbers of demonstrations. We demonstrate that our method can efficiently\nrecover rewards from images for novel tasks and provide intuition as to how our\napproach is analogous to learning a prior. \n\n"}
{"id": "1806.00428", "contents": "Title: A Classification approach towards Unsupervised Learning of Visual\n  Representations Abstract: In this paper, we present a technique for unsupervised learning of visual\nrepresentations. Specifically, we train a model for foreground and background\nclassification task, in the process of which it learns visual representations.\nForeground and background patches for training come af- ter mining for such\npatches from hundreds and thousands of unlabelled videos available on the web\nwhich we ex- tract using a proposed patch extraction algorithm. With- out using\nany supervision, with just using 150, 000 unla- belled videos and the PASCAL\nVOC 2007 dataset, we train a object recognition model that achieves 45.3 mAP\nwhich is close to the best performing unsupervised feature learn- ing technique\nwhereas better than many other proposed al- gorithms. The code for patch\nextraction is implemented in Matlab and available open source at the following\nlink . \n\n"}
{"id": "1806.00630", "contents": "Title: DAQN: Deep Auto-encoder and Q-Network Abstract: The deep reinforcement learning method usually requires a large number of\ntraining images and executing actions to obtain sufficient results. When it is\nextended a real-task in the real environment with an actual robot, the method\nwill be required more training images due to complexities or noises of the\ninput images, and executing a lot of actions on the real robot also becomes a\nserious problem. Therefore, we propose an extended deep reinforcement learning\nmethod that is applied a generative model to initialize the network for\nreducing the number of training trials. In this paper, we used a deep q-network\nmethod as the deep reinforcement learning method and a deep auto-encoder as the\ngenerative model. We conducted experiments on three different tasks: a\ncart-pole game, an atari game, and a real-game with an actual robot. The\nproposed method trained efficiently on all tasks than the previous method,\nespecially 2.5 times faster on a task with real environment images. \n\n"}
{"id": "1806.00875", "contents": "Title: Deploying Customized Data Representation and Approximate Computing in\n  Machine Learning Applications Abstract: Major advancements in building general-purpose and customized hardware have\nbeen one of the key enablers of versatility and pervasiveness of machine\nlearning models such as deep neural networks. To sustain this ubiquitous\ndeployment of machine learning models and cope with their computational and\nstorage complexity, several solutions such as low-precision representation of\nmodel parameters using fixed-point representation and deploying approximate\narithmetic operations have been employed. Studying the potency of such\nsolutions in different applications requires integrating them into existing\nmachine learning frameworks for high-level simulations as well as implementing\nthem in hardware to analyze their effects on power/energy dissipation,\nthroughput, and chip area. Lop is a library for design space exploration that\nbridges the gap between machine learning and efficient hardware realization. It\ncomprises a Python module, which can be integrated with some of the existing\nmachine learning frameworks and implements various customizable data\nrepresentations including fixed-point and floating-point as well as approximate\narithmetic operations.Furthermore, it includes a highly-parameterized Scala\nmodule, which allows synthesizing hardware based on the said data\nrepresentations and arithmetic operations. Lop allows researchers and designers\nto quickly compare quality of their models using various data representations\nand arithmetic operations in Python and contrast the hardware cost of viable\nrepresentations by synthesizing them on their target platforms (e.g., FPGA or\nASIC). To the best of our knowledge, Lop is the first library that allows both\nsoftware simulation and hardware realization using customized data\nrepresentations and approximate computing techniques. \n\n"}
{"id": "1806.00931", "contents": "Title: Holographic Neural Architectures Abstract: Representation learning is at the heart of what makes deep learning\neffective. In this work, we introduce a new framework for representation\nlearning that we call \"Holographic Neural Architectures\" (HNAs). In the same\nway that an observer can experience the 3D structure of a holographed object by\nlooking at its hologram from several angles, HNAs derive Holographic\nRepresentations from the training set. These representations can then be\nexplored by moving along a continuous bounded single dimension. We show that\nHNAs can be used to make generative networks, state-of-the-art regression\nmodels and that they are inherently highly resistant to noise. Finally, we\nargue that because of their denoising abilities and their capacity to\ngeneralize well from very few examples, models based upon HNAs are particularly\nwell suited for biological applications where training examples are rare or\nnoisy. \n\n"}
{"id": "1806.01003", "contents": "Title: Distributed Learning from Interactions in Social Networks Abstract: We consider a network scenario in which agents can evaluate each other\naccording to a score graph that models some interactions. The goal is to design\na distributed protocol, run by the agents, that allows them to learn their\nunknown state among a finite set of possible values. We propose a Bayesian\nframework in which scores and states are associated to probabilistic events\nwith unknown parameters and hyperparameters, respectively. We show that each\nagent can learn its state by means of a local Bayesian classifier and a\n(centralized) Maximum-Likelihood (ML) estimator of parameter-hyperparameter\nthat combines plain ML and Empirical Bayes approaches. By using tools from\ngraphical models, which allow us to gain insight on conditional dependencies of\nscores and states, we provide a relaxed probabilistic model that ultimately\nleads to a parameter-hyperparameter estimator amenable to distributed\ncomputation. To highlight the appropriateness of the proposed relaxation, we\ndemonstrate the distributed estimators on a social interaction set-up for user\nprofiling. \n\n"}
{"id": "1806.01427", "contents": "Title: Analysis of DAWNBench, a Time-to-Accuracy Machine Learning Performance\n  Benchmark Abstract: Researchers have proposed hardware, software, and algorithmic optimizations\nto improve the computational performance of deep learning. While some of these\noptimizations perform the same operations faster (e.g., increasing GPU clock\nspeed), many others modify the semantics of the training procedure (e.g.,\nreduced precision), and can impact the final model's accuracy on unseen data.\nDue to a lack of standard evaluation criteria that considers these trade-offs,\nit is difficult to directly compare these optimizations. To address this\nproblem, we recently introduced DAWNBench, a benchmark competition focused on\nend-to-end training time to achieve near-state-of-the-art accuracy on an unseen\ndataset---a combined metric called time-to-accuracy (TTA). In this work, we\nanalyze the entries from DAWNBench, which received optimized submissions from\nmultiple industrial groups, to investigate the behavior of TTA as a metric as\nwell as trends in the best-performing entries. We show that TTA has a low\ncoefficient of variation and that models optimized for TTA generalize nearly as\nwell as those trained using standard methods. Additionally, even though\nDAWNBench entries were able to train ImageNet models in under 3 minutes, we\nfind they still underutilize hardware capabilities such as Tensor Cores.\nFurthermore, we find that distributed entries can spend more than half of their\ntime on communication. We show similar findings with entries to the MLPERF v0.5\nbenchmark. \n\n"}
{"id": "1806.01818", "contents": "Title: LSTM Benchmarks for Deep Learning Frameworks Abstract: This study provides benchmarks for different implementations of LSTM units\nbetween the deep learning frameworks PyTorch, TensorFlow, Lasagne and Keras.\nThe comparison includes cuDNN LSTMs, fused LSTM variants and less optimized,\nbut more flexible LSTM implementations. The benchmarks reflect two typical\nscenarios for automatic speech recognition, notably continuous speech\nrecognition and isolated digit recognition. These scenarios cover input\nsequences of fixed and variable length as well as the loss functions CTC and\ncross entropy. Additionally, a comparison between four different PyTorch\nversions is included. The code is available online\nhttps://github.com/stefbraun/rnn_benchmarks. \n\n"}
{"id": "1806.01830", "contents": "Title: Relational Deep Reinforcement Learning Abstract: We introduce an approach for deep reinforcement learning (RL) that improves\nupon the efficiency, generalization capacity, and interpretability of\nconventional approaches through structured perception and relational reasoning.\nIt uses self-attention to iteratively reason about the relations between\nentities in a scene and to guide a model-free policy. Our results show that in\na novel navigation and planning task called Box-World, our agent finds\ninterpretable solutions that improve upon baselines in terms of sample\ncomplexity, ability to generalize to more complex scenes than experienced\nduring training, and overall performance. In the StarCraft II Learning\nEnvironment, our agent achieves state-of-the-art performance on six mini-games\n-- surpassing human grandmaster performance on four. By considering\narchitectural inductive biases, our work opens new directions for overcoming\nimportant, but stubborn, challenges in deep RL. \n\n"}
{"id": "1806.02508", "contents": "Title: Semi-Dynamic Load Balancing: Efficient Distributed Learning in\n  Non-Dedicated Environments Abstract: Machine learning (ML) models are increasingly trained in clusters with\nnon-dedicated workers possessing heterogeneous resources. In such scenarios,\nmodel training efficiency can be negatively affected by stragglers -- workers\nthat run much slower than others. Efficient model training requires eliminating\nsuch stragglers, yet for modern ML workloads, existing load balancing\nstrategies are inefficient and even infeasible. In this paper, we propose a\nnovel strategy called semi-dynamic load balancing to eliminate stragglers of\ndistributed ML workloads. The key insight is that ML workers shall be\nload-balanced at iteration boundaries, being non-intrusive to intra-iteration\nexecution. We develop LB-BSP based on such an insight, which is an integrated\nworker coordination mechanism that adapts workers' load to their instantaneous\nprocessing capabilities by right-sizing the sample batches at the\nsynchronization barriers. We have custom-designed the batch sizing algorithm\nrespectively for CPU and GPU clusters based on their own characteristics.\nLB-BSP has been implemented as a Python module for ML frameworks like\nTensorFlow and PyTorch. Our EC2 deployment confirms that LB-BSP is practical,\neffective and light-weight, and is able to accelerating distributed training by\nup to $54\\%$. \n\n"}
{"id": "1806.02739", "contents": "Title: Discovering space - Grounding spatial topology and metric regularity in\n  a naive agent's sensorimotor experience Abstract: In line with the sensorimotor contingency theory, we investigate the problem\nof the perception of space from a fundamental sensorimotor perspective. Despite\nits pervasive nature in our perception of the world, the origin of the concept\nof space remains largely mysterious. For example in the context of artificial\nperception, this issue is usually circumvented by having engineers pre-define\nthe spatial structure of the problem the agent has to face. We here show that\nthe structure of space can be autonomously discovered by a naive agent in the\nform of sensorimotor regularities, that correspond to so called compensable\nsensory experiences: these are experiences that can be generated either by the\nagent or its environment. By detecting such compensable experiences the agent\ncan infer the topological and metric structure of the external space in which\nits body is moving. We propose a theoretical description of the nature of these\nregularities and illustrate the approach on a simulated robotic arm equipped\nwith an eye-like sensor, and which interacts with an object. Finally we show\nhow these regularities can be used to build an internal representation of the\nsensor's external spatial configuration. \n\n"}
{"id": "1806.02942", "contents": "Title: SupportNet: solving catastrophic forgetting in class incremental\n  learning with support data Abstract: A plain well-trained deep learning model often does not have the ability to\nlearn new knowledge without forgetting the previously learned knowledge, which\nis known as catastrophic forgetting. Here we propose a novel method,\nSupportNet, to efficiently and effectively solve the catastrophic forgetting\nproblem in the class incremental learning scenario. SupportNet combines the\nstrength of deep learning and support vector machine (SVM), where SVM is used\nto identify the support data from the old data, which are fed to the deep\nlearning model together with the new data for further training so that the\nmodel can review the essential information of the old data when learning the\nnew information. Two powerful consolidation regularizers are applied to\nstabilize the learned representation and ensure the robustness of the learned\nmodel. We validate our method with comprehensive experiments on various tasks,\nwhich show that SupportNet drastically outperforms the state-of-the-art\nincremental learning methods and even reaches similar performance as the deep\nlearning model trained from scratch on both old and new data. Our program is\naccessible at: https://github.com/lykaust15/SupportNet \n\n"}
{"id": "1806.03335", "contents": "Title: Randomized Prior Functions for Deep Reinforcement Learning Abstract: Dealing with uncertainty is essential for efficient reinforcement learning.\nThere is a growing literature on uncertainty estimation for deep learning from\nfixed datasets, but many of the most popular approaches are poorly-suited to\nsequential decision problems. Other methods, such as bootstrap sampling, have\nno mechanism for uncertainty that does not come from the observed data. We\nhighlight why this can be a crucial shortcoming and propose a simple remedy\nthrough addition of a randomized untrainable `prior' network to each ensemble\nmember. We prove that this approach is efficient with linear representations,\nprovide simple illustrations of its efficacy with nonlinear representations and\nshow that this approach scales to large-scale problems far better than previous\nattempts. \n\n"}
{"id": "1806.03342", "contents": "Title: Discovering Signals from Web Sources to Predict Cyber Attacks Abstract: Cyber attacks are growing in frequency and severity. Over the past year alone\nwe have witnessed massive data breaches that stole personal information of\nmillions of people and wide-scale ransomware attacks that paralyzed critical\ninfrastructure of several countries. Combating the rising cyber threat calls\nfor a multi-pronged strategy, which includes predicting when these attacks will\noccur. The intuition driving our approach is this: during the planning and\npreparation stages, hackers leave digital traces of their activities on both\nthe surface web and dark web in the form of discussions on platforms like\nhacker forums, social media, blogs and the like. These data provide predictive\nsignals that allow anticipating cyber attacks. In this paper, we describe\nmachine learning techniques based on deep neural networks and autoregressive\ntime series models that leverage external signals from publicly available Web\nsources to forecast cyber attacks. Performance of our framework across ground\ntruth data over real-world forecasting tasks shows that our methods yield a\nsignificant lift or increase of F1 for the top signals on predicted cyber\nattacks. Our results suggest that, when deployed, our system will be able to\nprovide an effective line of defense against various types of targeted cyber\nattacks. \n\n"}
{"id": "1806.03677", "contents": "Title: Dissipativity Theory for Accelerating Stochastic Variance Reduction: A\n  Unified Analysis of SVRG and Katyusha Using Semidefinite Programs Abstract: Techniques for reducing the variance of gradient estimates used in stochastic\nprogramming algorithms for convex finite-sum problems have received a great\ndeal of attention in recent years. By leveraging dissipativity theory from\ncontrol, we provide a new perspective on two important variance-reduction\nalgorithms: SVRG and its direct accelerated variant Katyusha. Our perspective\nprovides a physically intuitive understanding of the behavior of SVRG-like\nmethods via a principle of energy conservation. The tools discussed here allow\nus to automate the convergence analysis of SVRG-like methods by capturing their\nessential properties in small semidefinite programs amenable to standard\nanalysis and computational techniques. Our approach recovers existing\nconvergence results for SVRG and Katyusha and generalizes the theory to\nalternative parameter choices. We also discuss how our approach complements the\nlinear coupling technique. Our combination of perspectives leads to a better\nunderstanding of accelerated variance-reduced stochastic methods for finite-sum\nproblems. \n\n"}
{"id": "1806.03945", "contents": "Title: A Fast and Easy Regression Technique for k-NN Classification Without\n  Using Negative Pairs Abstract: This paper proposes an inexpensive way to learn an effective dissimilarity\nfunction to be used for $k$-nearest neighbor ($k$-NN) classification. Unlike\nMahalanobis metric learning methods that map both query (unlabeled) objects and\nlabeled objects to new coordinates by a single transformation, our method\nlearns a transformation of labeled objects to new points in the feature space\nwhereas query objects are kept in their original coordinates. This method has\nseveral advantages over existing distance metric learning methods: (i) In\nexperiments with large document and image datasets, it achieves $k$-NN\nclassification accuracy better than or at least comparable to the\nstate-of-the-art metric learning methods. (ii) The transformation can be\nlearned efficiently by solving a standard ridge regression problem. For\ndocument and image datasets, training is often more than two orders of\nmagnitude faster than the fastest metric learning methods tested. This speed-up\nis also due to the fact that the proposed method eliminates the optimization\nover \"negative\" object pairs, i.e., objects whose class labels are different.\n(iii) The formulation has a theoretical justification in terms of reducing\nhubness in data. \n\n"}
{"id": "1806.04016", "contents": "Title: Baselines and a datasheet for the Cerema AWP dataset Abstract: This paper presents the recently published Cerema AWP (Adverse Weather\nPedestrian) dataset for various machine learning tasks and its exports in\nmachine learning friendly format. We explain why this dataset can be\ninteresting (mainly because it is a greatly controlled and fully annotated\nimage dataset) and present baseline results for various tasks. Moreover, we\ndecided to follow the very recent suggestions of datasheets for dataset, trying\nto standardize all the available information of the dataset, with a\ntransparency objective. \n\n"}
{"id": "1806.04245", "contents": "Title: Learning to Speed Up Structured Output Prediction Abstract: Predicting structured outputs can be computationally onerous due to the\ncombinatorially large output spaces. In this paper, we focus on reducing the\nprediction time of a trained black-box structured classifier without losing\naccuracy. To do so, we train a speedup classifier that learns to mimic a\nblack-box classifier under the learning-to-search approach. As the structured\nclassifier predicts more examples, the speedup classifier will operate as a\nlearned heuristic to guide search to favorable regions of the output space. We\npresent a mistake bound for the speedup classifier and identify inference\nsituations where it can independently make correct judgments without input\nfeatures. We evaluate our method on the task of entity and relation extraction\nand show that the speedup classifier outperforms even greedy search in terms of\nspeed without loss of accuracy. \n\n"}
{"id": "1806.04642", "contents": "Title: Accelerating Imitation Learning with Predictive Models Abstract: Sample efficiency is critical in solving real-world reinforcement learning\nproblems, where agent-environment interactions can be costly. Imitation\nlearning from expert advice has proved to be an effective strategy for reducing\nthe number of interactions required to train a policy. Online imitation\nlearning, which interleaves policy evaluation and policy optimization, is a\nparticularly effective technique with provable performance guarantees. In this\nwork, we seek to further accelerate the convergence rate of online imitation\nlearning, thereby making it more sample efficient. We propose two model-based\nalgorithms inspired by Follow-the-Leader (FTL) with prediction: MoBIL-VI based\non solving variational inequalities and MoBIL-Prox based on stochastic\nfirst-order updates. These two methods leverage a model to predict future\ngradients to speed up policy learning. When the model oracle is learned online,\nthese algorithms can provably accelerate the best known convergence rate up to\nan order. Our algorithms can be viewed as a generalization of stochastic\nMirror-Prox (Juditsky et al., 2011), and admit a simple constructive FTL-style\nanalysis of performance. \n\n"}
{"id": "1806.04965", "contents": "Title: The streaming rollout of deep networks - towards fully model-parallel\n  execution Abstract: Deep neural networks, and in particular recurrent networks, are promising\ncandidates to control autonomous agents that interact in real-time with the\nphysical world. However, this requires a seamless integration of temporal\nfeatures into the network's architecture. For the training of and inference\nwith recurrent neural networks, they are usually rolled out over time, and\ndifferent rollouts exist. Conventionally during inference, the layers of a\nnetwork are computed in a sequential manner resulting in sparse temporal\nintegration of information and long response times. In this study, we present a\ntheoretical framework to describe rollouts, the level of model-parallelization\nthey induce, and demonstrate differences in solving specific tasks. We prove\nthat certain rollouts, also for networks with only skip and no recurrent\nconnections, enable earlier and more frequent responses, and show empirically\nthat these early responses have better performance. The streaming rollout\nmaximizes these properties and enables a fully parallel execution of the\nnetwork reducing runtime on massively parallel devices. Finally, we provide an\nopen-source toolbox to design, train, evaluate, and interact with streaming\nrollouts. \n\n"}
{"id": "1806.05178", "contents": "Title: Generating Sentences Using a Dynamic Canvas Abstract: We introduce the Attentive Unsupervised Text (W)riter (AUTR), which is a word\nlevel generative model for natural language. It uses a recurrent neural network\nwith a dynamic attention and canvas memory mechanism to iteratively construct\nsentences. By viewing the state of the memory at intermediate stages and where\nthe model is placing its attention, we gain insight into how it constructs\nsentences. We demonstrate that AUTR learns a meaningful latent representation\nfor each sentence, and achieves competitive log-likelihood lower bounds whilst\nbeing computationally efficient. It is effective at generating and\nreconstructing sentences, as well as imputing missing words. \n\n"}
{"id": "1806.05780", "contents": "Title: Surprising Negative Results for Generative Adversarial Tree Search Abstract: While many recent advances in deep reinforcement learning (RL) rely on\nmodel-free methods, model-based approaches remain an alluring prospect for\ntheir potential to exploit unsupervised data to learn environment model. In\nthis work, we provide an extensive study on the design of deep generative\nmodels for RL environments and propose a sample efficient and robust method to\nlearn the model of Atari environments. We deploy this model and propose\ngenerative adversarial tree search (GATS) a deep RL algorithm that learns the\nenvironment model and implements Monte Carlo tree search (MCTS) on the learned\nmodel for planning. While MCTS on the learned model is computationally\nexpensive, similar to AlphaGo, GATS follows depth limited MCTS. GATS employs\ndeep Q network (DQN) and learns a Q-function to assign values to the leaves of\nthe tree in MCTS. We theoretical analyze GATS vis-a-vis the bias-variance\ntrade-off and show GATS is able to mitigate the worst-case error in the\nQ-estimate. While we were expecting GATS to enjoy a better sample complexity\nand faster converges to better policies, surprisingly, GATS fails to outperform\nDQN. We provide a study on which we show why depth limited MCTS fails to\nperform desirably. \n\n"}
{"id": "1806.05789", "contents": "Title: Image classification and retrieval with random depthwise signed\n  convolutional neural networks Abstract: We propose a random convolutional neural network to generate a feature space\nin which we study image classification and retrieval performance. Put briefly\nwe apply random convolutional blocks followed by global average pooling to\ngenerate a new feature, and we repeat this k times to produce a k-dimensional\nfeature space. This can be interpreted as partitioning the space of image\npatches with random hyperplanes which we formalize as a random depthwise\nconvolutional neural network. In the network's final layer we perform image\nclassification and retrieval with the linear support vector machine and\nk-nearest neighbor classifiers and study other empirical properties. We show\nthat the ratio of image pixel distribution similarity across classes to within\nclasses is higher in our network's final layer compared to the input space.\nWhen we apply the linear support vector machine for image classification we see\nthat the accuracy is higher than if we were to train just the final layer of\nVGG16, ResNet18, and DenseNet40 with random weights. In the same setting we\ncompare it to an unsupervised feature learning method and find our accuracy to\nbe comparable on CIFAR10 but higher on CIFAR100 and STL10. We see that the\naccuracy is not far behind that of trained networks, particularly in the top-k\nsetting. For example the top-2 accuracy of our network is near 90% on both\nCIFAR10 and a 10-class mini ImageNet, and 85% on STL10. We find that k-nearest\nneighbor gives a comparable precision on the Corel Princeton Image Similarity\nBenchmark than if we were to use the final layer of trained networks. As with\nother networks we find that our network fails to a black box attack even though\nwe lack a gradient and use the sign activation. We highlight sensitivity of our\nnetwork to background as a potential pitfall and an advantage. Overall our work\npushes the boundary of what can be achieved with random weights. \n\n"}
{"id": "1806.05805", "contents": "Title: Molecular generative model based on conditional variational autoencoder\n  for de novo molecular design Abstract: We propose a molecular generative model based on the conditional variational\nautoencoder for de novo molecular design. It is specialized to control multiple\nmolecular properties simultaneously by imposing them on a latent space. As a\nproof of concept, we demonstrate that it can be used to generate drug-like\nmolecules with five target properties. We were also able to adjust a single\nproperty without changing the others and to manipulate it beyond the range of\nthe dataset. \n\n"}
{"id": "1806.06122", "contents": "Title: Fairness Under Composition Abstract: Algorithmic fairness, and in particular the fairness of scoring and\nclassification algorithms, has become a topic of increasing social concern and\nhas recently witnessed an explosion of research in theoretical computer\nscience, machine learning, statistics, the social sciences, and law. Much of\nthe literature considers the case of a single classifier (or scoring function)\nused once, in isolation. In this work, we initiate the study of the fairness\nproperties of systems composed of algorithms that are fair in isolation; that\nis, we study fairness under composition. We identify pitfalls of naive\ncomposition and give general constructions for fair composition, demonstrating\nboth that classifiers that are fair in isolation do not necessarily compose\ninto fair systems and also that seemingly unfair components may be carefully\ncombined to construct fair systems. We focus primarily on the individual\nfairness setting proposed in [Dwork, Hardt, Pitassi, Reingold, Zemel, 2011],\nbut also extend our results to a large class of group fairness definitions\npopular in the recent literature, exhibiting several cases in which group\nfairness definitions give misleading signals under composition. \n\n"}
{"id": "1806.06384", "contents": "Title: Multi-variable LSTM neural network for autoregressive exogenous model Abstract: In this paper, we propose multi-variable LSTM capable of accurate forecasting\nand variable importance interpretation for time series with exogenous\nvariables. Current attention mechanism in recurrent neural networks mostly\nfocuses on the temporal aspect of data and falls short of characterizing\nvariable importance. To this end, the multi-variable LSTM equipped with\ntensorized hidden states is developed to learn hidden states for individual\nvariables, which give rise to our mixture temporal and variable attention.\nBased on such attention mechanism, we infer and quantify variable importance.\nExtensive experiments using real datasets with Granger-causality test and the\nsynthetic dataset with ground truth demonstrate the prediction performance and\ninterpretability of multi-variable LSTM in comparison to a variety of\nbaselines. It exhibits the prospect of multi-variable LSTM as an end-to-end\nframework for both forecasting and knowledge discovery. \n\n"}
{"id": "1806.06913", "contents": "Title: Deep Learning based Estimation of Weaving Target Maneuvers Abstract: In target tracking, the estimation of an unknown weaving target frequency is\ncrucial for improving the miss distance. The estimation process is commonly\ncarried out in a Kalman framework. The objective of this paper is to examine\nthe potential of using neural networks in target tracking applications. To that\nend, we propose estimating the weaving frequency using deep neural networks,\ninstead of classical Kalman framework based estimation. Particularly, we focus\non the case where a set of possible constant target frequencies is known.\nSeveral neural network architectures, requiring low computational resources\nwere designed to estimate the unknown frequency out of the known set of\nfrequencies. The proposed approach performance is compared with the multiple\nmodel adaptive estimation algorithm. Simulation results show that in the\nexamined scenarios, deep neural network outperforms multiple model adaptive\nestimation in terms of accuracy and the amount of required measurements to\nconvergence. \n\n"}
{"id": "1806.06928", "contents": "Title: Meta Continual Learning Abstract: Using neural networks in practical settings would benefit from the ability of\nthe networks to learn new tasks throughout their lifetimes without forgetting\nthe previous tasks. This ability is limited in the current deep neural networks\nby a problem called catastrophic forgetting, where training on new tasks tends\nto severely degrade performance on previous tasks. One way to lessen the impact\nof the forgetting problem is to constrain parameters that are important to\nprevious tasks to stay close to the optimal parameters. Recently, multiple\ncompetitive approaches for computing the importance of the parameters with\nrespect to the previous tasks have been presented. In this paper, we propose a\nlearning to optimize algorithm for mitigating catastrophic forgetting. Instead\nof trying to formulate a new constraint function ourselves, we propose to train\nanother neural network to predict parameter update steps that respect the\nimportance of parameters to the previous tasks. In the proposed meta-training\nscheme, the update predictor is trained to minimize loss on a combination of\ncurrent and past tasks. We show experimentally that the proposed approach works\nin the continual learning setting. \n\n"}
{"id": "1806.06949", "contents": "Title: Full deep neural network training on a pruned weight budget Abstract: We introduce a DNN training technique that learns only a fraction of the full\nparameter set without incurring an accuracy penalty. To do this, our algorithm\nconstrains the total number of weights updated during backpropagation to those\nwith the highest total gradients. The remaining weights are not tracked, and\ntheir initial value is regenerated at every access to avoid storing them in\nmemory. This can dramatically reduce the number of off-chip memory accesses\nduring both training and inference, a key component of the energy needs of DNN\naccelerators. By ensuring that the total weight diffusion remains close to that\nof baseline unpruned SGD, networks pruned using our technique are able to\nretain state-of-the-art accuracy across network architectures -- including\nnetworks previously identified as difficult to compress, such as Densenet and\nWRN. With ResNet18 on ImageNet, we observe an 11.7$\\times$ weight reduction\nwith no accuracy loss, and up to 24.4$\\times$ with a small accuracy impact. \n\n"}
{"id": "1806.07498", "contents": "Title: Defining Locality for Surrogates in Post-hoc Interpretablity Abstract: Local surrogate models, to approximate the local decision boundary of a\nblack-box classifier, constitute one approach to generate explanations for the\nrationale behind an individual prediction made by the back-box. This paper\nhighlights the importance of defining the right locality, the neighborhood on\nwhich a local surrogate is trained, in order to approximate accurately the\nlocal black-box decision boundary. Unfortunately, as shown in this paper, this\nissue is not only a parameter or sampling distribution challenge and has a\nmajor impact on the relevance and quality of the approximation of the local\nblack-box decision boundary and thus on the meaning and accuracy of the\ngenerated explanation. To overcome the identified problems, quantified with an\nadapted measure and procedure, we propose to generate surrogate-based\nexplanations for individual predictions based on a sampling centered on\nparticular place of the decision boundary, relevant for the prediction to be\nexplained, rather than on the prediction itself as it is classically done. We\nevaluate the novel approach compared to state-of-the-art methods and a\nstraightforward improvement thereof on four UCI datasets. \n\n"}
{"id": "1806.07703", "contents": "Title: Multi-View Multi-Graph Embedding for Brain Network Clustering Analysis Abstract: Network analysis of human brain connectivity is critically important for\nunderstanding brain function and disease states. Embedding a brain network as a\nwhole graph instance into a meaningful low-dimensional representation can be\nused to investigate disease mechanisms and inform therapeutic interventions.\nMoreover, by exploiting information from multiple neuroimaging modalities or\nviews, we are able to obtain an embedding that is more useful than the\nembedding learned from an individual view. Therefore, multi-view multi-graph\nembedding becomes a crucial task. Currently, only a few studies have been\ndevoted to this topic, and most of them focus on the vector-based strategy\nwhich will cause structural information contained in the original graphs lost.\nAs a novel attempt to tackle this problem, we propose Multi-view Multi-graph\nEmbedding (M2E) by stacking multi-graphs into multiple partially-symmetric\ntensors and using tensor techniques to simultaneously leverage the dependencies\nand correlations among multi-view and multi-graph brain networks. Extensive\nexperiments on real HIV and bipolar disorder brain network datasets demonstrate\nthe superior performance of M2E on clustering brain networks by leveraging the\nmulti-view multi-graph interactions. \n\n"}
{"id": "1806.07715", "contents": "Title: Method to Annotate Arrhythmias by Deep Network Abstract: This study targets to automatically annotate on arrhythmia by deep network.\nThe investigated types include sinus rhythm, asystole (Asys), supraventricular\ntachycardia (Tachy), ventricular flutter or fibrillation (VF/VFL), ventricular\ntachycardia (VT). Methods: 13s limb lead ECG chunks from MIT malignant\nventricular arrhythmia database (VFDB) and MIT normal sinus rhythm database\nwere partitioned into subsets for 5-fold cross validation. These signals were\nresampled to 200Hz, filtered to remove baseline wandering, projected to 2D gray\nspectrum and then fed into a deep network with brand-new structure. In this\nnetwork, a feature vector for a single time point was retrieved by residual\nlayers, from which latent representation was extracted by variational\nautoencoder (VAE). These front portions were trained to meet a certain\nthreshold in loss function, then fixed while training procedure switched to\nremaining bidirectional recurrent neural network (RNN), the very portions to\npredict an arrhythmia category. Attention windows were polynomial lumped on RNN\noutputs for learning from details to outlines. And over sampling was employed\nfor imbalanced data. The trained model was wrapped into docker image for\ndeployment in edge or cloud. Conclusion: Promising sensitivities were achieved\nin four arrhythmias and good precision rates in two ventricular arrhythmias\nwere also observed. Moreover, it was proven that latent representation by VAE,\ncan significantly boost the speed of convergence and accuracy. \n\n"}
{"id": "1806.07963", "contents": "Title: Latent heterogeneous multilayer community detection Abstract: We propose a method for simultaneously detecting shared and unshared\ncommunities in heterogeneous multilayer weighted and undirected networks. The\nmultilayer network is assumed to follow a generative probabilistic model that\ntakes into account the similarities and dissimilarities between the\ncommunities. We make use of a variational Bayes approach for jointly inferring\nthe shared and unshared hidden communities from multilayer network\nobservations. We show that our approach outperforms state-of-the-art algorithms\nin detecting disparate (shared and private) communities on synthetic data as\nwell as on real genome-wide fibroblast proliferation dataset. \n\n"}
{"id": "1806.08941", "contents": "Title: A Recursive PLS (Partial Least Squares) based Approach for Enterprise\n  Threat Management Abstract: Most of the existing solutions to enterprise threat management are preventive\napproaches prescribing means to prevent policy violations with varying degrees\nof success. In this paper we consider the complementary scenario where a number\nof security violations have already occurred, or security threats, or\nvulnerabilities have been reported and a security administrator needs to\ngenerate optimal response to these security events. We present a principled\napproach to study and model the human expertise in responding to the emergent\nthreats owing to these security events. A recursive Partial Least Squares based\nadaptive learning model is defined using a factorial analysis of the security\nevents together with a method for estimating the effect of global context\ndependent semantic information used by the security administrators. Presented\nmodel is theoretically optimal and operationally recursive in nature to deal\nwith the set of security events being generated continuously. We discuss the\nunderlying challenges and ways in which the model could be operationalized in\ncentralized versus decentralized, and real-time versus batch processing modes. \n\n"}
{"id": "1806.09444", "contents": "Title: A Transferable Pedestrian Motion Prediction Model for Intersections with\n  Different Geometries Abstract: This paper presents a novel framework for accurate pedestrian intent\nprediction at intersections. Given some prior knowledge of the curbside\ngeometry, the presented framework can accurately predict pedestrian\ntrajectories, even in new intersections that it has not been trained on. This\nis achieved by making use of the contravariant components of trajectories in\nthe curbside coordinate system, which ensures that the transformation of\ntrajectories across intersections is affine, regardless of the curbside\ngeometry. Our method is based on the Augmented Semi Nonnegative Sparse Coding\n(ASNSC) formulation and we use that as a baseline to show improvement in\nprediction performance on real pedestrian datasets collected at two\nintersections in Cambridge, with distinctly different curbside and crosswalk\ngeometries. We demonstrate a 7.2% improvement in prediction accuracy in the\ncase of same train and test intersections. Furthermore, we show a comparable\nprediction performance of TASNSC when trained and tested in different\nintersections with the baseline, trained and tested on the same intersection. \n\n"}
{"id": "1806.09710", "contents": "Title: Why Interpretability in Machine Learning? An Answer Using Distributed\n  Detection and Data Fusion Theory Abstract: As artificial intelligence is increasingly affecting all parts of society and\nlife, there is growing recognition that human interpretability of machine\nlearning models is important. It is often argued that accuracy or other similar\ngeneralization performance metrics must be sacrificed in order to gain\ninterpretability. Such arguments, however, fail to acknowledge that the overall\ndecision-making system is composed of two entities: the learned model and a\nhuman who fuses together model outputs with his or her own information. As\nsuch, the relevant performance criteria should be for the entire system, not\njust for the machine learning component. In this work, we characterize the\nperformance of such two-node tandem data fusion systems using the theory of\ndistributed detection. In doing so, we work in the population setting and model\ninterpretable learned models as multi-level quantizers. We prove that under our\nabstraction, the overall system of a human with an interpretable classifier\noutperforms one with a black box classifier. \n\n"}
{"id": "1806.09737", "contents": "Title: A Multi-View Ensemble Classification Model for Clinically Actionable\n  Genetic Mutations Abstract: This paper presents details of our winning solutions to the task IV of NIPS\n2017 Competition Track entitled Classifying Clinically Actionable Genetic\nMutations. The machine learning task aims to classify genetic mutations based\non text evidence from clinical literature with promising performance. We\ndevelop a novel multi-view machine learning framework with ensemble\nclassification models to solve the problem. During the Challenge, feature\ncombinations derived from three views including document view, entity text\nview, and entity name view, which complements each other, are comprehensively\nexplored. As the final solution, we submitted an ensemble of nine basic\ngradient boosting models which shows the best performance in the evaluation.\nThe approach scores 0.5506 and 0.6694 in terms of logarithmic loss on a fixed\nsplit in stage-1 testing phase and 5-fold cross validation respectively, which\nalso makes us ranked as a top-1 team out of more than 1,300 solutions in NIPS\n2017 Competition Track IV. \n\n"}
{"id": "1806.09777", "contents": "Title: On the Implicit Bias of Dropout Abstract: Algorithmic approaches endow deep learning systems with implicit bias that\nhelps them generalize even in over-parametrized settings. In this paper, we\nfocus on understanding such a bias induced in learning through dropout, a\npopular technique to avoid overfitting in deep learning. For single\nhidden-layer linear neural networks, we show that dropout tends to make the\nnorm of incoming/outgoing weight vectors of all the hidden nodes equal. In\naddition, we provide a complete characterization of the optimization landscape\ninduced by dropout. \n\n"}
{"id": "1806.09783", "contents": "Title: Understanding Dropout as an Optimization Trick Abstract: As one of standard approaches to train deep neural networks, dropout has been\napplied to regularize large models to avoid overfitting, and the improvement in\nperformance by dropout has been explained as avoiding co-adaptation between\nnodes. However, when correlations between nodes are compared after training the\nnetworks with or without dropout, one question arises if co-adaptation\navoidance explains the dropout effect completely. In this paper, we propose an\nadditional explanation of why dropout works and propose a new technique to\ndesign better activation functions. First, we show that dropout can be\nexplained as an optimization technique to push the input towards the saturation\narea of nonlinear activation function by accelerating gradient information\nflowing even in the saturation area in backpropagation. Based on this\nexplanation, we propose a new technique for activation functions, {\\em gradient\nacceleration in activation function (GAAF)}, that accelerates gradients to flow\neven in the saturation area. Then, input to the activation function can climb\nonto the saturation area which makes the network more robust because the model\nconverges on a flat region. Experiment results support our explanation of\ndropout and confirm that the proposed GAAF technique improves image\nclassification performance with expected properties. \n\n"}
{"id": "1806.09981", "contents": "Title: Dynamic Spectrum Matching with One-shot Learning Abstract: Convolutional neural networks (CNN) have been shown to provide a good\nsolution for classification problems that utilize data obtained from\nvibrational spectroscopy. Moreover, CNNs are capable of identification from\nnoisy spectra without the need for additional preprocessing. However, their\napplication in practical spectroscopy is limited due to two shortcomings. The\neffectiveness of the classification using CNNs drops rapidly when only a small\nnumber of spectra per substance are available for training (which is a typical\nsituation in real applications). Additionally, to accommodate new, previously\nunseen substance classes, the network must be retrained which is\ncomputationally intensive. Here we address these issues by reformulating a\nmulti-class classification problem with a large number of classes, but a small\nnumber of samples per class, to a binary classification problem with sufficient\ndata available for representation learning. Namely, we define the learning task\nas identifying pairs of inputs as belonging to the same or different classes.\nWe achieve this using a Siamese convolutional neural network. A novel sampling\nstrategy is proposed to address the imbalance problem in training the Siamese\nNetwork. The trained network can effectively classify samples of unseen\nsubstance classes using just a single reference sample (termed as one-shot\nlearning in the machine learning community). Our results demonstrate better\naccuracy than other practical systems to date, while allowing effortless\nupdates of the system's database with novel substance classes. \n\n"}
{"id": "1806.10019", "contents": "Title: Adversarial Active Exploration for Inverse Dynamics Model Learning Abstract: We present an adversarial active exploration for inverse dynamics model\nlearning, a simple yet effective learning scheme that incentivizes exploration\nin an environment without any human intervention. Our framework consists of a\ndeep reinforcement learning (DRL) agent and an inverse dynamics model\ncontesting with each other. The former collects training samples for the\nlatter, with an objective to maximize the error of the latter. The latter is\ntrained with samples collected by the former, and generates rewards for the\nformer when it fails to predict the actual action taken by the former. In such\na competitive setting, the DRL agent learns to generate samples that the\ninverse dynamics model fails to predict correctly, while the inverse dynamics\nmodel learns to adapt to the challenging samples. We further propose a reward\nstructure that ensures the DRL agent to collect only moderately hard samples\nbut not overly hard ones that prevent the inverse model from predicting\neffectively. We evaluate the effectiveness of our method on several robotic arm\nand hand manipulation tasks against multiple baseline models. Experimental\nresults show that our method is comparable to those directly trained with\nexpert demonstrations, and superior to the other baselines even without any\nhuman priors. \n\n"}
{"id": "1806.10909", "contents": "Title: ResNet with one-neuron hidden layers is a Universal Approximator Abstract: We demonstrate that a very deep ResNet with stacked modules with one neuron\nper hidden layer and ReLU activation functions can uniformly approximate any\nLebesgue integrable function in $d$ dimensions, i.e. $\\ell_1(\\mathbb{R}^d)$.\nBecause of the identity mapping inherent to ResNets, our network has\nalternating layers of dimension one and $d$. This stands in sharp contrast to\nfully connected networks, which are not universal approximators if their width\nis the input dimension $d$ [Lu et al, 2017; Hanin and Sellke, 2017]. Hence, our\nresult implies an increase in representational power for narrow deep networks\nby the ResNet architecture. \n\n"}
{"id": "1806.11038", "contents": "Title: Neural Network Cognitive Engine for Autonomous and Distributed Underlay\n  Dynamic Spectrum Access Abstract: Two key challenges in underlay dynamic spectrum access (DSA) are how to\nestablish an interference limit from the primary network (PN) and how cognitive\nradios (CRs) in the secondary network (SN) become aware of the interference\nthey create on the PN, especially when there is no exchange of information\nbetween the two networks. These challenges are addressed in this paper by\npresenting a fully autonomous and distributed underlay DSA scheme where each CR\noperates based on predicting its transmission effect on the PN. The scheme is\nbased on a cognitive engine with an artificial neural network that predicts,\nwithout exchanging information between the networks, the adaptive modulation\nand coding configuration for the primary link nearest to a transmitting CR. By\nmanaging the effect of the SN on the PN, the presented technique maintains the\nrelative average throughput change in the PN within a prescribed maximum value,\nwhile also finding transmit settings for the CRs that result in throughput as\nlarge as allowed by the PN interference limit. Simulation results show that the\nability of the cognitive engine in estimating the effect of a CR transmission\non the full adaptive modulation and coding (AMC) mode leads to a much more fine\nunderlay transmit power control. This ability also provides higher transmission\nopportunities for the CRs, compared to a scheme that can only estimate the\nmodulation scheme used at the PN link. \n\n"}
{"id": "1807.00123", "contents": "Title: Machine Learning for Integrating Data in Biology and Medicine:\n  Principles, Practice, and Opportunities Abstract: New technologies have enabled the investigation of biology and human health\nat an unprecedented scale and in multiple dimensions. These dimensions include\na myriad of properties describing genome, epigenome, transcriptome, microbiome,\nphenotype, and lifestyle. No single data type, however, can capture the\ncomplexity of all the factors relevant to understanding a phenomenon such as a\ndisease. Integrative methods that combine data from multiple technologies have\nthus emerged as critical statistical and computational approaches. The key\nchallenge in developing such approaches is the identification of effective\nmodels to provide a comprehensive and relevant systems view. An ideal method\ncan answer a biological or medical question, identifying important features and\npredicting outcomes, by harnessing heterogeneous data across several dimensions\nof biological variation. In this Review, we describe the principles of data\nintegration and discuss current methods and available implementations. We\nprovide examples of successful data integration in biology and medicine.\nFinally, we discuss current challenges in biomedical integrative methods and\nour perspective on the future development of the field. \n\n"}
{"id": "1807.00126", "contents": "Title: A New Benchmark and Progress Toward Improved Weakly Supervised Learning Abstract: Knowledge Matters: Importance of Prior Information for Optimization [7], by\nGulcehre et. al., sought to establish the limits of current black-box, deep\nlearning techniques by posing problems which are difficult to learn without\nengineering knowledge into the model or training procedure. In our work, we\ncompletely solve the previous Knowledge Matters problem using a generic model,\npose a more difficult and scalable problem, All-Pairs, and advance this new\nproblem by introducing a new learned, spatially-varying histogram model called\nTypeNet which outperforms conventional models on the problem. We present\nresults on All-Pairs where our model achieves 100% test accuracy while the best\nResNet models achieve 79% accuracy. In addition, our model is more than an\norder of magnitude smaller than Resnet-34. The challenge of solving\nlarger-scale All-Pairs problems with high accuracy is presented to the\ncommunity for investigation. \n\n"}
{"id": "1807.00374", "contents": "Title: Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation Abstract: Training a model to perform a task typically requires a large amount of data\nfrom the domains in which the task will be applied. However, it is often the\ncase that data are abundant in some domains but scarce in others. Domain\nadaptation deals with the challenge of adapting a model trained from a\ndata-rich source domain to perform well in a data-poor target domain. In\ngeneral, this requires learning plausible mappings between domains. CycleGAN is\na powerful framework that efficiently learns to map inputs from one domain to\nanother using adversarial training and a cycle-consistency constraint. However,\nthe conventional approach of enforcing cycle-consistency via reconstruction may\nbe overly restrictive in cases where one or more domains have limited training\ndata. In this paper, we propose an augmented cyclic adversarial learning model\nthat enforces the cycle-consistency constraint via an external task specific\nmodel, which encourages the preservation of task-relevant content as opposed to\nexact reconstruction. We explore digit classification in a low-resource setting\nin supervised, semi and unsupervised situation, as well as high resource\nunsupervised. In low-resource supervised setting, the results show that our\napproach improves absolute performance by 14% and 4% when adapting SVHN to\nMNIST and vice versa, respectively, which outperforms unsupervised domain\nadaptation methods that require high-resource unlabeled target domain.\nMoreover, using only few unsupervised target data, our approach can still\noutperforms many high-resource unsupervised models. In speech domains, we\nsimilarly adopt a speech recognition model from each domain as the task\nspecific model. Our approach improves absolute performance of speech\nrecognition by 2% for female speakers in the TIMIT dataset, where the majority\nof training samples are from male voices. \n\n"}
{"id": "1807.00459", "contents": "Title: How To Backdoor Federated Learning Abstract: Federated learning enables thousands of participants to construct a deep\nlearning model without sharing their private training data with each other. For\nexample, multiple smartphones can jointly train a next-word predictor for\nkeyboards without revealing what individual users type. We demonstrate that any\nparticipant in federated learning can introduce hidden backdoor functionality\ninto the joint global model, e.g., to ensure that an image classifier assigns\nan attacker-chosen label to images with certain features, or that a word\npredictor completes certain sentences with an attacker-chosen word.\n  We design and evaluate a new model-poisoning methodology based on model\nreplacement. An attacker selected in a single round of federated learning can\ncause the global model to immediately reach 100% accuracy on the backdoor task.\nWe evaluate the attack under different assumptions for the standard\nfederated-learning tasks and show that it greatly outperforms data poisoning.\nOur generic constrain-and-scale technique also evades anomaly detection-based\ndefenses by incorporating the evasion into the attacker's loss function during\ntraining. \n\n"}
{"id": "1807.00755", "contents": "Title: LeapsAndBounds: A Method for Approximately Optimal Algorithm\n  Configuration Abstract: We consider the problem of configuring general-purpose solvers to run\nefficiently on problem instances drawn from an unknown distribution. The goal\nof the configurator is to find a configuration that runs fast on average on\nmost instances, and do so with the least amount of total work. It can run a\nchosen solver on a random instance until the solver finishes or a timeout is\nreached. We propose LeapsAndBounds, an algorithm that tests configurations on\nrandomly selected problem instances for longer and longer time. We prove that\nthe capped expected runtime of the configuration returned by LeapsAndBounds is\nclose to the optimal expected runtime, while our algorithm's running time is\nnear-optimal. Our results show that LeapsAndBounds is more efficient than the\nrecent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the\nonly other algorithm configuration method with non-trivial theoretical\nguarantees. Experimental results on configuring a public SAT solver on a new\nbenchmark dataset also stand witness to the superiority of our method. \n\n"}
{"id": "1807.00867", "contents": "Title: Multi-User Multi-Armed Bandits for Uncoordinated Spectrum Access Abstract: A multi-user multi-armed bandit (MAB) framework is used to develop algorithms\nfor uncoordinated spectrum access. The number of users is assumed to be unknown\nto each user. A stochastic setting is first considered, where the rewards on a\nchannel are the same for each user. In contrast to prior work, it is assumed\nthat the number of users can possibly exceed the number of channels, and that\nrewards can be non-zero even under collisions. The proposed algorithm consists\nof an estimation phase and an allocation phase. It is shown that if every user\nadopts the algorithm, the system wide regret is constant with time with high\nprobability. The regret guarantees hold for any number of users and channels,\nin particular, even when the number of users is less than the number of\nchannels. Next, an adversarial multi-user MAB framework is considered, where\nthe rewards on the channels are user-dependent. It is assumed that the number\nof users is less than the number of channels, and that the users receive zero\nreward on collision. The proposed algorithm combines the Exp3.P algorithm\ndeveloped in prior work for single user adversarial bandits with a collision\nresolution mechanism to achieve sub-linear regret. It is shown that if every\nuser employs the proposed algorithm, the system wide regret is of the order\n$O(T^\\frac{3}{4})$ over a horizon of time $T$. The algorithms in both\nstochastic and adversarial scenarios are extended to the dynamic case where the\nnumber of users in the system evolves over time and are shown to lead to\nsub-linear regret. \n\n"}
{"id": "1807.00906", "contents": "Title: Uncertainty in the Variational Information Bottleneck Abstract: We present a simple case study, demonstrating that Variational Information\nBottleneck (VIB) can improve a network's classification calibration as well as\nits ability to detect out-of-distribution data. Without explicitly being\ndesigned to do so, VIB gives two natural metrics for handling and quantifying\nuncertainty. \n\n"}
{"id": "1807.01251", "contents": "Title: Training behavior of deep neural network in frequency domain Abstract: Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization. \n\n"}
{"id": "1807.01675", "contents": "Title: Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value\n  Expansion Abstract: Integrating model-free and model-based approaches in reinforcement learning\nhas the potential to achieve the high performance of model-free algorithms with\nlow sample complexity. However, this is difficult because an imperfect dynamics\nmodel can degrade the performance of the learning algorithm, and in\nsufficiently complex environments, the dynamics model will almost always be\nimperfect. As a result, a key challenge is to combine model-based approaches\nwith model-free learning in such a way that errors in the model do not degrade\nperformance. We propose stochastic ensemble value expansion (STEVE), a novel\nmodel-based technique that addresses this issue. By dynamically interpolating\nbetween model rollouts of various horizon lengths for each individual example,\nSTEVE ensures that the model is only utilized when doing so does not introduce\nsignificant errors. Our approach outperforms model-free baselines on\nchallenging continuous control benchmarks with an order-of-magnitude increase\nin sample efficiency, and in contrast to previous model-based approaches,\nperformance does not degrade in complex environments. \n\n"}
{"id": "1807.02373", "contents": "Title: Near Optimal Exploration-Exploitation in Non-Communicating Markov\n  Decision Processes Abstract: While designing the state space of an MDP, it is common to include states\nthat are transient or not reachable by any policy (e.g., in mountain car, the\nproduct space of speed and position contains configurations that are not\nphysically reachable). This leads to defining weakly-communicating or\nmulti-chain MDPs. In this paper, we introduce \\tucrl, the first algorithm able\nto perform efficient exploration-exploitation in any finite Markov Decision\nProcess (MDP) without requiring any form of prior knowledge. In particular, for\nany MDP with $S^{\\texttt{C}}$ communicating states, $A$ actions and\n$\\Gamma^{\\texttt{C}} \\leq S^{\\texttt{C}}$ possible communicating next states,\nwe derive a $\\widetilde{O}(D^{\\texttt{C}} \\sqrt{\\Gamma^{\\texttt{C}}\nS^{\\texttt{C}} AT})$ regret bound, where $D^{\\texttt{C}}$ is the diameter\n(i.e., the longest shortest path) of the communicating part of the MDP. This is\nin contrast with optimistic algorithms (e.g., UCRL, Optimistic PSRL) that\nsuffer linear regret in weakly-communicating MDPs, as well as posterior\nsampling or regularised algorithms (e.g., REGAL), which require prior knowledge\non the bias span of the optimal policy to bias the exploration to achieve\nsub-linear regret. We also prove that in weakly-communicating MDPs, no\nalgorithm can ever achieve a logarithmic growth of the regret without first\nsuffering a linear regret for a number of steps that is exponential in the\nparameters of the MDP. Finally, we report numerical simulations supporting our\ntheoretical findings and showing how TUCRL overcomes the limitations of the\nstate-of-the-art. \n\n"}
{"id": "1807.02567", "contents": "Title: Deep Learning for Launching and Mitigating Wireless Jamming Attacks Abstract: An adversarial machine learning approach is introduced to launch jamming\nattacks on wireless communications and a defense strategy is presented. A\ncognitive transmitter uses a pre-trained classifier to predict the current\nchannel status based on recent sensing results and decides whether to transmit\nor not, whereas a jammer collects channel status and ACKs to build a deep\nlearning classifier that reliably predicts the next successful transmissions\nand effectively jams them. This jamming approach is shown to reduce the\ntransmitter's performance much more severely compared with random or\nsensing-based jamming. The deep learning classification scores are used by the\njammer for power control subject to an average power constraint. Next, a\ngenerative adversarial network (GAN) is developed for the jammer to reduce the\ntime to collect the training dataset by augmenting it with synthetic samples.\nAs a defense scheme, the transmitter deliberately takes a small number of wrong\nactions in spectrum access (in form of a causative attack against the jammer)\nand therefore prevents the jammer from building a reliable classifier. The\ntransmitter systematically selects when to take wrong actions and adapts the\nlevel of defense to mislead the jammer into making prediction errors and\nconsequently increase its throughput. \n\n"}
{"id": "1807.02787", "contents": "Title: Financial Trading as a Game: A Deep Reinforcement Learning Approach Abstract: An automatic program that generates constant profit from the financial market\nis lucrative for every market practitioner. Recent advance in deep\nreinforcement learning provides a framework toward end-to-end training of such\ntrading agent. In this paper, we propose an Markov Decision Process (MDP) model\nsuitable for the financial trading task and solve it with the state-of-the-art\ndeep recurrent Q-network (DRQN) algorithm. We propose several modifications to\nthe existing learning algorithm to make it more suitable under the financial\ntrading setting, namely 1. We employ a substantially small replay memory (only\na few hundreds in size) compared to ones used in modern deep reinforcement\nlearning algorithms (often millions in size.) 2. We develop an action\naugmentation technique to mitigate the need for random exploration by providing\nextra feedback signals for all actions to the agent. This enables us to use\ngreedy policy over the course of learning and shows strong empirical\nperformance compared to more commonly used epsilon-greedy exploration. However,\nthis technique is specific to financial trading under a few market assumptions.\n3. We sample a longer sequence for recurrent neural network training. A side\nproduct of this mechanism is that we can now train the agent for every T steps.\nThis greatly reduces training time since the overall computation is down by a\nfactor of T. We combine all of the above into a complete online learning\nalgorithm and validate our approach on the spot foreign exchange market. \n\n"}
{"id": "1807.02839", "contents": "Title: Hierarchical stochastic graphlet embedding for graph-based pattern\n  recognition Abstract: Despite being very successful within the pattern recognition and machine\nlearning community, graph-based methods are often unusable because of the lack\nof mathematical operations defined in graph domain. Graph embedding, which maps\ngraphs to a vectorial space, has been proposed as a way to tackle these\ndifficulties enabling the use of standard machine learning techniques. However,\nit is well known that graph embedding functions usually suffer from the loss of\nstructural information. In this paper, we consider the hierarchical structure\nof a graph as a way to mitigate this loss of information. The hierarchical\nstructure is constructed by topologically clustering the graph nodes, and\nconsidering each cluster as a node in the upper hierarchical level. Once this\nhierarchical structure is constructed, we consider several configurations to\ndefine the mapping into a vector space given a classical graph embedding, in\nparticular, we propose to make use of the Stochastic Graphlet Embedding (SGE).\nBroadly speaking, SGE produces a distribution of uniformly sampled low to high\norder graphlets as a way to embed graphs into the vector space. In what\nfollows, the coarse-to-fine structure of a graph hierarchy and the statistics\nfetched by the SGE complements each other and includes important structural\ninformation with varied contexts. Altogether, these two techniques\nsubstantially cope with the usual information loss involved in graph embedding\ntechniques, obtaining a more robust graph representation. This fact has been\ncorroborated through a detailed experimental evaluation on various benchmark\ngraph datasets, where we outperform the state-of-the-art methods. \n\n"}
{"id": "1807.02872", "contents": "Title: Large Margin Few-Shot Learning Abstract: The key issue of few-shot learning is learning to generalize. This paper\nproposes a large margin principle to improve the generalization capacity of\nmetric based methods for few-shot learning. To realize it, we develop a unified\nframework to learn a more discriminative metric space by augmenting the\nclassification loss function with a large margin distance loss function for\ntraining. Extensive experiments on two state-of-the-art few-shot learning\nmethods, graph neural networks and prototypical networks, show that our method\ncan improve the performance of existing models substantially with very little\ncomputational overhead, demonstrating the effectiveness of the large margin\nprinciple and the potential of our method. \n\n"}
{"id": "1807.03326", "contents": "Title: Adaptive Adversarial Attack on Scene Text Recognition Abstract: Recent studies have shown that state-of-the-art deep learning models are\nvulnerable to the inputs with small perturbations (adversarial examples). We\nobserve two critical obstacles in adversarial examples: (i) Strong adversarial\nattacks (e.g., C&W attack) require manually tuning hyper-parameters and take a\nlong time to construct an adversarial example, making it impractical to attack\nreal-time systems; (ii) Most of the studies focus on non-sequential tasks, such\nas image classification, yet only a few consider sequential tasks. In this\nwork, we speed up adversarial attacks, especially on sequential learning tasks.\nBy leveraging the uncertainty of each task, we directly learn the adaptive\nmulti-task weightings, without manually searching hyper-parameters. A unified\narchitecture is developed and evaluated for both non-sequential tasks and\nsequential ones. To validate the effectiveness, we take the scene text\nrecognition task as a case study. To our best knowledge, our proposed method is\nthe first attempt to adversarial attack for scene text recognition. Adaptive\nAttack achieves over 99.9\\% success rate with 3-6X speedup compared to\nstate-of-the-art adversarial attacks. \n\n"}
{"id": "1807.03708", "contents": "Title: Deterministic Policy Gradients With General State Transitions Abstract: We study a reinforcement learning setting, where the state transition\nfunction is a convex combination of a stochastic continuous function and a\ndeterministic function. Such a setting generalizes the widely-studied\nstochastic state transition setting, namely the setting of deterministic policy\ngradient (DPG).\n  We firstly give a simple example to illustrate that the deterministic policy\ngradient may be infinite under deterministic state transitions, and introduce a\ntheoretical technique to prove the existence of the policy gradient in this\ngeneralized setting. Using this technique, we prove that the deterministic\npolicy gradient indeed exists for a certain set of discount factors, and\nfurther prove two conditions that guarantee the existence for all discount\nfactors. We then derive a closed form of the policy gradient whenever exists.\nFurthermore, to overcome the challenge of high sample complexity of DPG in this\nsetting, we propose the Generalized Deterministic Policy Gradient (GDPG)\nalgorithm. The main innovation of the algorithm is a new method of applying\nmodel-based techniques to the model-free algorithm, the deep deterministic\npolicy gradient algorithm (DDPG). GDPG optimize the long-term rewards of the\nmodel-based augmented MDP subject to a constraint that the long-rewards of the\nMDP is less than the original one.\n  We finally conduct extensive experiments comparing GDPG with state-of-the-art\nmethods and the direct model-based extension method of DDPG on several standard\ncontinuous control benchmarks. Results demonstrate that GDPG substantially\noutperforms DDPG, the model-based extension of DDPG and other baselines in\nterms of both convergence and long-term rewards in most environments. \n\n"}
{"id": "1807.03748", "contents": "Title: Representation Learning with Contrastive Predictive Coding Abstract: While supervised learning has enabled great progress in many applications,\nunsupervised learning has not seen such widespread adoption, and remains an\nimportant and challenging endeavor for artificial intelligence. In this work,\nwe propose a universal unsupervised learning approach to extract useful\nrepresentations from high-dimensional data, which we call Contrastive\nPredictive Coding. The key insight of our model is to learn such\nrepresentations by predicting the future in latent space by using powerful\nautoregressive models. We use a probabilistic contrastive loss which induces\nthe latent space to capture information that is maximally useful to predict\nfuture samples. It also makes the model tractable by using negative sampling.\nWhile most prior work has focused on evaluating representations for a\nparticular modality, we demonstrate that our approach is able to learn useful\nrepresentations achieving strong performance on four distinct domains: speech,\nimages, text and reinforcement learning in 3D environments. \n\n"}
{"id": "1807.03858", "contents": "Title: Algorithmic Framework for Model-based Deep Reinforcement Learning with\n  Theoretical Guarantees Abstract: Model-based reinforcement learning (RL) is considered to be a promising\napproach to reduce the sample complexity that hinders model-free RL. However,\nthe theoretical understanding of such methods has been rather limited. This\npaper introduces a novel algorithmic framework for designing and analyzing\nmodel-based RL algorithms with theoretical guarantees. We design a\nmeta-algorithm with a theoretical guarantee of monotone improvement to a local\nmaximum of the expected reward. The meta-algorithm iteratively builds a lower\nbound of the expected reward based on the estimated dynamical model and sample\ntrajectories, and then maximizes the lower bound jointly over the policy and\nthe model. The framework extends the optimism-in-face-of-uncertainty principle\nto non-linear dynamical models in a way that requires \\textit{no explicit}\nuncertainty quantification. Instantiating our framework with simplification\ngives a variant of model-based RL algorithms Stochastic Lower Bounds\nOptimization (SLBO). Experiments demonstrate that SLBO achieves\nstate-of-the-art performance when only one million or fewer samples are\npermitted on a range of continuous control benchmark tasks. \n\n"}
{"id": "1807.04065", "contents": "Title: Recurrent Neural Networks with Flexible Gates using Kernel Activation\n  Functions Abstract: Gated recurrent neural networks have achieved remarkable results in the\nanalysis of sequential data. Inside these networks, gates are used to control\nthe flow of information, allowing to model even very long-term dependencies in\nthe data. In this paper, we investigate whether the original gate equation (a\nlinear projection followed by an element-wise sigmoid) can be improved. In\nparticular, we design a more flexible architecture, with a small number of\nadaptable parameters, which is able to model a wider range of gating functions\nthan the classical one. To this end, we replace the sigmoid function in the\nstandard gate with a non-parametric formulation extending the recently proposed\nkernel activation function (KAF), with the addition of a residual\nskip-connection. A set of experiments on sequential variants of the MNIST\ndataset shows that the adoption of this novel gate allows to improve accuracy\nwith a negligible cost in terms of computational power and with a large\nspeed-up in the number of training iterations. \n\n"}
{"id": "1807.04778", "contents": "Title: Improving on Q & A Recurrent Neural Networks Using Noun-Tagging Abstract: Often, more time is spent on finding a model that works well, rather than\ntuning the model and working directly with the dataset. Our research began as\nan attempt to improve upon a simple Recurrent Neural Network for answering\n\"simple\" first-order questions (QA-RNN), developed by Ferhan Ture and Oliver\nJojic, from Comcast Labs, using the SimpleQuestions dataset. Their baseline\nmodel, a bidirectional, 2-layer LSTM RNN and a GRU RNN, have accuracies of 0.94\nand 0.90, for entity detection and relation prediction, respectively. We fine\ntuned these models by doing substantial hyper-parameter tuning, getting\nresulting accuracies of 0.70 and 0.80, for entity detection and relation\nprediction, respectively. An accuracy of 0.984 was obtained on entity detection\nusing a 1-layer LSTM, where preprocessing was done by removing all words not\npart of a noun chunk from the question. 100% of the dataset was available for\nrelation prediction, but only 20% of the dataset, was available for entity\ndetection, which we believe to be much of the reason for our initial\ndifficulties in replicating their result, despite the fact we were able to\nimprove on their entity detection results. \n\n"}
{"id": "1807.05185", "contents": "Title: Model Reconstruction from Model Explanations Abstract: We show through theory and experiment that gradient-based explanations of a\nmodel quickly reveal the model itself. Our results speak to a tension between\nthe desire to keep a proprietary model secret and the ability to offer model\nexplanations. On the theoretical side, we give an algorithm that provably\nlearns a two-layer ReLU network in a setting where the algorithm may query the\ngradient of the model with respect to chosen inputs. The number of queries is\nindependent of the dimension and nearly optimal in its dependence on the model\nsize. Of interest not only from a learning-theoretic perspective, this result\nhighlights the power of gradients rather than labels as a learning primitive.\nComplementing our theory, we give effective heuristics for reconstructing\nmodels from gradient explanations that are orders of magnitude more\nquery-efficient than reconstruction attacks relying on prediction interfaces. \n\n"}
{"id": "1807.05464", "contents": "Title: Tractable Querying and Learning in Hybrid Domains via Sum-Product\n  Networks Abstract: Probabilistic representations, such as Bayesian and Markov networks, are\nfundamental to much of statistical machine learning. Thus, learning\nprobabilistic representations directly from data is a deep challenge, the main\ncomputational bottleneck being inference that is intractable. Tractable\nlearning is a powerful new paradigm that attempts to learn distributions that\nsupport efficient probabilistic querying. By leveraging local structure,\nrepresentations such as sum-product networks (SPNs) can capture high tree-width\nmodels with many hidden layers, essentially a deep architecture, while still\nadmitting a range of probabilistic queries to be computable in time polynomial\nin the network size. The leaf nodes in SPNs, from which more intricate mixtures\nare formed, are tractable univariate distributions, and so the literature has\nfocused on Bernoulli and Gaussian random variables. This is clearly a\nrestriction for handling mixed discrete-continuous data, especially if the\ncontinuous features are generated from non-parametric and non-Gaussian\ndistribution families. In this work, we present a framework that systematically\nintegrates SPN structure learning with weighted model integration, a recently\nintroduced computational abstraction for performing inference in hybrid\ndomains, by means of piecewise polynomial approximations of density functions\nof arbitrary shape. Our framework is instantiated by exploiting the notion of\npropositional abstractions, thus minimally interfering with the SPN structure\nlearning module, and supports a powerful query interface for conditioning on\ninterval constraints. Our empirical results show that our approach is\neffective, and allows a study of the trade off between the granularity of the\nlearned model and its predictive power. \n\n"}
{"id": "1807.05827", "contents": "Title: Remember and Forget for Experience Replay Abstract: Experience replay (ER) is a fundamental component of off-policy deep\nreinforcement learning (RL). ER recalls experiences from past iterations to\ncompute gradient estimates for the current policy, increasing data-efficiency.\nHowever, the accuracy of such updates may deteriorate when the policy diverges\nfrom past behaviors and can undermine the performance of ER. Many algorithms\nmitigate this issue by tuning hyper-parameters to slow down policy changes. An\nalternative is to actively enforce the similarity between policy and the\nexperiences in the replay memory. We introduce Remember and Forget Experience\nReplay (ReF-ER), a novel method that can enhance RL algorithms with\nparameterized policies. ReF-ER (1) skips gradients computed from experiences\nthat are too unlikely with the current policy and (2) regulates policy changes\nwithin a trust region of the replayed behaviors. We couple ReF-ER with\nQ-learning, deterministic policy gradient and off-policy gradient methods. We\nfind that ReF-ER consistently improves the performance of continuous-action,\noff-policy RL on fully observable benchmarks and partially observable flow\ncontrol problems. \n\n"}
{"id": "1807.05924", "contents": "Title: Bipedal Walking Robot using Deep Deterministic Policy Gradient Abstract: Machine learning algorithms have found several applications in the field of\nrobotics and control systems. The control systems community has started to show\ninterest towards several machine learning algorithms from the sub-domains such\nas supervised learning, imitation learning and reinforcement learning to\nachieve autonomous control and intelligent decision making. Amongst many\ncomplex control problems, stable bipedal walking has been the most challenging\nproblem. In this paper, we present an architecture to design and simulate a\nplanar bipedal walking robot(BWR) using a realistic robotics simulator, Gazebo.\nThe robot demonstrates successful walking behaviour by learning through several\nof its trial and errors, without any prior knowledge of itself or the world\ndynamics. The autonomous walking of the BWR is achieved using reinforcement\nlearning algorithm called Deep Deterministic Policy Gradient(DDPG). DDPG is one\nof the algorithms for learning controls in continuous action spaces. After\ntraining the model in simulation, it was observed that, with a proper shaped\nreward function, the robot achieved faster walking or even rendered a running\ngait with an average speed of 0.83 m/s. The gait pattern of the bipedal walker\nwas compared with the actual human walking pattern. The results show that the\nbipedal walking pattern had similar characteristics to that of a human walking\npattern. The video presenting our experiment is available at\nhttps://goo.gl/NHXKqR. \n\n"}
{"id": "1807.06101", "contents": "Title: A PTAS for $\\ell_p$-Low Rank Approximation Abstract: A number of recent works have studied algorithms for entrywise $\\ell_p$-low\nrank approximation, namely, algorithms which given an $n \\times d$ matrix $A$\n(with $n \\geq d$), output a rank-$k$ matrix $B$ minimizing\n$\\|A-B\\|_p^p=\\sum_{i,j}|A_{i,j}-B_{i,j}|^p$ when $p > 0$; and\n$\\|A-B\\|_0=\\sum_{i,j}[A_{i,j}\\neq B_{i,j}]$ for $p=0$.\n  On the algorithmic side, for $p \\in (0,2)$, we give the first\n$(1+\\epsilon)$-approximation algorithm running in time\n$n^{\\text{poly}(k/\\epsilon)}$. Further, for $p = 0$, we give the first\nalmost-linear time approximation scheme for what we call the Generalized Binary\n$\\ell_0$-Rank-$k$ problem. Our algorithm computes $(1+\\epsilon)$-approximation\nin time $(1/\\epsilon)^{2^{O(k)}/\\epsilon^{2}} \\cdot nd^{1+o(1)}$.\n  On the hardness of approximation side, for $p \\in (1,2)$, assuming the Small\nSet Expansion Hypothesis and the Exponential Time Hypothesis (ETH), we show\nthat there exists $\\delta := \\delta(\\alpha) > 0$ such that the entrywise\n$\\ell_p$-Rank-$k$ problem has no $\\alpha$-approximation algorithm running in\ntime $2^{k^{\\delta}}$. \n\n"}
{"id": "1807.06473", "contents": "Title: Contextual Memory Trees Abstract: We design and study a Contextual Memory Tree (CMT), a learning memory\ncontroller that inserts new memories into an experience store of unbounded\nsize. It is designed to efficiently query for memories from that store,\nsupporting logarithmic time insertion and retrieval operations. Hence CMT can\nbe integrated into existing statistical learning algorithms as an augmented\nmemory unit without substantially increasing training and inference\ncomputation. Furthermore CMT operates as a reduction to classification,\nallowing it to benefit from advances in representation or architecture. We\ndemonstrate the efficacy of CMT by augmenting existing multi-class and\nmulti-label classification algorithms with CMT and observe statistical\nimprovement. We also test CMT learning on several image-captioning tasks to\ndemonstrate that it performs computationally better than a simple nearest\nneighbors memory system while benefitting from reward learning. \n\n"}
{"id": "1807.06756", "contents": "Title: SySeVR: A Framework for Using Deep Learning to Detect Software\n  Vulnerabilities Abstract: The detection of software vulnerabilities (or vulnerabilities for short) is\nan important problem that has yet to be tackled, as manifested by the many\nvulnerabilities reported on a daily basis. This calls for machine learning\nmethods for vulnerability detection. Deep learning is attractive for this\npurpose because it alleviates the requirement to manually define features.\nDespite the tremendous success of deep learning in other application domains,\nits applicability to vulnerability detection is not systematically understood.\nIn order to fill this void, we propose the first systematic framework for using\ndeep learning to detect vulnerabilities in C/C++ programs with source code. The\nframework, dubbed Syntax-based, Semantics-based, and Vector Representations\n(SySeVR), focuses on obtaining program representations that can accommodate\nsyntax and semantic information pertinent to vulnerabilities. Our experiments\nwith 4 software products demonstrate the usefulness of the framework: we detect\n15 vulnerabilities that are not reported in the National Vulnerability\nDatabase. Among these 15 vulnerabilities, 7 are unknown and have been reported\nto the vendors, and the other 8 have been \"silently\" patched by the vendors\nwhen releasing newer versions of the pertinent software products. \n\n"}
{"id": "1807.07506", "contents": "Title: Improving Simple Models with Confidence Profiles Abstract: In this paper, we propose a new method called ProfWeight for transferring\ninformation from a pre-trained deep neural network that has a high test\naccuracy to a simpler interpretable model or a very shallow network of low\ncomplexity and a priori low test accuracy. We are motivated by applications in\ninterpretability and model deployment in severely memory constrained\nenvironments (like sensors). Our method uses linear probes to generate\nconfidence scores through flattened intermediate representations. Our transfer\nmethod involves a theoretically justified weighting of samples during the\ntraining of the simple model using confidence scores of these intermediate\nlayers. The value of our method is first demonstrated on CIFAR-10, where our\nweighting method significantly improves (3-4%) networks with only a fraction of\nthe number of Resnet blocks of a complex Resnet model. We further demonstrate\noperationally significant results on a real manufacturing problem, where we\ndramatically increase the test accuracy of a CART model (the domain standard)\nby roughly 13%. \n\n"}
{"id": "1807.08241", "contents": "Title: NAVREN-RL: Learning to fly in real environment via end-to-end deep\n  reinforcement learning using monocular images Abstract: We present NAVREN-RL, an approach to NAVigate an unmanned aerial vehicle in\nan indoor Real ENvironment via end-to-end reinforcement learning RL. A suitable\nreward function is designed keeping in mind the cost and weight constraints for\nmicro drone with minimum number of sensing modalities. Collection of small\nnumber of expert data and knowledge based data aggregation is integrated into\nthe RL process to aid convergence. Experimentation is carried out on a Parrot\nAR drone in different indoor arenas and the results are compared with other\nbaseline technologies. We demonstrate how the drone successfully avoids\nobstacles and navigates across different arenas. \n\n"}
{"id": "1807.08518", "contents": "Title: Implementing Neural Turing Machines Abstract: Neural Turing Machines (NTMs) are an instance of Memory Augmented Neural\nNetworks, a new class of recurrent neural networks which decouple computation\nfrom memory by introducing an external memory unit. NTMs have demonstrated\nsuperior performance over Long Short-Term Memory Cells in several sequence\nlearning tasks. A number of open source implementations of NTMs exist but are\nunstable during training and/or fail to replicate the reported performance of\nNTMs. This paper presents the details of our successful implementation of a\nNTM. Our implementation learns to solve three sequential learning tasks from\nthe original NTM paper. We find that the choice of memory contents\ninitialization scheme is crucial in successfully implementing a NTM. Networks\nwith memory contents initialized to small constant values converge on average 2\ntimes faster than the next best memory contents initialization scheme. \n\n"}
{"id": "1807.09142", "contents": "Title: Recurrent Neural Networks for Long and Short-Term Sequential\n  Recommendation Abstract: Recommender systems objectives can be broadly characterized as modeling user\npreferences over short-or long-term time horizon. A large body of previous\nresearch studied long-term recommendation through dimensionality reduction\ntechniques applied to the historical user-item interactions. A recently\nintroduced session-based recommendation setting highlighted the importance of\nmodeling short-term user preferences. In this task, Recurrent Neural Networks\n(RNN) have shown to be successful at capturing the nuances of user's\ninteractions within a short time window. In this paper, we evaluate RNN-based\nmodels on both short-term and long-term recommendation tasks. Our experimental\nresults suggest that RNNs are capable of predicting immediate as well as\ndistant user interactions. We also find the best performing configuration to be\na stacked RNN with layer normalization and tied item embeddings. \n\n"}
{"id": "1807.09586", "contents": "Title: Perturb and Combine to Identify Influential Spreaders in Real-World\n  Networks Abstract: Some of the most effective influential spreader detection algorithms are\nunstable to small perturbations of the network structure. Inspired by bagging\nin Machine Learning, we propose the first Perturb and Combine (P&C) procedure\nfor networks. It (1) creates many perturbed versions of a given graph, (2)\napplies a node scoring function separately to each graph, and (3) combines the\nresults. Experiments conducted on real-world networks of various sizes with the\nk-core, generalized k-core, and PageRank algorithms reveal that P&C brings\nsubstantial improvements. Moreover, this performance boost can be obtained at\nalmost no extra cost through parallelization. Finally, a bias-variance analysis\nsuggests that P&C works mainly by reducing bias, and that therefore, it should\nbe capable of improving the performance of all vertex scoring functions,\nincluding stable ones. \n\n"}
{"id": "1807.09912", "contents": "Title: Meta-learning autoencoders for few-shot prediction Abstract: Compared to humans, machine learning models generally require significantly\nmore training examples and fail to extrapolate from experience to solve\npreviously unseen challenges. To help close this performance gap, we augment\nsingle-task neural networks with a meta-recognition model which learns a\nsuccinct model code via its autoencoder structure, using just a few informative\nexamples. The model code is then employed by a meta-generative model to\nconstruct parameters for the task-specific model. We demonstrate that for\npreviously unseen tasks, without additional training, this Meta-Learning\nAutoencoder (MeLA) framework can build models that closely match the true\nunderlying models, with loss significantly lower than given by fine-tuned\nbaseline networks, and performance that compares favorably with\nstate-of-the-art meta-learning algorithms. MeLA also adds the ability to\nidentify influential training examples and predict which additional data will\nbe most valuable to acquire to improve model prediction. \n\n"}
{"id": "1807.10261", "contents": "Title: Novelty Detection Meets Collider Physics Abstract: Novelty detection is the machine learning task to recognize data, which\nbelong to an unknown pattern. Complementary to supervised learning, it allows\nto analyze data model-independently. We demonstrate the potential role of\nnovelty detection in collider physics, using autoencoder-based deep neural\nnetwork. Explicitly, we develop a set of density-based novelty evaluators,\nwhich are sensitive to the clustering of unknown-pattern testing data or\nnew-physics signal events, for the design of detection algorithms. We also\nexplore the influence of the known-pattern data fluctuations, arising from\nnon-signal regions, on detection sensitivity. Strategies to address it are\nproposed. The algorithms are applied to detecting fermionic di-top partner and\nresonant di-top productions at LHC, and exotic Higgs decays of two specific\nmodes at a $e^+e^-$ future collider. With parton-level analysis, we conclude\nthat potentially the new-physics benchmarks can be recognized with high\nefficiency. \n\n"}
{"id": "1807.10570", "contents": "Title: Embedded Implementation of a Deep Learning Smile Detector Abstract: In this paper we study the real time deployment of deep learning algorithms\nin low resource computational environments. As the use case, we compare the\naccuracy and speed of neural networks for smile detection using different\nneural network architectures and their system level implementation on NVidia\nJetson embedded platform. We also propose an asynchronous multithreading scheme\nfor parallelizing the pipeline. Within this framework, we experimentally\ncompare thirteen widely used network topologies. The experiments show that low\ncomplexity architectures can achieve almost equal performance as larger ones,\nwith a fraction of computation required. \n\n"}
{"id": "1807.10675", "contents": "Title: Resource-Size matters: Improving Neural Named Entity Recognition with\n  Optimized Large Corpora Abstract: This study improves the performance of neural named entity recognition by a\nmargin of up to 11% in F-score on the example of a low-resource language like\nGerman, thereby outperforming existing baselines and establishing a new\nstate-of-the-art on each single open-source dataset. Rather than designing\ndeeper and wider hybrid neural architectures, we gather all available resources\nand perform a detailed optimization and grammar-dependent morphological\nprocessing consisting of lemmatization and part-of-speech tagging prior to\nexposing the raw data to any training process. We test our approach in a\nthreefold monolingual experimental setup of a) single, b) joint, and c)\noptimized training and shed light on the dependency of downstream-tasks on the\nsize of corpora used to compute word embeddings. \n\n"}
{"id": "1807.11236", "contents": "Title: Semantic Labeling in Very High Resolution Images via a Self-Cascaded\n  Convolutional Neural Network Abstract: Semantic labeling for very high resolution (VHR) images in urban areas, is of\nsignificant importance in a wide range of remote sensing applications. However,\nmany confusing manmade objects and intricate fine-structured objects make it\nvery difficult to obtain both coherent and accurate labeling results. For this\nchallenging task, we propose a novel deep model with convolutional neural\nnetworks (CNNs), i.e., an end-to-end self-cascaded network (ScasNet).\nSpecifically, for confusing manmade objects, ScasNet improves the labeling\ncoherence with sequential global-to-local contexts aggregation. Technically,\nmulti-scale contexts are captured on the output of a CNN encoder, and then they\nare successively aggregated in a self-cascaded manner. Meanwhile, for\nfine-structured objects, ScasNet boosts the labeling accuracy with a\ncoarse-to-fine refinement strategy. It progressively refines the target objects\nusing the low-level features learned by CNN's shallow layers. In addition, to\ncorrect the latent fitting residual caused by multi-feature fusion inside\nScasNet, a dedicated residual correction scheme is proposed. It greatly\nimproves the effectiveness of ScasNet. Extensive experimental results on three\npublic datasets, including two challenging benchmarks, show that ScasNet\nachieves the state-of-the-art performance. \n\n"}
{"id": "1807.11655", "contents": "Title: Security and Privacy Issues in Deep Learning Abstract: To promote secure and private artificial intelligence (SPAI), we review\nstudies on the model security and data privacy of DNNs. Model security allows\nsystem to behave as intended without being affected by malicious external\ninfluences that can compromise its integrity and efficiency. Security attacks\ncan be divided based on when they occur: if an attack occurs during training,\nit is known as a poisoning attack, and if it occurs during inference (after\ntraining) it is termed an evasion attack. Poisoning attacks compromise the\ntraining process by corrupting the data with malicious examples, while evasion\nattacks use adversarial examples to disrupt entire classification process.\nDefenses proposed against such attacks include techniques to recognize and\nremove malicious data, train a model to be insensitive to such data, and mask\nthe model's structure and parameters to render attacks more challenging to\nimplement. Furthermore, the privacy of the data involved in model training is\nalso threatened by attacks such as the model-inversion attack, or by dishonest\nservice providers of AI applications. To maintain data privacy, several\nsolutions that combine existing data-privacy techniques have been proposed,\nincluding differential privacy and modern cryptography techniques. In this\npaper, we describe the notions of some of methods, e.g., homomorphic\nencryption, and review their advantages and challenges when implemented in\ndeep-learning models. \n\n"}
{"id": "1807.11876", "contents": "Title: Predicting Tactical Solutions to Operational Planning Problems under\n  Imperfect Information Abstract: This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict expected tactical descriptions of operational solutions\n(TDOSs). The problem we address occurs in the context of two-stage stochastic\nprogramming where the second stage is demanding computationally. We aim to\npredict at a high speed the expected TDOS associated with the second stage\nproblem, conditionally on the first stage variables. This may be used in\nsupport of the solution to the overall two-stage problem by avoiding the online\ngeneration of multiple second stage scenarios and solutions. We formulate the\ntactical prediction problem as a stochastic optimal prediction program, whose\nsolution we approximate with supervised machine learning. The training dataset\nconsists of a large number of deterministic operational problems generated by\ncontrolled probabilistic sampling. The labels are computed based on solutions\nto these problems (solved independently and offline), employing appropriate\naggregation and subselection methods to address uncertainty. Results on our\nmotivating application on load planning for rail transportation show that deep\nlearning models produce accurate predictions in very short computing time\n(milliseconds or less). The predictive accuracy is close to the lower bounds\ncalculated based on sample average approximation of the stochastic prediction\nprograms. \n\n"}
{"id": "1808.00200", "contents": "Title: Anomaly Detection via Minimum Likelihood Generative Adversarial Networks Abstract: Anomaly detection aims to detect abnormal events by a model of normality. It\nplays an important role in many domains such as network intrusion detection,\ncriminal activity identity and so on. With the rapidly growing size of\naccessible training data and high computation capacities, deep learning based\nanomaly detection has become more and more popular. In this paper, a new\ndomain-based anomaly detection method based on generative adversarial networks\n(GAN) is proposed. Minimum likelihood regularization is proposed to make the\ngenerator produce more anomalies and prevent it from converging to normal data\ndistribution. Proper ensemble of anomaly scores is shown to improve the\nstability of discriminator effectively. The proposed method has achieved\nsignificant improvement than other anomaly detection methods on Cifar10 and UCI\ndatasets. \n\n"}
{"id": "1808.01204", "contents": "Title: Learning Overparameterized Neural Networks via Stochastic Gradient\n  Descent on Structured Data Abstract: Neural networks have many successful applications, while much less\ntheoretical understanding has been gained. Towards bridging this gap, we study\nthe problem of learning a two-layer overparameterized ReLU neural network for\nmulti-class classification via stochastic gradient descent (SGD) from random\ninitialization. In the overparameterized setting, when the data comes from\nmixtures of well-separated distributions, we prove that SGD learns a network\nwith a small generalization error, albeit the network has enough capacity to\nfit arbitrary labels. Furthermore, the analysis provides interesting insights\ninto several aspects of learning neural networks and can be verified based on\nempirical studies on synthetic data and on the MNIST dataset. \n\n"}
{"id": "1808.01664", "contents": "Title: Structured Adversarial Attack: Towards General Implementation and Better\n  Interpretability Abstract: When generating adversarial examples to attack deep neural networks (DNNs),\nLp norm of the added perturbation is usually used to measure the similarity\nbetween original image and adversarial example. However, such adversarial\nattacks perturbing the raw input spaces may fail to capture structural\ninformation hidden in the input. This work develops a more general attack\nmodel, i.e., the structured attack (StrAttack), which explores group sparsity\nin adversarial perturbations by sliding a mask through images aiming for\nextracting key spatial structures. An ADMM (alternating direction method of\nmultipliers)-based framework is proposed that can split the original problem\ninto a sequence of analytically solvable subproblems and can be generalized to\nimplement other attacking methods. Strong group sparsity is achieved in\nadversarial perturbations even with the same level of Lp norm distortion as the\nstate-of-the-art attacks. We demonstrate the effectiveness of StrAttack by\nextensive experimental results onMNIST, CIFAR-10, and ImageNet. We also show\nthat StrAttack provides better interpretability (i.e., better correspondence\nwith discriminative image regions)through adversarial saliency map (Papernot et\nal., 2016b) and class activation map(Zhou et al., 2016). \n\n"}
{"id": "1808.02032", "contents": "Title: Tunneling wave function of the universe Abstract: The tunneling wave function of the universe is investigated in a\nminisuperspace framework of a de Sitter universe with a quantum scalar field,\ntreated as a perturbation. We consider three different approaches to defining\nthe tunneling wave function: (1) tunneling boundary conditions in superspace,\n(2) Lorentzian path integral, and (3) quantum tunneling from initial universe\nof a vanishing size. We show that the superspace approach requires Robin\nboundary conditions for the scalar field modes, the path integral approach\nrequires adding an appropriate boundary term to the scalar field action, and\nthe initial universe approach requires the initial quantum state of the scalar\nfield to be Euclidean vacuum. We find that all three approaches yield identical\nwave functions and that scalar field fluctuations are well behaved, contrary to\nearlier claims in the literature. \n\n"}
{"id": "1808.02123", "contents": "Title: Structure Learning for Relational Logistic Regression: An Ensemble\n  Approach Abstract: We consider the problem of learning Relational Logistic Regression (RLR).\nUnlike standard logistic regression, the features of RLRs are first-order\nformulae with associated weight vectors instead of scalar weights. We turn the\nproblem of learning RLR to learning these vector-weighted formulae and develop\na learning algorithm based on the recently successful functional-gradient\nboosting methods for probabilistic logic models. We derive the functional\ngradients and show how weights can be learned simultaneously in an efficient\nmanner. Our empirical evaluation on standard and novel data sets demonstrates\nthe superiority of our approach over other methods for learning RLR. \n\n"}
{"id": "1808.03752", "contents": "Title: Knowledge Graph Embedding with Entity Neighbors and Deep Memory Network Abstract: Knowledge Graph Embedding (KGE) aims to represent entities and relations of\nknowledge graph in a low-dimensional continuous vector space. Recent works\nfocus on incorporating structural knowledge with additional information, such\nas entity descriptions, relation paths and so on. However, common used\nadditional information usually contains plenty of noise, which makes it hard to\nlearn valuable representation. In this paper, we propose a new kind of\nadditional information, called entity neighbors, which contain both semantic\nand topological features about given entity. We then develop a deep memory\nnetwork model to encode information from neighbors. Employing a gating\nmechanism, representations of structure and neighbors are integrated into a\njoint representation. The experimental results show that our model outperforms\nexisting KGE methods utilizing entity descriptions and achieves\nstate-of-the-art metrics on 4 datasets. \n\n"}
{"id": "1808.04580", "contents": "Title: NFFT meets Krylov methods: Fast matrix-vector products for the graph\n  Laplacian of fully connected networks Abstract: The graph Laplacian is a standard tool in data science, machine learning, and\nimage processing. The corresponding matrix inherits the complex structure of\nthe underlying network and is in certain applications densely populated. This\nmakes computations, in particular matrix-vector products, with the graph\nLaplacian a hard task. A typical application is the computation of a number of\nits eigenvalues and eigenvectors. Standard methods become infeasible as the\nnumber of nodes in the graph is too large. We propose the use of the fast\nsummation based on the nonequispaced fast Fourier transform (NFFT) to perform\nthe dense matrix-vector product with the graph Laplacian fast without ever\nforming the whole matrix. The enormous flexibility of the NFFT algorithm allows\nus to embed the accelerated multiplication into Lanczos-based eigenvalues\nroutines or iterative linear system solvers and even consider other than the\nstandard Gaussian kernels. We illustrate the feasibility of our approach on a\nnumber of test problems from image segmentation to semi-supervised learning\nbased on graph-based PDEs. In particular, we compare our approach with the\nNystr\\\"om method. Moreover, we present and test an enhanced, hybrid version of\nthe Nystr\\\"om method, which internally uses the NFFT. \n\n"}
{"id": "1808.04794", "contents": "Title: Improving Hearthstone AI by Combining MCTS and Supervised Learning\n  Algorithms Abstract: We investigate the impact of supervised prediction models on the strength and\nefficiency of artificial agents that use the Monte-Carlo Tree Search (MCTS)\nalgorithm to play a popular video game Hearthstone: Heroes of Warcraft. We\noverview our custom implementation of the MCTS that is well-suited for games\nwith partially hidden information and random effects. We also describe\nexperiments which we designed to quantify the performance of our Hearthstone\nagent's decision making. We show that even simple neural networks can be\ntrained and successfully used for the evaluation of game states. Moreover, we\ndemonstrate that by providing a guidance to the game state search heuristic, it\nis possible to substantially improve the win rate, and at the same time reduce\nthe required computations. \n\n"}
{"id": "1808.05163", "contents": "Title: A Simple Convolutional Generative Network for Next Item Recommendation Abstract: Convolutional Neural Networks (CNNs) have been recently introduced in the\ndomain of session-based next item recommendation. An ordered collection of past\nitems the user has interacted with in a session (or sequence) are embedded into\na 2-dimensional latent matrix, and treated as an image. The convolution and\npooling operations are then applied to the mapped item embeddings. In this\npaper, we first examine the typical session-based CNN recommender and show that\nboth the generative model and network architecture are suboptimal when modeling\nlong-range dependencies in the item sequence. To address the issues, we\nintroduce a simple, but very effective generative model that is capable of\nlearning high-level representation from both short- and long-range item\ndependencies. The network architecture of the proposed model is formed of a\nstack of \\emph{holed} convolutional layers, which can efficiently increase the\nreceptive fields without relying on the pooling operation. Another contribution\nis the effective use of residual block structure in recommender systems, which\ncan ease the optimization for much deeper networks. The proposed generative\nmodel attains state-of-the-art accuracy with less training time in the next\nitem recommendation task. It accordingly can be used as a powerful\nrecommendation baseline to beat in future, especially when there are long\nsequences of user feedback. \n\n"}
{"id": "1808.05731", "contents": "Title: Efficiently Learning Mixtures of Mallows Models Abstract: Mixtures of Mallows models are a popular generative model for ranking data\ncoming from a heterogeneous population. They have a variety of applications\nincluding social choice, recommendation systems and natural language\nprocessing. Here we give the first polynomial time algorithm for provably\nlearning the parameters of a mixture of Mallows models with any constant number\nof components. Prior to our work, only the two component case had been settled.\nOur analysis revolves around a determinantal identity of Zagier which was\nproven in the context of mathematical physics, which we use to show polynomial\nidentifiability and ultimately to construct test functions to peel off one\ncomponent at a time.\n  To complement our upper bounds, we show information-theoretic lower bounds on\nthe sample complexity as well as lower bounds against restricted families of\nalgorithms that make only local queries. Together, these results demonstrate\nvarious impediments to improving the dependence on the number of components.\nThey also motivate the study of learning mixtures of Mallows models from the\nperspective of beyond worst-case analysis. In this direction, we show that when\nthe scaling parameters of the Mallows models have separation, there are much\nfaster learning algorithms. \n\n"}
{"id": "1808.06684", "contents": "Title: Use Of Vapnik-Chervonenkis Dimension in Model Selection Abstract: In this dissertation, I derive a new method to estimate the\nVapnik-Chervonenkis Dimension (VCD) for the class of linear functions. This\nmethod is inspired by the technique developed by Vapnik et al. Vapnik et al.\n(1994). My contribution rests on the approximation of the expected maximum\ndifference between two empirical Losses (EMDBTEL). In fact, I use a\ncross-validated form of the error to compute the EMDBTEL, and I make the bound\non the EMDBTEL tighter by minimizing a constant in of its right upper bound. I\nalso derive two bounds for the true unknown risk using the additive (ERM1) and\nthe multiplicative (ERM2) Chernoff bounds. These bounds depend on the estimated\nVCD and the empirical risk. These bounds can be used to perform model selection\nand to declare with high probability, the chosen model will perform better\nwithout making strong assumptions about the data generating process (DG).\n  I measure the accuracy of my technique on simulated datasets and also on\nthree real datasets. The model selection provided by VCD was always as good as\nif not better than the other methods under reasonable conditions. \n\n"}
{"id": "1808.06725", "contents": "Title: Learning to Exploit Invariances in Clinical Time-Series Data using\n  Sequence Transformer Networks Abstract: Recently, researchers have started applying convolutional neural networks\n(CNNs) with one-dimensional convolutions to clinical tasks involving\ntime-series data. This is due, in part, to their computational efficiency,\nrelative to recurrent neural networks and their ability to efficiently exploit\ncertain temporal invariances, (e.g., phase invariance). However, it is\nwell-established that clinical data may exhibit many other types of invariances\n(e.g., scaling). While preprocessing techniques, (e.g., dynamic time warping)\nmay successfully transform and align inputs, their use often requires one to\nidentify the types of invariances in advance. In contrast, we propose the use\nof Sequence Transformer Networks, an end-to-end trainable architecture that\nlearns to identify and account for invariances in clinical time-series data.\nApplied to the task of predicting in-hospital mortality, our proposed approach\nachieves an improvement in the area under the receiver operating characteristic\ncurve (AUROC) relative to a baseline CNN (AUROC=0.851 vs. AUROC=0.838). Our\nresults suggest that a variety of valuable invariances can be learned directly\nfrom the data. \n\n"}
{"id": "1808.06733", "contents": "Title: Wrapped Loss Function for Regularizing Nonconforming Residual\n  Distributions Abstract: Multi-output is essential in machine learning that it might suffer from\nnonconforming residual distributions, i.e., the multi-output residual\ndistributions are not conforming to the expected distribution. In this paper,\nwe propose \"Wrapped Loss Function\" to wrap the original loss function to\nalleviate the problem. This wrapped loss function acts just like the original\nloss function that its gradient can be used for backpropagation optimization.\nEmpirical evaluations show wrapped loss function has advanced properties of\nfaster convergence, better accuracy, and improving imbalanced data. \n\n"}
{"id": "1808.06809", "contents": "Title: Are You Tampering With My Data? Abstract: We propose a novel approach towards adversarial attacks on neural networks\n(NN), focusing on tampering the data used for training instead of generating\nattacks on trained models. Our network-agnostic method creates a backdoor\nduring training which can be exploited at test time to force a neural network\nto exhibit abnormal behaviour. We demonstrate on two widely used datasets\n(CIFAR-10 and SVHN) that a universal modification of just one pixel per image\nfor all the images of a class in the training set is enough to corrupt the\ntraining procedure of several state-of-the-art deep neural networks causing the\nnetworks to misclassify any images to which the modification is applied. Our\naim is to bring to the attention of the machine learning community, the\npossibility that even learning-based methods that are personally trained on\npublic datasets can be subject to attacks by a skillful adversary. \n\n"}
{"id": "1808.07217", "contents": "Title: Don't Use Large Mini-Batches, Use Local SGD Abstract: Mini-batch stochastic gradient methods (SGD) are state of the art for\ndistributed training of deep neural networks. Drastic increases in the\nmini-batch sizes have lead to key efficiency and scalability gains in recent\nyears. However, progress faces a major roadblock, as models trained with large\nbatches often do not generalize well, i.e. they do not show good accuracy on\nnew data. As a remedy, we propose a \\emph{post-local} SGD and show that it\nsignificantly improves the generalization performance compared to large-batch\ntraining on standard benchmarks while enjoying the same efficiency\n(time-to-accuracy) and scalability. We further provide an extensive study of\nthe communication efficiency vs. performance trade-offs associated with a host\nof \\emph{local SGD} variants. \n\n"}
{"id": "1808.07233", "contents": "Title: Neural Architecture Optimization Abstract: Automatic neural architecture design has shown its potential in discovering\npowerful neural network architectures. Existing methods, no matter based on\nreinforcement learning or evolutionary algorithms (EA), conduct architecture\nsearch in a discrete space, which is highly inefficient. In this paper, we\npropose a simple and efficient method to automatic neural architecture design\nbased on continuous optimization. We call this new approach neural architecture\noptimization (NAO). There are three key components in our proposed approach:\n(1) An encoder embeds/maps neural network architectures into a continuous\nspace. (2) A predictor takes the continuous representation of a network as\ninput and predicts its accuracy. (3) A decoder maps a continuous representation\nof a network back to its architecture. The performance predictor and the\nencoder enable us to perform gradient based optimization in the continuous\nspace to find the embedding of a new architecture with potentially better\naccuracy. Such a better embedding is then decoded to a network by the decoder.\nExperiments show that the architecture discovered by our method is very\ncompetitive for image classification task on CIFAR-10 and language modeling\ntask on PTB, outperforming or on par with the best results of previous\narchitecture search methods with a significantly reduction of computational\nresources. Specifically we obtain 1.93% test set error rate for CIFAR-10 image\nclassification task and 56.0 test set perplexity of PTB language modeling task.\nFurthermore, combined with the recent proposed weight sharing mechanism, we\ndiscover powerful architecture on CIFAR-10 (with error rate 2.93%) and on PTB\n(with test set perplexity 56.6), with very limited computational resources\n(less than 10 GPU hours) for both tasks. \n\n"}
{"id": "1808.07632", "contents": "Title: DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection\n  with GAN Abstract: Recently, the introduction of the generative adversarial network (GAN) and\nits variants has enabled the generation of realistic synthetic samples, which\nhas been used for enlarging training sets. Previous work primarily focused on\ndata augmentation for semi-supervised and supervised tasks. In this paper, we\ninstead focus on unsupervised anomaly detection and propose a novel generative\ndata augmentation framework optimized for this task. In particular, we propose\nto oversample infrequent normal samples - normal samples that occur with small\nprobability, e.g., rare normal events. We show that these samples are\nresponsible for false positives in anomaly detection. However, oversampling of\ninfrequent normal samples is challenging for real-world high-dimensional data\nwith multimodal distributions. To address this challenge, we propose to use a\nGAN variant known as the adversarial autoencoder (AAE) to transform the\nhigh-dimensional multimodal data distributions into low-dimensional unimodal\nlatent distributions with well-defined tail probability. Then, we\nsystematically oversample at the `edge' of the latent distributions to increase\nthe density of infrequent normal samples. We show that our oversampling\npipeline is a unified one: it is generally applicable to datasets with\ndifferent complex data distributions. To the best of our knowledge, our method\nis the first data augmentation technique focused on improving performance in\nunsupervised anomaly detection. We validate our method by demonstrating\nconsistent improvements across several real-world datasets. \n\n"}
{"id": "1808.07724", "contents": "Title: Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs Abstract: This paper addresses the problem of mapping natural language text to\nknowledge base entities. The mapping process is approached as a composition of\na phrase or a sentence into a point in a multi-dimensional entity space\nobtained from a knowledge graph. The compositional model is an LSTM equipped\nwith a dynamic disambiguation mechanism on the input word embeddings (a\nMulti-Sense LSTM), addressing polysemy issues. Further, the knowledge base\nspace is prepared by collecting random walks from a graph enhanced with textual\nfeatures, which act as a set of semantic bridges between text and knowledge\nbase entities. The ideas of this work are demonstrated on large-scale\ntext-to-entity mapping and entity classification tasks, with state of the art\nresults. \n\n"}
{"id": "1808.07945", "contents": "Title: Maximal Jacobian-based Saliency Map Attack Abstract: The Jacobian-based Saliency Map Attack is a family of adversarial attack\nmethods for fooling classification models, such as deep neural networks for\nimage classification tasks. By saturating a few pixels in a given image to\ntheir maximum or minimum values, JSMA can cause the model to misclassify the\nresulting adversarial image as a specified erroneous target class. We propose\ntwo variants of JSMA, one which removes the requirement to specify a target\nclass, and another that additionally does not need to specify whether to only\nincrease or decrease pixel intensities. Our experiments highlight the\ncompetitive speeds and qualities of these variants when applied to datasets of\nhand-written digits and natural scenes. \n\n"}
{"id": "1808.07982", "contents": "Title: Proximal Policy Optimization and its Dynamic Version for Sequence\n  Generation Abstract: In sequence generation task, many works use policy gradient for model\noptimization to tackle the intractable backpropagation issue when maximizing\nthe non-differentiable evaluation metrics or fooling the discriminator in\nadversarial learning. In this paper, we replace policy gradient with proximal\npolicy optimization (PPO), which is a proved more efficient reinforcement\nlearning algorithm, and propose a dynamic approach for PPO (PPO-dynamic). We\ndemonstrate the efficacy of PPO and PPO-dynamic on conditional sequence\ngeneration tasks including synthetic experiment and chit-chat chatbot. The\nresults show that PPO and PPO-dynamic can beat policy gradient by stability and\nperformance. \n\n"}
{"id": "1808.08111", "contents": "Title: Multiclass Universum SVM Abstract: We introduce Universum learning for multiclass problems and propose a novel\nformulation for multiclass universum SVM (MU-SVM). We also propose an analytic\nspan bound for model selection with almost 2-4x faster computation times than\nstandard resampling techniques. We empirically demonstrate the efficacy of the\nproposed MUSVM formulation on several real world datasets achieving > 20%\nimprovement in test accuracies compared to multi-class SVM. \n\n"}
{"id": "1808.08762", "contents": "Title: Sentence Embeddings in NLI with Iterative Refinement Encoders Abstract: Sentence-level representations are necessary for various NLP tasks. Recurrent\nneural networks have proven to be very effective in learning distributed\nrepresentations and can be trained efficiently on natural language inference\ntasks. We build on top of one such model and propose a hierarchy of BiLSTM and\nmax pooling layers that implements an iterative refinement strategy and yields\nstate of the art results on the SciTail dataset as well as strong results for\nSNLI and MultiNLI. We can show that the sentence embeddings learned in this way\ncan be utilized in a wide variety of transfer learning tasks, outperforming\nInferSent on 7 out of 10 and SkipThought on 8 out of 9 SentEval sentence\nembedding evaluation tasks. Furthermore, our model beats the InferSent model in\n8 out of 10 recently published SentEval probing tasks designed to evaluate\nsentence embeddings' ability to capture some of the important linguistic\nproperties of sentences. \n\n"}
{"id": "1808.08784", "contents": "Title: Sparsity in Deep Neural Networks - An Empirical Investigation with\n  TensorQuant Abstract: Deep learning is finding its way into the embedded world with applications\nsuch as autonomous driving, smart sensors and aug- mented reality. However, the\ncomputation of deep neural networks is demanding in energy, compute power and\nmemory. Various approaches have been investigated to reduce the necessary\nresources, one of which is to leverage the sparsity occurring in deep neural\nnetworks due to the high levels of redundancy in the network parameters. It has\nbeen shown that sparsity can be promoted specifically and the achieved sparsity\ncan be very high. But in many cases the methods are evaluated on rather small\ntopologies. It is not clear if the results transfer onto deeper topologies. In\nthis paper, the TensorQuant toolbox has been extended to offer a platform to\ninvestigate sparsity, especially in deeper models. Several practical relevant\ntopologies for varying classification problem sizes are investigated to show\nthe differences in sparsity for activations, weights and gradients. \n\n"}
{"id": "1808.09334", "contents": "Title: A Discriminative Latent-Variable Model for Bilingual Lexicon Induction Abstract: We introduce a novel discriminative latent variable model for bilingual\nlexicon induction. Our model combines the bipartite matching dictionary prior\nof Haghighi et al. (2008) with a representation-based approach (Artetxe et al.,\n2017). To train the model, we derive an efficient Viterbi EM algorithm. We\nprovide empirical results on six language pairs under two metrics and show that\nthe prior improves the induced bilingual lexicons. We also demonstrate how\nprevious work may be viewed as a similarly fashioned latent-variable model,\nalbeit with a different prior. \n\n"}
{"id": "1808.09540", "contents": "Title: Lipschitz regularized Deep Neural Networks generalize and are\n  adversarially robust Abstract: In this work we study input gradient regularization of deep neural networks,\nand demonstrate that such regularization leads to generalization proofs and\nimproved adversarial robustness. The proof of generalization does not overcome\nthe curse of dimensionality, but it is independent of the number of layers in\nthe networks. The adversarial robustness regularization combines adversarial\ntraining, which we show to be equivalent to Total Variation regularization,\nwith Lipschitz regularization. We demonstrate empirically that the regularized\nmodels are more robust, and that gradient norms of images can be used for\nattack detection. \n\n"}
{"id": "1808.10549", "contents": "Title: Fair Algorithms for Learning in Allocation Problems Abstract: Settings such as lending and policing can be modeled by a centralized agent\nallocating a resource (loans or police officers) amongst several groups, in\norder to maximize some objective (loans given that are repaid or criminals that\nare apprehended). Often in such problems fairness is also a concern. A natural\nnotion of fairness, based on general principles of equality of opportunity,\nasks that conditional on an individual being a candidate for the resource, the\nprobability of actually receiving it is approximately independent of the\nindividual's group. In lending this means that equally creditworthy individuals\nin different racial groups have roughly equal chances of receiving a loan. In\npolicing it means that two individuals committing the same crime in different\ndistricts would have roughly equal chances of being arrested.\n  We formalize this fairness notion for allocation problems and investigate its\nalgorithmic consequences. Our main technical results include an efficient\nlearning algorithm that converges to an optimal fair allocation even when the\nfrequency of candidates (creditworthy individuals or criminals) in each group\nis unknown. The algorithm operates in a censored feedback model in which only\nthe number of candidates who received the resource in a given allocation can be\nobserved, rather than the true number of candidates. This models the fact that\nwe do not learn the creditworthiness of individuals we do not give loans to nor\nlearn about crimes committed if the police presence in a district is low.\n  As an application of our framework, we consider the predictive policing\nproblem. The learning algorithm is trained on arrest data gathered from its own\ndeployments on previous days, resulting in a potential feedback loop that our\nalgorithm provably overcomes. We empirically investigate the performance of our\nalgorithm on the Philadelphia Crime Incidents dataset. \n\n"}
{"id": "1808.10792", "contents": "Title: Bottom-Up Abstractive Summarization Abstract: Neural network-based methods for abstractive summarization produce outputs\nthat are more fluent than other techniques, but which can be poor at content\nselection. This work proposes a simple technique for addressing this issue: use\na data-efficient content selector to over-determine phrases in a source\ndocument that should be part of the summary. We use this selector as a\nbottom-up attention step to constrain the model to likely phrases. We show that\nthis approach improves the ability to compress text, while still generating\nfluent summaries. This two-step process is both simpler and higher performing\nthan other end-to-end content selection models, leading to significant\nimprovements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the\ncontent selector can be trained with as little as 1,000 sentences, making it\neasy to transfer a trained summarizer to a new domain. \n\n"}
{"id": "1809.00403", "contents": "Title: Effective Exploration for Deep Reinforcement Learning via Bootstrapped\n  Q-Ensembles under Tsallis Entropy Regularization Abstract: Recently deep reinforcement learning (DRL) has achieved outstanding success\non solving many difficult and large-scale RL problems. However the high sample\ncost required for effective learning often makes DRL unaffordable in\nresource-limited applications. With the aim of improving sample efficiency and\nlearning performance, we will develop a new DRL algorithm in this paper that\nseamless integrates entropy-induced and bootstrap-induced techniques for\nefficient and deep exploration of the learning environment. Specifically, a\ngeneral form of Tsallis entropy regularizer will be utilized to drive\nentropy-induced exploration based on efficient approximation of optimal\naction-selection policies. Different from many existing works that rely on\naction dithering strategies for exploration, our algorithm is efficient in\nexploring actions with clear exploration value. Meanwhile, by employing an\nensemble of Q-networks under varied Tsallis entropy regularization, the\ndiversity of the ensemble can be further enhanced to enable effective\nbootstrap-induced exploration. Experiments on Atari game playing tasks clearly\ndemonstrate that our new algorithm can achieve more efficient and effective\nexploration for DRL, in comparison to recently proposed exploration methods\nincluding Bootstrapped Deep Q-Network and UCB Q-Ensemble. \n\n"}
{"id": "1809.00934", "contents": "Title: A Deep Neural Network Sentence Level Classification Method with Context\n  Information Abstract: In the sentence classification task, context formed from sentences adjacent\nto the sentence being classified can provide important information for\nclassification. This context is, however, often ignored. Where methods do make\nuse of context, only small amounts are considered, making it difficult to\nscale. We present a new method for sentence classification, Context-LSTM-CNN,\nthat makes use of potentially large contexts. The method also utilizes\nlong-range dependencies within the sentence being classified, using an LSTM,\nand short-span features, using a stacked CNN. Our experiments demonstrate that\nthis approach consistently improves over previous methods on two different\ndatasets. \n\n"}
{"id": "1809.00946", "contents": "Title: Twin-GAN -- Unpaired Cross-Domain Image Translation with Weight-Sharing\n  GANs Abstract: We present a framework for translating unlabeled images from one domain into\nanalog images in another domain. We employ a progressively growing\nskip-connected encoder-generator structure and train it with a GAN loss for\nrealistic output, a cycle consistency loss for maintaining same-domain\ntranslation identity, and a semantic consistency loss that encourages the\nnetwork to keep the input semantic features in the output. We apply our\nframework on the task of translating face images, and show that it is capable\nof learning semantic mappings for face images with no supervised one-to-one\nimage mapping. \n\n"}
{"id": "1809.01354", "contents": "Title: Semantic Human Matting Abstract: Human matting, high quality extraction of humans from natural images, is\ncrucial for a wide variety of applications. Since the matting problem is\nseverely under-constrained, most previous methods require user interactions to\ntake user designated trimaps or scribbles as constraints. This user-in-the-loop\nnature makes them difficult to be applied to large scale data or time-sensitive\nscenarios. In this paper, instead of using explicit user input constraints, we\nemploy implicit semantic constraints learned from data and propose an automatic\nhuman matting algorithm (SHM). SHM is the first algorithm that learns to\njointly fit both semantic information and high quality details with deep\nnetworks. In practice, simultaneously learning both coarse semantics and fine\ndetails is challenging. We propose a novel fusion strategy which naturally\ngives a probabilistic estimation of the alpha matte. We also construct a very\nlarge dataset with high quality annotations consisting of 35,513 unique\nforegrounds to facilitate the learning and evaluation of human matting.\nExtensive experiments on this dataset and plenty of real images show that SHM\nachieves comparable results with state-of-the-art interactive matting methods. \n\n"}
{"id": "1809.01587", "contents": "Title: GAN Lab: Understanding Complex Deep Generative Models using Interactive\n  Visual Experimentation Abstract: Recent success in deep learning has generated immense interest among\npractitioners and students, inspiring many to learn about this new technology.\nWhile visual and interactive approaches have been successfully developed to\nhelp people more easily learn deep learning, most existing tools focus on\nsimpler models. In this work, we present GAN Lab, the first interactive\nvisualization tool designed for non-experts to learn and experiment with\nGenerative Adversarial Networks (GANs), a popular class of complex deep\nlearning models. With GAN Lab, users can interactively train generative models\nand visualize the dynamic training process's intermediate results. GAN Lab\ntightly integrates an model overview graph that summarizes GAN's structure, and\na layered distributions view that helps users interpret the interplay between\nsubmodels. GAN Lab introduces new interactive experimentation features for\nlearning complex deep learning models, such as step-by-step training at\nmultiple levels of abstraction for understanding intricate training dynamics.\nImplemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web\nbrowsers, without the need for installation or specialized hardware, overcoming\na major practical challenge in deploying interactive tools for deep learning. \n\n"}
{"id": "1809.01749", "contents": "Title: Geometry of Deep Learning for Magnetic Resonance Fingerprinting Abstract: Current popular methods for Magnetic Resonance Fingerprint (MRF) recovery are\nbottlenecked by the heavy storage and computation requirements of a\ndictionary-matching (DM) step due to the growing size and complexity of the\nfingerprint dictionaries in multi-parametric quantitative MRI applications. In\nthis paper we study a deep learning approach to address these shortcomings.\nCoupled with a dimensionality reduction first layer, the proposed MRF-Net is\nable to reconstruct quantitative maps by saving more than 60 times in memory\nand computations required for a DM baseline. Fine-grid manifold enumeration\ni.e. the MRF dictionary is only used for training the network and not during\nimage reconstruction. We show that the MRF-Net provides a piece-wise affine\napproximation to the Bloch response manifold projection and that rather than\nmemorizing the dictionary, the network efficiently clusters this manifold and\nlearns a set of hierarchical matched-filters for affine regression of the NMR\ncharacteristics in each segment. \n\n"}
{"id": "1809.01771", "contents": "Title: An Analysis of Hierarchical Text Classification Using Word Embeddings Abstract: Efficient distributed numerical word representation models (word embeddings)\ncombined with modern machine learning algorithms have recently yielded\nconsiderable improvement on automatic document classification tasks. However,\nthe effectiveness of such techniques has not been assessed for the hierarchical\ntext classification (HTC) yet. This study investigates the application of those\nmodels and algorithms on this specific problem by means of experimentation and\nanalysis. We trained classification models with prominent machine learning\nalgorithm implementations---fastText, XGBoost, SVM, and Keras' CNN---and\nnoticeable word embeddings generation methods---GloVe, word2vec, and\nfastText---with publicly available data and evaluated them with measures\nspecifically appropriate for the hierarchical context. FastText achieved an\n${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An\nanalysis indicates that using word embeddings and its flavors is a very\npromising approach for HTC. \n\n"}
{"id": "1809.01797", "contents": "Title: Describing a Knowledge Base Abstract: We aim to automatically generate natural language descriptions about an input\nstructured knowledge base (KB). We build our generation framework based on a\npointer network which can copy facts from the input KB, and add two attention\nmechanisms: (i) slot-aware attention to capture the association between a slot\ntype and its corresponding slot value; and (ii) a new \\emph{table position\nself-attention} to capture the inter-dependencies among related slots. For\nevaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we\npropose a KB reconstruction based metric by extracting a KB from the generation\noutput and comparing it with the input KB. We also create a new data set which\nincludes 106,216 pairs of structured KBs and their corresponding natural\nlanguage descriptions for two distinct entity types. Experiments show that our\napproach significantly outperforms state-of-the-art methods. The reconstructed\nKB achieves 68.8% - 72.6% F-score. \n\n"}
{"id": "1809.01890", "contents": "Title: Full-body High-resolution Anime Generation with Progressive\n  Structure-conditional Generative Adversarial Networks Abstract: We propose Progressive Structure-conditional Generative Adversarial Networks\n(PSGAN), a new framework that can generate full-body and high-resolution\ncharacter images based on structural information. Recent progress in generative\nadversarial networks with progressive training has made it possible to generate\nhigh-resolution images. However, existing approaches have limitations in\nachieving both high image quality and structural consistency at the same time.\nOur method tackles the limitations by progressively increasing the resolution\nof both generated images and structural conditions during training. In this\npaper, we empirically demonstrate the effectiveness of this method by showing\nthe comparison with existing approaches and video generation results of diverse\nanime characters at 1024x1024 based on target pose sequences. We also create a\nnovel dataset containing full-body 1024x1024 high-resolution images and exact\n2D pose keypoints using Unity 3D Avatar models. \n\n"}
{"id": "1809.02105", "contents": "Title: A Memory-Network Based Solution for Multivariate Time-Series Forecasting Abstract: Multivariate time series forecasting is extensively studied throughout the\nyears with ubiquitous applications in areas such as finance, traffic,\nenvironment, etc. Still, concerns have been raised on traditional methods for\nincapable of modeling complex patterns or dependencies lying in real word data.\nTo address such concerns, various deep learning models, mainly Recurrent Neural\nNetwork (RNN) based methods, are proposed. Nevertheless, capturing extremely\nlong-term patterns while effectively incorporating information from other\nvariables remains a challenge for time-series forecasting. Furthermore,\nlack-of-explainability remains one serious drawback for deep neural network\nmodels. Inspired by Memory Network proposed for solving the question-answering\ntask, we propose a deep learning based model named Memory Time-series network\n(MTNet) for time series forecasting. MTNet consists of a large memory\ncomponent, three separate encoders, and an autoregressive component to train\njointly. Additionally, the attention mechanism designed enable MTNet to be\nhighly interpretable. We can easily tell which part of the historic data is\nreferenced the most. \n\n"}
{"id": "1809.02206", "contents": "Title: Challenges of Context and Time in Reinforcement Learning: Introducing\n  Space Fortress as a Benchmark Abstract: Research in deep reinforcement learning (RL) has coalesced around improving\nperformance on benchmarks like the Arcade Learning Environment. However, these\nbenchmarks conspicuously miss important characteristics like abrupt\ncontext-dependent shifts in strategy and temporal sensitivity that are often\npresent in real-world domains. As a result, RL research has not focused on\nthese challenges, resulting in algorithms which do not understand critical\nchanges in context, and have little notion of real world time. To tackle this\nissue, this paper introduces the game of Space Fortress as a RL benchmark which\nincorporates these characteristics. We show that existing state-of-the-art RL\nalgorithms are unable to learn to play the Space Fortress game. We then confirm\nthat this poor performance is due to the RL algorithms' context insensitivity\nand reward sparsity. We also identify independent axes along which to vary\ncontext and temporal sensitivity, allowing Space Fortress to be used as a\ntestbed for understanding both characteristics in combination and also in\nisolation. We release Space Fortress as an open-source Gym environment. \n\n"}
{"id": "1809.02337", "contents": "Title: Information-Theoretic Active Learning for Content-Based Image Retrieval Abstract: We propose Information-Theoretic Active Learning (ITAL), a novel batch-mode\nactive learning method for binary classification, and apply it for acquiring\nmeaningful user feedback in the context of content-based image retrieval.\nInstead of combining different heuristics such as uncertainty, diversity, or\ndensity, our method is based on maximizing the mutual information between the\npredicted relevance of the images and the expected user feedback regarding the\nselected batch. We propose suitable approximations to this computationally\ndemanding problem and also integrate an explicit model of user behavior that\naccounts for possible incorrect labels and unnameable instances. Furthermore,\nour approach does not only take the structure of the data but also the expected\nmodel output change caused by the user feedback into account. In contrast to\nother methods, ITAL turns out to be highly flexible and provides\nstate-of-the-art performance across various datasets, such as MIRFLICKR and\nImageNet. \n\n"}
{"id": "1809.02497", "contents": "Title: Sparse Kernel PCA for Outlier Detection Abstract: In this paper, we propose a new method to perform Sparse Kernel Principal\nComponent Analysis (SKPCA) and also mathematically analyze the validity of\nSKPCA. We formulate SKPCA as a constrained optimization problem with elastic\nnet regularization (Hastie et al.) in kernel feature space and solve it. We\nconsider outlier detection (where KPCA is employed) as an application for\nSKPCA, using the RBF kernel. We test it on 5 real-world datasets and show that\nby using just 4% (or even less) of the principal components (PCs), where each\nPC has on average less than 12% non-zero elements in the worst case among all 5\ndatasets, we are able to nearly match and in 3 datasets even outperform KPCA.\nWe also compare the performance of our method with a recently proposed method\nfor SKPCA by Wang et al. and show that our method performs better in terms of\nboth accuracy and sparsity. We also provide a novel probabilistic proof to\njustify the existence of sparse solutions for KPCA using the RBF kernel. To the\nbest of our knowledge, this is the first attempt at theoretically analyzing the\nvalidity of SKPCA. \n\n"}
{"id": "1809.02519", "contents": "Title: Fairness Through Causal Awareness: Learning Latent-Variable Models for\n  Biased Data Abstract: How do we learn from biased data? Historical datasets often reflect\nhistorical prejudices; sensitive or protected attributes may affect the\nobserved treatments and outcomes. Classification algorithms tasked with\npredicting outcomes accurately from these datasets tend to replicate these\nbiases. We advocate a causal modeling approach to learning from biased data,\nexploring the relationship between fair classification and intervention. We\npropose a causal model in which the sensitive attribute confounds both the\ntreatment and the outcome. Building on prior work in deep learning and\ngenerative modeling, we describe how to learn the parameters of this causal\nmodel from observational data alone, even in the presence of unobserved\nconfounders. We show experimentally that fairness-aware causal modeling\nprovides better estimates of the causal effects between the sensitive\nattribute, the treatment, and the outcome. We further present evidence that\nestimating these causal effects can help learn policies that are both more\naccurate and fair, when presented with a historically biased dataset. \n\n"}
{"id": "1809.02731", "contents": "Title: Exploiting Invertible Decoders for Unsupervised Sentence Representation\n  Learning Abstract: The encoder-decoder models for unsupervised sentence representation learning\ntend to discard the decoder after being trained on a large unlabelled corpus,\nsince only the encoder is needed to map the input sentence into a vector\nrepresentation. However, parameters learnt in the decoder also contain useful\ninformation about language. In order to utilise the decoder after learning, we\npresent two types of decoding functions whose inverse can be easily derived\nwithout expensive inverse calculation. Therefore, the inverse of the decoding\nfunction serves as another encoder that produces sentence representations. We\nshow that, with careful design of the decoding functions, the model learns good\nsentence representations, and the ensemble of the representations produced from\nthe encoder and the inverse of the decoder demonstrate even better\ngeneralisation ability and solid transferability. \n\n"}
{"id": "1809.02786", "contents": "Title: Structure-Preserving Transformation: Generating Diverse and Transferable\n  Adversarial Examples Abstract: Adversarial examples are perturbed inputs designed to fool machine learning\nmodels. Most recent works on adversarial examples for image classification\nfocus on directly modifying pixels with minor perturbations. A common\nrequirement in all these works is that the malicious perturbations should be\nsmall enough (measured by an L_p norm for some p) so that they are\nimperceptible to humans. However, small perturbations can be unnecessarily\nrestrictive and limit the diversity of adversarial examples generated. Further,\nan L_p norm based distance metric ignores important structure patterns hidden\nin images that are important to human perception. Consequently, even the minor\nperturbation introduced in recent works often makes the adversarial examples\nless natural to humans. More importantly, they often do not transfer well and\nare therefore less effective when attacking black-box models especially for\nthose protected by a defense mechanism. In this paper, we propose a\nstructure-preserving transformation (SPT) for generating natural and diverse\nadversarial examples with extremely high transferability. The key idea of our\napproach is to allow perceptible deviation in adversarial examples while\nkeeping structure patterns that are central to a human classifier. Empirical\nresults on the MNIST and the fashion-MNIST datasets show that adversarial\nexamples generated by our approach can easily bypass strong adversarial\ntraining. Further, they transfer well to other target models with no loss or\nlittle loss of successful attack rate. \n\n"}
{"id": "1809.02864", "contents": "Title: Online Adaptive Methods, Universality and Acceleration Abstract: We present a novel method for convex unconstrained optimization that, without\nany modifications, ensures: (i) accelerated convergence rate for smooth\nobjectives, (ii) standard convergence rate in the general (non-smooth) setting,\nand (iii) standard convergence rate in the stochastic optimization setting. To\nthe best of our knowledge, this is the first method that simultaneously applies\nto all of the above settings. At the heart of our method is an adaptive\nlearning rate rule that employs importance weights, in the spirit of adaptive\nonline learning algorithms (Duchi et al., 2011; Levy, 2017), combined with an\nupdate that linearly couples two sequences, in the spirit of (Allen-Zhu and\nOrecchia, 2017). An empirical examination of our method demonstrates its\napplicability to the above mentioned scenarios and corroborates our theoretical\nfindings. \n\n"}
{"id": "1809.02925", "contents": "Title: Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward\n  Bias in Adversarial Imitation Learning Abstract: We identify two issues with the family of algorithms based on the Adversarial\nImitation Learning framework. The first problem is implicit bias present in the\nreward functions used in these algorithms. While these biases might work well\nfor some environments, they can also lead to sub-optimal behavior in others.\nSecondly, even though these algorithms can learn from few expert\ndemonstrations, they require a prohibitively large number of interactions with\nthe environment in order to imitate the expert for many real-world\napplications. In order to address these issues, we propose a new algorithm\ncalled Discriminator-Actor-Critic that uses off-policy Reinforcement Learning\nto reduce policy-environment interaction sample complexity by an average factor\nof 10. Furthermore, since our reward function is designed to be unbiased, we\ncan apply our algorithm to many problems without making any task-specific\nadjustments. \n\n"}
{"id": "1809.03316", "contents": "Title: Hierarchical Video Understanding Abstract: We introduce a hierarchical architecture for video understanding that\nexploits the structure of real world actions by capturing targets at different\nlevels of granularity. We design the model such that it first learns simpler\ncoarse-grained tasks, and then moves on to learn more fine-grained targets. The\nmodel is trained with a joint loss on different granularity levels. We\ndemonstrate empirical results on the recent release of Something-Something\ndataset, which provides a hierarchy of targets, namely coarse-grained action\ngroups, fine-grained action categories, and captions. Experiments suggest that\nmodels that exploit targets at different levels of granularity achieve better\nperformance on all levels. \n\n"}
{"id": "1809.03322", "contents": "Title: Guiding the Creation of Deep Learning-based Object Detectors Abstract: Object detection is a computer vision field that has applications in several\ncontexts ranging from biomedicine and agriculture to security. In the last\nyears, several deep learning techniques have greatly improved object detection\nmodels. Among those techniques, we can highlight the YOLO approach, that allows\nthe construction of accurate models that can be employed in real-time\napplications. However, as most deep learning techniques, YOLO has a steep\nlearning curve and creating models using this approach might be challenging for\nnon-expert users. In this work, we tackle this problem by constructing a suite\nof Jupyter notebooks that democratizes the construction of object detection\nmodels using YOLO. The suitability of our approach has been proven with a\ndataset of stomata images where we have achieved a mAP of 90.91%. \n\n"}
{"id": "1809.03368", "contents": "Title: Probabilistic Binary Neural Networks Abstract: Low bit-width weights and activations are an effective way of combating the\nincreasing need for both memory and compute power of Deep Neural Networks. In\nthis work, we present a probabilistic training method for Neural Network with\nboth binary weights and activations, called BLRNet. By embracing stochasticity\nduring training, we circumvent the need to approximate the gradient of\nnon-differentiable functions such as sign(), while still obtaining a fully\nBinary Neural Network at test time. Moreover, it allows for anytime ensemble\npredictions for improved performance and uncertainty estimates by sampling from\nthe weight distribution. Since all operations in a layer of the BLRNet operate\non random variables, we introduce stochastic versions of Batch Normalization\nand max pooling, which transfer well to a deterministic network at test time.\nWe evaluate the BLRNet on multiple standardized benchmarks. \n\n"}
{"id": "1809.03497", "contents": "Title: A Correlation Maximization Approach for Cross Domain Co-Embeddings Abstract: Although modern recommendation systems can exploit the structure in users'\nitem feedback, most are powerless in the face of new users who provide no\nstructure for them to exploit. In this paper we introduce ImplicitCE, an\nalgorithm for recommending items to new users during their sign-up flow.\nImplicitCE works by transforming users' implicit feedback towards auxiliary\ndomain items into an embedding in the target domain item embedding space.\nImplicitCE learns these embedding spaces and transformation function in an\nend-to-end fashion and can co-embed users and items with any differentiable\nsimilarity function. To train ImplicitCE we explore methods for maximizing the\ncorrelations between model predictions and users' affinities and introduce\nSample Correlation Update, a novel and extremely simple training strategy.\nFinally, we show that ImplicitCE trained with Sample Correlation Update\noutperforms a variety of state of the art algorithms and loss functions on both\na large scale Twitter dataset and the DBLP dataset. \n\n"}
{"id": "1809.03548", "contents": "Title: VPE: Variational Policy Embedding for Transfer Reinforcement Learning Abstract: Reinforcement Learning methods are capable of solving complex problems, but\nresulting policies might perform poorly in environments that are even slightly\ndifferent. In robotics especially, training and deployment conditions often\nvary and data collection is expensive, making retraining undesirable.\nSimulation training allows for feasible training times, but on the other hand\nsuffers from a reality-gap when applied in real-world settings. This raises the\nneed of efficient adaptation of policies acting in new environments. We\nconsider this as a problem of transferring knowledge within a family of similar\nMarkov decision processes.\n  For this purpose we assume that Q-functions are generated by some\nlow-dimensional latent variable. Given such a Q-function, we can find a master\npolicy that can adapt given different values of this latent variable. Our\nmethod learns both the generative mapping and an approximate posterior of the\nlatent variables, enabling identification of policies for new tasks by\nsearching only in the latent space, rather than the space of all policies. The\nlow-dimensional space, and master policy found by our method enables policies\nto quickly adapt to new environments. We demonstrate the method on both a\npendulum swing-up task in simulation, and for simulation-to-real transfer on a\npushing task. \n\n"}
{"id": "1809.04208", "contents": "Title: Convolutional Neural Network Approach for EEG-based Emotion Recognition\n  using Brain Connectivity and its Spatial Information Abstract: Emotion recognition based on electroencephalography (EEG) has received\nattention as a way to implement human-centric services. However, there is still\nmuch room for improvement, particularly in terms of the recognition accuracy.\nIn this paper, we propose a novel deep learning approach using convolutional\nneural networks (CNNs) for EEG-based emotion recognition. In particular, we\nemploy brain connectivity features that have not been used with deep learning\nmodels in previous studies, which can account for synchronous activations of\ndifferent brain regions. In addition, we develop a method to effectively\ncapture asymmetric brain activity patterns that are important for emotion\nrecognition. Experimental results confirm the effectiveness of our approach. \n\n"}
{"id": "1809.05096", "contents": "Title: Negative Update Intervals in Deep Multi-Agent Reinforcement Learning Abstract: In Multi-Agent Reinforcement Learning (MA-RL), independent cooperative\nlearners must overcome a number of pathologies to learn optimal joint policies.\nAddressing one pathology often leaves approaches vulnerable towards others. For\ninstance, hysteretic Q-learning addresses miscoordination while leaving agents\nvulnerable towards misleading stochastic rewards. Other methods, such as\nleniency, have proven more robust when dealing with multiple pathologies\nsimultaneously. However, leniency has predominately been studied within the\ncontext of strategic form games (bimatrix games) and fully observable Markov\ngames consisting of a small number of probabilistic state transitions. This\nraises the question of whether these findings scale to more complex domains.\nFor this purpose we implement a temporally extend version of the Climb Game,\nwithin which agents must overcome multiple pathologies simultaneously,\nincluding relative overgeneralisation, stochasticity, the alter-exploration and\nmoving target problems, while learning from a large observation space. We find\nthat existing lenient and hysteretic approaches fail to consistently learn near\noptimal joint-policies in this environment. To address these pathologies we\nintroduce Negative Update Intervals-DDQN (NUI-DDQN), a Deep MA-RL algorithm\nwhich discards episodes yielding cumulative rewards outside the range of\nexpanding intervals. NUI-DDQN consistently gravitates towards optimal\njoint-policies in our environment, overcoming the outlined pathologies. \n\n"}
{"id": "1809.05139", "contents": "Title: Choosing to Rank Abstract: Ranking data arises in a wide variety of application areas but remains\ndifficult to model, learn from, and predict. Datasets often exhibit\nmultimodality, intransitivity, or incomplete rankings---particularly when\ngenerated by humans---yet popular probabilistic models are often too rigid to\ncapture such complexities. In this work we leverage recent progress on similar\nchallenges in discrete choice modeling to form flexible and tractable\nchoice-based models for ranking data. We study choice representations, maps\nfrom rankings (complete or top-$k$) to collections of choices, as a way of\nforming ranking models from choice models. We focus on the repeated selection\n(RS) choice representation, first used to form the Plackett-Luce ranking model\nfrom the conditional multinomial logit choice model. We fully characterize, for\na prime number of alternatives, the choice representations that admit ranking\ndistributions with unit normalization, a desirably property that greatly\nsimplifies maximum likelihood estimation. We further show that only specific\nminor variations on repeated selection exhibit this property. Our choice-based\nranking models provide higher out-of-sample likelihood when compared to\nPlackett-Luce and Mallows models on a broad collection of ranking tasks\nincluding food preferences, ranked-choice elections, car racing, and search\nengine relevance tasks. \n\n"}
{"id": "1809.05259", "contents": "Title: Random Warping Series: A Random Features Method for Time-Series\n  Embedding Abstract: Time series data analytics has been a problem of substantial interests for\ndecades, and Dynamic Time Warping (DTW) has been the most widely adopted\ntechnique to measure dissimilarity between time series. A number of\nglobal-alignment kernels have since been proposed in the spirit of DTW to\nextend its use to kernel-based estimation method such as support vector\nmachine. However, those kernels suffer from diagonal dominance of the Gram\nmatrix and a quadratic complexity w.r.t. the sample size. In this work, we\nstudy a family of alignment-aware positive definite (p.d.) kernels, with its\nfeature embedding given by a distribution of \\emph{Random Warping Series\n(RWS)}. The proposed kernel does not suffer from the issue of diagonal\ndominance while naturally enjoys a \\emph{Random Features} (RF) approximation,\nwhich reduces the computational complexity of existing DTW-based techniques\nfrom quadratic to linear in terms of both the number and the length of\ntime-series. We also study the convergence of the RF approximation for the\ndomain of time series of unbounded length. Our extensive experiments on 16\nbenchmark datasets demonstrate that RWS outperforms or matches state-of-the-art\nclassification and clustering methods in both accuracy and computational time.\nOur code and data is available at {\n\\url{https://github.com/IBM/RandomWarpingSeries}}. \n\n"}
{"id": "1809.05650", "contents": "Title: Detecting and Explaining Drifts in Yearly Grant Applications Abstract: During the lifetime of a Business Process changes can be made to the\nworkflow, the required resources, required documents, . . . . Different traces\nfrom the same Business Process within a single log file can thus differ\nsubstantially due to these changes. We propose a method that is able to detect\nconcept drift in multivariate log files with a dozen attributes. We test our\napproach on the BPI Challenge 2018 data con- sisting of applications for EU\ndirect payment from farmers in Germany where we use it to detect Concept Drift.\nIn contrast to other methods our algorithm does not require the manual\nselection of the features used to detect drift. Our method first creates a\nmodel that captures the re- lations between attributes and between events of\ndifferent time steps. This model is then used to score every event and trace.\nThese scores can be used to detect outlying cases and concept drift. Thanks to\nthe decomposability of the score we are able to perform detailed root-cause\nanalysis. \n\n"}
{"id": "1809.05884", "contents": "Title: Multi-Label Image Classification via Knowledge Distillation from\n  Weakly-Supervised Detection Abstract: Multi-label image classification is a fundamental but challenging task\ntowards general visual understanding. Existing methods found the region-level\ncues (e.g., features from RoIs) can facilitate multi-label classification.\nNevertheless, such methods usually require laborious object-level annotations\n(i.e., object labels and bounding boxes) for effective learning of the\nobject-level visual features. In this paper, we propose a novel and efficient\ndeep framework to boost multi-label classification by distilling knowledge from\nweakly-supervised detection task without bounding box annotations.\nSpecifically, given the image-level annotations, (1) we first develop a\nweakly-supervised detection (WSD) model, and then (2) construct an end-to-end\nmulti-label image classification framework augmented by a knowledge\ndistillation module that guides the classification model by the WSD model\naccording to the class-level predictions for the whole image and the\nobject-level visual features for object RoIs. The WSD model is the teacher\nmodel and the classification model is the student model. After this cross-task\nknowledge distillation, the performance of the classification model is\nsignificantly improved and the efficiency is maintained since the WSD model can\nbe safely discarded in the test phase. Extensive experiments on two large-scale\ndatasets (MS-COCO and NUS-WIDE) show that our framework achieves superior\nperformances over the state-of-the-art methods on both performance and\nefficiency. \n\n"}
{"id": "1809.06019", "contents": "Title: Statistically and Computationally Efficient Variance Estimator for\n  Kernel Ridge Regression Abstract: In this paper, we propose a random projection approach to estimate variance\nin kernel ridge regression. Our approach leads to a consistent estimator of the\ntrue variance, while being computationally more efficient. Our variance\nestimator is optimal for a large family of kernels, including cubic splines and\nGaussian kernels. Simulation analysis is conducted to support our theory. \n\n"}
{"id": "1809.06213", "contents": "Title: Context-Dependent Diffusion Network for Visual Relationship Detection Abstract: Visual relationship detection can bridge the gap between computer vision and\nnatural language for scene understanding of images. Different from pure object\nrecognition tasks, the relation triplets of subject-predicate-object lie on an\nextreme diversity space, such as \\textit{person-behind-person} and\n\\textit{car-behind-building}, while suffering from the problem of combinatorial\nexplosion. In this paper, we propose a context-dependent diffusion network\n(CDDN) framework to deal with visual relationship detection. To capture the\ninteractions of different object instances, two types of graphs, word semantic\ngraph and visual scene graph, are constructed to encode global context\ninterdependency. The semantic graph is built through language priors to model\nsemantic correlations across objects, whilst the visual scene graph defines the\nconnections of scene objects so as to utilize the surrounding scene\ninformation. For the graph-structured data, we design a diffusion network to\nadaptively aggregate information from contexts, which can effectively learn\nlatent representations of visual relationships and well cater to visual\nrelationship detection in view of its isomorphic invariance to graphs.\nExperiments on two widely-used datasets demonstrate that our proposed method is\nmore effective and achieves the state-of-the-art performance. \n\n"}
{"id": "1809.06364", "contents": "Title: Generalizing Across Multi-Objective Reward Functions in Deep\n  Reinforcement Learning Abstract: Many reinforcement-learning researchers treat the reward function as a part\nof the environment, meaning that the agent can only know the reward of a state\nif it encounters that state in a trial run. However, we argue that this is an\nunnecessary limitation and instead, the reward function should be provided to\nthe learning algorithm. The advantage is that the algorithm can then use the\nreward function to check the reward for states that the agent hasn't even\nencountered yet. In addition, the algorithm can simultaneously learn policies\nfor multiple reward functions. For each state, the algorithm would calculate\nthe reward using each of the reward functions and add the rewards to its\nexperience replay dataset. The Hindsight Experience Replay algorithm developed\nby Andrychowicz et al. (2017) does just this, and learns to generalize across a\ndistribution of sparse, goal-based rewards. We extend this algorithm to\nlinearly-weighted, multi-objective rewards and learn a single policy that can\ngeneralize across all linear combinations of the multi-objective reward.\nWhereas other multi-objective algorithms teach the Q-function to generalize\nacross the reward weights, our algorithm enables the policy to generalize, and\ncan thus be used with continuous actions. \n\n"}
{"id": "1809.06573", "contents": "Title: Runtime Monitoring Neuron Activation Patterns Abstract: For using neural networks in safety critical domains, it is important to know\nif a decision made by a neural network is supported by prior similarities in\ntraining. We propose runtime neuron activation pattern monitoring - after the\nstandard training process, one creates a monitor by feeding the training data\nto the network again in order to store the neuron activation patterns in\nabstract form. In operation, a classification decision over an input is further\nsupplemented by examining if a pattern similar (measured by Hamming distance)\nto the generated pattern is contained in the monitor. If the monitor does not\ncontain any pattern similar to the generated pattern, it raises a warning that\nthe decision is not based on the training data. Our experiments show that, by\nadjusting the similarity-threshold for activation patterns, the monitors can\nreport a significant portion of misclassfications to be not supported by\ntraining with a small false-positive rate, when evaluated on a test set. \n\n"}
{"id": "1809.07258", "contents": "Title: DPPy: Sampling DPPs with Python Abstract: Determinantal point processes (DPPs) are specific probability distributions\nover clouds of points that are used as models and computational tools across\nphysics, probability, statistics, and more recently machine learning. Sampling\nfrom DPPs is a challenge and therefore we present DPPy, a Python toolbox that\ngathers known exact and approximate sampling algorithms for both finite and\ncontinuous DPPs. The project is hosted on GitHub and equipped with an extensive\ndocumentation. \n\n"}
{"id": "1809.07952", "contents": "Title: Refining Coarse-grained Spatial Data using Auxiliary Spatial Data Sets\n  with Various Granularities Abstract: We propose a probabilistic model for refining coarse-grained spatial data by\nutilizing auxiliary spatial data sets. Existing methods require that the\nspatial granularities of the auxiliary data sets are the same as the desired\ngranularity of target data. The proposed model can effectively make use of\nauxiliary data sets with various granularities by hierarchically incorporating\nGaussian processes. With the proposed model, a distribution for each auxiliary\ndata set on the continuous space is modeled using a Gaussian process, where the\nrepresentation of uncertainty considers the levels of granularity. The\nfine-grained target data are modeled by another Gaussian process that considers\nboth the spatial correlation and the auxiliary data sets with their\nuncertainty. We integrate the Gaussian process with a spatial aggregation\nprocess that transforms the fine-grained target data into the coarse-grained\ntarget data, by which we can infer the fine-grained target Gaussian process\nfrom the coarse-grained data. Our model is designed such that the inference of\nmodel parameters based on the exact marginal likelihood is possible, in which\nthe variables of fine-grained target and auxiliary data are analytically\nintegrated out. Our experiments on real-world spatial data sets demonstrate the\neffectiveness of the proposed model. \n\n"}
{"id": "1809.08846", "contents": "Title: Vis-DSS: An Open-Source toolkit for Visual Data Selection and\n  Summarization Abstract: With increasing amounts of visual data being created in the form of videos\nand images, visual data selection and summarization are becoming ever\nincreasing problems. We present Vis-DSS, an open-source toolkit for Visual Data\nSelection and Summarization. Vis-DSS implements a framework of models for\nsummarization and data subset selection using submodular functions, which are\nbecoming increasingly popular today for these problems. We present several\nclasses of models, capturing notions of diversity, coverage, representation and\nimportance, along with optimization/inference and learning algorithms. Vis-DSS\nis the first open source toolkit for several Data selection and summarization\ntasks including Image Collection Summarization, Video Summarization, Training\nData selection for Classification and Diversified Active Learning. We\ndemonstrate state-of-the art performance on all these tasks, and also show how\nwe can scale to large problems. Vis-DSS allows easy integration for\napplications to be built on it, also can serve as a general skeleton that can\nbe extended to several use cases, including video and image sharing platforms\nfor creating GIFs, image montage creation, or as a component to surveillance\nsystems and we demonstrate this by providing a graphical user-interface (GUI)\ndesktop app built over Qt framework. Vis-DSS is available at\nhttps://github.com/rishabhk108/vis-dss \n\n"}
{"id": "1809.09582", "contents": "Title: Contextual Bandits with Cross-learning Abstract: In the classical contextual bandits problem, in each round $t$, a learner\nobserves some context $c$, chooses some action $i$ to perform, and receives\nsome reward $r_{i,t}(c)$. We consider the variant of this problem where in\naddition to receiving the reward $r_{i,t}(c)$, the learner also learns the\nvalues of $r_{i,t}(c')$ for some other contexts $c'$ in set $\\mathcal{O}_i(c)$;\ni.e., the rewards that would have been achieved by performing that action under\ndifferent contexts $c'\\in \\mathcal{O}_i(c)$. This variant arises in several\nstrategic settings, such as learning how to bid in non-truthful repeated\nauctions, which has gained a lot of attention lately as many platforms have\nswitched to running first-price auctions. We call this problem the contextual\nbandits problem with cross-learning. The best algorithms for the classical\ncontextual bandits problem achieve $\\tilde{O}(\\sqrt{CKT})$ regret against all\nstationary policies, where $C$ is the number of contexts, $K$ the number of\nactions, and $T$ the number of rounds. We design and analyze new algorithms for\nthe contextual bandits problem with cross-learning and show that their regret\nhas better dependence on the number of contexts. Under complete cross-learning\nwhere the rewards for all contexts are learned when choosing an action, i.e.,\nset $\\mathcal{O}_i(c)$ contains all contexts, we show that our algorithms\nachieve regret $\\tilde{O}(\\sqrt{KT})$, removing the dependence on $C$. For any\nother cases, i.e., under partial cross-learning where $|\\mathcal{O}_i(c)|< C$\nfor some context-action pair of $(i,c)$, the regret bounds depend on how the\nsets $\\mathcal O_i(c)$ impact the degree to which cross-learning between\ncontexts is possible. We simulate our algorithms on real auction data from an\nad exchange running first-price auctions and show that they outperform\ntraditional contextual bandit algorithms. \n\n"}
{"id": "1809.09621", "contents": "Title: Inferring Complementary Products from Baskets and Browsing Sessions Abstract: Complementary products recommendation is an important problem in e-commerce.\nSuch recommendations increase the average order price and the number of\nproducts in baskets. Complementary products are typically inferred from basket\ndata. In this study, we propose the BB2vec model. The BB2vec model learns\nvector representations of products by analyzing jointly two types of data -\nBaskets and Browsing sessions (visiting web pages of products). These vector\nrepresentations are used for making complementary products recommendation. The\nproposed model alleviates the cold start problem by delivering better\nrecommendations for products having few or no purchases. We show that the\nBB2vec model has better performance than other models which use only basket\ndata. \n\n"}
{"id": "1809.10073", "contents": "Title: Rediscovering Deep Neural Networks Through Finite-State Distributions Abstract: We propose a new way of thinking about deep neural networks, in which the\nlinear and non-linear components of the network are naturally derived and\njustified in terms of principles in probability theory. In particular, the\nmodels constructed in our framework assign probabilities to uncertain\nrealizations, leading to Kullback-Leibler Divergence (KLD) as the linear layer.\nIn our model construction, we also arrive at a structure similar to ReLU\nactivation supported with Bayes' theorem. The non-linearities in our framework\nare normalization layers with ReLU and Sigmoid as element-wise approximations.\nAdditionally, the pooling function is derived as a marginalization of spatial\nrandom variables according to the mechanics of the framework. As such, Max\nPooling is an approximation to the aforementioned marginalization process.\nSince our models are comprised of finite state distributions (FSD) as variables\nand parameters, exact computation of information-theoretic quantities such as\nentropy and KLD is possible, thereby providing more objective measures to\nanalyze networks. Unlike existing designs that rely on heuristics, the proposed\nframework restricts subjective interpretations of CNNs and sheds light on the\nfunctionality of neural networks from a completely new perspective. \n\n"}
{"id": "1809.10093", "contents": "Title: Pay attention! - Robustifying a Deep Visuomotor Policy through\n  Task-Focused Attention Abstract: Several recent studies have demonstrated the promise of deep visuomotor\npolicies for robot manipulator control. Despite impressive progress, these\nsystems are known to be vulnerable to physical disturbances, such as accidental\nor adversarial bumps that make them drop the manipulated object. They also tend\nto be distracted by visual disturbances such as objects moving in the robot's\nfield of view, even if the disturbance does not physically prevent the\nexecution of the task. In this paper, we propose an approach for augmenting a\ndeep visuomotor policy trained through demonstrations with Task Focused visual\nAttention (TFA). The manipulation task is specified with a natural language\ntext such as `move the red bowl to the left'. This allows the visual attention\ncomponent to concentrate on the current object that the robot needs to\nmanipulate. We show that even in benign environments, the TFA allows the policy\nto consistently outperform a variant with no attention mechanism. More\nimportantly, the new policy is significantly more robust: it regularly recovers\nfrom severe physical disturbances (such as bumps causing it to drop the object)\nfrom which the baseline policy, i.e. with no visual attention, almost never\nrecovers. In addition, we show that the proposed policy performs correctly in\nthe presence of a wide class of visual disturbances, exhibiting a behavior\nreminiscent of human selective visual attention experiments. Our proposed\napproach consists of a VAE-GAN network which encodes the visual input and feeds\nit to a Motor network that moves the robot joints. Also, our approach benefits\nfrom a teacher network for the TFA that leverages textual input command to\nrobustify the visual encoder against various types of disturbances. \n\n"}
{"id": "1809.10610", "contents": "Title: Counterfactual Fairness in Text Classification through Robustness Abstract: In this paper, we study counterfactual fairness in text classification, which\nasks the question: How would the prediction change if the sensitive attribute\nreferenced in the example were different? Toxicity classifiers demonstrate a\ncounterfactual fairness issue by predicting that \"Some people are gay\" is toxic\nwhile \"Some people are straight\" is nontoxic. We offer a metric, counterfactual\ntoken fairness (CTF), for measuring this particular form of fairness in text\nclassifiers, and describe its relationship with group fairness. Further, we\noffer three approaches, blindness, counterfactual augmentation, and\ncounterfactual logit pairing (CLP), for optimizing counterfactual token\nfairness during training, bridging the robustness and fairness literature.\nEmpirically, we find that blindness and CLP address counterfactual token\nfairness. The methods do not harm classifier performance, and have varying\ntradeoffs with group fairness. These approaches, both for measurement and\noptimization, provide a new path forward for addressing fairness concerns in\ntext classification. \n\n"}
{"id": "1809.10804", "contents": "Title: Patient Risk Assessment and Warning Symptom Detection Using Deep\n  Attention-Based Neural Networks Abstract: We present an operational component of a real-world patient triage system.\nGiven a specific patient presentation, the system is able to assess the level\nof medical urgency and issue the most appropriate recommendation in terms of\nbest point of care and time to treat. We use an attention-based convolutional\nneural network architecture trained on 600,000 doctor notes in German. We\ncompare two approaches, one that uses the full text of the medical notes and\none that uses only a selected list of medical entities extracted from the text.\nThese approaches achieve 79% and 66% precision, respectively, but on a\nconfidence threshold of 0.6, precision increases to 85% and 75%, respectively.\nIn addition, a method to detect warning symptoms is implemented to render the\nclassification task transparent from a medical perspective. The method is based\non the learning of attention scores and a method of automatic validation using\nthe same data. \n\n"}
{"id": "1810.00031", "contents": "Title: Active Fairness in Algorithmic Decision Making Abstract: Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Recent work has\nproposed optimal post-processing methods that randomize classification\ndecisions for a fraction of individuals, in order to achieve fairness measures\nrelated to parity in errors and calibration. These methods, however, have\nraised concern due to the information inefficiency, intra-group unfairness, and\nPareto sub-optimality they entail. The present work proposes an alternative\nactive framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that by\nleveraging their additional degree of freedom, active approaches can\nsubstantially outperform randomization-based classifiers previously considered\noptimal, while avoiding limitations such as intra-group unfairness. \n\n"}
{"id": "1810.00068", "contents": "Title: Differentially Private Contextual Linear Bandits Abstract: We study the contextual linear bandit problem, a version of the standard\nstochastic multi-armed bandit (MAB) problem where a learner sequentially\nselects actions to maximize a reward which depends also on a user provided\nper-round context. Though the context is chosen arbitrarily or adversarially,\nthe reward is assumed to be a stochastic function of a feature vector that\nencodes the context and selected action. Our goal is to devise private learners\nfor the contextual linear bandit problem.\n  We first show that using the standard definition of differential privacy\nresults in linear regret. So instead, we adopt the notion of joint differential\nprivacy, where we assume that the action chosen on day $t$ is only revealed to\nuser $t$ and thus needn't be kept private that day, only on following days. We\ngive a general scheme converting the classic linear-UCB algorithm into a joint\ndifferentially private algorithm using the tree-based algorithm. We then apply\neither Gaussian noise or Wishart noise to achieve joint-differentially private\nalgorithms and bound the resulting algorithms' regrets. In addition, we give\nthe first lower bound on the additional regret any private algorithms for the\nMAB problem must incur. \n\n"}
{"id": "1810.00337", "contents": "Title: Learning to Perform Local Rewriting for Combinatorial Optimization Abstract: Search-based methods for hard combinatorial optimization are often guided by\nheuristics. Tuning heuristics in various conditions and situations is often\ntime-consuming. In this paper, we propose NeuRewriter that learns a policy to\npick heuristics and rewrite the local components of the current solution to\niteratively improve it until convergence. The policy factorizes into a\nregion-picking and a rule-picking component, each parameterized by a neural\nnetwork trained with actor-critic methods in reinforcement learning.\nNeuRewriter captures the general structure of combinatorial problems and shows\nstrong performance in three versatile tasks: expression simplification, online\njob scheduling and vehicle routing problems. NeuRewriter outperforms the\nexpression simplification component in Z3; outperforms DeepRM and Google\nOR-tools in online job scheduling; and outperforms recent neural baselines and\nGoogle OR-tools in vehicle routing problems. \n\n"}
{"id": "1810.00861", "contents": "Title: ProxQuant: Quantized Neural Networks via Proximal Operators Abstract: To make deep neural networks feasible in resource-constrained environments\n(such as mobile devices), it is beneficial to quantize models by using\nlow-precision weights. One common technique for quantizing neural networks is\nthe straight-through gradient method, which enables back-propagation through\nthe quantization mapping. Despite its empirical success, little is understood\nabout why the straight-through gradient method works.\n  Building upon a novel observation that the straight-through gradient method\nis in fact identical to the well-known Nesterov's dual-averaging algorithm on a\nquantization constrained optimization problem, we propose a more principled\nalternative approach, called ProxQuant, that formulates quantized network\ntraining as a regularized learning problem instead and optimizes it via the\nprox-gradient method. ProxQuant does back-propagation on the underlying\nfull-precision vector and applies an efficient prox-operator in between\nstochastic gradient steps to encourage quantizedness. For quantizing ResNets\nand LSTMs, ProxQuant outperforms state-of-the-art results on binary\nquantization and is on par with state-of-the-art on multi-bit quantization. For\nbinary quantization, our analysis shows both theoretically and experimentally\nthat ProxQuant is more stable than the straight-through gradient method (i.e.\nBinaryConnect), challenging the indispensability of the straight-through\ngradient method and providing a powerful alternative. \n\n"}
{"id": "1810.00956", "contents": "Title: Challenges of Using Text Classifiers for Causal Inference Abstract: Causal understanding is essential for many kinds of decision-making, but\ncausal inference from observational data has typically only been applied to\nstructured, low-dimensional datasets. While text classifiers produce\nlow-dimensional outputs, their use in causal inference has not previously been\nstudied. To facilitate causal analyses based on language data, we consider the\nrole that text classifiers can play in causal inference through established\nmodeling mechanisms from the causality literature on missing data and\nmeasurement error. We demonstrate how to conduct causal analyses using text\nclassifiers on simulated and Yelp data, and discuss the opportunities and\nchallenges of future work that uses text data in causal inference. \n\n"}
{"id": "1810.00997", "contents": "Title: A simple parameter-free and adaptive approach to optimization under a\n  minimal local smoothness assumption Abstract: We study the problem of optimizing a function under a \\emph{budgeted number\nof evaluations}. We only assume that the function is \\emph{locally} smooth\naround one of its global optima. The difficulty of optimization is measured in\nterms of 1) the amount of \\emph{noise} $b$ of the function evaluation and 2)\nthe local smoothness, $d$, of the function. A smaller $d$ results in smaller\noptimization error. We come with a new, simple, and parameter-free approach.\nFirst, for all values of $b$ and $d$, this approach recovers at least the\nstate-of-the-art regret guarantees. Second, our approach additionally obtains\nthese results while being \\textit{agnostic} to the values of both $b$ and $d$.\nThis leads to the first algorithm that naturally adapts to an \\textit{unknown}\nrange of noise $b$ and leads to significant improvements in a moderate and\nlow-noise regime. Third, our approach also obtains a remarkable improvement\nover the state-of-the-art SOO algorithm when the noise is very low which\nincludes the case of optimization under deterministic feedback ($b=0$). There,\nunder our minimal local smoothness assumption, this improvement is of\nexponential magnitude and holds for a class of functions that covers the vast\nmajority of functions that practitioners optimize ($d=0$). We show that our\nalgorithmic improvement is borne out in experiments as we empirically show\nfaster convergence on common benchmarks. \n\n"}
{"id": "1810.01765", "contents": "Title: Predicting Factuality of Reporting and Bias of News Media Sources Abstract: We present a study on predicting the factuality of reporting and bias of news\nmedia. While previous work has focused on studying the veracity of claims or\ndocuments, here we are interested in characterizing entire news media. These\nare under-studied but arguably important research problems, both in their own\nright and as a prior for fact-checking systems. We experiment with a large list\nof news websites and with a rich set of features derived from (i) a sample of\narticles from the target news medium, (ii) its Wikipedia page, (iii) its\nTwitter account, (iv) the structure of its URL, and (v) information about the\nWeb traffic it attracts. The experimental results show sizable performance\ngains over the baselines, and confirm the importance of each feature type. \n\n"}
{"id": "1810.02030", "contents": "Title: Robust Estimation and Generative Adversarial Nets Abstract: Robust estimation under Huber's $\\epsilon$-contamination model has become an\nimportant topic in statistics and theoretical computer science. Statistically\noptimal procedures such as Tukey's median and other estimators based on depth\nfunctions are impractical because of their computational intractability. In\nthis paper, we establish an intriguing connection between $f$-GANs and various\ndepth functions through the lens of $f$-Learning. Similar to the derivation of\n$f$-GANs, we show that these depth functions that lead to statistically optimal\nrobust estimators can all be viewed as variational lower bounds of the total\nvariation distance in the framework of $f$-Learning. This connection opens the\ndoor of computing robust estimators using tools developed for training GANs. In\nparticular, we show in both theory and experiments that some appropriate\nstructures of discriminator networks with hidden layers in GANs lead to\nstatistically optimal robust location estimators for both Gaussian distribution\nand general elliptical distributions where first moment may not exist. \n\n"}
{"id": "1810.02069", "contents": "Title: Finding Solutions to Generative Adversarial Privacy Abstract: We present heuristics for solving the maximin problem induced by the\ngenerative adversarial privacy setting for linear and convolutional neural\nnetwork (CNN) adversaries. In the linear adversary setting, we present a greedy\nalgorithm for approximating the optimal solution for the privatizer, which\nperforms better as the number of instances increases. We also provide an\nanalysis of the algorithm to show that it not only removes the features most\ncorrelated with the private label first, but also preserves the prediction\naccuracy of public labels that are sufficiently independent of the features\nthat are relevant to the private label. In the CNN adversary setting, we\npresent a method of hiding selected information from the adversary while\npreserving the others through alternately optimizing the goals of the\nprivatizer and the adversary using neural network backpropagation. We\nexperimentally show that our method succeeds on a fixed adversary. \n\n"}
{"id": "1810.02225", "contents": "Title: Memristor-based Deep Convolution Neural Network: A Case Study Abstract: In this paper, we firstly introduce a method to efficiently implement\nlarge-scale high-dimensional convolution with realistic memristor-based circuit\ncomponents. An experiment verified simulator is adapted for accurate prediction\nof analog crossbar behavior. An improved conversion algorithm is developed to\nconvert convolution kernels to memristor-based circuits, which minimizes the\nerror with consideration of the data and kernel patterns in CNNs. With circuit\nsimulation for all convolution layers in ResNet-20, we found that 8-bit ADC/DAC\nis necessary to preserve software level classification accuracy. \n\n"}
{"id": "1810.02789", "contents": "Title: Doubly Semi-Implicit Variational Inference Abstract: We extend the existing framework of semi-implicit variational inference\n(SIVI) and introduce doubly semi-implicit variational inference (DSIVI), a way\nto perform variational inference and learning when both the approximate\nposterior and the prior distribution are semi-implicit. In other words, DSIVI\nperforms inference in models where the prior and the posterior can be expressed\nas an intractable infinite mixture of some analytic density with a highly\nflexible implicit mixing distribution. We provide a sandwich bound on the\nevidence lower bound (ELBO) objective that can be made arbitrarily tight.\nUnlike discriminator-based and kernel-based approaches to implicit variational\ninference, DSIVI optimizes a proper lower bound on ELBO that is asymptotically\nexact. We evaluate DSIVI on a set of problems that benefit from implicit\npriors. In particular, we show that DSIVI gives rise to a simple modification\nof VampPrior, the current state-of-the-art prior for variational autoencoders,\nwhich improves its performance. \n\n"}
{"id": "1810.02810", "contents": "Title: Linear Queries Estimation with Local Differential Privacy Abstract: We study the problem of estimating a set of $d$ linear queries with respect\nto some unknown distribution $\\mathbf{p}$ over a domain $\\mathcal{J}=[J]$ based\non a sensitive data set of $n$ individuals under the constraint of local\ndifferential privacy. This problem subsumes a wide range of estimation tasks,\ne.g., distribution estimation and $d$-dimensional mean estimation. We provide\nnew algorithms for both the offline (non-adaptive) and adaptive versions of\nthis problem.\n  In the offline setting, the set of queries are fixed before the algorithm\nstarts. In the regime where $n\\lesssim d^2/\\log(J)$, our algorithms attain\n$L_2$ estimation error that is independent of $d$, and is tight up to a factor\nof $\\tilde{O}\\left(\\log^{1/4}(J)\\right)$. For the special case of distribution\nestimation, we show that projecting the output estimate of an algorithm due to\n[Acharya et al. 2018] on the probability simplex yields an $L_2$ error that\ndepends only sub-logarithmically on $J$ in the regime where $n\\lesssim\nJ^2/\\log(J)$. These results show the possibility of accurate estimation of\nlinear queries in the high-dimensional settings under the $L_2$ error\ncriterion.\n  In the adaptive setting, the queries are generated over $d$ rounds; one query\nat a time. In each round, a query can be chosen adaptively based on all the\nhistory of previous queries and answers. We give an algorithm for this problem\nwith optimal $L_{\\infty}$ estimation error (worst error in the estimated values\nfor the queries w.r.t. the data distribution). Our bound matches a lower bound\non the $L_{\\infty}$ error for the offline version of this problem [Duchi et al.\n2013]. \n\n"}
{"id": "1810.02923", "contents": "Title: Adaptive Geo-Topological Independence Criterion Abstract: Testing two potentially multivariate variables for statistical dependence on\nthe basis finite samples is a fundamental statistical challenge. Here we\nexplore a family of tests that adapt to the complexity of the relationship\nbetween the variables, promising robust power across scenarios. Building on the\ndistance correlation, we introduce a family of adaptive independence criteria\nbased on nonlinear monotonic transformations of distances. We show that these\ncriteria, like the distance correlation and RKHS-based criteria, provide\ndependence indicators. We propose a class of adaptive (multi-threshold) test\nstatistics, which form the basis for permutation tests. These tests empirically\noutperform some of the established tests in average and worst-case statistical\nsensitivity across a range of univariate and multivariate relationships, offer\nuseful insights to the data and may deserve further exploration. \n\n"}
{"id": "1810.03642", "contents": "Title: Fast Context Adaptation via Meta-Learning Abstract: We propose CAVIA for meta-learning, a simple extension to MAML that is less\nprone to meta-overfitting, easier to parallelise, and more interpretable. CAVIA\npartitions the model parameters into two parts: context parameters that serve\nas additional input to the model and are adapted on individual tasks, and\nshared parameters that are meta-trained and shared across tasks. At test time,\nonly the context parameters are updated, leading to a low-dimensional task\nrepresentation. We show empirically that CAVIA outperforms MAML for regression,\nclassification, and reinforcement learning. Our experiments also highlight\nweaknesses in current benchmarks, in that the amount of adaptation needed in\nsome cases is small. \n\n"}
{"id": "1810.03783", "contents": "Title: Unsupervised Online Video Object Segmentation with Motion Property\n  Understanding Abstract: Unsupervised video object segmentation aims to automatically segment moving\nobjects over an unconstrained video without any user annotation. So far, only\nfew unsupervised online methods have been reported in literature and their\nperformance is still far from satisfactory, because the complementary\ninformation from future frames cannot be processed under online setting. To\nsolve this challenging problem, in this paper, we propose a novel Unsupervised\nOnline Video Object Segmentation (UOVOS) framework by construing the motion\nproperty to mean moving in concurrence with a generic object for segmented\nregions. By incorporating salient motion detection and object proposal, a\npixel-wise fusion strategy is developed to effectively remove detection noise\nsuch as dynamic background and stationary objects. Furthermore, by leveraging\nthe obtained segmentation from immediately preceding frames, a forward\npropagation algorithm is employed to deal with unreliable motion detection and\nobject proposals. Experimental results on several benchmark datasets\ndemonstrate the efficacy of the proposed method. Compared to the\nstate-of-the-art unsupervised online segmentation algorithms, the proposed\nmethod achieves an absolute gain of 6.2%. Moreover, our method achieves better\nperformance than the best unsupervised offline algorithm on the DAVIS-2016\nbenchmark dataset. Our code is available on the project website:\nhttps://github.com/visiontao/uovos. \n\n"}
{"id": "1810.04966", "contents": "Title: How does an incomplete sky coverage affect the Hubble Constant variance? Abstract: We address the $\\simeq 4.4\\sigma$ tension between local and the CMB\nmeasurements of the Hubble Constant using simulated Type Ia Supernova (SN)\ndata-sets. We probe its directional dependence by means of a hemispherical\ncomparison through the entire celestial sphere as an estimator of the $H_0$\ncosmic variance. We perform Monte Carlo simulations assuming isotropic and\nnon-uniform distributions of data points, the latter coinciding with the real\ndata. This allows us to incorporate observational features, such as the sample\nincompleteness, in our estimation. We obtain that this tension can be\nalleviated to $3.4\\sigma$ for isotropic realizations, and $2.7\\sigma$ for\nnon-uniform ones. We also find that the $H_0$ variance is largely reduced if\nthe data-sets are augmented to 4 and 10 times the current size. Future surveys\nwill be able to tell whether the Hubble Constant tension happens due to\nunaccounted cosmic variance, or whether it is an actual indication of physics\nbeyond the standard cosmological model. \n\n"}
{"id": "1810.05193", "contents": "Title: Understanding Priors in Bayesian Neural Networks at the Unit Level Abstract: We investigate deep Bayesian neural networks with Gaussian weight priors and\na class of ReLU-like nonlinearities. Bayesian neural networks with Gaussian\npriors are well known to induce an L2, \"weight decay\", regularization. Our\nresults characterize a more intricate regularization effect at the level of the\nunit activations. Our main result establishes that the induced prior\ndistribution on the units before and after activation becomes increasingly\nheavy-tailed with the depth of the layer. We show that first layer units are\nGaussian, second layer units are sub-exponential, and units in deeper layers\nare characterized by sub-Weibull distributions. Our results provide new\ntheoretical insight on deep Bayesian neural networks, which we corroborate with\nsimulation experiments. \n\n"}
{"id": "1810.07168", "contents": "Title: An empirical evaluation of imbalanced data strategies from a\n  practitioner's point of view Abstract: This paper evaluates six strategies for mitigating imbalanced data:\noversampling, undersampling, ensemble methods, specialized algorithms, class\nweight adjustments, and a no-mitigation approach referred to as the baseline.\nThese strategies were tested on 58 real-life binary imbalanced datasets with\nimbalance rates ranging from 3 to 120. We conducted a comparative analysis of\n10 under-sampling algorithms, 5 over-sampling algorithms, 2 ensemble methods,\nand 3 specialized algorithms across eight different performance metrics:\naccuracy, area under the ROC curve (AUC), balanced accuracy, F1-measure,\nG-mean, Matthew's correlation coefficient, precision, and recall. Additionally,\nwe assessed the six strategies on altered datasets, derived from real-life\ndata, with both low (3) and high (100 or 300) imbalance ratios (IR).\n  The principal finding indicates that the effectiveness of each strategy\nsignificantly varies depending on the metric used. The paper also examines a\nselection of newer algorithms within the categories of specialized algorithms,\noversampling, and ensemble methods. The findings suggest that the current\nhierarchy of best-performing strategies for each metric is unlikely to change\nwith the introduction of newer algorithms. \n\n"}
{"id": "1810.07307", "contents": "Title: Solving Tree Problems with Category Theory Abstract: Artificial Intelligence (AI) has long pursued models, theories, and\ntechniques to imbue machines with human-like general intelligence. Yet even the\ncurrently predominant data-driven approaches in AI seem to be lacking humans'\nunique ability to solve wide ranges of problems. This situation begs the\nquestion of the existence of principles that underlie general problem-solving\ncapabilities. We approach this question through the mathematical formulation of\nanalogies across different problems and solutions. We focus in particular on\nproblems that could be represented as tree-like structures. Most importantly,\nwe adopt a category-theoretic approach in formalising tree problems as\ncategories, and in proving the existence of equivalences across apparently\nunrelated problem domains. We prove the existence of a functor between the\ncategory of tree problems and the category of solutions. We also provide a\nweaker version of the functor by quantifying equivalences of problem categories\nusing a metric on tree problems. \n\n"}
{"id": "1810.07743", "contents": "Title: PepCVAE: Semi-Supervised Targeted Design of Antimicrobial Peptide\n  Sequences Abstract: Given the emerging global threat of antimicrobial resistance, new methods for\nnext-generation antimicrobial design are urgently needed. We report a peptide\ngeneration framework PepCVAE, based on a semi-supervised variational\nautoencoder (VAE) model, for designing novel antimicrobial peptide (AMP)\nsequences. Our model learns a rich latent space of the biological peptide\ncontext by taking advantage of abundant, unlabeled peptide sequences. The model\nfurther learns a disentangled antimicrobial attribute space by using the\nfeedback from a jointly trained AMP classifier that uses limited labeled\ninstances. The disentangled representation allows for controllable generation\nof AMPs. Extensive analysis of the PepCVAE-generated sequences reveals superior\nperformance of our model in comparison to a plain VAE, as PepCVAE generates\nnovel AMP sequences with higher long-range diversity, while being closer to the\ntraining distribution of biological peptides. These features are highly desired\nin next-generation antimicrobial design. \n\n"}
{"id": "1810.08076", "contents": "Title: Discourse Embellishment Using a Deep Encoder-Decoder Network Abstract: We suggest a new NLG task in the context of the discourse generation pipeline\nof computational storytelling systems. This task, textual embellishment, is\ndefined by taking a text as input and generating a semantically equivalent\noutput with increased lexical and syntactic complexity. Ideally, this would\nallow the authors of computational storytellers to implement just lightweight\nNLG systems and use a domain-independent embellishment module to translate its\noutput into more literary text. We present promising first results on this task\nusing LSTM Encoder-Decoder networks trained on the WikiLarge dataset.\nFurthermore, we introduce \"Compiled Computer Tales\", a corpus of\ncomputationally generated stories, that can be used to test the capabilities of\nembellishment algorithms. \n\n"}
{"id": "1810.08102", "contents": "Title: First-order and second-order variants of the gradient descent in a\n  unified framework Abstract: In this paper, we provide an overview of first-order and second-order\nvariants of the gradient descent method that are commonly used in machine\nlearning. We propose a general framework in which 6 of these variants can be\ninterpreted as different instances of the same approach. They are the vanilla\ngradient descent, the classical and generalized Gauss-Newton methods, the\nnatural gradient descent method, the gradient covariance matrix approach, and\nNewton's method. Besides interpreting these methods within a single framework,\nwe explain their specificities and show under which conditions some of them\ncoincide. \n\n"}
{"id": "1810.08303", "contents": "Title: Compositional Verification for Autonomous Systems with Deep Learning\n  Components Abstract: As autonomy becomes prevalent in many applications, ranging from\nrecommendation systems to fully autonomous vehicles, there is an increased need\nto provide safety guarantees for such systems. The problem is difficult, as\nthese are large, complex systems which operate in uncertain environments,\nrequiring data-driven machine-learning components. However, learning techniques\nsuch as Deep Neural Networks, widely used today, are inherently unpredictable\nand lack the theoretical foundations to provide strong assurance guarantees. We\npresent a compositional approach for the scalable, formal verification of\nautonomous systems that contain Deep Neural Network components. The approach\nuses assume-guarantee reasoning whereby {\\em contracts}, encoding the\ninput-output behavior of individual components, allow the designer to model and\nincorporate the behavior of the learning-enabled components working\nside-by-side with the other components. We illustrate the approach on an\nexample taken from the autonomous vehicles domain. \n\n"}
{"id": "1810.08351", "contents": "Title: Exchangeability and Kernel Invariance in Trained MLPs Abstract: In the analysis of machine learning models, it is often convenient to assume\nthat the parameters are IID. This assumption is not satisfied when the\nparameters are updated through training processes such as SGD. A relaxation of\nthe IID condition is a probabilistic symmetry known as exchangeability. We show\nthe sense in which the weights in MLPs are exchangeable. This yields the result\nthat in certain instances, the layer-wise kernel of fully-connected layers\nremains approximately constant during training. We identify a sharp change in\nthe macroscopic behavior of networks as the covariance between weights changes\nfrom zero. \n\n"}
{"id": "1810.08646", "contents": "Title: SLAYER: Spike Layer Error Reassignment in Time Abstract: Configuring deep Spiking Neural Networks (SNNs) is an exciting research\navenue for low power spike event based computation. However, the spike\ngeneration function is non-differentiable and therefore not directly compatible\nwith the standard error backpropagation algorithm. In this paper, we introduce\na new general backpropagation mechanism for learning synaptic weights and\naxonal delays which overcomes the problem of non-differentiability of the spike\nfunction and uses a temporal credit assignment policy for backpropagating error\nto preceding layers. We describe and release a GPU accelerated software\nimplementation of our method which allows training both fully connected and\nconvolutional neural network (CNN) architectures. Using our software, we\ncompare our method against existing SNN based learning approaches and standard\nANN to SNN conversion techniques and show that our method achieves state of the\nart performance for an SNN on the MNIST, NMNIST, DVS Gesture, and TIDIGITS\ndatasets. \n\n"}
{"id": "1810.08810", "contents": "Title: The Frontiers of Fairness in Machine Learning Abstract: The last few years have seen an explosion of academic and popular interest in\nalgorithmic fairness. Despite this interest and the volume and velocity of work\nthat has been produced recently, the fundamental science of fairness in machine\nlearning is still in a nascent state. In March 2018, we convened a group of\nexperts as part of a CCC visioning workshop to assess the state of the field,\nand distill the most promising research directions going forward. This report\nsummarizes the findings of that workshop. Along the way, it surveys recent\ntheoretical work in the field and points towards promising directions for\nresearch. \n\n"}
{"id": "1810.09103", "contents": "Title: Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy\n  Improvement Abstract: Many policy gradient methods are variants of Actor-Critic (AC), where a value\nfunction (critic) is learned to facilitate updating the parameterized policy\n(actor). The update to the actor involves a log-likelihood update weighted by\nthe action-values, with the addition of entropy regularization for soft\nvariants. In this work, we explore an alternative update for the actor, based\non an extension of the cross entropy method (CEM) to condition on inputs\n(states). The idea is to start with a broader policy and slowly concentrate\naround maximal actions, using a maximum likelihood update towards actions in\nthe top percentile per state. The speed of this concentration is controlled by\na proposal policy, that concentrates at a slower rate than the actor. We first\nprovide a policy improvement result in an idealized setting, and then prove\nthat our conditional CEM (CCEM) strategy tracks a CEM update per state, even\nwith changing action-values. We empirically show that our Greedy AC algorithm,\nthat uses CCEM for the actor update, performs better than Soft Actor-Critic and\nis much less sensitive to entropy-regularization. \n\n"}
{"id": "1810.09136", "contents": "Title: Do Deep Generative Models Know What They Don't Know? Abstract: A neural network deployed in the wild may be asked to make predictions for\ninputs that were drawn from a different distribution than that of the training\ndata. A plethora of work has demonstrated that it is easy to find or synthesize\ninputs for which a neural network is highly confident yet wrong. Generative\nmodels are widely viewed to be robust to such mistaken confidence as modeling\nthe density of the input features can be used to detect novel,\nout-of-distribution inputs. In this paper we challenge this assumption. We find\nthat the density learned by flow-based models, VAEs, and PixelCNNs cannot\ndistinguish images of common objects such as dogs, trucks, and horses (i.e.\nCIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher\nlikelihood to the latter when the model is trained on the former. Moreover, we\nfind evidence of this phenomenon when pairing several popular image data sets:\nFashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN.\nTo investigate this curious behavior, we focus analysis on flow-based\ngenerative models in particular since they are trained and evaluated via the\nexact marginal likelihood. We find such behavior persists even when we restrict\nthe flows to constant-volume transformations. These transformations admit some\ntheoretical analysis, and we show that the difference in likelihoods can be\nexplained by the location and variances of the data and the model curvature.\nOur results caution against using the density estimates from deep generative\nmodels to identify inputs similar to the training distribution until their\nbehavior for out-of-distribution inputs is better understood. \n\n"}
{"id": "1810.09230", "contents": "Title: AST-Based Deep Learning for Detecting Malicious PowerShell Abstract: With the celebrated success of deep learning, some attempts to develop\neffective methods for detecting malicious PowerShell programs employ neural\nnets in a traditional natural language processing setup while others employ\nconvolutional neural nets to detect obfuscated malicious commands at a\ncharacter level. While these representations may express salient PowerShell\nproperties, our hypothesis is that tools from static program analysis will be\nmore effective. We propose a hybrid approach combining traditional program\nanalysis (in the form of abstract syntax trees) and deep learning. This poster\npresents preliminary results of a fundamental step in our approach: learning\nembeddings for nodes of PowerShell ASTs. We classify malicious scripts by\nfamily type and explore embedded program vector representations. \n\n"}
{"id": "1810.09352", "contents": "Title: On The Stability of Interpretable Models Abstract: Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process. Bias\nin data collection and preparation, or in model's construction may severely\naffect the accountability of the design process. We conduct an experimental\nstudy of the stability of interpretable models with respect to feature\nselection, instance selection, and model selection. Our conclusions should\nraise awareness and attention of the scientific community on the need of a\nstability impact assessment of interpretable models. \n\n"}
{"id": "1810.10096", "contents": "Title: Learning Representations in Model-Free Hierarchical Reinforcement\n  Learning Abstract: Common approaches to Reinforcement Learning (RL) are seriously challenged by\nlarge-scale applications involving huge state spaces and sparse delayed reward\nfeedback. Hierarchical Reinforcement Learning (HRL) methods attempt to address\nthis scalability issue by learning action selection policies at multiple levels\nof temporal abstraction. Abstraction can be had by identifying a relatively\nsmall set of states that are likely to be useful as subgoals, in concert with\nthe learning of corresponding skill policies to achieve those subgoals. Many\napproaches to subgoal discovery in HRL depend on the analysis of a model of the\nenvironment, but the need to learn such a model introduces its own problems of\nscale. Once subgoals are identified, skills may be learned through intrinsic\nmotivation, introducing an internal reward signal marking subgoal attainment.\nIn this paper, we present a novel model-free method for subgoal discovery using\nincremental unsupervised learning over a small memory of the most recent\nexperiences (trajectories) of the agent. When combined with an intrinsic\nmotivation learning mechanism, this method learns both subgoals and skills,\nbased on experiences in the environment. Thus, we offer an original approach to\nHRL that does not require the acquisition of a model of the environment,\nsuitable for large-scale applications. We demonstrate the efficiency of our\nmethod on two RL problems with sparse delayed feedback: a variant of the rooms\nenvironment and the first screen of the ATARI 2600 Montezuma's Revenge game. \n\n"}
{"id": "1810.10122", "contents": "Title: PoPPy: A Point Process Toolbox Based on PyTorch Abstract: PoPPy is a Point Process toolbox based on PyTorch, which achieves flexible\ndesigning and efficient learning of point process models. It can be used for\ninterpretable sequential data modeling and analysis, e.g., Granger causality\nanalysis of multi-variate point processes, point process-based simulation and\nprediction of event sequences. In practice, the key points of point\nprocess-based sequential data modeling include: 1) How to design intensity\nfunctions to describe the mechanism behind observed data? 2) How to learn the\nproposed intensity functions from observed data? The goal of PoPPy is providing\na user-friendly solution to the key points above and achieving large-scale\npoint process-based sequential data analysis, simulation and prediction. \n\n"}
{"id": "1810.10321", "contents": "Title: Active Ranking with Subset-wise Preferences Abstract: We consider the problem of probably approximately correct (PAC) ranking $n$\nitems by adaptively eliciting subset-wise preference feedback. At each round,\nthe learner chooses a subset of $k$ items and observes stochastic feedback\nindicating preference information of the winner (most preferred) item of the\nchosen subset drawn according to a Plackett-Luce (PL) subset choice model\nunknown a priori. The objective is to identify an $\\epsilon$-optimal ranking of\nthe $n$ items with probability at least $1 - \\delta$. When the feedback in each\nsubset round is a single Plackett-Luce-sampled item, we show $(\\epsilon,\n\\delta)$-PAC algorithms with a sample complexity of\n$O\\left(\\frac{n}{\\epsilon^2} \\ln \\frac{n}{\\delta} \\right)$ rounds, which we\nestablish as being order-optimal by exhibiting a matching sample complexity\nlower bound of $\\Omega\\left(\\frac{n}{\\epsilon^2} \\ln \\frac{n}{\\delta}\n\\right)$---this shows that there is essentially no improvement possible from\nthe pairwise comparisons setting ($k = 2$). When, however, it is possible to\nelicit top-$m$ ($\\leq k$) ranking feedback according to the PL model from each\nadaptively chosen subset of size $k$, we show that an $(\\epsilon, \\delta)$-PAC\nranking sample complexity of $O\\left(\\frac{n}{m \\epsilon^2} \\ln\n\\frac{n}{\\delta} \\right)$ is achievable with explicit algorithms, which\nrepresents an $m$-wise reduction in sample complexity compared to the pairwise\ncase. This again turns out to be order-wise unimprovable across the class of\nsymmetric ranking algorithms. Our algorithms rely on a novel {pivot trick} to\nmaintain only $n$ itemwise score estimates, unlike $O(n^2)$ pairwise score\nestimates that has been used in prior work. We report results of numerical\nexperiments that corroborate our findings. \n\n"}
{"id": "1810.10654", "contents": "Title: Sample-Efficient Learning of Nonprehensile Manipulation Policies via\n  Physics-Based Informed State Distributions Abstract: This paper proposes a sample-efficient yet simple approach to learning\nclosed-loop policies for nonprehensile manipulation. Although reinforcement\nlearning (RL) can learn closed-loop policies without requiring access to\nunderlying physics models, it suffers from poor sample complexity on\nchallenging tasks. To overcome this problem, we leverage rearrangement planning\nto provide an informative physics-based prior on the environment's optimal\nstate-visitation distribution. Specifically, we present a new technique,\nLearning with Planned Episodic Resets (LeaPER), that resets the environment's\nstate to one informed by the prior during the learning phase. We experimentally\nshow that LeaPER significantly outperforms traditional RL approaches by a\nfactor of up to 5X on simulated rearrangement. Further, we relax dynamics from\nquasi-static to welded contacts to illustrate that LeaPER is robust to the use\nof simpler physics models. Finally, LeaPER's closed-loop policies significantly\nimprove task success rates relative to both open-loop controls with a planned\npath or simple feedback controllers that track open-loop trajectories. We\ndemonstrate the performance and behavior of LeaPER on a physical 7-DOF\nmanipulator in https://youtu.be/feS-zFq6J1c. \n\n"}
{"id": "1810.11740", "contents": "Title: A Convex Duality Framework for GANs Abstract: Generative adversarial network (GAN) is a minimax game between a generator\nmimicking the true model and a discriminator distinguishing the samples\nproduced by the generator from the real training samples. Given an\nunconstrained discriminator able to approximate any function, this game reduces\nto finding the generative model minimizing a divergence measure, e.g. the\nJensen-Shannon (JS) divergence, to the data distribution. However, in practice\nthe discriminator is constrained to be in a smaller class $\\mathcal{F}$ such as\nneural nets. Then, a natural question is how the divergence minimization\ninterpretation changes as we constrain $\\mathcal{F}$. In this work, we address\nthis question by developing a convex duality framework for analyzing GANs. For\na convex set $\\mathcal{F}$, this duality framework interprets the original GAN\nformulation as finding the generative model with minimum JS-divergence to the\ndistributions penalized to match the moments of the data distribution, with the\nmoments specified by the discriminators in $\\mathcal{F}$. We show that this\ninterpretation more generally holds for f-GAN and Wasserstein GAN. As a\nbyproduct, we apply the duality framework to a hybrid of f-divergence and\nWasserstein distance. Unlike the f-divergence, we prove that the proposed\nhybrid divergence changes continuously with the generative model, which\nsuggests regularizing the discriminator's Lipschitz constant in f-GAN and\nvanilla GAN. We numerically evaluate the power of the suggested regularization\nschemes for improving GAN's training performance. \n\n"}
{"id": "1810.11755", "contents": "Title: Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo\n  Tree Search Abstract: Monte Carlo Tree Search (MCTS) algorithms have achieved great success on many\nchallenging benchmarks (e.g., Computer Go). However, they generally require a\nlarge number of rollouts, making their applications costly. Furthermore, it is\nalso extremely challenging to parallelize MCTS due to its inherent sequential\nnature: each rollout heavily relies on the statistics (e.g., node visitation\ncounts) estimated from previous simulations to achieve an effective\nexploration-exploitation tradeoff. In spite of these difficulties, we develop\nan algorithm, WU-UCT, to effectively parallelize MCTS, which achieves linear\nspeedup and exhibits only limited performance loss with an increasing number of\nworkers. The key idea in WU-UCT is a set of statistics that we introduce to\ntrack the number of on-going yet incomplete simulation queries (named as\nunobserved samples). These statistics are used to modify the UCT tree policy in\nthe selection steps in a principled manner to retain effective\nexploration-exploitation tradeoff when we parallelize the most time-consuming\nexpansion and simulation steps. Experiments on a proprietary benchmark and the\nAtari Game benchmark demonstrate the linear speedup and the superior\nperformance of WU-UCT comparing to existing techniques. \n\n"}
{"id": "1810.11874", "contents": "Title: Learning with Bad Training Data via Iterative Trimmed Loss Minimization Abstract: In this paper, we study a simple and generic framework to tackle the problem\nof learning model parameters when a fraction of the training samples are\ncorrupted. We first make a simple observation: in a variety of such settings,\nthe evolution of training accuracy (as a function of training epochs) is\ndifferent for clean and bad samples. Based on this we propose to iteratively\nminimize the trimmed loss, by alternating between (a) selecting samples with\nlowest current loss, and (b) retraining a model on only these samples. We prove\nthat this process recovers the ground truth (with linear convergence rate) in\ngeneralized linear models with standard statistical assumptions.\nExperimentally, we demonstrate its effectiveness in three settings: (a) deep\nimage classifiers with errors only in labels, (b) generative adversarial\nnetworks with bad training images, and (c) deep image classifiers with\nadversarial (image, label) pairs (i.e., backdoor attacks). For the well-studied\nsetting of random label noise, our algorithm achieves state-of-the-art\nperformance without having access to any a-priori guaranteed clean samples. \n\n"}
{"id": "1810.12085", "contents": "Title: Extractive Summarization of EHR Discharge Notes Abstract: Patient summarization is essential for clinicians to provide coordinated care\nand practice effective communication. Automated summarization has the potential\nto save time, standardize notes, aid clinical decision making, and reduce\nmedical errors. Here we provide an upper bound on extractive summarization of\ndischarge notes and develop an LSTM model to sequentially label topics of\nhistory of present illness notes. We achieve an F1 score of 0.876, which\nindicates that this model can be employed to create a dataset for evaluation of\nextractive summarization methods. \n\n"}
{"id": "1810.12118", "contents": "Title: Finding Answers from the Word of God: Domain Adaptation for Neural\n  Networks in Biblical Question Answering Abstract: Question answering (QA) has significantly benefitted from deep learning\ntechniques in recent years. However, domain-specific QA remains a challenge due\nto the significant amount of data required to train a neural network. This\npaper studies the answer sentence selection task in the Bible domain and answer\nquestions by selecting relevant verses from the Bible. For this purpose, we\ncreate a new dataset BibleQA based on bible trivia questions and propose three\nneural network models for our task. We pre-train our models on a large-scale QA\ndataset, SQuAD, and investigate the effect of transferring weights on model\naccuracy. Furthermore, we also measure the model accuracies with different\nanswer context lengths and different Bible translations. We affirm that\ntransfer learning has a noticeable improvement in the model accuracy. We\nachieve relatively good results with shorter context lengths, whereas longer\ncontext lengths decreased model accuracy. We also find that using a more modern\nBible translation in the dataset has a positive effect on the task. \n\n"}
{"id": "1810.12247", "contents": "Title: Enabling Factorized Piano Music Modeling and Generation with the MAESTRO\n  Dataset Abstract: Generating musical audio directly with neural networks is notoriously\ndifficult because it requires coherently modeling structure at many different\ntimescales. Fortunately, most music is also highly structured and can be\nrepresented as discrete note events played on musical instruments. Herein, we\nshow that by using notes as an intermediate representation, we can train a\nsuite of models capable of transcribing, composing, and synthesizing audio\nwaveforms with coherent musical structure on timescales spanning six orders of\nmagnitude (~0.1 ms to ~100 s), a process we call Wave2Midi2Wave. This large\nadvance in the state of the art is enabled by our release of the new MAESTRO\n(MIDI and Audio Edited for Synchronous TRacks and Organization) dataset,\ncomposed of over 172 hours of virtuosic piano performances captured with fine\nalignment (~3 ms) between note labels and audio waveforms. The networks and the\ndataset together present a promising approach toward creating new expressive\nand interpretable neural models of music. \n\n"}
{"id": "1810.12281", "contents": "Title: Three Mechanisms of Weight Decay Regularization Abstract: Weight decay is one of the standard tricks in the neural network toolbox, but\nthe reasons for its regularization effect are poorly understood, and recent\nresults have cast doubt on the traditional interpretation in terms of $L_2$\nregularization. Literal weight decay has been shown to outperform $L_2$\nregularization for optimizers for which they differ. We empirically investigate\nweight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a\nvariety of network architectures. We identify three distinct mechanisms by\nwhich weight decay exerts a regularization effect, depending on the particular\noptimization algorithm and architecture: (1) increasing the effective learning\nrate, (2) approximately regularizing the input-output Jacobian norm, and (3)\nreducing the effective damping coefficient for second-order optimization. Our\nresults provide insight into how to improve the regularization of neural\nnetworks. \n\n"}
{"id": "1810.12576", "contents": "Title: Improved Network Robustness with Adversary Critic Abstract: Ideally, what confuses neural network should be confusing to humans. However,\nrecent experiments have shown that small, imperceptible perturbations can\nchange the network prediction. To address this gap in perception, we propose a\nnovel approach for learning robust classifier. Our main idea is: adversarial\nexamples for the robust classifier should be indistinguishable from the regular\ndata of the adversarial target. We formulate a problem of learning robust\nclassifier in the framework of Generative Adversarial Networks (GAN), where the\nadversarial attack on classifier acts as a generator, and the critic network\nlearns to distinguish between regular and adversarial images. The classifier\ncost is augmented with the objective that its adversarial examples should\nconfuse the adversary critic. To improve the stability of the adversarial\nmapping, we introduce adversarial cycle-consistency constraint which ensures\nthat the adversarial mapping of the adversarial examples is close to the\noriginal. In the experiments, we show the effectiveness of our defense. Our\nmethod surpasses in terms of robustness networks trained with adversarial\ntraining. Additionally, we verify in the experiments with human annotators on\nMTurk that adversarial examples are indeed visually confusing. Codes for the\nproject are available at https://github.com/aam-at/adversary_critic. \n\n"}
{"id": "1810.12582", "contents": "Title: DSKG: A Deep Sequential Model for Knowledge Graph Completion Abstract: Knowledge graph (KG) completion aims to fill the missing facts in a KG, where\na fact is represented as a triple in the form of $(subject, relation, object)$.\nCurrent KG completion models compel two-thirds of a triple provided (e.g.,\n$subject$ and $relation$) to predict the remaining one. In this paper, we\npropose a new model, which uses a KG-specific multi-layer recurrent neural\nnetwork (RNN) to model triples in a KG as sequences. It outperformed several\nstate-of-the-art KG completion models on the conventional entity prediction\ntask for many evaluation metrics, based on two benchmark datasets and a more\ndifficult dataset. Furthermore, our model is enabled by the sequential\ncharacteristic and thus capable of predicting the whole triples only given one\nentity. Our experiments demonstrated that our model achieved promising\nperformance on this new triple prediction task. \n\n"}
{"id": "1810.12715", "contents": "Title: On the Effectiveness of Interval Bound Propagation for Training\n  Verifiably Robust Models Abstract: Recent work has shown that it is possible to train deep neural networks that\nare provably robust to norm-bounded adversarial perturbations. Most of these\nmethods are based on minimizing an upper bound on the worst-case loss over all\npossible adversarial perturbations. While these techniques show promise, they\noften result in difficult optimization procedures that remain hard to scale to\nlarger networks. Through a comprehensive analysis, we show how a simple\nbounding technique, interval bound propagation (IBP), can be exploited to train\nlarge provably robust neural networks that beat the state-of-the-art in\nverified accuracy. While the upper bound computed by IBP can be quite weak for\ngeneral networks, we demonstrate that an appropriate loss and clever\nhyper-parameter schedule allow the network to adapt such that the IBP bound is\ntight. This results in a fast and stable learning algorithm that outperforms\nmore sophisticated methods and achieves state-of-the-art results on MNIST,\nCIFAR-10 and SVHN. It also allows us to train the largest model to be verified\nbeyond vacuous bounds on a downscaled version of ImageNet. \n\n"}
{"id": "1810.12780", "contents": "Title: Advancing PICO Element Detection in Biomedical Text via Deep Neural\n  Networks Abstract: In evidence-based medicine (EBM), defining a clinical question in terms of\nthe specific patient problem aids the physicians to efficiently identify\nappropriate resources and search for the best available evidence for medical\ntreatment. In order to formulate a well-defined, focused clinical question, a\nframework called PICO is widely used, which identifies the sentences in a given\nmedical text that belong to the four components typically reported in clinical\ntrials: Participants/Problem (P), Intervention (I), Comparison (C) and Outcome\n(O). In this work, we propose a novel deep learning model for recognizing PICO\nelements in biomedical abstracts. Based on the previous state-of-the-art\nbidirectional long-short term memory (biLSTM) plus conditional random field\n(CRF) architecture, we add another layer of biLSTM upon the sentence\nrepresentation vectors so that the contextual information from surrounding\nsentences can be gathered to help infer the interpretation of the current one.\nIn addition, we propose two methods to further generalize and improve the\nmodel: adversarial training and unsupervised pre-training over large corpora.\nWe tested our proposed approach over two benchmark datasets. One is the\nPubMed-PICO dataset, where our best results outperform the previous best by\n5.5%, 7.9%, and 5.8% for P, I, and O elements in terms of F1 score,\nrespectively. And for the other dataset named NICTA-PIBOSO, the improvements\nfor P/I/O elements are 2.4%, 13.6%, and 1.0% in F1 score, respectively.\nOverall, our proposed deep learning model can obtain unprecedented PICO element\ndetection accuracy while avoiding the need for any manual feature selection. \n\n"}
{"id": "1810.12894", "contents": "Title: Exploration by Random Network Distillation Abstract: We introduce an exploration bonus for deep reinforcement learning methods\nthat is easy to implement and adds minimal overhead to the computation\nperformed. The bonus is the error of a neural network predicting features of\nthe observations given by a fixed randomly initialized neural network. We also\nintroduce a method to flexibly combine intrinsic and extrinsic rewards. We find\nthat the random network distillation (RND) bonus combined with this increased\nflexibility enables significant progress on several hard exploration Atari\ngames. In particular we establish state of the art performance on Montezuma's\nRevenge, a game famously difficult for deep reinforcement learning methods. To\nthe best of our knowledge, this is the first method that achieves better than\naverage human performance on this game without using demonstrations or having\naccess to the underlying state of the game, and occasionally completes the\nfirst level. \n\n"}
{"id": "1810.13259", "contents": "Title: Non-linear Canonical Correlation Analysis: A Compressed Representation\n  Approach Abstract: Canonical Correlation Analysis (CCA) is a linear representation learning\nmethod that seeks maximally correlated variables in multi-view data. Non-linear\nCCA extends this notion to a broader family of transformations, which are more\npowerful in many real-world applications. Given the joint probability, the\nAlternating Conditional Expectation (ACE) algorithm provides an optimal\nsolution to the non-linear CCA problem. However, it suffers from limited\nperformance and an increasing computational burden when only a finite number of\nsamples is available. In this work we introduce an information-theoretic\ncompressed representation framework for the non-linear CCA problem (CRCCA),\nwhich extends the classical ACE approach. Our suggested framework seeks compact\nrepresentations of the data that allow a maximal level of correlation. This way\nwe control the trade-off between the flexibility and the complexity of the\nmodel. CRCCA provides theoretical bounds and optimality conditions, as we\nestablish fundamental connections to rate-distortion theory, the information\nbottleneck and remote source coding. In addition, it allows a soft\ndimensionality reduction, as the compression level is determined by the mutual\ninformation between the original noisy data and the extracted signals. Finally,\nwe introduce a simple implementation of the CRCCA framework, based on lattice\nquantization. \n\n"}
{"id": "1810.13296", "contents": "Title: On Exploration, Exploitation and Learning in Adaptive Importance\n  Sampling Abstract: We study adaptive importance sampling (AIS) as an online learning problem and\nargue for the importance of the trade-off between exploration and exploitation\nin this adaptation. Borrowing ideas from the bandits literature, we propose\nDaisee, a partition-based AIS algorithm. We further introduce a notion of\nregret for AIS and show that Daisee has $\\mathcal{O}(\\sqrt{T}(\\log\nT)^{\\frac{3}{4}})$ cumulative pseudo-regret, where $T$ is the number of\niterations. We then extend Daisee to adaptively learn a hierarchical\npartitioning of the sample space for more efficient sampling and confirm the\nperformance of both algorithms empirically. \n\n"}
{"id": "1811.00002", "contents": "Title: WaveGlow: A Flow-based Generative Network for Speech Synthesis Abstract: In this paper we propose WaveGlow: a flow-based network capable of generating\nhigh quality speech from mel-spectrograms. WaveGlow combines insights from Glow\nand WaveNet in order to provide fast, efficient and high-quality audio\nsynthesis, without the need for auto-regression. WaveGlow is implemented using\nonly a single network, trained using only a single cost function: maximizing\nthe likelihood of the training data, which makes the training procedure simple\nand stable. Our PyTorch implementation produces audio samples at a rate of more\nthan 500 kHz on an NVIDIA V100 GPU. Mean Opinion Scores show that it delivers\naudio quality as good as the best publicly available WaveNet implementation.\nAll code will be made publicly available online. \n\n"}
{"id": "1811.00052", "contents": "Title: Some New Layer Architectures for Graph CNN Abstract: While convolutional neural networks (CNNs) have recently made great strides\nin supervised classification of data structured on a grid (e.g. images composed\nof pixel grids), in several interesting datasets, the relations between\nfeatures can be better represented as a general graph instead of a regular\ngrid. Although recent algorithms that adapt CNNs to graphs have shown promising\nresults, they mostly neglect learning explicit operations for edge features\nwhile focusing on vertex features alone. We propose new formulations for\nconvolutional, pooling, and fully connected layers for neural networks that\nmake more comprehensive use of the information available in multi-dimensional\ngraphs. Using these layers led to an improvement in classification accuracy\nover the state-of-the-art methods on benchmark graph datasets. \n\n"}
{"id": "1811.00115", "contents": "Title: Dimensionality Reduction has Quantifiable Imperfections: Two Geometric\n  Bounds Abstract: In this paper, we investigate Dimensionality reduction (DR) maps in an\ninformation retrieval setting from a quantitative topology point of view. In\nparticular, we show that no DR maps can achieve perfect precision and perfect\nrecall simultaneously. Thus a continuous DR map must have imperfect precision.\nWe further prove an upper bound on the precision of Lipschitz continuous DR\nmaps. While precision is a natural measure in an information retrieval setting,\nit does not measure `how' wrong the retrieved data is. We therefore propose a\nnew measure based on Wasserstein distance that comes with similar theoretical\nguarantee. A key technical step in our proofs is a particular optimization\nproblem of the $L_2$-Wasserstein distance over a constrained set of\ndistributions. We provide a complete solution to this optimization problem,\nwhich can be of independent interest on the technical side. \n\n"}
{"id": "1811.00135", "contents": "Title: Dirichlet Variational Autoencoder for Text Modeling Abstract: We introduce an improved variational autoencoder (VAE) for text modeling with\ntopic information explicitly modeled as a Dirichlet latent variable. By\nproviding the proposed model topic awareness, it is more superior at\nreconstructing input texts. Furthermore, due to the inherent interactions\nbetween the newly introduced Dirichlet variable and the conventional\nmultivariate Gaussian variable, the model is less prone to KL divergence\nvanishing. We derive the variational lower bound for the new model and conduct\nexperiments on four different data sets. The results show that the proposed\nmodel is superior at text reconstruction across the latent space and\nclassifications on learned representations have higher test accuracies. \n\n"}
{"id": "1811.00217", "contents": "Title: META-DES.Oracle: Meta-learning and feature selection for ensemble\n  selection Abstract: The key issue in Dynamic Ensemble Selection (DES) is defining a suitable\ncriterion for calculating the classifiers' competence. There are several\ncriteria available to measure the level of competence of base classifiers, such\nas local accuracy estimates and ranking. However, using only one criterion may\nlead to a poor estimation of the classifier's competence. In order to deal with\nthis issue, we have proposed a novel dynamic ensemble selection framework using\nmeta-learning, called META-DES. An important aspect of the META-DES framework\nis that multiple criteria can be embedded in the system encoded as different\nsets of meta-features. However, some DES criteria are not suitable for every\nclassification problem. For instance, local accuracy estimates may produce poor\nresults when there is a high degree of overlap between the classes. Moreover, a\nhigher classification accuracy can be obtained if the performance of the\nmeta-classifier is optimized for the corresponding data. In this paper, we\npropose a novel version of the META-DES framework based on the formal\ndefinition of the Oracle, called META-DES.Oracle. The Oracle is an abstract\nmethod that represents an ideal classifier selection scheme. A meta-feature\nselection scheme using an overfitting cautious Binary Particle Swarm\nOptimization (BPSO) is proposed for improving the performance of the\nmeta-classifier. The difference between the outputs obtained by the\nmeta-classifier and those presented by the Oracle is minimized. Thus, the\nmeta-classifier is expected to obtain results that are similar to the Oracle.\nExperiments carried out using 30 classification problems demonstrate that the\noptimization procedure based on the Oracle definition leads to a significant\nimprovement in classification accuracy when compared to previous versions of\nthe META-DES framework and other state-of-the-art DES techniques. \n\n"}
{"id": "1811.00246", "contents": "Title: SARN: Relational Reasoning through Sequential Attention Abstract: This paper proposes an attention module augmented relational network called\nSARN(Sequential Attention Relational Network) that can carry out relational\nreasoning by extracting reference objects and making efficient pairing between\nobjects. SARN greatly reduces the computational and memory requirements of the\nrelational network, which computes all object pairs. It also shows high\naccuracy on the Sort-of-CLEVR dataset compared to other models, especially on\nrelational questions. \n\n"}
{"id": "1811.00247", "contents": "Title: FNNC: Achieving Fairness through Neural Networks Abstract: In classification models fairness can be ensured by solving a constrained\noptimization problem. We focus on fairness constraints like Disparate Impact,\nDemographic Parity, and Equalized Odds, which are non-decomposable and\nnon-convex. Researchers define convex surrogates of the constraints and then\napply convex optimization frameworks to obtain fair classifiers. Surrogates\nserve only as an upper bound to the actual constraints, and convexifying\nfairness constraints might be challenging.\n  We propose a neural network-based framework, \\emph{FNNC}, to achieve fairness\nwhile maintaining high accuracy in classification. The above fairness\nconstraints are included in the loss using Lagrangian multipliers. We prove\nbounds on generalization errors for the constrained losses which asymptotically\ngo to zero. The network is optimized using two-step mini-batch stochastic\ngradient descent. Our experiments show that FNNC performs as good as the state\nof the art, if not better. The experimental evidence supplements our\ntheoretical guarantees. In summary, we have an automated solution to achieve\nfairness in classification, which is easily extendable to many fairness\nconstraints. \n\n"}
{"id": "1811.00264", "contents": "Title: Multiple Kernel $k$-Means Clustering by Selecting Representative Kernels Abstract: To cluster data that are not linearly separable in the original feature\nspace, $k$-means clustering was extended to the kernel version. However, the\nperformance of kernel $k$-means clustering largely depends on the choice of\nkernel function. To mitigate this problem, multiple kernel learning has been\nintroduced into the $k$-means clustering to obtain an optimal kernel\ncombination for clustering. Despite the success of multiple kernel $k$-means\nclustering in various scenarios, few of the existing work update the\ncombination coefficients based on the diversity of kernels, which leads to the\nresult that the selected kernels contain high redundancy and would degrade the\nclustering performance and efficiency. In this paper, we propose a simple but\nefficient strategy that selects a diverse subset from the pre-specified kernels\nas the representative kernels, and then incorporate the subset selection\nprocess into the framework of multiple $k$-means clustering. The representative\nkernels can be indicated as the significant combination weights. Due to the\nnon-convexity of the obtained objective function, we develop an alternating\nminimization method to optimize the combination coefficients of the selected\nkernels and the cluster membership alternatively. We evaluate the proposed\napproach on several benchmark and real-world datasets. The experimental results\ndemonstrate the competitiveness of our approach in comparison with the\nstate-of-the-art methods. \n\n"}
{"id": "1811.00513", "contents": "Title: Auditing Data Provenance in Text-Generation Models Abstract: To help enforce data-protection regulations such as GDPR and detect\nunauthorized uses of personal data, we develop a new \\emph{model auditing}\ntechnique that helps users check if their data was used to train a machine\nlearning model. We focus on auditing deep-learning models that generate\nnatural-language text, including word prediction and dialog generation. These\nmodels are at the core of popular online services and are often trained on\npersonal data such as users' messages, searches, chats, and comments.\n  We design and evaluate a black-box auditing method that can detect, with very\nfew queries to a model, if a particular user's texts were used to train it\n(among thousands of other users). We empirically show that our method can\nsuccessfully audit well-generalized models that are not overfitted to the\ntraining data. We also analyze how text-generation models memorize word\nsequences and explain why this memorization makes them amenable to auditing. \n\n"}
{"id": "1811.00703", "contents": "Title: Learning Latent Fractional dynamics with Unknown Unknowns Abstract: Despite significant effort in understanding complex systems (CS), we lack a\ntheory for modeling, inference, analysis and efficient control of time-varying\ncomplex networks (TVCNs) in uncertain environments. From brain activity\ndynamics to microbiome, and even chromatin interactions within the genome\narchitecture, many such TVCNs exhibits a pronounced spatio-temporal fractality.\nMoreover, for many TVCNs only limited information (e.g., few variables) is\naccessible for modeling, which hampers the capabilities of analytical tools to\nuncover the true degrees of freedom and infer the CS model, the hidden states\nand their parameters. Another fundamental limitation is that of understanding\nand unveiling of unknown drivers of the dynamics that could sporadically excite\nthe network in ways that straightforward modeling does not work due to our\ninability to model non-stationary processes. Towards addressing these\nchallenges, in this paper, we consider the problem of learning the fractional\ndynamical complex networks under unknown unknowns (i.e., hidden drivers) and\npartial observability (i.e., only partial data is available). More precisely,\nwe consider a generalized modeling approach of TVCNs consisting of\ndiscrete-time fractional dynamical equations and propose an iterative framework\nto determine the network parameterization and predict the state of the system.\nWe showcase the performance of the proposed framework in the context of task\nclassification using real electroencephalogram data. \n\n"}
{"id": "1811.00866", "contents": "Title: Efficient Neural Network Robustness Certification with General\n  Activation Functions Abstract: Finding minimum distortion of adversarial examples and thus certifying\nrobustness in neural network classifiers for given data points is known to be a\nchallenging problem. Nevertheless, recently it has been shown to be possible to\ngive a non-trivial certified lower bound of minimum adversarial distortion, and\nsome recent progress has been made towards this direction by exploiting the\npiece-wise linear nature of ReLU activations. However, a generic robustness\ncertification for general activation functions still remains largely\nunexplored. To address this issue, in this paper we introduce CROWN, a general\nframework to certify robustness of neural networks with general activation\nfunctions for given input data points. The novelty in our algorithm consists of\nbounding a given activation function with linear and quadratic functions, hence\nallowing it to tackle general activation functions including but not limited to\nfour popular choices: ReLU, tanh, sigmoid and arctan. In addition, we\nfacilitate the search for a tighter certified lower bound by adaptively\nselecting appropriate surrogates for each neuron activation. Experimental\nresults show that CROWN on ReLU networks can notably improve the certified\nlower bounds compared to the current state-of-the-art algorithm Fast-Lin, while\nhaving comparable computational efficiency. Furthermore, CROWN also\ndemonstrates its effectiveness and flexibility on networks with general\nactivation functions, including tanh, sigmoid and arctan. \n\n"}
{"id": "1811.01118", "contents": "Title: Learning to Rank Query Graphs for Complex Question Answering over\n  Knowledge Graphs Abstract: In this paper, we conduct an empirical investigation of neural query graph\nranking approaches for the task of complex question answering over knowledge\ngraphs. We experiment with six different ranking models and propose a novel\nself-attention based slot matching model which exploits the inherent structure\nof query graphs, our logical form of choice. Our proposed model generally\noutperforms the other models on two QA datasets over the DBpedia knowledge\ngraph, evaluated in different settings. In addition, we show that transfer\nlearning from the larger of those QA datasets to the smaller dataset yields\nsubstantial improvements, effectively offsetting the general lack of training\ndata. \n\n"}
{"id": "1811.01640", "contents": "Title: Leveraging Random Label Memorization for Unsupervised Pre-Training Abstract: We present a novel approach to leverage large unlabeled datasets by\npre-training state-of-the-art deep neural networks on randomly-labeled\ndatasets. Specifically, we train the neural networks to memorize arbitrary\nlabels for all the samples in a dataset and use these pre-trained networks as a\nstarting point for regular supervised learning. Our assumption is that the\n\"memorization infrastructure\" learned by the network during the random-label\ntraining proves to be beneficial for the conventional supervised learning as\nwell. We test the effectiveness of our pre-training on several video action\nrecognition datasets (HMDB51, UCF101, Kinetics) by comparing the results of the\nsame network with and without the random label pre-training. Our approach\nyields an improvement - ranging from 1.5% on UCF-101 to 5% on Kinetics - in\nclassification accuracy, which calls for further research in this direction. \n\n"}
{"id": "1811.01704", "contents": "Title: ReLeQ: A Reinforcement Learning Approach for Deep Quantization of Neural\n  Networks Abstract: Deep Neural Networks (DNNs) typically require massive amount of computation\nresource in inference tasks for computer vision applications. Quantization can\nsignificantly reduce DNN computation and storage by decreasing the bitwidth of\nnetwork encodings. Recent research affirms that carefully selecting the\nquantization levels for each layer can preserve the accuracy while pushing the\nbitwidth below eight bits. However, without arduous manual effort, this deep\nquantization can lead to significant accuracy loss, leaving it in a position of\nquestionable utility. As such, deep quantization opens a large hyper-parameter\nspace (bitwidth of the layers), the exploration of which is a major challenge.\nWe propose a systematic approach to tackle this problem, by automating the\nprocess of discovering the quantization levels through an end-to-end deep\nreinforcement learning framework (ReLeQ). We adapt policy optimization methods\nto the problem of quantization, and focus on finding the best design decisions\nin choosing the state and action spaces, network architecture and training\nframework, as well as the tuning of various hyperparamters. We show how ReLeQ\ncan balance speed and quality, and provide an asymmetric general solution for\nquantization of a large variety of deep networks (AlexNet, CIFAR-10, LeNet,\nMobileNet-V1, ResNet-20, SVHN, and VGG-11) that virtually preserves the\naccuracy (=< 0.3% loss) while minimizing the computation and storage cost. With\nthese DNNs, ReLeQ enables conventional hardware to achieve 2.2x speedup over\n8-bit execution. Similarly, a custom DNN accelerator achieves 2.0x speedup and\nenergy reduction compared to 8-bit runs. These encouraging results mark ReLeQ\nas the initial step towards automating the deep quantization of neural\nnetworks. \n\n"}
{"id": "1811.01710", "contents": "Title: Weakly Supervised Grammatical Error Correction using Iterative Decoding Abstract: We describe an approach to Grammatical Error Correction (GEC) that is\neffective at making use of models trained on large amounts of weakly supervised\nbitext. We train the Transformer sequence-to-sequence model on 4B tokens of\nWikipedia revisions and employ an iterative decoding strategy that is tailored\nto the loosely-supervised nature of the Wikipedia training corpus. Finetuning\non the Lang-8 corpus and ensembling yields an F0.5 of 58.3 on the CoNLL'14\nbenchmark and a GLEU of 62.4 on JFLEG. The combination of weakly supervised\ntraining and iterative decoding obtains an F0.5 of 48.2 on CoNLL'14 even\nwithout using any labeled GEC data. \n\n"}
{"id": "1811.02067", "contents": "Title: Sample Compression, Support Vectors, and Generalization in Deep Learning Abstract: Even though Deep Neural Networks (DNNs) are widely celebrated for their\npractical performance, they possess many intriguing properties related to depth\nthat are difficult to explain both theoretically and intuitively. Understanding\nhow weights in deep networks coordinate together across layers to form useful\nlearners has proven challenging, in part because the repeated composition of\nnonlinearities has proved intractable. This paper presents a reparameterization\nof DNNs as a linear function of a feature map that is locally independent of\nthe weights. This feature map transforms depth-dependencies into simple tensor\nproducts and maps each input to a discrete subset of the feature space. Then,\nusing a max-margin assumption, the paper develops a sample compression\nrepresentation of the neural network in terms of the discrete activation state\nof neurons induced by s ``support vectors\". The paper shows that the number of\nsupport vectors s relates with learning guarantees for neural networks through\nsample compression bounds, yielding a sample complexity of O(ns/epsilon) for\nnetworks with n neurons. Finally, the number of support vectors s is found to\nmonotonically increase with width and label noise but decrease with depth. \n\n"}
{"id": "1811.02122", "contents": "Title: Robust and fine-grained prosody control of end-to-end speech synthesis Abstract: We propose prosody embeddings for emotional and expressive speech synthesis\nnetworks. The proposed methods introduce temporal structures in the embedding\nnetworks, thus enabling fine-grained control of the speaking style of the\nsynthesized speech. The temporal structures can be designed either on the\nspeech side or the text side, leading to different control resolutions in time.\nThe prosody embedding networks are plugged into end-to-end speech synthesis\nnetworks and trained without any other supervision except for the target speech\nfor synthesizing. It is demonstrated that the prosody embedding networks\nlearned to extract prosodic features. By adjusting the learned prosody\nfeatures, we could change the pitch and amplitude of the synthesized speech\nboth at the frame level and the phoneme level. We also introduce the temporal\nnormalization of prosody embeddings, which shows better robustness against\nspeaker perturbations during prosody transfer tasks. \n\n"}
{"id": "1811.02579", "contents": "Title: Deep Weighted Averaging Classifiers Abstract: Recent advances in deep learning have achieved impressive gains in\nclassification accuracy on a variety of types of data, including images and\ntext. Despite these gains, however, concerns have been raised about the\ncalibration, robustness, and interpretability of these models. In this paper we\npropose a simple way to modify any conventional deep architecture to\nautomatically provide more transparent explanations for classification\ndecisions, as well as an intuitive notion of the credibility of each\nprediction. Specifically, we draw on ideas from nonparametric kernel\nregression, and propose to predict labels based on a weighted sum of training\ninstances, where the weights are determined by distance in a learned\ninstance-embedding space. Working within the framework of conformal methods, we\npropose a new measure of nonconformity suggested by our model, and\nexperimentally validate the accompanying theoretical expectations,\ndemonstrating improved transparency, controlled error rates, and robustness to\nout-of-domain data, without compromising on accuracy or calibration. \n\n"}
{"id": "1811.02616", "contents": "Title: Multi-View Network Embedding Via Graph Factorization Clustering and\n  Co-Regularized Multi-View Agreement Abstract: Real-world social networks and digital platforms are comprised of individuals\n(nodes) that are linked to other individuals or entities through multiple types\nof relationships (links). Sub-networks of such a network based on each type of\nlink correspond to distinct views of the underlying network. In real-world\napplications, each node is typically linked to only a small subset of other\nnodes. Hence, practical approaches to problems such as node labeling have to\ncope with the resulting sparse networks. While low-dimensional network\nembeddings offer a promising approach to this problem, most of the current\nnetwork embedding methods focus primarily on single view networks. We introduce\na novel multi-view network embedding (MVNE) algorithm for constructing\nlow-dimensional node embeddings from multi-view networks. MVNE adapts and\nextends an approach to single view network embedding (SVNE) using graph\nfactorization clustering (GFC) to the multi-view setting using an objective\nfunction that maximizes the agreement between views based on both the local and\nglobal structure of the underlying multi-view graph. Our experiments with\nseveral benchmark real-world single view networks show that GFC-based SVNE\nyields network embeddings that are competitive with or superior to those\nproduced by the state-of-the-art single view network embedding methods when the\nembeddings are used for labeling unlabeled nodes in the networks. Our\nexperiments with several multi-view networks show that MVNE substantially\noutperforms the single view methods on integrated view and the state-of-the-art\nmulti-view methods. We further show that even when the goal is to predict\nlabels of nodes within a single target view, MVNE outperforms its single-view\ncounterpart suggesting that the MVNE is able to extract the information that is\nuseful for labeling nodes in the target view from the all of the views. \n\n"}
{"id": "1811.02654", "contents": "Title: A Volumetric Convolutional Neural Network for Brain Tumor Segmentation Abstract: Brain cancer can be very fatal, but chances of survival increase through\nearly detection and treatment. Doctors use Magnetic Resonance Imaging (MRI) to\ndetect and locate tumors in the brain, and very carefully analyze scans to\nsegment brain tumors. Manual segmentation is time consuming and tiring for\ndoctors, and it can be difficult for them to notice extremely small\nabnormalities. Automated segmentations performed by computers offer quicker\ndiagnoses, the ability to notice small details, and more accurate\nsegmentations. Advances in deep learning and computer hardware have allowed for\nhigh-performing automated segmentation approaches. However, several problems\npersist in practice: increased training time, class imbalance, and low\nperformance. In this paper, I propose applying V-Net, a volumetric, fully\nconvolutional neural network, to segment brain tumors in MRI scans from the\nBraTS Challenges. With this approach, I achieve a whole tumor dice score of\n0.89 and train the network in a short time while addressing class imbalance\nwith the use of a dice loss layer. Then, I propose applying an existing\ntechnique to improve automated segmentation performance in practice. \n\n"}
{"id": "1811.03081", "contents": "Title: Forging new worlds: high-resolution synthetic galaxies with chained\n  generative adversarial networks Abstract: Astronomy of the 21st century increasingly finds itself with extreme\nquantities of data. This growth in data is ripe for modern technologies such as\ndeep image processing, which has the potential to allow astronomers to\nautomatically identify, classify, segment and deblend various astronomical\nobjects. In this paper, we explore the use of chained generative adversarial\nnetworks (GANs), a class of generative models that learn mappings from latent\nspaces to data distributions by modelling the joint distribution of the data,\nto produce physically realistic galaxy images as one use case of such models.\nIn cosmology, such datasets can aid in the calibration of shape measurements\nfor weak lensing by augmenting data with synthetic images. By measuring the\ndistributions of multiple physical properties, we show that images generated\nwith our approach closely follow the distributions of real galaxies, further\nestablishing state-of-the-art GAN architectures as a valuable tool for\nmodern-day astronomy. \n\n"}
{"id": "1811.03356", "contents": "Title: Linear Memory Networks Abstract: Recurrent neural networks can learn complex transduction problems that\nrequire maintaining and actively exploiting a memory of their inputs. Such\nmodels traditionally consider memory and input-output functionalities\nindissolubly entangled. We introduce a novel recurrent architecture based on\nthe conceptual separation between the functional input-output transformation\nand the memory mechanism, showing how they can be implemented through different\nneural components. By building on such conceptualization, we introduce the\nLinear Memory Network, a recurrent model comprising a feedforward neural\nnetwork, realizing the non-linear functional transformation, and a linear\nautoencoder for sequences, implementing the memory component. The resulting\narchitecture can be efficiently trained by building on closed-form solutions to\nlinear optimization problems. Further, by exploiting equivalence results\nbetween feedforward and recurrent neural networks we devise a pretraining\nschema for the proposed architecture. Experiments on polyphonic music datasets\nshow competitive results against gated recurrent networks and other state of\nthe art models. \n\n"}
{"id": "1811.03970", "contents": "Title: Looking Deeper into Deep Learning Model: Attribution-based Explanations\n  of TextCNN Abstract: Layer-wise Relevance Propagation (LRP) and saliency maps have been recently\nused to explain the predictions of Deep Learning models, specifically in the\ndomain of text classification. Given different attribution-based explanations\nto highlight relevant words for a predicted class label, experiments based on\nword deleting perturbation is a common evaluation method. This word removal\napproach, however, disregards any linguistic dependencies that may exist\nbetween words or phrases in a sentence, which could semantically guide a\nclassifier to a particular prediction. In this paper, we present a\nfeature-based evaluation framework for comparing the two attribution methods on\ncustomer reviews (public data sets) and Customer Due Diligence (CDD) extracted\nreports (corporate data set). Instead of removing words based on the relevance\nscore, we investigate perturbations based on embedded features removal from\nintermediate layers of Convolutional Neural Networks. Our experimental study is\ncarried out on embedded-word, embedded-document, and embedded-ngrams\nexplanations. Using the proposed framework, we provide a visualization tool to\nassist analysts in reasoning toward the model's final prediction. \n\n"}
{"id": "1811.04480", "contents": "Title: Semi-supervised Deep Representation Learning for Multi-View Problems Abstract: While neural networks for learning representation of multi-view data have\nbeen previously proposed as one of the state-of-the-art multi-view dimension\nreduction techniques, how to make the representation discriminative with only a\nsmall amount of labeled data is not well-studied. We introduce a\nsemi-supervised neural network model, named Multi-view Discriminative Neural\nNetwork (MDNN), for multi-view problems. MDNN finds nonlinear view-specific\nmappings by projecting samples to a common feature space using multiple coupled\ndeep networks. It is capable of leveraging both labeled and unlabeled data to\nproject multi-view data so that samples from different classes are separated\nand those from the same class are clustered together. It also uses the\ninter-view correlation between views to exploit the available information in\nboth the labeled and unlabeled data. Extensive experiments conducted on four\ndatasets demonstrate the effectiveness of the proposed algorithm for multi-view\nsemi-supervised learning. \n\n"}
{"id": "1811.05027", "contents": "Title: Deep Neural Network Augmentation: Generating Faces for Affect Analysis Abstract: This paper presents a novel approach for synthesizing facial affect; either\nin terms of the six basic expressions (i.e., anger, disgust, fear, joy, sadness\nand surprise), or in terms of valence (i.e., how positive or negative is an\nemotion) and arousal (i.e., power of the emotion activation). The proposed\napproach accepts the following inputs: i) a neutral 2D image of a person; ii) a\nbasic facial expression or a pair of valence-arousal (VA) emotional state\ndescriptors to be generated, or a path of affect in the 2D VA Space to be\ngenerated as an image sequence. In order to synthesize affect in terms of VA,\nfor this person, $600,000$ frames from the 4DFAB database were annotated. The\naffect synthesis is implemented by fitting a 3D Morphable Model on the neutral\nimage, then deforming the reconstructed face and adding the inputted affect,\nand blending the new face with the given affect into the original image.\nQualitative experiments illustrate the generation of realistic images, when the\nneutral image is sampled from thirteen well known lab-controlled or in-the-wild\ndatabases, including Aff-Wild, AffectNet, RAF-DB; comparisons with Generative\nAdversarial Networks (GANs) show the higher quality achieved by the proposed\napproach. Then, quantitative experiments are conducted, in which the\nsynthesized images are used for data augmentation in training Deep Neural\nNetworks to perform affect recognition over all databases; greatly improved\nperformances are achieved when compared with state-of-the-art methods, as well\nas with GAN-based data augmentation, in all cases. \n\n"}
{"id": "1811.05512", "contents": "Title: A domain agnostic measure for monitoring and evaluating GANs Abstract: Generative Adversarial Networks (GANs) have shown remarkable results in\nmodeling complex distributions, but their evaluation remains an unsettled\nissue. Evaluations are essential for: (i) relative assessment of different\nmodels and (ii) monitoring the progress of a single model throughout training.\nThe latter cannot be determined by simply inspecting the generator and\ndiscriminator loss curves as they behave non-intuitively. We leverage the\nnotion of duality gap from game theory to propose a measure that addresses both\n(i) and (ii) at a low computational cost. Extensive experiments show the\neffectiveness of this measure to rank different GAN models and capture the\ntypical GAN failure scenarios, including mode collapse and non-convergent\nbehaviours. This evaluation metric also provides meaningful monitoring on the\nprogression of the loss during training. It highly correlates with FID on\nnatural image datasets, and with domain specific scores for text, sound and\ncosmology data where FID is not directly suitable. In particular, our proposed\nmetric requires no labels or a pretrained classifier, making it domain\nagnostic. \n\n"}
{"id": "1811.05544", "contents": "Title: An Introductory Survey on Attention Mechanisms in NLP Problems Abstract: First derived from human intuition, later adapted to machine translation for\nautomatic token alignment, attention mechanism, a simple method that can be\nused for encoding sequence data based on the importance score each element is\nassigned, has been widely applied to and attained significant improvement in\nvarious tasks in natural language processing, including sentiment\nclassification, text summarization, question answering, dependency parsing,\netc. In this paper, we survey through recent works and conduct an introductory\nsummary of the attention mechanism in different NLP problems, aiming to provide\nour readers with basic knowledge on this widely used method, discuss its\ndifferent variants for different tasks, explore its association with other\ntechniques in machine learning, and examine methods for evaluating its\nperformance. \n\n"}
{"id": "1811.05826", "contents": "Title: Char2char Generation with Reranking for the E2E NLG Challenge Abstract: This paper describes our submission to the E2E NLG Challenge. Recently,\nneural seq2seq approaches have become mainstream in NLG, often resorting to\npre- (respectively post-) processing delexicalization (relexicalization) steps\nat the word-level to handle rare words. By contrast, we train a simple\ncharacter level seq2seq model, which requires no pre/post-processing\n(delexicalization, tokenization or even lowercasing), with surprisingly good\nresults. For further improvement, we explore two re-ranking approaches for\nscoring candidates. We also introduce a synthetic dataset creation procedure,\nwhich opens up a new way of creating artificial datasets for Natural Language\nGeneration. \n\n"}
{"id": "1811.06341", "contents": "Title: Spatio-temporal Stacked LSTM for Temperature Prediction in Weather\n  Forecasting Abstract: Long Short-Term Memory (LSTM) is a well-known method used widely on sequence\nlearning and time series prediction. In this paper we deployed stacked LSTM\nmodel in an application of weather forecasting. We propose a 2-layer\nspatio-temporal stacked LSTM model which consists of independent LSTM models\nper location in the first LSTM layer. Subsequently, the input of the second\nLSTM layer is formed based on the combination of the hidden states of the first\nlayer LSTM models. The experiments show that by utilizing the spatial\ninformation the prediction performance of the stacked LSTM model improves in\nmost of the cases. \n\n"}
{"id": "1811.06529", "contents": "Title: On transfer learning using a MAC model variant Abstract: We introduce a variant of the MAC model (Hudson and Manning, ICLR 2018) with\na simplified set of equations that achieves comparable accuracy, while training\nfaster. We evaluate both models on CLEVR and CoGenT, and show that, transfer\nlearning with fine-tuning results in a 15 point increase in accuracy, matching\nthe state of the art. Finally, in contrast, we demonstrate that improper\nfine-tuning can actually reduce a model's accuracy as well. \n\n"}
{"id": "1811.06533", "contents": "Title: Learning to Predict the Cosmological Structure Formation Abstract: Matter evolved under influence of gravity from minuscule density\nfluctuations. Non-perturbative structure formed hierarchically over all scales,\nand developed non-Gaussian features in the Universe, known as the Cosmic Web.\nTo fully understand the structure formation of the Universe is one of the holy\ngrails of modern astrophysics. Astrophysicists survey large volumes of the\nUniverse and employ a large ensemble of computer simulations to compare with\nthe observed data in order to extract the full information of our own Universe.\nHowever, to evolve trillions of galaxies over billions of years even with the\nsimplest physics is a daunting task. We build a deep neural network, the Deep\nDensity Displacement Model (hereafter D$^3$M), to predict the non-linear\nstructure formation of the Universe from simple linear perturbation theory. Our\nextensive analysis, demonstrates that D$^3$M outperforms the second order\nperturbation theory (hereafter 2LPT), the commonly used fast approximate\nsimulation method, in point-wise comparison, 2-point correlation, and 3-point\ncorrelation. We also show that D$^3$M is able to accurately extrapolate far\nbeyond its training data, and predict structure formation for significantly\ndifferent cosmological parameters. Our study proves, for the first time, that\ndeep learning is a practical and accurate alternative to approximate\nsimulations of the gravitational structure formation of the Universe. \n\n"}
{"id": "1811.06588", "contents": "Title: Infinite-Horizon Gaussian Processes Abstract: Gaussian processes provide a flexible framework for forecasting, removing\nnoise, and interpreting long temporal datasets. State space modelling (Kalman\nfiltering) enables these non-parametric models to be deployed on long datasets\nby reducing the complexity to linear in the number of data points. The\ncomplexity is still cubic in the state dimension $m$ which is an impediment to\npractical application. In certain special cases (Gaussian likelihood, regular\nspacing) the GP posterior will reach a steady posterior state when the data are\nvery long. We leverage this and formulate an inference scheme for GPs with\ngeneral likelihoods, where inference is based on single-sweep EP (assumed\ndensity filtering). The infinite-horizon model tackles the cubic cost in the\nstate dimensionality and reduces the cost in the state dimension $m$ to\n$\\mathcal{O}(m^2)$ per data point. The model is extended to online-learning of\nhyperparameters. We show examples for large finite-length modelling problems,\nand present how the method runs in real-time on a smartphone on a continuous\ndata stream updated at 100~Hz. \n\n"}
{"id": "1811.06665", "contents": "Title: Spatial-temporal Multi-Task Learning for Within-field Cotton Yield\n  Prediction Abstract: Understanding and accurately predicting within-field spatial variability of\ncrop yield play a key role in site-specific management of crop inputs such as\nirrigation water and fertilizer for optimized crop production. However, such a\ntask is challenged by the complex interaction between crop growth and\nenvironmental and managerial factors, such as climate, soil conditions,\ntillage, and irrigation. In this paper, we present a novel Spatial-temporal\nMulti-Task Learning algorithms for within-field crop yield prediction in west\nTexas from 2001 to 2003. This algorithm integrates multiple heterogeneous data\nsources to learn different features simultaneously, and to aggregate\nspatial-temporal features by introducing a weighted regularizer to the loss\nfunctions. Our comprehensive experimental results consistently outperform the\nresults of other conventional methods, and suggest a promising approach, which\nimproves the landscape of crop prediction research fields. \n\n"}
{"id": "1811.07023", "contents": "Title: An Infinite Parade of Giraffes: Expressive Augmentation and Complexity\n  Layers for Cartoon Drawing Abstract: In this paper, we explore creative image generation constrained by small\ndata. To partially automate the creation of cartoon sketches consistent with a\nspecific designer's style, where acquiring a very large original image set is\nimpossible or cost prohibitive, we exploit domain specific knowledge for a huge\nreduction in original image requirements, creating an effectively infinite\nnumber of cartoon giraffes from just nine original drawings. We introduce\n\"expressive augmentations\" for cartoon sketches, mathematical transformations\nthat create broad domain appropriate variation, far beyond the usual affine\ntransformations, and we show that chained GANs models trained on the temporal\nstages of drawing or \"complexity layers\" can effectively add character\nappropriate details and finish new drawings in the designer's style.\n  We discuss the application of these tools in design processes for textiles,\ngraphics, architectural elements and interior design. \n\n"}
{"id": "1811.07457", "contents": "Title: Generalizable Adversarial Training via Spectral Normalization Abstract: Deep neural networks (DNNs) have set benchmarks on a wide array of supervised\nlearning tasks. Trained DNNs, however, often lack robustness to minor\nadversarial perturbations to the input, which undermines their true\npracticality. Recent works have increased the robustness of DNNs by fitting\nnetworks using adversarially-perturbed training samples, but the improved\nperformance can still be far below the performance seen in non-adversarial\nsettings. A significant portion of this gap can be attributed to the decrease\nin generalization performance due to adversarial training. In this work, we\nextend the notion of margin loss to adversarial settings and bound the\ngeneralization error for DNNs trained under several well-known gradient-based\nattack schemes, motivating an effective regularization scheme based on spectral\nnormalization of the DNN's weight matrices. We also provide a\ncomputationally-efficient method for normalizing the spectral norm of\nconvolutional layers with arbitrary stride and padding schemes in deep\nconvolutional networks. We evaluate the power of spectral normalization\nextensively on combinations of datasets, network architectures, and adversarial\ntraining schemes. The code is available at\nhttps://github.com/jessemzhang/dl_spectral_normalization. \n\n"}
{"id": "1811.07490", "contents": "Title: Memory In Memory: A Predictive Neural Network for Learning Higher-Order\n  Non-Stationarity from Spatiotemporal Dynamics Abstract: Natural spatiotemporal processes can be highly non-stationary in many ways,\ne.g. the low-level non-stationarity such as spatial correlations or temporal\ndependencies of local pixel values; and the high-level variations such as the\naccumulation, deformation or dissipation of radar echoes in precipitation\nforecasting. From Cramer's Decomposition, any non-stationary process can be\ndecomposed into deterministic, time-variant polynomials, plus a zero-mean\nstochastic term. By applying differencing operations appropriately, we may turn\ntime-variant polynomials into a constant, making the deterministic component\npredictable. However, most previous recurrent neural networks for\nspatiotemporal prediction do not use the differential signals effectively, and\ntheir relatively simple state transition functions prevent them from learning\ntoo complicated variations in spacetime. We propose the Memory In Memory (MIM)\nnetworks and corresponding recurrent blocks for this purpose. The MIM blocks\nexploit the differential signals between adjacent recurrent states to model the\nnon-stationary and approximately stationary properties in spatiotemporal\ndynamics with two cascaded, self-renewed memory modules. By stacking multiple\nMIM blocks, we could potentially handle higher-order non-stationarity. The MIM\nnetworks achieve the state-of-the-art results on four spatiotemporal prediction\ntasks across both synthetic and real-world datasets. We believe that the\ngeneral idea of this work can be potentially applied to other time-series\nforecasting tasks. \n\n"}
{"id": "1811.07579", "contents": "Title: Deep Active Learning with a Neural Architecture Search Abstract: We consider active learning of deep neural networks. Most active learning\nworks in this context have focused on studying effective querying mechanisms\nand assumed that an appropriate network architecture is a priori known for the\nproblem at hand. We challenge this assumption and propose a novel active\nstrategy whereby the learning algorithm searches for effective architectures on\nthe fly, while actively learning. We apply our strategy using three known\nquerying techniques (softmax response, MC-dropout, and coresets) and show that\nthe proposed approach overwhelmingly outperforms active learning using fixed\narchitectures. \n\n"}
{"id": "1811.07727", "contents": "Title: Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct? Abstract: Yes, they do. This work investigates a perspective for deep learning: whether\ndifferent normalization layers in a ConvNet require different normalizers. This\nis the first step towards understanding this phenomenon. We allow each\nconvolutional layer to be stacked before a switchable normalization (SN) that\nlearns to choose a normalizer from a pool of normalization methods. Through\nsystematic experiments in ImageNet, COCO, Cityscapes, and ADE20K, we answer\nthree questions: (a) Is it useful to allow each normalization layer to select\nits own normalizer? (b) What impacts the choices of normalizers? (c) Do\ndifferent tasks and datasets prefer different normalizers? Our results suggest\nthat (1) using distinct normalizers improves both learning and generalization\nof a ConvNet; (2) the choices of normalizers are more related to depth and\nbatch size, but less relevant to parameter initialization, learning rate decay,\nand solver; (3) different tasks and datasets have different behaviors when\nlearning to select normalizers. \n\n"}
{"id": "1811.07769", "contents": "Title: Addressing the Invisible: Street Address Generation for Developing\n  Countries with Deep Learning Abstract: More than half of the world's roads lack adequate street addressing systems.\nLack of addresses is even more visible in daily lives of people in developing\ncountries. We would like to object to the assumption that having an address is\na luxury, by proposing a generative address design that maps the world in\naccordance with streets. The addressing scheme is designed considering several\ntraditional street addressing methodologies employed in the urban development\nscenarios around the world. Our algorithm applies deep learning to extract\nroads from satellite images, converts the road pixel confidences into a road\nnetwork, partitions the road network to find neighborhoods, and labels the\nregions, roads, and address units using graph- and proximity-based algorithms.\nWe present our results on a sample US city, and several developing cities,\ncompare travel times of users using current ad hoc and new complete addresses,\nand contrast our addressing solution to current industrial and open geocoding\nalternatives. \n\n"}
{"id": "1811.07896", "contents": "Title: Slum Segmentation and Change Detection : A Deep Learning Approach Abstract: More than one billion people live in slums around the world. In some\ndeveloping countries, slum residents make up for more than half of the\npopulation and lack reliable sanitation services, clean water, electricity,\nother basic services. Thus, slum rehabilitation and improvement is an important\nglobal challenge, and a significant amount of effort and resources have been\nput into this endeavor. These initiatives rely heavily on slum mapping and\nmonitoring, and it is essential to have robust and efficient methods for\nmapping and monitoring existing slum settlements. In this work, we introduce an\napproach to segment and map individual slums from satellite imagery, leveraging\nregional convolutional neural networks for instance segmentation using transfer\nlearning. In addition, we also introduce a method to perform change detection\nand monitor slum change over time. We show that our approach effectively learns\nslum shape and appearance, and demonstrates strong quantitative results,\nresulting in a maximum AP of 80.0. \n\n"}
{"id": "1811.08871", "contents": "Title: Efficient nonmyopic active search with applications in drug and\n  materials discovery Abstract: Active search is a learning paradigm for actively identifying as many members\nof a given class as possible. A critical target scenario is high-throughput\nscreening for scientific discovery, such as drug or materials discovery. In\nthis paper, we approach this problem in Bayesian decision framework. We first\nderive the Bayesian optimal policy under a natural utility, and establish a\ntheoretical hardness of active search, proving that the optimal policy can not\nbe approximated for any constant ratio. We also study the batch setting for the\nfirst time, where a batch of $b>1$ points can be queried at each iteration. We\ngive an asymptotic lower bound, linear in batch size, on the adaptivity gap:\nhow much we could lose if we query $b$ points at a time for $t$ iterations,\ninstead of one point at a time for $bt$ iterations. We then introduce a novel\napproach to nonmyopic approximations of the optimal policy that admits\nefficient computation. Our proposed policy can automatically trade off\nexploration and exploitation, without relying on any tuning parameters. We also\ngeneralize our policy to batch setting, and propose two approaches to tackle\nthe combinatorial search challenge. We evaluate our proposed policies on a\nlarge database of drug discovery and materials science. Results demonstrate the\nsuperior performance of our proposed policy in both sequential and batch\nsetting; the nonmyopic behavior is also illustrated in various aspects. \n\n"}
{"id": "1811.09794", "contents": "Title: Three-Dimensionally Embedded Graph Convolutional Network (3DGCN) for\n  Molecule Interpretation Abstract: We present a three-dimensional graph convolutional network (3DGCN), which\npredicts molecular properties and biochemical activities, based on 3D molecular\ngraph. In the 3DGCN, graph convolution is unified with learning operations on\nthe vector to handle the spatial information from molecular topology. The 3DGCN\nmodel exhibits significantly higher performance on various tasks compared with\nother deep-learning models, and has the ability of generalizing a given\nconformer to targeted features regardless of its rotations in the 3D space.\nMore significantly, our model also can distinguish the 3D rotations of a\nmolecule and predict the target value, depending upon the rotation degree, in\nthe protein-ligand docking problem, when trained with orientation-dependent\ndatasets. The rotation distinguishability of 3DGCN, along with rotation\nequivariance, provides a key milestone in the implementation of\nthree-dimensionality to the field of deep-learning chemistry that solves\nchallenging biochemical problems. \n\n"}
{"id": "1811.09890", "contents": "Title: Anisotropic Compact stars in the Buchdahl model: A comprehensive study Abstract: In this article, we present a class of relativistic solutions describing\nspherically symmetric and static anisotropic stars in hydrostatic equilibrium.\nFor this purpose, we consider a particularized matric potential, namely,\nBuchdahl ansatz [Phys. Rev. D \\textbf{116}, 1027 (1959).] which encompasses\nalmost all the known analytic solutions to the spherically symmetric, static\nEinstein field equations(EFEs) with a perfect fluid source, including in\nparticular the Vaidya-Tikekar and Finch-Skea. We here developed the model by\nconsidering an anisotropic spherically symmetric static general relativistic\nconfiguration that plays a significant effect on the structure and properties\nof stellar objects. We have considered eight different cases for generalized\nBuchdahl dimensionless parameter $K$, and analyzed them in a uniform manner. As\na result, it turns out that all the considered cases are valid at every point\nin the interior spacetime. In addition to this, we show that the model\nsatisfies all the energy conditions and maintains the hydrostatic equilibrium\nequation. In the framework of the anisotropic hypothesis, we consider analogue\nobjects with similar mass and radii such as LMC X-4, SMC X-1, EXO 1785-248\n\\emph{etc} to restrict the model parameter arbitrariness. Also, establishing a\nrelation between pressure and density in the form of $P = P (\\rho)$, we\ndemonstrate that EoSs can be approximated to a linear function of density.\nDespite the simplicity of this model, the obtained results are satisfactory. \n\n"}
{"id": "1811.10347", "contents": "Title: Estimating Causal Effects With Partial Covariates For Clinical\n  Interpretability Abstract: Estimating the causal effects of an intervention in the presence of\nconfounding is a frequently occurring problem in applications such as medicine.\nThe task is challenging since there may be multiple confounding factors, some\nof which may be missing, and inferences must be made from high-dimensional,\nnoisy measurements. In this paper, we propose a decision-theoretic approach to\nestimate the causal effects of interventions where a subset of the covariates\nis unavailable for some patients during testing. Our approach uses the\ninformation bottleneck principle to perform a discrete, low-dimensional\nsufficient reduction of the covariate data to estimate a distribution over\nconfounders. In doing so, we can estimate the causal effect of an intervention\nwhere only partial covariate information is available. Our results on a causal\ninference benchmark and a real application for treating sepsis show that our\nmethod achieves state-of-the-art performance, without sacrificing\ninterpretability. \n\n"}
{"id": "1811.10797", "contents": "Title: Node Embedding with Adaptive Similarities for Scalable Learning over\n  Graphs Abstract: Node embedding is the task of extracting informative and descriptive features\nover the nodes of a graph. The importance of node embeddings for graph\nanalytics, as well as learning tasks such as node classification, link\nprediction and community detection, has led to increased interest on the\nproblem leading to a number of recent advances. Much like PCA in the feature\ndomain, node embedding is an inherently \\emph{unsupervised} task; in lack of\nmetadata used for validation, practical methods may require standardization and\nlimiting the use of tunable hyperparameters. Finally, node embedding methods\nare faced with maintaining scalability in the face of large-scale real-world\ngraphs of ever-increasing sizes. In the present work, we propose an adaptive\nnode embedding framework that adjusts the embedding process to a given\nunderlying graph, in a fully unsupervised manner. To achieve this, we adopt the\nnotion of a tunable node similarity matrix that assigns weights on paths of\ndifferent length. The design of the multilength similarities ensures that the\nresulting embeddings also inherit interpretable spectral properties. The\nproposed model is carefully studied, interpreted, and numerically evaluated\nusing stochastic block models. Moreover, an algorithmic scheme is proposed for\ntraining the model parameters effieciently and in an unsupervised manner. We\nperform extensive node classification, link prediction, and clustering\nexperiments on many real world graphs from various domains, and compare with\nstate-of-the-art scalable and unsupervised node embedding alternatives. The\nproposed method enjoys superior performance in many cases, while also yielding\ninterpretable information on the underlying structure of the graph. \n\n"}
{"id": "1811.10990", "contents": "Title: Generating Responses Expressing Emotion in an Open-domain Dialogue\n  System Abstract: Neural network-based Open-ended conversational agents automatically generate\nresponses based on predictive models learned from a large number of pairs of\nutterances. The generated responses are typically acceptable as a sentence but\nare often dull, generic, and certainly devoid of any emotion. In this paper, we\npresent neural models that learn to express a given emotion in the generated\nresponse. We propose four models and evaluate them against 3 baselines. An\nencoder-decoder framework-based model with multiple attention layers provides\nthe best overall performance in terms of expressing the required emotion. While\nit does not outperform other models on all emotions, it presents promising\nresults in most cases. \n\n"}
{"id": "1811.11103", "contents": "Title: Bayesian graph convolutional neural networks for semi-supervised\n  classification Abstract: Recently, techniques for applying convolutional neural networks to\ngraph-structured data have emerged. Graph convolutional neural networks (GCNNs)\nhave been used to address node and graph classification and matrix completion.\nAlthough the performance has been impressive, the current implementations have\nlimited capability to incorporate uncertainty in the graph structure. Almost\nall GCNNs process a graph as though it is a ground-truth depiction of the\nrelationship between nodes, but often the graphs employed in applications are\nthemselves derived from noisy data or modelling assumptions. Spurious edges may\nbe included; other edges may be missing between nodes that have very strong\nrelationships. In this paper we adopt a Bayesian approach, viewing the observed\ngraph as a realization from a parametric family of random graphs. We then\ntarget inference of the joint posterior of the random graph parameters and the\nnode (or graph) labels. We present the Bayesian GCNN framework and develop an\niterative learning procedure for the case of assortative mixed-membership\nstochastic block models. We present the results of experiments that demonstrate\nthat the Bayesian formulation can provide better performance when there are\nvery few labels available during the training process. \n\n"}
{"id": "1811.11222", "contents": "Title: Grammars and reinforcement learning for molecule optimization Abstract: We seek to automate the design of molecules based on specific chemical\nproperties. Our primary contributions are a simpler method for generating\nSMILES strings guaranteed to be chemically valid, using a combination of a new\ncontext-free grammar for SMILES and additional masking logic; and casting the\nmolecular property optimization as a reinforcement learning problem,\nspecifically best-of-batch policy gradient applied to a Transformer model\narchitecture. This approach uses substantially fewer model steps per atom than\nearlier approaches, thus enabling generation of larger molecules, and beats\nprevious state-of-the art baselines by a significant margin. Applying\nreinforcement learning to a combination of a custom context-free grammar with\nadditional masking to enforce non-local constraints is applicable to any\noptimization of a graph structure under a mixture of local and nonlocal\nconstraints. \n\n"}
{"id": "1811.11264", "contents": "Title: Synthesizing Tabular Data using Generative Adversarial Networks Abstract: Generative adversarial networks (GANs) implicitly learn the probability\ndistribution of a dataset and can draw samples from the distribution. This\npaper presents, Tabular GAN (TGAN), a generative adversarial network which can\ngenerate tabular data like medical or educational records. Using the power of\ndeep neural networks, TGAN generates high-quality and fully synthetic tables\nwhile simultaneously generating discrete and continuous variables. When we\nevaluate our model on three datasets, we find that TGAN outperforms\nconventional statistical generative models in both capturing the correlation\nbetween columns and scaling up for large datasets. \n\n"}
{"id": "1811.11989", "contents": "Title: Sample Efficient Stochastic Variance-Reduced Cubic Regularization Method Abstract: We propose a sample efficient stochastic variance-reduced cubic\nregularization (Lite-SVRC) algorithm for finding the local minimum efficiently\nin nonconvex optimization. The proposed algorithm achieves a lower sample\ncomplexity of Hessian matrix computation than existing cubic regularization\nbased methods. At the heart of our analysis is the choice of a constant batch\nsize of Hessian matrix computation at each iteration and the stochastic\nvariance reduction techniques. In detail, for a nonconvex function with $n$\ncomponent functions, Lite-SVRC converges to the local minimum within\n$\\tilde{O}(n+n^{2/3}/\\epsilon^{3/2})$ Hessian sample complexity, which is\nfaster than all existing cubic regularization based methods. Numerical\nexperiments with different nonconvex optimization problems conducted on real\ndatasets validate our theoretical results. \n\n"}
{"id": "1811.12234", "contents": "Title: Machine Learning on Electronic Health Records: Models and Features\n  Usages to predict Medication Non-Adherence Abstract: Adherence can be defined as \"the extent to which patients take their\nmedications as prescribed by their healthcare providers\"[Osterberg and\nBlaschke, 2005]. World Health Organization's reports point out that, in\ndeveloped countries, only about 50% of patients with chronic diseases correctly\nfollow their treatments. This severely compromises the efficiency of long-term\ntherapy and increases the cost of health services. We propose in this paper\ndifferent models of patient drug consumption in breast cancer treatments. The\naim of these different approaches is to predict medication non-adherence while\ngiving insights to doctors of the underlying reasons of these illegitimate\ndrop-outs. Working with oncologists, we show the interest of Machine- Learning\nalgorithms fined tune by the feedback of experts to estimate a risk score of a\npatient's non-adherence and thus improve support throughout their care path. \n\n"}
{"id": "1812.00139", "contents": "Title: Number of Connected Components in a Graph: Estimation via Counting\n  Patterns Abstract: Due to the limited resources and the scale of the graphs in modern datasets,\nwe often get to observe a sampled subgraph of a larger original graph of\ninterest, whether it is the worldwide web that has been crawled or social\nconnections that have been surveyed. Inferring a global property of the\noriginal graph from such a sampled subgraph is of a fundamental interest. In\nthis work, we focus on estimating the number of connected components. It is a\nchallenging problem and, for general graphs, little is known about the\nconnection between the observed subgraph and the number of connected components\nof the original graph. In order to make this connection, we propose a highly\nredundant and large-dimensional representation of the subgraph, which at first\nglance seems counter-intuitive. A subgraph is represented by the counts of\npatterns, known as network motifs. This representation is crucial in\nintroducing a novel estimator for the number of connected components for\ngeneral graphs, under the knowledge of the spectral gap of the original graph.\nThe connection is made precise via the Schatten $k$-norms of the graph\nLaplacian and the spectral representation of the number of connected\ncomponents. We provide a guarantee on the resulting mean squared error that\ncharacterizes the bias variance tradeoff. Experiments on synthetic and\nreal-world graphs suggest that we improve upon competing algorithms for graphs\nwith spectral gaps bounded away from zero. \n\n"}
{"id": "1812.00415", "contents": "Title: Feature Selection Based on Unique Relevant Information for Health Data Abstract: Feature selection, which searches for the most representative features in\nobserved data, is critical for health data analysis. Unlike feature extraction,\nsuch as PCA and autoencoder based methods, feature selection preserves\ninterpretability, meaning that the selected features provide direct information\nabout certain health conditions (i.e., the label). Thus, feature selection\nallows domain experts, such as clinicians, to understand the predictions made\nby machine learning based systems, as well as improve their own diagnostic\nskills. Mutual information is often used as a basis for feature selection since\nit measures dependencies between features and labels. In this paper, we\nintroduce a novel mutual information based feature selection (MIBFS) method\ncalled SURI, which boosts features with high unique relevant information. We\ncompare SURI to existing MIBFS methods using 3 different classifiers on 6\npublicly available healthcare data sets. The results indicate that, in addition\nto preserving interpretability, SURI selects more relevant feature subsets\nwhich lead to higher classification performance. More importantly, we explore\nthe dynamics of mutual information on a public low-dimensional health data set\nvia exhaustive search. The results suggest the important role of unique\nrelevant information in feature selection and verify the principles behind\nSURI. \n\n"}
{"id": "1812.00420", "contents": "Title: Efficient Lifelong Learning with A-GEM Abstract: In lifelong learning, the learner is presented with a sequence of tasks,\nincrementally building a data-driven prior which may be leveraged to speed up\nlearning of a new task. In this work, we investigate the efficiency of current\nlifelong approaches, in terms of sample complexity, computational and memory\ncost. Towards this end, we first introduce a new and a more realistic\nevaluation protocol, whereby learners observe each example only once and\nhyper-parameter selection is done on a small and disjoint set of tasks, which\nis not used for the actual learning experience and evaluation. Second, we\nintroduce a new metric measuring how quickly a learner acquires a new skill.\nThird, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017),\ndubbed Averaged GEM (A-GEM), which enjoys the same or even better performance\nas GEM, while being almost as computationally and memory efficient as EWC\n(Kirkpatrick et al., 2016) and other regularization-based methods. Finally, we\nshow that all algorithms including A-GEM can learn even more quickly if they\nare provided with task descriptors specifying the classification tasks under\nconsideration. Our experiments on several standard lifelong learning benchmarks\ndemonstrate that A-GEM has the best trade-off between accuracy and efficiency. \n\n"}
{"id": "1812.00422", "contents": "Title: A multi-task deep learning model for the classification of Age-related\n  Macular Degeneration Abstract: Age-related Macular Degeneration (AMD) is a leading cause of blindness.\nAlthough the Age-Related Eye Disease Study group previously developed a 9-step\nAMD severity scale for manual classification of AMD severity from color fundus\nimages, manual grading of images is time-consuming and expensive. Built on our\nprevious work DeepSeeNet, we developed a novel deep learning model for\nautomated classification of images into the 9-step scale. Instead of predicting\nthe 9-step score directly, our approach simulates the reading center grading\nprocess. It first detects four AMD characteristics (drusen area, geographic\natrophy, increased pigment, and depigmentation), then combines these to derive\nthe overall 9-step score. Importantly, we applied multi-task learning\ntechniques, which allowed us to train classification of the four\ncharacteristics in parallel, share representation, and prevent overfitting.\nEvaluation on two image datasets showed that the accuracy of the model exceeded\nthe current state-of-the-art model by > 10%. \n\n"}
{"id": "1812.00786", "contents": "Title: Generating Material Maps to Map Informal Settlements Abstract: Detecting and mapping informal settlements encompasses several of the United\nNations sustainable development goals. This is because informal settlements are\nhome to the most socially and economically vulnerable people on the planet.\nThus, understanding where these settlements are is of paramount importance to\nboth government and non-government organizations (NGOs), such as the United\nNations Children's Fund (UNICEF), who can use this information to deliver\neffective social and economic aid. We propose a method that detects and maps\nthe locations of informal settlements using only freely available, Sentinel-2\nlow-resolution satellite spectral data and socio-economic data. This is in\ncontrast to previous studies that only use costly very-high resolution (VHR)\nsatellite and aerial imagery. We show how we can detect informal settlements by\ncombining both domain knowledge and machine learning techniques, to build a\nclassifier that looks for known roofing materials used in informal settlements.\nPlease find additional material at\nhttps://frontierdevelopmentlab.github.io/informal-settlements/. \n\n"}
{"id": "1812.00877", "contents": "Title: Automatic lesion boundary detection in dermoscopy Abstract: This manuscript addresses the problem of the automatic lesion boundary\ndetection in dermoscopy, using deep neural networks. An approach is based on\nthe adaptation of the U-net convolutional neural network with skip connections\nfor lesion boundary segmentation task. I hope this paper could serve, to some\nextent, as an experiment of using deep convolutional networks in biomedical\nsegmentation task and as a guideline of the boundary detection benchmark,\ninspiring further attempts and researches. \n\n"}
{"id": "1812.00914", "contents": "Title: Accelerating Large Scale Knowledge Distillation via Dynamic Importance\n  Sampling Abstract: Knowledge distillation is an effective technique that transfers knowledge\nfrom a large teacher model to a shallow student. However, just like massive\nclassification, large scale knowledge distillation also imposes heavy\ncomputational costs on training models of deep neural networks, as the softmax\nactivations at the last layer involve computing probabilities over numerous\nclasses. In this work, we apply the idea of importance sampling which is often\nused in Neural Machine Translation on large scale knowledge distillation. We\npresent a method called dynamic importance sampling, where ranked classes are\nsampled from a dynamic distribution derived from the interaction between the\nteacher and student in full distillation. We highlight the utility of our\nproposal prior which helps the student capture the main information in the loss\nfunction. Our approach manages to reduce the computational cost at training\ntime while maintaining the competitive performance on CIFAR-100 and Market-1501\nperson re-identification datasets. \n\n"}
{"id": "1812.01074", "contents": "Title: Distilling Information from a Flood: A Possibility for the Use of\n  Meta-Analysis and Systematic Review in Machine Learning Research Abstract: The current flood of information in all areas of machine learning research,\nfrom computer vision to reinforcement learning, has made it difficult to make\naggregate scientific inferences. It can be challenging to distill a myriad of\nsimilar papers into a set of useful principles, to determine which new\nmethodologies to use for a particular application, and to be confident that one\nhas compared against all relevant related work when developing new ideas.\nHowever, such a rapidly growing body of research literature is a problem that\nother fields have already faced - in particular, medicine and epidemiology. In\nthose fields, systematic reviews and meta-analyses have been used exactly for\ndealing with these issues and it is not uncommon for entire journals to be\ndedicated to such analyses. Here, we suggest the field of machine learning\nmight similarly benefit from meta-analysis and systematic review, and we\nencourage further discussion and development along this direction. \n\n"}
{"id": "1812.01484", "contents": "Title: Privacy-Preserving Distributed Deep Learning for Clinical Data Abstract: Deep learning with medical data often requires larger samples sizes than are\navailable at single providers. While data sharing among institutions is\ndesirable to train more accurate and sophisticated models, it can lead to\nsevere privacy concerns due the sensitive nature of the data. This problem has\nmotivated a number of studies on distributed training of neural networks that\ndo not require direct sharing of the training data. However, simple distributed\ntraining does not offer provable privacy guarantees to satisfy technical safe\nstandards and may reveal information about the underlying patients. We present\na method to train neural networks for clinical data in a distributed fashion\nunder differential privacy. We demonstrate these methods on two datasets that\ninclude information from multiple independent sites, the eICU collaborative\nResearch Database and The Cancer Genome Atlas. \n\n"}
{"id": "1812.01713", "contents": "Title: FineFool: Fine Object Contour Attack via Attention Abstract: Machine learning models have been shown vulnerable to adversarial attacks\nlaunched by adversarial examples which are carefully crafted by attacker to\ndefeat classifiers. Deep learning models cannot escape the attack either. Most\nof adversarial attack methods are focused on success rate or perturbations\nsize, while we are more interested in the relationship between adversarial\nperturbation and the image itself. In this paper, we put forward a novel\nadversarial attack based on contour, named FineFool. Finefool not only has\nbetter attack performance compared with other state-of-art white-box attacks in\naspect of higher attack success rate and smaller perturbation, but also capable\nof visualization the optimal adversarial perturbation via attention on object\ncontour. To the best of our knowledge, Finefool is for the first time combines\nthe critical feature of the original clean image with the optimal perturbations\nin a visible manner. Inspired by the correlations between adversarial\nperturbations and object contour, slighter perturbations is produced via\nfocusing on object contour features, which is more imperceptible and difficult\nto be defended, especially network add-on defense methods with the trade-off\nbetween perturbations filtering and contour feature loss. Compared with\nexisting state-of-art attacks, extensive experiments are conducted to show that\nFinefool is capable of efficient attack against defensive deep models. \n\n"}
{"id": "1812.01718", "contents": "Title: Deep Learning for Classical Japanese Literature Abstract: Much of machine learning research focuses on producing models which perform\nwell on benchmark tasks, in turn improving our understanding of the challenges\nassociated with those tasks. From the perspective of ML researchers, the\ncontent of the task itself is largely irrelevant, and thus there have\nincreasingly been calls for benchmark tasks to more heavily focus on problems\nwhich are of social or cultural relevance. In this work, we introduce\nKuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as\nwell as two larger, more challenging datasets, Kuzushiji-49 and\nKuzushiji-Kanji. Through these datasets, we wish to engage the machine learning\ncommunity into the world of classical Japanese literature. Dataset available at\nhttps://github.com/rois-codh/kmnist \n\n"}
{"id": "1812.01729", "contents": "Title: Boltzmann Generators -- Sampling Equilibrium States of Many-Body Systems\n  with Deep Learning Abstract: Computing equilibrium states in condensed-matter many-body systems, such as\nsolvated proteins, is a long-standing challenge. Lacking methods for generating\nstatistically independent equilibrium samples in \"one shot\", vast computational\neffort is invested for simulating these system in small steps, e.g., using\nMolecular Dynamics. Combining deep learning and statistical mechanics, we here\ndevelop Boltzmann Generators, that are shown to generate unbiased one-shot\nequilibrium samples of representative condensed matter systems and proteins.\nBoltzmann Generators use neural networks to learn a coordinate transformation\nof the complex configurational equilibrium distribution to a distribution that\ncan be easily sampled. Accurate computation of free energy differences and\ndiscovery of new configurations are demonstrated, providing a statistical\nmechanics tool that can avoid rare events during sampling without prior\nknowledge of reaction coordinates. \n\n"}
{"id": "1812.02159", "contents": "Title: The effects of negative adaptation in Model-Agnostic Meta-Learning Abstract: The capacity of meta-learning algorithms to quickly adapt to a variety of\ntasks, including ones they did not experience during meta-training, has been a\nkey factor in the recent success of these methods on few-shot learning\nproblems. This particular advantage of using meta-learning over standard\nsupervised or reinforcement learning is only well founded under the assumption\nthat the adaptation phase does improve the performance of our model on the task\nof interest. However, in the classical framework of meta-learning, this\nconstraint is only mildly enforced, if not at all, and we only see an\nimprovement on average over a distribution of tasks. In this paper, we show\nthat the adaptation in an algorithm like MAML can significantly decrease the\nperformance of an agent in a meta-reinforcement learning setting, even on a\nrange of meta-training tasks. \n\n"}
{"id": "1812.02261", "contents": "Title: GADGET SVM: A Gossip-bAseD sub-GradiEnT Solver for Linear SVMs Abstract: In the era of big data, an important weapon in a machine learning\nresearcher's arsenal is a scalable Support Vector Machine (SVM) algorithm. SVMs\nare extensively used for solving classification problems. Traditional\nalgorithms for learning SVMs often scale super linearly with training set size\nwhich becomes infeasible very quickly for large data sets. In recent years,\nscalable algorithms have been designed which study the primal or dual\nformulations of the problem. This often suggests a way to decompose the problem\nand facilitate development of distributed algorithms. In this paper, we present\na distributed algorithm for learning linear Support Vector Machines in the\nprimal form for binary classification called Gossip-bAseD sub-GradiEnT (GADGET)\nSVM. The algorithm is designed such that it can be executed locally on nodes of\na distributed system. Each node processes its local homogeneously partitioned\ndata and learns a primal SVM model. It then gossips with random neighbors about\nthe classifier learnt and uses this information to update the model. Extensive\ntheoretical and empirical results suggest that this anytime algorithm has\nperformance comparable to its centralized and online counterparts. \n\n"}
{"id": "1812.02353", "contents": "Title: Top-K Off-Policy Correction for a REINFORCE Recommender System Abstract: Industrial recommender systems deal with extremely large action spaces --\nmany millions of items to recommend. Moreover, they need to serve billions of\nusers, who are unique at any point in time, making a complex user state space.\nLuckily, huge quantities of logged implicit feedback (e.g., user clicks, dwell\ntime) are available for learning. Learning from the logged feedback is however\nsubject to biases caused by only observing feedback on recommendations selected\nby the previous versions of the recommender. In this work, we present a general\nrecipe of addressing such biases in a production top-K recommender system at\nYoutube, built with a policy-gradient-based algorithm, i.e. REINFORCE. The\ncontributions of the paper are: (1) scaling REINFORCE to a production\nrecommender system with an action space on the orders of millions; (2) applying\noff-policy correction to address data biases in learning from logged feedback\ncollected from multiple behavior policies; (3) proposing a novel top-K\noff-policy correction to account for our policy recommending multiple items at\na time; (4) showcasing the value of exploration. We demonstrate the efficacy of\nour approaches through a series of simulations and multiple live experiments on\nYoutube. \n\n"}
{"id": "1812.02648", "contents": "Title: Deep Reinforcement Learning and the Deadly Triad Abstract: We know from reinforcement learning theory that temporal difference learning\ncan fail in certain cases. Sutton and Barto (2018) identify a deadly triad of\nfunction approximation, bootstrapping, and off-policy learning. When these\nthree properties are combined, learning can diverge with the value estimates\nbecoming unbounded. However, several algorithms successfully combine these\nthree properties, which indicates that there is at least a partial gap in our\nunderstanding. In this work, we investigate the impact of the deadly triad in\npractice, in the context of a family of popular deep reinforcement learning\nmodels - deep Q-networks trained with experience replay - analysing how the\ncomponents of this system play a role in the emergence of the deadly triad, and\nin the agent's performance \n\n"}
{"id": "1812.02696", "contents": "Title: Differentially Private Fair Learning Abstract: Motivated by settings in which predictive models may be required to be\nnon-discriminatory with respect to certain attributes (such as race), but even\ncollecting the sensitive attribute may be forbidden or restricted, we initiate\nthe study of fair learning under the constraint of differential privacy. We\ndesign two learning algorithms that simultaneously promise differential privacy\nand equalized odds, a 'fairness' condition that corresponds to equalizing false\npositive and negative rates across protected groups. Our first algorithm is a\nprivate implementation of the equalized odds post-processing approach of [Hardt\net al., 2016]. This algorithm is appealingly simple, but must be able to use\nprotected group membership explicitly at test time, which can be viewed as a\nform of 'disparate treatment'. Our second algorithm is a differentially private\nversion of the oracle-efficient in-processing approach of [Agarwal et al.,\n2018] that can be used to find the optimal fair classifier, given access to a\nsubroutine that can solve the original (not necessarily fair) learning problem.\nThis algorithm is more complex but need not have access to protected group\nmembership at test time. We identify new tradeoffs between fairness, accuracy,\nand privacy that emerge only when requiring all three properties, and show that\nthese tradeoffs can be milder if group membership may be used at test time. We\nconclude with a brief experimental evaluation. \n\n"}
{"id": "1812.02765", "contents": "Title: Improving Reconstruction Autoencoder Out-of-distribution Detection with\n  Mahalanobis Distance Abstract: There is an increasingly apparent need for validating the classifications\nmade by deep learning systems in safety-critical applications like autonomous\nvehicle systems. A number of recent papers have proposed methods for detecting\nanomalous image data that appear different from known inlier data samples,\nincluding reconstruction-based autoencoders. Autoencoders optimize the\ncompression of input data to a latent space of a dimensionality smaller than\nthe original input and attempt to accurately reconstruct the input using that\ncompressed representation. Since the latent vector is optimized to capture the\nsalient features from the inlier class only, it is commonly assumed that images\nof objects from outside of the training class cannot effectively be compressed\nand reconstructed. Some thus consider reconstruction error as a kind of novelty\nmeasure. Here we suggest that reconstruction-based approaches fail to capture\nparticular anomalies that lie far from known inlier samples in latent space but\nnear the latent dimension manifold defined by the parameters of the model. We\npropose incorporating the Mahalanobis distance in latent space to better\ncapture these out-of-distribution samples and our results show that this method\noften improves performance over the baseline approach. \n\n"}
{"id": "1812.02848", "contents": "Title: Cyber Anomaly Detection Using Graph-node Role-dynamics Abstract: Intrusion detection systems (IDSs) generate valuable knowledge about network\nsecurity, but an abundance of false alarms and a lack of methods to capture the\ninterdependence among alerts hampers their utility for network defense. Here,\nwe explore a graph-based approach for fusing alerts generated by multiple IDSs\n(e.g., Snort, OSSEC, and Bro). Our approach generates a weighted graph of alert\nfields (not network topology) that makes explicit the connections between\nmultiple alerts, IDS systems, and other cyber artifacts. We use this\nmulti-modal graph to identify anomalous changes in the alert patterns of a\nnetwork. To detect the anomalies, we apply the role-dynamics approach, which\nhas successfully identified anomalies in social media, email, and IP\ncommunication graphs. In the cyber domain, each node (alert field) in the fused\nIDS alert graph is assigned a probability distribution across a small set of\nroles based on that node's features. A cyber attack should trigger IDS alerts\nand cause changes in the node features, but rather than track every feature for\nevery alert-field node individually, roles provide a succinct, integrated\nsummary of those feature changes. We measure changes in each node's\nprobabilistic role assignment over time, and identify anomalies as deviations\nfrom expected roles. We test our approach using simulations including three\nweeks of normal background traffic, as well as cyber attacks that occur near\nthe end of the simulations. This paper presents a novel approach to multi-modal\ndata fusion and a novel application of role dynamics within the cyber-security\ndomain. Our results show a drastic decrease in the false-positive rate when\nconsidering our anomaly indicator instead of the IDS alerts themselves, thereby\nreducing alarm fatigue and providing a promising avenue for threat intelligence\nin network defense. \n\n"}
{"id": "1812.02962", "contents": "Title: Online Learning and Decision-Making under Generalized Linear Model with\n  High-Dimensional Data Abstract: We propose a minimax concave penalized multi-armed bandit algorithm under\ngeneralized linear model (G-MCP-Bandit) for a decision-maker facing\nhigh-dimensional data in an online learning and decision-making process. We\ndemonstrate that the G-MCP-Bandit algorithm asymptotically achieves the optimal\ncumulative regret in the sample size dimension T , O(log T), and further\nattains a tight bound in the covariate dimension d, O(log d). In addition, we\ndevelop a linear approximation method, the 2-step weighted Lasso procedure, to\nidentify the MCP estimator for the G-MCP-Bandit algorithm under non-iid\nsamples. Under this procedure, the MCP estimator matches the oracle estimator\nwith high probability and converges to the true parameters with the optimal\nconvergence rate. Finally, through experiments based on synthetic data and two\nreal datasets (warfarin dosing dataset and Tencent search advertising dataset),\nwe show that the G-MCP-Bandit algorithm outperforms other benchmark algorithms,\nespecially when there is a high level of data sparsity or the decision set is\nlarge. \n\n"}
{"id": "1812.03188", "contents": "Title: METCC: METric learning for Confounder Control Making distance matter in\n  high dimensional biological analysis Abstract: High-dimensional data acquired from biological experiments such as next\ngeneration sequencing are subject to a number of confounding effects. These\neffects include both technical effects, such as variation across batches from\ninstrument noise or sample processing, or institution-specific differences in\nsample acquisition and physical handling, as well as biological effects arising\nfrom true but irrelevant differences in the biology of each sample, such as age\nbiases in diseases. Prior work has used linear methods to adjust for such batch\neffects. Here, we apply contrastive metric learning by a non-linear triplet\nnetwork to optimize the ability to distinguish biologically distinct sample\nclasses in the presence of irrelevant technical and biological variation. Using\nwhole-genome cell-free DNA data from 817 patients, we demonstrate that our\napproach, METric learning for Confounder Control (METCC), is able to match or\nexceed the classification performance achieved using a best-in-class linear\nmethod (HCP) or no normalization. Critically, results from METCC appear less\nconfounded by irrelevant technical variables like institution and batch than\nthose from other methods even without access to high quality metadata\ninformation required by many existing techniques; offering hope for improved\ngeneralization. \n\n"}
{"id": "1812.03190", "contents": "Title: Deep-RBF Networks Revisited: Robust Classification with Rejection Abstract: One of the main drawbacks of deep neural networks, like many other\nclassifiers, is their vulnerability to adversarial attacks. An important reason\nfor their vulnerability is assigning high confidence to regions with few or\neven no feature points. By feature points, we mean a nonlinear transformation\nof the input space extracting a meaningful representation of the input data. On\nthe other hand, deep-RBF networks assign high confidence only to the regions\ncontaining enough feature points, but they have been discounted due to the\nwidely-held belief that they have the vanishing gradient problem. In this\npaper, we revisit the deep-RBF networks by first giving a general formulation\nfor them, and then proposing a family of cost functions thereof inspired by\nmetric learning. In the proposed deep-RBF learning algorithm, the vanishing\ngradient problem does not occur. We make these networks robust to adversarial\nattack by adding the reject option to their output layer. Through several\nexperiments on the MNIST dataset, we demonstrate that our proposed method not\nonly achieves significant classification accuracy but is also very resistant to\nvarious adversarial attacks. \n\n"}
{"id": "1812.03565", "contents": "Title: The Gap Between Model-Based and Model-Free Methods on the Linear\n  Quadratic Regulator: An Asymptotic Viewpoint Abstract: The effectiveness of model-based versus model-free methods is a long-standing\nquestion in reinforcement learning (RL). Motivated by recent empirical success\nof RL on continuous control tasks, we study the sample complexity of popular\nmodel-based and model-free algorithms on the Linear Quadratic Regulator (LQR).\nWe show that for policy evaluation, a simple model-based plugin method requires\nasymptotically less samples than the classical least-squares temporal\ndifference (LSTD) estimator to reach the same quality of solution; the sample\ncomplexity gap between the two methods can be at least a factor of state\ndimension. For policy evaluation, we study a simple family of problem instances\nand show that nominal (certainty equivalence principle) control also requires\nseveral factors of state and input dimension fewer samples than the policy\ngradient method to reach the same level of control performance on these\ninstances. Furthermore, the gap persists even when employing commonly used\nbaselines. To the best of our knowledge, this is the first theoretical result\nwhich demonstrates a separation in the sample complexity between model-based\nand model-free methods on a continuous control task. \n\n"}
{"id": "1812.03664", "contents": "Title: Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions Abstract: Learning with limited data is a key challenge for visual recognition. Many\nfew-shot learning methods address this challenge by learning an instance\nembedding function from seen classes and apply the function to instances from\nunseen classes with limited labels. This style of transfer learning is\ntask-agnostic: the embedding function is not learned optimally discriminative\nwith respect to the unseen classes, where discerning among them leads to the\ntarget task. In this paper, we propose a novel approach to adapt the instance\nembeddings to the target classification task with a set-to-set function,\nyielding embeddings that are task-specific and are discriminative. We\nempirically investigated various instantiations of such set-to-set functions\nand observed the Transformer is most effective -- as it naturally satisfies key\nproperties of our desired model. We denote this model as FEAT (few-shot\nembedding adaptation w/ Transformer) and validate it on both the standard\nfew-shot classification benchmark and four extended few-shot learning settings\nwith essential use cases, i.e., cross-domain, transductive, generalized\nfew-shot learning, and low-shot learning. It archived consistent improvements\nover baseline models as well as previous methods and established the new\nstate-of-the-art results on two benchmarks. \n\n"}
{"id": "1812.04152", "contents": "Title: Duelling Bandits with Weak Regret in Adversarial Environments Abstract: Research on the multi-armed bandit problem has studied the trade-off of\nexploration and exploitation in depth. However, there are numerous applications\nwhere the cardinal absolute-valued feedback model (e.g. ratings from one to\nfive) is not suitable. This has motivated the formulation of the duelling\nbandits problem, where the learner picks a pair of actions and observes a noisy\nbinary feedback, indicating a relative preference between the two. There exist\na multitude of different settings and interpretations of the problem for two\nreasons. First, due to the absence of a total order of actions, there is no\nnatural definition of the best action. Existing work either explicitly assumes\nthe existence of a linear order, or uses a custom definition for the winner.\nSecond, there are multiple reasonable notions of regret to measure the\nlearner's performance. Most prior work has been focussing on the\n$\\textit{strong regret}$, which averages the quality of the two actions picked.\nThis work focusses on the $\\textit{weak regret}$, which is based on the quality\nof the better of the two actions selected. Weak regret is the more appropriate\nperformance measure when the pair's inferior action has no significant\ndetrimental effect on the pair's quality.\n  We study the duelling bandits problem in the adversarial setting. We provide\nan algorithm which has theoretical guarantees in both the utility-based\nsetting, which implies a total order, and the unrestricted setting. For the\nlatter, we work with the $\\textit{Borda winner}$, finding the action maximising\nthe probability of winning against an action sampled uniformly at random. The\nthesis concludes with experimental results based on both real-world data and\nsynthetic data, showing the algorithm's performance and limitations. \n\n"}
{"id": "1812.04363", "contents": "Title: Exploration Bonus for Regret Minimization in Undiscounted Discrete and\n  Continuous Markov Decision Processes Abstract: We introduce and analyse two algorithms for exploration-exploitation in\ndiscrete and continuous Markov Decision Processes (MDPs) based on exploration\nbonuses. SCAL$^+$ is a variant of SCAL (Fruit et al., 2018) that performs\nefficient exploration-exploitation in any unknown weakly-communicating MDP for\nwhich an upper bound C on the span of the optimal bias function is known. For\nan MDP with $S$ states, $A$ actions and $\\Gamma \\leq S$ possible next states,\nwe prove that SCAL$^+$ achieves the same theoretical guarantees as SCAL (i.e.,\na high probability regret bound of $\\widetilde{O}(C\\sqrt{\\Gamma SAT})$), with a\nmuch smaller computational complexity. Similarly, C-SCAL$^+$ exploits an\nexploration bonus to achieve sublinear regret in any undiscounted MDP with\ncontinuous state space. We show that C-SCAL$^+$ achieves the same regret bound\nas UCCRL (Ortner and Ryabko, 2012) while being the first implementable\nalgorithm with regret guarantees in this setting. While optimistic algorithms\nsuch as UCRL, SCAL or UCCRL maintain a high-confidence set of plausible MDPs\naround the true unknown MDP, SCAL$^+$ and C-SCAL$^+$ leverage on an exploration\nbonus to directly plan on the empirically estimated MDP, thus being more\ncomputationally efficient. \n\n"}
{"id": "1812.04407", "contents": "Title: Learning Item-Interaction Embeddings for User Recommendations Abstract: Industry-scale recommendation systems have become a cornerstone of the\ne-commerce shopping experience. For Etsy, an online marketplace with over 50\nmillion handmade and vintage items, users come to rely on personalized\nrecommendations to surface relevant items from its massive inventory. One\nhallmark of Etsy's shopping experience is the multitude of ways in which a user\ncan interact with an item they are interested in: they can view it, favorite\nit, add it to a collection, add it to cart, purchase it, etc. We hypothesize\nthat the different ways in which a user interacts with an item indicates\ndifferent kinds of intent. Consequently, a user's recommendations should be\nbased not only on the item from their past activity, but also the way in which\nthey interacted with that item. In this paper, we propose a novel method for\nlearning interaction-based item embeddings that encode the co-occurrence\npatterns of not only the item itself, but also the interaction type. The\nlearned embeddings give us a convenient way of approximating the likelihood\nthat one item-interaction pair would co-occur with another by way of a simple\ninner product. Because of its computational efficiency, our model lends itself\nnaturally as a candidate set selection method, and we evaluate it as such in an\nindustry-scale recommendation system that serves live traffic on Etsy.com. Our\nexperiments reveal that taking interaction type into account shows promising\nresults in improving the accuracy of modeling user shopping behavior. \n\n"}
{"id": "1812.04529", "contents": "Title: On the Ineffectiveness of Variance Reduced Optimization for Deep\n  Learning Abstract: The application of stochastic variance reduction to optimization has shown\nremarkable recent theoretical and practical success. The applicability of these\ntechniques to the hard non-convex optimization problems encountered during\ntraining of modern deep neural networks is an open problem. We show that naive\napplication of the SVRG technique and related approaches fail, and explore why. \n\n"}
{"id": "1812.04690", "contents": "Title: Learning representations of molecules and materials with atomistic\n  neural networks Abstract: Deep Learning has been shown to learn efficient representations for\nstructured data such as image, text or audio. In this chapter, we present\nneural network architectures that are able to learn efficient representations\nof molecules and materials. In particular, the continuous-filter convolutional\nnetwork SchNet accurately predicts chemical properties across compositional and\nconfigurational space on a variety of datasets. Beyond that, we analyze the\nobtained representations to find evidence that their spatial and chemical\nproperties agree with chemical intuition. \n\n"}
{"id": "1812.05082", "contents": "Title: Features Extraction Based on an Origami Representation of 3D Landmarks Abstract: Feature extraction analysis has been widely investigated during the last\ndecades in computer vision community due to the large range of possible\napplications. Significant work has been done in order to improve the\nperformance of the emotion detection methods. Classification algorithms have\nbeen refined, novel preprocessing techniques have been applied and novel\nrepresentations from images and videos have been introduced. In this paper, we\npropose a preprocessing method and a novel facial landmarks' representation\naiming to improve the facial emotion detection accuracy. We apply our novel\nmethodology on the extended Cohn-Kanade (CK+) dataset and other datasets for\naffect classification based on Action Units (AU). The performance evaluation\ndemonstrates an improvement on facial emotion classification (accuracy and F1\nscore) that indicates the superiority of the proposed methodology. \n\n"}
{"id": "1812.05555", "contents": "Title: Kalman-based Spectro-Temporal ECG Analysis using Deep Convolutional\n  Networks for Atrial Fibrillation Detection Abstract: In this article, we propose a novel ECG classification framework for atrial\nfibrillation (AF) detection using spectro-temporal representation (i.e., time\nvarying spectrum) and deep convolutional networks. In the first step we use a\nBayesian spectro-temporal representation based on the estimation of\ntime-varying coefficients of Fourier series using Kalman filter and smoother.\nNext, we derive an alternative model based on a stochastic oscillator\ndifferential equation to accelerate the estimation of the spectro-temporal\nrepresentation in lengthy signals. Finally, after comparative evaluations of\ndifferent convolutional architectures, we propose an efficient deep\nconvolutional neural network to classify the 2D spectro-temporal ECG data.\n  The ECG spectro-temporal data are classified into four different classes: AF,\nnon-AF normal rhythm (Normal), non-AF abnormal rhythm (Other), and noisy\nsegments (Noisy). The performance of the proposed methods is evaluated and\nscored with the PhysioNet/Computing in Cardiology (CinC) 2017 dataset. The\nexperimental results show that the proposed method achieves the overall F1\nscore of 80.2%, which is in line with the state-of-the-art algorithms. \n\n"}
{"id": "1812.05710", "contents": "Title: FPETS : Fully Parallel End-to-End Text-to-Speech System Abstract: End-to-end Text-to-speech (TTS) system can greatly improve the quality of\nsynthesised speech. But it usually suffers form high time latency due to its\nauto-regressive structure. And the synthesised speech may also suffer from some\nerror modes, e.g. repeated words, mispronunciations, and skipped words. In this\npaper, we propose a novel non-autoregressive, fully parallel end-to-end TTS\nsystem (FPETS). It utilizes a new alignment model and the recently proposed\nU-shape convolutional structure, UFANS. Different from RNN, UFANS can capture\nlong term information in a fully parallel manner. Trainable position encoding\nand two-step training strategy are used for learning better alignments.\nExperimental results show FPETS utilizes the power of parallel computation and\nreaches a significant speed up of inference compared with state-of-the-art\nend-to-end TTS systems. More specifically, FPETS is 600X faster than Tacotron2,\n50X faster than DCTTS and 10X faster than Deep Voice3. And FPETS can generates\naudios with equal or better quality and fewer errors comparing with other\nsystem. As far as we know, FPETS is the first end-to-end TTS system which is\nfully parallel. \n\n"}
{"id": "1812.05720", "contents": "Title: Why ReLU networks yield high-confidence predictions far away from the\n  training data and how to mitigate the problem Abstract: Classifiers used in the wild, in particular for safety-critical systems,\nshould not only have good generalization properties but also should know when\nthey don't know, in particular make low confidence predictions far away from\nthe training data. We show that ReLU type neural networks which yield a\npiecewise linear classifier function fail in this regard as they produce almost\nalways high confidence predictions far away from the training data. For bounded\ndomains like images we propose a new robust optimization technique similar to\nadversarial training which enforces low confidence predictions far away from\nthe training data. We show that this technique is surprisingly effective in\nreducing the confidence of predictions far away from the training data while\nmaintaining high confidence predictions and test error on the original\nclassification task compared to standard training. \n\n"}
{"id": "1812.05980", "contents": "Title: Probabilistic Class-Specific Discriminant Analysis Abstract: In this paper we formulate a probabilistic model for class-specific\ndiscriminant subspace learning. The proposed model can naturally incorporate\nthe multi-modal structure of the negative class, which is neglected by existing\nclass-specific methods. Moreover, it can be directly used to define a\nclass-specific probabilistic classification rule in the discriminant subspace.\nWe show that existing class-specific discriminant analysis methods are special\ncases of the proposed probabilistic model and, by casting them as probabilistic\nmodels, they can be extended to class-specific classifiers. We illustrate the\nperformance of the proposed model in both verification and classification\nproblems. \n\n"}
{"id": "1812.06161", "contents": "Title: Specification-Guided Safety Verification for Feedforward Neural Networks Abstract: This paper presents a specification-guided safety verification method for\nfeedforward neural networks with general activation functions. As such\nfeedforward networks are memoryless, they can be abstractly represented as\nmathematical functions, and the reachability analysis of the neural network\namounts to interval analysis problems. In the framework of interval analysis, a\ncomputationally efficient formula which can quickly compute the output interval\nsets of a neural network is developed. Then, a specification-guided\nreachability algorithm is developed. Specifically, the bisection process in the\nverification algorithm is completely guided by a given safety specification.\nDue to the employment of the safety specification, unnecessary computations are\navoided and thus the computational cost can be reduced significantly.\nExperiments show that the proposed method enjoys much more efficiency in safety\nverification with significantly less computational cost. \n\n"}
{"id": "1812.06303", "contents": "Title: Multi-Tasking Genetic Algorithm (MTGA) for Fuzzy System Optimization Abstract: Multi-task learning uses auxiliary data or knowledge from relevant tasks to\nfacilitate the learning in a new task. Multi-task optimization applies\nmulti-task learning to optimization to study how to effectively and efficiently\ntackle multiple optimization problems simultaneously. Evolutionary\nmulti-tasking, or multi-factorial optimization, is an emerging subfield of\nmulti-task optimization, which integrates evolutionary computation and\nmulti-task learning. This paper proposes a novel and easy-to-implement\nmulti-tasking genetic algorithm (MTGA), which copes well with significantly\ndifferent optimization tasks by estimating and using the bias among them.\nComparative studies with eight state-of-the-art single- and multi-task\napproaches in the literature on nine benchmarks demonstrated that on average\nthe MTGA outperformed all of them, and had lower computational cost than six of\nthem. Based on the MTGA, a simultaneous optimization strategy for fuzzy system\ndesign is also proposed. Experiments on simultaneous optimization of type-1 and\ninterval type-2 fuzzy logic controllers for couple-tank water level control\ndemonstrated that the MTGA can find better fuzzy logic controllers than other\napproaches. \n\n"}
{"id": "1812.06417", "contents": "Title: Visual Dialogue without Vision or Dialogue Abstract: We characterise some of the quirks and shortcomings in the exploration of\nVisual Dialogue - a sequential question-answering task where the questions and\ncorresponding answers are related through given visual stimuli. To do so, we\ndevelop an embarrassingly simple method based on Canonical Correlation Analysis\n(CCA) that, on the standard dataset, achieves near state-of-the-art performance\non mean rank (MR). In direct contrast to current complex and over-parametrised\narchitectures that are both compute and time intensive, our method ignores the\nvisual stimuli, ignores the sequencing of dialogue, does not need gradients,\nuses off-the-shelf feature extractors, has at least an order of magnitude fewer\nparameters, and learns in practically no time. We argue that these results are\nindicative of issues in current approaches to Visual Dialogue and conduct\nanalyses to highlight implicit dataset biases and effects of over-constrained\nevaluation metrics. Our code is publicly available. \n\n"}
{"id": "1812.06488", "contents": "Title: Feedback alignment in deep convolutional networks Abstract: Ongoing studies have identified similarities between neural representations\nin biological networks and in deep artificial neural networks. This has led to\nrenewed interest in developing analogies between the backpropagation learning\nalgorithm used to train artificial networks and the synaptic plasticity rules\noperative in the brain. These efforts are challenged by biologically\nimplausible features of backpropagation, one of which is a reliance on\nsymmetric forward and backward synaptic weights. A number of methods have been\nproposed that do not rely on weight symmetry but, thus far, these have failed\nto scale to deep convolutional networks and complex data. We identify principal\nobstacles to the scalability of such algorithms and introduce several\ntechniques to mitigate them. We demonstrate that a modification of the feedback\nalignment method that enforces a weaker form of weight symmetry, one that\nrequires agreement of weight sign but not magnitude, can achieve performance\ncompetitive with backpropagation. Our results complement those of Bartunov et\nal. (2018) and Xiao et al. (2018b) and suggest that mechanisms that promote\nalignment of feedforward and feedback weights are critical for learning in deep\nnetworks. \n\n"}
{"id": "1812.06649", "contents": "Title: Tachyon Inflation in Teleparallel Gravity Abstract: We present a tachyonic field inflationary model in a teleparallel framework.\nWe show that tachyonic coupled with the f(T) gravity model can describe the\ninflation era in which f(T) is an arbitrary function of torsion scalar T. For\nthis purpose, dynamical behavior of the tachyonic field in different potentials\nis studied, it is shown that the tachyonic field with these potentials can be\nan effective candidate for inflation. Then, we discuss slow-roll conditions and\nshow that by the appropriate choice of the parameters, the inflation era can be\nexplained via this model. Finally, we argue that our model not only satisfies\nthe result of BICEP2, Keck Array and Plank for the upper limit of $r < .012$\nbut also, the obtained value for spectral index $n_{s}$ is compatible with the\nresults of Plank and also Plank + WMAP + HighL + BAO at the 68% confidence\nlevel. \n\n"}
{"id": "1812.06705", "contents": "Title: Conditional BERT Contextual Augmentation Abstract: We propose a novel data augmentation method for labeled sentences called\nconditional BERT contextual augmentation. Data augmentation methods are often\napplied to prevent overfitting and improve generalization of deep neural\nnetwork models. Recently proposed contextual augmentation augments labeled\nsentences by randomly replacing words with more varied substitutions predicted\nby language model. BERT demonstrates that a deep bidirectional language model\nis more powerful than either an unidirectional language model or the shallow\nconcatenation of a forward and backward model. We retrofit BERT to conditional\nBERT by introducing a new conditional masked language model\\footnote{The term\n\"conditional masked language model\" appeared once in original BERT paper, which\nindicates context-conditional, is equivalent to term \"masked language model\".\nIn our paper, \"conditional masked language model\" indicates we apply extra\nlabel-conditional constraint to the \"masked language model\".} task. The well\ntrained conditional BERT can be applied to enhance contextual augmentation.\nExperiments on six various different text classification tasks show that our\nmethod can be easily applied to both convolutional or recurrent neural networks\nclassifier to obtain obvious improvement. \n\n"}
{"id": "1812.06968", "contents": "Title: Geometric Scattering on Manifolds Abstract: The Euclidean scattering transform was introduced nearly a decade ago to\nimprove the mathematical understanding of the success of convolutional neural\nnetworks (ConvNets) in image data analysis and other tasks. Inspired by recent\ninterest in geometric deep learning, which aims to generalize ConvNets to\nmanifold and graph-structured domains, we generalize the scattering transform\nto compact manifolds. Similar to the Euclidean scattering transform, our\ngeometric scattering transform is based on a cascade of designed filters and\npointwise nonlinearities, which enables rigorous analysis of the feature\nextraction provided by scattering layers. Our main focus here is on theoretical\nunderstanding of this geometric scattering network, while setting aside\nimplementation aspects, although we remark that application of similar\ntransforms to graph data analysis has been studied recently in related work.\nOur results establish conditions under which geometric scattering provides\nlocalized isometry invariant descriptions of manifold signals, which are also\nstable to families of diffeomorphisms formulated in intrinsic manifolds terms.\nThese results not only generalize the deformation stability and local\nroto-translation invariance of Euclidean scattering, but also demonstrate the\nimportance of linking the used filter structures (e.g., in geometric deep\nlearning) to the underlying manifold geometry, or the data geometry it\nrepresents. \n\n"}
{"id": "1812.07102", "contents": "Title: Deep Learning with Attention to Predict Gestational Age of the Fetal\n  Brain Abstract: Fetal brain imaging is a cornerstone of prenatal screening and early\ndiagnosis of congenital anomalies. Knowledge of fetal gestational age is the\nkey to the accurate assessment of brain development. This study develops an\nattention-based deep learning model to predict gestational age of the fetal\nbrain. The proposed model is an end-to-end framework that combines key insights\nfrom multi-view MRI including axial, coronal, and sagittal views. The model\nalso uses age-activated weakly-supervised attention maps to enable\nrotation-invariant localization of the fetal brain among background noise. We\nevaluate our methods on the collected fetal brain MRI cohort with a large age\ndistribution from 125 to 273 days. Our extensive experiments show age\nprediction performance with R2 = 0.94 using multi-view MRI and attention. \n\n"}
{"id": "1812.07135", "contents": "Title: Globalness Detection in Online Social Network Abstract: Classification problems have made significant progress due to the maturity of\nartificial intelligence (AI). However, differentiating items from categories\nwithout noticeable boundaries is still a huge challenge for machines -- which\nis also crucial for machines to be intelligent.\n  In order to study the fuzzy concept on classification, we define and propose\na globalness detection with the four-stage operational flow. We then\ndemonstrate our framework on Facebook public pages inter-like graph with their\ngeo-location. Our prediction algorithm achieves high precision (89%) and recall\n(88%) of local pages. We evaluate the results on both states and countries\nlevel, finding that the global node ratios are relatively high in those states\n(NY, CA) having large and international cities. Several global nodes examples\nhave also been shown and studied in this paper.\n  It is our hope that our results unveil the perfect value from every\nclassification problem and provide a better understanding of global and local\nnodes in Online Social Networks (OSNs). \n\n"}
{"id": "1812.07671", "contents": "Title: Deep Online Learning via Meta-Learning: Continual Adaptation for\n  Model-Based RL Abstract: Humans and animals can learn complex predictive models that allow them to\naccurately and reliably reason about real-world phenomena, and they can adapt\nsuch models extremely quickly in the face of unexpected changes. Deep neural\nnetwork models allow us to represent very complex functions, but lack this\ncapacity for rapid online adaptation. The goal in this paper is to develop a\nmethod for continual online learning from an incoming stream of data, using\ndeep neural network models. We formulate an online learning procedure that uses\nstochastic gradient descent to update model parameters, and an expectation\nmaximization algorithm with a Chinese restaurant process prior to develop and\nmaintain a mixture of models to handle non-stationary task distributions. This\nallows for all models to be adapted as necessary, with new models instantiated\nfor task changes and old models recalled when previously seen tasks are\nencountered again. Furthermore, we observe that meta-learning can be used to\nmeta-train a model such that this direct online adaptation with SGD is\neffective, which is otherwise not the case for large function approximators. In\nthis work, we apply our meta-learning for online learning (MOLe) approach to\nmodel-based reinforcement learning, where adapting the predictive model is\ncritical for control; we demonstrate that MOLe outperforms alternative prior\nmethods, and enables effective continuous adaptation in non-stationary task\ndistributions such as varying terrains, motor failures, and unexpected\ndisturbances. \n\n"}
{"id": "1812.07768", "contents": "Title: Modular meta-learning in abstract graph networks for combinatorial\n  generalization Abstract: Modular meta-learning is a new framework that generalizes to unseen datasets\nby combining a small set of neural modules in different ways. In this work we\npropose abstract graph networks: using graphs as abstractions of a system's\nsubparts without a fixed assignment of nodes to system subparts, for which we\nwould need supervision. We combine this idea with modular meta-learning to get\na flexible framework with combinatorial generalization to new tasks built in.\nWe then use it to model the pushing of arbitrarily shaped objects from little\nor no training data. \n\n"}
{"id": "1812.08769", "contents": "Title: What are the biases in my word embedding? Abstract: This paper presents an algorithm for enumerating biases in word embeddings.\nThe algorithm exposes a large number of offensive associations related to\nsensitive features such as race and gender on publicly available embeddings,\nincluding a supposedly \"debiased\" embedding. These biases are concerning in\nlight of the widespread use of word embeddings. The associations are identified\nby geometric patterns in word embeddings that run parallel between people's\nnames and common lower-case tokens. The algorithm is highly unsupervised: it\ndoes not even require the sensitive features to be pre-specified. This is\ndesirable because: (a) many forms of discrimination--such as racial\ndiscrimination--are linked to social constructs that may vary depending on the\ncontext, rather than to categories with fixed definitions; and (b) it makes it\neasier to identify biases against intersectional groups, which depend on\ncombinations of sensitive features. The inputs to our algorithm are a list of\ntarget tokens, e.g. names, and a word embedding. It outputs a number of Word\nEmbedding Association Tests (WEATs) that capture various biases present in the\ndata. We illustrate the utility of our approach on publicly available word\nembeddings and lists of names, and evaluate its output using crowdsourcing. We\nalso show how removing names may not remove potential proxy bias. \n\n"}
{"id": "1812.08997", "contents": "Title: Stochastic Doubly Robust Gradient Abstract: When training a machine learning model with observational data, it is often\nencountered that some values are systemically missing. Learning from the\nincomplete data in which the missingness depends on some covariates may lead to\nbiased estimation of parameters and even harm the fairness of decision outcome.\nThis paper proposes how to adjust the causal effect of covariates on the\nmissingness when training models using stochastic gradient descent (SGD).\nInspired by the design of doubly robust estimator and its theoretical property\nof double robustness, we introduce stochastic doubly robust gradient (SDRG)\nconsisting of two models: weight-corrected gradients for inverse propensity\nscore weighting and per-covariate control variates for regression adjustment.\nAlso, we identify the connection between double robustness and variance\nreduction in SGD by demonstrating the SDRG algorithm with a unifying framework\nfor variance reduced SGD. The performance of our approach is empirically tested\nby showing the convergence in training image classifiers with several examples\nof missing data. \n\n"}
{"id": "1812.09584", "contents": "Title: Meta Architecture Search Abstract: Neural Architecture Search (NAS) has been quite successful in constructing\nstate-of-the-art models on a variety of tasks. Unfortunately, the computational\ncost can make it difficult to scale. In this paper, we make the first attempt\nto study Meta Architecture Search which aims at learning a task-agnostic\nrepresentation that can be used to speed up the process of architecture search\non a large number of tasks. We propose the Bayesian Meta Architecture SEarch\n(BASE) framework which takes advantage of a Bayesian formulation of the\narchitecture search problem to learn over an entire set of tasks\nsimultaneously. We show that on Imagenet classification, we can find a model\nthat achieves 25.7% top-1 error and 8.1% top-5 error by adapting the\narchitecture in less than an hour from an 8 GPU days pretrained meta-network.\nBy learning a good prior for NAS, our method dramatically decreases the\nrequired computation cost while achieving comparable performance to current\nstate-of-the-art methods - even finding competitive models for unseen datasets\nwith very quick adaptation. We believe our framework will open up new\npossibilities for efficient and massively scalable architecture search research\nacross multiple tasks. \n\n"}
{"id": "1812.09922", "contents": "Title: Dynamic Runtime Feature Map Pruning Abstract: High bandwidth requirements are an obstacle for accelerating the training and\ninference of deep neural networks. Most previous research focuses on reducing\nthe size of kernel maps for inference. We analyze parameter sparsity of six\npopular convolutional neural networks - AlexNet, MobileNet, ResNet-50,\nSqueezeNet, TinyNet, and VGG16. Of the networks considered, those using ReLU\n(AlexNet, SqueezeNet, VGG16) contain a high percentage of 0-valued parameters\nand can be statically pruned. Networks with Non-ReLU activation functions in\nsome cases may not contain any 0-valued parameters (ResNet-50, TinyNet). We\nalso investigate runtime feature map usage and find that input feature maps\ncomprise the majority of bandwidth requirements when depth-wise convolution and\npoint-wise convolutions used. We introduce dynamic runtime pruning of feature\nmaps and show that 10% of dynamic feature map execution can be removed without\nloss of accuracy. We then extend dynamic pruning to allow for values within an\nepsilon of zero and show a further 5% reduction of feature map loading with a\n1% loss of accuracy in top-1. \n\n"}
{"id": "1812.10479", "contents": "Title: Multimodal deep learning for short-term stock volatility prediction Abstract: Stock market volatility forecasting is a task relevant to assessing market\nrisk. We investigate the interaction between news and prices for the\none-day-ahead volatility prediction using state-of-the-art deep learning\napproaches. The proposed models are trained either end-to-end or using sentence\nencoders transfered from other tasks. We evaluate a broad range of stock market\nsectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials.\nOur experimental results show that adding news improves the volatility\nforecasting as compared to the mainstream models that rely only on price data.\nIn particular, our model outperforms the widely-recognized GARCH(1,1) model for\nall sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$,\nachieving the best performance when training from both news and price data. \n\n"}
{"id": "1812.11794", "contents": "Title: Deep Reinforcement Learning for Multi-Agent Systems: A Review of\n  Challenges, Solutions and Applications Abstract: Reinforcement learning (RL) algorithms have been around for decades and\nemployed to solve various sequential decision-making problems. These algorithms\nhowever have faced great challenges when dealing with high-dimensional\nenvironments. The recent development of deep learning has enabled RL methods to\ndrive optimal policies for sophisticated and capable agents, which can perform\nefficiently in these challenging environments. This paper addresses an\nimportant aspect of deep RL related to situations that require multiple agents\nto communicate and cooperate to solve complex tasks. A survey of different\napproaches to problems related to multi-agent deep RL (MADRL) is presented,\nincluding non-stationarity, partial observability, continuous state and action\nspaces, multi-agent training schemes, multi-agent transfer learning. The merits\nand demerits of the reviewed methods will be analyzed and discussed, with their\ncorresponding applications explored. It is envisaged that this review provides\ninsights about various MADRL methods and can lead to future development of more\nrobust and highly useful multi-agent learning methods for solving real-world\nproblems. \n\n"}
{"id": "1812.11971", "contents": "Title: Mid-Level Visual Representations Improve Generalization and Sample\n  Efficiency for Learning Visuomotor Policies Abstract: How much does having visual priors about the world (e.g. the fact that the\nworld is 3D) assist in learning to perform downstream motor tasks (e.g.\ndelivering a package)? We study this question by integrating a generic\nperceptual skill set (e.g. a distance estimator, an edge detector, etc.) within\na reinforcement learning framework--see Figure 1. This skill set (hereafter\nmid-level perception) provides the policy with a more processed state of the\nworld compared to raw images.\n  We find that using a mid-level perception confers significant advantages over\ntraining end-to-end from scratch (i.e. not leveraging priors) in\nnavigation-oriented tasks. Agents are able to generalize to situations where\nthe from-scratch approach fails and training becomes significantly more sample\nefficient. However, we show that realizing these gains requires careful\nselection of the mid-level perceptual skills. Therefore, we refine our findings\ninto an efficient max-coverage feature set that can be adopted in lieu of raw\nimages. We perform our study in completely separate buildings for training and\ntesting and compare against visually blind baseline policies and\nstate-of-the-art feature learning methods. \n\n"}
{"id": "1901.00035", "contents": "Title: Convex Relaxations of Convolutional Neural Nets Abstract: We propose convex relaxations for convolutional neural nets with one hidden\nlayer where the output weights are fixed. For convex activation functions such\nas rectified linear units, the relaxations are convex second order cone\nprograms which can be solved very efficiently. We prove that the relaxation\nrecovers the global minimum under a planted model assumption, given\nsufficiently many training samples from a Gaussian distribution. We also\nidentify a phase transition phenomenon in recovering the global minimum for the\nrelaxation. \n\n"}
{"id": "1901.00098", "contents": "Title: Training with the Invisibles: Obfuscating Images to Share Safely for\n  Learning Visual Recognition Models Abstract: High-performance visual recognition systems generally require a large\ncollection of labeled images to train. The expensive data curation can be an\nobstacle for improving recognition performance. Sharing more data allows\ntraining for better models. But personal and private information in the data\nprevent such sharing. To promote sharing visual data for learning a recognition\nmodel, we propose to obfuscate the images so that humans are not able to\nrecognize their detailed contents, while machines can still utilize them to\ntrain new models. We validate our approach by comprehensive experiments on\nthree challenging visual recognition tasks; image classification, attribute\nclassification, and facial landmark detection on several datasets including\nSVHN, CIFAR10, Pascal VOC 2012, CelebA, and MTFL. Our method successfully\nobfuscates the images from humans recognition, but a machine model trained with\nthem performs within about 1% margin (up to 0.48%) of the performance of a\nmodel trained with the original, non-obfuscated data. \n\n"}
{"id": "1901.00433", "contents": "Title: Causal Calculus in the Presence of Cycles, Latent Confounders and\n  Selection Bias Abstract: We prove the main rules of causal calculus (also called do-calculus) for i/o\nstructural causal models (ioSCMs), a generalization of a recently proposed\ngeneral class of non-/linear structural causal models that allow for cycles,\nlatent confounders and arbitrary probability distributions. We also generalize\nadjustment criteria and formulas from the acyclic setting to the general one\n(i.e. ioSCMs). Such criteria then allow to estimate (conditional) causal\neffects from observational data that was (partially) gathered under selection\nbias and cycles. This generalizes the backdoor criterion, the\nselection-backdoor criterion and extensions of these to arbitrary ioSCMs.\nTogether, our results thus enable causal reasoning in the presence of cycles,\nlatent confounders and selection bias. Finally, we extend the ID algorithm for\nthe identification of causal effects to ioSCMs. \n\n"}
{"id": "1901.00630", "contents": "Title: Projecting \"better than randomly\": How to reduce the dimensionality of\n  very large datasets in a way that outperforms random projections Abstract: For very large datasets, random projections (RP) have become the tool of\nchoice for dimensionality reduction. This is due to the computational\ncomplexity of principal component analysis. However, the recent development of\nrandomized principal component analysis (RPCA) has opened up the possibility of\nobtaining approximate principal components on very large datasets. In this\npaper, we compare the performance of RPCA and RP in dimensionality reduction\nfor supervised learning. In Experiment 1, study a malware classification task\non a dataset with over 10 million samples, almost 100,000 features, and over 25\nbillion non-zero values, with the goal of reducing the dimensionality to a\ncompressed representation of 5,000 features. In order to apply RPCA to this\ndataset, we develop a new algorithm called large sample RPCA (LS-RPCA), which\nextends the RPCA algorithm to work on datasets with arbitrarily many samples.\nWe find that classification performance is much higher when using LS-RPCA for\ndimensionality reduction than when using random projections. In particular,\nacross a range of target dimensionalities, we find that using LS-RPCA reduces\nclassification error by between 37% and 54%. Experiment 2 generalizes the\nphenomenon to multiple datasets, feature representations, and classifiers.\nThese findings have implications for a large number of research projects in\nwhich random projections were used as a preprocessing step for dimensionality\nreduction. As long as accuracy is at a premium and the target dimensionality is\nsufficiently less than the numeric rank of the dataset, randomized PCA may be a\nsuperior choice. Moreover, if the dataset has a large number of samples, then\nLS-RPCA will provide a method for obtaining the approximate principal\ncomponents. \n\n"}
{"id": "1901.00786", "contents": "Title: Towards Global Remote Discharge Estimation: Using the Few to Estimate\n  The Many Abstract: Learning hydrologic models for accurate riverine flood prediction at scale is\na challenge of great importance. One of the key difficulties is the need to\nrely on in-situ river discharge measurements, which can be quite scarce and\nunreliable, particularly in regions where floods cause the most damage every\nyear. Accordingly, in this work we tackle the problem of river discharge\nestimation at different river locations. A core characteristic of the data at\nhand (e.g. satellite measurements) is that we have few measurements for many\nlocations, all sharing the same physics that underlie the water discharge. We\ncapture this scenario in a simple but powerful common mechanism regression\n(CMR) model with a local component as well as a shared one which captures the\nglobal discharge mechanism. The resulting learning objective is non-convex, but\nwe show that we can find its global optimum by leveraging the power of joining\nlocal measurements across sites. In particular, using a spectral initialization\nwith provable near-optimal accuracy, we can find the optimum using standard\ndescent methods. We demonstrate the efficacy of our approach for the problem of\ndischarge estimation using simulations. \n\n"}
{"id": "1901.01484", "contents": "Title: LanczosNet: Multi-Scale Deep Graph Convolutional Networks Abstract: We propose the Lanczos network (LanczosNet), which uses the Lanczos algorithm\nto construct low rank approximations of the graph Laplacian for graph\nconvolution. Relying on the tridiagonal decomposition of the Lanczos algorithm,\nwe not only efficiently exploit multi-scale information via fast approximated\ncomputation of matrix power but also design learnable spectral filters. Being\nfully differentiable, LanczosNet facilitates both graph kernel learning as well\nas learning node embeddings. We show the connection between our LanczosNet and\ngraph based manifold learning methods, especially the diffusion maps. We\nbenchmark our model against several recent deep graph networks on citation\nnetworks and QM8 quantum chemistry dataset. Experimental results show that our\nmodel achieves the state-of-the-art performance in most tasks. Code is released\nat: \\url{https://github.com/lrjconan/LanczosNetwork}. \n\n"}
{"id": "1901.01761", "contents": "Title: Credit Assignment Techniques in Stochastic Computation Graphs Abstract: Stochastic computation graphs (SCGs) provide a formalism to represent\nstructured optimization problems arising in artificial intelligence, including\nsupervised, unsupervised, and reinforcement learning. Previous work has shown\nthat an unbiased estimator of the gradient of the expected loss of SCGs can be\nderived from a single principle. However, this estimator often has high\nvariance and requires a full model evaluation per data point, making this\nalgorithm costly in large graphs. In this work, we address these problems by\ngeneralizing concepts from the reinforcement learning literature. We introduce\nthe concepts of value functions, baselines and critics for arbitrary SCGs, and\nshow how to use them to derive lower-variance gradient estimates from partial\nmodel evaluations, paving the way towards general and efficient credit\nassignment for gradient-based optimization. In doing so, we demonstrate how our\nresults unify recent advances in the probabilistic inference and reinforcement\nlearning literature. \n\n"}
{"id": "1901.02039", "contents": "Title: Spherical CNNs on Unstructured Grids Abstract: We present an efficient convolution kernel for Convolutional Neural Networks\n(CNNs) on unstructured grids using parameterized differential operators while\nfocusing on spherical signals such as panorama images or planetary signals. To\nthis end, we replace conventional convolution kernels with linear combinations\nof differential operators that are weighted by learnable parameters.\nDifferential operators can be efficiently estimated on unstructured grids using\none-ring neighbors, and learnable parameters can be optimized through standard\nback-propagation. As a result, we obtain extremely efficient neural networks\nthat match or outperform state-of-the-art network architectures in terms of\nperformance but with a significantly lower number of network parameters. We\nevaluate our algorithm in an extensive series of experiments on a variety of\ncomputer vision and climate science tasks, including shape classification,\nclimate pattern segmentation, and omnidirectional image semantic segmentation.\nOverall, we present (1) a novel CNN approach on unstructured grids using\nparameterized differential operators for spherical signals, and (2) we show\nthat our unique kernel parameterization allows our model to achieve the same or\nhigher accuracy with significantly fewer network parameters. \n\n"}
{"id": "1901.02358", "contents": "Title: FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated\n  Recurrent Neural Network Abstract: This paper develops the FastRNN and FastGRNN algorithms to address the twin\nRNN limitations of inaccurate training and inefficient prediction. Previous\napproaches have improved accuracy at the expense of prediction costs making\nthem infeasible for resource-constrained and real-time applications. Unitary\nRNNs have increased accuracy somewhat by restricting the range of the state\ntransition matrix's singular values but have also increased the model size as\nthey require a larger number of hidden units to make up for the loss in\nexpressive power. Gated RNNs have obtained state-of-the-art accuracies by\nadding extra parameters thereby resulting in even larger models. FastRNN\naddresses these limitations by adding a residual connection that does not\nconstrain the range of the singular values explicitly and has only two extra\nscalar parameters. FastGRNN then extends the residual connection to a gate by\nreusing the RNN matrices to match state-of-the-art gated RNN accuracies but\nwith a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse\nand quantized resulted in accurate models that could be up to 35x smaller than\nleading gated and unitary RNNs. This allowed FastGRNN to accurately recognize\nthe \"Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely\nresource-constrained IoT microcontrollers too tiny to store other RNN models.\nFastGRNN's code is available at https://github.com/Microsoft/EdgeML/. \n\n"}
{"id": "1901.02470", "contents": "Title: Bilinear Bandits with Low-rank Structure Abstract: We introduce the bilinear bandit problem with low-rank structure in which an\naction takes the form of a pair of arms from two different entity types, and\nthe reward is a bilinear function of the known feature vectors of the arms. The\nunknown in the problem is a $d_1$ by $d_2$ matrix $\\mathbf{\\Theta}^*$ that\ndefines the reward, and has low rank $r \\ll \\min\\{d_1,d_2\\}$. Determination of\n$\\mathbf{\\Theta}^*$ with this low-rank structure poses a significant challenge\nin finding the right exploration-exploitation tradeoff. In this work, we\npropose a new two-stage algorithm called \"Explore-Subspace-Then-Refine\" (ESTR).\nThe first stage is an explicit subspace exploration, while the second stage is\na linear bandit algorithm called \"almost-low-dimensional OFUL\" (LowOFUL) that\nexploits and further refines the estimated subspace via a regularization\ntechnique. We show that the regret of ESTR is\n$\\widetilde{\\mathcal{O}}((d_1+d_2)^{3/2} \\sqrt{r T})$ where\n$\\widetilde{\\mathcal{O}}$ hides logarithmic factors and $T$ is the time\nhorizon, which improves upon the regret of\n$\\widetilde{\\mathcal{O}}(d_1d_2\\sqrt{T})$ attained for a na\\\"ive linear bandit\nreduction. We conjecture that the regret bound of ESTR is unimprovable up to\npolylogarithmic factors, and our preliminary experiment shows that ESTR\noutperforms a na\\\"ive linear bandit reduction. \n\n"}
{"id": "1901.02474", "contents": "Title: On Relativistic $f$-Divergences Abstract: This paper provides a more rigorous look at Relativistic Generative\nAdversarial Networks (RGANs). We prove that the objective function of the\ndiscriminator is a statistical divergence for any concave function $f$ with\nminimal properties ($f(0)=0$, $f'(0) \\neq 0$, $\\sup_x f(x)>0$). We also devise\na few variants of relativistic $f$-divergences. Wasserstein GAN was originally\njustified by the idea that the Wasserstein distance (WD) is most sensible\nbecause it is weak (i.e., it induces a weak topology). We show that the WD is\nweaker than $f$-divergences which are weaker than relativistic $f$-divergences.\nGiven the good performance of RGANs, this suggests that WGAN does not performs\nwell primarily because of the weak metric, but rather because of regularization\nand the use of a relativistic discriminator. We also take a closer look at\nestimators of relativistic $f$-divergences. We introduce the minimum-variance\nunbiased estimator (MVUE) for Relativistic paired GANs (RpGANs; originally\ncalled RGANs which could bring confusion) and show that it does not perform\nbetter. Furthermore, we show that the estimator of Relativistic average GANs\n(RaGANs) is only asymptotically unbiased, but that the finite-sample bias is\nsmall. Removing this bias does not improve performance. \n\n"}
{"id": "1901.02671", "contents": "Title: Is it Time to Swish? Comparing Deep Learning Activation Functions Across\n  NLP tasks Abstract: Activation functions play a crucial role in neural networks because they are\nthe nonlinearities which have been attributed to the success story of deep\nlearning. One of the currently most popular activation functions is ReLU, but\nseveral competitors have recently been proposed or 'discovered', including\nLReLU functions and swish. While most works compare newly proposed activation\nfunctions on few tasks (usually from image classification) and against few\ncompetitors (usually ReLU), we perform the first large-scale comparison of 21\nactivation functions across eight different NLP tasks. We find that a largely\nunknown activation function performs most stably across all tasks, the\nso-called penalized tanh function. We also show that it can successfully\nreplace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage\npoint (pp) improvement over the standard choices on a challenging NLP task. \n\n"}
{"id": "1901.03450", "contents": "Title: Ubiquitous Acoustic Sensing on Commodity IoT Devices: A Survey Abstract: With the proliferation of Internet-of-Things devices, acoustic sensing\nattracts much attention in recent years. It exploits acoustic transceivers such\nas microphones and speakers beyond their primary functions, namely recording\nand playing, to enable novel applications and new user experiences. In this\npaper, we present the first systematic survey of recent advances in active\nacoustic sensing using commodity hardware with a frequency range below\n24~\\!kHz. We propose a general framework that categorizes main building blocks\nof acoustic sensing systems. This framework encompasses three layers, i.e.,\nphysical layer, core technique layer, and application layer. The physical layer\nincludes basic hardware components, acoustic platforms as well as the air-borne\nand structure-borne channel characteristics. The core technique layer\nencompasses key mechanisms to generate acoustic signals (waveforms) and to\nextract useful temporal, spatial and spectral information from received\nsignals. The application layer builds upon the functions offered by the core\ntechniques to realize different acoustic sensing applications. We highlight\nunique challenges due to the limitations of physical devices and acoustic\nchannels and how they are mitigated or overcame by core processing techniques\nand application-specific solutions. Finally, research opportunities and future\ndirections are discussed to spawn further in-depth investigation on acoustic\nsensing. \n\n"}
{"id": "1901.04215", "contents": "Title: How does Disagreement Help Generalization against Label Corruption? Abstract: Learning with noisy labels is one of the hottest problems in\nweakly-supervised learning. Based on memorization effects of deep neural\nnetworks, training on small-loss instances becomes very promising for handling\nnoisy labels. This fosters the state-of-the-art approach \"Co-teaching\" that\ncross-trains two deep neural networks using the small-loss trick. However, with\nthe increase of epochs, two networks converge to a consensus and Co-teaching\nreduces to the self-training MentorNet. To tackle this issue, we propose a\nrobust learning paradigm called Co-teaching+, which bridges the \"Update by\nDisagreement\" strategy with the original Co-teaching. First, two networks feed\nforward and predict all data, but keep prediction disagreement data only. Then,\namong such disagreement data, each network selects its small-loss data, but\nback propagates the small-loss data from its peer network and updates its own\nparameters. Empirical results on benchmark datasets demonstrate that\nCo-teaching+ is much superior to many state-of-the-art methods in the\nrobustness of trained models. \n\n"}
{"id": "1901.04966", "contents": "Title: Identifying and Correcting Label Bias in Machine Learning Abstract: Datasets often contain biases which unfairly disadvantage certain groups, and\nclassifiers trained on such datasets can inherit these biases. In this paper,\nwe provide a mathematical formulation of how this bias can arise. We do so by\nassuming the existence of underlying, unknown, and unbiased labels which are\noverwritten by an agent who intends to provide accurate labels but may have\nbiases against certain groups. Despite the fact that we only observe the biased\nlabels, we are able to show that the bias may nevertheless be corrected by\nre-weighting the data points without changing the labels. We show, with\ntheoretical guarantees, that training on the re-weighted dataset corresponds to\ntraining on the unobserved but unbiased labels, thus leading to an unbiased\nmachine learning classifier. Our procedure is fast and robust and can be used\nwith virtually any learning algorithm. We evaluate on a number of standard\nmachine learning fairness datasets and a variety of fairness notions, finding\nthat our method outperforms standard approaches in achieving fair\nclassification. \n\n"}
{"id": "1901.05075", "contents": "Title: Moduli Stabilization and Inflation in Type IIB/F-theory Abstract: In the first part of this talk, a short overview of the ongoing debate on the\nexistence of de Sitter vacua in string theory is presented. In the second part,\nthe moduli stabilisation and inflation are discussed in the context of type\nIIB/F-theory. Considering a configuration of three intersecting $D7$ branes\nwith fluxes, it is shown that higher loop effects inducing logarithmic\ncorrections to the K\\\"ahler potential can stabilise the K\\\"ahler moduli in a de\nSitter Vacuum. When a new Fayet-Iliopoulos term is included, it is also\npossible to generate the required number of e-foldings and satisfy the\nconditions for slow-roll inflation. \n\n"}
{"id": "1901.06803", "contents": "Title: Active Learning with Gaussian Processes for High Throughput Phenotyping Abstract: A looming question that must be solved before robotic plant phenotyping\ncapabilities can have significant impact to crop improvement programs is\nscalability. High Throughput Phenotyping (HTP) uses robotic technologies to\nanalyze crops in order to determine species with favorable traits, however, the\ncurrent practices rely on exhaustive coverage and data collection from the\nentire crop field being monitored under the breeding experiment. This works\nwell in relatively small agricultural fields but can not be scaled to the\nlarger ones, thus limiting the progress of genetics research. In this work, we\npropose an active learning algorithm to enable an autonomous system to collect\nthe most informative samples in order to accurately learn the distribution of\nphenotypes in the field with the help of a Gaussian Process model. We\ndemonstrate the superior performance of our proposed algorithm compared to the\ncurrent practices on sorghum phenotype data collection. \n\n"}
{"id": "1901.07334", "contents": "Title: Reducing state updates via Gaussian-gated LSTMs Abstract: Recurrent neural networks can be difficult to train on long sequence data due\nto the well-known vanishing gradient problem. Some architectures incorporate\nmethods to reduce RNN state updates, therefore allowing the network to preserve\nmemory over long temporal intervals. To address these problems of convergence,\nthis paper proposes a timing-gated LSTM RNN model, called the Gaussian-gated\nLSTM (g-LSTM). The time gate controls when a neuron can be updated during\ntraining, enabling longer memory persistence and better error-gradient flow.\nThis model captures long-temporal dependencies better than an LSTM and the time\ngate parameters can be learned even from non-optimal initialization values.\nBecause the time gate limits the updates of the neuron state, the number of\ncomputes needed for the network update is also reduced. By adding a\ncomputational budget term to the training loss, we can obtain a network which\nfurther reduces the number of computes by at least 10x. Finally, by employing a\ntemporal curriculum learning schedule for the g-LSTM, we can reduce the\nconvergence time of the equivalent LSTM network on long sequences. \n\n"}
{"id": "1901.07915", "contents": "Title: ICLabel: An automated electroencephalographic independent component\n  classifier, dataset, and website Abstract: The electroencephalogram (EEG) provides a non-invasive, minimally\nrestrictive, and relatively low cost measure of mesoscale brain dynamics with\nhigh temporal resolution. Although signals recorded in parallel by multiple,\nnear-adjacent EEG scalp electrode channels are highly-correlated and combine\nsignals from many different sources, biological and non-biological, independent\ncomponent analysis (ICA) has been shown to isolate the various source generator\nprocesses underlying those recordings. Independent components (IC) found by ICA\ndecomposition can be manually inspected, selected, and interpreted, but doing\nso requires both time and practice as ICs have no particular order or intrinsic\ninterpretations and therefore require further study of their properties.\nAlternatively, sufficiently-accurate automated IC classifiers can be used to\nclassify ICs into broad source categories, speeding the analysis of EEG studies\nwith many subjects and enabling the use of ICA decomposition in near-real-time\napplications. While many such classifiers have been proposed recently, this\nwork presents the ICLabel project comprised of (1) an IC dataset containing\nspatiotemporal measures for over 200,000 ICs from more than 6,000 EEG\nrecordings, (2) a website for collecting crowdsourced IC labels and educating\nEEG researchers and practitioners about IC interpretation, and (3) the\nautomated ICLabel classifier. The classifier improves upon existing methods in\ntwo ways: by improving the accuracy of the computed label estimates and by\nenhancing its computational efficiency. The ICLabel classifier outperforms or\nperforms comparably to the previous best publicly available method for all\nmeasured IC categories while computing those labels ten times faster than that\nclassifier as shown in a rigorous comparison against all other publicly\navailable EEG IC classifiers. \n\n"}
{"id": "1901.07957", "contents": "Title: CTCModel: a Keras Model for Connectionist Temporal Classification Abstract: We report an extension of a Keras Model, called CTCModel, to perform the\nConnectionist Temporal Classification (CTC) in a transparent way. Combined with\nRecurrent Neural Networks, the Connectionist Temporal Classification is the\nreference method for dealing with unsegmented input sequences, i.e. with data\nthat are a couple of observation and label sequences where each label is\nrelated to a subset of observation frames. CTCModel makes use of the CTC\nimplementation in the Tensorflow backend for training and predicting sequences\nof labels using Keras. It consists of three branches made of Keras models: one\nfor training, computing the CTC loss function; one for predicting, providing\nsequences of labels; and one for evaluating that returns standard metrics for\nanalyzing sequences of predictions. \n\n"}
{"id": "1901.08022", "contents": "Title: A Universally Optimal Multistage Accelerated Stochastic Gradient Method Abstract: We study the problem of minimizing a strongly convex, smooth function when we\nhave noisy estimates of its gradient. We propose a novel multistage accelerated\nalgorithm that is universally optimal in the sense that it achieves the optimal\nrate both in the deterministic and stochastic case and operates without\nknowledge of noise characteristics. The algorithm consists of stages that use a\nstochastic version of Nesterov's method with a specific restart and parameters\nselected to achieve the fastest reduction in the bias-variance terms in the\nconvergence rate bounds. \n\n"}
{"id": "1901.08082", "contents": "Title: Cooperative Online Learning: Keeping your Neighbors Updated Abstract: We study an asynchronous online learning setting with a network of agents. At\neach time step, some of the agents are activated, requested to make a\nprediction, and pay the corresponding loss. The loss function is then revealed\nto these agents and also to their neighbors in the network. Our results\ncharacterize how much knowing the network structure affects the regret as a\nfunction of the model of agent activations. When activations are stochastic,\nthe optimal regret (up to constant factors) is shown to be of order\n$\\sqrt{\\alpha T}$, where $T$ is the horizon and $\\alpha$ is the independence\nnumber of the network. We prove that the upper bound is achieved even when\nagents have no information about the network structure. When activations are\nadversarial the situation changes dramatically: if agents ignore the network\nstructure, a $\\Omega(T)$ lower bound on the regret can be proven, showing that\nlearning is impossible. However, when agents can choose to ignore some of their\nneighbors based on the knowledge of the network structure, we prove a\n$O(\\sqrt{\\overline{\\chi} T})$ sublinear regret bound, where $\\overline{\\chi}\n\\ge \\alpha$ is the clique-covering number of the network. \n\n"}
{"id": "1901.08201", "contents": "Title: ISeeU: Visually interpretable deep learning for mortality prediction\n  inside the ICU Abstract: To improve the performance of Intensive Care Units (ICUs), the field of\nbio-statistics has developed scores which try to predict the likelihood of\nnegative outcomes. These help evaluate the effectiveness of treatments and\nclinical practice, and also help to identify patients with unexpected outcomes.\nHowever, they have been shown by several studies to offer sub-optimal\nperformance. Alternatively, Deep Learning offers state of the art capabilities\nin certain prediction tasks and research suggests deep neural networks are able\nto outperform traditional techniques. Nevertheless, a main impediment for the\nadoption of Deep Learning in healthcare is its reduced interpretability, for in\nthis field it is crucial to gain insight on the why of predictions, to assure\nthat models are actually learning relevant features instead of spurious\ncorrelations. To address this, we propose a deep multi-scale convolutional\narchitecture trained on the Medical Information Mart for Intensive Care III\n(MIMIC-III) for mortality prediction, and the use of concepts from coalitional\ngame theory to construct visual explanations aimed to show how important these\ninputs are deemed by the network. Our results show our model attains state of\nthe art performance while remaining interpretable. Supporting code can be found\nat https://github.com/williamcaicedo/ISeeU. \n\n"}
{"id": "1901.08247", "contents": "Title: Machine Learning and Deep Learning Algorithms for Bearing Fault\n  Diagnostics -- A Comprehensive Review Abstract: In this survey paper, we systematically summarize existing literature on\nbearing fault diagnostics with machine learning (ML) and data mining\ntechniques. While conventional ML methods, including artificial neural network\n(ANN), principal component analysis (PCA), support vector machines (SVM), etc.,\nhave been successfully applied to the detection and categorization of bearing\nfaults for decades, recent developments in deep learning (DL) algorithms in the\nlast five years have sparked renewed interest in both industry and academia for\nintelligent machine health monitoring. In this paper, we first provide a brief\nreview of conventional ML methods, before taking a deep dive into the\nstate-of-the-art DL algorithms for bearing fault applications. Specifically,\nthe superiority of DL based methods over conventional ML methods are analyzed\nin terms of fault feature extraction and classification performances; many new\nfunctionalities enabled by DL techniques are also summarized. In addition, to\nobtain a more intuitive insight, a comparative study is conducted on the\nclassification accuracy of different algorithms utilizing the open-source Case\nWestern Reserve University (CWRU) bearing dataset. Finally, to facilitate the\ntransition on applying various DL algorithms to bearing fault diagnostics,\ndetailed recommendations and suggestions are provided for specific application\nconditions such as the setup environment, the data size, and the number of\nsensors and sensor types. Future research directions to further enhance the\nperformance of DL algorithms on health monitoring are also discussed. \n\n"}
{"id": "1901.08256", "contents": "Title: Large-Batch Training for LSTM and Beyond Abstract: Large-batch training approaches have enabled researchers to utilize\nlarge-scale distributed processing and greatly accelerate deep-neural net (DNN)\ntraining. For example, by scaling the batch size from 256 to 32K, researchers\nhave been able to reduce the training time of ResNet50 on ImageNet from 29\nhours to 2.2 minutes (Ying et al., 2018). In this paper, we propose a new\napproach called linear-epoch gradual-warmup (LEGW) for better large-batch\ntraining. With LEGW, we are able to conduct large-batch training for both CNNs\nand RNNs with the Sqrt Scaling scheme. LEGW enables Sqrt Scaling scheme to be\nuseful in practice and as a result we achieve much better results than the\nLinear Scaling learning rate scheme. For LSTM applications, we are able to\nscale the batch size by a factor of 64 without losing accuracy and without\ntuning the hyper-parameters. For CNN applications, LEGW is able to achieve the\nsame accuracy even as we scale the batch size to 32K. LEGW works better than\nprevious large-batch auto-tuning techniques. LEGW achieves a 5.3X average\nspeedup over the baselines for four LSTM-based applications on the same\nhardware. We also provide some theoretical explanations for LEGW. \n\n"}
{"id": "1901.08386", "contents": "Title: PAC Identification of Many Good Arms in Stochastic Multi-Armed Bandits Abstract: We consider the problem of identifying any $k$ out of the best $m$ arms in an\n$n$-armed stochastic multi-armed bandit. Framed in the PAC setting, this\nparticular problem generalises both the problem of `best subset selection' and\nthat of selecting `one out of the best m' arms [arcsk 2017]. In applications\nsuch as crowd-sourcing and drug-designing, identifying a single good solution\nis often not sufficient. Moreover, finding the best subset might be hard due to\nthe presence of many indistinguishably close solutions. Our generalisation of\nidentifying exactly $k$ arms out of the best $m$, where $1 \\leq k \\leq m$,\nserves as a more effective alternative. We present a lower bound on the\nworst-case sample complexity for general $k$, and a fully sequential PAC\nalgorithm, \\GLUCB, which is more sample-efficient on easy instances. Also,\nextending our analysis to infinite-armed bandits, we present a PAC algorithm\nthat is independent of $n$, which identifies an arm from the best $\\rho$\nfraction of arms using at most an additive poly-log number of samples than\ncompared to the lower bound, thereby improving over [arcsk 2017] and\n[Aziz+AKA:2018]. The problem of identifying $k > 1$ distinct arms from the best\n$\\rho$ fraction is not always well-defined; for a special class of this\nproblem, we present lower and upper bounds. Finally, through a reduction, we\nestablish a relation between upper bounds for the `one out of the best $\\rho$'\nproblem for infinite instances and the `one out of the best $m$' problem for\nfinite instances. We conjecture that it is more efficient to solve `small'\nfinite instances using the latter formulation, rather than going through the\nformer. \n\n"}
{"id": "1901.08553", "contents": "Title: Data Interpolations in Deep Generative Models under Non-Simply-Connected\n  Manifold Topology Abstract: Exploiting the deep generative model's remarkable ability of learning the\ndata-manifold structure, some recent researches proposed a geometric data\ninterpolation method based on the geodesic curves on the learned data-manifold.\nHowever, this interpolation method often gives poor results due to a\ntopological difference between the model and the dataset. The model defines a\nfamily of simply-connected manifolds, whereas the dataset generally contains\ndisconnected regions or holes that make them non-simply-connected. To\ncompensate this difference, we propose a novel density regularizer that make\nthe interpolation path circumvent the holes denoted by low probability density.\nWe confirm that our method gives consistently better interpolation results from\nthe experiments with real-world image datasets. \n\n"}
{"id": "1901.08556", "contents": "Title: Visualized Insights into the Optimization Landscape of Fully\n  Convolutional Networks Abstract: Many image processing tasks involve image-to-image mapping, which can be\naddressed well by fully convolutional networks (FCN) without any heavy\npreprocessing. Although empirically designing and training FCNs can achieve\nsatisfactory results, reasons for the improvement in performance are slightly\nambiguous. Our study is to make progress in understanding their generalization\nabilities through visualizing the optimization landscapes. The visualization of\nobjective functions is obtained by choosing a solution and projecting its\nvicinity onto a 3D space. We compare three FCN-based networks (two existing\nmodels and a new proposed in this paper for comparison) on multiple datasets.\nIt has been observed in practice that the connections from the pre-pooled\nfeature maps to the post-upsampled can achieve better results. We investigate\nthe cause and provide experiments to shows that the skip-layer connections in\nFCN can promote flat optimization landscape, which is well known to generalize\nbetter. Additionally, we explore the relationship between the models\ngeneralization ability and loss surface under different batch sizes. Results\nshow that large-batch training makes the model converge to sharp minimizers\nwith chaotic vicinities while small-batch method leads the model to flat\nminimizers with smooth and nearly convex regions. Our work may contribute to\ninsights and analysis for designing and training FCNs. \n\n"}
{"id": "1901.08571", "contents": "Title: Nonparametric Inference under B-bits Quantization Abstract: Statistical inference based on lossy or incomplete samples is often needed in\nresearch areas such as signal/image processing, medical image storage, remote\nsensing, signal transmission. In this paper, we propose a nonparametric testing\nprocedure based on samples quantized to $B$ bits through a computationally\nefficient algorithm. Under mild technical conditions, we establish the\nasymptotic properties of the proposed test statistic and investigate how the\ntesting power changes as $B$ increases. In particular, we show that if $B$\nexceeds a certain threshold, the proposed nonparametric testing procedure\nachieves the classical minimax rate of testing (Shang and Cheng, 2015) for\nspline models. We further extend our theoretical investigations to a\nnonparametric linearity test and an adaptive nonparametric test, expanding the\napplicability of the proposed methods. Extensive simulation studies {together\nwith a real-data analysis} are used to demonstrate the validity and\neffectiveness of the proposed tests. \n\n"}
{"id": "1901.08573", "contents": "Title: Theoretically Principled Trade-off between Robustness and Accuracy Abstract: We identify a trade-off between robustness and accuracy that serves as a\nguiding principle in the design of defenses against adversarial examples.\nAlthough this problem has been widely studied empirically, much remains unknown\nconcerning the theory underlying this trade-off. In this work, we decompose the\nprediction error for adversarial examples (robust error) as the sum of the\nnatural (classification) error and boundary error, and provide a differentiable\nupper bound using the theory of classification-calibrated loss, which is shown\nto be the tightest possible upper bound uniform over all probability\ndistributions and measurable predictors. Inspired by our theoretical analysis,\nwe also design a new defense method, TRADES, to trade adversarial robustness\noff against accuracy. Our proposed algorithm performs well experimentally in\nreal-world datasets. The methodology is the foundation of our entry to the\nNeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of\n~2,000 submissions, surpassing the runner-up approach by $11.41\\%$ in terms of\nmean $\\ell_2$ perturbation distance. \n\n"}
{"id": "1901.08624", "contents": "Title: AutoShuffleNet: Learning Permutation Matrices via an Exact Lipschitz\n  Continuous Penalty in Deep Convolutional Neural Networks Abstract: ShuffleNet is a state-of-the-art light weight convolutional neural network\narchitecture. Its basic operations include group, channel-wise convolution and\nchannel shuffling. However, channel shuffling is manually designed empirically.\nMathematically, shuffling is a multiplication by a permutation matrix. In this\npaper, we propose to automate channel shuffling by learning permutation\nmatrices in network training. We introduce an exact Lipschitz continuous\nnon-convex penalty so that it can be incorporated in the stochastic gradient\ndescent to approximate permutation at high precision. Exact permutations are\nobtained by simple rounding at the end of training and are used in inference.\nThe resulting network, referred to as AutoShuffleNet, achieved improved\nclassification accuracies on CIFAR-10 and ImageNet data sets. In addition, we\nfound experimentally that the standard convex relaxation of permutation\nmatrices into stochastic matrices leads to poor performance. We prove\ntheoretically the exactness (error bounds) in recovering permutation matrices\nwhen our penalty function is zero (very small). We present examples of\npermutation optimization through graph matching and two-layer neural network\nmodels where the loss functions are calculated in closed analytical form. In\nthe examples, convex relaxation failed to capture permutations whereas our\npenalty succeeded. \n\n"}
{"id": "1901.08817", "contents": "Title: State-Regularized Recurrent Neural Networks Abstract: Recurrent neural networks are a widely used class of neural architectures.\nThey have, however, two shortcomings. First, it is difficult to understand what\nexactly they learn. Second, they tend to work poorly on sequences requiring\nlong-term memorization, despite having this capacity in principle. We aim to\naddress both shortcomings with a class of recurrent networks that use a\nstochastic state transition mechanism between cell applications. This\nmechanism, which we term state-regularization, makes RNNs transition between a\nfinite set of learnable states. We evaluate state-regularized RNNs on (1)\nregular languages for the purpose of automata extraction; (2) nonregular\nlanguages such as balanced parentheses, palindromes, and the copy task where\nexternal memory is required; and (3) real-word sequence learning tasks for\nsentiment analysis, visual object recognition, and language modeling. We show\nthat state-regularization (a) simplifies the extraction of finite state\nautomata modeling an RNN's state transition dynamics; (b) forces RNNs to\noperate more like automata with external memory and less like finite state\nmachines; (c) makes RNNs have better interpretability and explainability. \n\n"}
{"id": "1901.08930", "contents": "Title: Effectiveness of Tree-based Ensembles for Anomaly Discovery: Insights,\n  Batch and Streaming Active Learning Abstract: In many real-world AD applications including computer security and fraud\nprevention, the anomaly detector must be configurable by the human analyst to\nminimize the effort on false positives. One important way to configure the\ndetector is by providing true labels (nominal or anomaly) for a few instances.\nRecent work on active anomaly discovery has shown that greedily querying the\ntop-scoring instance and tuning the weights of ensemble detectors based on\nlabel feedback allows us to quickly discover true anomalies.\n  This paper makes four main contributions to improve the state-of-the-art in\nanomaly discovery using tree-based ensembles. First, we provide an important\ninsight that explains the practical successes of unsupervised tree-based\nensembles and active learning based on greedy query selection strategy. We also\npresent empirical results on real-world data to support our insights and\ntheoretical analysis to support active learning. Second, we develop a novel\nbatch active learning algorithm to improve the diversity of discovered\nanomalies based on a formalism called compact description to describe the\ndiscovered anomalies. Third, we develop a novel active learning algorithm to\nhandle streaming data setting. We present a data drift detection algorithm that\nnot only detects the drift robustly, but also allows us to take corrective\nactions to adapt the anomaly detector in a principled manner. Fourth, we\npresent extensive experiments to evaluate our insights and our tree-based\nactive anomaly discovery algorithms in both batch and streaming data settings.\nOur results show that active learning allows us to discover significantly more\nanomalies than state-of-the-art unsupervised baselines, our batch active\nlearning algorithm discovers diverse anomalies, and our algorithms under the\nstreaming-data setup are competitive with the batch setup. \n\n"}
{"id": "1901.09047", "contents": "Title: Faster Boosting with Smaller Memory Abstract: State-of-the-art implementations of boosting, such as XGBoost and LightGBM,\ncan process large training sets extremely fast. However, this performance\nrequires that the memory size is sufficient to hold a 2-3 multiple of the\ntraining set size. This paper presents an alternative approach to implementing\nthe boosted trees, which achieves a significant speedup over XGBoost and\nLightGBM, especially when the memory size is small. This is achieved using a\ncombination of three techniques: early stopping, effective sample size, and\nstratified sampling. Our experiments demonstrate a 10-100 speedup over XGBoost\nwhen the training data is too large to fit in memory. \n\n"}
{"id": "1901.09087", "contents": "Title: Optimality Implies Kernel Sum Classifiers are Statistically Efficient Abstract: We propose a novel combination of optimization tools with learning theory\nbounds in order to analyze the sample complexity of optimal kernel sum\nclassifiers. This contrasts the typical learning theoretic results which hold\nfor all (potentially suboptimal) classifiers. Our work also justifies\nassumptions made in prior work on multiple kernel learning. As a byproduct of\nour analysis, we also provide a new form of Rademacher complexity for\nhypothesis classes containing only optimal classifiers. \n\n"}
{"id": "1901.09344", "contents": "Title: Stochastic Approximation of Smooth and Strongly Convex Functions: Beyond\n  the $O(1/T)$ Convergence Rate Abstract: Stochastic approximation (SA) is a classical approach for stochastic convex\noptimization. Previous studies have demonstrated that the convergence rate of\nSA can be improved by introducing either smoothness or strong convexity\ncondition. In this paper, we make use of smoothness and strong convexity\nsimultaneously to boost the convergence rate. Let $\\lambda$ be the modulus of\nstrong convexity, $\\kappa$ be the condition number, $F_*$ be the minimal risk,\nand $\\alpha>1$ be some small constant. First, we demonstrate that, in\nexpectation, an $O(1/[\\lambda T^\\alpha] + \\kappa F_*/T)$ risk bound is\nattainable when $T = \\Omega(\\kappa^\\alpha)$. Thus, when $F_*$ is small, the\nconvergence rate could be faster than $O(1/[\\lambda T])$ and approaches\n$O(1/[\\lambda T^\\alpha])$ in the ideal case. Second, to further benefit from\nsmall risk, we show that, in expectation, an $O(1/2^{T/\\kappa}+F_*)$ risk bound\nis achievable. Thus, the excess risk reduces exponentially until reaching\n$O(F_*)$, and if $F_*=0$, we obtain a global linear convergence. Finally, we\nemphasize that our proof is constructive and each risk bound is equipped with\nan efficient stochastic algorithm attaining that bound. \n\n"}
{"id": "1901.09450", "contents": "Title: ADMM-SOFTMAX : An ADMM Approach for Multinomial Logistic Regression Abstract: We present ADMM-Softmax, an alternating direction method of multipliers\n(ADMM) for solving multinomial logistic regression (MLR) problems. Our method\nis geared toward supervised classification tasks with many examples and\nfeatures. It decouples the nonlinear optimization problem in MLR into three\nsteps that can be solved efficiently. In particular, each iteration of\nADMM-Softmax consists of a linear least-squares problem, a set of independent\nsmall-scale smooth, convex problems, and a trivial dual variable update.\nSolution of the least-squares problem can be be accelerated by pre-computing a\nfactorization or preconditioner, and the separability in the smooth, convex\nproblem can be easily parallelized across examples. For two image\nclassification problems, we demonstrate that ADMM-Softmax leads to improved\ngeneralization compared to a Newton-Krylov, a quasi Newton, and a stochastic\ngradient descent method. \n\n"}
{"id": "1901.09501", "contents": "Title: Data-to-Text Generation with Style Imitation Abstract: Recent neural approaches to data-to-text generation have mostly focused on\nimproving content fidelity while lacking explicit control over writing styles\n(e.g., word choices, sentence structures). More traditional systems use\ntemplates to determine the realization of text. Yet manual or automatic\nconstruction of high-quality templates is difficult, and a template acting as\nhard constraints could harm content fidelity when it does not match the record\nperfectly. We study a new way of stylistic control by using existing sentences\nas soft templates. That is, the model learns to imitate the writing style of\nany given exemplar sentence, with automatic adaptions to faithfully describe\nthe content record. The problem is challenging due to the lack of parallel\ndata. We develop a neural approach that includes a hybrid attention-copy\nmechanism, learns with weak supervisions, and is enhanced with a new content\ncoverage constraint. We conduct experiments in restaurants and sports domains.\nResults show our approach achieves stronger performance than a range of\ncomparison methods. Our approach balances well between content fidelity and\nstyle control given exemplars that match the records to varying degrees. \n\n"}
{"id": "1901.09532", "contents": "Title: Target Tracking for Contextual Bandits: Application to Demand Side\n  Management Abstract: We propose a contextual-bandit approach for demand side management by\noffering price incentives. More precisely, a target mean consumption is set at\neach round and the mean consumption is modeled as a complex function of the\ndistribution of prices sent and of some contextual variables such as the\ntemperature, weather, and so on. The performance of our strategies is measured\nin quadratic losses through a regret criterion. We offer $T^{2/3}$ upper bounds\non this regret (up to poly-logarithmic terms)---and even faster rates under\nstronger assumptions---for strategies inspired by standard strategies for\ncontextual bandits (like LinUCB, see Li et al., 2010). Simulations on a real\ndata set gathered by UK Power Networks, in which price incentives were offered,\nshow that our strategies are effective and may indeed manage demand response by\nsuitably picking the price levels. \n\n"}
{"id": "1901.09892", "contents": "Title: A Black-box Attack on Neural Networks Based on Swarm Evolutionary\n  Algorithm Abstract: Neural networks play an increasingly important role in the field of machine\nlearning and are included in many applications in society. Unfortunately,\nneural networks suffer from adversarial samples generated to attack them.\nHowever, most of the generation approaches either assume that the attacker has\nfull knowledge of the neural network model or are limited by the type of\nattacked model. In this paper, we propose a new approach that generates a\nblack-box attack to neural networks based on the swarm evolutionary algorithm.\nBenefiting from the improvements in the technology and theoretical\ncharacteristics of evolutionary algorithms, our approach has the advantages of\neffectiveness, black-box attack, generality, and randomness. Our experimental\nresults show that both the MNIST images and the CIFAR-10 images can be\nperturbed to successful generate a black-box attack with 100\\% probability on\naverage. In addition, the proposed attack, which is successful on distilled\nneural networks with almost 100\\% probability, is resistant to defensive\ndistillation. The experimental results also indicate that the robustness of the\nartificial intelligence algorithm is related to the complexity of the model and\nthe data set. In addition, we find that the adversarial samples to some extent\nreproduce the characteristics of the sample data learned by the neural network\nmodel. \n\n"}
{"id": "1901.10053", "contents": "Title: Towards Fair Deep Clustering With Multi-State Protected Variables Abstract: Fair clustering under the disparate impact doctrine requires that population\nof each protected group should be approximately equal in every cluster.\nPrevious work investigated a difficult-to-scale pre-processing step for\n$k$-center and $k$-median style algorithms for the special case of this problem\nwhen the number of protected groups is two. In this work, we consider a more\ngeneral and practical setting where there can be many protected groups. To this\nend, we propose Deep Fair Clustering, which learns a discriminative but fair\ncluster assignment function. The experimental results on three public datasets\nwith different types of protected attribute show that our approach can steadily\nimprove the degree of fairness while only having minor loss in terms of\nclustering quality. \n\n"}
{"id": "1901.10155", "contents": "Title: Revisiting Sample Selection Approach to Positive-Unlabeled Learning:\n  Turning Unlabeled Data into Positive rather than Negative Abstract: In the early history of positive-unlabeled (PU) learning, the sample\nselection approach, which heuristically selects negative (N) data from U data,\nwas explored extensively. However, this approach was later dominated by the\nimportance reweighting approach, which carefully treats all U data as N data.\nMay there be a new sample selection method that can outperform the latest\nimportance reweighting method in the deep learning age? This paper is devoted\nto answering this question affirmatively---we propose to label large-loss U\ndata as P, based on the memorization properties of deep networks. Since P data\nselected in such a way are biased, we develop a novel learning objective that\ncan handle such biased P data properly. Experiments confirm the superiority of\nthe proposed method. \n\n"}
{"id": "1901.10208", "contents": "Title: A Push-Pull Layer Improves Robustness of Convolutional Neural Networks Abstract: We propose a new layer in Convolutional Neural Networks (CNNs) to increase\ntheir robustness to several types of noise perturbations of the input images.\nWe call this a push-pull layer and compute its response as the combination of\ntwo half-wave rectified convolutions, with kernels of opposite polarity. It is\nbased on a biologically-motivated non-linear model of certain neurons in the\nvisual system that exhibit a response suppression phenomenon, known as\npush-pull inhibition. We validate our method by substituting the first\nconvolutional layer of the LeNet-5 and WideResNet architectures with our\npush-pull layer. We train the networks on nonperturbed training images from the\nMNIST, CIFAR-10 and CIFAR-100 data sets, and test on images perturbed by noise\nthat is unseen by the training process. We demonstrate that our push-pull\nlayers contribute to a considerable improvement in robustness of classification\nof images perturbed by noise, while maintaining state-of-the-art performance on\nthe original image classification task. \n\n"}
{"id": "1901.10310", "contents": "Title: Robust Learning from Untrusted Sources Abstract: Modern machine learning methods often require more data for training than a\nsingle expert can provide. Therefore, it has become a standard procedure to\ncollect data from external sources, e.g. via crowdsourcing. Unfortunately, the\nquality of these sources is not always guaranteed. As additional complications,\nthe data might be stored in a distributed way, or might even have to remain\nprivate. In this work, we address the question of how to learn robustly in such\nscenarios. Studying the problem through the lens of statistical learning\ntheory, we derive a procedure that allows for learning from all available\nsources, yet automatically suppresses irrelevant or corrupted data. We show by\nextensive experiments that our method provides significant improvements over\nalternative approaches from robust statistics and distributed optimization. \n\n"}
{"id": "1901.10604", "contents": "Title: Improved Path-length Regret Bounds for Bandits Abstract: We study adaptive regret bounds in terms of the variation of the losses (the\nso-called path-length bounds) for both multi-armed bandit and more generally\nlinear bandit. We first show that the seemingly suboptimal path-length bound of\n(Wei and Luo, 2018) is in fact not improvable for adaptive adversary. Despite\nthis negative result, we then develop two new algorithms, one that strictly\nimproves over (Wei and Luo, 2018) with a smaller path-length measure, and the\nother which improves over (Wei and Luo, 2018) for oblivious adversary when the\npath-length is large. Our algorithms are based on the well-studied optimistic\nmirror descent framework, but importantly with several novel techniques,\nincluding new optimistic predictions, a slight bias towards recently selected\narms, and the use of a hybrid regularizer similar to that of (Bubeck et al.,\n2018).\n  Furthermore, we extend our results to linear bandit by showing a reduction to\nobtaining dynamic regret for a full-information problem, followed by a further\nreduction to convex body chasing. We propose a simple greedy chasing algorithm\nfor squared 2-norm, leading to new dynamic regret results and as a consequence\nthe first path-length regret for general linear bandit as well. \n\n"}
{"id": "1901.10634", "contents": "Title: Privacy-preserving Q-Learning with Functional Noise in Continuous State\n  Spaces Abstract: We consider differentially private algorithms for reinforcement learning in\ncontinuous spaces, such that neighboring reward functions are\nindistinguishable. This protects the reward information from being exploited by\nmethods such as inverse reinforcement learning. Existing studies that guarantee\ndifferential privacy are not extendable to infinite state spaces, as the noise\nlevel to ensure privacy will scale accordingly to infinity. Our aim is to\nprotect the value function approximator, without regard to the number of states\nqueried to the function. It is achieved by adding functional noise to the value\nfunction iteratively in the training. We show rigorous privacy guarantees by a\nseries of analyses on the kernel of the noise space, the probabilistic bound of\nsuch noise samples, and the composition over the iterations. We gain insight\ninto the utility analysis by proving the algorithm's approximate optimality\nwhen the state space is discrete. Experiments corroborate our theoretical\nfindings and show improvement over existing approaches. \n\n"}
{"id": "1901.10654", "contents": "Title: Domain Discrepancy Measure for Complex Models in Unsupervised Domain\n  Adaptation Abstract: Appropriately evaluating the discrepancy between domains is essential for the\nsuccess of unsupervised domain adaptation. In this paper, we first point out\nthat existing discrepancy measures are less informative when complex models\nsuch as deep neural networks are used, in addition to the facts that they can\nbe computationally highly demanding and their range of applications is limited\nonly to binary classification. We then propose a novel domain discrepancy\nmeasure, called the paired hypotheses discrepancy (PHD), to overcome these\nshortcomings. PHD is computationally efficient and applicable to multi-class\nclassification. Through generalization error bound analysis, we theoretically\nshow that PHD is effective even for complex models. Finally, we demonstrate the\npractical usefulness of PHD through experiments. \n\n"}
{"id": "1901.10801", "contents": "Title: Generalized Tensor Models for Recurrent Neural Networks Abstract: Recurrent Neural Networks (RNNs) are very successful at solving challenging\nproblems with sequential data. However, this observed efficiency is not yet\nentirely explained by theory. It is known that a certain class of\nmultiplicative RNNs enjoys the property of depth efficiency --- a shallow\nnetwork of exponentially large width is necessary to realize the same score\nfunction as computed by such an RNN. Such networks, however, are not very often\napplied to real life tasks. In this work, we attempt to reduce the gap between\ntheory and practice by extending the theoretical analysis to RNNs which employ\nvarious nonlinearities, such as Rectified Linear Unit (ReLU), and show that\nthey also benefit from properties of universality and depth efficiency. Our\ntheoretical results are verified by a series of extensive computational\nexperiments. \n\n"}
{"id": "1901.10964", "contents": "Title: Transfer in Deep Reinforcement Learning Using Successor Features and\n  Generalised Policy Improvement Abstract: The ability to transfer skills across tasks has the potential to scale up\nreinforcement learning (RL) agents to environments currently out of reach.\nRecently, a framework based on two ideas, successor features (SFs) and\ngeneralised policy improvement (GPI), has been introduced as a principled way\nof transferring skills. In this paper we extend the SFs & GPI framework in two\nways. One of the basic assumptions underlying the original formulation of SFs &\nGPI is that rewards for all tasks of interest can be computed as linear\ncombinations of a fixed set of features. We relax this constraint and show that\nthe theoretical guarantees supporting the framework can be extended to any set\nof tasks that only differ in the reward function. Our second contribution is to\nshow that one can use the reward functions themselves as features for future\ntasks, without any loss of expressiveness, thus removing the need to specify a\nset of features beforehand. This makes it possible to combine SFs & GPI with\ndeep learning in a more stable way. We empirically verify this claim on a\ncomplex 3D environment where observations are images from a first-person\nperspective. We show that the transfer promoted by SFs & GPI leads to very good\npolicies on unseen tasks almost instantaneously. We also describe how to learn\npolicies specialised to the new tasks in a way that allows them to be added to\nthe agent's set of skills, and thus be reused in the future. \n\n"}
{"id": "1901.11300", "contents": "Title: Robust Inference via Generative Classifiers for Handling Noisy Labels Abstract: Large-scale datasets may contain significant proportions of noisy (incorrect)\nclass labels, and it is well-known that modern deep neural networks (DNNs)\npoorly generalize from such noisy training datasets. To mitigate the issue, we\npropose a novel inference method, termed Robust Generative classifier (RoG),\napplicable to any discriminative (e.g., softmax) neural classifier pre-trained\non noisy datasets. In particular, we induce a generative classifier on top of\nhidden feature spaces of the pre-trained DNNs, for obtaining a more robust\ndecision boundary. By estimating the parameters of generative classifier using\nthe minimum covariance determinant estimator, we significantly improve the\nclassification accuracy with neither re-training of the deep model nor changing\nits architectures. With the assumption of Gaussian distribution for features,\nwe prove that RoG generalizes better than baselines under noisy labels.\nFinally, we propose the ensemble version of RoG to improve its performance by\ninvestigating the layer-wise characteristics of DNNs. Our extensive\nexperimental results demonstrate the superiority of RoG given different\nlearning models optimized by several training techniques to handle diverse\nscenarios of noisy labels. \n\n"}
{"id": "1901.11311", "contents": "Title: New Tricks for Estimating Gradients of Expectations Abstract: We introduce a family of pairwise stochastic gradient estimators for\ngradients of expectations, which are related to the log-derivative trick, but\ninvolve pairwise interactions between samples. The simplest example of our new\nestimator, dubbed the fundamental trick estimator, is shown to arise from\neither a) introducing and approximating an integral representation based on the\nfundamental theorem of calculus, or b) applying the reparameterisation trick to\nan implicit parameterisation under infinitesimal perturbation of the\nparameters. From the former perspective we generalise to a reproducing kernel\nHilbert space representation, giving rise to a locality parameter in the\npairwise interactions mentioned above, yielding our representer trick\nestimator. The resulting estimators are unbiased and shown to offer an\nindependent component of useful information in comparison with the\nlog-derivative estimator. We provide a further novel theoretical analysis which\nfurther characterises the variance reduction afforded by the new techniques.\nPromising analytical and numerical examples confirm the theory and intuitions\nbehind the new estimators. \n\n"}
{"id": "1901.11333", "contents": "Title: IMaT: Unsupervised Text Attribute Transfer via Iterative Matching and\n  Translation Abstract: Text attribute transfer aims to automatically rewrite sentences such that\nthey possess certain linguistic attributes, while simultaneously preserving\ntheir semantic content. This task remains challenging due to a lack of\nsupervised parallel data. Existing approaches try to explicitly disentangle\ncontent and attribute information, but this is difficult and often results in\npoor content-preservation and ungrammaticality. In contrast, we propose a\nsimpler approach, Iterative Matching and Translation (IMaT), which: (1)\nconstructs a pseudo-parallel corpus by aligning a subset of semantically\nsimilar sentences from the source and the target corpora; (2) applies a\nstandard sequence-to-sequence model to learn the attribute transfer; (3)\niteratively improves the learned transfer function by refining imperfections in\nthe alignment. In sentiment modification and formality transfer tasks, our\nmethod outperforms complex state-of-the-art systems by a large margin. As an\nauxiliary contribution, we produce a publicly-available test set with\nhuman-generated transfer references. \n\n"}
{"id": "1901.11365", "contents": "Title: Noise2Self: Blind Denoising by Self-Supervision Abstract: We propose a general framework for denoising high-dimensional measurements\nwhich requires no prior on the signal, no estimate of the noise, and no clean\ntraining data. The only assumption is that the noise exhibits statistical\nindependence across different dimensions of the measurement, while the true\nsignal exhibits some correlation. For a broad class of functions\n(\"$\\mathcal{J}$-invariant\"), it is then possible to estimate the performance of\na denoiser from noisy data alone. This allows us to calibrate\n$\\mathcal{J}$-invariant versions of any parameterised denoising algorithm, from\nthe single hyperparameter of a median filter to the millions of weights of a\ndeep neural network. We demonstrate this on natural image and microscopy data,\nwhere we exploit noise independence between pixels, and on single-cell gene\nexpression data, where we exploit independence between detections of individual\nmolecules. This framework generalizes recent work on training neural nets from\nnoisy images and on cross-validation for matrix factorization. \n\n"}
{"id": "astro-ph/0309566", "contents": "Title: Restrictions on a geometrical language in gravity Abstract: It was shown by the author (gr-qc/0207006) that screening the background of\nsuper-strong interacting gravitons creates Newtonian attraction if single\ngravitons are pairing and graviton pairs are destructed by collisions with a\nbody. In such the model, Newton's constant is connected with Hubble's constant,\nfor which the estimate is obtained: $94.576 km \\cdot s^{-1} \\cdot Mpc^{-1}.$ It\nis necessary to assume an atomic structure of any body to have the working\nmodel. Because of it, an existence of black holes contradicts to the\nequivalence principle in a frame of the model. For usual matter, the\nequivalence principle should be broken at distances $\\sim 10^{-11} m,$ if the\nmodel is true. \n\n"}
{"id": "astro-ph/0311063", "contents": "Title: Aberration and the Fundamental Speed of Gravity in the Jovian Deflection\n  Experiment Abstract: We describe our explicit Lorentz-invariant solution of the Einstein and null\ngeodesic equations for the deflection experiment of 2002 September 8 when a\nmassive moving body, Jupiter, passed within 3.7' of a line-of-sight to a\ndistant quasar. We develop a general relativistic framework which shows that\nour measurement of the retarded position of a moving light-ray deflecting body\n(Jupiter) by making use of the gravitational time delay of quasar's radio wave\nis equivalent to comparison of the relativistic laws of the Lorentz\ntransformation for gravity and light. Because, according to Einstein, the\nLorentz transformation of gravity field variables must depend on a fundamental\nspeed $c$, its measurement through the retarded position of Jupiter in the\ngravitational time delay allows us to study the causal nature of gravity and to\nset an upper limit on the speed of propagation of gravity in the near zone of\nthe solar system as contrasted to the speed of the radio waves. We discuss the\nmisconceptions which have inhibited the acceptance of this interpretation of\nthe experiment. We also comment on other interpretations of this experiment by\nAsada, Will, Samuel, Pascual-Sanchez, and Carlip and show that their `speed of\nlight' interpretations confuse the Lorentz transformation for gravity with that\nfor light, and the fundamental speed of gravity with the physical speed of\nlight from the quasar. \n\n"}
{"id": "cs/0102018", "contents": "Title: An effective Procedure for Speeding up Algorithms Abstract: The provably asymptotically fastest algorithm within a factor of 5 for\nformally described problems will be constructed. The main idea is to enumerate\nall programs provably equivalent to the original problem by enumerating all\nproofs. The algorithm could be interpreted as a generalization and improvement\nof Levin search, which is, within a multiplicative constant, the fastest\nalgorithm for inverting functions. Blum's speed-up theorem is avoided by taking\ninto account only programs for which a correctness proof exists. Furthermore,\nit is shown that the fastest program that computes a certain function is also\none of the shortest programs provably computing this function. To quantify this\nstatement, the definition of Kolmogorov complexity is extended, and two new\nnatural measures for the complexity of a function are defined. \n\n"}
{"id": "gr-qc/0008014", "contents": "Title: On a model of an unconstrained hyperfluid Abstract: A hyperfluid is a classical continuous medium carrying hypermomentum. We\nmodify the earlier developed variational approach to a hyperfluid in such a way\nthat the Frenkel type constraints imposed on the hypermomentum current are\neliminated. The resulting self-consistent model is different from the\nWeyssenhoff type one. The essential point is a conservation of the\nhypermomentum current such that the final metrical and canonical\nenergy-momentum forms coincide. \n\n"}
{"id": "gr-qc/0010035", "contents": "Title: Brane-world inflation without inflaton on the brane Abstract: Inspired by the Randall-Sundrum brane-world scenario, we investigate the\npossibility of brane-world inflation driven not by an inflaton field on the\nbrane, but by a bulk, dilaton-like gravitational field. As a toy model for the\ndilaton-like gravitational field, we consider a minimally coupled massive\nscalar field in the bulk 5-dimensional spacetime, and look for a perturbative\nsolution in the anti-de Sitter (AdS) background. For an adequate range of the\nscalar field mass, we find a unique solution that has non-trivial dependence on\nthe 5th dimensional coordinate and that induces slow-roll inflation on the\nbrane. \n\n"}
{"id": "gr-qc/0012074", "contents": "Title: Precanonical Quantum Gravity: quantization without the space-time\n  decomposition Abstract: A nonpertubative approach to quantum gravity using precanonical field\nquantization originating from the covariant De Donder-Weyl Hamiltonian\nformulation which treats space and time variables on equal footing is\npresented. A generally covariant ``multi-temporal'' generalized Schroedinger\nequation on the finite dimensional space of metric and space-time variables is\nobtained. An important ingredient of the formulation is the ``bootstrap\ncondition'' which introduces a classical space-time geometry as an approximate\nconcept emerging as the quantum average in a self-consistent with the\nunderlying quantum dynamics manner. An independence of the theory from an\narbitrarily fixed background is ensured in this way. The prospects and unsolved\nproblems of precanonical quantization of gravity are outlined. \n\n"}
{"id": "gr-qc/0110084", "contents": "Title: Horizon Properties of Einstein-Yang-Mills Black Hole Abstract: We consider static axially symmetric Einstein-Yang-Mills black holes in the\nisolated horizon formalism. The mass of these hairy black holes is related to\nthe mass of the corresponding particle-like solutions by the horizon mass. The\nhairy black holes violate the ``quasi-local uniqueness conjecture'', based on\nthe horizon charges. \n\n"}
{"id": "gr-qc/0206015", "contents": "Title: Horizons and Geodesics of Black Ellipsoids with Anholonomic Conformal\n  Symmetries Abstract: The horizon and geodesic structure of static configurations generated by\nanisotropic conformal transforms of the Schwarzschild metric is analyzed. We\nconstruct the maximal analytic extension of such off--diagonal vacuum metrics\nand conclude that for small deformations there are different classes of vacuum\nsolutions of the Einstein equations describing \"black ellipsoid\" objects. This\nis possible because, in general, for off--diagonal metrics with deformed\nnon--spherical symmetries and associated anholonomic frames the conditions of\nthe uniqueness black hole theorems do not hold. \n\n"}
{"id": "gr-qc/0304039", "contents": "Title: Closed Trapped Surfaces in Cosmology Abstract: The existence of closed trapped surfaces need not imply a cosmological\nsingularity when the spatial hypersurfaces are compact. This is illustrated by\na variety of examples, in particular de Sitter spacetime admits many closed\ntrapped surfaces and obeys the null convergence condition but is non-singular\nin the k=+1 frame. \n\n"}
{"id": "gr-qc/0305039", "contents": "Title: A new general purpose event horizon finder for 3D numerical spacetimes Abstract: I present a new general purpose event horizon finder for full 3D numerical\nspacetimes. It works by evolving a complete null surface backwards in time. The\nnull surface is described as the zero level set of a scalar function, that in\nprinciple is defined everywhere. This description of the surface allows the\nsurface, trivially, to change topology, making this event horizon finder able\nto handle numerical spacetimes, where two (or more) black holes merge into a\nsingle final black hole. \n\n"}
{"id": "gr-qc/0310068", "contents": "Title: How to approach Quantum Gravity - Background independence in 1+1\n  dimensions Abstract: The application of quantum theory to gravity is beset with many technical and\nconceptual problems. After a short tour d'horizon of recent attempts to master\nthose problems by the introduction of new approaches, we show that the aim, a\nbackground independent quantum theory of gravity, can be reached in a\nparticular area, 2d dilaton quantum gravity, without any assumptions beyond\nstandard quantum field theory. \n\n"}
{"id": "gr-qc/0312068", "contents": "Title: Problem of Cosmological Singularity, Inflationary Cosmology and Gauge\n  Theories of Gravitation Abstract: Problem of cosmological singularity is discussed in the framework of gauge\ntheories of gravitation. Generalizing cosmological Friedmann equations (GCFE)\nfor homogeneous isotropic models including scalar fields and usual gravitating\nmatter are introduced. It is shown that by certain restrictions on equation of\nstate of gravitating matter and indefinite parameter of GCFE generic feature of\ninflationary cosmological models of flat, open and closed type is their regular\nbouncing character. \n\n"}
{"id": "gr-qc/0404037", "contents": "Title: Cosmological evolution of a ghost scalar field Abstract: We consider a scalar field with a negative kinetic term minimally coupled to\ngravity. We obtain an exact non-static spherically symmetric solution which\ndescribes a wormhole in cosmological setting. The wormhole is shown to connect\ntwo homogeneous spatially flat universes expanding with acceleration. Depending\non the wormhole's mass parameter $m$ the acceleration can be constant (the de\nSitter case) or infinitely growing. \n\n"}
{"id": "gr-qc/0408093", "contents": "Title: Braneworld cosmological solutions and their stability Abstract: We consider cosmological solutions and their stability with respect to\nhomogeneous and isotropic perturbations in the braneworld model with the\nscalar-curvature term in the action for the brane. Part of the results are\nsimilar to those obtained by Campos and Sopuerta for the Randall-Sundrum\nbraneworld model. Specifically, the expanding de Sitter solution is an\nattractor, while the expanding Friedmann solution is a repeller. In the\nbraneworld theory with the scalar-curvature term in the action for the brane,\nstatic solutions with matter satisfying the strong energy condition exist not\nonly with closed spatial geometry but also with open and flat ones even in the\ncase where the dark-radiation contribution is absent. In a certain range of\nparameters, static solutions are stable with respect to homogeneous and\nisotropic perturbations. \n\n"}
{"id": "gr-qc/0408099", "contents": "Title: Quasinormal modes and classical wave propagation in analogue black holes Abstract: Many properties of black holes can be studied using acoustic analogues in the\nlaboratory through the propagation of sound waves. We investigate in detail\nsound wave propagation in a rotating acoustic (2+1)-dimensional black hole,\nwhich corresponds to the ``draining bathtub'' fluid flow. We compute the\nquasinormal mode frequencies of this system and discuss late-time power-law\ntails. Due to the presence of an ergoregion, waves in a rotating acoustic black\nhole can be superradiantly amplified. We compute superradiant reflection\ncoefficients and instability timescales for the acoustic black hole bomb, the\nequivalent of the Press-Teukolsky black hole bomb. Finally we discuss\nquasinormal modes and late-time tails in a non-rotating canonical acoustic\nblack hole, corresponding to an incompressible, spherically symmetric\n(3+1)-dimensional fluid flow. \n\n"}
{"id": "gr-qc/0409072", "contents": "Title: Riemannian light cone from vanishing birefringence in premetric vacuum\n  electrodynamics Abstract: We consider premetric electrodynamics with a local and linear constitutive\nlaw for the vacuum. Within this framework, we find quartic Fresnel wave\nsurfaces for the propagation of light. If we require vanishing birefringence in\nvacuum, then a Riemannian light cone is implied. No proper Finslerian structure\ncan occur. This is generalized to dynamical equations of any order. \n\n"}
{"id": "gr-qc/0411126", "contents": "Title: Formation of voids in the Universe within the Lemaitre-Tolman model Abstract: We develop models of void formation starting from a small initial fluctuation\nat recombination and growing to a realistic present day density profile in\nagreement with observations of voids. The model construction is an extension of\npreviously developed algorithms for finding a Lemaitre-Tolman metric that\nevolves between two profiles of either density or velocity specified at two\ntimes. Of the 4 profiles of concern -- those of density and velocity at\nrecombination and at the present day -- two can be specified and the other two\nfollow from the derived model. We find that, in order to reproduce the\npresent-day void density profiles, the initial velocity profile is more\nimportant than the initial density profile. Extrapolation of current CMB\nobservations to the scales relevant to proto-voids is very uncertain. Even so,\nwe find that it is very difficult to make both the initial density and velocity\nfluctuation amplitudes small enough, and still obtain a realistic void by\ntoday. \n\n"}
{"id": "gr-qc/0412032", "contents": "Title: General Relativity as a Genuine Connection Theory Abstract: The Palatini formulation is used to develop a genuine connection theory for\ngeneral relativity, in which the gravitational field is represented by a\nLorentz-valued spin connection. The existence of a tetrad field, given by the\nFock-Ivanenko covariant derivative of the tangent-space coordinates, implies a\ncoupling between the spin connection and the coordinate vector-field, which\nturns out to be the responsible for the onset of curvature. This\nconnection-coordinate coupling can thus be considered as the very foundation of\nthe gravitational interaction. The peculiar form of the tetrad field is shown\nto reduce both Bianchi identities of general relativity to a single one, which\nbrings this theory closer to the gauge theories describing the other\nfundamental interactions of Nature. Some further properties of this approach\nare also examined. \n\n"}
{"id": "gr-qc/0503001", "contents": "Title: A time-domain fourth-order-convergent numerical algorithm to integrate\n  black hole perturbations in the extreme-mass-ratio limit Abstract: We obtain a fourth order accurate numerical algorithm to integrate the\nZerilli and Regge-Wheeler wave equations, describing perturbations of\nnonrotating black holes, with source terms due to an orbiting particle. Those\nsource terms contain the Dirac's delta and its first derivative. We also\nre-derive the source of the Zerilli and Regge-Wheeler equations for more\nconvenient definitions of the waveforms, that allow direct metric\nreconstruction (in the Regge-Wheeler gauge). \n\n"}
{"id": "gr-qc/0510079", "contents": "Title: Problems with wormholes which involve arbitrarily small amounts of\n  exotic matter Abstract: A quantum inequality bound on the expectation value of the null-contracted\nstress tensor in an arbitrary Hadamard state is used to obtain constraints on\nthe geometries of traversable wormholes. Particular attention is given to the\nwormhole models of Visser, Kar, and Dadhich (VKD) and to those of Kuhfittig.\nThese are models which use arbitrarily small amounts of exotic matter for\nwormhole maintenance. It is shown that macroscopic VKD models are either ruled\nout or severely constrained, while a recent model of Kuhfittig is shown to be,\nin fact, non-traversable. \n\n"}
{"id": "gr-qc/0511071", "contents": "Title: The present universe in the Einstein frame, metric-affine R+1/R gravity Abstract: We study the present, flat isotropic universe in 1/R-modified gravity. We use\nthe Palatini (metric-affine) variational principle and the Einstein\n(metric-compatible connected) conformal frame. We show that the energy density\nscaling deviates from the usual scaling for nonrelativistic matter, and the\nlargest deviation occurs in the present epoch. We find that the current\ndeceleration parameter derived from the apparent matter density parameter is\nconsistent with observations. There is also a small overlap between the\npredicted and observed values for the redshift derivative of the deceleration\nparameter. The predicted redshift of the deceleration-to-acceleration\ntransition agrees with that in the \\Lambda-CDM model but it is larger than the\nvalue estimated from SNIa observations. \n\n"}
{"id": "gr-qc/0512121", "contents": "Title: The Study of the Pioneer Anomaly: New Data and Objectives for New\n  Investigation Abstract: Radiometric tracking data from Pioneer 10 and 11 spacecraft has consistently\nindicated the presence of a small, anomalous, Doppler frequency drift,\nuniformly changing with a rate of ~6 x 10^{-9} Hz/s; the drift can be\ninterpreted as a constant sunward acceleration of each particular spacecraft of\na_P = (8.74 \\pm 1.33) x 10^{-10} m/s^2. This signal is known as the Pioneer\nanomaly; the nature of this anomaly remains unexplained. We discuss the efforts\nto retrieve the entire data sets of the Pioneer 10/11 radiometric Doppler data.\nWe also report on the recently recovered telemetry files that may be used to\nreconstruct the engineering history of both spacecraft using original project\ndocumentation and newly developed software tools. We discuss possible ways to\nfurther investigate the discovered effect using these telemetry files in\nconjunction with the analysis of the much extended Doppler data. We present the\nmain objectives of new upcoming study of the Pioneer anomaly, namely i)\nanalysis of the early data that could yield the direction of the anomaly, ii)\nanalysis of planetary encounters, that should tell more about the onset of the\nanomaly, iii) analysis of the entire dataset, to better determine the anomaly's\ntemporal behavior, iv) comparative analysis of individual anomalous\naccelerations for the two Pioneers, v) the detailed study of on-board\nsystematics, and vi) development of a thermal-electric-dynamical model using\non-board telemetry. The outlined strategy may allow for a higher accuracy\nsolution for a_P and, possibly, will lead to an unambiguous determination of\nthe origin of the Pioneer anomaly. \n\n"}
{"id": "gr-qc/0601094", "contents": "Title: A quasi-Kinnersley tetrad for the quasi-Kerr metric Abstract: Explicit expressions for the quasi-Kinnersley tetrad for the quasi-Kerr\nmetric are given. These provide a very clear and simple example of the\nquasi-Kinnersley tetrad, and may be useful in the future development of a\n`quasi-Teukolsky' scheme for the analysis of perturbation equations in\nspacetimes which are Petrov type I but in some sense close to type D. \n\n"}
{"id": "gr-qc/0701018", "contents": "Title: A Rigorous Treatment of Energy Extraction from a Rotating Black Hole Abstract: The Cauchy problem is considered for the scalar wave equation in the Kerr\ngeometry. We prove that by choosing a suitable wave packet as initial data, one\ncan extract energy from the black hole, thereby putting supperradiance, the\nwave analogue of the Penrose process, into a rigorous mathematical framework.\nWe quantify the maximal energy gain. We also compute the infinitesimal change\nof mass and angular momentum of the black hole, in agreement with\nChristodoulou's result for the Penrose process. The main mathematical tool is\nour previously derived integral representation of the wave propagator. \n\n"}
{"id": "gr-qc/9401018", "contents": "Title: Nonsymmetric Gravity Does Have Acceptable Global Asymptotics Abstract: ``Reports of my death are greatly exaggerated''\n  - Mark Twain. We consider the claim by Damour, Deser and McCarthy that\nnonsymmetric gravity theory has unacceptable global asymptotics. We explain why\nthis claim is incorrect. \n\n"}
{"id": "gr-qc/9606016", "contents": "Title: Gravitational Collapse and Cosmic Censorship Abstract: This article gives an elementary overview of the end-state of gravitational\ncollapse according to classical general relativity. The focus of discussion is\nthe formation of black holes and naked singularities in various physically\nreasonable models of gravitational collapse. Possible implications for the\ncosmic censorship hypothesis are outlined. \n\n"}
{"id": "gr-qc/9607013", "contents": "Title: Classical stability of black hole Cauchy horizons in two-dimensional\n  asymptotically flat space-times Abstract: In this paper we analyse the stability of black hole Cauchy horizons arising\nin a class of 2d dilaton gravity models. It is shown that due to the\ncharacteristic asymptotic Rindler form of the metric of these models, time\ndependent gravitational perturbations generated in the external region do not\nnecessarily blow-up when propagated along the Cauchy horizon. There exists, in\nfact, a region of nonzero measure in the space of the parameters characterizing\nthe solutions such that both instability and mass inflation are avoided. This\nis a new result concerning asymptotically flat space-times, not shared by the\nwell-known solutions of General Relativity. Despite this fact, however, quantum\nback-reaction seems to produce a scalar curvature singularity there. \n\n"}
{"id": "gr-qc/9710068", "contents": "Title: Gravitational Collapse and Cosmic Censorship Abstract: We review the status of the weak cosmic censorship conjecture, which asserts,\nin essence, that all singularities of gravitational collapse are hidden within\nblack holes. Although little progress has been made toward a general proof (or\ndisproof) of this conjecture, there has been some notable recent progress in\nthe study of some examples and special cases related to the conjecture. These\nresults support the view that naked singularities cannot arise generically. \n\n"}
{"id": "gr-qc/9902019", "contents": "Title: Coalescing Binary Neutron Stars Abstract: Coalescing compact binaries with neutron star or black hole components\nprovide the most promising sources of gravitational radiation for detection by\nthe LIGO/VIRGO/GEO/TAMA laser interferometers now under construction. This fact\nhas motivated several different theoretical studies of the inspiral and\nhydrodynamic merging of compact binaries. Analytic analyses of the inspiral\nwaveforms have been performed in the Post-Newtonian approximation. Analytic and\nnumerical treatments of the coalescence waveforms from binary neutron stars\nhave been performed using Newtonian hydrodynamics and the quadrupole radiation\napproximation. Numerical simulations of coalescing black hole and neutron star\nbinaries are also underway in full general relativity. Recent results from each\nof these approaches will be described and their virtues and limitations\nsummarized. \n\n"}
{"id": "gr-qc/9905032", "contents": "Title: Godel-type Universes in String-inspired Charged Gravity Abstract: We consider a string-inspired, gravitational theory of scalar and\nelectromagnetic fields and we investigate the existence of axially-symmetric,\nG\\\"{o}del-type cosmological solutions. The neutral case is studied first and an\n\"extreme\" G\\\"{o}del-type rotating solution, that respects the causality, is\ndetermined. The charged case is considered next and two new configurations for\nthe, minimally-coupled to gravity, electromagnetic field are presented. Another\nconfiguration motivated by the expected distribution of currents and charges in\na rotating universe is studied and shown to lead to a G\\\"{o}del-type solution\nfor a space-dependent coupling function. Finally, we investigate the existence\nof G\\\"{o}del-type cosmological solutions in the framework of the one-loop\ncorrected superstring effective action and we determine the sole configuration\nof the electromagnetic field that leads to such a solution. It turns out that,\nin all the charged cases considered, Closed Timelike Curves do appear and the\ncausality is always violated. \n\n"}
{"id": "gr-qc/9908025", "contents": "Title: (2+1)-dimensional Einstein-Kepler problem in the centre-of-mass frame Abstract: We formulate and analyze the Hamiltonian dynamics of a pair of massive\nspinless point particles in (2+1)-dimensional Einstein gravity by anchoring the\nsystem to a conical infinity, isometric to the infinity generated by a single\nmassive but possibly spinning particle. The reduced phase space \\Gamma_{red}\nhas dimension four and topology R^3 x S^1. \\Gamma_{red} is analogous to the\nphase space of a Newtonian two-body system in the centre-of-mass frame, and we\nfind on \\Gamma_{red} a canonical chart that makes this analogue explicit and\nreduces to the Newtonian chart in the appropriate limit. Prospects for\nquantization are commented on. \n\n"}
{"id": "hep-ex/0401032", "contents": "Title: Neutron Background Studies for the CRESST Dark Matter Experiment Abstract: The new detection concept applied for the direct WIMP search experiment\nCRESST II, which enables a clear discrimination between electron recoils and\nnuclear recoils, will leave neutrons as the main background. This background\nwill soon limit the sensitivity of the experiment and therefore become an\nimportant issue for the next phase of CRESST. We have performed a study based\non Monte Carlo simulations to investigate how neutrons from different origins\naffect CRESST and which measures have to be taken to reach the projected\nsensitivity. \n\n"}
{"id": "hep-th/0107100", "contents": "Title: A Note on Conifolds Abstract: We present the Ricci-flat metric and its Kahler potential on the conifold\nwith the O(N) isometry, whose conical singularity is repaired by the complex\nquadric surface Q^{N-2} = SO(N)/SO(N-2)xU(1). \n\n"}
{"id": "hep-th/0107148", "contents": "Title: A Braneworld Universe From Colliding Bubbles Abstract: Much work has been devoted to the phenomenology and cosmology of the\nso-called braneworld universe, where our (3+1)-dimensional universe lies on a\nbrane surrounded by a (4+1)-dimensional bulk spacetime that is essentially\nempty except for a negative cosmological constant and the various modes\nassociated with gravity. For such a braneworld cosmology, the difficulty of\njustifying some preferred initial conditions inevitably arises. The various\nproposals for inflation restricted to the brane only partially explain the\nhomogeneity and isotropy of the resulting braneworld universe because the\nhomogeneity and isotropy of the bulk must be assumed. We propose a mechanism by\nwhich a brane surrounded by AdS space arises naturally so that the homogeneity\nand isotropy of both the brane and the bulk are guaranteed. We postulate an\ninitial false vacuum phase of (4+1)-dimensional Minkowski or de Sitter space\nsubsequently decaying to a true vacuum of anti-de Sitter space, assumed\ndiscretely degenerate. This decay takes place through bubble nucleation. When\ntwo bubbles of the true AdS vacuum collide, a brane (or domain wall) inevitably\nforms between the two AdS phases. We live on this brane. The SO(3,1) symmetry\nof the collision geometry ensures the three-dimensional spatial homogeneity and\nisotropy of the universe on the brane as well as of the bulk. In the\nsemi-classical limit, this symmetry is exact. We sketch how the leading quantum\ncorrections translate into cosmological perturbations. \n\n"}
{"id": "hep-th/0212105", "contents": "Title: Varying alpha and black hole entropy Abstract: Recently it has been suggested that an increase in the fine structure\nconstant alpha with time would decrease the entropy of a Reissner-Nordstrom\nblack hole, thereby violating the second law of thermodynamics. In this note we\npoint out that, at least for a certain class of charged dilaton black holes\nrelated to string theory, the entropy does not change under adiabatic\nvariations of alpha and one might expect it to increase for non-adiabatic\nchanges. \n\n"}
{"id": "hep-th/0310008", "contents": "Title: Black Rings, Supertubes, and a Stringy Resolution of Black Hole\n  Non-Uniqueness Abstract: In order to address the issues raised by the recent discovery of\nnon-uniqueness of black holes in five dimensions, we construct a solution of\nstring theory at low energies describing a five-dimensional spinning black ring\nwith three charges that can be interpreted as D1-brane, D5-brane, and momentum\ncharges. The solution possesses closed timelike curves (CTCs) and other\npathologies, whose origin we clarify. These pathologies can be avoided by\nsetting any one of the charges, e.g. the momentum, to zero. We argue that the\nD1-D5-charged black ring, lifted to six dimensions, describes the thermal\nexcitation of a supersymmetric D1-D5 supertube, which is in the same U-duality\nclass as the D0-F1 supertube. We explain how the stringy microscopic\ndescription of the D1-D5 system distinguishes between a spherical black hole\nand a black ring with the same asymptotic charges, and therefore provides a\n(partial) resolution of the non-uniqueness of black holes in five dimensions. \n\n"}
{"id": "hep-th/0311216", "contents": "Title: The Radion in the Karch-Randall Braneworld Abstract: In a braneworld context, the radion is a massless mode coupling to the trace\nof the matter stress tensor. Since the radion also governs the separation\nbetween branes, it is expected to decouple from the physical spectrum in single\nbrane scenarios, such as the one-brane Randall-Sundrum model. However, contrary\nto expectations, we demonstrate that the Karch-Randall radion always remains as\na physical excitation, even in the single brane case. Here, the radion measures\nthe distance not between branes, but rather between the brane and the anti-de\nSitter boundary on the other side of the bulk. \n\n"}
{"id": "hep-th/0504168", "contents": "Title: Shift Symmetry and Inflation in Supergravity Abstract: We consider models of inflation in supergravity with a shift symmetry. We\nfocus on models with one moduli and one inflaton field. The presence of this\nsymmetry guarantees the existence of a flat direction for the inflaton field.\nMildly breaking the shift symmetry using a superpotential which depends not\nonly on the moduli but also on the inflaton field allows one to lift the\ninflaton flat direction. Along the inflaton direction, the eta-problem is\nalleviated. Combining the KKLT mechanism for moduli stabilization and a shift\nsymmetry breaking superpotential of the chaotic inflation type, we find models\nreminiscent of ``mutated hybrid inflation'' where the inflationary trajectory\nis curved in the moduli--inflaton plane. We analyze the phenomenology of these\nmodels and stress their differences with both chaotic and hybrid inflation. \n\n"}
{"id": "hep-th/0703205", "contents": "Title: A Variational Formulation of Symplectic Noncommutative Mechanics Abstract: The standard lore in noncommutative physics is the use of first order\nvariational description of a dynamical system to probe the space\nnoncommutativity and its consequences in the dynamics in phase space. As the\nultimate goal is to understand the inherent space noncommutativity we propose a\nvariational principle for noncommutative dynamical systems in configuration\nspace, based on results of our previous work [14]. We hope that this\nvariational formulation in configuration space can be of help to elucidate the\ndefinition of some global and dynamical properties of classical and quantum\nnoncommutative space. \n\n"}
{"id": "hep-th/9510007", "contents": "Title: Aspects of hairy black holes in spontaneously-broken Einstein-Yang-Mills\n  systems: Stability analysis and Entropy considerations Abstract: We analyze (3+1)-dimensional black-hole space-times in spontaneously broken\nYang-Mills gauge theories that have been recently presented as candidates for\nan evasion of the scalar-no-hair theorem. Although we show that in principle\nthe conditions for the no-hair theorem do not apply to this case, however we\nprove that the `spirit' of the theorem is not violated, in the sense that there\nexist instabilities, in both the sphaleron and gravitational sectors. The\ninstability analysis of the sphaleron sector, which was expected to be unstable\nfor topological reasons, is performed by means of a variational method. As\nshown, there exist modes in this sector that are unstable against linear\nperturbations. Instabilities exist also in the gravitational sector. A method\nfor counting the gravitational unstable modes, which utilizes a\ncatastrophe-theoretic approach is presented. The r\\^ole of the catastrophe\nfunctional is played by the mass functional of the black hole. The Higgs vacuum\nexpectation value (v.e.v.) is used as a control parameter, having a critical\nvalue beyond which instabilities are turned on. The (stable) Schwarzschild\nsolution is then understood from this point of view. The catastrophe-theory\nappproach facilitates enormously a universal stability study of non-Abelian\nblack holes, which goes beyond linearized perturbations. Some elementary\nentropy considerations are also presented... \n\n"}
{"id": "hep-th/9607235", "contents": "Title: Black Holes in String Theory Abstract: This thesis is devoted to trying to find a microscopic quantum description of\nblack holes. We consider black holes in string theory which is a quantum theory\nof gravity. We find that the ``area law'' black hole entropy for extremal and\nnear-extremal charged black holes arises from counting microscopic\nconfigurations. We study black holes in five and four spacetime dimensions. We\ncalculate the Hawking temperature and give a physical picture of the Hawking\ndecay process. Hopefully, the reader will find here a moderately self contained\nreview of D-branes and string theory applied to black hole physics. \n\n"}
{"id": "math/0510442", "contents": "Title: Black holes in symmetric spaces : anti-de Sitter spaces Abstract: Using symmetric space techniques, we show that closed orbits of the Iwasawa\nsubgroups of $SO(2,l-1)$ naturally define singularities of a black hole causal\nstructure in anti-de Sitter spaces in $l \\geq 3$ dimensions. In particular, we\nrecover for $l=3$ the non-rotating massive BTZ black hole. The method presented\nhere is very simple and in principle generalizable to any semi-simple symmetric\nspace. \n\n"}
