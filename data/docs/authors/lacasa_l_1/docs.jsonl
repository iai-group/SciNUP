{"id": "0704.0089", "contents": "Title: A general approach to statistical modeling of physical laws:\n  nonparametric regression Abstract: Statistical modeling of experimental physical laws is based on the\nprobability density function of measured variables. It is expressed by\nexperimental data via a kernel estimator. The kernel is determined objectively\nby the scattering of data during calibration of experimental setup. A physical\nlaw, which relates measured variables, is optimally extracted from experimental\ndata by the conditional average estimator. It is derived directly from the\nkernel estimator and corresponds to a general nonparametric regression. The\nproposed method is demonstrated by the modeling of a return map of noisy\nchaotic data. In this example, the nonparametric regression is used to predict\na future value of chaotic time series from the present one. The mean predictor\nerror is used in the definition of predictor quality, while the redundancy is\nexpressed by the mean square distance between data points. Both statistics are\nused in a new definition of predictor cost function. From the minimum of the\npredictor cost function, a proper number of data in the model is estimated. \n\n"}
{"id": "0704.0308", "contents": "Title: Effect of node deleting on network structure Abstract: The ever-increasing knowledge of the structure of various real-world networks\nhas uncovered their complex multi-mechanism-governed evolution processes.\nTherefore, a better understanding of the structure and evolution of these\nnetworked complex systems requires us to describe such processes in a more\ndetailed and realistic manner. In this paper, we introduce a new type of\nnetwork growth rule which comprises addition and deletion of nodes, and propose\nan evolving network model to investigate the effect of node deleting on network\nstructure. It is found that, with the introduction of node deleting, network\nstructure is significantly transformed. In particular, degree distribution of\nthe network undergoes a transition from scale-free to exponential forms as the\nintensity of node deleting increases. At the same time, nontrivial\ndisassortative degree correlation develops spontaneously as a natural result of\nnetwork evolution in the model. We also demonstrate that node deleting\nintroduced in the model does not destroy the connectedness of a growing network\nso long as the increasing rate of edges is not excessively small. In addition,\nit is found that node deleting will weaken but not eliminate the small-world\neffect of a growing network, and generally it will decrease the clustering\ncoefficient in a network. \n\n"}
{"id": "0704.0726", "contents": "Title: Long-range correlation and multifractality in Bach's Inventions pitches Abstract: We show that it can be considered some of Bach pitches series as a stochastic\nprocess with scaling behavior. Using multifractal deterend fluctuation analysis\n(MF-DFA) method, frequency series of Bach pitches have been analyzed. In this\nview we find same second moment exponents (after double profiling) in ranges\n(1.7-1.8) in his works. Comparing MF-DFA results of original series to those\nfor shuffled and surrogate series we can distinguish multifractality due to\nlong-range correlations and a broad probability density function. Finally we\ndetermine the scaling exponents and singularity spectrum. We conclude fat tail\nhas more effect in its multifractality nature than long-range correlations. \n\n"}
{"id": "0704.0773", "contents": "Title: Collective behavior of stock price movements in an emerging market Abstract: To investigate the universality of the structure of interactions in different\nmarkets, we analyze the cross-correlation matrix C of stock price fluctuations\nin the National Stock Exchange (NSE) of India. We find that this emerging\nmarket exhibits strong correlations in the movement of stock prices compared to\ndeveloped markets, such as the New York Stock Exchange (NYSE). This is shown to\nbe due to the dominant influence of a common market mode on the stock prices.\nBy comparison, interactions between related stocks, e.g., those belonging to\nthe same business sector, are much weaker. This lack of distinct sector\nidentity in emerging markets is explicitly shown by reconstructing the network\nof mutually interacting stocks. Spectral analysis of C for NSE reveals that,\nthe few largest eigenvalues deviate from the bulk of the spectrum predicted by\nrandom matrix theory, but they are far fewer in number compared to, e.g., NYSE.\nWe show this to be due to the relative weakness of intra-sector interactions\nbetween stocks, compared to the market mode, by modeling stock price dynamics\nwith a two-factor model. Our results suggest that the emergence of an internal\nstructure comprising multiple groups of strongly coupled components is a\nsignature of market development. \n\n"}
{"id": "0704.1023", "contents": "Title: The Effect of Annealing Temperature on Statistical Properties of $WO_3$\n  Surface Abstract: We have studied the effect of annealing temperature on the statistical\nproperties of $WO_3$ surface using atomic force microscopy techniques (AFM). We\nhave applied both level crossing and structure function methods. Level crossing\nanalysis indicates an optimum annealing temperature of around 400$^oC$ at which\nthe effective area of the $WO_3$ thin film is maximum, whereas composition of\nthe surface remains stoichiometric. The complexity of the height fluctuation of\nsurfaces was characterized by roughness, roughness exponent and lateral size of\nsurface features. We have found that there is a phase transition at around\n400$^oC$ from one set to two sets of roughness parameters. This happens due to\nmicrostructural changes from amorphous to crystalline structure in the samples\nthat has been already found experimentally. \n\n"}
{"id": "0704.2115", "contents": "Title: Uncovering the Internal Structure of the Indian Financial Market:\n  Cross-correlation behavior in the NSE Abstract: The cross-correlations between price fluctuations of 201 frequently traded\nstocks in the National Stock Exchange (NSE) of India are analyzed in this\npaper. We use daily closing prices for the period 1996-2006, which coincides\nwith the period of rapid transformation of the market following liberalization.\nThe eigenvalue distribution of the cross-correlation matrix, $\\mathbf{C}$, of\nNSE is found to be similar to that of developed markets, such as the New York\nStock Exchange (NYSE): the majority of eigenvalues fall within the bounds\nexpected for a random matrix constructed from mutually uncorrelated time\nseries. Of the few largest eigenvalues that deviate from the bulk, the largest\nis identified with market-wide movements. The intermediate eigenvalues that\noccur between the largest and the bulk have been associated in NYSE with\nspecific business sectors with strong intra-group interactions. However, in the\nIndian market, these deviating eigenvalues are comparatively very few and lie\nmuch closer to the bulk. We propose that this is because of the relative lack\nof distinct sector identity in the market, with the movement of stocks\ndominantly influenced by the overall market trend. This is shown by explicit\nconstruction of the interaction network in the market, first by generating the\nminimum spanning tree from the unfiltered correlation matrix, and later, using\nan improved method of generating the graph after filtering out the market mode\nand random effects from the data. Both methods show, compared to developed\nmarkets, the relative absence of clusters of co-moving stocks that belong to\nthe same business sector. This is consistent with the general belief that\nemerging markets tend to be more correlated than developed markets. \n\n"}
{"id": "0705.1679", "contents": "Title: Extracting the hierarchical organization of complex systems Abstract: Extracting understanding from the growing ``sea'' of biological and\nsocio-economic data is one of the most pressing scientific challenges facing\nus. Here, we introduce and validate an unsupervised method that is able to\naccurately extract the hierarchical organization of complex biological, social,\nand technological networks. We define an ensemble of hierarchically nested\nrandom graphs, which we use to validate the method. We then apply our method to\nreal-world networks, including the air-transportation network, an electronic\ncircuit, an email exchange network, and metabolic networks. We find that our\nmethod enables us to obtain an accurate multi-scale descriptions of a complex\nsystem. \n\n"}
{"id": "0706.0641", "contents": "Title: Information diffusion epidemics in social networks Abstract: The dynamics of information dissemination in social networks is of paramount\nimportance in processes such as rumors or fads propagation, spread of product\ninnovations or \"word-of-mouth\" communications. Due to the difficulty in\ntracking a specific information when it is transmitted by people, most\nunderstanding of information spreading in social networks comes from models or\nindirect measurements. Here we present an integrated experimental and\ntheoretical framework to understand and quantitatively predict how and when\ninformation spreads over social networks. Using data collected in Viral\nMarketing campaigns that reached over 31,000 individuals in eleven European\nmarkets, we show the large degree of variability of the participants' actions,\ndespite them being confronted with the common task of receiving and forwarding\nthe same piece of information. This have a profound effect on information\ndiffusion: Firstly, most of the transmission takes place due to super-spreading\nevents which would be considered extraordinary in population-average models.\nSecondly, due to the different way individuals schedule information\ntransmission we observe a slowing down of the spreading of information in\nsocial networks that happens in logarithmic time. Quantitative description of\nthe experiments is possible through an stochastic branching process which\ncorroborates the importance of heterogeneity. Since high variability of both\nthe intensity and frequency of human responses are found in many other\nactivities, our findings are pertinent to many other human driven diffusion\nprocesses like rumors, fads, innovations or news which has important\nconsequences for organizations management, communications, marketing or\nelectronic social communities. \n\n"}
{"id": "0706.1645", "contents": "Title: Dynamics of Three Agent Games Abstract: We study the dynamics and resulting score distribution of three-agent games\nwhere after each competition a single agent wins and scores a point. A single\ncompetition is described by a triplet of numbers $p$, $t$ and $q$ denoting the\nprobabilities that the team with the highest, middle or lowest accumulated\nscore wins. We study the full family of solutions in the regime, where the\nnumber of agents and competitions is large, which can be regarded as a\nhydrodynamic limit. Depending on the parameter values $(p,q,t)$, we find six\nqualitatively different asymptotic score distributions and we also provide a\nqualitative understanding of these results. We checked our analytical results\nagainst numerical simulations of the microscopic model and find these to be in\nexcellent agreement. The three agent game can be regarded as a social model\nwhere a player can be favored or disfavored for advancement, based on his/her\naccumulated score. It is also possible to decide the outcome of a three agent\ngame through a mini tournament of two-a gent competitions among the\nparticipating players and it turns out that the resulting possible score\ndistributions are a subset of those obtained for the general three agent-games.\nWe discuss how one can add a steady and democratic decline rate to the model\nand present a simple geometric construction that allows one to write down the\ncorresponding score evolution equations for $n$-agent games. \n\n"}
{"id": "0706.1706", "contents": "Title: Spatiotemporal structure of Lyapunov vectors in chaotic coupled-map\n  lattices Abstract: The spatiotemporal dynamics of Lyapunov vectors (LVs) in spatially extended\nchaotic systems is studied by means of coupled-map lattices. We determine\nintrinsic length scales and spatiotemporal correlations of LVs corresponding to\nthe leading unstable directions by translating the problem to the language of\nscale-invariant growing surfaces. We find that the so-called 'characteristic'\nLVs exhibit spatial localization, strong clustering around given spatiotemporal\nloci, and remarkable dynamic scaling properties of the corresponding surfaces.\nIn contrast, the commonly used backward LVs (obtained through Gram-Schmidt\northogonalization) spread all over the system and do not exhibit dynamic\nscaling due to artifacts in the dynamical correlations by construction. \n\n"}
{"id": "0706.2040", "contents": "Title: Getting started in probabilistic graphical models Abstract: Probabilistic graphical models (PGMs) have become a popular tool for\ncomputational analysis of biological data in a variety of domains. But, what\nexactly are they and how do they work? How can we use PGMs to discover patterns\nthat are biologically relevant? And to what extent can PGMs help us formulate\nnew hypotheses that are testable at the bench? This note sketches out some\nanswers and illustrates the main ideas behind the statistical approach to\nbiological pattern discovery. \n\n"}
{"id": "0706.2592", "contents": "Title: Inhomogeneous and self-organised temperature in Schelling-Ising model Abstract: The Schelling model of 1971 is a complicated version of a square-lattice\nIsing model at zero temperature, to explain urban segregation, based on the\nneighbour preferences of the residents, without external reasons. Various\nversions between Ising and Schelling models give about the same results.\nInhomogeneous \"temperatures\" T do not change the results much, while a feedback\nbetween segregation and T leads to a self-organisation of an average T. \n\n"}
{"id": "0707.1616", "contents": "Title: Modularity and community detection in bipartite networks Abstract: The modularity of a network quantifies the extent, relative to a null model\nnetwork, to which vertices cluster into community groups. We define a null\nmodel appropriate for bipartite networks, and use it to define a bipartite\nmodularity. The bipartite modularity is presented in terms of a modularity\nmatrix B; some key properties of the eigenspectrum of B are identified and used\nto describe an algorithm for identifying modules in bipartite networks. The\nalgorithm is based on the idea that the modules in the two parts of the network\nare dependent, with each part mutually being used to induce the vertices for\nthe other part into the modules. We apply the algorithm to real-world network\ndata, showing that the algorithm successfully identifies the modular structure\nof bipartite networks. \n\n"}
{"id": "0707.2341", "contents": "Title: A Cultural Market Model Abstract: Social interactions and personal tastes shape our consumption behavior of\ncultural products. In this study, we present a computational model of a\ncultural market and we aim to analyze the behavior of the consumer population\nas an emergent phenomena. Our results suggest that the final market shares of\ncultural products dramatically depend on consumer heterogeneity and social\ninteraction pressure. Furthermore, the relation between the resulting market\nshares and social interaction is robust with respect to a wide range of\nvariation in the parameter values and the type of topology. \n\n"}
{"id": "0707.3478", "contents": "Title: Credit risk - A structural model with jumps and correlations Abstract: We set up a structural model to study credit risk for a portfolio containing\nseveral or many credit contracts. The model is based on a jump--diffusion\nprocess for the risk factors, i.e. for the company assets. We also include\ncorrelations between the companies. We discuss that models of this type have\nmuch in common with other problems in statistical physics and in the theory of\ncomplex systems. We study a simplified version of our model analytically.\nFurthermore, we perform extensive numerical simulations for the full model. The\nobservables are the loss distribution of the credit portfolio, its moments and\nother quantities derived thereof. We compile detailed information about the\nparameter dependence of these observables. In the course of setting up and\nanalyzing our model, we also give a review of credit risk modeling for a\nphysics audience. \n\n"}
{"id": "0708.0209", "contents": "Title: Models of Financial Markets with Extensive Participation Incentives Abstract: We consider models of financial markets in which all parties involved find\nincentives to participate. Strategies are evaluated directly by their virtual\nwealths. By tuning the price sensitivity and market impact, a phase diagram\nwith several attractor behaviors resembling those of real markets emerge,\nreflecting the roles played by the arbitrageurs and trendsetters, and including\na phase with irregular price trends and positive sums. The positive-sumness of\nthe players' wealths provides participation incentives for them. Evolution and\nthe bid-ask spread provide mechanisms for the gain in wealth of both the\nplayers and market-makers. New players survive in the market if the\nevolutionary rate is sufficiently slow. We test the applicability of the model\non real Hang Seng Index data over 20 years. Comparisons with other models show\nthat our model has a superior average performance when applied to real\nfinancial data. \n\n"}
{"id": "0708.0311", "contents": "Title: Lagrangian Structure Functions in Turbulence: A Quantitative Comparison\n  between Experiment and Direct Numerical Simulation Abstract: A detailed comparison between data from experimental measurements and\nnumerical simulations of Lagrangian velocity structure functions in turbulence\nis presented. By integrating information from experiments and numerics, a\nquantitative understanding of the velocity scaling properties over a wide range\nof time scales and Reynolds numbers is achieved. The local scaling properties\nof the Lagrangian velocity increments for the experimental and numerical data\nare in good quantitative agreement for all time lags. The degree of\nintermittency changes when measured close to the Kolmogorov time scales or at\nlarger time lags. This study resolves apparent disagreements between experiment\nand numerics. \n\n"}
{"id": "0708.0492", "contents": "Title: Brownian motion in a non-homogeneous force field and photonic force\n  microscope Abstract: The Photonic Force Microscope (PFM) is an opto-mechanical technique based on\nan optical trap that can be assumed to probe forces in microscopic systems.\nThis technique has been used to measure forces in the range of pico- and\nfemto-Newton, assessing the mechanical properties of biomolecules as well as of\nother microscopic systems. For a correct use of the PFM, the force field to\nmeasure has to be invariable (homogeneous) on the scale of the Brownian motion\nof the trapped probe. This condition implicates that the force field must be\nconservative, excluding the possibility of a rotational component. However,\nthere are cases where these assumptions are not fulfilled Here, we show how to\nimprove the PFM technique in order to be able to deal with these cases. We\nintroduce the theory of this enhanced PFM and we propose a concrete analysis\nworkflow to reconstruct the force field from the experimental time-series of\nthe probe position. Furthermore, we experimentally verify some particularly\nimportant cases, namely the case of a conservative or rotational force-field. \n\n"}
{"id": "0708.1866", "contents": "Title: On the equivalence of the microcanonical and the canonical ensembles: a\n  geometrical approach Abstract: In this paper, we consider the volume enclosed by the microcanonical ensemble\nin phase space as a statistical ensemble. This can be interpreted as an\nintermediate image between the microcanonical and the canonical pictures. By\nmaintaining the ergodic hypothesis over this ensemble, that is, the\nequiprobability of all its accessible states, the equivalence of this ensemble\nin the thermodynamic limit with the microcanonical and the canonical ensembles\nis suggested by means of geometrical arguments. The Maxwellian and the\nBoltzmann-Gibbs distributions are obtained from this formalism. In the\nappendix, the derivation of the Boltzmann factor from a new microcanonical\nimage of the canonical ensemble is also given. \n\n"}
{"id": "0708.3334", "contents": "Title: Communication regimes in opinion dynamics: Changing the number of\n  communicating agents Abstract: This article contributes in four ways to the research on time-discrete\ncontinuous opinion dynamics with compromising agents. First, communication\nregimes are introduced as an elementary concept of opinion dynamic models.\nSecond, we develop a model that covers two major models of continuous opinion\ndynamics, i.e. the basic model of Deffuant and Weisbuch as well as the model of\nKrause and Hegselmann. To combine these models, which handle different numbers\nof communicating agents, we convert the convergence parameter of Deffuant and\nWeisbuch into a parameter called self-support. Third, we present simulation\nresults that shed light on how the number of communicating agents but also how\nthe self-support affect opinion dynamics. The fourth contribution is a\ntheoretically driven criterion when to stop a simulation and how to extrapolate\nto infinite many steps. \n\n"}
{"id": "0708.3761", "contents": "Title: Multi-agent systems, Equiprobability, Gamma distributions and other\n  Geometrical questions Abstract: A set of many identical interacting agents obeying a global additive\nconstraint is considered. Under the hypothesis of equiprobability in the\nhigh-dimensional volume delimited in phase space by the constraint, the\nstatistical behavior of a generic agent over the ensemble is worked out. The\nasymptotic distribution of that statistical behavior is derived from\ngeometrical arguments. This distribution is related with the Gamma\ndistributions found in several multi-agent economy models. The parallelism with\nall these systems is established. Also, as a collateral result, a formula for\nthe volume of high-dimensional symmetrical bodies is proposed. \n\n"}
{"id": "0709.2740", "contents": "Title: Transverse Observables and Mass Determination at Hadron Colliders Abstract: I consider the two-body decay of a particle at a hadron collider into a\nvisible and an invisible particle, generalizing $W \\to e \\nu$, where the masses\nof the decaying particle and the invisible decay particle are, {\\em a priori},\nunknown. I prove that the transverse mass, when maximized over possible\nkinematic configurations, can be used to determine both of the unknown masses.\nI argue that the proof can be generalized to cover cases such as decays of\npair-produced superpartners to the lightest, stable superpartner at the Large\nHadron Collider. \n\n"}
{"id": "0709.3418", "contents": "Title: Spartan Random Processes in Time Series Modeling Abstract: A Spartan random process (SRP) is used to estimate the correlation structure\nof time series and to predict (extrapolate) the data values. SRP's are\nmotivated from statistical physics, and they can be viewed as Ginzburg-Landau\nmodels. The temporal correlations of the SRP are modeled in terms of\n`interactions' between the field values. Model parameter inference employs the\ncomputationally fast modified method of moments, which is based on matching\nsample energy moments with the respective stochastic constraints. The\nparameters thus inferred are then compared with those obtained by means of the\nmaximum likelihood method. The performance of the Spartan predictor (SP) is\ninvestigated using real time series of the quarterly S&P 500 index. SP\nprediction errors are compared with those of the Kolmogorov-Wiener predictor.\nTwo predictors, one of which explicit, are derived and used for extrapolation.\nThe performance of the predictors is similarly evaluated. \n\n"}
{"id": "0709.3662", "contents": "Title: Econophysics, Statistical Mechanics Approach to Abstract: This is a review article for Encyclopedia of Complexity and System Science,\nto be published by Springer http://refworks.springer.com/complexity/. The paper\nreviews statistical models for money, wealth, and income distributions\ndeveloped in the econophysics literature since late 1990s. \n\n"}
{"id": "0709.4371", "contents": "Title: The Gradient Mechanism in a Communication Network Abstract: We study the efficiency of the gradient mechanism of message transfer in a\n$2-d$ communication network of regular nodes and randomly distributed hubs.\nEach hub on the network is assigned some randomly chosen capacity and hubs with\nlower capacities are connected to the hubs with maximum capacity. The average\ntravel time of single messages traveling on this lattice, plotted as a function\nof hub density, shows q-exponential behavior. At high hub densities, this\ndistribution can be fitted well by a power law. We also study the relaxation\nbehavior of the network when a large number of messages are created\nsimultaneously at random locations, and travel on the network towards their\ndesignated destinations. For this situation, in the absence of the gradient\nmechanism, the network can show congestion effects due to the formation of\ntransport traps. We show that if hubs of high betweenness centrality are\nconnected by the gradient mechanism, efficient decongestion can be achieved.\nThe gradient mechanism is less prone to the formation of traps than other\ndecongestion schemes. We also study the spatial configurations of transport\ntraps, and propose minimal strategies for their elimination. \n\n"}
{"id": "0710.1068", "contents": "Title: Information and Entropy Abstract: What is information? Is it physical? We argue that in a Bayesian theory the\nnotion of information must be defined in terms of its effects on the beliefs of\nrational agents. Information is whatever constrains rational beliefs and\ntherefore it is the force that induces us to change our minds. This problem of\nupdating from a prior to a posterior probability distribution is tackled\nthrough an eliminative induction process that singles out the logarithmic\nrelative entropy as the unique tool for inference. The resulting method of\nMaximum relative Entropy (ME), which is designed for updating from arbitrary\npriors given information in the form of arbitrary constraints, includes as\nspecial cases both MaxEnt (which allows arbitrary constraints) and Bayes' rule\n(which allows arbitrary priors). Thus, ME unifies the two themes of these\nworkshops -- the Maximum Entropy and the Bayesian methods -- into a single\ngeneral inference scheme that allows us to handle problems that lie beyond the\nreach of either of the two methods separately. I conclude with a couple of\nsimple illustrative examples. \n\n"}
{"id": "0710.2228", "contents": "Title: Recommendation model based on opinion diffusion Abstract: Information overload in the modern society calls for highly efficient\nrecommendation algorithms. In this letter we present a novel diffusion based\nrecommendation model, with users' ratings built into a transition matrix. To\nspeed up computation we introduce a Green function method. The numerical tests\non a benchmark database show that our prediction is superior to the standard\nrecommendation methods. \n\n"}
{"id": "0710.2315", "contents": "Title: Universal Mandelbrot Set as a Model of Phase Transition Theory Abstract: The study of Mandelbrot Sets (MS) is a promising new approach to the phase\ntransition theory. We suggest two improvements which drastically simplify the\nconstruction of MS. They could be used to modify the existing computer programs\nso that they start building MS properly not only for the simplest families.\nThis allows us to add one more parameter to the base function of MS and\ndemonstrate that this is not enough to make the phase diagram connected \n\n"}
{"id": "0710.2402", "contents": "Title: Intraday pattern in bid-ask spreads and its power-law relaxation for\n  Chinese A-share stocks Abstract: We use high-frequency data of 1364 Chinese A-share stocks traded on the\nShanghai Stock Exchange and Shenzhen Stock Exchange to investigate the intraday\npatterns in the bid-ask spreads. The daily periodicity in the spread time\nseries is confirmed by Lomb analysis and the intraday bid-ask spreads are found\nto exhibit $L$-shaped pattern with idiosyncratic fine structure. The intraday\nspread of individual stocks relaxes as a power law within the first hour of the\ncontinuous double auction from 9:30AM to 10:30AM with exponents\n$\\beta_{\\rm{SHSE}}=0.19\\pm0.069$ for the Shanghai market and\n$\\beta_{\\rm{SZSE}}=0.18\\pm0.067$ for the Shenzhen market. The power-law\nrelaxation exponent $\\beta$ of individual stocks is roughly normally\ndistributed. There is evidence showing that the accumulation of information\nwidening the spread is an endogenous process. \n\n"}
{"id": "0710.2507", "contents": "Title: Stochastic suspensions of heavy particles Abstract: Turbulent suspensions of heavy particles in incompressible flows have gained\nmuch attention in recent years. A large amount of work focused on the impact\nthat the inertia and the dissipative dynamics of the particles have on their\ndynamical and statistical properties. Substantial progress followed from the\nstudy of suspensions in model flows which, although much simpler, reproduce\nmost of the important mechanisms observed in real turbulence. This paper\npresents recent developments made on the relative motion of a pair of particles\nsuspended in time-uncorrelated and spatially self-similar Gaussian flows. This\nreview is complemented by new results. By introducing a time-dependent Stokes\nnumber, it is demonstrated that inertial particle relative dispersion recovers\nasymptotically Richardson's diffusion associated to simple tracers. A\nperturbative (homogeneization) technique is used in the small-Stokes-number\nasymptotics and leads to interpreting first-order corrections to tracer\ndynamics in terms of an effective drift. This expansion implies that the\ncorrelation dimension deficit behaves linearly as a function of the Stokes\nnumber. The validity and the accuracy of this prediction is confirmed by\nnumerical simulations. \n\n"}
{"id": "0710.2992", "contents": "Title: Urban traffic from the perspective of dual graph Abstract: In this paper, urban traffic is modeled using dual graph representation of\nurban transportation network where roads are mapped to nodes and intersections\nare mapped to links. The proposed model considers both the navigation of\nvehicles on the network and the motion of vehicles along roads. The road's\ncapacity and the vehicle-turning ability at intersections are naturally\nincorporated in the model. The overall capacity of the system can be quantified\nby a phase transition from free flow to congestion. Simulation results show\nthat the system's capacity depends greatly on the topology of transportation\nnetworks. In general, a well-planned grid can hold more vehicles and its\noverall capacity is much larger than that of a growing scale-free network. \n\n"}
{"id": "0710.3058", "contents": "Title: Taxonomy and clustering in collaborative systems: the case of the\n  on-line encyclopedia Wikipedia Abstract: In this paper we investigate the nature and structure of the relation between\nimposed classifications and real clustering in a particular case of a\nscale-free network given by the on-line encyclopedia Wikipedia. We find a\nstatistical similarity in the distributions of community sizes both by using\nthe top-down approach of the categories division present in the archive and in\nthe bottom-up procedure of community detection given by an algorithm based on\nthe spectral properties of the graph. Regardless the statistically similar\nbehaviour the two methods provide a rather different division of the articles,\nthereby signaling that the nature and presence of power laws is a general\nfeature for these systems and cannot be used as a benchmark to evaluate the\nsuitability of a clustering method. \n\n"}
{"id": "0710.3566", "contents": "Title: Markov Chain Methods For Analyzing Complex Transport Networks Abstract: We have developed a steady state theory of complex transport networks used to\nmodel the flow of commodity, information, viruses, opinions, or traffic. Our\napproach is based on the use of the Markov chains defined on the graph\nrepresentations of transport networks allowing for the effective network\ndesign, network performance evaluation, embedding, partitioning, and network\nfault tolerance analysis. Random walks embed graphs into Euclidean space in\nwhich distances and angles acquire a clear statistical interpretation. Being\ndefined on the dual graph representations of transport networks random walks\ndescribe the equilibrium configurations of not random commodity flows on\nprimary graphs. This theory unifies many network concepts into one framework\nand can also be elegantly extended to describe networks represented by directed\ngraphs and multiple interacting networks. \n\n"}
{"id": "0710.5441", "contents": "Title: Community Detecting By Signaling on Complex Networks Abstract: Based on signaling process on complex networks, a method for identification\ncommunity structure is proposed. For a network with $n$ nodes, every node is\nassumed to be a system which can send, receive, and record signals. Each node\nis taken as the initial signal source once to inspire the whole network by\nexciting its neighbors and then the source node is endowed a $n$d vector which\nrecording the effects of signaling process. So by this process, the topological\nrelationship of nodes on networks could be transferred into the geometrical\nstructure of vectors in $n$d Euclidian space. Then the best partition of groups\nis determined by $F$-statistic and the final community structure is given by\nFuzzy $C$-means clustering method (FCM). This method can detect community\nstructure both in unweighted and weighted networks without any extra\nparameters. It has been applied to ad hoc networks and some real networks\nincluding Zachary Karate Club network and football team network. The results\nare compared with that of other approaches and the evidence indicates that the\nalgorithm based on signaling process is effective. \n\n"}
{"id": "0710.5678", "contents": "Title: The Universality of Dynamic Multiscaling in Homogeneous, Isotropic\n  Turbulence Abstract: We systematise the study of dynamic multiscaling of time-dependent structure\nfunctions in different models of passive-scalar and fluid turbulence. We show\nthat, by suitably normalising these structure functions, we can eliminate their\ndependence on the origin of time at which we start our measurements and that\nthese normalised structure functions yield the same linear bridge relations\nthat relate the dynamic-multiscaling and equal-time exponents for statistically\nsteady turbulence. We show analytically, for both the Kraichnan Model of\npassive-scalar turbulence and its shell model analogue, and numerically, for\nthe GOY shell model of fluid turbulence and a shell model for passive-scalar\nturbulence, that these exponents and bridge relations are the same for\nstatistically steady and decaying turbulence. Thus we provide strong evidence\nfor dynamic universality, i.e., dynamic-multiscaling exponents do not depend on\nwhether the turbulence decays or is statistically steady. \n\n"}
{"id": "0711.0491", "contents": "Title: Community Detection in Complex Networks Using Genetic Algorithms Abstract: Community detection is an important research topic in complex networks. We\npresent the employment of a genetic algorithm to detect communities in complex\nnetworks which is based on optimizing network modularity. It does not need any\nprior knowledge about the number of communities. Its performance is tested on\ntwo real life networks with known community structures and a set of synthetic\nnetworks. As the performance measure an information theoretical metric\nvariation of information is used. The results are promising and in some cases\nbetter than previously reported studies. \n\n"}
{"id": "0711.1639", "contents": "Title: The Kolkata Paise Restaurant Problem and Resource Utilization Abstract: We study the dynamics of the \"Kolkata Paise Restaurant problem\". The problem\nis the following: In each period, N agents have to choose between N\nrestaurants. Agents have a common ranking of the restaurants. Restaurants can\nonly serve one customer. When more than one customer arrives at the same\nrestaurant, one customer is chosen at random and is served; the others do not\nget the service. We first introduce the one-shot versions of the Kolkata Paise\nRestaurant problem which we call one-shot KPR games. We then study the dynamics\nof the Kolkata Paise Restaurant problem (which is a repeated game version of\nany given one shot KPR game) for large N. For statistical analysis, we explore\nthe long time steady state behavior. In many such models with myopic agents we\nget under-utilization of resources, that is, we get a lower aggregate payoff\ncompared to the social optimum. We study a number of myopic strategies,\nfocusing on the average occupation fraction of restaurants. \n\n"}
{"id": "0711.2314", "contents": "Title: Finite size effects and symmetry breaking in the evolution of networks\n  of competing Boolean nodes Abstract: The effects of the finite size of the network on the evolutionary dynamics of\na Boolean network are analyzed. In the model considered, Boolean networks\nevolve via a competition between nodes that punishes those in the majority. It\nis found that finite size networks evolve in a fundamentally different way than\ninfinitely large networks do. The symmetry of the evolutionary dynamics of\ninfinitely large networks that selects for canalizing Boolean functions is\nbroken in the evolutionary dynamics of finite size networks. In finite size\nnetworks there is an additional selection for input inverting Boolean functions\nthat output a value opposite to the majority of input values. These results are\nrevealed through an empirical study of the model that calculates the frequency\nof occurrence of the different possible Boolean functions. Classes of functions\nare found to occur with the same frequency. Those classes depend on the\nsymmetry of the evolutionary dynamics and correspond to orbits of the relevant\nsymmetry group. The empirical results match analytic results, determined by\nutilizing Polya's theorem, for the number of orbits expected in both finite\nsize and infinitely large networks. The reason for the symmetry breaking in the\nevolutionary dynamics is found to be due to the need for nodes in finite size\nnetworks to behave differently in order to cooperate so that the system\ncollectively performs as well as possible. The results suggest that both finite\nsize effects and symmetry are important for understanding the evolution of\nreal-world complex networks, including genetic regulatory networks. \n\n"}
{"id": "0711.2431", "contents": "Title: Identification of photon-tagged jets in the ALICE experiment Abstract: The ALICE experiment at LHC will detect and identify prompt photons and light\nneutral-mesons with the PHOS detector and the additional EMCal electromagnetic\ncalorimeter. Charged particles will be detected and identified by the central\ntracking system. In this article, the possibility of studying the interaction\nof jets with the nuclear medium, using prompt photons as a tool to tag jets, is\ninvestigated by simulations. New methods to identify prompt photon-jet events\nand to distinguish them from the jet-jet background are presented. \n\n"}
{"id": "0712.0083", "contents": "Title: Smearing Distributions and their use in Financial Markets Abstract: It is shown that superpositions of path integrals with arbitrary Hamiltonians\nand different scaling parameters v (\"variances\") obey the Chapman-Kolmogorov\nrelation for Markovian processes if and only if the corresponding smearing\ndistributions for v have a specific functional form. Ensuing \"smearing\"\ndistributions substantially simplify the coupled system of Fokker-Planck\nequations for smeared and un-smeared conditional probabilities. Simple\napplication in financial models with stochastic volatility is presented. \n\n"}
{"id": "0712.2684", "contents": "Title: An Economic Model of Coupled Exponential Maps Abstract: In this work, an ensemble of economic interacting agents is considered. The\nagents are arranged in a linear array where only local couplings are allowed.\nThe deterministic dynamics of each agent is given by a map. This map is\nexpressed by two factors. The first one is a linear term that models the\nexpansion of the agent's economy and that is controlled by the {\\it growth\ncapacity parameter}. The second one is an inhibition exponential term that is\nregulated by the {\\it local environmental pressure}. Depending on the parameter\nsetting, the system can display Pareto or Boltzmann-Gibbs behavior in the\nasymptotic dynamical regime. The regions of parameter space where the system\nexhibits one of these two statistical behaviors are delimited. Other properties\nof the system, such as the mean wealth, the standard deviation and the Gini\ncoefficient, are also calculated. \n\n"}
{"id": "0712.3137", "contents": "Title: Phase transition and computational complexity in a stochastic prime\n  number generator Abstract: We introduce a prime number generator in the form of a stochastic algorithm.\nThe character of such algorithm gives rise to a continuous phase transition\nwhich distinguishes a phase where the algorithm is able to reduce the whole\nsystem of numbers into primes and a phase where the system reaches a frozen\nstate with low prime density. In this paper we firstly pretend to give a broad\ncharacterization of this phase transition, both in terms of analytical and\nnumerical analysis. Critical exponents are calculated, and data collapse is\nprovided. Further on we redefine the model as a search problem, fitting it in\nthe hallmark of computational complexity theory. We suggest that the system\nbelongs to the class NP. The computational cost is maximal around the\nthreshold, as common in many algorithmic phase transitions, revealing the\npresence of an easy-hard-easy pattern. We finally relate the nature of the\nphase transition to an average-case classification of the problem. \n\n"}
{"id": "0802.2810", "contents": "Title: Why Does Zipf's Law Break Down in Rank-Size Distribution of Cities? Abstract: We study rank-size distribution of cities in Japan on the basis of data\nanalysis. From the census data after World War II, we find that the rank-size\ndistribution of cities is composed of two parts, each of which has independent\npower exponent. In addition, the power exponent of the head part of the\ndistribution changes in time and Zipf's law holds only in a restricted period.\nWe show that Zipf's law broke down due to both of Showa and Heisei great\nmergers and recovered due to population growth in middle-sized cities after the\ngreat Showa merger. \n\n"}
{"id": "0803.0057", "contents": "Title: Cross-correlations in Warsaw Stock Exchange Abstract: We study the inter-stock correlations for the largest companies listed on\nWarsaw Stock Exchange and included in the WIG20 index. Our results from the\ncorrelation matrix analysis indicate that the Polish stock market can be well\ndescribed by a one factor model. We also show that the stock-stock correlations\ntend to increase with the time scale of returns and they approach a saturation\nlevel for the time scales of at least 200 min, i.e. an order of magnitude\nlonger than in the case of some developed markets. We also show that the\nstrength of correlations among the stocks crucially depends on their\ncapitalization. These results combined with our earlier findings together\nsuggest that now the Polish stock market situates itself somewhere between an\nemerging market phase and a mature market phase. \n\n"}
{"id": "0803.1051", "contents": "Title: Conformal Invariance of Iso-height Lines in two-dimensional KPZ Surface Abstract: The statistics of the iso-height lines in (2+1)-dimensional\nKardar-Parisi-Zhang (KPZ) model is shown to be conformal invariant and\nequivalent to those of self-avoiding random walks. This leads to a rich variety\nof new exact analytical results for the KPZ dynamics. We present direct\nevidence that the iso-height lines can be described by the family of conformal\ninvariant curves called Schramm-Loewner evolution (or $SLE_\\kappa$) with\ndiffusivity $\\kappa=8/3$. It is shown that the absence of the non-linear term\nin the KPZ equation will change the diffusivity $\\kappa$ from 8/3 to 4,\nindicating that the iso-height lines of the Edwards-Wilkinson (EW) surface are\nalso conformally invariant, and belong to the universality class of the domain\nwalls in the O(2) spin model. \n\n"}
{"id": "0803.1145", "contents": "Title: Enrico Fermi and the Physics and Engineering of a nuclear pile: the\n  retrieval of novel documents Abstract: We give a detailed account of the recent retrieval of a consistent amount\n(about 600 pages) of documents written by Enrico Fermi and/or his\ncollaborators, coming from different sources previously unexplored. These\ndocuments include articles, patents, reports, notes on scientific and technical\nmeetings and other papers, mainly testifying Fermi's activity in the 1940s\nabout nuclear pile physics and engineering. All of them have been carefully\ndescribed, pointing out the relevance of the given papers for their scientific\nor even historical content. From the analysis of these papers, a number of\nimportant scientific and technical points comes out, putting a truly new light\non the Fermi's (and others') scientific activity about nuclear piles and their\napplications. Quite unexpectedly intriguing historical remarks, such as those\nregarding the relationships between U.S. and Britain, just after the end of the\nwar, about nuclear power for pacific and/or military use, or even regarding\nlong term physics research and post-war research policy, emerge as well. \n\n"}
{"id": "0803.2510", "contents": "Title: The Web of Connections between Tourism Companies in Elba: Structure and\n  Dynamics Abstract: Tourism destination networks are amongst the most complex dynamical systems,\ninvolving a myriad of human-made and natural resources. In this work we report\na complex network-based systematic analysis of the Elba (Italy) tourism\ndestination network, including the characterization of its structure in terms\nof a set of several traditional measurements, the investigation of its\nmodularity, as well as its comprehensive study in terms of the recently\nreported superedges approach. In particular, structural (the number of paths of\ndistinct lengths between pairs of nodes, as well as the number of reachable\ncompanies) and dynamical features (transition probabilities and the\ninward/outward activations and accessibilities) are measured and analyzed,\nleading to a series of important findings related to the interactions between\ntourism companies. Among the several reported results, it is shown that the\ntype and size of the companies influence strongly their respective activations\nand accessibilities, while their geographical position does not seem to matter.\nIt is also shown that the Elba tourism network is largely fragmented and\nheterogeneous, so that it could benefit from increased integration. \n\n"}
{"id": "0803.2548", "contents": "Title: Local resolution-limit-free Potts model for community detection Abstract: We report on an exceptionally accurate spin-glass-type Potts model for\ncommunity detection. With a simple algorithm, we find that our approach is at\nleast as accurate as the best currently available algorithms and robust to the\neffects of noise. It is also competitive with the best currently available\nalgorithms in terms of speed and size of solvable systems. We find that the\ncomputational demand often exhibits superlinear scaling L^1.3 where L is the\nnumber of edges in the system, and we have applied the algorithm to synthetic\nsystems as large as 40x10^6 nodes and over 1x10^9 edges. A previous stumbling\nblock encountered by popular community detection methods is the so-called\n\"resolution limit.\" Being a \"local\" measure of community structure, our Potts\nmodel is free from this resolution-limit effect, and it further remains a local\nmeasure on weighted and directed graphs. We also address the mitigation of\nresolution-limit effects for two other popular Potts models. \n\n"}
{"id": "0803.3422", "contents": "Title: Organization of modular networks Abstract: We examine the global organization of heterogeneous equilibrium networks\nconsisting of a number of well distinguished interconnected\nparts--``communities'' or modules. We develop an analytical approach allowing\nus to obtain the statistics of connected components and an intervertex distance\ndistribution in these modular networks, and to describe their global\norganization and structure. In particular, we study the evolution of the\nintervertex distance distribution with an increasing number of interlinks\nconnecting two infinitely large uncorrelated networks. We demonstrate that even\na relatively small number of shortcuts unite the networks into one. In more\nprecise terms, if the number of the interlinks is any finite fraction of the\ntotal number of connections, then the intervertex distance distribution\napproaches a delta-function peaked form, and so the network is united. \n\n"}
{"id": "0803.4091", "contents": "Title: Coevolution of teaching activity promotes cooperation Abstract: Evolutionary games are studied where the teaching activity of players can\nevolve in time. Initially all players following either the cooperative or\ndefecting strategy are distributed on a square lattice. The rate of strategy\nadoption is determined by the payoff difference and a teaching activity\ncharacterizing the donor's capability to enforce its strategy on the opponent.\nEach successful strategy adoption process is accompanied with an increase in\nthe donor's teaching activity. By applying an optimum value of the increment\nthis simple mechanism spontaneously creates relevant inhomogeneities in the\nteaching activities that support the maintenance of cooperation for both the\nprisoner's dilemma and the snowdrift game. \n\n"}
{"id": "0804.2231", "contents": "Title: Random changes of flow topology in two dimensional and geophysical\n  turbulence Abstract: We study the two dimensional (2D) stochastic Navier Stokes (SNS) equations in\nthe inertial limit of weak forcing and dissipation. The stationary measure is\nconcentrated close to steady solutions of the 2D Euler equation. For such\ninertial flows, we prove that bifurcations in the flow topology occur either by\nchanging the domain shape, the nonlinearity of the vorticity-stream function\nrelation, or the energy. Associated to this, we observe in SNS bistable\nbehavior with random changes from dipoles to unidirectional flows. The\ntheoretical explanation being very general, we infer the existence of similar\nphenomena in experiments and in models of geophysical flows. \n\n"}
{"id": "0804.2442", "contents": "Title: Scaling and allometry in the building geometries of Greater London Abstract: Many aggregate distributions of urban activities such as city sizes reveal\nscaling but hardly any work exists on the properties of spatial distributions\nwithin individual cities, notwithstanding considerable knowledge about their\nfractal structure. We redress this here by examining scaling relationships in a\nworld city using data on the geometric properties of individual buildings. We\nfirst summarise how power laws can be used to approximate the size\ndistributions of buildings, in analogy to city-size distributions which have\nbeen widely studied as rank-size and lognormal distributions following Zipf and\nGibrat. We then extend this analysis to allometric relationships between\nbuildings in terms of their different geometric size properties. We present\nsome preliminary analysis of building heights from the Emporis database which\nsuggests very strong scaling in world cities. The data base for Greater London\nis then introduced from which we extract 3.6 million buildings whose scaling\nproperties we explore. We examine key allometric relationships between these\ndifferent properties illustrating how building shape changes according to size,\nand we extend this analysis to the classification of buildings according to\nland use types. We conclude with an analysis of two-point correlation functions\nof building geometries which supports our non-spatial analysis of scaling. \n\n"}
{"id": "0804.3068", "contents": "Title: From Deterministic Chaos to Anomalous Diffusion Abstract: This is an easy-to-read introduction to foundations of deterministic chaos,\ndeterministic diffusion and anomalous diffusion. The first part introduces to\ndeterministic chaos in one-dimensional maps in form of Ljapunov exponents and\ndynamical entropies. The second part outlines the concept of deterministic\ndiffusion. Then the escape rate formalism for deterministic diffusion, which\nexpresses the diffusion coefficient in terms of the above two chaos quantities,\nis worked out for a simple map. Part three explains basics of anomalous\ndiffusion by demonstrating the stochastic approach of continuous time random\nwalk theory for an intermittent map. As an example of experimental\napplications, the anomalous dynamics of biological cell migration is discussed. \n\n"}
{"id": "0804.3793", "contents": "Title: Exact Statistics of Chaotic Dynamical Systems Abstract: We present an inverse method to construct large classes of chaotic invariant\nsets together with their exact statistics. The associated dynamical systems are\ncharacterized by a probability distribution and a two-form. While our emphasis\nis on classical systems, we briefly speculate about possible applications to\nquantum field theory, in the context of generalizations of stochastic\nquantization. \n\n"}
{"id": "0804.3853", "contents": "Title: Modelling coloured residual noise in gravitational-wave signal\n  processing Abstract: We introduce a signal processing model for signals in non-white noise, where\nthe exact noise spectrum is a priori unknown. The model is based on a Student's\nt distribution and constitutes a natural generalization of the widely used\nnormal (Gaussian) model. This way, it allows for uncertainty in the noise\nspectrum, or more generally is also able to accommodate outliers (heavy-tailed\nnoise) in the data. Examples are given pertaining to data from gravitational\nwave detectors. \n\n"}
{"id": "0805.0512", "contents": "Title: A comparative study of social network models: network evolution models\n  and nodal attribute models Abstract: This paper reviews, classifies and compares recent models for social networks\nthat have mainly been published within the physics-oriented complex networks\nliterature. The models fall into two categories: those in which the addition of\nnew links is dependent on the (typically local) network structure (network\nevolution models, NEMs), and those in which links are generated based only on\nnodal attributes (nodal attribute models, NAMs). An exponential random graph\nmodel (ERGM) with structural dependencies is included for comparison. We fit\nmodels from each of these categories to two empirical acquaintance networks\nwith respect to basic network properties. We compare higher order structures in\nthe resulting networks with those in the data, with the aim of determining\nwhich models produce the most realistic network structure with respect to\ndegree distributions, assortativity, clustering spectra, geodesic path\ndistributions, and community structure (subgroups with dense internal\nconnections). We find that the nodal attribute models successfully produce\nassortative networks and very clear community structure. However, they generate\nunrealistic clustering spectra and peaked degree distributions that do not\nmatch empirical data on large social networks. On the other hand, many of the\nnetwork evolution models produce degree distributions and clustering spectra\nthat agree more closely with data. They also generate assortative networks and\ncommunity structure, although often not to the same extent as in the data. The\nERG model turns out to produce the weakest community structure. \n\n"}
{"id": "0805.1564", "contents": "Title: Crossing intervals of non-Markovian Gaussian processes Abstract: We review the properties of time intervals between the crossings at a level M\nof a smooth stationary Gaussian temporal signal. The distribution of these\nintervals and the persistence are derived within the Independent Interval\nApproximation (IIA). These results grant access to the distribution of extrema\nof a general Gaussian process. Exact results are obtained for the persistence\nexponents and the crossing interval distributions, in the limit of large |M|.\nIn addition, the small time behavior of the interval distributions and the\npersistence is calculated analytically, for any M. The IIA is found to\nreproduce most of these exact results and its accuracy is also illustrated by\nextensive numerical simulations applied to non-Markovian Gaussian processes\nappearing in various physical contexts. \n\n"}
{"id": "0805.2689", "contents": "Title: Bayesian approach to clustering real value, categorical and network\n  data: solution via variational methods Abstract: Data clustering, including problems such as finding network communities, can\nbe put into a systematic framework by means of a Bayesian approach. The\napplication of Bayesian approaches to real problems can be, however, quite\nchallenging. In most cases the solution is explored via Monte Carlo sampling or\nvariational methods. Here we work further on the application of variational\nmethods to clustering problems. We introduce generative models based on a\nhidden group structure and prior distributions. We extend previous attends by\nJaynes, and derive the prior distributions based on symmetry arguments. As a\ncase study we address the problems of two-sides clustering real value data and\nclustering data represented by a hypergraph or bipartite graph. From the\nvariational calculations, and depending on the starting statistical model for\nthe data, we derive a variational Bayes algorithm, a generalized version of the\nexpectation maximization algorithm with a built in penalization for model\ncomplexity or bias. We demonstrate the good performance of the variational\nBayes algorithm using test examples. \n\n"}
{"id": "0805.3400", "contents": "Title: Derivation of Non-Local Macroscopic Traffic Equations and Consistent\n  Traffic Pressures from Microscopic Car-Following Models Abstract: This contribution compares several different approaches allowing one to\nderive macroscopic traffic equation directly from microscopic car-following\nmodels. While it is shown that some conventional approaches lead to theoretical\nproblems, it is proposed to use a smooth particle hydrodynamic approach and to\navoid gradient expansions. The derivation circumvents approximations and,\ntherefore, demonstrates the large range of validity of macroscopic traffic\nequations, without the need of averaging over many vehicles. It also gives an\nexpression for the ``traffic pressure'', which generalizes previously used\nformulas. Furthermore, the method avoids theoretical inconsistencies of\nmacroscopic traffic models, which have been criticized in the past by Daganzo\nand others. \n\n"}
{"id": "0806.0472", "contents": "Title: Empirical analysis of the worldwide maritime transportation network Abstract: In this paper we present an empirical study of the worldwide maritime\ntransportation network (WMN) in which the nodes are ports and links are\ncontainer liners connecting the ports. Using the different representation of\nnetwork topology namely the space $L$ and $P$, we study the statistical\nproperties of WMN including degree distribution, degree correlations, weight\ndistribution, strength distribution, average shortest path length, line length\ndistribution and centrality measures. We find that WMN is a small-world network\nwith power law behavior. Important nodes are identified based on different\ncentrality measures. Through analyzing weighted cluster coefficient and\nweighted average nearest neighbors degree, we reveal the hierarchy structure\nand \"rich-club\" phenomenon in the network. \n\n"}
{"id": "0806.1625", "contents": "Title: Computable bounds for the discrimination of Gaussian states Abstract: By combining the Minkowski inequality and the quantum Chernoff bound, we\nderive easy-to-compute upper bounds for the error probability affecting the\noptimal discrimination of Gaussian states. In particular, these bounds are\nuseful when the Gaussian states are unitarily inequivalent, i.e., they differ\nin their symplectic invariants. \n\n"}
{"id": "0806.2885", "contents": "Title: Testing long-term earthquake forecasts: likelihood methods and error\n  diagrams Abstract: We propose a new method to test the effectiveness of a spatial point process\nforecast based on a log-likelihood score for predicted point density and the\ninformation gain for events that actually occurred in the test period. The\nmethod largely avoids simulation use and allows us to calculate the information\nscore for each event or set of events as well as the standard error of each\nforecast. As the number of predicted events increases, the score distribution\napproaches the Gaussian law. The degree of its similarity to the Gaussian\ndistribution can be measured by the computed coefficients of skewness and\nkurtosis. To display the forecasted point density and the point events, we use\nan event concentration diagram or a variant of the Error Diagram (ED).\n  We demonstrate the application of the method by using our long-term forecast\nof seismicity in two western Pacific regions. We compare the ED for these\nregions with simplified diagrams based on two-segment approximations. Since the\nearthquakes in these regions are concentrated in narrow subduction belts, using\nthe forecast density as a template or baseline for the ED is a more convenient\ndisplay technique. We also show, using simulated event occurrence, that some\nproposed criteria for measuring forecast effectiveness at EDs would be strongly\nbiased for a small event number. \n\n"}
{"id": "0807.0015", "contents": "Title: An Ad-Hoc Method for Obtaining chi**2 Values from Unbinned Maximum\n  Likelihood Fits Abstract: A common goal in an experimental physics analysis is to extract information\nfrom a reaction with multi-dimensional kinematics. The preferred method for\nsuch a task is typically the unbinned maximum likelihood method. In fits using\nthis method, the likelihood is a goodness-of-fit quantity in that it\neffectively discriminates between available hypotheses; however, it does not\nprovide any information as to how well the best hypothesis describes the data.\n  In this paper, we present an {\\em ad-hoc} procedure for obtaining\nchi**2/n.d.f. values from unbinned maximum likelihood fits. This method does\nnot require binning the data, making it very applicable to multi-dimensional\nproblems. \n\n"}
{"id": "0807.1705", "contents": "Title: Universal, Continuous-Discrete Nonlinear Yau Filtering I: Affine, Linear\n  State Model with State-Independent Diffusion Matrix Abstract: The continuous-discrete filtering problem requires the solution of a partial\ndifferential equation known as the Fokker-Planck-Kolmogorov forward equation\n(FPKfe). In this paper, it is pointed out that for a state model with an\naffine, linear drift and state-independent diffusion matrix the fundamental\nsolution can be obtained using only linear algebra techniques. In particular,\nno differential equations need to be solved. Furthermore, there are no\nrestrictions on the size of the time step size, or on the measurement model.\nAlso discussed are important computational aspects that are crucial for\npotential real-time implementation for higher-dimensional problems. The\nsolution is universal in the sense that the initial distribution may be\narbitrary. \n\n"}
{"id": "0807.1984", "contents": "Title: Nonequilibrium phase transition due to social group isolation Abstract: We introduce a simple model of a growing system with $m$ competing\ncommunities. The model corresponds to the phenomenon of defeats suffered by\nsocial groups living in isolation. A nonequilibrium phase transition is\nobserved when at critical time $t_c$ the first isolated cluster occurs. In the\none-dimensional system the volume of the new phase, i.e. the number of the\nisolated individuals, increases with time as $Z \\sim t^3$. For a large number\nof possible communities the critical density of filled space equals to $\\rho_c\n= (m/N)^{1/3}$ where $N$ is the system size. A similar transition is observed\nfor Erd\\H{o}s-R\\'{e}nyi random graphs and Barab\\'{a}si-Albert scale-free\nnetworks. Analytic results are in agreement with numerical simulations. \n\n"}
{"id": "0807.2149", "contents": "Title: A Test for the Presence of a Signal, with Multiple Channels and Marked\n  Poisson Abstract: We describe a statistical hypothesis test for the presence of a signal based\non the likelihood ratio statistic. We derive the test for a special case of\ninterest. We study extensions of the test to cases where there are multiple\nchannels and to marked Poisson distributions. We show the results of a number\nof performance studies which indicate that the test works very well, even far\nout in the tails of the distribution and with multiple channels and marked\nPoisson. \n\n"}
{"id": "0807.4052", "contents": "Title: Modularity clustering is force-directed layout Abstract: Two natural and widely used representations for the community structure of\nnetworks are clusterings, which partition the vertex set into disjoint subsets,\nand layouts, which assign the vertices to positions in a metric space. This\npaper unifies prominent characterizations of layout quality and clustering\nquality, by showing that energy models of pairwise attraction and repulsion\nsubsume Newman and Girvan's modularity measure. Layouts with optimal energy are\nrelaxations of, and are thus consistent with, clusterings with optimal\nmodularity, which is of practical relevance because both representations are\ncomplementary and often used together. \n\n"}
{"id": "0807.5073", "contents": "Title: Hyperbolicity and the effective dimension of spatially-extended\n  dissipative systems Abstract: We show, using covariant Lyapunov vectors, that the chaotic solutions of\nspatially extended dissipative systems evolve within a manifold spanned by a\nfinite number of physical modes hyperbolically isolated from a set of residual\ndegrees of freedom, themselves individually isolated from each other. In the\ncontext of dissipative partial differential equations, our results imply that a\nfaithful numerical integration needs to incorporate at least all physical modes\nand that increasing the resolution merely increases the number of isolated\nmodes. \n\n"}
{"id": "0808.0032", "contents": "Title: Relating the microscopic rules in coalescence-fragmentation models to\n  the macroscopic cluster size distributions which emerge Abstract: Coalescence-fragmentation problems are of great interest across the physical,\nbiological, and recently social sciences. They are typically studied from the\nperspective of the rate equations, at the heart of such models are the rules\nused for coalescence and fragmentation. Here we discuss how changes in these\nmicroscopic rules affect the macroscopic cluster-size distribution which\nemerges from the solution to the rate equation. More generally, our work\nelucidates the crucial role that the fragmentation rule can play in such\ndynamical grouping models. We focus on two well-known models whose\nfragmentation rules lie at opposite extremes setting the models within the\nbroader context of binary coalescence-fragmentation models. Further, we provide\na range of generalizations and new analytic results for a well-known model of\nsocial group formation [V. M. Eguiluz and M. G. Zimmermann, Phys. Rev. Lett.\n85, 5659 (2000)]. We develop analytic perturbation treatment of the original\nmodel, and extend the mathematical to the treatment of growing and declining\npopulations. \n\n"}
{"id": "0808.1612", "contents": "Title: Detecting groups of similar components in complex networks Abstract: We study how to detect groups in a complex network each of which consists of\ncomponent nodes sharing a similar connection pattern. Based on the mixture\nmodels and the exploratory analysis set up by Newman and Leicht (Newman and\nLeicht 2007 {\\it Proc. Natl. Acad. Sci. USA} {\\bf 104} 9564), we develop an\nalgorithm that is applicable to a network with any degree distribution. The\npartition of a network suggested by this algorithm also applies to its\ncomplementary network. In general, groups of similar components are not\nnecessarily identical with the communities in a community network; thus\npartitioning a network into groups of similar components provides additional\ninformation of the network structure. The proposed algorithm can also be used\nfor community detection when the groups and the communities overlap. By\nintroducing a tunable parameter that controls the involved effects of the\nheterogeneity, we can also investigate conveniently how the group structure can\nbe coupled with the heterogeneity characteristics. In particular, an\ninteresting example shows a group partition can evolve into a community\npartition in some situations when the involved heterogeneity effects are tuned.\nThe extension of this algorithm to weighted networks is discussed as well. \n\n"}
{"id": "0808.2195", "contents": "Title: Scaling of degree correlations and the influence on diffusion in\n  scale-free networks Abstract: Connectivity correlations play an important role in the structure of\nscale-free networks. While several empirical studies exist, there is no general\ntheoretical analysis that can explain the largely varying behavior of real\nnetworks. Here, we use scaling theory to quantify the degree of correlations in\nthe particular case of networks with a power-law degree distribution. These\nnetworks are classified in terms of their correlation properties, revealing\nadditional information on their structure. For instance, the studied social\nnetworks and the Internet at the router level are clustered around the line of\nrandom networks, implying a strongly connected core of hubs. On the contrary,\nsome biological networks and the WWW exhibit strong anti-correlations. The\npresent approach can be used to study robustness or diffusion, where we find\nthat anti-correlations tend to accelerate the diffusion process. \n\n"}
{"id": "0808.2793", "contents": "Title: The Weibull - log Weibull transition of interoccurrence times for\n  synthetic and natural earthquakes Abstract: We have studied interoccurrence time distributions by analyzing the synthetic\nand three natural catalogs of the Japan Meteorological Agency (JMA), the\nSouthern California Earthquake Data Center (SCEDC), and Taiwan Central Weather\nBureau (TCWB) and revealed the universal feature of the interoccurrence time\nstatistics, Weibull - log Weibull transition. This transition reinforces the\nview that the interoccurrence time statistics possess Weibull statistics and\nlog-Weibull statistics. Here in this paper, the crossover magnitude from the\nsuperposition regime to the Weibull regime $m_c^2$ is proportional to the plate\nvelocity. In addition, we have found the region-independent relation,\n$m_c^2/m_{max} = 0.54 \\pm 0.004$. \n\n"}
{"id": "0808.3643", "contents": "Title: Bayesian Methods for Parameter Estimation in Effective Field Theories Abstract: We demonstrate and explicate Bayesian methods for fitting the parameters that\nencode the impact of short-distance physics on observables in effective field\ntheories (EFTs). We use Bayes' theorem together with the principle of maximum\nentropy to account for the prior information that these parameters should be\nnatural, i.e.O(1) in appropriate units. Marginalization can then be employed to\nintegrate the resulting probability density function (pdf) over the EFT\nparameters that are not of specific interest in the fit. We also explore\nmarginalization over the order of the EFT calculation, M, and over the\nvariable, R, that encodes the inherent ambiguity in the notion that these\nparameters are O(1). This results in a very general formula for the pdf of the\nEFT parameters of interest given a data set, D. We use this formula and the\nsimpler \"augmented chi-squared\" in a toy problem for which we generate\npseudo-data. These Bayesian methods, when used in combination with the\n\"naturalness prior\", facilitate reliable extractions of EFT parameters in cases\nwhere chi-squared methods are ambiguous at best. We also examine the problem of\nextracting the nucleon mass in the chiral limit, M_0, and the nucleon sigma\nterm, from pseudo-data on the nucleon mass as a function of the pion mass. We\nfind that Bayesian techniques can provide reliable information on M_0, even if\nsome of the data points used for the extraction lie outside the region of\napplicability of the EFT. \n\n"}
{"id": "0808.3661", "contents": "Title: Degree-distribution Stability of Growing Networks Abstract: In this paper, we abstract a kind of stochastic processes from evolving\nprocesses of growing networks, this process is called growing network Markov\nchains. Thus the existence and the formulas of degree distribution are\ntransformed to the corresponding problems of growing network Markov chains.\nFirst we investigate the growing network Markov chains, and obtain the\ncondition in which the steady degree distribution exists and get its exact\nformulas. Then we apply it to various growing networks. With this method, we\nget a rigorous, exact and unified solution of the steady degree distribution\nfor growing networks. \n\n"}
{"id": "0808.3785", "contents": "Title: Poincare recurrences and transient chaos in systems with leaks Abstract: In order to simulate observational and experimental situations, we consider a\nleak in the phase space of a chaotic dynamical system. We obtain an expression\nfor the escape rate of the survival probability applying the theory of\ntransient chaos. This expression improves previous estimates based on the\nproperties of the closed system and explains dependencies on the position and\nsize of the leak and on the initial ensemble. With a subtle choice of the\ninitial ensemble, we obtain an equivalence to the classical problem of Poincare\nrecurrences in closed systems, which is treated in the same framework. Finally,\nwe show how our results apply to weakly chaotic systems and justify a split of\nthe invariant saddle in hyperbolic and nonhyperbolic components, related,\nrespectively, to the intermediate exponential and asymptotic power-law decays\nof the survival probability. \n\n"}
{"id": "0809.0148", "contents": "Title: Remarks on Power Spectra of Chaotic Dynamical Systems Abstract: We develop novel methods to compute auto-correlation functions, or power\nspectral densities, for chaotic dynamical systems generated by an inverse\nmethod whose starting point is an invariant distribution and a two-form. In\ngeneral, the inverse method makes some aspects of chaotic dynamics calculable\nby methods familiar in quantum field theory. This approach has the numerical\nadvantage of being amenable to Monte-Carlo parallel computation. We demonstrate\nthe approach on a specific example, and show how auto-correlation functions can\nbe computed without any direct numerical simulation, by Pade approximants of a\nshort time expansion. \n\n"}
{"id": "0809.0939", "contents": "Title: Applications of Bayesian Probability Theory in Astrophysics Abstract: Bayesian Inference is a powerful approach to data analysis that is based\nalmost entirely on probability theory. In this approach, probabilities model\n{\\it uncertainty} rather than randomness or variability. This thesis is\ncomposed of a series of papers that have been published in various astronomical\njournals during the years 2005-2008. The unifying thread running through the\npapers is the use of Bayesian Inference to solve underdetermined inverse\nproblems in astrophysics. Firstly, a methodology is developed to solve a\nquestion in gravitational lens inversion - using the observed images of\ngravitational lens systems to reconstruct the undistorted source profile and\nthe mass profile of the lensing galaxy. A similar technique is also applied to\nthe task of inferring the number and frequency of modes of oscillation of a\nstar from the time series observations that are used in the field of\nasteroseismology. For these complex problems, many of the required calculations\ncannot be done analytically, and so Markov Chain Monte Carlo algorithms have\nbeen used. Finally, probabilistic reasoning is applied to a controversial\nquestion in astrobiology: does the fact that life formed quite soon after the\nEarth constitute evidence that the formation of life is quite probable, given\nthe right macroscopic conditions? \n\n"}
{"id": "0809.1289", "contents": "Title: Renormalization group in the infinite-dimensional turbulence:\n  third-order results Abstract: The field theoretic renormalization group is applied to the stochastic\nNavier-Stokes equation with the stirring force correlator of the form\nk^(4-d-2\\epsilon) in the d-dimensional space, in connection with the problem of\nconstruction of the 1/d expansion for the fully developed fluid turbulence\nbeyond the scope of the standard epsilon expansion. It is shown that in the\nlarge-d limit the number of the Feynman diagrams for the Green function (linear\nresponse function) decreases drastically, and the technique of their analytical\ncalculation is developed. The main ingredients of the renormalization group\napproach -- the renormalization constant, beta function and the ultraviolet\ncorrection exponent omega, are calculated to order epsilon^3 (three-loop\napproximation). The two-point velocity-velocity correlation function, the\nKolmogorov constant C_K in the spectrum of turbulent energy and the\ninertial-range skewness factor S are calculated in the large-d limit to third\norder of the epsilon expansion. Surprisingly enough, our results for C_K are in\na reasonable agreement with the existing experimental estimates. \n\n"}
{"id": "0809.2964", "contents": "Title: First echoes of relativity in Argentine astronomy Abstract: We consider the attitude of astronomers in Argentina in connection with the\nnew problems posed by relativity theory, before and after GR was presented. We\nbegin considering the sequence of \"technical\" publications that appeared and\nuse it to attempt to identify who were the relativity leaders and authors in\nthe Argentina scientific community of the 1910-1920s. Among them there are\nnatives of Argentina, permanent resident scientists, and occasional foreign\nvisitors. They are either academic scientists, or high school teachers; we\nleave aside the {\\it philosophers} and the {\\it aficionados}. We discuss the\nscientific facts and publications they handled, the modernity of their\ninformation and the \"language\" they use to transmit their ideas. Finally, we\nconsider astronomers proper; first Charles Perrine, an astronomer interested in\nastrophysics, contracted by the government of Argentina in the USA as director\nof its main observatory. He became interested in testing the possible\ndeflection of light rays by the Sun towards 1912; his Argentine expedition was\nthe first to attempt that test. Perhaps Perrine was not so much interested in\nrelativity as in testing the particular astronomical effects it predicted. In\nany case, he attempted the test with the acquiescence and financial support of\nthe Argentine state, and as a leading member of its official scientific elite.\nWe contrast his very specific and strictly scientific efforts with those of our\nsecond astronomer, Jos\\'e Ubach, SJ, a secondary school teacher of science at a\nleading Buenos Aires Catholic school who reported in response to Eddington's\nexpedition. Finally, our third astronomer is F\\'elix Aguilar, who made an\neffort to contribute to the public understanding of Einstein's theories in\n1924, when Einstein's visit to Argentina had become a certainty. [abridged] \n\n"}
{"id": "0810.0479", "contents": "Title: Mental States as Macrostates Emerging from EEG Dynamics Abstract: Correlations between psychological and physiological phenomena form the basis\nfor different medical and scientific disciplines, but the nature of this\nrelation has not yet been fully understood. One conceptual option is to\nunderstand the mental as \"emerging\" from neural processes in the specific sense\nthat psychology and physiology provide two different descriptions of the same\nsystem. Stating these descriptions in terms of coarser- and finer-grained\nsystem states (macro- and microstates), the two descriptions may be equally\nadequate if the coarse-graining preserves the possibility to obtain a dynamical\nrule for the system. To test the empirical viability of our approach, we\ndescribe an algorithm to obtain a specific form of such a coarse-graining from\ndata, and illustrate its operation using a simulated dynamical system. We then\napply the method to an electroencephalographic (EEG) recording, where we are\nable to identify macrostates from the physiological data that correspond to\nmental states of the subject. \n\n"}
{"id": "0810.1191", "contents": "Title: Spherical grand-canonical minority games with and without score\n  discounting Abstract: We present a spherical version of the grand-canonical minority game (GCMG),\nand solve its dynamics in the stationary state. The model displays several\ntypes of transitions between multiple ergodic phases and one non-ergodic phase.\nWe derive analytical solutions, including exact expressions for the volatility,\nthroughout all ergodic phases, and compute the phase behaviour of the system.\nIn contrast to conventional GCMGs, where the introduction of memory-loss\nprecludes analytical approaches, the spherical model can be solved also when\nexponential discounting is taken into account. For the case of homogeneous\nincentives to trade epsilon and memory loss rates rho, an efficient phase is\nfound only if rho=epsilon=0. Allowing for heterogeneous memory-loss rates we\nfind that efficiency can be achieved as long as there is any finite fraction of\nagents which is not subject to memory loss. \n\n"}
{"id": "0810.1355", "contents": "Title: Community Structure in Large Networks: Natural Cluster Sizes and the\n  Absence of Large Well-Defined Clusters Abstract: A large body of work has been devoted to defining and identifying clusters or\ncommunities in social and information networks. We explore from a novel\nperspective several questions related to identifying meaningful communities in\nlarge social and information networks, and we come to several striking\nconclusions. We employ approximation algorithms for the graph partitioning\nproblem to characterize as a function of size the statistical and structural\nproperties of partitions of graphs that could plausibly be interpreted as\ncommunities. In particular, we define the network community profile plot, which\ncharacterizes the \"best\" possible community--according to the conductance\nmeasure--over a wide range of size scales. We study over 100 large real-world\nsocial and information networks. Our results suggest a significantly more\nrefined picture of community structure in large networks than has been\nappreciated previously. In particular, we observe tight communities that are\nbarely connected to the rest of the network at very small size scales; and\ncommunities of larger size scales gradually \"blend into\" the expander-like core\nof the network and thus become less \"community-like.\" This behavior is not\nexplained, even at a qualitative level, by any of the commonly-used network\ngeneration models. Moreover, it is exactly the opposite of what one would\nexpect based on intuition from expander graphs, low-dimensional or\nmanifold-like graphs, and from small social networks that have served as\ntestbeds of community detection algorithms. We have found that a generative\ngraph model, in which new edges are added via an iterative \"forest fire\"\nburning process, is able to produce graphs exhibiting a network community\nprofile plot similar to what we observe in our network datasets. \n\n"}
{"id": "0810.2403", "contents": "Title: Competition and fragmentation: a simple model generating lognormal-like\n  distributions Abstract: The current distribution of language size in terms of speaker population is\ngenerally described using a lognormal distribution. Analyzing the original real\ndata we show how the double-Pareto lognormal distribution can give an\nalternative fit that indicates the existence of a power law tail. A simple\nMonte Carlo model is constructed based on the processes of competition and\nfragmentation. The results reproduce the power law tails of the real\ndistribution well and give better results for a poorly connected topology of\ninteractions. \n\n"}
{"id": "0810.4341", "contents": "Title: Entropy of Hidden Markov Processes via Cycle Expansion Abstract: Hidden Markov Processes (HMP) is one of the basic tools of the modern\nprobabilistic modeling. The characterization of their entropy remains however\nan open problem. Here the entropy of HMP is calculated via the cycle expansion\nof the zeta-function, a method adopted from the theory of dynamical systems.\nFor a class of HMP this method produces exact results both for the entropy and\nthe moment-generating function. The latter allows to estimate, via the Chernoff\nbound, the probabilities of large deviations for the HMP. More generally, the\nmethod offers a representation of the moment-generating function and of the\nentropy via convergent series. \n\n"}
{"id": "0810.5278", "contents": "Title: Power grids vulnerability: a complex network approach Abstract: Power grids exhibit patterns of reaction to outages similar to complex\nnetworks. Blackout sequences follow power laws, as complex systems operating\nnear a critical point. Here, the tolerance of electric power grids to both\naccidental and malicious outages is analyzed in the framework of complex\nnetwork theory. In particular, the quantity known as efficiency is modified by\nintroducing a new concept of distance between nodes. As a result, a new\nparameter called net-ability is proposed to evaluate the performance of power\ngrids. A comparison between efficiency and net-ability is provided by\nestimating the vulnerability of sample networks, in terms of both the metrics. \n\n"}
{"id": "0811.0499", "contents": "Title: Modeling Discrete Combinatorial Systems as Alphabetic Bipartite\n  Networks: Theory and Applications Abstract: Life and language are discrete combinatorial systems (DCSs) in which the\nbasic building blocks are finite sets of elementary units: nucleotides or\ncodons in a DNA sequence and letters or words in a language. Different\ncombinations of these finite units give rise to potentially infinite numbers of\ngenes or sentences. This type of DCS can be represented as an Alphabetic\nBipartite Network ($\\alpha$-BiN) where there are two kinds of nodes, one type\nrepresents the elementary units while the other type represents their\ncombinations. There is an edge between a node corresponding to an elementary\nunit $u$ and a node corresponding to a particular combination $v$ if $u$ is\npresent in $v$. Naturally, the partition consisting of the nodes representing\nelementary units is fixed, while the other partition is allowed to grow\nunboundedly. Here, we extend recently analytical findings for $\\alpha$-BiNs\nderived in [Peruani et al., Europhys. Lett. 79, 28001 (2007)] and empirically\ninvestigate two real world systems: the codon-gene network and the\nphoneme-language network. The evolution equations for $\\alpha$-BiNs under\ndifferent growth rules are derived, and the corresponding degree distributions\ncomputed. It is shown that asymptotically the degree distribution of\n$\\alpha$-BiNs can be described as a family of beta distributions. The one-mode\nprojections of the theoretical as well as the real world $\\alpha$-BiNs are also\nstudied. We propose a comparison of the real world degree distributions and our\ntheoretical predictions as a means for inferring the mechanisms underlying the\ngrowth of real world systems. \n\n"}
{"id": "0811.0881", "contents": "Title: Non-classical Role of Potential Energy in Adiabatic Quantum Annealing Abstract: Adiabatic quantum annealing is a paradigm of analog quantum computation,\nwhere a given computational job is converted to the task of finding the global\nminimum of some classical potential energy function and the search for the\nglobal potential minimum is performed by employing external kinetic quantum\nfluctuations and subsequent slow reduction (annealing) of them. In this method,\nthe entire potential energy landscape (PEL) may be accessed simultaneously\nthrough a delocalized wave-function, in contrast to a classical search, where\nthe searcher has to visit different points in the landscape (i.e., individual\nclassical configurations) sequentially. Thus in such searches, the role of the\npotential energy might be significantly different in the two cases. Here we\ndiscuss this in the context of searching of a single isolated hole (potential\nminimum) in a golf-course type gradient free PEL. We show, that the quantum\nparticle would be able to locate the hole faster if the hole is deeper, while\nthe classical particle of course would have no scope to exploit the depth of\nthe hole. We also discuss the effect of the underlying quantum phase transition\non the adiabatic dynamics. \n\n"}
{"id": "0811.3856", "contents": "Title: Levy flights, dynamical duality and fractional quantum mechanics Abstract: We discuss dual time evolution scenarios which, albeit running according to\nthe same real time clock, in each considered case may be mapped among each\nother by means of an analytic continuation in time. This dynamical duality is a\ngeneric feature of diffusion-type processes. Technically that involves a\nfamiliar transformation from a non-Hermitian Fokker-Planck operator to the\nHermitian operator (e.g. Schroedinger Hamiltonian), whose negative is known to\ngenerate a dynamical semigroup. Under suitable restrictions upon the generator,\nthe semigroup admits an analytic continuation in time and ultimately yields\ndual motions. We analyze an extension of the duality concept to Levy flights,\nfree and with an external forcing, while presuming that the corresponding\nevolution rule (fractional dynamical semigroup) is a dual counterpart of the\nquantum motion (fractional unitary dynamics). \n\n"}
{"id": "0811.4256", "contents": "Title: Mechanisms of Self-Organization and Finite Size Effects in a Minimal\n  Agent Based Model Abstract: We present a detailed analysis of the self-organization phenomenon in which\nthe stylized facts originate from finite size effects with respect to the\nnumber of agents considered and disappear in the limit of an infinite\npopulation. By introducing the possibility that agents can enter or leave the\nmarket depending on the behavior of the price, it is possible to show that the\nsystem self-organizes in a regime with a finite number of agents which\ncorresponds to the stylized facts. The mechanism to enter or leave the market\nis based on the idea that a too stable market is unappealing for traders while\nthe presence of price movements attracts agents to enter and speculate on the\nmarket. We show that this mechanism is also compatible with the idea that\nagents are scared by a noisy and risky market at shorter time scales. We also\nshow that the mechanism for self-organization is robust with respect to\nvariations of the exit/entry rules and that the attempt to trigger the system\nto self-organize in a region without stylized facts leads to an unrealistic\ndynamics. We study the self-organization in a specific agent based model but we\nbelieve that the basic ideas should be of general validity. \n\n"}
{"id": "0811.4749", "contents": "Title: Extremum complexity in the monodimensional ideal gas: the piecewise\n  uniform density distribution approximation Abstract: In this work, it is suggested that the extremum complexity distribution of a\nhigh dimensional dynamical system can be interpreted as a piecewise uniform\ndistribution in the phase space of its accessible states. When these\ndistributions are expressed as one--particle distribution functions, this leads\nto piecewise exponential functions. It seems plausible to use these\ndistributions in some systems out of equilibrium, thus greatly simplifying\ntheir description. In particular, here we study an isolated ideal\nmonodimensional gas far from equilibrium that presents an energy distribution\nformed by two non--overlapping Gaussian distribution functions. This is\ndemonstrated by numerical simulations. Also, some previous laboratory\nexperiments with granular systems seem to display this kind of distributions. \n\n"}
{"id": "0812.1018", "contents": "Title: Introducing the q-Theil index Abstract: Starting from the idea of Tsallis on non-extensive statistical mechanics and\nthe {\\it q-entropy} notion, we recall the Theil index $Th$ and transform it\ninto the $Th_q$ index. Both indices can be used to map onto themselves any time\nseries in a non linear way. We develop an application of the $Th_q$ to the GDP\nevolution of 20 rich countries in the time interval [1950 - 2003] and search\nfor a proof of globalization of their economies. First we calculate the\ndistances between the \"new\" time series and to their mean, from which such data\nsimple networks are constructed. We emphasize that it is useful to, and we do,\ntake into account different time \"parameters\": (i) the moving average time\nwindow for the raw time series to calculate the $Th_q$ index; (ii) the moving\naverage time window for calculating the time series distances; (iii) a\ncorrelation time lag. This allows us to deduce optimal conditions to measure\nthe features of the network, i.e. the appearance in 1970 of a globalization\nprocess in the economy of such countries and the present beginning of\ndeviations. The $q$ value hereby used is that which measures the overall data\ndistribution and is equal to 1.8125. \n\n"}
{"id": "0812.1122", "contents": "Title: Promoting cooperation in social dilemmas via simple coevolutionary rules Abstract: We study the evolution of cooperation in structured populations within\npopular models of social dilemmas, whereby simple coevolutionary rules are\nintroduced that may enhance players abilities to enforce their strategy on the\nopponent. Coevolution thus here refers to an evolutionary process affecting the\nteaching activity of players that accompanies the evolution of their\nstrategies. Particularly, we increase the teaching activity of a player after\nit has successfully reproduced, yet we do so depending on the disseminated\nstrategy. We separately consider coevolution affecting either only the\ncooperators or only the defectors, and show that both options promote\ncooperation irrespective of the applied game. Opposite to intuitive reasoning,\nhowever, we reveal that the coevolutionary promotion of players spreading\ndefection is, in the long run, more beneficial for cooperation than the\nlikewise promotion of cooperators. We explain the contradictory impact of the\ntwo considered coevolutionary rules by examining the differences between\nresulting heterogeneities that segregate participating players, and\nfurthermore, demonstrate that the influential individuals completely determine\nthe final outcome of the games. Our findings are immune to changes defining the\ntype of considered social dilemmas and highlight that the heterogeneity of\nplayers, resulting in a positive feedback mechanism, is a fundamental property\npromoting cooperation in groups of selfish individuals. \n\n"}
{"id": "0812.1811", "contents": "Title: Stability of graph communities across time scales Abstract: The complexity of biological, social and engineering networks makes it\ndesirable to find natural partitions into communities that can act as\nsimplified descriptions and provide insight into the structure and function of\nthe overall system. Although community detection methods abound, there is a\nlack of consensus on how to quantify and rank the quality of partitions. We\nshow here that the quality of a partition can be measured in terms of its\nstability, defined in terms of the clustered autocovariance of a Markov process\ntaking place on the graph. Because the stability has an intrinsic dependence on\ntime scales of the graph, it allows us to compare and rank partitions at each\ntime and also to establish the time spans over which partitions are optimal.\nHence the Markov time acts effectively as an intrinsic resolution parameter\nthat establishes a hierarchy of increasingly coarser clusterings. Within our\nframework we can then provide a unifying view of several standard partitioning\nmeasures: modularity and normalized cut size can be interpreted as one-step\ntime measures, whereas Fiedler's spectral clustering emerges at long times. We\napply our method to characterize the relevance and persistence of partitions\nover time for constructive and real networks, including hierarchical graphs and\nsocial networks. We also obtain reduced descriptions for atomic level protein\nstructures over different time scales. \n\n"}
{"id": "0812.2388", "contents": "Title: Physics of risk and uncertainty in quantum decision making Abstract: The Quantum Decision Theory, developed recently by the authors, is applied to\nclarify the role of risk and uncertainty in decision making and in particular\nin relation to the phenomenon of dynamic inconsistency. By formulating this\nnotion in precise mathematical terms, we distinguish three types of\ninconsistency: time inconsistency, planning paradox, and inconsistency\noccurring in some discounting effects. While time inconsistency is well\naccounted for in classical decision theory, the planning paradox is in\ncontradiction with classical utility theory. It finds a natural explanation in\nthe frame of the Quantum Decision Theory. Different types of discounting\neffects are analyzed and shown to enjoy a straightforward explanation within\nthe suggested theory. We also introduce a general methodology based on\nself-similar approximation theory for deriving the evolution equations for the\nprobabilities of future prospects. This provides a novel classification of\npossible discount factors, which include the previously known cases\n(exponential or hyperbolic discounting), but also predicts a novel class of\ndiscount factors that decay to a strictly positive constant for very large\nfuture time horizons. This class may be useful to deal with very long-term\ndiscounting situations associated with intergenerational public policy choices,\nencompassing issues such as global warming and nuclear waste disposal. \n\n"}
{"id": "0812.2705", "contents": "Title: Bayesian credible interval construction for Poisson statistics Abstract: The construction of the Bayesian credible (confidence) interval for a Poisson\nobservable including both the signal and background with and without systematic\nuncertainties is presented. Introducing the conditional probability satisfying\nthe requirement of the background not larger than the observed events to\nconstruct the Bayesian credible interval is also discussed. A Fortran routine,\nBPOCI, has been developed to implement the calculation. \n\n"}
{"id": "0812.2708", "contents": "Title: On Statistical Significance of Signal Abstract: A definition for the statistical significance of a signal in an experiment is\nproposed by establishing a correlation between the observed p-value and the\nnormal distribution integral probability, which is suitable for both counting\nexperiment and continuous test statistics. The explicit expressions to\ncalculate the statistical significance for both cases are given. \n\n"}
{"id": "0812.3227", "contents": "Title: Filtering of complex systems using overlapping tree networks Abstract: We introduce a technique that is capable to filter out information from\ncomplex systems, by mapping them to networks, and extracting a subgraph with\nthe strongest links. This idea is based on the Minimum Spanning Tree, and it\ncan be applied to sets of graphs that have as links different sets of\ninteractions among the system's elements, which are described as network nodes.\nIt can also be applied to correlation-based graphs, where the links are\nweighted and represent the correlation strength between all pairs of nodes. We\napplied this method to the European scientific collaboration network, which is\ncomposed of all the projects supported by the European Framework Program FP6,\nand also to the correlation-based network of the 100 highest capitalized stocks\ntraded in the NYSE. For both cases we identified meaningful structures, such as\na strongly interconnected community of countries that play important role in\nthe collaboration network, and clusters of stocks belonging to different\nsectors of economic activity, which gives significant information about the\ninvestigated systems. \n\n"}
{"id": "0812.4073", "contents": "Title: Multi-level algorithms for modularity clustering Abstract: Modularity is one of the most widely used quality measures for graph\nclusterings. Maximizing modularity is NP-hard, and the runtime of exact\nalgorithms is prohibitive for large graphs. A simple and effective class of\nheuristics coarsens the graph by iteratively merging clusters (starting from\nsingletons), and optionally refines the resulting clustering by iteratively\nmoving individual vertices between clusters. Several heuristics of this type\nhave been proposed in the literature, but little is known about their relative\nperformance.\n  This paper experimentally compares existing and new coarsening- and\nrefinement-based heuristics with respect to their effectiveness (achieved\nmodularity) and efficiency (runtime). Concerning coarsening, it turns out that\nthe most widely used criterion for merging clusters (modularity increase) is\noutperformed by other simple criteria, and that a recent algorithm by Schuetz\nand Caflisch is no improvement over simple greedy coarsening for these\ncriteria. Concerning refinement, a new multi-level algorithm is shown to\nproduce significantly better clusterings than conventional single-level\nalgorithms. A comparison with published benchmark results and algorithm\nimplementations shows that combinations of coarsening and multi-level\nrefinement are competitive with the best algorithms in the literature. \n\n"}
{"id": "0812.4905", "contents": "Title: Kronecker Graphs: An Approach to Modeling Networks Abstract: How can we model networks with a mathematically tractable model that allows\nfor rigorous analysis of network properties? Networks exhibit a long list of\nsurprising properties: heavy tails for the degree distribution; small\ndiameters; and densification and shrinking diameters over time. Most present\nnetwork models either fail to match several of the above properties, are\ncomplicated to analyze mathematically, or both. In this paper we propose a\ngenerative model for networks that is both mathematically tractable and can\ngenerate networks that have the above mentioned properties. Our main idea is to\nuse the Kronecker product to generate graphs that we refer to as \"Kronecker\ngraphs\".\n  First, we prove that Kronecker graphs naturally obey common network\nproperties. We also provide empirical evidence showing that Kronecker graphs\ncan effectively model the structure of real networks.\n  We then present KronFit, a fast and scalable algorithm for fitting the\nKronecker graph generation model to large real networks. A naive approach to\nfitting would take super- exponential time. In contrast, KronFit takes linear\ntime, by exploiting the structure of Kronecker matrix multiplication and by\nusing statistical simulation techniques.\n  Experiments on large real and synthetic networks show that KronFit finds\naccurate parameters that indeed very well mimic the properties of target\nnetworks. Once fitted, the model parameters can be used to gain insights about\nthe network structure, and the resulting synthetic graphs can be used for null-\nmodels, anonymization, extrapolations, and graph summarization. \n\n"}
{"id": "0901.0170", "contents": "Title: Pedestrian Traffic: on the Quickest Path Abstract: When a large group of pedestrians moves around a corner, most pedestrians do\nnot follow the shortest path, which is to stay as close as possible to the\ninner wall, but try to minimize the travel time. For this they accept to move\non a longer path with some distance to the corner, to avoid large densities and\nby this succeed in maintaining a comparatively high speed. In many models of\npedestrian dynamics the basic rule of motion is often either \"move as far as\npossible toward the destination\" or - reformulated - \"of all coordinates\naccessible in this time step move to the one with the smallest distance to the\ndestination\". Atop of this rule modifications are placed to make the motion\nmore realistic. These modifications usually focus on local behavior and neglect\nlong-ranged effects. Compared to real pedestrians this leads to agents in a\nsimulation valuing the shortest path a lot better than the quickest. So, in a\nsituation as the movement of a large crowd around a corner, one needs an\nadditional element in a model of pedestrian dynamics that makes the agents\ndeviate from the rule of the shortest path. In this work it is shown, how this\ncan be achieved by using a flood fill dynamic potential field method, where\nduring the filling process the value of a field cell is not increased by 1, but\nby a larger value, if it is occupied by an agent. This idea may be an obvious\none, however, the tricky part - and therefore in a strict sense the\ncontribution of this work - is a) to minimize unrealistic artifacts, as naive\nflood fill metrics deviate considerably from the Euclidean metric and in this\nrespect yield large errors, b) do this with limited computational effort, and\nc) keep agents' movement at very low densities unaltered. \n\n"}
{"id": "0901.2737", "contents": "Title: The Importance of Disagreeing: Contrarians and Extremism in the CODA\n  model Abstract: In this paper, we study the effects of introducing contrarians in a model of\nOpinion Dynamics where the agents have internal continuous opinions, but\nexchange information only about a binary choice that is a function of their\ncontinuous opinion, the CODA model. We observe that the hung election scenario\nstill exists here, but it is weaker and it shouldn't be expected in every\nelection. Finally, we also show that the introduction of contrarians make the\ntendency towards extremism of the original model weaker, indicating that the\nexistence of agents that prefer to disagree might be an important aspect and\nhelp society to diminish extremist opinions. \n\n"}
{"id": "0901.2924", "contents": "Title: Universal Complex Structures in Written Language Abstract: Quantitative linguistics has provided us with a number of empirical laws that\ncharacterise the evolution of languages and competition amongst them. In terms\nof language usage, one of the most influential results is Zipf's law of word\nfrequencies. Zipf's law appears to be universal, and may not even be unique to\nhuman language. However, there is ongoing controversy over whether Zipf's law\nis a good indicator of complexity. Here we present an alternative approach that\nputs Zipf's law in the context of critical phenomena (the cornerstone of\ncomplexity in physics) and establishes the presence of a large scale\n\"attraction\" between successive repetitions of words. Moreover, this phenomenon\nis scale-invariant and universal -- the pattern is independent of word\nfrequency and is observed in texts by different authors and written in\ndifferent languages. There is evidence, however, that the shape of the scaling\nrelation changes for words that play a key role in the text, implying the\nexistence of different \"universality classes\" in the repetition of words. These\nbehaviours exhibit striking parallels with complex catastrophic phenomena. \n\n"}
{"id": "0901.4075", "contents": "Title: Bayesian reasoning in cosmology Abstract: We discuss epistemological and methodological aspects of the Bayesian\napproach in astrophysics and cosmology. The introduction to the Bayesian\nframework is given for a further discussion concerning the Bayesian inference\nin physics. The interplay between the modern cosmology, Bayesian statistics,\nand philosophy of science is presented. We consider paradoxes of confirmation,\nlike Goodman's paradox, appearing in the Bayesian theory of confirmation. As in\nGoodman's paradox the Bayesian inference is susceptible to some epistemic\nlimitations in the logic of induction. However Goodman's paradox applied to\ncosmological hypotheses seems to be resolved due to the evolutionary character\nof cosmology and accumulation new empirical evidences. We argue that the\nBayesian framework is useful in the context of falsificability of quantum\ncosmological models, as well as contemporary dark energy and dark matter\nproblem. \n\n"}
{"id": "0901.4656", "contents": "Title: Kinematic Fitting in the Presence of ISR at the ILC Abstract: Kinematic fitting is a well-established tool to improve jet energy and\ninvariant mass resolutions by fitting the measured values under constraints\n(e.g. energy conservation). However, in the presence of substantial ISR and\nBeamstrahlung, naive energy and (longitudinal) momentum constraints fail due to\nthe a priori unknown amount of undetected momentum carried away by collinear\nphotons. It is possible to take care of those two effects and thus obtain\nsignificantly higher mass resolutions. \n\n"}
{"id": "0902.0888", "contents": "Title: Communication and correlation among communities Abstract: Given a network and a partition in communities, we consider the issues \"how\ncommunities influence each other\" and \"when two given communities do\ncommunicate\". Specifically, we address these questions in the context of\nsmall-world networks, where an arbitrary quenched graph is given and long range\nconnections are randomly added. We prove that, among the communities, a\nsuperposition principle applies and gives rise to a natural generalization of\nthe effective field theory already presented in [Phys. Rev. E 78, 031102]\n(n=1), which here (n>1) consists in a sort of effective TAP (Thouless, Anderson\nand Palmer) equations in which each community plays the role of a microscopic\nspin. The relative susceptibilities derived from these equations calculated at\nfinite or zero temperature, where the method provides an effective percolation\ntheory, give us the answers to the above issues. Unlike the case n=1,\nasymmetries among the communities may lead, via the TAP-like structure of the\nequations, to many metastable states whose number, in the case of negative\nshort-cuts among the communities, may grow exponentially fast with n. As\nexamples we consider the n Viana-Bray communities model and the n\none-dimensional small-world communities model. Despite being the simplest ones,\nthe relevance of these models in network theory, as e.g. in social networks, is\ncrucial and no analytic solution were known until now. Connections between\npercolation and the fractal dimension of a network are also discussed. Finally,\nas an inverse problem, we show how, from the relative susceptibilities, a\nnatural and efficient method to detect the community structure of a generic\nnetwork arises.\n  For a short presentation of the main result see arXiv:0812.0608. \n\n"}
{"id": "0902.1217", "contents": "Title: Advertising and irreversible opinion spreading in complex social\n  networks Abstract: Irreversible opinion spreading phenomena are studied on small-world and\nscale-free networks by means of the magnetic Eden model, a nonequilibrium\nkinetic model for the growth of binary mixtures in contact with a thermal bath.\nIn this model, the opinion of an individual is affected by those of their\nacquaintances, but opinion changes (analogous to spin flips in an Ising-like\nmodel) are not allowed. We focus on the influence of advertising, which is\nrepresented by external magnetic fields. The interplay and competition between\ntemperature and fields lead to order-disorder transitions, which are found to\nalso depend on the link density and the topology of the complex network\nsubstrate. The effects of advertising campaigns with variable duration, as well\nas the best cost-effective strategies to achieve consensus within different\nscenarios, are also discussed. \n\n"}
{"id": "0902.3161", "contents": "Title: Multiplicity Fluctuations in the Pion-Fireball Gas Abstract: The pion number fluctuations are considered in the system of pions and large\nmass fireballs decaying finally into pions. A formulation which gives an\nextension of the model of independent sources is suggested. The grand canonical\nand micro-canonical ensemble formulations of the pion-fireball gas are\nconsidered as particular examples. \n\n"}
{"id": "0902.4014", "contents": "Title: Phase space geometry and reaction dynamics near index two saddles Abstract: We study the phase space geometry associated with index 2 saddles of a\npotential energy surface and its influence on reaction dynamics for $n$\ndegree-of-freedom (DoF) Hamiltonian systems. For index 1 saddles of potential\nenergy surfaces (the case of classical transition state theory), the existence\nof a normally hyperbolic invariant manifold (NHIM) of saddle stability type has\nbeen shown, where the NHIM serves as the \"anchor\" for the construction of\ndividing surfaces having the no-recrossing property and minimal flux. For the\nindex 1 saddle case the stable and unstable manifolds of the NHIM are\nco-dimension one in the energy surface, and act as conduits for reacting\ntrajectories in phase space. The situation for index 2 saddles is quite\ndifferent. We show that NHIMs with their stable and unstable manifolds still\nexist, but that these manifolds by themselves lack sufficient dimension to act\nas barriers in the energy surface. Rather, there are different types of\ninvariant manifolds, containing the NHIM and its stable and unstable manifolds,\nthat act as co-dimension one barriers in the energy surface. These barriers\ndivide the energy surface in the vicinity of the index 2 saddle into regions of\nqualitatively different trajectories exhibiting a wider variety of dynamical\nbehavior than for the case of index 1 saddles. In particular, we can identify a\nclass of trajectories, which we refer to as \"roaming trajectories\", which are\nnot associated with reaction along the classical minimum energy path (MEP). We\nillustrate the significance of our analysis of the index 2 saddle for reaction\ndynamics with two examples. \n\n"}
{"id": "0903.0872", "contents": "Title: The Structure of Phonological Networks Across Multiple Languages Abstract: The network characteristics based on the phonological similarities in the\nlexicons of several languages were examined. These languages differed widely in\ntheir history and linguistic structure, but commonalities in the network\ncharacteristics were observed. These networks were also found to be different\nfrom other networks studied in the literature. The properties of these networks\nsuggest explanations for various aspects of linguistic processing and hint at\ndeeper organization within human language. \n\n"}
{"id": "0903.3623", "contents": "Title: Matrix plots of reordered bistochastized transaction flow tables: A\n  United States intercounty migration example Abstract: We present a number of variously rearranged matrix plots of the $3, 107\n\\times 3, 107$ 1995-2000 (asymmetric) intercounty migration table for the\nUnited States, principally in its bistochasticized form (all 3,107 row and\ncolumn sums iteratively proportionally fitted to equal 1). In one set of plots,\nthe counties are seriated on the bases of the subdominant (left and right)\neigenvectors of the bistochastic matrix. In another set, we use the ordering of\ncounties in the dendrogram generated by the associated strong component\nhierarchical clustering. Interesting, diverse features of U. S. intercounty\nmigration emerge--such as a contrast in centralized, hub-like\n(cosmopolitan/provincial) properties between cosmopolitan \"Sunbelt\" and\nprovincial \"Black Belt\" counties. The methodologies employed should also be\ninsightful for the many other diverse forms of interesting transaction\nflow-type data--interjournal citations being an obvious, much-studied example,\nwhere one might expect that the journals Science, Nature and PNAS would display\n\"cosmopolitan\" characteristics. \n\n"}
{"id": "0904.0659", "contents": "Title: Clustering in random line graphs Abstract: We investigate the degree distribution $P(k)$ and the clustering coefficient\n$C$ of the line graphs constructed on the Erd\\\"os-R\\'enyi networks, the\nexponential and the scale-free growing networks. We show that the character of\nthe degree distribution in these graphs remains Poissonian, exponential and\npower law, respectively, i.e. the same as in the original networks. When the\nmean degree $<k>$ increases, the obtained clustering coefficient $C$ tends to\n0.50 for the transformed Erd\\\"os-R\\'enyi networks, to 0.53 for the transformed\nexponential networks and to 0.61 for the transformed scale-free networks. These\nresults are close to theoretical values, obtained with the model assumption\nthat the degree-degree correlations in the initial networks are negligible. \n\n"}
{"id": "0904.0805", "contents": "Title: The (unfortunate) complexity of the economy Abstract: This article is a follow-up of a short essay that appeared in Nature 455,\n1181 (2008) [arXiv:0810.5306]. It has become increasingly clear that the\nerratic dynamics of markets is mostly endogenous and not due to the rational\nprocessing of exogenous news. I elaborate on the idea that spin-glass type of\nproblems, where the combination of competition and heterogeneities generically\nleads to long epochs of statis interrupted by crises and hyper-sensitivity to\nsmall changes of the environment, could be metaphors for the complexity of\neconomic systems. I argue that the most valuable contribution of physics to\neconomics might end up being of methodological nature, and that simple models\nfrom physics and agent based numerical simulations, although highly stylized,\nare more realistic than the traditional models of economics that assume\nrational agents with infinite foresight and infinite computing abilities. \n\n"}
{"id": "0904.1882", "contents": "Title: A middle option for choices in the Continuous Opinions and Discrete\n  Actions model Abstract: Modeling the conditions for the emergence of extremism is a very important\nproblem, with clear applications for describing the interaction among\nindividuals. Traditional models either are not suited for the task, as in the\ncase of discrete models, or, like Bounded Confidence models, are built with\nrules that make opinions tend to a common ground between agents or not change\nat all. Continuous Opinions and Discrete Actions (CODA) model allowed us to\nobserve the emergence of extremist agents, even when every agent was initially\na moderate, due to local influence effects. In this paper, the problem of\nemergence of extremism will be addressed by introducing a middle discrete\noption in the CODA model, making it similar to a Potts model. Different\nscenarios for the third option will be discussed: when it is equivalent to\nwithholding judgment, when it is a real third option and when it is a real,\nmiddle option. The effects on the opinions will be studied and its effects on\nextremism discussed. Withholding judgment seems to have an unexpected effect,\ncausing the diminishing of moderate opinions in the long run. For a central\nthird opinion, we find that, under specific conditions, this new choice can act\nas a buffer between the extreme choices. \n\n"}
{"id": "0904.2369", "contents": "Title: Scaling of human behavior during portal browsing Abstract: We investigate transitions of portals users between different subpages. A\nweighted network of portals subpages is reconstructed where edge weights are\nnumbers of corresponding transitions. Distributions of link weights and node\nstrengths follow power laws over several decades. Node strength increases\nfaster than linearly with node degree. The distribution of time spent by the\nuser at one subpage decays as power law with exponent around 1.3. Distribution\nof numbers P(z) of unique subpages during one visit is exponential. We find a\nsquare root dependence between the average z and the total number of\ntransitions n during a single visit. Individual path of portal user resembles\nof self-attracting walk on the weighted network. Analytical model is developed\nto recover in part the collected data. \n\n"}
{"id": "0904.3940", "contents": "Title: Benchmarks for testing community detection algorithms on directed and\n  weighted graphs with overlapping communities Abstract: Many complex networks display a mesoscopic structure with groups of nodes\nsharing many links with the other nodes in their group and comparatively few\nwith nodes of different groups. This feature is known as community structure\nand encodes precious information about the organization and the function of the\nnodes. Many algorithms have been proposed but it is not yet clear how they\nshould be tested. Recently we have proposed a general class of undirected and\nunweighted benchmark graphs, with heterogenous distributions of node degree and\ncommunity size. An increasing attention has been recently devoted to develop\nalgorithms able to consider the direction and the weight of the links, which\nrequire suitable benchmark graphs for testing. In this paper we extend the\nbasic ideas behind our previous benchmark to generate directed and weighted\nnetworks with built-in community structure. We also consider the possibility\nthat nodes belong to more communities, a feature occurring in real systems,\nlike, e. g., social networks. As a practical application, we show how\nmodularity optimization performs on our new benchmark. \n\n"}
{"id": "0905.2377", "contents": "Title: $1/f^\\alpha$ noise and integrable systems Abstract: An innovative test for detecting quantum chaos based on the analysis of the\nspectral fluctuations regarded as a time series has been recently proposed.\nAccording to this test, the fluctuations of a fully chaotic system should\nexhibit 1/f noise, whereas for an integrable system this noise should obey the\n1/f^2 power law. In this letter, we show that there is a family of well-known\nintegrable systems, namely spin chains of Haldane-Shastry type, whose spectral\nfluctuations decay instead as 1/f^4. We present a simple theoretical\njustification of this fact, and propose an alternative characterization of\nquantum chaos versus integrability formulated directly in terms of the power\nspectrum of the spacings of the unfolded spectrum. \n\n"}
{"id": "0905.3096", "contents": "Title: A shift-optimized Hill-type estimator Abstract: A wide range of natural and social phenomena result in observables whose\ndistributions can be well approximated by a power-law decay. The well-known\nHill estimator of the tail exponent provides results which are in many respects\nsuperior to other estimators in case the asymptotics of the distribution is\nindeed a pure power-law, however,systematic errors occur if the distribution is\naltered by simply shifting it. We demonstrate some related problems which\ntypically emerge when dealing with empirical data and suggest a procedure\ndesigned to extend the applicability of the Hill estimator. \n\n"}
{"id": "0905.4237", "contents": "Title: Statistical Properties of Fluctuations: A Method to Check Market\n  Behavior Abstract: We analyze the Bombay stock exchange (BSE) price index over the period of\nlast 12 years. Keeping in mind the large fluctuations in last few years, we\ncarefully find out the transient, non-statistical and locally structured\nvariations. For that purpose, we make use of Daubechies wavelet and\ncharacterize the fractal behavior of the returns using a recently developed\nwavelet based fluctuation analysis method. the returns show a fat-tail\ndistribution as also weak non-statistical behavior. We have also carried out\ncontinuous wavelet as well as Fourier power spectral analysis to characterize\nthe periodic nature and correlation properties of the time series. \n\n"}
{"id": "0905.4578", "contents": "Title: Three quantitative predictions based on past regularities about voter\n  turnout at the French 2009 European election Abstract: The previous twelve turnout rates of French national elections by\nmunicipality show regularities. These regularities do not depend on the\nnational turnout level, nor on the nature of the election. Based on past\nstatistical regularities we make three predictions. The first one deals with\nthe standard deviation of the turnout rate by municipality. The second one\nrefers to the continuity in time of the heterogeneity of turnout rates in the\nvicinity of a municipality. The last one is about the correlation between the\nheterogeneity of turnout rates in the vicinity of a municipality and the\npopulation in its surroundings. Details, explanations and discussions will be\ngiven in forthcoming papers. \n\n"}
{"id": "0905.4793", "contents": "Title: Class formation in a social network with asset exchange Abstract: We study two kinds of economic exchange, additive and multiplicative, in a\nsystem of N agents. The work is divided in two parts, in the first one, the\nagents are free to interact with each other. The system evolves to a\nBoltzmann-Gibbs distribution with additive exchange and condenses with a\nmultiplicative one. If bankruptcy is introduced, both types of exchange lead to\ncondensation. Condensation times have been studied. In the second part, the\nagents are placed in a social network. We analyze the behavior of wealth\ndistributions in time, and the formation of economic classes was observed for\ncertain values of network connectivity. \n\n"}
{"id": "0905.4804", "contents": "Title: Comments on Six Degrees of Separation based on the le Pool and Kochen\n  Models Abstract: In this article we discuss six degrees of separation, which has been\nsuggested by Milgram's famous experiment\\cite{Milg},\\cite{Milg2}, from a\ntheoretical point of view again. Though Milgram's experiment was partly\ninspired to Pool and Kochen's study \\cite{Pool} that was made from a\ntheoretical point of view. At the time numerically detailed study could not be\nmade because computers and important concepts, such as the clustering\ncoefficient, needed for a network analysis nowadays, have not yet developed. In\nthis article we devote deep study to the six degrees of separation based on\nsome models proposed by Pool and Kochen by using a computer, numerically.\nMoreover we estimate the clustering coefficient along the method developed by\nus \\cite{Toyota1} and extend our analysis of the subject through marrying Pool\nand Kochen's models to our method. \n\n"}
{"id": "0905.4815", "contents": "Title: Trading leads to scale-free self-organization Abstract: Financial markets display scale-free behavior in many different aspects. The\npower-law behavior of part of the distribution of individual wealth has been\nrecognized by Pareto as early as the nineteenth century. Heavy-tailed and\nscale-free behavior of the distribution of returns of different financial\nassets have been confirmed in a series of works. The existence of a Pareto-like\ndistribution of the wealth of market participants has been connected with the\nscale-free distribution of trading volumes and price-returns. The origin of the\nPareto-like wealth distribution, however, remained obscure. Here we show that\nit is the process of trading itself that under two mild assumptions\nspontaneously leads to a self-organization of the market with a Pareto-like\nwealth distribution for the market participants and at the same time to a\nscale-free behavior of return fluctuations. These assumptions are (i) everybody\ntrades proportional to his current capacity and (ii) supply and demand\ndetermine the relative value of the goods. \n\n"}
{"id": "0906.1109", "contents": "Title: Analysis of major failures in Europe's power grid Abstract: Power grids are prone to failure. Time series of reliability measures such as\ntotal power loss or energy not supplied can give significant account of the\nunderlying dynamical behavior of these systems, specially when the resulting\nprobability distributions present remarkable features such as an algebraic\ntail, for example. In this paper, seven years (from 2002 to 2008) of Europe's\ntransport of electricity network failure events have been analyzed and the best\nfit for this empirical data probability distribution is presented. With the\nactual span of available data and although there exists a moderate support for\nthe power law model, the relatively small amount of events contained in the\nfunction's tail suggests that other causal factors might be significantly\nruling the system's dynamics. \n\n"}
{"id": "0906.1282", "contents": "Title: Matrix formalism and singular-value decomposition for the location of\n  gamma interactions in segmented HPGe detectors Abstract: Modern coaxial and planar HPGe detectors allow a precise determination of the\nenergies and trajectories of the impinging gamma-rays. This entails the\nlocation of the gamma interactions inside the crystal from the shape of the\ndelivered signals. This paper reviews the state of the art of the analysis of\nthe HPGe response function and proposes methods that lead to optimum signal\ndecomposition. The generic matrix method allows fast location of the\ninteractions even when the induced signals strongly overlap. \n\n"}
{"id": "0906.3507", "contents": "Title: The common patterns of nature Abstract: We typically observe large-scale outcomes that arise from the interactions of\nmany hidden, small-scale processes. Examples include age of disease onset,\nrates of amino acid substitutions, and composition of ecological communities.\nThe macroscopic patterns in each problem often vary around a characteristic\nshape that can be generated by neutral processes. A neutral generative model\nassumes that each microscopic process follows unbiased stochastic fluctuations:\nrandom connections of network nodes; amino acid substitutions with no effect on\nfitness; species that arise or disappear from communities randomly. These\nneutral generative models often match common patterns of nature. In this paper,\nI present the theoretical background by which we can understand why these\nneutral generative models are so successful. I show how the classic patterns\nsuch as Poisson and Gaussian arise. Each classic pattern was often discovered\nby a simple neutral generative model. The neutral patterns share a special\ncharacteristic: they describe the patterns of nature that follow from simple\nconstraints on information. For example, any aggregation of processes that\npreserves information only about the mean and variance attracts to the Gaussian\npattern; any aggregation that preserves information only about the mean\nattracts to the exponential pattern; any aggregation that preserves information\nonly about the geometric mean attracts to the power law pattern. I present an\ninformational framework of the common patterns of nature based on the method of\nmaximum entropy. This framework shows that each neutral generative model is a\nspecial case that helps to discover a particular set of informational\nconstraints; those informational constraints define a much wider domain of\nnon-neutral generative processes that attract to the same neutral pattern. \n\n"}
{"id": "0907.0900", "contents": "Title: Impact of hierarchical modular structure on ranking of individual nodes\n  in directed networks Abstract: Many systems, ranging from biological and engineering systems to social\nsystems, can be modeled as directed networks, with links representing directed\ninteraction between two nodes. To assess the importance of a node in a directed\nnetwork, various centrality measures based on different criteria have been\nproposed. However, calculating the centrality of a node is often difficult\nbecause of the overwhelming size of the network or the incomplete information\nabout the network. Thus, developing an approximation method for estimating\ncentrality measures is needed. In this study, we focus on modular networks;\nmany real-world networks are composed of modules, where connection is dense\nwithin a module and sparse across different modules. We show that ranking-type\ncentrality measures including the PageRank can be efficiently estimated once\nthe modular structure of a network is extracted. We develop an analytical\nmethod to evaluate the centrality of nodes by combining the local property\n(i.e., indegree and outdegree of nodes) and the global property (i.e.,\ncentrality of modules). The proposed method is corroborated with real data. Our\nresults provide a linkage between the ranking-type centrality values of modules\nand those of individual nodes. They also reveal the hierarchical structure of\nnetworks in the sense of subordination (not nestedness) laid out by\nconnectivity among modules of different relative importance. The present study\nraises a novel motive of identifying modules in networks. \n\n"}
{"id": "0907.3450", "contents": "Title: Limits, discovery and cut optimization for a Poisson process with\n  uncertainty in background and signal efficiency: TRolke 2.0 Abstract: A C++ class was written for the calculation of frequentist confidence\nintervals using the profile likelihood method. Seven combinations of Binomial,\nGaussian, Poissonian and Binomial uncertainties are implemented. The package\nprovides routines for the calculation of upper and lower limits, sensitivity\nand related properties. It also supports hypothesis tests which take\nuncertainties into account. It can be used in compiled C++ code, in Python or\ninteractively via the ROOT analysis framework. \n\n"}
{"id": "0907.3864", "contents": "Title: Hawkes process as a model of social interactions: a view on video\n  dynamics Abstract: We study by computer simulation the \"Hawkes process\" that was proposed in a\nrecent paper by Crane and Sornette (Proc. Nat. Acad. Sci. USA 105, 15649\n(2008)) as a plausible model for the dynamics of YouTube video viewing numbers.\nWe test the claims made there that robust identification is possible for\nclasses of dynamic response following activity bursts. Our simulated timeseries\nfor the Hawkes process indeed fall into the different categories predicted by\nCrane and Sornette. However the Hawkes process gives a much narrower spread of\ndecay exponents than the YouTube data, suggesting limits to the universality of\nthe Hawkes-based analysis. \n\n"}
{"id": "0909.3892", "contents": "Title: Astroinformatics: A 21st Century Approach to Astronomy Abstract: Data volumes from multiple sky surveys have grown from gigabytes into\nterabytes during the past decade, and will grow from terabytes into tens (or\nhundreds) of petabytes in the next decade. This exponential growth of new data\nboth enables and challenges effective astronomical research, requiring new\napproaches. Thus far, astronomy has tended to address these challenges in an\ninformal and ad hoc manner, with the necessary special expertise being assigned\nto e-Science or survey science. However, we see an even wider scope and\ntherefore promote a broader vision of this data-driven revolution in\nastronomical research. For astronomy to effectively cope with and reap the\nmaximum scientific return from existing and future large sky surveys,\nfacilities, and data-producing projects, we need our own information science\nspecialists. We therefore recommend the formal creation, recognition, and\nsupport of a major new discipline, which we call Astroinformatics.\nAstroinformatics includes a set of naturally-related specialties including data\norganization, data description, astronomical classification taxonomies,\nastronomical concept ontologies, data mining, machine learning, visualization,\nand astrostatistics. By virtue of its new stature, we propose that astronomy\nnow needs to integrate Astroinformatics as a formal sub-discipline within\nagency funding plans, university departments, research programs, graduate\ntraining, and undergraduate education. Now is the time for the recognition of\nAstroinformatics as an essential methodology of astronomical research. The\nfuture of astronomy depends on it. \n\n"}
{"id": "0910.0681", "contents": "Title: Modeling noise induced resonance in an excitable system: An alternative\n  approach Abstract: Recently, it is observed [Md. Nurujjaman et al, Phy. Rev. E \\textbf{80},\n015201 (R) (2009)] that in an excitable system, one can maintain noise induced\ncoherency in the coherence resonance by blocking the destructive effect of the\nnoise on the system at higher noise level. This phenomenon of constant\ncoherence resonance (CCR) cannot be explained by the existing way of simulation\nof the model equations of an excitable system with added noise. In this paper,\nwe have proposed a general model which explains the noise induced resonance\nphenomenon CCR as well as coherence resonance (CR) and stochastic resonance\n(SR). The simulation has been carried out considering the basic mechanism of\nnoise induced resonance phenomena: noise only perturbs the system control\nparameter to excite coherent oscillations, taking proper precautions so that\nthe destructive effect of noise does not affect the system. In this approach,\nthe CR has been obtained from the interference between the system output and\nnoise, and the SR has been obtained by adding noise and a subthreshold signal.\nThis also explains the observation of the frequency shift of coherent\noscillations in the CCR with noise level. \n\n"}
{"id": "0910.1508", "contents": "Title: Consistent Community Identification in Complex Networks Abstract: We have found that known community identification algorithms produce\ninconsistent communities when the node ordering changes at input. We propose\ntwo metrics to quantify the level of consistency across multiple runs of an\nalgorithm: pairwise membership probability and consistency. Based on these two\nmetrics, we address the consistency problem without compromising the\nmodularity. Our solution uses pairwise membership probabilities as link weights\nand generates consistent communities within six or fewer cycles. It offers a\nnew tool in the study of community structures and their evolutions. \n\n"}
{"id": "0910.3483", "contents": "Title: Message transport characteristics in communication networks Abstract: We study message transport on a $1-d$ ring of nodes and randomly distributed\nhubs. Messages are deposited on the network at a constant rate. When the rate\nat which messages are deposited on the lattice is very high, messages start\naccumulating after a critical time and the average load per node starts\nincreasing. The power-spectrum of the load time-series shows $1/f$ like noise\nsimilar to the scenario of the Internet traffic. The inter-arrival time\ndistribution of messages for the $1-d$ ring network shows stretched exponential\nbehavior, which crosses over to power-law behavior if assortative connections\nare added to the hubs. The distribution of travel times in a related double\nring geometry is shown to be bimodal with one peak corresponding to initial\ncongestion and another peak to later decongestion. \n\n"}
{"id": "0911.0408", "contents": "Title: Revisiting Date and Party Hubs: Novel Approaches to Role Assignment in\n  Protein Interaction Networks Abstract: The idea of 'date' and 'party' hubs has been influential in the study of\nprotein-protein interaction networks. Date hubs display low co-expression with\ntheir partners, whilst party hubs have high co-expression. It was proposed that\nparty hubs are local coordinators whereas date hubs are global connectors. Here\nwe show that the reported importance of date hubs to network connectivity can\nin fact be attributed to a tiny subset of them. Crucially, these few, extremely\ncentral, hubs do not display particularly low expression correlation,\nundermining the idea of a link between this quantity and hub function. The\ndate/party distinction was originally motivated by an approximately bimodal\ndistribution of hub co-expression; we show that this feature is not always\nrobust to methodological changes. Additionally, topological properties of hubs\ndo not in general correlate with co-expression. Thus, we suggest that a\ndate/party dichotomy is not meaningful and it might be more useful to conceive\nof roles for protein-protein interactions rather than individual proteins. We\nfind significant correlations between interaction centrality and the functional\nsimilarity of the interacting proteins. \n\n"}
{"id": "0911.0505", "contents": "Title: Scientific Data Mining in Astronomy Abstract: We describe the application of data mining algorithms to research problems in\nastronomy. We posit that data mining has always been fundamental to\nastronomical research, since data mining is the basis of evidence-based\ndiscovery, including classification, clustering, and novelty discovery. These\nalgorithms represent a major set of computational tools for discovery in large\ndatabases, which will be increasingly essential in the era of data-intensive\nastronomy. Historical examples of data mining in astronomy are reviewed,\nfollowed by a discussion of one of the largest data-producing projects\nanticipated for the coming decade: the Large Synoptic Survey Telescope (LSST).\nTo facilitate data-driven discoveries in astronomy, we envision a new\ndata-oriented research paradigm for astronomy and astrophysics --\nastroinformatics. Astroinformatics is described as both a research approach and\nan educational imperative for modern data-intensive astronomy. An important\napplication area for large time-domain sky surveys (such as LSST) is the rapid\nidentification, characterization, and classification of real-time sky events\n(including moving objects, photometrically variable objects, and the appearance\nof transients). We describe one possible implementation of a classification\nbroker for such events, which incorporates several astroinformatics techniques:\nuser annotation, semantic tagging, metadata markup, heterogeneous data\nintegration, and distributed data mining. Examples of these types of\ncollaborative classification and discovery approaches within other science\ndisciplines are presented. \n\n"}
{"id": "0911.1084", "contents": "Title: Measuring social dynamics in a massive multiplayer online game Abstract: Quantification of human group-behavior has so far defied an empirical,\nfalsifiable approach. This is due to tremendous difficulties in data\nacquisition of social systems. Massive multiplayer online games (MMOG) provide\na fascinating new way of observing hundreds of thousands of simultaneously\nsocially interacting individuals engaged in virtual economic activities. We\nhave compiled a data set consisting of practically all actions of all players\nover a period of three years from a MMOG played by 300,000 people. This\nlarge-scale data set of a socio-economic unit contains all social and economic\ndata from a single and coherent source. Players have to generate a virtual\nincome through economic activities to `survive' and are typically engaged in a\nmultitude of social activities offered within the game. Our analysis of\nhigh-frequency log files focuses on three types of social networks, and tests a\nseries of social-dynamics hypotheses. In particular we study the structure and\ndynamics of friend-, enemy- and communication networks. We find striking\ndifferences in topological structure between positive (friend) and negative\n(enemy) tie networks. All networks confirm the recently observed phenomenon of\nnetwork densification. We propose two approximate social laws in communication\nnetworks, the first expressing betweenness centrality as the inverse square of\nthe overlap, the second relating communication strength to the cube of the\noverlap. These empirical laws provide strong quantitative evidence for the Weak\nties hypothesis of Granovetter. Further, the analysis of triad significance\nprofiles validates well-established assertions from social balance theory. We\nfind overrepresentation (underrepresentation) of complete (incomplete) triads\nin networks of positive ties, and vice versa for networks of negative ties... \n\n"}
{"id": "0911.2165", "contents": "Title: Methods for measuring pedestrian density, flow, speed and direction with\n  minimal scatter Abstract: The progress of image processing during recent years allows the measurement\nof pedestrian characteristics on a \"microscopic\" scale with low costs. However,\ndensity and flow are concepts of fluid mechanics defined for the limit of\ninfinitely many particles. Standard methods of measuring these quantities\nlocally (e.g. counting heads within a rectangle) suffer from large data\nscatter. The remedy of averaging over large spaces or long times reduces the\npossible resolution and inhibits the gain obtained by the new technologies.\n  In this contribution we introduce a concept for measuring microscopic\ncharacteristics on the basis of pedestrian trajectories. Assigning a personal\nspace to every pedestrian via a Voronoi diagram reduces the density scatter.\nSimilarly, calculating direction and speed from position differences between\ntimes with identical phases of movement gives low-scatter sequences for speed\nand direction. Closing we discuss the methods to obtain reliable values for\nderived quantities and new possibilities of in depth analysis of experiments.\nThe resolution obtained indicates the limits of stationary state theory. \n\n"}
{"id": "0911.2850", "contents": "Title: A simple event weighting technique for optimizing the measurement of the\n  forward-backward asymmetry of Drell-Yan dilepton pairs at hadron colliders Abstract: We describe a simple technique for optimizing the extraction of the\nforward-backward asymmetry ($A_{fb}$) of Drell-Yan lepton pairs ($e^+e^-$,$\n\\mu^+\\mu^-$) produced in $\\bar{p}p$ and $pp$ collisions at hadron colliders.\nThe method employs simple event weights which are functions of the rapidity and\n$cos\\theta$ decay angle of the lepton pair. It yields the best estimate of the\nacceptance corrected parton level ($\\bar{q}q$) forward backward asymmetry as a\nfunction of final state dilepton mass ($M_{\\ell\\ell}$). Typically, when\ncompared to the simple count method, the technique reduces the statistical\nerrors by 20% for $\\bar{p}p$, and 40% for $pp$ collisions, respectively. The\ntechnique can be used to search for new high mass and large width Z' bosons\nwhich may be best detected through the observation of deviations from the\nStandard Model expectation for the forward-backward asymmetry. In addition, we\nderive expressions for the QCD angular coefficients for Drell-Yan events. \n\n"}
{"id": "0911.5570", "contents": "Title: Organization and Complexity in a Nested Hierarchical Spin-Glass like\n  Social Space Abstract: In this paper, we mathematically formulate the interaction and dynamics of a\nhierarchical complex social system where each agent is seen as an array of many\nvariables. The formation of identities and modifications can be studied by\nusing interaction physics in an energy landscape. The spin glass Hamiltonian is\nmodified to suit our needs in light of complexity. The expression of variables\nsubject to weights and topology is considered. Interactions within the same\nhierarchy level as well as the effect of one hierarchy level on another are\nstudied. The effect of having many variables associated with a single agent\nbrings about interesting dynamics. The persistence of the identity units\nsubject to stiffness, continuous changes and also sudden reorganizations is\ndiscussed. \n\n"}
{"id": "0912.2807", "contents": "Title: $p$-th Clustering coefficients $C_{p}$ and Adjacent Matrix for Networks:\n  Formulation based on String Abstract: The phenomenon of six degrees of separation is an old but interesting\nproblem. The considerations of the clustering coefficient reflecting triangular\nstructures and its extension to square one to six degrees of separation have\nbeen made\\cite{Newm21}. Recently, Aoyama\\cite{Aoyama} has given some\nconsiderations to this problem in networks without loops, using a sort of\ngeneral formalism, \"string formalism\". In this article, we describe relations\nbetween the string formulation proposed by Aoyama and an adjacent matrix. Thus\nwe provided a reformulation of the string formulation proposed by \\cite{Aoyama}\nto analyze networks. According to it, we introduced a series of generalized\n$q$-$th$ clustering coefficients. The available rules between diagrams of\ngraphs and formulae are also given based on the formulation. Next we apply the\nformulation to some subjects in order to mainly check consistency with former\nstudies. By evaluating the clustering coefficient for typical networks studied\nwell earlier, we confirm a validity of our formulation. Lastly we applied it to\nthe subject of two degrees of separation. \n\n"}
{"id": "0912.5083", "contents": "Title: Ulam method and fractal Weyl law for Perron--Frobenius operators Abstract: We use the Ulam method to study spectral properties of the Perron-Frobenius\noperators of dynamical maps in a chaotic regime. For maps with absorption we\nshow that the spectrum is characterized by the fractal Weyl law recently\nestablished for nonunitary operators describing poles of quantum chaotic\nscattering with the Weyl exponent $\\nu=d-1$, where $d$ is the fractal dimension\nof corresponding strange set of trajectories nonescaping in future times. In\ncontrast, for dissipative maps we find the Weyl exponent $\\nu=d/2$ where $d$ is\nthe fractal dimension of strange attractor. The Weyl exponent can be also\nexpressed via the relation $\\nu=d_0/2$ where $d_0$ is the fractal dimension of\nthe invariant sets. We also discuss the properties of eigenvalues and\neigenvectors of such operators characterized by the fractal Weyl law. \n\n"}
{"id": "1001.4235", "contents": "Title: Dilbert-Peter model of organization effectiveness: computer simulations Abstract: We provide a technical report on a computer simulation of general\neffectiveness of a hierarchical organization depending on two main aspects:\neffects of promotion to managerial levels and efforts to self-promote of\nindividual employees, reducing their actual productivity. The combination of\njudgment by appearance in the promotion to higher levels of hierarchy and the\nPeter Principle (which states that people are promoted to their level of\nincompetence) results in fast declines in effectiveness of the organization.\nThe model uses a few synthetic parameters aimed at reproduction of realistic\nconditions in typical multilayer organizations. \n\n"}
{"id": "1002.3861", "contents": "Title: Zipf's Law Leads to Heaps' Law: Analyzing Their Relation in Finite-Size\n  Systems Abstract: Background: Zipf's law and Heaps' law are observed in disparate complex\nsystems. Of particular interests, these two laws often appear together. Many\ntheoretical models and analyses are performed to understand their co-occurrence\nin real systems, but it still lacks a clear picture about their relation.\nMethodology/Principal Findings: We show that the Heaps' law can be considered\nas a derivative phenomenon if the system obeys the Zipf's law. Furthermore, we\nrefine the known approximate solution of the Heaps' exponent provided the\nZipf's exponent. We show that the approximate solution is indeed an asymptotic\nsolution for infinite systems, while in the finite-size system the Heaps'\nexponent is sensitive to the system size. Extensive empirical analysis on tens\nof disparate systems demonstrates that our refined results can better capture\nthe relation between the Zipf's and Heaps' exponents. Conclusions/Significance:\nThe present analysis provides a clear picture about the relation between the\nZipf's law and Heaps' law without the help of any specific stochastic model,\nnamely the Heaps' law is indeed a derivative phenomenon from Zipf's law. The\npresented numerical method gives considerably better estimation of the Heaps'\nexponent given the Zipf's exponent and the system size. Our analysis provides\nsome insights and implications of real complex systems, for example, one can\nnaturally obtained a better explanation of the accelerated growth of scale-free\nnetworks. \n\n"}
{"id": "1002.4526", "contents": "Title: Horizontal visibility graphs: exact results for random time series Abstract: The visibility algorithm has been recently introduced as a mapping between\ntime series and complex networks. This procedure allows to apply methods of\ncomplex network theory for characterizing time series. In this work we present\nthe horizontal visibility algorithm, a geometrically simpler and analytically\nsolvable version of our former algorithm, focusing on the mapping of random\nseries (series of independent identically distributed random variables). After\npresenting some properties of the algorithm, we present exact results on the\ntopological properties of graphs associated to random series, namely the degree\ndistribution, clustering coefficient, and mean path length. We show that the\nhorizontal visibility algorithm stands as a simple method to discriminate\nrandomness in time series, since any random series maps to a graph with an\nexponential degree distribution of the shape P(k) = (1/3)(2/3)**(k-2),\nindependently of the probability distribution from which the series was\ngenerated. Accordingly, visibility graphs with other P(k) are related to\nnon-random series. Numerical simulations confirm the accuracy of the theorems\nfor finite series. In a second part, we show that the method is able to\ndistinguish chaotic series from i.i.d. theory, studying the following\nsituations: (i) noise-free low-dimensional chaotic series, (ii) low-dimensional\nnoisy chaotic series, even in the presence of large amounts of noise, and (iii)\nhigh-dimensional chaotic series (coupled map lattice), without needs for\nadditional techniques such as surrogate data or noise reduction methods.\nFinally, heuristic arguments are given to explain the topological properties of\nchaotic series and several sequences which are conjectured to be random are\nanalyzed. \n\n"}
{"id": "1003.0747", "contents": "Title: Asymptotic Results on Adaptive False Discovery Rate Controlling\n  Procedures Based on Kernel Estimators Abstract: The False Discovery Rate (FDR) is a commonly used type I error rate in\nmultiple testing problems. It is defined as the expected False Discovery\nProportion (FDP), that is, the expected fraction of false positives among\nrejected hypotheses. When the hypotheses are independent, the\nBenjamini-Hochberg procedure achieves FDR control at any pre-specified level.\nBy construction, FDR control offers no guarantee in terms of power, or type II\nerror. A number of alternative procedures have been developed, including\nplug-in procedures that aim at gaining power by incorporating an estimate of\nthe proportion of true null hypotheses. In this paper, we study the asymptotic\nbehavior of a class of plug-in procedures based on kernel estimators of the\ndensity of the $p$-values, as the number $m$ of tested hypotheses grows to\ninfinity. In a setting where the hypotheses tested are independent, we prove\nthat these procedures are asymptotically more powerful in two respects: (i) a\ntighter asymptotic FDR control for any target FDR level and (ii) a broader\nrange of target levels yielding positive asymptotic power. We also show that\nthis increased asymptotic power comes at the price of slower, non-parametric\nconvergence rates for the FDP. These rates are of the form $m^{-k/(2k+1)}$,\nwhere $k$ is determined by the regularity of the density of the $p$-value\ndistribution, or, equivalently, of the test statistics distribution. These\nresults are applied to one- and two-sided tests statistics for Gaussian and\nLaplace location models, and for the Student model. \n\n"}
{"id": "1003.2198", "contents": "Title: The relation between Eigenfactor, audience factor, and influence weight Abstract: We present a theoretical and empirical analysis of a number of bibliometric\nindicators of journal performance. We focus on three indicators in particular,\nnamely the Eigenfactor indicator, the audience factor, and the influence weight\nindicator. Our main finding is that the last two indicators can be regarded as\na kind of special cases of the first indicator. We also find that the three\nindicators can be nicely characterized in terms of two properties. We refer to\nthese properties as the property of insensitivity to field differences and the\nproperty of insensitivity to insignificant journals. The empirical results that\nwe present illustrate our theoretical findings. We also show empirically that\nthe differences between various indicators of journal performance are quite\nsubstantial. \n\n"}
{"id": "1003.5455", "contents": "Title: Towards physical laws for software architecture Abstract: Starting from the pioneering works on software architecture precious\nguidelines have emerged to indicate how computer programs should be organized.\nFor example the \"separation of concerns\" suggests to split a program into\nmodules that overlap in functionality as little as possible. However these\nrecommendations are mainly conceptual and are thus hard to express in a\nquantitative form. Hence software architecture relies on the individual\nexperience and skill of the designers rather than on quantitative laws. In this\narticle I apply the methods developed for the classification of information on\nthe World-Wide-Web to study the organization of Open Source programs in an\nattempt to establish the statistical laws governing software architecture. \n\n"}
{"id": "1004.0127", "contents": "Title: Heavy-tailed targets and (ab)normal asymptotics in diffusive motion Abstract: We investigate temporal behavior of probability density functions (pdfs) of\nparadigmatic jump-type and continuous processes that, under confining regimes,\nshare common heavy-tailed asymptotic (target) pdfs. Namely, we have shown that\nunder suitable confinement conditions, the ordinary Fokker-Planck equation may\ngenerate non-Gaussian heavy-tailed pdfs (like e.g. Cauchy or more general\nL\\'evy stable distribution) in its long time asymptotics. For diffusion-type\nprocesses, our main focus is on their transient regimes and specifically the\ncrossover features, when initially infinite number of the pdf moments drops\ndown to a few or none at all. The time-dependence of the variance (if in\nexistence), $\\sim t^{\\gamma}$ with $0<\\gamma <2$, in principle may be\ninterpreted as a signature of sub-, normal or super-diffusive behavior under\nconfining conditions; the exponent $\\gamma $ is generically well defined in\nsubstantial periods of time. However, there is no indication of any universal\ntime rate hierarchy, due to a proper choice of the driver and/or external\npotential. \n\n"}
{"id": "1004.1349", "contents": "Title: Ulam method for the Chirikov standard map Abstract: We introduce a generalized Ulam method and apply it to symplectic dynamical\nmaps with a divided phase space. Our extensive numerical studies based on the\nArnoldi method show that the Ulam approximant of the Perron-Frobenius operator\non a chaotic component converges to a continuous limit. Typically, in this\nregime the spectrum of relaxation modes is characterized by a power law decay\nfor small relaxation rates. Our numerical data show that the exponent of this\ndecay is approximately equal to the exponent of Poincar\\'e recurrences in such\nsystems. The eigenmodes show links with trajectories sticking around stability\nislands. \n\n"}
{"id": "1004.3539", "contents": "Title: Empirical Comparison of Algorithms for Network Community Detection Abstract: Detecting clusters or communities in large real-world graphs such as large\nsocial or information networks is a problem of considerable interest. In\npractice, one typically chooses an objective function that captures the\nintuition of a network cluster as set of nodes with better internal\nconnectivity than external connectivity, and then one applies approximation\nalgorithms or heuristics to extract sets of nodes that are related to the\nobjective function and that \"look like\" good communities for the application of\ninterest. In this paper, we explore a range of network community detection\nmethods in order to compare them and to understand their relative performance\nand the systematic biases in the clusters they identify. We evaluate several\ncommon objective functions that are used to formalize the notion of a network\ncommunity, and we examine several different classes of approximation algorithms\nthat aim to optimize such objective functions. In addition, rather than simply\nfixing an objective and asking for an approximation to the best cluster of any\nsize, we consider a size-resolved version of the optimization problem.\nConsidering community quality as a function of its size provides a much finer\nlens with which to examine community detection algorithms, since objective\nfunctions and approximation algorithms often have non-obvious size-dependent\nbehavior. \n\n"}
{"id": "1005.0157", "contents": "Title: Nested Sampling with Constrained Hamiltonian Monte Carlo Abstract: Nested sampling is a powerful approach to Bayesian inference ultimately\nlimited by the computationally demanding task of sampling from a heavily\nconstrained probability distribution. An effective algorithm in its own right,\nHamiltonian Monte Carlo is readily adapted to efficiently sample from any\nsmooth, constrained distribution. Utilizing this constrained Hamiltonian Monte\nCarlo, I introduce a general implementation of the nested sampling algorithm. \n\n"}
{"id": "1005.2197", "contents": "Title: Scalable Tensor Factorizations for Incomplete Data Abstract: The problem of incomplete data - i.e., data with missing or unknown values -\nin multi-way arrays is ubiquitous in biomedical signal processing, network\ntraffic analysis, bibliometrics, social network analysis, chemometrics,\ncomputer vision, communication networks, etc. We consider the problem of how to\nfactorize data sets with missing values with the goal of capturing the\nunderlying latent structure of the data and possibly reconstructing missing\nvalues (i.e., tensor completion). We focus on one of the most well-known tensor\nfactorizations that captures multi-linear structure, CANDECOMP/PARAFAC (CP). In\nthe presence of missing data, CP can be formulated as a weighted least squares\nproblem that models only the known entries. We develop an algorithm called\nCP-WOPT (CP Weighted OPTimization) that uses a first-order optimization\napproach to solve the weighted least squares problem. Based on extensive\nnumerical experiments, our algorithm is shown to successfully factorize tensors\nwith noise and up to 99% missing data. A unique aspect of our approach is that\nit scales to sparse large-scale data, e.g., 1000 x 1000 x 1000 with five\nmillion known entries (0.5% dense). We further demonstrate the usefulness of\nCP-WOPT on two real-world applications: a novel EEG (electroencephalogram)\napplication where missing data is frequently encountered due to disconnections\nof electrodes and the problem of modeling computer network traffic where data\nmay be absent due to the expense of the data collection process. \n\n"}
{"id": "1005.5139", "contents": "Title: A Better Definition of the Kilogram Abstract: This article reviews several recent proposed redefinitions of the kilogram,\nand compares them with respect to practical realizations, uncertainties\n(estimated standard deviations), and educational aspects. \n\n"}
{"id": "1006.1557", "contents": "Title: Ordering in voter models on networks: Exact reduction to a\n  single-coordinate diffusion Abstract: We study the voter model and related random-copying processes on arbitrarily\ncomplex network structures. Through a representation of the dynamics as a\nparticle reaction process, we show that a quantity measuring the degree of\norder in a finite system is, under certain conditions, exactly governed by a\nuniversal diffusion equation. Whenever this reduction occurs, the details of\nthe network structure and random-copying process affect only a single parameter\nin the diffusion equation. The validity of the reduction can be established\nwith considerably less information than one might expect: it suffices to know\njust two characteristic timescales within the dynamics of a single pair of\nreacting particles. We develop methods to identify these timescales, and apply\nthem to deterministic and random network structures. We focus in particular on\nhow the ordering time is affected by degree correlations, since such effects\nare hard to access by existing theoretical approaches. \n\n"}
{"id": "1006.1779", "contents": "Title: Heat conductance in nonlinear lattices at small temperature gradients Abstract: This paper proposes a new methodological framework within which the heat\nconductance in 1D lattices can be studied. The total process of heat\nconductance is separated into two parts where the first one is the equilibrium\nprocess at equal temperatures $T$ of both ends and the second one --\nnon-equilibrium with the temperature $\\Delta T$ of one end and zero temperature\nof the other. This approach allows significant decrease of computational time\nat $\\Delta T \\to 0$. The threshold temperature $T_{\\rm thr}$ is found which\nscales $T_{\\rm thr}(N) \\sim N^{-3}$ with the lattice size $N$ and by convention\nseparates two mechanisms of heat conductance: phonon mechanism dominates at $T\n< T_{\\rm thr}$ and the soliton contribution increases with temperature at $T >\nT_{\\rm thr}$. Solitons and breathers are directly visualized in numerical\nexperiments. The problem of heat conductance in non-linear lattices in the\nlimit $\\Delta T \\to 0$ can be reduced to the heat conductance of harmonic\nlattice with time-dependent stochastic rigidities determined by the equilibrium\nprocess at temperature $T$. The detailed analysis is done for the $\\beta$-FPU\nlattice though main results are valid for one-dimensional lattices with\narbitrary potentials. \n\n"}
{"id": "1006.2010", "contents": "Title: Prediction accuracy and sloppiness of log-periodic functions Abstract: We show that log-periodic power-law (LPPL) functions are intrinsically very\nhard to fit to time series. This comes from their sloppiness, the squared\nresiduals depending very much on some combinations of parameters and very\nlittle on other ones. The time of singularity that is supposed to give an\nestimate of the day of the crash belongs to the latter category. We discuss in\ndetail why and how the fitting procedure must take into account the sloppy\nnature of this kind of model. We then test the reliability of LPPLs on\nsynthetic AR(1) data replicating the Hang Seng 1987 crash and show that even\nthis case is borderline regarding predictability of divergence time. We finally\nargue that current methods used to estimate a probabilistic time window for the\ndivergence time are likely to be over-optimistic. \n\n"}
{"id": "1006.4884", "contents": "Title: Component Ratios of Independent and Herding Betters in a Racetrack\n  Betting Market Abstract: We study the time series data of the racetrack betting market in the Japan\nRacing Association (JRA). As the number of votes t increases, the win bet\nfraction x(t) converges to the final win bet fraction x_{f}. We observe the\npower law $(x(t)-x_{f})^{2} \\propto t^{-\\beta}$ with $\\beta\\simeq 0.488$. We\nmeasure the degree of the completeness of the ordering of the horses using an\nindex AR, the horses are ranked according to the size of the win bet fraction.\nAR(t) also obeys the power law and behaves as\n$\\mbox{AR}_{f}-\\mbox{AR}(t)\\propto t^{-\\gamma}$ with $\\gamma\\simeq 0.589$,\nwhere AR_{f} is the final value of AR. We introduce a simple voting model with\ntwo types of voters-independent and herding. Independent voters provide\ninformation about the winning probability of the horses and herding voters\ndecide their votes based on the popularities of the horses.This model can\nexplain two power laws of the betting process. The component ratio of the\nindependent voter to the herding voter is 1:3. \n\n"}
{"id": "1007.2818", "contents": "Title: Pluralistic Modeling of Complex Systems Abstract: The modeling of complex systems such as ecological or socio-economic systems\ncan be very challenging. Although various modeling approaches exist, they are\ngenerally not compatible and mutually consistent, and empirical data often do\nnot allow one to decide what model is the right one, the best one, or most\nappropriate one. Moreover, as the recent financial and economic crisis shows,\nrelying on a single, idealized model can be very costly. This contribution\ntries to shed new light on problems that arise when complex systems are\nmodeled. While the arguments can be transferred to many different systems, the\nrelated scientific challenges are illustrated for social, economic, and traffic\nsystems. The contribution discusses issues that are sometimes overlooked and\ntries to overcome some frequent misunderstandings and controversies of the\npast. At the same time, it is highlighted how some long-standing scientific\npuzzles may be solved by considering non-linear models of heterogeneous agents\nwith spatio-temporal interactions. As a result of the analysis, it is concluded\nthat a paradigm shift towards a pluralistic or possibilistic modeling approach,\nwhich integrates multiple world views, is overdue. In this connection, it is\nargued that it can be useful to combine many different approaches to obtain a\ngood picture of reality, even though they may be inconsistent. Finally, it is\nidentified what would be profitable areas of collaboration between the\nsocio-economic, natural, and engineering sciences. \n\n"}
{"id": "1007.4014", "contents": "Title: Low Surface Brightness Galaxies in the SDSS: the link between\n  environment, star-forming properties and AGN Abstract: Using the Sloan Digital Sky Survey (SDSS) data release 4 (DR 4), we\ninvestigate the spatial distribution of low and high surface brightness\ngalaxies (LSBGs and HSBGs, respectively). In particular, we focus our attention\non the influence of interactions between galaxies on the star formation\nstrength in the redshift range $0.01 < z < 0.1$. With cylinder counts and\nprojected distance to the first and fifth-nearest neighbor as environment\ntracers, we find that LSBGs tend to have a lack of companions compared to HSBGs\nat small scales ($<2$ Mpc). Regarding the interactions, we have evidence that\nthe fraction of LSBGs with strong star formation activity increases when the\ndistance between pairs of galaxies ($r_{p}$) is smaller than about four times\nthe Petrosian radius ($r_{90}$) of one of the components. Our results suggest\nthat, rather than being a condition for their formation, the isolation of LSBGs\nis more connected with their survival and evolution. The effect of the\ninteraction on the star formation strength, measured by the average value of\nthe birthrate parameter $b$, seems to be stronger for HSBGs than for LSBGs. The\nanalysis of our population of LSBGs and HSBGs hosting an AGN show that,\nregardless of the mass range, the fraction of LSBGs having an AGN is lower than\nthe corresponding fraction of HSBGs with an AGN. Also, we observe that the\nfraction of HSBGs and LSBGs having an AGN increases with the bulge luminosity.\nThese results, and those concerning the star-forming properties of LSBGs as a\nfunction of the environment, fit with the scenario proposed by some authors\nwhere, below a given threshold of surface mass density, low surface brightness\ndisks are unable to propagate instabilities, preventing the formation and\nevolution of massive black holes in the centers of LSBGs. \n\n"}
{"id": "1008.0073", "contents": "Title: Noise Can Reduce Disorder in Chaotic Dynamics Abstract: We evoke the idea of representation of the chaotic attractor by the set of\nunstable periodic orbits and disclose a novel noise-induced ordering\nphenomenon. For long unstable periodic orbits forming the strange attractor the\nweights (or natural measure) is generally highly inhomogeneous over the set,\neither diminishing or enhancing the contribution of these orbits into system\ndynamics. We show analytically and numerically a weak noise to reduce this\ninhomogeneity and, additionally to obvious perturbing impact, make a\nregularizing influence on the chaotic dynamics. This universal effect is rooted\ninto the nature of deterministic chaos. \n\n"}
{"id": "1008.0077", "contents": "Title: Universality of attractors at weak dissipation and particles\n  distribution in turbulence Abstract: We study stationary solutions to the continuity equation for weakly\ncompressible flows. These describe non-equilibrium steady states of weakly\ndissipative dynamical systems. Compressibility is a singular perturbation that\nchanges the steady state density from a constant \"microcanonical\" distribution\ninto a singular multifractal measure supported on the \"strange attractor\". We\nintroduce a representation of the latter and show that the space-averaged\nproperties are described universally by a log-normal distribution determined by\na single structure function. The spectrum of fractal dimensions is derived.\nApplication to the problem of distribution of particles in turbulence gives\ntestable predictions for real turbulence and stresses the role of pressure\nfluctuations. \n\n"}
{"id": "1008.1639", "contents": "Title: Calibration and validation of models describing the spatiotemporal\n  evolution of congested traffic patterns Abstract: We propose a quantitative approach for calibrating and validating key\nfeatures of traffic instabilities based on speed time series obtained from\naggregated data of a series of neighboring stationary detectors. We apply the\nproposed criteria to historic traffic databases of several freeways in Germany\ncontaining about 400 occurrences of congestions thereby providing a reference\nfor model calibration and quality assessment with respect to the spatiotemporal\ndynamics. First tests with microscopic and macroscopic models indicate that the\ncriteria are both robust and discriminative, i.e., clearly distinguishes\nbetween models of higher and lower predictive power. \n\n"}
{"id": "1008.3146", "contents": "Title: Exact Localization and Superresolution with Noisy Data and Random\n  Illumination Abstract: This paper studies the problem of exact localization of sparse (point or\nextended) objects with noisy data. The crux of the proposed approach consists\nof random illumination. Several recovery methods are analyzed: the Lasso, BPDN\nand the One-Step Thresholding (OST). For independent random probes, it is shown\nthat both recovery methods can localize exactly $s=\\cO(m)$, up to a logarithmic\nfactor, objects where $m$ is the number of data. Moreover, when the number of\nrandom probes is large the Lasso with random illumination has a performance\nguarantee for superresolution, beating the Rayleigh resolution limit. Numerical\nevidence confirms the predictions and indicates that the performance of the\nLasso is superior to that of the OST for the proposed set-up with random\nillumination. \n\n"}
{"id": "1008.3935", "contents": "Title: Noise-enhanced trapping in chaotic scattering Abstract: We show that noise enhances the trapping of trajectories in scattering\nsystems. In fully chaotic systems, the decay rate can decrease with increasing\nnoise due to a generic mismatch between the noiseless escape rate and the value\npredicted by the Liouville measure of the exit set. In Hamiltonian systems with\nmixed phase space we show that noise leads to a slower algebraic decay due to\ntrajectories performing a random walk inside Kolmogorov-Arnold-Moser islands.\nWe argue that these noise-enhanced trapping mechanisms exist in most scattering\nsystems and are likely to be dominant for small noise intensities, which is\nconfirmed through a detailed investigation in the Henon map. Our results can be\ntested in fluid experiments, affect the fractal Weyl's law of quantum systems,\nand modify the estimations of chemical reaction rates based on phase-space\ntransition state theory. \n\n"}
{"id": "1008.4686", "contents": "Title: Data analysis recipes: Fitting a model to data Abstract: We go through the many considerations involved in fitting a model to data,\nusing as an example the fit of a straight line to a set of points in a\ntwo-dimensional plane. Standard weighted least-squares fitting is only\nappropriate when there is a dimension along which the data points have\nnegligible uncertainties, and another along which all the uncertainties can be\ndescribed by Gaussians of known variance; these conditions are rarely met in\npractice. We consider cases of general, heterogeneous, and arbitrarily\ncovariant two-dimensional uncertainties, and situations in which there are bad\ndata (large outliers), unknown uncertainties, and unknown but expected\nintrinsic scatter in the linear relationship being fit. Above all we emphasize\nthe importance of having a \"generative model\" for the data, even an approximate\none. Once there is a generative model, the subsequent fitting is non-arbitrary\nbecause the model permits direct computation of the likelihood of the\nparameters or the posterior probability distribution. Construction of a\nposterior probability distribution is indispensible if there are \"nuisance\nparameters\" to marginalize away. \n\n"}
{"id": "1010.0210", "contents": "Title: An Operator--like Description of Love Affairs Abstract: We adopt the so--called \\emph{occupation number representation}, originally\nused in quantum mechanics and recently considered in the description of stock\nmarkets, in the analysis of the dynamics of love relations. We start with a\nsimple model, involving two actors (Alice and Bob): in the linear case we\nobtain periodic dynamics, whereas in the nonlinear regime either periodic or\nquasiperiodic solutions are found. Then we extend the model to a love triangle\ninvolving Alice, Bob and a third actress, Carla. Interesting features appear,\nand in particular we find analytical conditions for the linear model of love\ntriangle to have periodic or quasiperiodic solutions. Numerical solutions are\nexhibited in the nonlinear case. \n\n"}
{"id": "1010.1953", "contents": "Title: Passive Supporters of Terrorism and Phase Transitions Abstract: We discuss some social contagion processes to describe the formation and\nspread of radical opinions. The dynamics of opinion spread involves local\nthreshold processes as well as mean field effects. We calculate and observe\nphase transitions in the dynamical variables resulting in a rapidly increasing\nnumber of passive supporters. This strongly indicates that military solutions\nare inappropriate. \n\n"}
{"id": "1010.4088", "contents": "Title: Generalized Clustering Coefficients and Milgram Condition for q-th\n  Degrees of Separation Abstract: We introduce a series of generalized clustering coefficients based on String\nformalism given by Aoyama, using adjacent matrix in networks. We numerically\nevaluate Milgram condition proposed in order to explore q-th degrees of\nseparation in scale free networks and small world networks. We find that scale\nfree network with exponent 3 just shows 6-degrees of separation. Moreover we\nfind some relations between separation numbers and generalized clustering\ncoefficient in both networks. \n\n"}
{"id": "1010.4971", "contents": "Title: Correlated couplings and robustness of coupled networks Abstract: Most real-world complex systems can be modelled by coupled networks with\nmultiple layers. How and to what extent the pattern of couplings between\nnetwork layers may influence the interlaced structure and function of coupled\nnetworks are not clearly understood. Here we study the impact of correlated\ninter-layer couplings on the network robustness of coupled networks using\npercolation concept. We found that the positive correlated inter-layer coupling\nenhaces network robustness in the sense that it lowers the percolation\nthreshold of the interlaced network than the negative correlated coupling case.\nAt the same time, however, positive inter-layer correlation leads to smaller\ngiant component size in the well-connected region, suggesting potential\ndisadvantage for network connectivity, as demonstrated also with some\nreal-world coupled network structures. \n\n"}
{"id": "1010.5907", "contents": "Title: An investigation into the Multiple Optimised Parameter Estimation and\n  Data compression algorithm Abstract: We investigate the use of the Multiple Optimised Parameter Estimation and\nData compression algorithm (MOPED) for data compression and faster evaluation\nof likelihood functions. Since MOPED only guarantees maintaining the Fisher\nmatrix of the likelihood at a chosen point, multimodal and some degenerate\ndistributions will present a problem. We present examples of scenarios in which\nMOPED does faithfully represent the true likelihood but also cases in which it\ndoes not. Through these examples, we aim to define a set of criteria for which\nMOPED will accurately represent the likelihood and hence may be used to obtain\na significant reduction in the time needed to calculate it. These criteria may\ninvolve the evaluation of the full likelihood function for comparison. \n\n"}
{"id": "1010.6054", "contents": "Title: Spectral properties of two-body random matrix ensembles for boson\n  systems with spin Abstract: For $m$ number of bosons, carrying spin ($\\cs=\\spin$) degree of freedom, in\n$\\Omega$ number of single particle orbitals, each doubly degenerate, we\nintroduce and analyze embedded Gaussian orthogonal ensemble of random matrices\ngenerated by random two-body interactions that are spin ($S$) scalar\n[BEGOE(2)-$\\cs$]. Embedding algebra for the BEGOE(2)-$\\cs$ ensemble and also\nfor BEGOE(1+2)-$\\cs$ that includes the mean-field one-body part is $U(2\\Omega)\n\\supset U(\\Omega) \\otimes SU(2)$ with SU(2) generating spin. A method for\nconstructing the ensembles in fixed-($m,S$) spaces has been developed.\nNumerical calculations show that for BEGOE(2)-$\\cs$, the fixed-$(m,S)$ density\nof states is close to Gaussian and level fluctuations follow GOE in the dense\nlimit. For BEGOE(1+2)-$\\cs$, generically there is Poisson to GOE transition in\nlevel fluctuations as the interaction strength (measured in the units of the\naverage spacing of the single particle levels defining the mean-field) is\nincreased. The interaction strength needed for the onset of the transition is\nfound to decrease with increasing $S$. Covariances in energy centroids and\nspectral variances are analyzed. Propagation formula is derived for the\nvariance propagator for the fixed-$(m,S)$ ensemble averaged spectral variances.\nVariance propagator clearly shows, by applying the Jacquod and Stone\nprescription, that the BEGOE(2)-$\\cs$ ensemble generates ground states with\nspin $S=S_{max}$. This is further corroborated by analyzing the structure of\nthe ground states in the presence of the exchange interaction $\\hat{S}^2$ in\nBEGOE(1+2)-$\\cs$. Natural spin ordering is also observed with random\ninteractions. Going beyond these, we also introduce pairing symmetry in the\nspace defined by BEGOE(2)-$\\cs$. Expectation values of the pairing Hamiltonian\nshow that random interactions exhibit pairing correlations in the ground state\nregion. \n\n"}
{"id": "1011.0944", "contents": "Title: Irreversible Aggregation and Network Renormalization Abstract: Irreversible aggregation is revisited in view of recent work on\nrenormalization of complex networks. Its scaling laws and phase transitions are\nrelated to percolation transitions seen in the latter. We illustrate our points\nby giving the complete solution for the probability to find any given state in\nan aggregation process $(k+1)X\\to X$, given a fixed number of unit mass\nparticles in the initial state. Exactly the same probability distributions and\nscaling are found in one dimensional systems (a trivial network) and well-mixed\nsolutions. This reveals that scaling laws found in renormalization of complex\nnetworks do not prove that they are self-similar. \n\n"}
{"id": "1011.3686", "contents": "Title: Eigenfunction entropy and spectral compressibility for critical random\n  matrix ensembles Abstract: Based on numerical and perturbation series arguments we conjecture that for\ncertain critical random matrix models the information dimension of\neigenfunctions D_1 and the spectral compressibility chi are related by the\nsimple equation chi+D_1/d=1, where d is the system dimensionality. \n\n"}
{"id": "1012.0206", "contents": "Title: Catastrophic Cascade of Failures in Interdependent Networks Abstract: Modern network-like systems are usually coupled in such a way that failures\nin one network can affect the entire system. In infrastructures, biology,\nsociology, and economy, systems are interconnected and events taking place in\none system can propagate to any other coupled system. Recent studies on such\ncoupled systems show that the coupling increases their vulnerability to random\nfailure. Properties for interdependent networks differ significantly from those\nof single-network systems. In this article, these results are reviewed and the\nmain properties discussed. \n\n"}
{"id": "1012.1269", "contents": "Title: Identification of overlapping communities and their hierarchy by locally\n  calculating community-changing resolution levels Abstract: We propose a new local, deterministic and parameter-free algorithm that\ndetects fuzzy and crisp overlapping communities in a weighted network and\nsimultaneously reveals their hierarchy. Using a local fitness function, the\nalgorithm greedily expands natural communities of seeds until the whole graph\nis covered. The hierarchy of communities is obtained analytically by\ncalculating resolution levels at which communities grow rather than numerically\nby testing different resolution levels. This analytic procedure is not only\nmore exact than its numerical alternatives such as LFM and GCE but also much\nfaster. Critical resolution levels can be identified by searching for intervals\nin which large changes of the resolution do not lead to growth of communities.\nWe tested our algorithm on benchmark graphs and on a network of 492 papers in\ninformation science. Combined with a specific post-processing, the algorithm\ngives much more precise results on LFR benchmarks with high overlap compared to\nother algorithms and performs very similar to GCE. \n\n"}
{"id": "1012.2985", "contents": "Title: Scale-dependent non-Gaussianities in the WMAP data as identified by\n  using surrogates and scaling indices Abstract: We present a model-independent investigation of the WMAP data with respect to\nscale- dependent non-Gaussianities (NGs) by employing the method of constrained\nrandomization. For generating so-called surrogate maps a shuffling scheme is\napplied to the Fourier phases of the original data, which allows to test for\nthe presence of higher order correlations (HOCs) on well-defined scales. Using\nscaling indices as test statistics we find highly significant signatures for\nnon-Gaussianities when considering all scales. We test for NGs in the bands l =\n[2,20], l = [20,60], l = [60,120] and l = [120,300]. We find highly significant\nsignatures for non-Gaussianities and ecliptic hemispherical asymmetries for l =\n[2, 20]. We also obtain highly significant deviations from Gaussianity for the\nband l = [120,300]. The result for the full l-range can be interpreted as a\nsuperposition of the signatures found in the bands l = [2, 20] and l = [120,\n300]. We find remarkably similar results when analyzing different ILC-like\nmaps. We perform a set of tests to investigate if the detected anomalies can be\nexplained by systematics. While no test can convincingly rule out the intrinsic\nnature of the anomalies for the low l case, the ILC map making procedure and/or\nresidual noise in the maps can also lead to NGs at small scales. Our\ninvestigations prove that there are phase correlations in the WMAP data of the\nCMB. In the absence of an explanation in terms of Galactic foregrounds or known\nsystematic artefacts, the signatures at low l must so far be taken to be\ncosmological at high significance. These findings strongly disagree with\npredictions of isotropic cosmologies with single field slow roll inflation. The\ntask is now to elucidate the origin of the phase correlations and to understand\nthe physical processes leading to these scale-dependent non-Gaussianities - if\nsystematics as cause for them must be ruled out. \n\n"}
{"id": "1012.3793", "contents": "Title: A robust ranking algorithm to spamming Abstract: Ranking problem of web-based rating system has attracted many attentions. A\ngood ranking algorithm should be robust against spammer attack. Here we\nproposed a correlation based reputation algorithm to solve the ranking problem\nof such rating systems where user votes some objects with ratings. In this\nalgorithm, reputation of user is iteratively determined by the correlation\ncoefficient between his/her rating vector and the corresponding objects'\nweighted average rating vector. Comparing with iterative refinement (IR) and\nmean score algorithm, results for both artificial and real data indicate that,\nthe present algorithm shows a higher robustness against spammer attack. \n\n"}
{"id": "1012.4913", "contents": "Title: An Open-Source Microscopic Traffic Simulator Abstract: We present the interactive Java-based open-source traffic simulator available\nat www.traffic-simulation.de. In contrast to most closed-source commercial\nsimulators, the focus is on investigating fundamental issues of traffic\ndynamics rather than simulating specific road networks. This includes testing\ntheories for the spatiotemporal evolution of traffic jams, comparing and\ntesting different microscopic traffic models, modeling the effects of driving\nstyles and traffic rules on the efficiency and stability of traffic flow, and\ninvestigating novel ITS technologies such as adaptive cruise control,\ninter-vehicle and vehicle-infrastructure communication. \n\n"}
{"id": "1012.5314", "contents": "Title: Rescaling citations of publications in physics Abstract: We analyze the citation distributions of all papers published in Physical\nReview journals between 1985 and 2009. The average number of citations received\nby papers published in a given year and in a given field is computed. Large\nvariations are found, showing that it is not fair to compare citation numbers\nacross fields and years. However, when a rescaling procedure by the average is\nused, it is possible to compare impartially articles across years and fields.\nWe make the rescaling factors available for use by the readers. We also show\nthat rescaling citation numbers by the number of publication authors has strong\neffects and should therefore be taken into account when assessing the\nbibliometric performance of researchers. \n\n"}
{"id": "1101.0788", "contents": "Title: Valued Ties Tell Fewer Lies: Why Not To Dichotomize Network Edges With\n  Thresholds Abstract: In order to conduct analyses of networked systems where connections between\nindividuals take on a range of values - counts, continuous strengths or ordinal\nrankings - a common technique is to dichotomize the data according to their\npositions with respect to a threshold value. However, there are two issues to\nconsider: how the results of the analysis depend on the choice of threshold,\nand what role the presence of noise has on a system with respect to a fixed\nthreshold value. We show that while there are principled criteria of keeping\ninformation from the valued graph in the dichotomized version, they produce\nsuch a wide range of binary graphs that only a fraction of the relevant\ninformation will be kept. Additionally, while dichotomization of predictors in\nlinear models has a known asymptotic efficiency loss, the same process applied\nto network edges in a time series model will lead to an efficiency loss that\ngrows larger as the network increases in size. \n\n"}
{"id": "1101.1042", "contents": "Title: The Accelerating Growth of Online Tagging Systems Abstract: Research on the growth of online tagging systems not only is interesting in\nits own right, but also yields insights for website management and semantic web\nanalysis. Traditional models that describing the growth of online systems can\nbe divided between linear and nonlinear versions. Linear models, including the\nBA model (Brabasi and Albert, 1999), assume that the average activity of users\nis a constant independent of population. Hence the total activity is a linear\nfunction of population. On the contrary, nonlinear models suggest that the\naverage activity is affected by the size of the population and the total\nactivity is a nonlinear function of population. In the current study,\nsupporting evidences for the nonlinear growth assumption are obtained from data\non Internet users' tagging behavior. A power law relationship between the\nnumber of new tags (F) and the population (P), which can be expressed as F ~ P\n^ gamma (gamma > 1), is found. I call this pattern accelerating growth and find\nit relates the to time-invariant heterogeneity in individual activities. I also\nshow how a greater heterogeneity leads to a faster growth. \n\n"}
{"id": "1101.3122", "contents": "Title: Digital herders and phase transition in a voting model Abstract: In this paper, we discuss a voting model with two candidates, C_1 and C_2. We\nset two types of voters--herders and independents. The voting of independent\nvoters is based on their fundamental values; on the other hand, the voting of\nherders is based on the number of votes. Herders always select the majority of\nthe previous $r$ votes, which is visible to them. We call them digital herders.\nWe can accurately calculate the distribution of votes for special cases. When\nr>=3, we find that a phase transition occurs at the upper limit of t, where t\nis the discrete time (or number of votes). As the fraction of herders\nincreases, the model features a phase transition beyond which a state where\nmost voters make the correct choice coexists with one where most of them are\nwrong. On the other hand, when r<3, there is no phase transition. In this case,\nthe herders' performance is the same as that of the independent voters.\nFinally, we recognize the behavior of human beings by conducting simple\nexperiments. \n\n"}
{"id": "1101.3765", "contents": "Title: Reduced basis catalogs for gravitational wave templates Abstract: We introduce a reduced basis approach as a new paradigm for modeling,\nrepresenting and searching for gravitational waves. We construct waveform\ncatalogs for non-spinning compact binary coalescences, and we find that for\naccuracies of 99% and 99.999% the method generates a factor of about $10-10^5$\nfewer templates than standard placement methods. The continuum of gravitational\nwaves can be represented by a finite and comparatively compact basis. The\nmethod is robust under variations in the noise of detectors, implying that only\na single catalog needs to be generated. \n\n"}
{"id": "1102.0876", "contents": "Title: Fixation and escape times in stochastic game learning Abstract: Evolutionary dynamics in finite populations is known to fixate eventually in\nthe absence of mutation. We here show that a similar phenomenon can be found in\nstochastic game dynamical batch learning, and investigate fixation in learning\nprocesses in a simple 2x2 game, for two-player games with cyclic interaction,\nand in the context of the best-shot network game. The analogues of finite\npopulations in evolution are here finite batches of observations between\nstrategy updates. We study when and how such fixation can occur, and present\nresults on the average time-to-fixation from numerical simulations. Simple\ncases are also amenable to analytical approaches and we provide estimates of\nthe behaviour of so-called escape times as a function of the batch size. The\ndifferences and similarities with escape and fixation in evolutionary dynamics\nare discussed. \n\n"}
{"id": "1102.1402", "contents": "Title: Trends in Social Media : Persistence and Decay Abstract: Social media generates a prodigious wealth of real-time content at an\nincessant rate. From all the content that people create and share, only a few\ntopics manage to attract enough attention to rise to the top and become\ntemporal trends which are displayed to users. The question of what factors\ncause the formation and persistence of trends is an important one that has not\nbeen answered yet. In this paper, we conduct an intensive study of trending\ntopics on Twitter and provide a theoretical basis for the formation,\npersistence and decay of trends. We also demonstrate empirically how factors\nsuch as user activity and number of followers do not contribute strongly to\ntrend creation and its propagation. In fact, we find that the resonance of the\ncontent with the users of the social network plays a major role in causing\ntrends. \n\n"}
{"id": "1103.1243", "contents": "Title: Randomizing world trade. I. A binary network analysis Abstract: The international trade network (ITN) has received renewed multidisciplinary\ninterest due to recent advances in network theory. However, it is still unclear\nwhether a network approach conveys additional, nontrivial information with\nrespect to traditional international-economics analyses that describe world\ntrade only in terms of local (first-order) properties. In this and in a\ncompanion paper, we employ a recently proposed randomization method to assess\nin detail the role that local properties have in shaping higher-order patterns\nof the ITN in all its possible representations (binary/weighted,\ndirected/undirected, aggregated/disaggregated by commodity) and across several\nyears. Here we show that, remarkably, the properties of all binary projections\nof the network can be completely traced back to the degree sequence, which is\ntherefore maximally informative. Our results imply that explaining the observed\ndegree sequence of the ITN, which has not received particular attention in\neconomic theory, should instead become one the main focuses of models of trade. \n\n"}
{"id": "1103.2634", "contents": "Title: Strong and weak chaos in weakly nonintegrable many-body Hamiltonian\n  systems Abstract: We study properties of chaos in generic one-dimensional nonlinear Hamiltonian\nlattices comprised of weakly coupled nonlinear oscillators, by numerical\nsimulations of continuous-time systems and symplectic maps. For small coupling,\nthe measure of chaos is found to be proportional to the coupling strength and\nlattice length, with the typical maximal Lyapunov exponent being proportional\nto the square root of coupling. This strong chaos appears as a result of\ntriplet resonances between nearby modes. In addition to strong chaos we observe\na weakly chaotic component having much smaller Lyapunov exponent, the measure\nof which drops approximately as a square of the coupling strength down to\nsmallest couplings we were able to reach. We argue that this weak chaos is\nlinked to the regime of fast Arnold diffusion discussed by Chirikov and\nVecheslavov. In disordered lattices of large size we find a subdiffusive\nspreading of initially localized wave packets over larger and larger number of\nmodes. The relations between the exponent of this spreading and the exponent in\nthe dependence of the fast Arnold diffusion on coupling strength are analyzed.\nWe also trace parallels between the slow spreading of chaos and deterministic\nrheology. \n\n"}
{"id": "1103.2854", "contents": "Title: A program for the Bayesian Neural Network in the ROOT framework Abstract: We present a Bayesian Neural Network algorithm implemented in the TMVA\npackage, within the ROOT framework. Comparing to the conventional utilization\nof Neural Network as discriminator, this new implementation has more advantages\nas a non-parametric regression tool, particularly for fitting probabilities. It\nprovides functionalities including cost function selection, complexity control\nand uncertainty estimation. An example of such application in High Energy\nPhysics is shown. The algorithm is available with ROOT release later than 5.29. \n\n"}
{"id": "1103.3196", "contents": "Title: Condensation phase transition in nonlinear fitness networks Abstract: We analyze the condensation phase transitions in out-of-equilibrium complex\nnetworks in a unifying framework which includes the nonlinear model and the\nfitness model as its appropriate limits. We show a novel phase structure which\ndepends on both the fitness parameter and the nonlinear exponent. The\noccurrence of the condensation phase transitions in the dynamical evolution of\nthe network is demonstrated by using Bianconi-Barabasi method. We find that the\nnonlinear and the fitness preferential attachment mechanisms play important\nroles in formation of an interesting phase structure. \n\n"}
{"id": "1103.4536", "contents": "Title: Extensive and Sub-Extensive Chaos in Globally-Coupled Dynamical Systems Abstract: Using a combination of analytical and numerical techniques, we show that\nchaos in globally-coupled identical dynamical systems, be they dissipative or\nHamiltonian, is both extensive and sub-extensive: their spectrum of Lyapunov\nexponents is asymptotically flat (thus extensive) at the value $\\lambda_0$\ngiven by a single unit forced by the mean-field, but sandwiched between\nsub-extensive bands containing typically $\\mathcal{O}(\\log N)$ exponents whose\nvalues vary as $\\lambda \\simeq \\lambda_\\infty + c/\\log N$ with $\\lambda_\\infty\n\\neq \\lambda_0$. \n\n"}
{"id": "1103.5027", "contents": "Title: Google matrix of the world trade network Abstract: Using the United Nations Commodity Trade Statistics Database\n[http://comtrade.un.org/db/] we construct the Google matrix of the world trade\nnetwork and analyze its properties for various trade commodities for all\ncountries and all available years from 1962 to 2009. The trade flows on this\nnetwork are classified with the help of PageRank and CheiRank algorithms\ndeveloped for the World Wide Web and other large scale directed networks. For\nthe world trade this ranking treats all countries on equal democratic grounds\nindependent of country richness. Still this method puts at the top a group of\nindustrially developed countries for trade in {\\it all commodities}. Our study\nestablishes the existence of two solid state like domains of rich and poor\ncountries which remain stable in time, while the majority of countries are\nshown to be in a gas like phase with strong rank fluctuations. A simple random\nmatrix model provides a good description of statistical distribution of\ncountries in two-dimensional rank plane. The comparison with usual ranking by\nexport and import highlights new features and possibilities of our approach. \n\n"}
{"id": "1103.5231", "contents": "Title: Leaders in Social Networks, the Delicious Case Abstract: Finding pertinent information is not limited to search engines. Online\ncommunities can amplify the influence of a small number of power users for the\nbenefit of all other users. Users' information foraging in depth and breadth\ncan be greatly enhanced by choosing suitable leaders. For instance in\ndelicious.com, users subscribe to leaders' collection which lead to a deeper\nand wider reach not achievable with search engines. To consolidate such\ncollective search, it is essential to utilize the leadership topology and\nidentify influential users. Google's PageRank, as a successful search algorithm\nin the World Wide Web, turns out to be less effective in networks of people. We\nthus devise an adaptive and parameter-free algorithm, the LeaderRank, to\nquantify user influence. We show that LeaderRank outperforms PageRank in terms\nof ranking effectiveness, as well as robustness against manipulations and noisy\ndata. These results suggest that leaders who are aware of their clout may\nreinforce the development of social networks, and thus the power of collective\nsearch. \n\n"}
{"id": "1104.0186", "contents": "Title: Reconciling long-term cultural diversity and short-term collective\n  social behavior Abstract: An outstanding open problem is whether collective social phenomena occurring\nover short timescales can systematically reduce cultural heterogeneity in the\nlong run, and whether offline and online human interactions contribute\ndifferently to the process. Theoretical models suggest that short-term\ncollective behavior and long-term cultural diversity are mutually excluding,\nsince they require very different levels of social influence. The latter\njointly depends on two factors: the topology of the underlying social network\nand the overlap between individuals in multidimensional cultural space.\nHowever, while the empirical properties of social networks are well understood,\nlittle is known about the large-scale organization of real societies in\ncultural space, so that random input specifications are necessarily used in\nmodels. Here we use a large dataset to perform a high-dimensional analysis of\nthe scientific beliefs of thousands of Europeans. We find that inter-opinion\ncorrelations determine a nontrivial ultrametric hierarchy of individuals in\ncultural space, a result unaccessible to one-dimensional analyses and in\nstriking contrast with random assumptions. When empirical data are used as\ninputs in models, we find that ultrametricity has strong and counterintuitive\neffects, especially in the extreme case of long-range online-like interactions\nbypassing social ties. On short time-scales, it strongly facilitates a\nsymmetry-breaking phase transition triggering coordinated social behavior. On\nlong time-scales, it severely suppresses cultural convergence by restricting it\nwithin disjoint groups. We therefore find that, remarkably, the empirical\ndistribution of individuals in cultural space appears to optimize the\ncoexistence of short-term collective behavior and long-term cultural diversity,\nwhich can be realized simultaneously for the same moderate level of mutual\ninfluence. \n\n"}
{"id": "1104.1435", "contents": "Title: Anomalous scaling in the random-force-driven Burgers equation: A Monte\n  Carlo study Abstract: We present a new approach to determine numerically the statistical behavior\nof small-scale structures in hydrodynamic turbulence. Starting from the\nfunctional integral representation of the random-force-driven Burgers equation\nwe show that Monte Carlo simulations allow us to determine the anomalous\nscaling of high-order moments of velocity differences. Given the general\napplicability of Monte Carlo methods, this opens up the possibility to address\nalso other systems relevant to turbulence within this framework. \n\n"}
{"id": "1104.2404", "contents": "Title: Automatic anomaly detection in high energy collider data Abstract: We address the problem of automatic anomaly detection in high energy collider\ndata. Our approach is based on the random generation of analytic expressions\nfor kinematical variables, which can then be evolved following a genetic\nprogramming procedure to enhance their discriminating power. We apply this\napproach to three concrete scenarios to demonstrate its possible usefulness,\nboth as a detailed check of reference Monte-Carlo simulations and as a model\nindependent tool for the detection of New Physics signatures. \n\n"}
{"id": "1104.3248", "contents": "Title: Signal Classification for Acoustic Neutrino Detection Abstract: This article focuses on signal classification for deep-sea acoustic neutrino\ndetection. In the deep sea, the background of transient signals is very\ndiverse. Approaches like matched filtering are not sufficient to distinguish\nbetween neutrino-like signals and other transient signals with similar\nsignature, which are forming the acoustic background for neutrino detection in\nthe deep-sea environment. A classification system based on machine learning\nalgorithms is analysed with the goal to find a robust and effective way to\nperform this task. For a well-trained model, a testing error on the level of\none percent is achieved for strong classifiers like Random Forest and Boosting\nTrees using the extracted features of the signal as input and utilising dense\nclusters of sensors instead of single sensors. \n\n"}
{"id": "1104.3590", "contents": "Title: An efficient and principled method for detecting communities in networks Abstract: A fundamental problem in the analysis of network data is the detection of\nnetwork communities, groups of densely interconnected nodes, which may be\noverlapping or disjoint. Here we describe a method for finding overlapping\ncommunities based on a principled statistical approach using generative network\nmodels. We show how the method can be implemented using a fast, closed-form\nexpectation-maximization algorithm that allows us to analyze networks of\nmillions of nodes in reasonable running times. We test the method both on\nreal-world networks and on synthetic benchmarks and find that it gives results\ncompetitive with previous methods. We also show that the same approach can be\nused to extract nonoverlapping community divisions via a relaxation method, and\ndemonstrate that the algorithm is competitively fast and accurate for the\nnonoverlapping problem. \n\n"}
{"id": "1104.3668", "contents": "Title: Evolution of collision numbers for a chaotic gas dynamics Abstract: We put forward a conjecture of recurrence for a gas of hard spheres that\ncollide elastically in a finite volume. The dynamics consists of a sequence of\ninstantaneous binary collisions. We study how the numbers of collisions of\ndifferent pairs of particles grow as functions of time. We observe that these\nnumbers can be represented as a time-integral of a function on the phase space.\nAssuming the results of the ergodic theory apply, we describe the evolution of\nthe numbers by an effective Langevin dynamics. We use the facts that hold for\nthese dynamics with probability one, in order to establish properties of a\nsingle trajectory of the system. We find that for any triplet of particles\nthere will be an infinite sequence of moments of time, when the numbers of\ncollisions of all three different pairs of the triplet will be equal. Moreover,\nany value of difference of collision numbers of pairs in the triplet will\nrepeat indefinitely. On the other hand, for larger number of pairs there is but\na finite number of repetitions. Thus the ergodic theory produces a limitation\non the dynamics. \n\n"}
{"id": "1105.0812", "contents": "Title: Compression of Flow Can Reveal Overlapping-Module Organization in\n  Networks Abstract: To better understand the overlapping modular organization of large networks\nwith respect to flow, here we introduce the map equation for overlapping\nmodules. In this information-theoretic framework, we use the correspondence\nbetween compression and regularity detection. The generalized map equation\nmeasures how well we can compress a description of flow in the network when we\npartition it into modules with possible overlaps. When we minimize the\ngeneralized map equation over overlapping network partitions, we detect modules\nthat capture flow and determine which nodes at the boundaries between modules\nshould be classified in multiple modules and to what degree. With a novel\ngreedy search algorithm, we find that some networks, for example, the neural\nnetwork of C. Elegans, are best described by modules dominated by hard\nboundaries, but that others, for example, the sparse European road network,\nhave a highly overlapping modular organization. \n\n"}
{"id": "1105.2137", "contents": "Title: Semi-Markov Graph Dynamics Abstract: In this paper, we outline a model of graph (or network) dynamics based on two\ningredients. The first ingredient is a Markov chain on the space of possible\ngraphs. The second ingredient is a semi-Markov counting process of renewal\ntype. The model consists in subordinating the Markov chain to the semi-Markov\ncounting process. In simple words, this means that the chain transitions occur\nat random time instants called epochs. The model is quite rich and its possible\nconnections with algebraic geometry are briefly discussed. Moreover, for the\nsake of simplicity, we focus on the space of undirected graphs with a fixed\nnumber of nodes. However, in an example, we present an interbank market model\nwhere it is meaningful to use directed graphs or even weighted graphs. \n\n"}
{"id": "1105.3041", "contents": "Title: A Bayesian approach to evaluate confidence intervals in counting\n  experiments with background Abstract: In this paper we propose a procedure to evaluate Bayesian confidence\nintervals in counting experiments where both signal and background fluctuations\nare described by the Poisson statistics. The results obtained when the method\nis applied to the calculation of upper limits will also be illustrated. \n\n"}
{"id": "1105.3265", "contents": "Title: Epidemic spreading with immunization on bipartite networks Abstract: Bipartite networks are composed of two types of nodes and there are no links\nbetween nodes of the same type. Thus the study of epidemic spread and control\non such networks is relevant to sexually transmitted diseases (STDs). When\nentire populations of two types cannot be immunized and the effect of\nimmunization is not perfect, we have to consider the targeted immunization with\nimmunization rates. We derive the epidemic thresholds of SIR and SIS models\nwith immunization and illustrate the results with STDs on heterosexual contact\nnetworks. \n\n"}
{"id": "1105.4479", "contents": "Title: Return probability and k-step measures Abstract: The notion of return probability -- explored most famously by George\nP\\'{o}lya on d-dimensional lattices -- has potential as a measure for the\nanalysis of networks. We present an efficient method for finding return\nprobability distributions for connected undirected graphs. We argue that return\nprobability has the same discriminatory power as existing k-step measures -- in\nparticular, beta centrality (with negative beta), the graph-theoretical power\nindex (GPI), and subgraph centrality. We compare the running time of our\nalgorithm to beta centrality and subgraph centrality and find that it is\nsignificantly faster. When return probability is used to measure the same\nphenomena as beta centrality, it runs in linear time -- O(n+m), where n and m\nare the number of nodes and edges, respectively -- which takes much less time\nthan either the matrix inversion or the sequence of matrix multiplications\nrequired for calculating the exact or approximate forms of beta centrality,\nrespectively. We call this form of return probability the P\\'{o}lya power index\n(PPI). Computing subgraph centrality requires an expensive eigendecomposition\nof the adjacency matrix; return probability runs in half the time of the\neigendecomposition on a 2000-node network. These performance improvements are\nimportant because computationally efficient measures are necessary in order to\nanalyze large networks. \n\n"}
{"id": "1105.4965", "contents": "Title: Evolution of scaling emergence in large-scale spatial epidemic spreading Abstract: Background: Zipf's law and Heaps' law are two representatives of the scaling\nconcepts, which play a significant role in the study of complexity science. The\ncoexistence of the Zipf's law and the Heaps' law motivates different\nunderstandings on the dependence between these two scalings, which is still\nhardly been clarified.\n  Methodology/Principal Findings: In this article, we observe an evolution\nprocess of the scalings: the Zipf's law and the Heaps' law are naturally shaped\nto coexist at the initial time, while the crossover comes with the emergence of\ntheir inconsistency at the larger time before reaching a stable state, where\nthe Heaps' law still exists with the disappearance of strict Zipf's law. Such\nfindings are illustrated with a scenario of large-scale spatial epidemic\nspreading, and the empirical results of pandemic disease support a universal\nanalysis of the relation between the two laws regardless of the biological\ndetails of disease. Employing the United States(U.S.) domestic air\ntransportation and demographic data to construct a metapopulation model for\nsimulating the pandemic spread at the U.S. country level, we uncover that the\nbroad heterogeneity of the infrastructure plays a key role in the evolution of\nscaling emergence.\n  Conclusions/Significance: The analyses of large-scale spatial epidemic\nspreading help understand the temporal evolution of scalings, indicating the\ncoexistence of the Zipf's law and the Heaps' law depends on the collective\ndynamics of epidemic processes, and the heterogeneity of epidemic spread\nindicates the significance of performing targeted containment strategies at the\nearly time of a pandemic disease. \n\n"}
{"id": "1105.5344", "contents": "Title: Partitioning Breaks Communities Abstract: Considering a clique as a conservative definition of community structure, we\nexamine how graph partitioning algorithms interact with cliques. Many popular\ncommunity-finding algorithms partition the entire graph into non-overlapping\ncommunities. We show that on a wide range of empirical networks, from different\ndomains, significant numbers of cliques are split across the separate\npartitions produced by these algorithms. We then examine the largest connected\ncomponent of the subgraph formed by retaining only edges in cliques, and apply\npartitioning strategies that explicitly minimise the number of cliques split.\nWe further examine several modern overlapping community finding algorithms, in\nterms of the interaction between cliques and the communities they find, and in\nterms of the global overlap of the sets of communities they find. We conclude\nthat, due to the connectedness of many networks, any community finding\nalgorithm that produces partitions must fail to find at least some significant\nstructures. Moreover, contrary to traditional intuition, in some empirical\nnetworks, strong ties and cliques frequently do cross community boundaries;\nmuch community structure is fundamentally overlapping and unpartitionable in\nnature. \n\n"}
{"id": "1105.5488", "contents": "Title: Coarse-Grained Topology Estimation via Graph Sampling Abstract: Many online networks are measured and studied via sampling techniques, which\ntypically collect a relatively small fraction of nodes and their associated\nedges. Past work in this area has primarily focused on obtaining a\nrepresentative sample of nodes and on efficient estimation of local graph\nproperties (such as node degree distribution or any node attribute) based on\nthat sample. However, less is known about estimating the global topology of the\nunderlying graph.\n  In this paper, we show how to efficiently estimate the coarse-grained\ntopology of a graph from a probability sample of nodes. In particular, we\nconsider that nodes are partitioned into categories (e.g., countries or\nwork/study places in OSNs), which naturally defines a weighted category graph.\nWe are interested in estimating (i) the size of categories and (ii) the\nprobability that nodes from two different categories are connected. For each of\nthe above, we develop a family of estimators for design-based inference under\nuniform or non-uniform sampling, employing either of two measurement\nstrategies: induced subgraph sampling, which relies only on information about\nthe sampled nodes; and star sampling, which also exploits category information\nabout the neighbors of sampled nodes. We prove consistency of these estimators\nand evaluate their efficiency via simulation on fully known graphs. We also\napply our methodology to a sample of Facebook users to obtain a number of\ncategory graphs, such as the college friendship graph and the country\nfriendship graph; we share and visualize the resulting data at\nwww.geosocialmap.com. \n\n"}
{"id": "1105.6005", "contents": "Title: Analysis of KATRIN data using Bayesian inference Abstract: The KATRIN (KArlsruhe TRItium Neutrino) experiment will be analyzing the\ntritium beta-spectrum to determine the mass of the neutrino with a sensitivity\nof 0.2 eV (90% C.L.). This approach to a measurement of the absolute value of\nthe neutrino mass relies only on the principle of energy conservation and can\nin some sense be called model-independent as compared to cosmology and\nneutrino-less double beta decay. However by model independent we only mean in\ncase of the minimal extension of the standard model. One should therefore also\nanalyse the data for non-standard couplings to e.g. righthanded or sterile\nneutrinos. As an alternative to the frequentist minimization methods used in\nthe analysis of the earlier experiments in Mainz and Troitsk we have been\ninvestigating Markov Chain Monte Carlo (MCMC) methods which are very well\nsuited for probing multi-parameter spaces. We found that implementing the\nKATRIN chi squared function in the COSMOMC package - an MCMC code using\nBayesian parameter inference - solved the task at hand very nicely. \n\n"}
{"id": "1106.3107", "contents": "Title: An Iterative, Dynamically Stabilized(IDS) Method of Data Unfolding Abstract: We describe an iterative unfolding method for experimental data, making use\nof a regularization function. The use of this function allows one to build an\nimproved normalization procedure for Monte Carlo spectra, unbiased by the\npresence of possible new structures in data. We unfold, in a dynamically stable\nway, data spectra which can be strongly affected by fluctuations in the\nbackground subtraction and simultaneously reconstruct structures which were not\ninitially simulated. \n\n"}
{"id": "1106.5898", "contents": "Title: Perturbation approach to multifractal dimensions for certain critical\n  random matrix ensembles Abstract: Fractal dimensions of eigenfunctions for various critical random matrix\nensembles are investigated in perturbation series in the regimes of strong and\nweak multifractality. In both regimes we obtain expressions similar to those of\nthe critical banded random matrix ensemble extensively discussed in the\nliterature. For certain ensembles, the leading-order term for weak\nmultifractality can be calculated within standard perturbation theory. For\nother models such a direct approach requires modifications which are briefly\ndiscussed. Our analytical formulas are in good agreement with numerical\ncalculations. \n\n"}
{"id": "1107.1900", "contents": "Title: Behavior patterns of online users and the effect on information\n  filtering Abstract: Understanding the structure and evolution of web-based user-object bipartite\nnetworks is an important task since they play a fundamental role in online\ninformation filtering. In this paper, we focus on investigating the patterns of\nonline users' behavior and the effect on recommendation process. Empirical\nanalysis on the e-commercial systems show that users have significant taste\ndiversity and their interests for niche items highly overlap. Additionally,\nrecommendation process are investigated on both the real networks and the\nreshuffled networks in which real users' behavior patterns can be gradually\ndestroyed. Our results shows that the performance of personalized\nrecommendation methods is strongly related to the real network structure.\nDetail study on each item shows that recommendation accuracy for hot items is\nalmost maximum and quite robust to the reshuffling process. However, niche\nitems cannot be accurately recommended after removing users' behavior patterns.\nOur work also is meaningful in practical sense since it reveals an effective\ndirection to improve the accuracy and the robustness of the existing\nrecommender systems. \n\n"}
{"id": "1107.3974", "contents": "Title: The use of statistical methods for the search for new physics at the LHC\n  (in Russian) Abstract: We review statistical methods used for the search for new physics at LHC. \n\n"}
{"id": "1107.5266", "contents": "Title: Identifying Overlapping and Hierarchical Thematic Structures in Networks\n  of Scholarly Papers: A Comparison of Three Approaches Abstract: We implemented three recently proposed approaches to the identification of\noverlapping and hierarchical substructures in graphs and applied the\ncorresponding algorithms to a network of 492 information-science papers coupled\nvia their cited sources. The thematic substructures obtained and overlaps\nproduced by the three hierarchical cluster algorithms were compared to a\ncontent-based categorisation, which we based on the interpretation of titles\nand keywords. We defined sets of papers dealing with three topics located on\ndifferent levels of aggregation: h-index, webometrics, and bibliometrics. We\nidentified these topics with branches in the dendrograms produced by the three\ncluster algorithms and compared the overlapping topics they detected with one\nanother and with the three pre-defined paper sets. We discuss the advantages\nand drawbacks of applying the three approaches to paper networks in research\nfields. \n\n"}
{"id": "1108.0662", "contents": "Title: The Physics of Mergers: Theoretical and Statistical Techniques Applied\n  to Stellar Mergers in Dense Star Clusters Abstract: (abridged) This thesis presents theoretical and statistical techniques\nbroadly related to systems of dynamically-interacting particles composed of\nseveral different types of populations. They are applied to observations of\ndense star clusters (SCs) in order to study gravitational interactions between\nstars. We present a new analytic method of quantifying the frequency of\nencounters involving single, binary and triple stars. With this technique, we\nhave shown that dynamical encounters involving triple stars occur commonly in\nat least some SCs, and that they are likely to be an important dynamical\nchannel for stellar mergers to occur. We have also used our techniques to\nanalyze observational data for a large sample of SCs taken from the ACS Survey\nfor Globular Clusters. The results of this analysis are as follows: (1) We have\ncompiled a homogeneous catalogue of stellar populations for every cluster in\nour sample, including main-sequence (MS), red giant branch, horizontal branch\nand blue straggler (BS) stars. (2) With this catalogue, we have quantified the\neffects of the cluster dynamics in determining the relative sizes and spatial\ndistributions of these stellar populations. (3) These results are particularly\ninteresting for BSs since they provide compelling evidence that they are\ndescended from binary stars. (4) Our analysis of the MS populations is\nconsistent with a remarkably universal initial stellar mass function in old\nmassive SCs in the Milky Way. This is a new result with important implications\nfor our understanding of star formation in the early Universe and, more\ngenerally, the history of our Galaxy. Finally, we describe how our techniques\nare ideally suited for application to a number of other outstanding puzzles of\nmodern astrophysics, including chemical reactions in the interstellar medium\nand mergers between galaxies in galaxy clusters. \n\n"}
{"id": "1108.1158", "contents": "Title: Beyond Fisher: exact sampling distributions of the maximum-likelihood\n  estimator in gravitational-wave parameter estimation Abstract: Gravitational-wave astronomers often wish to characterize the expected\nparameter-estimation accuracy of future observations. The Fisher matrix\nprovides a lower bound on the spread of the maximum-likelihood estimator across\nnoise realizations, as well as the leading-order width of the posterior\nprobability, but it is limited to high signal strengths often not realized in\npractice. By contrast, Monte Carlo Bayesian inference provides the full\nposterior for any signal strength, but it is too expensive to repeat for a\nrepresentative set of noises. Here I describe an efficient semianalytical\ntechnique to map the exact sampling distribution of the maximum-likelihood\nestimator across noise realizations, for any signal strength. This technique\ncan be applied to any estimation problem for signals in additive Gaussian\nnoise. \n\n"}
{"id": "1108.2760", "contents": "Title: A mathematical review on the multiple-solution problem Abstract: The recent multiple-solution problem in extracting physics information from a\nfit to the experimental data in high energy physics is reviewed in a\nmathematical viewpoint. All these multiple solutions were found via a fit\nprocess previously, while in this letter we prove that if the sum of two\ncoherent Breit-Wigner functions is used to fit the measured distribution, there\nshould be two and only two non-trivial solutions, and they are related to each\nother by analytical formulae. For real experimental measurements in more\ncomplicated situations, we also provide a numerical method to derive the other\nsolution from the already obtained one. The excellent consistency between the\nexact solution obtained this way and the fit process justifies the method. From\nour results it is clear that the physics interpretation should be very\ndifferent depending on which solution is selected. So we suggest that all the\nexperimental measurements with potential multiple solutions be re-analyzed to\nfind the other solution because the result is not complete if only one solution\nis reported. \n\n"}
{"id": "1108.3074", "contents": "Title: Selectivity in Probabilistic Causality: Drawing Arrows from Inputs to\n  Stochastic Outputs Abstract: Given a set of several inputs into a system (e.g., independent variables\ncharacterizing stimuli) and a set of several stochastically non-independent\noutputs (e.g., random variables describing different aspects of responses), how\ncan one determine, for each of the outputs, which of the inputs it is\ninfluenced by? The problem has applications ranging from modeling pairwise\ncomparisons to reconstructing mental processing architectures to conjoint\ntesting. A necessary and sufficient condition for a given pattern of selective\ninfluences is provided by the Joint Distribution Criterion, according to which\nthe problem of \"what influences what\" is equivalent to that of the existence of\na joint distribution for a certain set of random variables. For inputs and\noutputs with finite sets of values this criterion translates into a test of\nconsistency of a certain system of linear equations and inequalities (Linear\nFeasibility Test) which can be performed by means of linear programming. The\nJoint Distribution Criterion also leads to a metatheoretical principle for\ngenerating a broad class of necessary conditions (tests) for diagrams of\nselective influences. Among them is the class of distance-type tests based on\nthe observation that certain functionals on jointly distributed random\nvariables satisfy triangle inequality. \n\n"}
{"id": "1108.4646", "contents": "Title: Antipersistent dynamics in kinetic models of wealth exchange Abstract: We investigate the detailed dynamics of gains and losses made by agents in\nsome kinetic models of wealth exchange. The concept of a walk in an abstract\ngain-loss space for the agents had been introduced in an earlier work. For\nmodels in which agents do not save, or save with uniform saving propensity,\nthis walk has diffusive behavior. In case the saving propensity $\\lambda$ is\ndistributed randomly ($0 \\leq \\lambda < 1$), the resultant walk showed a\nballistic nature (except at a particular value of $\\lambda^* \\approx 0.47$).\nHere we consider several other features of the walk with random $\\lambda$.\nWhile some macroscopic properties of this walk are comparable to a biased\nrandom walk, at microscopic level, there are gross differences. The difference\nturns out to be due to an antipersistent tendency towards making a gain (loss)\nimmediately after making a loss (gain). This correlation is in fact present in\nkinetic models without saving or with uniform saving as well, such that the\ncorresponding walks are not identical to ordinary random walks. In the\ndistributed saving case, antipersistence occurs with a simultaneous overall\nbias. \n\n"}
{"id": "1109.0839", "contents": "Title: Percolation on correlated random networks Abstract: We consider a class of random, weighted networks, obtained through a\nredefinition of patterns in an Hopfield-like model and, by performing\npercolation processes, we get information about topology and resilience\nproperties of the networks themselves. Given the weighted nature of the graphs,\ndifferent kinds of bond percolation can be studied: stochastic (deleting links\nrandomly) and deterministic (deleting links based on rank weights), each\nmimicking a different physical process. The evolution of the network is\naccordingly different, as evidenced by the behavior of the largest component\nsize and of the distribution of cluster sizes. In particular, we can derive\nthat weak ties are crucial in order to maintain the graph connected and that,\nwhen they are the most prone to failure, the giant component typically shrinks\nwithout abruptly breaking apart; these results have been recently evidenced in\nseveral kinds of social networks. \n\n"}
{"id": "1109.2475", "contents": "Title: Statistical Physics for Humanities: A Tutorial Abstract: The image of physics is connected with simple \"mechanical\" deterministic\nevents: that an apple always falls down, that force equals mass times\nacceleleration. Indeed, applications of such concept to social or historical\nproblems go back two centuries (population growth and stabilisation, by Malthus\nand by Verhulst) and use \"differential equations\", as recently revierwed by\nVitanov and Ausloos [2011]. However, since even today's computers cannot follow\nthe motion of all air molecules within one cubic centimeter, the probabilistic\napproach has become fashionable since Ludwig Boltzmann invented Statistical\nPhysics in the 19th century. Computer simulations in Statistical Physics deal\nwith single particles, a method called agent-based modelling in fields which\nadopted it later. Particularly simple are binary models where each particle has\nonly two choices, called spin up and spin down by physicists, bit zero and bit\none by computer scientists, and voters for the Republicans or for the Democrats\nin American politics (where one human is simulated as one particle).\nNeighbouring particles may influence each other, and the Ising model of 1925 is\nthe best-studied example of such models. This text will explain to the reader\nhow to program the Ising model on a square lattice (in Fortran language);\nstarting from there the readers can build their own computer programs. Some\napplications of Statistical Physics outside the natural sciences will be\nlisted. \n\n"}
{"id": "1109.3208", "contents": "Title: A decision between Bayesian and Frequentist upper limit in analyzing\n  continuous Gravitational Waves Abstract: Given the sensitivity of current ground-based Gravitational Wave (GW)\ndetectors, any continuous-wave signal we can realistically expect will be at a\nlevel or below the background noise. Hence, any data analysis of detector data\nwill need to rely on statistical techniques to separate the signal from the\nnoise. While with the current sensitivity of our detectors we do not expect to\ndetect any true GW signals in our data, we can still set upper limits (UL) on\ntheir amplitude. These upper limits, in fact, tell us how weak a signal\nstrength we would detect. In setting upper limit using two popular method,\nBayesian and Frequentist, there is always the question of a realistic results.\nIn this paper, we try to give an estimate of how realistically we can set the\nupper limit using the above mentioned methods. And if any, which one is\npreferred for our future data analysis work. \n\n"}
{"id": "1109.3627", "contents": "Title: Roulette-wheel selection via stochastic acceptance Abstract: Roulette-wheel selection is a frequently used method in genetic and\nevolutionary algorithms or in modeling of complex networks. Existing routines\nselect one of N individuals using search algorithms of O(N) or O(log(N))\ncomplexity. We present a simple roulette-wheel selection algorithm, which\ntypically has O(1) complexity and is based on stochastic acceptance instead of\nsearching. We also discuss a hybrid version, which might be suitable for highly\nheterogeneous weight distributions, found, for example, in some models of\ncomplex networks. With minor modifications, the algorithm might also be used\nfor sampling with fitness cut-off at a certain value or for sampling without\nreplacement. \n\n"}
{"id": "1109.3911", "contents": "Title: Benefits of Bias: Towards Better Characterization of Network Sampling Abstract: From social networks to P2P systems, network sampling arises in many\nsettings. We present a detailed study on the nature of biases in network\nsampling strategies to shed light on how best to sample from networks. We\ninvestigate connections between specific biases and various measures of\nstructural representativeness. We show that certain biases are, in fact,\nbeneficial for many applications, as they \"push\" the sampling process towards\ninclusion of desired properties. Finally, we describe how these sampling biases\ncan be exploited in several, real-world applications including disease outbreak\ndetection and market research. \n\n"}
{"id": "1109.4305", "contents": "Title: Strategy of Competition between Two Groups based on a Contrarian Opinion\n  Model Abstract: We introduce a contrarian opinion (CO) model in which a fraction p of\ncontrarians within a group holds a strong opinion opposite to the opinion held\nby the rest of the group. At the initial stage, stable clusters of two\nopinions, A and B exist. Then we introduce contrarians which hold a strong B\nopinion into the opinion A group. Through their interactions, the contrarians\nare able to decrease the size of the largest A opinion cluster, and even\ndestroy it. We see this kind of method in operation, e.g when companies send\nfree new products to potential customers in order to convince them to adopt the\nproduct and influence others. We study the CO model, using two different\nstrategies, on both ER and scale-free networks. In strategy I, the contrarians\nare positioned at random. In strategy II, the contrarians are chosen to be the\nhighest degrees nodes. We find that for both strategies the size of the largest\nA cluster decreases to zero as p increases as in a phase transition. At a\ncritical threshold value p_c the system undergoes a second-order phase\ntransition that belongs to the same universality class of mean field\npercolation. We find that even for an ER type model, where the degrees of the\nnodes are not so distinct, strategy II is significantly more effctive in\nreducing the size of the largest A opinion cluster and, at very small values of\np, the largest A opinion cluster is destroyed. \n\n"}
{"id": "1109.4521", "contents": "Title: Controlling centrality in complex networks Abstract: Spectral centrality measures allow to identify influential individuals in\nsocial groups, to rank Web pages by their popularity, and even to determine the\nimpact of scientific researches. The centrality score of a node within a\nnetwork crucially depends on the entire pattern of connections, so that the\nusual approach is to compute the node centralities once the network structure\nis assigned. We face here with the inverse problem, that is, we study how to\nmodify the centrality scores of the nodes by acting on the structure of a given\nnetwork. We prove that there exist particular subsets of nodes, called\ncontrolling sets, which can assign any prescribed set of centrality values to\nall the nodes of a graph, by cooperatively tuning the weights of their\nout-going links. We show that many large networks from the real world have\nsurprisingly small controlling sets, containing even less than 5-10% of the\nnodes. These results suggest that rankings obtained from spectral centrality\nmeasures have to be considered with extreme care, since they can be easily\ncontrolled and even manipulated by a small group of nodes acting in a\ncoordinated way. \n\n"}
{"id": "1109.5720", "contents": "Title: SLPA: Uncovering Overlapping Communities in Social Networks via A\n  Speaker-listener Interaction Dynamic Process Abstract: Overlap is one of the characteristics of social networks, in which a person\nmay belong to more than one social group. For this reason, discovering\noverlapping structures is necessary for realistic social analysis. In this\npaper, we present a novel, general framework to detect and analyze both\nindividual overlapping nodes and entire communities. In this framework, nodes\nexchange labels according to dynamic interaction rules. A specific\nimplementation called Speaker-listener Label Propagation Algorithm (SLPA1)\ndemonstrates an excellent performance in identifying both overlapping nodes and\noverlapping communities with different degrees of diversity. \n\n"}
{"id": "1109.6211", "contents": "Title: Editorial process in scientific journals: analysis and modeling Abstract: The editorial handling of papers in scientific journals as a human activity\nprocess is considered. Using recently proposed approaches of human dynamics\ntheory we examine the probability distributions of random variables reflecting\nthe temporal characteristics of studied processes. The first part of this paper\ncontains our results of analysis of the real data about papers published in\nscientific journals. The second part is devoted to modeling of time-series\nconnected with editorial work. The purpose of our work is to present new object\nthat can be studied in terms of human dynamics theory and to corroborate the\nscientometrical application of the results obtained. \n\n"}
{"id": "1109.6452", "contents": "Title: Chaos in the Hamiltonian mean field model Abstract: We study the dynamical properties of the canonical ordered phase of the\nHamiltonian mean-field (HMF) model, in which $N$ particles, globally-coupled\nvia pairwise attractive interactions, form a rotating cluster. Using a\ncombination of numerical and analytical arguments, we first show that the\nlargest Lyapunov exponent remains strictly positive in the infinite-size limit,\nconverging to its asymptotic value with $1/\\ln N$ corrections. We then\nelucidate the scaling laws ruling the behavior of this asymptotic value in the\ncritical region separating the ordered, clustered phase and the disordered\nphase present at high energy densities. We also show that the full spectrum of\nLyapunov exponents consists of a bulk component converging to the (zero) value\ntaken by a test oscillator forced by the mean field, plus subextensive bands of\n${\\cal O}(\\ln N)$ exponents taking finite values. We finally investigate the\nrobustness of these results by studying a \"2D\" extension of the HMF model where\neach particle is endowed with 4 degrees of freedom, thus allowing the emergence\nof chaos at the level of single particle. Altogether, these results illustrate\nthe subtle effects of global (or long-range) coupling, and the importance of\nthe order in which the infinite-time and infinite-size limits are taken: for an\ninfinite-size HMF system represented by the Vlasov equation, no chaos is\npresent, while chaos exists and subsists for any finite system size. \n\n"}
{"id": "1109.6834", "contents": "Title: Dynamics of threads and polymers in turbulence: power-law distributions\n  and synchronization Abstract: We study the behavior of threads and polymers in a turbulent flow. These\nobjects have finite spatial extension, so the flow along them differs slightly.\nThe corresponding drag forces produce a finite average stretching and the\nthread is stretched most of the time. Nevertheless, the probability of\nshrinking fluctuations is significant and is known to decay only as a\npower-law. We show that the exponent of the power law is a universal number\nindependent of the statistics of the flow. For polymers the coil-stretch\ntransition exists: the flow must have a sufficiently large Lyapunov exponent to\novercome the elastic resistance and stretch the polymer from the coiled state\nit takes otherwise. The probability of shrinking from the stretched state above\nthe transition again obeys a power law but with a non-universal exponent. We\nshow that well above the transition the exponent becomes universal and derive\nthe corresponding expression. Furthermore, we demonstrate synchronization: the\nend-to-end distances of threads or polymers above the transition are\nsynchronized by the flow and become identical. Thus, the transition from\nNewtonian to non-Newtonian behavior in dilute polymer solutions can be seen as\nan ordering transition. \n\n"}
{"id": "1110.0176", "contents": "Title: Universal behavior of extreme value statistics for selected observables\n  of dynamical systems Abstract: The main results of the extreme value theory developed for the investigation\nof the observables of dynamical systems rely, up to now, on the Gnedenko\napproach. In this framework, extremes are basically identified with the block\nmaxima of the time series of the chosen observable, in the limit of infinitely\nlong blocks. It has been proved that, assuming suitable mixing conditions for\nthe underlying dynamical systems, the extremes of a specific class of\nobservables are distributed according to the so called Generalized Extreme\nValue (GEV) distribution. Direct calculations show that in the case of\nquasi-periodic dynamics the block maxima are not distributed according to the\nGEV distribution. In this paper we show that, in order to obtain a universal\nbehaviour of the extremes, the requirement of a mixing dynamics can be relaxed\nif the Pareto approach is used, based upon considering the exceedances over a\ngiven threshold. Requiring that the invariant measure locally scales with a\nwell defined exponent - the local dimension -, we show that the limiting\ndistribution for the exceedances of the observables previously studied with the\nGnedenko approach is a Generalized Pareto distribution where the parameters\ndepends only on the local dimensions and the value of the threshold. This\nresult allows to extend the extreme value theory for dynamical systems to the\ncase of regular motions. We also provide connections with the results obtained\nwith the Gnedenko approach. In order to provide further support to our\nfindings, we present the results of numerical experiments carried out\nconsidering the well-known Chirikov standard map. \n\n"}
{"id": "1110.1432", "contents": "Title: A Sparse Semi-Blind Source Identification Method and Its Application to\n  Raman Spectroscopy for Explosives Detection Abstract: Rapid and reliable detection and identification of unknown chemical\nsubstances is critical to homeland security. It is challenging to identify\nchemical components from a wide range of explosives. There are two key steps\ninvolved. One is a nondestructive and informative spectroscopic technique for\ndata acquisition. The other is an associated library of reference features\nalong with a computational method for feature matching and meaningful detection\nwithin or beyond the library.\n  Recently several experimental techniques based on Raman scattering have been\ndeveloped to perform standoff detection and identification of explosives, and\nthey prove to be successful under certain idealized conditions. However data\nanalysis is limited to standard least squares method assuming the complete\nknowledge of the chemical components. In this paper, we develop a new iterative\nmethod to identify unknown substances from mixture samples of Raman\nspectroscopy. In the first step, a constrained least squares method decomposes\nthe data into a sum of linear combination of the known components and a\nnon-negative residual. In the second step, a sparse and convex blind source\nseparation method extracts components geometrically from the residuals.\nVerification based on the library templates or expert knowledge helps to\nconfirm these components. If necessary, the confirmed meaningful components are\nfed back into step one to refine the residual and then step two extracts\npossibly more hidden components. The two steps may be iterated until no more\ncomponents can be identified.\n  We illustrate the proposed method in processing a set of the so called swept\nwavelength optical resonant Raman spectroscopy experimental data by a\nsatisfactory blind extraction of a priori unknown chemical explosives from\nmixture samples. \n\n"}
{"id": "1110.1625", "contents": "Title: Construction and description of the stationary measure of weakly\n  dissipative dynamical systems Abstract: We consider the stationary measure of the dissipative dynamical system in a\nfinite volume. A finite dissipation, however small, generally makes the measure\nsingular, while at zero dissipation the measure is constant. Thus dissipative\npart of the dynamics is a singular perturbation producing an infinite change in\nthe measure. This is a result of the infinite time of evolution that enhances\nthe small effects of dissipation to form singularities. We show how to deal\nwith the singularity of the perturbation and describe the statistics of the\nmeasure. We derive all the correlation functions and the statistics of \"mass\"\ncontained in a small ball. The spectrum of dimensions of the attractor is\nobtained. The fractal dimension is equal to the space dimension, while the\ninformation dimension is equal to the Kaplan-Yorke dimension. \n\n"}
{"id": "1110.3798", "contents": "Title: Studying Deeply Virtual Compton Scattering with Neural Networks Abstract: Neural networks are utilized to fit Compton form factor H to HERMES data on\ndeeply virtual Compton scattering off unpolarized protons. We used this result\nto predict the beam charge-spin assymetry for muon scattering off proton at the\nkinematics of the COMPASS II experiment. \n\n"}
{"id": "1110.3854", "contents": "Title: Consistency of community detection in networks under degree-corrected\n  stochastic block models Abstract: Community detection is a fundamental problem in network analysis, with\napplications in many diverse areas. The stochastic block model is a common tool\nfor model-based community detection, and asymptotic tools for checking\nconsistency of community detection under the block model have been recently\ndeveloped. However, the block model is limited by its assumption that all nodes\nwithin a community are stochastically equivalent, and provides a poor fit to\nnetworks with hubs or highly varying node degrees within communities, which are\ncommon in practice. The degree-corrected stochastic block model was proposed to\naddress this shortcoming and allows variation in node degrees within a\ncommunity while preserving the overall block community structure. In this paper\nwe establish general theory for checking consistency of community detection\nunder the degree-corrected stochastic block model and compare several community\ndetection criteria under both the standard and the degree-corrected models. We\nshow which criteria are consistent under which models and constraints, as well\nas compare their relative performance in practice. We find that methods based\non the degree-corrected block model, which includes the standard block model as\na special case, are consistent under a wider class of models and that\nmodularity-type methods require parameter constraints for consistency, whereas\nlikelihood-based methods do not. On the other hand, in practice, the degree\ncorrection involves estimating many more parameters, and empirically we find it\nis only worth doing if the node degrees within communities are indeed highly\nvariable. We illustrate the methods on simulated networks and on a network of\npolitical blogs. \n\n"}
{"id": "1110.6437", "contents": "Title: Anthropic decision theory Abstract: This paper sets out to resolve how agents ought to act in the Sleeping Beauty\nproblem and various related anthropic (self-locating belief) problems, not\nthrough the calculation of anthropic probabilities, but through finding the\ncorrect decision to make. It creates an anthropic decision theory (ADT) that\ndecides these problems from a small set of principles. By doing so, it\ndemonstrates that the attitude of agents with regards to each other (selfish or\naltruistic) changes the decisions they reach, and that it is very important to\ntake this into account. To illustrate ADT, it is then applied to two major\nanthropic problems and paradoxes, the Presumptuous Philosopher and Doomsday\nproblems, thus resolving some issues about the probability of human extinction. \n\n"}
{"id": "1111.2078", "contents": "Title: Exploring the Time Domain With Synoptic Sky Surveys Abstract: Synoptic sky surveys are becoming the largest data generators in astronomy,\nand they are opening a new research frontier, that touches essentially every\nfield of astronomy. Opening of the time domain to a systematic exploration will\nstrengthen our understanding of a number of interesting known phenomena, and\nmay lead to the discoveries of as yet unknown ones. We describe some lessons\nlearned over the past decade, and offer some ideas that may guide strategic\nconsiderations in planning and execution of the future synoptic sky surveys. \n\n"}
{"id": "1111.2304", "contents": "Title: Anomalous scaling in the random-force-driven Burgers equation: A Monte\n  Carlo study Abstract: We present a new approach to determine the small-scale statistical behavior\nof hydrodynamic turbulence by means of lattice simulations. Using the\nfunctional integral representation of the random-force-driven Burgers equation\nwe show that high-order moments of velocity differences satisfy anomalous\nscaling. The general applicability of Monte Carlo methods provides the\nopportunity to study also other systems of interest within this framework. \n\n"}
{"id": "1111.4123", "contents": "Title: 2D and 3D Polar Plume Analysis from the Three Vantage Positions of\n  STEREO/EUVI A, B, and SOHO/EIT Abstract: Polar plumes are seen as elongated objects starting at the solar polar\nregions. Here, we analyze these objects from a sequence of images taken\nsimultaneously by the three spacecraft telescopes STEREO/EUVI A and B, and\nSOHO/EIT. We establish a method capable of automatically identifying plumes in\nsolar EUV images close to the limb at 1.01 - 1.39 R in order to study their\ntemporal evolution. This plume-identification method is based on a multiscale\nHough-wavelet analysis. Then two methods to determined their 3D localization\nand structure are discussed: First, tomography using the filtered\nback-projection and including the differential rotation of the Sun and,\nsecondly, conventional stereoscopic triangulation. We show that tomography and\nstereoscopy are complementary to study polar plumes. We also show that this\nsystematic 2D identification and the proposed methods of 3D reconstruction are\nwell suited, on one hand, to identify plumes individually and on the other\nhand, to analyze the distribution of plumes and inter-plume regions. Finally,\nthe results are discussed focusing on the plume position with their\ncross-section area. \n\n"}
{"id": "1111.4503", "contents": "Title: The Anatomy of the Facebook Social Graph Abstract: We study the structure of the social graph of active Facebook users, the\nlargest social network ever analyzed. We compute numerous features of the graph\nincluding the number of users and friendships, the degree distribution, path\nlengths, clustering, and mixing patterns. Our results center around three main\nobservations. First, we characterize the global structure of the graph,\ndetermining that the social network is nearly fully connected, with 99.91% of\nindividuals belonging to a single large connected component, and we confirm the\n\"six degrees of separation\" phenomenon on a global scale. Second, by studying\nthe average local clustering coefficient and degeneracy of graph neighborhoods,\nwe show that while the Facebook graph as a whole is clearly sparse, the graph\nneighborhoods of users contain surprisingly dense structure. Third, we\ncharacterize the assortativity patterns present in the graph by studying the\nbasic demographic and network properties of users. We observe clear degree\nassortativity and characterize the extent to which \"your friends have more\nfriends than you\". Furthermore, we observe a strong effect of age on friendship\npreferences as well as a globally modular community structure driven by\nnationality, but we do not find any strong gender homophily. We compare our\nresults with those from smaller social networks and find mostly, but not\nentirely, agreement on common structural network characteristics. \n\n"}
{"id": "1111.5951", "contents": "Title: Orthogonal versus covariant Lyapunov vectors for rough hard disk systems Abstract: The Oseledec splitting of the tangent space into covariant subspaces for a\nhyperbolic dynamical system is numerically accessible by computing the full set\nof covariant Lyapunov vectors. In this paper, the covariant Lyapunov vectors,\nthe orthogonal Gram-Schmidt vectors, and the corresponding local\n(time-dependent) Lyapunov exponents, are analyzed for a planar system of rough\nhard disks (RHDS). These results are compared to respective results for a\nsmooth-hard-disk system (SHDS). We find that the rotation of the disks deeply\naffects the Oseledec splitting and the structure of the tangent space. For both\nthe smooth and rough hard disks, the stable, unstable and central manifolds are\ntransverse to each other, although the minimal angle between the unstable and\nstable manifolds of the RHDS typically is very small. Both systems are\nhyperbolic. However, the central manifold is precisely orthogonal to the rest\nof the tangent space only for the smooth-particle case and not for the rough\ndisks. We also demonstrate that the rotations destroy the Hamiltonian character\nfor the rough-hard-disk system. \n\n"}
{"id": "1112.2239", "contents": "Title: Absence of influential spreaders in rumor dynamics Abstract: Recent research [1] has suggested that coreness, and not degree, constitutes\na better topological descriptor to identifying influential spreaders in complex\nnetworks. This hypothesis has been verified in the context of disease\nspreading. Here, we instead focus on rumor spreading models, which are more\nsuited for social contagion and information propagation. To this end, we\nperform extensive computer simulations on top of several real-world networks\nand find opposite results. Namely, we show that the spreading capabilities of\nthe nodes do not depend on their $k$-core index, which instead determines\nwhether or not a given node prevents the diffusion of a rumor to a system-wide\nscale. Our findings are relevant both for sociological studies of contagious\ndynamics and for the design of efficient commercial viral processes. \n\n"}
{"id": "1112.4312", "contents": "Title: Multiscale Analysis of Spreading in a Large Communication Network Abstract: In temporal networks, both the topology of the underlying network and the\ntimings of interaction events can be crucial in determining how some dynamic\nprocess mediated by the network unfolds. We have explored the limiting case of\nthe speed of spreading in the SI model, set up such that an event between an\ninfectious and susceptible individual always transmits the infection. The speed\nof this process sets an upper bound for the speed of any dynamic process that\nis mediated through the interaction events of the network. With the help of\ntemporal networks derived from large scale time-stamped data on mobile phone\ncalls, we extend earlier results that point out the slowing-down effects of\nburstiness and temporal inhomogeneities. In such networks, links are not\npermanently active, but dynamic processes are mediated by recurrent events\ntaking place on the links at specific points in time. We perform a multi-scale\nanalysis and pinpoint the importance of the timings of event sequences on\nindividual links, their correlations with neighboring sequences, and the\ntemporal pathways taken by the network-scale spreading process. This is\nachieved by studying empirically and analytically different characteristic\nrelay times of links, relevant to the respective scales, and a set of temporal\nreference models that allow for removing selected time-domain correlations one\nby one. \n\n"}
{"id": "1112.6326", "contents": "Title: Chaotic Encryption Method Based on Life-Like Cellular Automata Abstract: We propose a chaotic encryption method based on Cellular Automata(CA),\nspecifically on the family called the \"Life-Like\" type. Thus, the encryption\nprocess lying on the pseudo-random numbers generated (PRNG) by each CA's\nevolution, which transforms the password as the initial conditions to encrypt\nmessages. Moreover, is explored the dynamical behavior of CA to reach a \"good\"\nquality as PRNG based on measures to quantify \"how chaotic a dynamical system\nis\", through the combination of the entropy, Lyapunov exponent, and Hamming\ndistance. Finally, we present the detailed security analysis based on\nexperimental tests: DIEHARD and ENT suites, as well as Fouriers Power Spectrum,\nused as a security criteria. \n\n"}
{"id": "1201.0347", "contents": "Title: Kappa-deformed random-matrix theory based on Kaniadakis statistics Abstract: We present a possible extension of the random-matrix theory, which is widely\nused to describe spectral fluctuations of chaotic systems. By considering the\nKaniadakis non-Gaussian statistics, characterized by the index {\\kappa}\n(Boltzmann-Gibbs entropy is recovered in the limit {\\kappa}\\rightarrow0), we\npropose the non-Gaussian deformations ({\\kappa} \\neq 0) of the conventional\northogonal and unitary ensembles of random matrices. The joint eigenvalue\ndistributions for the {\\kappa}-deformed ensembles are derived by applying the\nprinciple maximum entropy to Kaniadakis entropy. The resulting distribution\nfunctions are base invarient as they depend on the matrix elements in a trace\nform. Using these expressions, we introduce a new generalized form of the\nWigner surmise valid for nearly-chaotic mixed systems, where a\nbasis-independent description is still expected to hold. We motivate the\nnecessity of such generalization by the need to describe the transition of the\nspacing distribution from chaos to order, at least in the initial stage. We\nshow several examples about the use of the generalized Wigner surmise to the\nanalysis of the results of a number of previous experiments and numerical\nexperiments. Our results suggest the entropic index {\\kappa} as a measure for\ndeviation from the state of chaos. We also introduce a {\\kappa}-deformed\nPorter-Thomas distribution of transition intensities, which fits the\nexperimental data for mixed systems better than the commonly-used\ngamma-distribution. \n\n"}
{"id": "1201.0524", "contents": "Title: Election turnout statistics in many countries: similarities,\n  differences, and a diffusive field model for decision-making Abstract: We study in details the turnout rate statistics for 77 elections in 11\ndifferent countries. We show that the empirical results established in a\nprevious paper for French elections appear to hold much more generally. We find\nin particular that the spatial correlation of turnout rates decay\nlogarithmically with distance in all cases. This result is quantitatively\nreproduced by a decision model that assumes that each voter makes his mind as a\nresult of three influence terms: one totally idiosyncratic component, one\ncity-specific term with short-ranged fluctuations in space, and one long-ranged\ncorrelated field which propagates diffusively in space. A detailed analysis\nreveals several interesting features: for example, different countries have\ndifferent degrees of local heterogeneities and seem to be characterized by a\ndifferent propensity for individuals to conform to the cultural norm. We\nfurthermore find clear signs of herding (i.e. strongly correlated decisions at\nthe individual level) in some countries, but not in others. \n\n"}
{"id": "1201.2036", "contents": "Title: Hierarchical multiresolution method to overcome the resolution limit in\n  complex networks Abstract: The analysis of the modular structure of networks is a major challenge in\ncomplex networks theory. The validity of the modular structure obtained is\nessential to confront the problem of the topology-functionality relationship.\nRecently, several authors have worked on the limit of resolution that different\ncommunity detection algorithms have, making impossible the detection of natural\nmodules when very different topological scales coexist in the network. Existing\nmultiresolution methods are not the panacea for solving the problem in extreme\nsituations, and also fail. Here, we present a new hierarchical multiresolution\nscheme that works even when the network decomposition is very close to the\nresolution limit. The idea is to split the multiresolution method for optimal\nsubgraphs of the network, focusing the analysis on each part independently. We\nalso propose a new algorithm to speed up the computational cost of screening\nthe mesoscale looking for the resolution parameter that best splits every\nsubgraph. The hierarchical algorithm is able to solve a difficult benchmark\nproposed in [Lancichinetti & Fortunato, 2011], encouraging the further analysis\nof hierarchical methods based on the modularity quality function. \n\n"}
{"id": "1201.2514", "contents": "Title: Analytical properties of horizontal visibility graphs in the Feigenbaum\n  scenario Abstract: Time series are proficiently converted into graphs via the horizontal\nvisibility (HV) algorithm, which prompts interest in its capability for\ncapturing the nature of different classes of series in a network context. We\nhave recently shown [1] that dynamical systems can be studied from a novel\nperspective via the use of this method. Specifically, the period-doubling and\nband-splitting attractor cascades that characterize unimodal maps transform\ninto families of graphs that turn out to be independent of map nonlinearity or\nother particulars. Here we provide an in depth description of the HV treatment\nof the Feigenbaum scenario, together with analytical derivations that relate to\nthe degree distributions, mean distances, clustering coefficients, etc.,\nassociated to the bifurcation cascades and their accumulation points. We\ndescribe how the resultant families of graphs can be framed into a\nrenormalization group scheme in which fixed-point graphs reveal their scaling\nproperties. These fixed points are then re-derived from an entropy optimization\nprocess defined for the graph sets, confirming a suggested connection between\nrenormalization group and entropy optimization. Finally, we provide analytical\nand numerical results for the graph entropy and show that it emulates the\nLyapunov exponent of the map independently of its sign. \n\n"}
{"id": "1201.2793", "contents": "Title: On the Asymptotics of the Hopf Characteristic Function Abstract: We study the asymptotic behavior of the Hopf characteristic function of\nfractals and chaotic dynamical systems in the limit of large argument. The\nsmall argument behavior is determined by the moments, since the characteristic\nfunction is defined as their generating function. Less well known is that the\nlarge argument behavior is related to the fractal dimension. While this\nrelation has been discussed in the literature, there has been very little in\nthe way of explicit calculation. We attempt to fill this gap, with explicit\ncalculations for the generalized Cantor set and the Lorenz attractor. In the\ncase of the generalized Cantor set, we define a parameter characterizing the\nasymptotics which we show corresponds exactly to the known fractal dimension.\nThe Hopf characteristic function of the Lorenz attractor is computed\nnumerically, obtaining results which are consistent with Hausdorff or\ncorrelation dimension, albeit too crude to distinguish between them. \n\n"}
{"id": "1201.2885", "contents": "Title: The impact of hydrodynamic interactions on the preferential\n  concentration of inertial particles in turbulence Abstract: We consider a dilute gas of inertial particles transported by the turbulent\nflow. Due to inertia the particles concentrate preferentially outside vortices.\nThe pair-correlation function of the particles' concentration is known to obey\nat small separations a power-law with a negative exponent, if the hydrodynamic\ninteractions between the particles are neglected. The divergence at zero\nseparation is the signature of the random attractor asymptoted by the\nparticles' trajectories at large times. However the hydrodynamic interactions\nproduce a repulsion between the particles that is non-negligible at small\nseparations. We introduce equations governing the repulsion and show it\nsmoothens the singular attractor near the particles where the pair correlation\nfunction saturates. The effect is most essential at the Stokes number of order\none, where the correlations decrease by a factor of a few. \n\n"}
{"id": "1201.3617", "contents": "Title: SpartyJet 4.0 User's Manual Abstract: SpartyJet is a set of software tools for jet finding and analysis, built\naround the FastJet library of jet algorithms. SpartyJet provides four key\nextensions to FastJet: a simple Python interface to most FastJet features, a\npowerful framework for building up modular analyses, extensive input file\nhandling capabilities, and a graphical browser for viewing analysis output and\ncreating new on-the-fly analyses. Many of these capabilities rely on a\nROOT-based backend. Beyond finding jets, many jet tools in SpartyJet perform\nmeasurement of jet or event variables, available to subsequent tools and stored\nin the final output. SpartyJet can be downloaded from HepForge at\nhttp://projects.hepforge.org/spartyjet. \n\n"}
{"id": "1201.5142", "contents": "Title: Detection of a small shift in a broad distribution Abstract: Statistical methods for the extraction of a small shift in broad data\ndistributions are examined by means of Monte Carlo simulations. This work was\noriginally motivated by the CERN neutrino beam to Gran Sasso (CNGS) experiment\nfor which the OPERA detector collaboration reported a time shift in a broad\ndistribution with an accuracy of $\\pm 7.8\\,$ns, while the fluctuation of the\naverage time turns with $\\pm 23.8\\,$ns out to be much larger. Although the\nphysical result of a big shift has been withdrawn, statistical methods that\nmake an identification in a broad distribution with such a small error possible\nremain of interest. \n\n"}
{"id": "1201.5442", "contents": "Title: Dynamics of Magnetized Vortex Tubes in the Solar Chromosphere Abstract: We use 3D radiative MHD simulations to investigate the formation and dynamics\nof small-scale (less than 0.5 Mm in diameter) vortex tubes spontaneously\ngenerated by turbulent convection in quiet-Sun regions with initially weak mean\nmagnetic fields. The results show that the vortex tubes penetrate into the\nchromosphere and substantially affect the structure and dynamics of the solar\natmosphere. The vortex tubes are mostly concentrated in intergranular lanes and\nare characterized by strong (near sonic) downflows and swirling motions that\ncapture and twist magnetic field lines, forming magnetic flux tubes that expand\nwith height and which attain magnetic field strengths ranging from 200 G in the\nchromosphere to more than 1 kG in the photosphere. We investigate in detail the\nphysical properties of these vortex tubes, including thermodynamic properties,\nflow dynamics, and kinetic and current helicities, and conclude that magnetized\nvortex tubes provide an important path for energy and momentum transfer from\nthe convection zone into the chromosphere. \n\n"}
{"id": "1203.0535", "contents": "Title: On Facebook, most ties are weak Abstract: Pervasive socio-technical networks bring new conceptual and technological\nchallenges to developers and users alike. A central research theme is\nevaluation of the intensity of relations linking users and how they facilitate\ncommunication and the spread of information. These aspects of human\nrelationships have been studied extensively in the social sciences under the\nframework of the \"strength of weak ties\" theory proposed by Mark Granovetter.13\nSome research has considered whether that theory can be extended to online\nsocial networks like Facebook, suggesting interaction data can be used to\npredict the strength of ties. The approaches being used require handling\nuser-generated data that is often not publicly available due to privacy\nconcerns. Here, we propose an alternative definition of weak and strong ties\nthat requires knowledge of only the topology of the social network (such as who\nis a friend of whom on Facebook), relying on the fact that online social\nnetworks, or OSNs, tend to fragment into communities. We thus suggest\nclassifying as weak ties those edges linking individuals belonging to different\ncommunities and strong ties as those connecting users in the same community. We\ntested this definition on a large network representing part of the Facebook\nsocial graph and studied how weak and strong ties affect the\ninformation-diffusion process. Our findings suggest individuals in OSNs\nself-organize to create well-connected communities, while weak ties yield\ncohesion and optimize the coverage of information spread. \n\n"}
{"id": "1203.0853", "contents": "Title: Phase retrieval combined with digital holography Abstract: We present a new method for real- and complex-valued image reconstruction\nfrom two intensity measurements made in the Fourier plane: the Fourier\nmagnitude of the unknown image, and the intensity of the interference pattern\narising from superimposition of the original signal with a reference beam. This\napproach can provide significant advantages in digital holography since it\nposes less stringent requirements on the reference beam. In particular, it does\nnot require spatial separation between the sought signal and the reference\nbeam. Moreover, the reference beam need not be known precisely, and in fact,\nmay contain severe errors, without leading to a deterioration in the\nreconstruction quality. Numerical simulations are presented to demonstrate the\nspeed and quality of reconstruction. \n\n"}
{"id": "1203.1791", "contents": "Title: Effect of noise in open chaotic billiards Abstract: We investigate the effect of white-noise perturbations on chaotic\ntrajectories in open billiards. We focus on the temporal decay of the survival\nprobability for generic mixed-phase-space billiards. The survival probability\nhas a total of five different decay regimes that prevail for different\nintermediate times. We combine new calculations and recent results on noise\nperturbed Hamiltonian systems to characterize the origin of these regimes, and\nto compute how the parameters scale with noise intensity and billiard openness.\nNumerical simulations in the annular billiard support and illustrate our\nresults. \n\n"}
{"id": "1204.0084", "contents": "Title: Long-term fluctuations in globally coupled phase oscillators with\n  general coupling: Finite size effects Abstract: We investigate the diffusion coefficient of the time integral of the Kuramoto\norder parameter in globally coupled nonidentical phase oscillators. This\ncoefficient represents the deviation of the time integral of the order\nparameter from its mean value on the sample average. In other words, this\ncoefficient characterizes long-term fluctuations of the order parameter. For a\nsystem of N coupled oscillators, we introduce a statistical quantity D, which\ndenotes the product of N and the diffusion coefficient. We study the scaling\nlaw of D with respect to the system size N. In other well-known models such as\nthe Ising model, the scaling property of D is D \\sim O(1) for both coherent and\nincoherent regimes except for the transition point. In contrast, in the\nglobally coupled phase oscillators, the scaling law of D is different for the\ncoherent and incoherent regimes: D \\sim O(1/N^a) with a certain constant a>0 in\nthe coherent regime and D \\sim O(1) in the incoherent regime. We demonstrate\nthat these scaling laws hold for several representative coupling schemes. \n\n"}
{"id": "1204.0266", "contents": "Title: Uncovering disassortativity in large scale-free networks Abstract: Mixing patterns in large self-organizing networks, such as the Internet, the\nWorld Wide Web, social and biological networks are often characterized by\ndegree-degree dependencies between neighbouring nodes. In this paper we propose\na new way of measuring degree-degree dependencies. One of the problems with the\ncommonly used assortativity coefficient is that in disassortative networks its\nmagnitude decreases with the network size. We mathematically explain this\nphenomenon and validate the results on synthetic graphs and real-world network\ndata. As an alternative, we suggest to use rank correlation measures such as\nSpearman's rho. Our experiments convincingly show that Spearman's rho produces\nconsistent values in graphs of different sizes but similar structure, and it is\nable to reveal strong (positive or negative) dependencies in large graphs. In\nparticular, we discover much stronger negative degree-degree dependencies} in\nWeb graphs than was previously thought. {Rank correlations allow us to compare\nthe assortativity of networks of different sizes, which is impossible with the\nassortativity coefficient due to its genuine dependence on the network size. We\nconclude that rank correlations provide a suitable and informative method for\nuncovering network mixing patterns. \n\n"}
{"id": "1204.0386", "contents": "Title: Tax evasion dynamics and Zaklan model on Opinion-dependent Network Abstract: Within the context of agent-based Monte-Carlo simulations, we study the\nwell-known majority-vote model (MVM) with noise applied to tax evasion on\nStauffer-Hohnisch-Pittnauer (SHP) networks. To control the fluctuations for tax\nevasion in the economics model proposed by Zaklan, MVM is applied in the\nneighborhood of the critical noise $q_{c}$ to evolve the Zaklan model. The\nZaklan model had been studied recently using the equilibrium Ising model. Here\nwe show that the Zaklan model is robust because this can be studied besides\nusing equilibrium dynamics of Ising model also through the nonequilibrium MVM\nand on various topologies giving the same behavior regardless of dynamic or\ntopology used here. \n\n"}
{"id": "1205.0149", "contents": "Title: Non-Universality in Semi-Directed Barabasi-Albert Networks Abstract: In usual scale-free networks of Barabasi-Albert type, a newly added node\nselects randomly m neighbors from the already existing network nodes,\nproportionally to the number of links these had before. Then the number N(k) of\nnodes with k links each decays as 1/k^gamma where gamma=3 is universal, i.e.\nindependent of m. Now we use a limited directedness in the construction of the\nnetwork, as a result of which the exponent gamma decreases from 3 to 2 for\nincreasing m. \n\n"}
{"id": "1205.1505", "contents": "Title: Crossover phenomenon in the performance of an Internet search engine Abstract: In this work we explore the ability of the Google search engine to find\nresults for random N-letter strings. These random strings, dense over the set\nof possible N-letter words, address the existence of typos, acronyms, and other\nwords without semantic meaning. Interestingly, we find that the probability of\nfinding such strings sharply drops from one to zero at Nc = 6. The behavior of\nsuch order parameter suggests the presence of a transition-like phenomenon in\nthe geometry of the search space. Furthermore, we define a susceptibility-like\nparameter which reaches a maximum in the neighborhood, suggesting the presence\nof criticality. We finally speculate on the possible connections to Ramsey\ntheory. \n\n"}
{"id": "1205.1682", "contents": "Title: Influence Maximization in Continuous Time Diffusion Networks Abstract: The problem of finding the optimal set of source nodes in a diffusion network\nthat maximizes the spread of information, influence, and diseases in a limited\namount of time depends dramatically on the underlying temporal dynamics of the\nnetwork. However, this still remains largely unexplored to date. To this end,\ngiven a network and its temporal dynamics, we first describe how continuous\ntime Markov chains allow us to analytically compute the average total number of\nnodes reached by a diffusion process starting in a set of source nodes. We then\nshow that selecting the set of most influential source nodes in the continuous\ntime influence maximization problem is NP-hard and develop an efficient\napproximation algorithm with provable near-optimal performance. Experiments on\nsynthetic and real diffusion networks show that our algorithm outperforms other\nstate of the art algorithms by at least ~20% and is robust across different\nnetwork topologies. \n\n"}
{"id": "1205.1902", "contents": "Title: Feigenbaum graphs at the onset of chaos Abstract: We analyze the properties of the self-similar network obtained from the\ntrajectories of unimodal maps at the transition to chaos via the horizontal\nvisibility (HV) algorithm. We first show that this network is uniquely\ndetermined by the encoded sequence of positions in the dynamics within the\nFeigenbaum attractor and it is universal in that it is independent of the shape\nand nonlinearity of the maps in this class. We then find that the network\ndegrees fluctuate at all scales with an amplitude that increases as the size of\nthe network grows. This suggests the definition of a graph-theoretical Lyapunov\nexponent that measures the expansion rate of trajectories in network space. On\ngood agreement with the map's counterpart, while at the onset of chaos this\nexponent vanishes, the subexponential expansion and contraction of network\ndegrees can be fully described via a Tsallis-type scalar deformation of the\nexpansion rate, that yields a discrete spectrum of non-null generalized\nexponents. We further explore the possibility of defining an entropy growth\nrate that describes the amount of information created along the trajectories in\nnetwork space. Making use of the trajectory distributions in the map's\naccumulation point and the scaling properties of the associated network, we\nshow that such entropic growth rate coincides with the spectrum of\ngraph-theoretical exponents, what appears as a set of Pesin-like identities in\nthe network. \n\n"}
{"id": "1205.2466", "contents": "Title: Emotional persistence in online chatting communities Abstract: How do users behave in online chatrooms, where they instantaneously read and\nwrite posts? We analyzed about 2.5 million posts covering various topics in\nInternet relay channels, and found that user activity patterns follow known\npower-law and stretched exponential distributions, indicating that online chat\nactivity is not different from other forms of communication. Analysing the\nemotional expressions (positive, negative, neutral) of users, we revealed a\nremarkable persistence both for individual users and channels. I.e. despite\ntheir anonymity, users tend to follow social norms in repeated interactions in\nonline chats, which results in a specific emotional \"tone\" of the channels. We\nprovide an agent-based model of emotional interaction, which recovers\nqualitatively both the activity patterns in chatrooms and the emotional\npersistence of users and channels. While our assumptions about agent's\nemotional expressions are rooted in psychology, the model allows to test\ndifferent hypothesis regarding their emotional impact in online communication. \n\n"}
{"id": "1205.2901", "contents": "Title: Largest Lyapunov exponents for lattices of interacting classical spins Abstract: We investigate how generic the onset of chaos in interacting many-body\nclassical systems is in the context of lattices of classical spins with nearest\nneighbor anisotropic couplings. Seven large lattices in different spatial\ndimensions were considered. For each lattice, more than 2000 largest Lyapunov\nexponents for randomly sampled Hamiltonians were numerically computed. Our\nresults strongly suggest the absence of integrable nearest-neighbor\nHamiltonians for the infinite lattices except for the trivial Ising case. In\nthe vicinity of the Ising case, the largest Lyapunov exponents exhibit a\npower-law growth, while further away they become rather weakly sensitive to the\nHamiltonian anisotropy. We also provide an analytical derivation of these\nresults. \n\n"}
{"id": "1205.3188", "contents": "Title: The robustness of interdependent clustered networks Abstract: It was recently found that cascading failures can cause the abrupt breakdown\nof a system of interdependent networks. Using the percolation method developed\nfor single clustered networks by Newman [Phys. Rev. Lett. {\\bf 103}, 058701\n(2009)], we develop an analytical method for studying how clustering within the\nnetworks of a system of interdependent networks affects the system's\nrobustness. We find that clustering significantly increases the vulnerability\nof the system, which is represented by the increased value of the percolation\nthreshold $p_c$ in interdependent networks. \n\n"}
{"id": "1205.3211", "contents": "Title: Information metric from a linear sigma model Abstract: The idea that a spacetime metric emerges as a Fisher-Rao `information metric'\nof instanton moduli space has been examined in several field theories such as\nthe Yang-Mills theories and nonlinear sigma models. In this brief paper, we\nreport that the flat Euclidean or Minkowskian metric, rather than an anti-de\nSitter metric that generically emerges from instanton moduli spaces, can be\nobtained as the Fisher-Rao metric from a non-trivial solution of the massive\nKlein-Gordon field (a linear sigma model). This realization of the flat space\nfrom the simple field theory would be useful to investigate the ideas that\nrelate the spacetime geometry with the information geometry. \n\n"}
{"id": "1205.3720", "contents": "Title: A k-shell decomposition method for weighted networks Abstract: We present a generalized method for calculating the k-shell structure of\nweighted networks. The method takes into account both the weight and the degree\nof a network, in such a way that in the absence of weights we resume the shell\nstructure obtained by the classic k-shell decomposition. In the presence of\nweights, we show that the method is able to partition the network in a more\nrefined way, without the need of any arbitrary threshold on the weight values.\nFurthermore, by simulating spreading processes using the\nsusceptible-infectious-recovered model in four different weighted real-world\nnetworks, we show that the weighted k-shell decomposition method ranks the\nnodes more accurately, by placing nodes with higher spreading potential into\nshells closer to the core. In addition, we demonstrate our new method on a real\neconomic network and show that the core calculated using the weighted k-shell\nmethod is more meaningful from an economic perspective when compared with the\nunweighted one. \n\n"}
{"id": "1205.3832", "contents": "Title: Social Climber attachment in forming networks produces phase transition\n  in a measure of connectivity Abstract: Formation and fragmentation of networks is typically studied using\npercolation theory, but most previous research has been restricted to studying\na phase transition in cluster size, examining the emergence of a giant\ncomponent. This approach does not study the effects of evolving network\nstructure on dynamics that occur at the nodes, such as the synchronization of\noscillators and the spread of information, epidemics, and neuronal excitations.\nWe introduce and analyze new link-formation rules, called Social Climber (SC)\nattachment, that may be combined with arbitrary percolation models to produce a\npreviously unstudied phase transition using the largest eigenvalue of the\nnetwork adjacency matrix as the order parameter. This eigenvalue is significant\nin the analyses of many network-coupled dynamical systems in which it measures\nthe quality of global coupling and is hence a natural measure of connectivity.\nWe highlight the important self-organized properties of SC attachment and\ndiscuss implications for controlling dynamics on networks. \n\n"}
{"id": "1206.4358", "contents": "Title: Robust Detection of Dynamic Community Structure in Networks Abstract: We describe techniques for the robust detection of community structure in\nsome classes of time-dependent networks. Specifically, we consider the use of\nstatistical null models for facilitating the principled identification of\nstructural modules in semi-decomposable systems. Null models play an important\nrole both in the optimization of quality functions such as modularity and in\nthe subsequent assessment of the statistical validity of identified community\nstructure. We examine the sensitivity of such methods to model parameters and\nshow how comparisons to null models can help identify system scales. By\nconsidering a large number of optimizations, we quantify the variance of\nnetwork diagnostics over optimizations (`optimization variance') and over\nrandomizations of network structure (`randomization variance'). Because the\nmodularity quality function typically has a large number of nearly-degenerate\nlocal optima for networks constructed using real data, we develop a method to\nconstruct representative partitions that uses a null model to correct for\nstatistical noise in sets of partitions. To illustrate our results, we employ\nensembles of time-dependent networks extracted from both nonlinear oscillators\nand empirical neuroscience data. \n\n"}
{"id": "1206.4780", "contents": "Title: Phenomenological study of light (anti)nuclei, (anti)hypertriton and\n  di-Lambda production at RHIC Abstract: We present the production of light (anti)nuclei, (anti)hypertriton and\ndi-Lambda based on coalescence model in central Au+Au collisions at\n$\\sqrt{s_{NN}}=200GeV$. The invariant yields of \\He(\\Hebar),\n\\hypert(\\hypertbar), \\Hee(\\Heebar) obtained is found to be consistent with the\nSTAR measurements. The $p_{T}$ integrated yields for di-Lambda\n$dN_{\\Lambda\\Lambda}/dy \\sim 2.23\\times10^{-5}$, and is not strongly dependent\non the parameter employed for coalescence process. Relative particle ratios of\nlight anti(nuclei) and (anti)hypertriton are explored, and agree with\nexperimental data and thermal model predictions quite well. An exponential\nreducion behavior is presented for the differential invariant yields with\nincreased baryon number. The production rate reduces by a factor of 1692 (1285)\nfor each additional antinucleon (nucleon) added to antinuclei (nuclei), and the\nproduction rate of \\Libar is predicted to be $10^{-16}$ which is consistent\nwith STAR result. \n\n"}
{"id": "1207.0078", "contents": "Title: Three predictions on July 2012 Federal Elections in Mexico based on past\n  regularities Abstract: Electoral systems are subject of study for physicist and mathematicians in\nlast years given place to a new area: sociophysics. Based on previous works of\nthe author on the Mexican electoral processes in the new millennium, he found\nthree characteristics appearing along the 2000 and 2006 preliminary dataset\noffered by the electoral authorities, named PREP: I) Error distributions are\nnot Gaussian or Lorentzian, they are characterized for power laws at the center\nand asymmetric lobes at each side. II) The Partido Revolucionario Institucional\n(PRI) presented a change in the slope of the percentage of votes obtained when\nit go beyond the 70% of processed certificates; hence it have an improvement at\nthe end of the electoral computation. III) The distribution of votes for the\nPRI is a smooth function well described by Daisy model distributions of rank\n$r$ in all the analyzed cases, presidential and congressional elections in\n2000, 2003 and 2006. If all these characteristics are proper of the Mexican\nreality they should appear in the July 2012 process. Here I discuss some\narguments on why such a behaviors could appear in the present process \n\n"}
{"id": "1207.1497", "contents": "Title: Hidden Markov models for the activity profile of terrorist groups Abstract: The main focus of this work is on developing models for the activity profile\nof a terrorist group, detecting sudden spurts and downfalls in this profile,\nand, in general, tracking it over a period of time. Toward this goal, a\n$d$-state hidden Markov model (HMM) that captures the latent states underlying\nthe dynamics of the group and thus its activity profile is developed. The\nsimplest setting of $d=2$ corresponds to the case where the dynamics are\ncoarsely quantized as Active and Inactive, respectively. A state estimation\nstrategy that exploits the underlying HMM structure is then developed for spurt\ndetection and tracking. This strategy is shown to track even nonpersistent\nchanges that last only for a short duration at the cost of learning the\nunderlying model. Case studies with real terrorism data from open-source\ndatabases are provided to illustrate the performance of the proposed\nmethodology. \n\n"}
{"id": "1207.1791", "contents": "Title: Spatial effects in real networks: measures, null models, and\n  applications Abstract: Spatially embedded networks are shaped by a combination of purely topological\n(space-independent) and space-dependent formation rules. While it is quite easy\nto artificially generate networks where the relative importance of these two\nfactors can be varied arbitrarily, it is much more difficult to disentangle\nthese two architectural effects in real networks. Here we propose a solution to\nthe problem by introducing global and local measures of spatial effects that,\nthrough a comparison with adequate null models, effectively filter out the\nspurious contribution of non-spatial constraints. Our filtering allows us to\nconsistently compare different embedded networks or different historical\nsnapshots of the same network. As a challenging application we analyse the\nWorld Trade Web, whose topology is expected to depend on geographic distances\nbut is also strongly determined by non-spatial constraints (degree sequence or\nGDP). Remarkably, we are able to detect weak but significant spatial effects\nboth locally and globally in the network, showing that our method succeeds in\nretrieving spatial information even when non-spatial factors dominate. We\nfinally relate our results to the economic literature on gravity models and\ntrade globalization. \n\n"}
{"id": "1207.2072", "contents": "Title: Stochastic dynamics of the prisoner's dilemma with cooperation\n  facilitators Abstract: In the framework of the paradigmatic prisoner's dilemma, we investigate the\nevolutionary dynamics of social dilemmas in the presence of \"cooperation\nfacilitators\". In our model, cooperators and defectors interact as in the\nclassical prisoner's dilemma game, where selection favors defection. However,\nhere the presence of a small number of cooperation facilitators enhances the\nfitness (reproductive potential) of cooperators, while it does not alter that\nof defectors. In a finite population of size N, the dynamics of the prisoner's\ndilemma with facilitators is characterized by the probability that cooperation\ntakes over (fixation probability) and by the mean times to reach the absorbing\nstates. These quantities are computed exactly and using Fokker-Planck\nequations. Our findings, corroborated by stochastic simulations, demonstrate\nthat the influence of facilitators crucially depends on the difference between\ntheir density z and the game's cost-to-benefit ratio r. When z>r, the fixation\nof cooperators is likely in a large population and, under weak selection\npressure, invasion and replacement of defection by cooperation is favored by\nselection if b(z-r)(1-z)>1/N, where 0<b<= 1 is the cooperation payoff benefit.\nWhen z<r, the fixation probability of cooperators is exponentially enhanced by\nthe presence of facilitators but defection is the dominating strategy. \n\n"}
{"id": "1207.5721", "contents": "Title: Cognitive network structure: an experimental study Abstract: In this paper we present first experimental results about a small group of\npeople exchanging private and public messages in a virtual community. Our goal\nis the study of the cognitive network that emerges during a chat seance. We\nused the Derrida coefficient and the triangle structure under the working\nassumption that moods and perceived mutual affinity can produce results\ncomplementary to a full semantic analysis. The most outstanding outcome is the\ndifference between the network obtained considering publicly exchanged messages\nand the one considering only privately exchanged messages: in the former case,\nthe network is very homogeneous, in the sense that each individual interacts in\nthe same way with all the participants, whilst in the latter the interactions\namong different agents are very heterogeneous, and are based on \"the enemy of\nmy enemy is my friend\" strategy. Finally a recent characterization of the\ntriangular cliques has been considered in order to describe the intimate\nstructure of the network. Experimental results confirm recent theoretical\nstudies indicating that certain 3-vertex structures can be used as indicators\nfor the network aging and some relevant dynamical features. \n\n"}
{"id": "1207.6005", "contents": "Title: The expected performance of stellar parametrization with Gaia\n  spectrophotometry Abstract: Gaia will obtain astrometry and spectrophotometry for essentially all sources\nin the sky down to a broad band magnitude limit of G=20, an expected yield of\n10^9 stars. Its main scientific objective is to reveal the formation and\nevolution of our Galaxy through chemo-dynamical analysis. In addition to\ninferring positions, parallaxes and proper motions from the astrometry, we must\nalso infer the astrophysical parameters of the stars from the\nspectrophotometry, the BP/RP spectrum. Here we investigate the performance of\nthree different algorithms (SVM, ILIUM, Aeneas) for estimating the effective\ntemperature, line-of-sight interstellar extinction, metallicity and surface\ngravity of A-M stars over a wide range of these parameters and over the full\nmagnitude range Gaia will observe (G=6-20mag). One of the algorithms, Aeneas,\ninfers the posterior probability density function over all parameters, and can\noptionally take into account the parallax and the Hertzsprung-Russell diagram\nto improve the estimates. For all algorithms the accuracy of estimation depends\non G and on the value of the parameters themselves, so a broad summary of\nperformance is only approximate. For stars at G=15 with less than two\nmagnitudes extinction, we expect to be able to estimate Teff to within 1%, logg\nto 0.1-0.2dex, and [Fe/H] (for FGKM stars) to 0.1-0.2dex, just using the BP/RP\nspectrum (mean absolute error statistics are quoted). Performance degrades at\nlarger extinctions, but not always by a large amount. Extinction can be\nestimated to an accuracy of 0.05-0.2mag for stars across the full parameter\nrange with a priori unknown extinction between 0 and 10mag. Performance\ndegrades at fainter magnitudes, but even at G=19 we can estimate logg to better\nthan 0.2dex for all spectral types, and [Fe/H] to within 0.35dex for FGKM\nstars, for extinctions below 1mag. \n\n"}
{"id": "1208.0254", "contents": "Title: Leaking Chaotic Systems Abstract: There are numerous physical situations in which a hole or leak is introduced\nin an otherwise closed chaotic system. The leak can have a natural origin, it\ncan mimic measurement devices, and it can also be used to reveal dynamical\nproperties of the closed system. In this paper we provide an unified treatment\nof leaking systems and we review applications to different physical problems,\nboth in the classical and quantum pictures. Our treatment is based on the\ntransient chaos theory of open systems, which is essential because real leaks\nhave finite size and therefore estimations based on the closed system differ\nessentially from observations. The field of applications reviewed is very\nbroad, ranging from planetary astronomy and hydrodynamical flows, to plasma\nphysics and quantum fidelity. The theory is expanded and adapted to the case of\npartial leaks (partial absorption/transmission) with applications to room\nacoustics and optical microcavities in mind. Simulations in the lima .con\nfamily of billiards illustrate the main text. Regarding billiard dynamics, we\nemphasize that a correct discrete time representation can only be given in\nterms of the so- called true-time maps, while traditional Poincar \\'e maps lead\nto erroneous results. We generalize Perron-Frobenius-type operators so that\nthey describe true-time maps with partial leaks. \n\n"}
{"id": "1208.0255", "contents": "Title: Limited Imitation Contagion on Random Networks: Chaos, Universality, and\n  Unpredictability Abstract: We study a family of binary state, socially-inspired contagion models which\nincorporate imitation limited by an aversion to complete conformity. We uncover\nrich behavior in our models whether operating with either probabilistic or\ndeterministic individual response functions on both dynamic and fixed random\nnetworks. In particular, we find significant variation in the limiting behavior\nof a population's infected fraction, ranging from steady-state to chaotic. We\nshow that period doubling arises as we increase the average node degree, and\nthat the universality class of this well known route to chaos depends on the\ninteraction structure of random networks rather than the microscopic behavior\nof individual nodes. We find that increasing the fixedness of the system tends\nto stabilize the infected fraction, yet disjoint, multiple equilibria are\npossible depending solely on the choice of the initially infected node. \n\n"}
{"id": "1208.0940", "contents": "Title: Connecting the underlying event with jet properties in pp collisions at\n  $\\sqrt{s}$ = 7 TeV with the ALICE experiment Abstract: A preliminary study of the fragmentation properties of charged particle jets\nas a function of the Underlying Multiplicity (UM) is presented. The UM is\ndefined such that it can be related to the global soft event characteristics by\nexcluding the contribution due to jet fragmentation. The measurement of jet\nproperties as a function of the UM might be connected to the impact parameter\ndependence of the transverse nucleon structure as described via Generalized\nParton Distributions. The results from the studies are compared to Monte Carlo\n(MC) models. \n\n"}
{"id": "1208.2589", "contents": "Title: Why, when, and how fast innovations are adopted Abstract: When the full stock of a new product is quickly sold in a few days or weeks,\none has the impression that new technologies develop and conquer the market in\na very easy way. This may be true for some new technologies, for example the\ncell phone, but not for others, like the blue-ray. Novelty, usefulness,\nadvertising, price, and fashion are the driving forces behind the adoption of a\nnew product. But, what are the key factors that lead to adopt a new technology?\nIn this paper we propose and investigate a simple model for the adoption of an\ninnovation which depends mainly on three elements: the appeal of the novelty,\nthe inertia or resistance to adopt it, and the interaction with other agents.\nSocial interactions are taken into account in two ways: by imitation and by\ndifferentiation, i.e., some agents will be inclined to adopt an innovation if\nmany people do the same, but other will act in the opposite direction, trying\nto differentiate from the \"herd\". We determine the conditions for a successful\nimplantation of the new technology, by considering the strength of advertising\nand the effect of social interactions. We find a balance between the\nadvertising and the number of anti-herding agents that may block the adoption\nof a new product. We also compare the effect of social interactions, when\nagents take into account the behavior of the whole society or just a part of\nit. In a nutshell, the present model reproduces qualitatively the available\ndata on adoption of innovation. \n\n"}
{"id": "1208.2610", "contents": "Title: Quantum Chaos and Quantum Computing Structures Abstract: A system of quantum computing structures is introduced and proven capable of\nmaking emerge, on average, the orbits of classical bounded nonlinear maps on\n\\mathbb{C} through the iterative action of path-dependent quantum gates. The\neffects of emerging nonlinear dynamics and chaos upon the quantum averages of\nrelevant observables and quantum probabilities are exemplified for a version of\nChirikov's standard map on \\mathbb{C} . Both the individual orbits and ensemble\nproperties are addressed so that the Poincar\\'e map for Chirikov's standard\nmap, in the current quantum setting, is reinterpreted in terms of a quantum\nensemble which is then formally introduced within the formalized system of\nquantum computing structures, in terms of quantum register machines, revealing\nthree phases of quantum ensemble dynamics: the regular, the chaotic and an\nintermediate phase called complex quantum stochastic phase which shares\nsimilarities to the edge of chaos notion from classical cellular automata and\nclassical random boolean networks' evolutionary computation. \n\n"}
{"id": "1208.3459", "contents": "Title: Randomness, Information, and Complexity Abstract: We review possible measures of complexity which might in particular be\napplicable to situations where the complexity seems to arise spontaneously. We\npoint out that not all of them correspond to the intuitive (or \"naive\") notion,\nand that one should not expect a unique observable of complexity. One of the\nmain problems is to distinguish complex from disordered systems. This and the\nfact that complexity is closely related to information requires that we also\ngive a review of information measures. We finally concentrate on quantities\nwhich measure in some way or other the difficulty of classifying and\nforecasting sequences of discrete symbols, and study them in simple examples. \n\n"}
{"id": "1208.3569", "contents": "Title: Asymptotically optimal quantum channel reversal for qudit ensembles and\n  multimode Gaussian states Abstract: We investigate the problem of optimally reversing the action of an arbitrary\nquantum channel C which acts independently on each component of an ensemble of\nn identically prepared d-dimensional quantum systems. In the limit of large\nensembles, we construct the optimal reversing channel R* which has to be\napplied at the output ensemble state, to retrieve a smaller ensemble of m\nsystems prepared in the input state, with the highest possible rate m/n. The\nsolution is found by mapping the problem into the optimal reversal of Gaussian\nchannels on quantum-classical continuous variable systems, which is here solved\nas well. Our general results can be readily applied to improve the\nimplementation of robust long-distance quantum communication. As an example, we\ninvestigate the optimal reversal rate of phase flip channels acting on a\nmulti-qubit register. \n\n"}
{"id": "1208.4552", "contents": "Title: Network-based information filtering algorithms: ranking and\n  recommendation Abstract: After the Internet and the World Wide Web have become popular and\nwidely-available, the electronically stored online interactions of individuals\nhave fast emerged as a challenge for researchers and, perhaps even faster, as a\nsource of valuable information for entrepreneurs. We now have detailed records\nof informal friendship relations in social networks, purchases on e-commerce\nsites, various sorts of information being sent from one user to another, online\ncollections of web bookmarks, and many other data sets that allow us to pose\nquestions that are of interest from both academical and commercial point of\nview. For example, which other users of a social network you might want to be\nfriend with? Which other items you might be interested to purchase? Who are the\nmost influential users in a network? Which web page you might want to visit\nnext? All these questions are not only interesting per se but the answers to\nthem may help entrepreneurs provide better service to their customers and,\nultimately, increase their profits. \n\n"}
{"id": "1208.4586", "contents": "Title: Differentially Private Data Analysis of Social Networks via Restricted\n  Sensitivity Abstract: We introduce the notion of restricted sensitivity as an alternative to global\nand smooth sensitivity to improve accuracy in differentially private data\nanalysis. The definition of restricted sensitivity is similar to that of global\nsensitivity except that instead of quantifying over all possible datasets, we\ntake advantage of any beliefs about the dataset that a querier may have, to\nquantify over a restricted class of datasets. Specifically, given a query f and\na hypothesis H about the structure of a dataset D, we show generically how to\ntransform f into a new query f_H whose global sensitivity (over all datasets\nincluding those that do not satisfy H) matches the restricted sensitivity of\nthe query f. Moreover, if the belief of the querier is correct (i.e., D is in\nH) then f_H(D) = f(D). If the belief is incorrect, then f_H(D) may be\ninaccurate.\n  We demonstrate the usefulness of this notion by considering the task of\nanswering queries regarding social-networks, which we model as a combination of\na graph and a labeling of its vertices. In particular, while our generic\nprocedure is computationally inefficient, for the specific definition of H as\ngraphs of bounded degree, we exhibit efficient ways of constructing f_H using\ndifferent projection-based techniques. We then analyze two important query\nclasses: subgraph counting queries (e.g., number of triangles) and local\nprofile queries (e.g., number of people who know a spy and a computer-scientist\nwho know each other). We demonstrate that the restricted sensitivity of such\nqueries can be significantly lower than their smooth sensitivity. Thus, using\nrestricted sensitivity we can maintain privacy whether or not D is in H, while\nproviding more accurate results in the event that H holds true. \n\n"}
{"id": "1208.5313", "contents": "Title: Comment on \"Bayesian astrostatistics: a backward look to the future\" by\n  Tom Loredo, arXiv:1208.3036 Abstract: This short note points out two of the incongruences that I find in the Loredo\n(2012) comments on Andreon (2012), i.e. on my chapter written for the book\n\"Astrostatistical Challenges for the New Astronomy\". First, I find illogic the\nLoredo decision of putting my chapter among those presenting simple models,\nbecause one of the models illustrated in my chapter is qualified by him as\n\"impressing for his complexity\". Second, Loredo criticizes my chapter at one\nlocation confusing it with another paper by another author, because my chapter\ndo not touch the subject mentioned by Loredo (2012) critics, the comparison\nbetween Bayesian and frequentist fitting models. \n\n"}
{"id": "1208.5582", "contents": "Title: Extreme value statistics for dynamical systems with noise Abstract: We study the distribution of maxima (Extreme Value Statistics) for sequences\nof observables computed along orbits generated by random transformations. The\nunderlying, deterministic, dynamical system can be regular or chaotic. In the\nformer case, we will show that by perturbing rational or irrational rotations\nwith additive noise, an extreme value law appears, regardless of the intensity\nof the noise, while unperturbed rotations do not admit such limiting\ndistributions. In the case of deterministic chaotic dynamics, we will consider\nobservables specially designed to study the recurrence properties in the\nneighbourhood of periodic points. Hence, the exponential limiting law for the\ndistribution of maxima is modified by the presence of the extremal index, a\npositive parameter not larger than one, whose inverse gives the average size of\nthe clusters of extreme events. The theory predicts that such a parameter is\nunitary when the system is perturbed randomly. We perform sophisticated\nnumerical tests to assess how strong is the impact of noise level, when finite\ntime series are considered. We find agreement with the asymptotic theoretical\nresults but also non-trivial behaviour in the finite range. In particular our\nresults suggest that in many applications where finite datasets can be produced\nor analysed one must be careful in assuming that the smoothing nature of noise\nprevails over the underlying deterministic dynamics. \n\n"}
{"id": "1208.5896", "contents": "Title: Benford's law and Theil transform of financial data Abstract: Among econophysics investigations, studies of religious groups have been of\ninterest. On one hand, the present paper concerns the Antoinist community\nfinancial reports, - a community which appeared at the end of the 19-th century\nin Belgium. Several growth-decay regimes have been previously found over\ndifferent time spans. However, there is common suspicion about sect finances.\nIn that spirit, the Antoinist community yearly financial reports, income and\nexpenses, are hereby examined along the so-called Benford's law. The latter is\noften used as a test about possible accounting wrongdoings. On the other hand,\nBenford's law is known to be invariant under scale and base transformation.\nTherefore, as a further test, of both such data and Benford's law use, the\nyearly financial reports are nonlinearly remapped through a sort of Theil\ntransformation, i.e. based on a log-transformation. The resulting data is again\nanalyzed along the Benford's law scheme. Bizarre, puzzling, features are seen.\nHowever, it is emphasized that such a non-linear transformation can shift the\nargument toward a more objective conclusion. In an Appendix, some brief\ndiscussion is made on why the original Theil mapping should not be used. In a\nsecond Appendix, an imperfect Benford's law-like form, - better suited for\nanomalous distributions, is presented. \n\n"}
{"id": "1209.0089", "contents": "Title: Estimating the historical and future probabilities of large terrorist\n  events Abstract: Quantities with right-skewed distributions are ubiquitous in complex social\nsystems, including political conflict, economics and social networks, and these\nsystems sometimes produce extremely large events. For instance, the 9/11\nterrorist events produced nearly 3000 fatalities, nearly six times more than\nthe next largest event. But, was this enormous loss of life statistically\nunlikely given modern terrorism's historical record? Accurately estimating the\nprobability of such an event is complicated by the large fluctuations in the\nempirical distribution's upper tail. We present a generic statistical algorithm\nfor making such estimates, which combines semi-parametric models of tail\nbehavior and a nonparametric bootstrap. Applied to a global database of\nterrorist events, we estimate the worldwide historical probability of observing\nat least one 9/11-sized or larger event since 1968 to be 11-35%. These results\nare robust to conditioning on global variations in economic development,\ndomestic versus international events, the type of weapon used and a truncated\nhistory that stops at 1998. We then use this procedure to make a data-driven\nstatistical forecast of at least one similar event over the next decade. \n\n"}
{"id": "1209.0835", "contents": "Title: Evolution of Social-Attribute Networks: Measurements, Modeling, and\n  Implications using Google+ Abstract: Understanding social network structure and evolution has important\nimplications for many aspects of network and system design including\nprovisioning, bootstrapping trust and reputation systems via social networks,\nand defenses against Sybil attacks. Several recent results suggest that\naugmenting the social network structure with user attributes (e.g., location,\nemployer, communities of interest) can provide a more fine-grained\nunderstanding of social networks. However, there have been few studies to\nprovide a systematic understanding of these effects at scale. We bridge this\ngap using a unique dataset collected as the Google+ social network grew over\ntime since its release in late June 2011. We observe novel phenomena with\nrespect to both standard social network metrics and new attribute-related\nmetrics (that we define). We also observe interesting evolutionary patterns as\nGoogle+ went from a bootstrap phase to a steady invitation-only stage before a\npublic release. Based on our empirical observations, we develop a new\ngenerative model to jointly reproduce the social structure and the node\nattributes. Using theoretical analysis and empirical evaluations, we show that\nour model can accurately reproduce the social and attribute structure of real\nsocial networks. We also demonstrate that our model provides more accurate\npredictions for practical application contexts. \n\n"}
{"id": "1209.1479", "contents": "Title: Communication dynamics in finite capacity social networks Abstract: In communication networks structure and dynamics are tightly coupled. The\nstructure controls the flow of information and is itself shaped by the\ndynamical process of information exchanged between nodes. In order to reconcile\nstructure and dynamics, a generic model, based on the local interaction between\nnodes, is considered for the communication in large social networks. In\nagreement with data from a large human organization, we show that the flow is\nnon-Markovian and controlled by the temporal limitations of individuals. We\nconfirm the versatility of our model by predicting simultaneously the\ndegree-dependent node activity, the balance between information input and\noutput of nodes and the degree distribution. Finally, we quantify the\nlimitations to network analysis when it is based on data sampled over a finite\nperiod of time. \n\n"}
{"id": "1209.3470", "contents": "Title: The future of astronomy PhDs in France Abstract: This contribution presents a poll undertaken at the beginning of 2012, and\naddressed to every doctor in astronomy who obtained his/her degree in France.\nIts goal is to motivate the French astronomical community to think and discuss\nabout what should be the training of PhDs, and what should be its objective.\nFurther discussions and reactions can be posted e.g. on\nhttp://docastro.blogspot.fr/. A worrying results from the poll is that the\nmajority of the participants would not encourage a young student to start a\nthesis in astronomy. The main reasons for this fact may be the high pressure on\nastronomy positions and the little interest a doctorate has for other careers\nin France. I suggest we either have to modify our formations or reduce the\nnumber of thesis starting each year in astronomy. \n\n"}
{"id": "1209.3700", "contents": "Title: Simulation of stochastic network dynamics via entropic matching Abstract: The simulation of complex stochastic network dynamics arising, for instance,\nfrom models of coupled biomolecular processes remains computationally\nchallenging. Often, the necessity to scan a models' dynamics over a large\nparameter space renders full-fledged stochastic simulations impractical,\nmotivating approximation schemes. Here we propose an approximation scheme which\nimproves upon the standard linear noise approximation while retaining similar\ncomputational complexity. The underlying idea is to minimize, at each time\nstep, the Kullback-Leibler divergence between the true time evolved probability\ndistribution and a Gaussian approximation (entropic matching). This condition\nleads to ordinary differential equations for the mean and the covariance matrix\nof the Gaussian. For cases of weak nonlinearity, the method is more accurate\nthan the linear method when both are compared to stochastic simulations. \n\n"}
{"id": "1209.3886", "contents": "Title: Spatio-temporal spike trains analysis for large scale networks using\n  maximum entropy principle and Monte-Carlo method Abstract: Understanding the dynamics of neural networks is a major challenge in\nexperimental neuroscience. For that purpose, a modelling of the recorded\nactivity that reproduces the main statistics of the data is required. In a\nfirst part, we present a review on recent results dealing with spike train\nstatistics analysis using maximum entropy models (MaxEnt). Most of these\nstudies have been focusing on modelling synchronous spike patterns, leaving\naside the temporal dynamics of the neural activity. However, the maximum\nentropy principle can be generalized to the temporal case, leading to Markovian\nmodels where memory effects and time correlations in the dynamics are properly\ntaken into account. In a second part, we present a new method based on\nMonte-Carlo sampling which is suited for the fitting of large-scale\nspatio-temporal MaxEnt models. The formalism and the tools presented here will\nbe essential to fit MaxEnt spatio-temporal models to large neural ensembles. \n\n"}
{"id": "1209.5576", "contents": "Title: Critical network effect induces business oscillations in multi-level\n  marketing systems Abstract: The \"social-networking revolution\" of late (e.g., with the advent of social\nmedia, Facebook, and the like) has been propelling the crusade to elucidate the\nembedded networks that underlie economic activity. An unexampled synthesis of\nnetwork science and economics uncovers how the web of human interactions\nspurred by familiarity and similarity could potentially induce the ups and\ndowns ever so common to our economy. Zeroing in on the million-strong global\nindustry known as multi-level marketing, this study finds that such a\nsocially-powered enterprise can only work stably through discrimination about\nwho to make entrepreneurial connections with. \n\n"}
{"id": "1209.5683", "contents": "Title: Role of conviction in nonequilibrium models of opinion formation Abstract: We analyze the critical behavior of a class of discrete opinion models in the\npresence of disorder. Within this class, each agent opinion takes a discrete\nvalue ($\\pm 1$ or 0) and its time evolution is ruled by two terms, one\nrepresenting agent-agent interactions and the other the degree of conviction or\npersuasion (a self-interaction). The mean-field limit, where each agent can\ninteract evenly with any other, is considered. Disorder is introduced in the\nstrength of both interactions, with either quenched or annealed random\nvariables. With probability $p$ (1-$p$), a pairwise interaction reflects a\nnegative (positive) coupling, while the degree of conviction also follows a\nbinary probability distribution (two different discrete probability\ndistributions are considered). Numerical simulations show that a\nnon-equilibrium continuous phase transition, from a disordered state to a state\nwith a prevailing opinion, occurs at a critical point $p_{c}$ that depends on\nthe distribution of the convictions, the transition being spoiled in some\ncases. We also show how the critical line, for each model, is affected by the\nupdate scheme (either parallel or sequential) as well as by the kind of\ndisorder (either quenched or annealed). \n\n"}
{"id": "1209.6170", "contents": "Title: Aging generates regular motions in weakly chaotic systems Abstract: Using intermittent maps with infinite invariant measures, we investigate the\nuniversality of time-averaged observables under aging conditions. According to\nAaronson-Darling-Kac theorem, in non-aged dynamical systems with infinite\ninvariant measures, the distribution of the normalized time averages of\nintegrable functions converge to the Mittag-Leffler distribution. This well\nknown theorem holds when the start of observations coincides with the start of\nthe dynamical processes. Introducing a concept of the aging limit where the\naging time $t_a$ and the total measurement time $t$ goes to infinity while the\naging ratio $t_a/t$ is a constant, we obtain a novel distributional limit\ntheorem of time-averaged observables integrable with respect to the infinite\ninvariant density. Applying the theorem to the Lyapunov exponent in\nintermittent maps, we find that regular motions and a weakly chaotic behavior\ncoexist in the aging limit. This mixed type of dynamics is controlled by the\naging ratio and hence is very different from the usual scenario of regular and\nchaotic motions in Hamiltonian systems. The probability of finding regular\nmotions in non-aged processes is zero, while in the aging regime it is finite\nand it increases when system ages. \n\n"}
{"id": "1210.4007", "contents": "Title: Extending modularity by capturing the similarity attraction feature in\n  the null model Abstract: Modularity is a widely used measure for evaluating community structure in\nnetworks. The definition of modularity involves a comparison of\nwithin-community edges in the observed network and that number in an equivalent\nrandomized network. This equivalent randomized network is called the null\nmodel, which serves as a reference. To make the comparison significant, the\nnull model should characterize some features of the observed network. However,\nthe null model in the original definition of modularity is unrealistically\nmixed, in the sense that any node can be linked to any other node without\npreference and only connectivity matters. Thus, it fails to be a good\nrepresentation of real-world networks. A common feature of many real-world\nnetworks is \"similarity attraction\", i.e., edges tend to link to nodes that are\nsimilar to each other. We propose a null model that captures the similarity\nattraction feature. This null model enables us to create a framework for\ndefining a family of Dist-Modularity adapted to various networks, including\nnetworks with additional information on nodes. We demonstrate that\nDist-Modularity is useful in identifying communities at different scales. \n\n"}
{"id": "1210.5802", "contents": "Title: What if CLIQUE were fast? Maximum Cliques in Information Networks and\n  Strong Components in Temporal Networks Abstract: Exact maximum clique finders have progressed to the point where we can\ninvestigate cliques in million-node social and information networks, as well as\nfind strongly connected components in temporal networks. We use one such finder\nto study a large collection of modern networks emanating from biological,\nsocial, and technological domains. We show inter-relationships between maximum\ncliques and several other common network properties, including network density,\nmaximum core, and number of triangles. In temporal networks, we find that the\nlargest temporal strong components have around 20-30% of the vertices of the\nentire network. These components represent groups of highly communicative\nindividuals. In addition, we discuss and improve the performance and utility of\nthe maximum clique finder itself. \n\n"}
{"id": "1210.6232", "contents": "Title: Measurement errors and scaling relations in astrophysics: a review Abstract: This review article considers some of the most common methods used in\nastronomy for regressing one quantity against another in order to estimate the\nmodel parameters or to predict an observationally expensive quantity using\ntrends between object values. These methods have to tackle some of the awkward\nfeatures prevalent in astronomical data, namely heteroscedastic\n(point-dependent) errors, intrinsic scatter, non-ignorable data collection and\nselection effects, data structure and non-uniform population (often called\nMalmquist bias), non-Gaussian data, outliers and mixtures of regressions. We\noutline how least square fits, weighted least squares methods, Maximum\nLikelihood, survival analysis, and Bayesian methods have been applied in the\nastrophysics literature when one or more of these features is present. In\nparticular we concentrate on errors-in-variables regression and we advocate\nBayesian techniques. \n\n"}
{"id": "1210.7284", "contents": "Title: Exact Mapping Noisy van der Pol Type Oscillator onto Quasi-symplectic\n  Dynamics Abstract: We find exact mappings for a class of limit cycle systems with noise onto\nquasi-symplectic dynamics, including a van der Pol type oscillator. A dual role\npotential function is obtained as a component of the quasi-symplectic dynamics.\nBased on a stochastic interpretation different from the traditional Ito's and\nStratonovich's, we show the corresponding steady state distribution is the\nfamiliar Boltzmann-Gibbs type for arbitrary noise strength. The result provides\na new angle for understanding processes without detailed balance and can be\nverified by experiments. \n\n"}
{"id": "1211.2535", "contents": "Title: Theory of self-organized traffic at light signal Abstract: Based on numerical simulations of a three-phase traffic flow model, a\nprobabilistic theory of traffic at the light signal is developed. We have found\nthat very complex spatiotemporal self-organized phenomena determine features of\ncity traffic. We have revealed that the breakdown of {\\it green wave} in a city\nis initiated by the emergence of a moving synchronized flow pattern (MSP)\nwithin the green wave. It turns out that a sequence of\nF$\\rightarrow$S$\\rightarrow$J transitions (F -- free flow, S -- synchronized\nflow, J -- moving queue) lead to traffic breakdown at the light signal. Both\nspontaneous and induced breakdowns of the green wave have been found. From a\nstudy of a variety of scenarios for arrival traffic, we have found that there\nare the infinite number of capacities of traffic at the light signal, which are\nin a capacity range between a minimum capacity and maximum capacity; each of\nthe capacities gives a flow rate at which under-saturated traffic is in a\nmetastable state with respect to the transition to over-saturated traffic. The\nmaximum capacity depends crucially on a time-dependence of the flow rate: The\nlarger the number of vehicles that arrive the light signal during the green\nphase, the larger the maximum capacity. \n\n"}
{"id": "1211.3412", "contents": "Title: Network Sampling: From Static to Streaming Graphs Abstract: Network sampling is integral to the analysis of social, information, and\nbiological networks. Since many real-world networks are massive in size,\ncontinuously evolving, and/or distributed in nature, the network structure is\noften sampled in order to facilitate study. For these reasons, a more thorough\nand complete understanding of network sampling is critical to support the field\nof network science. In this paper, we outline a framework for the general\nproblem of network sampling, by highlighting the different objectives,\npopulation and units of interest, and classes of network sampling methods. In\naddition, we propose a spectrum of computational models for network sampling\nmethods, ranging from the traditionally studied model based on the assumption\nof a static domain to a more challenging model that is appropriate for\nstreaming domains. We design a family of sampling methods based on the concept\nof graph induction that generalize across the full spectrum of computational\nmodels (from static to streaming) while efficiently preserving many of the\ntopological properties of the input graphs. Furthermore, we demonstrate how\ntraditional static sampling algorithms can be modified for graph streams for\neach of the three main classes of sampling methods: node, edge, and\ntopology-based sampling. Our experimental results indicate that our proposed\nfamily of sampling methods more accurately preserves the underlying properties\nof the graph for both static and streaming graphs. Finally, we study the impact\nof network sampling algorithms on the parameter estimation and performance\nevaluation of relational classification algorithms. \n\n"}
{"id": "1211.3671", "contents": "Title: L$_1$ Regularization for Reconstruction of a non-equilibrium Ising Model Abstract: The couplings in a sparse asymmetric, asynchronous Ising network are\nreconstructed using an exact learning algorithm. L$_1$ regularization is used\nto remove the spurious weak connections that would otherwise be found by simply\nminimizing the minus likelihood of a finite data set. In order to see how L$_1$\nregularization works in detail, we perform the calculation in several ways\nincluding (1) by iterative minimization of a cost function equal to minus the\nlog likelihood of the data plus an L$_1$ penalty term, and (2) an approximate\nscheme based on a quadratic expansion of the cost function around its minimum.\nIn these schemes, we track how connections are pruned as the strength of the\nL$_1$ penalty is increased from zero to large values. The performance of the\nmethods for various coupling strengths is quantified using ROC curves. \n\n"}
{"id": "1211.5986", "contents": "Title: Signal recognition and adapted filtering by non-commutative tomography Abstract: Tomograms, a generalization of the Radon transform to arbitrary pairs of\nnon-commuting operators, are positive bilinear transforms with a rigorous\nprobabilistic interpretation which provide a full characterization of the\nsignal and are robust in the presence of noise. Tomograms based on the\ntime-frequency operator pair, were used in the past for component separation\nand denoising. Here we show how, by the construction of an operator pair\nadapted to the signal, meaningful information with good time resolution is\nextracted even in very noisy situations. \n\n"}
{"id": "1211.6433", "contents": "Title: On the Star Formation Efficiency of Turbulent Magnetized Clouds Abstract: We study the star formation efficiency (SFE) in simulations and observations\nof turbulent, magnetized, molecular clouds. We find that the probability\ndensity functions (PDFs) of the density and the column density in our\nsimulations with solenoidal, mixed, and compressive forcing of the turbulence,\nsonic Mach numbers of 3-50, and magnetic fields in the super- to the\ntrans-Alfvenic regime, all develop power-law tails of flattening slope with\nincreasing SFE. The high-density tails of the PDFs are consistent with\nequivalent radial density profiles, rho ~ r^(-kappa) with kappa ~ 1.5-2.5, in\nagreement with observations. Studying velocity-size scalings, we find that all\nthe simulations are consistent with the observed v ~ l^(1/2) scaling of\nsupersonic turbulence, and seem to approach Kolmogorov turbulence with v ~\nl^(1/3) below the sonic scale. The velocity-size scaling is, however, largely\nindependent of the SFE. In contrast, the density-size and column density-size\nscalings are highly sensitive to star formation. We find that the power-law\nslope alpha of the density power spectrum, P(rho,k) ~ k^alpha, or equivalently\nthe Delta-variance spectrum of column density, DV(Sigma,l) ~ l^(-alpha),\nswitches sign from alpha < 0 for SFE ~ 0 to alpha > 0 when star formation\nproceeds (SFE > 0). We provide a relation to compute the SFE from a measurement\nof alpha. Studying the literature, we find values ranging from alpha = -1.6 to\n+1.6 in observations covering scales from the large-scale atomic medium, over\ncold molecular clouds, down to dense star-forming cores. From those alpha\nvalues, we infer SFEs and find good agreement with independent measurements\nbased on young stellar object (YSO) counts, where available. Our SFE-alpha\nrelation provides an independent estimate of the SFE based on the column\ndensity map of a cloud alone, without requiring a priori knowledge of\nstar-formation activity or YSO counts. \n\n"}
{"id": "1211.6496", "contents": "Title: TwitterPaul: Extracting and Aggregating Twitter Predictions Abstract: This paper introduces TwitterPaul, a system designed to make use of Social\nMedia data to help to predict game outcomes for the 2010 FIFA World Cup\ntournament. To this end, we extracted over 538K mentions to football games from\na large sample of tweets that occurred during the World Cup, and we classified\ninto different types with a precision of up to 88%. The different mentions were\naggregated in order to make predictions about the outcomes of the actual games.\nWe attempt to learn which Twitter users are accurate predictors and explore\nseveral techniques in order to exploit this information to make more accurate\npredictions. We compare our results to strong baselines and against the betting\nline (prediction market) and found that the quality of extractions is more\nimportant than the quantity, suggesting that high precision methods working on\na medium-sized dataset are preferable over low precision methods that use a\nlarger amount of data. Finally, by aggregating some classes of predictions, the\nsystem performance is close to the one of the betting line. Furthermore, we\nbelieve that this domain independent framework can help to predict other\nsports, elections, product release dates and other future events that people\ntalk about in social media. \n\n"}
{"id": "1212.0121", "contents": "Title: Opinion dynamics with disagreement and modulated information Abstract: Opinion dynamics concerns social processes through which populations or\ngroups of individuals agree or disagree on specific issues. As such, modelling\nopinion dynamics represents an important research area that has been\nprogressively acquiring relevance in many different domains. Existing\napproaches have mostly represented opinions through discrete binary or\ncontinuous variables by exploring a whole panoply of cases: e.g. independence,\nnoise, external effects, multiple issues. In most of these cases the crucial\ningredient is an attractive dynamics through which similar or similar enough\nagents get closer. Only rarely the possibility of explicit disagreement has\nbeen taken into account (i.e., the possibility for a repulsive interaction\namong individuals' opinions), and mostly for discrete or 1-dimensional\nopinions, through the introduction of additional model parameters. Here we\nintroduce a new model of opinion formation, which focuses on the interplay\nbetween the possibility of explicit disagreement, modulated in a\nself-consistent way by the existing opinions' overlaps between the interacting\nindividuals, and the effect of external information on the system. Opinions are\nmodelled as a vector of continuous variables related to multiple possible\nchoices for an issue. Information can be modulated to account for promoting\nmultiple possible choices. Numerical results show that extreme information\nresults in segregation and has a limited effect on the population, while milder\nmessages have better success and a cohesion effect. Additionally, the initial\ncondition plays an important role, with the population forming one or multiple\nclusters based on the initial average similarity between individuals, with a\ntransition point depending on the number of opinion choices. \n\n"}
{"id": "1212.0252", "contents": "Title: Hysteresis, Phase Transitions and Dangerous Transients in Electrical\n  Power Distribution Systems Abstract: The majority of dynamical studies in power systems focus on the high voltage\ntransmission grids where models consider large generators interacting with\ncrude aggregations of individual small loads. However, new phenomena have been\nobserved indicating that the spatial distribution of collective, nonlinear\ncontribution of these small loads in the low-voltage distribution grid is\ncrucial to outcome of these dynamical transients. To elucidate the phenomenon,\nwe study the dynamics of voltage and power flows in a spatially-extended\ndistribution feeder (circuit) connecting many asynchronous induction motors and\ndiscover that this relatively simple 1+1 (space+time) dimensional system\nexhibits a plethora of nontrivial spatio-temporal effects, some of which may be\ndangerous for power system stability. Long-range motor-motor interactions\nmediated by circuit voltage and electrical power flows result in coexistence\nand segregation of spatially-extended phases defined by individual motor\nstates--a \"normal\" state where the motors' mechanical (rotation) frequency is\nslightly smaller than the nominal frequency of the basic AC flows and a\n\"stalled\" state where the mechanical frequency is small. Transitions between\nthe two states can be initiated by a perturbation of the voltage or base\nfrequency at the head of the distribution feeder. Such behavior is typical of\nfirst-order phase transitions in physics, and this 1+1 dimensional model shows\nmany other properties of a first-order phase transition with the spatial\ndistribution of the motors' mechanical frequency playing the role of the order\nparameter. In particular we observe (a) propagation of the phase-transition\nfront with the constant speed very long feeders; and (b) hysteresis in\ntransitions between the normal and stalled (or partially stalled) phases. \n\n"}
{"id": "1212.3881", "contents": "Title: Optimal forwarding ratio on dynamical networks with heterogeneous\n  mobility Abstract: As the discovery of non-Poissonian statistics of human mobility trajectories,\nmore attention has been paid to understanding the role of these patterns in\ndifferent dynamics. In this study, we first introduce the heterogeneous\nmobility of mobile agents into dynamical networks, and then investigate the\nforwarding strategy on the heterogeneous dynamical networks. We find that the\nfaster speed and the higher proportion of high-speed agents can enhance the\nnetwork throughput and reduce the mean traveling time in the case of random\nforwarding. A hierarchical structure in the dependence of high-speed is\nobserved: the network throughput remains unchanged in small and large\nhigh-speed value. It is interesting to find that the slightly preferential\nforwarding to high-speed agents can maximize the network capacity. Through\ntheoretical analysis and numerical simulations, we show that the optimal\nforwarding ratio stems from local structural heterogeneity of low-speed agents. \n\n"}
{"id": "1301.0733", "contents": "Title: Towards a General Theory of Extremes for Observables of Chaotic\n  Dynamical Systems Abstract: In this paper we provide a connection between the geometrical properties of a\nchaotic dynamical system and the distribution of extreme values. We show that\nthe extremes of so-called physical observables are distributed according to the\nclassical generalised Pareto distribution and derive explicit expressions for\nthe scaling and the shape parameter. In particular, we derive that the shape\nparameter does not depend on the chosen observables, but only on the partial\ndimensions of the invariant measure on the stable, unstable, and neutral\nmanifolds. The shape parameter is negative and is close to zero when\nhigh-dimensional systems are considered. This result agrees with what was\nderived recently using the generalized extreme value approach. Combining the\nresults obtained using such physical observables and the properties of the\nextremes of distance observables, it is possible to derive estimates of the\npartial dimensions of the attractor along the stable and the unstable\ndirections of the flow. Moreover, by writing the shape parameter in terms of\nmoments of the extremes of the considered observable and by using linear\nresponse theory, we relate the sensitivity to perturbations of the shape\nparameter to the sensitivity of the moments, of the partial dimensions, and of\nthe Kaplan-Yorke dimension of the attractor. Preliminary numerical\ninvestigations provide encouraging results on the applicability of the theory\npresented here. The results presented here do not apply for all combinations of\nAxiom A systems and observables, but the breakdown seems to be related to very\nspecial geometrical configurations. \n\n"}
{"id": "1301.1626", "contents": "Title: Google matrix analysis of DNA sequences Abstract: For DNA sequences of various species we construct the Google matrix G of\nMarkov transitions between nearby words composed of several letters. The\nstatistical distribution of matrix elements of this matrix is shown to be\ndescribed by a power law with the exponent being close to those of outgoing\nlinks in such scale-free networks as the World Wide Web (WWW). At the same time\nthe sum of ingoing matrix elements is characterized by the exponent being\nsignificantly larger than those typical for WWW networks. This results in a\nslow algebraic decay of the PageRank probability determined by the distribution\nof ingoing elements. The spectrum of G is characterized by a large gap leading\nto a rapid relaxation process on the DNA sequence networks. We introduce the\nPageRank proximity correlator between different species which determines their\nstatistical similarity from the view point of Markov chains. The properties of\nother eigenstates of the Google matrix are also discussed. Our results\nestablish scale-free features of DNA sequence networks showing their\nsimilarities and distinctions with the WWW and linguistic networks. \n\n"}
{"id": "1301.2078", "contents": "Title: Efficient Bayesian estimation of Markov model transition matrices with\n  given stationary distribution Abstract: Direct simulation of biomolecular dynamics in thermal equilibrium is\nchallenging due to the metastable nature of conformation dynamics and the\ncomputational cost of molecular dynamics. Biased or enhanced sampling methods\nmay improve the convergence of expectation values of equilibrium probabilities\nand expectation values of stationary quantities significantly. Unfortunately\nthe convergence of dynamic observables such as correlation functions or\ntimescales of conformational transitions relies on direct equilibrium\nsimulations. Markov state models are well suited to describe both, stationary\nproperties and properties of slow dynamical processes of a molecular system, in\nterms of a transition matrix for a jump process on a suitable discretiza- tion\nof continuous conformation space. Here, we introduce statistical estimation\nmethods that allow a priori knowledge of equilibrium probabilities to be\nincorporated into the estimation of dynamical observables. Both, maximum\nlikelihood methods and an improved Monte Carlo sampling method for reversible\ntransition ma- trices with fixed stationary distribution are given. The\nsampling approach is applied to a toy example as well as to simulations of the\nMR121-GSGS-W peptide, and is demonstrated to converge much more rapidly than a\nprevious approach in [F. Noe, J. Chem. Phys. 128, 244103 (2008)] \n\n"}
{"id": "1301.2184", "contents": "Title: Penalized Splines for Smooth Representation of High-dimensional Monte\n  Carlo Datasets Abstract: Detector response to a high-energy physics process is often estimated by\nMonte Carlo simulation. For purposes of data analysis, the results of this\nsimulation are typically stored in large multi-dimensional histograms, which\ncan quickly become both too large to easily store and manipulate and\nnumerically problematic due to unfilled bins or interpolation artifacts. We\ndescribe here an application of the penalized spline technique to efficiently\ncompute B-spline representations of such tables and discuss aspects of the\nresulting B-spline fits that simplify many common tasks in handling tabulated\nMonte Carlo data in high-energy physics analysis, in particular their use in\nmaximum-likelihood fitting. \n\n"}
{"id": "1302.2761", "contents": "Title: Poincar\\'e recurrences and Ulam method for the Chirikov standard map Abstract: We study numerically the statistics of Poincar\\'e recurrences for the\nChirikov standard map and the separatrix map at parameters with a critical\ngolden invariant curve. The properties of recurrences are analyzed with the\nhelp of a generalized Ulam method. This method allows to construct the\ncorresponding Ulam matrix whose spectrum and eigenstates are analyzed by the\npowerful Arnoldi method. We also develop a new survival Monte Carlo method\nwhich allows us to study recurrences on times changing by ten orders of\nmagnitude. We show that the recurrences at long times are determined by\ntrajectory sticking in a vicinity of the critical golden curve and secondary\nresonance structures. The values of Poincar\\'e exponents of recurrences are\ndetermined for the two maps studied. We also discuss the localization\nproperties of eigenstates of the Ulam matrix and their relation with the\nPoincar\\'e recurrences. \n\n"}
{"id": "1302.3892", "contents": "Title: Identifying trends in word frequency dynamics Abstract: The word-stock of a language is a complex dynamical system in which words can\nbe created, evolve, and become extinct. Even more dynamic are the short-term\nfluctuations in word usage by individuals in a population. Building on the\nrecent demonstration that word niche is a strong determinant of future rise or\nfall in word frequency, here we introduce a model that allows us to distinguish\npersistent from temporary increases in frequency. Our model is illustrated\nusing a 10^8-word database from an online discussion group and a 10^11-word\ncollection of digitized books. The model reveals a strong relation between\nchanges in word dissemination and changes in frequency. Aside from their\nimplications for short-term word frequency dynamics, these observations are\npotentially important for language evolution as new words must survive in the\nshort term in order to survive in the long term. \n\n"}
{"id": "1302.6145", "contents": "Title: Oscillations in turbulence-condensate system Abstract: We consider developed turbulence in the Gross-Pitaevsky model where\ncondensate appears due to an inverse cascade. Despite being fully turbulent,\nthe system demonstrates non-decaying periodic oscillations around a steady\nstate, when turbulence and condensate periodically exchange a small fraction of\nwaves. We show that these collective oscillations are not of a predator-prey\ntype, as was suggested earlier; they are due to phase coherence and anomalous\ncorrelations imposed by the condensate. \n\n"}
{"id": "1302.6636", "contents": "Title: A Scalable Generative Graph Model with Community Structure Abstract: Network data is ubiquitous and growing, yet we lack realistic generative\nnetwork models that can be calibrated to match real-world data. The recently\nproposed Block Two-Level Erdss-Renyi (BTER) model can be tuned to capture two\nfundamental properties: degree distribution and clustering coefficients. The\nlatter is particularly important for reproducing graphs with community\nstructure, such as social networks. In this paper, we compare BTER to other\nscalable models and show that it gives a better fit to real data. We provide a\nscalable implementation that requires only O(d_max) storage where d_max is the\nmaximum number of neighbors for a single node. The generator is trivially\nparallelizable, and we show results for a Hadoop MapReduce implementation for a\nmodeling a real-world web graph with over 4.6 billion edges. We propose that\nthe BTER model can be used as a graph generator for benchmarking purposes and\nprovide idealized degree distributions and clustering coefficient profiles that\ncan be tuned for user specifications. \n\n"}
{"id": "1303.0484", "contents": "Title: Onomastics 2.0 - The Power of Social Co-Occurrences Abstract: Onomastics is \"the science or study of the origin and forms of proper names\nof persons or places.\" [\"Onomastics\". Merriam-Webster.com, 2013.\nhttp://www.merriam-webster.com (11 February 2013)]. Especially personal names\nplay an important role in daily life, as all over the world future parents are\nfacing the task of finding a suitable given name for their child. This choice\nis influenced by different factors, such as the social context, language,\ncultural background and, in particular, personal taste.\n  With the rise of the Social Web and its applications, users more and more\ninteract digitally and participate in the creation of heterogeneous,\ndistributed, collaborative data collections. These sources of data also reflect\ncurrent and new naming trends as well as new emerging interrelations among\nnames.\n  The present work shows, how basic approaches from the field of social network\nanalysis and information retrieval can be applied for discovering relations\namong names, thus extending Onomastics by data mining techniques. The\nconsidered approach starts with building co-occurrence graphs relative to data\nfrom the Social Web, respectively for given names and city names. As a main\nresult, correlations between semantically grounded similarities among names\n(e.g., geographical distance for city names) and structural graph based\nsimilarities are observed.\n  The discovered relations among given names are the foundation of \"nameling\"\n[http://nameling.net], a search engine and academic research platform for given\nnames which attracted more than 30,000 users within four months,\nunderpinningthe relevance of the proposed methodology. \n\n"}
{"id": "1303.1414", "contents": "Title: Dynamical influence processes on networks: General theory and\n  applications to social contagion Abstract: We study binary state dynamics on a network where each node acts in response\nto the average state of its neighborhood. Allowing varying amounts of\nstochasticity in both the network and node responses, we find different\noutcomes in random and deterministic versions of the model. In the limit of a\nlarge, dense network, however, we show that these dynamics coincide. We\nconstruct a general mean field theory for random networks and show this\npredicts that the dynamics on the network are a smoothed version of the average\nresponse function dynamics. Thus, the behavior of the system can range from\nsteady state to chaotic depending on the response functions, network\nconnectivity, and update synchronicity. As a specific example, we model the\ncompeting tendencies of imitation and non-conformity by incorporating an\noff-threshold into standard threshold models of social contagion. In this way\nwe attempt to capture important aspects of fashions and societal trends. We\ncompare our theory to extensive simulations of this \"limited imitation\ncontagion\" model on Poisson random graphs, finding agreement between the\nmean-field theory and stochastic simulations. \n\n"}
{"id": "1303.2176", "contents": "Title: Scaling behavior of online human activity Abstract: The rapid development of Internet technology enables human explore the web\nand record the traces of online activities. From the analysis of these\nlarge-scale data sets (i.e. traces), we can get insights about dynamic behavior\nof human activity. In this letter, the scaling behavior and complexity of human\nactivity in the e-commerce, such as music, book, and movie rating, are\ncomprehensively investigated by using detrended fluctuation analysis technique\nand multiscale entropy method. Firstly, the interevent time series of rating\nbehaviors of these three type medias show the similar scaling property with\nexponents ranging from 0.53 to 0.58, which implies that the collective\nbehaviors of rating media follow a process embodying self-similarity and\nlong-range correlation. Meanwhile, by dividing the users into three groups\nbased their activities (i.e., rating per unit time), we find that the scaling\nexponents of interevent time series in three groups are different. Hence, these\nresults suggest the stronger long-range correlations exist in these collective\nbehaviors. Furthermore, their information complexities vary from three groups.\nTo explain the differences of the collective behaviors restricted to three\ngroups, we study the dynamic behavior of human activity at individual level,\nand find that the dynamic behaviors of a few users have extremely small scaling\nexponents associating with long-range anticorrelations. By comparing with the\ninterevent time distributions of four representative users, we can find that\nthe bimodal distributions may bring the extraordinary scaling behaviors. These\nresults of analyzing the online human activity in the e-commerce may not only\nprovide insights to understand its dynamic behaviors but also be applied to\nacquire the potential economic interest. \n\n"}
{"id": "1303.2650", "contents": "Title: Diffusion on hierarchical systems of weakly-coupled networks Abstract: We analyse diffusion dynamics on weakly-coupled networks (interconnected\nnetworks) by means of separation of time scales. Using an adiabatic\napproximation we reduced the system dynamics to a Markov chain with aggregated\nvariables and derived a transport equation that is analogous to Fick's First\nLaw and includes a driving force. Entropy production is a sum of microscopic\nentropy transport, which results from the particle's migration between networks\nof different topologies and macroscopic entropy production of the Markov chain.\nEquilibrium particles partition between different sub-networks depends only on\ninternal sub-network parameters. Our framework, confirmed by numerical\nsimulations, is also useful for considering diffusion in nested systems\ncorresponding to hierarchical networks with several different time scales thus\nit can serve to uncover hidden hierarchy levels from observations of diffusion\nprocesses. \n\n"}
{"id": "1303.3354", "contents": "Title: Delay-induced driven patterns in coupled Cayley tree networks Abstract: We study effects of delay in diffusively coupled logistic maps on the Cayley\ntree networks. We find that smaller coupling values exhibits sensitiveness for\nvalue of delay, and leads to different cluster patterns of self-organized and\ndriven types. Whereas larger coupling strengths are very robust against change\nin delay values, and leads to stable driven clusters comprising only nodes from\nlast generation of the Calaye tree. Furthermore, introduction of delay exhibits\nsuppression as well as enhancement of synchronization depending upon coupling\nstrength values, hence demonstrating richness of the model. To the end we\nrelate the results with social conflicts and cooperation observed in families. \n\n"}
{"id": "1303.3938", "contents": "Title: Fast selection of N-2 contingencies for online security assessment Abstract: We propose a novel algorithm for selection of dangerous N-2 contingencies\nassociated with line or generator failures. The algorithm is based on iterative\nfiltering of the set of all possible double contingencies. It is certified to\nidentify all the dangerous contingencies, and has the complexity comparable to\nthe N-1 contingency screening. Tests performed on realistic model of Polish\npower grid with about 3000 buses show that only two iterations of algorithm\nallow one to certify the safety of 99.9% of all double contingencies, leaving\nonly 0.1% of the most dangerous ones for direct analysis. \n\n"}
{"id": "1303.6686", "contents": "Title: Individual Performance and Leader's Laterality in Interactive Contests Abstract: Left-handedness is known to provide an intrinsic and tactical advantage at\ntop level in many sports involving interactive contests. Again, most of the\nrenowned leaders of the world are known to have been left-handed. Leadership\nplays an important role in politics, sports and mentorship. In this paper we\nshow that Cricket captains who bat left-handed have a strategic advantage over\nthe right-handed captains in One Day International (ODI) and Test matches. The\npresent study involving 46 left-handed captains and 148 right-handed captains\nin ODI matches, reveal a strong relation between leader's laterality and\nteam-member performance, demonstrating the critical importance of\nleft-handedness and successful leadership. The odds for superior batting\nperformance in an ODI match under left-handed captains are 89% higher than the\nodds under right-handed captains. Our study shows that left-handed captains are\nmore successful in extracting superior performance from the batsmen and bowlers\nin ODI and Test matches; perhaps indicating left-handed leaders are better\nmotivators as leaders when compared to right-handed captains. \n\n"}
{"id": "1304.2126", "contents": "Title: Braess like Paradox in a Small World Network Abstract: Braess \\cite{1} has been studied about a traffic flow on a diamond type\nnetwork and found that introducing new edges to the networks always does not\nachieve the efficiency. Some researchers studied the Braess' paradox in similar\ntype networks by introducing various types of cost functions. But whether such\nparadox occurs or not is not scarcely studied in complex networks. In this\narticle, I analytically and numerically study whether Braess like paradox\noccurs or not on Dorogovtsev-Mendes network\\cite{2}, which is a sort of small\nworld networks. The cost function needed to go along an edge is postulated to\nbe equally identified with the length between two nodes, independently of an\namount of traffic on the edge. It is also assumed the it takes a certain cost\n$c$ to pass through the center node in Dorogovtsev-Mendes network. If $c$ is\nsmall, then bypasses have the function to provide short cuts. As result of\nnumerical and theoretical analyses, while I find that any Braess' like paradox\nwill not occur when the network size becomes infinite, I can show that a\nparadoxical phenomenon appears at finite size of network. \n\n"}
{"id": "1304.3947", "contents": "Title: Bifurcations of Normally Hyperbolic Invariant Manifolds and Consequences\n  for Reaction Dynamics Abstract: In this paper we study the breakdown of normal hyperbolicity and its\nconsequences for reaction dynamics; in particular, the dividing surface, the\nflux through the dividing surface (DS), and the gap time distribution. Our\napproach is to study these questions using simple, two degree-of-freedom\nHamiltonian models where calculations for the different geometrical and\ndynamical quantities can be carried out exactly. For our examples, we show that\nresonances within the normally hyperbolic invariant manifold may, or may not,\nlead to a `loss of normal hyperbolicity'. Moreover, we show that the onset of\nsuch resonances results in a change in topology of the dividing surface, but\ndoes not affect our ability to define a DS. The flux through the DS varies\ncontinuously with energy, even as the energy is varied in such a way that\nnormal hyperbolicity is lost. For our examples the gap time distributions\nexhibit singularities at energies corresponding to the existence of homoclinic\norbits in the DS, but these singularities are not associated with loss of\nnormal hyperbolicity. \n\n"}
{"id": "1305.0507", "contents": "Title: Hub-Accelerator: Fast and Exact Shortest Path Computation in Large\n  Social Networks Abstract: Shortest path computation is one of the most fundamental operations for\nmanaging and analyzing large social networks. Though existing techniques are\nquite effective for finding the shortest path on large but sparse road\nnetworks, social graphs have quite different characteristics: they are\ngenerally non-spatial, non-weighted, scale-free, and they exhibit small-world\nproperties in addition to their massive size. In particular, the existence of\nhubs, those vertices with a large number of connections, explodes the search\nspace, making the shortest path computation surprisingly challenging. In this\npaper, we introduce a set of novel techniques centered around hubs,\ncollectively referred to as the Hub-Accelerator framework, to compute the\nk-degree shortest path (finding the shortest path between two vertices if their\ndistance is within k). These techniques enable us to significantly reduce the\nsearch space by either greatly limiting the expansion scope of hubs (using the\nnovel distance- preserving Hub-Network concept) or completely pruning away the\nhubs in the online search (using the Hub2-Labeling approach). The\nHub-Accelerator approaches are more than two orders of magnitude faster than\nBFS and the state-of-the-art approximate shortest path method Sketch for the\nshortest path computation. The Hub- Network approach does not introduce\nadditional index cost with light pre-computation cost; the index size and index\nconstruction cost of Hub2-Labeling are also moderate and better than or\ncomparable to the approximation indexing Sketch method. \n\n"}
{"id": "1305.3146", "contents": "Title: Discriminating Power of Centrality Measures Abstract: The calculation of centrality measures is common practice in the study of\nnetworks, as they attempt to quantify the importance of individual vertices,\nedges, or other components. Different centralities attempt to measure\nimportance in different ways. In this paper, we examine a conjecture posed by\nE. Estrada regarding the ability of several measures to distinguish the\nvertices of networks. Estrada conjectured that if all vertices of a graph have\nthe same subgraph centrality, then all vertices must also have the same degree,\neigenvector, closeness, and betweenness centralities. We provide a\ncounterexample for the latter two centrality measures and propose a revised\nconjecture. \n\n"}
{"id": "1305.3532", "contents": "Title: Temporal networks of face-to-face human interactions Abstract: The ever increasing adoption of mobile technologies and ubiquitous services\nallows to sense human behavior at unprecedented levels of details and scale.\nWearable sensors are opening up a new window on human mobility and proximity at\nthe finest resolution of face-to-face proximity. As a consequence, empirical\ndata describing social and behavioral networks are acquiring a longitudinal\ndimension that brings forth new challenges for analysis and modeling. Here we\nreview recent work on the representation and analysis of temporal networks of\nface-to-face human proximity, based on large-scale datasets collected in the\ncontext of the SocioPatterns collaboration. We show that the raw behavioral\ndata can be studied at various levels of coarse-graining, which turn out to be\ncomplementary to one another, with each level exposing different features of\nthe underlying system. We briefly review a generative model of temporal contact\nnetworks that reproduces some statistical observables. Then, we shift our focus\nfrom surface statistical features to dynamical processes on empirical temporal\nnetworks. We discuss how simple dynamical processes can be used as probes to\nexpose important features of the interaction patterns, such as burstiness and\ncausal constraints. We show that simulating dynamical processes on empirical\ntemporal networks can unveil differences between datasets that would otherwise\nlook statistically similar. Moreover, we argue that, due to the temporal\nheterogeneity of human dynamics, in order to investigate the temporal\nproperties of spreading processes it may be necessary to abandon the notion of\nwall-clock time in favour of an intrinsic notion of time for each individual\nnode, defined in terms of its activity level. We conclude highlighting several\nopen research questions raised by the nature of the data at hand. \n\n"}
{"id": "1305.4503", "contents": "Title: Stochastic perturbation of integrable systems: a window to weakly\n  chaotic systems Abstract: Integrable non-linear Hamiltonian systems perturbed by additive noise develop\na Lyapunov instability, and are hence chaotic, for any amplitude of the\nperturbation. This phenomenon is related, but distinct, from Taylor's diffusion\nin hydrodynamics. We develop expressions for the Lyapunov exponents for the\ncases of white and colored noise. The situation described here being\n`multi-resonance' -- by nature well beyond the Kolmogorov-Arnold-Moser regime,\nit offers an analytic glimpse on the regime in which many near-integrable\nsystems, such as some planetary systems, find themselves in practice. We show\nwith the aid of a simple example, how one may model in some cases weakly\nchaotic deterministic systems by a stochastically perturbed one, with good\nqualitative results. \n\n"}
{"id": "1305.5153", "contents": "Title: Pair quenched mean-field theory for the susceptible-infected-susceptible\n  model on complex networks Abstract: We present a quenched mean-field (QMF) theory for the dynamics of the\nsusceptible-infected-susceptible (SIS) epidemic model on complex networks where\ndynamical correlations between connected vertices are taken into account by\nmeans of a pair approximation. We present analytical expressions of the\nepidemic thresholds in the star and wheel graphs and in random regular\nnetworks. For random networks with a power law degree distribution, the\nthresholds are numerically determined via an eigenvalue problem. The pair and\none-vertex QMF theories yield the same scaling for the thresholds as functions\nof the network size. However, comparisons with quasi-stationary simulations of\nthe SIS dynamics on large networks show that the former is quantitatively much\nmore accurate than the latter. Our results demonstrate the central role played\nby dynamical correlations on the epidemic spreading and introduce an efficient\nway to theoretically access the thresholds of very large networks that can be\nextended to dynamical processes in general. \n\n"}
{"id": "1305.6364", "contents": "Title: Unraveling the origin of exponential law in intra-urban human mobility Abstract: The vast majority of travel takes place within cities. Recently, new data has\nbecome available which allows for the discovery of urban mobility patterns\nwhich differ from established results about long distance travel. Specifically,\nthe latest evidence increasingly points to exponential trip length\ndistributions, contrary to the scaling laws observed on larger scales. In this\npaper, in order to explore the origin of the exponential law, we propose a new\nmodel which can predict individual flows in urban areas better. Based on the\nmodel, we explain the exponential law of intra-urban mobility as a result of\nthe exponential decrease in average population density in urban areas. Indeed,\nboth empirical and analytical results indicate that the trip length and the\npopulation density share the same exponential decaying rate. \n\n"}
{"id": "1306.0257", "contents": "Title: Spatially distributed social complex networks Abstract: We propose a bare-bones stochastic model that takes into account both the\ngeographical distribution of people within a country and their complex network\nof connections. The model, which is designed to give rise to a scale-free\nnetwork of social connections and to visually resemble the geographical spread\nseen in satellite pictures of the Earth at night, gives rise to a power-law\ndistribution for the ranking of cities by population size (but for the largest\ncities) and reflects the notion that highly connected individuals tend to live\nin highly populated areas. It also yields some interesting insights regarding\nGibrat's law for the rates of city growth (by population size), in partial\nsupport of the findings in a recent analysis of real data [Rozenfeld et al.,\nProc. Natl. Acad. Sci. U.S.A. 105, 18702 (2008)]. The model produces a\nnontrivial relation between city population and city population density and a\nsuperlinear relationship between social connectivity and city population, both\nof which seem quite in line with real data. \n\n"}
{"id": "1306.0340", "contents": "Title: Majority-vote model on Opinion-Dependent Networks Abstract: We study a nonequilibrium model with up-down symmetry and a noise parameter\n$q$ known as majority-vote model of M.J. Oliveira $1992$ on opinion-dependent\nnetwork or Stauffer-Hohnisch-Pittnauer networks. By Monte Carlo simulations and\nfinite-size scaling relations the critical exponents $\\beta/\\nu$, $\\gamma/\\nu$,\nand $1/\\nu$ and points $q_{c}$ and $U^*$ are obtained. After extensive\nsimulations, we obtain $\\beta/\\nu=0.230(3)$, $\\gamma/\\nu=0.535(2)$, and\n$1/\\nu=0.475(8)$. The calculated values of the critical noise parameter and\nBinder cumulant are $q_{c}=0.166(3)$ and $U^*=0.288(3)$. Within the error bars,\nthe exponents obey the relation $2\\beta/\\nu+\\gamma/\\nu=1$ and the results\npresented here demonstrate that the majority-vote model belongs to a different\nuniversality class than the equilibrium Ising model on\nStauffer-Hohnisch-Pittnauer networks, but to the same class as majority-vote\nmodels on some other networks. \n\n"}
{"id": "1306.2144", "contents": "Title: Importance Nested Sampling and the MultiNest Algorithm Abstract: Bayesian inference involves two main computational challenges. First, in\nestimating the parameters of some model for the data, the posterior\ndistribution may well be highly multi-modal: a regime in which the convergence\nto stationarity of traditional Markov Chain Monte Carlo (MCMC) techniques\nbecomes incredibly slow. Second, in selecting between a set of competing models\nthe necessary estimation of the Bayesian evidence for each is, by definition, a\n(possibly high-dimensional) integration over the entire parameter space; again\nthis can be a daunting computational task, although new Monte Carlo (MC)\nintegration algorithms offer solutions of ever increasing efficiency. Nested\nsampling (NS) is one such contemporary MC strategy targeted at calculation of\nthe Bayesian evidence, but which also enables posterior inference as a\nby-product, thereby allowing simultaneous parameter estimation and model\nselection. The widely-used MultiNest algorithm presents a particularly\nefficient implementation of the NS technique for multi-modal posteriors. In\nthis paper we discuss importance nested sampling (INS), an alternative\nsummation of the MultiNest draws, which can calculate the Bayesian evidence at\nup to an order of magnitude higher accuracy than `vanilla' NS with no change in\nthe way MultiNest explores the parameter space. This is accomplished by\ntreating as a (pseudo-)importance sample the totality of points collected by\nMultiNest, including those previously discarded under the constrained\nlikelihood sampling of the NS algorithm. We apply this technique to several\nchallenging test problems and compare the accuracy of Bayesian evidences\nobtained with INS against those from vanilla NS. \n\n"}
{"id": "1306.5004", "contents": "Title: Statistical mechanics of the US Supreme Court Abstract: We build simple models for the distribution of voting patterns in a group,\nusing the Supreme Court of the United States as an example. The least\nstructured, or maximum entropy, model that is consistent with the observed\npairwise correlations among justices' votes is equivalent to an Ising spin\nglass. While all correlations (perhaps surprisingly) are positive, the\neffective pairwise interactions in the spin glass model have both signs,\nrecovering some of our intuition that justices on opposite sides of the\nideological spectrum should have a negative influence on one another. Despite\nthe competing interactions, a strong tendency toward unanimity emerges from the\nmodel, and this agrees quantitatively with the data. The model shows that\nvoting patterns are organized in a relatively simple \"energy landscape,\"\ncorrectly predicts the extent to which each justice is correlated with the\nmajority, and gives us a measure of the influence that justices exert on one\nanother. These results suggest that simple models, grounded in statistical\nphysics, can capture essential features of collective decision making\nquantitatively, even in a complex political context. \n\n"}
{"id": "1307.2064", "contents": "Title: Cycles of strategies and changes of distribution in public goods game:\n  An experimental investigation Abstract: In this communication, a simple mechanism in the optional public goods game\nis experimentally investigated using two experimental settings; and first time,\nthe cyclic strategy pattern in full state space is demonstrated by means of\nvelocity. It is, furthermore, elaborated that the strategies of cooperation,\ndefection and nonparticipant form a Rock-Paper-Scissors type cycle, and the\ncycle of three strategies are persistent over 200 rounds. This cycle is very\nsimilar to the cycle given by evolutionary dynamics e.g. replicator dynamics.\nThe mechanism that nonparticipant can sustain cooperation is driven by the\nRock-Paper-Scissors type of cyclic dominance in the three strategies. That is,\nif the cycle is existent, the cooperation will always sustain. Meanwhile, the\ndistribution of social states changes in the state space and from cooperation\nas the most frequent strategy to defection and, from defection to\nnonparticipant, forms a clear rotation path in a long run. These results seem\nto implicate that the evolutionary dynamics has ability to capture the real\ndynamics applying not only on biosphere, but also on human society. \n\n"}
{"id": "1307.2090", "contents": "Title: Spectral properties of the Laplacian of multiplex networks Abstract: One of the more challenging tasks in the understanding of dynamical\nproperties of models on top of complex networks is to capture the precise role\nof multiplex topologies. In a recent paper, Gomez et al. [Phys. Rev. Lett. 101,\n028701 (2013)] proposed a framework for the study of diffusion processes in\nsuch networks. Here, we extend the previous framework to deal with general\nconfigurations in several layers of networks, and analyze the behavior of the\nspectrum of the Laplacian of the full multiplex. We derive an interesting\ndecoupling of the problem that allow us to unravel the role played by the\ninterconnections of the multiplex in the dynamical processes on top of them.\nCapitalizing on this decoupling we perform an asymptotic analysis that allow us\nto derive analytical expressions for the full spectrum of eigenvalues. This\nspectrum is used to gain insight into physical phenomena on top of multiplex,\nspecifically, diffusion processes and synchronizability. \n\n"}
{"id": "1307.4143", "contents": "Title: Storage Sizing and Placement through Operational and Uncertainty-Aware\n  Simulations Abstract: As the penetration level of transmission-scale time-intermittent renewable\ngeneration resources increases, control of flexible resources will become\nimportant to mitigating the fluctuations due to these new renewable resources.\nFlexible resources may include new or existing synchronous generators as well\nas new energy storage devices. Optimal placement and sizing of energy storage\nto minimize costs of integrating renewable resources is a difficult\noptimization problem. Further,optimal planning procedures typically do not\nconsider the effect of the time dependence of operations and may lead to\nunsatisfactory results. Here, we use an optimal energy storage control\nalgorithm to develop a heuristic procedure for energy storage placement and\nsizing. We perform operational simulation under various time profiles of\nintermittent generation, loads and interchanges (artificially generated or from\nhistorical data) and accumulate statistics of the usage of storage at each node\nunder the optimal dispatch. We develop a greedy heuristic based on the\naccumulated statistics to obtain a minimal set of nodes for storage placement.\nThe quality of the heuristic is explored by comparing our results to the\nobvious heuristic of placing storage at the renewables for IEEE benchmarks and\nreal-world network topologies. \n\n"}
{"id": "1307.4158", "contents": "Title: Metrics for multi-detector template placement in searches for\n  short-duration nonprecessing inspiral gravitational-wave signals Abstract: Using the family of multi-detector F-statistic metrics for short duration,\nnonprecessing inspiral signals, we derive a marginalized metric that is\ndirectly applicable to the problem of generating template banks for coincident\nand coherent multi-detector searches for gravitational-waves. This metric is\ncompared to other average metrics, such as that proposed for the case of\nsearches associated with continuous signals from rotating neutron stars. We\nshow how the four-dimensional metric can be separated into two two-dimensional\nmetrics associated with the sky and mass parameter subspaces, allowing the\ncreation of separate template banks for these subspaces. Finally, we present an\nalgorithm for computing the mass space metric associated with both coincident\nand coherent multi-detector targeted or all-sky searches for short duration,\nnonprecessing inspiral gravitational-wave signals. \n\n"}
{"id": "1307.4952", "contents": "Title: The Pin-Bang Theory: Discovering The Pinterest World Abstract: Pinterest is an image-based online social network, which was launched in the\nyear 2010 and has gained a lot of traction, ever since. Within 3 years,\nPinterest has attained 48.7 million unique users. This stupendous growth makes\nit interesting to study Pinterest, and gives rise to multiple questions about\nit's users, and content. We characterized Pinterest on the basis of large scale\ncrawls of 3.3 million user profiles, and 58.8 million pins. In particular, we\nexplored various attributes of users, pins, boards, pin sources, and user\nlocations, in detail and performed topical analysis of user generated textual\ncontent. The characterization revealed most prominent topics among users and\npins, top image sources, and geographical distribution of users on Pinterest.\nWe then investigated this social network from a privacy and security\nstandpoint, and found traces of malware in the form of pin sources. Instances\nof Personally Identifiable Information (PII) leakage were also discovered in\nthe form of phone numbers, BBM (Blackberry Messenger) pins, and email\naddresses. Further, our analysis demonstrated how Pinterest is a potential\nvenue for copyright infringement, by showing that almost half of the images\nshared on Pinterest go uncredited. To the best of our knowledge, this is the\nfirst attempt to characterize Pinterest at such a large scale. \n\n"}
{"id": "1307.5268", "contents": "Title: South African Riots: Repercussion of the Global Food Crisis and US\n  Drought Abstract: High and volatile global food prices have led to food riots and played a\ncritical role in triggering the Arab Spring revolutions in recent years. The\nsevere drought in the US in the summer of 2012 led to a new increase in food\nprices. Through the fall, they remained at a threshold above which the riots\nand revolutions had predominantly occurred. Global prices at this level create\nconditions where an exacerbating local circumstance can trigger unrest. Global\ncorn (maize) prices reached new highs, and countries that depend mostly on\nmaize are more likely to experience high local food prices and associated\npressures toward social unrest. Here we analyze the conditions in South Africa,\nwhich is a heavily maize-dependent country. Coinciding with increased consumer\nfood indices this summer, massive labor strikes in mining and agriculture have\nled to the greatest single incident of social violence since the fall of\napartheid in 1994. Worker demands for dramatic pay increases reflect that their\nwages have not kept up with drastic increases in the prices of necessities,\nespecially food. Without attention to the global food price situation, more\nincidents of food-based social instability are likely to arise. Other countries\nthat have manifested food-related protests and riots in 2012 include Haiti and\nArgentina. Moreover, these cases of unrest are just the most visible symptom of\nwidespread suffering of poor populations worldwide due to elevated food prices.\nPolicy decisions that would directly impact food prices are decreasing the\nconversion of maize to ethanol in the US, and reimposing regulations on\ncommodity futures markets to prevent excessive speculation, which we have shown\ncauses bubbles and crashes in these markets. Absent such policy actions,\ngovernments and companies should track and mitigate the impact of high and\nvolatile food prices on citizens and employees. \n\n"}
{"id": "1307.5707", "contents": "Title: Quantum Gibbs distribution from dynamical thermalization in classical\n  nonlinear lattices Abstract: We study numerically time evolution in classical lattices with weak or\nmoderate nonlinearity which leads to interactions between linear modes. Our\nresults show that in a certain strength range a moderate nonlinearity generates\na dynamical thermalization process which drives the system to the quantum Gibbs\ndistribution of probabilities, or average oscillation amplitudes. The effective\ndynamical temperature of the lattice varies from large positive to large\nnegative values depending on energy of initially excited modes. This quantum\nGibbs distribution is drastically different from usually expected energy\nequipartition over linear modes corresponding to a regime of classical\nthermalization. Possible experimental observations of this dynamical\nthermalization are discussed for cold atoms in optical lattices, nonlinear\nphotonic lattices and optical fiber arrays. \n\n"}
{"id": "1307.6145", "contents": "Title: Online Communities: Visualization and Formalization Abstract: Online communities have increased in size and importance dramatically over\nthe last decade. The fact that many communities are online means that it is\npossible to extract information about these communities and the connections\nbetween their members much more easily using software tools, despite their\npotentially very large size. The links between members of the community can be\npresented visually and often this can make patterns in the structure of\nsub-communities immediately obvious. The links and structures of layered\ncommunities can also be formalized to gain a better understanding of their\nmodelling. This paper explores these links with some specific examples,\nincluding visualization of these relationships and a formalized model of\ncommunities using the Z notation. It also considers the development of such\ncommunities within the Community of Practice social science framework. Such\napproaches may be applicable for communities associated with cybersecurity and\ncould be combined for a better understanding of their development. \n\n"}
{"id": "1307.6359", "contents": "Title: Percolation in Multiplex Networks with Overlap Abstract: From transportation networks to complex infrastructures, and to social and\ncommunication networks, a large variety of systems can be described in terms of\nmultiplexes formed by a set of nodes interacting through different networks\n(layers). Multiplexes may display an increased fragility with respect to the\nsingle layers that constitute them. However, so far the overlap of the links in\ndifferent layers has been mostly neglected, despite the fact that it is an\nubiquitous phenomenon in most multiplexes. Here we show that the overlap among\nlayers can improve the robustness of interdependent multiplex systems and\nchange the critical behavior of the percolation phase transition in a complex\nway. \n\n"}
{"id": "1308.0726", "contents": "Title: Power Laws and Fragility in Flow Networks Abstract: What makes economic and ecological networks so unlike other highly skewed\nnetworks in their tendency toward turbulence and collapse? Here, we explore the\nconsequences of a defining feature of these networks: their nodes are tied\ntogether by flow. We show that flow networks tend to the power law degree\ndistribution (PLDD) due to a self-reinforcing process involving position within\nthe global network structure, and thus present the first random graph model for\nPLDDs that does not depend on a rich-get-richer function of nodal degree. We\nalso show that in contrast to non-flow networks, PLDD flow networks are\ndramatically more vulnerable to catastrophic failure than non-PLDD flow\nnetworks, a finding with potential explanatory power in our age of resource-\nand financial-interdependence and turbulence. \n\n"}
{"id": "1308.4038", "contents": "Title: Multifractal portrayal of the Swiss population Abstract: Fractal geometry is a fundamental approach for describing the complex\nirregularities of the spatial structure of point patterns. The present research\ncharacterizes the spatial structure of the Swiss population distribution in the\nthree Swiss geographical regions (Alps, Plateau and Jura) and at the entire\ncountry level. These analyses were carried out using fractal and multifractal\nmeasures for point patterns, which enabled the estimation of the spatial degree\nof clustering of a distribution at different scales. The Swiss population\ndataset is presented on a grid of points and thus it can be modelled as a\n\"point process\" where each point is characterized by its spatial location\n(geometrical support) and a number of inhabitants (measured variable). The\nfractal characterization was performed by means of the box-counting dimension\nand the multifractal analysis was conducted through the Renyi's generalized\ndimensions and the multifractal spectrum. Results showed that the four\npopulation patterns are all multifractals and present different clustering\nbehaviours. Applying multifractal and fractal methods at different geographical\nregions and at different scales allowed us to quantify and describe the\ndissimilarities between the four structures and their underlying processes.\nThis paper is the first Swiss geodemographic study applying multifractal\nmethods using high resolution data. \n\n"}
{"id": "1308.4867", "contents": "Title: Information geometric complexity of entropic motion on curved\n  statistical manifolds Abstract: Physical systems behave according to their underlying dynamical equations\nwhich, in turn, can be identified from experimental data. Explaining data\nrequires selecting mathematical models that best capture the data regularities.\nIdentifying dynamical equations from the available data and statistical model\nselection are both very difficult tasks. Motivated by these fundamental links\namong physical systems, dynamical equations, experimental data and statistical\nmodeling, we discuss in this invited Contribution our information geometric\nmeasure of complexity of geodesic paths on curved statistical manifolds\nunderlying the entropic dynamics of classical physical systems described by\nprobability distributions. We also provide several illustrative examples of\nentropic dynamical models used to infer macroscopic predictions when only\npartial knowledge of the microscopic nature of the system is available.\nFinally, we present entropic arguments to briefly address complexity softening\neffects due to statistical embedding procedures. \n\n"}
{"id": "1309.0790", "contents": "Title: SKYNET: an efficient and robust neural network training tool for machine\n  learning in astronomy Abstract: We present the first public release of our generic neural network training\nalgorithm, called SkyNet. This efficient and robust machine learning tool is\nable to train large and deep feed-forward neural networks, including\nautoencoders, for use in a wide range of supervised and unsupervised learning\napplications, such as regression, classification, density estimation,\nclustering and dimensionality reduction. SkyNet uses a `pre-training' method to\nobtain a set of network parameters that has empirically been shown to be close\nto a good solution, followed by further optimisation using a regularised\nvariant of Newton's method, where the level of regularisation is determined and\nadjusted automatically; the latter uses second-order derivative information to\nimprove convergence, but without the need to evaluate or store the full Hessian\nmatrix, by using a fast approximate method to calculate Hessian-vector\nproducts. This combination of methods allows for the training of complicated\nnetworks that are difficult to optimise using standard backpropagation\ntechniques. SkyNet employs convergence criteria that naturally prevent\noverfitting, and also includes a fast algorithm for estimating the accuracy of\nnetwork outputs. The utility and flexibility of SkyNet are demonstrated by\napplication to a number of toy problems, and to astronomical problems focusing\non the recovery of structure from blurred and noisy images, the identification\nof gamma-ray bursters, and the compression and denoising of galaxy images. The\nSkyNet software, which is implemented in standard ANSI C and fully parallelised\nusing MPI, is available at http://www.mrao.cam.ac.uk/software/skynet/. \n\n"}
{"id": "1309.1392", "contents": "Title: Bayesian Structural Inference for Hidden Processes Abstract: We introduce a Bayesian approach to discovering patterns in structurally\ncomplex processes. The proposed method of Bayesian Structural Inference (BSI)\nrelies on a set of candidate unifilar HMM (uHMM) topologies for inference of\nprocess structure from a data series. We employ a recently developed exact\nenumeration of topological epsilon-machines. (A sequel then removes the\ntopological restriction.) This subset of the uHMM topologies has the added\nbenefit that inferred models are guaranteed to be epsilon-machines,\nirrespective of estimated transition probabilities. Properties of\nepsilon-machines and uHMMs allow for the derivation of analytic expressions for\nestimating transition probabilities, inferring start states, and comparing the\nposterior probability of candidate model topologies, despite process internal\nstructure being only indirectly present in data. We demonstrate BSI's\neffectiveness in estimating a process's randomness, as reflected by the Shannon\nentropy rate, and its structure, as quantified by the statistical complexity.\nWe also compare using the posterior distribution over candidate models and the\nsingle, maximum a posteriori model for point estimation and show that the\nformer more accurately reflects uncertainty in estimated values. We apply BSI\nto in-class examples of finite- and infinite-order Markov processes, as well to\nan out-of-class, infinite-state hidden process. \n\n"}
{"id": "1309.1472", "contents": "Title: Quantum discord determines the interferometric power of quantum states Abstract: Quantum metrology exploits quantum mechanical laws to improve the precision\nin estimating technologically relevant parameters such as phase, frequency, or\nmagnetic fields. Probe states are usually tailored on the particular dynamics\nwhose parameters are being estimated. Here we consider a novel framework where\nquantum estimation is performed in an interferometric configuration, using\nbipartite probe states prepared when only the spectrum of the generating\nHamiltonian is known. We introduce a figure of merit for the scheme, given by\nthe worst case precision over all suitable Hamiltonians, and prove that it\namounts exactly to a computable measure of discord-type quantum correlations\nfor the input probe. We complement our theoretical results with a metrology\nexperiment, realized in a highly controllable room-temperature nuclear magnetic\nresonance setup, which provides a proof-of-concept demonstration for the\nusefulness of discord in sensing applications. Discordant probes are shown to\nguarantee a nonzero precision in the estimation procedure for different\ngenerating Hamiltonians, while classically correlated probes are unable to\naccomplish the estimation in a worst case setting. This work establishes a\nrigorous and direct operational interpretation for general quantum\ncorrelations, shedding light on their potential for quantum technology. \n\n"}
{"id": "1309.3959", "contents": "Title: Bounded Confidence Opinion Dynamics in a Social Network of Bayesian\n  Decision Makers Abstract: Bounded confidence opinion dynamics model the propagation of information in\nsocial networks. However in the existing literature, opinions are only viewed\nas abstract quantities without semantics rather than as part of a\ndecision-making system. In this work, opinion dynamics are examined when agents\nare Bayesian decision makers that perform hypothesis testing or signal\ndetection, and the dynamics are applied to prior probabilities of hypotheses.\nBounded confidence is defined on prior probabilities through Bayes risk error\ndivergence, the appropriate measure between priors in hypothesis testing. This\ndefinition contrasts with the measure used between opinions in standard models:\nabsolute error. It is shown that the rapid convergence of prior probabilities\nto a small number of limiting values is similar to that seen in the standard\nKrause-Hegselmann model. The most interesting finding in this work is that the\nnumber of these limiting values and the time to convergence changes with the\nsignal-to-noise ratio in the detection task. The number of final values or\nclusters is maximal at intermediate signal-to-noise ratios, suggesting that the\nmost contentious issues lead to the largest number of factions. It is at these\nsame intermediate signal-to-noise ratios at which the degradation in detection\nperformance of the aggregate vote of the decision makers is greatest in\ncomparison to the Bayes optimal detection performance. \n\n"}
{"id": "1309.4058", "contents": "Title: Why SOV might be initially preferred and then lost or recovered? A\n  theoretical framework Abstract: Little is known about why SOV order is initially preferred and then discarded\nor recovered. Here we present a framework for understanding these and many\nrelated word order phenomena: the diversity of dominant orders, the existence\nof free words orders, the need of alternative word orders and word order\nreversions and cycles in evolution. Under that framework, word order is\nregarded as a multiconstraint satisfaction problem in which at least two\nconstraints are in conflict: online memory minimization and maximum\npredictability. \n\n"}
{"id": "1309.4796", "contents": "Title: Bayesian Degree-Corrected Stochastic Blockmodels for Community Detection Abstract: Community detection in networks has drawn much attention in diverse fields,\nespecially social sciences. Given its significance, there has been a large body\nof literature with approaches from many fields. Here we present a statistical\nframework that is representative, extensible, and that yields an estimator with\ngood properties. Our proposed approach considers a stochastic blockmodel based\non a logistic regression formulation with node correction terms. We follow a\nBayesian approach that explicitly captures the community behavior via prior\nspecification. We further adopt a data augmentation strategy with latent\nPolya-Gamma variables to obtain posterior samples. We conduct inference based\non a principled, canonically mapped centroid estimator that formally addresses\nlabel non-identifiability and captures representative community assignments. We\ndemonstrate the proposed model and estimation on real-world as well as\nsimulated benchmark networks and show that the proposed model and estimator are\nmore flexible, representative, and yield smaller error rates when compared to\nthe MAP estimator from classical degree-corrected stochastic blockmodels. \n\n"}
{"id": "1309.6972", "contents": "Title: Interdependent networks: the fragility of control Abstract: Recent work in the area of interdependent networks has focused on\ninteractions between two systems of the same type. However, an important and\nubiquitous class of systems are those involving monitoring and control, an\nexample of interdependence between processes that are very different. In this\nArticle, we introduce a framework for modelling distributed supervisory control\nin the guise of an electrical network supervised by a distributed system of\ncontrol devices. The system is characterised by degrees of freedom salient to\nreal-world systems--- namely, the number of control devices, their inherent\nreliability, and the topology of the control network. Surprisingly, the\nbehavior of the system depends crucially on the reliability of control devices.\nWhen devices are completely reliable, cascade sizes are percolation controlled;\nthe number of devices being the relevant parameter. For unreliable devices, the\ntopology of the control network is important and can dramatically reduce the\nresilience of the system. \n\n"}
{"id": "1309.7031", "contents": "Title: Controlling Contagion Processes in Time-Varying Networks Abstract: The vast majority of strategies aimed at controlling contagion processes on\nnetworks considers the connectivity pattern of the system as either quenched or\nannealed. However, in the real world many networks are highly dynamical and\nevolve in time concurrently to the contagion process. Here, we derive an\nanalytical framework for the study of control strategies specifically devised\nfor time-varying networks. We consider the removal/immunization of individual\nnodes according the their activity in the network and develop a block variable\nmean-field approach that allows the derivation of the equations describing the\nevolution of the contagion process concurrently to the network dynamic. We\nderive the critical immunization threshold and assess the effectiveness of the\ncontrol strategies. Finally, we validate the theoretical picture by simulating\nnumerically the information spreading process and control strategies in both\nsynthetic networks and a large-scale, real-world mobile telephone call dataset \n\n"}
{"id": "1309.7233", "contents": "Title: Multilayer Networks Abstract: In most natural and engineered systems, a set of entities interact with each\nother in complicated patterns that can encompass multiple types of\nrelationships, change in time, and include other types of complications. Such\nsystems include multiple subsystems and layers of connectivity, and it is\nimportant to take such \"multilayer\" features into account to try to improve our\nunderstanding of complex systems. Consequently, it is necessary to generalize\n\"traditional\" network theory by developing (and validating) a framework and\nassociated tools to study multilayer systems in a comprehensive fashion. The\norigins of such efforts date back several decades and arose in multiple\ndisciplines, and now the study of multilayer networks has become one of the\nmost important directions in network science. In this paper, we discuss the\nhistory of multilayer networks (and related concepts) and review the exploding\nbody of work on such networks. To unify the disparate terminology in the large\nbody of recent work, we discuss a general framework for multilayer networks,\nconstruct a dictionary of terminology to relate the numerous existing concepts\nto each other, and provide a thorough discussion that compares, contrasts, and\ntranslates between related notions such as multilayer networks, multiplex\nnetworks, interdependent networks, networks of networks, and many others. We\nalso survey and discuss existing data sets that can be represented as\nmultilayer networks. We review attempts to generalize single-layer-network\ndiagnostics to multilayer networks. We also discuss the rapidly expanding\nresearch on multilayer-network models and notions like community structure,\nconnected components, tensor decompositions, and various types of dynamical\nprocesses on multilayer networks. We conclude with a summary and an outlook. \n\n"}
{"id": "1309.7740", "contents": "Title: The quantum approach to human reasoning does explain the belief-bias\n  effect Abstract: Based on the ideas of quantum physics and dual-process theory of human\nreasoning that takes into account two primary mechanisms of reasoning : 1)\ndeductive rational thinking and 2) intuitive heuristic judgment, we proposed\nthe \"quantum\" approach to practical human logic that allows one to specify the\nmost distinctive peculiarities in activity of two reasoning systems mentioned\nabove and in addition to describe phenomenologically well-established\nexperimentally belief-bias effect. \n\n"}
{"id": "1310.2446", "contents": "Title: A statistical physics perspective on criticality in financial markets Abstract: Stock markets are complex systems exhibiting collective phenomena and\nparticular features such as synchronization, fluctuations distributed as\npower-laws, non-random structures and similarity to neural networks. Such\nspecific properties suggest that markets operate at a very special point.\nFinancial markets are believed to be critical by analogy to physical systems\nbut few statistically founded evidence have been given. Through a data-based\nmethodology and comparison to simulations inspired by statistical physics of\ncomplex systems, we show that the Dow Jones and indices sets are not rigorously\ncritical. However, financial systems are closer to the criticality in the crash\nneighborhood. \n\n"}
{"id": "1310.3980", "contents": "Title: Decay towards the overall-healthy state in SIS epidemics on networks Abstract: The decay rate of SIS epidemics on the complete graph $K_{N}$ is computed\nanalytically, based on a new, algebraic method to compute the second largest\neigenvalue of a stochastic three-diagonal matrix up to arbitrary precision. The\nlatter problem has been addressed around 1950, mainly via the theory of\northogonal polynomials and probability theory. The accurate determination of\nthe second largest eigenvalue, also called the \\emph{decay parameter}, has been\nan outstanding problem appearing in general birth-death processes and random\nwalks. Application of our general framework to SIS epidemics shows that the\nmaximum average lifetime of an SIS epidemics in any network with $N$ nodes is\nnot larger (but tight for $K_{N}$) than \\[ E\\left[ T\\right]\n\\sim\\frac{1}{\\delta}\\frac{\\frac{\\tau}{\\tau_{c}}\\sqrt{2\\pi}% }{\\left(\n\\frac{\\tau}{\\tau_{c}}-1\\right) ^{2}}\\frac{\\exp\\left( N\\left\\{\n\\log\\frac{\\tau}{\\tau_{c}}+\\frac{\\tau_{c}}{\\tau}-1\\right\\} \\right) }{\\sqrt\n{N}}=O\\left( e^{N\\ln\\frac{\\tau}{\\tau_{c}}}\\right) \\] for large $N$ and for an\neffective infection rate $\\tau=\\frac{\\beta}{\\delta}$ above the epidemic\nthreshold $\\tau_{c}$. Our order estimate of $E\\left[ T\\right] $ sharpens the\norder estimate $E\\left[ T\\right] =O\\left( e^{bN^{a}}\\right) $ of Draief and\nMassouli\\'{e} \\cite{Draief_Massoulie}. Combining the lower bound results of\nMountford \\emph{et al.} \\cite{Mountford2013} and our upper bound, we conclude\nthat for almost all graphs, the average time to absorption for $\\tau>\\tau_{c}$\nis $E\\left[ T\\right] =O\\left( e^{c_{G}N}\\right) $, where $c_{G}>0$ depends on\nthe topological structure of the graph $G$ and $\\tau$. \n\n"}
{"id": "1310.4377", "contents": "Title: Hierarchical Block Structures and High-resolution Model Selection in\n  Large Networks Abstract: Discovering and characterizing the large-scale topological features in\nempirical networks are crucial steps in understanding how complex systems\nfunction. However, most existing methods used to obtain the modular structure\nof networks suffer from serious problems, such as being oblivious to the\nstatistical evidence supporting the discovered patterns, which results in the\ninability to separate actual structure from noise. In addition to this, one\nalso observes a resolution limit on the size of communities, where smaller but\nwell-defined clusters are not detectable when the network becomes large. This\nphenomenon occurs not only for the very popular approach of modularity\noptimization, which lacks built-in statistical validation, but also for more\nprincipled methods based on statistical inference and model selection, which do\nincorporate statistical validation in a formally correct way. Here we construct\na nested generative model that, through a complete description of the entire\nnetwork hierarchy at multiple scales, is capable of avoiding this limitation,\nand enables the detection of modular structure at levels far beyond those\npossible with current approaches. Even with this increased resolution, the\nmethod is based on the principle of parsimony, and is capable of separating\nsignal from noise, and thus will not lead to the identification of spurious\nmodules even on sparse networks. Furthermore, it fully generalizes other\napproaches in that it is not restricted to purely assortative mixing patterns,\ndirected or undirected graphs, and ad hoc hierarchical structures such as\nbinary trees. Despite its general character, the approach is tractable, and can\nbe combined with advanced techniques of community detection to yield an\nefficient algorithm that scales well for very large networks. \n\n"}
{"id": "1310.4975", "contents": "Title: Competitive dynamics of lexical innovations in multi-layer networks Abstract: We study the introduction of lexical innovations into a community of language\nusers. Lexical innovations, i.e., new terms added to people's vocabulary, play\nan important role in the process of language evolution. Nowadays, information\nis spread through a variety of networks, including, among others, online and\noffline social networks and the World Wide Web. The entire system, comprising\nnetworks of different nature, can be represented as a multi-layer network. In\nthis context, lexical innovations diffusion occurs in a peculiar fashion. In\nparticular, a lexical innovation can undergo three different processes: its\noriginal meaning is accepted; its meaning can be changed or misunderstood\n(e.g., when not properly explained), hence more than one meaning can emerge in\nthe population; lastly, in the case of a loan word, it can be translated into\nthe population language (i.e., defining a new lexical innovation or using a\nsynonym) or into a dialect spoken by part of the population. Therefore, lexical\ninnovations cannot be considered simply as information. We develop a model for\nanalyzing this scenario using a multi-layer network comprising a social network\nand a media network. The latter represents the set of all information systems\nof a society, e.g., television, the World Wide Web and radio. Furthermore, we\nidentify temporal directed edges between the nodes of these two networks. In\nparticular, at each time step, nodes of the media network can be connected to\nrandomly chosen nodes of the social network and vice versa. In so doing,\ninformation spreads through the whole system and people can share a lexical\ninnovation with their neighbors or, in the event they work as reporters, by\nusing media nodes. Lastly, we use the concept of \"linguistic sign\" to model\nlexical innovations, showing its fundamental role in the study of these\ndynamics. Many numerical simulations have been performed. \n\n"}
{"id": "1310.5527", "contents": "Title: Power laws and Self-Organized Criticality in Theory and Nature Abstract: Power laws and distributions with heavy tails are common features of many\nexperimentally studied complex systems, like the distribution of the sizes of\nearthquakes and solar flares, or the duration of neuronal avalanches in the\nbrain. Previously, researchers surmised that a single general concept may act\nas a unifying underlying generative mechanism, with the theory of self\norganized criticality being a weighty contender.\n  Consequently, a substantial amount of effort has gone into developing new and\nextended models and, hitherto, three classes of models have emerged. The first\nline of models is based on a separation between the time scales of drive and\ndissipation, and includes the original sandpile model and its extensions, like\nthe dissipative earthquake model. Within this approach the steady state is\nclose to criticality in terms of an absorbing phase transition. The second line\nof models is based on external drives and internal dynamics competing on\nsimilar time scales and includes the coherent noise model, which has a\nnon-critical steady state characterized by heavy-tailed distributions. The\nthird line of models proposes a non-critical self-organizing state, being\nguided by an optimization principle, such as the concept of highly optimized\ntolerance.\n  We present a comparative overview regarding distinct modeling approaches\ntogether with a discussion of their potential relevance as underlying\ngenerative models for real-world phenomena. The complexity of physical and\nbiological scaling phenomena has been found to transcend the explanatory power\nof individual paradigmal concepts. The interaction between theoretical\ndevelopment and experimental observations has been very fruitful, leading to a\nseries of novel concepts and insights. \n\n"}
{"id": "1310.6345", "contents": "Title: Triple point induced by targeted autonomization on interdependent scale\n  free networks Abstract: Many man-made networks support each other to provide efficient services and\nresources to the customers, despite that this support produces a strong\ninterdependency between the individual networks. Thus an initial failure of a\nfraction $1-p$ of nodes in one network, exposes the system to cascade of\nfailures and, as a consequence, to a full collapse of the overall system.\nTherefore it is important to develop efficient strategies to avoid the collapse\nby increasing the robustness of the individual networks against failures. Here,\nwe provide an exact theoretical approach to study the evolution of the cascade\nof failures on interdependent networks when a fraction $\\alpha$ of the nodes\nwith higher connectivity in each individual network are autonomous. With this\npattern of interdependency we found, for pair of heterogeneous networks, two\ncritical percolation thresholds that depend on $\\alpha$, separating three\nregimes with very different network's final sizes that converge into a triple\npoint in the plane $p-\\alpha$. Our findings suggest that the heterogeneity of\nthe networks represented by high degree nodes is the responsible of the rich\nphase diagrams found in this and other investigations. \n\n"}
{"id": "1310.8219", "contents": "Title: Comparative model accuracy of a data-fitted generalized Aw-Rascle-Zhang\n  model Abstract: The Aw-Rascle-Zhang (ARZ) model can be interpreted as a generalization of the\nLighthill-Whitham-Richards (LWR) model, possessing a family of fundamental\ndiagram curves, each of which represents a class of drivers with a different\nempty road velocity. A weakness of this approach is that different drivers\npossess vastly different densities at which traffic flow stagnates. This\ndrawback can be overcome by modifying the pressure relation in the ARZ model,\nleading to the generalized Aw-Rascle-Zhang (GARZ) model. We present an approach\nto determine the parameter functions of the GARZ model from fundamental diagram\nmeasurement data. The predictive accuracy of the resulting data-fitted GARZ\nmodel is compared to other traffic models by means of a three-detector test\nsetup, employing two types of data: vehicle trajectory data, and sensor data.\nThis work also considers the extension of the ARZ and the GARZ models to models\nwith a relaxation term, and conducts an investigation of the optimal relaxation\ntime. \n\n"}
{"id": "1311.3037", "contents": "Title: Practical Characterization of Large Networks Using Neighborhood\n  Information Abstract: Characterizing large online social networks (OSNs) through node querying is a\nchallenging task. OSNs often impose severe constraints on the query rate, hence\nlimiting the sample size to a small fraction of the total network. Various\nad-hoc subgraph sampling methods have been proposed, but many of them give\nbiased estimates and no theoretical basis on the accuracy. In this work, we\nfocus on developing sampling methods for OSNs where querying a node also\nreveals partial structural information about its neighbors. Our methods are\noptimized for NoSQL graph databases (if the database can be accessed directly),\nor utilize Web API available on most major OSNs for graph sampling. We show\nthat our sampling method has provable convergence guarantees on being an\nunbiased estimator, and it is more accurate than current state-of-the-art\nmethods. We characterize metrics such as node label density estimation and edge\nlabel density estimation, two of the most fundamental network characteristics\nfrom which other network characteristics can be derived. We evaluate our\nmethods on-the-fly over several live networks using their native APIs. Our\nsimulation studies over a variety of offline datasets show that by including\nneighborhood information, our method drastically (4-fold) reduces the number of\nsamples required to achieve the same estimation accuracy of state-of-the-art\nmethods. \n\n"}
{"id": "1311.4468", "contents": "Title: Stochastic processes and feedback-linearisation for online\n  identification and Bayesian adaptive control of fully-actuated mechanical\n  systems Abstract: This work proposes a new method for simultaneous probabilistic identification\nand control of an observable, fully-actuated mechanical system. Identification\nis achieved by conditioning stochastic process priors on observations of\nconfigurations and noisy estimates of configuration derivatives. In contrast to\nprevious work that has used stochastic processes for identification, we\nleverage the structural knowledge afforded by Lagrangian mechanics and learn\nthe drift and control input matrix functions of the control-affine system\nseparately. We utilise feedback-linearisation to reduce, in expectation, the\nuncertain nonlinear control problem to one that is easy to regulate in a\ndesired manner. Thereby, our method combines the flexibility of nonparametric\nBayesian learning with epistemological guarantees on the expected closed-loop\ntrajectory. We illustrate our method in the context of torque-actuated pendula\nwhere the dynamics are learned with a combination of normal and log-normal\nprocesses. \n\n"}
{"id": "1311.4548", "contents": "Title: Estimating Functions of Distributions Defined over Spaces of Unknown\n  Size Abstract: We consider Bayesian estimation of information-theoretic quantities from\ndata, using a Dirichlet prior. Acknowledging the uncertainty of the event space\nsize $m$ and the Dirichlet prior's concentration parameter $c$, we treat both\nas random variables set by a hyperprior. We show that the associated\nhyperprior, $P(c, m)$, obeys a simple \"Irrelevance of Unseen Variables\" (IUV)\ndesideratum iff $P(c, m) = P(c) P(m)$. Thus, requiring IUV greatly reduces the\nnumber of degrees of freedom of the hyperprior. Some information-theoretic\nquantities can be expressed multiple ways, in terms of different event spaces,\ne.g., mutual information. With all hyperpriors (implicitly) used in earlier\nwork, different choices of this event space lead to different posterior\nexpected values of these information-theoretic quantities. We show that there\nis no such dependence on the choice of event space for a hyperprior that obeys\nIUV. We also derive a result that allows us to exploit IUV to greatly simplify\ncalculations, like the posterior expected mutual information or posterior\nexpected multi-information. We also use computer experiments to favorably\ncompare an IUV-based estimator of entropy to three alternative methods in\ncommon use. We end by discussing how seemingly innocuous changes to the\nformalization of an estimation problem can substantially affect the resultant\nestimates of posterior expectations. \n\n"}
{"id": "1311.6948", "contents": "Title: Measuring the evaluation and impact of scientific works and their\n  authors Abstract: Problems for evaluation and impact of published scientific works and their\nauthors are discussed. The role of citations in this process is pointed out.\nDifferent bibliometric indicators are reviewed in this connection and ways for\ngeneration of new bibliometric indices are given. The influence of different\ncircumstances, like self-citations, number of authors, time dependence and\npublication types, on the evaluation and impact of scientific papers are\nconsidered. The repercussion of works citations and their content is\ninvestigated in this respect. Attention is paid also on implicit citations\nwhich are not covered by the modern bibliometrics but often are reflected in\nthe peer reviews. Some aspects of the Web analogues of citations and new\npossibilities of the Internet resources in evaluating authors achievements are\npresented. \n\n"}
{"id": "1312.1993", "contents": "Title: Enhancing resilience of interdependent networks by healing Abstract: Interdependent networks are characterized by two kinds of interactions: The\nusual connectivity links within each network and the dependency links coupling\nnodes of different networks. Due to the latter links such networks are known to\nsuffer from cascading failures and catastrophic breakdowns. When modeling these\nphenomena, usually one assumes that a fraction of nodes gets damaged in one of\nthe networks, which is followed possibly by a cascade of failures. In real life\nthe initiating failures do not occur at once and effort is made replace the\nties eliminated due to the failing nodes. Here we study a dynamic extension of\nthe model of interdependent networks and introduce the possibility of link\nformation with a probability w, called healing, to bridge non-functioning nodes\nand enhance network resilience. A single random node is removed, which may\ninitiate an avalanche. After each removal step healing sets in resulting in a\nnew topology. Then a new node fails and the process continues until the giant\ncomponent disappears either in a catastrophic breakdown or in a smooth\ntransition. Simulation results are presented for square lattices as starting\nnetworks under random attacks of constant intensity. We find that the shift in\nthe position of the breakdown has a power-law scaling as a function of the\nhealing probability with an exponent close to 1. Below a critical healing\nprobability, catastrophic cascades form and the average degree of surviving\nnodes decreases monotonically, while above this value there are no macroscopic\ncascades and the average degree has first an increasing character and decreases\nonly at the very late stage of the process. These findings facilitate to plan\nintervention in case of crisis situation by describing the efficiency of\nhealing efforts needed to suppress cascading failures. \n\n"}
{"id": "1401.0655", "contents": "Title: Critical Nodes In Directed Networks Abstract: Critical nodes or \"middlemen\" have an essential place in both social and\neconomic networks when considering the flow of information and trade. This\npaper extends the concept of critical nodes to directed networks. We identify\nstrong and weak middlemen. Node contestability is introduced as a form of\ncompetition in networks; a duality between uncontested intermediaries and\nmiddlemen is established. The brokerage power of middlemen is formally\nexpressed and a general algorithm is constructed to measure the brokerage power\nof each node from the networks adjacency matrix. Augmentations of the brokerage\npower measure are discussed to encapsulate relevant centrality measures. We use\nthese concepts to identify and measure middlemen in two empirical\nsocio-economic networks, the elite marriage network of Renaissance Florence and\nKrackhardt's advice network. \n\n"}
{"id": "1401.2846", "contents": "Title: Boundary-induced instabilities in coupled oscillators Abstract: A novel class of nonequilibrium phase-transitions at zero temperature is\nfound in chains of nonlinear oscillators.For two paradigmatic systems, the\nHamiltonian XY model and the discrete nonlinear Schr\\\"odinger equation, we find\nthat the application of boundary forces induces two synchronized phases,\nseparated by a non-trivial interfacial region where the kinetic temperature is\nfinite. Dynamics in such supercritical state displays anomalous chaotic\nproperties whereby some observables are non-extensive and transport is\nsuperdiffusive. At finite temperatures, the transition is smoothed, but the\ntemperature profile is still non-monotonous. \n\n"}
{"id": "1401.4298", "contents": "Title: What can transmission do for a fully renewable Europe? Abstract: Our research is centred around the question how to best integrate the\nvariable renewable energy sources (VRES), wind power and solar photovoltaics,\ninto the European electricity grid. The future electricity supply will be based\nto a large extend on these fluctuating resources. We have conducted a study,\nextrapolating national historical and targeted wind and solar power\npenetrations in Europe up to 100% VRES (R.A. Rodriguez et al, Renewable Energy\n63, p. 467, Mar 2014 and S. Becker et al, Energy 64, p. 404, Jan 2014). A high\nshare of VRES means large fluctuations in the generation, causing\noverproduction and deficits. One way to reduce such mismatches is power\ntransmission spatially smoothing out the fluctuations. This has the potential\nto reduce the remaining shortages by sharing the surplus production of others.\nWe find that shortages can at maximum be reduced by 40% in the hypothetical\ncase of unlimited transmission capacities across all of Europe. A more\nrealistic extension of the transmission grid, roughly quadrupling today's\ninstallation, turns out to be sufficient to harvest 90% of this potential\nbenefit. Finally, the import and export of single countries is investigated. We\nconclude that a country's load size as well as its position in the network are\nthe determining factors for its import/export opportunities. \n\n"}
{"id": "1401.6141", "contents": "Title: New type of anomaly in turbulence Abstract: The turbulent energy flux through scales, $\\bar{\\epsilon}$, remains constant\nand non vanishing in the limit of zero viscosity, which results in the\nfundamental anomaly of time irreversibility. It was considered straightforward\nto deduce from this the Lagrangian velocity anomaly, $\\left< d u^2/dt\\right>=-4\n\\bar{\\epsilon}$ at $t=0$, where $\\vec{u}$ is the velocity difference of a pair\nof particles, initially separated by a fixed distance. In this letter we\ndemonstrate that this derivation assumed first taking the limit $t \\to 0$ and\nthen $\\nu \\to 0$, while the true anomaly requires taking viscosity to zero\nfirst. For compressible turbulence we find that the limits $t \\to 0$ and $\\nu\n\\to 0$ do not commute and the Lagrangian anomaly is completely altered: $\\left<\nd u^2/dt\\right>$ has different values forward and backward in time. We show\nthat this new anomaly is related to the particles entering/exiting shocks\nforward/backward in time. For incompressible flows, on the other hand, we show\nthat the limits can be interchanged and the Lagrangian anomaly is still induced\nby the flux law, apparently due to a homogeneous distribution of fluid\nparticles at all times. \n\n"}
{"id": "1401.8065", "contents": "Title: Financial Brownian particle in the layered order book fluid and\n  Fluctuation-Dissipation relations Abstract: We introduce a novel description of the dynamics of the order book of\nfinancial markets as that of an effective colloidal Brownian particle embedded\nin fluid particles. The analysis of a comprehensive market data enables us to\nidentify all motions of the fluid particles. Correlations between the motions\nof the Brownian particle and its surrounding fluid particles reflect specific\nlayering interactions; in the inner-layer, the correlation is strong and with\nshort memory while, in the outer-layer, it is weaker and with long memory. By\ninterpreting and estimating the contribution from the outer-layer as a drag\nresistance, we demonstrate the validity of the fluctuation-dissipation relation\n(FDR) in this non-material Brownian motion process. \n\n"}
{"id": "1401.8176", "contents": "Title: Double percolation phase transition in clustered complex networks Abstract: The internal organization of complex networks often has striking consequences\non either their response to external perturbations or on their dynamical\nproperties. In addition to small-world and scale-free properties, clustering is\nthe most common topological characteristic observed in many real networked\nsystems. In this paper, we report an extensive numerical study on the effects\nof clustering on the structural properties of complex networks. Strong\nclustering in heterogeneous networks induces the emergence of a core-periphery\norganization that has a critical effect on the percolation properties of the\nnetworks. We observe a novel double phase transition with an intermediate phase\nin which only the core of the network is percolated and a final phase in which\nthe periphery percolates regardless of the core. This result implies breaking\nof the same symmetry at two different values of the control parameter, in stark\ncontrast to the modern theory of continuous phase transitions. Inspired by this\ncore-periphery organization, we introduce a simple model that allows us to\nanalytically prove that such an anomalous phase transition is in fact possible. \n\n"}
{"id": "1402.0237", "contents": "Title: Dealing with correlated choices: How a spin-glass model can help\n  political parties select their policies Abstract: Starting from preferences on N proposed policies obtained via questionnaires\nfrom a sample of the electorate, an Ising spin-glass model in a field can be\nconstructed from which a political party could find the subset of the proposed\npolicies which would maximize its appeal, form a coherent choice in the eyes of\nthe electorate, and have maximum overlap with the party's existing policies. We\nillustrate the application of the procedure by simulations of a spin glass in a\nrandom field on scale-free networks. \n\n"}
{"id": "1402.1797", "contents": "Title: Turbulence on hyperbolic plane: the fate of inverse cascade Abstract: We describe ideal incompressible hydrodynamics on the hyperbolic plane which\nis an infinite surface of constant negative curvature. We derive equations of\nmotion, general symmetries and conservation laws, and then consider turbulence\nwith the energy density linearly increasing with time due to action of\nsmall-scale forcing. In a flat space, such energy growth is due to an inverse\ncascade, which builds a constant part of the velocity autocorrelation function\nproportional to time and expanding in scales, while the moments of the velocity\ndifference saturate during a time depending on the distance. For the curved\nspace, we analyze the long-time long-distance scaling limit, that lives in a\ndegenerate conical geometry, and find that the energy-containing mode linearly\ngrowing with time is not constant in space. The shape of the velocity\ncorrelation function indicates that the energy builds up in vortical rings of\narbitrary diameter but of width comparable to the curvature radius of the\nhyperbolic plane. The energy current across scales does not increase linearly\nwith the scale, as in a flat space, but reaches a maximum around the curvature\nradius. That means that the energy flux through scales decreases at larger\nscales so that the energy is transferred in a non-cascade way, that is the\ninverse cascade spills over to all larger scales where the energy pumped into\nthe system is cumulated in the rings. The time-saturated part of the spectral\ndensity of velocity fluctuations contains a finite energy per unit area, unlike\nin the flat space where the time-saturated spectrum behaves as k^{-5/3}. \n\n"}
{"id": "1402.4171", "contents": "Title: Reconstructing the world trade multiplex: the role of intensive and\n  extensive biases Abstract: In economic and financial networks, the strength of each node has always an\nimportant economic meaning, such as the size of supply and demand, import and\nexport, or financial exposure. Constructing null models of networks matching\nthe observed strengths of all nodes is crucial in order to either detect\ninteresting deviations of an empirical network from economically meaningful\nbenchmarks or reconstruct the most likely structure of an economic network when\nthe latter is unknown. However, several studies have proved that real economic\nnetworks and multiplexes are topologically very different from configurations\ninferred only from node strengths. Here we provide a detailed analysis of the\nWorld Trade Multiplex by comparing it to an enhanced null model that\nsimultaneously reproduces the strength and the degree of each node. We study\nseveral temporal snapshots and almost one hundred layers (commodity classes) of\nthe multiplex and find that the observed properties are systematically well\nreproduced by our model. Our formalism allows us to introduce the (static)\nconcept of extensive and intensive bias, defined as a measurable tendency of\nthe network to prefer either the formation of extra links or the reinforcement\nof link weights, with respect to a reference case where only strengths are\nenforced. Our findings complement the existing economic literature on (dynamic)\nintensive and extensive trade margins. More in general, they show that\nreal-world multiplexes can be strongly shaped by layer-specific local\nconstraints. \n\n"}
{"id": "1402.5146", "contents": "Title: Synchronization transitions in globally coupled rotors in presence of\n  noise and inertia: Exact results Abstract: We study a generic model of globally coupled rotors that includes the effects\nof noise, phase shift in the coupling, and distributions of moments of inertia\nand natural frequencies of oscillation. As particular cases, the setup includes\npreviously studied Sakaguchi-Kuramoto, Hamiltonian and Brownian mean-field, and\nTanaka-Lichtenberg-Oishi and Acebr\\'on-Bonilla-Spigler models. We derive an\nexact solution of the self-consistent equations for the order parameter in the\nstationary state, valid for arbitrary parameters in the dynamics, and\ndemonstrate nontrivial phase transitions to synchrony that include reentrant\nsynchronous regimes. \n\n"}
{"id": "1402.7010", "contents": "Title: Diffusion in the Lorentz gas Abstract: The Lorentz gas, a point particle making mirror-like reflections from an\nextended collection of scatterers, has been a useful model of deterministic\ndiffusion and related statistical properties for over a century. This survey\nsummarises recent results, including periodic and aperiodic models, finite and\ninfinite horizon, external fields, smooth or polygonal obstacles, and in the\nBoltzmann-Grad limit. New results are given for several moving particles and\nfor obstacles with flat points. Finally, a variety of applications are\npresented. \n\n"}
{"id": "1403.1546", "contents": "Title: Measuring and modelling correlations in multiplex networks Abstract: The interactions among the elementary components of many complex systems can\nbe qualitatively different. Such systems are therefore naturally described in\nterms of multiplex or multi-layer networks, i.e. networks where each layer\nstands for a different type of interaction between the same set of nodes. There\nis today a growing interest in understanding when and why a description in\nterms of a multiplex network is necessary and more informative than a\nsingle-layer projection. Here, we contribute to this debate by presenting a\ncomprehensive study of correlations in multiplex networks. Correlations in node\nproperties, especially degree-degree correlations, have been thoroughly studied\nin single-layer networks. Here we extend this idea to investigate and\ncharacterize correlations between the different layers of a multiplex network.\nSuch correlations are intrinsically multiplex, and we first study them\nempirically by constructing and analyzing several multiplex networks from the\nreal-world. In particular, we introduce various measures to characterize\ncorrelations in the activity of the nodes and in their degree at the different\nlayers, and between activities and degrees. We show that real-world networks\nexhibit indeed non-trivial multiplex correlations. For instance, we find cases\nwhere two layers of the same multiplex network are positively correlated in\nterms of node degrees, while other two layers are negatively correlated. We\nthen focus on constructing synthetic multiplex networks, proposing a series of\nmodels to reproduce the correlations observed empirically and/or to assess\ntheir relevance. \n\n"}
{"id": "1403.2732", "contents": "Title: The Bursty Dynamics of the Twitter Information Network Abstract: In online social media systems users are not only posting, consuming, and\nresharing content, but also creating new and destroying existing connections in\nthe underlying social network. While each of these two types of dynamics has\nindividually been studied in the past, much less is known about the connection\nbetween the two. How does user information posting and seeking behavior\ninteract with the evolution of the underlying social network structure?\n  Here, we study ways in which network structure reacts to users posting and\nsharing content. We examine the complete dynamics of the Twitter information\nnetwork, where users post and reshare information while they also create and\ndestroy connections. We find that the dynamics of network structure can be\ncharacterized by steady rates of change, interrupted by sudden bursts.\nInformation diffusion in the form of cascades of post re-sharing often creates\nsuch sudden bursts of new connections, which significantly change users' local\nnetwork structure. These bursts transform users' networks of followers to\nbecome structurally more cohesive as well as more homogenous in terms of\nfollower interests. We also explore the effect of the information content on\nthe dynamics of the network and find evidence that the appearance of new topics\nand real-world events can lead to significant changes in edge creations and\ndeletions. Lastly, we develop a model that quantifies the dynamics of the\nnetwork and the occurrence of these bursts as a function of the information\nspreading through the network. The model can successfully predict which\ninformation diffusion events will lead to bursts in network dynamics. \n\n"}
{"id": "1403.3011", "contents": "Title: The influence of persuasion in opinion formation and polarization Abstract: We present a model that explores the influence of persuasion in a population\nof agents with positive and negative opinion orientations. The opinion of each\nagent is represented by an integer number $k$ that expresses its level of\nagreement on a given issue, from totally against $k=-M$ to totally in favor\n$k=M$. Same-orientation agents persuade each other with probability $p$,\nbecoming more extreme, while opposite-orientation agents become more moderate\nas they reach a compromise with probability $q$. The population initially\nevolves to (a) a polarized state for $r=p/q>1$, where opinions' distribution is\npeaked at the extreme values $k=\\pm M$, or (b) a centralized state for $r<1$,\nwith most opinions around $k=\\pm 1$. When $r \\gg 1$, polarization lasts for a\ntime that diverges as $r^M \\ln N$, where $N$ is the population's size. Finally,\nan extremist consensus ($k=M$ or $-M$) is reached in a time that scales as\n$r^{-1}$ for $r \\ll 1$. \n\n"}
{"id": "1403.6607", "contents": "Title: Statistics of the inverse-cascade regime in two-dimensional\n  magnetohydrodynamic turbulence Abstract: We present a detailed direct numerical simulation of statistically steady,\nhomogeneous, isotropic, two-dimensional magnetohydrodynamic (2D MHD)\nturbulence. Our study concentrates on the inverse cascade of the magnetic\nvector potential. We examine the dependence of the statistical properties of\nsuch turbulence on dissipation and friction coefficients. We extend earlier\nwork sig- nificantly by calculating fluid and magnetic spectra, probability\ndistribution functions (PDFs) of the velocity, magnetic, vorticity, current,\nstream-function, and magnetic-vector-potential fields and their increments. We\nquantify the deviations of these PDFs from Gaussian ones by computing their\nflatnesses and hyperflatnesses. We also present PDFs of the Okubo-Weiss\nparameter, which distin- guishes between vortical and extensional flow regions,\nand its magnetic analog. We show that the hyperflatnesses of PDFs of the\nincrements of the stream-function and the magnetic vector potential exhibit\nsignificant scale dependence and we examine the implication of this for the\nmultiscaling of structure functions. We compare our results with those of\nearlier studies. \n\n"}
{"id": "1403.7242", "contents": "Title: Network Weirdness: Exploring the Origins of Network Paradoxes Abstract: Social networks have many counter-intuitive properties, including the\n\"friendship paradox\" that states, on average, your friends have more friends\nthan you do. Recently, a variety of other paradoxes were demonstrated in online\nsocial networks. This paper explores the origins of these network paradoxes.\nSpecifically, we ask whether they arise from mathematical properties of the\nnetworks or whether they have a behavioral origin. We show that sampling from\nheavy-tailed distributions always gives rise to a paradox in the mean, but not\nthe median. We propose a strong form of network paradoxes, based on utilizing\nthe median, and validate it empirically using data from two online social\nnetworks. Specifically, we show that for any user the majority of user's\nfriends and followers have more friends, followers, etc. than the user, and\nthat this cannot be explained by statistical properties of sampling. Next, we\nexplore the behavioral origins of the paradoxes by using the shuffle test to\nremove correlations between node degrees and attributes. We find that paradoxes\nfor the mean persist in the shuffled network, but not for the median. We\ndemonstrate that strong paradoxes arise due to the assortativity of user\nattributes, including degree, and correlation between degree and attribute. \n\n"}
{"id": "1403.7663", "contents": "Title: Dynamical Systems on Networks: A Tutorial Abstract: We give a tutorial for the study of dynamical systems on networks. We focus\nespecially on \"simple\" situations that are tractable analytically, because they\ncan be very insightful and provide useful springboards for the study of more\ncomplicated scenarios. We briefly motivate why examining dynamical systems on\nnetworks is interesting and important, and we then give several fascinating\nexamples and discuss some theoretical results. We also briefly discuss\ndynamical systems on dynamical (i.e., time-dependent) networks, overview\nsoftware implementations, and give an outlook on the field. \n\n"}
{"id": "1403.7827", "contents": "Title: Motif-based success scores in coauthorship networks are highly sensitive\n  to author name disambiguation Abstract: Following the work of Krumov et al. [Eur. Phys. J. B 84, 535 (2011)] we\nrevisit the question whether the usage of large citation datasets allows for\nthe quantitative assessment of social (by means of coauthorship of\npublications) influence on the progression of science. Applying a more\ncomprehensive and well-curated dataset containing the publications in the\njournals of the American Physical Society during the whole 20th century we find\nthat the measure chosen in the original study, a score based on small induced\nsubgraphs, has to be used with caution, since the obtained results are highly\nsensitive to the exact implementation of the author disambiguation task. \n\n"}
{"id": "1404.1069", "contents": "Title: Rewarding evolutionary fitness with links between populations promotes\n  cooperation Abstract: Evolution of cooperation in the prisoner's dilemma and the public goods game\nis studied, where initially players belong to two independent structured\npopulations. Simultaneously with the strategy evolution, players whose current\nutility exceeds a threshold are rewarded by an external link to a player\nbelonging to the other population. Yet as soon as the utility drops below the\nthreshold, the external link is terminated. The rewarding of current\nevolutionary fitness thus introduces a time-varying interdependence between the\ntwo populations. We show that, regardless of the details of the evolutionary\ngame and the interaction structure, the self-organization of fitness and reward\ngives rise to distinguished players that act as strong catalysts of cooperative\nbehavior. However, there also exist critical utility thresholds beyond which\ndistinguished players are no longer able to percolate. The interdependence\nbetween the two populations then vanishes, and cooperators are forced to rely\non traditional network reciprocity alone. We thus demonstrate that a simple\nstrategy-independent form of rewarding may significantly expand the scope of\ncooperation on structured populations. The formation of links outside the\nimmediate community seems particularly applicable in human societies, where an\nindividual is typically member in many different social networks. \n\n"}
{"id": "1404.2382", "contents": "Title: Parameter estimation on compact binary coalescences with abruptly\n  terminating gravitational waveforms Abstract: Gravitational-wave astronomy seeks to extract information about astrophysical\nsystems from the gravitational-wave signals they emit. For coalescing\ncompact-binary sources this requires accurate model templates for the inspiral\nand, potentially, the subsequent merger and ringdown. Models with\nfrequency-domain waveforms that terminate abruptly in the sensitive band of the\ndetector are often used for parameter-estimation studies. We show that the\nabrupt waveform termination contains significant information that affects\nparameter-estimation accuracy. If the sharp cutoff is not physically motivated,\nthis extra information can lead to misleadingly good accuracy claims. We also\nshow that using waveforms with a cutoff as templates to recover complete\nsignals can lead to biases in parameter estimates. We evaluate when the\ninformation content in the cutoff is likely to be important in both cases. We\nalso point out that the standard Fisher matrix formalism, frequently employed\nfor approximately predicting parameter-estimation accuracy, cannot properly\nincorporate an abrupt cutoff that is present in both signals and templates;\nthis observation explains some previously unexpected results found in the\nliterature. These effects emphasize the importance of using complete waveforms\nwith accurate merger and ringdown phases for parameter estimation. \n\n"}
{"id": "1404.5897", "contents": "Title: Fractional Laplace Transforms - A Perspective Abstract: A form of the Laplace transform is reviewed as a paradigm for an entire class\nof fractional functional transforms. Various of its properties are discussed.\nSuch transformations should be useful in application to differential/integral\nequations or problems in non-extensive statistical mechanics. \n\n"}
{"id": "1405.0843", "contents": "Title: MuxViz: A Tool for Multilayer Analysis and Visualization of Networks Abstract: Multilayer relationships among entities and information about entities must\nbe accompanied by the means to analyze, visualize, and obtain insights from\nsuch data. We present open-source software (muxViz) that contains a collection\nof algorithms for the analysis of multilayer networks, which are an important\nway to represent a large variety of complex systems throughout science and\nengineering. We demonstrate the ability of muxViz to analyze and interactively\nvisualize multilayer data using empirical genetic, neuronal, and transportation\nnetworks. Our software is available at https://github.com/manlius/muxViz. \n\n"}
{"id": "1405.1440", "contents": "Title: Equitable random graphs Abstract: Random graph models have played a dominant role in the theoretical study of\nnetworked systems. The Poisson random graph of Erdos and Renyi, in particular,\nas well as the so-called configuration model, have served as the starting point\nfor numerous calculations. In this paper we describe another large class of\nrandom graph models, which we call equitable random graphs and which are\nflexible enough to represent networks with diverse degree distributions and\nmany nontrivial types of structure, including community structure, bipartite\nstructure, degree correlations, stratification, and others, yet are exactly\nsolvable for a wide range of properties in the limit of large graph size,\nincluding percolation properties, complete spectral density, and the behavior\nof homogeneous dynamical systems, such as coupled oscillators or epidemic\nmodels. \n\n"}
{"id": "1405.4958", "contents": "Title: Resolving Histogram Binning Dilemmas with Binless and Binfull Algorithms Abstract: The histogram is an analysis tool in widespread use within many sciences,\nwith high energy physics as a prime example. However, there exists an inherent\nbias in the choice of binning for the histogram, with different choices\npotentially leading to different interpretations. This paper aims to eliminate\nthis bias using two \"debinning\" algorithms. Both algorithms generate an\nobserved cumulative distribution function from the data, and use it to\nconstruct a representation of the underlying probability distribution function.\nThe strengths and weaknesses of these two algorithms are compared and\ncontrasted. The applicability and future prospects of these algorithms is also\ndiscussed. \n\n"}
{"id": "1405.5010", "contents": "Title: Another Look at Confidence Intervals: Proposal for a More Relevant and\n  Transparent Approach Abstract: The behaviors of various confidence/credible interval constructions are\nexplored, particularly in the region of low statistics where methods diverge\nmost. We highlight a number of challenges, such as the treatment of nuisance\nparameters, and common misconceptions associated with such constructions. An\ninformal survey of the literature suggests that confidence intervals are not\nalways defined in relevant ways and are too often misinterpreted and/or\nmisapplied. This can lead to seemingly paradoxical behaviours and flawed\ncomparisons regarding the relevance of experimental results. We therefore\nconclude that there is a need for a more pragmatic strategy which recognizes\nthat, while it is critical to objectively convey the information content of the\ndata, there is also a strong desire to derive bounds on models and a natural\ninstinct to interpret things this way. Accordingly, we attempt to put aside\nphilosophical biases in favor of a practical view to propose a more transparent\nand self-consistent approach that better addresses these issues. \n\n"}
{"id": "1405.5348", "contents": "Title: Epidemic spreading and risk perception in multiplex networks: a\n  self-organized percolation method Abstract: In this paper we study the interplay between epidemic spreading and risk\nperception on multiplex networks. The basic idea is that the effective\ninfection probability is affected by the perception of the risk of being\ninfected, which we assume to be related to the fraction of infected neighbours,\nas introduced by Bagnoli et al., PRE 76:061904 (2007). We re-derive previous\nresults using a self-organized method, that automatically gives the percolation\nthreshold in just one simulation. We then extend the model to multiplex\nnetworks considering that people get infected by contacts in real life but\noften gather information from an information networks, that may be quite\ndifferent from the real ones. The similarity between the real and information\nnetworks determine the possibility of stopping the infection for a sufficiently\nhigh precaution level: if the networks are too different there is no mean of\navoiding the epidemics. \n\n"}
{"id": "1405.5803", "contents": "Title: Statistical properties of the energy in time-dependent homogeneous power\n  law potentials Abstract: We study 1D Hamilton systems with homogeneous power law potential and their\nstatistical behaviour, assuming the microcanonical distribution of the initial\nconditions and describing its change under monotonically increasing\ntime-dependent function $a(t)$ (prefactor of the potential). Using the\nnonlinear WKB-like method by Papamikos and Robnik {\\em J. Phys. A: Math. Theor.\n{\\bf 44} (2012) 315102} and following a previous work by Papamikos G and Robnik\nM {\\em J. Phys. A: Math. Theor. {\\bf 45} (2011) 015206} we specifically analyze\nthe mean energy, the variance and the adiabatic invariant (action) of the\nsystems for large time $t\\rightarrow\\infty$ and we show that the mean energy\nand variance increase as powers of $a(t)$, while the action oscillates and\nfinally remains constant. By means of a number of detailed case studies we show\nthat the theoretical prediction is excellent which demonstrates the usefulness\nof the method in such applications. \n\n"}
{"id": "1406.0574", "contents": "Title: The Dark Side of Micro-Task Marketplaces: Characterizing Fiverr and\n  Automatically Detecting Crowdturfing Abstract: As human computation on crowdsourcing systems has become popular and powerful\nfor performing tasks, malicious users have started misusing these systems by\nposting malicious tasks, propagating manipulated contents, and targeting\npopular web services such as online social networks and search engines.\nRecently, these malicious users moved to Fiverr, a fast-growing micro-task\nmarketplace, where workers can post crowdturfing tasks (i.e., astroturfing\ncampaigns run by crowd workers) and malicious customers can purchase those\ntasks for only $5. In this paper, we present a comprehensive analysis of\nFiverr. First, we identify the most popular types of crowdturfing tasks found\nin this marketplace and conduct case studies for these crowdturfing tasks.\nThen, we build crowdturfing task detection classifiers to filter these tasks\nand prevent them from becoming active in the marketplace. Our experimental\nresults show that the proposed classification approach effectively detects\ncrowdturfing tasks, achieving 97.35% accuracy. Finally, we analyze the real\nworld impact of crowdturfing tasks by purchasing active Fiverr tasks and\nquantifying their impact on a target site. As part of this analysis, we show\nthat current security systems inadequately detect crowdsourced manipulation,\nwhich confirms the necessity of our proposed crowdturfing task detection\napproach. \n\n"}
{"id": "1406.1197", "contents": "Title: Unbiased sampling of network ensembles Abstract: Sampling random graphs with given properties is a key step in the analysis of\nnetworks, as random ensembles represent basic null models required to identify\npatterns such as communities and motifs. An important requirement is that the\nsampling process is unbiased and efficient. The main approaches are\nmicrocanonical, i.e. they sample graphs that match the enforced constraints\nexactly. Unfortunately, when applied to strongly heterogeneous networks (like\nmost real-world examples), the majority of these approaches become biased\nand/or time-consuming. Moreover, the algorithms defined in the simplest cases,\nsuch as binary graphs with given degrees, are not easily generalizable to more\ncomplicated ensembles. Here we propose a solution to the problem via the\nintroduction of a \"Maximize and Sample\" (\"Max & Sam\" for short) method to\ncorrectly sample ensembles of networks where the constraints are `soft', i.e.\nrealized as ensemble averages. Our method is based on exact maximum-entropy\ndistributions and is therefore unbiased by construction, even for strongly\nheterogeneous networks. It is also more computationally efficient than most\nmicrocanonical alternatives. Finally, it works for both binary and weighted\nnetworks with a variety of constraints, including combined degree-strength\nsequences and full reciprocity structure, for which no alternative method\nexists. Our canonical approach can in principle be turned into an unbiased\nmicrocanonical one, via a restriction to the relevant subset. Importantly, the\nanalysis of the fluctuations of the constraints suggests that the\nmicrocanonical and canonical versions of all the ensembles considered here are\nnot equivalent. We show various real-world applications and provide a code\nimplementing all our algorithms. \n\n"}
{"id": "1407.0225", "contents": "Title: World Input-Output Network Abstract: Economic systems, traditionally analyzed as almost independent national\nsystems, are increasingly connected on a global scale. Only recently becoming\navailable, the World Input-Output Database (WIOD) is one of the first efforts\nto construct the multi-regional input-output (MRIO) tables at the global level.\nBy viewing the world input-output system as an interdependent network where the\nnodes are the individual industries in different economies and the edges are\nthe monetary goods flows between industries, we study the network properties of\nthe so-called world input-output network (WION) and document its evolution over\ntime. We are able to quantify not only some global network properties such as\nassortativity, clustering coefficient, and degree and strength distributions,\nbut also its subgraph structure and dynamics by using community detection\ntechniques. Over time, we detect a marked increase in cross-country\nconnectivity of the production system, only temporarily interrupted by the\n2008-2009 crisis. Moreover, we find a growing input-output regional community\nin Europe led by Germany and the rise of China in the global production system.\nFinally, we use the network-based PageRank centrality and community coreness\nmeasure to identify the key industries and economies in the WION and the\nresults are different from the one obtained by the traditional\nfinal-demand-weighted backward linkage measure. \n\n"}
{"id": "1407.0613", "contents": "Title: On the Predictability of Talk Attendance at Academic Conferences Abstract: This paper focuses on the prediction of real-world talk attendances at\nacademic conferences with respect to different influence factors. We study the\npredictability of talk attendances using real-world tracked face-to-face\ncontacts. Furthermore, we investigate and discuss the predictive power of user\ninterests extracted from the users' previous publications. We apply Hybrid\nRooted PageRank, a state-of-the-art unsupervised machine learning method that\ncombines information from different sources. Using this method, we analyze and\ndiscuss the predictive power of contact and interest networks separately and in\ncombination. We find that contact and similarity networks achieve comparable\nresults, and that combinations of different networks can only to a limited\nextend help to improve the prediction quality. For our experiments, we analyze\nthe predictability of talk attendance at the ACM Conference on Hypertext and\nHypermedia 2011 collected using the conference management system Conferator. \n\n"}
{"id": "1407.0657", "contents": "Title: A recipe for EFT uncertainty quantification in nuclear physics Abstract: The application of effective field theory (EFT) methods to nuclear systems\nprovides the opportunity to rigorously estimate the uncertainties originating\nin the nuclear Hamiltonian. Yet this is just one source of uncertainty in the\nobservables predicted by calculations based on nuclear EFTs. We discuss the\ngoals of uncertainty quantification in such calculations and outline a recipe\nto obtain statistically meaningful error bars for their predictions. We argue\nthat the different sources of theory error can be accounted for within a\nBayesian framework, as we illustrate using a toy model. \n\n"}
{"id": "1407.1443", "contents": "Title: Analysis of Yelp Reviews Abstract: In the era of Big Data and Social Computing, the role of customer reviews and\nratings can be instrumental in predicting the success and sustainability of\nbusinesses. In this paper, we show that, despite the apparent subjectivity of\nuser ratings, there are also external, or objective factors which help to\ndetermine the outcome of a business's reviews. The current model for social\nbusiness review sites, such as Yelp, allows data (reviews, ratings) to be\ncompiled concurrently, which introduces a bias to participants (Yelp Users).\nOur work examines Yelp Reviews for businesses in and around college towns. We\ndemonstrate that an Observer Effect causes data to behave cyclically: rising\nand falling as momentum (quantified in user ratings) shifts for businesses. \n\n"}
{"id": "1407.1865", "contents": "Title: New likelihoods for shape analysis Abstract: We introduce a new kind of likelihood function based on the sequence of\nmoments of the data distribution. Both binned and unbinned data samples are\ndiscussed, and the multivariate case is also derived. Building on this approach\nwe lay out the formalism of shape analysis for signal searches. In addition to\nmoment-based likelihoods, standard likelihoods and approximate statistical\ntests are provided. Enough material is included to make the paper\nself-contained from the perspective of shape analysis. We argue that the\nmoment-based likelihoods can advantageously replace unbinned standard\nlikelihoods for the search of non-local signals, by avoiding the step of\nfitting Monte-Carlo generated distributions. This benefit increases with the\nnumber of variables simultaneously analyzed. The moment-based signal search is\nexemplified and tested in various 1D toy models mimicking typical high-energy\nsignal--background configurations. Moment-based techniques should be\nparticularly appropriate for the searches for effective operators at the LHC. \n\n"}
{"id": "1407.4610", "contents": "Title: Understanding Zipf's law of word frequencies through sample-space\n  collapse in sentence formation Abstract: The formation of sentences is a highly structured and history-dependent\nprocess. The probability of using a specific word in a sentence strongly\ndepends on the 'history' of word-usage earlier in that sentence. We study a\nsimple history-dependent model of text generation assuming that the\nsample-space of word usage reduces along sentence formation, on average. We\nfirst show that the model explains the approximate Zipf law found in word\nfrequencies as a direct consequence of sample-space reduction. We then\nempirically quantify the amount of sample-space reduction in the sentences of\nten famous English books, by analysis of corresponding word-transition tables\nthat capture which words can follow any given word in a text. We find a highly\nnested structure in these transition tables and show that this `nestedness' is\ntightly related to the power law exponents of the observed word frequency\ndistributions. With the proposed model it is possible to understand that the\nnestedness of a text can be the origin of the actual scaling exponent, and that\ndeviations from the exact Zipf law can be understood by variations of the\ndegree of nestedness on a book-by-book basis. On a theoretical level we are\nable to show that in case of weak nesting, Zipf's law breaks down in a fast\ntransition. Unlike previous attempts to understand Zipf's law in language the\nsample-space reducing model is not based on assumptions of multiplicative,\npreferential, or self-organised critical mechanisms behind language formation,\nbut simply used the empirically quantifiable parameter 'nestedness' to\nunderstand the statistics of word frequencies. \n\n"}
{"id": "1407.4953", "contents": "Title: A Topological Investigation of Phase Transitions of Cascading Failures\n  in Power Grids Abstract: Cascading failures are one of the main reasons for blackouts in electric\npower transmission grids. The economic cost of such failures is in the order of\ntens of billion dollars annually. The loading level of power system is a key\naspect to determine the amount of the damage caused by cascading failures.\nExisting studies show that the blackout size exhibits phase transitions as the\nloading level increases. This paper investigates the impact of the topology of\na power grid on phase transitions in its robustness. Three spectral graph\nmetrics are considered: spectral radius, effective graph resistance and\nalgebraic connectivity. Experimental results from a model of cascading failures\nin power grids on the IEEE power systems demonstrate the applicability of these\nmetrics to design/optimize a power grid topology for an enhanced phase\ntransition behavior of the system. \n\n"}
{"id": "1407.5107", "contents": "Title: PageRank beyond the Web Abstract: Google's PageRank method was developed to evaluate the importance of\nweb-pages via their link structure. The mathematics of PageRank, however, are\nentirely general and apply to any graph or network in any domain. Thus,\nPageRank is now regularly used in bibliometrics, social and information network\nanalysis, and for link prediction and recommendation. It's even used for\nsystems analysis of road networks, as well as biology, chemistry, neuroscience,\nand physics. We'll see the mathematics and ideas that unite these diverse\napplications. \n\n"}
{"id": "1407.5455", "contents": "Title: Interplay of network dynamics and ties heterogeneity on spreading\n  dynamics Abstract: The structure of a network dramatically affects the spreading phenomena\nunfolding upon it. The contact distribution of the nodes has long been\nrecognized as the key ingredient in influencing the outbreak events. However,\nlimited knowledge is currently available on the role of the weight of the edges\non the persistence of a pathogen. At the same time, recent works showed a\nstrong influence of temporal network dynamics on disease spreading. In this\nwork we provide an analytical understanding, corroborated by numerical\nsimulations, about the conditions for infected stable state in weighted\nnetworks. In particular, we reveal the role of heterogeneity of edge weights\nand of the dynamic assignment of weights on the ties in the network in driving\nthe spread of the epidemic. In this context we show that when weights are\ndynamically assigned to ties in the network an heterogeneous distribution is\nable to hamper the diffusion of the disease, contrary to what happens when\nweights are fixed in time. \n\n"}
{"id": "1407.8134", "contents": "Title: People are Strange when you're a Stranger: Impact and Influence of Bots\n  on Social Networks Abstract: Bots are, for many Web and social media users, the source of many dangerous\nattacks or the carrier of unwanted messages, such as spam. Nevertheless,\ncrawlers and software agents are a precious tool for analysts, and they are\ncontinuously executed to collect data or to test distributed applications.\nHowever, no one knows which is the real potential of a bot whose purpose is to\ncontrol a community, to manipulate consensus, or to influence user behavior. It\nis commonly believed that the better an agent simulates human behavior in a\nsocial network, the more it can succeed to generate an impact in that\ncommunity. We contribute to shed light on this issue through an online social\nexperiment aimed to study to what extent a bot with no trust, no profile, and\nno aims to reproduce human behavior, can become popular and influential in a\nsocial media. Results show that a basic social probing activity can be used to\nacquire social relevance on the network and that the so-acquired popularity can\nbe effectively leveraged to drive users in their social connectivity choices.\nWe also register that our bot activity unveiled hidden social polarization\npatterns in the community and triggered an emotional response of individuals\nthat brings to light subtle privacy hazards perceived by the user base. \n\n"}
{"id": "1407.8541", "contents": "Title: Walking dynamics are symmetric (enough) Abstract: Many biological phenomena such as locomotion, circadian cycles, and breathing\nare rhythmic in nature and can be modeled as rhythmic dynamical systems.\nDynamical systems modeling often involves neglecting certain characteristics of\na physical system as a modeling convenience. For example, human locomotion is\nfrequently treated as symmetric about the sagittal plane. In this work, we test\nthis assumption by examining human walking dynamics around the steady-state\n(limit-cycle). Here we adapt statistical cross validation in order to examine\nwhether there are statistically significant asymmetries, and even if so, test\nthe consequences of assuming bilateral symmetry anyway. Indeed, we identify\nsignificant asymmetries in the dynamics of human walking, but nevertheless show\nthat ignoring these asymmetries results in a more consistent and predictive\nmodel. In general, neglecting evident characteristics of a system can be more\nthan a modeling convenience---it can produce a better model. \n\n"}
{"id": "1408.0063", "contents": "Title: Epidemic spreading driven by biased random walks Abstract: Random walk is one of the basic mechanisms found in many network\napplications. We study the epidemic spreading dynamics driven by biased random\nwalks on complex networks. In our epidemic model, each time infected nodes\nconstantly spread some infected packets by biased random walks to their\nneighbor nodes causing the infection of the susceptible nodes that receive the\npackets. An infected node get recovered from infection with a fixed\nprobability. Simulation and analytical results on model and real-world networks\nshow that the epidemic spreading becomes intense and wide with the increase of\ndelivery capacity of infected nodes, average node degree, homogeneity of node\ndegree distribution. Furthermore, there are corresponding optimal parameters\nsuch that the infected nodes have instantaneously the largest population, and\nthe epidemic spreading process covers the largest part of a network. \n\n"}
{"id": "1408.0256", "contents": "Title: Ergodicity of a Time-Reversibly Thermostated Harmonic Oscillator and the\n  2014 Ian Snook Prize Abstract: Shuichi Nos\\'e opened up a new world of atomistic simulation in 1984. He\nformulated a Hamiltonian tailored to generate Gibbs' canonical distribution\ndynamically. This clever idea bridged the gap between microcanonical molecular\ndynamics and canonical statistical mechanics. Until then the canonical\ndistribution was explored with Monte Carlo sampling. Nos\\'e's dynamical\nHamiltonian bridge requires the \"ergodic\" support of a space-filling structure\nin order to reproduce the entire distribution. For sufficiently small systems,\nsuch as the harmonic oscillator, Nos\\'e's dynamical approach failed to agree\nwith Gibbs' sampling and instead showed a complex structure, partitioned into a\nchaotic sea, islands, and chains of islands, that is familiar textbook fare\nfrom investigations of Hamiltonian chaos. In trying to enhance small-system\nergodicity several more complicated \"thermostated\" equations of motion were\ndeveloped. All were consistent with the canonical Gaussian distribution for the\noscillator coordinate and momentum. The ergodicity of the various approaches\nhas undergone several investigations, with somewhat inconclusive (\ncontradictory ) results. Here we illustrate several ways to test ergodicity and\nchallenge the reader to find even more convincing algorithms or an entirely new\napproach to this problem. \n\n"}
{"id": "1408.1365", "contents": "Title: Kinetic Exchange Models in Economics and Sociology Abstract: In this article, we briefly review the different aspects and applications of\nkinetic exchange models in economics and sociology. Our main aim is to show in\nwhat manner the kinetic exchange models for closed economic systems were\ninspired by the kinetic theory of gas molecules. The simple yet powerful\nframework of kinetic theory, first proposed in 1738, led to the successful\ndevelopment of statistical physics of gases towards the end of the 19th\ncentury. This framework was successfully adapted to modeling of wealth\ndistributions in the early 2000's. In later times, it was applied to other\nareas like firm dynamics and opinion formation in the society, as well. We have\ntried to present the flavour of the several models proposed and their\napplications, intentionally leaving out the intricate mathematical and\ntechnical details. \n\n"}
{"id": "1408.1667", "contents": "Title: Science vs Conspiracy: collective narratives in the age of\n  (mis)information Abstract: The large availability of user provided contents on online social media\nfacilitates people aggregation around common interests, worldviews and\nnarratives. However, in spite of the enthusiastic rhetoric about the so called\n{\\em wisdom of crowds}, unsubstantiated rumors -- as alternative explanation to\nmain stream versions of complex phenomena -- find on the Web a natural medium\nfor their dissemination. In this work we study, on a sample of 1.2 million of\nindividuals, how information related to very distinct narratives -- i.e. main\nstream scientific and alternative news -- are consumed on Facebook. Through a\nthorough quantitative analysis, we show that distinct communities with similar\ninformation consumption patterns emerge around distinctive narratives.\nMoreover, consumers of alternative news (mainly conspiracy theories) result to\nbe more focused on their contents, while scientific news consumers are more\nprone to comment on alternative news. We conclude our analysis testing the\nresponse of this social system to 4709 troll information -- i.e. parodistic\nimitation of alternative and conspiracy theories. We find that, despite the\nfalse and satirical vein of news, usual consumers of conspiracy news are the\nmost prone to interact with them. \n\n"}
{"id": "1408.2324", "contents": "Title: Agent based models for wealth distribution with preference in\n  interaction Abstract: We propose a set of conservative models in which agents exchange wealth with\na preference in the choice of interacting agents in different ways. The common\nfeature in all the models is that the temporary values of financial status of\nagents is a deciding factor for interaction. Other factors which may play\nimportant role are past interactions and wealth possessed by individuals.\nWealth distribution, network properties and activity are the main quantities\nwhich have been studied. Evidence of phase transitions and other interesting\nfeatures are presented. The results show that certain observations of real\neconomic system can be reproduced by the models. \n\n"}
{"id": "1408.2484", "contents": "Title: Several Multiplexes in the same City: The role of wealth differences in\n  urban mobility Abstract: In this work we analyze the architecture of real urban mobility networks from\nthe multiplex perspective. In particular, based on empirical data about the\nmobility patterns in the cities of Bogot\\'a and Medell\\'{\\i}n, each city is\nrepresented by six multiplex networks, each one representing the\norigin-destination trips performed by a subset of the population corresponding\nto a particular socioeconomic status. The nodes of each multiplex are the\ndifferent urban locations whereas links represent the existence of a trip from\none node (origin) to another (destination). On the other hand, the different\nlayers of each multiplex correspond to the different existing transportation\nmodes. By exploiting the characterization of multiplex transportation networks\ncombining different transportation modes, we aim at characterizing the mobility\npatterns of each subset of the population. Our results show that the\nsocioeconomic characteristics of the population have an extraordinary impact in\nthe layer organization of these multiplex systems. \n\n"}
{"id": "1408.3584", "contents": "Title: Non Parametric Statistics of Dynamic Networks with distinguishable nodes Abstract: The study of random graphs and networks had an explosive development in the\nlast couple of decades. Meanwhile, techniques for the statistical analysis of\nsequences of networks were less developed. In this paper we focus on networks\nsequences with a fixed number of labeled nodes and study some statistical\nproblems in a nonparametric framework. We introduce natural notions of center\nand a depth function for networks that evolve in time. We develop several\nstatistical techniques including testing, supervised and unsupervised\nclassification, and some notions of principal component sets in the space of\nnetworks. Some examples and asymptotic results are given, as well as two real\ndata examples. \n\n"}
{"id": "1408.5196", "contents": "Title: Community structure revealed by phase locking Abstract: Community structure can naturally emerge in paths to synchronization, and\nscratching it from the paths is a tough issue that accounts for the diverse\ndynamics of synchronization. In this paper, with assumption that the\nsynchronization on complex networks is made up of local and collective\nprocesses, we proposed a scheme to lock the local synchronization (phase\nlocking) at a stable state meanwhile suppress the collective synchronization\nbased on Kuramoto model. Through this scheme, the network dynamics only\ncontains the local synchronization, which suggests that the nodes in the same\ncommunity synchronize together and these synchronization clusters well reveal\nthe community structure of network. Furthermore, by analyzing the paths to\nsynchronization, the relations or overlaps among different communities are also\nobtained. Thus, the community detection based on the scheme is performed on\nfive real networks and the observed community structures are much more apparent\nthan modularity-based fast algorithm. Our results not only provide a deep\ninsight to understand the synchronization dynamics on complex network but also\nenlarge the research scope of community detection. \n\n"}
{"id": "1408.6303", "contents": "Title: Motif Conservation Laws for the Configuration Model Abstract: The observation that some subgraphs, called motifs, appear more often in real\nnetworks than in their randomized counterparts has attracted much attention in\nthe scientific community. In the prevalent approach the detection of motifs is\nbased on comparing subgraph counts in a network with their counterparts in the\nconfiguration model with the same degree distribution as the network. In this\nshort note we derive conservation laws that relate motif counts in the\nconfiguration model. \n\n"}
{"id": "1408.6973", "contents": "Title: How structurally stable are global socioeconomic systems? Abstract: The stability analysis of socioeconomic systems has been centered on\nanswering whether small perturbations when a system is in a given quantitative\nstate will push the system permanently to a different quantitative state.\nHowever, typically the quantitative state of socioeconomic systems is subject\nto constant change. Therefore, a key stability question that has been\nunder-investigated is how strong the conditions of a system itself can change\nbefore the system moves to a qualitatively different behavior, i.e., how\nstructurally stable the systems is. Here, we introduce a framework to\ninvestigate the structural stability of socioeconomic systems formed by the\nnetwork of interactions among agents competing for resources. We measure the\nstructural stability of the system as the range of conditions in the\ndistribution and availability of resources compatible with the qualitative\nbehavior in which all the constituent agents can be self-sustained across time.\nTo illustrate our framework, we study an empirical representation of the global\nsocioeconomic system formed by countries sharing and competing for\nmultinational companies used as proxy for resources. We demonstrate that the\nstructural stability of the system is inversely associated with the level of\ncompetition and the level of heterogeneity in the distribution of resources.\nImportantly, we show that the qualitative behavior of the observed global\nsocioeconomic system is highly sensitive to changes in the distribution of\nresources. We believe this work provides a methodological basis to develop\nsustainable strategies for socioeconomic systems subject to constantly changing\nconditions. \n\n"}
{"id": "1409.0507", "contents": "Title: Model reproduces individual, group and collective dynamics of human\n  contact networks Abstract: Empirical data on the dynamics of human face-to-face interactions across a\nvariety of social venues have recently revealed a number of context-independent\nstructural and temporal properties of human contact networks. This universality\nsuggests that some basic mechanisms may be responsible for the unfolding of\nhuman interactions in the physical space. Here we discuss a simple model that\nreproduces the empirical distributions for the individual, group and collective\ndynamics of face-to-face contact networks. The model describes agents that move\nrandomly in a two-dimensional space and tend to stop when meeting \"attractive\"\npeers, and reproduces accurately the empirical distributions. \n\n"}
{"id": "1409.1282", "contents": "Title: Propensity and stickiness in the naming game: Tipping fractions of\n  minorities Abstract: Agent-based models of the binary naming game are generalized here to\nrepresent a family of models parameterized by the introduction of two\ncontinuous parameters. These parameters define varying listener-speaker\ninteractions on the individual level with one parameter controlling the speaker\nand the other controlling the listener of each interaction. The major finding\npresented here is that the generalized naming game preserves the existence of\ncritical thresholds for the size of committed minorities. Above such threshold,\na committed minority causes a fast (in time logarithmic in size of the network)\nconvergence to consensus, even when there are other parameters influencing the\nsystem. Below such threshold, reaching consensus requires time exponential in\nthe size of the network. Moreover, the two introduced parameters cause\nbifurcations in the stabilities of the system's fixed points and may lead to\nchanges in the system's consensus. \n\n"}
{"id": "1409.1488", "contents": "Title: A finite-time exponent for random Ehrenfest gas Abstract: We consider the motion of a system of free particles moving on a plane with\nregular hard polygonal scatterers arranged in a random manner. Calling this the\nEhrenfest gas, which is known to have a zero Lyapunov exponent, we propose a\nfinite-time exponent to characterize its dynamics. As the number of sides of\nthe polygon goes to infinity, when polygon tends to a circle, we recover the\nusual Lyapunov exponent for the Lorentz gas from the exponent proposed here. To\nobtain this result, we generalize the reflection law of a beam of rays incident\non a polygonal scatterer in a way that the formula for the circular scatterer\nis recovered in the limit of infinite number of vertices. Thus, chaos emerges\nfrom pseudochaos in an appropriate limit. \n\n"}
{"id": "1409.1819", "contents": "Title: Analysis of heat kernel highlights the strongly modular and\n  heat-preserving structure of proteins Abstract: In this paper, we study the structure and dynamical properties of protein\ncontact networks with respect to other biological networks, together with\nsimulated archetypal models acting as probes. We consider both classical\ntopological descriptors, such as the modularity and statistics of the shortest\npaths, and different interpretations in terms of diffusion provided by the\ndiscrete heat kernel, which is elaborated from the normalized graph Laplacians.\nA principal component analysis shows high discrimination among the network\ntypes, either by considering the topological and heat kernel based vector\ncharacterizations. Furthermore, a canonical correlation analysis demonstrates\nthe strong agreement among those two characterizations, providing thus an\nimportant justification in terms of interpretability for the heat kernel.\nFinally, and most importantly, the focused analysis of the heat kernel provides\na way to yield insights on the fact that proteins have to satisfy specific\nstructural design constraints that the other considered networks do not need to\nobey. Notably, the heat trace decay of an ensemble of varying-size proteins\ndenotes subdiffusion, a peculiar property of proteins. \n\n"}
{"id": "1409.3059", "contents": "Title: Model selection and hypothesis testing for large-scale network models\n  with overlapping groups Abstract: The effort to understand network systems in increasing detail has resulted in\na diversity of methods designed to extract their large-scale structure from\ndata. Unfortunately, many of these methods yield diverging descriptions of the\nsame network, making both the comparison and understanding of their results a\ndifficult challenge. A possible solution to this outstanding issue is to shift\nthe focus away from ad hoc methods and move towards more principled approaches\nbased on statistical inference of generative models. As a result, we face\ninstead the more well-defined task of selecting between competing generative\nprocesses, which can be done under a unified probabilistic framework. Here, we\nconsider the comparison between a variety of generative models including\nfeatures such as degree correction, where nodes with arbitrary degrees can\nbelong to the same group, and community overlap, where nodes are allowed to\nbelong to more than one group. Because such model variants possess an\nincreasing number of parameters, they become prone to overfitting. In this\nwork, we present a method of model selection based on the minimum description\nlength criterion and posterior odds ratios that is capable of fully accounting\nfor the increased degrees of freedom of the larger models, and selects the best\none according to the statistical evidence available in the data. In applying\nthis method to many empirical unweighted networks from different fields, we\nobserve that community overlap is very often not supported by statistical\nevidence and is selected as a better model only for a minority of them. On the\nother hand, we find that degree correction tends to be almost universally\nfavored by the available data, implying that intrinsic node proprieties (as\nopposed to group properties) are often an essential ingredient of network\nformation. \n\n"}
{"id": "1409.3592", "contents": "Title: Distinguishing Cause from Correlation in Tokamak Experiments to Trigger\n  Edge Localised Plasma Instabilities Abstract: The generic question is considered: How can we determine the probability of\nan otherwise quasirandom event, having been triggered by an external influence?\nA specific problem is the quantification of the success of techniques to\ntrigger, and hence control, edge-localised plasma instabilities (ELMs) in\nmagnetically confined fusion (MCF) experiments. The development of such\ntechniques is essential to ensure tolerable heat loads on components in large\nMCF fusion devices, and is necessary for their development into economically\nsuccessful power plants. Bayesian probability theory is used to rigorously\nformulate the problem and to provide a formal solution. Accurate but pragmatic\nmethods are developed to estimate triggering probabilities, and are illustrated\nwith experimental data. These allow results from experiments to be\nquantitatively assessed, and rigorously quantified conclusions to be formed.\nExample applications include assessing whether triggering of ELMs is a\nstatistical or deterministic process, and the establishment of thresholds to\nensure that ELMs are reliably triggered. \n\n"}
{"id": "1409.4638", "contents": "Title: Suppressed epidemics in multi-relational networks Abstract: A two-state epidemic model in networks with links mimicking two kinds of\nrelationships between connected nodes is introduced. Links of weights w1 and w0\noccur with probabilities p and 1-p, respectively. The fraction of infected\nnodes rho(p) shows a non-monotonic behavior, with rho drops with p for small p\nand increases for large p. For small to moderate w1/w0 ratios, rho(p) exhibits\na minimum that signifies an optimal suppression. For large w1/w0 ratios, the\nsuppression leads to an absorbing phase consisting only of healthy nodes within\na range p_L =< p =< p_R, and an active phase with mixed infected and healthy\nnodes for p < p_L and p>p_R. A mean field theory that ignores spatial\ncorrelation is shown to give qualitative agreement and capture all the key\nfeatures. A physical picture that emphasizes the intricate interplay between\ninfections via w0 links and within clusters formed by nodes carrying the w1\nlinks is presented. The absorbing state at large w1/w0 ratios results when the\nclusters are big enough to disrupt the spread via w0 links and yet small enough\nto avoid an epidemic within the clusters. A theory that uses the possible local\nenvironments of a node as variables is formulated. The theory gives results in\ngood agreement with simulation results, thereby showing the necessity of\nincluding longer spatial correlations. \n\n"}
{"id": "1409.6033", "contents": "Title: Correlation between centrality metrics and their application to the\n  opinion model Abstract: In recent decades, a number of centrality metrics describing network\nproperties of nodes have been proposed to rank the importance of nodes. In\norder to understand the correlations between centrality metrics and to\napproximate a high-complexity centrality metric by a strongly correlated\nlow-complexity metric, we first study the correlation between centrality\nmetrics in terms of their Pearson correlation coefficient and their similarity\nin ranking of nodes. In addition to considering the widely used centrality\nmetrics, we introduce a new centrality measure, the degree mass. The m order\ndegree mass of a node is the sum of the weighted degree of the node and its\nneighbors no further than m hops away. We find that the B_{n}, the closeness,\nand the components of x_{1} are strongly correlated with the degree, the\n1st-order degree mass and the 2nd-order degree mass, respectively, in both\nnetwork models and real-world networks. We then theoretically prove that the\nPearson correlation coefficient between x_{1} and the 2nd-order degree mass is\nlarger than that between x_{1} and a lower order degree mass. Finally, we\ninvestigate the effect of the inflexible antagonists selected based on\ndifferent centrality metrics in helping one opinion to compete with another in\nthe inflexible antagonists opinion model. Interestingly, we find that selecting\nthe inflexible antagonists based on the leverage, the B_{n}, or the degree is\nmore effective in opinion-competition than using other centrality metrics in\nall types of networks. This observation is supported by our previous\nobservations, i.e., that there is a strong linear correlation between the\ndegree and the B_{n}, as well as a high centrality similarity between the\nleverage and the degree. \n\n"}
{"id": "1410.2890", "contents": "Title: Benford's law predicted digit distribution of aggregated income taxes:\n  the surprising conformity of Italian cities and regions Abstract: The yearly aggregated tax income data of all, more than 8000, Italian\nmunicipalities are analyzed for a period of five years, from 2007 to 2011, to\nsearch for conformity or not with Benford's law, a counter-intuitive phenomenon\nobserved in large tabulated data where the occurrence of numbers having smaller\ninitial digits is more favored than those with larger digits. This is done in\nanticipation that large deviations from Benford's law will be found in view of\ntax evasion supposedly being widespread across Italy. Contrary to expectations,\nwe show that the overall tax income data for all these years is in excellent\nagreement with Benford's law. Furthermore, we also analyze the data of\nCalabria, Campania and Sicily, the three Italian regions known for strong\npresence of mafia, to see if there are any marked deviations from Benford's\nlaw. Again, we find that all yearly data sets for Calabria and Sicily agree\nwith Benford's law whereas only the 2007 and 2008 yearly data show departures\nfrom the law for Campania. These results are again surprising in view of\nunderground and illegal nature of economic activities of mafia which\nsignificantly contribute to tax evasion. Some hypothesis for the found\nconformity is presented. \n\n"}
{"id": "1410.5356", "contents": "Title: Statistical computation of Boltzmann entropy and estimation of the\n  optimal probability density function from statistical sample Abstract: In this work, we investigate the statistical computation of the Boltzmann\nentropy of statistical samples. For this purpose, we use both histogram and\nkernel function to estimate the probability density function of statistical\nsamples. We find that, due to coarse-graining, the entropy is a monotonic\nincreasing function of the bin width for histogram or bandwidth for kernel\nestimation, which seems to be difficult to select an optimal bin\nwidth/bandwidth for computing the entropy. Fortunately, we notice that there\nexists a minimum of the first derivative of entropy for both histogram and\nkernel estimation, and this minimum point of the first derivative\nasymptotically points to the optimal bin width or bandwidth. We have verified\nthese findings by large amounts of numerical experiments. Hence, we suggest\nthat the minimum of the first derivative of entropy be used as a selector for\nthe optimal bin width or bandwidth of density estimation. Moreover, the optimal\nbandwidth selected by the minimum of the first derivative of entropy is purely\ndata-based, independent of the unknown underlying probability density\ndistribution, which is obviously superior to the existing estimators. Our\nresults are not restricted to one-dimensional, but can also be extended to\nmultivariate cases. It should be emphasized, however, that we do not provide a\nrobust mathematical proof of these findings, and we leave these issues with\nthose who are interested in them. \n\n"}
{"id": "1410.5474", "contents": "Title: Ermakov Systems with Multiplicative Noise Abstract: Using the Euler-Maruyama numerical method, we present calculations of the\nErmakov-Lewis invariant and the dynamic, geometric, and total phases for\nseveral cases of stochastic parametric oscillators, including the simplest case\nof the stochastic harmonic oscillator. The results are compared with the\ncorresponding numerical noiseless cases to evaluate the effect of the noise.\nBesides, the noiseless cases are analytic and their analytic solutions are\nbriefly presented. The Ermakov-Lewis invariant is not affected by the\nmultiplicative noise in the three particular examples presented in this work,\nwhereas there is a shift effect in the case of the phases \n\n"}
{"id": "1410.5485", "contents": "Title: A stronger null hypothesis for crossing dependencies Abstract: The syntactic structure of a sentence can be modeled as a tree where vertices\nare words and edges indicate syntactic dependencies between words. It is\nwell-known that those edges normally do not cross when drawn over the sentence.\nHere a new null hypothesis for the number of edge crossings of a sentence is\npresented. That null hypothesis takes into account the length of the pair of\nedges that may cross and predicts the relative number of crossings in random\ntrees with a small error, suggesting that a ban of crossings or a principle of\nminimization of crossings are not needed in general to explain the origins of\nnon-crossing dependencies. Our work paves the way for more powerful null\nhypotheses to investigate the origins of non-crossing dependencies in nature. \n\n"}
{"id": "1410.6252", "contents": "Title: Weak-value amplification: state of play Abstract: Weak values arise in quantum theory when the result of a weak measurement is\nconditioned on a subsequent strong measurement. The majority of the trials are\ndiscarded, leaving only very few successful events. Intriguingly those can\ndisplay a substantial signal amplification. This raises the question of whether\nweak values carry potential to improve the performance of quantum sensors, and\nindeed a number of impressive experimental results suggested this may be the\ncase. By contrast, recent theoretical studies have found the opposite: using\nweak-values to obtain an amplification generally worsens metrological\nperformance. This survey summarises the implications of those studies, which\ncall for a reappraisal of weak values' utility and for further work to\nreconcile theory and experiment. \n\n"}
{"id": "1410.7259", "contents": "Title: Hierarchical sequencing of online social graphs Abstract: In online communications, patterns of conduct of individual actors and use of\nemotions in the process can lead to a complex social graph exhibiting\nmultilayered structure and mesoscopic communities. Using simplicial complexes\nrepresentation of graphs, we investigate in-depth topology of online social\nnetwork which is based on MySpace dialogs. The network exhibits original\ncommunity structure. In addition, we simulate emotion spreading in this network\nthat enables to identify two emotion-propagating layers. The analysis resulting\nin three structure vectors quantifies the graph's architecture at different\ntopology levels. Notably, structures emerging through shared links, triangles\nand tetrahedral faces, frequently occur and range from tree-like to maximal\n5-cliques and their respective complexes. On the other hand, the structures\nwhich spread only negative or only positive emotion messages appear to have\nmuch simpler topology consisting of links and triangles. Furthermore, we\nintroduce the node's structure vector which represents the number of simplices\nat each topology level in which the node resides. The total number of such\nsimplices determines what we define as the node's topological dimension. The\npresented results suggest that the node's topological dimension provides a\nsuitable measure of the social capital which measures the agent's ability to\nact as a broker in compact communities, the so called Simmelian brokerage. We\nalso generalize the results to a wider class of computer-generated networks.\nInvestigating components of the node's vector over network layers reveals that\nsame nodes develop different socio-emotional relations and that the influential\nnodes build social capital by combining their connections in different layers. \n\n"}
{"id": "1410.7357", "contents": "Title: Statistical models for cores decomposition of an undirected random graph Abstract: The $k$-core decomposition is a widely studied summary statistic that\ndescribes a graph's global connectivity structure. In this paper, we move\nbeyond using $k$-core decomposition as a tool to summarize a graph and propose\nusing $k$-core decomposition as a tool to model random graphs. We propose using\nthe shell distribution vector, a way of summarizing the decomposition, as a\nsufficient statistic for a family of exponential random graph models. We study\nthe properties and behavior of the model family, implement a Markov chain Monte\nCarlo algorithm for simulating graphs from the model, implement a direct\nsampler from the set of graphs with a given shell distribution, and explore the\nsampling distributions of some of the commonly used complementary statistics as\ngood candidates for heuristic model fitting. These algorithms provide first\nfundamental steps necessary for solving the following problems: parameter\nestimation in this ERGM, extending the model to its Bayesian relative, and\ndeveloping a rigorous methodology for testing goodness of fit of the model and\nmodel selection. The methods are applied to a synthetic network as well as the\nwell-known Sampson monks dataset. \n\n"}
{"id": "1410.7388", "contents": "Title: Interpolation between multi-dimensional histograms using a new\n  non-linear moment morphing method Abstract: A prescription is presented for the interpolation between multi-dimensional\ndistribution templates based on one or multiple model parameters. The technique\nuses a linear combination of templates, each created using fixed values of the\nmodel's parameters and transformed according to a specific procedure, to model\na non-linear dependency on model parameters and the dependency between them. By\nconstruction the technique scales well with the number of input templates used,\nwhich is a useful feature in modern day particle physics, where a large number\nof templates is often required to model the impact of systematic uncertainties. \n\n"}
{"id": "1410.7882", "contents": "Title: Simulated Performance of Timescale Metrics for Aperiodic Light Curves Abstract: Aperiodic variability is a characteristic feature of young stars, massive\nstars, and active galactic nuclei. With the recent proliferation of time domain\nsurveys, it is increasingly essential to develop methods to quantify and\nanalyze aperiodic variability. We develop three timescale metrics that have\nbeen little used in astronomy -- {\\Delta}m-{\\Delta}t plots, peak-finding, and\nGaussian process regression -- and present simulations comparing their\neffectiveness across a range of aperiodic light curve shapes, characteristic\ntimescales, observing cadences, and signal to noise ratios. We find that\nGaussian process regression is easily confused by noise and by irregular\nsampling, even when the model being fit reflects the process underlying the\nlight curve, but that {\\Delta}m-{\\Delta}t plots and peak-finding can coarsely\ncharacterize timescales across a broad region of parameter space. We make\npublic the software we used for our simulations, both in the spirit of open\nresearch and to allow others to carry out analogous simulations for their own\nobserving programs. \n\n"}
{"id": "1411.0556", "contents": "Title: Measuring the Generalized Friendship Paradox in Networks with\n  Quality-dependent Connectivity Abstract: The friendship paradox is a sociological phenomenon stating that most people\nhave fewer friends than their friends do. The generalized friendship paradox\nrefers to the same observation for attributes other than degree, and it has\nbeen observed in Twitter and scientific collaboration networks. This paper\ntakes an analytical approach to model this phenomenon. We consider a\npreferential attachment-like network growth mechanism governed by both node\ndegrees and `qualities'. We introduce measures to quantify paradoxes, and\ncontrast the results obtained in our model to those obtained for an\nuncorrelated network, where the degrees and qualities of adjacent nodes are\nuncorrelated. We shed light on the effect of the distribution of node qualities\non the friendship paradox. We consider both the mean and the median to measure\nparadoxes, and compare the results obtained by using these two statistics. \n\n"}
{"id": "1411.1996", "contents": "Title: Predicting results of the Research Excellence Framework using\n  departmental $h$-Index Abstract: We compare estimates for past institutional research performances coming from\ntwo bibliometric indicators to the results of the UK's Research Assessment\nExercise which last took place in 2008. We demonstrate that a version of the\ndepartmental h-index is better correlated with the actual results of that\npeer-review exercise than a competing metric known as the normalised\ncitation-based indicator. We then determine the corresponding h-indices for\n2008-2013, the period examined in the UK's Research Excellence Framework (REF)\n2014. We place herewith the resulting predictions on the arXiv in advance of\nthe REF results being published (December 2014). These may be considered as\nunbiased predictions of relative performances in that exercise. We will revisit\nthis paper after the REF results are available and comment on the reliability\nor otherwise of these bibliometrics as compared with peer review. \n\n"}
{"id": "1411.2103", "contents": "Title: Revealing cell assemblies at multiple levels of granularity Abstract: Background: Current neuronal monitoring techniques, such as calcium imaging\nand multi-electrode arrays, enable recordings of spiking activity from hundreds\nof neurons simultaneously. Of primary importance in systems neuroscience is the\nidentification of cell assemblies: groups of neurons that cooperate in some\nform within the recorded population.\n  New Method: We introduce a simple, integrated framework for the detection of\ncell-assemblies from spiking data without a priori assumptions about the size\nor number of groups present. We define a biophysically-inspired measure to\nextract a directed functional connectivity matrix between both excitatory and\ninhibitory neurons based on their spiking history. The resulting network\nrepresentation is analyzed using the Markov Stability framework, a graph\ntheoretical method for community detection across scales, to reveal groups of\nneurons that are significantly related in the recorded time-series at different\nlevels of granularity.\n  Results and comparison with existing methods: Using synthetic spike-trains,\nincluding simulated data from leaky-integrate-and-fire networks, our method is\nable to identify important patterns in the data such as hierarchical structure\nthat are missed by other standard methods. We further apply the method to\nexperimental data from retinal ganglion cells of mouse and salamander, in which\nwe identify cell-groups that correspond to known functional types, and to\nhippocampal recordings from rats exploring a linear track, where we detect\nplace cells with high fidelity.\n  Conclusions: We present a versatile method to detect neural assemblies in\nspiking data applicable across a spectrum of relevant scales that contributes\nto understanding spatio-temporal information gathered from systems neuroscience\nexperiments. \n\n"}
{"id": "1411.2244", "contents": "Title: Contextuality in Three Types of Quantum-Mechanical Systems Abstract: We present a formal theory of contextuality for a set of random variables\ngrouped into different subsets (contexts) corresponding to different, mutually\nincompatible conditions. Within each context the random variables are jointly\ndistributed, but across different contexts they are stochastically unrelated.\nThe theory of contextuality is based on the analysis of the extent to which\nsome of these random variables can be viewed as preserving their identity\nacross different contexts when one considers all possible joint distributions\nimposed on the entire set of the random variables. We illustrate the theory on\nthree systems of traditional interest in quantum physics (and also in\nnon-physical, e.g., behavioral studies). These are systems of the\nKlyachko-Can-Binicioglu-Shumovsky-type, Einstein-Podolsky-Rosen-Bell-type, and\nSuppes-Zanotti-Leggett-Garg-type. Listed in this order, each of them is\nformally a special case of the previous one. For each of them we derive\nnecessary and sufficient conditions for contextuality while allowing for\nexperimental errors and contextual biases or signaling. Based on the same\nprinciples that underly these derivations we also propose a measure for the\ndegree of contextuality and compute it for the three systems in question. \n\n"}
{"id": "1411.3066", "contents": "Title: On the topological conjugacy problem for interval maps Abstract: We propose an inverse approach for dealing with interval maps based on the\nmanner whereby their branches are related (folding property), instead of\naddressing the map equations as a whole. As a main result, we provide a\nsymmetry-breaking framework for determining topological conjugacy of interval\nmaps, a well-known open problem in ergodic theory. Implications thereof for the\nspectrum and eigenfunctions of the Perron-Frobenius operator are also\ndiscussed. \n\n"}
{"id": "1411.3566", "contents": "Title: Diffusion in randomly perturbed dissipative dynamics Abstract: Dynamical systems having many coexisting attractors present interesting\nproperties from both fundamental theoretical and modelling points of view. When\nsuch dynamics is under bounded random perturbations, the basins of attraction\nare no longer invariant and there is the possibility of transport among them.\nHere we introduce a basic theoretical setting which enables us to study this\nhopping process from the perspective of anomalous transport using the concept\nof a random dynamical system with holes. We apply it to a simple model by\ninvestigating the role of hyperbolicity for the transport among basins. We show\nnumerically that our system exhibits non-Gaussian position distributions,\npower-law escape times, and subdiffusion. Our simulation results are reproduced\nconsistently from stochastic Continuous Time Random Walk theory. \n\n"}
{"id": "1411.4031", "contents": "Title: Angular Power Spectra with Finite Counts Abstract: Angular anisotropy techniques for cosmic diffuse radiation maps are powerful\nprobes, even for quite small data sets. A popular observable is the angular\npower spectrum; we present a detailed study applicable to any unbinned source\nskymap S(n) from which N random, independent events are observed. Its exact\nvariance, which is due to the finite statistics, depends only on S(n) and N; we\nalso derive an unbiased estimator of the variance from the data. First-order\neffects agree with previous analytic estimates. Importantly, heretofore\nunidentified higher-order effects are found to contribute to the variance and\nmay cause the uncertainty to be significantly larger than previous analytic\nestimates---potentially orders of magnitude larger. Neglect of these\nhigher-order terms, when significant, may result in a spurious detection of the\npower spectrum. On the other hand, this would indicate the presence of\nhigher-order spatial correlations, such as a large bispectrum, providing new\nclues about the sources. Numerical simulations are shown to support these\nconclusions. Applying the formalism to an ensemble of Gaussian-distributed\nskymaps, the noise-dominated part of the power spectrum uncertainty is\nsignificantly increased at high multipoles by the new, higher-order effects.\nThis work is important for harmonic analyses of the distributions of diffuse\nhigh-energy gamma-rays, neutrinos, and charged cosmic rays, as well as for\npopulations of sparse point sources such as active galactic nuclei. \n\n"}
{"id": "1411.4527", "contents": "Title: Given enough choice, simple local rules percolate discontinuously Abstract: There is still much to discover about the mechanisms and nature of\ndiscontinuous percolation transitions. Much of the past work considers graph\nevolution algorithms known as Achlioptas processes in which a single edge is\nadded to the graph from a set of $k$ randomly chosen candidate edges at each\ntimestep until a giant component emerges. Several Achlioptas processes seem to\nyield a discontinuous percolation transition, but it was proven by Riordan and\nWarnke that the transition must be continuous in the thermodynamic limit.\nHowever, they also proved that if the number $k(n)$ of candidate edges\nincreases with the number of nodes, then the percolation transition may be\ndiscontinuous. Here we attempt to find the simplest such process which yields a\ndiscontinuous transition in the thermodynamic limit. We introduce a process\nwhich considers only the degree of candidate edges and not component size. We\ncalculate the critical point $t_{c}=(1-\\theta(\\frac{1}{k}))n$ and rigorously\nshow that the critical window is of size $O(\\frac{n}{k(n)})$. If $k(n)$ grows\nvery slowly, for example $k(n)=\\log n$, the critical window is barely sublinear\nand hence the phase transition is discontinuous but appears continuous in\nfinite systems. We also present arguments that Achlioptas processes with\nbounded size rules will always have continuous percolation transitions even\nwith infinite choice. \n\n"}
{"id": "1411.6871", "contents": "Title: Tail-scope: Using friends to estimate heavy tails of degree\n  distributions in large-scale complex networks Abstract: Many complex networks in natural and social phenomena have often been\ncharacterized by heavy-tailed degree distributions. However, due to rapidly\ngrowing size of network data and concerns on privacy issues about using these\ndata, it becomes more difficult to analyze complete data sets. Thus, it is\ncrucial to devise effective and efficient estimation methods for heavy tails of\ndegree distributions in large-scale networks only using local information of a\nsmall fraction of sampled nodes. Here we propose a tail-scope method based on\nlocal observational bias of the friendship paradox. We show that the tail-scope\nmethod outperforms the uniform node sampling for estimating heavy tails of\ndegree distributions, while the opposite tendency is observed in the range of\nsmall degrees. In order to take advantages of both sampling methods, we devise\nthe hybrid method that successfully recovers the whole range of degree\ndistributions. Our tail-scope method shows how structural heterogeneities of\nlarge-scale complex networks can be used to effectively reveal the network\nstructure only with limited local information. \n\n"}
{"id": "1411.7757", "contents": "Title: A Perron-Frobenius theory for block matrices associated to a multiplex\n  network Abstract: The uniqueness of the Perron vector of a nonnegative block matrix associated\nto a multiplex network is discussed. The conclusions come from the\nrelationships between the irreducibility of some nonnegative block matrix\nassociated to a multiplex network and the irreducibility of the corresponding\nmatrices to each layer as well as the irreducibility of the adjacency matrix of\nthe projection network. In addition the computation of that Perron vector in\nterms of the Perron vectors of the blocks is also addressed. Finally we present\nthe precise relations that allow to express the Perron eigenvector of the\nmultiplex network in terms of the Perron eigenvectors of its layers. \n\n"}
{"id": "1412.0587", "contents": "Title: Burstiness and aging in social temporal networks Abstract: The presence of burstiness in temporal social networks, revealed by a power\nlaw form of the waiting time distribution of consecutive interactions, is\nexpected to produce aging effects in the corresponding time-integrated network.\nHere we propose an analytically tractable model, in which interactions among\nthe agents are ruled by a renewal process, and that is able to reproduce this\naging behavior. We develop an analytic solution for the topological properties\nof the integrated network produced by the model, finding that the time\ntranslation invariance of the degree distribution is broken. We validate our\npredictions against numerical simulations, and we check for the presence of\naging effects in a empirical temporal network, ruled by bursty social\ninteractions. \n\n"}
{"id": "1412.0666", "contents": "Title: Algebraic Geometrization of the Kuramoto Model: Equilibria and Stability\n  Analysis Abstract: Finding equilibria of the finite size Kuramoto model amounts to solving a\nnonlinear system of equations, which is an important yet challenging problem.\nWe translate this into an algebraic geometry problem and use numerical methods\nto find all of the equilibria for various choices of coupling constants K,\nnatural frequencies, and on different graphs. We note that for even modest\nsizes (N ~ 10-20), the number of equilibria is already more than 100,000. We\nanalyze the stability of each computed equilibrium as well as the configuration\nof angles. Our exploration of the equilibrium landscape leads to unexpected and\npossibly surprising results including non-monotonicity in the number of\nequilibria, a predictable pattern in the indices of equilibria,\ncounter-examples to popular conjectures, multi-stable equilibrium landscapes,\nscenarios with only unstable equilibria, and multiple distinct extrema in the\nstable equilibrium distribution as a function of the number of cycles in the\ngraph. \n\n"}
{"id": "1501.01903", "contents": "Title: Interests Diffusion in Social Networks Abstract: Understanding cultural phenomena on Social Networks (SNs) and exploiting the\nimplicit knowledge about their members is attracting the interest of different\nresearch communities both from the academic and the business side. The\ncommunity of complexity science is devoting significant efforts to define laws,\nmodels, and theories, which, based on acquired knowledge, are able to predict\nfuture observations (e.g. success of a product). In the mean time, the semantic\nweb community aims at engineering a new generation of advanced services by\ndefining constructs, models and methods, adding a semantic layer to SNs. In\nthis context, a leapfrog is expected to come from a hybrid approach merging the\ndisciplines above. Along this line, this work focuses on the propagation of\nindividual interests in social networks. The proposed framework consists of the\nfollowing main components: a method to gather information about the members of\nthe social networks; methods to perform some semantic analysis of the Domain of\nInterest; a procedure to infer members' interests; and an interests evolution\ntheory to predict how the interests propagate in the network. As a result, one\nachieves an analytic tool to measure individual features, such as members'\nsusceptibilities and authorities. Although the approach applies to any type of\nsocial network, here it is has been tested against the computer science\nresearch community.\n  The DBLP (Digital Bibliography and Library Project) database has been elected\nas test-case since it provides the most comprehensive list of scientific\nproduction in this field. \n\n"}
{"id": "1501.03875", "contents": "Title: Deterministic Time-Reversible Thermostats : Chaos, Ergodicity, and the\n  Zeroth Law of Thermodynamics Abstract: The relative stability and ergodicity of deterministic time-reversible\nthermostats, both singly and in coupled pairs, are assessed through their\nLyapunov spectra. Five types of thermostat are coupled to one another through a\nsingle Hooke's-Law harmonic spring. The resulting dynamics shows that three\nspecific thermostat types, Hoover-Holian, Ju-Bulgac, and\nMartyna-Klein-Tuckerman, have very similar Lyapunov spectra in their\nequilibrium four-dimensional phase spaces and when coupled in equilibrium or\nnonequilibrium pairs. All three of these oscillator-based thermostats are shown\nto be ergodic, with smooth analytic Gaussian distributions in their extended\nphase spaces ( coordinate, momentum, and two control variables ). Evidently\nthese three ergodic and time-reversible thermostat types are particularly\nuseful as statistical-mechanical thermometers and thermostats. Each of them\ngenerates Gibbs' universal canonical distribution internally as well as for\nsystems to which they are coupled. Thus they obey the Zeroth Law of\nThermodynamics, as a good heat bath should. They also provide dissipative heat\nflow with relatively small nonlinearity when two or more such bath temperatures\ninteract and provide useful deterministic replacements for the stochastic\nLangevin equation. \n\n"}
{"id": "1501.05139", "contents": "Title: Detecting Overlapping Link Communities by Finding Local Minima of a Cost\n  Function with a Memetic Algorithm. Part 1: Problem and Method Abstract: We propose an algorithm for detecting communities of links in networks which\nuses local information, is based on a new evaluation function, and allows for\npervasive overlaps of communities. The complexity of the clustering task\nrequires the application of a memetic algorithm that combines probabilistic\nevolutionary strategies with deterministic local searches. In Part 2 we will\npresent results of experiments with with citation networks. \n\n"}
{"id": "1502.03854", "contents": "Title: De-Biasing the Dynamic Mode Decomposition for Applied Koopman Spectral\n  Analysis Abstract: The Dynamic Mode Decomposition (DMD)---a popular method for performing\ndata-driven Koopman spectral analysis---has gained increased adoption as a\ntechnique for extracting dynamically meaningful spatio-temporal descriptions of\nfluid flows from snapshot measurements. Often times, DMD descriptions can be\nused for predictive purposes as well, which enables informed decision-making\nbased on DMD model-forecasts. Despite its widespread use and utility, DMD\nregularly fails to yield accurate dynamical descriptions when the measured\nsnapshot data are imprecise due to, e.g., sensor noise. Here, we express DMD as\na two-stage algorithm in order to isolate a source of systematic error. We show\nthat DMD's first stage, a subspace projection step, systematically introduces\nbias errors by processing snapshots asymmetrically. To remove this systematic\nerror, we propose utilizing an augmented snapshot matrix in a subspace\nprojection step, as in problems of total least-squares, in order to account for\nthe error present in all snapshots. The resulting unbiased and noise-aware\ntotal DMD (TDMD) formulation reduces to standard DMD in the absence of snapshot\nerrors, while the two-stage perspective generalizes the de-biasing framework to\nother related methods as well. TDMD's performance is demonstrated in numerical\nand experimental fluids examples. \n\n"}
{"id": "1502.05058", "contents": "Title: Tensor Spectral Clustering for Partitioning Higher-order Network\n  Structures Abstract: Spectral graph theory-based methods represent an important class of tools for\nstudying the structure of networks. Spectral methods are based on a first-order\nMarkov chain derived from a random walk on the graph and thus they cannot take\nadvantage of important higher-order network substructures such as triangles,\ncycles, and feed-forward loops. Here we propose a Tensor Spectral Clustering\n(TSC) algorithm that allows for modeling higher-order network structures in a\ngraph partitioning framework. Our TSC algorithm allows the user to specify\nwhich higher-order network structures (cycles, feed-forward loops, etc.) should\nbe preserved by the network clustering. Higher-order network structures of\ninterest are represented using a tensor, which we then partition by developing\na multilinear spectral method. Our framework can be applied to discovering\nlayered flows in networks as well as graph anomaly detection, which we\nillustrate on synthetic networks. In directed networks, a higher-order\nstructure of particular interest is the directed 3-cycle, which captures\nfeedback loops in networks. We demonstrate that our TSC algorithm produces\nlarge partitions that cut fewer directed 3-cycles than standard spectral\nclustering algorithms. \n\n"}
{"id": "1502.06579", "contents": "Title: Benchmarking Compressed Sensing, Super-Resolution, and Filter\n  Diagonalization Abstract: Signal processing techniques have been developed that use different\nstrategies to bypass the Nyquist sampling theorem in order to recover more\ninformation than a traditional discrete Fourier transform. Here we examine\nthree such methods: filter diagonalization, compressed sensing, and\nsuper-resolution. We apply them to a broad range of signal forms commonly found\nin science and engineering in order to discover when and how each method can be\nused most profitably. We find that filter diagonalization provides the best\nresults for Lorentzian signals, while compressed sensing and super-resolution\nperform better for arbitrary signals. \n\n"}
{"id": "1502.07758", "contents": "Title: Fast and accurate prediction of numerical relativity waveforms from\n  binary black hole coalescences using surrogate models Abstract: Simulating a binary black hole (BBH) coalescence by solving Einstein's\nequations is computationally expensive, requiring days to months of\nsupercomputing time. Using reduced order modeling techniques, we construct an\naccurate surrogate model, which is evaluated in a millisecond to a second, for\nnumerical relativity (NR) waveforms from non-spinning BBH coalescences with\nmass ratios in $[1, 10]$ and durations corresponding to about $15$ orbits\nbefore merger. We assess the model's uncertainty and show that our modeling\nstrategy predicts NR waveforms {\\em not} used for the surrogate's training with\nerrors nearly as small as the numerical error of the NR code. Our model\nincludes all spherical-harmonic ${}_{-2}Y_{\\ell m}$ waveform modes resolved by\nthe NR code up to $\\ell=8.$ We compare our surrogate model to Effective One\nBody waveforms from $50$-$300 M_\\odot$ for advanced LIGO detectors and find\nthat the surrogate is always more faithful (by at least an order of magnitude\nin most cases). \n\n"}
{"id": "1503.03752", "contents": "Title: Manipulation and abuse on social media Abstract: The computer science research community has became increasingly interested in\nthe study of social media due to their pervasiveness in the everyday life of\nmillions of individuals. Methodological questions and technical challenges\nabound as more and more data from social platforms become available for\nanalysis. This data deluge not only yields the unprecedented opportunity to\nunravel questions about online individuals' behavior at scale, but also allows\nto explore the potential perils that the massive adoption of social media\nbrings to our society. These communication channels provide plenty of\nincentives (both economical and social) and opportunities for abuse. As social\nmedia activity became increasingly intertwined with the events in the offline\nworld, individuals and organizations have found ways to exploit these platforms\nto spread misinformation, to attack and smear others, or to deceive and\nmanipulate. During crises, social media have been effectively used for\nemergency response, but fear-mongering actions have also triggered mass\nhysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt\nsocial media for propaganda and recruitment. Synthetic activity and social bots\nhave been used to coordinate orchestrated astroturf campaigns, to manipulate\npolitical elections and the stock market. The lack of effective content\nverification systems on many of these platforms, including Twitter and\nFacebook, rises concerns when younger users become exposed to cyber-bulling,\nharassment, or hate speech, inducing risks like depression and suicide. This\narticle illustrates some of the recent advances facing these issues and\ndiscusses what it remains to be done, including the challenges to address in\nthe future to make social media a more useful and accessible, safer and\nhealthier environment for all users. \n\n"}
{"id": "1503.05210", "contents": "Title: Speeding up lower bound estimation in powerlaw distributions Abstract: The traditional lower bound estimation method for powerlaw distributions\nbased on the Kolmogorov-Smirnov distance proved to perform better than other\ncompeting methods. However, if applied to very large collections of data, such\na method can be computationally demanding. In this paper, we propose two\nalternative methods with the aim to reduce the time required by the estimation\nprocedure. We apply the traditional method and the two proposed methods to\nlarge collections of data ($N = 500,000$) with varying values of the true lower\nbound. Both the proposed methods yield a significantly better performance and\naccuracy than the traditional method. \n\n"}
{"id": "1503.06152", "contents": "Title: Comparing and modeling land use organization in cities Abstract: The advent of geolocated ICT technologies opens the possibility of exploring\nhow people use space in cities, bringing an important new tool for urban\nscientists and planners, especially for regions where data is scarce or not\navailable. Here we apply a functional network approach to determine land use\npatterns from mobile phone records. The versatility of the method allows us to\nrun a systematic comparison between Spanish cities of various sizes. The method\ndetects four major land use types that correspond to different temporal\npatterns. The proportion of these types, their spatial organization and scaling\nshow a strong similarity between all cities that breaks down at a very local\nscale, where land use mixing is specific to each urban area. Finally, we\nintroduce a model inspired by Schelling's segregation, able to explain and\nreproduce these results with simple interaction rules between different land\nuses. \n\n"}
{"id": "1503.06584", "contents": "Title: Citation Analysis with Mark-and-Recapture Abstract: Mark-and-Recapture is a methodology from Population Biology to estimate the\nnumber of a species without counting every individual. This is done by multiple\nsamplings of the species using traps and discounting the instances that were\ncaught repeated. In this paper we show that this methodology is applicable for\ncitation analysis as it is also not feasible to count all the relevant\npublications of a research topic. In addition this estimation also allows us to\npropose a stopping rule for researchers to decide how far one should extend\ntheir search for relevant literature. \n\n"}
{"id": "1503.07630", "contents": "Title: Events Determine Spreading Patterns: Information Transmission via\n  Internal and External Influences on Social Networks Abstract: Recently, information transmission models motivated by the classical epidemic\npropagation, have been applied to a wide-range of social systems, generally\nassume that information mainly transmits among individuals via peer-to-peer\ninteractions on social networks. In this paper, we consider one more approach\nfor users to get information: the out-of-social-network influence. Empirical\nanalyses of eight typical events' diffusion on a very large micro-blogging\nsystem, \\emph{Sina Weibo}, show that the external influence has significant\nimpact on information spreading along with social activities. In addition, we\npropose a theoretical model to interpret the spreading process via both\ninternal and external channels, considering three essential properties: (i)\nmemory effect; (ii) role of spreaders; and (iii) non-redundancy of contacts.\nExperimental and mathematical results indicate that the information indeed\nspreads much quicker and broader with mutual effects of the internal and\nexternal influences. More importantly, the present model reveals that the event\ncharacteristic would highly determine the essential spreading patterns once the\nnetwork structure is established. The results may shed some light on the\nin-depth understanding of the underlying dynamics of information transmission\non real social networks. \n\n"}
{"id": "1503.08676", "contents": "Title: Dynamics of multi-stage infections on networks Abstract: This paper investigates the dynamics of infectious diseases with a\nnon-exponentially distributed infectious period. This is achieved by\nconsidering a multi-stage infection model on networks. Using pairwise\napproximation with a standard closure, a number of important characteristics of\ndisease dynamics are derived analytically, including the final size of an\nepidemic and a threshold for epidemic outbreaks, and it is shown how these\nquantities depend on disease characteristics, as well as the number of disease\nstages. Stochastic simulations of dynamics on networks are performed and\ncompared to the results of pairwise models for several realistic examples of\ninfectious diseases to illustrate the role played by the number of stages in\nthe disease dynamics. These results show that a higher number of disease stages\nresults in faster epidemic outbreaks with a higher peak prevalence and a larger\nfinal size of the epidemic. The agreement between the pairwise and simulation\nmethods is excellent in the cases we consider. \n\n"}
{"id": "1504.00298", "contents": "Title: Bayesian model comparison with un-normalised likelihoods Abstract: Models for which the likelihood function can be evaluated only up to a\nparameter-dependent unknown normalising constant, such as Markov random field\nmodels, are used widely in computer science, statistical physics, spatial\nstatistics, and network analysis. However, Bayesian analysis of these models\nusing standard Monte Carlo methods is not possible due to the intractability of\ntheir likelihood functions. Several methods that permit exact, or close to\nexact, simulation from the posterior distribution have recently been developed.\nHowever, estimating the evidence and Bayes' factors (BFs) for these models\nremains challenging in general. This paper describes new random weight\nimportance sampling and sequential Monte Carlo methods for estimating BFs that\nuse simulation to circumvent the evaluation of the intractable likelihood, and\ncompares them to existing methods. In some cases we observe an advantage in the\nuse of biased weight estimates. An initial investigation into the theoretical\nand empirical properties of this class of methods is presented. Some support\nfor the use of biased estimates is presented, but we advocate caution in the\nuse of such estimates. \n\n"}
{"id": "1504.00488", "contents": "Title: Direct Observation of Large Amplitude Spin Excitations Localized in a\n  Spin-Transfer Nanocontact Abstract: We report the direct observation of large amplitude spin-excitations\nlocalized in a spin-transfer nanocontact using scanning transmission x-ray\nmicroscopy. Experiments were conducted using a nanocontact to an ultrathin\nferromagnetic multilayer with perpendicular magnetic anisotropy. Element\nresolved x-ray magnetic circular dichroism images show an abrupt onset of spin\nexcitations at a threshold current that are localized beneath the nanocontact,\nwith average spin precession cone angles of 25{\\deg} at the contact center. The\nresults strongly suggest that we have observed a localized magnetic soliton. \n\n"}
{"id": "1504.00620", "contents": "Title: Comparison of Very Smooth Cell-Model Trajectories Using Five Symplectic\n  and Two Runge-Kutta Integrators Abstract: Time-reversible symplectic methods, which are precisely compatible with\nLiouville's phase-volume-conservation theorem, are often recommended for\ncomputational simulations of Hamiltonian mechanics. Lack of energy drift is an\napparent advantage of such methods. But all numerical methods are susceptible\nto Lyapunov instability, which severely limits the maximum time for which\nchaotic solutions can be \"accurate\". The \"advantages\" of higher-order methods\nare lost rapidly for typical chaotic Hamiltonians. We illustrate these\ndifficulties for a useful reproducible test case, the two-dimensional\none-particle cell model with specially smooth forces. This Hamiltonian problem\nis chaotic and occurs on a three-dimensional constant-energy shell, the minimum\ndimension for chaos. We benchmark the problem with quadruple-precision\ntrajectories using the fourth-order Candy-Rozmus, fifth-order Runge-Kutta, and\neighth-order Schlier-Seiter-Teloy integrators. We compare the last,\nmost-accurate particle trajectories to those from six double-precision\nalgorithms, four symplectic and two Runge-Kutta. \n\n"}
{"id": "1504.02065", "contents": "Title: Learning about probabilistic inference and forecasting by playing with\n  multivariate normal distributions Abstract: The properties of the normal distribution under linear transformation, as\nwell the easy way to compute the covariance matrix of marginals and\nconditionals, offer a unique opportunity to get an insight about several\naspects of uncertainties in measurements. The way to build the overall\ncovariance matrix in a few, but conceptually relevant cases is illustrated:\nseveral observations made with (possibly) different instruments measuring the\nsame quantity; effect of systematics (although limited to offset, in order to\nstick to linear models) on the determination of the 'true value', as well in\nthe prediction of future observations; correlations which arise when different\nquantities are measured with the same instrument affected by an offset\nuncertainty; inferences and predictions based on averages; inference about\nconstrained values; fits under some assumptions (linear models with known\nstandard deviations). Many numerical examples are provided, exploiting the\nability of the R language to handle large matrices and to produce high quality\nplots. Some of the results are framed in the general problem of 'propagation of\nevidence', crucial in analyzing graphical models of knowledge. \n\n"}
{"id": "1504.02361", "contents": "Title: Exploring multi-layer flow network of international trade based on flow\n  distances Abstract: Based on the approach of flow distances, the international trade flow system\nis studied from the perspective of multi-layer flow network. A model of\nmulti-layer flow network is proposed for modelling and analyzing multiple types\nof flows in flow systems. Then, flow distances are introduced, and symmetric\nminimum flow distance is presented. Subsequently, we discuss the establishment\nof the multi-layer flow networks of international trade from two coupled\nviewpoints, i.e., the viewpoint of commodity flow and that of money flow. Thus,\nthe multi-layer flow networks of international trade is explored. First,\ntrading \"trophic levels\" are adopted to depict positions that economies\noccupied in the flow network. We find that the distributions of trading\n\"trophic levels\" have the similar clustering pattern for different types of\ncommodity, and there are some regularities between money flow network and\ncommodity flow network. Second, we find that active and competitive countries\ntrade a wide spectrum of products, while inactive and underdeveloped countries\ntrade a limited variety of products. Besides, some abnormal countries import\nmany types of goods, which the vast majority of countries do not need to\nimport. It may indicate an abnormal economic status. Third, harmonic node\ncentrality is proposed and we find the phenomenon of centrality stratification.\nIt means that competitive countries tend to occupy the central positions in the\ntrading of a large variety of commodities, while underdeveloped countries\nlikely in the peripheral positions in the trading of their limited varieties of\nproducts. Fourth, we find that manufactured products have significant larger\nmean first-passage flow distances from the source to the sink than that of\nprimary products. \n\n"}
{"id": "1504.02661", "contents": "Title: Stochastic determination of matrix determinants Abstract: Matrix determinants play an important role in data analysis, in particular\nwhen Gaussian processes are involved. Due to currently exploding data volumes,\nlinear operations - matrices - acting on the data are often not accessible\ndirectly but are only represented indirectly in form of a computer routine.\nSuch a routine implements the transformation a data vector undergoes under\nmatrix multiplication. While efficient probing routines to estimate a matrix's\ndiagonal or trace, based solely on such computationally affordable\nmatrix-vector multiplications, are well known and frequently used in signal\ninference, there is no stochastic estimate for its determinant. We introduce a\nprobing method for the logarithm of a determinant of a linear operator. Our\nmethod rests upon a reformulation of the log-determinant by an integral\nrepresentation and the transformation of the involved terms into stochastic\nexpressions. This stochastic determinant determination enables large-size\napplications in Bayesian inference, in particular evidence calculations, model\ncomparison, and posterior determination. \n\n"}
{"id": "1504.04359", "contents": "Title: Evolutionary games on multilayer networks: A colloquium Abstract: Networks form the backbone of many complex systems, ranging from the Internet\nto human societies. Accordingly, not only is the range of our interactions\nlimited and thus best described and modeled by networks, it is also a fact that\nthe networks that are an integral part of such models are often interdependent\nor even interconnected. Networks of networks or multilayer networks are\ntherefore a more apt description of social systems. This colloquium is devoted\nto evolutionary games on multilayer networks, and in particular to the\nevolution of cooperation as one of the main pillars of modern human societies.\nWe first give an overview of the most significant conceptual differences\nbetween single-layer and multilayer networks, and we provide basic definitions\nand a classification of the most commonly used terms. Subsequently, we review\nfascinating and counterintuitive evolutionary outcomes that emerge due to\ndifferent types of interdependencies between otherwise independent populations.\nThe focus is on coupling through the utilities of players, through the flow of\ninformation, as well as through the popularity of different strategies on\ndifferent network layers. The colloquium highlights the importance of pattern\nformation and collective behavior for the promotion of cooperation under\nadverse conditions, as well as the synergies between network science and\nevolutionary game theory. \n\n"}
{"id": "1504.04387", "contents": "Title: Benford's Law Applies To Online Social Networks Abstract: Benford's Law states that the frequency of first digits of numbers in\nnaturally occurring systems is not evenly distributed. Numbers beginning with a\n1 occur roughly 30\\% of the time, and are six times more common than numbers\nbeginning with a 9. We show that Benford's Law applies to social and behavioral\nfeatures of users in online social networks. We consider social data from five\nmajor social networks: Facebook, Twitter, Google Plus, Pinterest, and Live\nJournal. We show that the distribution of first significant digits of friend\nand follower counts for users in these systems follow Benford's Law. The same\nholds for the number of posts users make. We extend this to egocentric\nnetworks, showing that friend counts among the people in an individual's social\nnetwork also follow the expected distribution. We discuss how this can be used\nto detect suspicious or fraudulent activity online and to validate datasets. \n\n"}
{"id": "1504.04531", "contents": "Title: Hyperspectral pansharpening: a review Abstract: Pansharpening aims at fusing a panchromatic image with a multispectral one,\nto generate an image with the high spatial resolution of the former and the\nhigh spectral resolution of the latter. In the last decade, many algorithms\nhave been presented in the literature for pansharpening using multispectral\ndata. With the increasing availability of hyperspectral systems, these methods\nare now being adapted to hyperspectral images. In this work, we compare new\npansharpening techniques designed for hyperspectral data with some of the state\nof the art methods for multispectral pansharpening, which have been adapted for\nhyperspectral data. Eleven methods from different classes (component\nsubstitution, multiresolution analysis, hybrid, Bayesian and matrix\nfactorization) are analyzed. These methods are applied to three datasets and\ntheir effectiveness and robustness are evaluated with widely used performance\nindicators. In addition, all the pansharpening techniques considered in this\npaper have been implemented in a MATLAB toolbox that is made available to the\ncommunity. \n\n"}
{"id": "1504.05552", "contents": "Title: Category theoretic properties of the A. R\\'enyi and C. Tsallis entropies Abstract: The problem of embedding the Tsallis and R\\'{e}nyi entropies in the framework\nof category theory and their axiomatic foundation is studied. To this end, we\nconstruct a special category MES related to measured spaces. We prove that both\nof the R\\'{e}nyi and Tsallis entropies can be imbedded in the formalism of\ncategory theory by proving that the same basic functional that appears in their\ndefinitions, as well as in the associated Lebesgue space norms, has good\nalgebraic compatibility properties. We prove that this functional is both\nadditive and multiplicative with respect to the direct product and the disjoint\nsum (the coproduct) in the category MES, so it is a natural candidate for the\nmeasure of information or uncertainty. We prove that the category MES can be\nextended to monoidal category, both with respect to the direct product as well\nas to the coproduct. The basic axioms of the original R\\'{e}nyi entropy theory\nare generalized and reformulated in the framework of category MES and we prove\nthat these axioms foresee the existence of an universal exponent having the\nsame values for all the objects of the category MES. In addition, this\nuniversal exponent is the parameter, which appears in the definition of the\nTsallis and R\\'{e}nyi entropies. \n\n"}
{"id": "1505.00644", "contents": "Title: Modeling the role of relationship fading and breakup in social network\n  formation Abstract: In social networks of human individuals, social relationships do not\nnecessarily last forever as they can either fade gradually with time, resulting\nin link aging, or terminate abruptly, causing link deletion, as even old\nfriendships may cease. In this paper, we study a social network formation model\nwhere we introduce several ways by which a link termination takes place. If we\nadopt the link aging, we get a more modular structure with more homogeneously\ndistributed link weights within communities than when link deletion is used. By\ninvestigating distributions and relations of various network characteristics,\nwe find that the empirical findings are better reproduced with the link\ndeletion model. This indicates that link deletion plays a more prominent role\nin organizing social networks than link aging. \n\n"}
{"id": "1505.02476", "contents": "Title: Identifying influential spreaders in complex networks based on gravity\n  formula Abstract: How to identify the influential spreaders in social networks is crucial for\naccelerating/hindering information diffusion, increasing product exposure,\ncontrolling diseases and rumors, and so on. In this paper, by viewing the\nk-shell value of each node as its mass and the shortest path distance between\ntwo nodes as their distance, then inspired by the idea of the gravity formula,\nwe propose a gravity centrality index to identify the influential spreaders in\ncomplex networks. The comparison between the gravity centrality index and some\nwell-known centralities, such as degree centrality, betweenness centrality,\ncloseness centrality, and k-shell centrality, and so forth, indicates that our\nmethod can effectively identify the influential spreaders in real networks as\nwell as synthetic networks. We also use the classical\nSusceptible-Infected-Recovered (SIR) epidemic model to verify the good\nperformance of our method. \n\n"}
{"id": "1505.02750", "contents": "Title: Effects of polynomial trends on detrending moving average analysis Abstract: The detrending moving average (DMA) algorithm is one of the best performing\nmethods to quantify the long-term correlations in nonstationary time series.\nMany long-term correlated time series in real systems contain various trends.\nWe investigate the effects of polynomial trends on the scaling behaviors and\nthe performances of three widely used DMA methods including backward algorithm\n(BDMA), centered algorithm (CDMA) and forward algorithm (FDMA). We derive a\ngeneral framework for polynomial trends and obtain analytical results for\nconstant shifts and linear trends. We find that the behavior of the CDMA method\nis not influenced by constant shifts. In contrast, linear trends cause a\ncrossover in the CDMA fluctuation functions. We also find that constant shifts\nand linear trends cause crossovers in the fluctuation functions obtained from\nthe BDMA and FDMA methods. When a crossover exists, the scaling behavior at\nsmall scales comes from the intrinsic time series while that at large scales is\ndominated by the constant shifts or linear trends. We also derive analytically\nthe expressions of crossover scales and show that the crossover scale depends\non the strength of the polynomial trend, the Hurst index, and in some cases\n(linear trends for BDMA and FDMA) the length of the time series. In all cases,\nthe BDMA and the FDMA behave almost the same under the influence of constant\nshifts or linear trends. Extensive numerical experiments confirm excellently\nthe analytical derivations. We conclude that the CDMA method outperforms the\nBDMA and FDMA methods in the presence of polynomial trends. \n\n"}
{"id": "1505.02760", "contents": "Title: Multifractal to monofractal evolution of the London's street network Abstract: We perform a multifractal analysis of the evolution of London's street\nnetwork from 1786 to 2010. First, we show that a single fractal dimension,\ncommonly associated with the morphological description of cities, does not su\nce to capture the dynamics of the system. Instead, for a proper\ncharacterization of such a dynamics, the multifractal spectrum needs to be\nconsidered. Our analysis reveals that London evolves from an inhomogeneous\nfractal structure, that can be described in terms of a multifractal, to a\nhomogeneous one, that converges to monofractality. We argue that London's\nmultifractal to monofracal evolution might be a special outcome of the\nconstraint imposed on its growth by a green belt. Through a series of\nsimulations, we show that multifractal objects, constructed through di usion\nlimited aggregation, evolve towards monofractality if their growth is\nconstrained by a non-permeable boundary. \n\n"}
{"id": "1505.06476", "contents": "Title: Emergence of bimodality in controlling complex networks Abstract: Our ability to control complex systems is a fundamental challenge of\ncontemporary science. Recently introduced tools to identify the driver nodes,\nnodes through which we can achieve full control, predict the existence of\nmultiple control configurations, prompting us to classify each node in a\nnetwork based on their role in control. Accordingly a node is critical,\nintermittent or redundant if it acts as a driver node in all, some or none of\nthe control configurations. Here we develop an analytical framework to identify\nthe category of each node, leading to the discovery of two distinct control\nmodes in complex systems: centralized vs distributed control. We predict the\ncontrol mode for an arbitrary network and show that one can alter it through\nsmall structural perturbations. The uncovered bimodality has implications from\nnetwork security to organizational research and offers new insights into the\ndynamics and control of complex systems. \n\n"}
{"id": "1506.00185", "contents": "Title: Bayesian semiparametric power spectral density estimation with\n  applications in gravitational wave data analysis Abstract: The standard noise model in gravitational wave (GW) data analysis assumes\ndetector noise is stationary and Gaussian distributed, with a known power\nspectral density (PSD) that is usually estimated using clean off-source data.\nReal GW data often depart from these assumptions, and misspecified parametric\nmodels of the PSD could result in misleading inferences. We propose a Bayesian\nsemiparametric approach to improve this. We use a nonparametric Bernstein\npolynomial prior on the PSD, with weights attained via a Dirichlet process\ndistribution, and update this using the Whittle likelihood. Posterior samples\nare obtained using a blocked Metropolis-within-Gibbs sampler. We simultaneously\nestimate the reconstruction parameters of a rotating core collapse supernova GW\nburst that has been embedded in simulated Advanced LIGO noise. We also discuss\nan approach to deal with non-stationary data by breaking longer data streams\ninto smaller and locally stationary components. \n\n"}
{"id": "1506.00627", "contents": "Title: Spatio-temporal networks: reachability, centrality and robustness Abstract: Recent advances in spatial and temporal networks have enabled researchers to\nmore-accurately describe many real-world systems such as urban transport\nnetworks. In this paper, we study the response of real-world spatio-temporal\nnetworks to random error and systematic attack, taking a unified view of their\nspatial and temporal performance. We propose a model of spatio-temporal paths\nin time-varying spatially embedded networks which captures the property that,\nas in many real-world systems, interaction between nodes is non-instantaneous\nand governed by the space in which they are embedded. Through numerical\nexperiments on three real-world urban transport systems, we study the effect of\nnode failure on a network's topological, temporal and spatial structure. We\nalso demonstrate the broader applicability of this framework to three other\nclasses of network. To identify weaknesses specific to the behaviour of a\nspatio-temporal system, we introduce centrality measures that evaluate the\nimportance of a node as a structural bridge and its role in supporting\nspatio-temporally efficient flows through the network. This exposes the complex\nnature of fragility in a spatio-temporal system, showing that there is a\nvariety of failure modes when a network is subject to systematic attacks. \n\n"}
{"id": "1506.00986", "contents": "Title: The Impact of Heterogeneous Thresholds on Social Contagion with Multiple\n  Initiators Abstract: The threshold model is a simple but classic model of contagion spreading in\ncomplex social systems. To capture the complex nature of social influencing we\ninvestigate numerically and analytically the transition in the behavior of\nthreshold-limited cascades in the presence of multiple initiators as the\ndistribution of thresholds is varied between the two extreme cases of identical\nthresholds and a uniform distribution. We accomplish this by employing a\ntruncated normal distribution of the nodes' thresholds and observe a\nnon-monotonic change in the cascade size as we vary the standard deviation.\nFurther, for a sufficiently large spread in the threshold distribution, the\ntipping-point behavior of the social influencing process disappears and is\nreplaced by a smooth crossover governed by the size of initiator set. We\ndemonstrate that for a given size of the initiator set, there is a specific\nvariance of the threshold distribution for which an opinion spreads optimally.\nFurthermore, in the case of synthetic graphs we show that the spread\nasymptotically becomes independent of the system size, and that global cascades\ncan arise just by the addition of a single node to the initiator set. \n\n"}
{"id": "1506.01565", "contents": "Title: The Many Faces of Graph Dynamics Abstract: The topological structure of complex networks has fascinated researchers for\nseveral decades, resulting in the discovery of many universal properties and\nreoccurring characteristics of different kinds of networks. However, much less\nis known today about the network dynamics: indeed, complex networks in reality\nare not static, but rather dynamically evolve over time.\n  Our paper is motivated by the empirical observation that network evolution\npatterns seem far from random, but exhibit structure. Moreover, the specific\npatterns appear to depend on the network type, contradicting the existence of a\n\"one fits it all\" model. However, we still lack observables to quantify these\nintuitions, as well as metrics to compare graph evolutions. Such observables\nand metrics are needed for extrapolating or predicting evolutions, as well as\nfor interpolating graph evolutions.\n  To explore the many faces of graph dynamics and to quantify temporal changes,\nthis paper suggests to build upon the concept of centrality, a measure of node\nimportance in a network. In particular, we introduce the notion of centrality\ndistance, a natural similarity measure for two graphs which depends on a given\ncentrality, characterizing the graph type. Intuitively, centrality distances\nreflect the extent to which (non-anonymous) node roles are different or, in\ncase of dynamic graphs, have changed over time, between two graphs.\n  We evaluate the centrality distance approach for five evolutionary models and\nseven real-world social and physical networks. Our results empirically show the\nusefulness of centrality distances for characterizing graph dynamics compared\nto a null-model of random evolution, and highlight the differences between the\nconsidered scenarios. Interestingly, our approach allows us to compare the\ndynamics of very different networks, in terms of scale and evolution speed. \n\n"}
{"id": "1506.02601", "contents": "Title: Solar Axion search with Micromegas detectors in the CAST Experiment with\n  $^{3}$He as buffer gas Abstract: Axions are well motivated particles proposed in an extension of the SM as a\nsolution to the strong CP problem. Also, there is the category of Axion-Like\nParticles (ALPs) which appear in extensions of the SM and share the same\nphenomenology of the axion. Axions and ALPs are candidates to solve the Dark\nMatter problem. CAST, the CERN Axion Solar Telescope is looking for solar\naxions since 2003. CAST exploit the helioscope technique using a decommissioned\nLHC dipole magnet in which solar axions could be reconverted into photons.\nThree of the four detectors operating at CAST are of the Micromegas type. The\nanalysis of the data of the three Micromegas detectors during the 2011 data\ntaking campaign at CAST is presented in this thesis, obtaining a limit on the\ncoupling constant of g$_{a \\gamma}$ < 3.90 $\\times$ 10$^{-10}$ GeV$^{-1}$ at a\n95$\\%$ of confidence level, for axion masses from 1 to 1.17 eV. CAST Micromegas\ndetectors exploit different strategies developed for the reduction of the\nbackground level. Moreover, different test benches have been developed in order\nto understand the origin of the background. The state of art in low background\ntechniques is shown in the upgrades of the Micromegas detectors at CAST, which\nhas led to a reduction of the background in a factor $\\sim$6. It translates in\nan improvement of the sensitivity of CAST in a factor $\\sim$2.5. Beyond CAST a\nnew generation axion helioscope has been proposed: IAXO-the International Axion\nObservatory. IAXO will enhance the helioscope technique by exploiting all the\nsingularities of CAST implemented into a large superconducting toroidal magnet,\ndedicated X-ray optics and ultra-low background detectors. A description of the\nIAXO proposal and the study of the sensitivity of IAXO are presented in this\nthesis. IAXO will surpass CAST in more than one order of magnitude, entering\ninto an unexplored parameter space area. \n\n"}
{"id": "1506.05009", "contents": "Title: The Omega Counter, a Frequency Counter Based on the Linear Regression Abstract: This article introduces the {\\Omega} counter, a frequency counter -- or a\nfrequency-to-digital converter, in a different jargon -- based on the Linear\nRegression (LR) algorithm on time stamps. We discuss the noise of the\nelectronics. We derive the statistical properties of the {\\Omega} counter on\nrigorous mathematical basis, including the weighted measure and the frequency\nresponse. We describe an implementation based on a SoC, under test in our\nlaboratory, and we compare the {\\Omega} counter to the traditional {\\Pi} and\n{\\Lambda} counters. The LR exhibits optimum rejection of white phase noise,\nsuperior to that of the {\\Pi} and {\\Lambda} counters. White noise is the major\npractical problem of wideband digital electronics, both in the instrument\ninternal circuits and in the fast processes which we may want to measure. The\n{\\Omega} counter finds a natural application in the measurement of the\nParabolic Variance, described in the companion article arXiv:1506.00687\n[physics.data-an]. \n\n"}
{"id": "1506.06053", "contents": "Title: Non-Uniform Distribution of Nodes in the Spatial Preferential Attachment\n  Model Abstract: The spatial preferential attachment (SPA) is a model for complex networks. In\nthe SPA model, nodes are embedded in a metric space, and each node has a sphere\nof influence whose size increases if the node gains an in-link, and otherwise\ndecreases with time. In this paper, we study the behaviour of the SPA model\nwhen the distribution of the nodes is non-uniform. Specifically, the space is\ndivided into dense and sparse regions, where it is assumed that the dense\nregions correspond to coherent communities. We prove precise theoretical\nresults regarding the degree of a node, the number of common neighbours, and\nthe average out-degree in a region. Moreover, we show how these theoretically\nderived results about the graph properties of the model can be used to\nformulate a reliable estimator for the distance between certain pairs of nodes,\nand to estimate the density of the region containing a given node. \n\n"}
{"id": "1506.06580", "contents": "Title: Quantifying Cultural Histories via Person Networks in Wikipedia Abstract: At least since Priestley's 1765 Chart of Biography, large numbers of\nindividual person records have been used to illustrate aggregate patterns of\ncultural history. Wikidata, the structured database sister of Wikipedia,\ncurrently contains about 2.7 million explicit person records, across all\nlanguage versions of the encyclopedia. These individuals, notable according to\nWikipedia editing criteria, are connected via millions of hyperlinks between\ntheir respective Wikipedia articles. This situation provides us with the chance\nto go beyond the illustration of an idiosyncratic subset of individuals, as in\nthe case of Priestly. In this work we summarize the overlap of nationalities\nand occupations, based on their co-occurrence in Wikidata individuals. We\nconstruct networks of co-occurring nationalities and occupations, provide\ninsights into their respective community structure, and apply the results to\nselect and color chronologically structured subsets of a large network of\nindividuals, connected by Wikipedia hyperlinks. While the imagined communities\nof nationality are much more discrete in terms of co-occurrence than\noccupations, our quantifications reveal the existing overlap of nationality as\nmuch less clear-cut than in case of occupational domains. Our work contributes\nto a growing body of research using biographies of notable persons to analyze\ncultural processes. \n\n"}
{"id": "1506.06716", "contents": "Title: A model of language inflection graphs Abstract: Inflection graphs are highly complex networks representing relationships\nbetween inflectional forms of words in human languages. For so-called synthetic\nlanguages, such as Latin or Polish, they have particularly interesting\nstructure due to abundance of inflectional forms. We construct the simplest\nform of inflection graphs, namely a bipartite graph in which one group of\nvertices corresponds to dictionary headwords and the other group to inflected\nforms encountered in a given text. We then study projection of this graph on\nthe set of headwords. The projection decomposes into a large number of\nconnected components, to be called word groups. Distribution of sizes of word\ngroup exhibits some remarkable properties, resembling cluster distribution in a\nlattice percolation near the critical point. We propose a simple model which\nproduces graphs of this type, reproducing the desired component distribution\nand other topological features. \n\n"}
{"id": "1506.06808", "contents": "Title: Statistical Measures of Planck Scale Signal Correlations in\n  Interferometers Abstract: A model-independent statistical framework is presented to interpret data from\nsystems where the mean time derivative of positional cross correlation between\nworld lines, a measure of spreading in a quantum geometrical wave function, is\nmeasured with a precision smaller than the Planck time. The framework provides\na general way to constrain possible departures from perfect independence of\nclassical world lines, associated with Planck scale bounds on positional\ninformation. A parametrized candidate set of possible correlation functions is\nshown to be consistent with the known causal structure of the classical\ngeometry measured by an apparatus, and the holographic scaling of information\nsuggested by gravity. Frequency-domain power spectra are derived that can be\ncompared with interferometer data. Simple projections of sensitivity for\nspecific experimental set-ups suggests that measurements will directly yield\nconstraints on a universal time derivative of the correlation function, and\nthereby confirm or rule out a class of Planck scale departures from classical\ngeometry. \n\n"}
{"id": "1506.08378", "contents": "Title: Slow-down or speed-up of inter- and intra-cluster diffusion of\n  controversial knowledge in stubborn communities based on a small world\n  network Abstract: Diffusion of knowledge is expected to be huge when agents are open minded.\nThe report concerns a more difficult diffusion case when communities are made\nof stubborn agents. Communities having markedly different opinions are for\nexample the Neocreationist and Intelligent Design Proponents (IDP), on one\nhand, and the Darwinian Evolution Defenders (DED), on the other hand. The case\nof knowledge diffusion within such communities is studied here on a network\nbased on an adjacency matrix built from time ordered selected quotations of\nagents, whence for inter- and intra-communities. The network is intrinsically\ndirected and not necessarily reciprocal. Thus, the adjacency matrices have\ncomplex eigenvalues, the eigenvectors present complex components. A\nquantification of the slow-down or speed-up effects of information diffusion in\nsuch temporal networks, with non-Markovian contact sequences, can be made by\ncomparing the real time dependent (directed) network to its counterpart, the\ntime aggregated (undirected) network, - which has real eigenvalues. In order to\ndo so, small world networks which both contain an $odd$ number of nodes are\nstudied and compared to similar networks with an $even$ number of nodes.\n  It is found that (i) the diffusion of knowledge is more difficult on the\nlargest networks, (ii) the network size influences the slowing-down or\nspeeding-up diffusion process. Interestingly, it is observed that (iii) the\ndiffusion of knowledge is slower in IDP and faster in DED communities. It is\nsuggested that the finding can be \"rationalized\", if some \"scientific quality\"\nand \"publication habit\" is attributed to the agents, as common sense would\nguess. This finding offers some opening discussion toward tying scientific\nknowledge to belief. \n\n"}
{"id": "1506.09096", "contents": "Title: Bounds of memory strength for power-law series Abstract: Many time series produced by complex systems are empirically found to follow\npower-law distributions with different exponents $\\alpha$. By permuting the\nindependently drawn samples from a power-law distribution, we present\nnon-trivial bounds on the memory strength (1st-order autocorrelation) as a\nfunction of $\\alpha$, which are markedly different from the ordinary $\\pm 1$\nbounds for Gaussian or uniform distributions. When $1 < \\alpha \\leq 3$, as\n$\\alpha$ grows bigger, the upper bound increases from 0 to +1 while the lower\nbound remains 0; when $\\alpha > 3$, the upper bound remains +1 while the lower\nbound descends below 0. Theoretical bounds agree well with numerical\nsimulations. Based on the posts on Twitter, ratings of MovieLens, calling\nrecords of the mobile operator Orange, and browsing behavior of Taobao, we find\nthat empirical power-law distributed data produced by human activities obey\nsuch constraints. The present findings explain some observed constraints in\nbursty time series and scale-free networks, and challenge the validity of\nmeasures like autocorrelation and assortativity coefficient in heterogeneous\nsystems. \n\n"}
{"id": "1507.00695", "contents": "Title: A new framework for dynamical models on multiplex networks Abstract: Many complex systems have natural representations as multi-layer networks.\nWhile these formulations retain more information than standard single-layer\nnetwork models, there is not yet a fully developed theory for computing network\nmetrics and statistics on these objects. We introduce a family of models of\nmultiplex processes motivated by dynamical applications and investigate the\nproperties of their spectra both theoretically and computationally. We study\nspecial cases of multiplex diffusion and Markov dynamics, using the spectral\nresults to compute their rates of convergence. We use our framework to define a\nversion of multiplex eigenvector centrality, which generalizes some existing\nnotions in the literature. Last, we compare our operator to\nstructurally-derived models on synthetic and real-world networks, helping\ndelineate the contexts in which the different frameworks are appropriate. \n\n"}
{"id": "1507.04255", "contents": "Title: Weak chaos, infinite ergodic theory, and anomalous dynamics Abstract: This book chapter introduces to the concept of weak chaos, aspects of its\nergodic theory description, and properties of the anomalous dynamics associated\nwith it. In the first half of the chapter we study simple one-dimensional\ndeterministic maps, in the second half basic stochastic models and eventually\nan experiment. We start by reminding the reader of fundamental chaos quantities\nand their relation to each other, exemplified by the paradigmatic Bernoulli\nshift. Using the intermittent Pomeau-Manneville map the problem of weak chaos\nand infinite ergodic theory is outlined, defining a very recent mathematical\nfield of research. Considering a spatially extended version of the\nPomeau-Manneville map leads us to the phenomenon of anomalous diffusion. This\nproblem will be discussed by applying stochastic continuous time random walk\ntheory and by deriving a fractional diffusion equation. Another important topic\nwithin modern nonequilibrium statistical physics are fluctuation relations,\nwhich we investigate for anomalous dynamics. The chapter concludes by showing\nthe importance of anomalous dynamics for understanding experimental results on\nbiological cell migration. \n\n"}
{"id": "1507.04308", "contents": "Title: A New Metric for Quality of Network Community Structure Abstract: Modularity is widely used to effectively measure the strength of the\ncommunity structure found by community detection algorithms. However,\nmodularity maximization suffers from two opposite yet coexisting problems: in\nsome cases, it tends to favor small communities over large ones while in\nothers, large communities over small ones. The latter tendency is known in the\nliterature as the resolution limit problem. To address them, we propose to\nmodify modularity by subtracting from it the fraction of edges connecting nodes\nof different communities and by including community density into modularity. We\nrefer to the modified metric as Modularity Density and we demonstrate that it\nindeed resolves both problems mentioned above. We describe the motivation for\nintroducing this metric by using intuitively clear and simple examples. We also\nprove that this new metric solves the resolution limit problem. Finally, we\ndiscuss the results of applying this metric, modularity, and several other\npopular community quality metrics to two real dynamic networks. The results\nimply that Modularity Density is consistent with all the community quality\nmeasurements but not modularity, which suggests that Modularity Density is an\nimproved measurement of the community quality compared to modularity. \n\n"}
{"id": "1507.05990", "contents": "Title: Estimation and uncertainty of reversible Markov models Abstract: Reversibility is a key concept in Markov models and Master-equation models of\nmolecular kinetics. The analysis and interpretation of the transition matrix\nencoding the kinetic properties of the model relies heavily on the\nreversibility property. The estimation of a reversible transition matrix from\nsimulation data is therefore crucial to the successful application of the\npreviously developed theory. In this work we discuss methods for the maximum\nlikelihood estimation of transition matrices from finite simulation data and\npresent a new algorithm for the estimation if reversibility with respect to a\ngiven stationary vector is desired. We also develop new methods for the\nBayesian posterior inference of reversible transition matrices with and without\ngiven stationary vector taking into account the need for a suitable prior\ndistribution preserving the meta- stable features of the observed process\nduring posterior inference. All algorithms here are implemented in the PyEMMA\nsoftware - http://pyemma.org - as of version 2.0. \n\n"}
{"id": "1507.06106", "contents": "Title: The dynamic of information-driven coordination phenomena: a transfer\n  entropy analysis Abstract: Data from social media are providing unprecedented opportunities to\ninvestigate the processes that rule the dynamics of collective social\nphenomena. Here, we consider an information theoretical approach to define and\nmeasure the temporal and structural signatures typical of collective social\nevents as they arise and gain prominence. We use the symbolic transfer entropy\nanalysis of micro-blogging time series to extract directed networks of\ninfluence among geolocalized sub-units in social systems. This methodology\ncaptures the emergence of system-level dynamics close to the onset of socially\nrelevant collective phenomena. The framework is validated against a detailed\nempirical analysis of five case studies. In particular, we identify a change in\nthe characteristic time-scale of the information transfer that flags the onset\nof information-driven collective phenomena. Furthermore, our approach\nidentifies an order-disorder transition in the directed network of influence\nbetween social sub-units. In the absence of a clear exogenous driving, social\ncollective phenomena can be represented as endogenously-driven structural\ntransitions of the information transfer network. This study provides results\nthat can help define models and predictive algorithms for the analysis of\nsocietal events based on open source data. \n\n"}
{"id": "1507.06348", "contents": "Title: Anosov C-systems and random number generators Abstract: We are developing further our earlier suggestion to use hyperbolic Anosov\nC-systems for the Monte-Carlo simulations in high energy particle physics. The\nhyperbolic dynamical systems have homogeneous instability of all trajectories\nand as such they have mixing of all orders, countable Lebesgue spectrum and\npositive Kolmogorov entropy. These extraordinary ergodic properties follow from\nthe C-condition introduced by Anosov. The C-condition defines a rich class of\ndynamical systems which span an open set in the space of all dynamical systems.\nThe important property of C-systems is that they have a countable set of\neverywhere dense periodic trajectories and that their density exponentially\nincreases with entropy. Of special interest are C-systems that are defined on a\nhigh dimensional torus. The C-systems on a torus are perfect candidates to be\nused for Monte-Carlo simulations. Recently an efficient algorithm was found,\nwhich allows very fast generation of long trajectories of the C-systems. These\ntrajectories have high quality statistical properties and we are suggesting to\nuse them for the QCD lattice simulations and at high energy particle physics. \n\n"}
{"id": "1507.06954", "contents": "Title: Detecting changes in maps of gamma spectra with Kolmogorov-Smirnov tests Abstract: Various security, regulatory, and consequence management agencies are\ninterested in continuously monitoring wide areas for unexpected changes in\nradioactivity. Existing detection systems are designed to search for\nradioactive sources but are not suited to repeat mapping and change detection.\nUsing a set of daily spectral observations collected at the Pickle Research\nCampus, we improved on the prior Spectral Comparison Ratio Anomaly Mapping\n(SCRAM) algorithm and developed a new method based on two-sample\nKolmogorov-Smirnov tests to detect sudden spectral changes. We also designed\nsimulations and visualizations of statistical power to compare methods and\nguide deployment scenarios. \n\n"}
{"id": "1507.07148", "contents": "Title: Quantifying knowledge exchange in R&D networks: A data-driven model Abstract: We propose a model that reflects two important processes in R&D activities of\nfirms, the formation of R&D alliances and the exchange of knowledge as a result\nof these collaborations. In a data-driven approach, we analyze two large-scale\ndata sets extracting unique information about 7500 R&D alliances and 5200\npatent portfolios of firms. This data is used to calibrate the model parameters\nfor network formation and knowledge exchange. We obtain probabilities for\nincumbent and newcomer firms to link to other incumbents or newcomers which are\nable to reproduce the topology of the empirical R&D network. The position of\nfirms in a knowledge space is obtained from their patents using two different\nclassification schemes, IPC in 8 dimensions and ISI-OST-INPI in 35 dimensions.\nOur dynamics of knowledge exchange assumes that collaborating firms approach\neach other in knowledge space at a rate $\\mu$ for an alliance duration $\\tau$.\nBoth parameters are obtained in two different ways, by comparing knowledge\ndistances from simulations and empirics and by analyzing the collaboration\nefficiency $\\mathcal{\\hat{C}}_{n}$. This is a new measure, that takes also in\naccount the effort of firms to maintain concurrent alliances, and is evaluated\nvia extensive computer simulations. We find that R&D alliances have a duration\nof around two years and that the subsequent knowledge exchange occurs at a very\nlow rate. Hence, a firm's position in the knowledge space is rather a\ndeterminant than a consequence of its R&D alliances. From our data-driven\napproach we also find model configurations that can be both realistic and\noptimized with respect to the collaboration efficiency $\\mathcal{\\hat{C}}_{n}$.\nEffective policies, as suggested by our model, would incentivize shorter R&D\nalliances and higher knowledge exchange rates. \n\n"}
{"id": "1507.07838", "contents": "Title: Shifting Behaviour of Users: Towards Understanding the Fundamental Law\n  of Social Networks Abstract: Social Networking Sites (SNSs) are powerful marketing and communication\ntools. There are hundreds of SNSs that have entered and exited the market over\ntime. The coexistence of multiple SNSs is a rarely observed phenomenon. Most\ncoexisting SNSs either serve different purposes for its users or have cultural\ndifferences among them. The introduction of a new SNS with a better set of\nfeatures can lead to the demise of an existing SNS, as observed in the\ntransition from Orkut to Facebook. The paper proposes a model for analyzing the\ntransition of users from one SNS to another, when a new SNS is introduced in\nthe system. The game theoretic model proposed considers two major factors in\ndetermining the success of a new SNS. The first being time that an old SNS gets\nto stabilise. We study whether the time that a SNS like Facebook received to\nmonopolize its reach had a distinguishable effect. The second factor is the set\nof features showcased by the new SNS. The results of the model are also\nexperimentally verified with data collected by means of a survey. \n\n"}
{"id": "1507.08199", "contents": "Title: On the Digital Daily Cycles of Individuals Abstract: Humans, like almost all animals, are phase-locked to the diurnal cycle. Most\nof us sleep at night and are active through the day. Because we have evolved to\nfunction with this cycle, the circadian rhythm is deeply ingrained and even\ndetectable at the biochemical level. However, within the broader day-night\npattern, there are individual differences: e.g., some of us are intrinsically\nmorning-active, while others prefer evenings. In this article, we look at\ndigital daily cycles: circadian patterns of activity viewed through the lens of\nauto-recorded data of communication and online activity. We begin at the\naggregate level, discuss earlier results, and illustrate differences between\npopulation-level daily rhythms in different media. Then we move on to the\nindividual level, and show that there is a strong individual-level variation\nbeyond averages: individuals typically have their distinctive daily pattern\nthat persists in time. We conclude by discussing the driving forces behind\nthese signature daily patterns, from personal traits (morningness/eveningness)\nto variation in activity level and external constraints, and outline\npossibilities for future research. \n\n"}
{"id": "1507.08335", "contents": "Title: Dissecting the roles of local packing density and longer-range effects\n  in protein sequence evolution Abstract: What are the structural determinants of protein sequence evolution? A number\nof site-specific structural characteristics have been proposed, most of which\nare broadly related to either the density of contacts or the solvent\naccessibility of individual residues. Most importantly, there has been\ndisagreement in the literature over the relative importance of solvent\naccessibility and local packing density for explaining site-specific sequence\nvariability in proteins. We show here that this discussion has been confounded\nby the definition of local packing density. The most commonly used measures of\nlocal packing, such as the contact number and the weighted contact number,\nrepresent by definition the combined effects of local packing density and\nlonger-range effects. As an alternative, we here propose a truly local measure\nof packing density around a single residue, based on the Voronoi cell volume.\nWe show that the Voronoi cell volume, when calculated relative to the geometric\ncenter of amino-acid side chains, behaves nearly identically to the relative\nsolvent accessibility, and both can explain, on average, approximately 34\\% of\nthe site-specific variation in evolutionary rate in a data set of 209 enzymes.\nAn additional 10\\% of variation can be explained by non-local effects that are\ncaptured in the weighted contact number. Consequently, evolutionary variation\nat a site is determined by the combined action of the immediate amino-acid\nneighbors of that site and of effects mediated by more distant amino acids. We\nconclude that instead of contrasting solvent accessibility and local packing\ndensity, future research should emphasize the relative importance of immediate\ncontacts and longer-range effects on evolutionary variation. \n\n"}
{"id": "1508.03147", "contents": "Title: Evolutionary potential games on lattices Abstract: Game theory provides a general mathematical background to study the effect of\npair interactions and evolutionary rules on the macroscopic behavior of\nmulti-player games where players with a finite number of strategies may\nrepresent a wide scale of biological objects, human individuals, or even their\nassociations. In these systems the interactions are characterized by matrices\nthat can be decomposed into elementary matrices (games) and classified into\nfour types. The concept of decomposition helps the identification of potential\ngames and also the evaluation of the potential that plays a crucial role in the\ndetermination of the preferred Nash equilibrium, and defines the Boltzmann\ndistribution towards which these systems evolve for suitable types of dynamical\nrules. This survey draws parallel between the potential games and the kinetic\nIsing type models which are investigated for a wide scale of connectivity\nstructures. We discuss briefly the applicability of the tools and concepts of\nstatistical physics and thermodynamics. Additionally the general features of\nordering phenomena, phase transitions and slow relaxations are outlined and\napplied to evolutionary games. The discussion extends to games with three or\nmore strategies. Finally we discuss what happens when the system is weakly\ndriven out of the \"equilibrium state\" by switching on non-potential components\nrepresenting games of cyclic dominance. \n\n"}
{"id": "1508.04819", "contents": "Title: Analyzing Organizational Routines in Online Knowledge Collaborations: A\n  Case for Sequence Analysis in CSCW Abstract: Research into socio-technical systems like Wikipedia has overlooked important\nstructural patterns in the coordination of distributed work. This paper argues\nfor a conceptual reorientation towards sequences as a fundamental unit of\nanalysis for understanding work routines in online knowledge collaboration. We\noutline a research agenda for researchers in computer-supported cooperative\nwork (CSCW) to understand the relationships, patterns, antecedents, and\nconsequences of sequential behavior using methods already developed in fields\nlike bio-informatics. Using a data set of 37,515 revisions from 16,616 unique\neditors to 96 Wikipedia articles as a case study, we analyze the prevalence and\nsignificance of different sequences of editing patterns. We illustrate the\nmixed method potential of sequence approaches by interpreting the frequent\npatterns as general classes of behavioral motifs. We conclude by discussing the\nmethodological opportunities for using sequence analysis for expanding existing\napproaches to analyzing and theorizing about co-production routines in online\nknowledge collaboration. \n\n"}
{"id": "1508.05169", "contents": "Title: Thou shalt not take sides: Cognition, Logic and the need for changing\n  how we believe Abstract: We believe, in the sense of supporting ideas and considering them correct\nwhile dismissing doubts about them. We take sides about ideas and theories as\nif that was the right thing to do. And yet, from a rational point of view, this\ntype of support and belief is not justifiable at all. The best we can hope when\ndescribing the real world, as far as we know, is to have probabilistic\nknowledge, to have probabilities associated to each statement. And even that\ncan be very hard to achieve in a reliable way. Far worse, when we defend ideas\nand believe them as if they were true, Cognitive Psychology experiments show\nthat we stop being able to analyze the question we believe at with competence.\nIn this paper, I gather the evidence we have about taking sides and present the\nobvious but unseen conclusion that these facts combined mean that we should\nactually never believe in anything about the real world, except in a\nprobabilistic way. We must actually never take sides because taking sides\ndestroy out abilities to seek for the most correct description of the world.\nThat means we need to start reformulating the way we debate ideas, from our\nteaching to our political debates, if we actually want to be able to arrive at\nthe best solutions as suggested by whatever evidence we might have. I will show\nthat this has deep consequences on a number of problems, ranging from the\nemergence of extremism to the reliability of whole scientific fields. Inductive\nreasoning requires that we allow every idea to make predictions so that we may\nrank which ideas are better and that has important consequences in scientific\npractice. The crisis around $p$-values is also discussed and much better\nunderstood under the light of this paper results. Finally, I will debate\npossible ideas to try to minimize the problem. \n\n"}
{"id": "1508.05384", "contents": "Title: Control Principles of Complex Networks Abstract: A reflection of our ultimate understanding of a complex system is our ability\nto control its behavior. Typically, control has multiple prerequisites: It\nrequires an accurate map of the network that governs the interactions between\nthe system's components, a quantitative description of the dynamical laws that\ngovern the temporal behavior of each component, and an ability to influence the\nstate and temporal behavior of a selected subset of the components. With deep\nroots in nonlinear dynamics and control theory, notions of control and\ncontrollability have taken a new life recently in the study of complex\nnetworks, inspiring several fundamental questions: What are the control\nprinciples of complex systems? How do networks organize themselves to balance\ncontrol with functionality? To address these here we review recent advances on\nthe controllability and the control of complex networks, exploring the\nintricate interplay between a system's structure, captured by its network\ntopology, and the dynamical laws that govern the interactions between the\ncomponents. We match the pertinent mathematical results with empirical findings\nand applications. We show that uncovering the control principles of complex\nsystems can help us explore and ultimately understand the fundamental laws that\ngovern their behavior. \n\n"}
{"id": "1508.06686", "contents": "Title: Analysis of multiview legislative networks with structured matrix\n  factorization: Does Twitter influence translate to the real world? Abstract: The rise of social media platforms has fundamentally altered the public\ndiscourse by providing easy to use and ubiquitous forums for the exchange of\nideas and opinions. Elected officials often use such platforms for\ncommunication with the broader public to disseminate information and engage\nwith their constituencies and other public officials. In this work, we\ninvestigate whether Twitter conversations between legislators reveal their\nreal-world position and influence by analyzing multiple Twitter networks that\nfeature different types of link relations between the Members of Parliament\n(MPs) in the United Kingdom and an identical data set for politicians within\nIreland. We develop and apply a matrix factorization technique that allows the\nanalyst to emphasize nodes with contextual local network structures by\nspecifying network statistics that guide the factorization solution. Leveraging\nonly link relation data, we find that important politicians in Twitter networks\nare associated with real-world leadership positions, and that rankings from the\nproposed method are correlated with the number of future media headlines. \n\n"}
{"id": "1509.00888", "contents": "Title: Fourier Phase Retrieval with a Single Mask by Douglas-Rachford Algorithm Abstract: Douglas-Rachford (DR) algorithm is analyzed for Fourier phase retrieval with\na single random phase mask. Local, geometric convergence to a unique fixed\npoint is proved with numerical demonstration of global convergence. \n\n"}
{"id": "1509.01940", "contents": "Title: Robustness and Closeness Centrality for Self-Organized and Planned\n  Cities Abstract: Street networks are important infrastructural transportation systems that\ncover a great part of the planet. It is now widely accepted that transportation\nproperties of street networks are better understood in the interplay between\nthe street network itself and the so called \\textit{information} or\n\\textit{dual network}, which embeds the topology of the street network\nnavigation system. In this work, we present a novel robustness analysis, based\non the interaction between the primal and the dual transportation layer for two\nlarge metropolis, London and Chicago, thus considering the structural\ndifferences to intentional attacks for \\textit{self-organized} and planned\ncities. We elaborate the results through an accurate closeness centrality\nanalysis in the Euclidean space and in the relationship between primal and dual\nspace. Interestingly enough, we find that even if the considered planar graphs\ndisplay very distinct properties, the information space induce them to converge\ntoward systems which are similar in terms of transportation properties. \n\n"}
{"id": "1509.04037", "contents": "Title: Measuring Partial Balance in Signed Networks Abstract: Is the enemy of an enemy necessarily a friend? If not, to what extent does\nthis tend to hold? Such questions were formulated in terms of signed (social)\nnetworks and necessary and sufficient conditions for a network to be \"balanced\"\nwere obtained around 1960. Since then the idea that signed networks tend over\ntime to become more balanced has been widely used in several application areas.\nHowever, investigation of this hypothesis has been complicated by the lack of a\nstandard measure of partial balance, since complete balance is almost never\nachieved in practice. We formalize the concept of a measure of partial balance,\ndiscuss various measures, compare the measures on synthetic datasets, and\ninvestigate their axiomatic properties. The synthetic data involves\nErd\\H{o}s-R\\'enyi and specially structured random graphs. We show that some\nmeasures behave better than others in terms of axioms and ability to\ndifferentiate between graphs. We also use well-known datasets from the\nsociology and biology literature, such as Read's New Guinean tribes, gene\nregulatory networks related to two organisms, and a network involving senate\nbill co-sponsorship. Our results show that substantially different levels of\npartial balance is observed under cycle-based, eigenvalue-based, and\nfrustration-based measures. We make some recommendations for measures to be\nused in future work. \n\n"}
{"id": "1509.04734", "contents": "Title: Information transfer in community structured multiplex networks Abstract: The study of complex networks that account for different types of\ninteractions has become a subject of interest in the last few years, specially\nbecause its representational power in the description of users interactions in\ndiverse online social platforms (Facebook, Twitter, Instagram, etc.). The\nmathematical description of these interacting networks has been coined under\nthe name of multilayer networks, where each layer accounts for a type of\ninteraction. It has been shown that diffusive processes on top of these\nnetworks present a phenomenology that cannot be explained by the naive\nsuperposition of single layer diffusive phenomena but require the whole\nstructure of interconnected layers. Nevertheless, the description of diffusive\nphenomena on multilayer networks has obviated the fact that social networks\nhave strong mesoscopic structure represented by different communities of\nindividuals driven by common interests, or any other social aspect. In this\nwork, we study the transfer of information in multilayer networks with\ncommunity structure. The final goal is to understand and quantify, if the\nexistence of well-defined community structure at the level of individual\nlayers, together with the multilayer structure of the whole network, enhances\nor deteriorates the diffusion of packets of information. \n\n"}
{"id": "1509.07271", "contents": "Title: Predictive implications of Gompertz's law Abstract: Gompertz's law tells us that for humans above the age of 35 the death rate\nincreases exponentially with a doubling time of about 10 years. Here, we show\nthat the same law continues to hold even for ages over 100. Beyond 106 there is\nso far no statistical evidence available because the number of survivors is too\nsmall even in the largest nations. However assuming that Gompertz's law\ncontinues to hold beyond 106, we conclude that the mortality rate becomes equal\nto 1 at age 120 (meaning that there are 1,000 deaths in a population of one\nthousand). In other words, the upper bound of human life is near 120. The\nexistence of this fixed-point has interesting implications. It allows us to\npredict the form of the relationship between death rates at age 35 and the\ndoubling time of Gompertz's law. In order to test this prediction, we first\ncarry out a transversal analysis for a sample of countries comprising both\nindustrialized and developing nations. As further confirmation, we also develop\na longitudinal analysis using historical data over a time period of almost two\ncenturies. Another prediction arising from this fixed-point model, is that,\nabove a given population threshold, the lifespan of the oldest person is\nindependent of the size of her national community. This prediction is supported\nby available empirical evidence. \n\n"}
{"id": "1509.07996", "contents": "Title: Overlapping Community Detection via Local Spectral Clustering Abstract: Large graphs arise in a number of contexts and understanding their structure\nand extracting information from them is an important research area. Early\nalgorithms on mining communities have focused on the global structure, and\noften run in time functional to the size of the entire graph. Nowadays, as we\noften explore networks with billions of vertices and find communities of size\nhundreds, it is crucial to shift our attention from macroscopic structure to\nmicroscopic structure in large networks. A growing body of work has been\nadopting local expansion methods in order to identify the community members\nfrom a few exemplary seed members.\n  In this paper, we propose a novel approach for finding overlapping\ncommunities called LEMON (Local Expansion via Minimum One Norm). The algorithm\nfinds the community by seeking a sparse vector in the span of the local spectra\nsuch that the seeds are in its support. We show that LEMON can achieve the\nhighest detection accuracy among state-of-the-art proposals. The running time\ndepends on the size of the community rather than that of the entire graph. The\nalgorithm is easy to implement, and is highly parallelizable. We further\nprovide theoretical analysis on the local spectral properties, bounding the\nmeasure of tightness of extracted community in terms of the eigenvalues of\ngraph Laplacian.\n  Moreover, given that networks are not all similar in nature, a comprehensive\nanalysis on how the local expansion approach is suited for uncovering\ncommunities in different networks is still lacking. We thoroughly evaluate our\napproach using both synthetic and real-world datasets across different domains,\nand analyze the empirical variations when applying our method to inherently\ndifferent networks in practice. In addition, the heuristics on how the seed set\nquality and quantity would affect the performance are provided. \n\n"}
{"id": "1509.08291", "contents": "Title: The spatial component of R&D networks Abstract: We study the role of geography in R&D networks by means of a quantitative,\nmicro-geographic approach. Using a large database that covers international R&D\ncollaborations from 1984 to 2009, we localize each actor precisely in space\nthrough its latitude and longitude. This allows us to analyze the R&D network\nat all geographic scales simultaneously. Our empirical results show that\ndespite the high importance of the city level, transnational R&D collaborations\nat large distances are much more frequent than expected from similar networks.\nThis provides evidence for the ambiguity of distance in economic cooperation\nwhich is also suggested by the existing literature. In addition we test whether\nthe hypothesis of local buzz and global pipelines applies to the observed R&D\nnetwork by calculating well-defined metrics from network theory. \n\n"}
{"id": "1509.08368", "contents": "Title: Limits of Friendship Networks in Predicting Epidemic Risk Abstract: The spread of an infection on a real-world social network is determined by\nthe interplay of two processes: the dynamics of the network, whose structure\nchanges over time according to the encounters between individuals, and the\ndynamics on the network, whose nodes can infect each other after an encounter.\nPhysical encounter is the most common vehicle for the spread of infectious\ndiseases, but detailed information about encounters is often unavailable\nbecause expensive, unpractical to collect or privacy sensitive. We asks whether\nthe friendship ties between the individuals in a social network successfully\npredict who is at risk. Using a dataset from a popular online review service,\nwe build a time-varying network that is a proxy of physical encounter between\nusers and a static network based on reported friendship. Through computer\nsimulations, we compare infection processes on the resulting networks and show\nthat, whereas distance on the friendship network is correlated to epidemic\nrisk, friendship provides a poor identification of the individuals at risk if\nthe infection is driven by physical encounter. Such limit is not due to the\nrandomness of the infection, but to the structural differences of the two\nnetworks. In contrast to the macroscopic similarity between processes spreading\non different networks, the differences in local connectivity determined by the\ntwo definitions of edges result in striking differences between the dynamics at\na microscopic level. Despite the limits highlighted, we show that periodical\nand relatively infrequent monitoring of the real infection on the encounter\nnetwork allows to correct the predicted infection on the friendship network and\nto achieve satisfactory prediction accuracy. In addition, the friendship\nnetwork contains valuable information to effectively contain epidemic outbreaks\nwhen a limited budget is available for immunization. \n\n"}
{"id": "1510.00074", "contents": "Title: Understanding the variability of daily travel-time expenditures using\n  GPS trajectory data Abstract: Transportation planning is strongly influenced by the assumption that every\nindividual has for his daily mobility a constant daily budget of ~1 hour.\nHowever, recent experimental results are proving this assumption as wrong.\nHere, we study the differences in daily travel-time expenditures among 24\nItalian cities, extracted from a large set of GPS data on vehicles mobility. To\nunderstand these variations at the level of individual behaviour, we introduce\na trip duration model that allows for a description of the distribution of\ntravel-time expenditures in a given city using two parameters. The first\nparameter reflects the accessibility of desired destinations, whereas the\nsecond one can be associated to a travel-time budget and represents\nphysiological limits due to stress and fatigue. Within the same city, we\nobserve variations in the distributions according to home position, number of\nmobility days and a driver's average number of daily trips. These results can\nbe interpreted by a stochastic time-consumption model, where the generalised\ncost of travel times is given by a logarithmic-like function, in agreement with\nthe Weber-Fechner law. Our experimental results show a significant variability\nin the travel-time budgets in different cities and for different categories of\ndrivers within the same city. This explicitly clashes with the idea of the\nexistence of a constant travel-time budget and opens new perspectives for the\nmodeling and governance of urban mobility. \n\n"}
{"id": "1510.01039", "contents": "Title: Dynamical complexity in the perception-based network formation model Abstract: Many link formation mechanisms for the evolution of social networks have been\nsuccessful to reproduce various empirical findings in social networks. However,\nthey have largely ignored the fact that individuals make decisions on whether\nto create links to other individuals based on cost and benefit of linking, and\nthe fact that individuals may use perception of the network in their decision\nmaking. In this paper, we study the evolution of social networks in terms of\nperception-based strategic link formation. Here each individual has her own\nperception of the actual network, and uses it to decide whether to create a\nlink to another individual. An individual with the least perception accuracy\ncan benefit from updating her perception using that of the most accurate\nindividual via a new link. This benefit is compared to the cost of linking in\ndecision making. Once a new link is created, it affects the accuracies of other\nindividuals' perceptions, leading to a further evolution of the actual network.\nAs for initial actual networks, we consider homogeneous and heterogeneous\ncases. The homogeneous initial actual network is modeled by Erd\\H{o}s-R\\'enyi\n(ER) random networks, while we take a star network for the heterogeneous case.\nIn any cases, individual perceptions of the actual network are modeled by ER\nrandom networks with controllable linking probability. Then the stable link\ndensity of the actual network is found to show discontinuous transitions or\njumps according to the cost of linking. As the number of jumps is the\nconsequence of the dynamical complexity, we discuss the effect of initial\nconditions on the number of jumps to find that the dynamical complexity\nstrongly depends on how much individuals initially overestimate or\nunderestimate the link density of the actual network. For the heterogeneous\ncase, the role of the highly connected individual as an information spreader is\ndiscussed. \n\n"}
{"id": "1510.01116", "contents": "Title: Centrality metrics and localization in core-periphery networks Abstract: Two concepts of centrality have been defined in complex networks. The first\nconsiders the centrality of a node and many different metrics for it has been\ndefined (e.g. eigenvector centrality, PageRank, non-backtracking centrality,\netc). The second is related to a large scale organization of the network, the\ncore-periphery structure, composed by a dense core plus an outlying and\nloosely-connected periphery. In this paper we investigate the relation between\nthese two concepts. We consider networks generated via the Stochastic Block\nModel, or its degree corrected version, with a strong core-periphery structure\nand we investigate the centrality properties of the core nodes and the ability\nof several centrality metrics to identify them. We find that the three measures\nwith the best performance are marginals obtained with belief propagation,\nPageRank, and degree centrality, while non-backtracking and eigenvector\ncentrality (or MINRES}, showed to be equivalent to the latter in the large\nnetwork limit) perform worse in the investigated networks. \n\n"}
{"id": "1510.02348", "contents": "Title: A vertex similarity index for better personalized recommendation Abstract: Recommender systems benefit us in tackling the problem of information\noverload by predicting our potential choices among diverse niche objects. So\nfar, a variety of personalized recommendation algorithms have been proposed and\nmost of them are based on similarities, such as collaborative filtering and\nmass diffusion. Here, we propose a novel vertex similarity index named CosRA,\nwhich combines advantages of both the cosine index and the resource-allocation\n(RA) index. By applying the CosRA index to real recommender systems including\nMovieLens, Netflix and RYM, we show that the CosRA-based method has better\nperformance in accuracy, diversity and novelty than some benchmark methods.\nMoreover, the CosRA index is free of parameters, which is a significant\nadvantage in real applications. Further experiments show that the introduction\nof two turnable parameters cannot remarkably improve the overall performance of\nthe CosRA index. \n\n"}
{"id": "1511.04925", "contents": "Title: PageRank in undirected random graphs Abstract: PageRank has numerous applications in information retrieval, reputation\nsystems, machine learning, and graph partitioning.In this paper, we study\nPageRank in undirected random graphs with expansion property. The Chung-Lu\nrandom graph representsan example of such graphs. We show that in the limit, as\nthe size of the graph goes to infinity, PageRank can be represented by a\nmixture of the restart distribution and the vertex degree distribution. \n\n"}
{"id": "1511.05404", "contents": "Title: Prediction in complex systems: the case of the international trade\n  network Abstract: Predicting the future evolution of complex systems is one of the main\nchallenges in complexity science. Based on a current snapshot of a network,\nlink prediction algorithms aim to predict its future evolution. We apply here\nlink prediction algorithms to data on the international trade between\ncountries. This data can be represented as a complex network where links\nconnect countries with the products that they export. Link prediction\ntechniques based on heat and mass diffusion processes are employed to obtain\npredictions for products exported in the future. These baseline predictions are\nimproved using a recent metric of country fitness and product similarity. The\noverall best results are achieved with a newly developed metric of product\nsimilarity which takes advantage of causality in the network evolution. \n\n"}
{"id": "1511.05606", "contents": "Title: Rescue of endemic states in interconnected networks with adaptive\n  coupling Abstract: We study the Susceptible-Infected-Susceptible model of epidemic spreading on\ntwo layers of networks interconnected by adaptive links, which are rewired at\nrandom to avoid contacts between infected and susceptible nodes at the\ninterlayer. We find that the rewiring reduces the effective connectivity for\nthe transmission of the disease between layers, and may even totally decouple\nthe networks. Weak endemic states, in which the epidemics spreads only if the\ntwo layers are interconnected, show a transition from the endemic to the\nhealthy phase when the rewiring overcomes a threshold value that depends on the\ninfection rate, the strength of the coupling and the mean connectivity of the\nnetworks. In the strong endemic scenario, in which the epidemics is able to\nspread on each separate network, the prevalence in each layer decreases when\nincreasing the rewiring, arriving to single network values only in the limit of\ninfinitely fast rewiring. We also find that finite-size effects are amplified\nby the rewiring, as there is a finite probability that the epidemics stays\nconfined in only one network during its lifetime. \n\n"}
{"id": "1511.05797", "contents": "Title: Quantifying the evolution of a scientific topic: reaction of the\n  academic community to the Chornobyl disaster Abstract: We analyze the reaction of academic communities to a particular urgent topic\nwhich abruptly arises as a scientific problem. To this end, we have chosen the\ndisaster that occurred in 1986 in Chornobyl (Chernobyl), Ukraine, considered as\none of the most devastating nuclear power plant accidents in history. The\nacademic response is evaluated using scientific-publication data concerning the\ndisaster using the Scopus database to present the picture on an international\nscale and the bibliographic database \"Ukrainika naukova\" to consider it on a\nnational level. We measured distributions of papers in different scientific\nfields, their growth rates and properties of co-authorship networks. {The\nelements of descriptive statistics and the tools of the complex network theory\nare used to highlight the interdisciplinary as well as international effects.}\nOur analysis allows to compare contributions of the international community to\nChornobyl-related research as well as integration of Ukraine in the\ninternational research on this subject. Furthermore, the content analysis of\ntitles and abstracts of the publications allowed to detect the most important\nterms used for description of Chornobyl-related problems. \n\n"}
{"id": "1511.06729", "contents": "Title: Simple and efficient self-healing strategy for damaged complex networks Abstract: The process of destroying a complex network through node removal has been the\nsubject of extensive interest and research. Node loss typically leaves the\nnetwork disintegrated into many small and isolated clusters. Here we show that\nthese clusters typically remain close to each other and we suggest a simple\nalgorithm that is able to reverse the inflicted damage by restoring the\nnetwork's functionality. After damage, each node decides independently whether\nto create a new link depending on the fraction of neighbors it has lost. In\naddition to relying only on local information, where nodes do not need\nknowledge of the global network status, we impose the additional constraint\nthat new links should be as short as possible (i.e. that the new edge completes\na shortest possible new cycle). We demonstrate that this self-healing method\noperates very efficiently, both in model and real networks. For example, after\nremoving the most connected airports in USA, the self-healing algorithm\nre-joined almost 90\\% of the surviving airports. \n\n"}
{"id": "1511.08974", "contents": "Title: Quantum Weiss-Weinstein bounds for quantum metrology Abstract: Sensing and imaging are among the most important applications of quantum\ninformation science. To investigate their fundamental limits and the\npossibility of quantum enhancements, researchers have for decades relied on the\nquantum Cram\\'er-Rao lower error bounds pioneered by Helstrom. Recent work,\nhowever, has called into question the tightness of those bounds for highly\nnonclassical states in the non-asymptotic regime, and better methods are now\nneeded to assess the attainable quantum limits in reality. Here we propose a\nnew class of quantum bounds called quantum Weiss-Weinstein bounds, which\ninclude Cram\\'er-Rao-type inequalities as special cases but can also be\nsignificantly tighter to the attainable error. We demonstrate the superiority\nof our bounds through the derivation of a Heisenberg limit and phase-estimation\nexamples. \n\n"}
{"id": "1511.09449", "contents": "Title: Two Universality Properties Associated with the Monkey Model of Zipf's\n  Law Abstract: The distribution of word probabilities in the monkey model of Zipf's law is\nassociated with two universality properties: (1) the power law exponent\nconverges strongly to $-1$ as the alphabet size increases and the letter\nprobabilities are specified as the spacings from a random division of the unit\ninterval for any distribution with a bounded density function on $[0,1]$; and\n(2), on a logarithmic scale the version of the model with a finite word length\ncutoff and unequal letter probabilities is approximately normally distributed\nin the part of the distribution away from the tails. The first property is\nproved using a remarkably general limit theorem for the logarithm of sample\nspacings from Shao and Hahn, and the second property follows from Anscombe's\ncentral limit theorem for a random number of i.i.d. random variables. The\nfinite word length model leads to a hybrid Zipf-lognormal mixture distribution\nclosely related to work in other areas. \n\n"}
{"id": "1512.02014", "contents": "Title: Temporal Dynamics of Connectivity and Epidemic Properties of Growing\n  Networks Abstract: Traditional mathematical models of epidemic disease had for decades\nconventionally considered static structure for contacts. Recently, an upsurge\nof theoretical inquiry has strived towards rendering the models more realistic\nby incorporating the temporal aspects of networks of contacts, societal and\nonline, that are of interest in the study of epidemics (and other similar\ndiffusion processes). However, temporal dynamics have predominantly focused on\nlink fluctuations and nodal activities, and less attention has been paid to the\ngrowth of the underlying network. Many real networks grow: online networks are\nevidently in constant growth, and societal networks can grow due to migration\nflux and reproduction. The effect of network growth on the epidemic properties\nof networks is hitherto unknown---mainly due to the predominant focus of the\nnetwork growth literature on the so-called steady-state. This paper takes a\nstep towards alleviating this gap. We analytically study the degree dynamics of\na given arbitrary network that is subject to growth. We use the theoretical\nfindings to predict the epidemic properties of the network as a function of\ntime. We observe that the introduction of new individuals into the network can\nenhance or diminish its resilience against endemic outbreaks, and investigate\nhow this regime shift depends upon the connectivity of newcomers and on how\nthey establish connections to existing nodes. Throughout, theoretical findings\nare corroborated with Monte Carlo simulations over synthetic and real networks.\nThe results shed light on the effects of network growth on the future epidemic\nproperties of networks, and offers insights for devising a-priori immunization\nstrategies. \n\n"}
{"id": "1512.02454", "contents": "Title: The double role of GDP in shaping the structure of the International\n  Trade Network Abstract: The International Trade Network (ITN) is the network formed by trade\nrelationships between world countries. The complex structure of the ITN impacts\nimportant economic processes such as globalization, competitiveness, and the\npropagation of instabilities. Modeling the structure of the ITN in terms of\nsimple macroeconomic quantities is therefore of paramount importance. While\ntraditional macroeconomics has mainly used the Gravity Model to characterize\nthe magnitude of trade volumes, modern network theory has predominantly focused\non modeling the topology of the ITN. Combining these two complementary\napproaches is still an open problem. Here we review these approaches and\nemphasize the double role played by GDP in empirically determining both the\nexistence and the volume of trade linkages. Moreover, we discuss a unified\nmodel that exploits these patterns and uses only the GDP as the relevant\nmacroeconomic factor for reproducing both the topology and the link weights of\nthe ITN. \n\n"}
{"id": "1512.02577", "contents": "Title: Model selection for identifying power-law scaling Abstract: Long-range temporal and spatial correlations have been reported in a\nremarkable number of studies. In particular power-law scaling in neural\nactivity raised considerable interest. We here provide a straightforward\nalgorithm not only to quantify power-law scaling but to test it against\nalternatives using (Bayesian) model comparison. Our algorithm builds on the\nwell-established detrended fluctuation analysis (DFA). After removing trends of\na signal, we determine its mean squared fluctuations in consecutive intervals.\nIn contrast to DFA we use the values per interval to approximate the\ndistribution of these mean squared fluctuations. This allows for estimating the\ncorresponding log-likelihood as a function of interval size without presuming\nthe fluctuations to be normally distributed, as is the case in conventional\nDFA. We demonstrate the validity and robustness of our algorithm using a\nvariety of simulated signals, ranging from scale-free fluctuations with known\nHurst exponents, via more conventional dynamical systems resembling\nexponentially correlated fluctuations, to a toy model of neural mass activity.\nWe also illustrate its use for encephalographic signals. We further discuss\nconfounding factors like the finite signal size. Our model comparison provides\na proper means to identify power-law scaling including the range over which it\nis present. \n\n"}
{"id": "1512.02859", "contents": "Title: The network structure of city-firm relations Abstract: How are economic activities linked to geographic locations? To answer this\nquestion, we use a data-driven approach that builds on the information about\nlocation, ownership and economic activities of the world's 3,000 largest firms\nand their almost one million subsidiaries. From this information we generate a\nbipartite network of cities linked to economic activities. Analysing the\nstructure of this network, we find striking similarities with nested networks\nobserved in ecology, where links represent mutualistic interactions between\nspecies. This motivates us to apply ecological indicators to identify the\nunbalanced deployment of economic activities. Such deployment can lead to an\nover-representation of specific economic sectors in a given city, and poses a\nsignificant thread for the city's future especially in times when the\nover-represented activities face economic uncertainties. If we compare our\nanalysis with external rankings about the quality of life in a city, we find\nthat the nested structure of the city-firm network also reflects such\ninformation about the quality of life, which can usually be assessed only via\ndedicated survey-based indicators. \n\n"}
{"id": "1512.05386", "contents": "Title: \"Social Laser\": Action Amplification by Stimulated Emission of Social\n  Energy Abstract: The problem of the \"explanation\" of recent social explosions, especially in\nthe Middle East, but also in Southern Europe and the USA, have been debated\nactively in the social and political literature. We can mention the\ncontributions of P. Mason, F. Fukuyama, E. Schmidt and J. Cohen, I. Krastev to\nthis debate. We point out that the diversity of opinions and conclusions is\nreally amazing. At the moment, there is no consistent and commonly acceptable\ntheory of these phenomena. We present a model of social explosions based on a\nnovel approach for the description of social processes, namely, the\nquantum-like approach. Here quantum theory is treated simply as an operational\nformalism - without any direct relation to physics. We explore the quantum-like\nlaser model to describe the possibility of Action Amplification by Stimulated\nEmission of Social Energy (ASE). \n\n"}
{"id": "1512.05935", "contents": "Title: Two-loop calculation of anomalous kinetics of the reaction $A + A\n  \\rightarrow\\varnothing$ in randomly stirred fluid Abstract: The single-species annihilation reaction $A + A \\rightarrow\\varnothing$ is\nstudied in the presence of a random velocity field generated by the stochastic\nNavier-Stokes equation. The renormalization group is used to analyze the\ncombined influence of the density and velocity fluctuations on the long-time\nbehavior of the system. The direct effect of velocity fluctuations on the\nreaction constant appears only from the two- loop order, therefore all stable\nfixed points of the renormalization group and their regions of stability are\ncalculated in the two-loop approximation in the two-parameter $(\\epsilon,\n\\Delta)$ expansion. A renormalized integro- differential equation for the\nnumber density is put forward which takes into account the effect of density\nand velocity fluctuations at next-to-leading order. Solution of this equation\nin perturbation theory is calculated in a homogeneous system. \n\n"}
{"id": "1512.06108", "contents": "Title: Generalized R\\'enyi Entropy and Structure Detection of Complex Dynamical\n  Systems Abstract: We study the problem of detecting the structure of a complex dynamical system\ndescribed by a set of deterministic differential equation that contains a\nHamiltonian subsystem, without any information on the explicit form of\nevolution laws. We suppose that initial conditions are random and the initial\nconditions of the Hamiltonian subsystem are independent from the initial\nconditions of the rest of the system. The single numerical information is the\nprobability density function of the system at one or several, finite number of\ntime instants. In the framework of the formalism of the generalized R\\'{e}nyi\nentropy we find necessary and sufficient conditions that the back reaction of\nthe Hamiltonian subsystem to the rest of the system is negligible.The results\ncan be easily generalized to the case of general, measure preserving subsystem. \n\n"}
{"id": "1512.06929", "contents": "Title: Facility Deployment Decisions through Warp Optimizaton of Regressed\n  Gaussian Processes Abstract: A method for quickly determining deployment schedules that meet a given fuel\ncycle demand is presented here. This algorithm is fast enough to perform in\nsitu within low-fidelity fuel cycle simulators. It uses Gaussian process\nregression models to predict the production curve as a function of time and the\nnumber of deployed facilities. Each of these predictions is measured against\nthe demand curve using the dynamic time warping distance. The minimum distance\ndeployment schedule is evaluated in a full fuel cycle simulation, whose\ngenerated production curve then informs the model on the next optimization\niteration. The method converges within five to ten iterations to a distance\nthat is less than one percent of the total deployable production. A\nrepresentative once-through fuel cycle is used to demonstrate the methodology\nfor reactor deployment. \n\n"}
{"id": "1512.09074", "contents": "Title: Bias, Belief and Consensus: Collective opinion formation on fluctuating\n  networks Abstract: With the advent of online networks, societies are substantially more\nconnected with individual members able to easily modify and maintain their own\nsocial links. Here, we show that active network maintenance exposes agents to\nconfirmation bias, the tendency to confirm one's beliefs, and we explore how\nthis affects collective opinion formation. We introduce a model of binary\nopinion dynamics on a complex network with fast, stochastic rewiring and show\nthat confirmation bias induces a segregation of individuals with different\nopinions. We use the dynamics of global opinion to generally categorize opinion\nupdate rules and find that confirmation bias always stabilizes the consensus\nstate. Finally, we show that the time to reach consensus has a non-monotonic\ndependence on the magnitude of the bias, suggesting a novel avenue for\nlarge-scale opinion engineering. \n\n"}
{"id": "1601.00963", "contents": "Title: Identifying System-Wide Early Warning Signs of Instability in Stochastic\n  Power Systems Abstract: Prior research has shown that spectral decomposition of the reduced power\nflow Jacobian (RPFJ) can yield participation factors that describe the extent\nto which particular buses contribute to particular spectral components of a\npower system. Research has also shown that both variance and autocorrelation of\ntime series voltage data tend to increase as a power system with stochastically\nfluctuating loads approaches certain critical transitions. This paper presents\nevidence suggesting that a system's participation factors predict the relative\nbus voltage variance values for all nodes in a system. As a result, these\nparticipation factors can be used to filter, weight, and combine real time PMU\ndata from various locations dispersed throughout a power network in order to\ndevelop coherent measures of global voltage stability. This paper first\ndescribes the method of computing the participation factors. Next, two\npotential uses of the participation factors are given: (1) predicting the\nrelative bus voltage variance magnitudes, and (2) locating generators at which\nthe autocorrelation of voltage measurements clearly indicate proximity to\ncritical transitions. The methods are tested using both analytical and\nnumerical results from a dynamic model of a 2383-bus test case. \n\n"}
{"id": "1601.01465", "contents": "Title: Maximum Leaf Spanning Trees of Growing Sierpinski Networks Models Abstract: The dynamical phenomena of complex networks are very difficult to predict\nfrom local information due to the rich microstructures and corresponding\ncomplex dynamics. On the other hands, it is a horrible job to compute some\nstochastic parameters of a large network having thousand and thousand nodes. We\ndesign several recursive algorithms for finding spanning trees having maximal\nleaves (MLS-trees) in investigation of topological structures of Sierpinski\ngrowing network models, and use MLS-trees to determine the kernels, dominating\nand balanced sets of the models. We propose a new stochastic method for the\nmodels, called the edge-cumulative distribution, and show that it obeys a power\nlaw distribution. \n\n"}
{"id": "1601.02808", "contents": "Title: Non-Thermal Transitions in n-th Order Moral Decisions Abstract: This work introduces a model in which agents of a network act upon one\nanother according to three different kinds of moral decisions. These decisions\nare based on an increasing level of sophistication in the empathy capacity of\nthe agent, a hierarchy which we name Piaget's Ladder. The decision strategy of\nthe agents is non-rational, in the sense that it does not minimize model's\nHamiltonian, and the model presents quenched disorder given by the distribution\nof its defining parameters. We obtain an analytical solution for this model in\nthe thermodynamic limit and also a leading order correction for finite sized\nsystems. Using these results, we show that typical realizations develop a rich\nphase structure with discontinuous non-thermal transitions. \n\n"}
{"id": "1601.03226", "contents": "Title: Strong subadditivity for log-determinant of covariance matrices and its\n  applications Abstract: We prove that the log-determinant of the covariance matrix obeys the strong\nsubadditivity inequality for arbitrary tripartite states of multimode\ncontinuous variable quantum systems. This establishes general limitations on\nthe distribution of information encoded in the second moments of canonically\nconjugate operators. The inequality is shown to be stronger than the\nconventional strong subadditivity inequality for von Neumann entropy in a class\nof pure tripartite Gaussian states. We finally show that such an inequality\nimplies a strict monogamy-type constraint for joint Einstein-Podolsky-Rosen\nsteerability of single modes by Gaussian measurements performed on multiple\ngroups of modes. \n\n"}
{"id": "1601.05532", "contents": "Title: Global multi-layer network of human mobility Abstract: Recent availability of geo-localized data capturing individual human activity\ntogether with the statistical data on international migration opened up\nunprecedented opportunities for a study on global mobility. In this paper we\nconsider it from the perspective of a multi-layer complex network, built using\na combination of three datasets: Twitter, Flickr and official migration data.\nThose datasets provide different but equally important insights on the global\nmobility: while the first two highlight short-term visits of people from one\ncountry to another, the last one - migration - shows the long-term mobility\nperspective, when people relocate for good. And the main purpose of the paper\nis to emphasize importance of this multi-layer approach capturing both aspects\nof human mobility at the same time. So we start from a comparative study of the\nnetwork layers, comparing short- and long- term mobility through the\nstatistical properties of the corresponding networks, such as the parameters of\ntheir degree centrality distributions or parameters of the corresponding\ngravity model being fit to the network. We also focus on the differences in\ncountry ranking by their short- and long-term attractiveness, discussing the\nmost noticeable outliers. Finally, we apply this multi-layered human mobility\nnetwork to infer the structure of the global society through a community\ndetection approach and demonstrate that consideration of mobility from a\nmulti-layer perspective can reveal important global spatial patterns in a way\nmore consistent with other available relevant sources of international\nconnections, in comparison to the spatial structure inferred from each network\nlayer taken separately. \n\n"}
{"id": "1601.07586", "contents": "Title: Dynamic communicability and epidemic spread: a case study on an\n  empirical dynamic contact network Abstract: We analyze a recently proposed temporal centrality measure applied to an\nempirical network based on person-to-person contacts in an emergency department\nof a busy urban hospital. We show that temporal centrality identifies a\ndistinct set of top-spreaders than centrality based on the time-aggregated\nbinarized contact matrix, so that taken together, the accuracy of capturing\ntop-spreaders improves significantly. However, with respect to predicting\nepidemic outcome, the temporal measure does not necessarily outperform less\ncomplex measures. Our results also show that other temporal markers such as\nduration observed and the time of first appearance in the the network can be\nused in a simple predictive model to generate predictions that capture the\ntrend of the observed data remarkably well. \n\n"}
{"id": "1602.00078", "contents": "Title: Latent common manifold learning with alternating diffusion: analysis and\n  applications Abstract: The analysis of data sets arising from multiple sensors has drawn significant\nresearch attention over the years. Traditional methods, including kernel-based\nmethods, are typically incapable of capturing nonlinear geometric structures.\nWe introduce a latent common manifold model underlying multiple sensor\nobservations for the purpose of multimodal data fusion. A method based on\nalternating diffusion is presented and analyzed; we provide theoretical\nanalysis of the method under the latent common manifold model. To exemplify the\npower of the proposed framework, experimental results in several applications\nare reported. \n\n"}
{"id": "1602.00667", "contents": "Title: Emergence of core-peripheries in networks Abstract: A number of important transport networks, such as the airline and trade\nnetworks of the world, exhibit a characteristic core-periphery structure,\nwherein a few nodes are highly interconnected and the rest of the network frays\ninto a tree. Mechanisms underlying the emergence of core-peripheries, however,\nremain elusive. Here, we demonstrate that a simple pruning process based on\nremoval of underutilized links and redistribution of loads can lead to the\nemergence of core-peripheries. Links are assumed beneficial if they either\ncarry a sufficiently large load or are essential for global connectivity. This\nincentivized redistribution process is controlled by a single parameter which\nbalances connectivity and profit. The obtained networks exhibit a highly\nresilient and connected core with a frayed periphery. The balanced network\nshows a higher resilience than the World Airline Network or the World Trade\nNetwork, revealing a pathway towards robust structural features through\npruning. \n\n"}
{"id": "1602.01211", "contents": "Title: A Fractional Micro-Macro Model for Crowds of Pedestrians based on\n  Fractional Mean Field Games Abstract: Modeling of crowds of pedestrians has been considered in this paper from\ndifferent aspects. Based on fractional microscopic model that may be much more\nclose to reality, a fractional macroscopic model has been proposed using\nconservation law of mass. Then in order to characterize the competitive and\ncooperative interactions among pedestrians, fractional mean field games are\nutilized in the modeling problem when the number of pedestrians goes to\ninfinity and fractional dynamic model composed of fractional backward and\nfractional forward equations are constructed in macro scale. Fractional\nmicro-macro model for crowds of pedestrians are obtained in the end. Simulation\nresults are also included to illustrate the proposed fractional microscopic\nmodel and fractional macroscopic model respectively. \n\n"}
{"id": "1602.01693", "contents": "Title: Thermodynamic aspects of information transfer in complex dynamical\n  systems Abstract: From the Horowitz-Esposito stochastic thermodynamical description of\ninformation flows in dynamical systems [J. M. Horowitz and M. Esposito, Phys.\nRev. X4, 031015 (2014)], it is known that while the second law of\nthermodynamics is satisfied by a joint system, the entropic balance for the\nsubsystems is adjusted by a term related to the mutual information exchange\nrate between the two subsystems. In this article, we present a quantitative\ndiscussion of the conceptual link between the Horowitz-Esposito analysis and\nthe Liang-Kleeman work on information transfer between dynamical system\ncomponents [X. S. Liang and R. Kleeman, Phys. Rev. Lett. 95, 244101 (2005)]. In\nparticular, the entropic balance arguments employed in the two approaches are\ncompared. Notwithstanding all differences between the two formalisms, our work\nstrengthens the Liang-Kleeman heuristic balance reasoning by showing its formal\nanalogy with the recent Horowitz-Esposito thermodynamic balance arguments. \n\n"}
{"id": "1602.03807", "contents": "Title: Variational Inference for Sparse and Undirected Models Abstract: Undirected graphical models are applied in genomics, protein structure\nprediction, and neuroscience to identify sparse interactions that underlie\ndiscrete data. Although Bayesian methods for inference would be favorable in\nthese contexts, they are rarely used because they require doubly intractable\nMonte Carlo sampling. Here, we develop a framework for scalable Bayesian\ninference of discrete undirected models based on two new methods. The first is\nPersistent VI, an algorithm for variational inference of discrete undirected\nmodels that avoids doubly intractable MCMC and approximations of the partition\nfunction. The second is Fadeout, a reparameterization approach for variational\ninference under sparsity-inducing priors that captures a posteriori\ncorrelations between parameters and hyperparameters with noncentered\nparameterizations. We find that, together, these methods for variational\ninference substantially improve learning of sparse undirected graphical models\nin simulated and real problems from physics and biology. \n\n"}
{"id": "1602.05530", "contents": "Title: Extreme robustness of scaling in sample space reducing processes\n  explains Zipf's law in diffusion on directed networks Abstract: It has been shown recently that a specific class of path-dependent stochastic\nprocesses, which reduce their sample space as they unfold, lead to exact\nscaling laws in frequency and rank distributions. Such Sample Space Reducing\nprocesses (SSRP) offer an alternative new mechanism to understand the emergence\nof scaling in countless processes. The corresponding power law exponents were\nshown to be related to noise levels in the process. Here we show that the\nemergence of scaling is not limited to the simplest SSRPs, but holds for a huge\ndomain of stochastic processes that are characterized by non-uniform prior\ndistributions. We demonstrate mathematically that in the absence of noise the\nscaling exponents converge to $-1$ (Zipf's law) for almost all prior\ndistributions. As a consequence it becomes possible to fully understand\ntargeted diffusion on weighted directed networks and its associated scaling\nlaws law in node visit distributions. The presence of cycles can be properly\ninterpreted as playing the same role as noise in SSRPs and, accordingly,\ndetermine the scaling exponents. The result that Zipf's law emerges as a\ngeneric feature of diffusion on networks, regardless of its details, and that\nthe exponent of visiting times is related to the amount of cycles in a network\ncould be relevant for a series of applications in traffic-, transport- and\nsupply chain management. \n\n"}
{"id": "1602.07479", "contents": "Title: Particle-Time Duality in the Kicked Ising Chain II: Applications to the\n  Spectrum Abstract: Previously, we demonstrated that the dynamics of kicked spin chains possess a\nremarkable duality property. The trace of the unitary evolution operator for\n$N$ spins at time $T$ is related to one of a non-unitary evolution operator for\n$T$ spins at time $N$. Using this duality relation we obtain the oscillating\npart of the density of states for a large number of spins. Furthermore, the\nduality relation explains the anomalous short-time behavior of the spectral\nform factor previously observed in the literature. \n\n"}
{"id": "1602.08451", "contents": "Title: Ground truth? Concept-based communities versus the external\n  classification of physics manuscripts Abstract: Community detection techniques are widely used to infer hidden structures\nwithin interconnected systems. Despite demonstrating high accuracy on\nbenchmarks, they reproduce the external classification for many real-world\nsystems with a significant level of discrepancy. A widely accepted reason\nbehind such outcome is the unavoidable loss of non-topological information\n(such as node attributes) encountered when the original complex system is\nrepresented as a network. In this article we emphasize that the observed\ndiscrepancies may also be caused by a different reason: the external\nclassification itself. For this end we use scientific publication data which i)\nexhibit a well defined modular structure and ii) hold an expert-made\nclassification of research articles. Having represented the articles and the\nextracted scientific concepts both as a bipartite network and as its unipartite\nprojection, we applied modularity optimization to uncover the inner thematic\nstructure. The resulting clusters are shown to partly reflect the author-made\nclassification, although some significant discrepancies are observed. A\ndetailed analysis of these discrepancies shows that they carry essential\ninformation about the system, mainly related to the use of similar techniques\nand methods across different (sub)disciplines, that is otherwise omitted when\nonly the external classification is considered. \n\n"}
{"id": "1603.00621", "contents": "Title: Incompatibility boundaries for properties of community partitions Abstract: We prove the incompatibility of certain desirable properties of community\npartition quality functions. Our results generalize the impossibility result of\n[Kleinberg 2003] by considering sets of weaker properties. In particular, we\nuse an alternative notion to solve the central issue of the consistency\nproperty. (The latter means that modifying the graph in a way consistent with a\npartition should not have counterintuitive effects). Our results clearly show\nthat community partition methods should not be expected to perfectly satisfy\nall ideally desired properties.\n  We then proceed to show that this incompatibility no longer holds when\nslightly relaxed versions of the properties are considered, and we provide in\nfact examples of simple quality functions satisfying these relaxed properties.\nAn experimental study of these quality functions shows a behavior comparable to\nestablished methods in some situations, but more debatable results in others.\nThis suggests that defining a notion of good partition in communities probably\nrequires imposing additional properties. \n\n"}
{"id": "1603.02135", "contents": "Title: Non-Equilibrium Thermodynamics and Stochasticity, A Phenomenological\n  Look on Jarzynki's Equality Abstract: The theory of phenomenological Non-equilibrium Thermodynamics is extended by\nincludimg stochastic processes in order to account for recently derived\nthermodynamical relations such as the Jarzynski equality. Four phenomenological\naxioms are postulated resulting in a phenomenological interpretation of\nJarzynski's equality. Especially, considering the class of Jarzynski processes\nJarzynski's equality follows from the axiom that the statistical average of the\nexponential work is protocol independent. \n\n"}
{"id": "1603.05859", "contents": "Title: Emergence of event cascades in inhomogeneous networks Abstract: There is a commonality among contagious diseases, tweets, urban crimes,\nnuclear reactions, and neuronal firings that past events facilitate the future\noccurrence of events. The spread of events has been extensively studied such\nthat the systems exhibit catastrophic chain reactions if the interaction\nrepresented by the ratio of reproduction exceeds unity; however, their\nsubthreshold states for the case of the weaker interaction are not fully\nunderstood. Here, we report that these systems are possessed by nonstationary\ncascades of event-occurrences already in the subthreshold regime. Event\ncascades can be harmful in some contexts, when the peak-demand causes vaccine\nshortages, heavy traffic on communication lines, frequent crimes, or large\nfluctuations in nuclear reactions, but may be beneficial in other contexts,\nsuch that spontaneous activity in neural networks may be used to generate\nmotion or store memory. Thus it is important to comprehend the mechanism by\nwhich such cascades appear, and consider controlling a system to tame or\nfacilitate fluctuations in the event-occurrences. The critical interaction for\nthe emergence of cascades depends greatly on the network structure in which\nindividuals are connected. We demonstrate that we can predict whether cascades\nmay emerge in a network, given information about the interactions between\nindividuals. Furthermore, we develop a method of reallocating connections among\nindividuals so that event cascades may be either impeded or impelled in a\nnetwork. \n\n"}
{"id": "1603.06240", "contents": "Title: Numerical Stability of Generalized Entropies Abstract: In many applications, the probability density function is subject to\nexperimental errors. In this work the continuos dependence of a class of\ngeneralized entropies on the experimental errors is studied. This class\nincludes the C. Shannon, C. Tsallis, A. R\\'{e}nyi and generalized R\\'{e}nyi\nentropies. By using the connection between R\\'{e}nyi or Tsallis entropies, and\nthe \\textit{distance} in a the Lebesgue functional spaces, we introduce a\nfurther extensive generalizations of the R\\'{e}nyi entropy. In this work we\nsuppose that the experimental error is measured by some generalized $L^{p}$\ndistance. In line with the methodology normally used for treating the so called\n\\textit{ill-posed problems}, auxiliary stabilizing conditions are determined,\nsuch that small - in the sense of $L^{p}$ metric - experimental errors provoke\nsmall variations of the classical and generalized entropies. These stabilizing\nconditions are formulated in terms of $L^{p}$ metric in a class of generalized\n$L^{p}$ spaces of functions. Shannon's entropy requires, however, more\nrestrictive stabilizing conditions. \n\n"}
{"id": "1604.00255", "contents": "Title: Network structure, metadata and the prediction of missing nodes and\n  annotations Abstract: The empirical validation of community detection methods is often based on\navailable annotations on the nodes that serve as putative indicators of the\nlarge-scale network structure. Most often, the suitability of the annotations\nas topological descriptors itself is not assessed, and without this it is not\npossible to ultimately distinguish between actual shortcomings of the community\ndetection algorithms on one hand, and the incompleteness, inaccuracy or\nstructured nature of the data annotations themselves on the other. In this work\nwe present a principled method to access both aspects simultaneously. We\nconstruct a joint generative model for the data and metadata, and a\nnonparametric Bayesian framework to infer its parameters from annotated\ndatasets. We assess the quality of the metadata not according to its direct\nalignment with the network communities, but rather in its capacity to predict\nthe placement of edges in the network. We also show how this feature can be\nused to predict the connections to missing nodes when only the metadata is\navailable, as well as missing metadata. By investigating a wide range of\ndatasets, we show that while there are seldom exact agreements between metadata\ntokens and the inferred data groups, the metadata is often informative of the\nnetwork structure nevertheless, and can improve the prediction of missing\nnodes. This shows that the method uncovers meaningful patterns in both the data\nand metadata, without requiring or expecting a perfect agreement between the\ntwo. \n\n"}
{"id": "1604.00963", "contents": "Title: Dynamical leaps due to microscopic changes in multiplex networks Abstract: Recent developments of the multiplex paradigm included efforts to understand\nthe role played by the presence of several layers on the dynamics of processes\nrunning on these networks. The possible existence of new phenomena associated\nto the richer topology has been discussed and examples of these differences\nhave been systematically searched. Here, we show that the interconnectivity of\nthe layers may have an important impact on the speed of the dynamics run in the\nnetwork and that microscopic changes such as the addition of one single\ninter-layer link can notably affect the arrival at a global stationary state.\nAs a practical verification, these results obtained with spectral techniques\nare confirmed with a Kuramoto dynamics for which the synchronization\nconsistently delays after the addition of single inter-layer links. \n\n"}
{"id": "1604.01004", "contents": "Title: Least square estimation of phase, frequency and PDEV Abstract: The Omega-preprocessing was introduced to improve phase noise rejection by\nusing a least square algorithm. The associated variance is the PVAR which is\nmore efficient than MVAR to separate the different noise types. However, unlike\nAVAR and MVAR, the decimation of PVAR estimates for multi-tau analysis is not\npossible if each counter measurement is a single scalar. This paper gives a\ndecimation rule based on two scalars, the processing blocks, for each\nmeasurement. For the Omega-preprocessing, this implies the definition of an\noutput standard as well as hardware requirements for performing high-speed\ncomputations of the blocks. \n\n"}
{"id": "1604.01125", "contents": "Title: Measuring burstiness for finite event sequences Abstract: Characterizing inhomogeneous temporal patterns in natural and social\nphenomena is important to understand underlying mechanisms behind such complex\nsystems, hence even to predict and control them. Temporal inhomogeneities in\nevent sequences have been described in terms of bursts that are rapidly\noccurring events in short time periods alternating with long inactive periods.\nThe bursts can be quantified by a simple measure, called burstiness parameter,\nwhich was introduced by Goh and Barab\\'asi [EPL \\textbf{81}, 48002 (2008)]. The\nburstiness parameter has been widely used due to its simplicity, which however\nturns out to be strongly affected by the finite number of events in the time\nseries. As the finite-size effects on burstiness parameter have been largely\nignored, we analytically investigate the finite-size effects of the burstiness\nparameter. Then we suggest an alternative definition of burstiness that is free\nfrom finite-size effects and yet simple. Using our alternative burstiness\nmeasure, one can distinguish the finite-size effects from the intrinsic bursty\nproperties in the time series. We also demonstrate the advantages of our\nburstiness measure by analyzing empirical datasets. \n\n"}
{"id": "1604.01170", "contents": "Title: Accurate and scalable social recommendation using mixed-membership\n  stochastic block models Abstract: With ever-increasing amounts of online information available, modeling and\npredicting individual preferences-for books or articles, for example-is\nbecoming more and more important. Good predictions enable us to improve advice\nto users, and obtain a better understanding of the socio-psychological\nprocesses that determine those preferences. We have developed a collaborative\nfiltering model, with an associated scalable algorithm, that makes accurate\npredictions of individuals' preferences. Our approach is based on the explicit\nassumption that there are groups of individuals and of items, and that the\npreferences of an individual for an item are determined only by their group\nmemberships. Importantly, we allow each individual and each item to belong\nsimultaneously to mixtures of different groups and, unlike many popular\napproaches, such as matrix factorization, we do not assume implicitly or\nexplicitly that individuals in each group prefer items in a single group of\nitems. The resulting overlapping groups and the predicted preferences can be\ninferred with a expectation-maximization algorithm whose running time scales\nlinearly (per iteration). Our approach enables us to predict individual\npreferences in large datasets, and is considerably more accurate than the\ncurrent algorithms for such large datasets. \n\n"}
{"id": "1604.04811", "contents": "Title: Using Text Similarity to Detect Social Interactions not Captured by\n  Formal Reply Mechanisms Abstract: In modeling social interaction online, it is important to understand when\npeople are reacting to each other. Many systems have explicit indicators of\nreplies, such as threading in discussion forums or replies and retweets in\nTwitter. However, it is likely these explicit indicators capture only part of\npeople's reactions to each other, thus, computational social science approaches\nthat use them to infer relationships or influence are likely to miss the mark.\nThis paper explores the problem of detecting non-explicit responses, presenting\na new approach that uses tf-idf similarity between a user's own tweets and\nrecent tweets by people they follow. Based on a month's worth of posting data\nfrom 449 ego networks in Twitter, this method demonstrates that it is likely\nthat at least 11% of reactions are not captured by the explicit reply and\nretweet mechanisms. Further, these uncaptured reactions are not evenly\ndistributed between users: some users, who create replies and retweets without\nusing the official interface mechanisms, are much more responsive to followees\nthan they appear. This suggests that detecting non-explicit responses is an\nimportant consideration in mitigating biases and building more accurate models\nwhen using these markers to study social interaction and information diffusion. \n\n"}
{"id": "1604.05521", "contents": "Title: Simple and accurate analytical calculation of shortest path lengths Abstract: We present an analytical approach to calculating the distribution of shortest\npaths lengths (also called intervertex distances, or geodesic paths) between\nnodes in unweighted undirected networks. We obtain very accurate results for\nsynthetic random networks with specified degree distribution (the so-called\nconfiguration model networks). Our method allows us to accurately predict the\ndistribution of shortest path lengths on real-world networks using their degree\ndistribution, or joint degree-degree distribution. Compared to some other\nmethods, our approach is simpler and yields more accurate results. In order to\nobtain the analytical results, we use the analogy between an infection reaching\na node in $n$ discrete time steps (i.e., as in the susceptible-infected\nepidemic model) and that node being at a distance $n$ from the source of the\ninfection. \n\n"}
{"id": "1605.00086", "contents": "Title: Fractional Brownian motion time-changed by gamma and inverse gamma\n  process Abstract: Many real time-series exhibit behavior adequate to long range dependent data.\nAdditionally very often these time-series have constant time periods and also\nhave characteristics similar to Gaussian processes although they are not\nGaussian. Therefore there is need to consider new classes of systems to model\nthese kind of empirical behavior. Motivated by this fact in this paper we\nanalyze two processes which exhibit long range dependence property and have\nadditional interesting characteristics which may be observed in real phenomena.\nBoth of them are constructed as the superposition of fractional Brownian motion\n(FBM) and other process. In the first case the internal process, which plays\nrole of the time, is the gamma process while in the second case the internal\nprocess is its inverse. We present in detail their main properties paying main\nattention to the long range dependence property. Moreover, we show how to\nsimulate these processes and estimate their parameters. We propose to use a\nnovel method based on rescaled modified cumulative distribution function for\nestimation of parameters of the second considered process. This method is very\nuseful in description of rounded data, like waiting times of subordinated\nprocesses delayed by inverse subordinators. By using the Monte Carlo method we\nshow the effectiveness of proposed estimation procedures. \n\n"}
{"id": "1605.01052", "contents": "Title: Regrets, learning and wisdom Abstract: This contribution discusses in what respect Econophysics may be able to\ncontribute to the rebuilding of economics theory. It focuses on aggregation,\nindividual vs collective learning and functional wisdom of the crowds. \n\n"}
{"id": "1605.01091", "contents": "Title: The Resistance Perturbation Distance: A Metric for the Analysis of\n  Dynamic Networks Abstract: To quantify the fundamental evolution of time-varying networks, and detect\nabnormal behavior, one needs a notion of temporal difference that captures\nsignificant organizational changes between two successive instants. In this\nwork, we propose a family of distances that can be tuned to quantify structural\nchanges occurring on a graph at different scales: from the local scale formed\nby the neighbors of each vertex, to the largest scale that quantifies the\nconnections between clusters, or communities. Our approach results in the\ndefinition of a true distance, and not merely a notion of similarity. We\npropose fast (linear in the number of edges) randomized algorithms that can\nquickly compute an approximation to the graph metric. The third contribution\ninvolves a fast algorithm to increase the robustness of a network by optimally\ndecreasing the Kirchhoff index. Finally, we conduct several experiments on\nsynthetic graphs and real networks, and we demonstrate that we can detect\nconfigurational changes that are directly related to the hidden variables\ngoverning the evolution of dynamic networks. \n\n"}
{"id": "1605.01326", "contents": "Title: Compression and the origins of Zipf's law for word frequencies Abstract: Here we sketch a new derivation of Zipf's law for word frequencies based on\noptimal coding. The structure of the derivation is reminiscent of Mandelbrot's\nrandom typing model but it has multiple advantages over random typing: (1) it\nstarts from realistic cognitive pressures (2) it does not require fine tuning\nof parameters and (3) it sheds light on the origins of other statistical laws\nof language and thus can lead to a compact theory of linguistic laws. Our\nfindings suggest that the recurrence of Zipf's law in human languages could\noriginate from pressure for easy and fast communication. \n\n"}
{"id": "1605.02115", "contents": "Title: Don't Walk, Skip! Online Learning of Multi-scale Network Embeddings Abstract: We present Walklets, a novel approach for learning multiscale representations\nof vertices in a network. In contrast to previous works, these representations\nexplicitly encode multiscale vertex relationships in a way that is analytically\nderivable.\n  Walklets generates these multiscale relationships by subsampling short random\nwalks on the vertices of a graph. By `skipping' over steps in each random walk,\nour method generates a corpus of vertex pairs which are reachable via paths of\na fixed length. This corpus can then be used to learn a series of latent\nrepresentations, each of which captures successively higher order relationships\nfrom the adjacency matrix.\n  We demonstrate the efficacy of Walklets's latent representations on several\nmulti-label network classification tasks for social networks such as\nBlogCatalog, DBLP, Flickr, and YouTube. Our results show that Walklets\noutperforms new methods based on neural matrix factorization. Specifically, we\noutperform DeepWalk by up to 10% and LINE by 58% Micro-F1 on challenging\nmulti-label classification tasks. Finally, Walklets is an online algorithm, and\ncan easily scale to graphs with millions of vertices and edges. \n\n"}
{"id": "1605.03479", "contents": "Title: Competition of simple and complex adoption on interdependent networks Abstract: We consider the competition of two mechanisms for adoption processes: a\nso-called complex threshold dynamics and a simple\nSusceptible-Infected-Susceptible (SIS) model. Separately, these mechanisms\nlead, respectively, to first order and continuous transitions between\nnon-adoption and adoption phases. We consider two interconnected layers. While\nall nodes on the first layer follow the complex adoption process, all nodes on\nthe second layer follow the simple adoption process. Coupling between the two\nadoption processes occurs as a result of the inclusion of some additional\ninterconnections between layers. We find that the transition points and also\nthe nature of the transitions are modified in the coupled dynamics. In the\ncomplex adoption layer, the critical threshold required for extension of\nadoption increases with interlayer connectivity whereas in the case of an\nisolated single network it would decrease with average connectivity. In\naddition, the transition can become continuous depending on the detailed inter\nand intralayer connectivities. In the SIS layer, any interlayer connectivity\nleads to the extension of the adopter phase. Besides, a new transition appears\nas as sudden drop of the fraction of adopters in the SIS layer. The main\nnumerical findings are described by a mean-field type analytical approach\nappropriately developed for the threshold-SIS coupled system. \n\n"}
{"id": "1605.03914", "contents": "Title: Dynamics of epidemic spreading with vaccination: impact of social\n  pressure and engagement Abstract: In this work we consider a model of epidemic spreading coupled with an\nopinion dynamics in a fully-connected population. Regarding the opinion\ndynamics, the individuals may be in two distinct states, namely in favor or\nagainst a vaccination campaign. Individuals against the vaccination follow a\nstandard SIS model, whereas the pro-vaccine individuals can also be in a third\ncompartment, namely Vaccinated. In addition, the opinions change according to\nthe majority-rule dynamics in groups with three individuals. We also consider\nthat the vaccine can give permanent or temporary immunization to the\nindividuals. By means of analytical calculations and computer simulations, we\nshow that the opinion dynamics can drastically affect the disease propagation,\nand that the engagement of the pro-vaccine individuals can be crucial for\nstopping the epidemic spreading. The full numerical code for simulate the model\nis available from the authors' webpage. \n\n"}
{"id": "1605.08562", "contents": "Title: Dynamics and Statistics of the Fermi--Pasta--Ulam $\\beta $--model with\n  different ranges of particle interactions Abstract: In the present work we study the Fermi--Pasta--Ulam (FPU) $\\beta $--model\ninvolving long--range interactions (LRI) in both the quadratic and quartic\npotentials, by introducing two independent exponents $\\alpha_1$ and $\\alpha_2$\nrespectively, which make the {forces decay} with distance $r$. Our results\ndemonstrate that weak chaos, in the sense of decreasing Lyapunov exponents, and\n$q$--Gaussian probability density functions (pdfs) of sums of the momenta,\noccurs only when long--range interactions are included in the quartic part.\nMore importantly, for $0\\leq \\alpha_2<1$, we obtain extrapolated values for $q\n\\equiv q_\\infty >1$, as $N\\rightarrow \\infty$, suggesting that these pdfs\npersist in that limit. On the other hand, when long--range interactions are\nimposed only on the quadratic part, strong chaos and purely Gaussian pdfs are\nalways obtained for the momenta. We have also focused on similar pdfs for the\nparticle energies and have obtained $q_E$-exponentials (with $q_E>1$) when the\nquartic-term interactions are long--ranged, otherwise we get the standard\nBoltzmann-Gibbs weight, with $q=1$. The values of $q_E$ coincide, within small\ndiscrepancies, with the values of $q$ obtained by the momentum distributions. \n\n"}
{"id": "1606.00034", "contents": "Title: Environment Identification in Flight using Sparse Approximation of Wing\n  Strain Abstract: This paper addresses the problem of identifying different flow environments\nfrom sparse data collected by wing strain sensors. Insects regularly perform\nthis feat using a sparse ensemble of noisy strain sensors on their wing. First,\nwe obtain strain data from numerical simulation of a Manduca sexta hawkmoth\nwing undergoing different flow environments. Our data-driven method learns\nlow-dimensional strain features originating from different aerodynamic\nenvironments using proper orthogonal decomposition (POD) modes in the frequency\ndomain, and leverages sparse approximation to classify a set of strain\nfrequency signatures using a dictionary of POD modes. This bio-inspired machine\nlearning architecture for dictionary learning and sparse classification permits\nfewer costly physical strain sensors while being simultaneously robust to\nsensor noise. A measurement selection algorithm identifies frequencies that\nbest discriminate the different aerodynamic environments in low-rank POD\nfeature space. In this manner, sparse and noisy wing strain data can be\nexploited to robustly identify different aerodynamic environments encountered\nin flight, providing insight into the stereotyped placement of neurons that act\nas strain sensors on a Manduca sexta hawkmoth wing. \n\n"}
{"id": "1606.01543", "contents": "Title: Permanence and Community Structure in Complex Networks Abstract: The goal of community detection algorithms is to identify densely-connected\nunits within large networks. An implicit assumption is that all the constituent\nnodes belong equally to their associated community. However, some nodes are\nmore important in the community than others. To date, efforts have been\nprimarily driven to identify communities as a whole, rather than understanding\nto what extent an individual node belongs to its community. Therefore, most\nmetrics for evaluating communities, for example modularity, are global. These\nmetrics produce a score for each community, not for each individual node. In\nthis paper, we argue that the belongingness of nodes in a community is not\nuniform.\n  The central idea of permanence is based on the observation that the strength\nof membership of a vertex to a community depends upon two factors: (i) the the\nextent of connections of the vertex within its community versus outside its\ncommunity, and (ii) how tightly the vertex is connected internally. We discuss\nhow permanence can help us understand and utilize the structure and evolution\nof communities by demonstrating that it can be used to -- (i) measure the\npersistence of a vertex in a community, (ii) design strategies to strengthen\nthe community structure, (iii) explore the core-periphery structure within a\ncommunity, and (iv) select suitable initiators for message spreading.\n  We demonstrate that the process of maximizing permanence produces meaningful\ncommunities that concur with the ground-truth community structure of the\nnetworks more accurately than eight other popular community detection\nalgorithms. Finally, we show that the communities obtained by this method are\n(i) less affected by the changes in vertex-ordering, and (ii) more resilient to\nresolution limit, degeneracy of solutions and asymptotic growth of values. \n\n"}
{"id": "1606.04012", "contents": "Title: Inferring Mechanisms for Global Constitutional Progress Abstract: Constitutions help define domestic political orders, but are known to be\ninfluenced by two international mechanisms: one that reflects global temporal\ntrends in legal development, and another that reflects international network\ndynamics such as shared colonial history. We introduce the provision space; the\ngrowing set of all legal provisions existing in the world's constitutions over\ntime. Through this we uncover a third mechanism influencing constitutional\nchange: hierarchical dependencies between legal provisions, under which the\nadoption of essential, fundamental provisions precedes more advanced\nprovisions. This third mechanism appears to play an especially important role\nin the emergence of new political rights, and may therefore provide a useful\nroadmap for advocates of those rights. We further characterise each legal\nprovision in terms of the strength of these mechanisms. \n\n"}
{"id": "1606.04241", "contents": "Title: An Empirically grounded Agent Based simulator for the Air Traffic\n  Management in the SESAR scenario Abstract: In this paper we present a simulator allowing to perform policy experiments\nrelative to the air traffic management. Different SESAR solutions can be\nimplemented in the model to see the reaction of the different stakeholders as\nwell as other relevant metrics (delays, safety, etc). The model describes both\nthe strategic phase associated to the planning of the flight trajectories and\nthe tactical modifications occurring in the en-route phase. An implementation\nof the model is available as open-source and freely accessible by any user.\n  More specifically, different procedures related to business trajectories and\nfree-routing are tested and we illustrate the capabilities of the model on\nairspace implementing these concepts. After performing numerical simulations\nwith the model, we show that in a free-routing scenario the controllers perform\nless operations although they are dispersed over a larger portion of the\nairspace. This can potentially increase the complexity of conflict detection\nand resolution for controllers.\n  In order to investigate this specific aspect, we consider some metrics used\nto measure traffic complexity. We first show that in non-free-routing\nsituations our simulator deals with complexity in a way similar to what humans\nwould do. This allows us to be confident that the results of our numerical\nsimulations relative to the free-routing can reasonably forecast how human\ncontrollers would behave in this new situation. Specifically, our numerical\nsimulations show that most of the complexity metrics decrease with\nfree-routing, while the few metrics which increase are all linked to the flight\nlevel changes. This is a non-trivial result since intuitively the complexity\nshould increase with free-routing because of problematic geometries and more\ndispersed conflicts over the airspace. \n\n"}
{"id": "1606.04872", "contents": "Title: The multiplex dependency structure of financial markets Abstract: We propose here a multiplex network approach to investigate simultaneously\ndifferent types of dependency in complex data sets. In particular, we consider\nmultiplex networks made of four layers corresponding respectively to linear,\nnon-linear, tail, and partial correlations among a set of financial time\nseries. We construct the sparse graph on each layer using a standard network\nfiltering procedure, and we then analyse the structural properties of the\nobtained multiplex networks. The study of the time evolution of the multiplex\nconstructed from financial data uncovers important changes in intrinsically\nmultiplex properties of the network, and such changes are associated with\nperiods of financial stress. We observe that some features are unique to the\nmultiplex structure and would not be visible otherwise by the separate analysis\nof the single-layer networks corresponding to each dependency measure. \n\n"}
{"id": "1606.05665", "contents": "Title: Perspectives on Multi-Level Dynamics Abstract: As Physics did in previous centuries, there is currently a common dream of\nextracting generic laws of nature in economics, sociology, neuroscience, by\nfocalising the description of phenomena to a minimal set of variables and\nparameters, linked together by causal equations of evolution whose structure\nmay reveal hidden principles. This requires a huge reduction of dimensionality\n(number of degrees of freedom) and a change in the level of description. Beyond\nthe mere necessity of developing accurate techniques affording this reduction,\nthere is the question of the correspondence between the initial system and the\nreduced one. In this paper, we offer a perspective towards a common framework\nfor discussing and understanding multi-level systems exhibiting structures at\nvarious spatial and temporal levels. We propose a common foundation and\nillustrate it with examples from different fields. We also point out the\ndifficulties in constructing such a general setting and its limitations. \n\n"}
{"id": "1606.08328", "contents": "Title: Maps of sparse Markov chains efficiently reveal community structure in\n  network flows with memory Abstract: To better understand the flows of ideas or information through social and\nbiological systems, researchers develop maps that reveal important patterns in\nnetwork flows. In practice, network flow models have implied memoryless\nfirst-order Markov chains, but recently researchers have introduced\nhigher-order Markov chain models with memory to capture patterns in multi-step\npathways. Higher-order models are particularly important for effectively\nrevealing actual, overlapping community structure, but higher-order Markov\nchain models suffer from the curse of dimensionality: their vast parameter\nspaces require exponentially increasing data to avoid overfitting and therefore\nmake mapping inefficient already for moderate-sized systems. To overcome this\nproblem, we introduce an efficient cross-validated mapping approach based on\nnetwork flows modeled by sparse Markov chains. To illustrate our approach, we\npresent a map of citation flows in science with research fields that overlap in\nmultidisciplinary journals. Compared with currently used categories in science\nof science studies, the research fields form better units of analysis because\nthe map more effectively captures how ideas flow through science. \n\n"}
{"id": "1607.00072", "contents": "Title: A multilayer perspective for the analysis of urban transportation\n  systems Abstract: Public urban mobility systems are composed by several transportation modes\nconnected together. Most studies in urban mobility and planning often ignore\nthe multi-layer nature of transportation systems considering only aggregated\nversions of this complex scenario. In this work we present a model for the\nrepresentation of the transportation system of an entire city as a multiplex\nnetwork. Using two different perspectives, one in which each line is a layer\nand one in which lines of the same transportation mode are grouped together, we\nstudy the interconnected structure of 9 different cities in Europe raging from\nsmall towns to mega-cities like London and Berlin highlighting their\nvulnerabilities and possible improvements. Finally, for the city of Zaragoza in\nSpain, we also consider data about service schedule and waiting times, which\nallow us to create a simple yet realistic model for urban mobility able to\nreproduce real-world facts and to test for network improvements. \n\n"}
{"id": "1607.02326", "contents": "Title: Particle methods for multi-group pedestrian flow Abstract: We consider a multi-group microscopic model for pedestrian flow describing\nthe behaviour of large groups. It is based on an interacting particle system\ncoupled to an eikonal equation. Hydrodynamic multi-group models are derived\nfrom the underlying particle system as well as scalar multi-group models. The\neikonal equation is used to compute optimal paths for the pedestrians. Particle\nmethods are used to solve the equations on all levels of the hierarchy.\nNumerical test cases are investigated and the models and, in particular, the\nresulting evacuation times are compared for a wide range of different\nparameters. \n\n"}
{"id": "1607.02481", "contents": "Title: Inferring monopartite projections of bipartite networks: an\n  entropy-based approach Abstract: Bipartite networks are currently regarded as providing a major insight into\nthe organization of many real-world systems, unveiling the mechanisms driving\nthe interactions occurring between distinct groups of nodes. One of the most\nimportant issues encountered when modeling bipartite networks is devising a way\nto obtain a (monopartite) projection on the layer of interest, which preserves\nas much as possible the information encoded into the original bipartite\nstructure. In the present paper we propose an algorithm to obtain\nstatistically-validated projections of bipartite networks, according to which\nany two nodes sharing a statistically-significant number of neighbors are\nlinked. Since assessing the statistical significance of nodes similarity\nrequires a proper statistical benchmark, here we consider a set of four null\nmodels, defined within the exponential random graph framework. Our algorithm\noutputs a matrix of link-specific p-values, from which a validated projection\nis straightforwardly obtainable, upon running a multiple hypothesis testing\nprocedure. Finally, we test our method on an economic network (i.e. the\ncountries-products World Trade Web representation) and a social network (i.e.\nMovieLens, collecting the users' ratings of a list of movies). In both cases\nnon-trivial communities are detected: while projecting the World Trade Web on\nthe countries layer reveals modules of similarly-industrialized nations,\nprojecting it on the products layer allows communities characterized by an\nincreasing level of complexity to be detected; in the second case, projecting\nMovieLens on the films layer allows clusters of movies whose affinity cannot be\nfully accounted for by genre similarity to be individuated. \n\n"}
{"id": "1607.03549", "contents": "Title: Statistical Issues in Neutrino Physics Analyses Abstract: Various statistical issues relevant to searches for new physics or to\nparameter determination in analyses of data in neutrino experiments are briefly\ndiscussed. \n\n"}
{"id": "1607.07243", "contents": "Title: Self-presentation and emotional contagion on Facebook: new experimental\n  measures of profiles' emotional coherence Abstract: Social Networks allow users to self-present by sharing personal contents with\nothers which may add comments. Recent studies highlighted how the emotions\nexpressed in a post affect others' posts, eliciting a congruent emotion. So\nfar, no studies have yet investigated the emotional coherence between wall\nposts and its comments. This research evaluated posts and comments mood of\nFacebook profiles, analyzing their linguistic features, and a measure to assess\nan excessive self-presentation was introduced. Two new experimental measures\nwere built, describing the emotional loading (positive and negative) of posts\nand comments, and the mood correspondence between them was evaluated. The\nprofiles \"empathy\", the mood coherence between post and comments, was used to\ninvestigate the relation between an excessive self-presentation and the\nemotional coherence of a profile. Participants publish a higher average number\nof posts with positive mood. To publish an emotional post corresponds to get\nmore likes, comments and receive a coherent mood of comments, confirming the\nemotional contagion effect reported in literature. Finally, the more empathetic\nprofiles are characterized by an excessive self-presentation, having more\nposts, and receiving more comments and likes. To publish emotional contents\nappears to be functional to receive more comments and likes, fulfilling needs\nof attention-seeking. \n\n"}
{"id": "1608.00607", "contents": "Title: Configuring Random Graph Models with Fixed Degree Sequences Abstract: Random graph null models have found widespread application in diverse\nresearch communities analyzing network datasets, including social, information,\nand economic networks, as well as food webs, protein-protein interactions, and\nneuronal networks. The most popular family of random graph null models, called\nconfiguration models, are defined as uniform distributions over a space of\ngraphs with a fixed degree sequence. Commonly, properties of an empirical\nnetwork are compared to properties of an ensemble of graphs from a\nconfiguration model in order to quantify whether empirical network properties\nare meaningful or whether they are instead a common consequence of the\nparticular degree sequence. In this work we study the subtle but important\ndecisions underlying the specification of a configuration model, and\ninvestigate the role these choices play in graph sampling procedures and a\nsuite of applications. We place particular emphasis on the importance of\nspecifying the appropriate graph labeling (stub-labeled or vertex-labeled)\nunder which to consider a null model, a choice that closely connects the study\nof random graphs to the study of random contingency tables. We show that the\nchoice of graph labeling is inconsequential for studies of simple graphs, but\ncan have a significant impact on analyses of multigraphs or graphs with\nself-loops. The importance of these choices is demonstrated through a series of\nthree vignettes, analyzing network datasets under many different configuration\nmodels and observing substantial differences in study conclusions under\ndifferent models. We argue that in each case, only one of the possible\nconfiguration models is appropriate. While our work focuses on undirected\nstatic networks, it aims to guide the study of directed networks, dynamic\nnetworks, and all other network contexts that are suitably studied through the\nlens of random graph null models. \n\n"}
{"id": "1608.00708", "contents": "Title: Detection of money laundering groups using supervised learning in\n  networks Abstract: Money laundering is a major global problem, enabling criminal organisations\nto hide their ill-gotten gains and to finance further operations. Prevention of\nmoney laundering is seen as a high priority by many governments, however\ndetection of money laundering without prior knowledge of predicate crimes\nremains a significant challenge. Previous detection systems have tended to\nfocus on individuals, considering transaction histories and applying anomaly\ndetection to identify suspicious behaviour. However, money laundering involves\ngroups of collaborating individuals, and evidence of money laundering may only\nbe apparent when the collective behaviour of these groups is considered. In\nthis paper we describe a detection system that is capable of analysing group\nbehaviour, using a combination of network analysis and supervised learning.\nThis system is designed for real-world application and operates on networks\nconsisting of millions of interacting parties. Evaluation of the system using\nreal-world data indicates that suspicious activity is successfully detected.\nImportantly, the system exhibits a low rate of false positives, and is\ntherefore suitable for use in a live intelligence environment. \n\n"}
{"id": "1608.00763", "contents": "Title: A Comparative Analysis of Community Detection Algorithms on Artificial\n  Networks Abstract: Many community detection algorithms have been developed to uncover the\nmesoscopic properties of complex networks. However how good an algorithm is, in\nterms of accuracy and computing time, remains still open. Testing algorithms on\nreal-world network has certain restrictions which made their insights\npotentially biased: the networks are usually small, and the underlying\ncommunities are not defined objectively. In this study, we employ the\nLancichinetti-Fortunato-Radicchi benchmark graph to test eight state-of-the-art\nalgorithms. We quantify the accuracy using complementary measures and\nalgorithms' computing time. Based on simple network properties and the\naforementioned results, we provide guidelines that help to choose the most\nadequate community detection algorithm for a given network. Moreover, these\nrules allow uncovering limitations in the use of specific algorithms given\nmacroscopic network properties. Our contribution is threefold: firstly, we\nprovide actual techniques to determine which is the most suited algorithm in\nmost circumstances based on observable properties of the network under\nconsideration. Secondly, we use the mixing parameter as an easily measurable\nindicator of finding the ranges of reliability of the different algorithms.\nFinally, we study the dependency with network size focusing on both the\nalgorithm's predicting power and the effective computing time. \n\n"}
{"id": "1608.01766", "contents": "Title: Asynchronous Rumor Spreading on Random Graphs Abstract: We perform a thorough study of various characteristics of the asynchronous\npush-pull protocol for spreading a rumor on Erd\\H{o}s-R\\'enyi random graphs\n$G_{n,p}$, for any $p>c\\ln(n)/n$ with $c>1$. In particular, we provide a simple\nstrategy for analyzing the asynchronous push-pull protocol on arbitrary graph\ntopologies and apply this strategy to $G_{n,p}$. We prove tight bounds of\nlogarithmic order for the total time that is needed until the information has\nspread to all nodes. Surprisingly, the time required by the asynchronous\npush-pull protocol is asymptotically almost unaffected by the average degree of\nthe graph. Similarly tight bounds for Erd\\H{o}s-R\\'enyi random graphs have\npreviously only been obtained for the synchronous push protocol, where it has\nbeen observed that the total running time increases significantly for sparse\nrandom graphs. Finally, we quantify the robustness of the protocol with respect\nto transmission and node failures. Our analysis suggests that the asynchronous\nprotocols are particularly robust with respect to these failures compared to\ntheir synchronous counterparts. \n\n"}
{"id": "1608.04418", "contents": "Title: A Note on Markov Normalized Magnetic Eigenmaps Abstract: We note that building a magnetic Laplacian from the Markov transition matrix,\nrather than the graph adjacency matrix, yields several benefits for the\nmagnetic eigenmaps algorithm. The two largest benefits are that the embedding\nbecomes more stable as a function of the rotation parameter g, and the\nprincipal eigenvector of the magnetic Laplacian now converges to the page rank\nof the network as a function of diffusion time. We show empirically that this\nnormalization improves the phase and real/imaginary embeddings of the\nlow-frequency eigenvectors of the magnetic Laplacian. \n\n"}
{"id": "1608.04506", "contents": "Title: Time-scale effects on the gain-loss asymmetry in stock indices Abstract: The gain-loss asymmetry, observed in the inverse statistics of stock indices\nis present for logarithmic return levels that are over $2\\%$, and it is the\nresult of the non-Pearson type auto-correlations in the index. These\nnon-Pearson type correlations can be viewed also as functionally dependent\ndaily volatilities, extending for a finite time interval. A generalized\ntime-window shuffling method is used to show the existence of such\nauto-correlations. Their characteristic time-scale proves to be smaller (less\nthan $25$ trading days) than what was previously believed. It is also found\nthat this characteristic time-scale has decreased with the appearance of\nprogram trading in the stock market transactions. Connections with the leverage\neffect are also established. \n\n"}
{"id": "1608.04772", "contents": "Title: The Use of Minimal Spanning Trees in Particle Physics Abstract: Minimal spanning trees (MSTs) have been used in cosmology and astronomy to\ndistinguish distributions of points in a multi-dimensional space. They are\nessentially unknown in particle physics, however. We briefly define MSTs and\nillustrate their properties through a series of examples. We show how they\nmight be applied to study a typical event sample from a collider experiment and\nconclude that MSTs may prove useful in distinguishing different classes of\nevents. \n\n"}
{"id": "1608.04863", "contents": "Title: Influence of selfish and polite behaviours on a pedestrian evacuation\n  through a narrow exit: A quantitative characterisation Abstract: We study the influence of selfish vs. polite behaviours on the dynamics of a\npedestrian evacuation through a narrow exit. To this end, experiments involving\nabout 80 participants with distinct prescribed behaviours are performed;\nreinjection of participants into the setup allowed us to improve the\nstatistics. Notwithstanding the fluctuations in the instantaneous flow rate, we\nfind that a stationary regime is almost immediately reached. The average flow\nrate increases monotonically with the fraction c\\_s of vying (selfish)\npedestrians, which corresponds to a \"faster-is-faster\" effect in our\nexperimental conditions; it is also positively correlated with the average\ndensity of pedestrians in front of the door, up to nearly close-packing. At\nlarge c\\_s , the flow displays marked intermittency, with bursts of\nquasi-simultaneous escapes. In addition to these findings, we wonder whether\nthe effect of cooperation is specific to systems of intelligent beings, or\nwhether it can be reproduced by a purely mechanical surrogate. To this purpose,\nwe consider a bidimensional granular flow through an orifice in which some\ngrains are made \"cooperative\" by repulsive magnetic interactions which impede\ntheir mutual collisions. \n\n"}
{"id": "1608.05119", "contents": "Title: Improving randomness characterization through Bayesian model selection Abstract: Nowadays random number generation plays an essential role in technology with\nimportant applications in areas ranging from cryptography, which lies at the\ncore of current communication protocols, to Monte Carlo methods, and other\nprobabilistic algorithms. In this context, a crucial scientific endeavour is to\ndevelop effective methods that allow the characterization of random number\ngenerators. However, commonly employed methods either lack formality (e.g. the\nNIST test suite), or are inapplicable in principle (e.g. the characterization\nderived from the Algorithmic Theory of Information (ATI)). In this letter we\npresent a novel method based on Bayesian model selection, which is both\nrigorous and effective, for characterizing randomness in a bit sequence. We\nderive analytic expressions for a model's likelihood which is then used to\ncompute its posterior probability distribution. Our method proves to be more\nrigorous than NIST's suite and the Borel-Normality criterion and its\nimplementation is straightforward. We have applied our method to an\nexperimental device based on the process of spontaneous parametric\ndownconversion, implemented in our laboratory, to confirm that it behaves as a\ngenuine quantum random number generator (QRNG). As our approach relies on\nBayesian inference, which entails model generalizability, our scheme transcends\nindividual sequence analysis, leading to a characterization of the source of\nthe random sequences itself. \n\n"}
{"id": "1608.05851", "contents": "Title: The Growth of Oligarchy in a Yard-Sale Model of Asset Exchange: A\n  Logistic Equation for Wealth Condensation Abstract: The addition of wealth-attained advantage (WAA) to the Yard-Sale Model (YSM)\nof asset exchange has been demonstrated to induce wealth condensation. In a\nmodel of WAA for which the bias is a continuous function of the wealth\ndifference of the transacting agents, the condensation was shown to arise from\na second-order phase transition to a coexistence regime. In this paper, we\npresent the first analytic time-dependent results for this model, by showing\nthat the condensed wealth obeys a logistic equation in time. \n\n"}
{"id": "1609.00876", "contents": "Title: Statistical Dynamics of Regional Populations and Economies Abstract: A practical statistical analysis on the regional populations and GDPs of\nChina is conducted. The result shows that the distribution of the populations\nand that of the GDPs obeys the shifted power law, respectively. To understand\nthese characteristics, a generalized Langevin equation describing variation of\npopulation is proposed based on the correlation between population and GDP as\nwell as the random fluctuations of the related factors. The equation is\ntransformed into the Fokker-Plank equation, and the solution demonstrates a\ntransform of population distribution from the normal Gaussian distribution to a\nshifted power law. It also suggests a critical point of time at which the\ntransform occurs. The shifted power law distribution in the supercritical\nsituation is qualitatively in accordance with the practical result. The\ndistribution of the GDPs is derived based on the Cobb-Douglas production\nfunction, and presents a change from a shifted power law to the Gaussian\ndistribution. This result indicates that the regional GDP distribution of our\nsociety will be the Gaussian distribution in the future. The analysis on the\ngrowth trend of economy suggests it will become a reality. These theoretical\nattempts may draw a historical picture of our world in the aspects of\npopulation and economy. \n\n"}
{"id": "1609.01641", "contents": "Title: Network Composition from Multi-layer Data Abstract: It is common for people to access multiple social networks, for example,\nusing phone, email, and social media. Together, the multi-layer social\ninteractions form a \"integrated social network.\" How can we extend well\ndeveloped knowledge about single-layer networks, including vertex centrality\nand community structure, to such heterogeneous structures? In this paper, we\napproach these challenges by proposing a principled framework of network\ncomposition based on a unified dynamical process. Mathematically, we consider\nthe following abstract problem: Given multi-layer network data and additional\nparameters for intra and inter-layer dynamics, construct a (single) weighted\nnetwork that best integrates the joint process. We use transformations of\ndynamics to unify heterogeneous layers under a common dynamics. For inter-layer\ncompositions, we will consider several cases as the inter-layer dynamics plays\ndifferent roles in various social or technological networks. Empirically, we\nprovide examples to highlight the usefulness of this framework for network\nanalysis and network design. \n\n"}
{"id": "1609.03526", "contents": "Title: Evidence for a Conserved Quantity in Human Mobility Abstract: Recent seminal works on human mobility have shown that individuals constantly\nexploit a small set of repeatedly visited locations. A concurrent literature\nhas emphasized the explorative nature of human behavior, showing that the\nnumber of visited places grows steadily over time. How to reconcile these\nseemingly contradicting facts remains an open question. Here, we analyze\nhigh-resolution multi-year traces of $\\sim$40,000 individuals from 4 datasets\nand show that this tension vanishes when the long-term evolution of mobility\npatterns is considered. We reveal that mobility patterns evolve significantly\nyet smoothly, and that the number of familiar locations an individual visits at\nany point is a conserved quantity with a typical size of $\\sim$25 locations. We\nuse this finding to improve state-of-the-art modeling of human mobility.\nFurthermore, shifting the attention from aggregated quantities to individual\nbehavior, we show that the size of an individual's set of preferred locations\ncorrelates with the number of her social interactions. This result suggests a\nconnection between the conserved quantity we identify, which as we show can not\nbe understood purely on the basis of time constraints, and the `Dunbar number'\ndescribing a cognitive upper limit to an individual's number of social\nrelations. We anticipate that our work will spark further research linking the\nstudy of Human Mobility and the Cognitive and Behavioral Sciences. \n\n"}
{"id": "1609.04903", "contents": "Title: Ensemble-Based Algorithms to Detect Disjoint and Overlapping Communities\n  in Networks Abstract: Given a set ${\\cal AL}$ of community detection algorithms and a graph $G$ as\ninputs, we propose two ensemble methods $\\mathtt{EnDisCO}$ and $\\mathtt{MeDOC}$\nthat (respectively) identify disjoint and overlapping communities in $G$.\n$\\mathtt{EnDisCO}$ transforms a graph into a latent feature space by leveraging\nmultiple base solutions and discovers disjoint community structure.\n$\\mathtt{MeDOC}$ groups similar base communities into a meta-community and\ndetects both disjoint and overlapping community structures. Experiments are\nconducted at different scales on both synthetically generated networks as well\nas on several real-world networks for which the underlying ground-truth\ncommunity structure is available. Our extensive experiments show that both\nalgorithms outperform state-of-the-art non-ensemble algorithms by a significant\nmargin. Moreover, we compare $\\mathtt{EnDisCO}$ and $\\mathtt{MeDOC}$ with a\nrecent ensemble method for disjoint community detection and show that our\napproaches achieve superior performance. To the best of our knowledge,\n$\\mathtt{MeDOC}$ is the first ensemble approach for overlapping community\ndetection. \n\n"}
{"id": "1609.05542", "contents": "Title: Public Goods Games on Adaptive Coevolutionary Networks Abstract: Productive societies feature high levels of cooperation and strong\nconnections between individuals. Public Goods Games (PGGs) are frequently used\nto study the development of social connections and cooperative behavior in\nmodel societies. In such games, contributions to the public good are made only\nby cooperators, while all players, including defectors, can reap public goods\nbenefits. Classic results of game theory show that mutual defection, as opposed\nto cooperation, is the Nash Equilibrium of PGGs in well-mixed populations,\nwhere each player interacts with all others. In this paper, we explore the\ncoevolutionary dynamics of a low information public goods game on a network\nwithout spatial constraints in which players adapt to their environment in\norder to increase individual payoffs. Players adapt by changing their\nstrategies, either to cooperate or to defect, and by altering their social\nconnections. We find that even if players do not know other players' strategies\nand connectivity, cooperation can arise and persist despite large short-term\nfluctuations. \n\n"}
{"id": "1609.07885", "contents": "Title: Optimal sensor placement using machine learning Abstract: A new method for optimal sensor placement based on variable importance of\nmachine learned models is proposed. With its simplicity, adaptivity, and low\ncomputational cost, the method offers many advantages over existing approaches.\nThe new method is implemented on the flow over an airfoil equipped with a\nCoanda actuator. The analysis is based on flow field data obtained from 2D\nunsteady Reynolds averaged Navier-Stokes (URANS) simulations with different\nactuation conditions. The optimal sensor locations is compared against the\ncurrent de-facto standard of maximum POD modal amplitude location, and against\na brute force approach that scans all possible sensor combinations. The results\nshow that both the flow conditions and the type of sensor have an effect on the\noptimal sensor placement, whereas the choice of the response function appears\nto have limited influence. \n\n"}
{"id": "1609.08556", "contents": "Title: Many-body methods in agent-based epidemic models Abstract: The susceptible-infected-susceptible (SIS) agent-based model is usually\nemployed in the investigation of epidemics. The model describes a Markov\nprocess for a single communicable disease among susceptible (S) and infected\n(I) agents. However, the disease spreading forecasting is often restricted to\nnumerical simulations, while analytic formulations lack both general results\nand perturbative approaches since they are subjected to asymmetric time\ngenerators. Here, we discuss perturbation theory, approximations and\napplication of many-body techniques in epidemic models in the framework for\nsquared norm of probability vector $|P(t)| ^2$, in which asymmetric time\ngenerators are replaced by their symmetric counterparts. \n\n"}
{"id": "1610.00195", "contents": "Title: Penalized Ensemble Kalman Filters for High Dimensional Non-linear\n  Systems Abstract: The ensemble Kalman filter (EnKF) is a data assimilation technique that uses\nan ensemble of models, updated with data, to track the time evolution of a\nusually non-linear system. It does so by using an empirical approximation to\nthe well-known Kalman filter. However, its performance can suffer when the\nensemble size is smaller than the state space, as is often necessary for\ncomputationally burdensome models. This scenario means that the empirical\nestimate of the state covariance is not full rank and possibly quite noisy. To\nsolve this problem in this high dimensional regime, we propose a\ncomputationally fast and easy to implement algorithm called the penalized\nensemble Kalman filter (PEnKF). Under certain conditions, it can be\ntheoretically proven that the PEnKF will be accurate (the estimation error will\nconverge to zero) despite having fewer ensemble members than state dimensions.\nFurther, as contrasted to localization methods, the proposed approach learns\nthe covariance structure associated with the dynamical system. These\ntheoretical results are supported with simulations of several non-linear and\nhigh dimensional systems. \n\n"}
{"id": "1610.02643", "contents": "Title: A model independent safeguard for unbinned Likelihood Abstract: We present a universal method to include residual un-modeled background shape\nuncertainties in likelihood based statistical tests for high energy physics and\nastroparticle physics. This approach provides a simple and natural protection\nagainst mismodeling, thus lowering the chances of a false discovery or of an\nover constrained confidence interval, and allows a natural transition to\nunbinned space. Unbinned likelihood allows optimal usage of information for the\ndata and the models, and enhances the sensitivity.\n  We show that the asymptotic behavior of the test statistic can be regained in\ncases where the model fails to describe the true background behavior, and\npresent 1D and 2D case studies for model-driven and data-driven background\nmodels. The resulting penalty on sensitivities follows the actual discrepancy\nbetween the data and the models, and is asymptotically reduced to zero with\nincreasing knowledge. \n\n"}
{"id": "1610.02736", "contents": "Title: Emergence of linguistic laws in human voice Abstract: Linguistic laws constitute one of the quantitative cornerstones of modern\ncognitive sciences and have been routinely investigated in written corpora, or\nin the equivalent transcription of oral corpora. This means that inferences of\nstatistical patterns of language in acoustics are biased by the arbitrary,\nlanguage-dependent segmentation of the signal, and virtually precludes the\npossibility of making comparative studies between human voice and other animal\ncommunication systems. Here we bridge this gap by proposing a method that\nallows to measure such patterns in acoustic signals of arbitrary origin,\nwithout needs to have access to the language corpus underneath. The method has\nbeen applied to six different human languages, recovering successfully some\nwell-known laws of human communication at timescales even below the phoneme and\nfinding yet another link between complexity and criticality in a biological\nsystem. These methods further pave the way for new comparative studies in\nanimal communication or the analysis of signals of unknown code. \n\n"}
{"id": "1610.06497", "contents": "Title: Information Overload in Group Communication: From Conversation to\n  Cacophony in the Twitch Chat Abstract: Online communication channels, especially social web platforms, are rapidly\nreplacing traditional ones. Online platforms allow users to overcome physical\nbarriers, enabling worldwide participation. However, the power of online\ncommunication bears an important negative consequence --- we are exposed to too\nmuch information to process. Too many participants, for example, can turn\nonline public spaces into noisy, overcrowded fora where no meaningful\nconversation can be held. Here we analyze a large dataset of public chat logs\nfrom Twitch, a popular video streaming platform, in order to examine how\ninformation overload affects online group communication. We measure structural\nand textual features of conversations such as user output, interaction, and\ninformation content per message across a wide range of information loads. Our\nanalysis reveals the existence of a transition from a conversational state to a\ncacophony --- a state of overload with lower user participation, more\ncopy-pasted messages, and less information per message. These results hold both\non average and at the individual level for the majority of users. This study\nprovides a quantitative basis for further studies of the social effects of\ninformation overload, and may guide the design of more resilient online\ncommunication systems. \n\n"}
{"id": "1610.08192", "contents": "Title: Transfer entropy in continuous time, with applications to jump and\n  neural spiking processes Abstract: Transfer entropy has been used to quantify the directed flow of information\nbetween source and target variables in many complex systems. While transfer\nentropy was originally formulated in discrete time, in this paper we provide a\nframework for considering transfer entropy in continuous time systems, based on\nRadon-Nikodym derivatives between measures of complete path realizations. To\ndescribe the information dynamics of individual path realizations, we introduce\nthe pathwise transfer entropy, the expectation of which is the transfer entropy\naccumulated over a finite time interval. We demonstrate that this formalism\npermits an instantaneous transfer entropy rate. These properties are analogous\nto the behavior of physical quantities defined along paths such as work and\nheat. We use this approach to produce an explicit form for the transfer entropy\nfor pure jump processes, and highlight the simplified form in the specific case\nof point processes (frequently used in neuroscience to model neural spike\ntrains). Finally, we present two synthetic spiking neuron model examples to\nexhibit the pertinent features of our formalism, namely, that the information\nflow for point processes consists of discontinuous jump contributions (at\nspikes in the target) interrupting a continuously varying contribution\n(relating to waiting times between target spikes). Numerical schemes based on\nour formalism promise significant benefits over existing strategies based on\ndiscrete time formalisms. \n\n"}
{"id": "1610.08918", "contents": "Title: Income and wealth distribution of the richest Norwegian individuals: An\n  inequality analysis Abstract: Using the empirical data from the Norwegian tax office, we analyse the wealth\nand income of the richest individuals in Norway during the period 2010--2013.\nWe find that both annual income and wealth level of the richest individuals are\ndescribable using the Pareto law. We find that the robust mean Pareto exponent\nover the four-year period to be $\\approx 2.3$ for income and $\\approx 1.5$ for\nwealth. \n\n"}
{"id": "1611.00723", "contents": "Title: Socio-economic inequality and prospects of institutional Econophysics Abstract: Socio-economic inequality is measured using various indices. The Gini ($g$)\nindex, giving the overall inequality is the most commonly used, while the\nrecently introduced Kolkata ($k$) index gives a measure of $1-k$ fraction of\npopulation who possess top $k$ fraction of wealth in the society. This article\nreviews the character of such inequalities, as seen from a variety of data\nsources, the apparent relationship between the two indices, and what toy models\ntell us. These socio-economic inequalities are also investigated in the context\nof man-made social conflicts or wars, as well as in natural disasters. Finally,\nwe forward a proposal for an international institution with sufficient fund for\nvisitors, where natural and social scientists from various institutions of the\nworld can come to discuss, debate and formulate further developments. \n\n"}
{"id": "1611.01970", "contents": "Title: Localization-Delocalization Transitions in Bosonic Random Matrix\n  Ensembles Abstract: Localization to delocalization transitions in eigenfunctions are studied for\nfinite interacting boson systems by employing one- plus two-body embedded\nGaussian orthogonal ensemble of random matrices [EGOE(1+2)]. In the first\nanalysis, considered are bosonic EGOE(1+2) for two-species boson systems with a\nfictitious ($F$) spin degree of freedom [called BEGOE(1+2)-$F$]. Numerical\ncalculations are carried out as a function of the two-body interaction strength\n($\\lambda$). It is shown that, in the region (defined by $\\lambda>\\lambda_c$)\nafter the onset of Poisson to GOE transition in energy levels, the strength\nfunctions exhibit Breit-Wigner to Gaussian transition for\n$\\lambda>\\lambda_{F_k}>\\lambda_c$. Further, analyzing information entropy and\nparticipation ratio, it is established that there is a region defined by\n$\\lambda\\sim\\lambda_t$ where the system exhibits thermalization. The $F$-spin\ndependence of the transition markers $\\lambda_{F_k}$ and $\\lambda_t$ follow\nfrom the propagator for the spectral variances. These results, well tested near\nthe center of the spectrum and extend to the region within $\\pm2\\sigma$ to\n$\\pm3\\sigma$ from the center ($\\sigma^2$ is the spectral variance), establish\nuniversality of the transitions generated by embedded ensembles. In the second\nanalysis, entanglement entropy is studied for spin-less BEGOE(1+2) ensemble and\nshown that the results generated are close to the recently reported results for\na Bose-Hubbard model. \n\n"}
{"id": "1611.02617", "contents": "Title: Color-avoiding percolation Abstract: Many real world networks have groups of similar nodes which are vulnerable to\nthe same failure or adversary. Nodes can be colored in such a way that colors\nencode the shared vulnerabilities. Using multiple paths to avoid these\nvulnerabilities can greatly improve network robustness. Color-avoiding\npercolation provides a theoretical framework for analyzing this scenario,\nfocusing on the maximal set of nodes which can be connected via multiple\ncolor-avoiding paths. In this paper we extend the basic theory of\ncolor-avoiding percolation that was published in [Krause et. al., Phys. Rev. X\n6 (2016) 041022]. We explicitly account for the fact that the same particular\nlink can be part of different paths avoiding different colors. This fact was\npreviously accounted for with a heuristic approximation. We compare this\napproximation with a new, more exact theory and show that the new theory is\nsubstantially more accurate for many avoided colors. Further, we formulate our\nnew theory with differentiated node functions, as senders/receivers or as\ntransmitters. In both functions, nodes can be explicitly trusted or avoided.\nWith only one avoided color we obtain standard percolation. With one by one\navoiding additional colors, we can understand the critical behavior of color\navoiding percolation. For heterogeneous color frequencies, we find that the\ncolors with the largest frequencies control the critical threshold and\nexponent. Colors of small frequencies have only a minor influence on color\navoiding connectivity, thus allowing for approximations. \n\n"}
{"id": "1611.04061", "contents": "Title: Contact activity and dynamics of the online elite Abstract: Humans interact through numerous channels to build and maintain social\nconnections: they meet face-to-face, initiate phone calls or send text\nmessages, and interact via social media. Although it is known that the network\nof physical contacts, for example, is distinct from the network arising from\ncommunication events via phone calls and instant messages, the extent to which\nthese networks differ is not clear. In fact, the network structure of these\nchannels shows large structural variations. Each network of interactions,\nhowever, contains both central and peripheral individuals: central members are\ncharacterized by higher connectivity and can reach a high fraction of the\nnetwork within a low number of connections, contrary to the nodes on the\nperiphery. Here we show that the various channels account for diverse\nrelationships between pairs of individuals and the corresponding interaction\npatterns across channels differ to an extent that hinders the simple reduction\nof social ties to a single layer. Furthemore, the origin and purpose of each\nnetwork also determine the role of their respective central members: highly\nconnected individuals in the person-to-person networks interact with their\nenvironment in a regular manner, while members central in the social\ncommunication networks display irregular behavior with respect to their\nphysical contacts and are more active through rare, social events. These\nresults suggest that due to the inherently different functions of communication\nchannels, each one favors different social behaviors and different strategies\nfor interacting with the environment. Our findings can facilitate the\nunderstanding of the varying roles and impact individuals have on the\npopulation, which can further shed light on the prediction and prevention of\nepidemic outbreaks, or information propagation. \n\n"}
{"id": "1611.04295", "contents": "Title: The parameters uncertainty inflation fallacy Abstract: Statistical estimation of the prediction uncertainty of physical models is\ntypically hindered by the inadequacy of these models due to various\napproximations they are built upon. The prediction errors due to model\ninadequacy can be handled either by correcting the model's results, or by\nadapting the model's parameters uncertainty to generate prediction uncertainty\nrepresentative, in a way to be defined, of model inadequacy errors. The main\nadvantage of the latter approach is its transferability to the prediction of\nother quantities of interest based on the same parameters. A critical review of\nstate-of-the-art implementations of this approach in computational chemistry\nshows that it is biased, in the sense that it does not produce prediction\nuncertainty bands conforming with model inadequacy errors. \n\n"}
{"id": "1611.05778", "contents": "Title: Towards the Modeling of Behavioral Trajectories of Users in Online\n  Social Media Abstract: In this paper, we introduce a methodology that allows to model behavioral\ntrajectories of users in online social media. First, we illustrate how to\nleverage the probabilistic framework provided by Hidden Markov Models (HMMs) to\nrepresent users by embedding the temporal sequences of actions they performed\nonline. We then derive a model-based distance between trained HMMs, and we use\nspectral clustering to find homogeneous clusters of users showing similar\nbehavioral trajectories. To provide platform-agnostic results, we apply the\nproposed approach to two different online social media --- i.e. Facebook and\nYouTube. We conclude discussing merits and limitations of our approach as well\nas future and promising research directions. \n\n"}
{"id": "1611.06715", "contents": "Title: Pitfalls in testing with linear regression model by OLS Abstract: This is a comment on Economic Letters DOI\nhttp://dx.doi.org/10.1016/j.econlet.2015.10.015. We show that due to some\nmethodological aspects the main conclusions of the above mentioned paper should\nbe a little bit altered. \n\n"}
{"id": "1611.07769", "contents": "Title: The many facets of community detection in complex networks Abstract: Community detection, the decomposition of a graph into essential building\nblocks, has been a core research topic in network science over the past years.\nSince a precise notion of what constitutes a community has remained evasive,\ncommunity detection algorithms have often been compared on benchmark graphs\nwith a particular form of assortative community structure and classified based\non the mathematical techniques they employ. However, this comparison can be\nmisleading because apparent similarities in their mathematical machinery can\ndisguise different goals and reasons for why we want to employ community\ndetection in the first place. Here we provide a focused review of these\ndifferent motivations that underpin community detection. This problem-driven\nclassification is useful in applied network science, where it is important to\nselect an appropriate algorithm for the given purpose. Moreover, highlighting\nthe different facets of community detection also delineates the many lines of\nresearch and points out open directions and avenues for future research. \n\n"}
{"id": "1611.09110", "contents": "Title: Master stability functions for complete, intra-layer and inter-layer\n  synchronization in multiplex networks Abstract: Synchronization phenomena are of broad interest across disciplines and\nincreasingly of interest in a multiplex network setting. Here we show how the\nMaster Stability Function, a celebrated framework for analyzing synchronization\non a single network, can be extended to certain classes of multiplex networks\nwith different intra-layer and inter-layer coupling functions. We derive three\nmaster stability equations that determine respectively the necessary regions of\ncomplete synchronization, intra-layer synchronization and inter-layer\nsynchronization. We calculate these three regions explicitly for the case of a\ntwo-layer network of R{\\\"o}ssler oscillators and show that the overlap of the\nregions determines the type of synchronization achieved. In particular, if the\ninter- or intra-layer coupling function is such that the inter-layer or\nintra-layer synchronization region is empty, complete synchronization cannot be\nachieved regardless of the coupling strength. Furthermore, for any given nodal\ndynamics and network structure, the occurrence of intra-layer and inter-layer\nsynchronization depend mainly on the coupling functions of nodes within a layer\nand across layers, respectively. Our mathematical analysis requires that the\nintra- and inter-layer supra-Laplacians commute. But we show this is only a\nsufficient, and not necessary, condition and that the results can be applied\nmore generally. \n\n"}
{"id": "1612.01510", "contents": "Title: The Effects of Data Quality on the Analysis of Corporate Board Interlock\n  Networks Abstract: Nowadays, social networks of ever increasing size are studied by researchers\nfrom a range of disciplines. The data underlying these networks is often\nautomatically gathered from API's, websites or existing databases. As a result,\nthe quality of this data is typically not manually validated, and the resulting\nnetworks may be based on false, biased or incomplete data. In this paper, we\ninvestigate the effect of data quality issues on the analysis of large\nnetworks. We focus on the global board interlock network, in which nodes\nrepresent firms across the globe, and edges model social ties between firms --\nshared board members holding a position at both firms. First, we demonstrate\nhow we can automatically assess the completeness of a large dataset of 160\nmillion firms, in which data is missing not at random. Second, we present a\nnovel method to increase the accuracy of the entries in our data. By comparing\nthe expected and empirical characteristics of the resulting network topology,\nwe develop a technique that automatically prunes and merges duplicate nodes and\nedges. Third, we use a case study of the board interlock network of Sweden to\nshow how poor quality data results in incorrect network topologies, biased\ncentrality values and abnormal influence spread under a well-known diffusion\nmodel. Finally, we demonstrate how our data quality assessment methods help\nrestore the correct network structure, ultimately allowing us to derive\nmeaningful and correct results from analyzing the network. \n\n"}
{"id": "1612.03727", "contents": "Title: Exponential Self-Organization and Moore's Law: Measures and Mechanisms Abstract: The question how complex systems become more organized and efficient with\ntime is open. Examples are, the formation of elementary particles from pure\nenergy, the formation of atoms from particles, the formation of stars and\ngalaxies, the formation of molecules from atoms, of organisms, and of the\nsociety. In this sequence, order appears inside complex systems and randomness\n(entropy) is expelled to their surroundings. Key features of self-organizing\nsystems are that they are open and they are far away from equilibrium, with\nincreasing energy flowing through them. This work searches for global measures\nof such self-organizing systems, that are predictable and do not depend on the\nsubstrate of the system studied. Our results will help to understand the\nexistence of complex systems and mechanisms of self-organization. In part we\nalso provide insights, in this work, about the underlying physical essence of\nthe Moore's law and the multiple logistic growth observed in technological\nprogress. \n\n"}
{"id": "1612.05001", "contents": "Title: Graph-based semi-supervised learning for relational networks Abstract: We address the problem of semi-supervised learning in relational networks,\nnetworks in which nodes are entities and links are the relationships or\ninteractions between them. Typically this problem is confounded with the\nproblem of graph-based semi-supervised learning (GSSL), because both problems\nrepresent the data as a graph and predict the missing class labels of nodes.\nHowever, not all graphs are created equally. In GSSL a graph is constructed,\noften from independent data, based on similarity. As such, edges tend to\nconnect instances with the same class label. Relational networks, however, can\nbe more heterogeneous and edges do not always indicate similarity. For\ninstance, instead of links being more likely to connect nodes with the same\nclass label, they may occur more frequently between nodes with different class\nlabels (link-heterogeneity). Or nodes with the same class label do not\nnecessarily have the same type of connectivity across the whole network\n(class-heterogeneity), e.g. in a network of sexual interactions we may observe\nlinks between opposite genders in some parts of the graph and links between the\nsame genders in others. Performing classification in networks with different\ntypes of heterogeneity is a hard problem that is made harder still when we do\nnot know a-priori the type or level of heterogeneity. Here we present two\nscalable approaches for graph-based semi-supervised learning for the more\ngeneral case of relational networks. We demonstrate these approaches on\nsynthetic and real-world networks that display different link patterns within\nand between classes. Compared to state-of-the-art approaches, ours give better\nclassification performance without prior knowledge of how classes interact. In\nparticular, our two-step label propagation algorithm gives consistently good\naccuracy and runs on networks of over 1.6 million nodes and 30 million edges in\naround 12 seconds. \n\n"}
{"id": "1612.06185", "contents": "Title: The appropriateness of ignorance in the inverse kinetic Ising model Abstract: We develop efficient ways to consider and correct for the effects of hidden\nunits for the paradigmatic case of the inverse kinetic Ising model with fully\nasymmetric couplings. We identify two sources of error in reconstructing the\nconnectivity among the observed units while ignoring part of the network. One\nleads to a systematic bias in the inferred parameters, whereas the other\ninvolves correlations between the visible and hidden populations and has a\nmagnitude that depends on the coupling strength. We estimate these two terms\nusing a mean field approach and derive self-consistent equations for the\ncouplings accounting for the systematic bias. Through application of these\nmethods on simple networks of varying relative population size and connectivity\nstrength, we assess how and under what conditions the hidden portion can\ninfluence inference and to what degree it can be crudely estimated. We find\nthat for weak to moderately coupled systems, the effects of the hidden units is\na simple rotation that can be easily corrected for. For strongly coupled\nsystems, the non-systematic term becomes large and can no longer be safely\nignored, further highlighting the importance of understanding the average\nstrength of couplings for a given system of interest. \n\n"}
{"id": "1612.08447", "contents": "Title: Higher-order organization of complex networks Abstract: Networks are a fundamental tool for understanding and modeling complex\nsystems in physics, biology, neuroscience, engineering, and social science.\nMany networks are known to exhibit rich, lower-order connectivity patterns that\ncan be captured at the level of individual nodes and edges. However,\nhigher-order organization of complex networks---at the level of small network\nsubgraphs---remains largely unknown. Here we develop a generalized framework\nfor clustering networks based on higher-order connectivity patterns. This\nframework provides mathematical guarantees on the optimality of obtained\nclusters and scales to networks with billions of edges. The framework reveals\nhigher-order organization in a number of networks including information\npropagation units in neuronal networks and hub structure in transportation\nnetworks. Results show that networks exhibit rich higher-order organizational\nstructures that are exposed by clustering based on higher-order connectivity\npatterns. \n\n"}
{"id": "1612.08884", "contents": "Title: Middlemen and Contestation in Directed Networks Abstract: This paper studies critical nodes or \"middlemen\" that intermediate flows in a\ndirected network. The contestability of a node is introduced as a network\ntopological concept of competitiveness meaning that an intermediary's role in\nthe brokering of flows in the network can be substituted by a group of other\nnodes. We establish the equivalence of uncontested intermediaries and\nmiddlemen.\n  The notion of node contestability gives rise to a measure that quantifies the\ncontrol exercised by a middleman in a network. We present a comparison of this\nmiddleman centrality measures with relevant, established network centrality\nmeasures. Furthermore, we provide concepts and measures expressing the\nrobustness of a middleman as the number of links or nodes that have to be added\nto or removed from the network to nullify the middleman's power.\n  We use these concepts to identify and measure middleman power and robustness\nin two empirical networks: Krackhardt's advice network of managers in a medium\nsized corporation and the well-known Florentine marriage network as a proxy of\npower brokerage between houses in Renaissance Florence. \n\n"}
{"id": "1612.09522", "contents": "Title: Redundancy and synergy in dual decompositions of mutual information gain\n  and information loss Abstract: Williams and Beer (2010) proposed a nonnegative mutual information\ndecomposition, based on the construction of information gain lattices, which\nallows separating the information that a set of variables contains about\nanother into components interpretable as the unique information of one\nvariable, or redundant and synergy components. In this work we extend the\nframework of Williams and Beer (2010) focusing on the lattices that underpin\nthe decomposition. We generalize the type of constructible lattices and examine\nthe relations between the terms in different lattices, for example relating\nbivariate and trivariate decompositions. We point out that, in information gain\nlattices, redundancy components are invariant across decompositions, but unique\nand synergy components are decomposition-dependent. Exploiting the connection\nbetween different lattices we propose a procedure to construct, in the general\nmultivariate case, information decompositions from measures of synergy or\nunique information. We introduce an alternative type of mutual information\ndecompositions based on information loss lattices, with the role and invariance\nproperties of redundancy and synergy components exchanged with respect to gain\nlattices. We study the correspondence between information gain and information\nloss lattices and we define dual decompositions that allow overcoming the\nintrinsic asymmetry between invariant and decomposition-dependent components,\nwhich hinders the consistent joint characterization of synergy and redundancy. \n\n"}
{"id": "1701.00406", "contents": "Title: Raising Graphs From Randomness to Reveal Information Networks Abstract: We analyze the fine-grained connections between the average degree and the\npower-law degree distribution exponent in growing information networks. Our\nstarting observation is a power-law degree distribution with a decreasing\nexponent and increasing average degree as a function of the network size. Our\nexperiments are based on three Twitter at-mention networks and three more from\nthe Koblenz Network Collection. We observe that popular network models cannot\nexplain decreasing power-law degree distribution exponent and increasing\naverage degree at the same time.\n  We propose a model that is the combination of exponential growth, and a\npower-law developing network, in which new \"homophily\" edges are continuously\nadded to nodes proportional to their current homophily degree. Parameters of\nthe average degree growth and the power-law degree distribution exponent\nfunctions depend on the ratio of the network growth exponent parameters.\nSpecifically, we connect the growth of the average degree to the decreasing\nexponent of the power-law degree distribution. Prior to our work, only one of\nthe two cases were handled. Existing models and even their combinations can\nonly reproduce some of our key new observations in growing information\nnetworks. \n\n"}
{"id": "1701.00568", "contents": "Title: Versatility of nodal affiliation to communities Abstract: Graph theoretical analysis of the community structure of networks attempts to\nidentify the communities (or modules) to which each node affiliates. However,\nthis is in most cases an ill-posed problem, as the affiliation of a node to a\nsingle community is often ambiguous. Previous solutions have attempted to\nidentify all of the communities to which each node affiliates. Instead of\ntaking this approach, we introduce versatility, $V$, as a novel metric of nodal\naffiliation: $V \\sim 0$ means that a node is consistently assigned to a\nspecific community; $V \\gg 0$ means it is inconsistently assigned to different\ncommunities. Versatility works in conjunction with existing community detection\nalgorithms, and it satisfies many theoretically desirable properties in\nidealised networks designed to maximise ambiguity of modular decomposition. The\nlocal minima of global mean versatility identified the resolution parameters of\na hierarchical community detection algorithm that least ambiguously decomposed\nthe community structure of a social (karate club) network and the mouse brain\nconnectome. Our results suggest that nodal versatility is useful in quantifying\nthe inherent ambiguity of modular decomposition. \n\n"}
{"id": "1701.02621", "contents": "Title: Geometric vulnerability of democratic institutions against lobbying: a\n  sociophysics approach Abstract: An alternative voting scheme is proposed to fill the democratic gap between a\npresident elected democratically via universal suffrage (deterministic outcome,\nthe actual majority decides), and a president elected by one person randomly\nselected from the population (probabilistic outcome depending on respective\nsupports). Moving from one voting agent to a group of r randomly selected\nvoting agents reduces the probabilistic character of the outcome. Building r\nsuch groups, each one electing its president, to constitute a group of the\ngroups with the r local presidents electing a higher-level president, does\nreduce further the outcome probabilistic aspect. Repeating the process n times\nleads to a n-level bottom-up pyramidal structure. The hierarchy top president\nis still elected with a probability but the distance from a deterministic\noutcome reduces quickly with increasing n. At a critical value n_{c,r} the\noutcome turns deterministic recovering the same result a universal suffrage\nwould yield. The scheme yields several social advantages like the distribution\nof local power to the competing minority making the structure more resilient,\nyet preserving the presidency allocation to the actual majority. An area is\nproduced around fifty percent for which the president is elected with an almost\nequiprobability slightly biased in favor of the actual majority. However, our\nresults reveal the existence of a severe geometric vulnerability to lobbying. A\ntiny lobbying group is able to kill the democratic balance by seizing the\npresidency democratically. It is sufficient to complete a correlated\ndistribution of a few agents at the hierarchy bottom. Moreover, at the present\nstage, identifying an actual killing distribution is not feasible, which sheds\na disturbing light on the devastating effect geometric lobbying can have on\ndemocratic hierarchical institutions. \n\n"}
{"id": "1701.03259", "contents": "Title: Multitarget search on complex networks: A logarithmic growth of global\n  mean random cover time Abstract: We investigate multitarget search on complex networks and derive an exact\nexpression for the mean random cover time that quantifies the expected time a\nwalker needs to visit multiple targets. Based on this, we recover and extend\nsome interesting results of multitarget search on networks. Specifically, we\nobserve the logarithmic increase of the global mean random cover time with the\ntarget number for a broad range of random search processes, including generic\nrandom walks, biased random walks, and maximal entropy random walks. We show\nthat the logarithmic growth pattern is a universal feature of multi-target\nsearch on networks by using the annealed network approach and the\nSherman-Morrison formula. Moreover, we find that for biased random walks, the\nglobal mean random cover time can be minimized, and that the corresponding\noptimal parameter also minimizes the global mean first passage time, pointing\ntowards its robustness. Our findings further confirm that the logarithmic\ngrowth pattern is a universal law governing multitarget search in confined\nmedia. \n\n"}
{"id": "1701.04939", "contents": "Title: Ensemble of Thermostatically Controlled Loads: Statistical Physics\n  Approach Abstract: Thermostatically Controlled Loads (TCL), e.g. air-conditioners and heaters,\nare by far the most wide-spread consumers of electricity. Normally the devices\nare calibrated to provide the so-called bang-bang control of temperature --\nchanging from on to off, and vice versa, depending on temperature. Aggregation\nof a large group of similar devices into a statistical ensemble is considered,\nwhere the devices operate following the same dynamics subject to stochastic\nperturbations and randomized, Poisson on/off switching policy. We analyze,\nusing theoretical and computational tools of statistical physics, how the\nensemble relaxes to a stationary distribution and establish relation between\nthe relaxation and statistics of the probability flux, associated with devices'\ncycling in the mixed (discrete, switch on/off, and continuous, temperature)\nphase space. This allowed us to derive and analyze spectrum of the\nnon-equilibrium (detailed balance broken) statistical system and uncover how\nswitching policy affects oscillatory trend and speed of the relaxation.\nRelaxation of the ensemble is of a practical interest because it describes how\nthe ensemble recovers from significant perturbations, e.g. forceful temporary\nswitching off aimed at utilizing flexibility of the ensemble in providing\n\"demand response\" services relieving consumption temporarily to balance larger\npower grid. We discuss how the statistical analysis can guide further\ndevelopment of the emerging demand response technology. \n\n"}
{"id": "1701.06265", "contents": "Title: Importance Sampling of Rare Events in Chaotic Systems Abstract: Finding and sampling rare trajectories in dynamical systems is a difficult\ncomputational task underlying numerous problems and applications. In this paper\nwe show how to construct Metropolis- Hastings Monte Carlo methods that can\nefficiently sample rare trajectories in the (extremely rough) phase space of\nchaotic systems. As examples of our general framework we compute the\ndistribution of finite-time Lyapunov exponents (in different chaotic maps) and\nthe distribution of escape times (in transient-chaos problems). Our methods\nsample exponentially rare states in polynomial number of samples (in both low-\nand high-dimensional systems). An open-source software that implements our\nalgorithms and reproduces our results can be found in\nhttps://github.com/jorgecarleitao/chaospp \n\n"}
{"id": "1701.06331", "contents": "Title: Higher-order models capture changes in controllability of temporal\n  networks Abstract: In many complex systems, elements interact via time-varying network\ntopologies. Recent research shows that temporal correlations in the\nchronological ordering of interactions crucially influence network properties\nand dynamical processes. How these correlations affect our ability to control\nsystems with time-varying interactions remains unclear. In this work, we use\nhigher-order network models to extend the framework of structural\ncontrollability to temporal networks, where the chronological ordering of\ninteractions gives rise to time-respecting paths with non-Markovian\ncharacteristics. We study six empirical data sets and show that non-Markovian\ncharacteristics of real systems can both increase or decrease the minimum time\nneeded to control the whole system. With both empirical data and synthetic\nmodels, we further show that spectral properties of generalisations of graph\nLaplacians to higher-order networks can be used to analytically capture the\neffect of temporal correlations on controllability. Our work highlights that\n(i) correlations in the chronological ordering of interactions are an important\nsource of complexity that significantly influences the controllability of\ntemporal networks, and (ii) higher-order network models are a powerful tool to\nunderstand the temporal-topological characteristics of empirical systems. \n\n"}
{"id": "1701.06905", "contents": "Title: Singly-Thermostated Ergodicity in Gibbs' Canonical Ensemble and the 2016\n  Ian Snook Prize Award Abstract: The 2016 Snook Prize has been awarded to Diego Tapias, Alessandro Bravetti,\nand David Sanders for their paper -- Ergodicity of One-Dimensional Systems\nCoupled to the Logistic Thermostat. They introduced a relatively stiff\nhyperbolic tangent thermostat force and successfully tested its ability to\nreproduce Gibbs' canonical distribution for the harmonic oscillator, the\nquartic oscillator, and the Mexican Hat potentials. Their work constitutes an\neffective response to the 2016 Ian Snook Prize Award goal -- Finding ergodic\nalgorithms for Gibbs' canonical ensemble using a single thermostat variable. We\nconfirm their work here and highlight an interesting feature of the Mexican Hat\nproblem when it is solved with an adaptive integrator. \n\n"}
{"id": "1702.00298", "contents": "Title: Cascading Failures in Interdependent Systems: Impact of Degree\n  Variability and Dependence Abstract: We study cascading failures in a system comprising interdependent\nnetworks/systems, in which nodes rely on other nodes both in the same system\nand in other systems to perform their function. The (inter-)dependence among\nnodes is modeled using a dependence graph, where the degree vector of a node\ndetermines the number of other nodes it can potentially cause to fail in each\nsystem through aforementioned dependency. In particular, we examine the impact\nof the variability and dependence properties of node degrees on the probability\nof cascading failures. We show that larger variability in node degrees hampers\nwidespread failures in the system, starting with random failures. Similarly,\npositive correlations in node degrees make it harder to set off an epidemic of\nfailures, thereby rendering the system more robust against random failures. \n\n"}
{"id": "1702.02048", "contents": "Title: Multiplex Network Regression: How do relations drive interactions? Abstract: We introduce a statistical regression model to investigate the impact of\ndyadic relations on complex networks generated from observed repeated\ninteractions. It is based on generalised hypergeometric ensembles (gHypEG), a\nclass of statistical network ensembles developed recently to deal with\nmulti-edge graph and count data. We represent different types of known\nrelations between system elements by weighted graphs, separated in the\ndifferent layers of a multiplex network. With our method, we can regress the\ninfluence of each relational layer, the explanatory variables, on the\ninteraction counts, the dependent variables. Moreover, we can quantify the\nstatistical significance of the relations as explanatory variables for the\nobserved interactions. To demonstrate the power of our approach, we investigate\nan example based on empirical data. \n\n"}
{"id": "1702.02527", "contents": "Title: Control of multidimensional systems on complex network Abstract: Multidimensional systems coupled via complex networks are widespread in\nnature and thus frequently invoked for a large plethora of interesting\napplications. From ecology to physics, individual entities in mutual\ninteractions are grouped in families, homogeneous in kind. These latter\ninteract selectively, through a sequence of self-consistently regulated steps,\nwhose deeply rooted architecture is stored in the assigned matrix of\nconnections. The asymptotic equilibrium eventually attained by the system, and\nits associated stability, can be assessed by employing standard nonlinear\ndynamics tools. For many practical applications, it is however important to\nexternally drive the system towards a desired equilibrium, which is resilient,\nhence stable, to external perturbations. To this end we here consider a system\nmade up of $N$ interacting populations which evolve according to general rate\nequations, bearing attributes of universality. One species is added to the pool\nof interacting families and used as a dynamical controller to induce novel\nstable equilibria. Use can be made of the root locus method to shape the needed\ncontrol, in terms of intrinsic reactivity and adopted protocol of injection.\nThe proposed method is tested on both synthetic and real data, thus enabling to\ndemonstrate its robustness and versatility. \n\n"}
{"id": "1702.03286", "contents": "Title: The Beneficial Role of Mobility for the Emergence of Innovation Abstract: Innovation is a key ingredient for the evolution of several systems,\nincluding social and biological ones. Focused investigations and lateral\nthinking may lead to innovation, as well as serendipity and other random\ndiscovery processes. Some individuals are talented at proposing innovation (say\ninnovators), while others at deeply exploring proposed novelties, at getting\nfurther insights on a theory, or at developing products, services, and so on\n(say developers). This separation in terms of innovators and developers raises\nan issue of paramount importance: under which conditions a system is able to\nmaintain innovators? According to a simple model, this work investigates the\nevolutionary dynamics that characterize the emergence of innovation. In\nparticular, we consider a population of innovators and developers, in which\nagents form small groups whose composition is crucial for their payoff. The\nlatter depends on the heterogeneity of the formed groups, on the amount of\ninnovators they include, and on an award-factor that represents the policy of\nthe system for promoting innovation. Under the hypothesis that a \"mobility\"\neffect may support the emergence of innovation, we compare the equilibria\nreached by our population in different cases. Results confirm the beneficial\nrole of \"mobility\", and the emergence of further interesting phenomena. \n\n"}
{"id": "1702.04686", "contents": "Title: Support Vector Machines and generalisation in HEP Abstract: We review the concept of Support Vector Machines (SVMs) and discuss examples\nof their use in a number of scenarios. Several SVM implementations have been\nused in HEP and we exemplify this algorithm using the Toolkit for Multivariate\nAnalysis (TMVA) implementation. We discuss examples relevant to HEP including\nbackground suppression for $H\\to\\tau^+\\tau^-$ at the LHC with several different\nkernel functions. Performance benchmarking leads to the issue of generalisation\nof hyper-parameter selection. The avoidance of fine tuning (over training or\nover fitting) in MVA hyper-parameter optimisation, i.e. the ability to ensure\ngeneralised performance of an MVA that is independent of the training,\nvalidation and test samples, is of utmost importance. We discuss this issue and\ncompare and contrast performance of hold-out and k-fold cross-validation. We\nhave extended the SVM functionality and introduced tools to facilitate cross\nvalidation in TMVA and present results based on these improvements. \n\n"}
{"id": "1702.05054", "contents": "Title: Concurrency-induced transitions in epidemic dynamics on temporal\n  networks Abstract: Social contact networks underlying epidemic processes in humans and animals\nare highly dynamic. The spreading of infections on such temporal networks can\ndiffer dramatically from spreading on static networks. We theoretically\ninvestigate the effects of concurrency, the number of neighbors that a node has\nat a given time point, on the epidemic threshold in the stochastic\nsusceptible-infected-susceptible dynamics on temporal network models. We show\nthat network dynamics can suppress epidemics (i.e., yield a higher epidemic\nthreshold) when the nodes' concurrency is low, but can also enhance epidemics\nwhen the concurrency is high. We analytically determine different phases of\nthis concurrency-induced transition, and confirm our results with numerical\nsimulations. \n\n"}
{"id": "1702.05695", "contents": "Title: Non-negative Tensor Factorization for Human Behavioral Pattern Mining in\n  Online Games Abstract: Multiplayer online battle arena has become a popular game genre. It also\nreceived increasing attention from our research community because they provide\na wealth of information about human interactions and behaviors. A major problem\nis extracting meaningful patterns of activity from this type of data, in a way\nthat is also easy to interpret. Here, we propose to exploit tensor\ndecomposition techniques, and in particular Non-negative Tensor Factorization,\nto discover hidden correlated behavioral patterns of play in a popular game:\nLeague of Legends. We first collect the entire gaming history of a group of\nabout one thousand players, totaling roughly $100K$ matches. By applying our\nmethodological framework, we then separate players into groups that exhibit\nsimilar features and playing strategies, as well as similar temporal\ntrajectories, i.e., behavioral progressions over the course of their gaming\nhistory: this will allow us to investigate how players learn and improve their\nskills. \n\n"}
{"id": "1703.01501", "contents": "Title: Opinion dynamics model based on cognitive biases Abstract: We present an introduction to a novel model of an individual and group\nopinion dynamics, taking into account different ways in which different sources\nof information are filtered due to cognitive biases. The agent based model,\nusing Bayesian updating of the individual belief distribution, is based on the\nrecent psychology work by Dan Kahan. Open nature of the model allows to study\nthe effects of both static and time-dependent biases and information processing\nfilters. In particular, the paper compares the effects of two important\npsychological mechanisms: the confirmation bias and the politically motivated\nreasoning. Depending on the effectiveness of the information filtering (agent\nbias), the agents confronted with an objective information source may either\nreach a consensus based on the truth, or remain divided despite the evidence.\nIn general, the model might provide an understanding into the increasingly\npolarized modern societies, especially as it allows mixing of different types\nof filters: psychological, social, and algorithmic. \n\n"}
{"id": "1703.02906", "contents": "Title: Modeling the Spread of Multiple Contagions on Multilayer Networks Abstract: A susceptible-infected-susceptible (SIS) model of multiple contagions on\nmultilayer networks is developed to incorporate different spreading channels\nand disease mutations. The basic reproduction number for this model is\nestimated analytically. In a special case when considering only compartmental\nmodels, we analytically analyze an example of a model with a mutation driven\nstrain persistence characterized by the absence of an epidemic threshold. This\nmodel is not related to the network topology and can be observed in both\ncompartmental models and models on networks. The novel multiple-contagion SIS\nmodel on a multilayer network could help in the understanding of other\nspreading phenomena including communicable diseases, cultural characteristics,\naddictions, or information spread through e-mail messages, web blogs, and\ncomputer networks. \n\n"}
{"id": "1703.03366", "contents": "Title: Knowledge Acquisition: A Complex Networks Approach Abstract: Complex networks have been found to provide a good representation of the\nstructure of knowledge, as understood in terms of discoverable concepts and\ntheir relationships. In this context, the discovery process can be modeled as\nagents walking in a knowledge space. Recent studies proposed more realistic\ndynamics, including the possibility of agents being influenced by others with\nhigher visibility or by their own memory. However, rather than dealing with\nthese two concepts separately, as previously approached, in this study we\npropose a multi-agent random walk model for knowledge acquisition that\nincorporates both concepts. More specifically, we employed the true self\navoiding walk alongside a new dynamics based on jumps, in which agents are\nattracted by the influence of others. That was achieved by using a L\\'evy\nflight influenced by a field of attraction emanating from the agents. In order\nto evaluate our approach, we use a set of network models and two real networks,\none generated from Wikipedia and another from the Web of Science. The results\nwere analyzed globally and by regions. In the global analysis, we found that\nmost of the dynamics parameters do not significantly affect the discovery\ndynamics. The local analysis revealed a substantial difference of performance\ndepending on the network regions where the dynamics are occurring. In\nparticular, the dynamics at the core of networks tend to be more effective. The\nchoice of the dynamics parameters also had no significant impact to the\nacquisition performance for the considered knowledge networks, even at the\nlocal scale. \n\n"}
{"id": "1703.04385", "contents": "Title: Topological Data Analysis of Financial Time Series: Landscapes of\n  Crashes Abstract: We explore the evolution of daily returns of four major US stock market\nindices during the technology crash of 2000, and the financial crisis of\n2007-2009. Our methodology is based on topological data analysis (TDA). We use\npersistence homology to detect and quantify topological patterns that appear in\nmultidimensional time series. Using a sliding window, we extract time-dependent\npoint cloud data sets, to which we associate a topological space. We detect\ntransient loops that appear in this space, and we measure their persistence.\nThis is encoded in real-valued functions referred to as a 'persistence\nlandscapes'. We quantify the temporal changes in persistence landscapes via\ntheir $L^p$-norms. We test this procedure on multidimensional time series\ngenerated by various non-linear and non-equilibrium models. We find that, in\nthe vicinity of financial meltdowns, the $L^p$-norms exhibit strong growth\nprior to the primary peak, which ascends during a crash. Remarkably, the\naverage spectral density at low frequencies of the time series of $L^p$-norms\nof the persistence landscapes demonstrates a strong rising trend for 250\ntrading days prior to either dotcom crash on 03/10/2000, or to the Lehman\nbankruptcy on 09/15/2008. Our study suggests that TDA provides a new type of\neconometric analysis, which goes beyond the standard statistical measures. The\nmethod can be used to detect early warning signals of imminent market crashes.\nWe believe that this approach can be used beyond the analysis of financial time\nseries presented here. \n\n"}
{"id": "1703.05833", "contents": "Title: Centralities of Nodes and Influences of Layers in Large Multiplex\n  Networks Abstract: We formulate and propose an algorithm (MultiRank) for the ranking of nodes\nand layers in large multiplex networks. MultiRank takes into account the full\nmultiplex network structure of the data and exploits the dual nature of the\nnetwork in terms of nodes and layers. The proposed centrality of the layers\n(influences) and the centrality of the nodes are determined by a coupled set of\nequations. The basic idea consists in assigning more centrality to nodes that\nreceive links from highly influential layers and from already central nodes.\nThe layers are more influential if highly central nodes are active in them. The\nalgorithm applies to directed/undirected as well as to weighted/unweighted\nmultiplex networks. We discuss the application of MultiRank to three major\nexamples of multiplex network datasets: the European Air Transportation\nMultiplex Network, the Pierre Auger Multiplex Collaboration Network and the FAO\nMultiplex Trade Network. \n\n"}
{"id": "1703.06091", "contents": "Title: Frequency-based brain networks: From a multiplex framework to a full\n  multilayer description Abstract: We explore how to study dynamical interactions between brain regions using\nfunctional multilayer networks whose layers represent the different frequency\nbands at which a brain operates. Specifically, we investigate the consequences\nof considering the brain as a multilayer network in which all brain regions can\ninteract with each other at different frequency bands, instead of as a\nmultiplex network, in which interactions between different frequency bands are\nonly allowed within each brain region and not between them. We study the second\nsmallest eigenvalue of the combinatorial supra-Laplacian matrix of the\nmultilayer network in detail, and we thereby show that the heterogeneity of\ninterlayer edges and, especially, the fraction of missing edges crucially\nmodify the spectral properties of the multilayer network. We illustrate our\nresults with both synthetic network models and real data sets obtained from\nresting state magnetoencephalography. Our work demonstrates an important issue\nin the construction of frequency-based multilayer brain networks. \n\n"}
{"id": "1703.07001", "contents": "Title: Recovery of the starting times of delayed signals Abstract: We present a new method to locate the starting points in time of an arbitrary\nnumber of (damped) delayed signals. For a finite data sequence, the method\npermits to first locate the starting point of the component with the longest\ndelay, and then --by iteration-- all the preceding ones. Numerical examples are\ngiven and noise sensitivity is tested for weak noise. \n\n"}
{"id": "1703.08643", "contents": "Title: Real-space analysis of scanning tunneling microscopy topography datasets\n  using sparse modeling approach Abstract: A sparse modeling approach is proposed for analyzing scanning tunneling\nmicroscopy topography data, which contains numerous peaks corresponding to\nsurface atoms. The method, based on the relevance vector machine with\n$\\mathrm{L}_1$ regularization and $k$-means clustering, enables separation of\nthe peaks and atomic center positioning with accuracy beyond the resolution of\nthe measurement grid. The validity and efficiency of the proposed method are\ndemonstrated using synthetic data in comparison to the conventional\nleast-square method. An application of the proposed method to experimental data\nof a metallic oxide thin film clearly indicates the existence of defects and\ncorresponding local lattice deformations. \n\n"}
{"id": "1703.09710", "contents": "Title: Fast and scalable Gaussian process modeling with applications to\n  astronomical time series Abstract: The growing field of large-scale time domain astronomy requires methods for\nprobabilistic data analysis that are computationally tractable, even with large\ndatasets. Gaussian Processes are a popular class of models used for this\npurpose but, since the computational cost scales, in general, as the cube of\nthe number of data points, their application has been limited to small\ndatasets. In this paper, we present a novel method for Gaussian Process\nmodeling in one-dimension where the computational requirements scale linearly\nwith the size of the dataset. We demonstrate the method by applying it to\nsimulated and real astronomical time series datasets. These demonstrations are\nexamples of probabilistic inference of stellar rotation periods, asteroseismic\noscillation spectra, and transiting planet parameters. The method exploits\nstructure in the problem when the covariance function is expressed as a mixture\nof complex exponentials, without requiring evenly spaced observations or\nuniform noise. This form of covariance arises naturally when the process is a\nmixture of stochastically-driven damped harmonic oscillators -- providing a\nphysical motivation for and interpretation of this choice -- but we also\ndemonstrate that it can be a useful effective model in some other cases. We\npresent a mathematical description of the method and compare it to existing\nscalable Gaussian Process methods. The method is fast and interpretable, with a\nrange of potential applications within astronomical data analysis and beyond.\nWe provide well-tested and documented open-source implementations of this\nmethod in C++, Python, and Julia. \n\n"}
{"id": "1704.02890", "contents": "Title: Opinion Polarization by Learning from Social Feedback Abstract: We explore a new mechanism to explain polarization phenomena in opinion\ndynamics in which agents evaluate alternative views on the basis of the social\nfeedback obtained on expressing them. High support of the favored opinion in\nthe social environment, is treated as a positive feedback which reinforces the\nvalue associated to this opinion. In connected networks of sufficiently high\nmodularity, different groups of agents can form strong convictions of competing\nopinions. Linking the social feedback process to standard equilibrium concepts\nwe analytically characterize sufficient conditions for the stability of\nbi-polarization. While previous models have emphasized the polarization effects\nof deliberative argument-based communication, our model highlights an affective\nexperience-based route to polarization, without assumptions about negative\ninfluence or bounded confidence. \n\n"}
{"id": "1704.05540", "contents": "Title: Combining parameter values or $p$-values Abstract: We review the methods to combine several measurements, in the form of\nparameter values or $p$-values. \n\n"}
{"id": "1704.07171", "contents": "Title: Exploring the Evolution of Node Neighborhoods in Dynamic Networks Abstract: Dynamic Networks are a popular way of modeling and studying the behavior of\nevolving systems. However, their analysis constitutes a relatively recent\nsubfield of Network Science, and the number of available tools is consequently\nmuch smaller than for static networks. In this work, we propose a method\nspecifically designed to take advantage of the longitudinal nature of dynamic\nnetworks. It characterizes each individual node by studying the evolution of\nits direct neighborhood, based on the assumption that the way this neighborhood\nchanges reflects the role and position of the node in the whole network. For\nthis purpose, we define the concept of \\textit{neighborhood event}, which\ncorresponds to the various transformations such groups of nodes can undergo,\nand describe an algorithm for detecting such events. We demonstrate the\ninterest of our method on three real-world networks: DBLP, LastFM and Enron. We\napply frequent pattern mining to extract meaningful information from temporal\nsequences of neighborhood events. This results in the identification of\nbehavioral trends emerging in the whole network, as well as the individual\ncharacterization of specific nodes. We also perform a cluster analysis, which\nreveals that, in all three networks, one can distinguish two types of nodes\nexhibiting different behaviors: a very small group of active nodes, whose\nneighborhood undergo diverse and frequent events, and a very large group of\nstable nodes. \n\n"}
{"id": "1705.00241", "contents": "Title: Dynamic interdependence and competition in multilayer networks Abstract: From critical infrastructure, to physiology and the human brain, complex\nsystems rarely occur in isolation. Instead, the functioning of nodes in one\nsystem often promotes or suppresses the functioning of nodes in another.\nDespite advances in structural interdependence, modeling interdependence and\nother interactions between dynamic systems has proven elusive. Here we define a\nbroadly applicable dynamic dependency link and develop a general framework for\ninterdependent and competitive interactions between general dynamic systems. We\napply our framework to studying interdependent and competitive synchronization\nin multi-layer oscillator networks and cooperative/competitive contagions in an\nepidemic model. Using a mean-field theory which we verify numerically, we find\nexplosive transitions and rich behavior which is absent in percolation models\nincluding hysteresis, multi-stability and chaos. The framework presented here\nprovides a powerful new way to model and understand many of the interacting\ncomplex systems which surround us. \n\n"}
{"id": "1705.00545", "contents": "Title: Labelled network subgraphs reveal stylistic subtleties in written texts Abstract: The vast amount of data and increase of computational capacity have allowed\nthe analysis of texts from several perspectives, including the representation\nof texts as complex networks. Nodes of the network represent the words, and\nedges represent some relationship, usually word co-occurrence. Even though\nnetworked representations have been applied to study some tasks, such\napproaches are not usually combined with traditional models relying upon\nstatistical paradigms. Because networked models are able to grasp textual\npatterns, we devised a hybrid classifier, called labelled subgraphs, that\ncombines the frequency of common words with small structures found in the\ntopology of the network, known as motifs. Our approach is illustrated in two\ncontexts, authorship attribution and translationese identification. In the\nformer, a set of novels written by different authors is analyzed. To identify\ntranslationese, texts from the Canadian Hansard and the European parliament\nwere classified as to original and translated instances. Our results suggest\nthat labelled subgraphs are able to represent texts and it should be further\nexplored in other tasks, such as the analysis of text complexity, language\nproficiency, and machine translation. \n\n"}
{"id": "1705.01068", "contents": "Title: Importance-sampling computation of statistical properties of coupled\n  oscillators Abstract: We introduce and implement an importance-sampling Monte Carlo algorithm to\nstudy systems of globally-coupled oscillators. Our computational method\nefficiently obtains estimates of the tails of the distribution of various\nmeasures of dynamical trajectories corresponding to states occurring with\n(exponentially) small probabilities. We demonstrate the general validity of our\nresults by applying the method to two contrasting cases: the driven-dissipative\nKuramoto model, a paradigm in the study of spontaneous synchronization; and the\nconservative Hamiltonian mean-field model, a prototypical system of long-range\ninteractions. We present results for the distribution of the finite-time\nLyapunov exponent and a time-averaged order parameter. Among other features,\nour results show most notably that the distributions exhibit a vanishing\nstandard deviation but a skewness that is increasing in magnitude with the\nnumber of oscillators, implying that non-trivial asymmetries and states\nyielding rare/atypical values of the observables persist even for a large\nnumber of oscillators. \n\n"}
{"id": "1705.04319", "contents": "Title: Anomalous slowing down of individual human activity due to successive\n  decision-making processes Abstract: Motivated by a host of empirical evidences revealing the bursty character of\nhuman dynamics, we develop a model of human activity based on successive\nswitching between an hesitation state and a decision-realization state, with\nresidency times in the hesitation state distributed according to a heavy-tailed\nPareto distribution. This model is particularly reminiscent of an individual\nstrolling through a randomly distributed human crowd. Using a stochastic model\nbased on the concept of anomalous and non-Markovian L\\'evy walk, we show\nexactly that successive decision-making processes drastically slow down the\nprogression of an individual faced with randomly distributed obstacles.\nSpecifically, we prove exactly that the average displacement exhibits a\nsublinear scaling with time that finds its origins in: (i) the intrinsically\nnon-Markovian character of human activity, and (ii) the power law distribution\nof hesitation times. \n\n"}
{"id": "1705.04353", "contents": "Title: On the records Abstract: World record setting has long attracted public interest and scientific\ninvestigation. Extremal records summarize the limits of the space explored by a\nprocess, and the historical progression of a record sheds light on the\nunderlying dynamics of the process. Existing analyses of prediction,\nstatistical properties, and ultimate limits of record progressions have focused\non particular domains. However, a broad perspective on how record progressions\nvary across different spheres of activity needs further development. Here we\nemploy cross-cutting metrics to compare records across a variety of domains,\nincluding sports, games, biological evolution, and technological development.\nWe find that these domains exhibit characteristic statistical signatures in\nterms of rates of improvement, \"burstiness\" of record-breaking time series, and\nthe acceleration of the record breaking process. Specifically, sports and games\nexhibit the slowest rate of improvement and a wide range of rates of\n\"burstiness.\" Technology improves at a much faster rate and, unlike other\ndomains, tends to show acceleration in records. Many biological and\ntechnological processes are characterized by constant rates of improvement,\nshowing less burstiness than sports and games. It is important to understand\nhow these statistical properties of record progression emerge from the\nunderlying dynamics. Towards this end, we conduct a detailed analysis of a\nparticular record-setting event: elite marathon running. In this domain, we\nfind that studying record-setting data alone can obscure many of the structural\nproperties of the underlying process. The marathon study also illustrates how\nsome of the standard statistical assumptions underlying record progression\nmodels may be inappropriate or commonly violated in real-world datasets. \n\n"}
{"id": "1705.05946", "contents": "Title: Optimal segmentation of directed graph and the minimum number of\n  feedback arcs Abstract: The minimum feedback arc set problem asks to delete a minimum number of arcs\n(directed edges) from a digraph (directed graph) to make it free of any\ndirected cycles. In this work we approach this fundamental cycle-constrained\noptimization problem by considering a generalized task of dividing the digraph\ninto D layers of equal size. We solve the D-segmentation problem by the\nreplica-symmetric mean field theory and belief-propagation heuristic\nalgorithms. The minimum feedback arc density of a given random digraph ensemble\nis then obtained by extrapolating the theoretical results to the limit of large\nD. A divide-and-conquer algorithm (nested-BPR) is devised to solve the minimum\nfeedback arc set problem with very good performance and high efficiency. \n\n"}
{"id": "1705.06768", "contents": "Title: The careless use of language in quantum information Abstract: An imperative aspect of modern science is that scientific institutions act\nfor the benefit of a common scientific enterprise, rather than for the personal\ngain of individuals within them. This implies that science should not\nperpetuate existing or historical unequal social orders. Some scientific\nterminology, though, gives a very different impression. I will give two\nexamples of terminology invented recently for the field of quantum information\nwhich use language associated with subordination, slavery, and racial\nsegregation: 'ancilla qubit' and 'quantum supremacy'. \n\n"}
{"id": "1705.07894", "contents": "Title: Immediate deployment opportunities for negative emissions with BECCS: a\n  Swedish case study Abstract: To meet the 2{\\deg}C target and, in particular the 1.5{\\deg}C target defined\nin the Paris Agreement, rapid scaling-up of BECCS (Bio-Energy with Carbon\nCapture and Storage) and other negative emissions technologies (NETs) is\nessential. Recent research on BECCS has mainly focused on biophysical and\nsustainability limitations to multi-Gigatonne deployment in the latter half of\nthis century. However, this paper focuses on the critical short-term\nopportunities for immediate deployment, considering solely existing bio-energy\nfacilities in Sweden as a case study. We show that the immediate potential for\nBECCS in this country amounts to 20 Mt annually. This corresponds to 39% of\ntotal GHG emissions in 2014 in Sweden. The current costs for implementing BECCS\nat this level is compared to the present carbon taxes and other incentives. We\nshow that including BECCS in the carbon tax incentive mechanism at current\nincentive levels would yield 16.7 Mt of negative emissions annually with an\nestimated societal cost saving of more than 600 M e annually, when compared to\ncurrent incentive marginal abatement costs. We conclude that Sweden is ideally\npositioned for immediate BECCS deployment. \n\n"}
{"id": "1705.08042", "contents": "Title: Spectral Simplicity of Apparent Complexity, Part I: The\n  Nondiagonalizable Metadynamics of Prediction Abstract: Virtually all questions that one can ask about the behavioral and structural\ncomplexity of a stochastic process reduce to a linear algebraic framing of a\ntime evolution governed by an appropriate hidden-Markov process generator. Each\ntype of question---correlation, predictability, predictive cost, observer\nsynchronization, and the like---induces a distinct generator class. Answers are\nthen functions of the class-appropriate transition dynamic. Unfortunately,\nthese dynamics are generically nonnormal, nondiagonalizable, singular, and so\non. Tractably analyzing these dynamics relies on adapting the recently\nintroduced meromorphic functional calculus, which specifies the spectral\ndecomposition of functions of nondiagonalizable linear operators, even when the\nfunction poles and zeros coincide with the operator's spectrum. Along the way,\nwe establish special properties of the projection operators that demonstrate\nhow they capture the organization of subprocesses within a complex system.\nCircumventing the spurious infinities of alternative calculi, this leads in the\nsequel, Part II, to the first closed-form expressions for complexity measures,\ncouched either in terms of the Drazin inverse (negative-one power of a singular\noperator) or the eigenvalues and projection operators of the appropriate\ntransition dynamic. \n\n"}
{"id": "1705.10225", "contents": "Title: Bayesian stochastic blockmodeling Abstract: This chapter provides a self-contained introduction to the use of Bayesian\ninference to extract large-scale modular structures from network data, based on\nthe stochastic blockmodel (SBM), as well as its degree-corrected and\noverlapping generalizations. We focus on nonparametric formulations that allow\ntheir inference in a manner that prevents overfitting, and enables model\nselection. We discuss aspects of the choice of priors, in particular how to\navoid underfitting via increased Bayesian hierarchies, and we contrast the task\nof sampling network partitions from the posterior distribution with finding the\nsingle point estimate that maximizes it, while describing efficient algorithms\nto perform either one. We also show how inferring the SBM can be used to\npredict missing and spurious links, and shed light on the fundamental\nlimitations of the detectability of modular structures in networks. \n\n"}
{"id": "1706.00883", "contents": "Title: Spectral Simplicity of Apparent Complexity, Part II: Exact Complexities\n  and Complexity Spectra Abstract: The meromorphic functional calculus developed in Part I overcomes the\nnondiagonalizability of linear operators that arises often in the temporal\nevolution of complex systems and is generic to the metadynamics of predicting\ntheir behavior. Using the resulting spectral decomposition, we derive\nclosed-form expressions for correlation functions, finite-length Shannon\nentropy-rate approximates, asymptotic entropy rate, excess entropy, transient\ninformation, transient and asymptotic state uncertainty, and synchronization\ninformation of stochastic processes generated by finite-state hidden Markov\nmodels. This introduces analytical tractability to investigating information\nprocessing in discrete-event stochastic processes, symbolic dynamics, and\nchaotic dynamical systems. Comparisons reveal mathematical similarities between\ncomplexity measures originally thought to capture distinct informational and\ncomputational properties. We also introduce a new kind of spectral analysis via\ncoronal spectrograms and the frequency-dependent spectra of past-future mutual\ninformation. We analyze a number of examples to illustrate the methods,\nemphasizing processes with multivariate dependencies beyond pairwise\ncorrelation. An appendix presents spectral decomposition calculations for one\nexample in full detail. \n\n"}
{"id": "1706.01143", "contents": "Title: Graphons: A Nonparametric Method to Model, Estimate, and Design\n  Algorithms for Massive Networks Abstract: Many social and economic systems are naturally represented as networks, from\noff-line and on-line social networks, to bipartite networks, like Netflix and\nAmazon, between consumers and products. Graphons, developed as limits of\ngraphs, form a natural, nonparametric method to describe and estimate large\nnetworks like Facebook and LinkedIn. Here we describe the development of the\ntheory of graphons, for both dense and sparse networks, over the last decade.\nWe also review theorems showing that we can consistently estimate graphons from\nmassive networks in a wide variety of models. Finally, we show how to use\ngraphons to estimate missing links in a sparse network, which has applications\nfrom estimating social and information networks in development economics, to\nrigorously and efficiently doing collaborative filtering with applications to\nmovie recommendations in Netflix and product suggestions in Amazon. \n\n"}
{"id": "1706.01878", "contents": "Title: Yadage and Packtivity - analysis preservation using parametrized\n  workflows Abstract: Preserving data analyses produced by the collaborations at LHC in a\nparametrized fashion is crucial in order to maintain reproducibility and\nre-usability. We argue for a declarative description in terms of individual\nprocessing steps - packtivities - linked through a dynamic directed acyclic\ngraph (DAG) and present an initial set of JSON schemas for such a description\nand an implementation - yadage - capable of executing workflows of analysis\npreserved via Linux containers. \n\n"}
{"id": "1706.02186", "contents": "Title: Hierarchical Change Point Detection on Dynamic Networks Abstract: This paper studies change point detection on networks with community\nstructures. It proposes a framework that can detect both local and global\nchanges in networks efficiently. Importantly, it can clearly distinguish the\ntwo types of changes. The framework design is generic and as such several\nstate-of-the-art change point detection algorithms can fit in this design.\nExperiments on both synthetic and real-world networks show that this framework\ncan accurately detect changes while achieving up to 800X speedup. \n\n"}
{"id": "1706.04872", "contents": "Title: Towards a theory of word order. Comment on \"Dependency distance: a new\n  perspective on syntactic patterns in natural language\" by Haitao Liu et al Abstract: Comment on \"Dependency distance: a new perspective on syntactic patterns in\nnatural language\" by Haitao Liu et al \n\n"}
{"id": "1706.07181", "contents": "Title: Equilibria, information and frustration in heterogeneous network games\n  with conflicting preferences Abstract: Interactions between people are the basis on which the structure of our\nsociety arises as a complex system and, at the same time, are the starting\npoint of any physical description of it. In the last few years, much\ntheoretical research has addressed this issue by combining the physics of\ncomplex networks with a description of interactions in terms of evolutionary\ngame theory. We here take this research a step further by introducing a most\nsalient societal factor such as the individuals' preferences, a characteristic\nthat is key to understand much of the social phenomenology these days. We\nconsider a heterogeneous, agent-based model in which agents interact\nstrategically with their neighbors but their preferences and payoffs for the\npossible actions differ. We study how such a heterogeneous network behaves\nunder evolutionary dynamics and different strategic interactions, namely\ncoordination games and best shot games. With this model we study the emergence\nof the equilibria predicted analytically in random graphs under best response\ndynamics, and we extend this test to unexplored contexts like proportional\nimitation and scale free networks. We show that some theoretically predicted\nequilibria do not arise in simulations with incomplete Information, and we\ndemonstrate the importance of the graph topology and the payoff function\nparameters for some games. Finally, we discuss our results with available\nexperimental evidence on coordination games, showing that our model agrees\nbetter with the experiment that standard economic theories, and draw hints as\nto how to maximize social efficiency in situations of conflicting preferences. \n\n"}
{"id": "1706.07896", "contents": "Title: Reservoir Computing on the Hypersphere Abstract: Reservoir Computing (RC) refers to a Recurrent Neural Networks (RNNs)\nframework, frequently used for sequence learning and time series prediction.\nThe RC system consists of a random fixed-weight RNN (the input-hidden reservoir\nlayer) and a classifier (the hidden-output readout layer). Here we focus on the\nsequence learning problem, and we explore a different approach to RC. More\nspecifically, we remove the non-linear neural activation function, and we\nconsider an orthogonal reservoir acting on normalized states on the unit\nhypersphere. Surprisingly, our numerical results show that the system's memory\ncapacity exceeds the dimensionality of the reservoir, which is the upper bound\nfor the typical RC approach based on Echo State Networks (ESNs). We also show\nhow the proposed system can be applied to symmetric cryptography problems, and\nwe include a numerical implementation. \n\n"}
{"id": "1706.07965", "contents": "Title: A two-dimensional data-driven model for traffic flow on highways Abstract: Based on experimental traffic data obtained from German and US highways, we\npropose a novel two-dimensional first-order macroscopic traffic flow model. The\ngoal is to reproduce a detailed description of traffic dynamics for the real\nroad geometry. In our approach both the dynamic along the road and across the\nlanes is continuous. The closure relations, being necessary to complete the\nhydrodynamic equation, are obtained by regression on fundamental diagram data.\nComparison with prediction of one-dimensional models shows the improvement in\nperformance of the novel model. \n\n"}
{"id": "1706.08968", "contents": "Title: Two golden times in two-step contagion models Abstract: The two-step contagion model is a simple toy model for understanding pandemic\noutbreaks that occur in the real world. The model takes into account that a\nsusceptible person either gets immediately infected or weakened when getting\ninto contact with an infectious one. As the number of weakened people\nincreases, they eventually can become infected in a short time period and a\npandemic outbreak occurs. The time required to reach such a pandemic outbreak\nallows for intervention and is often called golden time. Understanding the\nsize-dependence of the golden time is useful for controlling pandemic outbreak.\nHere we find that there exist two types of golden times in the two-step\ncontagion model, which scale as $O(N^{1/3})$ and $O(N^{\\zeta})$ with the system\nsize $N$ on Erd\\H{o}s-R\\'enyi networks, where the measured $\\zeta$ is slightly\nlarger than $1/4$. They are distinguished by the initial number of infected\nnodes, $o(N)$ and $O(N)$, respectively. While the exponent $1/3$ of the\n$N$-dependence of the golden time is universal even in other models showing\ndiscontinuous transitions induced by cascading dynamics, the measured $\\zeta$\nexponents are all close to $1/4$ but show model-dependence. It remains open\nwhether or not $\\zeta$ reduces to $1/4$ in the asymptotically large-$N$ limit. \n\n"}
{"id": "1706.09011", "contents": "Title: Multilink Communities of Multiplex Networks Abstract: Multiplex networks describe a large number of complex social, biological and\ntransportation networks where a set of nodes is connected by links of different\nnature and connotation. Here we uncover the rich community structure of\nmultiplex networks by associating a community to each multilink where the\nmultilinks characterize the connections existing between any two nodes of the\nmultiplex network. Our community detection method reveals the rich interplay\nbetween the mesoscale structure of the multiplex networks and their\nmultiplexity. For instance some nodes can belong to many layers and few\ncommunities while others can belong to few layers but many communities.\nMoreover the multilink communities can be formed by a different number of\nrelevant layers. These results point out that mesoscopically there can be large\ndifferences in the compressibility of multiplex networks. \n\n"}
{"id": "1707.04087", "contents": "Title: Zealots in the mean-field noisy voter model Abstract: The influence of zealots on the noisy voter model is studied theoretically\nand numerically at the mean-field level. The noisy voter model is a\nmodification of the voter model that includes a second mechanism for\ntransitions between states: apart from the original herding processes, voters\nmay change their states because of an intrinsic, noisy in origin source. By\nincreasing the importance of the noise with respect to the herding, the system\nexhibits a finite-size phase transition from a quasi-consensus state, where\nmost of the voters share the same opinion, to a one with coexistence. Upon\nintroducing some zealots, or voters with fixed opinion, the latter scenario may\nchange significantly. We unveil the new situations by carrying out a systematic\nnumerical and analytical study of a fully connected network for voters, but\nallowing different voters to be directly influenced by different zealots. We\nshow that this general system is equivalent to a system of voters without\nzealots, but with heterogeneous values of their parameters characterizing\nherding and noisy dynamics. We find excellent agreement between our analytical\nand numerical results. Noise and herding/zealotry acting together in the voter\nmodel yields not a trivial mixture of the scenarios with the two mechanisms\nacting alone: it represents a situation where the global-local (noise-herding)\ncompetitions is coupled to a symmetry breaking (zealots). In general, the\nzealotry enhances the effective noise of the system, which may destroy the\noriginal quasi--consensus state, and can introduce a bias towards the opinion\nof the majority of zealots, hence breaking the symmetry of the system and\ngiving rise to new phases ... \n\n"}
{"id": "1707.04459", "contents": "Title: Fast Detection of Community Structures using Graph Traversal in Social\n  Networks Abstract: Finding community structures in social networks is considered to be a\nchallenging task as many of the proposed algorithms are computationally\nexpensive and does not scale well for large graphs. Most of the community\ndetection algorithms proposed till date are unsuitable for applications that\nwould require detection of communities in real-time, especially for massive\nnetworks. The Louvain method, which uses modularity maximization to detect\nclusters, is usually considered to be one of the fastest community detection\nalgorithms even without any provable bound on its running time. We propose a\nnovel graph traversal-based community detection framework, which not only runs\nfaster than the Louvain method but also generates clusters of better quality\nfor most of the benchmark datasets. We show that our algorithms run in O(|V | +\n|E|) time to create an initial cover before using modularity maximization to\nget the final cover.\n  Keywords - community detection; Influenced Neighbor Score; brokers; community\nnodes; communities \n\n"}
{"id": "1707.07556", "contents": "Title: Decision Theory with a Hilbert Space as Possibility Space Abstract: In this paper, we propose an interpretation of the Hilbert space method used\nin quantum theory in the context of decision making under uncertainty. For a\nclear comparison we will stay as close as possible to the framework of SEU\nsuggested by Savage. We will use the Ellsberg-paradox to illustrate the\npotential of our approach to deal with well-known paradoxa of decision theory. \n\n"}
{"id": "1708.01951", "contents": "Title: Diffusion Dynamics and Optimal Coupling in Directed Multiplex Networks Abstract: We study the dynamics of diffusion processes acting on directed multiplex\nnetworks, i.e., coupled multilayer networks where at least one layer consists\nof a directed graph. We reveal that directed multiplex networks may exhibit a\nfaster diffusion at an intermediate degree of coupling than when the two layers\nare fully coupled. We use three simple multiplex examples and a real-world\ntopology to illustrate the characteristics of the directed dynamics that give\nrise to a regime in which an optimal coupling exists. Given the ubiquity of\nboth directed and multilayer networks in nature, our results could have\nimportant implications for the dynamics of multilevel complex systems towards\noptimality. \n\n"}
{"id": "1708.05250", "contents": "Title: Field dynamics inference via spectral density estimation Abstract: Stochastic differential equations (SDEs) are of utmost importance in various\nscientific and industrial areas. They are the natural description of dynamical\nprocesses whose precise equations of motion are either not known or too\nexpensive to solve, e.g., when modeling Brownian motion. In some cases, the\nequations governing the dynamics of a physical system on macroscopic scales\noccur to be unknown since they typically cannot be deduced from general\nprinciples. In this work, we describe how the underlying laws of a stochastic\nprocess can be approximated by the spectral density of the corresponding\nprocess. Furthermore, we show how the density can be inferred from possibly\nvery noisy and incomplete measurements of the dynamical field. Generally,\ninverse problems like these can be tackled with the help of Information Field\nTheory (IFT). For now, we restrict to linear and autonomous processes. Though,\nthis is a non-conceptual limitation that may be omitted in future work. To\ndemonstrate its applicability we employ our reconstruction algorithm on a\ntime-series and spatio-temporal processes. \n\n"}
{"id": "1708.06748", "contents": "Title: Analytic sensitivity analysis for models with correlated input variables Abstract: An analytic formula is proposed to characterize the variance propagation from\ncorrelated input variables to the model response, by using multi-variate Taylor\nseries. With the formula, partial variance contributions to the model response\nare then straightforwardly evaluated in the presence of input correlations.\nAdditionally, an arbitrary variable is represented as the sum of independent\nand correlated parts. Universal expressions of the coefficients that specify\nthe correlated and independent sections of a single variable are derived by\nemploying linear correlation model. Based on the coefficients, it is nature to\nquantify the independent, correlated and coupling contributions to the total\nvariance of model response. Numerical examples suggest the effectiveness and\nvalidation of our analytic framework for general models. A practical\napplication of the analytic framework is also proposed to the sensitivity\nanalysis of a deterministic HIV model. \n\n"}
{"id": "1709.02230", "contents": "Title: Remote optimization of an ultra-cold atoms experiment by experts and\n  citizen scientists Abstract: We introduce a novel remote interface to control and optimize the\nexperimental production of Bose-Einstein condensates (BECs) and find improved\nsolutions using two distinct implementations. First, a team of theoreticians\nemployed a Remote version of their dCRAB optimization algorithm (RedCRAB), and\nsecond a gamified interface allowed 600 citizen scientists from around the\nworld to participate in real-time optimization. Quantitative studies of player\nsearch behavior demonstrated that they collectively engage in a combination of\nlocal and global search. This form of adaptive search prevents premature\nconvergence by the explorative behavior of low-performing players while\nhigh-performing players locally refine their solutions. In addition, many\nsuccessful citizen science games have relied on a problem representation that\ndirectly engaged the visual or experiential intuition of the players. Here we\ndemonstrate that citizen scientists can also be successful in an entirely\nabstract problem visualization. This gives encouragement that a much wider\nrange of challenges could potentially be open to gamification in the future. \n\n"}
{"id": "1709.02426", "contents": "Title: Intelligent Disaster Response via Social Media Analysis - A Survey Abstract: The success of a disaster relief and response process is largely dependent on\ntimely and accurate information regarding the status of the disaster, the\nsurrounding environment, and the affected people. This information is primarily\nprovided by first responders on-site and can be enhanced by the firsthand\nreports posted in real-time on social media. Many tools and methods have been\ndeveloped to automate disaster relief by extracting, analyzing, and visualizing\nactionable information from social media. However, these methods are not well\nintegrated in the relief and response processes and the relation between the\ntwo requires exposition for further advancement. In this survey, we review the\nnew frontier of intelligent disaster relief and response using social media,\nshow stages of disasters which are reflected on social media, establish a\nconnection between proposed methods based on social media and relief efforts by\nfirst responders, and outline pressing challenges and future research\ndirections. \n\n"}
{"id": "1709.02595", "contents": "Title: Targeting in Quantum Persuasion Problems Abstract: In this paper we investigate the potential for persuasion arising from the\nquantum indeterminacy of a decision-maker's beliefs, a feature that has been\nproposed as a formal expression of well-known cognitive limitations. We focus\non a situation where an agent called Sender only has few opportunities to\ninfluence the decision-maker called Receiver. We do not address the full\npersuasion problem but restrict attention to a simpler one that we call\ntargeting, i.e. inducing a specific belief state. The analysis is developed\nwithin the frame of a n-dimensional Hilbert space model. We find that when the\nprior is known, Sender can induce a targeted belief with a probability of at\nleast 1/n when using two sequential measurements. This figure climbs to 1/2\nwhen both the target and the belief are known pure states. A main insight from\nthe analysis is that a well-designed strategy of distraction can be used as a\nfirst step to confuse Receiver. We thus find that distraction rather than the\nprovision of relevant arguments is an effective means to achieve persuasion. We\nprovide an example from political decision-making. \n\n"}
{"id": "1709.04495", "contents": "Title: Inverse Ising problem in continuous time: A latent variable approach Abstract: We consider the inverse Ising problem, i.e. the inference of network\ncouplings from observed spin trajectories for a model with continuous time\nGlauber dynamics. By introducing two sets of auxiliary latent random variables\nwe render the likelihood into a form, which allows for simple iterative\ninference algorithms with analytical updates. The variables are: (1) Poisson\nvariables to linearise an exponential term which is typical for point process\nlikelihoods and (2) P\\'olya-Gamma variables, which make the likelihood\nquadratic in the coupling parameters. Using the augmented likelihood, we derive\nan expectation-maximization (EM) algorithm to obtain the maximum likelihood\nestimate of network parameters. Using a third set of latent variables we extend\nthe EM algorithm to sparse couplings via L1 regularization. Finally, we develop\nan efficient approximate Bayesian inference algorithm using a variational\napproach. We demonstrate the performance of our algorithms on data simulated\nfrom an Ising model. For data which are simulated from a more biologically\nplausible network with spiking neurons, we show that the Ising model captures\nwell the low order statistics of the data and how the Ising couplings are\nrelated to the underlying synaptic structure of the simulated network. \n\n"}
{"id": "1709.05681", "contents": "Title: Modeling Smooth Backgrounds and Generic Localized Signals with Gaussian\n  Processes Abstract: We describe a procedure for constructing a model of a smooth data spectrum\nusing Gaussian processes rather than the historical parametric description.\nThis approach considers a fuller space of possible functions, is robust at\nincreasing luminosity, and allows us to incorporate our understanding of the\nunderlying physics. We demonstrate the application of this approach to modeling\nthe background to searches for dijet resonances at the Large Hadron Collider\nand describe how the approach can be used in the search for generic localized\nsignals. \n\n"}
{"id": "1709.05716", "contents": "Title: Response to 'Burden of proof: A comprehensive review of the feasibility\n  of 100% renewable-electricity systems' Abstract: A recent article 'Burden of proof: A comprehensive review of the feasibility\nof 100% renewable-electricity systems' claims that many studies of 100%\nrenewable electricity systems do not demonstrate sufficient technical\nfeasibility, according to the criteria of the article's authors (henceforth\n'the authors'). Here we analyse the authors' methodology and find it\nproblematic. The feasibility criteria chosen by the authors are important, but\nare also easily addressed at low economic cost, while not affecting the main\nconclusions of the reviewed studies and certainly not affecting their technical\nfeasibility. A more thorough review reveals that all of the issues have already\nbeen addressed in the engineering and modelling literature. Nuclear power,\nwhich the authors have evaluated positively elsewhere, faces other, genuine\nfeasibility problems, such as the finiteness of uranium resources and a\nreliance on unproven technologies in the medium- to long-term. Energy systems\nbased on renewables, on the other hand, are not only feasible, but already\neconomically viable and decreasing in cost every year. \n\n"}
{"id": "1710.00530", "contents": "Title: Belief Dynamics in Social Networks: A Fluid-Based Analysis Abstract: The advent and proliferation of social media have led to the development of\nmathematical models describing the evolution of beliefs/opinions in an\necosystem composed of socially interacting users. The goal is to gain insights\ninto collective dominant social beliefs and into the impact of different\ncomponents of the system, such as users' interactions, while being able to\npredict users' opinions. Following this thread, in this paper we consider a\nfairly general dynamical model of social interactions, which captures all the\nmain features exhibited by a social system. For such model, by embracing a\nmean-field approach, we derive a diffusion differential equation that\nrepresents asymptotic belief dynamics, as the number of users grows large. We\nthen analyze the steady-state behavior as well as the time dependent\n(transient) behavior of the system. In particular, for the steady-state\ndistribution, we obtain simple closed-form expressions for a relevant class of\nsystems, while we propose efficient semi-analytical techniques in the most\ngeneral cases. At last, we develop an efficient semi-analytical method to\nanalyze the dynamics of the users' belief over time, which can be applied to a\nremarkably large class of systems. \n\n"}
{"id": "1710.01808", "contents": "Title: Allometric scaling laws derived from symmetric tree networks Abstract: A set of general allometric scaling laws is derived for different systems\nrepresented by tree networks. The formulation postulates self-similar networks\nwith an arbitrary number of branches developed in each generation, and with an\ninhomogeneous structure given by a fractal relation between successive\ngenerations. Three idealized examples are considered: networks of masses,\nelectric resistors, and elastic springs, which obey a specific recurrence\nrelation between generations. The results can be generalized to networks made\nwith different elements obeying equivalent relations. The equivalent values of\nthe networks (total mass, resistance and elastic coefficient) are compared with\ntheir corresponding spatial scales (length, cross-section and volume) in order\nto derive allometric scaling laws. Under appropriate fractal-like\napproximations of the length and cross-section of the branches, some allometric\nexponents reported in the literature are recovered (for instance, the 3/4-law\nof metabolism in biological organisms or the hydraulic conductivity scaling in\nporous networks). The formulation allows different choices of the fractal\nparameters, thus enabling the derivation of new power-laws not reported before. \n\n"}
{"id": "1710.04947", "contents": "Title: A combinatorial framework to quantify peak/pit asymmetries in complex\n  dynamics Abstract: We explore a combinatorial framework which efficiently quantifies the\nasymmetries between minima and maxima in local fluctuations of time series. We\nfirstly showcase its performance by applying it to a battery of synthetic\ncases. We find rigorous results on some canonical dynamical models (stochastic\nprocesses with and without correlations, chaotic processes) complemented by\nextensive numerical simulations for a range of processes which indicate that\nthe methodology correctly distinguishes different complex dynamics and\noutperforms state of the art metrics in several cases. Subsequently, we apply\nthis methodology to real-world problems emerging across several disciplines\nincluding cases in neurobiology, finance and climate science. We conclude that\ndifferences between the statistics of local maxima and local minima in time\nseries are highly informative of the complex underlying dynamics and a\ngraph-theoretic extraction procedure allows to use these features for\nstatistical learning purposes. \n\n"}
{"id": "1710.06285", "contents": "Title: Preliminary steps toward a universal economic dynamics for monetary and\n  fiscal policy Abstract: We consider the relationship between economic activity and intervention,\nincluding monetary and fiscal policy, using a universal dynamic framework.\nCentral bank policies are designed for growth without excess inflation.\nHowever, unemployment, investment, consumption, and inflation are interlinked.\nUnderstanding dynamics is crucial to assessing the effects of policy,\nespecially in the aftermath of the financial crisis. Here we lay out a program\nof research into monetary and economic dynamics and preliminary steps toward\nits execution. We use principles of response theory to derive implications for\npolicy. We find that the current approach, which considers the overall money\nsupply, is insufficient to regulate economic growth. While it can achieve some\ndegree of control, optimizing growth also requires a fiscal policy balancing\nmonetary injection between two dominant loop flows, the consumption and wages\nloop, and investment and returns loop. The balance arises from a composite of\ngovernment tax, entitlement, subsidy policies, corporate policies, as well as\nmonetary policy. We show empirically that a transition occurred in 1980 between\ntwo regimes--an oversupply to the consumption and wages loop, to an oversupply\nof the investment and returns loop. The imbalance is manifest in savings and\nborrowing by consumers and investors, and in inflation. The latter increased\nuntil 1980, and decreased subsequently, resulting in a zero rate largely\nunrelated to the financial crisis. Three recessions and the financial crisis\nare part of this dynamic. Optimizing growth now requires shifting the balance.\nOur analysis supports advocates of greater income and / or government support\nfor the poor who use a larger fraction of income for consumption. This promotes\ninvestment due to growth in demand. Otherwise, investment opportunities are\nlimited, capital remains uninvested, and does not contribute to growth. \n\n"}
{"id": "1710.07737", "contents": "Title: Dynamic mode decomposition for compressive system identification Abstract: Dynamic mode decomposition has emerged as a leading technique to identify\nspatiotemporal coherent structures from high-dimensional data, benefiting from\na strong connection to nonlinear dynamical systems via the Koopman operator. In\nthis work, we integrate and unify two recent innovations that extend DMD to\nsystems with actuation [Proctor et al., 2016] and systems with heavily\nsubsampled measurements [Brunton et al., 2015]. When combined, these methods\nyield a novel framework for compressive system identification [code is publicly\navailable at: https://github.com/zhbai/cDMDc]. It is possible to identify a\nlow-order model from limited input-output data and reconstruct the associated\nfull-state dynamic modes with compressed sensing, adding interpretability to\nthe state of the reduced-order model. Moreover, when full-state data is\navailable, it is possible to dramatically accelerate downstream computations by\nfirst compressing the data. We demonstrate this unified framework on two model\nsystems, investigating the effects of sensor noise, different types of\nmeasurements (e.g., point sensors, Gaussian random projections, etc.),\ncompression ratios, and different choices of actuation (e.g., localized,\nbroadband, etc.). In the first example, we explore this architecture on a test\nsystem with known low-rank dynamics and an artificially inflated state\ndimension. The second example consists of a real-world engineering application\ngiven by the fluid flow past a pitching airfoil at low Reynolds number. This\nexample provides a challenging and realistic test-case for the proposed method,\nand results demonstrate that the dominant coherent structures are well\ncharacterized despite actuation and heavily subsampled data. \n\n"}
{"id": "1710.07924", "contents": "Title: Searching for effective and efficient way of knowledge transfer within\n  an organization Abstract: In this paper three models of knowledge transfer in organization are\nconsidered. In the first model (A) the transfer of chunks of knowledge among\nagents is possible only when the sender has exactly one more chunks of\nknowledge than recipient. This is not dissimilar with bounded confidence model\nof opinion dynamics. In the second model (B) the knowledge transfer take place\nwhen sender is \"smarter\" than recipient. Finally, in the third scenario (model\nC) we allow for knowledge transfer also when sender posses the same or greater\nnumber of chunks of knowledge as recipient. The simulation bases on cellular\nautomata technique. The organization members occupy nodes of square lattice and\nthey interact only with their nearest neighbors. With computer simulations we\nshow, that the efficiency and the effectiveness of knowledge transfer i) for\nmodel C is better than for model B ii) and it is worse for model A than for\nmodel B. \n\n"}
{"id": "1710.08693", "contents": "Title: Bring your friend! Real or virtual? Abstract: A monopolist faces a partially uninformed population of consumers,\ninterconnected through a directed social network. In the network, the\nmonopolist offers rewards to informed consumers (influencers) conditional on\ninforming uninformed consumers (influenced). Rewards are needed to bear a\ncommunication cost. We investigate the incentives for the monopolist to move to\na denser network and the impact of this decision on social welfare. Social\nwelfare increases in information diffusion which, for given communication\nincentives, is higher in denser networks. However, the monopolist internalizes\ntransfers and thus may prefer an environment with less competition between\ninformed consumers. The presence of highly connected influencers (hubs) is the\nmain driver that aligns monopolist incentives and welfare. \n\n"}
{"id": "1710.08826", "contents": "Title: GooFit 2.0 Abstract: The GooFit package provides physicists a simple, familiar syntax for\nmanipulating probability density functions and performing fits, and is highly\noptimized for data analysis on NVIDIA GPUs and multithreaded CPU backends.\nGooFit was updated to version 2.0, bringing a host of new features. A\ncompletely revamped and redesigned build system makes GooFit easier to install,\ndevelop with, and run on virtually any system. Unit testing, continuous\nintegration, and advanced logging options are improving the stability and\nreliability of the system. Developing new PDFs now uses standard CUDA\nterminology and provides a lower barrier for new users. The system now has\nbuilt-in support for multiple graphics cards or nodes using MPI, and is being\ntested on a wide range of different systems. GooFit also has significant\nimprovements in performance on some GPU architectures due to optimized memory\naccess. Support for time-dependent four-body amplitude analyses has also been\nadded. \n\n"}
{"id": "1710.09281", "contents": "Title: Image registration of low signal-to-noise cryo-STEM data Abstract: Combining multiple fast image acquisitions to mitigate scan noise and drift\nartifacts has proven essential for picometer precision, quantitative analysis\nof atomic resolution scanning transmission electron microscopy (STEM) data. For\nvery low signal-to-noise ratio (SNR) image stacks - frequently required for\nundistorted imaging at liquid nitrogen temperatures - image registration is\nparticularly delicate, and standard approaches may either fail, or produce\nsubtly specious reconstructed lattice images. We present an approach which\neffectively registers and averages image stacks which are challenging due to\ntheir low-SNR and propensity for unit cell misalignments. Registering all\npossible image pairs in a multi-image stack leads to significant information\nsurplus. In combination with a simple physical picture of stage drift, this\nenables identification of incorrect image registrations, and determination of\nthe optimal image shifts from the complete set of relative shifts. We\ndemonstrate the effectiveness of our approach on experimental, cryogenic STEM\ndatasets, highlighting subtle artifacts endemic to low-SNR lattice images and\nhow they can be avoided. High-SNR average images with information transfer out\nto 0.72 A are achieved at 300 kV and with the sample cooled to near liquid\nnitrogen temperature. \n\n"}
{"id": "1710.09656", "contents": "Title: Tackling information asymmetry in networks: a new entropy-based ranking\n  index Abstract: Information is a valuable asset for agents in socio-economic systems, a\nsignificant part of the information being entailed into the very network of\nconnections between agents. The different interlinkages patterns that agents\nestablish may, in fact, lead to asymmetries in the knowledge of the network\nstructure; since this entails a different ability of quantifying relevant\nsystemic properties (e.g. the risk of financial contagion in a network of\nliabilities), agents capable of providing a better estimate of (otherwise)\nunaccessible network properties, ultimately have a competitive advantage. In\nthis paper, we address for the first time the issue of quantifying the\ninformation asymmetry arising from the network topology. To this aim, we define\na novel index - InfoRank - intended to measure the quality of the information\npossessed by each node, computing the Shannon entropy of the ensemble\nconditioned on the node-specific information. Further, we test the performance\nof our novel ranking procedure in terms of the reconstruction accuracy of the\n(unaccessible) network structure and show that it outperforms other popular\ncentrality measures in identifying the \"most informative\" nodes. Finally, we\ndiscuss the socio-economic implications of network information asymmetry. \n\n"}
{"id": "1710.11324", "contents": "Title: Resolution and Relevance Trade-offs in Deep Learning Abstract: Deep learning has been successfully applied to various tasks, but its\nunderlying mechanism remains unclear. Neural networks associate similar inputs\nin the visible layer to the same state of hidden variables in deep layers. The\nfraction of inputs that are associated to the same state is a natural measure\nof similarity and is simply related to the cost in bits required to represent\nthese inputs. The degeneracy of states with the same information cost provides\ninstead a natural measure of noise and is simply related the entropy of the\nfrequency of states, that we call relevance. Representations with minimal\nnoise, at a given level of similarity (resolution), are those that maximise the\nrelevance. A signature of such efficient representations is that frequency\ndistributions follow power laws. We show, in extensive numerical experiments,\nthat deep neural networks extract a hierarchy of efficient representations from\ndata, because they i) achieve low levels of noise (i.e. high relevance) and ii)\nexhibit power law distributions. We also find that the layer that is most\nefficient to reliably generate patterns of training data is the one for which\nrelevance and resolution are traded at the same price, which implies that\nfrequency distribution follows Zipf's law. \n\n"}
{"id": "1711.01330", "contents": "Title: Asymptotics of extreme statistics of escape time in 1,2 and\n  3-dimensional diffusions Abstract: The first of $N$ identical independently distributed (i.i.d.) Brownian\ntrajectories that arrives to a small target, sets the time scale of activation,\nwhich in general is much faster than the arrival to the target of only a single\ntrajectory. Analytical asymptotic expressions for the minimal time is\nnotoriously difficult to compute in general geometries. We derive here\nasymptotic laws for the probability density function of the first and second\narrival times of a large number of i.i.d. Brownian trajectories to a small\ntarget in 1,2, and 3 dimensions and study their range of validity by stochastic\nsimulations. The results are applied to activation of biochemical pathways in\ncellular transduction. \n\n"}
{"id": "1711.06287", "contents": "Title: Accuracy of inference on the physics of binary evolution from\n  gravitational-wave observations Abstract: The properties of the population of merging binary black holes encode some of\nthe uncertain physics of the evolution of massive stars in binaries. The binary\nblack hole merger rate and chirp mass distribution are being measured by\nground-based gravitational-wave detectors. We consider isolated binary\nevolution and explore how accurately the physical model can be constrained with\nsuch observations by applying the Fisher information matrix to the merging\nblack hole population simulated with the rapid binary population synthesis code\nCOMPAS. We investigate variations in four COMPAS parameters: common envelope\nefficiency, kick velocity dispersion, and mass loss rates during the luminous\nblue variable and Wolf--Rayet stellar evolutionary phases. We find that 1000\nobservations would constrain these model parameters to a fractional accuracy of\na few percent. Given the empirically determined binary black hole merger rate,\nwe can expect gravitational-wave observations alone to place strong constraints\non the physics of stellar and binary evolution within a few years. \n\n"}
{"id": "1711.07833", "contents": "Title: Collective patterns of pedestrians interacting with attractions Abstract: Walking is a fundamental activity of human life, not only for moving between\nplaces but also for interacting with surrounding environments. While walking to\ndestinations, pedestrians may acquaint themselves with attractions such as\nartworks, shop displays, and public events. If such attractions are tempting\nenough, pedestrians opt to stop walking in order to join the attractions. In\ncrowded conditions, the existence of attractions may considerably affect the\npedestrian flow patterns. One can see that the attracted pedestrians often\nimpede passerby flow near the attractions during peak hour in a shopping\ncenter. During shopping holidays such as Black Friday in the United States,\nshoppers are competing for very attractive products in stores and such behavior\nmight lead to pedestrian incidents.\n  The work presented in this dissertation reproduced those phenomena in\nnumerical simulations by developing mathematical models of attracted pedestrian\nmovements. In the models, the crowd preference and the attractiveness of the\nattraction were taken into account in order to reflect the characteristics of\nattractions and pedestrian traffic. Furthermore, this dissertation suggested\npossible explanations of the predicted phenomena based on the interactions\nbetween pedestrians and attractions. The presented models can be applied and\nextended, for example, to optimize pedestrian flow in shopping centers and\nmuseums. \n\n"}
{"id": "1711.08813", "contents": "Title: Controlling Physical Attributes in GAN-Accelerated Simulation of\n  Electromagnetic Calorimeters Abstract: High-precision modeling of subatomic particle interactions is critical for\nmany fields within the physical sciences, such as nuclear physics and high\nenergy particle physics. Most simulation pipelines in the sciences are\ncomputationally intensive -- in a variety of scientific fields, Generative\nAdversarial Networks have been suggested as a solution to speed up the forward\ncomponent of simulation, with promising results. An important component of any\nsimulation system for the sciences is the ability to condition on any number of\nphysically meaningful latent characteristics that can effect the forward\ngeneration procedure. We introduce an auxiliary task to the training of a\nGenerative Adversarial Network on particle showers in a multi-layer\nelectromagnetic calorimeter, which allows our model to learn an attribute-aware\nconditioning mechanism. \n\n"}
{"id": "1712.00910", "contents": "Title: A general formulation of long-range degree correlations in complex\n  networks Abstract: We provide a general framework for analyzing degree correlations between\nnodes separated by more than one step (i.e., beyond nearest neighbors) in\ncomplex networks. One probability and four conditional probabilities are\nintroduced to fully describe long-range degree correlations with respect to $k$\nand $k'$ of two nodes and shortest path length $l$ between them. We present\ngeneral relations among these probabilities and clarify the relevance to\nnearest-neighbor degree correlations. Unlike nearest-neighbor correlations,\nsome of these probabilities are meaningful only in finite-size networks.\nFurthermore, as a baseline to determine the existence or nonexistence of\nlong-range degree correlations in a network, the functional forms of these\nprobabilities for networks without any long-range degree correlations are\nanalytically evaluated within a mean-field approximation. The validity of our\nargument is demonstrated by applying it to real-world networks. \n\n"}
{"id": "1712.02665", "contents": "Title: Many-body quantum chaos: Analytic connection to random matrix theory Abstract: A key goal of quantum chaos is to establish a relationship between widely\nobserved universal spectral fluctuations of clean quantum systems and random\nmatrix theory (RMT). For single particle systems with fully chaotic classical\ncounterparts, the problem has been partly solved by Berry (1985) within the\nso-called diagonal approximation of semiclassical periodic-orbit sums.\nDerivation of the full RMT spectral form factor $K(t)$ from semiclassics has\nbeen completed only much later in a tour de force by Mueller et al (2004). In\nrecent years, the questions of long-time dynamics at high energies, for which\nthe full many-body energy spectrum becomes relevant, are coming at the\nforefront even for simple many-body quantum systems, such as locally\ninteracting spin chains. Such systems display two universal types of behaviour\nwhich are termed as `many-body localized phase' and `ergodic phase'. In the\nergodic phase, the spectral fluctuations are excellently described by RMT, even\nfor very simple interactions and in the absence of any external source of\ndisorder. Here we provide the first theoretical explanation for these\nobservations. We compute $K(t)$ explicitly in the leading two orders in $t$ and\nshow its agreement with RMT for non-integrable, time-reversal invariant\nmany-body systems without classical counterparts, a generic example of which\nare Ising spin 1/2 models in a periodically kicking transverse field. \n\n"}
{"id": "1712.03407", "contents": "Title: Self-organization and time-stability of social hierarchies Abstract: The formation and stability of social hierarchies is a question of general\nrelevance. Here, we propose a simple generalized theoretical model for\nestablishing social hierarchy via pair-wise interactions between individuals\nand investigate its stability. In each interaction or fight, the probability of\n\"winning\" depends solely on the relative societal status of the participants,\nand the winner has a gain of status whereas there is an equal loss to the\nloser. The interactions are characterized by two parameters. The first\nparameter represents how much can be lost, and the second parameter represents\nthe degree to which even a small difference of status can guarantee a win for\nthe higher-status individual. Depending on the parameters, the resulting status\ndistributions reach either a continuous unimodal form or lead to a totalitarian\nend state with one high-status individual and all other individuals having\nstatus approaching zero. However, we find that in the latter case long-lived\nintermediary distributions often exist, which can give the illusion of a stable\nsociety. As we show, our model allows us to make predictions consistent with\nanimal interaction data and their evolution over a number of years. Moreover,\nby implementing a simple, but realistic rule that restricts interactions to\nsufficiently similar-status individuals, the stable or long-lived distributions\nacquire high-status structure corresponding to a distinct high-status class.\nUsing household income as a proxy for societal status in human societies, we\nfind agreement over their entire range from the low-to-middle-status parts to\nthe characteristic high-status \"tail\". We discuss how the model provides a\nconceptual framework for understanding the origin of social hierarchy and the\nfactors which lead to the preservation or deterioration of the societal\nstructure. \n\n"}
{"id": "1712.04053", "contents": "Title: Cascading Failures as Continuous Phase-Space Transitions Abstract: In network systems, a local perturbation can amplify as it propagates,\npotentially leading to a large-scale cascading failure. Here we derive a\ncontinuous model to advance our understanding of cascading failures in\npower-grid networks. The model accounts for both the failure of transmission\nlines and the desynchronization of power generators, and incorporates the\ntransient dynamics between successive steps of the cascade. In this framework,\nwe show that a cascade event is a phase-space transition from an equilibrium\nstate with high energy to an equilibrium state with lower energy, which can be\nsuitably described in closed form using a global Hamiltonian-like function.\nFrom this function we show that a perturbed system cannot always reach the\nequilibrium state predicted by quasi-steady-state cascade models, which would\ncorrespond to a reduced number of failures, and may instead undergo a larger\ncascade. We also show that in the presence of two or more perturbations, the\noutcome depends strongly on the order and timing of the individual\nperturbations. These results offer new insights into the current understanding\nof cascading dynamics, with potential implications for control interventions. \n\n"}
{"id": "1712.04107", "contents": "Title: Attack Vulnerability of Complex Networks in Center-Based Strategies Abstract: Central nodes are critical in establishing structural connectivity in a\ncomplex network. Attacking such nodes can create real havoc in a complex\nsystem. We propose attack strategies based on four types of centers, namely\nbetweenness center, degree center, median, and center. We study the\nvulnerability of synthetic as well as real-world networks in these center-based\nattacks. These attacks are node-removal attacks which involve identifying the\ncentral node set and removing them from the network. We observed that the\nattacks based on recalculated network information are more efficient than ones\nbased on initial network information. This work shows that the median-based\nattack, which is a novel strategy proposed in this work, is highly destructive\nin real as well as synthetic networks. \n\n"}
{"id": "1712.04144", "contents": "Title: Information Perspective to Probabilistic Modeling: Boltzmann Machines\n  versus Born Machines Abstract: We compare and contrast the statistical physics and quantum physics inspired\napproaches for unsupervised generative modeling of classical data. The two\napproaches represent probabilities of observed data using energy-based models\nand quantum states respectively.Classical and quantum information patterns of\nthe target datasets therefore provide principled guidelines for structural\ndesign and learning in these two approaches. Taking the restricted Boltzmann\nmachines (RBM) as an example, we analyze the information theoretical bounds of\nthe two approaches. We verify our reasonings by comparing the performance of\nRBMs of various architectures on the standard MNIST datasets. \n\n"}
{"id": "1712.04386", "contents": "Title: Hawkes Processes for Invasive Species Modeling and Management Abstract: The spread of invasive species to new areas threatens the stability of\necosystems and causes major economic losses in agriculture and forestry. We\npropose a novel approach to minimizing the spread of an invasive species given\na limited intervention budget. We first model invasive species propagation\nusing Hawkes processes, and then derive closed-form expressions for\ncharacterizing the effect of an intervention action on the invasion process. We\nuse this to obtain an optimal intervention plan based on an integer programming\nformulation, and compare the optimal plan against several\necologically-motivated heuristic strategies used in practice. We present an\nempirical study of two variants of the invasive control problem: minimizing the\nfinal rate of invasions, and minimizing the number of invasions at the end of a\ngiven time horizon. Our results show that the optimized intervention achieves\nnearly the same level of control that would be attained by completely\neradicating the species, with a 20% cost saving. Additionally, we design a\nheuristic intervention strategy based on a combination of the density and life\nstage of the invasive individuals, and find that it comes surprisingly close to\nthe optimized strategy, suggesting that this could serve as a good rule of\nthumb in invasive species management. \n\n"}
{"id": "1712.05089", "contents": "Title: DAMPE squib? Significance of the 1.4 TeV DAMPE excess Abstract: We present a Bayesian and frequentist analysis of the DAMPE charged cosmic\nray spectrum. The spectrum, by eye, contained a spectral break at about 1 TeV\nand a monochromatic excess at about 1.4 TeV. The break was supported by a Bayes\nfactor of about $10^{10}$ and we argue that the statistical significance was\nresounding. We investigated whether we should attribute the excess to dark\nmatter annihilation into electrons in a nearby subhalo. We found a local\nsignificance of about $3.6\\sigma$ and a global significance of about\n$2.3\\sigma$, including a two-dimensional look-elsewhere effect by simulating\n1000 pseudo-experiments. The Bayes factor was sensitive to our choices of\npriors, but favoured the excess by about 2 for our choices. Thus, whilst\nintriguing, the evidence for a signal is not currently compelling. \n\n"}
{"id": "1712.07901", "contents": "Title: Improvements to Inference Compilation for Probabilistic Programming in\n  Large-Scale Scientific Simulators Abstract: We consider the problem of Bayesian inference in the family of probabilistic\nmodels implicitly defined by stochastic generative models of data. In\nscientific fields ranging from population biology to cosmology, low-level\nmechanistic components are composed to create complex generative models. These\nmodels lead to intractable likelihoods and are typically non-differentiable,\nwhich poses challenges for traditional approaches to inference. We extend\nprevious work in \"inference compilation\", which combines universal\nprobabilistic programming and deep learning methods, to large-scale scientific\nsimulators, and introduce a C++ based probabilistic programming library called\nCPProb. We successfully use CPProb to interface with SHERPA, a large code-base\nused in particle physics. Here we describe the technical innovations realized\nand planned for this library. \n\n"}
{"id": "1712.08894", "contents": "Title: EXONEST: The Bayesian Exoplanetary Explorer Abstract: The fields of astronomy and astrophysics are currently engaged in an\nunprecedented era of discovery as recent missions have revealed thousands of\nexoplanets orbiting other stars. While the Kepler Space Telescope mission has\nenabled most of these exoplanets to be detected by identifying transiting\nevents, exoplanets often exhibit additional photometric effects that can be\nused to improve the characterization of exoplanets. The EXONEST Exoplanetary\nExplorer is a Bayesian exoplanet inference engine based on nested sampling and\noriginally designed to analyze archived Kepler Space Telescope and CoRoT\n(Convection Rotation et Transits plan\\'etaires) exoplanet mission data. We\ndiscuss the EXONEST software package and describe how it accommodates\nplug-and-play models of exoplanet-associated photometric effects for the\npurpose of exoplanet detection, characterization and scientific hypothesis\ntesting. The current suite of models allows for both circular and eccentric\norbits in conjunction with photometric effects, such as the primary transit and\nsecondary eclipse, reflected light, thermal emissions, ellipsoidal variations,\nDoppler beaming and superrotation. We discuss our new efforts to expand the\ncapabilities of the software to include more subtle photometric effects\ninvolving reflected and refracted light. We discuss the EXONEST inference\nengine design and introduce our plans to port the current MATLAB-based EXONEST\nsoftware package over to the next generation Exoplanetary Explorer, which will\nbe a Python-based open source project with the capability to employ third-party\nplug-and-play models of exoplanet-related photometric effects. \n\n"}
{"id": "1712.09648", "contents": "Title: Representing Big Data as Networks: New Methods and Insights Abstract: Our world produces massive data every day; they exist in diverse forms, from\npairwise data and matrix to time series and trajectories. Meanwhile, we have\naccess to the versatile toolkit of network analysis. Networks also have\ndifferent forms; from simple networks to higher-order network, each\nrepresentation has different capabilities in carrying information. For\nresearchers who want to leverage the power of the network toolkit, and apply it\nbeyond networks data to sequential data, diffusion data, and many more, the\nquestion is: how to represent big data and networks? This dissertation makes a\nfirst step to answering the question. It proposes the higher-order network,\nwhich is a critical piece for representing higher-order interaction data; it\nintroduces a scalable algorithm for building the network, and visualization\ntools for interactive exploration. Finally, it presents broad applications of\nthe higher-order network in the real-world. \n\n"}
{"id": "1801.01359", "contents": "Title: An approximation theoretic perspective of the Sobol' indices with\n  dependent variables Abstract: The Sobol' indices are a recognized tool in global sensitivity analysis. When\nthe uncertain variables in a model are statistically independent, the Sobol'\nindices may be easily interpreted and utilized. However, their interpretation\nand utility is more challenging with statistically dependent variables. This\narticle develops an approximation theoretic perspective to interpret Sobol'\nindices in the presence of variable dependencies. The value of this perspective\nis demonstrated in the context of dimension reduction, a common application of\nthe Sobol' indices. Theoretical analysis and illustrative examples are\nprovided. \n\n"}
{"id": "1801.04343", "contents": "Title: Susceptibility of power grids to input fluctuations Abstract: With the increasing inclusion of regenerative resources in the energy mix,\ntheir intermittent character challenges power grid stability. Hence it is\nessential to determine which input fluctuations power grids are particularly\nvulnerable to. Focusing on angular stability in transmission grids, we propose\na linear-response approach that yields a frequency-resolved measure of a grid's\nsusceptibility to temporal input fluctuations. This approach can be applied to\narbitrary transmission grid topologies as well as other settings described by\noscillator networks. \n\n"}
{"id": "1801.04642", "contents": "Title: Stable and Efficient Structures for the Content Production and\n  Consumption in Information Communities Abstract: Real-world information communities exhibit inherent structures that\ncharacterize a system that is stable and efficient for content production and\nconsumption. In this paper, we study such structures through mathematical\nmodelling and analysis. We formulate a generic model of a community in which\neach member decides how they allocate their time between content production and\nconsumption with the objective of maximizing their individual reward. We define\nthe community system as \"stable and efficient\" when a Nash equilibrium is\nreached while the social welfare of the community is maximized. We investigate\nthe conditions for forming a stable and efficient community under two\nvariations of the model representing different internal relational structures\nof the community. Our analysis results show that the structure with \"a small\ncore of celebrity producers\" is the optimally stable and efficient for a\ncommunity. These analysis results provide possible explanations to the\nsociological observations such as \"the Law of the Few\" and also provide\ninsights into how to effectively build and maintain the structure of\ninformation communities. \n\n"}
{"id": "1801.05672", "contents": "Title: On the origin of self-oscillations in large systems Abstract: In this article is shown that large systems endowing phase coexistence\ndisplay self-oscillations in presence of linear feedback between the control\nand order parameters, where an Andronov-Hopf bifurcation takes over the phase\ntransition. This is simply illustrated through the mean field Landau theory\nwhose feedback dynamics turns out to be described by the Van der Pol equation\nand it is then validated for the fully connected Ising model following heat\nbath dynamics. Despite its simplicity, this theory accounts potentially for a\nrich range of phenomena: here it is applied to describe in a stylized way i)\nexcess demand-price cycles due to strong herding in a simple agent-based market\nmodel; ii) congestion waves in queueing networks triggered by users feedback to\ndelays in overloaded conditions; iii) metabolic network oscillations resulting\nfrom cell growth control in a bistable phenotypic landscape. \n\n"}
{"id": "1801.09783", "contents": "Title: Performance Dynamics and Success in Online Games Abstract: Online data provide a way to monitor how users behave in social systems like\nsocial networks and online games, and understand which features turn an\nordinary individual into a successful one. Here, we propose to study individual\nperformance and success in Multiplayer Online Battle Arena (MOBA) games. Our\npurpose is to identify those behaviors and playing styles that are\ncharacteristic of players with high skill level and that distinguish them from\nother players. To this aim, we study Defense of the ancient 2 (Dota 2), a\npopular MOBA game. Our findings highlight three main aspects to be successful\nin the game: (i) players need to have a warm-up period to enhance their\nperformance in the game; (ii) having a long in-game experience does not\nnecessarily translate in achieving better skills; but rather, (iii) players\nthat reach high skill levels differentiate from others because of their\naggressive playing strategy, which implies to kill opponents more often than\ncooperating with teammates, and trying to give an early end to the match. \n\n"}
{"id": "1802.01614", "contents": "Title: ComPAS: Community Preserving Sampling for Streaming Graphs Abstract: In the era of big data, graph sampling is indispensable in many settings.\nExisting sampling methods are mostly designed for static graphs, and aim to\npreserve basic structural properties of the original graph (such as degree\ndistribution, clustering coefficient etc.) in the sample. We argue that for any\nsampling method it is impossible to produce an universal representative sample\nwhich can preserve all the properties of the original graph; rather sampling\nshould be application specific (such as preserving hubs - needed for\ninformation diffusion). Here we consider community detection as an application\nscenario. We propose ComPAS, a novel sampling strategy that unlike previous\nmethods, is not only designed for streaming graphs (which is a more realistic\nrepresentation of a real-world scenario) but also preserves the community\nstructure of the original graph in the sample. Empirical results on both\nsynthetic and different real-world graphs show that ComPAS is the best to\npreserve the underlying community structure with average performance reaching\n73.2% of the most informed algorithm for static graphs. \n\n"}
{"id": "1802.04966", "contents": "Title: Destination Choice Game: A Spatial Interaction Theory on Human Mobility Abstract: With remarkable significance in migration prediction, global disease\nmitigation, urban planning and many others, an arresting challenge is to\npredict human mobility fluxes between any two locations. A number of methods\nhave been proposed against the above challenge, including the gravity model,\nthe intervening opportunity model, the radiation model, the population-weighted\nopportunity model, and so on. Despite their theoretical elegance, all models\nignored an intuitive and important ingredient in individual decision about\nwhere to go, that is, the possible congestion on the way and the possible\ncrowding in the destination. Here we propose a microscopic mechanism underlying\nmobility decisions, named destination choice game (DCG), which takes into\naccount the crowding effects resulted from spatial interactions among\nindividuals. In comparison with the state-of-the-art models, the present one\nshows more accurate prediction on mobility fluxes across wide scales from\nintracity trips to intercity travels, and further to internal migrations. The\nwell-known gravity model is proved to be the equilibrium solution of a\ndegenerated DCG neglecting the crowding effects in the destinations. \n\n"}
{"id": "1802.05139", "contents": "Title: Structural changes in the interbank market across the financial crisis\n  from multiple core-periphery analysis Abstract: Interbank markets are often characterised in terms of a core-periphery\nnetwork structure, with a highly interconnected core of banks holding the\nmarket together, and a periphery of banks connected mostly to the core but not\ninternally. This paradigm has recently been challenged for short time scales,\nwhere interbank markets seem better characterised by a bipartite structure with\nmore core-periphery connections than inside the core. Using a novel\ncore-periphery detection method on the eMID interbank market, we enrich this\npicture by showing that the network is actually characterised by multiple\ncore-periphery pairs. Moreover, a transition from core-periphery to bipartite\nstructures occurs by shortening the temporal scale of data aggregation. We\nfurther show how the global financial crisis transformed the market, in terms\nof composition, multiplicity and internal organisation of core-periphery pairs.\nBy unveiling such a fine-grained organisation and transformation of the\ninterbank market, our method can find important applications in the\nunderstanding of how distress can propagate over financial networks. \n\n"}
{"id": "1802.05337", "contents": "Title: Link transmission centrality in large-scale social networks Abstract: Understanding the importance of links in transmitting information in a\nnetwork can provide ways to hinder or postpone ongoing dynamical phenomena like\nthe spreading of epidemic or the diffusion of information. In this work, we\npropose a new measure based on stochastic diffusion processes, the\n\\textit{transmission centrality}, that captures the importance of links by\nestimating the average number of nodes to whom they transfer information during\na global spreading diffusion process. We propose a simple algorithmic solution\nto compute transmission centrality and to approximate it in very large networks\nat low computational cost. Finally we apply transmission centrality in the\nidentification of weak ties in three large empirical social networks, showing\nthat this metric outperforms other centrality measures in identifying links\nthat drive spreading processes in a social network. \n\n"}
{"id": "1803.00894", "contents": "Title: Sparse Identification of Nonlinear Dynamics for Rapid Model Recovery Abstract: Big data has become a critically enabling component of emerging mathematical\nmethods aimed at the automated discovery of dynamical systems, where first\nprinciples modeling may be intractable. However, in many engineering systems,\nabrupt changes must be rapidly characterized based on limited, incomplete, and\nnoisy data. Many leading automated learning techniques rely on unrealistically\nlarge data sets and it is unclear how to leverage prior knowledge effectively\nto re-identify a model after an abrupt change. In this work, we propose a\nconceptual framework to recover parsimonious models of a system in response to\nabrupt changes in the low-data limit. First, the abrupt change is detected by\ncomparing the estimated Lyapunov time of the data with the model prediction.\nNext, we apply the sparse identification of nonlinear dynamics (SINDy)\nregression to update a previously identified model with the fewest changes,\neither by addition, deletion, or modification of existing model terms. We\ndemonstrate this sparse model recovery on several examples for abrupt system\nchange detection in periodic and chaotic dynamical systems. Our examples show\nthat sparse updates to a previously identified model perform better with less\ndata, have lower runtime complexity, and are less sensitive to noise than\nidentifying an entirely new model. The proposed abrupt-SINDy architecture\nprovides a new paradigm for the rapid and efficient recovery of a system model\nafter abrupt changes. \n\n"}
{"id": "1803.01482", "contents": "Title: Three-dimensional convolutional neural networks for neutrinoless\n  double-beta decay signal/background discrimination in high-pressure gaseous\n  Time Projection Chamber Abstract: In the search for neutrinoless double-beta decay, the high-pressure gaseous\nTime Projection Chamber has a distinct advantage, because the ionization charge\ntracks produced by particle interactions are extended and the detector captures\nthe full three-dimensional charge distribution with appropriate charge readout\nsystems. Such information of tracks provides a crucial extra-handle for\ndiscriminating signal events against backgrounds. In this paper, we constructed\na toy model to demonstrate where the discrimination power comes from and how\nmuch of it the neural network models have already harnessed. Then we adapted\n3-dimensional convolutional and residual neural networks on the simulated\ndouble-beta and background charge tracks and tested their capabilities in\nclassifying these two types of events. We show that both the 3D structure and\nthe overall depth of the neural networks significantly improve the accuracy of\nthe classifier and lead to results better than previous works. We also studied\ntheir performance under various spatial granularities as well as different\ndiffusion and noise conditions. The results indicate that the methods are\nstable and generalize well despite varying experimental conditions. \n\n"}
{"id": "1803.02111", "contents": "Title: Algorithmic bias amplifies opinion polarization: A bounded confidence\n  model Abstract: The flow of information reaching us via the online media platforms is\noptimized not by the information content or relevance but by popularity and\nproximity to the target. This is typically performed in order to maximise\nplatform usage. As a side effect, this introduces an algorithmic bias that is\nbelieved to enhance polarization of the societal debate. To study this\nphenomenon, we modify the well-known continuous opinion dynamics model of\nbounded confidence in order to account for the algorithmic bias and investigate\nits consequences. In the simplest version of the original model the pairs of\ndiscussion participants are chosen at random and their opinions get closer to\neach other if they are within a fixed tolerance level. We modify the selection\nrule of the discussion partners: there is an enhanced probability to choose\nindividuals whose opinions are already close to each other, thus mimicking the\nbehavior of online media which suggest interaction with similar peers. As a\nresult we observe: a) an increased tendency towards polarization, which emerges\nalso in conditions where the original model would predict convergence, and b) a\ndramatic slowing down of the speed at which the convergence at the asymptotic\nstate is reached, which makes the system highly unstable. Polarization is\naugmented by a fragmented initial population. \n\n"}
{"id": "1803.02580", "contents": "Title: Bursty Human Dynamics Abstract: Bursty dynamics is a common temporal property of various complex systems in\nNature but it also characterises the dynamics of human actions and\ninteractions. At the phenomenological level it is a feature of all systems that\nevolve heterogeneously over time by alternating between periods of low and high\nevent frequencies. In such systems, bursts are identified as periods in which\nthe events occur with a rapid pace within a short time-interval while these\nperiods are separated by long periods of time with low frequency of events. As\nsuch dynamical patterns occur in a wide range of natural phenomena, their\nobservation, characterisation, and modelling have been a long standing\nchallenge in several fields of research. However, due to some recent\ndevelopments in communication and data collection techniques it has become\npossible to follow digital traces of actions and interactions of humans from\nthe individual up to the societal level. This led to several new observations\nof bursty phenomena in the new but largely unexplored area of human dynamics,\nwhich called for the renaissance to study these systems using research concepts\nand methodologies, including data analytics and modelling. As a result, a large\namount of new insight and knowledge as well as innovations have been\naccumulated in the field, which provided us a timely opportunity to write this\nbrief monograph to make an up-to-date review and summary of the observations,\nappropriate measures, modelling, and applications of heterogeneous bursty\npatterns occurring in the dynamics of human behaviour. \n\n"}
{"id": "1803.02695", "contents": "Title: The Altes Family of Log-Periodic Chirplets and the Hyperbolic Chirplet\n  Transform Abstract: This work revisits a class of biomimetically inspired log-periodic waveforms\nfirst introduced by R.A. Altes in the 1970s for generalized target description.\nIt was later observed that there is a close connection between such sonar\ntechniques and wavelet decomposition for multiresolution analysis. Motivated by\nthis, we formalize the original Altes waveforms as a family of hyperbolic\nchirplets suitable for the detection of accelerating time-series oscillations.\nThe formalism results in a remarkably flexible set of wavelets with desirable\nproperties of admissibility, regularity, vanishing moments, and time-frequency\nlocalization. These \"Altes wavelets\" also facilitate efficient implementation\nof the scale invariant hyperbolic chirplet transform (HCT).\n  From a practical perspective, log-periodic oscillations with an acceleration\ntowards criticality can serve as indicators of an incipient bifurcation. Such\nsignals abound in nature, often as precursors to phase transitions in the\nnon-linear dynamics of complex systems. For example, the authors' interest lies\nin automatic detection of the well documented phenomenon of log-periodic price\ndynamics during financial bubbles and preceding market crashes. However, the\nmethodology presented here is more widely applicable in such diverse domains as\nprediction of critical failures in mechanical systems, and fault detection in\nelectrical networks. Examples beyond failure diagnostics include animal species\nidentification via call recordings, commercial \\& military radar, and there are\nmany more. A synthetic application is presented in this report for illustrative\npurposes. \n\n"}
{"id": "1803.03528", "contents": "Title: Biological and Shortest-Path Routing Procedures for Transportation\n  Network Design Abstract: The design of efficient transportation networks is an important challenge in\nmany research areas. Among the most promising recent methods, biological\nrouting mimic local rules found in nature. However comparisons with other\nmethods are rare. In this paper we define a common framework to compare network\ndesign method. We use it to compare biological and a shortest-path routing\napproaches. We find that biological routing explore a more efficient set of\nsolution when looking to design a network for uniformly distributed transfers.\nHowever, the difference between the two approaches is not as important for a\nskewed distribution of transfers. \n\n"}
{"id": "1803.03858", "contents": "Title: Testing One Hypothesis Multiple Times: The Multidimensional Case Abstract: The identification of new rare signals in data, the detection of a sudden\nchange in a trend, and the selection of competing models, are among the most\nchallenging problems in statistical practice. These challenges can be tackled\nusing a test of hypothesis where a nuisance parameter is present only under the\nalternative, and a computationally efficient solution can be obtained by the\n\"Testing One Hypothesis Multiple times\" (TOHM) method. In the one-dimensional\nsetting, a fine discretization of the space of the non-identifiable parameter\nis specified, and a global p-value is obtained by approximating the\ndistribution of the supremum of the resulting stochastic process. In this\npaper, we propose a computationally efficient inferential tool to perform TOHM\nin the multidimensional setting. Here, the approximations of interest typically\ninvolve the expected Euler Characteristics (EC) of the excursion set of the\nunderlying random field. We introduce a simple algorithm to compute the EC in\nmultiple dimensions and for arbitrary large significance levels. This leads to\nan highly generalizable computational tool to perform inference under\nnon-standard regularity conditions. \n\n"}
{"id": "1803.04493", "contents": "Title: Particle Identification In Camera Image Sensors Using Computer Vision Abstract: We present a deep learning, computer vision algorithm constructed for the\npurposes of identifying and classifying charged particles in camera image\nsensors. We apply our algorithm to data collected by the Distributed Electronic\nCosmic-ray Observatory (DECO), a global network of smartphones that monitors\ncamera image sensors for the signatures of cosmic rays and other energetic\nparticles, such as those produced by radioactive decays. The algorithm, whose\ncore component is a convolutional neural network, achieves classification\nperformance comparable to human quality across four distinct DECO event\ntopologies. We apply our model to the entire DECO data set and determine a\nselection that achieves $\\ge90\\%$ purity for all event types. In particular, we\nestimate a purity of $95\\%$ when applied to cosmic-ray muons. The automated\nclassification is run on the public DECO data set in real time in order to\nprovide classified particle interaction images to users of the app and other\ninterested members of the public. \n\n"}
{"id": "1803.04924", "contents": "Title: Dense Limit of the Dawid-Skene Model for Crowdsourcing and Regions of\n  Sub-optimality of Message Passing Algorithms Abstract: Crowdsourcing is a strategy to categorize data through the contribution of\nmany individuals. A wide range of theoretical and algorithmic contributions are\nbased on the model of Dawid and Skene [1]. Recently it was shown in [2,3] that,\nin certain regimes, belief propagation is asymptotically optimal for data\ngenerated from the Dawid-Skene model. This paper is motivated by this recent\nprogress. We analyze the dense limit of the Dawid-Skene model. It is shown that\nit belongs to a larger class of low-rank matrix estimation problems for which\nit is possible to express the asymptotic, Bayes-optimal, performance in a\nsimple closed form. In the dense limit the mapping to a low-rank matrix\nestimation problem provides an approximate message passing algorithm that\nsolves the problem algorithmically. We identify the regions where the algorithm\nefficiently computes the Bayes-optimal estimates. Our analysis refines the\nresults of [2,3] about optimality of message passing algorithms by\ncharacterizing regions of parameters where these algorithms do not match the\nBayes-optimal performance. We further study numerically the performance of\napproximate message passing, derived in the dense limit, on sparse instances\nand carry out experiments on a real world dataset. \n\n"}
{"id": "1803.09394", "contents": "Title: A vertex reconstruction algorithm in the central detector of JUNO Abstract: The Jiangmen Underground Neutrino Observatory (JUNO) is designed to study\nneutrino mass hierarchy and measure three of the neutrino oscillation\nparameters with high precision using reactor antineutrinos. It is also able to\nstudy many other physical phenomena, including supernova neutrinos, solar\nneutrinos, geo-neutrinos, atmosphere neutrinos, and so forth. The central\ndetector of JUNO contains 20,000~tons of liquid scintillator (LS) and about\n18,000 20-inch photomultiplier tubes (PMTs), which is the largest liquid\nscintillator one under construction in the world up today. The energy\nresolution is expected to be 3\\%/$\\sqrt{E(MeV)}$. To meet the requirements of\nthe experiment, an algorithm of vertex reconstruction, which takes into account\ntime and charge information of PMTs, has been developed by deploying the\nmaximum likelihood method and well understanding the complicated optical\nprocesses in the liquid scintillator. \n\n"}
{"id": "1803.09745", "contents": "Title: English verb regularization in books and tweets Abstract: The English language has evolved dramatically throughout its lifespan, to the\nextent that a modern speaker of Old English would be incomprehensible without\ntranslation. One concrete indicator of this process is the movement from\nirregular to regular (-ed) forms for the past tense of verbs. In this study we\nquantify the extent of verb regularization using two vastly disparate datasets:\n(1) Six years of published books scanned by Google (2003--2008), and (2) A\ndecade of social media messages posted to Twitter (2008--2017). We find that\nthe extent of verb regularization is greater on Twitter, taken as a whole, than\nin English Fiction books. Regularization is also greater for tweets geotagged\nin the United States relative to American English books, but the opposite is\ntrue for tweets geotagged in the United Kingdom relative to British English\nbooks. We also find interesting regional variations in regularization across\ncounties in the United States. However, once differences in population are\naccounted for, we do not identify strong correlations with socio-demographic\nvariables such as education or income. \n\n"}
{"id": "1803.10713", "contents": "Title: Biblioranking fundamental physics Abstract: We propose measures of the impact of research that improve on existing ones\nsuch as counting of number of papers, citations and $h$-index. Since different\npapers and different fields have largely different average number of co-authors\nand of references we replace citations with individual citations, shared among\nco-authors. Next, we improve on citation counting applying the PageRank\nalgorithm to citations among papers. Being time-ordered, this reduces to a\nweighted counting of citation descendants that we call PaperRank. Similarly, we\ncompute an AuthorRank applying the PageRank algorithm to citations among\nauthors. These metrics quantify the impact of an author or paper taking into\naccount the impact of those authors that cite it. Finally, we show how self-\nand circular- citations can be eliminated by defining a closed market of\ncitation-coins. We apply these metrics to the InSpire database that covers\nfundamental physics, ranking papers, authors, journals, institutes, towns,\ncountries, continents, genders, for all-time and in recent time periods. \n\n"}
{"id": "1804.00501", "contents": "Title: Multilayer Complex Network Descriptors for Color-Texture\n  Characterization Abstract: A new method based on complex networks is proposed for color-texture\nanalysis. The proposal consists on modeling the image as a multilayer complex\nnetwork where each color channel is a layer, and each pixel (in each color\nchannel) is represented as a network vertex. The network dynamic evolution is\naccessed using a set of modeling parameters (radii and thresholds), and new\ncharacterization techniques are introduced to capt information regarding within\nand between color channel spatial interaction. An automatic and adaptive\napproach for threshold selection is also proposed. We conduct classification\nexperiments on 5 well-known datasets: Vistex, Usptex, Outex13, CURet and MBT.\nResults among various literature methods are compared, including deep\nconvolutional neural networks with pre-trained architectures. The proposed\nmethod presented the highest overall performance over the 5 datasets, with 97.7\nof mean accuracy against 97.0 achieved by the ResNet convolutional neural\nnetwork with 50 layers. \n\n"}
{"id": "1804.01465", "contents": "Title: Predicting interactions between individuals with structural and\n  dynamical information Abstract: Capturing both the structural and temporal aspects of interactions is crucial\nfor many real world datasets like contact between individuals. Using the link\nstream formalism to capture the dynamic of the systems, we tackle the issue of\nactivity prediction in link streams, that is to say predicting the number of\nlinks occurring during a given period of time and we present a protocol that\ntakes advantage of the temporal and structural information contained in the\nlink stream. Using a supervised learning method, we are able to model the\ndynamic of our system to improve the prediction. We investigate the behavior of\nour algorithm and crucial elements affecting the prediction. By introducing\ndifferent categories of pair of nodes, we are able to improve the quality as\nwell as increase the diversity of our prediction. \n\n"}
{"id": "1804.03269", "contents": "Title: Characterising information-theoretic storage and transfer in continuous\n  time processes Abstract: The characterisation of information processing is an important task in\ncomplex systems science. Information dynamics is a quantitative methodology for\nmodelling the intrinsic information processing conducted by a process\nrepresented as a time series, but to date has only been formulated in discrete\ntime. Building on previous work which demonstrated how to formulate transfer\nentropy in continuous time, we give a total account of information processing\nin this setting, incorporating information storage. We find that a convergent\nrate of predictive capacity, comprised of the transfer entropy and active\ninformation storage, does not exist, arising through divergent rates of active\ninformation storage. We identify that active information storage can be\ndecomposed into two separate quantities that characterise predictive capacity\nstored in a process: active memory utilisation and instantaneous predictive\ncapacity. The latter involves prediction related to path regularity and so\nsolely inherits the divergent properties of the active information storage,\nwhilst the former permits definitions of pathwise and rate quantities. We\nformulate measures of memory utilisation for jump and neural spiking processes\nand illustrate measures of information processing in synthetic neural spiking\nmodels and coupled Ornstein-Uhlenbeck models. The application to synthetic\nneural spiking models demonstrates that active memory utilisation for point\nprocesses consists of discontinuous jump contributions (at spikes) interrupting\na continuously varying contribution (relating to waiting times between spikes),\ncomplementing the behaviour previously demonstrated for transfer entropy in\nthese processes. \n\n"}
{"id": "1804.03665", "contents": "Title: An information-theoretic, all-scales approach to comparing networks Abstract: As network research becomes more sophisticated, it is more common than ever\nfor researchers to find themselves not studying a single network but needing to\nanalyze sets of networks. An important task when working with sets of networks\nis network comparison, developing a similarity or distance measure between\nnetworks so that meaningful comparisons can be drawn. The best means to\naccomplish this task remains an open area of research. Here we introduce a new\nmeasure to compare networks, the Network Portrait Divergence, that is\nmathematically principled, incorporates the topological characteristics of\nnetworks at all structural scales, and is general-purpose and applicable to all\ntypes of networks. An important feature of our measure that enables many of its\nuseful properties is that it is based on a graph invariant, the network\nportrait. We test our measure on both synthetic graphs and real world networks\ntaken from protein interaction data, neuroscience, and computational social\nscience applications. The Network Portrait Divergence reveals important\ncharacteristics of multilayer and temporal networks extracted from data. \n\n"}
{"id": "1804.04422", "contents": "Title: The incentive (in)compatibility of group-based qualification systems Abstract: Tournament organisers supposedly design rules such that a team cannot be\nstrictly better off by exerting a lower effort. However, the European\nqualification tournaments for recent FIFA soccer World Cups are known to\nviolate this requirement, which inspires our study on the incentive\ncompatibility of similar group-based qualification systems. Theorems listing\nthe sufficient and necessary conditions of strategy-proofness are provided and\napplied to classify several soccer qualification tournaments for FIFA World\nCups and UEFA European Championships. Two reasonable mechanisms are proposed to\nsolve the problem of incentive incompatibility: the first is based on\nabolishing the anonymity of the matches discarded in the comparison of teams\nfrom different groups, while the second involves a rethinking of the seeding\nprocedure. Our results have useful implications for the governing bodies of\nmajor sports. \n\n"}
{"id": "1804.06465", "contents": "Title: Triggers for cooperative behavior in the thermodynamic limit: a case\n  study in Public goods game Abstract: In this work, we aim to answer the question: what triggers cooperative\nbehavior in the thermodynamic limit by taking recourse to the Public goods\ngame. Using the idea of mapping the 1D Ising model Hamiltonian with nearest\nneighbor coupling to payoffs in the game theory we calculate the Magnetisation\nof the game in the thermodynamic limit. We see a phase transition in the\nthermodynamic limit of the two player Public goods game. We observe that\npunishment acts as an external field for the two player Public goods game\ntriggering cooperation or provide strategy, while cost can be a trigger for\nsuppressing cooperation or free riding. Finally, reward also acts as a trigger\nfor providing while the role of inverse temperature (fluctuations in choices)\nis to introduce randomness in strategic choices. \n\n"}
{"id": "1804.06892", "contents": "Title: Statistical algorithms for particle trajectography Abstract: The various algorithms used to extrapolate particle trajectories from\nmeasurements are often very time-consuming with computational complexities\nwhich are typically quadratic. In this article, we propose a new algorithm\ncalled GEM with a lower complexity and reasonable performance on linear tracks.\nIt is an extension of the EM algorithm used to fit Gaussian mixtures. It works\nin arbitrary dimension and with an arbitrary number of simultaneous particles.\nIn a second part, we extend it to circular tracks (for charged particles) and\neven a mix of linear and circular tracks. This algorithm is implemented in an\nopen-source library called libgem and two applications are proposed, based on\ndata-sets from two kind of particle trackers. \n\n"}
{"id": "1804.07223", "contents": "Title: Phase Transition of the 2-Choices Dynamics on Core-Periphery Networks Abstract: Consider the following process on a network: Each agent initially holds\neither opinion blue or red; then, in each round, each agent looks at two random\nneighbors and, if the two have the same opinion, the agent adopts it. This\nprocess is known as the 2-Choices dynamics and is arguably the most basic\nnon-trivial opinion dynamics modeling voting behavior on social networks.\nDespite its apparent simplicity, 2-Choices has been analytically characterized\nonly on restricted network classes---under assumptions on the initial\nconfiguration that establish it as a fast majority consensus protocol.\n  In this work, we aim at contributing to the understanding of the 2-Choices\ndynamics by considering its behavior on a class of networks with core-periphery\nstructure, a well-known topological assumption in social networks. In a\nnutshell, assume that a densely-connected subset of agents, the core, holds a\ndifferent opinion from the rest of the network, the periphery. Then, depending\non the strength of the cut between the core and the periphery, a\nphase-transition phenomenon occurs: Either the core's opinion rapidly spreads\namong the rest of the network, or a metastability phase takes place, in which\nboth opinions coexist in the network for superpolynomial time. The interest of\nour result is twofold. On the one hand, by looking at the 2-Choices dynamics as\na simplistic model of competition among opinions in social networks, our\ntheorem sheds light on the influence of the core on the rest of the network, as\na function of the core's connectivity toward the latter. On the other hand, we\nprovide one of the first analytical results which shows a heterogeneous\nbehavior of a simple dynamics as a function of structural parameters of the\nnetwork. Finally, we validate our theoretical predictions with extensive\nexperiments on real networks. \n\n"}
{"id": "1804.07352", "contents": "Title: The impact of margin trading on share price evolution: A cascading\n  failure model investigation Abstract: Margin trading in which investors purchase shares with money borrowed from\nbrokers is blamed to be a major cause of the 2015 Chinese stock market crash.\nWe propose a cascading failure model and examine how an increase in margin\ntrading increases share price vulnerability. The model is based on a bipartite\ngraph of investors and shares that includes four margin trading factors, (i)\ninitial margin $k$, (ii) minimum maintenance $r$, (iii) volatility $v$, and\n(iv) diversity $s$. We use our model to simulate margin trading and observe how\nthe share prices are affected by these four factors. The experimental results\nindicate that a stock market can be either vulnerable or stable. A stock market\nis vulnerable when an external shock can cause a cascading failure of its share\nprices. It is stable when its share prices are resilient to external shocks.\nFurthermore, we investigate how the cascading failure of share price is\naffected by these four factors, and find that by increasing $v$ and $r$ or\ndecreasing $k$ we increase the probability that the stock market will\nexperience a phase transition from stable to vulnerable. It is also found that\nincreasing $s$ decreases resilience and increases systematic risk. These\nfindings could be useful to regulators supervising margin trading activities. \n\n"}
{"id": "1804.08174", "contents": "Title: Stochastic Dynamics II: Finite Random Dynamical Systems, Linear\n  Representation, and Entropy Production Abstract: We study finite state random dynamical systems (RDS) and their induced Markov\nchains (MC) as stochastic models for complex dynamics. The linear\nrepresentation of deterministic maps in RDS are matrix-valued random variables\nwhose expectations correspond to the transition matrix of the MC. The\ninstantaneous Gibbs entropy, Shannon-Khinchin entropy per step, and the entropy\nproduction rate of the MC are discussed. These three concepts as key anchor\npoints in stochastic dynamics, characterize respectively the uncertainties of\nthe system at instant time $t$, the randomness generated per step, and the\ndynamical asymmetry with respect to time reversal. The entropy production rate,\nexpressed in terms of the cycle distributions, has found an expression in terms\nof the probability of the deterministic maps with the single attractor in the\nmaximum entropy RDS. For finite RDS with invertible transformations, the\nnon-negative entropy production rate of its MC is bounded above by the\nKullback-Leibler divergence of the probability of the deterministic maps with\nrespect to its time-reversal dual probability. \n\n"}
{"id": "1805.00850", "contents": "Title: Fast and accurate simulation of particle detectors using generative\n  adversarial networks Abstract: Deep generative models parametrised by neural networks have recently started\nto provide accurate results in modelling natural images. In particular,\ngenerative adversarial networks provide an unsupervised solution to this\nproblem. In this work we apply this kind of technique to the simulation of\nparticle-detector response to hadronic jets. We show that deep neural networks\ncan achieve high-fidelity in this task, while attaining a speed increase of\nseveral orders of magnitude with respect to traditional algorithms. \n\n"}
{"id": "1805.00931", "contents": "Title: Exact Spectral Form Factor in a Minimal Model of Many-Body Quantum Chaos Abstract: The most general and versatile defining feature of quantum chaotic systems is\nthat they possess an energy spectrum with correlations universally described by\nrandom matrix theory (RMT). This feature can be exhibited by systems with a\nwell defined classical limit as well as by systems with no classical\ncorrespondence, such as locally interacting spins or fermions. Despite great\nphenomenological success, a general mechanism explaining the emergence of RMT\nwithout reference to semiclassical concepts is still missing. Here we provide\nthe example of a quantum many-body system with no semiclassical limit (no large\nparameter) where the emergence of RMT spectral correlations is proven exactly.\nSpecifically, we consider a periodically driven Ising model and write the\nFourier transform of spectral density's two-point function, the spectral form\nfactor, in terms of a partition function of a two-dimensional classical Ising\nmodel featuring a space-time duality. We show that the self-dual cases provide\na minimal model of many-body quantum chaos, where the spectral form factor is\ndemonstrated to match RMT for all values of the integer time variable $t$ in\nthe thermodynamic limit. In particular, we rigorously prove RMT form factor for\nodd $t$, while we formulate a precise conjecture for even $t$. The results\nimply ergodicity for any finite amount of disorder in the longitudinal field,\nrigorously excluding the possibility of many-body localization. Our method\nprovides a novel route for obtaining exact nonperturbative results in\nnon-integrable systems. \n\n"}
{"id": "1805.01711", "contents": "Title: Using Quantum Mechanics to Cluster Time Series Abstract: In this article we present a method by which we can reduce a time series into\na single point in $\\mathbb{R}^{13}$. We have chosen 13 dimensions so as to\nprevent too many points from being labeled as \"noise.\" When using a Euclidean\n(or Mahalanobis) metric, a simple clustering algorithm will with near certainty\nlabel the majority of points as \"noise.\" On pure physical considerations, this\nis not possible. Included in our 13 dimensions are four parameters which\ndescribe the coefficients of a cubic polynomial attached to a Gaussian picking\nup a general trend, four parameters picking up periodicity in a time series,\ntwo each for amplitude of a wave and period of a wave, and the final five\nreport the \"leftover\" noise of the detrended and aperiodic time series. Of the\nfinal five parameters, four are the centralized probabilistic moments, and the\nfinal for the relative size of the series. The first main contribution of this\nwork is to apply a theorem of quantum mechanics about the completeness of the\nsolutions to the quantum harmonic oscillator on $L^2(\\mathbb{R})$ to estimating\ntrends in time series. The second main contribution is the method of fitting\nparameters. After many numerical trials, we realized that methods such a\nNewton-Rhaphson and Levenberg-Marquardt converge extremely fast if the initial\nguess is good. Thus we guessed many initial points in our parameter space and\ncomputed only a few iterations, a technique common in Keogh's work on time\nseries clustering. Finally, we have produced a model which gives incredibly\naccurate results quickly. We ackowledge that there are faster methods as well\nof more accurate methods, but this work shows that we can still increase\ncomputation speed with little, if any, cost to accuracy in the sense of data\nclustering. \n\n"}
{"id": "1805.02608", "contents": "Title: Anticipating contingengies in power grids using fast neural net\n  screening Abstract: We address the problem of maintaining high voltage power transmission\nnetworks in security at all time. This requires that power flowing through all\nlines remain below a certain nominal thermal limit above which lines might\nmelt, break or cause other damages. Current practices include enforcing the\ndeterministic \"N-1\" reliability criterion, namely anticipating exceeding of\nthermal limit for any eventual single line disconnection (whatever its cause\nmay be) by running a slow, but accurate, physical grid simulator. New\nconceptual frameworks are calling for a probabilistic risk based security\ncriterion and are in need of new methods to assess the risk. To tackle this\ndifficult assessment, we address in this paper the problem of rapidly ranking\nhigher order contingencies including all pairs of line disconnections, to\nbetter prioritize simulations. We present a novel method based on neural\nnetworks, which ranks \"N-1\" and \"N-2\" contingencies in decreasing order of\npresumed severity. We demonstrate on a classical benchmark problem that the\nresidual risk of contingencies decreases dramatically compared to considering\nsolely all \"N-1\" cases, at no additional computational cost. We evaluate that\nour method scales up to power grids of the size of the French high voltage\npower grid (over 1000 power lines). \n\n"}
{"id": "1805.03673", "contents": "Title: Optimality of the Maximum Likelihood estimator in Astrometry Abstract: The problem of astrometry is revisited from the perspective of analyzing the\nattainability of well-known performance limits (the Cramer-Rao bound) for the\nestimation of the relative position of light-emitting (usually point-like)\nsources on a CCD-like detector using commonly adopted estimators such as the\nweighted least squares and the maximum likelihood. Novel technical results are\npresented to determine the performance of an estimator that corresponds to the\nsolution of an optimization problem in the context of astrometry. Using these\nresults we are able to place stringent bounds on the bias and the variance of\nthe estimators in close form as a function of the data. We confirm these\nresults through comparisons to numerical simulations under a broad range of\nrealistic observing conditions. The maximum likelihood and the weighted least\nsquare estimators are analyzed. We confirm the sub-optimality of the weighted\nleast squares scheme from medium to high signal-to-noise found in an earlier\nstudy for the (unweighted) least squares method. We find that the maximum\nlikelihood estimator achieves optimal performance limits across a wide range of\nrelevant observational conditions. Furthermore, from our results, we provide\nconcrete insights for adopting an adaptive weighted least square estimator that\ncan be regarded as a computationally efficient alternative to the optimal\nmaximum likelihood solution. We provide, for the first time, close-form\nanalytical expressions that bound the bias and the variance of the weighted\nleast square and maximum likelihood implicit estimators for astrometry using a\nPoisson-driven detector. These expressions can be used to formally assess the\nprecision attainable by these estimators in comparison with the minimum\nvariance bound. \n\n"}
{"id": "1805.06797", "contents": "Title: Large algebraic connectivity fluctuations in spatial network ensembles\n  imply a predictive advantage from node location information Abstract: A Random Geometric Graph (RGG) ensemble is defined by the disordered\ndistribution of its node locations. We investigate how this randomness drives\nsample-to-sample fluctuations in the dynamical properties of these graphs. We\nstudy the distributional properties of the algebraic connectivity which is\ninformative of diffusion and synchronization timescales in graphs. We use\nnumerical simulations to provide the first characterisation of the algebraic\nconnectivity distribution for RGG ensembles. We find that the algebraic\nconnectivity can show fluctuations relative to its mean on the order of $30\n\\%$, even for relatively large RGG ensembles ($N=10^5$). We explore the factors\ndriving these fluctuations for RGG ensembles with different choices of\ndimensionality, boundary conditions and node distributions. Within a given\nensemble, the algebraic connectivity can covary with the minimum degree and can\nalso be affected by the presence of density inhomogeneities in the nodal\ndistribution. We also derive a closed-form expression for the expected\nalgebraic connectivity for RGGs with periodic boundary conditions for general\ndimension. \n\n"}
{"id": "1805.06929", "contents": "Title: A new $\\kappa$-deformed parametric model for the size distribution of\n  wealth Abstract: It has been pointed out by Patriarca et al. (2005) that the power-law tailed\nequilibrium distribution in heterogeneous kinetic exchange models with a\ndistributed saving parameter can be resolved as a mixture of Gamma\ndistributions corresponding to particular subsets of agents. Here, we propose a\nnew four-parameter statistical distribution which is a $\\kappa$-deformation of\nthe Generalized Gamma distribution with a power-law tail, based on the deformed\nexponential and logarithm functions introduced by Kaniadakis(2001). We found\nthat this new distribution is also an extension to the $\\kappa$-Generalized\ndistribution proposed by Clementi et al. (2007), with an additional shape\nparameter $\\nu$, and properly reproduces the whole range of the distribution of\nwealth in such heterogeneous kinetic exchange models. We also provide various\nassociated statistical measures and inequality measures. \n\n"}
{"id": "1805.06981", "contents": "Title: Peer-review under review - A statistical study on proposal ranking at\n  ESO. Part I: the pre-meeting phase Abstract: Peer review is the most common mechanism in place for assessing requests for\nresources in a large variety of scientific disciplines. One of the strongest\ncriticisms to this paradigm is the limited reproducibility of the process,\nespecially at largely oversubscribed facilities. In this and in a subsequent\npaper we address this specific aspect in a quantitative way, through a\nstatistical study on proposal ranking at the European Southern Observatory. For\nthis purpose we analysed a sample of about 15000 proposals, submitted by more\nthan 3000 Principal Investigators over 8 years. The proposals were reviewed by\nmore than 500 referees, who assigned over 140000 grades in about 200 panel\nsessions. After providing a detailed analysis of the statistical properties of\nthe sample, the paper presents an heuristic model based on these findings,\nwhich is then used to provide quantitative estimates of the reproducibility of\nthe pre-meeting process. On average, about one third of the proposals ranked in\nthe top quartile by one referee are ranked in the same quartile by any other\nreferee of the panel. A similar value is observed for the bottom quartile. In\nthe central quartiles, the agreement fractions are very marginally above the\nvalue expected for a fully aleatory process (25%). The agreement fraction\nbetween two panels composed by 6 referees is 55+/-5% (50% confidence level) for\nthe top and bottom quartiles. The corresponding fraction for the central\nquartiles is 33+/-5%. The model predictions are confirmed by the results\nobtained from boot-strapping the data for sub-panels composed by 3 referees,\nand fully consistent with the NIPS experiment. The post-meeting phase will be\npresented and discussed in a forthcoming paper. \n\n"}
{"id": "1805.07601", "contents": "Title: Deep Generative Markov State Models Abstract: We propose a deep generative Markov State Model (DeepGenMSM) learning\nframework for inference of metastable dynamical systems and prediction of\ntrajectories. After unsupervised training on time series data, the model\ncontains (i) a probabilistic encoder that maps from high-dimensional\nconfiguration space to a small-sized vector indicating the membership to\nmetastable (long-lived) states, (ii) a Markov chain that governs the\ntransitions between metastable states and facilitates analysis of the long-time\ndynamics, and (iii) a generative part that samples the conditional distribution\nof configurations in the next time step. The model can be operated in a\nrecursive fashion to generate trajectories to predict the system evolution from\na defined starting state and propose new configurations. The DeepGenMSM is\ndemonstrated to provide accurate estimates of the long-time kinetics and\ngenerate valid distributions for molecular dynamics (MD) benchmark systems.\nRemarkably, we show that DeepGenMSMs are able to make long time-steps in\nmolecular configuration space and generate physically realistic structures in\nregions that were not seen in training data. \n\n"}
{"id": "1805.08310", "contents": "Title: Effect of Social Media on Opinion Formation Abstract: In this work, we investigate the effect of social media on the process of\nopinion formation in a human population. This effect is modeled as an external\nfield in the dynamics of the two-dimensional Sznajd model with a probability P\nfor an agent to follow the social media. We investigate the evolution of\nmagnetization, the distribution of decision time and the average relaxation\ntime in the presence of the external field. Our results suggest that the\naverage relaxation time on the lattice of size L follows a power law, where the\nexponent depends on the probability P. We also show that phase transition\nbetween two distinct states of the system decreases for any initial\ndistribution of the opinions as the probability P is increasing. For a critical\npoint of P ~ 0.18, no phase transition is observed and the system evolves to a\ndictatorship regardless of the initial distribution of the opinions in the\npopulation. \n\n"}
{"id": "1805.08550", "contents": "Title: Anticipating cryptocurrency prices using machine learning Abstract: Machine learning and AI-assisted trading have attracted growing interest for\nthe past few years. Here, we use this approach to test the hypothesis that the\ninefficiency of the cryptocurrency market can be exploited to generate abnormal\nprofits. We analyse daily data for $1,681$ cryptocurrencies for the period\nbetween Nov. 2015 and Apr. 2018. We show that simple trading strategies\nassisted by state-of-the-art machine learning algorithms outperform standard\nbenchmarks. Our results show that nontrivial, but ultimately simple,\nalgorithmic mechanisms can help anticipate the short-term evolution of the\ncryptocurrency market. \n\n"}
{"id": "1805.08740", "contents": "Title: A change of perspective in network centrality Abstract: Typing Yesterday into the search-bar of your browser provides a long list of\nwebsites with, in top places, a link to a video by The Beatles. The order your\nbrowser shows its search results is a notable example of the use of network\ncentrality. Centrality is a measure of the importance of the nodes in a network\nand it plays a crucial role in a huge number of fields, ranging from sociology\nto engineering, and from biology to economics. Many metrics are available to\nevaluate centrality. However, centrality measures are generally based on ad hoc\nassumptions, and there is no commonly accepted way to compare the effectiveness\nand reliability of different metrics. Here we propose a new perspective where\ncentrality definition arises naturally from the most basic feature of a\nnetwork, its adjacency matrix. Following this perspective, different centrality\nmeasures naturally emerge, including the degree, eigenvector, and hub-authority\ncentrality. Within this theoretical framework, the accuracy of different\nmetrics can be compared. Tests on a large set of networks show that the\nstandard centrality metrics perform unsatisfactorily, highlighting intrinsic\nlimitations of these metrics for describing the centrality of nodes in complex\nnetworks. More informative multi-component centrality metrics are proposed as\nthe natural extension of standard metrics. \n\n"}
{"id": "1805.09943", "contents": "Title: Training of photonic neural networks through in situ backpropagation Abstract: Recently, integrated optics has gained interest as a hardware platform for\nimplementing machine learning algorithms. Of particular interest are artificial\nneural networks, since matrix-vector multi- plications, which are used heavily\nin artificial neural networks, can be done efficiently in photonic circuits.\nThe training of an artificial neural network is a crucial step in its\napplication. However, currently on the integrated photonics platform there is\nno efficient protocol for the training of these networks. In this work, we\nintroduce a method that enables highly efficient, in situ training of a\nphotonic neural network. We use adjoint variable methods to derive the photonic\nanalogue of the backpropagation algorithm, which is the standard method for\ncomputing gradients of conventional neural networks. We further show how these\ngradients may be obtained exactly by performing intensity measurements within\nthe device. As an application, we demonstrate the training of a numerically\nsimulated photonic artificial neural network. Beyond the training of photonic\nmachine learning implementations, our method may also be of broad interest to\nexperimental sensitivity analysis of photonic systems and the optimization of\nreconfigurable optics platforms. \n\n"}
{"id": "1805.11673", "contents": "Title: The Impact of Climate Change on a Cost-Optimal Highly Renewable European\n  Electricity Network Abstract: We use three ensemble members of the EURO-CORDEX project and their data on\nsurface wind speeds, solar irradiation as well as water runoff with a spatial\nresolution of 12 km and a temporal resolution of 3 hours under representative\nconcentration pathway 8.5 (associated with a temperature increase of 2.6 to 4.8\ndegrees C until the end of the century) until 2100 to investigate the impact of\nclimate change on wind, solar and hydro resources and consequently on a highly\nrenewable and cost-optimal European power system. The weather data is\ntransformed into power, different aspects such as capacity factors and\ncorrelation lengths are investigated and the resulting implications for the\nEuropean power system are discussed. In addition, we compare a 30-node model of\nEurope with historical and climate change-affected data, where investments in\ngeneration, transmission and storage facilities are optimised for deep carbon\ndioxide reductions. Differences in capacity factors among European countries\nare more strongly emphasized at the end of the century compared to historic\ndata. This results in a significantly increased photovoltaic share in the\ncost-optimal power system. System costs increase by 5% until the end of the\ncentury and the impact of climate change on these costs is of similar magnitude\nas differences between the ensemble members. \n\n"}
{"id": "1805.12572", "contents": "Title: A comparison of partisan-gerrymandering measures Abstract: We compare and contrast fourteen measures that have been proposed for the\npurpose of quantifying partisan gerrymandering. We consider measures that,\nrather than examining the shapes of districts, utilize only the partisan vote\ndistribution among districts. The measures considered are two versions of\npartisan bias; the efficiency gap and several of its variants; the mean-median\ndifference and the equal vote weight standard; the declination and one variant;\nand the lopsided-means test. Our primary means of evaluating these measures is\na suite of hypothetical elections we classify from the start as fair or unfair.\nWe conclude that the declination is the most successful measure in terms of\navoiding false positives and false negatives on the elections considered. We\ninclude in an appendix the most extreme outliers for each measure among\nhistorical congressional and state legislative elections. \n\n"}
{"id": "1806.00128", "contents": "Title: Brain networks reveal the effects of antipsychotic drugs on\n  schizophrenia patients and controls Abstract: The study of brain networks, including derived from functional neuroimaging\ndata, attracts broad interest and represents a rapidly growing\ninterdisciplinary field. Comparing networks of healthy volunteers with those of\npatients can potentially offer new, quantitative diagnostic methods, and a\nframework for better understanding brain and mind disorders. We explore resting\nstate fMRI data through network measures, and demonstrate that not only is\nthere a distinctive network architecture in the healthy brain that is disrupted\nin schizophrenia, but also that both networks respond to medication. We\nconstruct networks representing 15 healthy individuals and 12 schizophrenia\npatients (males and females), all of whom are administered three drug\ntreatments: (i) a placebo; and two antipsychotic medications (ii) aripiprazole\nand; (iii) sulpiride. We first reproduce the established finding that brain\nnetworks of schizophrenia patients exhibit increased efficiency and reduced\nclustering compared to controls. Our data then reveals that the antipsychotic\nmedications mitigate this effect, shifting the metrics towards those observed\nin healthy volunteers, with a marked difference in efficacy between the two\ndrugs. Additionally, we find that aripiprazole considerably alters the network\nstatistics of healthy controls. Using a test of cognitive ability, we establish\nthat aripiprazole also adversely affects their performance. This provides\nevidence that changes to macroscopic brain network architecture result in\nmeasurable behavioural differences. This is the first time different\nmedications have been assessed in this way. Our results lay the groundwork for\nan objective methodology with which to calculate and compare the efficacy of\ndifferent treatments of mind and brain disorders. \n\n"}
{"id": "1806.00433", "contents": "Title: Unfolding with Generative Adversarial Networks Abstract: Correcting measured detector-level distributions to particle-level is\nessential to make data usable outside the experimental collaborations. The term\nunfolding is used to describe this procedure. A new method of unfolding data\nusing a modified Generative Adversarial Network (MSGAN) is presented here.\nApplied to various distributions with widely different shapes, it performs\nroughly at par with currently used methods. This is a proof-of-principle\ndemonstration of a state-of-the-art machine learning method that can be used to\nmodel detector effects well. \n\n"}
{"id": "1806.01174", "contents": "Title: Two novel immunization strategies for epidemic control in directed\n  scale-free networks with nonlinear infectivity Abstract: In this paper, we propose two novel immunization strategies, i.e., combined\nimmunization and duplex immunization, for SIS model in directed scale-free\nnetworks, and obtain the epidemic thresholds for them with linear and nonlinear\ninfectivities. With the suggested two new strategies, the epidemic thresholds\nafter immunization are greatly increased. For duplex immunization, we\ndemonstrate that its performance is the best among all usual immunization\nschemes with respect to degree distribution. And for combined immunization\nscheme, we show that it is more effective than active immunization. Besides, we\ngive a comprehensive theoretical analysis on applying targeted immunization to\ndirected networks. For targeted immunization strategy, we prove that immunizing\nnodes with large out-degrees are more effective than immunizing nodes with\nlarge in-degrees, and nodes with both large out-degrees and large in-degrees\nare more worthy to be immunized than nodes with only large out-degrees or large\nin-degrees. Finally, some numerical analysis are performed to verify and\ncomplement our theoretical results. This work is the first to divide the whole\npopulation into different types and embed appropriate immunization scheme\naccording to the characteristics of the population, and it will benefit the\nstudy of immunization and control of infectious diseases on complex networks. \n\n"}
{"id": "1806.02264", "contents": "Title: Differential Correlation Measurements with the Identity Method Abstract: We present an extension of the identity method initially introduced for\nparticle yield fluctuation studies towards measurements of differential\ncorrelations. The extension is developed and illustrated in the context of\nmeasurements of the normalized two-particle cumulant $R_2$ but is adaptable to\nany correlation measurements, including differential flow measurements. The\nidentity method is also extended to account for an arbitrary number of particle\nidentification devices and signals. \n\n"}
{"id": "1806.03167", "contents": "Title: A spatial likelihood analysis for MAGIC telescope data Abstract: Context. The increase in sensitivity of Imaging Atmospheric Cherenkov\nTelescopes (IACTs) has lead to numerous detections of extended $\\gamma$-ray\nsources at TeV energies, sometimes of sizes comparable to the instrument's\nfield of view (FoV). This creates a demand for advanced and flexible data\nanalysis methods, able to extract source information by utilising the photon\ncounts in the entire FoV.\n  Aims. We present a new software package, \"SkyPrism\", aimed at performing 2D\n(3D if energy is considered) fits of IACT data, possibly containing multiple\nand extended sources, based on sky images binned in energy. Though the\ndevelopment of this package was focused on the analysis of data collected with\nthe MAGIC telescopes, it can further be adapted to other instruments, such as\nthe future Cherenkov Telescope Array (CTA).\n  Methods. We have developed a set of tools that, apart from sky images (count\nmaps), compute the instrument response functions (IRFs) of MAGIC (effective\nexposure throughout the FoV, point spread function (PSF), energy resolution and\nbackground shape), based on the input data, Monte-Carlo simulations and the\npointing track of the telescopes. With this information, the presented package\ncan perform a simultaneous maximum likelihood fit of source models of arbitrary\nmorphology to the sky images providing energy spectra, detection significances,\nand upper limits.\n  Results. We demonstrate that the SkyPrism tool accurately reconstructs the\nMAGIC PSF, on and off-axis performance as well as the underlying background. We\nfurther show that for a point source analysis with MAGIC's default\nobservational settings, SkyPrism gives results compatible with those of the\nstandard tools while being more flexible and widely applicable. \n\n"}
{"id": "1806.03350", "contents": "Title: PyUnfold: A Python Package for Iterative Unfolding Abstract: PyUnfold is a Python package for incorporating imperfections of the\nmeasurement process into a data analysis pipeline. In an ideal world, we would\nhave access to the perfect detector: an apparatus that makes no error in\nmeasuring a desired quantity. However, in real life, detectors have finite\nresolutions, characteristic biases that cannot be eliminated, less than full\ndetection efficiencies, and statistical and systematic uncertainties. By\nbuilding a matrix that encodes a detector's smearing of the desired true\nquantity into the measured observable(s), a deconvolution can be performed that\nprovides an estimate of the true variable. This deconvolution process is known\nas unfolding. The unfolding method implemented in PyUnfold accomplishes this\ndeconvolution via an iterative procedure, providing results based on physical\nexpectations of the desired quantity. Furthermore, tedious book-keeping for\nboth statistical and systematic errors produces precise final uncertainty\nestimates. \n\n"}
{"id": "1806.03405", "contents": "Title: Data based reconstruction of complex multiplex networks Abstract: It has been recognized that many complex dynamical systems in the real world\nrequire a description in terms of multiplex networks, where a set of common,\nmutually connected nodes belong to distinct network layers and play a different\nrole in each layer. In spite of recent progress towards data based inference of\nsingle-layer networks, to reconstruct complex systems with a multiplex\nstructure remains largely open. We articulate a mean-field based maximum\nlikelihood estimation framework to solve this outstanding and challenging\nproblem. We demonstrate the power of the reconstruction framework and\ncharacterize its performance using binary time series from a class of\nprototypical duplex network systems that host two distinct types of spreading\ndynamics. In addition to validating the framework using synthetic and\nreal-world multiplex networks, we carry out a detailed analysis to elucidate\nthe impacts of structural and dynamical parameters as well as noise on the\nreconstruction accuracy and robustness. \n\n"}
{"id": "1806.04032", "contents": "Title: Randomized reference models for temporal networks Abstract: Many dynamical systems can be successfully analyzed by representing them as\nnetworks. Empirically measured networks and dynamic processes that take place\nin these situations show heterogeneous, non-Markovian, and intrinsically\ncorrelated topologies and dynamics. This makes their analysis particularly\nchallenging. Randomized reference models (RRMs) have emerged as a general and\nversatile toolbox for studying such systems. Defined as random networks with\ngiven features constrained to match those of an input (empirical) network, they\nmay, for example, be used to identify important features of empirical networks\nand their effects on dynamical processes unfolding in the network. RRMs are\ntypically implemented as procedures that reshuffle an empirical network, making\nthem very generally applicable. However, the effects of most shuffling\nprocedures on network features remain poorly understood, rendering their use\nnontrivial and susceptible to misinterpretation. Here we propose a unified\nframework for classifying and understanding microcanonical RRMs (MRRMs) that\nsample networks with uniform probability. Focusing on temporal networks, we\nsurvey applications of MRRMs found in the literature, and we use this framework\nto build a taxonomy of MRRMs that proposes a canonical naming convention,\nclassifies them, and deduces their effects on a range of important network\nfeatures. We furthermore show that certain classes of MRRMs may be applied in\nsequential composition to generate new MRRMs from the existing ones surveyed in\nthis article. We finally provide a tutorial showing how to apply a series of\nMRRMs to analyze how different network features affect a dynamic process in an\nempirical temporal network. \n\n"}
{"id": "1806.04103", "contents": "Title: Thermodynamics of computing with circuits Abstract: Digital computers implement computations using circuits, as do many naturally\noccurring systems (e.g., gene regulatory networks). The topology of any such\ncircuit restricts which variables may be physically coupled during the\noperation of a circuit. We investigate how such restrictions on the physical\ncoupling affects the thermodynamic costs of running the circuit. To do this we\nfirst calculate the minimal additional entropy production that arises when we\nrun a given gate in a circuit. We then build on this calculation, to analyze\nhow the thermodynamic costs of implementing a computation with a full circuit,\ncomprising multiple connected gates, depends on the topology of that circuit.\nThis analysis provides a rich new set of optimization problems that must be\naddressed by any designer of a circuit, if they wish to minimize thermodynamic\ncosts. \n\n"}
{"id": "1806.05266", "contents": "Title: Statistical Significance of CP Violation in Long Baseline Neutrino\n  Experiments Abstract: The p-value or statistical significance of a CP conservation null hypothesis\ntest is determined from counting electron neutrino and antineutrino appearance\noscillation events. The statistical estimates include cases with background\nevents and different data sample sizes, graphical plots to interpret results\nand methods to combine p-values from different experiments. These estimates are\nuseful for optimizing the search for CP violation with different amounts of\nneutrino and antineutrino beam running, comparing results from different\nexperiments and for simple cross checks of more elaborate statistical estimates\nthat use likelihood fitting of neutrino parameters. \n\n"}
{"id": "1806.07343", "contents": "Title: Quantum Nash equilibrium in the thermodynamic limit Abstract: The quantum Nash equilibrium in the thermodynamic limit is studied for games\nlike quantum Prisoner's dilemma and the quantum game of chicken. A phase\ntransition is seen in both games as a function of the entanglement in the game.\nWe observe that for maximal entanglement irrespective of the classical payoffs,\na majority of players choose Quantum strategy over Defect in the thermodynamic\nlimit. \n\n"}
{"id": "1806.08259", "contents": "Title: Dynamic Network 3 -- 0 FIFA Rankings: Replacing an inaccurate, biased,\n  and exploitable ranking system Abstract: We explore the advantages of representing international football results as a\ndirected network in order to give each team a rank. Two network-based models\n--- Static and Dynamic --- are constructed and compared with the FIFA Rankings.\nThe Dynamic Model outperforms the FIFA Rankings in terms of World Cup\npredictive accuracy, while also removing continental bias and reducing the\nvulnerability of the FIFA Rankings to exploitation. \n\n"}
{"id": "1807.00083", "contents": "Title: Topology classification with deep learning to improve real-time event\n  selection at the LHC Abstract: We show how event topology classification based on deep learning could be\nused to improve the purity of data samples selected in real time at at the\nLarge Hadron Collider. We consider different data representations, on which\ndifferent kinds of multi-class classifiers are trained. Both raw data and\nhigh-level features are utilized. In the considered examples, a filter based on\nthe classifier's score can be trained to retain ~99% of the interesting events\nand reduce the false-positive rate by as much as one order of magnitude for\ncertain background processes. By operating such a filter as part of the online\nevent selection infrastructure of the LHC experiments, one could benefit from a\nmore flexible and inclusive selection strategy while reducing the amount of\ndownstream resources wasted in processing false positives. The saved resources\ncould be translated into a reduction of the detector operation cost or into an\neffective increase of storage and processing capabilities, which could be\nreinvested to extend the physics reach of the LHC experiments. \n\n"}
{"id": "1807.04775", "contents": "Title: Aging-induced continuous phase transition Abstract: Aging is considered as the property of the elements of a system to be less\nprone to change states as they get older. We incorporate aging into the noisy\nvoter model, a stochastic model in which the agents modify their binary state\nby means of noise and pair-wise interactions. Interestingly, due to aging the\nsystem passes from a finite-size discontinuous transition between ordered\n(ferromagnetic) and disordered (paramagnetic) phases to a second order phase\ntransition, well defined in the thermodynamic limit, belonging to the Ising\nuniversality class. We characterize it analytically by finding the stationary\nsolution of an infinite set of mean field equations. The theoretical\npredictions are tested with extensive numerical simulations in low dimensional\nlattices and complex networks. We finally employ the aging properties to\nunderstand the symmetries broken in the phase transition. \n\n"}
{"id": "1807.06312", "contents": "Title: Analytical approach to network inference: Investigating degree\n  distribution Abstract: When the network is reconstructed, two types of errors can occur: false\npositive and false negative errors about the presence or absence of links. In\nthis paper, the influence of these two errors on the vertex degree distribution\nis analytically analysed. Moreover, an analytic formula of the density of the\nbiased vertex degree distribution is found. In the inverse problem, we find a\nreliable procedure to reconstruct analytically the density of the vertex degree\ndistribution of any network based on the inferred network and estimates for the\nfalse positive and false negative errors based on, e.g., simulation studies. \n\n"}
{"id": "1807.06392", "contents": "Title: Equivalence between nonlinear dynamical systems and urn processes Abstract: An equivalence is shown between a large class of deterministic dynamical\nsystems and a class of stochastic processes, the balanced urn processes. These\ndynamical systems are governed by quasi-polynomial differential systems that\nare widely used in mathematical modeling while urn processes are actively\nstudied in combinatorics and probability theory. The presented equivalence\nextends a theorem by Flajolet et al. (Flajolet, Dumas and Puyhaubert Discr.\nMath. Theor. Comp. Sc. AG - 2006, DMTCS Proceedings) already establishing an\nisomorphism between urn processes and a particular class of differential\nsystems with monomial vector fields. The present result is based on the fact\nthat such monomial differential systems are canonical forms for more general\ndynamical systems. \n\n"}
{"id": "1807.07911", "contents": "Title: Application of the Iterated Weighted Least-Squares Fit to counting\n  experiments Abstract: Least-squares fits are an important tool in many data analysis applications.\nIn this paper, we review theoretical results, which are relevant for their\napplication to data from counting experiments. Using a simple example, we\nillustrate the well known fact that commonly used variants of the least-squares\nfit applied to Poisson-distributed data produce biased estimates. The bias can\nbe overcome with an iterated weighted least-squares method, which produces\nresults identical to the maximum-likelihood method. For linear models, the\niterated weighted least-squares method converges faster than the equivalent\nmaximum-likelihood method, and does not require problem-specific starting\nvalues, which may be a practical advantage. The equivalence of both methods\nalso holds for binomially distributed data. We further show that the unbinned\nmaximum-likelihood method can be derived as a limiting case of the iterated\nleast-squares fit when the bin width goes to zero, which demonstrates a deep\nconnection between the two methods. \n\n"}
{"id": "1807.09592", "contents": "Title: Graph Distance from the Topological View of Non-backtracking Cycles Abstract: Whether comparing networks to each other or to random expectation, measuring\ndissimilarity is essential to understanding the complex phenomena under study.\nHowever, determining the structural dissimilarity between networks is an\nill-defined problem, as there is no canonical way to compare two networks.\nIndeed, many of the existing approaches for network comparison differ in their\nheuristics, efficiency, interpretability, and theoretical soundness. Thus,\nhaving a notion of distance that is built on theoretically robust first\nprinciples and that is interpretable with respect to features ubiquitous in\ncomplex networks would allow for a meaningful comparison between different\nnetworks. Here we introduce a theoretically sound and efficient new measure of\ngraph distance, based on the \"length spectrum\" function from algebraic\ntopology, which compares the structure of two undirected, unweighted graphs by\nconsidering their non-backtracking cycles. We show how this distance relates to\nstructural features such as presence of hubs and triangles through the behavior\nof the eigenvalues of the so-called non-backtracking matrix, and we showcase\nits ability to discriminate between networks in both real and synthetic data\nsets. By taking a topological interpretation of non-backtracking cycles, this\nwork presents a novel application of Topological Data Analysis to the study of\ncomplex networks. \n\n"}
{"id": "1807.10044", "contents": "Title: Using validated reanalysis data to investigate the impact of the PV\n  system configurations at high penetration levels in European countries Abstract: Long-term hourly time series representing the PV generation in European\ncountries have been obtained and made available under open license. For every\ncountry, four different PV configurations, i.e. rooftop, optimum tilt,\ntracking, and delta have been investigated. These are shown to have a strong\ninfluence in the hourly difference between electricity demand and PV\ngeneration. To obtain PV time series, irradiance from CFSR reanalysis dataset\nis converted into electricity generation and aggregated at country level. Prior\nto conversion, reanalysis irradiance is bias corrected using satellite-based\nSARAH dataset and a globally-applicable methodology. Moreover, a novel\nprocedure is proposed to infer the orientation and inclination angles\nrepresentative for PV panels based on the historical PV output throughout the\ndays around summer and winter solstices. A key strength of the methodology is\nthat it doesn't rely on historical PV output data. Consequently, it can be\napplied in places with no existing knowledge of PV performance. \n\n"}
{"id": "1807.11386", "contents": "Title: On the Inability of Markov Models to Capture Criticality in Human\n  Mobility Abstract: We examine the non-Markovian nature of human mobility by exposing the\ninability of Markov models to capture criticality in human mobility. In\nparticular, the assumed Markovian nature of mobility was used to establish a\ntheoretical upper bound on the predictability of human mobility (expressed as a\nminimum error probability limit), based on temporally correlated entropy. Since\nits inception, this bound has been widely used and empirically validated using\nMarkov chains. We show that recurrent-neural architectures can achieve\nsignificantly higher predictability, surpassing this widely used upper bound.\nIn order to explain this anomaly, we shed light on several underlying\nassumptions in previous research works that has resulted in this bias. By\nevaluating the mobility predictability on real-world datasets, we show that\nhuman mobility exhibits scale-invariant long-range correlations, bearing\nsimilarity to a power-law decay. This is in contrast to the initial assumption\nthat human mobility follows an exponential decay. This assumption of\nexponential decay coupled with Lempel-Ziv compression in computing Fano's\ninequality has led to an inaccurate estimation of the predictability upper\nbound. We show that this approach inflates the entropy, consequently lowering\nthe upper bound on human mobility predictability. We finally highlight that\nthis approach tends to overlook long-range correlations in human mobility. This\nexplains why recurrent-neural architectures that are designed to handle\nlong-range structural correlations surpass the previously computed upper bound\non mobility predictability. \n\n"}
{"id": "1808.02652", "contents": "Title: Cooperation in Evolutionary Public Goods Game on Complex Networks with\n  Topology Change Abstract: The evolution of cooperation among unrelated individuals in human and animal\nsocieties remains a challenging issue across disciplines. It is an important\nsubject also in the evolutionary game theory to research how cooperation\narises. The subject has been extensively studied especially in Prisonars'\ndilemma game(PD) and the emergence of cooperation is important subject also in\npublic goods game(PGG).\n  In this article, we consider evolutionary PGG on complex networks where the\ntopology of the networks varies under the infulence of game dynamics. Then we\nstudy what effects on the evolution of player's strategies, defection and\ncooretation and the average payoff does the interaction between the game\ndynamics and the network topology bring. By investigating them by making\ncomputer simulations, we intend to clear in what situations cooperation\nstrategy is promoted or preserved. We also intend to investigate the infuluence\nof the interaction on the average payoff over all players. Furthermore how\ninitial networks are transformed to final networks by the evolution through the\ninfluences of PGG dynamics is invistigated. \n\n"}
{"id": "1808.04170", "contents": "Title: Impact of perception models on friendship paradox and opinion formation Abstract: Topological heterogeneities of social networks have a strong impact on the\nindividuals embedded in those networks. One of the interesting phenomena driven\nby such heterogeneities is the friendship paradox (FP), stating that the mean\ndegree of one's neighbors is larger than the degree of oneself. Alternatively,\none can use the median degree of neighbors as well as the fraction of neighbors\nhaving a higher degree than oneself. Each of these reflects on how people\nperceive their neighborhoods, i.e., their perception models, hence how they\nfeel peer pressure. In our paper, we study the impact of perception models on\nthe FP by comparing three versions of the perception model in networks\ngenerated with a given degree distribution and a tunable degree-degree\ncorrelation or assortativity. The increasing assortativity is expected to\ndecrease network-level peer pressure, while we find a nontrivial behavior only\nfor the mean-based perception model. By simulating opinion formation, in which\nthe opinion adoption probability of an individual is given as a function of\nindividual peer pressure, we find that it takes the longest time to reach\nconsensus when individuals adopt the median-based perception model, compared to\nother versions. Our findings suggest that one needs to consider the proper\nperception model for better modeling human behaviors and social dynamics. \n\n"}
{"id": "1808.05836", "contents": "Title: Topological Percolation on Hyperbolic Simplicial Complexes Abstract: Simplicial complexes are increasingly used to understand the topology of\ncomplex systems as different as brain networks and social interactions. It is\ntherefore of special interest to extend the study of percolation to simplicial\ncomplexes. Here we propose a topological theory of percolation for discrete\nhyperbolic simplicial complexes. Specifically we consider hyperbolic manifolds\nin dimension $d=2$ and $d=3$ formed by simplicial complexes, and we investigate\ntheir percolation properties in the presence of topological damage, i.e., when\nnodes, links, triangles or tetrahedra are randomly removed. We show that in\n$d=2$ simplicial complexes there are four topological percolation problems and\nin $d=3$, there are six. We demonstrate the presence of two percolation phase\ntransitions characteristic of hyperbolic spaces for the different variants of\ntopological percolation. While most of the known results on percolation in\nhyperbolic manifolds are in $d=2$, here we uncover the rich critical behavior\nof $d=3$ hyperbolic manifolds, and show that triangle percolation displays a\nBerezinskii-Kosterlitz-Thouless (BKT) transition. Finally we provide evidence\nthat topological percolation can display a critical behavior that is unexpected\nif only node and link percolation are considered. \n\n"}
{"id": "1808.10506", "contents": "Title: Maximum Entropy Principle Analysis in Network Systems with Short-time\n  Recordings Abstract: In many realistic systems, maximum entropy principle (MEP) analysis provides\nan effective characterization of the probability distribution of network\nstates. However, to implement the MEP analysis, a sufficiently long-time data\nrecording in general is often required, e.g., hours of spiking recordings of\nneurons in neuronal networks. The issue of whether the MEP analysis can be\nsuccessfully applied to network systems with data from short recordings has yet\nto be fully addressed. In this work, we investigate relationships underlying\nthe probability distributions, moments, and effective interactions in the MEP\nanalysis and then show that, with short recordings of network dynamics, the MEP\nanalysis can be applied to reconstructing probability distributions of network\nstates under the condition of asynchronous activity of nodes in the network.\nUsing spike trains obtained from both Hodgkin-Huxley neuronal networks and\nelectrophysiological experiments, we verify our results and demonstrate that\nMEP analysis provides a tool to investigate the neuronal population coding\nproperties, even for short recordings. \n\n"}
{"id": "1808.10698", "contents": "Title: Large Deviations of Convex Hulls of the \"True\" Self-Avoiding Random Walk Abstract: We study the distribution of the area and perimeter of the convex hull of the\n\"true\" self-avoiding random walk in a plane. Using a Markov chain Monte Carlo\nsampling method, we obtain the distributions also in their far tails, down to\nprobabilities like $10^{-800}$. This enables us to test previous conjectures\nregarding the scaling of the distribution and the large-deviation rate function\n$\\Phi$. In previous studies, e.g., for standard random walks, the whole\ndistribution was governed by the Flory exponent $\\nu$. We confirm this in the\npresent study by considering expected logarithmic corrections. On the other\nhand, the behavior of the rate function deviates from the expected form. For\nthis exception we give a qualitative reasoning. \n\n"}
{"id": "1808.10716", "contents": "Title: Influence Dynamics and Consensus in an Opinion-Neighborhood based\n  Modified Vicsek-like Social Network Abstract: We propose a modified Vicsek-like model to study influence dynamics and\nopinion formation in social networks. We work on the premise that opinions of\nmembers of a group may be considered to be analogous to the direction of motion\nof a particle in space. The opinions are susceptible to change under the\ninfluence of familiar individuals who maintain similar beliefs. This is unlike\nthe bounded-confidence models which solely rely on interactions based on\ncloseness of opinions. The influence network evolves either when similar-minded\nindividuals acquaint or when they fall out over their beliefs. This yields an\nadaptive network to which are assigned dynamic centrality scores and varying\ninfluence strengths. A mix of individuals - rigid and flexible - is assumed to\nconstitute groups - liberal and conservative. We analyse emergent group\nbehaviours subject to different initial conditions, agent types, their\ndensities and tolerances. The model accurately predicts the role of rigid\nagents in hampering consensus. Also, a few structural properties of the dynamic\nnetwork, which result as a consequence of the proposed model have been\nestablished. \n\n"}
{"id": "1809.00277", "contents": "Title: On the scaling patterns of infectious disease incidence in cities Abstract: Urban areas with larger and more connected populations offer an auspicious\nenvironment for contagion processes such as the spread of pathogens. Empirical\nevidence reveals a systematic increase in the rates of certain sexually\ntransmitted diseases (STDs) with larger urban population size. However, the\nmain drivers of these systemic infection patterns are still not well\nunderstood, and rampant urbanization rates worldwide makes it critical to\nadvance our understanding on this front. Using confirmed-cases data for three\nSTDs in US metropolitan areas, we investigate the scaling patterns of\ninfectious disease incidence in urban areas. The most salient features of these\npatterns are that, on average, the incidence of infectious diseases that\ntransmit with less ease-- either because of a lower inherent transmissibility\nor due to a less suitable environment for transmission-- scale more steeply\nwith population size, are less predictable across time and more variable across\ncities of similar size. These features are explained, first, using a simple\nmathematical model of contagion, and then through the lens of a new theory of\nurban scaling. These theoretical frameworks help us reveal the links between\nthe factors that determine the transmissibility of infectious diseases and the\nproperties of their scaling patterns across cities. \n\n"}
{"id": "1809.00885", "contents": "Title: Identifying long-term precursors of financial market crashes using\n  correlation patterns Abstract: The study of the critical dynamics in complex systems is always interesting\nyet challenging. Here, we choose financial market as an example of a complex\nsystem, and do a comparative analyses of two stock markets - the S&P 500 (USA)\nand Nikkei 225 (JPN). Our analyses are based on the evolution of\ncrosscorrelation structure patterns of short time-epochs for a 32-year period\n(1985-2016). We identify \"market states\" as clusters of similar correlation\nstructures, which occur more frequently than by pure chance (randomness). The\ndynamical transitions between the correlation structures reflect the evolution\nof the market states. Power mapping method from the random matrix theory is\nused to suppress the noise on correlation patterns, and an adaptation of the\nintra-cluster distance method is used to obtain the \"optimum\" number of market\nstates. We find that the USA is characterized by four market states and JPN by\nfive. We further analyze the co-occurrence of paired market states; the\nprobability of remaining in the same state is much higher than the transition\nto a different state. The transitions to other states mainly occur among the\nimmediately adjacent states, with a few rare intermittent transitions to the\nremote states. The state adjacent to the critical state (market crash) may\nserve as an indicator or a \"precursor\" for the critical state and this novel\nmethod of identifying the long-term precursors may be very helpful for\nconstructing the early warning system in financial markets, as well as in other\ncomplex systems. \n\n"}
{"id": "1809.03457", "contents": "Title: Event Graphs: Advances and Applications of Second-Order Time-Unfolded\n  Temporal Network Models Abstract: Recent advances in data collection and storage have allowed both researchers\nand industry alike to collect data in real time. Much of this data comes in the\nform of 'events', or timestamped interactions, such as email and social media\nposts, website clickstreams, or protein-protein interactions. This of type data\nposes new challenges for modelling, especially if we wish to preserve all\ntemporal features and structure. We propose a generalised framework to explore\ntemporal networks using second-order time-unfolded models, called event graphs.\nThrough examples we demonstrate how event graphs can be used to understand the\nhigher-order topological-temporal structure of temporal networks and capture\nproperties of the network that are unobserved when considering either a static\n(or time-aggregated) model. Furthermore, we show that by modelling a temporal\nnetwork as an event graph our analysis extends easily to consider non-dyadic\ninteractions, known as hyper-events. \n\n"}
{"id": "1809.05760", "contents": "Title: History of art paintings through the lens of entropy and complexity Abstract: Art is the ultimate expression of human creativity that is deeply influenced\nby the philosophy and culture of the corresponding historical epoch. The\nquantitative analysis of art is therefore essential for better understanding\nhuman cultural evolution. Here we present a large-scale quantitative analysis\nof almost 140 thousand paintings, spanning nearly a millennium of art history.\nBased on the local spatial patterns in the images of these paintings, we\nestimate the permutation entropy and the statistical complexity of each\npainting. These measures map the degree of visual order of artworks into a\nscale of order-disorder and simplicity-complexity that locally reflects\nqualitative categories proposed by art historians. The dynamical behavior of\nthese measures reveals a clear temporal evolution of art, marked by transitions\nthat agree with the main historical periods of art. Our research shows that\ndifferent artistic styles have a distinct average degree of entropy and\ncomplexity, thus allowing a hierarchical organization and clustering of styles\naccording to these metrics. We have further verified that the identified groups\ncorrespond well with the textual content used to qualitatively describe the\nstyles, and that the employed complexity-entropy measures can be used for an\neffective classification of artworks. \n\n"}
{"id": "1809.06190", "contents": "Title: A Network Topology Approach to Bot Classification Abstract: Automated social agents, or bots, are increasingly becoming a problem on\nsocial media platforms. There is a growing body of literature and multiple\ntools to aid in the detection of such agents on online social networking\nplatforms. We propose that the social network topology of a user would be\nsufficient to determine whether the user is a automated agent or a human. To\ntest this, we use a publicly available dataset containing users on Twitter\nlabelled as either automated social agent or human. Using an unsupervised\nmachine learning approach, we obtain a detection accuracy rate of 70%. \n\n"}
{"id": "1809.06293", "contents": "Title: Mapping structural diversity in networks sharing a given degree\n  distribution and global clustering: Adaptive resolution grid search evolution\n  with Diophantine equation-based mutations Abstract: Methods that generate networks sharing a given degree distribution and global\nclustering can induce changes in structural properties other than that\ncontrolled for. Diversity in structural properties, in turn, can affect the\noutcomes of dynamical processes operating on those networks. Since exhaustive\nsampling is not possible, we propose a novel evolutionary framework for mapping\nthis structural diversity. The three main features of this framework are: (a)\nsubgraph-based encoding of networks, (b) exact mutations based on solving\nsystems of Diophantine equations, and (c) heuristic diversity-driven mechanism\nto drive resolution changes in the MapElite algorithm. We show that our\nframework can elicit networks with diversity in their higher-order structure\nand that this diversity affects the behaviour of the complex contagion model.\nThrough a comparison with state of the art clustered network generation\nmethods, we demonstrate that our approach can uncover a comparably diverse\nrange of networks without needing computationally unfeasible mixing times.\nFurther, we suggest that the subgraph-based encoding provides greater\nconfidence in the diversity of higher-order network structure for low numbers\nof samples and is the basis for explaining our results with complex contagion\nmodel. We believe that this framework could be applied to other complex\nlandscapes that cannot be practically mapped via exhaustive sampling. \n\n"}
{"id": "1809.06966", "contents": "Title: Astrophysical S-factors, thermonuclear rates, and electron screening\n  potential for the $^3$He(d,p)$^{4}$He Big Bang reaction via a hierarchical\n  Bayesian model Abstract: We developed a hierarchical Bayesian framework to estimate S-factors and\nthermonuclear rates for the $^3$He(d,p)$^{4}$He reaction, which impacts the\nprimordial abundances of $^3$He and $^7$Li. The available data are evaluated\nand all direct measurements are taken into account in our analysis for which we\ncan estimate separate uncertainties for systematic and statistical effects. For\nthe nuclear reaction model, we adopt a single-level, two-channel approximation\nof R-matrix theory, suitably modified to take the effects of electron screening\nat lower energies into account. Apart from the usual resonance parameters\n(resonance location and reduced widths for the incoming and outgoing reaction\nchannel), we include for the first time the channel radii and boundary\ncondition in the fitting process. Our new analysis of the $^3$He(d,p)$^{4}$He\nS-factor data results in improved estimates for the thermonuclear rates. This\nwork represents the first nuclear rate evaluation using the R-matrix theory\nembedded into a hierarchical Bayesian framework, properly accounting for all\nknown sources of uncertainty. Therefore, it provides a test bed for future\nstudies of more complex reactions. \n\n"}
{"id": "1809.08004", "contents": "Title: Multi-Dimensional, Multilayer, Nonlinear and Dynamic HITS Abstract: We introduce a ranking model for temporal multi-dimensional weighted and\ndirected networks based on the Perron eigenvector of a multi-homogeneous\norder-preserving map. The model extends to the temporal multilayer setting the\nHITS algorithm and defines five centrality vectors: two for the nodes, two for\nthe layers, and one for the temporal stamps. Nonlinearity is introduced in the\nstandard HITS model in order to guarantee existence and uniqueness of these\ncentrality vectors for any network, without any requirement on its connectivity\nstructure. We introduce a globally convergent power iteration like algorithm\nfor the computation of the centrality vectors. Numerical experiments on\nreal-world networks are performed in order to assess the effectiveness of the\nproposed model and showcase the performance of the accompanying algorithm. \n\n"}
{"id": "1809.08855", "contents": "Title: Measuring the effect of node aggregation on community detection Abstract: Many times the nodes of a complex network, whether deliberately or not, are\naggregated for technical, ethical, legal limitations or privacy reasons. A\ncommon example is the geographic position: one may uncover communities in a\nnetwork of places, or of individuals identified with their typical geographical\nposition, and then aggregate these places into larger entities, such as\nmunicipalities, thus obtaining another network. The communities found in the\nnetworks obtained at various levels of aggregation may exhibit various degrees\nof similarity, from full alignment to perfect independence. This is akin to the\nproblem of ecological and atomic fallacies in statistics, or to the Modified\nAreal Unit Problem in geography. We identify the class of community detection\nalgorithms most suitable to cope with node aggregation, and develop an index\nfor aggregability, capturing to which extent the aggregation preserves the\ncommunity structure. We illustrate its relevance on real-world examples (mobile\nphone and Twitter reply-to networks). Our main message is that any\nnode-partitioning analysis performed on aggregated networks should be\ninterpreted with caution, as the outcome may be strongly influenced by the\nlevel of the aggregation. \n\n"}
{"id": "1809.09098", "contents": "Title: Propagation of wind-power-induced fluctuations in power grids Abstract: Renewable generators perturb the electric power grid with heavily\nnon-Gaussian and time correlated fluctuations. While changes in generated power\non timescales of minutes and hours are compensated by frequency control\nmeasures, we report subsecond distribution grid frequency measurements with\nlocal non-Gaussian fluctuations which depend on the magnitude of wind power\ngeneration in the grid. Motivated by such experimental findings, we simulate\nthe sub-second grid frequency dynamics by perturbing the power grid, as modeled\nby a network of phase coupled nonlinear oscillators, with synthetically\ngenerated wind power feed-in time series. We derive a linear response theory\nand obtain analytical results for the variance of frequency increment\ndistributions. We find that the variance of short-term fluctuations decays, for\nlarge inertia, exponentially with distance to the feed-in node, in agreement\nwith numerical results both for a linear chain of nodes and the German\ntransmission grid topology. In sharp contrast, the kurtosis of frequency\nincrements is numerically found to decay only slowly, not exponentially, in\nboth systems, indicating that the non-Gaussian shape of frequency fluctuations\npersists over long ranges. \n\n"}
{"id": "1809.09291", "contents": "Title: Dynamic Scaling, Data-collapse and Self-Similarity in Mediation-Driven\n  Attachment Networks Abstract: Recently, we have shown that if the $i$th node of the Barab\\'{a}si-Albert\n(BA) network is characterized by the generalized degree\n$q_i(t)=k_i(t)t_i^\\beta/m$, where $k_i(t)\\sim t^\\beta$ and $m$ are its degree\nat current time $t$ and at birth time $t_i$, then the corresponding\ndistribution function $F(q,t)$ exhibits dynamic scaling. Applying the same idea\nto our recently proposed mediation-driven attachment (MDA) network, we find\nthat it too exhibits dynamic scaling but, unlike the BA model, the exponent\n$\\beta$ of the MDA model assumes a spectrum of value $1/2\\leq \\beta \\leq 1$.\nMoreover, we find that the scaling curves for small $m$ are significantly\ndifferent from those of the larger $m$ and the same is true for the BA networks\nalbeit in a lesser extent. We use the idea of the distribution of inverse\nharmonic mean (IHM) of the neighbours of each node and show that the number of\ndata points that follow the power-law degree distribution increases as the\nskewness of the IHM distribution decreases. Finally, we show that both MDA and\nBA models become almost identical for large $m$. \n\n"}
{"id": "1809.10369", "contents": "Title: Impact of CO2 prices on the design of a highly decarbonised coupled\n  electricity and heating system in Europe Abstract: Ambitious targets for renewable energy and CO2 taxation both represent\npolitical instruments for decarbonisation of the energy system. We model a high\nnumber of coupled electricity and heating systems, where the primary sources of\nCO2 neutral energy are from variable renewable energy sources (VRES), i.e.,\nwind and solar generators. The model includes hourly dispatch of all\ntechnologies for a full year for every country in Europe. In each model run,\nthe amount of renewable energy and the level of CO2 tax are fixed exogenously,\nwhile the cost-optimal composition of energy generation, conversion,\ntransmission and storage technologies and the corresponding CO2 emissions are\ncalculated. We show that even for high penetrations of VRES, a significant CO2\ntax of more than 100 euro/tCO2 is required to limit the combined CO2 emissions\nfrom the sectors to less than 5% of 1990 levels, because curtailment of VRES,\ncombustion of fossil fuels and inefficient conversion technologies are\neconomically favoured despite the presence of abundant VRES. A sufficiently\nhigh CO2 tax results in the more efficient use of VRES by means of heat pumps\nand hot water storage, in particular. We conclude that a renewable energy\ntarget on its own is not sufficient; in addition, a CO2 tax is required to\ndecarbonise the electricity and heating sectors and incentivise the least cost\ncombination of flexible and efficient energy conversion and storage. \n\n"}
{"id": "1809.10747", "contents": "Title: Constraining neutrino mass with tomographic weak lensing one-point\n  probability distribution function and power spectrum Abstract: We study the constraints on neutrino mass sum (M_nu) from the one-point\nprobability distribution function (PDF) and power spectrum of weak lensing\nmeasurements for an LSST-like survey, using the MassiveNuS simulations. The PDF\nprovides access to non-Gaussian information beyond the power spectrum. It is\nparticularly sensitive to nonlinear growth on small scales, where massive\nneutrinos also have the largest effect. We find that tomography helps improve\nthe constraint on M_nu by 14% and 32% for the power spectrum and the PDF,\nrespectively, compared to a single redshift bin. The PDF alone outperforms the\npower spectrum in constraining M_nu. When the two statistics are combined, the\nconstraint is further tightened by 35%. We conclude that weak lensing PDF is\ncomplementary to the power spectrum and has the potential to become a powerful\ntool for constraining neutrino mass. \n\n"}
{"id": "1809.10781", "contents": "Title: Methods and Concepts in Economic Complexity Abstract: Knowhow in societies accumulates as it gets transmitted from group to group,\nand from generation to generation. However, we lack of a unified quantitative\nformalism that takes into account the structured process for how this\naccumulation occurs, and this has precluded the development of a unified view\nof human development in the past and in the present. Here, we summarize a\nparadigm to understand and model this process. The paradigm goes under the\ngeneral name of the Theory of Economic Complexity (TEC). Based on it, we\npresent a combination of analytical, numerical and empirical results that\nillustrate how to characterize the process of development, providing measurable\nquantities that can be used to predict future developments. The emphasis is the\nquantification of the collective knowhow an economy has accumulated, and what\nare the directions in which it is likely to expand. As a case study we consider\ndata on trade, which provides consistent data on the technological\ndiversification of 200 countries across more than 50 years. The paradigm\nrepresented by TEC should be relevant for anthropologists, sociologists, and\neconomists interested in the role of collective knowhow as the main determinant\nof the success and welfare of a society. \n\n"}
{"id": "1810.00735", "contents": "Title: Smeared phase transitions in percolation on real complex networks Abstract: Percolation on complex networks is used both as a model for dynamics on\nnetworks, such as network robustness or epidemic spreading, and as a benchmark\nfor our models of networks, where our ability to predict percolation measures\nour ability to describe the networks themselves. In many applications,\ncorrectly identifying the phase transition of percolation on real-world\nnetworks is of critical importance. Unfortunately, this phase transition is\nobfuscated by the finite size of real systems, making it hard to distinguish\nfinite size effects from the inaccuracy of a given approach that fails to\ncapture important structural features. Here, we borrow the perspective of\nsmeared phase transitions and argue that many observed discrepancies are due to\nthe complex structure of real networks rather than to finite size effects only.\nIn fact, several real networks often used as benchmarks feature a smeared phase\ntransition where inhomogeneities in the topological distribution of the order\nparameter do not vanish in the thermodynamic limit. We find that these smeared\ntransitions are sometimes better described as sequential phase transitions\nwithin correlated subsystems. Our results shed light not only on the nature of\nthe percolation transition in complex systems, but also provide two important\ninsights on the numerical and analytical tools we use to study them. First, we\npropose a measure of local susceptibility to better detect both clean and\nsmeared phase transitions by looking at the topological variability of the\norder parameter. Second, we highlight a shortcoming in state-of-the-art\nanalytical approaches such as message passing, which can detect smeared\ntransitions but not characterize their nature. \n\n"}
{"id": "1810.01841", "contents": "Title: Galerkin Approximation of Dynamical Quantities using Trajectory Data Abstract: Understanding chemical mechanisms requires estimating dynamical statistics\nsuch as expected hitting times, reaction rates, and committors. Here, we\npresent a general framework for calculating these dynamical quantities by\napproximating boundary value problems using dynamical operators with a Galerkin\nexpansion. A specific choice of basis set in the expansion corresponds to\nestimation of dynamical quantities using a Markov state model. More generally,\nthe boundary conditions impose restrictions on the choice of basis sets. We\ndemonstrate how an alternative basis can be constructed using ideas from\ndiffusion maps. In our numerical experiments, this basis gives results of\ncomparable or better accuracy to Markov state models. Additionally, we show\nthat delay embedding can reduce the information lost when projecting the\nsystem's dynamics for model construction; this improves estimates of dynamical\nstatistics considerably over the standard practice of increasing the lag time. \n\n"}
{"id": "1810.08988", "contents": "Title: Predicting the outcomes of policy diffusion from U.S. states to federal\n  law Abstract: In the United States, national policies often begin as state laws, which then\nspread from state to state until they gain momentum to become enacted as a\nnational policy. However, not every state policy reaches the national level.\nPrevious work has suggested that state-level policies are more likely to become\nnational policies depending on their geographic origin, their category of\nlegislation, or some characteristic of their initiating states, such as wealth,\nurbanicity, or ideological liberalism. Here, we tested these hypotheses by\ndivorcing the set of traits from the states' identities and building predictive\nforecasting models of state policies becoming national policies. Using a large,\nlongitudinal data set of state level policies and their traits, we train models\nto predict (i) whether policies become national policy, and (ii) how many\nstates must pass a given policy before it becomes national. Using these models\nas components, we then develop a logistic growth model to forecast when a\ncurrently spreading state-level policy is likely to pass at the national level.\nOur results indicate that traits of initiating states are not systematically\ncorrelated with becoming national policy and they predict neither how many\nstates must enact a policy before it becomes national nor whether it ultimately\nbecomes a national law. In contrast, the cumulative number of state-level\nadoptions of a policy is reasonably predictive of when a policy becomes\nnational. For the policies of same sex marriage and methamphetamine precursor\nlaws, we investigate how well the logistic growth model could forecast the\nprobable time horizon for true national action. We close with a data-driven\nforecast of when marijuana legalization and \"stand your ground\" laws will\nbecome national policy. \n\n"}
{"id": "1810.09505", "contents": "Title: What Does a Successful Postdoctoral Fellowship Publication Record Look\n  Like? Abstract: Obtaining a prize postdoctoral fellowship in astronomy and astrophysics\ninvolves a number of factors, many of which cannot be quantified. One criterion\nthat can be measured is the publication record of an applicant. The publication\nrecords of past fellowship recipients may, therefore, provide some quantitative\nguidance for future prospective applicants. We investigated the publication\npatterns of recipients of the NASA prize postdoctoral fellowships in the\nHubble, Einstein, and Sagan programs from 2014 through 2017, using the NASA ADS\nreference system. We tabulated their publications at the point where fellowship\napplications were submitted, and we find that the 133 fellowship recipients in\nthat time frame had a median of 6 +/- 2 first-author publications, and 14 +/- 6\nco-authored publications. The full range of first author papers is 1 to 15, and\nfor all papers ranges from 2 to 76, indicating very diverse publication\npatterns. Thus, while fellowship recipients generally have strong publication\nrecords, the distribution of both first-author and co-authored papers is quite\nbroad; there is no apparent threshold of publications necessary to obtain these\nfellowships. We also examined the post-PhD publication rates for each of the\nthree fellowship programs, between male and female recipients, across the four\nyears of the analysis and find no consistent trends. We hope that these\nfindings will prove a useful reference to future junior scientists. \n\n"}
{"id": "1810.10034", "contents": "Title: Uncovering Complex Overlapping Pattern of Communities in Large-scale\n  Social Networks Abstract: The conventional notion of community that favors a high ratio of internal\nedges to outbound edges becomes invalid when each vertex participates in\nmultiple communities. Such a behavior is commonplace in social networks. The\nsignificant overlaps among communities make most existing community detection\nalgorithms ineffective. The lack of effective and efficient tools resulted in\nvery few empirical studies on large-scale detection and analyses of overlapping\ncommunity structure in real social networks. We developed recently a scalable\nand accurate method called the Partial Community Merger Algorithm (PCMA) with\nlinear complexity and demonstrated its effectiveness by analyzing two online\nsocial networks, Sina Weibo and Friendster, with 79.4 and 65.6 million\nvertices, respectively. Here, we report in-depth analyses of the 2.9 million\ncommunities detected by PCMA to uncover their complex overlapping structure.\nEach community usually overlaps with a significant number of other communities\nand has far more outbound edges than internal edges. Yet, the communities\nremain well separated from each other. Most vertices in a community are\nmulti-membership vertices, and they can be at the core or the peripheral.\nAlmost half of the entire network can be accounted for by an extremely dense\nnetwork of communities, with the communities being the vertices and the\noverlaps being the edges. The empirical findings ask for rethinking the notion\nof community, especially the boundary of a community. Realizing that it is how\nthe edges are organized that matters, the f-core is suggested as a suitable\nconcept for overlapping community in social networks. The results shed new\nlight on the understanding of overlapping community. \n\n"}
{"id": "1810.12879", "contents": "Title: Regressive and generative neural networks for scalar field theory Abstract: We explore the perspectives of machine learning techniques in the context of\nquantum field theories. In particular, we discuss two-dimensional complex\nscalar field theory at nonzero temperature and chemical potential -- a theory\nwith a nontrivial phase diagram. A neural network is successfully trained to\nrecognize the different phases of this system and to predict the value of\nvarious observables, based on the field configurations. We analyze a broad\nrange of chemical potentials and find that the network is robust and able to\nrecognize patterns far away from the point where it was trained. Aside from the\nregressive analysis, which belongs to supervised learning, an unsupervised\ngenerative network is proposed to produce new quantum field configurations that\nfollow a specific distribution. An implicit local constraint fulfilled by the\nphysical configurations was found to be automatically captured by our\ngenerative model. We elaborate on potential uses of such a generative approach\nfor sampling outside the training region. \n\n"}
{"id": "1811.01452", "contents": "Title: Assembly in populations of social networks Abstract: In-depth studies of sociotechnical systems are largely limited to single\ninstances. Network surveys are expensive, and platforms vary in important ways,\nfrom interface design, to social norms, to historical contingencies. With\nsingle examples, we can not in general know how much of observed network\nstructure is explained by historical accidents, random noise, or meaningful\nsocial processes, nor can we claim that network structure predicts outcomes,\nsuch as organization success or ecosystem health. Here, I show how we can adopt\na comparative approach for settings where we have, or can cleverly construct,\nmultiple instances of a network to estimate the natural variability in social\nsystems. The comparative approach makes previously untested theories testable.\nDrawing on examples from the social networks literature, I discuss emerging\ndirections in the study of populations of sociotechnical systems using insights\nfrom organization theory and ecology. \n\n"}
{"id": "1811.02071", "contents": "Title: Scale-free Networks Well Done Abstract: We bring rigor to the vibrant activity of detecting power laws in empirical\ndegree distributions in real-world networks. We first provide a rigorous\ndefinition of power-law distributions, equivalent to the definition of\nregularly varying distributions that are widely used in statistics and other\nfields. This definition allows the distribution to deviate from a pure power\nlaw arbitrarily but without affecting the power-law tail exponent. We then\nidentify three estimators of these exponents that are proven to be\nstatistically consistent -- that is, converging to the true value of the\nexponent for any regularly varying distribution -- and that satisfy some\nadditional niceness requirements. In contrast to estimators that are currently\npopular in network science, the estimators considered here are based on\nfundamental results in extreme value theory, and so are the proofs of their\nconsistency. Finally, we apply these estimators to a representative collection\nof synthetic and real-world data. According to their estimates, real-world\nscale-free networks are definitely not as rare as one would conclude based on\nthe popular but unrealistic assumption that real-world data comes from power\nlaws of pristine purity, void of noise and deviations. \n\n"}
{"id": "1811.04295", "contents": "Title: Using NonBacktracking Expansion to Analyze k-core Pruning Process Abstract: We induce the NonBacktracking Expansion Branch method to analyze the k-core\npruning process on the monopartite graph G which does not contain any self-loop\nor multi-edge. Different from the traditional approaches like the generating\nfunctions or the degree distribution evolution equations which are\nmathematically difficult to solve, this method provides a simple and intuitive\nsolution of the k-core pruning process. Besides, this method can be naturally\nextended to study the k-core pruning process on correlated networks, which is\namong the few attempts to analytically solve the problem. \n\n"}
{"id": "1811.05063", "contents": "Title: SMERC: Social media event response clustering using textual and temporal\n  information Abstract: Tweet clustering for event detection is a powerful modern method to automate\nthe real-time detection of events. In this work we present a new tweet\nclustering approach, using a probabilistic approach to incorporate temporal\ninformation. By analysing the distribution of time gaps between tweets we show\nthat the gaps between pairs of related tweets exhibit exponential decay,\nwhereas the gaps between unrelated tweets are approximately uniform. Guided by\nthis insight, we use probabilistic arguments to estimate the likelihood that a\npair of tweets are related, and build an improved clustering method. Our method\nSocial Media Event Response Clustering (SMERC) creates clusters of tweets based\non their tendency to be related to a single event. We evaluate our method at\nthree levels: through traditional event prediction from tweet clustering, by\nmeasuring the improvement in quality of clusters created, and also comparing\nthe clustering precision and recall with other methods. By applying SMERC to\ntweets collected during a number of sporting events, we demonstrate that\nincorporating temporal information leads to state of the art clustering\nperformance. \n\n"}
{"id": "1811.06321", "contents": "Title: Multivariate Spatiotemporal Hawkes Processes and Network Reconstruction Abstract: There is often latent network structure in spatial and temporal data and the\ntools of network analysis can yield fascinating insights into such data. In\nthis paper, we develop a nonparametric method for network reconstruction from\nspatiotemporal data sets using multivariate Hawkes processes. In contrast to\nprior work on network reconstruction with point-process models, which has often\nfocused on exclusively temporal information, our approach uses both temporal\nand spatial information and does not assume a specific parametric form of\nnetwork dynamics. This leads to an effective way of recovering an underlying\nnetwork. We illustrate our approach using both synthetic networks and networks\nconstructed from real-world data sets (a location-based social media network, a\nnarrative of crime events, and violent gang crimes). Our results demonstrate\nthat, in comparison to using only temporal data, our spatiotemporal approach\nyields improved network reconstruction, providing a basis for meaningful\nsubsequent analysis --- such as community structure and motif analysis --- of\nthe reconstructed networks. \n\n"}
{"id": "1811.07050", "contents": "Title: Gaussian Process Accelerated Feldman-Cousins Approach for Physical\n  Parameter Inference Abstract: The unified approach of Feldman and Cousins allows for exact statistical\ninference of small signals that commonly arise in high energy physics. It has\ngained widespread use, for instance, in measurements of neutrino oscillation\nparameters in long-baseline experiments. However, the approach relies on the\nNeyman construction of the classical confidence interval and is computationally\nintensive as it is typically done in a grid-based fashion over the entire\nparameter space. In this letter, we propose an efficient algorithm for the\nFeldman-Cousins approach using Gaussian processes to construct confidence\nintervals iteratively. We show that in the neutrino oscillation context, one\ncan obtain confidence intervals 5 times faster in one dimension and 10 times\nfaster in two dimensions, while maintaining an accuracy above 99.5%. \n\n"}
{"id": "1811.12284", "contents": "Title: Reactive explorers to unravel network topology Abstract: A procedure is developed and tested to recover the distribution of\nconnectivity of an a priori unknown network, by sampling the dynamics of an\nensemble made of reactive walkers. The relative weight between reaction and\nrelocation is gauged by a scalar control parameter, which can be adjusted at\nwill. Different equilibria are attained by the system, following the externally\nimposed modulation, and reflecting the interplay between reaction and diffusion\nterms. The information gathered on the observation node is used to predict the\nstationary density as displayed by the system, via a direct implementation of\nthe celebrated Heterogeneous Mean Field (HMF) approximation. This knowledge\ntranslates into a linear problem which can be solved to return the entries of\nthe sought distribution. A variant of the model is then considered which\nconsists in assuming a localized source where the reactive constituents are\ninjected, at a rate that can be adjusted as a stepwise function of time. The\nlinear problem obtained when operating in this setting allows one to recover a\nfair estimate of the underlying system size. Numerical experiments are carried\nso as to challenge the predictive ability of the theory. \n\n"}
{"id": "1812.00799", "contents": "Title: On sampling of scattering phase functions Abstract: Monte Carlo radiative transfer, which has been demonstrated as a successful\nalgorithm for modeling radiation transport through the astrophysical medium,\nrelies on sampling of scattering phase functions. We review several classic\nsampling algorithms such as the tabulated method and the accept-reject method\nfor sampling the scattering phase function. The tabulated method uses a\npiecewise constant approximation for the true scattering phase function; we\nimprove its sampling performance on a small scattering angle by using piecewise\nlinear and piecewise log-linear approximations. It has previously been believed\nthat certain complicated analytic phase functions such as the Fournier-Forand\nphase function cannot be simulated without approximations. We show that the\ntabulated method combined with the accept-reject method can be applied to\nsample such complicated scattering phase functions accurately. Furthermore, we\nintroduce the Gibbs sampling method for sampling complicated approximate\nanalytic phase functions. In addition, we propose a new modified\nHenyey-Greenstein phase function with exponential decay terms for modeling\nrealistic dust scattering. Based on Monte Carlo simulations of radiative\ntransfer through a plane-parallel medium, we also demonstrate that the result\nsimulated with the new phase function can provide a good fit to the result\nsimulated with the realistic dust phase function. \n\n"}
{"id": "1812.03814", "contents": "Title: Adaptive Diffusion Processes of Time-Varying Local Information on\n  Networks Abstract: This paper mainly discusses the diffusion on complex networks with\ntime-varying couplings. We propose a model to describe the adaptive diffusion\nprocess of local topological and dynamical information, and find that the\nBarabasi-Albert scale-free network (BA network) is beneficial to the diffusion\nand leads nodes to arrive at a larger state value than other networks do. The\nability of diffusion for a node is related to its own degree. Specifically,\nnodes with smaller degrees are more likely to change their states and reach\nlarger values, while those with larger degrees tend to stick to their original\nstates. We introduce state entropy to analyze the thermodynamic mechanism of\nthe diffusion process, and interestingly find that this kind of diffusion\nprocess is a minimization process of state entropy. We use the inequality\nconstrained optimization method to reveal the restriction function of the\nminimization and find that it has the same form as the Gibbs free energy. The\nthermodynamical concept allows us to understand dynamical processes on complex\nnetworks from a brand-new perspective. The result provides a convenient means\nof optimizing relevant dynamical processes on practical circuits as well as\nrelated complex systems. \n\n"}
{"id": "1812.07029", "contents": "Title: The statistical mechanics of Twitter Abstract: We build models for the distribution of social states in Twitter communities.\nStates can be defined by the participation vs silence of individuals in\nconversations that surround key words, and we approximate the joint\ndistribution of these binary variables using the maximum entropy principle,\nfinding the least structured models that match the mean probability of\nindividuals tweeting and their pairwise correlations. These models provide very\naccurate, quantitative descriptions of higher order structure in these social\nnetworks. The parameters of these models seem poised close to critical surfaces\nin the space of possible models, and we observe scaling behavior of the data\nunder coarse-graining. These results suggest that simple models, grounded in\nstatistical physics, may provide a useful point of view on the larger data sets\nnow emerging from complex social systems. \n\n"}
{"id": "1812.11615", "contents": "Title: Metaplex networks: influence of the exo-endo structure of complex\n  systems on diffusion Abstract: In a complex system the interplay between the internal structure of its\nentities and their interconnection may play a fundamental role in the global\nfunctioning of the system. Here, we define the concept of metaplex, which\ndescribes such trade-off between internal structure of entities and their\ninterconnections. We then define a dynamical system on a metaplex and study\ndiffusive processes on them. We provide analytical and computational evidences\nabout the role played by the size of the nodes, the location of the internal\ncoupling areas, and the strength and range of the coupling between the nodes on\nthe global dynamics of metaplexes. Finally, we extend our analysis to two\nreal-world metaplexes: a landscape and a brain metaplex. We corroborate that\nthe internal structure of the nodes in a metaplex may dominate the global\ndynamics (brain metaplex) or play a regulatory role (landscape metaplex) to the\ninfluence of the interconnection between nodes. \n\n"}
{"id": "1901.00924", "contents": "Title: Improving solutions by embedding larger subproblems in a D-Wave quantum\n  annealer Abstract: Quantum annealing is a heuristic algorithm that solves combinatorial\noptimization problems, and D-Wave Systems Inc. has developed hardware\nimplementation of this algorithm. However, in general, we cannot embed all the\nlogical variables of a large-scale problem, since the number of available\nqubits is limited. In order to handle a large problem, qbsolv has been proposed\nas a method for partitioning the original large problem into subproblems that\nare embeddable in the D-Wave quantum annealer, and it then iteratively\noptimizes the subproblems using the quantum annealer. Multiple logical\nvariables in the subproblem are simultaneously updated in this iterative\nsolver, and using this approach we expect to obtain better solutions than can\nbe obtained by conventional local search algorithms. Although embedding of\nlarge subproblems is essential for improving the accuracy of solutions in this\nscheme, the size of the subproblems are small in qbsolv since the subproblems\nare basically embedded by using an embedding of a complete graph even for\nsparse problem graphs. This means that the resource of the D-Wave quantum\nannealer is not exploited efficiently. In this paper, we propose a fast\nalgorithm for embedding larger subproblems, and we show that better solutions\nare obtained efficiently by embedding larger subproblems. \n\n"}
{"id": "1901.02381", "contents": "Title: Generalization of the small-world effect on a model approaching the\n  Erd\\H{o}s-R\\'enyi random graph Abstract: The famous Watts-Strogatz (WS) small-world network model does not approach\nthe Erd\\H{o}s-R\\'enyi (ER) random graph model in the limit of total\nrandomization which can lead to confusion and complicates certain analyses. In\nthis paper we discuss a simple alternative which was first introduced by Song\nand Wang, where instead of rewiring, edges are drawn between pairs of nodes\nwith a distance-based connection probability. We show that this model is\nsimpler to analyze, approaches the true ER random graph model in the completely\nrandomized limit, and demonstrate that the WS model and the alternative model\nmay yield different quantitative results using the example of a random walk\ntemporal observable. An efficient sampling algorithm for the alternative model\nis proposed. Analytic results regarding the degree distribution, degree\nvariance, number of two-stars per node, number of triangles per node,\nclustering coefficient, and random walk mixing time are presented.\nSubsequently, the small-world effect is illustrated by showing that the\nclustering coefficient decreases much slower than an upper bound on the message\ndelivery time with increasing long-range connection probability which\ngeneralizes the small-world effect from informed searches to random search\nstrategies. Due to its accessibility for analytic evaluations, we propose that\nthis modified model should be used as an alternative reference model for\nstudying the influence of small-world topologies on dynamic systems as well as\na simple model to introduce numerous topics when teaching network science. \n\n"}
{"id": "1901.03607", "contents": "Title: Exploring the Role of Interdisciplinarity in Physics: Success, Talent\n  and Luck Abstract: Although interdisciplinarity is often touted as a necessity for modern\nresearch, the evidence on the relative impact of sectorial versus to\ninterdisciplinary science is qualitative at best. In this paper we leverage the\nbibliographic data set of the American Physical Society to quantify the role of\ninterdisciplinarity in physics, and that of talent and luck in achieving\nsuccess in scientific careers. We analyze a period of 30 years (1980-2009)\ntagging papers and their authors by means of the Physics and Astronomy\nClassification Scheme (PACS), to show that some degree of interdisciplinarity\nis quite helpful to reach success, measured as a proxy of either the number of\narticles or the citations score. We also propose an agent-based model of the\npublication-reputation-citation dynamics reproduces the trends observed in the\nAPS data set. On the one hand, the results highlight the crucial role of\nrandomness and serendipity in real scientific research; on the other, they shed\nlight on a counter-intuitive effect indicating that the most talented authors\nare not necessarily the most successful ones. \n\n"}
{"id": "1901.06936", "contents": "Title: Local and Global Perspectives on Diffusion Maps in the Analysis of\n  Molecular Systems Abstract: Diffusion maps approximate the generator of Langevin dynamics from simulation\ndata. They afford a means of identifying the slowly-evolving principal modes of\nhigh-dimensional molecular systems. When combined with a biasing mechanism,\ndiffusion maps can accelerate the sampling of the stationary Boltzmann-Gibbs\ndistribution. In this work, we contrast the local and global perspectives on\ndiffusion maps, based on whether or not the data distribution has been fully\nexplored. In the global setting, we use diffusion maps to identify metastable\nsets and to approximate the corresponding committor functions of transitions\nbetween them. We also discuss the use of diffusion maps within the metastable\nsets, formalising the locality via the concept of the quasi-stationary\ndistribution and justifying the convergence of diffusion maps within a local\nequilibrium. This perspective allows us to propose an enhanced sampling\nalgorithm. We demonstrate the practical relevance of these approaches both for\nsimple models and for molecular dynamics problems (alanine dipeptide and\ndeca-alanine). \n\n"}
{"id": "1901.07901", "contents": "Title: Network centrality: an introduction Abstract: Centrality is a key property of complex networks that influences the behavior\nof dynamical processes, like synchronization and epidemic spreading, and can\nbring important information about the organization of complex systems, like our\nbrain and society. There are many metrics to quantify the node centrality in\nnetworks. Here, we review the main centrality measures and discuss their main\nfeatures and limitations. The influence of network centrality on epidemic\nspreading and synchronization is also pointed out in this chapter. Moreover, we\npresent the application of centrality measures to understand the function of\ncomplex systems, including biological and cortical networks. Finally, we\ndiscuss some perspectives and challenges to generalize centrality measures for\nmultilayer and temporal networks. \n\n"}
{"id": "1901.08696", "contents": "Title: A Generative Model for Exploring Structure Regularities in Attributed\n  Networks Abstract: Many real-world networks known as attributed networks contain two types of\ninformation: topology information and node attributes. It is a challenging task\non how to use these two types of information to explore structural\nregularities. In this paper, by characterizing potential relationship between\nlink communities and node attributes, a principled statistical model named\nPSB_PG that generates link topology and node attributes is proposed. This model\nfor generating links is based on the stochastic blockmodels following a Poisson\ndistribution. Therefore, it is capable of detecting a wide range of network\nstructures including community structures, bipartite structures and other\nmixture structures. The model for generating node attributes assumes that node\nattributes are high dimensional and sparse and also follow a Poisson\ndistribution. This makes the model be uniform and the model parameters can be\ndirectly estimated by expectation-maximization (EM) algorithm. Experimental\nresults on artificial networks and real networks containing various structures\nhave shown that the proposed model PSB_PG is not only competitive with the\nstate-of-the-art models, but also provides good semantic interpretation for\neach community via the learned relationship between the community and its\nrelated attributes. \n\n"}
{"id": "1901.08831", "contents": "Title: Flocking and spreading dynamics in populations of self-propelled agents Abstract: Populations of self-propelled mobile agents - animal groups, robot swarms or\ncrowds of people - that exchange information with their surrounding, host\nfascinating cooperative behaviors. While in many situations of interest the\nagents motion is driven by the transmission of information (e.g. the presence\nof an approaching predator) from neighboring peers, previous modeling efforts\nhave focused on situations where agents either sit on static networks, or move\nindependently of the information spreading across the population. Here, we\nintroduce a reference model to tackle this current lack of general framework.\nWe consider mobile agents which align their direction of motion (based on the\nKuramoto dynamics) and carry an internal state governed by the\nSusceptible-Infected-Susceptible (SIS) epidemic process, characterizing the\nspread of information in the population, and affecting the way agents move in\nspace. We show that the feedback between the agents motion and information\nspreading is responsible for (i) the enhancement of both flocking and\ninformation spreading, (ii) the emergence of complex spatial structures, or\nswarms, which can be controlled by the velocity of the agents. The SIS dynamics\nis able to drive a flocking phase transition even in the absence of explicit\nvelocity-alignment, recovering a behavior reminiscent of Vicsek-like systems\nbut featuring macro-phase separation rather than micro-phase separation. We\nshow that the formation of dense swarms at low velocities reduces the epidemic\nthreshold of information spreading with respect to the mean field limit. By\nbridging together soft active matter physics and agent based modeling of\ncomplex systems, we shed light upon a general positive feedback mechanism that\ncrucially affects the collective behavior of mobile agents, providing a\nreference framework to study realistic situations where this mechanism is at\nplay. \n\n"}
{"id": "astro-ph/0206431", "contents": "Title: Search for correlation between GRB's detected by BeppoSAX and\n  gravitational wave detectors EXPLORER and NAUTILUS Abstract: Data obtained during five months of 2001 with the gravitational wave (GW)\ndetectors EXPLORER and NAUTILUS were studied in correlation with the gamma ray\nburst data (GRB) obtained with the BeppoSAX satellite. During this period\nBeppoSAX was the only GRB satellite in operation, while EXPLORER and NAUTILUS\nwere the only GW detectors in operation.\n  No correlation between the GW data and the GRB bursts was found. The\nanalysis, performed over 47 GRB's, excludes the presence of signals of\namplitude h >=1.2 * 10^{-18}, with 95 % probability, if we allow a time delay\nbetween GW bursts and GRB within +-400 s, and h >= 6.5 * 10^{-19}, if the time\ndelay is within +- 5 s. The result is also provided in form of scaled\nlikelihood for unbiased interpretation and easier use for further analysis. \n\n"}
{"id": "astro-ph/9804321", "contents": "Title: AGAPEROS: Searches for microlensing in the LMC with the Pixel Method II.\n  Selection of possible microlensing events Abstract: We apply the pixel method of analysis (sometimes called ``pixel lensing'') to\na small subset of the EROS-1 microlensing observations of the bar of the Large\nMagellanic Cloud (LMC). The pixel method is designed to find microlensing\nevents of unresolved source stars and had heretofore been applied only to M31\nwhere essentially all sources are unresolved. With our analysis optimised for\nthe detection of long-duration microlensing events due to 0.01-1 Mo Machos, we\ndetect no microlensing events and compute the corresponding detection\nefficiencies. We show that the pixel method, applied to crowded fields, should\ndetect 10 to 20 times more microlensing events for M>0.05 Mo Machos compared to\na classical analysis of the same data which latter monitors only resolved\nstars. In particular, we show that for a full halo of Machos in the mass range\n0.1-0.5 Mo, a pixel analysis of the three-year EROS-1 data set covering\n0.39deg^2 would yield ~4 events. \n\n"}
{"id": "cond-mat/0002331", "contents": "Title: From naive to sophisticated behavior in multiagents based financial\n  market models Abstract: We discuss the behavior of two magnitudes, physical complexity and mutual\ninformation function of the outcome of a model of heterogeneous, inductive\nrational agents inspired in the El Farol Bar problem and the Minority Game. The\nfirst is a measure rooted in Kolmogorov-Chaitin theory and the second one a\nmeasure related with information entropy of Shannon.\n  We make extensive computer simulations, as result of which, we propose an\nansatz for physical complexity and establish the dependence of exponent of that\nansatz from the parameters of the model. We discuss the accuracy of our results\nand the relationship with the behavior of mutual information function as a\nmeasure of time correlations of agents choice. \n\n"}
{"id": "cond-mat/0107212", "contents": "Title: Intentional Walks on Scale Free Small Worlds Abstract: We present a novel algorithm that generates scale free small world graphs\nsuch as those found in the World Wide Web,social and metabolic networks. We use\nthe generated graphs to study the dynamics of a realistic search strategy on\nthe graphs, and find that they can be navigated in a very short number of\nsteps. \n\n"}
{"id": "cond-mat/0302095", "contents": "Title: Multiple time scales in volatility and leverage correlations: An\n  stochastic volatility model Abstract: Financial time series exhibit two different type of non linear correlations:\n(i) volatility autocorrelations that have a very long range memory, on the\norder of years, and (ii) asymmetric return-volatility (or `leverage')\ncorrelations that are much shorter ranged. Different stochastic volatility\nmodels have been proposed in the past to account for both these correlations.\nHowever, in these models, the decay of the correlations is exponential, with a\nsingle time scale for both the volatility and the leverage correlations, at\nvariance with observations. We extend the linear Ornstein-Uhlenbeck stochastic\nvolatility model by assuming that the mean reverting level is itself random. We\nfind that the resulting three-dimensional diffusion process can account for\ndifferent correlation time scales. We show that the results are in good\nagreement with a century of the Dow Jones index daily returns (1900-2000), with\nthe exception of crash days. \n\n"}
{"id": "cond-mat/0402389", "contents": "Title: An analysis of Cross-correlations in South African Market data Abstract: We apply random matrix theory to compare correlation matrix estimators C\nobtained from emerging market data. The correlation matrices are constructed\nfrom 10 years of daily data for stocks listed on the Johannesburg Stock\nExchange (JSE) from January 1993 to December 2002. We test the spectral\nproperties of C against random matrix predictions and find some agreement\nbetween the distributions of eigenvalues, nearest neighbour spacings,\ndistributions of eigenvector components and the inverse participation ratios\nfor eigenvectors. We show that interpolating both missing data and illiquid\ntrading days with a zero-order hold increases agreement with RMT predictions.\nFor the more realistic estimation of correlations in an emerging market, we\nsuggest a pairwise measured-data correlation matrix. For the data set used,\nthis approach suggests greater temporal stability for the leading eigenvectors.\nAn interpretation of eigenvectors in terms of trading strategies is given in\nlieu of classification by economic sectors. \n\n"}
{"id": "cond-mat/0404521", "contents": "Title: Patterns of link reciprocity in directed networks Abstract: We address the problem of link reciprocity, the non-random presence of two\nmutual links between pairs of vertices. We propose a new measure of reciprocity\nthat allows the ordering of networks according to their actual degree of\ncorrelation between mutual links. We find that real networks are always either\ncorrelated or anticorrelated, and that networks of the same type (economic,\nsocial, cellular, financial, ecological, etc.) display similar values of the\nreciprocity. The observed patterns are not reproduced by current models. This\nleads us to introduce a more general framework where mutual links occur with a\nconditional connection probability. In some of the studied networks we discuss\nthe form of the conditional connection probability and the size dependence of\nthe reciprocity. \n\n"}
{"id": "cond-mat/0405688", "contents": "Title: Minimum spanning trees on weighted scale-free networks Abstract: A complete understanding of real networks requires us to understand the\nconsequences of the uneven interaction strengths between a system's components.\nHere we use the minimum spanning tree (MST) to explore the effect of weight\nassignment and network topology on the organization of complex networks. We\nfind that if the weight distribution is correlated with the network topology,\nthe MSTs are either scale-free or exponential. In contrast, when the\ncorrelations between weights and topology are absent, the MST degree\ndistribution is a power-law and independent of the weight distribution. These\nresults offer a systematic way to explore the impact of weak links on the\nstructure and integrity of complex networks. \n\n"}
{"id": "cond-mat/0409773", "contents": "Title: Analysis of the Airport Network of India as a complex weighted network Abstract: Transportation infrastructure of a country is one of the most important\nindicators of its economic growth. Here we study the Airport Network of India\n(ANI), which represents India's domestic civil aviation infrastructure, as a\ncomplex network. We find that ANI, a network of domestic airports connected by\nair links, is a small-world network characterized by a truncated power-law\ndegree distribution, and has a signature of hierarchy. We investigate ANI as a\nweighted network to explore its various properties and compare them with their\ntopological counterparts. The traffic in ANI, as in the World-wide Airport\nNetwork (WAN), is found to be accumulated on interconnected groups of airports\nand is concentrated between large airports. In contrast to WAN, ANI is found to\nbe having disassortative mixing which is offset by the traffic dynamics. The\nanalysis indicates toward possible mechanism of formation of a national\ntransportation network, which is different from that on a global scale. \n\n"}
{"id": "cond-mat/0501299", "contents": "Title: What entropy at the edge of chaos? Abstract: Numerical experiments support the interesting conjecture that statistical\nmethods be applicable not only to fully-chaotic systems, but also at the edge\nof chaos by using Tsallis' generalizations of the standard exponential and\nentropy. In particular, the entropy increases linearly and the sensitivity to\ninitial conditions grows as a generalized exponential. We show that this\nconjecture has actually a broader validity by using a large class of deformed\nentropies and exponentials and the logistic map as test cases. \n\n"}
{"id": "cond-mat/0501361", "contents": "Title: Fractal Power Law in Literary English Abstract: We present in this paper a numerical investigation of literary texts by\nvarious well-known English writers, covering the first half of the twentieth\ncentury, based upon the results obtained through corpus analysis of the texts.\nA fractal power law is obtained for the lexical wealth defined as the ratio\nbetween the number of different words and the total number of words of a given\ntext. By considering as a signature of each author the exponent and the\namplitude of the power law, and the standard deviation of the lexical wealth,\nit is possible to discriminate works of different genres and writers and show\nthat each writer has a very distinct signature, either considered among other\nliterary writers or compared with writers of non-literary texts. It is also\nshown that, for a given author, the signature is able to discriminate between\nshort stories and novels. \n\n"}
{"id": "cond-mat/0503413", "contents": "Title: Will jams get worse when slow cars move over? Abstract: Motivated by an analogy with traffic, we simulate two species of particles\n(`vehicles'), moving stochastically in opposite directions on a two-lane ring\nroad. Each species prefers one lane over the other, controlled by a parameter\n$0 \\leq b \\leq 1$ such that $b=0$ corresponds to random lane choice and $b=1$\nto perfect `laning'. We find that the system displays one large cluster (`jam')\nwhose size increases with $b$, contrary to intuition. Even more remarkably, the\nlane `charge' (a measure for the number of particles in their preferred lane)\nexhibits a region of negative response: even though vehicles experience a\nstronger preference for the `right' lane, more of them find themselves in the\n`wrong' one! For $b$ very close to 1, a sharp transition restores a homogeneous\nstate. Various characteristics of the system are computed analytically, in good\nagreement with simulation data. \n\n"}
{"id": "cond-mat/0504025", "contents": "Title: Point process model of 1/f noise versus a sum of Lorentzians Abstract: We present a simple point process model of $1/f^{\\beta}$ noise, covering\ndifferent values of the exponent $\\beta$. The signal of the model consists of\npulses or events. The interpulse, interevent, interarrival, recurrence or\nwaiting times of the signal are described by the general Langevin equation with\nthe multiplicative noise and stochastically diffuse in some interval resulting\nin the power-law distribution. Our model is free from the requirement of a wide\ndistribution of relaxation times and from the power-law forms of the pulses. It\ncontains only one relaxation rate and yields $1/f^ {\\beta}$ spectra in a wide\nrange of frequency. We obtain explicit expressions for the power spectra and\npresent numerical illustrations of the model. Further we analyze the relation\nof the point process model of $1/f$ noise with the Bernamont-Surdin-McWhorter\nmodel, representing the signals as a sum of the uncorrelated components. We\nshow that the point process model is complementary to the model based on the\nsum of signals with a wide-range distribution of the relaxation times. In\ncontrast to the Gaussian distribution of the signal intensity of the sum of the\nuncorrelated components, the point process exhibits asymptotically a power-law\ndistribution of the signal intensity. The developed multiplicative point\nprocess model of $1/f^{\\beta}$ noise may be used for modeling and analysis of\nstochastic processes in different systems with the power-law distribution of\nthe intensity of pulsing signals. \n\n"}
{"id": "cond-mat/0601240", "contents": "Title: MEDUSA - New Model of Internet Topology Using k-shell Decomposition Abstract: The k-shell decomposition of a random graph provides a different and more\ninsightful separation of the roles of the different nodes in such a graph than\ndoes the usual analysis in terms of node degrees. We develop this approach in\norder to analyze the Internet's structure at a coarse level, that of the\n\"Autonomous Systems\" or ASes, the subnetworks out of which the Internet is\nassembled. We employ new data from DIMES (see http://www.netdimes.org), a\ndistributed agent-based mapping effort which at present has attracted over 3800\nvolunteers running more than 7300 DIMES clients in over 85 countries. We\ncombine this data with the AS graph information available from the RouteViews\nproject at Univ. Oregon, and have obtained an Internet map with far more detail\nthan any previous effort.\n  The data suggests a new picture of the AS-graph structure, which\ndistinguishes a relatively large, redundantly connected core of nearly 100 ASes\nand two components that flow data in and out from this core. One component is\nfractally interconnected through peer links; the second makes direct\nconnections to the core only. The model which results has superficial\nsimilarities with and important differences from the \"Jellyfish\" structure\nproposed by Tauro et al., so we call it a \"Medusa.\" We plan to use this picture\nas a framework for measuring and extrapolating changes in the Internet's\nphysical structure. Our k-shell analysis may also be relevant for estimating\nthe function of nodes in the \"scale-free\" graphs extracted from other\nnaturally-occurring processes. \n\n"}
{"id": "cond-mat/0602295", "contents": "Title: Effects of substrate network topologies on competition dynamics Abstract: We study a competition dynamics, based on the minority game, endowed with\nvarious substrate network structures. We observe the effects of the network\ntopologies by investigating the volatility of the system and the structure of\nfollower networks. The topology of substrate structures significantly\ninfluences the system efficiency represented by the volatility and such\nsubstrate networks are shown to amplify the herding effect and cause\ninefficiency in most cases. The follower networks emerging from the leadership\nstructure show a power-law incoming degree distribution. This study shows the\nemergence of scale-free structures of leadership in the minority game and the\neffects of the interaction among players on the networked version of the game. \n\n"}
{"id": "cond-mat/0602611", "contents": "Title: k-core (bootstrap) percolation on complex networks: Critical phenomena\n  and nonlocal effects Abstract: We develop the theory of the k-core (bootstrap) percolation on uncorrelated\nrandom networks with arbitrary degree distributions. We show that the k-core\npercolation is an unusual, hybrid phase transition with a jump emergence of the\nk-core as at a first order phase transition but also with a critical\nsingularity as at a continuous transition. We describe the properties of the\nk-core, explain the meaning of the order parameter for the k-core percolation,\nand reveal the origin of the specific critical phenomena. We demonstrate that a\nso-called ``corona'' of the k-core plays a crucial role (corona is a subset of\nvertices in the k-core which have exactly k neighbors in the k-core). It turns\nout that the k-core percolation threshold is at the same time the percolation\nthreshold of finite corona clusters. The mean separation of vertices in corona\nclusters plays the role of the correlation length and diverges at the critical\npoint. We show that a random removal of even one vertex from the k-core may\nresult in the collapse of a vast region of the k-core around the removed\nvertex. The mean size of this region diverges at the critical point. We find an\nexact mapping of the k-core percolation to a model of cooperative relaxation.\nThis model undergoes critical relaxation with a divergent rate at some critical\nmoment. \n\n"}
{"id": "cond-mat/0612214", "contents": "Title: Exact Solution for the Time Evolution of Network Rewiring Models Abstract: We consider the rewiring of a bipartite graph using a mixture of random and\npreferential attachment. The full mean field equations for the degree\ndistribution and its generating function are given. The exact solution of these\nequations for all finite parameter values at any time is found in terms of\nstandard functions. It is demonstrated that these solutions are an excellent\nfit to numerical simulations of the model. We discuss the relationship between\nour model and several others in the literature including examples of Urn,\nBackgammon, and Balls-in-Boxes models, the Watts and Strogatz rewiring problem\nand some models of zero range processes. Our model is also equivalent to those\nused in various applications including cultural transmission, family name and\ngene frequencies, glasses, and wealth distributions. Finally some Voter models\nand an example of a Minority game also show features described by our model. \n\n"}
{"id": "cs/0504089", "contents": "Title: Universal Similarity Abstract: We survey a new area of parameter-free similarity distance measures useful in\ndata-mining, pattern recognition, learning and automatic semantics extraction.\nGiven a family of distances on a set of objects, a distance is universal up to\na certain precision for that family if it minorizes every distance in the\nfamily between every two objects in the set, up to the stated precision (we do\nnot require the universal distance to be an element of the family). We consider\nsimilarity distances for two types of objects: literal objects that as such\ncontain all of their meaning, like genomes or books, and names for objects. The\nlatter may have literal embodyments like the first type, but may also be\nabstract like ``red'' or ``christianity.'' For the first type we consider a\nfamily of computable distance measures corresponding to parameters expressing\nsimilarity according to particular features between pairs of literal objects.\nFor the second type we consider similarity distances generated by web users\ncorresponding to particular semantic relations between the (names for) the\ndesignated objects. For both families we give universal similarity distance\nmeasures, incorporating all particular distance measures in the family. In the\nfirst case the universal distance is based on compression and in the second\ncase it is based on Google page counts related to search terms. In both cases\nexperiments on a massive scale give evidence of the viability of the\napproaches. \n\n"}
{"id": "cs/0512095", "contents": "Title: The Internet AS-Level Topology: Three Data Sources and One Definitive\n  Metric Abstract: We calculate an extensive set of characteristics for Internet AS topologies\nextracted from the three data sources most frequently used by the research\ncommunity: traceroutes, BGP, and WHOIS. We discover that traceroute and BGP\ntopologies are similar to one another but differ substantially from the WHOIS\ntopology. Among the widely considered metrics, we find that the joint degree\ndistribution appears to fundamentally characterize Internet AS topologies as\nwell as narrowly define values for other important metrics. We discuss the\ninterplay between the specifics of the three data collection mechanisms and the\nresulting topology views. In particular, we show how the data collection\npeculiarities explain differences in the resulting joint degree distributions\nof the respective topologies. Finally, we release to the community the input\ntopology datasets, along with the scripts and output of our calculations. This\nsupplement should enable researchers to validate their models against real data\nand to make more informed selection of topology data sources for their specific\nneeds. \n\n"}
{"id": "gr-qc/0009081", "contents": "Title: The doomsday argument and the number of possible observers Abstract: If the human race comes to an end relatively shortly, then we have been born\nat a fairly typical time in history of humanity. On the other hand, if humanity\nlasts for much longer and trillions of people eventually exist, then we have\nbeen born in the first surprisingly tiny fraction of all people. According to\nthe Doomsday Argument of Carter, Leslie, Gott, and Nielsen, this means that the\nchance of a disaster which would obliterate humanity is much larger than\nusually thought. Here I argue that treating possible observers in the same way\nas those who actually exist avoids this conclusion. Under this treatment, it is\nmore likely to exist at all in a race which is long-lived, as originally\ndiscussed by Dieks, and this cancels the Doomsday Argument, so that the chance\nof a disaster is only what one would ordinarily estimate. Treating possible and\nactual observers alike also allows sensible anthropic predictions from quantum\ncosmology, which would otherwise depend on one's interpretation of quantum\nmechanics. \n\n"}
{"id": "hep-ex/0305034", "contents": "Title: Including gaussian uncertainty on the background estimate for upper\n  limit calculations using Poissonian sampling Abstract: A procedure to include the uncertainty on the background estimate for upper\nlimit calculations using Poissonian sampling is presented for the case where a\nGaussian assumption on the uncertainty can be made. Under that hypothesis an\nanalytic expression of the likelihood is derived which can be written in terms\nof polynomials defined by recursion. This expression may lead to a significant\nspeed up of computing applications that extract the upper limits using Toy\nMonte Carlo. \n\n"}
{"id": "hep-ex/0608038", "contents": "Title: Review of Recent and Future Needs in Hadronic Flavor Particle Production\n  Measurements Abstract: Interactions of energetic particles on target nuclei producing secondary\nparticles will be reviewed. Current simulation codes rely upon poorly measured\nresults from the past. While current neutrino experiments, both atmospheric and\naccelerator based, rely upon Kaon and pion production measurements which are\npoorly known and dominate their errors. The goal for the current round of\nexperiments are to dramatically improve these measurements while improvments\nbeyond this are still needed. It is not only of interest to neutrino\nexperiments, but also for designing calorimeters for the the International\nLinear Collider which must achieve unprecedented resolutions for reaching their\nstated physics goals. \n\n"}
{"id": "hep-ph/0207130", "contents": "Title: Signal Significance in the Presence of Systematic and Statistical\n  Uncertainties Abstract: The incorporation of uncertainties to calculations of signal significance in\nplanned experiments is an actual task. Several approaches to this problem are\ndiscussed. We present a procedure for taking into account the systematic\nuncertainty related to nonexact knowledge of signal and background cross\nsections. A method of a treatment of statistical errors of the expected signal\nand background rates is proposed. The interrelation between Gamma- and Poisson\ndistributions is demonstrated. \n\n"}
{"id": "hep-ph/0512040", "contents": "Title: Multiparticle correlations in Q-space Abstract: We introduce Q-space, the tensor product of an index space with a primary\nspace, to achieve a more general mathematical description of correlations in\nterms of q-tuples. Topics discussed include the decomposition of Q-space into a\nsum-variable (location) subspace S plus an orthogonal difference-variable\nsubspace D, and a systematisation of q-tuple size estimation in terms of\np-norms. The \"GHP sum\" prescription for q-tuple size emerges naturally as the\n2-norm of difference-space vectors. Maximum- and minimum-size prescriptions are\nfound to be special cases of a continuum of p-sizes. \n\n"}
{"id": "hep-th/9812061", "contents": "Title: Theoretical and Phenomenological Aspects of Superstring Theories Abstract: We discuss aspects of the heterotic string effective field theories in\norbifold constructions of the heterotic string. We calculate the moduli\ndependence of threshold corrections to gauge couplings in (2,2) symmetric\norbifold compactifications. We perform the calculation of the threshold\ncorrections for a particular class of abelian (2,2) symmetric non-decomposable\norbifold models... internal twist is realized as generalized Coxeter\nautomorphism. We define the limits for the existence of states causing\nsingularities in the moduli space in the perturbative regime for a generic\nvacuum of the heterotic string. The 'proof' provides evidence for the\nexplanation of the stringy 'Higgs effect'. Furthermore, we calculate the moduli\ndependence of threshold corrections as target space invariant free energies for\nnon-decomposable orbifolds, identifying the Hauptmodul' functions for the\nrelevant congruence subgroups. The required solutions provide for the \\mu mass\nterm generation in the effective low energy theory and affect the induced\nsypersymmetry breaking by gaugino condensation. In addition, we discuss the one\nloop gauge and gravitational couplings in (0,2) non-decomposable orbifold\ncompactifications. In the second part of the Thesis the one loop correction to\nthe Kahler metric for a generic N=2 orbifold compactification of the heterotic\nstring is calculated... In this way, with the use of the one loop string\namplitudes, the prepotential of the vector multiplets of the N=2 effective\nlow-energy heterotic string is calculated in decomposable toroidal\ncompactifications of the heterotic string ... This method provides the solution\nfor the one loop correction to the prepotential of the vector multiplets of the\nheterotic string compactified on the K_3 \\times T^2... \n\n"}
{"id": "math/0108163", "contents": "Title: Interval straight line fitting Abstract: I consider the task of experimental data fitting. Unlike the traditional\napproach I do not try to minimize any functional based on available\nexperimental information, instead the minimization problem is replaced with\nconstraint satisfaction procedure, which produces the interval hull of\nsolutions of desired type. The method, called 'box slicing algorithm', is\ndescribed in details. The results obtained this way need not to be labeled with\nconfidence level of any kind, they are simply certain (guaranteed). The method\neasily handles the case with uncertainties in one or both variables. There is\nno need for, always more or less arbitrary, weighting the experimental data.\nThe approach is directly applicable to other experimental data processing\nproblems like outliers detection or finding the straight line, which is tangent\nto the experimental curve. \n\n"}
{"id": "math/0609626", "contents": "Title: Evolutionary Prisoner's Dilemma on heterogeneous Newman-Watts\n  small-world network Abstract: We focus on the heterogeneity of social networks and its role to the\nemergence of prevailing cooperation and sustaining cooperators. The social\nnetworks are representative of the interaction relationships between players\nand their encounters in each round of games. We study an evolutionary\nPrisoner's Dilemma game on a variant of Watts-Strogatz small-world network,\nwhose heterogeneity can be tuned by a parameter. It is found that optimal\ncooperation level exists at some intermediate topological heterogeneity for\ndifferent temptations to defect. Moreover, neither the most heterogeneous case\nnor the most homogeneous one would favor the cooperators. At intermediate\nheterogeneity in degree sequences, cooperators could resist the invasion of\ndefectors for large temptation to defect. \n\n"}
{"id": "nlin/0001016", "contents": "Title: Modelling thermostatting, entropy currents and cross effects by\n  dynamical systems Abstract: A generalized multibaker map with periodic boundary conditions is shown to\nmodel boundary-driven transport, when the driving is applied by a\n``perturbation'' of the dynamics localised in a macroscopically small region.\nIn this case there are sustained density gradients in the steady state. A\nnon-uniform stationary temperature profile can be maintained by incorporating a\nheat source into the dynamics, which deviates from the one of a bulk system\nonly in a (macroscopically small) localized region such that a heat (or\nentropy) flux can enter an attached thermostat only in that region. For these\nsettings the relation between the average phase-space contraction, the entropy\nflux to the thermostat and irreversible entropy production is clarified for\nstationary and non-stationary states. In addition, thermoelectric cross-effects\nare described by a multibaker chain consisting of two parts with different\ntransport properties, modelling a junction between two metals. \n\n"}
{"id": "nlin/0001029", "contents": "Title: Intermittency effects in Burgers equation driven by thermal noise Abstract: For the Burgers equation driven by thermal noise leading asymptotics of pair\nand high-order correlators of the velocity field are found for finite times and\nlarge distances. It is shown that the intermittency takes place: some\ncorrelators are much larger than their reducible parts. \n\n"}
{"id": "nlin/0002045", "contents": "Title: Scarred Patterns in Surface Waves Abstract: Surface wave patterns are investigated experimentally in a system geometry\nthat has become a paradigm of quantum chaos: the stadium billiard. Linear waves\nin bounded geometries for which classical ray trajectories are chaotic are\nknown to give rise to scarred patterns. Here, we utilize parametrically forced\nsurface waves (Faraday waves), which become progressively nonlinear beyond the\nwave instability threshold, to investigate the subtle interplay between\nboundaries and nonlinearity. Only a subset (three main types) of the computed\nlinear modes of the stadium are observed in a systematic scan. These correspond\nto modes in which the wave amplitudes are strongly enhanced along paths\ncorresponding to certain periodic ray orbits. Many other modes are found to be\nsuppressed, in general agreement with a prediction by Agam and Altshuler based\non boundary dissipation and the Lyapunov exponent of the associated orbit.\nSpatially asymmetric or disordered (but time-independent) patterns are also\nfound even near onset. As the driving acceleration is increased, the\ntime-independent scarred patterns persist, but in some cases transitions\nbetween modes are noted. The onset of spatiotemporal chaos at higher forcing\namplitude often involves a nonperiodic oscillation between spatially ordered\nand disordered states. We characterize this phenomenon using the concept of\npattern entropy. The rate of change of the patterns is found to be reduced as\nthe state passes temporarily near the ordered configurations of lower entropy.\nWe also report complex but highly symmetric (time-independent) patterns far\nabove onset in the regime that is normally chaotic. \n\n"}
{"id": "nlin/0003010", "contents": "Title: Transition to Stochastic Synchronization in Spatially Extended Systems Abstract: Spatially extended dynamical systems, namely coupled map lattices, driven by\nadditive spatio-temporal noise are shown to exhibit stochastic synchronization.\nIn analogy with low-dymensional systems, synchronization can be achieved only\nif the maximum Lyapunov exponent becomes negative for sufficiently large noise\namplitude. Moreover, noise can suppress also the non-linear mechanism of\ninformation propagation, that may be present in the spatially extended system.\nA first example of phase transition is observed when both the linear and the\nnon-linear mechanisms of information production disappear at the same critical\nvalue of the noise amplitude. The corresponding critical properties can be\nhardly identified numerically, but some general argument suggests that they\ncould be ascribed to the Kardar-Parisi-Zhang universality class. Conversely,\nwhen the non-linear mechanism prevails on the linear one, another type of phase\ntransition to stochastic synchronization occurs. This one is shown to belong to\nthe universality class of directed percolation. \n\n"}
{"id": "nlin/0003043", "contents": "Title: Exit-Times and {\\Large $\\epsilon$}-Entropy for Dynamical Systems,\n  Stochastic Processes, and Turbulence Abstract: We present a comprehensive investigation of $\\epsilon$-entropy,\n$h(\\epsilon)$, in dynamical systems, stochastic processes and turbulence.\nParticular emphasis is devoted on a recently proposed approach to the\ncalculation of the $\\epsilon$-entropy based on the exit-time statistics. The\nadvantages of this method are demonstrated in examples of deterministic\ndiffusive maps, intermittent maps, stochastic self-affine and multi-affine\nsignals and experimental turbulent data. Concerning turbulence, the\nmultifractal formalism applied to the exit time statistics allows us to predict\nthat $h(\\epsilon)\\sim \\epsilon^{-3}$ for velocity time measurement. This power\nlaw is independent of the presence of intermittency and has been confirmed by\nthe experimental data analysis. Moreover, we show that the $\\epsilon$-entropy\ndensity of a 3-dimensional velocity field is affected by the correlations\ninduced by the sweeping of large scales. \n\n"}
{"id": "nlin/0006046", "contents": "Title: On thermostats and entropy production Abstract: The connection between the rate of entropy production and the rate of phase\nspace contraction for thermostatted systems in nonequilibrium steady states is\ndiscussed for a simple model of heat flow in a Lorentz gas, previously\ndescribed by Spohn and Lebowitz. It is easy to show that for the model\ndiscussed here the two rates are not connected, since the rate of entropy\nproduction is non-zero and positive, while the overall rate of phase space\ncontraction is zero. This is consistent with conclusions reached by other\nworkers. Fractal structures appear in the phase space for this model and their\nproperties are discussed. We conclude with a discussion of the implications of\nthis and related work for understanding the role of chaotic dynamics and\nspecial initial conditions for an explanation of the Second Law of\nThermodynamics. \n\n"}
{"id": "nlin/0009014", "contents": "Title: Fronts in passive scalar turbulence Abstract: The evolution of scalar fields transported by turbulent flow is characterized\nby the presence of fronts, which rule the small-scale statistics of scalar\nfluctuations. With the aid of numerical simulations, it is shown that: isotropy\nis not recovered, in the classical sense, at small scales; scaling exponents\nare universal with respect to the scalar injection mechanisms; high-order\nexponents saturate to a constant value; non-mature fronts dominate the\nstatistics of intense fluctuations. Results on the statistics inside the\nplateaux, where fluctuations are weak, are also presented. Finally, we analyze\nthe statistics of scalar dissipation and scalar fluxes. \n\n"}
{"id": "nlin/0010003", "contents": "Title: Rectification of current in ac-driven nonlinear systems and symmetry\n  properties of the Boltzmann equation Abstract: We study rectification of a current of particles moving in a spatially\nperiodic potential under the influence of time-periodic forces with zero mean\nvalue. If certain time-space symmetries are broken a non-zero directed current\nof particles is possible. We investigate this phenomenon in the framework of\nthe kinetic Boltzmann equation. We find that the attractor of the Boltzmann\nequation completely reflects the symmetries of the original one-particle\nequation of motion. Especially, we analyse the limits of weak and strong\nrelaxation. The dc current increases by several orders of magnitude with\ndecreasing dissipation. \n\n"}
{"id": "nlin/0010033", "contents": "Title: Front propagation in laminar flows Abstract: The problem of front propagation in flowing media is addressed for laminar\nvelocity fields in two dimensions. Three representative cases are discussed:\nstationary cellular flow, stationary shear flow, and percolating flow.\nProduction terms of Fisher-Kolmogorov-Petrovskii-Piskunov type and of Arrhenius\ntype are considered under the assumption of no feedback of the concentration on\nthe velocity. Numerical simulations of advection-reaction-diffusion equations\nhave been performed by an algorithm based on discrete-time maps. The results\nshow a generic enhancement of the speed of front propagation by the underlying\nflow. For small molecular diffusivity, the front speed $V_f$ depends on the\ntypical flow velocity $U$ as a power law with an exponent depending on the\ntopological properties of the flow, and on the ratio of reactive and advective\ntime-scales. For open-streamline flows we find always $V_f \\sim U$, whereas for\ncellular flows we observe $V_f \\sim U^{1/4}$ for fast advection, and $V_f \\sim\nU^{3/4}$ for slow advection. \n\n"}
{"id": "nlin/0011025", "contents": "Title: Note on chaos and diffusion Abstract: Using standard definitions of chaos (as positive Kolmogorov-Sinai entropy)\nand diffusion (that multiple time distribution functions are Gaussian), we show\nnumerically that both chaotic and nonchaotic systems exhibit diffusion, and\nhence that there is no direct logical connection between the two properties.\nThis extends a previous result for two time distribution functions. \n\n"}
{"id": "nlin/0011045", "contents": "Title: Classical dynamics on graphs Abstract: We consider the classical evolution of a particle on a graph by using a\ntime-continuous Frobenius-Perron operator which generalizes previous\npropositions. In this way, the relaxation rates as well as the chaotic\nproperties can be defined for the time-continuous classical dynamics on graphs.\nThese properties are given as the zeros of some periodic-orbit zeta functions.\nWe consider in detail the case of infinite periodic graphs where the particle\nundergoes a diffusion process. The infinite spatial extension is taken into\naccount by Fourier transforms which decompose the observables and probability\ndensities into sectors corresponding to different values of the wave number.\nThe hydrodynamic modes of diffusion are studied by an eigenvalue problem of a\nFrobenius-Perron operator corresponding to a given sector. The diffusion\ncoefficient is obtained from the hydrodynamic modes of diffusion and has the\nGreen-Kubo form. Moreover, we study finite but large open graphs which converge\nto the infinite periodic graph when their size goes to infinity. The lifetime\nof the particle on the open graph is shown to correspond to the lifetime of a\nsystem which undergoes a diffusion process before it escapes. \n\n"}
{"id": "nlin/0104044", "contents": "Title: Analytical and Numerical Studies of Noise-induced Synchronization of\n  Chaotic Systems Abstract: We study the effect that the injection of a common source of noise has on the\ntrajectories of chaotic systems, addressing some contradictory results present\nin the literature. We present particular examples of 1-d maps and the Lorenz\nsystem, both in the chaotic region, and give numerical evidence showing that\nthe addition of a common noise to different trajectories, which start from\ndifferent initial conditions, leads eventually to their perfect\nsynchronization. When synchronization occurs, the largest Lyapunov exponent\nbecomes negative. For a simple map we are able to show this phenomenon\nanalytically. Finally, we analyze the structural stability of the phenomenon. \n\n"}
{"id": "nlin/0107048", "contents": "Title: An Elementary Proof of Lyapunov Exponent Pairing for Hard-Sphere Systems\n  at Constant Kinetic Energy Abstract: The conjugate pairing of Lyapunov exponents for a field-driven system with\nsmooth inter-particle interaction at constant total kinetic energy was first\nproved by Dettmann and Morriss [Phys. Rev. E {\\bf 53}, R5545 (1996)] using\nsimple methods of geometry. Their proof was extended to systems interacting via\nhard-core inter-particle potentials by Wojtkowski and Liverani [Comm. Math.\nPhys. {\\bf 194}, 47 (1998)], using more sophisticated methods. Another, and\nsomewhat more direct version of the proof for hard-sphere systems has been\nprovided by Ruelle [J. Stat. Phys. {\\bf 95}, 393 (1999)]. However, these\napproaches for hard-sphere systems are somewhat difficult to follow. In this\npaper, a proof of the pairing of Lyapunov exponents for hard-sphere systems at\nconstant kinetic energy is presented, based on a very simple explicit geometric\nconstruction, similar to that of Ruelle. Generalizations of this construction\nto higher dimensions and arbitrary shapes of scatterers or particles are\ntrivial. This construction also works for hard-sphere systems in an external\nfield with a Nos\\'e-Hoover thermostat. However, there are situations of\nphysical interest, where these proofs of conjugate pairing rule for systems\ninteracting via hard-core inter-particle potentials break down. \n\n"}
{"id": "nlin/0107057", "contents": "Title: On multifractality and fractional derivatives Abstract: It is shown phenomenologically that the fractional derivative $\\xi=D^\\alpha\nu$ of order $\\alpha$ of a multifractal function has a power-law tail $\\propto\n|\\xi| ^{-p_\\star}$ in its cumulative probability, for a suitable range of\n$\\alpha$'s. The exponent is determined by the condition $\\zeta_{p_\\star} =\n\\alpha p_\\star$, where $\\zeta_p$ is the exponent of the structure function of\norder $p$. A detailed study is made for the case of random multiplicative\nprocesses (Benzi {\\it et al.} 1993 Physica D {\\bf 65}: 352) which are amenable\nto both theory and numerical simulations. Large deviations theory provides a\nconcrete criterion, which involves the departure from straightness of the\n$\\zeta_p$ graph, for the presence of power-law tails when there is only a\nlimited range over which the data possess scaling properties (e.g. because of\nthe presence of a viscous cutoff). The method is also applied to wind tunnel\ndata and financial data. \n\n"}
{"id": "nlin/0110023", "contents": "Title: Transitions from deterministic to stochastic diffusion Abstract: We examine characteristic properties of deterministic and stochastic\ndiffusion in low-dimensional chaotic dynamical systems. As an example, we\nconsider a periodic array of scatterers defined by a simple chaotic map on the\nline. Adding different types of time-dependent noise to this model we compute\nthe diffusion coefficient from simulations. We find that there is a crossover\nfrom deterministic to stochastic diffusion under variation of the perturbation\nstrength related to different asymptotic laws for the diffusion coefficient.\nTypical signatures of this scenario are suppression and enhancement of normal\ndiffusion. Our results are explained by a simple theoretical approximation. \n\n"}
{"id": "nlin/0112019", "contents": "Title: When do tracer particles dominate the Lyapunov spectrum? Abstract: Dynamical instability is studied in a deterministic dynamical system of\nHamiltonian type composed of a tracer particle in a fluid of many particles.\nThe tracer and fluid particles are hard balls (disks, in two dimensions, or\nspheres, in three dimensions) undergoing elastic collisions. The dynamical\ninstability is characterized by the spectrum of Lyapunov exponents. The tracer\nparticle is shown to dominate the Lyapunov spectrum in the neighborhoods of two\nlimiting cases: the Lorentz-gas limit in which the tracer particle is much\nlighter than the fluid particles and the Rayleigh-flight limit in which the\nfluid particles have a vanishing radius and form an ideal gas. In both limits,\na gap appears in the Lyapunov spectrum between the few largest Lyapunov\nexponents associated with the tracer and the rest of the Lyapunov spectrum. \n\n"}
{"id": "nlin/0201038", "contents": "Title: Decoherence of spin echoes Abstract: We define a quantity, the so-called purity fidelity, which measures the rate\nof dynamical irreversibility due to decoherence, observed e.g in echo\nexperiments, in the presence of an arbitrary small perturbation of the total\n(system + environment) Hamiltonian. We derive a linear response formula for the\npurity fidelity in terms of integrated time correlation functions of the\nperturbation. Our relation predicts, similarly to the case of fidelity decay,\nfaster decay of purity fidelity the slower decay of time correlations is. In\nparticular, we find exponential decay in quantum mixing regime and faster,\ninitially quadratic and later typically gaussian decay in the regime of\nnon-ergodic, e.g. integrable quantum dynamics. We illustrate our approach by an\nanalytical calculation and numerical experiments in the Ising spin 1/2 chain\nkicked with tilted homogeneous magnetic field where part of the chain is\ninterpreted as a system under observation and part as an environment. \n\n"}
{"id": "nlin/0202015", "contents": "Title: Pairing of Lyapunov Exponents for a Hard-Sphere Gas under Shear in the\n  Thermodynamic Limit Abstract: We consider a dilute gas of hard spheres under shear. We use one of the\npredominant models to study this system, namely the SLLOD equations of motion,\nwith an iso-kinetic Gaussian thermostat in between collisions, to get a\nstationary total peculiar kinetic energy. Based on the previously obtained\nresult that in the non-equilibrium steady state and in case the number of\nparticles $N$ becomes large, the coefficient of dynamical friction representing\nthe iso-kinetic Gaussian thermostat for the SLLOD dynamics fluctuates with\n$1/\\sqrt{N}$ fluctuations around a fixed value, we show on analytical grounds\nthat for a hard sphere gas at small shear rate and with a large number of\nspheres, the conjugate pairing of the Lyapunov exponents is expected to be\nviolated at the fourth power of the constant shear rate in the bulk. \n\n"}
{"id": "nlin/0202016", "contents": "Title: Lyapunov Exponent Pairing for a Thermostatted Hard-Sphere Gas under\n  Shear in the Thermodynamic Limit Abstract: We demonstrate why for a sheared gas of hard spheres, described by the SLLOD\nequations with an iso-kinetic Gaussian thermostat in between collisions,\ndeviations of the conjugate pairing rule for the Lyapunov spectrum are to be\nexpected, employing a previous result that for a large number of particles $N$,\nthe iso-kinetic Gaussian thermostat is equivalent to a constant friction\nthermostat, up to $1/\\sqrt{N}$ fluctuations. We also show that these deviations\nare at most of the order of the fourth power in the shear rate. \n\n"}
{"id": "nlin/0203019", "contents": "Title: Heat Conduction and Entropy Production in a One-Dimensional\n  Hard-Particle Gas Abstract: We present large scale simulations for a one-dimensional chain of hard-point\nparticles with alternating masses. We correct several claims in the recent\nliterature based on much smaller simulations. Both for boundary conditions with\ntwo heat baths at different temperatures at both ends and from heat current\nautocorrelations in equilibrium we find heat conductivities kappa to diverge\nwith the number N of particles. These depended very strongly on the mass\nratios, and extrapolation to N -> infty resp. t -> infty is difficult due to\nvery large finite-size and finite-time corrections. Nevertheless, our data seem\ncompatible with a universal power law kappa ~ N^alpha with alpha approx 0.33.\nThis suggests a relation to the Kardar-Parisi-Zhang model. We finally show that\nthe hard-point gas with periodic boundary conditions is not chaotic in the\nusual sense and discuss why the system, when kept out of equilibrium, leads\nnevertheless to energy dissipation and entropy production. \n\n"}
{"id": "nlin/0203046", "contents": "Title: Entropy production of diffusion in spatially periodic deterministic\n  systems Abstract: This paper presents an {\\it ab initio} derivation of the expression given by\nirreversible thermodynamics for the rate of entropy production for different\nclasses of diffusive processes. The first class are Lorentz gases, where\nnon-interacting particles move on a spatially periodic lattice, and collide\nelastically with fixed scatterers. The second class are periodic systems where\n$N$ particles interact with each other, and one of them is a tracer particle\nwhich diffuses among the cells of the lattice. We assume that, in either case,\nthe dynamics of the system is deterministic and hyperbolic, with positive\nLyapunov exponents. This work extends methods originally developed for a\nchaotic two-dimensional model of diffusion, the multi-baker map, to higher\ndimensional, continuous time dynamical systems appropriate for systems with one\nor more moving particles. Here we express the rate of entropy production in\nterms of hydrodynamic measures that are determined by the fractal properties of\nmicroscopic hydrodynamic modes that describe the slowest decay of the system to\nan equilibrium state. \n\n"}
{"id": "nlin/0204046", "contents": "Title: Deterministic diffusion in flower shape billiards Abstract: We propose a flower shape billiard in order to study the irregular parameter\ndependence of chaotic normal diffusion. Our model is an open system consisting\nof periodically distributed obstacles of flower shape, and it is strongly\nchaotic for almost all parameter values. We compute the parameter dependent\ndiffusion coefficient of this model from computer simulations and analyze its\nfunctional form by different schemes all generalizing the simple random walk\napproximation of Machta and Zwanzig. The improved methods we use are based\neither on heuristic higher-order corrections to the simple random walk model,\non lattice gas simulation methods, or they start from a suitable Green-Kubo\nformula for diffusion. We show that dynamical correlations, or memory effects,\nare of crucial importance to reproduce the precise parameter dependence of the\ndiffusion coefficent. \n\n"}
{"id": "nlin/0205006", "contents": "Title: Stable Quantum Resonances in Atom Optics Abstract: A theory for stabilization of quantum resonances by a mechanism similar to\none leading to classical resonances in nonlinear systems is presented. It\nexplains recent surprising experimental results, obtained for cold Cesium atoms\nwhen driven in the presence of gravity, and leads to further predictions. The\ntheory makes use of invariance properties of the system, that are similar to\nthose of solids, allowing for separation into independent kicked rotor\nproblems. The analysis relies on a fictitious classical limit where the small\nparameter is {\\em not} Planck's constant, but rather the detuning from the\nfrequency that is resonant in absence of gravity. \n\n"}
{"id": "nlin/0206027", "contents": "Title: Fractal structures of normal and anomalous diffusion in nonlinear\n  nonhyperbolic dynamical systems Abstract: A paradigmatic nonhyperbolic dynamical system exhibiting deterministic\ndiffusion is the smooth nonlinear climbing sine map. We find that this map\ngenerates fractal hierarchies of normal and anomalous diffusive regions as\nfunctions of the control parameter. The measure of these self-similar sets is\npositive, parameter-dependent, and in case of normal diffusion it shows a\nfractal diffusion coefficient. By using a Green-Kubo formula we link these\nfractal structures to the nonlinear microscopic dynamics in terms of fractal\nTakagi-like functions. \n\n"}
{"id": "nlin/0209038", "contents": "Title: Self-Organized Criticality and Thermodynamic formalism Abstract: We introduce a dissipative version of the Zhang's model of Self-Organized\nCriticality, where a parameter allows to tune the local energy dissipation. We\nanalyze the main dynamical features of the model and relate in particular the\nLyapunov spectrum with the transport properties in the stationary regime. We\ndevelop a thermodynamic formalism where we define formal Gibbs measure,\npartition function and pressure characterizing the avalanche distributions. We\ndiscuss the infinite size limit in this setting. We show in particular that a\nLee-Yang phenomenon occurs in this model, for the only conservative case. This\nsuggests new connexions to classical critical phenomena. \n\n"}
{"id": "nlin/0211012", "contents": "Title: Fractality of deterministic diffusion in the nonhyperbolic climbing sine\n  map Abstract: The nonlinear climbing sine map is a nonhyperbolic dynamical system\nexhibiting both normal and anomalous diffusion under variation of a control\nparameter. We show that on a suitable coarse scale this map generates an\noscillating parameter-dependent diffusion coefficient, similarly to hyperbolic\nmaps, whose asymptotic functional form can be understood in terms of simple\nrandom walk approximations. On finer scales we find fractal hierarchies of\nnormal and anomalous diffusive regions as functions of the control parameter.\nBy using a Green-Kubo formula for diffusion the origin of these different\nregions is systematically traced back to strong dynamical correlations.\nStarting from the equations of motion of the map these correlations are\nformulated in terms of fractal generalized Takagi functions obeying generalized\nde Rham-type functional recursion relations. We finally analyze the measure of\nthe normal and anomalous diffusive regions in the parameter space showing that\nin both cases it is positive, and that for normal diffusion it increases by\nincreasing the parameter value. \n\n"}
{"id": "nlin/0212033", "contents": "Title: Quantum resonances and decoherence for delta-kicked atoms Abstract: The quantum resonances occurring with delta-kicked atoms when the kicking\nperiod is an integer multiple of the half-Talbot time are analyzed in detail.\nExact results about the momentum distribution at exact resonance are\nestablished, both in the case of totally coherent dynamics and in the case when\ndecoherence is induced by Spontaneous Emission. A description of the dynamics\nwhen the kicking period is close to, but not exactly at resonance, is derived\nby means of a quasi-classical approximation where the detuning from exact\nresonance plays the role of the Planck constant. In this way scaling laws\ndescribing the shape of the resonant peaks are obtained. Such analytical\nresults are supported by extensive numerical simulations, and explain some\nrecent surprising experimental observations. \n\n"}
{"id": "nlin/0212036", "contents": "Title: Crossover from Diffusive to Ballistic Transport in Periodic Quantum Maps Abstract: We derive an expression for the mean square displacement of a particle whose\nmotion is governed by a uniform, periodic, quantum multi-baker map. The\nexpression is a function of both time, $t$, and Planck's constant, $\\hbar$, and\nallows a study of both the long time, $t\\to\\infty$, and semi-classical,\n$\\hbar\\to 0$, limits taken in either order. We evaluate the expression using\nrandom matrix theory as well as numerically, and observe good agreement between\nboth sets of results. The long time limit shows that particle transport is\ngenerically ballistic, for any fixed value of Planck's constant. However, for\nfixed times, the semi-classical limit leads to diffusion. The mean square\ndisplacement for non-zero Planck's constant, and finite time, exhibits a\ncrossover from diffusive to ballistic motion, with crossover time on the order\nof the inverse of Planck's constant. We argue, that these results are generic\nfor a large class of 1D quantum random walks, similar to the quantum\nmulti-baker, and that a sufficient condition for diffusion in the\nsemi-classical limit is classically chaotic dynamics in each cell. Some\nconnections between our work and the other literature on quantum random walks\nare discussed. These walks are of some interest in the theory of quantum\ncomputation. \n\n"}
{"id": "nlin/0305040", "contents": "Title: Turbulence and Tsallis Statistics Abstract: Fully-developed incompressible Navier-Stokes turbulence in three dimensions\nis a dissipative dynamical system that exhibits strong departure from absolute\nequilibrium. Nevertheless, several kinds of representation by Tsallis\nequilibria have been proposed. The symmetry of the contributions to the kinetic\nenergy from the degrees of freedom of the flow must be broken in order to\nconstruct turbulence applications. Tsallis representations of turbulence\ninvolve the extrapolation of results for systems with a single degree of\nfreedom, a procedure that requires critical examination. Theories of Tsallis\nstatistics for acceleration of fluid particles are compared with computer\nsimulations of the pressure gradient field in the present paper. Applications\nof Tsallis formulations to statistics of longitudinal velocity differences are\nanalyzed. No flavor of equilibrium statistics based on the kinetic energy can\nencompass the dynamically fundamental turbulent energy cascade, which requires\ncorrelation of triads of degrees of freedom at different scales. \n\n"}
{"id": "nlin/0307015", "contents": "Title: Methods and Techniques of Complex Systems Science: An Overview Abstract: In this chapter, I review the main methods and techniques of complex systems\nscience. As a first step, I distinguish among the broad patterns which recur\nacross complex systems, the topics complex systems science commonly studies,\nthe tools employed, and the foundational science of complex systems. The focus\nof this chapter is overwhelmingly on the third heading, that of tools. These in\nturn divide, roughly, into tools for analyzing data, tools for constructing and\nevaluating models, and tools for measuring complexity. I discuss the principles\nof statistical learning and model selection; time series analysis; cellular\nautomata; agent-based models; the evaluation of complex-systems models;\ninformation theory; and ways of measuring complexity. Throughout, I give only\nrough outlines of techniques, so that readers, confronted with new problems,\nwill have a sense of which ones might be suitable, and which ones definitely\nare not. \n\n"}
{"id": "nlin/0307029", "contents": "Title: Synchronized clusters in coupled map networks: Self-organized and driven\n  phase synchronization Abstract: We study the synchronization of coupled maps on a variety of networks\nincluding regular one and two dimensional networks, scale free networks, small\nworld networks, tree networks, and random networks. For small coupling\nstrengths nodes show turbulent behavior but form phase synchronized clusters as\ncoupling increases. We identify two different ways of cluster formation,\nself-organized clusters which have mostly intra-cluster couplings and driven\nclusters which have mostly inter-cluster couplings. The synchronized clusters\nmay be of dominant self-organized type, dominant driven type or mixed type\ndepending on the type of network and the parameters of the dynamics. There are\nsome nodes of the floating type that show intermittent behaviour between\ngetting attached to some clusters and evolving independently. The residence\ntimes of a floating node in a synchronized cluster show an exponential\ndistribution. We define different states of the coupled dynamics by considering\nthe number and type of synchronized clusters. For the local dynamics governed\nby the logistic map we study the phase diagram in the plane of the coupling\nconstant ($\\epsilon$) and the logistic map parameter ($\\mu$). For large\ncoupling strengths and nonlinear coupling we find that the scale free networks\nand the Caley tree networks lead to better cluster formation than the other\ntypes of networks with the same average connectivity. For most of our study we\nuse the number of connections of the order of the number of nodes which allows\nus to distinguish between the two mechanisms of cluster formation. As the\nnumber of connections increases the number of nodes forming clusters and the\nsize of the clusters in general increase. \n\n"}
{"id": "nlin/0307037", "contents": "Title: Synchronized clusters in coupled map networks: Stability analysis Abstract: We study self-organized (s-) and driven (d-) synchronization in coupled map\nnetworks for some simple networks, namely two and three node networks and their\nnatural generalization to globally coupled and complete bipartite networks. We\nuse both linear stability analysis and Lyapunov function approach for this\nstudy and determine stability conditions for synchronization. We see that most\nof the features of coupled dynamics of small networks with two or three nodes,\nare carried over to the larger networks of the same type. The phase diagrams\nfor the networks studied here have features very similar to the different kinds\nof networks studied in Ref. \\cite{sarika-REA2}. The analysis of the dynamics of\nthe difference variable corresponding to any two nodes shows that when the two\nnodes are in driven synchronization, all the coupling terms cancel out whereas\nwhen they are in self-organized synchronization, the direct coupling term\nbetween the two nodes adds an extra decay term while the other couplings cancel\nout. \n\n"}
{"id": "nlin/0309065", "contents": "Title: Statistics of finite-time Lyapunov exponents in the Ulam map Abstract: The statistical properties of finite-time Lyapunov exponents at the Ulam\npoint of the logistic map are investigated. The exact analytical expression for\nthe autocorrelation function of one-step Lyapunov exponents is obtained,\nallowing the calculation of the variance of exponents computed over time\nintervals of length $n$. The variance anomalously decays as $1/n^2$. The\nprobability density of finite-time exponents noticeably deviates from the\nGaussian shape, decaying with exponential tails and presenting $2^{n-1}$ spikes\nthat narrow and accumulate close to the mean value with increasing $n$. The\nasymptotic expression for this probability distribution function is derived. It\nprovides an adequate smooth approximation to describe numerical histograms\nbuilt for not too small $n$, where the finiteness of bin size trimmes the sharp\npeaks. \n\n"}
{"id": "nlin/0309069", "contents": "Title: Microscopic chaos and transport in thermostated dynamical systems Abstract: A fundamental challenge is to understand nonequilibrium statistical mechanics\nstarting from microscopic chaos in the equations of motion of a many-particle\nsystem. In this review we summarize recent theoretical advances along these\nlines. Particularly, we are concerned with nonequilibrium situations created by\nexternal electric fields and by temperature or velocity gradients. These\nconstraints pump energy into a system, hence there must be some thermal\nreservoir that prevents the system from heating up. About twenty years ago a\ndeterministic and time-reversible modeling of such thermal reservoirs was\nproposed in form of Gaussian and Nose-Hoover thermostats. This approach yielded\nsimple relations between fundamental quantities of nonequilibrium statistical\nmechanics and of dynamical systems theory. The main theme of our review is to\ncritically assess the universality of these results. As a vehicle of\ndemonstration we employ the driven periodic Lorentz gas, which is a toy model\nfor the classical dynamics of an electron in a metal under application of an\nelectric field. Applying different types of thermal reservoirs to this system\nwe compare the resulting nonequilibrium steady states with each other. Along\nthe same lines we discuss an interacting many-particle system under shear and\nheat. Finally, we outline an unexpected relationship between deterministic\nthermostats and active Brownian particles modeling biophysical cell motility. \n\n"}
{"id": "nlin/0311016", "contents": "Title: Dynamic Scaling of Bred Vectors in Chaotic Extended Systems Abstract: We argue that the spatiotemporal dynamics of bred vectors in chaotic extended\nsystems are related to a kinetic roughening process in the Kardar-Parisi-Zhang\nuniversality class. This implies that there exists a characteristic length\nscale corresponding to the typical extend over which the finite-size\nperturbation is actually correlated in space. This can be used as a\nquantitative parameter to characterize the degree of projection of the bred\nvectors into the dynamical attractor. \n\n"}
{"id": "nlin/0312033", "contents": "Title: Entropy production away from the equilibrium Abstract: For a system moving away from equilibrium, we express the entropy production\nvia a two-point correlation function for any time and any distance from\nequilibrium. The long-time limit gives the sum of the Lyapunov exponents for a\ngeneral dynamical system expressed via the formula of a Green-Kubo type. \n\n"}
{"id": "nlin/0312044", "contents": "Title: Fractional Generalization of Liouville Equations Abstract: In this paper fractional generalization of Liouville equation is considered.\nWe derive fractional analog of normalization condition for distribution\nfunction. Fractional generalization of the Liouvile equation for dissipative\nand Hamiltonian systems was derived from the fractional normalization\ncondition. This condition is considered considered as a normalization condition\nfor systems in fractional phase space. The interpretation of the fractional\nspace is discussed. \n\n"}
{"id": "nlin/0401034", "contents": "Title: Chaos synchronization in long-range coupled map lattices Abstract: We investigate the synchronization phenomenon in coupled chaotic map lattices\nwhere the couplings decay with distance following a power-law. Depending on the\nlattice size, the coupling strength and the range of the interactions, complete\nchaos synchronization may be attained. The synchronization domain in parameter\nspace can be analytically delimited by means of the condition of negativity of\nthe largest transversal Lyapunov exponent. Here we analyze in detail the role\nof all the system parameters in the ability of the lattice to achieve complete\nsynchronization, testing analytical results with the outcomes of numerical\nexperiments. \n\n"}
{"id": "nlin/0404014", "contents": "Title: Anisotropy in Turbulent Flows and in Turbulent Transport Abstract: We discuss the problem of anisotropy and intermittency in statistical theory\nof high Reynolds-number turbulence (and turbulent transport). We present a\ndetailed description of the new tools that allow effective data analysis and\nsystematic theoretical studies such as to separate isotropic from anisotropic\naspects of turbulent statistical fluctuations. Employing the invariance of the\nequations of fluid mechanics to all rotations, we show how to decompose the\n(tensorial) statistical objects in terms of the irreducible representation of\nthe SO(3) symmetry group. For the case of turbulent advection of passive scalar\nor vector fields, this decomposition allows rigorous statements to be made: (i)\nthe scaling exponents are universal, (ii) the isotropic scaling exponents are\nalways leading, (iii) the anisotropic scaling exponents form a discrete\nspectrum which is strictly increasing as a function of the anisotropic degree.\nNext we explain how to apply the SO(3) decomposition to the statistical\nNavier-Stokes theory. We show how to extract information about the scaling\nbehavior in the isotropic sector. Doing so furnishes a systematic way to assess\nthe universality of the scaling exponents in this sector, clarifying the\nanisotropic origin of the many measurements that claimed the opposite. A\nsystematic analysis of Direct Numerical Simulations and of experiments provides\na strong support to the proposition that also for the non-linear problem there\nexists foliation of the statistical theory into sectors of the symmetry group.\nThe exponents appear universal in each sector, and again strictly increasing as\na function of the anisotropic degreee. \n\n"}
{"id": "nlin/0407018", "contents": "Title: Active and passive fields face to face Abstract: The statistical properties of active and passive scalar fields transported by\nthe same turbulent flow are investigated. Four examples of active scalar have\nbeen considered: temperature in thermal convection, magnetic potential in\ntwo-dimensional magnetohydrodynamics, vorticity in two-dimensional Ekman\nturbulence and potential temperature in surface flows. In the cases of\ntemperature and vorticity, it is found that the active scalar behavior is akin\nto that of its co-evolving passive counterpart. The two other cases indicate\nthat this similarity is in fact not generic and differences between passive and\nactive fields can be striking: in two-dimensional magnetohydrodynamics the\nmagnetic potential performs an inverse cascade while the passive scalar\ncascades toward the small-scales; in surface flows, albeit both perform a\ndirect cascade, the potential temperature and the passive scalar have different\nscaling laws already at the level of low-order statistical objects. These\ndramatic differences are rooted in the correlations between the active scalar\ninput and the particle trajectories. The role of such correlations in the issue\nof universality in active scalar transport and the behavior of dissipative\nanomalies is addressed. \n\n"}
{"id": "nlin/0408004", "contents": "Title: Scaling properties of growing noninfinitesimal perturbations in\n  space-time chaos Abstract: We study the spatiotemporal dynamics of random spatially distributed\nnoninfinitesimal perturbations in one-dimensional chaotic extended systems. We\nfind that an initial perturbation of finite size $\\epsilon_0$ grows in time\nobeying the tangent space dynamic equations (Lyapunov vectors) up to a\ncharacteristic time $t_{\\times}(\\epsilon_0) \\sim b - (1/\\lambda_{max}) \\ln\n(\\epsilon_0)$, where $\\lambda_{max}$ is the largest Lyapunov exponent and $b$\nis a constant. For times $t < t_{\\times}$ perturbations exhibit spatial\ncorrelations up to a typical distance $\\xi \\sim t^z$. For times larger than\n$t_{\\times}$ finite perturbations are no longer described by tangent space\nequations, memory of spatial correlations is progressively destroyed and\nperturbations become spatiotemporal white noise. We are able to explain these\nresults by mapping the problem to the Kardar-Parisi-Zhang universality class of\nsurface growth. \n\n"}
{"id": "nlin/0411012", "contents": "Title: Fine structure of distributions and central limit theorem in diffusive\n  billiards Abstract: We investigate deterministic diffusion in periodic billiard models, in terms\nof the convergence of rescaled distributions to the limiting normal\ndistribution required by the central limit theorem; this is stronger than the\nusual requirement that the mean square displacement grow asymptotically\nlinearly in time. The main model studied is a chaotic Lorentz gas where the\ncentral limit theorem has been rigorously proved. We study one-dimensional\nposition and displacement densities describing the time evolution of\nstatistical ensembles in a channel geometry, using a more refined method than\nhistograms. We find a pronounced oscillatory fine structure, and show that this\nhas its origin in the geometry of the billiard domain. This fine structure\nprevents the rescaled densities from converging pointwise to gaussian\ndensities; however, demodulating them by the fine structure gives new densities\nwhich seem to converge uniformly. We give an analytical estimate of the rate of\nconvergence of the original distributions to the limiting normal distribution,\nbased on the analysis of the fine structure, which agrees well with simulation\nresults. We show that using a Maxwellian (gaussian) distribution of velocities\nin place of unit speed velocities does not affect the growth of the mean square\ndisplacement, but changes the limiting shape of the distributions to a\nnon-gaussian one. Using the same methods, we give numerical evidence that a\nnon-chaotic polygonal channel model also obeys the central limit theorem, but\nwith a slower convergence rate. \n\n"}
{"id": "nlin/0411054", "contents": "Title: Anomalous transport in Charney-Hasegawa-Mima flows Abstract: Transport properties of particles evolving in a system governed by the\nCharney-Hasegawa-Mima equation are investigated. Transport is found to be\nanomalous with a non linear evolution of the second moments with time. The\norigin of this anomaly is traced back to the presence of chaotic jets within\nthe flow. All characteristic transport exponents have a similar value around\n$\\mu=1.75$, which is also the one found for simple point vortex flows in the\nliterature, indicating some kind of universality. Moreover the law\n$\\gamma=\\mu+1$ linking the trapping time exponent within jets to the transport\nexponent is confirmed and an accumulation towards zero of the spectrum of\nfinite time Lyapunov exponent is observed. The localization of a jet is\nperformed, and its structure is analyzed. It is clearly shown that despite a\nregular coarse grained picture of the jet, motion within the jet appears as\nchaotic but chaos is bounded on successive small scales. \n\n"}
{"id": "nlin/0412038", "contents": "Title: Multifractal Behavior of the Korean Stock-market Index KOSPI Abstract: We investigate multifractality in the Korean stock-market index KOSPI. The\ngeneralized $q$th order height-height correlation function shows multiscaling\nproperties. There are two scaling regimes with a crossover time around $t_c\n=40$ min. We consider the original data sets and the modified data sets\nobtained by removing the daily jumps, which occur due to the difference between\nthe closing index and the opening index. To clarify the origin of the\nmultifractality, we also smooth the data through convolution with a Gaussian\nfunction. After convolution we observe that the multifractality disappears in\nthe short-time scaling regime $t<t_c$, but remains in the long-time scaling\nregime $t>t_c$, regardless of whether or not the daily jumps are removed. We\nsuggest that multifractality in the short-time scaling regime is caused by the\nlocal fluctuations of the stock index. But the multifractality in the long-time\nscaling regime appears to be due to the intrinsic trading properties, such as\nherding behavior, information outside the market, the long memory of the\nvolatility, and the nonlinear dynamics of the stock market. \n\n"}
{"id": "nlin/0412046", "contents": "Title: Wavelet analysis and scaling properties of time series Abstract: We propose a wavelet based method for the characterization of the scaling\nbehavior of non-stationary time series. It makes use of the built-in ability of\nthe wavelets for capturing the trends in a data set, in variable window sizes.\nDiscrete wavelets from the Daubechies family are used to illustrate the\nefficacy of this procedure. After studying binomial multifractal time series\nwith the present and earlier approaches of detrending for comparison, we\nanalyze the time series of averaged spin density in the 2D Ising model at the\ncritical temperature, along with several experimental data sets possessing\nmulti-fractal behavior. \n\n"}
{"id": "nlin/0501006", "contents": "Title: Anomalous scaling of passive scalar in turbulence and in equilibrium Abstract: We analyze multi-point correlation functions of a tracer in an incompressible\nflow at scales far exceeding the scale $L$ at which fluctuations are generated\n(quasi-equilibrium domain) and compare them with the correlation functions at\nscales smaller than $L$ (turbulence domain). We demonstrate that the scale\ninvariance can be broken in the equilibrium domain and trace this breakdown to\nthe statistical integrals of motion (zero modes) as has been done before for\nturbulence. Employing Kraichnan model of short-correlated velocity we identify\nthe new type of zero modes, which break scale invariance and determine an\nanomalously slow decay of correlations at large scales. \n\n"}
{"id": "nlin/0503035", "contents": "Title: Properties making a chaotic system a good Pseudo Random Number Generator Abstract: We discuss two properties making a deterministic algorithm suitable to\ngenerate a pseudo random sequence of numbers: high value of Kolmogorov-Sinai\nentropy and high-dimensionality. We propose the multi dimensional Anosov\nsymplectic (cat) map as a Pseudo Random Number Generator. We show what chaotic\nfeatures of this map are useful for generating Pseudo Random Numbers and\ninvestigate numerically which of them survive in the discrete version of the\nmap. Testing and comparisons with other generators are performed. \n\n"}
{"id": "nlin/0504005", "contents": "Title: Nonequilibrium Energy Profiles for a Class of 1-D Models Abstract: As a paradigm for heat conduction in 1 dimension, we propose a class of\nmodels represented by chains of identical cells, each one of which containing\nan energy storage device called a \"tank\". Energy exchange among tanks is\nmediated by tracer particles, which are injected at characteristic temperatures\nand rates from heat baths at the two ends of the chain. For stochastic and\nHamiltonian models of this type, we develop a theory that allows one to derive\nrigorously -- under physically natural assumptions -- macroscopic equations for\nquantities related to heat transport, including mean energy profiles and tracer\ndensities. Concrete examples are treated for illustration, and the validity of\nthe Fourier Law in the present context is discussed. \n\n"}
{"id": "nlin/0504013", "contents": "Title: Nonlinearly driven transverse synchronization in coupled chaotic systems Abstract: Synchronization transitions are investigated in coupled chaotic maps.\nDepending on the relative weight of linear versus nonlinear instability\nmechanisms associated to the single map two different scenarios for the\ntransition may occur. When only two maps are considered we always find that the\ncritical coupling $\\epsilon_l$ for chaotic synchronization can be predicted\nwithin a linear analysis by the vanishing of the transverse Lyapunov exponent\n$\\lambda_T$. However, major differences between transitions driven by linear or\nnonlinear mechanisms are revealed by the dynamics of the transient toward the\nsynchronized state. As a representative example of extended systems a one\ndimensional lattice of chaotic maps with power-law coupling is considered. In\nthis high dimensional model finite amplitude instabilities may have a dramatic\neffect on the transition. For strong nonlinearities an exponential divergence\nof the synchronization times with the chain length can be observed above\n$\\epsilon_l$, notwithstanding the transverse dynamics is stable against\ninfinitesimal perturbations at any instant. Therefore, the transition takes\nplace at a coupling $\\epsilon_{nl}$ definitely larger than $\\epsilon_l$ and its\norigin is intrinsically nonlinear. The linearly driven transitions are\ncontinuous and can be described in terms of mean field results for\nnon-equilibrium phase transitions with long range interactions. While the\ntransitions dominated by nonlinear mechanisms appear to be discontinuous. \n\n"}
{"id": "nlin/0504025", "contents": "Title: Order in Binary Sequences and the Routes to Chaos Abstract: The natural order in the space of binary sequences permits to recover the\n$U$-sequence. Also the scaling laws of the period-doubling cascade and the\nintermittency route to chaos defined in that ordered set are explained. These\narise as intrinsic properties of this ordered set, and independent from any\nconsideration about dynamical systems. \n\n"}
{"id": "nlin/0505026", "contents": "Title: Dynamic characterisers of spatiotemporal intermittency Abstract: We study spatiotemporal intermittency in a system of coupled sine circle\nmaps. The phase diagram of the system shows parameter regimes where the STI\nlies in the directed percolation class, as well as regimes which show pure\nspatial intermittency (where the temporal behaviour is regular) which do not\nbelong to the DP class. Thus, both DP and non-DP behaviour can be seen in the\nsame system. The signature of DP and non-DP behaviour can be seen in the\ndynamic characterisers, viz. the spectrum of eigenvalues of the linear\nstability matrix of the evolution equation, as well as in the multifractal\nspectrum of the eigenvalue distribution. The eigenvalue spectrum of the system\nin the DP regimes is continuous, whereas it shows evidence of level repulsion\nin the form of gaps in the spectrum in the non-DP regime. The multifractal\nspectrum of the eigenvalue distribution also shows the signature of DP and\nnon-DP behaviour. These results have implications for the manner in which\ncorrelations build up in extended systems. \n\n"}
{"id": "nlin/0506061", "contents": "Title: Transmitting a signal by amplitude modulation in a chaotic network Abstract: We discuss the ability of a network with non linear relays and chaotic\ndynamics to transmit signals, on the basis of a linear response theory\ndeveloped by Ruelle \\cite{Ruelle} for dissipative systems. We show in\nparticular how the dynamics interfere with the graph topology to produce an\neffective transmission network, whose topology depends on the signal, and\ncannot be directly read on the ``wired'' network. This leads one to reconsider\nnotions such as ``hubs''. Then, we show examples where, with a suitable choice\nof the carrier frequency (resonance), one can transmit a signal from a node to\nanother one by amplitude modulation, \\textit{in spite of chaos}. Also, we give\nan example where a signal, transmitted to any node via different paths, can\nonly be recovered by a couple of \\textit{specific} nodes. This opens the\npossibility for encoding data in a way such that the recovery of the signal\nrequires the knowledge of the carrier frequency \\textit{and} can be performed\nonly at some specific node. \n\n"}
{"id": "nlin/0507036", "contents": "Title: Ergodicity Breaking in a Deterministic Dynamical System Abstract: The concept of weak ergodicity breaking is defined and studied in the context\nof deterministic dynamics. We show that weak ergodicity breaking describes a\nweakly chaotic dynamical system: a nonlinear map which generates subdiffusion\ndeterministically. In the non-ergodic phase non-trivial distribution of the\nfraction of occupation times is obtained. The visitation fraction remains\nuniform even in the non-ergodic phase. In this sense the non-ergodicity is\nquantified, leading to a statistical mechanical description of the system even\nthough it is not ergodic. \n\n"}
{"id": "nlin/0508037", "contents": "Title: One-Particle and Few-Particle Billiards Abstract: We study the dynamics of one-particle and few-particle billiard systems in\ncontainers of various shapes. In few-particle systems, the particles collide\nelastically both against the boundary and against each other. In the\none-particle case, we investigate the formation and destruction of resonance\nislands in (generalized) mushroom billiards, which are a recently discovered\nclass of Hamiltonian systems with mixed regular-chaotic dynamics. In the\nfew-particle case, we compare the dynamics in container geometries whose\ncounterpart one-particle billiards are integrable, chaotic, and mixed. One of\nour findings is that two-, three-, and four-particle billiards confined to\ncontainers with integrable one-particle counterparts inherit some integrals of\nmotion and exhibit a regular partition of phase space into ergodic components\nof positive measure. Therefore, the shape of a container matters not only for\nnoninteracting particles but also for interacting particles. \n\n"}
{"id": "nlin/0601027", "contents": "Title: Dynamics and statistics of heavy particles in turbulent flows Abstract: We present the results of Direct Numerical Simulations (DNS) of turbulent\nflows seeded with millions of passive inertial particles. The maximum Taylor's\nReynolds number is around 200. We consider particles much heavier than the\ncarrier flow in the limit when the Stokes drag force dominates their dynamical\nevolution. We discuss both the transient and the stationary regimes. In the\ntransient regime, we study the growt of inhomogeneities in the particle spatial\ndistribution driven by the preferential concentration out of intense vortex\nfilaments. In the stationary regime, we study the acceleration fluctuations as\na function of the Stokes number in the range [0.16:3.3]. We also compare our\nresults with those of pure fluid tracers (St=0) and we find a critical behavior\nof inertia for small Stokes values. Starting from the pure monodisperse\nstatistics we also characterize polydisperse suspensions with a given mean\nStokes. \n\n"}
{"id": "nlin/0602017", "contents": "Title: Conformal invariance in two-dimensional turbulence Abstract: Simplicity of fundamental physical laws manifests itself in fundamental\nsymmetries. While systems with an infinity of strongly interacting degrees of\nfreedom (in particle physics and critical phenomena) are hard to describe, they\noften demonstrate symmetries, in particular scale invariance. In two dimensions\n(2d) locality often promotes scale invariance to a wider class of conformal\ntransformations which allow for nonuniform re-scaling. Conformal invariance\nallows a thorough classification of universality classes of critical phenomena\nin 2d. Is there conformal invariance in 2d turbulence, a paradigmatic example\nof strongly-interacting non-equilibrium system? Here, using numerical\nexperiment, we show that some features of 2d inverse turbulent cascade display\nconformal invariance. We observe that the statistics of vorticity clusters is\nremarkably close to that of critical percolation, one of the simplest\nuniversality classes of critical phenomena. These results represent a new step\nin the unification of 2d physics within the framework of conformal symmetry. \n\n"}
{"id": "nlin/0602062", "contents": "Title: Fractional Liouville and BBGKI Equations Abstract: We consider the fractional generalizations of Liouville equation. The\nnormalization condition, phase volume, and average values are generalized for\nfractional case.The interpretation of fractional analog of phase space as a\nspace with fractal dimension and as a space with fractional measure are\ndiscussed. The fractional analogs of the Hamiltonian systems are considered as\na special class of non-Hamiltonian systems. The fractional generalization of\nthe reduced distribution functions are suggested. The fractional analogs of the\nBBGKI equations are derived from the fractional Liouville equation. \n\n"}
{"id": "nlin/0603031", "contents": "Title: Scaling, renormalization and statistical conservation laws in the\n  Kraichnan model of turbulent advection Abstract: We present a systematic way to compute the scaling exponents of the structure\nfunctions of the Kraichnan model of turbulent advection in a series of powers\nof $\\xi$, adimensional coupling constant measuring the degree of roughness of\nthe advecting velocity field. We also investigate the relation between standard\nand renormalization group improved perturbation theory. The aim is to shed\nlight on the relation between renormalization group methods and the statistical\nconservation laws of the Kraichnan model, also known as zero modes. \n\n"}
{"id": "nlin/0605040", "contents": "Title: Sling effect in collisions of water droplets in turbulent clouds Abstract: We describe and evaluate the contribution of sling effect into the collision\nrate of the same-size water droplets in turbulent clouds. We show that already\nfor Stokes numbers exceeding 0.2 the sling effect gives a contribution\ncomparable to Saffman-Turner contribution, which may explain why the latter\nconsistently underestimates collision rate (even with the account of\npreferential concentration). \n\n"}
{"id": "nlin/0609025", "contents": "Title: A Borel transform method for locating singularities of Taylor and\n  Fourier series Abstract: Given a Taylor series with a finite radius of convergence, its Borel\ntransform defines an entire function. A theorem of P\\'olya relates the large d\nistance behavior of the Borel transform in different directions to\nsingularities of the original function. With the help of the new asymptotic\ninterpolation method of van der Hoeven, we show that from the knowledge of a\nlarge number of Taylor coefficients we can identify precisely the location of\nsuch singularities, as well as their type when they are isolated. There is no\nrisk of getting artefacts with this method, which also gives us access to some\nof the singularities beyond the convergence disk. The method can also be\napplied to Fourier series of analytic periodic functions and is here tested on\nvarious instances constructed from solutions to the Burgers equation. Large\nprecision on scaling exponents (up to twenty accurate digits) can be achieved. \n\n"}
{"id": "nlin/0610057", "contents": "Title: Synchronization processes in complex networks Abstract: We present an extended analysis, based on the dynamics towards\nsynchronization of a system of coupled oscillators, of the hierarchy of\ncommunities in complex networks. In the synchronization process, different\nstructures corresponding to well defined communities of nodes appear in a\nhierarchical way. The analysis also provides a useful connection between\nsynchronization dynamics, complex networks topology and spectral graph\nanalysis. \n\n"}
{"id": "nlin/0611044", "contents": "Title: Why the Maxwellian Distribution is the Attractive Fixed Point of the\n  Boltzmann Equation Abstract: The origin of the Boltzmann factor is revisited. An alternative derivation\nfrom the microcanonical picture is given. The Maxwellian distribution in a\nmono-dimensional ideal gas is obtained by following this insight. Other\npossible applications, as for instance the obtaining of the wealth distribution\nin the human society, are suggested in the remarks. \n\n"}
{"id": "nlin/0612001", "contents": "Title: Clustering of matter in waves and currents Abstract: The growth rate of small-scale density inhomogeneities (the entropy\nproduction rate) is given by the sum of the Lyapunov exponents in a random\nflow. We derive an analytic formula for the rate in a flow of weakly\ninteracting waves and show that in most cases it is zero up to the fourth order\nin the wave amplitude. We then derive an analytic formula for the rate in a\nflow of potential waves and solenoidal currents. Estimates of the rate and the\nfractal dimension of the density distribution show that the interplay between\nwaves and currents is a realistic mechanism for providing patchiness of\npollutant distribution on the ocean surface. \n\n"}
{"id": "nlin/0612052", "contents": "Title: Growing condensate in two-dimensional turbulence Abstract: We report a numerical study, supplemented by phenomenological explanations,\nof ``energy condensation'' in forced 2D turbulence in a biperiodic box.\nCondensation is a finite size effect which occurs after the standard inverse\ncascade reaches the size of the system. It leads to emergence of a coherent\nvortex dipole. We show that the time growth of the dipole is self-similar, and\nit contains most of the injected energy, thus resulting in an energy spectrum\nwhich is markedly steeper than the standard $k^{-5/3}$ one. Once the coherent\ncomponent is subtracted, however, the remaining fluctuations have a spectrum\nclose to $k^{-1}$. The fluctuations decay slowly as the coherent part grows. \n\n"}
{"id": "nlin/0703014", "contents": "Title: Classical nonlinear response of a chaotic system: Langevin dynamics and\n  spectral decomposition Abstract: We consider the classical response of a strongly chaotic Hamiltonian system.\nThe spectrum of such a system consists of discrete complex Ruelle-Pollicott\n(RP) resonances which manifest themselves in the behavior of the correlation\nand response functions. We interpret the RP resonances as the eigenstates and\neigenvalues of the Fokker-Planck operator obtained by adding an infinitesimal\nnoise term to the first-order Liouville operator. We demonstrate how the\ndeterministic expression for the linear response is reproduced in the limit of\nvanishing noise. For the second-order response we establish an equivalence of\nthe spectral decomposition with infinitesimal noise and the long-time\nasymptotic expansion for the deterministic case. \n\n"}
{"id": "nlin/0703054", "contents": "Title: Fluid-particle separation in a random flow described by the telegraph\n  model Abstract: We study the statistics of the relative separation between two fluid\nparticles in a spatially smooth and temporally random flow. The Lagrangian\nstrain is modelled by a telegraph noise, which is a stationary random Markov\nprocess that can only take two values with known transition probabilities. The\nsimplicity of the model enables us to write closed equations for the\ninter-particle distance in the presence of a finite-correlated noise. In 1D, we\nare able to find analytically the long-time growth rates of the distance\nmoments and the senior Lyapunov exponent, which consistently turns out to be\nnegative. We also find the exact expression for the Cram\\'er function and show\nthat it satisfies the fluctuation relation (for the probability of positive and\nnegative entropy production) despite the time irreversibility of the strain\nstatistics. For the 2D incompressible isotropic case, we obtain the Lyapunov\nexponent (positive) and the asymptotic growth rates of the moments in two\nopposite limits of fast and slow strain. The quasi-deterministic limit (of slow\nstrain) turns out to be singular, while a perfect agreement is found with the\nalready-known delta-correlated case. \n\n"}
{"id": "physics/0004009", "contents": "Title: Coupled Two-Way Clustering Analysis of Gene Microarray Data Abstract: We present a novel coupled two-way clustering approach to gene microarray\ndata analysis. The main idea is to identify subsets of the genes and samples,\nsuch that when one of these is used to cluster the other, stable and\nsignificant partitions emerge. The search for such subsets is a computationally\ncomplex task: we present an algorithm, based on iterative clustering, which\nperforms such a search. This analysis is especially suitable for gene\nmicroarray data, where the contributions of a variety of biological mechanisms\nto the gene expression levels are entangled in a large body of experimental\ndata. The method was applied to two gene microarray data sets, on colon cancer\nand leukemia. By identifying relevant subsets of the data and focusing on them\nwe were able to discover partitions and correlations that were masked and\nhidden when the full dataset was used in the analysis. Some of these partitions\nhave clear biological interpretation; others can serve to identify possible\ndirections for future research. \n\n"}
{"id": "physics/0004052", "contents": "Title: A Comment on the Roe-Woodroofe Construction of Poisson Confidence\n  Intervals Abstract: We consider the Roe-Woodroofe construction of confidence intervals for the\ncase of a Poisson distributed variate where the mean is the sum of a known\nbackground and an unknown non-negative signal. We point out that the intervals\ndo not have coverage in the usual sense but can be made to have such with a\nmodification that does not affect the believability and other desirable\nfeatures of this attractive construction. A similar modification can be used to\nprovide coverage to the construction recently proposed by Cousins for the\nGaussian-with-boundary problem. \n\n"}
{"id": "physics/0009064", "contents": "Title: Confidence intervals for the parameter of Poisson distribution in\n  presence of background Abstract: A results of numerical procedure for construction of confidence intervals for\nparameter of Poisson distribution for signal in the presence of background\nwhich has Poisson distribution with known value of parameter are presented. It\nis shown that the described procedure has both Bayesian and frequentist\ninterpretations. \n\n"}
{"id": "physics/0103076", "contents": "Title: Complexity Through Nonextensivity Abstract: The problem of defining and studying complexity of a time series has\ninterested people for years. In the context of dynamical systems, Grassberger\nhas suggested that a slow approach of the entropy to its extensive asymptotic\nlimit is a sign of complexity. We investigate this idea further by information\ntheoretic and statistical mechanics techniques and show that these arguments\ncan be made precise, and that they generalize many previous approaches to\ncomplexity, in particular unifying ideas from the physics literature with ideas\nfrom learning and coding theory; there are even connections of this statistical\napproach to algorithmic or Kolmogorov complexity. Moreover, a set of simple\naxioms similar to those used by Shannon in his development of information\ntheory allows us to prove that the divergent part of the subextensive component\nof the entropy is a unique complexity measure. We classify time series by their\ncomplexities and demonstrate that beyond the `logarithmic' complexity classes\nwidely anticipated in the literature there are qualitatively more complex,\n`power--law' classes which deserve more attention. \n\n"}
{"id": "physics/0108025", "contents": "Title: Entropy and inference, revisited Abstract: We study properties of popular near-uniform (Dirichlet) priors for learning\nundersampled probability distributions on discrete nonmetric spaces and show\nthat they lead to disastrous results. However, an Occam-style phase space\nargument expands the priors into their infinite mixture and resolves most of\nthe observed problems. This leads to a surprisingly good estimator of entropies\nof discrete distributions. \n\n"}
{"id": "physics/0111199", "contents": "Title: DNA hybridization to mismatched templates: a chip study Abstract: High-density oligonucleotide arrays are among the most rapidly expanding\ntechnologies in biology today. In the {\\sl GeneChip} system, the reconstruction\nof the target concentration depends upon the differential signal generated from\nhybridizing the target RNA to two nearly identical templates: a perfect match\n(PM) and a single mismatch (MM) probe. It has been observed that a large\nfraction of MM probes repeatably bind targets better than the PMs, against the\nusual expectation from sequence-specific hybridization; this is difficult to\ninterpret in terms of the underlying physics. We examine this problem via a\nstatistical analysis of a large set of microarray experiments. We classify the\nprobes according to their signal to noise ($S/N$) ratio, defined as the\neccentricity of a (PM, MM) pair's `trajectory' across many experiments. Of\nthose probes having large $S/N$ ($>3$) only a fraction behave consistently with\nthe commonly assumed hybridization model. Our results imply that the physics of\nDNA hybridization in microarrays is more complex than expected, and they\nsuggest new ways of constructing estimators for the target RNA concentration. \n\n"}
{"id": "physics/0201016", "contents": "Title: Entropic Priors for Discrete Probabilistic Networks and for Mixtures of\n  Gaussians Models Abstract: The ongoing unprecedented exponential explosion of available computing power,\nhas radically transformed the methods of statistical inference. What used to be\na small minority of statisticians advocating for the use of priors and a strict\nadherence to bayes theorem, it is now becoming the norm across disciplines. The\nevolutionary direction is now clear. The trend is towards more realistic,\nflexible and complex likelihoods characterized by an ever increasing number of\nparameters. This makes the old question of: What should the prior be? to\nacquire a new central importance in the modern bayesian theory of inference.\nEntropic priors provide one answer to the problem of prior selection. The\ngeneral definition of an entropic prior has existed since 1988, but it was not\nuntil 1998 that it was found that they provide a new notion of complete\nignorance. This paper re-introduces the family of entropic priors as minimizers\nof mutual information between the data and the parameters, as in\n[rodriguez98b], but with a small change and a correction. The general formalism\nis then applied to two large classes of models: Discrete probabilistic networks\nand univariate finite mixtures of gaussians. It is also shown how to perform\ninference by efficiently sampling the corresponding posterior distributions. \n\n"}
{"id": "physics/0205053", "contents": "Title: A Quantum Approach to Stock Price Fluctuations Abstract: A simple quantum model explains the Levy-unstable distributions for\nindividual stock returns observed by ref.[1]. The probability density function\nof the returns is written as the squared modulus of an amplitude. For short\ntime intervals this amplitude is proportional to a Cauchy-distribution and\nsatisfies the Schroedinger equation with a non-hermitian Hamiltonian. The\nobserved power law tails of the return fluctuations imply that the \"decay\nrate\", $\\gamma(q)$ asymptotically is proportional to $|q|$, for large $|q|$.\nThe wave number, the Fourier-conjugate variable to the return, is interpreted\nas a quantitative measure of \"market sentiment\". On a time scale of less than a\nfew weeks, the distribution of returns in this quantum model is shape stable\nand scales. The model quantitatively reproduces the observed cumulative\ndistribution for the short-term normalized returns over 7 orders of magnitude\nwithout adjustable parameters. The return fluctuations over large time periods\nultimately become Gaussian if $\\gamma(q\\sim 0)\\propto q^2$. The ansatz\n$\\gamma(q)=b_T\\sqrt{m^2+q^2}$ is found to describe the positive part of the\nobserved historic probability of normalized returns for time periods between\nT=5 min and $T\\sim 4$ years over more than 4 orders of magnitude in terms of\none adjustable parameter $s_T=m b_T\\propto T$. The Sharpe ratio of a stock in\nthis model has a finite limit as the investment horizon $T\\to 0$. Implications\nfor short-term investments are discussed. \n\n"}
{"id": "physics/0211010", "contents": "Title: Citation Networks in High Energy Physics Abstract: The citation network constituted by the SPIRES data base is investigated\nempirically. The probability that a given paper in the SPIRES data base has $k$\ncitations is well described by simple power laws, $P(k) \\propto k^{-\\alpha}$,\nwith $\\alpha \\approx 1.2$ for $k$ less than 50 citations and $\\alpha \\approx\n2.3$ for 50 or more citations. Two models are presented that both represent the\ndata well, one which generates power laws and one which generates a stretched\nexponential. It is not possible to discriminate between these models on the\npresent empirical basis. A consideration of citation distribution by subfield\nshows that the citation patterns of high energy physics form a remarkably\nhomogeneous network. Further, we utilize the knowledge of the citation\ndistributions to demonstrate the extreme improbability that the citation\nrecords of selected individuals and institutions have been obtained by a random\ndraw on the resulting distribution. \n\n"}
{"id": "physics/0212085", "contents": "Title: Fundamental Research and Developing Countries Abstract: In the first part of this report, I discuss the sociological role of\nfundamental research in Developing Countries (DC) and how to realize this\nprogram. In the second part, I give a brief and elementary introduction to the\nfield of high-energy physics (HEP), accessible to a large audience not\nnecessary physicists. The aim of this report is to make politicians and\nfinancial backers aware on the long-term usefulness of fundamental research in\nDC and on the possible globalisation of HEP and, in general, of science. \n\n"}
{"id": "physics/0212114", "contents": "Title: An information theoretic approach to the functional classification of\n  neurons Abstract: A population of neurons typically exhibits a broad diversity of responses to\nsensory inputs. The intuitive notion of functional classification is that cells\ncan be clustered so that most of the diversity is captured in the identity of\nthe clusters rather than by individuals within clusters. We show how this\nintuition can be made precise using information theory, without any need to\nintroduce a metric on the space of stimuli or responses. Applied to the retinal\nganglion cells of the salamander, this approach recovers classical results, but\nalso provides clear evidence for subclasses beyond those identified previously.\nFurther, we find that each of the ganglion cells is functionally unique, and\nthat even within the same subclass only a few spikes are needed to reliably\ndistinguish between cells. \n\n"}
{"id": "physics/0303015", "contents": "Title: Periodic and Quasi-Periodic Compensation Strategies of Extreme Outages\n  caused by Polarization Mode Dispersion and Amplifier Noise Abstract: Effect of birefringent disorder on the Bit Error Rate (BER) in an optical\nfiber telecommunication system subject to amplifier noise may lead to extreme\noutages, related to anomalously large values of BER. We analyze the Probability\nDistribution Function (PDF) of BER for various strategies of Polarization Mode\nDispersion (PMD) compensation. A compensation method is proposed that is\ncapable of more efficient extreme outages suppression, which leads to\nsubstantial improvement of the fiber system performance. \n\n"}
{"id": "physics/0307131", "contents": "Title: Information Metric on Instanton Moduli Spaces in Nonlinear Sigma Models Abstract: We study the information metric on instanton moduli spaces in two-dimensional\nnonlinear sigma models. In the CP^1 model, the information metric on the moduli\nspace of one instanton with the topological charge Q=k which is any positive\ninteger is a three-dimensional hyperbolic metric, which corresponds to\nEuclidean anti--de Sitter space-time metric in three dimensions, and the\noverall scale factor of the information metric is (4k^2)/3; this means that the\nsectional curvature is -3/(4k^2). We also calculate the information metric in\nthe CP^2 model. \n\n"}
{"id": "physics/0401143", "contents": "Title: Volcanic forcing improves Atmosphere-Ocean Coupled General Circulation\n  Model scaling performance Abstract: Recent Atmosphere-Ocean Coupled General Circulation Model (AOGCM) simulations\nof the twentieth century climate, which account for anthropogenic and natural\nforcings, make it possible to study the origin of long-term temperature\ncorrelations found in the observed records. We study ensemble experiments\nperformed with the NCAR PCM for 10 different historical scenarios, including no\nforcings, greenhouse gas, sulfate aerosol, ozone, solar, volcanic forcing and\nvarious combinations, such as it natural, anthropogenic and all forcings. We\ncompare the scaling exponents characterizing the long-term correlations of the\nobserved and simulated model data for 16 representative land stations and 16\nsites in the Atlantic Ocean for these scenarios. We find that inclusion of\nvolcanic forcing in the AOGCM considerably improves the PCM scaling behavior.\nThe scenarios containing volcanic forcing are able to reproduce quite well the\nobserved scaling exponents for the land with exponents around 0.65 independent\nof the station distance from the ocean. For the Atlantic Ocean, scenarios with\nthe volcanic forcing slightly underestimate the observed persistence exhibiting\nan average exponent 0.74 instead of 0.85 for reconstructed data. \n\n"}
{"id": "physics/0402039", "contents": "Title: Pattern Recognition and Event Reconstruction in Particle Physics\n  Experiments Abstract: This report reviews methods of pattern recognition and event reconstruction\nused in modern high energy physics experiments. After a brief introduction into\ngeneral concepts of particle detectors and statistical evaluation, different\napproaches in global and local methods of track pattern recognition are\nreviewed with their typical strengths and shortcomings. The emphasis is then\nmoved to methods which estimate the particle properties from the signals which\npattern recognition has associated. Finally, the global reconstruction of the\nevent is briefly addressed. \n\n"}
{"id": "physics/0403069", "contents": "Title: Experimental test of the probability density function of true value of\n  Poisson distribution parameter by single observation of number of events Abstract: The empirical probability density function for the conditional distribution\nof the true value of Poisson distribution parameter on one measurement is\nconstructed by computer experiment. The analysis of the obtained distributions\nconfirms that these distributions are gamma-distributions. \n\n"}
{"id": "physics/0404021", "contents": "Title: Increment definitions for scale dependent analysis of stochastic data Abstract: It is common for scale-dependent analysis of stochastic data to use the\nincrement $\\Delta(t,r) = \\xi(t+r) - \\xi(t)$ of a data set $\\xi(t)$ as a\nstochastic measure, where $r$ denotes the scale. For joint statistics of\n$\\Delta(t,r)$ and $\\Delta(t,r')$ the question how to nest the increments on\ndifferent scales $r,r'$ is investigated. Here we show that in some cases\nspurious correlations between scales can be introduced by the common\nleft-justified definition. The consequences for a Markov process are discussed.\nThese spurious correlations can be avoided by an appropriate nesting of\nincrements. We demonstrate this effect for different data sets and show how it\ncan be detected and quantified. The problem allows to propose a unique method\nto distinguish between experimental data generated by a noiselike or a\nLangevin-like random-walk process, respectively. \n\n"}
{"id": "physics/0406091", "contents": "Title: Innovation flow through social networks: Productivity distribution Abstract: A detailed empirical analysis of the productivity of non financial firms\nacross several countries and years shows that productivity follows a\nnon-Gaussian distribution with power law tails. We demonstrate that these\nempirical findings can be interpreted as consequence of a mechanism of\nexchanges in a social network where firms improve their productivity by direct\ninnovation or/and by imitation of other firm's technological and organizational\nsolutions. The type of network-connectivity determines how fast and how\nefficiently information can diffuse and how quickly innovation will permeate or\nbehaviors will be imitated. From a model for innovation flow through a complex\nnetwork we obtain that the expectation values of the productivity level are\nproportional to the connectivity of the network of links between firms. The\ncomparison with the empirical distributions reveals that such a network must be\nof a scale-free type with a power-law degree distribution in the large\nconnectivity range. \n\n"}
{"id": "physics/0408022", "contents": "Title: Cat's Dilemma - transitivity vs. intransitivity Abstract: We study a simple example of a sequential game illustrating problems\nconnected with making rational decisions that are universal for social\nsciences. The set of chooser's optimal decisions that manifest his preferences\nin case of a constant strategy of the adversary (the offering player), is\ninvestigated. It turns out that the order imposed by the player's rational\npreferences can be intransitive. The presented quantitative results imply a\nrevision of the \"common sense\" opinions stating that preferences showing\nintransitivity are paradoxical and undesired. \n\n"}
{"id": "physics/0408039", "contents": "Title: On Bayesian Treatment of Systematic Uncertainties in Confidence Interval\n  Calculation Abstract: In high energy physics, a widely used method to treat systematic\nuncertainties in confidence interval calculations is based on combining a\nfrequentist construction of confidence belts with a Bayesian treatment of\nsystematic uncertainties. In this note we present a study of the coverage of\nthis method for the standard Likelihood Ratio (aka Feldman & Cousins)\nconstruction for a Poisson process with known background and Gaussian or\nlog-Normal distributed uncertainties in the background or signal efficiency.\nFor uncertainties in the signal efficiency of upto 40 % we find over-coverage\non the level of 2 to 4 % depending on the size of uncertainties and the region\nin signal space. Uncertainties in the background generally have smaller effect\non the coverage. A considerable smoothing of the coverage curves is observed. A\nsoftware package is presented which allows fast calculation of the confidence\nintervals for a variety of assumptions on shape and size of systematic\nuncertainties for different nuisance parameters. The calculation speed allows\nexperimenters to test the coverage for their specific conditions. \n\n"}
{"id": "physics/0409129", "contents": "Title: Interval estimation in the presence of nuisance parameters. 1. Bayesian\n  approach Abstract: We address the common problem of calculating intervals in the presence of\nsystematic uncertainties. We aim to investigate several approaches, but here\ndescribe just a Bayesian technique for setting upper limits. The particular\nexample we study is that of inferring the rate of a Poisson process when there\nare uncertainties on the acceptance and the background. Limit calculating\nsoftware associated with this work is available in the form of C functions. \n\n"}
{"id": "physics/0410274", "contents": "Title: Recurrence intervals between earthquakes strongly depend on history Abstract: We study the statistics of the recurrence times between earthquakes above a\ncertain magnitude M$ in California. We find that the distribution of the\nrecurrence times strongly depends on the previous recurrence time $\\tau_0$. As\na consequence, the conditional mean recurrence time $\\hat \\tau(\\tau_0)$ between\ntwo events increases monotonically with $\\tau_0$. For $\\tau_0$ well below the\naverage recurrence time $\\ov{\\tau}, \\hat\\tau(\\tau_0)$ is smaller than\n$\\ov{\\tau}$, while for $\\tau_0>\\ov{\\tau}$, $\\hat\\tau(\\tau_0)$ is greater than\n$\\ov{\\tau}$. Also the mean residual time until the next earthquake does not\ndepend only on the elapsed time, but also strongly on $\\tau_0$. The larger\n$\\tau_0$ is, the larger is the mean residual time. The above features should be\ntaken into account in any earthquake prognosis. \n\n"}
{"id": "physics/0411151", "contents": "Title: Observations of three slow glitches in the spin rate of the pulsar\n  B1822-09 Abstract: Three slow glitches in the rotation rate of the pulsar B1822-09 were revealed\nover the 1995-2004 interval. The slow glitches observed are characterized by a\ngradual increase in the rotation frequency with a long timescale of several\nmonths, accompanied by a rapid decrease in the magnitude of the frequency first\nderivative by 1-2 per cent of the initial value and subsequent exponential\nincrease back to its initial value on the same timescale. The cumulative\nfractional increase in the pulsar rotation rate for the three glitches amounts\nto Delta_nu/nu ~ 7 10^{-8}. \n\n"}
{"id": "physics/0412026", "contents": "Title: Endogenous versus Exogenous Origins of Crises Abstract: Are large biological extinctions such as the Cretaceous/Tertiary KT boundary\ndue to a meteorite, extreme volcanic activity or self-organized critical\nextinction cascades? Are commercial successes due to a progressive reputation\ncascade or the result of a well orchestrated advertisement? Determining the\nchain of causality for extreme events in complex systems requires disentangling\ninterwoven exogenous and endogenous contributions with either no clear or too\nmany signatures. Here, I review several efforts carried out with collaborators,\nwhich suggest a general strategy for understanding the organization of several\ncomplex systems under the dual effect of endogenous and exogenous fluctuations.\nThe studied examples are: Internet download shocks, book sale shocks, social\nshocks, financial volatility shocks, and financial crashes. Simple models are\noffered to quantitatively relate the endogenous organization to the exogenous\nresponse of the system. Suggestions for applications of these ideas to many\nother systems are offered. \n\n"}
{"id": "physics/0412043", "contents": "Title: Power law distribution of seismic rates: theory and data Abstract: We report an empirical determination of the probability density functions\nP(r) of the number r of earthquakes in finite space-time windows for the\nCalifornia catalog, over fixed spatial boxes 5 x 5 km^2 and time intervals dt\n=1, 10, 100 and 1000 days. We find a stable power law tail P(r) ~ 1/r^{1+mu}\nwith exponent mu \\approx 1.6 for all time intervals. These observations are\nexplained by a simple stochastic branching process previously studied by many\nauthors, the ETAS (epidemic-type aftershock sequence) model which assumes that\neach earthquake can trigger other earthquakes (``aftershocks''). An aftershock\nsequence results in this model from the cascade of aftershocks of each past\nearthquake. We develop the full theory in terms of generating functions for\ndescribing the space-time organization of earthquake sequences and develop\nseveral approximations to solve the equations. The calibration of the theory to\nthe empirical observations shows that it is essential to augment the ETAS model\nby taking account of the pre-existing frozen heterogeneity of spontaneous\nearthquake sources. This seems natural in view of the complex multi-scale\nnature of fault networks, on which earthquakes nucleate. Our extended theory is\nable to account for the empirical observation satisfactorily. In particular,\nthe adjustable parameters are determined by fitting the largest time window\n$dt=1000$ days and are then used as frozen in the formulas for other time\nscales, with very good agreement with the empirical data. \n\n"}
{"id": "physics/0502061", "contents": "Title: Experimental verification of a one-parameter scaling law for the quantum\n  and \"classical\" resonances of the atom-optics kicked rotor Abstract: We present experimental measurements of the mean energy in the vicinity of\nthe first and second quantum resonances of the atom optics kicked rotor for a\nnumber of different experimental parameters. Our data is rescaled and compared\nwith the one parameter epsilon--classical scaling function developed to\ndescribe the quantum resonance peaks. Additionally, experimental data is\npresented for the ``classical'' resonance which occurs in the limit as the\nkicking period goes to zero. This resonance is found to be analogous to the\nquantum resonances, and a similar one-parameter classical scaling function is\nderived, and found to match our experimental results. The width of the quantum\nand classical resonance peaks is compared, and their Sub-Fourier nature\nexamined. \n\n"}
{"id": "physics/0503168", "contents": "Title: Cyclic Topology in Complex Networks Abstract: We propose a cyclic coefficient $R$ which represents the cyclic\ncharacteristics of complex networks. If the network forms a perfect tree-like\nstructure then $R$ becomes zero. The larger value of $R$ represents that the\nnetwork is more cyclic. We measure the cyclic coefficients and the\ndistributions of the local cyclic coefficient for both various real networks\nand the representative network models and characterize the cyclic structures of\nthem. \n\n"}
{"id": "physics/0503177", "contents": "Title: Shareholding Networks in Japan Abstract: The Japanese shareholding network existing at the end of March 2002 is\nstudied empirically. The network is constructed from 2,303 listed companies and\n53 non-listed financial institutions. We consider this network as a directed\ngraph by drawing edges from shareholders to stock corporations. The lengths of\nthe shareholder lists vary with the companies, and the most comprehensive lists\ncontain the top 30 shareholders. Consequently, the distribution of incoming\nedges has an upper bound, while that of outgoing edges has no bound. The\ndistribution of outgoing degrees is well explained by the power law function\nwith an exponential tail. The exponent in the power law range is gamma=1.7. To\nunderstand these features from the viewpoint of a company's growth, we consider\nthe correlations between the outgoing degree and the company's age, profit, and\ntotal assets. \n\n"}
{"id": "physics/0504059", "contents": "Title: Improved spectral algorithm for the detection of network communities Abstract: We review and improve a recently introduced method for the detection of\ncommunities in complex networks. This method combines spectral properties of\nsome matrices encoding the network topology, with well known hierarchical\nclustering techniques, and the use of the modularity parameter to quantify the\ngoodness of any possible community subdivision. This provides one of the best\navailable methods for the detection of community structures in complex systems. \n\n"}
{"id": "physics/0504149", "contents": "Title: Two-Scale Kirchhoff Theory: Comparison of Experimental Observations With\n  Theoretical Prediction Abstract: We introduce a non-perturbative two scale Kirchhoff theory, in the context of\nlight scattering by a rough surface. This is a two scale theory which considers\nthe roughness both in the wavelength scale (small scale) and in the scales much\nlarger than the wavelength of the incident light (large scale). The theory can\nprecisely explain the small peaks which appear at certain scattering angles.\nThese peaks can not be explained by one scale theories. The theory was assessed\nby calculating the light scattering profiles using the Atomic Force Microscope\n(AFM) images, as well as surface profilometer scans of a rough surface, and\ncomparing the results with experiments. The theory is in good agreement with\nthe experimental results. \n\n"}
{"id": "physics/0505034", "contents": "Title: No need to blur the picture Abstract: A formalism specifying efficient, \"emergent\" descriptions of experimental\nsystems is developed. It does not depend on an a priori assumption of limited\navailable data. \n\n"}
{"id": "physics/0505079", "contents": "Title: Fundamental Factors versus Herding in the 2000-2005 US Stock Market and\n  Prediction Abstract: We present a general methodology to incorporate fundamental economic factors\nto our previous theory of herding to describe bubbles and antibubbles. We start\nfrom the strong form of Rational Expectation and derive the general method to\nincorporate factors in addition to the log-periodic power law (LPPL) signature\nof herding developed in ours and others' works. These factors include interest\nrate, interest spread, historical volatility, implied volatility and exchange\nrates. Standard statistical AIC and Wilks tests allow us to compare the\nexplanatory power of the different proposed factor models. We find that the\nhistorical volatility played the key role before August of 2002. Around October\n2002, the interest rate dominated. In the first six months of 2003, the foreign\nexchange rate became the key factor. Since the end of 2003, all factors have\nplayed an increasingly large role. However, the most surprising result is that\nthe best model is the second-order LPPL without any factor. We thus present a\nscenario for the future evolution of the US stock market based on the\nextrapolation of the fit of the second-order LPPL formula, which suggests that\nherding is still the dominating force and that the unraveling of the US stock\nmarket antibubble since 2000 is still qualitatively similar to (but\nquantitatively different from) the Japanese Nikkei case after 1990. \n\n"}
{"id": "physics/0506126", "contents": "Title: Exact results for the Barabasi model of human dynamics Abstract: Human activity patterns display a bursty dynamics, with interevent times\nfollowing a heavy tailed distribution. This behavior has been recently shown to\nbe rooted in the fact that humans assign their active tasks different\npriorities, a process that can be modeled as a priority queueing system [A.-L.\nBarabasi, Nature 435, 207 (2005)]. In this work we obtain exact results for the\nBarabasi model with two tasks, calculating the priority and waiting time\ndistribution of active tasks. We demonstrate that the model has a singular\nbehavior in the extremal dynamics limit, when the highest priority task is\nselected first. We find that independently of the selection protocol, the\naverage waiting time is smaller or equal to the number of active tasks, and\ndiscuss the asymptotic behavior of the waiting time distribution. These results\nhave important implications for understanding complex systems with extremal\ndynamics. \n\n"}
{"id": "physics/0507139", "contents": "Title: Antimatter underestimated Abstract: We warn of the potential nuclear proliferation's consequences of military\napplications of nano- or microgram amounts of antimatter, such as triggering of\nhigh-yield thermonuclear explosions, laser pumping, compact sources of energy,\ndirected-energy beams, and portable sources of muons. \n\n"}
{"id": "physics/0508164", "contents": "Title: Correlation Networks Among Currencies Abstract: By analyzing the foreign exchange market data of various currencies, we\nderive a hierarchical taxonomy of currencies constructing minimal-spanning\ntrees. Clustered structure of the currencies and the key currency in each\ncluster are found. The clusters match nicely with the geographical regions of\ncorresponding countries in the world such as Asia or East Europe, the key\ncurrencies are generally given by major economic countries as expected. \n\n"}
{"id": "physics/0508190", "contents": "Title: Maximum-likelihood estimation prevents unphysical Mueller matrices Abstract: We show that the method of maximum-likelihood estimation, recently introduced\nin the context of quantum process tomography, can be applied to the\ndetermination of Mueller matrices characterizing the polarization properties of\nclassical optical systems. Contrary to linear reconstruction algorithms, the\nproposed method yields physically acceptable Mueller matrices even in presence\nof uncontrolled experimental errors. We illustrate the method on the case of an\nunphysical measured Mueller matrix taken from the literature. \n\n"}
{"id": "physics/0509045", "contents": "Title: Wealth distribution and Pareto's law in the Hungarian medieval society Abstract: The distribution of wealth in the Hungarian medieval aristocratic society is\nreported and studied. The number of serf families belonging to a noble is taken\nas a measure of the corresponding wealth. Our results reveal the power-law\nnature of this distribution function, confirming the validity of the Pareto law\nfor such a society. The obtained Pareto index $\\alpha=0.92$ is however smaller\nthan the values currently reported in the literature. We argue that the value\nclose to 1, of the Pareto index is a consequence of the absence of a relevant\neconomic life in the targeted society, in agreement with the prediction of\nexisting wealth distribution models for the idealized case of independently\nacting agents. Models developed to explain city populations may also be adapted\nto justify our results. \n\n"}
{"id": "physics/0509092", "contents": "Title: Time-evolving distribution of time lags between commercial airline\n  disasters Abstract: We have studied the time lags between commercial line airplane disasters and\ntheir occurrence frequency till 2002, as obtained from a freely available\nwebsite. We show that the time lags seem to be well described by Poisson random\nevents, where the average events rate is itself a function of time, i.e.\ntime-dependent Poisson events. This is likely due to the unsteady growth of the\nindustry. The time lag distribution is compared with a truncated Tsallis\ndistribution, thereby showing that the ''phenomenon'' has similarities with a\nBrownian particle with time dependent mass. We distinguish between ''other\ncauses'' (or natural causes) and ''terrorism acts\", the latter amounts to about\n5 percents, but we find no drastic difference nor impact due to the latter on\nthe overall distribution. \n\n"}
{"id": "physics/0509095", "contents": "Title: Rescue Model for the Bystanders' Intervention in Emergencies Abstract: To investigate an effect of social interaction on the bystanders'\nintervention in emergency situations we introduce a rescue model which includes\nthe effects of the victim's acquaintance with bystanders and those among\nbystanders. This model reproduces the surprising experimental result that the\nhelping rate tends to decrease although the number of bystanders $k$ increases.\nThe model also shows that given the coupling effect among bystanders, for a\ncertain range of small $k$ the helping rate increases according to $k$ and that\ncoupling effect plays both positive and negative roles in emergencies. Finally\nwe find a broad range of coupling strength to maximize the helping rate. \n\n"}
{"id": "physics/0509172", "contents": "Title: Role of Selective Interaction in Wealth Distribution Abstract: In our simplified description `wealth' is money ($m$). A kinetic theory of\ngas like model of money is investigated where two agents interact (trade)\nselectively and exchange some amount of money between them so that sum of their\nmoney is unchanged and thus total money of all the agents remains conserved.\nThe probability distributions of individual money ($P(m)$ vs. $m$) is seen to\nbe influenced by certain ways of selective interactions. The distributions\nshift away from Boltzmann-Gibbs like exponential distribution and in some cases\ndistributions emerge with power law tails known as Pareto's law ($P(m) \\propto\nm^{-(1+\\alpha)}$). Power law is also observed in some other closely related\nconserved and discrete models. A discussion is provided with numerical support\nto have a dig into the emergence of power laws in such models. \n\n"}
{"id": "physics/0509257", "contents": "Title: Small scale behavior of financial data Abstract: A new approach is presented to describe the change in the statistics of the\nlog return distribution of financial data as a function of the timescale. To\nthis purpose a measure is introduced, which quantifies the distance of a\nconsidered distribution to a reference distribution. The existence of a small\ntimescale regime is demonstrated, which exhibits different properties compared\nto the normal timescale regime. This regime seems to be universal for\nindividual stocks. It is shown that the existence of this small timescale\nregime is not dependent on the special choice of the distance measure or the\nreference distribution. These findings have important implications for risk\nanalysis, in particular for the probability of extreme events. \n\n"}
{"id": "physics/0510047", "contents": "Title: Time series of stock price and of two fractal overlap: Anticipating\n  market crashes? Abstract: We find prominent similarities in the features of the time series for the\noverlap of two Cantor sets when one set moves with uniform relative velocity\nover the other and time series of stock prices. An anticipation method for some\nof the crashes have been proposed here, based on these observations. \n\n"}
{"id": "physics/0510162", "contents": "Title: Structural Properties of Planar Graphs of Urban Street Patterns Abstract: Recent theoretical and empirical studies have focused on the structural\nproperties of complex relational networks in social, biological and\ntechnological systems. Here we study the basic properties of twenty\n1-square-mile samples of street patterns of different world cities. Samples are\nrepresented by spatial (planar) graphs, i.e. valued graphs defined by metric\nrather than topologic distance and where street intersections are turned into\nnodes and streets into edges. We study the distribution of nodes in the\n2-dimensional plane. We then evaluate the local properties of the graphs by\nmeasuring the meshedness coefficient and counting short cycles (of three, four\nand five edges), and the global properties by measuring global efficiency and\ncost. As normalization graphs, we consider both minimal spanning trees (MST)\nand greedy triangulations (GT) induced by the same spatial distribution of\nnodes. The results indicate that most of the cities have evolved into networks\nas efficienct as GT, although their cost is closer to the one of a tree. An\nanalysis based on relative efficiency and cost is able to characterize\ndifferent classes of cities. \n\n"}
{"id": "physics/0510198", "contents": "Title: Scale Invariance in Road Networks Abstract: We study the topological and geographic structure of the national road\nnetworks of the United States, England and Denmark. By transforming these\nnetworks into their dual representation, where roads are vertices and an edge\nconnects two vertices if the corresponding roads ever intersect, we show that\nthey exhibit both topological and geographic scale invariance. That is, we show\nthat for sufficiently large geographic areas, the dual degree distribution\nfollows a power law with exponent 2.2 < alpha < 2.4, and that journeys,\nregardless of their length, have a largely identical structure. To explain\nthese properties, we introduce and analyze a simple fractal model of road\nplacement that reproduces the observed structure, and suggests a testable\nconnection between the scaling exponent alpha and the fractal dimensions\ngoverning the placement of roads and intersections. \n\n"}
{"id": "physics/0510216", "contents": "Title: Comment on Barabasi, Nature 435, 207 (2005) Abstract: In a recent letter, Barabasi claims that the dynamics of a number of human\nactivities are scale-free [1]. He specifically reports that the probability\ndistribution of time intervals tau between consecutive e-mails sent by a single\nuser and time delays for e-mail replies follow a power-law with an exponent -1,\nand proposes a priority-queuing process as an explanation of the bursty nature\nof human activity. Here, we quantitatively demonstrate that the reported\npower-law distributions are solely an artifact of the analysis of the empirical\ndata and that the proposed model is not representative of e-mail communication\npatterns. \n\n"}
{"id": "physics/0511063", "contents": "Title: The Backbone of a City Abstract: Recent studies have revealed the importance of centrality measures to analyze\nvarious spatial factors affecting human life in cities. Here we show how it is\npossible to extract the backbone of a city by deriving spanning trees based on\nedge betweenness and edge information. By using as sample cases the cities of\nBologna and San Francisco, we show how the obtained trees are radically\ndifferent from those based on edge lengths, and allow an extended comprehension\nof the ``skeleton'' of most important routes that so much affects\npedestrian/vehicular flows, retail commerce vitality, land-use separation,\nurban crime and collective dynamical behaviours. \n\n"}
{"id": "physics/0512167", "contents": "Title: Perfect Tempering Abstract: Multimodal structures in the sampling density (e.g. two competing phases) can\nbe a serious problem for traditional Markov Chain Monte Carlo (MCMC), because\ncorrect sampling of the different structures can only be guaranteed for\ninfinite sampling time. Samples may not decouple from the initial configuration\nfor a long time and autocorrelation times may be hard to determine.\n  We analyze a suitable modification (C. J. Geyer and E. A. Thompson, J. Amer.\nStatist. Assoc., 90, 909, 1995) of the simulated tempering idea (E. Marinari\nand G. Parisi, Europhys. Lett. 19, 451, 1992), which has orders of magnitude\nsmaller autocorrelation times for multimodal sampling densities and which\nsamples all peaks of multimodal structures according to their weight. The\nmethod generates exact, i.e. uncorrelated, samples and thus gives access to\nreliable error estimates. Exact tempering is applicable to arbitrary\n(continuous or discreet) sampling densities and moreover presents a possibility\nto calculate integrals over the density (e.g. the partition function for the\nBoltzmann distribution), which are not accessible by usual MCMC. \n\n"}
{"id": "physics/0601089", "contents": "Title: Hidden Forces and Fluctuations from Moving Averages: A Test Study Abstract: The possibility that price dynamics is affected by its distance from a moving\naverage has been recently introduced as new statistical tool. The purpose is to\nidentify the tendency of the price dynamics to be attractive or repulsive with\nrespect to its own moving average. We consider a number of tests for various\nmodels which clarify the advantages and limitations of this new approach. The\nanalysis leads to the identification of an effective potential with respect to\nthe moving average. Its specific implementation requires a detailed\nconsideration of various effects which can alter the statistical methods used.\nHowever, the study of various model systems shows that this approach is indeed\nsuitable to detect hidden forces in the market which go beyond usual\ncorrelations and volatility clustering. \n\n"}
{"id": "physics/0601158", "contents": "Title: Gossip in random networks Abstract: We consider the average probability X of being informed on a gossip in a\ngiven social network. The network is modeled within the random graph theory of\nErdos and Renyi. In this theory, a network is characterized by two parameters:\nthe size N and the link probability p. Our experimental data suggest three\nlevels of social inclusion of friendship. The critical value p_c, for which\nhalf of agents are informed, scales with the system size as N^{-\\gamma} with\n\\gamma\\approx 0.68. Computer simulations show that the probability X varies\nwith p as a sigmoidal curve. Influence of the correlations between neighbors is\nalso evaluated: with increasing clustering coefficient C, X decreases. \n\n"}
{"id": "physics/0602097", "contents": "Title: An elementary model of price dynamics in a financial market:\n  Distribution, Multiscaling & Entropy Abstract: Stylized facts of empirical assets log-returns $Z$ include the existence of\n(semi) heavy tailed distributions $f_Z(z)$ and a non-linear spectrum of Hurst\nexponents $\\tau(\\beta)$. Empirical data considered are daily prices of 10 large\nindices from 01/01/1990 to 12/31/2004. We propose a stylized model of price\ndynamics which is driven by expectations. The model is a multiplicative random\nprocess with a stochastic, state-dependent growth rate which establishes a\nnegative feedback component in the price dynamics. This 0-order model implies\nthat the distribution of log-returns is Laplacian $f_Z(z) \\sim\n\\exp(-\\frac{|z|}{\\alpha})$, whose single parameter $\\alpha$ can be regarded as\na measure for the long-time averaged liquidity in the respective market. A\ncomparison with the (more general) Weibull distribution shows that empirical\ndaily log returns are close to being Laplacian distributed. The spectra of\nHurst exponents of both, empirical data $\\tau_{emp}$ and simulated data due to\nour model $\\tau_{theor}$, are compared. Due to the finding of non-linear Hurst\nspectra, the Renyi entropy (RE) $R_\\beta(f_Z)$is considered. An explicit\nfunctional form of the RE for an exponential distribution is derived.\nTheoretical REs of simulated asset return trails are in good agreement with the\nRE estimated from empirical returns. \n\n"}
{"id": "physics/0602107", "contents": "Title: The Exponent Expansion: An Effective Approximation of Transition\n  Probabilities of Diffusion Processes and Pricing Kernels of Financial\n  Derivatives Abstract: A computational technique borrowed from the physical sciences is introduced\nto obtain accurate closed-form approximations for the transition probability of\narbitrary diffusion processes. Within the path integral framework the same\ntechnique allows one to obtain remarkably good approximations of the pricing\nkernels of financial derivatives. Several examples are presented, and the\napplication of these results to increase the efficiency of numerical approaches\nto derivative pricing is discussed. \n\n"}
{"id": "physics/0603150", "contents": "Title: Wavelet analysis of event by event fluctuations Abstract: The temporal fluctuations of produced hadron density in heavy ion collisions,\nmodelled by 2D Ising model at temperatures $T_c$ and below, are studied through\na recently developed wavelet based fluctuation analysis method. At $T_c$,\nlong-range correlated multifractal behavior, matching with the recently\nobserved Hurst exponent $H\\simeq 1$, is found. Below $T_c$ uncorrelated\nmonofractal behavior is seen. The correlation behavior compares well with the\nresults obtained from continuous wavelet based average wavelet co-efficient\nmethod, as well as with Fourier power spectral analysis. \n\n"}
{"id": "physics/0604051", "contents": "Title: Measurable Systems and Behavioral Sciences Abstract: Individual choices often depend on the order in which the decisions are made.\nIn this paper, we expose a general theory of measurable systems (an example of\nwhich is an individual's preferences) allowing for incompatible (non-commuting)\nmeasurements. The basic concepts are illustrated in an example of non-classical\nrational choice. We conclude with a discussion of some of the basic properties\nof non-classical systems in the context of social sciences. In particular, we\nargue that the distinctive feature of non-classical systems translates into a\nformulation of bounded rationality. \n\n"}
{"id": "physics/0604226", "contents": "Title: Dynamics of Multi-Player Games Abstract: We analyze the dynamics of competitions with a large number of players. In\nour model, n players compete against each other and the winner is decided based\non the standings: in each competition, the mth ranked player wins. We solve for\nthe long time limit of the distribution of the number of wins for all n and m\nand find three different scenarios. When the best player wins, the standings\nare most competitive as there is one-tier with a clear differentiation between\nstrong and weak players. When an intermediate player wins, the standings are\ntwo-tier with equally-strong players in the top tier and clearly-separated\nplayers in the lower tier. When the worst player wins, the standings are least\ncompetitive as there is one tier in which all of the players are equal. This\nbehavior is understood via scaling analysis of the nonlinear evolution\nequations. \n\n"}
{"id": "physics/0605029", "contents": "Title: Detecting degree symmetries in networks Abstract: The surrounding of a vertex in a network can be more or less symmetric. We\nderive measures of a specific kind of symmetry of a vertex which we call degree\nsymmetry -- the property that many paths going out from a vertex have\noverlapping degree sequences. These measures are evaluated on artificial and\nreal networks. Specifically we consider vertices in the human metabolic\nnetwork. We also measure the average degree-symmetry coefficient for different\nclasses of real-world network. We find that most studied examples are weakly\npositively degree-symmetric. The exceptions are an airport network (having a\nnegative degree-symmetry coefficient) and one-mode projections of social\naffiliation networks that are rather strongly degree-symmetric. \n\n"}
{"id": "physics/0605116", "contents": "Title: Spanning Trees and bootstrap reliability estimation in correlation based\n  networks Abstract: We introduce a new technique to associate a spanning tree to the average\nlinkage cluster analysis. We term this tree as the Average Linkage Minimum\nSpanning Tree. We also introduce a technique to associate a value of\nreliability to links of correlation based graphs by using bootstrap replicas of\ndata. Both techniques are applied to the portfolio of the 300 most capitalized\nstocks traded at New York Stock Exchange during the time period 2001-2003. We\nshow that the Average Linkage Minimum Spanning Tree recognizes economic sectors\nand sub-sectors as communities in the network slightly better than the Minimum\nSpanning Tree does. We also show that the average reliability of links in the\nMinimum Spanning Tree is slightly greater than the average reliability of links\nin the Average Linkage Minimum Spanning Tree. \n\n"}
{"id": "physics/0606007", "contents": "Title: On the Frequency of Severe Terrorist Events Abstract: In the spirit of Richardson's original (1948) study of the statistics of\ndeadly conflicts, we study the frequency and severity of terrorist attacks\nworldwide since 1968. We show that these events are uniformly characterized by\nthe phenomenon of scale invariance, i.e., the frequency scales as an inverse\npower of the severity, P(x) ~ x^-alpha. We find that this property is a robust\nfeature of terrorism, persisting when we control for economic development of\nthe target country, the type of weapon used, and even for short time-scales.\nFurther, we show that the center of the distribution oscillates slightly with a\nperiod of roughly tau ~ 13 years, that there exist significant temporal\ncorrelations in the frequency of severe events, and that current models of\nevent incidence cannot account for these variations or the scale invariance\nproperty of global terrorism. Finally, we describe a simple toy model for the\ngeneration of these statistics, and briefly discuss its implications. \n\n"}
{"id": "physics/0606164", "contents": "Title: Analysis of aggregated tick returns: evidence for anomalous diffusion Abstract: In order to investigate the origin of large price fluctuations, we analyze\nstock price changes of ten frequently traded NASDAQ stocks in the year 2002.\nThough the influence of the trading frequency on the aggregate return in a\ncertain time interval is important, it cannot alone explain the heavy tailed\ndistribution of stock price changes. For this reason, we analyze intervals with\na fixed number of trades in order to eliminate the influence of the trading\nfrequency and investigate the relevance of other factors for the aggregate\nreturn. We show that in tick time the price follows a discrete diffusion\nprocess with a variable step width while the difference between the number of\nsteps in positive and negative direction in an interval is Gaussian\ndistributed. The step width is given by the return due to a single trade and is\nlong-term correlated in tick time. Hence, its mean value can well characterize\nan interval of many trades and turns out to be an important determinant for\nlarge aggregate returns. We also present a statistical model reproducing the\ncumulative distribution of aggregate returns. For an accurate agreement with\nthe empirical distribution, we also take into account asymmetries of the step\nwidths in different directions together with crosscorrelations between these\nasymmetries and the mean step width as well as the signs of the steps. \n\n"}
{"id": "physics/0606224", "contents": "Title: Of Songs and Men: a Model for Multiple Choice with Herding Abstract: We propose a generic model for multiple choice situations in the presence of\nherding and compare it with recent empirical results from a Web-based music\nmarket experiment. The model predicts a phase transition between a weak\nimitation phase and a strong imitation, `fashion' phase, where choices are\ndriven by peer pressure and the ranking of individual preferences is strongly\ndistorted at the aggregate level. The model can be calibrated to reproduce the\nmain experimental results of Salganik et al. (Science, 311, pp. 854-856\n(2006)); we show in particular that the value of the social influence parameter\ncan be estimated from the data. In one of the experimental situation, this\nvalue is found to be close to the critical value of the model. \n\n"}
{"id": "physics/0607001", "contents": "Title: Naming Game on small-world networks: the role of clustering structure Abstract: Naming Game is a recently proposed model for describing how a multi-agent\nsystem can converge towards a consensus state in a self-organized way. In this\npaper, we investigate this model on the so-called homogeneous small-world\nnetworks and focus on the influence of the triangular topology on the dynamics.\nOf all the topological quantities, the clustering coefficient is found to play\na significant role in the dynamics of the Naming Game. On the one hand, it\naffects the maximum memory of each agent; on the other hand, it inhibits the\ngrowing of clusters in which agents share a common word, i.e., a larger\nclustering coefficient will cause a slower convergence of the system. We also\nfind a quantitative relationship between clustering coefficient and the maximum\nmemory. \n\n"}
{"id": "physics/0607131", "contents": "Title: Dynamical change of Pareto index in Japanese land prices Abstract: We investigate the dynamical behavior in the large scale region of\nnon-equilibrium systems, by employing data on the assessed value of land in\n1983 -- 2006 Japan. In the system we find the detailed quasi-balance, which has\nthe symmetry: x_1 -> a {x_2}^{\\theta} (x_1 and x_2 are two successive land\nprices). By using the detailed quasi-balance and Gibrat's law, we derive\nPareto's law with varying Pareto index annually. The parameter \\theta\ncorresponds with the ratio of Pareto indices (\\mu_1 + 1)/(\\mu_2 + 1), and the\nrelation is confirmed in the empirical data nicely. \n\n"}
{"id": "physics/0607178", "contents": "Title: Impact of Unexpected Events, Shocking News and Rumours on Foreign\n  Exchange Market Dynamics Abstract: We analyze the dynamical response of the world's financial community to\nvarious types of unexpected events, including the 9/11 terrorist attacks as\nthey unfolded on a minute-by-minute basis. We find that there are various\n'species' of news, characterized by how quickly the news get absorbed, how much\nmeaning and importance is assigned to it by the community, and what subsequent\nactions are then taken. For example, the response to the unfolding events of\n9/11 shows a gradual collective understanding of what was happening, rather\nthan an immediate realization. For news items which are not simple economic\nstatements, and hence whose implications are not immediately obvious, we\nuncover periods of collective discovery during which collective opinions seem\nto oscillate in a remarkably synchronized way. In the case of a rumour, our\nfindings also provide a concrete example of contagion in inter-connected\ncommunities. Practical applications of this work include the possibility of\nproducing selective newsfeeds for specific communities, based on their likely\nimpact. \n\n"}
{"id": "physics/0607258", "contents": "Title: Ideal-gas like market models with savings: quenched and annealed cases Abstract: We analyze the ideal gas like models of markets and review the different\ncases where a `savings' factor changes the nature and shape of the distribution\nof wealth. These models can produce similar distribution of wealth as observed\nacross varied economies. We present a more realistic model where the saving\nfactor can vary over time (annealed savings) and yet produces Pareto\ndistribution of wealth in certain cases. We discuss the relevance of such\nmodels in the context of wealth distribution, and address some recent issues in\nthe context of these models. \n\n"}
{"id": "physics/0608099", "contents": "Title: Characterization of foreign exchange market using the\n  threshold-dealer-model Abstract: We introduce a deterministic dealer model which implements most of the\nempirical laws, such as fat tails in the price change distributions, long term\nmemory of volatility and non-Poissonian intervals. We also clarify the\ncausality between microscopic dealers' dynamics and macroscopic market's\nempirical laws. \n\n"}
{"id": "physics/0608282", "contents": "Title: Power-law distribution of individual Hirsch indices, the comparison of\n  merits in different fields, and the relation to a Pareto distribution Abstract: A data set of Hirsch indices, $h$, for Finnish scientists in certain fields\nis statistically analyzed and fitted to $h(n) =Pn^p$ for the $n$-th most-quoted\nscientist. The precoefficient $P$ is characteristic for the field and the\nexponent $p$ is about -0.2 for all data sets considered. For Physics, Chemistry\nand Chemical Engineering, the $P$ are 49.7(8), 41.3(6), and 21.4(6),\nrespectively. These $p$ values correspond to Pareto exponents of about -7 for\nthe distribution of Hirsch indices $h$. \n\n"}
{"id": "physics/0609031", "contents": "Title: Traffic flow and efficient routing on scale-free networks: A survey Abstract: Recently, motivated by the pioneer works in revealing the small-world effect\nand scale-free property of various real-life networks, many scientists devote\nthemselves to studying complex networks. In this paper, we give a brief review\non the studies of traffic flow and efficient routing on scale-free networks,\nincluding the traffic dynamics based on global routing protocol, Traffic\ndynamics based on local routing protocol, and the critical phenomena and\nscaling behaviors of real and artificial traffic. Finally, perspectives and\nsome interesting problems are proposed. \n\n"}
{"id": "physics/0609046", "contents": "Title: Fear and its implications for stock markets Abstract: The value of stocks, indices and other assets, are examples of stochastic\nprocesses with unpredictable dynamics. In this paper, we discuss asymmetries in\nshort term price movements that can not be associated with a long term positive\ntrend. These empirical asymmetries predict that stock index drops are more\ncommon on a relatively short time scale than the corresponding raises. We\npresent several empirical examples of such asymmetries. Furthermore, a simple\nmodel featuring occasional short periods of synchronized dropping prices for\nall stocks constituting the index is introduced with the aim of explaining\nthese facts. The collective negative price movements are imagined triggered by\nexternal factors in our society, as well as internal to the economy, that\ncreate fear of the future among investors. This is parameterized by a ``fear\nfactor'' defining the frequency of synchronized events. It is demonstrated that\nsuch a simple fear factor model can reproduce several empirical facts\nconcerning index asymmetries. It is also pointed out that in its simplest form,\nthe model has certain shortcomings. \n\n"}
{"id": "physics/0609069", "contents": "Title: Kinetic market models with single commodity having price fluctuations Abstract: We study here numerically the behavior of an ideal gas like model of markets\nhaving only one non-consumable commodity. We investigate the behavior of the\nsteady-state distributions of money, commodity and total wealth, as the\ndynamics of trading or exchange of money and commodity proceeds, with local (in\ntime) fluctuations in the price of the commodity. These distributions are\nstudied in markets with agents having uniform and random saving factors. The\nself-organizing features in money distribution are similar to the cases without\nany commodity (or with consumable commodities), while the commodity\ndistribution shows an exponential decay. The wealth distribution shows\ninteresting behavior: Gamma like distribution for uniform saving propensity and\nhas the same power-law tail, as that of the money distribution, for a market\nwith agents having random saving propensity. \n\n"}
{"id": "physics/0609124", "contents": "Title: Dynamical Phenomena on Complex Networks Abstract: The work presented in this thesis concerns different aspects of dynamical\nprocesses on networks. The first subject considered is the theoretical modeling\nof exploration processes of complex networks, such as the ``traceroute''\nprocess used to map the Internet. Our mean-field analysis of the traceroute\nmodel provides a better understanding of the Internet topology. A second part\nof the thesis is devoted to the study of the weighted representation of\nnetworks and their relations with the functional properties of infrastructure\nsystems (e.g. the airports network). Other results concerning spreading\nprocesses and percolation on weighted networks are presented. Finally, we turns\nto social networks, introducing the Naming Game, a model for the emergence of a\ncommunication system in a structured population of individuals. We show that\nthe dynamical phenomena generated by this model depend strongly on the topology\nof the interactions. \n\n"}
{"id": "physics/0609184", "contents": "Title: Impact of non-Poisson activity patterns on spreading processes Abstract: Halting a computer or biological virus outbreak requires a detailed\nunderstanding of the timing of the interactions between susceptible and\ninfected individuals. While current spreading models assume that users interact\nuniformly in time, following a Poisson process, a series of recent measurements\nindicate that the inter-contact time distribution is heavy tailed,\ncorresponding to a temporally inhomogeneous bursty contact process. Here we\nshow that the non-Poisson nature of the contact dynamics results in prevalence\ndecay times significantly larger than predicted by the standard Poisson process\nbased models. Our predictions are in agreement with the detailed time resolved\nprevalence data of computer viruses, which, according to virus bulletins, show\na decay time close to a year, in contrast with the one day decay predicted by\nthe standard Poisson process based models. \n\n"}
{"id": "physics/0609241", "contents": "Title: Optimal Paths in Complex Networks with Correlated Weights: The\n  World-wide Airport Network Abstract: We study complex networks with weights, $w_{ij}$, associated with each link\nconnecting node $i$ and $j$. The weights are chosen to be correlated with the\nnetwork topology in the form found in two real world examples, (a) the\nworld-wide airport network, and (b) the {\\it E. Coli} metabolic network. Here\n$w_{ij} \\sim x_{ij} (k_i k_j)^\\alpha$, where $k_i$ and $k_j$ are the degrees of\nnodes $i$ and $j$, $x_{ij}$ is a random number and $\\alpha$ represents the\nstrength of the correlations. The case $\\alpha > 0$ represents correlation\nbetween weights and degree, while $\\alpha < 0$ represents anti-correlation and\nthe case $\\alpha = 0$ reduces to the case of no correlations. We study the\nscaling of the lengths of the optimal paths, $\\ell_{\\rm opt}$, with the system\nsize $N$ in strong disorder for scale-free networks for different $\\alpha$. We\ncalculate the robustness of correlated scale-free networks with different\n$\\alpha$, and find the networks with $\\alpha < 0$ to be the most robust\nnetworks when compared to the other values of $\\alpha$. We propose an\nanalytical method to study percolation phenomena on networks with this kind of\ncorrelation. We compare our simulation results with the real world-wide airport\nnetwork, and we find good agreement. \n\n"}
{"id": "physics/0610051", "contents": "Title: Structural Inference of Hierarchies in Networks Abstract: One property of networks that has received comparatively little attention is\nhierarchy, i.e., the property of having vertices that cluster together in\ngroups, which then join to form groups of groups, and so forth, up through all\nlevels of organization in the network. Here, we give a precise definition of\nhierarchical structure, give a generic model for generating arbitrary\nhierarchical structure in a random graph, and describe a statistically\nprincipled way to learn the set of hierarchical features that most plausibly\nexplain a particular real-world network. By applying this approach to two\nexample networks, we demonstrate its advantages for the interpretation of\nnetwork data, the annotation of graphs with edge, vertex and community\nproperties, and the generation of generic null models for further hypothesis\ntesting. \n\n"}
{"id": "physics/0610260", "contents": "Title: Focusing of opinions in the Deffuant model: First impression counts Abstract: The paper treats opinion dynamics of an unequal distribution as the initial\nopinion distribution. Simulated is the Deffuant model on a directed\nBarabasi-Albert network with discrete opinions and several subjects. Noticed is\na focusing of the the resulting opinion distribution during the simulation\ntowards the average value of the initial opinion distribution. A small change\nof the focusing is seen. A dependency of this change on the number of subjects\nand opinions is detected and indicates the change as a consequence of\ndiscretization the opinions. Hereby the average value of the initial opinion\ndistribution can be identified as the guide of opinion forming. \n\n"}
{"id": "physics/0611032", "contents": "Title: Parametric investigation of nonlinear fluctuations in a dc glow\n  discharge plasma Abstract: Glow discharge plasmas exhibit various types of self excited oscillations for\ndifferent initial conditions like discharge voltages and filling pressures. The\nbehavior of such oscillations associated with the anode glow have been\ninvestigated using nonlinear techniques like correlation dimension, largest\nLyapunov exponent etc. It is seen that these oscillations go to an ordered\nstate from a chaotic state with increase in input energy i.e. with discharge\nvoltages implying occurrence of inverse bifurcations. These results are\ndifferent from the other observations wherein the fluctuations have been\nobserved to go from ordered to chaotic state. \n\n"}
{"id": "physics/0612069", "contents": "Title: Modelling temporal and spatial features of collaboration network Abstract: The collaboration network is an example of a social network which has both\nnon-trivial temporal and spatial dependence. Based on the observations of\ncollaborations in Physical Review Letters, a model of collaboration network is\nproposed which correctly reproduces the time evolution of the link length\ndistributions, clustering coefficients, degree distributions and assortative\nproperty of real data to a large extent. \n\n"}
{"id": "physics/0612234", "contents": "Title: Quantum Game Theory and Open Access Publishing Abstract: The digital revolution of the information age and in particular the sweeping\nchanges of scientific communication brought about by computing and novel\ncommunication technology, potentiate global, high grade scientific information\nfor free. The arXiv for example is the leading scientific communication\nplatform, mainly for mathematics and physics, where everyone in the world has\nfree access on. While in some scientific disciplines the open access way is\nsuccessfully realized, other disciplines (e.g. humanities and social sciences)\ndwell on the traditional path, even though many scientists belonging to these\ncommunities approve the open access principle. In this paper we try to explain\nthese different publication patterns by using a game theoretical approach.\nBased on the assumption, that the main goal of scientists is the maximization\nof their reputation, we model different possible game settings, namely a zero\nsum game, the prisoners' dilemma case and a version of the stag hunt game, that\nshow the dilemma of scientists belonging to ''non-open access communities''.\n  From an individual perspective, they have no incentive to deviate from the\nNash Equilibrium of traditional publishing. By extending the model using the\nquantum game theory approach it can be shown, that if the strength of\nentanglement exceeds a certain value, the scientists will overcome the dilemma\nand terminate to publish only traditionally in all three settings. \n\n"}
{"id": "physics/0701107", "contents": "Title: New approaches to model and study social networks Abstract: We describe and develop three recent novelties in network research which are\nparticularly useful for studying social systems. The first one concerns the\ndiscovery of some basic dynamical laws that enable the emergence of the\nfundamental features observed in social networks, namely the nontrivial\nclustering properties, the existence of positive degree correlations and the\nsubdivision into communities. To reproduce all these features we describe a\nsimple model of mobile colliding agents, whose collisions define the\nconnections between the agents which are the nodes in the underlying network,\nand develop some analytical considerations. The second point addresses the\nparticular feature of clustering and its relationship with global network\nmeasures, namely with the distribution of the size of cycles in the network.\nSince in social bipartite networks it is not possible to measure the clustering\nfrom standard procedures, we propose an alternative clustering coefficient that\ncan be used to extract an improved normalized cycle distribution in any\nnetwork. Finally, the third point addresses dynamical processes occurring on\nnetworks, namely when studying the propagation of information in them. In\nparticular, we focus on the particular features of gossip propagation which\nimpose some restrictions in the propagation rules. To this end we introduce a\nquantity, the spread factor, which measures the average maximal fraction of\nnearest neighbors which get in contact with the gossip, and find the striking\nresult that there is an optimal non-trivial number of friends for which the\nspread factor is minimized, decreasing the danger of being gossiped. \n\n"}
{"id": "physics/0701110", "contents": "Title: On the origin of the Epps effect Abstract: The Epps effect, the decrease of correlations between stock returns for short\ntime windows, was traced back to the trading asynchronicity and to the\noccasional lead-lag relation between the prices. We study pairs of stocks where\nthe latter is negligible and confirm the importance of asynchronicity but point\nout that alone these aspects are insufficient to give account for the whole\neffect. \n\n"}
{"id": "physics/0701171", "contents": "Title: A case study of speculative financial bubbles in the South African stock\n  market 2003-2006 Abstract: We tested 45 indices and common stocks traded in the South African stock\nmarket for the possible existence of a bubble over the period from Jan. 2003 to\nMay 2006. A bubble is defined by a faster-than-exponential acceleration with\nsignificant log-periodic oscillations. The faster-than-exponential acceleration\ncharacteristics are tested with several different metrics, including\nnonlinearity on the logarithm of the price and power law fits. The log-periodic\nproperties are investigated in detail using the first-order log-periodic\npower-law (LPPL) formula, the parametric detrending method, the\n$(H,q)$-analysis, and the second-order Weierstrass-type model, resulting in a\nconsistent and robust estimation of the fundamental angular log-frequency\n$\\omega_1 =7\\pm 2$, in reasonable agreement with previous estimations on many\nother bubbles in developed and developing markets. Sensitivity tests of the\nestimated critical times and of the angular log-frequency are performed by\nvarying the first date and the last date of the stock price time series. These\ntests show that the estimated parameters are robust. With the insight of 6\nadditional month of data since the analysis was performed, we observe that many\nof the stocks on the South Africa market experienced an abrupt drop mid-June\n2006, which is compatible with the predicted $t_c$ for several of the stocks,\nbut not all. This suggests that the mini-crash that occurred around mid-June of\n2006 was only a partial correction, which has resumed into a renewed bubbly\nacceleration bound to end some times in 2007, similarly to what happened on the\nS&P500 US market from Oct. 1997 to Aug. 1998. \n\n"}
{"id": "physics/0701204", "contents": "Title: Dynamical affinity in opinion dynamics modelling Abstract: We here propose a model to simulate the process of opinion formation, which\naccounts for the mutual affinity between interacting agents. Opinion and\naffinity evolve self-consistently, manifesting a highly non trivial interplay.\nA continuous transition is found between single and multiple opinion states.\nFractal dimension and signature of critical behaviour are also reported. A rich\nphenomenology is presented and discussed with reference to corresponding\npsychological implications. \n\n"}
{"id": "physics/0701316", "contents": "Title: Information propagation and collective consensus in blogosphere: a\n  game-theoretical approach Abstract: In this paper, we study the information propagation in an empirical blogging\nnetwork by game-theoretical approach. The blogging network has small-world\nproperty and is scale-free. Individuals in the blogosphere coordinate their\ndecisions according to their idiosyncratic preferences and the choices of their\nneighbors. We find that corresponding to different initial conditions and\nweights, the equilibrium frequency of discussions has a transition from high to\nlow as a result of the common interest in the topics specified by payoff\nmatrices. Furthermore, under recommendation, namely, individuals in blogging\nnetworks refer to additional bloggers' resources besides their nearest\nneighbors preferentially according to the popularity of the blogs, the whole\nblogging network ultrafastly evolves into consensus state (absorbing state).\nOur results reflect the dynamic pattern of information propagation in blogging\nnetworks. \n\n"}
{"id": "physics/0701318", "contents": "Title: Influence of initial distributions on robust cooperation in evolutionary\n  Prisoner's Dilemma Abstract: We study the evolutionary Prisoner's Dilemma game on scale-free networks for\ndifferent initial distributions. We consider three types of initial\ndistributions for cooperators and defectors: initially random distribution with\ndifferent frequencies of defectors; intentional organization with defectors\ninitially occupying the most connected nodes with different fractions of\ndefectors; intentional assignment for cooperators occupying the most connected\nnodes with different proportions of defectors at the beginning. It is shown\nthat initial configurations for cooperators and defectors can influence the\nstationary level of cooperation and the evolution speed of cooperation.\nOrganizations with the vertices with highest connectivity representing\nindividuals cooperators could exhibit the most robust cooperation and drive\nevolutionary process to converge fastest to the high steady cooperation in the\nthree situations of initial distributions. Otherwise, we determine the critical\ninitial frequencies of defectors above which the extinction of cooperators\noccurs for the respective initial distributions, and find that the presence of\nnetwork loops and clusters for cooperators can favor the emergence of\ncooperation. \n\n"}
{"id": "physics/0701348", "contents": "Title: Deterministic Modularity Optimization Abstract: We study community structure of networks. We have developed a scheme for\nmaximizing the modularity Q based on mean field methods. Further, we have\ndefined a simple family of random networks with community structure; we\nunderstand the behavior of these networks analytically. Using these networks,\nwe show how the mean field methods display better performance than previously\nknown deterministic methods for optimization of Q. \n\n"}
{"id": "physics/0702041", "contents": "Title: Tagging heavy flavours with boosted decision trees Abstract: This paper evaluates the performance of boosted decision trees for tagging\nb-jets. It is shown, using a Monte Carlo simulation of $WH \\to l\\nu q\\bar{q}$\nevents that boosted decision trees outperform feed-forward neural networks. The\nresults show that for a b-tagging efficiency of 60% the light jet rejection\ngiven by boosted decision trees is about 35% higher than that given by neural\nnetworks. \n\n"}
{"id": "physics/0702064", "contents": "Title: Hilbert Space Becomes Ultrametric in the High Dimensional Limit:\n  Application to Very High Frequency Data Analysis Abstract: An ultrametric topology formalizes the notion of hierarchical structure. An\nultrametric embedding, referred to here as ultrametricity, is implied by a\nnatural hierarchical embedding. Such hierarchical structure can be global in\nthe data set, or local. By quantifying extent or degree of ultrametricity in a\ndata set, we show that ultrametricity becomes pervasive as dimensionality\nand/or spatial sparsity increases. This leads us to assert that very high\ndimensional data are of simple structure. We exemplify this finding through a\nrange of simulated data cases. We discuss also application to very high\nfrequency time series segmentation and modeling. \n\n"}
{"id": "physics/0702089", "contents": "Title: Better Physics Teaching Can Increase Physics Enrollment Abstract: Our main goal is to develop plans to increase physics enrollment. Once again\nwe thoroughly analyze the problem from the beginning and reach the conclusion\nthat the most appropriate starting point in this direction should be to look\ninto K-12 teaching. We give a few recommendations to improve science/physics\nteaching at K-12 level. It is proposed that the quickest way to make some\nadvancement is to start teacher training or refresher courses for school\nteachers to fill up their gaps in knowledge. We suggest a comparison of the\naffectivity of different methods of teaching to decide which one of them works\nbetter under what type of circumstances. We also propose a few steps to improve\nphysics teaching standards at the higher levels. \n\n"}
{"id": "physics/0702185", "contents": "Title: Yet on statistical properties of traded volume: correlation and mutual\n  information at different value magnitudes Abstract: In this article we analyse linear correlation and non-linear dependence of\ntraded volume, $v$, of the 30 constituents of Dow Jones Industrial Average at\ndifferent value scales. Specifically, we have raised $v$ to some real value\n$\\alpha $ or $\\beta $, which introduces a bias for small ($ \\alpha, \\beta <0$)\nor large ($\\alpha, \\beta >1$) values. Our results show that small values of $v$\nare regularly \\emph{anti-correlated} with values at other scales of traded\nvolume. This is consistent with the high liquidity of the 30 equities analysed\nand the asymmetric form of the multi-fractal spectrum for traded volume which\nhas supported the dynamical scenario presented by us. \n\n"}
{"id": "physics/0703201", "contents": "Title: Economic Inequality: Is it Natural? Abstract: Mounting evidences are being gathered suggesting that income and wealth\ndistribution in various countries or societies follow a robust pattern, close\nto the Gibbs distribution of energy in an ideal gas in equilibrium, but also\ndeviating significantly for high income groups. Application of physics models\nseem to provide illuminating ideas and understanding, complimenting the\nobservations. \n\n"}
{"id": "physics/9705008", "contents": "Title: A Simple Model of Evolution with Variable System Size Abstract: A simple model of biological extinction with variable system size is\npresented that exhibits a power-law distribution of extinction event sizes. The\nmodel is a generalization of a model recently introduced by Newman (Proc. R.\nSoc. Lond. B265, 1605 (1996). Both analytical and numerical analysis show that\nthe exponent of the power-law distribution depends only marginally on the\ngrowth rate $g$ at which new species enter the system and is equal to the one\nof the original model in the limit $g\\to\\infty$. A critical growth rate $g_c$\ncan be found below which the system dies out. Under these model assumptions\nstable ecosystems can only exist if the regrowth of species is sufficiently\nfast. \n\n"}
{"id": "physics/9710023", "contents": "Title: Aftershocks in Coherent-Noise Models Abstract: The decay pattern of aftershocks in the so-called 'coherent-noise' models [M.\nE. J. Newman and K. Sneppen, Phys. Rev. E54, 6226 (1996)] is studied in detail.\nAnalytical and numerical results show that the probability to find a large\nevent at time $t$ after an initial major event decreases as $t^{-\\tau}$ for\nsmall $t$, with the exponent $\\tau$ ranging from 0 to values well above 1. This\nis in contrast to Sneppen und Newman, who stated that the exponent is about 1,\nindependent of the microscopic details of the simulation. Numerical simulations\nof an extended model [C. Wilke, T. Martinetz, Phys. Rev. E56, 7128 (1997)] show\nthat the power-law is only a generic feature of the original dynamics and does\nnot necessarily appear in a more general context. Finally, the implications of\nthe results to the modeling of earthquakes are discussed. \n\n"}
{"id": "physics/9811014", "contents": "Title: Millisecond and Binary Pulsars as Nature's Frequency Standards. II.\n  Effects of Low-Frequency Timing Noise on Residuals and Measured Parameters Abstract: Pulsars are the most stable natural frequency standards. They can be applied\nto a number of principal problems of modern astronomy and time-keeping\nmetrology. The full exploration of pulsar properties requires obtaining\nunbiased estimates of the spin and orbital parameters. These estimates depend\nessentially on the random noise component being revealed in the residuals of\ntime of arrivals (TOA). In the present paper, the influence of low-frequency\n(\"red\") timing noise with spectral indices from 1 to 6 on TOA residuals,\nvariances, and covariances of estimates of measured parameters of single and\nbinary pulsars are studied. In order to determine their functional dependence\non time, an analytic technique of processing of observational data in time\ndomain is developed which takes into account both stationary and non-stationary\ncomponents of noise. Our analysis includes a simplified timing model of a\nbinary pulsar in a circular orbit and procedure of estimation of pulsar\nparameters and residuals under the influence of red noise. We reconfirm that\nuncorrelated white noise of errors of measurements of TOA brings on gradually\ndecreasing residuals, variances and covariances of all parameters. On the other\nhand, we show that any red noise causes the residuals, variances, and\ncovariances of certain parameters to increase with time. Hence, the low\nfrequency noise corrupts our observations and reduces experimental\npossibilities for better tests of General Relativity Theory. We also treat in\ndetail the influence of a polynomial drift of noise on the residuals and\nfitting parameters. Results of the analitic analysis are used for discussion of\na statistic describing stabilities of kinematic and dynamic pulsar time scales. \n\n"}
{"id": "physics/9908014", "contents": "Title: Teaching statistics in the physics curriculum: Unifying and clarifying\n  role of subjective probability Abstract: Subjective probability is based on the intuitive idea that probability\nquantifies the degree of belief that an event will occur. A probability theory\nbased on this idea represents the most general framework for handling\nuncertainty. A brief introduction to subjective probability and Bayesian\ninference is given, with comments on typical misconceptions which tend to\ndiscredit it and comparisons to other approaches. \n\n"}
{"id": "physics/9910035", "contents": "Title: Analyzing symmetry breaking within a chaotic quantum system via Bayesian\n  inference Abstract: Bayesian inference is applied to the level fluctuations of two coupled\nmicrowave billiards in order to extract the coupling strength. The coupled\nresonators provide a model of a chaotic quantum system containing two coupled\nsymmetry classes of levels. The number variance is used to quantify the level\nfluctuations as a function of the coupling and to construct the conditional\nprobability distribution of the data. The prior distribution of the coupling\nparameter is obtained from an invariance argument on the entropy of the\nposterior distribution. \n\n"}
{"id": "q-bio/0311037", "contents": "Title: Hierarchical Clustering Using Mutual Information Abstract: We present a method for hierarchical clustering of data called {\\it mutual\ninformation clustering} (MIC) algorithm. It uses mutual information (MI) as a\nsimilarity measure and exploits its grouping property: The MI between three\nobjects $X, Y,$ and $Z$ is equal to the sum of the MI between $X$ and $Y$, plus\nthe MI between $Z$ and the combined object $(XY)$. We use this both in the\nShannon (probabilistic) version of information theory and in the Kolmogorov\n(algorithmic) version. We apply our method to the construction of phylogenetic\ntrees from mitochondrial DNA sequences and to the output of independent\ncomponents analysis (ICA) as illustrated with the ECG of a pregnant woman. \n\n"}
{"id": "quant-ph/0006009", "contents": "Title: Increased Efficiency of Quantum State Estimation Using Non-Separable\n  Measurements Abstract: We address the \"major open problem\" of evaluating how much increased\nefficiency in estimation is possible using non-separable, as opposed to\nseparable, measurements of N copies of m-level quantum systems. First, we study\nthe six cases m = 2, N = 2,...,7 by computing the the 3 x 3 Fisher information\nmatrices for the corresponding optimal measurements recently devised by Vidal\net al (quant-ph/9812068) for N = 2,...,7. We obtain simple polynomial\nexpressions for the (\"Gill-Massar\") traces of the products of the inverse of\nthe quantum Helstrom information matrix and these Fisher information matrices.\nThe six traces all have minima of 2 N -1 in the pure state limit, while for\nseparable measurements (quant-ph/9902063), the traces can equal N, but not\nexceed it. Then, the result of an analysis for m = 3, N = 2 leads us to\nconjecture that for optimal measurements for all m and N, the \"Gill-Massar\ntrace\" achieves a minimum of (2N-1)(m-1) in the pure state limit. \n\n"}
{"id": "quant-ph/9806013", "contents": "Title: Volume of classical and quantum ensembles: geometric approach to entropy\n  and information Abstract: It is shown for classical and quantum ensembles that there is a unique\nquantity which has the properties of a \"volume\". This quantity is a function of\nthe ensemble entropy, and hence provides a geometric interpretation for the\nlatter. It further provides a geometric picture for deriving and unifying a\nnumber of results in classical and quantum information theory, and for\ndiscussing entropic uncertainty relations. \n\n"}
