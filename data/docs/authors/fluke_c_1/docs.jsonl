{"id": "0704.2593", "contents": "Title: CPT and lepton number violation in neutrino sector: Modified mass matrix\n  and oscillation due to gravity Abstract: We study the consequences of CPT and lepton number violation in neutrino\nsector. For CPT violation we take gravity with which neutrino and antineutrino\ncouple differently. Gravity mixes neutrino and antineutrino in an unequal ratio\nto give two mass eigenstates. Lepton number violation interaction together with\nCPT violation gives rise to neutrino-antineutrino oscillation. Subsequently, we\nstudy the neutrino flavor mixing and oscillation under the influence of\ngravity. It is found that gravity changes flavor oscillation significantly\nwhich influences the relative abundance of different flavors in present\nuniverse. We show that the neutrinoless double beta decay rate is modified due\nto presence of gravity- the origin of CPT violation, as the mass of the flavor\nstate is modified. \n\n"}
{"id": "0705.1494", "contents": "Title: Deep Spectroscopy of Systematically Surveyed Extended Lyman-alpha\n  Sources at z~3-5 Abstract: Spatially extended Ly-alpha sources that are faint and/or compact in coninuum\nare candidates for extremely young (~< 10^7 yrs) galaxies at high redshifts. We\npresent medium-resolution (R~2000) spectroscopy of such extended Ly-alpha\nsources found in our previous study at z~3-5, using VLT/VIMOS. The deep\nspectroscopy showed that all 18 objects we observed have large equivalent\nwidths (EWs) exceeding 100 A. For about 30% of our sample (five objects), we\nidentified conspicuous asymmetry on the profiles of the Ly-alpha line. They\nshow broad wing emission components on the red side, and sharp cut-off on the\nblue side of the Ly-alpha line. Such asymmetry is often seen in superwind\ngalaxies known to date, and also consistent with a theoretical prediction of\nsuperwind activity. There are eight objects (8/18 ~ 40%) that have large EWs\nexceeding 200 A, and no clear signature of superwind activities. Such large EWs\ncannot be explained in terms of photo-ionization by a moderately old (>10^7\nyrs) stellar population, even with a top-heavy IMF or an extremely low\nmetallicity. These eight objects clearly show a positive correlation between\nthe Ly-alpha luminosity and the velocity width. This suggests that these eight\nobjects are good candidates for forming-galaxies in a gas-cooling phase. \n\n"}
{"id": "0705.1508", "contents": "Title: A SuperMassive Black Hole Fundamental Plane for Ellipticals Abstract: We obtain the coefficients of a new fundamental plane for supermassive black\nholes at the centers of elliptical galaxies, involving measured central black\nhole mass and photometric parameters which define the light distribution. The\ngalaxies are tightly distributed around this mass fundamental plane, with\nimprovement in the rms residual over those obtained from the $\\mbh-\\sigma$ and\n$\\mbh-L$ relations. This implies a strong multidimensional link between the\ncentral massive black hole formation and global photometric properties of\nelliptical galaxies and provides an improved estimate of black hole mass from\ngalaxy data. \n\n"}
{"id": "0707.0503", "contents": "Title: Spin-Orbit Alignment for the Eccentric Exoplanet HD 147506b Abstract: The short-period exoplanet HD 147506b (also known as HAT-P-2b) has an\neccentric orbit, raising the possibility that it migrated through planet-planet\nscattering or Kozai oscillations accompanied by tidal dissipation. Either of\nthese scenarios could have significantly tilted the orbit relative to the host\nstar's equatorial plane. Here we present spectroscopy of a transit of HD\n147506b, and assess the spin-orbit alignment via the Rossiter-McLaughlin\neffect. We find the sky projections of the stellar spin axis and orbital axis\nto be aligned within 14 deg. Thus we find no corroborating evidence for\nscattering or Kozai migration, although these scenarios cannot be ruled out\nwith the present data. \n\n"}
{"id": "0709.1287", "contents": "Title: Finite size corrections to the blackbody radiation laws Abstract: We investigate the radiation of a blackbody in a cavity of finite size. For a\ngiven geometry, we use semiclassical techniques to obtain explicit expressions\nof the modified Planck's and Stefan-Boltzmann's blackbody radiation laws as a\nfunction of the size and shape of the cavity. We determine the range of\nparameters (temperature, size and shape of the cavity) for which these effects\nare accessible to experimental verification. Finally we discuss potential\napplications of our findings in the physics of the cosmic microwave background\nand sonoluminescence. \n\n"}
{"id": "0712.0860", "contents": "Title: Mass Models for Low Surface Brightness Galaxies with High Resolution\n  Optical Velocity Fields Abstract: We present high-resolution optical velocity fields from DensePak integral\nfield spectroscopy, along with derived rotation curves, for a sample of low\nsurface brightness galaxies. In the limit of no baryons, we fit the NFW and\npseudoisothermal halo models to the data and find the rotation curve shapes and\nhalo central densities to be better described by the isothermal halo. For those\ngalaxies with photometry, we present halo fits for three assumptions of the\nstellar mass-to-light ratio. We find that the velocity contribution from the\nbaryons is significant enough in the maximum disk case that maximum disk and\nthe NFW halo are mutually exclusive. We find a substantial cusp mass excess at\nthe centers of the galaxies, with at least two times more mass expected in the\ncuspy CDM halo than is allowed by the data. We also find that to reconcile the\ndata with LCDM, ~20 km/s noncircular motions are needed and/or the power\nspectrum has a lower amplitude on the scales we probe. \n\n"}
{"id": "0712.1562", "contents": "Title: Size of spectroscopic calibration samples for cosmic shear photometric\n  redshifts Abstract: Weak gravitational lensing surveys using photometric redshifts can have their\ncosmological constraints severely degraded by errors in the photo-z scale. We\nexplore the cosmological degradation vs the size of the spectroscopic survey\nrequired to calibrate the photo-z probability distribution. Previous work has\nassumed a simple Gaussian distribution of photo-z errors; here we describe a\nmethod for constraining an arbitrary parametric photo-z error model. As an\nexample we allow the photo-z probability distribution to be the sum of $N_g$\nGaussians. To limit cosmological degradation to a fixed level, photo-z models\nwith multiple Gaussians require up to 5 times larger calibration sample than\none would estimate from assuming a single-Gaussian model. This degradation\nsaturates at $N_g\\approx 4$. Assuming a single Gaussian when the photo-z\ndistribution has multiple parameters underestimates cosmological parameter\nuncertainties by up to 35%. The size of required calibration sample also\ndepends upon the shape of the fiducial distribution, even when the RMS photo-z\nerror is held fixed. The required calibration sample size varies up to a factor\nof 40 among the fiducial models studied, but this is reduced to a factor of a\nfew if the photo-z parameters are forced to be slowly varying with redshift.\nFinally we show that the size of the required calibration sample can be\nsubstantially reduced by optimizing its redshift distribution. We hope this\nstudy will help stimulate work on better understanding of photo-z errors. \n\n"}
{"id": "0801.1985", "contents": "Title: Generalizing TeVeS Cosmology Abstract: I consider an extented version of Bekenstein's Tensor-Vector-Scalar theory\nwhere the action of the vector field is of a general Einstein-Ether form. This\nwork presents the cosmological equations of this theory, both at the background\nand perturbed level, for scalar, vector and tensor perturbation modes. By\nsolving the background equations in the radiation era analytically, to an\nexcellent approximation, I construct the primordial adiabatic perturbation for\na general family of scalar field kinetic functions. \n\n"}
{"id": "0802.2308", "contents": "Title: Three-dimensional Simulations of Accretion to Stars with Complex\n  Magnetic Fields Abstract: Disk accretion to rotating stars with complex magnetic fields is investigated\nusing full three-dimensional magnetohydrodynamic (MHD) simulations. The studied\nmagnetic configurations include superpositions of misaligned dipole and\nquadrupole fields and off-centre dipoles. The simulations show that when the\nquadrupole component is comparable to the dipole component, the magnetic field\nhas a complex structure with three major magnetic poles on the surface of the\nstar and three sets of loops of field lines connecting them. A significant\namount of matter flows to the quadrupole \"belt\", forming a ring-like hot spot\non the star. If the maximum strength of the magnetic field on the star is\nfixed, then we observe that the mass accretion rate, the torque on the star,\nand the area covered by hot spots are several times smaller in the\nquadrupole-dominant cases than in the pure dipole cases. The influence of the\nquadrupole component on the shape of the hot spots becomes noticeable when the\nratio of the quadrupole and dipole field strengths $B_q/B_d\\gtrsim0.5$, and\nbecomes dominant when $B_q/B_d\\gtrsim1$. In the case of an off-centre dipole\nfield, most of the matter flows through a one-armed accretion stream, forming a\nlarge hot spot on the surface, with a second much smaller secondary spot. The\nlight curves may have simple, sinusoidal shapes, thus mimicking stars with pure\ndipole fields. Or, they may be complex and unusual. In some cases the light\ncurves may be indicators of a complex field, in particular if the inclination\nangle is known independently. We also note that in the case of complex fields,\nmagnetospheric gaps are often not empty, and this may be important for the\nsurvival of close-in exosolar planets. \n\n"}
{"id": "0804.0406", "contents": "Title: Composition of Ices in Low-Mass Extrasolar Planets Abstract: We study the formation conditions of icy planetesimals in protoplanetary\ndisks in order to determine the composition of ices in small and cold\nextrasolar planets. Assuming that ices are formed from hydrates, clathrates,\nand pure condensates, we calculate their mass fractions with respect to the\ntotal quantity of ices included in planetesimals, for a grid of disk models. We\nfind that the composition of ices weakly depends on the adopted disk\nthermodynamic conditions, and is rather influenced by the initial composition\nof the gas phase. The use of a plausible range of molecular abundance ratios\nand the variation of the relative elemental carbon over oxygen ratio in the gas\nphase of protoplanetary disks, allow us to apply our model to a wide range of\nplanetary systems. Our results can thus be used to constrain the icy/volatile\nphase composition of cold planets evidenced by microlensing surveys,\nhypothetical ocean-planets and carbon planets, which could be detected by Corot\nor Kepler. \n\n"}
{"id": "0806.0925", "contents": "Title: Swift uncovers that SAX J0840.7+2248 is not an X-ray Binary, but\n  BeppoSAX X-ray Rich GRB 980429 Abstract: During our Swift/XRT program to obtain X-ray positions at arcsecond level for\na sample of Galactic X-ray binaries, we discovered that SAX J0840.7+2248 is not\na binary, but rather BeppoSAX/WFC+GRBM X-ray Rich GRB 980429. Here we report on\nthis discovery and on the properties of this long, X-ray rich gamma-ray burst,\nfrom prompt to (very) late followup. \n\n"}
{"id": "0809.1364", "contents": "Title: Biases on the cosmological parameters and thermal SZ residuals Abstract: We examine the biases induced on cosmological parameters when the presence of\nsecondary anisotropies is not taken into account in Cosmic Microwave Background\nanalyses. We first develop an exact analytical expression for computing the\nbiases on parameters when any additive signal is neglected in the analysis. We\nthen apply it in the context of the forthcoming Planck experiment. For\nillustration, we investigate the effect of the sole residual thermal\nSunyaev--Zel'dovich signal that remains after cluster extraction. We find in\nparticular that analyses neglecting the presence of this contribution introduce\non the cosmological parameters n_s and tau biases, at least 6.5 and 2.9 times\ntheir one sigma confidence intervals. The Omega_b parameter is also biased to a\nlesser extent. \n\n"}
{"id": "0809.2507", "contents": "Title: On the chemical evolution of the Milky Way Abstract: I discuss three different topics concerning the chemical evolution of the\nMilky Way (MW). 1) The metallicity distribution of the MW halo; it is shown\nthat this distribution can be analytically derived in the framework of the\nhierarchical merging scenario for galaxy formation, assuming that the component\nsub-haloes had chemical properties similar to those of the progenitors of\nsatellite galaxies of the MW. 2) The age-metallicity relationship (AMR) in the\nsolar neighborhood; I argue for caution in deriving from data with important\nuncertainties (such as the age uncertainties in the Geneva-Kopenhaguen survey)\na relationship between average metallicity and age: derived relationships are\nshown to be systematically flatter than the true ones and should not be\ndirectly compared to models. 3) The radial mixing of stars in the disk, which\nmay have important effects on various observables (scatter in AMR, extension of\nthe tails of the metallicity distribution, flatenning of disk abundance\nprofiles). Recent SPH + N-body simulations find considerable radial mixing, but\nonly comparison to observations will ultimately determine the extent of that\nmixing. \n\n"}
{"id": "0810.0190", "contents": "Title: Dynamical Dark Energy simulations: high accuracy Power Spectra at high\n  redshift Abstract: Accurate predictions on non--linear power spectra, at various redshift z,\nwill be a basic tool to interpret cosmological data from next generation mass\nprobes, so obtaining key information on Dark Energy nature. This calls for high\nprecision simulations, covering the whole functional space of w(z) state\nequations and taking also into account the admitted ranges of other\ncosmological parameters; surely a difficult task. A procedure was however\nsuggested, able to match the spectra at z=0, up to k~3, hMpc^{-1}, in\ncosmologies with an (almost) arbitrary w(z), by making recourse to the results\nof N-body simulations with w = const. In this paper we extend such procedure to\nhigh redshift and test our approach through a series of N-body gravitational\nsimulations of various models, including a model closely fitting WMAP5 and\ncomplementary data. Our approach detects w= const. models, whose spectra meet\nthe requirement within 1% at z=0 and perform even better at higher redshift,\nwhere they are close to a permil precision. Available Halofit expressions,\nextended to (constant) w \\neq -1 are unfortunately unsuitable to fit the\nspectra of the physical models considered here. Their extension to cover the\ndesired range should be however feasible, and this will enable us to match\nspectra from any DE state equation. \n\n"}
{"id": "0810.1092", "contents": "Title: A microlensing study of the accretion disc in the quasar MG 0414+0534 Abstract: Observations of gravitational microlensing in multiply imaged quasars\ncurrently provide the only direct probe of quasar emission region structure on\nsub-microarcsecond scales. Analyses of microlensing variability are\nobservationally expensive, requiring long-term monitoring of lensed systems.\nHere we demonstrate a technique for constraining the size of the quasar\ncontinuum emission region as a function of wavelength using single-epoch\nmulti-band imaging. We have obtained images of the lensed quasar MG 0414+0534\nin five wavelength bands using the Magellan 6.5-metre Baade telescope at Las\nCampanas Observatory, Chile. These data, in combination with two existing\nepochs of Hubble Space Telescope data, are used to model the size of the\ncontinuum emission region $\\sigma$ as a power-law in wavelength,\n$\\sigma\\propto\\lambda^\\nu$. We place an upper limit on the Gaussian width of\nthe $r^\\prime$-band emission region of $1.80 \\times 10^{16} h_{70}^{-1/2}\n(<M>/\\rmn{M}_{\\odot})^{1/2}$cm, and constrain the power-law index to\n$0.77\\leq\\nu\\leq2.67$ (95 per cent confidence range). These results can be used\nto constrain models of quasar accretion discs. As a example, we find that the\naccretion disc in MG 0414+0534 is statistically consistent with a\nShakura-Sunyaev thin disc model. \n\n"}
{"id": "0810.3409", "contents": "Title: Cosmic Ray Results from the IceTop Air Shower Array Abstract: We report on the first results obtained with the IceTop air shower array on\nthe cosmic ray energy spectrum and mass composition in the range of 1 PeV to 80\nPeV. IceTop is the surface detector of the IceCube neutrino telescope currently\nunder construction at the South Pole. A high sensitivity to the primary mass\ncomposition was observed by reconstructing showers at different zenith angles.\nAssuming only protons or iron nuclei as primary particles yields significantly\ndifferent energy spectra for different zenith angle ranges, while only models\nwith mixed composition, like the poly-gonato model, lead to the expected\nisotropic flux. The prospects of composition measurements with different,\nalternative methods using the full IceCube detector are also discussed. \n\n"}
{"id": "0810.4150", "contents": "Title: Determining Star Formation Rates for Infrared Galaxies Abstract: We show that measures of star formation rates (SFRs) for infrared galaxies\nusing either single-band 24 um or extinction-corrected Paschen-alpha\nluminosities are consistent in the total infrared luminosity = L(TIR) ~ 10^10\nL_sun range. MIPS 24 micron photometry can yield star formation rates\naccurately from this luminosity upward: SFR(M_sun/yr) = 7.8 x 10^-10 L(24 um,\nL_sun) from L(TIR) = 5 x 10^9 L_sun to 10^11 L_sun, and SFR = 7.8 x 10^-10 L(24\num, L_sun) x (7.76 x 10^-11 L(24))^0.048 for higher L(TIR). For galaxies with\nL(TIR) >= 10^10 L_sun, these new expressions should provide SFRs to within 0.2\ndex. For L(TIR) >= 10^11 L_sun, we find that the SFR of infrared galaxies is\nsignificantly underestimated using extinction-corrected Pa-alpha (and\npresumably using any other optical or near infrared recombination lines). As a\npart of this work, we constructed spectral energy distribution (SED) templates\nfor eleven luminous and ultraluminous purely star forming infrared galaxies\n(LIRGs and ULIRGs) and over the spectral range 0.4 microns to 30 cm. We use\nthese templates and the SINGS data to construct average templates from 5\nmicrons to 30 cm for infrared galaxies with L(TIR) = 5 x 10^9 to 10^13 L_sun.\nAll of these templates are made available on line. \n\n"}
{"id": "0810.4201", "contents": "Title: Interchanging Interactive 3-d Graphics for Astronomy Abstract: We demonstrate how interactive, three-dimensional (3-d) scientific\nvisualizations can be efficiently interchanged between a variety of mediums.\nThrough the use of an appropriate interchange format, and a unified interaction\ninterface, we minimize the effort to produce visualizations appropriate for\nundertaking knowledge discovery at the astronomer's desktop, as part of\nconference presentations, in digital publications or as Web content. We use\nexamples from cosmological visualization to address some of the issues of\ninterchange, and to describe our approach to adapting S2PLOT desktop\nvisualizations to the Web.\n  Supporting demonstrations are available at\nhttp://astronomy.swin.edu.au/s2plot/interchange/ \n\n"}
{"id": "0811.0576", "contents": "Title: HD 271791: An Extreme Supernova Runaway B Star Escaping from the Galaxy Abstract: Hyper-velocity stars (HVSs) were first predicted by theory to be the result\nof the tidal disruption of a binary system by a super-massive black hole (SMBH)\nthat accelerates one component to beyond the Galactic escape velocity (the\nHills mechanism). Because the Galactic centre hosts such a SMBH it is the\nsuggested place of origin for HVSs. However, the SMBH paradigm has been\nchallenged recently by the young HVS HD271791 because its kinematics point to a\nbirthplace in the metal-poor rim of the Galactic disc. Here we report the\natmosphere of HD271791 to indeed show a sub-solar iron abundance along with an\nenhancement of the alpha-elements, indicating capture of nucleosynthesis\nproducts from a supernova or a more energetic hypernova. This implies that\nHD271791 is the surviving secondary of a massive binary system disrupted in a\nsupernova explosion. No such run-away star has ever been found to exceed the\nGalactic escape velocity, hence HD271791 is the first hyper-runaway star. Such\na run-away scenario is an alternative to the Hills mechanism for the\nacceleration of some HVSs with moderate velocities. The observed chemical\ncomposition of HD271791 puts invaluable observational constraints on\nnucleosynthesis in a supernova from the core-collapse of a very massive star\n(M_ZAMS >= 55 M_Sun), which may be observed as a gamma-ray burst of the\nlong-duration/soft-spectrum type. \n\n"}
{"id": "0812.2442", "contents": "Title: Dark matter from SUGRA GUTs: mSUGRA, NUSUGRA and Yukawa-unified SUGRA Abstract: Gravity-mediated SUSY breaking models with R-parity conservation give rise to\ndark matter in the universe. I review neutralino dark matter in the minimal\nsupergravity model (mSUGRA), models with non-universal soft SUSY breaking terms\n(NUSUGRA) which yield a well-tempered neutralino, and models with unified\nYukawa couplings at the GUT scale (as may occur in an SO(10) SUSY GUT theory).\nThese latter models have difficulty accommodating neutralino dark matter, but\nwork very well if the dark matter particles are axions and axinos. \n\n"}
{"id": "0812.3669", "contents": "Title: Enabling Next Generation Dark Energy and Epoch of Reionization Radio\n  Observatories with the MOFF Correlator Abstract: Proposed 21 cm cosmology observatories for studying the epoch of reionization\n(z ~6-15) and dark energy (z ~0-6) envision compact arrays with tens of\nthousands of antenna elements. Fully correlating this many elements is\ncomputationally expensive using traditional XF or FX correlators, and has led\nsome groups to reconsider direct imaging/FFT correlators. In this paper we\ndevelop a variation of the direct imaging correlator we call the MOFF\ncorrelator. The MOFF correlator shares the computational advantages of a direct\nimaging correlator, while avoiding a number of its shortcomings. In particular\nthe MOFF correlator makes no constraints on the antenna arrangement or type,\nprovides a fully calibrated output image including widefield polarimetry and\nnon-coplanar baseline effects, and can be orders-of-magnitude more efficient\nthan XF or FX correlators for compact radio cosmology arrays. \n\n"}
{"id": "0812.4817", "contents": "Title: 3D Spectroscopic Study of the Line Emitting Regions of Mrk 493 Abstract: We report the results of 3D spectroscopic observations of Mrk 493 (NLS1\ngalaxy) with the integral-field spectrograph MPFS of the SAO RAS 6-m telescope.\nThe difference in the slope of the optical continuum emission intensity across\nthe nucleus part and an extensive continuum emission region} is detected. The\nemission in lines (H$\\alpha$, H$\\beta$, [OIII], etc.) coincides with a\ncomposite nuclear region: an AGN plus a circum-nuclear star-forming ring\nobserved in the HST UV/optical images. The [SII] emission region tends to be up\nto 1kpc around the center. The H$\\alpha$ and H$\\beta$ could be decomposed into\nthree components (broad $\\sim$ 2000 km/s. intermediate $\\sim$ 700 km/s and\nnarrow $\\sim$ 250 km/s). We found that width ($\\sim$ 750 km/s) of the Fe II\nlines correspond to the intermediate component, that may indicate a non-BLR\norigin of the Fe II lines, or that a large fraction of the Fe II emission arise\nin the outher parts of the BLR. The weak broad component detected in the\nH$\\alpha$, H$\\beta$ and He$\\lambda$4686 may come from the unresolved central\nBLR, but also partly produced by violent starburst in the circum-nuclear ring.\nMoreover, diagnostic diagrams clearly show presence of the HII regions (not a\nSy 1 nucleus) in the NLR of Mrk 493. \n\n"}
{"id": "0901.0922", "contents": "Title: Model independent analysis of dark matter points to a particle mass at\n  the keV scale Abstract: We present a model independent analysis of dark matter (DM) both decoupling\nultra relativistic (UR) and non-relativistic (NR) based in the phase-space\ndensity D = rho_{DM}/sigma^3_{DM}. We derive explicit formulas for the DM\nparticle mass m and for the number of ultra relativistic degrees of freedom g_d\nat decoupling. We find that for DM particles decoupling UR both at local\nthermal equilibrium (LTE) and out of LTE, m turns to be at the keV scale. For\nexample, for DM Majorana fermions decoupling at LTE the mass results m ~ 0.85\nkeV. For DM particles decoupling NR, sqrt{m T_d} results in the keV scale (T_d\nis the decoupling temperature) and the m value is consistent with the keV\nscale. In all cases, DM turns to be cold DM (CDM). Also, lower and upper bounds\non the DM annihilation cross-section for NR decoupling are derived. We evaluate\nthe free-streaming (Jeans') length and Jeans' mass: they result independent of\nthe type of DM except for the DM self-gravity dynamics. The free-streaming\nlength today results in the kpc range. These results are based on our\ntheoretical analysis, astronomical observations of dwarf spheroidal satellite\ngalaxies in the Milky Way and N-body numerical simulations. We analyze and\ndiscuss the results on D from analytic approximate formulas both for linear\nfluctuations and the (non-linear) spherical model and from N-body simulations\nresults. We obtain in this way upper bounds for the DM particle mass which all\nresult below the 100 keV range. \n\n"}
{"id": "0901.1049", "contents": "Title: The hunt for cosmic neutrino sources with IceCube Abstract: IceCube is a cubic-kilometer neutrino telescope under construction at the\ngeographic South Pole. Once completed it will comprise 4800 optical sensors\ndeployed on 80 vertical strings at depths in the ice between 1450 and 2450\nmeters. Part of the array is already operational and data was recorded in the\nconfigurations with 9 (year 2006/2007), 22 (year 2007/2008) and 40-strings\n(year 2008/2009) respectively. Here we report preliminary results on the search\nfor point-like neutrino sources using data collected with the first 22 strings\n(IC-22). \n\n"}
{"id": "0901.1888", "contents": "Title: The Equation of State of the Intergalactic Medium After Hydrogen\n  Reionization Abstract: We use an analytic model to study how inhomogeneous hydrogen reionization\naffects the temperature distribution of the intergalactic medium (IGM). During\nthis process, the residual energy of each ionizing photon is deposited in the\nIGM as heat, increasing its temperature to 20,000-30,000 K; subsequent\nexpansion of the Universe then cools the gas. Because reionization most likely\nproceeds from high to low densities, underdense voids are ionized last, have\nless time to cool, and are (on average) warmer than mean-density gas\nimmediately after reionization is complete (an \"inverted\" equation of state).\n  From this initial configuration, the low-density gas cools quickly and\neventually returns to a more normal equation of state. The rapidly evolving\ntemperature introduces systematic uncertainties in measurements of the ionizing\nbackground at z~6. For example, late reionization implies rapid cooling, so\nthat the ionizing background would have to evolve even more rapidly at z ~5-6\nthan typically claimed. This degeneracy is difficult to disentangle, because\nthe Lyman-alpha forest probes only a narrow range in densities (over which the\ngas is nearly isothermal). However, higher Lyman-series transitions probe wider\ndensity ranges, sampling different effective temperatures, and offer a new way\nto measure the IGM equation of state that should work where nearly saturated\nabsorption precludes other methods. This will help to separate evolution in\ntemperature from that in the ionizing background. While more detailed study\nwith hydrodynamic simulations is needed, we show that such measurements could\npotentially distinguish early and late reionization using only a handful of\nlines of sight. \n\n"}
{"id": "0901.2664", "contents": "Title: Neutrino Astronomy in the Ice Abstract: The South Pole is an optimal location for hosting astrophysical\nobservatories. The status of the construction of the IceCube Observatory and\nsome selected physics results will be discussed. Moreover prospects for\ndetection of Ultra-High Energy cosmogenic neutrinos and techniques that can\naddress this energy region will be considered. \n\n"}
{"id": "0901.2676", "contents": "Title: Spacetime Singularities in String and its Low Dimensional Effective\n  Theory Abstract: Spacetime singularities are studied in both the $D+d$-dimensional string\ntheory and its $D$-dimensional effective theory, obtained by the Kaluza-Klein\ncompactification. It is found that spacetime singularities in the low\ndimensional effective theory may or may not remain after lifted to the\n$D+d$-dimensional string theory, depending on particular solutions. It is also\nfound that there exist cases in which spacetime singularities appearing in\nhigh/low dimensional spacetimes do not necessarily happen on the same surfaces. \n\n"}
{"id": "0901.2834", "contents": "Title: Deep wide-field GMRT surveys at 610 MHz Abstract: The GMRT has been used to make deep, wide-field surveys of several fields at\n610 MHz, with a resolution of about 5 arcsec. These include the Spitzer\nExtragalactic First Look Survey field, where 4 square degrees were observed\nwith a r.m.s. sensitivity of about 30 microJy/beam, and several SWIRE fields\n(namely the Lockman Hole, ELAIS-N1 and N2 fields) covering more than 20 square\ndegrees with a sensitivity of about 80 microJy beam or better. The analysis of\nthese observations, and some of the science results are described. \n\n"}
{"id": "0901.3557", "contents": "Title: Optimal PSF modeling for weak lensing: complexity and sparsity Abstract: We investigate the impact of point spread function (PSF) fitting errors on\ncosmic shear measurements using the concepts of complexity and sparsity.\nComplexity, introduced in a previous paper, characterizes the number of degrees\nof freedom of the PSF. For instance, fitting an underlying PSF with a model\nwith low complexity will lead to small statistical errors on the model\nparameters, however these parameters could suffer from large biases.\nAlternatively, fitting with a large number of parameters will tend to reduce\nbiases at the expense of statistical errors. We perform an optimisation of\nscatters and biases by studying the mean squared error of a PSF model. We also\ncharacterize a model sparsity, which describes how efficiently the model is\nable to represent the underlying PSF using a limited number of free parameters.\nWe present the general case and illustrate it for a realistic example of PSF\nfitted with shapelet basis sets. We derive the relation between complexity and\nsparsity of the PSF model, signal-to-noise ratio of stars and systematic errors\non cosmological parameters. With the constraint of maintaining the systematics\nbelow the statistical uncertainties, this lead to a relation between the\nrequired number of stars to calibrate the PSF and the sparsity. We discuss the\nimpact of our results for current and future cosmic shear surveys. In the\ntypical case where the biases can be represented as a power law of the\ncomplexity, we show that current weak lensing surveys can calibrate the PSF\nwith few stars, while future surveys will require hard constraints on the\nsparsity in order to calibrate the PSF with 50 stars. \n\n"}
{"id": "0902.0631", "contents": "Title: The Crab optical and ultraviolet polarimetry Abstract: Polarisation measurements of pulsars and of their pulsar wind nebulae (PWNe)\nare uniquely able to provide deep insights into the highly magnetised\nrelativistic environment of young, rotation-powered isolated neutron stars\n(INSs). Besides the radio band, optical observations are primarily suited to\nproviding such insights. The first INS for which optical polarisation\nobservations were performed is the Crab pulsar which is also the brightest one\n(V=16.5). For this reason, the Crab pulsar is also the only INS for which\nrepeated, phase-resolved polarisation measurements have been performed through\nthe years. Moreover, it is the only case, together with the much fainter and\ndistant PSR B0540-69 in the Large Magellanic Cloud (LMC), of an optical pulsar\nembedded in an optical PWN. Thus, the Crab is a perfect test case to study the\noptical polarisation properties of pulsars and of their PWNe. In this paper, we\nreview the polarisation properties of the Crab pulsar and of its PWN in the\noptical and ultraviolet domains, we summarise the state of the art of the\npolarisation observations of other INSs, and we outline perspectives for INS\npolarisation studies with present and future generations of optical telescopes \n\n"}
{"id": "0902.1177", "contents": "Title: Effects of Alpha-Element Enhancement and the Thermally\n  Pulsing-Asymptotic Giant Branch on Surface Brightness Fluctuation Magnitudes\n  and Broadband Colors Abstract: We investigate the effects of alpha-element enhancement and the thermally\npulsing-asymptotic giant branch (TP-AGB) stars on the surface brightness\nfluctuation (SBF) magnitudes and broadband colors of simple stellar populations\nand compare to the empirical calibrations. We consider a broad range of ages\nand metallicities using the recently updated Teramo BaSTI isochrones. We find\nthat the alpha-element enhanced I-band SBF magnitudes are about 0.35 mag\nbrighter and their integrated V - I colors are about 0.02 mag redder, mostly\nbecause of oxygen enhancement effects on the upper red giant branch and\nasymptotic giant branch. We also demonstrate, using both the Teramo BaSTI and\nPadova isochrones, the acute sensitivity of SBF magnitudes to the presence of\nTP-AGB stars, particularly in the near-IR, but in the I-band as well. Empirical\nSBF trends therefore hold great promise for constraining this important but\nstill highly uncertain stage of stellar evolution. In a similar vein,\nnon-negligible disparities are found among several different models available\nin the literature due to intrinsic model uncertainties. \n\n"}
{"id": "0902.2437", "contents": "Title: AMiBA: System Performance Abstract: The Y.T. Lee Array for Microwave Background Anisotropy (AMiBA) started\nscientific operation in early 2007. This work describes the optimization of the\nsystem performance for the measurements of the Sunyaev-Zel'dovich effect for\nsix massive galaxy clusters at redshifts $0.09 - 0.32$. We achieved a point\nsource sensitivity of $63\\pm 7$ mJy with the seven 0.6m dishes in 1 hour of\non-source integration in 2-patch differencing observations. We measured and\ncompensated for the delays between the antennas of our platform-mounted\ninterferometer. Beam switching was used to cancel instrumental instabilities\nand ground pick up. Total power and phase stability were good on time scales of\nhours, and the system was shown to integrate down on equivalent timescales of\n300 hours per baseline/correlation, or about 10 hours for the entire array.\nWhile the broadband correlator leads to good sensitivity, the small number of\nlags in the correlator resulted in poorly measured bandpass response. We\ncorrected for this by using external calibrators (Jupiter and Saturn). Using\nJupiter as the flux standard, we measured the disk brightness temperature of\nSaturn to be $149^{+5}_{-12}$ K. \n\n"}
{"id": "0902.3610", "contents": "Title: Axionic dark energy and a composite QCD axion Abstract: We discuss the idea that the model-independent (MI) axion of string theory is\nthe source of quintessential dark energy. The scenario is completed with a\ncomposite QCD axion from hidden sector squark condensation that could serve as\ndark matter candidate. The mechanism relies on the fact that the hidden sector\nanomaly contribution to the composite axion is much smaller than the QCD\nanomaly term. This intuitively surprising scenario is based on the fact that\nbelow the hidden sector scale $\\Lambda_h$ there are many light hidden sector\nquarks. Simply, by counting engineering dimensions the hidden sector instanton\npotential can be made negligible compared to the QCD anomaly term. \n\n"}
{"id": "0902.4103", "contents": "Title: Quasar Optical Variability in the Palomar-QUEST Survey Abstract: The ensemble variability properties of nearly 23,000 quasars are studied\nusing the Palomar-QUEST Survey. The survey has covered 15,000 square degrees\nmultiple times over 3.5 years using 7 optical filters, and has been calibrated\nspecifically for variability work. Palomar-QUEST allows for the study of rare\nobjects using multiple epochs of consistently calibrated, homogeneous data,\nobviating the common problem of generating comparable measurements from\ndisparate datasets. A power law fit to the quasar structure function versus\ntime yields an index of 0.432 +/- 0.024 for our best measured sample. We see\nthe commonly reported anticorrelation between average optical variability\namplitude and optical luminosity, and measure the logarithmic decrease in\nvariability amplitude to scale as the logarithm of the luminosity times 0.205\n+/- 0.002. Black hole mass is positively correlated with variability amplitude\nover three orders of magnitude in mass. Quasar variability amplitude is seen to\ndecrease with Eddington ratio as a step function with a transition around\nEddington ratio of 0.5. The higher variability at low Eddington ratios is due\nto excess power at timescales shorter than roughly 300 days. X-ray and radio\nmeasurements exist for subsets of the quasar sample. We observe an\nanticorrelation between optical variability amplitude and X-ray luminosity. No\nsignificant correlation is seen between average optical variability properties\nand radio luminosity. The timescales of quasar fluctuations are suggestive of\naccretion disk instabilities. The relationships seen between variability,\nEddington ratio, and radio and X-ray emission are discussed in terms of a\npossible link between the behavior of quasars and black hole X-ray binaries. \n\n"}
{"id": "0902.4636", "contents": "Title: How well do STARLAB and NBODY4 compare? I: Simple models Abstract: N-body simulations are widely used to simulate the dynamical evolution of a\nvariety of systems, among them star clusters. Much of our understanding of\ntheir evolution rests on the results of such direct N-body simulations. They\nprovide insight in the structural evolution of star clusters, as well as into\nthe occurrence of stellar exotica. Although the major pure N-body codes\nSTARLAB/KIRA and NBODY4 are widely used for a range of applications, there is\nno thorough comparison study yet. Here we thoroughly compare basic quantities\nas derived from simulations performed either with STARLAB/KIRA or NBODY4.\n  We construct a large number of star cluster models for various stellar mass\nfunction settings (but without stellar/binary evolution, primordial binaries,\nexternal tidal fields etc), evolve them in parallel with STARLAB/KIRA and\nNBODY4, analyse them in a consistent way and compare the averaged results\nquantitatively. For this quantitative comparison we develop a bootstrap\nalgorithm for functional dependencies.\n  We find an overall excellent agreement between the codes, both for the\nclusters' structural and energy parameters as well as for the properties of the\ndynamically created binaries. However, we identify small differences, like in\nthe energy conservation before core collapse and the energies of escaping\nstars, which deserve further studies. Our results reassure the comparability\nand the possibility to combine results from these two major N-body codes, at\nleast for the purely dynamical models (i.e. without stellar/binary evolution)\nwe performed. (abridged) \n\n"}
{"id": "0903.0949", "contents": "Title: Study of the acoustic signature of UHE neutrino interactions in water\n  and ice Abstract: The production of acoustic signals from the interactions of ultra-high energy\n(UHE) cosmic ray neutrinos in water and ice has been studied. A new\ncomputationally fast and efficient method of deriving the signal is presented.\nThis method allows the implementation of up to date parameterisations of\nacoustic attenuation in sea water and ice that now includes the effects of\ncomplex attenuation, where appropriate. The methods presented here have been\nused to compute and study the properties of the acoustic signals which would be\nexpected from such interactions. A matrix method of parameterising the signals,\nwhich includes the expected fluctuations, is also presented. These methods are\nused to generate the expected signals that would be detected in acoustic UHE\nneutrino telescopes. \n\n"}
{"id": "0903.1092", "contents": "Title: The anatomy of the NGC 5044 group -- II. Stellar populations and\n  star-formation histories Abstract: The distribution of galaxy properties in groups and clusters holds important\ninformation on galaxy evolution and growth of structure in the Universe. While\nclusters have received appreciable attention in this regard, the role of groups\nas fundamental to formation of the present day galaxy population has remained\nrelatively unaddressed. Here we present stellar ages, metallicities and\nalpha-element abundances derived using Lick indices for 67 spectroscopically\nconfirmed members of the NGC 5044 galaxy group with the aim of shedding light\non galaxy evolution in the context of the group environment.\n  We find that galaxies in the NGC 5044 group show evidence for a strong\nrelationship between stellar mass and metallicity, consistent with their\ncounterparts in both higher and lower mass groups and clusters. Galaxies show\nno clear trend of age or alpha-element abundance with mass, but these data form\na tight sequence when fit simultaneously in age, metallicity and stellar mass.\nIn the context of the group environment, our data support the tidal disruption\nof low-mass galaxies at small group-centric radii, as evident from an apparent\nlack of galaxies below ~10^9 M_sun within ~100 kpc of the brightest group\ngalaxy. Using a joint analysis of absorption- and emission-line metallicities,\nwe are able to show that the star-forming galaxy population in the NGC 5044\ngroup appears to require gas removal to explain the ~1.5 dex offset between\nabsorption- and emission-line metallicities observed in some cases. A\ncomparison with other stellar population properties suggests that this gas\nremoval is dominated by galaxy interactions with the hot intragroup medium. \n\n"}
{"id": "0903.1420", "contents": "Title: The cosmic microwave background temperature bispectrum from scalar\n  perturbations induced by primordial magnetic fields Abstract: We evaluate the angular bispectrum of the CMB temperature anisotropy at large\nangular scale due to a stochastic background of primordial magnetic fields. The\nshape of non-Gaussianity depends on the spectral index of the magnetic field\npower spectrum and is peaked in the squeezed configuration for a\nscale-invariant magnetic spectrum. By using the large angular part of the\nbispectrum generated by magnetic fields, the present bounds on non-Gaussianity\nset a limit on the amplitude of the primordial magnetic field of the order of\n10 nGauss for the scale-invariant case and 20 nGauss for the other spectral\nindexes. \n\n"}
{"id": "0903.1937", "contents": "Title: Bulge formation by the coalescence of giant clumps in primordial disk\n  galaxies Abstract: The observations and evolution of clumpy, high-redshift galaxies are\nreviewed. Models suggest that the clumps form by gravitational instabilities in\na gas-rich disk, interact with each other gravitationally, and then merge in\nthe center where they form a bulge. The model requires smooth gas accretion\nduring galaxy growth. \n\n"}
{"id": "0903.2068", "contents": "Title: Data boundary fitting using a generalised least-squares method Abstract: In many astronomical problems one often needs to determine the upper and/or\nlower boundary of a given data set. An automatic and objective approach\nconsists in fitting the data using a generalised least-squares method, where\nthe function to be minimized is defined to handle asymmetrically the data at\nboth sides of the boundary. In order to minimise the cost function, a numerical\napproach, based on the popular downhill simplex method, is employed. The\nprocedure is valid for any numerically computable function. Simple polynomials\nprovide good boundaries in common situations. For data exhibiting a complex\nbehaviour, the use of adaptive splines gives excellent results. Since the\ndescribed method is sensitive to extreme data points, the simultaneous\nintroduction of error weighting and the flexibility of allowing some points to\nfall outside of the fitted frontier, supplies the parameters that help to tune\nthe boundary fitting depending on the nature of the considered problem. Two\nsimple examples are presented, namely the estimation of spectra\npseudo-continuum and the segregation of scattered data into ranges. The\nnormalisation of the data ranges prior to the fitting computation typically\nreduces both the numerical errors and the number of iterations required during\nthe iterative minimisation procedure. \n\n"}
{"id": "0903.2814", "contents": "Title: On the peculiar momentum of baryons after Reionization Abstract: The peculiar motion of ionized baryons is known to introduce temperature\nanisotropies in the CMB by means of the kinetic Sunyaev-Zel'dovich effect\n(kSZ). In this work, we present an all sky computation of angular power\nspectrum of the temperature anisotropies introduced by kSZ momentum of all\nbaryons in the Universe during and after reionization. In an attempt to study\nthe bulk flows of the missing baryons not yet detected, we address separately\nthe contribution from all baryons in the IGM and those baryons located in\ncollapsed structures like groups and clusters of galaxies. In the first case,\nour approach provides a complete, all sky computation of the kSZ in second\norder of cosmological perturbation theory (also known as the Ostriker-Vishniac\neffect, OV). Most of the power of OV is generated during reionization, although\nit has a non-negligible tail at low redshifts, when the bulk of the kSZ\npeculiar momentum of the halo (cluster + group) population arises. If gas\noutside halos is comoving with clusters as the theory predicts, then the\nsignature of the bulk flows of the missing baryons should be recovered by a\ncross-correlation analysis of future CMB data sets with kSZ estimates in\nclusters of galaxies. For an ACT or SPT type of CMB experiment, all sky kSZ\nestimates of all clusters above $2\\times 10^{14} h^{-1}M_{\\odot}$ should\nprovide a detection of {\\it dark} flows with signal to noise ratio (S/N) of\n$\\sim 10$, (S/N $\\sim 2.5-5$ for 2,000 - 10,000 square degrees). Improving kSZ\nestimates with data from Large Scale Structure surveys should enable a deeper\nconfrontation of the theoretical predictions for bulk flows with observations.\nThe combination of future CMB and optical data should shed light on the dark\nflows of the nearby, so far undetected, diffuse baryons. \n\n"}
{"id": "0903.2979", "contents": "Title: ULySS: A Full Spectrum Fitting Package Abstract: Aims. We provide an easy-to-use full-spectrum fitting package and explore its\napplications to (i) the determination of the stellar atmospheric parameters and\n(ii) the study of the history of stellar populations. Methods. We developed\nULySS, a package to fit spectroscopic observations against a linear combination\nof non-linear model components convolved with a parametric line-of-sight\nvelocity distribution. The minimization can be either local or global, and\ndetermines all the parameters in a single fit. We use chi2 maps, convergence\nmaps and Monte-Carlo simulations to study the degeneracies, local minima and to\nestimate the errors. Results. We show the importance of determining the shape\nof the continuum simultaneously to the other parameters by including a\nmultiplicative polynomial in the model (without prior pseudo-continuum\ndetermination, or rectification of the spectrum). We also stress the benefice\nof using an accurate line-spread function, depending on the wavelength, so that\nthe line-shape of the models properly match the observation. For simple models,\ni. e., to measure the atmospheric parameters or the age/metallicity of a\nsingle-age stellar population, there is often a unique minimum, or when local\nminima exist they can unambiguously be recognized. For more complex models,\nMonte-Carlo simulations are required to assess the validity of the solution.\nConclusions. The ULySS package is public, simple to use and flexible. The full\nspectrum fitting makes optimal usage of the signal. \n\n"}
{"id": "0903.3411", "contents": "Title: An optical group catalogue to z = 1 from the zCOSMOS 10k sample Abstract: We present a galaxy group catalogue spanning the redshift range 0.1 <~ z <~ 1\nin the ~1.7 deg^2 COSMOS field, based on the first ~10,000 zCOSMOS spectra. The\nperformance of both the Friends-of-Friends (FOF) and Voronoi-Delaunay-Method\n(VDM) approaches to group identification has been extensively explored and\ncompared using realistic mock catalogues. We find that the performance improves\nsubstantially if groups are found by progressively optimizing the group-finding\nparameters for successively smaller groups, and that the highest fidelity\ncatalogue, in terms of completeness and purity, is obtained by combining the\nindependently created FOF and VDM catalogues. The final completeness and purity\nof this catalogue, both in terms of the groups and of individual members,\ncompares favorably with recent results in the literature. The current group\ncatalogue contains 102 groups with N >= 5 spectroscopically confirmed members,\nwith a further ~700 groups with 2 <= N <= 4. Most of the groups can be assigned\na velocity dispersion and a dark-matter mass derived from the mock catalogues,\nwith quantifiable uncertainties. The fraction of zCOSMOS galaxies in groups is\nabout 25% at low redshift and decreases toward ~15% at z ~ 0.8. The zCOSMOS\ngroup catalogue is broadly consistent with that expected from the semi-analytic\nevolution model underlying the mock catalogues. Not least, we show that the\nnumber density of groups with a given intrinsic richness increases from\nredshift z ~ 0.8 to the present, consistent with the hierarchical growth of\nstructure. \n\n"}
{"id": "0903.3895", "contents": "Title: The DMTPC project Abstract: The DMTPC detector is a low-pressure CF4 TPC with optical readout for\ndirectional detection of Dark Matter. The combination of the energy and\ndirectional tracking information allows for an efficient suppression of all\nbackgrounds. The choice of gas (CF4) makes this detector particularly sensitive\nto spin-dependent interactions. \n\n"}
{"id": "0903.5075", "contents": "Title: Astrophysical Smooth Particle Hydrodynamics Abstract: The paper presents a detailed review of the smooth particle hydrodynamics\n(SPH) method with particular focus on its astrophysical applications. We start\nby introducing the basic ideas and concepts and thereby outline all ingredients\nthat are necessary for a practical implementation of the method in a working\nSPH code. Much of SPH's success relies on its excellent conservation properties\nand therefore the numerical conservation of physical invariants receives much\nattention throughout this review. The self-consistent derivation of the SPH\nequations from the Lagrangian of an ideal fluid is the common theme of the\nremainder of the text. We derive a modern, Newtonian SPH formulation from the\nLagrangian of an ideal fluid. It accounts for changes of the local resolution\nlengths which result in corrective, so-called \"grad-h-terms\". We extend this\nstrategy to special relativity for which we derive the corresponding grad-h\nequation set. The variational approach is further applied to a\ngeneral-relativistic fluid evolving in a fixed, curved background space-time.\nParticular care is taken to explicitely derive all relevant equations in a\ncoherent way. \n\n"}
{"id": "0904.0026", "contents": "Title: The Stellar Disk of M81 Abstract: Wide-field images obtained with the 3.6 meter Canada-France-Hawaii Telescope\nare used to investigate the spatial distribution and photometric properties of\nthe brightest stars in the disk of M81 (NGC 3031). With the exception of the\ncentral regions of the galaxy and gaps between CCDs, the survey is spatially\ncomplete for stars with i' < 24 and major axis distances of 18 kpc. A more\nmodest near-infrared survey detects stars with K < 20 over roughly one third of\nthe disk. Bright main sequence (MS) stars and RSGs are traced out to\ngalactocentric distances of at least 18 kpc. The spatial distribution of bright\nMS stars tracks emission at far-ultraviolet, mid- and far-infrared wavelengths,\nalthough tidal features contain bright MS stars but have little or no infrared\nflux. The specific frequency of bright MS stars and RSGs, normalized to K-band\nintegrated brightness, increases with radius, indicating that during the past\n30 Myr the specific star formation rate (SSFR) has increased with increasing\nradius. The stellar content of the M81 disk undergoes a distinct change near R\n~ 14 kpc, and the luminosity-weighted mean age decreases with increasing radius\nin the outer regions of the M81 disk. \n\n"}
{"id": "0904.0823", "contents": "Title: Turbulent Magnetic Reconnection in Two Dimensions Abstract: Two-dimensional numerical simulations of the effect of background turbulence\non 2D resistive magnetic reconnection are presented. For sufficiently small\nvalues of the resistivity ($\\eta$) and moderate values of the turbulent power\n($\\epsilon$), the reconnection rate is found to have a much weaker dependence\non $\\eta$ than the Sweet-Parker scaling of $\\eta^{1/2}$ and is even consistent\nwith an $\\eta-$independent value. For a given value of $\\eta$, the dependence\nof the reconnection rate on the turbulent power exhibits a critical threshold\nin $\\epsilon$ above which the reconnection rate is significantly enhanced. \n\n"}
{"id": "0904.2150", "contents": "Title: Search for blue compact dwarf galaxies during quiescence II:\n  metallicities of gas and stars, ages, and star-formation rates Abstract: We examine the metallicity and age of a large set of SDSS/DR6 galaxies that\nmay be Blue Compact Dwarf (BCD) galaxies during quiescence (QBCDs).The\nindividual spectra are first classified and then averaged to reduce noise. The\nmetallicity inferred from emission lines (tracing ionized gas) exceeds by ~0.35\ndex the metallicity inferred from absorption lines (tracing stars). Such a\nsmall difference is significant according to our error budget estimate. The\nsame procedure was applied to a reference sample of BCDs, and in this case the\ntwo metallicities agree, being also consistent with the stellar metallicity in\nQBCDs. Chemical evolution models indicate that the gas metallicity of QBCDs is\ntoo high to be representative of the galaxy as a whole, but it can represent a\nsmall fraction of the galactic gas, self enriched by previous starbursts. The\nluminosity weighted stellar age of QBCDs spans the whole range between 1 and 10\nGyr, whereas it is always smaller than 1 Gyr for BCDs. Our stellar ages and\nmetallicities rely on a single stellar population spectrum fitting procedure,\nwhich we have specifically developed for this work using the stellar library\nMILES. \n\n"}
{"id": "0904.3046", "contents": "Title: The Thermal Abundance of Semi-Relativistic Relics Abstract: Approximate analytical solutions of the Boltzmann equation for particles that\nare either extremely relativistic or non-relativistic when they decouple from\nthe thermal bath are well established. However, no analytical formula for the\nrelic density of particles that are semi-relativistic at decoupling is yet\nknown. We propose a new ansatz for the thermal average of the annihilation\ncross sections for such particles, and find a semi-analytical treatment for\ncalculating their relic densities. As examples, we consider Majorana- and\nDirac-type neutrinos. We show that such semi-relativistic relics cannot be good\ncold Dark Matter candidates. However, late decays of meta-stable\nsemi-relativistic relics might have released a large amount of entropy, thereby\ndiluting the density of other, unwanted relics. \n\n"}
{"id": "0904.3212", "contents": "Title: Biases on initial mass function determinations. III. Cluster masses\n  derived from unresolved photometry Abstract: It is currently common to use spatially unresolved multi-filter broad-band\nphotometry to determine the masses of individual stellar clusters (and hence\nthe cluster mass function, CMF). I analyze the stochastic effects introduced by\nthe sampling of the stellar initial mass function (SIMF) in the derivation of\nthe individual masses and the CMF and I establish that such effects are the\nlargest contributor to the observational uncertainties. An analytical solution,\nvalid in the limit where uncertainties are small, is provided to establish the\nrange of cluster masses over which the CMF slope can be obtained with a given\naccuracy. The validity of the analytical solution is extended to higher mass\nuncertainties using Monte Carlo simulations and the Gamma approximation. The\nvalue of the Poisson mass is calculated for a large range of ages and a variety\nof filters for solar-metallicity clusters measured with single-filter\nphotometry. A method that uses the code CHORIZOS is presented to simultaneously\nderive masses, ages, and extinctions. The classical method of using unweighted\nUBV photometry to simultaneously establish ages and extinctions of stellar\nclusters is found to be unreliable for clusters older than approx. 30 Ma, even\nfor relatively large cluster masses. On the other hand, augmenting the filter\nset to include longer-wavelength filters and using weights for each filter\nincreases the range of masses and ages that can be accurately measured with\nunresolved photometry. Nevertheless, a relatively large range of masses and\nages is found to be dominated by SIMF sampling effects that render the observed\nmasses useless, even when using UBVRIJHK photometry. A revision of some\nliterature results affected by these effects is presented and possible\nsolutions for future observations and analyses are suggested. \n\n"}
{"id": "0904.3623", "contents": "Title: Destriping CMB temperature and polarization maps Abstract: We study destriping as a map-making method for temperature-and-polarization\ndata for cosmic microwave background observations. We present a particular\nimplementation of destriping and study the residual error in output maps, using\nsimulated data corresponding to the 70 GHz channel of the Planck satellite, but\nassuming idealized detector and beam properties. The relevant residual map is\nthe difference between the output map and a binned map obtained from the signal\n+ white noise part of the data stream. For destriping it can be divided into\nsix components: unmodeled correlated noise, white noise reference baselines,\nreference baselines of the pixelization noise from the signal, and baseline\nerrors from correlated noise, white noise, and signal. These six components\ncontribute differently to the different angular scales in the maps. We derive\nanalytical results for the first three components. This study is related to\nPlanck LFI activities. \n\n"}
{"id": "0905.0001", "contents": "Title: The Host Galaxies of Swift Dark Gamma-Ray Bursts: Observational\n  Constraints on Highly Obscured and Very High-Redshift GRBs Abstract: In this work we present the first results of our imaging campaign at Keck\nObservatory to identify the host galaxies of \"dark\" gamma-ray bursts (GRBs),\nevents with no detected optical afterglow or with detected optical flux\nsignificantly fainter than expected from the observed X-ray afterglow. We find\nthat out of a uniform sample of 29 Swift bursts rapidly observed by the Palomar\n60-inch telescope through March 2008 (14 of which we classify as dark), all\nevents have either a detected optical afterglow, a probable optical host-galaxy\ndetection, or both. Our results constrain the fraction of Swift GRBs coming\nfrom very high redshift (z > 7), such as the recent GRB 090423, to between\n0.2-7 percent at 80% confidence. In contrast, a significant fraction of the\nsample requires large extinction columns (host-frame A_V > 1 mag, with several\nevents showing A_V > 2-6 mag), identifying dust extinction as the dominant\ncause of the dark GRB phenomenon. We infer that a significant fraction of GRBs\n(and, by association, of high-mass star formation) occurs in highly obscured\nregions. However, the host galaxies of dark GRBs seem to have normal optical\ncolors, suggesting that the source of obscuring dust is local to the vicinity\nof the GRB progenitor or highly unevenly distributed within the host galaxy. \n\n"}
{"id": "0905.0584", "contents": "Title: X-ray spectral evolution of the extragalactic Z-source, LMC X-2 Abstract: We present the results obtained by a detailed study of the extragalactic Z\nsource, LMC X-2, using broad band Suzaku data and a large ($ \\sim 750$ ksec)\ndata set obtained with the proportional counter array (PCA) onboard RXTE. The\nPCA data allows for studying the complete spectral evolution along the\nhorizontal, normal and flaring branches of the Z-track. Comparison with\nprevious study show that the details of spectral evolution (like variation of\nComptonizing electron temperature), is similar to that of GX 17+2 but unlike\nthat of Cyg X-2 and GX 349+2. This suggests that Z sources are heterogeneous\ngroup with perhaps LMC X-2 and GX 17+2 being member of a subclass. However non\nmonotonic evolution of the Compton y-parameter seems to be generic to all\nsources. The broad band {\\it Suzaku} data reveals that the additional soft\ncomponent of the source modelled as a disk blackbody emission is strongly\npreferred over one where it is taken to be a blackbody spectrum. This component\nas well as the temperature of seed photons do not vary when source goes into a\nflaring mode and the entire variation can be ascribed to the Comptonizing\ncloud. The bolometric unabsorbed luminosity of the source is well constrained\nto be $ \\sim 2.23 \\times 10^{38}$ ergs/sec which if the source is Eddington\nlimited implies a neutron star mass of 1.6 M$_\\odot$. We discuss the\nimplications of these results. \n\n"}
{"id": "0905.0588", "contents": "Title: Deep 1.4 GHZ Follow Up of the Steep Spectrum Radio Halo in Abell 521 Abstract: In a recent paper we reported on the discovery of a radio halo with very\nsteep spectrum in the merging galaxy cluster Abell 521 through observations\nwith the Giant Metrewave Radio Telescope (GMRT). We showed that the steep\nspectrum of the halo is inconsistent with a secondary origin of the\nrelativistic electrons and supports a turbulent acceleration scenario. At that\ntime, due to the steep spectrum, the available observations at 1.4 GHz\n(archival NRAO - Very Large Array - VLA CnB-configuration data) were not\nadequate to accurately determine the flux density associated with the radio\nhalo. In this paper we report the detection at 1.4 GHz of the radio halo in\nAbell 521 using deep VLA observations in the D-configuration. We use these new\ndata to confirm the steep-spectrum of the object. We consider Abell 521 the\nprototype of a population of very-steep spectrum halos. This population is\npredicted assuming that turbulence plays an important role in the acceleration\nof relativistic particles in galaxy clusters, and we expect it will be unveiled\nby future surveys at low frequencies with the LOFAR and LWA radio telescopes. \n\n"}
{"id": "0905.1691", "contents": "Title: Stellar sources of dust in the high redshift Universe Abstract: With the aim of investigating whether stellar sources can account for the\n>10^8 Msun dust masses inferred from mm/sub-mm observations of samples of\n5<z<6.4 quasars,we develop a chemical evolution model which follows the\nevolution of metals and dust on the stellar characteristic lifetimes, taking\ninto account dust destruction mechanisms.Using a grid of stellar dust yields as\na function of the initial mass and metallicity over the range 1-40 Msun and 0-1\nZsun,we show that the role of AGB stars in cosmic dust evolution at high\nredshift might have been over-looked.We apply the chemical evolution model with\ndust to the host galaxy of the most distant quasar at z=6.4, SDSS\nJ1148+5251.Given the current uncertainties on the star formation history of the\nhost galaxy, we have considered two models: (i) a star formation history\nobtained in a numerical simulation by Li et al.(2007) which predicts that a\nlarge stellar bulge is already formed at z=6.4,and (ii) a constant star\nformation rate of 1000 Msun/yr, as suggested by the observations if most of the\nFIR luminosity is due to young stars.The total mass of dust predicted at z=6.4\nby the first model is 2x10^8Msun,within the range of values inferred by\nobservations,with a substantial contribution (80%) of AGB-dust.When a constant\nstar formation rate is adopted,the contribution of AGB-dust decreases to 50%\nbut the total mass of dust formed is a factor 2 smaller.Both models predict a\nrapid enrichment of the ISM with metals and a relatively mild evolution of the\ncarbon abundance,in agreement with observational constraints. This supports the\nidea that stellar sources can account for the dust observed but show that the\ncontribution of AGB stars to dust production cannot be neglected, even at the\nmost extreme redshifts currently accessible to observations. \n\n"}
{"id": "0905.1702", "contents": "Title: Halo abundances in the f_{nl} model Abstract: We show how the excursion set moving barrier model for halo abundances may be\ngeneralized to the local non-Gaussian f_{nl} model. Our estimate assumes that\nthe distribution of step sizes depends on f_{nl}, but that they are otherwise\nuncorrelated. Our analysis is consistent with previous results for the case of\na constant barrier, and highlights some implicit assumptions. It also clarifies\nthe basis of an approximate analytic solution to the moving barrier problem in\nthe Gaussian case, and shows how it might be improved. \n\n"}
{"id": "0905.1965", "contents": "Title: The Synoptic All-Sky Infrared (SASIR) Survey Abstract: We are proposing to conduct a multicolor, synoptic infrared (IR) imaging\nsurvey of the Northern sky with a new, dedicated 6.5-meter telescope at San\nPedro M\\'artir (SPM) Observatory. This initiative is being developed in\npartnership with astronomy institutions in Mexico and the University of\nCalifornia. The 4-year, dedicated survey, planned to begin in 2017, will reach\nmore than 100 times deeper than 2MASS. The Synoptic All-Sky Infrared (SASIR)\nSurvey will reveal the missing sample of faint red dwarf stars in the local\nsolar neighborhood, and the unprecedented sensitivity over such a wide field\nwill result in the discovery of thousands of z ~ 7 quasars (and reaching to z >\n10), allowing detailed study (in concert with JWST and Giant Segmented Mirror\nTelescopes) of the timing and the origin(s) of reionization. As a time-domain\nsurvey, SASIR will reveal the dynamic infrared universe, opening new phase\nspace for discovery. Synoptic observations of over 10^6 supernovae and variable\nstars will provide better distance measures than optical studies alone. SASIR\nalso provides significant synergy with other major Astro2010 facilities,\nimproving the overall scientific return of community investments. Compared to\noptical-only measurements, IR colors vastly improve photometric redshifts to z\n~ 4, enhancing dark energy and dark matter surveys based on weak lensing and\nbaryon oscillations. The wide field and ToO capabilities will enable a\nconnection of the gravitational wave and neutrino universe - with events\notherwise poorly localized on the sky - to transient electromagnetic phenomena. \n\n"}
{"id": "0905.2453", "contents": "Title: Teraflop per second gravitational lensing ray-shooting using graphics\n  processing units Abstract: Gravitational lensing calculation using a direct inverse ray-shooting\napproach is a computationally expensive way to determine magnification maps,\ncaustic patterns, and light-curves (e.g. as a function of source profile and\nsize). However, as an easily parallelisable calculation, gravitational\nray-shooting can be accelerated using programmable graphics processing units\n(GPUs). We present our implementation of inverse ray-shooting for the NVIDIA\nG80 generation of graphics processors using the NVIDIA Compute Unified Device\nArchitecture (CUDA) software development kit. We also extend our code to\nmultiple-GPU systems, including a 4-GPU NVIDIA S1070 Tesla unit. We achieve\nsustained processing performance of 182 Gflop/s on a single GPU, and 1.28\nTflop/s using the Tesla unit. We demonstrate that billion-lens microlensing\nsimulations can be run on a single computer with a Tesla unit in timescales of\norder a day without the use of a hierarchical tree code. \n\n"}
{"id": "0905.2651", "contents": "Title: The accretion disc in the quasar SDSS J0924+0219 Abstract: We present single-epoch multi-wavelength optical-NIR observations of the\n\"anomalous\" lensed quasar SDSS J0924+0219, made using the Magellan 6.5-metre\nBaade telescope at Las Campanas Observatory, Chile. The data clearly resolve\nthe anomalous bright image pair in the lensed system, and exhibit a strong\ndecrease in the anomalous flux ratio with decreasing wavelength. This is\ninterpreted as a result of microlensing of a source of decreasing size in the\ncore of the lensed quasar. We model the radius of the continuum emission\nregion, sigma, as a power-law in wavelength, sigma lambda^zeta. We place an\nupper limit on the Gaussian radius of the u'-band emission region of 3.04E16\nh70^{-1/2} (<M>/M_sun)^{1/2} cm, and constrain the size-wavelength power-law\nindex to zeta<1.34 at 95% confidence. These observations rule out an alpha-disc\nprescription for the accretion disc in SDSS J0924+0219 with 94% confidence. \n\n"}
{"id": "0905.3554", "contents": "Title: The Origin of Extended Disk Galaxies at z=2 Abstract: Galaxy formation models typically assume that the size and rotation speed of\ngalaxy disks are largely dictated by the mass, concentration, and spin of their\nsurrounding dark matter haloes. Equally important, however, are the fraction of\nbaryons in the halo that collect into the central galaxy, as well as the net\nangular momentum that they are able to retain during its assembly process. We\nexplore the latter using a set of four large cosmological N-body/gasdynamical\nsimulations drawn from the OWLS (OverWhelmingly Large Simulations) project.\nThese runs differ only in their implementation of feedback from supernovae. We\nfind that, when expressed as fractions of their virial values, galaxy mass and\nnet angular momentum are tightly correlated. Galaxy mass fractions,\nm_d=M_gal/M_vir, depend strongly on feedback, but only weakly on halo mass or\nspin over the halo mass range explored here (M_vir>1e11 h^{-1}M_sun). The\nangular momentum of a galaxy, j_d=J_gal/J_vir, correlates with m_d in a manner\nthat is insensitive to feedback and that deviates strongly from the simple j_d\n= m_d assumption often adopted in semi-analytic models of galaxy formation. The\nm_d-j_d correlation implies that, in a given halo, galaxy disk size is maximal\nwhen the central galaxy makes up a substantial fraction (~20%-30%) of all\nbaryons within the virial radius. At z=2, such systems may host gaseous disks\nwith radial scale lengths as large as those reported for star-forming disks by\nthe SINS survey, even in moderately massive haloes of average spin. Extended\ndisks at z=2 may thus signal the presence of systems where galaxy formation has\nbeen particularly efficient, rather than the existence of haloes with unusually\nhigh spin parameter. \n\n"}
{"id": "0905.3698", "contents": "Title: The low-mass stellar mass functions of rich, compact clusters in the\n  Large Magellanic Cloud Abstract: Context. We use Hubble Space Telescope photometry of six rich, compact star\nclusters in the Large Magellanic Cloud (LMC), with ages ranging from 0.01 to\n1.0 Gyr, to derive the clusters' stellar mass functions (MFs) at their\nhalf-mass radii.\n  Aims. The LMC is an ideal environment to study stellar MFs, because it\ncontains a large population of compact clusters at different evolutionary\nstages. We aim to obtain constraints on the initial MFs (IMFs) of our sample\nclusters on the basis of their present-day MFs, combined with our understanding\nof their dynamical and photometric evolution.\n  Methods. We derive the clusters' present-day MFs below 1.0 Msun using deep\nobservations with the Space Telescope Imaging Spectrograph and updated stellar\npopulation synthesis models.\n  Results. Since the relaxation timescales of low-mass stars are very long,\ndynamical evolution will not have affected the MFs below 1.0 Msun\nsignificantly, so that - within the uncertainties - the derived MFs are\nconsistent with the solar-neighbourhood IMF, at least for the younger clusters.\n  Conclusions. The IMF in the low-density, low-metallicity environment of the\nLMC disk is not significantly different from that in the solar neighbourhood. \n\n"}
{"id": "0906.0001", "contents": "Title: Extragalactic Inverse Compton Light from Dark Matter Annihilation and\n  the Pamela Positron Excess Abstract: We calculate the extragalactic diffuse emission originating from the\nup-scattering of cosmic microwave photons by energetic electrons and positrons\nproduced in particle dark matter annihilation events at all redshifts and in\nall halos. We outline the observational constraints on this emission and we\nstudy its dependence on both the particle dark matter model (including the\nparticle mass and its dominant annihilation final state) and on assumptions on\nstructure formation and on the density profile of halos. We find that for\nlow-mass dark matter models, data in the X-ray band provide the most stringent\nconstraints, while the gamma-ray energy range probes models featuring large\nmasses and pair-annihilation rates, and a hard spectrum for the injected\nelectrons and positrons. Specifically, we point out that the all-redshift,\nall-halo inverse Compton emission from many dark matter models that might\nprovide an explanation to the anomalous positron fraction measured by the\nPamela payload severely overproduces the observed extragalactic gamma-ray\nbackground. \n\n"}
{"id": "0906.0993", "contents": "Title: Fisher Matrix Preloaded -- Fisher4Cast Abstract: The Fisher Matrix is the backbone of modern cosmological forecasting. We\ndescribe the Fisher4Cast software: a general-purpose, easy-to-use, Fisher\nMatrix framework. It is open source, rigorously designed and tested and\nincludes a Graphical User Interface (GUI) with automated LATEX file creation\ncapability and point-and-click Fisher ellipse generation. Fisher4Cast was\ndesigned for ease of extension and, although written in Matlab, is easily\nportable to open-source alternatives such as Octave and Scilab. Here we use\nFisher4Cast to present new 3-D and 4-D visualisations of the forecasting\nlandscape and to investigate the effects of growth and curvature on future\ncosmological surveys. Early releases have been available at\nhttp://www.cosmology.org.za since May 2008 with 750 downloads in the first\nyear. Version 2.2 is made public with this paper and includes a Quick Start\nguide and the code used to produce the figures in this paper, in the hope that\nit will be useful to the cosmology and wider scientific communities. \n\n"}
{"id": "0906.2173", "contents": "Title: Data Mining and Machine Learning in Astronomy Abstract: We review the current state of data mining and machine learning in astronomy.\n'Data Mining' can have a somewhat mixed connotation from the point of view of a\nresearcher in this field. If used correctly, it can be a powerful approach,\nholding the potential to fully exploit the exponentially increasing amount of\navailable data, promising great scientific advance. However, if misused, it can\nbe little more than the black-box application of complex computing algorithms\nthat may give little physical insight, and provide questionable results. Here,\nwe give an overview of the entire data mining process, from data collection\nthrough to the interpretation of results. We cover common machine learning\nalgorithms, such as artificial neural networks and support vector machines,\napplications from a broad range of astronomy, emphasizing those where data\nmining techniques directly resulted in improved science, and important current\nand future directions, including probability density functions, parallel\nalgorithms, petascale computing, and the time domain. We conclude that, so long\nas one carefully selects an appropriate algorithm, and is guided by the\nastronomical problem at hand, data mining can be very much the powerful tool,\nand not the questionable black box. \n\n"}
{"id": "0906.2201", "contents": "Title: New Observations of the Very Luminous Supernova 2006gy: Evidence for\n  Echoes Abstract: Supernova (SN) 2006gy was a hydrogen-rich core-collapse SN that remains one\nof the most luminous optical supernovae ever observed. The total energy budget\n(> 2 x 10^51 erg radiated in the optical alone) poses many challenges for\nstandard SN theory. We present new ground-based near-infrared (NIR)\nobservations of SN 2006gy, as well as a single epoch of Hubble Space Telescope\n(HST) imaging obtained more than two years after the explosion. Our NIR data\ntaken around peak optical emission show an evolution that is largely consistent\nwith a cooling blackbody, with tentative evidence for a growing NIR excess\nstarting at day ~100. Our late-time Keck adaptive optics (AO) NIR image, taken\non day 723, shows little change from previous NIR observations taken around day\n400. Furthermore, the optical HST observations show a reduced decline rate\nafter day 400, and the SN is bluer on day 810 than it was at peak. This\nlate-time decline is inconsistent with Co56 decay, and thus is problematic for\nthe various pair-instability SN models used to explain the nature of SN 2006gy.\nThe slow decline of the NIR emission can be explained with a light echo, and we\nconfirm that the late-time NIR excess is the result of a massive (>10 Msun)\ndusty shell heated by the SN peak luminosity. The late-time optical\nobservations require the existence of a scattered light echo, which may be\ngenerated by the same dust that contributes to the NIR echo. Both the NIR and\noptical echoes originate in the proximity of the progenitor, ~10^18 cm for the\nNIR echo and <~10-40 pc for the optical echo, which provides further evidence\nthat the progenitor of SN 2006gy was a very massive star. \n\n"}
{"id": "0906.4115", "contents": "Title: Two phase galaxy formation: The Gas Content of Normal Galaxies Abstract: We investigate the atomic (HI) and molecular (H_2) Hydrogen content of normal\ngalaxies by combining observational studies linking galaxy stellar and gas\nbudgets to their host dark matter (DM) properties, with a physically grounded\ngalaxy formation model. This enables us to analyse empirical relationships\nbetween the virial, stellar, and gaseous masses of galaxies and explore their\nphysical origins. Utilising a semi-analytic model (SAM) to study the evolution\nof baryonic material within evolving DM halos, we study the effects of baryonic\ninfall and various star formation and feedback mechanisms on the properties of\nformed galaxies using the most up-to-date physical recipes. We find that in\norder to significantly improve agreement with observations of low-mass galaxies\nwe must suppress the infall of baryonic material and exploit a two-phase\ninterstellar medium (ISM), where the ratio of HI to H_2 is determined by the\ngalactic disk structure. Modifying the standard Schmidt-Kennicutt star\nformation law, which acts upon the total cold gas in galaxy discs and includes\na critical density threshold, and employing a star formation law which\ncorrelates with the H_2 gas mass results in a lower overall star formation\nrate. This in turn, allows us to simultaneously reproduce stellar, HI and H_2\nmass functions of normal galaxies. \n\n"}
{"id": "0906.4237", "contents": "Title: Non-minimal coupling of the phantom field and cosmic acceleration Abstract: Motivated by the recent interest in phantom fields as candidates for the dark\nenergy component, we investigate the consequences of the phantom field when is\nminimally coupled to gravity. In particular, the necessary (but insufficient)\nconditions for the acceleration and superacceleration of the universe are\nobtained when the non-minimal coupling term is taken into account. Furthermore,\nthe necessary condition for the cosmic acceleration is derived when the phantom\nfield is non-minimally coupled to gravity and baryonic matter is included. \n\n"}
{"id": "0906.5092", "contents": "Title: Limitations for shapelet-based weak-lensing measurements Abstract: We seek to understand the impact on shape estimators obtained from circular\nand elliptical shapelet models under two realistic conditions: (a) only a\nlimited number of shapelet modes is available for the model, and (b) the\nintrinsic galactic shapes are not restricted to shapelet models.\n  We create a set of simplistic simulations, in which the galactic shapes\nfollow a Sersic profile. By varying the Sersic index and applied shear, we\nquantify the amount of bias on shear estimates which arises from insufficient\nmodeling. Additional complications due to PSF convolution, pixelation and pixel\nnoise are also discussed.\n  Steep and highly elliptical galaxy shapes cannot be accurately modeled within\nthe circular shapelet basis system and are biased towards shallower and less\nelongated shapes. This problem can be cured partially by allowing elliptical\nbasis functions, but for steep profiles elliptical shapelet models still depend\ncritically on accurate ellipticity priors. As a result, shear estimates are\ntypically biased low. Independently of the particular form of the estimator,\nthe bias depends on the true intrinsic galaxy morphology, but also on the size\nand shape of the PSF.\n  As long as the issues discussed here are not solved, the shapelet method\ncannot provide weak-lensing measurements with an accuracy demanded by upcoming\nmissions and surveys, unless one can provide an accurate and reliable\ncalibration, specific for the dataset under investigation. \n\n"}
{"id": "0906.5354", "contents": "Title: G\\\"{o}del-type universes in f(R) gravity Abstract: The $f(R)$ gravity theories provide an alternative way to explain the current\ncosmic acceleration without a dark energy matter component. If gravity is\ngoverned by a $f(R)$ theory a number of issues should be reexamined in this\nframework, including the violation of causality problem on nonlocal scale. We\nexamine the question as to whether the $f(R)$ gravity theories permit\nspace-times in which the causality is violated. We show that the field\nequations of these $f(R)$ gravity theories do not exclude solutions with\nbreakdown of causality for a physically well-motivated perfect-fluid matter\ncontent. We demonstrate that every perfect-fluid G\\\"{o}del-type solution of a\ngeneric $f(R)$ gravity satisfying the condition $df/dR > 0$ is necessarily\nisometric to the G\\\"odel geometry, and therefore presents violation of\ncausality. This result extends a theorem on G\\\"{o}del-type models, which has\nbeen established in the context of general relativity. We also derive an\nexpression for the critical radius $r_c$ (beyond which the causality is\nviolated) for an arbitrary $f(R)$ theory, making apparent that the violation of\ncausality depends on both the $f(R)$ gravity theory and the matter content. As\nan illustration, we concretely take a recent $f(R)$ gravity theory that is free\nfrom singularities of the Ricci scalar and is cosmologically viable, and show\nthat this theory accommodates noncausal as well as causal G\\\"odel-type\nsolutions. \n\n"}
{"id": "0907.1301", "contents": "Title: Magnetic Fields and Infall Motions in NGC 1333 IRAS 4 Abstract: We present single-dish 350 micron dust continuum polarimetry as well as HCN\nand HCO+ J=4-3 rotational emission spectra obtained on NGC 1333 IRAS 4. The\npolarimetry indicates a uniform field morphology over a 20\" radius from the\npeak continuum flux of IRAS 4A, in agreement with models of magnetically\nsupported cloud collapse. The field morphology around IRAS 4B appears to be\nquite distinct however, with indications of depolarization observed towards the\npeak flux of this source. Inverse P-Cygni profiles are observed in the HCN\nJ=4-3 line spectra towards IRAS 4A, providing a clear indication of infall gas\nmotions. Taken together, the evidence gathered here appears to support the\nscenario that IRAS 4A is a cloud core in a critical state of support against\ngravitational collapse. \n\n"}
{"id": "0907.2198", "contents": "Title: A Bayesian approach to the study of white dwarf binaries in LISA data:\n  The application of a reversible jump Markov chain Monte Carlo method Abstract: The Laser Interferometer Space Antenna (LISA) defines new demands on data\nanalysis efforts in its all-sky gravitational wave survey, recording\nsimultaneously thousands of galactic compact object binary foreground sources\nand tens to hundreds of background sources like binary black hole mergers and\nextreme mass ratio inspirals. We approach this problem with an adaptive and\nfully automatic Reversible Jump Markov Chain Monte Carlo sampler, able to\nsample from the joint posterior density function (as established by Bayes\ntheorem) for a given mixture of signals \"out of the box'', handling the total\nnumber of signals as an additional unknown parameter beside the unknown\nparameters of each individual source and the noise floor. We show in examples\nfrom the LISA Mock Data Challenge implementing the full response of LISA in its\nTDI description that this sampler is able to extract monochromatic Double White\nDwarf signals out of colored instrumental noise and additional foreground and\nbackground noise successfully in a global fitting approach. We introduce 2\nexamples with fixed number of signals (MCMC sampling), and 1 example with\nunknown number of signals (RJ-MCMC), the latter further promoting the idea\nbehind an experimental adaptation of the model indicator proposal densities in\nthe main sampling stage. We note that the experienced runtimes and degeneracies\nin parameter extraction limit the shown examples to the extraction of a low but\nrealistic number of signals. \n\n"}
{"id": "0907.5275", "contents": "Title: ESAF: Full Simulation of Space-Based Extensive Air Showers Detectors Abstract: Future detection of Extensive Air Showers (EAS) produced by Ultra High Energy\nCosmic Particles (UHECP) by means of space based fluorescence telescopes will\nopen a new window on the universe and allow cosmic ray and neutrino astronomy\nat a level that is virtually impossible for ground based detectors. In this\npaper we summarize the results obtained in the context of the EUSO project by\nmeans of a detailed Monte Carlo simulation of all the physical processes\ninvolved in the fluorescence technique, from the Extensive Air Shower\ndevelopment to the instrument response. Particular emphasis is given to\nmodeling the light propagation in the atmosphere and the effect of clouds. Main\nresults on energy threshold and resolution, direction resolution and Xmax\ndetermination are reported. Results are based on EUSO telescope design, but are\nalso extended to larger and more sensitive detectors. \n\n"}
{"id": "0908.0860", "contents": "Title: Search for Exotic Physics with the ANTARES Detector Abstract: Besides the detection of high energy neutrinos, the ANTARES telescope offers\nan opportunity to improve sensitivity to exotic cosmological relics. In this\narticle we discuss the sensitivity of the ANTARES detector to elativistic\nmonopoles and slow nuclearites. Dedicated trigger algorithms and search\nstrategies are being developed to search or them. The data filtering,\nbackground rejection selection criteria are described, as well as the expected\nsensitivity of ANTARES to exotic physics. \n\n"}
{"id": "0908.1381", "contents": "Title: Spectroscopic Confirmation of the Pisces Overdensity Abstract: We present spectroscopic confirmation of the \"Pisces Overdensity\", also known\nas \"Structure J\", a photometric overdensity of RR Lyrae stars discovered by the\nSloan Digital Sky Survey (SDSS) at an estimated photometric distance of ~85kpc.\nWe measure radial velocities for 8 RR Lyrae stars within Pisces. We find that 5\nof the 8 stars have heliocentric radial velocities within a narrow range of -87\nkm/s < v < -67 km/s, suggesting that the photometric overdensity is mainly due\nto a physically associated system, probably a dwarf galaxy or a disrupted\ngalaxy. Two of the remaining 3 stars differ from one another by only 9 km/s,\nbut it would be premature to identify them as a second system. \n\n"}
{"id": "0908.3283", "contents": "Title: DECIGO/BBO as a probe to constrain alternative theories of gravity Abstract: We calculate how strongly one can constrain the alternative theories of\ngravity with deci-Hz gravitational wave interferometers such as DECIGO and BBO.\nHere we discuss Brans-Dicke theory and massive graviton theories as typical\nexamples. We consider the inspiral of compact binaries composed of a neutron\nstar (NS) and an intermediate mass black hole (IMBH) for Brans-Dicke (BD)\ntheory and those composed of a super massive black hole (SMBH) and a black hole\n(SMBH) for massive graviton theories. Using the restricted 2PN waveforms\nincluding spin effects and taking the spin precession into account, we perform\nthe Monte Carlo simulations of $10^4$ binaries to estimate the determination\naccuracy of binary parameters including the Brans-Dicke parameter\n$\\omega_{\\mathrm{BD}}$ and the graviton Compton length $\\lambda_g$. Assuming a\n$(1.4, 10)M_{\\odot}$ NS/BH binary of SNR=$\\sqrt{200}$, the constraint on\n$\\omega_{\\mathrm{BD}}$ is obtained as $\\omega_{\\mathrm{BD}}>2.32\\times 10^6$,\nwhich is 300 times stronger than the estimated constraint from LISA\nobservation. Furthermore, we find that, due to the expected large merger rate\nof NS/BH binaries of $O(10^4)$ yr$^{-1}$, a statistical analysis yields\n$\\omega_{\\mathrm{BD}}>3.77\\times10^8$, which is 4 orders of magnitude stronger\nthan the current strongest bound obtained from the solar system experiment. For\nmassive graviton theories, assuming a $(10^6, 10^5)M_{\\odot}$ BH/BH binary at\n3Gpc, one can put a constraint $\\lambda_g>3.35\\times10^{20}$cm, on average.\nThis is three orders of magnitude stronger than the one obtained from the solar\nsystem experiment. From these results, it is understood that DECIGO/BBO is a\nvery powerful tool for constraining alternative theories of gravity, too. \n\n"}
{"id": "0908.3415", "contents": "Title: Testing the (generalized) Chaplygin gas model with the Lookback\n  time-Redshift data Abstract: The Chaplygin gas (CG) and the generalized Chaplygin gas (GCG) models,\nproposed as candidates of the unified dark matter-dark energy (UDME), are\ntested with the look-back time (LT) redshift data. We find that the LT data\nonly give a very weak constraint on the model parameter. However, by combing\nthe LT with the baryonic acoustic oscillation peak, we obtain, at the 95.4%\nconfidence level, $0.68\\leq A_c\\leq0.82$ and $0.59\\leq h\\leq0.65$ for the CG\nmodel, and $0.67\\leq A_s\\leq0.89$ and $-0.29\\leq \\alpha\\leq0.61$ for the GCG\nmodel. This shows that both the CG and the GCG are viable as a candidate of\nUDME. Within the GCG model, we also find that the Chaplygin gas model\n($\\alpha=1$) is ruled out by these data at the 99.7% confidence level. \n\n"}
{"id": "0908.3808", "contents": "Title: Photometric Calibration of the Supernova Legacy Survey Fields Abstract: We present the photometric calibration of the Supernova Legacy Survey (SNLS)\nfields. The SNLS aims at measuring the distances to SNe Ia at (0.3<z<1) using\nMegaCam, the 1 deg^2 imager on the Canada-France-Hawaii Telescope (CFHT). The\nuncertainty affecting the photometric calibration of the survey dominates the\nsystematic uncertainty of the key measurement of the survey, namely the dark\nenergy equation of state. The photometric calibration of the SNLS requires\nobtaining a uniform response across the imager, calibrating the science field\nstars in each survey band (SDSS-like ugriz bands) with respect to standards\nwith known flux in the same bands, and binding the calibration to the UBVRI\nLandolt standards used to calibrate the nearby SNe from the literature\nnecessary to produce cosmological constraints. The spatial non-uniformities of\nthe imager photometric response are mapped using dithered observations of dense\nstellar fields. Photometric zero-points against Landolt standards are obtained.\nThe linearity of the instrument is studied. We show that the imager filters and\nphotometric response are not uniform and publish correction maps. We present\nmodels of the effective passbands of the instrument as a function of the\nposition on the focal plane. We define a natural magnitude system for MegaCam.\nWe show that the systematics affecting the magnitude-to-flux relations can be\nreduced if we use the spectrophotometric standard star BD +17 4708 instead of\nVega as a fundamental flux standard. We publish ugriz catalogs of tertiary\nstandards for all the SNLS fields. \n\n"}
{"id": "0909.0040", "contents": "Title: Star clusters as tracers of galaxy evolution Abstract: Star clusters represent the most common 'mode' of star formation. They are\nfound in all types of environments, cascading down from galaxy groups and\nmerging pairs through starbursts to normal galaxies and dwarves and even\nisolated regions in extragalactic space. As they maintain a link to the overall\nstar formation in a system, they can be used as tracers of the star formation\nhistory of environments located at distances prohibitive to the study of\nindividual stars. This makes them ideally suited to the study of mergers and\ninteractions in galaxy pairs and groups. In this work we present observations\nof the star cluster populations in the local starburst galaxy M82,\npost-interaction spiral NGC 6872, the \"Antennae\" merging pair and two compact\ngroups, \"Stephan's Quintet\" and HCG 7. In each case, we extract information on\nthe clusters and their hosts using mainly HST photometry and Gemini\nspectroscopy. \n\n"}
{"id": "0909.0822", "contents": "Title: A new stochastic approach to cumulative weak lensing Abstract: We study the weak gravitational lensing effects caused by a stochastic\ndistribution of dark matter halos. We develop a simple approach to calculate\nthe magnification probability distribution function which allows us to easily\ncompute the magnitude bias and dispersion for an arbitrary data sample and a\ngiven universe model. As an application we consider the effects of single-mass\nlarge-scale cosmic inhomogeneities to the SNe magnitude-redshift relation, and\nconclude that such structures could bias the PDF enough to affect the\nextraction of cosmological parameters from the limited size of present-day SNe\ndata samples. We also release turboGL, a simple and very fast (<= 1s)\nMathematica code based on the method here presented. \n\n"}
{"id": "0909.1748", "contents": "Title: EAGLE Spectroscopy of Resolved Stellar Populations Beyond the Local\n  Group Abstract: Valuable insights into galaxy evolution can be gleaned from studies of\nresolved stellar populations in the local Universe. Deep photometric surveys\nhave provided tracers of the star-formation histories in galaxies from 0.8-16\nMpc, but without robust chemical abundances and stellar kinematics from\nspectroscopy, their sub-structures and assembly histories remain hidden from\nus. In this context, we introduce the EAGLE design study for a\nmulti--integral-field-unit, near-infrared spectrograph for the European\nExtremely Large Telescope (E-ELT). EAGLE will exploit the unprecedented\nlight-gathering power of the E-ELT to deliver AO-corrected spectroscopy across\na large (38.5 sq. arcmin) field, truly revolutionising our view of stellar\npopulations in the Local Volume. \n\n"}
{"id": "0909.2795", "contents": "Title: Data reduction strategy of the Effelsberg-Bonn HI Survey (EBHIS) Abstract: Since autumn 2008 a new L-band 7-Feed-Array receiver is used for an HI 21-cm\nline survey performed with the 100-m Effelsberg telescope. The survey will\ncover the whole northern hemisphere comprising both, the galactic and\nextragalactic sky in parallel. Using state-of-the-art FPGA based digital Fast\nFourier Transform spectrometers, superior in dynamic range and temporal\nresolution, allows to apply sophisticated radio frequency interferences (RFI)\nmitigation schemes to the survey data.\n  The EBHIS data reduction software includes the RFI mitigation, gain-curve\ncorrection, intensity calibration, stray-radiation correction, gridding, and\nsource detection. We discuss the severe degradation of radio astronomical HI\ndata by RFI signals and the gain in scientific yield when applying modern RFI\nmitigation schemes. For this aim simulations of the galaxy distribution within\nthe local volume (z<0.07) with and without RFI degradation were performed.\nThese simulations, allow us to investigate potential biases and selection\neffects introduced by the data reduction software and the applied source\nparametrization methods. \n\n"}
{"id": "0909.3983", "contents": "Title: A Larger Estimate of the Entropy of the Universe Abstract: Using recent measurements of the supermassive black hole (SMBH) mass\nfunction, we find that SMBHs are the largest contributor to the entropy of the\nobservable universe, contributing at least an order of magnitude more entropy\nthan previously estimated. The total entropy of the observable universe is\ncorrespondingly higher, and is S_obs = 3.1+3.0-1.7x10^104 k. We calculate the\nentropy of the current cosmic event horizon to be S_CEH = 2.6+-0.3x10^122 k,\ndwarfing the entropy of its interior, S_CEHint = 1.2+1.1-0.7x10^103 k. We make\nthe first tentative estimate of the entropy of weakly interacting massive\nparticle dark matter within the observable universe, S_dm = 10^87-10^89 k. We\nhighlight several caveats pertaining to these estimates and make\nrecommendations for future work. \n\n"}
{"id": "0909.4463", "contents": "Title: Two Suggestions to See the Hidden Magnetism of the Solar Chromosphere Abstract: Solar magnetic fields leave their fingerprints in the polarization signatures\nof the emergent spectral line radiation. This occurs through a variety of\nrather unfamiliar physical mechanisms, not only via the Zeeman effect. In\nparticular, magnetic fields modify the atomic level polarization (population\nimbalances and quantum coherences) that anisotropic radiative pumping processes\ninduce in the atoms and molecules of the solar atmosphere. Interestingly, this\nso-called Hanle effect allows us to \"see\" magnetic fields to which the Zeeman\neffect is blind within the limitations of the available instrumentation. Here I\nargue that the IR triplet of Ca II and the He I 10830 \\AA multiplet would be\nvery suitable choices for investigating the magnetism of the solar chromosphere\nvia spectropolarimetric observations from a future space telescope, such as\nJAXA's SOLAR-C mission. \n\n"}
{"id": "0910.0015", "contents": "Title: Hierarchical models of high redshift galaxies with thermally pulsing\n  asymptotic giant branch stars: comparison with observations Abstract: In a recent paper we presented the first semi-analytic model of galaxy\nformation in which the Thermally-Pulsing Asymptotic Giant Branch phase of\nstellar evolution has been fully implemented. Here we address the comparison\nwith observations, and show how the TP-AGB recipe affects the performance of\nthe model in reproducing the colours and near-IR luminosities of high-redshift\ngalaxies. We find that the semi-analytic model with the TP-AGB better matches\nthe colour-magnitude and colour-colour relations at z ~ 2, both for\nnearly-passive and for star-forming galaxies. The model with TP-AGB produces\nstar-forming galaxies with red V-K colours, thus revising the unique\ninterpretation of high-redshift red objects as 'red & dead'. We also show that\nwithout the TP-AGB the semi-analytic model fails at reproducing the observed\ncolours, a situation that cannot be corrected by dust reddening. We also\nexplore the effect of nebular emission on the predicted colour-magnitude\nrelation of star-forming galaxies, to conclude that it does not play a\nsignificant role in reddening their colours, at least in the range of\nstar-formation rates covered by the model. Finally, the rest-frame K-band\nluminosity function at z ~ 2.5 is more luminous by almost 1 magnitude. This\nindicates that the AGN feedback recipe that is adopted to regulate the\nhigh-mass end of the luminosity function should be sophisticated to take the\neffect of the stellar populations into account at high redshifts. \n\n"}
{"id": "0910.0257", "contents": "Title: Foundations of Supernova Cosmology Abstract: This is a brief sketch of the use of supernovae to measure cosmological\nparameters. It traces the early work, the events surrounding the discovery and\nverification of cosmic acceleration using SN Ia, and the efforts today to make\nsound inferences about the nature of dark energy. The prospects for minimizing\nsystematics by using near-infrared observations in the supernova restframe are\nemphasized. This could be an important point in the design of a JDEM that\nemploys supernovae to measure the history of cosmic expansion. \n\n"}
{"id": "0910.0391", "contents": "Title: QUBIC, a bolometric interferometer to measure the B modes of the CMB Abstract: Measuring the B modes of the CMB polarization fluctuations would provide very\nstrong constraints on inflation. The main challenge in this measurement is the\ntreatment of systematic effects. CMB observations with imagers and\ninterferometers, subject to very different systematics, are complementary in\nthis respect. Interferometry provides direct access to the Fourier transform of\nthe sky signal. In bolometric interferometry, the interference pattern produced\nby the sky through a few hundred horns is imaged on a bolometer array. Several\nsuch modules are needed to achieve the required sensitivity. We will describe\nQUBIC, a merger of the US and European MBI and BRAIN collaborations. QUBIC is a\npolarized bolometric interferometer to be deployed in 2011-2012. \n\n"}
{"id": "0910.1351", "contents": "Title: Solving the Corner-Turning Problem for Large Interferometers Abstract: The so-called corner turning problem is a major bottleneck for radio\ntelescopes with large numbers of antennas. The problem is essentially that of\nrapidly transposing a matrix that is too large to store on one single device;\nin radio interferometry, it occurs because data from each antenna needs to be\nrouted to an array of processors that will each handle a limited portion of the\ndata (a frequency range, say) but requires input from each antenna. We present\na low-cost solution allowing the correlator to transpose its data in real time,\nwithout contending for bandwidth, via a butterfly network requiring neither\nadditional RAM memory nor expensive general-purpose switching hardware. We\ndiscuss possible implementations of this using FPGA, CMOS, analog logic and\noptical technology, and conclude that the corner turner cost can be small even\nfor upcoming massive radio arrays. \n\n"}
{"id": "0910.1716", "contents": "Title: Multi-wavelength study of XMMU J2235.3-2557: the most massive galaxy\n  cluster at z > 1 Abstract: [Abridged] XMMU J2235.3-2557 is one of the most distant X-ray selected\nclusters, spectroscopically confirmed at z=1.39. We characterize the galaxy\npopulations of passive members, the thermodynamical properties of the hot gas,\nits metal abundance and the total mass of the system using imaging data with\nHST/ACS (i775 and z850 bands) and VLT/ISAAC (J and K_s bands), extensive\nspectroscopic data obtained with VLT/FORS2, and deep Chandra observations. Out\nof a total sample of 34 spectroscopically confirmed cluster members, we\nselected 16 passive galaxies within the central 2' (or 1 Mpc) with ACS\ncoverage, and inferred star formation histories for a sub-sample of galaxies\ninside and outside the core by modeling their spectro-photometric data with\nspectral synthesis models, finding a strong mean age radial gradient. Chandra\ndata show a regular elongated morphology, closely resembling the distribution\nof core galaxies, with a significant cool core. We measure a global X-ray\ntemperature of kT=8.6(-1.2,+1.3) keV (68% c.l.). By detecting the rest-frame\n6.7 keV Iron K line, we measure a metallicty Z= 0.26(+0.20,-0.16) Zsun. In the\nlikely hypothesis of hydrostatic equilibrium, we obtain a total mass of Mtot(<1\nMpc)=(5.9+-1.3)10^14 Msun. Overall, our analysis implies that XMM2235 is the\nhottest and most massive bona-fide cluster discovered to date at z>1, with a\nbaryonic content, both its galaxy population and intra-cluster gas, in a\nsignificantly advanced evolutionary stage at 1/3 of the current age of the\nUniverse. \n\n"}
{"id": "0910.3786", "contents": "Title: Weak lensing power spectra for precision cosmology: Multiple-deflection,\n  reduced shear and lensing bias corrections Abstract: It is usually assumed that the ellipticity power spectrum measured in weak\nlensing observations can be expressed as an integral over the underlying matter\npower spectrum. This is true at second order in the gravitational potential. We\nextend the standard calculation, constructing all corrections to fourth order\nin the gravitational potential. There are four types of corrections:\ncorrections to the lensing shear due to multiple-deflections; corrections due\nto the fact that shape distortions probe the reduced shear $\\gamma/(1-\\kappa)$\nrather than the shear itself; corrections associated with the non-linear\nconversion of reduced shear to mean ellipticity; and corrections due to the\nfact that observational galaxy selection and shear measurement is based on\ngalaxy brightnesses and sizes which have been (de)magnified by lensing. We show\nhow the previously considered corrections to the shear power spectrum\ncorrespond to terms in our analysis, and highlight new terms that were not\npreviously identified. All correction terms are given explicitly as integrals\nover the matter power spectrum, bispectrum, and trispectrum, and are\nnumerically evaluated for the case of sources at z=1. We find agreement with\nprevious works for the ${\\mathcal O}(\\Phi^3)$ terms. We find that for ambitious\nfuture surveys, the ${\\mathcal O}(\\Phi^4)$ terms affect the power spectrum at\nthe ~ 1-5 $\\sigma$ level; they will thus need to be accounted for, but are\nunlikely to represent a serious difficulty for weak lensing as a cosmological\nprobe. \n\n"}
{"id": "0910.4393", "contents": "Title: Photometric redshift estimation using Gaussian processes Abstract: We present a comparison between Gaussian processes (GPs) and artificial\nneural networks (ANNs) as methods for determining photometric redshifts for\ngalaxies, given training set data. In particular, we compare their degradation\nin performance as the training set size is degraded in ways which might be\ncaused by the observational limitations of spectroscopy. We find that\nperformance with large, complete training sets is very similar, although the\nANN achieves slightly smaller root mean square errors. If the size of the\ntraining set is reduced by random sampling, the RMS errors of both methods\nincrease, but they do so to a lesser extent and in a much smoother manner for\nthe case of GP regression. When training objects are removed at redshifts\n1.3<z<1.7, to simulate the effects of the \"redshift desert\" of optical\nspectroscopy, the GP regression is successful at interpolating across the\nredshift gap, while the ANN suffers from strong bias for test objects in this\nredshift range. Overall, GP regression has attractive properties for\nphotometric redshift estimation, particularly for deep, high-redshift surveys\nwhere it is difficult to obtain a large, complete training set. At present,\nunlike the ANN code, public GP regression codes do not take account of\ninhomogeneous measurement errors on the photometric data, and thus cannot\nestimate reliable uncertainties on the predicted redshifts. However, a better\ntreatment of errors is in principle possible, and the promising results in this\npaper suggest that such improved GP algorithms should be pursued. (abridged) \n\n"}
{"id": "0910.5059", "contents": "Title: How Universal are the Young Cluster Sequences? - the Cases of LMC, SMC,\n  M83 and the Antennae Abstract: Aims.Recently a new analysis of cluster observations in the Milky Way found\nevidence that clustered star formation may work under tight constraints with\nrespect to cluster size and density, implying the presence of just two\nsequences of young massive cluster. These two types of clusters each expand at\ndifferent rates with cluster age. Methods. Here we investigate whether similar\nsequences exist in other nearby galaxies. Results:We find that while for the\nextragalactic young stellar clusters the overall trend in the cluster-density\nscaling is quite comparable to the relation obtained for Galactic clusters,\nthere are also possible difference. For the LMC and SMC clusters the densities\nare below the Galactic data points and/or the core radii are smaller than those\nof data points with comparable density. For M83 and the Antenna clusters the\ncore radii are possibly comparable to the Galactic clusters but it is not clear\nwhether they exhibit similar expansion speeds. These findings should serve as\nan incentive to perform more systematic observations and analysis to answer the\nquestion of a possible similarity between young galactic and extragalactic star\nclusters sequences. \n\n"}
{"id": "0910.5269", "contents": "Title: IRAS 16293: A \"Magnetic\" Tale of Two Cores Abstract: We present polarization observations of the dust continuum emission from IRAS\n16293 which is a Class 0 protostar and is known to have at least two\ncomponents, source A and B. These measurements were conducted by the\nSubmillimeter Array (SMA) at a frequency of ~341 GHz and with high angular\nresolution (~2-3 arcseconds). We find that the large scale global direction of\nthe field, which is perpendicular to the observed polarization, appears to be\nalong the dust ridge where the emission peaks. On smaller scales we find that\nthe field structure is significantly different for the two components of the\nbinary. The first component, source A, shows a magnetic field structure which\nis \"hourglass\" shaped as predicted from theoretical models of low mass star\nformation in the presence of strong magnetic fields. However, the other\ncomponent, source B, shows a relatively ordered magnetic field with no evidence\nof any deformation. There is an observed decrease in polarization towards the\ncenter. Our calculations show that in IRAS 16293 the magnetic energy is\nstronger than the turbulent energy but is approximately similar to the\ncentrifugal energy. Our results provide additional evidence to show that the\ntwo protostars appear to be in different stages during their evolution. \n\n"}
{"id": "0911.0738", "contents": "Title: Prospects of Search for Solar Axions with Mass over 1 eV and Hidden\n  Sector Photons Abstract: We present prospects of two experiments using the Tokyo Axion Helioscope. One\nis a search for solar axions. In the past measurements, axion mass from 0 to\n0.27 eV and from 0.84 to 1.00 eV have been scanned and no positive evidence was\nseen. We are now actively preparing a new phase of the experiment aiming at\naxion mass over 1 eV. The other is a search for hidden sector photons from the\nSun. We have been designing and testing some additional equipments, which have\nto be installed on the helioscope to search for hidden photons with mass of\nover $10^{-3}$ eV. \n\n"}
{"id": "0911.0795", "contents": "Title: Binaries in star clusters and the origin of the field stellar population Abstract: Many, possibly most, stars form in binary and higher-order multiple systems.\nTherefore, the properties and frequency of binary systems provide strong clues\nto the star-formation process, and constraints on star-formation models.\nHowever, the majority of stars also form in star clusters in which the birth\nbinary properties and frequency can be altered rapidly by dynamical processing.\nThus, we almost never see the birth population, which makes it very difficult\nto know if star formation (as traced by binaries, at least) is universal, or if\nit depends on environment. In addition, the field population consists of a\nmixture of systems from different clusters which have all been processed in\ndifferent ways. \n\n"}
{"id": "0911.0976", "contents": "Title: Neutrino mass from cosmology: Impact of high-accuracy measurement of the\n  Hubble constant Abstract: Non-zero neutrino mass would affect the evolution of the Universe in\nobservable ways, and a strong constraint on the mass can be achieved using\ncombinations of cosmological data sets. We focus on the power spectrum of\ncosmic microwave background (CMB) anisotropies, the Hubble constant H_0, and\nthe length scale for baryon acoustic oscillations (BAO) to investigate the\nconstraint on the neutrino mass, m_nu. We analyze data from multiple existing\nCMB studies (WMAP5, ACBAR, CBI, BOOMERANG, and QUAD), recent measurement of H_0\n(SHOES), with about two times lower uncertainty (5%) than previous estimates,\nand recent treatments of BAO from the Sloan Digital Sky Survey (SDSS). We\nobtained an upper limit of m_nu < 0.2eV (95% C.L.), for a flat LambdaCDM model.\nThis is a 40% reduction in the limit derived from previous H_0 estimates and\none-third lower than can be achieved with extant CMB and BAO data. We also\nanalyze the impact of smaller uncertainty on measurements of H_0 as may be\nanticipated in the near term, in combination with CMB data from the Planck\nmission, and BAO data from the SDSS/BOSS program. We demonstrate the\npossibility of a 5 sigma detection for a fiducial neutrino mass of 0.1eV or a\n95% upper limit of 0.04eV for a fiducial of m_nu = 0eV. These constraints are\nabout 50% better than those achieved without external constraint. We further\ninvestigate the impact on modeling where the dark-energy equation of state is\nconstant but not necessarily -1, or where a non-flat universe is allowed. In\nthese cases, the next-generation accuracies of Planck, BOSS, and 1% measurement\nof H_0 would all be required to obtain the limit m_nu < 0.05 - 0.06eV (95%\nC.L.) for the fiducial of m_nu = 0eV. The independence of systematics argues\nfor pursuit of both BAO and H_0 measurements. \n\n"}
{"id": "0911.1788", "contents": "Title: The Observed Growth of Massive Galaxy Clusters IV: Robust Constraints on\n  Neutrino Properties Abstract: This is the fourth of a series of papers in which we derive simultaneous\nconstraints on cosmological parameters and X-ray scaling relations using\nobservations of the growth of massive, X-ray flux-selected galaxy clusters.\nHere we examine the constraints on neutrino properties that are enabled by the\nprecise and robust constraint on the amplitude of the matter power spectrum at\nlow redshift that is available from our data. In combination with cluster\ngas-mass fraction, cosmic microwave background, supernova and baryon acoustic\noscillation data, and incorporating conservative allowances for systematic\nuncertainties, we limit the species-summed neutrino mass, M_nu, to <0.33 eV at\n95.4 per cent confidence in a spatially flat, cosmological constant (LambdaCDM)\nmodel. In a flat LambdaCDM model where the effective number of neutrino\nspecies, N_eff, is allowed to vary, we find N_eff = 3.4 -0.5 +0.6 (68.3 per\ncent confidence, incorporating a direct constraint on the Hubble parameter from\nCepheid and supernova data). We also obtain results with additional degrees of\nfreedom in the cosmological model, in the form of global spatial curvature\n(Omega_k) and a primordial spectrum of tensor perturbations (r and n_t). The\nresults are not immune to these generalizations; however, in the most general\ncase we consider, in which M_nu, N_eff, curvature and tensors are all free, we\nstill obtain M_nu < 0.70 eV and N_eff = 3.7 +- 0.7 (at respectively the same\nconfidence levels as above). These results agree well with recent work using\nindependent data, and highlight the importance of measuring cosmic structure\nand expansion at low as well as high redshifts. Although our cluster data\nextend to redshift z=0.5, the effect of neutrino mass on the growth of\nstructure at late times is not yet detected at a significant level. \n\n"}
{"id": "0911.3243", "contents": "Title: A re--analysis of the iron line in the XMM-Newton data from the low/hard\n  state in GX339--4 Abstract: The detection of an extremely broad iron line in XMM-Newton MOS data from the\nlow/hard state of the black hole binary GX339-4 is the only piece of evidence\nwhich unambiguously conflicts with the otherwise extremely successful truncated\ndisc interpretation of this state. However, it also conflicts with some aspect\nof observational data for all other alternative geometries of the low/hard\nstate, including jet models, making it very difficult to understand. We\nre-analyse these data and show that they are strongly affected by pileup even\nwith extensive centroid removal as the source is ~200x brighter than the\nrecommended maximum countrate. Instead, we extract the simultaneous PN timing\nmode data which should not be affected by pileup. These show a line which is\nsignificantly narrower than in the MOS data. Thus these data are easily\nconsistent with a truncated disc, and indeed, strongly support such an\ninterpretation. \n\n"}
{"id": "0911.4448", "contents": "Title: Tuning of Kilopixel Transition Edge Sensor Bolometer Arrays with a\n  Digital Frequency Multiplexed Readout System Abstract: A digital frequency multiplexing (DfMUX) system has been developed and used\nto tune large arrays of transition edge sensor (TES) bolometers read out with\nSQUID arrays for mm-wavelength cosmology telescopes. The DfMUX system\nmultiplexes the input bias voltages and output currents for several bolometers\non a single set of cryogenic wires. Multiplexing reduces the heat load on the\ncamera's sub-Kelvin cryogenic detector stage. In this paper we describe the\nalgorithms and software used to set up and optimize the operation of the\nbolometric camera. The algorithms are implemented on soft processors embedded\nwithin FPGA devices operating on each backend readout board. The result is a\nfully parallelized implementation for which the setup time is independent of\nthe array size. \n\n"}
{"id": "0911.4956", "contents": "Title: Introducing ADAPTSMOOTH, a new code for the adaptive smoothing of\n  astronomical images Abstract: We introduce and publicly release a new code, ADAPTSMOOTH, which serves to\nsmooth astronomical images in an adaptive fashion, in order to enhance the\nsignal-to-noise ratio (S/N). The adaptive smoothing scheme allows to take full\nadvantage of the spatially resolved photometric information contained in an\nimage in that at any location the minimal smoothing is applied to reach the\nrequested S/N. Support is given to match more images on the same smoothing\nlength, such that proper estimates of local colours can be done, with a big\npotential impact on multi-wavelength studies of extended sources (galaxies,\nnebulae). Different modes to estimate local S/N are provided. In addition to\nclassical arithmetic-mean averaging mode, the code can operate in median\naveraging mode, resulting in a significant enhancement of the final image\nquality and very accurate flux conservation. To this goal also other code\noptions are implemented and discussed in this paper. Finally, we analyze in\ngreat detail the effect of the adaptive smoothing on galaxy photometry, in\nparticular in terms of surface brightness (SB) profiles and aperture\nphotometry: deviations in SB with respect to the original image can be limited\nto <0.01 mag, with flux difference in apertures of less than 0.001 mag. \n\n"}
{"id": "0911.5056", "contents": "Title: The Planck On-Flight Forecaster (POFF) Abstract: The Planck On-Fligh Forecaster (POFF) is a tool to predict when a position in\nthe sky will be within a selected angular distance from any receiver direction\nof the Planck satellite according to its pre-programmed observational strategy.\nThis tool has been developed in the framework of the Planck LFI Core Team\nactivities, but it is now used by the whole collaboration. In this paper we\nwill describe the tool and its applications to plan observations with other\ninstruments of point sources which are expected to enhance the possibilities of\nscientific exploitation of the Planck satellite data, once they will be\npublicly available. Collecting simultaneous multi-frequency data, like those\nthat can be planned with the POFF, will help, on one hand, to investigate\nvariability of point sources and, on the other, to reconstruct point source\nspectral energy distributions on wide frequency ranges minimizing the effects\ndue to source variability. POFF is a combination of IDL routines which combine\nthe publicly available information about the Planck scanning strategy and focal\nplane shape in order to identify if a given (list of) position(s) can be\nobservable by the satellite at a given frequency and/or by selected receivers\nin a given time range. The output can be displayed with the desired time\nresolution and selecting among various sorting options. The code is not a\nPlanck product, but it has been validated within the Planck LFI pipeline. The\ncode format and the large number of options make it flexible and suitable for\nmany applications, allowing to get results quickly. POFF is currently\nsuccessfully used to plan activities within the Planck collaboration, including\nobservations with several ground-based facilities, and it is distributed\noutside it. \n\n"}
{"id": "0911.5453", "contents": "Title: Calibration of liquid argon and neon detectors with $^{83}Kr^m$ Abstract: We report results from tests of $^{83}$Kr$^{\\mathrm{m}}$, as a calibration\nsource in liquid argon and liquid neon. $^{83}$Kr$^{\\mathrm{m}}$ atoms are\nproduced in the decay of $^{83}$Rb, and a clear $^{83}$Kr$^{\\mathrm{m}}$\nscintillation peak at 41.5 keV appears in both liquids when filling our\ndetector through a piece of zeolite coated with $^{83}$Rb. Based on this\nscintillation peak, we observe 6.0 photoelectrons/keV in liquid argon with a\nresolution of 6% ($\\sigma$/E) and 3.0 photoelectrons/keV in liquid neon with a\nresolution of 19% ($\\sigma$/E). The observed peak intensity subsequently decays\nwith the $^{83}$Kr$^{\\mathrm{m}}$ half-life after stopping the fill, and we\nfind evidence that the spatial location of $^{83}$Kr$^{\\mathrm{m}}$ atoms in\nthe chamber can be resolved. $^{83}$Kr$^{\\mathrm{m}}$ will be a useful\ncalibration source for liquid argon and neon dark matter and solar neutrino\ndetectors. \n\n"}
{"id": "0912.0635", "contents": "Title: Analysis of Peculiarities of the Stellar Velocity Field in the Solar\n  Neighborhood Abstract: Based on a new version of the Hipparcos catalogue and an updated\nGeneva-Copenhagen survey of F and G dwarfs, we analyze the space velocity field\nof about 17000 single stars in the solar neighborhood. The main known clumps,\nstreams, and branches (Pleiades, Hyades, Sirius, Coma Berenices, Hercules, Wolf\n630-alpha Ceti, and Arcturus) have been identified using various approaches.\nThe evolution of the space velocity field for F and G dwarfs has been traced as\na function of the stellar age. We have managed to confirm the existence of the\nrecently discovered KFR08 stream. We have found 19 Hipparcos stars, candidates\nfor membership in the KFR08 stream, and obtained an isochrone age estimate for\nthe stream, 13 Gyr. The mean stellar ages of the Wolf 630-alpha Ceti and\nHercules streams are shown to be comparable, 4--6 Gyr. No significant\ndifferences in the metallicities of stars belonging to these streams have been\nfound. This is an argument for the hypothesis that these streams owe their\norigin to a common mechanism. \n\n"}
{"id": "0912.1855", "contents": "Title: Are astronomical papers with more authors cited more? Abstract: Following my previous study of paper length vs. number of citations in\nastronomy (Stanek 2008), some colleagues expressed an interest in knowing if\nany correlation exists between citations and the number of authors on an\nastronomical paper. At least naively, one would expect papers with more authors\nto be cited more. I test this expectation with the same sample of papers as\nanalyzed in Stanek (2008), selecting all (~30,000) refereed papers from A&A,\nAJ, ApJ and MNRAS published between 2000 and 2004. (...) I find that indeed\npapers with more authors are on average cited more, but only weakly so:\nroughly, the number of citations doubles with ten-fold increase in the number\nof authors. While the median number of citations to a 2 author paper is 17, the\nmedian number of citations to a paper with 10 to 20 authors is 32. I find that\nmost of the papers are written by a small number of authors, with a mode of 2\nauthors and a median of 3 authors. I also find that papers with more authors\nare not longer than papers with fewer authors, in fact a median number of 8 to\n10 pages per paper holds for any number of authors. For the same sample of\npapers, a median number of citations per paper grew from 15 in June 2008\n(Stanek 2008) to 19 in November 2009. Unlike Stanek (2008), I do not conclude\nwith any career advice, semi-humorous or otherwise. \n\n"}
{"id": "0912.1931", "contents": "Title: X-Ray Studies of HESS J1809-193 with Suzaku Abstract: Suzaku observed the region including HESS J1809-193, one of the TeV\nunidentified (unID) sources, and confirmed existence of the extended hard X-ray\nemission previously reported by ASCA, as well as hard X-ray emission from the\npulsar PSR J1809-1917 in the region. One-dimensional profile of the diffuse\nemission is represented with a Gaussian model with the best-fit sigma of 7+-1\narcmin. The diffuse emission extends for at least 21 pc (at the 3sigma level,\nassuming the distance of 3.5 kpc), and has a hard spectrum with the photon\nindex of Gamma ~1.7. The hard spectrum suggests the pulsar wind nebula (PWN)\norigin, which is also strengthened by the hard X-ray emission from PSR\nJ1809-1917 itself. Thanks to the low background of Suzaku XIS, we were able to\ninvestigate spatial variation of the energy spectrum, but no systematic\nspectral change in the extended emission is found. These results imply that the\nX-ray emitting pulsar wind electrons can travel up to 21 pc from the pulsar\nwithout noticeable energy loss via synchrotron emission. \n\n"}
{"id": "0912.2054", "contents": "Title: Time-Dependent Models for the Afterglows of Massive Black Hole Mergers Abstract: The Laser Interferometer Space Antenna (LISA) will detect gravitational wave\nsignals from coalescing pairs of massive black holes in the total mass range\n(10^5 - 10^7)/Msol out to cosmological distances. Identifying and monitoring\nthe electromagnetic counterparts of these events would enable cosmological\nstudies and offer new probes of gas physics around well-characterized massive\nblack holes. Milosavljevic & Phinney (2005) proposed that a circumbinary disk\naround a binary of mass ~10^6 Msol will emit an accretion-powered X-ray\nafterglow approximately one decade after the gravitational wave event. We\nrevisit this scenario by using Green's function solutions to calculate the\ntemporal viscous evolution and the corresponding electromagnetic signature of\nthe circumbinary disk. Our calculations suggest that an electromagnetic\ncounterpart may become observable as a rapidly brightening source soon after\nthe merger, i.e. several years earlier than previously thought. The afterglow\ncan reach super-Eddington luminosities without violating the local Eddington\nflux limit. It is emitted in the soft X-ray by the innermost circumbinary disk,\nbut it may be partially reprocessed at optical and infrared frequencies. We\nalso find that the spreading disk becomes increasingly geometrically thick\nclose to the central object as it evolves, indicating that the innermost flow\ncould become advective and radiatively inefficient, and generate a powerful\noutflow. We conclude that the mergers of massive black holes detected by LISA\noffer unique opportunities for monitoring on humanly tractable timescales the\nviscous evolution of accretion flows and the emergence of outflows around\nmassive black holes with precisely known masses, spins and orientations. \n\n"}
{"id": "0912.2478", "contents": "Title: Inert-Sterile Neutrino: Cold or Warm Dark Matter Candidate Abstract: In usual particle models, sterile neutrinos can account for the dark matter\nof the Universe only if they have masses in the keV range and are warm dark\nmatter. Stringent cosmological and astrophysical bounds, in particular imposed\nby X-ray observations, apply to them. We point out that in a particular\nvariation of the inert doublet model, sterile neutrinos can account for the\ndark matter in the Universe and may be either cold or warm dark matter\ncandidates, even for masses much larger than the keV range. These Inert-Sterile\nneutrinos, produced non-thermally in the early Universe, would be stable and\nhave very small couplings to Standard Model particles, rendering very difficult\ntheir detection in either direct or indirect dark matter searches. They could\nbe, in principle, revealed in colliders by discovering other particles in the\nmodel. \n\n"}
{"id": "0912.2738", "contents": "Title: Fast and precise map-making for massively multi-detector CMB experiments Abstract: Future cosmic microwave background (CMB) polarisation experiments aim to\nmeasure an unprecedentedly small signal - the primordial gravity wave component\nof the polarisation field B-mode. To achieve this, they will analyse huge\ndatasets, involving years worth of time-ordered data (TOD) from massively\nmulti-detector focal planes. This creates the need for fast and precise methods\nto complement the M-L approach in analysis pipelines. In this paper, we\ninvestigate fast map-making methods as applied to long duration, massively\nmulti-detector, ground-based experiments, in the context of the search for\nB-modes. We focus on two alternative map-making approaches: destriping and TOD\nfiltering, comparing their performance on simulated multi-detector polarisation\ndata. We have written an optimised, parallel destriping code, the DEStriping\nCARTographer DESCART, that is generalised for massive focal planes, including\nthe potential effect of cross-correlated TOD 1/f noise. We also determine the\nscaling of computing time for destriping as applied to a simulated full-season\ndata-set for a realistic experiment. We find that destriping can out-perform\nfiltering in estimating both the large-scale E and B-mode angular power\nspectra. In particular, filtering can produce significant spurious B-mode power\nvia EB mixing. Whilst this can be removed, it contributes to the variance of\nB-mode bandpower estimates at scales near the primordial B-mode peak. For the\nexperimental configuration we simulate, this has an effect on the possible\ndetection significance for primordial B-modes. Destriping is a viable\nalternative fast method to the full M-L approach that does not cause the\nproblems associated with filtering, and is flexible enough to fit into both M-L\nand Monte-Carlo pseudo-Cl pipelines. \n\n"}
{"id": "0912.3448", "contents": "Title: Geometry and Morphology of the Cosmic Web: Analyzing Spatial Patterns in\n  the Universe Abstract: We review the analysis of the Cosmic Web by means of an extensive toolset\nbased on the use of Delaunay and Voronoi tessellations. The Cosmic Web is the\nsalient and pervasive foamlike pattern in which matter has organized itself on\nscales of a few up to more than a hundred Megaparsec. First, we describe the\nDelaunay Tessellation Field Estimator (DTFE). The DTFE formalism is shown to\nrecover the hierarchical nature and the anisotropic morphology of the cosmic\nmatter distribution. The Multiscale Morphology Filter (MMF) uses the DTFE\ndensity field to extract the diverse morphological elements - filaments, sheets\nand clusters - on the basis of a ScaleSpace analysis which searches for these\nmorphologies over a range of scales. Subsequently, we discuss the Watershed\nVoidfinder (WVF), which invokes the discrete watershed transform to identify\nvoids in the cosmic matter distribution. The WVF is able to determine the\nlocation, size and shape of the voids. The watershed transform is also a key\nelement in the SpineWeb analysis of the cosmic matter distribution. It allows\nthe determination of the filamentary spine and connected walls in the cosmic\nmatter density field through the identification of the singularities and\ncorresponding separatrices. Finally, we describe the concept of Alphashapes for\nassessing the topology of the cosmic matter distribution. \n\n"}
{"id": "0912.3554", "contents": "Title: Chandra Observations of WR147 Reveal a Double X-ray Source Abstract: We report the first results from deep X-ray observations of the Wolf-Rayet\nbinary system WR147 with the Chandra HETG. Analysis of the zeroth order data\nreveals that WR147 is a double X-ray source. The northern counterpart is likely\nassociated with the colliding wind region, while the southern component is\ncertainly identified with the WN star in this massive binary. The latter is the\nsource of high energy X-rays (including the Fe K_alpha complex at 6.67 keV)\nwhose production mechanism is yet unclear. For the first time, X-rays are\nobserved directly from a WR star in a binary system. \n\n"}
{"id": "0912.5423", "contents": "Title: Comments on SUSY inflation models on the brane Abstract: In this paper we consider a class of inflation models on the brane where the\ndominant part of the inflaton scalar potential does not depend on the inflaton\nfield value during inflation. In particular, we consider supernatural\ninflation, its hilltop version, A-term inflation, and supersymmetric (SUSY) D-\nand F-term hybrid inflation on the brane. We show that the parameter space can\nbe broadened, the inflation scale generally can be lowered, and still possible\nto have the spectral index $n_s=0.96$. \n\n"}
{"id": "1001.0719", "contents": "Title: Comment on \"Bayesian evidence: can we beat MultiNest using traditional\n  MCMC methods\", by Rutger van Haasteren (arXiv:0911.2150) Abstract: In arXiv:0911.2150, Rutger van Haasteren seeks to criticize the nested\nsampling algorithm for Bayesian data analysis in general and its MultiNest\nimplementation in particular. He introduces a new method for evidence\nevaluation based on the idea of Voronoi tessellation and requiring samples from\nthe posterior distribution obtained through MCMC based methods. He compares its\naccuracy and efficiency with MultiNest, concluding that it outperforms\nMultiNest in several cases. This comparison is completely unfair since the\nproposed method can not perform the complete Bayesian data analysis including\nposterior exploration and evidence evaluation on its own while MultiNest allows\none to perform Bayesian data analysis end to end. Furthermore, their criticism\nof nested sampling (and in turn MultiNest) is based on a few conceptual\nmisunderstandings of the algorithm. Here we seek to set the record straight. \n\n"}
{"id": "1001.2037", "contents": "Title: Gravitationally lensed quasars and supernovae in future wide-field\n  optical imaging surveys Abstract: Cadenced optical imaging surveys in the next decade will be capable of\ndetecting time-varying galaxy-scale strong gravitational lenses in large\nnumbers, increasing the size of the statistically well-defined samples of\nmultiply-imaged quasars by two orders of magnitude, and discovering the first\nstrongly-lensed supernovae. We carry out a detailed calculation of the likely\nyields of several planned surveys, using realistic distributions for the lens\nand source properties and taking magnification bias and image configuration\ndetectability into account. We find that upcoming wide-field synoptic surveys\nshould detect several thousand lensed quasars. In particular, the LSST should\nfind 8000 lensed quasars, 3000 of which will have well-measured time delays,\nand also ~130 lensed supernovae, which is compared with ~15 lensed supernovae\npredicted to be found by the JDEM. We predict the quad fraction to be ~15% for\nthe lensed quasars and ~30% for the lensed supernovae. Generating a mock\ncatalogue of around 1500 well-observed double-image lenses, we compute the\navailable precision on the Hubble constant and the dark energy equation\nparameters for the time delay distance experiment (assuming priors from\nPlanck): the predicted marginalised 68% confidence intervals are\n\\sigma(w_0)=0.15, \\sigma(w_a)=0.41, and \\sigma(h)=0.017. While this is\nencouraging in the sense that these uncertainties are only 50% larger than\nthose predicted for a space-based type-Ia supernova sample, we show how the\ndark energy figure of merit degrades with decreasing knowledge of the the lens\nmass distribution. (Abridged) \n\n"}
{"id": "1001.2048", "contents": "Title: Advanced Architectures for Astrophysical Supercomputing Abstract: Astronomers have come to rely on the increasing performance of computers to\nreduce, analyze, simulate and visualize their data. In this environment, faster\ncomputation can mean more science outcomes or the opening up of new parameter\nspaces for investigation. If we are to avoid major issues when implementing\ncodes on advanced architectures, it is important that we have a solid\nunderstanding of our algorithms. A recent addition to the high-performance\ncomputing scene that highlights this point is the graphics processing unit\n(GPU). The hardware originally designed for speeding-up graphics rendering in\nvideo games is now achieving speed-ups of $O(100\\times)$ in general-purpose\ncomputation -- performance that cannot be ignored. We are using a generalized\napproach, based on the analysis of astronomy algorithms, to identify the\noptimal problem-types and techniques for taking advantage of both current GPU\nhardware and future developments in computing architectures. \n\n"}
{"id": "1001.2834", "contents": "Title: Design and Performance of the XENON10 Dark Matter Experiment Abstract: XENON10 is the first two-phase xenon time projection chamber (TPC) developed\nwithin the XENON dark matter search program. The TPC, with an active liquid\nxenon (LXe) mass of about 14 kg, was installed at the Gran Sasso underground\nlaboratory (LNGS) in Italy, and operated for more than one year, with excellent\nstability and performance. Results from a dark matter search with XENON10 have\nbeen published elsewhere. In this paper, we summarize the design and\nperformance of the detector and its subsystems, based on calibration data using\nsources of gamma-rays and neutrons as well as background and Monte Carlo\nsimulations data. The results on the detector's energy threshold, energy and\nposition resolution, and overall efficiency show a performance that exceeds\ndesign specifications, in view of the very low energy threshold achieved (<10\nkeVr) and the excellent energy resolution achieved by combining the ionization\nand scintillation signals, detected simultaneously. \n\n"}
{"id": "1001.4061", "contents": "Title: Exploring the possibility of detecting dark energy in a terrestrial\n  experiment using atom interferometry Abstract: The majority of astronomers and physicists accept the reality of dark energy\nbut also believe it can only be studied indirectly through observation of the\nmotions of galaxies. This paper opens the experimental question of whether it\nis possible to directly detect dark energy on earth using atom interferometry\nthrough a force hypothetically caused by a gradient in the dark energy density.\nOur proposed experimental design is outlined. The possibility of detecting\nother weak fields is briefly discussed. \n\n"}
{"id": "1001.4633", "contents": "Title: Planck LFI flight model feed horns Abstract: this paper is part of the Prelaunch status LFI papers published on JINST:\nhttp://www.iop.org/EJ/journal/-page=extra.proc5/jinst The Low Frequency\nInstrument is optically interfaced with the ESA Planck telescope through 11\ncorrugated feed horns each connected to the Radiometer Chain Assembly (RCA).\nThis paper describes the design, the manufacturing and the testing of the\nflight model feed horns. They have been designed to optimize the LFI optical\ninterfaces taking into account the tight mechanical requirements imposed by the\nPlanck focal plane layout. All the eleven units have been successfully tested\nand integrated with the Ortho Mode transducers. \n\n"}
{"id": "1001.4731", "contents": "Title: Seven-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations:\n  Planets and Celestial Calibration Sources Abstract: (Abridged) We present WMAP seven-year observations of bright sources which\nare often used as calibrators at microwave frequencies. Ten objects are studied\nin five frequency bands (23 - 94 GHz): the outer planets (Mars, Jupiter,\nSaturn, Uranus and Neptune) and five fixed celestial sources (Cas A, Tau A, Cyg\nA, 3C274 and 3C58). The seven-year analysis of Jupiter provides temperatures\nwhich are within 1-sigma of the previously published WMAP five-year values,\nwith slightly tighter constraints on variability with orbital phase, and limits\n(but no detections) on linear polarization. Scaling factors are provided which,\nwhen multiplied by the Wright Mars thermal model predictions at 350 micron,\nreproduce WMAP seasonally averaged observations of Mars within ~2%. An\nempirical model is described which fits brightness variations of Saturn due to\ngeometrical effects and can be used to predict the WMAP observations to within\n3%. Seven-year mean temperatures for Uranus and Neptune are also tabulated.\nUncertainties in Uranus temperatures are 3%-4% in the 41, 61 and 94 GHz bands;\nthe smallest uncertainty for Neptune is ~8% for the 94 GHz band. Intriguingly,\nthe spectrum of Uranus appears to show a dip at ~30 GHz of unidentified origin,\nalthough the feature is not of high statistical significance. Flux densities\nfor the five selected fixed celestial sources are derived from the seven-year\nWMAP sky maps, and are tabulated for Stokes I, Q and U, along with polarization\nfraction and position angle. Fractional uncertainties for the Stokes I fluxes\nare typically 1% to 3%. Source variability over the seven-year baseline is also\nestimated. Significant secular decrease is seen for Cas A and Tau A: our\nresults are consistent with a frequency independent decrease of about 0.53% per\nyear for Cas A and 0.22% per year for Tau A. \n\n"}
{"id": "1002.1194", "contents": "Title: The Soft X-ray Imager on board EXIST Abstract: The Soft X-ray Imager (SXI) is one of the three instruments on board EXIST, a\nmulti-wavelength observatory in charge of performing a global survey of the sky\nin hard X-rays searching for Super-massive Black Holes (Grindlay & Natalucci,\nthese Proceedings). One of the primary objectives of EXIST is also to study\nwith unprecedented sensitivity the most unknown high energy sources in the\nUniverse, like high redshift GRBs, which will be pointed promptly by the\nSpacecraft by autonomous trigger based on hard X-ray localization on board. The\npresence of a soft X-ray telescope with an effective area of about 950cm2 in\nthe energy band 0.2-3 keV and extended response up to 10 keV will allow to make\nbroadband studies from 0.1 to 600 keV. In particular, investigations of the\nspectra components and states of AGNs and monitoring of variability of sources,\nstudy of the prompt and afterglow emission of GRBs since the early phases,\nwhich will help to constrain the emission models and finally, help the\nidentification of sources in the EXIST hard X-ray survey and the\ncharacterization of the transient events detected. SXI will also perform\nsurveys: a scanning survey with sky coverage 2pi and a limiting flux of\n5x10^(-14) cgs plus other serendipitous. \n\n"}
{"id": "1002.1479", "contents": "Title: The effects of charge transfer inefficiency (CTI) on galaxy shape\n  measurements Abstract: (Abridged) We examine the effects of charge transfer inefficiency (CTI)\nduring CCD readout on galaxy shape measurements required by studies of weak\ngravitational lensing. We simulate a CCD readout with CTI such as that caused\nby charged particle radiation damage. We verify our simulations on data from\nlaboratory-irradiated CCDs. Only charge traps with time constants of the same\norder as the time between row transfers during readout affect galaxy shape\nmeasurements. We characterize the effects of CTI on various galaxy populations.\nWe baseline our study around p-channel CCDs that have been shown to have charge\ntransfer efficiency up to an order of magnitude better than several models of\nn-channel CCDs designed for space applications. We predict that for galaxies\nfurthest from the readout registers, bias in the measurement of galaxy shapes,\nDelta(e), will increase at a rate of 2.65 +/- 0.02 x 10^(-4) per year at L2 for\naccumulated radiation exposure averaged over the solar cycle. If uncorrected,\nthis will consume the entire shape measurement error budget of a dark energy\nmission within about 4 years. Software mitigation techniques demonstrated\nelsewhere can reduce this by a factor of ~10, bringing the effect well below\nmission requirements. CCDs with higher CTI than the ones we studeied may not\nmeet the requirements of future dark energy missions. We discuss ways in which\nhardware could be designed to further minimize the impact of CTI. \n\n"}
{"id": "1002.1715", "contents": "Title: The Morphologies and Lifetimes of Transitional Protoplanetary Disks Abstract: I describe new constraints on the lifetimes and morphologies of transitional\nprotoplanetary disks from observations of 1--10 Myr old stars with the\n\\textit{Spitzer Space Telescope}. New Spitzer results clearly show evidence for\ntwo kinds of transitional disks and thus two main disk evolutionary pathways:\ndisks which form an inner hole/gap and clear from the inside out and disks that\ndeplete more homologously. Analyzing the disk populations of 1--10 Myr old\nclusters such as Taurus, IC 348, NGC 2362, and $\\eta$ Cha show that the mean\ntransitional disk lifetime must be an appreciable fraction of the mean\nprotoplanetary disk lifetime: $\\approx$ 1 Myr out of 3--5 Myr. The varieties of\ntransitional disk SEDs and correlations with other disk diagnostics are\nconsistent with multiple mechanisms responsible for clearing disks. \n\n"}
{"id": "1002.3038", "contents": "Title: Prospects of Stellar Abundance Studies from Near-IR Spectra Observed\n  with the E-ELT Abstract: In 2006 ESO Council authorized a Phase B study of a European AO-telescope\nwith a 42 m segmented primary with a 5-mirror design, the E-ELT. Several\nreports and working groups have already presented science cases for an E-ELT,\nspecifically exploiting the new capabilities of such a large telescope. One of\nthe aims of the design has been to find a balance in the performances between\nan E-ELT and the James Webb Space Telescope, JWST. Apart from the larger\nphoton-collecting area, the strengths of the former is the higher attainable\nspatial and spectral resolutions. The E-ELT AO system will have an optimal\nperformance in the near-IR, which makes it specially advantageous.\nHigh-resolution spectroscopy in the near-infrared has, however, not been\ndiscussed much. This paper aims at filling that gap, by specifically discussing\nspectroscopy of stellar (mainly red giant), photospheric abundances. Based on\nstudies in the literature of stellar abundances, at the needed medium to high\nspectral resolutions in the near-infrared (0.8-2.4 microns), I will try to\nextrapolate published results to the performance of the E-ELT and explore what\ncould be done at the E-ELT in this field. A discussion on what instrument\ncharacteristics that would be needed for stellar abundance analyses in the\nnear-IR will be given. \n\n"}
{"id": "1002.3101", "contents": "Title: Cosmological perturbations in a healthy extension of Horava gravity Abstract: In Horava's theory of gravity, Lorentz symmetry is broken in exchange for\nrenormalizability, but the original theory has been argued to be plagued with\nproblems associated with a new scalar mode stemming from the very breaking of\nLorentz symmetry. Recently, Blas, Pujolas, and Sibiryakov have proposed a\nhealthy extension of Horava gravity, in which the behavior of the scalar mode\nis improved. In this paper, we study scalar modes of cosmological perturbations\nin extended Horava gravity. The evolution of metric and density perturbations\nis addressed analytically and numerically. It is shown that for vanishing\nnon-adiabatic pressure of matter the large scale evolution of cosmological\nperturbations converges to that described by a single constant, $\\zeta$, which\nis an analog of a curvature perturbation on the uniform-density slicing\ncommonly used in usual gravitational theories. The subsequent evolution is thus\ndetermined completely by the value of $\\zeta$. \n\n"}
{"id": "1002.4619", "contents": "Title: The jet/disk connection in blazars Abstract: The new high energy data coming mainly from the Fermi and Swift satellites\nand from the ground based Cerenkov telescopes are making possible to study not\nonly the energetics of blazar jets, but also their connection to the associated\naccretion disks. Furthermore, the black hole mass of the most powerful objects\ncan be constrained through IR-optical emission, originating in the accretion\ndisks. For the first time, we can evaluate jet and accretion powers in units of\nthe Eddington luminosity for a large number of blazars. Firsts results are\nintriguing. Blazar jets have powers comparable to, and often larger than the\nluminosity produced by their accretion disk. Blazar jets are produced at all\naccretion rates (in Eddington units), and their appearance depends if the\naccretion regime is radiatively efficient or not. The jet power is dominated by\nthe bulk motion of matter, not by the Poynting flux, at least in the jet region\nwhere the bulk of the emission is produced, at ~1000 Schwarzschild radii. The\nmechanism at the origin of relativistic jets must be very efficient, possibly\nmore than accretion, even if accretion must play a crucial role. Black hole\nmasses for the most powerful jets at redshift ~3 exceed one billion solar\nmasses, flagging the existence of a very large population of heavy black holes\nat these redshifts. \n\n"}
{"id": "1002.4702", "contents": "Title: An educated search for transiting habitable planets. Targetting M dwarfs\n  with known transiting planets Abstract: Because the planets of a system form in a flattened disk, they are expected\nto share similar orbital inclinations at the end of their formation. The\nhigh-precision photometric monitoring of stars known to host a transiting\nplanet could thus reveal the transits of one or more other planets. We\ninvestigate here the potential of this approach for the M dwarf GJ 1214 that\nhosts a transiting super-Earth. For this system, we infer the transit\nprobabilities as a function of orbital periods. Using Monte-Carlo simulations\nwe address both the cases for fully coplanar and for non-coplanar orbits, with\nthree different choices of inclinations distribution for the non-coplanar case.\nGJ 1214 reveals to be a very promising target for the considered approach.\nBecause of its small size, a ground-based photometric monitoring of this star\ncould detect the transit of a habitable planet as small as the Earth, while a\nspace-based monitoring could detect any transiting habitable planet down to the\nsize of Mars. The mass measurement of such a small planet would be out of reach\nfor current facilities, but we emphasize that a planet mass would not be needed\nto confirm the planetary nature of the transiting object. Furthermore, the\nradius measurement combined with theoretical arguments would help us to\nconstrain the structure of the planet. \n\n"}
{"id": "1003.0039", "contents": "Title: Two Lensed Lyman-alpha Emitting Galaxies at z~5 Abstract: We present observations of two strongly lensed $z\\sim5$ Lyman-$\\alpha$\nEmitting (LAE) galaxies that were discovered in the Sloan Giant Arcs Survey\n(SGAS). We identify the two sources as SGAS J091541+382655, at $z=5.200$, and\nSGAS J134331+415455 at $z=4.994$. We measure their AB magnitudes at\n$(i,z)=(23.34\\pm0.09,23.29\\pm0.13$) mags and\n$(i,z)=(23.78\\pm0.18,24.24^{+0.18}_{-0.16}$) mags, and the rest-frame\nequivalent widths of the Lyman-$\\alpha$ emission at $25.3\\pm4.1$\\AA~and\n$135.6\\pm20.3$\\AA~for SGAS J091541+382655 and SGAS J134331+415455,\nrespectively. Each source is strongly lensed by a massive galaxy cluster in the\nforeground, and the magnifications due to gravitational lensing are recovered\nfrom strong lens modeling of the foreground lensing potentials. We use the\nmagnification to calculate the intrinsic, unlensed Lyman-$\\alpha$ and UV\ncontinuum luminosities for both sources, as well as the implied star formation\nrates (SFR). We find SGAS J091541+382655 and SGAS J134341+415455 to be galaxies\nwith (L$_{Ly-\\alpha}$, L$_{UV})\\leq(0.6$L$_{Ly-\\alpha}^{*}, 2$L$_{UV}^{*}$) and\n(L$_{Ly-\\alpha}$, L$_{UV})=(0.5$L$_{Ly-\\alpha}^{*}, 0.9$L$_{UV}^{*}$),\nrespectively. Comparison of the spectral energy distributions (SEDs) of both\nsources against stellar population models produces estimates of the mass in\nyoung stars in each galaxy: we report an upper limit of M$_{stars} \\leq\n7.9^{+3.7}_{-2.5} \\times 10^{7}$ M$_{\\sun} h_{0.7}^{-1}$ for SGAS\nJ091531+382655, and a range of viable masses for SGAS J134331+415455 of\n$2\\times10^{8}$ M$_{\\sun} h_{0.7}^{-1} <$ M$_{stars} < 6\\times10^{9}$ M$_{\\sun}\nh_{0.7}^{-1}$. \n\n"}
{"id": "1003.0876", "contents": "Title: The generalized second law of thermodynamics in Horava-Lifshitz\n  cosmology Abstract: We investigate the validity of the generalized second law of thermodynamics\nin a universe governed by Horava-Lifshitz gravity. Under the equilibrium\nassumption, that is in the late-time cosmological regime, we calculate\nseparately the entropy time-variation for the matter fluid and, using the\nmodified entropy relation, that of the apparent horizon itself. We find that\nunder detailed balance the generalized second law is generally valid for flat\nand closed geometry and it is conditionally valid for an open universe, while\nbeyond detailed balance it is only conditionally valid for all curvatures.\nFurthermore, we also follow the effective approach showing that it can lead to\nmisleading results. The non-complete validity of the generalized second law\ncould either provide a suggestion for its different application, or act as an\nadditional problematic feature of Horava-Lifshitz gravity. \n\n"}
{"id": "1003.3243", "contents": "Title: The GalMer database: Galaxy Mergers in the Virtual Observatory Abstract: We present the GalMer database, a library of galaxy merger simulations, made\navailable to users through tools compatible with the Virtual Observatory (VO)\nstandards adapted specially for this theoretical database. To investigate the\nphysics of galaxy formation through hierarchical merging, it is necessary to\nsimulate galaxy interactions varying a large number of parameters:\nmorphological types, mass ratios, orbital configurations, etc. On one side,\nthese simulations have to be run in a cosmological context, able to provide a\nlarge number of galaxy pairs, with boundary conditions given by the large-scale\nsimulations, on the other side the resolution has to be high enough at galaxy\nscales, to provide realistic physics. The GalMer database is a library of\nthousands simulations of galaxy mergers at moderate spatial resolution and it\nis a compromise between the diversity of initial conditions and the details of\nunderlying physics. We provide all coordinates and data of simulated particles\nin FITS binary tables. The main advantages of the database are VO access\ninterfaces and value-added services which allow users to compare the results of\nthe simulations directly to observations: stellar population modelling, dust\nextinction, spectra, images, visualisation using dedicated VO tools. The GalMer\nvalue-added services can be used as virtual telescope producing broadband\nimages, 1D spectra, 3D spectral datacubes, thus making our database oriented\ntowards the usage by observers. We present several examples of the GalMer\ndatabase scientific usage obtained from the analysis of simulations and\nmodelling their stellar population properties, including: (1) studies of the\nstar formation efficiency in interactions; (2) creation of old counter-rotating\ncomponents; (3) reshaping metallicity profiles in elliptical galaxies; (4)\norbital to internal angular momentum transfer; (5) reproducing observed colour\nbimodality of galaxies. \n\n"}
{"id": "1003.5600", "contents": "Title: The Evolution of Quasar CIV and SiIV Broad Absorption Lines Over\n  Multi-Year Time Scales Abstract: We investigate the variability of CIV 1549A broad absorption line (BAL)\ntroughs over rest-frame time scales of up to ~7 yr in 14 quasars at redshifts\nz>2.1. For 9 sources at sufficiently high redshift, we also compare CIV and\nSiIV 1400A absorption variation. We compare shorter- and longer-term\nvariability using spectra from up to four different epochs per source and find\ncomplex patterns of variation in the sample overall. The scatter in the change\nof absorption equivalent width (EW), Delta EW, increases with the time between\nobservations. BALs do not, in general, strengthen or weaken monotonically, and\nvariation observed over shorter (<months) time scales is not predictive of\nmulti-year variation. We find no evidence for asymmetry in the distribution of\nDelta EW that would indicate that BALs form and decay on different time scales,\nand we constrain the typical BAL lifetime to be >~30 yr. The BAL absorption for\none source, LBQS 0022+0150, has weakened and may now be classified as a\nmini-BAL. Another source, 1235+1453, shows evidence of variable, blue continuum\nemission that is relatively unabsorbed by the BAL outflow. CIV and SiIV BAL\nshape changes are related in at least some sources. Given their high\nvelocities, BAL outflows apparently traverse large spatial regions and may\ninteract with parsec-scale structures such as an obscuring torus. Assuming BAL\noutflows are launched from a rotating accretion disk, notable azimuthal\nsymmetry is required in the outflow to explain the relatively small changes\nobserved in velocity structure over times up to 7 yr. \n\n"}
{"id": "1004.0227", "contents": "Title: Cosmology in One Dimension: Fractal Geometry, Power Spectra and\n  Correlation Abstract: Concentrations of matter, such as galaxies and galactic clusters, originated\nas very small density fluctuations in the early universe. The existence of\ngalaxy clusters and super-clusters suggests that a natural scale for the matter\ndistribution may not exist. A point of controversy is whether the distribution\nis fractal and, if so, over what range of scales. One-dimensional models\ndemonstrate that the important dynamics for cluster formation occur in the\nposition-velocity plane. Here the development of scaling behavior and\nmultifractal geometry is investigated for a family of one-dimensional models\nfor three different, scale-free, initial conditions. The methodology employed\nincludes: 1) The derivation of explicit solutions for the gravitational\npotential and field for a one-dimensional system with periodic boundary\nconditions (Ewald sums for one dimension); 2) The development of a procedure\nfor obtaining scale-free initial conditions for the growing mode in phase space\nfor an arbitrary power-law index; 3) The evaluation of power spectra,\ncorrelation functions, and generalized fractal dimensions at different stages\nof the system evolution. It is shown that a simple analytic representation of\nthe power spectra captures the main features of the evolution, including the\ncorrect time dependence of the crossover from the linear to nonlinear regime\nand the transition from regular to fractal geometry. A possible physical\nmechanism for understanding the self-similar evolution is introduced. It is\nshown that hierarchical cluster formation depends both on the model and the\ninitial power spectrum. Under special circumstances a simple relation between\nthe power spectrum, correlation function, and correlation dimension in the\nhighly nonlinear regime is confirmed. \n\n"}
{"id": "1004.3294", "contents": "Title: Cosmological Tests of Gravity Abstract: Modifications of general relativity provide an alternative explanation to\ndark energy for the observed acceleration of the universe. We review recent\ndevelopments in modified gravity theories, focusing on higher dimensional\napproaches and chameleon/f(R) theories. We classify these models in terms of\nthe screening mechanisms that enable such theories to approach general\nrelativity on small scales (and thus satisfy solar system constraints). We\ndescribe general features of the modified Friedman equation in such theories.\n  The second half of this review describes experimental tests of gravity in\nlight of the new theoretical approaches. We summarize the high precision tests\nof gravity on laboratory and solar system scales. We describe in some detail\ntests on astrophysical scales ranging from ~kpc (galaxy scales) to ~Gpc\n(large-scale structure). These tests rely on the growth and inter-relationship\nof perturbations in the metric potentials, density and velocity fields which\ncan be measured using gravitational lensing, galaxy cluster abundances, galaxy\nclustering and the Integrated Sachs-Wolfe effect. A robust way to interpret\nobservations is by constraining effective parameters, such as the ratio of the\ntwo metric potentials. Currently tests of gravity on astrophysical scales are\nin the early stages --- we summarize these tests and discuss the interesting\nprospects for new tests in the coming decade. \n\n"}
{"id": "1004.3377", "contents": "Title: On the conversion of mass eigenstates Abstract: In this paper we consider a stable particle with flavor mixing. We\ndemonstrate that incoherent conversion of heavy mass eigenstates into light\nones and vice versa can occur, as a result of elastic scattering. This effect\nis nontrivial for non-relativistic particles, for which the standard flavor\noscillation ceases rapidly due to incoherence. We also prove that if a heavy\nstate is bound in a gravitational potential and a light state is unbound, the\nmass-state conversion can lead to gradual \"evaporation\" of the mixed particle\nfrom the potential. A number of implications, ranging from the cosmic neutrino\nbackground distortions to scenarios of cold dark matter evaporation from halos,\nare addressed. \n\n"}
{"id": "1005.0021", "contents": "Title: The Jet-Driven Outflow in the Radio Galaxy SDSS J1517+3353: Implications\n  for Double-Peaked Narrow-Line AGN Abstract: We report on the study of an intriguing active galaxy that was selected as a\npotential multiple supermassive black hole merger in the early-type host SDSS\nJ151709.20+335324.7 (z=0.135). Ground-based SDSS imaging reveals two blue\nstructures on either side of the photometric center of the host galaxy,\nseparated from each other by about 5.7 kpc. The analysis of spatially resolved\nemission line profiles from a Keck/HIRES spectrum reveal three distinct\nkinematic subcomponents, one at rest and the other two moving at -350 km/s and\n500 km/s with respect to the systemic velocity of the host galaxy. A comparison\nof imaging and spectral data confirm a strong association between the kinematic\ncomponents and the spatial knots, which implies a highly disturbed and complex\nactive region in this object. Subsequent VLA radio imaging reveals a clear jet\naligned with the emission line gas, confirming that a jet-gas interaction is\nthe best explanation for emission line region. We use the broadband radio\nmeasurements to examine the impact of the jet on the ISM of the host galaxy,\nand find that the energy in the radio lobes can heat a significant fraction of\nthe gas to the virial temperature. Finally, we discuss tests that may help\nfuture surveys distinguish between jet-driven kinematics and true black-hole\nbinaries. SDSS J151709.20+335324.7 is a remarkable laboratory for AGN feedback\nand warrants deeper follow-up study. In the Appendix, we present\nhigh-resolution radio imaging of a second AGN with double-peaked [O III] lines,\nSDSS J112939.78+605742.6, which shows a sub-arcsecond radio jet. If the\ndouble-peaked nature of the narrow lines in radio-loud AGN are generally due to\nradio jet interactions, we suggest that extended radio structure should be\nexpected in most of such systems. \n\n"}
{"id": "1005.0479", "contents": "Title: Updated constraints on the cosmic string tension Abstract: We re-examine the constraints on the cosmic string tension from Cosmic\nMicrowave Background (CMB) and matter power spectra, and also from limits on a\nstochastic background of gravitational waves provided by pulsar timing. We\ndiscuss the different approaches to modeling string evolution and radiation. In\nparticular, we show that the unconnected segment model can describe CMB spectra\nexpected from thin string (Nambu) and field theory (Abelian-Higgs) simulations\nusing the computed values for the correlation length, rms string velocity and\nsmall-scale structure relevant to each variety of simulation. Applying the\ncomputed spectra in a fit to CMB and SDSS data we find that $G\\mu/c^2<\n2.6\\times 10^{-7}$ ($2 \\sigma$) if the Nambu simulations are correct and $G\\mu\n/c^2< 6.4\\times 10^{-7}$ in the Abelian-Higgs case. The degeneracy between\n$G\\mu/c^2$ and the power spectrum slope $n_{\\rm S}$ is substantially reduced\nfrom previous work. Inclusion of constraints on the baryon density from Big\nBang Nucleosynthesis (BBN) imply that $n_{\\rm S} <1$ at around the $4\\sigma$\nlevel for both the Nambu and Abelian-Higgs cases. As a by-product of our\nresults, we find there is \"moderate-to-strong\" Bayesian evidence that the\nHarrison-Zel'dovich spectrum is excluded (odds ratio of $\\sim 100:1$) by the\ncombination of CMB, SDSS and BBN when compared to the standard 6 parameter fit.\nUsing the contribution to the gravitational wave background from radiation era\nloops as a conservative lower bound on the signal for specific values of\n$G\\mu/c^2$ and loop production size, $\\alpha$, we find that $G\\mu /c^2< 7\\times\n10^{-7} $ for $\\alpha c^2/(\\Gamma G\\mu)\\ll1$ and $G\\mu/c^2 < 5\\times\n10^{-11}/\\alpha$ for $\\alpha c^2/(\\Gamma G\\mu) \\gg1$. \n\n"}
{"id": "1005.1067", "contents": "Title: Dual Jets from Binary Black Holes Abstract: Supermassive black holes are found at the centers of most galaxies and their\ninspiral is a natural outcome when galaxies merge. The inspiral of these\nsystems is of utmost astrophysical importance as prodigious producers of\ngravitational waves and in their possible role in energetic electromagnetic\nevents. We study such binary black hole coalescence under the influence of an\nexternal magnetic field produced by the expected circumbinary disk surrounding\nthem. Solving the Einstein equations to describe the spacetime and using the\nforce-free approach for the electromagnetic fields and the tenuous plasma, we\npresent numerical evidence for possible jets driven by these systems. Extending\nthe process described by Blandford and Znajek for a single spinning black hole,\nthe picture that emerges suggests the electromagnetic field extracts energy\nfrom the orbiting black holes, which ultimately merge and settle into the\nstandard Blandford-Znajek scenario. Emissions along dual and single jets would\nbe expected that could be observable to large distances. \n\n"}
{"id": "1005.1178", "contents": "Title: The Double-Peaked 2008 Outburst of the Accreting Milli-Second X-ray\n  Pulsar, IGR J00291+5934 Abstract: In August 2008, the accreting milli-second X-ray pulsar (AMXP), IGR\nJ00291+5934, underwent an outburst lasting ~ 100 days, the first since its\ndiscovery in 2004. We present data from the double-peaked outburst from Faulkes\nTelescope North, the INT, the Keck Telescope, PAIRITEL, the Westerbork\nSynthesis Radio Telescope and the Swift, XMM-Newton and RXTE X-ray missions. We\nstudy the outburst's evolution at various wavelengths. We study the light curve\nmorphology, presenting the first radio-X-ray Spectral Energy Distributions\n(SEDs) for this source and the most detailed UV-IR SEDs for any outbursting\nAMXP. We show simple models that attempt to identify the emission mechanisms\nresponsible. We analyse short-timescale optical variability, and compare a\nmedium resolution optical spectrum with those from 2004. The outburst\nmorphology is unusual for an AMXP, comprising two peaks, the second containing\na 'plateau' of ~ 10 days at maximum brightness within 30 days of the initial\nactivity. This has implications on duty cycles of short-period X-ray\ntransients. The X-ray spectrum can be fitted by a single, hard power-law. We\ndetect optical variability of ~ 0.05 magnitudes, on timescales of minutes, but\nfind no periodic modulation. In the optical, the SEDs contain a blue component,\nindicative of an irradiated disc, and a transient near-infrared (NIR) excess.\nThis excess is consistent with a simple model of an optically thick synchrotron\njet (as seen in other outbursting AMXPs). The optical spectrum shows a\ndouble-peaked H alpha profile, a diagnostic of an accretion disc, but we do not\nclearly see other lines (e.g. He I, II) reported in 2004. Optical/IR\nobservations of AMXPs are excellent for studying the evolution of both the\nouter accretion disc and the inner jet, and may eventually provide us with\ntight constraints to model disc-jet coupling in accreting neutron stars. \n\n"}
{"id": "1005.2409", "contents": "Title: The Herschel-ATLAS: Extragalactic Number Counts from 250 to 500 Microns Abstract: Aims. The Herschel-ATLAS survey (H-ATLAS) will be the largest area survey to\nbe undertaken by the Herschel Space Observatory. It will cover 550 sq. deg. of\nextragalactic sky at wavelengths of 100, 160, 250, 350 and 500 microns when\ncompleted, reaching flux limits (5 sigma) from 32 to 145mJy. We here present\ngalaxy number counts obtained for SPIRE observations of the first ~14 sq. deg.\nobserved at 250, 350 and 500 microns. Methods. Number counts are a fundamental\ntool in constraining models of galaxy evolution. We use source catalogs\nextracted from the H-ATLAS maps as the basis for such an analysis. Correction\nfactors for completeness and flux boosting are derived by applying our\nextraction method to model catalogs and then applied to the raw observational\ncounts. Results. We find a steep rise in the number counts at flux levels of\n100-200mJy in all three SPIRE bands, consistent with results from BLAST. The\ncounts are compared to a range of galaxy evolution models. None of the current\nmodels is an ideal fit to the data but all ascribe the steep rise to a\npopulation of luminous, rapidly evolving dusty galaxies at moderate to high\nredshift. \n\n"}
{"id": "1005.3492", "contents": "Title: Constraints on primordial non-Gaussianity from Galaxy-CMB lensing\n  cross-correlation Abstract: Recent studies have shown that the primordial non-Gaussianity affects\nclustering of dark matter halos through a scale-dependent bias and various\nconstraints on the non-Gaussianity through this scale-dependent bias have been\nplaced. Here we introduce the cross-correlation between the CMB lensing\npotential and the galaxy angular distribution to effectively extract\ninformation about the bias from the galaxy distribution. Then, we estimate the\nerror of non-linear parameter, f_NL, for the on-going CMB experiments and\ngalaxy surveys, such as Planck and Hyper Suprime-Cam (HSC). We found that for\nthe constraint on f_NL with Planck and HSC, the wide field galaxy survey is\npreferable to the deep one, and the expected error on f_NL can be as small as:\n\\Delta f_NL ~ 20 for b_0 = 2 and \\Delta f_NL ~ 10 for b_0 = 4, where b_0 is the\nlinear bias parameter. It is also found that future wide field galaxy survey\ncould achieve \\Delta f_NL ~ 5 with CMB prior from Planck if one could observe\nhighly biased objects at higher redshift (z ~ 2). \n\n"}
{"id": "1005.4056", "contents": "Title: Testing Two-Field Inflation Abstract: We derive semi-analytic formulae for the power spectra of two-field inflation\nassuming an arbitrary potential and non-canonical kinetic terms, and we use\nthem both to build phenomenological intuition and to constrain classes of\ntwo-field models using WMAP data. Using covariant formalism, we first develop a\nframework for understanding the background field kinematics and introduce a\n\"slow-turn\" approximation. Next, we find covariant expressions for the\nevolution of the adiabatic/curvature and entropy/isocurvature modes, and we\ndiscuss how the mode evolution can be inferred directly from the background\nkinematics and the geometry of the field manifold. From these expressions, we\nderive semi-analytic formulae for the curvature, isocurvature, and cross\nspectra, and the spectral observables, all to second-order in the slow-roll and\nslow-turn approximations. In tandem, we show how our covariant formalism\nprovides useful intuition into how the characteristics of the inflationary\nLagrangian translate into distinct features in the power spectra. In\nparticular, we find that key features of the power spectra can be directly read\noff of the nature of the roll path, the curve the field vector rolls along with\nrespect to the field manifold. For example, models whose roll path makes a\nsharp turn 60 e-folds before inflation ends tend to be ruled out because they\nproduce strong departures from scale invariance. Finally, we apply our\nformalism to confront four classes of two-field models with WMAP data,\nincluding doubly quadratic and quartic potentials and non-standard kinetic\nterms, showing how whether a model is ruled out depends not only on certain\nfeatures of the inflationary Lagrangian, but also on the initial conditions.\nUltimately, models must possess the right balance of kinematical and dynamical\nbehaviors, which we capture in a set of functions that can be reconstructed\nfrom spectral observables. \n\n"}
{"id": "1006.0670", "contents": "Title: Astronomy 3.0 Style Abstract: Over the next decade we will witness the development of a new infrastructure\nin support of data-intensive scientific research, which includes Astronomy.\nThis new networked environment will offer both challenges and opportunities to\nour community and has the potential to transform the way data are described,\ncurated and preserved. Based on the lessons learned during the development and\nmanagement of the ADS, a case is made for adopting the emerging technologies\nand practices of the Semantic Web to support the way Astronomy research will be\nconducted. Examples of how small, incremental steps can, in the aggregate, make\na significant difference in the provision and repurposing of astronomical data\nare provided. \n\n"}
{"id": "1006.3359", "contents": "Title: Modeling dielectric half-wave plates for cosmic microwave background\n  polarimetry using a Mueller matrix formalism Abstract: We derive an analytic formula using the Mueller matrix formalism that\nparameterizes the nonidealities of a half-wave plate (HWP) made from dielectric\nantireflection-coated birefringent slabs. This model accounts for\nfrequency-dependent effects at normal incidence, including effects driven by\nthe reflections at dielectric boundaries. The model also may be used to guide\nthe characterization of an instrument that uses a HWP. We discuss the coupling\nof a HWP to different source spectra, and the potential impact of that effect\non foreground removal for the SPIDER cosmic microwave background experiment. We\nalso describe a way to use this model in a mapmaking algorithm that fully\ncorrects for HWP nonidealities. \n\n"}
{"id": "1006.4198", "contents": "Title: Fitting cosmological data to the function $q(z)$ from GR Theory:\n  Modified Chaplygin Gas Abstract: In the Friedmann cosmology the deceleration of the expansion $q$ plays a\nfundamental role. We derive the deceleration as a function of redshift $q(z)$\nin two scenarios: $\\Lambda$CDM model and modified Chaplygin gas ($MCG$) model.\nThe function for the $MCG$ model is then fitted to the cosmological data in\norder to obtain the cosmological parameters that minimize $\\chi^2$. We use the\nFisher matrix to construct the covariance matrix of our parameters and\nreconstruct the q(z) function. We use Supernovae Ia, WMAP5 and BAO measurements\nto obtain the observational constraints. We determined the present acceleration\nas $q_0=-0.60 \\pm 0.12$ for the $MCG$ model using the Constitution dataset of\nSNeIa and BAO, and $q_0=-0.63 \\pm 0.17$ for the Union dataset and BAO. The\ntransition redshift from deceleration to acceleration was found to be around\n$0.6$ for both datasets. We have also determined the dark energy parameter for\nthe $MCG$ model: $\\Omega_{X0}=0.834 \\pm 0.028$ for the Constitution dataset and\n$\\Omega_{X0}=0.854 \\pm 0.036$ using the Union dataset. \n\n"}
{"id": "1007.0185", "contents": "Title: Model Independent Signatures of New Physics in the Inflationary Power\n  Spectrum Abstract: We compute the universal generic corrections to the inflationary power\nspectrum due to unknown high-energy physics. We arrive at this result via a\ncareful integrating out of massive fields in the \"in-in\" formalism yielding a\nconsistent and predictive low-energy effective description in time-dependent\nbackgrounds. We find that the power spectrum is universally modified at order\nH/M, where H is the scale of inflation. This is qualitatively different from\nthe universal corrections in time-independent backgrounds, and it suggests that\nsuch effects may be present in upcoming cosmological observations. \n\n"}
{"id": "1007.0443", "contents": "Title: Generalization of the Fierz-Pauli Action Abstract: We consider the Lagrangian of gravity covariantly amended by the mass and\npolynomial interaction terms with arbitrary coefficients, and reinvestigate the\nconsistency of such a theory in the decoupling limit, up to the fifth order in\nthe nonlinearities. We calculate explicitly the self-interactions of the\nhelicity-0 mode, as well as the nonlinear mixing between the helicity-0 and -2\nmodes. We show that ghost-like pathologies in these interactions disappear for\nspecial choices of the polynomial interactions, and argue that this result\nremains true to all orders in the decoupling limit. Moreover, we show that the\nlinear, and some of the nonlinear mixing terms between the helicity-0 and -2\nmodes can be absorbed by a local change of variables, which then naturally\ngenerates the cubic, quartic, and quintic Galileon interactions, introduced in\na different context. We also point out that the mixing between the helicity-0\nand 2 modes can be at most quartic in the decoupling limit. Finally, we discuss\nthe implications of our findings for the consistency of the effective field\ntheory away from the decoupling limit, and for the Boulware-Deser problem. \n\n"}
{"id": "1007.1145", "contents": "Title: Predicting dust extinction from the stellar mass of a galaxy Abstract: We investigate how the typical dust extinction of H-alpha luminosity from a\nstar-forming galaxy depends upon star formation rate (SFR), metallicity and\nstellar mass independently, using a sample of ~90,000 galaxies from Data\nRelease 7 of the Sloan Digital Sky Survey (SDSS). We measure extinctions\ndirectly from the Balmer decrement of each source, and while higher values of\nextinction are associated with an increase in any of the three parameters, we\ndemonstrate that the fundamental property that governs extinction is stellar\nmass. After this mass-dependent relationship is removed, there is very little\nsystematic dependence of the residual extinctions with either SFR or\nmetallicity, and no significant improvement is obtained from a more general\nparameterisation. In contrast to this, if either a SFR-dependent or\nmetallicity-dependent extinction relationship is applied, the residual\nextinctions show significant trends that correlate with the other parameters.\nUsing the SDSS data, we present a relationship to predict the median dust\nextinction of a sample of galaxies from its stellar mass, which has a scatter\nof ~0.3 mag. The relationship was calibrated for H-alpha emission, but can be\nmore generally applied to radiation emitted at other wavelengths. These results\nhave important applications for studies of high-redshift galaxies, where\nindividual extinction measurements are hard to obtain but stellar mass\nestimates can be relatively easily estimated from long-wavelength data. \n\n"}
{"id": "1007.1179", "contents": "Title: Optimal Compression of Floating-point Astronomical Images Without\n  Significant Loss of Information Abstract: We describe a compression method for floating-point astronomical images that\ngives compression ratios of 6 -- 10 while still preserving the scientifically\nimportant information in the image. The pixel values are first preprocessed by\nquantizing them into scaled integer intensity levels, which removes some of the\nuncompressible noise in the image. The integers are then losslessly compressed\nusing the fast and efficient Rice algorithm and stored in a portable FITS\nformat file. Quantizing an image more coarsely gives greater image compression,\nbut it also increases the noise and degrades the precision of the photometric\nand astrometric measurements in the quantized image. Dithering the pixel values\nduring the quantization process can greatly improve the precision of\nmeasurements in the images. This is especially important if the analysis\nalgorithm relies on the mode or the median which would be similarly quantized\nif the pixel values are not dithered. We perform a series of experiments on\nboth synthetic and real astronomical CCD images to quantitatively demonstrate\nthat the magnitudes and positions of stars in the quantized images can be\nmeasured with the predicted amount of precision. In order to encourage wider\nuse of these image compression methods, we have made available a pair of\ngeneral-purpose image compression programs, called fpack and funpack, which can\nbe used to compress any FITS format image. \n\n"}
{"id": "1007.1681", "contents": "Title: Galaxy Modeling with Compound Elliptical Shapelets Abstract: Gauss-Hermite and Gauss-Laguerre (\"shapelet\") decompositions of images have\nbecome important tools in galaxy modeling, particularly for the purpose of\nextracting ellipticity and morphological information from astronomical data.\nHowever, the standard shapelet basis functions cannot compactly represent\ngalaxies with high ellipticity or large Sersic index, and the resulting\nunderfitting bias has been shown to present a serious challenge for\nweak-lensing methods based on shapelets. We present here a new convolution\nrelation and a compound \"multi-scale\" shapelet basis to address these problems,\nand provide a proof-of-concept demonstration using a small sample of nearby\ngalaxies. \n\n"}
{"id": "1007.2700", "contents": "Title: Cosmology of a covariant Galileon field Abstract: We study the cosmology of a covariant scalar field respecting a Galilean\nsymmetry in flat space-time. We show the existence of a tracker solution that\nfinally approaches a de Sitter fixed point responsible for cosmic acceleration\ntoday. The viable region of model parameters is clarified by deriving\nconditions under which ghosts and Laplacian instabilities of scalar and tensor\nperturbations are absent. The field equation of state exhibits a peculiar\nphantom-like behavior along the tracker, which allows a possibility to\nobservationally distinguish the Galileon gravity from the Lambda-CDM model. \n\n"}
{"id": "1007.2874", "contents": "Title: Absolute polarization angle calibration using polarized diffuse Galactic\n  emission observed by BICEP Abstract: We present a method of cross-calibrating the polarization angle of a\npolarimeter using BICEP Galactic observations. \\bicep\\ was a ground based\nexperiment using an array of 49 pairs of polarization sensitive bolometers\nobserving from the geographic South Pole at 100 and 150 GHz. The BICEP\npolarimeter is calibrated to +/-0.01 in cross-polarization and less than +/-0.7\ndegrees in absolute polarization orientation. BICEP observed the temperature\nand polarization of the Galactic plane (R.A= 100 degrees ~ 270 degrees and Dec.\n= -67 degrees ~ -48 degrees). We show that the statistical error in the 100 GHz\nBICEP Galaxy map can constrain the polarization angle offset of WMAP Wband to\n0.6 degrees +\\- 1.4 degrees. The expected 1 sigma errors on the polarization\nangle cross-calibration for Planck or EPIC are 1.3 degrees and 0.3 degrees at\n100 and 150 GHz, respectively. We also discuss the expected improvement of the\nBICEP Galactic field observations with forthcoming BICEP2 and Keck\nobservations. \n\n"}
{"id": "1007.3816", "contents": "Title: LoCuSS: Calibrating Mass-Observable Scaling Relations for Cluster\n  Cosmology with Subaru Weak Lensing Observations Abstract: We present a joint weak-lensing/X-ray study of galaxy cluster mass-observable\nscaling relations, motivated by the critical importance of accurate calibration\nof mass proxies for future X-ray missions, including eROSITA. We use a sample\nof 12 clusters at z\\simeq0.2 that we have observed with Subaru and XMM-Newton\nto construct relationships between the weak-lensing mass (M), and three X-ray\nobservables: gas temperature (T), gas mass (Mgas), and quasi-integrated gas\npressure (Yx) at overdensities of \\Delta=2500, 1000, and 500 with respect to\nthe critical density. We find that Mgas at \\Delta\\le1000 appears to be the most\npromising mass proxy of the three, because it has the lowest intrinsic scatter\nin mass at fixed observable: \\sigma_lnM\\simeq0.1, independent of cluster\ndynamical state. The scatter in mass at fixed T and Yx is a factor of \\sim2-3\nlarger than at fixed Mgas, which are indicative of the structural segregation\nthat we find in the M-T and M-Yx relationships. Undisturbed clusters are found\nto be \\sim40% and \\sim20% more massive than disturbed clusters at fixed T and\nYx respectively at \\sim2\\sigma significance. In particular, A1914 - a\nwell-known merging cluster - significantly increases the scatter and lowers the\nthe normalization of the relation for disturbed clusters. We also investigated\nthe covariance between intrinsic scatter in M-Mgas and M-T relations, finding\nthat they are positively correlated. This contradicts the adaptive mesh\nrefinement simulations that motivated the idea that Yx may be a low scatter\nmass proxy, and agrees with more recent smoothed particle hydrodynamic\nsimulations based on the Millennium Simulation. We also propose a method to\nidentify a robust mass proxy based on principal component analysis. The\nstatistical precision of our results are limited by the small sample size and\nthe presence of the extreme merging cluster in our sample. \n\n"}
{"id": "1007.4492", "contents": "Title: The Sloan Great Wall. Rich clusters Abstract: We present the results of the study of the substructure and galaxy content of\nten rich clusters of galaxies in three different superclusters of the Sloan\nGreat Wall. We determine the substructure in clusters using the 'Mclust'\npackage from the 'R' statistical environment and analyse their galaxy content.\nWe analyse the distribution of the peculiar velocities of galaxies in clusters\nand calculate the peculiar velocity of the first ranked galaxy. We show that\nclusters in our sample have more than one component; in some clusters different\ncomponents also have different galaxy content. We find that in some clusters\nwith substructure the peculiar velocities of the first ranked galaxies are\nlarge. All clusters in our sample host luminous red galaxies. They can be found\nboth in the central areas of clusters as well as in the outskirts, some of them\nhave large peculiar velocities. About 1/3 of red galaxies in clusters are\nspirals. The scatter of colours of red ellipticals is in most clusters larger\nthan that of red spirals. The presence of substructure in rich clusters, signs\nof possible mergers and infall, as well as the large peculiar velocities of the\nfirst ranked galaxies suggest that the clusters in our sample are not yet\nvirialized. We present merger trees of dark matter haloes in an N-body\nsimulation to demonstrate the formation of present-day dark matter haloes via\nmultiple mergers during their evolution. In simulated dark matter haloes we\nfind a substructure similar to that in observed clusters. \n\n"}
{"id": "1007.4750", "contents": "Title: Pulse-Shape Discrimination of CaF2(Eu) Abstract: We measured the decay time of the scintillation pulses produced by electron\nand nuclear recoils in CaF2(Eu) by a new fitting method. In the recoil energy\nregion 5-30 keVee, we found differences of the decay time between electron and\nnuclear recoil events. In the recoil energy region above 20 keVee, we found\nthat the decay time is independent of the recoil energy. \n\n"}
{"id": "1007.5351", "contents": "Title: uvby-$\\beta$ photometry of solar twins: the solar colors, model\n  atmospheres, and the Teff and metallicity scales Abstract: Solar colors have been determined on the uvby-$\\beta$ photometric system to\ntest absolute solar fluxes, to examine colors predicted by model atmospheres as\na function of stellar parameters (Teff, log g, [Fe/H]), and to probe\nzero-points of Teff and metallicity scales.\n  New uvby-$\\beta$ photometry is presented for 73 solar-twin candidates. Most\nstars of our sample have also been observed spectroscopically to obtain\naccurate stellar parameters. Using the stars that most closely resemble the\nSun, and complementing our data with photometry available in the literature,\nthe solar colors on the uvby-$\\beta$ system have been inferred. Our solar\ncolors are compared with synthetic solar colors computed from absolute solar\nspectra and from the latest Kurucz (ATLAS9) and MARCS model atmospheres. The\nzero-points of different Teff and metallicity scales are verified and\ncorrections are proposed.\n  The Teff calibration of Alonso and collaborators has the poorest performance\n(~140 K off), while the relation of Casagrande et al. (2010) is the most\naccurate (within 10 K). We confirm that the Ramirez & Melendez (2005) uvby\nmetallicity calibration, recommended by \\'Arnad\\'ottir et al. (2010) to obtain\n[Fe/H] in F, G, and K dwarfs, needs a small (~10%) zero-point correction to\nplace the stars and the Sun on the same metallicity scale. Finally, we confirm\nthat the c_1 index in solar analogs has a strong metallicity sensitivity. \n\n"}
{"id": "1008.0641", "contents": "Title: An Alternative Approach To Measuring Reverberation Lags in Active\n  Galactic Nuclei Abstract: Motivated by recent progress in the statistical modeling of quasar\nvariability, we develop a new approach to measuring emission-line reverberation\nlags to estimate the size of broad-line regions (BLRs) in active galactic\nnuclei. Assuming that all emission-line light curves are scaled, smoothed, and\ndisplaced versions of the continuum, this alternative approach fits the light\ncurves directly using a damped random walk model and aligns them to recover the\ntime lag and its statistical confidence limits. We introduce the mathematical\nformalism of this approach and demonstrate its ability to cope with some of the\nproblems for traditional methods, such as irregular sampling, correlated\nerrors, and seasonal gaps. We redetermine the lags for 87 emission lines in 31\nquasars and reassess the BLR size--luminosity relationship using 60 H-beta\nlags. We confirm the general results from the traditional cross-correlation\nmethods, with a few exceptions. Our method, however, also supports a broad\nrange of extensions. In particular, it can simultaneously fit multiple lines\nand continuum light curves which improves the lag estimate for the lines and\nprovides estimates of the error correlations between them. Determining these\ncorrelations is of particular importance for interpreting emission-line\nvelocity--delay maps. We can also include parameters for luminosity-dependent\nlags or line responses. We use this to detect the scaling of the BLR size with\ncontinuum luminosity in NGC 5548. \n\n"}
{"id": "1008.0826", "contents": "Title: The Emerging Scholarly Brain Abstract: It is now a commonplace observation that human society is becoming a coherent\nsuper-organism, and that the information infrastructure forms its emerging\nbrain. Perhaps, as the underlying technologies are likely to become billions of\ntimes more powerful than those we have today, we could say that we are now\nbuilding the lizard brain for the future organism. \n\n"}
{"id": "1008.1880", "contents": "Title: The Chameleonic Contribution to the SZ Radial Profile of the Coma\n  Cluster Abstract: We constrain the chameleonic Sunyaev--Zel'dovich (CSZ) effect in the Coma\ncluster from measurements of the Coma radial profile presented in the WMAP\n7-year results. The CSZ effect arises from the interaction of a scalar (or\npseudoscalar) particle with the cosmic microwave background in the magnetic\nfield of galaxy clusters. We combine this radial profile data with SZ\nmeasurements towards the centre of the Coma cluster in different frequency\nbands, to find Delta T_{SZ,RJ}(0)=-400+/-40 microKelvin and Delta T_{CSZ}^{204\nGHz}(0)=-20+/-15 microKelvin (68% CL) for the thermal SZ and CSZ effects in the\ncluster respectively. The central value leads to an estimate of the photon to\nscalar (or pseudoscalar) coupling strength of g = (5.2 - 23.8) x 10^{-10}\nGeV^{-1}, while the 95% confidence bound is estimated to be g < (8.7 - 39.4) x\n10^{-10} GeV^{-1}. \n\n"}
{"id": "1008.2102", "contents": "Title: Cross-calibrating X-ray detectors with clusters of galaxies: an IACHEC\n  study Abstract: We used a sample of 11 nearby relaxed clusters of galaxies observed with the\nX-ray instruments XMM-Newton (EPIC) pn and MOS, Chandra ACIS-S and ACIS-I and\nBeppoSAX MECS to examine the cross-calibration of the energy dependence and\nnormalisation of the effective area of these instruments as of December 2009.\nWe also examined the Fe XXV/XXVI line ratio temperature measurement method for\nthe pn and MOS. We performed X-ray spectral analysis on the XMM-Newton and\nChandra data for a sample of 11 clusters. We obtained the information for\nBeppoSAX from DeGrandi & Molendi (2002). We compared the spectroscopic results\nobtained with different instruments for the same clusters in order to examine\npossible systematic calibration effects between the instruments. We did not\ndetect any significant systematic differences between the temperatures derived\nin the 2-7 keV band using the different instruments. Also, the EPIC\ntemperatures derived from the bremsstrahlung continuum agreed with those\nobtained from the Fe XXV/XXVI emission line ratio, implying that the energy\ndependence of the hard band effective area of the above instruments is\naccurately calibrated. On the other hand, the hard band EPIC/ACIS fluxes\ndisagreed by 5-10% (i.e. at 6-25 sigma level) which indicates a similar level\nof uncertainty in the normalisations of the effective areas of these\ninstruments in the 2--7 keV band. In the soft energy band (0.5-2.0 keV) there\nare greater cross-calibration differences between EPIC and ACIS. Due to the\nhigh statistical weight of the soft band data, the 0.5-7.0 keV band temperature\nmeasurements of clusters of galaxies with EPIC or ACIS are uncertain by ~10-15%\non average. \n\n"}
{"id": "1008.2205", "contents": "Title: Viewpoints: A high-performance high-dimensional exploratory data\n  analysis tool Abstract: Scientific data sets continue to increase in both size and complexity. In the\npast, dedicated graphics systems at supercomputing centers were required to\nvisualize large data sets, but as the price of commodity graphics hardware has\ndropped and its capability has increased, it is now possible, in principle, to\nview large complex data sets on a single workstation. To do this in practice,\nan investigator will need software that is written to take advantage of the\nrelevant graphics hardware. The Viewpoints visualization package described\nherein is an example of such software. Viewpoints is an interactive tool for\nexploratory visual analysis of large, high-dimensional (multivariate) data. It\nleverages the capabilities of modern graphics boards (GPUs) to run on a single\nworkstation or laptop. Viewpoints is minimalist: it attempts to do a small set\nof useful things very well (or at least very quickly) in comparison with\nsimilar packages today. Its basic feature set includes linked scatter plots\nwith brushing, dynamic histograms, normalization and outlier detection/removal.\nViewpoints was originally designed for astrophysicists, but it has since been\nused in a variety of fields that range from astronomy, quantum chemistry, fluid\ndynamics, machine learning, bioinformatics, and finance to information\ntechnology server log mining. In this article, we describe the Viewpoints\npackage and show examples of its usage. \n\n"}
{"id": "1008.2852", "contents": "Title: Evolution of sub-horizon cold dark matter perturbations Abstract: We investigate the evolution of sub-horizon cold dark matter perturbation in\nthe dark energy dominated era of the Universe. By generalising the Meszaros\nequation to be valid for an arbitrary equation of state parameter, we derive\nthe $w$-Meszaros equation. Its solutions determine the evolution of the cold\ndark matter perturbation by neglecting dark energy perturbations. Our\nanalytical results provide a qualitative understanding of this evolution. \n\n"}
{"id": "1008.3088", "contents": "Title: Mass reconstruction by gravitational shear and flexion Abstract: Galaxy clusters are considered as excellent probes for cosmology. For that\npurpose, their mass needs to be measured and their structural properties needs\nto be understood. We propose a method for galaxy cluster mass reconstruction\nwhich combines information from strong lensing, weak lensing shear and flexion.\nWe extend the weak lensing analysis to the inner parts of the cluster and, in\nparticular, improve the resolution of substructure. We use simulations to show\nthat the method recovers the mass density profiles of the cluster. We find that\nthe weak lensing flexion is sensitive to substructure. After combining the\nflexion data into the joint weak and strong lensing analysis, we can resolve\nthe cluster properties with substructures. \n\n"}
{"id": "1008.4459", "contents": "Title: Simulations of galaxy formation with radiative transfer: Hydrogen\n  reionization and radiative feedback Abstract: We carry out hydrodynamical simulations of galaxy formation that\nsimultaneously follow radiative transfer of hydrogen-ionizing photons, based on\nthe optically-thin variable Eddington tensor approximation as implemented in\nthe {\\small GADGET} code. We consider only star-forming galaxies as sources and\nexamine to what extent they can yield a reasonable reionization history and\nthermal state of the intergalactic medium at redshifts around $z\\sim 3$. This\nserves as an important benchmark for our self-consistent methodology to\nsimulate galaxy formation and reionization, and for future improvements through\naccounting of other sources and other wavelength ranges. We find that star\nformation alone is sufficient for reionizing the Universe by redshift $z\\sim6$.\nFor a suitable choice of the escape fraction and the heating efficiency, our\nmodels are approximately able to account at the same time for the one-point\nfunction and the power spectrum of the Lyman-$\\alpha$ forest. The radiation\nfield has an important impact on the star formation rate density in our\nsimulations and significantly lowers the gaseous and stellar fractions in\nlow-mass dark matter halos. Our results thus directly demonstrate the\nimportance of radiative feedback for galaxy formation. The spatial and temporal\nimportance of this effect can be studied accurately with the modelling\ntechnique explored here, allowing more faithful simulations of galaxy\nformation. \n\n"}
{"id": "1008.5164", "contents": "Title: Seyfert 2 galaxies in the GeV band: jets and starburst Abstract: The Fermi/LAT collaboration recently reported the detection of starburt\ngalaxies in the high energy gamma-ray domain, as well as radio-loud narrow-line\nSeyfert 1 objects. Motivated by the presence of sources close to the location\nof composite starburst/Seyfert 2 galaxies in the first year Fermi/LAT\ncatalogue, we aim at studying high energy gamma-ray emission from such objects,\nand at disentangling the emission of starburst and Seyfert activity. We\nanalysed 1.6 years of Fermi/LAT data from NGC 1068 and NGC 4945, which count\namong the brightest Seyfert 2 galaxies. We search for potential variability of\nthe high energy signal, and derive a spectrum of these sources. We also analyse\npublic INTEGRAL IBIS/ISGRI data over the last seven years to derive their hard\nX-ray spectrum. We find an excess of high energy gamma-rays of 8.3 sigma and\n9.2 sigma for 1FGL J0242.7+0007 and 1FGL J1305.4-4928, which are found to be\nconsistent with the position of the Seyfert 2 galaxies NGC 1068 and NGC 4945,\nrespectively. The energy spectrum of the sources can be described by a power\nlaw with a photon index of Gamma=2.31 \\pm 0.13 for NGC 1068, while for NGC\n4945, we obtain a photon index of Gamma=2.31 \\pm 0.10. For both sources, we\ndetect no significant variability nor any indication of a curvature of the\nspectrum. We discuss the origin of the high energy emission of these objects in\nthe context of Seyfert or starburst activity. While the emission of NGC 4945 is\nconsistent with starburst activity, that of NGC 1068 is an order of magnitude\nabove expectations, suggesting dominant emission from the active nucleus. We\nshow that a leptonic scenario can account for the multi-wavelength spectral\nenergy distribution of NGC 1068. \n\n"}
{"id": "1009.1620", "contents": "Title: On the Masses of Galaxies in the Local Universe Abstract: We compare estimates of stellar mass, Mstar, and dynamical mass,Mdyn,for a\nsample of galaxies from the Sloan Digital Sky Survey (SDSS). We assume\ndynamical homology (i.e., Mdyn = dispersion**2 * Reff, and we find a tight but\nstrongly non-linear relation: the best fit relation is Mstar = Mdyn**0.73, with\nan observed scatter of 0.15 dex. We also find that, at fixed Mstar, the ratio\nMstar/Mdyn depends strongly on galaxy structure, as parameterized by Sersic\nindex, n. The size of the differential effect is on the order of 0.6 dex across\n2 < n < 10. The apparent n-dependence of Mstar/Mdyn is similar to expectations\nfrom simple models, indicating that assuming homology gives the wrong dynamical\nmass. We have also derived dynamical mass estimates that explicitly account for\ndifferences in galaxies' profiles. Using this `structure-corrected' dynamical\nmass estimator, M(dyn,n), the best fit relation is Mstar = M(dyn,n)**(0.92 +-\n0.08) with an observed scatter of 0.13 dex. While the data are thus consistent\nwith a linear relation, they do prefer a slightly shallower slope. Further, we\nsee only a small residual trend in Mstar/M(dyn,n) with n. We find no\nstatistically significant systematic trends in Mstar/M(dyn,n) as a function of\nobserved quantities (e.g, apparent magnitude, redshift), or as a function of\ntracers of stellar populations. The net differential bias in Mstar/M(dyn,n)\nacross a wide range of stellar populations and star formation activities is <=\n0.12 dex. The very good agreement between stellar mass and structure-corrected\ndynamical mass strongly suggests that: 1.) galaxy non-homology has a major\nimpact on dynamical mass estimates, and 2. there are not strong systematic\nbiases in the stellar mass-to-light ratios derived from broadband optical SEDs.\nFurther, these results suggest that that the central dark-to-luminous mass\nratio has a relatively weak mass dependence. \n\n"}
{"id": "1009.1938", "contents": "Title: LOFAR, LEAP and beyond: Using next generation telescopes for pulsar\n  astrophysics Abstract: Radio astronomy has benefited greatly from advances in technology and will\ncontinue to do so in the future. In fact, we are experiencing a revolution in\nthe way radio astronomy is conducted as our instruments allow us now to\ndirectly \"digitize\" our photons. This has enormous consequences, since we can\ngreatly benefit from the continuing advances in digital electronics,\ntelecommunication and computing. The results are dramatic increase in\nobservable bandwidths, FoVs, frequency coverage and collecting area. The global\nefforts will culminate in the construction of the SKA as the world's largest\nand most powerful telescope. On the way projects like LOFAR, LEAP and others\nwill revolutionize many areas of astrophysics and fundamental physics.\nObservations of pulsars will play a central role in these scientific\nendeavours. We briefly summarize here some recent scientific developments that\nhelp us in defining our expectations for the the new generation of radio\ntelescopes for pulsar astrophysics. \n\n"}
{"id": "1009.3276", "contents": "Title: Hot-Dust-Poor Type 1 Active Galactic Nuclei in the COSMOS Survey Abstract: We report a sizable class of type 1 active galactic nuclei (AGNs) with\nunusually weak near-infrared (1-3{\\mu}m) emission in the XMM-COSMOS type 1 AGN\nsample. The fraction of these \"hot-dust-poor\" AGNs increases with redshift from\n6% at lowredshift (z < 2) to 20% at moderate high redshift (2 < z < 3.5). There\nis no clear trend of the fraction with other parameters: bolometric luminosity,\nEddington ratio, black hole mass, and X-ray luminosity. The 3{\\mu}m emission\nrelative to the 1{\\mu}m emission is a factor of 2-4 smaller than the typical\nElvis et al. AGN spectral energy distribution (SED), which indicates a \"torus\"\ncovering factor of 2%-29%, a factor of 3-40 smaller than required by unified\nmodels. The weak hot dust emission seems to expose an extension of the\naccretion disk continuum in some of the source SEDs. We estimate the outer edge\nof their accretion disks to lie at $(0.3-2.0) /times 10^4$ Schwarzschild radii,\n~10-23 times the gravitational stability radii. Formation scenarios for these\nsources are discussed. \n\n"}
{"id": "1009.3380", "contents": "Title: The outer halos of elliptical galaxies Abstract: Recent progress is summarized on the determination of the density\ndistributions of stars and dark matter, stellar kinematics, and stellar\npopulation properties, in the extended, low surface brightness halo regions of\nelliptical galaxies. With integral field absorption spectroscopy and with\nplanetary nebulae as tracers, velocity dispersion and rotation profiles have\nbeen followed to ~4 and ~5-8 effective radii, respectively, and in M87 to the\nouter edge at ~150 kpc. The results are generally consistent with the known\ndichotomy of elliptical galaxy types, but some galaxies show more complex\nrotation profiles in their halos and there is a higher incidence of\nmisalignments, indicating triaxiality. Dynamical models have shown a range of\nslopes for the total mass profiles, and that the inner dark matter densities in\nellipticals are higher than in spiral galaxies, indicating earlier assembly\nredshifts. Analysis of the hot X-ray emitting gas in X-ray bright ellipticals\nand comparison with dynamical mass determinations indicates that non-thermal\ncomponents to the pressure may be important in the inner ~10 kpc, and that the\nproperties of these systems are closely related to their group environments.\nFirst results on the outer halo stellar population properties do not yet give a\nclear picture. In the halo of one bright galaxy, lower [alpha/Fe] abundances\nindicate longer star formation histories pointing towards late accretion of the\nhalo. This is consistent with independent evidence for on-going accretion, and\nsuggests a connection to the observed size evolution of elliptical galaxies\nwith redshift. \n\n"}
{"id": "1009.5071", "contents": "Title: Self-tuning of the cosmological constant Abstract: Here, I discuss the cosmological constant (CC) problems, in particular paying\nattention to the vanishing cosmological constant. There are three cosmological\nconstant problems in particle physics. Hawking's idea of calculating the\nprobability amplitude for our Universe is peaked at CC = 0 which I try to\nobtain after the initial inflationary period using a self-tuning model. I\nreview what has been discussed on the Hawking type calculation, and present a\n(probably) correct way to calculate the amplitude, and show that the\nKim-Kyae-Lee self-tuning model allows a finite range of parameters for the CC =\n0 to have a singularly large probability, approached from the AdS side. \n\n"}
{"id": "1009.5190", "contents": "Title: Calibration and sensitivity of the Virgo detector during its second\n  science run Abstract: The Virgo detector is a kilometer-length interferometer for gravitational\nwave detection located near Pisa (Italy). During its second science run (VSR2)\nin 2009, six months of data were accumulated with a sensitivity close to its\ndesign. In this paper, the methods used to determine the parameters for\nsensitivity estimation and gravitational wave reconstruction are described. The\nmain quantities to be calibrated are the frequency response of the mirror\nactuation and the sensing of the output power. Focus is also put on their\nabsolute timing. The monitoring of the calibration data as well as the\nparameter estimation with independent techniques are discussed to provide an\nestimation of the calibration uncertainties. Finally, the estimation of the\nVirgo sensitivity in the frequency-domain is described and typical\nsensitivities measured during VSR2 are shown. \n\n"}
{"id": "1009.5243", "contents": "Title: Relic gravitational waves: latest revisions and preparations for new\n  data Abstract: The forthcoming release of data from the Planck mission, and possibly from\nthe next round of Wilkinson Microwave Anisotropy Probe (WMAP) observations,\nmake it necessary to revise the evaluations of relic gravitational waves in the\nexisting data and, at the same time, to refine the assumptions and data\nanalysis techniques in preparation for the arrival of new data. We reconsider\nwith the help of the commonly used CosmoMC numerical package the previously\nfound indications of relic gravitational waves in the 7-year (WMAP7) data. The\nCosmoMC approach reduces the confidence of these indications from approximately\n2$\\sigma$ level to approximately 1$\\sigma$ level, but the indications do not\ndisappear altogether. We critically analyze the assumptions that are currently\nused in the Cosmic Microwave Background (CMB) data analyzes and outline the\nstrategy that should help avoid the oversight of relic gravitational waves in\nthe future CMB data. In particular, it is important to keep away from the\nunwarranted assumptions about density perturbations. The prospects of confident\ndetection of relic gravitational waves by the Planck satellite have worsened,\nbut they are still good. It appears that more effort will be required in order\nto mitigate the foreground contamination. \n\n"}
{"id": "1010.0006", "contents": "Title: Understanding micro-image configurations in quasar microlensing Abstract: The micro-arcsecond scale structure of the seemingly point-like images in\nlensed quasars, though unobservable, is nevertheless much studied\ntheoretically, because it affects the observable (or macro) brightness, and\nthrough that provides clues to substructure in both source and lens. A curious\nfeature is that, while an observable macro-image is made up of a very large\nnumber of micro-images, the macro flux is dominated by a few micro-images.\nMicro minima play a key role, and the well-known broad distribution of macro\nmagnification can be decomposed into narrower distributions with 0,1,2,3,...\nmicro minima. This paper shows how the dominant micro-images exist alongside\nthe others, using the ideas of Fermat's principle and arrival-time surfaces,\nalongside simulations. \n\n"}
{"id": "1010.0855", "contents": "Title: The GRBs Hubble diagram in quintessential cosmological models Abstract: It has been recently empirically established that some of the directly\nobserved pa- rameters of GRBs are correlated with their important intrinsic\nparameters, like the luminosity or the total radiated energy. These\ncorrelations were derived, tested and used to standardize GRBs, i.e., to derive\ntheir luminosity or radiated energy from one or more observables, in order to\nconstruct an estimated fiducial Hubble diagram, assuming that radiation\npropagates in the standard LambdaCDM cosmological model. We extend these\nanalyses by considering more general models of dark energy, and an updated data\nset of high redshift GRBs. We show that the correlation parameters only weakly\ndepend on the cosmological model. Moreover we apply a local regression\ntechnique to estimate, in a model independent way, the distance modulus from\nthe recently updated SNIa sample containing 307 SNIa (Astier et al. 2006), in\norder to calibrate the GRBs 2D correlations, considering only GRBs with z <1.4.\nThe derived calibration parameters are used to construct a new GRBs Hubble\ndiagram, which we call the calibrated GRBs HD. We also compare the estimated\nand calibrated GRBs HDs. It turns out that for the common GRBs they are fully\nstatistically consistent, thus indicating that both of them are not affected by\nany systematic bias induced by the different standardizing procedures. We\nfinally apply our methods to calibrate 95 long GRBs with the well-known Amati\nrelation and construct the estimated and calibrated GRBs Hubble diagram that\nextends to redshifts z ~ 8. Even in this case there is consistency between\nthese datasets. This means that the high redshift GRBs can be used to test\ndifferent models of dark energy. We used the calibrated GRBs HD to constrain\nour quintessential cosmological model and derived the likelihood values of\nOmega_m and w(0). \n\n"}
{"id": "1010.2010", "contents": "Title: Relic Densities of Dark Matter in the U(1)-Extended NMSSM and the Gauged\n  Axion Supermultiplet Abstract: We compute the dark matter relic densities of neutralinos and axions in a\nsupersymmetric model with a gauged anomalous U(1) symmetry, kinetically mixed\nwith $U(1)_Y$ of hypercharge. The model is a variant of the USSM (the U(1)\nextended NMSSM), containing an extra U(1) symmetry and an extra singlet in the\nsuperpotential respect to the MSSM, where gauge invariance is restored by\nPeccei-Quinn interactions using a Stuckelberg multiplet. This approach\nintroduces an axion (Im b) and a saxion (Re b) in the spectrum and generates an\naxino component for the neutralino. The Stuckelberg axion (Im b) develops a\nphysical component (the gauged axion) after electroweak symmetry breaking. We\nclassify all the interactions of the Lagrangian and perform a complete\nsimulation study of the spectrum, determining the neutralino relic densities\nusing micrOMEGAs. We discuss the phenomenological implications of the model\nanalyzing mass values for the axion from the milli-eV to the MeV region. The\npossible scenarios that we analyze are significantly constrained by a\ncombination of WMAP data, the exclusion limits from direct axion searches and\nthe veto on late entropy release at the time of nucleosynthesis. \n\n"}
{"id": "1010.3580", "contents": "Title: Axions and Cosmic Rays Abstract: We investigate the propagation of a charged particle in a spatially constant\nbut time dependent pseudoscalar background. Physically this pseudoscalar\nbackground could be provided by a relic axion density. The background leads to\nan explicit breaking of Lorentz invariance; as a consequence processes such as\n$p\\to p \\gamma$ or $e\\to e \\gamma$ are possible within some kinematical\nconstraints. The phenomenon is described by the QED lagrangian extended with a\nChern-Simons term that contains a 4-vector which characterizes the breaking of\nLorentz invariance induced by the time-dependent background. While the\nradiation induced (similar to the Cherenkov effect) is too small to influence\nthe propagation of cosmic rays in a significant way, the hypothetical detection\nof the photons radiated by high energy cosmic rays via this mechanism would\nprovide an indirect way of verifying the cosmological relevance of axions. We\ndiscuss on the order of magnitude of the effect. \n\n"}
{"id": "1010.4376", "contents": "Title: Evolution of gaseous disk viscosity driven by supernova explosion. II.\n  Structure and emissions from star-forming galaxies at high redshift Abstract: (Abridged) High redshift galaxies are undergoing intensive evolution of\ndynamical structure and morphologies. We incorporate the feedback into the\ndynamical equations through mass dropout and angular momentum transportation\ndriven by the SNexp-excited turbulent viscosity. We numerically solve the\nequations and show that there can be intensive evolution of structure of the\ngaseous disk. Secular evolution of the disk shows interesting characteristics\nthat are 1) high viscosity excited by SNexp can efficiently transport the gas\nfrom 10kpc to $\\sim 1$kpc forming a stellar disk whereas a stellar ring forms\nfor the case with low viscosity; 2) starbursts trigger SMBH activity with a lag\n$\\sim 10^8$yr depending on star formation rates, prompting the joint evolution\nof SMBHs and bulges; 3) the velocity dispersion is as high as $\\sim 100~\\kms$\nin the gaseous disk. In order to compare the present models with the observed\ndynamical structure and images, we use the incident continuum from the simple\nstellar synthesis (GALAXEV) and CLOUDY to calculate emission line ratios of\nH$\\alpha$, H$\\beta$, $\\OIII$ and $\\NII$, and H$\\alpha$ brightness of gas\nphotoionized by young massive stars formed on the disks. The models can produce\nthe main features of emission from star forming galaxies and the observed\nrelation between turbulent velocity and the H$\\alpha$ brightness. We\nsuccessfully apply the present model to BX 389 and BX 482 observed in SINS\nhigh$-z$ sample, which are bulge and disk-dominated, respectively. High\nviscosity excited by SNexp is able to efficiently transport the gas into a\nbulge to maintain high star formation rates, or, to form a stellar ring close\nenough to the bulge so that it immigrates into the bulge of its host galaxy.\nThis leads to a fast growing bulge. Implications and future work of the present\nmodels have been extensively discussed for galaxy formation. \n\n"}
{"id": "1010.4489", "contents": "Title: GMRT observation towards detecting the Post-reionization 21-cm signal Abstract: We have analyzed 610 MHz GMRT observations towards detecting the redshifted\n21-cm signal from z=1.32. The multi-frequency angular power spectrum C_l(Delta\nnu) is used to characterize the statistical properties of the background\nradiation across angular scales ~20\" to 10', and a frequency bandwidth of 7.5\nMHz with resolution 125 kHz. The measured C_l(Delta nu) which ranges from 7\nmK^2 to 18 mK^2 is dominated by foregrounds, the expected HI signal\nC_l^HI(Delta nu) ~10^{-6}- 10^{-7} mK^2 is several orders of magnitude smaller.\nThe foregrounds, believed to originate from continuum sources, is expected to\nvary smoothly with Delta nu whereas the HI signal decorrelates within ~0.5 MHz\nand this holds the promise of separating the two. For each l, we use the\ninterval 0.5 < Delta nu < 7.5 MHz to fit a fourth order polynomial which is\nsubtracted from the measured C_l(Delta nu) to remove any smoothly varying\ncomponent across the entire bandwidth Delta nu < 7.5 MHz. The residual\nC_l(Delta nu), we find, has an oscillatory pattern with amplitude and period\nrespectively ~0.1 mK^2 and Delta nu = 3 MHz at the smallest l value of 1476,\nand the amplitude and period decreasing with increasing l. Applying a suitably\nchosen high pass filter, we are able to remove the residual oscillatory pattern\nfor l=1476 where the residual C_l(Delta nu) is now consistent with zero at the\n3-sigma noise level. We conclude that we have successfully removed the\nforegrounds at l=1476 and the residuals are consistent with noise. We use this\nto place an upper limit on the HI signal whose amplitude is determined by x_HI\nb where x_HI and b are the HI neutral fraction and the HI bias respectively. A\nvalue of x_HI b greater than 7.95 would have been detected in our observation,\nand is therefore ruled out at the 3-sigma level. (abridged) \n\n"}
{"id": "1010.4543", "contents": "Title: CMB two- and three-point correlation functions from Alfv\\'en waves Abstract: We study the cosmic microwave background (CMB) temperature fluctuations\nnon-gaussianity due to the vector mode perturbations (Alfv\\'en waves) supported\nby a stochastic cosmological magnetic field. We present detailed derivations of\nthe statistical properties, two and three point correlation functions of the\nvorticity perturbations and corresponding CMB temperature fluctuations. \n\n"}
{"id": "1010.5187", "contents": "Title: Light WIMP Searches: The Effect of the Uncertainty in Recoil Energy\n  Scale and Quenching Factor Abstract: Taking liquid xenon detectors as a case study, the importance of a robust\nrecoil energy calibration as a prerequisite to a search for light-mass Weakly\nInteracting Massive Particles (WIMPs) is emphasized. Important shortfalls in\nthe analysis of existing measurements of the relative scintillation efficiency\nand ionization yield for nuclear recoils in liquid xenon are described, leading\nto the conclusion that recent attempts to extract light-WIMP sensitivity limits\nfrom the XENON10 and XENON100 detectors are premature and overly optimistic. \n\n"}
{"id": "1010.5289", "contents": "Title: The first bent double lobe radio source in a known cluster filament:\n  Constraints on the intra-filament medium Abstract: We announce the first discovery of a bent double lobe radio source (DLRS) in\na known cluster filament. The bent DLRS is found at a distance of 3.4 Mpc from\nthe center of the rich galaxy cluster, Abell~1763. We derive a bend angle\nalpha=25deg, and infer that the source is most likely seen at a viewing angle\nof Phi=10deg. From measuring the flux in the jet between the core and further\nlobe and assuming a spectral index of 1, we calculate the minimum pressure in\nthe jet, (8.0+-3.2)x10^-13 dyn/cm^2, and derive constraints on the\nintra-filament medium (IFM) assuming the bend of the jet is due to ram\npressure. We constrain the IFM to be between (1-20)x10^-29 gm/cm^3. This is\nconsistent with recent direct probes of the IFM and theoretical models. These\nobservations justify future searches for bent double lobe radio sources located\nseveral Mpc from cluster cores, as they may be good markers of super cluster\nfilaments. \n\n"}
{"id": "1010.5343", "contents": "Title: REAS3: Monte Carlo simulations of radio emission from cosmic ray air\n  showers using an \"end-point\" formalism Abstract: In recent years, the freely available Monte Carlo code REAS for modelling\nradio emission from cosmic ray air showers has evolved to include the full\ncomplexity of air shower physics. However, it turned out that in REAS2 and all\nother time-domain models which calculate the radio emission by superposing the\nradiation of the single air shower electrons and positrons, the calculation of\nthe emission contributions was not fully consistent. In this article, we\npresent a revised implementation in REAS3, which incorporates the missing radio\nemission due to the variation of the number of charged particles during the air\nshower evolution using an \"end-point formalism\". With the inclusion of these\nemission contributions, the structure of the simulated radio pulses changes\nfrom unipolar to bipolar, and the azimuthal emission pattern becomes nearly\nsymmetric. Remaining asymmetries can be explained by radio emission due to the\nvariation of the net charge excess in air showers, which is automatically taken\ninto account in the new implementation. REAS3 constitutes the first\nself-consistent time-domain implementation based on single particle emission\ntaking the full complexity of air shower physics into account, and is freely\navailable for all interested users. \n\n"}
{"id": "1010.5787", "contents": "Title: Herschel-ATLAS: First data release of the Science Demonstration Phase\n  source catalogues Abstract: The Herschel-ATLAS is a survey of 550 square degrees with the Herschel Space\nObservatory in five far--infrared and submillimetre bands. The first data for\nthe survey, observations of a field 4x4 sq. degrees in size, were taken during\nthe Science Demonstration Phase, and reach a 5 sigma noise level of 33 mJy/beam\nat 250 microns. This paper describes the source extraction methods used to\ncreate the corresponding Science Demonstration Phase catalogue, which contains\n6876 sources, selected at 250 microns, within ~14 sq. degrees. SPIRE sources\nare extracted using a new method specifically developed for Herschel data; PACS\ncounterparts of these sources are identified using circular apertures placed at\nthe SPIRE positions. Aperture flux densities are measured for sources\nidentified as extended after matching to optical wavelengths. The reliability\nof this catalogue is also discussed, using full simulated maps at the three\nSPIRE bands. These show that a significant number of sources at 350 and 500\nmicrons have undergone flux density enhancements of up to a factor of ~2, due\nmainly to source confusion. Correction factors are determined for these\neffects. The SDP dataset and corresponding catalogue will be available from\nhttp://www.h-atlas.org/. \n\n"}
{"id": "1010.6299", "contents": "Title: Investigation of the fundamental constants stability based on the\n  reactor Oklo burn-up analysis Abstract: The burn-up for SC56-1472 sample of the natural Oklo reactor zone 3 was\ncalculated using the modern Monte Carlo codes. We reconstructed the neutron\nspectrum in the core by means of the isotope ratios: $^{147}$Sm/$^{148}$Sm and\n$^{176}$Lu/$^{175}$Lu. These ratios unambiguously determine the spectrum index\nand core temperature. The effective neutron absorption cross section of\n$^{149}$Sm calculated using this spectrum was compared with experimental one.\nThe disagreement between these two values allows to limit a possible shift of\nthe low laying resonance of $^{149}$Sm even more . Then, these limits were\nconverted to the limits for the change of the fine structure constant $\\alpha$.\nWe found that for the rate of $\\alpha$ change the inequality $|\\delta\n\\dot{\\alpha}/\\alpha| \\le 5\\cdot 10^{-18}$ is fulfilled, which is of the next\nhigher order than our previous limit. \n\n"}
{"id": "1011.1913", "contents": "Title: Towards Precision LSST Weak-Lensing Measurement - I: Impacts of\n  Atmospheric Turbulence and Optical Aberration Abstract: The weak-lensing science of the LSST project drives the need to carefully\nmodel and separate the instrumental artifacts from the intrinsic lensing\nsignal. The dominant source of the systematics for all ground based telescopes\nis the spatial correlation of the PSF modulated by both atmospheric turbulence\nand optical aberrations. In this paper, we present a full FOV simulation of the\nLSST images by modeling both the atmosphere and the telescope optics with the\nmost current data for the telescope specifications and the environment. To\nsimulate the effects of atmospheric turbulence, we generated six-layer phase\nscreens with the parameters estimated from the on-site measurements. For the\noptics, we combined the ray-tracing tool ZEMAX and our simulated focal plane\ndata to introduce realistic aberrations and focal plane height fluctuations.\nAlthough this expected flatness deviation for LSST is small compared with that\nof other existing cameras, the fast f-ratio of the LSST optics makes this focal\nplane flatness variation and the resulting PSF discontinuities across the CCD\nboundaries significant challenges in our removal of the systematics. We resolve\nthis complication by performing PCA CCD-by-CCD, and interpolating the basis\nfunctions using conventional polynomials. We demonstrate that this PSF\ncorrection scheme reduces the residual PSF ellipticity correlation below 10^-7\nover the cosmologically interesting scale. From a null test using HST/UDF\ngalaxy images without input shear, we verify that the amplitude of the galaxy\nellipticity correlation function, after the PSF correction, is consistent with\nthe shot noise set by the finite number of objects. Therefore, we conclude that\nthe current optical design and specification for the accuracy in the focal\nplane assembly are sufficient to enable the control of the PSF systematics\nrequired for weak-lensing science with the LSST. \n\n"}
{"id": "1011.2209", "contents": "Title: Monte Carlo simulations of the Nickel K$\\alpha$ fluorescent emission\n  line in a toroidal geometry Abstract: We present new results from Monte Carlo calculations of the flux and\nequivalent width (EW) of the Ni Kalpha fluorescent emission line in the\ntoroidal X-ray reprocessor model of Murphy & Yaqoob (2009, MNRAS, 397, 1549).\nIn the Compton-thin regime, the EW of the Ni Kalpha line is a factor of ~22\nless than that of the Fe Kalpha line but this factor can be as low as ~6 in the\nCompton-thick regime. We show that the optically-thin limit for this ratio\ndepends only on the Fe to Ni abundance ratio, it being independent of the\ngeometry and covering factor of the reprocessor, and also independent of the\nshape of the incident X-ray continuum. We give some useful analytic expressions\nfor the absolute flux and the EW of the Ni Kalpha line in the optically-thin\nlimit. When the reprocessor is Compton-thick and the incident continuum is a\npower-law with a photon index of 1.9, the Ni Kalpha line EW has a maximum value\nof ~3 eV and ~250 eV for non-intercepting and intercepting lines-of-sight\nrespectively. Larger EWs are obtained for flatter continua. We have also\nstudied the Compton shoulder of the Ni Ka line and find that the ratio of\nscattered to unscattered flux in the line has a maximum value of 0.26, less\nthan the corresponding maximum for the Fe Kalpha line. However, we find that\nthe shape of the Compton shoulder profile for a given column density and\ninclination angle of the torus is similar to the corresponding profile for the\nFe Ka line. Our results will be useful for interpreting X-ray spectra of active\ngalactic nuclei (AGNs) and X-ray binary systems in which the system parameters\nare favorable for the Ni Kalpha line to be detected. \n\n"}
{"id": "1011.2345", "contents": "Title: Enhanced Inflation in the Dirac-Born-Infeld framework Abstract: We consider the Einstein equations within the DBI scenario for a spatially\nflat Friedmann-Robertson-Walker (FRW) spacetime without a cosmological\nconstant. We derive the inflationary scenario by applying the symmetry\ntransformations which preserve the form of the Friedmann and conservation\nequations. These form invariance transformations generate a symmetry group\nparametrized by the Lorentz factor $\\ga$. We explicitly obtain an inflationary\nscenario by the cooperative effect of adding energy density into the Friedmann\nequation. For the case of a constant Lorentz factor, and under the slow roll\nassumption, we find the transformation rules for the scalar and tensor power\nspectra of perturbations as well as their ratio under the action of the form\ninvariance symmetry group. Within this case and due to its relevance for the\ninflationary paradigm, we find the general solution of the dynamical equations\nfor a DBI field driven by an exponential potential and show a broad set of\ninflationary solutions. The general solution can be split into three subsets\nand all these behave asymptotically as a power law solution at early and at\nlate times. \n\n"}
{"id": "1011.2779", "contents": "Title: Inflationary observables in loop quantum cosmology Abstract: The full set of cosmological observables coming from linear scalar and tensor\nperturbations of loop quantum cosmology is computed in the presence of\ninverse-volume corrections. Background inflationary solutions are found at\nlinear order in the quantum corrections; depending on the values of\nquantization parameters, they obey an exact or perturbed power-law expansion in\nconformal time. The comoving curvature perturbation is shown to be conserved at\nlarge scales, just as in the classical case. Its associated Mukhanov equation\nis obtained and solved. Combined with the results for tensor modes, this yields\nthe scalar and tensor indices, their running, and the tensor-to-scalar ratio,\nwhich are all first order in the quantum correction. The latter could be\nsizable in phenomenological scenarios. Contrary to a pure minisuperspace\nparametrization, the lattice refinement parametrization is in agreement with\nboth anomaly cancellation and our results on background solutions and linear\nperturbations. The issue of the choice of parametrization is also discussed in\nrelation with a possible superluminal propagation of perturbative modes, and\nconclusions for quantum spacetime structure are drawn. \n\n"}
{"id": "1011.3988", "contents": "Title: Running Spectral Index from Inflation with Modulations Abstract: We argue that a large negative running spectral index, if confirmed, might\nsuggest that there are abundant structures in the inflaton potential, which\nresult in a fairly large (both positive and negative) running of the spectral\nindex at all scales. It is shown that the center value of the running spectral\nindex suggested by the recent CMB data can be easily explained by an inflaton\npotential with superimposed periodic oscillations. In contrast to cases with\nconstant running, the perturbation spectrum is enhanced at small scales, due to\nthe repeated modulations. We mention that such features at small scales may be\nseen by 21 cm observations in the future. \n\n"}
{"id": "1011.5311", "contents": "Title: Citations and impact of Dutch astronomy Abstract: The aim of this study is to make a bibliometric comparison of the performance\nof research astronomers in the Netherlands Research School for Astronomy (NOVA)\nwith astronomers elsewhere by using the NASA Astrophysics Data System (ADS). We\nuse various indices for bibliometric performance for a sample of NOVA\nastronomers to compare to samples of astronomers worldwide, and from the United\nStates. We give much weight to normalising bibliometric measures by number of\nauthors, and number of years since first publication. In particular we\ncalculate the `Hirsh-index' normalized to number of authors and for\nfirst-author papers. Secondly, we consider the results of the 'Nederlands\nObservatorium van Wetenschap en Technologie' (NOWT; Netherlands Observatory of\nScience and Technology), which regularly publishes a report 'Science and\nTechnology Indicators'. We reproduce those results using publication lists from\ninstitutions in the Netherlands, again using ADS, and examine and discuss the\nconclusions and indications in these reports. We find that the NOVA researchers\nperform much better in bibliometric measures than samples drawn from IAU or AAS\nmembership lists. A more suitable comparison is one with the (tenured) staff of\nthe top-15 US institutions and there the NOVA staff performs in these respects\nas good or almost as good as that of American top institutes. From a citation\nanalysis through the use of ADS we conclude that the impact ratio of Dutch\nastronomical publications is rising which is opposite to what is reported by\nNOWT. This difference is most likely caused by a better separation of astronomy\nand physics in ADS than in World of Knowledge. ADS probably finds more\ncitations in conference proceedings, while the inclusion of citations to\narticles with their pre-print identifier could also help explain the difference\n(especially since the citation windows in the reports are short). \n\n"}
{"id": "1011.6146", "contents": "Title: On Dark Energy Isocurvature Perturbation Abstract: Determining the equation of state of dark energy with astronomical\nobservations is crucially important to understand the nature of dark energy. In\nperforming a likelihood analysis of the data, especially of the cosmic\nmicrowave background and large scale structure data the dark energy\nperturbations have to be taken into account both for theoretical consistency\nand for numerical accuracy. Usually, one assumes in the global fitting analysis\nthat the dark energy perturbations are adiabatic. In this paper, we study the\ndark energy isocurvature perturbation analytically and discuss its implications\nfor the cosmic microwave background radiation and large scale structure.\nFurthermore, with the current astronomical observational data and by employing\nMarkov Chain Monte Carlo method, we perform a global analysis of cosmological\nparameters assuming general initial conditions for the dark energy\nperturbations. The results show that the dark energy isocurvature perturbations\nare very weakly constrained and that purely adiabatic initial conditions are\nconsistent with the data. \n\n"}
{"id": "1011.6363", "contents": "Title: Modeling the frequency response of microwave radiometers with QUCS Abstract: Characterization of the frequency response of coherent radiometric receivers\nis a key element in estimating the flux of astrophysical emissions, since the\nmeasured signal depends on the convolution of the source spectral emission with\nthe instrument band shape.\n  Laboratory Radio Frequency (RF) measurements of the instrument bandpass often\nrequire complex test setups and are subject to a number of systematic effects\ndriven by thermal issues and impedance matching, particularly if cryogenic\noperation is involved.\n  In this paper we present an approach to modeling radiometers bandpasses by\nintegrating simulations and RF measurements of individual components. This\nmethod is based on QUCS (Quasi Universal Circuit Simulator), an open-source\ncircuit simulator, which gives the flexibility of choosing among the available\ndevices, implementing new analytical software models or using measured\nS-parameters. Therefore an independent estimate of the instrument bandpass is\nachieved using standard individual component measurements and validated\nanalytical simulations.\n  In order to automate the process of preparing input data, running simulations\nand exporting results we developed the Python package python-qucs and released\nit under GNU Public License.\n  We discuss, as working cases, bandpass response modeling of the COFE and\nPlanck Low Frequency Instrument (LFI) radiometers and compare results obtained\nwith QUCS and with a commercial circuit simulator software. The main purpose of\nbandpass modeling in COFE is to optimize component matching, while in LFI they\nrepresent the best estimation of frequency response, since end-to-end\nmeasurements were strongly affected by systematic effects. \n\n"}
{"id": "1012.1166", "contents": "Title: MIMAC : A micro-tpc matrix for directional detection of dark matter Abstract: Directional detection of non-baryonic Dark Matter is a promising search\nstrategy for discriminating WIMP events from background. However, this strategy\nrequires both a precise measurement of the energy down to a few keV and 3D\nreconstruction of tracks down to a few mm. To achieve this goal, the MIMAC\nproject has been developed. It is based on a gaseous micro-TPC matrix, filled\nwith 3He, CF4 and/or C4H10. The first results on low energy nuclear recoils (1H\nand 19F) obtained with a low mono-energetic neutron field are presented. The\ndiscovery potential of this search strategy is discussed and illustrated by a\nrealistic case accessible to MIMAC. \n\n"}
{"id": "1012.2756", "contents": "Title: Cosmic acceleration a new review Abstract: Recent observations of near supernova show that the acceleration expansion of\nUniverse decreases. This phenomenon is called the transient acceleration. In\nthe second part of work we consider the 3-component Universe composed of a\nscalar field, interacting with the dark matter on the agegraphic dark energy\nbackground. We show that the transient acceleration appears in frame of such a\nmodel. The obtained results agree with the latest cosmological observations,\nnamely, the 557 SNIa sample (Union2) was released by the Supernova Cosmology\nProject (SCP) Collaboration. \n\n"}
{"id": "1012.2865", "contents": "Title: Enzo+Moray: Radiation Hydrodynamics Adaptive Mesh Refinement Simulations\n  with Adaptive Ray Tracing Abstract: We describe a photon-conserving radiative transfer algorithm, using a\nspatially-adaptive ray tracing scheme, and its parallel implementation into the\nadaptive mesh refinement (AMR) cosmological hydrodynamics code, Enzo. By\ncoupling the solver with the energy equation and non-equilibrium chemistry\nnetwork, our radiation hydrodynamics framework can be utilised to study a broad\nrange of astrophysical problems, such as stellar and black hole (BH) feedback.\nInaccuracies can arise from large timesteps and poor sampling, therefore we\ndevised an adaptive time-stepping scheme and a fast approximation of the\noptically-thin radiation field with multiple sources. We test the method with\nseveral radiative transfer and radiation hydrodynamics tests that are given in\nIliev et al. (2006, 2009). We further test our method with more dynamical\nsituations, for example, the propagation of an ionisation front through a\nRayleigh-Taylor instability, time-varying luminosities, and collimated\nradiation. The test suite also includes an expanding H II region in a\nmagnetised medium, utilising the newly implemented magnetohydrodynamics module\nin Enzo. This method linearly scales with the number of point sources and\nnumber of grid cells. Our implementation is scalable to 512 processors on\ndistributed memory machines and can include radiation pressure and secondary\nionisations from X-ray radiation. It is included in the newest public release\nof Enzo. \n\n"}
{"id": "1012.3045", "contents": "Title: Bulk viscous cosmology: unified dark matter Abstract: The bulk viscosity is introduced to model unified dark matter. The viscous\nunified model assumes the universe is filled with a single fluid with the bulk\nviscosity. We review the general framework of the viscous cosmology. The Hubble\nparameter has a direct connection with the bulk viscosity coefficient. For\nconcrete form of the bulk viscosity, the Hubble parameter which has the scaling\nrelation with the redshift can be obtained. We discuss two viscosity models and\nthe cosmological evolution to which they lead. Using SNe Ia data, the viscosity\nmodel can be fitted. We briefly review the fitting method here. \n\n"}
{"id": "1012.3912", "contents": "Title: DMTPC: Dark matter detection with directional sensitivity Abstract: The Dark Matter Time Projection Chamber (DMTPC) experiment uses CF_4 gas at\nlow pressure (0.1 atm) to search for the directional signature of Galactic WIMP\ndark matter. We describe the DMTPC apparatus and summarize recent results from\na 35.7 g-day exposure surface run at MIT. After nuclear recoil cuts are applied\nto the data, we find 105 candidate events in the energy range 80 - 200 keV,\nwhich is consistent with the expected cosmogenic neutron background. Using this\ndata, we obtain a limit on the spin-dependent WIMP-proton cross-section of 2.0\n\\times 10^{-33} cm^2 at a WIMP mass of 115 GeV/c^2. This detector is currently\ndeployed underground at the Waste Isolation Pilot Plant in New Mexico. \n\n"}
{"id": "1012.4243", "contents": "Title: First geodetic observations using new VLBI stations ASKAP-29 and WARK12M Abstract: We report the results of a successful 7 hour 1.4 GHz VLBI experiment using\ntwo new stations, ASKAP-29 located in Western Australia and WARK12M located on\nthe North Island of New Zealand. This was the first geodetic VLBI observing\nsession with the participation of these new stations. We have determined the\npositions of ASKAP-29 and WARK12M. Random errors on position estimates are\n150-200 mm for the vertical component and 40-50 mm for the horizontal\ncomponent. Systematic errors caused by the unmodeled ionosphere path delay may\nreach 1.3 m for the vertical component. \n\n"}
{"id": "1012.4669", "contents": "Title: G-essence with Yukawa Interactions Abstract: We study the g-essence model with Yukawa interactions between a scalar field\n$\\phi$ and a Dirac field $\\psi$. For the homogeneous, isotropic and flat\nFriedmann-Robertson-Walker universe filled with the such g-essence, the exact\nsolution of the model is found. Moreover, we reconstruct the corresponding\nscalar and fermionic potentials which describe the coupled dynamics of the\nscalar and fermionic fields. It is shown that some particular g-essence models\nwith Yukawa interactions correspond to the usual and generalized Chaplygin gas\nunified models of dark energy and dark matter. Also we present some\nscalar-fermionic Dirac-Born-Infeld models corresponding g-essence models with\nYukawa interactions which again describe the unified dark energy-dark matter\nsystem. \n\n"}
{"id": "1101.1026", "contents": "Title: Cosmological structure formation with clustering quintessence Abstract: We study large-scale structure formation in the presence of a quintessence\ncomponent with zero speed of sound in the framework of Eulerian Perturbation\nTheory. Due to the absence of pressure gradients, quintessence and dark matter\nare comoving and can be studied as a unique fluid in terms of the total energy\ndensity contrast and the common velocity. In this description the clustering of\nquintessence enhances the linear term proportional to the velocity divergence\nin the continuity equation by a factor (1+w) Omega_Q / Omega_m. This is\nresponsible for a rapid evolution of the growth rate at low redshifts, and\nmodifies the standard relation between the velocity divergence and the growth\nfactor. For the total fluid, the solutions for the linear growth function and\ngrowth rate can be written in integral forms and admit simple fitting formulae,\nas in the LambdaCDM case. At second order in perturbation theory, we derive an\nexplicit expression for the kernels F_2 and G_2. They receive modifications of\nthe order of the ratio between quintessence and total energy density\nperturbations, which affect the corresponding tree-level bispectra. We finally\ncompute the cumulative signal-to-noise in the power spectrum, bispectrum and\nreduced bispectrum, expected for departures from a LambdaCDM cosmology both in\nthe clustering and smooth quintessence scenarios. The reduced bispectrum, in\nparticular, receives sensible modifications only in the clustering case and can\npotentially be used to detect or rule out the model. \n\n"}
{"id": "1101.1559", "contents": "Title: The Eighth Data Release of the Sloan Digital Sky Survey: First Data from\n  SDSS-III Abstract: The Sloan Digital Sky Survey (SDSS) started a new phase in August 2008, with\nnew instrumentation and new surveys focused on Galactic structure and chemical\nevolution, measurements of the baryon oscillation feature in the clustering of\ngalaxies and the quasar Ly alpha forest, and a radial velocity search for\nplanets around ~8000 stars. This paper describes the first data release of\nSDSS-III (and the eighth counting from the beginning of the SDSS). The release\nincludes five-band imaging of roughly 5200 deg^2 in the Southern Galactic Cap,\nbringing the total footprint of the SDSS imaging to 14,555 deg^2, or over a\nthird of the Celestial Sphere. All the imaging data have been reprocessed with\nan improved sky-subtraction algorithm and a final, self-consistent photometric\nrecalibration and flat-field determination. This release also includes all data\nfrom the second phase of the Sloan Extension for Galactic Understanding and\nEvolution (SEGUE-2), consisting of spectroscopy of approximately 118,000 stars\nat both high and low Galactic latitudes. All the more than half a million\nstellar spectra obtained with the SDSS spectrograph have been reprocessed\nthrough an improved stellar parameters pipeline, which has better determination\nof metallicity for high metallicity stars. \n\n"}
{"id": "1101.2254", "contents": "Title: Fitting Galaxies on GPUs Abstract: Structural parameters are normally extracted from observed galaxies by\nfitting analytic light profiles to the observations. Obtaining accurate fits to\nhigh-resolution images is a computationally expensive task, requiring many\nmodel evaluations and convolutions with the imaging point spread function.\nWhile these algorithms contain high degrees of parallelism, current\nimplementations do not exploit this property. With evergrowing volumes of\nobservational data, an inability to make use of advances in computing power can\nact as a constraint on scientific outcomes. This is the motivation behind our\nwork, which aims to implement the model-fitting procedure on a graphics\nprocessing unit (GPU). We begin by analysing the algorithms involved in model\nevaluation with respect to their suitability for modern many-core computing\narchitectures like GPUs, finding them to be well-placed to take advantage of\nthe high memory bandwidth offered by this hardware. Following our analysis, we\nbriefly describe a preliminary implementation of the model fitting procedure\nusing freely-available GPU libraries. Early results suggest a speed-up of\naround 10x over a CPU implementation. We discuss the opportunities such a\nspeed-up could provide, including the ability to use more computationally\nexpensive but better-performing fitting routines to increase the quality and\nrobustness of fits. \n\n"}
{"id": "1101.3866", "contents": "Title: Study of the electromagnetic background in the XENON100 experiment Abstract: The XENON100 experiment, located at the Laboratori Nazionali del Gran Sasso\n(LNGS), aims to directly detect dark matter in the form of Weakly Interacting\nMassive Particles (WIMPs) via their elastic scattering off xenon nuclei. We\npresent a comprehensive study of the predicted electronic recoil background\ncoming from radioactive decays inside the detector and shield materials, and\nintrinsic contamination. Based on GEANT4 Monte Carlo simulations using a\ndetailed geometry together with the measured radioactivity of all detector\ncomponents, we predict an electronic recoil background in the WIMP-search\nenergy range (0-100 keV) in the 30 kg fiducial mass of less than 10e-2\nevents/(kg-day-keV), consistent with the experiment's design goal. The\npredicted background spectrum is in very good agreement with the data taken\nduring the commissioning of the detector, in Fall 2009. \n\n"}
{"id": "1101.5328", "contents": "Title: Affleck-Dine Baryogenesis, Condensate Fragmentation and Gravitino Dark\n  Matter in Gauge-Mediation with a Large Messenger Mass Abstract: We study the conditions for successful Affleck-Dine baryogenesis and the\norigin of gravitino dark matter in GMSB models. AD baryogenesis in GMSB models\nis ruled out by neutron star stability unless Q-balls are unstable and decay\nbefore nucleosynthesis. Unstable Q-balls can form if the messenger mass scale\nis larger than the flat-direction field Phi when the condensate fragments. We\nprovide an example based on AD baryogenesis along a d = 6 flat direction for\nthe case where m_{3/2} \\approx 2 GeV, as predicted by gravitino dark matter\nfrom Q-ball decay. Using a phenomenological GMSB potential which models the Phi\ndependence of the SUSY breaking terms, we numerically solve for the evolution\nof Phi and show that the messenger mass can be sufficiently close to the\nflat-direction field when the condensate fragments. We compute the\ncorresponding reheating temperature and the baryonic charge of the condensate\nfragments and show that the charge is large enough to produce late-decaying\nQ-balls which can be the origin of gravitino dark matter. \n\n"}
{"id": "1101.5401", "contents": "Title: Asymptotically Safe Cosmology Abstract: We study quantum modifications to cosmology in a Friedmann-Robertson-Walker\nuniverse with and without scalar fields by taking the renormalisation group\nrunning of gravitational and matter couplings into account. We exploit the\nBianchi identity to relate the renormalisation group scale with scale factor\nand derive the improved cosmological evolution equations. We find two types of\ncosmological fixed points where the renormalisation group scale either freezes\nin, or continues to evolve with scale factor. We discuss the implications of\neach of these, and classify the different cosmological fixed points with and\nwithout gravity displaying an asymptotically safe renormalisation group fixed\npoint. We state conditions of existence for an inflating ultraviolet\ncosmological fixed point for Einstein gravity coupled to a scalar field. We\nalso discuss other fixed point solutions such as \"scaling\" solutions, or fixed\npoints with equipartition between kinetic and potential energies. \n\n"}
{"id": "1102.0144", "contents": "Title: A High Speed Networked Signal Processing Platform for Multi-element\n  Radio Telescopes Abstract: A new architecture is presented for a Networked Signal Processing System\n(NSPS) suitable for handling the real-time signal processing of multi-element\nradio telescopes. In this system, a multi-element radio telescope is viewed as\nan application of a multi-sensor, data fusion problem which can be decomposed\ninto a general set of computing and network components for which a practical\nand scalable architecture is enabled by current technology. The need for such a\nsystem arose in the context of an ongoing program for reconfiguring the Ooty\nRadio Telescope (ORT) as a programmable 264-element array, which will enable\nseveral new observing capabilities for large scale surveys on this mature\ntelescope. For this application, it is necessary to manage, route and combine\nlarge volumes of data whose real-time collation requires large I/O bandwidths\nto be sustained. Since these are general requirements of many multi-sensor\nfusion applications, we first describe the basic architecture of the NSPS in\nterms of a Fusion Tree before elaborating on its application for the ORT. The\npaper addresses issues relating to high speed distributed data acquisition,\nField Programmable Gate Array (FPGA) based peer-to-peer networks supporting\nsignificant on-the fly processing while routing, and providing a last mile\ninterface to a typical commodity network like Gigabit Ethernet. The system is\nfundamentally a pair of two co-operative networks, among which one is part of a\ncommodity high performance computer cluster and the other is based on\nCommercial-Off The-Shelf (COTS) technology with support from software/firmware\ncomponents in the public domain. \n\n"}
{"id": "1102.0870", "contents": "Title: A dual-band millimeter-wave kinetic inductance camera for the IRAM\n  30-meter telescope Abstract: Context. The Neel IRAM KIDs Array (NIKA) is a fully-integrated measurement\nsystem based on kinetic inductance detectors (KIDs) currently being developed\nfor millimeter wave astronomy. In a first technical run, NIKA was successfully\ntested in 2009 at the Institute for Millimetric Radio Astronomy (IRAM) 30-meter\ntelescope at Pico Veleta, Spain. This prototype consisted of a 27-42 pixel\ncamera imaging at 150 GHz. Subsequently, an improved system has been developed\nand tested in October 2010 at the Pico Veleta telescope. The instrument\nupgrades included dual-band optics allowing simultaneous imaging at 150 GHz and\n220 GHz, faster sampling electronics enabling synchronous measurement of up to\n112 pixels per measurement band, improved single-pixel sensitivity, and the\nfabrication of a sky simulator to replicate conditions present at the\ntelescope. Results. The new dual-band NIKA was successfully tested in October\n2010, performing in-line with sky simulator predictions. Initially the sources\ntargeted during the 2009 run were re-imaged, verifying the improved system\nperformance. An optical NEP was then calculated to be around 2 \\dot 10-16\nW/Hz1/2. This improvement in comparison with the 2009 run verifies that NIKA is\napproaching the target sensitivity for photon-noise limited ground-based\ndetectors. Taking advantage of the larger arrays and increased sensitivity, a\nnumber of scientifically-relevant faint and extended objects were then imaged\nincluding the Galactic Center SgrB2(FIR1), the radio galaxy Cygnus A and the\nNGC1068 Seyfert galaxy. These targets were all observed simultaneously in the\n150 GHz and 220 GHz atmospheric windows. \n\n"}
{"id": "1102.4633", "contents": "Title: The Atlas3D project -- IV: the molecular gas content of early-type\n  galaxies Abstract: We have carried out a survey for 12CO J=1-0 and J=2-1 emission in the 260\nearly-type galaxies of the volume-limited Atlas3D sample, with the goal of\nconnecting their star formation and assembly histories to their cold gas\ncontent. This is the largest volume-limited CO survey of its kind and is the\nfirst to include many Virgo Cluster members. Sample members are dynamically hot\ngalaxies with a median stellar mass 3\\times 10^{10} Msun; they are selected by\nmorphology rather than colour, and the bulk of them lie on the red sequence.\nThe overall CO detection rate is 56/259 = 0.22 \\error 0.03, with no dependence\non K luminosity and only a modest dependence on dynamical mass. There are a\ndozen CO detections among the Virgo Cluster members; statistical analysis of\ntheir H_2 mass distributions and their dynamical status within the cluster\nshows that the cluster's influence on their molecular masses is subtle at best,\neven though (unlike spirals) they seem to be virialized within the cluster. We\nsuggest that the cluster members have retained their molecular gas through\nseveral Gyr residences in the cluster. There are also a few extremely CO-rich\nearly-type galaxies with H_2 masses >= 10^9 Msun, and these are in low density\nenvironments. We do find a significant trend between molecular content and the\nstellar specific angular momentum. The galaxies of low angular momentum also\nhave low CO detection rates, suggesting that their formation processes were\nmore effective at destroying molecular gas or preventing its re-accretion. We\nspeculate on the implications of these data for the formation of various\nsub-classes of early-type galaxies. \n\n"}
{"id": "1102.5123", "contents": "Title: Scientific Visualization in Astronomy: Towards the Petascale Astronomy\n  Era Abstract: Astronomy is entering a new era of discovery, coincident with the\nestablishment of new facilities for observation and simulation that will\nroutinely generate petabytes of data. While an increasing reliance on automated\ndata analysis is anticipated, a critical role will remain for\nvisualization-based knowledge discovery. We have investigated scientific\nvisualization applications in astronomy through an examination of the\nliterature published during the last two decades. We identify the two most\nactive fields for progress - visualization of large-N particle data and\nspectral data cubes - discuss open areas of research, and introduce a mapping\nbetween astronomical sources of data and data representations used in general\npurpose visualization tools. We discuss contributions using high performance\ncomputing architectures (e.g: distributed processing and GPUs), collaborative\nastronomy visualization, the use of workflow systems to store metadata about\nvisualization parameters, and the use of advanced interaction devices. We\nexamine a number of issues that may be limiting the spread of scientific\nvisualization research in astronomy and identify six grand challenges for\nscientific visualization research in the Petascale Astronomy Era. \n\n"}
{"id": "1102.5123", "contents": "Title: Scientific Visualization in Astronomy: Towards the Petascale Astronomy\n  Era Abstract: Astronomy is entering a new era of discovery, coincident with the\nestablishment of new facilities for observation and simulation that will\nroutinely generate petabytes of data. While an increasing reliance on automated\ndata analysis is anticipated, a critical role will remain for\nvisualization-based knowledge discovery. We have investigated scientific\nvisualization applications in astronomy through an examination of the\nliterature published during the last two decades. We identify the two most\nactive fields for progress - visualization of large-N particle data and\nspectral data cubes - discuss open areas of research, and introduce a mapping\nbetween astronomical sources of data and data representations used in general\npurpose visualization tools. We discuss contributions using high performance\ncomputing architectures (e.g: distributed processing and GPUs), collaborative\nastronomy visualization, the use of workflow systems to store metadata about\nvisualization parameters, and the use of advanced interaction devices. We\nexamine a number of issues that may be limiting the spread of scientific\nvisualization research in astronomy and identify six grand challenges for\nscientific visualization research in the Petascale Astronomy Era. \n\n"}
{"id": "1103.0007", "contents": "Title: Too big to fail? The puzzling darkness of massive Milky Way subhaloes Abstract: We show that dissipationless LCDM simulations predict that the majority of\nthe most massive subhaloes of the Milky Way are too dense to host any of its\nbright satellites (L_V > 10^5 L_sun). These dark subhaloes have circular\nvelocities at infall of 30-70 km/s and infall masses of [0.2-4] x 10^10 M_sun.\nUnless the Milky Way is a statistical anomaly, this implies that galaxy\nformation becomes effectively stochastic at these masses. This is in marked\ncontrast to the well-established monotonic relation between galaxy luminosity\nand halo circular velocity (or halo mass) for more massive haloes. We show that\nat least two (and typically four) of these massive dark subhaloes are expected\nto produce a larger dark matter annihilation flux than Draco. It may be\npossible to circumvent these conclusions if baryonic feedback in dwarf\nsatellites or different dark matter physics can reduce the central densities of\nmassive subhaloes by order unity on a scale of 0.3 - 1 kpc. \n\n"}
{"id": "1103.0694", "contents": "Title: Coupled Quintessence and the Halo Mass Function Abstract: A sufficiently light scalar field slowly evolving in a potential can account\nfor the dark energy that presently dominates the universe. This quintessence\nfield is expected to couple directly to matter components, unless some symmetry\nof a more fundamental theory protects or suppresses it. Such a coupling would\nleave distinctive signatures in the background expansion history of the\nuniverse and on cosmic structure formation, particularly at galaxy cluster\nscales. Using semi--analytic expressions for the CDM halo mass function, we\nmake predictions for halo abundance in models where the quintessence scalar\nfield is coupled to cold dark matter, for a variety of quintessence potentials.\nWe evaluate the linearly extrapolated density contrast at the redshift of\ncollapse using the spherical collapse model and we compare this result to the\ncorresponding prediction obtained from the non--linear perturbation equations\nin the Newtonian limit. For all the models considered in this work, if there is\na continuous flow of energy from the quintessence scalar field to the CDM\ncomponent, then the predicted number of CDM haloes can only lie below that of\n$\\Lambda$CDM, when each model shares the same cosmological parameters today. In\nthe last stage of our analysis we perform a global MCMC fit to data to find the\nbest fit values for the cosmological model parameters. We find that for some\nforms of the quintessence potential, coupled dark energy models can offer a\nviable alternative to $\\Lambda$CDM in light of the recent detections of massive\nhigh--$z$ galaxy clusters, while other models of coupled quintessence predict a\nsmaller number of massive clusters at high redshift compared to $\\Lambda$CDM. \n\n"}
{"id": "1103.2497", "contents": "Title: Line Profiles of Intermediate Redshift Type Ia Supernovae Abstract: We present the temporal evolution of line profiles ranging from near\nultraviolet to optical wavelengths by analyzing 59 Subaru telescope spectra of\nnormal Type Ia Supernovae (SNe Ia) in the intermediate redshift range (0.05 < z\n< 0.4) discovered by the Sloan Digital Sky Survey-II (SDSS-II) Supernova\nSurvey. We derive line velocities, peak wavelengths and pseudo-equivalent\nwidths (pEWs) of these lines. Additionally, we compare the line profiles around\nthe date of maximum brightness with those from their nearby counterparts. We\nfind that line profiles represented by their velocities and pEWs for\nintermediate redshift SNe Ia are consistent with their nearby counterparts\nwithin 2 $\\sigma$. These findings support the picture that SNe Ia are a\n\"standard\" candle for the intermediate redshift range as has been shown between\nSNe Ia at nearby and high redshifts. There is a hint that the \"MgII \\lambda\n4300\" pEW distribution for intermediate redshift SNe Ia is larger than for the\nnearby sample, which could be interpreted as a difference in the progenitor\nabundance. \n\n"}
{"id": "1104.0668", "contents": "Title: Effects of Biases in Virial Mass Estimation on Cosmic Synchronization of\n  Quasar Accretion Abstract: Recent work using virial mass estimates and the quasar mass-luminosity plane\nhas yielded several new puzzles regarding quasar accretion, including a\nsub-Eddington boundary on most quasar accretion, near-independence of the\naccretion rate from properties of the host galaxy, and a cosmic synchronization\nof accretion among black holes of a common mass. We consider how these puzzles\nmight change if virial mass estimation turns out to have a systematic bias. As\nexamples, we consider two recent claims of mass-dependent biases in MgII\nmasses. Under any such correction, the surprising cosmic synchronization of\nquasar accretion rates and independence from the host galaxy remain. The slope\nand location of the sub-Eddington boundary are very sensitive to biases in\nvirial mass estimation, and various mass calibrations appear to favor different\npossible physical explanations for feedback between the central black hole and\nits environment. The alternative mass estimators considered do not simply\nremove puzzling quasar behavior, but rather replace it with new puzzles that\nmay be more difficult to solve than those using current virial mass estimators\nand the Shen et al. (2008) catalog. \n\n"}
{"id": "1104.1578", "contents": "Title: Formation and destruction of jets in X-ray binaries Abstract: Neutron-star and black-hole X-ray binaries (XRBs) exhibit radio jets, whose\nproperties depend on the X-ray spectral state and history of the source. In\nparticular, black-hole XRBs emit compact, steady radio jets when they are in\nthe so-called hard state, the jets become eruptive as the sources move toward\nthe soft state, disappear in the soft state, and re-appear when the sources\nreturn to the hard state. On the other hand, jets from neutron-star X-ray\nbinaries are typically weaker radio emitters than the black-hole ones at the\nsame X-ray luminosity and in some cases radio emission is detected in the soft\nstate. Significant phenomenology has been accumulated so far regarding the\nspectral states of neutron-star and black-hole XRBs, and there is general\nagreement about the type of the accretion disk around the compact object in the\nvarious spectral states. Our aim is to investigate whether the phenomenology\nregarding the X-ray emission on one hand and the jet appearance and\ndisappearance on the other can be put together in a consistent physical\npicture. It has been shown that the so-called Poynting-Robertson Cosmic Battery\n(PRCB) explains in a natural way the formation of magnetic fields in the disks\nof AGN and the ejection of jets. We investigate whether the PRCB can also\nexplain the formation, destruction, and variability of jets in XRBs. We find\nexcellent agreement between the conditions under which the PRCB is efficient\n(i.e., the type of the accretion disk) and the emission or destruction of the\nradio jet. The disk-jet connection in XRBs is explained in a natural way using\nthe PRCB. \n\n"}
{"id": "1104.2700", "contents": "Title: N-body simulation for self-gravitating collisional systems with a new\n  SIMD instruction set extension to the x86 architecture, Advanced Vector\n  eXtensions Abstract: We present a high-performance N-body code for self-gravitating collisional\nsystems accelerated with the aid of a new SIMD instruction set extension of the\nx86 architecture: Advanced Vector eXtensions (AVX), an enhanced version of the\nStreaming SIMD Extensions (SSE). With one processor core of Intel Core i7-2600\nprocessor (8 MB cache and 3.40 GHz) based on Sandy Bridge micro-architecture,\nwe implemented a fourth-order Hermite scheme with individual timestep scheme\n(Makino and Aarseth, 1992), and achieved the performance of 20 giga floating\npoint number operations per second (GFLOPS) for double-precision accuracy,\nwhich is two times and five times higher than that of the previously developed\ncode implemented with the SSE instructions (Nitadori et al., 2006b), and that\nof a code implemented without any explicit use of SIMD instructions with the\nsame processor core, respectively. We have parallelized the code by using\nso-called NINJA scheme (Nitadori et al., 2006a), and achieved 90 GFLOPS for a\nsystem containing more than N = 8192 particles with 8 MPI processes on four\ncores. We expect to achieve about 10 tera FLOPS (TFLOPS) for a self-gravitating\ncollisional system with N 105 on massively parallel systems with at most 800\ncores with Sandy Bridge micro-architecture. This performance will be comparable\nto that of Graphic Processing Unit (GPU) cluster systems, such as the one with\nabout 200 Tesla C1070 GPUs (Spurzem et al., 2010). This paper offers an\nalternative to collisional N-body simulations with GRAPEs and GPUs. \n\n"}
{"id": "1104.3182", "contents": "Title: Dethinning Extensive Air Shower Simulations Abstract: We describe a method for restoring information lost during statistical\nthinning in extensive air shower simulations. By converting weighted particles\nfrom thinned simulations to swarms of particles with similar characteristics,\nwe obtain a result that is essentially identical to the thinned shower, and\nwhich is very similar to non-thinned simulations of showers. We call this\nmethod dethinning. Using non-thinned showers on a large scale is impossible\nbecause of unrealistic CPU time requirements, but with thinned showers that\nhave been dethinned, it is possible to carry out large-scale simulation studies\nof the detector response for ultra-high energy cosmic ray surface arrays. The\ndethinning method is described in detail and comparisons are presented with\nparent thinned showers and with non-thinned showers. \n\n"}
{"id": "1104.3860", "contents": "Title: The stellar velocity dispersion of a compact massive galaxy at z=1.80\n  using X-Shooter: confirmation of the evolution in the mass-size and\n  mass-dispersion relations Abstract: Recent photometric studies have shown that early-type galaxies at fixed\nstellar mass were smaller and denser at earlier times. In this paper we assess\nthat finding by deriving the dynamical mass of such a compact quiescent galaxy\nat z=1.8. We have obtained a high-quality spectrum with full UV-NIR wavelength\ncoverage of galaxy NMBS-C7447 using X-Shooter on the VLT. We determined a\nvelocity dispersion of 294 +- 51 km/s. Given this velocity dispersion and the\neffective radius of 1.64 +- 0.15 kpc (as determined from HST-WFC3 F160W\nobservations) we derive a dynamical mass of 1.7 +- 0.5 x 10^11 Msun. Comparison\nof the full spectrum with stellar population synthesis models indicates that\nNMBS-C774 has a relatively young stellar population (0.40 Gyr) with little or\nno star formation and a stellar mass of ~1.5 x 10^11 Msun. The dynamical and\nphotometric stellar mass are in good agreement. Thus, our study supports the\nconclusion that the mass densities of quiescent galaxies were indeed higher at\nearlier times, and this earlier result is not caused by systematic measurement\nerrors. By combining available spectroscopic measurements at different\nredshifts, we find that the velocity dispersion at fixed dynamical mass was a\nfactor of ~1.8 higher at z=1.8 compared to z=0. Finally, we show that the\napparent discrepancies between the few available velocity dispersion\nmeasurements at z>1.5 are consistent with the intrinsic scatter of the\nmass-size relation. \n\n"}
{"id": "1104.4872", "contents": "Title: Spatial variation of fundamental couplings and Lunar Laser Ranging Abstract: If the fundamental constants of nature have a cosmic spatial variation, there\nwill in general be extra forces with a preferred direction in space which\nviolate the equivalence principle. We show that the millimeter-precision Apache\nPoint Observatory Lunar Laser-ranging Operation provides a very sensitive probe\nof such variation that has the capability of detecting a cosmic gradient of the\nratio between the quark masses and the strong interaction scale at the level\nwith the gradient of ln (m_quark/Lambda_QCD) ~ 2.6 x 10^-6 Glyr^-1, which is\ncomparable to the cosmic gradients suggested by the recently reported\nmeasurements of Webb et al. We also point out the capability of presently\nplanned improved equivalence principle tests, at the Delta g/g < 10^-17 level,\nto probe similar cosmic gradients. \n\n"}
{"id": "1105.1783", "contents": "Title: Vainshtein Mechanism In $\\Lambda_3$ - Theories Abstract: We explore the space of spherically symmetric, static solutions in the\ndecoupling limit of a class of non-linear covariant extensions of Fierz-Pauli\nmassive gravity obtained recently in arXiv:1007.0443. In general, several such\nsolutions with various asymptotic limits exist. We find their approximate short\nand long-distance behaviour and use numerical analysis to match them at the\nVainshtein radius, $r_*$. Our findings indicate, that for a broad range of\nparameters, the theory does possess the Vainshtein mechanism, screening the\nscalar contribution to the gravitational force within $r_*$. In addition, there\nexists a class of solutions in the literature, for which the $1/r$\ngravitational potential is completely screened within the Vainshtein scale.\nHowever, numerical analysis indicates, that for this type of solutions, the\ngravitational potential does not decay at spatial infinity. \n\n"}
{"id": "1105.3683", "contents": "Title: The Padova-Millennium Galaxy and Group Catalogue (PM2GC): the\n  group-finding method and the PM2GC catalogues of group, binary and single\n  field galaxies Abstract: We present the construction and describe the properties of the\nPadova-Millennium Galaxy and Group Catalogue (PM2GC), a galaxy catalogue\nrepresentative of the general field population in the local Universe. We\ncharacterize galaxy environments by identifying galaxy groups at 0.04<=z<=0.1\nwith a Friends-of-Friends (FoF) algorithm using a complete sample of 3210\ngalaxies brighter than MB = -18.7 taken from the Millennium Galaxy Catalogue\n(MGC, Liske et al. (2003)), a 38deg^2 photometric and spectroscopic equatorial\nsurvey. We identified 176 groups with at least three members, comprising in\ntotal 1057 galaxies and representing ~43 per cent of the general field\npopulation in that redshift range. The median redshift and velocity dispersion\nof our groups are 0.0823 and 192 km s^-1, respectively. 88 per cent of the\ngroups have fewer than ten members, and 63 per cent have fewer than five\nmembers. Nongroup galaxies were subdivided into \"inary\" systems of two bright\nclose companions, and \"single\" galaxies with no companion, in order to identify\ndifferent environments useful for future scientific analysis. We performed a\ndetailed comparison with the 2PIGG catalogue to validate the effectiveness of\nour method and the robustness of our results. Galaxy stellar masses are\ncomputed for all PM2GC galaxies, and found to be in good agreement with Sloan\nDigital Survey Data Release 7 (SDSS-DR7) mass estimates. The catalogues of\nPM2GC groups, group properties and galaxy properties in all environments are\npublicly available on theWorld Wide Web. \n\n"}
{"id": "1105.4114", "contents": "Title: The Glashow resonance as a discriminator of UHE cosmic neutrinos\n  originating from p-gamma and p-p collisions Abstract: We re-examine the interesting possibility of utilizing the Glashow resonance\n(GR) channel nu_ebar + e^- to W^- to anything to discriminate between the UHE\ncosmic neutrinos originating from p-gamma and pp collisions in an optically\nthin source of cosmic rays. We propose a general parametrization of the initial\nneutrino flavor composition by allowing the ratios Phi^{p gamma}_{pi^-}/Phi^{p\ngamma}_{pi^+} and Phi^{pp}_{pi^-}/Phi^{pp}_{pi^+} to slightly deviate from\ntheir conventional values. A relationship between the typical source parameter\nkappa = (Phi^{p gamma}_{pi^+} + Phi^{p gamma}_{pi^-})/(Phi^{pp}_{pi^+} +\nPhi^{pp}_{pi^-} + Phi^{p gamma}_{pi^+} + Phi^{p gamma}_{pi^-}) and the working\nobservable of the GR R_0 = Phi^T_{nu_ebar}/ (Phi^T_{nu_mu} + Phi^T_{nu_mu}) at\na neutrino telescope is derived, and the numerical dependence of R_0 on kappa\nis illustrated by taking account of the latest experimental data on three\nneutrino mixing angles. It is shown that a measurement of R_0 is in principle\npossible to identify the pure p-gamma interaction (kappa =1), the pure pp\ninteraction (kappa =0) or a mixture of both of them (0 < kappa < 1) at a given\nsource of UHE cosmic neutrinos. The event rate of the GR signal against the\nbackground is also estimated. \n\n"}
{"id": "1105.6085", "contents": "Title: Detecting Chameleon Dark Energy via Electrostatic Analogy Abstract: The late-time accelerated expansion of the universe could be caused by a\nscalar field that is screened on small scales, as in chameleon or symmetron\nscenarios. We present an analogy between thin shell configurations of such\nscalar fields and electrostatics, which allows calculation of the field profile\nfor general extended bodies. Interestingly, the field demonstrates a `lightning\nrod' effect, where it becomes enhanced near the ends of a pointy or elongated\nobject. Drawing from this correspondence, we show that non-spherical test\nbodies immersed in a background field will experience a net torque caused by\nthe scalar field. This effect, with no counterpart in the gravitational case,\ncan be potentially tested in future experiments. \n\n"}
{"id": "1106.0700", "contents": "Title: Spectral scaling laws in MHD turbulence simulations and in the solar\n  wind Abstract: The question is addressed to what extent incompressible magnetohydrodynamics\n(MHD) can describe random magnetic and velocity fluctuations measured in the\nsolar wind. It is demonstrated that distributions of spectral indices for the\nvelocity, magnetic field, and total energy obtained from high resolution\nnumerical simulations are qualitatively and quantitatively similar to solar\nwind observations at 1 AU. Both simulations and observations show that in the\ninertial range the magnetic field spectrum E_b is steeper than the velocity\nspectrum E_v with E_b >~ E_v and that the residual energy E_R = E_b-E_v\ndecreases nearly following a k_perp^-2 scaling. \n\n"}
{"id": "1106.0760", "contents": "Title: Simulating the Electroweak Phase Transition: Sonification of Bubble\n  Nucleation Abstract: As an applicaton of sonification, a simulation of the early universe was\ndeveloped to portray a phase transition that occurred shortly after the Big\nBang. The Standard Model of particle physics postulates that a hypothetical\nparticle, the Higgs boson, is responsible for the breaking of the symmetry\nbetween the electromagnetic force and the weak force. This phase transition may\nhave been responsible for triggering Baryogenesis, the generation of an\nabundance of matter over anti-matter. This hypothesis is known as Electroweak\nBaryogenesis. In this simulation, aspects of bubble nucleation in Standard\nModel Electroweak Baryogenesis were examined and modeled using Mathematica, and\nsonified using SuperCollider3. The resulting simulation, which has been used\nfor pedagogical purposes by one of the authors, suggests interesting\npossibilities for the integration of science and aesthetics as well as auditory\nperception. The sonification component in particular also had the unexpected\nbenefit of being useful in debugging the Mathematica code. \n\n"}
{"id": "1106.1454", "contents": "Title: Latest results of the EDELWEISS-II experiment Abstract: The EDELWEISS-II collaboration has performed a direct search for WIMP dark\nmatter with an array of ten 400-g heat-and-ionization cryogenic detectors\nequipped with Inter-Digit electrodes for the rejection of near-surface events.\nResults from one year of continuous operation at the Laboratoire Souterrain de\nModane will be presented. A sensitivity to the spin-independent WIMP-nucleon\nelastic cross-section of 4.4x10^{-8} pb was achieved using a 384 kgd effective\nexposure. We also interpret the results in the inelastic scattering scenario,\nexcluding the DAMA allowed region for WIMP masses greater than 90 GeV for a\nmass splitting of 120 keV. The results obtained demonstrate the excellent\nbackground rejection capabilities of these simple and robust detectors in an\nactual WIMP search experiment. Some first results with 800-g detectors will be\nalso presented together with the prospects for this experiment and the\nton-scale EURECA project. \n\n"}
{"id": "1106.1937", "contents": "Title: Novel technique for supernova detection with IceCube Abstract: The current supernova detection technique used in IceCube relies on the\nsudden deviation of the summed photomultiplier noise rate from its nominal\nvalue during the neutrino burst, making IceCube a $\\approx 3$ Megaton effective\ndetection volume - class supernova detector. While galactic supernovae can be\nresolved with this technique, the supernova neutrino emission spectrum remains\nunconstrained and thus presents a limited potential for the topics related to\nsupernova core collapse models.\n  The paper elaborates analytically on the capabilities of IceCube to detect\nsupernovae through the analysis of hits in the detector correlated in space and\ntime. These arise from supernova neutrinos interacting in the instrumented\ndetector volume along single strings. Although the effective detection volume\nfor such coincidental hits is much smaller ($\\gtrsim 35\\,$kton, about the scale\nof SuperK), a wealth of information is obtained due to the comparatively low\ncoincidental noise rate. We demonstrate that a neutrino flux from a core\ncollapse supernova will produce a signature enabling the resolution of rough\nspectral features and, in the case of a strong signal, providing indication on\nits location.\n  We further discuss the enhanced potential of a rather modest detector\nextension, a denser array in the center of IceCube, within our one dimensional\nanalytic calculation framework. Such an extension would enable the exploration\nof the neutrino sky above a few GeV and the detection of supernovae up to a few\n100's of kilo parsec. However, a $3-4\\,$Mpc detection distance, necessary for\nroutine supernova detection, demands a significant increase of the effective\ndetection volume and can be obtained only with a more ambitious instrument,\nparticularly the boosting of sensor parameters such as the quantum efficiency\nand light collection area. \n\n"}
{"id": "1106.2020", "contents": "Title: SCORPIO at the 6-m telescope: current state and perspectivies for\n  spectroscopy of galactic and extragalactic objects Abstract: A significant part of observations by Russian 6-m telescope is carried out\nusing SCORPIO multi-mode focal reducer. A lot of scientific data have been\ncollected using observations in direct imaging, slit spectroscopy and\nFabry-Perot interferometry modes during the past ten years. Some results of\nthese observations are considered in this review. We are also present a short\ndescription of a new generation instrument named SCORPIO-2. \n\n"}
{"id": "1106.2262", "contents": "Title: An equation of state for dark matter Abstract: Dark matter, believed to be present in many galaxies, is interpreted as a\nhydrodynamical system in interaction with the gravitational field and nothing\nelse. An equation of state determines the mass distribution and the associated\ngravitational field. Conversely, the gravitational field can be inferred from\nobservation of orbital velocities of stars in the Milky Way, in a first\napproximation in which the field is mainly due to the distribution of dark\nmatter. In this approximation, the equation of state is determined by the\ngravitational field via the equations of motion.\n  The resulting equation of state is a simple expression that accounts for the\nmain features of the galactic rotation curve over 6 orders of magnitude. \n\n"}
{"id": "1106.2767", "contents": "Title: Comparison of LISA and Atom Interferometry for Gravitational Wave\n  Astronomy in Space Abstract: One of the atom interferometer gravitational wave missions proposed by\nDimopoulos et al.1 in 2008 was called AGIS-Sat. 2. It had a suggested\ngravitational wave sensitivity set by the atom state detection shot noise level\nthat started at 1 mHz, was comparable to LISA sensitivity from 1 to about 20\nmHz, and had better sensitivity from 20 to 500 mHz. The separation between the\nspacecraft was 1,000 km, with atom interferometers 200 m long and shades from\nsunlight used at each end. A careful analysis of many error sources was\nincluded, but requirements on the time-stability of both the laser wavefront\naberrations and the atom temperatures in the atom clouds were not investigated.\nAfter including these considerations, the laser wavefront aberration stability\nrequirement to meet the quoted sensitivity level is about 1\\times10-8\nwavelengths, and is far tighter than for LISA. Also, the temperature\nfluctuations between atom clouds have to be less than 1 pK. An alternate atom\ninterferometer GW mission in Earth orbit called AGIS-LEO with 30 km satellite\nseparation has been suggested recently. The reduction of wavefront aberration\nnoise by sending the laser beam through a high-finesse mode-scrubbing optical\ncavity is discussed briefly, but the requirements on such a cavity are not\ngiven. Unfortunately, such an Earth-orbiting mission seems to be considerably\nmore difficult to design than a non-geocentric mission and does not appear to\nhave comparably attractive scientific goals. \n\n"}
{"id": "1106.4237", "contents": "Title: A deconvolution map-making method for experiments with circular scanning\n  strategies Abstract: Aims. To investigate the performance of a deconvolution map-making algorithm\nfor an experiment with a circular scanning strategy, specifically in this case\nfor the analysis of Planck data, and to quantify the effects of making maps\nusing simplified approximations to the true beams. Methods. We present an\nimplementation of a map-making algorithm which allows the combined treatment of\ntemperature and polarisation data, and removal of instrumental effects, such as\ndetector time constants and finite sampling intervals, as well as the\ndeconvolution of arbitrarily complex beams from the maps. This method may be\napplied to any experiment with a circular scanning-strategy. Results.\nLow-resolution experiments were used to demonstrate the ability of this method\nto remove the effects of arbitrary beams from the maps and to demonstrate the\neffects on the maps of ignoring beam asymmetries. Additionally, results are\npresented of an analysis of a realistic full-scale simulated data-set for the\nPlanck LFI 30 GHz channel. Conclusions. Our method successfully removes the\neffects of the beams from the maps, and although it is computationally\nexpensive, the analysis of the Planck LFI data should be feasible with this\napproach. \n\n"}
{"id": "1106.5644", "contents": "Title: The ADS in the Information Age - Impact on Discovery Abstract: The SAO/NASA Astrophysics Data System (ADS) grew up with and has been riding\nthe waves of the Information Age, closely monitoring and anticipating the needs\nof its end-users. By now, all professional astronomers are using the ADS on a\ndaily basis, and a substantial fraction have been using it for their entire\nprofessional career. In addition to being an indispensable tool for\nprofessional scientists, the ADS also moved into the public domain, as a tool\nfor science education. In this paper we will highlight and discuss some aspects\nindicative of the impact the ADS has had on research and the access to\nscholarly publications.\n  The ADS is funded by NASA Grant NNX09AB39G \n\n"}
{"id": "1107.0186", "contents": "Title: The SKA and \"High-Resolution\" Science Abstract: \"High-resolution\", or \"long-baseline\", science with the SKA and its\nprecursors covers a broad range of topics in astrophysics. In several research\nareas, the coupling between improved brightness sensitivity of the SKA and a\nsub-arcsecond resolution would uncover truly unique avenues and opportunities\nfor studying extreme states of matter, vicinity of compact relativistic\nobjects, and complex processes in astrophysical plasmas. At the same time, long\nbaselines would secure excellent positional and astrometric measurements with\nthe SKA and critically enhance SKA image fidelity at all scales. The latter\naspect may also have a substantial impact on the survey speed of the SKA, thus\naffecting several key science projects of the instrument. \n\n"}
{"id": "1107.1185", "contents": "Title: Dust around R Coronae Borealis stars: I. Spitzer/IRS observations Abstract: Spitzer/IRS spectra from 5 to 37 um for a complete sample of 31 R Coronae\nBorealis stars (RCBs) are presented. These spectra are combined with optical\nand near-infrared photometry of each RCB at maximum light to compile a spectral\nenergy distribution (SED). The SEDs are fitted with blackbody flux\ndistributions and estimates made of the ratio of the infrared flux from\ncircumstellar dust to the flux emitted by the star. Comparisons for 29 of the\n31 stars are made with the IRAS fluxes from three decades earlier: Spitzer and\nIRAS fluxes at 12 um and 25 um are essentially equal for all but a minority of\nthe sample. For this minority, the IRAS to Spitzer flux ratio exceeds a factor\nof three. The outliers are suggested to be stars where formation of a dust\ncloud or dust puff is a rare event. A single puff ejected prior to the IRAS\nobservations may have been reobserved by Spitzer as a cooler puff at a greater\ndistance from the RCB. RCBs which experience more frequent optical declines\nhave, in general, a circumstellar environment containing puffs subtending a\nlarger solid angle at the star and a quasi-constant infrared flux. Yet, the\nestimated subtended solid angles and the blackbody temperatures of the dust\nshow a systematic evolution to lower solid angles and cooler temperatures in\nthe interval between IRAS and Spitzer. Dust emission by these RCBs and those in\nthe LMC is similar in terms of total 24 um luminosity and [8.0]-[24.0] color\nindex. \n\n"}
{"id": "1107.1728", "contents": "Title: Systematic Bias in 2MASS Galaxy Photometry Abstract: We report the discovery of a serious bias in galaxy photometry reported in\nthe 2MASS Extended Source Catalog (Jarrett et al. 2000). Due to an undetermined\nflaw in the 2MASS surface photometry routines, isophotal and total magnitudes\ncalculated by their methods underestimate the luminosity of galaxies from 10%\nto 40%. This is found to be due to incorrectly determined scalelengths and\nisophotal radii, which are used to define the aperture sizes for Kron and total\nfluxes. While 2MASS metric aperture luminosities are correct (and, thus, colors\nbased on those apertures), comparison to other filters (e.g. optical) based on\ntotal magnitudes will produce erroneous results. We use our own galaxy\nphotometry package (ARCHANGEL) to determine correct total magnitudes and colors\nusing the same 2MASS images, but with a more refined surface brightness\nreduction scheme. Our resulting colors, and color-magnitude relation, are more\nin line with model expectations and previous pointed observations. \n\n"}
{"id": "1107.2155", "contents": "Title: The XENON100 Dark Matter Experiment Abstract: The XENON100 dark matter experiment uses liquid xenon (LXe) in a time\nprojection chamber (TPC) to search for Xe nuclear recoils resulting from the\nscattering of dark matter Weakly Interacting Massive Particles (WIMPs). In this\npaper we present a detailed description of the detector design and present\nperformance results, as established during the commissioning phase and during\nthe first science runs.\n  The active target of XENON100 contains 62 kg of LXe, surrounded by an LXe\nveto of 99 kg, both instrumented with photomultiplier tubes (PMTs) operating\ninside the liquid or in Xe gas. The LXe target and veto are contained in a\nlow-radioactivity stainless steel vessel, embedded in a passive radiation\nshield. The experiment is installed underground at the Laboratori Nazionali del\nGran Sasso (LNGS), Italy and has recently published results from a 100\nlive-days dark matter search. The ultimate design goal of XENON100 is to\nachieve a spin-independent WIMP-nucleon scattering cross section sensitivity of\n\\sigma = 2x10^-45 cm^2 for a 100 GeV/c^2 WIMP. \n\n"}
{"id": "1107.2642", "contents": "Title: Inflation and primordial non-Gaussianities of \"generalized Galileons\" Abstract: We set up cosmological perturbation theory and study the cosmological\nimplications of the so-called ``generalized Galileon'' developed in\n\\cite{Deffayet:2011gz,horndeski}. This is the most general scalar field theory\nwhose Lagrangian contains derivatives up to second order while keeping second\norder equations of motion, and contains as sub-cases $k$-inflation,\n$G$-inflation and many other models. We calculate the power spectrum of the\nprimordial curvature perturbation, finding a modification of the usual\nconsistency relation of the tensor-to-scalar ratio in $k$-inflation or perfect\nfluid models. Finally we also calculate the bispectrum, which contains no new\nshapes beyond those of $k$-inflation. \n\n"}
{"id": "1107.2931", "contents": "Title: Oxford SWIFT IFS and multi-wavelength observations of the Eagle galaxy\n  at z=0.77 Abstract: The `Eagle' galaxy at a redshift of 0.77 is studied with the Oxford Short\nWavelength Integral Field Spectrograph (SWIFT) and multi-wavelength data from\nthe All-wavelength Extended Groth strip International Survey (AEGIS). It was\nchosen from AEGIS because of the bright and extended emission in its slit\nspectrum. Three dimensional kinematic maps of the Eagle reveal a gradient in\nvelocity dispersion which spans 35-75 +/- 10 km/s and a rotation velocity of 25\n+/- 5 km/s uncorrected for inclination. Hubble Space Telescope images suggest\nit is close to face-on. In comparison with galaxies from AEGIS at similar\nredshifts, the Eagle is extremely bright and blue in the rest-frame optical,\nhighly star-forming, dominated by unobscured star-formation, and has a low\nmetallicity for its size. This is consistent with its selection. The Eagle is\nlikely undergoing a major merger and is caught in the early stage of a\nstar-burst when it has not yet experienced metal enrichment or formed the mass\nof dust typically found in star-forming galaxies. \n\n"}
{"id": "1107.4103", "contents": "Title: Black Hole Mass and Bulge Luminosity for Low-mass Black Holes Abstract: We study the scaling between bulge magnitude and central black hole (BH) mass\nin galaxies with virial BH masses < 10^6 solar mass. Based on careful image\ndecomposition of a snapshot Hubble Space Telescope I-band survey, we found that\nthese BHs are found predominantly in galaxies with pseudobulges. Here we show\nthat the \\mbulge\\ relation for the pseudobulges at low mass is significantly\ndifferent from classical bulges with BH masses >10^7 solar mass. Specfically,\nbulges span a much wider range of bulge luminosity, and on average the\nluminosity is larger, at fixed black hole mass. The trend holds both for the\nactive galaxies from Bentz et al. and the inactive sample of Gultekin et al.\nand cannot be explained by differences in stellar populations, as it persists\nwhen we use dynamical bulge masses. Put another way, the ratio between bulge\nand BH mass is much larger than $\\sim 1000$ for our sample. This is consistent\nwith recent suggestions that black hole mass does not scale with the\npseudobulge luminosity. The low-mass scaling relations appear to flatten,\nconsistent with predictions from Volonteri & Natarajan for massive seed BHs. \n\n"}
{"id": "1107.4772", "contents": "Title: Can 21-cm observations discriminate between high-mass and low-mass\n  galaxies as reionization sources? Abstract: The prospect of detecting the first galaxies by observing their impact on the\nintergalactic medium as they reionized it during the first billion years leads\nus to ask whether such indirect observations are capable of diagnosing which\ntypes of galaxies were most responsible for reionization. We attempt to answer\nthis by considering a set of large-scale radiative transfer simulations of\nreionization in sufficiently large volumes to make statistically meaningful\npredictions of observable signatures, while also directly resolving all\natomically-cooling halos down to 10^8 M_solar. We focus here on predictions of\nthe 21-cm background, to see if upcoming observations are capable of\ndistinguishing a universe ionized primarily by high-mass halos from one in\nwhich both high-mass and low-mass halos are responsible, and to see how these\nresults depend upon the uncertain source efficiencies. We find that 21-cm\nfluctuation power spectra observed by the first generation EoR/21-cm radio\ninterferometer arrays should be able to distinguish the case of reionization by\nhigh-mass halos alone from that by both high- and low-mass halos, together.\nSome reionization scenarios yield very similar power spectra and rms evolution\nand thus can only be discriminated by their different mean reionization history\nand 21-cm PDF distributions. We find that the skewness of the 21-cm PDF\ndistribution smoothed over LOFAR-like window shows a clear feature correlated\nwith the rise of the rms due to patchiness. Measurements of the mean\nphotoionization rates are sensitive to the average density of the regions being\nstudied and therefore could be strongly skewed in certain cases. (abridged) \n\n"}
{"id": "1107.5719", "contents": "Title: A 3D radiative transfer framework: XIII. OpenCL implementation Abstract: We discuss an implementation of our 3D radiative transfer (3DRT) framework\nwith the OpenCL paradigm for general GPU computing. We implement the kernel for\nsolving the 3DRT problem in Cartesian coordinates with periodic boundary\nconditions in the horizontal $(x,y)$ plane, including the construction of the\nnearest neighbor $\\Lstar$ and the operator splitting step. We present the\nresults of a small and a large test case and compare the timing of the 3DRT\ncalculations for serial CPUs and various GPUs. The latest available GPUs can\nlead to significant speedups for both small and large grids compared to serial\n(single core) computations. \n\n"}
{"id": "1108.0426", "contents": "Title: An Analytic Model for the Evolution of the Stellar, Gas, and Metal\n  Content of Galaxies Abstract: We present an analytic formalism that describes the evolution of the stellar,\ngas, and metal content of galaxies. It is based on the idea, inspired by\nhydrodynamic simulations, that galaxies live in a slowly-evolving equilibrium\nbetween inflow, outflow, and star formation. We argue that this formalism\nbroadly captures the behavior of galaxy properties evolving in simulations. The\nresulting equilibrium equations for the star formation rate, gas fraction, and\nmetallicity depend on three key free parameters that represent ejective\nfeedback, preventive feedback, and re-accretion of ejected material. We\nschematically describe how these parameters are constrained by models and\nobservations. Galaxies perturbed off the equilibrium relations owing to inflow\nstochasticity tend to be driven back towards equilibrium, such that deviations\nin star formation rate at a given mass are correlated with gas fraction and\nanti-correlated with metallicity. After an early gas accumulation epoch,\nquiescently star-forming galaxies are expected to be in equilibrium over most\nof cosmic time. The equilibrium model provides a simple intuitive framework for\nunderstanding the cosmic evolution of galaxy properties, and centrally features\nthe cycle of baryons between galaxies and surrounding gas as the driver of\ngalaxy growth. \n\n"}
{"id": "1108.1803", "contents": "Title: Detectability of Exoplanet Periastron Passage in the Infra-Red Abstract: Characterization of exoplanets has matured in recent years, particularly\nthrough studies of exoplanetary atmospheres of transiting planets at infra-red\nwavelenegths. The primary source for such observations has been the Spitzer\nSpace Telescope but these studies are anticipated to continue with the James\nWebb Space Telescope (JWST). A relatively unexplored region of exoplanet\nparameter space is the thermal detection of long-period eccentric planets\nduring periastron passage. Here we describe the thermal properties and albedos\nof long-period giant planets along with the eccentricities of those orbits\nwhich allow them to remain within the habitable zone. We further apply these\nresults to the known exoplanets by calculating temperatures and flux ratios for\nthe IRAC passbands occupied by warm Spitzer, considering both low and high\nthermal redistribution efficiencies from the perspective of an observer. We\nconclude with recommendations on which targets are best suited for follow-up\nobservations. \n\n"}
{"id": "1108.3134", "contents": "Title: Status of the UC-Berkeley SETI Efforts Abstract: We summarize radio and optical SETI programs based at the University of\nCalifornia, Berkeley. The SEVENDIP optical pulse search looks for ns time scale\npulses at visible wavelengths using an automated 30 inch telescope. The ongoing\nSERENDIP V.v sky survey searches for radio signals at the 300 meter Arecibo\nObservatory. The currently installed configuration supports 128 million\nchannels over a 200 MHz bandwidth with ~1.6 Hz spectral resolution. SETI@home\nuses the desktop computers of volunteers to analyze over 160 TB of data at\ntaken at Arecibo looking for two types of continuous wave signals and two types\nof pulsed signals. A version to be released this summer adds autocorrelation\nanalysis to look for complex wave forms that have been repeated (and overlayed)\nafter a short delay. SETI@home will soon be processing data of Kepler exoplanet\nsystems collected at the GBT. The Astropulse project is the first SETI search\nfor $\\mu$s time scale dispersed pulses in the radio spectrum. We recently\nreobserved 114 sky locations where microsecond pulses were detected. This data\nis in process of being transferred to Berkeley for analysis. \n\n"}
{"id": "1108.3717", "contents": "Title: Halo Shapes From Weak Lensing: The Impact of Galaxy--Halo Misalignment Abstract: We analyse the impact of galaxy--halo misalignment on the ability of weak\nlensing studies to constrain the shape of dark matter haloes, using a\ncombination of the Millennium dark matter N-body simulation and different\nsemi-analytic galaxy formation models, as well as simpler Monte Carlo tests.\nSince the distribution of galaxy--halo alignments is not known in detail, we\ntest various alignment models, together with different methods of determining\nthe halo shape. In addition to alignment, we examine the interplay of halo mass\nand shape, and galaxy colour and morphology with the resulting stacked\nprojected halo shape. We find that only in the case where significant numbers\nof galaxy and halo minor axes are parallel does the stacked, projected halo\naxis ratio fall below 0.95. When using broader misalignment distributions, such\nas those found in recent simulations of galaxy formation, the halo ellipticity\nsignal is washed out and would be extremely difficult to measure\nobservationally. It is important to note that the spread in stacked halo axis\nratio due to theoretical unknowns (differences between semi-analytic models,\nand between alignment models) are much bigger than any statistical uncertainty:\nIt is naive to assume that, simply because LCDM predicts aspherical haloes, the\nstacked projected shape will be elliptical. In fact, there is no robust LCDM\nprediction yet for this procedure, and the interpretation of any such\nelliptical halo signal from lensing in terms of physical halo properties will\nbe extremely difficult. \n\n"}
{"id": "1108.5995", "contents": "Title: PNe as observational constraints in chemical evolution models for NGC\n  6822 Abstract: Chemical evolution models are useful for understanding the formation and\nevolution of stars and galaxies. Model predictions will be more robust as more\nobservational constraints are used. We present chemical evolution models for\nthe dwarf irregular galaxy NGC 6822 using chemical abundances of old and young\nPlanetary Nebulae (PNe) and \\ion{H}{ii} regions as observational constraints.\nTwo sets of chemical abundances, one derived from collisionally excited lines\n(CELs) and one, from recombination lines (RLs), are used. We try to use our\nmodels as a tool to discriminate between both procedures for abundance\ndeterminations. In our chemical evolution code, the chemical contribution of\nlow and intermediate mass stars is time delayed, while for the massive stars\nthe chemical contribution follows the instantaneous recycling approximation.\nOur models have two main free parameters: the mass-loss rate of a well-mixed\noutflow and the upper mass limit, $M_{up}$, of the initial mass function (IMF).\nTo reproduce the gaseous mass and the present-day O/H value we need to vary the\noutflow rate and the $M_{up}$ value. \n\n"}
{"id": "1109.0735", "contents": "Title: Daily Modulation of the Dark Matter Signal in Crystalline Detectors Abstract: The channeling effect in crystals refers to the orientation dependence of\ncharged ion penetration in crystals. In direct dark matter crystalline\ndetectors, a channeled ion recoiling after a collision with a WIMP gives all\nits energy to electrons. Thus channeling increases the ionization or\nscintillation signal expected from a WIMP. Channeling is a directional effect\nwhich depends on the velocity distribution of WIMPs in the dark halo of our\nGalaxy and could lead to a daily modulation of the signal. I will present\nestimates of the expected amplitude of the daily modulation in direct dark\nmatter detectors, both due to channeling and just due to the rotational\nvelocity of the Earth around itself. \n\n"}
{"id": "1109.1611", "contents": "Title: Discovery and Atmospheric Characterization of Giant Planet Kepler-12b:\n  An Inflated Radius Outlier Abstract: We report the discovery of planet Kepler-12b (KOI-20), which at 1.695\\pm0.030\nRJ is among the handful of planets with super-inflated radii above 1.65 RJ.\nOrbiting its slightly evolved G0 host with a 4.438-day period, this\n0.431\\pm0.041 MJ planet is the least-irradiated within this\nlargest-planet-radius group, which has important implications for planetary\nphysics. The planet's inflated radius and low mass lead to a very low density\nof 0.111\\pm0.010 g cm-3. We detect the occultation of the planet at a\nsignificance of 3.7{\\sigma} in the Kepler bandpass. This yields a geometric\nalbedo of 0.14\\pm0.04; the planetary flux is due to a combination of scattered\nlight and emitted thermal flux. We use multiple observations with Warm Spitzer\nto detect the occultation at 7{\\sigma} and 4{\\sigma} in the 3.6 and 4.5 {\\mu}m\nbandpasses, respectively. The occultation photometry timing is consistent with\na circular orbit, at e < 0.01 (1{\\sigma}), and e < 0.09 (3{\\sigma}). The\noccultation detections across the three bands favor an atmospheric model with\nno dayside temperature inversion. The Kepler occultation detection provides\nsignificant leverage, but conclusions regarding temperature structure are\npreliminary, given our ignorance of opacity sources at optical wavelengths in\nhot Jupiter atmospheres. If Kepler-12b and HD 209458b, which intercept similar\nincident stellar fluxes, have the same heavy element masses, the interior\nenergy source needed to explain the large radius of Kepler-12b is three times\nlarger than that of HD 209458b. This may suggest that more than one\nradius-inflation mechanism is at work for Kepler-12b, or that it is less\nheavy-element rich than other transiting planets. \n\n"}
{"id": "1109.2529", "contents": "Title: On the \"The Kolmogorov-Smirnov test for the CMB\" by M.Frommert, R.Durrer\n  and J.Michaud Abstract: In arxiv:1108.5354 the Kolmogorov-Smirnov (K-S) test and Kolmogorov\nstochasticity parameter (KSP) is applied to CMB data. Their interpretation of\nthe KSP method, however, lacks essential elements. In addition, their main\nresult on the Gaussianity of CMB was not a matter of debate in previous KSP-CMB\nstudies which also included predictions on cold spots, point sources. \n\n"}
{"id": "1109.5844", "contents": "Title: Correlation between Fermi/LAT gamma-ray and 37 GHz radio properties of\n  northern AGN averaged over 11 months Abstract: Although the Fermi mission has increased our knowledge of gamma-ray AGN, many\nquestions remain, such as the site of gamma-ray production, the emission\nmechanism, and the factors that govern the strength of the emission. Using data\nfrom a high radio band, 37 GHz, uncontaminated by other radiation components\nbesides the jet emission, we study these questions with averaged flux densities\nover the the first year of Fermi operations. We look for possible correlations\nbetween the 100 MeV - 100 GeV band used by the Fermi satellite and 37 GHz radio\nband observed at the Aalto University Metsahovi Radio Telescope, as well as for\ndifferences between the gamma-ray emission of different AGN subsamples. We use\ndata averaged over the 1FGL period. Our sample includes 249 northern AGN,\nincluding a complete sample of 68 northern AGN with a measured average flux\ndensity exceeding 1 Jy. We find significant correlation between both the flux\ndensities and luminosities in gamma and radio bands. The Fermi luminosity is\ninversely correlated with the peak frequency of the synchrotron component of\nthe AGN spectral energy distributions. We also calculate the gamma dominances,\ndefined as the ratio between the gamma and radio flux densities, and find an\nindication that high-energy blazars are more gamma-dominated than low-energy\nblazars. After studying the distributions of gamma and radio luminosities, it\nis clear that BL Lacertae objects are different from quasars, with\nsignificantly lower luminosities. It is unclear whether this is an intrinsic\ndifference, an effect of variable relativistic boosting across the synchrotron\npeak frequency range, or the result of Fermi being more sensitive to hard\nspectrum sources like BL Lacertae objects. Our results suggest that the gamma\nradiation is produced co-spatially with the 37 GHz emission, i.e., in the jet. \n\n"}
{"id": "1109.6096", "contents": "Title: The Design and Performance of IceCube DeepCore Abstract: The IceCube neutrino observatory in operation at the South Pole, Antarctica,\ncomprises three distinct components: a large buried array for ultrahigh energy\nneutrino detection, a surface air shower array, and a new buried component\ncalled DeepCore. DeepCore was designed to lower the IceCube neutrino energy\nthreshold by over an order of magnitude, to energies as low as about 10 GeV.\nDeepCore is situated primarily 2100 m below the surface of the icecap at the\nSouth Pole, at the bottom center of the existing IceCube array, and began\ntaking physics data in May 2010. Its location takes advantage of the\nexceptionally clear ice at those depths and allows it to use the surrounding\nIceCube detector as a highly efficient active veto against the principal\nbackground of downward-going muons produced in cosmic-ray air showers. DeepCore\nhas a module density roughly five times higher than that of the standard\nIceCube array, and uses photomultiplier tubes with a new photocathode featuring\na quantum efficiency about 35% higher than standard IceCube PMTs. Taken\ntogether, these features of DeepCore will increase IceCube's sensitivity to\nneutrinos from WIMP dark matter annihilations, atmospheric neutrino\noscillations, galactic supernova neutrinos, and point sources of neutrinos in\nthe northern and southern skies. In this paper we describe the design and\ninitial performance of DeepCore. \n\n"}
{"id": "1110.0103", "contents": "Title: After LUX: The LZ Program Abstract: The LZ program consists of two stages of direct dark matter searches using\nliquid Xe detectors. The first stage will be a 1.5-3 tonne detector, while the\nlast stage will be a 20 tonne detector. Both devices will benefit tremendously\nfrom research and development performed for the LUX experiment, a 350 kg liquid\nXe dark matter detector currently operating at the Sanford Underground\nLaboratory. In particular, the technology used for cryogenics and electrical\nfeedthroughs, circulation and purification, low-background materials and\nshielding techniques, electronics, calibrations, and automated control and\nrecovery systems are all directly scalable from LUX to the LZ detectors.\nExtensive searches for potential background sources have been performed, with\nan emphasis on previously undiscovered background sources that may have a\nsignificant impact on tonne-scale detectors. The LZ detectors will probe\nspin-independent interaction cross sections as low as 5E-49 cm2 for 100 GeV\nWIMPs, which represents the ultimate limit for dark matter detection with\nliquid xenon technology. \n\n"}
{"id": "1110.2997", "contents": "Title: BAMBI: blind accelerated multimodal Bayesian inference Abstract: In this paper we present an algorithm for rapid Bayesian analysis that\ncombines the benefits of nested sampling and artificial neural networks. The\nblind accelerated multimodal Bayesian inference (BAMBI) algorithm implements\nthe MultiNest package for nested sampling as well as the training of an\nartificial neural network (NN) to learn the likelihood function. In the case of\ncomputationally expensive likelihoods, this allows the substitution of a much\nmore rapid approximation in order to increase significantly the speed of the\nanalysis. We begin by demonstrating, with a few toy examples, the ability of a\nNN to learn complicated likelihood surfaces. BAMBI's ability to decrease\nrunning time for Bayesian inference is then demonstrated in the context of\nestimating cosmological parameters from Wilkinson Microwave Anisotropy Probe\nand other observations. We show that valuable speed increases are achieved in\naddition to obtaining NNs trained on the likelihood functions for the different\nmodel and data combinations. These NNs can then be used for an even faster\nfollow-up analysis using the same likelihood and different priors. This is a\nfully general algorithm that can be applied, without any pre-processing, to\nother problems with computationally expensive likelihood functions. \n\n"}
{"id": "1110.3462", "contents": "Title: Properties of a thin accretion disk around a rotating non-Kerr black\n  hole Abstract: We study the accretion process in the thin disk around a rotating non-Kerr\nblack hole with a deformed parameter and an unbound rotation parameter. Our\nresults show that the presence of the deformed parameter $\\epsilon$ modifies\nthe standard properties of the disk. For the case in which the black hole is\nmore oblate than a Kerr black hole, the larger deviation leads to the smaller\nenergy flux, the lower radiation temperature and the fainter spectra luminosity\nin the disk. For the black hole with positive deformed parameter, we find that\nthe effect of the deformed parameter on the disk becomes more complicated. It\ndepends not only on the rotation direction of the black hole and the orbit\nparticles, but also on the sign of the difference between the deformed\nparameter $\\epsilon$ and a certain critical value $\\epsilon_{c}$. These\nsignificant features in the mass accretion process may provide a possibility to\ntest the no-hair theorem in the strong field regime in future astronomical\nobservations. \n\n"}
{"id": "1110.5360", "contents": "Title: New Zealand involvement in Radio Astronomical VLBI Image Processing Abstract: With the establishment of the AUT University 12m radio telescope at\nWarkworth, New Zealand has now become a part of the international Very Long\nBaseline Interferometry (VLBI) community. A major product of VLBI observations\nare images in the radio domain of astronomical objects such as Active Galactic\nNuclei (AGN). Using large geographical separations between radio antennas, very\nhigh angular resolution can be achieved. Detailed images can be created using\nthe technique of VLBI Earth Rotation Aperture Synthesis. We review the current\nprocess of VLBI radio imaging. In addition we model VLBI configurations using\nthe Warkworth telescope, AuScope (a new array of three 12m antennas in\nAustralia) and the Australian Square Kilometre Array Pathfinder (ASKAP) array\ncurrently under construction in Western Australia, and discuss how the\nconfiguration of these arrays affects the quality of images. Recent imaging\nresults that demonstrate the modeled improvements from inclusion of the AUT and\nfirst ASKAP telescope in the Australian Long Baseline Array (LBA) are\npresented. \n\n"}
{"id": "1110.6178", "contents": "Title: Parameter Estimation with BEAMS in the presence of biases and\n  correlations Abstract: The original formulation of BEAMS - Bayesian Estimation Applied to Multiple\nSpecies - showed how to use a dataset contaminated by points of multiple\nunderlying types to perform unbiased parameter estimation. An example is\ncosmological parameter estimation from a photometric supernova sample\ncontaminated by unknown Type Ibc and II supernovae. Where other methods require\ndata cuts to increase purity, BEAMS uses all of the data points in conjunction\nwith their probabilities of being each type. Here we extend the BEAMS formalism\nto allow for correlations between the data and the type probabilities of the\nobjects as can occur in realistic cases. We show with simple simulations that\nthis extension can be crucial, providing a 50% reduction in parameter\nestimation variance when such correlations do exist. We then go on to perform\ntests to quantify the importance of the type probabilities, one of which\nillustrates the effect of biasing the probabilities in various ways. Finally, a\ngeneral presentation of the selection bias problem is given, and discussed in\nthe context of future photometric supernova surveys and BEAMS, which lead to\nspecific recommendations for future supernova surveys. \n\n"}
{"id": "1111.0172", "contents": "Title: Low-velocity cosmic strings in accelerating universe Abstract: The standard cosmological model supposes that the dominant matter component\nchanges in the course of the evolution of the universe. We study the\nhomogeneous and isotropic universe with non-zero cosmological constant in the\nepoch when the dominant matter component has a form of a gas of low-velocity\ncosmic strings. It is shown that after the scale transformation of the time\nvariable such a model and the standard model of a spatially flat universe\nfilled with pressure-free matter provide the equivalent descriptions of\ncosmological parameters as functions of time at equal values of the\ncosmological constant. The exception is the behavior of the deceleration\nparameter in the early universe. Pressure-free matter can obtain the properties\nof a gas of low-velocity cosmic strings in the epoch when the global geometry\nand total amount of matter in the universe as a whole obey an additional\nconstraint. This constraint follows from the quantum geometrodynamical approach\nin the semiclassical approximation. In terms of general relativity, its\neffective contribution to the field equations can be linked to the evolution in\ntime of the equation of state of matter caused by the processes of\nredistribution of energy between matter components. \n\n"}
{"id": "1111.0313", "contents": "Title: Discovery, classification, and scientific exploration of transient\n  events from the Catalina Real-time Transient Survey Abstract: Exploration of the time domain - variable and transient objects and phenomena\n- is rapidly becoming a vibrant research frontier, touching on essentially\nevery field of astronomy and astrophysics, from the Solar system to cosmology.\nTime domain astronomy is being enabled by the advent of the new generation of\nsynoptic sky surveys that cover large areas on the sky repeatedly, and\ngenerating massive data streams. Their scientific exploration poses many\nchallenges, driven mainly by the need for a real-time discovery,\nclassification, and follow-up of the interesting events. Here we describe the\nCatalina Real-Time Transient Survey (CRTS), that discovers and publishes\ntransient events at optical wavelengths in real time, thus benefiting the\nentire community. We describe some of the scientific results to date, and then\nfocus on the challenges of the automated classification and prioritization of\ntransient events. CRTS represents a scientific and a technological testbed and\nprecursor for the larger surveys in the future, including the Large Synoptic\nSurvey Telescope (LSST) and the Square Kilometer Array (SKA). \n\n"}
{"id": "1111.1566", "contents": "Title: MIMAC: A micro-tpc matrix project for directional detection of dark\n  matter Abstract: Directional detection of non-baryonic DarkMatter is a promising search\nstrategy for discriminating WIMP events from background ones. This strategy\nrequires both a measurement of the recoil energy down to a few keV and 3D\nreconstruction of tracks down to a few mm. The MIMAC project, based on a\nmicro-TPC matrix, filled with CF4 and CHF3 is being developed. The first\nresults of a chamber prototype of this matrix, on low energy nuclear recoils\n(1H and 19F) obtained with mono-energetic neutron fields are presented. The\ndiscovery potential of this search strategy is illustrated by a realistic case\naccessible to MIMAC. \n\n"}
{"id": "1111.1701", "contents": "Title: Gravitational Waves and Time Domain Astronomy Abstract: The gravitational wave window onto the universe will open in roughly five\nyears, when Advanced LIGO and Virgo achieve the first detections of high\nfrequency gravitational waves, most likely coming from compact binary mergers.\nElectromagnetic follow-up of these triggers, using radio, optical, and high\nenergy telescopes, promises exciting opportunities in multi-messenger time\ndomain astronomy. In the next decade, space-based observations of low frequency\ngravitational waves from massive black hole mergers, and their electromagnetic\ncounterparts, will open up further vistas for discovery. This two-part workshop\nat featured brief presentations and stimulating discussions on the challenges\nand opportunities presented by gravitational wave astronomy. Highlights from\nthe workshop, with the emphasis on strategies for electromagnetic follow-up,\nare presented in this report. \n\n"}
{"id": "1111.3909", "contents": "Title: The environment of weak emission-line quasars Abstract: The nature of weak emission-line quasars (WLQs) is probed by comparing the\nBaldwin effect (BEff) in WLQs and normal quasars (QSOs). We selected 81\nhigh-redshift (z>2.2) and 2 intermediate-redshift (z=1.66 and 1.89) WLQs. Their\nrest-frame equivalent widths (EWs) of the C IV emission-line and their\nEddington ratio were obtained from the Sloan Digital Sky Survey Data Release 7\n(SDSS DR7) Quasar Catalogue or from Diamond-Stanic et al. We compare the\nparameters of WLQs with these of 81 normal quasars from Bright Quasar Survey\n(BQS) and 155 radio-quiet and radio-intermediate quasars detected by SDSS and\nChandra. The influence of the Eddington ratio, Lbol/Ledd, and the X-ray to\noptical luminosity ratio,alpha_ox, on the BEff is analysed. We find that WLQs\nfollow a different relationship on the EW(CIV)-Lbol/Ledd plane than normal\nquasars. This relationship disagrees with the super-Eddington hypothesis. The\nweakness/absence of emission-lines in WLQs does not seem to be caused by their\nextremely soft ionizing continuum but by low covering factor (Omega) of their\nbroad line region (BLR). Comparing emission-line intensities indicates that the\nratios of high-ionization line and low-ionization line regions (i.e.\nOmega_(HIL)/Omega_(LIL)) are lower in WLQs than in normal QSOs. The covering\nfactor of the regions producing C IV and Lyalpha emission-lines are similar in\nboth WLQs and QSOs. \n\n"}
{"id": "1111.5039", "contents": "Title: Properties of gas in and around galaxy haloes Abstract: We study the properties of gas inside and around galaxy haloes as a function\nof radius and halo mass, focussing mostly on z=2, but also showing some results\nfor z=0. For this purpose, we use a suite of large cosmological, hydrodynamical\nsimulations from the OverWhelmingly Large Simulations project. The properties\nof cold- and hot-mode gas, which we separate depending on whether the\ntemperature has been higher than 10^5.5 K while it was extragalactic, are\nclearly distinguishable in the outer parts of massive haloes (virial\ntemperatures >> 10^5 K. The differences between cold- and hot-mode gas resemble\nthose between inflowing and outflowing gas. The cold-mode gas is mostly\nconfined to clumpy filaments that are approximately in pressure equilibrium\nwith the diffuse, hot-mode gas. Besides being colder and denser, cold-mode gas\ntypically has a much lower metallicity and is much more likely to be infalling.\nHowever, the spread in the properties of the gas is large, even for a given\nmode and a fixed radius and halo mass, which makes it impossible to make strong\nstatements about individual gas clouds. Metal-line cooling causes a strong\ncooling flow near the central galaxy, which makes it hard to distinguish gas\naccreted through the cold and hot modes in the inner halo. Stronger feedback\nresults in larger outflow velocities and pushes hot-mode gas to larger radii.\nThe gas properties evolve as expected from virial arguments, which can also\naccount for the dependence of many gas properties on halo mass. We argue that\ncold streams penetrating hot haloes are observable as high-column density HI\nLyman-alpha absorption systems in sightlines near massive foreground galaxies. \n\n"}
{"id": "1111.5081", "contents": "Title: Accelerating the Rate of Astronomical Discovery with GPU-Powered\n  Clusters Abstract: In recent years, the Graphics Processing Unit (GPU) has emerged as a low-cost\nalternative for high performance computing, enabling impressive speed-ups for a\nrange of scientific computing applications. Early adopters in astronomy are\nalready benefiting in adapting their codes to take advantage of the GPU's\nmassively parallel processing paradigm. I give an introduction to, and overview\nof, the use of GPUs in astronomy to date, highlighting the adoption and\napplication trends from the first ~100 GPU-related publications in astronomy. I\ndiscuss the opportunities and challenges of utilising GPU computing clusters,\nsuch as the new Australian GPU supercomputer, gSTAR, for accelerating the rate\nof astronomical discovery. \n\n"}
{"id": "1111.6116", "contents": "Title: AstroDAbis: Annotations and Cross-Matches for Remote Catalogues Abstract: Astronomers are good at sharing data, but poorer at sharing knowledge.\n  Almost all astronomical data ends up in open archives, and access to these is\nbeing simplified by the development of the global Virtual Observatory (VO).\nThis is a great advance, but the fundamental problem remains that these\narchives contain only basic observational data, whereas all the astrophysical\ninterpretation of that data -- which source is a quasar, which a low-mass star,\nand which an image artefact -- is contained in journal papers, with very little\nlinkage back from the literature to the original data archives. It is therefore\ncurrently impossible for an astronomer to pose a query like \"give me all\nsources in this data archive that have been identified as quasars\" and this\nlimits the effective exploitation of these archives, as the user of an archive\nhas no direct means of taking advantage of the knowledge derived by its\nprevious users.\n  The AstroDAbis service aims to address this, in a prototype service enabling\nastronomers to record annotations and cross-identifications in the AstroDAbis\nservice, annotating objects in other catalogues. We have deployed two\ninterfaces to the annotations, namely one astronomy-specific one using the TAP\nprotocol}, and a second exploiting generic Linked Open Data (LOD) and RDF\ntechniques. \n\n"}
{"id": "1111.6525", "contents": "Title: What is a Spectrum? Abstract: This contribution describes the \"spectro-perfectionism\" algorithm of Bolton &\nSchlegel (2010, PASP, 122, 248) that is being implemented within the Baryon\nOscillation Spectroscopic Survey (BOSS) of the Sloan Digital Sky Survey III\n(SDSS-III), in terms of its potential to deliver Poisson-limited sky\nsubtraction and lossless compression of the input spectrum likelihood\nfunctional given raw CCD data. \n\n"}
{"id": "1111.6591", "contents": "Title: Stellar Feedback & Bulge Formation in Clumpy Disks Abstract: We use numerical simulations of isolated galaxies to study the effects of\nstellar feedback on the formation and evolution of giant star-forming gas\n'clumps' in high-redshift, gas-rich galaxies. Such galactic disks are unstable\nto the formation of bound gas-rich clumps whose properties initially depend\nonly on global disk properties, not the microphysics of feedback. In\nsimulations without stellar feedback, clumps turn an order-unity fraction of\ntheir mass into stars and sink to the center, forming a large bulge and kicking\nmost of the stars out into a much more extended stellar envelope. By contrast,\nstrong radiative stellar feedback disrupts even the most massive clumps after\nthey turn ~10-20% of their mass into stars, in a timescale of ~10-100 Myr,\nejecting some material into a super-wind and recycling the rest of the gas into\nthe diffuse ISM. This suppresses the bulge formation rate by direct 'clump\ncoalescence' by a factor of several. However, the galactic disks do undergo\nsignificant internal evolution in the absence of mergers: clumps form and\ndisrupt continuously and torque gas to the galactic center. The resulting\nevolution is qualitatively similar to bar/spiral evolution in simulations with\na more homogeneous ISM. \n\n"}
{"id": "1111.6980", "contents": "Title: Ion-by-ion Cooling efficiencies Abstract: We present ion-by-ion cooling efficiencies for low-density gas. We use Cloudy\n(ver. 08.00) to estimate the cooling efficiencies for each ion of the first 30\nelements (H-Zn) individually. We present results for gas temperatures between\n1e4 and 1e8K, assuming low densities and optically thin conditions. When\nnonequilibrium ionization plays a significant role the ionization states\ndeviate from those that obtain in collisional ionization equilibrium (CIE), and\nthe local cooling efficiency at any given temperature depends on specific\nnon-equilibrium ion fractions. The results presented here allow for an\nefficient estimate of the total cooling efficiency for any ionic composition.\nWe also list the elemental cooling efficiencies assuming CIE conditions. These\ncan be used to construct CIE cooling efficiencies for non-solar abundance\nratios, or to estimate the cooling due to elements not explicitly included in\nany nonequilibrium computation. All the computational results are listed in\nconvenient online tables. \n\n"}
{"id": "1111.7110", "contents": "Title: Particle acceleration at relativistic shock waves Abstract: Relativistic sources, e.g. gamma-ray bursts, pulsar wind nebulae and powerful\nactive galactic nuclei produce relativistic outflows that lead to the formation\nof collisionless shock waves, where particle acceleration is thought to take\nplace. Our understanding of relativistic shock acceleration has improved in the\npast decade, thanks to the combination of analytical studies and high level\nnumerical simulations. In ultra-relativistic shocks, particle acceleration is\nmade difficult by the generically transverse magnetic field and large advection\nspeed of the shocked plasma. Fast growing microturbulence is thus needed to\nmake the Fermi process operative. It is thought, and numerical simulations\nsupport that view, that the penetration of supra-thermal particles in the shock\nprecursor generates a magnetic turbulence which in turn produces the scattering\nprocess needed for particle acceleration through the Fermi mechanism. Through\nthe comparison of the growth timescale of the microinstabilities in the shock\nprecursor and the precursor crossing timescale, it is possible to delimit in\nterms of magnetization and shock Lorentz factor the region in which\nmicro-turbulence may be excited, hence whether and how Fermi acceleration is\ntriggered. These findings are summarized here and astrophysical consequences\nare drawn. \n\n"}
{"id": "1112.1071", "contents": "Title: HYPERION: An open-source parallelized three-dimensional dust continuum\n  radiative transfer code Abstract: HYPERION is a new three-dimensional dust continuum Monte-Carlo radiative\ntransfer code that is designed to be as generic as possible, allowing radiative\ntransfer to be computed through a variety of three-dimensional grids. The main\npart of the code is problem-independent, and only requires an arbitrary\nthree-dimensional density structure, dust properties, the position and\nproperties of the illuminating sources, and parameters controlling the running\nand output of the code. HYPERION is parallelized, and is shown to scale well to\nthousands of processes. Two common benchmark models for protoplanetary disks\nwere computed, and the results are found to be in excellent agreement with\nthose from other codes. Finally, to demonstrate the capabilities of the code,\ndust temperatures, SEDs, and synthetic multi-wavelength images were computed\nfor a dynamical simulation of a low-mass star formation region. HYPERION is\nbeing actively developed to include new features, and is publicly available\n(http://www.hyperion-rt.org). \n\n"}
{"id": "1112.1688", "contents": "Title: Why don't we already have an Integrated Framework for the Publication\n  and Preservation of all Data Products? Abstract: Astronomy has long had a working network of archives supporting the curation\nof publications and data. The discipline has already created many of the\nfeatures which perplex other areas of science: (1) data repositories:\n(supra)national institutes, dedicated to large projects; a culture of\nuser-contributed data; practical experience of long-term data preservation; (2)\ndataset identifiers: the community has already piloted experiments, knows what\ncan undermine these efforts, and is participating in the development of\nnext-generation standards; (3) citation of datasets in papers: the community\nhas an innovative and expanding infrastructure for the curation of data and\nbibliographic resources, and through them a community of author s and editors\nfamiliar with such electronic publication efforts; as well, it has experimented\nwith next-generation web standards (e.g. the Semantic Web); (4) publisher\nbuy-in: publishers in this area have been willing to innovate within the\nconstraints of their commercial imperatives. What can possibly be missing? Why\ndon't we have an integrated framework for the publication and preservation of\nall data products already? Are there technical barriers? We don't believe so.\nAre there cultural or commercial forces inhibiting this? We aren't aware of\nany. This Birds of a Feather session (BoF) attempted to identify existing\nbarriers to the creation of such a framework, and attempted to identify the\nparties or groups which can contribute to the creation of a VO-powered\ndata-publishing framework. \n\n"}
{"id": "1112.3057", "contents": "Title: The Impact of the Spectral Response of an Achromatic Half-Wave Plate on\n  the Measurement of the Cosmic Microwave Background Polarization Abstract: We study the impact of the spectral dependence of the linear polarization\nrotation induced by an achromatic half-wave plate on measurements of cosmic\nmicrowave background polarization in the presence of astrophysical foregrounds.\nWe focus on the systematic effects induced on the measurement of inflationary\ngravitational waves by uncertainties in the polarization and spectral index of\nGalactic dust. We find that for the experimental configuration and noise levels\nof the balloon-borne EBEX experiment, which has three frequency bands centered\nat 150, 250, and 410 GHz, a crude dust subtraction process mitigates systematic\neffects to below detectable levels for 10% polarized dust and tensor to scalar\nratio of as low as r = 0.01. We also study the impact of uncertainties in the\nspectral response of the instrument. With a top-hat model of the spectral\nresponse for each band, characterized by band-center and band-width, and with\nthe same crude dust subtraction process, we find that these parameters need to\nbe determined to within 1 and 0.8 GHz at 150 GHz; 9 and 2.0 GHz at 250 GHz; and\n20 and 14 GHz at 410 GHz, respectively. The approach presented in this paper is\napplicable to other optical elements that exhibit polarization rotation as a\nfunction of frequency. \n\n"}
{"id": "1112.3652", "contents": "Title: Understanding better (some) astronomical data using Bayesian methods Abstract: Current analysis of astronomical data are confronted with the daunting task\nof modeling the awkward features of astronomical data, among which\nheteroscedastic (point-dependent) errors, intrinsic scatter, non-ignorable data\ncollection (selection effects), data structure, non-uniform populations (often\ncalled Malmquist bias), non-Gaussian data, and upper/lower limits. This chapter\nshows, by examples, how modeling all these features using Bayesian methods. In\nshort, one just need to formalize, using maths, the logical link between the\ninvolved quantities, how the data arise and what we already known on the\nquantities we want to study. The posterior probability distribution summarizes\nwhat we known on the studied quantities after the data, and we should not be\nafraid about their actual numerical computation, because it is left to\n(special) Monte Carlo programs such as JAGS. As examples, we show how to\npredict the mass of a new object disposing of a calibrating sample, how to\nconstraint cosmological parameters from supernovae data and how to check if the\nfitted data are in tension with the adopted fitting model. Examples are given\nwith their coding. These examples can be easily used as template for completely\ndifferent analysis, on totally unrelated astronomical objects, requiring to\nmodel the same awkward data features. \n\n"}
{"id": "1112.4482", "contents": "Title: High-Performance Astrophysical Simulations and Analysis with Python Abstract: The usage of the high-level scripting language Python has enabled new\nmechanisms for data interrogation, discovery and visualization of scientific\ndata. We present yt, an open source, community-developed astrophysical analysis\nand visualization toolkit for data generated by high-performance computing\n(HPC) simulations of astrophysical phenomena. Through a separation of\nresponsibilities in the underlying Python code, yt allows data generated by\nincompatible, and sometimes even directly competing, astrophysical simulation\nplatforms to be analyzed in a consistent manner, focusing on physically\nrelevant quantities rather than quantities native to astrophysical simulation\ncodes. We present on its mechanisms for data access, capabilities for\nMPI-parallel analysis, and its implementation as an in situ analysis and\nvisualization tool. \n\n"}
{"id": "1112.5120", "contents": "Title: Measuring the Effects of Artificial Viscosity in SPH Simulations of\n  Rotating Fluid Flows Abstract: A commonly cited drawback of SPH is the introduction of spurious shear\nviscosity by the artificial viscosity term in situations involving rotation.\nExisting approaches for quantifying its effect include approximate analytic\nformulae and disc-averaged be- haviour in specific ring-spreading simulations,\nbased on the kinematic effects produced by the artificial viscosity. These\nmethods have disadvantages, in that they typically are applicable to a very\nsmall range of physical scenarios, have a large number of simplifying\nassumptions, and often are tied to specific SPH formulations which do not\ninclude corrective (e.g., Balsara) or time-dependent viscosity terms. In this\nstudy we have developed a simple, generally applicable and practical technique\nfor evaluating the local effect of artificial viscosity directly from the\ncreation of specific entropy for each SPH particle. This local approach is\nsimple and quick to implement, and it al- lows a detailed characterization of\nviscous effects as a function of position. Several advantages of this method\nare discussed, including its ease in evaluation, its greater accuracy and its\nbroad applicability. In order to compare this new method with ex- isting ones,\nsimple disc flow examples are used. Even in these basic cases, the very roughly\napproximate nature of the previous methods is shown. Our local method pro-\nvides a detailed description of the effects of the artificial viscosity\nthroughout the disc, even for extended examples which implement Balsara\ncorrections. As a further use of this approach, explicit dependencies of the\neffective viscosity in terms of SPH and flow parameters are estimated from the\nexample cases. In an appendix, a method for the initial placement of SPH\nparticles is discussed which is very effective in reducing numerical\nfluctuations. \n\n"}
{"id": "1112.6128", "contents": "Title: Holographic Grid Cloud, a futurable high storage technology for the next\n  generation astronomical facilities Abstract: In the immediate future holographic technology will be available to store a\nvery large amount of data in HVD (Holographic Versatile Disk) devices. This\ntechnology make extensive use of the WORM (Write-Once-Read-Many) paradigm: this\nmeans that such devices allow for a simultaneous and parallel reading of\nmillions of volumetric pixels (i.e. voxels). This characteristic will make\naccessible wherever the acquired data from a telescope (or satellite) in a\nquite-simultaneous way.\n  With the support of this new technology the aim of this paper is to identify\nthe guidelines for the implementation of a distributed RAID system, a sort of\n\"storage block\" to distribute astronomical data over different geographical\nsites acting as a single remote device as an effect of a property of\ndistributed computing, the abstraction of resources. The end user will only\nhave to take care on connecting in a opportune and secure mode (using personal\ncertificates) to the remote device and will have access to all (or part) of\nthis potential technology.\n  A Storage-Block+Services engineered on such a platform will allow rapid\nscalability of resources, creating a \"network-distributed cloud\" of services\nfor an instrument or a mission. It is recommended the use of a dedicated\ngrid-infrastructure within each single cloud to enhance some critical tasks and\nto speed-up services working on the redundant, encrypted and compressed\nscientific data. The power, the accessibility, the degree of parallelism and of\nredundancy will only depend on the number of distributed storage-blocks: the\nhigher this amount, the greater will be throughput of the IT-system. A\nstorage-block of this kind is a meeting point between two technologies and two\nantithetical computing paradigms: the Grid-Computing and Cloud-Computing. \n\n"}
{"id": "1201.1000", "contents": "Title: Information escaping the correlation hierarchy of the convergence field\n  in the study of cosmological parameters Abstract: Using fits to numerical simulations, we show that the entire hierarchy of\nmoments quickly ceases to provide a complete description of the convergence\none-point probability density function leaving the linear regime. This suggests\nthat the full N-point correlation function hierarchy of the convergence field\nbecomes quickly generically incomplete and a very poor cosmological probe on\nnonlinear scales. At the scale of unit variance, only 5% of the Fisher\ninformation content of the one-point probability density function is still\ncontained in its hierarchy of moments, making clear that information escaping\nthe hierarchy is a far stronger effect than information propagating to higher\norder moments. It follows that the constraints on cosmological parameters\nachievable through extraction of the entire hierarchy become suboptimal by\nlarge amounts. A simple logarithmic mapping makes the moment hierarchy well\nsuited again for parameter extraction. \n\n"}
{"id": "1201.1446", "contents": "Title: Hypervelocity Planets and Transits Around Hypervelocity Stars Abstract: The disruption of a binary star system by the massive black hole at the\nGalactic Centre, SgrA*, can lead to the capture of one star around SgrA* and\nthe ejection of its companion as a hypervelocity star (HVS). We consider the\npossibility that these stars may have planets and study the dynamics of these\nplanets. Using a direct $N$-body integration code, we simulated a large number\nof different binary orbits around SgrA*. For some orbital parameters, a planet\nis ejected at a high speed. In other instances, a HVS is ejected with one or\nmore planets orbiting around it. In these cases, it may be possible to observe\nthe planet as it transits the face of the star. A planet may also collide with\nits host star. In such cases the atmosphere of the star will be enriched with\nmetals. In other cases, a planet is tidally disrupted by SgrA*, leading to a\nbright flare. \n\n"}
{"id": "1201.3238", "contents": "Title: Science performance of Gaia, ESA's space-astrometry mission Abstract: Gaia is the next astrometry mission of the European Space Agency (ESA),\nfollowing up on the success of the Hipparcos mission. With a focal plane\ncontaining 106 CCD detectors, Gaia will survey the entire sky and repeatedly\nobserve the brightest 1,000 million objects, down to 20th magnitude, during its\n5-year lifetime. Gaia's science data comprises absolute astrometry, broad-band\nphotometry, and low-resolution spectro-photometry. Spectroscopic data with a\nresolving power of 11,500 will be obtained for the brightest 150 million\nsources, down to 17th magnitude. The thermo-mechanical stability of the\nspacecraft, combined with the selection of the L2 Lissajous point of the\nSun-Earth/Moon system for operations, allows stellar parallaxes to be measured\nwith standard errors less than 10 micro-arcsecond (muas) for stars brighter\nthan 12th magnitude, 25 muas for stars at 15th magnitude, and 300 muas at\nmagnitude 20. Photometric standard errors are in the milli-magnitude regime.\nThe spectroscopic data allows the measurement of radial velocities with errors\nof 15 km/s at magnitude 17. Gaia's primary science goal is to unravel the\nkinematical, dynamical, and chemical structure and evolution of the Milky Way.\nIn addition, Gaia's data will touch many other areas of science, e.g., stellar\nphysics, solar-system bodies, fundamental physics, and exo-planets. The Gaia\nspacecraft is currently in the qualification and production phase. With a\nlaunch in 2013, the final catalogue is expected in 2021. The science community\nin Europe, organised in the Data Processing and Analysis Consortium (DPAC), is\nresponsible for the processing of the data. \n\n"}
{"id": "1201.3658", "contents": "Title: In-spiraling Clumps in Blue Compact Dwarf Galaxies Abstract: Giant star-formation clumps in dwarf irregular galaxies can have masses\nexceeding a few percent of the galaxy mass enclosed inside their orbital radii.\nThey can produce sufficient torques on dark matter halo particles, halo stars,\nand the surrounding disk to lose their angular momentum and spiral into the\ncentral region in 1 Gyr. Pairs of giant clumps with similarly large relative\nmasses can interact and exchange angular momentum to the same degree. The\nresult of this angular momentum loss is a growing central concentration of old\nstars, gas, and star formation that can produce a long-lived starburst in the\ninner region, identified with the BCD phase. This central concentration is\nproposed to be analogous to the bulge in a young spiral galaxy. Observations of\nstar complexes in five local BCDs confirm the relatively large clump masses\nthat are expected for this process. The observed clumps also seem to contain\nold field stars, even after background light subtraction, in which case the\nclumps may be long-lived. The two examples with clumps closest to the center\nhave the largest relative clump masses and the greatest contributions from old\nstars. An additional indication that the dense central regions of BCDs are like\nbulges is the high ratio of the inner disk scale height to the scale length,\nwhich is comparable to 1 for four of the galaxies. \n\n"}
{"id": "1201.5029", "contents": "Title: PyCOOL - a Cosmological Object-Oriented Lattice code written in Python Abstract: There are a number of different phenomena in the early universe that have to\nbe studied numerically with lattice simulations. This paper presents a graphics\nprocessing unit (GPU) accelerated Python program called PyCOOL that solves the\nevolution of scalar fields in a lattice with very precise symplectic\nintegrators. The program has been written with the intention to hit a sweet\nspot of speed, accuracy and user friendliness. This has been achieved by using\nthe Python language with the PyCUDA interface to make a program that is easy to\nadapt to different scalar field models. In this paper we derive the symplectic\ndynamics that govern the evolution of the system and then present the\nimplementation of the program in Python and PyCUDA. The functionality of the\nprogram is tested in a chaotic inflation preheating model, a single field\noscillon case and in a supersymmetric curvaton model which leads to Q-ball\nproduction. We have also compared the performance of a consumer graphics card\nto a professional Tesla compute card in these simulations. We find that the\nprogram is not only accurate but also very fast. To further increase the\nusefulness of the program we have equipped it with numerous post-processing\nfunctions that provide useful information about the cosmological model. These\ninclude various spectra and statistics of the fields. The program can be\nadditionally used to calculate the generated curvature perturbation. The\nprogram is publicly available under GNU General Public License at\nhttps://github.com/jtksai/PyCOOL . Some additional information can be found\nfrom http://www.physics.utu.fi/tiedostot/theory/particlecosmology/pycool/ . \n\n"}
{"id": "1201.5101", "contents": "Title: Slicing the Torus: Obscuring Structures in Quasars Abstract: Quasars and Active Galactic Nuclei (AGNs) are often obscured by dust and gas.\nIt is normally assumed that the obscuration occurs in an oblate \"obscuring\ntorus\", that begins at the radius at which the most refractive dust can remain\nsolid. The most famous form of this torus is a donut-shaped region of molecular\ngas with a large scale-height. While this model is elegant and accounts for\nmany phenomena at once, it does not hold up to detailed tests. Instead the\nobscuration in AGNs must occur on a wide range of scales and be due to a\nminimum of three physically distinct absorbers. Slicing the \"torus\" into these\nthree regions will allow interesting physics of the AGN to be extracted. \n\n"}
{"id": "1201.5476", "contents": "Title: The relative significance of the H-index Abstract: Use of the Hirsch-index ($h$) as measure of an author's visibility in the\nscientific literature has become popular as an alternative to a gross measure\nlike total citations (c). I show that, at least in astrophysics, $h$ correlates\ntightly with overall citations. The mean relation is $h=0.5(\\sqrt c+1)$.\nOutliers are few and not too far from the mean, especially if `normalized' ADS\ncitations are used for $c$ and $h$. Whatever the theoretical reasoning behind\nit, the Hirsch index in practice does not appear to measure something\nsignificantly new. \n\n"}
{"id": "1201.6348", "contents": "Title: The effect of systematics on polarized spectral indices Abstract: We study four particularly bright polarized compact objects (Tau A, Virgo A,\n3C273 and Fornax A) in the 7-year WMAP sky maps, with the goal of understanding\npotential systematics involved in estimation of foreground spectral indices. We\nestimate the spectral index, the polarization angle, the polarization fraction\nand apparent size and shape of these objects when smoothed to a nominal\nresolution of 1 degree FWHM. Second, we compute the spectral index as a\nfunction of polarization orientation, alpha. Because these objects are\napproximately point sources with constant polarization angle, this function\nshould be constant in the absence of systematics. However, computing it for the\nK- and Ka-band WMAP data we find strong index variations for all four sources.\nFor Tau A, we find a spectral index beta=-2.59+-0.03 for alpha=30 degrees, and\nbeta=-2.03+-0.01 for alpha=50 degrees. On the other hand, the spectral index\nbetween Ka and Q band is found to be stable. A simple elliptical Gaussian toy\nmodel with parameters matching those observed in Tau A reproduces the observed\nsignal, and shows that the spectral index is in particular sensitive to the\ndetector polarization angle. Based on these findings, we first conclude that\nestimation of spectral indices with the WMAP K-band polarization data at 1\ndegree scales is not robust. Second, we note that these issues may be of\nconcern for ground-based and sub-orbital experiments that use the WMAP\npolarization measurements of Tau A for calibration of gain and polarization\nangles. \n\n"}
{"id": "1202.1034", "contents": "Title: Spectral components analysis of diffuse emission processes Abstract: We develop a novel method to separate the components of a diffuse emission\nprocess based on an association with the energy spectra. Most of the existing\nmethods use some information about the spatial distribution of components,\ne.g., closeness to an external template, independence of components etc., in\norder to separate them. In this paper we propose a method where one puts\nconditions on the spectra only. The advantages of our method are: 1) it is\ninternal: the maps of the components are constructed as combinations of data in\ndifferent energy bins, 2) the components may be correlated among each other, 3)\nthe method is semi-blind: in many cases, it is sufficient to assume a\nfunctional form of the spectra and determine the parameters from a maximization\nof a likelihood function. As an example, we derive the CMB map and the\nforeground maps for seven yeas of WMAP data. In an Appendix, we present a\ngeneralization of the method, where one can also add a number of external\ntemplates. \n\n"}
{"id": "1202.1426", "contents": "Title: Approximate Bayesian Computation for Astronomical Model Analysis: A Case\n  Study in Galaxy Demographics and Morphological Transformation at High\n  Redshift Abstract: \"Approximate Bayesian Computation\" (ABC) represents a powerful methodology\nfor the analysis of complex stochastic systems for which the likelihood of the\nobserved data under an arbitrary set of input parameters may be entirely\nintractable-the latter condition rendering useless the standard machinery of\ntractable likelihood-based, Bayesian statistical inference (e.g. conventional\nMarkov Chain Monte Carlo simulation; MCMC). In this article we demonstrate the\npotential of ABC for astronomical model analysis by application to a case study\nin the morphological transformation of high redshift galaxies. To this end we\ndevelop, first, a stochastic model for the competing processes of merging and\nsecular evolution in the early Universe; and second, through an ABC-based\ncomparison against the observed demographics of massive (M_gal > 10^11 M_sun)\ngalaxies (at 1.5 < z < 3) in the CANDELS/EGS dataset we derive posterior\nprobability densities for the key parameters of this model. The \"Sequential\nMonte Carlo\" (SMC) implementation of ABC exhibited herein, featuring both a\nself-generating target sequence and self-refining MCMC kernel, is amongst the\nmost efficient of contemporary approaches to this important statistical\nalgorithm. We highlight as well through our chosen case study the value of\ncareful summary statistic selection, and demonstrate two modern strategies for\nassessment and optimisation in this regard. Ultimately, our ABC analysis of the\nhigh redshift morphological mix returns tight constraints on the evolving\nmerger rate in the early Universe and favours major merging (with disc survival\nor rapid reformation) over secular evolution as the mechanism most responsible\nfor building up the first generation of bulges in early-type disks. \n\n"}
{"id": "1202.3032", "contents": "Title: Forecast constraints on cosmic string parameters from gravitational wave\n  direct detection experiments Abstract: Gravitational waves (GWs) are one of the key signatures of cosmic strings. If\nGWs from cosmic strings are detected in future experiments, not only their\nexistence can be confirmed but also their properties might be probed. In this\npaper, we study the determination of cosmic string parameters through direct\ndetection of GW signatures in future ground-based GW experiments. We consider\ntwo types of GWs, bursts and the stochastic GW background, which provide us\nwith different information about cosmic string properties. Performing the\nFisher matrix calculation on the cosmic string parameters, such as parameters\ngoverning the string tension $G\\mu$ and initial loop size $\\alpha$ and the\nreconnection probability $p$, we find that the two different types of GW can\nbreak degeneracies in some of these parameters and provide better constraints\nthan those from each measurement. \n\n"}
{"id": "1202.3990", "contents": "Title: A Bayesian Approach to Calibrating Period-Luminosity Relations of RR\n  Lyrae Stars in the Mid-Infrared Abstract: A Bayesian approach to calibrating period-luminosity (PL) relations has\nsubstantial benefits over generic least-squares fits. In particular, the\nBayesian approach takes into account the full prior distribution of the model\nparameters, such as the a priori distances, and refits these parameters as part\nof the process of settling on the most highly-constrained final fit.\nAdditionally, the Bayesian approach can naturally ingest data from multiple\nwavebands and simultaneously fit the parameters of PL relations for each\nwaveband in a procedure that constrains the parameter posterior distributions\nso as to minimize the scatter of the final fits appropriately in all wavebands.\nHere we describe the generalized approach to Bayesian model fitting and then\nspecialize to a detailed description of applying Bayesian linear model fitting\nto the mid-infrared PL relations of RR Lyrae variable stars. For this example\napplication we quantify the improvement afforded by using a Bayesian model fit.\nWe also compare distances previously predicted in our example application to\nrecently published parallax distances measured with the Hubble Space Telescope\nand find their agreement to be a vindication of our methodology. Our intent\nwith this article is to spread awareness of the benefits and applicability of\nthis Bayesian approach and encourage future PL relation investigations to\nconsider employing this powerful analysis method. \n\n"}
{"id": "1202.4051", "contents": "Title: Citations to Australian Astronomy: 5 and 10 Year Benchmarks Abstract: Expanding upon Pimbblet's informative 2011 analysis of career h-indices for\nmembers of the Astronomical Society of Australia, we provide additional\ncitation metrics which are geared to a) quantifying the current performance of\nb) all professional astronomers in Australia. We have trawled the staff\nweb-pages of Australian Universities, Observatories and Research Organisations\nhosting professional astronomers, and identified 383 PhD-qualified,\nresearch-active, astronomers in the nation - 131 of these are not members of\nthe Astronomical Society of Australia. Using the SAO/NASA Astrophysics Data\nSystem, we provide the three following common metrics based on publications in\nthe first decade of the 21st century (2001-2010): h-index, author-normalised\ncitation count and lead-author citation count. We additionally present a\nsomewhat more inclusive analysis, applicable for many early-career researchers,\nthat is based on publications from 2006-2010. Histograms and percentiles, plus\ntop-performer lists, are presented for each category. Finally, building on\nHirsch's empirical equation, we find that the (10-year) h-index and (10-year)\ntotal citation count T can be approximated by the relation h =\n(0.5+sqrt{T})/sqrt{5} for h > 5. \n\n"}
{"id": "1202.4067", "contents": "Title: Axino dark matter and baryon number asymmetry from Q-ball decay in gauge\n  mediation Abstract: We investigate the Q-ball decay into the axino dark matter in the\ngauge-mediated supersymmetry breaking. In our scenario, the Q ball decays\nmainly into nucleons and partially into axinos to account for the baryon\nasymmetry and the dark matter of the universe simultaneously. The Q ball decays\nwell before the big bang nucleosynthesis so that it is not affected by the\ndecay. The decay into the supersymmetric particles of the minimal\nsupersymmetric standard model is kinematically prohibited until the very end of\nthe decay, and we could safely make their abundances small enough for the\nsuccessful big bang nucleosynthesis. We show the regions of axino model\nparameters and the Q-ball parameters which realize this scenario. \n\n"}
{"id": "1202.5900", "contents": "Title: A tidal disruption-like X-ray flare from the quiescent galaxy SDSS\n  J120136.02+300305.5 Abstract: SDSS J120136.02+300305.5 was detected in an XMM-Newton slew from June 2010\nwith a flux 56 times higher than an upper limit from ROSAT, corresponding to\nLx~3x10^44 ergs/s. It has the optical spectrum of a quiescent galaxy (z=0.146).\nOverall the X-ray flux has evolved consistently with the canonical t^-5/3\nmodel, expected for returning stellar debris from a tidal disruption event,\nfading by a factor ~300 over 300 days. In detail the source is very variable\nand became invisible to Swift between 27 and 48 days after discovery, perhaps\ndue to self-absorption. The X-ray spectrum is soft but is not the expected tail\nof optically thick thermal emission. It may be fit with a Bremsstrahlung or\ndouble-power-law model and is seen to soften with time and declining flux.\nOptical spectra taken 12 days and 11 months after discovery indicate a deficit\nof material in the broad line and coronal line regions of this galaxy, while a\ndeep radio non-detection implies that a jet was not launched during this event. \n\n"}
{"id": "1203.0604", "contents": "Title: DEAP-3600 Dark Matter Search at SNOLAB Abstract: The DEAP-3600 detector, currently under construction at SNOLAB, has been\ndesigned to achieve extremely low background rates from all sources, including\n39Ar beta decays, neutron scatters (from internal and external sources),\nsurface alpha contamination and radon. An overview of the detector and its\nsensitivity are presented. \n\n"}
{"id": "1203.4237", "contents": "Title: A minor merger scenario for the ultraluminous X-ray source ESO 243-49\n  HLX-1 Abstract: The point-like X-ray source HLX-1 is the brightest known ultraluminous X-ray\nsource and likely the strongest intermediate-mass black hole candidate. HLX-1\nis hosted in the S0 galaxy ESO 243-49, but offset with respect to the nucleus,\nand its optical counterpart was identified with a massive star cluster. In this\npaper, we study, through N-body/smoothed particle hydrodynamics simulations,\nthe scenario where ESO 243-49 is undergoing (or just underwent) a minor merger\nwith a gas-rich low-mass late-type galaxy. The simulations suggest that the\nobserved star formation rate (SFR) in ESO 243-49 is a consequence of the\ninteraction and that the companion galaxy already underwent the second\npericentre passage. We propose that the counterpart of HLX-1 coincides with the\nnucleus (and possibly with the nuclear star cluster) of the secondary galaxy.\nWe estimate that, if the minor merger scenario is correct, the number density\nof X-ray sources similar to HLX-1 is ~10^-6 Mpc^-3. \n\n"}
{"id": "1203.4571", "contents": "Title: Direct Constraints on the Impact of TP-AGB Stars on the SED of Galaxies\n  from Near-Infrared Spectroscopy Abstract: We present new spectro-photometric NIR observations of 16 post-starburst\ngalaxies especially designed to test for the presence of strong carbon features\nof thermally pulsing AGB (TP-AGB) stars, as predicted by recent models of\nstellar population synthesis. Selection based on clear spectroscopic optical\nfeatures indicating the strong predominance of stellar populations with ages\nbetween 0.5 and 1.5 Gyr and redshift around 0.2 allows us to probe the spectral\nregion that is most affected by the carbon features of TP-AGB stars\n(unaccessible from the ground for z~0 galaxies) in the evolutionary phase when\ntheir impact on the IR luminosity is maximum. Nevertheless, none of the\nobserved galaxies display such features. Moreover the NIR fluxes relative to\noptical are consistent with those predicted by the original Bruzual & Charlot\n(2003) models, where the impact of TP-AGB stars is much lower than has been\nrecently advocated. \n\n"}
{"id": "1203.5596", "contents": "Title: Cosmology in the Newtonian limit Abstract: Numerical N-body simulations of large scale structure formation in the\nuniverse are based on Newtonian gravity. However, according to our current\nunderstanding, the most correct theory of gravity is general relativity. It is\ntherefore important to understand which degrees of freedom and which features\nare lost when the relativistic universe is approximated, or rather replaced, by\na Newtonian one. This is the main purpose of our investigation. We first define\nNewtonian cosmology and we give an overview on general relativity, both in its\nstandard and covariant formulations. We show how the two theories deal with\ninhomogeneous cosmological models and we introduce the backreaction conjecture.\nThen we review on how Newtonian gravity and general relativity relate to each\nother in the fully non-linear regime. For this purpose we discuss frame theory.\nWe carry out the same investigation also in the weak-field, small-velocity\nlimit of general relativity, and we derive the Newtonian limit resorting to the\nframework of post-Newtonian cosmology. Finally we remark that there are\nsolutions of Newtonian gravity which do not have any relativistic counterpart. \n\n"}
{"id": "1203.6892", "contents": "Title: Attractors, Universality and Inflation Abstract: Studies of the initial conditions for inflation have conflicting predictions\nfrom exponential suppression to inevitability. At the level of phase space,\nthis conflict arises from the competing intuitions of CPT invariance and\nthermodynamics. After reviewing this conflict, we enlarge the ensemble beyond\nphase space to include scalar potential data. We show how this leads to an\nimportant contribution from inflection point inflation, enhancing the\nlikelihood of inflation to an inverse cubic power law. In the process, we\nemphasize the attractor dynamics of the gravity-scalar system and the existence\nof universality classes from inflection point inflation. Finally, we comment on\nthe predictivity of inflation in light of these results. \n\n"}
{"id": "1204.1978", "contents": "Title: Cosmic dust in MgII absorbers Abstract: MgII absorbers induce reddening on background quasars. We measure this effect\nand infer the cosmic density of dust residing in these systems to be \\Omega\\ ~\n2e-6, in units of the critical density of the Universe, which is comparable to\nthe amount of dust found in galactic disks or about half the amount inferred to\nexist outside galaxies. We also estimate the neutral hydrogen abundance in MgII\nclouds to be \\Omega\\ ~ 1.5e-4, which is approximately 5% of hydrogen in stars\nin galaxies. This implies a dust-to-gas mass ratio for MgII clouds of about\n1/100, which is similar to the value for normal galaxies. This would support\nthe hypothesis of the outflow origin of MgII clouds, which are intrinsically\ndevoid of stars and hence have no sources of dust. Considerations of the dust\nabundance imply that the presence of MgII absorbers around galaxies lasts\neffectively for a few Gyr. High redshift absorbers allow us to measure the\nrest-frame extinction curve to 900 Angstroms at which the absorption by the\nLyman edge dominates over scattering by dust in the extinction opacity. \n\n"}
{"id": "1204.2280", "contents": "Title: Bonsai: A GPU Tree-Code Abstract: We present a gravitational hierarchical N-body code that is designed to run\nefficiently on Graphics Processing Units (GPUs). All parts of the algorithm are\nexecuted on the GPU which eliminates the need for data transfer between the\nCentral Processing Unit (CPU) and the GPU. Our tests indicate that the\ngravitational tree-code outperforms tuned CPU code for all parts of the\nalgorithm and show an overall performance improvement of more than a factor 20,\nresulting in a processing rate of more than 2.8 million particles per second. \n\n"}
{"id": "1204.3090", "contents": "Title: Fermionic warm dark matter produces galaxy cores in the observed scales\n  because of quantum mechanics Abstract: We derive the main physical galaxy properties: mass, halo radius, phase space\ndensity and velocity dispersion from a semiclassical gravitational approach in\nwhich fermionic WDM is treated quantum mechanically. They turn out to be\ncompatible with observations. Pauli Principle implies for the fermionic DM\nphase-space density Q(r) = rho(r)/sigma^3(r) the quantum bound Q(r) < K\nm^4/hbar^3, where m is the DM particle mass, sigma(r) is the DM velocity\ndispersion and K is a pure number of order one which we estimate. N-body galaxy\nsimulations produce a divergent Q(r) at r = 0 violating this quantum bound.\nCombining this bound with the behaviour of Q(r) from simulations, the virial\nand galaxy data on Q implies lower bounds on the halo radius and a minimal\ndistance r_{min} at which classical dynamics for DM fermions breaks down. This\nquantum bound rules out the presence of galaxy cusps for fermionic WDM, in\nagreement with astronomical observations, which show that the DM halos are\ncored. We show that compact dwarf galaxies are quantum objects supported\nagainst gravity by the fermionic WDM quantum pressure. Quantum mechanical\ncalculations become necessary to compute galaxy structures at kpc scales and\nbelow. Classical N-body simulations are not valid at scales below r_{min}. We\napply the Thomas-Fermi semiclassical approach to fermionic WDM galaxies and\nfind the physical magnitudes: mass, halo radius, phase-space density, velocity\ndispersion, consistent with observations especially for compact dwarf galaxies.\nNamely, fermionic WDM treated quantum mechanically, as it must be, reproduces\nthe sizes of the observed cores. The lightest known galaxy Willman I implies a\nlower bound for the WDM particle mass m > 0.96 keV. These results and the\nobserved galaxies with halo radius > 30 pc and halo mass > 4 10^5 M_sun provide\nfurther indication that the WDM particle mass m is in the range 1-2 keV. \n\n"}
{"id": "1204.4779", "contents": "Title: Paraiso : An Automated Tuning Framework for Explicit Solvers of Partial\n  Differential Equations Abstract: We propose Paraiso, a domain specific language embedded in functional\nprogramming language Haskell, for automated tuning of explicit solvers of\npartial differential equations (PDEs) on GPUs as well as multicore CPUs. In\nParaiso, one can describe PDE solving algorithms succinctly using tensor\nequations notation. Hydrodynamic properties, interpolation methods and other\nbuilding blocks are described in abstract, modular, re-usable and combinable\nforms, which lets us generate versatile solvers from little set of Paraiso\nsource codes.\n  We demonstrate Paraiso by implementing a compressive hydrodynamics solver. A\nsingle source code less than 500 lines can be used to generate solvers of\narbitrary dimensions, for both multicore CPUs and GPUs. We demonstrate both\nmanual annotation based tuning and evolutionary computing based automated\ntuning of the program. \n\n"}
{"id": "1204.5186", "contents": "Title: Higgs Dark Matter in UEDs: A Good WIMP with Bad Detection Prospects Abstract: We study the first Kaluza-Klein excitation of the Higgs boson in universal\nextra dimensions as a dark matter candidate. The first-level Higgs boson could\nbe the lightest Kaluza-Klein particle, which is stable due to the conservation\nof Kaluza-Klein parity, in non-minimal models where boundary localized terms\nmodify the mass spectrum. We calculate the relic abundance and find that it\nagrees with the observed dark matter density if the mass of the first-level\nHiggs boson is slightly above 2 TeV, not considering coannihilations and\nassuming no relative mass splitting among the first-level Kaluza-Klein modes.\nIn the case of coannihilations and a non-zero mass splitting, the mass of the\nfirst-level Higgs boson can range from 1 TeV to 4 TeV. We study also the\nprospects for detection of this dark matter candidate in direct as well as\nindirect detection experiments. Although the first-level Higgs boson is a\ntypical weakly interacting massive particle, an observation in any of the\nconventional experiments is very challenging. \n\n"}
{"id": "1204.6292", "contents": "Title: A Comparative Study of Local Galaxy Clusters: II: X-ray and SZ Scaling\n  Relations Abstract: We compare cluster scaling relations published for three different samples\nselected via X-ray and Sunyaev-Zel'dovich (SZ) signatures. We find tensions\ndriven mainly by two factors: i) systematic differences in the X-ray cluster\nobservables used to derive the scaling relations, and ii) uncertainty in the\nmodeling of how the gas mass of galaxy clusters scales with total mass. All\nscaling relations are in agreement after accounting for these two effects. We\ndescribe a multivariate scaling model that enables a fully self-consistent\ntreatment of multiple observational catalogs in the presence of property\ncovariance, and apply this formalism when interpreting published results. The\ncorrections due to scatter and observable covariance can be significant. For\ninstance, our predicted Ysz-Lx scaling relation differs from that derived using\nthe naive \"plug in\" method by \\approx 25%. Finally, we test the mass\nnormalization for each of the X-ray data sets we consider by applying a space\ndensity consistency test: we compare the observed REFLEX luminosity function to\nexpectations from published Lx-M relations convolved with the mass function for\na WMAP7 flat \\Lambda CDM model. \n\n"}
{"id": "1204.6354", "contents": "Title: Selecting Quasar Candidates by a SVM Classification System Abstract: We develop and demonstrate a classification system constituted by several\nSupport Vector Machines (SVM) classifiers, which can be applied to select\nquasar candidates from large sky survey projects, such as SDSS, UKIDSS, GALEX.\nHow to construct this SVM classification system is presented in detail. When\nthe SVM classification system works on the test set to predict quasar\ncandidates, it acquires the efficiency of 93.21% and the completeness of\n97.49%. In order to further prove the reliability and feasibility of this\nsystem, two chunks are randomly chosen to compare its performance with that of\nthe XDQSO method used for SDSS-III's BOSS. The experimental results show that\nthe high faction of overlap exists between the quasar candidates selected by\nthis system and those extracted by the XDQSO technique in the dereddened i-band\nmagnitude range between 17.75 and 22.45, especially in the interval of\ndereddened i-band magnitude < 20.0. In the two test areas, 57.38% and 87.15% of\nthe quasar candidates predicted by the system are also targeted by the XDQSO\nmethod. Similarly, the prediction of subcategories of quasars according to\nredshift achieves a high level of overlap with these two approaches. Depending\non the effectiveness of this system, the SVM classification system can be used\nto create the input catalog of quasars for the GuoShouJing Telescope (LAMOST)\nor other spectroscopic sky survey projects. In order to get higher confidence\nof quasar candidates, cross-result from the candidates selected by this SVM\nsystem with that by XDQSO method is applicable. \n\n"}
{"id": "1205.0282", "contents": "Title: A Distributed GPU-based Framework for real-time 3D Volume Rendering of\n  Large Astronomical Data Cubes Abstract: We present a framework to interactively volume-render three-dimensional data\ncubes using distributed ray-casting and volume bricking over a cluster of\nworkstations powered by one or more graphics processing units (GPUs) and a\nmulti-core CPU. The main design target for this framework is to provide an\nin-core visualization solution able to provide three-dimensional interactive\nviews of terabyte-sized data cubes. We tested the presented framework using a\ncomputing cluster comprising 64 nodes with a total of 128 GPUs. The framework\nproved to be scalable to render a 204 GB data cube with an average of 30 frames\nper second. Our performance analyses also compare between using NVIDIA Tesla\n1060 and 2050 GPU architectures and the effect of increasing the visualization\noutput resolution on the rendering performance. Although our initial focus, and\nthe examples presented in this work, is volume rendering of spectral data cubes\nfrom radio astronomy, we contend that our approach has applicability to other\ndisciplines where close to real-time volume rendering of terabyte-order 3D data\nsets is a requirement. \n\n"}
{"id": "1205.0282", "contents": "Title: A Distributed GPU-based Framework for real-time 3D Volume Rendering of\n  Large Astronomical Data Cubes Abstract: We present a framework to interactively volume-render three-dimensional data\ncubes using distributed ray-casting and volume bricking over a cluster of\nworkstations powered by one or more graphics processing units (GPUs) and a\nmulti-core CPU. The main design target for this framework is to provide an\nin-core visualization solution able to provide three-dimensional interactive\nviews of terabyte-sized data cubes. We tested the presented framework using a\ncomputing cluster comprising 64 nodes with a total of 128 GPUs. The framework\nproved to be scalable to render a 204 GB data cube with an average of 30 frames\nper second. Our performance analyses also compare between using NVIDIA Tesla\n1060 and 2050 GPU architectures and the effect of increasing the visualization\noutput resolution on the rendering performance. Although our initial focus, and\nthe examples presented in this work, is volume rendering of spectral data cubes\nfrom radio astronomy, we contend that our approach has applicability to other\ndisciplines where close to real-time volume rendering of terabyte-order 3D data\nsets is a requirement. \n\n"}
{"id": "1205.0364", "contents": "Title: A new perspective on Dark Energy modeling via Genetic Algorithms Abstract: We use Genetic Algorithms to extract information from several cosmological\nprobes, such as the type Ia supernovae (SnIa), the Baryon Acoustic Oscillations\n(BAO) and the growth rate of matter perturbations. This is done by implementing\na model independent and bias-free reconstruction of the various scales and\ndistances that characterize the data, like the luminosity $d_L(z)$ and the\nangular diameter distance $d_A(z)$ in the SnIa and BAO data, respectively, or\nthe dependence with redshift of the matter density $\\om_m(a)$ in the growth\nrate data, $f\\sigma_8(z)$. These quantities can then be used to reconstruct the\nexpansion history of the Universe, and the resulting Dark Energy (DE) equation\nof state $w(z)$ in the context of FRW models, or the mass radial function\n$\\om_M(r)$ in LTB models. In this way, the reconstruction is completely\nindependent of our prior bias. Furthermore, we use this method to test the\nEtherington relation, ie the well-known relation between the luminosity and the\nangular diameter distance, $\\eta \\equiv \\frac{d_L(z)}{(1+z)^2 d_A(z)}$, which\nis equal to 1 in metric theories of gravity. We find that the present data seem\nto suggest a 3-$\\sigma$ deviation from one at redshifts $z\\sim 0.5$. Finally,\nwe present a novel way, within the Genetic Algorithm paradigm, to analytically\nestimate the errors on the reconstructed quantities by calculating a Path\nIntegral over all possible functions that may contribute to the likelihood. We\nshow that this can be done regardless of the data being correlated or\nuncorrelated with each other and we also explicitly demonstrate that our\napproach is in good agreement with other error estimation techniques like the\nFisher Matrix approach and the Bootstrap Monte Carlo. \n\n"}
{"id": "1205.0847", "contents": "Title: Reconstruction of the Dark Energy equation of state Abstract: One of the main challenges of modern cosmology is to investigate the nature\nof dark energy in our Universe. The properties of such a component are normally\nsummarised as a perfect fluid with a (potentially) time-dependent\nequation-of-state parameter $w(z)$. We investigate the evolution of this\nparameter with redshift by performing a Bayesian analysis of current\ncosmological observations. We model the temporal evolution as piecewise linear\nin redshift between `nodes', whose $w$-values and redshifts are allowed to\nvary. The optimal number of nodes is chosen by the Bayesian evidence. In this\nway, we can both determine the complexity supported by current data and locate\nany features present in $w(z)$. We compare this node-based reconstruction with\nsome previously well-studied parameterisations: the Chevallier-Polarski-Linder\n(CPL), the Jassal-Bagla-Padmanabhan (JBP) and the Felice-Nesseris-Tsujikawa\n(FNT). By comparing the Bayesian evidence for all of these models we find an\nindication towards possible time-dependence in the dark energy\nequation-of-state. It is also worth noting that the CPL and JBP models are\nstrongly disfavoured, whilst the FNT is just significantly disfavoured, when\ncompared to a simple cosmological constant $w=-1$. We find that our node-based\nreconstruction model is slightly disfavoured with respect to the $\\Lambda$CDM\nmodel. \n\n"}
{"id": "1205.3607", "contents": "Title: Lepton asymmetries and primordial hypermagnetic helicity evolution Abstract: The hypermagnetic helicity density at the electroweak phase transition (EWPT)\nexceeds many orders of magnitude the galactic magnetic helicity density.\nTogether with previous magnetic helicity evolution calculations after the EWPT\nand hypermagnetic helicity conversion to the magnetic one at the EWPT, the\npresent calculation completes the description of the evolution of this\nimportant topological feature of cosmological magnetic fields. It suggests that\nif the magnetic field seeding the galactic dynamo has a primordial origin, it\nshould be substantially helical. This should be taken into account in scenarios\nof galactic magnetic field evolution with a cosmological seed. \n\n"}
{"id": "1205.4239", "contents": "Title: The optically unbiased GRB host (TOUGH) survey. VI. Radio observations\n  at z<1 and consistency with typical star-forming galaxies Abstract: The objective of this paper is to determine the level of obscured star\nformation activity and dust attenuation in a sample of gamma-ray burst (GRB)\nhosts; and to test the hypothesis that GRB hosts have properties consistent\nwith those of the general star-forming galaxy populations. We present a radio\ncontinuum survey of all z<1 GRB hosts in The Optically Unbiased GRB Host\n(TOUGH) sample supplemented with radio data for all (mostly pre-Swift) GRB-SN\nhosts discovered before October 2006. We present new radio data for 22 objects\nand have obtained a detection for three of them (GRB 980425, 021211, 031203;\nnone in the TOUGH sample), increasing the number of radio-detected GRB hosts\nfrom two to five. The star formation rate (SFR) for the GRB 021211 host of ~825\nMo yr^-1, the highest ever reported for a GRB host, places it in the category\nof ultraluminous infrared galaxies. We found that at least 63% of GRB hosts\nhave SFR < 100 Mo yr^-1 and at most 8% can have SFR > 500 Mo yr^-1. For the\nundetected hosts the mean radio flux (<35 uJy 3sigma) corresponds to an average\nSFR < 15 Mo yr^-1. Moreover, ~88% of the z<1 GRB hosts have ultraviolet dust\nattenuation A_UV < 6.7 mag (visual attenuation A_V < 3 mag). Hence we did not\nfind evidence for large dust obscuration in a majority of GRB hosts. Finally,\nwe found that the distributions of SFRs and A_UV of GRB hosts are consistent\nwith those of Lyman break galaxies, Halpha emitters at similar redshifts and of\ngalaxies from cosmological simulations. The similarity of the GRB population\nwith other star-forming galaxies is consistent with the hypothesis that GRBs, a\nleast at z<1, trace a large fraction of all star formation, and are therefore\nless biased indicators than once thought. \n\n"}
{"id": "1205.4245", "contents": "Title: The Correlated Formation Histories of Massive Galaxies and Their Dark\n  Matter Halos Abstract: Using observations in the COSMOS field, we report an intriguing correlation\nbetween the star formation activity of massive (~10^{11.4}\\msol) central\ngalaxies, their stellar masses, and the large-scale (~10 Mpc) environments of\ntheir group-mass (~10^{13.6}\\msol) dark matter halos. Probing the redshift\nrange z=[0.2,1.0], our measurements come from two independent sources: an X-ray\ndetected group catalog and constraints on the stellar-to-halo mass relation\nderived from a combination of clustering and weak lensing statistics. At z=1,\nwe find that the stellar mass in star-forming centrals is a factor of two less\nthan in passive centrals at the same halo mass. This implies that the presence\nor lack of star formation in group-scale centrals cannot be a stochastic\nprocess. By z=0, the offset reverses, probably as a result of the different\ngrowth rates of these objects. A similar but weaker trend is observed when\ndividing the sample by morphology rather than star formation. Remarkably, we\nfind that star-forming centrals at z~1 live in groups that are significantly\nmore clustered on 10 Mpc scales than similar mass groups hosting passive\ncentrals. We discuss this signal in the context of halo assembly and recent\nsimulations, suggesting that star-forming centrals prefer halos with higher\nangular momentum and/or formation histories with more recent growth; such halos\nare known to evolve in denser large-scale environments. If confirmed, this\nwould be evidence of an early established link between the assembly history of\nhalos on large scales and the future properties of the galaxies that form\ninside them. \n\n"}
{"id": "1205.4747", "contents": "Title: Principles of High-Dimensional Data Visualization in Astronomy Abstract: Astronomical researchers often think of analysis and visualization as\nseparate tasks. In the case of high-dimensional data sets, though, interactive\nexploratory data visualization can give far more insight than an approach where\ndata processing and statistical analysis are followed, rather than accompanied,\nby visualization. This paper attempts to charts a course toward \"linked view\"\nsystems, where multiple views of high-dimensional data sets update live as a\nresearcher selects, highlights, or otherwise manipulates, one of several open\nviews. For example, imagine a researcher looking at a 3D volume visualization\nof simulated or observed data, and simultaneously viewing statistical displays\nof the data set's properties (such as an x-y plot of temperature vs. velocity,\nor a histogram of vorticities). Then, imagine that when the researcher selects\nan interesting group of points in any one of these displays, that the same\npoints become a highlighted subset in all other open displays. Selections can\nbe graphical or algorithmic, and they can be combined, and saved. For tabular\n(ASCII) data, this kind of analysis has long been possible, even though it has\nbeen under-used in Astronomy. The bigger issue for Astronomy and several other\n\"high-dimensional\" fields is the need systems that allow full integration of\nimages and data cubes within a linked-view environment. The paper concludes its\nhistory and analysis of the present situation with suggestions that look toward\ncooperatively-developed open-source modular software as a way to create an\nevolving, flexible, high-dimensional, linked-view visualization environment\nuseful in astrophysical research. \n\n"}
{"id": "1205.5028", "contents": "Title: Type Ia Single Degenerate Survivors Must Be Overluminous Abstract: In the single-degenerate (SD) channel of a Type Ia supernovae (SN Ia)\nexplosion, a main-sequence (MS) donor star survives the explosion but it is\nstripped of mass and shock heated. An essentially unavoidable consequence of\nmass loss during the explosion is that the companion must have an overextended\nenvelope after the explosion. While this has been noted previously, it has not\nbeen strongly emphasized as an inevitable consequence. We calculate the future\nevolution of the companion by injecting 2-6 10^47 ergs into the stellar\nevolution model of a 1 Msun donor star based on the post-explosion progenitors\nseen in simulations. We find that, due to the Kelvin-Helmholtz collapse of the\nenvelope, the companion must become significantly more luminous (10 - 10^3\nLsun) for a long period of time (10^3 - 10^4 years). The lack of such a\nluminous \"leftover\" star in the LMC supernova remnant SNR 0609-67.5 provides\nanother piece of evidence against the SD scenario. We also show that none of\nthe stars proposed as the survivors of the Tycho supernova, including Tycho G,\ncould plausibly be the donor star. Additionally, luminous donors closer than\n~10 Mpc should be observable with the Hubble Space Telescope starting ~2 years\npost-peak. Such systems include SN 1937C, SN 1972E, SN 1986G, and SN 2011fe.\nThus, the SD channel is already ruled out for at least two nearby SNe Ia and\ncan be easily tested for a number of additional ones. We also discuss similar\nimplications for the companions of core-collapse SNe. \n\n"}
{"id": "1205.5313", "contents": "Title: BLOBCAT: Software to Catalogue Flood-Filled Blobs in Radio Images of\n  Total Intensity and Linear Polarization Abstract: We present BLOBCAT, new source extraction software that utilises the flood\nfill algorithm to detect and catalogue blobs, or islands of pixels representing\nsources, in two-dimensional astronomical images. The software is designed to\nprocess radio-wavelength images of both Stokes I intensity and linear\npolarization, the latter formed through the quadrature sum of Stokes Q and U\nintensities or as a byproduct of rotation measure synthesis. We discuss an\nobjective, automated method by which estimates of position-dependent background\nroot-mean-square noise may be obtained and incorporated into BLOBCAT's\nanalysis. We derive and implement within BLOBCAT corrections for two systematic\nbiases to enable the flood fill algorithm to accurately measure flux densities\nfor Gaussian sources. We discuss the treatment of non-Gaussian sources in light\nof these corrections. We perform simulations to validate the flux density and\npositional measurement performance of BLOBCAT, and we benchmark the results\nagainst those of a standard Gaussian fitting task. We demonstrate that BLOBCAT\nexhibits accurate measurement performance in total intensity and, in\nparticular, linear polarization. BLOBCAT is particularly suited to the analysis\nof large survey data. The BLOBCAT software, supplemented with test data to\nillustrate its use, is available at: http://blobcat.sourceforge.net/ . \n\n"}
{"id": "1205.5905", "contents": "Title: Fundamental properties of Fanaroff-Riley II radio galaxies investigated\n  via Monte Carlo simulations Abstract: [Abridged] Radio galaxies and quasars are among the largest and most powerful\nsingle objects known and are believed to have had a significant impact on the\nevolving Universe and its large scale structure. We explore the intrinsic and\nextrinsic properties of the population of FRII objects (kinetic luminosities,\nlifetimes, and the central densities of their environments). In particular, the\nradio and kinetic luminosity functions of FRIIs are investigated using the\ncomplete, flux limited radio catalogues of 3CRR and Best et al. We construct\nmultidimensional Monte Carlo simulations using semi-analytical models of FRII\nradio source growth to create artificial samples of radio galaxies. Unlike\nprevious studies, we compare radio luminosity functions found with both the\nobserved and simulated data to explore the fundamental source parameters. We\nallow the source physical properties to co-evolve with redshift, and we find\nthat all the investigated parameters most likely undergo cosmological\nevolution. Strikingly, we find that the break in the kinetic luminosity\nfunction must undergo redshift evolution of at least (1+z)^3. The fundamental\nparameters are strongly degenerate, and independent constraints are necessary\nto draw more precise conclusions. We use the estimated kinetic luminosity\nfunctions to set constraints on the duty cycles of these powerful radio\nsources. A comparison of the duty cycles of powerful FRIIs with those\ndetermined from radiative luminosities of AGN of comparable black hole mass\nsuggests a transition in behaviour from high to low redshifts, corresponding to\neither a drop in the typical black hole mass of powerful FRIIs at low\nredshifts, or a transition to a kinetically-dominated, radiatively-inefficient\nFRII population. \n\n"}
{"id": "1205.6012", "contents": "Title: Exact Hairy Black Holes and their Modification to the Universal Law of\n  Gravitation Abstract: In this paper two things are done. First, it is pointed out the existence of\nexact asymptotically flat, spherically symmetric black holes when a self\ninteracting, minimally coupled scalar field is the source of the energy\nmomentum of the Einstein equations in four dimensions. The scalar field\npotential is the recently found to be compatible with the hairy generalization\nof the Plebanski-Demianski solution of general relativity. This paper describes\nthe spherically symmetric solutions that smoothly connect the Schwarzschild\nblack hole with its hairy counterpart. The geometry and scalar field are\neverywhere regular except at the usual Schwarzschild like singularity inside\nthe black hole. The scalar field energy momentum tensor satisfies the null\nenergy condition in the static region of the spacetime. The first law holds\nwhen the parameters of the scalar field potential are fixed under\nthermodynamical variation. Secondly, it is shown that an extra, dimensionless\nparameter, present in the hairy solution, allows to modify the gravitational\nfield of a spherically symmetric black hole in a remarkable way. When the\ndimensionless parameter is increased, the scalar field generates a flat\ngravitational potential, that however asymptotically matches the Schwarzschild\ngravitational field. Finally, it is shown that a positive cosmological constant\ncan render the scalar field potential convex if the parameters are within a\nspecific rank. \n\n"}
{"id": "1205.6492", "contents": "Title: 150 New transiting planet candidates from Kepler Q1-Q6 data Abstract: We have performed an extensive search for planet candidates in the publicly\navailable Kepler Long Cadence data from quarters Q1 through Q6. The search\nmethod consists of initial de-trending of the data, applying the trend\nfiltering algorithm, searching for transit signals with the Box Least Squares\nfitting method in three frequency domains, visual inspection of the potential\ntransit candidates, and in-depth analysis of the shortlisted candidates. In\nthis paper we present 150 new periodic planet candidates and 7 single transit\nevents, 72 of which are in multiple systems. The periods of these planet\ncandidates vary from $\\sim$0.17\\,day to $\\sim$ 440\\,day. 124 of the planet\ncandidates have radii smaller than 3 \\rearth. We recover 82.5% of the Batalha\net al. (2012) KOI catalog. We also report 40 newly identified false\npositives---systems that look like transiting planets, but are probably due to\nblended eclipsing binaries. Our search improves the statistics in the short\nperiod and small planet radii parameter ranges. \n\n"}
{"id": "1205.6495", "contents": "Title: On the anomalous afterglow seen in a chameleon afterglow search Abstract: We present data from our investigation of the anomalous orange-colored\nafterglow that was seen in the GammeV Chameleon Afterglow Search (CHASE). These\ndata includes information about the broad band color of the observed glow, the\nrelationship between the glow and the temperature of the apparatus, and other\ndata taken prior to and during the science operations of CHASE. While differing\nin several details, the generic properties of the afterglow from CHASE are\nsimilar to luminescence seen in some vacuum compounds. Contamination from this,\nor similar, luminescent signatures will likely impact the design of\nimplementation of future experiments involving single photon detectors and high\nintensity light sources in a cryogenic environment. \n\n"}
{"id": "1206.1064", "contents": "Title: The Palomar Transient Factory photometric catalog 1.0 Abstract: We construct a photometrically calibrated catalog of non-variable sources\nfrom the Palomar Transient Factory (PTF) observations. The first version of\nthis catalog presented here, the PTF photometric catalog 1.0, contains\ncalibrated R_PTF-filter magnitudes for about 21 million sources brighter than\nmagnitude 19, over an area of about 11233 deg^2. The magnitudes are provided in\nthe PTF photometric system, and the color of a source is required in order to\nconvert these magnitudes into other magnitude systems. We estimate that the\nmagnitudes in this catalog have typical accuracy of about 0.02 mag with respect\nto magnitudes from the Sloan Digital Sky Survey. The median repeatability of\nour catalog's magnitudes for stars between 15 and 16 mag, is about 0.01 mag,\nand it is better than 0.03 mag for 95% of the sources in this magnitude range.\nThe main goal of this catalog is to provide reference magnitudes for\nphotometric calibration of visible light observations. Subsequent versions of\nthis catalog, which will be published incrementally online, will be extended to\na larger sky area and will also include g_PTF-filter magnitudes, as well as\nvariability and proper motion information. \n\n"}
{"id": "1206.2169", "contents": "Title: Dark Matter Search with liquid Noble Gases Abstract: Dark matter detectors using the liquid noble gases xenon and argon as WIMP\ntargets have evolved rapidly in the last decade and will continue to play a\nmajor role in the field. Due to the possibility to scale these detectors to\nlarger masses relatively easily, noble liquids will likely be the first\ntechnology realizing a detector with a ton-scale target mass. In this article,\nwe summarize the basic concepts of liquid noble gas dark matter detectors and\nreview the current experimental status. \n\n"}
{"id": "1206.2396", "contents": "Title: The lithium problem, a phenomenologist's perspective Abstract: Thirty years after the first observation of the 7Li isotope in the atmosphere\nof metal-poor halo stars, the puzzle about its origin persists. Do current\nobservations still support the existence of a \"plateau\": a single value of\nlithium abundance, constant over several orders of magnitude in the metallicity\nof the target star? If this plateau exists, is it universal in terms of\nobservational loci of target stars? Is it possible to explain such observations\nwith known astrophysical processes? Can yet poorly explored astrophysical\nmechanisms explain the observations or do we need to invoke physics beyond the\nstandard model of Cosmology and/or the standard model of Particle Physics to\nexplain them? Is there a 6Li problem, and is it connected to the 7Li one? These\nquestions have been discussed at the Paris workshop Lithium in the Cosmos, and\nI summarize here its contents, providing an overview from the perspective of a\nphenomenologist. \n\n"}
{"id": "1206.3307", "contents": "Title: Planets Around Low-Mass Stars (PALMS). II. A Low-Mass Companion to the\n  Young M Dwarf GJ 3629 Separated By 0.2\" Abstract: We present the discovery of a 0.2\" companion to the young M dwarf GJ 3629 as\npart of our high contrast adaptive optics imaging search for giant planets\naround low-mass stars with the Keck-II and Subaru telescopes. Two epochs of\nimaging confirm the pair is co-moving and reveal signs of orbital motion. The\nprimary exhibits saturated X-ray emission, which together with its UV\nphotometry from GALEX point to an age younger than ~300 Myr. At these ages the\ncompanion lies below the hydrogen burning limit with a model-dependent mass of\n46 +/- 16 Mjup based on the system's photometric distance of 22 +/- 3 pc.\nResolved YJHK photometry of the pair indicates a spectral type of M7 +/- 2 for\nGJ 3629 B. With a projected separation of 4.4 +/- 0.6 AU and an estimated\norbital period of 21 +/- 5 yr, GJ 3629 AB is likely to yield a dynamical mass\nin the next several years, making it one of only a handful of brown dwarfs to\nhave a measured mass and an age constrained from the stellar primary. \n\n"}
{"id": "1206.5004", "contents": "Title: How do minor mergers promote inside-out growth of ellipticals,\n  transforming the size, density profile and dark matter fraction? Abstract: There is observational evidence for inside-out growth of elliptical galaxies\nsince $z \\gtrsim 2-3$, which is not driven by in-situ star formation. Many\nsystems at high redshift have small sizes $\\sim 1kpc$ and surface brightness\nprofiles with low Sersic indices n. The most likely descendants have, on\naverage, grown by a factor of two in mass and a factor of four in size,\nindicating $r \\propto M^{\\alpha}$ with $\\alpha \\gtrsim 2$. They also have\nsurface brightness profiles with $n \\gtrsim 5$. This evolution can be\nqualitatively explained on the basis of two assumptions: compact ellipticals\npredominantly grow by collisionless minor or intermediate 'dry' mergers, and\nthey are embedded in massive dark matter halos. We draw these conclusions from\nidealized collisionless mergers spheroidal galaxies - with and without dark\nmatter - with mass ratios of 1:1, 1:5, and 1:10. The sizes evolve as $r \\propto\nM^{\\alpha}$ with $\\alpha < 2$ for mass-ratios of 1:1. For minor mergers of\ngalaxies embedded in dark matter halos, the sizes grow significantly faster and\nthe profile shapes change more rapidly. Mergers with moderate mass-ratios of\n1:5 give $\\alpha \\sim 2.3$ and a final Sersic index of $n = 9.5$ after doubling\nthe stellar mass. This is accompanied by a significant increase of the dark\nmatter fraction within the stellar half-mass radius, driven by the strong size\nincrease probing larger, dark matter dominated regions. Only a few intermediate\nmass-ratio mergers of galaxies embedded in massive dark matter halos can result\nin the observed concurrent inside-out growth and the rapid evolution in profile\nshapes. Apart from negative stellar metallicity gradients such a 'minor' merger\nscenario also predicts significantly lower dark matter fractions for $z \\sim 2$\ncompact quiescent galaxies and their rare present day analogues (abbreviated). \n\n"}
{"id": "1206.5006", "contents": "Title: A General Class of Lagrangian Smoothed Particle Hydrodynamics Methods\n  and Implications for Fluid Mixing Problems Abstract: Various formulations of smooth-particle hydrodynamics (SPH) have been\nproposed, intended to resolve certain difficulties in the treatment of fluid\nmixing instabilities. Most have involved changes to the algorithm which either\nintroduce artificial correction terms or violate arguably the greatest\nadvantage of SPH over other methods: manifest conservation of energy, entropy,\nmomentum, and angular momentum. Here, we show how a class of alternative SPH\nequations of motion (EOM) can be derived self-consistently from a discrete\nparticle Lagrangian (guaranteeing manifest conservation) in a manner which\ntremendously improves treatment of instabilities and contact discontinuities.\nSaitoh & Makino recently noted that the volume element used to discretize the\nEOM does not need to explicitly invoke the mass density (as in the 'standard'\napproach); we show how this insight, and the resulting degree of freedom, can\nbe incorporated into the rigorous Lagrangian formulation that retains ideal\nconservation properties and includes the 'Grad-h' terms that account for\nvariable smoothing lengths. We derive a general EOM for any choice of volume\nelement (particle 'weights') and method of determining smoothing lengths. We\nthen specify this to a 'pressure-entropy formulation' which resolves problems\nin the traditional treatment of fluid interfaces. Implementing this in a new\nversion of the GADGET code, we show it leads to good performance in mixing\nexperiments (e.g. Kelvin-Helmholtz & blob tests). And conservation is\nmaintained even in strong shock/blastwave tests, where formulations without\nmanifest conservation produce large errors. This also improves the treatment of\nsub-sonic turbulence, and lessens the need for large kernel particle numbers.\nThe code changes are trivial and entail no additional numerical expense. This\nprovides a general framework for self-consistent derivation of different\n'flavors' of SPH. \n\n"}
{"id": "1206.5021", "contents": "Title: SkyQuery: An Implementation of a Parallel Probabilistic Join Engine for\n  Cross-Identification of Multiple Astronomical Databases Abstract: Multi-wavelength astronomical studies require cross-identification of\ndetections of the same celestial objects in multiple catalogs based on\nspherical coordinates and other properties. Because of the large data volumes\nand spherical geometry, the symmetric N-way association of astronomical\ndetections is a computationally intensive problem, even when sophisticated\nindexing schemes are used to exclude obviously false candidates. Legacy\nastronomical catalogs already contain detections of more than a hundred million\nobjects while the ongoing and future surveys will produce catalogs of billions\nof objects with multiple detections of each at different times. The varying\nstatistical error of position measurements, moving and extended objects, and\nother physical properties make it necessary to perform the cross-identification\nusing a mathematically correct, proper Bayesian probabilistic algorithm,\ncapable of including various priors. One time, pair-wise cross-identification\nof these large catalogs is not sufficient for many astronomical scenarios.\nConsequently, a novel system is necessary that can cross-identify multiple\ncatalogs on-demand, efficiently and reliably. In this paper, we present our\nsolution based on a cluster of commodity servers and ordinary relational\ndatabases. The cross-identification problems are formulated in a language based\non SQL, but extended with special clauses. These special queries are\npartitioned spatially by coordinate ranges and compiled into a complex workflow\nof ordinary SQL queries. Workflows are then executed in a parallel framework\nusing a cluster of servers hosting identical mirrors of the same data sets. \n\n"}
{"id": "1206.6352", "contents": "Title: Telescope Bibliographies: an Essential Component of Archival Data\n  Management and Operations Abstract: Assessing the impact of astronomical facilities rests upon an evaluation of\nthe scientific discoveries which their data have enabled. Telescope\nbibliographies, which link data products with the literature, provide a way to\nuse bibliometrics as an impact measure for the underlying data. In this paper\nwe argue that the creation and maintenance of telescope bibliographies should\nbe considered an integral part of an observatory's operations. We review the\nexisting tools, services, and workflows which support these curation\nactivities, giving an estimate of the effort and expertise required to maintain\nan archive-based telescope bibliography. \n\n"}
{"id": "1206.6501", "contents": "Title: On the stability criteria for equatorial circular orbits in Galactic\n  Dynamics: I.Newtonian Thin Disks Abstract: We make a revision of the stability criteria for equatorial circular orbits,\nobtained from the epicyclic approximation, which is widely used in Newtonian\nmodels for axisymmetric galaxies. We find that, for the case of thin disk\nmodels, the criteria of vertical stability must be reformulated, due to the\ndiscontinuity in the gravitational field. We show that, for a model\ncharacterized by a surface mass density $\\Sigma$, the necessary and sufficient\ncondition to have vertically stable orbits is that $\\Sigma>0$. On the other\nhand, the criteria for radial stability is the same as in thick diks, i.e. that\nthe epicyclic frequency is positive. \n\n"}
{"id": "1206.6502", "contents": "Title: THC: a new high-order finite-difference high-resolution shock-capturing\n  code for special-relativistic hydrodynamics Abstract: We present THC: a new high-order flux-vector-splitting code for Newtonian and\nspecial-relativistic hydrodynamics designed for direct numerical simulations of\nturbulent flows. Our code implements a variety of different reconstruction\nalgorithms, such as the popular weighted essentially non oscillatory and\nmonotonicity-preserving schemes, or the more specialised bandwidth-optimised\nWENO scheme that has been specifically designed for the study of compressible\nturbulence. We show the first systematic comparison of these schemes in\nNewtonian physics as well as for special-relativistic flows. In particular we\nwill present the results obtained in simulations of grid-aligned and oblique\nshock waves and nonlinear, large-amplitude, smooth adiabatic waves. We will\nalso discuss the results obtained in classical benchmarks such as the\ndouble-Mach shock reflection test in Newtonian physics or the linear and\nnonlinear development of the relativistic Kelvin-Helmholtz instability in two\nand three dimensions. Finally, we study the turbulent flow induced by the\nKelvin-Helmholtz instability and we show that our code is able to obtain\nwell-converged velocity spectra, from which we benchmark the effective\nresolution of the different schemes. \n\n"}
{"id": "1206.7106", "contents": "Title: A compact and robust method for full Stokes spectropolarimetry Abstract: We present an approach to spectropolarimetry which requires neither moving\nparts nor time dependent modulation, and which offers the prospect of achieving\nhigh sensitivity. The technique applies equally well, in principle, in the\noptical, UV or IR. The concept, which is one of those generically known as\nchanneled polarimetry, is to encode the polarization information at each\nwavelength along the spatial dimension of a 2D data array using static, robust\noptical components. A single two-dimensional data frame contains the full\npolarization information and can be configured to measure either two or all of\nthe Stokes polarization parameters. By acquiring full polarimetric information\nin a single observation, we simplify polarimetry of transient sources and in\nsituations where the instrument and target are in relative motion. The\nrobustness and simplicity of the approach, coupled to its potential for high\nsensitivity, and applicability over a wide wavelength range, is likely to prove\nuseful for applications in challenging environments such as space. \n\n"}
{"id": "1207.2311", "contents": "Title: High-Frequency Quasi-Periodic Oscillations in black-hole binaries Abstract: We present the results of the analysis of a large database of X-ray\nobservations of 22 galactic black-hole transients with the Rossi X-Ray timing\nexplorer throughout its operative life for a total exposure time of ~12 Ms. We\nexcluded persistent systems and the peculiar source GRS 1915+105, as well as\nthe most recently discovered sources. The semi-automatic homogeneous analysis\nwas aimed at the detection of high-frequency (100-1000 Hz) quasi-periodic\noscillations (QPO), of which several cases were previously reported in the\nliterature. After taking into account the number of independent trials, we\nobtained 11 detections from two sources only: XTE J1550-564 and GRO J1655-40.\nFor the former, the detected frequencies are clustered around 180 Hz and 280\nHz, as previously found. For the latter, the previously-reported dichotomy\n300-450 Hz is found to be less sharp. We discuss our results in comparison with\nkHz QPO in neutron-star X-ray binaries and the prospects for future timing\nX-ray missions. \n\n"}
{"id": "1207.2367", "contents": "Title: A fully parallel, high precision, N-body code running on hybrid\n  computing platforms Abstract: We present a new implementation of the numerical integration of the\nclassical, gravitational, N-body problem based on a high order Hermite's\nintegration scheme with block time steps, with a direct evaluation of the\nparticle-particle forces. The main innovation of this code (called HiGPUs) is\nits full parallelization, exploiting both OpenMP and MPI in the use of the\nmulticore Central Processing Units as well as either Compute Unified Device\nArchitecture (CUDA) or OpenCL for the hosted Graphic Processing Units. We\ntested both performance and accuracy of the code using up to 256 GPUs in the\nsupercomputer IBM iDataPlex DX360M3 Linux Infiniband Cluster provided by the\nitalian supercomputing consortium CINECA, for values of N up to 8 millions. We\nwere able to follow the evolution of a system of 8 million bodies for few\ncrossing times, task previously unreached by direct summation codes. The code\nis freely available to the scientific community. \n\n"}
{"id": "1207.3393", "contents": "Title: GenASiS: General Astrophysical Simulation System. II. Nonrelativistic\n  Hydrodynamics Abstract: In this paper, the second in a series, we document the algorithms and solvers\nfor compressible nonrelativistic hydrodynamics implemented in GenASiS (General\nAstrophysical Simulation System)---a new code being developed initially and\nprimarily, though by no means exclusively, for the simulation of core-collapse\nsupernovae. In the Mathematics division of GenASiS we introduce Solvers, which\nincludes finite-volume updates for generic hyperbolic BalanceEquations and\nordinary differential equation integration Steps. We also introduce the Physics\ndivision of GenASiS; this extends the Manifolds division of Mathematics into\nphysical Spaces, defines StressEnergies, and combines these into Universes. We\nbenchmark the hydrodynamics capabilities of GenASiS against many standard test\nproblems; the results illustrate the basic competence of our implementation,\ndemonstrate the manifest superiority of the HLLC over the HLL Riemann solver in\na number of interesting cases, and provide preliminary indications of the\ncode's ability to scale and to function with cell-by-cell fixed-mesh\nrefinement. \n\n"}
{"id": "1207.3923", "contents": "Title: Managing Research Data in Big Science Abstract: The project which led to this report was funded by JISC in 2010--2011 as part\nof its 'Managing Research Data' programme, to examine the way in which Big\nScience data is managed, and produce any recommendations which may be\nappropriate.\n  Big science data is different: it comes in large volumes, and it is shared\nand exploited in ways which may differ from other disciplines. This project has\nexplored these differences using as a case-study Gravitational Wave data\ngenerated by the LSC, and has produced recommendations intended to be useful\nvariously to JISC, the funding council (STFC) and the LSC community.\n  In Sect. 1 we define what we mean by 'big science', describe the overall data\nculture there, laying stress on how it necessarily or contingently differs from\nother disciplines.\n  In Sect. 2 we discuss the benefits of a formal data-preservation strategy,\nand the cases for open data and for well-preserved data that follow from that.\nThis leads to our recommendations that, in essence, funders should adopt rather\nlight-touch prescriptions regarding data preservation planning: normal data\nmanagement practice, in the areas under study, corresponds to notably good\npractice in most other areas, so that the only change we suggest is to make\nthis planning more formal, which makes it more easily auditable, and more\namenable to constructive criticism.\n  In Sect. 3 we briefly discuss the LIGO data management plan, and pull\ntogether whatever information is available on the estimation of digital\npreservation costs.\n  The report is informed, throughout, by the OAIS reference model for an open\narchive. \n\n"}
{"id": "1207.4235", "contents": "Title: Dark Matter and Enhanced Higgs to Di-photon Rate from Vector-like\n  Leptons Abstract: In this paper, we study an extension of the standard model with a vector-like\ngeneration of leptons. This model provides a viable dark matter candidate and a\npossibility to enhance the Higgs decay rate into a pair of photons. We evaluate\nconstraints from electroweak precision tests and from vacuum stability, and\nfind that the latter provide an upper limit on the lepton Yukawa couplings. A\nlarge enhancement of the Higgs di-photon rate can therefore only be obtained\nwhen the mass of the lightest charged lepton is close to the LEP limit. The\nrelic density constraint suggests a co-annihilation scenario with a small mass\ndifference between the lightest charged and neutral leptons, which also weakens\nthe LEP limit on the lightest charged lepton mass and allows for larger Higgs\ndi-photon decay rates. Cross sections for direct detection of the dark matter\ncandidate are calculated, and prospects for detecting the new particles at the\nLHC are discussed briefly. \n\n"}
{"id": "1207.5872", "contents": "Title: Early science with Korean VLBI network: the QCAL-1 43GHz calibrator\n  survey Abstract: This paper presents the catalog of correlated flux densities in three ranges\nof baseline projection lengths of 637 sources from a 43 GHz (Q-band) survey\nobserved with the Korean VLBI Network. Of them, 623 sources have not been\nobserved before at Q-band with VLBI. The goal of this work in the early science\nphase of the new VLBI array is twofold: to evaluate the performance of the new\ninstrument that operates in a frequency range of 22-129 GHz and to build a list\nof objects that can be used as targets and as calibrators. We have observed the\nlist of 799 target sources with declinations down to -40 degrees. Among them,\n724 were observed before with VLBI at 22 GHz and had correlated flux densities\ngreater than 200 mJy. The overall detection rate is 78%. The detection limit,\ndefined as the minimum flux density for a source to be detected with 90%\nprobability in a single observation, was in a range of 115-180 mJy depending on\ndeclination. However, some sources as weak as 70 mJy have been detected. Of 623\ndetected sources, 33 objects are detected for the first time in VLBI mode. We\ndetermined their coordinates with the median formal uncertainty 20 mas. The\nresults of this work set the basis for future efforts to build the complete\nflux-limited sample of extragalactic sources at frequencies 22 GHz and higher\nat 3/4 of the celestial sphere. \n\n"}
{"id": "1207.5897", "contents": "Title: The SINS/zC-SINF survey of z~2 galaxy kinematics: Outflow properties Abstract: Based on SINFONI Ha, [NII] and [SII] AO data of 30 z \\sim 2 star-forming\ngalaxies (SFGs) from the SINS and zcSINF surveys, we find a strong correlation\nof the Ha broad flux fraction with the star formation surface density of the\ngalaxy, with an apparent threshold for strong outflows occurring at 1 Msun\nyr^-1 kpc^-2. Above this threshold, we find that SFGs with logm_\\ast>10 have\nsimilar or perhaps greater wind mass loading factors (eta = Mdotout/SFR) and\nfaster outflow velocities than lower mass SFGs. This trend suggests that the\nmajority of outflowing gas at z \\sim 2 may derive from high-mass SFGs, and that\nthe z \\sim 2 mass-metallicity relation is driven more by dilution of enriched\ngas in the galaxy gas reservoir than by the efficiency of outflows. The mass\nloading factor is also correlated with the SFR and inclination, such that more\nstar-forming and face-on galaxies launch more powerful outflows. For galaxies\nthat have evidence for strong outflows, we find that the broad emission is\nspatially extended to at least the half-light radius (\\sim a few kpc). We\npropose that the observed threshold for strong outflows and the observed mass\nloading of these winds can be explained by a simple model wherein break-out of\nwinds is governed by pressure balance in the disk. Using the ratio of the [SII]\ndoublet in a broad and narrow component, we find that outflowing gas has a\ndensity of \\sim10-100 cm^-3, significantly less than that of the star forming\ngas (600 cm^-3). \n\n"}
{"id": "1207.6005", "contents": "Title: The expected performance of stellar parametrization with Gaia\n  spectrophotometry Abstract: Gaia will obtain astrometry and spectrophotometry for essentially all sources\nin the sky down to a broad band magnitude limit of G=20, an expected yield of\n10^9 stars. Its main scientific objective is to reveal the formation and\nevolution of our Galaxy through chemo-dynamical analysis. In addition to\ninferring positions, parallaxes and proper motions from the astrometry, we must\nalso infer the astrophysical parameters of the stars from the\nspectrophotometry, the BP/RP spectrum. Here we investigate the performance of\nthree different algorithms (SVM, ILIUM, Aeneas) for estimating the effective\ntemperature, line-of-sight interstellar extinction, metallicity and surface\ngravity of A-M stars over a wide range of these parameters and over the full\nmagnitude range Gaia will observe (G=6-20mag). One of the algorithms, Aeneas,\ninfers the posterior probability density function over all parameters, and can\noptionally take into account the parallax and the Hertzsprung-Russell diagram\nto improve the estimates. For all algorithms the accuracy of estimation depends\non G and on the value of the parameters themselves, so a broad summary of\nperformance is only approximate. For stars at G=15 with less than two\nmagnitudes extinction, we expect to be able to estimate Teff to within 1%, logg\nto 0.1-0.2dex, and [Fe/H] (for FGKM stars) to 0.1-0.2dex, just using the BP/RP\nspectrum (mean absolute error statistics are quoted). Performance degrades at\nlarger extinctions, but not always by a large amount. Extinction can be\nestimated to an accuracy of 0.05-0.2mag for stars across the full parameter\nrange with a priori unknown extinction between 0 and 10mag. Performance\ndegrades at fainter magnitudes, but even at G=19 we can estimate logg to better\nthan 0.2dex for all spectral types, and [Fe/H] to within 0.35dex for FGKM\nstars, for extinctions below 1mag. \n\n"}
{"id": "1208.0050", "contents": "Title: The Atacama Cosmology Telescope: Data Characterization and Map Making Abstract: We present a description of the data reduction and mapmaking pipeline used\nfor the 2008 observing season of the Atacama Cosmology Telescope (ACT). The\ndata presented here at 148 GHz represent 12% of the 90 TB collected by ACT from\n2007 to 2010. In 2008 we observed for 136 days, producing a total of 1423 hours\nof data (11 TB for the 148 GHz band only), with a daily average of 10.5 hours\nof observation. From these, 1085 hours were devoted to a 850 deg^2 stripe (11.2\nhours by 9.1 deg) centered on a declination of -52.7 deg, while 175 hours were\ndevoted to a 280 deg^2 stripe (4.5 hours by 4.8 deg) centered at the celestial\nequator. We discuss sources of statistical and systematic noise, calibration,\ntelescope pointing, and data selection. Out of 1260 survey hours and 1024\ndetectors per array, 816 hours and 593 effective detectors remain after data\nselection for this frequency band, yielding a 38% survey efficiency. The total\nsensitivity in 2008, determined from the noise level between 5 Hz and 20 Hz in\nthe time-ordered data stream (TOD), is 32 micro-Kelvin sqrt{s} in CMB units.\nAtmospheric brightness fluctuations constitute the main contaminant in the data\nand dominate the detector noise covariance at low frequencies in the TOD. The\nmaps were made by solving the least-squares problem using the Preconditioned\nConjugate Gradient method, incorporating the details of the detector and noise\ncorrelations. Cross-correlation with WMAP sky maps, as well as analysis from\nsimulations, reveal that our maps are unbiased at multipoles ell > 300. This\npaper accompanies the public release of the 148 GHz southern stripe maps from\n2008. The techniques described here will be applied to future maps and data\nreleases. \n\n"}
{"id": "1208.0298", "contents": "Title: The cosmic microwave background: observing directly the early universe Abstract: The Cosmic Microwave Background (CMB) is a relict of the early universe. Its\nperfect 2.725K blackbody spectrum demonstrates that the universe underwent a\nhot, ionized early phase; its anisotropy (about 80 \\mu K rms) provides strong\nevidence for the presence of photon-matter oscillations in the primeval plasma,\nshaping the initial phase of the formation of structures; its polarization\nstate (about 3 \\mu K rms), and in particular its rotational component (less\nthan 0.1 \\mu K rms) might allow to study the inflation process in the very\nearly universe, and the physics of extremely high energies, impossible to reach\nwith accelerators. The CMB is observed by means of microwave and mm-wave\ntelescopes, and its measurements drove the development of ultra-sensitive\nbolometric detectors, sophisticated modulators, and advanced cryogenic and\nspace technologies. Here we focus on the new frontiers of CMB research: the\nprecision measurements of its linear polarization state, at large and\nintermediate angular scales, and the measurement of the inverse-Compton effect\nof CMB photons crossing clusters of Galaxies. In this framework, we will\ndescribe the formidable experimental challenges faced by ground-based,\nnear-space and space experiments, using large arrays of detectors. We will show\nthat sensitivity and mapping speed improvement obtained with these arrays must\nbe accompanied by a corresponding reduction of systematic effects (especially\nfor CMB polarimeters), and by improved knowledge of foreground emission, to\nfully exploit the huge scientific potential of these missions. \n\n"}
{"id": "1208.0447", "contents": "Title: The Astro-WISE datacentric information system Abstract: In this paper we present the various concepts behind the Astro-WISE\nInformation System. The concepts form a blueprint for general scientific\ninformation systems (WISE) which can satisfy a wide and challenging range of\nrequirements for the data dissemination, storage and processing for various\nfields in science. We review the main features of the information system and\nits practical implementation. \n\n"}
{"id": "1208.0865", "contents": "Title: PreCam, a Precursor Observational Campaign for Calibration of the Dark\n  Energy Survey Abstract: PreCam, a precursor observational campaign supporting the Dark Energy Survey\n(DES), is designed to produce a photometric and astrometric catalog of nearly a\nhundred thousand standard stars within the DES footprint, while the PreCam\ninstrument also serves as a prototype testbed for the Dark Energy Camera\n(DECam)'s hardware and software. This catalog represents a potential 100-fold\nincrease in Southern Hemisphere photometric standard stars, and therefore will\nbe an important component in the calibration of the Dark Energy Survey. We\nprovide details on the PreCam instrument's design, construction and testing, as\nwell as results from a subset of the 51 nights of PreCam survey observations on\nthe University of Michigan Department of Astronomy's Curtis-Schmidt telescope\nat Cerro Tololo Inter-American Observatory. We briefly describe the preliminary\ndata processing pipeline that has been developed for PreCam data and the\npreliminary results of the instrument performance, as well as astrometry and\nphotometry of a sample of stars previously included in other southern sky\nsurveys. \n\n"}
{"id": "1208.1157", "contents": "Title: Swarm-NG: a CUDA Library for Parallel n-body Integrations with focus on\n  Simulations of Planetary Systems Abstract: We present Swarm-NG, a C++ library for the efficient direct integration of\nmany n-body systems using highly-parallel Graphics Processing Unit (GPU), such\nas NVIDIA's Tesla T10 and M2070 GPUs. While previous studies have demonstrated\nthe benefit of GPUs for n-body simulations with thousands to millions of\nbodies, Swarm-NG focuses on many few-body systems, e.g., thousands of systems\nwith 3...15 bodies each, as is typical for the study of planetary systems.\nSwarm-NG parallelizes the simulation, including both the numerical integration\nof the equations of motion and the evaluation of forces using NVIDIA's \"Compute\nUnified Device Architecture\" (CUDA) on the GPU. Swarm-NG includes optimized\nimplementations of 4th order time-symmetrized Hermite integration and mixed\nvariable symplectic integration, as well as several sample codes for other\nalgorithms to illustrate how non-CUDA-savvy users may themselves introduce\ncustomized integrators into the Swarm-NG framework. To optimize performance, we\nanalyze the effect of GPU-specific parameters on performance under double\nprecision.\n  Applications of Swarm-NG include studying the late stages of planet\nformation, testing the stability of planetary systems and evaluating the\ngoodness-of-fit between many planetary system models and observations of\nextrasolar planet host stars (e.g., radial velocity, astrometry, transit\ntiming). While Swarm-NG focuses on the parallel integration of many planetary\nsystems,the underlying integrators could be applied to a wide variety of\nproblems that require repeatedly integrating a set of ordinary differential\nequations many times using different initial conditions and/or parameter\nvalues. \n\n"}
{"id": "1208.3206", "contents": "Title: A Novel Approach to Visualizing Dark Matter Simulations Abstract: In the last decades cosmological N-body dark matter simulations have enabled\nab initio studies of the formation of structure in the Universe. Gravity\namplified small density fluctuations generated shortly after the Big Bang,\nleading to the formation of galaxies in the cosmic web. These calculations have\nled to a growing demand for methods to analyze time-dependent particle based\nsimulations. Rendering methods for such N-body simulation data usually employ\nsome kind of splatting approach via point based rendering primitives and\napproximate the spatial distributions of physical quantities using kernel\ninterpolation techniques, common in SPH (Smoothed Particle\nHydrodynamics)-codes. This paper proposes three GPU-assisted rendering\napproaches, based on a new, more accurate method to compute the physical\ndensities of dark matter simulation data. It uses full phase-space information\nto generate a tetrahedral tessellation of the computational domain, with mesh\nvertices defined by the simulation's dark matter particle positions. Over time\nthe mesh is deformed by gravitational forces, causing the tetrahedral cells to\nwarp and overlap. The new methods are well suited to visualize the cosmic web.\nIn particular they preserve caustics, regions of high density that emerge, when\nseveral streams of dark matter particles share the same location in space,\nindicating the formation of structures like sheets, filaments and halos. We\ndemonstrate the superior image quality of the new approaches in a comparison\nwith three standard rendering techniques for N-body simulation data. \n\n"}
{"id": "1208.3491", "contents": "Title: Searching for gravitational waves from binary coalescence Abstract: We describe the implementation of a search for gravitational waves from\ncompact binary coalescences in LIGO and Virgo data. This all-sky, all-time,\nmulti-detector search for binary coalescence has been used to search data taken\nin recent LIGO and Virgo runs. The search is built around a matched filter\nanalysis of the data, augmented by numerous signal consistency tests designed\nto distinguish artifacts of non-Gaussian detector noise from potential\ndetections. We demonstrate the search performance using Gaussian noise and data\nfrom the fifth LIGO science run and demonstrate that the signal consistency\ntests are capable of mitigating the effect of non-Gaussian noise and providing\na sensitivity comparable to that achieved in Gaussian noise. \n\n"}
{"id": "1208.3658", "contents": "Title: Cosmological Calculations on the GPU Abstract: Cosmological measurements require the calculation of nontrivial quantities\nover large datasets. The next generation of survey telescopes (such as DES,\nPanSTARRS, and LSST) will yield measurements of billions of galaxies. The scale\nof these datasets, and the nature of the calculations involved, make\ncosmological calculations ideal models for implementation on graphics\nprocessing units (GPUs). We consider two cosmological calculations, the\ntwo-point angular correlation function and the aperture mass statistic, and aim\nto improve the calculation time by constructing code for calculating them on\nthe GPU. Using CUDA, we implement the two algorithms on the GPU and compare the\ncalculation speeds to comparable code run on the CPU. We obtain a code speed-up\nof between 10 - 180x faster, compared to performing the same calculation on the\nCPU. The code has been made publicly available. \n\n"}
{"id": "1208.4866", "contents": "Title: Empirical modelling of the BLASTPol achromatic half-wave plate for\n  precision submillimetre polarimetry Abstract: A cryogenic achromatic half-wave plate (HWP) for submillimetre astronomical\npolarimetry has been designed, manufactured, tested, and deployed in the\nBalloon-borne Large-Aperture Submillimeter Telescope for Polarimetry\n(BLASTPol). The design is based on the five-slab Pancharatnam recipe and it\nworks in the wavelength range 200-600 micron, making it the broadest-band HWP\nbuilt to date at (sub)millimetre wavelengths. The frequency behaviour of the\nHWP has been fully characterised at room and cryogenic temperatures with\nincoherent radiation from a polarising Fourier transform spectrometer. We\ndevelop a novel empirical model, complementary to the physical and analytical\nones available in the literature, that allows us to recover the HWP Mueller\nmatrix and phase shift as a function of frequency and extrapolated to 4K. We\nshow that most of the HWP non-idealities can be modelled by quantifying one\nwavelength-dependent parameter, the position of the HWP equivalent axes, which\nis then readily implemented in a map-making algorithm. We derive this parameter\nfor a range of spectral signatures of input astronomical sources relevant to\nBLASTPol, and provide a benchmark example of how our method can yield improved\naccuracy on measurements of the polarisation angle on the sky at submillimetre\nwavelengths. \n\n"}
{"id": "1208.5046", "contents": "Title: Importance of upgraded energy reconstruction for direct dark matter\n  searches with liquid xenon detectors Abstract: The usual nuclear recoil energy reconstruction employed by liquid xenon dark\nmatter search experiments relies only on the primary scintillation photon\nsignal. Energy reconstruction based on both the photon and electron signals\nyields a more accurate representation of search results. For a dark matter\nparticle mass m~10 GeV, a nuclear recoil from a scattering event is more likely\nto be observed in the lower left corner of the typical search box, rather than\nnear the nuclear recoil calibration centroid. In this region of the search box,\nthe actual nuclear recoil energies are smaller than the usual energy scale\nsuggests, by about a factor x2. Recent search results from the XENON100\nexperiment are discussed in light of these considerations. \n\n"}
{"id": "1208.6299", "contents": "Title: The Data Zoo in Astro-WISE Abstract: In this paper we describe the way the Astro-WISE information system (or\nsimply Astro-WISE) supports the data from a wide range of in- struments and\ncombines multiple surveys and their catalogues. Astro-WISE allows ingesting of\ndata from any optical instrument, survey or catalogue, pro- cessing of this\ndata to create new catalogues and bringing in data from different surveys into\na single catalogue, keeping all dependencies back to the original data. Full\ndata lineage is kept on each step of compiling a new catalogue with an ability\nto add a new data source recursively. With these features, Astro- WISE allows\nnot only combining and retrieving data from multiple surveys, but performing\nscientific data reduction and data mining down to the rawest data in the data\nprocessing chain within a single environment. \n\n"}
{"id": "1209.0712", "contents": "Title: Stability analysis for the background equations for inflation with\n  dissipation and in a viscous radiation bath Abstract: The effects of bulk viscosity are examined for inflationary dynamics in which\ndissipation and thermalization are present. A complete stability analysis is\ndone for the background inflaton evolution equations, which includes both\ninflaton dissipation and radiation bulk viscous effects. Three representative\napproaches of bulk viscous irreversible thermodynamics are analyzed: the Eckart\nnoncausal theory, the linear and causal theory of Israel-Stewart and a more\nrecent nonlinear and causal bulk viscous theory. It is found that the causal\ntheories allow for larger bulk viscosities before encountering an instability\nin comparison to the noncausal Eckart theory. It is also shown that the causal\ntheories tend to suppress the radiation production due to bulk viscous\npressure, because of the presence of relaxation effects implicit in these\ntheories. Bulk viscosity coefficients derived from quantum field theory are\napplied to warm inflation model building and an analysis is made of the effects\nto the duration of inflation. The treatment of bulk pressure would also be\nrelevant to the reheating phase after inflation in cold inflation dynamics and\nduring the radiation dominated regime, although very little work in both areas\nhas been done, the methodology developed in this paper could be extended to\napply to these other problems. \n\n"}
{"id": "1209.1277", "contents": "Title: Measurement of the CMB Polarization at 95 GHz from QUIET Abstract: (Abridged) Despite the great success of precision cosmology, cosmologists\ncannot fully explain the initial conditions of the Universe. Inflation, an\nexponential expansion in the first 10^-36s, is a promising potential\nexplanation. A generic prediction of inflation is odd-parity (B-mode)\npolarization in the cosmic microwave background (CMB). The Q/U Imaging\nExperimenT (QUIET) aimed to limit or detect this polarization.\n  We built a coherent pseudo-correlation microwave polarimeter. An array of\nmass-produced modules populated the focal plane of a 1.4m telescope. Each\nmodule had a sensitivity to polarization of 756muK sqrt{s} with a bandwidth of\n10.7+/-1.1 GHz centered at 94.5+/-0.8 GHz; the combined sensitivity was\n87+/-7muK sqrt{s}. We incorporated deck rotation, an absorbing ground screen, a\nnew time-stream double-demodulation technique, and optimized optics into the\ndesign to reduce instrumental polarization. We observed with this instrument at\nthe Atacama Plateau in Chile between August 2009 and December 2010. We\ncollected 5336.9 hours of CMB observation and 1090 hours of astronomical\ncalibration.\n  This thesis describes the analysis and results of these data. We\ncharacterized the instrument using the astronomical calibration data as well as\npurpose-built artificial sources. We developed noise modeling, filtering, and\ndata selection following a blind-analysis strategy. Central to this strategy\nwas a suite of 32 null tests, each motivated by a possible instrumental problem\nor systematic effect. We also evaluated the systematic errors in the blind\nstage of the analysis before the result was known. We then calculated the CMB\npower spectra using a pseudo-Cl cross-correlation technique that suppressed\ncontamination and made the result insensitive to noise bias. \n\n"}
{"id": "1209.1877", "contents": "Title: SkuareView: Client-Server Framework for Accessing Extremely Large Radio\n  Astronomy Image Data Abstract: The new wide-field radio telescopes, such as: ASKAP, MWA, and SKA; will\nproduce spectral-imaging data-cubes (SIDC) of unprecedented volume. This\nrequires new approaches to managing and servicing the data to the end-user. We\npresent a new integrated framework based on the JPEG2000/ISO/IEC 15444 standard\nto address the challenges of working with extremely large SIDC. We also present\nthe developed j2k software, that converts and encodes FITS image cubes into\nJPEG2000 images, paving the way to implementing the pre- sented framework. \n\n"}
{"id": "1209.1877", "contents": "Title: SkuareView: Client-Server Framework for Accessing Extremely Large Radio\n  Astronomy Image Data Abstract: The new wide-field radio telescopes, such as: ASKAP, MWA, and SKA; will\nproduce spectral-imaging data-cubes (SIDC) of unprecedented volume. This\nrequires new approaches to managing and servicing the data to the end-user. We\npresent a new integrated framework based on the JPEG2000/ISO/IEC 15444 standard\nto address the challenges of working with extremely large SIDC. We also present\nthe developed j2k software, that converts and encodes FITS image cubes into\nJPEG2000 images, paving the way to implementing the pre- sented framework. \n\n"}
{"id": "1209.2124", "contents": "Title: A measure of total research impact independent of time and discipline Abstract: Authorship and citation practices evolve with time and differ by academic\ndiscipline. As such, indicators of research productivity based on citation\nrecords are naturally subject to historical and disciplinary effects. We\nobserve these effects on a corpus of astronomer career data constructed from a\ndatabase of refereed publications. We employ a simple mechanism to measure\nresearch output using author and reference counts available in bibliographic\ndatabases to develop a citation-based indicator of research productivity. The\ntotal research impact (tori) quantifies, for an individual, the total amount of\nscholarly work that others have devoted to his/her work, measured in the volume\nof research papers. A derived measure, the research impact quotient (riq), is\nan age independent measure of an individual's research ability. We demonstrate\nthat these measures are substantially less vulnerable to temporal debasement\nand cross-disciplinary bias than the most popular current measures. The\nproposed measures of research impact, tori and riq, have been implemented in\nthe Smithsonian/NASA Astrophysics Data System. \n\n"}
{"id": "1209.2768", "contents": "Title: The Quest for Gravity Wave B-modes Abstract: One of the most exciting quests in all of contemporary science is to find\nhints that in the first tiny fraction of a second after the Big-Bang the\nUniverse hyper-inflated by a factor of \\sim 10^{60}. Such inflation will have\ninjected gravity waves into the fabric of spacetime which will in turn have\nleft a faint imprint in the polarization pattern of the Cosmic Microwave\nBackground. This paper describes the history of polarization measurement, the\nexperimental optimization of this latest search for the gravity wave imprint,\nand the current round of experiments and their various approaches to the\nchallenge. \n\n"}
{"id": "1209.3840", "contents": "Title: Antennas for the Detection of Radio Emission Pulses from Cosmic-Ray\n  induced Air Showers at the Pierre Auger Observatory Abstract: The Pierre Auger Observatory is exploring the potential of the radio\ndetection technique to study extensive air showers induced by ultra-high energy\ncosmic rays. The Auger Engineering Radio Array (AERA) addresses both\ntechnological and scientific aspects of the radio technique. A first phase of\nAERA has been operating since September 2010 with detector stations observing\nradio signals at frequencies between 30 and 80 MHz. In this paper we present\ncomparative studies to identify and optimize the antenna design for the final\nconfiguration of AERA consisting of 160 individual radio detector stations. The\ntransient nature of the air shower signal requires a detailed description of\nthe antenna sensor. As the ultra-wideband reception of pulses is not widely\ndiscussed in antenna literature, we review the relevant antenna characteristics\nand enhance theoretical considerations towards the impulse response of antennas\nincluding polarization effects and multiple signal reflections. On the basis of\nthe vector effective length we study the transient response characteristics of\nthree candidate antennas in the time domain. Observing the variation of the\ncontinuous galactic background intensity we rank the antennas with respect to\nthe noise level added to the galactic signal. \n\n"}
{"id": "1209.4935", "contents": "Title: Adaptive Real Time Imaging Synthesis Telescopes Abstract: The digital revolution is transforming astronomy from a data-starved to a\ndata-submerged science. Instruments such as the Atacama Large Millimeter Array\n(ALMA), the Large Synoptic Survey Telescope (LSST), and the Square Kilometer\nArray (SKA) will measure their accumulated data in petabytes. The capacity to\nproduce enormous volumes of data must be matched with the computing power to\nprocess that data and produce meaningful results. In addition to handling huge\ndata rates, we need adaptive calibration and beamforming to handle atmospheric\nfluctuations and radio frequency interference, and to provide a user\nenvironment which makes the full power of large telescope arrays accessible to\nboth expert and non-expert users. Delayed calibration and analysis limit the\nscience which can be done. To make the best use of both telescope and human\nresources we must reduce the burden of data reduction.\n  Our instrumentation comprises of a flexible correlator, beam former and\nimager with digital signal processing closely coupled with a computing cluster.\nThis instrumentation will be highly accessible to scientists, engineers, and\nstudents for research and development of real-time processing algorithms, and\nwill tap into the pool of talented and innovative students and visiting\nscientists from engineering, computing, and astronomy backgrounds.\n  Adaptive real-time imaging will transform radio astronomy by providing\nreal-time feedback to observers. Calibration of the data is made in close to\nreal time using a model of the sky brightness distribution. The derived\ncalibration parameters are fed back into the imagers and beam formers. The\nregions imaged are used to update and improve the a-priori model, which becomes\nthe final calibrated image by the time the observations are complete. \n\n"}
{"id": "1209.6577", "contents": "Title: Exploring Design Tradeoffs Of A Distributed Algorithm For Cosmic Ray\n  Event Detection Abstract: Many sensor networks, including large particle detector arrays measuring\nhigh-energy cosmic-ray air showers, traditionally rely on centralised trigger\nalgorithms to find spatial and temporal coincidences of individual nodes. Such\nschemes suffer from scalability problems, especially if the nodes communicate\nwirelessly or have bandwidth limitations. However, nodes which instead\ncommunicate with each other can, in principle, use a distributed algorithm to\nfind coincident events themselves without communication with a central node. We\npresent such an algorithm and consider various design tradeoffs involved, in\nthe context of a potential trigger for the Auger Engineering Radio Array\n(AERA). \n\n"}
{"id": "1210.0553", "contents": "Title: Baryogenesis from Mixing of Lepton Doublets Abstract: It is shown that the mixing of lepton doublets of the Standard Model can\nyield sizeable contributions to the lepton asymmetry, that is generated through\nthe decays of right-handed neutrinos at finite temperature in the early\nUniverse. When calculating the flavour-mixing correlations, we account for the\neffects of Yukawa as well as of gauge interactions. We compare the freeze-out\nasymmetry from lepton-doublet mixing to the standard contributions from the\nmixing and direct decays of right-handed neutrinos. The asymmetry from lepton\nmixing is considerably large when the mass ratio between the right-handed\nneutrinos is of order of a few, while it becomes Maxwell-suppressed for larger\nhierarchies. For an intermediate range between the case of degenerate\nright-handed neutrinos (resonant Leptogenesis) and the hierarchical case,\nlepton mixing can yield the main contribution to the lepton asymmetry. \n\n"}
{"id": "1210.0840", "contents": "Title: ADS Labs - Supporting Information Discovery in Science Education Abstract: The SAO/NASA Astrophysics Data System (ADS) is an open access digital library\nportal for researchers in astronomy and physics, operated by the Smithsonian\nAstrophysical Observatory (SAO) under a NASA grant, successfully serving the\nprofessional science community for two decades. Currently there are about\n55,000 frequent users (100+ queries per year), and up to 10 million infrequent\nusers per year. Access by the general public now accounts for about half of all\nADS use, demonstrating the vast reach of the content in our databases. The\nvisibility and use of content in the ADS can be measured by the fact that there\nare over 17,000 links from Wikipedia pages to ADS content, a figure comparable\nto the number of links that Wikipedia has to OCLCs WorldCat catalog. The ADS,\nthrough its holdings and innovative techniques available in ADS Labs\n(http://adslabs.org), offers an environment for information discovery that is\nunlike any other service currently available to the astrophysics community.\nLiterature discovery and review are important components of science education,\naiding the process of preparing for a class, project, or presentation. The ADS\nhas been recognized as a rich source of information for the science education\ncommunity in astronomy, thanks to its collaborations within the astronomy\ncommunity, publishers and projects like Com- PADRE. One element that makes the\nADS uniquely relevant for the science education community is the availability\nof powerful tools to explore aspects of the astronomy literature as well as the\nrelationship between topics, people, observations and scientific papers. The\nother element is the extensive repository of scanned literature, a significant\nfraction of which consists of historical literature. \n\n"}
{"id": "1210.0906", "contents": "Title: On the Higgs Fit and Electroweak Phase Transition Abstract: We consider the Higgs portal through which light scalars contribute both to\nthe Higgs production and decay and Higgs effective potential at finite\ntemperature via quantum loops. The positive Higgs portal coupling required by a\nstrongly first order electroweak phase transition is disfavored by the current\nHiggs data if we consider one such scalar. We observe that by introducing a\nsecond scalar with negative Higgs portal coupling, one can not only improve the\nHiggs fits, but also enhance the strength of first order EWPT. We apply this\nmechanism to the light stop scenario for electroweak baryogenesis in the MSSM\nand find a light sbottom could play the role as the second scalar, which allows\nthe stop to be relatively heavier. Non-decoupled effects on the Higgs or\nsbottom self-interactions from physics beyond MSSM is found to be indispensable\nfor this scenario to work. A clear prediction from the picture is the existence\nof a light sbottom (below 200 GeV) and a light stop (can be as heavy as 140\nGeV), which can be directly tested in the near future. \n\n"}
{"id": "1210.2168", "contents": "Title: Modified Gravity and the Radiation Dominated Epoch Abstract: In this paper we consider scalar-tensor theories, allowing for both conformal\nand disformal couplings to a fluid with a generic equation of state. We derive\nthe effective coupling for both background cosmology and for perturbations in\nthat fluid. As an application we consider the scalar degree of freedom to be\ncoupled to baryons and study the dynamics of the tightly coupled photon-baryon\nfluid in the early universe. We derive an expression for the effective speed of\nsound, which differs from its value in General Relativity. We apply our\nfindings to the \\mu-distortion of the cosmic microwave background radiation,\nwhich depends on the effective sound-speed of the photon-baryon fluid, and show\nthat the predictions differ from General Relativity. Thus, the \\mu-distortion\nprovides further information about gravity in the very early universe well\nbefore decoupling. \n\n"}
{"id": "1210.2774", "contents": "Title: Pulsar Timing Arrays: Status and Techniques Abstract: Three pulsar timing arrays are now producing high quality data sets. As\nreviewed in this paper, these data sets are been processed to 1) develop a\npulsar-based time standard, 2) search for errors in the solar system planetary\nephemeris and 3) detect gravitational waves. It is expected that the data sets\nwill significantly improve in the near future by combining existing\nobservations and by using new telescopes. \n\n"}
{"id": "1210.3627", "contents": "Title: Vector instabilities and self-acceleration in the decoupling limit of\n  massive gravity Abstract: We investigate vector contributions to the Lagrangian of $\\Lambda_3-$massive\ngravity in the decoupling limit, the less explored sector of this theory. The\nmain purpose is to understand the stability of maximally symmetric\n%self-accelerating vacuum solutions. Around self-accelerating configurations,\nvector degrees of freedom become strongly coupled since their kinetic terms\nvanish, so their dynamics is controlled by higher order interactions. Even in\nthe decoupling limit, the vector Lagrangian contains an infinite number of\nterms. We develop a systematic method to covariantly determine the vector\nLagrangian at each order in perturbations, fully manifesting the symmetries of\nthe system. We show that, around self-accelerating solutions, the structure of\nhigher order $p$-form Galileons arise, avoiding the emergence of a sixth BD\nghost mode. However, a careful analysis shows that there are directions along\nwhich the Hamiltonian is unbounded from below. This instability can be\ninterpreted as one of the available fifth physical modes behaving as a ghost.\nTherefore, we conclude that self-accelerating configurations, in the decoupling\nlimit of $\\Lambda_3$-massive gravity, are generically unstable. \n\n"}
{"id": "1210.3903", "contents": "Title: Degeneracies in parametrized modified gravity models Abstract: We study degeneracies between parameters in some of the widely used\nparametrized modified gravity models. We investigate how different observables\nfrom a future photometric weak lensing survey such as LSST, correlate the\neffects of these parameters and to what extent the degeneracies are broken. We\nalso study the impact of other degenerate effects, namely massive neutrinos and\nsome of the weak lensing systematics, on the correlations. \n\n"}
{"id": "1210.4966", "contents": "Title: South Pole Telescope Software Systems: Control, Monitoring, and Data\n  Acquisition Abstract: We present the software system used to control and operate the South Pole\nTelescope. The South Pole Telescope is a 10-meter millimeter-wavelength\ntelescope designed to measure anisotropies in the cosmic microwave background\n(CMB) at arcminute angular resolution. In the austral summer of 2011/12, the\nSPT was equipped with a new polarization-sensitive camera, which consists of\n1536 transition-edge sensor bolometers. The bolometers are read out using 36\nindependent digital frequency multiplexing (\\dfmux) readout boards, each with\nits own embedded processors. These autonomous boards control and read out data\nfrom the focal plane with on-board software and firmware. An overall control\nsoftware system running on a separate control computer controls the \\dfmux\nboards, the cryostat and all other aspects of telescope operation. This control\nsoftware collects and monitors data in real-time, and stores the data to disk\nfor transfer to the United States for analysis. \n\n"}
{"id": "1210.4970", "contents": "Title: SPTpol: an instrument for CMB polarization measurements with the South\n  Pole Telescope Abstract: SPTpol is a dual-frequency polarization-sensitive camera that was deployed on\nthe 10-meter South Pole Telescope in January 2012. SPTpol will measure the\npolarization anisotropy of the cosmic microwave background (CMB) on angular\nscales spanning an arcminute to several degrees. The polarization sensitivity\nof SPTpol will enable a detection of the CMB \"B-mode\" polarization from the\ndetection of the gravitational lensing of the CMB by large scale structure, and\na detection or improved upper limit on a primordial signal due to inflationary\ngravity waves. The two measurements can be used to constrain the sum of the\nneutrino masses and the energy scale of inflation. These science goals can be\nachieved through the polarization sensitivity of the SPTpol camera and careful\ncontrol of systematics. The SPTpol camera consists of 768 pixels, each\ncontaining two transition-edge sensor (TES) bolometers coupled to orthogonal\npolarizations, and a total of 1536 bolometers. The pixels are sensitive to\nlight in one of two frequency bands centered at 90 and 150 GHz, with 180 pixels\nat 90 GHz and 588 pixels at 150 GHz. The SPTpol design has several features\ndesigned to control polarization systematics, including: single-moded feedhorns\nwith low cross-polarization, bolometer pairs well-matched to difference\natmospheric signals, an improved ground shield design based on far-sidelobe\nmeasurements of the SPT, and a small beam to reduce temperature to polarization\nleakage. We present an overview of the SPTpol instrument design, project\nstatus, and science projections. \n\n"}
{"id": "1210.6734", "contents": "Title: Precise measurement of the absolute fluorescence yield of the 337 nm\n  band in atmospheric gases Abstract: A measurement of the absolute fluorescence yield of the 337 nm nitrogen band,\nrelevant to ultra-high energy cosmic ray (UHECR) detectors, is reported. Two\nindependent calibrations of the fluorescence emission induced by a 120 GeV\nproton beam were employed: Cherenkov light from the beam particle and\ncalibrated light from a nitrogen laser. The fluorescence yield in air at a\npressure of 1013 hPa and temperature of 293 K was found to be $Y_{337} =\n5.61\\pm 0.06_{stat} \\pm 0.21_{syst}$ photons/MeV. When compared to the\nfluorescence yield currently used by UHECR experiments, this measurement\nimproves the uncertainty by a factor of three, and has a significant impact on\nthe determination of the energy scale of the cosmic ray spectrum. \n\n"}
{"id": "1210.7691", "contents": "Title: Defining a weak lensing experiment in space Abstract: This paper describes the definition of a typical next-generation space-based\nweak gravitational lensing experiment. We first adopt a set of top-level\nscience requirements from the literature, based on the scale and depth of the\ngalaxy sample, and the avoidance of systematic effects in the measurements\nwhich would bias the derived shear values. We then identify and categorise the\ncontributing factors to the systematic effects, combining them with the correct\nweighting, in such a way as to fit within the top-level requirements. We\npresent techniques which permit the performance to be evaluated and explore the\nlimits at which the contributing factors can be managed. Besides the modelling\nbiases resulting from the use of weighted moments, the main contributing\nfactors are the reconstruction of the instrument point spread function (PSF),\nwhich is derived from the stellar images on the image, and the correction of\nthe charge transfer inefficiency (CTI) in the CCD detectors caused by radiation\ndamage. \n\n"}
{"id": "1210.7874", "contents": "Title: A soft X-ray reverberation lag in the AGN ESO 113-G010 Abstract: Reverberation lags have recently been discovered in a handful of nearby,\nvariable AGN. Here, we analyze a ~100 ksec archival XMM-Newton observation of\nthe highly variable AGN, ESO 113-G010 in order to search for lags between hard,\n1.5 - 4.5 keV, and soft, 0.3 - 0.9 keV, energy X-ray bands. At the lowest\nfrequencies available in the lightcurve (<1.5E-4 Hz), we find hard lags where\nthe power-law dominated hard band lags the soft band (where the reflection\nfraction is high). However, at higher frequencies in the range (2-3)E-4 Hz we\nfind a soft lag of -325 +/- 89 s. The general evolution from hard to soft lags\nas the frequency increases is similar to other AGN where soft lags have been\ndetected. We interpret this soft lag as due to reverberation from the accretion\ndisk, with the reflection component responding to variability from the X-ray\ncorona. For a black hole mass of 7E6 M(solar) this corresponds to a\nlight-crossing time of ~9 R_g/c, however, dilution effects mean that the\nintrinsic lag is likely longer than this. Based on recent black hole\nmass-scaling for lag properties, the lag amplitude and frequency are more\nconsistent with a black hole a few times more massive than the best estimates,\nthough flux-dependent effects could easily add scatter this large. \n\n"}
{"id": "1210.8030", "contents": "Title: Astronomy and Computing: a New Journal for the Astronomical Computing\n  Community Abstract: We introduce \\emph{Astronomy and Computing}, a new journal for the growing\npopulation of people working in the domain where astronomy overlaps with\ncomputer science and information technology. The journal aims to provide a new\ncommunication channel within that community, which is not well served by\ncurrent journals, and to help secure recognition of its true importance within\nmodern astronomy. In this inaugural editorial, we describe the rationale for\ncreating the journal, outline its scope and ambitions, and seek input from the\ncommunity in defining in detail how the journal should work towards its\nhigh-level goals. \n\n"}
{"id": "1210.8221", "contents": "Title: Probing Dark Energy Anisotropy Abstract: Wide area cosmological surveys enable investigation of whether dark energy\nproperties are the same in different directions on the sky. Cosmic microwave\nbackground observations strongly restrict any dynamical effects from\nanisotropy, in an integrated sense. For more local constraints we compute\nlimits from simulated distance measurements for various distributions of survey\nfields in a Bianchi I anisotropic universe. We then consider the effects of\nfitting for line of sight properties where isotropic dynamics is assumed\n(testing the accuracy through simulations) and compare sensitivities of\nobservational probes for anisotropies, from astrophysical systematics as well\nas dark energy. We also point out some interesting features of anisotropic\nexpansion in Bianchi I cosmology. \n\n"}
{"id": "1211.0165", "contents": "Title: Modelling grand minima of solar activity using a flux transport dynamo\n  model Abstract: The occurrence of grand minima like the Maunder minimum is an intriguing\naspect of the sunspot cycle. We use the flux transport dynamo model to explain\nthe grand minima, showing that they arise when either the poloidal field or the\nmeridional circulation falls to a sufficiently low value due to fluctuations.\nAssuming these fluctuations to be Gaussian and determining the various\nparameters from the data of the last 28 cycles, we carry on a dynamo simulation\nwith both these fluctuations. The results are remarkably close to the\nobservational data. \n\n"}
{"id": "1211.0525", "contents": "Title: Generating Optimal Initial Conditions for Smoothed Particle\n  Hydrodynamics Simulations Abstract: We review existing SPH setup methods and outline their advantages,\nlimitations and drawbacks. We present a new method for constructing initial\nconditions for smoothed particle hydrodynamics (SPH) simulations, which may\nalso be of interest for N-body simulations, and demonstrate this method on a\nnumber of applications. This new method is inspired by adaptive binning\ntechniques using weighted Voronoi tesselations. Particles are placed and\niteratively moved based on their proximity to neighboring particles and the\ndesired spatial resolution. This new method can satisfy arbitrarily complex\nspatial resolution requirements. \n\n"}
{"id": "1211.1012", "contents": "Title: Linear dark energy equation of state revealed by supernovae? Abstract: In this letter we propose a test to detect the linearity of the dark energy\nequation of state, and apply it to two different Type Ia Supernova (SN Ia) data\nsets, Union2.1 and SNLS3. We find that: a. current SN Ia data are well\ndescribed by a dark energy equation of state linear in the cosmic scale factor\na, at least up to a redshift z = 1, independent of the pivot points chosen for\nthe linear relation; b. there is no significant evidence of any deviation from\nlinearity. This apparent linearity may reflect the limit of dark energy\ninformation extractable from current SN Ia data. \n\n"}
{"id": "1211.1014", "contents": "Title: $Z_3$ Scalar Singlet Dark Matter Abstract: We consider the minimal scalar singlet dark matter stabilised by a $Z_3$\nsymmetry. Due to the cubic term in the scalar potential, semi-annihilations,\nbesides annihilations, contribute to the dark matter relic density. Unlike in\nthe $Z_2$ case, the dark matter spin independent direct detection cross section\nis no more linked to the annihilation cross section. We study the extrema of\nthe potential and show that a too large cubic term would break the $Z_3$\nsymmetry spontaneously, implying a lower bound on the direct detection cross\nsection, and allowing the whole parameter space to be tested by XENON1T. In a\nsmall region of the parameter space the model can avoid the instability of the\nstandard model vacuum up to the unification scale. If the semi-annihilations\nare large, however, new physics will be needed at TeV scale because the model\nbecomes non-perturbative. The singlet dark matter mass cannot be lower than\n53.8 GeV due to the constraint from Higgs boson decay into dark matter. \n\n"}
{"id": "1211.2023", "contents": "Title: An Arecibo Survey for Zeeman Splitting in OH Megamaser Galaxies Abstract: We present the results of a comprehensive survey using the Arecibo\nObservatory for Zeeman splitting of OH lines in OH megamasers (OHMs). A total\nof seventy-seven sources were observed with the Arecibo telescope. Of these,\nmaser emission could not be detected for eight sources, and two sources were\nonly ambiguously detected. Another twenty-seven sources were detected at low\nsignal-to-noise ratios or with interference that prevented placing any useful\nlimits on the presence of magnetic fields. In twenty-six sources, it was\npossible to place upper limits on the magnitude of magnetic fields, typically\nbetween 10-30 mG. For fourteen sources, the Stokes V spectra exhibit features\nconsistent with Zeeman splitting. Eleven of these fourteen are new detections,\nand the remaining three are re-detections of Stokes V detections in Robishaw et\nal. (2008). Among confident new detections, we derive magnetic fields\nassociated with maser regions with magnitudes ranging from 6.1-27.6 mG. The\ndistribution of magnetic field strengths suggests the magnetic fields in OH\nmasing clouds in OHMs are larger than those in Galactic OH masers. The results\nare consistent with magnetic fields playing a dynamically important role in OH\nmasing clouds in OHMs. \n\n"}
{"id": "1211.3097", "contents": "Title: Exploring the origin of the fine structures in the CMB temperature\n  angular power spectrum Abstract: The angular power spectrum of the cosmic microwave background (CMB)\ntemperature anisotropies is a good probe to look into the primordial density\nfluctuations at large scales in the universe. Here we re-examine the angular\npower spectrum of the Wilkinson Microwave Anisotropy Probe data, paying\nparticular attention to the fine structures (oscillations) at $\\ell=100 \\sim\n150$ reported by several authors. Using Monte-Carlo simulations, we confirm\nthat the gap from the simple power law spectrum is a rare event, about\n2.5--3$\\sigma$, if these fine structures are generated by experimental noise\nand the cosmic variance. Next, in order to investigate the origin of the\nstructures, we examine frequency and direction dependencies of the fine\nstructures by dividing the observed QUV frequency maps into four sky regions.\nWe find that the structures around $\\ell \\sim 120$ do not have significant\ndependences either on frequencies or directions. For the structure around $\\ell\n\\sim 140$, however, we find that the characteristic signature found in the all\nsky power spectrum is attributed to the anomaly only in the South East region. \n\n"}
{"id": "1211.4655", "contents": "Title: Allan Sandage and the Distance Scale Abstract: Allan Sandage returned to the distance scale and the calibration of the\nHubble constant again and again during his active life, experimenting with\ndifferent distance indicators. In 1952 his proof of the high luminosity of\nCepheids confirmed Baade's revision of the distance scale (H0 ~ 250 km/s/Mpc).\nDuring the next 25 years, he lowered the value to 75 and 55. Upon the arrival\nof the Hubble Space Telescope, he observed Cepheids to calibrate the mean\nluminosity of nearby Type Ia supernovae (SNe Ia) which, used as standard\ncandles, led to the cosmic value of H0 = 62.3 +/- 1.3 +/- 5.0. Eventually he\nturned to the tip of the red-giant branch (TRGB) as a very powerful distance\nindicator. A compilation of 176 TRGB distances yielded a mean, very local value\nof H0 = 62.9 +/- 1.6 and shed light on the streaming velocities in the Local\nSupercluster. Moreover, TRGB distances are now available for six SNe Ia; if\ntheir mean luminosity is applied to distant SNe Ia, one obtains H0 = 64.6 +/-\n1.6 +/- 2.0. The weighted mean of the two independent large-scale calibrations\nyields H0 = 64.1 km/s/Mpc within 3.6%. \n\n"}
{"id": "1211.4896", "contents": "Title: Tera-scale Astronomical Data Analysis and Visualization Abstract: We present a high-performance, graphics processing unit (GPU)-based framework\nfor the efficient analysis and visualization of (nearly) terabyte (TB)-sized\n3-dimensional images. Using a cluster of 96 GPUs, we demonstrate for a 0.5 TB\nimage: (1) volume rendering using an arbitrary transfer function at 7--10\nframes per second; (2) computation of basic global image statistics such as the\nmean intensity and standard deviation in 1.7 s; (3) evaluation of the image\nhistogram in 4 s; and (4) evaluation of the global image median intensity in\njust 45 s. Our measured results correspond to a raw computational throughput\napproaching one teravoxel per second, and are 10--100 times faster than the\nbest possible performance with traditional single-node, multi-core CPU\nimplementations. A scalability analysis shows the framework will scale well to\nimages sized 1 TB and beyond. Other parallel data analysis algorithms can be\nadded to the framework with relative ease, and accordingly, we present our\nframework as a possible solution to the image analysis and visualization\nrequirements of next-generation telescopes, including the forthcoming Square\nKilometre Array pathfinder radiotelescopes. \n\n"}
{"id": "1211.4896", "contents": "Title: Tera-scale Astronomical Data Analysis and Visualization Abstract: We present a high-performance, graphics processing unit (GPU)-based framework\nfor the efficient analysis and visualization of (nearly) terabyte (TB)-sized\n3-dimensional images. Using a cluster of 96 GPUs, we demonstrate for a 0.5 TB\nimage: (1) volume rendering using an arbitrary transfer function at 7--10\nframes per second; (2) computation of basic global image statistics such as the\nmean intensity and standard deviation in 1.7 s; (3) evaluation of the image\nhistogram in 4 s; and (4) evaluation of the global image median intensity in\njust 45 s. Our measured results correspond to a raw computational throughput\napproaching one teravoxel per second, and are 10--100 times faster than the\nbest possible performance with traditional single-node, multi-core CPU\nimplementations. A scalability analysis shows the framework will scale well to\nimages sized 1 TB and beyond. Other parallel data analysis algorithms can be\nadded to the framework with relative ease, and accordingly, we present our\nframework as a possible solution to the image analysis and visualization\nrequirements of next-generation telescopes, including the forthcoming Square\nKilometre Array pathfinder radiotelescopes. \n\n"}
{"id": "1211.5481", "contents": "Title: Genetic Algorithm Modeling with GPU Parallel Computing Technology Abstract: We present a multi-purpose genetic algorithm, designed and implemented with\nGPGPU / CUDA parallel computing technology. The model was derived from a\nmulti-core CPU serial implementation, named GAME, already scientifically\nsuccessfully tested and validated on astrophysical massive data classification\nproblems, through a web application resource (DAMEWARE), specialized in data\nmining based on Machine Learning paradigms. Since genetic algorithms are\ninherently parallel, the GPGPU computing paradigm has provided an exploit of\nthe internal training features of the model, permitting a strong optimization\nin terms of processing performances and scalability. \n\n"}
{"id": "1211.7054", "contents": "Title: Dark Energy or Modified Gravity? An Effective Field Theory Approach Abstract: We take an Effective Field Theory (EFT) approach to unifying existing\nproposals for the origin of cosmic acceleration and its connection to\ncosmological observations. Building on earlier work where EFT methods were used\nwith observations to constrain the background evolution, we extend this program\nto the level of the EFT of the cosmological perturbations - following the\nexample from the EFT of Inflation. Within this framework, we construct the\ngeneral theory around an assumed background which will typically be chosen to\nmimic Lambda-CDM, and identify the parameters of interest for constraining dark\nenergy and modified gravity models with observations. We discuss the\nsimilarities to the EFT of Inflation, but we also identify a number of\nsubtleties including the relationship between the scalar perturbations and the\nGoldstone boson of the spontaneously broken time translations. We present\nformulae that relate the parameters of the fundamental Lagrangian to the speed\nof sound, anisotropic shear stress, effective Newtonian constant, and\nCaldwell's varpi parameter emphasizing the connection to observations. It is\nanticipated that this framework will be of use in constraining individual\nmodels, as well as for placing model-independent constraints on dark energy and\nmodified gravity model building. \n\n"}
{"id": "1212.1166", "contents": "Title: Self-consistency of the Excursion Set Approach Abstract: The excursion set approach provides a framework for predicting how the\nabundance of dark matter halos depends on the initial conditions. A key\ningredient of this formalism comes from the physics of halo formation: the\nspecification of a critical overdensity threshold (barrier) which protohalos\nmust exceed if they are to form bound virialized halos at a later time. Another\ningredient is statistical, as it requires the specification of the appropriate\nstatistical ensemble over which to average when making predictions. The\nexcursion set approach explicitly averages over all initial positions, thus\nimplicitly assuming that the appropriate ensemble is that associated with\nrandomly chosen positions in space, rather than special positions such as peaks\nof the initial density field. Since halos are known to collapse around special\npositions, it is not clear that the physical and statistical assumptions which\nunderlie the excursion set approach are self-consistent. We argue that they are\nat least for low mass halos, and illustrate by comparing our excursion set\npredictions with numerical data from the DEUS simulations. \n\n"}
{"id": "1212.1915", "contents": "Title: Bring out your codes! Bring out your codes! (Increasing Software\n  Visibility and Re-use) Abstract: Progress is being made in code discoverability and preservation, but as\ndiscussed at ADASS XXI, many codes still remain hidden from public view. With\nthe Astrophysics Source Code Library (ASCL) now indexed by the SAO/NASA\nAstrophysics Data System (ADS), the introduction of a new journal, Astronomy &\nComputing, focused on astrophysics software, and the increasing success of\neducation efforts such as Software Carpentry and SciCoder, the community has\nthe opportunity to set a higher standard for its science by encouraging the\nrelease of software for examination and possible reuse. We assembled\nrepresentatives of the community to present issues inhibiting code release and\nsought suggestions for tackling these factors.\n  The session began with brief statements by panelists; the floor was then\nopened for discussion and ideas. Comments covered a diverse range of related\ntopics and points of view, with apparent support for the propositions that\nalgorithms should be readily available, code used to produce published\nscientific results should be made available, and there should be discovery\nmechanisms to allow these to be found easily. With increased use of resources\nsuch as GitHub (for code availability), ASCL (for code discovery), and a stated\nstrong preference from the new journal Astronomy & Computing for code release,\nwe expect to see additional progress over the next few years. \n\n"}
{"id": "1212.1916", "contents": "Title: Astrophysics Source Code Library Abstract: The Astrophysics Source Code Library (ASCL), founded in 1999, is a free\non-line registry for source codes of interest to astronomers and\nastrophysicists. The library is housed on the discussion forum for Astronomy\nPicture of the Day (APOD) and can be accessed at http://ascl.net. The ASCL has\na comprehensive listing that covers a significant number of the astrophysics\nsource codes used to generate results published in or submitted to refereed\njournals and continues to grow. The ASCL currently has entries for over 500\ncodes; its records are citable and are indexed by ADS. The editors of the ASCL\nand members of its Advisory Committee were on hand at a demonstration table in\nthe ADASS poster room to present the ASCL, accept code submissions, show how\nthe ASCL is starting to be used by the astrophysics community, and take\nquestions on and suggestions for improving the resource. \n\n"}
{"id": "1212.2252", "contents": "Title: On distinguishing age from metallicity with photometric data Abstract: In the study of galaxy integrated light, if photometric indicators could\nextract age and metallicity information of high enough quality, photometry\nmight be vastly more efficient than spectroscopy for the same astrophysical\ngoals. Toward this end, we search three photometric systems: David Dunlap\nObservatory (DDO), Beijing-Arizona-Taiwan-Connecticut (BATC), and Stromgren\nsystems for their ability to disentangle age and abundance effects. Only the\nStromgren [c_1] vs. [m_1] plot shows moderate age-metallicity disentanglement.\nWe also add to the discussion of optical to near-infrared Johnson-Cousins broad\nband colours, finding a great decrease in age sensitivity when updated\nisochrones are used. \n\n"}
{"id": "1212.4152", "contents": "Title: The VIRUS-P Exploration of Nearby Galaxies (VENGA): The Xco Gradient in\n  NGC 628 Abstract: We measure the radial profile of the 12CO(1-0) to H_2 conversion factor (Xco)\nin NGC 628. The H\\alpha emission from the VENGA integral field spectroscopy is\nused to map the star formation rate surface density (\\Sigma_{SFR}). We estimate\nthe molecular gas surface density (\\Sigma_{H2}) from \\Sigma_{SFR} by inverting\nthe molecular star formation law (SFL), and compare it to the CO intensity to\nmeasure Xco. We study the impact of systematic uncertainties by changing the\nslope of the SFL, using different SFR tracers (H\\alpha vs. far-UV plus 24\\mu\nm), and CO maps from different telescopes (single-dish and interferometers).\nThe observed Xco profile is robust against these systematics, drops by a factor\nof 2 from R~7 kpc to the center of the galaxy, and is well fit by a gradient\n\\Delta log(Xco)=0.06\\pm0.02 dex kpc^-1. We study how changes in Xco follow\nchanges in metallicity, gas density, and ionization parameter. Theoretical\nmodels show that the gradient in Xco can be explained by a combination of\ndecreasing metallicity, and decreasing \\Sigma_{H2} with radius. Photoelectric\nheating from the local UV radiation field appears to contribute to the decrease\nof Xco in higher density regions. Our results show that galactic environment\nplays an important role at setting the physical conditions in star forming\nregions, in particular the chemistry of carbon in molecular complexes, and the\nradiative transfer of CO emission. We caution against adopting a single Xco\nvalue when large changes in gas surface density or metallicity are present. \n\n"}
{"id": "1212.4268", "contents": "Title: The cosmological constant as an eigenvalue of a Sturm-Liouville problem Abstract: It is observed that one of Einstein-Friedmann's equations has formally the\naspect of a Sturm-Liouville problem, and that the cosmological constant,\n$\\Lambda$, plays thereby the role of spectral parameter (what hints to its\nconnection with the Casimir effect). The subsequent formulation of appropriate\nboundary conditions leads to a set of admissible values for $\\Lambda$,\nconsidered as eigenvalues of the corresponding linear operator. Simplest\nboundary conditions are assumed, namely that the eigenfunctions belong to $L^2$\nspace, with the result that, when all energy conditions are satisfied, they\nyield a discrete spectrum for $\\Lambda>0$ and a continuous one for $\\Lambda<0$.\nA very interesting situation is seen to occur when the discrete spectrum\ncontains only one point: then, there is the possibility to obtain appropriate\ncosmological conditions without invoking the anthropic principle. This\npossibility is shown to be realized in cyclic cosmological models, provided the\npotential of the matter field is similar to the potential of the scalar field.\nThe dynamics of the universe in this case contains a sudden future singularity. \n\n"}
{"id": "1212.5151", "contents": "Title: Science with the Murchison Widefield Array Abstract: Significant new opportunities for astrophysics and cosmology have been\nidentified at low radio frequencies. The Murchison Widefield Array is the first\ntelescope in the Southern Hemisphere designed specifically to explore the\nlow-frequency astronomical sky between 80 and 300 MHz with arcminute angular\nresolution and high survey efficiency. The telescope will enable new advances\nalong four key science themes, including searching for redshifted 21 cm\nemission from the epoch of reionisation in the early Universe; Galactic and\nextragalactic all-sky southern hemisphere surveys; time-domain astrophysics;\nand solar, heliospheric, and ionospheric science and space weather. The\nMurchison Widefield Array is located in Western Australia at the site of the\nplanned Square Kilometre Array (SKA) low-band telescope and is the only\nlow-frequency SKA precursor facility. In this paper, we review the performance\nproperties of the Murchison Widefield Array and describe its primary scientific\nobjectives. \n\n"}
{"id": "1212.6007", "contents": "Title: Dark Radiation and interacting scenarios Abstract: An extra dark radiation component can be present in the universe in the form\nof sterile neutrinos, axions or other very light degrees of freedom which may\ninteract with the dark matter sector. We derive here the cosmological\nconstraints on the dark radiation abundance, on its effective velocity and on\nits viscosity parameter from current data in dark radiation-dark matter coupled\nmodels. The cosmological bounds on the number of extra dark radiation species\ndo not change significantly when considering interacting schemes. We also find\nthat the constraints on the dark radiation effective velocity are degraded by\nan order of magnitude while the errors on the viscosity parameter are a factor\nof two larger when considering interacting scenarios. If future Cosmic\nMicrowave Background data are analysed assuming a non interacting model but the\ndark radiation and the dark matter sectors interact in nature, the\nreconstructed values for the effective velocity and for the viscosity parameter\nwill be shifted from their standard 1/3 expectation, namely ceff=0.34 (+0.006\n-0.003) and cvis=0.29 (+0.002 -0.001) at 95% CL for the future COrE mission\ndata. \n\n"}
{"id": "1212.6026", "contents": "Title: Consequences of f(R)-theories of gravity on gravitational leptogenesis Abstract: f(R)-theories of gravity are reviewed in the framework of the\nmatter-antimatter asymmetry in the Universe. The asymmetry is generated by the\ngravitational coupling of heavy (Majorana) neutrinos with the Ricci scalar\ncurvature. In order that the mechanism works, a time varying non-zero Ricci\ncurvature is necessary. The latter is provided by f(R) cosmology, whose\nLagrangian density is of the form {\\cal L}(R)\\sim f(R). In particular we study\nthe cases f(R)\\sim R+\\alpha R^n and f(R)\\sim R^{1+\\epsilon}. \n\n"}
{"id": "1212.6278", "contents": "Title: The Tianlai project: a 21cm cosmology experiment Abstract: In my talk at the 2nd Galileo-Xu Meeting, I presented several different\ntopics in 21cm cosmology for which I have done research. These includes the\n21cm signature of the first stars[1,2], the 21cm signal from the IGM and\nminihalos[3], effect of dark matter annihila- tions on 21cm signal[4], the 21cm\nforest by ionized/neutral region[5], and the 21cm forest by minihalo and\nearliest galaxies[6,7]. In this conference proceeding I shall not repeat these\ndiscussions, but instead focus on the last part of my talk, i.e. the Tianlai\nproject, an experiment effort on low redshift 21cm intensity mapping\nobservation for dark energy measurements. \n\n"}
{"id": "1212.6893", "contents": "Title: Direct Distance Measurements to SN2009ip Abstract: We demonstrate the applicability of our new method (the Dense Shell Method or\nDSM) for the determination of astronomical distances by calculating the\ndistance to SN2009ip. The distance to this supernova has been accurately\ndetermined in the standard approach via the cosmic distance ladder and has been\nfound to be 20.4 Mpc. Our direct method, assuming the most reasonable parameter\nvalues, gives a very close result, namely 20.1+/-0.8 (68% CL) Mpc to SN2009ip. \n\n"}
{"id": "1301.0371", "contents": "Title: Cool Gas in High Redshift Galaxies Abstract: Over the last decade, observations of the cool interstellar medium in distant\ngalaxies via molecular and atomic fine structure line emission has gone from a\ncurious look into a few extreme, rare objects, to a mainstream tool to study\ngalaxy formation, out to the highest redshifts. Molecular gas has now been\nobserved in close to 200 galaxies at z>1, including numerous AGN host-galaxies\nout to z~7, highly starforming sub-millimeter galaxies (median redshift z~2.5),\nand increasing samples of 'main-sequence' star forming galaxies at z~1.5-2.5.\nStudies have moved well beyond simple detections, to dynamical imaging at\nkpc-scale resolution, and multi-line, multi-species studies that determine the\nphysical conditions in the interstellar medium. Observations of the cool gas\nare the required complement to studies of the stellar density and star\nformation history of the Universe, as they reveal the phase of the interstellar\nmedium that immediately precedes star formation. Current observations suggest\nthat the order of magnitude increase in the cosmic star formation rate density\nfrom z~0 to 2 is commensurate with a similar increase in the gas to stellar\nmass ratio in star forming disk galaxies. Progress has been made on determining\nthe CO luminosity to H_2 mass conversion factor at high-z, and the dichotomy\nbetween high versus low depletion time values for main sequence versus\nstarburst galaxies, respectively, with a likely dependence on metallicity and\nother local physical conditions. Studies of atomic fine structure line emission\nare rapidly progressing, with some tens of galaxies detected in the\nexceptionally bright [CII] 158 micron line to date. This line is proving to be\na unique tracer of galaxy dynamics in the early Universe and has the potential\nto be the most direct means of obtaining spectroscopic redshifts for the first\ngalaxies during cosmic reionization. \n\n"}
{"id": "1301.0514", "contents": "Title: Simulation of optical interstellar scintillation Abstract: Stars twinkle because their light propagates through the atmosphere. The same\nphenomenon is expected on a longer time scale when the light of remote stars\ncrosses an interstellar turbulent molecular cloud, but it has never been\nobserved at optical wavelengths. The aim of the study described in this paper\nis to fully simulate the scintillation process, starting from the molecular\ncloud description as a fractal object, ending with the simulations of\nfluctuating stellar light curves. Fast Fourier transforms are first used to\nsimulate fractal clouds. Then, the illumination pattern resulting from the\ncrossing of background star light through these refractive clouds is calculated\nfrom a Fresnel integral that also uses fast Fourier transform techniques.\nRegularisation procedure and computing limitations are discussed, along with\nthe effect of spatial and temporal coherency (source size and wavelength\npassband). We quantify the expected modulation index of stellar light curves as\na function of the turbulence strength --characterised by the diffraction radius\n$R_{diff}$-- and the projected source size, introduce the timing aspects, and\nestablish connections between the light curve observables and the refractive\ncloud. We extend our discussion to clouds with different structure functions\nfrom Kolmogorov-type turbulence. Our study confirms that current telescopes of\n~4m with fast-readout, wide-field detectors have the capability of discovering\nthe first interstellar optical scintillation effects. We also show that this\neffect should be unambiguously distinguished from any other type of variability\nthrough the observation of desynchronised light curves, simultaneously measured\nby two distant telescopes. \n\n"}
{"id": "1301.1242", "contents": "Title: Feeding Versus Feedback in AGNs from Near-Infrared IFU Observations: The\n  Case of Mrk79 Abstract: We have mapped the gaseous kinematics and the emission-line flux\ndistributions and ratios from the inner ~680pc radius of the Seyfert 1 galaxy\nMrk79, using two-dimensional (2D) near-IR J- and Kl-band spectra obtained with\nthe Gemini instrument NIFS at a spatial resolution of ~100pc and velocity\nresolution of ~40km/s. The molecular hydrogen flux distribution presents two\nspiral arms extending by ~700pc, one to the north and another to the south of\nthe nucleus, with an excitation indicating heating by X-rays from the central\nsource. The low velocity dispersion (sigma~50km/s) and rotation pattern\nsupports a location of the H2 gas in the disk of the galaxy. Blueshifts\nobserved along the spiral arm in the far side of the galaxy and redshifts in\nthe spiral arm in the near side, suggest that the spiral arms are feeding\nchannels of H2 to the inner 200pc. From channel maps along the H2 l2.1218um\nemission-line profile we estimate a mass inflow rate of ~4E-3 M_Sun/year, which\nis one order of magnitude smaller than the mass accretion rate necessary to\npower the AGN of Mrk79. The emission from the ionized gas (traced by Pabeta and\n[FeII]l1.2570um emission lines) is correlated with the radio jet and with the\nnarrow-band [OIII] flux distribution. Its kinematics shows both rotation and\noutflows to the north and south of the nucleus. The ionized gas mass outflow\nrate through a cross section with radius ~320pc located at a distance of ~455pc\nfrom the nucleus is 3.5 MSun/year, which is much larger than the AGN mass\naccretion rate, indicating that most of the outflowing gas originates in the\ninterstellar medium surrounding the galaxy nucleus, which is pushed away by a\nnuclear jet. \n\n"}
{"id": "1301.1677", "contents": "Title: Observations of Feedback from Radio-Quiet Quasars: I. Extents and\n  Morphologies of Ionized Gas Nebulae Abstract: Black hole feedback -- the strong interaction between the energy output of\nsupermassive black holes and their surrounding environments -- is routinely\ninvoked to explain the absence of overly luminous galaxies, the black hole vs.\nbulge correlations and the similarity of black hole accretion and star\nformation histories. Yet direct probes of this process in action are scarce and\nlimited to small samples of active nuclei. We present Gemini IFU observations\nof the distribution of ionized gas around luminous, obscured, radio-quiet (RQ)\nquasars at z~0.5. We detect extended ionized gas nebulae via [O III]5007\nemission in every case, with a mean diameter of 28 kpc. These nebulae are\nnearly perfectly round. The regular morphologies of nebulae around RQ quasars\nare in striking contrast with lumpy or elongated nebulae seen around radio\ngalaxies at low and high redshifts. We present the uniformly measured\nsize-luminosity relationship of [O III] nebulae around Seyfert 2 galaxies and\ntype 2 quasars spanning 6 orders of magnitude in luminosity and confirm the\nflat slope of the correlation (R ~ L^{0.25+/-0.02}). We find a universal\nbehavior of the [O III]/H-beta ratio in our entire RQ quasar sample: it\npersists at a constant value (~10) in the central regions, until reaching a\n\"break\" isophotal radius ranging from 4 to 11 kpc where it starts to decrease.\nWe propose a model of clumpy nebulae in which clouds that produce line emission\ntransition from being ionization-bounded at small distances from the quasar to\nbeing matter-bounded in the outer parts of the nebula, which qualitatively\nexplains the observed line ratio and surface brightness profiles. It is\nstriking that we see such smooth and round large-scale gas nebulosities in this\nsample, which are inconsistent with illuminated merger debris and which we\nsuggest may be the signature of accretion energy from the nucleus reaching gas\nat large scales. \n\n"}
{"id": "1301.2424", "contents": "Title: Axially symmetric static sources: A general framework and some\n  analytical solutions Abstract: We provide all basic equations and concepts required to carry out a general\nstudy on axially symmetric static sources. The Einstein equations and the\nconservation equations are written down for a general anisotropic static fluid\nendowed with axial symmetry. The structure scalars are calculated and the\ninhomogeneity factors are identified. Finally some exact analytical solutions\nwere found. One of these solutions describes an incompressible spheroid with\nisotropic pressure and becomes the well known interior Schwarzschild solution\nin the spherically symmetric limit, however it cannot be matched smoothly to\nany Weyl exterior metric. Another family of solutions was found that\ncorresponds to an anisotropic fluid distribution and can in principle be\nmatched to a Weyl exterior. \n\n"}
{"id": "1301.4434", "contents": "Title: Simulations of the merging galaxy cluster Abell 3376 Abstract: Observed galaxy clusters often exhibit X-ray morphologies suggestive of\nrecent interaction with an infalling subcluster. Abell 3376 is a nearby\n(z=0.046) massive galaxy cluster whose bullet-shaped X-ray emission indicates\nthat it may have undergone a recent collision. It displays a pair of Mpc-scale\nradio relics and its brightest cluster galaxy is located 970 h_70^-1 kpc away\nfrom the peak of X-ray emission, where the second brightest galaxy lies. We\nattempt to recover the dynamical history of Abell 3376. We perform a set of\nN-body adiabatic hydrodynamical simulations using the SPH code Gadget-2. These\nsimulations of binary cluster collisions are aimed at exploring the parameter\nspace of possible initial configurations. By attempting to match X-ray\nmorphology, temperature, virial mass and X-ray luminosity, we set approximate\nconstraints on some merger parameters. Our best models suggest a collision of\nclusters with mass ratio in the range 1/6-1/8, and having a subcluster with\ncentral gas density four times higher than that of the major cluster. Models\nwith small impact parameter (b<150 kpc), if any, are preferred. We estimate\nthat Abell 3376 is observed approximately 0.5 Gyr after core passage, and that\nthe collision axis is inclined by i~40 degrees with respect to the plane of the\nsky. The infalling subcluster drives a supersonic shock wave that propagates at\nalmost 2600 km/s, implying a Mach number as high as M~4; but we show how it\nwould have been underestimated as M~3 due to projection effects. \n\n"}
{"id": "1301.5407", "contents": "Title: The catalogue of positions of optically bright extragalactic radio\n  sources OBRS-2 Abstract: It is anticipated that future space-born missions, such as Gaia, will be able\nto determine in optical domain positions of more than 100,000 bright quasars\nwith sub-mas accuracies that are comparable to very long baseline\ninterferometry (VLBI) accuracies. Comparisons of coordinate systems from\nspace-born missions and from VLBI will be very important, first for\ninvestigation of possible systematic errors, second for investigation of\npossible shift between centroids of radio and optical emissions in active\ngalaxy nuclea. In order to make such a comparison more robust, a program of\ndensification of the grid of radio sources detectable with both VLBI and Gaia\nwas launched in 2006. In the second observing campaign a set of 290 objects\nfrom the list of 398 compact extragalactic radio sources with declinations\ngreater -10 deg was observed with the VLBA+EVN in 2010-2011 with the primary\ngoal of producing their images with milliarcsecond resolution. These sources\nare brighter than 18 magnitude at V band. In this paper coordinates of observed\nsources have been derived with milliarcsecond accuracies from analysis of these\nVLBI observations following the method of absolute astrometry and their images\nwere produced. The catalogue of positions of 295 target sources and estimates\nof their correlated flux densities at 2.2 and 8.4 GHz is presented. The\naccuracies of source coordinates are in a range of 2 to 200 mas, with the\nmedian 3.2 mas. \n\n"}
{"id": "1301.6243", "contents": "Title: DAMA/LIBRA results and perspectives Abstract: The DAMA/LIBRA experiment, running at the Gran Sasso National Laboratory of\nthe I.N.F.N. in Italy, has a sensitive mass of about 250 kg highly radiopure\nNaI(Tl). It is mainly devoted to the investigation of Dark Matter (DM)\nparticles in the Galactic halo by exploiting the model independent DM annual\nmodulation signature. The present DAMA/LIBRA experiment and the former DAMA/NaI\none (the first generation experiment having an exposed mass of about 100 kg)\nhave released so far results corresponding to a total exposure of 1.17 ton yr\nover 13 annual cycles. They provide a model independent evidence of the\npresence of DM particles in the galactic halo at 8.9 sigma C.L.. A short\nsummary of the obtained results is presented and future perspectives of the\nexperiment mentioned. \n\n"}
{"id": "1302.0467", "contents": "Title: Einstein@Home Discovery of 24 Pulsars in the Parkes Multi-beam Pulsar\n  Survey Abstract: We have conducted a new search for radio pulsars in compact binary systems in\nthe Parkes multi-beam pulsar survey (PMPS) data, employing novel methods to\nremove the Doppler modulation from binary motion. This has yielded unparalleled\nsensitivity to pulsars in compact binaries. The required computation time of\napproximately 17000 CPU core years was provided by the distributed volunteer\ncomputing project Einstein@Home, which has a sustained computing power of about\n1 PFlop/s. We discovered 24 new pulsars in our search, of which 18 were\nisolated pulsars, and six were members of binary systems. Despite the wide\nfilterbank channels and relatively slow sampling time of the PMPS data, we\nfound pulsars with very large ratios of dispersion measure (DM) to spin period.\nAmong those is PSR J1748-3009, the millisecond pulsar with the highest known DM\n(approximately 420 pc/cc). We also discovered PSR J1840-0643, which is in a\nbinary system with an orbital period of 937 days, the fourth largest known. The\nnew pulsar J1750-2536 likely belongs to the rare class of intermediate-mass\nbinary pulsars. Three of the isolated pulsars show long-term nulling or\nintermittency in their emission, further increasing this growing family. Our\ndiscoveries demonstrate the value of distributed volunteer computing for\ndata-driven astronomy and the importance of applying new analysis methods to\nextensively searched data. \n\n"}
{"id": "1302.1721", "contents": "Title: Bayesian Model Averaging in Astrophysics: A Review Abstract: We review the use of Bayesian Model Averaging in astrophysics. We first\nintroduce the statistical basis of Bayesian Model Selection and Model\nAveraging. We discuss methods to calculate the model-averaged posteriors,\nincluding Markov Chain Monte Carlo (MCMC), nested sampling, Population Monte\nCarlo, and Reversible Jump MCMC. We then review some applications of Bayesian\nModel Averaging in astrophysics, including measurements of the dark energy and\nprimordial power spectrum parameters in cosmology, cluster weak lensing and\nSunyaev-Zel'dovich effect data, estimating distances to Cepheids, and\nclassifying variable stars. \n\n"}
{"id": "1302.1903", "contents": "Title: An Efficient Approximation to the Likelihood for Gravitational Wave\n  Stochastic Background Detection Using Pulsar Timing Data Abstract: Direct detection of gravitational waves by pulsar timing arrays will become\nfeasible over the next few years. In the low frequency regime ($10^{-7}$ Hz --\n$10^{-9}$ Hz), we expect that a superposition of gravitational waves from many\nsources will manifest itself as an isotropic stochastic gravitational wave\nbackground. Currently, a number of techniques exist to detect such a signal;\nhowever, many detection methods are computationally challenging. Here we\nintroduce an approximation to the full likelihood function for a pulsar timing\narray that results in computational savings proportional to the square of the\nnumber of pulsars in the array. Through a series of simulations we show that\nthe approximate likelihood function reproduces results obtained from the full\nlikelihood function. We further show, both analytically and through\nsimulations, that, on average, this approximate likelihood function gives\nunbiased parameter estimates for astrophysically realistic stochastic\nbackground amplitudes. \n\n"}
{"id": "1302.4363", "contents": "Title: Calibration of the total infrared luminosity of nearby galaxies from\n  Spitzer and Herschel bands Abstract: We present new empirical calibrations to estimate resolved and integrated\ntotal infrared luminosities from Spitzer and Herschel bands used as\nmonochromatic or combined tracers. We base our calibrations on resolved\nelements of nearby galaxies (3 to 30 Mpc) observed with Herschel. We perform a\nresolved SED modelling of these objects using the Draine and Li (2007) dust\nmodels and investigate the influence of the addition of SPIRE measurements in\nthe estimation of LTIR. We find that using data up to 250 um leads to local\nLTIR values consistent with those obtained with a complete coverage (up to 500\num) within 10 per cent for most of our resolved elements. We then study the\ndistribution of energy in the resolved SEDs of our galaxies. The bulk of energy\n(30-50 per cent) is contained in the (70-160 um) band. The (24-70 um) fraction\ndecreases with increasing metallicity. The (160-1100 um) submillimeter band can\naccount for up to 25 per cent of the LTIR in metal-rich galaxies. We\ninvestigate the correlation between TIR surface brightnesses/luminosities and\nmonochromatic Spitzer and Herschel surface brightnesses/luminosities. The three\nPACS bands can be used as reliable monochromatic estimators of the LTIR, the\n100 um band being the most reliable monochromatic tracer. There is also a\nstrong correlation between the SPIRE 250um and LTIR, although with more scatter\nthan for the PACS relations. We also study the ability of our monochromatic\nrelations to reproduce integrated LTIR of nearby galaxies as well as LTIR of\nz=1-3 sources. Finally, we provide calibration coefficients that can be used to\nderive TIR surface brightnesses/luminosities from a combination of Spitzer and\nHerschel surface brightnesses/fluxes and analyse the associated uncertainties. \n\n"}
{"id": "1303.0384", "contents": "Title: Cosmological constraints on holographic dark energy models under the\n  energy conditions Abstract: We study the holographic and agegraphic dark energy models without\ninteraction using the latest observational Hubble parameter data (OHD), the\nUnion2.1 compilation of type Ia supernovae (SNIa), and the energy conditions.\nScenarios of dark energy are distinguished by the cut-off of cosmic age,\nconformal time, and event horizon. The best-fit value of matter density for the\nthree scenarios almost steadily located at $\\Omega_{m0}=0.26$ by the joint\nconstraint. For the agegraphic models, they can be recovered to the standard\ncosmological model when the constant $c$ which presents the fraction of dark\nenergy approaches to infinity. Absence of upper limit of $c$ by the joint\nconstraint demonstrates the recovery possibility. Using the fitted result, we\nalso reconstruct the current equation of state of dark energy at different\nscenarios, respectively. Employing the model criteria\n$\\chi^2_{\\textrm{min}}/dof$, we find that conformal time model is the worst,\nbut they can not be distinguished clearly. Comparing with the observational\nconstraints, we find that SEC is fulfilled at redshift $0.2 \\lesssim z \\lesssim\n0.3$ with $1\\sigma$ confidence level. We also find that NEC gives a meaningful\nconstraint for the event horizon cut-off model, especially compared with OHD\nonly. We note that the energy condition maybe could play an important role in\nthe interacting models because of different degeneracy between $\\Omega_m$ and\nconstant $c$. \n\n"}
{"id": "1303.0897", "contents": "Title: A new technique for the determination of the initial mass function in\n  unresolved stellar populations Abstract: We present a new technique for the determination of the low-mass slope\n($\\alpha_1$; $M_* < 0.5 M_{\\odot}$) of the present day stellar mass function\n(PDMF) using the pixel space fitting of integrated light spectra. It can be\nused to constrain the initial mass function (IMF) of stellar systems with\nrelaxation timescales exceeding the Hubble time and testing the IMF\nuniversality hypothesis. We provide two versions of the technique: (1) a fully\nunconstrained determination of the age, metallicity, and $\\alpha_1$ and (2) a\nconstrained fitting by imposing the externally determined mass-to-light ratio\nof the stellar population. We have tested our approach by Monte-Carlo\nsimulations using mock spectra and conclude that: (a) age, metallicity and\n$\\alpha_1$ can be precisely determined by applying the unconstrained version of\nthe code to high signal-to-noise datasets (S/N=100, R=7000 yield $\\Delta\n\\alpha_1 \\approx 0.1$); (b) the $M/L$ constraint significantly improves the\nprecision and reduces the degeneracies, however its systematic errors will\ncause biased $\\alpha_1$ estimates; (c) standard Lick indices cannot constrain\nthe PDMF because they miss most of the mass function sensitive spectral\nfeatures; (d) the $\\alpha_1$ determination remains unaffected by the high-mass\nIMF shape ($\\alpha_3$; $M_* \\ge 1 M_{\\odot}$) variation for stellar systems\nolder than 8 Gyr, while the intermediate-mass IMF slope ($\\alpha_2$; $0.5 \\le\nM_* < 1 M_{\\odot}$) may introduce biases into the best-fitting $\\alpha_1$\nvalues if it is different from the canonical value $\\alpha_2 = 2.3$. We\nanalysed observed intermediate resolution spectra of ultracompact dwarf\ngalaxies with our technique and demonstrated its applicability to real data. \n\n"}
{"id": "1303.2119", "contents": "Title: Non-Gaussianity Unleashed Abstract: The Hamilton-Jacobi (HJ) approach for exploring inflationary trajectories is\nemployed in the generation of generalised inflationary non-Gaussian signals\narising from single field inflation. Scale dependent solutions for $f_{NL}$ are\ndetermined via the numerical integration of the three--point function in the\ncurvature perturbation. This allows the full exploration of single field\ninflationary dynamics in the out-of-slow-roll regime and opens up the\npossibility of using future observations of non-Gaussianity to constraint the\ninflationary potential using model-independent methods. The distribution of\n`equilateral' $f_{NL}$ arising from single field inflation with both canonical\nand non-canonical kinetic terms are show as an example of the application of\nthis procedure. \n\n"}
{"id": "1303.3538", "contents": "Title: The Bluedisks project, a study of unusually HI-rich galaxies: I. HI\n  Sizes and Morphology Abstract: We introduce the \"Bluedisk\" project, a large program at the Westerbork\nSynthesis Radio Telescope (WSRT) that has mapped the HI in a sample of 23\nnearby galaxies with unusually high HI mass fractions, along with a\nsimilar-sized sample of control galaxies matched in stellar mass, size,\ninclination and redshift. This paper presents the sample selection,\nobservational set-up, data reduction strategy, and a first analysis of the\nsizes and structural properties of the HI disks. We find that the HI-rich\ngalaxies lie on the same HI mass versus HI size relation as normal spiral\ngalaxies, extending it to total HI masses of $2 \\times 10^{10} M_{\\odot}$ and\nradii R1 of $\\sim 100$ kpc (where R1 is defined as the radius where the HI\ncolumn density reaches 1 $M_{\\odot}$ pc$^{-2}$). HI-rich galaxies have\nsignificantly larger values of HI-to-optical size ratio at fixed stellar mass,\nconcentration index, stellar and star formation rate surface density compared\nto the control sample. The disks of HI-rich galaxies are also significantly\nmore clumpy (i.e. have higher HI Gini and $\\Delta$Area coefficient) than those\nof normal spirals. There is no evidence that the disks of HI-rich galaxies are\nmore disturbed: HI-rich galaxies exhibit no difference with respect to control\nsamples in their distributions of HI asymmetry indices or optical/HI disk\nposition angle differences. In fact, the center of the HI distribution\ncorresponds more closely with the center of the optical light in the HI-rich\ngalaxies than in the controls. All these results argue against a scenario in\nwhich new gas has been brought in by mergers. It is possible that they may be\nmore consistent with cooling from a surrounding quasi-static halo of warm/hot\ngas. \n\n"}
{"id": "1303.4714", "contents": "Title: The Atacama Cosmology Telescope: Beam Measurements and the Microwave\n  Brightness Temperatures of Uranus and Saturn Abstract: We describe the measurement of the beam profiles and window functions for the\nAtacama Cosmology Telescope (ACT), which operated from 2007 to 2010 with\nkilo-pixel bolometer arrays centered at 148, 218, and 277 GHz. Maps of Saturn\nare used to measure the beam shape in each array and for each season of\nobservations. Radial profiles are transformed to Fourier space in a way that\npreserves the spatial correlations in the beam uncertainty, to derive window\nfunctions relevant for angular power spectrum analysis. Several corrections are\napplied to the resulting beam transforms, including an empirical correction\nmeasured from the final CMB survey maps to account for the effects of mild\npointing variation and alignment errors. Observations of Uranus made regularly\nthroughout each observing season are used to measure the effects of atmospheric\nopacity and to monitor deviations in telescope focus over the season. Using the\nWMAP-based calibration of the ACT maps to the CMB blackbody, we obtain precise\nmeasurements of the brightness temperatures of the Uranus and Saturn disks at\neffective frequencies of 149 and 219 GHz. For Uranus we obtain thermodynamic\nbrightness temperatures T_U^{149} = 106.7 \\pm 2.2 K and T_U^{219} = 100.1 \\pm\n3.1 K. For Saturn, we model the effects of the ring opacity and emission using\na simple model and obtain resulting (unobscured) disk temperatures of T_S^{149}\n= 137.3 \\pm 3.2 K and T_S^{219} = 137.3 \\pm 4.7 K. \n\n"}
{"id": "1303.5068", "contents": "Title: Planck 2013 results. VII. HFI time response and beams Abstract: This paper characterizes the effective beams,the effective beam window\nfunctions and the associated errors for the Planck HFI detectors. The effective\nbeam is the angular response including the effect of the optics,detectors,data\nprocessing and the scan strategy. The window function is the representation of\nthis beam in the harmonic domain which is required to recover an unbiased\nmeasurement of the CMB angular power spectrum. The HFI is a scanning instrument\nand its effective beams are the convolution of: (a) the optical response of the\ntelescope and feeds;(b)the processing of the time-ordered data and\ndeconvolution of the bolometric and electronic time response; and (c) the\nmerging of several surveys to produce maps. The time response functions are\nmeasured using observations of Jupiter and Saturn and by minimizing survey\ndifference residuals. The scanning beam is the post-deconvolution angular\nresponse of the instrument, and is characterized with observations of Mars. The\nmain beam solid angles are determined to better than 0.5% at each HFI frequency\nband. Observations of Jupiter and Saturn limit near sidelobes (within 5deg) to\nabout 0.1% of the total solid angle. Time response residuals remain as long\ntails in the scanning beams, but contribute less than 0.1% of the total. The\nbias and uncertainty in the beam products are estimated using ensembles of\nsimulated planet observations that include the impact of instrumental noise and\nknown systematic effects.The correlation structure of these ensembles is\nwell-described by five error eigenmodes that are sub-dominant to sample\nvariance and instrumental noise in the harmonic domain. A suite of consistency\ntests provide confidence that the error model represents a sufficient\ndescription of the data. The total error in the effective beam window functions\nis below 1% at 100GHz up to ell~1500$,and below 0.5% at 143 and 217GHz up to\n~2000. \n\n"}
{"id": "1303.5076", "contents": "Title: Planck 2013 results. XVI. Cosmological parameters Abstract: We present the first results based on Planck measurements of the CMB\ntemperature and lensing-potential power spectra. The Planck spectra at high\nmultipoles are extremely well described by the standard spatially-flat\nsix-parameter LCDM cosmology. In this model Planck data determine the\ncosmological parameters to high precision. We find a low value of the Hubble\nconstant, H0=67.3+/-1.2 km/s/Mpc and a high value of the matter density\nparameter, Omega_m=0.315+/-0.017 (+/-1 sigma errors) in excellent agreement\nwith constraints from baryon acoustic oscillation (BAO) surveys. Including\ncurvature, we find that the Universe is consistent with spatial flatness to\npercent-level precision using Planck CMB data alone. We present results from an\nanalysis of extensions to the standard cosmology, using astrophysical data sets\nin addition to Planck and high-resolution CMB data. None of these models are\nfavoured significantly over standard LCDM. The deviation of the scalar spectral\nindex from unity is insensitive to the addition of tensor modes and to changes\nin the matter content of the Universe. We find a 95% upper limit of r<0.11 on\nthe tensor-to-scalar ratio. There is no evidence for additional neutrino-like\nrelativistic particles. Using BAO and CMB data, we find N_eff=3.30+/-0.27 for\nthe effective number of relativistic degrees of freedom, and an upper limit of\n0.23 eV for the summed neutrino mass. Our results are in excellent agreement\nwith big bang nucleosynthesis and the standard value of N_eff=3.046. We find no\nevidence for dynamical dark energy. Despite the success of the standard LCDM\nmodel, this cosmology does not provide a good fit to the CMB power spectrum at\nlow multipoles, as noted previously by the WMAP team. While not of decisive\nsignificance, this is an anomaly in an otherwise self-consistent analysis of\nthe Planck temperature data. \n\n"}
{"id": "1303.5087", "contents": "Title: Planck 2013 results. XXVII. Doppler boosting of the CMB: Eppur si muove Abstract: Our velocity relative to the rest frame of the cosmic microwave background\n(CMB) generates a dipole temperature anisotropy on the sky which has been well\nmeasured for more than 30 years, and has an accepted amplitude of v/c =\n0.00123, or v = 369km/s. In addition to this signal generated by Doppler\nboosting of the CMB monopole, our motion also modulates and aberrates the CMB\ntemperature fluctuations (as well as every other source of radiation at\ncosmological distances). This is an order 0.1% effect applied to fluctuations\nwhich are already one part in roughly one hundred thousand, so it is quite\nsmall. Nevertheless, it becomes detectable with the all-sky coverage, high\nangular resolution, and low noise levels of the Planck satellite. Here we\nreport a first measurement of this velocity signature using the aberration and\nmodulation effects on the CMB temperature anisotropies, finding a component in\nthe known dipole direction, (l,b)=(264, 48) [deg], of 384km/s +- 78km/s (stat.)\n+- 115km/s (syst.). This is a significant confirmation of the expected\nvelocity. \n\n"}
{"id": "1303.5328", "contents": "Title: Updated Nearby Galaxy Catalog Abstract: We present an all-sky catalog of 869 nearby galaxies, having individual\ndistance estimates within 11 Mpc or corrected radial velocities V_{LG} < 600\nkm/s. The catalog is a renewed and expanded version of the \"Catalog of\nNeighboring Galaxies\" by Karachentsev et al. (2004). It collects data on the\nfollowing observables for the galaxies: angular diameters, apparent magnitudes\nin FUV-, B-, and K_s- bands, H_alpha and HI fluxes, morphological types,\nHI-line widths, radial velocities and distance estimates. In this Local Volume\n(LV) sample 108 dwarf galaxies remain to be still without measured radial\nvelocities.\n  The catalog yields also calculated global galaxy parameters: linear Holmberg\ndiameter, absolute B-magnitude, surface brightness, HI-mass, stellar mass\nestimated via K-band luminosity, HI rotational velocity corrected for galaxy\ninclination, indicative mass within the Holmberg radius, and three kinds of\n\"tidal index\", which quantify the local density environment. The catalog is\nsupplemented with the data based on the local galaxies\n(http://www.sao.ru/lv/lvgdb), which presents their optical and available\nH_alpha images, as well as other service.\n  We briefly discuss the Hubble flow within the LV, and different scaling\nrelations that characterize galaxy structure and global star formation in them.\nWe also trace the behavior of the mean stellar mass density, HI-mass density\nand star formation rate density within the considered volume. \n\n"}
{"id": "1303.6116", "contents": "Title: Using electromagnetic observations to aid gravitational-wave parameter\n  estimation of compact binaries observed with LISA II: The effect of knowing\n  the sky position Abstract: In this follow-up paper, we continue our study of the effect of using\nknowledge from electromagnetic observations in the gravitational wave (GW) data\nanalysis of Galactic binaries that are predicted to be observed by the new\n\\textit{Laser Interferometer Space Antenna} in the low-frequency range,\n$10^{-4} \\:\\mathrm{Hz}<f<1 \\:\\mathrm{Hz}$. In the first paper, we have shown\nthat the strong correlation between amplitude and inclination can be used for\nmildly inclined binaries to improve the uncertainty in amplitude, and that this\ncorrelation depends on the inclination of the system. In this paper we\ninvestigate the overall effect of the other orientation parameters, namely the\nsky position and the polarisation angle. We find that after the inclination,\nthe ecliptic latitude of the source has the strongest effect in determining the\nGW parameter uncertainties. We ascertain that the strong correlation we found\npreviously, only depends on the inclination of the source and not on the other\norientation parameters. We find that knowing the sky position of the source\nfrom electromagnetic data can reduce the GW parameter uncertainty up to a\nfactor of $\\sim 2$, depending on the inclination and the ecliptic latitude of\nthe system. Knowing the sky position and inclination can reduce the uncertainty\nin amplitude by a factor larger than 40. We also find that unphysical errors in\nthe inclinations, which we found when using the Fisher matrix, can affect the\ncorresponding uncertainties in the amplitudes, which need to be corrected. \n\n"}
{"id": "1303.6267", "contents": "Title: Dark Radiation or Warm Dark Matter from long lived particle decays in\n  the light of Planck Abstract: Although Planck data supports the standard \\Lambda CDM model, it still allows\nfor the presence of Dark Radiation corresponding up to about half an extra\nstandard neutrino species. We propose a scenario for obtaining a fractional\n\"effective neutrino species\" from a thermally produced particle which decays\ninto a much lighter stable relic plus standard fermions. At lifetimes much\nlonger than 1 sec, both the relic particles and the non-thermal neutrino\ncomponent contribute to Dark Radiation. By increasing the stable-to-unstable\nparticle mass ratio, the relic particle no longer acts as Dark Radiation but\ninstead becomes a candidate for Warm Dark Matter with mass O(1keV - 100GeV). In\nboth cases it is possible to address the lithium problem. \n\n"}
{"id": "1303.6877", "contents": "Title: Acoustic Calibration for the KM3NeT Pre-Production Module Abstract: The proposed large scale Cherenkov neutrino telescope KM3NeT will carry\nphoto-sensors on flexible structures, the detection units. The Mediterranean\nSea, where KM3NeT will be installed, constitutes a highly dynamic environment\nin which the detection units are constantly in motion. Thus it is necessary to\nmonitor the exact sensor positions continuously to achieve the desired\nresolution for the neutrino telescope. A common way to perform this monitoring\nis the use of acoustic positioning systems with emitters and receivers based on\nthe piezoelectric effect. The acoustic receivers are attached to detection\nunits whereas the emitters are located at known positions on the sea floor.\nThere are complete commercial systems for this application with sufficient\nprecision. But these systems are limited in the use of their data and\ninefficient as they were designed to perform only this single task. Several\nworking groups in the KM3NeT consortium are cooperating to custom-design a\npositioning system for the specific requirements of KM3NeT. Most of the studied\nsolutions hold the possibility to extend the application area from positioning\nto additional tasks like acoustic particle detection or monitoring of the\ndeep-sea acoustic environment. The KM3NeT Pre-Production Module (PPM) is a test\nsystem to verify the correct operation and interoperability of the major\ninvolved hardware and software components developed for KM3NeT. In the context\nof the PPM, alternative designs of acoustic sensors including small\npiezoelectric elements equipped with preamplifiers inside the same housing as\nthe optical sensors will be tested. These will be described in this article. \n\n"}
{"id": "1304.0989", "contents": "Title: Constraints on axion-like particles from X-ray observations of Hydra\n  galaxy cluster Abstract: Axion-like particles (ALPs) belong to a class of new pseudoscalar particles\nthat generically couple to photons, opening the possibility of oscillations\nfrom photons into ALPs in an external magnetic field. Having witnessed the\nturbulence of their magnetic fields, these oscillations are expected to imprint\nirregularities in a limited energy range of the spectrum of astrophysical\nsources. In this study, Chandra observations of the Hydra galaxy cluster are\nused to constrain the value of the coupling of ALPs to photons. We consider the\nconversion of X-ray photons from the central source Hydra A in the magnetic\nfield of the cluster. The magnetic field strength and structure are well\ndetermined observationally, which adds to the robustness of the analysis. The\nabsence of anomalous irregularities in the X-ray spectrum of Hydra A\nconservatively provides the most competitive constraints on the coupling\nconstant for ALP masses below 7e-12 eV at the level of g < 8.3e-12 GeV-1 at the\n95% confidence level. Because of the specific phenomenology involved, these\nconstraints actually hold more generally for very light pseudo-Nambu-Goldstone\nbosons. \n\n"}
{"id": "1304.2404", "contents": "Title: DESPOTIC -- A New Software Library to Derive the Energetics and SPectra\n  of Optically Thick Interstellar Clouds Abstract: I describe DESPOTIC, a code to Derive the Energetics and SPectra of Optically\nThick Interstellar Clouds. DESPOTIC represents such clouds using a one-zone\nmodel, and can calculate line luminosities, line cooling rates, and in\nrestricted cases line profiles using an escape probability formalism. It also\nincludes approximate treatments of the dominant heating, cooling, and chemical\nprocesses for the cold interstellar medium, including cosmic ray and X-ray\nheating, grain photoelectric heating, heating of the dust by infrared and\nultraviolet radiation, thermal cooling of the dust, collisional energy exchange\nbetween dust and gas, and a simple network for carbon chemistry. Based on these\nheating, cooling, and chemical rates, DESPOTIC can calculate clouds'\nequilibrium gas and dust temperatures, equilibrium carbon chemical state, and\ntime-dependent thermal and chemical evolution. The software is intended to\nallow rapid and interactive calculation of clouds' characteristic temperatures,\nidentification of their dominant heating and cooling mechanisms, and prediction\nof their observable spectra across a wide range of interstellar environments.\nDESPOTIC is implemented as a Python package, and is released under the GNU\nGeneral Public License. \n\n"}
{"id": "1304.6088", "contents": "Title: The Observable Thermal and Kinetic Sunyaev-Zel'dovich Effect in Merging\n  Galaxy Clusters Abstract: The advent of high-resolution imaging of galaxy clusters using the\nSunyaev-Zel'dovich Effect (SZE) provides a unique probe of the astrophysics of\nthe intracluster medium (ICM) out to high redshifts. To investigate the effects\nof cluster mergers on resolved SZE images, we present a high-resolution\ncosmological simulation of a 1.5E15 M_sun adiabatic cluster using the TreeSPH\ncode ChaNGa. This massive cluster undergoes a 10:3:1 ratio triple merger\naccompanied by a dramatic rise in its integrated Compton-Y, peaking at z =\n0.05. By modeling the thermal SZE (tSZ) and kinetic SZE (kSZ) spectral\ndistortions of the Cosmic Microwave Background (CMB) at this redshift with\nrelativistic corrections, we produce various mock images of the cluster at\nfrequencies and resolutions achievable with current high-resolution SZE\ninstruments. The two gravitationally-bound merging subclusters account for 10%\nand 1% of the main cluster's integrated Compton-Y, and have extended merger\nshock features in the background ICM visible in our mock images. We show that\nalong certain projections and at specific frequencies, the kSZ CMB intensity\ndistortion can dominate over the tSZ due to the large line of sight velocities\nof the subcluster gas and the unique frequency-dependence of these effects. We\nestimate that a one-velocity assumption in estimation of line of sight\nvelocities of the merging subclusters from the kSZ induces a bias of ~10%. This\nvelocity bias is small relative to other sources of uncertainty in\nobservations, partially due to helpful bulk motions in the background ICM\ninduced by the merger. Our results show that high-resolution SZE observations,\nwhich have recently detected strong kSZ signals in subclusters of merging\nsystems, can robustly probe the dynamical as well as the thermal state of the\nICM. \n\n"}
{"id": "1305.0497", "contents": "Title: Ellipticity and prolaticity of the initial gravitational-shear field at\n  the position of density maxima Abstract: Dark-matter haloes are supposed to form at the positions of maxima in the\ninitial matter density field. The gravitational-shear field's ellipticity and\nprolaticity that serve as input for the ellipsoidal-collapse model, however,\nare derived from a distribution that does not take the additional maximum\nconstraint into account. In this article, I quantify the variations of the most\nprobable and the expected values of the ellipticity and the prolaticity when\nconsidering this additional constraint as well as the implications for the\nellipsoidal-collapse model. Based on the statistics of Gaussian random fields,\nit is possible to set up a joint distribution for the eigenvalues of the\ngravitational-shear tensor and the matter density that incorporates the maximum\nconstraint by invoking a vanishing first derivative and a negative definite\nsecond derivative of the density field into the calculation. In the density\nrange relevant for cosmological structure formation, both the most probable and\nthe expected value of the ellipticity calculated from the standard distribution\nused in the literature are about 3-8 per cent higher compared to the ones\ncalculated under the additional assumption of a density maximum. Additionally,\nthe analogous quantities for the prolaticity do not vanish but acquire slightly\npositive values in the range of $10^{-3}$-$10^{-2}$. For large overdensities,\nthe predictions from both distributions converge. The values for\n$\\delta_\\mathrm{c}$ and $\\Delta_\\mathrm{v}$ derived from the\nellipsoidal-collapse model using the standard distribution for the initial\nellipticity and prolaticity are up to 4 and 6 per cent higher, respectively,\nthan those obtained taking the additional maximum constraint into account in\nthe range of $10^{13}$-$10^{15}~h^{-1}~\\mathrm{M}_\\odot$ in mass and 0-2 in\nredshift. \n\n"}
{"id": "1305.0753", "contents": "Title: Statistical Distribution of the Vacuum Energy Density in Racetrack\n  K\\\"ahler Uplift Models in String Theory Abstract: We study a racetrack model in the presence of the leading alpha'-correction\nin flux compactification in Type IIB string theory, for the purpose of getting\nconceivable de-Sitter vacua in the large compactified volume approximation.\nUnlike the K\\\"ahler Uplift model studied previously, the alpha'-correction is\nmore controllable for the meta-stable de-Sitter vacua in the racetrack case\nsince the constraint on the compactified volume size is very much relaxed. We\nfind that the vacuum energy density \\Lambda for de-Sitter vacua approaches zero\nexponentially as the volume grows. We also analyze properties of the\nprobability distribution of \\Lambda in this class of models. As in other cases\nstudied earlier, the probability distribution again peaks sharply at \\Lambda=0.\nWe also study the Racetrack K\\\"ahler Uplift model in the Swiss-Cheese type\nmodel. \n\n"}
{"id": "1305.0835", "contents": "Title: A Bayesian analysis pipeline for continuous GW sources in the PTA band Abstract: The direct detection of Gravitational Waves (GWs) by Pulsar Timing Arrays\n(PTAs) is very likely within the next decade. While the stochastic GW\nbackground is a promising candidate for detection it is also possible that\nsingle resolvable sources may be detectable as well. In this work we will focus\non the detection and characterization of single GW sources from supermassive\nblack hole binaries (SMBHBs). We introduce a fully Bayesian data analysis\npipeline that is meant to carry out a search, characterization, and evaluation\nphase. This will allow us to rapidly locate the global maxima in parameter\nspace, map out the posterior, and finally weigh the evidence of a GW detection\nthrough a Bayes Factor. Here we will make use of an adaptive metropolis (AM)\nalgorithm and parallel tempering. We test this algorithm on realistic simulated\ndata that are representative of modern PTAs. \n\n"}
{"id": "1305.0934", "contents": "Title: Redshift-space distortions from the cross-correlation of photometric\n  populations Abstract: Several papers have recently highlighted the possibility of measuring\nredshift space distortions from angular auto-correlations of galaxies in\nphotometric redshift bins. In this work we extend this idea to include as\nobservables the cross-correlations between redshift bins, as an additional way\nof measuring radial information. We show that this extra information allows to\nreduce the recovered error in the growth rate index \\gamma by a factor of ~2.\nAlthough the final error in \\gamma depends on the bias and the mean photometric\naccuracy of the galaxy sample, the improvement from adding cross-correlations\nis robust in different settings. Another factor of 2-3 improvement in the\ndetermination of \\gamma can be achieved by considering two galaxy populations\nover the same photometric sky area but with different biases. This additional\ngain is shown to be much larger than the one from the same populations when\nobserved over different areas of the sky (with twice the combined area). The\ntotal improvement of ~5 implies that a photometric survey such as the Dark\nEnergy Survey should be able to recover \\gamma at the 5-10% from the angular\nclustering in linear scales of two different tracers. It can also constrain the\nevolution of f(z)x\\sigma_8(z) in few bins beyond z~0.8-0.9 at the 10-15% level\nper-bin, compatible with recent constrains from lower-z spectroscopic surveys.\nWe also show how further improvement can be achieved by reducing the\nphotometric redshift error. \n\n"}
{"id": "1305.3130", "contents": "Title: HERschel Observations of Edge-on Spirals (HEROES). I: Far-infrared\n  morphology and dust mass determination Abstract: Context. Edge-on spiral galaxies with prominent dust lanes provide us with an\nexcellent opportunity to study the distribution and properties of the dust\nwithin them. The HEROES project was set up to observe a sample of seven large\nedge-on galaxies across various wavelengths for this investigation.\n  Aims. Within this first paper, we present the Herschel observations and\nperform a qualitative and quantitative analysis on them, and we derive some\nglobal properties of the far infrared and submillimetre emission.\n  Methods. We determine horizontal and vertical profiles from the Herschel\nobservations of the galaxies in the sample and describe the morphology.\nModified black-body fits to the global fluxes, measured using aperture\nphotometry, result in dust temperatures and dust masses. The latter values are\ncompared to those that are derived from radiative transfer models taken from\nthe literature.\n  Results. On the whole, our Herschel flux measurements agree well with\narchival values. We find that the exponential horizontal dust distribution\nmodel often used in the literature generally provides a good description of the\nobserved horizontal profiles. Three out of the seven galaxies show signatures\nof extended vertical emission at 100 and 160 {\\mu}m at the 5{\\sigma} level, but\nin two of these it is probably due to deviations from an exactly edge-on\norientation. Only for NGC 4013, a galaxy in which vertically extended dust has\nalready been detected in optical images, we can detect vertically extended\ndust, and the derived scaleheight agrees with the value estimated through\nradiative transfer modelling. Our analysis hints at a correlation between the\ndust scaleheight and its degree of clumpiness, which we infer from the\ndifference between the dust masses as calculated from modelling of optical data\nand from fitting the spectral energy distribution of Herschel datapoints. \n\n"}
{"id": "1305.5177", "contents": "Title: Infrared background signatures of the first black holes Abstract: Angular fluctuations of the Near InfraRed Background (NIRB) intensity are\nobserved up to scales $\\simlt 1^{\\ensuremath{^{\\circ}}}$. Their interpretation\nis challenging as even after removing the contribution from detected sources,\nthe residual signal is $>10$ times higher than expected from distant galaxies\nbelow the detection limit and first stars. We propose here a novel\ninterpretation in which early, intermediate mass, accreting direct collapse\nblack holes (DCBH), which are too faint to be detected individually in current\nsurveys, could explain the observed fluctuations. We find that a population of\nhighly obscured ($N_{\\rm H}\\simgt 10^{25} \\rm cm^{-2}$) DCBHs formed in\nmetal-free halos with virial temperature $10^4$ K at $z\\simgt 12$, can explain\nthe observed level $\\approx 10^{-3}$ (nW m$^{-2}$ sr$^{-1})^2$ of the 3.6 and\n4.5 $\\mu$m fluctuations on scales $>100''$. The signal on smaller scales is\ninstead produced by undetected galaxies at low and intermediate redshifts.\nAlbeit Compton-thick, at scales $\\theta> 100''$ DCBHs produce a CXB (0.5-2\nkeV)-NIRB ($4.5 \\rm \\mu m$) cross-correlation signal of $\\simeq 10^{-11}$ erg\ns$^{-1}$ cm$^{-2}$ nW m$^{-2}$ sr$^{-1}$ slightly dependent on the specific\nvalue of the absorbing gas column ($N_{\\rm H} \\approx 10^{25} \\rm cm^{-2}$)\nadopted and in agreement with the recent measurements by\n\\cite{2012arXiv1210.5302C}. At smaller scales the cross-correlation is\ndominated by the emission of high-mass X-ray binaries (HMXB) hosted by the same\nlow-$z$, undetected galaxies accounting for small scale NIRB fluctuations.\nThese results outline the great potential of the NIRB as a tool to investigate\nthe nature of the first galaxies and black holes. \n\n"}
{"id": "1305.5639", "contents": "Title: Scaling Radio Astronomy Signal Correlation on Heterogeneous\n  Supercomputers Using Various Data Distribution Methodologies Abstract: Next generation radio telescopes will require orders of magnitude more\ncomputing power to provide a view of the universe with greater sensitivity. In\nthe initial stages of the signal processing flow of a radio telescope, signal\ncorrelation is one of the largest challenges in terms of handling huge data\nthroughput and intensive computations. We implemented a GPU cluster based\nsoftware correlator with various data distribution models and give a systematic\ncomparison based on testing results obtained using the Fornax supercomputer. By\nanalyzing the scalability and throughput of each model, optimal approaches are\nidentified across a wide range of problem sizes, covering the scale of next\ngeneration telescopes. \n\n"}
{"id": "1306.0010", "contents": "Title: A Two-moment Radiation Hydrodynamics Module in Athena Using a\n  Time-explicit Godunov Method Abstract: We describe a module for the Athena code that solves the gray equations of\nradiation hydrodynamics (RHD), based on the first two moments of the radiative\ntransfer equation. We use a combination of explicit Godunov methods to advance\nthe gas and radiation variables including the non-stiff source terms, and a\nlocal implicit method to integrate the stiff source terms. We adopt the M1\nclosure relation and include all leading source terms. We employ the reduced\nspeed of light approximation (RSLA) with subcycling of the radiation variables\nin order to reduce computational costs. Our code is dimensionally unsplit in\none, two, and three space dimensions and is parallelized using MPI. The\nstreaming and diffusion limits are well-described by the M1 closure model, and\nour implementation shows excellent behavior for a problem with a concentrated\nradiation source containing both regimes simultaneously. Our operator-split\nmethod is ideally suited for problems with a slowly varying radiation field and\ndynamical gas flows, in which the effect of the RSLA is minimal. We present an\nanalysis of the dispersion relation of RHD linear waves highlighting the\nconditions of applicability for the RSLA. To demonstrate the accuracy of our\nmethod, we utilize a suite of radiation and RHD tests covering a broad range of\nregimes, including RHD waves, shocks, and equilibria, which show second-order\nconvergence in most cases. As an application, we investigate radiation-driven\nejection of a dusty, optically thick shell in the interstellar medium (ISM).\nFinally, we compare the timing of our method with other well-known iterative\nschemes for the RHD equations. Our code implementation, Hyperion, is suitable\nfor a wide variety of astrophysical applications and will be made freely\navailable on the Web. \n\n"}
{"id": "1306.0792", "contents": "Title: Interpreting signals from astrophysical transient experiments Abstract: Time domain astronomy has come of age with astronomers now able to monitor\nthe sky at high cadence both across the electromagnetic spectrum and using\nneutrinos and gravitational waves. The advent of new observing facilities\npermits new science, but the ever increasing throughput of facilities demands\nefficient communication of coincident detections and better subsequent\ncoordination among the scientific community so as to turn detections into\nscientific discoveries. To discuss the revolution occurring in our ability to\nmonitor the Universe and the challenges it brings, on 2012 April 25-26 a group\nof scientists from observational and theoretical teams studying transients met\nwith representatives of the major international transient observing facilities\nat the Kavli Royal Society International Centre, UK. This immediately followed\nthe Royal Society Discussion meeting \"New windows on transients across the\nUniverse\" held in London. Here we present a summary of the Kavli meeting at\nwhich the participants discussed the science goals common to the transient\nastronomy community and analysed how to better meet the challenges ahead as\never more powerful observational facilities come on stream. \n\n"}
{"id": "1306.0913", "contents": "Title: Cold dark matter: controversies on small scales Abstract: The cold dark matter (CDM) cosmological model has been remarkably successful\nin explaining cosmic structure over an enormous span of redshift, but it has\nfaced persistent challenges from observations that probe the innermost regions\nof dark matter halos and the properties of the Milky Way's dwarf galaxy\nsatellites. We review the current observational and theoretical status of these\n\"small scale controversies.\" Cosmological simulations that incorporate only\ngravity and collisionless CDM predict halos with abundant substructure and\ncentral densities that are too high to match constraints from galaxy dynamics.\nThe solution could lie in baryonic physics: recent numerical simulations and\nanalytic models suggest that gravitational potential fluctuations tied to\nefficient supernova feedback can flatten the central cusps of halos in massive\ngalaxies, and a combination of feedback and low star-formation efficiency could\nexplain why most of the dark matter subhalos orbiting the Milky Way do not host\nvisible galaxies. However, it is not clear that this solution can work in the\nlowest mass galaxies where discrepancies are observed. Alternatively, the\nsmall-scale conflicts could be evidence of more complex physics in the dark\nsector itself. For example, elastic scattering from strong dark matter\nself-interactions can alter predicted halo mass profiles, leading to good\nagreement with observations across a wide range of galaxy mass. Gravitational\nlensing and dynamical perturbations of tidal streams in the stellar halo\nprovide evidence for an abundant population of low mass subhalos in accord with\nCDM predictions. These observational approaches will get more powerful over the\nnext few years. \n\n"}
{"id": "1306.2946", "contents": "Title: Non-linear Representations of the Conformal Group and Mapping of\n  Galileons Abstract: There are two common non-linear realizations of the 4D conformal group: in\nthe first, the dilaton is the conformal factor of the effective metric\n\\eta_{\\mu\\nu} e^{-2 \\pi}; in the second it describes the fluctuations of a\nbrane in AdS_5. The two are related by a complicated field redefinition, found\nby Bellucci, Ivanov and Krivonos (2002) to all orders in derivatives. We show\nthat this field redefinition can be understood geometrically as a change of\ncoordinates in AdS_5. In one gauge the brane is rigid at a fixed radial\ncoordinate with a conformal factor on the AdS_5 boundary, while in the other\none the brane bends in an unperturbed AdS_5. This geometrical picture\nilluminates some aspects of the mapping between the two representations. We\nshow that the conformal Galileons in the two representations are mapped into\neach other in a quite non-trivial way: the DBI action, for example, is mapped\ninto a complete linear combination of all the five Galileons in the other\nrepresentation. We also verify the equivalence of the dilaton S-matrix in the\ntwo representations and point out that the aperture of the dilaton light-cone\naround non-trivial backgrounds is not the same in the two representations. \n\n"}
{"id": "1306.3481", "contents": "Title: Visualizing Astronomical Data with Blender Abstract: Astronomical data take on a multitude of forms -- catalogs, data cubes,\nimages, and simulations. The availability of software for rendering\nhigh-quality three-dimensional graphics lends itself to the paradigm of\nexploring the incredible parameter space afforded by the astronomical sciences.\nThe software program Blender gives astronomers a useful tool for displaying\ndata in a manner used by three-dimensional (3D) graphics specialists and\nanimators. The interface to this popular software package is introduced with\nattention to features of interest in astronomy. An overview of the steps for\ngenerating models, textures, animations, camera work, and renders is outlined.\nAn introduction is presented on the methodology for producing animations and\ngraphics with a variety of astronomical data. Examples from sub-fields of\nastronomy with different kinds of data are shown with resources provided to\nmembers of the astronomical community. An example video showcasing the outlined\nprinciples and features is provided along with scripts and files for sample\nvisualizations. \n\n"}
{"id": "1306.4681", "contents": "Title: Novel Gamma-ray Spectral Features in the Inert Doublet Model Abstract: The inert doublet model contains a neutral stable particle which is an\nexcellent dark matter candidate. We discuss in this paper the indirect\nsignatures of this model in gamma-rays when the dark matter mass is larger than\nthe $W$ boson mass. We show that, in addition to the featureless gamma-ray\nspectrum produced in the annihilations into two weak gauge bosons, the model\ngenerically predicts a distinctive spectral feature from the internal\nbremsstrahlung process $H^0 H^0 \\rightarrow W^+ W^- \\gamma$. We discuss under\nwhich conditions the spectral feature is generated and we construct a number of\nbenchmark points, compatible with the observed relic density and all other\ndirect and indirect detection experiments, which lead to a sharp gamma-ray\nfeature from internal bremsstrahlung. \n\n"}
{"id": "1306.6885", "contents": "Title: Galactic electron and positron properties from cosmic ray and radio\n  observations Abstract: We perform a consistent modeling of cosmic ray electrons, positrons and of\nthe radio emission of the Galaxy. For the time we reproduce all relevant data\nsets between 1 GeV and 1 TeV including the recent AMS-02 positron fraction\nresults.\n  We show that below few GeV cosmic ray and radio data require that electron\nprimary spectrum to be drastically suppressed and the propagated spectrum be\ndominated by secondary particles. Above 10 GeV an electron + positron\nextra-component with a hard spectrum is required. The positron spectrum\nmeasured below few GeV is consistently reproduced only within low\nreacceleration models. We also constrain the scale-height of the cosmic-ray\ndistribution showing that a thin halo ($z_t \\lsim 2 \\kpc$) is excluded. \n\n"}
{"id": "1307.0397", "contents": "Title: Neutron Stars and the EOS Abstract: Implications of recently well-measured neutron star masses, particularly near\nand above 2 solar masses, for the equation of state (EOS) of neutron star\nmatter are highlighted. Model-independent upper limits to thermodynamic\nproperties in neutron stars, which only depend on the neutron star maximum\nmass, established from causality considerations are presented. The need for\nnon-perturbative treatments of quark matter in neutron stars is stressed\nthrough studies of self-bound quark matter stars, and of nucleon-quark hybrid\nstars. The extent to which several well-measured masses and radii of individual\nneutron stars can establish a model-independent EOS through an inversion of the\nstellar structure equations is briefly discussed. \n\n"}
{"id": "1307.4943", "contents": "Title: Comparison of Different Trigger and Readout Approaches for Cameras in\n  the Cherenkov Telescope Array Project Abstract: The Cherenkov Telescope Array (CTA) is a next-generation ground-based\nobservatory for g -rays with energies between some ten GeV and a few hundred\nTeV. CTA is currently in the advanced design phase and will consist of arrays\nwith different size of prime-focus Cherenkov telescopes, to ensure a proper\nenergy coverage from the threshold up to the highest energies. The extension of\nthe CTA array with double-mirror Schwarzschild- Couder telescopes is planned to\nimprove the array angular resolution over wider field of view.We present an\nend-to-end Monte-Carlo comparison of trigger concepts for the different imaging\ncameras that will be used on the Cherenkov telescopes. The comparison comprises\nthree alternative trigger schemes (analog, majority, flexible pattern analysis)\nfor each camera design. The study also addresses the influence of the\nproperties of the readout system (analog bandwidth of the electronics, length\nof the readout window in time) and uses an offline shower reconstruction to\ninvestigate the impact on key performances such as energy threshold and flux\nsensitivity \n\n"}
{"id": "1308.1404", "contents": "Title: Cosmic Bandits: Exploration versus Exploitation in CMB B-Mode\n  Experiments Abstract: A preferred method to detect the curl-component, or B-mode, signature of\ninflationary gravitational waves (IGWs) in the cosmic microwave background\n(CMB) polarization, in the absence of foregrounds and lensing, is a prolonged\nintegration over a single patch of sky of a few square degrees. In practice,\nhowever, foregrounds abound and the sensitivity to B modes can be improved\nconsiderably by finding the region of sky cleanest of foregrounds. The best\nstrategy to detect B modes thus involves a tradeoff between exploration (to\nfind lower-foreground patches) and exploitation (through prolonged\nintegration). This problem is akin to the multi-armed bandit (MAB) problem in\nprobability theory, wherein a gambler faces a series of slot machines with\nunknown winning odds and must develop a strategy to maximize his/her winnings\nwith some finite number of pulls. While the optimal MAB strategy remains to be\ndetermined, a number of algorithms have been developed in an effort to maximize\nthe winnings. Here, based on this resemblance, we tackle the search for IGW B\nmodes with single frequency experiments in the presence of spatially-varying\nforegrounds by developing adaptive survey strategies to optimize the\nsensitivity to IGW B modes. We demonstrate, using realistic foreground models\nand taking lensing-induced B modes into account, that adaptive experiments can\nsubstantially improve the upper bound on the tensor-to-scalar ratio (by factors\nof 2--3 in single frequency experiments, and possibly even more). Similar\ntechniques can be applied to other surveys, including 21-cm measurements of\nsignatures of the epoch of reionization, searches for a stochastic primordial\ngravitational wave background, deep-field imaging by the James Webb Space\nTelescope or various radio interferometers, and transient follow-up searches. \n\n"}
{"id": "1308.4408", "contents": "Title: Multi-messenger approaches to binary supermassive black holes in the\n  \"continuous-wave\" regime Abstract: Pulsar timing arrays are sensitive to gravitational waves from supermassive\nblack hole (SMBH) binaries at orbital separations of << 1pc. There is currently\nan observational paucity of such systems, although they are central figures in\nstudies of galaxy evolution, merger dynamics, and active nucleus formation. We\nreview the prospects of detecting SMBH binaries through electromagnetic\nradiative processes thought to be associated with galaxy mergers and late-stage\nbinary evolution. We then discuss the scientific goals of joint pulsar timing\nand electromagnetic studies of these systems, including the facilitation of\nbinary parameter estimation, identifying galactic hosts of gravitational wave\nemitters, and relevant studies of merger dynamics and cosmology. The use of\nupcoming high-precision timing arrays with the International Pulsar Timing\nArray and the Square Kilometre Array, combined with ongoing electromagnetic\nobserving campaigns to identify active SMBH binaries, provide generous\npossibilities for multi-messenger astrophysics in the near future. \n\n"}
{"id": "1309.1469", "contents": "Title: Probabilistic image reconstruction for radio interferometers Abstract: We present a novel, general-purpose method for deconvolving and denoising\nimages from gridded radio interferometric visibilities using Bayesian inference\nbased on a Gaussian process model. The method automatically takes into account\nincomplete coverage of the uv-plane, signal mode coupling due to the primary\nbeam, and noise mode coupling due to uv sampling. Our method uses Gibbs\nsampling to efficiently explore the full posterior distribution of the\nunderlying signal image given the data. We use a set of widely diverse mock\nimages with a realistic interferometer setup and level of noise to assess the\nmethod. Compared to results from a proxy for point source- based CLEAN method\nwe find that in terms of RMS error and signal-to-noise ratio our approach\nperforms better than traditional deconvolution techniques, regardless of the\nstructure of the source image in our test suite. Our implementation scales as\nO(np log np), provides full statistical and uncertainty information of the\nreconstructed image, requires no supervision, and provides a robust, consistent\nframework for incorporating noise and parameter marginalizations and foreground\nremoval. \n\n"}
{"id": "1309.2639", "contents": "Title: Mapping our Universe in 3D with MITEoR Abstract: Mapping our universe in 3D by imaging the redshifted 21 cm line from neutral\nhydrogen has the potential to overtake the cosmic microwave background as our\nmost powerful cosmological probe, because it can map a much larger volume of\nour Universe, shedding new light on the epoch of reionization, inflation, dark\nmatter, dark energy, and neutrino masses. We report on MITEoR, a pathfinder\nlow-frequency radio interferometer whose goal is to test technologies that\ngreatly reduce the cost of such 3D mapping for a given sensitivity. MITEoR\naccomplishes this by using massive baseline redundancy both to enable automated\nprecision calibration and to cut the correlator cost scaling from N^2 to NlogN,\nwhere N is the number of antennas. The success of MITEoR with its 64\ndual-polarization elements bodes well for the more ambitious HERA project,\nwhich would incorporate many identical or similar technologies using an order\nof magnitude more antennas, each with dramatically larger collecting area. \n\n"}
{"id": "1309.2932", "contents": "Title: Oscillatory inflation in non-minimal derivative coupling model Abstract: Inflation during rapid oscillation of a scalar field in non-minimal\nderivative coupling model is discussed. Cosmological perturbations originated\nin this stage are studied and consistency of the results with observational\nconstraints coming from Planck 2013 data are investigated. \n\n"}
{"id": "1309.3435", "contents": "Title: Conformal anomaly and primordial magnetic fields Abstract: The conformal symmetry of the quantized electromagnetic field breaks down in\ncurved space-time. We point out that this conformal anomaly is able to generate\na sizable magnetic field during a phase of slow-roll inflation. Such primordial\nmagnetism is characterized by the expectation value of the squared of the\nmagnetic field for comoving observers, which at leading order in slow-roll\ntakes the value $\\ < \\vec B^2\\ > =\\frac{8}{15(4\\pi)^2}\\, H^4\\epsilon$, where\n$\\epsilon$ is the standard slow-roll parameter. This result is insensitive to\nthe intrinsic ambiguities of renormalization in curved space-times. The\ninformation in the quantum state gets diluted during inflation and does not\naffect the prediction. A primordial field of this strength is able to seed the\nobserved cosmic magnetism. \n\n"}
{"id": "1309.3519", "contents": "Title: High-Angular-Resolution and High-Sensitivity Science Enabled by\n  Beamformed ALMA Abstract: An international consortium is presently constructing a beamformer for the\nAtacama Large Millimeter/submillimeter Array (ALMA) in Chile that will be\navailable as a facility instrument. The beamformer will aggregate the entire\ncollecting area of the array into a single, very large aperture. The\nextraordinary sensitivity of phased ALMA, combined with the extremely fine\nangular resolution available on baselines to the Northern Hemisphere, will\nenable transformational new very long baseline interferometry (VLBI)\nobservations in Bands 6 and 7 (1.3 and 0.8 mm) and provide substantial\nimprovements to existing VLBI arrays in Bands 1 and 3 (7 and 3 mm). The ALMA\nbeamformer will have impact on a variety of scientific topics, including\naccretion and outflow processes around black holes in active galactic nuclei\n(AGN), tests of general relativity near black holes, jet launch and collimation\nfrom AGN and microquasars, pulsar and magnetar emission processes, the chemical\nhistory of the universe and the evolution of fundamental constants across\ncosmic time, maser science, and astrometry. \n\n"}
{"id": "1309.4448", "contents": "Title: SATMC: Spectral Energy Distribution Analysis Through Markov Chains Abstract: We present the general purpose spectral energy distribution (SED) fitting\ntool SED Analysis Through Markov Chains (SATMC). Utilizing Monte Carlo Markov\nChain (MCMC) algorithms, SATMC fits an observed SED to SED templates or models\nof the user's choice to infer intrinsic parameters, generate confidence levels\nand produce the posterior parameter distribution. Here we describe the key\nfeatures of SATMC from the underlying MCMC engine to specific features for\nhandling SED fitting. We detail several test cases of SATMC, comparing results\nobtained to traditional least-squares methods, which highlight its accuracy,\nrobustness and wide range of possible applications. We also present a sample of\nsubmillimetre galaxies that have been fitted using the SED synthesis routine\nGRASIL as input. In general, these SMGs are shown to occupy a large volume of\nparameter space, particularly in regards to their star formation rates which\nrange from ~30-3000 M_sun yr^-1 and stellar masses which range from\n~10^10-10^12 M_sun. Taking advantage of the Bayesian formalism inherent to\nSATMC, we also show how the fitting results may change under different\nparametrizations (i.e., different initial mass functions) and through\nadditional or improved photometry, the latter being crucial to the study of\nhigh-redshift galaxies. \n\n"}
{"id": "1309.6294", "contents": "Title: Lunar laser ranging: the millimeter challenge Abstract: Lunar laser ranging has provided many of the best tests of gravitation since\nthe first Apollo astronauts landed on the Moon. The march to higher precision\ncontinues to this day, now entering the millimeter regime, and promising\ncontinued improvement in scientific results. This review introduces key aspects\nof the technique, details the motivations, observables, and results for a\nvariety of science objectives, summarizes the current state of the art,\nhighlights new developments in the field, describes the modeling challenges,\nand looks to the future of the enterprise. \n\n"}
{"id": "1309.6366", "contents": "Title: pcigale: porting Code Investigating Galaxy Emission to Python Abstract: We present pcigale, the port to Python of CIGALE (Code Investigating Galaxy\nEmission) a Fortran spectral energy distribution (SED) fitting code developed\nat the Laboratoire d'Astrophysique de Marseille. After recalling the specifics\nof the SED fitting method, we show the gains in modularity and versatility\noffered by Python, as well as the drawbacks compared to the compiled code. \n\n"}
{"id": "1309.7080", "contents": "Title: Neutrino production from photo-hadronic interactions of the gamma flux\n  from Active Galactic Nuclei with their gas content Abstract: The diffuse neutrino flux from FRI and BL Lac type galaxies generated from\ninteractions of their own gamma radiation with the gas and dust at the sources\nis reported. This neutrino-production channel has not been studied in detail up\nto now. The calculations are based on individual estimations of the neutrino\nflux in two nearby AGN's: Centaurus A and M87, assuming the validity of the AGN\nunification model. The predictions for Centaurus A and M87 involved the\nparameterization of the measured gamma-ray luminosities and the modeling of the\nmaterial of the galaxies both based on observations performed by several\ndetectors. No hadronic origin for the TeV photons is assumed. The results show\nthat, although the corresponding neutrino flux ($E^{2} \\Phi_{\\nu + \\bar{\\nu}} <\n10^{-13} s^{-1} sr^{-1} GeV cm^{-2}$) is not competitive at high-energies\n($E_\\nu > 1 TeV$) with that from hadronic models, FRI and BL Lac galaxies with\ngamma emission should be already contributing to the diffuse flux of neutrinos\nin the universe. \n\n"}
{"id": "1309.7473", "contents": "Title: A fast map-making preconditioner for regular scanning patterns Abstract: High-resolution Maximum Likelihood map-making of the Cosmic Microwave\nBackground is usually performed using Conjugate Gradients with a preconditioner\nthat ignores noise correlations. We here present a new preconditioner that\napproximates the map noise covariance as circulant, and show that this results\nin a speedup of up to 400% for a realistic scanning pattern from the Atacama\nCosmology Telescope. The improvement is especially large for polarized maps. \n\n"}
{"id": "1310.0468", "contents": "Title: Anisotropic dark matter distribution functions and impact on WIMP direct\n  detection Abstract: Dark matter N-body simulations suggest that the velocity distribution of dark\nmatter is anisotropic. In this work we employ a mass model for the Milky Way\nwhose parameters are determined from a fit to kinematical data. Then we adopt\nan ansatz for the dark matter phase space distribution which allows to\nconstruct self-consistent halo models which feature a degree of anisotropy as a\nfunction of the radius such as suggested by the simulations. The resulting\nvelocity distributions are then used for an analysis of current data from dark\nmatter direct detection experiments. We find that velocity distributions which\nare radially biased at large galactocentric distances (up to the virial radius)\nlead to an increased high velocity tail of the local dark matter distribution.\nThis affects the interpretation of data from direct detection experiments,\nespecially for dark matter masses around 10 GeV, since in this region the high\nvelocity tail is sampled. We find that the allowed regions in the dark matter\nmass-cross section plane as indicated by possible hints for a dark matter\nsignal reported by several experiments as well as conflicting exclusion limits\nfrom other experiments shift in a similar way when the halo model is varied.\nHence, it is not possible to improve the consistency of the data by referring\nto anisotropic halo models of the type considered in this work. \n\n"}
{"id": "1310.0615", "contents": "Title: Measuring galaxy [OII] emission line doublet with future ground-based\n  wide-field spectroscopic surveys Abstract: The next generation of wide-field spectroscopic redshift surveys will map the\nlarge-scale galaxy distribution in the redshift range 0.7< z<2 to measure\nbaryonic acoustic oscillations (BAO). The primary optical signature used in\nthis redshift range comes from the [OII] emission line doublet, which provides\na unique redshift identification that can minimize confusion with other single\nemission lines. To derive the required spectrograph resolution for these\nredshift surveys, we simulate observations of the [OII] (3727,3729) doublet for\nvarious instrument resolutions, and line velocities. We foresee two strategies\nabout the choice of the resolution for future spectrographs for BAO surveys.\nFor bright [OII] emitter surveys ([OII] flux ~30.10^{-17} erg /cm2/s like\nSDSS-IV/eBOSS), a resolution of R~3300 allows the separation of 90 percent of\nthe doublets. The impact of the sky lines on the completeness in redshift is\nless than 6 percent. For faint [OII] emitter surveys ([OII] flux ~10.10^{-17}\nerg /cm2/s like DESi), the detection improves continuously with resolution, so\nwe recommend the highest possible resolution, the limit being given by the\nnumber of pixels (4k by 4k) on the detector and the number of spectroscopic\nchannels (2 or 3). \n\n"}
{"id": "1310.1707", "contents": "Title: Prospects for detecting the 326.5 MHz redshifted 21 cm HI signal with\n  the Ooty Radio Telescope (ORT) Abstract: Observations of the redshifted 21 cm HI fluctuations promise to be an\nimportant probe of the post-reionization era. In this paper we calculate the\nexpected signal and foregrounds for the upgraded Ooty Radio Telescope (ORT)\nwhich operates at frequency =326.5 MHz which corresponds to redshift z=3.35.\nAssuming that the visibilities contain only the HI signal and system noise, we\nshow that a 3 sigma detection of the HI signal ~ 1 mk is possible at angular\nscales 11 arc-minutes to 3 degree with ~ 1000 hours of observation. Foreground\nremoval is one of the major challenges for a statistical detection of the\nredshifted 21 cm HI signal. We assess the contribution of different foregrounds\nand find that the 326.5 MHz sky is dominated by the extragalactic point sources\nat the angular scales of our interest. The expected total foregrounds are 4-5\norders of magnitude higher than the HI signal. \n\n"}
{"id": "1310.2606", "contents": "Title: Bayesian inference for pulsar timing models Abstract: The extremely regular, periodic radio emission from millisecond pulsars makes\nthem useful tools for studying neutron star astrophysics, general relativity,\nand low-frequency gravitational waves. These studies require that the observed\npulse times of arrival be fit to complex timing models that describe numerous\neffects such as the astrometry of the source, the evolution of the pulsar's\nspin, the presence of a binary companion, and the propagation of the pulses\nthrough the interstellar medium. In this paper, we discuss the benefits of\nusing Bayesian inference to obtain pulsar timing solutions. These benefits\ninclude the validation of linearized least-squares model fits when they are\ncorrect, and the proper characterization of parameter uncertainties when they\nare not; the incorporation of prior parameter information and of models of\ncorrelated noise; and the Bayesian comparison of alternative timing models. We\ndescribe our computational setup, which combines the timing models of Tempo2\nwith the nested-sampling integrator MultiNest. We compare the timing solutions\ngenerated using Bayesian inference and linearized least-squares for three\npulsars: B1953+29, J2317+1439, and J1640+2224, which demonstrate a variety of\nthe benefits that we posit. \n\n"}
{"id": "1310.2947", "contents": "Title: Herschel SPIRE and PACS observations of the red supergiant VY CMa:\n  analysis of the molecular line spectra Abstract: We present an analysis of the far-infrared and submillimetre molecular\nemission line spectrum of the luminous M-supergiant VY CMa, observed with the\nSPIRE and PACS spectrometers aboard the Herschel Space Observatory. Over 260\nemission lines were detected in the 190-650-micron SPIRE FTS spectra, with\none-third of the observed lines being attributable to H2O. Other detected\nspecies include CO, 13CO, H2^18O, SiO, HCN, SO, SO2, CS, H2S, and NH3. Our\nmodel fits to the observed 12CO and 13CO line intensities yield a 12C/13C ratio\nof 5.6+-1.8, consistent with measurements of this ratio for other M\nsupergiants, but significantly lower than previously estimated for VY CMa from\nobservations of lower-J lines. The spectral line energy distribution for twenty\nSiO rotational lines shows two temperature components: a hot component at 1000\nK, which we attribute to the stellar atmosphere and inner wind, plus a cooler\n~200 K component, which we attribute to an origin in the outer circumstellar\nenvelope. We fit the line fluxes of 12CO, 13CO, H2O and SiO, using the SMMOL\nnon-LTE line transfer code, with a mass-loss rate of 1.85x10^-4 Msun yr^-1\nbetween 9 R* and 350 R*. To fit the observed line fluxes of 12CO, 13CO, H2O and\nSiO with SMMOL non-LTE line radiative transfer code, along with a mass-loss\nrate of 1.85x10^-4 Msun yr^-1.\n  To fit the high rotational lines of CO and H2O, the model required a rather\nflat temperature distribution inside the dust condensation radius, attributed\nto the high H2O opacity. Beyond the dust condensation radius the gas\ntemperature is fitted best by an r^-0.5 radial dependence, consistent with the\ncoolant lines becoming optically thin. Our H2O emission line fits are\nconsistent with an ortho:para ratio of 3 in the outflow. \n\n"}
{"id": "1310.2992", "contents": "Title: The nature of pulses delayed by 5 mcs in scintillation detectors from\n  showers with the energy above 1E17 eV Abstract: Here we consider EAS events with energy above 1E17 eV with recorded pulses\ndelayed by t>=5 mcs in scintillation detectors with different thresholds: 10, 5\nand 1.8 MeV. In order to identify pulses from electrons, muons and neutrons,\nexperimental data were compared to computational results performed within the\nframework of QGSJET01d model. Preliminary, one may speculate of registration of\nlow-energy electrons arisen from moderation of neutrons in a detector or a\nmedium surrounding a detector or in the snow cover and frozen crust (albedo\nparticles). The fact that such pulses were registered mostly in low-threshold\ndetectors confirms this hypothesis. \n\n"}
{"id": "1310.3319", "contents": "Title: Scalar Field as a Bose-Einstein Condensate? Abstract: We discuss the analogy between a classical scalar field with a\nself-interacting potential, in a curved spacetime described by a quasi--bounded\nstate, and a trapped Bose-Einstein condensate. In this context, we compare the\nKlein-Gordon equation with the Gross-Pitaevskii equation. Moreover, the\nintroduction of a curved background spacetime endows, in a natural way, an\nequivalence to the Gross-Pitaevskii equation with an explicit confinement\npotential. The curvature also induces a position dependent self-interaction\nparameter. We exploit this analogy by means of the Thomas-Fermi approximation,\ncommonly used to describe the Bose-Einstein condensate, in order to analyze the\nquasi bound scalar field distribution surrounding a black hole. \n\n"}
{"id": "1310.3339", "contents": "Title: Weak Gravitational Lensing Systematics from Image Combination Abstract: Extremely accurate shape measurements of galaxy images are needed to probe\ndark energy properties with weak gravitational lensing surveys. To increase\nsurvey area with a fixed observing time and pixel count, images from surveys\nsuch as the Wide Field Infrared Survey Telescope (WFIRST) or Euclid will\nnecessarily be undersampled and therefore distorted by aliasing. Oversampled,\nunaliased images can be obtained by combining multiple, dithered exposures of\nthe same source with a suitable reconstruction algorithm. Any such\nreconstruction must minimally distort the reconstructed images for weak lensing\nanalyses to be unbiased. In this paper, we use the IMage COMbination (IMCOM)\nalgorithm of Rowe, Hirata, and Rhodes to investigate the effect of image\ncombination on shape measurements (size and ellipticity). We simulate dithered\nimages of sources with varying amounts of ellipticity and undersampling,\nreconstruct oversampled output images from them using IMCOM, and measure shape\ndistortions in the output. Our simulations show that IMCOM creates no\nsignificant distortions when the relative offsets between dithered images are\nprecisely known. Distortions increase with the uncertainty in those offsets but\nbecome problematic only with relatively poor astrometric precision. E.g. for\nimages similar to those from the Astrophysics Focused Telescope Asset (AFTA)\nimplementation of WFIRST, combining eight undersampled images (sampling ratio\nQ=1) with highly pessimistic uncertainty in astrometric registration\n(\\sigma_d~10^{-3} pixels) yields an RMS shear error of O(10^{-4}). Our analysis\npipeline is adapted from that of the Precision Projector Laboratory -- a joint\nproject between NASA Jet Propulsion Laboratory and Caltech which characterizes\nimage sensors using laboratory emulations of astronomical data. \n\n"}
{"id": "1310.4826", "contents": "Title: Search for CP Violating Signature of Intergalactic Magnetic Helicity in\n  the Gamma Ray Sky Abstract: The existence of a cosmological magnetic field could be revealed by the\neffects of non-trivial helicity on large scales. We evaluate a CP odd\nstatistic, $Q$, using gamma ray data obtained from Fermi satellite observations\nat high galactic latitudes to search for such a signature. Observed values of\n$Q$ are found to be non-zero; the probability of a similar signal in Monte\nCarlo simulations is $\\sim 0.2\\%$. Contamination from the Milky Way does not\nseem to be responsible for the signal since it is present even for data at very\nhigh galactic latitudes. Assuming that the signal is indeed due to a helical\ncosmological magnetic field, our results indicate left-handed magnetic helicity\nand field strength $\\sim 10^{-14}~{\\rm G}$ on $\\sim 10~{\\rm Mpc}$ scales. \n\n"}
{"id": "1310.4830", "contents": "Title: Strong Lens Time Delay Challenge: I. Experimental Design Abstract: The time delays between point-like images in gravitational lens systems can\nbe used to measure cosmological parameters. The number of lenses with measured\ntime delays is growing rapidly; the upcoming \\emph{Large Synoptic Survey\nTelescope} (LSST) will monitor $\\sim10^3$ strongly lensed quasars. In an effort\nto assess the present capabilities of the community to accurately measure the\ntime delays, and to provide input to dedicated monitoring campaigns and future\nLSST cosmology feasibility studies, we have invited the community to take part\nin a \"Time Delay Challenge\" (TDC). The challenge is organized as a set of\n\"ladders,\" each containing a group of simulated datasets to be analyzed blindly\nby participating teams. Each rung on a ladder consists of a set of realistic\nmock observed lensed quasar light curves, with the rungs' datasets increasing\nin complexity and realism. The initial challenge described here has two\nladders, TDC0 and TDC1. TDC0 has a small number of datasets, and is designed to\nbe used as a practice set by the participating teams. The (non-mandatory)\ndeadline for completion of TDC0 was the TDC1 launch date, December 1, 2013. The\nTDC1 deadline was July 1 2014. Here we give an overview of the challenge, we\nintroduce a set of metrics that will be used to quantify the goodness-of-fit,\nefficiency, precision, and accuracy of the algorithms, and we present the\nresults of TDC0. Thirteen teams participated in TDC0 using 47 different\nmethods. Seven of those teams qualified for TDC1, which is described in the\ncompanion paper II. \n\n"}
{"id": "1311.1530", "contents": "Title: Supermassive Black Holes and Their Host Galaxies - I. Bulge luminosities\n  from dedicated near-infrared data Abstract: In an effort to secure, refine and supplement the relation between central\nSupermassive Black Hole masses (Mbh), and the bulge luminosities of their host\ngalaxies, (Lbul), we obtained deep, high spatial resolution K-band images of 35\nnearby galaxies with securely measured Mbh, using the wide-field WIRCam imager\nat the Canada-France-Hawaii-Telescope (CFHT). A dedicated data reduction and\nsky subtraction strategy was adopted to estimate the brightness and structure\nof the sky, a critical step when tracing the light distribution of extended\nobjects in the near-infrared. From the final image product, bulge and total\nmagnitudes were extracted via two-dimensional profile fitting. As a first order\napproximation, all galaxies were modeled using a simple Sersic-bulge +\nexponential-disk decomposition. However, we found that such models did not\nadequately describe the structure that we observe in a large fraction of our\nsample galaxies which often include cores, bars, nuclei, inner disks, spiral\narms, rings and envelopes. In such cases, we adopted profile modifications\nand/or more complex models with additional components. The derived bulge\nmagnitudes are very sensitive to the details and number of components used in\nthe models, although total magnitudes remain almost unaffected. Usually, but\nnot always, the luminosities and sizes of the bulges are overestimated when a\nsimple bulge+disk decomposition is adopted in lieu of a more complex model.\nFurthermore we found that some spheroids are not well fit when the ellipticity\nof the Sersic model is held fixed. This paper presents the details of the image\nprocessing and analysis, while in a companion paper we discuss how\nmodel-induced biases and systematics in bulge magnitudes impact the Mbh-Lbul\nrelation. \n\n"}
{"id": "1311.1879", "contents": "Title: B-Machine Polarimeter: A Telescope to Measure the Polarization of the\n  Cosmic Microwave Background Abstract: The B-Machine Telescope is the culmination of several years of development,\nconstruction, characterization and observation. The telescope is a departure\nfrom standard polarization chopping of correlation receivers to a half wave\nplate technique. Typical polarimeters use a correlation receiver to chop the\npolarization signal to overcome the $1/f$ noise inherent in HEMT amplifiers.\nB-Machine uses a room temperature half wave plate technology to chop between\npolarization states and measure the polarization signature of the CMB. The\ntelescope has a demodulated $1/f$ knee of 5 mHz and an average sensitivity of\n1.6 $\\mathrm{mK}\\sqrt{\\mathrm{s}}$. This document examines the construction,\ncharacterization, observation of astronomical sources, and data set analysis of\nB-Machine. Preliminary power spectra and sky maps with large sky coverage for\nthe first year data set are included. \n\n"}
{"id": "1311.2553", "contents": "Title: Atomic data for S II - Toward Better Diagnostics of Chemical Evolution\n  in High-redshift Galaxies Abstract: Absorption-line spectroscopy is a powerful tool used to estimate element\nabundances in the nearby as well as distant universe. The accuracy of the\nabundances thus derived is, naturally, limited by the accuracy of the atomic\ndata assumed for the spectral lines. We have recently started a project to\nperform the new extensive atomic data calculations used for optical/UV spectral\nlines in the plasma modeling code Cloudy using state-of-the-art quantal\ncalculations. Here we demonstrate our approach by focussing on S II, an ion\nused to estimate metallicities for Milky Way interstellar clouds as well as\ndistant damped Lyman-alpha (DLA) and sub-DLA absorber galaxies detected in the\nspectra of quasars and gamma-ray bursts (GRBs). We report new extensive\ncalculations of a large number of energy levels of S II, and the line strengths\nof the resulting radiative transitions. Our calculations are based on the\nconfiguration interaction approach within a numerical Hartree-Fock framework,\nand utilize both non-ralativistic and quasirelativistic one-electron radial\norbitals. The results of these new atomic calculations are then incorporated\ninto Cloudy and applied to a lab plasma, and a typical DLA, for illustrative\npurposes. The new results imply relatively modest changes (~0.04 dex) to the\nmetallicities estimated from S II in past studies. These results will be\nreadily applicable to other studies of S II in the Milky Way and other\ngalaxies. \n\n"}
{"id": "1311.2800", "contents": "Title: Test of conformal gravity with astrophysical observations Abstract: Since it can describe the rotation curves of galaxies without dark matter and\ncan give rise to accelerated expansion, conformal gravity attracts much\nattention recently. As a theory of modified gravity, it is important to test\nconformal gravity with astrophysical observations. Here we constrain conformal\ngravity with SNIa and Hubble parameter data and investigate whether it suffers\nfrom an age problem with the age of APM~08279+5255. We find conformal gravity\ncan accommodate the age of APM~08279+5255 at 3 $\\sigma$ deviation, unlike most\nof dark energy models which suffer from an age problem. \n\n"}
{"id": "1312.0003", "contents": "Title: Alcock-Paczynski cosmological test Abstract: In order to test the expansion of the universe and its geometry, we carry out\nan Alcock & Paczynski cosmological test, that is, an evaluation of the ratio of\nobserved angular size to radial/redshift size. The main advantage of this test\nis that it does not depend on the evolution of the galaxies, but only on the\ngeometry of the universe. However, the redshift distortions produced by the\npeculiar velocities of the gravitational infall do also have an influence,\nwhich should be separated from the cosmological effect. We derive the\nanisotropic correlation function of sources in three surveys within the Sloan\nDigital Sky Survey (SDSS): galaxies from SDSS-III/Baryon Oscillation\nSpectroscopy Survey-Data Release 10 (BOSS-DR10), and QSOs from SDSS-II and\nSDSS-III/BOSS-DR10. From these, we are able to disentangle the dynamic and\ngeometric distortions and thus derive the ratio of observed angular size to\nradial/redshift size at different redshifts. We also add some other values\navailable in the literature. Then, we use the data to evaluate which\ncosmological model fits them. We used six different models: concordance\nLambda-CDM, Einstein-de Sitter, open-Friedman Cosmology without dark energy,\nflat quasi-steady state cosmology, a static universe with a linear Hubble law,\nand a static universe with tired-light redshift. Only two of the six models\nabove fit the data of the Alcock & Paczynski test: concordance Lambda-CDM and\nstatic universe with tired-light redshift; whereas the rest of them are\nexcluded at a >95% confidence level. If we assume that Lambda-CDM is the\ncorrect one, the best fit with a free Omega_m is produced for\nOmega_m=0.24^{+0.10}_{-0.07}. \n\n"}
{"id": "1312.0015", "contents": "Title: The stochastic nature of stellar population modelling Abstract: Since the early 1970s, stellar population modelling has been one of the basic\ntools for understanding the physics of unresolved systems from observation of\ntheir integrated light. Models allow us to relate the integrated spectra (or\ncolours) of a system with the evolutionary status of the stars of which it is\ncomposed and hence to infer how the system has evolved from its formation to\nits present stage. On average, observational data follow model predictions, but\nwith some scatter, so that systems with the same physical parameters (age,\nmetallicity, total mass) produce a variety of integrated spectra. The fewer the\nstars in a system, the larger is the scatter. Such scatter is sometimes much\nlarger than the observational errors, reflecting its physical nature. This\nsituation has led to the development in recent years (especially since 2010) of\nMonte Carlo models of stellar populations. Some authors have proposed that such\nmodels are more realistic than state-of-the-art standard synthesis codes that\nproduce the mean of the distribution of Monte Carlo models.\n  In this review, I show that these two modelling strategies are actually\nequivalent, and that they are not in opposition to each other. They are just\ndifferent ways of describing the probability distributions intrinsic in the\nvery modelling of stellar populations. I show the advantages and limitations of\neach strategy and how they complement each other. I also show the implications\nof the probabilistic description of stellar populations in the application of\nmodels to observational data obtained with high-resolution observational\nfacilities. Finally, I outline some possible developments that could be\nrealized in stellar population modelling in the near future.\n  Open your window and take a look at the night sky on a clear night..... \n\n"}
{"id": "1312.0919", "contents": "Title: Hierarchical Reverberation Mapping Abstract: Reverberation mapping (RM) is an important technique in studies of active\ngalactic nuclei (AGN). The key idea of RM is to measure the time lag $\\tau$\nbetween variations in the continuum emission from the accretion disc and\nsubsequent response of the broad line region (BLR). The measurement of $\\tau$\nis typically used to estimate the physical size of the BLR and is combined with\nother measurements to estimate the black hole mass $M_{\\rm BH}$. A major\ndifficulty with RM campaigns is the large amount of data needed to measure\n$\\tau$. Recently, Fine et al (2012) introduced a new approach to RM where the\nBLR light curve is sparsely sampled, but this is counteracted by observing a\nlarge sample of AGN, rather than a single system. The results are combined to\ninfer properties of the sample of AGN. In this letter we implement this method\nusing a hierarchical Bayesian model and contrast this with the results from the\nprevious stacked cross-correlation technique. We find that our inferences are\nmore precise and allow for more straightforward interpretation than the stacked\ncross-correlation results. \n\n"}
{"id": "1312.2670", "contents": "Title: Tracking quintessence: a dynamical systems study Abstract: With the tracking condition, the stability of quintessence solutions are\nexamined. It is found that there is only one physically relevant fixed point\nfor the system generically. Two specific examples of quintessence potentials\nare worked out in the frame work. \n\n"}
{"id": "1312.3249", "contents": "Title: Spectral stellar libraries and the Virtual Observatory Abstract: This paper describes the main characteristics of the Virtual Observatory as a\nresearch infrastructure in Astronomy, and identifies those fields in which it\ncan be of help for the community of spectral stellar libraries. \n\n"}
{"id": "1312.3502", "contents": "Title: Bianchi I Model: An Alternative Way To Model The Presentday Universe Abstract: Although the new era of high precision cosmology of the cosmic microwave\nbackground (CMB) radiation improves our knowledge to understand the infant as\nwell as the presentday Universe, it also leads us to question the main\nassumption of the exact isotropy of the CMB. There are two pieces of\nobservational evidence that hint towards there being no exact isotropy. These\nare first the existence of small anisotropy deviations from isotropy of the CMB\nradiation and second, the presence of large angle anomalies, although the\nexistence of these anomalies is currently a huge matter of debate. These hints\nare particularly important since isotropy is one of the two main postulates of\nthe Copernican principle on which the FRW models are built. This almost\nisotropic CMB radiation implies that the universe is almost a FRW universe, as\nis proved by previous studies.\n  Assuming the matter component forms the deviations from isotropy in the CMB\ndensity fluctuations when matter and radiation decouples, we here attempt to\nfind possible constraints on the FRW type scale and Hubble parameter by using\nthe Bianchi type I (BI) anisotropic model which is asymptotically equivalent to\nthe standard FRW. To obtain constraints on such an anisotropic model, we derive\naverage and late-time shear values that come from the anisotropy upper limits\nof the recent Planck data based on a model independent shear parameter of\nMaartens et al. (1995a,b) and from the theoretical consistency relation. These\nconstraints lead us to obtain a BI model which becomes an almost-FRW model in\ntime, and which is consistent with the latest observational data of the CMB. \n\n"}
{"id": "1312.3540", "contents": "Title: Integrable cosmological models with non-minimally coupled scalar fields Abstract: We obtain general solutions for some flat Friedmann universes filled with a\nscalar field in induced gravity models and models including the\nHilbert-Einstein curvature term plus a scalar field conformally coupled to\ngravity. As is well known, these models are connected to minimally coupled\nmodels through the combination of a conformal transformation and a\ntransformation of the scalar field. The explicit forms of the self-interaction\npotentials for six exactly solvable models are presented here. We obtain the\ngeneral solution for one of the integrable models, namely, the induced gravity\nmodel with a power-law potential for the self-interaction of the scalar field.\nWe argue that although being mathematically in a one-to-one correspondence with\nthe solutions in the minimally coupled models, the solutions in the\ncorresponding non-minimally coupled models are physically different. This is\nbecause the cosmological evolutions seen by an internal observer connected with\nthe cosmic time can be quite different. The study of a few induced gravity\nmodels with particular potentials gives us an explicit example of such a\ndifference. \n\n"}
{"id": "1312.3948", "contents": "Title: Compressed convolution Abstract: We introduce the concept of compressed convolution, a technique to convolve a\ngiven data set with a large number of non-orthogonal kernels. In typical\napplications our technique drastically reduces the effective number of\ncomputations. The new method is applicable to convolutions with symmetric and\nasymmetric kernels and can be easily controlled for an optimal trade-off\nbetween speed and accuracy. It is based on linear compression of the collection\nof kernels into a small number of coefficients in an optimal eigenbasis. The\nfinal result can then be decompressed in constant time for each desired\nconvolved output. The method is fully general and suitable for a wide variety\nof problems. We give explicit examples in the context of simulation challenges\nfor upcoming multi-kilo-detector cosmic microwave background (CMB) missions.\nFor a CMB experiment with O(10,000) detectors with similar beam properties, we\ndemonstrate that the algorithm can decrease the costs of beam convolution by\ntwo to three orders of magnitude with negligible loss of accuracy. Likewise, it\nhas the potential to allow the reduction of disk space required to store signal\nsimulations by a similar amount. Applications in other areas of astrophysics\nand beyond are optimal searches for a large number of templates in noisy data,\ne.g. from a parametrized family of gravitational wave templates; or calculating\nconvolutions with highly overcomplete wavelet dictionaries, e.g. in methods\ndesigned to uncover sparse signal representations. \n\n"}
{"id": "1312.4835", "contents": "Title: Particle dark matter searches in the anisotropic sky Abstract: Anisotropies in the electromagnetic emission produced by dark matter\nannihilation or decay in the extragalactic sky are a recent tool in the quest\nfor a particle dark matter evidence. We review the formalism to compute the\ntwo-point angular power spectrum in the halo-model approach and discuss the\nfeatures and the relative size of the various auto- and cross-correlation\nsignals that can be envisaged for anisotropy studies. From the side of particle\ndark matter signals, we consider the full multi-wavelength spectrum, from the\nradio emission to X-ray and gamma-ray productions. We discuss the angular power\nspectra of the auto-correlation of each of these signals and of the\ncross-correlation between any pair of them. We then extend the search to\ncomprise specific gravitational tracers of dark matter distribution in the\nUniverse: weak-lensing cosmic shear, large-scale-structure matter distribution\nand CMB-lensing. We have shown that cross-correlating a multi-wavelength dark\nmatter signal (which is a direct manifestation of its particle physics nature)\nwith a gravitational tracer (which is a manifestation of the presence of large\namounts of unseen matter in the Universe) may offer a promising tool to\ndemonstrate that what we call dark matter is indeed formed by elementary\nparticles. \n\n"}
{"id": "1312.4961", "contents": "Title: Cosmo++: An Object-Oriented C++ Library for Cosmology Abstract: This paper introduces a new publicly available numerical library for\ncosmology, Cosmo++. The library has been designed using object-oriented\nprogramming techniques, and fully implemented in C++. Cosmo++ introduces a\nunified interface for using most of the frequently used numerical methods in\ncosmology. Most of the features are implemented in Cosmo++ itself, while a part\nof the functionality is implemented by linking to other publicly available\nlibraries. The most important features of the library are Cosmic Microwave\nBackground anisotropies power spectrum and transfer function calculations,\nlikelihood calculations, parameter space sampling tools, sky map simulations,\nand mask apodization. Cosmo++ also includes a few mathematical tools that are\nfrequently used in numerical research in cosmology and beyond. A few simple\nexamples are included in Cosmo++ to help the user understand the key features.\nThe library has been fully tested, and we describe some of the important tests\nin this paper. Cosmo++ is publicly available at http://cosmo.grigoraslanyan.com \n\n"}
{"id": "1312.5753", "contents": "Title: SOMz: photometric redshift PDFs with self organizing maps and random\n  atlas Abstract: In this paper we explore the applicability of the unsupervised machine\nlearning technique of Self Organizing Maps (SOM) to estimate galaxy photometric\nredshift probability density functions (PDFs). This technique takes a\nspectroscopic training set, and maps the photometric attributes, but not the\nredshifts, to a two dimensional surface by using a process of competitive\nlearning where neurons compete to more closely resemble the training data\nmultidimensional space. The key feature of a SOM is that it retains the\ntopology of the input set, revealing correlations between the attributes that\nare not easily identified. We test three different 2D topological mapping:\nrectangular, hexagonal, and spherical, by using data from the DEEP2 survey. We\nalso explore different implementations and boundary conditions on the map and\nalso introduce the idea of a random atlas where a large number of different\nmaps are created and their individual predictions are aggregated to produce a\nmore robust photometric redshift PDF. We also introduced a new metric, the\n$I$-score, which efficiently incorporates different metrics, making it easier\nto compare different results (from different parameters or different\nphotometric redshift codes). We find that by using a spherical topology mapping\nwe obtain a better representation of the underlying multidimensional topology,\nwhich provides more accurate results that are comparable to other,\nstate-of-the-art machine learning algorithms. Our results illustrate that\nunsupervised approaches have great potential for many astronomical problems,\nand in particular for the computation of photometric redshifts. \n\n"}
{"id": "1312.6299", "contents": "Title: Characterizing faint galaxies in the reionization epoch: LBT confirms\n  two L<0.2L* sources at z=6.4 behind the CLASH/Frontier Fields cluster\n  MACS0717.5+3745 Abstract: We report the LBT/MODS1 spectroscopic confirmation of two images of faint\nLyman alpha emitters at $z=6.4$ behind the Frontier Fields galaxy cluster\nMACSJ0717.5+3745. A wide range of lens models suggests that the two images are\nhighly magnified, with a strong lower limit of mu>5. These are the faintest z>6\ncandidates spectroscopically confirmed to date. These may be also multiple\nimages of the same z=6.4 source as supported by their similar intrinsic\nproperties, but the lens models are inconclusive regarding this interpretation.\nTo be cautious, we derive the physical properties of each image individually.\nThanks to the high magnification, the observed near-infrared (restframe\nultraviolet) part of the spectral energy distributions and Ly-alpha lines are\nwell detected with S/N(m_1500)>~10 and S/N(Ly-alpha)~10-15. Adopting mu>5, the\nabsolute magnitudes, M_1500, and Ly-alpha fluxes, are fainter than -18.7 and\n2.8x10^(-18)erg/s/cm2, respectively. We find a very steep ultraviolet spectral\nslope beta=-3.0+/-0.5 (F_lambda=lambda^(beta)), implying that these are very\nyoung, dust-free and low metallicity objects, made of standard stellar\npopulations or even extremely metal poor stars (age<~30Myr, E(B-V)=0 and\nmetallicity 0.0-0.2 Z/Zsolar). The objects are compact (< 1 kpc^(2)), and with\na stellar mass M* < 10^(8) M_solar. The very steep beta, the presence of the\nLy-alpha line and the intrinsic FWHM (<300 km/s) of these newborn objects do\nnot exclude a possible leakage of ionizing radiation. We discuss the\npossibility that such faint galaxies may resemble those responsible for cosmic\nreionization. \n\n"}
{"id": "1312.7352", "contents": "Title: Ideas for Advancing Code Sharing (A Different Kind of Hack Day) Abstract: How do we as a community encourage the reuse of software for telescope\noperations, data processing, and calibration? How can we support making codes\nused in research available for others to examine? Continuing the discussion\nfrom last year Bring out your codes! BoF session, participants separated into\ngroups to brainstorm ideas to mitigate factors which inhibit code sharing and\nnurture those which encourage code sharing. The BoF concluded with the sharing\nof ideas that arose from the brainstorming sessions and a brief summary by the\nmoderator. \n\n"}
{"id": "1312.7877", "contents": "Title: Self-Calibration of BICEP1 Three-Year Data and Constraints on\n  Astrophysical Polarization Rotation Abstract: Cosmic Microwave Background (CMB) polarimeters aspire to measure the faint\n$B$-mode signature predicted to arise from inflationary gravitational waves.\nThey also have the potential to constrain cosmic birefringence which would\nproduce non-zero expectation values for the CMB's $TB$ and $EB$ spectra.\nHowever, instrumental systematic effects can also cause these $TB$ and $EB$\ncorrelations to be non-zero. In particular, an overall miscalibration of the\npolarization orientation of the detectors produces $TB$ and $EB$ spectra which\nare degenerate with isotropic cosmological birefringence, while also\nintroducing a small but predictable bias on the $BB$ spectrum. The \\bicep\nthree-year spectra, which use our standard calibration of detector polarization\nangles from a dielectric sheet, are consistent with a polarization rotation of\n$\\alpha = -2.77^\\circ \\pm 0.86^\\circ \\text{(statistical)} \\pm 1.3^\\circ\n\\text{(systematic)}$. We revise the estimate of systematic error on the\npolarization rotation angle from the two-year analysis by comparing multiple\ncalibration methods. We investigate the polarization rotation for the \\bicep\n100 GHz and 150 GHz bands separately to investigate theoretical models that\nproduce frequency-dependent cosmic birefringence. We find no evidence in the\ndata supporting either these models or Faraday rotation of the CMB polarization\nby the Milky Way galaxy's magnetic field. If we assume that there is no cosmic\nbirefringence, we can use the $TB$ and $EB$ spectra to calibrate detector\npolarization orientations, thus reducing bias of the cosmological $B$-mode\nspectrum from leaked $E$-modes due to possible polarization orientation\nmiscalibration. After applying this \"self-calibration\" process, we find that\nthe upper limit on the tensor-to-scalar ratio decreases slightly, from $r<0.70$\nto $r<0.65$ at $95\\%$ confidence. \n\n"}
{"id": "1401.0716", "contents": "Title: Radio Astronomy in LSST Era Abstract: A community meeting on the topic of \"Radio Astronomy in the LSST Era\" was\nhosted by the National Radio Astronomy Observatory in Charlottesville, VA (2013\nMay 6--8). The focus of the workshop was on time domain radio astronomy and sky\nsurveys. For the time domain, the extent to which radio and visible wavelength\nobservations are required to understand several classes of transients was\nstressed, but there are also classes of radio transients for which no visible\nwavelength counterpart is yet known, providing an opportunity for discovery.\nFrom the LSST perspective, the LSST is expected to generate as many as 1\nmillion alerts nightly, which will require even more selective specification\nand identification of the classes and characteristics of transients that can\nwarrant follow up, at radio or any wavelength. The LSST will also conduct a\ndeep survey of the sky, producing a catalog expected to contain over 38 billion\nobjects in it. Deep radio wavelength sky surveys will also be conducted on a\ncomparable time scale, and radio and visible wavelength observations are part\nof the multi-wavelength approach needed to classify and understand these\nobjects. Radio wavelengths are valuable because they are unaffected by dust\nobscuration and, for galaxies, contain contributions both from star formation\nand from active galactic nuclei. The workshop touched on several other topics,\non which there was consensus including the placement of other LSST \"Deep\nDrilling Fields,\" inter-operability of software tools, and the challenge of\nfiltering and exploiting the LSST data stream. There were also topics for which\nthere was insufficient time for full discussion or for which no consensus was\nreached, which included the procedures for following up on LSST observations\nand the nature for future support of researchers desiring to use LSST data\nproducts. \n\n"}
{"id": "1401.1548", "contents": "Title: Black holes and fundamental fields in Numerical Relativity: initial data\n  construction and evolution of bound states Abstract: Fundamental fields are a natural outcome in cosmology and particle physics\nand might therefore serve as a proxy for more complex interactions. The\nequivalence principle implies that all forms of matter gravitate, and one\ntherefore expects relevant, universal imprints of new physics in strong field\ngravity, such as that encountered close to black holes. Fundamental fields in\nthe vicinities of supermassive black holes give rise to extremely long-lived,\nor even unstable, configurations which slowly extract angular momentum from the\nblack hole or simply evolve non-linearly over long timescales, with important\nimplications for particle physics and gravitational-wave physics. Here, we\nperform a fully non-linear study of scalar-field condensates around rotating\nblack holes. We provide novel ways to specify initial data for the\nEinstein-Klein-Gordon system, with potential applications in a variety of\nscenarios. Our numerical results confirm the existence of long-lived bar-modes\nwhich act as lighthouses for gravitational wave emission: the scalar field\ncondenses outside the black hole geometry and acts as a constant frequency\ngravitational-wave source for very long timescales. This effect could turn out\nto be a potential signature of beyond standard model physics and also a\npromising source of gravitational waves for future gravitational wave\ndetectors. \n\n"}
{"id": "1401.6081", "contents": "Title: Planning the Future of U.S. Particle Physics (Snowmass 2013): Chapter 3:\n  Energy Frontier Abstract: These reports present the results of the 2013 Community Summer Study of the\nAPS Division of Particles and Fields (\"Snowmass 2013\") on the future program of\nparticle physics in the U.S. Chapter 3, on the Energy Frontier, discusses the\nprogram of research with high-energy colliders. This area includes experiments\non the Higgs boson, the electroweak and strong interactions, and the top quark.\nIt also encompasses direct searches for new particles and interactions at high\nenergy. \n\n"}
{"id": "1401.7433", "contents": "Title: The impact of JPEG2000 lossy compression on the scientific quality of\n  radio astronomy imagery Abstract: The sheer volume of data anticipated to be captured by future radio\ntelescopes, such as, The Square Kilometer Array (SKA) and its precursors\npresent new data challenges, including the cost and technical feasibility of\ndata transport and storage. Image and data compression are going to be\nimportant techniques to reduce the data size. We provide a quantitative\nanalysis of the effects of JPEG2000's lossy wavelet image compression algorithm\non the quality of the radio astronomy imagery data. This analysis is completed\nby evaluating the completeness, soundness and source parameterisation of the\nDuchamp source finder using compressed data. Here we found the JPEG2000 image\ncompression has the potential to denoise image cubes, however this effect is\nonly significant at high compression rates where the accuracy of source\nparameterisation is decreased. \n\n"}
{"id": "1401.7711", "contents": "Title: GERLUMPH Data Release 1: High-resolution cosmological microlensing\n  magnification maps and eResearch tools Abstract: As synoptic all-sky surveys begin to discover new multiply lensed quasars,\nthe flow of data will enable statistical cosmological microlensing studies of\nsufficient size to constrain quasar accretion disc and supermassive black hole\nproperties. In preparation for this new era, we are undertaking the\nGPU-Enabled, High Resolution cosmological MicroLensing parameter survey\n(GERLUMPH). We present here the GERLUMPH Data Release 1, which consists of\n12342 high resolution cosmological microlensing magnification maps and provides\nthe first uniform coverage of the convergence, shear and smooth matter fraction\nparameter space. We use these maps to perform a comprehensive numerical\ninvestigation of the mass-sheet degeneracy, finding excellent agreement with\nits predictions. We study the effect of smooth matter on microlensing induced\nmagnification fluctuations. In particular, in the minima and saddle-point\nregions, fluctuations are enhanced only along the critical line, while in the\nmaxima region they are always enhanced for high smooth matter fractions (~0.9).\nWe describe our approach to data management, including the use of an SQL\ndatabase with a Web interface for data access and online analysis, obviating\nthe need for individuals to download large volumes of data. In combination with\nexisting observational databases and online applications, the GERLUMPH archive\nrepresents a fundamental component of a new microlensing eResearch cloud. Our\nmaps and tools are publicly available at http://gerlumph.swin.edu.au/. \n\n"}
{"id": "1401.7768", "contents": "Title: Molecfit: A Package for Telluric Absorption Correction Abstract: Correcting for the sky signature usually requires supplementary calibration\ndata which are very expensive in terms of telescope time. In addition, the\nscheduling flexibility is restricted as these data have to be taken usually\ndirectly before/after the science observations due to the high variability of\nthe telluric absorption which depends on the state and the chemical composition\nof the atmosphere at the time of observations. Therefore, a tool for sky\ncorrection, which does not require this supplementary calibration data, saves a\nsignificant amount of valuable telescope time and increases its efficiency. We\ndeveloped a software package aimed at performing telluric feature corrections\non the basis of synthetic absorption spectra. \n\n"}
{"id": "1402.6159", "contents": "Title: Spectral analysis in orbital/superorbital phase space and hints of\n  superorbital variability in the hard X-rays of LS I +61 303 Abstract: We present INTEGRAL spectral analysis in the orbital/superorbital phase space\nof LS I +61 303. A hard X-ray spectrum with no cutoff is observed at all\norbital/superorbital phases. The hard X-ray index is found to be uncorrelated\nwith the radio index (non-simultaneously) measured at the same orbital and\nsuperorbital phases. In particular, the absence of an X-ray spectrum softening\nduring the periods of negative radio index does not favor a simple\ninterpretation of the radio index variations in terms of changes of state in a\nmicroquasar. We uncover hints for the superorbital variability in the hard\nX-ray flux, in phase with the superorbital modulation in soft X-rays. An\norbital phase drift of radio peak flux and index along the superorbital period\nis observed in the radio data. We explore its influence on a previously\nreported double peak structure of radio orbital lightcurve, posing it as a\nplausible explanation. \n\n"}
{"id": "1402.7180", "contents": "Title: Online classification for time-domain astronomy Abstract: The advent of synoptic sky surveys has spurred the development of techniques\nfor real-time classification of astronomical sources in order to ensure timely\nfollow-up with appropriate instruments. Previous work has focused on algorithm\nselection or improved light curve representations, and naively convert light\ncurves into structured feature sets without regard for the time span or phase\nof the light curves. In this paper, we highlight the violation of a fundamental\nmachine learning assumption that occurs when archival light curves with long\nobservational time spans are used to train classifiers that are applied to\nlight curves with fewer observations. We propose two solutions to deal with the\nmismatch in the time spans of training and test light curves. The first is the\nuse of classifier committees where each classifier is trained on light curves\nof different observational time spans. Only the committee member whose training\nset matches the test light curve time span is invoked for classification. The\nsecond solution uses hierarchical classifiers that are able to predict source\ntypes both individually and by sub-group, so that the user can trade-off an\nearlier, more robust classification with classification granularity. We test\nboth methods using light curves from the MACHO survey, and demonstrate their\nusefulness in improving performance over similar methods that naively train on\nall available archival data. \n\n"}
{"id": "1403.0293", "contents": "Title: First measurement of $\\sigma_8$ using supernova magnitudes only Abstract: A method was recently proposed which allows the conversion of the\nweak-lensing effects in the supernova Hubble diagram from noise into signal.\nSuch signal is sensitive to the growth of structure in the universe, and in\nparticular can be used as a measurement of $\\sigma_8$ which is independent from\nmore traditional methods such as those based on the CMB, cosmic shear or\ncluster abundance. We extend here that analysis to allow for intrinsic\nnon-Gaussianities in the supernova PDF, and discuss how this can be best\nmodelled using the Bayes Factor. Although it was shown that a precise\nmeasurement of $\\sigma_8$ requires ~$10^5$ supernovae, current data already\nallows an important proof of principle. In particular we make use of the 732\nsupernovae with z < 1 of the recent JLA catalog and show that a simple\ntreatment of intrinsic non-Gaussianities with a couple of nuisance parameters\nis enough for our method to yield the values $\\sigma_8 = 0.84^{+0.28}_{-0.65}$\nor $\\sigma_8 < 1.45$ at a $2\\sigma$ confidence level. This result is consistent\nwith mock simulations and it is also in agreement with independent measurements\nand presents the first ever measurement of $\\sigma_8$ using supernova\nmagnitudes alone. \n\n"}
{"id": "1403.1063", "contents": "Title: A PCA-based automated finder for galaxy-scale strong lenses Abstract: We present an algorithm using Principal Component Analysis (PCA) to subtract\ngalaxies from imaging data, and also two algorithms to find strong,\ngalaxy-scale gravitational lenses in the resulting residual image. The combined\nmethod is optimized to find full or partial Einstein rings. Starting from a\npre-selection of potential massive galaxies, we first perform a PCA to build a\nset of basis vectors. The galaxy images are reconstructed using the PCA basis\nand subtracted from the data. We then filter the residual image with two\ndifferent methods. The first uses a curvelet (curved wavelets) filter of the\nresidual images to enhance any curved/ring feature. The resulting image is\ntransformed in polar coordinates, centered on the lens galaxy center. In these\ncoordinates, a ring is turned into a line, allowing us to detect very faint\nrings by taking advantage of the integrated signal-to-noise in the ring (a line\nin polar coordinates). The second way of analysing the PCA-subtracted images\nidentifies structures in the residual images and assesses whether they are\nlensed images according to their orientation, multiplicity and elongation. We\napply the two methods to a sample of simulated Einstein rings, as they would be\nobserved with the ESA Euclid satellite in the VIS band. The polar coordinates\ntransform allows us to reach a completeness of 90% and a purity of 86%, as soon\nas the signal-to-noise integrated in the ring is higher than 30, and almost\nindependent of the size of the Einstein ring. Finally, we show with real data\nthat our PCA-based galaxy subtraction scheme performs better than traditional\nsubtraction based on model fitting to the data. Our algorithm can be developed\nand improved further using machine learning and dictionary learning methods,\nwhich would extend the capabilities of the method to more complex and diverse\ngalaxy shapes. \n\n"}
{"id": "1403.1271", "contents": "Title: SCoPE: An efficient method of Cosmological Parameter Estimation Abstract: Markov Chain Monte Carlo (MCMC) sampler is widely used for cosmological\nparameter estimation from CMB and other data. However, due to the intrinsic\nserial nature of the MCMC sampler, convergence is often very slow. Here we\npresent a fast and independently written Monte Carlo method for cosmological\nparameter estimation named as Slick Cosmological Parameter Estimator (SCoPE),\nthat employs delayed rejection to increase the acceptance rate of a chain, and\npre-fetching that helps an individual chain to run on parallel CPUs. An\ninter-chain covariance update is also incorporated to prevent clustering of the\nchains allowing faster and better mixing of the chains. We use an adaptive\nmethod for covariance calculation to calculate and update the covariance\nautomatically as the chains progress. Our analysis shows that the acceptance\nprobability of each step in SCoPE is more than $95\\%$ and the convergence of\nthe chains are faster. Using SCoPE, we carry out some cosmological parameter\nestimations with different cosmological models using WMAP-9 and Planck results.\nOne of the current research interests in cosmology is quantifying the nature of\ndark energy. We analyze the cosmological parameters from two illustrative\ncommonly used parameterisations of dark energy models. We also asses primordial\nhelium fraction in the universe can be constrained by the present CMB data from\nWMAP-9 and Planck. The results from our MCMC analysis on the one hand helps us\nto understand the workability of the SCoPE better, on the other hand it\nprovides a completely independent estimation of cosmological parameters from\nWMAP-9 and Planck data. \n\n"}
{"id": "1403.2491", "contents": "Title: NuSTAR J033202-2746.8: direct constraints on the Compton reflection in a\n  heavily obscured quasar at z~2 Abstract: We report NuSTAR observations of NuSTAR J033202-2746.8, a heavily obscured,\nradio-loud quasar detected in the Extended Chandra Deep Field-South, the\ndeepest layer of the NuSTAR extragalactic survey (~400 ks, at its deepest).\nNuSTAR J033202-2746.8 is reliably detected by NuSTAR only at E>8 keV and has a\nvery flat spectral slope in the NuSTAR energy band (Gamma=0.55^{+0.62}_{-0.64};\n3-30 keV). Combining the NuSTAR data with extremely deep observations by\nChandra and XMM-Newton (4 Ms and 3 Ms, respectively), we constrain the\nbroad-band X-ray spectrum of NuSTAR J033202-2746.8, indicating that this source\nis a heavily obscured quasar (N_H=5.6^{+0.9}_{-0.8}x10^23 cm^-2) with\nluminosity L_{10-40 keV}~6.4x10^44 erg s^-1. Although existing optical and\nnear-infrared (near-IR) data, as well as follow-up spectroscopy with the Keck\nand VLT telescopes, failed to provide a secure redshift identification for\nNuSTAR J033202-2746.8, we reliably constrain the redshift z=2.00+/-0.04 from\nthe X-ray spectral features (primarily from the iron K edge). The NuSTAR\nspectrum shows a significant reflection component (R=0.55^{+0.44}_{-0.37}),\nwhich was not constrained by previous analyses of Chandra and XMM-Newton data\nalone. The measured reflection fraction is higher than the R~0 typically\nobserved in bright radio-loud quasars such as NuSTAR J033202-2746.8, which has\nL_{1.4 GHz}~10^27 W Hz^-1. Constraining the spectral shape of AGN, including\nbright quasars, is very important for understanding the AGN population, and can\nhave a strong impact on the modeling of the X-ray background. Our results show\nthe importance of NuSTAR in investigating the broad-band spectral properties of\nquasars out to high redshift. \n\n"}
{"id": "1403.6656", "contents": "Title: The Unified Astronomy Thesaurus Abstract: The Unified Astronomy Thesaurus (UAT) is an open, interoperable and\ncommunity-supported thesaurus which unifies the existing divergent and isolated\nAstronomy & Astrophysics vocabularies into a single high-quality,\nfreely-available open thesaurus formalizing astronomical concepts and their\ninter-relationships. The UAT builds upon the existing IAU Thesaurus with major\ncontributions from the astronomy portions of the thesauri developed by the\nInstitute of Physics Publishing, the American Institute of Physics, and SPIE.\nWe describe the effort behind the creation of the UAT and the process through\nwhich we plan to maintain the document updated through broad community\nparticipation. \n\n"}
{"id": "1403.6820", "contents": "Title: Study on atmospheric optical turbulence above Mt. Shatdzhatmaz in\n  2007--2013 Abstract: We present the results of the atmospheric optical turbulence (OT)\nmeasurements performed atop Mt. Shatdzhatmaz at the installation site of new\n2.5-m telescope of Sternberg Astronomical Institute. Nearly 300 000 vertical OT\nprofiles from the ground up to an altitude of 23 km were obtained in the period\nNovember 2007 - June 2013 with the combined multi-aperture scintillation sensor\n(MASS) and differential image motion monitor (DIMM) instrument.\n  The medians of the main OT characteristics computed over the whole dataset\nare as follows: the integral seeing $\\beta_0 = 0.96$ arcsec, the\nfree-atmosphere seeing $\\beta_{free} = 0.43$ arcsec, and the isoplanatic angle\n$\\theta_0 = 2.07$ arcsec. The median atmospheric time constant is $\\tau_0 =\n6.57 \\mbox{ ms}$. The revealed long-term variability of these parameters on\nscales of months and years implies the need to take it into account in\nastroclimatic campaign planning. For example, the annual variation in the\nmonthly $\\theta_0$ estimate amounts up to 30% while the time constant $\\tau_0$\nchanges by a factor of 2.5.\n  Evaluation of the potential of Mt. Shatdzhatmaz in terms of high angular\nresolution observations indicates that in October--November, this site is as\ngood as the best of studied summits in the world. \n\n"}
{"id": "1403.7147", "contents": "Title: Distinguishing black-hole spin-orbit resonances by their\n  gravitational-wave signatures Abstract: If binary black holes form following the successive core collapses of\nsufficiently massive binary stars, precessional dynamics may align their spins\n$\\mathbf S_1$ and $\\mathbf S_2$ and the orbital angular momentum $\\mathbf L$\ninto a plane in which they jointly precess about the total angular momentum\n$\\mathbf J$. These spin orientations are known as spin-orbit resonances since\n$\\mathbf S_1$, $\\mathbf S_2$, and $\\mathbf L$ all precess at the same frequency\nto maintain their planar configuration. Two families of such spin-orbit\nresonances exist, alike in dignity but differentiated by whether the components\nof the two spins in the orbital plane are either aligned or antialigned. The\nfraction of binary black holes in each family is determined by the stellar\nevolution of their progenitors, so if gravitational-wave detectors could\nmeasure this fraction they could provide important insights into astrophysical\nformation scenarios for binary black holes. In this paper, we show that even\nunder the conservative assumption that binary black holes are observed along\nthe direction of $\\mathbf J$ (where precession-induced modulations to the\ngravitational waveforms are minimized), the waveforms of many members of each\nresonant family can be distinguished from all members of the opposing family in\nevents with signal-to-noise ratios $\\rho \\simeq 10$, typical of those expected\nfor the first detections with Advanced LIGO/Virgo. We hope that our preliminary\nfindings inspire a greater appreciation of the capability of gravitational-wave\ndetectors to constrain stellar astrophysics and stimulate further studies of\nthe distinguishability of spin-orbit resonant families in more expanded regions\nof binary black-hole parameter space. \n\n"}
{"id": "1404.0360", "contents": "Title: Whipped inflation Abstract: Motivated by the idea that inflation occurs at the GUT symmetry breaking\nscale, in this paper we construct a new class of large field inflaton\npotentials where the inflaton starts with a power law potential; after initial\nperiod of relative fast roll that lasts until after a few e-folds inside the\nhorizon, it transits to the attractor of the slow roll part of the potential\nwith a lower power. Due to the initial fast roll stages of inflation, we find a\nsuppression in scalar primordial power at large scales and at the same time the\nchoice of the potential can provide us a tensor primordial spectrum with high\namplitude. This suppression in scalar power with a large tensor-to-scalar ratio\nhelps us to reconcile the Planck and BICEP2 data in a single framework. We find\nthat a transition from a cubic to quadratic form of inflaton potential\ngenerates an appropriate suppression in power of scalar primordial spectrum\nthat provides significant improvement in fit compared to power law model when\ncompared with Planck and BICEP2 data together. We calculate the extent of\nnon-Gaussianity, specifically, the bispectrum for the best fit potential and\nshow that it is consistent with Planck bispectrum constraints. \n\n"}
{"id": "1404.0532", "contents": "Title: Higgs Dark Energy Abstract: We study the classical dynamics of a non-abelian Higgs theory coupled to\ngravity in an isotropic and homogeneous Universe. For non-minimal coupling,\nthis theory leads to a model of cosmic inflation that is very attractive due to\nits simplicity and consistency with the latest experimental data. We show that\nthis theory can also explain the current accelerated expansion of the Universe,\nprovided that all the gravitational and bosonic degrees of freedom, together\nwith their symmetries, are correctly taken in account. \n\n"}
{"id": "1404.2068", "contents": "Title: Lateral density and arrival time distributions of Cherenkov photons in\n  extensive air showers: a simulation study Abstract: We have investigated some features of the density and arrival time\ndistributions of Cherenkov photons in extensive air showers using the CORSIKA\nsimulation package. The main thrust of this study is to see the effect of\nhadronic interaction models on the production pattern of Cherenkov photons with\nrespect to distance from the shower core. Such studies are very important in\nground based $\\gamma$-ray astronomy for an effective rejection of huge cosmic\nray background, where the atmospheric Cherenkov technique is being used\nextensively within the energy range of some hundred GeV to few TeV. We have\nfound that for all primary particles, the density distribution patterns of\nCherenkov photons follow the negative exponential function with different\ncoefficients and slopes depending on the type of primary particle, its energy\nand the type of interaction model combinations. Whereas the arrival time\ndistribution patterns of Cherenkov photons follow the function of the form $t\n(r) = t_{0}e^{\\Gamma/r^{\\lambda}}$, with different values of the function\nparameters. There is no significant effect of hadronic interaction model\ncombinations on the density and arrival time distributions for the $\\gamma$-ray\nprimaries. However, for the hadronic showers, the effects of the model\ncombinations are significant under different conditions. \n\n"}
{"id": "1404.2920", "contents": "Title: $H_0$ from ten well-measured time delay lenses Abstract: In this work, we present a homogeneous curve-shifting analysis using the\ndifference-smoothing technique of the publicly available light curves of 24\ngravitationally lensed quasars, for which time delays have been reported in the\nliterature. The uncertainty of each measured time delay was estimated using\nrealistic simulated light curves. The recipe for generating such simulated\nlight curves with known time delays in a plausible range around the measured\ntime delay is introduced here. We identified 14 gravitationally lensed quasars\nthat have light curves of sufficiently good quality to enable the measurement\nof at least one time delay between the images, adjacent to each other in terms\nof arrival-time order, to a precision of better than 20% (including systematic\nerrors). We modeled the mass distribution of ten of those systems that have\nknown lens redshifts, accurate astrometric data, and sufficiently simple mass\ndistribution, using the publicly available PixeLens code to infer a value of\n$H_0$ of 68.1 $\\pm$ 5.9 km s$^{-1}$ Mpc$^{-1}$ (1$\\sigma$ uncertainty, 8.7%\nprecision) for a spatially flat universe having $\\Omega_m$ = 0.3 and\n$\\Omega_\\Lambda$ = 0.7. We note here that the lens modeling approach followed\nin this work is a relatively simple one and does not account for subtle\nsystematics such as those resulting from line-of-sight effects and hence our\n$H_0$ estimate should be considered as indicative. \n\n"}
{"id": "1404.3612", "contents": "Title: K-Inflation in Noncommutative Space-Time Abstract: The power spectra of the scalar and tensor perturbations in the\nnoncommutative k-inflation model are calculated in this paper. In this model,\nall the modes created when the stringy space-time uncertainty relation is\nsatisfied are generated inside the sound/Hubble horizon during inflation for\nthe scalar/tensor perturbations. It turns out that a linear term describing the\nnoncommutative space-time effect contributes to the power spectra of the scalar\nand tensor perturbations. Confronting the general noncommutative k-inflation\nmodel with latest results from \\textit{Planck} and BICEP2, and taking $c_S$ and\n$\\lambda$ as free parameters, we find that it is well consistent with\nobservations. However, for the two specific models, i.e. the tachyon and DBI\ninflation models, it is found that the DBI model is not favored, while the\ntachyon model lies inside the $1\\sigma$ contour, if the e-folds number is\nassumed to be around $50\\sim60$. \n\n"}
{"id": "1404.3799", "contents": "Title: The 6dF Galaxy Velocity Survey: Cosmological constraints from the\n  velocity power spectrum Abstract: We present scale-dependent measurements of the normalised growth rate of\nstructure $f\\sigma_{8}(k, z=0)$ using only the peculiar motions of galaxies. We\nuse data from the 6-degree Field Galaxy Survey velocity sample (6dFGSv)\ntogether with a newly-compiled sample of low-redshift $(z < 0.07)$ type Ia\nsupernovae. We constrain the growth rate in a series of $\\Delta k \\sim 0.03\nh{\\rm Mpc^{-1}}$ bins to $\\sim35\\%$ precision, including a measurement on\nscales $>300 h^{-1}{\\rm Mpc}$, which represents one of the largest-scale growth\nrate measurement to date. We find no evidence for a scale dependence in the\ngrowth rate, or any statistically significant variation from the growth rate as\npredicted by the {\\it Planck} cosmology. Bringing all the scales together, we\ndetermine the normalised growth rate at $z=0$ to $\\sim15\\%$ in a manner {\\it\nindependent} of galaxy bias and in excellent agreement with the constraint from\nthe measurements of redshift-space distortions from 6dFGS. We pay particular\nattention to systematic errors. We point out that the intrinsic scatter present\nin Fundamental-Plane and Tully-Fisher relations is only Gaussian in logarithmic\ndistance units; wrongly assuming it is Gaussian in linear (velocity) units can\nbias cosmological constraints. We also analytically marginalise over zero-point\nerrors in distance indicators, validate the accuracy of all our constraints\nusing numerical simulations, and demonstrate how to combine different\n(correlated) velocity surveys using a matrix `hyper-parameter' analysis.\nCurrent and forthcoming peculiar velocity surveys will allow us to understand\nin detail the growth of structure in the low-redshift universe, providing\nstrong constraints on the nature of dark energy. \n\n"}
{"id": "1404.4632", "contents": "Title: Line Emitting Galaxies Beyond a Redshift of 7: An Improved Method for\n  Estimating the Evolving Neutrality of the Intergalactic Medium Abstract: The redshift-dependent fraction of color-selected galaxies revealing Lyman\nalpha emission has become the most valuable constraint on the evolving\nneutrality of the early intergalactic medium. However, in addition to resonant\nscattering by neutral gas, the visibility of Lyman alpha is also dependent on\nthe intrinsic properties of the host galaxy, including its stellar population,\ndust content and the nature of outflowing gas. Taking advantage of significant\nprogress we have made in determining the line emitting properties of $z \\simeq\n4-6$ galaxies, we propose an improved method, based on using the measured\nslopes of the rest-frame ultraviolet continua of galaxies, to interpret the\ngrowing body of near-infrared spectra of $z>7$ galaxies in order to take into\naccount these host galaxy dependencies. In a first application of our new\nmethod, we demonstrate its potential via a new spectroscopic survey of $7<z<8$\ngalaxies undertaken with the Keck MOSFIRE spectrograph. Together with earlier\npublished data our data provides improved estimates of the evolving visibility\nof Lyman alpha, particularly at redshift $z\\simeq 8$. As a byproduct, we also\npresent a new line emitting galaxy at a redshift $z=7.62$ which supersedes an\nearlier redshift record. We discuss the improving constraints on the evolving\nneutral fraction over $6<z<8$ and the implications for cosmic reionization. \n\n"}
{"id": "1404.5795", "contents": "Title: Mitigation of the spectral dependent polarization angle response for\n  achromatic half-wave plate Abstract: Polarimetry using a half-wave plate (HWP) modulator provides the strong tools\nto avoid a detector 1/f noise and instrument-originated spurious polarization\nsystematic effects. While the Pancharatnam achromatic HWP (AHWP) is commonly\nused for an application that needs a broadband frequency coverage, this\ntechnique introduces a frequency-dependent polarization angle rotation. In this\npaper we propose a new technique to mitigate this effect by introducing a\nsecond set of an AHWP. One rotational and one stationary set of AHWPs achieve a\nbroadband coverage of modulation efficiency without the frequency-dependent\npolarization angle rotation. We conducted measurements by using three layers of\nsapphire wave plates and demonstrated this technique at millimeter wavelengths\nbetween 72 and 162 GHz. We also discuss a potential application in the CMB\npolarization experiment based on numerical simulations. \n\n"}
{"id": "1405.0011", "contents": "Title: Frontier Fields: High-Redshift Predictions and Early Results Abstract: The Frontier Fields program is obtaining deep Hubble and Spitzer Space\nTelescope images of new \"blank\" fields and nearby fields gravitationally lensed\nby massive galaxy clusters. The Hubble images of the lensed fields are\nrevealing nJy sources (AB mag > 31), the faintest galaxies yet observed. In\nthis paper, we present high-redshift (z > 6) number count predictions for the\nfull program and candidates in three of the first Hubble Frontier Fields\nimages. The full program will transform our understanding of galaxy evolution\nin the first 600 million years (z > 9). Where previous programs yielded perhaps\na dozen z > 9 candidates, the Frontier Fields may yield ~70 (~6 per field). We\nbase this estimate on an extrapolation of luminosity functions observed between\n4 < z < 8 and gravitational lensing models submitted by the community. However,\nin the first two deep infrared Hubble images obtained to date, we find z ~ 8\ncandidates but no strong candidates at z > 9. This might suggest a deficit of\nfaint z > 9 galaxies as also reported in the Ultra Deep Field (even while\nexcesses of brighter z > 9 galaxies were reported in shallower fields). At\nthese redshifts, cosmic variance (field-to-field variation) is expected to be\nsignificant (greater than +/-50%) and include clustering of early galaxies\nformed in overdensities. The full Frontier Fields program will significantly\nmitigate this uncertainty by observing six independent sightlines each with a\nlensing cluster and nearby blank field. \n\n"}
{"id": "1405.2296", "contents": "Title: Coincidence problem within dark energy as a coupled self-interacting\n  Bose-Einstein gas Abstract: A late accelerated expansion of the Universe is obtained from\nnon-relativistic particles with a short-range attractive interaction, and low\nenough temperature to produce a Bose-Einstein condensate; by considering\ncoupled dark-energy particles, energy is interchanged with dark matter,\nallowing it to describe recent acceleration by strengthening its effect. We\nshow that for a sizable range of parameters, dark energy and dark matter evolve\nwith similar energy densities, solving the coincidence problem, and in\nagreement with the luminosity distance vs redshift, derived from supernova\ndata. \n\n"}
{"id": "1405.3464", "contents": "Title: The Swift X-ray Telescope Cluster Survey II. X-ray spectral analysis Abstract: (Abridged) We present a spectral analysis of a new, flux-limited sample of 72\nX-ray selected clusters of galaxies identified with the X-ray Telescope (XRT)\non board the Swift satellite down to a flux limit of ~10-14 erg/s/cm2 (SWXCS,\nTundo et al. 2012). We carry out a detailed X-ray spectral analysis with the\ntwofold aim of measuring redshifts and characterizing the properties of the\nIntra-Cluster Medium (ICM). Optical counterparts and spectroscopic or\nphotometric redshifts are obtained with a cross-correlation with NED.\nAdditional photometric redshifts are computed with a dedicated follow-up\nprogram with the TNG and a cross-correlation with the SDSS. We also detect the\niron emission lines in 35% of the sample, and hence obtain a robust measure of\nthe X-ray redshift zX. We use zX whenever the optical redshift is not\navailable. Finally, for all the sources with measured redshift,\nbackground-subtracted spectra are fitted with a mekal model. We perform\nextensive spectral simulations to derive an empirical formula to account for\nfitting bias. The bias-corrected values are then used to investigate the\nscaling properties of the X-ray observables. Overall, we are able to\ncharacterize the ICM of 46 sources. The sample is mostly constituted by\nclusters with temperatures between 3 and 10 keV, plus 14 low-mass clusters and\ngroups with temperatures below 3 keV. The redshift distribution peaks around\nz~0.25 and extends up to z~1, with 60% of the sample at 0.1<z<0.4. We derive\nthe Luminosity-Temperature relation for these 46 sources, finding good\nagreement with previous studies. The quality of the SWXCS sample is comparable\nto other samples available in the literature and obtained with much larger\nX-ray telescopes. Our results have interesting implications for the design of\nfuture X-ray survey telescopes, characterised by good-quality PSF over the\nentire field of view and low background. \n\n"}
{"id": "1405.3590", "contents": "Title: EFTCAMB/EFTCosmoMC: Numerical Notes v3.0 Abstract: EFTCAMB/EFTCosmoMC are publicly available patches to the CAMB/CosmoMC codes\nimplementing the effective field theory approach to single scalar field dark\nenergy and modified gravity models. With the present numerical notes we provide\na guide to the technical details of the code. Moreover we reproduce, as they\nappear in the code, the complete set of the modified equations and the\nexpressions for all the other relevant quantities used to construct these\npatches. We submit these notes to the arXiv to grant full and permanent access\nto this material which provides very useful guidance to the numerical\nimplementation of the EFT framework. We will update this set of notes when\nrelevant modifications to the EFTCAMB/EFTCosmoMC codes will be released. The\npresent version is based on the version of EFTCAMB/EFTCosmoMC Sep17. \n\n"}
{"id": "1405.5482", "contents": "Title: Sparse point-source removal for full-sky CMB experiments: application to\n  WMAP 9-year data Abstract: Missions such as WMAP or Planck measure full-sky fluctuations of the cosmic\nmicrowave background and foregrounds, among which bright compact source\nemissions cover a significant fraction of the sky. To accurately estimate the\ndiffuse components, the point-source emissions need to be separated from the\ndata, which requires a dedicated processing. We propose a new technique to\nestimate the flux of the brightest point sources using a morphological\nseparation approach: point sources with known support and shape are separated\nfrom diffuse emissions that are assumed to be sparse in the spherical harmonic\ndomain. This approach is compared on both WMAP simulations and data with the\nstandard local chi2 minimization, modelling the background as a low-order\npolynomial. The proposed approach generally leads to 1) lower biases in flux\nrecovery, 2) an improved root mean-square error of up to 35% and 3) more\nrobustness to background fluctuations at the scale of the source. The WMAP\n9-year point-source-subtracted maps are available online. \n\n"}
{"id": "1405.5634", "contents": "Title: Application of Lossless Data Compression Techniques to Radio Astronomy\n  Data flows Abstract: The modern practice of Radio Astronomy is characterized by extremes of data\nvolume and rates, principally because of the direct relationship between the\nsignal to noise ratio that can be achieved and the need to Nyquist sample the\nRF bandwidth necessary by way of support. The transport of these data flows is\ncostly. By examining the statistical nature of typical data flows and applying\nwell known techniques from the field of Information Theory the following work\nshows that lossless compression of typical radio astronomy data flows is in\ntheory possible. The key parameter in determining the degree of compression\npossible is the standard deviation of the data. The practical application of\ncompression could prove beneficial in reducing the costs of data transport and\n(arguably) storage for new generation instruments such as the Square Kilometer\nArray. \n\n"}
{"id": "1405.5881", "contents": "Title: The Snapshot Hubble U-Band Cluster Survey (SHUCS) II. Star Cluster\n  Population of NGC 2997 Abstract: We study the star cluster population of NGC 2997, a giant spiral galaxy\nlocated at 9.5 Mpc and targeted by the Snapshot Hubble U-band Cluster Survey\n(SHUCS). Combining our U-band imaging from SHUCS with archival BVI imaging from\nHST, we select a high confidence sample of clusters in the circumnuclear ring\nand disk through a combination of automatic detection procedures and visual\ninspection. The cluster luminosity functions in all four filters can be\napproximated by power-laws with indices of $-1.7$ to $-2.3$. Some deviations\nfrom pure power-law shape are observed, hinting at the presence of a high-mass\ntruncation in the cluster mass function. However, upon inspection of the\ncluster mass function, we find it is consistent with a pure power-law of index\n$-2.2\\pm0.2$ despite a slight bend at $\\sim$$2.5\\times10^{4}$ M$_{\\odot}$. No\nstatistically significant truncation is observed. From the cluster age\ndistributions, we find a low rate of disruption ($\\zeta\\sim-0.1$) in both the\ndisk and circumnuclear ring. Finally, we estimate the cluster formation\nefficiency ($\\Gamma$) over the last 100 Myr in each region, finding $7\\pm2$%\nfor the disk, $12\\pm4$% for the circumnuclear ring, and $10\\pm3$% for the\nentire UBVI footprint. This study highlights the need for wide-field UBVI\ncoverage of galaxies to study cluster populations in detail, though a small\nsample of clusters can provide significant insight into the characteristics of\nthe population. \n\n"}
{"id": "1405.6967", "contents": "Title: 7 keV Sterile neutrino dark matter in $U(1)_R-$ lepton number model Abstract: We study the phenomenology of a keV sterile neutrino in a supersymmetric\nmodel with $U(1)_R-$ lepton number in the light of a very recent observation of\nan X-ray line signal at around 3.5 keV, detected in the X-ray spectra of\nAndromeda galaxy and various galaxy clusters including the Perseus galaxy\ncluster. This model not only provides a small tree level mass to one of the\nactive neutrinos but also renders a suitable warm dark matter candidate in the\nform of a sterile neutrino with negligible active-sterile mixing. Light\nneutrino masses and mixing can be explained once one-loop radiative corrections\nare taken into account. The scalar sector of this model can accommodate a Higgs\nboson with a mass of $\\sim$ 125 GeV. In this model gravitino is the lightest\nsupersymmetric particle (LSP) and we also study the cosmological implications\nof this light gravitino with mass $\\sim \\mathcal O$(GeV). \n\n"}
{"id": "1405.7029", "contents": "Title: The CIB-lensing bispectrum: impact on primordial non-Gaussianity and\n  detectability for the Planck mission Abstract: We characterize the Cosmic Infrared Background (CIB)-lensing bispectrum which\nis one of the contributions to the three-point functions of Cosmic Microwave\nBackground (CMB) maps in harmonic space. We show that the CIB-lensing\nbispectrum has a considerable strength and that it can be detected with high\nsignificance in the Planck high-frequency maps. We also present forecasts of\nthe contamination on different shapes of the primordial non-Gaussianity\n$f_{nl}$ parameter produced by the CIB-lensing bispectrum and by the\nextragalactic point sources bispectrum in the Planck high-resolution CMB\nanisotropy maps. The local, equilateral and orthogonal shapes are considered\nfor 'raw' single-frequency (i.e., without applying any component separation\ntechnique) and foreground-reduced Planck temperature maps. The CIB-lensing\ncorrelation seems to mainly affect orthogonal shapes of the bispectrum - with\n{\\Delta}$f_{nl}$ = -21 and -88 for the 143 and 217 GHz bands respectively -\nwhile point sources mostly impact equilateral shapes, with {\\Delta}$f_{nl}$ =\n160, 54 and 60 at 100, 143 and 217 GHz. However, the results indicate that\nthese contaminants do not induce any relevant bias on Planck $f_{nl}$ estimates\nwhen foreground-reduced maps are considered: using SEVEM for the component\nseparation we obtain {\\Delta}$f_{nl}$ = 10.5 due to the CIB-lensing and\n{\\Delta}$f_{nl}$ = 30.4 due to point sources, corresponding to 0.30{\\sigma} and\n0.45{\\sigma} in terms of the Planck 2013 $f_{nl}$ uncertainty. The component\nseparation technique is, in fact, able to partially clean the extragalactic\nsource contamination and the bias is reduced for all the shapes. We have\nfurther developed single- and multiple-frequency estimators based on the\nKomatsu, Spergel & Wandelt (2005) formalism that can be implemented to\nefficiently detect this signal. \n\n"}
{"id": "1405.7697", "contents": "Title: Milky Way mass constraints from the Galactic satellite gap Abstract: We use the distribution of maximum circular velocities, $V_{max}$, of\nsatellites in the Milky Way (MW) to constrain the virial mass, $M_{200}$, of\nthe Galactic halo under an assumed prior of a $\\Lambda$CDM universe. This is\ndone by analysing the subhalo populations of a large sample of halos found in\nthe Millennium II cosmological simulation. The observation that the MW has at\nmost three subhalos with $V_{max}\\ge30 km/s$ requires a halo mass\n$M_{200}\\le1.4\\times10^{12} M_\\odot$, while the existence of the Magellanic\nClouds (assumed to have $V_{max}\\ge60 km/s$) requires\n$M_{200}\\ge1.0\\times10^{12} M_\\odot$. The first of these conditions is\nnecessary to avoid the \"too-big-to-fail\" problem highlighted by Boylan-Kolchin\net al., while the second stems from the observation that massive satellites\nlike the Magellanic Clouds are rare. When combining both requirements, we find\nthat the MW halo mass must lie in the range $0.25 \\le M_{200}/(10^{12} M_\\odot)\n\\le 1.4$ at $90\\%$ confidence. The gap in the abundance of Galactic satellites\nbetween $30 km/s\\le V_{max} \\le 60 km/s$ places our galaxy in the tail of the\nexpected satellite distribution. \n\n"}
{"id": "1406.0559", "contents": "Title: Adventures in the microlensing cloud: large datasets, eResearch tools,\n  and GPUs Abstract: As astronomy enters the petascale data era, astronomers are faced with new\nchallenges relating to storage, access and management of data. A shift from the\ntraditional approach of combining data and analysis at the desktop to the use\nof remote services, pushing the computation to the data, is now underway. In\nthe field of cosmological gravitational microlensing, future synoptic all--sky\nsurveys are expected to bring the number of multiply imaged quasars from the\nfew tens that are currently known to a few thousands. This inflow of\nobservational data, together with computationally demanding theoretical\nmodelling via the production of microlensing magnification maps, requires a new\napproach. We present our technical solutions to supporting the GPU-Enabled,\nHigh Resolution cosmological MicroLensing parameter survey (GERLUMPH). This\nextensive dataset for cosmological microlensing modelling comprises over 70,000\nindividual magnification maps and ${\\sim}10^6$ related results. We describe our\napproaches to hosting, organizing, and serving ${\\sim}$30 Terabytes of data and\nmetadata products. We present a set of online analysis tools developed with\nPHP, JavaScript and WebGL to support access and analysis of GELRUMPH data in a\nWeb browser. We discuss our use of graphics processing units (GPUs) to\naccelerate data production, and we release the core of the GPU-D direct inverse\nray--shooting code (Thompson et al., 2010; Astrophysics Source Code Library,\nrecord ascl:1403.001) used to generate the magnification maps. All of the\nGERLUMPH data and tools are available online from http://gerlumph.swin.edu.au .\nThis project made use of gSTAR, the GPU Supercomputer for Theoretical\nAstrophysical Research. \n\n"}
{"id": "1406.0559", "contents": "Title: Adventures in the microlensing cloud: large datasets, eResearch tools,\n  and GPUs Abstract: As astronomy enters the petascale data era, astronomers are faced with new\nchallenges relating to storage, access and management of data. A shift from the\ntraditional approach of combining data and analysis at the desktop to the use\nof remote services, pushing the computation to the data, is now underway. In\nthe field of cosmological gravitational microlensing, future synoptic all--sky\nsurveys are expected to bring the number of multiply imaged quasars from the\nfew tens that are currently known to a few thousands. This inflow of\nobservational data, together with computationally demanding theoretical\nmodelling via the production of microlensing magnification maps, requires a new\napproach. We present our technical solutions to supporting the GPU-Enabled,\nHigh Resolution cosmological MicroLensing parameter survey (GERLUMPH). This\nextensive dataset for cosmological microlensing modelling comprises over 70,000\nindividual magnification maps and ${\\sim}10^6$ related results. We describe our\napproaches to hosting, organizing, and serving ${\\sim}$30 Terabytes of data and\nmetadata products. We present a set of online analysis tools developed with\nPHP, JavaScript and WebGL to support access and analysis of GELRUMPH data in a\nWeb browser. We discuss our use of graphics processing units (GPUs) to\naccelerate data production, and we release the core of the GPU-D direct inverse\nray--shooting code (Thompson et al., 2010; Astrophysics Source Code Library,\nrecord ascl:1403.001) used to generate the magnification maps. All of the\nGERLUMPH data and tools are available online from http://gerlumph.swin.edu.au .\nThis project made use of gSTAR, the GPU Supercomputer for Theoretical\nAstrophysical Research. \n\n"}
{"id": "1406.1225", "contents": "Title: Ergo-spheres, ergo-tori and ergo-Saturns for Kerr black holes with\n  scalar hair Abstract: We have recently reported (arXiv:1403.2757) the existence of Kerr black holes\nwith scalar hair in General Relativity minimally coupled to a massive, complex\nscalar field. These solutions interpolate between boson stars and Kerr black\nholes. The latter have a well known topologically S^2 ergo-surface\n(ergo-sphere) whereas the former develop a S^1*S^1 ergo-surface (ergo-torus) in\na region of parameter space. We show that hairy black holes always have an\nergo-region, and that this region is delimited by either an ergo-sphere or an\nergo-Saturn -- i.e. a S^2\\oplus (S^1*S^1) ergo-surface. In the phase space of\nsolutions, the ergo-torus can either appear disconnected from the ergo-sphere\nor pinch off from it. We provide a heuristic argument, based on a measure of\nthe size of the ergo-region, that superradiant instabilities - which are likely\nto be present - are weaker for hairy black holes than for Kerr black holes with\nthe same global charges. We observe that Saturn-like, and even more remarkable\nergo-surfaces, should also arise for other rotating `hairy' black holes. \n\n"}
{"id": "1406.1759", "contents": "Title: Relic Neutrino Freeze-out: Dependence on Natural Constants Abstract: Analysis of cosmic microwave background radiation fluctuations favors an\neffective number of neutrinos, $N_\\nu>3$. This motivates a reinvestigation of\nthe neutrino freeze-out process. Here we characterize the dependence of $N_\\nu$\non the Standard Model (SM) parameters that govern neutrino freeze-out. We show\nthat $N_\\nu$ depends on a combination $\\eta$ of several natural constants\ncharacterizing the relative strength of weak interaction processes in the early\nUniverse and on the Weinberg angle $\\sin^2\\theta_W$. We determine numerically\nthe dependence $N_\\nu(\\eta,\\sin^2\\theta_W)$ and discuss these results. The\nextensive numerical computations are made possible by two novel numerical\nprocedures: a spectral method Boltzmann equation solver adapted to allow\nemerging chemical non-equilibrium, and a method to evaluate Boltzmann equation\ncollision integrals that generates a smooth integrand. \n\n"}
{"id": "1406.4407", "contents": "Title: Photometric redshift analysis in the Dark Energy Survey Science\n  Verification data Abstract: We present results from a study of the photometric redshift performance of\nthe Dark Energy Survey (DES), using the early data from a Science Verification\n(SV) period of observations in late 2012 and early 2013 that provided\nscience-quality images for almost 200 sq.~deg.~at the nominal depth of the\nsurvey. We assess the photometric redshift performance using about 15000\ngalaxies with spectroscopic redshifts available from other surveys. These\ngalaxies are used, in different configurations, as a calibration sample, and\nphoto-$z$'s are obtained and studied using most of the existing photo-$z$\ncodes. A weighting method in a multi-dimensional color-magnitude space is\napplied to the spectroscopic sample in order to evaluate the photo-$z$\nperformance with sets that mimic the full DES photometric sample, which is on\naverage significantly deeper than the calibration sample due to the limited\ndepth of spectroscopic surveys. Empirical photo-$z$ methods using, for\ninstance, Artificial Neural Networks or Random Forests, yield the best\nperformance in the tests, achieving core photo-$z$ resolutions $\\sigma_{68}\n\\sim 0.08$. Moreover, the results from most of the codes, including template\nfitting methods, comfortably meet the DES requirements on photo-$z$\nperformance, therefore, providing an excellent precedent for future DES data\nsets. \n\n"}
{"id": "1406.5420", "contents": "Title: Cosmological Applications of the Gaussian Kinematic Formula Abstract: The Gaussian Kinematic Formula (GKF, see Adler and Taylor (2007,2011)) is an\nextremely powerful tool allowing for explicit analytic predictions of expected\nvalues of Minkowski functionals under realistic experimental conditions for\ncosmological data collections. In this paper, we implement Minkowski\nfunctionals on multipoles and needlet components of CMB fields, thus allowing a\nbetter control of cosmic variance and extraction of information on both\nharmonic and real domains; we then exploit the GKF to provide their expected\nvalues on spherical maps, in the presence of arbitrary sky masks, and under\nnonGaussian circumstances. All our results are validated by numerical\nexperiments, which show a perfect agreement between theoretical predictions and\nMonte Carlo simulations. \n\n"}
{"id": "1406.6691", "contents": "Title: VADER: A Flexible, Robust, Open-Source Code for Simulating Viscous Thin\n  Accretion Disks Abstract: The evolution of thin axisymmetric viscous accretion disks is a classic\nproblem in astrophysics. While models based on this simplified geometry provide\nonly approximations to the true processes of instability-driven mass and\nangular momentum transport, their simplicity makes them invaluable tools for\nboth semi-analytic modeling and simulations of long-term evolution where two-\nor three-dimensional calculations are too computationally costly. Despite the\nutility of these models, the only publicly-available frameworks for simulating\nthem are rather specialized and non-general. Here we describe a highly\nflexible, general numerical method for simulating viscous thin disks with\narbitrary rotation curves, viscosities, boundary conditions, grid spacings,\nequations of state, and rates of gain or loss of mass (e.g., through winds) and\nenergy (e.g., through radiation). Our method is based on a conservative,\nfinite-volume, second-order accurate discretization of the equations, which we\nsolve using an unconditionally-stable implicit scheme. We implement Anderson\nacceleration to speed convergence of the scheme, and show that this leads to\nfactor of $\\sim 5$ speed gains over non-accelerated methods in realistic\nproblems, though the amount of speedup is highly problem-dependent. We have\nimplemented our method in the new code Viscous Accretion Disk Evolution\nResource (VADER), which is freely available for download from\nhttps://bitbucket.org/krumholz/vader/ under the terms of the GNU General Public\nLicense. \n\n"}
{"id": "1406.6948", "contents": "Title: GeV excess in the Milky Way: The Role of Diffuse Galactic gamma ray\n  Emission template Abstract: Several groups have analyzed the publicly-available Fermi-LAT data and\nreported a spatially extended $\\gamma-$ray excess of around $1-3$ GeV from the\nregion surrounding the Galactic Center that might originate from annihilation\nof dark matter particles with a rest mass $m_\\chi \\sim 30-40$ GeV. In this work\nwe examine the role of the diffuse Galactic gamma ray emission (DGE) templates\nplayed in suppressing the GeV excess. For such a purpose, we adopt in total 128\nbackground templates that have been generated by Ackermann et al.\n\\cite{FermiLAT:2012aa} in the study of the {Fermi-LAT} observations of the\ndiffuse gamma ray emission considering the effects of cosmic rays and the\ninterstellar medium. The possible GeV excess, assumed to follow the spatial\ndistribution of the prompt gamma-rays produced in the annihilation of dark\nmatter particles taking a generalized NFW profile with an inner slope\n$\\alpha=1.2$, has been analyzed in some regions of interest. The introduction\nof such an additional component centered at the Galactic center is found to\nhave improved the goodness of fit to the data significantly in all background\ntemplate models regardless of whether the excess spectrum is fixed or not. Our\nresults thus suggest that the presence of a statistically significant GeV\nexcess in the inner Galaxy is robust thought its spectrum depends on the DGE\nmodel adopted in the analysis. The possible physical origin of the GeV excess\ncomponent is discussed and in the dark matter model the annihilation cross\nsection of such particles is evaluated. \n\n"}
{"id": "1406.7242", "contents": "Title: LOFAR Sparse Image Reconstruction Abstract: Context. The LOw Frequency ARray (LOFAR) radio telescope is a giant digital\nphased array interferometer with multiple antennas distributed in Europe. It\nprovides discrete sets of Fourier components of the sky brightness. Recovering\nthe original brightness distribution with aperture synthesis forms an inverse\nproblem that can be solved by various deconvolution and minimization methods\nAims. Recent papers have established a clear link between the discrete nature\nof radio interferometry measurement and the \"compressed sensing\" (CS) theory,\nwhich supports sparse reconstruction methods to form an image from the measured\nvisibilities. Empowered by proximal theory, CS offers a sound framework for\nefficient global minimization and sparse data representation using fast\nalgorithms. Combined with instrumental direction-dependent effects (DDE) in the\nscope of a real instrument, we developed and validated a new method based on\nthis framework Methods. We implemented a sparse reconstruction method in the\nstandard LOFAR imaging tool and compared the photometric and resolution\nperformance of this new imager with that of CLEAN-based methods (CLEAN and\nMS-CLEAN) with simulated and real LOFAR data Results. We show that i) sparse\nreconstruction performs as well as CLEAN in recovering the flux of point\nsources; ii) performs much better on extended objects (the root mean square\nerror is reduced by a factor of up to 10); and iii) provides a solution with an\neffective angular resolution 2-3 times better than the CLEAN images.\nConclusions. Sparse recovery gives a correct photometry on high dynamic and\nwide-field images and improved realistic structures of extended sources (of\nsimulated and real LOFAR datasets). This sparse reconstruction method is\ncompatible with modern interferometric imagers that handle DDE corrections (A-\nand W-projections) required for current and future instruments such as LOFAR\nand SKA \n\n"}
{"id": "1407.0021", "contents": "Title: Cosmological solutions to the Lithium problem: Big-bang nucleosynthesis\n  with photon cooling, $X$-particle decay and a primordial magnetic field Abstract: The $^7$Li abundance calculated in BBN with the baryon-to-photon ratio fixed\nfrom fits to the CMB power spectrum is inconsistent with the observed lithium\nabundances on the surface of metal-poor halo stars. Previous cosmological\nsolutions proposed to resolve this $^7$Li problem include photon cooling\n(possibly via the Bose-Einstein condensation of a scalar particle) or the decay\nof a long-lived $X-$particle (possibly the next-to-lightest supersymmetric\nparticle). In this paper we reanalyze these solutions, both separately and in\nconcert. We also introduce the possibility of a primordial magnetic field (PMF)\ninto these models. We constrain the $X-$particles and the PMF parameters by the\nobserved light element abundances using a likelihood analysis to show that the\ninclusion of all three possibilities leads to an optimum solution to the\nlithium problem. We deduce allowed ranges for the $X-$particle parameters and\nenergy density in the PMF that can solve $^7$Li problem. \n\n"}
{"id": "1407.0794", "contents": "Title: Cosmology in generalized Horndeski theories with second-order equations\n  of motion Abstract: We study the cosmology of an extended version of Horndeski theories with\nsecond-order equations of motion on the flat\nFriedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) background. In addition to a\ndark energy field $\\chi$ associated with the gravitational sector, we take into\naccount multiple scalar fields $\\phi_I$ ($I=1,2\\cdots,N-1$) characterized by\nthe Lagrangians $P^{(I)}(X_I)$ with\n$X_I=\\partial_{\\mu}\\phi_I\\partial^{\\mu}\\phi_I$. These additional scalar fields\ncan model the perfect fluids of radiation and non-relativistic matter. We\nderive propagation speeds of scalar and tensor perturbations as well as\nconditions for the absence of ghosts. The theories beyond Horndeski induce\nnon-trivial modifications to all the propagation speeds of $N$ scalar fields,\nbut the modifications to those for the matter fields $\\phi_I$ are generally\nsuppressed relative to that for the dark energy field $\\chi$. We apply our\nresults to the covariantized Galileon with an Einstein-Hilbert term in which\npartial derivatives of the Minkowski Galileon are replaced by covariant\nderivatives. Unlike the covariant Galileon with second-order equations of\nmotion in general space-time, the scalar propagation speed square $c_{s1}^2$\nassociated with the field $\\chi$ becomes negative during the matter era for\nlate-time tracking solutions, so the two Galileon theories can be clearly\ndistinguished at the level of linear cosmological perturbations. \n\n"}
{"id": "1407.1042", "contents": "Title: Multimessenger Search for Sources of Gravitational Waves and High-Energy\n  Neutrinos: Results for Initial LIGO-Virgo and IceCube Abstract: We report the results of a multimessenger search for coincident signals from\nthe LIGO and Virgo gravitational-wave observatories and the partially completed\nIceCube high-energy neutrino detector, including periods of joint operation\nbetween 2007-2010. These include parts of the 2005-2007 run and the 2009-2010\nrun for LIGO-Virgo, and IceCube's observation periods with 22, 59 and 79\nstrings. We find no significant coincident events, and use the search results\nto derive upper limits on the rate of joint sources for a range of source\nemission parameters. For the optimistic assumption of gravitational-wave\nemission energy of $10^{-2}$\\,M$_\\odot$c$^2$ at $\\sim 150$\\,Hz with $\\sim\n60$\\,ms duration, and high-energy neutrino emission of $10^{51}$\\,erg\ncomparable to the isotropic gamma-ray energy of gamma-ray bursts, we limit the\nsource rate below $1.6 \\times 10^{-2}$\\,Mpc$^{-3}$yr$^{-1}$. We also examine\nhow combining information from gravitational waves and neutrinos will aid\ndiscovery in the advanced gravitational-wave detector era. \n\n"}
{"id": "1407.1318", "contents": "Title: Black hole-like hysteresis and accretion states in neutron star low mass\n  X-ray binaries Abstract: We have systematically studied a large sample of the neutron star low mass\nX-ray binaries (LMXBs) monitored by the Rossi X-ray Timing Explorer (50\nsources; 10000+ observations). We find that the hysteresis patterns between\nCompton dominated and thermal dominated states, typically observed in black\nhole LMXBs, are also common in neutron star systems. These patterns, which also\nsample intermediate states, are found when looking at the evolution of both\nX-ray colour and fast variability of ten systems accreting below ~ 30 % of the\nEddington Luminosity. We show that hysteresis does not require large changes in\nluminosity and it is the natural form that state transitions take at these\nluminosities. At higher accretion rates neutron stars do not show hysteresis,\nand they remain in a thermal dominated, low variability state, characterized by\nflaring behaviour and fast colour changes. Only at luminosities close to the\nEddington Luminosity, are high variability levels seen again, in correspondence\nto an increase in the fractional contribution of the Comptonization component.\nWe compare this behaviour with that observed in LMXBs harbouring black holes,\nshowing that the spectral, timing and multi-wavelength properties of a given\nsource can be determined by its location in the fast variability-luminosity\ndiagram, which, therefore, provides a common framework for neutron star and\nblack hole accretion states. \n\n"}
{"id": "1407.1783", "contents": "Title: Simulating X-ray Observations with Python Abstract: X-ray astronomy is an important tool in the astrophysicist's toolkit to\ninvestigate high-energy astrophysical phenomena. Theoretical numerical\nsimulations of astrophysical sources are fully three-dimensional\nrepresentations of physical quantities such as density, temperature, and\npressure, whereas astronomical observations are two-dimensional projections of\nthe emission generated via mechanisms dependent on these quantities. To bridge\nthe gap between simulations and observations, algorithms for generating\nsynthetic observations of simulated data have been developed. We present an\nimplementation of such an algorithm in the yt analysis software package. We\ndescribe the underlying model for generating the X-ray photons, the important\nrole that yt and other Python packages play in its implementation, and present\na detailed workable example of the creation of simulated X-ray observations. \n\n"}
{"id": "1407.2230", "contents": "Title: Sound speed of scalar field dark energy: weak effects and large\n  uncertainties Abstract: The possibility of reconstruction of Lagrangian for the scalar field dark\nenergy with constant effective sound speed $c_s$ is analyzed. It is found that\nsuch reconstruction can be made with accuracy up to an arbitrary constant. The\nvalue of $c_s$ is estimated together with other dark energy parameters\n($\\Omega_{de}$, $w_0$, $c_a^2$) and main cosmological ones on the basis of data\nincluding Planck-2013 results on CMB anisotropy, BAO distance ratios from\nrecent galaxy surveys, galaxy power spectrum from WiggleZ, magnitude-redshift\nrelations for distant SNe Ia from SNLS3 and Union2.1 compilations, the HST\ndetermination of the Hubble constant. It is shown that no value of $c_s$ from\nthe range [0,1] is preferred by the used data because of very weak influence of\ndark energy perturbations on the large scale structure formation and CMB\ntemperature fluctuations. \n\n"}
{"id": "1407.2289", "contents": "Title: Rotation periods and ages of solar analogs and solar twins revealed by\n  the Kepler Mission Abstract: A new sample of solar analogs and twin candidates have been constructed and\nstudied, with particular attention to their light curves from NASA's Kepler\nmission. This letter aims to assess the evolutionary status, derive their\nrotation and ages and identify those solar analogs or solar twin candidates. We\nseparate out the subgiants that compose a large fraction of the asteroseismic\nsample, and which show an increase in the average rotation period as the stars\nascend the subgiant branch. The rotation periods of the dwarfs, ranging from 6\nto 30 days, and averaged 19d, allow us to assess their individual evolutionary\nstates on the main sequence, and to derive their ages using gyrochronology.\nThese ages are found to be in agreement with a correlation coefficient of r =\n0.79 with the independent asteroseismic ages, where available. As a result of\nthis investigation, we are able to identify 34 stars as solar analogs and 22 of\nthem as solar twin candidates. \n\n"}
{"id": "1407.2376", "contents": "Title: Explaining the Proton Radius Puzzle with Disformal Scalars Abstract: We analyse the consequences of a disformal interaction between a massless\nscalar and matter particles in the context of atomic physics. We focus on the\ndisplacement of the atomic energy levels that it induces, and in particular the\nchange in the Lamb shift between the 2s and 2p states. We find that the\ncorrection to the Lamb shift depends on the mass of the fermion orbiting around\nthe nucleus, implying a larger effect for muonic atoms. Taking the cut-off\nscale describing the effective scalar field theory close to the QCD scale, we\nfind that the disformal interaction can account for the observed difference in\nthe proton radius of muonic versus electronic Hydrogen. Explaining the proton\nradius puzzle is only possible when the scalar field is embedded in non-linear\ntheories which alleviate constraints from collider and stellar physics. Short\ndistance properties of the Galileon where non-perturbative effects in vacuum\nare present ensure that unitarity is preserved in high energy particle\ncollisions. In matter, the chameleon mechanism alleviates the constraints on\ndisformal interactions coming from the burning rates for stellar objects. We\nshow how to combine these two properties in a single model which renders the\nproposed explanation of the proton radius puzzle viable. \n\n"}
{"id": "1407.2973", "contents": "Title: SPT-3G: A Next-Generation Cosmic Microwave Background Polarization\n  Experiment on the South Pole Telescope Abstract: We describe the design of a new polarization sensitive receiver, SPT-3G, for\nthe 10-meter South Pole Telescope (SPT). The SPT-3G receiver will deliver a\nfactor of ~20 improvement in mapping speed over the current receiver, SPTpol.\nThe sensitivity of the SPT-3G receiver will enable the advance from statistical\ndetection of B-mode polarization anisotropy power to high signal-to-noise\nmeasurements of the individual modes, i.e., maps. This will lead to precise\n(~0.06 eV) constraints on the sum of neutrino masses with the potential to\ndirectly address the neutrino mass hierarchy. It will allow a separation of the\nlensing and inflationary B-mode power spectra, improving constraints on the\namplitude and shape of the primordial signal, either through SPT-3G data alone\nor in combination with BICEP-2/KECK, which is observing the same area of sky.\nThe measurement of small-scale temperature anisotropy will provide new\nconstraints on the epoch of reionization. Additional science from the SPT-3G\nsurvey will be significantly enhanced by the synergy with the ongoing optical\nDark Energy Survey (DES), including: a 1% constraint on the bias of optical\ntracers of large-scale structure, a measurement of the differential Doppler\nsignal from pairs of galaxy clusters that will test General Relativity on ~200\nMpc scales, and improved cosmological constraints from the abundance of\nclusters of galaxies. \n\n"}
{"id": "1407.3084", "contents": "Title: Dynamical Fractional Chaotic Inflation -- Dynamical Generation of a\n  Fractional Power-Law Potential for Chaotic Inflation Abstract: Chaotic inflation based on a simple monomial scalar potential, V(phi) ~\nphi^p, is an attractive large-field model of inflation capable of generating a\nsizable tensor-to-scalar ratio r. Therefore, assuming that future CMB\nobservations will confirm the large r value reported by BICEP2, it is important\nto determine what kind of dynamical mechanism could possibly endow the inflaton\nfield with such a simple effective potential. In this paper, we answer this\nquestion in the context of field theory, i.e. in the framework of dynamical\nchaotic inflation (DCI), where strongly interacting supersymmetric gauge\ndynamics around the scale of grand unification dynamically generate a\nfractional power-law potential via the quantum effect of dimensional\ntransmutation. In constructing explicit models, we significantly extend our\nprevious work, as we now consider a large variety of possible underlying gauge\ndynamics and relax our conditions on the field content of the model. This\nallows us to realize almost arbitrary rational values for the power p in the\ninflaton potential. The present paper may hence be regarded as a first step\ntowards a more complete theory of dynamical chaotic inflation. \n\n"}
{"id": "1407.3271", "contents": "Title: Schwarzschild-Couder Telescope for the Cherenkov Telescope Array Abstract: The Cherenkov Telescope Array (CTA) is the next major ground-based\nobservatory for gamma-ray astronomy. With CTA gamma-ray sources will be studied\nin the very-high energy gamma-ray range of a few tens of GeV to 100 TeV with up\nto ten times better sensitivity than available with current generation\ninstruments. We discuss the proposed US contribution to CTA that comprises\nimaging atmospheric Cherenkov telescope with Schwarzschild-Couder (SC) optics.\nKey features of the SC telescope are a wide field of view of eight degrees, a\nfinely pixelated camera with silicon photomultipliers as photon detectors, and\na compact and power efficient 1 GS/s readout. The progress in both the optical\nsystem and camera development are discussed in this paper. \n\n"}
{"id": "1407.7199", "contents": "Title: Single scale factor for the universe from the creation of radiation and\n  matter till the present Abstract: A scheme for incorporating the creation of radiation and matter into the\ncosmological evolution is introduced so that it becomes possible to merge the\ntimes before and after the creation of radiation and matter in a single scale\nfactor in Robertson-Walker metric. This scheme is illustrated through a toy\nmodel that has the prospect of constituting a basis for a realistic model. \n\n"}
{"id": "1407.7676", "contents": "Title: GalSim: The modular galaxy image simulation toolkit Abstract: GALSIM is a collaborative, open-source project aimed at providing an image\nsimulation tool of enduring benefit to the astronomical community. It provides\na software library for generating images of astronomical objects such as stars\nand galaxies in a variety of ways, efficiently handling image transformations\nand operations such as convolution and rendering at high precision. We describe\nthe GALSIM software and its capabilities, including necessary theoretical\nbackground. We demonstrate that the performance of GALSIM meets the stringent\nrequirements of high precision image analysis applications such as weak\ngravitational lensing, for current datasets and for the Stage IV dark energy\nsurveys of the Large Synoptic Survey Telescope, ESA's Euclid mission, and\nNASA's WFIRST-AFTA mission. The GALSIM project repository is public and\nincludes the full code history, all open and closed issues, installation\ninstructions, documentation, and wiki pages (including a Frequently Asked\nQuestions section). The GALSIM repository can be found at\nhttps://github.com/GalSim-developers/GalSim . \n\n"}
{"id": "1407.8116", "contents": "Title: Optimizing performance per watt on GPUs in High Performance Computing:\n  temperature, frequency and voltage effects Abstract: The magnitude of the real-time digital signal processing challenge attached\nto large radio astronomical antenna arrays motivates use of high performance\ncomputing (HPC) systems. The need for high power efficiency (performance per\nwatt) at remote observatory sites parallels that in HPC broadly, where\nefficiency is an emerging critical metric. We investigate how the performance\nper watt of graphics processing units (GPUs) is affected by temperature, core\nclock frequency and voltage. Our results highlight how the underlying physical\nprocesses that govern transistor operation affect power efficiency. In\nparticular, we show experimentally that GPU power consumption grows\nnon-linearly with both temperature and supply voltage, as predicted by physical\ntransistor models. We show lowering GPU supply voltage and increasing clock\nfrequency while maintaining a low die temperature increases the power\nefficiency of an NVIDIA K20 GPU by up to 37-48% over default settings when\nrunning xGPU, a compute-bound code used in radio astronomy. We discuss how\ntemperature-aware power models could be used to reduce power consumption for\nfuture HPC installations. Automatic temperature-aware and application-dependent\nvoltage and frequency scaling (T-DVFS and A-DVFS) may provide a mechanism to\nachieve better power efficiency for a wider range of codes running on GPUs \n\n"}
{"id": "1408.0178", "contents": "Title: The magnetic field of $\\zeta$ Ori A Abstract: Magnetic fields play a significant role in the evolution of massive stars.\nAbout 7% of massive stars are found to be magnetic at a level detectable with\ncurrent instrumentation and only a few magnetic O stars are known. Detecting\nmagnetic field in O stars is particularly challenging because they only have\nfew, often broad, lines to measure the field, which leads to a deficit in the\nknowledge of the basic magnetic properties of O stars. We present new\nspectropolarimetric Narval observations of $\\zeta$ Ori A. We also provide a new\nanalysis of both the new and older data taking binarity into account. The aim\nof this study was to confirm the presence of a magnetic field in $\\zeta$ Ori A.\nWe identify that it belongs to $\\zeta$ Ori Aa and characterize it. \n\n"}
{"id": "1408.4160", "contents": "Title: The Deep Diffuse Extragalactic Radio Sky at 1.75 GHz Abstract: We present a study of diffuse extragalactic radio emission at $1.75\\,$GHz\nfrom part of the ELAIS-S1 field using the Australia Telescope Compact Array.\nThe resulting mosaic is $2.46\\,$deg$^2$, with a roughly constant noise region\nof $0.61\\,$deg$^2$ used for analysis. The image has a beam size of $150\n\\times60\\,$arcsec and instrumental $\\langle\\sigma_{\\rm n}\\rangle= (52\\pm5)\\,\n\\mu$Jy beam$^{-1}$. Using point-source models from the ATLAS survey, we\nsubtract the discrete emission in this field for $S \\ge 150\\, \\mu$Jy\nbeam$^{-1}$. Comparison of the source-subtracted probability distribution, or\n\\pd, with the predicted distribution from unsubtracted discrete emission and\nnoise, yields an excess of $(76 \\pm 23) \\, \\mu$Jy beam$^{-1}$. Taking this as\nan upper limit on any extended emission we constrain several models of extended\nsource counts, assuming $\\Omega_{\\rm source} \\le 2\\,$arcmin. The best-fitting\nmodels yield temperatures of the radio background from extended emission of\n$T_{\\rm b}=(10\\pm7) \\,$mK, giving an upper limit on the total temperature at\n$1.75\\,$GHz of $(73\\pm10)\\,$mK. Further modelling shows that our data are\ninconsistent with the reported excess temperature of ARCADE2 to a source-count\nlimit of $1\\, \\mu$Jy. Our new data close a loop-hole in the previous\nconstraints, because of the possibility of extended emission being resolved out\nat higher resolution. Additionally, we look at a model of cluster halo emission\nand two WIMP dark matter annihilation source-count models, and discuss general\nconstraints on any predicted counts from such sources. Finally, we report the\nderived integral count at $1.4\\,$GHz using the deepest discrete count plus our\nnew extended-emission limits, providing numbers that can be used for planning\nfuture ultra-deep surveys. \n\n"}
{"id": "1408.5338", "contents": "Title: Voids in Modified Gravity Reloaded: Eulerian Void Assignment Abstract: We revisit the excursion set approach to calculate void abundances in\nchameleon-type modified gravity theories, which was previously studied by\nClampitt, Cai and Li (2013). We focus on properly accounting for the\nvoid-in-cloud effect, i.e., the growth of those voids sitting in over-dense\nregions may be restricted by the evolution of their surroundings. This effect\nmay change the distribution function of voids hence affect predictions on the\ndifferences between modified gravity and GR. We show that the thin-shell\napproximation usually used to calculate the fifth force is qualitatively good\nbut quantitatively inaccurate. Therefore, it is necessary to numerically solve\nthe fifth force in both over-dense and under-dense regions. We then generalise\nthe Eulerian void assignment method of Paranjape, Lam and Sheth (2012) to our\nmodified gravity model. We implement this method in our Monte Carlo simulations\nand compare its results with the original Lagrangian methods. We find that the\nabundances of small voids are significantly reduced in both modified gravity\nand GR due to the restriction of environments. However, the change in void\nabundances for the range of void radii of interest for both models is similar.\nTherefore, the difference between models remains similar to the results from\nthe Lagrangian method, especially if correlated steps of the random walks are\nused. As Clampitt, Cai and Li (2013), we find that the void abundance is much\nmore sensitive to modified gravity than halo abundances. Our method can then be\na faster alternative to N-body simulations for studying the qualitative\nbehaviour of a broad class of theories. We also discuss the limitations and\nother practical issues associated with its applications. \n\n"}
{"id": "1408.6842", "contents": "Title: The Illustris simulation: the evolving population of black holes across\n  cosmic time Abstract: We study the properties of black holes and their host galaxies across cosmic\ntime in the Illustris simulation. Illustris is a large scale cosmological\nhydrodynamical simulation which resolves a (106.5 Mpc)^3 volume with more than\n12 billion resolution elements and includes state-of-the-art physical models\nrelevant for galaxy formation. We find that the black hole mass density for\nredshifts z = 0 - 5 and the black hole mass function at z = 0 predicted by\nIllustris are in very good agreement with the most recent observational\nconstraints. We show that the bolometric and hard X-ray luminosity functions of\nAGN at z = 0 and 1 reproduce observational data very well over the full dynamic\nrange probed. Unless the bolometric corrections are largely underestimated,\nthis requires radiative efficiencies to be on average low, epsilon_r <= 0.1,\nnoting however that in our model radiative efficiencies are degenerate with\nblack hole feedback efficiencies. Cosmic downsizing of the AGN population is in\nbroad agreement with the findings from X-ray surveys, but we predict a larger\nnumber density of faint AGN at high redshifts than currently inferred. We also\nstudy black hole -- host galaxy scaling relations as a function of galaxy\nmorphology, colour and specific star formation rate. We find that black holes\nand galaxies co-evolve at the massive end, but for low mass, blue and\nstar-forming galaxies there is no tight relation with either their central\nblack hole masses or the nuclear AGN activity. \n\n"}
{"id": "1409.1254", "contents": "Title: Strong Lens Time Delay Challenge: II. Results of TDC1 Abstract: We present the results of the first strong lens time delay challenge. The\nmotivation, experimental design, and entry level challenge are described in a\ncompanion paper. This paper presents the main challenge, TDC1, which consisted\nof analyzing thousands of simulated light curves blindly. The observational\nproperties of the light curves cover the range in quality obtained for current\ntargeted efforts (e.g.,~COSMOGRAIL) and expected from future synoptic surveys\n(e.g.,~LSST), and include simulated systematic errors. \\nteamsA\\ teams\nparticipated in TDC1, submitting results from \\nmethods\\ different method\nvariants. After a describing each method, we compute and analyze basic\nstatistics measuring accuracy (or bias) $A$, goodness of fit $\\chi^2$,\nprecision $P$, and success rate $f$. For some methods we identify outliers as\nan important issue. Other methods show that outliers can be controlled via\nvisual inspection or conservative quality control. Several methods are\ncompetitive, i.e., give $|A|<0.03$, $P<0.03$, and $\\chi^2<1.5$, with some of\nthe methods already reaching sub-percent accuracy. The fraction of light curves\nyielding a time delay measurement is typically in the range $f = $20--40\\%. It\ndepends strongly on the quality of the data: COSMOGRAIL-quality cadence and\nlight curve lengths yield significantly higher $f$ than does sparser sampling.\nTaking the results of TDC1 at face value, we estimate that LSST should provide\naround 400 robust time-delay measurements, each with $P<0.03$ and $|A|<0.01$,\ncomparable to current lens modeling uncertainties. In terms of observing\nstrategies, we find that $A$ and $f$ depend mostly on season length, while P\ndepends mostly on cadence and campaign duration. \n\n"}
{"id": "1409.2840", "contents": "Title: Autonomous Gaussian Decomposition Abstract: We present a new algorithm, named Autonomous Gaussian Decomposition (AGD),\nfor automatically decomposing spectra into Gaussian components. AGD uses\nderivative spectroscopy and machine learning to provide optimized guesses for\nthe number of Gaussian components in the data, and also their locations,\nwidths, and amplitudes. We test AGD and find that it produces results\ncomparable to human-derived solutions on 21cm absorption spectra from the 21cm\nSPectral line Observations of Neutral Gas with the EVLA (21-SPONGE) survey. We\nuse AGD with Monte Carlo methods to derive the HI line completeness as a\nfunction of peak optical depth and velocity width for the 21-SPONGE data, and\nalso show that the results of AGD are stable against varying observational\nnoise intensity. The autonomy and computational efficiency of the method over\ntraditional manual Gaussian fits allow for truly unbiased comparisons between\nobservations and simulations, and for the ability to scale up and interpret the\nvery large data volumes from the upcoming Square Kilometer Array and pathfinder\ntelescopes. \n\n"}
{"id": "1409.3775", "contents": "Title: Dark Energy and Mass Generation Abstract: We consider a set of solutions for a massless quartic scalar field, recently\ndevised, that satisfy a massive dispersion relation. We show that such\nsolutions have the property to give the correct behavior for the equation of\nstate of the dark energy. It seen that conformal invariance is restored and the\nmass gap goes to zero on a time scale determined by the Hubble constant and the\nstrength of the self-interaction of the scalar field. When conformal invariance\nis restored, the equation of state for the dark energy can apply. \n\n"}
{"id": "1409.3852", "contents": "Title: Detecting solar chameleons through radiation pressure Abstract: Light scalar fields can drive the accelerated expansion of the universe.\nHence, they are obvious dark energy candidates. To make such models compatible\nwith tests of General Relativity in the solar system and \"fifth force\" searches\non Earth, one needs to screen them. One possibility is the so-called\n\"chameleon\" mechanism, which renders an effective mass depending on the local\nmatter density. If chameleon particles exist, they can be produced in the sun\nand detected on Earth exploiting the equivalent of a radiation pressure. Since\ntheir effective mass scales with the local matter density, chameleons can be\nreflected by a dense medium if their effective mass becomes greater than their\ntotal energy. Thus, under appropriate conditions, a flux of solar chameleons\nmay be sensed by detecting the total instantaneous momentum transferred to a\nsuitable opto-mechanical force/pressure sensor. We calculate the solar\nchameleon spectrum and the reach in the chameleon parameter space of an\nexperiment using the preliminary results from a force/pressure sensor,\ncurrently under development at INFN Trieste, to be mounted in the focal plane\nof one of the X-Ray telescopes of the CAST experiment at CERN. We show, that\nsuch an experiment signifies a pioneering effort probing uncharted chameleon\nparameter space. \n\n"}
{"id": "1409.4151", "contents": "Title: Comparison of algorithms for determination of rotation measure and\n  Faraday structure I. 1100 - 1400 MHz Abstract: (abridged) We run a Faraday structure determination data challenge to\nbenchmark the currently available algorithms including Faraday synthesis\n(previously called RM synthesis in the literature), wavelet, compressive\nsampling and $QU$-fitting. The frequency set is similar to POSSUM/GALFACTS with\na 300 MHz bandwidth from 1.1 to 1.4 GHz. We define three figures of merit\nmotivated by the underlying science: a) an average RM weighted by polarized\nintensity, RMwtd, b) the separation $\\Delta\\phi$ of two Faraday components and\nc) the reduced chi-squared. Based on the current test data of signal to noise\nratio of about 32, we find that: (1) When only one Faraday thin component is\npresent, most methods perform as expected, with occasional failures where two\ncomponents are incorrectly found; (2) For two Faraday thin components,\nQU-fitting routines perform the best, with errors close to the theoretical ones\nfor RMwtd, but with significantly higher errors for $\\Delta\\phi$. All other\nmethods including standard Faraday synthesis frequently identify only one\ncomponent when $\\Delta\\phi$ is below or near the width of the Faraday point\nspread function; (3) No methods, as currently implemented, work well for\nFaraday thick components due to the narrow bandwidth; (4) There exist\ncombinations of two Faraday components which produce a large range of\nacceptable fits and hence large uncertainties in the derived single RMs; in\nthese cases, different RMs lead to the same Q, U behavior, so no method can\nrecover a unique input model. \n\n"}
{"id": "1409.7699", "contents": "Title: The Overlooked Potential of Generalized Linear Models in Astronomy-II:\n  Gamma regression and photometric redshifts Abstract: Machine learning techniques offer a precious tool box for use within\nastronomy to solve problems involving so-called big data. They provide a means\nto make accurate predictions about a particular system without prior knowledge\nof the underlying physical processes of the data. In this article, and the\ncompanion papers of this series, we present the set of Generalized Linear\nModels (GLMs) as a fast alternative method for tackling general astronomical\nproblems, including the ones related to the machine learning paradigm. To\ndemonstrate the applicability of GLMs to inherently positive and continuous\nphysical observables, we explore their use in estimating the photometric\nredshifts of galaxies from their multi-wavelength photometry. Using the gamma\nfamily with a log link function we predict redshifts from the PHoto-z Accuracy\nTesting simulated catalogue and a subset of the Sloan Digital Sky Survey from\nData Release 10. We obtain fits that result in catastrophic outlier rates as\nlow as ~1% for simulated and ~2% for real data. Moreover, we can easily obtain\nsuch levels of precision within a matter of seconds on a normal desktop\ncomputer and with training sets that contain merely thousands of galaxies. Our\nsoftware is made publicly available as an user-friendly package developed in\nPython, R and via an interactive web application\n(https://cosmostatisticsinitiative.shinyapps.io/CosmoPhotoz). This software\nallows users to apply a set of GLMs to their own photometric catalogues and\ngenerates publication quality plots with minimum effort from the user. By\nfacilitating their ease of use to the astronomical community, this paper series\naims to make GLMs widely known and to encourage their implementation in future\nlarge-scale projects, such as the Large Synoptic Survey Telescope. \n\n"}
{"id": "1409.8409", "contents": "Title: Axion Landscape and Natural Inflation Abstract: Multiple axions form a landscape in the presence of various shift symmetry\nbreaking terms. Eternal inflation populates the axion landscape, continuously\ncreating new universes by bubble nucleation. Slow-roll inflation takes place\nafter the tunneling event, if a very flat direction with a super-Planckian\ndecay constant arises due to the alignment mechanism. We study the vacuum\nstructure as well as possible inflationary dynamics in the axion landscape\nscenario, and find that the inflaton dynamics is given by either natural or\nmulti-natural inflation. In the limit of large decay constant, it is\napproximated by the quadratic chaotic inflation, which however is disfavored if\nthere is a pressure toward shorter duration of inflation. Therefore, if the\nspectral index and the tensor-to-scalar ratio turn out to be different from the\nquadratic chaotic inflation, there might be observable traces of the bubble\nnucleation. Also, the existence of small modulations to the inflaton potential\nis a common feature in the axion landscape, which generates a sizable and\nalmost constant running of the scalar spectral index over CMB scales.\nNon-Gaussianity of equilateral type can also be generated if some of the axions\nare coupled to massless gauge fields. \n\n"}
{"id": "1410.2805", "contents": "Title: HACC: Simulating Sky Surveys on State-of-the-Art Supercomputing\n  Architectures Abstract: Current and future surveys of large-scale cosmic structure are associated\nwith a massive and complex datastream to study, characterize, and ultimately\nunderstand the physics behind the two major components of the 'Dark Universe',\ndark energy and dark matter. In addition, the surveys also probe primordial\nperturbations and carry out fundamental measurements, such as determining the\nsum of neutrino masses. Large-scale simulations of structure formation in the\nUniverse play a critical role in the interpretation of the data and extraction\nof the physics of interest. Just as survey instruments continue to grow in size\nand complexity, so do the supercomputers that enable these simulations. Here we\nreport on HACC (Hardware/Hybrid Accelerated Cosmology Code), a recently\ndeveloped and evolving cosmology N-body code framework, designed to run\nefficiently on diverse computing architectures and to scale to millions of\ncores and beyond. HACC can run on all current supercomputer architectures and\nsupports a variety of programming models and algorithms. It has been\ndemonstrated at scale on Cell- and GPU-accelerated systems, standard multi-core\nnode clusters, and Blue Gene systems. HACC's design allows for ease of\nportability, and at the same time, high levels of sustained performance on the\nfastest supercomputers available. We present a description of the design\nphilosophy of HACC, the underlying algorithms and code structure, and outline\nimplementation details for several specific architectures. We show selected\naccuracy and performance results from some of the largest high resolution\ncosmological simulations so far performed, including benchmarks evolving more\nthan 3.6 trillion particles. \n\n"}
{"id": "1410.3481", "contents": "Title: Data engineering for archive evolution Abstract: From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression. \n\n"}
{"id": "1410.3838", "contents": "Title: The Hector Survey: integral field spectroscopy of 100,000 galaxies Abstract: In March 2013, the Sydney--AAO Multi-object Integral field spectrograph\n(SAMI) began a major survey of 3400 galaxies at the AAT, the largest of its\nkind to date. At the time of writing, over a third of the targets have been\nobserved and the scientific impact has been immediate. The Manga galaxy survey\nhas now started at the SDSS telescope and will target an even larger sample of\nnearby galaxies. In Australia, the community is now gearing up to deliver a\nmajor new facility called Hector that will allow integral field spectroscopy of\n100 galaxies observed simultaneously. By the close of the decade, it will be\npossible to obtain integral field spectroscopy of 100,000 galaxies over 3000\nsquare degrees of sky down to r=17 (median). Many of these objects will have HI\nimaging from the new ASKAP radio surveys. We discuss the motivation for such a\nsurvey and the use of new cosmological simulations that are properly matched to\nthe integral field observations. The Hector survey will open up a new and\nunique parameter space for galaxy evolution studies. \n\n"}
{"id": "1410.8291", "contents": "Title: First Experimental Characterization of Microwave Emission from Cosmic\n  Ray Air Showers Abstract: We report the first direct measurement of the overall characteristics of\nmicrowave radio emission from extensive air showers. Using a trigger provided\nby the KASCADE-Grande air shower array, the signals of the microwave antennas\nof the CROME (Cosmic-Ray Observation via Microwave Emission) experiment have\nbeen read out and searched for signatures of radio emission by high-energy air\nshowers in the GHz frequency range. Microwave signals have been detected for\nmore than 30 showers with energies above 3*10^16 eV. The observations presented\nin this Letter are consistent with a mainly forward-directed and polarised\nemission process in the GHz frequency range. The measurements show that\nmicrowave radiation offers a new means of studying air showers at energies\nabove 10^17 eV. \n\n"}
{"id": "1411.0032", "contents": "Title: Modelling the Transfer Function for the Dark Energy Survey Abstract: We present a forward-modelling simulation framework designed to model the\ndata products from the Dark Energy Survey (DES). This forward-model process can\nbe thought of as a transfer function -- a mapping from cosmological and\nastronomical signals to the final data products used by the scientists. Using\noutput from the cosmological simulations (the Blind Cosmology Challenge), we\ngenerate simulated images (the Ultra Fast Image Simulator, Berge et al. 2013)\nand catalogs representative of the DES data. In this work we simulate the 244\nsq. deg coadd images and catalogs in 5 bands for the DES Science Verification\n(SV) data. The simulation output is compared with the corresponding data to\nshow that major characteristics of the images and catalogs can be captured. We\nalso point out several directions of future improvements. Two practical\nexamples, star/galaxy classification and proximity effects on object detection,\nare then used to demonstrate how one can use the simulations to address\nsystematics issues in data analysis. With clear understanding of the\nsimplifications in our model, we show that one can use the simulations\nside-by-side with data products to interpret the measurements. This forward\nmodelling approach is generally applicable for other upcoming and future\nsurveys. It provides a powerful tool for systematics studies which is\nsufficiently realistic and highly controllable. \n\n"}
{"id": "1411.0507", "contents": "Title: Is HDF5 a good format to replace UVFITS? Abstract: The FITS (Flexible Image Transport System) data format was developed in the\nlate 1970s for storage and exchange of astronomy-related image data. Since\nthen, it has become a standard file format not only for images, but also for\nradio interferometer data (e.g. UVFITS, FITS-IDI). But is FITS the right format\nfor next-generation telescopes to adopt? The newer Hierarchical Data Format\n(HDF5) file format offers considerable advantages over FITS, but has yet to\ngain widespread adoption within radio astronomy. One of the major holdbacks is\nthat HDF5 is not well supported by data reduction software packages. Here, we\npresent a comparison of FITS, HDF5, and the MeasurementSet (MS) format for\nstorage of interferometric data. In addition, we present a tool for converting\nbetween formats. We show that the underlying data model of FITS can be ported\nto HDF5, a first step toward achieving wider HDF5 support. \n\n"}
{"id": "1411.1150", "contents": "Title: Direction Dependent Effects In Wide-Field Wideband Full Stokes Radio\n  Imaging Abstract: Synthesis imaging in radio astronomy is affected by instrumental and\natmospheric effects which introduce direction-dependent (DD) gains.The antenna\npower pattern varies both as a function of time and frequency. The broad band\ntime varying nature of the antenna power pattern when not corrected leads to\ngross errors in full Stokes imaging and flux estimation. In this poster we\nexplore the errors that arise in image deconvolution while not accounting for\nthe time and frequency dependence of the antenna power pattern. Simulations\nwere conducted with the wide-band full Stokes power pattern of the Karl G.\nJansky Very Large Array (VLA) antennas to demonstrate the level of errors\narising from direction-dependent gains and their non-neglegible impact on\nupcoming sky surveys such as the VLASS. DD corrections through hybrid\nprojection algorithms are computationally expensive to perform. A highly\nparallel implementation through high performance computing architectures is the\nonly feasible way of applying these corrections to the large data sizes of\nthese upcoming surveys. \n\n"}
{"id": "1411.1405", "contents": "Title: Solar Flare Prediction Using SDO/HMI Vector Magnetic Field Data with a\n  Machine-Learning Algorithm Abstract: We attempt to forecast M-and X-class solar flares using a machine-learning\nalgorithm, called Support Vector Machine (SVM), and four years of data from the\nSolar Dynamics Observatory's Helioseismic and Magnetic Imager, the first\ninstrument to continuously map the full-disk photospheric vector magnetic field\nfrom space. Most flare forecasting efforts described in the literature use\neither line-of-sight magnetograms or a relatively small number of ground-based\nvector magnetograms. This is the first time a large dataset of vector\nmagnetograms has been used to forecast solar flares. We build a catalog of\nflaring and non-flaring active regions sampled from a database of 2,071 active\nregions, comprised of 1.5 million active region patches of vector magnetic\nfield data, and characterize each active region by 25 parameters. We then train\nand test the machine-learning algorithm and we estimate its performances using\nforecast verification metrics with an emphasis on the True Skill Statistic\n(TSS). We obtain relatively high TSS scores and overall predictive abilities.\nWe surmise that this is partly due to fine-tuning the SVM for this purpose and\nalso to an advantageous set of features that can only be calculated from vector\nmagnetic field data. We also apply a feature selection algorithm to determine\nwhich of our 25 features are useful for discriminating between flaring and\nnon-flaring active regions and conclude that only a handful are needed for good\npredictive abilities. \n\n"}
{"id": "1411.3193", "contents": "Title: Hopfield Neural Network deconvolution for weak lensing measurement Abstract: Weak gravitational lensing has the potential to place tight constraints on\nthe equation of the state of dark energy. However, this will only be possible\nif shear measurement methods can reach the required level of accuracy. We\npresent a new method to measure the ellipticity of galaxies used in weak\nlensing surveys. The method makes use of direct deconvolution of the data by\nthe total Point Spread Function (PSF). We adopt a linear algebra formalism that\nrepresents the PSF as a Toeplitz matrix. This allows us to solve the\nconvolution equation by applying the Hopfield Neural Network iterative scheme.\nThe ellipticity of galaxies in the deconvolved images are then measured using\nsecond order moments of the autocorrelation function of the images. To our\nknowledge, it is the first time full image deconvolution is used to measure\nweak lensing shear. We apply our method to the simulated weak lensing data\nproposed in the GREAT10 challenge and obtain a quality factor of Q=87. This\nresult is obtained after applying image denoising to the data, prior to the\ndeconvolution. The additive and multiplicative biases on the shear power\nspectrum are then +0.000009 and +0.0357, respectively. \n\n"}
{"id": "1412.0167", "contents": "Title: Debris Distribution in HD 95086 - A Young Analog of HR 8799 Abstract: HD 95086 is a young early-type star that hosts (1) a 5 MJ planet at the\nprojected distance of 56 AU revealed by direct imaging, and (2) a prominent\ndebris disk. Here we report the detection of 69 um crystalline olivine feature\nfrom the disk using the Spitzer/MIPS-SED data covering 55-95 um. Due to the low\nresolution of MIPS-SED mode, this feature is not spectrally resolved, but is\nconsistent with the emission from crystalline forsterite contributing 5% of the\ntotal dust mass. We also present detailed analysis of the disk SED and\nre-analysis of resolved images obtained by Herschel. Our results suggest that\nthe debris structure around HD 95086 consists of a warm (175 K) belt, a cold\n(55 K) disk, and an extended disk halo (up to 800 AU), and is very similar to\nthat of HR 8799. We compare the properties of the three debris components, and\nsuggest that HD 95086 is a young analog of HR 8799. We further investigate and\nconstrain single-planet, two-planet, three-planet and four-planet architectures\nthat can account for the observed debris structure and are compatible with\ndynamical stability constraints. We find that equal-mass four-planet\nconfigurations of geometrically spaced orbits, with each planet of mass 5 MJ,\ncould maintain the gap between the warm and cold debris belts, and also be just\nmarginally stable for timescales comparable to the age of the system. \n\n"}
{"id": "1412.5049", "contents": "Title: Analytic Prediction of Baryonic Effects from the EFT of Large Scale\n  Structures Abstract: The large scale structures of the universe will likely be the next leading\nsource of cosmological information. It is therefore crucial to understand their\nbehavior. The Effective Field Theory of Large Scale Structures provides a\nconsistent way to perturbatively predict the clustering of dark matter at large\ndistances. The fact that baryons move distances comparable to dark matter\nallows us to infer that baryons at large distances can be described in a\nsimilar formalism: the backreaction of short-distance non-linearities and of\nstar-formation physics at long distances can be encapsulated in an effective\nstress tensor, characterized by a few parameters. The functional form of\nbaryonic effects can therefore be predicted. In the power spectrum the leading\ncontribution goes as $\\propto k^2 P(k)$, with $P(k)$ being the linear power\nspectrum and with the numerical prefactor depending on the details of the\nstar-formation physics. We also perform the resummation of the contribution of\nthe long-wavelength displacements, allowing us to consistently predict the\neffect of the relative motion of baryons and dark matter. We compare our\npredictions with simulations that contain several implementations of baryonic\nphysics, finding percent agreement up to relatively high wavenumbers such as\n$k\\simeq 0.3\\,h\\, Mpc^{-1}$ or $k\\simeq 0.6\\, h\\, Mpc^{-1}$, depending on the\norder of the calculation. Our results open a novel way to understand baryonic\neffects analytically, as well as to interface with simulations. \n\n"}
{"id": "1501.00321", "contents": "Title: Unravelling the origin of large-scale magnetic fields in galaxy clusters\n  and beyond through Faraday Rotation Measures with the SKA Abstract: We investigate the possibility for the SKA to detect and study the magnetic\nfields in galaxy clusters and in the less dense environments surrounding them\nusing Faraday Rotation Measures. To this end, we produce 3-dimensional magnetic\nfield models for galaxy clusters of different masses and in different stages of\ntheir evolution, and derive mock rotation measure observations of background\nradiogalaxies. According to our results, already in phase I, we will be able to\ninfer the magnetic field properties in galaxy clusters as a function of the\ncluster mass, down to $10^{13}$ solar-masses. Moreover, using cosmological\nsimulations to model the gas density, we have computed the expected rotation\nmeasure through shock-fronts that occur in the intra-cluster medium during\ncluster mergers. The enhancement in the rotation measure due to the density\njump will permit to constraint the magnetic field strength and structure after\nthe shock passage. SKA observations of polarised sources located behind galaxy\nclusters will answer several questions about the magnetic field strength and\nstructure in galaxy clusters, and its evolution with cosmic time. \n\n"}
{"id": "1501.00963", "contents": "Title: The Eleventh and Twelfth Data Releases of the Sloan Digital Sky Survey:\n  Final Data from SDSS-III Abstract: The third generation of the Sloan Digital Sky Survey (SDSS-III) took data\nfrom 2008 to 2014 using the original SDSS wide-field imager, the original and\nan upgraded multi-object fiber-fed optical spectrograph, a new near-infrared\nhigh-resolution spectrograph, and a novel optical interferometer. All the data\nfrom SDSS-III are now made public. In particular, this paper describes Data\nRelease 11 (DR11) including all data acquired through 2013 July, and Data\nRelease 12 (DR12) adding data acquired through 2014 July (including all data\nincluded in previous data releases), marking the end of SDSS-III observing.\nRelative to our previous public release (DR10), DR12 adds one million new\nspectra of galaxies and quasars from the Baryon Oscillation Spectroscopic\nSurvey (BOSS) over an additional 3000 sq. deg of sky, more than triples the\nnumber of H-band spectra of stars as part of the Apache Point Observatory (APO)\nGalactic Evolution Experiment (APOGEE), and includes repeated accurate radial\nvelocity measurements of 5500 stars from the Multi-Object APO Radial Velocity\nExoplanet Large-area Survey (MARVELS). The APOGEE outputs now include measured\nabundances of 15 different elements for each star. In total, SDSS-III added\n2350 sq. deg of ugriz imaging; 155,520 spectra of 138,099 stars as part of the\nSloan Exploration of Galactic Understanding and Evolution 2 (SEGUE-2) survey;\n2,497,484 BOSS spectra of 1,372,737 galaxies, 294,512 quasars, and 247,216\nstars over 9376 sq. deg; 618,080 APOGEE spectra of 156,593 stars; and 197,040\nMARVELS spectra of 5,513 stars. Since its first light in 1998, SDSS has imaged\nover 1/3 of the Celestial sphere in five bands and obtained over five million\nastronomical spectra. \n\n"}
{"id": "1501.02047", "contents": "Title: Photometric Redshift with Bayesian Priors on Physical Properties of\n  Galaxies Abstract: We present a proof-of-concept analysis of photometric redshifts with Bayesian\npriors on physical properties of galaxies. This concept is particularly suited\nfor upcoming/on-going large imaging surveys, in which only several broad-band\nfilters are available and it is hard to break some of the degeneracies in the\nmulti-color space. We construct model templates of galaxies using a stellar\npopulation synthesis code and apply Bayesian priors on physical properties such\nas stellar mass and star formation rate. These priors are a function of\nredshift and they effectively evolve the templates with time in an\nobservationally motivated way. We demonstrate that the priors help reduce the\ndegeneracy and deliver significantly improved photometric redshifts.\nFurthermore, we show that a template error function, which corrects for\nsystematic flux errors in the model templates as a function of rest-frame\nwavelength, delivers further improvements. One great advantage of our technique\nis that we simultaneously measure redshifts and physical properties of galaxies\nin a fully self-consistent manner, unlike the two-step measurements with\ndifferent templates often performed in the literature. One may rightly worry\nthat the physical priors bias the inferred galaxy properties, but we show that\nthe bias is smaller than systematic uncertainties inherent in physical\nproperties inferred from the SED fitting and hence is not a major issue. We\nwill extensively test and tune the priors in the on-going Hyper Suprime-Cam\nsurvey and will make the code publicly available in the future. \n\n"}
{"id": "1501.02110", "contents": "Title: SNIa detection in the SNLS photometric analysis using Morphological\n  Component Analysis Abstract: Detection of supernovae and, more generally, of transient events in large\nsurveys can provide numerous false detections.In the case of a deferred\nprocessing of survey images, this implies reconstructing complete light curves\nfor all detections, requiring sizable processing time and resources.Optimizing\nthe detection of transient events is thus an important issue for both present\nand future surveys.We present here the optimization done in the SuperNova\nLegacy Survey (SNLS) for the 5-year data deferred photometric analysis. In this\nanalysis, detections are derived from stacks of subtracted images with one\nstack per lunation.The 3-year analysis provided 300,000 detections dominated by\nsignals of bright objects that were not perfectly subtracted.Allowing these\nartifacts to be detected leads not only to a waste of resources but also to\npossible signal coordinate contamination.We developed a subtracted image stack\ntreatment to reduce the number of non SN-like events using morphological\ncomponent analysis.This technique exploits the morphological diversity of\nobjects to be detected to extract the signal of interest.At the level of our\nsubtraction stacks, SN-like events are rather circular objects while most\nspurious detections exhibit different shapes.A two-step procedure was necessary\nto have a proper evaluation of the noise in the subtracted image stacks and\nthus a reliable signal extraction.We also set up a new detection strategy to\nobtain coordinates with good resolution for the extracted signal.SNIa MC\ngenerated images were used to study detection efficiency and coordinate\nresolution.When tested on SNLS 3 data this procedure decreases the number of\ndetections by a factor of two, while losing only 10% of SN-like events, almost\nall faint.MC results show that SNIa detection efficiency is equivalent to that\nof the original method for bright events, while the coordinate resolution is\nimproved. \n\n"}
{"id": "1501.02198", "contents": "Title: Weak-Field Spherically Symmetric Solutions in $f(T)$ gravity Abstract: We study weak-field solutions having spherical symmetry in $f(T)$ gravity; to\nthis end, we solve the field equations for a non diagonal tetrad, starting from\nLagrangian in the form $f(T)=T+\\alpha T^{n}$, where $\\alpha$ is a small\nconstant, parameterizing the departure of the theory from GR. We show that the\nclassical spherically symmetric solutions of GR, i.e. the Schwarzschild and\nSchwarzschild-de Sitter solutions, are perturbed by terms in the form $\\propto\nr^{2-2n}$ and discuss the impact of these perturbations in observational tests. \n\n"}
{"id": "1501.02999", "contents": "Title: A new multidimensional, energy-dependent two-moment transport code for\n  neutrino-hydrodynamics Abstract: We present the new code ALCAR developed to model multidimensional, multi\nenergy-group neutrino transport in the context of supernovae and neutron-star\nmergers. The algorithm solves the evolution equations of the 0th- and 1st-order\nangular moments of the specific intensity, supplemented by an algebraic\nrelation for the 2nd-moment tensor to close the system. The scheme takes into\naccount frame-dependent effects of order O(v/c) as well as the most important\ntypes of neutrino interactions. The transport scheme is significantly more\nefficient than a multidimensional solver of the Boltzmann equation, while it is\nmore accurate and consistent than the flux-limited diffusion method. The\nfinite-volume discretization of the essentially hyperbolic system of moment\nequations employs methods well-known from hydrodynamics. For the time\nintegration of the potentially stiff moment equations we employ a scheme in\nwhich only the local source terms are treated implicitly, while the advection\nterms are kept explicit, thereby allowing for an efficient computational\nparallelization of the algorithm. We investigate various problem setups in one\nand two dimensions to verify the implementation and to test the quality of the\nalgebraic closure scheme. In our most detailed test, we compare a fully\ndynamic, one-dimensional core-collapse simulation with two published\ncalculations performed with well-known Boltzmann-type neutrino-hydrodynamics\ncodes and we find very satisfactory agreement. \n\n"}
{"id": "1501.03415", "contents": "Title: Measuring the Muon Content of Air Showers with IceTop Abstract: IceTop, the surface component of the IceCube detector, has been used to\nmeasure the energy spectrum of cosmic ray primaries in the range between 1.58\nPeV and 1.26 EeV. It can also be used to study the low energy muons in air\nshowers by looking at large distances (> 300m) from the shower axis. We will\nshow the muon lateral distribution function at large lateral distances as\nmeasured with IceTop and discuss the implications of this measurement. We also\ndiscuss the prospects for low energy muon studies with IceTop. \n\n"}
{"id": "1501.03742", "contents": "Title: The Data Reduction Pipeline for the Apache Point Observatory Galactic\n  Evolution Experiment Abstract: The Apache Point Observatory Galactic Evolution Experiment (APOGEE), part of\nthe Sloan Digital Sky Survey III, explores the stellar populations of the Milky\nWay using the Sloan 2.5-m telescope linked to a high resolution (R~22,500),\nnear-infrared (1.51-1.70 microns) spectrograph with 300 optical fibers. For\nover 150,000 predominantly red giant branch stars that APOGEE targeted across\nthe Galactic bulge, disks and halo, the collected high S/N (>100 per\nhalf-resolution element) spectra provide accurate (~0.1 km/s) radial\nvelocities, stellar atmospheric parameters, and precise (~0.1 dex) chemical\nabundances for about 15 chemical species. Here we describe the basic APOGEE\ndata reduction software that reduces multiple 3D raw data cubes into\ncalibrated, well-sampled, combined 1D spectra, as implemented for the\nSDSS-III/APOGEE data releases (DR10, DR11 and DR12). The processing of the\nnear-IR spectral data of APOGEE presents some challenges for reduction,\nincluding automated sky subtraction and telluric correction over a 3 degree\ndiameter field and the combination of spectrally dithered spectra. We also\ndiscuss areas for future improvement. \n\n"}
{"id": "1501.04455", "contents": "Title: Eternal Higgs inflation and cosmological constant problem Abstract: We investigate the Higgs potential beyond the Planck scale in the superstring\ntheory, under the assumption that the supersymmetry is broken at the string\nscale. We identify the Higgs field as a massless state of the string, which is\nindicated by the fact that the bare Higgs mass can be zero around the string\nscale. We find that, in the large field region, the Higgs potential is\nconnected to a runaway vacuum with vanishing energy, which corresponds to\nopening up an extra dimension. We verify that such universal behavior indeed\nfollows from the toroidal compactification of the non-supersymmetric\n$SO(16)\\times SO(16)$ heterotic string theory. We show that this behavior fits\nin the picture that the Higgs field is the source of the eternal inflation. The\nobserved small value of the cosmological constant of our universe may be\nunderstood as the degeneracy with this runaway vacuum, which has vanishing\nenergy, as is suggested by the multiple point criticality principle. \n\n"}
{"id": "1501.05304", "contents": "Title: Bayesian Inference for Radio Observations Abstract: New telescopes like the Square Kilometre Array (SKA) will push into a new\nsensitivity regime and expose systematics, such as direction-dependent effects,\nthat could previously be ignored. Current methods for handling such systematics\nrely on alternating best estimates of instrumental calibration and models of\nthe underlying sky, which can lead to inadequate uncertainty estimates and\nbiased results because any correlations between parameters are ignored. These\ndeconvolution algorithms produce a single image that is assumed to be a true\nrepresentation of the sky, when in fact it is just one realization of an\ninfinite ensemble of images compatible with the noise in the data. In contrast,\nhere we report a Bayesian formalism that simultaneously infers both systematics\nand science. Our technique, Bayesian Inference for Radio Observations (BIRO),\ndetermines all parameters directly from the raw data, bypassing image-making\nentirely, by sampling from the joint posterior probability distribution. This\nenables it to derive both correlations and accurate uncertainties, making use\nof the flexible software MEQTREES to model the sky and telescope\nsimultaneously. We demonstrate BIRO with two simulated sets of Westerbork\nSynthesis Radio Telescope data sets. In the first, we perform joint estimates\nof 103 scientific (flux densities of sources) and instrumental (pointing\nerrors, beamwidth and noise) parameters. In the second example, we perform\nsource separation with BIRO. Using the Bayesian evidence, we can accurately\nselect between a single point source, two point sources and an extended\nGaussian source, allowing for 'super-resolution' on scales much smaller than\nthe synthesized beam. \n\n"}
{"id": "1501.05343", "contents": "Title: NANOGrav Constraints on Gravitational Wave Bursts with Memory Abstract: Among efforts to detect gravitational radiation, pulsar timing arrays are\nuniquely poised to detect \"memory\" signatures, permanent perturbations in\nspacetime from highly energetic astrophysical events such as mergers of\nsupermassive black hole binaries. The North American Nanohertz Observatory for\nGravitational Waves (NANOGrav) observes dozens of the most stable millisecond\npulsars using the Arecibo and Green Bank radio telescopes in an effort to\nstudy, among other things, gravitational wave memory. We herein present the\nresults of a search for gravitational wave bursts with memory (BWMs) using the\nfirst five years of NANOGrav observations. We develop original methods for\ndramatically speeding up searches for BWM signals. In the directions of the sky\nwhere our sensitivity to BWMs is best, we would detect mergers of binaries with\nreduced masses of $10^9$ $M_\\odot$ out to distances of 30 Mpc; such massive\nmergers in the Virgo cluster would be marginally detectable. We find no\nevidence for BWMs. However, with our non-detection, we set upper limits on the\nrate at which BWMs of various amplitudes could have occurred during the time\nspanned by our data--e.g., BWMs with amplitudes greater than $10^{-13}$ must\noccur at a rate less than 1.5 yr$^{-1}$. \n\n"}
{"id": "1501.07191", "contents": "Title: On the detection of spectral ripples from the Recombination Epoch Abstract: Photons emitted during the epochs of Hydrogen ($500 \\lesssim z \\lesssim\n1600$) and Helium recombination ($1600 \\lesssim z \\lesssim 3500$ for HeII\n$\\rightarrow$ HeI, $5000 \\lesssim z \\lesssim 8000$ for HeIII $\\rightarrow$\nHeII) are predicted to appear as broad, weak spectral distortions of the Cosmic\nMicrowave Background. We present a feasibility study for a ground-based\nexperimental detection of these recombination lines, which would provide an\nobservational constraint on the thermal ionization history of the Universe,\nuniquely probing astrophysical cosmology beyond the last scattering surface. We\nfind that an octave band in the 2--6 GHz window is optimal for such an\nexperiment, both maximizing signal-to-noise ratio and including sufficient line\nspectral structure. At these frequencies the predicted signal appears as an\nadditive quasi-sinusoidal component with amplitude about $8$ nK that is\nembedded in a sky spectrum some nine orders of magnitude brighter. We discuss\nan algorithm to detect these tiny spectral fluctuations in the sky spectrum by\nforeground modeling. We introduce a \\textit{Maximally Smooth} function capable\nof describing the foreground spectrum and distinguishing the signal of\ninterest. With Bayesian statistical tests and mock data we estimate that a\ndetection of the predicted distortions is possible with 90\\% confidence by\nobserving for 255 days with an array of 128 radiometers using cryogenically\ncooled state-of-the-art receivers. We conclude that detection is in principle\nfeasible in realistic observing times; we propose APSERa---Array of Precision\nSpectrometers for the Epoch of Recombination---a dedicated radio telescope to\ndetect these recombination lines. \n\n"}
{"id": "1501.07309", "contents": "Title: Arbitrary Transform Telescopes: The Generalization of Interferometry Abstract: The basic principle of astronomical interferometry is to derive the angular\ndistribution of radiation in the sky from the Fourier transform of the electric\nfield on the ground. What is so special about the Fourier transform? Nothing,\nit turns out. I consider the possibility of performing other transforms on the\nelectric field with digital technology. The Fractional Fourier Transform (FrFT)\nis useful for interpreting observations of sources that are close to the\ninterferometer (in the atmosphere for radio interferometers). Essentially,\napplying the FrFT focuses the array somewhere nearer than infinity. Combined\nwith the other Linear Canonical Transforms, any homogeneous linear optical\nsystem with thin elements can be instantiated. The time variation of the\nelectric field can also be decomposed into other bases besides the Fourier\nmodes, which is especially useful for dispersed transients or quick pulses. I\ndiscuss why the Fourier basis is so commonly used, and suggest it is partly\nbecause most astrophysical sources vary slowly in time. \n\n"}
{"id": "1502.00008", "contents": "Title: Gravitational lens modelling in a citizen science context Abstract: We develop a method to enable collaborative modelling of gravitational lenses\nand lens candidates, that could be used by non-professional lens enthusiasts.\nIt uses an existing free-form modelling program (glass), but enables the input\nto this code to be provided in a novel way, via a user-generated diagram that\nis essentially a sketch of an arrival-time surface. We report on an\nimplementation of this method, SpaghettiLens, which has been tested in a\nmodelling challenge using 29 simulated lenses drawn from a larger set created\nfor the Space Warps citizen science strong lens search. We find that volunteers\nfrom this online community asserted the image parities and time ordering\nconsistently in some lenses, but made errors in other lenses depending on the\nimage morphology. While errors in image parity and time ordering lead to large\nerrors in the mass distribution, the enclosed mass was found to be more robust:\nthe model-derived Einstein radii found by the volunteers were consistent with\nthose produced by one of the professional team, suggesting that given the\nappropriate tools, gravitational lens modelling is a data analysis activity\nthat can be crowd-sourced to good effect. Ideas for improvement are discussed,\nthese include (a) overcoming the tendency of the models to be shallower than\nthe correct answer in test cases, leading to systematic overestimation of the\nEinstein radius by 10 per cent at present, and (b) detailed modelling of arcs. \n\n"}
{"id": "1502.00596", "contents": "Title: BICEP2/Keck Array IV: Optical Characterization and Performance of the\n  BICEP2 and Keck Array Experiments Abstract: BICEP2 and the Keck Array are polarization-sensitive microwave telescopes\nthat observe the cosmic microwave background (CMB) from the South Pole at\ndegree angular scales in search of a signature of inflation imprinted as B-mode\npolarization in the CMB. BICEP2 was deployed in late 2009, observed for three\nyears until the end of 2012 at 150 GHz with 512 antenna-coupled transition edge\nsensor bolometers, and has reported a detection of B-mode polarization on\ndegree angular scales. The Keck Array was first deployed in late 2010 and will\nobserve through 2016 with five receivers at several frequencies (95, 150, and\n220 GHz). BICEP2 and the Keck Array share a common optical design and employ\nthe field-proven BICEP1 strategy of using small-aperture, cold, on-axis\nrefractive optics, providing excellent control of systematics while maintaining\na large field of view. This design allows for full characterization of\nfar-field optical performance using microwave sources on the ground. Here we\ndescribe the optical design of both instruments and report a full\ncharacterization of the optical performance and beams of BICEP2 and the Keck\nArray at 150 GHz. \n\n"}
{"id": "1502.01589", "contents": "Title: Planck 2015 results. XIII. Cosmological parameters Abstract: We present results based on full-mission Planck observations of temperature\nand polarization anisotropies of the CMB. These data are consistent with the\nsix-parameter inflationary LCDM cosmology. From the Planck temperature and\nlensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9)\nkm/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar\nspectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured\nparameters and 95% limits on other parameters.) Combined with Planck\ntemperature and lensing data, Planck LFI polarization measurements lead to a\nreionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with\nother astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective\nnumber of relativistic degrees of freedom and the sum of neutrino masses is\nconstrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005.\nFor LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent\nwith the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck\n(BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We\nfind no evidence for isocurvature perturbations or cosmic defects. The equation\nof state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big\nbang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent\nagreement with observations. We investigate annihilating dark matter and\ndeviations from standard recombination, finding no evidence for new physics.\nThe Planck results for base LCDM are in agreement with BAO data and with the\nJLA SNe sample. However the amplitude of the fluctuations is found to be higher\nthan inferred from rich cluster counts and weak gravitational lensing. Apart\nfrom these tensions, the base LCDM cosmology provides an excellent description\nof the Planck CMB observations and many other astrophysical data sets. \n\n"}
{"id": "1502.02735", "contents": "Title: A Compact Filter-Bank Waveguide Spectrometer for Millimeter Wavelengths Abstract: We present the design and measurements of a 90GHz prototype of a\nmillimeter-wave channelizing spectrometer realized in rectangular waveguide for\nastronomical instrumentation. The device was fabricated using conventional\nhigh-precision metal machining, and the spectrometer can be tiled into a 2D\narray to fill the focal plane of a telescope. Measurements of the fabricated\nfive-channel device matched well with electromagnetic simulations using HFSS\nand a cascaded S-matrix approach. This motivated the design of a 54-channel\nR=200 spectrometer that fills the single-moded passband of rectangular\nwaveguide in the 130-175 GHz and 190-250 GHz atmospheric windows for\nmillimeter-wave spectroscopic mapping and multi-object spectroscopy. \n\n"}
{"id": "1502.02821", "contents": "Title: Building a scalable global data processing pipeline for large\n  astronomical photometric datasets Abstract: Astronomical photometry is the science of measuring the flux of a celestial\nobject. Since its introduction, the CCD has been the principle method of\nmeasuring flux to calculate the apparent magnitude of an object. Each CCD image\ntaken must go through a process of cleaning and calibration prior to its use.\nAs the number of research telescopes increases the overall computing resources\nrequired for image processing also increases. Existing processing techniques\nare primarily sequential in nature, requiring increasingly powerful servers,\nfaster disks and faster networks to process data. Existing High Performance\nComputing solutions involving high capacity data centres are complex in design\nand expensive to maintain, while providing resources primarily to high profile\nscience projects. This research describes three distributed pipeline\narchitectures, a virtualised cloud based IRAF, the Astronomical Compute Node\n(ACN), a private cloud based pipeline, and NIMBUS, a globally distributed\nsystem. The ACN pipeline processed data at a rate of 4 Terabytes per day\ndemonstrating data compression and upload to a central cloud storage service at\na rate faster than data generation. The primary contribution of this research\nis NIMBUS, which is rapidly scalable, resilient to failure and capable of\nprocessing CCD image data at a rate of hundreds of Terabytes per day. This\npipeline is implemented using a decentralised web queue to control the\ncompression of data, uploading of data to distributed web servers, and creating\nweb messages to identify the location of the data. Using distributed web queue\nmessages, images are downloaded by computing resources distributed around the\nglobe. Rigorous experimental evidence is presented verifying the horizontal\nscalability of the system which has demonstrated a processing rate of 192\nTerabytes per day with clear indications that higher processing rates are\npossible. \n\n"}
{"id": "1502.03710", "contents": "Title: Beyond the growth rate of cosmic structure: Testing modified gravity\n  models with an extra degree of freedom Abstract: In 'modified' gravity the observed acceleration of the universe is explained\nby changing the gravitational force law or the number of degrees of freedom in\nthe gravitational sector. Both possibilities can be tested by measurements of\ncosmological structure formation. In this paper we elaborate the details of\nsuch tests using the Galileon model as a case study. We pay attention to the\npossibility that each new degree of freedom may have stochastically independent\ninitial conditions, generating different types of potential well in the early\nuniverse and breaking complete correlation between density and velocity power\nspectra. This 'stochastic bias' can confuse schemes to parametrize the\npredictions of modified gravity models, such as the use of the growth parameter\nf alone. Using data from the WiggleZ Dark Energy Survey we show that it will be\npossible to obtain constraints using information about the cosmological-scale\nforce law embedded in the multipole power spectra of redshift-space\ndistortions. As an example, we obtain an upper limit on the strength of the\nconformal coupling to matter in the cubic Galileon model, giving |1/M| < 200 /\nMp. This allows the fifth-force to be stronger than gravity, but is consistent\nwith zero coupling. \n\n"}
{"id": "1502.06001", "contents": "Title: Detection and localization of single-source gravitational waves with\n  pulsar timing arrays Abstract: Pulsar timing arrays (PTAs) can be used to search for very low frequency\n($10^{-9}$--$10^{-7}$ Hz) gravitational waves (GWs). In this paper we present a\ngeneral method for the detection and localization of single-source GWs using\nPTAs. We demonstrate the effectiveness of this new method for three types of\nsignals: monochromatic waves as expected from individual supermassive binary\nblack holes in circular orbits, GWs from eccentric binaries and GW bursts. We\nalso test its implementation in realistic data sets that include effects such\nas uneven sampling and heterogeneous data spans and measurement precision. It\nis shown that our method, which works in the frequency domain, performs as well\nas published time-domain methods. In particular, we find it equivalent to the\n$\\mathcal{F}_{e}$-statistic for monochromatic waves. We also discuss the\nconstruction of null streams -- data streams that have null response to GWs,\nand the prospect of using null streams as a consistency check in the case of\ndetected GW signals. Finally, we present sensitivities to individual\nsupermassive binary black holes in eccentric orbits. We find that a\nmonochromatic search that is designed for circular binaries can efficiently\ndetect eccentric binaries with both high and low eccentricities, while a\nharmonic summing technique provides greater sensitivities only for binaries\nwith moderate eccentricities. \n\n"}
{"id": "1502.07596", "contents": "Title: Foregrounds in Wide-Field Redshifted 21 cm Power Spectra Abstract: Detection of 21~cm emission of HI from the epoch of reionization, at\nredshifts z>6, is limited primarily by foreground emission. We investigate the\nsignatures of wide-field measurements and an all-sky foreground model using the\ndelay spectrum technique that maps the measurements to foreground object\nlocations through signal delays between antenna pairs. We demonstrate\ninterferometric measurements are inherently sensitive to all scales, including\nthe largest angular scales, owing to the nature of wide-field measurements.\nThese wide-field effects are generic to all observations but antenna shapes\nimpact their amplitudes substantially. A dish-shaped antenna yields the most\ndesirable features from a foreground contamination viewpoint, relative to a\ndipole or a phased array. Comparing data from recent Murchison Widefield Array\nobservations, we demonstrate that the foreground signatures that have the\nlargest impact on the HI signal arise from power received far away from the\nprimary field of view. We identify diffuse emission near the horizon as a\nsignificant contributing factor, even on wide antenna spacings that usually\nrepresent structures on small scales. For signals entering through the primary\nfield of view, compact emission dominates the foreground contamination. These\ntwo mechanisms imprint a characteristic \"pitchfork\" signature on the\n\"foreground wedge\" in Fourier delay space. Based on these results, we propose\nthat selective down-weighting of data based on antenna spacing and time can\nmitigate foreground contamination substantially by a factor ~100 with\nnegligible loss of sensitivity. \n\n"}
{"id": "1503.02233", "contents": "Title: NebulOS: A Big Data Framework for Astrophysics Abstract: We introduce NebulOS, a Big Data platform that allows a cluster of Linux\nmachines to be treated as a single computer. With NebulOS, the process of\nwriting a massively parallel program for a datacenter is no more complicated\nthan writing a Python script for a desktop computer. The platform enables most\npre-existing data analysis software to be used, as scale, in a datacenter\nwithout modification. The shallow learning curve and compatibility with\nexisting software greatly reduces the time required to develop distributed data\nanalysis pipelines. The platform is built upon industry-standard, open-source\nBig Data technologies, from which it inherits several fault tolerance features.\nNebulOS enhances these technologies by adding an intuitive user interface,\nautomated task monitoring, and other usability features. We present a summary\nof the architecture, provide usage examples, and discuss the system's\nperformance scaling. \n\n"}
{"id": "1503.02665", "contents": "Title: Zooming in on accretion - I. The structure of halo gas Abstract: We study the properties of gas in and around 10^12 solar mass halos at z=2\nusing a suite of high-resolution cosmological hydrodynamic 'zoom' simulations.\nWe quantify the thermal and dynamical structure of these gaseous reservoirs in\nterms of their mean radial distributions and angular variability along\ndifferent sightlines. With each halo simulated at three levels of increasing\nresolution, the highest reaching a baryon mass resolution of ~10,000 solar\nmasses, we study the interaction of filamentary inflow and the quasi-static hot\nhalo atmosphere. We highlight the discrepancy between the spatial resolution\navailable in the halo gas as opposed to within the galaxy itself, and find that\nstream morphologies become increasingly complex at higher resolution, with\nlarge coherent flows revealing density and temperature structure at\nprogressively smaller scales. Moreover, multiple gas components co-exist at the\nsame radius within the halo, making radially averaged analyses misleading. This\nis particularly true where the hot, quasi-static, high entropy halo atmosphere\ninteracts with cold, rapidly inflowing, low entropy accretion. We investigate\nthe process of gas virialization and identify different regimes for the heating\nof gas as it accretes from the intergalactic medium. Haloes at this mass have a\nwell-defined virial shock, associated with a sharp jump in temperature and\nentropy at ~1.25 r_vir. The presence, radius, and radial width of this boundary\nfeature, however, vary not only from halo to halo, but also as a function of\nangular direction, covering roughly ~85% of the 4pi sphere. Our findings are\nrelevant for the proper interpretation of observations pertaining to the\ncircumgalactic medium, including evidence for large amounts of cold gas\nsurrounding massive haloes at intermediate redshifts. \n\n"}
{"id": "1503.04155", "contents": "Title: Regaining the FORS: optical ground-based transmission spectroscopy of\n  the exoplanet WASP-19b with VLT+FORS2 Abstract: In the past few years, the study of exoplanets has evolved from being pure\ndiscovery, then being more exploratory in nature and finally becoming very\nquantitative. In particular, transmission spectroscopy now allows the study of\nexoplanetary atmospheres. Such studies rely heavily on space-based or large\nground-based facilities, because one needs to perform time-resolved, high\nsignal-to-noise spectroscopy. The very recent exchange of the prisms of the\nFORS2 atmospheric diffraction corrector on ESO's Very Large Telescope should\nallow us to reach higher data quality than was ever possible before. With\nFORS2, we have obtained the first optical ground-based transmission spectrum of\nWASP-19b, with 20 nm resolution in the 550--830 nm range. For this planet, the\ndata set represents the highest resolution transmission spectrum obtained to\ndate. We detect large deviations from planetary atmospheric models in the\ntransmission spectrum redwards of 790 nm, indicating either additional sources\nof opacity not included in the current atmospheric models for WASP-19b or\nadditional, unexplored sources of systematics. Nonetheless, this work shows the\nnew potential of FORS2 for studying the atmospheres of exoplanets in greater\ndetail than has been possible so far. \n\n"}
{"id": "1503.04194", "contents": "Title: ADS: The Next Generation Search Platform Abstract: Four years after the last LISA meeting, the NASA Astrophysics Data System\n(ADS) finds itself in the middle of major changes to the infrastructure and\ncontents of its database. In this paper we highlight a number of features of\ngreat importance to librarians and discuss the additional functionality that we\nare currently developing. Starting in 2011, the ADS started to systematically\ncollect, parse and index full-text documents for all the major publications in\nPhysics and Astronomy as well as many smaller Astronomy journals and arXiv\ne-prints, for a total of over 3.5 million papers. Our citation coverage has\ndoubled since 2010 and now consists of over 70 million citations. We are\nnormalizing the affiliation information in our records and, in collaboration\nwith the CfA library and NASA, we have started collecting and linking funding\nsources with papers in our system. At the same time, we are undergoing major\ntechnology changes in the ADS platform which affect all aspects of the system\nand its operations. We have rolled out and are now enhancing a new\nhigh-performance search engine capable of performing full-text as well as\nmetadata searches using an intuitive query language which supports fielded,\nunfielded and functional searches. We are currently able to index\nacknowledgments, affiliations, citations, funding sources, and to the extent\nthat these metadata are available to us they are now searchable under our new\nplatform. The ADS private library system is being enhanced to support reading\ngroups, collaborative editing of lists of papers, tagging, and a variety of\nprivacy settings when managing one's paper collection. While this effort is\nstill ongoing, some of its benefits are already available through the ADS Labs\nuser interface and API at http://adslabs.org/adsabs/ \n\n"}
{"id": "1503.05703", "contents": "Title: New tools for finding and testing of weak periodical variability Abstract: Our paper presents new methods for finding and testing of weak periodic\nvariability of stellar objects developed for the purpose of detecting expected\nregular light variations of magnetic chemically peculiar (mCP) candidates in\nthe Large Magellanic Cloud. We introduce two new periodograms of the mCP star,\nBS Cir (HD 125630), appropriate for rotating spotted variables and compare the\nresults with those obtained by the well-known Lomb-Scargle periodogram. The\nusage of periodograms and the testing of the significance of the found period\ncandidates are demonstrated with two examples: the observed and simulated\nobservations of the magnetic field of the mCP star CQ UMa (HD 119213) and the\nmCP candidate OGLE LMC136.7 16501. Three newly developed tests of the periodic\nvariability - the shuffling, bootstrap and subsidiary ones, are presented. We\ndemonstrate that the found periodic variations known with Signal-to-Noise ratio\nlarger than 6 can be approved as real. \n\n"}
{"id": "1503.07524", "contents": "Title: The Swift X-ray monitoring campaign of the center of the Milky Way Abstract: In 2006 February, shortly after its launch, Swift began monitoring the center\nof the Milky Way with the onboard X-Ray Telescope using short 1-ks exposures\nperformed every 1-4 days. Between 2006 and 2014, over 1200 observations have\nbeen obtained, amounting to ~1.2 Ms of exposure time. This has yielded a wealth\nof information about the long-term X-ray behavior of the supermassive black\nhole Sgr A*, and numerous transient X-ray binaries that are located within the\n25'x25' region covered by the campaign. In this review we highlight the\ndiscoveries made during these first nine years, which includes 1) the detection\nof seven bright X-ray flares from Sgr A*, 2) the discovery of the magnetar SGR\nJ1745-29, 3) the first systematic analysis of the outburst light curves and\nenergetics of the peculiar class of very-faint X-ray binaries, 4) the discovery\nof three new transient X-ray sources, 5) exposing low-level accretion in\notherwise bright X-ray binaries, and 6) the identification of a candidate X-ray\nbinary/millisecond radio pulsar transitional object. We also reflect on future\nscience to be done by continuing this Swift's legacy campaign of the Galactic\ncenter, which includes high-cadence monitoring of how the interaction between\nthe gaseous object `G2' and Sgr A* plays out in the future. \n\n"}
{"id": "1503.08146", "contents": "Title: The effects of He I 10830 on helium abundance determinations Abstract: Observations of helium and hydrogen emission lines from metal-poor\nextragalactic H II regions provide an independent method for determining the\nprimordial helium abundance, Y_p. Traditionally, the emission lines employed\nare in the visible wavelength range, and the number of suitable lines is\nlimited. Furthermore, when using these lines, large systematic uncertainties in\nhelium abundance determinations arise due to the degeneracy of physical\nparameters, such as temperature and density. Recently, Izotov, Thuan, & Guseva\n(2014) have pioneered adding the He 10830 infrared emission line in helium\nabundance determinations. The strong electron density dependence of He 10830\nmakes it ideal for better constraining density, potentially breaking the\ndegeneracy with temperature. We revisit our analysis of the dataset published\nby Izotov, Thuan, & Stasinska (2007) and incorporate the newly available\nobservations of He 10830 by scaling them using the observed-to-theoretical\nPaschen-gamma ratio. The solutions are better constrained, in particular for\nelectron density, temperature, and the neutral hydrogen fraction, improving the\nmodel fit to data, with the result that more spectra now pass screening for\nquality and reliability, in addition to a standard 95% confidence level cut.\nFurthermore, the addition of He 10830 decreases the uncertainty on the helium\nabundance for all galaxies, with reductions in the uncertainty ranging from\n10-80%. Overall, we find a reduction in the uncertainty on Y_p by over 50%.\nFrom a regression to zero metallicity, we determine Y_p = 0.2449 +/- 0.0040,\nconsistent with the BBN result, Y_p = 0.2470 +/- 0.0002, based on the Planck\ndetermination of the baryon density. The dramatic improvement in the\nuncertainty from incorporating He 10830 strongly supports the case for\nsimultaneous (thus not requiring scaling) observations of visible and infrared\nhelium emission line spectra. \n\n"}
{"id": "1504.00308", "contents": "Title: Non-linear hydrodynamics of axion dark matter: relative velocity effects\n  and \"quantum forces\" Abstract: The non-linear hydrodynamic equations for axion/scalar field dark matter (DM)\nin the non-relativistic Madelung-Shcr\\\"{o}dinger form are derived in a simple\nmanner, including the effects of universal expansion and Hubble drag. The\nhydrodynamic equations are used to investigate the relative velocity between\naxion DM and baryons, and the moving-background perturbation theory (MBPT)\nderived. Axions massive enough to be all of the DM do not affect the coherence\nlength of the relative velocity, but the MBPT equations are modified by the\ninclusion of the axion effective sound speed. These MBPT equations are\nnecessary for accurately modelling the effects of axion DM on the formation of\nthe first cosmic structures, and suggest that the 21cm power spectrum could\nimprove constraints on axion mass by up to four orders of magnitude with\nrespect to the current best constraints. A further application of these results\nuses the \"quantum force\" analogy to model scalar field gradient energy in a\nsmoothed-particle hydrodynamics model of axion DM. Such a model can treat axion\nDM in the non-linear regime and could be incorporated into existing N-body\ncodes. \n\n"}
{"id": "1504.00683", "contents": "Title: Simple brane-world inflationary models: an update Abstract: In the light of the Planck 2015 results, we update simple inflationary models\nbased on the quadratic, quartic, Higgs and Coleman-Weinberg potentials in the\ncontext of the Randall-Sundrum brane-world cosmology. Brane-world cosmological\neffect alters the inflationary predictions of the spectral index ($n_s$) and\nthe tensor-to-scalar ratio ($r$) from those obtained in the standard cosmology.\nIn particular, the tensor-to-scalar ratio is enhanced in the presence of the\n5th dimension. In order to maintain the consistency with the Planck 2015\nresults for the inflationary predictions in the standard cosmology, we find a\nlower bound on the five-dimensional Planck mass ($M_5$). On the other hand, the\ninflationary predictions laying outside of the Planck allowed region can be\npushed into the allowed region by the brane-world cosmological effect with a\nsuitable choice of $M_5$. \n\n"}
{"id": "1504.00782", "contents": "Title: A comparative study of four significance measures for periodicity\n  detection in astronomical surveys Abstract: We study the problem of periodicity detection in massive data sets of\nphotometric or radial velocity time series, as presented by ESA's Gaia mission.\nPeriodicity detection hinges on the estimation of the false alarm probability\n(FAP) of the extremum of the periodogram of the time series. We consider the\nproblem of its estimation with two main issues in mind. First, for a given\nnumber of observations and signal-to-noise ratio, the rate of correct\nperiodicity detections should be constant for all realized cadences of\nobservations regardless of the observational time patterns, in order to avoid\nsky biases that are difficult to assess. Second, the computational loads should\nbe kept feasible even for millions of time series. Using the Gaia case, we\ncompare the $F^M$ method (Paltani 2004, Schwarzenberg-Czerny 2012), the Baluev\nmethod (Baluev 2008) and the GEV method (S\\\"uveges 2014), as well as a method\nfor the direct estimation of a threshold. Three methods involve some unknown\nparameters, which are obtained by fitting a regression-type predictive model\nusing easily obtainable covariates derived from observational time series. We\nconclude that the GEV and the Baluev methods both provide good solutions to the\nissues posed by a large-scale processing. The first of these yields the best\nscientific quality at the price of some moderately costly pre-processing. When\nthis pre-processing is impossible for some reason (e.g. the computational costs\nare prohibitive or good regression models cannot be constructed), the Baluev\nmethod provides a computationally inexpensive alternative with slight biases in\nregions where time samplings exhibit strong aliases. \n\n"}
{"id": "1504.00866", "contents": "Title: Tunable compression of template banks for fast gravitational-wave\n  detection and localisation Abstract: One strategy for reducing the online computational cost of matched-filter\nsearches for gravitational waves is to introduce a compressed basis for the\nwaveform template bank in a grid-based search. In this paper, we propose and\ninvestigate several tunable compression schemes for a general template bank.\nThrough offline compression, such schemes are shown to yield faster detection\nand localisation of signals, along with moderately improved sensitivity and\naccuracy over coarsened banks at the same level of computational cost. This is\npotentially useful for any search involving template banks, and especially in\nthe analysis of data from future space-based detectors such as eLISA, for which\nonline grid searches are difficult due to the long-duration waveforms and large\nparameter spaces. \n\n"}
{"id": "1504.02158", "contents": "Title: All-sky, narrowband, gravitational-wave radiometry with folded data Abstract: Gravitational-wave radiometry is a powerful tool by which weak signals with\nunknown signal morphologies are recovered through a process of cross\ncorrelation. Radiometry has been used, e.g., to search for persistent signals\nfrom known neutron stars such as Scorpius X-1. In this paper, we demonstrate\nhow a more ambitious search--for persistent signals from unknown neutron\nstars--can be efficiently carried out using folded data, in which an entire\n~year-long observing run is represented as a single sidereal day. The all-sky,\nnarrowband radiometer search described here will provide a computationally\ntractable means to uncover gravitational-wave signals from unknown, nearby\nneutron stars in binary systems, which can have modulation depths of ~0.1-2 Hz.\nIt will simultaneously provide a sensitive search algorithm for other\npersistent, narrowband signals from unexpected sources. \n\n"}
{"id": "1504.03606", "contents": "Title: Milestones of general relativity: Hubble's law (1929) and the expansion\n  of the universe Abstract: Hubble's announcement of the magnitude-redshift relation \\cite{Hub29} brought\nabout a major change in our understanding of the Universe. After tracing the\npre-history of Hubble's work, and the hiatus in our understanding which his\nunderestimate of distances led to, this review focuses on the development and\nsuccess of our understanding of the expanding universe up to the present day,\nand the part which General Relativity plays in that success. \n\n"}
{"id": "1504.04999", "contents": "Title: Constraints on secret neutrino interactions after Planck Abstract: (Abridged) Neutrino interactions beyond the standard model may affect the\ncosmological evolution and can be constrained through observations. We consider\nthe possibility that neutrinos possess secret scalar or pseudoscalar\ninteractions mediated by the Nambu-Goldstone boson of a still unknown\nspontaneously broken global $U(1)$ symmetry, as in, e.g. , Majoron models. In\nsuch scenarios, neutrinos still decouple at $T\\simeq 1$ MeV, but become tightly\ncoupled again ('recouple') at later stages of the cosmological evolution. We\nuse available observations of CMB anisotropies, including Planck 2013 and the\njoint BICEP2/Planck 2015 data, to derive constraints on the quantity\n$\\gamma_{\\nu \\nu}^4$, parameterizing the neutrino collision rate due to\n(pseudo)scalar interactions. We consider both a minimal extension of the\nstandard $\\Lambda$CDM model, and scenarios with extra relativistic species or\nnon-vanishing tensors. We find a typical constraint $\\gamma_{\\nu \\nu}^4 <\n0.9\\times 10^{-27}$ (95% C.L.), implying an upper limit on the redshift\n$z_{rec}$ of neutrino recoupling $< 8500$. In the framework of Majoron models,\nthe upper limit on $\\gamma_{\\nu \\nu}$ roughly translates on a constraint $g <\n8.2\\times 10^{-7}$ on the Majoron-neutrino coupling constant $g$. In general,\nthe data show a weak ($\\sim 1\\sigma$) but intriguing preference for non-zero\nvalues of $\\gamma_{\\nu \\nu}^4$, with best fits in the range $\\gamma_{\\nu \\nu}^4\n= (0.15 - 0.35)\\times 10^{-27}$, depending on the particular dataset. This is\nmore evident when either observations from ACT and SPT are included, or the\npossibility of non-vanishing tensor modes is considered. In particular, for the\nminimal model $\\Lambda$CDM +$\\gamma_{\\nu \\nu}$ and including the Planck 2013,\nACT and SPT data, we report $\\gamma_{\\nu \\nu}^4=( 0.45^{+0.15}_{-0.38}\n)\\times10^{-27}$ ($200 < z_{rec} < 5700$) at 68% confidence level. \n\n"}
{"id": "1504.05083", "contents": "Title: Reconstruction of air-shower parameters for large-scale radio detectors\n  using the lateral distribution Abstract: We investigate features of the lateral distribution function (LDF) of the\nradio signal emitted by cosmic ray air-showers with primary energies $>\n0.1$~EeV and its connection to air-shower parameters such as energy and shower\nmaximum using CoREAS simulations made for the configuration of the Tunka-Rex\nantenna array. Taking into account all significant contributions to the total\nradio emission, such as by the geomagnetic effect, the charge excess, and the\natmospheric refraction we parameterize the radio LDF. This parameterization is\ntwo-dimensional and has several free parameters. The large number of free\nparameters is not suitable for experiments of sparse arrays operating at low\nSNR (signal-to-noise ratios). Thus, exploiting symmetries, we decrease the\nnumber of free parameters and reduce the LDF to a simple one-dimensional\nfunction. The remaining parameters can be fit with a small number of points,\ni.e. as few as the signal from three antennas above detection threshold.\nFinally, we present a method for the reconstruction of air-shower parameters,\nin particular, energy and $X_{\\mathrm{max}}$ (shower maximum), which can be\nreached with a theoretical accuracy of better than 15\\% and 30~g/cm$^2$,\nrespectively. \n\n"}
{"id": "1504.07250", "contents": "Title: Genetically modified halos: towards controlled experiments in\n  $\\Lambda$CDM galaxy formation Abstract: We propose a method to generate `genetically-modified' (GM) initial\nconditions for high-resolution simulations of galaxy formation in a\ncosmological context. Building on the Hoffman-Ribak algorithm, we start from a\nreference simulation with fully random initial conditions, then make controlled\nchanges to specific properties of a single halo (such as its mass and merger\nhistory). The algorithm demonstrably makes minimal changes to other properties\nof the halo and its environment, allowing us to isolate the impact of a given\nmodification. As a significant improvement over previous work, we are able to\ncalculate the abundance of the resulting objects relative to the reference\nsimulation. Our approach can be applied to a wide range of cosmic structures\nand epochs; here we study two problems as a proof-of-concept. First, we\ninvestigate the change in density profile and concentration as the collapse\ntime of three individual halos are varied at fixed final mass, showing good\nagreement with previous statistical studies using large simulation suites.\nSecond, we modify the $z=0$ mass of halos to show that our theoretical\nabundance calculations correctly recover the halo mass function. The results\ndemonstrate that the technique is robust, opening the way to controlled\nexperiments in galaxy formation using hydrodynamic zoom simulations. \n\n"}
{"id": "1504.08032", "contents": "Title: Evolutionary stellar population synthesis with MILES - II. Scaled-solar\n  and \\alpha-enhanced models Abstract: We present models that predict spectra of old- and intermediate-aged stellar\npopulations at 2.51\\AA\\ (FWHM) with varying [\\alpha/Fe] abundance. The models\nare based on the MILES library and on corrections from theoretical stellar\nspectra. The models employ recent [Mg/Fe] determinations for the MILES stars\nand BaSTI scaled-solar and \\alpha-enhanced isochrones. We compute models for a\nsuite of IMF shapes and slopes, covering a wide age/metallicity range. Using\nBaSTI, we also compute \"base models\" matching The Galactic abundance pattern.\nWe confirm that the \\alpha-enhanced models show a flux excess with respect to\nthe scaled-solar models blue-ward $\\sim$4500\\AA, which increases with age and\nmetallicity. We also confirm that both [MgFe] and [MgFe]' indices are\n[\\alpha/Fe]-insensitive. We show that the sensitivity of the higher order\nBalmer lines to [\\alpha/Fe] resides in their pseudo-continua, with narrower\nindex definitions yielding lower sensitivity. We confirm that the\n\\alpha-enhanced models yield bluer (redder) colours in the blue (red) spectral\nrange. To match optical colours of massive galaxies we require both\n\\alpha-enhancement and a bottom-heavy IMF. The comparison of Globular Cluster\nline-strengths with our predictions match the [Mg/Fe] determinations from their\nindividual stars. We obtain good fits to both full spectra and indices of\ngalaxies with varying [\\alpha/Fe]. Using thousands of SDSS galaxy spectra we\nobtain a linear relation between a proxy for the abundance, [Z$_{\\rm\nMg}$/Z$_{\\rm Fe}$]$_{\\rm SS(BaSTI)}$, using solely scaled-solar models and the\n[Mg/Fe] derived with models with varying abundance ([Mg/Fe]=0.59[Z$_{\\rm\nMg}$/Z$_{\\rm Fe}$]$_{\\rm SS(BaSTI)}$). Finally we provide a user-friendly,\nweb-based facility, which allows composite populations with varying IMF and\n[\\alpha/Fe] ( http://miles.iac.es ). \n\n"}
{"id": "1505.02307", "contents": "Title: Chromatic CCD effects on weak lensing measurements for LSST Abstract: Wavelength-dependent point spread functions (PSFs) violate an implicit\nassumption in current galaxy shape measurement algorithms that deconvolve the\nPSF measured from stars (which have stellar spectral energy distributions\n(SEDs)) from images of galaxies (which have galactic SEDs). Since the\nabsorption length of silicon depends on wavelength, CCDs are a potential source\nof PSF chromaticity. Here we develop two toy models to estimate the sensitivity\nof the cosmic shear survey from the Large Synoptic Survey Telescope to\nchromatic effects in CCDs. We then compare these toy models to simulated\nestimates of PSF chromaticity derived from the LSST photon simulator PhoSim. We\nfind that even though sensor contributions to PSF chromaticity are subdominant\nto atmospheric contributions, they can still significantly bias cosmic shear\nresults if left uncorrected, particularly in the redder filter bands and for\nobjects that are off-axis in the field of view. \n\n"}
{"id": "1505.02783", "contents": "Title: Accurate, Meshless Methods for Magneto-Hydrodynamics Abstract: Recently, we developed a pair of meshless finite-volume Lagrangian methods\nfor hydrodynamics: the 'meshless finite mass' (MFM) and 'meshless finite\nvolume' (MFV) methods. These capture advantages of both smoothed-particle\nhydrodynamics (SPH) and adaptive mesh-refinement (AMR) schemes. Here, we extend\nthese to include ideal magneto-hydrodynamics (MHD). The MHD equations are\nsecond-order consistent and conservative. We augment these with a\ndivergence-cleaning scheme, which maintains div*B~0 to high accuracy. We\nimplement these in the code GIZMO, together with a state-of-the-art\nimplementation of SPH MHD. In every one of a large suite of test problems, the\nnew methods are competitive with moving-mesh and AMR schemes using constrained\ntransport (CT) to ensure div*B=0. They are able to correctly capture the growth\nand structure of the magneto-rotational instability (MRI), MHD turbulence, and\nthe launching of magnetic jets, in some cases converging more rapidly than AMR\ncodes. Compared to SPH, the MFM/MFV methods exhibit proper convergence at fixed\nneighbor number, sharper shock capturing, and dramatically reduced noise, div*B\nerrors, and diffusion. Still, 'modern' SPH is able to handle most of our tests,\nat the cost of much larger kernels and 'by hand' adjustment of artificial\ndiffusion parameters. Compared to AMR, the new meshless methods exhibit\nenhanced 'grid noise' but reduced advection errors and numerical diffusion,\nvelocity-independent errors, and superior angular momentum conservation and\ncoupling to N-body gravity solvers. As a result they converge more slowly on\nsome problems (involving smooth, slowly-moving flows) but more rapidly on\nothers (involving advection or rotation). In all cases, divergence-control\nbeyond the popular Powell 8-wave approach is necessary, or else all methods we\nconsider will systematically converge to unphysical solutions. \n\n"}
{"id": "1505.03955", "contents": "Title: On the equation-of-motion versus in-in approach in cosmological\n  perturbation theory Abstract: In this paper, we study several issues in the linear equation-of-motion (EoM)\nand in-in approaches of computing the two-point correlation functions in\nmulti-field inflation. We prove the equivalence between this EoM approach and\nthe first-principle in-in formalism. We check this equivalence using several\nexplicit examples, including cases with scale-invariant corrections and\nscale-dependent features. Motivated by the explicit proof, we show that the\nusual procedures in these approaches can be extended and applied to some\ninteresting model categories beyond what has been studied in the literature so\nfar. These include the density perturbations with strong couplings and\ncorrelated multi-field initial states. \n\n"}
{"id": "1505.05885", "contents": "Title: Beam calibration of radio telescopes with drones Abstract: We present a multi-frequency far-field beam map for the 5m dish telescope at\nthe Bleien Observatory measured using a commercially available drone. We\ndescribe the hexacopter drone used in this experiment, the design of the flight\npattern, and the data analysis scheme. This is the first application of this\ncalibration method to a single dish radio telescope in the far-field. The high\nsignal-to-noise data allows us to characterise the beam pattern with high\naccuracy out to at least the 4th side-lobe. The resulting 2D beam pattern is\ncompared with that derived from a more traditional calibration approach using\nan astronomical calibration source. We discuss the advantages of this method\ncompared to other beam calibration methods. Our results show that this\ndrone-based technique is very promising for ongoing and future radio\nexperiments, where the knowledge of the beam pattern is key to obtaining\nhigh-accuracy cosmological and astronomical measurements. \n\n"}
{"id": "1505.06213", "contents": "Title: Monte Carlo Method for Calculating Oxygen Abundances and Their\n  Uncertainties from Strong-Line Flux Measurements Abstract: We present the open-source Python code pyMCZ that determines oxygen abundance\nand its distribution from strong emission lines in the standard metallicity\ncalibrators, based on the original IDL code of Kewley & Dopita (2002) with\nupdates from Kewley & Ellison (2008), and expanded to include more recently\ndeveloped calibrators. The standard strong-line diagnostics have been used to\nestimate the oxygen abundance in the interstellar medium through various\nemission line ratios in many areas of astrophysics, including galaxy evolution\nand supernova host galaxy studies. We introduce a Python implementation of\nthese methods that, through Monte Carlo sampling, better characterizes the\nstatistical oxygen abundance confidence region including the effect due to the\npropagation of observational uncertainties. These uncertainties are likely to\ndominate the error budget in the case of distant galaxies, hosts of cosmic\nexplosions. Given line flux measurements and their uncertainties, our code\nproduces synthetic distributions for the oxygen abundance in up to 15\nmetallicity calibrators simultaneously, as well as for E(B-V), and estimates\ntheir median values and their 68% confidence regions. We test our code on\nemission line measurements from a sample of nearby supernova host galaxies (z <\n0.15) and compare our metallicity results with those from previous methods. Our\nmetallicity estimates are consistent with previous methods but yield smaller\nstatistical uncertainties. Systematic uncertainties are not taken into account.\nWe offer visualization tools to assess the spread of the oxygen abundance in\nthe different calibrators, as well as the shape of the estimated oxygen\nabundance distribution in each calibrator, and develop robust metrics for\ndetermining the appropriate Monte Carlo sample size. The code is open access\nand open source and can be found at https://github.com/nyusngroup/pyMCZ\n(Abridged) \n\n"}
{"id": "1505.06741", "contents": "Title: A principal possibility for computer investigation of evolution of\n  dynamical systems with independent on time accuracy Abstract: Extensive N-body simulations are among the key means for the study of\nnumerous astrophysical and cosmological phenomena, so various schemes are\ndeveloped for possibly higher accuracy computations. We demonstrate the\nprincipal possibility for revealing the evolution of a perturbed Hamiltonian\nsystem with an accuracy independent on time. The method is based on the Laplace\ntransform and the derivation and analytical solution of an evolution equation\nin the phase space for the resolvent and using computer algebra. \n\n"}
{"id": "1505.06903", "contents": "Title: Scalar field deformations of Lambda-CDM cosmology Abstract: This paper treats nonrelativistic matter and a scalar field $\\phi$ with a\nmonotonically decreasing potential minimally coupled to gravity in flat\nFriedmann-Lema\\^{i}tre-Robertson-Walker cosmology. The field equations are\nreformulated as a three-dimensional dynamical system on an extended compact\nstate space, complemented with cosmographic diagrams. A dynamical systems\nanalysis provides global dynamical results describing possible asymptotic\nbehavior. It is shown that one should impose \\emph{global and asymptotic}\nbounds on $\\lambda=-V^{-1}\\,dV/d\\phi$ to obtain viable cosmological models that\ncontinuously deform $\\Lambda$CDM cosmology. In particular we introduce a\nregularized inverse power-law potential as a simple specific example. \n\n"}
{"id": "1505.08022", "contents": "Title: Planck 2015 results. V. LFI calibration Abstract: We present a description of the pipeline used to calibrate the Planck Low\nFrequency Instrument (LFI) timelines into thermodynamic temperatures for the\nPlanck 2015 data release, covering four years of uninterrupted operations. As\nin the 2013 data release, our calibrator is provided by the spin-synchronous\nmodulation of the cosmic microwave background dipole, but we now use the\norbital component, rather than adopting the Wilkinson Microwave Anisotropy\nProbe (WMAP) solar dipole. This allows our 2015 LFI analysis to provide an\nindependent Solar dipole estimate, which is in excellent agreement with that of\nHFI and within $1\\sigma$ (0.3% in amplitude) of the WMAP value. This 0.3% shift\nin the peak-to-peak dipole temperature from WMAP and a global overhaul of the\niterative calibration code increases the overall level of the LFI maps by 0.45%\n(30 GHz), 0.64% (44 GHz), and 0.82% (70 GHz) in temperature with respect to the\n2013 Planck data release, thus reducing the discrepancy with the power spectrum\nmeasured by WMAP. We estimate that the LFI calibration uncertainty is now at\nthe level of 0.20% for the 70 GHz map, 0.26% for the 44 GHz map, and 0.35% for\nthe 30 GHz map. We provide a detailed description of the impact of all the\nchanges implemented in the calibration since the previous data release. \n\n"}
{"id": "1505.08122", "contents": "Title: The Spitzer c2d Survey of Large, Nearby, Interstellar Clouds. XII. The\n  Perseus YSO Population as Observed with IRAC and MIPS Abstract: The Spitzer Space Telescope mapped the Perseus molecular cloud complex with\nIRAC and MIPS as part of the c2d Spitzer Legacy project. This paper combines\nthe observations from both instruments giving an overview of low-mass star\nformation across Perseus from 3.6 to 70 micron. We provide an updated list of\nyoung stellar objects with new classifications and source fluxes from previous\nworks, identifying 369 YSOs in Perseus with the Spitzer dataset. By\nsynthesizing the IRAC and MIPS maps of Perseus and building on the work of\nprevious papers in this series (Jorgensen et al. 2006, Rebull et al. 2007), we\npresent a current census of star formation across the cloud and within smaller\nregions. 67% of the YSOs are associated with the young clusters NGC 1333 and IC\n348. The majority of the star formation activity in Perseus occurs in the\nregions around the clusters, to the eastern and western ends of the cloud\ncomplex. The middle of the cloud is nearly empty of YSOs despite containing\nregions of high visual extinction. The western half of Perseus contains\nthree-quarters of the total number of embedded YSOs (Class 0+I and Flat SED\nsources) in the cloud and nearly as many embedded YSOs as Class II and III\nsources. Class II and III greatly outnumber Class 0+I objects in eastern\nPerseus and IC 348. These results are consistent with previous age estimates\nfor the clusters. Across the cloud, 56% of YSOs and 91% of the Class 0+I and\nFlat sources are in areas where Av > 5 mag, indicating a possible extinction\nthreshold for star formation. \n\n"}
{"id": "1506.01011", "contents": "Title: Scale-invariant perturbations in ekpyrotic cosmologies without\n  fine-tuning of initial conditions Abstract: Ekpyrotic bouncing cosmologies have been proposed as alternatives to\ninflation. In these scenarios, the universe is smoothed and flattened during a\nperiod of slow contraction preceding the bounce while quantum fluctuations\ngenerate nearly scale-invariant super-horizon perturbations that seed structure\nin the post-bounce universe. An analysis by Tolley and Wesley (2007) showed\nthat, for a wide range of ekpyrotic models, generating a scale-invariant\nspectrum of adiabatic or entropic fluctuations is only possible if the\ncosmological background is unstable, in which case the scenario is highly\nsensitive to initial conditions. In this paper, we analyze an important\ncounterexample: a simple action that generates a Gaussian, scale-invariant\nspectrum of entropic perturbations during ekpyrotic contraction without\nrequiring fine-tuned initial conditions. Based on this example, we discuss some\ngeneralizations. \n\n"}
{"id": "1506.03618", "contents": "Title: Diagnostic of $f(R)$ under the $Om(z)$ function Abstract: We perform the two$-$point diagnostic for the $Om(z)$ function proposed by\nSahni ${\\it et al}$ in 2014 for the Starobinsky and Hu & Sawicki models in\n$f(R)$ gravity. We show that the observed values of the $Omh^2$ function can be\nexplained in $f(R)$ models while in LCDM the $Omh^2$ funticon is expected to be\na redshift independent number. We perform the analysis for some particular\nvalues of $\\Omega_m^0$ founding a cumulative probability ($P(\\chi^2 \\leq\n\\chi^2_{{\\it model}})$) $P \\sim 0.16$ or $\\sim0.09$ for the better cases versus\na cumulative probability of $P \\sim 0.98$ in the $\\Lambda$CDM scenario. We also\nshow that these models present a characteristic signature around the interval\nbetween $z\\sim 2$ and $z\\sim 4$, that could be confronted with future\nobservations using the same test. \n\n"}
{"id": "1506.04273", "contents": "Title: Optimized Large-Scale CMB Likelihood And Quadratic Maximum Likelihood\n  Power Spectrum Estimation Abstract: We revisit the problem of exact CMB likelihood and power spectrum estimation\nwith the goal of minimizing computational cost through linear compression. This\nidea was originally proposed for CMB purposes by Tegmark et al.\\ (1997), and\nhere we develop it into a fully working computational framework for large-scale\npolarization analysis, adopting \\WMAP\\ as a worked example. We compare five\ndifferent linear bases (pixel space, harmonic space, noise covariance\neigenvectors, signal-to-noise covariance eigenvectors and signal-plus-noise\ncovariance eigenvectors) in terms of compression efficiency, and find that the\ncomputationally most efficient basis is the signal-to-noise eigenvector basis,\nwhich is closely related to the Karhunen-Loeve and Principal Component\ntransforms, in agreement with previous suggestions. For this basis, the\ninformation in 6836 unmasked \\WMAP\\ sky map pixels can be compressed into a\nsmaller set of 3102 modes, with a maximum error increase of any single\nmultipole of 3.8\\% at $\\ell\\le32$, and a maximum shift in the mean values of a\njoint distribution of an amplitude--tilt model of 0.006$\\sigma$. This\ncompression reduces the computational cost of a single likelihood evaluation by\na factor of 5, from 38 to 7.5 CPU seconds, and it also results in a more robust\nlikelihood by implicitly regularizing nearly degenerate modes. Finally, we use\nthe same compression framework to formulate a numerically stable and\ncomputationally efficient variation of the Quadratic Maximum Likelihood\nimplementation that requires less than 3 GB of memory and 2 CPU minutes per\niteration for $\\ell \\le 32$, rendering low-$\\ell$ QML CMB power spectrum\nanalysis fully tractable on a standard laptop. \n\n"}
{"id": "1506.06135", "contents": "Title: Evidence of Halo Assembly Bias in Massive Clusters Abstract: We present significant evidence of halo assembly bias for SDSS redMaPPer\ngalaxy clusters in the redshift range $[0.1, 0.33]$. By dividing the 8,648\nclusters into two subsamples based on the average member galaxy separation from\nthe cluster center, we first show that the two subsamples have very similar\nhalo mass of $M_{\\rm 200m}\\simeq 1.9\\times 10^{14}~h^{-1}M_\\odot$ based on the\nweak lensing signals at small radii $R<\\sim 10~h^{-1}{\\rm Mpc}$. However, their\nhalo bias inferred from both the large-scale weak lensing and the projected\nauto-correlation functions differs by a factor of $\\sim$1.5, which is a\nsignature of assembly bias. The same bias hypothesis for the two subsamples is\nexcluded at 2.5$\\sigma$ in the weak lensing and 4.4$\\sigma$ in the\nauto-correlation data, respectively. This result could bring a significant\nimpact on both galaxy evolution and precision cosmology. \n\n"}
{"id": "1506.07170", "contents": "Title: Near-Infrared Polarimetric Adaptive Optics Observations of NGC 1068: A\n  torus created by a hydromagnetic outflow wind Abstract: We present J' and K' imaging linear polarimetric adaptive optics observations\nof NGC 1068 using MMT-Pol on the 6.5-m MMT. These observations allow us to\nstudy the torus from a magnetohydrodynamical (MHD) framework. In a 0.5\" (30 pc)\naperture at K', we find that polarisation arising from the passage of radiation\nfrom the inner edge of the torus through magnetically aligned dust grains in\nthe clumps is the dominant polarisation mechanism, with an intrinsic\npolarisation of 7.0%$\\pm$2.2%. This result yields a torus magnetic field\nstrength in the range of 4$-$82 mG through paramagnetic alignment, and\n139$^{+11}_{-20}$ mG through the Chandrasekhar-Fermi method. The measured\nposition angle (P.A.) of polarisation at K$'$ is found to be similar to the\nP.A. of the obscuring dusty component at few parsec scales using infrared\ninterferometric techniques. We show that the constant component of the magnetic\nfield is responsible for the alignment of the dust grains, and aligned with the\ntorus axis onto the plane of the sky. Adopting this magnetic field\nconfiguration and the physical conditions of the clumps in the MHD outflow wind\nmodel, we estimate a mass outflow rate $\\le$0.17 M$_{\\odot}$ yr$^{-1}$ at 0.4\npc from the central engine for those clumps showing near-infrared dichroism.\nThe models used were able to create the torus in a timescale of $\\geq$10$^{5}$\nyr with a rotational velocity of $\\leq$1228 km s$^{-1}$ at 0.4 pc. We conclude\nthat the evolution, morphology and kinematics of the torus in NGC 1068 can be\nexplained within a MHD framework. \n\n"}
{"id": "1506.07524", "contents": "Title: COSMOGRAIL: the COSmological MOnitoring of GRAvItational Lenses XV.\n  Assessing the achievability and precision of time-delay measurements Abstract: COSMOGRAIL is a long-term photometric monitoring of gravitationally lensed\nQSOs aimed at implementing Refsdal's time-delay method to measure cosmological\nparameters, in particular H0. Given long and well sampled light curves of\nstrongly lensed QSOs, time-delay measurements require numerical techniques\nwhose quality must be assessed. To this end, and also in view of future\nmonitoring programs or surveys such as the LSST, a blind signal processing\ncompetition named Time Delay Challenge 1 (TDC1) was held in 2014. The aim of\nthe present paper, which is based on the simulated light curves from the TDC1,\nis double. First, we test the performance of the time-delay measurement\ntechniques currently used in COSMOGRAIL. Second, we analyse the quantity and\nquality of the harvest of time delays obtained from the TDC1 simulations. To\nachieve these goals, we first discover time delays through a careful inspection\nof the light curves via a dedicated visual interface. Our measurement\nalgorithms can then be applied to the data in an automated way. We show that\nour techniques have no significant biases, and yield adequate uncertainty\nestimates resulting in reduced chi2 values between 0.5 and 1.0. We provide\nestimates for the number and precision of time-delay measurements that can be\nexpected from future time-delay monitoring campaigns as a function of the\nphotometric signal-to-noise ratio and of the true time delay. We make our blind\nmeasurements on the TDC1 data publicly available \n\n"}
{"id": "1506.07982", "contents": "Title: Mastering the effects of peculiar velocities in cosmic voids Abstract: How do peculiar velocities affect observed voids? To answer this question we\nuse the VIDE toolkit to identify voids in mock galaxy populations embedded\nwithin an N-body simulation both with and without peculiar velocities included.\nWe compare the resulting void populations to assess the impact on void\nproperties. We find that void abundances and spherically-averaged radial\ndensity profiles are mildly affected by peculiar velocities. However, peculiar\nvelocities can distort by up to 10% the shapes for a particular subset of voids\ndepending on the void size and density contrast, which can lead to increased\nvariance in Alcock-Paczy\\'nski test. We offer guidelines for performing optimal\ncuts on the void catalogue to reduce this variance by removing the most\nseverely affected voids while preserving the unaffected ones. In addition,\nsince this shape distortion is largely limited to the line of sight, we show\nthat the void radii are only affected at the $\\sim$ 10% level and the\nmacrocenter positions at the $\\sim$ 20% (even before performing cuts), meaning\nthat cosmological probes based on the Integrated Sachs-Wolfe and gravitational\nlensing are not severely impacted by peculiar velocities. \n\n"}
{"id": "1507.01589", "contents": "Title: Teaching a machine to see: unsupervised image segmentation and\n  categorisation using growing neural gas and hierarchical clustering Abstract: We present a novel unsupervised learning approach to automatically segment\nand label images in astronomical surveys. Automation of this procedure will be\nessential as next-generation surveys enter the petabyte scale: data volumes\nwill exceed the capability of even large crowd-sourced analyses. We demonstrate\nhow a growing neural gas (GNG) can be used to encode the feature space of\nimaging data. When coupled with a technique called hierarchical clustering,\nimaging data can be automatically segmented and labelled by organising nodes in\nthe GNG. The key distinction of unsupervised learning is that these labels need\nnot be known prior to training, rather they are determined by the algorithm\nitself. Importantly, after training a network can be be presented with images\nit has never 'seen' before and provide consistent categorisation of features.\nAs a proof-of-concept we demonstrate application on data from the Hubble Space\nTelescope Frontier Fields: images of clusters of galaxies containing a mixture\nof galaxy types that would easily be recognised and classified by a human\ninspector. By training the algorithm using one field (Abell 2744) and applying\nthe result to another (MACS0416.1-2403), we show how the algorithm can cleanly\nseparate image features that a human would associate with early and late type\ngalaxies. We suggest that the algorithm has potential as a tool in the\nautomatic analysis and data mining of next-generation imaging and spectral\nsurveys, and could also find application beyond astronomy. \n\n"}
{"id": "1507.04742", "contents": "Title: Conflation: a new type of accelerated expansion Abstract: In the framework of scalar-tensor theories of gravity, we construct a new\nkind of cosmological model that conflates inflation and ekpyrosis. During a\nphase of conflation, the universe undergoes accelerated expansion, but with\ncrucial differences compared to ordinary inflation. In particular, the\npotential energy is negative, which is of interest for supergravity and string\ntheory where both negative potentials and the required scalar-tensor couplings\nare rather natural. A distinguishing feature of the model is that, for a large\nparameter range, it does not significantly amplify adiabatic scalar and tensor\nfluctuations, and in particular does not lead to eternal inflation and the\nassociated infinities. We also show how density fluctuations in accord with\ncurrent observations may be generated by adding a second scalar field to the\nmodel. Conflation may be viewed as complementary to the recently proposed\nanamorphic universe of Ijjas and Steinhardt. \n\n"}
{"id": "1507.05536", "contents": "Title: Gamma-rays from Heavy Minimal Dark Matter Abstract: We consider the annihilation into gamma rays of Minimal Dark Matter\ncandidates in the fermionic 5-plet and scalar 7-plet representations of\n$SU(2)_L$, taking into account both the Sommerfeld effect and the internal\nbremsstrahlung. Assuming the Einasto profile, we show that present measurements\nof the Galactic Center by the H.E.S.S. instrument exclude the 5-plet and 7-plet\nas the dominant form of dark matter for masses between 1 TeV and 20 TeV, in\nparticular, the 5-plet mass leading to the observed dark matter density via\nthermal freeze-out. We also discuss prospects for the upcoming Cherenkov\nTelescope Array, which will be able to probe even heavier dark matter masses,\nincluding the scenario where the scalar 7-plet is thermally produced. \n\n"}
{"id": "1507.06639", "contents": "Title: SKA Engineering Change Proposal: Gridded Visibilities to Enable\n  Precision Cosmology with Radio Weak Lensing Abstract: This document was submitted as supporting material to an Engineering Change\nProposal (ECP) for the Square Kilometre Array (SKA). This ECP requests gridded\nvisibilities as an extra imaging data product from the SKA, in order to enable\nbespoke analysis techniques to measure source morphologies to the accuracy\nnecessary for precision cosmology with radio weak lensing. We also discuss the\nproperties of an SKA weak lensing data set and potential overlaps with other\ncosmology science goals. \n\n"}
{"id": "1507.07769", "contents": "Title: Radio detection of cosmic rays: present and future Abstract: Digital radio detection of cosmic rays has made tremendous progress over the\npast decade. It has become increasingly clear where the potential --- but also\nthe limitations --- of the technique lie. In this article, we discuss roads\nthat could be followed in future radio detection efforts and try to evaluate\nthe associated prospects and challenges. \n\n"}
{"id": "1508.00990", "contents": "Title: New readout and data-acquisition system in an electron-tracking Compton\n  camera for MeV gamma-ray astronomy (SMILE-II) Abstract: For MeV gamma-ray astronomy, we have developed an electron-tracking Compton\ncamera (ETCC) as a MeV gamma-ray telescope capable of rejecting the radiation\nbackground and attaining the high sensitivity of near 1 mCrab in space. Our\nETCC comprises a gaseous time-projection chamber (TPC) with a micro pattern gas\ndetector for tracking recoil electrons and a position-sensitive scintillation\ncamera for detecting scattered gamma rays. After the success of a first balloon\nexperiment in 2006 with a small ETCC (using a 10$\\times$10$\\times$15 cm$^3$\nTPC) for measuring diffuse cosmic and atmospheric sub-MeV gamma rays (Sub-MeV\ngamma-ray Imaging Loaded-on-balloon Experiment I; SMILE-I), a (30 cm)$^{3}$\nmedium-sized ETCC was developed to measure MeV gamma-ray spectra from celestial\nsources, such as the Crab Nebula, with single-day balloon flights (SMILE-II).\nTo achieve this goal, a 100-times-larger detection area compared with that of\nSMILE-I is required without changing the weight or power consumption of the\ndetector system. In addition, the event rate is also expected to dramatically\nincrease during observation. Here, we describe both the concept and the\nperformance of the new data-acquisition system with this (30 cm)$^{3}$ ETCC to\nmanage 100 times more data while satisfying the severe restrictions regarding\nthe weight and power consumption imposed by a balloon-borne observation. In\nparticular, to improve the detection efficiency of the fine tracks in the TPC\nfrom $\\sim$10\\% to $\\sim$100\\%, we introduce a new data-handling algorithm in\nthe TPC. Therefore, for efficient management of such large amounts of data, we\ndeveloped a data-acquisition system with parallel data flow. \n\n"}
{"id": "1508.01187", "contents": "Title: (Quasi-)collisional Magneto-optic Effects in Collisionless Plasmas with\n  sub-Larmor-scale Electromagnetic Fluctuations Abstract: High-amplitude, chaotic/turbulent electromagnetic fluctuations are ubiquitous\nin high-energy-density laboratory and astrophysical plasmas, where they can be\nexcited by various kinetic-streaming and/or anisotropy-driven instabilities,\nsuch as the Weibel instability. These fields typically exist on \"sub-Larmor\nscales\" -- scales smaller than the electron Larmor radius. Electrons moving\nthrough such magnetic fields undergo small-angle stochastic deflections of\ntheir pitch-angles, thus establishing diffusive transport on long time-scales.\nWe show that this behavior, under certain conditions, is equivalent to Coulomb\ncollisions in collisional plasmas. The magnetic pitch-angle diffusion\ncoefficient, which acts as an effective \"collision\" frequency, may be\nsubstantial in these, otherwise, collisionless environments. We show that this\neffect, colloquially referred to as the plasma \"quasicollisionality\", may\nradically alter the expected radiative transport properties of candidate\nplasmas. We argue that the modified magneto-optic effects in these plasmas\nprovide an attractive, novel radiative diagnostic tool for the exploration and\ncharacterization of small-scale magnetic turbulence, as well as affect inertial\nconfinement fusion and other laser-plasma experiments. \n\n"}
{"id": "1508.02120", "contents": "Title: A family of lowered isothermal models Abstract: We present a family of self-consistent, spherical, lowered isothermal models,\nconsisting of one or more mass components, with parameterised prescriptions for\nthe energy truncation and for the amount of radially biased pressure\nanisotropy. The models are particularly suited to describe the phase-space\ndensity of stars in tidally limited, mass-segregated star clusters in all\nstages of their life-cycle. The models extend a family of isotropic,\nsingle-mass models by Gomez-Leyton and Velazquez, of which the well-known\nWoolley, King and Wilson (in the non-rotating and isotropic limit) models are\nmembers. We derive analytic expressions for the density and velocity dispersion\ncomponents in terms of potential and radius, and introduce a fast model solver\nin PYTHON (LIMEPY), that can be used for data fitting or for generating\ndiscrete samples. \n\n"}
{"id": "1508.05655", "contents": "Title: An accurate and practical method for inference of weak gravitational\n  lensing from galaxy images Abstract: We demonstrate highly accurate recovery of weak gravitational lensing shear\nusing an implementation of the Bayesian Fourier Domain (BFD) method proposed by\nBernstein & Armstrong (2014, BA14), extended to correct for selection biases.\nThe BFD formalism is rigorously correct for Nyquist-sampled,\nbackground-limited, uncrowded image of background galaxies. BFD does not assign\nshapes to galaxies, instead compressing the pixel data D into a vector of\nmoments M, such that we have an analytic expression for the probability P(M|g)\nof obtaining the observations with gravitational lensing distortion g along the\nline of sight. We implement an algorithm for conducting BFD's integrations over\nthe population of unlensed source galaxies which measures ~10\ngalaxies/second/core with good scaling properties. Initial tests of this code\non ~10^9 simulated lensed galaxy images recover the simulated shear to a\nfractional accuracy of m=0.0021+-0.0004, substantially more accurate than has\nbeen demonstrated previously for any generally applicable method. Deep sky\nexposures generate a sufficiently accurate approximation to the noiseless,\nunlensed galaxy population distribution assumed as input to BFD. Potential\nextensions of the method include simultaneous measurement of magnification and\nshear; multiple-exposure, multi-band observations; and joint inference of\nphotometric redshifts and lensing tomography. \n\n"}
{"id": "1508.06635", "contents": "Title: Dark Matter and Global Symmetries Abstract: General considerations in general relativity and quantum mechanics are known\nto potentially rule out continuous global symmetries in the context of any\nconsistent theory of quantum gravity. Assuming the validity of such\nconsiderations, we derive stringent bounds from gamma-ray, X-ray, cosmic-ray,\nneutrino, and CMB data on models that invoke global symmetries to stabilize the\ndark matter particle. We compute up-to-date, robust model-independent limits on\nthe dark matter lifetime for a variety of Planck-scale suppressed\ndimension-five effective operators. We then specialize our analysis and apply\nour bounds to specific models including the Two-Higgs-Doublet, Left-Right,\nSinglet Fermionic, Zee-Babu, 3-3-1 and Radiative See-Saw models. {Assuming that\n(i) global symmetries are broken at the Planck scale, that (ii) the\nnon-renormalizable operators mediating dark matter decay have $O(1)$ couplings,\nthat (iii) the dark matter is a singlet field, and that (iv) the dark matter\ndensity distribution is well described by a NFW profile}, we are able to rule\nout fermionic, vector, and scalar dark matter candidates across a broad mass\nrange (keV-TeV), including the WIMP regime. \n\n"}
{"id": "1509.03931", "contents": "Title: The ASKAP/EMU Source Finding Data Challenge Abstract: The Evolutionary Map of the Universe (EMU) is a proposed radio continuum\nsurvey of the Southern Hemisphere up to declination +30 deg., with the\nAustralian Square Kilometre Array Pathfinder (ASKAP). EMU will use an automated\nsource identification and measurement approach that is demonstrably optimal, to\nmaximise the reliability, utility and robustness of the resulting radio source\ncatalogues. As part of the process of achieving this aim, a \"Data Challenge\"\nhas been conducted, providing international teams the opportunity to test a\nvariety of source finders on a set of simulated images. The aim is to quantify\nthe accuracy of existing automated source finding and measurement approaches,\nand to identify potential limitations. The Challenge attracted nine independent\nteams, who tested eleven different source finding tools. In addition, the\nChallenge initiators also tested the current ASKAPsoft source-finding tool to\nestablish how it could benefit from incorporating successful features of the\nother tools. Here we present the results of the Data Challenge, identifying the\nsuccesses and limitations for this broad variety of the current generation of\nradio source finding tools. As expected, most finders demonstrate completeness\nlevels close to 100% at 10sigma dropping to levels around 10% by 5sigma. The\nreliability is typically close to 100% at 10sigma, with performance to lower\nsensitivities varying greatly between finders. All finders demonstrate the\nusual trade-off between completeness and reliability, whereby maintaining a\nhigh completeness at low signal-to-noise comes at the expense of reduced\nreliability, and vice-versa. We conclude with a series of recommendations for\nimproving the performance of the ASKAPsoft source-finding tool. \n\n"}
{"id": "1509.04034", "contents": "Title: Bayesian Inference for Radio Observations - Going beyond deconvolution Abstract: Radio interferometers suffer from the problem of missing information in their\ndata, due to the gaps between the antennas. This results in artifacts, such as\nbright rings around sources, in the images obtained. Multiple deconvolution\nalgorithms have been proposed to solve this problem and produce cleaner radio\nimages. However, these algorithms are unable to correctly estimate\nuncertainties in derived scientific parameters or to always include the effects\nof instrumental errors. We propose an alternative technique called Bayesian\nInference for Radio Observations (BIRO) which uses a Bayesian statistical\nframework to determine the scientific parameters and instrumental errors\nsimultaneously directly from the raw data, without making an image. We use a\nsimple simulation of Westerbork Synthesis Radio Telescope data including\npointing errors and beam parameters as instrumental effects, to demonstrate the\nuse of BIRO. \n\n"}
{"id": "1509.04628", "contents": "Title: Recovery of Large Angular Scale CMB Polarization for Instruments\n  Employing Variable-delay Polarization Modulators Abstract: Variable-delay Polarization Modulators (VPMs) are currently being implemented\nin experiments designed to measure the polarization of the cosmic microwave\nbackground on large angular scales because of their capability for providing\nrapid, front-end polarization modulation and control over systematic errors.\nDespite the advantages provided by the VPM, it is important to identify and\nmitigate any time-varying effects that leak into the synchronously modulated\ncomponent of the signal. In this paper, the effect of emission from a $300$ K\nVPM on the system performance is considered and addressed. Though instrument\ndesign can greatly reduce the influence of modulated VPM emission, some\nresidual modulated signal is expected. VPM emission is treated in the presence\nof rotational misalignments and temperature variation. Simulations of\ntime-ordered data are used to evaluate the effect of these residual errors on\nthe power spectrum. The analysis and modeling in this paper guides\nexperimentalists on the critical aspects of observations using VPMs as\nfront-end modulators. By implementing the characterizations and controls as\ndescribed, front-end VPM modulation can be very powerful for mitigating $1/f$\nnoise in large angular scale polarimetric surveys. None of the systematic\nerrors studied fundamentally limit the detection and characterization of\nB-modes on large scales for a tensor-to-scalar ratio of $r=0.01$. Indeed,\n$r<0.01$ is achievable with commensurately improved characterizations and\ncontrols. \n\n"}
{"id": "1509.07137", "contents": "Title: Bayesian inference on the sphere beyond statistical isotropy Abstract: We present a general method for Bayesian inference of the underlying\ncovariance structure of random fields on a sphere. We employ the Bipolar\nSpherical Harmonic (BipoSH) representation of general covariance structure on\nthe sphere. We illustrate the efficacy of the method as a principled approach\nto assess violation of statistical isotropy (SI) in the sky maps of Cosmic\nMicrowave Background (CMB) fluctuations. SI violation in observed CMB maps\narise due to known physical effects such as Doppler boost and weak lensing; yet\nunknown theoretical possibilities like cosmic topology and subtle violations of\nthe cosmological principle, as well as, expected observational artefacts of\nscanning the sky with a non-circular beam, masking, foreground residuals,\nanisotropic noise, etc. We explicitly demonstrate the recovery of the input SI\nviolation signals with their full statistics in simulated CMB maps. Our\nformalism easily adapts to exploring parametric physical models with non-SI\ncovariance, as we illustrate for the inference of the parameters of a Doppler\nboosted sky map. Our approach promises to provide a robust quantitative\nevaluation of the evidence for SI violation related anomalies in the CMB sky by\nestimating the BipoSH spectra along with their complete posterior. \n\n"}
{"id": "1509.08181", "contents": "Title: Perfect fluids with $\\omega=\\mathrm{const}$ as sources of scalar\n  cosmological perturbations Abstract: We make a generalization of a self-consistent first-order perturbation\nscheme, being suitable for all (sub-horizon and super-horizon) scales, which\nhas been recently constructed for the concordance cosmological model and\ndiscrete presentation of matter sources, to the case of extended models with\nextra perfect fluids and continuous presentation. Namely, we derive a single\nequation determining the scalar perturbation and covering the whole space as\nwell as define the corresponding universal Yukawa interaction range. We also\ndemonstrate explicitly that the structure growth is suppressed at distances\nexceeding this fundamental range. \n\n"}
{"id": "1509.09221", "contents": "Title: Common-mode rejection in Martin-Puplett spectrometers for astronomical\n  observations at mm-wavelengths Abstract: The Martin-Puplett interferometer (MPI) is a differential Fourier transform\nspectrometer (FTS), measuring the difference between spectral brightness at two\ninput ports. This unique feature makes the MPI an optimal zero instrument, able\nto detect small brightness gradients embeddend in a large common background. In\nthis paper we investigate experimentally the common-mode rejection achievable\nin the MPI at mm wavelengths, and discuss the use of the instrument to measure\nthe spectrum of cosmic microwave background (CMB) anisotropy. \n\n"}
{"id": "1510.01692", "contents": "Title: What determines large scale galaxy clustering: halo mass or local\n  density? Abstract: Using dark matter simulations we show how halo bias is determined by local\ndensity and not by halo mass. This is not totally surprising, as according to\nthe peak-background split model, local density is the property that constraints\nbias at large scales. Massive haloes have a high clustering because they reside\nin high density regions. Small haloes can be found in a wide range of\nenvironments which determine their clustering amplitudes differently. This\ncontradicts the assumption of standard Halo Occupation Distribution (HOD)\nmodels that the bias and occupation of haloes is determined solely by their\nmass. We show that the bias of central galaxies from semi-analytic models of\ngalaxy formation as a function of luminosity and colour is not correctly\npredicted by the standard HOD model. Using local density instead of halo mass\nthe HOD model correctly predicts galaxy bias. These results indicate the need\nto include information about local density and not only mass in order to\ncorrectly apply HOD analysis in these galaxy samples. This new model can be\nreadily applied to observations and has the advantage that the galaxy density\ncan be directly observed, in contrast with the dark matter halo mass. \n\n"}
{"id": "1510.01843", "contents": "Title: Meridional circulation in the solar convection zone: time-distance\n  helioseismic inferences from four years of HMI/SDO observations Abstract: We present and discuss results from time-distance helioseismic measurements\nof meridional circulation in the solar convection zone using 4 years of Doppler\nvelocity observations by the Helioseismic and Magnetic Imager (HMI) onboard the\nSolar Dynamics Observatory (SDO). Using an in-built mass conservation\nconstraint in terms of the stream function we invert helioseismic travel times\nto infer meridional circulation in the solar convection zone. We find that the\nreturn flow that closes the meridional circulation is possibly beneath the\ndepth of $0.77 R_{\\odot}$. We discuss the significance of this result in\nrelation to other helioseismic inferences published recently and possible\nreasons for the differences in the results. Our results show clearly the\npitfalls involved in the measurements of material flows in the deep solar\ninterior given the current limits on signal-to-noise and our limited\nunderstanding of systematics in the data. We also discuss the implications of\nour results for the dynamics of solar interior and popular solar dynamo models. \n\n"}
{"id": "1510.02005", "contents": "Title: A no-go theorem for monodromy inflation Abstract: We study the embedding of the monodromy inflation mechanism by E. Silverstein\nand A. Westphal (2008) in a concrete compactification setting. To that end, we\nlook for an appropriate vacuum of type IIA supergravity, corresponding to the\nminimum of the inflaton potential. We prove a no-go theorem on the existence of\nsuch a vacuum, using ten-dimensional equations of motion. Anti-de Sitter and\nMinkowski vacua are ruled out; de Sitter vacua are not excluded, but have a\nlower bound on their cosmological constant which is too high for phenomenology. \n\n"}
{"id": "1510.02809", "contents": "Title: Advanced ACTPol Cryogenic Detector Arrays and Readout Abstract: Advanced ACTPol is a polarization-sensitive upgrade for the 6 m aperture\nAtacama Cosmology Telescope (ACT), adding new frequencies and increasing\nsensitivity over the previous ACTPol receiver. In 2016, Advanced ACTPol will\nbegin to map approximately half the sky in five frequency bands (28-230 GHz).\nIts maps of primary and secondary cosmic microwave background (CMB)\nanisotropies -- imaged in intensity and polarization at few arcminute-scale\nresolution -- will enable precision cosmological constraints and also a wide\narray of cross-correlation science that probes the expansion history of the\nuniverse and the growth of structure via gravitational collapse. To accomplish\nthese scientific goals, the Advanced ACTPol receiver will be a significant\nupgrade to the ACTPol receiver, including four new multichroic arrays of\ncryogenic, feedhorn-coupled AlMn transition edge sensor (TES) polarimeters\n(fabricated on 150 mm diameter wafers); a system of continuously rotating\nmeta-material silicon half-wave plates; and a new multiplexing readout\narchitecture which uses superconducting quantum interference devices (SQUIDs)\nand time division to achieve a 64-row multiplexing factor. Here we present the\nstatus and scientific goals of the Advanced ACTPol instrument, emphasizing the\ndesign and implementation of the Advanced ACTPol cryogenic detector arrays. \n\n"}
{"id": "1510.04075", "contents": "Title: Matter bispectrum of large-scale structure: Three-dimensional comparison\n  between theoretical models and numerical simulations Abstract: We study the matter bispectrum of the large-scale structure by comparing\ndifferent perturbative and phenomenological models with measurements from\n$N$-body simulations obtained with a modal bispectrum estimator. Using shape\nand amplitude correlators, we directly compare simulated data with theoretical\nmodels over the full three-dimensional domain of the bispectrum, for different\nredshifts and scales. We review and investigate the main perturbative methods\nin the literature that predict the one-loop bispectrum: standard perturbation\ntheory, effective field theory, resummed Lagrangian and renormalised\nperturbation theory, calculating the latter also at two loops for some triangle\nconfigurations. We find that effective field theory (EFT) succeeds in extending\nthe range of validity furthest into the mildly nonlinear regime, albeit at the\nprice of free extra parameters requiring calibration on simulations. For the\nmore phenomenological halo model, we confirm that despite its validity in the\ndeeply nonlinear regime it has a deficit of power on intermediate scales, which\nworsens at higher redshifts; this issue is ameliorated, but not solved, by\ncombined halo-perturbative models. We show from simulations that in this\ntransition region there is a strong squeezed bispectrum component that is\nsignificantly underestimated in the halo model at earlier redshifts. We thus\npropose a phenomenological method for alleviating this deficit, which we\ndevelop into a simple phenomenological \"three-shape\" benchmark model based on\nthe three fundamental shapes we have obtained from studying the halo model.\nWhen calibrated on the simulations, this three-shape benchmark model accurately\ndescribes the bispectrum on all scales and redshifts considered, providing a\nprototype bispectrum HALOFIT-like methodology that could be used to describe\nand test parameter dependencies. \n\n"}
{"id": "1510.05161", "contents": "Title: Constraints on the neutrino parameters by future cosmological 21cm line\n  and precise CMB polarization observations (PhD thesis, The Graduate\n  University for Advanced Studies (SOKENDAI)) Abstract: Observations of the 21 cm line radiation coming from the epoch of\nreionization have a great capacity to study the cosmological growth of the\nUniverse. Also, CMB polarization produced by gravitational lensing has a large\namount of information about the growth of matter fluctuations at late time. In\nthis thesis, we investigate their sensitivities to the impact of neutrino\nproperty on the growth of density fluctuations, such as the total neutrino\nmass, the neutrino mass hierarchy, the effective number of neutrino species\n(extra radiation), and the lepton asymmetry of our Universe. We will show that\nby combining the precise CMB polarization observations with Square Kilometer\nArray (SKA) we can measure the impact of non-zero neutrino mass on the growth\nof density fluctuation, and determine the neutrino mass hierarchy at 2 sigma\nlevel if the total neutrino mass is smaller than 0.1 eV. Additionally, we will\nshow that by using these combinations we can constrain the lepton asymmetry\nbetter than big-bang nucleosynthesis (BBN). Besides we discuss constraints on\nthat in the presence of some extra radiation, and show that the 21 cm line\nobservations can substantially improve the constraints obtained by CMB alone,\nand allow us to distinguish the effects of the lepton asymmetry from those of\nextra radiation. \n\n"}
{"id": "1510.08514", "contents": "Title: Affleck-Dine leptogenesis and its backreaction to inflaton dynamics Abstract: We investigate the backreaction of the Affleck-Dine leptogenesis to inflaton\ndynamics in the F-term hybrid and chaotic inflation models in supergravity. We\ndetermine the lightest neutrino mass in both models so that the predictions of\nspectral index, tensor-to-scalar ratio, and baryon abundance are consistent\nwith observations. \n\n"}
{"id": "1510.09194", "contents": "Title: The noise properties of 42 millisecond pulsars from the European Pulsar\n  Timing Array and their impact on gravitational wave searches Abstract: The sensitivity of Pulsar Timing Arrays to gravitational waves depends on the\nnoise present in the individual pulsar timing data. Noise may be either\nintrinsic or extrinsic to the pulsar. Intrinsic sources of noise will include\nrotational instabilities, for example. Extrinsic sources of noise include\ncontributions from physical processes which are not sufficiently well modelled,\nfor example, dispersion and scattering effects, analysis errors and\ninstrumental instabilities. We present the results from a noise analysis for 42\nmillisecond pulsars (MSPs) observed with the European Pulsar Timing Array. For\ncharacterising the low-frequency, stochastic and achromatic noise component, or\n\"timing noise\", we employ two methods, based on Bayesian and frequentist\nstatistics. For 25 MSPs, we achieve statistically significant measurements of\ntheir timing noise parameters and find that the two methods give consistent\nresults. For the remaining 17 MSPs, we place upper limits on the timing noise\namplitude at the 95% confidence level. We additionally place an upper limit on\nthe contribution to the pulsar noise budget from errors in the reference\nterrestrial time standards (below 1%), and we find evidence for a noise\ncomponent which is present only in the data of one of the four used telescopes.\nFinally, we estimate that the timing noise of individual pulsars reduces the\nsensitivity of this data set to an isotropic, stochastic GW background by a\nfactor of >9.1 and by a factor of >2.3 for continuous GWs from resolvable,\ninspiralling supermassive black-hole binaries with circular orbits. \n\n"}
{"id": "1511.00704", "contents": "Title: Rapidly Rising Transients in the Supernova - Superluminous Supernova Gap Abstract: We present observations of four rapidly rising (t_{rise}~10d) transients with\npeak luminosities between those of supernovae (SNe) and superluminous SNe\n(M_{peak}~-20) - one discovered and followed by the Palomar Transient Factory\n(PTF) and three by the Supernova Legacy Survey (SNLS). The light curves\nresemble those of SN 2011kl, recently shown to be associated with an\nultra-long-duration gamma ray burst (GRB), though no GRB was seen to accompany\nour SNe. The rapid rise to a luminous peak places these events in a unique part\nof SN phase space, challenging standard SN emission mechanisms. Spectra of the\nPTF event formally classify it as a Type II SN due to broad Halpha emission,\nbut an unusual absorption feature, which can be interpreted as either high\nvelocity Halpha (though deeper than in previously known cases) or Si II (as\nseen in Type Ia SNe), is also observed. We find that existing models of white\ndwarf detonations, CSM interaction, shock breakout in a wind (or steeper CSM)\nand magnetar spindown can not readily explain the observations. We consider the\npossibility that a \"Type 1.5 SN\" scenario could be the origin of our events.\nMore detailed models for these kinds of transients and more constraining\nobservations of future such events should help better determine their nature. \n\n"}
{"id": "1511.01105", "contents": "Title: Departures from the FLRW Cosmological Model in an Inhomogeneous\n  Universe: A Numerical Examination Abstract: While the use of numerical general relativity for modeling astrophysical\nphenomena and compact objects is commonplace, the application to cosmological\nscenarios is only just beginning. Here, we examine the expansion of a spacetime\nusing the Baumgarte-Shapiro-Shibata-Nakamura (BSSN) formalism of numerical\nrelativity in synchronous gauge. This work represents the first numerical\ncosmological study that is fully relativistic, non-linear and without symmetry.\nThe universe that emerges exhibits an average\nFriedmann-Lema\\\"itre-Robertston-Walker (FLRW) behavior, however this universe\nalso exhibits locally inhomogeneous expansion beyond that expected in linear\nperturbation theory around a FLRW background. \n\n"}
{"id": "1511.01474", "contents": "Title: Primordial trispectra and CMB spectral distortions Abstract: We study the $TT\\mu$ bispectrum, generated by correlations between Cosmic\nMicrowave Background temperature (T) anisotropies and chemical potential\n($\\mu$) distortions, and we analyze its dependence on primordial local\ntrispectrum parameters $g_{\\rm NL}$ and $\\tau_{\\rm NL}$. We cross-check our\nresults by comparing the full bispectrum calculation with the expectations from\na general physical argument, based on predicting the shape of $\\mu$-T\ncorrelations from the couplings between short and long perturbation modes\ninduced by primordial non-Gaussianity. We show that $both$ $g_{\\rm NL}$ and\n$\\tau_{\\rm NL}$-parts of the primordial trispectrum source a non-vanishing\n$TT\\mu$ signal, contrary to the $\\mu\\mu$ auto-correlation function, which is\nsensitive only to the $\\tau_{\\rm NL}$-component. A simple Fisher matrix-based\nforecast shows that a futuristic, cosmic-variance dominated experiment could in\nprinciple detect $g_{\\rm NL} \\sim 0.4$ and $\\tau_{\\rm NL} \\sim 40$ using\n$TT\\mu$. \n\n"}
{"id": "1511.02512", "contents": "Title: The data sharing advantage in astrophysics Abstract: We present here evidence for the existence of a citation advantage within\nastrophysics for papers that link to data. Using simple measures based on\npublication data from NASA Astrophysics Data System we find a citation\nadvantage for papers with links to data receiving on the average significantly\nmore citations per paper than papers without links to data. Furthermore, using\nINSPEC and Web of Science databases we investigate whether either papers of an\nexperimental or theoretical nature display different citation behavior. \n\n"}
{"id": "1511.02735", "contents": "Title: Observation of polarised hard X-ray emission from the Crab by the\n  PoGOLite Pathfinder Abstract: We have measured the linear polarisation of hard X-ray emission from the Crab\nin a previously unexplored energy interval, 20-120 keV. The introduction of two\nnew observational parameters, the polarisation fraction and angle stands to\ndisentangle geometrical and physical effects, thereby providing information on\nthe pulsar wind geometry and magnetic field environment. Measurements are\nconducted using the PoGOLite Pathfinder - a balloon-borne polarimeter.\nPolarisation is determined by measuring the azimuthal Compton scattering angle\nof incident X-rays in an array of plastic scintillators housed in an\nanticoincidence well. The polarimetric response has been characterised prior to\nflight using both polarised and unpolarised calibration sources. We address\npossible systematic effects through observations of a background field. The\nmeasured polarisation fraction for the integrated Crab light-curve is\n($18.4^{+9.8}_{-10.6}$)%, corresponding to an upper limit (99% credibility) of\n42.4%, for a polarisation angle of ($149.2\\pm16.0)^\\circ$. \n\n"}
{"id": "1511.03599", "contents": "Title: A polyphase filter for many-core architectures Abstract: In this article we discuss our implementation of a polyphase filter for\nreal-time data processing in radio astronomy. We describe in detail our\nimplementation of the polyphase filter algorithm and its behaviour on three\ngenerations of NVIDIA GPU cards, on dual Intel Xeon CPUs and the Intel Xeon Phi\n(Knights Corner) platforms. All of our implementations aim to exploit the\npotential for data reuse that the algorithm offers. Our GPU implementations\nexplore two different methods for achieving this, the first makes use of\nL1/Texture cache, the second uses shared memory. We discuss the usability of\neach of our implementations along with their behaviours. We measure performance\nin execution time, which is a critical factor for real-time systems, we also\npresent results in terms of bandwidth (GB/s), compute (GFlop/s) and type\nconversions (GTc/s). We include a presentation of our results in terms of the\nsample rate which can be processed in real-time by a chosen platform, which\nmore intuitively describes the expected performance in a signal processing\nsetting. Our findings show that, for the GPUs considered, the performance of\nour polyphase filter when using lower precision input data is limited by type\nconversions rather than device bandwidth. We compare these results to an\nimplementation on the Xeon Phi. We show that our Xeon Phi implementation has a\nperformance that is 1.47x to 1.95x greater than our CPU implementation, however\nis not insufficient to compete with the performance of GPUs. We conclude with a\ncomparison of our best performing code to two other implementations of the\npolyphase filter, showing that our implementation is faster in nearly all\ncases. This work forms part of the Astro-Accelerate project, a many-core\naccelerated real-time data processing library for digital signal processing of\ntime-domain radio astronomy data. \n\n"}
{"id": "1511.03635", "contents": "Title: Fisher Matrix Optimization of Cosmic Microwave Background\n  Interferometers Abstract: We describe a method for forecasting errors in interferometric measurements\nof polarization of the cosmic microwave background (CMB) radiation, based on\nthe use of the Fisher matrix calculated from the visibility covariance and\nrelation matrices. In addition to noise and sample variance, the method can\naccount for many kinds of systematic error by calculating an augmented Fisher\nmatrix, including parameters that characterize the instrument along with the\ncosmological parameters to be estimated. The method is illustrated with\nexamples of gain errors and errors in polarizer orientation. The augmented\nFisher matrix approach is applicable to a much wider range of problems beyond\nCMB interferometry. \n\n"}
{"id": "1511.04608", "contents": "Title: Nonthermal particles and photons in starburst regions and superbubbles Abstract: Starforming factories in galaxies produce compact clusters and loose\nassociations of young massive stars. Fast radiation-driven winds and supernovae\ninput their huge kinetic power into the interstellar medium in the form of\nhighly supersonic and superalfvenic outflows. Apart from gas heating,\ncollisionless relaxation of fast plasma outflows results in fluctuating\nmagnetic fields and energetic particles. The energetic particles comprise a\nlong-lived component which may contain a sizeable fraction of the kinetic\nenergy released by the winds and supernova ejecta and thus modify the\nmagnetohydrodynamic flows in the systems. We present a concise review of\nobservational data and models of nonthermal emission from starburst galaxies,\nsuperbubbles, and compact clusters of massive stars. Efficient mechanisms of\nparticle acceleration and amplification of fluctuating magnetic fields with a\nwide dynamical range in starburst regions are discussed. Sources of cosmic\nrays, neutrinos and multi-wavelength nonthermal emission associated with\nstarburst regions including potential galactic \"PeVatrons\" are reviewed in the\nglobal galactic ecology context. \n\n"}
{"id": "1512.00012", "contents": "Title: Wavelet-Based Techniques for the Gamma-Ray Sky Abstract: We demonstrate how the image analysis technique of wavelet decomposition can\nbe applied to the gamma-ray sky to separate emission on different angular\nscales. New structures on scales that differ from the scales of the\nconventional astrophysical foreground and background uncertainties can be\nrobustly extracted, allowing a model-independent characterization with no\npresumption of exact signal morphology. As a test case, we generate mock\ngamma-ray data to demonstrate our ability to extract extended signals without\nassuming a fixed spatial template. For some point source luminosity functions,\nour technique also allows us to differentiate a diffuse signal in gamma-rays\nfrom dark matter annihilation and extended gamma-ray point source populations\nin a data-driven way. \n\n"}
{"id": "1512.00410", "contents": "Title: Measuring the dynamical state of Planck SZ-selected clusters: X-ray peak\n  - BCG offset Abstract: We want to characterize the dynamical state of galaxy clusters detected with\nthe Sunyaev-Zeldovich (SZ) effect by Planck and compare them with the dynamical\nstate of clusters selected in X-rays survey. We analyzed a representative\nsubsample of the Planck SZ catalogue, containing the 132 clusters with the\nhighest signal to noise ratio and characterize their dynamical state using as\nindicator the projected offset between the peak of the X-ray emission and the\nposition of the Brightest cluster galaxy. We study the distribution of our\nindicator in our sample and compare it to its distribution in X-ray selected\nsamples (HIFLUGCS, MACS and REXCESS). The distributions are significantly\ndifferent and the fraction of relaxed objects is smaller in the Planck sample\n($52 \\pm 4 \\%$) than in X-ray samples ($\\simeq 74\\%$) We interpret this result\nas an indication of different selection effects affecting X-rays (e.g. \"cool\ncore bias\") and SZ surveys of galaxy clusters. \n\n"}
{"id": "1512.01204", "contents": "Title: Creating updated, scientifically-calibrated mosaic images for the RC3\n  catalogue Abstract: The Third Reference Catalogue of Bright Galaxies (RC3) is a reasonably\ncomplete listing of 23,011 nearby, large, bright galaxies. By using the final\nimaging data release from the Sloan Digital Sky Survey, we generate\nscientifically-calibrated FITS mosaics by using the montage program for all\nSDSS imaging bands for all RC3 galaxies that lie within the survey footprint.\nWe further combine the SDSS g, r, and i band FITS mosaics for these galaxies to\ncreate color-composite images by using the STIFF program. We generalized this\nsoftware framework to make FITS mosaics and color-composite images for an\narbitrary catalog and imaging data set. Due to positional inaccuracies inherent\nin the RC3 catalog, we employ a recursive algorithm in our mosaicking pipeline\nthat first determines the correct location for each galaxy, and subsequently\napplies the mosaicking procedure. As an additional test of this new software\npipeline and to obtain mosaic images of a larger sample of RC3 galaxies, we\nalso applied this pipeline to photographic data taken by the Second Palomar\nObservatory Sky Survey with $B_J$, $R_F$, and $I_N$ plates. We publicly release\nall generated data, accessible via a web search form, and the software pipeline\nto enable others to make galaxy mosaics by using other catalogs or surveys. \n\n"}
{"id": "1512.02947", "contents": "Title: On the Green and Wald formalism Abstract: Backreaction in the cosmological context is a longstanding problem that is\nespecially important in the present era of precise cosmology. The standard\nmodel of a homogeneous background plus density perturbations is most probably\noversimplified and is expected to fail to fully account for the near-future\nobservations of sub-percent precision. From a theoretical point of view, the\nproblem of backreaction is very complicated and deserves careful examination.\nRecently, Green and Wald claimed in a series of papers to have developed a\nformalism to properly describe the influence of density inhomogeneities on\naverage properties of the Universe, i.e., the backreaction effect. A brief\ndiscussion of this framework is presented, focussing on its drawbacks and on\nmisconceptions that have arisen during the \"backreaction debate\". \n\n"}
{"id": "1512.05248", "contents": "Title: A practical theorem on using interferometry to measure the global 21-cm\n  signal Abstract: The sky-averaged, or global, background of redshifted $21$ cm radiation is\nexpected to be a rich source of information on cosmological reheating and\nreionizaton. However, measuring the signal is technically challenging: one must\nextract a small, frequency-dependent signal from under much brighter spectrally\nsmooth foregrounds. Traditional approaches to study the global signal have used\nsingle antennas, which require one to calibrate out the frequency-dependent\nstructure in the overall system gain (due to internal reflections, for example)\nas well as remove the noise bias from auto-correlating a single amplifier\noutput. This has motivated proposals to measure the signal using\ncross-correlations in interferometric setups, where additional calibration\ntechniques are available. In this paper we focus on the general principles\ndriving the sensitivity of the interferometric setups to the global signal. We\nprove that this sensitivity is directly related to two characteristics of the\nsetup: the cross-talk between readout channels (i.e. the signal picked up at\none antenna when the other one is driven) and the correlated noise due to\nthermal fluctuations of lossy elements (e.g. absorbers or the ground) radiating\ninto both channels. Thus in an interferometric setup, one cannot suppress\ncross-talk and correlated thermal noise without reducing sensitivity to the\nglobal signal by the same factor -- instead, the challenge is to characterize\nthese effects and their frequency dependence. We illustrate our general theorem\nby explicit calculations within toy setups consisting of two short dipole\nantennas in free space and above a perfectly reflecting ground surface, as well\nas two well-separated identical lossless antennas arranged to achieve zero\ncross-talk. \n\n"}
{"id": "1512.06344", "contents": "Title: On post-inflation validity of perturbation theory in Horndeski\n  scalar-tensor models Abstract: By using the newtonian gauge, we re-confirm that, as in the minimal case, the\nre-scaled Mukhanov-Sasaki variable is conserved leading to a constraint\nequation for the Newtonian potential. However, conversely to the minimal case,\nin Horndeski theories, the super-horizon Newtonian potential can potentially\ngrow to very large values after inflation exit. If that happens, inflationary\npredictability is lost during the oscillating period. When this does not\nhappen, the perturbations generated during inflation can be standardly related\nto the CMB, if the theory chosen is minimal at low energies. As a concrete\nexample, we analytically and numerically discuss the new Higgs inflationary\ncase. There, the Inflaton is the Higgs boson that is non-minimally kinetically\ncoupled to gravity. During the high-energy part of the post-inflationary\noscillations, the system is anisotropic and the Newtonian potential is largely\namplified. Thanks to the smallness of today's amplitude of curvature\nperturbations, however, the system stays in the linear regime, so that\ninflationary predictions are not lost. At low energies, when the system relaxes\nto the minimal case, the anisotropies disappear and the Newtonian potential\nconverges to a constant value. We show that the constant value to which the\nNewtonian potential converges is related to the frozen part of curvature\nperturbations during inflation, precisely like in the minimal case. \n\n"}
{"id": "1512.06872", "contents": "Title: How to coadd images? I. Optimal source detection and photometry using\n  ensembles of images Abstract: Stacks of digital astronomical images are combined in order to increase image\ndepth. The variable seeing conditions, sky background and transparency of\nground-based observations make the coaddition process non-trivial. We present\nimage coaddition methods optimized for source detection and flux measurement,\nthat maximize the signal-to-noise ratio (S/N). We show that for these purposes\nthe best way to combine images is to apply a matched filter to each image using\nits own point spread function (PSF) and only then to sum the images with the\nappropriate weights. Methods that either match filter after coaddition, or\nperform PSF homogenization prior to coaddition will result in loss of\nsensitivity. We argue that our method provides an increase of between a few and\n25 percent in the survey speed of deep ground-based imaging surveys compared\nwith weighted coaddition techniques. We demonstrate this claim using simulated\ndata as well as data from the Palomar Transient Factory data release 2. We\npresent a variant of this coaddition method which is optimal for PSF or\naperture photometry. We also provide an analytic formula for calculating the\nS/N for PSF photometry on single or multiple observations. In the next paper in\nthis series we present a method for image coaddition in the limit of\nbackground-dominated noise which is optimal for any statistical test or\nmeasurement on the constant-in-time image (e.g., source detection, shape or\nflux measurement or star-galaxy separation), making the original data\nredundant. We provide an implementation of this algorithm in MATLAB. \n\n"}
{"id": "1512.07784", "contents": "Title: The more investigation of inflation and reheating stages based on the\n  Planck and WMAP-9 Abstract: The potential $V(\\phi)=\\lambda \\phi^{n}$ is responsible for the inflation of\nthe universe as scalar field $\\phi$ oscillates quickly around some point where\n$V(\\phi)$ has a minimum. The end of this stage has an important role on the\nfurther evolution stages of the universe. The created particles are responsible\nfor reheating the universe at the end of this stage. The behaviour of the\ninflation and reheating stages are often known as power law expansion $S(\\eta)\n\\varpropto \\eta^{1+\\beta}$, $S(\\eta) \\varpropto \\eta^{1+\\beta_{s}}$\nrespectively. The reheating temperature ($T_{rh}$) and $\\beta_{s}$ give us\nvaluable information about the reheating stage. Recently people have studied\nabout the behaviour of $T_{rh}$ based on slow-roll inflation and initial\ncondition of quantum normalization. It is shown that there is some discrepancy\non $T_{rh}$ due to amount of $\\beta_{s}$ under the condition of slow-roll\ninflation and quantum normalization \\cite{acq}. Therefore the author is\nbelieved in \\cite{acq} that the quantum normalization may not be a good initial\ncondition. But it seems that we can remove this discrepancy by determining the\nappropriate parameter $\\beta_{s}$ and hence the obtained temperatures based on\nthe calculated $\\beta_{s}$ are in favour of both mentioned conditions. Then\nfrom given $\\beta_{s}$, we can calculate $T_{rh}$, tensor to scalar ratio $r$\nand parameters $\\beta, n$ based on the Planck and WMAP-9 data. The observed\nresults of $r, \\beta_{s}, \\beta$ and $n$ have consistency with their\nconstrains. Also the results of $T_{rh}$ are in agreement with its general\nrange and special range based on the DECIGO and BBO detectors. \n\n"}
{"id": "1601.00631", "contents": "Title: Bounding $f(R)$ gravity by particle production rate Abstract: Several models of $f(R)$ gravity have been proposed in order to address the\ndark side problem in cosmology. However, these models should be constrained\nalso at ultraviolet scales in order to achieve some correct fundamental\ninterpretation. Here we analyze this possibility comparing quantum vacuum\nstates in given $f(R)$ cosmological backgrounds. Specifically, we compare the\nBogolubov transformations associated to different vacuum states for some $f(R)$\nmodels. The procedure consists in fixing the $f(R)$ free parameters by\nrequiring that the Bogolubov coefficients can be correspondingly minimized to\nbe in agreement with both high redshift observations and quantum field theory\npredictions. In such a way, the particle production is related to the value of\nthe Hubble parameter and then to the given $f(R)$ model. The approach is\ndeveloped in both metric and Palatini formalism. \n\n"}
{"id": "1601.03729", "contents": "Title: Improved dark matter search results from PICO-2L Run 2 Abstract: New data are reported from a second run of the 2-liter PICO-2L C$_3$F$_8$\nbubble chamber with a total exposure of 129$\\,$kg-days at a thermodynamic\nthreshold energy of 3.3$\\,$keV. These data show that measures taken to control\nparticulate contamination in the superheated fluid resulted in the absence of\nthe anomalous background events observed in the first run of this bubble\nchamber. One single nuclear-recoil event was observed in the data, consistent\nboth with the predicted background rate from neutrons and with the observed\nrate of unambiguous multiple-bubble neutron scattering events. The chamber\nexhibits the same excellent electron-recoil and alpha decay rejection as was\npreviously reported. These data provide the most stringent direct detection\nconstraints on weakly interacting massive particle (WIMP)-proton spin-dependent\nscattering to date for WIMP masses $<$ 50$\\,$GeV/c$^2$. \n\n"}
{"id": "1601.04052", "contents": "Title: Precise Astronomical Flux Calibration and its Impact on Studying the\n  Nature of Dark Energy Abstract: Measurements of the luminosity of type Ia supernovae vs. redshift provided\nthe original evidence for the accelerating expansion of the Universe and the\nexistence of dark energy. Despite substantial improvements in survey\nmethodology, systematic uncertainty in flux calibration dominates the error\nbudget for this technique, exceeding both statistics and other systematic\nuncertainties. Consequently, any further collection of type Ia supernova data\nwill fail to refine the constraints on the nature of dark energy unless we also\nimprove the state of the art in astronomical flux calibration to the order of\n1%. We describe how these systematic errors arise from calibration of\ninstrumental sensitivity, atmospheric transmission, and Galactic extinction,\nand discuss ongoing efforts to meet the 1% precision challenge using white\ndwarf stars as celestial standards, exquisitely calibrated detectors as\nfundamental metrologic standards, and real-time atmospheric monitoring. \n\n"}
{"id": "1601.04064", "contents": "Title: An Extended action for the effective field theory of dark energy: a\n  stability analysis and a complete guide to the mapping at the basis of\n  EFTCAMB Abstract: We present a generalization of the effective field theory (EFT) formalism for\ndark energy and modified gravity models to include operators with higher order\nspatial derivatives. This allows the extension of the EFT framework to a wider\nclass of gravity theories such as Horava gravity. We present the corresponding\nextended action, both in the EFT and the Arnowitt-Deser-Misner (ADM) formalism,\nand proceed to work out a convenient mapping between the two, providing a self\ncontained and general procedure to translate a given model of gravity into the\nEFT language at the basis of the Einstein-Boltzmann solver EFTCAMB. Putting\nthis mapping at work, we illustrate, for several interesting models of dark\nenergy and modified gravity, how to express them in the ADM notation and then\nmap them into the EFT formalism. We also provide for the first time, the full\nmapping of GLPV models into the EFT framework. We next perform a thorough\nanalysis of the physical stability of the generalized EFT action, in absence of\nmatter components. We work out viability conditions that correspond to the\nabsence of ghosts and modes that propagate with a negative speed of sound in\nthe scalar and tensor sector, as well as the absence of tachyonic modes in the\nscalar sector. Finally, we extend and generalize the phenomenological basis in\nterms of $\\alpha$-functions introduced to parametrize Horndeski models, to\ncover all theories with higher order spatial derivatives included in our\nextended action. We elaborate on the impact of the additional functions on\nphysical quantities, such as the kinetic term and the speeds of propagation for\nscalar and tensor modes. \n\n"}
{"id": "1601.04854", "contents": "Title: Collisions of CO$_2$ Ice Grains in Planet Formation Abstract: In protoplanetary disks, CO$_2$ is solid ice beyond its snow line at $\\sim 10\n\\rm AU$. Due to its high abundance, it contributes heavily to the collisional\nevolution in this region of the disk. For the first time, we carried out\nlaboratory collision experiments with CO$_2$ ice particles and a CO$_2$-covered\nwall at a temperature of 80 K. Collision velocities varied between 0 - 2.5 m/s.\nParticle sizes were on the order of $\\sim$ 100 $\\mu$m. We find a threshold\nvelocity between the sticking and the bouncing regime at 0.04 m/s. Particles\nwith greater velocities but below 1 m/s bounce off the wall. For yet greater\nvelocities, fragmentation occurs. We give analytical models for the\ncoefficients of restitution and fragmentation strength consistent with the\nexperimental data. Set in context, our data show that CO$_2$ ice and silicate\ndust resemble each other in the collisional behavior. Compared to water ice the\nsticking velocity is an order of magnitude smaller. One immediate consequence\nas example is that water ice particles mantled by CO$_2$ ice lose any \"sticking\nadvantage.\" In this case, preferential planetesimal growth attributed to the\nsticking properties of water ice will be limited to the region between the\nH$_2$O ice line and the CO$_2$ ice line. \n\n"}
{"id": "1601.05028", "contents": "Title: The CDF Archive: Herschel PACS and SPIRE Spectroscopic Data Pipeline and\n  Products for Protostars and Young Stellar Objects Abstract: We present the COPS-DIGIT-FOOSH (CDF) Herschel spectroscopy data product\narchive, and related ancillary data products, along with data fidelity\nassessments, and a user-created archive in collaboration with the Herschel-PACS\nand SPIRE ICC groups. Our products include datacubes, contour maps, automated\nline fitting results, and best 1-D spectra products for all protostellar and\ndisk sources observed with PACS in RangeScan mode for two observing programs:\nthe DIGIT Open Time Key Program (KPOT_nevans_1 and SDP_nevans_1; PI: N. Evans),\nand the FOOSH Open Time Program (OT1_jgreen02_2; PI: J. Green). In addition, we\nprovide our best SPIRE-FTS spectroscopic products for the COPS Open Time\nProgram (OT2_jgreen02_6; PI: J. Green) and FOOSH sources. We include details of\ndata processing, descriptions of output products, and tests of their\nreliability for user applications. We identify the parts of the dataset to be\nused with caution. The resulting absolute flux calibration has improved in\nalmost all cases. Compared to previous reductions, the resulting rotational\ntemperatures and numbers of CO molecules have changed substantially in some\nsources. On average, however, the rotational temperatures have not changed\nsubstantially (< 2%), but the number of warm (Trot ~ 300 K) CO molecules has\nincreased by about 18%. \n\n"}
{"id": "1601.05107", "contents": "Title: A pragmatic Bayesian perspective on correlation analysis: The\n  exoplanetary gravity - stellar activity case Abstract: We apply the Bayesian framework to assess the presence of a correlation\nbetween two quantities. To do so, we estimate the probability distribution of\nthe parameter of interest, $\\rho$, characterizing the strength of the\ncorrelation. We provide an implementation of these ideas and concepts using\npython programming language and the pyMC module in a very short ($\\sim$130\nlines of code, heavily commented) and user-friendly program.\n  We used this tool to assess the presence and properties of the correlation\nbetween planetary surface gravity and stellar activity level as measured by the\nlog($R'_{\\mathrm{HK}}$) indicator. The results of the Bayesian analysis are\nqualitatively similar to those obtained via p-value analysis, and support the\npresence of a correlation in the data. The results are more robust in their\nderivation and more informative, revealing interesting features such as\nasymmetric posterior distributions or markedly different credible intervals,\nand allowing for a deeper exploration.\n  We encourage the reader interested in this kind of problem to apply our code\nto his/her own scientific problems. The full understanding of what the Bayesian\nframework is can only be gained through the insight that comes by handling\npriors, assessing the convergence of Monte Carlo runs, and a multitude of other\npractical problems. We hope to contribute so that Bayesian analysis becomes a\ntool in the toolkit of researchers, and they understand by experience its\nadvantages and limitations. \n\n"}
{"id": "1601.06429", "contents": "Title: PARAVT: Parallel Voronoi Tessellation code Abstract: We present a new open source code for massive parallel computation of Voronoi\ntessellations(VT hereafter) in large data sets. The code is focused for\nastrophysical purposes where VT densities and neighbors are widely used. There\nare several serial Voronoi tessellation codes, however no open source and\nparallel implementations are available to handle the large number of\nparticles/galaxies in current N-body simulations and sky surveys.\nParallelization is implemented under MPI and VT using Qhull library. Domain\ndecomposition takes into account consistent boundary computation between tasks,\nand includes periodic conditions. In addition, the code computes neighbors\nlist, Voronoi density, Voronoi cell volume, density gradient for each particle,\nand densities on a regular grid. \n\n"}
{"id": "1601.07368", "contents": "Title: Long-rising Type II supernovae from PTF and CCCP Abstract: Supernova (SN) 1987A was a peculiar H-rich event with a long-rising (LR)\nlight curve (LC), stemming from a compact blue supergiant star (BSG). Only a\nfew similar events have been presented in the literature. We present new data\nfor a sample of 6 LR Type II SNe (SNe II), 3 of which were discovered and\nobserved by the Palomar Transient Factory (PTF) and 3 observed by the Caltech\nCore-Collapse Project (CCCP). Our aim is to enlarge the family of LR SNe II,\ncharacterizing their properties. Spectra, LCs, and host-galaxies (HG) of these\nSNe are presented. Comparisons with known SN 1987A-like events are shown, with\nemphasis on the absolute magnitudes, colors, expansion velocities, and HG\nmetallicities. Bolometric properties are derived from the multiband LC. By\nmodeling the early-time LCs with scaling relations derived from the SuperNova\nExplosion Code (SNEC) models of MESA progenitor stars, we estimate the\nprogenitor radii of these SNe and other progenitor parameters. We present\nPTF12kso, a LR SN II with the largest amount of 56Ni mass for this class.\nPTF09gpn and PTF12kso are found at the lowest HG metallicities for this SN\ngroup. The variety of early LC luminosities depends on the wide range of\nprogenitor radii, from a few tens of solar radii (SN 2005ci) up to thousands\n(SN 2004ek) with intermediate cases between 100 (PTF09gpn) and 300 solar radii\n(SN 2004em). We confirm that LR SNe II with LC shapes closely resembling that\nof SN 1987A generally arise from BSGs. However, some of them likely have\nprogenitors with larger radii (~300 solar radii, typical of yellow supergiants)\nand can thus be regarded as intermediate cases between normal SNe IIP and SN\n1987A-like SNe. Some extended red supergiant (RSG) stars such as the progenitor\nof SN 2004ek can also produce LR SNe II if they synthesized a large amount of\n56Ni. Low HG metallicity is confirmed as a characteristic of BSG SNe. \n\n"}
{"id": "1601.07531", "contents": "Title: Background and Imaging Simulations for the Hard X-Ray Camera of the\n  MIRAX Mission Abstract: We report the results of detailed Monte Carlo simulations of the performance\nexpected both at balloon altitudes and at the probable satellite orbit of a\nhard X-ray coded-aperture camera being developed for the MIRAX mission. Based\non a thorough mass model of the instrument and detailed specifications of the\nspectra and angular dependence of the various relevant radiation fields at both\nthe stratospheric and orbital environments, we have used the well-known package\nGEANT4 to simulate the instrumental background of the camera. We also show\nsimulated images of source fields to be observed and calculated the detailed\nsensitivity of the instrument in both situations. The results reported here are\nespecially important to researchers in this field considering that we provide\nimportant information, not easily found in the literature, on how to prepare\ninput files and calculate crucial instrumental parameters to perform GEANT4\nsimulations for high-energy astrophysics space experiments. \n\n"}
{"id": "1601.07858", "contents": "Title: Aggregation and Linking of Observational Metadata in the ADS Abstract: We discuss current efforts behind the curation of observing proposals,\narchive bibliographies, and data links in the NASA Astrophysics Data System\n(ADS). The primary data in the ADS is the bibliographic content from scholarly\narticles in Astronomy and Physics, which ADS aggregates from publishers, arXiv\nand conference proceeding sites. This core bibliographic information is then\nfurther enriched by ADS via the generation of citations and usage data, and\nthrough the aggregation of external resources from astronomy data archives and\nlibraries. Important sources of such additional information are the metadata\ndescribing observing proposals and high level data products, which, once\ningested in ADS, become easily discoverable and citeable by the science\ncommunity. Bibliographic studies have shown that the integration of links\nbetween data archives and the ADS provides greater visibility to data products\nand increased citations to the literature associated with them. \n\n"}
{"id": "1602.05573", "contents": "Title: Gravitational wave astrophysics, data analysis and multimessenger\n  astronomy Abstract: This paper reviews gravitational wave sources and their detection. One of the\nmost exciting potential sources of gravitational waves are coalescing binary\nblack hole systems. They can occur on all mass scales and be formed in numerous\nways, many of which are not understood. They are generally invisible in\nelectromagnetic waves, and they provide opportunities for deep investigation of\nEinstein's general theory of relativity. Sect. 1 of this paper considers ways\nthat binary black holes can be created in the universe, and includes the\nprediction that binary black hole coalescence events are likely to be the first\ngravitational wave sources to be detected. The next parts of this paper address\nthe detection of chirp waveforms from coalescence events in noisy data. Such\nanalysis is computationally intensive. Sect. 2 reviews a new and powerful\nmethod of signal detection based on the GPU-implemented summed parallel\ninfinite impulse response filters. Such filters are intrinsically real time\nalorithms, that can be used to rapidly detect and localise signals. Sect. 3 of\nthe paper reviews the use of GPU processors for rapid searching for\ngravitational wave bursts that can arise from black hole births and\ncoalescences. In sect. 4 the use of GPU processors to enable fast efficient\nstatistical significance testing of gravitational wave event candidates is\nreviewed. Sect. 5 of this paper addresses the method of multimessenger\nastronomy where the discovery of electromagnetic counterparts of gravitational\nwave events can be used to identify sources, understand their nature and obtain\nmuch greater science outcomes from each identified event. \n\n"}
{"id": "1602.05836", "contents": "Title: RadioLensfit: Bayesian weak lensing measurement in the visibility domain Abstract: Observationally, weak lensing has been served so far by optical surveys due\nto the much larger number densities of background galaxies achieved, which is\ntypically by two to three orders of magnitude compared to radio. However, the\nhigh sensitivity of the new generation of radio telescopes such as the Square\nKilometre Array (SKA) will provide a density of detected galaxies that is\ncomparable to that found at optical wavelengths, and with significant source\nshape measurements to make large area radio surveys competitive for weak\nlensing studies. This will lead weak lensing to become one of the primary\nscience drivers in radio surveys too, with the advantage that they will access\nthe largest scales in the Universe going beyond optical surveys, like LSST and\nEuclid, in terms of redshifts that are probed. RadioLensfit is an adaptation to\nradio data of \"lensfit\", a model-fitting approach for galaxy shear measurement,\noriginally developed for optical weak lensing surveys. Its key advantage is\nworking directly in the visibility domain, which is the natural approach to\nadopt with radio data, avoiding systematics due to the imaging process. We\npresent results on galaxy shear measurements, including investigation of\nsensitivity to instrumental parameters such as the visibilities gridding size,\nbased on simulations of individual galaxy visibilities performed by using\nSKA1-MID baseline configuration. We get an amplitude of the shear bias in the\nmethod comparable with SKA1 requirements for a population of galaxies with\nrealistic flux and scalelength distributions estimated from the VLA SWIRE\ncatalog. \n\n"}
{"id": "1602.06259", "contents": "Title: Redundant Array Configurations for 21 cm Cosmology Abstract: Realizing the potential of 21 cm tomography to statistically probe the\nintergalactic medium before and during the Epoch of Reionization requires large\ntelescopes and precise control of systematics. Next-generation telescopes are\nnow being designed and built to meet these challenges, drawing lessons from\nfirst-generation experiments that showed the benefits of densely packed, highly\nredundant arrays--in which the same mode on the sky is sampled by many antenna\npairs--for achieving high sensitivity, precise calibration, and robust\nforeground mitigation. In this work, we focus on the Hydrogen Epoch of\nReionization Array (HERA) as an interferometer with a dense, redundant core\ndesigned following these lessons to be optimized for 21 cm cosmology. We show\nhow modestly supplementing or modifying a compact design like HERA's can still\ndeliver high sensitivity while enhancing strategies for calibration and\nforeground mitigation. In particular, we compare the imaging capability of\nseveral array configurations, both instantaneously (to address instrumental and\nionospheric effects) and with rotation synthesis (for foreground removal). We\nalso examine the effects that configuration has on calibratability using\ninstantaneous redundancy. We find that improved imaging with sub-aperture\nsampling via \"off-grid\" antennas and increased angular resolution via far-flung\n\"outrigger\" antennas is possible with a redundantly calibratable array\nconfiguration. \n\n"}
{"id": "1602.06294", "contents": "Title: Stacking for machine learning redshifts applied to SDSS galaxies Abstract: We present an analysis of a general machine learning technique called\n'stacking' for the estimation of photometric redshifts. Stacking techniques can\nfeed the photometric redshift estimate, as output by a base algorithm, back\ninto the same algorithm as an additional input feature in a subsequent learning\nround. We shown how all tested base algorithms benefit from at least one\nadditional stacking round (or layer). To demonstrate the benefit of stacking,\nwe apply the method to both unsupervised machine learning techniques based on\nself-organising maps (SOMs), and supervised machine learning methods based on\ndecision trees. We explore a range of stacking architectures, such as the\nnumber of layers and the number of base learners per layer. Finally we explore\nthe effectiveness of stacking even when using a successful algorithm such as\nAdaBoost. We observe a significant improvement of between 1.9% and 21% on all\ncomputed metrics when stacking is applied to weak learners (such as SOMs and\ndecision trees). When applied to strong learning algorithms (such as AdaBoost)\nthe ratio of improvement shrinks, but still remains positive and is between\n0.4% and 2.5% for the explored metrics and comes at almost no additional\ncomputational cost. \n\n"}
{"id": "1602.06301", "contents": "Title: Interpreting the Recent Upper Limit on the Gravitational Wave Background\n  from the Parkes Pulsar Timing Array Abstract: We provide comments on the article by Shannon et al. (Sep 2015) entitled\n\"Gravitational waves from binary supermassive black holes missing in pulsar\nobservations\". The purpose of this letter is to address several misconceptions\nof the public and other scientists regarding the conclusions of that work. \n\n"}
{"id": "1602.08816", "contents": "Title: Asymmetric Dark Matter Bound State Abstract: We propose an interesting framework for asymmetric scalar dark matter (ADM),\nwhich has novel collider phenomenology in terms of an unstable ADM bound state\n(ADMonium) produced via Higgs portals. ADMonium is a natural consequence of the\nbasic features of ADM: the (complex scalar) ADM is charged under a dark local\n$U(1)_d$ symmetry which is broken at a low scale and provides a light gauge\nboson $X$. The dark gauge coupling is strong and then ADM can annihilate away\ninto $X$-pair effectively. Therefore, the ADM can form bound state due to its\nlarge self-interaction via $X$ mediation. To explore the collider signature of\nADMonium, we propose that ADM has a two-Higgs doublet portal. The ADMonium can\nhave a sizable mixing with the heavier Higgs boson, which admits a large cross\nsection of ADMonium production associated with $b\\bar b$. The resulting\nsignature at the LHC depends on the decays of $X$. In this paper we consider a\ncase of particular interest: $pp\\ra b\\bar b+ {\\rm ADMonium}$ followed by ${\\rm\nADMonium}\\ra 2X\\ra 2e^+e^-$ where the electrons are identified as (un)converted\nphotons. It may provide a competitive explanation to heavy di-photon resonance\nsearches at the LHC. \n\n"}
{"id": "1603.00048", "contents": "Title: Non-random structures in universal compression and the Fermi paradox Abstract: We study the hypothesis of information panspermia assigned recently among\npossible solutions of the Fermi paradox (\"where are the aliens?\"). It suggests\nthat the expenses of alien signaling can be significantly reduced, if their\nmessages contain compressed information. To this end we consider universal\ncompression and decoding mechanisms (e.g. the Lempel-Ziv-Welch algorithm) that\ncan reveal non-random structures in compressed bit strings. The efficiency of\nKolmogorov stochasticity parameter for detection of non-randomness is\nillustrated, along with the Zipf's law. The universality of these methods, i.e.\nindependence on data details, can be principal in searching for intelligent\nmessages. \n\n"}
{"id": "1603.00882", "contents": "Title: Photometric Supernova Classification With Machine Learning Abstract: Automated photometric supernova classification has become an active area of\nresearch in recent years in light of current and upcoming imaging surveys such\nas the Dark Energy Survey (DES) and the Large Synoptic Survey Telescope, given\nthat spectroscopic confirmation of type for all supernovae discovered will be\nimpossible. Here, we develop a multi-faceted classification pipeline, combining\nexisting and new approaches. Our pipeline consists of two stages: extracting\ndescriptive features from the light curves and classification using a machine\nlearning algorithm. Our feature extraction methods vary from model-dependent\ntechniques, namely SALT2 fits, to more independent techniques fitting\nparametric models to curves, to a completely model-independent wavelet\napproach. We cover a range of representative machine learning algorithms,\nincluding naive Bayes, k-nearest neighbors, support vector machines, artificial\nneural networks and boosted decision trees (BDTs). We test the pipeline on\nsimulated multi-band DES light curves from the Supernova Photometric\nClassification Challenge. Using the commonly used area under the curve (AUC) of\nthe Receiver Operating Characteristic as a metric, we find that the SALT2 fits\nand the wavelet approach, with the BDTs algorithm, each achieves an AUC of\n0.98, where 1 represents perfect classification. We find that a representative\ntraining set is essential for good classification, whatever the feature set or\nalgorithm, with implications for spectroscopic follow-up. Importantly, we find\nthat by using either the SALT2 or the wavelet feature sets with a BDT\nalgorithm, accurate classification is possible purely from light curve data,\nwithout the need for any redshift information. \n\n"}
{"id": "1603.01262", "contents": "Title: Testing the variation of fundamental constants by astrophysical methods:\n  overview and prospects Abstract: By measuring the fundamental constants in astrophysical objects one can test\nbasic physical principles as space-time invariance of physical laws along with\nprobing the applicability limits of the standard model of particle physics. The\nlatest constraints on the fine structure constant alpha and the\nelectron-to-proton mass ratio mu obtained from observations at high redshifts\nand in the Milky Way disk are reviewed. In optical range, the most accurate\nmeasurements have already reached the sensitivity limit of available\ninstruments, and further improvements will be possible only with next\ngeneration of telescopes and receivers. New methods of the wavelength\ncalibration should be realized to control systematic errors at the sub-pixel\nlevel. In radio sector, the main tasks are the search for galactic and\nextragalactic objects suitable for precise molecular spectroscopy as well as\nhigh resolution laboratory measurements of molecular lines to provide accurate\nfrequency standards. The expected progress in the optical and radio\nastrophysical observations is quantified. \n\n"}
{"id": "1603.05976", "contents": "Title: BICEP2 / Keck Array VII: Matrix based E/B Separation applied to BICEP2\n  and the Keck Array Abstract: A linear polarization field on the sphere can be uniquely decomposed into an\nE-mode and a B-mode component. These two components are analytically defined in\nterms of spin-2 spherical harmonics. Maps that contain filtered modes on a\npartial sky can also be decomposed into E-mode and B-mode components. However,\nthe lack of full sky information prevents orthogonally separating these\ncomponents using spherical harmonics. In this paper, we present a technique for\ndecomposing an incomplete map into E and B-mode components using E and B\neigenmodes of the pixel covariance in the observed map. This method is found to\northogonally define E and B in the presence of both partial sky coverage and\nspatial filtering. This method has been applied to the BICEP2 and the Keck\nArray maps and results in reducing E to B leakage from LCDM E-modes to a level\ncorresponding to a tensor-to-scalar ratio of $r<1\\times10^{-4}$. \n\n"}
{"id": "1603.06540", "contents": "Title: Improvement of Spectroscopic Performance using a Charge-sensitive\n  Amplifier Circuit for an X-Ray Astronomical SOI Pixel Detector Abstract: We have been developing monolithic active pixel sensors series, named\n\"XRPIX,\" based on the silicon-on-insulator (SOI) pixel technology, for future\nX-ray astronomical satellites. The XRPIX series offers high coincidence time\nresolution ({\\rm \\sim}1 {\\rm \\mu}s), superior readout time ({\\rm \\sim}10 {\\rm\n\\mu}s), and a wide energy range (0.5--40 keV). In the previous study, we\nsuccessfully demonstrated X-ray detection by event-driven readout of XRPIX2b.\nWe here report recent improvements in spectroscopic performance. We\nsuccessfully increased the gain and reduced the readout noise in XRPIX2b by\ndecreasing the parasitic capacitance of the sense-node originated in the buried\np-well (BPW). On the other hand, we found significant tail structures in the\nspectral response due to the loss of the charge collection efficiency when a\nsmall BPW is employed. Thus, we increased the gain in XRPIX3b by introducing\nin-pixel charge sensitive amplifiers instead of having even smaller BPW. We\nfinally achieved the readout noise of 35 e{\\rm ^{-}} (rms) and the energy\nresolution of 320 eV (FWHM) at 6 keV without significant loss of the charge\ncollection efficiency. \n\n"}
{"id": "1603.07142", "contents": "Title: CRPropa 3 - a Public Astrophysical Simulation Framework for Propagating\n  Extraterrestrial Ultra-High Energy Particles Abstract: We present the simulation framework CRPropa version 3 designed for efficient\ndevelopment of astrophysical predictions for ultra-high energy particles. Users\ncan assemble modules of the most relevant propagation effects in galactic and\nextragalactic space, include their own physics modules with new features, and\nreceive on output primary and secondary cosmic messengers including nuclei,\nneutrinos and photons. In extension to the propagation physics contained in a\nprevious CRPropa version, the new version facilitates high-performance\ncomputing and comprises new physical features such as an interface for galactic\npropagation using lensing techniques, an improved photonuclear interaction\ncalculation, and propagation in time dependent environments to take into\naccount cosmic evolution effects in anisotropy studies and variable sources.\nFirst applications using highlighted features are presented as well. \n\n"}
{"id": "1603.07565", "contents": "Title: Challenges and prospects for better measurements of the CMB intensity\n  spectrum Abstract: Spectral distortions of the Cosmic Microwave Background (CMB) offer the\npossibility of probing processes which occurred during the evolution of our\nUniverse going back up to Z$\\simeq 10^7$. Unfortunately all the attempts so far\ncarried out for detecting distortions failed. All of them were based on\ncomparisons among absolute measurements of the CMB temperature at different\nfrequencies. We suggest a different approach: measurements of the frequency\nderivative of the CMB temperature over large frequency intervals instead of\nobservations of the absolute temperature at few, well separated, frequencies as\nfrequently done in the past, and, direct measurements of the foregrounds which\nhinder bobservations, at the same site and with the same radiometer prepared\nfor the search of CMB distortions. We discuss therefore the perspectives of new\nobservations in the next years from the ground, at very special sites, or in\nspace as independent missions or part of other CMB projects \n\n"}
{"id": "1604.00332", "contents": "Title: Anisotropies in the gravitational wave background as a probe of the\n  cosmic string network Abstract: Pulsar timing arrays are one of the powerful tools to test the existence of\ncosmic strings through searching for the gravitational wave background. The\namplitude of the background connects to information on cosmic strings such as\nthe tension and string network properties. In addition, one may be able to\nextract more information on properties of cosmic strings by measuring\nanisotropies in the gravitational wave (GW) background. In this paper, we\nprovide estimates of the level of anisotropy expected in the GW background\ngenerated by cusps on cosmic strings. We find that the anisotropy level\nstrongly depends on the initial loop size $\\alpha$, and thus we may be able to\nput constraint on $\\alpha$ by measuring the anisotropy of the GW background. We\nalso find that certain regions of the parameter space can be probed by shifting\nthe observation frequency of GWs. \n\n"}
{"id": "1604.02263", "contents": "Title: Constraining particle dark matter using local galaxy distribution Abstract: It has been long discussed that cosmic rays may contain signals of dark\nmatter. In the last couple of years an anomaly of cosmic-ray positrons has\ndrawn a lot of attentions, and recently an excess in cosmic-ray anti-proton has\nbeen reported by AMS-02 collaboration. Both excesses may indicate towards\ndecaying or annihilating dark matter with a mass of around 1-10 TeV. In this\narticle we study the gamma rays from dark matter and constraints from cross\ncorrelations with distribution of galaxies, particularly in a local volume. We\nfind that gamma rays due to inverse-Compton process have large intensity, and\nhence they give stringent constraints on dark matter scenarios in the TeV scale\nmass regime. Taking the recent developments in modeling astrophysical gamma-ray\nsources as well as comprehensive possibilities of the final state products of\ndark matter decay or annihilation into account, we show that the parameter\nregions of decaying dark matter that are suggested to explain the excesses are\nexcluded. We also discuss the constrains on annihilating scenarios. \n\n"}
{"id": "1604.05035", "contents": "Title: Probing classically conformal $B-L$ model with gravitational waves Abstract: We study the cosmological history of the classical conformal $B-L$ gauge\nextension of the standard model, in which the physical scales are generated via\nthe Coleman-Weinberg-type symmetry breaking. Especially, we consider the\nthermal phase transition of the U$(1)_{B-L}$ symmetry in the early universe and\nresulting gravitational-wave production. Due to the classical conformal\ninvariance, the phase transition tends to be a first-order one with\nultra-supercooling, which enhances the strength of the produced gravitational\nwaves. We show that, requiring (1) U$(1)_{B-L}$ is broken after the reheating,\n(2) the $B-L$ gauge coupling does not blow up below the Planck scale, (3) the\nthermal phase transition completes in almost all the patches in the universe,\nthe gravitational wave spectrum can be as large as $\\Omega_{\\rm GW} \\sim\n10^{-8}$ at the frequency $f \\sim 0.01$-$1$Hz for some model parameters, and a\nvast parameter region can be tested by future interferometer experiments such\nas eLISA, LISA, BBO and DECIGO. \n\n"}
{"id": "1604.05318", "contents": "Title: Implications of solar wind measurements for solar models and composition Abstract: We critically examine recent claims of a high solar metallicity by von\nSteiger \\& Zurbuchen (2016) based on \\textit{in situ} measurements of the solar\nwind, rather than the standard spectroscopically-inferred abundances (Asplund\net al. 2009). We test the claim by Vagnozzi et al. (2016) that a composition\nbased on the solar wind enables one to construct a standard solar model in\nagreement with helioseismological observations and thus solve the decades-old\nsolar modelling problem. We show that, although some helioseismological\nobservables are improved compared to models computed with spectroscopic\nabundances, most are in fact worse. The high abundance of refractory elements\nleads to an overproduction of neutrinos, with a predicted $^8$B flux that is\nnearly twice its observed value, and $^7$Be and CNO fluxes that are\nexperimentally ruled out at high confidence. A combined likelihood analysis\nshows that models using the vSZ16 abundances fare worse than AGSS09 despite a\nhigher metallicity. We also present astrophysical and spectroscopic arguments\nshowing the vSZ16 composition to be an implausible representation of the solar\ninterior, identifying the first ionisation potential effect in the outer solar\natmosphere and wind as the likely culprit. \n\n"}
{"id": "1604.06071", "contents": "Title: A supernova feedback implementation for the astrophysical simulation\n  software Arepo Abstract: Supernova (SN) explosions play an important role in the development of\ngalactic structures. The energy and momentum imparted on the interstellar\nmedium (ISM) in so-called \"supernova feedback\" drives turbulence, heats the\ngas, enriches it with heavy elements, can lead to the formation of new stars or\neven suppress star formation by disrupting stellar nurseries. In the numerical\nsimulation at the sub-galactic level, not including the energy and momentum of\nsupernovas in the physical description of the problem can also lead to several\nproblems that might partially be resolved by including a description of\nsupernovas. In this thesis such an implementation is attempted for the combined\nnumerical hydrodynamics and N-body simulation software Arepo (Springel, 2010)\nfor the high density gas in the ISM only. This allows supernova driven\nturbulence in boxes of 400pc cubed to be studied. In a stochastic process a\nlarge amount of thermal energy is imparted on a number of neighbouring cells,\nmimicking the effect of a supernova explosions. We test this approach by\nmodelling the explosion of a single supernova in a uniform density medium and\ncomparing the evolution of the resulting supernova remnant to the\ntheoretically-predicted behaviour. We also run a simulation with our feedback\ncode and a fixed supernova rate derived from the Kennicutt-Schmidt relation\n(Kennicutt, 1998) for a duration of about 20 Myrs. We describe our method in\ndetail in this text and discuss the properties of our implementation. vii \n\n"}
{"id": "1604.07493", "contents": "Title: The 2.4 $\\mu$m Galaxy Luminosity Function as Measured Using WISE. I.\n  Measurement Techniques Abstract: The astronomy community has at its disposal a large back catalog of public\nspectroscopic galaxy redshift surveys that can be used for the measurement of\nluminosity functions. Utilizing the back catalog with new photometric surveys\nto maximum efficiency requires modeling the color selection bias imposed on\nselection of target galaxies by flux limits at multiple wavelengths. The\nlikelihood derived herein can address, in principle, all possible color\nselection biases through the use of a generalization of the luminosity\nfunction, $\\Phi(L)$, over the space of all spectra: the spectro-luminosity\nfunctional, $\\Psi[L_\\nu]$. It is, therefore, the first estimator capable of\nsimultaneously analyzing multiple redshift surveys in a consistent way. We also\npropose a new way of parametrizing the evolution of the classic Shechter\nfunction parameters, $L_\\star$ and $\\phi_\\star$, that improves both the\nphysical realism and statistical performance of the model. The techniques\nderived in this work will be used in an upcoming paper to measure the\nluminosity function of galaxies at the rest frame wavelength of\n$2.4\\operatorname{\\mu m}$ using the Widefield Infrared Survey Explorer (WISE). \n\n"}
{"id": "1604.07844", "contents": "Title: Type III Societies (Apparently) Do Not Exist Abstract: [Abridged] Whether technological societies remain small and planet-bound like\nour own, or ultimately span across galaxies is an open question in the Search\nfor Extraterrestrial Intelligence. Societies that engineer on a galactic scale\nare classified as Type III on Kardashev's scale. I argue that Type III\nsocieties can take the form of blackboxes, entire galaxies veiled in an opaque\nscreen. A blackbox has a temperature that is just above that of the cosmic\nmicrowave background. The screen can be made from artificial dust pervading the\ngalaxy. I show that there is enough material in galaxies to build blackboxes if\nthe dust is fashioned into dipole antennas. The thermal emission of a blackbox\nmakes it a bright microwave source. I examine the Planck Catalog of Compact\nSources to constrain the abundance of blackboxes. None of the 100 GHz sources\nhas the spectrum expected of a blackbox. The null result rules out shrouded\ngalaxy clusters out to z ~ 1 and shrouded Milky Ways out to (comoving) 700 Mpc.\nThe reach of the results includes 3 million galaxies containing an estimated\n300 quadrillion terrestrial planets, as well as tens of thousands of galaxy\nclusters. Combined with the null results from other searches for Type III\nsocieties, I conclude that they are so rare that they basically do not exist\nwithin the observable Universe. A hypothesis of \"Cosmic Pessimism\" is\ndiscussed, in which we are alone, our long-term chances for survival are slim,\nand if we do survive, our future history will be checkered. Our loneliness is\nsuggested by the lack of Type III societies. I discuss the remaining forms of\nType III societies not yet well constrained by observation. I argue that the\nease of building blackboxes on planetary and Solar System scales may lead,\nwithin a few centuries, to environmental catastrophes vastly more devastating\nthan anything we are doing now, boding ill for us. \n\n"}
{"id": "1605.07256", "contents": "Title: Exploring the evolution of Reionisation using a wavelet transform and\n  the light cone effect Abstract: The Cosmic Dawn and Epoch of Reionisation, during which collapsed structures\nproduce the first ionising photons and proceed to reionise the intergalactic\nmedium, span a large range in redshift (z~30-6) and time (t_{age} ~\n0.1-1.0~Gyr). Exploration of these epochs using the redshifted 21~cm emission\nline from neutral hydrogen is currently limited to statistical detection and\nestimation metrics (e.g., the power spectrum) due to the weakness of the\nsignal. Brightness temperature fluctuations in the line-of-sight (LOS)\ndimension are probed by observing the emission line at different frequencies,\nand their structure is used as a primary discriminant between the cosmological\nsignal and contaminating foreground extragalactic and Galactic continuum\nemission. Evolution of the signal over the observing bandwidth leads to the\n`line cone effect' whereby the HI structures at the start and end of the\nobserving band are not statistically consistent, yielding a biased estimate of\nthe signal power, and potential reduction in signal detectability. We implement\na wavelet transform to wide bandwidth radio interferometry experiments to probe\nthe local statistical properties of the signal. We show that use of the wavelet\ntransform yields estimates with improved estimation performance, compared with\nthe standard Fourier Transform over a fixed bandwidth. With the suite of\ncurrent and future large bandwidth reionisation experiments, such as with the\n300~MHz instantaneous bandwidth of the Square Kilometre Array, a transform that\nretains local information will be important. \n\n"}
{"id": "1605.07619", "contents": "Title: Systematic biases in low frequency radio interferometric data due to\n  calibration: the LOFAR EoR case Abstract: The redshifted 21 cm line of neutral hydrogen is a promising probe of the\nEpoch of Reionization (EoR). However, its detection requires a thorough\nunderstanding and control of the systematic errors. We study two systematic\nbiases observed in the LOFAR EoR residual data after calibration and\nsubtraction of bright discrete foreground sources. The first effect is a\nsuppression in the diffuse foregrounds, which could potentially mean a\nsuppression of the 21 cm signal. The second effect is an excess of noise beyond\nthe thermal noise. The excess noise shows fluctuations on small frequency\nscales, and hence it can not be easily removed by foreground removal or\navoidance methods. Our analysis suggests that sidelobes of residual sources due\nto the chromatic point spread function and ionospheric scintillation can not be\nthe dominant causes of the excess noise. Rather, both the suppression of\ndiffuse foregrounds and the excess noise can occur due to calibration with an\nincomplete sky model containing predominantly bright discrete sources. We show\nthat calibrating only on bright sources can cause suppression of other signals\nand introduce an excess noise in the data. The levels of the suppression and\nexcess noise depend on the relative flux of sources which are not included in\nthe model with respect to the flux of modeled sources. We discuss possible\nsolutions such as using only long baselines to calibrate the interferometric\ngain solutions as well as simultaneous multi-frequency calibration along with\ntheir benefits and shortcomings. \n\n"}
{"id": "1605.08355", "contents": "Title: On the 4D generalized Proca action for an Abelian vector field Abstract: We summarize previous results on the most general Proca theory in 4\ndimensions containing only first-order derivatives in the vector field\n(second-order at most in the associated St\\\"uckelberg scalar) and having only\nthree propagating degrees of freedom with dynamics controlled by second-order\nequations of motion. Discussing the Hessian condition used in previous works,\nwe conjecture that, as in the scalar galileon case, the most complete action\ncontains only a finite number of terms with second-order derivatives of the\nSt\\\"uckelberg field describing the longitudinal mode, which is in agreement\nwith the results of JCAP 1405, 015 (2014) and Phys. Lett. B 757, 405 (2016) and\ncomplements those of JCAP 1602, 004 (2016). We also correct and complete the\nparity violating sector, obtaining an extra term on top of the arbitrary\nfunction of the field $A_\\mu$, the Faraday tensor $F_{\\mu \\nu}$ and its Hodge\ndual $\\tilde{F}_{\\mu \\nu}$. \n\n"}
{"id": "1606.00767", "contents": "Title: The small-scale turbulent dynamo in smoothed particle\n  magnetohydrodynamics Abstract: Supersonic turbulence is believed to be at the heart of star formation. We\nhave performed smoothed particle magnetohydrodynamics (SPMHD) simulations of\nthe small-scale dynamo amplification of magnetic fields in supersonic\nturbulence. The calculations use isothermal gas driven at rms velocity of Mach\n10 so that conditions are representative of star-forming molecular clouds in\nthe Milky Way. The growth of magnetic energy is followed for 10 orders in\nmagnitude until it reaches saturation, a few percent of the kinetic energy. The\nresults of our dynamo calculations are compared with results from grid-based\nmethods, finding excellent agreement on their statistics and their qualitative\nbehaviour. The simulations utilise the latest algorithmic developments we have\ndeveloped, in particular, a new divergence cleaning approach to maintain the\nsolenoidal constraint on the magnetic field and a method to reduce the\nnumerical dissipation of the magnetic shock capturing scheme. We demonstrate\nthat our divergence cleaning method may be used to achieve $\\nabla \\cdot {\\bf\nB}=0$ to machine precision, albeit at significant computational expense. \n\n"}
{"id": "1606.01860", "contents": "Title: A Resonant Mode for Gravitational Wave Detectors based on Atom\n  Interferometry Abstract: We describe an atom interferometric gravitational wave detector design that\ncan operate in a resonant mode for increased sensitivity. By oscillating the\npositions of the atomic wavepackets, this resonant detection mode allows for\ncoherently enhanced, narrow-band sensitivity at target frequencies. The\nproposed detector is flexible and can be rapidly switched between broadband and\nnarrow-band detection modes. For instance, a binary discovered in broadband\nmode can subsequently be studied further as the inspiral evolves by using a\ntailored narrow-band detector response. In addition to functioning like a\nlock-in amplifier for astrophysical events, the enhanced sensitivity of the\nresonant approach also opens up the possibility of searching for important\ncosmological signals, including the stochastic gravitational wave background\nproduced by inflation. We give an example of detector parameters which would\nallow detection of inflationary gravitational waves down to $\\Omega_\\text{GW}\n\\sim 10^{-14}$ for a two satellite space-based detector. \n\n"}
{"id": "1606.01887", "contents": "Title: Ensemble Average Theory of Gravity Abstract: We put forward the idea that all the theoretically consistent models of\ngravity have contributions to the observed gravity interaction. In this\nformulation, each model comes with its own Euclidean path-integral weight where\ngeneral relativity (GR) has automatically the maximum weight in high-curvature\nregions. We employ this idea in the framework of Lovelock models and show that\nin four dimensions the result is a specific form of the $f(R,G)$ model. This\nspecific $f(R,G)$ satisfies the stability conditions and possesses\nself-accelerating solutions. Our model is consistent with the local tests of\ngravity since its behavior is the same as in GR for the high-curvature regime.\nIn the low-curvature regime the gravitational force is weaker than in GR, which\ncan be interpreted as the existence of a repulsive fifth force for very large\nscales. Interestingly, there is an intermediate-curvature regime where the\ngravitational force is stronger in our model compared to GR. The different\nbehavior of our model in comparison with GR in both low- and\nintermediate-curvature regimes makes it observationally distinguishable from\n$\\Lambda$CDM. \n\n"}
{"id": "1606.02389", "contents": "Title: About the isocurvature tension between axion and high scale inflationary\n  models Abstract: The present work suggests that the isocurvature tension between axion and\nhigh energy inflationary scenarios may be avoided by considering a double field\ninflationary model involving the hidden Peccei-Quinn Higgs and the Standard\nModel one. Some terms in the lagrangian we propose explicitly violate the\nPeccei-Quinn symmetry but, at the present era, their effect is completely\nnegligible. The resulting mechanism allows a large value for the axion\nconstant, of the order $f_a\\sim M_p$, thus the axion isocurvature fluctuations\nare suppressed even when the scale of inflation $H_{inf}$ is very high, of the\norder of $H_{inf}\\sim M_{gut}$. This numerical value is typical in Higgs\ninflationary models. An analysis about topological defect formation in this\nscenario is also performed, and it is suggested that, under certain\nassumptions, their effect is not catastrophic from the cosmological point of\nview. \n\n"}
{"id": "1606.02620", "contents": "Title: False periodicities in quasar time-domain surveys Abstract: There have recently been several reports of apparently periodic variations in\nthe light curves of quasars, e.g. PG 1302-102 by Graham et al. (2015a). Any\nquasar showing periodic oscillations in brightness would be a strong candidate\nto be a close binary supermassive black hole and, in turn, a candidate for\ngravitational wave studies. However, normal quasars -- powered by accretion\nonto a single, supermassive black hole -- usually show stochastic variability\nover a wide range of timescales. It is therefore important to carefully assess\nthe methods for identifying periodic candidates from among a population\ndominated by stochastic variability. Using a Bayesian analysis of the light\ncurve of PG 1302-102, we find that a simple stochastic process is preferred\nover a sinusoidal variations. We then discuss some of the problems one\nencounters when searching for rare, strictly periodic signals among a large\nnumber of irregularly sampled, stochastic time series, and use simulations of\nquasar light curves to illustrate these points. From a few thousand simulations\nof steep spectrum (`red noise') stochastic processes, we find many simulations\nthat display few-cycle periodicity like that seen in PG 1302-102. We emphasise\nthe importance of calibrating the false positive rate when the number of\ntargets in a search is very large. \n\n"}
{"id": "1606.03451", "contents": "Title: SKA Weak Lensing III: Added Value of Multi-Wavelength Synergies for the\n  Mitigation of Systematics Abstract: In this third paper of a series on radio weak lensing for cosmology with the\nSquare Kilometre Array, we scrutinise synergies between cosmic shear\nmeasurements in the radio and optical/near-IR bands for mitigating systematic\neffects. We focus on three main classes of systematics: (i) experimental\nsystematic errors in the observed shear; (ii) signal contamination by intrinsic\nalignments; and (iii) systematic effects due to an incorrect modelling of\nnon-linear scales. First, we show that a comprehensive, multi-wavelength\nanalysis provides a self-calibration method for experimental systematic\neffects, only implying <50% increment on the errors on cosmological parameters.\nWe also illustrate how the cross-correlation between radio and optical/near-IR\nsurveys alone is able to remove residual systematics with variance as large as\n0.00001, i.e. the same order of magnitude of the cosmological signal. This also\nopens the possibility of using such a cross-correlation as a means to detect\nunknown experimental systematics. Secondly, we demonstrate that, thanks to\npolarisation information, radio weak lensing surveys will be able to mitigate\ncontamination by intrinsic alignments, in a way similar but fully complementary\nto available self-calibration methods based on position-shear correlations.\nLastly, we illustrate how radio weak lensing experiments, reaching higher\nredshifts than those accessible to optical surveys, will probe dark energy and\nthe growth of cosmic structures in regimes less contaminated by non-linearities\nin the matter perturbations. For instance, the higher-redshift bins of radio\ncatalogues peak at z~0.8-1, whereas their optical/near-IR counterparts are\nlimited to z<0.5-0.7. This translates into having a cosmological signal 2 to 5\ntimes less contaminated by non-linear perturbations. \n\n"}
{"id": "1606.05354", "contents": "Title: EGG: hatching a mock Universe from empirical prescriptions Abstract: This paper introduces EGG, the Empirical Galaxy Generator, a tool designed\nwithin the ASTRODEEP collaboration to generate mock galaxy catalogs for deep\nfields with realistic fluxes and simple morphologies. The simulation procedure\nis based exclusively on empirical prescriptions -- rather than first principles\n-- to provide the most accurate match with observations at 0<z<7. In\nparticular, we consider that galaxies can be either quiescent or star-forming,\nand use their stellar mass (M*) and redshift (z) as the fundamental properties\nfrom which all the other observables can be statistically derived. Drawing z\nand M* from the observed galaxy stellar mass functions, we associate a star\nformation rate (SFR) to each galaxy from the tight SFR-M* main sequence, while\ndust attenuation, optical colors and morphologies (including bulge-to-total\nratios, sizes and aspect ratios) are obtained from empirical relations that we\nestablish from the high quality Hubble and Herschel observations available in\nthe CANDELS fields. Random scatter is introduced in each step to reproduce the\nobserved distributions of each parameter. Based on these observables, a\npanchromatic spectral energy distribution (SED) is selected for each galaxy and\nsynthetic photometry is produced by integrating the redshifted SED in common\nbroad-band filters. Finally, the mock galaxies are placed on the sky at random\npositions with a fixed angular two-point correlation function to implement\nbasic clustering. The resulting flux catalogs reproduce accurately the observed\nnumber counts in all broad bands from the ultraviolet up to the sub-millimeter,\nand can be directly fed to image simulators such as Skymaker. The images can\nthen be used to test source extraction softwares and image-based techniques\nsuch as stacking. EGG is open-source, and is made available to the community\ntogether with a set of pre-generated catalogs and images. \n\n"}
{"id": "1606.05790", "contents": "Title: Mathematical Foundations of the GraphBLAS Abstract: The GraphBLAS standard (GraphBlas.org) is being developed to bring the\npotential of matrix based graph algorithms to the broadest possible audience.\nMathematically the Graph- BLAS defines a core set of matrix-based graph\noperations that can be used to implement a wide class of graph algorithms in a\nwide range of programming environments. This paper provides an introduction to\nthe mathematics of the GraphBLAS. Graphs represent connections between vertices\nwith edges. Matrices can represent a wide range of graphs using adjacency\nmatrices or incidence matrices. Adjacency matrices are often easier to analyze\nwhile incidence matrices are often better for representing data. Fortunately,\nthe two are easily connected by matrix mul- tiplication. A key feature of\nmatrix mathematics is that a very small number of matrix operations can be used\nto manipulate a very wide range of graphs. This composability of small number\nof operations is the foundation of the GraphBLAS. A standard such as the\nGraphBLAS can only be effective if it has low performance overhead. Performance\nmeasurements of prototype GraphBLAS implementations indicate that the overhead\nis low. \n\n"}
{"id": "1606.06268", "contents": "Title: CosmicFish Implementation Notes V1.0 Abstract: CosmicFish is a publicly available library to perform Fisher matrix forecast\nfor several cosmological observations. With the present implementation notes we\nprovide a guide to the physical and technical details of the library. We\nreproduce here the details and all the relevant equations, as they appear in\nthe code. We submit these notes to the arXiv to grant full and permanent access\nto this material which provides a useful guidance to forecasting and the use of\nCosmicFish code. We will update this set of notes when relevant modifications\nto the CosmicFish code will be released. The present version is based on\nCosmicFish Jun16. \n\n"}
{"id": "1606.06374", "contents": "Title: An Empirical Approach to Cosmological Galaxy Survey Simulation:\n  Application to SPHEREx Low-Resolution Spectroscopy Abstract: Highly accurate models of the galaxy population over cosmological volumes are\nnecessary in order to predict the performance of upcoming cosmological\nmissions. We present a data-driven model of the galaxy population constrained\nby deep 0.1-8 $\\rm \\mu m$ imaging and spectroscopic data in the COSMOS survey,\nwith the immediate goal of simulating the spectroscopic redshift performance of\nthe proposed SPHEREx mission. SPHEREx will obtain over the full-sky $R\\sim41$\nspectrophotometry at moderate spatial resolution ($\\sim6\"$) over the wavelength\nrange 0.75-4.18 $\\rm \\mu m$ and $R\\sim135$ over the wavelength range 4.18-5\n$\\rm \\mu m$. We show that our simulation accurately reproduces a range of known\ngalaxy properties, encapsulating the full complexity of the galaxy population\nand enables realistic, full end-to-end simulations to predict mission\nperformance. Finally, we discuss potential applications of the simulation\nframework to future cosmology missions and give a description of released data\nproducts. \n\n"}
{"id": "1606.07345", "contents": "Title: A Communication Efficient and Scalable Distributed Data Mining for the\n  Astronomical Data Abstract: In 2020, ~60PB of archived data will be accessible to the astronomers. But to\nanalyze such a paramount data will be a challenging task. This is basically due\nto the computational model used to download the data from complex\ngeographically distributed archives to a central site and then analyzing it in\nthe local systems. Because the data has to be downloaded to the central site,\nthe network BW limitation will be a hindrance for the scientific discoveries.\nAlso analyzing this PB-scale on local machines in a centralized manner is\nchallenging. In this virtual observatory is a step towards this problem,\nhowever, it does not provide the data mining model. Adding the distributed data\nmining layer to the VO can be the solution in which the knowledge can be\ndownloaded by the astronomers instead the raw data and thereafter astronomers\ncan either reconstruct the data back from the downloaded knowledge or use the\nknowledge directly for further analysis.Therefore, in this paper, we present\nDistributed Load Balancing Principal Component Analysis for optimally\ndistributing the computation among the available nodes to minimize the\ntransmission cost and downloading cost for the end user. The experimental\nanalysis is done with Fundamental Plane(FP) data, Gadotti data and complex\nMfeat data. In terms of transmission cost, our approach performs better than\nQi. et al. and Yue.et al. The analysis shows that with the complex Mfeat data\n~90% downloading cost can be reduced for the end user with the negligible loss\nin accuracy. \n\n"}
{"id": "1607.00270", "contents": "Title: Constraining the dark energy equation of state using Bayes theorem and\n  the Kullback-Leibler divergence Abstract: Data-driven model-independent reconstructions of the dark energy equation of\nstate $w(z)$ are presented using Planck 2015 era CMB, BAO, SNIa and\nLyman-$\\alpha$ data. These reconstructions identify the $w(z)$ behaviour\nsupported by the data and show a bifurcation of the equation of state posterior\nin the range $1.5{<}z{<}3$. Although the concordance $\\Lambda$CDM model is\nconsistent with the data at all redshifts in one of the bifurcated spaces, in\nthe other a supernegative equation of state (also known as `phantom dark\nenergy') is identified within the $1.5 \\sigma$ confidence intervals of the\nposterior distribution. To identify the power of different datasets in\nconstraining the dark energy equation of state, we use a novel formulation of\nthe Kullback--Leibler divergence. This formalism quantifies the information the\ndata add when moving from priors to posteriors for each possible dataset\ncombination. The SNIa and BAO datasets are shown to provide much more\nconstraining power in comparison to the Lyman-$\\alpha$ datasets. Further, SNIa\nand BAO constrain most strongly around redshift range $0.1-0.5$, whilst the\nLyman-$\\alpha$ data constrains weakly over a broader range. We do not attribute\nthe supernegative favouring to any particular dataset, and note that the\n$\\Lambda$CDM model was favoured at more than $2$ log-units in Bayes factors\nover all the models tested despite the weakly preferred $w(z)$ structure in the\ndata. \n\n"}
{"id": "1607.02150", "contents": "Title: Foreground Bias From Parametric Models of Far-IR Dust Emission Abstract: We use simple toy models of far-IR dust emission to estimate the accuracy to\nwhich the polarization of the cosmic microwave background can be recovered\nusing multi-frequency fits, if the parametric form chosen for the fitted dust\nmodel differs from the actual dust emission. Commonly used approximations to\nthe far-IR dust spectrum yield CMB residuals comparable to or larger than the\nsensitivities expected for the next generation of CMB missions, despite fitting\nthe combined CMB + foreground emission to precision 0.1% or better. The\nRayleigh-Jeans approximation to the dust spectrum biases the fitted dust\nspectral index by Delta beta_d = 0.2 and the inflationary B-mode amplitude by\nDelta r = 0.03. Fitting the dust to a modified blackbody at a single\ntemperature biases the best-fit CMB by Delta r > 0.003 if the true dust\nspectrum contains multiple temperature components. A 13-parameter model fitting\ntwo temperature components reduces this bias by an order of magnitude if the\ntrue dust spectrum is in fact a simple superposition of emission at different\ntemperatures, but fails at the level Delta r = 0.006 for dust whose spectral\nindex varies with frequency. Restricting the observing frequencies to a narrow\nregion near the foreground minimum reduces these biases for some dust spectra\nbut can increase the bias for others. Data at THz frequencies surrounding the\npeak of the dust emission can mitigate these biases while providing a direct\ndetermination of the dust temperature profile. \n\n"}
{"id": "1607.03318", "contents": "Title: The impact of galactic properties and environment on the quenching of\n  central and satellite galaxies: A comparison between SDSS, Illustris and\n  L-Galaxies Abstract: We quantify the impact that a variety of galactic and environmental\nproperties have on the quenching of star formation. We collate a sample of\n$\\sim$ 400,000 central and $\\sim$ 100,000 satellite galaxies from the Sloan\nDigital Sky Survey Data Release 7 (SDSS DR7). Specifically, we consider central\nvelocity dispersion ($\\sigma_{c}$), stellar, halo, bulge and disk mass, local\ndensity, bulge-to-total ratio, group-centric distance and galaxy-halo mass\nratio. We develop and apply a new statistical technique to quantify the impact\non the quenched fraction ($f_{\\rm Quench}$) of varying one parameter, while\nkeeping the remaining parameters fixed. For centrals, we find that the $f_{\\rm\nQuench} - \\sigma_{c}$ relationship is tighter and steeper than for any other\nvariable considered. We compare to the Illustris hydrodynamical simulation and\nthe Munich semi-analytic model (L-Galaxies), finding that our results for\ncentrals are qualitatively consistent with their predictions for quenching via\nradio-mode AGN feedback, hinting at the viability of this process in explaining\nour observational trends. However, we also find evidence that quenching in\nL-Galaxies is too efficient and quenching in Illustris is not efficient enough,\ncompared to observations. For satellites, we find strong evidence that\nenvironment affects their quenched fraction at fixed central velocity\ndispersion, particularly at lower masses. At higher masses, satellites behave\nidentically to centrals in their quenching. Of the environmental parameters\nconsidered, local density affects the quenched fraction of satellites the most\nat fixed central velocity dispersion. \n\n"}
{"id": "1607.03446", "contents": "Title: Unresolved versus resolved: testing the validity of young simple stellar\n  population models with VLT/MUSE observations of NGC 3603 Abstract: CONTEXT. Stellar populations are the building blocks of galaxies including\nthe Milky Way. The majority, if not all extragalactic studies are entangled\nwith the use of stellar population models given the unresolved nature of their\nobservation. Extragalactic systems contain multiple stellar populations with\ncomplex star formation histories. However, their study is mainly based upon the\nprinciples of simple stellar populations (SSP). Hence, it is critical to\nexamine the validity of SSP models. AIMS. This work aims to empirically test\nthe validity of SSP models. This is done by comparing SSP models against\nobservations of spatially resolved young stellar population in the\ndetermination of its physical properties, i.e. age and metallicity. METHODS.\nIntegral field spectroscopy of a young stellar cluster in the Milky Way, NGC\n3603, is used to study the properties of the cluster both as a resolved and\nunresolved stellar population. The unresolved stellar population is analysed\nusing the H$\\alpha$ equivalent width as an age indicator, and the ratio of\nstrong emission lines to infer metallicity. In addition, spectral energy\ndistribution (SED) fitting using STARLIGHT, is used to infer these properties\nfrom the integrated spectrum. Independently, the resolved stellar population is\nanalysed using the color-magnitude diagram (CMD) for age and metallicity\ndetermination. As the SSP model represents the unresolved stellar population,\nthe derived age and metallicity are put to test whether they agree with those\nderived from resolved stars. RESULTS. The age and metallicity estimate of NGC\n3603 derived from integrated spectroscopy are confirmed to be within the range\nof those derived from the CMD of the resolved stellar population, including\nother estimates found in the literature. The result from this pilot study\nsupports the reliability of SSP models for studying unresolved young stellar\npopulations. \n\n"}
{"id": "1607.04637", "contents": "Title: Inference of Unresolved Point Sources At High Galactic Latitudes Using\n  Probabilistic Catalogs Abstract: Detection of point sources in images is a fundamental operation in\nastrophysics, and is crucial for constraining population models of the\nunderlying point sources or characterizing the background emission. Standard\ntechniques fall short in the crowded-field limit, losing sensitivity to faint\nsources and failing to track their covariance with close neighbors. We\nconstruct a Bayesian framework to perform inference of faint or overlapping\npoint sources. The method involves probabilistic cataloging, where samples are\ntaken from the posterior probability distribution of catalogs consistent with\nan observed photon count map. In order to validate our method we sample random\ncatalogs of the gamma-ray sky in the direction of the North Galactic Pole (NGP)\nby binning the data in energy and Point Spread Function (PSF) classes. Using\nthree energy bins spanning $0.3 - 1$, $1 - 3$ and $3 - 10$ GeV, we identify\n$270\\substack{+30 \\\\ -10}$ point sources inside a $40^\\circ \\times 40^\\circ$\nregion around the NGP above our point-source inclusion limit of $3 \\times\n10^{-11}$/cm$^2$/s/sr/GeV at the $1-3$ GeV energy bin. Modeling the flux\ndistribution as a power law, we infer the slope to be $-1.92\\substack{+0.07 \\\\\n-0.05}$ and estimate the contribution of point sources to the total emission as\n$18\\substack{+2 \\\\ -2}$\\%. These uncertainties in the flux distribution are\nfully marginalized over the number as well as the spatial and spectral\nproperties of the unresolved point sources. This marginalization allows a\nrobust test of whether the apparently isotropic emission in an image is due to\nunresolved point sources or of truly diffuse origin. \n\n"}
{"id": "1607.05406", "contents": "Title: Galaxy-Galaxy Weak Lensing Measurements from SDSS: I. Image Processing\n  and Lensing signals Abstract: As the first paper in a series on the study of the galaxy-galaxy lensing from\nSloan Digital Sky Survey Data Release 7 (SDSS DR7), we present our image\nprocessing pipeline that corrects the systematics primarily introduced by the\nPoint Spread Function (PSF). Using this pipeline, we processed SDSS DR7 imaging\ndata in $r$ band and generated a background galaxy catalog containing the shape\ninformation of each galaxy. Based on our own shape measurements of the galaxy\nimages from SDSS DR7, we extract the galaxy-galaxy (GG) lensing signals around\nforeground spectroscopic galaxies binned in different luminosity and stellar\nmass. The overall signals are in good agreement with those obtained by\n\\citet{Mandelbaum2005, Mandelbaum2006} from the SDSS DR4. The results in this\npaper with higher signal to noise ratio is due to the larger survey area than\nSDSS DR4, confirm that more luminous/massive galaxies bear stronger GG lensing\nsignal. We also divide the foreground galaxies into red/blue and star\nforming/quenched subsamples and measured their GG lensing signals,\nrespectively. We find that, at a specific stellar mass/luminosity, the\nred/quenched galaxies have relatively stronger GG lensing signals than their\ncounterparts especially at large radii. These GG lensing signals can be used to\nprobe the galaxy-halo mass relations and their environmental dependences in the\nhalo occupation or conditional luminosity function framework. \n\n"}
{"id": "1607.05706", "contents": "Title: Born-Infeld condensate as a possible origin of neutrino masses and dark\n  energy Abstract: We discuss the possibility that a Born-Infeld condensate coupled to neutrinos\ncan generate both neutrino masses and an effective cosmological constant. In\nparticular, an effective field theory is provided capable of dynamically\nrealizing the neutrino superfluid phase firstly suggested by Ginzburg and\nZharkov. In such a case, neutrinos acquire a mass gap inside the Born-Infeld\nether forming a long-range Cooper pair. Phenomenological implications of the\napproach are also discussed. \n\n"}
{"id": "1607.08247", "contents": "Title: On the decreasing fraction of Strong Ly$\\alpha$ Emitters around $z$\n  $\\sim$ $6$-$7$ Abstract: The fraction of galaxies with strong Ly$\\alpha$ emission has been observed to\ndecrease rapidly with redshift at $z \\ge 6$, after a gradual increase at $z<\n6$. This has been interpreted as a hint of the reionization of the\nintergalactic medium (IGM): the emitted Ly$\\alpha$ photons would be scattered\nby an increasingly neutral IGM at $z>6$. We study this effect by modeling the\nionization and Ly$\\alpha$ radiative transfer in the infall region and the IGM\naround a Ly$\\alpha$ emitting galaxy (LAE), for a spherical halo model with the\nmean density and radial velocity profiles in the standard $\\Lambda$CDM\ncosmological scenario. We find that the expected fast increase of the ionizing\nbackground intensity toward the end of the reionization epoch implies a rapid\nevolution of halo infall regions from being self-shielded against the external\nionizing background to being mostly ionized. Whereas self-shielded infall\nregions can scatter the Ly$\\alpha$ photons over a much larger area than the\ncommonly used apertures for observing LAEs, the same infalling gas is no longer\noptically thick to the Ly$\\alpha$ emission line after it is ionized by the\nexternal background, making the Ly$\\alpha$ emission more compact and brighter\nwithin the observed apertures. Based on this simple model, we show that the\nobserved drop in the abundance of LAEs at $z>6$ does not imply a rapid increase\nwith redshift of the fraction of the whole IGM volume that is atomic, but is\naccounted for by a rapid increase of the neutral fraction in the infall regions\naround galaxy host halos. \n\n"}
{"id": "1607.08765", "contents": "Title: Directional detection of Dark Matter with the MIcro-tpc MAtrix of\n  Chambers Abstract: Particles weakly interacting with ordinary matter, with an associated mass of\nthe order of an atomic nucleus (WIMPs), are plausible candidates for Dark\nMatter. The direct detection of an elastic collision of a target nuclei induced\nby one of these WIMPs has to be discriminated from the signal produced by the\nneutrons, which leaves the same signal in a detector. The MIMAC (MIcro-tpc\nMAtrix of Chambers) collaboration has developed an original prototype detector\nwhich combines a large pixelated Micromegas coupled with a fast,\nself-triggering, electronics. Aspects of the two-chamber module in operation in\nthe Modane Underground Laboratory are presented: calibration, characterization\nof the $^{222}$Rn progeny. A new test bench combining a MIMAC chamber with the\nCOMIMAC portable quenching line has been set up to characterize the 3D tracks\nof low energy ions in the MIMAC gas mixture: the preliminary results thereof\nare presented. Future steps are briefly discussed. \n\n"}
{"id": "1607.08818", "contents": "Title: An Opportunistic Search for ExtraTerrestrial Intelligence (SETI) with\n  the Murchison Widefield Array Abstract: A spectral line image cube generated from 115 minutes of MWA data that covers\na field of view of 400 sq. deg. around the Galactic Centre is used to perform\nthe first Search for ExtraTerrestrial Intelligence (SETI) with the Murchison\nWidefield Array. Our work constitutes the first modern SETI experiment at low\nradio frequencies, here between 103 and 133 MHz, paving the way for large-scale\nsearches with the MWA and, in the future, the low frequency Square Kilometre\nArray. Limits of a few hundred mJy/beam for narrow band emission (10 kHz) are\nderived from our data, across our 400 sq. deg. field of view. Within this\nfield, 45 exoplanets in 38 planetary systems are known. We extract spectra at\nthe locations of these systems from our image cube, to place limits on the\npresence of narrow line emission from these systems. We then derive minimum\nisotropic transmitter powers for these exoplanets; a small handful of the\nclosest objects (10s of pc) yield our best limits of order $10^{14}$ W\n(Equivalent Isotropic Radiated Power: EIRP). These limits lie above the highest\npower directional transmitters near these frequencies currently operational on\nEarth. A SETI experiment with the MWA covering the full accessible sky and its\nfull frequency range would require approximately one month of observing time.\nThe MWA frequency range, its Southern Hemisphere location on an extraordinarily\nradio quiet site, its very large field of view, and its high sensitivity make\nit a unique facility for SETI. \n\n"}
{"id": "1608.00596", "contents": "Title: Nuclear Data for Astrophysical Modeling Abstract: Nuclear physics has been playing an important role in modern astrophysics and\ncosmology. Since the early 1950's it has been successfully applied for the\ninterpretation and prediction of astrophysical phenomena. Nuclear physics\nmodels helped to explain the observed elemental and isotopic abundances and\nstar evolution and provided valuable insights on the Big Bang theory. Today,\nthe variety of elements observed in stellar surfaces, solar system and cosmic\nrays, and isotope abundances are calculated and compared with the observed\nvalues. Consequently, the overall success of the modeling critically depends on\nthe quality of underlying nuclear data that helps to bring physics of macro and\nmicro scales together. To broaden the scope of traditional nuclear astrophysics\nactivities and produce additional complementary information, I will investigate\napplicability of the U.S. Nuclear Data Program (USNDP) databases for\nastrophysical applications. EXFOR (Experimental Nuclear Reaction Data) and ENDF\n(Evaluated Nuclear Data File) libraries have large astrophysics potential; the\nformer library contains experimental data sets while the latter library\nincludes evaluated neutron cross sections. ENSDF (Evaluated Nuclear Structure\nData File) database is a primary depository of nuclear structure and decay\nrates information. The decay rates are essential in stellar nucleosynthesis\ncalculations, and these rates are evaluated using nuclear structure codes. The\nstructure evaluation codes are pure mathematical procedures that can be applied\nto diverse data samples. A brief review of astrophysical nuclear data needs has\nbeen presented. Several opportunities and the corresponding computer tools have\nbeen identified. Further work will include extensive analysis of nuclear\ndatabases and computer procedures for astrophysical calculations. \n\n"}
{"id": "1608.01624", "contents": "Title: Making maps of Cosmic Microwave Background polarization for B-mode\n  studies: the POLARBEAR example Abstract: Analysis of cosmic microwave background (CMB) datasets typically requires\nsome filtering of the raw time-ordered data. Filtering is frequently used to\nminimize the impact of low frequency noise, atmospheric contributions and/or\nscan synchronous signals on the resulting maps. In this work we explicitly\nconstruct a general filtering operator, which can unambiguously remove any set\nof unwanted modes in the data, and then amend the map-making procedure in order\nto incorporate and correct for it. We show that such an approach is\nmathematically equivalent to the solution of a problem in which the sky signal\nand unwanted modes are estimated simultaneously and the latter are marginalized\nover. We investigate the conditions under which this amended map-making\nprocedure can render an unbiased estimate of the sky signal in realistic\ncircumstances. We then study the effects of time-domain filtering on the noise\ncorrelation structure in the map domain, as well as impact it may have on the\nperformance of the popular pseudo-spectrum estimators. We conclude that\nalthough maps produced by the proposed estimators arguably provide the most\nfaithful representation of the sky possible given the data, they may not\nstraightforwardly lead to the best constraints on the power spectra of the\nunderlying sky signal and special care may need to be taken to ensure this is\nthe case. By contrast, simplified map-makers which do not explicitly correct\nfor time-domain filtering, but leave it to subsequent steps in the data\nanalysis, may perform equally well and be easier and faster to implement. We\nfocus on polarization-sensitive measurements targeting the B-mode component of\nthe CMB signal and apply the proposed methods to realistic simulations based on\ncharacteristics of an actual CMB polarization experiment, POLARBEAR. \n\n"}
{"id": "1608.05423", "contents": "Title: Photometric classification of type Ia supernovae in the SuperNova Legacy\n  Survey with supervised learning Abstract: In the era of large astronomical surveys, photometric classification of\nsupernovae (SNe) has become an important research field due to limited\nspectroscopic resources for candidate follow-up and classification. In this\nwork, we present a method to photometrically classify type Ia supernovae based\non machine learning with redshifts that are derived from the SN light-curves.\nThis method is implemented on real data from the SNLS deferred pipeline, a\npurely photometric pipeline that identifies SNe Ia at high-redshifts\n($0.2<z<1.1$).\n  Our method consists of two stages: feature extraction (obtaining the SN\nredshift from photometry and estimating light-curve shape parameters) and\nmachine learning classification. We study the performance of different\nalgorithms such as Random Forest and Boosted Decision Trees. We evaluate the\nperformance using SN simulations and real data from the first 3 years of the\nSupernova Legacy Survey (SNLS), which contains large spectroscopically and\nphotometrically classified type Ia samples. Using the Area Under the Curve\n(AUC) metric, where perfect classification is given by 1, we find that our\nbest-performing classifier (Extreme Gradient Boosting Decision Tree) has an AUC\nof $0.98$.\n  We show that it is possible to obtain a large photometrically selected type\nIa SN sample with an estimated contamination of less than $5\\%$. When applied\nto data from the first three years of SNLS, we obtain 529 events. We\ninvestigate the differences between classifying simulated SNe, and real SN\nsurvey data. In particular, we find that applying a thorough set of selection\ncuts to the SN sample is essential for good classification. This work\ndemonstrates for the first time the feasibility of machine learning\nclassification in a high-$z$ SN survey with application to real SN data. \n\n"}
{"id": "1608.06097", "contents": "Title: Core-collapse supernova progenitor constraints using the spatial\n  distributions of massive stars in local galaxies Abstract: We study the spatial correlations between the H$\\alpha$ emission and\ndifferent types of massive stars in two local galaxies, the Large Magellanic\nCloud (LMC) and Messier 33. We compare these to correlations derived for\ncore-collapse supernovae (CCSNe) in the literature to connect CCSNe of\ndifferent types with the initial masses of their progenitors and to test the\nvalidity of progenitor mass estimates which use the pixel statistics method. We\nobtain samples of evolved massive stars in both galaxies from catalogues with\ngood spatial coverage and/or completeness, and combine them with coordinates of\nmain-sequence stars in the LMC from the SIMBAD database. We calculate the\nspatial correlation of stars of different classes and spectral types with\nH$\\alpha$ emission. We also investigate the effects of distance, noise and\npositional errors on the pixel statistics method. A higher correlation with\nH$\\alpha$ emission is found to correspond to a shorter stellar lifespan, and we\nconclude that the method can be used as an indicator of the ages, and therefore\ninitial masses, of SN progenitors. We find that the spatial distributions of\ntype II-P SNe and red supergiants of appropriate initial mass ($\\gtrsim$9\n$M_{\\odot}$) are consistent with each other. We also find the distributions of\ntype Ic SNe and WN stars with initial masses $\\gtrsim$20 $M_{\\odot}$\nconsistent, while supergiants with initial masses around 15 $M_{\\odot}$ are a\nbetter match for type IIb and II-L SNe. The type Ib distribution corresponds to\nthe same stellar types as type II-P, which suggests an origin in interacting\nbinaries. On the other hand, we find that luminous blue variable stars show a\nmuch stronger correlation with H$\\alpha$ emission than do type IIn SNe. \n\n"}
{"id": "1608.06281", "contents": "Title: First Season MWA EoR Power Spectrum Results at Redshift 7 Abstract: The Murchison Widefield Array (MWA) has collected hundreds of hours of Epoch\nof Reionization (EoR) data and now faces the challenge of overcoming foreground\nand systematic contamination to reduce the data to a cosmological measurement.\nWe introduce several novel analysis techniques such as cable reflection\ncalibration, hyper-resolution gridding kernels, diffuse foreground model\nsubtraction, and quality control methods. Each change to the analysis pipeline\nis tested against a two dimensional power spectrum figure of merit to\ndemonstrate improvement. We incorporate the new techniques into a deep\nintegration of 32 hours of MWA data. This data set is used to place a\nsystematic-limited upper limit on the cosmological power spectrum of $\\Delta^2\n\\leq 2.7 \\times 10^4$ mK$^2$ at $k=0.27$ h~Mpc$^{-1}$ and $z=7.1$, consistent\nwith other published limits, and a modest improvement (factor of 1.4) over\nprevious MWA results. From this deep analysis we have identified a list of\nimprovements to be made to our EoR data analysis strategies. These improvements\nwill be implemented in the future and detailed in upcoming publications. \n\n"}
{"id": "1608.08138", "contents": "Title: Dust polarization and ISM turbulence Abstract: Perhaps the most intriguing result of Planck's dust-polarization measurements\nis the observation that the power in the E-mode polarization is twice that in\nthe B mode, as opposed to pre-Planck expectations of roughly equal dust powers\nin E and B modes. Here we show how the E- and B-mode powers depend on the\ndetailed properties of the fluctuations in the magnetized interstellar medium.\nThese fluctuations are classified into the slow, fast, and Alfv\\'en\nmagnetohydrodynamic (MHD) waves, which are determined once the ratio of gas to\nmagnetic-field pressures is specified. We also parametrize models in terms of\nthe power amplitudes and power anisotropies for the three types of waves. We\nfind that the observed EE/BB ratio (and its scale invariance) and positive TE\ncorrelation cannot be easily explained in terms of favored models for MHD\nturbulence. The observed power-law index for temperature/polarization\nfluctuations also disfavors MHD turbulence. We thus speculate that the 0.1--30\npc length scales probed by these dust-polarization measurements are not\ndescribed by MHD turbulence but, rather, probe the large-scale physics that\ndrives ISM turbulence. We develop a simple phenomenological model, based on\nrandom displacements of the magnetized fluid, that produces EE/BB $\\simeq2$ and\na positive TE cross-correlation. According to this model, the EE/BB and TE\nsignals are due to longitudinal, rather than transverse, modes in the\nrandom-displacement field, providing, perhaps, some clue to the mechanism that\nstirs the ISM. Future investigations involving the spatial dependence of the\nEE/BB ratio, TE correlation, and local departures from statistical isotropy in\ndust-polarization maps, as well as further tests of some of the assumptions in\nthis analysis, are outlined. This work may also aid in the improvement of\nforeground-separation techniques for studies of CMB polarization. \n\n"}
{"id": "1608.08539", "contents": "Title: A PSF-based approach to Kepler/K2 data - III. Search for exoplanets and\n  variable stars within the open cluster M 67 (NGC 2682) Abstract: In the third paper of this series we continue the exploitation of Kepler/K2\ndata in dense stellar fields using our PSF-based method. This work is focused\non a ~720-arcmin^2 region centred on the Solar-metallicity and Solar-age open\ncluster M 67. We extracted light curves for all detectable sources in the\nKepler channels 13 and 14, adopting our technique based on the usage of a\nhigh-angular-resolution input catalogue and target-neighbour subtraction. We\ndetrended light curves for systematic errors, and searched for variables and\nexoplanets using several tools. We found 451 variables, of which 299 are new\ndetection. Three planetary candidates were detected by our pipeline in this\nfield. Raw and detrended light curves, catalogues, and K2 stacked images used\nin this work will be released to the community. \n\n"}
{"id": "1608.08772", "contents": "Title: New Extreme Trans-Neptunian Objects: Towards a Super-Earth in the Outer\n  Solar System Abstract: We are conducting a survey for extreme solar system objects to understand\nSedna and 2012 VP113 and determine if an unknown massive planet exists in the\nouter solar system. Two new objects, 2014 SR349 and 2013 FT28, are extreme\ndetached trans-Neptunian objects, with a>150 AU and perihelia well beyond\nNeptune (q>40 AU). Both new objects have orbits with arguments of perihelia\nwithin the range of clustering of this angle for other extreme objects. One of\nthese objects, 2014 SR349, has a longitude of perihelion similar to the other\nextreme objects, but 2013 FT28 is about 180 degrees away or anti-aligned in its\nlongitude of perihelion. We also discovered the first outer Oort cloud object\nwith a perihelion beyond Neptune, 2014 FE72. We discuss these and other\ninteresting objects discovered in our ongoing survey. All the high semi-major\naxis (a>150 AU) and high perihelion (q>35 AU) bodies follow the previously\nidentified argument of perihelion clustering as first reported and explained as\nbeing from an unknown massive planet by Trujillo and Sheppard (2014), which\nsome have called Planet X or Planet 9. Finally, with the discovery of 2013\nFT28, we find that the longitude of perihelion is significantly correlated with\nthe argument of perihelion and orbit pole angle for all extreme objects. This\nprevious unnoticed correlation is further evidence of an unknown massive planet\non an eccentric inclined orbit, as extreme eccentric objects with perihelia on\nopposite sides of the sky (180 degree longitude of perihelion differences)\nwould approach the inclined eccentric planet at opposite points in their\norbits, thus making the extreme objects prefer to stay away from opposite\necliptic latitudes to avoid the planet (i.e. opposite argument of perihelia or\npole angles). \n\n"}
{"id": "1609.00716", "contents": "Title: Lectures on Inflation Abstract: Planning to explore the beginning of the Universe? A lightweight introductory\nguide to the theory of Inflation. \n\n"}
{"id": "1609.00809", "contents": "Title: The ARCHES project Abstract: ARCHES (Astronomical Resource Cross-matching for High Energy Studies) is a\nFP7-Space funded project whose aim is to provide the international astronomical\ncommunity with well-characterised multi-wavelength data in the form of spectral\nenergy distributions (SEDs) for large samples of objects extracted from the\n3XMM DR5 X-ray catalogue of serendipitous sources. The project has developed\nnew tools implementing fully probabilistic simultaneous cross-correlation of\nseveral catalogues for unresolved sources and a multi-wavelength finder for\nclusters of galaxies for extended sources. These enhanced resources have been\ntested in the framework of several science cases. \n\n"}
{"id": "1609.01363", "contents": "Title: Modelling the structure and kinematics of the Firework nebula: The\n  nature of the GK Persei nova shell and its jet-like feature Abstract: To gain a more complete understanding of the dynamics of the GK Per (1901)\nremnant faint-object high-resolution echelle spectroscopic observations and\nimaging were undertaken covering the knots which comprise the nova shell and\nthe surrounding nebulosity. New imaging from the Aristarchos telescope in\nGreece and long-slit spectra from the MES instrument at the San Pedro Martir\nobservatory in Mexico were obtained, supplemented with archival observations\nfrom several other optical telescopes. Position-velocity arrays are produced of\nthe shell, and also individual knots, and are then used for morpho-kinematic\nmodelling with the shape code. Evidence is found for the interaction of knots\nwith each other and with a wind component, most likely the periodic fast wind\nemanating from the central binary system. We find that a cylindrical shell with\na lower velocity polar structure gives the best model fit to the spectroscopy\nand imaging. We show in this work that the previously seen jet-like feature is\nof low velocity. The individual knots have irregular tail shapes; we propose\nhere that they emanate from episodic winds from ongoing dwarf nova outbursts by\nthe central system. The nova shell is cylindrical and the symmetry axis relates\nto the inclination of the central binary system. Furthermore, the cylinder axis\nis aligned with the long axis of the bipolar planetary nebula in which it is\nembedded. Thus, the central binary system is responsible for the bipolarity of\nthe planetary nebula and the cylindrical nova shell. The gradual planetary\nnebula ejecta versus sudden nova ejecta is the reason for the different degrees\nof bipolarity. We propose that the 'jet' feature is an illuminated lobe of the\nfossil planetary nebula that surrounds the nova shell. \n\n"}
{"id": "1609.03350", "contents": "Title: Gamma-ray opacity of the anisotropic stratified broad-line regions in\n  blazars Abstract: The GeV-range spectra of blazars are shaped not only by non-thermal emission\nprocesses internal to the relativistic jet but also by external pair-production\nabsorption on the thermal emission of the accretion disc and the broad-line\nregion (BLR). For the first time, we compute here the pair-production opacities\nin the GeV range produced by a realistic BLR accounting for the radial\nstratification and radiation anisotropy. Using photoionization modelling with\nthe CLOUDY code, we calculate a series of BLR models of different sizes,\ngeometries, cloud densities, column densities and metallicities. The strongest\nemission features in the model BLR are Ly$\\alpha$ and HeII Ly$\\alpha$.\nContribution of recombination continua is smaller, especially for hydrogen,\nbecause Ly continuum is efficiently trapped inside the large optical depth BLR\nclouds and converted to Lyman emission lines and higher-order recombination\ncontinua. The largest effects on the gamma-ray opacity are produced by the BLR\ngeometry and localization of the gamma-ray source. We show that when the\ngamma-ray source moves further from the central source, all the absorption\ndetails move to higher energies and the overall level of absorption drops\nbecause of decreasing incidence angles between the gamma-rays and BLR photons.\nThe observed positions of the spectral breaks can be used to measure the\ngeometry and the location of the gamma-ray emitting region relative to the BLR.\nStrong dependence on geometry means that the soft photons dominating the\npair-production opacity may be actually produced by a different population of\nBLR clouds than the bulk of the observed broad line emission. \n\n"}
{"id": "1609.03656", "contents": "Title: Supermassive Black Hole Binary Environments: Effects on the Scaling Laws\n  and Time to Detection for the Stochastic Background Abstract: One of the primary gravitational wave (GW) sources for pulsar timing arrays\n(PTAs) is the stochastic background formed by supermassive black holes binaries\n(SMBHBs). In this paper, we investigate how the environments of SMBHBs will\neffect the sensitivity of PTAs by deriving scaling laws for the signal-to-noise\nratio (SNR) of the optimal cross-correlation statistic. The presence of gas and\nstars around SMBHBs will accelerate the merger at large distances, depleting\nthe GW stochastic background at low frequencies. We show that environmental\ninteractions may delay detection by a few years or more, depending on the PTA\nconfiguration and the frequency at which the dynamical evolution transitions\nfrom being dominated by environmental effects to GW-dominated. \n\n"}
{"id": "1609.04372", "contents": "Title: QUBIC Technical Design Report Abstract: QUBIC is an instrument aiming at measuring the B mode polarisation\nanisotropies at medium scales angular scales (30-200 multipoles). The search\nfor the primordial CMB B-mode polarization signal is challenging, because of\nmany difficulties: smallness of the expected signal, instrumental systematics\nthat could possibly induce polarization leakage from the large E signal into B,\nbrighter than anticipated polarized foregrounds (dust) reducing to zero the\ninitial hope of finding sky regions clean enough to have a direct primordial\nB-modes observation. The QUBIC instrument is designed to address all aspects of\nthis challenge with a novel kind of instrument, a Bolometric Interferometer,\ncombining the background-limited sensitivity of Transition-Edge-Sensors and the\ncontrol of systematics allowed by the observation of interference fringe\npatterns, while operating at two frequencies to disentangle polarized\nforegrounds from primordial B mode polarization. Its characteristics are\ndescribed in details in this Technological Design Report. \n\n"}
{"id": "1609.05157", "contents": "Title: On the spatial distribution of neutral hydrogen in the Universe: bias\n  and shot-noise of the HI Power Spectrum Abstract: The spatial distribution of neutral hydrogen (HI) in the Universe contains a\nwealth of cosmological information. The 21 cm emission line can be used to map\nthe HI up to very high redshift and therefore reveal us something about the\nevolution of the large scale structures in the Universe. However little is\nknown about the abundance and clustering properties of the HI over cosmic time.\nMotivated by this, we build an analytic framework where the relevant parameters\nthat govern how the HI is distributed among dark matter halos can be fixed\nusing observations. At the same time we provide tools to study the column\ndensity distribution function of the HI absorbers together with their\nclustering properties. Our formalism is the first one able to account for all\nobservations at a single redshift, $z = 2.3$. The linear bias of the HI and the\nmean number density of HI sources, two main ingredients in the calculation of\nthe signal-to-noise ratio of a cosmological survey, are then discussed in\ndetail, also extrapolating the results to low and high redshift. We find that\nHI bias is relatively higher than the value reported in similar studies, but\nthe shot noise level is always sub dominant, making the HI Power Spectrum\nalways a high signal-to-noise measurements up to $z\\simeq5$ in the limit of no\ninstrumental noise and foreground contamination. \n\n"}
{"id": "1609.05901", "contents": "Title: Sensitivity to a Frequency-Dependent Circular Polarization in an\n  Isotropic Stochastic Gravitational Wave Background Abstract: We calculate the sensitivity to a circular polarization of an isotropic\nstochastic gravitational wave background (ISGWB) as a function of frequency for\nground- and space-based interferometers and observations of the cosmic\nmicrowave background. The origin of a circularly polarized ISGWB may be due to\nexotic primordial physics (i.e., parity violation in the early universe) and\nmay be strongly frequency dependent. We present calculations within a coherent\nframework which clarifies the basic requirements for sensitivity to circular\npolarization, in distinction from previous work which focused on each of these\ntechniques separately. We find that the addition of an interferometer with the\nsensitivity of the Einstein Telescope in the southern hemisphere improves the\nsensitivity of the ground-based network to circular polarization by about a\nfactor of two. The sensitivity curves presented in this paper make clear that\nthe wide range in frequencies of current and planned observations ($10^{-18}\\\n{\\rm Hz} \\lesssim f \\lesssim 100\\ {\\rm Hz}$) will be critical to determining\nthe physics that underlies any positive detection of circular polarization in\nthe ISGWB. We also identify a desert in circular polarization sensitivity for\nfrequencies between $10^{-15}\\ {\\rm Hz} \\lesssim f \\lesssim 10^{-3}\\ {\\rm Hz}$,\ngiven the inability for pulsar timing arrays and indirect-detection methods to\ndistinguish the gravitational wave polarization. \n\n"}
{"id": "1609.06728", "contents": "Title: ASTErIsM - Application of topometric clustering algorithms in automatic\n  galaxy detection and classification Abstract: We present a study on galaxy detection and shape classification using\ntopometric clustering algorithms. We first use the DBSCAN algorithm to extract,\nfrom CCD frames, groups of adjacent pixels with significant fluxes and we then\napply the DENCLUE algorithm to separate the contributions of overlapping\nsources. The DENCLUE separation is based on the localization of pattern of\nlocal maxima, through an iterative algorithm which associates each pixel to the\nclosest local maximum. Our main classification goal is to take apart elliptical\nfrom spiral galaxies. We introduce new sets of features derived from the\ncomputation of geometrical invariant moments of the pixel group shape and from\nthe statistics of the spatial distribution of the DENCLUE local maxima\npatterns. Ellipticals are characterized by a single group of local maxima,\nrelated to the galaxy core, while spiral galaxies have additional ones related\nto segments of spiral arms. We use two different supervised ensemble\nclassification algorithms, Random Forest, and Gradient Boosting. Using a sample\nof ~ 24000 galaxies taken from the Galaxy Zoo 2 main sample with spectroscopic\nredshifts, and we test our classification against the Galaxy Zoo 2 catalog. We\nfind that features extracted from our pipeline give on average an accuracy of ~\n93%, when testing on a test set with a size of 20% of our full data set, with\nfeatures deriving from the angular distribution of density attractor ranking at\nthe top of the discrimination power. \n\n"}
{"id": "1609.09075", "contents": "Title: The Pale Green Dot: A Method to Characterize Proxima Centauri b using\n  Exo-Aurorae Abstract: We examine the feasibility of detecting auroral emission from the potentially\nhabitable exoplanet Proxima Centauri b. Detection of aurorae would yield an\nindependent confirmation of the planet's existence, constrain the presence and\ncomposition of its atmosphere, and determine the planet's eccentricity and\ninclination, thereby breaking the mass-inclination degeneracy. If Proxima\nCentauri b is a terrestrial world with an Earth-like atmosphere and magnetic\nfield, we estimate the power at the 5577\\AA\\ OI auroral line is on the order of\n0.1 TW under steady-state stellar wind, or ${\\sim} 100 {\\times}$ stronger than\nthat on Earth. This corresponds to a planet-star contrast ratio of\n$10^{-6}-10^{-7}$ in a narrow band about the 5577\\AA\\ line, although higher\ncontrast ($10^{-4}-10^{-5}$) may be possible during periods of strong\nmagnetospheric disturbance (auroral power $1-10$ TW). We searched the Proxima\nCentauri b HARPS data for the 5577\\AA\\ line and for other prominent oxygen and\nnitrogen lines, but find no signal, indicating that the OI auroral line\ncontrast must be lower than $2\\times 10^{-2}$ (with power $\\lesssim$ 3,000 TW),\nconsistent with our predictions. We find that observations of 0.1 TW auroral\nemission lines are likely infeasible with current and planned telescopes.\nHowever, future observations with a space-based coronagraphic telescope or a\nground-based extremely large telescope (ELT) with a coronagraph could push\nsensitivity down to terawatt oxygen aurorae (contrast $7\\times 10^{-6}$) with\nexposure times of ${\\sim} 1$ day. If a coronagraph design contrast of $10^{-7}$\ncan be achieved with negligible instrumental noise, a future concept ELT could\nobserve steady-state auroral emission in a few nights. \n\n"}
{"id": "1610.00438", "contents": "Title: Theory of Gas Phase Scattering and Reactivity for Astrochemistry Abstract: Because of the very peculiar conditions of chemistry in many astrophysical\ngases (low densities, mostly low temperatures, kinetics-dominated chemical\nevolution), great efforts have been devoted to study molecular signatures and\nchemical evolution. While experiments are being performed in many laboratories,\nit appears that the efforts directed towards theoretical works are not as\nstrong.\n  This report deals with the present status of chemical physics/physical\nchemistry theory, for the qualitative and quantitative understanding of\nkinetics of molecular scattering, being it reactive or inelastic. By gathering\nseveral types of expertise, from applied mathematics to physical chemistry,\ndialog is made possible, as a step towards new and more adapted theoretical\nframeworks, capable of meeting the theoretical, methodological and numerical\nchallenges of kinetics-dominated gas phase chemistry in astrophysical\nenvironments.\n  A state of the art panorama is presented, alongside present-day strengths and\nshortcomings. However, coverage is not complete, being limited in this report\nto actual attendance of the workshop. Some paths towards relevant progress are\nproposed. \n\n"}
{"id": "1610.03236", "contents": "Title: Measuring Structural Parameters Through Stacking Galaxy Images Abstract: It remains challenging to detect the low surface brightness structures of\nfaint high-z galaxies, which is key to understanding the structural evolution\nof galaxies. The technique of image stacking allows us to measure the averaged\nlight profile beneath the detection limit and probe the extended structure of a\ngroup of galaxies. We carry out simulations to examine the recovery of the\naveraged surface brightness profile through stacking model HST/ACS images of a\nset of galaxies as functions of Sersic index (n), effective radius (Re) and\naxis ratio (AR). The Sersic profile best fitting the radial profile of the\nstacked image is taken as the recovered profile, in comparison with the\nintrinsic mean profile of the model galaxies. Our results show that, in\ngeneral, the structural parameters of the mean profile can be properly\ndetermined through stacking, although systematic biases need to be corrected\nwhen spreads of Re and AR are counted. We find that Sersic index is slightly\noverestimated and Re is underestimated at AR < 0.5 as the stacked image appears\nto be more compact due to the presence of inclined galaxies; the spread of Re\nbiases the stacked profile to have a higher Sersic index. We stress that the\nmeasurements of structural parameters through stacking should take these biases\ninto account. We estimate the biases in the recovered structural parameters\nfrom stacks of galaxies when the samples have distributions of Re, AR and n\nseen in local galaxies. \n\n"}
{"id": "1610.03767", "contents": "Title: Primordial Universe Inside the Black Hole and Inflation Abstract: We speculate that the early Universe was inside a primordial black hole. The\ninterior of the the black hole is a dS background and the two spacetimes are\nseparated on the surface of black hole's event horizon. We argue that this\npicture provides a natural realization of inflation without invoking the\ninflaton field. The black hole evaporation by Hawking radiation provides a\nnatural mechanism for terminating inflation so reheating and the hot big bang\ncosmology starts from the evaporation of black hole to relativistic particles.\nThe quantum gravitational fluctuations at the boundary of black hole generate\nthe nearly scale invariant scalar and tensor perturbations with the ratio of\ntensor to scalar power spectra at the order of $10^{-3}$. As the black hole\nevaporates, the radius of its event horizon shrinks and the Hubble expansion\nrate during inflation increases slowly so the quantum Hawking radiation\nprovides a novel mechanism for the violation of null energy condition in\ncosmology. \n\n"}
{"id": "1610.04365", "contents": "Title: Accurate Polarization Calibration at 800 MHz with the Green Bank\n  Telescope Abstract: Polarization leakage of foreground synchrotron emission is a critical issue\nin HI intensity mapping experiments. While the sought-after HI emission is\nunpolarized, polarized foregrounds such as Galactic and extragalactic\nsynchrotron radiation, if coupled with instrumental impurity, can mimic or\noverwhelm the HI signals. In this paper we present the methodology for\npolarization calibration at 700-900 MHz, applied on data obtained from the\nGreen Bank Telescope (GBT). We use astrophysical sources, both polarized and\nunpolarized sources including quasars and pulsars, as calibrators to\ncharacterize the polarization leakage and control systematic effects in our GBT\nHI intensity mapping project. The resulting fractional errors on polarization\nmeasurements on boresight are well controlled to within 0.6%-0.8% of their\ntotal intensity. The polarized beam patterns are measured by performing spider\nscans across both polarized quasars and pulsars. A dominant Stokes I to V\nleakage feature and secondary features of Stokes I to Q and I to U leakages in\nthe 700-900 MHz frequency range are identified. These characterizations are\nimportant for separating foreground polarization leakage from the HI 21 cm\nsignal. \n\n"}
{"id": "1610.05326", "contents": "Title: Stochastic Optics: A Scattering Mitigation Framework for Radio\n  Interferometric Imaging Abstract: Just as turbulence in the Earth's atmosphere can severely limit the angular\nresolution of optical telescopes, turbulence in the ionized interstellar medium\nfundamentally limits the resolution of radio telescopes. We present a\nscattering mitigation framework for radio imaging with very long baseline\ninterferometry (VLBI) that partially overcomes this limitation. Our framework,\n\"stochastic optics,\" derives from a simplification of strong interstellar\nscattering to separate small-scale (\"diffractive\") effects from large-scale\n(\"refractive\") effects, thereby separating deterministic and random\ncontributions to the scattering. Stochastic optics extends traditional\nsynthesis imaging by simultaneously reconstructing an unscattered image and its\nrefractive perturbations. Its advantages over direct imaging come from\nutilizing the many deterministic properties of the scattering -- such as the\ntime-averaged \"blurring,\" polarization independence, and the deterministic\nevolution in frequency and time -- while still accounting for the stochastic\nimage distortions on large scales. These distortions are identified in the\nimage reconstructions through regularization by their time-averaged power\nspectrum. Using synthetic data, we show that this framework effectively removes\nthe blurring from diffractive scattering while reducing the spurious image\nfeatures from refractive scattering. Stochastic optics can provide significant\nimprovements over existing scattering mitigation strategies and is especially\npromising for imaging the Galactic Center supermassive black hole, Sagittarius\nA*, with the Global mm-VLBI Array and with the Event Horizon Telescope. \n\n"}
{"id": "1610.06892", "contents": "Title: The Deep and Transient Universe in the SVOM Era: New Challenges and\n  Opportunities - Scientific prospects of the SVOM mission Abstract: To take advantage of the astrophysical potential of Gamma-Ray Bursts (GRBs),\nChinese and French astrophysicists have engaged the SVOM mission (Space-based\nmulti-band astronomical Variable Objects Monitor). Major advances in GRB\nstudies resulting from the synergy between space and ground observations, the\nSVOM mission implements space and ground instrumentation. The scientific\nobjectives of the mission put a special emphasis on two categories of GRBs:\nvery distant GRBs at z$>$5 which constitute exceptional cosmological probes,\nand faint/soft nearby GRBs which allow probing the nature of the progenitors\nand the physics at work in the explosion. These goals have a major impact on\nthe design of the mission: the on-board hard X-ray imager is sensitive down to\n4 keV and computes on line image and rate triggers, and the follow-up\ntelescopes on the ground are sensitive in the NIR. At the beginning of the next\ndecade, SVOM will be the main provider of GRB positions and spectral parameters\non very short time scale. The SVOM instruments will operate simultaneously with\na wide range of powerful astronomical devices. This rare instrumental\nconjunction, combined with the relevance of the scientific topics connected\nwith GRB studies, warrants a remarkable scientific return for SVOM. In\naddition, the SVOM instrumentation, primarily designed for GRB studies,\ncomposes a unique multi-wavelength observatory with rapid slew capability that\nwill find multiple applications for the whole astronomy community beyond the\nspecific objectives linked to GRBs. This report lists the scientific themes\nthat will benefit from observations made with SVOM, whether they are specific\nGRB topics, or more generally all the issues that can take advantage of the\nmulti-wavelength capabilities of SVOM. \n\n"}
{"id": "1610.07558", "contents": "Title: The Grism Lens-Amplified Survey from Space (GLASS) X. Sub-kpc resolution\n  gas-phase metallicity maps at cosmic noon behind the Hubble Frontier Fields\n  cluster MACS1149.6+2223 Abstract: (Abridged) We combine deep HST grism spectroscopy with a new Bayesian method\nto derive maps of gas-phase metallicity, nebular dust extinction, and\nstar-formation rate for 10 star-forming galaxies at high redshift\n($1.2<z<2.3$). Exploiting lensing magnification by the foreground cluster\nMACS1149.6+2223, we reach sub-kpc spatial resolution and push the stellar mass\nlimit associated with such high-z spatially resolved measurements below\n$10^8M_\\odot$ for the first time. Our maps exhibit diverse morphologies,\nindicative of various effects such as efficient radial mixing from tidal\ntorques, rapid accretion of low-metallicity gas, etc., which can affect the gas\nand metallicity distributions in individual galaxies. Based upon an exhaustive\nsample of all existing sub-kpc metallicity gradients at high-z, we find that\npredictions given by analytical chemical evolution models assuming a relatively\nextended star-formation profile in the early disk formation phase can explain\nthe majority of observed gradients, without involving galactic feedback or\nradial outflows. We observe a tentative correlation between stellar mass and\nmetallicity gradient, consistent with the downsizing galaxy formation picture\nthat more massive galaxies are more evolved into a later phase of disk growth,\nwhere they experience more coherent mass assembly at all radii and thus show\nshallower metallicity gradients. In addition, we compile a sample of\nhomogeneously cross-calibrated integrated metallicity measurements spanning\nthree orders of magnitude in stellar mass at $z\\sim1.8$. We use this sample to\nstudy the mass-metallicity relation (MZR) and test the fundamental metallicity\nrelation (FMR). The slope of the observed MZR can rule out the momentum-driven\nwind model at 3-$\\sigma$ confidence level. We find no significant offset with\nrespect to the FMR, taking into account the intrinsic scatter and measurement\nuncertainties. \n\n"}
{"id": "1610.07604", "contents": "Title: Cosmic Microwave Background Science at Commercial Airline Altitudes Abstract: Obtaining high-sensitivity measurements of degree-scale cosmic microwave\nbackground (CMB) polarization is the most direct path to detecting primordial\ngravitational waves. Robustly recovering any primordial signal from the\ndominant foreground emission will require high-fidelity observations at\nmultiple frequencies, with excellent control of systematics. We explore the\npotential for a new platform for CMB observations, the Airlander 10 hybrid air\nvehicle, to perform this task. We show that the Airlander 10 platform,\noperating at commercial airline altitudes, is well-suited to mapping\nfrequencies above 220 GHz, which are critical for cleaning CMB maps of dust\nemission. Optimizing the distribution of detectors across frequencies, we\nforecast the ability of Airlander 10 to clean foregrounds of varying complexity\nas a function of altitude, demonstrating its complementarity with both existing\n(Planck) and ongoing (C-BASS) foreground observations. This novel platform\ncould play a key role in defining our ultimate view of the polarized microwave\nsky. \n\n"}
{"id": "1610.08984", "contents": "Title: Quantitative Evaluation of Gender Bias in Astronomical Publications from\n  Citation Counts Abstract: We analyze the role of first (leading) author gender on the number of\ncitations that a paper receives, on the publishing frequency and on the\nself-citing tendency. We consider a complete sample of over 200,000\npublications from 1950 to 2015 from five major astronomy journals. We determine\nthe gender of the first author for over 70% of all publications. The fraction\nof papers which have a female first author has increased from less than 5% in\nthe 1960s to about 25% today. We find that the increase of the fraction of\npapers authored by females is slowest in the most prestigious journals such as\nScience and Nature. Furthermore, female authors write 19$\\pm$7% fewer papers in\nseven years following their first paper than their male colleagues. At all\ntimes papers with male first authors receive more citations than papers with\nfemale first authors. This difference has been decreasing with time and amounts\nto $\\sim$6% measured over the last 30 years. To account for the fact that the\nproperties of female and male first author papers differ intrinsically, we use\na random forest algorithm to control for the non-gender specific properties of\nthese papers which include seniority of the first author, number of references,\ntotal number of authors, year of publication, publication journal, field of\nstudy and region of the first author's institution. We show that papers\nauthored by females receive 10.4$\\pm$0.9% fewer citations than what would be\nexpected if the papers with the same non-gender specific properties were\nwritten by the male authors. Finally, we also find that female authors in our\nsample tend to self-cite more, but that this effect disappears when controlled\nfor non-gender specific variables. \n\n"}
{"id": "1611.00015", "contents": "Title: Searching for Planet Nine with Coadded WISE and NEOWISE-Reactivation\n  Images Abstract: A distant, as yet unseen ninth planet has been invoked to explain various\nobservations of the outer solar system. While such a 'Planet Nine', if it\nexists, is most likely to be discovered via reflected light in the optical, it\nmay emit much more strongly at 3$-$5$\\mu$m than simple blackbody predictions\nwould suggest, depending on its atmospheric properties (Fortney et al. 2016).\nAs a result, Planet Nine may be detectable at 3.4$\\mu$m with WISE, but single\nexposures are too shallow except at relatively small distances ($d_9 \\lesssim\n430$ AU). We develop a method to search for Planet Nine far beyond the W1\nsingle-exposure sensitivity, to distances as large as 800 AU, using inertial\ncoadds of W1 exposures binned into $\\sim$1 day intervals. We apply our\nmethodology to $\\sim$2000 square degrees of sky identified by Holman & Payne\n(2016) as a potentially likely Planet Nine location, based on the Fienga et al.\n(2016) Cassini ranging analysis. We do not detect a plausible Planet Nine\ncandidate, but are able to derive a detailed completeness curve, ruling out its\npresence within the parameter space searched at $W1 < 16.66$ (90%\ncompleteness). Our method uses all publicly available W1 imaging, spanning 2010\nJanuary to 2015 December, and will become more sensitive with future\nNEOWISE-Reactivation releases of additional W1 exposures. We anticipate that\nour method will be applicable to the entire high Galactic latitude sky, and we\nwill extend our search to that full footprint in the near future. \n\n"}
{"id": "1611.00428", "contents": "Title: Metastable dark energy Abstract: We build a model of metastable dark energy, in which the observed vacuum\nenergy is the value of the scalar potential at the false vacuum. The scalar\npotential is given by a sum of even self-interactions up to order six. The\ndeviation from the Minkowski vacuum is due to a term suppressed by the Planck\nscale. The decay time of the metastable vacuum can easily accommodate a mean\nlife time compatible with the age of the universe. The metastable dark energy\nis also embedded into a model with $SU(2)_R$ symmetry. The dark energy doublet\nand the dark matter doublet naturally interact with each other. A three-body\ndecay of the dark energy particle into (cold and warm) dark matter can be as\nlong as large fraction of the age of the universe, if the mediator is massive\nenough, the lower bound being at intermediate energy level some orders below\nthe grand unification scale. Such a decay shows a different form of interaction\nbetween dark matter and dark energy, and the model opens a new window to\ninvestigate the dark sector from the point-of-view of particle physics. \n\n"}
{"id": "1611.02700", "contents": "Title: The LOFAR Two-metre Sky Survey - I. Survey Description and Preliminary\n  Data Release Abstract: The LOFAR Two-metre Sky Survey (LoTSS) is a deep 120-168 MHz imaging survey\nthat will eventually cover the entire Northern sky. Each of the 3170 pointings\nwill be observed for 8 hrs, which, at most declinations, is sufficient to\nproduce ~5arcsec resolution images with a sensitivity of ~0.1mJy/beam and\naccomplish the main scientific aims of the survey which are to explore the\nformation and evolution of massive black holes, galaxies, clusters of galaxies\nand large-scale structure. Due to the compact core and long baselines of LOFAR,\nthe images provide excellent sensitivity to both highly extended and compact\nemission. For legacy value, the data are archived at high spectral and time\nresolution to facilitate subarcsecond imaging and spectral line studies. In\nthis paper we provide an overview of the LoTSS. We outline the survey strategy,\nthe observational status, the current calibration techniques, a preliminary\ndata release, and the anticipated scientific impact. The preliminary images\nthat we have released were created using a fully-automated but\ndirection-independent calibration strategy and are significantly more sensitive\nthan those produced by any existing large-area low-frequency survey. In excess\nof 44,000 sources are detected in the images that have a resolution of\n25arcsec, typical noise levels of less than 0.5 mJy/beam, and cover an area of\nover 350 square degrees in the region of the HETDEX Spring Field (right\nascension 10h45m00s to 15h30m00s and declination 45d00m00s to 57d00m00s). \n\n"}
{"id": "1611.04516", "contents": "Title: Primordial gravitational waves in supersolid inflation Abstract: Supersolid inflation is a class of inflationary theories that simultaneously\nbreaks time and space reparameterization invariance during inflation, with\ndistinctive features for the dynamics of cosmological fluctuations. We\ninvestigate concrete realizations of such a scenario, including non-minimal\ncouplings between gravity and the fields driving inflation. We focus in\nparticular on the dynamics of primordial gravitational waves and discuss how\ntheir properties depend on the pattern of symmetry breaking that we consider.\nTensor modes can have a blue spectrum, and for the first time we build models\nin which the squeezed limit of primordial tensor bispectra can be\nparametrically enhanced with respect to standard single-field scenarios. At\nleading order in a perturbative expansion, the tensor-to-scalar ratio depends\nonly on the parameter controlling the breaking of space-reparameterization. It\nis independent from the quantities controlling the breaking of\ntime-reparameterization, and this represents a difference with respect to\nstandard single-field inflationary models. \n\n"}
{"id": "1611.04826", "contents": "Title: A novel facility for reduced-gravity testing: a set-up for studying\n  low-velocity collisions into granular surfaces Abstract: This work presents an experimental design for studying low-velocity\ncollisions into granular surfaces in low-gravity. In the experiment apparatus,\nreduced-gravity is simulated by releasing a free-falling projectile into a\nsurface container with a downward acceleration less than that of Earth's\ngravity. The acceleration of the surface is controlled through the use of an\nAtwood machine, or a system of pulleys and counterweights. The starting height\nof the surface container and the initial separation distance between the\nprojectile and surface are variable and chosen to accommodate collision\nvelocities up to 20 cm/s and effective accelerations of ~0.1 - 1.0 m/s^2.\nAccelerometers, placed on the surface container and inside the projectile,\nprovide acceleration data, while high-speed cameras capture the collision and\nact as secondary data sources. The experiment is built into an existing 5.5 m\ndrop-tower frame and requires the custom design of all components, including\nthe projectile, surface sample container, release mechanism and deceleration\nsystem. Data from calibration tests verify the efficiency of the experiment's\ndeceleration system and provide a quantitative understanding of the performance\nof the Atwood system. \n\n"}
{"id": "1611.05515", "contents": "Title: Self-interacting scalar fields at high-temperature Abstract: We study two self-interacting scalar field theories in their high-temperature\nlimit using path integrals on a lattice. We first discuss the formalism and\nrecover known potentials to validate the method. We then discuss how these\ntheories can model, in the high-temperature limit, the strong interaction and\nGeneral Relativity. For the strong interaction, the model recovers the known\nphenomenology of the nearly static regime of heavy quarkonia. The model also\nexposes a possible origin for the emergence of the confinement scale from the\napproximately conformal Lagrangian. Aside from such possible insights, the main\npurpose of addressing the strong interaction here --given that more\nsophisticated approaches already exist-- is mostly to further verify the\npertinence of the model in the more complex case of General Relativity for\nwhich non-perturbative methods are not as developed. The results have important\nimplications on the nature of Dark Matter. In particular, non-perturbative\neffects naturally provide flat rotation curves for disk galaxies, without need\nfor non-baryonic matter, and explain as well other observations involving Dark\nMatter such as cluster dynamics or the dark mass of elliptical galaxies. \n\n"}
{"id": "1611.06965", "contents": "Title: Voxel datacubes for 3D visualization in Blender Abstract: The growth of computational astrophysics and complexity of multidimensional\ndatasets evidences the need for new versatile visualization tools for both\nanalysis and presentation of the data. In this work we show how to use the open\nsource software Blender as a 3D visualization tool to study and visualize\nnumerical simulation results, focusing on astrophysical hydrodynamic\nexperiments. With a datacube as input, the software can generate a volume\nrendering of the 3D data, show the evolution of a simulation in time, and do a\nfly-around camera animation to highlight the points of interest. We explain the\nprocess to import simulation outputs into Blender using the Voxel Data format,\nand how to set up a visualization scene in the software interface. This method\nallows scientists to perform a complementary visual analysis of their data, and\ndisplay their results in an appealing way, both for outreach and science\npresentations. \n\n"}
{"id": "1611.07123", "contents": "Title: Design and Operational Experience of a Microwave Cavity Axion Detector\n  for the 20-100 micro-eV Range Abstract: We describe a dark matter axion detector designed, constructed, and operated\nboth as an innovation platform for new cavity and amplifier technologies and as\na data pathfinder in the $5 - 25$ GHz range ($\\sim20-100\\: \\mu$eV). The\nplatform is small but flexible to facilitate the development of new microwave\ncavity and amplifier concepts in an operational environment. The experiment has\nrecently completed its first data production; it is the first microwave cavity\naxion search to deploy a Josephson parametric amplifier and a dilution\nrefrigerator to achieve near-quantum limited performance. \n\n"}
{"id": "1611.09459", "contents": "Title: How to Find Gravitationally Lensed Type Ia Supernovae Abstract: Type Ia supernovae (SNe Ia) that are multiply imaged by gravitational lensing\ncan extend the SN Ia Hubble diagram to very high redshifts $(z\\gtrsim 2)$,\nprobe potential SN Ia evolution, and deliver high-precision constraints on\n$H_0$, $w$, and $\\Omega_m$ via time delays. However, only one, iPTF16geu, has\nbeen found to date, and many more are needed to achieve these goals. To\nincrease the multiply imaged SN Ia discovery rate, we present a simple\nalgorithm for identifying gravitationally lensed SN Ia candidates in cadenced,\nwide-field optical imaging surveys. The technique is to look for supernovae\nthat appear to be hosted by elliptical galaxies, but that have absolute\nmagnitudes implied by the apparent hosts' photometric redshifts that are far\nbrighter than the absolute magnitudes of normal SNe Ia (the brightest type of\nsupernovae found in elliptical galaxies). Importantly, this purely photometric\nmethod does not require the ability to resolve the lensed images for discovery.\nAGN, the primary sources of contamination that affect the method, can be\ncontrolled using catalog cross-matches and color cuts. Highly magnified\ncore-collapse supernovae will also be discovered as a byproduct of the method.\nUsing a Monte Carlo simulation, we forecast that LSST can discover up to 500\nmultiply imaged SNe Ia using this technique in a 10-year $z$-band search, more\nthan an order of magnitude improvement over previous estimates (Oguri &\nMarshall 2010). We also predict that ZTF should find up to 10 multiply imaged\nSNe Ia using this technique in a 3-year $R$-band search---despite the fact that\nthis survey will not resolve a single system. \n\n"}
{"id": "1612.01528", "contents": "Title: Gaia's view of the $\\lambda$ Boo star puzzle Abstract: The evolutionary status of the chemically peculiar class of $\\lambda$ Boo\nstars has been intensely debated. It is now agreed that the $\\lambda$ Boo\nphenomenon affects A stars of all ages, from star formation to the terminal age\nmain sequence, but the cause of the chemical peculiarity is still a puzzle. We\nrevisit the debate of their ages and temperatures in order to shed light on the\nphenomenon, using the new parallaxes in Gaia Data Release 1 with existing\nHipparcos parallaxes and multicolour photometry. We find that no single\nformation mechanism is able to explain all the observations, and suggest that\nthere are multiple channels producing $\\lambda$ Boo spectra. The relative\nimportance of these channels varies with age, temperature and environment. \n\n"}
{"id": "1612.02260", "contents": "Title: Chemical evolution library for galaxy formation simulation Abstract: We have developed a software library for chemical evolution simulations of\ngalaxy formation under the simple stellar population (SSP) approximation. In\nthis library, all of the necessary components concerning chemical evolution,\nsuch as initial mass functions, stellar lifetimes, yields from type II and Ia\nsupernovae, asymptotic giant branch stars, and neutron star mergers, are\ncompiled from the literature. Various models are pre-implemented in this\nlibrary so that users can choose their favorite combination of models.\nSubroutines of this library return released energy and masses of individual\nelements depending on a given event type. Since the redistribution manner of\nthese quantities depends on the implementation of users' simulation codes, this\nlibrary leaves it up to the simulation code. As demonstrations, we carry out\nboth one-zone, closed box simulations and three-dimensional simulations of a\ncollapsing gas and dark matter system using this library. In these simulations,\nwe can easily compare the impact of individual models on the chemical evolution\nof galaxies, just by changing the control flags and parameters of the library.\nSince this library only deals with the part of chemical evolution under the SSP\napproximation, any simulation codes that use the SSP approximation -- namely\nparticle-base and mesh codes, as well as semi-analytical models -- can use it.\nThis library is named \"CELib\" after the term \"Chemical Evolution Library\" and\nis made available to the community. \n\n"}
{"id": "1612.03165", "contents": "Title: The second catalog of flaring gamma-ray sources from the Fermi All-sky\n  Variability Analysis Abstract: We present the second catalog of flaring gamma-ray sources (2FAV) detected\nwith the Fermi All-sky Variability Analysis (FAVA), a tool that blindly\nsearches for transients over the entire sky observed by the Large Area\nTelescope (LAT) on board the \\textit{Fermi} Gamma-ray Space Telescope. With\nrespect to the first FAVA catalog, this catalog benefits from a larger data\nset, the latest LAT data release (Pass 8), as well as from an improved analysis\nthat includes likelihood techniques for a more precise localization of the\ntransients. Applying this analysis on the first 7.4 years of \\textit{Fermi}\nobservations, and in two separate energy bands 0.1$-$0.8 GeV and 0.8$-$300 GeV,\na total of 4547 flares has been detected with a significance greater than\n$6\\sigma$ (before trials), on the time scale of one week. Through spatial\nclustering of these flares, 518 variable gamma-ray sources are identified.\nLikely counterparts, based on positional coincidence, have been found for 441\nsources, mostly among the blazar class of active galactic nuclei. For 77 2FAV\nsources, no likely gamma-ray counterpart has been found. For each source in the\ncatalog, we provide the time, location, and spectrum of each flaring episode.\nStudying the spectra of the flares, we observe a harder-when-brighter behavior\nfor flares associated with blazars, with the exception of BL Lac flares\ndetected in the low-energy band. The photon indexes of the flares are never\nsignificantly smaller than 1.5. For a leptonic model, and under the assumption\nof isotropy, this limit suggests that the spectrum of the freshly accelerated\nelectrons is never harder than $p\\sim$2. \n\n"}
{"id": "1612.03255", "contents": "Title: An efficient method for removing point sources from full-sky radio\n  interferometric maps Abstract: A new generation of wide-field radio interferometers designed for 21-cm\nsurveys is being built as drift scan instruments allowing them to observe large\nfractions of the sky. With large numbers of antennas and frequency channels the\nenormous instantaneous data rates of these telescopes require novel, efficient,\ndata management and analysis techniques. The $m$-mode formalism exploits the\nperiodicity of such data with the sidereal day, combined with the assumption of\nstatistical isotropy of the sky, to achieve large computational savings and\nrender optimal analysis methods computationally tractable. We present an\nextension to that work that allows us to adopt a more realistic sky model and\ntreat objects such as bright point sources. We develop a linear procedure for\ndeconvolving maps, using a Wiener filter reconstruction technique, which\nsimultaneously allows filtering of these unwanted components. We construct an\nalgorithm, based on the Sherman-Morrison-Woodbury formula, to efficiently\ninvert the data covariance matrix, as required for any optimal signal-to-noise\nweighting. The performance of our algorithm is demonstrated using simulations\nof a cylindrical transit telescope. \n\n"}
{"id": "1612.04827", "contents": "Title: Host galaxies and large-scale structures of active galactic nuclei Abstract: Our understanding of the cosmic evolution of supermassive black holes (SMBHs)\nhas been revolutionized by the advent of large multiwavelength extragalactic\nsurveys, which have enabled detailed statistical studies of the host galaxies\nand large-scale structures of active galactic nuclei (AGN). We give an overview\nof some recent results on SMBH evolution, including the connection between AGN\nactivity and star formation in galaxies, the role of galaxy mergers in fueling\nAGN activity, the nature of luminous obscured AGN, and the connection between\nAGN and their host dark matter halos. We conclude by looking to the future of\nlarge-scale extragalactic X-ray and spectroscopic surveys. \n\n"}
{"id": "1612.04834", "contents": "Title: Variable classification in the LSST era: Exploring a model for\n  quasi-periodic light curves Abstract: LSST is expected to yield ~10^7 light curves over the course of its mission,\nwhich will require a concerted effort in automated classification. Stochastic\nprocesses provide one means of quantitatively describing variability with the\npotential advantage over simple light curve statistics that the parameters may\nbe physically meaningful. Here, we survey a large sample of periodic,\nquasi-periodic, and stochastic OGLE-III variables using the damped random walk\n(DRW, CARMA(1,0)) and quasi-periodic oscillation (QPO, CARMA(2,1)) stochastic\nprocess models. The QPO model is described by an amplitude, a period, and a\ncoherence time-scale, while the DRW has only an amplitude and a time-scale. We\nfind that the periodic and quasi-periodic stellar variables are generally\nbetter described by a QPO than a DRW, while quasars are better described by the\nDRW model. There are ambiguities in interpreting the QPO coherence time due to\nnon-sinusoidal light curve shapes, signal-to-noise, error mischaracterizations,\nand cadence. Higher-order implementations of the QPO model that better capture\nlight curve shapes are necessary for the coherence time to have its implied\nphysical meaning. Independent of physical meaning, the extra parameter of the\nQPO model successfully distinguishes most of the classes of periodic and\nquasi-periodic variables we consider. \n\n"}
{"id": "1612.09202", "contents": "Title: Starobinsky Inflation: From Non-SUSY To SUGRA Realizations Abstract: We review the realization of Starobinsky-type inflation within\ninduced-gravity Supersymmetric (SUSY) and non-SUSY models. In both cases,\ninflation is in agreement with the current data and can be attained for\nsubplanckian values of the inflaton. The corresponding effective theories\nretain perturbative unitarity up to the Planck scale and the inflaton mass is\npredicted to be 3x10^13 GeV. The supergravity embedding of these models is\nachieved by employing two gauge singlet chiral supefields, a superpotential\nthat is uniquely determined by a continuous R and a discrete Zn symmetry, and\nseveral (semi)logarithmic Kaehler potentials that respect these symmetries.\nChecking various functional forms for the non-inflaton accompanying field in\nthe Kaehler potentials, we identify four cases which stabilize it without\ninvoking higher order terms. \n\n"}
{"id": "1701.01100", "contents": "Title: The Host Galaxy and Redshift of the Repeating Fast Radio Burst FRB\n  121102 Abstract: The precise localization of the repeating fast radio burst (FRB 121102) has\nprovided the first unambiguous association (chance coincidence probability\n$p\\lesssim3\\times10^{-4}$) of an FRB with an optical and persistent radio\ncounterpart. We report on optical imaging and spectroscopy of the counterpart\nand find that it is an extended ($0.6^{\\prime\\prime}-0.8^{\\prime\\prime}$)\nobject displaying prominent Balmer and [OIII] emission lines. Based on the\nspectrum and emission line ratios, we classify the counterpart as a\nlow-metallicity, star-forming, $m_{r^\\prime} = 25.1$ AB mag dwarf galaxy at a\nredshift of $z=0.19273(8)$, corresponding to a luminosity distance of 972 Mpc.\nFrom the angular size, the redshift, and luminosity, we estimate the host\ngalaxy to have a diameter $\\lesssim4$ kpc and a stellar mass of\n$M_*\\sim4-7\\times 10^{7}\\,M_\\odot$, assuming a mass-to-light ratio between 2 to\n3$\\,M_\\odot\\,L_\\odot^{-1}$. Based on the H$\\alpha$ flux, we estimate the star\nformation rate of the host to be $0.4\\,M_\\odot\\,\\mathrm{yr^{-1}}$ and a\nsubstantial host dispersion measure depth $\\lesssim 324\\,\\mathrm{pc\\,cm^{-3}}$.\nThe net dispersion measure contribution of the host galaxy to FRB 121102 is\nlikely to be lower than this value depending on geometrical factors. We show\nthat the persistent radio source at FRB 121102's location reported by Marcote\net al (2017) is offset from the galaxy's center of light by $\\sim$200 mas and\nthe host galaxy does not show optical signatures for AGN activity. If FRB\n121102 is typical of the wider FRB population and if future interferometric\nlocalizations preferentially find them in dwarf galaxies with low metallicities\nand prominent emission lines, they would share such a preference with long\ngamma ray bursts and superluminous supernovae. \n\n"}
{"id": "1701.01730", "contents": "Title: Houdini for Astrophysical Visualization Abstract: The rapid growth in scale and complexity of both computational and\nobservational astrophysics over the past decade necessitates efficient and\nintuitive methods for examining and visualizing large datasets. Here we discuss\nsome newly developed tools to import and manipulate astrophysical data into the\nthree dimensional visual effects software, {\\it Houdini}. This software is\nwidely used by visual effects artists, but a recently implemented Python API\nnow allows astronomers to more easily use Houdini as a visualization tool. This\npaper includes a description of features, work flow, and various example\nvisualizations. The project website, www.ytini.com, contains Houdini tutorials\nand links to the Python script Bitbucket repository aimed at a scientific\naudience to simplify the process of importing and rendering astrophysical data. \n\n"}
{"id": "1701.03384", "contents": "Title: Bayesian power spectrum estimation at the Epoch of Reionization Abstract: We introduce a new method for performing robust Bayesian estimation of the\nthree-dimensional spatial power spectrum at the Epoch of Reionization (EoR),\nfrom interferometric observations. The versatility of this technique allows us\nto present two approaches. First, when the observations span only a small\nnumber of independent spatial frequencies ($k$-modes) we sample directly from\nthe spherical power spectrum coefficients that describe the EoR signal\nrealisation. Second, when the number of $k$-modes to be included in the model\nbecomes large, we sample from the joint probability density of the spherical\npower spectrum and the signal coefficients, using Hamiltonian Monte Carlo\nmethods to explore this high dimensional ($\\sim$ 20000) space efficiently. This\napproach has been successfully applied to simulated observations that include\nastrophysically realistic foregrounds in a companion publication (Sims et al.\n2016). Here we focus on explaining the methodology in detail, and use simple\nforeground models to both demonstrate its efficacy, and highlight salient\nfeatures. In particular, we show that including an arbitrary flat spectrum\ncontinuum foreground that is $10^8$ times greater in power than the EoR signal\nhas no detectable impact on our parameter estimates of the EoR power spectrum\nrecovered from the data. \n\n"}
{"id": "1701.04049", "contents": "Title: Consistency relations for large-scale structures: Applications for the\n  integrated Sachs-Wolfe effect and the kinematic Sunyaev-Zeldovich effect Abstract: Consistency relations of large-scale structures provide exact nonperturbative\nresults for cross-correlations of cosmic fields in the squeezed limit. They\nonly depend on the equivalence principle and the assumption of Gaussian initial\nconditions, and remain nonzero at equal times for cross-correlations of density\nfields with velocity or momentum fields, or with the time derivative of density\nfields. We show how to apply these relations to observational probes that\ninvolve the integrated Sachs-Wolfe effect or the kinematic Sunyaev-Zeldovich\neffect. In the squeezed limit, this allows us to express the three-point\ncross-correlations, or bispectra, of two galaxy or matter density fields, or\nweak lensing convergence fields, with the secondary Cosmic Microwave Background\n(CMB) distortion in terms of products of a linear and a nonlinear power\nspectrum. In particular, we find that cross-correlations with the integrated\nSachs-Wolfe effect show a specific angular dependence. These results could be\nused to test the equivalence principle and the primordial Gaussianity, or to\ncheck the modeling of large-scale structures. \n\n"}
{"id": "1701.04057", "contents": "Title: The Solar Orbiter Mission: an Energetic Particle Perspective Abstract: Solar Orbiter is a joint ESA-NASA mission planed for launch in October 2018.\nThe science payload includes remote-sensing and in-situ instrumentation\ndesigned with the primary goal of understanding how the Sun creates and\ncontrols the heliosphere. The spacecraft will follow an elliptical orbit around\nthe Sun, with perihelion as close as 0.28 AU. During the late orbit phase the\norbital plane will reach inclinations above 30 degrees, allowing direct\nobservations of the solar polar regions. The Energetic Particle Detector (EPD)\nis an instrument suite consisting of several sensors measuring electrons,\nprotons and ions over a broad energy interval (2 keV to 15 MeV for electrons, 3\nkeV to 100 MeV for protons and few tens of keV/nuc to 450 MeV/nuc for ions),\nproviding composition, spectra, timing and anisotropy information. We present\nan overview of Solar Orbiter from the energetic particle perspective,\nsummarizing the capabilities of EPD and the opportunities that these new\nobservations will provide for understanding how energetic particles are\naccelerated during solar eruptions and how they propagate through the\nHeliosphere. \n\n"}
{"id": "1701.05566", "contents": "Title: Corral Framework: Trustworthy and Fully Functional Data Intensive\n  Parallel Astronomical Pipelines Abstract: Data processing pipelines represent an important slice of the astronomical\nsoftware library that include chains of processes that transform raw data into\nvaluable information via data reduction and analysis. In this work we present\nCorral, a Python framework for astronomical pipeline generation. Corral\nfeatures a Model-View-Controller design pattern on top of an SQL Relational\nDatabase capable of handling: custom data models; processing stages; and\ncommunication alerts, and also provides automatic quality and structural\nmetrics based on unit testing. The Model-View-Controller provides concept\nseparation between the user logic and the data models, delivering at the same\ntime multi-processing and distributed computing capabilities. Corral represents\nan improvement over commonly found data processing pipelines in Astronomy since\nthe design pattern eases the programmer from dealing with processing flow and\nparallelization issues, allowing them to focus on the specific algorithms\nneeded for the successive data transformations and at the same time provides a\nbroad measure of quality over the created pipeline. Corral and working examples\nof pipelines that use it are available to the community at\nhttps://github.com/toros-astro. \n\n"}
{"id": "1701.07747", "contents": "Title: Dipolar Dark Matter as an Effective Field Theory Abstract: Dipolar Dark Matter (DDM) is an alternative model motivated by the challenges\nfaced by the standard cold dark matter model to describe the right\nphenomenology at galactic scales. A promising realisation of DDM was recently\nproposed in the context of massive bigravity theory. The model contains dark\nmatter particles, as well as a vector field coupled to the effective composite\nmetric of bigravity. This model is completely safe in the gravitational sector\nthanks to the underlying properties of massive bigravity. In this work we\ninvestigate the exact decoupling limit of the theory, including the\ncontribution of the matter sector, and prove that it is free of ghosts in this\nlimit. We conclude that the theory is acceptable as an Effective Field Theory\nbelow the strong coupling scale. \n\n"}
{"id": "1701.07932", "contents": "Title: Searching for the 3.5 keV Line in the Deep Fields with Chandra: the 10\n  Ms observations Abstract: In this paper we report a systematic search for an emission line around 3.5\nkeV in the spectrum of the Cosmic X-ray Background using a total of $\\sim$10 Ms\nChandra observations towards the COSMOS Legacy and CDFS survey fields. We find\na marginal evidence of a feature at an energy of $\\sim$3.51 keV with a\nsignificance of 2.5-3 $\\sigma$, depending on the choice of the statistical\ntreatment. The line intensity is best fit at $8.8\\ \\pm\\ {2.9}\\times10^{-7}$ ph\ncm$^{-2}$s$^{-1}$ when using a simple $\\Delta\\chi^2$ or $10.2\\ ^{+0.2}_{-0.4}\n\\times10^{-7}$ ph cm$^{-2}$s$^{-1}$ when MCMC is used. Based on our knowledge\nof $Chandra$, and the reported detection of the line by other instruments, an\ninstrumental origin for the line remains unlikely. We cannot though rule out a\nstatistical fluctuation and in that case our results provide a 3$\\sigma$ upper\nlimit at 1.85$\\times$10$^{-6}$ ph cm$^{-2}$s$^{-1}$. We discuss the\ninterpretation of this observed line in terms of the iron line background; S\n{\\sc XVI} charge exchange as well as potentially from sterile neutrino decay.\nWe note that our detection is consistent with previous measurements of this\nline toward the Galactic center, and can be modeled as the result of sterile\nneutrino decay from the Milky Way for the dark matter distribution modeled as\nan NFW profile. For this case, we estimate a mass m$_{\\nu}\\sim$7.01 keV and a\nmixing angle sin$^2$(2$\\theta$)= 0.83--2.75 $\\times 10^{-10}$. These derived\nvalues are in agreement with independent estimates from galaxy clusters; the\nGalactic center and M31. \n\n"}
{"id": "1702.00314", "contents": "Title: Geant4 simulations of radio signals from particle showers for the SLAC\n  T-510 experiment Abstract: The SLAC T-510 experiment was designed to reproduce the physics of radio\nemission from air showers caused by ultra-high energy cosmic rays in a\ncontrolled lab experiment with the goal to test established formalisms for\nsimulation of radio emission physics: the \"end-point\" formalism and the \"ZHS\"\nformalism. Simulation results derived with these formalisms can be explained by\na superposition of magnetically induced transverse current radiation and the\nAskaryan (charge-excess) effect. Here, we present results of Geant4 simulations\nof the experiment with both formalisms, taking into account the details of the\nexperimental setup (beam energy, target geometry and material, magnetic field\nconfiguration, and refraction effects) to test this hypothesis \n\n"}
{"id": "1702.00403", "contents": "Title: Generative Adversarial Networks recover features in astrophysical images\n  of galaxies beyond the deconvolution limit Abstract: Observations of astrophysical objects such as galaxies are limited by various\nsources of random and systematic noise from the sky background, the optical\nsystem of the telescope and the detector used to record the data. Conventional\ndeconvolution techniques are limited in their ability to recover features in\nimaging data by the Shannon-Nyquist sampling theorem. Here we train a\ngenerative adversarial network (GAN) on a sample of $4,550$ images of nearby\ngalaxies at $0.01<z<0.02$ from the Sloan Digital Sky Survey and conduct\n$10\\times$ cross validation to evaluate the results. We present a method using\na GAN trained on galaxy images that can recover features from artificially\ndegraded images with worse seeing and higher noise than the original with a\nperformance which far exceeds simple deconvolution. The ability to better\nrecover detailed features such as galaxy morphology from low-signal-to-noise\nand low angular resolution imaging data significantly increases our ability to\nstudy existing data sets of astrophysical objects as well as future\nobservations with observatories such as the Large Synoptic Sky Telescope (LSST)\nand the Hubble and James Webb space telescopes. \n\n"}
{"id": "1702.02256", "contents": "Title: Acceleration of low-latency gravitational wave searches using\n  Maxwell-microarchitecture GPUs Abstract: Low-latency detections of gravitational waves (GWs) are crucial to enable\nprompt follow-up observations to astrophysical transients by conventional\ntelescopes. We have developed a low-latency pipeline using a technique called\nSummed Parallel Infinite Impulse Response (SPIIR) filtering, realized by a\nGraphic Processing Unit (GPU). In this paper, we exploit the new\n\\textit{Maxwell} memory access architecture in NVIDIA GPUs, namely the\nread-only data cache, warp-shuffle, and cross-warp atomic techniques. We report\na 3-fold speed-up over our previous implementation of this filtering technique.\nTo tackle SPIIR with relatively few filters, we develop a new GPU thread\nconfiguration with a nearly 10-fold speedup. In addition, we implement a\nmulti-rate scheme of SPIIR filtering using Maxwell GPUs. We achieve more than\n100-fold speed-up over a single core CPU for the multi-rate filtering scheme.\nThis results in an overall of 21-fold CPU usage reduction for the entire SPIIR\npipeline. \n\n"}
{"id": "1702.05487", "contents": "Title: Scalable explicit implementation of anisotropic diffusion with\n  Runge-Kutta-Legendre super-time-stepping Abstract: An important ingredient in numerical modelling of high temperature magnetised\nastrophysical plasmas is the anisotropic transport of heat along magnetic field\nlines from higher to lower temperatures.Magnetohydrodynamics (MHD) typically\ninvolves solving the hyperbolic set of conservation equations along with the\ninduction equation. Incorporating anisotropic thermal conduction requires to\nalso treat parabolic terms arising from the diffusion operator. An explicit\ntreatment of parabolic terms will considerably reduce the simulation time step\ndue to its dependence on the square of the grid resolution ($\\Delta x$) for\nstability. Although an implicit scheme relaxes the constraint on stability, it\nis difficult to distribute efficiently on a parallel architecture. Treating\nparabolic terms with accelerated super-time stepping (STS) methods has been\ndiscussed in literature but these methods suffer from poor accuracy (first\norder in time) and also have difficult-to-choose tuneable stability parameters.\nIn this work we highlight a second order (in time) Runge Kutta Legendre (RKL)\nscheme (first described by Meyer et. al. 2012) that is robust, fast and\naccurate in treating parabolic terms alongside the hyperbolic conversation\nlaws. We demonstrate its superiority over the first order super time stepping\nschemes with standard tests and astrophysical applications. We also show that\nexplicit conduction is particularly robust in handling saturated thermal\nconduction. Parallel scaling of explicit conduction using RKL scheme is\ndemonstrated up to more than $10^4$ processors. \n\n"}
{"id": "1702.07111", "contents": "Title: Performance of a continuously rotating half-wave plate on the POLARBEAR\n  telescope Abstract: A continuously rotating half-wave plate (CRHWP) is a promising tool to\nimprove the sensitivity to large angular scales in cosmic microwave background\n(CMB) polarization measurements. With a CRHWP, single detectors can measure\nthree of the Stokes parameters, $I$, $Q$ and $U$, thereby avoiding the set of\nsystematic errors that can be introduced by mismatches in the properties of\northogonal detector pairs. We focus on the implementation of CRHWPs in large\naperture telescopes (i.e. the primary mirror is larger than the current maximum\nhalf-wave plate diameter of $\\sim$0.5 m), where the CRHWP can be placed between\nthe primary mirror and focal plane. In this configuration, one needs to address\nthe intensity to polarization ($I{\\rightarrow}P$) leakage of the optics, which\nbecomes a source of 1/f noise and also causes differential gain systematics\nthat arise from CMB temperature fluctuations. In this paper, we present the\nperformance of a CRHWP installed in the POLARBEAR experiment, which employs a\nGregorian telescope with a 2.5 m primary illumination pattern. The CRHWP is\nplaced near the prime focus between the primary and secondary mirrors. We find\nthat the $I{\\rightarrow}P$ leakage is larger than the expectation from the\nphysical properties of our primary mirror, resulting in a 1/f knee of 100 mHz.\nThe excess leakage could be due to imperfections in the detector system, i.e.\ndetector non-linearity in the responsivity and time-constant. We demonstrate,\nhowever, that by subtracting the leakage correlated with the intensity signal,\nthe 1/f noise knee frequency is reduced to 32 mHz ($\\ell \\sim$39 for our scan\nstrategy), which is very promising to probe the primordial B-mode signal. We\nalso discuss methods for further noise subtraction in future projects where the\nprecise temperature control of instrumental components and the leakage\nreduction will play a key role. \n\n"}
{"id": "1702.07147", "contents": "Title: San Pedro Meeting on Wide Field Variability Surveys: Some Concluding\n  Comments Abstract: This is a written version of the closing talk at the 22nd Los Alamos Stellar\npulsation conference on wide field variability surveys. It comments on some of\nthe issues which arise from the meeting. These include the need for attention\nto photometric standardization (especially in the infrared) and the somewhat\ncontroversial problem of statistical bias in the use of parallaxes (and other\nmethods of distance determination). Some major advances in the use of pulsating\nvariables to study Galactic structure are mentioned. The paper includes a\nclarification of apparently conflicting results from classical Cepheids and RR\nLyrae stars in the inner Galaxy and bulge. The importance of understanding\nnon-periodic phenomena in variable stars,particularly AGB variables and RCB\nstars is stressed, especially for its relevance to mass-loss, in which\npulsation may only play a minor role. \n\n"}
{"id": "1703.02920", "contents": "Title: Multi-GPU maximum entropy image synthesis for radio astronomy Abstract: The maximum entropy method (MEM) is a well known deconvolution technique in\nradio-interferometry. This method solves a non-linear optimization problem with\nan entropy regularization term. Other heuristics such as CLEAN are faster but\nhighly user dependent. Nevertheless, MEM has the following advantages: it is\nunsupervised, it has a statistical basis, it has a better resolution and better\nimage quality under certain conditions. This work presents a high performance\nGPU version of non-gridding MEM, which is tested using real and simulated data.\nWe propose a single-GPU and a multi-GPU implementation for single and\nmulti-spectral data, respectively. We also make use of the Peer-to-Peer and\nUnified Virtual Addressing features of newer GPUs which allows to exploit\ntransparently and efficiently multiple GPUs. Several ALMA data sets are used to\ndemonstrate the effectiveness in imaging and to evaluate GPU performance. The\nresults show that a speedup from 1000 to 5000 times faster than a sequential\nversion can be achieved, depending on data and image size. This allows to\nreconstruct the HD142527 CO(6-5) short baseline data set in 2.1 minutes,\ninstead of 2.5 days that takes a sequential version on CPU. \n\n"}
{"id": "1703.03493", "contents": "Title: An improved algorithm for narrow-band searches of continuous\n  gravitational waves Abstract: Continuous gravitational waves signals, emitted by asymmetric spinning\nneutron stars, are among the main targets of current detectors like Advanced\nLIGO and Virgo. In the case of sources, like pulsars, which rotational\nparameters are measured through electromagnetic observations, typical searches\nassume that the gravitational wave frequency is at a given known fixed ratio\nwith respect to the star rotational frequency. For instance, for a neutron star\nrotating around one of its principal axis of inertia the gravitational signal\nfrequency would be exactly two times the rotational frequency of the star. It\nis possible, however, that this assumption is wrong. This is why search\nalgorithms able to take into account a possible small mismatch between the\ngravitational waves frequency and the frequency inferred from electromagnetic\nobservations have been developed. In this paper we present an improved pipeline\nto perform such narrow-band searches for continuous gravitational waves from\nneutron stars, about three orders of magnitude faster than previous\nimplementations. The algorithm that we have developed is based on the {\\it\n5-vectors} framework and is able to perform a fully coherent search over a\nfrequency band of width $\\mathcal{O}$(Hertz) and for hundreds of spin-down\nvalues running a few hours on a standard workstation. This new algorithm opens\nthe possibility of long coherence time searches for objects which rotational\nparameters are highly uncertain. \n\n"}
{"id": "1703.03772", "contents": "Title: How Well Do We Know The Supernova Equation of State? Abstract: We give an overview about equations of state (EOS) which are currently\navailable for simulations of core-collapse supernovae and neutron star mergers.\nA few selected important aspects of the EOS, such as the symmetry energy, the\nmaximum mass of neutron stars, and cluster formation, are confronted with\nconstraints from experiments and astrophysical observations. There are just\nvery few models which are compatible even with this very restricted set of\nconstraints. These remaining models illustrate the uncertainty of the uniform\nnuclear matter EOS at high densities. In addition, at finite temperatures the\nmedium modifications of nuclear clusters represent a conceptual challenge. In\nconclusion, there has been significant development in the recent years, but\nthere is still need for further improved general purpose EOS tables. \n\n"}
{"id": "1703.09160", "contents": "Title: COCOA Code for Creating Mock Observations of Star Cluster Models Abstract: We introduce and present results from the COCOA (Cluster simulatiOn\nComparison with ObservAtions) code that has been developed to create idealized\nmock photometric observations using results from numerical simulations of star\ncluster evolution. COCOA is able to present the output of realistic numerical\nsimulations of star clusters carried out using Monte Carlo or \\textit{N}-body\ncodes in a way that is useful for direct comparison with photometric\nobservations. In this paper, we describe the COCOA code and demonstrate its\ndifferent applications by utilizing globular cluster (GC) models simulated with\nthe MOCCA (MOnte Carlo Cluster simulAtor) code. COCOA is used to synthetically\nobserve these different GC models with optical telescopes, perform PSF\nphotometry and subsequently produce observed colour magnitude diagrams. We also\nuse COCOA to compare the results from synthetic observations of a cluster model\nthat has the same age and metallicity as the Galactic GC NGC 2808 with\nobservations of the same cluster carried out with a 2.2 meter optical\ntelescope. We find that COCOA can effectively simulate realistic observations\nand recover photometric data. COCOA has numerous scientific applications that\nmaybe be helpful for both theoreticians and observers that work on star\nclusters. Plans for further improving and developing the code are also\ndiscussed in this paper. \n\n"}
{"id": "1703.09446", "contents": "Title: Is ram-pressure stripping an efficient mechanism to remove gas in\n  galaxies? Abstract: We study how the gas in a sample of galaxies (M* > 10e9 Msun) in clusters,\nobtained in a cosmological simulation, is affected by the interaction with the\nintra-cluster medium (ICM). The dynamical state of each elemental parcel of gas\nis studied using the total energy. At z ~ 2, the galaxies in the simulation are\nevenly distributed within clusters, moving later on towards more central\nlocations. In this process, gas from the ICM is accreted and mixed with the gas\nin the galactic halo. Simultaneously, the interaction with the environment\nremoves part of the gas. A characteristic stellar mass around M* ~ 10e10 Msun\nappears as a threshold marking two differentiated behaviours. Below this mass,\ngalaxies are located at the external part of clusters and have eccentric\norbits. The effect of the interaction with the environment is marginal. Above,\ngalaxies are mainly located at the inner part of clusters with mostly radial\norbits with low velocities. In these massive systems, part of the gas, strongly\ncorrelated with the stellar mass of the galaxy, is removed. The amount of\nremoved gas is sub-dominant compared with the quantity of retained gas which is\ncontinuously influenced by the hot gas coming from the ICM. The analysis of\nindividual galaxies reveals the existence of a complex pattern of flows,\nturbulence and a constant fuelling of gas to the hot corona from the ICM that\ncould make the global effect of the interaction of galaxies with their\nenvironment to be substantially less dramatic than previously expected. \n\n"}
{"id": "1703.09673", "contents": "Title: The Sardinia Radio Telescope: From a Technological Project to a Radio\n  Observatory Abstract: [Abridged] The Sardinia Radio Telescope (SRT) is the new 64-m dish operated\nby INAF (Italy). Its active surface will allow us to observe at frequencies of\nup to 116 GHz. At the moment, three receivers, one per focal position, have\nbeen installed and tested. The SRT was officially opened in October 2013, upon\ncompletion of its technical commissioning phase. In this paper, we provide an\noverview of the main science drivers for the SRT, describe the main outcomes\nfrom the scientific commissioning of the telescope, and discuss a set of\nobservations demonstrating the SRT's scientific capabilities. One of the main\nobjectives of scientific commissioning was the identification of deficiencies\nin the instrumentation and/or in the telescope sub-systems for further\noptimization. As a result, the overall telescope performance has been\nsignificantly improved. As part of the scientific commissioning activities,\ndifferent observing modes were tested and validated, and first astronomical\nobservations were carried out to demonstrate the science capabilities of the\nSRT. In addition, we developed astronomer-oriented software tools, to support\nfuture observers on-site. The astronomical validation activities were\nprioritized based on technical readiness and scientific impact. The highest\npriority was to make the SRT available for joint observations as part of\nEuropean networks. As a result, the SRT started to participate (in shared-risk\nmode) in EVN (European VLBI Network) and LEAP (Large European Array for\nPulsars) observing sessions in early 2014. The validation of single-dish\noperations for the suite of SRT first light receivers and backends continued in\nthe following years, and was concluded with the first call for\nshared-risk/early-science observations issued at the end of 2015. \n\n"}
{"id": "1703.09937", "contents": "Title: The eShel Spectrograph: A Radial-velocity Tool at the Wise Observatory Abstract: The eShel, an off-the-shelf, fiber-fed echelle spectrograph ($R \\approx\n10,000$), was installed on the 1m telescope at the Wise observatory in Israel.\nWe report the installation of the multi-order spectrograph, and describe our\npipeline to extract stellar radial velocity from the obtained spectra. We also\nintroduce a new algorithm---UNICOR, to remove radial-velocity systematics that\ncan appear in some of the observed orders. We show that the system performance\nis close to the photon-noise limit for exposures with more than $10^7$ counts,\nwith a precision that can get better than 200 m/s for F--K stars, for which the\neShel spectral response is optimal. This makes the eShel at Wise a useful tool\nfor studying spectroscopic binaries brighter than $m_V=11$. We demonstrate this\ncapability with orbital solutions of two binaries from projects being performed\nat Wise. \n\n"}
{"id": "1704.01131", "contents": "Title: Theory of Cosmological Perturbations with Cuscuton Abstract: This paper presents the first derivation of the quadratic action for\ncurvature perturbations, $\\zeta$, within the framework of cuscuton gravity. We\nstudy the scalar cosmological perturbations sourced by a canonical single\nscalar field in the presence of cuscuton field. We identify $\\zeta$ as comoving\ncurvature with respect to the source field and we show that it retains its\nconservation characteristic on super horizon scales. The result provides an\nexplicit proof that cuscuton modification of gravity around\nFriedmann-Lemaitre-Robertson-Walker (FLRW) metric is ghost free. We also\ninvestigate the potential development of other instabilities in cuscuton\nmodels. We find that in a large class of these models, there is no generic\ninstability problem. However, depending on the details of slow-roll parameters,\nspecific models may display gradient instabilities. \n\n"}
{"id": "1704.01577", "contents": "Title: Dark Kinetic Heating of Neutron Stars and An Infrared Window On WIMPs,\n  SIMPs, and Pure Higgsinos Abstract: We identify a largely model-independent signature of dark matter interactions\nwith nucleons and electrons. Dark matter in the local galactic halo,\ngravitationally accelerated to over half the speed of light, scatters against\nand deposits kinetic energy into neutron stars, heating them to infrared\nblackbody temperatures. The resulting radiation could potentially be detected\nby the James Webb Space Telescope, the Thirty Meter Telescope, or the European\nExtremely Large Telescope. This mechanism also produces optical emission from\nneutron stars in the galactic bulge, and X-ray emission near the galactic\ncenter, because dark matter is denser in these regions. For GeV - PeV mass dark\nmatter, dark kinetic heating would initially unmask any spin-independent or\nspin-dependent dark matter-nucleon cross-sections exceeding $2 \\times 10^{-45}$\ncm$^2$, with improved sensitivity after more telescope exposure. For\nlighter-than-GeV dark matter, cross-section sensitivity scales inversely with\ndark matter mass because of Pauli blocking; for heavier-than-PeV dark matter,\nit scales linearly with mass as a result of needing multiple scatters for\ncapture. Future observations of dark sector-warmed neutron stars could\ndetermine whether dark matter annihilates in or only kinetically heats neutron\nstars. Because inelastic inter-state transitions of up to a few GeV would occur\nin relativistic scattering against nucleons, elusive inelastic dark matter like\npure Higgsinos can also be discovered. \n\n"}
{"id": "1704.02704", "contents": "Title: POLOCALC: a Novel Method to Measure the Absolute Polarization\n  Orientation of the Cosmic Microwave Background Abstract: We describe a novel method to measure the absolute orientation of the\npolarization plane of the CMB with arcsecond accuracy, enabling unprecedented\nmeasurements for cosmology and fundamental physics. Existing and planned CMB\npolarization instruments looking for primordial B-mode signals need an\nindependent, experimental method for systematics control on the absolute\npolarization orientation. The lack of such a method limits the accuracy of the\ndetection of inflationary gravitational waves, the constraining power on the\nneutrino sector through measurements of gravitational lensing of the CMB, the\npossibility of detecting Cosmic Birefringence, and the ability to measure\nprimordial magnetic fields. Sky signals used for calibration and direct\nmeasurements of the detector orientation cannot provide an accuracy better than\n1 deg. Self-calibration methods provide better accuracy, but may be affected by\nforeground signals and rely heavily on model assumptions. The POLarization\nOrientation CALibrator for Cosmology, POLOCALC, will dramatically improve\ninstrumental accuracy by means of an artificial calibration source flying on\nballoons and aerial drones. A balloon-borne calibrator will provide far-field\nsource for larger telescopes, while a drone will be used for tests and smaller\npolarimeters. POLOCALC will also allow a unique method to measure the\ntelescopes' polarized beam. It will use microwave emitters between 40 and 150\nGHz coupled to precise polarizing filters. The orientation of the source\npolarization plane will be registered to sky coordinates by star cameras and\ngyroscopes with arcsecond accuracy. This project can become a rung in the\ncalibration ladder for the field: any existing or future CMB polarization\nexperiment observing our polarization calibrator will enable measurements of\nthe polarization angle for each detector with respect to absolute sky\ncoordinates. \n\n"}
{"id": "1704.02744", "contents": "Title: Finding strong lenses in CFHTLS using convolutional neural networks Abstract: We train and apply convolutional neural networks, a machine learning\ntechnique developed to learn from and classify image data, to\nCanada-France-Hawaii Telescope Legacy Survey (CFHTLS) imaging for the\nidentification of potential strong lensing systems. An ensemble of four\nconvolutional neural networks was trained on images of simulated galaxy-galaxy\nlenses. The training sets consisted of a total of 62,406 simulated lenses and\n64,673 non-lens negative examples generated with two different methodologies.\nThe networks were able to learn the features of simulated lenses with accuracy\nof up to 99.8% and a purity and completeness of 94-100% on a test set of 2000\nsimulations. An ensemble of trained networks was applied to all of the 171\nsquare degrees of the CFHTLS wide field image data, identifying 18,861\ncandidates including 63 known and 139 other potential lens candidates. A second\nsearch of 1.4 million early type galaxies selected from the survey catalog as\npotential deflectors, identified 2,465 candidates including 117 previously\nknown lens candidates, 29 confirmed lenses/high-quality lens candidates, 266\nnovel probable or potential lenses and 2097 candidates we classify as false\npositives. For the catalog-based search we estimate a completeness of 21-28%\nwith respect to detectable lenses and a purity of 15%, with a false-positive\nrate of 1 in 671 images tested. We predict a human astronomer reviewing\ncandidates produced by the system would identify ~20 probable lenses and 100\npossible lenses per hour in a sample selected by the robot. Convolutional\nneural networks are therefore a promising tool for use in the search for lenses\nin current and forthcoming surveys such as the Dark Energy Survey and the Large\nSynoptic Survey Telescope. \n\n"}
{"id": "1704.04417", "contents": "Title: Joint Elastic Side-Scattering Lidar and Raman Lidar Measurements of\n  Aerosol Optical Properties in South East Colorado Abstract: We describe an experiment, located in south-east Colorado, USA, that measured\naerosol optical depth profiles using two Lidar techniques. Two independent\ndetectors measured scattered light from a vertical UV laser beam. One detector,\nlocated at the laser site, measured light via the inelastic Raman\nbackscattering process. This is a common method used in atmospheric science for\nmeasuring aerosol optical depth profiles. The other detector, located\napproximately 40km distant, viewed the laser beam from the side. This detector\nfeatured a 3.5m2 mirror and measured elastically scattered light in a bistatic\nLidar configuration following the method used at the Pierre Auger cosmic ray\nobservatory. The goal of this experiment was to assess and improve methods to\nmeasure atmospheric clarity, specifically aerosol optical depth profiles, for\ncosmic ray UV fluorescence detectors that use the atmosphere as a giant\ncalorimeter. The experiment collected data from September 2010 to July 2011\nunder varying conditions of aerosol loading. We describe the instruments and\ntechniques and compare the aerosol optical depth profiles measured by the Raman\nand bistatic Lidar detectors. \n\n"}
{"id": "1704.05458", "contents": "Title: A Fresh Approach to Forecasting in Astroparticle Physics and Dark Matter\n  Searches Abstract: We present a toolbox of new techniques and concepts for the efficient\nforecasting of experimental sensitivities. These are applicable to a large\nrange of scenarios in (astro-)particle physics, and based on the Fisher\ninformation formalism. Fisher information provides an answer to the question\nwhat is the maximum extractable information from a given observation?. It is a\ncommon tool for the forecasting of experimental sensitivities in many branches\nof science, but rarely used in astroparticle physics or searches for particle\ndark matter. After briefly reviewing the Fisher information matrix of general\nPoisson likelihoods, we propose very compact expressions for estimating\nexpected exclusion and discovery limits (equivalent counts method). We\ndemonstrate by comparison with Monte Carlo results that they remain\nsurprisingly accurate even deep in the Poisson regime. We show how correlated\nbackground systematics can be efficiently accounted for by a treatment based on\nGaussian random fields. Finally, we introduce the novel concept of Fisher\ninformation flux. It can be thought of as a generalization of the commonly used\nsignal-to-noise ratio, while accounting for the non-local properties and\nsaturation effects of background and instrumental uncertainties. It is a\npowerful and flexible tool ready to be used as core concept for informed\nstrategy development in astroparticle physics and searches for particle dark\nmatter. \n\n"}
{"id": "1704.07484", "contents": "Title: CRPropa 3.1 -- A low energy extension based on stochastic differential\n  equations Abstract: The propagation of charged cosmic rays through the Galactic environment\ninfluences all aspects of the observation at Earth. Energy spectrum,\ncomposition and arrival directions are changed due to deflections in magnetic\nfields and interactions with the interstellar medium. Today the transport is\nsimulated with different simulation methods either based on the solution of a\ntransport equation (multi-particle picture) or a solution of an equation of\nmotion (single-particle picture).\n  We developed a new module for the publicly available propagation software\nCRPropa 3.1, where we implemented an algorithm to solve the transport equation\nusing stochastic differential equations. This technique allows us to use a\ndiffusion tensor which is anisotropic with respect to an arbitrary magnetic\nbackground field. The source code of CRPropa is written in C++ with python\nsteering via SWIG which makes it easy to use and computationally fast.\n  In this paper, we present the new low-energy propagation code together with\nvalidation procedures that are developed to proof the accuracy of the new\nimplementation. Furthermore, we show first examples of the cosmic ray density\nevolution, which depends strongly on the ratio of the parallel\n$\\kappa_\\parallel$ and perpendicular $\\kappa_\\perp$ diffusion coefficients.\nThis dependency is systematically examined as well the influence of the\nparticle rigidity on the diffusion process. \n\n"}
{"id": "1704.07956", "contents": "Title: First and second order cosmological perturbations in light mass Galileon\n  models Abstract: In this paper, we investigate the first and second order cosmological\nperturbations in the light mass Galileon (LMG) scenario. LMG action includes\ncubic Galileon term along with the standard kinetic term and a potential which\nis added phenomenologically to achieve late time acceleration. The scalar field\nis nonminimally coupled to matter in the Einstein frame. Integral solutions of\ngrowing and decaying modes are obtained. The effect of the conformal coupling\nconstant ($\\beta$), at the perturbation level, has been studied. In this\nregard, we have studied linear power spectrum and bispectrum. Though different\nvalues of $\\beta$ has different effects on power spectrum on reduced bispectrum\nthe effect is not significant. It has been found that the redshift-space\ndistortions (RSD) data can be very useful to constrain $\\beta$. In this study\nwe consider potentials which can lead to tracker behavior of the scalar field. \n\n"}
{"id": "1705.00026", "contents": "Title: Fully Coupled Simulation of Cosmic Reionization. III. Stochastic Early\n  Reionization by the Smallest Galaxies Abstract: Previously we identified a new class of early galaxy that we estimate\ncontributes up to 30\\% of the ionizing photons responsible for reionization.\nThese are low mass halos in the range $M_h =10^{6.5}-10^{8} M_{\\odot}$ that\nhave been chemically enriched by supernova ejecta from prior Pop III star\nformation. Despite their low star formation rates, these Metal Cooling halos\n(MCs) are significant sources of ionizing radiation, especially at the onset of\nreionization, due to their high number density and ionizing escape fractions.\nHere we present a fully-coupled radiation hydrodynamic simulation of\nreionization that includes these MCs as well the more massive hydrogen atomic\nline cooling halos. Our method is novel: we perform halo finding inline with\nthe radiation hydrodynamical simulation, and assign escaping ionizing fluxes to\nhalos using a probability distribution function (PDF) measured from the\ngalaxy-resolving Renaissance Simulations. The PDF captures the mass dependence\nof the ionizing escape fraction as well as the probability that a halo is\nactively forming stars. With MCs, reionization starts earlier than if only\nhalos of $10^8 M_{\\odot}$ and above are included, however the redshift when\nreionization completes is only marginally affected as this is driven by more\nmassive galaxies. Because star formation is intermittent in MCs, the earliest\nphase of reionization exhibits a stochastic nature, with small H II regions\nforming and recombining. Only later, once halos of mass $\\sim 10^9 M_{\\odot}$\nand above begin to dominate the ionizing emissivity, does reionization proceed\nsmoothly in the usual manner deduced from previous studies. This occurs at\n$z\\approx 10$ in our simulation. \n\n"}
{"id": "1705.02007", "contents": "Title: Accelerated Parameter Estimation with DALE$\\chi$ Abstract: We consider methods for improving the estimation of constraints on a\nhigh-dimensional parameter space with a computationally expensive likelihood\nfunction. In such cases Markov chain Monte Carlo (MCMC) can take a long time to\nconverge and concentrates on finding the maxima rather than the often-desired\nconfidence contours for accurate error estimation. We employ DALE$\\chi$ (Direct\nAnalysis of Limits via the Exterior of $\\chi^2$) for determining confidence\ncontours by minimizing a cost function parametrized to incentivize points in\nparameter space which are both on the confidence limit and far from previously\nsampled points. We compare DALE$\\chi$ to the nested sampling algorithm\nimplemented in MultiNest on a toy likelihood function that is highly\nnon-Gaussian and non-linear in the mapping between parameter values and\n$\\chi^2$. We find that in high-dimensional cases DALE$\\chi$ finds the same\nconfidence limit as MultiNest using roughly an order of magnitude fewer\nevaluations of the likelihood function. DALE$\\chi$ is open-source and available\nat https://github.com/danielsf/Dalex.git. \n\n"}
{"id": "1705.02170", "contents": "Title: Exploring Cosmic Origins with CORE: The Instrument Abstract: We describe a space-borne, multi-band, multi-beam polarimeter aiming at a\nprecise and accurate measurement of the polarization of the Cosmic Microwave\nBackground. The instrument is optimized to be compatible with the strict budget\nrequirements of a medium-size space mission within the Cosmic Vision Programme\nof the European Space Agency. The instrument has no moving parts, and uses\narrays of diffraction-limited Kinetic Inductance Detectors to cover the\nfrequency range from 60 GHz to 600 GHz in 19 wide bands, in the focal plane of\na 1.2 m aperture telescope cooled at 40 K, allowing for an accurate extraction\nof the CMB signal from polarized foreground emission. The projected CMB\npolarization survey sensitivity of this instrument, after foregrounds removal,\nis 1.7 {\\mu}K$\\cdot$arcmin. The design is robust enough to allow, if needed, a\ndownscoped version of the instrument covering the 100 GHz to 600 GHz range with\na 0.8 m aperture telescope cooled at 85 K, with a projected CMB polarization\nsurvey sensitivity of 3.2 {\\mu}K$\\cdot$arcmin. \n\n"}
{"id": "1705.03285", "contents": "Title: The correct estimate of the probability of false detection of the\n  matched filter in the detection of weak signals. II. (Further results with\n  application to a set of ALMA and ATCA data) Abstract: The matched filter (MF) is one of the most popular and reliable techniques to\nthe detect signals of known structure and amplitude smaller than the level of\nthe contaminating noise. Under the assumption of stationary Gaussian noise, MF\nmaximizes the probability of detection subject to a constant probability of\nfalse detection or false alarm (PFA). This property relies upon a priori\nknowledge of the position of the searched signals, which is usually not\navailable. Recently, it has been shown that when applied in its standard form,\nMF may severely underestimate the PFA. As a consequence the statistical\nsignificance of features that belong to noise is overestimated and the\nresulting detections are actually spurious. For this reason, an alternative\nmethod of computing the PFA has been proposed that is based on the probability\ndensity function (PDF) of the peaks of an isotropic Gaussian random field. In\nthis paper we further develop this method. In particular, we discuss the\nstatistical meaning of the PFA and show that, although useful as a preliminary\nstep in a detection procedure, it is not able to quantify the actual\nreliability of a specific detection. For this reason, a new quantity is\nintroduced called the specific probability of false alarm (SPFA), which is able\nto carry out this computation. We show how this method works in targeted\nsimulations and apply it to a few interferometric maps taken with the Atacama\nLarge Millimeter/submillimeter Array (ALMA) and the Australia Telescope Compact\nArray (ATCA). We select a few potential new point sources and assign an\naccurate detection reliability to these sources. \n\n"}
{"id": "1705.05027", "contents": "Title: Ultrahigh-energy Cosmic-ray Nuclei from Black Hole Jets: Recycling\n  Galactic Cosmic Rays through Shear Acceleration Abstract: We perform Monte Carlo simulations of transrelativistic shear acceleration\ndedicated to a jet-cocoon system of active galactic nuclei. A certain fraction\nof galactic cosmic rays in a halo is entrained, and sufficiently high-energy\nparticles can be injected to the reacceleration process and further accelerated\nup to 100 EeV. We show that the shear reacceleration mechanism leads to a hard\nspectrum of escaping cosmic rays, $dL_E/dE\\propto E^{-1}-E^0$, distinct from a\nconventional $E^{-2}$ spectrum. The supersolar abundance of ultrahigh-energy\nnuclei is achieved due to injections at TeV-PeV energies. As a result, we find\nthat the highest-energy spectrum and mass composition can be reasonably\nexplained by our model without contradictions with the anisotropy data. \n\n"}
{"id": "1705.08995", "contents": "Title: Classifying initial conditions of long GRBs modeled with relativistic\n  radiation hydrodynamics Abstract: We present a method to classify initial conditions of a long gamma ray bursts\nmodel sourced by a single relativistic shock. It is based on the use of\nartificial neural networks (ANNs) that are trained with light curves (LC)\ngenerated with radiation relativistic hydrodynamics simulations. The model we\nuse consists in a single shock with a highly relativistic injected beam into a\nstratified surrounding medium with profile $1/r^2$. In the process we only\nconsider the bremsstrahlung radiation and Thomson scattering process. The\ninitial conditions we use to train the ANN are three: the rest mass density,\nLorentz factor and radiation energy density of the beam that produces the\nrelativistic shock, together with the LC generated during the process. The\nclassification selects the location of a box in the 3d parameter space that\nbetter fits a given LC, and in order to decrease the uncertainty of the\nparameters this box is refined and the classification selects a new box of\nsmaller size. \n\n"}
{"id": "1706.01202", "contents": "Title: Statistical Significance of spectral lag transition in GRB 160625B Abstract: Recently Wei et al (arXiv:1612.09425) have found evidence for a transition\nfrom positive time lags to negative time lags in the spectral lag data of GRB\n160625B. They have fit these observed lags to a sum of two components: an\nassumed functional form for intrinsic time lag due to astrophysical mechanisms\nand an energy-dependent speed of light due to quadratic and linear Loren tz\ninvariance violation (LIV) models. Here, we examine the statistical\nsignificance of the evidence for a transition to nega tive time lags. Such a\ntransition, even if present in GRB 160625B, cannot be due to an energy\ndependent speed of light as th is would contradict previous limits by some 3-4\norders of magnitude, and must therefore be of intrinsic astrophysical origin .\nWe use three different model comparison techniques: a frequentist test and two\ninformation based criteria (AIC and BIC). From the frequentist model comparison\ntest, we find that the evidence for transition in the spectral lag data is\nfavored at $3.05\\sigma$ and $3.74\\sigma$ for the linear and quadratic models\nrespectively. We find that $\\Delta$AIC and $\\Delta$BIC have values $\\gtrsim$ 10\nfor the spectral lag transition that was motivated as being due to quadratic\nLorentz invariance vio lating model pointing to \"decisive evidence\". We note\nhowever that none of the three models (including the model of intr insic\nastrophysical emission) provide a good fit to the data. \n\n"}
{"id": "1706.06389", "contents": "Title: Automated novelty detection in the WISE survey with one-class support\n  vector machines Abstract: Wide-angle photometric surveys of previously uncharted sky areas or\nwavelength regimes will always bring in unexpected sources whose existence and\nproperties cannot be easily predicted from earlier observations: novelties or\neven anomalies. Such objects can be efficiently sought for with novelty\ndetection algorithms. Here we present an application of such a method, called\none-class support vector machines (OCSVM), to search for anomalous patterns\namong sources preselected from the mid-infrared AllWISE catalogue covering the\nwhole sky. To create a model of expected data we train the algorithm on a set\nof objects with spectroscopic identifications from the SDSS DR13 database,\npresent also in AllWISE. OCSVM detects as anomalous those sources whose\npatterns - WISE photometric measurements in this case - are inconsistent with\nthe model. Among the detected anomalies we find artefacts, such as objects with\nspurious photometry due to blending, but most importantly also real sources of\ngenuine astrophysical interest. Among the latter, OCSVM has identified a sample\nof heavily reddened AGN/quasar candidates distributed uniformly over the sky\nand in a large part absent from other WISE-based AGN catalogues. It also\nallowed us to find a specific group of sources of mixed types, mostly stars and\ncompact galaxies. By combining the semi-supervised OCSVM algorithm with\nstandard classification methods it will be possible to improve the latter by\naccounting for sources which are not present in the training sample but are\notherwise well-represented in the target set. Anomaly detection adds\nflexibility to automated source separation procedures and helps verify the\nreliability and representativeness of the training samples. It should be thus\nconsidered as an essential step in supervised classification schemes to ensure\ncompleteness and purity of produced catalogues. \n\n"}
{"id": "1706.06786", "contents": "Title: An optimized algorithm for multi-scale wideband deconvolution of radio\n  astronomical images Abstract: We describe a new multi-scale deconvolution algorithm that can also be used\nin multi-frequency mode. The algorithm only affects the minor clean loop. In\nsingle-frequency mode, the minor loop of our improved multi-scale algorithm is\nover an order of magnitude faster than the CASA multi-scale algorithm, and\nproduces results of similar quality. For multi-frequency deconvolution, a\ntechnique named joined-channel cleaning is used. In this mode, the minor loop\nof our algorithm is 2-3 orders of magnitude faster than CASA MSMFS. We extend\nthe multi-scale mode with automated scale-dependent masking, which allows\nstructures to be cleaned below the noise. We describe a new scale-bias function\nfor use in multi-scale cleaning. We test a second deconvolution method that is\na variant of the MORESANE deconvolution technique, and uses a convex\noptimisation technique with isotropic undecimated wavelets as dictionary. On\nsimple, well calibrated data the convex optimisation algorithm produces\nvisually more representative models. On complex or imperfect data, the convex\noptimisation algorithm has stability issues. \n\n"}
{"id": "1707.02981", "contents": "Title: Joint Bayesian estimation of tensor and lensing B-modes in the power\n  spectrum of CMB polarization data Abstract: We investigate the performance of a simple Bayesian fitting approach to\ncorrect the cosmic microwave background (CMB) B-mode polarization for\ngravitational lensing effects in the recovered probability distribution of the\ntensor-to-scalar ratio. We perform a two-dimensional power spectrum fit of the\namplitude of the primordial B-modes (tensor-to-scalar ratio, $r$) and the\namplitude of the lensing B-modes (parameter $A_{lens}$), jointly with the\nestimation of the astrophysical foregrounds including both synchrotron and\nthermal dust emissions. Using this Bayesian framework, we forecast the ability\nof the proposed CMB space mission LiteBIRD to constrain $r$ in the presence of\nrealistic lensing and foreground contributions. We compute the joint posterior\ndistribution of $r$ and $A_{lens}$, which we improve by adopting a prior on\n$A_{lens}$ taken from the South Pole Telescope (SPT) measurement. As it applies\nto the power spectrum, this approach cannot mitigate the uncertainty on $r$\nthat is due to E-mode cosmic variance transferred to B-modes by lensing, unlike\nstandard delensing techniques that are performed on maps. However, the method\nallows to correct for the bias on $r$ induced by lensing, at the expense of a\nlarger uncertainty due to the increased volume of the parameter space. We\nquantify, for different values of the tensor-to-scalar ratio, the trade-off\nbetween bias correction and increase of uncertainty on $r$. For LiteBIRD\nsimulations, which include foregrounds and lensing contamination, we find that\ncorrecting the foreground-cleaned CMB B-mode power spectrum for the lensing\nbias, not the lensing cosmic variance, still guarantees a $3\\sigma$ detection\nof $r=5\\times 10^{-3}$. The significance of the detection is increased to\n$6\\sigma$ when the current SPT prior on $A_{lens}$ is adopted. \n\n"}
{"id": "1707.08900", "contents": "Title: Methods for compressible fluid simulation on GPUs using high-order\n  finite differences Abstract: We focus on implementing and optimizing a sixth-order finite-difference\nsolver for simulating compressible fluids on a GPU using third-order\nRunge-Kutta integration. Since graphics processing units perform well in\ndata-parallel tasks, this makes them an attractive platform for fluid\nsimulation. However, high-order stencil computation is memory-intensive with\nrespect to both main memory and the caches of the GPU. We present two\napproaches for simulating compressible fluids using 55-point and 19-point\nstencils. We seek to reduce the requirements for memory bandwidth and cache\nsize in our methods by using cache blocking and decomposing a latency-bound\nkernel into several bandwidth-bound kernels. Our fastest implementation is\nbandwidth-bound and integrates $343$ million grid points per second on a Tesla\nK40t GPU, achieving a $3.6 \\times$ speedup over a comparable hydrodynamics\nsolver benchmarked on two Intel Xeon E5-2690v3 processors. Our alternative GPU\nimplementation is latency-bound and achieves the rate of $168$ million updates\nper second. \n\n"}
{"id": "1707.09322", "contents": "Title: The Fourteenth Data Release of the Sloan Digital Sky Survey: First\n  Spectroscopic Data from the extended Baryon Oscillation Spectroscopic Survey\n  and from the second phase of the Apache Point Observatory Galactic Evolution\n  Experiment Abstract: The fourth generation of the Sloan Digital Sky Survey (SDSS-IV) has been in\noperation since July 2014. This paper describes the second data release from\nthis phase, and the fourteenth from SDSS overall (making this, Data Release\nFourteen or DR14). This release makes public data taken by SDSS-IV in its first\ntwo years of operation (July 2014-2016). Like all previous SDSS releases, DR14\nis cumulative, including the most recent reductions and calibrations of all\ndata taken by SDSS since the first phase began operations in 2000. New in DR14\nis the first public release of data from the extended Baryon Oscillation\nSpectroscopic Survey (eBOSS); the first data from the second phase of the\nApache Point Observatory (APO) Galactic Evolution Experiment (APOGEE-2),\nincluding stellar parameter estimates from an innovative data driven machine\nlearning algorithm known as \"The Cannon\"; and almost twice as many data cubes\nfrom the Mapping Nearby Galaxies at APO (MaNGA) survey as were in the previous\nrelease (N = 2812 in total). This paper describes the location and format of\nthe publicly available data from SDSS-IV surveys. We provide references to the\nimportant technical papers describing how these data have been taken (both\ntargeting and observation details) and processed for scientific use. The SDSS\nwebsite (www.sdss.org) has been updated for this release, and provides links to\ndata downloads, as well as tutorials and examples of data use. SDSS-IV is\nplanning to continue to collect astronomical data until 2020, and will be\nfollowed by SDSS-V. \n\n"}
{"id": "1708.00037", "contents": "Title: Magellan/M2FS Spectroscopy of Galaxy Clusters: Stellar Population Model\n  and Application to Abell 267 Abstract: We report the results of a pilot program to use the Magellan/M2FS\nspectrograph to survey the galactic populations and internal kinematics of\ngalaxy clusters. For this initial study, we present spectroscopic measurements\nfor $223$ quiescent galaxies observed along the line of sight to the galaxy\ncluster Abell 267 ($z\\sim0.23$). We develop a Bayesian method for modeling the\nintegrated light from each galaxy as a simple stellar population, with free\nparameters that specify redshift ($v_\\mathrm{los}/c$) and characteristic age,\nmetallicity ($\\mathrm{[Fe/H]}$), alpha-abundance ($[\\alpha/\\mathrm{Fe}]$), and\ninternal velocity dispersion ($\\sigma_\\mathrm{int}$) for individual galaxies.\nParameter estimates derived from our 1.5-hour observation of A267 have median\nrandom errors of $\\sigma_{v_\\mathrm{los}}=20\\ \\mathrm{km\\ s^{-1}}$,\n$\\sigma_{\\mathrm{Age}}=1.2\\ \\mathrm{Gyr}$, $\\sigma_{\\mathrm{[Fe/H]}}=0.11\\\n\\mathrm{dex}$, $\\sigma_{[\\alpha/\\mathrm{Fe}]}=0.07\\ \\mathrm{dex}$, and\n$\\sigma_{\\sigma_\\mathrm{int}}=20\\ \\mathrm{km\\ s^{-1}}$. In a companion paper,\nwe use these results to model the structure and internal kinematics of A267. \n\n"}
{"id": "1708.00720", "contents": "Title: Bifrost: a Python/C++ Framework for High-Throughput Stream Processing in\n  Astronomy Abstract: Radio astronomy observatories with high throughput back end instruments\nrequire real-time data processing. While computing hardware continues to\nadvance rapidly, development of real-time processing pipelines remains\ndifficult and time-consuming, which can limit scientific productivity.\nMotivated by this, we have developed Bifrost: an open-source software framework\nfor rapid pipeline development. Bifrost combines a high-level Python interface\nwith highly efficient reconfigurable data transport and a library of computing\nblocks for CPU and GPU processing. The framework is generalizable, but\ninitially it emphasizes the needs of high-throughput radio astronomy pipelines,\nsuch as the ability to process data buffers as if they were continuous streams,\nthe capacity to partition processing into distinct data sequences (e.g.,\nseparate observations), and the ability to extract specific intervals from\nbuffered data. Computing blocks in the library are designed for applications\nsuch as interferometry, pulsar dedispersion and timing, and transient search\npipelines. We describe the design and implementation of the Bifrost framework\nand demonstrate its use as the backbone in the correlation and beamforming back\nend of the Long Wavelength Array station in the Sevilleta National Wildlife\nRefuge, NM. \n\n"}
{"id": "1708.02265", "contents": "Title: Entangled de Sitter from Stringy Axionic Bell pair I: An analysis using\n  Bunch Davies vacuum Abstract: In this work, we study the quantum entanglement and compute entanglement\nentropy in de Sitter space for a bipartite quantum field theory driven by axion\noriginating from ${\\bf Type~ IIB}$ string compactification on a Calabi Yau\nthree fold (${\\bf CY^3}$) and in presence of ${\\bf NS5}$ brane. For this\ncompuation, we consider a spherical surface ${\\bf S}^2$, which divide the\nspatial slice of de Sitter (${\\bf dS_4}$) into exterior and interior sub\nregions. We also consider the initial choice of vaccum to be Bunch Davies\nstate. First we derive the solution of the wave function of axion in a\nhyperbolic open chart by constructing a suitable basis for Bunch Davies vacuum\nstate using Bogoliubov transformation. We then, derive the expression for\ndensity matrix by tracing over the exterior region. This allows us to compute\nentanglement entropy and R$\\acute{e}$nyi entropy in $3+1$ dimension. Further we\nquantify the UV finite contribution of entanglement entropy which contain the\nphysics of long range quantum correlations of our expanding universe. Finally,\nour analysis compliments the necessary condition for the violation of Bell's\ninequality in primordial cosmology due to the non vanishing entanglement\nentropy for axionic Bell pair. \n\n"}
{"id": "1708.02477", "contents": "Title: On the implementation of the spherical collapse model for dark energy\n  models Abstract: In this work we review the theory of the spherical collapse model and\ncritically analyse the aspects of the numerical implementation of its\nfundamental equations. By extending a recent work by Herrera et al. 2017, we\nshow how different aspects, such as the initial integration time, the\ndefinition of constant infinity and the criterion for the extrapolation method\n(how close the inverse of the overdensity has to be to zero at the collapse\ntime) can lead to an erroneous estimation (a few per mill error which\ntranslates to a few percent in the mass function) of the key quantity in the\nspherical collapse model: the linear critical overdensity $\\delta_{\\rm c}$,\nwhich plays a crucial role for the mass function of halos. We provide a better\nrecipe to adopt in designing a code suitable to a generic smooth dark energy\nmodel and we compare our numerical results with analytic predictions for the\nEdS and the $\\Lambda$CDM models. We further discuss the evolution of\n$\\delta_{\\rm c}$ for selected classes of dark energy models as a general test\nof the robustness of our implementation. We finally outline which modifications\nneed to be taken into account to extend the code to more general classes of\nmodels, such as clustering dark energy models and non-minimally coupled models. \n\n"}
{"id": "1708.02588", "contents": "Title: Effects of primordial black holes quantum gravity decay on galaxy\n  clustering Abstract: It has been recently suggested that small mass black holes (BHs) may become\nunstable due to quantum-gravitational effects and eventually decay, producing\nradiation, on a timescale shorter than the Hawking evaporation time. We argue\nthat the existence of a population of low-mass Primordial Black Holes (PBHs)\nacting as a fraction of the Universe dark matter component can be used to test\nproposed models of quantum decay of BHs via their effect on galaxy number\ncounts. We study what constraints future galaxy clustering measurements can set\non quantum-gravity parameters governing the BH lifetime and PBH abundance. In\ncase of no detection of such effects, this would rule out either the existence\nof a non-negligible number of small PBHs, or the BH quantum decay scenario (or\nboth). In case of independent observations of PBHs, the observables discussed\nhere could be used to study the quantum effects that modify the final fate of\nBHs. \n\n"}
{"id": "1708.04058", "contents": "Title: Science-Driven Optimization of the LSST Observing Strategy Abstract: The Large Synoptic Survey Telescope is designed to provide an unprecedented\noptical imaging dataset that will support investigations of our Solar System,\nGalaxy and Universe, across half the sky and over ten years of repeated\nobservation. However, exactly how the LSST observations will be taken (the\nobserving strategy or \"cadence\") is not yet finalized. In this\ndynamically-evolving community white paper, we explore how the detailed\nperformance of the anticipated science investigations is expected to depend on\nsmall changes to the LSST observing strategy. Using realistic simulations of\nthe LSST schedule and observation properties, we design and compute diagnostic\nmetrics and Figures of Merit that provide quantitative evaluations of different\nobserving strategies, analyzing their impact on a wide range of proposed\nscience projects. This is work in progress: we are using this white paper to\ncommunicate to each other the relative merits of the observing strategy choices\nthat could be made, in an effort to maximize the scientific value of the\nsurvey. The investigation of some science cases leads to suggestions for new\nstrategies that could be simulated and potentially adopted. Notably, we find\nmotivation for exploring departures from a spatially uniform annual tiling of\nthe sky: focusing instead on different parts of the survey area in different\nyears in a \"rolling cadence\" is likely to have significant benefits for a\nnumber of time domain and moving object astronomy projects. The communal\nassembly of a suite of quantified and homogeneously coded metrics is the vital\nfirst step towards an automated, systematic, science-based assessment of any\ngiven cadence simulation, that will enable the scheduling of the LSST to be as\nwell-informed as possible. \n\n"}
{"id": "1708.08884", "contents": "Title: Galactic Archeology with 4MOST Abstract: 4MOST is a new wide-field, high-multiplex spectroscopic survey facility for\nthe VISTA telescope of ESO. Starting in 2022, 4MOST will deploy more than 2400\nfibres in a 4.1 square degree field-of-view using a positioner based on the\ntilting spine principle. In this ontribution we give an outline of the major\nscience goals we wish to achieve with 4MOST in the area of Galactic Archeology.\nThe 4MOST Galactic Archeology surveys have been designed to address\nlong-standing and far-reaching problems in Galactic science. They are focused\non our major themes: 1) Near-field cosmology tests, 2) Chemo-dynamical\ncharacterisation of the major Milky Way stellar components, 3) The Galactic\nHalo and beyond, and 4) Discovery and characterisation of extremely metal-poor\nstars. In addition to a top-level description of the Galactic surveys we\nprovide information about how the community will be able to join 4MOST via a\ncall for Public Spectroscopic Surveys that ESO will launch. \n\n"}
{"id": "1709.00688", "contents": "Title: Current status of direct dark matter detection experiments Abstract: Much like ordinary matter, dark matter might consist of elementary particles,\nand weakly interacting massive particles are one of the prime suspects. During\nthe past decade, the sensitivity of experiments trying to directly detect them\nhas improved by three to four orders of magnitude, but solid evidence for their\nexistence is yet to come. We overview the recent progress in direct dark matter\ndetection experiments and discuss future directions. \n\n"}
{"id": "1709.02052", "contents": "Title: How do stars gain their mass? A JCMT/SCUBA-2 Transient Survey of\n  Protostars in Nearby Star Forming Regions Abstract: Most protostars have luminosities that are fainter than expected from steady\naccretion over the protostellar lifetime. The solution to this problem may lie\nin episodic mass accretion -- prolonged periods of very low accretion\npunctuated by short bursts of rapid accretion. However, the timescale and\namplitude for variability at the protostellar phase is almost entirely\nunconstrained. In \"A JCMT/SCUBA-2 Transient Survey of Protostars in Nearby Star\nForming Regions\", we are monitoring monthly with SCUBA-2 the sub-mm emission in\neight fields within nearby (<500 pc) star forming regions to measure the\naccretion variability of protostars. The total survey area of ~1.6 sq.deg.\nincludes ~105 peaks with peaks brighter than 0.5 Jy/beam (43 associated with\nembedded protostars or disks) and 237 peaks of 0.125-0.5 Jy/beam (50 with\nembedded protostars or disks). Each field has enough bright peaks for flux\ncalibration relative to other peaks in the same field, which improves upon the\nnominal flux calibration uncertainties of sub-mm observations to reach a\nprecision of ~2-3% rms, and also provides quantified confidence in any measured\nvariability. The timescales and amplitudes of any sub-mm variation will then be\nconverted into variations in accretion rate and subsequently used to infer the\nphysical causes of the variability. This survey is the first dedicated survey\nfor sub-mm variability and complements other transient surveys at optical and\nnear-IR wavelengths, which are not sensitive to accretion variability of deeply\nembedded protostars. \n\n"}
{"id": "1709.03264", "contents": "Title: Report: Performance comparison between C2075 and P100 GPU cards using\n  cosmological correlation functions Abstract: In this report, some cosmological correlation functions are used to evaluate\nthe differential performance between C2075 and P100 GPU cards. In the past, the\ncorrelation functions used in this work have been widely studied and exploited\non some previous GPU architectures. The analysis of the performance indicates\nthat a speedup in the range from 13 to 15 is achieved without any additional\noptimization process for the P100 card. \n\n"}
{"id": "1709.08228", "contents": "Title: Inspiraling Halo Accretion Mapped in Lyman-$\\alpha$ Emission around a\n  $z\\sim3$ Quasar Abstract: In an effort to search for Ly$\\alpha$ emission from circum- and intergalactic\ngas on scales of hundreds of kpc around $z\\sim3$ quasars, and thus characterise\nthe physical properties of the gas in emission, we have initiated an extensive\nfast-survey with the Multi Unit Spectroscopic Explorer (MUSE): Quasar Snapshot\nObservations with MUse: Search for Extended Ultraviolet eMission (QSO MUSEUM).\nIn this work, we report the discovery of an enormous Ly$\\alpha$ nebula (ELAN)\naround the quasar SDSS~J102009.99+104002.7 at $z=3.164$, which we followed-up\nwith deeper MUSE observations. This ELAN spans $\\sim297$ projected kpc, has an\naverage Ly$\\alpha$ surface brightness ${\\rm SB}_{\\rm Ly\\alpha}\\sim\n6.04\\times10^{-18}$ erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$ (within the $2\\sigma$\nisophote), and is associated with an additional four, previously unknown\nembedded sources: two Ly$\\alpha$ emitters and two faint active galactic nuclei\n(one Type-1 and one Type-2 quasar). By mapping at high significance the\nline-of-sight velocity in the entirety of the observed structure, we unveiled a\nlarge-scale coherent rotation-like pattern spanning $\\sim300$ km s$^{-1}$ with\na velocity dispersion of $<270$ km s$^{-1}$, which we interpret as a signature\nof the inspiraling accretion of substructures within the quasar's host halo.\nFuture multiwavelength data will complement our MUSE observations, and are\ndefinitely needed to fully characterise such a complex system. None the less,\nour observations reveal the potential of new sensitive integral-field\nspectrographs to characterise the dynamical state of diffuse gas on large\nscales in the young Universe, and thereby witness the assembly of galaxies. \n\n"}
{"id": "1709.09053", "contents": "Title: Tibet's Ali: A New Window to Detect the CMB Polarization Abstract: The Cosmic Microwave Background (CMB) Polarization plays an important role in\ncurrent cosmological studies. CMB B-mode polarization is the most effective\nprobe to primordial gravitational waves (PGWs) and a test of the inflation as\nwell as other theories of the early universe such as bouncing and cyclic\nuniverse. So far, major ground-based CMB polarization experiments are located\nin the southern hemisphere.Recently, China has launched the Ali CMB\nPolarization Telescope (AliCPT) in Tibetan Plateau to measure CMB B mode\npolarization and detect the PGWs in northern hemisphere. AliCPT include two\nstages, the first one is to build a telescope at the 5250m site (AliCPT-1) and\nthe second one is to have a more sensitive telescope at a higher altitude of\nabout 6000m (AliCPT-2). In this paper, we report the atmospherical conditions,\nsky coverage and the current infrastructure associated with AliCPT. We analyzed\nthe reanalysis data from MERRA-2 together with radiosonde data from the Ali\nMeteorological Service and found that the amount of water vapor has a heavy\nseasonal variation and October to March is the suitable observation time. We\nalso found 95/150 GHz to be feasible for AliCPT-1 and higher frequencies to be\npossible for AliCPT-2. Then we analyzed the observable sky and the target\nfields, and showed that Ali provides us a unique opportunity to observe CMB\nwith less foreground contamination in the northern hemisphere and is\ncomplementary to the existed southern CMB experiments. Together with the\ndeveloped infrastructure, we point out that Ali opens a new window for CMB\nobservation and will be one of the major sites in the world along with\nAntarctic and Atacama. \n\n"}
{"id": "1710.02428", "contents": "Title: A pixel-level model for event discovery in time-domain imaging Abstract: Difference imaging or image subtraction is a method that measures\ndifferential photometry by matching the pointing and point-spread function\n(PSF) between image frames. It is used for the detection of time-variable\nphenomena. Here we present a new category of method---CPM Difference Imaging,\nin which differences are not measured between matched images but instead\nbetween image frames and a data-driven predictive model that has been designed\nonly to predict the pointing, PSF, and detector effects but not astronomical\nvariability. In CPM Difference Imaging each pixel is modelled by the Causal\nPixel Model (CPM) originally built for modeling Kepler data, in which pixel\nvalues are predicted by a linear combination of other pixels at the same epoch\nbut far enough away such that these pixels are causally disconnected,\nastrophysically. It does not require that the user have any explicit model or\ndescription of the pointing or point-spread function of any of the images. Its\nprincipal drawback is that---in its current form---it requires an imaging\ncampaign with many epochs and fairly stable telescope pointing. The method is\napplied to simulated data and also the K2 Campaign 9 microlensing data. We show\nthat CPM Difference Imaging can detect variable objects and produce precise\ndifferentiate photometry in a crowded field. CPM Difference Imaging is capable\nof producing image differences at nearly photon-noise precision. \n\n"}
{"id": "1710.02564", "contents": "Title: Detectability of Galactic Faraday Rotation in Multi-wavelength CMB\n  Observations: A Cross-Correlation Analysis of CMB and Radio Maps Abstract: We introduce a new cross-correlation method to detect and verify the\nastrophysical origin of Faraday Rotation (FR) in multiwavelength surveys. FR is\nwell studied in radio astronomy from radio point sources but the $\\lambda^{2}$\nsuppression of FR makes detecting and accounting for this effect difficult at\nmillimeter and sub-millimeter wavelengths. Therefore statistical methods are\nused to attempt to detect FR in the cosmic microwave background (CMB). Most\nestimators of the FR power spectrum rely on single frequency data. In contrast,\nwe investigate the correlation of polarized CMB maps with FR measure maps from\nradio point sources. We show a factor of $\\sim30$ increase in sensitivity over\nsingle frequency estimators and predict detections exceeding $10\\sigma$\nsignificance for a CMB-S4 like experiment. Improvements in observations of FR\nfrom current and future radio polarization surveys will greatly increase the\nusefulness of this method. \n\n"}
{"id": "1710.03116", "contents": "Title: Coincident General Relativity Abstract: The metric-affine variational principle is applied to generate teleparallel\nand symmetric teleparallel theories of gravity. From the latter is discovered\nan exceptional class which is consistent with a vanishing affine connection.\nBased on this remarkable property, this work proposes a simpler geometrical\nformulation of General Relativity that is oblivious to the affine spacetime\nstructure, thus fundamentally depriving gravity of any inertial character. The\nresulting theory is described by the Hilbert action purged from the boundary\nterm and is more robustly underpinned by the spin-2 field theory, where an\nextra symmetry is now manifest, possibly related to the double copy structure\nof the gravity amplitudes. This construction also provides a novel starting\npoint for modified gravity theories, and the paper presents new and simple\ngeneralisations where analytical self-accelerating cosmological solutions arise\nnaturally in the early and late time universe. \n\n"}
{"id": "1710.04165", "contents": "Title: Search for tau neutrinos at PeV energies and beyond with the MAGIC\n  telescopes Abstract: The MAGIC telescopes, located at the Roque de los Muchachos Observatory (2200\na.s.l.) in the Canary Island of La Palma, are placed on the top of a mountain,\nfrom where a window of visibility of about 5 deg in zenith and 80 deg in\nazimuth is open in the direction of the surrounding ocean. This permits to\nsearch for a signature of particle showers induced by earth-skimming cosmic tau\nneutrinos in the PeV to EeV energy range arising from the ocean. We have\nstudied the response of MAGIC to such events, employing Monte Carlo simulations\nof upward-going tau neutrino showers. The analysis of the shower images shows\nthat air showers induced by tau neutrinos can be discriminated from the\nhadronic background coming from a similar direction. We have calculated the\npoint source acceptance and the expected event rates, for a sample of generic\nneutrino fluxes from photo-hadronic interactions in AGNs. The analysis of about\n30 hours of data taken toward the sea leads to a point source sensitivity for\ntau neutrinos at the level of the down-going point source analysis of the\nPierre Auger Observatory, if the AUGER observation time is dedicated to a\nsimilar amount by MAGIC. \n\n"}
{"id": "1710.05656", "contents": "Title: Adaptive ADMM in Distributed Radio Interferometric Calibration Abstract: Distributed radio interferometric calibration based on consensus optimization\nhas been shown to improve the estimation of systematic errors in radio\nastronomical observations. The intrinsic continuity of systematic errors across\nfrequency is used by a consensus polynomial to penalize traditional\ncalibration. Consensus is achieved via the use of alternating direction method\nof multipliers (ADMM) algorithm. In this paper, we extend the existing\ndistributed calibration algorithms to use ADMM with an adaptive penalty\nparameter update. Compared to a fixed penalty, its adaptive update has been\nshown to perform better in diverse applications of ADMM. In this paper, we\ncompare two such popular penalty parameter update schemes: residual balance\npenalty update and spectral penalty update (Barzilai-Borwein). We apply both\nschemes to distributed radio interferometric calibration and compare their\nperformance against ADMM with a fixed penalty parameter. Simulations show that\nboth methods of adaptive penalty update improve the convergence of ADMM but the\nspectral penalty parameter update shows more stability. \n\n"}
{"id": "1710.06624", "contents": "Title: Non-Gaussian Error Distributions of Galactic Rotation Speed Measurements Abstract: We construct the error distributions for the galactic rotation speed\n($\\Theta_0$) using 137 data points from measurements compiled in De Grijs et\nal. (arXiv:1709.02501), with all observations normalized to the galactocentric\ndistance of 8.3 kpc. We then checked (using the same procedures as in works by\nRatra et al) if the errors constructed using the weighted mean and the median\nas the estimate, obey Gaussian statistics. We find using both these estimates\nthat they have much wider tails than a Gaussian distribution. We also tried to\nfit the data to three other distributions: Cauchy, double-exponential, and\nStudents-t. The best fit is obtained using the Students-$t$ distribution for\n$n=2$ using the median value as the central estimate, corresponding to a\n$p$-value of 0.1. We also calculate the median value of $\\Theta_0$ using all\nthe data as well as using the median of each set of measurements based on the\ntracer population used. Because of the non-gaussianity of the residuals, we\npoint out that the subgroup median value, given by $\\Theta_{med}=219.65$ km/sec\nshould be used as the central estimate for $\\Theta_0$. \n\n"}
{"id": "1710.08372", "contents": "Title: Gravitational wave signals from multi-dimensional core-collapse\n  supernova explosion simulations Abstract: In this work we report briefly on the gravitational wave (GW) signal computed\nin the context of a self-consistent, 3D simulation of a core-collapse supernova\n(CCSN) explosion of a 15M$_\\odot$ progenitor star. We present a short overview\nof the GW signal, including signal amplitude, frequency distribution, and the\nenergy emitted in the form of GWs for each phase of explosion, along with\nneutrino luminosities, and discuss correlations between them. \n\n"}
{"id": "1710.08505", "contents": "Title: New ADS Functionality for the Curator Abstract: In this paper we provide an update concerning the operations of the NASA\nAstrophysics Data System (ADS), its services and user interface, and the\ncontent currently indexed in its database. As the primary information system\nused by researchers in Astronomy, the ADS aims to provide a comprehensive index\nof all scholarly resources appearing in the literature. With the current effort\nin our community to support data and software citations, we discuss what steps\nthe ADS is taking to provide the needed infrastructure in collaboration with\npublishers and data providers. A new API provides access to the ADS search\ninterface, metrics, and libraries allowing users to programmatically automate\ndiscovery and curation tasks. The new ADS interface supports a greater\nintegration of content and services with a variety of partners, including ORCID\nclaiming, indexing of SIMBAD objects, and article graphics from a variety of\npublishers. Finally, we highlight how librarians can facilitate the ingest of\ngray literature that they curate into our system. \n\n"}
{"id": "1710.09389", "contents": "Title: SDSS-IV MaNGA: Identification of active galactic nuclei in optical\n  integral field unit surveys Abstract: In this paper, we investigate 2727 galaxies observed by MaNGA as of June 2016\nto develop spatially resolved techniques for identifying signatures of active\ngalactic nuclei (AGN). We identify 303 AGN candidates. The additional spatial\ndimension imposes challenges in identifying AGN due to contamination from\ndiffuse ionized gas, extra-planar gas and photoionization by hot stars. We show\nthat the combination of spatially-resolved line diagnostic diagrams and\nadditional cuts on H$\\alpha$ surface brighness and H$\\alpha$ equivalent width\ncan distinguish between AGN-like signatures and high-metallicity galaxies with\nLINER-like spectra. Low mass galaxies with high specific star formation rates\nare particularly difficult to diagnose and routinely show diagnostic line\nratios outside of the standard star-formation locus. We develop a new\ndiagnostic -- the distance from the standard diagnostic line in the line-ratios\nspace -- to evaluate the significance of the deviation from the star-formation\nlocus. We find 173 galaxies that would not have been selected as AGN candidates\nbased on single-fibre spectral measurements but exhibit photoionization\nsignatures suggestive of AGN activity in the MaNGA resolved observations,\nunderscoring the power of large integral field unit (IFU) surveys. A complete\ncensus of these new AGN candidates is necessary to understand their nature and\nprobe the complex co-evolution of supermassive black holes and their hosts. \n\n"}
{"id": "1710.09970", "contents": "Title: StarHorse: A Bayesian tool for determining stellar masses, ages,\n  distances, and extinctions for field stars Abstract: Understanding the formation and evolution of our Galaxy requires accurate\ndistances, ages and chemistry for large populations of field stars. Here we\npresent several updates to our spectro-photometric distance code, that can now\nalso be used to estimate ages, masses, and extinctions for individual stars.\nGiven a set of measured spectro-photometric parameters, we calculate the\nposterior probability distribution over a given grid of stellar evolutionary\nmodels, using flexible Galactic stellar-population priors. The code (called\n{\\tt StarHorse}) can acommodate different observational datasets, prior\noptions, partially missing data, and the inclusion of parallax information into\nthe estimated probabilities. We validate the code using a variety of simulated\nstars as well as real stars with parameters determined from asteroseismology,\neclipsing binaries, and isochrone fits to star clusters. Our main goal in this\nvalidation process is to test the applicability of the code to field stars with\nknown {\\it Gaia}-like parallaxes. The typical internal precision (obtained from\nrealistic simulations of an APOGEE+Gaia-like sample) are $\\simeq 8\\%$ in\ndistance, $\\simeq 20\\%$ in age,$\\simeq 6\\ %$ in mass, and $\\simeq 0.04$ mag in\n$A_V$. The median external precision (derived from comparisons with earlier\nwork for real stars) varies with the sample used, but lies in the range of\n$\\simeq [0,2]\\%$ for distances, $\\simeq [12,31]\\%$ for ages, $\\simeq [4,12]\\%$\nfor masses, and $\\simeq 0.07$ mag for $A_V$. We provide StarHorse distances and\nextinctions for the APOGEE DR14, RAVE DR5, GES DR3 and GALAH DR1 catalogues. \n\n"}
{"id": "1710.10929", "contents": "Title: Constraints on the cosmic distance duality relation with simulated data\n  of gravitational waves from the Einstein Telescope Abstract: The cosmic distance duality relation (CDDR) has been test through several\nastronomical observations in the last years. This relation establishes a simple\nequation relating the angular diameter ($D_A$) and luminosity ($D_L$) distances\nat a redshift $z$, $D_LD_A^{-1}(1+z)^{-2}=\\eta=1$. However, only very recently\nthis relation has been observationally tested at high redshifts ($z \\approx\n3.6$) by using luminosity distances from type Ia supernovae (SNe Ia) and gamma\nray bursts (GRBs) plus angular diameter distances from strong gravitational\nlensing (SGL) observations. The results show that no significant deviation from\nthe CDDR validity has been verified. In this work, we test the potentialities\nof future luminosity distances from gravitational waves (GWs) sources to impose\nlimit on possible departures of CDDR jointly with current SGL observations. The\nbasic advantage of $D_L$ from GWs is being insensitive to non-conservation of\nthe number of photons. By simulating 600, 900 and 1200 data of GWs using the\nEinstein Telescope (ET) as reference, we derive limits on $\\eta(z)$ function\nand obtain that the results will be at least competitive with current limits\nfrom the SNe Ia $+$ GRBs $+$ SGLs analyses. \n\n"}
{"id": "1710.11509", "contents": "Title: Classifying GRB170817A / GW170817 in a Fermi duration - hardness plane Abstract: GRB170817A, associated with the LIGO-Virgo GW170817 neutron-star merger\nevent, lacks the short duration and hard spectrum of a Short gamma-ray burst\n(GRB) expected from long-standing classification models. Correctly identifying\nthe class to which this burst belongs requires comparison with other GRBs\ndetected by the Fermi GBM. The aim of our analysis is to classify Fermi GRBs\nand to test whether or not GRB170817A belongs - as suggested - to the Short GRB\nclass. The Fermi GBM catalog provides a large database with many measured\nvariables that can be used to explore gamma-ray burst classification. We use\nstatistical techniques to look for clustering in a sample of 1298 gamma-ray\nbursts described by duration and spectral hardness. Classification of the\ndetected bursts shows that GRB170817A most likely belongs to the Intermediate,\nrather than the Short GRB class. We discuss this result in light of theoretical\nneutron-star merger models and existing GRB classification schemes. It appears\nthat GRB classification schemes may not yet be linked to appropriate\ntheoretical models, and that theoretical models may not yet adequately account\nfor known GRB class properties. We conclude that GRB170817A may not fit into a\nsimple phenomenological classification scheme. \n\n"}
{"id": "1711.02793", "contents": "Title: Robust Statistics for Image Deconvolution Abstract: We present a blind multiframe image-deconvolution method based on robust\nstatistics. The usual shortcomings of iterative optimization of the likelihood\nfunction are alleviated by minimizing the M-scale of the residuals, which\nachieves more uniform convergence across the image. We focus on the\ndeconvolution of astronomical images, which are among the most challenging due\nto their huge dynamic ranges and the frequent presence of large noise-dominated\nregions in the images. We show that high-quality image reconstruction is\npossible even in super-resolution and without the use of traditional\nregularization terms. Using a robust \\r{ho}-function is straightforward to\nimplement in a streaming setting and, hence our method is applicable to the\nlarge volumes of astronomy images. The power of our method is demonstrated on\nobservations from the Sloan Digital Sky Survey (Stripe 82) and we briefly\ndiscuss the feasibility of a pipeline based on Graphical Processing Units for\nthe next generation of telescope surveys. \n\n"}
{"id": "1711.03173", "contents": "Title: Global 21-cm signal extraction from foreground and instrumental effects\n  I: Pattern recognition framework for separation using training sets Abstract: The sky-averaged (global) highly redshifted 21-cm spectrum from neutral\nhydrogen is expected to appear in the VHF range of $\\sim20-200$ MHz and its\nspectral shape and strength are determined by the heating properties of the\nfirst stars and black holes, by the nature and duration of reionization, and by\nthe presence or absence of exotic physics. Measurements of the global signal\nwould therefore provide us with a wealth of astrophysical and cosmological\nknowledge. However, the signal has not yet been detected because it must be\nseen through strong foregrounds weighted by a large beam, instrumental\ncalibration errors, and ionospheric, ground and radio-frequency-interference\neffects, which we collectively refer to as \"systematics\". Here, we present a\nsignal extraction method for global signal experiments which uses Singular\nValue Decomposition (SVD) of \"training sets\" to produce systematics basis\nfunctions specifically suited to each observation. Instead of requiring precise\nabsolute knowledge of the systematics, our method effectively requires precise\nknowledge of how the systematics can vary. After calculating eigenmodes for the\nsignal and systematics, we perform a weighted least square fit of the\ncorresponding coefficients and select the number of modes to include by\nminimizing an information criterion. We compare the performance of the signal\nextraction when minimizing various information criteria and find that\nminimizing the Deviance Information Criterion (DIC) most consistently yields\nunbiased fits. The methods used here are built into our widely applicable,\npublicly available Python package, $\\texttt{pylinex}$, which analytically\ncalculates constraints on signals and systematics from given data, errors, and\ntraining sets. \n\n"}
{"id": "1711.07421", "contents": "Title: On the Signal Processing Operations in LIGO signals Abstract: This article analyzes the data for the five gravitational wave (GW) events\ndetected in Hanford(H1), Livingston(L1) and Virgo(V1) detectors by the LIGO\ncollaboration. It is shown that GW170814, GW170817, GW151226 and GW170104 are\nvery weak signals whose amplitude does not rise significantly during the GW\nevent, and they are indistinguishable from non-stationary detector noise. LIGO\nsoftware implements cross-correlation funcion(CCF) of H1/L1 signals with the\ntemplate reference signal, in frequency domain, in a matched filter, using 32\nsecond windows. It is shown that this matched filter misfires with high SNR/CCF\npeaks, even for very low-amplitude, short bursts of sine wave signals and\nadditive white gaussian noise(AWGN), all the time. It is shown that this\nerratic behaviour of the matched filter, is due to the error in signal\nprocessing operations, such as lack of cyclic prefix necessary to account for\ncircular convolution. It is also shown that normalized CCF method implemented\nin time domain using short windows, does not have false CCF peaks for sine wave\nand noise bursts. It is shown that the normalized CCF for GW151226 and\nGW170104, when correlating H1/L1 and template, is indistinguishable from\ncorrelating detector noise and the template. It is also shown that the\nnormalized CCF for GW151226 and GW170104, when correlating H1/L1 and template,\nis indistinguishable from correlating H1/L1 and bogus chirp templates which are\nfrequency modulated(FM) waveforms which differ significantly from ideal\ntemplates. Similar results are shown with LIGO matched filter, which misfires\nwith high Signal to Noise Ratio(SNR) for bogus chirp templates. \n\n"}
{"id": "1711.07450", "contents": "Title: Anisotropic Inflation with Derivative Couplings Abstract: We study anisotropic inflationary solutions when the inflaton and its\nderivative couple to a vector field. This type of coupling is motivated by\nD-brane inflationary models, in which the inflaton, and a vector field living\non the D-brane, couple disformally (derivatively). We start by studying a\nphenomenological model where we show the existence of anisotropic solutions and\ndemonstrate their stability via a dynamical system analysis. Compared to the\ncase without a derivative coupling, the anisotropy is reduced and thus can be\nmade consistent with current limits, while the value of the slow-roll parameter\nremains almost unchanged. We also discuss solutions for more general cases,\nincluding D-brane like couplings. \n\n"}
{"id": "1711.07692", "contents": "Title: First results on low-mass dark matter from the CRESST-III experiment Abstract: The CRESST experiment, located at Laboratori Nazionali del Gran Sasso in\nItaly, searches for dark matter particles via their elastic scattering off\nnuclei in a target material. The CRESST target consists of scintillating\nCaWO$_4$ crystals, which are operated as cryogenic calorimeters at millikelvin\ntemperatures. Each interaction in the CaWO$_4$ target crystal produces a phonon\nsignal and a light signal that is measured by a second cryogenic calorimeter.\nSince the CRESST-II result in 2015, the experiment is leading the field of\ndirect dark matter search for dark matter masses below 1.7\\,GeV/$c^2$,\nextending the reach of direct searches to the sub-GeV/$c^2$ mass region. For\nCRESST-III, whose Phase 1 started in July 2016, detectors have been optimized\nto reach the performance required to further probe the low-mass region with\nunprecedented sensitivity. In this contribution the achievements of the\nCRESST-III detectors will be discussed together with preliminary results and\nperspectives of Phase 1. \n\n"}
{"id": "1711.08456", "contents": "Title: Multiple component decomposition from millimeter single-channel data Abstract: We present an implementation of a blind source separation algorithm to remove\nforegrounds off millimeter surveys made by single-channel instruments. In order\nto make possible such a decomposition over single-wavelength data: we generate\nlevels of artificial redundancy, then perform a blind decomposition, calibrate\nthe resulting maps, and lastly measure physical information. We simulate the\nreduction pipeline using mock data: atmospheric fluctuations, extended\nastrophysical foregrounds, and point-like sources, but we apply the same\nmethodology to the AzTEC/ASTE survey of the Great Observatories Origins Deep\nSurvey-South (GOODS-S). In both applications, our technique robustly decomposes\nredundant maps into their underlying components, reducing flux bias, improving\nsignal-to-noise, and minimizing information loss. In particular, the GOODS-S\nsurvey is decomposed into four independent physical components, one of them is\nthe already known map of point sources, two are atmospheric and systematic\nforegrounds, and the fourth component is an extended emission that can be\ninterpreted as the confusion background of faint sources. \n\n"}
{"id": "1711.10221", "contents": "Title: Data Multiplexing in Radio Interferometric Calibration Abstract: New and upcoming radio interferometers will produce unprecedented amounts of\ndata that demand extremely powerful computers for processing. This is a\nlimiting factor due to the large computational power and energy costs involved.\nSuch limitations restrict several key data processing steps in radio\ninterferometry. One such step is calibration where systematic errors in the\ndata are determined and corrected. Accurate calibration is an essential\ncomponent in reaching many scientific goals in radio astronomy and the use of\nconsensus optimization that exploits the continuity of systematic errors across\nfrequency significantly improves calibration accuracy. In order to reach full\nconsensus, data at all frequencies need to be calibrated simultaneously. In the\nSKA regime, this can become intractable if the available compute agents do not\nhave the resources to process data from all frequency channels simultaneously.\nIn this paper, we propose a multiplexing scheme that is based on the\nalternating direction method of multipliers (ADMM) with cyclic updates. With\nthis scheme, it is possible to simultaneously calibrate the full dataset using\nfar fewer compute agents than the number of frequencies at which data are\navailable. We give simulation results to show the feasibility of the proposed\nmultiplexing scheme in simultaneously calibrating a full dataset when a limited\nnumber of compute agents are available. \n\n"}
{"id": "1712.00094", "contents": "Title: Strong orientation dependence of surface mass density profiles of dark\n  haloes at large scales Abstract: We study the dependence of surface mass density profiles, which can be\ndirectly measured by weak gravitational lensing, on the orientation of haloes\nwith respect to the line-of-sight direction, using a suite of $N$-body\nsimulations. We find that, when major axes of haloes are aligned with the\nline-of-sight direction, surface mass density profiles have higher amplitudes\nthan those averaged over all halo orientations, over all scales from $0.1$ to\n$100\\,\\mathrm{Mpc}/h$ we studied. While the orientation dependence at small\nscales is ascribed to the halo triaxiality, our results indicate even stronger\norientation dependence in the so-called two-halo regime, up to\n$100\\,\\mathrm{Mpc}/h$. The orientation dependence for the two-halo term is well\napproximated by a multiplicative shift of the amplitude and therefore a shift\nin the halo bias parameter value. The halo bias from the two-halo term can be\noverestimated or underestimated by up to $\\sim 30 \\%$ depending on the viewing\nangle, which translates into the bias in estimated halo masses by up to a\nfactor of two from halo bias measurements. The orientation dependence at large\nscales originates from the anisotropic halo-matter correlation function, which\nhas an elliptical shape with the axis ratio of $\\sim 0.55$ up to $100\\,\n\\mathrm{Mpc}/h$. We discuss potential impacts of halo orientation bias on other\nobservables such as optically selected cluster samples and a clustering\nanalysis of large-scale structure tracers such as quasars. \n\n"}
{"id": "1712.01932", "contents": "Title: Backgrounds and pulse shape discrimination in the ArDM liquid argon TPC Abstract: The ArDM experiment completed a single-phase commissioning run in 2015 with\nan active liquid argon target of nearly one tonne in mass. The analysis of the\ndata and comparison to simulations allowed for a test of the crucial detector\nproperties and confirmed the low background performance of the setup. The\nstatistical rejection power for electron recoil events using the pulse shape\ndiscrimination method was estimated using data from a Cf-252 neutron\ncalibration source. Electron and nuclear recoil band profiles were found to be\nwell described by Gaussian distributions. Employing such a model we derive\nvalues for the electron recoil statistical rejection power of more than 10$^8$\nin the tonne-scale liquid argon target for events with more than 50 detected\nphotons at a 50% acceptance for nuclear recoils. The Rn-222 emanation rate of\nthe ArDM cryostat at room temperature was found to be 65.6$\\pm$0.4 $\\mu$Hz/l,\nand the Ar-39 specific activity from the employed atmospheric argon to be\n0.95$\\pm$0.05 Bq/kg. The cosmic muon flux at the Canfranc underground site was\ndetermined to be between 2 and 3.5$\\times 10^{-3}m^{2}s^{-1}$ . These results\npave the way for the next physics run of ArDM in the double-phase operational\nmode. \n\n"}
{"id": "1712.03880", "contents": "Title: Empirical velocity profiles for galactic rotation curves Abstract: A unified parametrization of the circular velocity, which accurately fits 850\ngalaxy rotation curves without needing in advance the knowledge of the luminous\nmatter components, nor a fixed dark matter halo model, is proposed. A notable\nfeature is that the associated gravitational potential increases with the\ndistance from the galaxy center, giving rise to a length scale indicating a\nfinite size of a galaxy, and after, the Keplerian fall-off of the parametrized\ncircular velocity is recovered according to Newtonian gravity, making possible\nthe estimation of the total mass enclosed by the galaxy. \n\n"}
{"id": "1712.03970", "contents": "Title: Learning from the machine: interpreting machine learning algorithms for\n  point- and extended- source classification Abstract: We investigate star-galaxy classification for astronomical surveys in the\ncontext of four methods enabling the interpretation of black-box machine\nlearning systems. The first is outputting and exploring the decision boundaries\nas given by decision tree based methods, which enables the visualization of the\nclassification categories. Secondly, we investigate how the Mutual Information\nbased Transductive Feature Selection (MINT) algorithm can be used to perform\nfeature pre-selection. If one would like to provide only a small number of\ninput features to a machine learning classification algorithm, feature\npre-selection provides a method to determine which of the many possible input\nproperties should be selected. Third is the use of the tree-interpreter package\nto enable popular decision tree based ensemble methods to be opened,\nvisualized, and understood. This is done by additional analysis of the tree\nbased model, determining not only which features are important to the model,\nbut how important a feature is for a particular classification given its value.\nLastly, we use decision boundaries from the model to revise an already existing\nmethod of classification, essentially asking the tree based method where\ndecision boundaries are best placed and defining a new classification method.\n  We showcase these techniques by applying them to the problem of star-galaxy\nseparation using data from the Sloan Digital Sky Survey (hereafter SDSS). We\nuse the output of MINT and the ensemble methods to demonstrate how more complex\ndecision boundaries improve star-galaxy classification accuracy over the\nstandard SDSS frames approach (reducing misclassifications by up to\n$\\approx33\\%$). We then show how tree-interpreter can be used to explore how\nrelevant each photometric feature is when making a classification on an object\nby object basis. \n\n"}
{"id": "1712.05834", "contents": "Title: nbodykit: an open-source, massively parallel toolkit for large-scale\n  structure Abstract: We present nbodykit, an open-source, massively parallel Python toolkit for\nanalyzing large-scale structure (LSS) data. Using Python bindings of the\nMessage Passing Interface (MPI), we provide parallel implementations of many\ncommonly used algorithms in LSS. nbodykit is both an interactive and scalable\npiece of scientific software, performing well in a supercomputing environment\nwhile still taking advantage of the interactive tools provided by the Python\necosystem. Existing functionality includes estimators of the power spectrum, 2\nand 3-point correlation functions, a Friends-of-Friends grouping algorithm,\nmock catalog creation via the halo occupation distribution technique, and\napproximate N-body simulations via the FastPM scheme. The package also provides\na set of distributed data containers, insulated from the algorithms themselves,\nthat enable nbodykit to provide a unified treatment of both simulation and\nobservational data sets. nbodykit can be easily deployed in a high performance\ncomputing environment, overcoming some of the traditional difficulties of using\nPython on supercomputers. We provide performance benchmarks illustrating the\nscalability of the software. The modular, component-based approach of nbodykit\nallows researchers to easily build complex applications using its tools. The\npackage is extensively documented at http://nbodykit.readthedocs.io, which also\nincludes an interactive set of example recipes for new users to explore. As\nopen-source software, we hope nbodykit provides a common framework for the\ncommunity to use and develop in confronting the analysis challenges of future\nLSS surveys. \n\n"}
{"id": "1712.07212", "contents": "Title: Polarized Redundant-Baseline Calibration for 21 cm Cosmology Without\n  Adding Spectral Structure Abstract: 21 cm cosmology is a promising new probe of the evolution of visible matter\nin our universe, especially during the poorly-constrained Cosmic Dawn and Epoch\nof Reionization. However, in order to separate the 21 cm signal from bright\nastrophysical foregrounds, we need an exquisite understanding of our telescopes\nso as to avoid adding spectral structure to spectrally-smooth foregrounds. One\npowerful calibration method relies on repeated simultaneous measurements of the\nsame interferometric baseline to solve for the sky signal and for instrumental\nparameters simultaneously. However, certain degrees of freedom are not\nconstrained by asserting internal consistency between redundant measurements.\nIn this paper, we review the origin of these \"degeneracies\" of\nredundant-baseline calibration and demonstrate how they can source unwanted\nspectral structure in our measurement and show how to eliminate that\nadditional, artificial structure. We also generalize redundant calibration to\ndual-polarization instruments, derive the degeneracy structure, and explore the\nunique challenges to calibration and preserving spectral smoothness presented\nby a polarized measurement. \n\n"}
{"id": "1712.08894", "contents": "Title: EXONEST: The Bayesian Exoplanetary Explorer Abstract: The fields of astronomy and astrophysics are currently engaged in an\nunprecedented era of discovery as recent missions have revealed thousands of\nexoplanets orbiting other stars. While the Kepler Space Telescope mission has\nenabled most of these exoplanets to be detected by identifying transiting\nevents, exoplanets often exhibit additional photometric effects that can be\nused to improve the characterization of exoplanets. The EXONEST Exoplanetary\nExplorer is a Bayesian exoplanet inference engine based on nested sampling and\noriginally designed to analyze archived Kepler Space Telescope and CoRoT\n(Convection Rotation et Transits plan\\'etaires) exoplanet mission data. We\ndiscuss the EXONEST software package and describe how it accommodates\nplug-and-play models of exoplanet-associated photometric effects for the\npurpose of exoplanet detection, characterization and scientific hypothesis\ntesting. The current suite of models allows for both circular and eccentric\norbits in conjunction with photometric effects, such as the primary transit and\nsecondary eclipse, reflected light, thermal emissions, ellipsoidal variations,\nDoppler beaming and superrotation. We discuss our new efforts to expand the\ncapabilities of the software to include more subtle photometric effects\ninvolving reflected and refracted light. We discuss the EXONEST inference\nengine design and introduce our plans to port the current MATLAB-based EXONEST\nsoftware package over to the next generation Exoplanetary Explorer, which will\nbe a Python-based open source project with the capability to employ third-party\nplug-and-play models of exoplanet-related photometric effects. \n\n"}
{"id": "1712.09917", "contents": "Title: Cosmic Microwave Background Dipole Asymmetry could be explained by Axion\n  Monodromy Cosmic Strings Abstract: Observations by the Wilkinson Microwave Anisotropy Probe and the Planck\nmission suggest a hemispherical power amplitude asymmetry in the cosmic\nmicrowave background, with a correlation length on the order of the size of the\nobservable Universe. We find that this anomaly can be naturally explained by an\naxion-like particle (ALP) cosmic string formed near our visible Universe. The\nfield variation associated to this cosmic string creates particle density\nfluctuations after inflation, which consequently decay into radiation before\nthe Big Bang Nucleosynthesis (BBN) era and resulted in the observed power\nasymmetry. We find in this scenario that the hemispherical power amplitude\nasymmetry is strongly scale dependent: $A(k)\\propto {\\rm exp}(-kl)/k$.\nAdmittedly, typical inflation models predict a relic number density of\ntopological defects of order one per observable Universe and so in our model\nthe cosmic string must be tuned to have an impact factor of order $1/H_0$.\nInterestingly, the constraints based on purely cosmological considerations also\ngive rise to a Peccei-Quinn scale $F_a$ of order $10^3$ larger then the Hubble\nscale of inflation $H_I$. Assuming $H_I\\sim 10^{13}$GeV, we then have an ALP\nwith $F_a\\sim 10^{16}$GeV, which coincides with the presumed scale of grand\nunification. As we require ALP decays occur before the BBN era, which implies a\nrelatively heavy mass or strong self-coupling, and considering that the\nassociated potential should break the shift symmetry softly in order to protect\nthe system from radiative corrections, we also conclude that the required ALP\npotential should be monodromic in nature. \n\n"}
{"id": "1712.10116", "contents": "Title: A momentum conserving $N$-body scheme with individual timesteps Abstract: $N$-body simulations study the dynamics of $N$ particles under the influence\nof mutual long-distant forces such as gravity. In practice, $N$-body codes will\nviolate Newton's third law if they use either an approximate Poisson solver or\nindividual timesteps. In this study, we construct a novel $N$-body scheme by\ncombining a fast multipole method (FMM) based Poisson solver and a time\nintegrator using a hierarchical Hamiltonian splitting (HHS) technique. We test\nour implementation for collision-less systems using several problems in\ngalactic dynamics. As a result of the momentum conserving nature of these two\nkey components, the new $N$-body scheme is also momentum conserving. Moreover,\nwe can fully utilize the $\\mathcal O(\\textit N)$ complexity of FMM with the\nintegrator. With the restored force symmetry, we can improve both angular\nmomentum conservation and energy conservation substantially. The new scheme\nwill be suitable for many applications in galactic dynamics and structure\nformation. Our implementation, in the code Taichi, is publicly available at\nhttps://bitbucket.org/qirong_zhu/taichi_public/. \n\n"}
{"id": "1712.10318", "contents": "Title: The future of gravitational theories in the era of the gravitational\n  wave astronomy Abstract: We discuss the future of gravitational theories in the framework of\ngravitational wave (GW) astronomy after the recent GW detections (the events\nGW150914, GW151226, GW170104, GW170814, GW170817 and GW170608). In particular,\na calculation of the frequency and angular dependent response function that a\nGW detector would see if massive modes from f(R) theories or scalar tensor\ngravity (STG) were present, allowing for sources incident from any direction on\nthe sky, is shown. In addition, through separate theoretical results which do\nnot involve the recent GW detections, we show that f(R) theories of gravity\nhaving a third massless mode are ultimately ruled out while there is still room\nfor STG having a third (massive or massless) mode and for f(R) theories of\ngravity having a third massive mode. \n\n"}
{"id": "1801.02094", "contents": "Title: Schroedinger's code: A preliminary study on research source code\n  availability and link persistence in astrophysics Abstract: We examined software usage in a sample set of astrophysics research articles\npublished in 2015 and searched for source code for the software mentioned in\nthese research papers. We categorized the software to indicate whether source\ncode is available for download and whether there are restrictions to accessing\nit, and if source code is not available, whether some other form of the\nsoftware, such as a binary, is. We also extracted hyperlinks from one journal's\n2015 research articles, as links in articles can serve as an acknowledgment of\nsoftware use and lead to data used in the research, and tested them to\ndetermine which of these URLs are still accessible. For our sample of 715\nsoftware instances in the 166 articles we examined, we were able to categorize\n418 records as to availability of source code and found that 285 unique codes\nwere used, 58% of which offer source code available online for download. Of the\n2,558 hyperlinks extracted from 1,669 research articles, at best, 90% of them\nwere available over our testing period. \n\n"}
{"id": "1801.03249", "contents": "Title: Redundant interferometric calibration as a complex optimization problem Abstract: Observations of the redshifted 21-cm line from the epoch of reionization have\nrecently motivated the construction of low frequency radio arrays with highly\nredundant configurations. These configurations provide an alternative\ncalibration strategy - \"redundant calibration\" - and boosts sensitivity on\nspecific spatial scales. In this paper, we formulate calibration of redundant\ninterferometric arrays as a complex optimization problem. We solve this\noptimization problem via the Levenberg-Marquardt algorithm. This calibration\napproach is more robust to initial conditions than current algorithms and, by\nleveraging an approximate matrix inversion, allows for further optimization and\nan efficient implementation (\"redundant StEfCal\"). We also investigated using\nthe preconditioned conjugate gradient method as an alternative to the\napproximate matrix inverse, but found that its computational performance is not\ncompetitive with respect to \"redundant StEfCal\". The efficient implementation\nof this new algorithm is made publicly available. \n\n"}
{"id": "1801.08559", "contents": "Title: The impact of baryons on the matter power spectrum from the Horizon-AGN\n  cosmological hydrodynamical simulation Abstract: Accurate cosmology from upcoming weak lensing surveys relies on knowledge of\nthe total matter power spectrum at percent level at scales $k < 10$ $h$/Mpc,\nfor which modelling the impact of baryonic physics is crucial. We compare\nmeasurements of the total matter power spectrum from the Horizon cosmological\nhydrodynamical simulations: a dark matter-only run, one with full baryonic\nphysics, and another lacking Active Galactic Nuclei (AGN) feedback. Baryons\ncause a suppression of power at $k\\simeq 10$ $h/$Mpc of $<15\\%$ at $z=0$, and\nan enhancement of a factor of a few at smaller scales due to the more efficient\ncooling and star formation. The results are sensitive to the presence of the\nhighest mass haloes in the simulation and the distribution of dark matter is\nalso impacted up to a few percent. The redshift evolution of the effect is\nnon-monotonic throughout $z=0-5$ due to an interplay between AGN feedback and\ngas pressure, and the growth of structure. We investigate the effectiveness of\nan analytic `baryonic correction model' in describing our results. We require a\ndifferent redshift evolution and propose an alternative fitting function with\n$4$ free parameters that reproduces our results within $5\\%$. Compared to other\nsimulations, we find the impact of baryonic processes on the total matter power\nspectrum to be smaller at $z=0$. Correspondingly, our results suggest that AGN\nfeedback is not strong enough in the simulation. Total matter power spectra\nfrom the Horizon simulations are made publicly available at\nhttps://www.horizon-simulation.org/catalogues.html \n\n"}
{"id": "1802.01566", "contents": "Title: Towards Precision Constraints on Gravity with the Effective Field Theory\n  of Large-Scale Structure Abstract: We compare analytical computations with numerical simulations for dark-matter\nclustering, in general relativity and in the normal branch of DGP gravity\n(nDGP). Our analytical frameword is the Effective Field Theory of Large-Scale\nStructure (EFTofLSS), which we use to compute the one-loop dark-matter power\nspectrum, including the resummation of infrared bulk displacement effects. We\ncompare this to a set of 20 COLA simulations at redshifts $z = 0$, $z=0.5$, and\n$z =1$, and fit the free parameter of the EFTofLSS, called the speed of sound,\nin both $\\Lambda$CDM and nDGP at each redshift. At one-loop at $z = 0$, the\nreach of the EFTofLSS is $k_{\\rm reach}\\approx 0.14 \\, h { \\rm Mpc^{-1}}$ for\nboth $\\Lambda$CDM and nDGP. Along the way, we compare two different infrared\nresummation schemes and two different treatments of the time dependence of the\nperturbative expansion, concluding that they agree to approximately $1\\%$ over\nthe scales of interest. Finally, we use the ratio of the COLA power spectra to\nmake a precision measurement of the difference between the speeds of sound in\n$\\Lambda$CDM and nDGP, and verify that this is proportional to the modification\nof the linear coupling constant of the Poisson equation. \n\n"}
{"id": "1802.03272", "contents": "Title: The ESO Survey of Non-Publishing Programmes Abstract: One of the classic ways to measure the success of a scientific facility is\nthe publication return, which is defined as the number of refereed papers\nproduced per unit of allocated resources (for example, telescope time or\nproposals). The recent studies by Sterzik et al. (2015, 2016) have shown that\n30-50 % of the programmes allocated time at ESO do not produce a refereed\npublication. While this may be inherent to the scientific process, this finding\nprompted further investigation. For this purpose, ESO conducted a Survey of\nNon-Publishing Programmes (SNPP) within the activities of the Time Allocation\nWorking Group, similar to the monitoring campaign that was recently implemented\nat ALMA (Stoehr et al. 2016). The SNPP targeted 1278 programmes scheduled\nbetween ESO Periods 78 and 90 (October 2006 to March 2013) that had not\npublished a refereed paper as of April 2016. The poll was launched on 6 May\n2016, remained open for four weeks, and returned 965 valid responses. This\narticle summarises and discusses the results of this survey, the first of its\nkind at ESO. \n\n"}
{"id": "1802.03629", "contents": "Title: Astrolabe: Curating, Linking and Computing Astronomy's Dark Data Abstract: Where appropriate repositories are not available to support all relevant\nastronomical data products, data can fall into darkness: unseen and unavailable\nfor future reference and re-use. Some data in this category are legacy or old\ndata, but newer datasets are also often uncurated and could remain \"dark\". This\npaper provides a description of the design motivation and development of\nAstrolabe, a cyberinfrastructure project that addresses a set of community\nrecommendations for locating and ensuring the long-term curation of dark or\notherwise at-risk data and integrated computing. This paper also describes the\noutcomes of the series of community workshops that informed creation of\nAstrolabe. According to participants in these workshops, much astronomical dark\ndata currently exist that are not curated elsewhere, as well as software that\ncan only be executed by a few individuals and therefore becomes unusable\nbecause of changes in computing platforms. Astronomical research questions and\nchallenges would be better addressed with integrated data and computational\nresources that fall outside the scope of existing observatory and space mission\nprojects. As a solution, the design of the Astrolabe system is aimed at\ndeveloping new resources for management of astronomical data. The project is\nbased in CyVerse cyberinfrastructure technology and is a collaboration between\nthe University of Arizona and the American Astronomical Society. Overall the\nproject aims to support open access to research data by leveraging existing\ncyberinfrastructure resources and promoting scientific discovery by making\npotentially-useful data in a computable format broadly available to the\nastronomical community. \n\n"}
{"id": "1802.05450", "contents": "Title: Hierarchical multi-stage MCMC follow-up of continuous gravitational wave\n  candidates Abstract: Leveraging Markov chain Monte Carlo (MCMC) optimization of the F-statistic,\nwe introduce a method for the hierarchical follow-up of continuous\ngravitational wave candidates identified by wide-parameter space semi-coherent\nsearches. We demonstrate parameter estimation for continuous wave sources and\ndevelop a framework and tools to understand and control the effective size of\nthe parameter space, critical to the success of the method. Monte Carlo tests\nof simulated signals in noise demonstrate that this method is close to the\ntheoretical optimal performance. \n\n"}
{"id": "1802.06039", "contents": "Title: Projected WIMP sensitivity of the LUX-ZEPLIN (LZ) dark matter experiment Abstract: LUX-ZEPLIN (LZ) is a next generation dark matter direct detection experiment\nthat will operate 4850 feet underground at the Sanford Underground Research\nFacility (SURF) in Lead, South Dakota, USA. Using a two-phase xenon detector\nwith an active mass of 7~tonnes, LZ will search primarily for low-energy\ninteractions with Weakly Interacting Massive Particles (WIMPs), which are\nhypothesized to make up the dark matter in our galactic halo. In this paper,\nthe projected WIMP sensitivity of LZ is presented based on the latest\nbackground estimates and simulations of the detector. For a 1000~live day run\nusing a 5.6~tonne fiducial mass, LZ is projected to exclude at 90\\% confidence\nlevel spin-independent WIMP-nucleon cross sections above $1.4 \\times\n10^{-48}$~cm$^{2}$ for a 40~$\\mathrm{GeV}/c^{2}$ mass WIMP. Additionally, a\n$5\\sigma$ discovery potential is projected reaching cross sections below the\nexclusion limits of recent experiments. For spin-dependent\nWIMP-neutron(-proton) scattering, a sensitivity of $2.3 \\times\n10^{-43}$~cm$^{2}$ ($7.1 \\times 10^{-42}$~cm$^{2}$) for a\n40~$\\mathrm{GeV}/c^{2}$ mass WIMP is expected. With underground installation\nwell underway, LZ is on track for commissioning at SURF in 2020. \n\n"}
{"id": "1802.06088", "contents": "Title: Reducing and Analyzing the PHAT Survey with the Cloud Abstract: We discuss the technical challenges we faced and the techniques we used to\novercome them when reducing the PHAT photometric data set on the Amazon Elastic\nCompute Cloud (EC2). We first describe the architecture of our photometry\npipeline, which we found particularly efficient for reducing the data in\nmultiple ways for different purposes. We then describe the features of EC2 that\nmake this architecture both efficient to use and challenging to implement. We\ndescribe the techniques we adopted to process our data, and suggest ways these\ntechniques may be improved for those interested in trying such reductions in\nthe future. Finally, we summarize the output photometry data products, which\nare now hosted publicly in two places in two formats. They are in simple fits\ntables in the high-level science products on MAST, and on a queryable database\navailable through the NOAO Data Lab. \n\n"}
{"id": "1802.06280", "contents": "Title: Spatial field reconstruction with INLA: Application to IFU galaxy data Abstract: Astronomical observations of extended sources, such as cubes of integral\nfield spectroscopy (IFS), encode auto-correlated spatial structures that cannot\nbe optimally exploited by standard methodologies. This work introduces a novel\ntechnique to model IFS datasets, which treats the observed galaxy properties as\nrealizations of an unobserved Gaussian Markov random field. The method is\ncomputationally efficient, resilient to the presence of low-signal-to-noise\nregions, and uses an alternative to Markov Chain Monte Carlo for fast Bayesian\ninference, the Integrated Nested Laplace Approximation (INLA). As a case study,\nwe analyse 721 IFS data cubes of nearby galaxies from the CALIFA and PISCO\nsurveys, for which we retrieve the maps of the following physical properties:\nage, metallicity, mass and extinction. The proposed Bayesian approach, built on\na generative representation of the galaxy properties, enables the creation of\nsynthetic images, recovery of areas with bad pixels, and an increased power to\ndetect structures in datasets subject to substantial noise and/or sparsity of\nsampling. A snippet code to reproduce the analysis of this paper is available\nin the COIN toolbox, together with the field reconstructions of the CALIFA and\nPISCO samples. \n\n"}
{"id": "1802.06849", "contents": "Title: The World Space Observatory Ultraviolet (WSO-UV), as a bridge to future\n  UV astronomy Abstract: The ultraviolet (UV) astronomy is a very demanded branch of space astronomy.\nMany dozens of short-term UV-experiments in space, as well as long-term\nobservatories, have brought a very important knowledge on the physics and\nchemistry of the Universe during the last decades. Unfortunately, no large\nUV-observatories are planned to be launched by most of space agencies in the\ncoming 10 -- 15 years. Conversely, the large UVOIR observatories of the future\nwill appear not earlier than in 2030s. This paper briefly describes the\nprojects that have been proposed by various groups. We conclude that the World\nSpace Observatory -- Ultraviolet (WSO-UV) will be the only 2-m class UV\ntelescope with capabilities similar to those of the HST for the next decade.\nThe WSO-UV has been described in detail in previous publications, and this\npaper updates the main characteristics of its instruments and the current state\nof the whole project. It also addresses the major science topics that have been\nincluded in the core program of the WSO-UV, making this core program very\nrelevant to the current state of the UV-astronomy. Finally, we also present\nhere the ground segment architecture that will implement this program. \n\n"}
{"id": "1802.08420", "contents": "Title: New Bounds on Axion-Like Particles From the Fermi Large Area Telescope\n  observation of PKS $2155-304$ Abstract: The axion-like particle (ALP)-photon mixing in the magnetic field around\n$\\gamma$-ray sources or along the line-of-sight could induce oscillation\nbetween photons and ALPs, which then causes irregularities in the $\\gamma$-ray\nspectra. In this work we try to search for such spectral irregularities in the\nspectrum of PKS $2155-304$ using 8.6 years of the Fermi Large Area Telescope\n(Fermi-LAT) data. No significant evidence for the presence of ALP-photon\noscillation is obtained, and the parameter space of ALPs is constrained. The\nexclusion region sensitively depends on the poorly known magnetic field of host\ngalaxy cluster of PKS $2155-304$. If the magnetic field is as high as $\\sim\n10~{\\rm \\mu G}$, the \"hole\"-like parameter region allowed in Ref.~\\cite{Fermi}\ncan be ruled out. \n\n"}
{"id": "1802.08713", "contents": "Title: Integrating human and machine intelligence in galaxy morphology\n  classification tasks Abstract: Quantifying galaxy morphology is a challenging yet scientifically rewarding\ntask. As the scale of data continues to increase with upcoming surveys,\ntraditional classification methods will struggle to handle the load. We present\na solution through an integration of visual and automated classifications,\npreserving the best features of both human and machine. We demonstrate the\neffectiveness of such a system through a re-analysis of visual galaxy\nmorphology classifications collected during the Galaxy Zoo 2 (GZ2) project. We\nreprocess the top level question of the GZ2 decision tree with a Bayesian\nclassification aggregation algorithm dubbed SWAP, originally developed for the\nSpace Warps gravitational lens project. Through a simple binary classification\nscheme we increase the classification rate nearly 5-fold, classifying 226,124\ngalaxies in 92 days of GZ2 project time while reproducing labels derived from\nGZ2 classification data with 95.7% accuracy.\n  We next combine this with a Random Forest machine learning algorithm that\nlearns on a suite of nonparametric morphology indicators widely used for\nautomated morphologies. We develop a decision engine that delegates tasks\nbetween human and machine, and demonstrate that the combined system provides at\nleast a factor of 8 increase in the classification rate, classifying 210,803\ngalaxies in just 32 days of GZ2 project time with 93.1% accuracy. As the Random\nForest algorithm requires a minimal amount of computation cost, this result has\nimportant implications for galaxy morphology identification tasks in the era of\nEuclid and other large scale surveys. \n\n"}
{"id": "1802.09536", "contents": "Title: Astrophysics with New Horizons: Making the Most of a Generational\n  Opportunity Abstract: The outer solar system provides a unique, quiet vantage point from which to\nobserve the universe around us, where measurements could enable several niche\nastrophysical science cases that are too difficult to perform near Earth.\nNASA's New Horizons mission comprises an instrument package that provides\nimaging capability from ultraviolet (UV) to near-infrared (near-IR) wavelengths\nwith moderate spectral resolution located beyond the orbit of Pluto. A\ncarefully designed survey with New Horizons can optimize the use of expendable\npropellant and the limited data telemetry bandwidth to allow several\nmeasurements, including a detailed understanding of the cosmic extragalactic\nbackground light; studies of the local and extragalactic UV background;\nmeasurements of the properties of dust and ice in the outer solar system;\nconfirmation and characterization of transiting exoplanets; determinations of\nthe mass of dark objects using gravitational microlensing; and rapid follow-up\nof transient events. New Horizons is currently in an extended mission designed\nto focus on Kuiper Belt science that will conclude in 2021. The astrophysics\ncommunity has a unique, generational opportunity to use this mission for\nastronomical observation at heliocentric distances beyond 50 au in the next\ndecade. In this paper, we discuss the potential science cases for such an\nextended mission, and provide an initial assessment of the most important\noperational requirements and observation strategies it would require. We\nconclude that New Horizons is capable of transformative science, and that it\nwould make a valuable and unique asset for astrophysical science that is\nunlikely to be replicated in the near future. \n\n"}
{"id": "1802.10194", "contents": "Title: A Search for Tensor, Vector, and Scalar Polarizations in the Stochastic\n  Gravitational-Wave Background Abstract: The detection of gravitational waves with Advanced LIGO and Advanced Virgo\nhas enabled novel tests of general relativity, including direct study of the\npolarization of gravitational waves. While general relativity allows for only\ntwo tensor gravitational-wave polarizations, general metric theories can\nadditionally predict two vector and two scalar polarizations. The polarization\nof gravitational waves is encoded in the spectral shape of the stochastic\ngravitational-wave background, formed by the superposition of cosmological and\nindividually-unresolved astrophysical sources. Using data recorded by Advanced\nLIGO during its first observing run, we search for a stochastic background of\ngenerically-polarized gravitational waves. We find no evidence for a background\nof any polarization, and place the first direct bounds on the contributions of\nvector and scalar polarizations to the stochastic background. Under log-uniform\npriors for the energy in each polarization, we limit the energy-densities of\ntensor, vector, and scalar modes at 95% credibility to $\\Omega^T_0 < 5.6 \\times\n10^{-8}$, $\\Omega^V_0 < 6.4\\times 10^{-8}$, and $\\Omega^S_0 < 1.1\\times\n10^{-7}$ at a reference frequency $f_0 = 25$ Hz. \n\n"}
{"id": "1803.06473", "contents": "Title: Variational Inference as an alternative to MCMC for parameter estimation\n  and model selection Abstract: Most applications of Bayesian Inference for parameter estimation and model\nselection in astrophysics involve the use of Monte Carlo techniques such as\nMarkov Chain Monte Carlo (MCMC) and nested sampling. However, these techniques\nare time consuming and their convergence to the posterior could be difficult to\ndetermine. In this work, we advocate Variational inference as an alternative to\nsolve the above problems, and demonstrate its usefulness for parameter\nestimation and model selection in Astrophysics. Variational inference converts\nthe inference problem into an optimization problem by approximating the\nposterior from a known family of distributions and using Kullback-Leibler\ndivergence to characterize the difference. It takes advantage of fast\noptimization techniques, which make it ideal to deal with large datasets and\nmakes it trivial to parallelize on a multicore platform. We also derive a new\napproximate evidence estimation based on variational posterior, and importance\nsampling technique called posterior weighted importance sampling for the\ncalculation of evidence (PWISE), which is useful to perform Bayesian model\nselection. As a proof of principle, we apply variational inference to five\ndifferent problems in astrophysics, where Monte Carlo techniques were\npreviously used. These include assessment of significance of annual modulation\nin the COSINE-100 dark matter experiment, measuring exoplanet orbital\nparameters from radial velocity data, tests of periodicities in measurements of\nNewton's constant $G$, assessing the significance of a turnover in the spectral\nlag data of GRB 160625B and estimating the mass of a galaxy cluster using weak\ngravitational lensing. We find that variational inference is much faster than\nMCMC and nested sampling techniques for most of these problems while providing\ncompetitive results. All our analysis codes have been made publicly available. \n\n"}
{"id": "1803.07630", "contents": "Title: The Effects of Bandpass Variations on Foreground Removal Forecasts for\n  Future CMB Experiments Abstract: Time-dependent and systematic variations in band gain and central frequencies\nof instruments used to study the Cosmic Microwave Background are important\nfactors in the data-to-map analysis pipeline. If not properly characterized,\nthey could limit the ability of next-generation experiments to remove\nastrophysical foreground contamination. Uncertainties include the instrument\ndetector band, which could systematically change across the focal plane, as\nwell as the calibration of the instrument used to measure the bands. A\npotentially major effect is time-dependent gain and band uncertainties caused\nby atmospheric fluctuations. More specifically, changes in atmospheric\nconditions lead to frequency-dependent changes in the atmospheric transmission\nwhich, in turn, leads to variations in the effective gain and central frequency\nof the instrument's bandpass. Using atmospheric modeling software and ACTPol\nbandpasses, we simulate the expected variations in band gain and central\nfrequency for 20, 40, 90, 150, and 240 GHz bands as a function of precipitable\nwater vapor, observing angle, and ground temperature. Combining these effects\nenables us to set maximum and minimum limits on the expected uncertainties in\nband gain and central frequency over the course of a full observing season. We\nthen introduce the uncertainties to parametric maximum-likelihood component\nseparation methods on simulated CMB maps to forecast foreground removal\nperformance and likelihoods on the tensor-to-scalar ratio r. We conclude that\nto measure a $\\sigma(r=0)$ ~ $10^{-3}$ with a bias on the recovered $r$ under\ncontrol, the limit on the uncertainty in the relative gain and central\nfrequency of the bandpass must be <2% and <1%, respectively. We also comment on\nthe possibility of self-calibrating bandpass uncertainties. \n\n"}
{"id": "1803.08185", "contents": "Title: The Zeldovich approximation and wide-angle redshift-space distortions Abstract: The contribution of line-of-sight peculiar velocities to the observed\nredshift of objects breaks the translational symmetry of the underlying theory,\nmodifying the predicted 2-point functions. These `wide angle effects' have\nmostly been studied using linear perturbation theory in the context of the\nmultipoles of the correlation function and power spectrum. In this work we\npresent the first calculation of wide angle terms in the Zeldovich\napproximation, which is known to be more accurate than linear theory on scales\nprobed by the next generation of galaxy surveys. We present the exact result\nfor dark matter and perturbatively biased tracers as well as the small angle\nexpansion of the configuration- and Fourier-space two-point functions and the\nconnection to the multi-frequency angular power spectrum. We compare different\ndefinitions of the line-of-sight direction and discuss how to translate between\nthem. We show that wide angle terms can reach tens of percent of the total\nsignal in a measurement at low redshift in some approximations, and that a\ngeneric feature of wide angle effects is to slightly shift the Baryon Acoustic\nOscillation scale. \n\n"}
{"id": "1803.10265", "contents": "Title: The dominant origin of diffuse Ly$\\alpha$ halos around LAEs explored by\n  SED fitting and clustering analysis Abstract: The physical origin of diffuse Ly$\\alpha$ halos (LAHs) around star-forming\ngalaxies is still a matter of debate. We present the dependence of LAH\nluminosity ($L({\\rm Ly}\\alpha)_H$) on the stellar mass ($M_\\star$), $SFR$,\ncolor excess ($E(B-V)_\\star$), and dark matter halo mass ($M_{\\rm h}$) of the\nparent galaxy for $\\sim 900$ Ly$\\alpha$ emitters (LAEs) at $z\\sim2$ divided\ninto ten subsamples. We calculate $L({\\rm Ly}\\alpha)_H$ using the stacked\nobservational relation between $L({\\rm Ly}\\alpha)_H$ and central Ly$\\alpha$\nluminosity by Momose et al. (2016), which we find agrees with the average trend\nof VLT/MUSE-detected individual LAEs. We find that our LAEs have relatively\nhigh $L({\\rm Ly}\\alpha)_H$ despite low $M_\\star$ and $M_{\\rm h}$, and that\n$L({\\rm Ly}\\alpha)_H$ remains almost unchanged with $M_\\star$ and perhaps with\n$M_{\\rm h}$. These results are incompatible with the cold stream (cooling\nradiation) scenario and the satellite-galaxy star-formation scenario, because\nthe former predicts fainter $L({\\rm Ly}\\alpha)_H$ and both predict steeper\n$L({\\rm Ly}\\alpha)_H$ vs. $M_\\star$ slopes. We argue that LAHs are mainly\ncaused by Ly$\\alpha$ photons escaping from the main body and then scattered in\nthe circum-galactic medium. This argument is supported by LAH observations of\nH$\\alpha$ emitters (HAEs). When LAHs are taken into account, the Ly$\\alpha$\nescape fractions of our LAEs are about ten times higher than those of HAEs with\nsimilar $M_\\star$ or $E(B-V)_\\star$, which may partly arise from lower HI gas\nmasses implied from lower $M_{\\rm h}$ at fixed $M_\\star$, or from another\nLy$\\alpha$ source in the central part. \n\n"}
{"id": "1803.10764", "contents": "Title: On the prospect of discovering `galaxy groups' through radio\n  observations Abstract: Observed steep mass scaling of radio power from the available high mass\nclusters has ruled out the prospect of detection of 'galaxy groups'. But, the\navailable simulations and observations of thermal emissions show that the\ngroups are merger prone, thus non-virialised, indicating better visibility in\nthe radio waves. Detection of radio emissions from them would help us to\nunderstand the scale-dependent particle acceleration mechanisms also groups can\nbe a unique laboratory to test the models of cosmic magnetism and canbe the\npotential source of WHIMs. So, we have modelled radio emissions from the\nsimulated structures using {\\sc{ENZO}}. We present a model for computing\nmagnetic field and for the first time, used the electron energy spectrum from\nboth the Fermi I (DSA) and Fermi II (TRA) mechanisms to compute radio\nemissions. Computed radio power from more than 200 simulated objects, mass\nranging $\\geq 10^{13}$ to $2\\times 10^{15} M_{\\odot}$ show a new mass scaling\nof $M_{500} \\propto P_{1.4\\;GHz}^{2.17\\pm 0.08}$ and a strong correlation scale\nof $L_X \\propto P_{1.4\\;GHz}^{1.08\\pm 0.05}$. Both magnetic field and radio\npower are shown to have adequately replicated the available observations at\nhigh mass, allowing us to extend the results to further smaller masses. We\nreport that groups below $10^{14}\\;\\rm{M_{\\odot}}$ show the existence of 10s of\nnano to a sub-$\\mu$G magnetic field and about 10$^{19-23}$ W Hz$^{-1}$ of radio\npower, much higher than what existing mass scaling predicts. We found that the\ncombined radio power from TRA and DSA electrons can only fit very well to all\nthe observed `radio halos'. Finally, we have implemented this model on a real\ndata set obtained from the Sloan Digital Sky Survey (SDSS). It predicts about\n10s to 100s $\\mu$Jy/(10$\\arcsec$ beam) of radio flux in groups indicating their\ndetectability with existing and aplenty with the future radio telescopes. \n\n"}
{"id": "1803.11394", "contents": "Title: Gravitational Wave Driven Mergers and Coalescence Time of Supermassive\n  Black Holes Abstract: The evolution of Supermassive Black Holes (SMBHs) initially embedded in the\ncentres of merging galaxies realised with a stellar mass function (SMF) is\nstudied from the onset of galaxy mergers till coalescence. We performed a large\nset of direct N-body simulations with three different slopes of the central\nstellar cusp and different random seeds. Post Newtonian terms up to order 3.5\nare used to drive the SMBH binary evolution in the relativistic regime. The\nimpact of a SMF on the hardening rate and the coalescence time is investigated.\nWe find that SMBH binaries coalesce well within one billion years when our\nmodels are scaled to galaxies with a steep cusp at low redshift. Here higher\ncentral densities provide larger supply of stars to efficiently extract energy\nfrom the SMBH binary orbit and shrink it to the phase where gravitational wave\n(GW) emission becomes dominant leading to the coalescence of the SMBHs. Mergers\nof models with shallow cusps that are representative for giant elliptical\ngalaxies having central cores result in less efficient extraction of binary\norbital energy due to the lower stellar densities in the centre. However, high\nvalues of eccentricity witnessed for SMBH binaries in such galaxy mergers\nensure that the GW emission dominated phase sets in earlier at larger values of\nthe semi-major axis. This helps to compensate for the less efficient energy\nextraction during the phase dominated by stellar encounters resulting in\nmergers of SMBHs in about one Gyr after the formation of the binary.\nAdditionally, we witness mass segregation in the merger remnant resulting in\nenhanced SMBH binary hardening rates. We show that at least the final phase of\nthe merger in cuspy low mass galaxies would be observable with the GW detector\neLISA. \n\n"}
{"id": "1803.11399", "contents": "Title: Interactive 3D Visualization for Theoretical Virtual Observatories Abstract: Virtual Observatories (VOs) are online hubs of scientific knowledge. They\nencompass a collection of platforms dedicated to the storage and dissemination\nof astronomical data, from simple data archives to e-research platforms\noffering advanced tools for data exploration and analysis. Whilst the more\nmature platforms within VOs primarily serve the observational community, there\nare also services fulfilling a similar role for theoretical data. Scientific\nvisualization can be an effective tool for analysis and exploration of datasets\nmade accessible through web platforms for theoretical data, which often contain\nspatial dimensions and properties inherently suitable for visualization via\ne.g. mock imaging in 2d or volume rendering in 3d. We analyze the current state\nof 3d visualization for big theoretical astronomical datasets through\nscientific web portals and virtual observatory services. We discuss some of the\nchallenges for interactive 3d visualization and how it can augment the workflow\nof users in a virtual observatory context. Finally we showcase a lightweight\nclient-server visualization tool for particle-based datasets allowing\nquantitative visualization via data filtering, highlighting two example use\ncases within the Theoretical Astrophysical Observatory. \n\n"}
{"id": "1804.01987", "contents": "Title: AREPO-RT: Radiation hydrodynamics on a moving mesh Abstract: We introduce AREPO-RT, a novel radiation hydrodynamic (RHD) solver for the\nunstructured moving-mesh code AREPO. Our method solves the moment-based\nradiative transfer equations using the M1 closure relation. We achieve second\norder convergence by using a slope limited linear spatial extrapolation and a\nfirst order time prediction step to obtain the values of the primitive\nvariables on both sides of the cell interface. A Harten-Lax-Van Leer flux\nfunction, suitably modified for moving meshes, is then used to solve the\nRiemann problem at the interface. The implementation is fully conservative and\ncompatible with the individual timestepping scheme of AREPO. It incorporates\natomic Hydrogen (H) and Helium (He) thermochemistry, which is used to couple\nthe ultra-violet (UV) radiation field to the gas. Additionally, infrared\nradiation is coupled to the gas under the assumption of local thermodynamic\nequilibrium between the gas and the dust. We successfully apply our code to a\nlarge number of test problems, including applications such as the expansion of\n${\\rm H_{II}}$ regions, radiation pressure driven outflows and the levitation\nof optically thick layer of gas by trapped IR radiation. The new implementation\nis suitable for studying various important astrophysical phenomena, such as the\neffect of radiative feedback in driving galactic scale outflows, radiation\ndriven dusty winds in high redshift quasars, or simulating the reionisation\nhistory of the Universe in a self consistent manner. \n\n"}
{"id": "1804.02486", "contents": "Title: Evaluating virtual hosted desktops for graphics-intensive astronomy Abstract: Visualisation of data is critical to understanding astronomical phenomena.\nToday, many instruments produce datasets that are too big to be downloaded to a\nlocal computer, yet many of the visualisation tools used by astronomers are\ndeployed only on desktop computers. Cloud computing is increasingly used to\nprovide a computation and simulation platform in astronomy, but it also offers\ngreat potential as a visualisation platform. Virtual hosted desktops, with\ngraphics processing unit (GPU) acceleration, allow interactive,\ngraphics-intensive desktop applications to operate co-located with astronomy\ndatasets stored in remote data centres. By combining benchmarking and user\nexperience testing, with a cohort of 20 astronomers, we investigate the\nviability of replacing physical desktop computers with virtual hosted desktops.\nIn our work, we compare two Apple MacBook computers (one old and one new,\nrepresenting hardware and opposite ends of the useful lifetime) with two\nvirtual hosted desktops: one commercial (Amazon Web Services) and one in a\nprivate research cloud (the Australian Nectar Research Cloud). For\ntwo-dimensional image-based tasks and graphics-intensive three-dimensional\noperations -- typical of astronomy visualisation workflows -- we found that\nbenchmarks do not necessarily provide the best indication of performance. When\ncompared to typical laptop computers, virtual hosted desktops can provide a\nbetter user experience, even with lower performing graphics cards. We also\nfound that virtual hosted desktops are equally simple to use, provide greater\nflexibility in choice of configuration, and may actually be a more\ncost-effective option for typical usage profiles. \n\n"}
{"id": "1804.03462", "contents": "Title: Evolving Black Holes in Inflation Abstract: We present an analytic, perturbative solution to the Einstein equations with\na scalar field that describes dynamical black holes in a slow-roll inflationary\ncosmology. We show that the metric evolves quasi-statically through a sequence\nof Schwarzschild-de Sitter like metrics with time dependent cosmological\nconstant and mass parameters, such that the cosmological constant is\ninstantaneously equal to the value of the scalar potential. The areas of the\nblack hole and cosmological horizons each increase in time as the effective\ncosmological constant decreases, and the fractional area increase is\nproportional to the fractional change of the cosmological constant, times a\ngeometrical factor. For black holes ranging in size from much smaller than to\ncomparable to the cosmological horizon, the pre-factor varies from very small\nto order one. The \"mass first law\" and the \"Schwarzschild-de Sitter patch first\nlaw\" of thermodynamics are satisfied throughout the evolution. \n\n"}
{"id": "1804.04126", "contents": "Title: Vibrational Satellites of C$_2$S, C$_3$S, and C$_4$S: Microwave Spectral\n  Taxonomy as a Stepping Stone to the Millimeter-Wave Band Abstract: We present a microwave spectral taxonomy study of several hydrocarbon/CS$_2$\ndischarge mixtures in which more than 60 distinct chemical species, their more\nabundant isotopic species, and/or their vibrationally excited states were\ndetected using chirped-pulse and cavity Fourier-transform microwave\nspectroscopies. Taken together, in excess of 85 unique variants were detected,\nincluding several new isotopic species and more than 25 new vibrationally\nexcited states of C$_2$S, C$_3$S, and C$_4$S, which have been assigned on the\nbasis of published vibration-rotation interaction constants for C$_3$S, or\nnewly calculated ones for C$_2$S and C$_4$S. On the basis of these precise,\nlow-frequency measurements, several vibrationally exited states of C$_2$S and\nC$_3$S were subsequently identified in archival millimeter-wave data in the\n253--280 GHz frequency range, ultimately providing highly accurate catalogs for\nastronomical searches. As part of this work, formation pathways of the two\nsmaller carbon-sulfur chains were investigated using $^{13}$C isotopic\nspectroscopy, as was their vibrational excitation. The present study\nillustrates the utility of microwave spectral taxonomy as a tool for complex\nmixture analysis, and as a powerful and convenient `stepping stone' to higher\nfrequency measurements in the millimeter and submillimeter bands. \n\n"}
{"id": "1804.07501", "contents": "Title: FITS Data Source for Apache Spark Abstract: We investigate the performance of Apache Spark, a cluster computing\nframework, for analyzing data from future LSST-like galaxy surveys. Apache\nSpark attempts to address big data problems have hitherto proved successful in\nthe industry, but its use in the astronomical community still remains limited.\nWe show how to manage complex binary data structures handled in astrophysics\nexperiments such as binary tables stored in FITS files, within a distributed\nenvironment. To this purpose, we first designed and implemented a Spark\nconnector to handle sets of arbitrarily large FITS files, called spark-fits.\nThe user interface is such that a simple file \"drag-and-drop\" to a cluster\ngives full advantage of the framework. We demonstrate the very high scalability\nof spark-fits using the LSST fast simulation tool, CoLoRe, and present the\nmethodologies for measuring and tuning the performance bottlenecks for the\nworkloads, scaling up to terabytes of FITS data on the Cloud@VirtualData,\nlocated at Universit\\'e Paris Sud. We also evaluate its performance on Cori, a\nHigh-Performance Computing system located at NERSC, and widely used in the\nscientific community. \n\n"}
{"id": "1804.07537", "contents": "Title: Mass, radius, and composition of the transiting planet 55 Cnc e : using\n  interferometry and correlations Abstract: The characterization of exoplanets relies on that of their host star.\nHowever, stellar evolution models cannot always be used to derive the mass and\nradius of individual stars, because many stellar internal parameters are poorly\nconstrained. Here, we use the probability density functions (PDFs) of directly\nmeasured parameters to derive the joint PDF of the stellar and planetary mass\nand radius. Because combining the density and radius of the star is our most\nreliable way of determining its mass, we find that the stellar (respectively\nplanetary) mass and radius are strongly (respectively moderately) correlated.\nWe then use a generalized Bayesian inference analysis to characterize the\npossible interiors of 55 Cnc e. We quantify how our ability to constrain the\ninterior improves by accounting for correlation. The information content of the\nmass-radius correlation is also compared with refractory element abundance\nconstraints. We provide posterior distributions for all interior parameters of\ninterest. Given all available data, we find that the radius of the gaseous\nenvelope is $0.08 \\pm 0.05 R_p$. A stronger correlation between the planetary\nmass and radius (potentially provided by a better estimate of the transit\ndepth) would significantly improve interior characterization and reduce\ndrastically the uncertainty on the gas envelope properties. \n\n"}
{"id": "1804.08390", "contents": "Title: Gaia space mission and quasars Abstract: Quasars are often considered to be point-like objects. This is largely true\nand allows for an excellent alignment of the optical positional reference frame\nof the ongoing ESA mission Gaia with the International Celestial Reference\nFrame. But presence of optical jets in quasars can cause shifts of the optical\nphoto-centers at levels detectable by Gaia. Similarly, motion of emitting blobs\nin the jet can be detected as proper motion shifts. Gaia's measurements of\nspectral energy distribution for around a million distant quasars is useful to\ndetermine their redshifts and to assess their variability on timescales from\nhours to years. Spatial resolution of Gaia allows to build a complete magnitude\nlimited sample of strongly lensed quasars. The mission had its first public\ndata release in September 2016 and is scheduled to have the next and much more\ncomprehensive one in April 2018. Here we briefly review the capabilities and\ncurrent results of the mission. Gaia's unique contributions to the studies of\nquasars are already being published, a highlight being a discovery of a number\nof quasars with optical jets. \n\n"}
{"id": "1804.08581", "contents": "Title: The Radio Background Below 100 MHz Abstract: The recent detection of the \"cosmic dawn\" redshifted 21 cm signal at 78 MHz\nby the EDGES experiment differs significantly from theoretical predictions. In\nparticular, the absorption trough is roughly a factor of two stronger than the\nmost optimistic theoretical models. The early interpretations of the origin of\nthis discrepancy fall into two categories. The first is that there is increased\ncooling of the gas due to interactions with dark matter, while the second is\nthat the background radiation field includes a contribution from a component in\naddition to the cosmic microwave background. In this paper we examine the\nfeasibility of the second idea using new data from the first station of the\nLong Wavelength Array. The data span 40 to 80 MHz and provide important\nconstraints on the present-day background in a frequency range where there are\nfew surveys with absolute temperature calibration suitable for measuring the\nstrength of the radio monopole. We find support for a strong, diffuse radio\nbackground that was suggested by the ARCARDE 2 results in the 3 to 10 GHz\nrange. We find that this background is well modeled by a power law with a\nspectral index of $-$2.58$\\pm$0.05 and a temperature at the rest frame 21 cm\nfrequency of 603$^{+102}_{-92}$ mK. \n\n"}
{"id": "1804.09581", "contents": "Title: NIKA 150 GHz polarization observations of the Crab nebula and its\n  spectral energy distribution Abstract: The Crab nebula is a supernova remnant exhibiting a highly polarized\nsynchrotron radiation at radio and millimeter wavelengths. It is the brightest\nsource in the microwave sky with an extension of 7 by 5 arcminutes and commonly\nused as a standard candle for any experiment which aims at measuring the\npolarization of the sky. Though its spectral energy distribution has been well\ncharacterized in total intensity, polarization data are still lacking at\nmillimetre wavelengths. We report in this paper high resolution (18 arcsec\nFWHM) observations of the Crab nebula in total intensity and linear\npolarization at 150 GHz with the NIKA camera. NIKA, operated at the IRAM 30 m\ntelescope from 2012 to 2015, is a camera made of Lumped Element Kinetic\nInductance Detectors (LEKIDs) observing the sky at 150 and 260 GHz. From these\nobservations we are able to reconstruct the spatial distribution of the\npolarization degree and angle of the Crab nebula, which is found to be\ncompatible with previous observations at lower and higher frequencies.\nAveraging across the source and using other existing data sets we find that the\nCrab nebula polarization angle is consistent with being constant over a wide\nrange of frequencies with a value of -87.7$^\\circ$ +- 0.3 in Galactic\ncoordinates. We also present the first estimation of the Crab nebula spectral\nenergy distribution polarized flux in a wide frequency range: 30-353 GHz.\nAssuming a single power law emission model we find that the polarization\nspectral index $\\beta_{pol}$ = - 0.347 +- 0.026 is compatible with the\nintensity spectral index $\\beta$ = - 0.323 +- 0.001. \n\n"}
{"id": "1804.11176", "contents": "Title: A Comparative Analysis of the Cobb-Douglas Habitability Score (CDHS)\n  with the Earth Similarity Index (ESI) Abstract: We present an analytical comparison of the Cobb-Douglas Habitability\nProduction Function (CD-HPF) and the Earth Similarity Index (ESI). The key\ndifferences between the ESI and CD-HPF are highlighted and based on\nmathematical analysis, we show that the CD-HPF satisfies the conditions for\nmodel scalability and stability but the ESI does not. Using visualizations, we\nalso demonstrate that there do not exist any causal relationships between the\nESI and CD-HPF. The conclusion from the work done is that the CD-HPF and ESI do\nnot share any sensible relationship and that both should be used independently. \n\n"}
{"id": "1805.00027", "contents": "Title: Model-independent reconstruction of the linear anisotropic stress $\\eta$ Abstract: In this work, we use recent data on the Hubble expansion rate $H(z)$, the\nquantity $f\\sigma_8(z)$ from redshift space distortions and the statistic $E_g$\nfrom clustering and lensing observables to constrain in a model-independent way\nthe linear anisotropic stress parameter $\\eta$. This estimate is free of\nassumptions about initial conditions, bias, the abundance of dark matter and\nthe background expansion. We denote this observable estimator as $\\eta_{{\\rm\nobs}}$. If $\\eta_{{\\rm obs}}$ turns out to be different from unity, it would\nimply either a modification of gravity or a non-perfect fluid form of dark\nenergy clustering at sub-horizon scales. Using three different methods to\nreconstruct the underlying model from data, we report the value of $\\eta_{{\\rm\nobs}}$ at three redshift values, $z=0.29, 0.58, 0.86$. Using the method of\npolynomial regression, we find $\\eta_{{\\rm obs}}=0.57\\pm1.05$, $\\eta_{{\\rm\nobs}}=0.48\\pm0.96$, and $\\eta_{{\\rm obs}}=-0.11\\pm3.21$, respectively. Assuming\na constant $\\eta_{{\\rm obs}}$ in this range, we find $\\eta_{{\\rm\nobs}}=0.49\\pm0.69$. We consider this method as our fiducial result, for reasons\nclarified in the text. The other two methods give for a constant anisotropic\nstress $\\eta_{{\\rm obs}}=0.15\\pm0.27$ (binning) and $\\eta_{{\\rm obs}}=0.53 \\pm\n0.19$ (Gaussian Process). We find that all three estimates are compatible with\neach other within their $1\\sigma$ error bars. While the polynomial regression\nmethod is compatible with standard gravity, the other two methods are in\ntension with it. \n\n"}
{"id": "1805.02472", "contents": "Title: Anisotropy of dark matter velocity distribution Abstract: Direct detection of dark matter with directional sensitivity has the\npotential to discriminate the dark matter velocity distribution. Especially, it\nwill be suitable to discriminate isotropic distribution from anisotropic one.\nAnalyzing data produced with Monte-Carlo simulation, required conditions for\nthe discrimination is estimated. If energy threshold of detector is optimized,\n$O(10^3-10^4)$ event number is required to discriminate the anisotropy. \n\n"}
{"id": "1805.03354", "contents": "Title: Immersive Virtual Reality Experiences for All-Sky Data Abstract: Spherical coordinate systems, which are ubiquitous in astronomy, cannot be\nshown without distortion on flat, two-dimensional surfaces. This poses\nchallenges for the two complementary phases of visual exploration -- making\ndiscoveries in data by looking for relationships, patterns or anomalies -- and\npublication -- where the results of an exploration are made available for\nscientific scrutiny or communication. This is a long-standing problem, and many\npractical solutions have been developed. Our allskyVR approach provides a\nworkflow for experimentation with commodity virtual reality head-mounted\ndisplays. Using the free, open source S2PLOT programming library, and the\nA-Frame WebVR browser-based framework, we provide a straightforward way to\nvisualise all-sky catalogues on a user-centred, virtual celestial sphere. The\nallskyVR distribution contains both a quickstart option, complete with a\ngaze-based menu system, and a fully customisable mode for those who need more\ncontrol of the immersive experience.\n  The software is available for download from:\nhttps://github.com/cfluke/allskyVR \n\n"}
{"id": "1805.04078", "contents": "Title: Tomographic local 2D analyses of the WISExSuperCOSMOS all-sky galaxy\n  catalogue Abstract: The recent progress in obtaining larger and deeper galaxy catalogues is of\nfundamental importance for cosmological studies, especially to robustly measure\nthe large scale density fluctuations in the Universe. The present work uses the\nMinkowski Functionals (MF) to probe the galaxy density field from the\nWISExSuperCOSMOS (WSC) all-sky catalogue by performing tomographic local\nanalyses in five redshift shells (of thickness $\\delta z = 0.05$) in the total\nrange of $0.10 < z < 0.35$. Here, for the first time, the MF are applied to 2D\nprojections of the galaxy number count (GNC) fields with the purpose of looking\nfor regions in the WSC catalogue with unexpected features compared to\n$\\Lambda$CDM mock realisations. Our methodology reveals 1 - 3 regions of the\nGNC maps in each redshift shell with an uncommon behaviour (extreme regions),\ni.e., $p$-value $<$ 1.4\\%. Indeed, the resulting MF curves show signatures that\nsuggest the uncommon behaviour to be associated with the presence of over- or\nunder-densities there, but contamination due to residual foregrounds is not\ndiscarded. Additionally, even though our analyses indicate a good agreement\namong data and simulations, we identify 1 highly extreme region, seemingly\nassociated to a large clustered distribution of galaxies. Our results confirm\nthe usefulness of the MF to analyse GNC maps from photometric galaxy datasets. \n\n"}
{"id": "1805.04490", "contents": "Title: The C-Band All-Sky Survey (C-BASS): Design and capabilities Abstract: The C-Band All-Sky Survey (C-BASS) is an all-sky full-polarisation survey at\na frequency of 5 GHz, designed to provide complementary data to the all-sky\nsurveys of WMAP and Planck, and future CMB B-mode polarization imaging surveys.\nThe observing frequency has been chosen to provide a signal that is dominated\nby Galactic synchrotron emission, but suffers little from Faraday rotation, so\nthat the measured polarization directions provide a good template for higher\nfrequency observations, and carry direct information about the Galactic\nmagnetic field. Telescopes in both northern and southern hemispheres with\nmatched optical performance are used to provide all-sky coverage from a\nground-based experiment. A continuous-comparison radiometer and a correlation\npolarimeter on each telescope provide stable imaging properties such that all\nangular scales from the instrument resolution of 45 arcmin up to full sky are\naccurately measured. The northern instrument has completed its survey and the\nsouthern instrument has started observing. We expect that C-BASS data will\nsignificantly improve the component separation analysis of Planck and other CMB\ndata, and will provide important constraints on the properties of anomalous\nGalactic dust and the Galactic magnetic field. \n\n"}
{"id": "1805.05904", "contents": "Title: Dark Matter and Baryon Asymmetry from the very Dawn of Universe Abstract: We propose a universal mechanism of producing dark matter and baryon (lepton)\ncharge at the stage of the quasi-de Sitter expansion of the\nUniverse---inflation. The key ingredient of the mechanism is a linear coupling\nof the field, responsible for generation of dark matter or baryon (lepton)\ncharge, to a function of the inflaton. During inflation this induces almost\nconstant force dragging the corresponding field to the non-zero value. This\nforce explicitly breaks quantum numbers associated with dark matter/baryon\nabundance at later stages. As a particular realization of the mechanism we\nintroduce a super-heavy complex scalar field with the mass larger than the\nHubble rate during the last e-folds of inflation. The global U(1)-symmetry is\nviolated due to the linear coupling of the phase of the complex scalar to the\ninflaton. The symmetry breaking leads to the generation of a non-zero Noether\ncharge. The latter is directly related to the dark matter abundance, or,\nalternatively, can be converted into baryon asymmetry, if the complex scalar\ncarries the baryon charge. \n\n"}
{"id": "1805.06408", "contents": "Title: Constraints on dark energy dynamics and spatial curvature from Hubble\n  parameter and baryon acoustic oscillation data Abstract: We use all available baryon acoustic oscillation distance measurements and\nHubble parameter data to constrain the cosmological constant $\\Lambda$,\ndynamical dark energy, and spatial curvature in simple cosmological models. We\nfind that the consensus spatially flat $\\Lambda$CDM model provides a reasonable\nfit to the data, but depending on the Hubble constant prior and cosmological\nmodel, it can be a little more than 1$\\sigma$ away from the best-fit model,\nwhich can favor mild dark energy dynamics or non-flat spatial hypersurfaces. \n\n"}
{"id": "1805.06479", "contents": "Title: GalWeight: A New and Effective Weighting Technique for Determining\n  Galaxy Cluster and Group Membership Abstract: We introduce GalWeight, a new technique for assigning galaxy cluster\nmembership. This technique is specifically designed to simultaneously maximize\nthe number of bona fide cluster members while minimizing the number of\ncontaminating interlopers. The GalWeight technique can be applied to both\nmassive galaxy clusters and poor galaxy groups. Moreover, it is effective in\nidentifying members in both the virial and infall regions with high efficiency.\nWe apply the GalWeight technique to MDPL2 \\& Bolshoi N-body simulations, and\nfind that it is $> 98\\%$ accurate in correctly assigning cluster membership. We\nshow that GalWeight compares very favorably against four well-known existing\ncluster membership techniques (shifting gapper, den Hartog, caustic, SIM). We\nalso apply the GalWeight technique to a sample of twelve Abell clusters\n(including the Coma cluster) using observations from the Sloan Digital Sky\nSurvey. We end by discussing GalWeight's potential for other astrophysical\napplications. \n\n"}
{"id": "1805.06799", "contents": "Title: Radio Galaxy Shape Measurement with Hamiltonian Monte Carlo in the\n  Visibility Domain Abstract: Radio weak lensing, while a highly promising complementary probe to optical\nweak lensing, will require incredible precision in the measurement of galaxy\nshape parameters. In this paper, we extend the Bayesian Inference for Radio\nObservations model fitting approach to measure galaxy shapes directly from\nvisibility data of radio continuum surveys, instead of from image data. We\napply a Hamiltonian Monte Carlo (HMC) technique for sampling the posterior,\nwhich is more efficient than the standard Monte Carlo Markov Chain method when\ndealing with a large dimensional parameter space. Adopting the exponential\nprofile for galaxy model fitting allows us to analytically calculate the\nlikelihood gradient required by HMC, allowing a faster and more accurate\nsampling. The method is tested on SKA1-MID simulated observations at 1.4 GHz of\na field containing up to 1000 star-forming galaxies. It is also applied to a\nsimulated observation of the weak lensing precursor survey SuperCLASS. In both\ncases we obtain reliable measurements of the galaxies' ellipticity and size for\nall sources with SNR $\\ge 10$, and we also find relationships between the\nconvergence properties of the HMC technique and some source parameters. Direct\nshape measurement in the visibility domain achieves high accuracy at the\nexpected source number densities of the current and next SKA precursor\ncontinuum surveys. The proposed method can be easily extended for the fitting\nof other galaxy and scientific parameters, as well as simultaneously\nmarginalising over systematic and instrumental effects. \n\n"}
{"id": "1805.06981", "contents": "Title: Peer-review under review - A statistical study on proposal ranking at\n  ESO. Part I: the pre-meeting phase Abstract: Peer review is the most common mechanism in place for assessing requests for\nresources in a large variety of scientific disciplines. One of the strongest\ncriticisms to this paradigm is the limited reproducibility of the process,\nespecially at largely oversubscribed facilities. In this and in a subsequent\npaper we address this specific aspect in a quantitative way, through a\nstatistical study on proposal ranking at the European Southern Observatory. For\nthis purpose we analysed a sample of about 15000 proposals, submitted by more\nthan 3000 Principal Investigators over 8 years. The proposals were reviewed by\nmore than 500 referees, who assigned over 140000 grades in about 200 panel\nsessions. After providing a detailed analysis of the statistical properties of\nthe sample, the paper presents an heuristic model based on these findings,\nwhich is then used to provide quantitative estimates of the reproducibility of\nthe pre-meeting process. On average, about one third of the proposals ranked in\nthe top quartile by one referee are ranked in the same quartile by any other\nreferee of the panel. A similar value is observed for the bottom quartile. In\nthe central quartiles, the agreement fractions are very marginally above the\nvalue expected for a fully aleatory process (25%). The agreement fraction\nbetween two panels composed by 6 referees is 55+/-5% (50% confidence level) for\nthe top and bottom quartiles. The corresponding fraction for the central\nquartiles is 33+/-5%. The model predictions are confirmed by the results\nobtained from boot-strapping the data for sub-panels composed by 3 referees,\nand fully consistent with the NIPS experiment. The post-meeting phase will be\npresented and discussed in a forthcoming paper. \n\n"}
{"id": "1805.10001", "contents": "Title: The DAMIC experiment at SNOLAB Abstract: The DAMIC (Dark Matter in CCDs) experiment at the SNOLAB underground\nlaboratory uses fully depleted, high resistivity CCDs to search for dark matter\nparticles with masses below 10 GeV/c$^2$. An upgrade of the detector using an\narray of seven 16-Mpixel CCDs (40 g of mass) started operation in February\n2017. The new results, obtained with the current detector configuration, will\nbe presented. Future plans for DAMIC-M, with a total mass of 1kg and a\nionization threshold of 2 electrons, will be discussed. \n\n"}
{"id": "1805.12203", "contents": "Title: Lyman-$\\alpha$ forest constraints on interacting dark sectors Abstract: The Lyman-$\\alpha$ forest is a valuable probe of dark matter models featuring\na scale-dependent suppression of the power spectrum as compared to\n$\\Lambda$CDM. In this work, we present a new estimator of the Lyman-$\\alpha$\nflux power spectrum that does not rely on hydrodynamical simulations. Our\nframework is characterized by nuisance parameters that encapsulate the complex\nphysics of the intergalactic medium and sensitivity to highly non-linear\nsmall-scale modes. After validating the approach based on high-resolution\nhydrodynamical simulations for $\\Lambda$CDM, we derive conservative constraints\non interacting dark matter models from BOSS Lyman-$\\alpha$ data on large\nscales, k<0.02(km/s)^(-1), with the relevant nuisance parameters left free in\nthe model fit. The estimator yields lower bounds on the mass of cannibal dark\nmatter, where freeze-out occurs through 3-to-2 annihilation, in the MeV range.\nFurthermore, we find that models of dark matter interacting with dark\nradiation, which have been argued to address the $H_0$ and $\\sigma_8$ tensions,\nare compatible with BOSS Lyman-$\\alpha$ data. \n\n"}
{"id": "1806.02500", "contents": "Title: Multi-wavelength observations of cosmological phase transitions using\n  LISA and Cosmic Explorer Abstract: We reanalyze the detection possibilities for gravitational waves arising from\ncosmological first order phase transitions. We discuss the stochastic\ngravitational wave background corresponding to the three expected scenarios of\nphase transition dynamics. We then perform an analysis on the detection\npossibilities for each case using sensitivities for the next generation\nground-based detector Cosmic Explorer and the current LISA proposal, using two\nanalysis methods. We find that having both detectors allows wide detection\npossibilities over much of the parameter space, including that corresponding to\nseveral points relevant to different early Universe models. \n\n"}
{"id": "1806.02841", "contents": "Title: Calibrating Long Period Variables as Standard Candles with Machine\n  Learning Abstract: Variable stars with well-calibrated period-luminosity relationships provide\naccurate distance measurements to nearby galaxies and are therefore a vital\ntool for cosmology and astrophysics. While these measurements typically rely on\nsamples of Cepheid and RR-Lyrae stars, abundant populations of luminous\nvariable stars with longer periods of $10 - 1000$ days remain largely unused.\nWe apply machine learning to derive a mapping between lightcurve features of\nthese variable stars and their magnitude to extend the traditional\nperiod-luminosity (PL) relation commonly used for Cepheid samples. Using\nphotometric data for long period variable stars in the Large Magellanic cloud\n(LMC), we demonstrate that our predictions produce residual errors comparable\nto those obtained on the corresponding Cepheid population. We show that our\nmodel generalizes well to other samples by performing a blind test on\nphotometric data from the Small Magellanic Cloud (SMC). Our predictions on the\nSMC again show small residual errors and biases, comparable to results that\nemploy PL relations fitted on Cepheid samples. The residual biases are\ncomplementary between the long period variable and Cepheid fits, which provides\nexciting prospects to better control sources of systematic error in\ncosmological distance measurements. We finally show that the proposed\nmethodology can be used to optimize samples of variable stars as standard\ncandles independent of any prior variable star classification. \n\n"}
{"id": "1806.06979", "contents": "Title: Proving the short-wavelength approximation in Pulsar Timing Array\n  gravitational-wave background searches Abstract: A low-frequency gravitational-wave background (GWB) from the cosmic merger\nhistory of supermassive black holes is expected to be detected in the next few\nyears by pulsar timing arrays. A GWB induces distinctive correlations in the\npulsar residuals --- the expected arrival time of the pulse less its actual\narrival time. Simplifying assumptions are made in order to write an analytic\nexpression for this correlation function, called the Hellings and Downs curve\nfor an isotropic GWB, which depends on the angular separation of the pulsar\npairs, the gravitational-wave frequency considered, and the distance to the\npulsars. This is called the short-wavelength approximation, which we prove here\nrigorously and analytically for the first time. \n\n"}
{"id": "1806.08380", "contents": "Title: The initial mass function in the Coma Berenices dwarf galaxy from deep\n  near-infrared HST observations Abstract: We use deep $HST$ WFC3/IR imaging to study the Initial Mass Function (IMF) of\nthe ultra faint dwarf galaxy Coma Berenices (Com Ber). Our observations reach\nthe lowest stellar mass ever probed in a resolved galaxy, with 50\\%\ncompleteness at $\\sim 0.17$ M$_{\\odot}$. Unresolved background galaxies however\nlimit our purity below $\\sim 0.23$ M$_{\\odot}$. If modeled with a single power\nlaw, we find that the IMF slope is $-1.45^{+0.29}_{-0.3}$ (68\\% credible\nintervals), compared to a Milky Way value of $-2.3$. For a broken power law, we\nobtain a low-mass slope of $-1.18_{-0.33}^{+0.49}$, a high-mass slope of\n$-1.88_{-0.49}^{+0.43}$ and a break mass of $0.57_{-0.08}^{+0.12}$ M$_{\\odot}$,\ncompared to $-1.3$, $-2.3$ and 0.5 M$_{\\odot}$ for a Kroupa IMF. For a\nlog-normal IMF model we obtain values of $0.33_{-0.16}^{+0.15}$ M$_{\\odot}$ for\nthe location parameter and of $0.68_{-0.12}^{+0.17}$ for $\\sigma$ (0.22\nM$_{\\odot}$ and 0.57 for the Chabrier system IMF). All three parametrizations\nproduce similar agreement with the data. Our results agree with previous\nanalysis of shallower optical HST data. However analysis of similar optical\ndata of other dwarfs finds IMFs significantly more bottom-light than in the\nMilky Way. These results suggest two, non mutually exclusive, possibilities:\nthat the discrepancy of the dwarf galaxies IMF with respect to the Milky Way\nis, at least partly, an artifact of using a single power law model, and that\nthere is real variance in the IMF at low masses between the currently studied\nnearby dwarfs, with Com Ber being similar to the Milky Way, but other dwarfs\ndiffering significantly. \n\n"}
{"id": "1806.11360", "contents": "Title: Mapping Incoherent Gravitational Wave Backgrounds Abstract: Given the recent detection of gravitational waves from individual sources it\nis almost a certainty that some form of background of gravitational waves will\nbe detected in future. The most promising candidate for such a detection are\nbackgrounds made up of incoherent superposition of the signal of unresolved\nastrophysical or, backgrounds sourced by earlier cosmological events. Such\nbackgrounds will also contain anisotropies about an average value. The\ninformation contained in the background level and any anisotropies will be\nextremely valuable as an astrophysical and cosmological probe. As such, the\nability to reconstruct sky maps of the signal will become important as the\nsensitivity increases. We build and test a pixel--based, maximum--likelihood\nGravitational Wave Background (GWB) map-maker that uses the cross-correlation\nof sets of generalised baselines as input. The resulting maps are a\nrepresentation of the GWB power, or strain \"intensity\" on the sky. We test the\nalgorithm by reconstructing known input maps with different baseline\nconfigurations. We also apply the map-maker to a subset of the Advance LIGO\ndata. \n\n"}
{"id": "1807.03098", "contents": "Title: TASI Lectures on Primordial Cosmology Abstract: These lectures cover aspects of primordial cosmology with a focus on\nobservational tests of physics beyond the Standard Model. The presentation is\ndivided into two parts: In Part I, we study the production of new light\nparticles in the hot big bang and describe their effects on the anisotropies of\nthe cosmic microwave background. In Part II, we investigate the possibility of\nvery massive particles being created during inflation and determine their\nimprints in higher-order cosmological correlations. \n\n"}
{"id": "1807.05999", "contents": "Title: The VIMOS Public Extragalactic Redshift Survey (VIPERS): Unbiased\n  clustering estimate with VIPERS slit assignment Abstract: The VIPERS galaxy survey has measured the clustering of $0.5<z<1.2$ galaxies,\nenabling a number of measurements of galaxy properties and cosmological\nredshift-space distortions (RSD). Because the measurements were made using\none-pass of the VIMOS instrument on the Very Large Telescope (VLT), the\ngalaxies observed only represent approximately 47\\% of the parent target\nsample, with a distribution imprinted with the pattern of the VIMOS slitmask.\nCorrecting for the effect on clustering has previously been achieved using an\napproximate approach developed using mock catalogues. Pairwise inverse\nprobability (PIP) weighting has recently been proposed by Bianchi & Percival to\ncorrect for missing galaxies, and we apply it to mock VIPERS catalogues to show\nthat it accurately corrects the clustering for the VIMOS effects, matching the\nclustering measured from the observed sample to that of the parent. We then\napply PIP-weighting to the VIPERS data, and fit the resulting monopole and\nquadrupole moments of the galaxy two-point correlation function with respect to\nthe line-of-sight, making measurements of RSD. The results are close to\nprevious measurements, showing that the previous approximate methods used by\nthe VIPERS team are sufficient given the errors obtained on the RSD parameter. \n\n"}
{"id": "1807.06758", "contents": "Title: Fast Linearized Coronagraph Optimizer (FALCO) IV. Coronagraph design\n  survey for obstructed and segmented apertures Abstract: Coronagraph instruments on future space telescopes will enable the direct\ndetection and characterization of Earth-like exoplanets around Sun-like stars\nfor the first time. The quest for the optimal optical coronagraph designs has\nmade rapid progress in recent years thanks to the Segmented Coronagraph Design\nand Analysis (SCDA) initiative led by the Exoplanet Exploration Program at\nNASA's Jet Propulsion Laboratory. As a result, several types of\nhigh-performance designs have emerged that make use of dual deformable mirrors\nto (1) correct for optical aberrations and (2) suppress diffracted starlight\nfrom obstructions and discontinuities in the telescope pupil. However, the\nalgorithms used to compute the optimal deformable mirror surface tend to be\ncomputationally intensive, prohibiting large scale design surveys. Here, we\nutilize the Fast Linearized Coronagraph Optimizer (FALCO), a tool that allows\nfor rapid optimization of deformable mirror shapes, to explore trade-offs in\ncoronagraph designs for obstructed and segmented space telescopes. We compare\ndesigns for representative shaped pupil Lyot and vortex coronagraphs, two of\nthe most promising concepts for the LUVOIR space mission concept. We analyze\nthe optical performance of each design, including their throughput and ability\nto passively suppress light from partially resolved stars in the presence of\nlow-order aberrations. Our main result is that deformable mirror based\napodization can sufficiently suppress diffraction from support struts and\ninter-segment gaps whose widths are on the order of $\\sim$0.1% of the primary\nmirror diameter to detect Earth-sized planets within a few tens of\nmilliarcseconds from the star. \n\n"}
{"id": "1807.06830", "contents": "Title: Hill-climbing dark inflation Abstract: Within the framework of the scalar-tensor theory we consider a hill-climbing\ninflation, in which the effective Planck mass increases in time. We obtain the\nEinstein frame potential with infinitely long and flat plateau as we approach\ntowards the strong coupling regime, together with a run-away vacuum in the GR\nlimit of the theory. The inflation ends with the scalar field rolling down\ntowards infinity, which at the effective level indicates the massless scalar\nfield domination in the Universe. In this scheme we assume that the inflaton is\na dark particle, which has no couplings to the Standard Model degrees of\nfreedom (other than the gravitational ones). We discuss the gravitational\nreheating of the Universe together with its implications on the predictions of\nthe model, including possible amplification of primordial gravitational waves.\nOur model for the first time realizes explicitly the enhancement of the\nprimordial gravitational waves in the dark inflation scenario. \n\n"}
{"id": "1807.10312", "contents": "Title: PyCBC Inference: A Python-based parameter estimation toolkit for compact\n  binary coalescence signals Abstract: We introduce new modules in the open-source PyCBC gravitational- wave\nastronomy toolkit that implement Bayesian inference for compact-object binary\nmergers. We review the Bayesian inference methods implemented and describe the\nstructure of the modules. We demonstrate that the PyCBC Inference modules\nproduce unbiased estimates of the parameters of a simulated population of\nbinary black hole mergers. We show that the posterior parameter distributions\nobtained used our new code agree well with the published estimates for binary\nblack holes in the first LIGO-Virgo observing run. \n\n"}
{"id": "1808.01141", "contents": "Title: Logarithmic potential for the gravitational field of Schwarzschild black\n  holes Abstract: Approximate gravitational potentials are often used to describe analytically\nthe motion of particles near black holes (BHs), as well as to study the\nstructure of an accretion disk. Such 'pseudo-Newtonian' potentials are used\nwith the flat-metric equations. Here we consider the motion of a free particle\nnear a non-rotating BH in the context of an exact `logarithmic' gravitational\npotential. We show how the logarithmic potential gives an exact solution for a\nmechanical problem and present the relativistic Bernoulli equation for the\nfluid in the Schwarzschild metric. \n\n"}
{"id": "1808.04772", "contents": "Title: Methods for the detection of gravitational waves from sub-solar mass\n  ultracompact binaries Abstract: We describe detection methods for extensions of gravitational wave searches\nto sub-solar mass compact binaries. Sub-solar mass searches were previously\ncarried out using Initial LIGO, and Advanced LIGO boasts a detection volume\napproximately 1000 times bigger than Initial LIGO at design sensitivity. Low\nmasses present computational difficulties, and we suggest a way to rein in the\nincrease while retaining a sensitivity much greater than previous searches.\nSub-solar mass compact objects are of particular interest because they are not\nexpected to form astrophysically. If detected they could be evidence of\nprimordial black holes (PBH). We consider a particular model of PBH binary\nformation that would allow LIGO/Virgo to place constraints on this population\nwithin the context of dark matter, and we demonstrate how to obtain\nconservative bounds for the upper limit on the dark matter fraction. \n\n"}
{"id": "1808.05968", "contents": "Title: Ionospheric Attenuation of Polarized Foregrounds in 21 cm Epoch of\n  Reionization Measurements: A Demonstration for the HERA Experiment Abstract: Foregrounds with polarization states that are not smooth functions of\nfrequency present a challenge to HI Epoch of Reionization (EoR) power spectrum\nmeasurements if they are not cleanly separated from the desired Stokes I\nsignal. The intrinsic polarization impurity of an antenna's electromagnetic\nresponse limits the degree to which components of the polarization state on the\nsky can be separated from one another, leading to the possibility that this\nfrequency structure could be confused for HI emission. We investigate the\npotential of Faraday rotation by the Earth's ionosphere to provide a mechanism\nfor both mitigation of, and systematic tests for, this contamination.\nSpecifically, we consider the delay power spectrum estimator, which relies on\nthe expectation that foregrounds will be separated from the cosmological signal\nby a clearly demarcated boundary in Fourier space, and is being used by the\nHydrogen Epoch of Reionization Array (HERA) experiment. Through simulations of\nvisibility measurements which include the ionospheric Faraday rotation\ncalculated from real historical ionospheric plasma density data, we find that\nthe incoherent averaging of the polarization state over repeated observations\nof the sky may attenuate polarization leakage in the power spectrum by a factor\nof 10 or more. Additionally, this effect provides a way to test for the\npresence of polarized foreground contamination in the EoR power spectrum\nestimate. \n\n"}
{"id": "1808.06378", "contents": "Title: Condensate Dynamics with Non-Local Interactions Abstract: Systems of identical particles possessing non-local interactions are capable\nof exhibiting extra-classical properties beyond the characteristic quantum\nlength scales. This letter derives the dynamics of such systems in the\nnon-relativistic and degenerate limit, showing the effect of exchange symmetry\nand correlations on structure both in and out of equilibrium. Such descriptions\nmay be crucial to understanding systems ranging from nuclei to dark matter.\nAppropriate limits for restoring the mean-field description are also discussed. \n\n"}
{"id": "1808.07442", "contents": "Title: Studies of Systematic Uncertainties for Simons Observatory: Polarization\n  Modulator Related Effects Abstract: The Simons Observatory (SO) will observe the temperature and polarization\nanisotropies of the cosmic microwave background (CMB) over a wide range of\nfrequencies (27 to 270 GHz) and angular scales by using both small (0.5 m) and\nlarge (6 m) aperture telescopes. The SO small aperture telescopes will target\ndegree angular scales where the primordial B-mode polarization signal is\nexpected to peak. The incoming polarization signal of the small aperture\ntelescopes will be modulated by a cryogenic, continuously-rotating half-wave\nplate (CRHWP) to mitigate systematic effects arising from slowly varying noise\nand detector pair-differencing. In this paper, we present an assessment of some\nsystematic effects arising from using a CRHWP in the SO small aperture systems.\nWe focus on systematic effects associated with structural properties of the HWP\nand effects arising when operating a HWP, including the amplitude of the HWP\nsynchronous signal (HWPSS), and I -> P (intensity to polarization) leakage that\narises from detector non-linearity in the presence of a large HWPSS. We\ndemonstrate our ability to simulate the impact of the aforementioned systematic\neffects in the time domain. This important step will inform mitigation\nstrategies and design decisions to ensure that SO will meet its science goals. \n\n"}
{"id": "1808.09153", "contents": "Title: A Semi-Analytical Computation of the Theoretical Uncertainties of the\n  Solar Neutrino Flux Abstract: We present a comparison between Monte Carlo simulations and a semi-analytical\napproach that reproduces the theoretical probability distribution functions of\nthe solar neutrino fluxes, stemming from the $pp$, $pep$, $hep$,\n$^7\\mathrm{Be}$, $^8\\mathrm{B}$, $^{13}\\mathrm{N}$, $^{15}\\mathrm{O}$, and\n$^{17}\\mathrm{F}$ source reactions. We obtain good agreement between the two\napproaches. Thus, the semi-analytical method yields confidence intervals that\nclosely match those found, based on Monte Carlo simulations, and points towards\nthe same general symmetries of the investigated probability distribution\nfunctions. Furthermore, the negligible computational cost of this method is a\nclear advantage over Monte Carlo simulations, making it trivial to take new\nobservational constraints on the input parameters into account. \n\n"}
{"id": "1809.00036", "contents": "Title: Year two instrument status of the SPT-3G cosmic microwave background\n  receiver Abstract: The South Pole Telescope (SPT) is a millimeter-wavelength telescope designed\nfor high-precision measurements of the cosmic microwave background (CMB). The\nSPT measures both the temperature and polarization of the CMB with a large\naperture, resulting in high resolution maps sensitive to signals across a wide\nrange of angular scales on the sky. With these data, the SPT has the potential\nto make a broad range of cosmological measurements. These include constraining\nthe effect of massive neutrinos on large-scale structure formation as well as\ncleaning galactic and cosmological foregrounds from CMB polarization data in\nfuture searches for inflationary gravitational waves. The SPT began observing\nin January 2017 with a new receiver (SPT-3G) containing $\\sim$16,000\npolarization-sensitive transition-edge sensor bolometers. Several key\ntechnology developments have enabled this large-format focal plane, including\nadvances in detectors, readout electronics, and large millimeter-wavelength\noptics. We discuss the implementation of these technologies in the SPT-3G\nreceiver as well as the challenges they presented. In late 2017 the\nimplementations of all three of these technologies were modified to optimize\ntotal performance. Here, we present the current instrument status of the SPT-3G\nreceiver. \n\n"}
{"id": "1809.00873", "contents": "Title: Search for heavy blackholes with Microlensing: The MEMO project Abstract: The historical microlensing surveys MACHO, EROS, MOA and OGLE (hereafter\nsummarized in the MEMO acronym) have searched for microlensing toward the LMC\nfor a total duration of 27 years. We have studied the potential of joining all\ndatabases to search for very heavy objects producing several year duration\nevents. We show that a combined systematic search for microlensing should\ndetect of the order of 10 events due to $100M_\\odot$ black holes, that were not\ndetectable by the individual surveys, if these objects have a major\ncontribution to the Milky-Way halo. Assuming that a common analysis is\nfeasible, i.e. that the difficulties due to the use of different passbands can\nbe overcome, we show that the sensitivity of such an analysis should allow one\nto quantify the Galactic black hole component. \n\n"}
{"id": "1809.01548", "contents": "Title: Measuring precise radial velocities on individual spectral lines. I.\n  Validation of the method and application to mitigate stellar activity Abstract: Stellar activity is the main limitation to the detection of Earth-twins using\nthe RV technique. Despite many efforts in trying to mitigate the effect of\nstellar activity using empirical and statistical techniques, it seems that we\nare facing an obstacle that will be extremely difficult to overcome using\ncurrent techniques. In this paper, we investigate a novel approach to derive\nprecise RVs considering the wealth of information present in high-resolution\nspectra. This new method consists in building a master spectrum from all\nobservations and measure the RVs of each spectral line in a spectrum relative\nto it. When analysing several spectra, the final product is the RVs of each\nline as a function of time. We demonstrate on three stars intensively observed\nwith HARPS that our new method gives RVs that are extremely similar to the ones\nderived from the HARPS data reduction software. Our new approach to derive RVs\ndemonstrates that the non-stability of daily HARPS wavelength solution induces\nnight-to-night RV offsets with an standard deviation of 0.4 m/s, and we propose\na solution to correct for this systematic. Finally, and this is probably the\nmost astrophysically relevant result of this paper, we demonstrate that some\nspectral lines are strongly affected by stellar activity while others are not.\nBy measuring the RVs on two carefully selected subsample of spectral lines, we\ndemonstrate that we can boost by a factor of 2 or mitigate by a factor of 1.6\nthe red noise induced by stellar activity in the 2010 RVs of Alpha Cen B. By\nmeasuring the RVs of each spectral line, we are able to reach the same RV\nprecision as other approved techniques. In addition, this new approach allows\nto demonstrate that each line is differently affected by stellar activity.\nPreliminary results show that studying in details the behaviour of each\nspectral line is probably the key to overcome stellar activity. \n\n"}
{"id": "1809.05034", "contents": "Title: Full-sky beam convolution for cosmic microwave background applications Abstract: We introduce a publicly available full-sky beam convolution code library\nintended to inform the design of future cosmic microwave background (CMB)\ninstruments and help current experiments probe potential systematic effects.\nThe code can be used to assess the impact of optical systematics on all stages\nof data reduction for a realistic experiment, including analyses beyond power\nspectrum estimation, by generating signal timelines that may serve as input to\nfull analysis pipelines. The design and mathematical framework of the Python\ncode is discussed along with a few simple benchmarking results. We present a\nsimple two-lens refracting telescope design and use it together with the code\nto simulate a year-long dataset for 400 detectors scanning the sky on a\nsatellite instrument. The simulation results identify a number of sub-leading\noptical non-idealities and demonstrate significant B-mode residuals caused by\nextended sidelobes that are sensitive to polarized radiation from the Galaxy.\nFor the proposed design and satellite scanning strategy, we show that a full\nphysical optics beam model generates B-mode systematics that differ\nsignificantly from the simpler elliptical Gaussian model. The code is available\nat https://github.com/adrijd/beamconv \n\n"}
{"id": "1809.05608", "contents": "Title: Chimera: A massively parallel code for core-collapse supernova\n  simulation Abstract: We provide a detailed description of the Chimera code, a code developed to\nmodel core collapse supernovae in multiple spatial dimensions. The core\ncollapse supernova explosion mechanism remains the subject of intense research.\nProgress to date demonstrates that it involves a complex interplay of neutrino\nproduction, transport, and interaction in the stellar core, three-dimensional\nstellar core fluid dynamics and its associated instabilities, nuclear burning,\nand the foundational physics of the neutrino-stellar core weak interactions and\nthe equations of state of all stellar core constituents -particularly, the\nnuclear equation of state associated with nucleons, both free and bound in\nnuclei. Chimera, by incorporating detailed neutrino transport, realistic\nneutrino-matter interactions, three-dimensional hydrodynamics, realistic\nnuclear, leptonic, and photonic equations of state, and a nuclear reaction\nnetwork, along with other refinements, can be used to study the role of\nneutrino radiation, hydrodynamic instabilities, and a variety of input physics\nin the explosion mechanism itself. It can also be used to compute observables\nsuch as neutrino signatures, gravitational radiation, and the products of\nnucleosynthesis associated with core collapse supernovae. The code contains\nmodules for neutrino transport, multidimensional compressible hydrodynamics,\nnuclear reactions, a variety of neutrino interactions, equations of state, and\nmodules to provide data for post-processing observables such as the products of\nnucleosynthesis, and gravitational radiation. Chimera is an evolving code,\nbeing updated periodically with improved input physics and numerical\nrefinements. We detail here the current version of the code, from which future\nimprovements will stem, which can in turn be described as needed in future\npublications. \n\n"}
{"id": "1809.06851", "contents": "Title: Assessment of ionospheric activity tolerances for Epoch of Reionisation\n  science with the Murchison Widefield Array Abstract: Structure imprinted in foreground extragalactic point sources by ionospheric\nrefraction has the potential to contaminate Epoch of Reionisation (EoR) power\nspectra of the 21~cm emission line of neutral hydrogen. The alteration of the\nspatial and spectral structure of foreground measurements due to total electron\ncontent (TEC) gradients in the ionosphere create a departure from the expected\nsky signal. We present a general framework for understanding the signatures of\nionospheric behaviour in the two-dimensional (2D) neutral hydrogen power\nspectrum measured by a low-frequency radio interferometer. Two primary classes\nof ionospheric behaviour are considered, corresponding to dominant modes\nobserved in Murchison Widefield Array (MWA) EoR data; namely, anisotropic\nstructured wave behaviour, and isotropic turbulence. Analytic predictions for\npower spectrum bias due to this contamination are computed, and compared with\nsimulations. We then apply the ionospheric metric described in Jordan et al.\n(2017) to study the impact of ionospheric structure on MWA data, by dividing\nMWA EoR datasets into classes with good and poor ionospheric conditions, using\nsets of matched 30-minute observations from 2014 September. The results are\ncompared with the analytic and simulated predictions, demonstrating the\nobserved bias in the power spectrum when the ionosphere is active (displays\ncoherent structures or isotropic turbulence). The analysis demonstrates that\nunless ionospheric activity can be quantified and corrected, active data should\nnot be included in EoR analysis in order to avoid systematic biases in\ncosmological power spectra. When data are corrected with a model formed from\nthe calibration information, bias reduces below the expected 21~cm signal\nlevel. Data are considered `quiet' when the median measured source position\noffsets are less than 10-15~arcseconds. \n\n"}
{"id": "1809.10317", "contents": "Title: INO: Interplanetary Network of Optical Lattice Clocks Abstract: The new technique of measuring frequency by optical lattice clocks now\napproaches to the relative precision of $(\\Delta f/f)=O(10^{-18})$. We propose\nto place such precise clocks in space and to use Doppler tracking method for\ndetecting low-frequency gravitational wave below 1 Hz. Our idea is to locate\nthree spacecrafts at one A.U. distance (say at L1, L4 & L5 of the Sun-Earth\norbit), and apply the Doppler tracking method by communicating \"the time\" each\nother. Applying the current available technologies, we obtain the sensitivity\nfor gravitational wave with three or four-order improvement ($h_{\\rm n}\\sim\n10^{-17}$ or $10^{-18}$ level in $10^{-5}$Hz -- $1$ Hz) than that of Cassini\nspacecraft in 2001. This sensitivity enables us to observe black-hole mergers\nof their mass greater than $10^5 M_\\odot$ in the cosmological scale. Based on\nthe hierarchical growth model of black-holes in galaxies, we estimate the event\nrate of detection will be 20-50 a year. We nickname \"INO\" (Interplanetary\nNetwork of Optical Lattice Clocks) for this system, named after Tadataka Ino\n(1745--1818), a Japanese astronomer, cartographer, and geodesist. \n\n"}
{"id": "1809.11145", "contents": "Title: The Photometric LSST Astronomical Time-series Classification Challenge\n  (PLAsTiCC): Selection of a performance metric for classification\n  probabilities balancing diverse science goals Abstract: Classification of transient and variable light curves is an essential step in\nusing astronomical observations to develop an understanding of their underlying\nphysical processes. However, upcoming deep photometric surveys, including the\nLarge Synoptic Survey Telescope (LSST), will produce a deluge of low\nsignal-to-noise data for which traditional labeling procedures are\ninappropriate. Probabilistic classification is more appropriate for the data\nbut are incompatible with the traditional metrics used on deterministic\nclassifications. Furthermore, large survey collaborations intend to use these\nclassification probabilities for diverse science objectives, indicating a need\nfor a metric that balances a variety of goals. We describe the process used to\ndevelop an optimal performance metric for an open classification challenge that\nseeks probabilistic classifications and must serve many scientific interests.\nThe Photometric LSST Astronomical Time-series Classification Challenge\n(PLAsTiCC) is an open competition aiming to identify promising techniques for\nobtaining classification probabilities of transient and variable objects by\nengaging a broader community both within and outside astronomy. Using mock\nclassification probability submissions emulating archetypes of those\nanticipated of PLAsTiCC, we compare the sensitivity of metrics of\nclassification probabilities under various weighting schemes, finding that they\nyield qualitatively consistent results. We choose as a metric for PLAsTiCC a\nweighted modification of the cross-entropy because it can be meaningfully\ninterpreted. Finally, we propose extensions of our methodology to ever more\ncomplex challenge goals and suggest some guiding principles for approaching the\nchoice of a metric of probabilistic classifications. \n\n"}
{"id": "1810.02821", "contents": "Title: Fast Sampling from Wiener Posteriors for Image Data with Dataflow\n  Engines Abstract: We use Dataflow Engines (DFE) to construct an efficient Wiener filter of\nnoisy and incomplete image data, and to quickly draw probabilistic samples of\nthe compatible true underlying images from the Wiener posterior. Dataflow\ncomputing is a powerful approach using reconfigurable hardware, which can be\ndeeply pipelined and is intrinsically parallel. The unique Wiener-filtered\nimage is the minimum-variance linear estimate of the true image (if the signal\nand noise covariances are known) and the most probable true image (if the\nsignal and noise are Gaussian distributed). However, many images are compatible\nwith the data with different probabilities, given by the analytic posterior\nprobability distribution referred to as the Wiener posterior. The DFE code also\ndraws large numbers of samples of true images from this posterior, which allows\nfor further statistical analysis. Naive computation of the Wiener-filtered\nimage is impractical for large datasets, as it scales as $n^3$, where $n$ is\nthe number of pixels. We use a messenger field algorithm, which is well suited\nto a DFE implementation, to draw samples from the Wiener posterior, that is,\nwith the correct probability we draw samples of noiseless images that are\ncompatible with the observed noisy image. The Wiener-filtered image can be\nobtained by a trivial modification of the algorithm. We demonstrate a lower\nbound on the speed-up, from drawing 10$^5$ samples of a 128$^2$ image, of 11.3\n${\\pm}$ 0.8 with 8 DFEs in a 1U MPC-X box when compared with a 1U server\npresenting 32 CPU threads. We also discuss a potential application in\nastronomy, to provide better dark matter maps and improved determination of the\nparameters of the Universe. \n\n"}
{"id": "1810.02916", "contents": "Title: A High-Fidelity Realization of the Euclid Code Comparison $N$-body\n  Simulation with Abacus Abstract: We present a high-fidelity realization of the cosmological $N$-body\nsimulation from the Schneider et al. (2016) code comparison project. The\nsimulation was performed with our Abacus $N$-body code, which offers high force\naccuracy, high performance, and minimal particle integration errors. The\nsimulation consists of $2048^3$ particles in a $500\\ h^{-1}\\mathrm{Mpc}$ box,\nfor a particle mass of $1.2\\times 10^9\\ h^{-1}\\mathrm{M}_\\odot$ with $10\\\nh^{-1}\\mathrm{kpc}$ spline softening. Abacus executed 1052 global time steps to\n$z=0$ in 107 hours on one dual-Xeon, dual-GPU node, for a mean rate of 23\nmillion particles per second per step. We find Abacus is in good agreement with\nRamses and Pkdgrav3 and less so with Gadget3. We validate our choice of time\nstep by halving the step size and find sub-percent differences in the power\nspectrum and 2PCF at nearly all measured scales, with $<0.3\\%$ errors at $k<10\\\n\\mathrm{Mpc}^{-1}h$. On large scales, Abacus reproduces linear theory better\nthan $0.01\\%$. Simulation snapshots are available at\nhttp://nbody.rc.fas.harvard.edu/public/S2016 . \n\n"}
{"id": "1810.03942", "contents": "Title: New observational constraints on $f(T)$ gravity through\n  gravitational-wave astronomy Abstract: We investigate the new observational constraints on $f(T)$ gravity that arise\nfrom the effects of primordial gravitational waves (GWs) on the cosmic\nmicrowave background (CMB) anisotropies and the BB spectrum. We first show that\non the GWs propagation in $f(T)$ gravity we obtain only an amplitude\nmodification and not a phase one, comparing to the case of general relativity\nin the background of $\\Lambda$CDM cosmology. Concerning primordial GWs we find\nthat the more the model departs from general relativity the larger is the GW\namplitude decay, and thus a possible future detection would bring the viable\n$f(T)$ gravity models five orders of magnitude closer to $\\Lambda$CDM cosmology\ncomparing to standard cosmological constraints. Additionally, we use the CLASS\ncode and both data from the Planck probe, as well as forecasts from the\nnear-future CORE collaboration, and we show that possible non-trivial\nconstraints on the tensor-to-scalar ratio would offer a clear signature of\n$f(T)$ gravity. Finally, we discuss on the possibility to use the properties of\nthe GWs that arise from neutron stars mergers in order to extract additional\nconstrains on the theory. \n\n"}
{"id": "1810.04060", "contents": "Title: Data calibration for the MASCARA and bRing instruments Abstract: Aims: MASCARA and bRing are photometric surveys designed to detect\nvariability caused by exoplanets in stars with $m_V < 8.4$. Such variability\nsignals are typically small and require an accurate calibration algorithm,\ntailored to the survey, in order to be detected. This paper presents the\nmethods developed to calibrate the raw photometry of the MASCARA and bRing\nstations and characterizes the performance of the methods and instruments.\nMethods: For the primary calibration a modified version of the coarse\ndecorrelation algorithm is used, which corrects for the extinction due to the\nearth's atmosphere, the camera transmission, and intrapixel variations.\nResidual trends are removed from the light curves of individual stars using\nempirical secondary calibration methods. In order to optimize these methods, as\nwell as characterize the performance of the instruments, transit signals were\ninjected in the data. Results: After optimal calibration an RMS scatter of 10\nmmag at $m_V \\sim 7.5$ is achieved in the light curves. By injecting transit\nsignals with periods between one and five days in the MASCARA data obtained by\nthe La Palma station over the course of one year, we demonstrate that MASCARA\nLa Palma is able to recover 84.0, 60.5 and 20.7% of signals with depths of 2, 1\nand 0.5% respectively, with a strong dependency on the observed declination,\nrecovering 65.4% of all transit signals at $\\delta > 0^\\circ$ versus 35.8% at\n$\\delta < 0^\\circ$. Using the full three years of data obtained by MASCARA La\nPalma to date, similar recovery rates are extended to periods up to ten days.\nWe derive a preliminary occurrence rate for hot Jupiters around A-stars of ${>}\n0.4 \\%$, knowing that many hot Jupiters are still overlooked. In the era of\nTESS, MASCARA and bRing will provide an interesting synergy for finding\nlong-period (${>} 13.5$ days) transiting gas-giant planets around the brightest\nstars. \n\n"}
{"id": "1810.06441", "contents": "Title: Improved Photometric Classification of Supernovae using Deep Learning Abstract: We present improved photometric supernovae classification using deep\nrecurrent neural networks. The main improvements over previous work are (i) the\nintroduction of a time gate in the recurrent cell that uses the observational\ntime as an input; (ii) greatly increased data augmentation including time\ntranslation, addition of Gaussian noise and early truncation of the lightcurve.\nFor post Supernovae Photometric Classification Challenge (SPCC) data, using a\ntraining fraction of $5.2\\%$ (1103 supernovae) of a representational dataset,\nwe obtain a type Ia vs. non type Ia classification accuracy of $93.2 \\pm\n0.1\\%$, a Receiver Operating Characteristic curve AUC of $0.980 \\pm 0.002$ and\na SPCC figure-of-merit of $F_1=0.57 \\pm 0.01$. Using a representational dataset\nof $50\\%$ ($10660$ supernovae), we obtain a classification accuracy of $96.6\n\\pm 0.1\\%$, an AUC of $0.995 \\pm 0.001$ and $F_1=0.76 \\pm 0.01$. We found the\nnon-representational training set of the SPCC resulted in a large degradation\nin performance due to a lack of faint supernovae, but this can be migrated by\nthe introduction of only a small number ($\\sim 100$) of faint training samples.\nWe also outline ways in which this could be achieved using unsupervised domain\nadaptation. \n\n"}
{"id": "1810.06594", "contents": "Title: Science with the Next-Generation VLA and Pulsar Timing Arrays Abstract: Pulsar timing arrays (PTAs) can be used to detect and study gravitational\nwaves in the nanohertz band (i.e., wavelengths of order light-years). This\nrequires high-precision, decades-long data sets from sensitive, instrumentally\nstable telescopes. NANOGrav and its collaborators in the International Pulsar\nTiming Array consortium are on the verge of the first detection of the\nstochastic background produced by supermassive binary black holes, which form\nvia the mergers of massive galaxies. By providing Northern hemisphere sky\ncoverage with exquisite sensitivity and higher frequency coverage compared to\nthe SKA, a Next-Generation Very Large Array (ngVLA) will be a fundamental\ncomponent in the next phase of nanohertz GW astrophysics, enabling detailed\ncharacterization of the stochastic background and the detection of individual\nsources contributing to the background, as well as detections of (or stringent\nconstraints on) cosmic strings and other exotica. Here we summarize the\nscientific goals of PTAs and the technical requirements for the ngVLA to play a\nsignificant role in the characterization of the nanohertz gravitational wave\nuniverse. \n\n"}
{"id": "1810.07231", "contents": "Title: Disentangling interstellar plasma screens with pulsar VLBI: Combining\n  auto- and cross-correlations Abstract: Pulsar scintillation allows a glimpse into small-scale plasma structures in\nthe interstellar medium, if we can infer their properties from the\nscintillation pattern. With Very Long Baseline Interferometry and working in\ndelay-delay rate space, where the contributions of pairs of images to the\ninterference pattern become localized, the scattering geometry and distribution\nof scattered images on the sky can be determined if a single,\nhighly-anisotropic scattering screen is responsible for the scintillation.\nHowever, many pulsars are subject to much more complex scattering environments\nwhere this method cannot be used. We present a novel technique to reconstruct\nthe scattered flux of the pulsar and solve for the scattering geometry in these\ncases by combining interferometric visibilities with cross-correlations of\nsingle-station intensities. This takes advantage of the fact that, considering\na single image pair in delay-delay rate space, the visibilities are sensitive\nto the sum of the image angular displacements, while the cross-correlated\nintensities are sensitive to the difference, so that their combination can be\nused to localize both images of the pair. We show that this technique is able\nto reconstruct the published scattering geometry of PSR B0834+06, then apply it\nto simulations of more complicated scattering systems, where we find that it\ncan distinguish features from different scattering screens even when the\npresence of multiple screens is not obvious in the Fourier transform of the\ndynamic spectrum. This technique will allow us to both better understand the\ndistribution of scattering within the interstellar medium and to apply current\nscintillometry techniques, such as modelling scintillation and constraining the\nlocation of pulsar emission, to sources for which a current lack of\nunderstanding of the scattering environment precludes the use of these\ntechniques. (abridged) \n\n"}
{"id": "1810.08866", "contents": "Title: Tensor non-Gaussianities from Non-minimal Coupling to the Inflaton Abstract: Tensor non-Gaussianity represents an important future probe of the physics of\ninflation. Inspired by recent works, we elaborate further on the possibility of\nsignificant primordial tensor non-Gaussianities sourced by extra fields during\ninflation. Unitarity constraints limit the impact of extra (spinning) particle\ncontent by means of a lower bound on the corresponding mass spectrum. For\nspin-2 particles, this takes the form of the well-known Higuchi bound. Massive\n($m\\gtrsim H$) particles will typically decay during inflation unless they are\nnon-minimally coupled to the inflaton sector: the inflating field \"lifts\" the\ndynamics of the extra field(s), effectively getting around the limits imposed\nby unitarity. There exist several models that realize such a mechanism, but we\nfocus here on the set-up of [1] where, through an EFT approach, one is able to\ncapture the essential features common to an entire class of theories. In the\npresence of an extra massive spin-2 particle, the interactions in the tensor\nsector mimic very closely those in the scalar sector of quasi-single-field\ninflationary models. We calculate the tensor bispectrum in different\nconfigurations and extract its dependence on the extra tensor sound speed. We\nshow in detail how one may obtain significant tensor non-Gaussianities whose\nshape-function interpolates between local and equilateral, depending on the\nmass of the extra field. We also estimate the LISA response functions to a\ntensor bispectrum supporting the intermediate-type shapes we find. \n\n"}
{"id": "1810.09505", "contents": "Title: What Does a Successful Postdoctoral Fellowship Publication Record Look\n  Like? Abstract: Obtaining a prize postdoctoral fellowship in astronomy and astrophysics\ninvolves a number of factors, many of which cannot be quantified. One criterion\nthat can be measured is the publication record of an applicant. The publication\nrecords of past fellowship recipients may, therefore, provide some quantitative\nguidance for future prospective applicants. We investigated the publication\npatterns of recipients of the NASA prize postdoctoral fellowships in the\nHubble, Einstein, and Sagan programs from 2014 through 2017, using the NASA ADS\nreference system. We tabulated their publications at the point where fellowship\napplications were submitted, and we find that the 133 fellowship recipients in\nthat time frame had a median of 6 +/- 2 first-author publications, and 14 +/- 6\nco-authored publications. The full range of first author papers is 1 to 15, and\nfor all papers ranges from 2 to 76, indicating very diverse publication\npatterns. Thus, while fellowship recipients generally have strong publication\nrecords, the distribution of both first-author and co-authored papers is quite\nbroad; there is no apparent threshold of publications necessary to obtain these\nfellowships. We also examined the post-PhD publication rates for each of the\nthree fellowship programs, between male and female recipients, across the four\nyears of the analysis and find no consistent trends. We hope that these\nfindings will prove a useful reference to future junior scientists. \n\n"}
{"id": "1810.09777", "contents": "Title: Statistical analysis of probability density functions for photometric\n  redshifts through the KiDS-ESO-DR3 galaxies Abstract: Despite the high accuracy of photometric redshifts (zphot) derived using\nMachine Learning (ML) methods, the quantification of errors through reliable\nand accurate Probability Density Functions (PDFs) is still an open problem.\nFirst, because it is difficult to accurately assess the contribution from\ndifferent sources of errors, namely internal to the method itself and from the\nphotometric features defining the available parameter space. Second, because\nthe problem of defining a robust statistical method, always able to quantify\nand qualify the PDF estimation validity, is still an open issue. We present a\ncomparison among PDFs obtained using three different methods on the same data\nset: two ML techniques, METAPHOR (Machine-learning Estimation Tool for Accurate\nPHOtometric Redshifts) and ANNz2, plus the spectral energy distribution\ntemplate fitting method, BPZ. The photometric data were extracted from the KiDS\n(Kilo Degree Survey) ESO Data Release 3, while the spectroscopy was obtained\nfrom the GAMA (Galaxy and Mass Assembly) Data Release 2. The statistical\nevaluation of both individual and stacked PDFs was done through quantitative\nand qualitative estimators, including a dummy PDF, useful to verify whether\ndifferent statistical estimators can correctly assess PDF quality. We conclude\nthat, in order to quantify the reliability and accuracy of any zphot PDF\nmethod, a combined set of statistical estimators is required. \n\n"}
{"id": "1810.11040", "contents": "Title: The effect of dark matter-dark radiation interactions on halo abundance\n  -- a Press-Schechter approach Abstract: We study halo mass functions with the Press-Schechter formalism for\ninteracting dark matter models, where matter power spectra are damped due to\ndark acoustic oscillations in the early universe. After adopting a smooth\nwindow function, we calibrate the analytical model with numerical simulations\nfrom the \"effective theory of structure formation\" (ETHOS) project and fix the\nmodel parameters in the high mass regime, $M_{\\rm h}\\gtrsim3\\times10^{10}\\;{\\rm\nM}_{\\odot}$. We also perform high-resolution cosmological simulations with halo\nmasses down to $M_{\\rm h}\\sim10^8\\;{\\rm M}_{\\odot}$ to cover a wide mass range\nfor comparison. Although the model is calibrated with ETHOS1 and CDM\nsimulations for high halo masses at redshift $z=0$, it successfully reproduces\nsimulations for two other ETHOS models in the low mass regime at low and high\nredshifts. As an application, we compare the cumulative number density of\nhaloes to that of observed galaxies at $z=6$, and find the interacting dark\nmatter models with a kinetic decoupling temperature below $0.5\\ \\rm{keV}$ is\ndisfavored. We also perform the abundance-matching analysis and derive the\nstellar-halo mass relation for these models at $z=4$. Suppression in halo\nabundance leads to less massive haloes that host observed galaxies in the\nstellar mass range $M_*\\simeq 10^5-10^7\\ {\\rm M}_{\\odot}$. \n\n"}
{"id": "1811.03081", "contents": "Title: Forging new worlds: high-resolution synthetic galaxies with chained\n  generative adversarial networks Abstract: Astronomy of the 21st century increasingly finds itself with extreme\nquantities of data. This growth in data is ripe for modern technologies such as\ndeep image processing, which has the potential to allow astronomers to\nautomatically identify, classify, segment and deblend various astronomical\nobjects. In this paper, we explore the use of chained generative adversarial\nnetworks (GANs), a class of generative models that learn mappings from latent\nspaces to data distributions by modelling the joint distribution of the data,\nto produce physically realistic galaxy images as one use case of such models.\nIn cosmology, such datasets can aid in the calibration of shape measurements\nfor weak lensing by augmenting data with synthetic images. By measuring the\ndistributions of multiple physical properties, we show that images generated\nwith our approach closely follow the distributions of real galaxies, further\nestablishing state-of-the-art GAN architectures as a valuable tool for\nmodern-day astronomy. \n\n"}
{"id": "1811.03336", "contents": "Title: PynPoint: a modular pipeline architecture for processing and analysis of\n  high-contrast imaging data Abstract: The direct detection and characterization of planetary and substellar\ncompanions at small angular separations is a rapidly advancing field. Dedicated\nhigh-contrast imaging instruments deliver unprecedented sensitivity, enabling\ndetailed insights into the atmospheres of young low-mass companions. In\naddition, improvements in data reduction and PSF subtraction algorithms are\nequally relevant for maximizing the scientific yield, both from new and\narchival data sets. We aim at developing a generic and modular data reduction\npipeline for processing and analysis of high-contrast imaging data obtained\nwith pupil-stabilized observations. The package should be scalable and robust\nfor future implementations and in particular well suitable for the 3-5 micron\nwavelength range where typically (ten) thousands of frames have to be processed\nand an accurate subtraction of the thermal background emission is critical.\nPynPoint is written in Python 2.7 and applies various image processing\ntechniques, as well as statistical tools for analyzing the data, building on\nopen-source Python packages. The current version of PynPoint has evolved from\nan earlier version that was developed as a PSF subtraction tool based on PCA.\nThe architecture of PynPoint has been redesigned with the core functionalities\ndecoupled from the pipeline modules. Modules have been implemented for\ndedicated processing and analysis steps, including background subtraction,\nframe registration, PSF subtraction, photometric and astrometric measurements,\nand estimation of detection limits. The pipeline package enables end-to-end\ndata reduction of pupil-stabilized data and supports classical dithering and\ncoronagraphic data sets. As an example, we processed archival VLT/NACO L' and\nM' data of beta Pic b and reassessed the planet's brightness and position with\nan MCMC analysis, and we provide a derivation of the photometric error budget. \n\n"}
{"id": "1811.04917", "contents": "Title: Assessment of the Projection-induced Polarimetry Technique for\n  Constraining the Foreground Spectrum in Global 21 cm Cosmology Abstract: Detecting the cosmological sky-averaged (global) 21 cm signal as a function\nof observed frequency will provide a powerful tool to study the ionization and\nthermal history of the intergalactic medium (IGM) in the early Universe ($\\sim$\n400 million years after the Big Bang). The greatest challenge in conventional\ntotal-power global 21 cm experiments is the removal of the foreground\nsynchrotron emission ($\\sim 10^3$-$10^4$ K) to uncover the weak cosmological\nsignal (tens to hundreds of mK), especially since the intrinsic smoothness of\nthe foreground spectrum is corrupted by instrumental effects. Although the\nEDGES team has recently reported an absorption profile at 78 MHz in the\nsky-averaged spectrum, it is necessary to confirm this detection with an\nindependent approach. The projection effect from observing anisotropic\nforeground source emission with a wide-view antenna pointing at the North\nCelestial Pole (NCP) can induce a net polarization, referred as the\nProjection-Induced Polarization Effect (PIPE). Due to Earth's rotation,\nobservation centered at the circumpolar region will impose a dynamic sky\nmodulation on the net polarization's waveforms which is unique to the\nforeground component. In this study, we review the implementation practicality\nand underlying instrumental effects of this new polarimetry-based technique\nwith detailed numerical simulation and a testbed instrument, the Cosmic\nTwilight Polarimeter (CTP). In addition, we explore an SVD-based analysis\napproach for separating the foreground and instrumental effects from the\nbackground global 21 cm signal using the sky-modulated PIPE. \n\n"}
{"id": "1811.05951", "contents": "Title: Inflationary soft theorems revisited: A generalized consistency relation Abstract: We reconsider the derivation of soft theorems associated with\nnonlinearly-realized symmetries in cosmology. Utilizing the path integral, we\nderive a generalized consistency relation that relates a squeezed $(N+1)$-point\ncorrelation function to an $N$-point function, where the relevant soft mode is\nat early rather than late time. This generalized (early-late-time) version has\nwider applicability than the standard consistency relation where all modes are\nevaluated at late times. We elucidate the conditions under which the latter\nfollows from the former. A key ingredient is the physical mode condition: that\nthe nonlinear part of the symmetry transformation must match the time\ndependence of the dominant, long wavelength physical mode. This is closely\nrelated to, but distinct from, the adiabatic mode condition. Our derivation\nsheds light on a number of otherwise puzzling features of the standard\nconsistency relation: (1) the underlying nonlinearly-realized symmetries (such\nas dilation and special conformal transformation SCT) originate as residual\ngauge redundancies, yet the consistency relation has physical content---for\ninstance, it can be violated; (2) the standard consistency relation is known to\nfail in ultra-slow-roll inflation, but since dilation and SCT remain good\nsymmetries, there should be a replacement for the standard relation; (3) in\nlarge scale structure applications, it is known that the standard consistency\nrelation breaks down if the long wavelength power spectrum is too blue. The\nearly-late-time consistency relation helps address these puzzles. We introduce\na toy model where explicit checks of this generalized consistency relation are\nsimple to carry out. Our methodology can be adapted to cases where violations\nof the standard consistency relation involve additional light degrees of\nfreedom beyond the inflaton. \n\n"}
{"id": "1811.06124", "contents": "Title: The C-Band All-Sky Survey (C-BASS): Digital backend for the northern\n  survey Abstract: The C-Band All-Sky Survey (C-BASS) is an all-sky full-polarization survey at\na frequency of 5 GHz, designed to provide data complementary to the all-sky\nsurveys of WMAP and Planck and future CMB B-mode polarization imaging surveys.\nWe describe the design and performance of the digital backend used for the\nnorthern part of the survey. In particular we describe the features that\nefficiently implement the demodulation and filtering required to suppress\ncontaminating signals in the time-ordered data, and the capability for\nreal-time correction of detector non-linearity and receiver balance. \n\n"}
{"id": "1811.06644", "contents": "Title: SITELLE: An Imaging Fourier Transform Spectrometer for the\n  Canada-France-Hawaii Telescope Abstract: We present an overview of SITELLE, an Imaging Fourier Transform Spectrometer\n(iFTS) available at the 3.6-meter Canada-France-Hawaii Telescope. SITELLE is a\nMichelson-type interferometer able to reconstruct the spectrum of every light\nsource within its 11' field of view in filter-selected bands of the visible\n(350 to 900 nm). The spectral resolution can be adjusted up to R = 10 000 and\nthe spatial resolution is seeing-limited and sampled at 0.32 arcsec per pixel.\nWe describe the design of the instrument as well as the data reduction and\nanalysis process. To illustrate SITELLE's capabilities, we present some of the\ndata obtained during and since the August 2015 commissioning run. In\nparticular, we demonstrate its ability to separate the components of the [OII]\n$\\lambda\\lambda$ 3726,29 doublet in Orion and to reach R = 9500 around H-alpha;\nto detect diffuse emission at a level of 4 x 10e-17 erg/cm2/s/arcsec2; to\nobtain integrated spectra of stellar absorption lines in galaxies despite the\nwell-known multiplex disadvantage of the iFTS; and to detect emission-line\ngalaxies at different redshifts. \n\n"}
{"id": "1811.10615", "contents": "Title: Galaxy and Quasar Fueling Caught in the Act from the Intragroup to the\n  Interstellar Medium Abstract: We report the discovery of six spatially extended (10-100 kpc) line-emitting\nnebulae in the z=0.57 galaxy group hosting PKS0405-123, one of the most\nluminous quasars at z<1. The discovery is enabled by the Multi Unit\nSpectroscopic Explorer (MUSE) and provides tantalizing evidence connecting\nlarge-scale gas streams with nuclear activity on scales of <10 proper kpc\n(pkpc). One of the nebulae exhibits a narrow, filamentary morphology extending\nover 50 pkpc toward the quasar with narrow internal velocity dispersion (50\nkm/s) and is not associated with any detected galaxies, consistent with a cool\nintragroup medium (IGrM) filament. Two of the nebulae are 10 pkpc North and\nSouth of the quasar with tidal arm like morphologies. These two nebulae, along\nwith a continuum emitting arm extending 60 pkpc from the quasar are signatures\nof interactions which are expected to redistribute angular momentum in the host\ninterstellar medium (ISM) to facilitate star formation and quasar fueling in\nthe nucleus. The three remaining nebulae are among the largest and most\nluminous [O III] emitting `blobs' known (1400-2400 pkpc^2) and correspond both\nkinematically and morphologically with interacting galaxy pairs in the quasar\nhost group, consistent with arising from stripped ISM rather than large-scale\nquasar outflows. The presence of these large- and small-scale nebulae in the\nvicinity of a luminous quasar bears significantly on the effect of large-scale\nenvironment on galaxy and black hole fueling, providing a natural explanation\nfor the previously known correlation between quasar luminosity and cool\ncircumgalactic medium (CGM). \n\n"}
{"id": "1812.00119", "contents": "Title: Pre-selection of the Candidate Fields for Deep Imaging of the Epoch of\n  Reionization with SKA1-Low Abstract: The Square Kilometre Array (SKA) will be the first low-frequency instrument\nwith the capability to directly image the structures of the Epoch of\nReionization (EoR). Indeed, deep imaging of the EoR over 5 targeted fields of\n20 square degrees each has been selected as the highest priority science\nobjective for SKA1. Aiming at preparing for this highly challenging\nobservation, we perform an extensive pre-selection of the `quietest' and\n`cleanest' candidate fields in the southern sky to be suited for deep imaging\nof the EoR using existing catalogs and observations over a broad frequency\nrange. The candidate fields should meet a number of strict criteria to avoid\ncontaminations from foreground structures and sources. The candidate fields\nshould also exhibit both the lowest average surface brightness and smallest\nvariance to ensure uniformity and high quality deep imaging over the fields.\nOur selection eventually yields a sample of 7 `ideal' fields of 20 square\ndegrees in the southern sky that could be targeted for deep imaging of the EoR.\nFinally, these selected fields are convolved with the synthesized beam of\nSKA1-low stations to ensure that the effect of sidelobes from the far field\nbright sources is also weak. \n\n"}
{"id": "1812.00514", "contents": "Title: LSST Observing Strategy White Paper: LSST Observations of WFIRST Deep\n  Fields Abstract: The Wide-Field Infrared Survey Telescope (WFIRST) is expected to launch in\nthe mid-2020s. With its wide-field near-infrared (NIR) camera, it will survey\nthe sky to unprecedented detail. As part of normal operations and as the result\nof multiple expected dedicated surveys, WFIRST will produce several relatively\nwide-field (tens of square degrees) deep (limiting magnitude of 28 or fainter)\nfields. In particular, a planned supernova survey is expected to image 3 deep\nfields in the LSST footprint roughly every 5 days over 2 years. Stacking all\ndata, this survey will produce, over all WFIRST supernova fields in the LSST\nfootprint, ~12-25 deg^2 and ~5-15 deg^2 regions to depths of ~28 mag and ~29\nmag, respectively. We suggest LSST undertake mini-surveys that will match the\nWFIRST cadence and simultaneously observe the supernova survey fields during\nthe 2-year WFIRST supernova survey, achieving a stacked depth similar to that\nof the WFIRST data. We also suggest additional observations of these same\nregions throughout the LSST survey to get deep images earlier, have long-term\nmonitoring in the fields, and produce deeper images overall. These fields will\nprovide a legacy for cosmology, extragalactic, and transient/variable science. \n\n"}
{"id": "1812.01477", "contents": "Title: JOVIAL: Notebook-based Astronomical Data Analysis in the Cloud Abstract: Performing astronomical data analysis using only personal computers is\nbecoming impractical for the very large data sets produced nowadays. As\nanalysis is not a task that can be automatized to its full extent, the idea of\nmoving processing where the data is located means also moving the whole\nscientific process towards the archives and data centers. Using Jupyter\nNotebooks as a remote service is a recent trend in data analysis that aims to\ndeal with this problem, but harnessing the infrastructure to serve the\nastronomer without increasing the complexity of the service is a challenge. In\nthis paper we present the architecture and features of JOVIAL, a Cloud service\nwhere astronomers can safely use Jupyter notebooks over a personal space\ndesigned for high-performance processing under the high-availability principle.\nWe show that features existing only in specific packages can be adapted to run\nin the notebooks, and that algorithms can be adapted to run across the data\ncenter without necessarily redesigning them. \n\n"}
{"id": "1812.01650", "contents": "Title: An efficient approach to extract parameters from star cluster CMDs:\n  fitCMD Abstract: This work presents an approach (fitCMD) designed to obtain a comprehensive\nset of astrophysical parameters from colour-magnitude diagrams (CMDs) of star\nclusters. Based on initial mass function (IMF) properties taken from\nisochrones, fitCMD searches for the values of total (or cluster) stellar mass,\nage, global metallicity, foreground reddening, distance modulus, and\nmagnitude-dependent photometric completeness that produce the artificial CMD\nthat best reproduces the observed one; photometric scatter is also taken into\naccount in the artificial CMDs. Inclusion of photometric completeness proves to\nbe an important feature of fitCMD, something that becomes apparent especially\nwhen luminosity functions are considered. These parameters are used to build a\nsynthetic CMD that also includes photometric scatter. Residual minimization\nbetween the observed and synthetic CMDs leads to the best-fit parameters. When\ntested against artificial star clusters, fitCMD shows to be efficient both in\nterms of computational time and ability to recover the input values. \n\n"}
{"id": "1812.03995", "contents": "Title: Comments on arXiv:1811.00154 [astro-ph.IM] \"AGN Variability Analysis\n  Handbook\" Abstract: Why do we write this note?\n  It is erroneous to pretend to extract physical information from the\nexperimental light curves (time series) of astrophysical systems by means of\nlinear stochastic differential equations (LSDE). In general, the time evolution\nof these systems is governed by a set of nonlinear differential equations.\nHence, the LSDEs are not suitable to model their dynamics. In spite of this,\nrecently the LSDEs have been proposed as tools for the analysis of AGN light\ncurves. Their use in this context seems to be dictated by their simplicity\nrather than by a real physical argument. We stress in this note that the\ncorrect approach to the analysis of signals coming from systems with nonlinear\ndynamics is to tackle the problem using methodologies in well defined physical\ncontexts. \n\n"}
{"id": "1812.06725", "contents": "Title: Flares in Open Clusters with K2. I. M45 (Pleiades), M44 (Praesepe) and\n  M67 Abstract: The presence and strength of a stellar magnetic field and activity is rooted\nin a star's fundamental parameters such as mass and age. Can flares serve as an\naccurate stellar \"clock\"?\n  To explore if we can quantify an activity-age relation in the form of a\nflaring-age relation, we measured trends in the flaring rates and energies for\nstars with different masses and ages.\n  We investigated the time-domain photometry provided by Kepler's follow-up\nmission K2 and searched for flares in three solar metallicity open clusters\nwith well-known ages, M45 (0.125 Gyr), M44 (0.63 Gyr), and M67 (4.3 Gyr). We\nupdated and employed the automated flare finding and analysis pipeline\nAppaloosa, originally designed for Kepler. We introduced a synthetic flare\ninjection and recovery subroutine to ascribe detection and energy recovery\nrates for flares in a broad energy range for each light curve. We collected a\nsample of 1 761 stars, mostly late-K to mid-M dwarfs and found 751 flare\ncandidates with energies ranging from $4\\cdot10^{32}$ erg to $6\\cdot10^{34}$\nerg, of which 596 belong to M45, 155 to M44, and none to M67.\n  We find that flaring activity depends both on $T_\\mathrm{eff}$, and age. But\nall flare frequency distributions have similar slopes with $\\alpha\n\\approx2.0-2.4$, supporting a universal flare generation process. We discuss\nimplications for the physical conditions under which flares occur, and how the\nsample's metallicity and multiplicity affect our results. \n\n"}
{"id": "1812.06837", "contents": "Title: High-resolution spectroscopy of Boyajian's star during optical dimming\n  events Abstract: Boyajian's star is an apparently normal main sequence F-type star with a very\nunusual light curve. The dipping activity of the star, discovered during the\nKepler mission, presents deep, asymmetric, and aperiodic events. Here we\npresent high resolution spectroscopic follow-up during some dimming events\nrecorded post-Kepler observations, from ground-based telescopes. We analise\ndata from the HERMES, HARPS-N and FIES spectrographs to characterise the\nstellar atmosphere and to put some constraints on the hypotheses that have\nappeared in the literature concerning the occulting elements. The star's\nmagnetism, if existing, is not extreme. The spots on the surface, if present,\nwould occupy 0.02% of the area, at most. The chromosphere, irrespective of the\nepoch of observation, is hotter than the values expected from radiative\nequilibrium, meaning that the star has some degree of activity. We find no\nclear evidence of the interstellar medium nor exocoments being responsible for\nthe dimmings of the light curve. However, we detect at 1-2 sigma level, a\ndecrease of the radial velocity of the star during the first dip recorded after\nthe \\emph{\\emph{Kepler}} observations. We claim the presence of an optically\nthick object with likely inclined and high impact parameter orbits that\nproduces the observed Rossiter-McLaughlin effect. \n\n"}
{"id": "1812.11323", "contents": "Title: Resonant leptogenesis at TeV-scale and neutrinoless double beta decay Abstract: We investigate a resonant leptogenesis scenario by quasi-degenerate\nright-handed neutrinos which have TeV-scale masses. Especially, we consider the\ncase when two right-handed neutrinos are responsible to leptogenesis and the\nseesaw mechanism for active neutrino masses, and assume that the CP violation\noccurs only in the mixing matrix of active neutrinos. In this case the sign of\nthe baryon asymmetry depends on the Dirac and Majorana CP phases as well as the\nmixing angle of the right-handed neutrinos. It is shown how the yield of the\nbaryon asymmetry correlates with these parameters. In addition, we find that\nthe effective neutrino mass in the neutrinoless double beta decay receives an\nadditional constraint in order to account for the observed baryon asymmetry\ndepending on the masses and mixing angle of right-handed neutrinos. \n\n"}
{"id": "1901.00869", "contents": "Title: Gravitational Wave Denoising of Binary Black Hole Mergers with Deep\n  Learning Abstract: Gravitational wave detection requires an in-depth understanding of the\nphysical properties of gravitational wave signals, and the noise from which\nthey are extracted. Understanding the statistical properties of noise is a\ncomplex endeavor, particularly in realistic detection scenarios. In this\narticle we demonstrate that deep learning can handle the non-Gaussian and\nnon-stationary nature of gravitational wave data, and showcase its application\nto denoise the gravitational wave signals generated by the binary black hole\nmergers GW150914, GW170104, GW170608 and GW170814 from advanced LIGO noise. To\nexhibit the accuracy of this methodology, we compute the overlap between the\ntime-series signals produced by our denoising algorithm, and the numerical\nrelativity templates that are expected to describe these gravitational wave\nsources, finding overlaps ${\\cal{O}}\\gtrsim0.99$. We also show that our deep\nlearning algorithm is capable of removing noise anomalies from numerical\nrelativity signals that we inject in real advanced LIGO data. We discuss the\nimplications of these results for the characterization of gravitational wave\nsignals. \n\n"}
{"id": "1901.01359", "contents": "Title: Data-Driven Reconstruction of Gravitationally Lensed Galaxies using\n  Recurrent Inference Machines Abstract: We present a machine learning method for the reconstruction of the\nundistorted images of background sources in strongly lensed systems. This\nmethod treats the source as a pixelated image and utilizes the Recurrent\nInference Machine (RIM) to iteratively reconstruct the background source given\na lens model. Our architecture learns to minimize the likelihood of the model\nparameters (source pixels) given the data using the physical forward model (ray\ntracing simulations) while implicitly learning the prior of the source\nstructure from the training data. This results in better performance compared\nto linear inversion methods, where the prior information is limited to the\n2-point covariance of the source pixels approximated with a Gaussian form, and\noften specified in a relatively arbitrary manner. We combine our source\nreconstruction network with a convolutional neural network that predicts the\nparameters of the mass distribution in the lensing galaxies directly from\ntelescope images, allowing a fully automated reconstruction of the background\nsource images and the foreground mass distribution. \n\n"}
{"id": "1901.02418", "contents": "Title: Cosmology with kSZ: breaking the optical depth degeneracy with Fast\n  Radio Bursts Abstract: The small-scale cosmic microwave background (CMB) is dominated by\nanisotropies from the kinematic Sunyaev-Zeldovich (kSZ) effect, and upcoming\nexperiments will measure it very precisely, but the optical depth degeneracy\nlimits the cosmological information that can be extracted. At the same time,\nfast radio bursts (FRBs) are an exciting new frontier for astrophysics, but\ntheir usefulness as cosmological probes is currently unclear. We show that FRBs\nare uniquely suited for breaking the kSZ optical depth degeneracy. This opens\nup new possibilities for constraining cosmology with the kSZ effect, and new\ncosmological applications for FRBs. \n\n"}
{"id": "1901.02879", "contents": "Title: Towards reliable uncertainties in IR interferometry: The bootstrap for\n  correlated statistical & systematic errors Abstract: We propose a method to overcome the usual limitation of current data\nprocessing techniques in optical and infrared long-baseline interferometry:\nmost reduction pipelines assume uncorrelated statistical errors and ignore\nsystematics. We use the bootstrap method to sample the multivariate probability\ndensity function of the interferometric observables. It allows us to determine\nthe correlations between statistical error terms and their deviation from a\nGaussian distribution. In addition, we introduce systematics as an additional,\nhighly correlated error term whose magnitude is chosen to fit the data\ndispersion.\n  We have applied the method to obtain accurate measurements of stellar\ndiameters for under-resolved stars, i.e. smaller than the angular resolution of\nthe interferometer. We show that taking correlations and systematics has a\nsignificant impact on both the diameter estimate and its uncertainty. The\nrobustness of our diameter determination comes at a price: we obtain 4 times\nlarger uncertainties, of a few percent for most stars in our sample. \n\n"}
{"id": "1901.05463", "contents": "Title: Fundamentals of effective cloud management for the new NASA Astrophysics\n  Data System Abstract: The new NASA Astrophysics Data System (ADS) is designed with a\nserviceoriented architecture (SOA) that consists of multiple customized Apache\nSolr search engine instances plus a collection of microservices, containerized\nusing Docker, and deployed in Amazon Web Services (AWS). For complex systems,\nlike the ADS, this loosely coupled architecture can lead to a more scalable,\nreliable and resilient system if some fundamental questions are addressed.\nAfter having experimented with different AWS environments and deployment\nmethods, we decided in December 2017 to go with Kubernetes as our container\norchestration. Defining the best strategy to properly setup Kubernetes has\nshown to be challenging: automatic scaling services and load balancing traffic\ncan lead to errors whose origin is difficult to identify, monitoring and\nlogging the activity that happens across multiple layers for a single request\nneeds to be carefully addressed, and the best workflow for a Continuous\nIntegration and Delivery (CI/CD) system is not self-evident. We present here\nhow we tackle these challenges and our plans for the future. \n\n"}
{"id": "1901.08040", "contents": "Title: Data-driven estimation of the invisible energy of cosmic ray showers\n  with the Pierre Auger Observatory Abstract: The determination of the primary energy of extensive air showers using the\nfluorescence detection technique requires an estimation of the energy carried\naway by particles that do not deposit all their energy in the atmosphere. This\nestimation is typically made using Monte Carlo simulations and thus depends on\nthe assumed primary particle mass and on model predictions for neutrino and\nmuon production. In this work we present a new method to obtain the invisible\nenergy from events detected by the Pierre Auger Observatory. The method uses\nmeasurements of the muon number at ground level, and it allows us to reduce\nsignificantly the systematic uncertainties related to the mass composition and\nthe high energy hadronic interaction models, and consequently to improve the\nestimation of the energy scale of the Observatory. \n\n"}
{"id": "1901.11033", "contents": "Title: Metric Gaussian Variational Inference Abstract: Solving Bayesian inference problems approximately with variational approaches\ncan provide fast and accurate results. Capturing correlation within the\napproximation requires an explicit parametrization. This intrinsically limits\nthis approach to either moderately dimensional problems, or requiring the\nstrongly simplifying mean-field approach. We propose Metric Gaussian\nVariational Inference (MGVI) as a method that goes beyond mean-field. Here\ncorrelations between all model parameters are taken into account, while still\nscaling linearly in computational time and memory. With this method we achieve\nhigher accuracy and in many cases a significant speedup compared to traditional\nmethods. MGVI is an iterative method that performs a series of Gaussian\napproximations to the posterior. We alternate between approximating the\ncovariance with the inverse Fisher information metric evaluated at an\nintermediate mean estimate and optimizing the KL-divergence for the given\ncovariance with respect to the mean. This procedure is iterated until the\nuncertainty estimate is self-consistent with the mean parameter. We achieve\nlinear scaling by avoiding to store the covariance explicitly at any time.\nInstead we draw samples from the approximating distribution relying on an\nimplicit representation and numerical schemes to approximately solve linear\nequations. Those samples are used to approximate the KL-divergence and its\ngradient. The usage of natural gradient descent allows for rapid convergence.\nFormulating the Bayesian model in standardized coordinates makes MGVI\napplicable to any inference problem with continuous parameters. We demonstrate\nthe high accuracy of MGVI by comparing it to HMC and its fast convergence\nrelative to other established methods in several examples. We investigate\nreal-data applications, as well as synthetic examples of varying size and\ncomplexity and up to a million model parameters. \n\n"}
{"id": "astro-ph/0001396", "contents": "Title: Gamma-Ray Bursts via Pair Plasma Fireballs from Heated Neutron Stars Abstract: In this paper we model the emission from a relativistically expanding\nelectron-positron pair plasma fireball originating near the surface of a heated\nneutron star. This pair fireball is deposited via the annihilation of neutrino\npairs emanating from the surface of the hot neutron star. The heating of\nneutron stars may occur in close neutron star binary systems near their last\nstable orbit. We model the relativistic expansion and subsequent emission of\nthe plasma and find 10^51 to 10^52 ergs in gamma-rays are produced with\nspectral and temporal properties consistent with observed gamma-ray bursts. \n\n"}
{"id": "astro-ph/0007089", "contents": "Title: New results from the HRX BL Lac sample Abstract: We present results for the Hamburg BL Lac sample, based on data provided by\nthe RASS-BSC. By fitting a single power law to the X-ray data we find, in a\nnumber of objects, an additional absorbing component to the galactic value of\nNH, which might be attributed to intrinsic absorption. A more probable cause\nseems however to be a curvature in the X-ray spectra in the sense that they are\nmore curved for steeper slopes. The known relation between the X-ray spectral\nslope and the ratio between optical and X-ray flux alpha_ox also applies to\nthis BL Lac sample, even though less significant than in previous works. We\nalso find a dependence of X-ray luminosity on alpha_ox. \n\n"}
{"id": "astro-ph/0010201", "contents": "Title: Dynamical Bar Instability in Rotating Stars: Effect of General\n  Relativity Abstract: We study the dynamical stability against bar-mode deformation of rapidly and\ndifferentially rotating stars in the first post-Newtonian approximation of\ngeneral relativity. We vary the compaction of the star $M/R$ (where $M$ is the\ngravitational mass and $R$ the equatorial circumferential radius) between 0.01\nand 0.05 to isolate the influence of relativistic gravitation on the\ninstability. For compactions in this moderate range, the critical value of\n$\\beta \\equiv T/W$ for the onset of the dynamical instability (where $T$ is the\nrotational kinetic energy and $W$ the gravitational binding energy) slightly\ndecreases from $\\sim 0.26$ to $\\sim 0.25$ with increasing compaction for our\nchoice of the differential rotational law. Combined with our earlier findings\nbased on simulations in full general relativity for stars with higher\ncompaction, we conclude that relativistic gravitation {\\em enhances} the\ndynamical bar-mode instability, i.e. the onset of instability sets in for\nsmaller values of $\\beta$ in relativistic gravity than in Newtonian gravity. We\nalso find that once a triaxial structure forms after the bar-mode perturbation\nsaturates in dynamically unstable stars, the triaxial shape is maintained, at\nleast for several rotational periods. To check the reliability of our numerical\nintegrations, we verify that the general relativistic Kelvin-Helmholtz\ncirculation is well-conserved, in addition to rest-mass energy, total\nmass-energy, linear and angular momentum. Conservation of circulation indicates\nthat our code is not seriously affected by numerical viscosity. We determine\nthe amplitude and frequency of the quasi-periodic gravitational waves emitted\nduring the bar formation process using the quadrupole formula. \n\n"}
{"id": "astro-ph/0101479", "contents": "Title: How to Correct for Dust Absorption in Starbursts Abstract: We review new and published results to examine how well the bolometric flux\nof starbursts can be recovered from ultraviolet (UV) and optical observations.\nWe show that the effective absorption of starbursts can be substantial, up to\n\\~10 mag in the far UV, and ~5 mag in H-alpha, but apparently not as high as\nsome claims in the literature (several tens to a thousand mag). The bolometric\nfluxes of an IUE sample of starbursts can be recovered to 0.14 dex accuracy\nusing the UV flux and spectral slope. However, this relationship breaks down\nfor Ultra Luminous Infrared Galaxies (ULIGs). The H-alpha flux combined with\nthe Balmer decrement can be used to predict the bolometric flux to 0.5 dex\naccuracy for starbursts including most ULIGs. These results imply a foreground\nscreen component to the dust distribution. \n\n"}
{"id": "astro-ph/0101495", "contents": "Title: X-Ray Observations of Low-Mass X-Ray Binaries: Accretion Instabilities\n  on Long and Short Time-Scales Abstract: X-rays trace accretion onto compact objects in binaries with low mass\ncompanions at rates ranging up to near Eddington. Accretion at high rates onto\nneutron stars goes through cycles with time-scales of days to months. At lower\naverage rates the sources are recurrent transients; after months to years of\nquiescence, during a few weeks some part of a disk dumps onto the neutron star.\nQuasiperiodic oscillations near 1 kHz in the persistent X-ray flux attest to\ncircular motion close to the surface of the neutron star. The neutron stars are\nprobably inside their innermost stable circular orbits and the x-ray\noscillations reflect the structure of that region. The long term variations\nshow us the phenomena for a range of accretion rates. For black hole compact\nobjects in the binary, the disk flow tends to be in the transient regime.\nAgain, at high rates of flow from the disk to the black hole there are\nquasiperiodic oscillations in the frequency range expected for the innermost\npart of an accretion disk. There are differences between the neutron star and\nblack hole systems, such as two oscillation frequencies versus one. For both\ntypes of compact object there are strong oscillations below 100 Hz.\nInterpretations differ on the role of the nature of the compact object. \n\n"}
{"id": "astro-ph/0103344", "contents": "Title: Near infrared spectroscopy of starburst galaxies Abstract: (Abridged) We present new K-band spectroscopy for a sample of 48 starburst\ngalaxies, obtained using UKIRT in Hawaii. This constitutes a fair sample of the\nmost common types of starburst galaxies found in the nearby Universe. The\nvariety of near infrared spectral features shown by these galaxies implies\ndifferent bursts characteristics, which suggests that we survey galaxies with\ndifferent star formation histories or at different stages of their burst\nevolution.\n  Using synthetic starburst models, we conclude that the best ensemble of\nparameters which describe starburst galaxies in the nearby universe are a\nconstant rate of star formation, a Salpeter IMF with an upper mass cutoff equal\nto 30 solar mass and bursts ages between 10 Myr and 1 Gyr. The model is fully\nconsistent with the differences observed in the optical and FIR between the\ndifferent types of starbursts. It suggests that HII galaxies have younger\nbursts and lower metallicities than SBNGs, while LIRGs have younger bursts but\nhigher metallicities.\n  Our observations suggest that the starburst phenomenon must be a sustained or\nself--sustained phenomenon: either star formation is continuous in time or\nmultiple bursts happen in sequence over a relatively long period of time. The\ngenerality of our observations implies that this is a characteristic of\nstarburst galaxies in the nearby Universe. \n\n"}
{"id": "astro-ph/0105525", "contents": "Title: The BeppoSAX High Energy Large Area Survey HELLAS, III: testing\n  synthesis models for the X-ray background Abstract: The BeppoSAX High Energy Large Area Survey (HELLAS) has surveyed several tens\nof square degrees of the sky in the 5--10 keV band down to a flux of about 5\n10^-14 erg cm-2 s-1. The extrapolation of the HELLAS logN--logS towards fainter\nfluxes with an euclidean slope is consistent with the first XMM measurements,\nin the same energy band, which are a factor 20 more sensitive. The source\ncounts in the hardest band so far surveyed by X-ray satellites are used to\nconstrain XRB models. It is shown that in order to reproduce the 5--10 keV\ncounts over the range of fluxes covered by BeppoSAX and XMM a large fraction of\nhighly absorbed (logN_H = 23--24 cm-2), luminous (L_X > 10^44 erg s-1) AGN is\nneeded. A sizeable number of more heavily obscured, Compton thick, objects\ncannot be ruled out but it is not required by the present data. The model\npredicts an absorption distribution consistent with that found from the\nhardness ratios analysis of the so far identified HELLAS sources. Interestingly\nenough, there is evidence of a decoupling between X-ray absorption and optical\nreddening indicators especially at high redshifts/luminosities where several\nbroad line quasars show hardness ratios typical of absorbed power law models\nwith logN_H=22--24 cm-2. \n\n"}
{"id": "astro-ph/0106332", "contents": "Title: Mass Spectra from Turbulent Fragmentation Abstract: Turbulent fragmentation determines where and when protostellar cores form,\nand how they contract and grow in mass from the surrounding cloud material.\nMolecular cloud regions without turbulent driving sources, or where turbulence\nis driven on large scales, exhibit rapid and efficient star formation in a\nclustered mode, whereas interstellar turbulence that carries most energy on\nsmall scales results in isolated star formation with low efficiency. The clump\nmass spectrum of shock-generated density fluctuations in pure hydrodynamic,\nsupersonic turbulence is not well fit by a power law, and it is too steep at\nthe high-mass end to be in agreement with the observational data. When gravity\nis included in the turbulence models, local collapse occurs, and the spectrum\nextends towards larger masses as clumps merge together, a power-law description\ndN/dM ~ M^nu becomes possible with slope nu = -2. In the case of pure\ngravitational contraction the clump mass spectrum is shallower with nu = -3/2.\nThe mass spectrum of protostellar cores in regions without turbulent support\nand where turbulence is replenished on large-scales, however, is well described\nby a log-normal or by multiple power laws, similar to the stellar IMF at low\nand intermediate masses. In the case of small-scale turbulence, the core mass\nspectrum is too flat compared to the IMF for all masses. \n\n"}
{"id": "astro-ph/0107507", "contents": "Title: Can Photoionization Squelching Resolve the Sub-structure Crisis? Abstract: Cold Dark Matter theory predicts that the Local Group should contain many\nmore dwarf-sized objects than the observed number of dwarf galaxies --- the\nso-called sub-structure problem. We investigate whether the suppression of star\nformation in these small objects due to the presence of a photoionizing\nbackground can resolve the problem. We make use of results from recent\nhydrodynamic simulations to build a recipe for the suppression of gas infall\ninto semi-analytic galaxy formation models, and use these to predict the\nluminosity function of dwarf galaxies in the Local Group. In the models without\nphotoionization ``squelching'', we predict a large excess of faint dwarf\ngalaxies compared with the observed number in the Local Group --- thus, the\nusual recipe for supernovae feedback used in semi-analytic models does not\nsolve the sub-structure problem on its own. When we include photoionization\nsquelching, we find good agreement with the observations. We have neglected\ntidal destruction, which probably further reduces the number of dwarf galaxies.\nWe conclude that photoionizing squelching easily solves the sub-structure\nproblem. In fact, it is likely that once this effect is taken into account,\nmodels with reduced small-scale power (e.g. Warm Dark Matter) would\nunderproduce dwarf galaxies. \n\n"}
{"id": "astro-ph/0111008", "contents": "Title: The Nonlinear Turbulent Dynamo Abstract: We simulate the evolution of an initially weak magnetic field in forced\nturbulence for a range of Prandtl numbers. The field grows exponentially with\nthe Kulsrud-Anderson $k^{3/2}$ spectrum until the magnetic energy approaches\nthe viscous-scale kinetic energy, where the magnetic forces then backreact on\nthe velocity. Further growth proceeds more slowly until a saturated state is\nreached where the magnetic and kinetic energies are equal, and where the\nmagnetic energy exists primarily at the resistive scale. We discuss the\nstructure of this turbulence and the extrapolation of the results to\nastrophysically-large Prandtl numbers. \n\n"}
{"id": "astro-ph/0112227", "contents": "Title: UHECR propagation in the Galaxy: clustering versus isotropy Abstract: Recently the AGASA Collaboration presented data suggesting a significant\nclustering of ultra-high energy cosmic rays coming from the outer Galaxy\nregion. In this paper we calculate expected cosmic ray arrival distributions\nfor several simple, limiting source location scenarios and investigate the\npossibility of clustering and correlation effects. The role of the Galactic\nmagnetic field is discussed in detail. \n\n"}
{"id": "astro-ph/0201066", "contents": "Title: The Formation of the First Globular Clusters in Dwarf Galaxies Before\n  the Epoch of Reionization Abstract: We explore a mechanism for the formation of the first globular clusters,\noperating during the assembly of dwarf galaxies at high redshifts, z > 10. The\nsubstructure in the dark matter and the corresponding potential wells are\nresponsible for setting the cluster scale of ~10^5 M_sun. The second mass scale\nin the formation problem, the stellar scale of ~1 M_sun, is determined in turn\nby the processes that cool the gas. We address the origin of the first, cluster\nscale by means of three-dimensional numerical simulations of the collapsing\ndark matter and gaseous components. We find that the gas falls into the deepest\ndark subhalos, resulting in a system of ~ 5 proto-globular clouds. The\nincipient globular clusters lose their individual dark halos in the process of\nviolent relaxation, leading to the build-up of the general dark halo around the\ndwarf galaxy. \n\n"}
{"id": "astro-ph/0201527", "contents": "Title: Probing the dark energy with redshift space quasar clustering distortion Abstract: We have run Monte Carlo simulations, for quasar clustering redshift\ndistortions in the Two-Degree Field QSO Redshift Survey (2QZ), in order to\nelicit the power of redshift distortions (geometric Alcock-Paczynski and linear\nkinematic) to constrain the cosmological density and equation of state\nparameters, Omega_{m0}, Omega_{x0}, w, of a pressureless matter + dark energy\nmodel. It turns out that, for the cosmological constant case (w = -1), the test\nis especially sensitive to the difference Delta := Omega_{m0} - Omega_{Lambda\n0}, whereas for the spatially flat case (k = 0), it is quite competitive with\nSNAP and DEEP, besides being complimentary to them; furthermore, we find that,\nwhereas not knowing the actual value of the bias does not compromise the\ncorrect recovering of Delta, taking into account the linear velocity effect is\nabsolutely relevant, all within the 2 sigma confidence level. \n\n"}
{"id": "astro-ph/0204025", "contents": "Title: The Dynamical Evolution of Substructure Abstract: The evolution of substructure embedded in non-dissipative dark halos is\nstudied through N-body simulations of isolated systems, both in and out of\ninitial equilibrium, complementing cosmological simulations of the growth of\nstructure. We determine by both analytic calculations and direct analysis of\nthe N-body simulations the relative importance of various dynamical processes\nacting on the clumps, such as the removal of material by global tides,\nclump-clump heating, clump-clump merging and dynamical friction. Our comparison\nbetween merging and disruption processes implies that spiral galaxies cannot be\nformed in a proto-system that contains a few large clumps, but can be formed\nthrough the accretion of many small clumps; elliptical galaxies form in a more\nclumpy environment than do spiral galaxies. Our results support the idea that\nthe central cusp in the density profiles of dark halos is the consequence of\nself-limiting merging of small, dense halos. This implies that the collapse of\na system of clumps/substructure is not sufficient to form a cD galaxy, with an\nextended envelope; plausibly subsequent accretion of large galaxies is\nrequired. Persistent streams of material from disrupted clumps can be found in\nthe outer regions of the final system, and at an overdensity of around 0.75,\ncan cover 10% to 30% of the sky. \n\n"}
{"id": "astro-ph/0211344", "contents": "Title: The number and metallicities of the most metal-poor stars Abstract: Simple, one-zone models for inhomogeneous chemical evolution of the Galactic\nhalo are used to predict the number fraction of zero-metallicity, Population\nIII stars, which currently is empirically estimated at < 4e-4. These analytic\nmodels minimize the number of free parameters, highlighting the most\nfundamental constraints on halo evolution. There are disagreements of at least\nan order of magnitude between observations and predictions in limiting cases\nfor both homogeneous Simple Model and Simple Inhomogeneous Model (SIM). Hence,\nthis demonstrates a quantitative, unambiguous discrepancy in the observed and\nexpected fraction of Population III stars. We explore how the metallicity\ndistribution of the parent enrichment events f(z_0) drives the SIM and\npredictions for the Population III fraction. The SIM shows that the\npreviously-identified \"high halo\" and \"low halo\" populations are consistent\nwith a continuous evolutionary progression, and therefore may not necessarily\nbe physically distinct populations. Possible evolutionary scenarios for halo\nevolution are discussed within the SIM's simplistic one-zone paradigm.\n  The values of z_0 depend strongly on metal dispersal processes, thus we\ninvestigate interstellar mixing and mass transport, for the first time\nexplicitly incorporating this into a semi-analytic chemical evolution model.\nDiffusion is found to be inefficient for all phases, including the hot phase,\nof the interstellar medium (ISM): relevant diffusion lengths are 2 - 4 orders\nof magnitude smaller than corresponding length scales for turbulent mixing.\nRough relations for dispersal processes are given for multiphase ISM. These\nsuggest that the expected low-metallicity threshold above zero is consistent\nwith the currently observed limit. \n\n"}
{"id": "astro-ph/0212218", "contents": "Title: Cosmology with coalescing massive black holes Abstract: The gravitational waves generated in the coalescence of massive binary black\nholes will be measurable by LISA to enormous distances. Redshifts z~10 or\nlarger (depending somewhat on the mass of the binary) can potentially be probed\nby such measurements, suggesting that binary coalescences can be made into\ncosmological tools. We discuss two particularly interesting types of probes.\nFirst, by combining gravitational-wave measurements with information about the\nuniverse's cosmography, we can study the evolution of black hole masses and\nmerger rates as a function of redshift, providing information about the growth\nof structures at high redshift and possibly constraining hierarchical merger\nscenarios. Second, if it is possible to associate an ``electromagnetic''\ncounterpart with a coalescence, it may be possible to measure both redshift and\nluminosity distance to an event with less than ~1% error. Such a measurement\nwould constitute an amazingly precise cosmological standard candle.\nUnfortunately, gravitational lensing uncertainties will reduce the quality of\nthis candle significantly. Though not as amazing as might have been hoped, such\na candle would nonetheless very usefully complement other distance-redshift\nprobes, in particular providing a valuable check on systematic effects in such\nmeasurements. \n\n"}
{"id": "astro-ph/0301533", "contents": "Title: Galactic Halos of Fluid Dark Matter Abstract: Dwarf spiral galaxies - and in particular the prototypical DDO 154 - are\nknown to be completely dominated by an unseen component. The putative\nneutralinos - so far the favored explanation for the astronomical dark matter -\nfail to reproduce the well measured rotation curves of those systems because\nthese species tend to form a central cusp whose presence is not supported by\nobservation. We have considered here a self-coupled charged scalar field as an\nalternative to neutralinos and investigated whether a Bose condensate of that\nfield could account for the dark matter inside DDO 154 and more generally\ninside dwarf spirals. The size of the condensate turns out to be precisely\ndetermined by the scalar mass m and self-coupling lambda of the field. We find\nactually that for m^4 / lambda = 50 - 75 eV^4, the agreement with the\nmeasurements of the circular speed of DDO 154 is impressive whereas it lessens\nfor larger systems. The cosmological behavior of the field is also found to be\nconsistent - yet marginally - with the limits set by BBN on the effective\nnumber of neutrino families. We conclude that classical configurations of a\nscalar and self-coupled field provide a possible solution to the astronomical\ndark matter problem and we suggest further directions of research. \n\n"}
{"id": "astro-ph/0302182", "contents": "Title: Radio Emission from an Ultraluminous X-Ray Source Abstract: The physical nature of ultraluminous x-ray sources is uncertain. Stellar mass\nblack holes with beamed radiation and intermediate mass black holes with\nisotropic radiation are two plausible explanations. We discovered radio\nemission from an ultraluminous x-ray source in the dwarf irregular galaxy NGC\n5408. The x-ray, radio and optical fluxes as well as the x-ray spectral shape\nare consistent with beamed relativistic jet emission from an accreting stellar\nblack hole. If confirmed, this would suggest that the ultraluminous x-ray\nsources may be stellar-mass rather than intermediate mass black holes. However,\ninterpretation of the source as a jet-producing intermediate-mass black hole\ncannot be ruled out at this time. \n\n"}
{"id": "astro-ph/0302436", "contents": "Title: One-Armed Spiral Instability in Differentially Rotating Stars Abstract: We investigate the dynamical instability of the one-armed spiral m=1 mode in\ndifferentially rotating stars by means of 3+1 hydrodynamical simulations in\nNewtonian gravitation. We find that both a soft equation of state and a high\ndegree of differential rotation in the equilibrium star are necessary to excite\na dynamical m=1 mode as the dominant instability at small values of the ratio\nof rotational kinetic to potential energy, T/|W|. We find that this spiral mode\npropagates outward from its point of origin near the maximum density at the\ncenter to the surface over several central orbital periods. An unstable m=1\nmode triggers a secondary m=2 bar mode of smaller amplitude, and the bar mode\ncan excite gravitational waves. As the spiral mode propagates to the surface it\nweakens, simultaneously damping the emitted gravitational wave signal. This\nbehavior is in contrast to waves triggered by a dynamical m=2 bar instability,\nwhich persist for many rotation periods and decay only after a\nradiation-reaction damping timescale. \n\n"}
{"id": "astro-ph/0303108", "contents": "Title: Cosmic Microwave Radiation Anisotropies in Brane Worlds Abstract: We propose a new formulation to calculate the Cosmic Microwave Background\n(CMB) spectrum in the Randall Sundrum two-branes model based on recent\nprogresses in solving the bulk geometry using a low energy approximation. The\nevolution of the anisotropic stress imprinted on the brane by the 5D Weyl\ntensor is calculated. An impact of the dark radiation perturbation on CMB\nspectrum is investigated in a simple model assuming an initially\nscale-invariant adiabatic perturbations. The dark radiation perturbation\ninduces isocurvature perturbations, but the resultant spectrum can be quite\ndifferent from the prediction of simple mixtures of adiabatic and isocurvature\nperturbations due to Weyl anisotropic stress. \n\n"}
{"id": "astro-ph/0306040", "contents": "Title: The Hubble Constant from Gravitational Lens Time Delays Abstract: There are now 10 firm time delay measurements in gravitational lenses. The\nphysics of time delays is well understood, and the only important variable for\ninterpreting the time delays to determine H_0 is the mean surface mass density\n<k> (in units of the critical density for gravitational lensing) of the lens\ngalaxy at the radius of the lensed images. More centrally concentrated mass\ndistributions with lower <k> predict higher Hubble constants, with H_0~1-<k> to\nlowest order. While we cannot determine <k> directly given the available data\non the current time delay lenses, we find H_0=48+/-3 km/s/Mpc for the\nisothermal (flat rotation curve) models, which are our best present estimate\nfor the mass distributions of the lens galaxies. Only if we eliminate the dark\nmatter halo of the lenses and use a constant mass-to-light ratio (M/L) model to\nfind H_0=71+/-3 km/s/Mpc is the result consistent with local estimates.\nMeasurements of time delays in better-constrained systems or observations to\nobtain new constraints on the current systems provide a clear path to\neliminating the <k> degeneracy and making estimates of H_0 with smaller\nuncertainties than are possible locally. Independent of the value of H_0, the\ntime delay lenses provide a new and unique probe of the dark matter\ndistributions of galaxies and clusters because they measure the total (light +\ndark) matter surface density. \n\n"}
{"id": "astro-ph/0307187", "contents": "Title: An Extensive Census of HST Counterparts to Chandra X-ray Sources in the\n  Globular Cluster 47 Tucanae. I. Astrometry and Photometry Abstract: We report the largest number of optical identifications of X-ray sources yet\nobtained in a single globular cluster. Using deep Chandra/ACIS-I imaging and\nextensive HST studies with WFPC2, we have detected optical counterparts to at\nleast 22 cataclysmic variables (CVs) and 29 chromospherically active binaries\n(BY Dras and RS CVns) in 47 Tuc. These identifications are all based on tight\nastrometric matches between X-ray sources and objects with unusual (non main\nsequence) optical colors and/or optical variability. In the U vs U-V color\nmagnitude diagram (CMD), the CVs all show evidence for blue colors compared to\nthe main sequence, but most of them fall close to the main sequence in the V vs\nV-I CMD, showing that the secondary stars dominate the optical light. The X-ray\ndetected active binaries have magnitude offsets above the main sequence that\nare indistinguishable from those of the much larger sample of optical variables\n(eclipsing and contact binaries and BY Dras) detected in the WFPC2 studies of\nAlbrow et al. (2001). We also present the results of a new, deeper search for\noptical companions to MSPs. One possible optical companion to an MSP (47 Tuc T)\nwas found, adding to the two optical companions already known. Finally, we\nstudy several blue stars with periodic variability from Albrow et al. (2001)\nthat show little or no evidence for X-ray emission. The optical colors of these\nobjects differ from those of 47 Tuc (and field) CVs. \n\n"}
{"id": "astro-ph/0307422", "contents": "Title: Quantitative Interpretation of Quasar Microlensing Light Curves Abstract: We develop a general method for analyzing the light curves of microlensed\nquasars and apply it to the OGLE light curves of the four-image lens\nQ2237+0305. We simultaneously estimate the effective source velocity, the\naverage stellar mass, the stellar mass function, and the size and structure of\nthe quasar accretion disk. The light curves imply an effective source plane\nvelocity of 10200 km/s < v_e h / sqrt(<M>) < 39600 km/s (68% confidence). Given\nan independent estimate for the source velocity, found by combining estimates\nfor the peculiar velocity of the lens galaxy with its measured stellar velocity\ndispersion, we obtain a mean stellar mass of <M>=0.037h^2 solar masses\n(0.0059h^2 < <M>/Msun < 0.20h^2). We were unable to distinguish a Salpeter mass\nfunction from one in which all stars had the same mass, but we do find a strong\nlower bound of 50% on the fraction of the surface mass density represented by\nthe microlenses. Our models favor a standard thin accretion disk model as the\nsource structure over a simple Gaussian source. For a face-on, thin disk\nradiating as a black body with temperature profile T_s ~ R^(-3/4), the radius\nr_s where the temperature matches the filter pass band (2000 Angstroms or\nT_s(r_s)=70000K) is (1.4 x 10^15)/h cm < r_s < (4.5 x 10^15)/h cm. The flux\npredicted by the disk model agrees with the observed flux of the quasar, so\nnon-thermal or optically thin emission processes are not required. From the\ndisk structure we estimate a black hole mass of M_BH = (1.1_(-0.7)^(+1.4) x\n10^9) h^(-3/2) (L/L_E)^(-1/2) solar masses, consistent with the mass estimated\nunder the assumption that the quasar is radiating at the Eddington luminosity\n(L/L_E=1). \n\n"}
{"id": "astro-ph/0308002", "contents": "Title: Statistical isotropy of the Cosmic Microwave Background Abstract: The breakdown of statistical homogeneity and isotropy of cosmic perturbations\nis a generic feature of ultra large scale structure of the cosmos, in\nparticular, of non trivial cosmic topology. The statistical isotropy (SI) of\nthe Cosmic Microwave Background temperature fluctuations (CMB anisotropy) is\nsensitive to this breakdown on the largest scales comparable to, and even\nbeyond the cosmic horizon. We propose a set of measures, $\\kappa_\\ell$\n($\\ell=1,2,3, ...$) which for non-zero values indicate and quantify statistical\nisotropy violations in a CMB map. We numerically compute the predicted\n$\\kappa_\\ell$ spectra for CMB anisotropy in flat torus universe models.\nCharacteristic signature of different models in the $\\kappa_\\ell$ spectrum are\nnoted. \n\n"}
{"id": "astro-ph/0309726", "contents": "Title: Tracing a Z-track in the M31 X-ray Binary RX J0042.6+4115 Abstract: Four XMM-Newton observations of the core of M31, spaced at 6 month intervals,\nshow that the brightest point X-ray source, RX J0042.6+4115, has a 0.4-10 keV\nluminosity of ~5 10^38 erg/s, and exhibits significant variability in intensity\nand X-ray spectrum over a time scale of ~100 s including hard flares; such\nbehaviour is only observed in Z-sources and transient blackhole binaries in our\nGalaxy. The lightcurves, X-ray spectra and hardness-intensity data from the\nfour XMM-Newton observations all strongly suggest that it is a Z-source,\nbringing the total number of known Z-sources to nine. \n\n"}
{"id": "astro-ph/0311072", "contents": "Title: The Consistency of Cosmic Flows on 100 Mpc/h Scales Abstract: We have compared the bulk flow of recent large-scale peculiar velocity\nsurveys (SMAC, SC, Lauer and Postman, Willick, EFAR and Tonry's SNIa sample) to\neach other, allowing for the errors due to sparse sampling. We conclude that,\ncontrary to the current perception, there is no significant conflict between\nthese surveys. The combined peculiar velocity dataset samples a volume $\\sim\n100 \\h^{-1}$ mpc in radius and has a bulk flow of $350 \\pm 80 $ km/s. Allowing\nfor the sparse sampling, we find that this result is not in conflict with the\n$\\Lambda$CDM models. Structure(s) responsible for the large-scale motion have\nnot yet been identified, but some likely suspects are presently under\nsurveillance. \n\n"}
{"id": "astro-ph/0311220", "contents": "Title: Combined Long and Short Timescale X-ray Variability of NGC4051 with RXTE\n  and XMM-Newton Abstract: We present over 6.5 years of frequent X-ray observations of the NLS1 galaxy\nNGC4051 by RXTE together with a >100ks observation by XMM-Newton and so derive\na 2-10 keV PSD covering an unprecedent frequency range of over 6.5 decades from\n<10^-8 to >10^-2 Hz. This PSD is a very good match to the PSD of the galactic\nblack hole binary system (GBH) Cyg X-1 when in a `high', rather than `low',\nstate providing the first definite confirmation of an AGN in a `high' state. A\nbending, rather than sharply broken, powerlaw is a better description of the\nPSDs of Cyg X-1 in the high state and of NGC4051. At low frequencies the PSD of\nNGC4051 has a slope of -1.1 bending, at nu_B = 8 x 10^-4 Hz, to a slope of\nalpha_H ~ -2 (steeper at lower energies). If nu_B scales with mass, we imply a\nblack hole mass of 3 x 10^5 Msolar in NGC4051, consistent with the 5 x 10^5\nMsolar reverberation value. Hence NGC4051 is emitting at ~30% L_Edd.\n  NGC4051 follows the same rms-flux relationship as GBHs. Phase lags and\ncoherence between bands are also the same as in GBHs. The lag of soft by hard\nphotons increases, and coherence decreases, as band separation increases. The\nlag, and coherence, are greater for variations of longer Fourier period. This\nbehaviour suggests that higher photon energies and shorter variability\ntimescales are associated with smaller radii. Using also data from the\nliterature, we cannot fit all AGN to the same linear scaling of break timescale\nwith black hole mass. However broad line AGN are consistent with a linear\nscaling from Cyg X-1 in its low state and NLS1 galaxies scale better with Cyg\nX-1 in its high state. We suggest that the relationship between black hole mass\nand break timescale is a function of at least one other underlying parameter,\nwhich may be accretion rate or black hole spin. \n\n"}
{"id": "astro-ph/0312443", "contents": "Title: Cosmic distance-duality as probe of exotic physics and acceleration Abstract: In cosmology, distances based on standard candles (e.g. supernovae) and\nstandard rulers (e.g. baryon oscillations) agree as long as three conditions\nare met: (1) photon number is conserved, (2) gravity is described by a metric\ntheory with (3) photons travelling on unique null geodesics. This is the\ncontent of distance-duality (the reciprocity relation) which can be violated by\nexotic physics. Here we analyse the implications of the latest cosmological\ndata sets for distance-duality. While broadly in agreement and confirming\nacceleration we find a 2-sigma violation caused by excess brightening of SN-Ia\nat z > 0.5, perhaps due to lensing magnification bias. This brightening has\nbeen interpreted as evidence for a late-time transition in the dark energy but\nbecause it is not seen in the d_A data we argue against such an interpretation.\nOur results do, however, rule out significant SN-Ia evolution and extinction:\nthe \"replenishing\" grey-dust model with no cosmic acceleration is excluded at\nmore than 4-sigma despite this being the best-fit to SN-Ia data alone, thereby\nillustrating the power of distance-duality even with current data sets. \n\n"}
{"id": "astro-ph/0401189", "contents": "Title: The Evolution of Accreting Black Holes in Outburst Abstract: Black hole binaries exhibit dramatic changes in their X-ray spectral and\ntiming properties over time, providing important clues about the physical\nprocesses that occur in these systems. Black holes and black hole candidates\nare prime targets for RXTE with observational goals including the study of\nextreme gravitational fields and jet formation mechanisms. The great wealth of\ndata from RXTE has helped us to learn about these systems as well as raising\nnew questions about accreting black holes. RXTE observations have allowed us to\nstudy a wide range of black hole science topics including the connection\nbetween the accretion disk and jets, the geometry of the inner accretion flow,\nand the physical changes that occur between spectral states. In this\npresentation, I discuss significant results on these topics that have been\nobtained for persistent and transient black holes over the past several years,\nand I present results from our program of X-ray and radio observations during\nthe decays of black hole transient outbursts. \n\n"}
{"id": "astro-ph/0402514", "contents": "Title: Phase Transitions in Nucleonic Matter and Neutron-Star Cooling Abstract: A new scenario for neutron-star cooling is proposed, based on the\ncorrespondence between pion condensation, occurring in neutron matter due to\ncritical spin-isospin fluctuations, and the metal-insulator phase transition in\na two-dimensional electron gas. Beyond the threshold density for pion\ncondensation, where neutron-star matter loses its spatial homogeneity, the\nneutron single-particle spectrum acquires an insulating gap that quenches\nneutron contributions to neutrino-production reactions and to the star's\nspecific heat. In the liquid phase at densities below the transition point,\nspin-isospin fluctuations are found to play dual roles. On the one hand, they\nlead to a multi-sheeted neutron Fermi surface that extends to low momenta,\nthereby activating the normally forbidden direct-Urca cooling mechanism; on the\nother, they amplify the nodeless $P$-wave neutron superfluid gap while\nsuppressing $S$-wave pairing. In this picture, lighter stars without a\npion-condensed core experience slow cooling, while enhanced cooling occurs in\nheavier stars through direct-Urca emission from a narrow shell of the interior. \n\n"}
{"id": "astro-ph/0402579", "contents": "Title: The Temperature of the CMB at 10 GHz Abstract: We report the results of an effort to measure the low frequency portion of\nthe spectrum of the Cosmic Microwave Background Radiation (CMB), using a\nballoon-borne instrument called ARCADE (Absolute Radiometer for Cosmology,\nAstrophysics, and Diffuse Emission). These measurements are to search for\ndeviations from a thermal spectrum that are expected to exist in the CMB due to\nvarious processes in the early universe. The radiometric temperature was\nmeasured at 10 and 30 GHz using a cryogenic open-aperture instrument with no\nemissive windows. An external blackbody calibrator provides an in situ\nreference. A linear model is used to compare the radiometer output to a set of\nthermometers on the instrument. The unmodeled residuals are less than 50 mK\npeak-to-peak with a weighted RMS of 6 mK. Small corrections are made for the\nresidual emission from the flight train, atmosphere, and foreground Galactic\nemission. The measured radiometric temperature of the CMB is 2.721 +/- 0.010 K\nat 10 GHz and 2.694 +/- 0.032 K at 30 GHz. \n\n"}
{"id": "astro-ph/0403537", "contents": "Title: Detection of D2H+ in the Dense Interstellar Medium Abstract: The 692 GHz para ground-state line of D2H+ has been detected at the Caltech\nSubmillimeter Observatory towards the pre-stellar core 16293E. The derived D2H+\nabundance is comparable to that of H2D+, as determined by observations of the\n372 GHz line of ortho-H2D+. This is an observational verification of recent\ntheoretical predictions (Roberts, Herbst & Millar 2003), developed to explain\nthe large deuteration ratios observed in cold, high-density regions of the\ninterstellar medium associated with low mass pre-stellar cores and protostars.\nThis detection confirms expectations that the multiply deuterated forms of H3+\nwere missing factors of earlier models. The inclusion of D2H+ and D3+ in the\nmodels leads to predictions of higher values of the D/H ratio in the gas phase. \n\n"}
{"id": "astro-ph/0404543", "contents": "Title: Chandra Observations of Radio-Loud Quasars at z > 4: X-rays from the\n  Radio Beacons of the Early Universe Abstract: We present the results of Chandra observations of six radio-loud quasars\n(RLQs) and one optically bright radio-quiet quasar (RQQ) at z = 4.1-4.4. These\nobservations cover a representative sample of RLQs with moderate radio-loudness\n(R ~ 40-400), filling the X-ray observational gap between optically selected\nRQQs and the five known blazars at z > 4 (R ~ 800-27000). We study the\nrelationship between X-ray luminosity and radio-loudness for quasars at high\nredshift and constrain RLQ X-ray continuum emission and absorption. From a\njoint spectral fit of nine moderate-R RLQs observed by Chandra, we find\ntentative evidence for absorption above the Galactic N_H, with a best-fit\nneutral intrinsic column density of N_H = 2.4^{+2.0}_{-1.8} x 10^{22} cm^{-2},\nconsistent with earlier claims of increased absorption toward high-redshift\nRLQs. We also search for evidence of an enhanced jet-linked component in the\nX-ray emission due to the increased energy density of the cosmic microwave\nbackground (CMB) at high redshift, but we find neither spatial detections of\nX-ray jets nor a significant enhancement in the X-ray emission relative to\ncomparable RLQs at low-to-moderate redshifts. Overall, the z ~ 4-5 RLQs have\nbasic X-ray properties consistent with comparable RLQs in the local universe,\nsuggesting that the accretion/jet mechanisms of these objects are similar as\nwell. \n\n"}
{"id": "astro-ph/0406656", "contents": "Title: A Comparison of Intermediate Mass Black Hole Candidate ULXs and\n  Stellar-Mass Black Holes Abstract: Cool thermal emission components have recently been revealed in the X-ray\nspectra of a small number of ultra-luminous X-ray (ULX) sources with L_X > 1\nE+40 erg/s in nearby galaxies. These components can be well fitted with\naccretion disk models, with temperatures approximately 5-10 times lower than\ndisk temperatures measured in stellar-mass Galactic black holes when observed\nin their brightest states. Because disk temperature is expected to fall with\nincreasing black hole mass, and because the X-ray luminosity of these sources\nexceeds the Eddington limit for 10 Msun black holes (L_Edd = 1.3 E+39 erg/s),\nthese sources are extremely promising intermediate-mass black hole candidates\n(IMBHCs). In this Letter, we directly compare the inferred disk temperatures\nand luminosities of these ULXs, with the disk temperatures and luminosities of\na number of Galactic black holes. The sample of stellar-mass black holes was\nselected to include different orbital periods, companion types, inclinations,\nand column densities. These ULXs and stellar-mass black holes occupy distinct\nregions of a L_X -- kT diagram, suggesting these ULXs may harbor IMBHs. We\nbriefly discuss the important strengths and weaknesses of this interpretation. \n\n"}
{"id": "astro-ph/0407133", "contents": "Title: Spectroscopy of PNe in Sextans A, Sextans B, NGC 3109 and Fornax Abstract: Planetary nebulae (PNe) and HII regions provide a probe of the chemical\nenrichment and star formation history of a galaxy from intermediate ages to the\npresent day. We present the first results of NTT spectroscopy of HII regions\nand/or PNe in four nearby dwarf galaxies: Sextans A, Sextans B, NGC 3109, and\nFornax. For all PNe and some of the HII regions in these galaxies we have\nobtained elemental abundances via the classic Te-method based on the detection\nof the [OIII] 4363 line. The oxygen abundances in three HII regions of Sextans\nA are all consistent within the individual rms uncertainties. The oxygen\nabundance in the PN of Sextans A is however significantly higher. This PN is\neven more enriched in nitrogen and helium, implying its classification as a PN\nof Type I. The presumably unaffected PN abundances of S and Ar are well below\nthose in the HII regions, indicating a lower metallicity at the epoch of the PN\nprogenitor formation. For two HII regions in Sextans B, the oxygen abundances\ndo not differ within the rms uncertainties. The third one is, however, twice as\nmetal-rich, providing evidence for the inhomogeneity of the current metallicity\ndistribution in Sextans B. For the PN in Sextans B we measured an O/H that is\nconsistent with that of the low-metallicity HII regions. For NGC 3109 our\npreliminary results indicate that the oxygen abundances of PNe and HII regions\nare all within a small range of $\\pm$0.15 dex. For the PN in Fornax, Ne, Ar and\nS abundances suggest that the ISM metallicity was $\\sim$0.3 dex lower at the\nepoch of the PN progenitor's formation, compared to the O/H value derived for\nthe PN (abridged). \n\n"}
{"id": "astro-ph/0410266", "contents": "Title: Particle Acceleration, Magnetic Field Generation, and Emission in\n  Relativistic Shocks Abstract: Shock acceleration is an ubiquitous phenomenon in astrophysical plasmas.\nPlasma waves and their associated instabilities (e.g., Buneman, Weibel and\nother two-stream instabilities) created in collisionless shocks are responsible\nfor particle (electron, positron, and ion) acceleration. Using a 3-D\nrelativistic electromagnetic particle (REMP) code, we have investigated\nparticle acceleration associated with a relativistic jet front propagating into\nan ambient plasma. We find small differences in the results for no ambient and\nmodest ambient magnetic fields. Simulations show that the Weibel instability\ncreated in the collisionless shock front accelerates jet and ambient particles\nboth perpendicular and parallel to the jet propagation direction. The small\nscale magnetic field structure generated by the Weibel instability is\nappropriate to the generation of ``jitter'' radiation from deflected electrons\n(positrons) as opposed to synchrotron radiation. The jitter radiation resulting\nfrom small scale magnetic field structures may be important for understanding\nthe complex time structure and spectral evolution observed in gamma-ray bursts\nor other astrophysical sources containing relativistic jets and relativistic\ncollisionless shocks. \n\n"}
{"id": "astro-ph/0411325", "contents": "Title: The Calan-Yale Deep Extragalactic Research (CYDER) Survey: Optical\n  Properties and Deep Spectroscopy of Serendipitous X-ray Sources Abstract: We present the first results from the Cal\\'an-Yale Deep Extragalactic\nResearch (CYDER) survey. The main goal of this survey is to study serendipitous\nX-ray sources detected by Chandra in an intermediate flux range\n($10^{-15}-10^{-12}$ ergs s$^{-1}$) that comprises most of the X-ray\nbackground. 267 X-ray sources spread over 5 archived fields were detected. The\n$\\log N-\\log S$ distribution obtained for this sample is consistent with the\nresults of other surveys. Deep $V$ and $I$ images were taken of these fields in\norder to calculate X-ray-to-optical flux ratios. Identifications and redshifts\nwere obtained for 106 sources using optical spectroscopy from 8-m class\ntelescopes to reach the optically faintest sources, to the same level as deeper\nX-ray fields like the Chandra Deep Fields, showing that the nature of sources\ndetected depends mostly on the optical limit for spectroscopy. In general,\nsources optically classified as obscured Active Galactic Nuclei (AGNs) have\nredder optical colors than unobscured AGN. A rough correlation between\n$f_X/f_{\\rm opt}$ and hard X-ray luminosity was found for obscured AGN\nconfirming the prediction by existing models that in obscured AGN the optical\nlight is completely dominated by the host galaxy. The previously claimed\ndecrease of the obscured to unobscured AGN ratio with increasing X-ray\nluminosity is observed. However, this correlation can be explained as a\nselection effect caused by the lower optical flux of obscured AGN. Comparison\nbetween the observed $N_H$ distribution and predictions by existing models\nshows that the sample appears complete up to $N_H<3\\times 10^{22}$ cm$^{-2}$,\nwhile for more obscured sources incompleteness plays an important role in the\nobserved obscured to unobscured AGN ratio. \n\n"}
{"id": "astro-ph/0411679", "contents": "Title: Low-Mass Companions to Solar-Type Stars Abstract: We present preliminary results from a coronagraphic survey of young nearby\nSun-like stars using the Palomar and Keck adaptive optics systems. We have\ntargeted 251 solar analogs (F5-K5) at 20-160 pc from the Sun, spanning the\n3-3000 Myr age range. The youngest (<500 Myr) 100 of these have been imaged\nwith deeper exposures to search for sub-stellar companions. The deep survey is\nsensitive to brown-dwarf companions at separations >0.5\" from their host stars,\nwith sensitivity extending to planetary-mass (5-15 Mjup) objects at wider (>3\")\nseparations. Based on the discovery of a number of new low-mass (<0.2 Msun)\nstellar companions, we infer that their frequency at >20 AU separations (probed\nvia direct imaging) may be greater (12%) than that found from radial velocity\nsurveys probing <4 AU separations (6%; Mazeh et al. 2003). We also report the\nastrometric confirmation of the first sub-stellar companion from the survey -\nan L4 brown dwarf at a projected distance of 44 AU from the 500 Myr-old star HD\n49197. Based on this detection, we estimate that the frequency of sub-stellar\ncompanions to solar-type stars is at least 1%, and possibly of order a few per\ncent. \n\n"}
{"id": "astro-ph/0412325", "contents": "Title: Cluster Mergers and Non-Thermal Phenomena: A Statistical\n  Magneto-Turbulent Model Abstract: With the aim to investigate the statistical properties and the connection\nbetween thermal and non-thermal properties of the ICM in galaxy clusters, we\nhave developed a statistical magneto-turbulent model which describes, at the\nsame time, the evolution of the thermal and non-thermal emission from galaxy\nclusters. In particular, starting from the cosmological evolution of clusters,\nwe follow cluster mergers, calculate the spectrum of the magnetosonic waves\ngenerated in the ICM during these mergers, the evolution of relativistic\nelectrons and the resulting synchrotron and Inverse Compton spectra. We show\nthat the broad band (radio and hard x-ray) non-thermal spectral properties of\ngalaxy clusters can be well accounted for by our model for viable values of the\nparameters. \n\n"}
{"id": "astro-ph/0502210", "contents": "Title: The structural and scaling properties of nearby galaxy clusters - II.\n  The M-T relation Abstract: Using a sample of ten nearby (z< 0.15), relaxed galaxy clusters in the\ntemperature range [2-9] keV, we have investigated the scaling relation between\nthe mass at various density contrasts (delta=2500,1000,500,200) and the cluster\ntemperature. The masses are derived from NFW-type model fits to mass profiles,\nobtained under the hydrostatic assumption using precise measurements, with XMM,\nat least down to delta=1000. The logarithmic slope of the M-T relation is well\nconstrained and is the same at all delta, reflecting the self-similarity of the\nmass profiles. At delta=500, the slope of the relation for the sub-sample of\nhot clusters (kT>3.5 keV) is consistent with the standard self-similar\nexpectation: alpha= 1.49\\pm0.15. The relation steepens when the whole sample is\nconsidered: alpha=1.71\\pm0.09. The normalisation of the relation is discrepant\n(by ~ 30%), at all density contrasts, with the prediction from purely\ngravitation based models. Models that take into account radiative cooling and\ngalaxy feedback are generally in better agreement with our data. We argue that\nremaining discrepancies, in particular at low delta, are more likely due to\nproblems with models of the ICM thermal structure rather than to an incorrect\nestimate of the mass from X-ray data. \n\n"}
{"id": "astro-ph/0504097", "contents": "Title: Simulating the joint evolution of quasars, galaxies and their\n  large-scale distribution Abstract: The cold dark matter model has become the leading theoretical paradigm for\nthe formation of structure in the Universe. Together with the theory of cosmic\ninflation, this model makes a clear prediction for the initial conditions for\nstructure formation and predicts that structures grow hierarchically through\ngravitational instability. Testing this model requires that the precise\nmeasurements delivered by galaxy surveys can be compared to robust and equally\nprecise theoretical calculations. Here we present a novel framework for the\nquantitative physical interpretation of such surveys. This combines the largest\nsimulation of the growth of dark matter structure ever carried out with new\ntechniques for following the formation and evolution of the visible components.\nWe show that baryon-induced features in the initial conditions of the Universe\nare reflected in distorted form in the low-redshift galaxy distribution, an\neffect that can be used to constrain the nature of dark energy with next\ngeneration surveys. \n\n"}
{"id": "astro-ph/0505296", "contents": "Title: Winds, B-Fields, and Magnetotails of Pulsars Abstract: We investigate the emission of rotating magnetized neutron stars due to the\nacceleration and radiation of particles in the relativistic wind and in the\nmagnetotail of the star. We consider that the charged particles are accelerated\nby driven collisionless reconnection. Outside of the light cylinder, the star's\nrotation acts to wind up the magnetic field to form a predominantly azimuthal,\nslowly decreasing with distance, magnetic field of opposite polarity on either\nside of the equatorial plane normal to the star's rotation axis. The magnetic\nfield annihilates across the equatorial plane with the magnetic energy going to\naccelerate the charged particles to relativistic energies. For a typical\nsupersonically moving pulsar, the star's wind extends outward to the standoff\ndistance with the interstellar medium. At larger distances, the power output of\npulsar's wind $\\dot{E}_w$ of electromagnetic field and relativistic particles\nis {\\it redirected and collimated into the magnetotail} of the star. In the\nmagnetotail it is proposed that equipartition is reached between the magnetic\nenergy and the relativistic particle energy. For such conditions, synchrotron\nradiation from the magnetotails may be a significant fraction of $\\dot{E}_w$\nfor high velocity pulsars. An equation is derived for the radius of the\nmagnetotail $r_m(z^\\prime)$ as a function of distance $z^\\prime$ from the star.\nFor large distances $z^\\prime$, of the order of the distance travelled by the\nstar, we argue that the magnetotail has a `trumpet' shape owing to the slowing\ndown of the magnetotail flow. \n\n"}
{"id": "astro-ph/0510149", "contents": "Title: The Evolution of Stellar Mass in the NICMOS UDF and the CFHTLS Deep\n  Fields Abstract: We measure the build-up of the stellar mass of galaxies from z=6 to z=1.\nUsing 15 band multicolour imaging data in the NICMOS Ultra Deep Field we derive\nphotometric redshifts and masses for 796 galaxies down to H_AB=26.5. The\nderived evolution of the global stellar mass density of galaxies is consistent\nwith previous star formation rate density measurements over the observed range\nof redshifts. Ongoing research in the CFHTLS Deep Fields confirms this result\nat lower redshifts. Further, if the sample is split by morphological type, a\nsubstantial increase is seen in the number of bulge dominated galaxies relative\nto disk-dominated galaxies since z=1. \n\n"}
{"id": "astro-ph/0601327", "contents": "Title: Evolution of the Color-Magnitude Relation in High-Redshift Clusters:\n  Blue Early-Type Galaxies and Red Pairs in RDCS J0910+5422 Abstract: The color-magnitude relation has been determined for the RDCS J0910+5422\ncluster of galaxies at redshift z = 1.106. Cluster members were selected from\nHST ACS images, combined with ground--based near--IR imaging and optical\nspectroscopy. The observed early--type color--magnitude relation (CMR) in\n(i_775 -z_850) versus z_850 shows intrinsic scatters in color of 0.042 +/-\n0.010 mag and 0.044 +/- 0.020 mag for ellipticals and S0s, respectively. From\nthe scatter about the CMR, a mean luminosity--weighted age t > 3.3 Gyr (z > 3)\nis derived for the elliptical galaxies.\n  Strikingly, the S0 galaxies in RDCS J0910+5422 are systematically bluer in\n(i_775 - z_850) by 0.07 +/- 0.02 mag, with respect to the ellipticals. The\nellipticity distribution as a function of color indicates that the face-on S0s\nin this particular cluster have likely been classified as elliptical. Thus, if\nanything, the offset in color between the elliptical and S0 populations may be\neven more significant.\n  The color offset between S0 and E corresponds to an age difference of ~1 Gyr,\nfor a single-burst solar metallicity model. A solar metallicity model with an\nexponential decay in star formation will reproduce the offset for an age of 3.5\nGyr, i.e. the S0s have evolved gradually from star forming progenitors.\n  The early--type population in this cluster appears to be still forming. The\nblue early-type disk galaxies in RDCS J0910+5422 likely represent the direct\nprogenitors of the more evolved S0s that follow the same red sequence as\nellipticals in other clusters.\n  Thirteen red galaxy pairs are observed and the galaxies associated in pairs\nconstitute ~40% of the CMR galaxies in this cluster. \n\n"}
{"id": "astro-ph/0601658", "contents": "Title: Newtonian mechanics of neutron superfluid in elastic star crust Abstract: To account for pulsar frequency glitches, it is necessary to use a neutron\nstar crust model allowing not only for neutron superfluidity but also for\nelastic solidity. These features have been treated separarately in previous\ntreatments of crust matter, but are combined here in a unified treatment that\nis based on the use of a Lagrangian master functon, so that the coherence the\nsystem is ensured by the relevant Noether identities. As well as the model\nobtained directly from the variation principle, the same master function can\nprovide other conservative alternatives, allowing in particular for the effect\nof perfect vortex pinning. It is also shown how such models can be generalised\nto allow for dissipative effects, including that of imperfect pinning, meaning\nvortex drag or creep. \n\n"}
{"id": "astro-ph/0602005", "contents": "Title: How galaxies lose their angular momentum Abstract: The processes are investigated by which gas loses its angular momentum during\nthe protogalactic collapse phase, leading to disk galaxies that are too compact\nwith respect to the observations. High-resolution N-body/SPH simulations in a\ncosmological context are presented including cold gas and dark matter. A halo\nwith quiet merging activity since z~3.8 and with a high spin parameter is\nanalysed that should be an ideal candidate for the formation of an extended\ngalactic disk. We show that the gas and the dark matter have similar specific\nangular momenta until a merger event occurs at z~2 with a mass ratio of 5:1.\nAll the gas involved in the merger loses a substantial fraction of its specific\nangular momentum due to tidal torques and falls quickly into the center.\nDynamical friction plays a minor role,in contrast to previous claims. In fact,\nafter this event a new extended disk begins to form from gas that was not\ninvolved in the 5:1 merger event and that falls in subsequently. We argue that\nthe angular momentum problem of disk galaxy formation is a merger problem: in\ncold dark matter cosmology substantial mergers with mass ratios of 1:1 to 6:1\nare expected to occur in almost all galaxies. We suggest that energetic\nfeedback processes could in principle solve this problem, however only if the\nheating occurs at the time or shortly before the last substantial merger event.\nGood candidates for such a coordinated feedback would be a merger-triggered\nstar burst or central black hole heating. If a large fraction of the low\nangular momentum gas would be ejected as a result of these processes, late-type\ngalaxies could form with a dominant extended disk component, resulting from\nlate infall, a small bulge-to-disk ratio and a low baryon fraction, in\nagreement with observations. \n\n"}
{"id": "astro-ph/0603279", "contents": "Title: The shock break-out of GRB 060218/SN 2006aj Abstract: Although the link between long Gamma Ray Bursts (GRBs) and supernovae (SNe)\nhas been established, hitherto there have been no observations of the beginning\nof a supernova explosion and its intimate link to a GRB. In particular, we do\nnot know however how a GRB jet emerges from the star surface nor how a GRB\nprogenitor explodes. Here we report on observations of the close GRB060218 and\nits connection to SN2006aj. In addition to the classical non-thermal emission,\nGRB060218 shows a thermal component in its X-ray spectrum, which cools and\nshifts into the optical/UV band as time passes. We interpret these features as\narising from the break out of a shock driven by a mildly relativistic shell\ninto the dense wind surrounding the progenitor. Our observations allow us for\nthe first time to catch a SN in the act of exploding, to directly observe the\nshock break-out and to provide strong evidence that the GRB progenitor was a\nWolf-Rayet star. \n\n"}
{"id": "astro-ph/0607642", "contents": "Title: Does Radiative Feedback by the First Stars Promote or Prevent Second\n  Generation Star Formation? Abstract: We study the effect of starlight from the first stars on the ability of other\nminihaloes in their neighborhood to form additional stars. The question of what\nthe dynamical consequences were for these target minihaloes, of their exposure\nto the ionizing and dissociating starlight from the Pop III star requires a\nfull radiation-hydrodynamics calculation. Towards this end, we have performed a\nseries of detailed, 1D, radiation-hydrodynamical simulations. We have varied\nthe distance to the source (and, hence, the flux) and the mass and evolutionary\nstage of the target haloes to quantify this effect. We find: (1) trapping of\nthe I-front and its transformation from R-type to D-type, preceded by a shock\nfront; (2) photoevaporation of the ionized gas (i.e. all gas originally located\noutside the trapping radius); (3) formation of an H_2 precursor shell which\nleads the I-front, stimulated by partial photoionization; and (4) the\nshock-induced formation of H_2 in the minihalo neutral core when the shock\nspeeds up and partially ionizes the gas. The fate of the neutral core is mostly\ndetermined by the response of the core to this shock front, which leads to\nmolecular cooling and collapse that, when compared to the same halo without\nexternal radiation, is either: (a) expedited, (b) delayed, (c) unaltered, or\n(d) reversed or prevented, depending upon the flux (i.e. distance to the\nsource) and the halo mass and evolutionary stage. Roughly speaking, most haloes\nthat were destined to cool, collapse, and form stars in the absence of external\nradiation are found to do so even when exposed to the first Pop III star in\ntheir neighborhood, while those that would not have done so are still not able\nto. (abridged) \n\n"}
{"id": "astro-ph/0608014", "contents": "Title: Spectropolarimetry of PKS 0040-005 and the Orientation of Broad\n  Absorption Line Quasars Abstract: We have used the Very Large Telescope (VLT) to obtain spectropolarimetry of\nthe radio-loud, double-lobed broad absorption line (BAL) quasar PKS 0040-005.\nWe find that the optical continuum of PKS 0040-005 is intrinsically polarized\nat 0.7% with an electric vector position angle nearly parallel to that of the\nlarge-scale radio axis. This result is naturally explained in terms of an\nequatorial scattering region seen at a small inclination, building a strong\ncase that the BAL outflow is not equatorial. In conjunction with other recent\nresults concerning radio-loud BAL quasars, the era of simply characterizing\nthese sources as ``edge-on'' is over. \n\n"}
{"id": "astro-ph/0609010", "contents": "Title: The Southern Galactic Plane Survey: Polarized Radio Continuum\n  Observations and Analysis Abstract: The Southern Galactic Plane Survey (SGPS) is a radio survey in the 21 cm H I\nline and in 1.4 GHz full-polarization continuum, observed with the Australia\nTelescope Compact Array and the Parkes 64m single dish telescope. The survey\nspans a Galactic longitude of 253 deg < l < 358 deg and a latitude of |b| < 1\ndeg at a resolution of 100 arcsec and a sensitivity below 1 mJy/beam. This\npaper presents interferometer only polarized continuum survey data and\ndescribes the data taking, analysis processes and data products. The primary\ndata products are the four Stokes parameters I, Q, U, and V in 25 overlapping\nfields of 5.5 deg by 2 deg, from which polarized intensity, polarization angle\nand rotation measure are calculated. We describe the effects of missing short\nspacings, and discuss the importance of the polarized continuum data in the\nSGPS for studies of fluctuations and turbulence in the ionized interstellar\nmedium and for studying the strength and structure of the Galactic magnetic\nfield. \n\n"}
{"id": "astro-ph/0609125", "contents": "Title: On the Proof of Dark Matter, the Law of Gravity and the Mass of\n  Neutrinos Abstract: We develop a new method to predict the density associated with weak lensing\nmaps of (un)relaxed clusters in a range of theories interpolating between GR\nand MOND (General Relativity and Modified Newtonian Dynamics). We apply it to\nfit the lensing map of the bullet merging cluster 1E0657-56, in order to\nconstrain more robustly the nature and amount of collisionless matter in\nclusters {\\it beyond} the usual assumption of spherical equilibrium\n(Pointecouteau & Silk 2005) and the validity of GR on cluster scales (Clowe et\nal. 2006). Strengthening the proposal of previous authors we show that the\nbullet cluster is dominated by a collisionless -- most probably non-baryonic --\ncomponent in GR as well as in MOND, a result consistent with the dynamics of\nmany X-ray clusters. Our findings add to the number of known pathologies for a\npurely baryonic MOND, including its inability to fit the latest data from the\nWilkinson Microwave Anisotropy Probe. A plausible resolution of all these\nissues and standard issues of Cold Dark Matter with galaxy rotation curves is\nthe \"marriage\" of MOND with ordinary hot neutrinos of 2eV. This prediction is\njust within the GR-independent maximum of neutrino mass from current\n$\\beta$-decay experiments, and is falsifiable by the Karlsruhe Tritium Neutrino\n(KATRIN) experiment by 2009. Issues of consistency with strong lensing arcs and\nthe large relative velocity of the two clusters comprising the bullet cluster\nare also addressed. \n\n"}
{"id": "astro-ph/0610074", "contents": "Title: Constraining hybrid inflation models with WMAP three-year results Abstract: We reconsider the original model of quadratic hybrid inflation in light of\nthe WMAP three-year results and study the possibility of obtaining a spectral\nindex of primordial density perturbations, $n_s$, smaller than one from this\nmodel. The original hybrid inflation model naturally predicts $n_s\\geq1$ in the\nfalse vacuum dominated regime but it is also possible to have $n_s<1$ when the\nquadratic term dominates. We therefore investigate whether there is also an\nintermediate regime compatible with the latest constraints, where the scalar\nfield value during the last 50 e-folds of inflation is less than the Planck\nscale. \n\n"}
{"id": "astro-ph/0610461", "contents": "Title: Revisiting the soft X-ray excess emission in clusters of galaxies\n  observed with XMM-Newton Abstract: We analyze four XMM-Newton galaxy clusters in order to test whether their\nsoft X-ray excess emission in the 0.2-0.5 keV band as reported by Kaastra et\nal. (2003) maintains after the application of the current knowledge of the\nXMM-Newton background and calibration. We show that in the bright central 500\nkpc regions the details of the background modeling are insignificant. Thus, the\ncluster soft excess is not a background artifact, contrary to recent claims by\nBregman et al. (2006). We find evidence that the change in PN calibration\nbetween years 2002 and 2005 results in significant decrease of the soft excess\nsignal. However, the MOS instruments measure significant amounts of soft\nexcess, or sub-Galactic NH. These differences are compatible with the current\nlevel of uncertainty in the calibration of both instruments. \n\n"}
{"id": "astro-ph/0612045", "contents": "Title: Mid-IR Observations and a Revised Time Delay for the Gravitational Lens\n  System Quasar HE 1104-1805 Abstract: The mid-IR flux ratios F_A/F_B = 2.84 +/- 0.06 of the two images of the\ngravitationally lensed quasar HE 1104-1805 show no wavelength dependence to\nwithin 3% across 3.6-8.0 um, no time dependence over 6 months and agree with\nthe broad emission line flux ratios. This indicates that the mid-IR emission\nlikely comes from scales large enough to be little affected by microlensing and\nthat there is little differential extinction between the images. We measure a\nrevised time-delay between these two images of 152.2 +2.8-3.0 days from R and\nV-band data covering 1997 to 2006. This time-delay indicates that the lens has\nan approximately flat rotation curve over scales of 1-2 R_e. We also observed\nuncorrelated variations of ~0.05 mag/yr which we attribute to microlensing of\nthe optical emission from the accretion disk. The optical colors have also\nchanged significantly in the sense that image A is now redder than image B,\nrather than bluer as it was in 1993. \n\n"}
{"id": "astro-ph/9703120", "contents": "Title: Possible Evidence for Relativistic Shocks in Gamma-Ray Bursts Abstract: Relativistic shock models of gamma-ray bursts may be tested by comparison of\ntheir predicted low energy asymptotic spectral indices s to observations.\nSynchrotron radiation theory predicts that the instantaneous spectrum has s = -\n1/3 and the spectrum integrated over the radiative decay of the electrons'\nenergies has s = 1/2, with other cases lying between these limits. We examine\nthe spectra of 11 bursts obtained by the Large Area Detectors on BATSE. One\nagrees with the predicted instantaneous spectrum, as does the initial portion\nof a second, and three are close to the predicted integrated spectrum. All the\nobserved asymptotic spectral slopes lie in the predicted range. This evidence\nfor relativistic shocks is independent of detailed models of bursts and of\nassumptions about their distances. Radiation observed with the predicted\ninstantaneous spectrum has a comparatively smooth time dependence, consistent\nwith the necessarily long radiation time, while that with the predicted\nintegrated spectrum has a spiky time dependence, consistent with the\nnecessarily short radiation time. \n\n"}
{"id": "astro-ph/9711349", "contents": "Title: Structure and Dynamics of Magnetized Interstellar Clouds: Super-Alfvenic\n  Turbulence? Abstract: This review summarizes the argument for molecular clouds being dominated by\nturbulence, most likely super-Alfvenic turbulence. Five lines of observational\nevidence are given: molecular linewidths and line shapes, nonequilibrium\nchemical abundances, fractal cloud shapes, measurements of the dispersion of\ndust extinction through clouds, and Zeeman measurements of the field strength.\nRecent models by Padoan & Nordlund are summarized, that show that\nsuper-Alfvenic turbulence appears consistent with these observations. I then\npresent recent computations of my own, with numerical resolution as high as\n256^3 zones, confirming the basic picture proposed by Padoan & Nordlund, but\nshowing that the decay timescales they quote are actually too long. My\ncomputations show that decaying turbulence loses its kinetic energy with a ~1/t\ndependence on time regardless of whether the turbulence is subsonic,\nsupersonic, isothermal, adiabatic, unmagnetized or magnetized. Finally, the\nimplications for star formation and turbulence theory are discussed. \n\n"}
{"id": "astro-ph/9806196", "contents": "Title: Unambiguous quasar microlensing Abstract: Microlensing studies of quasars can reveal dark matter lumps over a broad\nmass spectrum; we highlight the importance of monitoring quasars which are seen\nthrough the halos of low-redshift galaxies. For these configurations\nmicrolensing by planetary-mass objects will manifest itself as isolated events\nwhich are only weakly chromatic. Statistical comparison of the observed optical\ndepths with their theoretical counterparts provides a strong test for a\nmicrolensing origin of such events. If microlensing is detected, the\nlight-curves can reveal not only the characteristic microlens masses, and their\ncorresponding contribution to dark halos, but also how compact the individual\nobjects are. In this way we can decisively test the possibility that the dark\nmatter associated with galaxies is composed principally of planetary-mass gas\nclouds. \n\n"}
{"id": "astro-ph/9806308", "contents": "Title: Ring diagram analysis of velocity fields within the solar convection\n  zone Abstract: Ring diagram analysis of solar oscillation power spectra obtained from MDI\ndata is performed to study the velocity fields within the solar convection\nzone. The three dimensional power spectra are fitted to a model with a\nLorentzian profile in frequency and includes the advection of the wave front by\nhorizontal flows to obtain the two horizontal components of flows as a function\nof the horizontal wave number and radial order of the oscillation modes. This\ninformation is then inverted using the OLA and RLS techniques to infer the\nvariation in flow velocity with depth. The resulting velocity fields yield the\nmean rotation velocity at different latitudes which agrees reasonably with\nhelioseismic estimates. The zonal flow inferred in the outermost layers also\nappears to be in agreement with other measurements. A meridional flow from\nequator polewards is found to have an amplitude of about 25 m/s near the\nsurface and the amplitude appears to increase with depth. \n\n"}
{"id": "astro-ph/9810395", "contents": "Title: Cloning Hubble Deep Fields I: A Model-Independent Measurement of Galaxy\n  Evolution Abstract: We present a model-independent method of quantifying galaxy evolution in\nhigh-resolution images, which we apply to the Hubble Deep Field (HDF). Our\nprocedure is to k-correct all pixels belonging to the images of a complete set\nof bright galaxies and then to replicate each galaxy image to higher redshift\nby the product of its space density, 1/V_{max}, and the cosmological volume.\nThe set of bright galaxies is itself selected from the HDF, because presently\nthe HDF provides the highest quality UV images of a redshift-complete sample of\ngalaxies (31 galaxies with I<21.9, \\bar{z}=0.5, and for which V/V_{max} is\nspread fairly). These galaxies are bright enough to permit accurate\npixel-by-pixel k-corrections into the restframe UV (\\sim 2000 A). We match the\nshot noise, spatial sampling and PSF smoothing of the HDF data, resulting in\nentirely empirical and parameter-free ``no-evolution'' deep fields of galaxies\nfor direct comparison with the HDF. In addition, the overcounting rate and the\nlevel of incompleteness can be accurately quantified by this procedure. We\nobtain the following results. Faint HDF galaxies (I>24) are much smaller, more\nnumerous, and less regular than our ``no-evolution'' extrapolation, for any\ninteresting geometry. A higher proportion of HDF galaxies ``dropout'' in both U\nand B, indicating that some galaxies were brighter at higher redshifts than our\n``cloned'' z\\sim0.5 population. \n\n"}
{"id": "astro-ph/9902347", "contents": "Title: Emission-Line Galaxies from the NICMOS/HST GRISM Parallel Survey Abstract: We present the first results of a survey of random fields with the slitless\nG141 ($\\lambda_c = 1.5\\mu, \\Delta\\lambda=0.8\\mu$) grism on NICMOS.\nApproximately 64 square arcminutes have been observed at intermediate and high\ngalactic latitudes. The 3$\\sigma$ limiting line and continuum fluxes in each\nfield vary from $7.5 \\times 10^{-17}$ to $1 \\times 10^{-17} erg/cm^2/sec$ and\nfrom H = 20 to 22, respectively. Our median and area weighted $3\\sigma $\nlimiting line fluxes within a 4 pixel aperture are nearly identical at $4.1\n\\times 10^{-17} erg/cm^2/sec$ and are 60% deeper than the deepest narrow-band\nimaging surveys from the ground. We have identified 33 emission-line objects\nand derive their observed wavelengths, fluxes and equivalent widths. We argue\nthat the most likely line identification is H$\\alpha$ and that the redshift\nrange probed is from 0.75 to 1.9. The 2$\\sigma$ rest-frame equivalent width\nlimits range from 9\\AA to 130\\AA with an average of 40\\AA. The survey probes an\neffective co-moving volume of $10^5 h_{50}^{-3} Mpc^3$ for $q_0=0.5$. Our\nderived co-moving number density of emission line galaxies in the range $0.7 <\nz < 1.9$ is $3.3\\times10^{-4} h_{50}^{3} Mpc^{-3}$, very similar to that of the\nbright Lyman break objects at $z \\sim 3$. The objects with detected\nemission-lines have a median F160W magnitude of 20.4 (Vega scale) and a median\nH$\\alpha$ luminosity of $2.7 \\times 10^{42} erg/sec$. The implied star\nformation rates range from 1 to 324 M_{\\odot}/yr, with an average\n[NII]6583,6548 corrected rate of 21 M_{\\odot}/yr for H_0=50 km/s/Mpc and\n$q_0=0.5$ (34 M_{\\odot}/yr for $q_0=0.1$). \n\n"}
{"id": "astro-ph/9903082", "contents": "Title: Wormhole Dominance Proposal and Wave Function Discord Abstract: Using the wormhole dominance proposal, it is shown that quantum corrections\nto the usual WKB ansatz for the wave function of the universe ably circumvent\nmany of the drawbacks present in the current proposals. We also find that the\nrecent criticism by Hawking and Turok does not apply to the tunneling proposal. \n\n"}
{"id": "astro-ph/9903440", "contents": "Title: Determination of Galaxy Spin Vectors in the Pisces-Perseus Supercluster\n  with the Arecibo Telescope Abstract: We use HI observations made with the upgraded Arecibo 305M Telescope in\nAugust 1998 to obtain accurate spin vector determinations for 54 nearly edge-on\ngalaxies in the Minnesota Automated Plate Scanner Pisces-Perseus Survey\n(MAPS-PP). We introduce a simple observational technique of determining the\nsense of rotation for galaxies, even when their HI disks are not fully\nresolved. We examined the spin vector distribution of these 54 galaxies for\nevidence of preferential galaxy alignments. We use the Kuiper statistic, a\nvariant of the Kolmogorov--Smirnov statistic, to determine the significance of\nany anisotropies in the distribution of galaxy spin vectors. The possibility of\n``spin vector domains'' is also investigated. We find no significant evidence\nof preferential galaxy alignments in this sample. However, we show tha t the\nsmall sample size places weak limits on the level of galaxy alignments. \n\n"}
{"id": "astro-ph/9904315", "contents": "Title: Monopole-antimonopole bound states as a source of ultra-high-energy\n  cosmic rays Abstract: The electromagnetic decay and final annihilation of magnetic\nmonopole-antimonopole pairs formed in the early universe has been proposed as a\npossible mechanism to produce the highest energy cosmic rays. We show that for\na monopole abundance saturating the Parker limit, the density of magnetic\nmonopolonium formed is many orders of magnitude less than that required to\nexplain the observed cosmic ray flux. We then propose a different scenario in\nwhich the monopoles and antimonopoles are connected by strings formed at a low\nenergy phase transition (~ 100 GeV). The bound states decay by gravitational\nradiation, with lifetimes comparable with the age of the universe. This\nmechanism avoids the problems of the standard monopolonium scenario, since the\nbinding of monopoles and antimonopoles is perfectly efficient. \n\n"}
{"id": "astro-ph/9905283", "contents": "Title: Positrons from particle dark-matter annihilation in the Galactic halo:\n  propagation Green's functions Abstract: We have made a calculation of the propagation of positrons from dark-matter\nparticle annihilation in the Galactic halo in different models of the dark\nmatter halo distribution using our 3D code, and present fits to our numerical\npropagation Green's functions. We show that the Green's functions are not very\nsensitive to the dark matter distribution for the same local dark matter energy\ndensity. We compare our predictions with computed cosmic ray positron spectra\n(``background'') for the ``conventional'' CR nucleon spectrum which matches the\nlocal measurements, and a modified spectrum which respects the limits imposed\nby measurements of diffuse Galactic gamma-rays, antiprotons, and positrons. We\nconclude that significant detection of a dark matter signal requires favourable\nconditions and precise measurements unless the dark matter is clumpy which\nwould produce a stronger signal. Although our conclusion qualitatively agrees\nwith that of previous authors, it is based on a more realistic model of\nparticle propagation and thus reduces the scope for future speculations.\nReliable background evaluation requires new accurate positron measurements and\nfurther developments in modelling production and propagation of cosmic ray\nspecies in the Galaxy. \n\n"}
{"id": "astro-ph/9909216", "contents": "Title: A Near-Infrared Stellar Census of the Blue Compact Dwarf Galaxy\n  VII~Zw~403 Abstract: We present near-infrared single-star photometry for the low-metallicity Blue\nCompact Dwarf galaxy VII~Zw~403. We achieve limiting magnitudes of\nF110W~$\\approx$~25.5 and F160W~$\\approx$~24.5 using one of the NICMOS cameras\nwith the HST equivalents of the ground-based J and H filters. The data have a\nhigh photometric precision (0.1 mag) and are $>95$% complete down to magnitudes\nof about 23, far deeper than previous ground-based studies in the near-IR. The\ncolor-magnitude diagram contains about 1000 point sources. We provide a\npreliminary transformation of the near-IR photometry into the ground system... \n\n"}
{"id": "astro-ph/9912406", "contents": "Title: Galaxy and Cluster Biasing from Local Group Dynamics Abstract: Comparing the gravitational acceleration induced on the Local Group of\ngalaxies by different tracers of the underline density field we estimate,\nwithin the linear gravitational instability theory and the linear biasing\nansatz, their relative bias factors. Using optical SSRS2 galaxies, IRAS (PSCz)\ngalaxies and Abell/ACO clusters, we find b_{O,I} ~ 1.21 +- 0.06 and b_{C,I} ~\n4.3 +- 0.8, in agreement with other recent studies. Finally, there is an\nexcellent one-to-one correspondence of the PSCz and Abell/ACO cluster dipole\nprofiles, once the latter is rescaled by b_{C,I}, out to at least ~150 h^{-1}\nMpc. \n\n"}
{"id": "gr-qc/0006080", "contents": "Title: On the influence of gravitational radiation on a gyroscope Abstract: We calculate the precession of a gyroscope at rest in a Bondi spacetime. It\nis shown that, far from the source, the leading term in the rate of precession\nof the gyroscope is simply expressed through the news function of the system,\nand vanishes if and only if there is no news. Rough estimates are presented,\nillustrating the order of magnitude of the expected effect for different\nscenarios. It is also shown from the next order term that non-radiative (but\ntime dependent) spacetimes will produce a gyroscope precession of that order,\nproviding thereby ``observational'' evidence for the violation of the Huygens's\nprinciple. \n\n"}
{"id": "gr-qc/0207062", "contents": "Title: Searching for Gravitational Waves from the Inspiral of Precessing Binary\n  Systems: Problems with Current Waveforms Abstract: We consider the problem of searching for gravitational waves emitted during\nthe inspiral phase of binary systems when the orbital plane precesses due to\nrelativistic spin-orbit coupling. Such effect takes place when the spins of the\nbinary members are misaligned with respect to the orbital angular momentum. As\na first step we assess the importance of precession specifically for the\nfirst-generation of LIGO detectors. We investigate the extent of the\nsignal-to-noise ratio reduction and, hence, detection rate that occurs when\nprecession effects are not accounted for in the template waveforms. We restrict\nour analysis to binary systems that undergo the so-called simple precession and\nhave a total mass close to 10 solar mass. We find that for binary systems with\nrather high mass ratios (e.g., a 1.4 solar mass neutron star and a 10 solar\nmass black hole) the detection rate can decrease by almost an order of\nmagnitude. Current astrophysical estimates of the rate of binary inspiral\nevents suggest that LIGO could detect at most a few events per year, and\ntherefore the reduction of the detection rate even by a factor of a few is\ncritical. In the second part of our analysis, we examine whether the effect of\nprecession could be included in the templates by capturing the main features of\nthe phase modulation through a small number of extra parameters. Specifically\nwe examine and tested for the first time the 3-parameter family suggested by\nApostolatos. We find that, even though these ``mimic'' templates improve the\ndetection rate, they are still inadequate in recovering the signal-to-noise\nratio at the desired level. We conclude that a more complex template family is\nneeded in the near future, still maintaining the number of additional\nparameters as small as possible in order to reduce the computational costs. \n\n"}
{"id": "gr-qc/0511038", "contents": "Title: Mach's Principle and a Variable Speed of Light Abstract: Ernst Mach (1838-1916) suggested that the origin of gravitational interaction\ncould depend on the presence of all masses in the universe. A corresponding\nhypothesis of Sciama (1953) on the gravitational constant, c^2/G = \\sum\nm_i/r_i, is linked to Dicke's (1957) proposal of an electromagnetic origin of\ngravitation, a precursor of scalar-tensor-theories. In this an equivalent\ndescription in terms of a variable speed of light (VSL) is given, and the\nagreement with the four classical tests of general relativity is shown.\nMoreover, VSL opens the possibility to write the total energy of a particle as\nE=mc^2; this necessarily leads to the proportionality of inertial and\ngravitating mass, the equivalence principle. Furthermore, a formula for c\ndepending on the mass distribution is given that reproduces Newton's law of\ngravitation. This mass distribution allows to calculate a slightly variable\nterm that corresponds to the `constant' G. The present proposal may also supply\nan alternative explanation to the flatness problem and the horizon problem in\ncosmology. \n\n"}
{"id": "hep-ph/0405215", "contents": "Title: Supersymmetry and Cosmology Abstract: Cosmology now provides unambiguous, quantitative evidence for new particle\nphysics. I discuss the implications of cosmology for supersymmetry and vice\nversa. Topics include: motivations for supersymmetry; supersymmetry breaking;\ndark energy; freeze out and WIMPs; neutralino dark matter; cosmologically\npreferred regions of minimal supergravity; direct and indirect detection of\nneutralinos; the DAMA and HEAT signals; inflation and reheating; gravitino dark\nmatter; Big Bang nucleosynthesis; and the cosmic microwave background. I\nconclude with speculations about the prospects for a microscopic description of\nthe dark universe, stressing the necessity of diverse experiments on both sides\nof the particle physics/cosmology interface. \n\n"}
{"id": "hep-ph/0406120", "contents": "Title: Constraints on Supersymmetric Grand Unified Theories from Cosmology Abstract: Within the context of SUSY GUTs, cosmic strings are generically formed at the\nend of hybrid inflation. However, the WMAP CMB measurements strongly constrain\nthe possible cosmic strings contribution to the angular power spectrum of\nanisotropies. We investigate the parameter space of SUSY hybrid (F- and D-\nterm) inflation, to get the conditions under which theoretical predictions are\nin agreement with data. The predictions of F-term inflation are in agreement\nwith data, only if the superpotential coupling $\\kappa$ is small. In\nparticular, for SUSY SO(10), the upper bound is $\\kappa\\lsim 7\\times 10^{-7}$.\nThis fine tuning problem can be lifted if we employ the curvaton mechanism, in\nwhich case $\\kappa\\lsim 8\\times 10^{-3}$; higher values are not allowed by the\ngravitino constraint. The constraint on $\\kappa$ is equivalent to a constraint\non the SSB mass scale $M$, namely $M \\lsim 2\\times 10^{15}$ GeV. The study of\nD-term inflation shows that the inflaton field is of the order of the Planck\nscale; one should therefore consider SUGRA. We find that the cosmic strings\ncontribution to the CMB anisotropies is not constant, but it is strongly\ndependent on the gauge coupling $g$ and on the superpotential coupling\n$\\lambda$. We obtain $g\\lsim 2\\times 10^{-2}$ and $\\lambda \\lsim 3\\times\n10^{-5}$. SUGRA corrections induce also a lower limit for $\\lambda$.\nEquivalently, the Fayet-Iliopoulos term $\\xi$ must satisfy $\\sqrt\\xi \\lsim\n2\\times 10^{15}$ GeV. This constraint holds for all allowed values of $g$. \n\n"}
{"id": "hep-ph/0603244", "contents": "Title: Reheating in supersymmetric high scale inflation Abstract: Motivated by Refs \\cite{am1,am2}, we analyze how the inflaton decay reheats\nthe Universe within supersymmetry. In a non-supersymmetric case the inflaton\nusually decays via preheating unless its couplings to other fields are very\nsmall. Naively one would expect that supersymmetry enhances bosonic preheating\nas it introduces new scalars such as squarks and sleptons. On the contrary, we\npoint out that preheating is unlikely within supersymmetry. The reason is that\nflat directions in the scalar potential, classified by gauge invariant\ncombinations of slepton and squark fields, are generically displaced towards a\nlarge vacuum expectation value (VEV) in the early Universe. They induce\nsupersymmetry preserving masses to the inflaton decay products through the\nStandard Model Yukawa couplings, which kinematically blocks preheating for VEVs\n$> 10^{13}$ GeV. The decay will become allowed only after the flat directions\nstart oscillating, and once the flat direction VEV is sufficiently redshifted.\nFor models with weak scale supersymmetry, this generically happens at a Hubble\nexpansion rate: $H \\simeq (10^{-3}-10^{-1}) {\\rm TeV}$, at which time the\ninflaton decays in the perturbative regime. This is to our knowledge first\nanalysis where the inflaton decay to the Standard Model particles is treated\nproperly within supersymmetry. There are number of important consequences: no\noverproduction of dangerous supersymmetric relics (particularly gravitinos), no\nresonant excitation of superheavy dark matter, and no non-thermal leptogenesis\nthrough non-perturbative creation of the right-handed (s)neutrinos. Finally\nsupersymmetric flat directions can even spoil hybrid inflation all together by\nnot allowing the auxiliary field become tachyonic. \n\n"}
{"id": "hep-ph/0605033", "contents": "Title: Topical Review on \"Beta-beams\" Abstract: Neutrino physics is traversing an exciting period, after the important\ndiscovery that neutrinos are massive particles, that has implications from\nhigh-energy physics to cosmology. A new method for the production of intense\nand pure neutrino beams has been proposed recently: the ``beta-beam''. It\nexploits boosted radioactive ions decaying through beta-decay. This novel\nconcept has been the starting point for a new possible future facility. Its\nmain goal is to address the crucial issue of the existence of CP violation in\nthe lepton sector. Here we review the status and the recent developments with\nbeta-beams. We discuss the original, the medium and high-energy scenarios as\nwell as mono-chromatic neutrino beams produced through ion electron-capture.\nThe issue of the degeneracies is mentioned. An overview of low energy\nbeta-beams is also presented. These beams can be used to perform experiments of\ninterest for nuclear structure, for the study of fundamental interactions and\nfor nuclear astrophysics. \n\n"}
{"id": "hep-ph/0611027", "contents": "Title: Constraints on Gravitino Dark Matter Scenarios with Long-Lived Charged\n  Sleptons Abstract: Considering scenarios in which the gravitino is the lightest supersymmetric\nparticle and a charged slepton the next-to-lightest supersymmetric particle\n(NLSP), we discuss cosmological constraints on the masses of the gravitino and\nthe NLSP slepton. The presented mass bounds are crucial for gravitino dark\nmatter studies and potential gravitino signatures at future colliders. \n\n"}
{"id": "hep-ph/9709399", "contents": "Title: The Highest Energy Cosmic Rays and Particle Physics Abstract: It has been argued that the observations of cosmic particles with energies in\nexcess of $10^8$ TeV represent a puzzle. Its solution requires new astrophysics\nor new particle physics. We show that the latter is unlikely given that the\nscale associated with a new particle physics threshold must be of order 1 GeV,\nnot TeV and above, in order to resolve the problem. In most cases such new\nphysics should have been revealed by accelerator experiments. We examine the\npossibility that the highest energy cosmic rays are initiated by non-standard\ninteractions of neutrinos in the atmosphere. We show that proposals in this\ndirection either violate s-wave unitarity or fall short of producing a sizeable\neffect by several orders of magnitude. \n\n"}
{"id": "hep-th/0204017", "contents": "Title: String Cosmology and Chaos Abstract: We briefly review three aspects of string cosmology: (1) the ``stochastic''\napproach to the pre-big bang scenario, (2) the presence of chaos in the generic\ncosmological solutions of the tree-level low-energy effective actions coming\nout of string theory, and (3) the remarkable link between the latter chaos and\nthe Weyl groups of some hyperbolic Kac-Moody algebras. Talk given at the\nFrancqui Colloquium ``Strings and Gravity: Tying the Forces Together''\n(Brussels, October 2001). \n\n"}
{"id": "hep-th/9907081", "contents": "Title: Towards a unified description of the four interactions in terms of\n  Dirac-Bergmann observables Abstract: A review is given of the status and developments of the research program\naiming to reformulate the physics of the four interactions at the classical\nlevel in a unified way in terms of Dirac-Bergmann observables with special\nemphasis on the open mathematical, physical and interpretational problems. \n\n"}
