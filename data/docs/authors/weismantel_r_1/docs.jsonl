{"id": "0704.2824", "contents": "Title: Sums of squares over totally real fields are rational sums of squares Abstract: Let $K$ be a totally real number field with Galois closure $L$. We prove that\nif $f \\in \\mathbb Q[x_1,...,x_n]$ is a sum of $m$ squares in $K[x_1,...,x_n]$,\nthen $f$ is a sum of \\[4m \\cdot 2^{[L: \\mathbb Q]+1} {[L: \\mathbb Q] +1 \\choose\n2}\\] squares in $\\mathbb Q[x_1,...,x_n]$. Moreover, our argument is\nconstructive and generalizes to the case of commutative $K$-algebras. This\nresult gives a partial resolution to a question of Sturmfels on the algebraic\ndegree of certain semidefinite programing problems. \n\n"}
{"id": "0704.3875", "contents": "Title: Controlled Lagrangians and Stabilization of Discrete Mechanical Systems\n  I Abstract: Controlled Lagrangian and matching techniques are developed for the\nstabilization of relative equilibria and equilibria of discrete mechanical\nsystems with symmetry as well as broken symmetry. Interesting new phenomena\narise in the controlled Lagrangian approach in the discrete context that are\nnot present in the continuous theory. In particular, to make the discrete\ntheory effective, one can make an appropriate selection of momentum levels or,\nalternatively, introduce a new parameter into the controlled Lagrangian to\ncomplete the kinetic matching procedure. Specifically, new terms in the\ncontrolled shape equation that are necessary for potential matching in the\ndiscrete setting are introduced. The theory is illustrated with the problem of\nstabilization of the cart-pendulum system on an incline. The paper also\ndiscusses digital and model predictive controllers. \n\n"}
{"id": "0705.2302", "contents": "Title: On randomized stopping Abstract: A general result on the method of randomized stopping is proved. It is\napplied to optimal stopping of controlled diffusion processes with unbounded\ncoefficients to reduce it to an optimal control problem without stopping. This\nis motivated by recent results of Krylov on numerical solutions to the Bellman\nequation. \n\n"}
{"id": "0705.3370", "contents": "Title: Adaptive classification of temporal signals in fixed-weights recurrent\n  neural networks: an existence proof Abstract: We address the important theoretical question why a recurrent neural network\nwith fixed weights can adaptively classify time-varied signals in the presence\nof additive noise and parametric perturbations. We provide a mathematical proof\nassuming that unknown parameters are allowed to enter the signal nonlinearly\nand the noise amplitude is sufficiently small. \n\n"}
{"id": "0710.3003", "contents": "Title: A polynomial oracle-time algorithm for convex integer minimization Abstract: In this paper we consider the solution of certain convex integer minimization\nproblems via greedy augmentation procedures. We show that a greedy augmentation\nprocedure that employs only directions from certain Graver bases needs only\npolynomially many augmentation steps to solve the given problem. We extend\nthese results to convex $N$-fold integer minimization problems and to convex\n2-stage stochastic integer minimization problems. Finally, we present some\napplications of convex $N$-fold integer minimization problems for which our\napproach provides polynomial time solution algorithms. \n\n"}
{"id": "0801.0090", "contents": "Title: Necessary conditions for linear noncooperative N-player delta\n  differential games on time scales Abstract: We present necessary conditions for linear noncooperative N-player delta\ndynamic games on a generic time scale. Necessary conditions for an open-loop\nNash-equilibrium and for a memoryless perfect state Nash-equilibrium are\nproved. \n\n"}
{"id": "0801.3348", "contents": "Title: Statistical Arbitrage and Optimal Trading with Transaction Costs in\n  Futures Markets Abstract: We consider the Brownian market model and the problem of expected utility\nmaximization of terminal wealth. We, specifically, examine the problem of\nmaximizing the utility of terminal wealth under the presence of transaction\ncosts of a fund/agent investing in futures markets. We offer some preliminary\nremarks about statistical arbitrage strategies and we set the framework for\nfutures markets, and introduce concepts such as margin, gearing and slippage.\nThe setting is of discrete time, and the price evolution of the futures prices\nis modelled as discrete random sequence involving Ito's sums. We assume the\ndrift and the Brownian motion driving the return process are non-observable and\nthe transaction costs are represented by the bid-ask spread. We provide\nexplicit solution to the optimal portfolio process, and we offer an example\nusing logarithmic utility. \n\n"}
{"id": "0802.3613", "contents": "Title: Modeling and Optimal Control of Networks of Pipes and Canals Abstract: This paper deals with the optimal control of systems governed by nonlinear\nsystems of conservation laws at junctions. The applications considered range\nfrom gas compressors in pipelines to open channels management. The existence of\nan optimal control is proved. From the analytical point of view, these results\nare based on the well posedness of a suitable initial boundary value problem\nand on techniques for quasidifferential equations in a metric space. \n\n"}
{"id": "0803.0925", "contents": "Title: Robust Smoothed Analysis of a Condition Number for Linear Programming Abstract: We perform a smoothed analysis of the GCC-condition number C(A) of the linear\nprogramming feasibility problem \\exists x\\in\\R^{m+1} Ax < 0. Suppose that\n\\bar{A} is any matrix with rows \\bar{a_i} of euclidean norm 1 and,\nindependently for all i, let a_i be a random perturbation of \\bar{a_i}\nfollowing the uniform distribution in the spherical disk in S^m of angular\nradius \\arcsin\\sigma and centered at \\bar{a_i}. We prove that E(\\ln C(A)) =\nO(mn / \\sigma). A similar result was shown for Renegar's condition number and\nGaussian perturbations by Dunagan, Spielman, and Teng [arXiv:cs.DS/0302011].\nOur result is robust in the sense that it easily extends to radially symmetric\nprobability distributions supported on a spherical disk of radius\n\\arcsin\\sigma, whose density may even have a singularity at the center of the\nperturbation. Our proofs combine ideas from a recent paper of B\\\"urgisser,\nCucker, and Lotz (Math. Comp. 77, No. 263, 2008) with techniques of Dunagan et\nal. \n\n"}
{"id": "0803.2065", "contents": "Title: Alternatives for Testing Total Dual Integrality Abstract: In this paper we provide characterizing properties of TDI systems, among\nothers the following: a system of linear inequalities is TDI if and only if its\ncoefficient vectors form a Hilbert basis, and there exists a test-set for the\nsystem's dual integer programs where all test vectors have positive entries\nequal to 1. Reformulations of this provide relations between computational\nalgebra and integer programming and they contain Applegate, Cook and\nMcCormick's sufficient condition for the TDI property and Sturmfels' theorem\nrelating toric initial ideals generated by square-free monomials to unimodular\ntriangulations. We also study the theoretical and practical efficiency and\nlimits of the characterizations of the TDI property presented here.\n  In the particular case of set packing polyhedra our results correspond to\nendowing the weak perfect graph theorem with an additional, computationally\ninteresting, geometric feature: the normal fan of the stable set polytope of a\nperfect graph can be refined into a regular triangulation consisting only of\nunimodular cones. \n\n"}
{"id": "0805.0828", "contents": "Title: Gradient-like observers for invariant dynamics on a Lie group Abstract: This paper proposes a design methodology for non-linear state observers for\ninvariant kinematic systems posed on finite dimensional connected Lie groups,\nand studies the associated fundamental system structure. The concept of\nsynchrony of two dynamical systems is specialised to systems on Lie groups. For\ninvariant systems this leads to a general factorisation theorem of a nonlinear\nobserver into a synchronous (internal model) term and an innovation term. The\nsynchronous term is fully specified by the system model. We propose a design\nmethodology for the innovation term based on gradient-like terms derived from\ninvariant or non-invariant cost functions. The resulting nonlinear observers\nhave strong (almost) global convergence properties and examples are used to\ndemonstrate the relevance of the proposed approach. \n\n"}
{"id": "0805.1563", "contents": "Title: A Linear Programming Relaxation and a Heuristic for the Restless Bandit\n  Problem with General Switching Costs Abstract: We extend a relaxation technique due to Bertsimas and Nino-Mora for the\nrestless bandit problem to the case where arbitrary costs penalize switching\nbetween the bandits. We also construct a one-step lookahead policy using the\nsolution of the relaxation. Computational experiments and a bound for\napproximate dynamic programming provide some empirical support for the\nheuristic. \n\n"}
{"id": "0805.4609", "contents": "Title: On the surjectivity properties of perturbations of maximal monotone\n  operators in non-reflexive Banach spaces Abstract: We are concerned with surjectivity of perturbations of maximal monotone\noperators in non-reflexive Banach spaces. While in a reflexive setting, a\nclassical surjectivity result due to Rockafellar gives a necessary and\nsufficient condition to maximal monotonicity, in a non-reflexive space we\ncharacterize maximality using a ``enlarged'' version of the duality mapping,\nintroduced previously by Gossez. \n\n"}
{"id": "0807.3096", "contents": "Title: Stochastic Maximum Principle for a PDEs with noise and control on the\n  boundary Abstract: In this paper we prove necessary conditions for optimality of a stochastic\ncontrol problem for a class of stochastic partial differential equations that\nis controlled through the boundary. This kind of problems can be interpreted as\na stochastic control problem for an evolution system in an Hilbert space. The\nregularity of the solution of the adjoint equation, that is a backward\nstochastic equation in infinite dimension, plays a crucial role in the\nformulation of the maximum principle. \n\n"}
{"id": "0807.3355", "contents": "Title: Parallel Approximation and Integer Programming Reformulation Abstract: We show that in a knapsack feasibility problem an integral vector $p$, which\nis short, and near parallel to the constraint vector gives a branching\ndirection with small integer width.\n  We use this result to analyze two computationally efficient reformulation\ntechniques on low density knapsack problems. Both reformulations have a\nconstraint matrix with columns reduced in the sense of Lenstra, Lenstra, and\nLov\\'asz. We prove an upper bound on the integer width along the last variable,\nwhich becomes 1, when the density is sufficiently small.\n  In the proof we extract from the transformation matrices a vector which is\nnear parallel to the constraint vector $a.$ The near parallel vector is a good\nbranching direction in the original knapsack problem, and this transfers to the\nlast variable in the reformulations. \n\n"}
{"id": "0809.3480", "contents": "Title: Theta Bodies for Polynomial Ideals Abstract: Inspired by a question of Lov\\'asz, we introduce a hierarchy of nested\nsemidefinite relaxations of the convex hull of real solutions to an arbitrary\npolynomial ideal, called theta bodies of the ideal. For the stable set problem\nin a graph, the first theta body in this hierarchy is exactly Lov\\'asz's theta\nbody of the graph. We prove that theta bodies are, up to closure, a version of\nLasserre's relaxations for real solutions to ideals, and that they can be\ncomputed explicitly using combinatorial moment matrices. Theta bodies provide a\nnew canonical set of semidefinite relaxations for the max cut problem. For\nvanishing ideals of finite point sets, we give several equivalent\ncharacterizations of when the first theta body equals the convex hull of the\npoints. We also determine the structure of the first theta body for all ideals. \n\n"}
{"id": "0812.1817", "contents": "Title: Least-Squares Approximation by Elements from Matrix Orbits Achieved by\n  Gradient Flows on Compact Lie Groups Abstract: Let $S(A)$ denote the orbit of a complex or real matrix $A$ under a certain\nequivalence relation such as unitary similarity, unitary equivalence, unitary\ncongruences etc. Efficient gradient-flow algorithms are constructed to\ndetermine the best approximation of a given matrix $A_0$ by the sum of matrices\nin $S(A_1), ..., S(A_N)$ in the sense of finding the Euclidean least-squares\ndistance $$\\min \\{\\|X_1+ ... + X_N - A_0\\|: X_j \\in S(A_j), j = 1, >..., N\\}.$$\nConnections of the results to different pure and applied areas are discussed. \n\n"}
{"id": "0812.3687", "contents": "Title: On multivariate Newton-like inequalities Abstract: We study multivariate entire functions and polynomials with non-negative\ncoefficients. A class of {\\bf Strongly Log-Concave} entire functions,\ngeneralizing {\\it Minkowski} volume polynomials, is introduced: an entire\nfunction $f$ in $m$ variables is called {\\bf Strongly Log-Concave} if the\nfunction $(\\partial x_1)^{c_1}...(\\partial x_m)^{c_m} f$ is either zero or\n$\\log((\\partial x_1)^{c_1}...(\\partial x_m)^{c_m} f)$ is concave on\n$R_{+}^{m}$. We start with yet another point of view (via {\\it propagation}) on\nthe standard univarite (or homogeneous bivariate) {\\bf Newton Inequlities}. We\nprove analogues of (univariate) {\\bf Newton Inequlities} in the (multivariate)\n{\\bf Strongly Log-Concave} case. One of the corollaries of our new Newton(like)\ninequalities is the fact that the support $supp(f)$ of a {\\bf Strongly\nLog-Concave} entire function $f$ is discretely convex ($D$-convex in our\nnotation). The proofs are based on a natural convex relaxation of the\nderivatives $Der_{f}(r_1,...,r_m)$ of $f$ at zero and on the lower bounds on\n$Der_{f}(r_1,...,r_m)$, which generalize the {\\bf Van Der\nWaerden-Falikman-Egorychev} inequality for the permanent of doubly-stochastic\nmatrices. A few open questions are posed in the final section. \n\n"}
{"id": "0901.2269", "contents": "Title: An Excursion-Theoretic Approach to Stability of Discrete-Time Stochastic\n  Hybrid Systems Abstract: We address stability of a class of Markovian discrete-time stochastic hybrid\nsystems. This class of systems is characterized by the state-space of the\nsystem being partitioned into a safe or target set and its exterior, and the\ndynamics of the system being different in each domain. We give conditions for\n$L_1$-boundedness of Lyapunov functions based on certain negative drift\nconditions outside the target set, together with some more minor assumptions.\nWe then apply our results to a wide class of randomly switched systems (or\niterated function systems), for which we give conditions for global asymptotic\nstability almost surely and in $L_1$. The systems need not be time-homogeneous,\nand our results apply to certain systems for which functional-analytic or\nmartingale-based estimates are difficult or impossible to get. \n\n"}
{"id": "0901.2408", "contents": "Title: Synchronization on the circle Abstract: The goal of the present paper is to highlight the fundamental differences of\nso-called synchronization or consensus algorithms when the agents to\nsynchronize evolve on a compact homogeneous manifold (like the circle, sphere\nor the group of rotation matrices), instead of a vector space. For the benefit\nof understanding, the discussion is restricted to the circle. First, a\nfundamental consensus algorithm on R^n is reviewed, from which continuous- and\ndiscrete-time synchronization algorithms on the circle are deduced by analogy.\nIt is shown how they are connected to Kuramoto and Vicsek models from the\nliterature. Their convergence properties are similar to vector spaces only for\nspecific graphs or if the agents are all located within a semicircle. Examples\nare proposed to illustrate several other possible behaviors. Finally, new\nalgorithms are proposed to recover (almost-)global synchronization properties. \n\n"}
{"id": "0901.4400", "contents": "Title: Faster Real Feasibility via Circuit Discriminants Abstract: We show that detecting real roots for honestly n-variate (n+2)-nomials (with\ninteger exponents and coefficients) can be done in time polynomial in the\nsparse encoding for any fixed n. The best previous complexity bounds were\nexponential in the sparse encoding, even for n fixed. We then give a\ncharacterization of those functions k(n) such that the complexity of detecting\nreal roots for n-variate (n+k(n))-nomials transitions from P to NP-hardness as\nn tends to infinity. Our proofs follow in large part from a new complexity\nthreshold for deciding the vanishing of A-discriminants of n-variate\n(n+k(n))-nomials. Diophantine approximation, through linear forms in\nlogarithms, also arises as a key tool. \n\n"}
{"id": "0902.2367", "contents": "Title: Dequantizing Compressed Sensing: When Oversampling and Non-Gaussian\n  Constraints Combine Abstract: In this paper we study the problem of recovering sparse or compressible\nsignals from uniformly quantized measurements. We present a new class of convex\noptimization programs, or decoders, coined Basis Pursuit DeQuantizer of moment\n$p$ (BPDQ$_p$), that model the quantization distortion more faithfully than the\ncommonly used Basis Pursuit DeNoise (BPDN) program. Our decoders proceed by\nminimizing the sparsity of the signal to be reconstructed subject to a\ndata-fidelity constraint expressed in the $\\ell_p$-norm of the residual error\nfor $2\\leq p\\leq \\infty$.\n  We show theoretically that, (i) the reconstruction error of these new\ndecoders is bounded if the sensing matrix satisfies an extended Restricted\nIsometry Property involving the $\\ell_p$ norm, and (ii), for Gaussian random\nmatrices and uniformly quantized measurements, BPDQ$_p$ performance exceeds\nthat of BPDN by dividing the reconstruction error due to quantization by\n$\\sqrt{p+1}$. This last effect happens with high probability when the number of\nmeasurements exceeds a value growing with $p$, i.e. in an oversampled situation\ncompared to what is commonly required by BPDN = BPDQ$_2$. To demonstrate the\ntheoretical power of BPDQ$_p$, we report numerical simulations on signal and\nimage reconstruction problems. \n\n"}
{"id": "0904.0068", "contents": "Title: Verifiable conditions of $\\ell_1$-recovery of sparse signals with sign\n  restrictions Abstract: We propose necessary and sufficient conditions for a sensing matrix to be\n\"s-semigood\" -- to allow for exact $\\ell_1$-recovery of sparse signals with at\nmost $s$ nonzero entries under sign restrictions on part of the entries. We\nexpress the error bounds for imperfect $\\ell_1$-recovery in terms of the\ncharacteristics underlying these conditions. Furthermore, we demonstrate that\nthese characteristics, although difficult to evaluate, lead to verifiable\nsufficient conditions for exact sparse $\\ell_1$-recovery and to efficiently\ncomputable upper bounds on those $s$ for which a given sensing matrix is\n$s$-semigood. We concentrate on the properties of proposed verifiable\nsufficient conditions of $s$-semigoodness and describe their limits of\nperformance. \n\n"}
{"id": "0904.2193", "contents": "Title: Minimization of $\\lambda_2(\\Omega)$ with a perimeter constraint Abstract: We study the problem of minimizing the second Dirichlet eigenvalue for the\nLaplacian operator among sets of given perimeter. In two dimensions, we prove\nthat the optimum exists, is convex, regular, and its boundary contains exactly\ntwo points where the curvature vanishes. In $N$ dimensions, we prove a more\ngeneral existence theorem for a class of functionals which is decreasing with\nrespect to set inclusion and $\\gamma$ lower semicontinuous. \n\n"}
{"id": "0904.2427", "contents": "Title: Remarks on the Controllability of Some Quasilinear Equations Abstract: In this Note, we review the main existing results, methods, and some key open\nproblems on the controllability of nonlinear hyperbolic and parabolic\nequations. Especially, we describe our recent universal approach to solve the\nlocal controllability problem of quasilinear time-reversible evolution\nequations, which is based on a new unbounded perturbation technique. It is also\nworthy to mention that the technique we develop can also be applied to other\nproblems for quasilinear equations, say local existence, stabilization, etc. \n\n"}
{"id": "0905.1888", "contents": "Title: A Short Proof of the Pontryagin Maximum Principle on Manifolds Abstract: Applying the Tubular Neighborhood Theorem, we give a short and new proof of\nthe Pontryagin Maximum Principle on a smooth manifold. The idea is as follows.\nGiven a control system on a manifold $M$, we embed it into an open subset of\nsome $\\mathbb R^n$, and extend the control system to the open set. Then, we\napply the Pontryagin Maximum Principle on $\\mathbb R^n$ to the extended system\nand project the consequence to $M$. \n\n"}
{"id": "0905.3601", "contents": "Title: Optimal Stopping for Non-linear Expectations Abstract: We develop a theory for solving continuous time optimal stopping problems for\nnon-linear expectations. Our motivation is to consider problems in which the\nstopper uses risk measures to evaluate future rewards. \n\n"}
{"id": "0907.1020", "contents": "Title: Convergence and Convergence Rate of Stochastic Gradient Search in the\n  Case of Multiple and Non-Isolated Extrema Abstract: The asymptotic behavior of stochastic gradient algorithms is studied. Relying\non results from differential geometry (Lojasiewicz gradient inequality), the\nsingle limit-point convergence of the algorithm iterates is demonstrated and\nrelatively tight bounds on the convergence rate are derived. In sharp contrast\nto the existing asymptotic results, the new results presented here allow the\nobjective function to have multiple and non-isolated minima. The new results\nalso offer new insights into the asymptotic properties of several classes of\nrecursive algorithms which are routinely used in engineering, statistics,\nmachine learning and operations research. \n\n"}
{"id": "0907.4518", "contents": "Title: A new semidefinite programming hierarchy for cycles in binary matroids\n  and cuts in graphs Abstract: The theta bodies of a polynomial ideal are a series of semidefinite\nprogramming relaxations of the convex hull of the real variety of the ideal. In\nthis paper we construct the theta bodies of the vanishing ideal of cycles in a\nbinary matroid. Applied to cuts in graphs, this yields a new hierarchy of\nsemidefinite programming relaxations of the cut polytope of the graph. If the\nbinary matroid avoids certain minors we can characterize when the first theta\nbody in the hierarchy equals the cycle polytope of the matroid. Specialized to\ncuts in graphs, this result solves a problem posed by Lov\\'asz. \n\n"}
{"id": "0908.1586", "contents": "Title: Minimal half-spaces and external representation of tropical polyhedra Abstract: We give a characterization of the minimal tropical half-spaces containing a\ngiven tropical polyhedron, from which we derive a counter example showing that\nthe number of such minimal half-spaces can be infinite, contradicting some\nstatements which appeared in the tropical literature, and disproving a\nconjecture of F. Block and J. Yu. We also establish an analogue of the\nMinkowski-Weyl theorem, showing that a tropical polyhedron can be equivalently\nrepresented internally (in terms of extreme points and rays) or externally (in\nterms of half-spaces containing it). A canonical external representation of a\npolyhedron turns out to be provided by the extreme elements of its tropical\npolar. We characterize these extreme elements, showing in particular that they\nare determined by support vectors. \n\n"}
{"id": "0909.4948", "contents": "Title: Optimal Stopping for Dynamic Convex Risk Measures Abstract: We use martingale and stochastic analysis techniques to study a\ncontinuous-time optimal stopping problem, in which the decision maker uses a\ndynamic convex risk measure to evaluate future rewards. We also find a saddle\npoint for an equivalent zero-sum game of control and stopping, between an agent\n(the \"stopper\") who chooses the termination time of the game, and an agent (the\n\"controller\", or \"nature\") who selects the probability measure. \n\n"}
{"id": "0909.5577", "contents": "Title: A Class of Semidefinite Programs with rank-one solutions Abstract: We show that a class of semidefinite programs (SDP) admits a solution that is\na positive semidefinite matrix of rank at most $r$, where $r$ is the rank of\nthe matrix involved in the objective function of the SDP. The optimization\nproblems of this class are semidefinite packing problems, which are the SDP\nanalogs to vector packing problems. Of particular interest is the case in which\nour result guarantees the existence of a solution of rank one: we show that the\ncomputation of this solution actually reduces to a Second Order Cone Program\n(SOCP). We point out an application in statistics, in the optimal design of\nexperiments. \n\n"}
{"id": "0911.1536", "contents": "Title: Parallel Proximal Algorithm for Image Restoration Using Hybrid\n  Regularization -- Extended Version Abstract: Regularization approaches have demonstrated their effectiveness for solving\nill-posed problems. However, in the context of variational restoration methods,\na challenging question remains, which is how to find a good regularizer. While\ntotal variation introduces staircase effects, wavelet domain regularization\nbrings other artefacts, e.g. ringing. However, a compromise can be found by\nintroducing a hybrid regularization including several terms non necessarily\nacting in the same domain (e.g. spatial and wavelet transform domains). We\nadopt a convex optimization framework where the criterion to be minimized is\nsplit in the sum of more than two terms. For spatial domain regularization,\nisotropic or anisotropic total variation definitions using various gradient\nfilters are considered. An accelerated version of the Parallel ProXimal\nAlgorithm is proposed to perform the minimization. Some difficulties in the\ncomputation of the proximity operators involved in this algorithm are also\naddressed in this paper. Numerical experiments performed in the context of\nPoisson data recovery, show the good behavior of the algorithm as well as\npromising results concerning the use of hybrid regularization techniques. \n\n"}
{"id": "1003.1332", "contents": "Title: Tangency vis-a'-vis differentiability by Peano, Severi and Guareschi Abstract: Peano defined 'differentiability' of functions and 'lower tangent cones' in\n1887, and 'upper tangent cones' in 1903, but uses the latter concept already in\n1887 without giving a formal definition. Both cones were defined for arbitrary\nsets, as certain limits of appropriate homothetic relations. Around 1930 Severi\nand Guareschi, in a series of mutually fecundating individual papers,\ncharacterized differentiability in terms of 'lower tangent cones' and strict\ndifferentiability in terms of 'lower paratangent cones', a notion introduced,\nindependently, by Severi and Bouligand in 1928. Severi and Guareschi graduated\nabout 1900 from the University of Turin, where Peano taught till his demise in\n1932. \n\n"}
{"id": "1003.5826", "contents": "Title: The Second Euler-Lagrange Equation of Variational Calculus on Time\n  Scales Abstract: The fundamental problem of the calculus of variations on time scales concerns\nthe minimization of a delta-integral over all trajectories satisfying given\nboundary conditions. In this paper we prove the second Euler-Lagrange necessary\noptimality condition for optimal trajectories of variational problems on time\nscales. As an example of application of the main result, we give an alternative\nand simpler proof to the Noether theorem on time scales recently obtained in\n[J. Math. Anal. Appl. 342 (2008), no. 2, 1220-1226]. \n\n"}
{"id": "1004.0368", "contents": "Title: Semi-algebraic functions have small subdifferentials Abstract: We prove that the subdifferential of any semi-algebraic extended-real-valued\nfunction on $\\R^n$ has $n$-dimensional graph. We discuss consequences for\ngeneric semi-algebraic optimization problems. \n\n"}
{"id": "1004.0595", "contents": "Title: Precautionary Measures for Credit Risk Management in Jump Models Abstract: Sustaining efficiency and stability by properly controlling the equity to\nasset ratio is one of the most important and difficult challenges in bank\nmanagement. Due to unexpected and abrupt decline of asset values, a bank must\nclosely monitor its net worth as well as market conditions, and one of its\nimportant concerns is when to raise more capital so as not to violate capital\nadequacy requirements. In this paper, we model the tradeoff between avoiding\ncosts of delay and premature capital raising, and solve the corresponding\noptimal stopping problem. In order to model defaults in a bank's loan/credit\nbusiness portfolios, we represent its net worth by Levy processes, and solve\nexplicitly for the double exponential jump diffusion process and for a general\nspectrally negative Levy process. \n\n"}
{"id": "1004.3113", "contents": "Title: Minimal modified energy control for fractional linear control systems\n  with the Caputo derivative Abstract: Fractional control systems with the Caputo derivative are considered. The\nmodified controllability Gramian and the minimum energy optimal control problem\nare investigated. Construction of minimizing steering controls for the modified\nenergy functional are proposed. \n\n"}
{"id": "1005.1357", "contents": "Title: Stock loan with Automatic termination clause, cap and margin Abstract: This paper works out fair values of stock loan model with automatic\ntermination clause, cap and margin. This stock loan is treated as a generalized\nperpetual American option with possibly negative interest rate and some\nconstraints. Since it helps a bank to control the risk, the banks charge less\nservice fees compared to stock loans without any constraints. The automatic\ntermination clause, cap and margin are in fact a stop order set by the bank.\nMathematically, it is a kind of optimal stopping problems arising from the\npricing of financial products which is first revealed. We aim at establishing\nexplicitly the value of such a loan and ranges of fair values of key parameters\n: this loan size, interest rate, cap, margin and fee for providing such a\nservice and quantity of this automatic termination clause and relationships\namong these parameters as well as the optimal exercise times. We present\nnumerical results and make analysis about the model parameters and how they\nimpact on value of stock loan. \n\n"}
{"id": "1006.0158", "contents": "Title: Statistics of voltage drop in radial distribution circuits: a dynamic\n  programming approach Abstract: We analyze a power distribution line with high penetration of distributed\ngeneration and strong variations of power consumption and generation levels. In\nthe presence of uncertainty the statistical description of the system is\nrequired to assess the risks of power outages. In order to find the probability\nof exceeding the constraints for voltage levels we introduce the probability\ndistribution of maximal voltage drop and propose an algorithm for finding this\ndistribution. The algorithm is based on the assumption of random but\nstatistically independent distribution of loads on buses. Linear complexity in\nthe number of buses is achieved through the dynamic programming technique. We\nillustrate the performance of the algorithm by analyzing a simple 4-bus system\nwith high variations of load levels. \n\n"}
{"id": "1006.4392", "contents": "Title: Dynamics of Dengue epidemics using optimal control Abstract: We present an application of optimal control theory to Dengue epidemics. This\nepidemiologic disease is an important theme in tropical countries due to the\ngrowing number of infected individuals. The dynamic model is described by a set\nof nonlinear ordinary differential equations, that depend on the dynamic of the\nDengue mosquito, the number of infected individuals, and the people's\nmotivation to combat the mosquito. The cost functional depends not only on the\ncosts of medical treatment of the infected people but also on the costs related\nto educational and sanitary campaigns. Two approaches to solve the problem are\nconsidered: one using optimal control theory, another one by discretizing first\nthe problem and then solving it with nonlinear programming. The results\nobtained with OC-ODE and IPOPT solvers are given and discussed. We observe that\nwith current computational tools it is easy to obtain, in an efficient way,\nbetter solutions to Dengue problems, leading to a decrease of infected\nmosquitoes and individuals in less time and with lower costs. \n\n"}
{"id": "1007.0584", "contents": "Title: Euler-Lagrange equations for composition functionals in calculus of\n  variations on time scales Abstract: In this paper we consider the problem of the calculus of variations for a\nfunctional which is the composition of a certain scalar function $H$ with the\ndelta integral of a vector valued field $f$, i.e., of the form\n$H(\\int_{a}^{b}f(t,x^{\\sigma}(t),x^{\\Delta}(t))\\Delta t)$. Euler-Lagrange\nequations, natural boundary conditions for such problems as well as a necessary\noptimality condition for isoperimetric problems, on a general time scale, are\ngiven. A number of corollaries are obtained, and several examples illustrating\nthe new results are discussed in detail. \n\n"}
{"id": "1007.0743", "contents": "Title: Fractional variational calculus in terms of a combined Caputo derivative Abstract: We generalize the fractional Caputo derivative to the fractional derivative\n${^CD^{\\alpha,\\beta}_{\\gamma}}$, which is a convex combination of the left\nCaputo fractional derivative of order $\\alpha$ and the right Caputo fractional\nderivative of order $\\beta$. The fractional variational problems under our\nconsideration are formulated in terms of ${^CD^{\\alpha,\\beta}_{\\gamma}}$. The\nEuler-Lagrange equations for the basic and isoperimetric problems, as well as\ntransversality conditions, are proved. \n\n"}
{"id": "1007.1191", "contents": "Title: Convex Hulls of Algebraic Sets Abstract: This article describes a method to compute successive convex approximations\nof the convex hull of a set of points in R^n that are the solutions to a system\nof polynomial equations over the reals. The method relies on sums of squares of\npolynomials and the dual theory of moment matrices. The main feature of the\ntechnique is that all computations are done modulo the ideal generated by the\npolynomials defining the set to the convexified. This work was motivated by\nquestions raised by Lov\\'asz concerning extensions of the theta body of a graph\nto arbitrary real algebraic varieties, and hence the relaxations described here\nare called theta bodies. The convexification process can be seen as an\nincarnation of Lasserre's hierarchy of convex relaxations of a semialgebraic\nset in R^n. When the defining ideal is real radical the results become\nespecially nice. We provide several examples of the method and discuss\nconvergence issues. Finite convergence, especially after the first step of the\nmethod, can be described explicitly for finite point sets. \n\n"}
{"id": "1007.2905", "contents": "Title: Invariant semidefinite programs Abstract: In the last years many results in the area of semidefinite programming were\nobtained for invariant (finite dimensional, or infinite dimensional)\nsemidefinite programs - SDPs which have symmetry. This was done for a variety\nof problems and applications. The purpose of this handbook chapter is to give\nthe reader the necessary background for dealing with semidefinite programs\nwhich have symmetry. Here the basic theory is given and it is illustrated in\napplications from coding theory, combinatorics, geometry, and polynomial\noptimization. \n\n"}
{"id": "1007.3125", "contents": "Title: On the computation of the Omega invariant of a numerical semigroup by\n  optimizing over an efficient integer set Abstract: In this paper we present a mathematical formulation for the omega invariant\nof a numerical semigroup for each of its minimal generators. The model consists\nof solving a problem of optimizing a linear function over the efficient set of\na multiobjective linear integer program. We offer a methodology to solve this\nproblem and we provide some computational experiments to show the applicability\nof the proposed algorithm. \n\n"}
{"id": "1007.3946", "contents": "Title: Modified Optimal Energy and Initial Memory of Fractional Continuous-Time\n  Linear Systems Abstract: Fractional systems with Riemann-Liouville derivatives are considered. The\ninitial memory value problem is posed and studied. We obtain explicit steering\nlaws with respect to the values of the fractional integrals of the state\nvariables. The Gramian is generalized and steering functions between memory\nvalues are characterized. \n\n"}
{"id": "1007.5178", "contents": "Title: Noether's symmetry theorem for nabla problems of the calculus of\n  variations Abstract: We prove a Noether-type symmetry theorem and a DuBois-Reymond necessary\noptimality condition for nabla problems of the calculus of variations on time\nscales. \n\n"}
{"id": "1008.4895", "contents": "Title: LIFO-Backpressure Achieves Near Optimal Utility-Delay Tradeoff Abstract: There has been considerable recent work developing a new stochastic network\nutility maximization framework using Backpressure algorithms, also known as\nMaxWeight. A key open problem has been the development of utility-optimal\nalgorithms that are also delay efficient. In this paper, we show that the\nBackpressure algorithm, when combined with the LIFO queueing discipline (called\nLIFO-Backpressure), is able to achieve a utility that is within $O(1/V)$ of the\noptimal value, while maintaining an average delay of $O([\\log(V)]^2)$ for all\nbut a tiny fraction of the network traffic. This result holds for general\nstochastic network optimization problems and general Markovian dynamics.\nRemarkably, the performance of LIFO-Backpressure can be achieved by simply\nchanging the queueing discipline; it requires no other modifications of the\noriginal Backpressure algorithm. We validate the results through empirical\nmeasurements from a sensor network testbed, which show good match between\ntheory and practice. \n\n"}
{"id": "1009.0410", "contents": "Title: Generalized Newton's Method based on Graphical Derivatives Abstract: This paper concerns developing a numerical method of the Newton type to solve\nsystems of nonlinear equations described by nonsmooth continuous functions. We\npropose and justify a new generalized Newton algorithm based on graphical\nderivatives, which have never been used to derive a Newton-type method for\nsolving nonsmooth equations. Based on advanced techniques of variational\nanalysis and generalized differentiation, we establish the well-posedness of\nthe algorithm, its local superlinear convergence, and its global convergence of\nthe Kantorovich type. Our convergence results hold with no semismoothness\nassumption, which is illustrated by examples. The algorithm and main results\nobtained in the paper are compared with well-recognized semismooth and\n$B$-differentiable versions of Newton's method for nonsmooth Lipschitzian\nequations. \n\n"}
{"id": "1009.5253", "contents": "Title: A probabilistic comparison of the strength of split, triangle, and\n  quadrilateral cuts (extended version) Abstract: We consider mixed integer linear sets defined by two equations involving two\ninteger variables and any number of non-negative continuous variables. The\nnon-trivial valid inequalities of such sets can be classified into split, type\n1, type 2, type 3, and quadrilateral inequalities. We use a strength measure of\nGoemans to analyze the benefit from adding a non-split inequality on top of the\nsplit closure. Applying a probabilistic model, we show that the importance of a\ntype 2 inequality decreases with decreasing lattice width, on average. Our\nresults suggest that this is also true for type 3 and quadrilateral\ninequalities. \n\n"}
{"id": "1009.6036", "contents": "Title: Efficient Information Aggregation Strategies for Distributed Control and\n  Signal Processing Abstract: This thesis is concerned with distributed control and coordination of\nnetworks consisting of multiple, potentially mobile, agents. This is motivated\nmainly by the emergence of large scale networks characterized by the lack of\ncentralized access to information and time-varying connectivity. Control and\noptimization algorithms deployed in such networks should be completely\ndistributed, relying only on local observations and information, and robust\nagainst unexpected changes in topology such as link failures. We will describe\nprotocols to solve certain control and signal processing problems in this\nsetting. We will demonstrate that a key challenge for such systems is the\nproblem of computing averages in a decentralized way. Namely, we will show that\na number of distributed control and signal processing problems can be solved\nstraightforwardly if solutions to the averaging problem are available. The rest\nof the thesis will be concerned with algorithms for the averaging problem and\nits generalizations. We will (i) derive the fastest known averaging algorithms\nin a variety of settings and subject to a variety of communication and storage\nconstraints (ii) prove a lower bound identifying a fundamental barrier for\naveraging algorithms (iii) propose a new model for distributed function\ncomputation which reflects the constraints facing many large-scale networks,\nand nearly characterize the general class of functions which can be computed in\nthis model. \n\n"}
{"id": "1010.1077", "contents": "Title: Maximal lattice-free polyhedra: finiteness and an explicit description\n  in dimension three Abstract: A convex set with nonempty interior is maximal lattice-free if it is\ninclusion-maximal with respect to the property of not containing integer points\nin its interior. Maximal lattice-free convex sets are known to be polyhedra.\nThe precision of a rational polyhedron $P$ in $\\mathbb{R}^d$ is the smallest\ninteger $s$ such that $sP$ is an integral polyhedron. In this paper we show\nthat, up to affine mappings preserving $\\mathbb{Z}^d$, the number of maximal\nlattice-free rational polyhedra of a given precision $s$ is finite.\nFurthermore, we present the complete list of all maximal lattice-free integral\npolyhedra in dimension three. Our results are motivated by recent research on\ncutting plane theory in mixed-integer linear optimization. \n\n"}
{"id": "1010.6148", "contents": "Title: On a small-gain approach to distributed event-triggered control Abstract: In this paper the problem of stabilizing large-scale systems by distributed\ncontrollers, where the controllers exchange information via a shared limited\ncommunication medium is addressed. Event-triggered sampling schemes are\nproposed, where each system decides when to transmit new information across the\nnetwork based on the crossing of some error thresholds. Stability of the\ninterconnected large-scale system is inferred by applying a generalized\nsmall-gain theorem. Two variations of the event-triggered controllers which\nprevent the occurrence of the Zeno phenomenon are also discussed. \n\n"}
{"id": "1011.2348", "contents": "Title: Ergodic Control and Polyhedral approaches to PageRank Optimization Abstract: We study a general class of PageRank optimization problems which consist in\nfinding an optimal outlink strategy for a web site subject to design\nconstraints. We consider both a continuous problem, in which one can choose the\nintensity of a link, and a discrete one, in which in each page, there are\nobligatory links, facultative links and forbidden links. We show that the\ncontinuous problem, as well as its discrete variant when there are no\nconstraints coupling different pages, can both be modeled by constrained Markov\ndecision processes with ergodic reward, in which the webmaster determines the\ntransition probabilities of websurfers. Although the number of actions turns\nout to be exponential, we show that an associated polytope of transition\nmeasures has a concise representation, from which we deduce that the continuous\nproblem is solvable in polynomial time, and that the same is true for the\ndiscrete problem when there are no coupling constraints. We also provide\nefficient algorithms, adapted to very large networks. Then, we investigate the\nqualitative features of optimal outlink strategies, and identify in particular\nassumptions under which there exists a \"master\" page to which all controlled\npages should point. We report numerical results on fragments of the real web\ngraph. \n\n"}
{"id": "1012.4442", "contents": "Title: On backward stochastic differential equations approach to valuation of\n  American options Abstract: We consider the problem of valuation of American (call and put) options\nwritten on a dividend paying stock governed by the geometric Brownian motion.\nWe show that the value function has two different but related representations:\nby means of a solution of some nonlinear backward stochastic differential\nequation and weak solution to some semilinear partial differential equation. \n\n"}
{"id": "1101.0694", "contents": "Title: Backward variational approach on time scales with an action depending on\n  the free endpoints Abstract: We establish necessary optimality conditions for variational problems with an\naction depending on the free endpoints. New transversality conditions are also\nobtained. The results are formulated and proved using the recent and general\ntheory of time scales via the backward nabla differential operator. \n\n"}
{"id": "1102.1337", "contents": "Title: Fractional Calculus of Variations for Double Integrals Abstract: We consider fractional isoperimetric problems of calculus of variations with\ndouble integrals via the recent modified Riemann-Liouville approach. A\nnecessary optimality condition of Euler-Lagrange type, in the form of a\nmultitime fractional PDE, is proved, as well as a sufficient condition and\nfractional natural boundary conditions. \n\n"}
{"id": "1102.2361", "contents": "Title: Convergence of type-symmetric and cut-balanced consensus seeking systems\n  (extended version) Abstract: We consider continuous-time consensus seeking systems whose time-dependent\ninteractions are cut-balanced, in the following sense: if a group of agents\ninfluences the remaining ones, the former group is also influenced by the\nremaining ones by at least a proportional amount. Models involving symmetric\ninterconnections and models in which a weighted average of the agent values is\nconserved are special cases. We prove that such systems always converge. We\ngive a sufficient condition on the evolving interaction topology for the limit\nvalues of two agents to be the same. Conversely, we show that if our condition\nis not satisfied, then these limits are generically different. These results\nallow treating systems where the agent interactions are a priori unknown, e.g.,\nrandom or determined endogenously by the agent values. We also derive\ncorresponding results for discrete-time systems. \n\n"}
{"id": "1102.2950", "contents": "Title: Kron Reduction of Graphs with Applications to Electrical Networks Abstract: Consider a weighted and undirected graph, possibly with self-loops, and its\ncorresponding Laplacian matrix, possibly augmented with additional diagonal\nelements corresponding to the self-loops. The Kron reduction of this graph is\nagain a graph whose Laplacian matrix is obtained by the Schur complement of the\noriginal Laplacian matrix with respect to a subset of nodes. The Kron reduction\nprocess is ubiquitous in classic circuit theory and in related disciplines such\nas electrical impedance tomography, smart grid monitoring, transient stability\nassessment in power networks, or analysis and simulation of induction motors\nand power electronics. More general applications of Kron reduction occur in\nsparse matrix algorithms, multi-grid solvers, finite--element analysis, and\nMarkov chains. The Schur complement of a Laplacian matrix and related concepts\nhave also been studied under different names and as purely theoretic problems\nin the literature on linear algebra. In this paper we propose a general\ngraph-theoretic framework for Kron reduction that leads to novel and deep\ninsights both on the mathematical and the physical side. We show the\napplicability of our framework to various practical problem setups arising in\nengineering applications and computation. Furthermore, we provide a\ncomprehensive and detailed graph-theoretic analysis of the Kron reduction\nprocess encompassing topological, algebraic, spectral, resistive, and\nsensitivity analyses. Throughout our theoretic elaborations we especially\nemphasize the practical applicability of our results. \n\n"}
{"id": "1102.3214", "contents": "Title: LQG Control Approach to Gaussian Broadcast Channels with Feedback Abstract: A code for communication over the k-receiver additive white Gaussian noise\nbroadcast channel with feedback is presented and analyzed using tools from the\ntheory of linear quadratic Gaussian optimal control. It is shown that the\nperformance of this code depends on the noise correlation at the receivers and\nit is related to the solution of a discrete algebraic Riccati equation. For the\ncase of independent noises, the sum rate achieved by the proposed code,\nsatisfying average power constraint P, is characterized as 1/2 log (1+P*phi),\nwhere the coefficient \"phi\" in the interval [1,k] quantifies the power gain due\nto the presence of feedback. When specialized to the case of two receivers,\nthis includes a previous result by Elia and strictly improves upon the code of\nOzarow and Leung. When the noises are correlated, the pre-log of the\nsum-capacity of the broadcast channel with feedback can be strictly greater\nthan one. It is established that for all noise covariance matrices of rank r\nthe pre-log of the sum capacity is at most k-r+1 and, conversely, there exists\na noise covariance matrix of rank r for which the proposed code achieves this\nupper bound. This generalizes a previous result by Gastpar and Wigger for the\ntwo-receiver broadcast channel. \n\n"}
{"id": "1102.3727", "contents": "Title: Generalizing the variational theory on time scales to include the delta\n  indefinite integral Abstract: We prove necessary optimality conditions of Euler-Lagrange type for\ngeneralized problems of the calculus of variations on time scales with a\nLagrangian depending not only on the independent variable, an unknown function\nand its delta derivative, but also on a delta indefinite integral that depends\non the unknown function. Such kind of variational problems were considered by\nEuler himself and have been recently investigated in [Methods Appl. Anal. 15\n(2008), no. 4, 427-435]. Our results not only provide a generalization to\nprevious results, but also give some other interesting optimality conditions as\nspecial cases. \n\n"}
{"id": "1103.0571", "contents": "Title: On the Ramified Optimal Allocation Problem Abstract: This paper proposes an optimal allocation problem with ramified transport\ntechnology in a spatial economy. Ramified transportation is used to model the\ntransport economy of scale in group transportation observed widely in both\nnature and efficiently designed transport systems of branching structures. The\nramified allocation problem aims at finding an optimal allocation plan as well\nas an associated optimal allocation path to minimize overall cost of\ntransporting commodity from factories to households. This problem\ndifferentiates itself from existing ramified transportation literature in that\nthe distribution of production among factories is not fixed but endogenously\ndetermined as observed in many allocation practices. It's shown that due to the\ntransport economy of scale in ramified transportation, each optimal allocation\nplan corresponds equivalently to an optimal assignment map from households to\nfactories. This optimal assignment map provides a natural partition of both\nhouseholds and allocation paths. We develop methods of marginal transportation\nanalysis and projectional analysis to study properties of optimal assignment\nmaps. These properties are then related to the search for an optimal assignment\nmap in the context of state matrix. \n\n"}
{"id": "1104.1872", "contents": "Title: Convex and Network Flow Optimization for Structured Sparsity Abstract: We consider a class of learning problems regularized by a structured\nsparsity-inducing norm defined as the sum of l_2- or l_infinity-norms over\ngroups of variables. Whereas much effort has been put in developing fast\noptimization techniques when the groups are disjoint or embedded in a\nhierarchy, we address here the case of general overlapping groups. To this end,\nwe present two different strategies: On the one hand, we show that the proximal\noperator associated with a sum of l_infinity-norms can be computed exactly in\npolynomial time by solving a quadratic min-cost flow problem, allowing the use\nof accelerated proximal gradient methods. On the other hand, we use proximal\nsplitting techniques, and address an equivalent formulation with\nnon-overlapping groups, but in higher dimension and with additional\nconstraints. We propose efficient and scalable algorithms exploiting these two\nstrategies, which are significantly faster than alternative approaches. We\nillustrate these methods with several problems such as CUR matrix\nfactorization, multi-task learning of tree-structured dictionaries, background\nsubtraction in video sequences, image denoising with wavelets, and topographic\ndictionary learning of natural image patches. \n\n"}
{"id": "1104.3221", "contents": "Title: On the geometry of higher-order variational problems on Lie groups Abstract: In this paper, we describe a geometric setting for higher-order lagrangian\nproblems on Lie groups. Using left-trivialization of the higher-order tangent\nbundle of a Lie group and an adaptation of the classical Skinner-Rusk\nformalism, we deduce an intrinsic framework for this type of dynamical systems.\nInteresting applications as, for instance, a geometric derivation of the\nhigher-order Euler-Poincar\\'e equations, optimal control of underactuated\ncontrol systems whose configuration space is a Lie group are shown, among\nothers, along the paper. \n\n"}
{"id": "1104.5391", "contents": "Title: On Optimality of Greedy Policy for a Class of Standard Reward Function\n  of Restless Multi-armed Bandit Problem Abstract: In this paper,we consider the restless bandit problem, which is one of the\nmost well-studied generalizations of the celebrated stochastic multi-armed\nbandit problem in decision theory. However, it is known be PSPACE-Hard to\napproximate to any non-trivial factor. Thus the optimality is very difficult to\nobtain due to its high complexity. A natural method is to obtain the greedy\npolicy considering its stability and simplicity. However, the greedy policy\nwill result in the optimality loss for its intrinsic myopic behavior generally.\nIn this paper, by analyzing one class of so-called standard reward function, we\nestablish the closed-form condition about the discounted factor \\beta such that\nthe optimality of the greedy policy is guaranteed under the discounted expected\nreward criterion, especially, the condition \\beta = 1 indicating the optimality\nof the greedy policy under the average accumulative reward criterion. Thus, the\nstandard form of reward function can easily be used to judge the optimality of\nthe greedy policy without any complicated calculation. Some examples in\ncognitive radio networks are presented to verify the effectiveness of the\nmathematical result in judging the optimality of the greedy policy. \n\n"}
{"id": "1105.2755", "contents": "Title: Continuous-time consensus under persistent connectivity and slow\n  divergence of reciprocal interaction weights Abstract: In this paper, we present new results on consensus for continuous-time multi-\nagent systems. We introduce the assumptions of persistent connectivity of the\ninteraction graph and of slow divergence of reciprocal interaction weights.\nPersistent connectivity can be considered as the counterpart of the notion of\nultimate connectivity used in discrete- time consensus protocols. Slow\ndivergence of reciprocal interaction weights generalizes the assumption of\ncut-balanced interactions. We show that under these two assumptions, the\ncontinuous-time consensus protocol succeeds: the states of all the agents\nconverge asymptotically to a common value. Moreover, our proof allows us to\ngive an estimate of the rate of convergence towards the consensus. We also\nprovide two examples that make us think that both of our assumptions are tight. \n\n"}
{"id": "1105.2924", "contents": "Title: On the derivative cones of polyhedral cones Abstract: Hyperbolic polynomials elegantly encode a rich class of convex cones that\nincludes polyhedral and spectrahedral cones. Hyperbolic polynomials are closed\nunder taking polars and the corresponding cones, the derivative cones, yield\nrelaxations for the associated optimization problem and exhibit interesting\nfacial properties. While it is unknown if every hyperbolicity cone is a section\nof the positive semidefinite cone, it is natural to ask whether spectrahedral\ncones are closed under taking polars. In this note we give an affirmative\nanswer for polyhedral cones by exhibiting an explicit spectrahedral\nrepresentation for the first derivative cone. We also proof that higher polars\ndo not have an determinantal representation which shows that the problem for\ngeneral spectrahedral cones is considerably more difficult. \n\n"}
{"id": "1105.3298", "contents": "Title: Graphical model approximations of random finite set filters Abstract: Random finite sets (RFSs) has been a fruitful area of research in recent\nyears, yielding new approximate filters such as the probability hypothesis\ndensity (PHD), cardinalised PHD (CPHD), and multiple target multi-Bernoulli\n(MeMBer). These new methods have largely been based on approximations that\nside-step the need for measurement-to-track association. Comparably, RFS\nmethods that incorporate data association, such as Morelande and Challa's (M-C)\nmethod, have received little attention. This paper provides a RFS algorithm\nthat incorporates data association similarly to the M-C method, but retains\ncomputational tractability via a recently developed approximation of marginal\nassociation weights. We describe an efficient method for resolving the track\ncoalescence phenomenon which is problematic for joint probabilistic data\nassociation (JPDA) and related methods (including M-C). The method utilises a\nnetwork flow optimisation, and thus is tractable for large numbers of targets.\nFinally, our derivation also shows that it is natural for the multi-target\ndensity to incorporate both a Poisson point process (PPP) component\n(representing targets that have never been detected) and a multi-Bernoulli\ncomponent (representing targets under track). We describe a method of\nrecycling, in which tracks with a low probability existence are transferred\nfrom the multi-Bernoulli component to the PPP component, effectively yielding a\nhybrid of M-C and PHD. \n\n"}
{"id": "1105.4049", "contents": "Title: A coordinate-free condition number for convex programming Abstract: We introduce and analyze a natural geometric version of Renegar's condition\nnumber R for the homogeneous convex feasibility problem associated with a\nregular cone C subseteq R^n. Let Gr_{n,m} denote the Grassmann manifold of\nm-dimensional linear subspaces of R^n and consider the projection distance\nd_p(W_1,W_2) := ||Pi_{W_1} - Pi_{W_2}|| (spectral norm) between W_1 and W_2 in\nGr_{n,m}, where Pi_{W_i} denotes the orthogonal projection onto W_i. We call\nC_G(W) := max {d_p(W,W')^{-1} | W' \\in Sigma_m} the Grassmann condition number\nof W in Gr_{n,m}, where the set of ill-posed instances Sigma_m subset Gr_{n,m}\nis defined as the set of linear subspaces touching C. We show that if W =\nim(A^T) for a matrix A in R^{m\\times n}, then C_G(W) \\le R(A) \\le C_G(W)\nkappa(A), where kappa(A) =||A|| ||A^\\dagger|| denotes the matrix condition\nnumber. This extends work by Belloni and Freund in Math. Program. 119:95-107\n(2009). Furthermore, we show that C_G(W) can as well be characterized in terms\nof the Riemannian distance metric on Gr_{n,m}. This differential geometric\ncharacterization of C_G(W) is the starting point of the sequel\n[arXiv:1112.2603] to this paper, where the first probabilistic analysis of\nRenegar's condition number for an arbitrary regular cone C is achieved. \n\n"}
{"id": "1106.0423", "contents": "Title: Physarum Can Compute Shortest Paths Abstract: Physarum Polycephalum is a slime mold that is apparently able to solve\nshortest path problems.\n  A mathematical model has been proposed by biologists to describe the feedback\nmechanism used by the slime mold to adapt its tubular channels while foraging\ntwo food sources s0 and s1. We prove that, under this model, the mass of the\nmold will eventually converge to the shortest s0 - s1 path of the network that\nthe mold lies on, independently of the structure of the network or of the\ninitial mass distribution.\n  This matches the experimental observations by the biologists and can be seen\nas an example of a \"natural algorithm\", that is, an algorithm developed by\nevolution over millions of years. \n\n"}
{"id": "1106.2735", "contents": "Title: Computing the Grothendieck constant of some graph classes Abstract: Given a graph $G=([n],E)$ and $w\\in\\R^E$, consider the integer program\n${\\max}_{x\\in \\{\\pm 1\\}^n} \\sum_{ij \\in E} w_{ij}x_ix_j$ and its canonical\nsemidefinite programming relaxation ${\\max} \\sum_{ij \\in E} w_{ij}v_i^Tv_j$,\nwhere the maximum is taken over all unit vectors $v_i\\in\\R^n$. The integrality\ngap of this relaxation is known as the Grothendieck constant $\\ka(G)$ of $G$.\nWe present a closed-form formula for the Grothendieck constant of $K_5$-minor\nfree graphs and derive that it is at most 3/2. Moreover, we show that\n$\\ka(G)\\le \\ka(K_k)$ if the cut polytope of $G$ is defined by inequalities\nsupported by at most $k$ points. Lastly, since the Grothendieck constant of\n$K_n$ grows as $\\Theta(\\log n)$, it is interesting to identify instances with\nlarge gap. However this is not the case for the clique-web inequalities, a wide\nclass of valid inequalities for the cut polytope, whose integrality ratio is\nshown to be bounded by 3. \n\n"}
{"id": "1106.2781", "contents": "Title: Optimal Dividend Payments for the Piecewise-Deterministic Poisson Risk\n  Model Abstract: This paper considers the optimal dividend payment problem in\npiecewise-deterministic compound Poisson risk models. The objective is to\nmaximize the expected discounted dividend payout up to the time of ruin. We\nprovide a comparative study in this general framework of both restricted and\nunrestricted payment schemes, which were only previously treated separately in\ncertain special cases of risk models in the literature. In the case of\nrestricted payment scheme, the value function is shown to be a classical\nsolution of the corresponding HJB equation, which in turn leads to an optimal\nrestricted payment policy known as the threshold strategy. In the case of\nunrestricted payment scheme, by solving the associated integro-differential\nquasi-variational inequality, we obtain the value function as well as an\noptimal unrestricted dividend payment scheme known as the barrier strategy.\nWhen claim sizes are exponentially distributed, we provide easily verifiable\nconditions under which the threshold and barrier strategies are optimal\nrestricted and unrestricted dividend payment policies, respectively. The main\nresults are illustrated with several examples, including a new example\nconcerning regressive growth rates. \n\n"}
{"id": "1106.3678", "contents": "Title: An introduction to ML(n)BiCGStab Abstract: ML(n)BiCGStab is a Krylov subspace method for the solution of large, sparse\nand non-symmetric linear systems. In theory, it is a method that lies between\nthe well-known BiCGStab and GMRES/FOM. In fact, when n = 1, ML(1)BiCGStab is\nBiCGStab and when n = N, ML(N)BiCGStab is GMRES/FOM where N is the size of the\nlinear system. Therefore, ML(n)BiCGStab is a bridge that connects the\nLanczos-based BiCGStab and the Arnoldi-based GMRES/FOM. In computation,\nML(n)BiCGStab can be much more stable and converge much faster than BiCGStab\nwhen a problem with ill-condition is solved. We have tested ML(n)BiCGStab on\nthe standard oil reservoir simulation test data called SPE9 and found that\nML(n)BiCGStab reduced the total computational time by more than 60% when\ncompared to BiCGStab. Tests made on the data from Matrix Market also support\nthe superiority of ML(n)BiCGStab over BiCGStab. Because of the O(N^2) storage\nrequirement in the full GMRES, one has to adopt a restart strategy to get the\nstorage under control when GMRES is implemented. In comparison, ML(n)BiCGStab\nis a method with only O(nN) storage requirement and therefore it does not need\na restart strategy. In this paper, we introduce ML(n)BiCGStab (in particular, a\nnew algorithm involving A-transpose), its relations to some existing methods\nand its implementations. \n\n"}
{"id": "1107.0190", "contents": "Title: The Stability of the Constrained Utility Maximization Problem - A BSDE\n  Approach Abstract: This article studies the sensitivity of the power utility maximization\nproblem with respect to the investor's relative risk aversion, the statistical\nprobability measure, the investment constraints and the market price of risk.\nWe extend previous descriptions of the dual domain then exploit the link\nbetween the constrained utility maximization problem and continuous\nsemimartingale quadratic BSDEs to reduce questions on sensitivity to results on\nstability for such equations. This then allows us to prove appropriate\nconvergence of the primal and dual optimizers in the semimartingale topology. \n\n"}
{"id": "1107.0344", "contents": "Title: The power quantum calculus and variational problems Abstract: We introduce the power difference calculus based on the operator $D_{n,q}\nf(t) = \\frac{f(qt^n)-f(t)}{qt^n -t}$, where $n$ is an odd positive integer and\n$0<q<1$. Properties of the new operator and its inverse --- the $d_{n,q}$\nintegral --- are proved. As an application, we consider power quantum\nLagrangian systems and corresponding $n,q$-Euler--Lagrange equations. \n\n"}
{"id": "1107.2988", "contents": "Title: Robust maximization of asymptotic growth under covariance uncertainty Abstract: This paper resolves a question proposed in Kardaras and Robertson [Ann. Appl.\nProbab. 22 (2012) 1576-1610]: how to invest in a robust growth-optimal way in a\nmarket where precise knowledge of the covariance structure of the underlying\nassets is unavailable. Among an appropriate class of admissible covariance\nstructures, we characterize the optimal trading strategy in terms of a\ngeneralized version of the principal eigenvalue of a fully nonlinear elliptic\noperator and its associated eigenfunction, by slightly restricting the\ncollection of nondominated probability measures. \n\n"}
{"id": "1107.4142", "contents": "Title: Asymptotics of the Invariant Measure in Mean Field Models with Jumps Abstract: We consider the asymptotics of the invariant measure for the process of the\nempirical spatial distribution of $N$ coupled Markov chains in the limit of a\nlarge number of chains. Each chain reflects the stochastic evolution of one\nparticle. The chains are coupled through the dependence of the transition rates\non this spatial distribution of particles in the various states. Our model is a\ncaricature for medium access interactions in wireless local area networks. It\nis also applicable to the study of spread of epidemics in a network. The\nlimiting process satisfies a deterministic ordinary differential equation\ncalled the McKean-Vlasov equation. When this differential equation has a unique\nglobally asymptotically stable equilibrium, the spatial distribution\nasymptotically concentrates on this equilibrium. More generally, its limit\npoints are supported on a subset of the $\\omega$-limit sets of the\nMcKean-Vlasov equation. Using a control-theoretic approach, we examine the\nquestion of large deviations of the invariant measure from this limit. \n\n"}
{"id": "1107.4623", "contents": "Title: A Unifying Analysis of Projected Gradient Descent for\n  $\\ell_p$-constrained Least Squares Abstract: In this paper we study the performance of the Projected Gradient Descent(PGD)\nalgorithm for $\\ell_{p}$-constrained least squares problems that arise in the\nframework of Compressed Sensing. Relying on the Restricted Isometry Property,\nwe provide convergence guarantees for this algorithm for the entire range of\n$0\\leq p\\leq1$, that include and generalize the existing results for the\nIterative Hard Thresholding algorithm and provide a new accuracy guarantee for\nthe Iterative Soft Thresholding algorithm as special cases. Our results suggest\nthat in this group of algorithms, as $p$ increases from zero to one, conditions\nrequired to guarantee accuracy become stricter and robustness to noise\ndeteriorates. \n\n"}
{"id": "1108.0986", "contents": "Title: A proximal point algorithm for sequential feature extraction\n  applications Abstract: We propose a proximal point algorithm to solve LAROS problem, that is the\nproblem of finding a \"large approximately rank-one submatrix\". This LAROS\nproblem is used to sequentially extract features in data. We also develop a new\nstopping criterion for the proximal point algorithm, which is based on the\nduality conditions of \\eps-optimal solutions of the LAROS problem, with a\ntheoretical guarantee. We test our algorithm with two image databases and show\nthat we can use the LAROS problem to extract appropriate common features from\nthese images. \n\n"}
{"id": "1108.2018", "contents": "Title: Resource allocation with costly participation Abstract: We propose a new all-pay auction format in which risk-loving bidders pay a\nconstant fee each time they bid for an object whose monetary value is common\nknowledge among the bidders, and bidding fees are the only source of benefit\nfor the seller. We show that for the proposed model there exists a {unique}\nSymmetric Subgame Perfect Equilibrium (SSPE). The characterized SSPE is\nstationary when re-entry in the auction is allowed, and it is Markov perfect\nwhen re-entry is forbidden. Furthermore, we fully characterize the expected\nrevenue of the seller. Generally, with or without re-entry, it is more\nbeneficial for the seller to choose $v$ (value of the object), $s$ (sale\nprice), and $c$ (bidding fee) such that $\\frac{v-s}{c}$ becomes sufficiently\nlarge. In particular, when re-entry is permitted: the expected revenue of the\nseller is \\emph{independent} of the number of bidders, decreasing in the sale\nprice, increasing in the value of the object, and decreasing in the bidding\nfee; Moreover, the seller's revenue is equal to the value of the object when\nplayers are risk neutral, and it is strictly greater than the value of the\nobject when bidders are risk-loving. We further show that allowing re-entry can\nbe important in practice. Because, if the seller were to run such an auction\nwithout allowing re-entry, the auction would last a long time, and for almost\nall of its duration have only two remaining players. Thus, the seller's revenue\nrelies on those two players being willing to participate, without any breaks,\nin an auction that might last for thousands of rounds \n\n"}
{"id": "1109.1545", "contents": "Title: Exploiting Polyhedral Symmetries in Social Choice Abstract: A large amount of literature in social choice theory deals with quantifying\nthe probability of certain election outcomes. One way of computing the\nprobability of a specific voting situation under the Impartial Anonymous\nCulture assumption is via counting integral points in polyhedra. Here, Ehrhart\ntheory can help, but unfortunately the dimension and complexity of the involved\npolyhedra grows rapidly with the number of candidates. However, if we exploit\navailable polyhedral symmetries, some computations become possible that\npreviously were infeasible. We show this in three well known examples:\nCondorcet's paradox, Condorcet efficiency of plurality voting and in Plurality\nvoting vs Plurality Runoff. \n\n"}
{"id": "1109.2800", "contents": "Title: Adjoint-based predictor-corrector sequential convex programming for\n  parametric nonlinear optimization Abstract: This paper proposes an algorithmic framework for solving parametric\noptimization problems which we call adjoint-based predictor-corrector\nsequential convex programming. After presenting the algorithm, we prove a\ncontraction estimate that guarantees the tracking performance of the algorithm.\nTwo variants of this algorithm are investigated. The first one can be used to\nsolve nonlinear programming problems while the second variant is aimed to treat\nonline parametric nonlinear programming problems. The local convergence of\nthese variants is proved. An application to a large-scale benchmark problem\nthat originates from nonlinear model predictive control of a hydro power plant\nis implemented to examine the performance of the algorithms. \n\n"}
{"id": "1109.4184", "contents": "Title: A (k+1)-Slope Theorem for the k-Dimensional Infinite Group Relaxation Abstract: We prove that any minimal valid function for the k-dimensional infinite group\nrelaxation that is piecewise linear with at most k+1 slopes and does not factor\nthrough a linear map with non-trivial kernel is extreme. This generalizes a\ntheorem of Gomory and Johnson for k=1, and Cornuejols and Molinaro for k=2. \n\n"}
{"id": "1109.6179", "contents": "Title: On maximal S-free sets and the Helly number for the family of S-convex\n  sets Abstract: We study two combinatorial parameters, which we denote by f(S) and h(S),\nassociated to an arbitrary set S \\subseteq R^d, where d \\in N. In the\nnondegenerate situation, f(S) is the largest possible number of facets of a\nd-dimensional polyhedron L such that the interior of L is disjoint with S and L\nis inclusion-maximal with respect to this property. The parameter h(S) is the\nHelly number of the family of all sets that can be given as the intersection of\nS with a convex subset of R^d. We obtain the inequality f(S) \\le h(S) for an\narbitrary S and the equality f(S)=h(S) for every discrete S. Furthermore,\nmotivated by research in integer and mixed-integer optimization, we show that\n2^d is the sharp upper bound on f(S) in the case S = (Z^d \\times R^n) \\cap C,\nwhere n \\ge 0 and C \\subseteq R^{d+n} is convex. The presented material\ngeneralizes and unifies results of various authors, including the result h(Z^d)\n= 2^d of Doignon, the related result f(Z^d)=2^d of Lov\\'asz and the inequality\nf(Z^d \\cap C) \\le 2^d, which has recently been proved for every convex set C\n\\subseteq R^d by Dey & Mor\\'an. \n\n"}
{"id": "1110.4877", "contents": "Title: Attouch-Th\\'era duality revisited: paramonotonicity and operator\n  splitting Abstract: The problem of finding the zeros of the sum of two maximally monotone\noperators is of fundamental importance in optimization and variational\nanalysis. In this paper, we systematically study Attouch-Th\\'era duality for\nthis problem. We provide new results related to Passty's parallel sum, to\nEckstein and Svaiter's extended solution set, and to Combettes' fixed point\ndescription of the set of primal solutions. Furthermore, paramonotonicity is\nrevealed to be a key property because it allows for the recovery of all primal\nsolutions given just one arbitrary dual solution. As an application, we\ngeneralize the best approximation results by Bauschke, Combettes and Luke [J.\nApprox. Theory 141 (2006), 63-69] from normal cone operators to paramonotone\noperators. Our results are illustrated through numerous examples. \n\n"}
{"id": "1111.2108", "contents": "Title: A criterion of simultaneously symmetrization and spectral finiteness for\n  a finite set of real 2-by-2 matrices Abstract: In this paper, we consider the simultaneously symmetrization and spectral\nfiniteness for a finite set of real 2-by-2 matrices. \n\n"}
{"id": "1111.4642", "contents": "Title: Optimal control of coupled forward-backward stochastic system with jumps\n  and related Hamilton-Jacobi-Bellman equations Abstract: In this paper we investigate a kind of optimal control problem of coupled\nforward-backward stochastic system with jumps whose cost functional is defined\nthrough a coupled forward-backward stochastic differential equation with\nBrownian motion and Poisson random measure. For this end, we first study the\nregularity of solutions for this kind of forward-backward stochastic\ndifferential equations. We obtain that the value function is a deterministic\nfunction and satisfies the dynamic programming principle for this kind of\noptimal control problem. Moreover, we prove that the value functions is a\nviscosity solutions of the associated Hamilton-Jacobi-Bellman equations with\nintegral-differential operators. \n\n"}
{"id": "1112.2090", "contents": "Title: A coarea-type formula for the relaxation of a generalized elastica\n  functional Abstract: We consider in R^2 the generalized elastica functional defined, for smooth\nfunctions, as the p-elastica energies of the level lines integrated over all\nlevels. Extending the functional to L1, we study its L1-lower semicontinuous\nenvelope and we prove that, for any u in BV, the envelope at u can be\nrepresented by a coarea-type formula involving suitable collections of W2,p\ncurves that cover the essential boundaries of the level sets of u. \n\n"}
{"id": "1112.2091", "contents": "Title: Gradient Young measures, varifolds, and a generalized Willmore\n  functional Abstract: Being Omega an open and bounded Lipschitz domain of R^n, we consider the\ngeneralized Willmore functional on Omega defined, for smooth functions, as the\np-Willmore energy of each isolevel set integrated over all levels. We propose a\nnew framework, that combines varifolds and Young measures, to study the\nrelaxation of this functional in BV(Omega) with respect to the strong topology\nof L^1. \n\n"}
{"id": "1112.2603", "contents": "Title: Probabilistic analysis of the Grassmann condition number Abstract: We analyze the probability that a random m-dimensional linear subspace of R^n\nboth intersects a regular closed convex cone C\\subseteq R^n and lies within\ndistance \\alpha of an m-dimensional subspace not intersecting C (except at the\norigin). The result is expressed in terms of the spherical intrinsic volumes of\nthe cone C. This allows us to perform an average analysis of the Grassmann\ncondition number \\C(A) for the homogeneous convex feasibility problem \\exists\nx\\in C\\setminus 0 : Ax=0. The Grassmann condition number is a geometric version\nof Renegar's condition number, that we have introduced recently in [SIOPT\n22(3):1029-1041, 2012]. We thus give the first average analysis of convex\nprogramming that is not restricted to linear programming. In particular, we\nprove that if the entries of A\\in R^{m\\times n} are chosen i.i.d. standard\nnormal, then for any regular cone C, we have E[ln\\C(A)]<1.5 ln(n)+1.5. The\nproofs rely on various techniques from Riemannian geometry applied to Grassmann\nmanifolds. \n\n"}
{"id": "1112.5529", "contents": "Title: On the Geometry of Maximum Entropy Problems Abstract: We show that a simple geometric result suffices to derive the form of the\noptimal solution in a large class of finite and infinite-dimensional maximum\nentropy problems concerning probability distributions, spectral densities and\ncovariance matrices. These include Burg's spectral estimation method and\nDempster's covariance completion, as well as various recent generalizations of\nthe above. We then apply this orthogonality principle to the new problem of\ncompleting a block-circulant covariance matrix when an a priori estimate is\navailable. \n\n"}
{"id": "1201.2892", "contents": "Title: Algebraic Relaxations and Hardness Results in Polynomial Optimization\n  and Lyapunov Analysis Abstract: This thesis settles a number of questions related to computational complexity\nand algebraic, semidefinite programming based relaxations in optimization and\ncontrol. \n\n"}
{"id": "1201.4897", "contents": "Title: Adaptive Systems with Closed-loop Reference Models: Stability,\n  Robustness and Transient Performance Abstract: This paper explores the properties of adaptive systems with closed-loop\nreference models. Using additional design freedom available in closed-loop\nreference models, we design new adaptive controllers that are (a) stable, and\n(b) have improved transient properties. Numerical studies that complement\ntheoretical derivations are also reported. \n\n"}
{"id": "1202.1432", "contents": "Title: Regularity properties for general HJB equations. A BSDE method Abstract: In this work we investigate regularity properties of a large class of\nHamilton-Jacobi-Bellman (HJB) equations with or without obstacles, which can be\nstochastically interpreted in form of a stochastic control system which\nnonlinear cost functional is defined with the help of a backward stochastic\ndifferential equation (BSDE) or a reflected BSDE (RBSDE). More precisely, we\nprove that, firstly, the unique viscosity solution $V(t,x)$ of such a HJB\nequation over the time interval $[0,T],$ with or without an obstacle, and with\nterminal condition at time $T$, is jointly Lipschitz in $(t,x)$, for $t$\nrunning any compact subinterval of $[0,T)$. Secondly, for the case that $V$\nsolves a HJB equation without an obstacle or with an upper obstacle it is shown\nunder appropriate assumptions that $V(t,x)$ is jointly semiconcave in $(t,x)$.\nThese results extend earlier ones by Buckdahn, Cannarsa and Quincampoix [1].\nOur approach embeds their idea of time change into a BSDE analysis. We also\nprovide an elementary counter-example which shows that, in general, for the\ncase that $V$ solves a HJB equation with a lower obstacle the semi-concavity\ndoesn't hold true. \n\n"}
{"id": "1202.5923", "contents": "Title: Controllability of 3D Low Reynolds Swimmers Abstract: In this article, we consider a swimmer (i.e. a self-deformable body) immersed\nin a fluid, the flow of which is governed by the stationary Stokes equations.\nThis model is relevant for studying the locomotion of microorganisms or micro\nrobots for which the inertia effects can be neglected. Our first main\ncontribution is to prove that any such microswimmer has the ability to track,\nby performing a sequence of shape changes, any given trajectory in the fluid.\nWe show that, in addition, this can be done by means of arbitrarily small body\ndeformations that can be superimposed to any preassigned sequence of macro\nshape changes. Our second contribution is to prove that, when no macro\ndeformations are prescribed, tracking is generically possible by means of shape\nchanges obtained as a suitable combination of only four elementary\ndeformations. Eventually, still considering finite dimensional deformations, we\nstate results about the existence of optimal swimming strategies for a wide\nclass of cost functionals. \n\n"}
{"id": "1203.0253", "contents": "Title: Certificates of Impossibility of Hilbert-Artin Representations of a\n  Given Degree for Definite Polynomials and Functions Abstract: We deploy numerical semidefinite programming and conversion to exact rational\ninequalities to certify that for a positive semidefinite input polynomial or\nrational function, any representation as a fraction of sums-of-squares of\npolynomials with real coefficients must contain polynomials in the denominator\nof degree no less than a given input lower bound. By Artin's solution to\nHilbert's 17th problems, such representations always exist for some denominator\ndegree. Our certificates of infeasibility are based on the generalization of\nFarkas's Lemma to semidefinite programming.\n  The literature has many famous examples of impossibility of SOS\nrepresentability including Motzkin's, Robinson's, Choi's and Lam's polynomials,\nand Reznick's lower degree bounds on uniform denominators, e.g., powers of the\nsum-of-squares of each variable. Our work on exact certificates for positive\nsemidefiniteness allows for non-uniform denominators, which can have lower\ndegree and are often easier to convert to exact identities. Here we demonstrate\nour algorithm by computing certificates of impossibilities for an arbitrary\nsum-of-squares denominator of degree 2 and 4 for some symmetric sextics in 4\nand 5 variables, respectively. We can also certify impossibility of base\npolynomials in the denominator of restricted term structure, for instance as in\nLandau's reduction by one less variable. \n\n"}
{"id": "1203.1457", "contents": "Title: PageRank optimization applied to spam detection Abstract: We give a new link spam detection and PageRank demotion algorithm called\nMaxRank. Like TrustRank and AntiTrustRank, it starts with a seed of hand-picked\ntrusted and spam pages. We define the MaxRank of a page as the frequency of\nvisit of this page by a random surfer minimizing an average cost per time unit.\nOn a given page, the random surfer selects a set of hyperlinks and clicks with\nuniform probability on any of these hyperlinks. The cost function penalizes\nspam pages and hyperlink removals. The goal is to determine a hyperlink\ndeletion policy that minimizes this score. The MaxRank is interpreted as a\nmodified PageRank vector, used to sort web pages instead of the usual PageRank\nvector. The bias vector of this ergodic control problem, which is unique up to\nan additive constant, is a measure of the \"spamicity\" of each page, used to\ndetect spam pages. We give a scalable algorithm for MaxRank computation that\nallowed us to perform experimental results on the WEBSPAM-UK2007 dataset. We\nshow that our algorithm outperforms both TrustRank and AntiTrustRank for spam\nand nonspam page detection. \n\n"}
{"id": "1203.2295", "contents": "Title: Techniques for Solving Sudoku Puzzles Abstract: Solving Sudoku puzzles is one of the most popular pastimes in the world.\nPuzzles range in difficulty from easy to very challenging; the hardest puzzles\ntend to have the most empty cells. The current paper explains and compares\nthree algorithms for solving Sudoku puzzles. Backtracking, simulated annealing,\nand alternating projections are generic methods for attacking combinatorial\noptimization problems. Our results favor backtracking. It infallibly solves a\nSudoku puzzle or deduces that a unique solution does not exist. However,\nbacktracking does not scale well in high-dimensional combinatorial\noptimization. Hence, it is useful to expose students in the mathematical\nsciences to the other two solution techniques in a concrete setting. Simulated\nannealing shares a common structure with MCMC (Markov chain Monte Carlo) and\nenjoys wide applicability. The method of alternating projections solves the\nfeasibility problem in convex programming. Converting a discrete optimization\nproblem into a continuous optimization problem opens up the possibility of\nhandling combinatorial problems of much higher dimensionality. \n\n"}
{"id": "1203.2380", "contents": "Title: Quantum Control and Representation Theory Abstract: A new notion of controllability for quantum systems that takes advantage of\nthe linear superposition of quantum states is introduced. We call such notion\nvon Neumann controllabilty and it is shown that it is strictly weaker than the\nusual notion of pure state and operator controlability. We provide a simple and\neffective characterization of it by using tools from the theory of unitary\nrepresentations of Lie groups. In this sense we are able to approach the\nproblem of control of quantum states from a new perspective, that of the theory\nof unitary representations of Lie groups. A few examples of physical interest\nand the particular instances of compact and nilpotent dynamical Lie groups are\ndiscussed. \n\n"}
{"id": "1203.3656", "contents": "Title: Noether's Symmetry Theorem for Variational and Optimal Control Problems\n  with Time Delay Abstract: We extend the DuBois-Reymond necessary optimality condition and Noether's\nsymmetry theorem to the time delay variational setting. Both Lagrangian and\nHamiltonian versions of Noether's theorem are proved, covering problems of the\ncalculus of variations and optimal control with delays. \n\n"}
{"id": "1203.5161", "contents": "Title: Effect of correlations on network controllability Abstract: A dynamical system is controllable if by imposing appropriate external\nsignals on a subset of its nodes, it can be driven from any initial state to\nany desired state in finite time. Here we study the impact of various network\ncharacteristics on the minimal number of driver nodes required to control a\nnetwork. We find that clustering and modularity have no discernible impact, but\nthe symmetries of the underlying matching problem can produce linear, quadratic\nor no dependence on degree correlation coefficients, depending on the nature of\nthe underlying correlations. The results are supported by numerical simulations\nand help narrow the observed gap between the predicted and the observed number\nof driver nodes in real networks. \n\n"}
{"id": "1203.5483", "contents": "Title: Greedy Sparsity-Constrained Optimization Abstract: Sparsity-constrained optimization has wide applicability in machine learning,\nstatistics, and signal processing problems such as feature selection and\ncompressive Sensing. A vast body of work has studied the sparsity-constrained\noptimization from theoretical, algorithmic, and application aspects in the\ncontext of sparse estimation in linear models where the fidelity of the\nestimate is measured by the squared error. In contrast, relatively less effort\nhas been made in the study of sparsity-constrained optimization in cases where\nnonlinear models are involved or the cost function is not quadratic. In this\npaper we propose a greedy algorithm, Gradient Support Pursuit (GraSP), to\napproximate sparse minima of cost functions of arbitrary form. Should a cost\nfunction have a Stable Restricted Hessian (SRH) or a Stable Restricted\nLinearization (SRL), both of which are introduced in this paper, our algorithm\nis guaranteed to produce a sparse vector within a bounded distance from the\ntrue sparse optimum. Our approach generalizes known results for quadratic cost\nfunctions that arise in sparse linear regression and Compressive Sensing. We\nalso evaluate the performance of GraSP through numerical simulations on\nsynthetic data, where the algorithm is employed for sparse logistic regression\nwith and without $\\ell_2$-regularization. \n\n"}
{"id": "1204.0734", "contents": "Title: A new graph parameter related to bounded rank positive semidefinite\n  matrix completions Abstract: The Gram dimension $\\gd(G)$ of a graph $G$ is the smallest integer $k\\ge 1$\nsuch that any partial real symmetric matrix, whose entries are specified on the\ndiagonal and at the off-diagonal positions corresponding to edges of $G$, can\nbe completed to a positive semidefinite matrix of rank at most $k$ (assuming a\npositive semidefinite completion exists). For any fixed $k$ the class of graphs\nsatisfying $\\gd(G) \\le k$ is minor closed, hence it can characterized by a\nfinite list of forbidden minors. We show that the only minimal forbidden minor\nis $K_{k+1}$ for $k\\le 3$ and that there are two minimal forbidden minors:\n$K_5$ and $K_{2,2,2}$ for $k=4$. We also show some close connections to\nEuclidean realizations of graphs and to the graph parameter $\\nu^=(G)$ of\n\\cite{H03}. In particular, our characterization of the graphs with $\\gd(G)\\le\n4$ implies the forbidden minor characterization of the 3-realizable graphs of\nBelk and Connelly \\cite{Belk,BC} and of the graphs with $\\nu^=(G) \\le 4$ of van\nder Holst \\cite{H03}. \n\n"}
{"id": "1204.1106", "contents": "Title: Message Passing for Dynamic Network Energy Management Abstract: We consider a network of devices, such as generators, fixed loads, deferrable\nloads, and storage devices, each with its own dynamic constraints and\nobjective, connected by lossy capacitated lines. The problem is to minimize the\ntotal network objective subject to the device and line constraints, over a\ngiven time horizon. This is a large optimization problem, with variables for\nconsumption or generation in each time period for each device. In this paper we\ndevelop a decentralized method for solving this problem. The method is\niterative: At each step, each device exchanges simple messages with its\nneighbors in the network and then solves its own optimization problem,\nminimizing its own objective function, augmented by a term determined by the\nmessages it has received. We show that this message passing method converges to\na solution when the device objective and constraints are convex. The method is\ncompletely decentralized, and needs no global coordination other than\nsynchronizing iterations; the problems to be solved by each device can\ntypically be solved extremely efficiently and in parallel. The method is fast\nenough that even a serial implementation can solve substantial problems in\nreasonable time frames. We report results for several numerical experiments,\ndemonstrating the method's speed and scaling, including the solution of a\nproblem instance with over 30 million variables in 52 minutes for a serial\nimplementation; with decentralized computing, the solve time would be less than\none second. \n\n"}
{"id": "1204.2997", "contents": "Title: Hyperbolicity cones of elementary symmetric polynomials are\n  spectrahedral Abstract: We prove that the hyperbolicity cones of elementary symmetric polynomials are\nspectrahedral, i.e., they are slices of the cone of positive semidefinite\nmatrices. The proof uses the matrix--tree theorem, an idea already present in\nChoe et al. \n\n"}
{"id": "1204.3982", "contents": "Title: Adaptive Restart for Accelerated Gradient Schemes Abstract: In this paper we demonstrate a simple heuristic adaptive restart technique\nthat can dramatically improve the convergence rate of accelerated gradient\nschemes. The analysis of the technique relies on the observation that these\nschemes exhibit two modes of behavior depending on how much momentum is\napplied. In what we refer to as the 'high momentum' regime the iterates\ngenerated by an accelerated gradient scheme exhibit a periodic behavior, where\nthe period is proportional to the square root of the local condition number of\nthe objective function. This suggests a restart technique whereby we reset the\nmomentum whenever we observe periodic behavior. We provide analysis to show\nthat in many cases adaptively restarting allows us to recover the optimal rate\nof convergence with no prior knowledge of function parameters. \n\n"}
{"id": "1204.4313", "contents": "Title: Containment problems for polytopes and spectrahedra Abstract: We study the computational question whether a given polytope or spectrahedron\n$S_A$ (as given by the positive semidefiniteness region of a linear matrix\npencil $A(x)$) is contained in another one $S_B$.\n  First we classify the computational complexity, extending results on the\npolytope/polytope-case by Gritzmann and Klee to the\npolytope/spectrahedron-case. For various restricted containment problems,\nNP-hardness is shown.\n  We then study in detail semidefinite conditions to certify containment,\nbuilding upon work by Ben-Tal, Nemirovski and Helton, Klep, McCullough. In\nparticular, we discuss variations of a sufficient semidefinite condition to\ncertify containment of a spectrahedron in a spectrahedron. It is shown that\nthese sufficient conditions even provide exact semidefinite characterizations\nfor containment in several important cases, including containment of a\nspectrahedron in a polyhedron. Moreover, in the case of bounded $S_A$ the\ncriteria will always succeed in certifying containment of some scaled\nspectrahedron $\\nu S_A$ in $S_B$. \n\n"}
{"id": "1204.6624", "contents": "Title: Theorems about Ergodicity and Class-Ergodicity of Chains with\n  Applications in Known Consensus Models Abstract: In a multi-agent system, unconditional (multiple) consensus is the property\nof reaching to (multiple) consensus irrespective of the instant and values at\nwhich states are initialized. For linear algorithms, occurrence of\nunconditional (multiple) consensus turns out to be equivalent to (class-)\nergodicity of the transition chain (A_n). For a wide class of chains, chains\nwith so-called balanced asymmetry property, necessary and sufficient conditions\nfor ergodicity and class-ergodicity are derived. The results are employed to\nanalyze the limiting behavior of agents' states in the JLM model, the Krause\nmodel, and the Cucker-Smale model. In particular, unconditional single or\nmultiple consensus occurs in all three models. Moreover, a necessary and\nsufficient condition for unconditional consensus in the JLM model and a\nsufficient condition for consensus in the Cucker-Smale model are obtained. \n\n"}
{"id": "1205.1482", "contents": "Title: Risk estimation for matrix recovery with spectral regularization Abstract: In this paper, we develop an approach to recursively estimate the quadratic\nrisk for matrix recovery problems regularized with spectral functions. Toward\nthis end, in the spirit of the SURE theory, a key step is to compute the (weak)\nderivative and divergence of a solution with respect to the observations. As\nsuch a solution is not available in closed form, but rather through a proximal\nsplitting algorithm, we propose to recursively compute the divergence from the\nsequence of iterates. A second challenge that we unlocked is the computation of\nthe (weak) derivative of the proximity operator of a spectral function. To show\nthe potential applicability of our approach, we exemplify it on a matrix\ncompletion problem to objectively and automatically select the regularization\nparameter. \n\n"}
{"id": "1205.2415", "contents": "Title: Constructing Sublinear Expectations on Path Space Abstract: We provide a general construction of time-consistent sublinear expectations\non the space of continuous paths. It yields the existence of the conditional\nG-expectation of a Borel-measurable (rather than quasi-continuous) random\nvariable, a generalization of the random G-expectation, and an optional\nsampling theorem that holds without exceptional set. Our results also shed\nlight on the inherent limitations to constructing sublinear expectations\nthrough aggregation. \n\n"}
{"id": "1205.4748", "contents": "Title: Time-Consistent Mean-Variance Portfolio Selection in Discrete and\n  Continuous Time Abstract: It is well known that mean-variance portfolio selection is a\ntime-inconsistent optimal control problem in the sense that it does not satisfy\nBellman's optimality principle and therefore the usual dynamic programming\napproach fails. We develop a time- consistent formulation of this problem,\nwhich is based on a local notion of optimality called local mean-variance\nefficiency, in a general semimartingale setting. We start in discrete time,\nwhere the formulation is straightforward, and then find the natural extension\nto continuous time. This complements and generalises the formulation by Basak\nand Chabakauri (2010) and the corresponding example in Bj\\\"ork and Murgoci\n(2010), where the treatment and the notion of optimality rely on an underlying\nMarkovian framework. We justify the continuous-time formulation by showing that\nit coincides with the continuous-time limit of the discrete-time formulation.\nThe proof of this convergence is based on a global description of the locally\noptimal strategy in terms of the structure condition and the\nF\\\"ollmer-Schweizer decomposition of the mean-variance tradeoff. As a\nbyproduct, this also gives new convergence results for the F\\\"ollmer-Schweizer\ndecomposition, i.e. for locally risk minimising strategies. \n\n"}
{"id": "1205.6315", "contents": "Title: A General Stochastic Maximum Principle For Optimal Control Of Stochastic\n  Systems Driven By Multidimensional Teugel's Martingales Abstract: A necessary maximum principle is proved for optimal controls of stochastic\nsystems driven by multidimensional Teugel's martingales. The multidimensional\nTeugel's martingales are constructed by orthogonalizing the multidimensional\nL\\'{e}vy processes. The control domain need not be convex, and the control is\nallowed to enter into the terms of Teugel's martingales. \n\n"}
{"id": "1206.2119", "contents": "Title: Stochastic maximum principle for optimal control of SPDEs Abstract: In this note, we give the stochastic maximum principle for optimal control of\nstochastic PDEs in the general case (when the control domain need not be convex\nand the diffusion coefficient can contain a control variable). \n\n"}
{"id": "1206.3610", "contents": "Title: On moving averages Abstract: We show that the moving arithmetic average is closely connected to a\nGauss-Seidel type fixed point method studied by Bauschke, Wang and Wylie, and\nwhich was observed to converge only numerically. Our analysis establishes a\nrigorous proof of convergence of their algorithm in a special case; moreover,\nlimit is explicitly identified. Moving averages in Banach spaces and Kolmogorov\nmeans are also studied. Furthermore, we consider moving proximal averages and\nepi-averages of convex functions. \n\n"}
{"id": "1206.5072", "contents": "Title: Fast computation of gradient and sentitivity in 13C metabolic flux\n  analysis instationary experiments using the adjoint method Abstract: Metabolic flux analysis using 13C labeled substrates is an important tool for\nmetabolic engineering. Although it has now been evolving for more than ten\nyears, metabolic flux analysis has still not reached the limits of its\napplication. First and foremost, there is only one reference software for the\nanalysis and identification of metabolic fluxes using stationnary carbon\nlabeling experiments, which is closed-source. Moreover, this software lacks\nconnections with the new standards of systems biology community, for example\nthe Systems Biology Markup Language, which allows to describe arbitrary large\nmetabolic networks. The first part of this paper, after recalling all the\nmathematics involved in the mathematical problem of flux identification in the\ncase of multiple experiments (state equations, regularized cost function,\nexplicit computation of the gradient) concentrates on the problem of specific\nautomatic generation of scripts (Matlab or Scilab) implementing the numerical\nresolution. To this purpose, we will describe the architecture of the software\nchain implementing the transformation from the XML file describing the\nmetaboling network and the carbon transitions to the final collection of\nscripts computing, for example, the exact gradient of the regularized\nleast-squares cost function and the output sensitivities. In the unstationnary\ncase the adjoint state method is used to speed up computations. \n\n"}
{"id": "1207.0048", "contents": "Title: Economic Dispatch in Unbalanced Distribution Networks via Semidefinite\n  Relaxation Abstract: The economic dispatch problem is considered for unbalanced three-phase power\ndistribution networks entailing both non-deferrable and elastic loads, and\ndistributed generation (DG) units. The objective is to minimize the costs of\npower drawn from the main grid and supplied by the DG units over a given time\nhorizon, while meeting the overall load demand and effecting voltage\nregulation. Similar to optimal power flow counterparts for balanced systems,\nthe resultant optimization problem is nonconvex. Nevertheless, a semidefinite\nprogramming (SDP) relaxation technique is advocated to obtain a (relaxed)\nconvex problem solvable in polynomial-time complexity. To promote a reliable\nyet efficient feeder operation, SDP-compliant constraints on line and neutral\ncurrent magnitudes are accommodated in the optimization formulated, along with\nconstraints on the power factor at the substation and at nodes equipped with\ncapacitor banks. Tests on the IEEE 13-node radial feeder demonstrate the\nability of the proposed method to attain the globally optimal solution of the\noriginal nonconvex problem. \n\n"}
{"id": "1207.2848", "contents": "Title: Pricing of Fluctuations in Electricity Markets Abstract: In an electric power system, demand fluctuations may result in significant\nancillary cost to suppliers. Furthermore, in the near future, deep penetration\nof volatile renewable electricity generation is expected to exacerbate the\nvariability of demand on conventional thermal generating units. We address this\nissue by explicitly modeling the ancillary cost associated with demand\nvariability. We argue that a time-varying price equal to the suppliers'\ninstantaneous marginal cost may not achieve social optimality, and that\nconsumer demand fluctuations should be properly priced. We propose a dynamic\npricing mechanism that explicitly encourages consumers to adapt their\nconsumption so as to offset the variability of demand on conventional units.\nThrough a dynamic game-theoretic formulation, we show that (under suitable\nconvexity assumptions) the proposed pricing mechanism achieves social\noptimality asymptotically, as the number of consumers increases to infinity.\nNumerical results demonstrate that compared with marginal cost pricing, the\nproposed mechanism creates a stronger incentive for consumers to shift their\npeak load, and therefore has the potential to reduce the need for long-term\ninvestment in peaking plants. \n\n"}
{"id": "1208.0441", "contents": "Title: Smooth Hyperbolicity Cones are Spectrahedral Shadows Abstract: Hyperbolicity cones are convex algebraic cones arising from hyperbolic\npolynomials. A well-understood subclass of hyperbolicity cones is that of\nspectrahedral cones and it is conjectured that every hyperbolicity cone is\nspectrahedral. In this paper we prove a weaker version of this conjecture by\nshowing that every smooth hyperbolicity cone is the linear projection of a\nspectrahedral cone, that is, a spectrahedral shadow. \n\n"}
{"id": "1208.2363", "contents": "Title: Existence of Minimizers for Fractional Variational Problems Containing\n  Caputo Derivatives Abstract: We study dynamic minimization problems of the calculus of variations with\nLagrangian functionals containing Riemann-Liouville fractional integrals,\nclassical and Caputo fractional derivatives. Under assumptions of regularity,\ncoercivity and convexity, we prove existence of solutions. \n\n"}
{"id": "1208.2503", "contents": "Title: Distributed Pareto Optimization via Diffusion Strategies Abstract: We consider solving multi-objective optimization problems in a distributed\nmanner by a network of cooperating and learning agents. The problem is\nequivalent to optimizing a global cost that is the sum of individual\ncomponents. The optimizers of the individual components do not necessarily\ncoincide and the network therefore needs to seek Pareto optimal solutions. We\ndevelop a distributed solution that relies on a general class of adaptive\ndiffusion strategies. We show how the diffusion process can be represented as\nthe cascade composition of three operators: two combination operators and a\ngradient descent operator. Using the Banach fixed-point theorem, we establish\nthe existence of a unique fixed point for the composite cascade. We then study\nhow close each agent converges towards this fixed point, and also examine how\nclose the Pareto solution is to the fixed point. We perform a detailed\nmean-square error analysis and establish that all agents are able to converge\nto the same Pareto optimal solution within a sufficiently small\nmean-square-error (MSE) bound even for constant step-sizes. We illustrate one\napplication of the theory to collaborative decision making in finance by a\nnetwork of agents. \n\n"}
{"id": "1209.3600", "contents": "Title: Output Feedback H_2 Model Matching for Decentralized Systems with Delays Abstract: This paper gives a new solution to the output feedback H_2 model matching\nproblem for a large class of delayed information sharing patterns. Existing\nmethods for such problems typically reduce the decentralized problem to a\ncentralized problem of higher state dimension. In contrast, the controller\ngiven in this paper is constructed from the solutions to the centralized\ncontrol and estimation Riccati equations for the original system. The problem\nis solved by decomposing the controller into two components. One is\ncentralized, but delayed, while the other is decentralized with finite impulse\nresponse (FIR). It is then shown that the optimal controller can be constructed\nthrough a combination of centralized spectral factorization and quadratic\nprogramming. \n\n"}
{"id": "1209.4433", "contents": "Title: Transverse Contraction Criteria for Existence, Stability, and Robustness\n  of a Limit Cycle Abstract: This paper derives a differential contraction condition for the existence of\nan orbitally-stable limit cycle in an autonomous system. This transverse\ncontraction condition can be represented as a pointwise linear matrix\ninequality (LMI), thus allowing convex optimization tools such as\nsum-of-squares programming to be used to search for certificates of the\nexistence of a stable limit cycle. Many desirable properties of contracting\ndynamics are extended to this context, including preservation of contraction\nunder a broad class of interconnections. In addition, by introducing the\nconcepts of differential dissipativity and transverse differential\ndissipativity, contraction and transverse contraction can be established for\nlarge scale systems via LMI conditions on component subsystems. \n\n"}
{"id": "1209.4609", "contents": "Title: On the Optimal Control of Impulsive Hybrid Systems On Riemannian\n  Manifolds Abstract: This paper provides a geometrical derivation of the Hybrid Minimum Principle\n(HMP) for autonomous impulsive hybrid systems on Riemannian manifolds, i.e.\nsystems where the manifold valued component of the hybrid state trajectory may\nhave a jump discontinuity when the discrete component changes value. The\nanalysis is expressed in terms of extremal trajectories on the cotangent bundle\nof the manifold state space. In the case of autonomous hybrid systems,\nswitching manifolds are defined as smooth embedded submanifolds of the state\nmanifold and the jump function is defined as a smooth map on the switching\nmanifold. The HMP results are obtained in the case of time invariant switching\nmanifolds and state jumps on Riemannian manifolds. \n\n"}
{"id": "1209.6601", "contents": "Title: Optimal Stopping under Nonlinear Expectation Abstract: Let $X$ be a bounded c\\`adl\\`ag process with positive jumps defined on the\ncanonical space of continuous paths. We consider the problem of optimal\nstopping the process $X$ under a nonlinear expectation operator $\\cE$ defined\nas the supremum of expectations over a weakly compact family of nondominated\nmeasures. We introduce the corresponding nonlinear Snell envelope. Our main\nobjective is to extend the Snell envelope characterization to the present\ncontext. Namely, we prove that the nonlinear Snell envelope is an\n$\\cE-$supermartingale, and an $\\cE-$martingale up to its first hitting time of\nthe obstacle $X$. This result is obtained under an additional uniform\ncontinuity property of $X$. We also extend the result in the context of a\nrandom horizon optimal stopping problem.\n  This result is crucial for the newly developed theory of viscosity solutions\nof path-dependent PDEs as introduced in Ekren et al., in the semilinear case,\nand extended to the fully nonlinear case in the accompanying papers (Ekren,\nTouzi, and Zhang, parts I and II). \n\n"}
{"id": "1210.0888", "contents": "Title: Control Design along Trajectories with Sums of Squares Programming Abstract: Motivated by the need for formal guarantees on the stability and safety of\ncontrollers for challenging robot control tasks, we present a control design\nprocedure that explicitly seeks to maximize the size of an invariant \"funnel\"\nthat leads to a predefined goal set. Our certificates of invariance are given\nin terms of sums of squares proofs of a set of appropriately defined Lyapunov\ninequalities. These certificates, together with our proposed polynomial\ncontrollers, can be efficiently obtained via semidefinite optimization. Our\napproach can handle time-varying dynamics resulting from tracking a given\ntrajectory, input saturations (e.g. torque limits), and can be extended to deal\nwith uncertainty in the dynamics and state. The resulting controllers can be\nused by space-filling feedback motion planning algorithms to fill up the space\nwith significantly fewer trajectories. We demonstrate our approach on a\nseverely torque limited underactuated double pendulum (Acrobot) and provide\nextensive simulation and hardware validation. \n\n"}
{"id": "1210.4235", "contents": "Title: Node Classification in Networks of Stochastic Evidence Accumulators Abstract: This paper considers a network of stochastic evidence accumulators, each\nrepresented by a drift-diffusion model accruing evidence towards a decision in\ncontinuous time by observing a noisy signal and by exchanging information with\nother units according to a fixed communication graph. We bring into focus the\nrelationship between the location of each unit in the communication graph and\nits certainty as measured by the inverse of the variance of its state. We show\nthat node classification according to degree distributions or geodesic\ndistances cannot faithfully capture node ranking in terms of certainty.\nInstead, all possible paths connecting each unit with the rest in the network\nmust be incorporated. We make this precise by proving that node classification\naccording to information centrality provides a rank ordering with respect to\nnode certainty, thereby affording a direct interpretation of the certainty\nlevel of each unit in terms of the structural properties of the underlying\ncommunication graph. \n\n"}
{"id": "1210.4765", "contents": "Title: A Lagrangian relaxation view of linear and semidefinite hierarchies Abstract: We consider the general polynomial optimization problem $P: f^*=\\min\n\\{f(x)\\,:\\,x\\in K\\}$ where $K$ is a compact basic semi-algebraic set. We first\nshow that the standard Lagrangian relaxation yields a lower bound as close as\ndesired to the global optimum $f^*$, provided that it is applied to a problem\n$\\tilde{P}$ equivalent to $P$, in which sufficiently many redundant constraints\n(products of the initial ones) are added to the initial description of $P$.\nNext we show that the standard hierarchy of LP-relaxations of $P$ (in the\nspirit of Sherali-Adams' RLT) can be interpreted as a brute force\nsimplification of the above Lagrangian relaxation in which a nonnegative\npolynomial (with coefficients to be determined) is replaced with a constant\npolynomial equal to zero. Inspired by this interpretation, we provide a\nsystematic improvement of the LP-hierarchy by doing a much less brutal\nsimplification which results into a parametrized hierarchy of semidefinite\nprograms (and not linear programs any more). For each semidefinite program in\nthe parametrized hierarchy, the semidefinite constraint has a fixed size\n$O(n^k)$, independently of the rank in the hierarchy, in contrast with the\nstandard hierarchy of semidefinite relaxations. The parameter $k$ is to be\ndecided by the user. When applied to a non trivial class of convex problems,\nthe first relaxation of the parametrized hierarchy is exact, in contrast with\nthe LP-hierarchy where convergence cannot be finite. When applied to 0/1\nprograms it is at least as good as the first one in the hierarchy of\nsemidefinite relaxations. However obstructions to exactness still exist and are\nbriefly analyzed. Finally, the standard semidefinite hierarchy can also be\nviewed as a simplification of an extended Lagrangian relaxation, but different\nin spirit as sums of squares (and not scalars) multipliers are allowed. \n\n"}
{"id": "1210.6280", "contents": "Title: On the convergence of the affine hull of the Chv\\'atal-Gomory closures Abstract: Given an integral polyhedron P and a rational polyhedron Q living in the same\nn-dimensional space and containing the same integer points as P, we investigate\nhow many iterations of the Chv\\'atal-Gomory closure operator have to be\nperformed on Q to obtain a polyhedron contained in the affine hull of P. We\nshow that if P contains an integer point in its relative interior, then such a\nnumber of iterations can be bounded by a function depending only on n. On the\nother hand, we prove that if P is not full-dimensional and does not contain any\ninteger point in its relative interior, then no finite bound on the number of\niterations exists. \n\n"}
{"id": "1210.6853", "contents": "Title: On solving large scale polynomial convex problems by randomized\n  first-order algorithms Abstract: One of the most attractive recent approaches to processing well-structured\nlarge-scale convex optimization problems is based on smooth convex-concave\nsaddle point reformu-lation of the problem of interest and solving the\nresulting problem by a fast First Order saddle point method utilizing\nsmoothness of the saddle point cost function. In this paper, we demonstrate\nthat when the saddle point cost function is polynomial, the precise gra-dients\nof the cost function required by deterministic First Order saddle point\nalgorithms and becoming prohibitively computationally expensive in the\nextremely large-scale case, can be replaced with incomparably cheaper\ncomputationally unbiased random estimates of the gradients. We show that for\nlarge-scale problems with favourable geometry, this randomization accelerates,\nprogressively as the sizes of the problem grow, the solution process. This\nextends significantly previous results on acceleration by randomization, which,\nto the best of our knowledge, dealt solely with bilinear saddle point problems.\nWe illustrate our theoretical findings by instructive and encouraging numerical\nexperiments. \n\n"}
{"id": "1210.7221", "contents": "Title: The value of Markov Chain Games with incomplete information on both\n  sides Abstract: We consider zero-sum repeated games with incomplete information on both\nsides, where the states privately observed by each player follow independent\nMarkov chains. It generalizes the model, introduced by Aumann and Maschler in\nthe sixties and solved by Mertens and Zamir in the seventies, where the private\nstates of the players were fixed. It also includes the model introduced in\nRenault \\cite{R2006}, of Markov chain repeated games with lack of information\non one side, where only one player privately observes the sequence of states.\nWe prove here that the limit value exists, and we obtain a characterization via\nthe Mertens-Zamir system, where the \"non revealing value function\" plugged in\nthe system is now defined as the limit value of an auxiliary \"non revealing\"\ndynamic game. This non revealing game is defined by restricting the players not\nto reveal any information on the {\\it limit behavior} of their own Markov\nchain, as in Renault 2006. There are two key technical difficulties in the\nproof: 1) proving regularity, in the sense of equicontinuity, of the $T$-stage\nnon revealing value functions, and 2) constructing strategies by blocks in\norder to link the values of the non revealing games with the original values. \n\n"}
{"id": "1210.8220", "contents": "Title: Closed-loop Reference Models for Output-Feedback Adaptive Systems Abstract: Closed-loop reference models have recently been proposed for states\naccessible adaptive systems. They have been shown to have improved transient\nresponse over their open loop counter parts. The results in the states\naccessible case are extended to single input single output plants of arbitrary\nrelative degree. \n\n"}
{"id": "1211.0412", "contents": "Title: On an integral equation for the free-boundary of stochastic,\n  irreversible investment problems Abstract: In this paper, we derive a new handy integral equation for the free-boundary\nof infinite time horizon, continuous time, stochastic, irreversible investment\nproblems with uncertainty modeled as a one-dimensional, regular diffusion $X$.\nThe new integral equation allows to explicitly find the free-boundary\n$b(\\cdot)$ in some so far unsolved cases, as when the operating profit function\nis not multiplicatively separable and $X$ is a three-dimensional Bessel process\nor a CEV process. Our result follows from purely probabilistic arguments.\nIndeed, we first show that $b(X(t))=l^*(t)$, with $l^*$ the unique optional\nsolution of a representation problem in the spirit of Bank-El Karoui [Ann.\nProbab. 32 (2004) 1030-1067]; then, thanks to such an identification and the\nfact that $l^*$ uniquely solves a backward stochastic equation, we find the\nintegral problem for the free-boundary. \n\n"}
{"id": "1211.1550", "contents": "Title: A Riemannian geometry for low-rank matrix completion Abstract: We propose a new Riemannian geometry for fixed-rank matrices that is\nspecifically tailored to the low-rank matrix completion problem. Exploiting the\ndegree of freedom of a quotient space, we tune the metric on our search space\nto the particular least square cost function. At one level, it illustrates in a\nnovel way how to exploit the versatile framework of optimization on quotient\nmanifold. At another level, our algorithm can be considered as an improved\nversion of LMaFit, the state-of-the-art Gauss-Seidel algorithm. We develop\nnecessary tools needed to perform both first-order and second-order\noptimization. In particular, we propose gradient descent schemes (steepest\ndescent and conjugate gradient) and trust-region algorithms. We also show that,\nthanks to the simplicity of the cost function, it is numerically cheap to\nperform an exact linesearch given a search direction, which makes our\nalgorithms competitive with the state-of-the-art on standard low-rank matrix\ncompletion instances. \n\n"}
{"id": "1211.2245", "contents": "Title: Composite Strategy for Multicriteria Ranking/Sorting (methodological\n  issues, examples) Abstract: The paper addresses the modular design of composite solving strategies for\nmulticriteria ranking (sorting). Here a 'scale of creativity' that is close to\ncreative levels proposed by Altshuller is used as the reference viewpoint: (i)\na basic object, (ii) a selected object, (iii) a modified object, and (iv) a\ndesigned object (e.g., composition of object components). These levels maybe\nused in various parts of decision support systems (DSS) (e.g., information,\noperations, user). The paper focuses on the more creative above-mentioned level\n(i.e., composition or combinatorial synthesis) for the operational part (i.e.,\ncomposite solving strategy). This is important for a search/exploration mode of\ndecision making process with usage of various procedures and techniques and\nanalysis/integration of obtained results. The paper describes methodological\nissues of decision technology and synthesis of composite strategy for\nmulticriteria ranking. The synthesis of composite strategies is based on\n'hierarchical morphological multicriteria design' (HMMD) which is based on\nselection and combination of design alternatives (DAs) (here: local procedures\nor techniques) while taking into account their quality and quality of their\ninterconnections (IC). A new version of HMMD with interval multiset estimates\nfor DAs is used. The operational environment of DSS COMBI for multicriteria\nranking, consisting of a morphology of local procedures or techniques (as\ndesign alternatives DAs), is examined as a basic one. \n\n"}
{"id": "1211.2766", "contents": "Title: Remarks on the semi-classical Hohenberg-Kohn functional Abstract: In this note, we study an optimal transportation problem arising in density\nfunctional theory. We derive an upper bound on the semi-classical\nHohenberg-Kohn functional derived by Cotar, Friesecke and Kl\\\"{u}ppelberg\n(2012) which can be computed in a straightforward way for a given single\nparticle density. This complements a lower bound derived by the aforementioned\nauthors. We also show that for radially symmetric densities the optimal\ntransportation problem arising in the semi-classical Hohenberg-Kohn functional\ncan be reduced to a 1-dimensional problem. This yields a simple new proof of\nthe explicit solution to the optimal transport problem for two particles found\nby Cotar, Friesecke and Kl\\\"{u}ppelberg (2012). For more particles, we use our\nresult to demonstrate two new qualitative facts: first, that the solution can\nconcentrate on higher dimensional submanifolds and second that the solution can\nbe non-unique, even with an additional symmetry constraint imposed. \n\n"}
{"id": "1211.3634", "contents": "Title: On a Class of Boundary Control Problems Abstract: We discuss a class of linear control problems in a Hilbert space setting,\nwhich covers diverse systems such as hyperbolic and parabolic equations with\nboundary control and boundary observation even including memory terms. We\nintroduce abstract boundary data spaces in which the control and observation\nequations can be formulated without strong geometric constraints on the\nunderlying domain. The results are applied to a boundary control problem for\nthe equations of visco-elasticity. \n\n"}
{"id": "1211.3831", "contents": "Title: Objective Improvement in Information-Geometric Optimization Abstract: Information-Geometric Optimization (IGO) is a unified framework of stochastic\nalgorithms for optimization problems. Given a family of probability\ndistributions, IGO turns the original optimization problem into a new\nmaximization problem on the parameter space of the probability distributions.\nIGO updates the parameter of the probability distribution along the natural\ngradient, taken with respect to the Fisher metric on the parameter manifold,\naiming at maximizing an adaptive transform of the objective function. IGO\nrecovers several known algorithms as particular instances: for the family of\nBernoulli distributions IGO recovers PBIL, for the family of Gaussian\ndistributions the pure rank-mu CMA-ES update is recovered, and for exponential\nfamilies in expectation parametrization the cross-entropy/ML method is\nrecovered. This article provides a theoretical justification for the IGO\nframework, by proving that any step size not greater than 1 guarantees monotone\nimprovement over the course of optimization, in terms of q-quantile values of\nthe objective function f. The range of admissible step sizes is independent of\nf and its domain. We extend the result to cover the case of different step\nsizes for blocks of the parameters in the IGO algorithm. Moreover, we prove\nthat expected fitness improves over time when fitness-proportional selection is\napplied, in which case the RPP algorithm is recovered. \n\n"}
{"id": "1211.4368", "contents": "Title: The Delta-nabla Calculus of Variations for Composition Functionals on\n  Time Scales Abstract: We develop the calculus of variations on time scales for a functional that is\nthe composition of a certain scalar function with the delta and nabla integrals\nof a vector valued field. Euler-Lagrange equations, transversality conditions,\nand necessary optimality conditions for isoperimetric problems, on an arbitrary\ntime scale, are proved. Interesting corollaries and examples are presented. \n\n"}
{"id": "1211.4391", "contents": "Title: A Non-Differentiable Quantum Variational Embedding in Presence of Time\n  Delays Abstract: We develop Cresson's non-differentiable embedding to quantum problems of the\ncalculus of variations and optimal control with time delay. Main results show\nthat the dynamics of non-differentiable Lagrangian and Hamiltonian systems with\ntime delays can be determined, in a coherent way, by the least-action\nprinciple. \n\n"}
{"id": "1211.4549", "contents": "Title: Design of Charge-Balanced Time-Optimal Stimuli for Spiking Neuron\n  Oscillators Abstract: In this paper, we investigate the fundamental limits on how the inter- spike\ntime of a neuron oscillator can be perturbed by the application of a bounded\nexternal control input (a current stimulus) with zero net electric charge\naccumulation. We use phase models to study the dynamics of neurons and derive\ncharge-balanced controls that achieve the minimum and maximum inter-spike times\nfor a given bound on the control amplitude. Our derivation is valid for any\narbitrary shape of the phase response curve and for any value of the given\ncontrol amplitude bound. In addition, we characterize the change in the\nstructures of the charge-balanced time-optimal controls with the allowable\ncontrol amplitude. We demonstrate the applicability of the derived optimal\ncontrol laws by applying them to mathematically ideal and experimentally\nobserved neuron phase models, including the widely-studied Hodgkin-Huxley phase\nmodel, and by verifying them with the corresponding original full state-space\nmodels. This work addresses a fundamental problem in the field of neural\ncontrol and provides a theoretical investigation to the optimal control of\noscillatory systems. \n\n"}
{"id": "1211.4598", "contents": "Title: How Non-Arbitrage, Viability and Num\\'eraire Portfolio are Related Abstract: This paper proposes two approaches that quantify the exact relationship among\nthe viability, the absence of arbitrage, and/or the existence of the\nnum\\'eraire portfolio under minimal assumptions and for general continuous-time\nmarket models. Precisely, our first and principal contribution proves the\nequivalence among the No-Unbounded-Profit-with-Bounded-Risk condition (NUPBR\nhereafter), the existence of the num\\'eraire portfolio, and the existence of\nthe optimal portfolio under an equivalent probability measure for any \"nice\"\nutility and positive initial capital. Herein, a 'nice\" utility is any smooth\nvon Neumann-Morgenstern utility satisfying Inada's conditions and the\nelasticity assumptions of Kramkov and Schachermayer. Furthermore, the\nequivalent probability measure ---under which the utility maximization problems\nhave solutions--- can be chosen as close to the real-world probability measure\nas we want (but might not be equal). Without changing the underlying\nprobability measure and under mild assumptions, our second contribution proves\nthat the NUPBR is equivalent to the \"{\\it local}\" existence of the optimal\nportfolio. This constitutes an alternative to the first contribution, if one\ninsists on working under the real-world probability. These two contributions\nlead naturally to new types of viability that we call weak and local\nviabilities. \n\n"}
{"id": "1211.7084", "contents": "Title: On dynamics of Lagrangian trajectories for Hamilton-Jacobi equations Abstract: Characteristic curves of a Hamilton-Jacobi equation can be seen as action\nminimizing trajectories of fluid particles. However this description is valid\nonly for smooth solutions. For nonsmooth \"viscosity\" solutions, which give rise\nto discontinuous velocity fields, this picture holds only up to the moment when\ntrajectories hit a shock and cease to minimize the Lagrangian action. In this\npaper we discuss two physically meaningful regularisation procedures, one\ncorresponding to vanishing viscosity and another to weak noise limit. We show\nthat for any convex Hamiltonian, a viscous regularization allows to construct a\nnonsmooth flow that extends particle trajectories and determines dynamics\ninside the shock manifolds. This flow consists of integral curves of a\nparticular \"effective\" velocity field, which is uniquely defined everywhere in\nthe flow domain and is discontinuous on shock manifolds. The effective velocity\nfield arising in the weak noise limit is generally non-unique and different\nfrom the viscous one, but in both cases there is a fundamental self-consistency\ncondition constraining the dynamics. \n\n"}
{"id": "1212.1862", "contents": "Title: On the response of quantum linear systems to single photon input fields Abstract: The purpose of this paper is to extend linear systems and signals theory to\ninclude single photon quantum signals. We provide detailed results describing\nhow quantum linear systems respond to multichannel single photon quantum\nsignals. In particular, we characterize the class of states (which we call {\\em\nphoton-Gaussian} states) that result when multichannel photons are input to a\nquantum linear system. We show that this class of quantum states is preserved\nby quantum linear systems. Multichannel photon-Gaussian states are defined via\nthe action of certain creation and annihilation operators on Gaussian states.\nOur results show how the output states are determined from the input states\nthrough a pair of transfer function relations. We also provide equations from\nwhich output signal intensities can be computed. Examples from quantum optics\nare provided to illustrate the results. \n\n"}
{"id": "1212.2243", "contents": "Title: On the construction of 1-dimensional MDS convolutional Goppa codes Abstract: We show that the free distance, as a function on a space parameterizing a\nfamily of convolutional codes, is a lower-semicontinuous function and that,\ntherefore, the property of being Maximum Distance Separable (MDS) is an open\ncondition. For a class of convolutional codes, an algorithm is offered to\ncompute the free distance. The behaviour of the free distance by enlargements\nof the alphabet and by increasing the length is also studied. As an\napplication, the algebraic equations characterizing the subfamily of MDS codes\nis explicitly computed for families of 1-dimensional convolutional Goppa codes\n(CGC). \n\n"}
{"id": "1212.3621", "contents": "Title: Local Irreducibility of Tail-Biting Trellises Abstract: This paper investigates tail-biting trellis realizations for linear block\ncodes. Intrinsic trellis properties are used to characterize irreducibility on\ngiven intervals of the time axis. It proves beneficial to always consider the\ntrellis and its dual simultaneously. A major role is played by trellis\nproperties that amount to observability and controllability for fragments of\nthe trellis of various lengths. For fragments of length less than the minimum\nspan length of the code it is shown that fragment observability and fragment\ncontrollability are equivalent to irreducibility. For reducible trellises, a\nconstructive reduction procedure is presented. The considerations also lead to\na characterization for when the dual of a trellis allows a product\nfactorization into elementary (\"atomic\") trellises. \n\n"}
{"id": "1212.3721", "contents": "Title: Approximate continuous-discrete filters for the estimation of diffusion\n  processes from partial and noisy observations Abstract: In this paper, an alternative approximation to the innovation method is\nintroduced for the parameter estimation of diffusion processes from partial and\nnoisy observations. This is based on a convergent approximation to the first\ntwo conditional moments of the innovation process through approximate\ncontinuous-discrete filters of minimum variance. It is shown that, for finite\nsamples, the resulting approximate estimators converge to the exact one when\nthe error of the approximate filters decreases. For an increasing number of\nobservations, the estimators are asymptotically normal distributed and their\nbias decreases when the above mentioned error does it. A simulation study is\nprovided to illustrate the performance of the new estimators. The results show\nthat, with respect to the conventional approximate estimators, the new ones\nsignificantly enhance the parameter estimation of the test equations. The\nproposed estimators are intended for the recurrent practical situation where a\nnonlinear stochastic system should be identified from a reduced number of\npartial and noisy observations distant in time. \n\n"}
{"id": "1212.4415", "contents": "Title: Lattice-like operations and isotone projection sets Abstract: By using some lattice-like operations which constitute extensions of ones\nintroduced by M. S. Gowda, R. Sznajder and J. Tao for self-dual cones, a new\nperspective is gained on the subject of isotonicity of the metric projection\nonto the closed convex sets. The results of this paper are wide range\ngeneralizations of some results of the authors obtained for self-dual cones.\nThe aim of the subsequent investigations is to put into evidence some closed\nconvex sets for which the metric projection is isotonic with respect the order\nrelation which give rise to the above mentioned lattice-like operations. The\ntopic is related to variational inequalities where the isotonicity of the\nmetric projection is an important technical tool. For Euclidean sublattices\nthis approach was considered by G. Isac and respectively by H. Nishimura and E.\nA. Ok. \n\n"}
{"id": "1212.6069", "contents": "Title: Evaluation of Lyapunov exponent in generalized linear dynamical models\n  of queueing networks Abstract: The problem of evaluation of Lyapunov exponent in queueing network analysis\nis considered based on models and methods of idempotent algebra. General\nexistence conditions for Lyapunov exponent to exist in generalized linear\nstochastic dynamic systems are given, and examples of evaluation of the\nexponent for systems with matrices of particular types are presented. A method\nwhich allow one to get the exponent is proposed based on some appropriate\ndecomposition of the system matrix. A general approach to modeling of a wide\nclass of queueing networks is taken to provide for models in the form of\nstochastic dynamic systems. It is shown how to find the mean service cycle time\nfor the networks through the evaluation of Lyapunov exponent for their\nassociated dynamic systems. As an illustration, the mean service time is\nevaluated for some systems including open and closed tandem queues with finite\nand infinite buffers, fork-join networks, and systems with round-robin routing. \n\n"}
{"id": "1301.0154", "contents": "Title: Completely monotonic degree of a function involving the tri- and\n  tetra-gamma functions Abstract: Let $\\psi(x)$ be the di-gamma function, the logarithmic derivative of the\nclassical Euler's gamma function $\\Gamma(x)$. In the paper, the author shows\nthat the completely monotonic degree of the function $[\\psi'(x)]^2+\\psi''(x)$\nis $4$, surveys the history and motivation of the topic, supplies a proof for\nthe claim that a function $f(x)$ is strongly completely monotonic if and only\nif the function $xf(x)$ is completely monotonic, conjectures the completely\nmonotonic degree of a function involving $[\\psi'(x)]^2+\\psi''(x)$, presents the\nlogarithmic concavity and monotonicity of an elementary function, and poses an\nopen problem on convolution of logarithmically concave functions. \n\n"}
{"id": "1301.2783", "contents": "Title: On the accuracy of the approximation of the complex exponent by the\n  first terms of its Taylor expansion with applications Abstract: A new bound for the remainder term in the Taylor expansion of the complex\nexponent $e^{ix}$, $x\\in\\R$, is proved yielding precise moment-type estimates\nof the accuracy of the approximation of the characteristic function (the\nFourier--Stieltjes transform) of a probability distribution by the first terms\nof its Taylor expansion. Moreover, a precise upper bound for the third moment\nof a probability distribution in terms of the absolute third moment is\nestablished which sharpens Jensen's inequality. Based on these results, new\nimproved bounds for characteristic functions and their derivatives are obtained\nthat are {\\it uniform} in the class of distributions with fixed first three\nmoments. \n\n"}
{"id": "1301.6879", "contents": "Title: A Unified Software Framework for Empirical Gramians Abstract: A common approach in model reduction is balanced truncation, which is based\non gramian matrices classifiying certain attributes of states or parameters of\na given dynamic system. Initially restricted to linear systems, the empirical\ngramians not only extended this concept to nonlinear systems, but also provide\na uniform computational method. This work introduces a unified software\nframework supplying routines for six types of empirical gramians. The gramian\ntypes will be discussed and applied in a model reduction framework for\nmultiple-input-multiple-output (MIMO) systems. \n\n"}
{"id": "1302.0134", "contents": "Title: Maximization of Non-Concave Utility Functions in Discrete-Time Financial\n  Market Models Abstract: This paper investigates the problem of maximizing expected terminal utility\nin a (generically incomplete) discrete-time financial market model with finite\ntime horizon. In contrast to the standard setting, a possibly non-concave\nutility function $U$ is considered, with domain of definition $\\mathbb{R}$.\nSimple conditions are presented which guarantee the existence of an optimal\nstrategy for the problem. In particular, the asymptotic elasticity of $U$ plays\na decisive role: existence can be shown when it is strictly greater at\n$-\\infty$ than at $+\\infty$. \n\n"}
{"id": "1302.0221", "contents": "Title: Balanced truncation for linear switched systems Abstract: In this paper, we present a theoretical analysis of the model reduction\nalgorithm for linear switched systems. This algorithm is a reminiscence of the\nbalanced truncation method for linear parameter varying systems. Specifically\nin this paper, we provide a bound on the approximation error in L2 norm for\ncontinuous-time and l2 norm for discrete-time linear switched systems. We\nprovide a system theoretic interpretation of grammians and their singular\nvalues. Furthermore, we show that the performance of bal- anced truncation\ndepends only on the input-output map and not on the choice of the state-space\nrepresentation. For a class of stable discrete-time linear switched systems (so\ncalled strongly stable systems), we define nice controllability and nice\nobservability grammians, which are genuinely related to reachability and\ncontrollability of switched systems. In addition, we show that quadratic\nstability and LMI estimates of the L2 and l2 gains depend only on the\ninput-output map. \n\n"}
{"id": "1302.3513", "contents": "Title: Pontryagin Maximum Principle for finite dimensional nonlinear optimal\n  control problems on time scales Abstract: In this article we derive a strong version of the Pontryagin Maximum\nPrinciple for general nonlinear optimal control problems on time scales in\nfinite dimension. The final time can be fixed or not, and in the case of\ngeneral boundary conditions we derive the corresponding transversality\nconditions. Our proof is based on Ekeland's variational principle. Our\nstatement and comments clearly show the distinction between right-dense points\nand right-scattered points. At right-dense points a maximization condition of\nthe Hamiltonian is derived, similarly to the continuous-time case. At\nright-scattered points a weaker condition is derived, in terms of so-called\nstable $\\Omega$-dense directions. We do not make any specific restrictive\nassumption on the dynamics or on the set $\\Omega$ of control constraints. Our\nstatement encompasses the classical continuous-time and discrete-time versions\nof the Pontryagin Maximum Principle, and holds on any general time scale, that\nis any closed subset of $\\R$. \n\n"}
{"id": "1303.0126", "contents": "Title: Linear PDEs and eigenvalue problems corresponding to ergodic stochastic\n  optimization problems on compact manifolds Abstract: We consider long term average or `ergodic' optimal control poblems with a\nspecial structure: Control is exerted in all directions and the control costs\nare proportional to the square of the norm of the control field with respect to\nthe metric induced by the noise. The long term stochastic dynamics on the\nmanifold will be completely characterized by the long term density $\\rho$ and\nthe long term current density $J$. As such, control problems may be\nreformulated as variational problems over $\\rho$ and $J$. We discuss several\noptimization problems: the problem in which both $\\rho$ and $J$ are varied\nfreely, the problem in which $\\rho$ is fixed and the one in which $J$ is fixed.\nThese problems lead to different kinds of operator problems: linear PDEs in the\nfirst two cases and a nonlinear PDE in the latter case. These results are\nobtained through through variational principle using infinite dimensional\nLagrange multipliers. In the case where the initial dynamics are reversible we\nobtain the result that the optimally controlled diffusion is also\nsymmetrizable. The particular case of constraining the dynamics to be\nreversible of the optimally controlled process leads to a linear eigenvalue\nproblem for the square root of the density process. \n\n"}
{"id": "1303.2314", "contents": "Title: Mini-Batch Primal and Dual Methods for SVMs Abstract: We address the issue of using mini-batches in stochastic optimization of\nSVMs. We show that the same quantity, the spectral norm of the data, controls\nthe parallelization speedup obtained for both primal stochastic subgradient\ndescent (SGD) and stochastic dual coordinate ascent (SCDA) methods and use it\nto derive novel variants of mini-batched SDCA. Our guarantees for both methods\nare expressed in terms of the original nonsmooth primal problem based on the\nhinge-loss. \n\n"}
{"id": "1303.2358", "contents": "Title: Control of a Novel Chaotic Fractional Order System Using a State\n  Feedback Technique Abstract: We consider a new fractional order chaotic system displaying an interesting\nbehavior. A necessary condition for the system to remain chaotic is derived. It\nis found that chaos exists in the system with order less than three. Using the\nRouth-Hurwitz and the Matignon stability criteria, we analyze the novel chaotic\nfractional order system and propose a control methodology that is better than\nthe nonlinear counterparts available in the literature, in the sense of\nsimplicity of implementation and analysis. A scalar control input that excites\nonly one of the states is proposed, and sufficient conditions for the\ncontroller gain to stabilize the unstable equilibrium points derived. Numerical\nsimulations confirm the theoretical analysis. \n\n"}
{"id": "1303.3598", "contents": "Title: The Hirsch conjecture holds for normal flag complexes Abstract: Using an intuition from metric geometry, we prove that any flag and normal\nsimplicial complex satisfies the non-revisiting path conjecture. As a\nconsequence, the diameter of its facet-ridge graph is smaller than the number\nof vertices minus the dimension, as in the Hirsch conjecture. This proves the\nHirsch conjecture for all flag polytopes, and more generally, for all\n(connected) flag homology manifolds. \n\n"}
{"id": "1303.5457", "contents": "Title: Explicit solution of a tropical optimization problem with application to\n  project scheduling Abstract: A new multidimensional optimization problem is considered in the tropical\nmathematics setting. The problem is to minimize a nonlinear function defined on\na finite-dimensional semimodule over an idempotent semifield and given by a\nconjugate transposition operator. A special case of the problem, which arises\nin just-in-time scheduling, serves as a motivation for the study. To solve the\ngeneral problem, we derive a sharp lower bound for the objective function and\nthen find vectors that yield the bound. Under general conditions, an explicit\nsolution is obtained in a compact vector form. This result is applied to\nprovide new solutions for scheduling problems under consideration. To\nillustrate, numerical examples are also presented. \n\n"}
{"id": "1304.0004", "contents": "Title: Linear under-determined systems with sparse solutions: Redirecting a\n  challenge? Abstract: Seminal works \\cite{CRT,DonohoUnsigned,DonohoPol} generated a massive\ninterest in studying linear under-determined systems with sparse solutions. In\nthis paper we give a short mathematical overview of what was accomplished in\nlast 10 years in a particular direction of such a studying. We then discuss\nwhat we consider were the main challenges in last 10 years and give our own\nview as to what are the main challenges that lie ahead. Through the\npresentation we arrive to a point where the following natural rhetoric question\narises: is it a time to redirect the main challenges? While we can not provide\nthe answer to such a question we hope that our small discussion will stimulate\nfurther considerations in this direction. \n\n"}
{"id": "1304.0678", "contents": "Title: Randomized Methods for Design of Uncertain Systems: Sample Complexity\n  and Sequential Algorithms Abstract: In this paper, we study randomized methods for feedback design of uncertain\nsystems. The first contribution is to derive the sample complexity of various\nconstrained control problems. In particular, we show the key role played by the\nbinomial distribution and related tail inequalities, and compute the sample\ncomplexity. This contribution significantly improves the existing results by\nreducing the number of required samples in the randomized algorithm. These\nresults are then applied to the analysis of worst-case performance and design\nwith robust optimization. The second contribution of the paper is to introduce\na general class of sequential algorithms, denoted as Sequential Probabilistic\nValidation (SPV). In these sequential algorithms, at each iteration, a\ncandidate solution is probabilistically validated, and corrected if necessary,\nto meet the required specifications. The results we derive provide the sample\ncomplexity which guarantees that the solutions obtained with SPV algorithms\nmeet some pre-specified probabilistic accuracy and confidence. The performance\nof these algorithms is illustrated and compared with other existing methods\nusing a numerical example dealing with robust system identification. \n\n"}
{"id": "1304.3246", "contents": "Title: Team Games Optimality Conditions of Distributed Stochastic Differential\n  Decision Systems with Decentralized Noisy Information Structures Abstract: We consider a team game reward, and we derive a stochastic Pontryagin's\nmaximum principle for distributed stochastic differential systems with\ndecentralized noisy information structures. Our methodology utilizes the semi\nmartingale representation theorem, variational methods, and backward stochastic\ndifferential equations. Furthermore, we derive necessary and sufficient\noptimality conditions that characterize team and person-by-person optimality of\ndecentralized strategies.\n  Finally, we apply the stochastic maximum principle to several examples from\nthe application areas of communications, filtering and control. \n\n"}
{"id": "1304.4985", "contents": "Title: Non Total-Unimodularity Neutralized Simplicial Complexes Abstract: Given a simplicial complex K with weights on its simplices and a chain on it,\nthe Optimal Homologous Chain Problem (OHCP) is to find a chain with minimal\nweight that is homologous (over the integers) to the given chain. The OHCP is\nNP-complete, but if the boundary matrix of K is totally unimodular (TU), it\nbecomes solvable in polynomial time when modeled as a linear program (LP). We\ndefine a condition on the simplicial complex called non total-unimodularity\nneutralized, or NTU neutralized, which ensures that even when the boundary\nmatrix is not TU, the OHCP LP must contain an integral optimal vertex for every\ninput chain. This condition is a property of K, and is independent of the input\nchain and the weights on the simplices. This condition is strictly weaker than\nthe boundary matrix being TU. More interestingly, the polytope of the OHCP LP\nmay not be integral under this condition. Still, an integral optimal vertex\nexists for every right-hand side, i.e., for every input chain. Hence a much\nlarger class of OHCP instances can be solved in polynomial time than previously\nconsidered possible. As a special case, we show that 2-complexes with trivial\nfirst homology group are guaranteed to be NTU neutralized. \n\n"}
{"id": "1304.5269", "contents": "Title: A Time-Scale Variational Approach to Inflation, Unemployment and Social\n  Loss Abstract: Both inflation and unemployment inflict social losses. When a tradeoff exists\nbetween the two, what would be the best combination of inflation and\nunemployment? A well known approach in economics to address this question\nconsists to write the social loss as a function of the rate of inflation $p$\nand the rate of unemployment $u$, with different weights, and then, using known\nrelations between $p$, $u$, and the expected rate of inflation $\\pi$, to\nrewrite the social loss function as a function of $\\pi$. The answer is achieved\nby applying the theory of the calculus of variations in order to find an\noptimal path $\\pi$ that minimizes the total social loss over a given time\ninterval. Economists dealing with this question use a continuous or a discrete\nvariational problem. Here we propose to use a time-scale model, unifying\navailable results in the literature. Moreover, the new formalism allow us to\nobtain new insights to the classical models when applied to real data of\ninflation and unemployment. \n\n"}
{"id": "1304.6139", "contents": "Title: Optimal Control for a Steady State Dead Oil Isotherm Problem Abstract: We study the optimal control of a steady-state dead oil isotherm problem. The\nproblem is described by a system of nonlinear partial differential equations\nresulting from the traditional modelling of oil engineering within the\nframework of mechanics of a continuous medium. Existence and regularity results\nof the optimal control are proved, as well as necessary optimality conditions. \n\n"}
{"id": "1304.7844", "contents": "Title: Seeded graph matching for correlated Erd\\H{o}s-R\\'enyi graphs Abstract: Graph matching is an important problem in machine learning and pattern\nrecognition. Herein, we present theoretical and practical results on the\nconsistency of graph matching for estimating a latent alignment function\nbetween the vertex sets of two graphs, as well as subsequent algorithmic\nimplications when the latent alignment is partially observed. In the correlated\nErd\\H{o}s-R\\'enyi graph setting, we prove that graph matching provides a\nstrongly consistent estimate of the latent alignment in the presence of even\nmodest correlation. We then investigate a tractable, restricted-focus version\nof graph matching, which is only concerned with adjacency involving vertices in\na partial observation of the latent alignment; we prove that a logarithmic\nnumber of vertices whose alignment is known is sufficient for this\nrestricted-focus version of graph matching to yield a strongly consistent\nestimate of the latent alignment of the remaining vertices. We show how\nFrank-Wolfe methodology for approximate graph matching, when there is a\npartially observed latent alignment, inherently incorporates this restricted\nfocus graph matching. Lastly, we illustrate the relationship between seeded\ngraph matching and restricted-focus graph matching by means of an illuminating\nexample from human connectomics. \n\n"}
{"id": "1305.4147", "contents": "Title: Dagstuhl Report 13082: Communication Complexity, Linear Optimization,\n  and lower bounds for the nonnegative rank of matrices Abstract: This report documents the program and the outcomes of Dagstuhl Seminar 13082\n\"Communication Complexity, Linear Optimization, and lower bounds for the\nnonnegative rank of matrices\", held in February 2013 at Dagstuhl Castle. \n\n"}
{"id": "1305.4372", "contents": "Title: Risk Limiting Dispatch with Ramping Constraints Abstract: Reliable operation in power systems is becoming more difficult as the\npenetration of random renewable resources increases. In particular, operators\nface the risk of not scheduling enough traditional generators in the times when\nrenewable energies becomes lower than expected. In this paper we study the\noptimal trade-off between system and risk, and the cost of scheduling reserve\ngenerators. We explicitly model the ramping constraints on the generators. We\nmodel the problem as a multi-period stochastic control problem, and we show the\nstructure of the optimal dispatch. We then show how to efficiently compute the\ndispatch using two methods: i) solving a surrogate chance constrained program,\nii) a MPC-type look ahead controller. Using real world data, we show the chance\nconstrained dispatch outperforms the MPC controller and is also robust to\nchanges in the probability distribution of the renewables. \n\n"}
{"id": "1305.4600", "contents": "Title: Worst-Case Results For Positive Semidefinite Rank Abstract: This paper presents various worst-case results on the positive semidefinite\n(psd) rank of a nonnegative matrix, primarily in the context of polytopes. We\nprove that the psd rank of a generic n-dimensional polytope with v vertices is\nat least (nv)^(1/4) improving on previous lower bounds. For polygons with v\nvertices, we show that psd rank cannot exceed 4ceil(v/6) which in turn shows\nthat the psd rank of a p by q matrix of rank three is at most\n4ceil(min{p,q}/6). In general, a nonnegative matrix of rank (k+1 choose 2) has\npsd rank at least k and we pose the problem of deciding whether the psd rank is\nexactly k. Using geometry and bounds on quantifier elimination, we show that\nthis decision can be made in polynomial time when k is fixed. \n\n"}
{"id": "1306.1875", "contents": "Title: Semidefinite relaxations for semi-infinite polynomial programming Abstract: This paper studies how to solve semi-infinite polynomial programming (SIPP)\nproblems by semidefinite relaxation method. We first introduce two SDP\nrelaxation methods for solving polynomial optimization problems with finitely\nmany constraints. Then we propose an exchange algorithm with SDP relaxations to\nsolve SIPP problems with compact index set. At last, we extend the proposed\nmethod to SIPP problems with noncompact index set via homogenization. Numerical\nresults show that the algorithm is efficient in practice. \n\n"}
{"id": "1306.2039", "contents": "Title: An optimal control approach to malaria prevention via\n  insecticide-treated nets Abstract: Malaria is a life threatening disease, entirely preventable and treatable,\nprovided the currently recommended interventions are properly implemented.\nThese interventions include vector control through the use of\ninsecticide-treated nets (ITNs). However, ITN possession does not necessarily\ntranslate into use. Human behavior change interventions, including information,\neducation, communication (IEC) campaigns and post-distribution hang-up\ncampaigns are strongly recommended. In this paper we consider a recent\nmathematical model for the effects of ITNs on the transmission dynamics of\nmalaria infection, which takes into account the human behavior. We introduce in\nthis model a supervision control, representing IEC campaigns for improving the\nITN usage. We propose and solve an optimal control problem where the aim is to\nminimize the number of infectious humans while keeping the cost low. Numerical\nresults are provided, which show the effectiveness of the optimal control\ninterventions. \n\n"}
{"id": "1306.3409", "contents": "Title: Constrained fractional set programs and their application in local\n  clustering and community detection Abstract: The (constrained) minimization of a ratio of set functions is a problem\nfrequently occurring in clustering and community detection. As these\noptimization problems are typically NP-hard, one uses convex or spectral\nrelaxations in practice. While these relaxations can be solved globally\noptimally, they are often too loose and thus lead to results far away from the\noptimum. In this paper we show that every constrained minimization problem of a\nratio of non-negative set functions allows a tight relaxation into an\nunconstrained continuous optimization problem. This result leads to a flexible\nframework for solving constrained problems in network analysis. While a\nglobally optimal solution for the resulting non-convex problem cannot be\nguaranteed, we outperform the loose convex or spectral relaxations by a large\nmargin on constrained local clustering problems. \n\n"}
{"id": "1306.3764", "contents": "Title: Bounding ground state energy of Hopfield models Abstract: In this paper we look at a class of random optimization problems that arise\nin the forms typically known as Hopfield models. We view two scenarios which we\nterm as the positive Hopfield form and the negative Hopfield form. For both of\nthese scenarios we define the binary optimization problems that essentially\nemulate what would typically be known as the ground state energy of these\nmodels. We then present a simple mechanism that can be used to create a set of\ntheoretical rigorous bounds for these energies. In addition to purely\ntheoretical bounds, we also present a couple of fast optimization algorithms\nthat can also be used to provide solid (albeit a bit weaker) algorithmic bounds\nfor the ground state energies. \n\n"}
{"id": "1306.5318", "contents": "Title: Curvature: a variational approach Abstract: The curvature discussed in this paper is a rather far going generalization of\nthe Riemannian sectional curvature. We define it for a wide class of optimal\ncontrol problems: a unified framework including geometric structures such as\nRiemannian, sub-Riemannian, Finsler and sub-Finsler structures; a special\nattention is paid to the sub-Riemannian (or Carnot-Caratheodory) metric spaces.\nOur construction of the curvature is direct and naive, and it is similar to the\noriginal approach of Riemann. Surprisingly, it works in a very general setting\nand, in particular, for all sub-Riemannian spaces. \n\n"}
{"id": "1307.4047", "contents": "Title: Convex relaxation for finding planted influential nodes in a social\n  network Abstract: We consider the problem of maximizing influence in a social network. We focus\non the case that the social network is a directed bipartite graph whose arcs\njoin senders to receivers. We consider both the case of deterministic networks\nand probabilistic graphical models, that is, the so-called \"cascade\" model. The\nproblem is to find the set of the $k$ most influential senders for a given\ninteger $k$. Although this problem is NP-hard, there is a polynomial-time\napproximation algorithm due to Kempe, Kleinberg and Tardos. In this work we\nconsider convex relaxation for the problem. We prove that convex optimization\ncan recover the exact optimizer in the case that the network is constructed\naccording to a generative model in which influential nodes are planted but then\nobscured with noise. We also demonstrate computationally that the convex\nrelaxation can succeed on a more realistic generative model called the \"forest\nfire\" model. \n\n"}
{"id": "1307.5703", "contents": "Title: Fourier analysis on finite groups and the Lov\\'asz theta-number of\n  Cayley graphs Abstract: We apply Fourier analysis on finite groups to obtain simplified formulations\nfor the Lov\\'asz theta-number of a Cayley graph. We put these formulations to\nuse by checking a few cases of a conjecture of Ellis, Friedgut, and Pilpel made\nin a recent article proving a version of the Erd\\H{o}s-Ko-Rado theorem for\n$k$-intersecting families of permutations. We also introduce a $q$-analog of\nthe notion of $k$-intersecting families of permutations, and we verify a few\ncases of the corresponding Erd\\H{o}s-Ko-Rado assertion by computer. \n\n"}
{"id": "1307.5942", "contents": "Title: A unified modeling approach for the static-dynamic uncertainty strategy\n  in stochastic lot-sizing Abstract: In this paper, we develop mixed integer linear programming models to compute\nnear-optimal policy parameters for the non-stationary stochastic lot sizing\nproblem under Bookbinder and Tan's static-dynamic uncertainty strategy. Our\nmodels build on piecewise linear upper and lower bounds of the first order loss\nfunction. We discuss different formulations of the stochastic lot sizing\nproblem, in which the quality of service is captured by means of backorder\npenalty costs, non-stockout probability, or fill rate constraints. These models\ncan be easily adapted to operate in settings in which unmet demand is\nbackordered or lost. The proposed approach has a number of advantages with\nrespect to existing methods in the literature: it enables seamless modelling of\ndifferent variants of the above problem, which have been previously tackled via\nad-hoc solution methods; and it produces an accurate estimation of the expected\ntotal cost, expressed in terms of upper and lower bounds. Our computational\nstudy demonstrates the effectiveness and flexibility of our models. \n\n"}
{"id": "1307.8281", "contents": "Title: Probabilistic Algorithm for Polynomial Optimization over a Real\n  Algebraic Set Abstract: Let $f, f_1, \\ldots, f_\\nV$ be polynomials with rational coefficients in the\nindeterminates $\\bfX=X_1, \\ldots, X_n$ of maximum degree $D$ and $V$ be the set\nof common complex solutions of $\\F=(f_1,\\ldots, f_\\nV)$. We give an algorithm\nwhich, up to some regularity assumptions on $\\F$, computes an exact\nrepresentation of the global infimum $f^\\star=\\inf_{x\\in V\\cap\\R^n} f\\Par{x}$,\ni.e. a univariate polynomial vanishing at $f^\\star$ and an isolating interval\nfor $f^\\star$. Furthermore, this algorithm decides whether $f^\\star$ is reached\nand if so, it returns $x^\\star\\in V\\cap\\R^n$ such that\n$f\\Par{x^\\star}=f^\\star$. This algorithm is probabilistic. It makes use of the\nnotion of polar varieties. Its complexity is essentially cubic in $\\Par{\\nV\nD}^n$ and linear in the complexity of evaluating the input. This fits within\nthe best known deterministic complexity class $D^{O(n)}$. We report on some\npractical experiments of a first implementation that is available as a Maple\npackage. It appears that it can tackle global optimization problems that were\nunreachable by previous exact algorithms and can manage instances that are hard\nto solve with purely numeric techniques. As far as we know, even under the\nextra genericity assumptions on the input, it is the first probabilistic\nalgorithm that combines practical efficiency with good control of complexity\nfor this problem. \n\n"}
{"id": "1308.6337", "contents": "Title: A dual algorithm for a class of augmented convex models Abstract: Convex optimization models find interesting applications, especially in\nsignal/image processing and compressive sensing. We study some augmented convex\nmodels, which are perturbed by strongly convex functions, and propose a dual\ngradient algorithm. The proposed algorithm includes the linearized Bregman\nalgorithm and the singular value thresholding algorithm as special cases. Based\non fundamental properties of proximal operators, we present a concise approach\nto establish the convergence of both primal and dual sequences, improving the\nresults in the existing literature. \n\n"}
{"id": "1308.6378", "contents": "Title: String-Averaging Projected Subgradient Methods for Constrained\n  Minimization Abstract: We consider constrained minimization problems and propose to replace the\nprojection onto the entire feasible region, required in the Projected\nSubgradient Method (PSM), by projections onto the individual sets whose\nintersection forms the entire feasible region. Specifically, we propose to\nperform such projections onto the individual sets in an algorithmic regime of a\nfeasibility-seeking iterative projection method. For this purpose we use the\nrecently developed family of Dynamic String-Averaging Projection (DSAP) methods\nwherein iteration-index-dependent variable strings and variable weights are\npermitted. This gives rise to an algorithmic scheme that generalizes, from the\nalgorithmic structural point of view, earlier work of Helou Neto and De Pierro,\nof Nedi\\'c, of Nurminski, and of Ram et al. \n\n"}
{"id": "1309.1110", "contents": "Title: When Backpressure Meets Predictive Scheduling Abstract: Motivated by the increasing popularity of learning and predicting human user\nbehavior in communication and computing systems, in this paper, we investigate\nthe fundamental benefit of predictive scheduling, i.e., predicting and\npre-serving arrivals, in controlled queueing systems. Based on a lookahead\nwindow prediction model, we first establish a novel equivalence between the\npredictive queueing system with a \\emph{fully-efficient} scheduling scheme and\nan equivalent queueing system without prediction. This connection allows us to\nanalytically demonstrate that predictive scheduling necessarily improves system\ndelay performance and can drive it to zero with increasing prediction power. We\nthen propose the \\textsf{Predictive Backpressure (PBP)} algorithm for achieving\noptimal utility performance in such predictive systems. \\textsf{PBP}\nefficiently incorporates prediction into stochastic system control and avoids\nthe great complication due to the exponential state space growth in the\nprediction window size. We show that \\textsf{PBP} can achieve a utility\nperformance that is within $O(\\epsilon)$ of the optimal, for any $\\epsilon>0$,\nwhile guaranteeing that the system delay distribution is a\n\\emph{shifted-to-the-left} version of that under the original Backpressure\nalgorithm. Hence, the average packet delay under \\textsf{PBP} is strictly\nbetter than that under Backpressure, and vanishes with increasing prediction\nwindow size. This implies that the resulting utility-delay tradeoff with\npredictive scheduling beats the known optimal $[O(\\epsilon),\nO(\\log(1/\\epsilon))]$ tradeoff for systems without prediction. \n\n"}
{"id": "1309.1913", "contents": "Title: Dynamic Team Theory of Stochastic Differential Decision Systems with\n  Decentralized Noisy Information Structures via Girsanov's Measure\n  Transformation Abstract: In this paper, we present two methods which generalize static team theory to\ndynamic team theory, in the context of continuous-time stochastic nonlinear\ndifferential decentralized decision systems, with relaxed strategies, which are\nmeasurable to different noisy information structures. For both methods we apply\nGirsanov's measure transformation to obtain an equivalent dynamic team problem\nunder a reference probability measure, so that the observations and information\nstructures available for decisions, are not affected by any of the team\ndecisions. The first method is based on function space integration with respect\nto products of Wiener measures, and generalizes Witsenhausen's [1] definition\nof equivalence between discrete-time static and dynamic team problems. The\nsecond method is based on stochastic Pontryagin's maximum principle. The team\noptimality conditions are given by a \"Hamiltonian System\" consisting of forward\nand backward stochastic differential equations, and a conditional variational\nHamiltonian with respect to the information structure of each team member,\nexpressed under the initial and a reference probability space via Girsanov's\nmeasure transformation. Under global convexity conditions, we show that that\nPbP optimality implies team optimality. In addition, we also show existence of\nteam and PbP optimal relaxed decentralized strategies (conditional\ndistributions), in the weak$^*$ sense, without imposing convexity on the action\nspaces of the team members. Moreover, using the embedding of regular strategies\ninto relaxed strategies, we also obtain team and PbP optimality conditions for\nregular team strategies, which are measurable functions of decentralized\ninformation structures, and we use the Krein-Millman theorem to show\nrealizability of relaxed strategies by regular strategies. \n\n"}
{"id": "1309.2545", "contents": "Title: Forbidden vertices Abstract: In this work, we introduce and study the forbidden-vertices problem. Given a\npolytope P and a subset X of its vertices, we study the complexity of linear\noptimization over the subset of vertices of P that are not contained in X. This\nproblem is closely related to finding the k-best basic solutions to a linear\nproblem. We show that the complexity of the problem changes significantly\ndepending on the encoding of both P and X. We provide additional tractability\nresults and extended formulations when P has binary vertices only. Some\napplications and extensions to integral polytopes are discussed. \n\n"}
{"id": "1309.4372", "contents": "Title: Faithful Implementations of Distributed Algorithms and Control Laws Abstract: When a distributed algorithm must be executed by strategic agents with\nmisaligned interests, a social leader needs to introduce an appropriate\ntax/subsidy mechanism to incentivize agents to faithfully implement the\nintended algorithm so that a correct outcome is obtained. We discuss the\nincentive issues of implementing economically efficient distributed algorithms\nusing the framework of indirect mechanism design theory. In particular, we show\nthat indirect Groves mechanisms are not only sufficient but also necessary to\nachieve incentive compatibility. This result can be viewed as a generalization\nof the Green-Laffont theorem to indirect mechanisms. Then we introduce the\nnotion of asymptotic incentive compatibility as an appropriate solution concept\nto faithfully implement distributed and iterative optimization algorithms. We\nconsider two special types of optimization algorithms: dual decomposition\nalgorithms for resource allocation and average consensus algorithms. \n\n"}
{"id": "1309.7264", "contents": "Title: Robust Consensus in Distributed Networks using Total Variation Abstract: Consider a connected network of agents endowed with local cost functions\nrepresenting private objectives. Agents seek to find an agreement on some\nminimizer of the aggregate cost, by means of repeated communications between\nneighbors. Consensus on the average over the network, usually addressed by\ngossip algorithms, is a special instance of this problem, corresponding to\nquadratic private objectives. Consensus on the median, or more generally\nquantiles, is also a special instance, as many more consensus problems. In this\npaper we show that optimizing the aggregate cost function regularized by a\ntotal variation term has appealing properties. First, it can be done very\nnaturally in a distributed way, yielding algorithms that are efficient on\nnumerical simulations. Secondly, the optimum for the regularized cost is shown\nto be also the optimum for the initial aggregate cost function under\nassumptions that are simple to state and easily verifiable. Finally, these\nalgorithms are robust to unreliable agents that keep injecting some false value\nin the network. This is remarkable enough, and is not the case, for instance,\nof gossip algorithms, that are entirely ruled by unreliable agents as detailed\nin the paper. \n\n"}
{"id": "1309.7415", "contents": "Title: Vertices of Spectrahedra arising from the Elliptope, the Theta Body, and\n  Their Relatives Abstract: Utilizing dual descriptions of the normal cone of convex optimization\nproblems in conic form, we characterize the vertices of semidefinite\nrepresentations arising from Lov\\'asz theta body, generalizations of the\nelliptope, and related convex sets. Our results generalize vertex\ncharacterizations due to Laurent and Poljak from the 1990's. Our approach also\nleads us to nice characterizations of strict complementarity and to connections\nwith some of the related literature. \n\n"}
{"id": "1310.1840", "contents": "Title: Parallel coordinate descent for the Adaboost problem Abstract: We design a randomised parallel version of Adaboost based on previous studies\non parallel coordinate descent. The algorithm uses the fact that the logarithm\nof the exponential loss is a function with coordinate-wise Lipschitz continuous\ngradient, in order to define the step lengths. We provide the proof of\nconvergence for this randomised Adaboost algorithm and a theoretical\nparallelisation speedup factor. We finally provide numerical examples on\nlearning problems of various sizes that show that the algorithm is competitive\nwith concurrent approaches, especially for large scale problems. \n\n"}
{"id": "1310.2213", "contents": "Title: Controller design and region of attraction estimation for nonlinear\n  dynamical systems Abstract: This work presents a method to obtain inner and outer approximations of the\nregion of attraction of a given target set as well as an admissible controller\ngenerating the inner approximation. The method is applicable to constrained\npolynomial dynamical systems and extends to trigonometric and rational systems.\nThe method consists of three steps: compute outer approximations, extract a\npolynomial controller while guaranteeing the satisfaction of the input\nconstraints, compute inner approximations with respect to the closed-loop\nsystem with this controller. Each step of the method is a convex optimization\nproblem, in fact a semidefinite program consisting of minimizing a linear\nfunction subject to linear matrix inequality (LMI) constraints. The inner\napproximations are positively invariant provided that the target set is\nincluded in the inner approximation and/or is itself invariant. %The approach\nreadily extends to trigonometric dynamics and/or constraints. \n\n"}
{"id": "1310.2558", "contents": "Title: Identification of the diffusion parameter in nonlocal steady diffusion\n  problems Abstract: The problem of identifying the diffusion parameter appearing in a nonlocal\nsteady diffusion equation is considered. The identification problem is\nformulated as an optimal control problem having a matching functional as the\nobjective of the control and the parameter function as the control variable.\nThe analysis makes use of a nonlocal vector calculus that allows one to define\na variational formulation of the nonlocal problem. In a manner analogous to the\nlocal partial differential equations counterpart, we demonstrate, for certain\nkernel functions, the existence of at least one optimal solution in the space\nof admissible parameters. We introduce a Galerkin finite element discretization\nof the optimal control problem and derive a priori error estimates for the\napproximate state and control variables. Using one-dimensional numerical\nexperiments, we illustrate the theoretical results and show that by using\nnonlocal models it is possible to estimate non-smooth and discontinuous\ndiffusion parameters. \n\n"}
{"id": "1310.4845", "contents": "Title: Homological differential calculus Abstract: This article provides a definition of a subdifferential for continuous\nfunctions based on homological considerations. We show that it satisfies all\nthe requirement for a good notion of subdifferential. Moreover, we prove\nsublinearity, a Leibniz formula and an approximation result. This work fits in\nthe framework of microlocal analysis of sheaves for C^0 symplectic problems and\napplication to Aubry-Mather theory. \n\n"}
{"id": "1310.5168", "contents": "Title: A New Notion of Effective Resistance for Directed Graphs-Part II:\n  Computing Resistances Abstract: In Part I of this work we defined a generalization of the concept of\neffective resistance to directed graphs, and we explored some of the properties\nof this new definition. Here, we use the theory developed in Part I to compute\neffective resistances in some prototypical directed graphs. This exploration\nhighlights cases where our notion of effective resistance for directed graphs\nbehaves analogously to our experience from undirected graphs, as well as cases\nwhere it behaves in unexpected ways. \n\n"}
{"id": "1310.6025", "contents": "Title: An optimal three-way stable and monotonic spectrum of bounds on\n  quantiles: a spectrum of coherent measures of financial risk and economic\n  inequality Abstract: A certain spectrum, indexed by a\\in[0,\\infty], of upper bounds P_a(X;x) on\nthe tail probability P(X\\geq x), with P_0(X;x)=P(X\\geq x) and P_\\infty(X;x)\nbeing the best possible exponential upper bound on P(X\\geq x), is shown to be\nstable and monotonic in a, x, and X, where x is a real number and X is a random\nvariable. The bounds P_a(X;x) are optimal values in certain minimization\nproblems. The corresponding spectrum, also indexed by a\\in[0,\\infty], of upper\nbounds Q_a(X;p) on the (1-p)-quantile of X is stable and monotonic in a, p, and\nX, with Q_0(X;p) equal the largest (1-p)-quantile of X. In certain sense, the\nquantile bounds Q_a(X;p) are usually close enough to the true quantiles\nQ_0(X;p). Moreover, Q_a(X;p) is subadditive in X if a\\geq 1, as well as\npositive-homogeneous and translation-invariant, and thus is a so-called\ncoherent measure of risk. A number of other useful properties of the bounds\nP_a(X;x) and Q_a(X;p) are established. In particular, quite similarly to the\nbounds P_a(X;x) on the tail probabilities, the quantile bounds Q_a(X;p) are the\noptimal values in certain minimization problems. This allows for a\ncomparatively easy incorporation of the bounds P_a(X;x) and Q_a(X;p) into more\nspecialized optimization problems. It is shown that the minimization problems\nfor which P_a(X;x) and Q_a(X;p) are the optimal values are in a certain sense\ndual to each other; in the case a=\\infty this corresponds to the bilinear\nLegendre--Fenchel duality. In finance, the (1-p)-quantile Q_0(X;p) is known as\nthe value-at-risk (VaR), whereas the value of Q_1(X;p) is known as the\nconditional value-at-risk (CVaR) and also as the expected shortfall (ES),\naverage value-at-risk (AVaR), and expected tail loss (ETL). It is shown that\nthe quantile bounds Q_a(X;p) can be used as measures of economic inequality.\nThe spectrum parameter, a, may be considered an index of sensitivity to\nrisk/inequality. \n\n"}
{"id": "1310.7292", "contents": "Title: Robust Optimal Power Flow with Wind Integration Using Conditional\n  Value-at-Risk Abstract: Integrating renewable energy into the power grid requires intelligent\nrisk-aware dispatch accounting for the stochastic availability of renewables.\nToward achieving this goal, a robust DC optimal flow problem is developed in\nthe present paper for power systems with a high penetration of wind energy. The\noptimal dispatch is obtained as the solution to a convex program with a\nsuitable regularizer, which is able to mitigate the potentially high risk of\ninadequate wind power. The regularizer is constructed based on the energy\ntransaction cost using conditional value-at-risk (CVaR). Bypassing the\nprohibitive high-dimensional integral, the distribution-free sample average\napproximation method is efficiently utilized for solving the resulting\noptimization problem. Case studies are reported to corroborate the efficacy of\nthe novel model and approach tested on the IEEE 30-bus benchmark system with\nreal operation data from seven wind farms. \n\n"}
{"id": "1311.1644", "contents": "Title: The Maximum Entropy Relaxation Path Abstract: The relaxed maximum entropy problem is concerned with finding a probability\ndistribution on a finite set that minimizes the relative entropy to a given\nprior distribution, while satisfying relaxed max-norm constraints with respect\nto a third observed multinomial distribution. We study the entire relaxation\npath for this problem in detail. We show existence and a geometric description\nof the relaxation path. Specifically, we show that the maximum entropy\nrelaxation path admits a planar geometric description as an increasing,\npiecewise linear function in the inverse relaxation parameter. We derive fast\nalgorithms for tracking the path. In various realistic settings, our algorithms\nrequire $O(n\\log(n))$ operations for probability distributions on $n$ points,\nmaking it possible to handle large problems. Once the path has been recovered,\nwe show that given a validation set, the family of admissible models is reduced\nfrom an infinite family to a small, discrete set. We demonstrate the merits of\nour approach in experiments with synthetic data and discuss its potential for\nthe estimation of compact n-gram language models. \n\n"}
{"id": "1311.2796", "contents": "Title: Mixed Human-Robot Team Surveillance Abstract: We study the mixed human-robot team design in a system theoretic setting\nusing the context of a surveillance mission. The three key coupled components\nof a mixed team design are (i) policies for the human operator, (ii) policies\nto account for erroneous human decisions, and (iii) policies to control the\nautomaton. In this paper, we survey elements of human decision-making,\nincluding evidence aggregation, situational awareness, fatigue, and memory\neffects. We bring together the models for these elements in human\ndecision-making to develop a single coherent model for human decision-making in\na two-alternative choice task. We utilize the developed model to design\nefficient attention allocation policies for the human operator. We propose an\nanomaly detection algorithm that utilizes potentially erroneous decision by the\noperator to ascertain an anomalous region among the set of regions surveilled.\nFinally, we propose a stochastic vehicle routing policy that surveils an\nanomalous region with high probability. Our mixed team design relies on the\ncertainty-equivalent receding-horizon control framework. \n\n"}
{"id": "1311.3019", "contents": "Title: An Excursion-Theoretic Approach to Regulator's Bank Reorganization\n  Problem Abstract: The importance of the global financial system cannot be exaggerated. When a\nlarge financial institution becomes problematic and is bailed out, that bank is\noften claimed as \"too big to fail\". On the other hand, to prevent bank's\nfailure, regulatory authorities adopt the Prompt Corrective Action (PCA)\nagainst a bank that violates certain criteria, often measured by its leverage\nratio. In this article, we provide a framework where one can analyze the cost\nand effect of PCA's. We model a large bank with deteriorating asset and\nregulatory actions attempting to prevent a failure. The model uses the\nexcursion theory of Levy processes and finds an optimal leverage ratio that\ntriggers a PCA. A nice feature includes it incorporates the fact that social\ncost associated with PCA's are be greatly affected by the size of banks subject\nto PCA's, so that one can see the cost of rescuing a bank \"too big to fail\". \n\n"}
{"id": "1311.3789", "contents": "Title: A semidefinite programming hierarchy for packing problems in discrete\n  geometry Abstract: Packing problems in discrete geometry can be modeled as finding independent\nsets in infinite graphs where one is interested in independent sets which are\nas large as possible. For finite graphs one popular way to compute upper bounds\nfor the maximal size of an independent set is to use Lasserre's semidefinite\nprogramming hierarchy. We generalize this approach to infinite graphs. For this\nwe introduce topological packing graphs as an abstraction for infinite graphs\ncoming from packing problems in discrete geometry. We show that our hierarchy\nconverges to the independence number. \n\n"}
{"id": "1311.4625", "contents": "Title: Control Contraction Metrics and Universal Stabilizability Abstract: In this paper we introduce the concept of universal stabilizability: the\ncondition that every solution of a nonlinear system can be globally stabilized.\nWe give sufficient conditions in terms of the existence of a control\ncontraction metric, which can be found by solving a pointwise linear matrix\ninequality. Extensions to approximate optimal control are straightforward. The\nconditions we give are necessary and sufficient for linear systems and certain\nclasses of nonlinear systems, and have interesting connections to the theory of\ncontrol Lyapunov functions. \n\n"}
{"id": "1312.0332", "contents": "Title: Semidefinite programming and eigenvalue bounds for the graph partition\n  problem Abstract: The graph partition problem is the problem of partitioning the vertex set of\na graph into a fixed number of sets of given sizes such that the sum of weights\nof edges joining different sets is optimized. In this paper we simplify a known\nmatrix-lifting semidefinite programming relaxation of the graph partition\nproblem for several classes of graphs and also show how to aggregate additional\ntriangle and independent set constraints for graphs with symmetry. We present\nan eigenvalue bound for the graph partition problem of a strongly regular\ngraph, extending a similar result for the equipartition problem. We also derive\na linear programming bound of the graph partition problem for certain Johnson\nand Kneser graphs. Using what we call the Laplacian algebra of a graph, we\nderive an eigenvalue bound for the graph partition problem that is the first\nknown closed form bound that is applicable to any graph, thereby extending a\nwell-known result in spectral graph theory. Finally, we strengthen a known\nsemidefinite programming relaxation of a specific quadratic assignment problem\nand the above-mentioned matrix-lifting semidefinite programming relaxation by\nadding two constraints that correspond to assigning two vertices of the graph\nto different parts of the partition. This strengthening performs well on highly\nsymmetric graphs when other relaxations provide weak or trivial bounds. \n\n"}
{"id": "1312.0418", "contents": "Title: Stability of continuous-time quantum filters with measurement\n  imperfections Abstract: The fidelity between the state of a continuously observed quantum system and\nthe state of its associated quantum filter, is shown to be always a\nsubmartingale. The observed system is assumed to be governed by a\ncontinuous-time Stochastic Master Equation (SME), driven simultaneously by\nWiener and Poisson processes and that takes into account incompleteness and\nerrors in measurements. This stability result is the continuous-time\ncounterpart of a similar stability result already established for discrete-time\nquantum systems and where the measurement imperfections are modeled by a left\nstochastic matrix. \n\n"}
{"id": "1312.2638", "contents": "Title: Vertex nomination schemes for membership prediction Abstract: Suppose that a graph is realized from a stochastic block model where one of\nthe blocks is of interest, but many or all of the vertices' block labels are\nunobserved. The task is to order the vertices with unobserved block labels into\na ``nomination list'' such that, with high probability, vertices from the\ninteresting block are concentrated near the list's beginning. We propose\nseveral vertex nomination schemes. Our basic - but principled - setting and\ndevelopment yields a best nomination scheme (which is a Bayes-Optimal\nanalogue), and also a likelihood maximization nomination scheme that is\npractical to implement when there are a thousand vertices, and which is\nempirically near-optimal when the number of vertices is small enough to allow\ncomparison to the best nomination scheme. We then illustrate the robustness of\nthe likelihood maximization nomination scheme to the modeling challenges\ninherent in real data, using examples which include a social network involving\nhuman trafficking, the Enron Graph, a worm brain connectome and a political\nblog network. \n\n"}
{"id": "1312.3013", "contents": "Title: Improving Fast Dual Ascent for MPC - Part II: The Embedded Case Abstract: Recently, several authors have suggested the use of first order methods, such\nas fast dual ascent and the alternating direction method of multipliers, for\nembedded model predictive control. The main reason is that they can be\nimplemented using simple arithmetic operations only. However, a known\nlimitation of gradient-based methods is that they are sensitive to\nill-conditioning of the problem data. In this paper, we present a fast dual\ngradient method for which the sensitivity to ill-conditioning is greatly\nreduced. This is achieved by approximating the negative dual function with a\nquadratic upper bound with different curvature in different directions in the\nalgorithm, as opposed to having the same curvature in all directions as in\nstandard fast gradient methods. The main contribution of this paper is a\ncharacterization of the set of matrices that can be used to form such a\nquadratic upper bound to the negative dual function. We also describe how to\nchoose a matrix from this set to get an improved approximation of the dual\nfunction, especially if it is ill-conditioned, compared to the approximation\nused in standard fast dual gradient methods. This can give a significantly\nimproved performance as illustrated by a numerical evaluation on an\nill-conditioned AFTI-16 aircraft model. \n\n"}
{"id": "1312.4354", "contents": "Title: Decomposition of Optical Flow on the Sphere Abstract: We propose a number of variational regularisation methods for the estimation\nand decomposition of motion fields on the $2$-sphere. While motion estimation\nis based on the optical flow equation, the presented decomposition models are\nmotivated by recent trends in image analysis. In particular we treat $u+v$\ndecomposition as well as hierarchical decomposition. Helmholtz decomposition of\nmotion fields is obtained as a natural by-product of the chosen numerical\nmethod based on vector spherical harmonics. All models are tested on time-lapse\nmicroscopy data depicting fluorescently labelled endodermal cells of a\nzebrafish embryo. \n\n"}
{"id": "1312.4883", "contents": "Title: A Riemannian approach to low-rank algebraic Riccati equations Abstract: We propose a Riemannian optimization approach for computing low-rank\nsolutions of the algebraic Riccati equation. The scheme alternates between\nfixed-rank optimization and rank-one updates. The fixed-rank optimization is on\nthe set of fixed-rank symmetric positive definite matrices which is endowed\nwith a particular Riemannian metric (and geometry) that is tuned to the\nstructure of the objective function. We specifically discuss the implementation\nof a Riemannian trust-region algorithm that is potentially scalable to\nlarge-scale problems. The rank-one update is based on a descent direction that\nensures a monotonic decrease of the cost function. Preliminary numerical\nresults on standard small-scale benchmarks show that we obtain solutions to the\nRiccati equation at lower ranks than the standard approaches. \n\n"}
{"id": "1312.5634", "contents": "Title: Fixed points of the EM algorithm and nonnegative rank boundaries Abstract: Mixtures of $r$ independent distributions for two discrete random variables\ncan be represented by matrices of nonnegative rank $r$. Likelihood inference\nfor the model of such joint distributions leads to problems in real algebraic\ngeometry that are addressed here for the first time. We characterize the set of\nfixed points of the Expectation-Maximization algorithm, and we study the\nboundary of the space of matrices with nonnegative rank at most $3$. Both of\nthese sets correspond to algebraic varieties with many irreducible components. \n\n"}
{"id": "1312.6662", "contents": "Title: Equivariant semidefinite lifts and sum-of-squares hierarchies Abstract: A central question in optimization is to maximize (or minimize) a linear\nfunction over a given polytope P. To solve such a problem in practice one needs\na concise description of the polytope P. In this paper we are interested in\nrepresentations of P using the positive semidefinite cone: a positive\nsemidefinite lift (psd lift) of a polytope P is a representation of P as the\nprojection of an affine slice of the positive semidefinite cone\n$\\mathbf{S}^d_+$. Such a representation allows linear optimization problems\nover P to be written as semidefinite programs of size d. Such representations\ncan be beneficial in practice when d is much smaller than the number of facets\nof the polytope P. In this paper we are concerned with so-called equivariant\npsd lifts (also known as symmetric psd lifts) which respect the symmetries of\nthe polytope P. We present a representation-theoretic framework to study\nequivariant psd lifts of a certain class of symmetric polytopes known as\norbitopes. Our main result is a structure theorem where we show that any\nequivariant psd lift of size d of an orbitope is of sum-of-squares type where\nthe functions in the sum-of-squares decomposition come from an invariant\nsubspace of dimension smaller than d^3. We use this framework to study two\nwell-known families of polytopes, namely the parity polytope and the cut\npolytope, and we prove exponential lower bounds for equivariant psd lifts of\nthese polytopes. \n\n"}
{"id": "1312.7377", "contents": "Title: Designing Fully Distributed Consensus Protocols for Linear Multi-agent\n  Systems with Directed Graphs Abstract: This paper addresses the distributed consensus protocol design problem for\nmulti-agent systems with general linear dynamics and directed communication\ngraphs. Existing works usually design consensus protocols using the smallest\nreal part of the nonzero eigenvalues of the Laplacian matrix associated with\nthe communication graph, which however is global information. In this paper,\nbased on only the agent dynamics and the relative states of neighboring agents,\na distributed adaptive consensus protocol is designed to achieve\nleader-follower consensus for any communication graph containing a directed\nspanning tree with the leader as the root node. The proposed adaptive protocol\nis independent of any global information of the communication graph and thereby\nis fully distributed. Extensions to the case with multiple leaders are further\nstudied. \n\n"}
{"id": "1312.7581", "contents": "Title: On the Learning Behavior of Adaptive Networks - Part I: Transient\n  Analysis Abstract: This work carries out a detailed transient analysis of the learning behavior\nof multi-agent networks, and reveals interesting results about the learning\nabilities of distributed strategies. Among other results, the analysis reveals\nhow combination policies influence the learning process of networked agents,\nand how these policies can steer the convergence point towards any of many\npossible Pareto optimal solutions. The results also establish that the learning\nprocess of an adaptive network undergoes three (rather than two) well-defined\nstages of evolution with distinctive convergence rates during the first two\nstages, while attaining a finite mean-square-error (MSE) level in the last\nstage. The analysis reveals what aspects of the network topology influence\nperformance directly and suggests design procedures that can optimize\nperformance by adjusting the relevant topology parameters. Interestingly, it is\nfurther shown that, in the adaptation regime, each agent in a sparsely\nconnected network is able to achieve the same performance level as that of a\ncentralized stochastic-gradient strategy even for left-stochastic combination\nstrategies. These results lead to a deeper understanding and useful insights on\nthe convergence behavior of coupled distributed learners. The results also lead\nto effective design mechanisms to help diffuse information more thoroughly over\nnetworks. \n\n"}
{"id": "1401.1255", "contents": "Title: Interiors of completely positive cones Abstract: A symmetric matrix $A$ is completely positive (CP) if there exists an\nentrywise nonnegative matrix $B$ such that $A = BB^T$. We characterize the\ninterior of the CP cone. A semidefinite algorithm is proposed for checking\ninteriors of the CP cone, and its properties are studied. A CP-decomposition of\na matrix in Dickinson's form can be obtained if it is an interior of the CP\ncone. Some computational experiments are also presented. \n\n"}
{"id": "1401.1863", "contents": "Title: Optimal Subharmonic Entrainment Abstract: For many natural and engineered systems, a central function or design goal is\nthe synchronization of one or more rhythmic or oscillating processes to an\nexternal forcing signal, which may be periodic on a different time-scale from\nthe actuated process. Such subharmonic synchrony, which is dynamically\nestablished when N control cycles occur for every M cycles of a forced\noscillator, is referred to as N:M entrainment. In many applications,\nentrainment must be established in an optimal manner, for example by minimizing\ncontrol energy or the transient time to phase locking. We present a theory for\nderiving inputs that establish subharmonic N:M entrainment of general nonlinear\noscillators, or of collections of rhythmic dynamical units, while optimizing\nsuch objectives. Ordinary differential equation models of oscillating systems\nare reduced to phase variable representations, each of which consists of a\nnatural frequency and phase response curve. Formal averaging and the calculus\nof variations are then applied to such reduced models in order to derive\noptimal subharmonic entrainment waveforms. The optimal entrainment of a\ncanonical model for a spiking neuron is used to illustrate this approach, which\nis readily extended to arbitrary oscillating systems. \n\n"}
{"id": "1401.2181", "contents": "Title: A biologically inspired model for transshipment problem Abstract: Transshipment problem is one of the basic operational research problems. In\nthis paper, our first work is to develop a biologically inspired mathematical\nmodel for a dynamical system, which is first used to solve minimum cost flow\nproblem. It has lower computational complexity than Physarum Solver. Second, we\napply the proposed model to solve the traditional transshipment problem.\nCompared with the conditional methods, experiment results show the provided\nmodel is simple, effective as well as handling problem in a continuous manner. \n\n"}
{"id": "1401.3229", "contents": "Title: Principal Component Analysis in an Asymmetric Norm Abstract: Principal component analysis (PCA) is a widely used dimension reduction tool\nin the analysis of many kind of high-dimensional data. It is used in signal\nprocessing, mechanical engineering, psychometrics, and other fields under\ndifferent names. It still bears the same mathematical idea: the decomposition\nof variation of a high dimensional object into uncorrelated factors or\ncomponents. However, in many of the above applications, one is interested in\ncapturing the tail variables of the data rather than variation around the mean.\nSuch applications include weather related event curves, expected shortfalls,\nand speeding analysis among others. These are all high dimensional tail objects\nwhich one would like to study in a PCA fashion. The tail character though\nrequires to do the dimension reduction in an asymmetric norm rather than the\nclassical $L_2$-type orthogonal projection. We develop an analogue of PCA in an\nasymmetric norm. These norms cover both quantiles and expectiles, another tail\nevent measure. The difficulty is that there is no natural basis, no `principal\ncomponents', to the $k$-dimensional subspace found. We propose two definitions\nof principal components and provide algorithms based on iterative least\nsquares. We prove upper bounds on their convergence times, and compare their\nperformances in a simulation study. We apply the algorithms to a Chinese\nweather dataset with a view to weather derivative pricing \n\n"}
{"id": "1401.4636", "contents": "Title: Dynamic Equilibrium Limit Order Book Model and Optimal Execution Problem Abstract: In this paper we propose a dynamic model of Limit Order Book (LOB). The main\nfeature of our model is that the shape of the LOB is determined endogenously by\nan expected utility function via a competitive equilibrium argument. Assuming\nzero resilience, the resulting equilibrium density of the LOB is random,\nnonlinear, and time inhomogeneous. Consequently, the liquidity cost can be\ndefined dynamically in a natural way.\n  We next study an optimal execution problem in our model. We verify that the\nvalue function satisfies the Dynamic Programming Principle, and is a viscosity\nsolution to the corresponding Hamilton-Jacobi-Bellman equation which is in the\nform of an integro-partial-differential quasi-variational inequality. We also\nprove the existence and analyze the structure of the optimal strategy via a\nverification theorem argument, assuming that the PDE has a classical solution. \n\n"}
{"id": "1401.4780", "contents": "Title: An Asynchronous Parallel Randomized Kaczmarz Algorithm Abstract: We describe an asynchronous parallel variant of the randomized Kaczmarz (RK)\nalgorithm for solving the linear system $Ax=b$. The analysis shows linear\nconvergence and indicates that nearly linear speedup can be expected if the\nnumber of processors is bounded by a multiple of the number of rows in $A$. \n\n"}
{"id": "1401.5226", "contents": "Title: The Why and How of Nonnegative Matrix Factorization Abstract: Nonnegative matrix factorization (NMF) has become a widely used tool for the\nanalysis of high-dimensional data as it automatically extracts sparse and\nmeaningful features from a set of nonnegative data vectors. We first illustrate\nthis property of NMF on three applications, in image processing, text mining\nand hyperspectral imaging --this is the why. Then we address the problem of\nsolving NMF, which is NP-hard in general. We review some standard NMF\nalgorithms, and also present a recent subclass of NMF problems, referred to as\nnear-separable NMF, that can be solved efficiently (that is, in polynomial\ntime), even in the presence of noise --this is the how. Finally, we briefly\ndescribe some problems in mathematics and computer science closely related to\nNMF via the nonnegative rank. \n\n"}
{"id": "1401.5484", "contents": "Title: Infinite horizon Stochastic Optimal Control for Volterra equations with\n  completely monotone kernels Abstract: The aim of the paper is to study an optimal control problem on infinite\nhorizon for an infinite dimensional integro-differential equation with\ncompletely monotone kernelskernels, where we assume that the noise enters the\nsystem when we introduce a control. We start by reformulating the state\nequation into a semilinear evolution equation which can be treated by semigroup\nmethods. The application to optimal control provide other interesting result\nand require a precise descriprion of the properties of the generated semigroup.\nThe main tools consist in studying the differentiability of the\nforward-backward system with infinite horizon corresponding with the\nreformulated problem and the proof of existence and uniqueness of of mild\nsolutions to the corresponding HJB equation. \n\n"}
{"id": "1401.5828", "contents": "Title: Applications of Information Nonanticipative Rate Distortion Function Abstract: The objective of this paper is to further investigate various applications of\ninformation Nonanticipative Rate Distortion Function (NRDF) by discussing two\nworking examples, the Binary Symmetric Markov Source with parameter $p$\n(BSMS($p$)) with Hamming distance distortion, and the multidimensional\npartially observed Gaussian-Markov source. For the BSMS($p$), we give the\nsolution to the NRDF, and we use it to compute the Rate Loss (RL) of causal\ncodes with respect to noncausal codes. For the multidimensional Gaussian-Markov\nsource, we give the solution to the NRDF, we show its operational meaning via\njoint source-channel matching over a vector of parallel Gaussian channels, and\nwe compute the RL of causal and zero-delay codes with respect to noncausal\ncodes. \n\n"}
{"id": "1401.7569", "contents": "Title: Transversality and alternating projections for nonconvex sets Abstract: We consider the method of alternating projections for finding a point in the\nintersection of two closed sets, possibly nonconvex. Assuming only the standard\ntransversality condition (or a weaker version thereof), we prove local linear\nconvergence. When the two sets are semi-algebraic and bounded, but not\nnecessarily transversal, we nonetheless prove subsequence convergence. \n\n"}
{"id": "1401.7715", "contents": "Title: Video Compressive Sensing for Dynamic MRI Abstract: We present a video compressive sensing framework, termed kt-CSLDS, to\naccelerate the image acquisition process of dynamic magnetic resonance imaging\n(MRI). We are inspired by a state-of-the-art model for video compressive\nsensing that utilizes a linear dynamical system (LDS) to model the motion\nmanifold. Given compressive measurements, the state sequence of an LDS can be\nfirst estimated using system identification techniques. We then reconstruct the\nobservation matrix using a joint structured sparsity assumption. In particular,\nwe minimize an objective function with a mixture of wavelet sparsity and joint\nsparsity within the observation matrix. We derive an efficient convex\noptimization algorithm through alternating direction method of multipliers\n(ADMM), and provide a theoretical guarantee for global convergence. We\ndemonstrate the performance of our approach for video compressive sensing, in\nterms of reconstruction accuracy. We also investigate the impact of various\nsampling strategies. We apply this framework to accelerate the acquisition\nprocess of dynamic MRI and show it achieves the best reconstruction accuracy\nwith the least computational time compared with existing algorithms in the\nliterature. \n\n"}
{"id": "1401.8161", "contents": "Title: Das Optimierungslabor -- ein Erfahrungsbericht (Experiencing\n  optimization with students) Abstract: For several years, students visit us on different occasions at the\nuniversity. But how to bridge from the school curriculum to the contents of the\nuniversity mathematics? And how to find a focal point at which an active\ncontribute, despite the lack of knowledge, in view of limited time is possible?\nOur approach: Translate,under guidance, everyday life optimization problems\ninto the language of mathematics, i.e. using variables, target functions,\nequations and inequalities. These so-called integer linear programming models\nare then solved by standard software. In this report we wnat to tell about the\nlessons we have learned. \n\n"}
{"id": "1401.8232", "contents": "Title: An Inverse Problem of the Calculus of Variations on Arbitrary Time\n  Scales Abstract: We consider an inverse extremal problem for variational functionals on\narbitrary time scales. Using the Euler-Lagrange equation and the strengthened\nLegendre condition, we derive a general form for a variational functional that\nattains a local minimum at a given point of the vector space. \n\n"}
{"id": "1402.0140", "contents": "Title: Probabilistic Model Validation for Uncertain Nonlinear Systems Abstract: This paper presents a probabilistic model validation methodology for\nnonlinear systems in time-domain. The proposed formulation is simple,\nintuitive, and accounts both deterministic and stochastic nonlinear systems\nwith parametric and nonparametric uncertainties. Instead of hard invalidation\nmethods available in the literature, a relaxed notion of validation in\nprobability is introduced. To guarantee provably correct inference, algorithm\nfor constructing probabilistically robust validation certificate is given along\nwith computational complexities. Several examples are worked out to illustrate\nits use. \n\n"}
{"id": "1402.0240", "contents": "Title: Graph Cuts with Interacting Edge Costs - Examples, Approximations, and\n  Algorithms Abstract: We study an extension of the classical graph cut problem, wherein we replace\nthe modular (sum of edge weights) cost function by a submodular set function\ndefined over graph edges. Special cases of this problem have appeared in\ndifferent applications in signal processing, machine learning, and computer\nvision. In this paper, we connect these applications via the generic\nformulation of \"cooperative graph cuts\", for which we study complexity,\nalgorithms, and connections to polymatroidal network flows. Finally, we compare\nthe proposed algorithms empirically. \n\n"}
{"id": "1402.1310", "contents": "Title: Feasibility-Seeking and Superiorization Algorithms Applied to Inverse\n  Treatment Planning in Radiation Therapy Abstract: We apply the recently proposed superiorization methodology (SM) to the\ninverse planning problem in radiation therapy. The inverse planning problem is\nrepresented here as a constrained minimization problem of the total variation\n(TV) of the intensity vector over a large system of linear two-sided\ninequalities. The SM can be viewed conceptually as lying between\nfeasibility-seeking for the constraints and full-fledged constrained\nminimization of the objective function subject to these constraints. It is\nbased on the discovery that many feasibility-seeking algorithms (of the\nprojection methods variety) are perturbation-resilient, and can be proactively\nsteered toward a feasible solution of the constraints with a reduced, thus\nsuperiorized, but not necessarily minimal, objective function value. \n\n"}
{"id": "1402.1697", "contents": "Title: Geodesic Density Tracking with Applications to Data Driven Modeling Abstract: Many problems in dynamic data driven modeling deals with distributed rather\nthan lumped observations. In this paper, we show that the Monge-Kantorovich\noptimal transport theory provides a unifying framework to tackle such problems\nin the systems-control parlance. Specifically, given distributional\nmeasurements at arbitrary instances of measurement availability, we show how to\nderive dynamical systems that interpolate the observed distributions along the\ngeodesics. We demonstrate the framework in the context of three specific\nproblems: (i) \\emph{finding a feedback control} to track observed ensembles\nover finite-horizon, (ii) \\emph{finding a model} whose prediction matches the\nobserved distributional data, and (iii) \\emph{refining a baseline model} that\nresults a distribution-level prediction-observation mismatch. We emphasize how\nthe three problems can be posed as variants of the optimal transport problem,\nbut lead to different types of numerical methods depending on the problem\ncontext. Several examples are given to elucidate the ideas. \n\n"}
{"id": "1402.2402", "contents": "Title: Local asymptotics for controlled martingales Abstract: We consider controlled martingales with bounded steps where the controller is\nallowed at each step to choose the distribution of the next step, and where the\ngoal is to hit a fixed ball at the origin at time $n$. We show that the\nalgebraic rate of decay (as $n$ increases to infinity) of the value function in\nthe discrete setup coincides with its continuous counterpart, provided a\nreachability assumption is satisfied. We also study in some detail the\nuniformly elliptic case and obtain explicit bounds on the rate of decay. This\ngeneralizes and improves upon several recent studies of the one dimensional\ncase, and is a discrete analogue of a stochastic control problem recently\ninvestigated in Armstrong and Trokhimtchouck [Calc. Var. Partial Differential\nEquations 38 (2010) 521-540]. \n\n"}
{"id": "1402.2467", "contents": "Title: A model problem for Mean Field Games on networks Abstract: In [14], Gueant, Lasry and Lions considered the model problem ``What time\ndoes meeting start?'' as a prototype for a general class of optimization\nproblems with a continuum of players, called Mean Field Games problems. In this\npaper we consider a similar model, but with the dynamics of the agents defined\non a network. We discuss appropriate transition conditions at the vertices\nwhich give a well posed problem and we present some numerical results. \n\n"}
{"id": "1402.3131", "contents": "Title: Risk minimization in financial markets modeled by It\\^o-L\\'evy processes Abstract: This paper is mainly a survey of recent research developments regarding\nmethods for risk minimization in financial markets modeled by It\\^o-L\\'evy\nprocesses, but it also contains some new results on the underlying stochastic\nmaximum principle.\n  The concept of a convex risk measure is introduced, and two representations\nof such measures are given, namely: (i) the dual representation and (ii) the\nrepresentation by means of backward stochastic differential equations (BSDEs)\nwith jumps. Depending on the representation, the corresponding risk minimal\nportfolio problem is studied, either in the context of stochastic differential\ngames or optimal control of forward-backward SDEs.\n  The related concept of recursive utility is also introduced, and\ncorresponding recursive utility maximization problems are studied.\n  In either case the maximum principle for optimal stochastic control plays a\ncrucial role, and in the paper we prove a version of this principle which is\nstronger than what was previously known.\n  The theory is illustrated by examples, showing explicitly the risk minimizing\nportfolio in some cases. \n\n"}
{"id": "1402.3730", "contents": "Title: A Discretization Method to Solve Fractional Variational Problems with\n  Dependence on Hadamard Derivatives Abstract: We provide a fast and simple method to solve fractional variational problems\nwith dependence on Hadamard fractional derivatives. Using a relation between\nthe Hadamard fractional operator and a sum involving integer-order derivatives,\nwe rewrite the fractional problem into a classical optimal control problem. The\nlatter problem is then solved by application of standard numerical techniques.\nWe illustrate the procedure with an example. \n\n"}
{"id": "1402.7291", "contents": "Title: Optimal subgradient algorithms with application to large-scale linear\n  inverse problems Abstract: This study addresses some algorithms for solving structured unconstrained\nconvex optimiza- tion problems using first-order information where the\nunderlying function includes high-dimensional data. The primary aim is to\ndevelop an implementable algorithmic framework for solving problems with multi-\nterm composite objective functions involving linear mappings using the optimal\nsubgradient algorithm, OSGA, proposed by Neumaier in [49]. To this end, we\npropose some prox-functions for which the cor- responding subproblem of OSGA is\nsolved in a closed form. Considering various inverse problems arising in signal\nand image processing, machine learning, statistics, we report extensive\nnumerical and compar- isons with several state-of-the-art solvers proposing\nfavourably performance of our algorithm. We also compare with the most widely\nused optimal first-order methods for some smooth and nonsmooth con- vex\nproblems. Surprisingly, when some Nesterov-type optimal methods originally\nproposed for smooth problems are adapted for solving nonsmooth problems by\nsimply passing a subgradient instead of the gradient, the results of these\nsubgradient-based algorithms are competitive and totally interesting for\nsolving nonsmooth problems. Finally, the OSGA software package is available. \n\n"}
{"id": "1403.1166", "contents": "Title: Mathematical optimization for packing problems Abstract: During the last few years several new results on packing problems were\nobtained using a blend of tools from semidefinite optimization, polynomial\noptimization, and harmonic analysis. We survey some of these results and the\ntechniques involved, concentrating on geometric packing problems such as the\nsphere-packing problem or the problem of packing regular tetrahedra in R^3. \n\n"}
{"id": "1403.2356", "contents": "Title: Corners in non-equiregular sub-Riemannian manifolds Abstract: We prove that in a class of non-equiregular sub-Riemannian manifolds corners\nare not length minimizing. This extends the results [4]. As an application of\nour main result we complete and simplify the analysis in [6], showing that in a\n4-dimensional sub-Riemannian structure suggested by Agrachev and Gauthier all\nlength-minimizing curves are smooth. \n\n"}
{"id": "1403.2900", "contents": "Title: A Maximum Principle for Markov Regime-Switching Forward Backward\n  Stochastic Differential Games and Applications Abstract: In this paper, we present an optimal control problem for stochastic\ndifferential games under Markov regime-switching forward-backward stochastic\ndifferential equations with jumps and partial information. First, we prove a\nsufficient maximum principle for non zero-sum stochastic differential game\nproblems and obtain equilibrium point for such games. Second, we prove an\nequivalent maximum principle for non zero-sum stochastic differential games.\nThe zero-sum stochastic differential games equivalent maximum principle is then\nobtained as a corollary. We apply the obtained results to study a problem of\nrobust utility maximization under penalty entropy. We also apply the result to\nfind optimal investment of an insurance firm under model uncertainty. \n\n"}
{"id": "1403.3937", "contents": "Title: Existence of minimizers for generalized Lagrangian functionals and a\n  necessary optimality condition --- Application to fractional variational\n  problems Abstract: We study dynamic minimization problems of the calculus of variations with\ngeneralized Lagrangian functionals that depend on a general linear operator $K$\nand defined on bounded-time intervals. Under assumptions of regularity,\nconvexity and coercivity, we derive sufficient conditions ensuring the\nexistence of a minimizer. Finally, we obtain necessary optimality conditions of\nEuler-Lagrange type. Main results are illustrated with special cases, when $K$\nis a general kernel operator and, in particular, with $K$ the fractional\nintegral of Riemann-Liouville and Hadamard. The application of our results to\nthe recent fractional calculus of variations gives answer to an open question\nposed in [Abstr. Appl. Anal. 2012, Art. ID 871912; doi:10.1155/2012/871912]. \n\n"}
{"id": "1403.3998", "contents": "Title: Semidefinite Relaxation for Two Mixed Binary Quadratically Constrained\n  Quadratic Programs: Algorithms and Approximation Bounds Abstract: This paper develops new semidefinite programming (SDP) relaxation techniques\nfor two classes of mixed binary quadratically constrained quadratic programs\n(MBQCQP) and analyzes their approximation performance. The first class of\nproblem finds two minimum norm vectors in $N$-dimensional real or complex\nEuclidean space, such that $M$ out of $2M$ concave quadratic functions are\nsatisfied. By employing a special randomized rounding procedure, we show that\nthe ratio between the norm of the optimal solution of this model and its SDP\nrelaxation is upper bounded by $\\frac{54M^2}{\\pi}$ in the real case and by\n$\\frac{24M}{\\sqrt{\\pi}}$ in the complex case. The second class of problem finds\na series of minimum norm vectors subject to a set of quadratic constraints and\na cardinality constraint with both binary and continuous variables. We show\nthat in this case the approximation ratio is also bounded and independent of\nproblem dimension for both the real and the complex cases. \n\n"}
{"id": "1403.5315", "contents": "Title: A Deterministic Annealing Optimization Approach for Witsenhausen's and\n  Related Decentralized Control Settings Abstract: This paper studies the problem of mapping optimization in decentralized\ncontrol problems. A global optimization algorithm is proposed based on the\nideas of ``deterministic annealing\" - a powerful non-convex optimization\nframework derived from information theoretic principles with analogies to\nstatistical physics. The key idea is to randomize the mappings and control the\nShannon entropy of the system during optimization. The entropy constraint is\ngradually relaxed in a deterministic annealing process while tracking the\nminimum, to obtain the ultimate deterministic mappings. Deterministic annealing\nhas been successfully employed in several problems including clustering, vector\nquantization, regression, as well as the Witsenhausen's counterexample in our\nrecent work[1]. We extend our method to a more involved setting, a variation of\nWitsenhausen's counterexample, where there is a side channel between the two\ncontrollers. The problem can be viewed as a two stage cancellation problem. We\ndemonstrate that there exist complex strategies that can exploit the side\nchannel efficiently, obtaining significant gains over the best affine and known\nnon-linear strategies. \n\n"}
{"id": "1403.5339", "contents": "Title: Spacecraft Position and Attitude Formation Control using Line-of-Sight\n  Observations Abstract: This paper studies formation control of an arbitrary number of spacecraft\nbased on a serial network structure. The leader controls its absolute position\nand absolute attitude with respect to an inertial frame, and the followers\ncontrol its relative position and attitude with respect to another spacecraft\nassigned by the serial network. The unique feature is that both the absolute\nattitude and the relative attitude control systems are developed directly in\nterms of the line-of-sight observations between spacecraft, without need for\nestimating the full absolute and relative attitudes, to improve accuracy and\nefficiency. Control systems are developed on the nonlinear configuration\nmanifold, guaranteeing exponential stability. Numerical examples are presented\nto illustrate the desirable properties of the proposed control system. \n\n"}
{"id": "1403.5991", "contents": "Title: A Potential Reduction Method for Canonical Duality, with an Application\n  to the Sensor Network Localization Problem Abstract: We propose to solve large instances of the non-convex optimization problems\nreformulated with canonical duality theory. To this aim we propose an interior\npoint potential reduction algorithm based on the solution of the primal-dual\ntotal complementarity (Lagrange) function. We establish the global convergence\nresult for the algorithm under mild assumptions and demonstrate the method on\ninstances of the Sensor Network Localization problem. Our numerical results are\npromising and show the possibility of devising efficient interior points\nmethods for non-convex duality. \n\n"}
{"id": "1403.6622", "contents": "Title: Iteration complexity analysis of random coordinate descent methods for\n  $\\ell_0$ regularized convex problems Abstract: In this paper we analyze a family of general random block coordinate descent\nmethods for the minimization of $\\ell_0$ regularized optimization problems,\ni.e. the objective function is composed of a smooth convex function and the\n$\\ell_0$ regularization. Our family of methods covers particular cases such as\nrandom block coordinate gradient descent and random proximal coordinate descent\nmethods. We analyze necessary optimality conditions for this nonconvex $\\ell_0$\nregularized problem and devise a separation of the set of local minima into\nrestricted classes based on approximation versions of the objective function.\nWe provide a unified analysis of the almost sure convergence for this family of\nblock coordinate descent algorithms and prove that, for each approximation\nversion, the limit points are local minima from the corresponding restricted\nclass of local minimizers. Under the strong convexity assumption, we prove\nlinear convergence in probability for our family of methods. \n\n"}
{"id": "1404.0814", "contents": "Title: Controllability of the 1D Schrodinger equation by the flatness approach Abstract: We derive in a straightforward way the exact controllability of the 1-D\nSchrodinger equation with a Dirichlet boundary control. We use the so-called\nflatness approach, which consists in parameterizing the solution and the\ncontrol by the derivatives of a \"flat output\". This provides an explicit\ncontrol input achieving the exact controllability in the energy space. As an\napplication, we derive an explicit pair of control inputs achieving the exact\nsteering to zero for a simply-supported beam. \n\n"}
{"id": "1404.1592", "contents": "Title: The Power of Online Learning in Stochastic Network Optimization Abstract: In this paper, we investigate the power of online learning in stochastic\nnetwork optimization with unknown system statistics {\\it a priori}. We are\ninterested in understanding how information and learning can be efficiently\nincorporated into system control techniques, and what are the fundamental\nbenefits of doing so. We propose two \\emph{Online Learning-Aided Control}\ntechniques, $\\mathtt{OLAC}$ and $\\mathtt{OLAC2}$, that explicitly utilize the\npast system information in current system control via a learning procedure\ncalled \\emph{dual learning}. We prove strong performance guarantees of the\nproposed algorithms: $\\mathtt{OLAC}$ and $\\mathtt{OLAC2}$ achieve the\nnear-optimal $[O(\\epsilon), O([\\log(1/\\epsilon)]^2)]$ utility-delay tradeoff\nand $\\mathtt{OLAC2}$ possesses an $O(\\epsilon^{-2/3})$ convergence time.\n$\\mathtt{OLAC}$ and $\\mathtt{OLAC2}$ are probably the first algorithms that\nsimultaneously possess explicit near-optimal delay guarantee and sub-linear\nconvergence time. Simulation results also confirm the superior performance of\nthe proposed algorithms in practice. To the best of our knowledge, our attempt\nis the first to explicitly incorporate online learning into stochastic network\noptimization and to demonstrate its power in both theory and practice. \n\n"}
{"id": "1404.1667", "contents": "Title: Continuous-Time Singular Linear-Quadratic Control: Necessary and\n  Sufficient Conditions for the Existence of Regular Solutions Abstract: The purpose of this paper is to close the remaining gaps in the understanding\nof the role that the constrained generalized continuous algebraic Riccati\nequation plays in singular linear-quadratic (LQ) optimal control. Indeed, in\nspite of the vast literature on LQ problems, it is only in a recent paper that\na sufficient condition for the existence of a non-impulsive optimal control has\nfor the first time connected this equation with the singular LQ optimal control\nproblem. In this paper, we establish four equivalent conditions providing a\ncomplete picture that connects the singular LQ problem with the generalized\ncontinuous algebraic Riccati equation and with the geometric properties of the\nunderlying system. \n\n"}
{"id": "1404.1668", "contents": "Title: On Resilient Control of Nonlinear Systems under Denial-of-Service Abstract: We analyze and design a control strategy for nonlinear systems under\nDenial-of-Service attacks. Based on an ISS-Lyapunov function analysis, we\nprovide a characterization of the maximal percentage of time during which\nfeedback information can be lost without resulting in the instability of the\nsystem. Motivated by the presence of a digital channel we consider event-based\ncontrollers for which a minimal inter-sampling time is explicitly\ncharacterized. \n\n"}
{"id": "1404.2427", "contents": "Title: Projection onto simplicial cones by a semi-smooth Newton method Abstract: By using Moreau's decomposition theorem for projecting onto cones, the\nproblem of projecting onto a simplicial cone is reduced to finding the unique\nsolution of a nonsmooth system of equations. It is shown that a semi-smooth\nNewton method applied to the system of equations associated to the problem of\nprojecting onto a simplicial cone is always well defined, and the generated\nsequence is bounded for any starting point and under a somewhat restrictive\nassumption it is finite. Besides, under a mild assumption on the simplicial\ncone, the generated sequence converges linearly to the solution of the\nassociated system of equations. \n\n"}
{"id": "1404.3626", "contents": "Title: Optimal Power Flow as a Polynomial Optimization Problem Abstract: Formulating the alternating current optimal power flow (ACOPF) as a\npolynomial optimization problem makes it possible to solve large instances in\npractice and to guarantee asymptotic convergence in theory. \n\n"}
{"id": "1404.5222", "contents": "Title: Self-Averaging Property of Minimal Investment Risk of Mean-Variance\n  Model Abstract: In portfolio optimization problems, the minimum expected investment risk is\nnot always smaller than the expected minimal investment risk. That is, using a\nwell-known approach from operations research, it is possible to derive a\nstrategy that minimizes the expected investment risk, but this strategy does\nnot always result in the best rate of return on assets. Prior to making\ninvestment decisions, it is important to an investor to know the potential\nminimal investment risk (or the expected minimal investment risk) and to\ndetermine the strategy that will maximize the return on assets. We use the\nself-averaging property to analyze the potential minimal investment risk and\nthe concentrated investment level for the strategy that gives the best rate of\nreturn. We compare the results from our method with the results obtained by the\noperations research approach and with those obtained by a numerical simulation\nusing the optimal portfolio. The results of our method and the numerical\nsimulation are in agreement, but they differ from that of the operations\nresearch approach. \n\n"}
{"id": "1404.5350", "contents": "Title: On the Linear Convergence of the Approximate Proximal Splitting Method\n  for Non-Smooth Convex Optimization Abstract: Consider the problem of minimizing the sum of two convex functions, one being\nsmooth and the other non-smooth. In this paper, we introduce a general class of\napproximate proximal splitting (APS) methods for solving such minimization\nproblems. Methods in the APS class include many well-known algorithms such as\nthe proximal splitting method (PSM), the block coordinate descent method (BCD)\nand the approximate gradient projection methods for smooth convex optimization.\nWe establish the linear convergence of APS methods under a local error bound\nassumption. Since the latter is known to hold for compressive sensing and\nsparse group LASSO problems, our analysis implies the linear convergence of the\nBCD method for these problems without strong convexity assumption. \n\n"}
{"id": "1404.5699", "contents": "Title: Quantum Trajectories for a Class of Continuous Matrix Product Input\n  States Abstract: We introduce a new class of continuous matrix product (CMP) states and\nestablish the stochastic master equations (quantum filters) for an arbitrary\nquantum system probed by a bosonic input field in this class of states. We show\nthat this class of CMP states arise naturally as outputs of a Markovian model,\nand that input fields in these states lead to master and filtering (quantum\ntrajectory) equations which are matrix-valued. Furthermore, it is shown that\nthis class of continuous matrix product states include the (continuous-mode)\nsingle photon and time-ordered multi-photon states. \n\n"}
{"id": "1404.6213", "contents": "Title: Optimal Routing of Energy-aware Vehicles in Networks with Inhomogeneous\n  Charging Nodes Abstract: We study the routing problem for vehicles with limited energy through a\nnetwork of inhomogeneous charging nodes. This is substantially more complicated\nthan the homogeneous node case studied in [1]. We seek to minimize the total\nelapsed time for vehicles to reach their destinations considering both\ntraveling and recharging times at nodes when the vehicles do not have adequate\nenergy for the entire journey. We study two versions of the problem. In the\nsingle vehicle routing problem, we formulate a mixed-integer nonlinear\nprogramming (MINLP) problem and show that it can be reduced to a lower\ndimensionality problem by exploiting properties of an optimal solution. We also\nobtain a Linear Programming (LP) formulation allowing us to decompose it into\ntwo simpler problems yielding near-optimal solutions. For a multi-vehicle\nproblem, where traffic congestion effects are included, we use a similar\napproach by grouping vehicles into \"subflows\". We also provide an alternative\nflow optimization formulation leading to a computationally simpler problem\nsolution with minimal loss in accuracy. Numerical results are included to\nillustrate these approaches. \n\n"}
{"id": "1404.7665", "contents": "Title: On Submodularity and Controllability in Complex Dynamical Networks Abstract: Controllability and observability have long been recognized as fundamental\nstructural properties of dynamical systems, but have recently seen renewed\ninterest in the context of large, complex networks of dynamical systems. A\nbasic problem is sensor and actuator placement: choose a subset from a finite\nset of possible placements to optimize some real-valued controllability and\nobservability metrics of the network. Surprisingly little is known about the\nstructure of such combinatorial optimization problems. In this paper, we show\nthat several important classes of metrics based on the controllability and\nobservability Gramians have a strong structural property that allows for either\nefficient global optimization or an approximation guarantee by using a simple\ngreedy heuristic for their maximization. In particular, the mapping from\npossible placements to several scalar functions of the associated Gramian is\neither a modular or submodular set function. The results are illustrated on\nrandomly generated systems and on a problem of power electronic actuator\nplacement in a model of the European power grid. \n\n"}
{"id": "1405.0736", "contents": "Title: Boltzmann type control of opinion consensus through leaders Abstract: The study of formations and dynamics of opinions leading to the so called\nopinion consensus is one of the most important areas in mathematical modeling\nof social sciences. Following the Boltzmann type control recently introduced in\n[G. Albi, M. Herty, L. Pareschi arXiv:1401.7798], we consider a group of\nopinion leaders which modify their strategy accordingly to an objective\nfunctional with the aim to achieve opinion consensus. The main feature of the\nBoltzmann type control is that, thanks to an instantaneous binary control\nformulation, it permits to embed the minimization of the cost functional into\nthe microscopic leaders interactions of the corresponding Boltzmann equation.\nThe related Fokker-Planck asymptotic limits are also derived which allow to\ngive explicit expressions of stationary solutions. The results demonstrate the\nvalidity of the Boltzmann type control approach and the capability of the\nleaders control to strategically lead the followers opinion. \n\n"}
{"id": "1405.1303", "contents": "Title: Computing the permanent of (some) complex matrices Abstract: We present a deterministic algorithm, which, for any given 0< epsilon < 1 and\nan nxn real or complex matrix A=(a_{ij}) such that | a_{ij}-1| < 0.19 for all\ni, j computes the permanent of A within relative error epsilon in n^{O(ln n -ln\nepsilon)} time. The method can be extended to computing hafnians and\nmultidimensional permanents. \n\n"}
{"id": "1405.2301", "contents": "Title: On Farkas Lemma and Dimensional Rigidity of Bar Frameworks Abstract: We present a new semidefinite Farkas lemma involving a side constraint on the\nrank. This lemma is then used to present a new proof of a recent\ncharacterization, by Connelly and Gortler, of dimensional rigidity of bar\nframeworks. \n\n"}
{"id": "1405.2996", "contents": "Title: Noether's Theorem with Momentum and Energy Terms for Cresson's Quantum\n  Variational Problems Abstract: We prove a DuBois-Reymond necessary optimality condition and a Noether\nsymmetry theorem to the recent quantum variational calculus of Cresson. The\nresults are valid for problems of the calculus of variations with functionals\ndefined on sets of nondifferentiable functions. As an application, we obtain a\nconstant of motion for a linear Schrodinger equation. \n\n"}
{"id": "1405.3133", "contents": "Title: Graph Matching: Relax at Your Own Risk Abstract: Graph matching---aligning a pair of graphs to minimize their edge\ndisagreements---has received wide-spread attention from both theoretical and\napplied communities over the past several decades, including combinatorics,\ncomputer vision, and connectomics. Its attention can be partially attributed to\nits computational difficulty. Although many heuristics have previously been\nproposed in the literature to approximately solve graph matching, very few have\nany theoretical support for their performance. A common technique is to relax\nthe discrete problem to a continuous problem, therefore enabling practitioners\nto bring gradient-descent-type algorithms to bear. We prove that an indefinite\nrelaxation (when solved exactly) almost always discovers the optimal\npermutation, while a common convex relaxation almost always fails to discover\nthe optimal permutation. These theoretical results suggest that initializing\nthe indefinite algorithm with the convex optimum might yield improved practical\nperformance. Indeed, experimental results illuminate and corroborate these\ntheoretical findings, demonstrating that excellent results are achieved in both\nbenchmark and real data problems by amalgamating the two approaches. \n\n"}
{"id": "1405.3480", "contents": "Title: Numerical approximation of phase field based shape and topology\n  optimization for fluids Abstract: We consider the problem of finding optimal shapes of fluid domains. The fluid\nobeys the Navier--Stokes equations. Inside a holdall container we use a phase\nfield approach using diffuse interfaces to describe the domain of free flow. We\nformulate a corresponding optimization problem where flow outside the fluid\ndomain is penalized. The resulting formulation of the shape optimization\nproblem is shown to be well-posed, hence there exists a minimizer, and first\norder optimality conditions are derived.\n  For the numerical realization we introduce a mass conserving gradient flow\nand obtain a Cahn--Hilliard type system, which is integrated numerically using\nthe finite element method. An adaptive concept using reliable, residual based\nerror estimation is exploited for the resolution of the spatial mesh.\n  The overall concept is numerically investigated and comparison values are\nprovided. \n\n"}
{"id": "1405.4161", "contents": "Title: Long and winding central paths Abstract: We disprove a continuous analogue of the Hirsch conjecture proposed by Deza,\nTerlaky and Zinchenko, by constructing a family of linear programs with $3r+4$\ninequalities in dimension $2r+2$ where the central path has a total curvature\nin $\\Omega(2^r)$. Our method is to tropicalize the central path in linear\nprogramming. The tropical central path is the piecewise-linear limit of the\ncentral paths of parameterized families of classical linear programs viewed\nthrough logarithmic glasses. The lower bound for the classical curvature is\nobtained by developing a combinatorial concept of a tropical angle. \n\n"}
{"id": "1405.5498", "contents": "Title: A Comparison of Monte Carlo Tree Search and Mathematical Optimization\n  for Large Scale Dynamic Resource Allocation Abstract: Dynamic resource allocation (DRA) problems are an important class of dynamic\nstochastic optimization problems that arise in a variety of important\nreal-world applications. DRA problems are notoriously difficult to solve to\noptimality since they frequently combine stochastic elements with intractably\nlarge state and action spaces. Although the artificial intelligence and\noperations research communities have independently proposed two successful\nframeworks for solving dynamic stochastic optimization problems---Monte Carlo\ntree search (MCTS) and mathematical optimization (MO), respectively---the\nrelative merits of these two approaches are not well understood. In this paper,\nwe adapt both MCTS and MO to a problem inspired by tactical wildfire and\nmanagement and undertake an extensive computational study comparing the two\nmethods on large scale instances in terms of both the state and the action\nspaces. We show that both methods are able to greatly improve on a baseline,\nproblem-specific heuristic. On smaller instances, the MCTS and MO approaches\nperform comparably, but the MO approach outperforms MCTS as the size of the\nproblem increases for a fixed computational budget. \n\n"}
{"id": "1405.5960", "contents": "Title: LASS: a simple assignment model with Laplacian smoothing Abstract: We consider the problem of learning soft assignments of $N$ items to $K$\ncategories given two sources of information: an item-category similarity\nmatrix, which encourages items to be assigned to categories they are similar to\n(and to not be assigned to categories they are dissimilar to), and an item-item\nsimilarity matrix, which encourages similar items to have similar assignments.\nWe propose a simple quadratic programming model that captures this intuition.\nWe give necessary conditions for its solution to be unique, define an\nout-of-sample mapping, and derive a simple, effective training algorithm based\non the alternating direction method of multipliers. The model predicts\nreasonable assignments from even a few similarity values, and can be seen as a\ngeneralization of semisupervised learning. It is particularly useful when items\nnaturally belong to multiple categories, as for example when annotating\ndocuments with keywords or pictures with tags, with partially tagged items, or\nwhen the categories have complex interrelations (e.g. hierarchical) that are\nunknown. \n\n"}
{"id": "1405.5988", "contents": "Title: Minimal proper non-IRUP instances of the one-dimensional Cutting Stock\n  Problem Abstract: We consider the well-known one dimensional cutting stock problem (1CSP).\nBased on the pattern structure of the classical ILP formulation of Gilmore and\nGomory, we can decompose the infinite set of 1CSP instances, with a fixed\ndemand n, into a finite number of equivalence classes. We show up a strong\nrelation to weighted simple games. Studying the integer round-up property we\ncomputationally show that all 1CSP instances with $n\\le 9$ are proper IRUP,\nwhile we give examples of a proper non-IRUP instances with $n=10$. A gap larger\nthan 1 occurs for $n=11$. The worst known gap is raised from 1.003 to 1.0625.\nThe used algorithmic approaches are based on exhaustive enumeration and integer\nlinear programming. Additionally we give some theoretical bounds showing that\nall 1CSP instances with some specific parameters have the proper IRUP. \n\n"}
{"id": "1405.7121", "contents": "Title: Strict Fej\\'er Monotonicity by Superiorization of Feasibility-Seeking\n  Projection Methods Abstract: We consider the superiorization methodology, which can be thought of as lying\nbetween feasibility-seeking and constrained minimization. It is not quite\ntrying to solve the full fledged constrained minimization problem; rather, the\ntask is to find a feasible point which is superior (with respect to the\nobjective function value) to one returned by a feasibility-seeking only\nalgorithm. Our main result reveals new information about the mathematical\nbehavior of the superiorization methodology. We deal with a constrained\nminimization problem with a feasible region, which is the intersection of\nfinitely many closed convex constraint sets, and use the dynamic\nstring-averaging projection method, with variable strings and variable weights,\nas a feasibility-seeking algorithm. We show that any sequence, generated by the\nsuperiorized version of a dynamic string-averaging projection algorithm, not\nonly converges to a feasible point but, additionally, either its limit point\nsolves the constrained minimization problem or the sequence is strictly Fej\\'er\nmonotone with respect to a subset of the solution set of the original problem. \n\n"}
{"id": "1406.0026", "contents": "Title: Multi-marginal optimal transport: theory and applications Abstract: Over the past five years, multi-marginal optimal transport, a generalization\nof the well known optimal transport problem of Monge and Kantorovich, has begun\nto attract considerable attention, due in part to a wide variety of emerging\napplications. Here, we survey this problem, addressing fundamental theoretical\nquestions including the uniqueness and structure of solutions. The (partial)\nanswers to these questions uncover a surprising divergence from the classical\ntwo marginal setting, and reflect a delicate dependence on the cost function.\nWe go one to describe two applications of the multi-marginal problem. \n\n"}
{"id": "1406.4454", "contents": "Title: An Improved Approximation Algorithm for the Hard Uniform Capacitated\n  k-median Problem Abstract: In the $k$-median problem, given a set of locations, the goal is to select a\nsubset of at most $k$ centers so as to minimize the total cost of connecting\neach location to its nearest center. We study the uniform hard capacitated\nversion of the $k$-median problem, in which each selected center can only serve\na limited number of locations.\n  Inspired by the algorithm of Charikar, Guha, Tardos and Shmoys, we give a\n$(6+10\\alpha)$-approximation algorithm for this problem with increasing the\ncapacities by a factor of $2+\\frac{2}{\\alpha}, \\alpha\\geq 4$, which improves\nthe previous best $(32 l^2+28 l+7)$-approximation algorithm proposed by Byrka,\nFleszar, Rybicki and Spoerhase violating the capacities by factor\n$2+\\frac{3}{l-1}, l\\in \\{2,3,4,\\dots\\}$. \n\n"}
{"id": "1406.4599", "contents": "Title: On the generalization of linear least mean squares estimation to quantum\n  systems with non-commutative outputs Abstract: The purpose of this paper is to study the problem of generalizing the\nBelavkin-Kalman filter to the case where the classical measurement signal is\nreplaced by a fully quantum non-commutative output signal. We formulate a least\nmean squares estimation problem that involves a non-commutative system as the\nfilter processing the non-commutative output signal. We solve this estimation\nproblem within the framework of non-commutative probability. Also, we find the\nnecessary and sufficient conditions which make these non-commutative estimators\nphysically realizable. These conditions are restrictive in practice. \n\n"}
{"id": "1406.5231", "contents": "Title: Reducing Basis Mismatch in Harmonic Signal Recovery via Alternating\n  Convex Search Abstract: The theory behind compressive sampling pre-supposes that a given sequence of\nobservations may be exactly represented by a linear combination of a small\nnumber of basis vectors. In practice, however, even small deviations from an\nexact signal model can result in dramatic increases in estimation error; this\nis the so-called \"basis mismatch\" problem. This work provides one possible\nsolution to this problem in the form of an iterative, biconvex search\nalgorithm. The approach uses standard $\\ell_1$-minimization to find the signal\nmodel coefficients followed by a maximum likelihood estimate of the signal\nmodel. The algorithm is illustrated on harmonic signals of varying sparsity and\noutperforms the current state-of-the-art. \n\n"}
{"id": "1406.5295", "contents": "Title: Rows vs Columns for Linear Systems of Equations - Randomized Kaczmarz or\n  Coordinate Descent? Abstract: This paper is about randomized iterative algorithms for solving a linear\nsystem of equations $X \\beta = y$ in different settings. Recent interest in the\ntopic was reignited when Strohmer and Vershynin (2009) proved the linear\nconvergence rate of a Randomized Kaczmarz (RK) algorithm that works on the rows\nof $X$ (data points). Following that, Leventhal and Lewis (2010) proved the\nlinear convergence of a Randomized Coordinate Descent (RCD) algorithm that\nworks on the columns of $X$ (features). The aim of this paper is to simplify\nour understanding of these two algorithms, establish the direct relationships\nbetween them (though RK is often compared to Stochastic Gradient Descent), and\nexamine the algorithmic commonalities or tradeoffs involved with working on\nrows or columns. We also discuss Kernel Ridge Regression and present a\nKaczmarz-style algorithm that works on data points and having the advantage of\nsolving the problem without ever storing or forming the Gram matrix, one of the\nrecognized problems encountered when scaling kernelized methods. \n\n"}
{"id": "1406.6406", "contents": "Title: Variational Inequality Approach to Stochastic Nash Equilibrium Problems\n  with an Application to Cournot Oligopoly Abstract: In this note we investigate stochastic Nash equilibrium problems by means of\nmonotone variational inequalities in probabilistic Lebesgue spaces. We apply\nour approach to a class of oligopolistic market equilibrium problems where the\ndata are known through their probability distributions. \n\n"}
{"id": "1407.0214", "contents": "Title: A hybrid proximal-extragradient algorithm with inertial effects Abstract: We incorporate inertial terms in the hybrid proximal-extragradient algorithm\nand investigate the convergence properties of the resulting iterative scheme\ndesigned for finding the zeros of a maximally monotone operator in real Hilbert\nspaces. The convergence analysis relies on extended Fej\\'er monotonicity\ntechniques combined with the celebrated Opial Lemma. We also show that the\nclassical hybrid proximal-extragradient algorithm and the inertial versions of\nthe proximal point, the forward-backward and the forward-backward-forward\nalgorithms can be embedded in the framework of the proposed iterative scheme. \n\n"}
{"id": "1407.2108", "contents": "Title: An error analysis for polynomial optimization over the simplex based on\n  the multivariate hypergeometric distribution Abstract: We study the minimization of fixed-degree polynomials over the simplex. This\nproblem is well-known to be NP-hard, as it contains the maximum stable set\nproblem in graph theory as a special case. In this paper, we consider a\nrational approximation by taking the minimum over the regular grid, which\nconsists of rational points with denominator $r$ (for given $r$). We show that\nthe associated convergence rate is $O(1/r^2)$ for quadratic polynomials. For\ngeneral polynomials, if there exists a rational global minimizer over the\nsimplex, we show that the convergence rate is also of the order $O(1/r^2)$. Our\nresults answer a question posed by De Klerk et al. (2013) and improves on\npreviously known $O(1/r)$ bounds in the quadratic case. \n\n"}
{"id": "1407.3087", "contents": "Title: Mean curvature bounds and eigenvalues of Robin Laplacians Abstract: We consider the Laplacian with attractive Robin boundary conditions, \\[\nQ^\\Omega_\\alpha u=-\\Delta u, \\quad \\dfrac{\\partial u}{\\partial n}=\\alpha u\n\\text{ on } \\partial\\Omega, \\] in a class of bounded smooth domains\n$\\Omega\\in\\mathbb{R}^\\nu$; here $n$ is the outward unit normal and $\\alpha>0$\nis a constant. We show that for each $j\\in\\mathbb{N}$ and $\\alpha\\to+\\infty$,\nthe $j$th eigenvalue $E_j(Q^\\Omega_\\alpha)$ has the asymptotics \\[\nE_j(Q^\\Omega_\\alpha)=-\\alpha^2 -(\\nu-1)H_\\mathrm{max}(\\Omega)\\,\\alpha+{\\mathcal\nO}(\\alpha^{2/3}), \\] where $H_\\mathrm{max}(\\Omega)$ is the maximum mean\ncurvature at $\\partial \\Omega$. The discussion of the reverse Faber-Krahn\ninequality gives rise to a new geometric problem concerning the minimization of\n$H_\\mathrm{max}$. In particular, we show that the ball is the strict minimizer\nof $H_\\mathrm{max}$ among the smooth star-shaped domains of a given volume,\nwhich leads to the following result: if $B$ is a ball and $\\Omega$ is any other\nstar-shaped smooth domain of the same volume, then for any fixed\n$j\\in\\mathbb{N}$ we have $E_j(Q^B_\\alpha)>E_j(Q^\\Omega_\\alpha)$ for large\n$\\alpha$. An open question concerning a larger class of domains is formulated. \n\n"}
{"id": "1407.3437", "contents": "Title: High-order maximum principles for the stability analysis of positive\n  bilinear control systems Abstract: We consider a continuous-time positive bilinear control system (PBCS), i.e. a\nbilinear control system with Metzler matrices. The positive orthant is an\ninvariant set of such a system, and the corresponding transition matrix C(t) is\nentrywise nonnegative for all time t>0. Motivated by the stability analysis of\npositive linear switched systems (PLSSs) under arbitrary switching laws, we fix\na final time T>0 and define a control as optimal if it maximizes the spectral\nradius of C(T). A recent paper developed a first-order necessary condition for\noptimality in the form of a maximum principle (MP). In this paper, we derive\nhigher-order necessary conditions for optimality for both singular and\nbang-bang controls. Our approach is based on combining results on the\nsecond-order derivative of the spectral radius of a nonnegative matrix with the\ngeneralized Legendre-Clebsch condition and the Agrachev-Gamkrelidze\nsecond-order optimality condition. \n\n"}
{"id": "1407.5210", "contents": "Title: Faster convergence rates of relaxed Peaceman-Rachford and ADMM under\n  regularity assumptions Abstract: Splitting schemes are a class of powerful algorithms that solve complicated\nmonotone inclusion and convex optimization problems that are built from many\nsimpler pieces. They give rise to algorithms in which the simple pieces of the\ndecomposition are processed individually. This leads to easily implementable\nand highly parallelizable algorithms, which often obtain nearly\nstate-of-the-art performance.\n  In this paper, we provide a comprehensive convergence rate analysis of the\nDouglas-Rachford splitting (DRS), Peaceman-Rachford splitting (PRS), and\nalternating direction method of multipliers (ADMM) algorithms under various\nregularity assumptions including strong convexity, Lipschitz differentiability,\nand bounded linear regularity. The main consequence of this work is that\nrelaxed PRS and ADMM automatically adapt to the regularity of the problem and\nachieve convergence rates that improve upon the (tight) worst-case rates that\nhold in the absence of such regularity. All of the results are obtained using\nsimple techniques. \n\n"}
{"id": "1407.6267", "contents": "Title: Learning in games via reinforcement and regularization Abstract: We investigate a class of reinforcement learning dynamics where players\nadjust their strategies based on their actions' cumulative payoffs over time -\nspecifically, by playing mixed strategies that maximize their expected\ncumulative payoff minus a regularization term. A widely studied example is\nexponential reinforcement learning, a process induced by an entropic\nregularization term which leads mixed strategies to evolve according to the\nreplicator dynamics. However, in contrast to the class of regularization\nfunctions used to define smooth best responses in models of stochastic\nfictitious play, the functions used in this paper need not be infinitely steep\nat the boundary of the simplex; in fact, dropping this requirement gives rise\nto an important dichotomy between steep and nonsteep cases. In this general\nframework, we extend several properties of exponential learning, including the\nelimination of dominated strategies, the asymptotic stability of strict Nash\nequilibria, and the convergence of time-averaged trajectories in zero-sum games\nwith an interior Nash equilibrium. \n\n"}
{"id": "1407.7220", "contents": "Title: A Parallel Method for Large Scale Convex Regression Problems Abstract: Convex regression (CR) problem deals with fitting a convex function to a\nfinite number of observations. It has many applications in various disciplines,\nsuch as statistics, economics, operations research, and electrical engineering.\nComputing the least squares (LS) estimator via solving a quadratic program (QP)\nis the most common technique to fit a piecewise-linear convex function to the\nobserved data. Since the number of constraints in the QP formulation increases\nquadratically in N, the number of observed data points, computing the LS\nestimator is not practical using interior point methods when N is very large.\nThe first-order method proposed in this paper carefully manages the memory\nusage through parallelization, and efficiently solves large-scale instances of\nCR. \n\n"}
{"id": "1407.7839", "contents": "Title: Semiampleness criteria for divisors on $\\overline M_{0,n}$ Abstract: We develop new characteristic-independent combinatorial criteria for\nsemiampleness of divisors on $\\overline{M}_{0,n}$. As an application, we\nassociate to a cyclic rational quadratic form satisfying a certain balancedness\ncondition an infinite sequence of semiample line bundles. We also give several\nsufficient and effective conditions for a symmetric divisor on\n$\\overline{M}_{0,n}$ to be semiample or nef. \n\n"}
{"id": "1408.0173", "contents": "Title: Variational Depth from Focus Reconstruction Abstract: This paper deals with the problem of reconstructing a depth map from a\nsequence of differently focused images, also known as depth from focus or shape\nfrom focus. We propose to state the depth from focus problem as a variational\nproblem including a smooth but nonconvex data fidelity term, and a convex\nnonsmooth regularization, which makes the method robust to noise and leads to\nmore realistic depth maps. Additionally, we propose to solve the nonconvex\nminimization problem with a linearized alternating directions method of\nmultipliers (ADMM), allowing to minimize the energy very efficiently. A\nnumerical comparison to classical methods on simulated as well as on real data\nis presented. \n\n"}
{"id": "1408.1434", "contents": "Title: Controlling of clock synchronization in WSNs: structure of optimal\n  solutions Abstract: Energy-saving optimization is very important for various engineering problems\nrelated to modern distributed systems. We consider here a control problem for a\nwireless sensor network with a single time server node and a large number of\nclient nodes. The problem is to minimize a functional which accumulates clock\nsynchronization errors in the clients nodes and the energy consumption of the\nserver over some time interval $[0,T]$. The control function $u=u(t)$, $0\\leq\nu(t)\\leq u_{1}$, corresponds to the power of the server node transmitting\nsynchronization signals to the clients. For all possible parameter values we\nfind the structure of optimal trajectories. We show that for sufficiently large\n$u_{1}$ the solutions contain singular arcs. \n\n"}
{"id": "1408.2416", "contents": "Title: Invariance Entropy of Hyperbolic Control Sets Abstract: In this paper, we improve the known estimates for the invariance entropy of a\nnonlinear control system. For sets of complete approximate controllability we\nderive an upper bound in terms of Lyapunov exponents and for uniformly\nhyperbolic sets we obtain a similar lower bound. Both estimates can be applied\nto hyperbolic chain control sets, and we prove that under mild assumptions they\ncan be merged into a formula. \n\n"}
{"id": "1408.3229", "contents": "Title: Robustness of the nonlinear PI control method to ignored actuator\n  dynamics Abstract: This note examines the robustness properties of the nonlinear PI control\nmethod to ignored actuator dynamics. It is proven that global boundedness and\nregulation can be achieved for sector bounded nonlinear systems with unknown\ncontrol directions if the actuator dynamics are sufficiently fast and the\nnonlinear PI control gain is chosen from a subclass of the Nussbaum function\nclass. Simulation examples are also presented that demonstrate the validity of\nour arguments. \n\n"}
{"id": "1408.4184", "contents": "Title: Quadratic diameter bounds for dual network flow polyhedra Abstract: Both the combinatorial and the circuit diameters of polyhedra are of interest\nto the theory of linear programming for their intimate connection to a\nbest-case performance of linear programming algorithms.\n  We study the diameters of dual network flow polyhedra associated to $b$-flows\non directed graphs $G=(V,E)$ and prove quadratic upper bounds for both of them:\nthe minimum of $(|V|-1)\\cdot |E|$ and $\\frac{1}{6}|V|^3$ for the combinatorial\ndiameter, and $\\frac{|V|\\cdot (|V|-1)}{2}$ for the circuit diameter. The latter\nstrengthens the cubic bound implied by a result in [De Loera, Hemmecke, Lee;\n2014].\n  Previously, bounds on these diameters have only been known for bipartite\ngraphs. The situation is much more involved for general graphs. In particular,\nwe construct a family of dual network flow polyhedra with members that violate\nthe circuit diameter bound for bipartite graphs by an arbitrary additive\nconstant. Further, it provides examples of circuit diameter $\\frac{4}{3}|V| -\n4$. \n\n"}
{"id": "1408.5370", "contents": "Title: Numerical studies of the optimization of the first eigenvalue of the\n  heat diffusion in inhomogeneous media Abstract: In this paper, we study optimization of the first eigenvalue of the heat\nequation with spatially nonuniform conductivity on a bounded domain under\nseveral constraints for the conductivity. We consider this problem in various\nboundary conditions and various type of topology of domains. As a result, we\nnumerically observe several common criteria of the conductivity for optimizing\neigenvalues in terms of corresponding eigenfunctions, which are independent of\ntopology of domains and boundary conditions. The geometric characterization of\noptimizers are also numerically observed. \n\n"}
{"id": "1408.6799", "contents": "Title: Stochastic Perron for stochastic target games Abstract: We extend the stochastic Perron method to analyze the framework of stochastic\ntarget games, in which one player tries to find a strategy such that the state\nprocess almost surely reaches a given target no matter which action is chosen\nby the other player. Within this framework, our method produces a viscosity\nsub-solution (super-solution) of a Hamilton-Jacobi-Bellman (HJB) equation. We\nthen characterize the value function as a viscosity solution to the HJB\nequation using a comparison result and a byproduct to obtain the dynamic\nprogramming principle. \n\n"}
{"id": "1409.1462", "contents": "Title: Iteration complexity analysis of dual first order methods for conic\n  convex programming Abstract: In this paper we provide a detailed analysis of the iteration complexity of\ndual first order methods for solving conic convex problems. When it is\ndifficult to project on the primal feasible set described by convex\nconstraints, we use the Lagrangian relaxation to handle the complicated\nconstraints and then, we apply dual first order algorithms for solving the\ncorresponding dual problem. We give convergence analysis for dual first order\nalgorithms (dual gradient and fast gradient algorithms): we provide sublinear\nor linear estimates on the primal suboptimality and feasibility violation of\nthe generated approximate primal solutions. Our analysis relies on the\nLipschitz property of the gradient of the dual function or an error bound\nproperty of the dual. Furthermore, the iteration complexity analysis is based\non two types of approximate primal solutions: the last primal iterate or an\naverage primal sequence. \n\n"}
{"id": "1409.2594", "contents": "Title: A Direct Coupling Coherent Quantum Observer for a Single Qubit Finite\n  Level Quantum System Abstract: This paper considers the problem of constructing a direct coupling quantum\nobserver for a single qubit finite level quantum system plant. The proposed\nobserver is a single mode linear quantum system which is shown to be able to\nestimate one of the plant variables in a time averaged sense. A numerical\nexample and simulations are included to illustrate the properties of the\nobserver. \n\n"}
{"id": "1409.2617", "contents": "Title: Large-scale randomized-coordinate descent methods with non-separable\n  linear constraints Abstract: We develop randomized (block) coordinate descent (CD) methods for linearly\nconstrained convex optimization. Unlike most CD methods, we do not assume the\nconstraints to be separable, but let them be coupled linearly. To our\nknowledge, ours is the first CD method that allows linear coupling constraints,\nwithout making the global iteration complexity have an exponential dependence\non the number of constraints. We present algorithms and analysis for four key\nproblem scenarios: (i) smooth; (ii) smooth + nonsmooth separable; (iii)\nasynchronous parallel; and (iv) stochastic. We illustrate empirical behavior of\nour algorithms by simulation experiments. \n\n"}
{"id": "1409.2848", "contents": "Title: A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate Abstract: We describe and analyze a simple algorithm for principal component analysis\nand singular value decomposition, VR-PCA, which uses computationally cheap\nstochastic iterations, yet converges exponentially fast to the optimal\nsolution. In contrast, existing algorithms suffer either from slow convergence,\nor computationally intensive iterations whose runtime scales with the data\nsize. The algorithm builds on a recent variance-reduced stochastic gradient\ntechnique, which was previously analyzed for strongly convex optimization,\nwhereas here we apply it to an inherently non-convex problem, using a very\ndifferent analysis. \n\n"}
{"id": "1409.3496", "contents": "Title: Cost effectiveness analysis of optimal control measures for tuberculosis Abstract: We propose and analyse an optimal control problem where the control system is\na mathematical model for tuberculosis that considers reinfection. The control\nfunctions represent the fraction of early latent and persistent latent\nindividuals that are treated. Our aim is to study how these control measures\nshould be implemented, for a certain time period, in order to reduce the number\nof active infected individuals, while minimizing the interventions\nimplementation costs. The optimal intervention is compared along different\nepidemiological scenarios, by varying the transmission coefficient. The impact\nof variation of the risk of reinfection, as a result of acquired immunity to a\nprevious infection for treated individuals on the optimal controls and\nassociated solutions, is analysed. A cost-effectiveness analysis is done, to\ncompare the application of each one of the control measures, separately or in\ncombination. \n\n"}
{"id": "1409.4320", "contents": "Title: Self-Dictionary Sparse Regression for Hyperspectral Unmixing: Greedy\n  Pursuit and Pure Pixel Search are Related Abstract: This paper considers a recently emerged hyperspectral unmixing formulation\nbased on sparse regression of a self-dictionary multiple measurement vector\n(SD-MMV) model, wherein the measured hyperspectral pixels are used as the\ndictionary. Operating under the pure pixel assumption, this SD-MMV formalism is\nspecial in that it allows simultaneous identification of the endmember spectral\nsignatures and the number of endmembers. Previous SD-MMV studies mainly focus\non convex relaxations. In this study, we explore the alternative of greedy\npursuit, which generally provides efficient and simple algorithms. In\nparticular, we design a greedy SD-MMV algorithm using simultaneous orthogonal\nmatching pursuit. Intriguingly, the proposed greedy algorithm is shown to be\nclosely related to some existing pure pixel search algorithms, especially, the\nsuccessive projection algorithm (SPA). Thus, a link between SD-MMV and pure\npixel search is revealed. We then perform exact recovery analyses, and prove\nthat the proposed greedy algorithm is robust to noise---including its\nidentification of the (unknown) number of endmembers---under a sufficiently low\nnoise level. The identification performance of the proposed greedy algorithm is\ndemonstrated through both synthetic and real-data experiments. \n\n"}
{"id": "1409.6086", "contents": "Title: Parallel and Distributed Block-Coordinate Frank-Wolfe Algorithms Abstract: We develop parallel and distributed Frank-Wolfe algorithms; the former on\nshared memory machines with mini-batching, and the latter in a delayed update\nframework. Whenever possible, we perform computations asynchronously, which\nhelps attain speedups on multicore machines as well as in distributed\nenvironments. Moreover, instead of worst-case bounded delays, our methods only\ndepend (mildly) on \\emph{expected} delays, allowing them to be robust to\nstragglers and faulty worker threads. Our algorithms assume block-separable\nconstraints, and subsume the recent Block-Coordinate Frank-Wolfe (BCFW)\nmethod~\\citep{lacoste2013block}. Our analysis reveals problem-dependent\nquantities that govern the speedups of our methods over BCFW. We present\nexperiments on structural SVM and Group Fused Lasso, obtaining significant\nspeedups over competing state-of-the-art (and synchronous) methods. \n\n"}
{"id": "1409.6404", "contents": "Title: Localized LQR Optimal Control Abstract: This paper introduces a receding horizon like control scheme for localizable\ndistributed systems, in which the effect of each local disturbance is limited\nspatially and temporally. We characterize such systems by a set of linear\nequality constraints, and show that the resulting feasibility test can be\nsolved in a localized and distributed way. We also show that the solution of\nthe local feasibility tests can be used to synthesize a receding horizon like\ncontroller that achieves the desired closed loop response in a localized manner\nas well. Finally, we formulate the Localized LQR (LLQR) optimal control problem\nand derive an analytic solution for the optimal controller. Through a numerical\nexample, we show that the LLQR optimal controller, with its constraints on\nlocality, settling time, and communication delay, can achieve similar\nperformance as an unconstrained H2 optimal controller, but can be designed and\nimplemented in a localized and distributed way. \n\n"}
{"id": "1409.6731", "contents": "Title: On the risk-sensitive escape control for diffusion processes pertaining\n  to an expanding construction of distributed control systems Abstract: In this paper, we consider an expanding construction of a distributed control\nsystem, which is obtained by adding a new subsystem one after the other, until\nall $n$ subsystems, where $n \\ge 2$, are included in the distributed control\nsystem. It is assumed that a small random perturbation enters only into the\nfirst subsystem and is then subsequently transmitted to the other subsystems.\nMoreover, for any $\\ell \\in \\{2, ..., n\\}$, the distributed control system,\ncompatible with the expanding construction, which is obtained from the first\n$\\ell$ subsystems, satisfies an appropriate H\\\"{o}rmander condition. As a\nresult of this, the diffusion process is degenerate, i.e., the backward\noperator associated with it is a degenerate parabolic equation. Our main\ninterest here is to prevent the diffusion process (that corresponds to a\nparticular subsystem) from leaving a given bounded open domain. In particular,\nwe consider a risk-sensitive version of the mean escape time criterion with\nrespect to each of the subsystems. Using a variational representation, we\ncharacterize the risk-sensitive escape control for the diffusion process as the\nlower and upper values of an associated stochastic differential game. Finally,\nwe comment on the implication of our results, where one is also interested in\nevaluating the performance of the risk-sensitive escape control, when there is\nsome modeling error in the distributed control system. \n\n"}
{"id": "1409.6773", "contents": "Title: On a Stopping Game in continuous time Abstract: We consider a zero-sum continuous time stopping game in which the pay-off is\nrevealed in the maximum of the two stopping times instead of the minimum, which\nis the case in Dynkin games. \n\n"}
{"id": "1409.7345", "contents": "Title: Translation invariant mean field games with common noise Abstract: This note highlights a special class of mean field games in which the\ncoefficients satisfy a convolution-type structural condition. A mean field game\nof this type with common noise is related to a certain mean field game without\ncommon noise by a simple transformation, which permits a tractable construction\nof a solution of the problem with common noise from a solution of the problem\nwithout. \n\n"}
{"id": "1409.8033", "contents": "Title: On the Convergence of Alternating Direction Lagrangian Methods for\n  Nonconvex Structured Optimization Problems Abstract: Nonconvex and structured optimization problems arise in many engineering\napplications that demand scalable and distributed solution methods. The study\nof the convergence properties of these methods is in general difficult due to\nthe nonconvexity of the problem. In this paper, two distributed solution\nmethods that combine the fast convergence properties of augmented\nLagrangian-based methods with the separability properties of alternating\noptimization are investigated. The first method is adapted from the classic\nquadratic penalty function method and is called the Alternating Direction\nPenalty Method (ADPM). Unlike the original quadratic penalty function method,\nin which single-step optimizations are adopted, ADPM uses an alternating\noptimization, which in turn makes it scalable. The second method is the\nwell-known Alternating Direction Method of Multipliers (ADMM). It is shown that\nADPM for nonconvex problems asymptotically converges to a primal feasible point\nunder mild conditions and an additional condition ensuring that it\nasymptotically reaches the standard first order necessary conditions for local\noptimality are introduced. In the case of the ADMM, novel sufficient conditions\nunder which the algorithm asymptotically reaches the standard first order\nnecessary conditions are established. Based on this, complete convergence of\nADMM for a class of low dimensional problems are characterized. Finally, the\nresults are illustrated by applying ADPM and ADMM to a nonconvex localization\nproblem in wireless sensor networks. \n\n"}
{"id": "1409.8444", "contents": "Title: Douglas-Rachford splitting for nonconvex optimization with application\n  to nonconvex feasibility problems Abstract: We adapt the Douglas-Rachford (DR) splitting method to solve nonconvex\nfeasibility problems by studying this method for a class of nonconvex\noptimization problem. While the convergence properties of the method for convex\nproblems have been well studied, far less is known in the nonconvex setting. In\nthis paper, for the direct adaptation of the method to minimize the sum of a\nproper closed function $g$ and a smooth function $f$ with a Lipschitz\ncontinuous gradient, we show that if the step-size parameter is smaller than a\ncomputable threshold and the sequence generated has a cluster point, then it\ngives a stationary point of the optimization problem. Convergence of the whole\nsequence and a local convergence rate are also established under the additional\nassumption that $f$ and $g$ are semi-algebraic. We also give simple sufficient\nconditions guaranteeing the boundedness of the sequence generated. We then\napply our nonconvex DR splitting method to finding a point in the intersection\nof a closed convex set $C$ and a general closed set $D$ by minimizing the\nsquared distance to $C$ subject to $D$. We show that if either set is bounded\nand the step-size parameter is smaller than a computable threshold, then the\nsequence generated from the DR splitting method is actually bounded.\nConsequently, the sequence generated will have cluster points that are\nstationary for an optimization problem, and the whole sequence is convergent\nunder an additional assumption that $C$ and $D$ are semi-algebraic. We achieve\nthese results based on a new merit function constructed particularly for the DR\nsplitting method. Our preliminary numerical results indicate that our DR\nsplitting method usually outperforms the alternating projection method in\nfinding a sparse solution of a linear system, in terms of both the solution\nquality and the number of iterations taken. \n\n"}
{"id": "1410.0342", "contents": "Title: Generalized Low Rank Models Abstract: Principal components analysis (PCA) is a well-known technique for\napproximating a tabular data set by a low rank matrix. Here, we extend the idea\nof PCA to handle arbitrary data sets consisting of numerical, Boolean,\ncategorical, ordinal, and other data types. This framework encompasses many\nwell known techniques in data analysis, such as nonnegative matrix\nfactorization, matrix completion, sparse and robust PCA, $k$-means, $k$-SVD,\nand maximum margin matrix factorization. The method handles heterogeneous data\nsets, and leads to coherent schemes for compressing, denoising, and imputing\nmissing entries across all data types simultaneously. It also admits a number\nof interesting interpretations of the low rank factors, which allow clustering\nof examples or of features. We propose several parallel algorithms for fitting\ngeneralized low rank models, and describe implementations and numerical\nresults. \n\n"}
{"id": "1410.0719", "contents": "Title: Proceedings of the second \"international Traveling Workshop on\n  Interactions between Sparse models and Technology\" (iTWIST'14) Abstract: The implicit objective of the biennial \"international - Traveling Workshop on\nInteractions between Sparse models and Technology\" (iTWIST) is to foster\ncollaboration between international scientific teams by disseminating ideas\nthrough both specific oral/poster presentations and free discussions. For its\nsecond edition, the iTWIST workshop took place in the medieval and picturesque\ntown of Namur in Belgium, from Wednesday August 27th till Friday August 29th,\n2014. The workshop was conveniently located in \"The Arsenal\" building within\nwalking distance of both hotels and town center. iTWIST'14 has gathered about\n70 international participants and has featured 9 invited talks, 10 oral\npresentations, and 14 posters on the following themes, all related to the\ntheory, application and generalization of the \"sparsity paradigm\":\nSparsity-driven data sensing and processing; Union of low dimensional\nsubspaces; Beyond linear and convex inverse problem; Matrix/manifold/graph\nsensing/processing; Blind inverse problems and dictionary learning; Sparsity\nand computational neuroscience; Information theory, geometry and randomness;\nComplexity/accuracy tradeoffs in numerical methods; Sparsity? What's next?;\nSparse machine learning and inference. \n\n"}
{"id": "1410.0989", "contents": "Title: On the Effective Measure of Dimension in the Analysis Cosparse Model Abstract: Many applications have benefited remarkably from low-dimensional models in\nthe recent decade. The fact that many signals, though high dimensional, are\nintrinsically low dimensional has given the possibility to recover them stably\nfrom a relatively small number of their measurements. For example, in\ncompressed sensing with the standard (synthesis) sparsity prior and in matrix\ncompletion, the number of measurements needed is proportional (up to a\nlogarithmic factor) to the signal's manifold dimension.\n  Recently, a new natural low-dimensional signal model has been proposed: the\ncosparse analysis prior. In the noiseless case, it is possible to recover\nsignals from this model, using a combinatorial search, from a number of\nmeasurements proportional to the signal's manifold dimension. However, if we\nask for stability to noise or an efficient (polynomial complexity) solver, all\nthe existing results demand a number of measurements which is far removed from\nthe manifold dimension, sometimes far greater. Thus, it is natural to ask\nwhether this gap is a deficiency of the theory and the solvers, or if there\nexists a real barrier in recovering the cosparse signals by relying only on\ntheir manifold dimension. Is there an algorithm which, in the presence of\nnoise, can accurately recover a cosparse signal from a number of measurements\nproportional to the manifold dimension? In this work, we prove that there is no\nsuch algorithm. Further, we show through numerical simulations that even in the\nnoiseless case convex relaxations fail when the number of measurements is\ncomparable to the manifold dimension. This gives a practical counter-example to\nthe growing literature on compressed acquisition of signals based on manifold\ndimension. \n\n"}
{"id": "1410.1944", "contents": "Title: Adaptive Output Feedback based on Closed-loop Reference Models Abstract: This note presents the design and analysis of an adaptive controller for a\nclass of linear plants in the presence of output feedback. This controller\nmakes use of a closed-loop reference model as an observer, and guarantees\nglobal stability and asymptotic output tracking. \n\n"}
{"id": "1410.2228", "contents": "Title: Stability and continuity of functions of least gradient Abstract: In this note we prove that on metric measure spaces, functions of least\ngradient, as well as local minimizers of the area functional (after\nmodification on a set of measure zero) are continuous everywhere outside their\njump sets. As a tool, we develop some stability properties of sequences of\nleast gradient functions. We also apply these tools to prove a maximum\nprinciple for functions of least gradient that arise as solutions to a\nDirichlet problem. \n\n"}
{"id": "1410.4307", "contents": "Title: Social Learning and Distributed Hypothesis Testing Abstract: This paper considers a problem of distributed hypothesis testing and social\nlearning. Individual nodes in a network receive noisy local (private)\nobservations whose distribution is parameterized by a discrete parameter\n(hypotheses). The conditional distributions are known locally at the nodes, but\nthe true parameter/hypothesis is not known. An update rule is analyzed in which\nnodes first perform a Bayesian update of their belief (distribution estimate)\nof the parameter based on their local observation, communicate these updates to\ntheir neighbors, and then perform a \"non-Bayesian\" linear consensus using the\nlog-beliefs of their neighbors. In this paper we show that under mild\nassumptions, the belief of any node in any incorrect hypothesis converges to\nzero exponentially fast, and we characterize the exponential rate of learning\nwhich is given in terms of the network structure and the divergences between\nthe observations' distributions. Our main result is the concentration property\nestablished on the rate of convergence. \n\n"}
{"id": "1410.5076", "contents": "Title: A Parallel Stochastic Approximation Method for Nonconvex Multi-Agent\n  Optimization Problems Abstract: Consider the problem of minimizing the expected value of a (possibly\nnonconvex) cost function parameterized by a random (vector) variable, when the\nexpectation cannot be computed accurately (e.g., because the statistics of the\nrandom variables are unknown and/or the computational complexity is\nprohibitive). Classical sample stochastic gradient methods for solving this\nproblem may empirically suffer from slow convergence. In this paper, we propose\nfor the first time a stochastic parallel Successive Convex Approximation-based\n(best-response) algorithmic framework for general nonconvex stochastic\nsum-utility optimization problems, which arise naturally in the design of\nmulti-agent systems. The proposed novel decomposition enables all users to\nupdate their optimization variables in parallel by solving a sequence of\nstrongly convex subproblems, one for each user. Almost surely convergence to\nstationary points is proved. We then customize our algorithmic framework to\nsolve the stochastic sum rate maximization problem over\nSingle-Input-Single-Output (SISO) frequency-selective interference channels,\nmultiple-input-multiple-output (MIMO) interference channels, and MIMO\nmultiple-access channels. Numerical results show that our algorithms are much\nfaster than state-of-the-art stochastic gradient schemes while achieving the\nsame (or better) sum-rates. \n\n"}
{"id": "1410.5956", "contents": "Title: Stability Analysis and Control Synthesis for Dynamical Transportation\n  Networks Abstract: We study dynamical transportation networks in a framework that includes\nextensions of the classical Cell Transmission Model to arbitrary network\ntopologies. The dynamics are modeled as systems of ordinary differential\nequations describing the traffic flow among a finite number of cells\ninterpreted as links of a directed network. Flows between contiguous cells, in\nparticular at junctions, are determined by merging and splitting rules within\nconstraints imposed by the cells' demand and supply functions as well as by the\ndrivers' turning preferences, while inflows at on-ramps are modeled as\nexogenous and possibly time-varying.\n  First, we analyze stability properties of dynamical transportation networks.\nWe associate to the dynamics a state-dependent dual graph whose connectivity\ndepends on the signs of the derivatives of the inter-cell flows with respect to\nthe densities. Sufficient conditions for the stability of equilibria and\nperiodic solutions are then provided in terms of the connectivity of such dual\ngraph.\n  Then, we consider synthesis of control policies that use a combination of\nturning preferences, speed limits, and ramp metering, in order to optimize\nconvex objectives. We first show that, in the general case, the optimal control\nsynthesis problem can be cast as a convex optimization problem, and that the\nequilibrium of the controlled network is in free-flow. If the control policies\nare restricted to speed limits and ramp metering, then the resulting synthesis\nproblem is still convex for networks where every node is either a merge or a\ndiverge junction, and where the dynamics is monotone. These results apply both\nto the optimal selection of equilibria and periodic solutions, as well as to\nfinite-horizon network trajectory optimization.\n  Finally, we illustrate our findings through simulations on a road network\ninspired by the freeway system in southern Los Angeles. \n\n"}
{"id": "1410.7596", "contents": "Title: Fast Algorithms for Online Stochastic Convex Programming Abstract: We introduce the online stochastic Convex Programming (CP) problem, a very\ngeneral version of stochastic online problems which allows arbitrary concave\nobjectives and convex feasibility constraints. Many well-studied problems like\nonline stochastic packing and covering, online stochastic matching with concave\nreturns, etc. form a special case of online stochastic CP. We present fast\nalgorithms for these problems, which achieve near-optimal regret guarantees for\nboth the i.i.d. and the random permutation models of stochastic inputs. When\napplied to the special case online packing, our ideas yield a simpler and\nfaster primal-dual algorithm for this well studied problem, which achieves the\noptimal competitive ratio. Our techniques make explicit the connection of\nprimal-dual paradigm and online learning to online stochastic CP. \n\n"}
{"id": "1411.0222", "contents": "Title: SISO Output Affine Feedback Transformation Group and Its Faa di Bruno\n  Hopf Algebra Abstract: The general goal of this paper is to identify a transformation group that can\nbe used to describe a class of feedback interconnections involving subsystems\nwhich are modeled solely in terms of Chen-Fliess functional expansions or\nFliess operators and are independent of the existence of any state space\nmodels. This interconnection, called an output affine feedback connection, is\ndistinguished from conventional output feedback by the presence of a multiplier\nin an outer loop. Once this transformation group is established, three basic\nquestions are addressed. How can this transformation group be used to provide\nan explicit Fliess operator representation of such a closed-loop system? Is it\npossible to use this feedback scheme to do system inversion purely in an\ninput-output setting? In particular, can feedback input-output linearization be\nposed and solved entirely in this framework, i.e., without the need for any\nstate space realization? Lastly, what can be said about feedback invariants\nunder this transformation group? A final objective of the paper is to describe\nthe Lie algebra of infinitesimal characters associated with the group in terms\nof a pre-Lie product. \n\n"}
{"id": "1411.0226", "contents": "Title: Horizontal Holonomy for Affine Manifolds Abstract: In this paper, we consider a smooth connected finite-dimensional manifold\n$M$, an affine connection $\\nabla$ with holonomy group $H^{\\nabla}$ and\n$\\Delta$ a smooth completely non integrable distribution. We define the\n$\\Delta$-horizontal holonomy group $H^{\\;\\nabla}_\\Delta$ as the subgroup of\n$H^{\\nabla}$ obtained by $\\nabla$-parallel transporting frames only along loops\ntangent to $\\Delta$. We first set elementary properties of\n$H^{\\;\\nabla}_\\Delta$ and show how to study it using the rolling formalism\n(\\cite{ChitourKokkonen}). In particular, it is shown that $H^{\\;\\nabla}_\\Delta$\nis a Lie group. Moreover, we study an explicit example where $M$ is a free\nstep-two homogeneous Carnot group and $\\nabla$ is the Levi-Civita connection\nassociated to a Riemannian metric on $M$, and show that in this particular case\nthe connected component of the identity of $H^{\\;\\nabla}_\\Delta$ is compact and\nstrictly included in $H^{\\nabla}$. \n\n"}
{"id": "1411.0589", "contents": "Title: Modular proximal optimization for multidimensional total-variation\n  regularization Abstract: We study \\emph{TV regularization}, a widely used technique for eliciting\nstructured sparsity. In particular, we propose efficient algorithms for\ncomputing prox-operators for $\\ell_p$-norm TV. The most important among these\nis $\\ell_1$-norm TV, for whose prox-operator we present a new geometric\nanalysis which unveils a hitherto unknown connection to taut-string methods.\nThis connection turns out to be remarkably useful as it shows how our geometry\nguided implementation results in efficient weighted and unweighted 1D-TV\nsolvers, surpassing state-of-the-art methods. Our 1D-TV solvers provide the\nbackbone for building more complex (two or higher-dimensional) TV solvers\nwithin a modular proximal optimization approach. We review the literature for\nan array of methods exploiting this strategy, and illustrate the benefits of\nour modular design through extensive suite of experiments on (i) image\ndenoising, (ii) image deconvolution, (iii) four variants of fused-lasso, and\n(iv) video denoising. To underscore our claims and permit easy reproducibility,\nwe provide all the reviewed and our new TV solvers in an easy to use\nmulti-threaded C++, Matlab and Python library. \n\n"}
{"id": "1411.0835", "contents": "Title: Variations on the Stochastic Shortest Path Problem Abstract: In this invited contribution, we revisit the stochastic shortest path\nproblem, and show how recent results allow one to improve over the classical\nsolutions: we present algorithms to synthesize strategies with multiple\nguarantees on the distribution of the length of paths reaching a given target,\nrather than simply minimizing its expected value. The concepts and algorithms\nthat we propose here are applications of more general results that have been\nobtained recently for Markov decision processes and that are described in a\nseries of recent papers. \n\n"}
{"id": "1411.1745", "contents": "Title: Exploiting chordal structure in polynomial ideals: a Gr\\\"obner bases\n  approach Abstract: Chordal structure and bounded treewidth allow for efficient computation in\nnumerical linear algebra, graphical models, constraint satisfaction and many\nother areas. In this paper, we begin the study of how to exploit chordal\nstructure in computational algebraic geometry, and in particular, for solving\npolynomial systems. The structure of a system of polynomial equations can be\ndescribed in terms of a graph. By carefully exploiting the properties of this\ngraph (in particular, its chordal completions), more efficient algorithms can\nbe developed. To this end, we develop a new technique, which we refer to as\nchordal elimination, that relies on elimination theory and Gr\\\"obner bases. By\nmaintaining graph structure throughout the process, chordal elimination can\noutperform standard Gr\\\"obner basis algorithms in many cases. The reason is\nthat all computations are done on \"smaller\" rings, of size equal to the\ntreewidth of the graph. In particular, for a restricted class of ideals, the\ncomputational complexity is linear in the number of variables. Chordal\nstructure arises in many relevant applications. We demonstrate the suitability\nof our methods in examples from graph colorings, cryptography, sensor\nlocalization and differential equations. \n\n"}
{"id": "1411.2038", "contents": "Title: A real stable extension of the Vamos matroid polynomial Abstract: In 2004, Choe, Oxley, Sokal and Wagner established a tight connection between\nmatroids and multiaffine real stable polynomials. Recently, Branden used this\ntheory and a polynomial coming from the Vamos matroid to disprove the\ngeneralized Lax conjecture. Here we present a 10-element extension of the Vamos\nmatroid and prove that its basis generating polynomial is real stable (i.e.\nthat the matroid has the half-plane property). We do this via large sums of\nsquares computations and a criterion for real stability given by Wagner and\nWei. Like the Vamos matroid, this matroid is not representable over any field\nand no power of its basis generating polynomial can be written as the\ndeterminant of a linear matrix with positive semidefinite Hermitian forms. \n\n"}
{"id": "1411.2129", "contents": "Title: Interior-point algorithms for convex optimization based on primal-dual\n  metrics Abstract: We propose and analyse primal-dual interior-point algorithms for convex\noptimization problems in conic form. The families of algorithms we analyse are\nso-called short-step algorithms and they match the current best iteration\ncomplexity bounds for primal-dual symmetric interior-point algorithm of\nNesterov and Todd, for symmetric cone programming problems with given\nself-scaled barriers. Our results apply to any self-concordant barrier for any\nconvex cone. We also prove that certain specializations of our algorithms to\nhyperbolic cone programming problems (which lie strictly between symmetric cone\nprogramming and general convex optimization problems in terms of generality)\ncan take advantage of the favourable special structure of hyperbolic barriers.\nWe make new connections to Riemannian geometry, integrals over operator spaces,\nGaussian quadrature, and strengthen the connection of our algorithms to\nquasi-Newton updates and hence first-order methods in general. \n\n"}
{"id": "1411.2876", "contents": "Title: Stochastic Intermediate Gradient Method for Convex Problems with Inexact\n  Stochastic Oracle Abstract: In this paper we introduce new methods for convex optimization problems with\ninexact stochastic oracle. First method is an extension of the intermediate\ngradient method proposed by Devolder, Glineur and Nesterov for problems with\ninexact oracle. Our new method can be applied to the problems with composite\nstructure, stochastic inexact oracle and allows using non-Euclidean setup. We\nprove estimates for mean rate of convergence and probabilities of large\ndeviations from this rate. Also we introduce two modifications of this method\nfor strongly convex problems. For the first modification we prove mean rate of\nconvergence estimates and for the second we prove estimates for large\ndeviations from the mean rate of convergence. All the rates give the complexity\nestimates for proposed methods which up to multiplicative constant coincide\nwith lower complexity bound for the considered class of convex composite\noptimization problems with stochastic inexact oracle. \n\n"}
{"id": "1411.6282", "contents": "Title: Multi-input control-affine systems static feedback equivalent to a\n  triangular form and their flatness Abstract: In this paper, we give a complete geometric characterization of control\nsystems, with m+1 inputs, locally static feedback equivalent to a triangular\nform compatible with the chained form, for m=1, respectively with the m-chained\nform, for m>1. They are x-flat systems. We provide a system of first order\nPDE's to be solved in order to find all x-flat outputs, for m=1, respectively\nall minimal x-flat outputs, for m>1. We illustrate our results by examples, in\nparticular by an application to a mechanical system: the coin rolling without\nslipping on a moving table. \n\n"}
{"id": "1411.6867", "contents": "Title: Convergence analysis for Lasserre's measure--based hierarchy of upper\n  bounds for polynomial optimization Abstract: We consider the problem of minimizing a continuous function f over a compact\nset K. We analyze a hierarchy of upper bounds proposed by Lasserre in [SIAM J.\nOptim. 21(3) (2011), pp. 864--885], obtained by searching for an optimal\nprobability density function h on K which is a sum of squares of polynomials,\nso that the expectation $\\int_{K}f(x)h(x)dx$ is minimized. We show that the\nrate of convergence is no worse than $O(1/\\sqrt{r})$, where 2r is the degree\nbound on the density function. This analysis applies to the case when f is\nLipschitz continuous and K is a full-dimensional compact set satisfying some\nboundary condition (which is satisfied, e.g., for convex bodies). The r-th\nupper bound in the hierarchy may be computed using semidefinite programming if\nf is a polynomial of degree d, and if all moments of order up to 2r+d of the\nLebesgue measure on K are known, which holds for example if K is a simplex,\nhypercube, or a Euclidean ball. \n\n"}
{"id": "1412.0402", "contents": "Title: Adding a single state memory optimally accelerates symmetric linear maps Abstract: Previous papers have proposed to add memory registers to the dynamics of\ndiscrete-time linear systems in order to accelerate their convergence. In\nparticular, it has been proved that adding one memory slot per agent allows\nfaster convergence towards average consensus. We here prove that this situation\n\\emph{cannot} be improved by adding more memory slots, when the knowledge about\nthe self-adjoint linear map to be accelerated reduces to bounds on its extreme\neigenvalues. \n\n"}
{"id": "1412.0528", "contents": "Title: Multiobjective approach to optimal control for a tuberculosis model Abstract: Mathematical modelling can help to explain the nature and dynamics of\ninfection transmissions, as well as support a policy for implementing those\nstrategies that are most likely to bring public health and economic benefits.\nThe paper addresses the application of optimal control strategies in a\ntuberculosis model. The model consists of a system of ordinary differential\nequations, which considers reinfection and post-exposure interventions. We\npropose a multiobjective optimization approach to find optimal control\nstrategies for the minimization of active infectious and persistent latent\nindividuals, as well as the cost associated to the implementation of the\ncontrol strategies. Optimal control strategies are investigated for different\nvalues of the model parameters. The obtained numerical results cover a whole\nrange of the optimal control strategies, providing valuable information about\nthe tuberculosis dynamics and showing the usefulness of the proposed approach. \n\n"}
{"id": "1412.1481", "contents": "Title: Dilations, Linear Matrix Inequalities, the Matrix Cube Problem and Beta\n  Distributions Abstract: An operator C on a Hilbert space H dilates to an operator T on a Hilbert\nspace K if there is an isometry V from H to K such that C=V^*TV. A main result\nof this paper is, for a positive integer d, the simultaneous dilation, up to a\nsharp factor $\\vartheta(d)$, of all d-by-d symmetric matrices of operator norm\nat most one to a collection of commuting self-adjoint contraction operators on\na Hilbert space. An analytic formula for $\\vartheta(d)$ is derived, which as a\nby-product gives new probabilistic results for the binomial and beta\ndistributions.\n  Dilating to commuting operators has consequences for the theory of linear\nmatrix inequalities (LMIs). Given a tuple A=(A_1,...,A_g) of symmetric matrices\nof the same size, L(x):=I-\\sum A_j x_j is a monic linear pencil. The solution\nset S_L of the corresponding linear matrix inequality, consisting of those x in\nR^g for which L(x) is positive semidefinite (PsD), is a spectrahedron. The set\nD_L of tuples X=(X_1,...,X_g) of symmetric matrices (of the same size) for\nwhich L(X):=I-\\sum A_j \\otimes X_j is PsD, is a free spectrahedron. A result\nhere is: any tuple X of d-by-d symmetric matrices in a bounded free\nspectrahedron D_L dilates, up to a scale factor, to a tuple T of commuting\nself-adjoint operators with joint spectrum in the corresponding spectrahedron\nS_L. From another viewpoint, the scale factor measures the extent that a\npositive map can fail to be completely positive.\n  Given another monic linear pencil M, the inclusion D_L \\subset D_M obviously\nimplies the inclusion S_L \\subset S_M and thus can be thought of as its free\nrelaxation. Determining if one free spectrahedron contains another can be done\nby solving an explicit LMI and is thus computationally tractable. The scale\nfactor for commutative dilation of D_L gives a precise measure of the worst\ncase error inherent in the free relaxation, over all monic linear pencils M of\nsize d. \n\n"}
{"id": "1412.2128", "contents": "Title: Fast Bundle-Level Type Methods for unconstrained and ball-constrained\n  convex optimization Abstract: It has been shown in \\cite{Lan13-1} that the accelerated prox-level (APL)\nmethod and its variant, the uniform smoothing level (USL) method, have optimal\niteration complexity for solving black-box and structured convex programming\nproblems without requiring the input of any smoothness information. However,\nthese algorithms require the assumption on the boundedness of the feasible set\nand their efficiency relies on the solutions of two involved subproblems. These\nhindered the applicability of these algorithms in solving large-scale and\nunconstrained optimization problems. In this paper, we first present a generic\nalgorithmic framework to extend these uniformly optimal level methods for\nsolving unconstrained problems. Moreover, we introduce two new variants of\nlevel methods, i.e., the fast APL (FAPL) method and the fast USL (FUSL) method,\nfor solving large scale black-box and structured convex programming problems\nrespectively. Both FAPL and FUSL enjoy the same optimal iteration complexity as\nAPL and USL, while the number of subproblems in each iteration is reduced from\ntwo to one. Moreover, we present an exact method to solve the only subproblem\nfor these algorithms. As a result, the proposed FAPL and FUSL methods have\nimproved the performance of the APL and USL in practice significantly in terms\nof both computational time and solution quality. Our numerical results on\nsolving some large-scale least square problems and total variation based image\nreconstruction have shown great advantages of these new bundle-level type\nmethods over APL, USL, and some other state-of-the-art first-order methods. \n\n"}
{"id": "1412.2196", "contents": "Title: Relations among Some Low Rank Subspace Recovery Models Abstract: Recovering intrinsic low dimensional subspaces from data distributed on them\nis a key preprocessing step to many applications. In recent years, there has\nbeen a lot of work that models subspace recovery as low rank minimization\nproblems. We find that some representative models, such as Robust Principal\nComponent Analysis (R-PCA), Robust Low Rank Representation (R-LRR), and Robust\nLatent Low Rank Representation (R-LatLRR), are actually deeply connected. More\nspecifically, we discover that once a solution to one of the models is\nobtained, we can obtain the solutions to other models in closed-form\nformulations. Since R-PCA is the simplest, our discovery makes it the center of\nlow rank subspace recovery models. Our work has two important implications.\nFirst, R-PCA has a solid theoretical foundation. Under certain conditions, we\ncould find better solutions to these low rank models at overwhelming\nprobabilities, although these models are non-convex. Second, we can obtain\nsignificantly faster algorithms for these models by solving R-PCA first. The\ncomputation cost can be further cut by applying low complexity randomized\nalgorithms, e.g., our novel $\\ell_{2,1}$ filtering algorithm, to R-PCA.\nExperiments verify the advantages of our algorithms over other state-of-the-art\nones that are based on the alternating direction method. \n\n"}
{"id": "1412.2277", "contents": "Title: Linear conic optimization for inverse optimal control Abstract: We address the inverse problem of Lagrangian identification based on\ntrajecto-ries in the context of nonlinear optimal control. We propose a general\nformulation of the inverse problem based on occupation measures and\ncomplementarity in linear programming. The use of occupation measures in this\ncontext offers several advan-tages from the theoretical, numerical and\nstatistical points of view. We propose an approximation procedure for which\nstrong theoretical guarantees are available. Finally, the relevance of the\nmethod is illustrated on academic examples. \n\n"}
{"id": "1412.4659", "contents": "Title: Finding a sparse vector in a subspace: Linear sparsity using alternating\n  directions Abstract: Is it possible to find the sparsest vector (direction) in a generic subspace\n$\\mathcal{S} \\subseteq \\mathbb{R}^p$ with $\\mathrm{dim}(\\mathcal{S})= n < p$?\nThis problem can be considered a homogeneous variant of the sparse recovery\nproblem, and finds connections to sparse dictionary learning, sparse PCA, and\nmany other problems in signal processing and machine learning. In this paper,\nwe focus on a **planted sparse model** for the subspace: the target sparse\nvector is embedded in an otherwise random subspace. Simple convex heuristics\nfor this planted recovery problem provably break down when the fraction of\nnonzero entries in the target sparse vector substantially exceeds\n$O(1/\\sqrt{n})$. In contrast, we exhibit a relatively simple nonconvex approach\nbased on alternating directions, which provably succeeds even when the fraction\nof nonzero entries is $\\Omega(1)$. To the best of our knowledge, this is the\nfirst practical algorithm to achieve linear scaling under the planted sparse\nmodel. Empirically, our proposed algorithm also succeeds in more challenging\ndata models, e.g., sparse dictionary learning. \n\n"}
{"id": "1412.5691", "contents": "Title: An improved upper bound on the diameters of subset partition graphs Abstract: In 1992, Kalai and Kleitman proved the first subexponential upper bound for\nthe diameters of convex polyhedra. Eisenbrand et al. proved this bound holds\nfor connected layer families, a novel approach to analyzing polytope diameters.\nVery recently, Todd improved the Kalai-Kleitman bound for polyhedra to\n$(n-d)^{1+\\log_2d}$. In this note, we prove an analogous upper bound on the\ndiameters of subset partition graphs satisfying a property related to the\nconnectivity property of connected layer families. \n\n"}
{"id": "1412.6293", "contents": "Title: Semi-Stochastic Coordinate Descent Abstract: We propose a novel stochastic gradient method---semi-stochastic coordinate\ndescent (S2CD)---for the problem of minimizing a strongly convex function\nrepresented as the average of a large number of smooth convex functions:\n$f(x)=\\tfrac{1}{n}\\sum_i f_i(x)$. Our method first performs a deterministic\nstep (computation of the gradient of $f$ at the starting point), followed by a\nlarge number of stochastic steps. The process is repeated a few times, with the\nlast stochastic iterate becoming the new starting point where the deterministic\nstep is taken. The novelty of our method is in how the stochastic steps are\nperformed. In each such step, we pick a random function $f_i$ and a random\ncoordinate $j$---both using nonuniform distributions---and update a single\ncoordinate of the decision vector only, based on the computation of the\n$j^{th}$ partial derivative of $f_i$ at two different points. Each random step\nof the method constitutes an unbiased estimate of the gradient of $f$ and\nmoreover, the squared norm of the steps goes to zero in expectation, meaning\nthat the stochastic estimate of the gradient progressively improves. The\ncomplexity of the method is the sum of two terms: $O(n\\log(1/\\epsilon))$\nevaluations of gradients $\\nabla f_i$ and $O(\\hat{\\kappa}\\log(1/\\epsilon))$\nevaluations of partial derivatives $\\nabla_j f_i$, where $\\hat{\\kappa}$ is a\nnovel condition number. \n\n"}
{"id": "1412.6792", "contents": "Title: A linear time algorithm to verify strong structural controllability Abstract: We prove that strong structural controllability of a pair of structural\nmatrices $(\\mathcal{A},\\mathcal{B})$ can be verified in time linear in $n + r +\n\\nu$, where $\\mathcal{A}$ is square, $n$ and $r$ denote the number of columns\nof $\\mathcal{A}$ and $\\mathcal{B}$, respectively, and $\\nu$ is the number of\nnon-zero entries in $(\\mathcal{A},\\mathcal{B})$. We also present an algorithm\nrealizing this bound, which depends on a recent, high-level method to verify\nstrong structural controllability and uses sparse matrix data structures.\nLinear time complexity is actually achieved by separately storing both the\nstructural matrix $(\\mathcal{A},\\mathcal{B})$ and its transpose, linking the\ntwo data structures through a third one, and a novel, efficient scheme to\nupdate all the data during the computations. We illustrate the performance of\nour algorithm using systems of various sizes and sparsity. \n\n"}
{"id": "1412.7457", "contents": "Title: Global convergence of the Heavy-ball method for convex optimization Abstract: This paper establishes global convergence and provides global bounds of the\nconvergence rate of the Heavy-ball method for convex optimization problems.\nWhen the objective function has Lipschitz-continuous gradient, we show that the\nCesaro average of the iterates converges to the optimum at a rate of $O(1/k)$\nwhere k is the number of iterations. When the objective function is also\nstrongly convex, we prove that the Heavy-ball iterates converge linearly to the\nunique optimum. \n\n"}
{"id": "1412.7840", "contents": "Title: Value Function in Maximum Hands-off Control Abstract: In this brief paper, we study the value function in maximum hands-off\ncontrol. Maximum hands-off control, also known as sparse control, is the\nL0-optimal control among the admissible controls. Although the L0 measure is\ndiscontinuous and non- convex, we prove that the value function, or the minimum\nL0 norm of the control, is a continuous and strictly convex function of the\ninitial state in the reachable set, under an assumption on the controlled plant\nmodel. This property is important, in particular, for discussing the\nsensitivity of the optimality against uncertainties in the initial state, and\nalso for investigating the stability by using the value function as a Lyapunov\nfunction in model predictive control. \n\n"}
{"id": "1412.8236", "contents": "Title: Optimal Sparse Output Feedback Control Design: a Rank Constrained\n  Optimization Approach Abstract: We consider the problem of optimal sparse output feedback controller\nsynthesis for continuous linear time invariant systems when the feedback gain\nis static and subject to specified structural constraints. Introducing an\nadditional term penalizing the number of non-zero entries of the feedback gain\ninto the optimization cost function, we show that this inherently non-convex\nproblem can be equivalently cast as a rank constrained optimization, hence, it\nis an NP-hard problem. We further exploit our rank constrained approach to\ndefine a structured output feedback control feasibility test with global\nconvergence property, then, obtain upper/lower bounds for the optimal cost of\nthe sparse output feedback control problem. Moreover, we show that our problem\nreformulation allows us to incorporate additional implementation constraints,\nsuch as norm bounds on the control inputs or system output, by assimilating\nthem into the rank constraint. We propose to utilize a version of the\nAlternating Direction Method of Multipliers (ADMM) as an efficient method to\nsub-optimally solve the equivalent rank constrained problem. As a special case,\nwe study the problem of designing the sparsest stabilizing output feedback\ncontroller, and show that it is, in fact, a structured matrix recovery problem\nwhere the matrix of interest is simultaneously sparse and low rank.\nFurthermore, we show that this matrix recovery problem can be equivalently cast\nin the form of a canonical and well-studied rank minimization problem. We\nfinally illustrate performance of our proposed methodology using numerical\nexamples. \n\n"}
{"id": "1412.8736", "contents": "Title: Sharing Information Without Regret in Managed Stochastic Games Abstract: This paper considers information sharing in a multi-player repeated game.\nEvery round, each player observes a subset of components of a random vector and\nthen takes a control action. The utility earned by each player depends on the\nfull random vector and on the actions of others. An example is a game where\ndifferent rewards are placed over multiple locations, each player only knows\nthe rewards in a subset of the locations, and players compete to collect the\nrewards. Sharing information can help others, but can also increase competition\nfor desirable locations. Standard Nash equilibrium and correlated equilibrium\nconcepts are inadequate in this scenario. Instead, this paper develops an\nalgorithm where, every round, all players pass their information and intended\nactions to a game manager. The manager provides suggested actions for each\nplayer that, if taken, maximize a concave function of average utilities subject\nto the constraint that each player gets an average utility no worse than it\nwould get without sharing. The algorithm acts online using information given at\neach round and does not require a specific model of random events or player\nactions. Thus, the analytical results of this paper apply in non-ergodic\nsituations with any sequence of actions taken by human players. \n\n"}
{"id": "1501.00307", "contents": "Title: Coderivative characterizations of maximal monotonicity for set-valued\n  mappings Abstract: This paper concerns generalized differential characterizations of maximal\nmonotone set-valued mappings. Using advanced tools of variational analysis, we\nestablish coderivative criteria for maximal monotonicity of set-valued\nmappings, which seem to be the first infinitesimal characterizations of maximal\nmonotonicity outside the single-valued case. We also present second-order\nnecessary and sufficient conditions for lower-${\\mathcal C}^2$ functions to be\nconvex and strongly convex. Examples are provided to illustrate the obtained\nresults and the imposed assumptions. \n\n"}
{"id": "1501.02604", "contents": "Title: On the cone eigenvalue complementarity problem for higher-order tensors Abstract: In this paper, we consider the tensor generalized eigenvalue complementarity\nproblem (TGEiCP), which is an interesting generalization of matrix eigenvalue\ncomplementarity problem (EiCP). First, we given an affirmative result showing\nthat TGEiCP is solvable and has at least one solution under some reasonable\nassumptions. Then, we introduce two optimization reformulations of TGEiCP,\nthereby beneficially establishing an upper bound of cone eigenvalues of\ntensors. Moreover, some new results concerning the bounds of number of\neigenvalues of TGEiCP further enrich the theory of TGEiCP. Last but not least,\nan implementable projection algorithm for solving TGEiCP is also developed for\nthe problem under consideration. As an illustration of our theoretical results,\npreliminary computational results are reported. \n\n"}
{"id": "1501.03792", "contents": "Title: An inequality for the maximum curvature through a geometric flow Abstract: We provide a new proof of the following inequality: the maximum curvature\n$k_\\mathrm{max}$ and the enclosed area $A$ of a smooth Jordan curve satisfy\n$k_\\mathrm{max}\\ge \\sqrt{\\pi/A}$. The feature of our proof is the use of the\ncurve shortening flow. \n\n"}
{"id": "1501.04477", "contents": "Title: Ergodicity of robust switching control and nonlinear system of quasi\n  variational inequalities Abstract: We analyze the asymptotic behavior for a system of fully nonlinear parabolic\nand elliptic quasi variational inequalities. These equations are related to\nrobust switching control problems introduced in [3]. We prove that, as time\nhorizon goes to infinity (resp. discount factor goes to zero) the long run\naverage solution to the parabolic system (resp. the limiting discounted\nsolution to the elliptic system) is characterized by a solution of a nonlinear\nsystem of ergodic variational inequalities. Our results hold under a\ndissipativity condition and without any non degeneracy assumption on the\ndiffusion term. Our approach uses mainly probabilistic arguments and in\nparticular a dual randomized game representation for the solution to the system\nof variational inequalities. \n\n"}
{"id": "1501.04910", "contents": "Title: Dynamics and Control of Quadrotor UAVs Transporting a Rigid Body\n  Connected via Flexible Cables Abstract: This paper is focused on the dynamics and control of arbitrary number of\nquadrotor UAVs transporting a rigid body payload. The rigid body payload is\nconnected to quadrotors via flexible cables where each flexible cable is\nmodeled as a system of serially-connected links. It is shown that a\ncoordinate-free form of equations of motion can be derived for arbitrary\nnumbers of quadrotors and links according to Lagrangian mechanics on a\nmanifold. A geometric nonlinear controller is presented to transport the rigid\nbody to a fixed desired position while aligning all of the links along the\nvertical direction. Numerical results are provided to illustrate the desirable\nfeatures of the proposed control system. \n\n"}
{"id": "1501.06494", "contents": "Title: On Optimal Frame Conditioners Abstract: A (unit norm) frame is scalable if its vectors can be rescaled so as to\nresult into a tight frame. Tight frames can be considered optimally conditioned\nbecause the condition number of their frame operators is unity. In this paper\nwe reformulate the scalability problem as a convex optimization question. In\nparticular, we present examples of various formulations of the problem along\nwith numerical results obtained by using our methods on randomly generated\nframes. \n\n"}
{"id": "1501.07591", "contents": "Title: Direct solution to constrained tropical optimization problems with\n  application to project scheduling Abstract: We examine a new optimization problem formulated in the tropical mathematics\nsetting as a further extension of certain known problems. The problem is to\nminimize a nonlinear objective function, which is defined on vectors over an\nidempotent semifield by using multiplicative conjugate transposition, subject\nto inequality constraints. As compared to the known problems, the new one has a\nmore general objective function and additional constraints. We provide a\ncomplete solution in an explicit form to the problem by using an approach that\nintroduces an auxiliary variable to represent the values of the objective\nfunction, and then reduces the initial problem to a parametrized vector\ninequality. The minimum of the objective function is evaluated by applying the\nexistence conditions for the solution of this inequality. A complete solution\nto the problem is given by solving the parametrized inequality, provided the\nparameter is set to the minimum value. As a consequence, we obtain solutions to\nnew special cases of the general problem. To illustrate the application of the\nresults, we solve a real-world problem drawn from time-constrained project\nscheduling, and offer a representative numerical example. \n\n"}
{"id": "1502.00325", "contents": "Title: High order variational integrators in the optimal control of mechanical\n  systems Abstract: In recent years, much effort in designing numerical methods for the\nsimulation and optimization of mechanical systems has been put into schemes\nwhich are structure preserving. One particular class are variational\nintegrators which are momentum preserving and symplectic. In this article, we\ndevelop two high order variational integrators which distinguish themselves in\nthe dimension of the underling space of approximation and we investigate their\napplication to finite-dimensional optimal control problems posed with\nmechanical systems. The convergence of state and control variables of the\napproximated problem is shown. Furthermore, by analyzing the adjoint systems of\nthe optimal control problem and its discretized counterpart, we prove that, for\nthese particular integrators, dualization and discretization commute. \n\n"}
{"id": "1502.02209", "contents": "Title: Tensor Complementarity Problem and Semi-positive Tensors Abstract: The tensor complementarity problem $(\\q, \\mathcal{A})$ is to\n  $$\\mbox{ find } \\x \\in \\mathbb{R}^n\\mbox{ such that }\\x \\geq \\0, \\q +\n\\mathcal{A}\\x^{m-1} \\geq \\0, \\mbox{ and }\\x^\\top (\\q + \\mathcal{A}\\x^{m-1}) =\n0.$$ We prove that a real tensor $\\mathcal{A}$ is a (strictly) semi-positive\ntensor if and only if the tensor complementarity problem $(\\q, \\mathcal{A})$\nhas a unique solution for $\\q>\\0$ ($\\q\\geq\\0$), and a symmetric real tensor is\na (strictly) semi-positive tensor if and only if it is (strictly) copositive.\nThat is, for a strictly copositive symmetric tensor $\\mathcal{A}$, the tensor\ncomplementarity problem $(\\q, \\mathcal{A})$ has a solution for all $\\q \\in\n\\mathbb{R}^n$. \n\n"}
{"id": "1502.02842", "contents": "Title: On the closure of the completely positive semidefinite cone and linear\n  approximations to quantum colorings Abstract: We investigate structural properties of the completely positive semidefinite\ncone $\\mathcal{CS}_+^n$, consisting of all the $n \\times n$ symmetric matrices\nthat admit a Gram representation by positive semidefinite matrices of any size.\nThis cone has been introduced to model quantum graph parameters as conic\noptimization problems. Recently it has also been used to characterize the set\n$\\mathcal Q$ of bipartite quantum correlations, as projection of an affine\nsection of it. We have two main results concerning the structure of the\ncompletely positive semidefinite cone, namely about its interior and about its\nclosure. On the one hand we construct a hierarchy of polyhedral cones which\ncovers the interior of $\\mathcal{CS}_+^n$, which we use for computing some\nvariants of the quantum chromatic number by way of a linear program. On the\nother hand we give an explicit description of the closure of the completely\npositive semidefinite cone, by showing that it consists of all matrices\nadmitting a Gram representation in the tracial ultraproduct of matrix algebras. \n\n"}
{"id": "1502.03475", "contents": "Title: Combinatorial Bandits Revisited Abstract: This paper investigates stochastic and adversarial combinatorial multi-armed\nbandit problems. In the stochastic setting under semi-bandit feedback, we\nderive a problem-specific regret lower bound, and discuss its scaling with the\ndimension of the decision space. We propose ESCB, an algorithm that efficiently\nexploits the structure of the problem and provide a finite-time analysis of its\nregret. ESCB has better performance guarantees than existing algorithms, and\nsignificantly outperforms these algorithms in practice. In the adversarial\nsetting under bandit feedback, we propose \\textsc{CombEXP}, an algorithm with\nthe same regret scaling as state-of-the-art algorithms, but with lower\ncomputational complexity for some combinatorial problems. \n\n"}
{"id": "1502.05744", "contents": "Title: Scale-Free Algorithms for Online Linear Optimization Abstract: We design algorithms for online linear optimization that have optimal regret\nand at the same time do not need to know any upper or lower bounds on the norm\nof the loss vectors. We achieve adaptiveness to norms of loss vectors by scale\ninvariance, i.e., our algorithms make exactly the same decisions if the\nsequence of loss vectors is multiplied by any positive constant. Our algorithms\nwork for any decision set, bounded or unbounded. For unbounded decisions sets,\nthese are the first truly adaptive algorithms for online linear optimization. \n\n"}
{"id": "1502.07328", "contents": "Title: Combined Top-down and Bottom-up Approach to Multilevel Supervisory\n  Control Abstract: Recently, we have proposed two complementary approaches, top-down and\nbottom-up, to multilevel supervisory control of discrete-event systems. In this\npaper, we compare and combine these approaches. The combined approach has\nstrong features of both approaches, namely, a lower complexity of the top-down\napproach with the generality of the bottom-up approach. We show that, for\nprefix-closed languages, a posteriori supervisors computed in the bottom-up\nmanner do not alter maximal permissiveness within the three-level coordination\ncontrol architecture, that is, the supremal three-level\nconditionally-controllable and conditionally-normal language can always be\ncomputed in a distributed way using multilevel coordination. Moreover, a\ngeneral polynomial-time procedure for non-prefix closed case is proposed based\non coordinators for nonblockingness and a posteriori supervisors. \n\n"}
{"id": "1503.01189", "contents": "Title: Physical Interpretations of Negative Imaginary Systems Theory Abstract: This paper presents some physical interpretations of recent stability results\non the feedback interconnection of negative imaginary systems. These\ninterpretations involve spring mass damper systems coupled together by springs\nor RLC electrical networks coupled together via inductors or capacitors. \n\n"}
{"id": "1503.01207", "contents": "Title: Sparse sum-of-squares certificates on finite abelian groups Abstract: Let G be a finite abelian group. This paper is concerned with nonnegative\nfunctions on G that are sparse with respect to the Fourier basis. We establish\ncombinatorial conditions on subsets S and T of Fourier basis elements under\nwhich nonnegative functions with Fourier support S are sums of squares of\nfunctions with Fourier support T. Our combinatorial condition involves\nconstructing a chordal cover of a graph related to G and S (the Cayley graph\nCay($\\hat{G}$,S)) with maximal cliques related to T. Our result relies on two\nmain ingredients: the decomposition of sparse positive semidefinite matrices\nwith a chordal sparsity pattern, as well as a simple but key observation\nexploiting the structure of the Fourier basis elements of G.\n  We apply our general result to two examples. First, in the case where $G =\n\\mathbb{Z}_2^n$, by constructing a particular chordal cover of the half-cube\ngraph, we prove that any nonnegative quadratic form in n binary variables is a\nsum of squares of functions of degree at most $\\lceil n/2 \\rceil$, establishing\na conjecture of Laurent. Second, we consider nonnegative functions of degree d\non $\\mathbb{Z}_N$ (when d divides N). By constructing a particular chordal\ncover of the d'th power of the N-cycle, we prove that any such function is a\nsum of squares of functions with at most $3d\\log(N/d)$ nonzero Fourier\ncoefficients. Dually this shows that a certain cyclic polytope in\n$\\mathbb{R}^{2d}$ with N vertices can be expressed as a projection of a section\nof the cone of psd matrices of size $3d\\log(N/d)$. Putting $N=d^2$ gives a\nfamily of polytopes $P_d \\subset \\mathbb{R}^{2d}$ with LP extension complexity\n$\\text{xc}_{LP}(P_d) = \\Omega(d^2)$ and SDP extension complexity\n$\\text{xc}_{PSD}(P_d) = O(d\\log(d))$. To the best of our knowledge, this is the\nfirst explicit family of polytopes in increasing dimensions where\n$\\text{xc}_{PSD}(P_d) = o(\\text{xc}_{LP}(P_d))$. \n\n"}
{"id": "1503.03033", "contents": "Title: On the Complexity of Parallel Coordinate Descent Abstract: In this work we study the parallel coordinate descent method (PCDM) proposed\nby Richt\\'arik and Tak\\'a\\v{c} [26] for minimizing a regularized convex\nfunction. We adopt elements from the work of Xiao and Lu [39], and combine them\nwith several new insights, to obtain sharper iteration complexity results for\nPCDM than those presented in [26]. Moreover, we show that PCDM is monotonic in\nexpectation, which was not confirmed in [26], and we also derive the first high\nprobability iteration complexity result where the initial levelset is\nunbounded. \n\n"}
{"id": "1503.03231", "contents": "Title: Adaptive-Rate Sparse Signal Reconstruction With Application in\n  Compressive Background Subtraction Abstract: We propose and analyze an online algorithm for reconstructing a sequence of\nsignals from a limited number of linear measurements. The signals are assumed\nsparse, with unknown support, and evolve over time according to a generic\nnonlinear dynamical model. Our algorithm, based on recent theoretical results\nfor $\\ell_1$-$\\ell_1$ minimization, is recursive and computes the number of\nmeasurements to be taken at each time on-the-fly. As an example, we apply the\nalgorithm to compressive video background subtraction, a problem that can be\nstated as follows: given a set of measurements of a sequence of images with a\nstatic background, simultaneously reconstruct each image while separating its\nforeground from the background. The performance of our method is illustrated on\nsequences of real images: we observe that it allows a dramatic reduction in the\nnumber of measurements with respect to state-of-the-art compressive background\nsubtraction schemes. \n\n"}
{"id": "1503.03773", "contents": "Title: An Online Parallel and Distributed Algorithm for Recursive Estimation of\n  Sparse Signals Abstract: In this paper, we consider a recursive estimation problem for linear\nregression where the signal to be estimated admits a sparse representation and\nmeasurement samples are only sequentially available. We propose a convergent\nparallel estimation scheme that consists in solving a sequence of\n$\\ell_{1}$-regularized least-square problems approximately. The proposed scheme\nis novel in three aspects: i) all elements of the unknown vector variable are\nupdated in parallel at each time instance, and convergence speed is much faster\nthan state-of-the-art schemes which update the elements sequentially; ii) both\nthe update direction and stepsize of each element have simple closed-form\nexpressions, so the algorithm is suitable for online (real-time)\nimplementation; and iii) the stepsize is designed to accelerate the convergence\nbut it does not suffer from the common trouble of parameter tuning in\nliterature. Both centralized and distributed implementation schemes are\ndiscussed. The attractive features of the proposed algorithm are also\nnumerically consolidated. \n\n"}
{"id": "1503.04904", "contents": "Title: Distributed Continuous-time Approximate Projection Protocols for\n  Shortest Distance Optimization Problems Abstract: In this paper, we investigate the distributed shortest distance optimization\nproblem for a multi-agent network to cooperatively minimize the sum of the\nquadratic distances from some convex sets, where each set is only associated\nwith one agent. To deal with the optimization problem with projection\nuncertainties, we propose a distributed continuous-time dynamical protocol\nbased on a new concept of approximate projection. Here each agent can only\nobtain an approximate projection point on the boundary of its convex set, and\ncommunicate with its neighbors over a time-varying communication graph. First,\nwe show that no matter how large the approximate angle is, the system states\nare always bounded for any initial condition, and uniformly bounded with\nrespect to all initial conditions if the inferior limit of the stepsize is\ngreater than zero. Then, in the two cases, nonempty intersection and empty\nintersection of convex sets, we provide stepsize and approximate angle\nconditions to ensure the optimal convergence, respectively. Moreover, we give\nsome characterizations about the optimal solutions for the empty intersection\ncase and also present the convergence error between agents' estimates and the\noptimal point in the case of constant stepsizes and approximate angles. \n\n"}
{"id": "1503.06595", "contents": "Title: New bounds for the max-$k$-cut and chromatic number of a graph Abstract: We consider several semidefinite programming relaxations for the max-$k$-cut\nproblem, with increasing complexity. The optimal solution of the weakest\npresented semidefinite programming relaxation has a closed form expression that\nincludes the largest Laplacian eigenvalue of the graph under consideration.\nThis is the first known eigenvalue bound for the max-$k$-cut when $k>2$ that is\napplicable to any graph. This bound is exploited to derive a new eigenvalue\nbound on the chromatic number of a graph. For regular graphs, the new bound on\nthe chromatic number is the same as the well-known Hoffman bound; however, the\ntwo bounds are incomparable in general. We prove that the eigenvalue bound for\nthe max-$k$-cut is tight for several classes of graphs. We investigate the\npresented bounds for specific classes of graphs, such as walk-regular graphs,\nstrongly regular graphs, and graphs from the Hamming association scheme. \n\n"}
{"id": "1503.07254", "contents": "Title: Optimal network design for synchronization of coupled oscillators Abstract: This paper studies the problem of designing networks of nonidentical coupled\noscillators in order to achieve a desired level of phase cohesiveness, defined\nas the maximum asymptotic phase difference across the edges of the network. In\nparticular, we consider the following two design problems: (i) the\nnodal-frequency design problem, in which we tune the natural frequencies of the\noscillators given the topology of the network, and (ii) the (robust)\nedge-weight design problem, in which we design the edge weights assuming that\nthe natural frequencies are given (or belong to a given convex uncertainty\nset). For both problems, we optimize an objective function of the design\nvariables while considering a desired level of phase cohesiveness as our design\nconstraint. This constraint defines a convex set in the nodal-frequency design\nproblem. In contrast, in the edge-weight design problem, the phase cohesiveness\nconstraint yields a non-convex set, unless the underlying network is either a\ntree or an arbitrary graph with identical edge weights. We then propose a\nconvex semidefinite relaxation to approximately solve the (non-convex)\nedge-weight design problem for general (possibly cyclic) networks with\nnonidentical edge weights. We illustrate the applicability of our results by\nanalyzing several network design problems of practical interest, such as power\nre-dispatch in power grids, sparse network design, (robust) network design for\ndistributed wireless analog clocks, and the detection of edges leading to the\nBraess' paradox in power grids. \n\n"}
{"id": "1503.07728", "contents": "Title: A forward-backward-forward differential equation and its asymptotic\n  properties Abstract: In this paper, we approach the problem of finding the zeros of the sum of a\nmaximally monotone operator and a monotone and Lipschitz continuous one in a\nreal Hilbert space via an implicit forward-backward-forward dynamical system\nwith nonconstant relaxation parameters and stepsizes of the resolvents. Besides\nproving existence and uniqueness of strong global solutions for the\ndifferential equation under consideration, we show weak convergence of the\ngenerated trajectories and, under strong monotonicity assumptions, strong\nconvergence with exponential rate. In the particular setting of minimizing the\nsum of a proper, convex and lower semicontinuous function with a smooth convex\none, we provide a rate for the convergence of the objective function along the\nergodic trajectory to its minimum value. \n\n"}
{"id": "1504.00499", "contents": "Title: Exact algorithms for $L^1$-TV regularization of real-valued or\n  circle-valued signals Abstract: We consider $L^1$-TV regularization of univariate signals with values on the\nreal line or on the unit circle. While the real data space leads to a convex\noptimization problem, the problem is non-convex for circle-valued data. In this\npaper, we derive exact algorithms for both data spaces. A key ingredient is the\nreduction of the infinite search spaces to a finite set of configurations,\nwhich can be scanned by the Viterbi algorithm. To reduce the computational\ncomplexity of the involved tabulations, we extend the technique of distance\ntransforms to non-uniform grids and to the circular data space. In total, the\nproposed algorithms have complexity $\\mathscr{O}(KN)$ where $N$ is the length\nof the signal and $K$ is the number of different values in the data set. In\nparticular, the complexity is $\\mathscr{O}(N)$ for quantized data. It is the\nfirst exact algorithm for TV regularization with circle-valued data, and it is\ncompetitive with the state-of-the-art methods for scalar data, assuming that\nthe latter are quantized. \n\n"}
{"id": "1504.00874", "contents": "Title: Steering state statistics with output feedback Abstract: Consider a linear stochastic system whose initial state is a random vector\nwith a specified Gaussian distribution. Such a distribution may represent a\ncollection of particles abiding by the specified system dynamics. In recent\npublications, we have shown that, provided the system is controllable, it is\nalways possible to steer the state covariance to any specified terminal\nGaussian distribution using state feedback. The purpose of the present work is\nto show that, in the case where only partial state observation is available, a\nnecessary and sufficient condition for being able to steer the system to a\nspecified terminal Gaussian distribution for the state vector is that the\nterminal state covariance be greater (in the positive-definite sense) than the\nerror covariance of a corresponding Kalman filter. \n\n"}
{"id": "1504.01515", "contents": "Title: Simultaneously sparse and low-rank abundance matrix estimation for\n  hyperspectral image unmixing Abstract: In a plethora of applications dealing with inverse problems, e.g. in image\nprocessing, social networks, compressive sensing, biological data processing\netc., the signal of interest is known to be structured in several ways at the\nsame time. This premise has recently guided the research to the innovative and\nmeaningful idea of imposing multiple constraints on the parameters involved in\nthe problem under study. For instance, when dealing with problems whose\nparameters form sparse and low-rank matrices, the adoption of suitably combined\nconstraints imposing sparsity and low-rankness, is expected to yield\nsubstantially enhanced estimation results. In this paper, we address the\nspectral unmixing problem in hyperspectral images. Specifically, two novel\nunmixing algorithms are introduced, in an attempt to exploit both spatial\ncorrelation and sparse representation of pixels lying in homogeneous regions of\nhyperspectral images. To this end, a novel convex mixed penalty term is first\ndefined consisting of the sum of the weighted $\\ell_1$ and the weighted nuclear\nnorm of the abundance matrix corresponding to a small area of the image\ndetermined by a sliding square window. This penalty term is then used to\nregularize a conventional quadratic cost function and impose simultaneously\nsparsity and row-rankness on the abundance matrix. The resulting regularized\ncost function is minimized by a) an incremental proximal sparse and low-rank\nunmixing algorithm and b) an algorithm based on the alternating minimization\nmethod of multipliers (ADMM). The effectiveness of the proposed algorithms is\nillustrated in experiments conducted both on simulated and real data. \n\n"}
{"id": "1504.02418", "contents": "Title: Modulus on graphs as a generalization of standard graph theoretic\n  quantities Abstract: This paper presents new results for the modulus of families of walks on a\ngraph---a discrete analog of the modulus of curve families due to Beurling and\nAhlfors. Particular attention is paid to the dependence of the modulus on its\nparameters. Modulus is shown to generalize (and interpolate among) three\nimportant quantities in graph theory: shortest path, effective resistance, and\nmax-flow or min-cut. \n\n"}
{"id": "1504.03534", "contents": "Title: New results on subgradient methods for strongly convex optimization\n  problems with a unified analysis Abstract: We develop subgradient- and gradient-based methods for minimizing strongly\nconvex functions under a notion which generalizes the standard Euclidean strong\nconvexity. We propose a unifying framework for subgradient methods which yields\ntwo kinds of methods, namely, the Proximal Gradient Method (PGM) and the\nConditional Gradient Method (CGM), unifying several existing methods. The\nunifying framework provides tools to analyze the convergence of PGMs and CGMs\nfor non-smooth, (weakly) smooth, and further for structured problems such as\nthe inexact oracle models. The proposed subgradient methods yield optimal PGMs\nfor several classes of problems and yield optimal and nearly optimal CGMs for\nsmooth and weakly smooth problems, respectively. \n\n"}
{"id": "1505.00597", "contents": "Title: A general Doob-Meyer-Mertens decomposition for $g$-supermartingale\n  systems Abstract: We provide a general Doob-Meyer decomposition for $g$-supermartingale\nsystems, which does not require any right-continuity on the system. In\nparticular, it generalizes the Doob-Meyer decomposition of Mertens (1972) for\nclassical supermartingales, as well as Peng's (1999) version for\nright-continuous $g$-supermartingales. As examples of application, we prove an\noptional decomposition theorem for $g$-supermartingale systems, and also obtain\na general version of the well-known dual formation for BSDEs with constraint on\nthe gains-process, using very simple arguments. \n\n"}
{"id": "1505.03132", "contents": "Title: On integer programing with bounded determinants Abstract: Let $A$ be an $(m \\times n)$ integral matrix, and let $P=\\{ x : A x \\leq b\\}$\nbe an $n$-dimensional polytope. The width of $P$ is defined as $ w(P)=min\\{\nx\\in \\mathbb{Z}^n\\setminus\\{0\\} :\\: max_{x \\in P} x^\\top u - min_{x \\in P}\nx^\\top v \\}$. Let $\\Delta(A)$ and $\\delta(A)$ denote the greatest and the\nsmallest absolute values of a determinant among all $r(A) \\times r(A)$\nsub-matrices of $A$, where $r(A)$ is the rank of a matrix $A$. We prove that if\nevery $r(A) \\times r(A)$ sub-matrix of $A$ has a determinant equal to $\\pm\n\\Delta(A)$ or $0$ and $w(P)\\ge (\\Delta(A)-1)(n+1)$, then $P$ contains $n$\naffine independent integer points. Also we have similar results for the case of\n\\emph{$k$-modular} matrices. The matrix $A$ is called \\emph{totally\n$k$-modular} if every square sub-matrix of $A$ has a determinant in the set\n$\\{0,\\, \\pm k^r :\\: r \\in \\mathbb{N} \\}$. When $P$ is a simplex and $w(P)\\ge\n\\delta(A)-1$, we describe a polynomial time algorithm for finding an integer\npoint in $P$. Finally we show that if $A$ is \\emph{almost unimodular}, then\ninteger program $\\max \\{c^\\top x :\\: x \\in P \\cap \\mathbb{Z}^n \\}$ can be\nsolved in polynomial time. The matrix $A$ is called \\emph{almost unimodular} if\n$\\Delta(A) \\leq 2$ and any $(r(A)-1)\\times(r(A)-1)$ sub-matrix has a\ndeterminant from the set $\\{0,\\pm 1\\}$. \n\n"}
{"id": "1505.03132", "contents": "Title: On integer programing with bounded determinants Abstract: Let $A$ be an $(m \\times n)$ integral matrix, and let $P=\\{ x : A x \\leq b\\}$\nbe an $n$-dimensional polytope. The width of $P$ is defined as $ w(P)=min\\{\nx\\in \\mathbb{Z}^n\\setminus\\{0\\} :\\: max_{x \\in P} x^\\top u - min_{x \\in P}\nx^\\top v \\}$. Let $\\Delta(A)$ and $\\delta(A)$ denote the greatest and the\nsmallest absolute values of a determinant among all $r(A) \\times r(A)$\nsub-matrices of $A$, where $r(A)$ is the rank of a matrix $A$. We prove that if\nevery $r(A) \\times r(A)$ sub-matrix of $A$ has a determinant equal to $\\pm\n\\Delta(A)$ or $0$ and $w(P)\\ge (\\Delta(A)-1)(n+1)$, then $P$ contains $n$\naffine independent integer points. Also we have similar results for the case of\n\\emph{$k$-modular} matrices. The matrix $A$ is called \\emph{totally\n$k$-modular} if every square sub-matrix of $A$ has a determinant in the set\n$\\{0,\\, \\pm k^r :\\: r \\in \\mathbb{N} \\}$. When $P$ is a simplex and $w(P)\\ge\n\\delta(A)-1$, we describe a polynomial time algorithm for finding an integer\npoint in $P$. Finally we show that if $A$ is \\emph{almost unimodular}, then\ninteger program $\\max \\{c^\\top x :\\: x \\in P \\cap \\mathbb{Z}^n \\}$ can be\nsolved in polynomial time. The matrix $A$ is called \\emph{almost unimodular} if\n$\\Delta(A) \\leq 2$ and any $(r(A)-1)\\times(r(A)-1)$ sub-matrix has a\ndeterminant from the set $\\{0,\\pm 1\\}$. \n\n"}
{"id": "1505.03840", "contents": "Title: Non-unique games over compact groups and orientation estimation in\n  cryo-EM Abstract: Let $\\mathcal{G}$ be a compact group and let $f_{ij} \\in L^2(\\mathcal{G})$.\nWe define the Non-Unique Games (NUG) problem as finding $g_1,\\dots,g_n \\in\n\\mathcal{G}$ to minimize $\\sum_{i,j=1}^n f_{ij} \\left( g_i g_j^{-1}\\right)$. We\ndevise a relaxation of the NUG problem to a semidefinite program (SDP) by\ntaking the Fourier transform of $f_{ij}$ over $\\mathcal{G}$, which can then be\nsolved efficiently. The NUG framework can be seen as a generalization of the\nlittle Grothendieck problem over the orthogonal group and the Unique Games\nproblem and includes many practically relevant problems, such as the maximum\nlikelihood estimator} to registering bandlimited functions over the unit sphere\nin $d$-dimensions and orientation estimation in cryo-Electron Microscopy. \n\n"}
{"id": "1505.05166", "contents": "Title: Unique Measure for the Time-Periodic Navier-Stokes on the Sphere Abstract: This paper proves the existence and uniqueness of a time-invariant measure\nfor the 2D Navier-Stokes equations on the sphere under a random kick-force and\na time-periodic deterministic force. Several examples of deterministic forces\nsatisfying the necessary conditions for there to be a unique invariant measure\nare given. The support of the measure is examined and given explicitly for\nseveral cases. \n\n"}
{"id": "1506.02005", "contents": "Title: Robust $H_\\infty$ Estimation of Uncertain Linear Quantum Systems Abstract: We consider classical estimators for a class of physically realizable linear\nquantum systems. Optimal estimation using a complex Kalman filter for this\nproblem has been previously explored. Here, we study robust $H_\\infty$\nestimation for uncertain linear quantum systems. The estimation problem is\nsolved by converting it to a suitably scaled $H_\\infty$ control problem. The\nsolution is obtained in the form of two algebraic Riccati equations. Relevant\nexamples involving dynamic squeezers are presented to illustrate the efficacy\nof our method. \n\n"}
{"id": "1506.02081", "contents": "Title: On the Convergence Rate of Incremental Aggregated Gradient Algorithms Abstract: Motivated by applications to distributed optimization over networks and\nlarge-scale data processing in machine learning, we analyze the deterministic\nincremental aggregated gradient method for minimizing a finite sum of smooth\nfunctions where the sum is strongly convex. This method processes the functions\none at a time in a deterministic order and incorporates a memory of previous\ngradient values to accelerate convergence. Empirically it performs well in\npractice; however, no theoretical analysis with explicit rate results was\npreviously given in the literature to our knowledge, in particular most of the\nrecent efforts concentrated on the randomized versions. In this paper, we show\nthat this deterministic algorithm has global linear convergence and\ncharacterize the convergence rate. We also consider an aggregated method with\nmomentum and demonstrate its linear convergence. Our proofs rely on a careful\nchoice of a Lyapunov function that offers insight into the algorithm's behavior\nand simplifies the proofs considerably. \n\n"}
{"id": "1506.02159", "contents": "Title: Riemannian preconditioning for tensor completion Abstract: We propose a novel Riemannian preconditioning approach for the tensor\ncompletion problem with rank constraint. A Riemannian metric or inner product\nis proposed that exploits the least-squares structure of the cost function and\ntakes into account the structured symmetry in Tucker decomposition. The\nspecific metric allows to use the versatile framework of Riemannian\noptimization on quotient manifolds to develop a preconditioned nonlinear\nconjugate gradient algorithm for the problem. To this end, concrete matrix\nrepresentations of various optimization-related ingredients are listed.\nNumerical comparisons suggest that our proposed algorithm robustly outperforms\nstate-of-the-art algorithms across different problem instances encompassing\nvarious synthetic and real-world datasets. \n\n"}
{"id": "1506.02227", "contents": "Title: Primal Method for ERM with Flexible Mini-batching Schemes and Non-convex\n  Losses Abstract: In this work we develop a new algorithm for regularized empirical risk\nminimization. Our method extends recent techniques of Shalev-Shwartz [02/2015],\nwhich enable a dual-free analysis of SDCA, to arbitrary mini-batching schemes.\nMoreover, our method is able to better utilize the information in the data\ndefining the ERM problem. For convex loss functions, our complexity results\nmatch those of QUARTZ, which is a primal-dual method also allowing for\narbitrary mini-batching schemes. The advantage of a dual-free analysis comes\nfrom the fact that it guarantees convergence even for non-convex loss\nfunctions, as long as the average loss is convex. We illustrate through\nexperiments the utility of being able to design arbitrary mini-batching\nschemes. \n\n"}
{"id": "1506.02244", "contents": "Title: Efficient PDE constrained shape optimization based on Steklov-Poincar\\'e\n  type metrics Abstract: Recent progress in PDE constrained optimization on shape manifolds is based\non the Hadamard form of shape derivatives, i.e., in the form of integrals at\nthe boundary of the shape under investigation, as well as on intrinsic shape\nmetrics. From a numerical point of view, domain integral forms of shape\nderivatives seem promising, which rather require an outer metric on the domain\nsurrounding the shape boundary. This paper tries to harmonize both points of\nview by employing a Steklov-Poincar\\'e type intrinsic metric, which is derived\nfrom an outer metric. Based on this metric, efficient shape optimization\nalgorithms are proposed, which also reduce the analytical labor, so far\ninvolved in the derivation of shape derivatives. \n\n"}
{"id": "1506.02789", "contents": "Title: Theoretical and Numerical Analysis of an Optimal Execution Problem with\n  Uncertain Market Impact Abstract: This paper is a continuation of Ishitani and Kato (2015), in which we derived\na continuous-time value function corresponding to an optimal execution problem\nwith uncertain market impact as the limit of a discrete-time value function.\nHere, we investigate some properties of the derived value function. In\nparticular, we show that the function is continuous and has the semigroup\nproperty, which is strongly related to the Hamilton-Jacobi-Bellman\nquasi-variational inequality. Moreover, we show that noise in market impact\ncauses risk-neutral assessment to underestimate the impact cost. We also study\ntypical examples under a log-linear/quadratic market impact function with\nGamma-distributed noise. \n\n"}
{"id": "1506.02802", "contents": "Title: The Limits of Leverage Abstract: When trading incurs proportional costs, leverage can scale an asset's return\nonly up to a maximum multiple, which is sensitive to its volatility and\nliquidity. In a model with one safe and one risky asset, with constant\ninvestment opportunities and proportional costs, we find strategies that\nmaximize long term returns given average volatility. As leverage increases,\nrising rebalancing costs imply declining Sharpe ratios. Beyond a critical\nlevel, even returns decline. Holding the Sharpe ratio constant, higher asset\nvolatility leads to superior returns through lower costs. \n\n"}
{"id": "1506.04255", "contents": "Title: Entropic and displacement interpolation: a computational approach using\n  the Hilbert metric Abstract: Monge-Kantorovich optimal mass transport (OMT) provides a blueprint for\ngeometries in the space of positive densities -- it quantifies the cost of\ntransporting a mass distribution into another. In particular, it provides\nnatural options for interpolation of distributions (displacement interpolation)\nand for modeling flows. As such it has been the cornerstone of recent\ndevelopments in physics, probability theory, image processing, time-series\nanalysis, and several other fields. In spite of extensive work and theoretical\ndevelopments, the computation of OMT for large scale problems has remained a\nchallenging task. An alternative framework for interpolating distributions,\nrooted in statistical mechanics and large deviations, is that of Schroedinger\nbridges (entropic interpolation). This may be seen as a stochastic\nregularization of OMT and can be cast as the stochastic control problem of\nsteering the probability density of the state-vector of a dynamical system\nbetween two marginals. In this approach, however, the actual computation of\nflows had hardly received any attention. In recent work on Schroedinger bridges\nfor Markov chains and quantum evolutions, we noted that the solution can be\nefficiently obtained from the fixed-point of a map which is contractive in the\nHilbert metric. Thus, the purpose of this paper is to show that a similar\napproach can be taken in the context of diffusion processes which i) leads to a\nnew proof of a classical result on Schroedinger bridges and ii) provides an\nefficient computational scheme for both, Schroedinger bridges and OMT. We\nillustrate this new computational approach by obtaining interpolation of\ndensities in representative examples such as interpolation of images. \n\n"}
{"id": "1506.04681", "contents": "Title: Byzantine Multi-Agent Optimization: Part I Abstract: We study Byzantine fault-tolerant distributed optimization of a sum of convex\n(cost) functions with real-valued scalar input/ouput. In particular, the goal\nis to optimize a global cost function $\\frac{1}{|\\mathcal{N}|}\\sum_{i\\in\n\\mathcal{N}} h_i(x)$, where $\\mathcal{N}$ is the set of non-faulty agents, and\n$h_i(x)$ is agent $i$'s local cost function, which is initially known only to\nagent $i$. In general, when some of the agents may be Byzantine faulty, the\nabove goal is unachievable, because the identity of the faulty agents is not\nnecessarily known to the non-faulty agents, and the faulty agents may behave\narbitrarily. Since the above global cost function cannot be optimized exactly\nin presence of Byzantine agents, we define a weaker version of the problem.\n  The goal for the weaker problem is to generate an output that is an optimum\nof a function formed as a convex combination of local cost functions of the\nnon-faulty agents. More precisely, for some choice of weights $\\alpha_i$ for\n$i\\in \\mathcal{N}$ such that $\\alpha_i\\geq 0$ and $\\sum_{i\\in\n\\mathcal{N}}\\alpha_i=1$, the output must be an optimum of the cost function\n$\\sum_{i\\in \\mathcal{N}} \\alpha_ih_i(x)$. Ideally, we would like\n$\\alpha_i=\\frac{1}{|\\mathcal{N}|}$ for all $i\\in \\mathcal{N}$ -- however, this\ncannot be guaranteed due to the presence of faulty agents. In fact, we show\nthat the maximum achievable number of nonzero weights ($\\alpha_i$'s) is\n$|\\mathcal{N}|-f$, where $f$ is the upper bound on the number of Byzantine\nagents. In addition, we present algorithms that ensure that at least\n$|\\mathcal{N}|-f$ agents have weights that are bounded away from 0. We also\npropose a low-complexity suboptimal algorithm, which ensures that at least\n$\\lceil \\frac{n}{2}\\rceil-\\phi$ agents have weights that are bounded away from\n0, where $n$ is the total number of agents, and $\\phi$ ($\\phi\\le f$) is the\nactual number of Byzantine agents. \n\n"}
{"id": "1506.04737", "contents": "Title: A transverse Hamiltonian variational technique for open quantum\n  stochastic systems and its application to coherent quantum control Abstract: This paper is concerned with variational methods for nonlinear open quantum\nsystems with Markovian dynamics governed by Hudson-Parthasarathy quantum\nstochastic differential equations. The latter are driven by quantum Wiener\nprocesses of the external boson fields and are specified by the system\nHamiltonian and system-field coupling operators. We consider the system\nresponse to perturbations of these energy operators and introduce a transverse\nHamiltonian which encodes the propagation of the perturbations through the\nunitary system-field evolution. This provides a tool for the infinitesimal\nperturbation analysis and development of optimality conditions for coherent\nquantum control problems. We apply the transverse Hamiltonian variational\ntechnique to a mean square optimal coherent quantum filtering problem for a\nmeasurement-free cascade connection of quantum systems. \n\n"}
{"id": "1506.05866", "contents": "Title: An Efficient Optimization Approach for a Cardinality-Constrained Index\n  Tracking Problem Abstract: In the practical business environment, portfolio managers often face\nbusiness-driven requirements that limit the number of constituents in their\ntracking portfolio. A natural index tracking model is thus to minimize a\ntracking error measure while enforcing an upper bound on the number of assets\nin the portfolio. In this paper we consider such a cardinality-constrained\nindex tracking model. In particular, we propose an efficient nonmonotone\nprojected gradient (NPG) method for solving this problem. At each iteration,\nthis method usually solves several projected gradient subproblems. We show that\neach subproblem has a closed-form solution, which can be computed in linear\ntime. Under some suitable assumptions, we establish that any accumulation point\nof the sequence generated by the NPG method is a local minimizer of the\ncardinality-constrained index tracking problem. We also conduct empirical tests\nto compare our method with the hybrid evolutionary algorithm and the hybrid\nhalf thresholding algorithm \\cite{L1/2} for index tracking. The computational\nresults demonstrate that our approach generally produces sparse portfolios with\nsmaller out-of-sample tracking error and higher consistency between in-sample\nand out-of-sample tracking errors. Moreover, our method outperforms the other\ntwo approaches in terms of speed. \n\n"}
{"id": "1506.07029", "contents": "Title: Alternating Direction Method of Multipliers for A Class of Nonconvex and\n  Nonsmooth Problems with Applications to Background/Foreground Extraction Abstract: In this paper, we study a general optimization model, which covers a large\nclass of existing models for many applications in imaging sciences. To solve\nthe resulting possibly nonconvex, nonsmooth and non-Lipschitz optimization\nproblem, we adapt the alternating direction method of multipliers (ADMM) with a\ngeneral dual step-size to solve a reformulation that contains three blocks of\nvariables, and analyze its convergence. We show that for any dual step-size\nless than the golden ratio, there exists a computable threshold such that if\nthe penalty parameter is chosen above such a threshold and the sequence thus\ngenerated by our ADMM is bounded, then the cluster point of the sequence gives\na stationary point of the nonconvex optimization problem. We achieve this via a\npotential function specifically constructed for our ADMM. Moreover, we\nestablish the global convergence of the whole sequence if, in addition, this\nspecial potential function is a Kurdyka-{\\L}ojasiewicz function. Furthermore,\nwe present a simple strategy for initializing the algorithm to guarantee\nboundedness of the sequence. Finally, we perform numerical experiments\ncomparing our ADMM with the proximal alternating linearized minimization (PALM)\nproposed in [5] on the background/foreground extraction problem with real data.\nThe numerical results show that our ADMM with a nontrivial dual step-size is\nefficient. \n\n"}
{"id": "1506.07212", "contents": "Title: Elicitation Complexity of Statistical Properties Abstract: A property, or statistical functional, is said to be elicitable if it\nminimizes expected loss for some loss function. The study of which properties\nare elicitable sheds light on the capabilities and limitations of point\nestimation and empirical risk minimization. While recent work asks which\nproperties are elicitable, we instead advocate for a more nuanced question: how\nmany dimensions are required to indirectly elicit a given property? This number\nis called the elicitation complexity of the property. We lay the foundation for\na general theory of elicitation complexity, including several basic results\nabout how elicitation complexity behaves, and the complexity of standard\nproperties of interest. Building on this foundation, our main result gives\ntight complexity bounds for the broad class of Bayes risks. We apply these\nresults to several properties of interest, including variance, entropy, norms,\nand several classes of financial risk measures. We conclude with discussion and\nopen directions. \n\n"}
{"id": "1506.07699", "contents": "Title: Two results on the size of spectrahedral descriptions Abstract: A spectrahedron is a set defined by a linear matrix inequality. Given a\nspectrahedron we are interested in the question of the smallest possible size\n$r$ of the matrices in the description by linear matrix inequalities. We show\nthat for the $n$-dimensional unit ball $r$ is at least $\\frac{n}{2}$. If\n$n=2^k+1$, then we actually have $r=n$. The same holds true for any compact\nconvex set in $\\mathbb{R}^n$ defined by a quadratic polynomial. Furthermore, we\nshow that for a convex region in $\\mathbb{R}^3$ whose algebraic boundary is\nsmooth and defined by a cubic polynomial we have that $r$ is at least five.\nMore precisely, we show that if $A,B,C$ are real symmetric matrices such that\n$f(x,y,z)=\\det(I+A x+B y+C z)$ is a cubic polynomial, the surface in complex\nprojective three-space with affine equation $f(x,y,z)=0$ is singular. \n\n"}
{"id": "1506.08187", "contents": "Title: A geometric alternative to Nesterov's accelerated gradient descent Abstract: We propose a new method for unconstrained optimization of a smooth and\nstrongly convex function, which attains the optimal rate of convergence of\nNesterov's accelerated gradient descent. The new algorithm has a simple\ngeometric interpretation, loosely inspired by the ellipsoid method. We provide\nsome numerical evidence that the new method can be superior to Nesterov's\naccelerated gradient descent. \n\n"}
{"id": "1507.01160", "contents": "Title: Correlated Multiarmed Bandit Problem: Bayesian Algorithms and Regret\n  Analysis Abstract: We consider the correlated multiarmed bandit (MAB) problem in which the\nrewards associated with each arm are modeled by a multivariate Gaussian random\nvariable, and we investigate the influence of the assumptions in the Bayesian\nprior on the performance of the upper credible limit (UCL) algorithm and a new\ncorrelated UCL algorithm. We rigorously characterize the influence of accuracy,\nconfidence, and correlation scale in the prior on the decision-making\nperformance of the algorithms. Our results show how priors and correlation\nstructure can be leveraged to improve performance. \n\n"}
{"id": "1507.04371", "contents": "Title: Cloud-Enabled Differentially Private Multi-Agent Optimization with\n  Constraints Abstract: We present an optimization framework for solving multi-agent nonlinear\nprograms subject to inequality constraints while keeping the agents' state\ntrajectories private. Each agent has an objective function depending only upon\nits own state and the agents are collectively subject to global constraints.\nThe agents do not directly communicate with each other but instead route\nmessages through a trusted cloud computer. The cloud computer adds noise to\ndata being sent to the agents in accordance with the framework of differential\nprivacy in order to keep each agent's state trajectory private from all other\nagents and any eavesdroppers. This private problem can be viewed as a\nstochastic variational inequality and is solved using a projection-based method\nfor solving variational inequalities that resembles a noisy primal-dual\ngradient algorithm. Convergence of the optimization algorithm in the presence\nof noise is proven and a quantifiable trade-off between privacy and convergence\nis extracted from this proof. Simulation results are provided that demonstrate\nnumerical convergence for both $\\epsilon$-differential privacy and $(\\epsilon,\n\\delta)$-differential privacy. \n\n"}
{"id": "1507.04404", "contents": "Title: Bound-constrained polynomial optimization using only elementary\n  calculations Abstract: We provide a monotone non increasing sequence of upper bounds $f^H_k$ ($k\\ge\n1$) converging to the global minimum of a polynomial $f$ on simple sets like\nthe unit hypercube. The novelty with respect to the converging sequence of\nupper bounds in [J.B. Lasserre, A new look at nonnegativity on closed sets and\npolynomial optimization, SIAM J. Optim. 21, pp. 864--885, 2010] is that only\nelementary computations are required. For optimization over the hypercube, we\nshow that the new bounds $f^H_k$ have a rate of convergence in $O(1/\\sqrt\n{k})$. Moreover we show a stronger convergence rate in $O(1/k)$ for quadratic\npolynomials and more generally for polynomials having a rational minimizer in\nthe hypercube. In comparison, evaluation of all rational grid points with\ndenominator $k$ produces bounds with a rate of convergence in $O(1/k^2)$, but\nat the cost of $O(k^n)$ function evaluations, while the new bound $f^H_k$ needs\nonly $O(n^k)$ elementary calculations. \n\n"}
{"id": "1507.05125", "contents": "Title: On the Convergence of Optimal Actions for Markov Decision Processes and\n  the Optimality of $(s,S)$ Inventory Policies Abstract: This paper studies convergence properties of optimal values and actions for\ndiscounted and average-cost Markov Decision Processes (MDPs) with weakly\ncontinuous transition probabilities and applies these properties to the\nstochastic periodic-review inventory control problem with backorders, positive\nsetup costs, and convex holding/backordering costs. The following results are\nestablished for MDPs with possibly noncompact action sets and unbounded cost\nfunctions: (i) convergence of value iterations to optimal values for discounted\nproblems with possibly non-zero terminal costs, (ii) convergence of optimal\nfinite-horizon actions to optimal infinite-horizon actions for total discounted\ncosts, as the time horizon tends to infinity, and (iii) convergence of optimal\ndiscount-cost actions to optimal average-cost actions for infinite-horizon\nproblems, as the discount factor tends to 1.\n  Being applied to the setup-cost inventory control problem, the general\nresults on MDPs imply the optimality of $(s,S)$ policies and convergence\nproperties of optimal thresholds. In particular this paper analyzes the\nsetup-cost inventory control problem without two assumptions often used in the\nliterature: (a) the demand is either discrete or continuous or (b) the\nbackordering cost is higher than the cost of backordered inventory if the\namount of backordered inventory is large. \n\n"}
{"id": "1507.08092", "contents": "Title: Linear programs and convex hulls over fields of Puiseux fractions Abstract: We describe the implementation of a subfield of the field of formal Puiseux\nseries in polymake. This is employed for solving linear programs and computing\nconvex hulls depending on a real parameter. Moreover, this approach is also\nuseful for computations in tropical geometry. \n\n"}
{"id": "1507.08322", "contents": "Title: Distributed Mini-Batch SDCA Abstract: We present an improved analysis of mini-batched stochastic dual coordinate\nascent for regularized empirical loss minimization (i.e. SVM and SVM-type\nobjectives). Our analysis allows for flexible sampling schemes, including where\ndata is distribute across machines, and combines a dependence on the smoothness\nof the loss and/or the data spread (measured through the spectral norm). \n\n"}
{"id": "1507.08339", "contents": "Title: Inspection games in a mean field setting Abstract: In this paper, we present a new development of inspection games in a mean\nfield setting. In our dynamic version of an inspection game, there is one\ninspector and a large number N interacting inspectees with a finite state\nspace. By applying the mean field game methodology, we present a solution as an\nepsilon-equilibrium to this type of inspection games, where epsilon goes to 0\nas N tends to infinity. In order to facilitate numerical analysis of this new\ntype inspection game, we conduct an approximation analysis, that is we\napproximate the optimal Lipschitz continuous switching strategies by smooth\nswitching strategies. We show that any approximating smooth switching strategy\nis also an epsilon-equilibrium solution to the inspection game with a large and\nfinite number N of inspectees with epsilon being of order 1/N. \n\n"}
{"id": "1508.00625", "contents": "Title: Sparse PCA via Bipartite Matchings Abstract: We consider the following multi-component sparse PCA problem: given a set of\ndata points, we seek to extract a small number of sparse components with\ndisjoint supports that jointly capture the maximum possible variance. These\ncomponents can be computed one by one, repeatedly solving the single-component\nproblem and deflating the input data matrix, but as we show this greedy\nprocedure is suboptimal. We present a novel algorithm for sparse PCA that\njointly optimizes multiple disjoint components. The extracted features capture\nvariance that lies within a multiplicative factor arbitrarily close to 1 from\nthe optimal. Our algorithm is combinatorial and computes the desired components\nby solving multiple instances of the bipartite maximum weight matching problem.\nIts complexity grows as a low order polynomial in the ambient dimension of the\ninput data matrix, but exponentially in its rank. However, it can be\neffectively applied on a low-dimensional sketch of the data; this allows us to\nobtain polynomial-time approximation guarantees via spectral bounds. We\nevaluate our algorithm on real data-sets and empirically demonstrate that in\nmany cases it outperforms existing, deflation-based approaches. \n\n"}
{"id": "1508.02087", "contents": "Title: A Linearly-Convergent Stochastic L-BFGS Algorithm Abstract: We propose a new stochastic L-BFGS algorithm and prove a linear convergence\nrate for strongly convex and smooth functions. Our algorithm draws heavily from\na recent stochastic variant of L-BFGS proposed in Byrd et al. (2014) as well as\na recent approach to variance reduction for stochastic gradient descent from\nJohnson and Zhang (2013). We demonstrate experimentally that our algorithm\nperforms well on large-scale convex and non-convex optimization problems,\nexhibiting linear convergence and rapidly solving the optimization problems to\nhigh levels of precision. Furthermore, we show that our algorithm performs well\nfor a wide-range of step sizes, often differing by several orders of magnitude. \n\n"}
{"id": "1508.02134", "contents": "Title: Linear Rate Convergence of the Alternating Direction Method of\n  Multipliers for Convex Composite Quadratic and Semi-Definite Programming Abstract: In this paper, we aim to provide a comprehensive analysis on the linear rate\nconvergence of the alternating direction method of multipliers (ADMM) for\nsolving linearly constrained convex composite optimization problems. Under a\ncertain error bound condition, we establish the global linear rate of\nconvergence for a more general semi-proximal ADMM with the dual steplength\nbeing restricted to be in the open interval $(0, (1+\\sqrt{5})/2)$. In our\nanalysis, we assume neither the strong convexity nor the strict complementarity\nexcept an error bound condition, which holds automatically for convex composite\nquadratic programming. This semi-proximal ADMM, which includes the classic\nADMM, not only has the advantage to resolve the potentially non-solvability\nissue of the subproblems in the classic ADMM but also possesses the abilities\nof handling multi-block convex optimization problems efficiently. We shall use\nconvex composite quadratic programming and quadratic semi-definite programming\nas important applications to demonstrate the significance of the obtained\nresults. Of its own novelty in second-order variational analysis, a complete\ncharacterization is provided on the isolated calmness for the nonlinear convex\nsemi-definite optimization problem in terms of its second order sufficient\noptimality condition and the strict Robinson constraint qualification for the\npurpose of proving the linear rate convergence of the semi-proximal ADMM when\napplied to two- and multi-block convex quadratic semi-definite programming. \n\n"}
{"id": "1508.02531", "contents": "Title: Realizability and inscribability for simplicial polytopes via nonlinear\n  optimization Abstract: We show that nonlinear optimization techniques can successfully be applied to\nrealize and to inscribe matroid polytopes and simplicial spheres. Thus we\nobtain a complete classification of neighborly polytopes of dimension $4$, $6$\nand $7$ with $11$ vertices, of neighborly $5$-polytopes with $10$ vertices, as\nwell as a complete classification of simplicial $3$-spheres with $10$ vertices\ninto polytopal and non-polytopal spheres. Surprisingly many of the realizable\npolytopes are also inscribable. \n\n"}
{"id": "1508.03702", "contents": "Title: On the Duality Gap Convergence of ADMM Methods Abstract: This paper provides a duality gap convergence analysis for the standard ADMM\nas well as a linearized version of ADMM. It is shown that under appropriate\nconditions, both methods achieve linear convergence. However, the standard ADMM\nachieves a faster accelerated convergence rate than that of the linearized\nADMM. A simple numerical example is used to illustrate the difference in\nconvergence behavior. \n\n"}
{"id": "1508.04625", "contents": "Title: A Coordinate Descent Primal-Dual Algorithm with Large Step Size and\n  Possibly Non Separable Functions Abstract: This paper introduces a coordinate descent version of the V\\~u-Condat\nalgorithm. By coordinate descent, we mean that only a subset of the coordinates\nof the primal and dual iterates is updated at each iteration, the other\ncoordinates being maintained to their past value. Our method allows us to solve\noptimization problems with a combination of differentiable functions,\nconstraints as well as non-separable and non-differentiable regularizers. We\nshow that the sequences generated by our algorithm converge to a saddle point\nof the problem at stake, for a wider range of parameter values than previous\nmethods. In particular, the condition on the step-sizes depends on the\ncoordinate-wise Lipschitz constant of the differentiable function's gradient,\nwhich is a major feature allowing classical coordinate descent to perform so\nwell when it is applicable. We then prove a sublinear rate of convergence in\ngeneral and a linear rate of convergence if the objective enjoys strong\nconvexity properties. We illustrate the performances of the algorithm on a\ntotal-variation regularized least squares regression problem and on large scale\nsupport vector machine problems. \n\n"}
{"id": "1508.05161", "contents": "Title: Fast Convergence Rates for Distributed Non-Bayesian Learning Abstract: We consider the problem of distributed learning, where a network of agents\ncollectively aim to agree on a hypothesis that best explains a set of\ndistributed observations of conditionally independent random processes. We\npropose a distributed algorithm and establish consistency, as well as a\nnon-asymptotic, explicit and geometric convergence rate for the concentration\nof the beliefs around the set of optimal hypotheses. Additionally, if the\nagents interact over static networks, we provide an improved learning protocol\nwith better scalability with respect to the number of nodes in the network. \n\n"}
{"id": "1508.05384", "contents": "Title: Control Principles of Complex Networks Abstract: A reflection of our ultimate understanding of a complex system is our ability\nto control its behavior. Typically, control has multiple prerequisites: It\nrequires an accurate map of the network that governs the interactions between\nthe system's components, a quantitative description of the dynamical laws that\ngovern the temporal behavior of each component, and an ability to influence the\nstate and temporal behavior of a selected subset of the components. With deep\nroots in nonlinear dynamics and control theory, notions of control and\ncontrollability have taken a new life recently in the study of complex\nnetworks, inspiring several fundamental questions: What are the control\nprinciples of complex systems? How do networks organize themselves to balance\ncontrol with functionality? To address these here we review recent advances on\nthe controllability and the control of complex networks, exploring the\nintricate interplay between a system's structure, captured by its network\ntopology, and the dynamical laws that govern the interactions between the\ncomponents. We match the pertinent mathematical results with empirical findings\nand applications. We show that uncovering the control principles of complex\nsystems can help us explore and ultimately understand the fundamental laws that\ngovern their behavior. \n\n"}
{"id": "1508.06307", "contents": "Title: Joint User-Association and Resource-Allocation in Virtualized Wireless\n  Networks Abstract: In this paper, we consider a down-link transmission of multicell virtualized\nwireless networks (VWNs) where users of different service providers (slices)\nwithin a specific region are served by a set of base stations (BSs) through\northogonal frequency division multiple access (OFDMA). In particular, we\ndevelop a joint BS assignment, sub-carrier and power allocation algorithm to\nmaximize the network throughput, while satisfying the minimum required rate of\neach slice. Under the assumption that each user at each transmission instance\ncan connect to no more than one BS, we introduce the user-association factor\n(UAF) to represent the joint sub-carrier and BS assignment as the optimization\nvariable vector in the mathematical problem formulation. Sub-carrier reuse is\nallowed in different cells, but not within one cell. As the proposed\noptimization problem is inherently non-convex and NP-hard, by applying the\nsuccessive convex approximation (SCA) and complementary geometric programming\n(CGP), we develop an efficient two-step iterative approach with low\ncomputational complexity to solve the proposed problem. For a given\npower-allocation, Step 1 derives the optimum userassociation and subsequently,\nfor an obtained user-association, Step 2 find the optimum power-allocation.\nSimulation results demonstrate that the proposed iterative algorithm\noutperforms the traditional approach in which each user is assigned to the BS\nwith the largest average value of signal strength, and then, joint sub-carrier\nand power allocation is obtained for the assigned users of each cell.\nEspecially, for the cell-edge users, simulation results reveal a coverage\nimprovement up to 57% and 71% for uniform and non-uniform users distribution,\nrespectively leading to more reliable transmission and higher spectrum\nefficiency for VWN. \n\n"}
{"id": "1508.06777", "contents": "Title: On Lipschitz continuity of value functions for infinite horizon problem Abstract: We investigate conditions of optimality for an infinite horizon control\nproblem and consider their correspondence with the value function. Assuming\nLipschitz continuity of the value function, we prove that sensitivity relations\nplus the normal form version of the Pontryagin Maximum Principle is a necessary\nand sufficient condition for the optimality criteria that correspond to this\nvalue function. Different criteria of optimality under different asymptotic\nconstraints may be used, including almost strong and classical optimality\nproposed by D.Bogusz. Special attention is devoted to weakly agreeable\ncriteria. We also obtain the conditions on control system (like\ncontrollability) that guarantee the Lipschitz continuity of the value function,\nwithout any other asymptotic conditions besides finiteness of the value\nfunction. Some examples are discussed. In particular, it was shown that the\nsame control, regarded as agreeable optimal and overtaking optimal control, can\ncorrespond to different (everywhere) value functions. \n\n"}
{"id": "1508.06958", "contents": "Title: Maximum Likelihood Estimates for Gaussian Mixtures Are Transcendental Abstract: Gaussian mixture models are central to classical statistics, widely used in\nthe information sciences, and have a rich mathematical structure. We examine\ntheir maximum likelihood estimates through the lens of algebraic statistics.\nThe MLE is not an algebraic function of the data, so there is no notion of ML\ndegree for these models. The critical points of the likelihood function are\ntranscendental, and there is no bound on their number, even for mixtures of two\nunivariate Gaussians. \n\n"}
{"id": "1508.07607", "contents": "Title: Efficient Numerical Methods to Solve Sparse Linear Equations with\n  Application to PageRank Abstract: In this paper, we propose three methods to solve the PageRank problem for the\ntransition matrices with both row and column sparsity. Our methods reduce the\nPageRank problem to the convex optimization problem over the simplex. The first\nalgorithm is based on the gradient descent in L1 norm instead of the Euclidean\none. The second algorithm extends the Frank-Wolfe to support sparse gradient\nupdates. The third algorithm stands for the mirror descent algorithm with a\nrandomized projection. We proof converges rates for these methods for sparse\nproblems as well as numerical experiments support their effectiveness. \n\n"}
{"id": "1508.07837", "contents": "Title: Borwein-Preiss Vector Variational Principle Abstract: This article extends to the vector setting the results of our previous work\nKruger et al. (2015) which refined and slightly strengthened the metric space\nversion of the Borwein-Preiss variational principle due to Li and Shi, J. Math.\nAnal. Appl. 246(1), 308-319 (2000). We introduce and characterize two seemingly\nnew natural concepts of epsilon-minimality, one of them dependent on the chosen\nelement in the ordering cone and the fixed \"gauge-type\" function. \n\n"}
{"id": "1509.01621", "contents": "Title: Symmetrizing quantum dynamics beyond gossip-type algorithms Abstract: Recently, consensus-type problems have been formulated in the quantum domain.\nObtaining average quantum consensus consists in the dynamical symmetrization of\na multipartite quantum system while preserving the expectation of a given\nglobal observable. In this paper, two improved ways of obtaining consensus via\ndissipative engineering are introduced, which employ on quasi local preparation\nof mixtures of symmetric pure states, and show better performance in terms of\npurity dynamics with respect to existing algorithms. In addition, the first\nmethod can be used in combination with simple control resources in order to\nengineer pure Dicke states, while the second method guarantees a stronger type\nof consensus, namely single-measurement consensus. This implies that outcomes\nof local measurements on different subsystems are perfectly correlated when\nconsensus is achieved. Both dynamics can be randomized and are suitable for\nfeedback implementation. \n\n"}
{"id": "1509.01864", "contents": "Title: Fault-Tolerant Multi-Agent Optimization: Part III Abstract: We study fault-tolerant distributed optimization of a sum of convex (cost)\nfunctions with real-valued scalar input/output in the presence of crash faults\nor Byzantine faults. In particular, the goal is to optimize a global cost\nfunction $\\frac{1}{n}\\sum_{i\\in \\mathcal{V}} h_i(x)$, where $\\mathcal{V}=\\{1,\n\\ldots, n\\}$ is the collection of agents, and $h_i(x)$ is agent $i$'s local\ncost function, which is initially known only to agent $i$. Since the above\nglobal cost function cannot be optimized exactly in presence of crash faults or\nByzantine faults, we define two weaker versions of the problem for crash faults\nand Byzantine faults, respectively.\n  When some agents may crash, the goal for the weaker problem is to generate an\noutput that is an optimum of a function formed as $$C(\\sum_{i\\in \\mathcal{N}}\nh_i(x)+\\sum_{i\\in \\mathcal{F}} \\alpha_i h_i(x)),$$ where $\\mathcal{N}$ is the\nset of non-faulty agents, $\\mathcal{F}$ is the set of faulty agents (crashed\nagents), $0\\le \\alpha_i\\le 1$ for each $i\\in \\mathcal{F}$ and $C$ is a\nnormalization constant such that $C(|\\mathcal{N}|+\\sum_{i\\in \\mathcal{F}}\n\\alpha_i)=1$. We present an iterative algorithm in which each agent only needs\nto perform local computation, and send one message per iteration.\n  When some agents may be Byzantine, the system cannot take full advantage of\nthe data kept by non-faulty agents. The goal for the associated weaker problem\nis to generate an output that is an optimum of a function formed as\n$$\\sum_{i\\in \\mathcal{N}}\\alpha_i h_i(x),$$ such that $\\alpha_i\\geq 0$ for each\n$i\\in \\mathcal{N}$ and $\\sum_{i\\in \\mathcal{N}}\\alpha_i=1$. We present an\niterative algorithm, where only local computation is needed and only one\nmessage per agent is sent in each iteration, that ensures that at least\n$|\\mathcal{N}|-f$ agents have weights ($\\alpha_i$'s) that are lower bounded by\n$\\frac{1}{2(|\\mathcal{N}|-f)}$. \n\n"}
{"id": "1509.01898", "contents": "Title: A Possible Implementation of a Direct Coupling Coherent Quantum Observer Abstract: This paper considers the problem of implementing a previously proposed direct\ncoupling quantum observer for a closed linear quantum system. This observer is\nshown to be able to estimate some but not all of the plant variables in a time\naveraged sense. The paper proposes a possible experimental implementation of\nthe observer plant system using a non-degenerate parametric amplifier. \n\n"}
{"id": "1509.02735", "contents": "Title: Containment Problems for Projections of Polyhedra and Spectrahedra Abstract: Spectrahedra are affine sections of the cone of positive semidefinite\nmatrices which form a rich class of convex bodies that properly contains that\nof polyhedra. While the class of polyhedra is closed under linear projections,\nthe class of spectrahedra is not. In this paper we investigate the problem of\ndeciding containment of projections of polyhedra and spectrahedra based on\nprevious works on containment of spectrahedra. The main concern is to study\nthese containment problems by formulating them as polynomial nonnegativity\nproblems. This allows to state hierarchies of (sufficient) semidefinite\nconditions by applying (and proving) sophisticated Positivstellens\\\"atze. We\nalso extend results on a solitary sufficient condition for containment of\nspectrahedra coming from the polyhedral situation as well as connections to the\ntheory of (completely) positive linear maps. \n\n"}
{"id": "1509.03976", "contents": "Title: Approximability of TSP on Power Law Graphs Abstract: In this paper we study the special case of Graphic TSP where the underlying\ngraph is a power law graph (PLG). We give a refined analysis of some of the\ncurrent best approximation algorithms and show that an improved approximation\nratio can be achieved for certain ranges of the power law exponent $\\beta$. For\nthe value of power law exponent $\\beta=1.5$ we obtain an approximation ratio of\n$1.34$ for Graphic TSP. Moreover we study the $(1,2)$-TSP with the underlying\ngraph of $1$-edges being a PLG. We show improved approximation ratios in the\ncase of underlying deterministic PLGs for $\\beta$ greater than $1.666$. For\nunderlying random PLGs we further improve the analysis and show even better\nexpected approximation ratio for the range of $\\beta$ between $1$ and $3.5$. On\nthe other hand we prove the first explicit inapproximability bounds for\n$(1,2)$-TSP for an underlying power law graph. \n\n"}
{"id": "1509.04609", "contents": "Title: Randomized Block Subgradient Methods for Convex Nonsmooth and Stochastic\n  Optimization Abstract: Block coordinate descent methods and stochastic subgradient methods have been\nextensively studied in optimization and machine learning. By combining\nrandomized block sampling with stochastic subgradient methods based on dual\naveraging, we present stochastic block dual averaging (SBDA)---a novel class of\nblock subgradient methods for convex nonsmooth and stochastic optimization.\nSBDA requires only a block of subgradients and updates blocks of variables and\nhence has significantly lower iteration cost than traditional subgradient\nmethods. We show that the SBDA-based methods exhibit the optimal convergence\nrate for convex nonsmooth stochastic optimization. More importantly, we\nintroduce randomized stepsize rules and block sampling schemes that are\nadaptive to the block structures, which significantly improves the convergence\nrate w.r.t. the problem parameters. This is in sharp contrast to recent block\nsubgradient methods applied to nonsmooth deterministic or stochastic\noptimization. For strongly convex objectives, we propose a new averaging scheme\nto make the regularized dual averaging method optimal, without having to resort\nto any accelerated schemes. \n\n"}
{"id": "1509.06245", "contents": "Title: On the attainable distributions of controlled-diffusion processes\n  pertaining to a chain of distributed systems Abstract: We consider a controlled-diffusion process pertaining to a chain of\ndistributed systems with random perturbations that satisfies a weak H\\\"ormander\ntype condition. In particular, we consider a stochastic control problem with\nthe following objectives that we would like to achieve. The first one being of\na reachability-type that consists of determining a set of attainable\ndistributions at a given time starting from an initial distribution, while the\nsecond one involves minimizing the relative entropy subject to the initial and\ndesired final attainable distributions. Using the logarithmic transformations\napproach from Fleming, we provide a sufficient condition on the existence of an\noptimal admissible control for such a stochastic control problem which is\namounted to changing the drift by a certain perturbation suggested by Jamison\nin the context of reciprocal processes. Moreover, such a perturbation coincides\nwith a minimum energy control among all admissible controls forcing the\ncontrolled-diffusion process to the desired final attainable distribution\nstarting from the initial distribution. Finally, we briefly remark on the\ninvariance property of the path-space measure for such a controlled-diffusion\nprocess pertaining to the chain of distributed systems. \n\n"}
{"id": "1509.06686", "contents": "Title: Asymptotic stability of wave equations coupled by velocities Abstract: This paper is devoted to study the asymptotic stability of wave equations\nwith constant coefficients coupled by velocities. By using Riesz basis\napproach, multiplier method and frequency domain approach respectively, we find\nthe sufficient and necessary condition, that the coefficients satisfy, leading\nto the exponential stability of the system. In addition, we give the optimal\ndecay rate in one dimensional case. \n\n"}
{"id": "1509.08224", "contents": "Title: A geometric answer to an open question of singular control with stopping Abstract: We solve a problem of singular stochastic control with discretionary\nstopping, suggested as an interesting open problem by Karatzas, Ocone, Wang and\nZervos (2000), by providing suitable candidates for the moving boundaries in an\nunsolved parameter range. We proceed by identifying an optimal stopping problem\nwith similar variational inequalities and inspecting its parameter-dependent\ngeometry (in a sense going back to Dynkin (1965)), which reveals a\ndiscontinuity not previously exploited. We thus highlight the potential\nimportance of this geometric information in both singular control and\nparameter-dependent optimal stopping. \n\n"}
{"id": "1509.08451", "contents": "Title: Phase Retrieval Using Feasible Point Pursuit: Algorithms and\n  Cram\\'er-Rao Bound Abstract: Reconstructing a signal from squared linear (rank-one quadratic) measurements\nis a challenging problem with important applications in optics and imaging,\nwhere it is known as phase retrieval. This paper proposes two new phase\nretrieval algorithms based on non-convex quadratically constrained quadratic\nprogramming (QCQP) formulations, and a recently proposed approximation\ntechnique dubbed feasible point pursuit (FPP). The first is designed for\nuniformly distributed bounded measurement errors, such as those arising from\nhigh-rate quantization (B-FPP). The second is designed for Gaussian measurement\nerrors, using a least squares criterion (LS-FPP). Their performance is measured\nagainst state-of-the-art algorithms and the Cram\\'er-Rao bound (CRB), which is\nalso derived here. Simulations show that LS-FPP outperforms the state-of-art\nand operates close to the CRB. Compact CRB expressions, properties, and\ninsights are obtained by explicitly computing the CRB in various special cases\n-- including when the signal of interest admits a sparse parametrization, using\nharmonic retrieval as an example. \n\n"}
{"id": "1509.09259", "contents": "Title: Distributionally Robust Logistic Regression Abstract: This paper proposes a distributionally robust approach to logistic\nregression. We use the Wasserstein distance to construct a ball in the space of\nprobability distributions centered at the uniform distribution on the training\nsamples. If the radius of this ball is chosen judiciously, we can guarantee\nthat it contains the unknown data-generating distribution with high confidence.\nWe then formulate a distributionally robust logistic regression model that\nminimizes a worst-case expected logloss function, where the worst case is taken\nover all distributions in the Wasserstein ball. We prove that this optimization\nproblem admits a tractable reformulation and encapsulates the classical as well\nas the popular regularized logistic regression problems as special cases. We\nfurther propose a distributionally robust approach based on Wasserstein balls\nto compute upper and lower confidence bounds on the misclassification\nprobability of the resulting classifier. These bounds are given by the optimal\nvalues of two highly tractable linear programs. We validate our theoretical\nout-of-sample guarantees through simulated and empirical experiments. \n\n"}
{"id": "1510.00793", "contents": "Title: Skew-selfadjoint Dirac systems: stability of the procedure of explicit\n  solving the inverse problem Abstract: Procedures to recover explicitly discrete and continuous skew-selfadjoint\nDirac systems on semi-axis from rational Weyl matrix functions are considered.\nTheir stability is shown. Some new facts on asymptotics of pseudo-exponential\npotentials (i.e., of explicit solutions of inverse problems) are proved as\nwell. GBDT version of Backlund-Darboux transformation, methods from system\ntheory and results on algebraic Riccati equations are used for this purpose. \n\n"}
{"id": "1510.01946", "contents": "Title: Consensus Control for Heterogeneous Multi-Agent Systems Abstract: We study distributed output feedback control for a heterogeneous multi-agent\nsystem (MAS), consisting of N different continuous-time linear dynamical\nsystems. For achieving output consensus, a virtual reference model is assumed\nto generate the desired trajectory that the MAS is required to track and\nsynchronize. A distinct feature of our results lies in the local optimality and\nrobustness achieved by our proposed consensus control algorithm. In addition\nour study is focused on the case when the available output measurements contain\nonly relative information from the neighboring agents and reference signal.\nIndeed by exploiting properties of strictly positive real (SPR) transfer\nmatrices, conditions are derived for the existence of distributed output\nfeedback control protocols, and solutions are proposed to synthesize the\nstabilizing and consensus control protocol over a given connected digraph. It\nis shown that design techniques based on the LQG, LQG/LTR and H-infinity loop\nshaping can all be directly applied to synthesize the consensus output feedback\ncontrol protocol, thereby ensuring the local optimality and stability\nrobustness. Finally the reference trajectory is required to be transmitted to\nonly one or a few agents and no local reference models are employed in the\nfeedback controllers thereby eliminating synchronization of the local reference\nmodels. Our results complement the existing ones, and are illustrated by a\nnumerical example. \n\n"}
{"id": "1510.02462", "contents": "Title: Secure State Estimation against Sensor Attacks in the Presence of Noise Abstract: We consider the problem of estimating the state of a noisy linear dynamical\nsystem when an unknown subset of sensors is arbitrarily corrupted by an\nadversary. We propose a secure state estimation algorithm, and derive (optimal)\nbounds on the achievable state estimation error given an upper bound on the\nnumber of attacked sensors. The proposed state estimator involves Kalman\nfilters operating over subsets of sensors to search for a sensor subset which\nis reliable for state estimation. To further improve the subset search time, we\npropose Satisfiability Modulo Theory based techniques to exploit the\ncombinatorial nature of searching over sensor subsets. Finally, as a result of\nindependent interest, we give a coding theoretic view of attack detection and\nstate estimation against sensor attacks in a noiseless dynamical system. \n\n"}
{"id": "1510.04224", "contents": "Title: Controllability of Linear Systems on Generalized Heisenberg Groups Abstract: This paper is devoted to the study of controllability of linear systems on\ngeneralized Heisenberg groups. Some general necessary controllability\nconditions and some sufficient ones are provided. We introduce the notion of\ndecoupled systems, and more precise controllability criteria are stated for\nthem. \n\n"}
{"id": "1510.05761", "contents": "Title: Symmetry Reduction, Contact Geometry and Nonlinear Trajectory Planning Abstract: We study control systems invariant under a Lie group with application to the\nproblem of nonlinear trajectory planning. A theory of symmetry reduction of\nexterior differential systems is employed to demonstrate how symmetry reduction\nand reconstruction is effective in the explicit, exact construction of planned\nsystem trajectories. We show that, while a given control system with symmetry\nmay not be static feedback linearizable or even flat, it may nevertheless\npossess a flat or even linearizable symmetry reduction and from this,\ntrajectory planning in the original system may often be carried out or greatly\nsimplified. We employ the contact geometry of Brunovsky normal forms to develop\ntools for detecting and analysing these phenomena. The effectiveness of this\napproach is illustrated by its application to a problem in the guidance of\nmarine vessels. A method is given for the exact and explicit planning of\nsurface trajectories of models for the control of under-actuated ships. It is\nshown that a 3-degrees-of-freedom control system for an under-actuated ship has\na symmetry reduction which permits us to give an elegant explicit, exact\nsolution to this problem. \n\n"}
{"id": "1510.06076", "contents": "Title: Chebyshev approximation for multivariate functions Abstract: In this paper, we derive optimality conditions (Chebyshev approximation) for\nmultivariate functions. The theory of Chebyshev (uniform) approximation for\nunivariate functions is very elegant. The optimality conditions are based on\nthe notion of alternance (maximal deviation points with alternating deviation\nsigns). It is not very straightforward, however, how to extend the notion of\nalternance to the case of multivariate functions. There have been several\nattempts to extend the theory of Chebyshev approximation to the case of\nmultivariate functions. We propose an alternative approach, which is based on\nthe notion of convexity and nonsmooth analysis. \n\n"}
{"id": "1510.07356", "contents": "Title: Decentralized Quadratically Approximated Alternating Direction Method of\n  Multipliers Abstract: This paper considers an optimization problem that components of the objective\nfunction are available at different nodes of a network and nodes are allowed to\nonly exchange information with their neighbors. The decentralized alternating\nmethod of multipliers (DADMM) is a well-established iterative method for\nsolving this category of problems; however, implementation of DADMM requires\nsolving an optimization subproblem at each iteration for each node. This\nprocedure is often computationally costly for the nodes. We introduce a\ndecentralized quadratic approximation of ADMM (DQM) that reduces computational\ncomplexity of DADMM by minimizing a quadratic approximation of the objective\nfunction. Notwithstanding that DQM successively minimizes approximations of the\ncost, it converges to the optimal arguments at a linear rate which is identical\nto the convergence rate of DADMM. Further, we show that as time passes the\ncoefficient of linear convergence for DQM approaches the one for DADMM.\nNumerical results demonstrate the effectiveness of DQM. \n\n"}
{"id": "1510.08573", "contents": "Title: On the convergence analysis of the optimized gradient method Abstract: This paper considers the problem of unconstrained minimization of smooth\nconvex functions having Lipschitz continuous gradients with known Lipschitz\nconstant. We recently proposed an optimized gradient method (OGM) for this\nproblem and showed that it has a worst-case convergence bound for the cost\nfunction decrease that is twice as small as that of Nesterov's fast gradient\nmethod (FGM), yet has a similarly efficient practical implementation. Drori\nshowed recently that OGM has optimal complexity over the general class of\nfirst-order methods. This optimality makes it important to study fully the\nconvergence properties of OGM. The previous worst-case convergence bound for\nOGM was derived for only the last iterate of a secondary sequence. This paper\nprovides an analytic convergence bound for the primary sequence generated by\nOGM. We then discuss additional convergence properties of OGM, including the\ninteresting fact that OGM has two types of worst-case functions: a piecewise\naffine-quadratic function and a quadratic function. These results help complete\nthe theory of optimal first-order methods for smooth convex minimization. \n\n"}
{"id": "1510.08999", "contents": "Title: Mean Square Stabilization of Vector LTI Systems over Power Constrained\n  Lossy Channels Abstract: This paper studies the mean square stabilization problem of vector LTI\nsystems over power constrained lossy channels. The communication channel is\nwith packet dropouts, additive noises and input power constraints. To overcome\nthe difficulty of optimally allocating channel resources among different\nsub-dynamics, schedulers are designed with time division multiplexing of\nchannels. An adaptive TDMA (Time Division Multiple Access) scheduler is\nproposed first, which is shown to be able to achieve a larger stabilizability\nregion than the conventional TDMA scheduler, and is optimal under some special\ncases. In particular, for two-dimensional systems, an optimal scheduler is\ndesigned, which provides the necessary and sufficient condition for mean square\nstabilization. \n\n"}
{"id": "1511.00065", "contents": "Title: A New Class of Problems in the Calculus of Variations Abstract: This paper investigates an infinite-horizon problems in the one-dimensional\ncalculus of variations, arising from the Ramsey model of endogeneous economic\ngrowth. Following Chichilnisky, we introduce an additional term, which models\nconcern for the well-being of future generations. We show that there are no\noptimal solutions, but that there are equilibrium strateges, i.e. Nash\nequilibria of the leader-follower game between successive generations. To solve\nthe problem, we approximate the Chichilnisky criterion by a biexponential\ncriterion, we characterize its equilibria by a pair of coupled differential\nequations of HJB type, and we go to the limit. We find all the equilibrium\nstrategies for the Chichilnisky criterion. The mathematical analysis is\ndifficult because one has to solve an implicit differential equation in the\nsense of Thom. Our analysis extends earlier work by Ekeland and Lazrak. It is\nshown that optimal solutions a class of problems raising from time\ninconsistency problems in the framework of the neoclassical one-sector model of\neconomic growth, and contains new results in environment economics. Without\nexogenous commitment mechanism, a notion of the equilibrium strategies instead\nof the optimal strategies is introduced. We characterized the equilibrium\nstrategies by an integro-differential equation system. For two special\ncriteria, the bi-exponential criteria and the Chichilnisky criteria, we\nestablished the existence of the equilibrium strategies. \n\n"}
{"id": "1511.01798", "contents": "Title: Optimality gaps in asymptotic dimensioning of many-server systems Abstract: The Quality-and-Efficiency-Driven (QED) regime provides a basis for solving\nasymptotic dimensioning problems that trade off revenue, costs and service\nquality. We derive bounds for the optimality gaps that capture the differences\nbetween the true optimum and the asymptotic optimum based on the QED\napproximations. Our bounds generalize earlier results for classical many-server\nsystems. We also apply our bounds to a many-server system with threshold\ncontrol. \n\n"}
{"id": "1511.04815", "contents": "Title: Convex programming with fast proximal and linear operators Abstract: We present Epsilon, a system for general convex programming using fast linear\nand proximal operators. As with existing convex programming frameworks, users\nspecify convex optimization problems using a natural grammar for mathematical\nexpressions, composing functions in a way that is guaranteed to be convex by\nthe rules of disciplined convex programming. Given such an input, the Epsilon\ncompiler transforms the optimization problem into a mathematically equivalent\nform consisting only of functions with efficient proximal operators---an\nintermediate representation we refer to as prox-affine form. By reducing\nproblems to this form, Epsilon enables solving general convex problems using a\nlarge library of fast proximal and linear operators; numerical examples on many\npopular problems from statistics and machine learning show that this often\nimproves running times by an order of magnitude or more vs. existing approaches\nbased on conic solvers. \n\n"}
{"id": "1511.06566", "contents": "Title: Acceleration of the PDHGM on strongly convex subspaces Abstract: We propose several variants of the primal-dual method due to Chambolle and\nPock. Without requiring full strong convexity of the objective functions, our\nmethods are accelerated on subspaces with strong convexity. This yields mixed\nrates, $O(1/N^2)$ with respect to initialisation and $O(1/N)$ with respect to\nthe dual sequence, and the residual part of the primal sequence. We demonstrate\nthe efficacy of the proposed methods on image processing problems lacking\nstrong convexity, such as total generalised variation denoising and total\nvariation deblurring. \n\n"}
{"id": "1511.07086", "contents": "Title: Neighboring Optimal Guidance for Low-Thrust Multi-Burn Orbital Transfers Abstract: This paper presents a novel neighboring extremal approach to establish the\nneighboring optimal guidance (NOG) strategy for fixed-time low-thrust\nmulti-burn orbital transfer problems. Unlike the classical variational methods\nwhich define and solve an accessory minimum problem (AMP) to design the NOG,\nthe core of the proposed method is to construct a parameterized family of\nneighboring extremals around a nominal one. A geometric analysis on the\nprojection behavior of the parameterized neighboring extremals shows that it is\nimpossible to establish the NOG unless not only the typical Jacobi condition\n(JC) between switching times but also a transversal condition (TC) at each\nswitching time is satisfied. According to the theory of field of extremals, the\nJC and the TC, once satisfied, are also sufficient to ensure a multi-burn\nextremal trajectory to be locally optimal. Then, through deriving the\nfirst-order Taylor expansion of the parameterized neighboring extremals, the\nneighboring optimal feedbacks on thrust direction and switching times are\nobtained. Finally, to verify the development of this paper, a fixed-time\nlow-thrust fuel-optimal orbital transfer problem is calculated. \n\n"}
{"id": "1511.07549", "contents": "Title: Using tropical optimization to solve constrained minimax single-facility\n  location problems with rectilinear distance Abstract: The aim of this paper is twofold: first, to extend the area of applications\nof tropical optimization by solving new constrained location problems, and\nsecond, to offer new closed-form solutions to general problems that are of\ninterest to location analysis. We consider a constrained minimax\nsingle-facility location problem with addends on the plane with rectilinear\ndistance. The solution commences with the representation of the problem in a\nstandard form, and then in terms of tropical mathematics, as a constrained\noptimization problem. We use a transformation technique, which can act as a\ntemplate to handle optimization problems in other application areas, and hence\nis of independent interest. To solve the constrained optimization problem, we\napply methods and results of tropical optimization, which provide direct,\nexplicit solutions. The results obtained serve to derive new solutions of the\nlocation problem, and of its special cases with reduced sets of constraints, in\na closed form, ready for practical implementation and immediate computation. As\nillustrations, numerical solutions of example problems and their graphical\nrepresentation are given. We conclude with an application of the results to\noptimal location of the central monitoring facility in an indoor video\nsurveillance system in a multi-floor building environment. \n\n"}
{"id": "1511.07974", "contents": "Title: Distributed Resource Allocation Over Random Networks Based on Stochastic\n  Approximation Abstract: In this paper, a stochastic approximation (SA) based distributed algorithm is\nproposed to solve the resource allocation (RA) with uncertainties. In this\nproblem, a group of agents cooperatively optimize a separable optimization\nproblem with a linear network resource constraint and allocation feasibility\nconstraints, where the global objective function is the sum of agents' local\nobjective functions. Each agent can only get noisy observations of its local\nfunction's gradient and its local resource, which cannot be shared by other\nagents or transmitted to a center. Moreover, there are communication\nuncertainties such as time-varying topologies (described by random graphs) and\nadditive channel noises. To solve the RA, we propose an SA-based distributed\nalgorithm, and prove that agents can collaboratively achieve the optimal\nallocation with probability one by virtue of ordinary differential equation\n(ODE) method for SA. Finally, simulations related to the demand response\nmanagement in power systems verify the effectiveness of the proposed algorithm. \n\n"}
{"id": "1512.04039", "contents": "Title: Distributed Optimization with Arbitrary Local Solvers Abstract: With the growth of data and necessity for distributed optimization methods,\nsolvers that work well on a single machine must be re-designed to leverage\ndistributed computation. Recent work in this area has been limited by focusing\nheavily on developing highly specific methods for the distributed environment.\nThese special-purpose methods are often unable to fully leverage the\ncompetitive performance of their well-tuned and customized single machine\ncounterparts. Further, they are unable to easily integrate improvements that\ncontinue to be made to single machine methods. To this end, we present a\nframework for distributed optimization that both allows the flexibility of\narbitrary solvers to be used on each (single) machine locally, and yet\nmaintains competitive performance against other state-of-the-art\nspecial-purpose distributed methods. We give strong primal-dual convergence\nrate guarantees for our framework that hold for arbitrary local solvers. We\ndemonstrate the impact of local solver selection both theoretically and in an\nextensive experimental comparison. Finally, we provide thorough implementation\ndetails for our framework, highlighting areas for practical performance gains. \n\n"}
{"id": "1512.05402", "contents": "Title: Optimization over Structured Subsets of Positive Semidefinite Matrices\n  via Column Generation Abstract: We develop algorithms for inner approximating the cone of positive\nsemidefinite matrices via linear programming and second order cone programming.\nStarting with an initial linear algebraic approximation suggested recently by\nAhmadi and Majumdar, we describe an iterative process through which our\napproximation is improved at every step. This is done using ideas from column\ngeneration in large-scale linear and integer programming. We then apply these\ntechniques to approximate the sum of squares cone in a nonconvex polynomial\noptimization setting, and the copositive cone for a discrete optimization\nproblem. \n\n"}
{"id": "1512.05891", "contents": "Title: Optimality Conditions for Weak and Strong Local Extrema in Infinite\n  Horizon Optimal Control Problems Abstract: In this paper we summarize our results in infinite horizon optimal control.\nWe present optimality conditions for weak local minimizer in the framework of\nweighted functions. Moreover we formulate the Pontryagin Maximum Principle for\nstrong local minimizer for trajectories converging at infinity. The considered\nproblems, the requirements and the results depend on the choice of the function\nspace. \n\n"}
{"id": "1512.06427", "contents": "Title: Towards Integrated Glance To Restructuring in Combinatorial Optimization Abstract: The paper focuses on a new class of combinatorial problems which consists in\nrestructuring of solutions (as sets/structures) in combinatorial optimization.\nTwo main features of the restructuring process are examined: (i) a cost of the\nrestructuring, (ii) a closeness to a goal solution. Three types of the\nrestructuring problems are under study: (a) one-stage structuring, (b)\nmulti-stage structuring, and (c) structuring over changed element set.\nOne-criterion and multicriteria problem formulations can be considered. The\nrestructuring problems correspond to redesign (improvement, upgrade) of modular\nsystems or solutions. The restructuring approach is described and illustrated\n(problem statements, solving schemes, examples) for the following combinatorial\noptimization problems: knapsack problem, multiple choice problem, assignment\nproblem, spanning tree problems, clustering problem, multicriteria ranking\n(sorting) problem, morphological clique problem. Numerical examples illustrate\nthe restructuring problems and solving schemes. \n\n"}
{"id": "1512.06516", "contents": "Title: Local exact controllability for the 2 and 3-d compressible Navier-Stokes\n  equations Abstract: The goal of this article is to present a local exact controllability result\nfor the 2 and 3-dimensional compressible Navier-Stokes equations on a constant\ntarget trajectory when the controls act on the whole boundary. Our study is\nthen based on the observability of the adjoint system of some linearized\nversion of the system, which is analyzed thanks to a subsystem for which the\ncoupling terms are somewhat weaker. In this step, we strongly use Carleman\nestimates in negative Sobolev spaces. \n\n"}
{"id": "1512.07866", "contents": "Title: Bellman equation and viscosity solutions for mean-field stochastic\n  control problem Abstract: We consider the stochastic optimal control problem of McKean-Vlasov\nstochastic differential equation where the coefficients may depend upon the\njoint law of the state and control. By using feedback controls, we reformulate\nthe problem into a deterministic control problem with only the marginal\ndistribution of the process as controlled state variable, and prove that\ndynamic programming principle holds in its general form. Then, by relying on\nthe notion of differentiability with respect to pro\\-bability measures recently\nintroduced by P.L. Lions in [32], and a special It{\\^o} formula for flows of\nprobability measures, we derive the (dynamic programming) Bellman equation for\nmean-field stochastic control problem, and prove a veri\\-fication theorem in\nour McKean-Vlasov framework. We give explicit solutions to the Bellman equation\nfor the linear quadratic mean-field control problem, with applications to the\nmean-variance portfolio selection and a systemic risk model. We also consider a\nnotion of lifted visc-sity solutions for the Bellman equation, and show the\nviscosity property and uniqueness of the value function to the McKean-Vlasov\ncontrol problem. Finally, we consider the case of McKean-Vlasov control problem\nwith open-loop controls and discuss the associated dynamic programming equation\nthat we compare with the case of closed-loop controls. \n\n"}
{"id": "1512.08018", "contents": "Title: Primitive Zonotopes Abstract: We introduce and study a family of polytopes which can be seen as a\ngeneralization of the permutahedron of type $B_d$. We highlight connections\nwith the largest possible diameter of the convex hull of a set of points in\ndimension $d$ whose coordinates are integers between $0$ and $k$, and with the\ncomputational complexity of multicriteria matroid optimization. \n\n"}
{"id": "1512.08122", "contents": "Title: Distributed Linearized Alternating Direction Method of Multipliers for\n  Composite Convex Consensus Optimization Abstract: Given an undirected graph $\\mathcal{G}=(\\mathcal{N},\\mathcal{E})$ of agents\n$\\mathcal{N}=\\{1,\\ldots,N\\}$ connected with edges in $\\mathcal{E}$, we study\nhow to compute an optimal decision on which there is consensus among agents and\nthat minimizes the sum of agent-specific private convex composite functions\n$\\{\\Phi_i\\}_{i\\in\\mathcal{N}}$ while respecting privacy requirements, where\n$\\Phi_i\\triangleq \\xi_i + f_i$ belongs to agent-$i$. Assuming only agents\nconnected by an edge can communicate, we propose a distributed proximal\ngradient method DPGA for consensus optimization over both unweighted and\nweighted static (undirected) communication networks. In one iteration, each\nagent-$i$ computes the prox map of $\\xi_i$ and gradient of $f_i$, and this is\nfollowed by local communication with neighboring agents. We also study its\nstochastic gradient variant, SDPGA, which can only access to noisy estimates of\n$\\nabla f_i$ at each agent-$i$. This computational model abstracts a number of\napplications in distributed sensing, machine learning and statistical\ninference. We show ergodic convergence in both sub-optimality error and\nconsensus violation for DPGA and SDPGA with rates $\\mathcal{O}(1/t)$ and\n$\\mathcal{O}(1/\\sqrt{t})$, respectively. \n\n"}
{"id": "1512.08630", "contents": "Title: Construction of the Minimum Time Function Via Reachable Sets of Linear\n  Control Systems. Part 2: Numerical Computations Abstract: In the first part of this paper we introduced an algorithm that uses\nreachable set approximation to approximate the minimum time function of linear\ncontrol problems. To illustrate the error estimates and to demonstrate\ndifferences to other numerical approaches we provide a collection of numerical\nexamples which either allow higher order of convergence with respect to time\ndiscretization or where the continuity of the minimum time function cannot be\nsufficiently granted, i.e. we study cases in which the minimum time function is\nH\\\"older continuous or even discontinuous. \n\n"}
{"id": "1512.09235", "contents": "Title: A primal-dual fixed-point algorithm for minimization of the sum of three\n  convex separable functions Abstract: Many problems arising in image processing and signal recovery with\nmulti-regularization can be formulated as minimization of a sum of three convex\nseparable functions. Typically, the objective function involves a smooth\nfunction with Lipschitz continuous gradient, a linear composite nonsmooth\nfunction and a nonsmooth function. In this paper, we propose a primal-dual\nfixed-point (PDFP) scheme to solve the above class of problems. The proposed\nalgorithm for three block problems is a fully splitting symmetric scheme, only\ninvolving explicit gradient and linear operators without inner iteration, when\nthe nonsmooth functions can be easily solved via their proximity operators,\nsuch as $\\ell_1$ type regularization. We study the convergence of the proposed\nalgorithm and illustrate its efficiency through examples on fused LASSO and\nimage restoration with non-negative constraint and sparse regularization. \n\n"}
{"id": "1601.01399", "contents": "Title: An adaptive gradient method for computing generalized tensor eigenpairs Abstract: High order tensor arises more and more often in signal processing,data\nanalysis, higher-order statistics, as well as imaging sciences. In this paper,\nan adaptive gradient (AG) method is presented for generalized tensor\neigenpairs. Global convergence and linear convergence rate are established\nunder some suitable conditions. Numerical results are reported to illustrate\nthe efficiency of the proposed method. Comparing with the GEAP method, an\nadaptive shifted power method proposed by Tamara G. Kolda and Jackson R. Mayo\n[SIAM J. Matrix Anal. Appl., 35 (2014), pp. 1563-1581], the AG method is much\nfaster and could reach the largest eigenpair with a higher probability. \n\n"}
{"id": "1601.02010", "contents": "Title: Boundary control of a singular reaction-diffusion equation on a disk Abstract: Recently, the problem of boundary stabilization for unstable linear\nconstant-coefficient reaction-diffusion equation on N-balls has been solved by\nmeans of the backstepping method. However, the extension of this result to\nspatially-varying coefficients is far from trivial. This work deals with\nradially-varying reaction coefficients under revolution symmetry conditions on\na disk (the 2-D case). Under these conditions, the equations become singular in\nthe radius. When applying the backstepping method, the same type of singularity\nappears in the backstepping kernel equations. Traditionally, well-posedness of\nthe kernel equations is proved by transforming them into integral equations and\nthen applying the method of successive approximations. In this case, the\nresulting integral equation is singular. A successive approximation series can\nstill be formulated, however its convergence is challenging to show due to the\nsingularities. The problem is solved by a rather non-standard proof that uses\nthe properties of the Catalan numbers, a well-known sequence frequently used in\ncombinatorial mathematics. \n\n"}
{"id": "1601.05102", "contents": "Title: Monotone Order Properties for Control of Nonlinear Parabolic PDE on\n  Graphs Abstract: We derive conditions for the propagation of monotone ordering properties for\na class of nonlinear parabolic partial differential equation (PDE) systems on\nmetric graphs. For such systems, PDE equations with a general nonlinear\ndissipation term define evolution on each edge, and balance laws create\nKirchhoff-Neumann boundary conditions at the vertices. Initial conditions, as\nwell as time-varying parameters in the coupling conditions at vertices, provide\nan initial value problem (IVP). We first prove that ordering properties of the\nsolution to the IVP are preserved when the initial conditions and time-varying\ncoupling law parameters at vertices are appropriately ordered. In addition, we\nprove that when monotone ordering is not preserved, the first crossing of\nsolutions occurs at a graph vertex. We consider the implications for robust\noptimal control formulations and real-time monitoring involving uncertain\ndynamic flows on networks, and discuss application to subsonic compressible\nfluid flow with energy dissipation on physical networks. \n\n"}
{"id": "1601.06416", "contents": "Title: A Simple Accurate Method for Solving Fractional Variational and Optimal\n  Control Problems Abstract: We develop a simple and accurate method to solve fractional variational and\nfractional optimal control problems with dependence on Caputo and\nRiemann-Liouville operators. Using known formulas for computing fractional\nderivatives of polynomials, we rewrite the fractional functional dynamical\noptimization problem as a classical static optimization problem. The method for\nclassical optimal control problems is called Ritz's method. Examples show that\nthe proposed approach is more accurate than recent methods available in the\nliterature. \n\n"}
{"id": "1601.06464", "contents": "Title: Robust Global Solutions of Bilevel Polynomial Optimization Problems with\n  Uncertain Linear Constraints Abstract: This paper studies, for the first time, a bilevel polynomial program whose\nconstraints involve uncertain linear constraints and another uncertain linear\noptimization problem. In the case of box data uncertainty, we present a sum of\nsquares polynomial characterization of a global solution of its robust\ncounterpart where the constraints are enforced for all realizations of the\nuncertainties within the prescribed uncertainty sets. By characterizing a\nsolution of the robust counterpart of the lower-level uncertain linear program\nunder spectrahedral uncertainty using a new generalization of Farkas' lemma, we\nreformulate the robust bilevel program as a single level non-convex polynomial\noptimization problem. We then characterize a global solution of the single\nlevel polynomial program by employing Putinar's Positivstellensatz of algebraic\ngeometry under coercivity of the polynomial objective function. Consequently,\nwe show that the robust global optimal value of the bilevel program is the\nlimit of a sequence of values of Lasserre-type hierarchy of semidefinite linear\nprogramming relaxations. Numerical examples are given to show how the robust\noptimal value of the bilevel program can be calculated by solving semidefinite\nprogramming problems using the Matlab toolbox YALMIP. \n\n"}
{"id": "1602.00079", "contents": "Title: Unit Commitment with N-1 Security and Wind Uncertainty Abstract: As renewable wind energy penetration rates continue to increase, one of the\nmajor challenges facing grid operators is the question of how to control\ntransmission grids in a reliable and a cost-efficient manner. The stochastic\nnature of wind forces an alteration of traditional methods for solving\nday-ahead and look-ahead unit commitment and dispatch. In particular,\nuncontrollable wind generation increases the risk of random component failures.\nTo address these questions, we present an N-1 Security and Chance-Constrained\nUnit Commitment (SCCUC) that includes the modeling of generation reserves that\nrespond to wind fluctuations and tertiary reserves to account for single\ncomponent outages. The basic formulation is reformulated as a mixed-integer\nsecond-order cone problem to limit the probability of failure. We develop three\ndifferent algorithms to solve the problem to optimality and present a detailed\ncase study on the IEEE RTS-96 single area system. The case study assesses the\neconomic impacts due to contingencies and various degrees of wind power\npenetration into the system and also corroborates the effectiveness of the\nalgorithms. \n\n"}
{"id": "1602.01543", "contents": "Title: Semi-Stochastic Frank-Wolfe Algorithms with Away-Steps for\n  Block-Coordinate Structure Problems Abstract: We propose a semi-stochastic Frank-Wolfe algorithm with away-steps for\nregularized empirical risk minimization and extend it to problems with\nblock-coordinate structure. Our algorithms use adaptive step-size and we show\nthat they converge linearly in expectation. The proposed algorithms can be\napplied to many important problems in statistics and machine learning including\nregularized generalized linear models, support vector machines and many others.\nIn preliminary numerical tests on structural SVM and graph-guided fused LASSO,\nour algorithms outperform other competing algorithms in both iteration cost and\ntotal number of data passes. \n\n"}
{"id": "1602.02263", "contents": "Title: DOLPHIn - Dictionary Learning for Phase Retrieval Abstract: We propose a new algorithm to learn a dictionary for reconstructing and\nsparsely encoding signals from measurements without phase. Specifically, we\nconsider the task of estimating a two-dimensional image from squared-magnitude\nmeasurements of a complex-valued linear transformation of the original image.\nSeveral recent phase retrieval algorithms exploit underlying sparsity of the\nunknown signal in order to improve recovery performance. In this work, we\nconsider such a sparse signal prior in the context of phase retrieval, when the\nsparsifying dictionary is not known in advance. Our algorithm jointly\nreconstructs the unknown signal - possibly corrupted by noise - and learns a\ndictionary such that each patch of the estimated image can be sparsely\nrepresented. Numerical experiments demonstrate that our approach can obtain\nsignificantly better reconstructions for phase retrieval problems with noise\nthan methods that cannot exploit such \"hidden\" sparsity. Moreover, on the\ntheoretical side, we provide a convergence result for our method. \n\n"}
{"id": "1602.02923", "contents": "Title: Globally Optimal Energy-Efficient Power Control and Receiver Design in\n  Wireless Networks Abstract: The characterization of the global maximum of energy efficiency (EE) problems\nin wireless networks is a challenging problem due to the non-convex nature of\ninvestigated problems in interference channels. The aim of this work is to\ndevelop a new and general framework to achieve globally optimal solutions.\nFirst, the hidden monotonic structure of the most common EE maximization\nproblems is exploited jointly with fractional programming theory to obtain\nglobally optimal solutions with exponential complexity in the number of network\nlinks. To overcome this issue, we also propose a framework to compute\nsuboptimal power control strategies characterized by affordable complexity.\nThis is achieved by merging fractional programming and sequential optimization.\nThe proposed monotonic framework is used to shed light on the ultimate\nperformance of wireless networks in terms of EE and also to benchmark the\nperformance of the lower-complexity framework based on sequential programming.\nNumerical evidence is provided to show that the sequential fractional\nprogramming framework achieves global optimality in several practical\ncommunication scenarios. \n\n"}
{"id": "1602.04286", "contents": "Title: Geometric Adaptive Control of Attitude Dynamics on SO(3) with State\n  Inequality Constraints Abstract: This paper presents a new geometric adaptive control system with state\ninequality constraints for the attitude dynamics of a rigid body. The control\nsystem is designed such that the desired attitude is asymptotically stabilized,\nwhile the controlled attitude trajectory avoids undesired regions defined by an\ninequality constraint. In addition, we develop an adaptive update law that\nenables attitude stabilization in the presence of unknown disturbances. The\nattitude dynamics and the proposed control systems are developed on the special\northogonal group such that singularities and ambiguities of other attitude\nparameterizations, such as Euler angles and quaternions are completely avoided.\nThe effectiveness of the proposed control system is demonstrated through\nnumerical simulations and experimental results. \n\n"}
{"id": "1602.06180", "contents": "Title: An Approach to Constrained Polynomial Optimization via Nonnegative\n  Circuit Polynomials and Geometric Programming Abstract: In this article we combine two developments in polynomial optimization. On\nthe one hand, we consider nonnegativity certificates based on sums of\nnonnegative circuit polynomials, which were recently introduced by the second\nand the third author. On the other hand, we investigate geometric programming\nmethods for constrained polynomial optimization problems, which were recently\ndeveloped by Ghasemi and Marshall. We show that the combination of both results\nyields a new method to solve certain classes of constrained polynomial\noptimization problems. We test the new method experimentally and compare it to\nsemidefinite programming in various examples. \n\n"}
{"id": "1602.07630", "contents": "Title: Online Dual Coordinate Ascent Learning Abstract: The stochastic dual coordinate-ascent (S-DCA) technique is a useful\nalternative to the traditional stochastic gradient-descent algorithm for\nsolving large-scale optimization problems due to its scalability to large data\nsets and strong theoretical guarantees. However, the available S-DCA\nformulation is limited to finite sample sizes and relies on performing multiple\npasses over the same data. This formulation is not well-suited for online\nimplementations where data keep streaming in. In this work, we develop an {\\em\nonline} dual coordinate-ascent (O-DCA) algorithm that is able to respond to\nstreaming data and does not need to revisit the past data. This feature embeds\nthe resulting construction with continuous adaptation, learning, and tracking\nabilities, which are particularly attractive for online learning scenarios. \n\n"}
{"id": "1602.07819", "contents": "Title: SOCP Reformulation for the Generalized Trust Region Subproblem via a\n  Canonical Form of Two Symmetric Matrices Abstract: We investigate in this paper the generalized trust region subproblem (GTRS)\nof minimizing a general quadratic objective function subject to a general\nquadratic inequality constraint. By applying a simultaneous block\ndiagonalization approach, we obtain a congruent canonical form for the\nsymmetric matrices in both the objective and constraint functions. By\nexploiting the block separability of the canonical form, we show that all GTRSs\nwith an optimal value bounded from below are second order cone programming\n(SOCP) representable. Our result generalizes the recent work of Ben-Tal and\nHertog (Math. Program. 143(1-2):1-29, 2014), which establishes the SOCP\nrepresentability of the GTRS under the assumption of the simultaneous\ndiagonalizability of the two matrices in the objective and constraint\nfunctions. Compared with the state-of-the-art approach to reformulate the GTRS\nas a semi-definite programming problem, our SOCP reformulation delivers a much\nfaster solution algorithm. We further extend our method to two variants of the\nGTRS in which the inequality constraint is replaced by either an equality\nconstraint or an interval constraint. Our methods also enable us to obtain\nsimplified versions of the classical S-lemma, the S-lemma with equality, and\nthe S-lemma with interval bounds. \n\n"}
{"id": "1603.00300", "contents": "Title: Efficient 3-D Placement of an Aerial Base Station in Next Generation\n  Cellular Networks Abstract: Agility and resilience requirements of future cellular networks may not be\nfully satisfied by terrestrial base stations in cases of unexpected or\ntemporary events. A promising solution is assisting the cellular network via\nlow-altitude unmanned aerial vehicles equipped with base stations, i.e.,\ndrone-cells. Although drone-cells provide a quick deployment opportunity as\naerial base stations, efficient placement becomes one of the key issues. In\naddition to mobility of the drone-cells in the vertical dimension as well as\nthe horizontal dimension, the differences between the air-to-ground and\nterrestrial channels cause the placement of the drone-cells to diverge from\nplacement of terrestrial base stations. In this paper, we first highlight the\nproperties of the dronecell placement problem, and formulate it as a 3-D\nplacement problem with the objective of maximizing the revenue of the network.\nAfter some mathematical manipulations, we formulate an equivalent\nquadratically-constrained mixed integer non-linear optimization problem and\npropose a computationally efficient numerical solution for this problem. We\nverify our analytical derivations with numerical simulations and enrich them\nwith discussions which could serve as guidelines for researchers, mobile\nnetwork operators, and policy makers. \n\n"}
{"id": "1603.01517", "contents": "Title: Optimal Control of a Parabolic Distributed Parameter System Using a\n  Barycentric Shifted Gegenbauer Pseudospectral Method Abstract: In this paper, we introduce a novel pseudospectral method for the numerical\nsolution of optimal control problems governed by a parabolic distributed\nparameter system. The infinite-dimensional optimal control problem is reduced\ninto a finite-dimensional nonlinear programming problem through shifted\nGegenbauer quadratures constructed using a stable barycentric representation of\nLagrange interpolating polynomials and explicit barycentric weights for the\nshifted Gegenbauer-Gauss (SGG) points. A rigorous error analysis of the method\nis presented, and a numerical test example is given to show the accuracy and\nefficiency of the proposed pseudospectral method. \n\n"}
{"id": "1603.03236", "contents": "Title: Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic\n  Differentiation Abstract: Optimization on manifolds is a class of methods for optimization of an\nobjective function, subject to constraints which are smooth, in the sense that\nthe set of points which satisfy the constraints admits the structure of a\ndifferentiable manifold. While many optimization problems are of the described\nform, technicalities of differential geometry and the laborious calculation of\nderivatives pose a significant barrier for experimenting with these methods.\n  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox\nfor optimization on manifolds, implemented in Python, that---similarly to the\nManopt Matlab toolbox---implements several manifold geometries and optimization\nalgorithms. Moreover, we lower the barriers to users further by using automated\ndifferentiation for calculating derivative information, saving users time and\nsaving them from potential calculation and implementation errors. \n\n"}
{"id": "1603.03634", "contents": "Title: A Semidefinite Hierarchy for Disjointly Constrained Multilinear\n  Programming Abstract: Disjointly constrained multilinear programming concerns the problem of\nmaximizing a multilinear function on the product of finitely many disjoint\npolyhedra. While maximizing a linear function on a polytope (linear\nprogramming) is known to be solvable in polynomial time, even bilinear\nprogramming is NP-hard. Based on a reformulation of the problem in terms of\nsum-of-squares polynomials, we study a hierarchy of semidefinite relaxations to\nthe problem. It follows from the general theory that the sequence of optimal\nvalues converges asymptotically to the optimal value of the multilinear\nprogram. We show that the semidefinite hierarchy converges generically in\nfinitely many steps to the optimal value of the multilinear problem. We outline\ntwo applications of the main result. For nondegenerate bimatrix games, a Nash\nequilibrium can be computed by the sum of squares approach in finitely many\nsteps. Under an additional geometric condition, the NP-complete containment\nproblem for projections of $\\mathcal{H}$-polytopes can be decided in finitely\nmany steps. \n\n"}
{"id": "1603.04064", "contents": "Title: A Grothendieck-type inequality for local maxima Abstract: A large number of problems in optimization, machine learning, signal\nprocessing can be effectively addressed by suitable semidefinite programming\n(SDP) relaxations. Unfortunately, generic SDP solvers hardly scale beyond\ninstances with a few hundreds variables (in the underlying combinatorial\nproblem). On the other hand, it has been observed empirically that an effective\nstrategy amounts to introducing a (non-convex) rank constraint, and solving the\nresulting smooth optimization problem by ascent methods. This non-convex\nproblem has --generically-- a large number of local maxima, and the reason for\nthis success is therefore unclear.\n  This paper provides rigorous support for this approach. For the problem of\nmaximizing a linear functional over the elliptope, we prove that all local\nmaxima are within a small gap from the SDP optimum. In several problems of\ninterest, arbitrarily small relative error can be achieved by taking the rank\nconstraint $k$ to be of order one, independently of the problem size. \n\n"}
{"id": "1603.04949", "contents": "Title: A Reduced Order Direct Coupling Coherent Quantum Observer for a Complex\n  Quantum Plant Abstract: This paper extends previous results on constructing a direct coupling quantum\nobserver for a quantum harmonic oscillator system. In this case, we consider a\ncomplex linear quantum system plant consisting of a network of quantum harmonic\noscillators. Conditions are given for which there exists a direct coupling\nobserver which estimates a collection of variables in the quantum plant. It is\nshown that the order of the observer can be the same as the number of variables\nto be estimated when this number is even and thus this is a reduced order\nobserver. \n\n"}
{"id": "1603.05296", "contents": "Title: Exact Clustering of Weighted Graphs via Semidefinite Programming Abstract: As a model problem for clustering, we consider the densest k-disjoint-clique\nproblem of partitioning a weighted complete graph into k disjoint subgraphs\nsuch that the sum of the densities of these subgraphs is maximized. We\nestablish that such subgraphs can be recovered from the solution of a\nparticular semidefinite relaxation with high probability if the input graph is\nsampled from a distribution of clusterable graphs. Specifically, the\nsemidefinite relaxation is exact if the graph consists of k large disjoint\nsubgraphs, corresponding to clusters, with weight concentrated within these\nsubgraphs, plus a moderate number of outliers. Further, we establish that if\nnoise is weakly obscuring these clusters, i.e, the between-cluster edges are\nassigned very small weights, then we can recover significantly smaller\nclusters. For example, we show that in approximately sparse graphs, where the\nbetween-cluster weights tend to zero as the size n of the graph tends to\ninfinity, we can recover clusters of size polylogarithmic in n. Empirical\nevidence from numerical simulations is also provided to support these\ntheoretical phase transitions to perfect recovery of the cluster structure. \n\n"}
{"id": "1603.05533", "contents": "Title: Compressed sensing of data with a known distribution Abstract: Compressed sensing is a technique for recovering an unknown sparse signal\nfrom a small number of linear measurements. When the measurement matrix is\nrandom, the number of measurements required for perfect recovery exhibits a\nphase transition: there is a threshold on the number of measurements after\nwhich the probability of exact recovery quickly goes from very small to very\nlarge. In this work we are able to reduce this threshold by incorporating\nstatistical information about the data we wish to recover. Our algorithm works\nby minimizing a suitably weighted $\\ell_1$-norm, where the weights are chosen\nso that the expected statistical dimension of the corresponding descent cone is\nminimized. We also provide new discrete-geometry-based Monte Carlo algorithms\nfor computing intrinsic volumes of such descent cones, allowing us to bound the\nfailure probability of our methods. \n\n"}
{"id": "1603.06916", "contents": "Title: Solving generic nonarchimedean semidefinite programs using stochastic\n  game algorithms Abstract: A general issue in computational optimization is to develop combinatorial\nalgorithms for semidefinite programming. We address this issue when the base\nfield is nonarchimedean. We provide a solution for a class of semidefinite\nfeasibility problems given by generic matrices. Our approach is based on\ntropical geometry. It relies on tropical spectrahedra, which are defined as the\nimages by the valuation of nonarchimedean spectrahedra. We establish a\ncorrespondence between generic tropical spectrahedra and zero-sum stochastic\ngames with perfect information. The latter have been well studied in\nalgorithmic game theory. This allows us to solve nonarchimedean semidefinite\nfeasibility problems using algorithms for stochastic games. These algorithms\nare of a combinatorial nature and work for large instances. \n\n"}
{"id": "1603.07133", "contents": "Title: Ensemble controllability by Lie algebraic methods Abstract: We study possibilities to control an ensemble (a parameterized family) of\nnonlinear control systems by a single parameter-independent control. Proceeding\nby Lie algebraic methods we establish genericity of exact controllability\nproperty for finite ensembles, prove sufficient approximate controllability\ncondition for a model problem in $\\mathbb{R}^3$, and provide a variant of\nRashevsky-Chow theorem for approximate controllability of control-linear\nensembles. \n\n"}
{"id": "1603.07383", "contents": "Title: Distributed Average Tracking for Second-order Agents with Nonlinear\n  Dynamics Abstract: This paper addresses distributed average tracking of physical second-order\nagents with nonlinear dynamics, where the interaction among the agents is\ndescribed by an undirected graph. In both agents' and reference inputs'\ndynamics, there is a nonlinear term that satisfying the Lipschitz-type\ncondition. To achieve the distributed average tracking problem in the presence\nof nonlinear term, a non-smooth filter and a control input are designed for\neach agent. The idea is that each filter outputs converge to the average of the\nreference inputs and the reference velocities asymptotically and in parallel\neach agent's position and velocity are driven to track its filter outputs. To\novercome the nonlinear term unboundedness effect, novel state-dependent time\nvarying gains are employed in each agent's filter and control input. In the\nproposed algorithm, each agent needs its neighbors' filters outputs besides its\nown filter outputs, absolute position and absolute velocity and its neighbors'\nreference inputs and reference velocities. Finally, the algorithm is simplified\nto achieve the distributed average tracking of physical second-order agents in\nthe presence of an unknown bounded term in both agents' and reference inputs'\ndynamics. \n\n"}
{"id": "1603.07686", "contents": "Title: On Existence of Solutions to Structured Lyapunov Inequalities Abstract: In this paper, we derive sufficient conditions on drift matrices under which\nblock-diagonal solutions to Lyapunov inequalities exist. The motivation for the\nproblem comes from a recently proposed basis pursuit algorithm. In particular,\nthis algorithm can provide approximate solutions to optimisation programmes\nwith constraints involving Lyapunov inequalities using linear or second order\ncone programming. This algorithm requires an initial feasible point, which we\naim to provide in this paper. Our existence conditions are based on the\nso-called $\\mathcal{H}$ matrices. We also establish a link between\n$\\mathcal{H}$ matrices and an application of a small gain theorem to the drift\nmatrix. We finally show how to construct these solutions in some cases without\nsolving the full Lyapunov inequality. \n\n"}
{"id": "1603.08099", "contents": "Title: Partial Convergence of Heterogeneous Hegselmann-Krause Opinion Dynamics Abstract: In opinion dynamics, the convergence of the heterogeneous Hegselmann-Krause\n(HK) dynamics has always been an open problem for years which looks forward to\nany essential progress. In this short note, we prove a partial convergence\nconclusion of the general heterogeneous HK dynamis. That is, there must be some\nagents who will reach static states in finite time, while the other opinions\nhave to evolve between them with a minimum distance if all the opinions does\nnot reach consensus. And this result leads to the convergence of two special\ncase of heterogeneous HK dynamics: the minimum confidence threshold is large\nenough, or the initial opinion difference is small enough. \n\n"}
{"id": "1603.09586", "contents": "Title: Singularity Degree of the Positive Semidefinite Matrix Completion\n  Problem Abstract: The singularity degree of a semidefinite programming problem is the smallest\nnumber of facial reduction steps to make the problem strictly feasible. We\nintroduce two new graph parameters, called the singularity degree and the\nnondegenerate singularity degree, based on the singularity degree of the\npositive semidefinite matrix completion problem. We give a characterization of\nthe class of graphs whose parameter value is equal to one for each parameter.\nSpecifically, we show that the singularity degree of a graph is equal to one if\nand only if the graph is chordal, and the nondegenerate singularity degree of a\ngraph is equal to one if and only if the graph is the clique sum of chordal\ngraphs and $K_4$-minor free graphs. We also show that the singularity degree is\nbounded by two if the treewidth is bounded by two, and exhibit a family of\ngraphs with treewidth three, whose singularity degree grows linearly in the\nnumber of vertices. \n\n"}
{"id": "1604.00548", "contents": "Title: Convex Estimation of the $\\alpha$-Confidence Reachable Sets of Systems\n  with Parametric Uncertainty Abstract: Accurately modeling and verifying the correct operation of systems\ninteracting in dynamic environments is challenging. By leveraging parametric\nuncertainty within the model description, one can relax the requirement to\ndescribe exactly the interactions with the environment; however, one must still\nguarantee that the model, despite uncertainty, behaves acceptably. This paper\npresents a convex optimization method to efficiently compute the set of\nconfigurations of a polynomial dynamical system that are able to safely reach a\nuser defined target set despite parametric uncertainty in the model. Since\nplanning in the presence of uncertainty can lead to undesirable conservatives,\nthis paper computes those trajectories of the uncertain nonlinear systems which\nare $\\alpha$-probable of reaching the desired configuration. The presented\napproach uses the notion of occupation measures to describe the evolution of\ntrajectories of a nonlinear system with parametric uncertainty as a linear\nequation over measures whose supports coincide with the trajectories under\ninvestigation. This linear equation is approximated with vanishing conservatism\nusing a hierarchy of semidefinite programs each of which is proven to compute\nan approximation to the set of initial conditions that are $\\alpha$-probable of\nreaching the user defined target set safely in spite of uncertainty. The\nefficacy of this method is illustrated on four systems with parametric\nuncertainty. \n\n"}
{"id": "1604.00652", "contents": "Title: Galaxy Redshifts from Discrete Optimization of Correlation Functions Abstract: We propose a new method of constraining the redshifts of individual\nextragalactic sources based on celestial coordinates and their ensemble\nstatistics. Techniques from integer linear programming are utilized to optimize\nsimultaneously for the angular two-point cross- and autocorrelation functions.\nOur novel formalism introduced here not only transforms the otherwise\nhopelessly expensive, brute-force combinatorial search into a linear system\nwith integer constraints but also is readily implementable in off-the-shelf\nsolvers. We adopt Gurobi, a commercial optimization solver, and use Python to\nbuild the cost function dynamically. The preliminary results on simulated data\nshow potential for future applications to sky surveys by complementing and\nenhancing photometric redshift estimators. Our approach is the first\napplication of integer linear programming to astronomical analysis. \n\n"}
{"id": "1604.00691", "contents": "Title: Event excitation for event-driven control and optimization of\n  multi-agent systems Abstract: We consider event-driven methods in a general framework for the control and\noptimization of multi-agent systems, viewing them as stochastic hybrid systems.\nSuch systems often have feasible realizations in which the events needed to\nexcite an on-line event-driven controller cannot occur, rendering the use of\nsuch controllers ineffective. We show that this commonly happens in\nenvironments which contain discrete points of interest which the agents must\nvisit. To address this problem in event-driven gradient-based optimization\nproblems, we propose a new metric for the objective function which creates a\npotential field guaranteeing that gradient values are non-zero when no events\nare present and which results in eventual event excitation. We apply this\napproach to the class of cooperative multi-agent data collection problems using\nthe event-driven Infinitesimal Perturbation Analysis (IPA) methodology and\ninclude numerical examples illustrating its effectiveness. \n\n"}
{"id": "1604.01074", "contents": "Title: GPU-accelerated stochastic predictive control of drinking water networks Abstract: Despite the proven advantages of scenario-based stochastic model predictive\ncontrol for the operational control of water networks, its applicability is\nlimited by its considerable computational footprint. In this paper we fully\nexploit the structure of these problems and solve them using a proximal\ngradient algorithm parallelizing the involved operations. The proposed\nmethodology is applied and validated on a case study: the water network of the\ncity of Barcelona. \n\n"}
{"id": "1604.01542", "contents": "Title: A biobjective approach to robustness based on location planning Abstract: Finding robust solutions of an optimization problem is an important issue in\npractice, and various concepts on how to define the robustness of a solution\nhave been suggested. The idea of recoverable robustness requires that a\nsolution can be recovered to a feasible one as soon as the realized scenario\nbecomes known. The usual approach in the literature is to minimize the\nobjective function value of the recovered solution in the nominal or in the\nworst case.\n  As the recovery itself is also costly, there is a trade-off between the\nrecovery costs and the solution value obtained; we study both, the recovery\ncosts and the solution value in the worst case in a biobjective setting.\n  To this end, we assume that the recovery costs can be described by a metric.\nWe demonstrate that this leads to a location planning problem, bringing\ntogether two fields of research which have been considered separate so far.\n  We show how weakly Pareto efficient solutions to this biobjective problem can\nbe computed by minimizing the recovery costs for a fixed worst-case objective\nfunction value and present approaches for the case of linear and quasiconvex\nproblems for finite uncertainty sets. We furthermore derive cases in which the\nsize of the uncertainty set can be reduced without changing the set of Pareto\nefficient solutions. \n\n"}
{"id": "1604.03257", "contents": "Title: Unified Convergence Analysis of Stochastic Momentum Methods for Convex\n  and Non-convex Optimization Abstract: Recently, {\\it stochastic momentum} methods have been widely adopted in\ntraining deep neural networks. However, their convergence analysis is still\nunderexplored at the moment, in particular for non-convex optimization. This\npaper fills the gap between practice and theory by developing a basic\nconvergence analysis of two stochastic momentum methods, namely stochastic\nheavy-ball method and the stochastic variant of Nesterov's accelerated gradient\nmethod. We hope that the basic convergence results developed in this paper can\nserve the reference to the convergence of stochastic momentum methods and also\nserve the baselines for comparison in future development of stochastic momentum\nmethods. The novelty of convergence analysis presented in this paper is a\nunified framework, revealing more insights about the similarities and\ndifferences between different stochastic momentum methods and stochastic\ngradient method. The unified framework exhibits a continuous change from the\ngradient method to Nesterov's accelerated gradient method and finally the\nheavy-ball method incurred by a free parameter, which can help explain a\nsimilar change observed in the testing error convergence behavior for deep\nlearning. Furthermore, our empirical results for optimizing deep neural\nnetworks demonstrate that the stochastic variant of Nesterov's accelerated\ngradient method achieves a good tradeoff (between speed of convergence in\ntraining error and robustness of convergence in testing error) among the three\nstochastic methods. \n\n"}
{"id": "1604.03800", "contents": "Title: Tracking of Lines in Spherical Images via Sub-Riemannian Geodesics on\n  SO(3) Abstract: In order to detect salient lines in spherical images, we consider the problem\nof minimizing the functional $\\int \\limits_0^l C(\\gamma(s)) \\sqrt{\\xi^2 +\nk_g^2(s)} \\, {\\rm d}s$ for a curve $\\gamma$ on a sphere with fixed boundary\npoints and directions. The total length $l$ is free, $s$ denotes the spherical\narclength, and $k_g$ denotes the geodesic curvature of $\\gamma$. Here the\nsmooth external cost $C\\geq \\delta>0$ is obtained from spherical data. We lift\nthis problem to the sub-Riemannian (SR) problem in Lie group $SO(3)$ and show\nthat the spherical projection of certain SR geodesics provides a solution to\nour curve optimization problem. In fact, this holds only for the geodesics\nwhose spherical projection does not exhibit a cusp. The problem is a spherical\nextension of a well-known contour perception model, where we extend the model\nby Boscain and Rossi to the general case $\\xi > 0$, $C \\neq 1$. For $C=1$, we\nderive SR geodesics and evaluate the first cusp time. We show that these curves\nhave a simpler expression when they are parameterized by spherical arclength\nrather than by sub-Riemannian arclength. For case $C \\neq 1$ (data-driven SR\ngeodesics), we solve via a SR Fast Marching method. Finally, we show an\nexperiment of vessel tracking in a spherical image of the retina and study the\neffect of including the spherical geometry in analysis of vessels curvature. \n\n"}
{"id": "1604.03913", "contents": "Title: Dynamic Approaches for Some Time Inconsistent Problems Abstract: In this paper we investigate possible approaches to study general\ntime-inconsistent optimization problems without assuming the existence of\noptimal strategy. This leads immediately to the need to refine the concept of\ntime-consistency as well as any method that is based on Pontryagin's Maximum\nPrinciple. The fundamental obstacle is the dilemma of having to invoke the {\\it\nDynamic Programming Principle} (DPP) in a time-inconsistent setting, which is\ncontradictory in nature. The main contribution of this work is the introduction\nof the idea of the \"dynamic utility\" under which the original time inconsistent\nproblem (under the fixed utility) becomes a time consistent one. As a benchmark\nmodel, we shall consider a stochastic controlled problem with multidimensional\nbackward SDE dynamics, which covers many existing time-inconsistent problems in\nthe literature as special cases, and we argue that the time inconsistency is\nessentially equivalent to the lack of {\\it comparison principle}. We shall\npropose three approaches aiming at reviving the DPP in this setting: the\nduality approach, the dynamic utility approach, and the master equation\napproach. Unlike the game approach in many existing works in continuous time\nmodels, all our approaches produce the same value as the original static\nproblem. \n\n"}
{"id": "1604.04603", "contents": "Title: On the Douglas-Rachford algorithm Abstract: The Douglas-Rachford algorithm is a very popular splitting technique for\nfinding a zero of the sum of two maximally monotone operators. However, the\nbehaviour of the algorithm remains mysterious in the general inconsistent case,\ni.e., when the sum problem has no zeros. More than a decade ago, however, it\nwas shown that in the (possibly inconsistent) convex feasibility setting, the\nshadow sequence remains bounded and it is weak cluster points solve a best\napproximation problem.\n  In this paper, we advance the understanding of the inconsistent case\nsignificantly by providing a complete proof of the full weak convergence in the\nconvex feasibility setting. In fact, a more general sufficient condition for\nthe weak convergence in the general case is presented. Several examples\nillustrate the results. \n\n"}
{"id": "1604.04852", "contents": "Title: Efficient primal-dual fixed point algorithm with dynamic stepsize for\n  convex problems with applications to imaging restoration Abstract: We consider the problem of finding the minimization of the sum of a convex\nfunction and the composition of another convex function with a continuous\nlinear operator from the view of fixed point algorithms based on proximity\noperators. We design a primal-dual fixed point algorithm with dynamic stepsize\nbased on the proximity operator and obtain a scheme with a closed form solution\nfor each iteration. Based on Modified Mann iteration and the firmly\nnonexpansive properties of the proximity operator, we achieve the convergence\nof the proposed algorithm. \n\n"}
{"id": "1604.05694", "contents": "Title: Proximal Distance Algorithms: Theory and Examples Abstract: Proximal distance algorithms combine the classical penalty method of\nconstrained minimization with distance majorization. If $f(\\boldsymbol{x})$ is\nthe loss function, and $C$ is the constraint set in a constrained minimization\nproblem, then the proximal distance principle mandates minimizing the penalized\nloss $f(\\boldsymbol{x})+\\frac{\\rho}{2}\\mathop{dist}(x,C)^2$ and following the\nsolution $\\boldsymbol{x}_{\\rho}$ to its limit as $\\rho$ tends to $\\infty$. At\neach iteration the squared Euclidean distance\n$\\mathop{dist}(\\boldsymbol{x},C)^2$ is majorized by the spherical quadratic $\\|\n\\boldsymbol{x}-P_C(\\boldsymbol{x}_k)\\|^2$, where $P_C(\\boldsymbol{x}_k)$\ndenotes the projection of the current iterate $\\boldsymbol{x}_k$ onto $C$. The\nminimum of the surrogate function\n$f(\\boldsymbol{x})+\\frac{\\rho}{2}\\|\\boldsymbol{x}-P_C(\\boldsymbol{x}_k)\\|^2$ is\ngiven by the proximal map $\\mathop{prox}_{\\rho^{-1}f}[P_C(\\boldsymbol{x}_k)]$.\nThe next iterate $\\boldsymbol{x}_{k+1}$ automatically decreases the original\npenalized loss for fixed $\\rho$. Since many explicit projections and proximal\nmaps are known, it is straightforward to derive and implement novel\noptimization algorithms in this setting. These algorithms can take hundreds if\nnot thousands of iterations to converge, but the stereotyped nature of each\niteration makes proximal distance algorithms competitive with traditional\nalgorithms. For convex problems, we prove global convergence. Our numerical\nexamples include a) linear programming, b) nonnegative quadratic programming,\nc) projection to the closest kinship matrix, d) projection onto a second-order\ncone constraint, e) calculation of Horn's copositive matrix index, f) linear\ncomplementarity programming, and g) sparse principal components analysis. The\nproximal distance algorithm in each case is competitive or superior in speed to\ntraditional methods. \n\n"}
{"id": "1604.07120", "contents": "Title: A Comparative Study of STA on Large Scale Global Optimization Abstract: State transition algorithm has been emerging as a new intelligent global\noptimization method in recent few years. The standard continuous STA has\ndemonstrated powerful global search ability for global optimization problems\nwhose dimension is no more than 100. In this study, we give a test report to\npresent the performance of standard continuous STA for large scale global\noptimization when compared with other state-of-the-art evolutionary algorithms.\nFrom the experimental results, it is shown that the standard continuous STA\nstill works well for almost all of the test problems, and its global search\nability is much superior to its competitors. \n\n"}
{"id": "1605.00125", "contents": "Title: Efficiency of minimizing compositions of convex functions and smooth\n  maps Abstract: We consider global efficiency of algorithms for minimizing a sum of a convex\nfunction and a composition of a Lipschitz convex function with a smooth map.\nThe basic algorithm we rely on is the prox-linear method, which in each\niteration solves a regularized subproblem formed by linearizing the smooth map.\nWhen the subproblems are solved exactly, the method has efficiency\n$\\mathcal{O}(\\varepsilon^{-2})$, akin to gradient descent for smooth\nminimization. We show that when the subproblems can only be solved by\nfirst-order methods, a simple combination of smoothing, the prox-linear method,\nand a fast-gradient scheme yields an algorithm with complexity\n$\\widetilde{\\mathcal{O}}(\\varepsilon^{-3})$. The technique readily extends to\nminimizing an average of $m$ composite functions, with complexity\n$\\widetilde{\\mathcal{O}}(m/\\varepsilon^{2}+\\sqrt{m}/\\varepsilon^{3})$ in\nexpectation. We round off the paper with an inertial prox-linear method that\nautomatically accelerates in presence of convexity. \n\n"}
{"id": "1605.02585", "contents": "Title: System Intelligence: Model, Bounds and Algorithms Abstract: We present a general framework for understanding system intelligence, i.e.,\nthe level of system smartness perceived by users, and propose a novel metric\nfor measuring intelligence levels of dynamical human-in-the-loop systems,\ndefined to be the maximum average reward obtained by proactively serving user\ndemands, subject to a resource constraint. Our metric captures two important\nelements of smartness, i.e., being able to know what users want and pre-serve\nthem, and achieving good resource management while doing so. We provide an\nexplicit characterization of the system intelligence, and show that it is\njointly determined by user demand volume (opportunity to impress), demand\ncorrelation (user predictability), and system resource and action costs\n(flexibility to pre-serve).\n  We then propose an online learning-aided control algorithm called\nLearning-aided Budget-limited Intelligent System Control (\\mtt{LBISC}). We show\nthat \\lbisc{} achieves an intelligence level that is within\n$O(N(T)^{-\\frac{1}{2}}+\\epsilon)$ of the highest level, where $N(T)$ represents\nthe number of data samples collected within a learning period $T$ and is\nproportional to the user population size in the system, while guaranteeing an\n$O(\\max( N(T)^{-\\frac{1}{2}}/\\epsilon, \\log(1/\\epsilon)^2))$ average resource\ndeficit. Moreover, we show that \\lbisc{} possesses an $O(\\max(\nN(T)^{-\\frac{1}{2}}/\\epsilon$, $ \\log(1/\\epsilon)^2)+T)$ convergence time,\nwhich is much smaller compared to the $\\Theta(1/\\epsilon)$ time required for\nnon-learning based algorithms. The analysis of \\lbisc{} rigorously quantifies\nthe impacts of data and user population (captured by $N(T)$), learning\n(captured by our learning method), and control (captured by \\lbisc) on\nachievable system intelligence, and provides novel insight and guideline into\ndesigning future smart systems. \n\n"}
{"id": "1605.03243", "contents": "Title: On \"Exponential Lower Bounds for Polytopes in Combinatorial\n  Optimization\" by Fiorini et al. (2015): A Refutation For Models With Disjoint\n  Sets of Descriptive Variables Abstract: We provide a numerical refutation of the developments of Fiorini et al.\n(2015)* for models with disjoint sets of descriptive variables. We also provide\nan insight into the meaning of the existence of a one-to-one linear map between\nsolutions of such models.\n  *: Fiorini, S., S. Massar, S. Pokutta, H.R. Tiwary, and R. de Wolf (2015).\nExponential Lower Bounds for Polytopes in Combinatorial Optimization. Journal\nof the ACM 62:2, Article No. 17. \n\n"}
{"id": "1605.04814", "contents": "Title: Smart Meter Privacy with Renewable Energy and a Finite Capacity Battery Abstract: We address the smart meter (SM) privacy problem by considering the\navailability of a renewable energy source (RES) and a battery which can be\nexploited by a consumer to partially hide the consumption pattern from the\nutility provider (UP). Privacy is measured by the mutual information rate\nbetween the consumer's energy consumption and the renewable energy generation\nprocess, and the energy received from the grid, where the latter is known by\nthe UP through the SM readings, and the former two are to be kept private. By\nexpressing the information leakage as an additive quantity, we cast the problem\nas a stochastic control problem, and formulate the corresponding Bellman\nequations. \n\n"}
{"id": "1605.05232", "contents": "Title: Switching in time-optimal problem. The 3-D case with 2-D control Abstract: We study local structure of time-optimal controls and trajectories for a\n3-dimensional control-affine system with a 2-dimensional control parameter with\nvalues in the disk. In particular, we give sufficient conditions, in terms of\nLie bracket relations, for optimal controls to be smooth or to have only\nisolated jump discontinuities. \n\n"}
{"id": "1605.05641", "contents": "Title: Existence and almost everywhere regularity of isoperimetric clusters for\n  fractional perimeters Abstract: The existence of minimizers in the fractional isoperimetric problem with\nmultiple volume constraints is proved, together with a partial regularity\nresult. \n\n"}
{"id": "1605.06294", "contents": "Title: Regularity of Minimizers of Shape Optimization Problems involving\n  Perimeter Abstract: We prove existence and regularity of optimal shapes for the\nproblem$$\\min\\Big\\{P(\\Omega)+\\mathcal{G}(\\Omega):\\ \\Omega\\subset D,\\\n|\\Omega|=m\\Big\\},$$where $P$ denotes the perimeter, $|\\cdot|$ is the volume,\nand the functional $\\mathcal{G}$ is either one of the\nfollowing:\\textless{}ul\\textgreater{}\\textless{}li\\textgreater{} the Dirichlet\nenergy $E\\_f$, with respect to a (possibly sign-changing) function $f\\in\nL^p$;\\textless{}/li\\textgreater{}\\textless{}li\\textgreater{}a spectral\nfunctional of the form $F(\\lambda\\_{1},\\dots,\\lambda\\_{k})$, where $\\lambda\\_k$\nis the $k$th eigenvalue of the Dirichlet Laplacian and\n$F:\\mathbb{R}^k\\to\\mathbb{R}$ is Lipschitz continuous and increasing in each\nvariable.\\textless{}/li\\textgreater{}\\textless{}/ul\\textgreater{}The domain $D$\nis the whole space $\\mathbb{R}^d$ or a bounded domain. We also give general\nassumptions on the functional $\\mathcal{G}$ so that the result remains valid. \n\n"}
{"id": "1605.06492", "contents": "Title: Linear-memory and Decomposition-invariant Linearly Convergent\n  Conditional Gradient Algorithm for Structured Polytopes Abstract: Recently, several works have shown that natural modifications of the\nclassical conditional gradient method (aka Frank-Wolfe algorithm) for\nconstrained convex optimization, provably converge with a linear rate when: i)\nthe feasible set is a polytope, and ii) the objective is smooth and\nstrongly-convex. However, all of these results suffer from two significant\nshortcomings: large memory requirement due to the need to store an explicit\nconvex decomposition of the current iterate, and as a consequence, large\nrunning-time overhead per iteration, and worst case convergence rate that\ndepends unfavorably on the dimension.\n  In this work we present a new conditional gradient variant and a\ncorresponding analysis that improves on both of the above shortcomings. In\nparticular: both memory and computation overheads are only linear in the\ndimension. Moreover, in case the optimal solution is sparse, the new\nconvergence rate replaces a factor which is at least linear in the dimension in\nprevious works, with a linear dependence on the number of non-zeros in the\noptimal solution.\n  At the heart of our method, and corresponding analysis, is a novel way to\ncompute decomposition-invariant away-steps. While our theoretical guarantees do\nnot apply to any polytope, they apply to several important structured polytopes\nthat capture central concepts such as paths in graphs, perfect matchings in\nbipartite graphs, marginal distributions that arise in structured prediction\ntasks, and more. Our theoretical findings are complemented by empirical\nevidence which shows that our method delivers state-of-the-art performance. \n\n"}
{"id": "1605.06593", "contents": "Title: Online Influence Maximization under Independent Cascade Model with\n  Semi-Bandit Feedback Abstract: We study the online influence maximization problem in social networks under\nthe independent cascade model. Specifically, we aim to learn the set of \"best\ninfluencers\" in a social network online while repeatedly interacting with it.\nWe address the challenges of (i) combinatorial action space, since the number\nof feasible influencer sets grows exponentially with the maximum number of\ninfluencers, and (ii) limited feedback, since only the influenced portion of\nthe network is observed. Under a stochastic semi-bandit feedback, we propose\nand analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our\nbounds on the cumulative regret are polynomial in all quantities of interest,\nachieve near-optimal dependence on the number of interactions and reflect the\ntopology of the network and the activation probabilities of its edges, thereby\ngiving insights on the problem complexity. To the best of our knowledge, these\nare the first such results. Our experiments show that in several representative\ngraph topologies, the regret of IMLinUCB scales as suggested by our upper\nbounds. IMLinUCB permits linear generalization and thus is both statistically\nand computationally suitable for large-scale problems. Our experiments also\nshow that IMLinUCB with linear generalization can lead to low regret in\nreal-world online influence maximization. \n\n"}
{"id": "1605.07581", "contents": "Title: Generalized characteristics and Lax-Oleinik operators: global theory Abstract: For autonomous Tonelli systems on $\\R^n$, we develop an intrinsic proof of\nthe existence of generalized characteristics using sup-convolutions. This\napproach, together with convexity estimates for the fundamental solution, leads\nto new results such as the global propagation of singularities along\ngeneralized characteristics. \n\n"}
{"id": "1605.08101", "contents": "Title: Global rates of convergence for nonconvex optimization on manifolds Abstract: We consider the minimization of a cost function $f$ on a manifold $M$ using\nRiemannian gradient descent and Riemannian trust regions (RTR). We focus on\nsatisfying necessary optimality conditions within a tolerance $\\varepsilon$.\nSpecifically, we show that, under Lipschitz-type assumptions on the pullbacks\nof $f$ to the tangent spaces of $M$, both of these algorithms produce points\nwith Riemannian gradient smaller than $\\varepsilon$ in $O(1/\\varepsilon^2)$\niterations. Furthermore, RTR returns a point where also the Riemannian\nHessian's least eigenvalue is larger than $-\\varepsilon$ in\n$O(1/\\varepsilon^3)$ iterations. There are no assumptions on initialization.\nThe rates match their (sharp) unconstrained counterparts as a function of the\naccuracy $\\varepsilon$ (up to constants) and hence are sharp in that sense.\n  These are the first deterministic results for global rates of convergence to\napproximate first- and second-order Karush-Kuhn-Tucker points on manifolds.\nThey apply in particular for optimization constrained to compact submanifolds\nof $\\mathbb{R}^n$, under simpler assumptions. \n\n"}
{"id": "1605.08754", "contents": "Title: Faster Eigenvector Computation via Shift-and-Invert Preconditioning Abstract: We give faster algorithms and improved sample complexities for estimating the\ntop eigenvector of a matrix $\\Sigma$ -- i.e. computing a unit vector $x$ such\nthat $x^T \\Sigma x \\ge (1-\\epsilon)\\lambda_1(\\Sigma)$:\n  Offline Eigenvector Estimation: Given an explicit $A \\in \\mathbb{R}^{n \\times\nd}$ with $\\Sigma = A^TA$, we show how to compute an $\\epsilon$ approximate top\neigenvector in time $\\tilde O([nnz(A) + \\frac{d*sr(A)}{gap^2} ]* \\log\n1/\\epsilon )$ and $\\tilde O([\\frac{nnz(A)^{3/4} (d*sr(A))^{1/4}}{\\sqrt{gap}} ]\n* \\log 1/\\epsilon )$. Here $nnz(A)$ is the number of nonzeros in $A$, $sr(A)$\nis the stable rank, $gap$ is the relative eigengap. By separating the $gap$\ndependence from the $nnz(A)$ term, our first runtime improves upon the\nclassical power and Lanczos methods. It also improves prior work using fast\nsubspace embeddings [AC09, CW13] and stochastic optimization [Sha15c], giving\nsignificantly better dependencies on $sr(A)$ and $\\epsilon$. Our second running\ntime improves these further when $nnz(A) \\le \\frac{d*sr(A)}{gap^2}$.\n  Online Eigenvector Estimation: Given a distribution $D$ with covariance\nmatrix $\\Sigma$ and a vector $x_0$ which is an $O(gap)$ approximate top\neigenvector for $\\Sigma$, we show how to refine to an $\\epsilon$ approximation\nusing $ O(\\frac{var(D)}{gap*\\epsilon})$ samples from $D$. Here $var(D)$ is a\nnatural notion of variance. Combining our algorithm with previous work to\ninitialize $x_0$, we obtain improved sample complexity and runtime results\nunder a variety of assumptions on $D$.\n  We achieve our results using a general framework that we believe is of\nindependent interest. We give a robust analysis of the classic method of\nshift-and-invert preconditioning to reduce eigenvector computation to\napproximately solving a sequence of linear systems. We then apply fast\nstochastic variance reduced gradient (SVRG) based system solvers to achieve our\nclaims. \n\n"}
{"id": "1605.08823", "contents": "Title: Symmetric Tensor Nuclear Norms Abstract: This paper studies nuclear norms of symmetric tensors. As recently shown by\nFriedland and Lim, the nuclear norm of a symmetric tensor can be achieved at a\nsymmetric decomposition. We discuss how to compute symmetric tensor nuclear\nnorms, depending on the tensor order and the ground field. Lasserre relaxations\nare proposed for the computation. The theoretical properties of the relaxations\nare studied. For symmetric tensors, we can compute their nuclear norms, as well\nas the nuclear decompositions. The proposed methods can be extended to\nnonsymmetric tensors. \n\n"}
{"id": "1605.08882", "contents": "Title: Optimal Rates for Multi-pass Stochastic Gradient Methods Abstract: We analyze the learning properties of the stochastic gradient method when\nmultiple passes over the data and mini-batches are allowed. We study how\nregularization properties are controlled by the step-size, the number of passes\nand the mini-batch size. In particular, we consider the square loss and show\nthat for a universal step-size choice, the number of passes acts as a\nregularization parameter, and optimal finite sample bounds can be achieved by\nearly-stopping. Moreover, we show that larger step-sizes are allowed when\nconsidering mini-batches. Our analysis is based on a unifying approach,\nencompassing both batch and stochastic gradient methods as special cases. As a\nbyproduct, we derive optimal convergence results for batch gradient methods\n(even in the non-attainable cases). \n\n"}
{"id": "1605.08961", "contents": "Title: A simple and provable algorithm for sparse diagonal CCA Abstract: Given two sets of variables, derived from a common set of samples, sparse\nCanonical Correlation Analysis (CCA) seeks linear combinations of a small\nnumber of variables in each set, such that the induced canonical variables are\nmaximally correlated. Sparse CCA is NP-hard.\n  We propose a novel combinatorial algorithm for sparse diagonal CCA, i.e.,\nsparse CCA under the additional assumption that variables within each set are\nstandardized and uncorrelated. Our algorithm operates on a low rank\napproximation of the input data and its computational complexity scales\nlinearly with the number of input variables. It is simple to implement, and\nparallelizable. In contrast to most existing approaches, our algorithm\nadministers precise control on the sparsity of the extracted canonical vectors,\nand comes with theoretical data-dependent global approximation guarantees, that\nhinge on the spectrum of the input data. Finally, it can be straightforwardly\nadapted to other constrained variants of CCA enforcing structure beyond\nsparsity.\n  We empirically evaluate the proposed scheme and apply it on a real\nneuroimaging dataset to investigate associations between brain activity and\nbehavior measurements. \n\n"}
{"id": "1605.09157", "contents": "Title: Extreme properties of curves with bounded curvature on a sphere Abstract: We give a sharp lower bound on the area of the domain enclosed by an embedded\ncurve lying on a two-dimensional sphere, provided that geodesic curvature of\nthis curve is bounded from below. Furthermore, we prove some dual inequalities\nfor convex curves whose curvatures are bounded from above. \n\n"}
{"id": "1605.09739", "contents": "Title: Path Planning for Cooperative Routing of Air-Ground Vehicles Abstract: We consider a cooperative vehicle routing problem for surveillance and\nreconnaissance missions with communication constraints between the vehicles. We\npropose a framework which involves a ground vehicle and an aerial vehicle; the\nvehicles travel cooperatively satisfying the communication limits, and visit a\nset of targets. We present a mixed integer linear programming (MILP)\nformulation and develop a branch-and-cut algorithm to solve the path planning\nproblem for the ground and air vehicles. The effectiveness of the proposed\napproach is corroborated through extensive computational experiments on several\nrandomly generated instances. \n\n"}
{"id": "1605.09774", "contents": "Title: Asynchrony begets Momentum, with an Application to Deep Learning Abstract: Asynchronous methods are widely used in deep learning, but have limited\ntheoretical justification when applied to non-convex problems. We show that\nrunning stochastic gradient descent (SGD) in an asynchronous manner can be\nviewed as adding a momentum-like term to the SGD iteration. Our result does not\nassume convexity of the objective function, so it is applicable to deep\nlearning systems. We observe that a standard queuing model of asynchrony\nresults in a form of momentum that is commonly used by deep learning\npractitioners. This forges a link between queuing theory and asynchrony in deep\nlearning systems, which could be useful for systems builders. For convolutional\nneural networks, we experimentally validate that the degree of asynchrony\ndirectly correlates with the momentum, confirming our main result. An important\nimplication is that tuning the momentum parameter is important when considering\ndifferent levels of asynchrony. We assert that properly tuned momentum reduces\nthe number of steps required for convergence. Finally, our theory suggests new\nways of counteracting the adverse effects of asynchrony: a simple mechanism\nlike using negative algorithmic momentum can improve performance under high\nasynchrony. Since asynchronous methods have better hardware efficiency, this\nresult may shed light on when asynchronous execution is more efficient for deep\nlearning systems. \n\n"}
{"id": "1606.00229", "contents": "Title: Uncertainty and filtering of hidden Markov models in discrete time Abstract: We consider the problem of filtering an unseen Markov chain from noisy\nobservations, in the presence of uncertainty regarding the parameters of the\nprocesses involved. Using the theory of nonlinear expectations, we describe the\nuncertainty in terms of a penalty function, which can be propagated forward in\ntime in the place of the filter. \n\n"}
{"id": "1606.01327", "contents": "Title: Envelope Functions: Unifications and Further Properties Abstract: Recently, the forward-backward and Douglas-Rachford envelope functions were\nproposed in the literature. The stationary points of these envelope functions\nhave a close relationship with the solutions of the possibly nonsmooth\noptimization problem to be solved. The envelopes were shown to be smooth and\nconvex under some additional assumptions. Therefore, these envelope functions\ncreate powerful bridges between nonsmooth and smooth optimization.\n  In this paper, we present a general envelope function that unifies and\ngeneralizes these envelope functions. We provide properties of the general\nenvelope function that sharpen corresponding known results for the special\ncases. We also present an envelope function for the generalized alternating\nprojections method (GAP), named the GAP envelope. It enables for convex\nfeasibility problems with two sets, of which one is affine, to be solved by\nfinding any stationary point of the smooth and under some assumptions convex\nGAP envelope. \n\n"}
{"id": "1606.02635", "contents": "Title: Feedback Scheduling for Energy-Efficient Real-Time Homogeneous\n  Multiprocessor Systems Abstract: Real-time scheduling algorithms proposed in the literature are often based on\nworst-case estimates of task parameters. The performance of an open-loop scheme\ncan be degraded significantly if there are uncertainties in task parameters,\nsuch as the execution times of the tasks. Therefore, to cope with such a\nsituation, a closed-loop scheme, where feedback is exploited to adjust the\nsystem parameters, can be applied. We propose an optimal control framework that\ntakes advantage of feeding back information of finished tasks to solve a\nreal-time multiprocessor scheduling problem with uncertainty in task execution\ntimes, with the objective of minimizing the total energy consumption.\nSpecifically, we propose a linear programming based algorithm to solve a\nworkload partitioning problem and adopt McNaughton's wrap around algorithm to\nfind the task execution order. The simulation results illustrate that our\nfeedback scheduling algorithm can save energy by as much as 40% compared to an\nopen-loop method for two processor models, i.e. a PowerPC 405LP and an XScale\nprocessor. \n\n"}
{"id": "1606.03280", "contents": "Title: Optimal control of forward-backward stochastic Volterra equations Abstract: We study the problem of optimal control of a coupled system of\nforward-backward stochastic Volterra equations. We use Hida-Malliavin calculus\nto prove a sufficient and a necessary maximum principle for the optimal control\nof such systems. Existence and uniqueness of backward stochastic Volterra\nintegral equations are proved. As an application of our methods, we solve a\nrecursive utility optimisation problem in a financial model with memory. \n\n"}
{"id": "1606.04991", "contents": "Title: A Class of Parallel Doubly Stochastic Algorithms for Large-Scale\n  Learning Abstract: We consider learning problems over training sets in which both, the number of\ntraining examples and the dimension of the feature vectors, are large. To solve\nthese problems we propose the random parallel stochastic algorithm (RAPSA). We\ncall the algorithm random parallel because it utilizes multiple parallel\nprocessors to operate on a randomly chosen subset of blocks of the feature\nvector. We call the algorithm stochastic because processors choose training\nsubsets uniformly at random. Algorithms that are parallel in either of these\ndimensions exist, but RAPSA is the first attempt at a methodology that is\nparallel in both the selection of blocks and the selection of elements of the\ntraining set. In RAPSA, processors utilize the randomly chosen functions to\ncompute the stochastic gradient component associated with a randomly chosen\nblock. The technical contribution of this paper is to show that this minimally\ncoordinated algorithm converges to the optimal classifier when the training\nobjective is convex. Moreover, we present an accelerated version of RAPSA\n(ARAPSA) that incorporates the objective function curvature information by\npremultiplying the descent direction by a Hessian approximation matrix. We\nfurther extend the results for asynchronous settings and show that if the\nprocessors perform their updates without any coordination the algorithms are\nstill convergent to the optimal argument. RAPSA and its extensions are then\nnumerically evaluated on a linear estimation problem and a binary image\nclassification task using the MNIST handwritten digit dataset. \n\n"}
{"id": "1606.07380", "contents": "Title: Variable-Sized Uncertainty and Inverse Problems in Robust Optimization Abstract: In robust optimization, the general aim is to find a solution that performs\nwell over a set of possible parameter outcomes, the so-called uncertainty set.\nIn this paper, we assume that the uncertainty size is not fixed, and instead\naim at finding a set of robust solutions that covers all possible uncertainty\nset outcomes. We refer to these problems as robust optimization with\nvariable-sized uncertainty. We discuss how to construct smallest possible sets\nof min-max robust solutions and give bounds on their size.\n  A special case of this perspective is to analyze for which uncertainty sets a\nnominal solution ceases to be a robust solution, which amounts to an inverse\nrobust optimization problem. We consider this problem with a min-max regret\nobjective and present mixed-integer linear programming formulations that can be\napplied to construct suitable uncertainty sets.\n  Results on both variable-sized uncertainty and inverse problems are further\nsupported with experimental data. \n\n"}
{"id": "1607.02037", "contents": "Title: Refinement of the Equilibrium of Public Goods Games over Networks:\n  Efficiency and Effort of Specialized Equilibria Abstract: Recently Bramoulle and Kranton presented a model for the provision of public\ngoods over a network and showed the existence of a class of Nash equilibria\ncalled specialized equilibria wherein some agents exert maximum effort while\nother agents free ride. We examine the efficiency, effort and cost of\nspecialized equilibria in comparison to other equilibria. Our main results show\nthat the welfare of a particular specialized equilibrium approaches the maximum\nwelfare amongst all equilibria as the concavity of the benefit function tends\nto unity. For forest networks a similar result also holds as the concavity\napproaches zero. Moreover, without any such concavity conditions, there exists\nfor any network a specialized equilibrium that requires the maximum weighted\neffort amongst all equilibria. When the network is a forest, a specialized\nequilibrium also incurs the minimum total cost amongst all equilibria. For\nwell-covered forest networks we show that all welfare maximizing equilibria are\nspecialized and all equilibria incur the same total cost. Thus we argue that\nspecialized equilibria may be considered as a refinement of the equilibrium of\nthe public goods game. We show several results on the structure and efficiency\nof equilibria that highlight the role of dependants in the network. \n\n"}
{"id": "1607.02624", "contents": "Title: Beating level-set methods for 3D seismic data interpolation: a\n  primal-dual alternating approach Abstract: Acquisition cost is a crucial bottleneck for seismic workflows, and low-rank\nformulations for data interpolation allow practitioners to `fill in' data\nvolumes from critically subsampled data acquired in the field. Tremendous size\nof seismic data volumes required for seismic processing remains a major\nchallenge for these techniques.\n  We propose a new approach to solve residual constrained formulations for\ninterpolation. We represent the data volume using matrix factors, and build a\nblock-coordinate algorithm with constrained convex subproblems that are solved\nwith a primal-dual splitting scheme. The new approach is competitive with state\nof the art level-set algorithms that interchange the role of objectives with\nconstraints. We use the new algorithm to successfully interpolate a large scale\n5D seismic data volume, generated from the geologically complex synthetic 3D\nCompass velocity model, where 80% of the data has been removed. \n\n"}
{"id": "1607.03218", "contents": "Title: Achieving Geometric Convergence for Distributed Optimization over\n  Time-Varying Graphs Abstract: This paper considers the problem of distributed optimization over\ntime-varying graphs. For the case of undirected graphs, we introduce a\ndistributed algorithm, referred to as DIGing, based on a combination of a\ndistributed inexact gradient method and a gradient tracking technique. The\nDIGing algorithm uses doubly stochastic mixing matrices and employs fixed\nstep-sizes and, yet, drives all the agents' iterates to a global and consensual\nminimizer. When the graphs are directed, in which case the implementation of\ndoubly stochastic mixing matrices is unrealistic, we construct an algorithm\nthat incorporates the push-sum protocol into the DIGing structure, thus\nobtaining Push-DIGing algorithm. The Push-DIGing uses column stochastic\nmatrices and fixed step-sizes, but it still converges to a global and\nconsensual minimizer. Under the strong convexity assumption, we prove that the\nalgorithms converge at R-linear (geometric) rates as long as the step-sizes do\nnot exceed some upper bounds. We establish explicit estimates for the\nconvergence rates. When the graph is undirected it shows that DIGing scales\npolynomially in the number of agents. We also provide some numerical\nexperiments to demonstrate the efficacy of the proposed algorithms and to\nvalidate our theoretical findings. \n\n"}
{"id": "1607.03312", "contents": "Title: Compactness Criterion for Semimartingale Laws and Semimartingale Optimal\n  Transport Abstract: We provide a compactness criterion for the set of laws\n$\\mathfrak{P}^{ac}_{sem}(\\Theta)$ on the Skorokhod space for which the\ncanonical process $X$ is a semimartingale having absolutely continuous\ncharacteristics with differential characteristics taking values in some given\nset $\\Theta$ of L\\'evy triplets. Whereas boundedness of $\\Theta$ implies\ntightness of $\\mathfrak{P}^{ac}_{sem}(\\Theta)$, closedness fails in general,\neven when choosing $\\Theta$ to be additionally closed and convex, as a sequence\nof purely discontinuous martingales may converge to a diffusion. To that end,\nwe provide a necessary and sufficient condition that prevents the purely\ndiscontinuous martingale part in the canonical representation of $X$ to create\na diffusion part in the limit. As a result, we obtain a sufficient criterion\nfor $\\mathfrak{P}^{ac}_{sem}(\\Theta)$ to be compact, which turns out to be also\na necessary one if the geometry of $\\Theta$ is similar to a box on the product\nspace.\n  As an application, we consider a semimartingale optimal transport problem,\nwhere the transport plans are elements of $\\mathfrak{P}^{ac}_{sem}(\\Theta)$. We\nprove the existence of an optimal transport law $\\widehat{\\mathbb{P}}$ and\nobtain a duality result extending the classical Kantorovich duality to this\nsetup. \n\n"}
{"id": "1607.05375", "contents": "Title: Fractional Wishart Processes and $\\varepsilon$-Fractional Wishart\n  Processes with Applications Abstract: In this paper, we introduce two new matrix stochastic processes: fractional\nWishart processes and $\\varepsilon$-fractional Wishart processes with integer\nindices which are based on the fractional Brownian motions and then extend\n$\\varepsilon$-fractional Wishart processes to the case with non-integer\nindices. Both of two kinds of processes include classic Wishart processes when\nthe Hurst index $H$ equals $\\frac{1}{2}$ and present serial correlation of\nstochastic processes. Applying $\\varepsilon$-fractional Wishart processes to\nfinancial volatility theory, the financial models account for the stochastic\nvolatilities of the assets and for the stochastic correlations not only between\nthe underlying assets' returns but also between their volatilities and for\nstochastic serial correlation of the relevant assets. \n\n"}
{"id": "1607.06764", "contents": "Title: Generalizing the optimized gradient method for smooth convex\n  minimization Abstract: This paper generalizes the optimized gradient method (OGM) that achieves the\noptimal worst-case cost function bound of first-order methods for smooth convex\nminimization. Specifically, this paper studies a generalized formulation of OGM\nand analyzes its worst-case rates in terms of both the function value and the\nnorm of the function gradient. This paper also develops a new algorithm called\nOGM-OG that is in the generalized family of OGM and that has the best known\nanalytical worst-case bound with rate $O(1/N^{1.5})$ on the decrease of the\ngradient norm among fixed-step first-order methods. This paper also proves that\nNesterov's fast gradient method has an $O(1/N^{1.5})$ worst-case gradient norm\nrate but with constant larger than OGM-OG. The proof is based on the worst-case\nanalysis called Performance Estimation Problem. \n\n"}
{"id": "1607.07209", "contents": "Title: Short-term Forecasting of Price-responsive Loads Using Inverse\n  Optimization Abstract: We consider the problem of forecasting the aggregate demand of a pool of\nprice-responsive consumers of electricity. The price-response of the\naggregation is modeled by an optimization problem that is characterized by a\nset of marginal utility curves and minimum and maximum power consumption\nlimits. The task of estimating these parameters is addressed using a\ngeneralized inverse optimization scheme that, in turn, requires solving a\nnonconvex mathematical program. We introduce a solution method that overcomes\nthe nonconvexities by solving instead two linear problems with a penalty term,\nwhich is statistically adjusted by using a cross-validation algorithm. The\nproposed methodology is data-driven and leverages information from regressors,\nsuch as time and weather variables, to account for changes in the parameter\nestimates. The power load of a group of heating, ventilation, and air\nconditioning systems in buildings is simulated, and the results show that the\naggregate demand of the group can be successfully captured by the proposed\nmodel, making it suitable for short-term forecasting purposes. \n\n"}
{"id": "1607.08012", "contents": "Title: Learning of Generalized Low-Rank Models: A Greedy Approach Abstract: Learning of low-rank matrices is fundamental to many machine learning\napplications. A state-of-the-art algorithm is the rank-one matrix pursuit\n(R1MP). However, it can only be used in matrix completion problems with the\nsquare loss. In this paper, we develop a more flexible greedy algorithm for\ngeneralized low-rank models whose optimization objective can be smooth or\nnonsmooth, general convex or strongly convex. The proposed algorithm has low\nper-iteration time complexity and fast convergence rate. Experimental results\nshow that it is much faster than the state-of-the-art, with comparable or even\nbetter prediction performance. \n\n"}
{"id": "1607.08256", "contents": "Title: A new approach for the strong unique continuation of electromagnetic\n  Schroedinger operator with complex-valued coefficient Abstract: This paper mainly addresses the strong unique continuation property for the\nelectromagnetic Schr\\\"{o}dinger operator with complex-valued coefficients.\nAppropriate multipliers with physical backgrounds have been introduced to prove\na priori estimates. Moreover, its application in an exact controllability\nproblem has been shown, in which case, the boundary value determines the\ninterior value completely. \n\n"}
{"id": "1607.08863", "contents": "Title: Exponentially fast convergence to (strict) equilibrium via hedging Abstract: Motivated by applications to data networks where fast convergence is\nessential, we analyze the problem of learning in generic N-person games that\nadmit a Nash equilibrium in pure strategies. Specifically, we consider a\nscenario where players interact repeatedly and try to learn from past\nexperience by small adjustments based on local - and possibly imperfect -\npayoff information. For concreteness, we focus on the so-called \"hedge\" variant\nof the exponential weights algorithm where players select an action with\nprobability proportional to the exponential of the action's cumulative payoff\nover time. When players have perfect information on their mixed payoffs, the\nalgorithm converges locally to a strict equilibrium and the rate of convergence\nis exponentially fast - of the order of\n$\\mathcal{O}(\\exp(-a\\sum_{j=1}^{t}\\gamma_{j}))$ where $a>0$ is a constant and\n$\\gamma_{j}$ is the algorithm's step-size. In the presence of uncertainty,\nconvergence requires a more conservative step-size policy, but with high\nprobability, the algorithm remains locally convergent and achieves an\nexponential convergence rate. \n\n"}
{"id": "1608.00075", "contents": "Title: Online Nonnegative Matrix Factorization with General Divergences Abstract: We develop a unified and systematic framework for performing online\nnonnegative matrix factorization under a wide variety of important divergences.\nThe online nature of our algorithm makes it particularly amenable to\nlarge-scale data. We prove that the sequence of learned dictionaries converges\nalmost surely to the set of critical points of the expected loss function. We\ndo so by leveraging the theory of stochastic approximations and projected\ndynamical systems. This result substantially generalizes the previous results\nobtained only for the squared-$\\ell_2$ loss. Moreover, the novel techniques\ninvolved in our analysis open new avenues for analyzing similar matrix\nfactorization problems. The computational efficiency and the quality of the\nlearned dictionary of our algorithm are verified empirically on both synthetic\nand real datasets. In particular, on the tasks of topic learning, shadow\nremoval and image denoising, our algorithm achieves superior trade-offs between\nthe quality of learned dictionary and running time over the batch and other\nonline NMF algorithms. \n\n"}
{"id": "1608.00598", "contents": "Title: Computing the Feasible Spaces of Optimal Power Flow Problems Abstract: The solution to an optimal power flow (OPF) problem provides a minimum cost\noperating point for an electric power system. The performance of OPF solution\ntechniques strongly depends on the problem's feasible space. This paper\npresents an algorithm for provably computing the entire feasible spaces of\nsmall OPF problems to within a specified discretization tolerance.\nSpecifically, the feasible space is computed by discretizing certain of the OPF\nproblem's inequality constraints to obtain a set of power flow equations. All\nsolutions to the power flow equations at each discretization point are obtained\nusing the Numerical Polynomial Homotopy Continuation (NPHC) algorithm. To\nimprove computational tractability, \"bound tightening\" and \"grid pruning\"\nalgorithms use convex relaxations to eliminate the consideration of\ndiscretization points for which the power flow equations are provably\ninfeasible. The proposed algorithm is used to generate the feasible spaces of\ntwo small test cases. \n\n"}
{"id": "1608.01646", "contents": "Title: Reward Maximization in General Dynamic Matching Systems Abstract: We consider a matching system with random arrivals of items of different\ntypes. The items wait in queues -- one per each item type -- until they are\n\"matched.\" Each matching requires certain quantities of items of different\ntypes; after a matching is activated, the associated items leave the system.\nThere exists a finite set of possible matchings, each producing a certain\namount of \"reward\". This model has a broad range of important applications,\nincluding assemble-to-order systems, Internet advertising, matching web\nportals, etc.\n  We propose an optimal matching scheme in the sense that it asymptotically\nmaximizes the long-term average matching reward, while keeping the queues\nstable. The scheme makes matching decisions in a specially constructed virtual\nsystem, which in turn control decisions in the physical system. The key feature\nof the virtual system is that, unlike the physical one, it allows the queues to\nbecome negative. The matchings in the virtual system are controlled by an\nextended version of the greedy primal-dual (GPD) algorithm, which we prove to\nbe asymptotically optimal -- this in turn implies the asymptotic optimality of\nthe entire scheme. The scheme is real-time, at any time it uses simple rules\nbased on the current state of virtual and physical queues. It is very robust in\nthat it does not require any knowledge of the item arrival rates, and\nautomatically adapts to changing rates.\n  The extended GPD algorithm and its asymptotic optimality apply to a quite\ngeneral queueing network framework, not limited to matching problems, and\ntherefore is of independent interest. \n\n"}
{"id": "1608.01713", "contents": "Title: Global Convergence Rate of Proximal Incremental Aggregated Gradient\n  Methods Abstract: We focus on the problem of minimizing the sum of smooth component functions\n(where the sum is strongly convex) and a non-smooth convex function, which\narises in regularized empirical risk minimization in machine learning and\ndistributed constrained optimization in wireless sensor networks and smart\ngrids. We consider solving this problem using the proximal incremental\naggregated gradient (PIAG) method, which at each iteration moves along an\naggregated gradient (formed by incrementally updating gradients of component\nfunctions according to a deterministic order) and taking a proximal step with\nrespect to the non-smooth function. While the convergence properties of this\nmethod with randomized orders (in updating gradients of component functions)\nhave been investigated, this paper, to the best of our knowledge, is the first\nstudy that establishes the convergence rate properties of the PIAG method for\nany deterministic order. In particular, we show that the PIAG algorithm is\nglobally convergent with a linear rate provided that the step size is\nsufficiently small. We explicitly identify the rate of convergence and the\ncorresponding step size to achieve this convergence rate. Our results improve\nupon the best known condition number dependence of the convergence rate of the\nincremental aggregated gradient methods used for minimizing a sum of smooth\nfunctions. \n\n"}
{"id": "1608.02377", "contents": "Title: Regional controllability analysis of fractional diffusion equations with\n  Riemann-Liouville time fractional derivatives Abstract: This paper is concerned with the concepts of regional controllability for the\nRiemann-Liouville time fractional diffusion systems of order $\\alpha\\in(0,1)$.\nThe characterizations of strategic actuators to achieve regional\ncontrollability are investigated when the control inputs emerge in the\ndifferential equations as distributed inputs. In the end, an approach to\nguarantee the regional controllability of the problems under consideration in\nthe considered subregion with minimum energy control is described and\nsuccessfully tested through two applications. \n\n"}
{"id": "1608.04311", "contents": "Title: Optimal Control of Connected Automated Vehicles at Urban Traffic\n  Intersections: A Feasibility Enforcement Analysis Abstract: Earlier work has established a decentralized optimal control framework for\ncoordinating online a continuous flow of connected automated vehicles (CAVs)\nentering a control zone and crossing two adjacent intersections in an urban\narea. A solution, when it exists, allows the vehicles to cross the\nintersections without the use of traffic lights, without creating congestion on\nthe connecting road, and under the hard safety constraint of collision\navoidance. We establish the conditions under which such solutions exist and\nshow that they can be enforced through an appropriately designed feasibility\nenforcement zone that precedes the control zone. The proposed solution and\noverall control architecture are illustrated through simulation. \n\n"}
{"id": "1608.04773", "contents": "Title: Faster Principal Component Regression and Stable Matrix Chebyshev\n  Approximation Abstract: We solve principal component regression (PCR), up to a multiplicative\naccuracy $1+\\gamma$, by reducing the problem to $\\tilde{O}(\\gamma^{-1})$\nblack-box calls of ridge regression. Therefore, our algorithm does not require\nany explicit construction of the top principal components, and is suitable for\nlarge-scale PCR instances. In contrast, previous result requires\n$\\tilde{O}(\\gamma^{-2})$ such black-box calls.\n  We obtain this result by developing a general stable recurrence formula for\nmatrix Chebyshev polynomials, and a degree-optimal polynomial approximation to\nthe matrix sign function. Our techniques may be of independent interests,\nespecially when designing iterative methods. \n\n"}
{"id": "1608.05031", "contents": "Title: Learning Topology of Distribution Grids using only Terminal Node\n  Measurements Abstract: Distribution grids include medium and low voltage lines that are involved in\nthe delivery of electricity from substation to end-users/loads. A distribution\ngrid is operated in a radial/tree-like structure, determined by switching on or\noff lines from an underling loopy graph. Due to the presence of limited\nreal-time measurements, the critical problem of fast estimation of the radial\ngrid structure is not straightforward. This paper presents a new learning\nalgorithm that uses measurements only at the terminal or leaf nodes in the\ndistribution grid to estimate its radial structure. The algorithm is based on\nresults involving voltages of node triplets that arise due to the radial\nstructure. The polynomial computational complexity of the algorithm is\npresented along with a detailed analysis of its working. The most significant\ncontribution of the approach is that it is able to learn the structure in\ncertain cases where available measurements are confined to only half of the\nnodes. This represents learning under minimum permissible observability.\nPerformance of the proposed approach in learning structure is demonstrated by\nexperiments on test radial distribution grids. \n\n"}
{"id": "1609.00127", "contents": "Title: On a class of conserved phase field systems with a maximal monotone\n  perturbation Abstract: We prove existence and regularity for the solutions to a Cahn-Hilliard system\ndescribing the phenomenon of phase separation for a material contained in a\nbounded and regular domain. Since the first equation of the system is perturbed\nby the presence of an additional maximal monotone operator, we show our results\nusing suitable regularization of the nonlinearities of the problem and\nperforming some a priori estimates which allow us to pass to the limit thanks\nto compactness and monotonicity arguments. Next, under further assumptions, we\ndeduce a continuous dependence estimate whence the uniqueness property is also\nachieved. Then, we consider the relating sliding mode control (SMC) problem and\nshow that the chosen SMC law forces a suitable linear combination of the\ntemperature and the phase to reach a given (space dependent) value within\nfinite time. \n\n"}
{"id": "1609.00978", "contents": "Title: Local Maxima in the Likelihood of Gaussian Mixture Models: Structural\n  Results and Algorithmic Consequences Abstract: We provide two fundamental results on the population (infinite-sample)\nlikelihood function of Gaussian mixture models with $M \\geq 3$ components. Our\nfirst main result shows that the population likelihood function has bad local\nmaxima even in the special case of equally-weighted mixtures of well-separated\nand spherical Gaussians. We prove that the log-likelihood value of these bad\nlocal maxima can be arbitrarily worse than that of any global optimum, thereby\nresolving an open question of Srebro (2007). Our second main result shows that\nthe EM algorithm (or a first-order variant of it) with random initialization\nwill converge to bad critical points with probability at least\n$1-e^{-\\Omega(M)}$. We further establish that a first-order variant of EM will\nnot converge to strict saddle points almost surely, indicating that the poor\nperformance of the first-order method can be attributed to the existence of bad\nlocal maxima rather than bad saddle points. Overall, our results highlight the\nnecessity of careful initialization when using the EM algorithm in practice,\neven when applied in highly favorable settings. \n\n"}
{"id": "1609.01100", "contents": "Title: A max-cut approach to heterogeneity in cryo-electron microscopy Abstract: The field of cryo-electron microscopy has made astounding advancements in the\npast few years, mainly due to advancements in electron detectors' technology.\nYet, one of the key open challenges of the field remains the processing of\nheterogeneous data sets, produced from samples containing particles at several\ndifferent conformational states. For such data sets, the algorithms must\ninclude some classification procedure to identify homogeneous groups within the\ndata, so that the images in each group correspond to the same underlying\nstructure. The fundamental importance of the heterogeneity problem in\ncryo-electron microscopy has drawn many research efforts, and resulted in\nsignificant progress in classification algorithms for heterogeneous data sets.\nWhile these algorithms are extremely useful and effective in practice, they\nlack rigorous mathematical analysis and performance guarantees.\n  In this paper, we attempt to make the first steps towards rigorous\nmathematical analysis of the heterogeneity problem in cryo-electron microscopy.\nTo that end, we present an algorithm for processing heterogeneous data sets,\nand prove accuracy and stability bounds for it. We also suggest an extension of\nthis algorithm that combines the classification and reconstruction steps. We\ndemonstrate it on simulated data, and compare its performance to the\nstate-of-the-art algorithm in RELION. \n\n"}
{"id": "1609.02233", "contents": "Title: Optimization methods for frame conditioning and application to graph\n  Laplacian scaling Abstract: A frame is scalable if each of its vectors can be rescaled in such a way that\nthe resulting set becomes a Parseval frame. In this paper, we consider four\ndifferent optimization problems for determining if a frame is scalable. We\noffer some algorithms to solve these problems. We then apply and extend our\nmethods to the problem of reweighing (finite) graph so as to minimize the\ncondition number of the resulting Laplacian. \n\n"}
{"id": "1609.02247", "contents": "Title: Demixing Sines and Spikes: Robust Spectral Super-resolution in the\n  Presence of Outliers Abstract: We consider the problem of super-resolving the line spectrum of a\nmultisinusoidal signal from a finite number of samples, some of which may be\ncompletely corrupted. Measurements of this form can be modeled as an additive\nmixture of a sinusoidal and a sparse component. We propose to demix the two\ncomponents and super-resolve the spectrum of the multisinusoidal signal by\nsolving a convex program. Our main theoretical result is that-- up to\nlogarithmic factors-- this approach is guaranteed to be successful with high\nprobability for a number of spectral lines that is linear in the number of\nmeasurements, even if a constant fraction of the data are outliers. The result\nholds under the assumption that the phases of the sinusoidal and sparse\ncomponents are random and the line spectrum satisfies a minimum-separation\ncondition. We show that the method can be implemented via semidefinite\nprogramming and explain how to adapt it in the presence of dense perturbations,\nas well as exploring its connection to atomic-norm denoising. In addition, we\npropose a fast greedy demixing method which provides good empirical results\nwhen coupled with a local nonconvex-optimization step. \n\n"}
{"id": "1609.02654", "contents": "Title: Optimal Disease Outbreak Detection in a Community Using Network\n  Observability Abstract: Given a network, we would like to determine which subset of nodes should be\nmeasured by limited sensing facilities to maximize information about the entire\nnetwork. The optimal choice corresponds to the configuration that returns the\nhighest value of a measure of observability of the system. Here, the\ndeterminant of the inverse of the observability Gramian is used to evaluate the\ndegree of observability. Additionally, the effects of changes in the topology\nof the corresponding graph of a network on the observability of the network are\ninvestigated. The theory is illustrated on the problem of detection of an\nepidemic disease in a community. The purpose here is to find the smallest\nnumber of people who must be examined to predict the number of infected people\nin an arbitrary community. Results are demonstrated in simulation. \n\n"}
{"id": "1609.02845", "contents": "Title: Distributed Online Optimization in Dynamic Environments Using Mirror\n  Descent Abstract: This work addresses decentralized online optimization in non-stationary\nenvironments. A network of agents aim to track the minimizer of a global\ntime-varying convex function. The minimizer evolves according to a known\ndynamics corrupted by an unknown, unstructured noise. At each time, the global\nfunction can be cast as a sum of a finite number of local functions, each of\nwhich is assigned to one agent in the network. Moreover, the local functions\nbecome available to agents sequentially, and agents do not have a prior\nknowledge of the future cost functions. Therefore, agents must communicate with\neach other to build an online approximation of the global function. We propose\na decentralized variation of the celebrated Mirror Descent, developed by\nNemirovksi and Yudin. Using the notion of Bregman divergence in lieu of\nEuclidean distance for projection, Mirror Descent has been shown to be a\npowerful tool in large-scale optimization. Our algorithm builds on Mirror\nDescent, while ensuring that agents perform a consensus step to follow the\nglobal function and take into account the dynamics of the global minimizer. To\nmeasure the performance of the proposed online algorithm, we compare it to its\noffline counterpart, where the global functions are available a priori. The gap\nbetween the two is called dynamic regret. We establish a regret bound that\nscales inversely in the spectral gap of the network, and more notably it\nrepresents the deviation of minimizer sequence with respect to the given\ndynamics. We then show that our results subsume a number of results in\ndistributed optimization. We demonstrate the application of our method to\ndecentralized tracking of dynamic parameters and verify the results via\nnumerical experiments. \n\n"}
{"id": "1609.03065", "contents": "Title: Probabilistic Cross-Identification in Crowded Fields as an Assignment\n  Problem Abstract: One of the outstanding challenges of cross-identification is multiplicity:\ndetections in crowded regions of the sky are often linked to more than one\ncandidate associations of similar likelihoods. We map the resulting maximum\nlikelihood partitioning to the fundamental assignment problem of discrete\nmathematics and efficiently solve the two-way catalog-level matching in the\nrealm of combinatorial optimization using the so-called Hungarian algorithm. We\nintroduce the method, demonstrate its performance in a mock universe where the\ntrue associations are known, and discuss the applicability of the new procedure\nto large surveys. \n\n"}
{"id": "1609.03194", "contents": "Title: Network Utility Maximization Revisited: Three Issues and Their\n  Resolution Abstract: Distributed and iterative network utility maximization algorithms, such as\nthe primal-dual algorithms or the network-user decomposition algorithms, often\ninvolve trajectories where the iterates may be infeasible, convergence to the\noptimal points of relaxed problems different from the original, or convergence\nto local maxima. In this paper, we highlight the three issues with iterative\nalgorithms. We then propose a distributed and iterative algorithm that does not\nsuffer from the three issues. In particular, we assert the feasibility of the\nalgorithm's iterates at all times, convergence to the global maximum of the\ngiven problem (rather than to global maximum of a relaxed problem), and\navoidance of any associated spurious rest points of the dynamics. A benchmark\nalgorithm due to Kelly, Maulloo and Tan (1998) [Rate control for communication\nnetworks: shadow prices, proportional fairness and stability, Journal of the\nOperational Research Society, 49(3), 237-252] involves fast user updates\ncoupled with slow network updates in the form of additive-increase\nmultiplicative-decrease of suggested user flows. The proposed algorithm may be\nviewed as one with fast user updates and fast network updates that keeps the\niterates feasible at all times. Simulations suggest that the convergence rate\nof the ordinary differential equation (ODE) tracked by our proposed algorithm's\niterates is comparable to that of the ODE for the aforementioned benchmark\nalgorithm. \n\n"}
{"id": "1609.04836", "contents": "Title: On Large-Batch Training for Deep Learning: Generalization Gap and Sharp\n  Minima Abstract: The stochastic gradient descent (SGD) method and its variants are algorithms\nof choice for many Deep Learning tasks. These methods operate in a small-batch\nregime wherein a fraction of the training data, say $32$-$512$ data points, is\nsampled to compute an approximation to the gradient. It has been observed in\npractice that when using a larger batch there is a degradation in the quality\nof the model, as measured by its ability to generalize. We investigate the\ncause for this generalization drop in the large-batch regime and present\nnumerical evidence that supports the view that large-batch methods tend to\nconverge to sharp minimizers of the training and testing functions - and as is\nwell known, sharp minima lead to poorer generalization. In contrast,\nsmall-batch methods consistently converge to flat minimizers, and our\nexperiments support a commonly held view that this is due to the inherent noise\nin the gradient estimation. We discuss several strategies to attempt to help\nlarge-batch methods eliminate this generalization gap. \n\n"}
{"id": "1609.05167", "contents": "Title: Improving the semidefinite programming bound for the kissing number by\n  exploiting polynomial symmetry Abstract: The kissing number of $\\mathbb{R}^n$ is the maximum number of\npairwise-nonoverlapping unit spheres that can simultaneously touch a central\nunit sphere. Mittelmann and Vallentin (2010), based on the semidefinite\nprogramming bound of Bachoc and Vallentin (2008), computed the best known upper\nbounds for the kissing number for several values of $n \\leq 23$. In this paper,\nwe exploit the symmetry present in the semidefinite programming bound to\nprovide improved upper bounds for $n = 9, \\ldots, 23$. \n\n"}
{"id": "1609.07221", "contents": "Title: Convergence analysis of the direct extension of ADMM for multiple-block\n  separable convex minimization Abstract: Recently, the alternating direction method of multipliers (ADMM) has found\nmany efficient applications in various areas; and it has been shown that the\nconvergence is not guaranteed when it is directly extended to the\nmultiple-block case of separable convex minimization problems where there are\n$m\\ge 3$ functions without coupled variables in the objective. This fact has\ngiven great impetus to investigate various conditions on both the model and the\nalgorithm's parameter that can ensure the convergence of the direct extension\nof ADMM (abbreviated as \"e-ADMM\"). Despite some results under very strong\nconditions (e.g., at least $(m-1)$ functions should be strongly convex) that\nare applicable to the generic case with a general $m$, some others concentrate\non the special case of $m=3$ under the relatively milder condition that only\none function is assumed to be strongly convex. We focus on extending the\nconvergence analysis from the case of $m=3$ to the more general case of\n$m\\ge3$. That is, we show the convergence of e-ADMM for the case of $m\\ge 3$\nwith the assumption of only $(m-2)$ functions being strongly convex; and\nestablish its convergence rates in different scenarios such as the worst-case\nconvergence rates measured by iteration complexity and the asymptotically\nlinear convergence rate under stronger assumptions. Thus the convergence of\ne-ADMM for the general case of $m\\ge 4$ is proved; this result seems to be\nstill unknown even though it is intuitive given the known result of the case of\n$m=3$. Even for the special case of $m=3$, our convergence results turn out to\nbe more general than the exiting results that are derived specifically for the\ncase of $m=3$. \n\n"}
{"id": "1609.07237", "contents": "Title: Decentralized Nonlinear Feedback Design with Separable Control\n  Contraction Metrics Abstract: The problem under consideration is the synthesis of a distributed controller\nfor a nonlinear network composed of input affine systems. The objective is to\nachieve exponential convergence of the solutions. To design such a feedback\nlaw, methods based on contraction theory are employed to render the\ncontroller-synthesis problem scalable and suitable to use distributed\noptimization. The nature of the proposed approach is constructive, because the\ncomputation of the desired feedback law is obtained by solving a convex\noptimization problem. An example illustrates the proposed methodology. \n\n"}
{"id": "1609.07261", "contents": "Title: Existence of tangent lines to Carnot-Carath\\'eodory geodesics Abstract: We show that length minimizing curves in Carnot-Carath\\'eodory spaces possess\nat any point at least one tangent curve (i.e., a blow-up in the nilpotent\napproximation) equal to a straight horizontal line. This is the first\nregularity result for length minimizers that holds with no assumption on either\nthe space (e.g., its rank, step, or analyticity) or the curve, and it is novel\neven in the setting of Carnot groups. \n\n"}
{"id": "1609.07537", "contents": "Title: A Tutorial on Distributed (Non-Bayesian) Learning: Problem, Algorithms\n  and Results Abstract: We overview some results on distributed learning with focus on a family of\nrecently proposed algorithms known as non-Bayesian social learning. We consider\ndifferent approaches to the distributed learning problem and its algorithmic\nsolutions for the case of finitely many hypotheses. The original centralized\nproblem is discussed at first, and then followed by a generalization to the\ndistributed setting. The results on convergence and convergence rate are\npresented for both asymptotic and finite time regimes. Various extensions are\ndiscussed such as those dealing with directed time-varying networks, Nesterov's\nacceleration technique and a continuum sets of hypothesis. \n\n"}
{"id": "1609.07664", "contents": "Title: Max-Norm Optimization for Robust Matrix Recovery Abstract: This paper studies the matrix completion problem under arbitrary sampling\nschemes. We propose a new estimator incorporating both max-norm and\nnuclear-norm regularization, based on which we can conduct efficient low-rank\nmatrix recovery using a random subset of entries observed with additive noise\nunder general non-uniform and unknown sampling distributions. This method\nsignificantly relaxes the uniform sampling assumption imposed for the widely\nused nuclear-norm penalized approach, and makes low-rank matrix recovery\nfeasible in more practical settings. Theoretically, we prove that the proposed\nestimator achieves fast rates of convergence under different settings.\nComputationally, we propose an alternating direction method of multipliers\nalgorithm to efficiently compute the estimator, which bridges a gap between\ntheory and practice of machine learning methods with max-norm regularization.\nFurther, we provide thorough numerical studies to evaluate the proposed method\nusing both simulated and real datasets. \n\n"}
{"id": "1609.08121", "contents": "Title: Improving the Randomization Step in Feasibility Pump Abstract: Feasibility pump (FP) is a successful primal heuristic for mixed-integer\nlinear programs (MILP). The algorithm consists of three main components:\nrounding fractional solution to a mixed-integer one, projection of infeasible\nsolutions to the LP relaxation, and a randomization step used when the\nalgorithm stalls. While many generalizations and improvements to the original\nFeasibility Pump have been proposed, they mainly focus on the rounding and\nprojection steps.\n  We start a more in-depth study of the randomization step in Feasibility Pump.\nFor that, we propose a new randomization step based on the WalkSAT algorithm\nfor solving SAT instances. First, we provide theoretical analyses that show the\npotential of this randomization step; to the best of our knowledge, this is the\nfirst time any theoretical analysis of running-time of Feasibility Pump or its\nvariants has been conducted. Moreover, we also conduct computational\nexperiments incorporating the proposed modification into a state-of-the-art\nFeasibility Pump code that reinforce the practical value of the new\nrandomization step. \n\n"}
{"id": "1610.02617", "contents": "Title: Time-Average Optimization with Non-Convex Decision Set and Its\n  Convergence Abstract: This paper considers time-average optimization, where a decision vector is\nchosen every time step within a (possibly non-convex) set, and the goal is to\nminimize a convex function of the time averages subject to convex constraints\non these averages. Such problems have applications in networking, multi-agent\nsystems, and operations research, where decisions are constrained to a discrete\nset and the decision average can represent average bit rates or average agent\nactions. This time-average optimization extends traditional convex formulations\nto allow a non-convex decision set. This class of problems can be solved by\nLyapunov optimization. A simple drift-based algorithm, related to a classical\ndual subgradient algorithm, converges to an $\\epsilon$-optimal solution within\n$O(1/\\epsilon^2)$ time steps. Further, the algorithm is shown to have a\ntransient phase and a steady state phase which can be exploited to improve\nconvergence rates to $O(1/\\epsilon)$ and $O(1/{\\epsilon^{1.5}})$ when vectors\nof Lagrange multipliers satisfy locally-polyhedral and locally-smooth\nassumptions respectively. Practically, this improved convergence suggests that\ndecisions should be implemented after the transient period. \n\n"}
{"id": "1610.02851", "contents": "Title: A Greedy Blind Calibration Method for Compressed Sensing with Unknown\n  Sensor Gains Abstract: The realisation of sensing modalities based on the principles of compressed\nsensing is often hindered by discrepancies between the mathematical model of\nits sensing operator, which is necessary during signal recovery, and its actual\nphysical implementation, which can amply differ from the assumed model. In this\npaper we tackle the bilinear inverse problem of recovering a sparse input\nsignal and some unknown, unstructured multiplicative factors affecting the\nsensors that capture each compressive measurement. Our methodology relies on\ncollecting a few snapshots under new draws of the sensing operator, and\napplying a greedy algorithm based on projected gradient descent and the\nprinciples of iterative hard thresholding. We explore empirically the sample\ncomplexity requirements of this algorithm by testing its phase transition, and\nshow in a practically relevant instance of this problem for compressive imaging\nthat the exact solution can be obtained with only a few snapshots. \n\n"}
{"id": "1610.03002", "contents": "Title: Efficient Algorithm for Scalable Event-based Demand Response Management\n  in Microgrids Abstract: Demand response management has become one of the key enabling technologies\nfor smart grids. Motivated by the increasing demand response incentives offered\nby service operators, more customers are subscribing to various demand response\nprograms. However, with growing customer participation, the problem of\ndetermining the optimal loads to be curtailed in a microgrid during\ncontingencies within a feasible time frame becomes computationally hard. This\npaper proposes an efficient approximation algorithm for event-based demand\nresponse management in microgrids. In event-based management, it is important\nto curtail loads as fast as possible to maintain the stability of a microgrid\nduring the islanded mode in a scalable manner. A simple greedy approach is\npresented that can rapidly determine a close-to-optimal load curtailment scheme\nto maximize the aggregate customer utility in milliseconds for a large number\nof customers. This paper further derives a novel theoretical guarantee of the\ngap between the proposed efficient algorithm and the optimal solution (that may\nbe computationally hard to obtain). The performance of algorithm is\ncorroborated extensively by simulations with up to thousands of customers. For\nthe sake of practicality, the proposed event-based demand response management\nalgorithm is applied to a feeder from the Canadian benchmark distribution\nsystem. The simulation results demonstrate that the proposed approach\nefficiently optimizes microgrid operation during islanded mode while\nmaintaining appropriate voltage levels and network constrains. \n\n"}
{"id": "1610.03045", "contents": "Title: Sketching Meets Random Projection in the Dual: A Provable Recovery\n  Algorithm for Big and High-dimensional Data Abstract: Sketching techniques have become popular for scaling up machine learning\nalgorithms by reducing the sample size or dimensionality of massive data sets,\nwhile still maintaining the statistical power of big data. In this paper, we\nstudy sketching from an optimization point of view: we first show that the\niterative Hessian sketch is an optimization process with preconditioning, and\ndevelop accelerated iterative Hessian sketch via the searching the conjugate\ndirection; we then establish primal-dual connections between the Hessian sketch\nand dual random projection, and apply the preconditioned conjugate gradient\napproach on the dual problem, which leads to the accelerated iterative dual\nrandom projection methods. Finally to tackle the challenges from both large\nsample size and high-dimensionality, we propose the primal-dual sketch, which\niteratively sketches the primal and dual formulations. We show that using a\nlogarithmic number of calls to solvers of small scale problem, primal-dual\nsketch is able to recover the optimum of the original problem up to arbitrary\nprecision. The proposed algorithms are validated via extensive experiments on\nsynthetic and real data sets which complements our theoretical results. \n\n"}
{"id": "1610.03303", "contents": "Title: The Phase Transition in 5 Point Energy Minimization Abstract: Let R_s(r)=sign(s)/r^s be the Riesz s-energy potential. (This is the usual\npower-law potential.) This monograph proves the existence of a computable\nnumber S=15.048... such that the triangular bi-pyramid is the unique minimizer\nwith respect to R_s, amongst all 5-point configurations on the sphere, if and\nonly if s lies in (-2,0) or (0,S). This establishes the existence of the\nlong-conjectured phase transition constant in 5-point energy minimization. \n\n"}
{"id": "1610.04395", "contents": "Title: A Geometric PID Control Framework for Mechanical Systems Abstract: These lectures demonstrate the development of a PID control framework for\nmechanical systems. Based on the observation that mechanical systems are\nessentially double integrator systems, we generalize the linear PID controller\nto mechanical systems that have a non-Euclidean configuration space.\nSpecifically we start by presenting the development of the geometric PID\ncontroller for fully actuated mechanical systems and then extend it to a class\nof under actuated interconnected mechanical systems of practical significance\nby introducing the notion of feedback regularization. We show that feedback\nregularization is the mechanical system equivalent to partial feedback\nlinearization. We apply these results for trajectory tracking for several\nsystems of interest in the field of robotics. First, we demonstrate the robust\nalmost-global stability properties of the geometric PID controller developed\nfor fully actuated mechanical systems using simulations and experiments on a\nmulti-rotor-aerial-vehicle. The extension to the class of under actuated\ninterconnected systems allow one to ensure the semi-almost-global locally\nexponential tracking of the geometric center of a spherical robot on an\ninclined plane of unknown angle of inclination. The results are demonstrated\nusing simulations for a hoop rolling on an inclined plane and then for a sphere\nrolling on an inclined plane. The final extension that we present here is that\nof geometric PID control for holonomically or non-holonomically constrained\nmechanical systems on Lie groups. The results are demonstrated by ensuring the\nrobust almost global locally exponential tracking of a nontrivial spherical\npendulum. \n\n"}
{"id": "1610.05127", "contents": "Title: Compromise Solutions for Robust Combinatorial Optimization with\n  Variable-Sized Uncertainty Abstract: In classic robust optimization, it is assumed that a set of possible\nparameter realizations, the uncertainty set, is modeled in a previous step and\npart of the input. As recent work has shown, finding the most suitable\nuncertainty set is in itself already a difficult task. We consider robust\nproblems where the uncertainty set is not completely defined. Only the shape is\nknown, but not its size. Such a setting is known as variable-sized uncertainty.\n  In this work we present an approach how to find a single robust solution,\nthat performs well on average over all possible uncertainty set sizes. We\ndemonstrate that this approach can be solved efficiently for min-max robust\noptimization, but is more involved in the case of min-max regret, where\npositive and negative complexity results for the selection problem, the minimum\nspanning tree problem, and the shortest path problem are provided. We introduce\nan iterative solution procedure, and evaluate its performance in an\nexperimental comparison. \n\n"}
{"id": "1610.05350", "contents": "Title: How Well Do Local Algorithms Solve Semidefinite Programs? Abstract: Several probabilistic models from high-dimensional statistics and machine\nlearning reveal an intriguing --and yet poorly understood-- dichotomy. Either\nsimple local algorithms succeed in estimating the object of interest, or even\nsophisticated semi-definite programming (SDP) relaxations fail.\n  In order to explore this phenomenon, we study a classical SDP relaxation of\nthe minimum graph bisection problem, when applied to Erd\\H{o}s-Renyi random\ngraphs with bounded average degree $d>1$, and obtain several types of results.\nFirst, we use a dual witness construction (using the so-called non-backtracking\nmatrix of the graph) to upper bound the SDP value. Second, we prove that a\nsimple local algorithm approximately solves the SDP to within a factor\n$2d^2/(2d^2+d-1)$ of the upper bound. In particular, the local algorithm is at\nmost $8/9$ suboptimal, and $1+O(1/d)$ suboptimal for large degree.\n  We then analyze a more sophisticated local algorithm, which aggregates\ninformation according to the harmonic measure on the limiting Galton-Watson\n(GW) tree. The resulting lower bound is expressed in terms of the conductance\nof the GW tree and matches surprisingly well the empirically determined SDP\nvalues on large-scale Erd\\H{o}s-Renyi graphs.\n  We finally consider the planted partition model. In this case, purely local\nalgorithms are known to fail, but they do succeed if a small amount of side\ninformation is available. Our results imply quantitative bounds on the\nthreshold for partial recovery using SDP in this model. \n\n"}
{"id": "1610.05604", "contents": "Title: Dynamic Assortment Personalization in High Dimensions Abstract: We study the problem of dynamic assortment personalization with large,\nheterogeneous populations and wide arrays of products, and demonstrate the\nimportance of structural priors for effective, efficient large-scale\npersonalization. Assortment personalization is the problem of choosing, for\neach individual (type), a best assortment of products, ads, or other offerings\n(items) so as to maximize revenue. This problem is central to revenue\nmanagement in e-commerce and online advertising where both items and types can\nnumber in the millions.\n  We formulate the dynamic assortment personalization problem as a\ndiscrete-contextual bandit with $m$ contexts (types) and exponentially many\narms (assortments of the $n$ items). We assume that each type's preferences\nfollow a simple parametric model with $n$ parameters. In all, there are $mn$\nparameters, and existing literature suggests that order optimal regret scales\nas $mn$. However, the data required to estimate so many parameters is orders of\nmagnitude larger than the data available in most revenue management\napplications; and the optimal regret under these models is unacceptably high.\n  In this paper, we impose a natural structure on the problem -- a small latent\ndimension, or low rank. In the static setting, we show that this model can be\nefficiently learned from surprisingly few interactions, using a time- and\nmemory-efficient optimization algorithm that converges globally whenever the\nmodel is learnable. In the dynamic setting, we show that structure-aware\ndynamic assortment personalization can have regret that is an order of\nmagnitude smaller than structure-ignorant approaches. We validate our\ntheoretical results empirically. \n\n"}
{"id": "1610.06470", "contents": "Title: On lexicographic approximations of integer programs Abstract: We use the lexicographic order to define a hierarchy of primal and dual\nbounds on the optimum of a bounded integer program. These bounds are\nconstructed using lex maximal and minimal feasible points taken under different\npermutations. Their strength is analyzed and it is shown that a family of\nprimal bounds is tight for any $0\\backslash 1$ program with nonnegative linear\nobjective, and a different family of dual bounds is tight for any packing- or\ncovering-type $0\\backslash 1$ program with an arbitrary linear objective. The\nformer result yields a structural characterization for the optimum of\n$0\\backslash 1$ programs, with connections to matroid optimization, and a\nheuristic for general integer programs. The latter result implies a stronger\npolyhedral representation for the integer feasible points and a new approach\nfor deriving strong valid inequalities to the integer hull. Since the\nconstruction of our bounds depends on the computation of lex optima, we derive\nexplicit formulae for lex optima of some special polytopes, such as polytopes\nthat are monotone with respect to each variable, and integral polymatroids and\ntheir base polytopes. We also classify $\\mathrm{P}$ and\n$\\mathrm{NP}$-$\\mathrm{hard}$ cases of computing lex bounds and lex optima. \n\n"}
{"id": "1610.06538", "contents": "Title: A general double-proximal gradient algorithm for d.c. programming Abstract: The possibilities of exploiting the special structure of d.c. programs, which\nconsist of optimizing the difference of convex functions, are currently more or\nless limited to variants of the DCA proposed by Pham Dinh Tao and Le Thi Hoai\nAn in 1997. These assume that either the convex or the concave part, or both,\nare evaluated by one of their subgradients.\n  In this paper we propose an algorithm which allows the evaluation of both the\nconcave and the convex part by their proximal points. Additionally, we allow a\nsmooth part, which is evaluated via its gradient. In the spirit of primal-dual\nsplitting algorithms, the concave part might be the composition of a concave\nfunction with a linear operator, which are, however, evaluated separately.\n  For this algorithm we show that every cluster point is a solution of the\noptimization problem. Furthermore, we show the connection to the Toland dual\nproblem and prove a descent property for the objective function values of a\nprimal-dual formulation of the problem. Convergence of the iterates is shown if\nthis objective function satisfies the Kurdyka--\\L ojasiewicz property. In the\nlast part, we apply the algorithm to an image processing model. \n\n"}
{"id": "1610.07201", "contents": "Title: On the dynamic consistency of hierarchical risk-averse decision problems Abstract: In this paper, we consider a risk-averse decision problem for\ncontrolled-diffusion processes, with dynamic risk measures, in which there are\ntwo risk-averse decision makers (i.e., {\\it leader} and {\\it follower}) with\ndifferent risk-averse related responsibilities and information. Moreover, we\nassume that there are two objectives that these decision makers are expected to\nachieve. That is, the first objective being of {\\it stochastic controllability}\ntype that describes an acceptable risk-exposure set vis-\\'a-vis some uncertain\nfuture payoff, and while the {\\it second one} is making sure the solution of a\ncertain risk-related system equation has to stay always above a given\ncontinuous stochastic process, namely {\\it obstacle}. In particular, we\nintroduce multi-structure, time-consistent, dynamic risk measures induced from\nconditional $g$-expectations, where the latter are associated with the\ngenerator functionals of two backward-SDEs that implicitly take into account\nthe above two objectives along with the given continuous obstacle process.\nMoreover, under certain conditions, we establish the existence of optimal\nhierarchical risk-averse solutions, in the sense of viscosity solutions, to the\nassociated risk-averse dynamic programming equations that formalize the way in\nwhich both the {\\it leader} and {\\it follower} consistently choose their\nrespective risk-averse decisions. Finally, we remark on the implication of our\nresult in assessing the influence of the {\\it leader'}s decisions on the\nrisk-averseness of the {\\it follower} in relation to the direction of {\\it\nleader-follower} information flow. \n\n"}
{"id": "1611.01385", "contents": "Title: Model Uncertainty Stochastic Mean-Field Control Abstract: We consider the problem of optimal control of a mean-field stochastic\ndifferential equation under model uncertainty. The model uncertainty is\nrepresented by ambiguity about the law $\\mathcal{L}(X(t))$ of the state $X(t)$\nat time $t$. For example, it could be the law $\\mathcal{L}_{\\mathbb{P}}(X(t))$\nof $X(t)$ with respect to the given, underlying probability measure\n$\\mathbb{P}$. This is the classical case when there is no model uncertainty.\nBut it could also be the law $\\mathcal{L}_{\\mathbb{Q}}(X(t))$ with respect to\nsome other probability measure $\\mathbb{Q}$ or, more generally, any random\nmeasure $\\mu(t)$ on $\\mathbb{R}$ with total mass $1$.\n  We represent this model uncertainty control problem as a stochastic\ndifferential game of a mean-field related type stochastic differential equation\n(SDE) with two players. The control of one of the players, representing the\nuncertainty of the law of the state, is a measure valued stochastic process\n$\\mu(t)$ and the control of the other player is a classical real-valued\nstochastic process $u(t)$. This control with respect to random probability\nprocesses $\\mu(t)$ on $\\mathbb{R}$ is a new type of stochastic control problems\nthat has not been studied before. By introducing operator-valued backward\nstochastic differential equations, we obtain a sufficient maximum principle for\nNash equilibria for such games in the general nonzero-sum case, and saddle\npoints for zero-sum games.\n  As an application we find an explicit solution of the problem of optimal\nconsumption under model uncertainty of a cash flow described by a mean-field\nrelated type SDE. \n\n"}
{"id": "1611.01947", "contents": "Title: SPECTRA -- a Maple library for solving linear matrix inequalities in\n  exact arithmetic Abstract: This document describes our freely distributed Maple library {\\sc spectra},\nfor Semidefinite Programming solved Exactly with Computational Tools of Real\nAlgebra. It solves linear matrix inequalities with symbolic computation in\nexact arithmetic and it is targeted to small-size, possibly degenerate problems\nfor which symbolic infeasibility or feasibility certificates are required. \n\n"}
{"id": "1611.02014", "contents": "Title: Swimming by switching Abstract: In this paper we investigate different strategies to overcome the scallop\ntheorem. We will show how to obtain a net motion exploiting the fluid's type\nchange during a periodic deformation. We are interested in two different\nmodels: in the first one that change is linked to the magnitude of the opening\nand closing velocity. Instead, in the second one it is related to the sign of\nthe above velocity. An interesting feature of the latter model is the\nintroduction of a delay-switching rule through a thermostat. We remark that the\nlatter is fundamental in order to get both forward and backward motion. \n\n"}
{"id": "1611.02918", "contents": "Title: Minimum Spanning trees with Neighborhoods Abstract: This paper studies Minimum Spanning Trees under incomplete information for\nits vertices. We assume that no information is available on the precise\nplacement of vertices so that it is only known that vertices belong to some\nneighborhoods that are second order cone representable and distances are\nmeasured with a $\\ell_q$-norm. Two mixed integer non linear mathematical\nprogramming formulations are presented, based on alternative representations of\nsubtour elimination constraints. A solution scheme is also proposed, resulting\nfrom a reformulation suitable for a Benders-like decomposition, which is\nembedded within an exact branch-and-cut framework. Furthermore, a mathheuristic\nis developed, which alternates in solving convex subproblems in different\nsolution spaces, and is able to solve larger instances. The results of\nextensive computational experiments are reported and analyzed. \n\n"}
{"id": "1611.05827", "contents": "Title: Towards a Mathematical Understanding of the Difficulty in Learning with\n  Feedforward Neural Networks Abstract: Training deep neural networks for solving machine learning problems is one\ngreat challenge in the field, mainly due to its associated optimisation problem\nbeing highly non-convex. Recent developments have suggested that many training\nalgorithms do not suffer from undesired local minima under certain scenario,\nand consequently led to great efforts in pursuing mathematical explanations for\nsuch observations. This work provides an alternative mathematical understanding\nof the challenge from a smooth optimisation perspective. By assuming exact\nlearning of finite samples, sufficient conditions are identified via a critical\npoint analysis to ensure any local minimum to be globally minimal as well.\nFurthermore, a state of the art algorithm, known as the Generalised\nGauss-Newton (GGN) algorithm, is rigorously revisited as an approximate\nNewton's algorithm, which shares the property of being locally quadratically\nconvergent to a global minimum under the condition of exact learning. \n\n"}
{"id": "1611.07891", "contents": "Title: New constraint qualifications for mathematical programs with equilibrium\n  constraints via variational analysis Abstract: In this paper, we study the mathematical program with equilibrium constraints\n(MPEC) formulated as a mathematical program with a parametric generalized\nequation involving the regular normal cone. Compared with the usual way of\nformulating MPEC through a KKT condition, this formulation has the advantage\nthat it does not involve extra multipliers as new variables, and it usually\nrequires weaker assumptions on the problem data. Using the so-called first\norder sufficient condition for metric subregularity, we derive verifiable\nsufficient conditions for the metric subregularity of the involved set-valued\nmapping, or equivalently the calmness of the perturbed generalized equation\nmapping. \n\n"}
{"id": "1611.09030", "contents": "Title: A modelling and computational study of the frustration index in signed\n  networks Abstract: Computing the frustration index of a signed graph is a key step toward\nsolving problems in many fields including social networks, political science,\nphysics, chemistry, and biology. The frustration index determines the distance\nof a network from a state of total structural balance. Although the definition\nof the frustration index goes back to the 1950's, its exact algorithmic\ncomputation, which is closely related to classic NP-hard graph problems, has\nonly become a focus in recent years. We develop three new binary linear\nprogramming models to compute the frustration index exactly and efficiently as\nthe solution to a global optimisation problem. Solving the models with\nprioritised branching and valid inequalities in Gurobi, we can compute the\nfrustration index of real signed networks with over 15000 edges in less than a\nminute on inexpensive hardware. We provide extensive performance analysis for\nboth random and real signed networks and show that our models outperform all\nexisting approaches by large factors. Based on solve time, algorithm output,\nand effective branching factor we highlight the superiority of our models to\nboth exact and heuristic methods in the literature. \n\n"}
{"id": "1611.09179", "contents": "Title: Optimal stopping with f -expectations: the irregular case Abstract: We consider the optimal stopping problem with non-linear $f$-expectation\n(induced by a BSDE) without making any regularity assumptions on the reward\nprocess $\\xi$. and with general filtration. We show that the value family can\nbe aggregated by an optional process $Y$. We characterize the process $Y$ as\nthe $\\mathcal{E}^f$-Snell envelope of $\\xi$. We also establish an infinitesimal\ncharacterization of the value process $Y$ in terms of a Reflected BSDE with\n$\\xi$ as the obstacle. To do this, we first establish a comparison theorem for\nirregular RBSDEs. We give an application to the pricing of American options\nwith irregular pay-off in an imperfect market model. \n\n"}
{"id": "1611.09556", "contents": "Title: Bounds for smooth Fano weighted complete intersections Abstract: We prove that if a smooth variety with non-positive canonical class can be\nembedded into a weighted projective space of dimension $n$ as a well formed\ncomplete intersection and it is not an intersection with a linear cone therein,\nthen the weights of the weighted projective space do not exceed $n+1$. Based on\nthis bound we classify all smooth Fano complete intersections of dimensions $4$\nand $5$, and compute their invariants. \n\n"}
{"id": "1611.10041", "contents": "Title: Subsampled online matrix factorization with convergence guarantees Abstract: We present a matrix factorization algorithm that scales to input matrices\nthat are large in both dimensions (i.e., that contains morethan 1TB of data).\nThe algorithm streams the matrix columns while subsampling them, resulting in\nlow complexity per iteration andreasonable memory footprint. In contrast to\nprevious online matrix factorization methods, our approach relies on\nlow-dimensional statistics from past iterates to control the extra variance\nintroduced by subsampling. We present a convergence analysis that guarantees us\nto reach a stationary point of the problem. Large speed-ups can be obtained\ncompared to previous online algorithms that do not perform subsampling, thanks\nto the feature redundancy that often exists in high-dimensional settings. \n\n"}
{"id": "1612.00059", "contents": "Title: Synchronization over Cartan motion groups via contraction Abstract: Group contraction is an algebraic map that relates two classes of Lie groups\nby a limiting process. We utilize this notion for the compactification of the\nclass of Cartan motion groups. The compactification process is then applied to\nreduce a non-compact synchronization problem to a problem where the solution\ncan be obtained by means of a unitary, faithful representation. We describe\nthis method of synchronization via contraction in detail and analyze several\nimportant aspects of this application. One important special case of Cartan\nmotion groups is the group of rigid motions, also called the special Euclidean\ngroup. We thoroughly discuss the synchronization over this group and show\nnumerically the advantages of our approach compared to some current\nstate-of-the-art synchronization methods on both synthetic and real data. \n\n"}
{"id": "1612.01890", "contents": "Title: Abstract tropical linear programming Abstract: In this paper we develop a combinatorial abstraction of tropical linear\nprogramming. This generalizes the search for a feasible point of a system of\nmin-plus-inequalities. It is based on the polyhedral properties of\ntriangulations of the product of two simplices and the combinatorics of the\nassociated set of bipartite graphs with an additional sign information which we\ncall a signed tropical matroid. We demonstrate the connections with the\nclassical simplex method, mean payoff games and scheduling. \n\n"}
{"id": "1612.02519", "contents": "Title: Moment Relaxations of Optimal Power Flow Problems: Beyond the Convex\n  Hull Abstract: Optimal power flow (OPF) is one of the key electric power system optimization\nproblems. \"Moment\" relaxations from the Lasserre hierarchy for polynomial\noptimization globally solve many OPF problems. Previous work illustrates the\nability of higher-order moment relaxations to approach the convex hulls of OPF\nproblems' non-convex feasible spaces. Using a small test case, this paper\nfocuses on the ability of the moment relaxations to globally solve problems\nwith objective functions that have unconstrained minima at infeasible points\ninside the convex hull of the non-convex constraints. \n\n"}
{"id": "1612.04519", "contents": "Title: Data allocation on disks with solution reconfiguration (problems,\n  heuristics) Abstract: The paper addresses problem of data allocation in two-layer computer storage\nwhile taking into account dynamic digraph(s) over computing tasks. The basic\nversion of data file allocation on parallel hard magnetic disks is considered\nas special bin packing model. Two problems of the allocation solution\nreconfiguration (restructuring) are suggested: (i) one-stage restructuring\nmodel, (ii) multistage restructuring models. Solving schemes are based on\nsimplified heuristics. Numerical examples illustrate problems and solving\nschemes. \n\n"}
{"id": "1612.04777", "contents": "Title: SVD-based Kalman Filter Derivative Computation Abstract: Recursive adaptive filtering methods are often used for solving the problem\nof simultaneous state and parameters estimation arising in many areas of\nresearch. The gradient-based schemes for adaptive Kalman filtering (KF) require\nthe corresponding filter sensitivity computations. The standard approach is\nbased on the direct differentiation of the KF equations. The shortcoming of\nthis strategy is a numerical instability of the conventional KF (and its\nderivatives) with respect to roundoff errors. For decades, special attention\nhas been paid in the KF community for designing efficient filter\nimplementations that improve robustness of the estimator against roundoff. The\nmost popular and beneficial techniques are found in the class of square-root\n(SR) or UD factorization-based methods. They imply the Cholesky decomposition\nof the corresponding error covariance matrix. Another important matrix\nfactorization method is the singular value decomposition (SVD) and, hence,\nfurther encouraging KF algorithms might be found under this approach.\nMeanwhile, the filter sensitivity computation heavily relies on the use of\nmatrix differential calculus. Previous works on the robust KF derivative\ncomputation have produced the SR- and UD-based methodologies. Alternatively, in\nthis paper we design the SVD-based approach. The solution is expressed in terms\nof the SVD-based KF covariance quantities and their derivatives (with respect\nto unknown system parameters). The results of numerical experiments illustrate\nthat although the newly-developed SDV-based method is algebraically equivalent\nto the conventional approach and the previously derived SR- and UD-based\nstrategies, it outperforms the mentioned techniques for estimation accuracy in\nill-conditioned situations. \n\n"}
{"id": "1612.05708", "contents": "Title: Mutual information for fitting deep nonlinear models Abstract: Deep nonlinear models pose a challenge for fitting parameters due to lack of\nknowledge of the hidden layer and the potentially non-affine relation of the\ninitial and observed layers. In the present work we investigate the use of\ninformation theoretic measures such as mutual information and Kullback-Leibler\n(KL) divergence as objective functions for fitting such models without\nknowledge of the hidden layer. We investigate one model as a proof of concept\nand one application of cogntive performance. We further investigate the use of\noptimizers with these methods. Mutual information is largely successful as an\nobjective, depending on the parameters. KL divergence is found to be similarly\nsuccesful, given some knowledge of the statistics of the hidden layer. \n\n"}
{"id": "1612.06265", "contents": "Title: A proximal difference-of-convex algorithm with extrapolation Abstract: We consider a class of difference-of-convex (DC) optimization problems whose\nobjective is level-bounded and is the sum of a smooth convex function with\nLipschitz gradient, a proper closed convex function and a continuous concave\nfunction. While this kind of problems can be solved by the classical\ndifference-of-convex algorithm (DCA) [26], the difficulty of the subproblems of\nthis algorithm depends heavily on the choice of DC decomposition. Simpler\nsubproblems can be obtained by using a specific DC decomposition described in\n[27]. This decomposition has been proposed in numerous work such as [18], and\nwe refer to the resulting DCA as the proximal DCA. Although the subproblems are\nsimpler, the proximal DCA is the same as the proximal gradient algorithm when\nthe concave part of the objective is void, and hence is potentially slow in\npractice. In this paper, motivated by the extrapolation techniques for\naccelerating the proximal gradient algorithm in the convex settings, we\nconsider a proximal difference-of-convex algorithm with extrapolation to\npossibly accelerate the proximal DCA. We show that any cluster point of the\nsequence generated by our algorithm is a stationary point of the DC\noptimization problem for a fairly general choice of extrapolation parameters:\nin particular, the parameters can be chosen as in FISTA with fixed restart\n[15]. In addition, by assuming the Kurdyka-{\\L}ojasiewicz property of the\nobjective and the differentiability of the concave part, we establish global\nconvergence of the sequence generated by our algorithm and analyze its\nconvergence rate. Our numerical experiments on two difference-of-convex\nregularized least squares models show that our algorithm usually outperforms\nthe proximal DCA and the general iterative shrinkage and thresholding algorithm\nproposed in [17]. \n\n"}
{"id": "1612.06332", "contents": "Title: On Dantzig figures from graded lexicographic orders Abstract: We construct two families of Dantzig figures, which are $(d,2d)$-polytopes\nwith an antipodal vertex pair, from convex hulls of initial subsets for the\ngraded lexicographic (grlex) and graded reverse lexicographic (grevlex) orders\non $\\mathbb{Z}^{d}_{\\geq 0}$. These two polytopes have the same number of\nvertices, $\\mathcal{O}(d^{2})$, and the same number of edges,\n$\\mathcal{O}(d^{3})$, but are not combinatorially equivalent. We provide an\nexplicit description of the vertices and the facets for both families and\ndescribe their graphs along with analyzing their basic properties such as the\nradius, diameter, existence of Hamiltonian circuits, and chromatic number.\nMoreover, we also analyze the edge expansions of these graphs. \n\n"}
{"id": "1612.06997", "contents": "Title: Linear Superiorization for Infeasible Linear Programming Abstract: Linear superiorization (abbreviated: LinSup) considers linear programming\n(LP) problems wherein the constraints as well as the objective function are\nlinear. It allows to steer the iterates of a feasibility-seeking iterative\nprocess toward feasible points that have lower (not necessarily minimal) values\nof the objective function than points that would have been reached by the same\nfeasiblity-seeking iterative process without superiorization. Using a\nfeasibility-seeking iterative process that converges even if the linear\nfeasible set is empty, LinSup generates an iterative sequence that converges to\na point that minimizes a proximity function which measures the linear\nconstraints violation. In addition, due to LinSup's repeated objective function\nreduction steps such a point will most probably have a reduced objective\nfunction value. We present an exploratory experimental result that illustrates\nthe behavior of LinSup on an infeasible LP problem. \n\n"}
{"id": "1612.07435", "contents": "Title: Partial $\\ell_1$ optimization in random linear systems -- phase\n  transitions and large deviations Abstract: $\\ell_1$ optimization is a well known heuristic often employed for solving\nvarious forms of sparse linear problems. In this paper we look at its a variant\nthat we refer to as the \\emph{partial} $\\ell_1$ and discuss its mathematical\nproperties when used for solving linear under-determined systems of equations.\nWe will focus on large random systems and discuss the phase transition (PT)\nphenomena and how they connect to the large deviation principles (LDP). Using a\nvariety of probabilistic and geometric techniques that we have developed in\nrecent years we will first present general guidelines that conceptually fully\ncharacterize both, the PTs and the LDPs. After that we will put an emphasis on\nproviding a collection of explicit analytical solutions to all of the\nunderlying mathematical problems. As a nice bonus to the developed concepts,\nthe forms of the analytical solutions will, in our view, turn out to be fairly\nelegant as well. \n\n"}
{"id": "1612.08412", "contents": "Title: Multi-Objective Simultaneous Optimistic Optimization Abstract: Optimistic methods have been applied with success to single-objective\noptimization. Here, we attempt to bridge the gap between optimistic methods and\nmulti-objective optimization. In particular, this paper is concerned with\nsolving black-box multi-objective problems given a finite number of function\nevaluations and proposes an optimistic approach, which we refer to as the\nMulti-Objective Simultaneous Optimistic Optimization (MO-SOO). Popularized by\nmulti-armed bandits, MO-SOO follows the optimism in the face of uncertainty\nprinciple to recognize Pareto optimal solutions, by combining several\nmulti-armed bandits in a hierarchical structure over the feasible decision\nspace of a multi-objective problem. Based on three assumptions about the\nobjective functions smoothness and hierarchical partitioning, the algorithm\nfinite-time and asymptotic convergence behaviors are analyzed. The finite-time\nanalysis establishes an upper bound on the Pareto-compliant unary additive\nepsilon indicator characterized by the objectives smoothness as well as the\nstructure of the Pareto front with respect to its extrema. On the other hand,\nthe asymptotic analysis indicates the consistency property of MO-SOO. Moreover,\nwe validate the theoretical provable performance of the algorithm on a set of\nsynthetic problems. Finally, three-hundred bi-objective benchmark problems from\nthe literature are used to substantiate the performance of the optimistic\napproach and compare it with three state-of-the-art stochastic algorithms,\nnamely MOEA/D, MO-CMA-ES, and SMS-EMOA in terms of two Pareto-compliant quality\nindicators. Besides sound theoretical properties, MO-SOO shows a performance on\na par with the top performing stochastic algorithm, viz. SMS-EMOA. \n\n"}
{"id": "1701.01801", "contents": "Title: Stochastic Control of Memory Mean-Field Processes Abstract: By a memory mean-field process we mean the solution $X(\\cdot)$ of a\nstochastic mean-field equation involving not just the current state $X(t)$ and\nits law $\\mathcal{L}(X(t))$ at time $t$, but also the state values $X(s)$ and\nits law $\\mathcal{L}(X(s))$ at some previous times $s<t$. Our purpose is to\nstudy stochastic control problems of memory mean-field processes.\n  - We consider the space $\\mathcal{M}$ of measures on $\\mathbb{R}$ with the\nnorm $|| \\cdot||_{\\mathcal{M}}$ introduced by Agram and {\\O}ksendal in\n\\cite{AO1}, and prove the existence and uniqueness of solutions of memory\nmean-field stochastic functional differential equations.\n  - We prove two stochastic maximum principles, one sufficient (a verification\ntheorem) and one necessary, both under partial information. The corresponding\nequations for the adjoint variables are a pair of \\emph{(time-) advanced\nbackward stochastic differential equations}, one of them with values in the\nspace of bounded linear functionals on path segment spaces.\n  - As an application of our methods, we solve a memory mean-variance problem\nas well as a linear-quadratic problem of a memory process. \n\n"}
{"id": "1701.03614", "contents": "Title: On resilient control of dynamical flow networks Abstract: Resilience has become a key aspect in the design of contemporary\ninfrastructure networks. This comes as a result of ever-increasing loads,\nlimited physical capacity, and fast-growing levels of interconnectedness and\ncomplexity due to the recent technological advancements. The problem has\nmotivated a considerable amount of research within the last few years,\nparticularly focused on the dynamical aspects of network flows, complementing\nmore classical static network flow optimization approaches. In this tutorial\npaper, a class of single-commodity first-order models of dynamical flow\nnetworks is considered. A few results recently appeared in the literature and\ndealing with stability and robustness of dynamical flow networks are gathered\nand originally presented in a unified framework. In particular, (differential)\nstability properties of monotone dynamical flow networks are treated in some\ndetail, and the notion of margin of resilience is introduced as a quantitative\nmeasure of their robustness. While emphasizing methodological aspects --\nincluding structural properties, such as monotonicity, that enable tractability\nand scalability -- over the specific applications, connections to\nwell-established road traffic flow models are made. \n\n"}
{"id": "1701.03955", "contents": "Title: Fundamental Properties of Process Distances Abstract: Information is an inherent component of stochastic processes and to measure\nthe distance between different stochastic processes it is not sufficient to\nconsider the distance between their laws. Instead, the information which\naccumulates over time and which is mathematically encoded by filtrations has to\nbe accounted for as well. The nested distance/bicausal Wasserstein distance\naddresses this challenge by incorporating the filtration. It is of emerging\nimportance due to its applications in stochastic analysis, stochastic\nprogramming, mathematical economics and other disciplines.\n  This article establishes a number of fundamental properties of the nested\ndistance. In particular we prove that the nested distance of processes\ngenerates a Polish topology but is itself not a complete metric. We identify\nits completion to be the set of nested distributions, which are a form of\ngeneralized stochastic processes. We also characterize the extreme points of\nthe set of couplings which participate in the definition of the nested\ndistance, proving that they can be identified with adapted deterministic maps.\nFinally, we compare the nested distance to an alternative metric, which could\npossibly be easier to compute in practical situations. \n\n"}
{"id": "1701.03961", "contents": "Title: Communication-Efficient Algorithms for Decentralized and Stochastic\n  Optimization Abstract: We present a new class of decentralized first-order methods for nonsmooth and\nstochastic optimization problems defined over multiagent networks. Considering\nthat communication is a major bottleneck in decentralized optimization, our\nmain goal in this paper is to develop algorithmic frameworks which can\nsignificantly reduce the number of inter-node communications. We first propose\na decentralized primal-dual method which can find an $\\epsilon$-solution both\nin terms of functional optimality gap and feasibility residual in\n$O(1/\\epsilon)$ inter-node communication rounds when the objective functions\nare convex and the local primal subproblems are solved exactly. Our major\ncontribution is to present a new class of decentralized primal-dual type\nalgorithms, namely the decentralized communication sliding (DCS) methods, which\ncan skip the inter-node communications while agents solve the primal\nsubproblems iteratively through linearizations of their local objective\nfunctions. By employing DCS, agents can still find an $\\epsilon$-solution in\n$O(1/\\epsilon)$ (resp., $O(1/\\sqrt{\\epsilon})$) communication rounds for\ngeneral convex functions (resp., strongly convex functions), while maintaining\nthe $O(1/\\epsilon^2)$ (resp., $O(1/\\epsilon)$) bound on the total number of\nintra-node subgradient evaluations. We also present a stochastic counterpart\nfor these algorithms, denoted by SDCS, for solving stochastic optimization\nproblems whose objective function cannot be evaluated exactly. In comparison\nwith existing results for decentralized nonsmooth and stochastic optimization,\nwe can reduce the total number of inter-node communication rounds by orders of\nmagnitude while still maintaining the optimal complexity bounds on intra-node\nstochastic subgradient evaluations. The bounds on the subgradient evaluations\nare actually comparable to those required for centralized nonsmooth and\nstochastic optimization. \n\n"}
{"id": "1701.05246", "contents": "Title: Second order dynamical systems with penalty terms associated to monotone\n  inclusions Abstract: In this paper we investigate in a Hilbert space setting a second order\ndynamical system of the form $$\\ddot{x}(t)+\\g(t)\\dot{x}(t)+x(t)-J_{\\lambda(t)\nA}\\big(x(t)-\\lambda(t) D(x(t))-\\lambda(t)\\beta(t)B(x(t))\\big)=0,$$ where\n$A:{\\mathcal H}\\toto{\\mathcal H}$ is a maximal monotone operator,\n$J_{\\lambda(t) A}:{\\mathcal H}\\To{\\mathcal H}$ is the resolvent operator of\n$\\lambda(t)A$ and $D,B: {\\mathcal H}\\rightarrow{\\mathcal H}$ are cocoercive\noperators, and $\\lambda,\\beta :[0,+\\infty)\\rightarrow (0,+\\infty)$, and\n$\\gamma:[0,+\\infty)\\rightarrow (0,+\\infty)$ are step size, penalization and,\nrespectively, damping functions, all depending on time. We show the existence\nand uniqueness of strong global solutions in the framework of the\nCauchy-Lipschitz-Picard Theorem and prove ergodic asymptotic convergence for\nthe generated trajectories to a zero of the operator $A+D+{N}_C,$ where $C=\\zer\nB$ and $N_C$ denotes the normal cone operator of $C$. To this end we use\nLyapunov analysis combined with the celebrated Opial Lemma in its ergodic\ncontinuous version. Furthermore, we show strong convergence for trajectories to\nthe unique zero of $A+D+{N}_C$, provided that $A$ is a strongly monotone\noperator. \n\n"}
{"id": "1701.06692", "contents": "Title: A geometric approach to cut-generating functions Abstract: The cutting-plane approach to integer programming was initiated more that 40\nyears ago: Gomory introduced the corner polyhedron as a relaxation of a mixed\ninteger set in tableau form and Balas introduced intersection cuts for the\ncorner polyhedron. This line of research was left dormant for several decades\nuntil relatively recently, when a paper of Andersen, Louveaux, Weismantel and\nWolsey generated renewed interest in the corner polyhedron and intersection\ncuts. Recent developments rely on tools drawn from convex analysis, geometry\nand number theory, and constitute an elegant bridge between these areas and\ninteger programming. We survey these results and highlight recent breakthroughs\nin this area. \n\n"}
{"id": "1701.07248", "contents": "Title: Distributed methods for synchronization of orthogonal matrices over\n  graphs Abstract: This paper addresses the problem of synchronizing orthogonal matrices over\ndirected graphs. For synchronized transformations (or matrices), composite\ntransformations over loops equal the identity. We formulate the synchronization\nproblem as a least-squares optimization problem with nonlinear constraints. The\nsynchronization problem appears as one of the key components in applications\nranging from 3D-localization to image registration. The main contributions of\nthis work can be summarized as the introduction of two novel algorithms; one\nfor symmetric graphs and one for graphs that are possibly asymmetric. Under\ngeneral conditions, the former has guaranteed convergence to the solution of a\nspectral relaxation to the synchronization problem. The latter is stable for\nsmall step sizes when the graph is quasi-strongly connected. The proposed\nmethods are verified in numerical simulations. \n\n"}
{"id": "1701.07569", "contents": "Title: Data-Driven Sparse Sensor Placement for Reconstruction Abstract: Optimal sensor placement is a central challenge in the design, prediction,\nestimation, and control of high-dimensional systems. High-dimensional states\ncan often leverage a latent low-dimensional representation, and this inherent\ncompressibility enables sparse sensing. This article explores optimized sensor\nplacement for signal reconstruction based on a tailored library of features\nextracted from training data. Sparse point sensors are discovered using the\nsingular value decomposition and QR pivoting, which are two ubiquitous matrix\ncomputations that underpin modern linear dimensionality reduction. Sparse\nsensing in a tailored basis is contrasted with compressed sensing, a universal\nsignal recovery method in which an unknown signal is reconstructed via a sparse\nrepresentation in a universal basis. Although compressed sensing can recover a\nwider class of signals, we demonstrate the benefits of exploiting known\npatterns in data with optimized sensing. In particular, drastic reductions in\nthe required number of sensors and improved reconstruction are observed in\nexamples ranging from facial images to fluid vorticity fields. Principled\nsensor placement may be critically enabling when sensors are costly and\nprovides faster state estimation for low-latency, high-bandwidth control.\nMATLAB code is provided for all examples. \n\n"}
{"id": "1701.08246", "contents": "Title: About intrinsic transversality of pairs of sets Abstract: The article continues the study of the 'regular' arrangement of a collection\nof sets near a point in their intersection. Such regular intersection or, in\nother words, transversality properties are crucial for the validity of\nqualification conditions in optimisation as well as subdifferential, normal\ncone and coderivative calculus, and convergence analysis of computational\nalgorithms. One of the main motivations for the development of the\ntransversality theory of collections of sets comes from the convergence\nanalysis of alternating projections for solving feasibility problems. This\narticle targets infinite dimensional extensions of the intrinsic transversality\nproperty introduced recently by Drusvyatskiy, Ioffe and Lewis as a sufficient\ncondition for local linear convergence of alternating projections. Several\ncharacterisations of this property are established involving new limiting\nobjects defined for pairs of sets. Special attention is given to the convex\ncase. \n\n"}
{"id": "1701.08498", "contents": "Title: Efficient DC Algorithm for Constrained Sparse Optimization Abstract: We address the minimization of a smooth objective function under an\n$\\ell_0$-constraint and simple convex constraints. When the problem has no\nconstraints except the $\\ell_0$-constraint, some efficient algorithms are\navailable; for example, Proximal DC (Difference of Convex functions) Algorithm\n(PDCA) repeatedly evaluates closed-form solutions of convex subproblems,\nleading to a stationary point of the $\\ell_0$-constrained problem. However,\nwhen the problem has additional convex constraints, they become inefficient\nbecause it is difficult to obtain closed-form solutions of the associated\nsubproblems. In this paper, we reformulate the problem by employing a new DC\nrepresentation of the $\\ell_0$-constraint, so that PDCA can retain the\nefficiency by reducing its subproblems to the projection operation onto a\nconvex set. Moreover, inspired by the Nesterov's acceleration technique for\nproximal methods, we propose the Accelerated PDCA (APDCA), which attains the\noptimal convergence rate if applied to convex programs, and performs well in\nnumerical experiments. \n\n"}
{"id": "1701.08585", "contents": "Title: Variational Policy for Guiding Point Processes Abstract: Temporal point processes have been widely applied to model event sequence\ndata generated by online users. In this paper, we consider the problem of how\nto design the optimal control policy for point processes, such that the\nstochastic system driven by the point process is steered to a target state. In\nparticular, we exploit the key insight to view the stochastic optimal control\nproblem from the perspective of optimal measure and variational inference. We\nfurther propose a convex optimization framework and an efficient algorithm to\nupdate the policy adaptively to the current system state. Experiments on\nsynthetic and real-world data show that our algorithm can steer the user\nactivities much more accurately and efficiently than other stochastic control\nmethods. \n\n"}
{"id": "1702.01474", "contents": "Title: Generalized Coordinated Transaction Scheduling: A Market Approach to\n  Seamless Interfaces Abstract: A generalization of the coordinated transaction scheduling (CTS)---the\nstate-of-the-art interchange scheduling---is proposed. Referred to as\ngeneralized coordinated transaction scheduling (GCTS), the proposed approach\naddresses major seams issues of CTS: the ad hoc use of proxy buses, the\npresence of loop flow as a result of proxy bus approximation, and difficulties\nin dealing with multiple interfaces. By allowing market participants to submit\nbids across market boundaries, GCTS also generalizes the joint economic\ndispatch that achieves seamless interchange without market participants. It is\nshown that GCTS asymptotically achieves seamless interface under certain\nconditions. GCTS is also shown to be revenue adequate in that each regional\nmarket has a non-negative net revenue that is equal to its congestion rent.\nNumerical examples are presented to illustrate the quantitative improvement of\nthe proposed approach. \n\n"}
{"id": "1702.03849", "contents": "Title: Non-convex learning via Stochastic Gradient Langevin Dynamics: a\n  nonasymptotic analysis Abstract: Stochastic Gradient Langevin Dynamics (SGLD) is a popular variant of\nStochastic Gradient Descent, where properly scaled isotropic Gaussian noise is\nadded to an unbiased estimate of the gradient at each iteration. This modest\nchange allows SGLD to escape local minima and suffices to guarantee asymptotic\nconvergence to global minimizers for sufficiently regular non-convex objectives\n(Gelfand and Mitter, 1991). The present work provides a nonasymptotic analysis\nin the context of non-convex learning problems, giving finite-time guarantees\nfor SGLD to find approximate minimizers of both empirical and population risks.\nAs in the asymptotic setting, our analysis relates the discrete-time SGLD\nMarkov chain to a continuous-time diffusion process. A new tool that drives the\nresults is the use of weighted transportation cost inequalities to quantify the\nrate of convergence of SGLD to a stationary distribution in the Euclidean\n$2$-Wasserstein distance. \n\n"}
{"id": "1702.04144", "contents": "Title: A constant step Forward-Backward algorithm involving random maximal\n  monotone operators Abstract: A stochastic Forward-Backward algorithm with a constant step is studied. At\neach time step, this algorithm involves an independent copy of a couple of\nrandom maximal monotone operators. Defining a mean operator as a selection\nintegral, the differential inclusion built from the sum of the two mean\noperators is considered. As a first result, it is shown that the interpolated\nprocess obtained from the iterates converges narrowly in the small step regime\nto the solution of this differential inclusion. In order to control the long\nterm behavior of the iterates, a stability result is needed in addition. To\nthis end, the sequence of the iterates is seen as a homogeneous Feller Markov\nchain whose transition kernel is parameterized by the algorithm step size. The\ncluster points of the Markov chains invariant measures in the small step regime\nare invariant for the semiflow induced by the differential inclusion.\nConclusions regarding the long run behavior of the iterates for small steps are\ndrawn. It is shown that when the sum of the mean operators is demipositive, the\nprobabilities that the iterates are away from the set of zeros of this sum are\nsmall in Ces\\`aro mean. The ergodic behavior of these iterates is studied as\nwell. Applications of the proposed algorithm are considered. In particular, a\ndetailed analysis of the random proximal gradient algorithm with constant step\nis performed. \n\n"}
{"id": "1702.05577", "contents": "Title: A Statistical Comparison of Objective Functions for the Vehicle Routing\n  Problem with Route Balancing Abstract: The Vehicle Routing Problem with Route Balancing (VRPRB) is a biobjective\nversion of the original Vehicle Routing Problem (VRP) in which, besides\nminimizing the total distance traveled by the vehicles involved, the balance\namong route loads is also pursued. Different objective functions (OFs) to\nachieve balanced route configurations have been proposed in the literature,\nhowever to the best of the authors knowledge there is still no consensus on\nwhich OF is the most suitable one for addressing, through metaheuristics, this\nchallenging multiobjective optimization problem. This paper inquires into the\neffectiveness of seven different OFs for the VRPRB. Their influence on the\nperformance of a basic single solution based evolutionary algorithm is analyzed\nby comparing the quality of the Pareto approximations produced for a set of\nwell known benchmark instances. The obtained results indicate that studying\nalternative evaluation schemes for the VRPRB represents a highly valuable\ndirection for future research which merits more attention. \n\n"}
{"id": "1702.06917", "contents": "Title: Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe Abstract: We consider the problem of bandit optimization, inspired by stochastic\noptimization and online learning problems with bandit feedback. In this\nproblem, the objective is to minimize a global loss function of all the\nactions, not necessarily a cumulative loss. This framework allows us to study a\nvery general class of problems, with applications in statistics, machine\nlearning, and other fields. To solve this problem, we analyze the\nUpper-Confidence Frank-Wolfe algorithm, inspired by techniques for bandits and\nconvex optimization. We give theoretical guarantees for the performance of this\nalgorithm over various classes of functions, and discuss the optimality of\nthese results. \n\n"}
{"id": "1702.07842", "contents": "Title: Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding\n  Projection onto Simplex Abstract: In this paper we study the well-known greedy coordinate descent (GCD)\nalgorithm to solve $\\ell_1$-regularized problems and improve GCD by the two\npopular strategies: Nesterov's acceleration and stochastic optimization.\nFirstly, we propose a new rule for greedy selection based on an $\\ell_1$-norm\nsquare approximation which is nontrivial to solve but convex, then an efficient\nalgorithm called \"SOft ThreshOlding PrOjection (SOTOPO)\" is proposed to exactly\nsolve the $\\ell_1$-regularized $\\ell_1$-norm square approximation problem,\nwhich is induced by the new rule. Based on the new rule and the SOTOPO\nalgorithm, the Nesterov's acceleration and stochastic optimization strategies\nare then successfully applied to the GCD algorithm. The resulted algorithm\ncalled accelerated stochastic greedy coordinate descent (ASGCD) has the optimal\nconvergence rate $O(\\sqrt{1/\\epsilon})$, meanwhile, it reduces the iteration\ncomplexity of greedy selection up to a factor of sample size. Both\ntheoretically and empirically, we show that ASGCD has better performance for\nhigh-dimensional and dense problems with sparse solution. \n\n"}
{"id": "1703.00319", "contents": "Title: Robust and structural ergodicity analysis of stochastic biomolecular\n  networks involving synthetic antithetic integral controllers Abstract: Ergodicity and output controllability have been shown to be fundamental\nconcepts for the analysis and synthetic design of closed-loop stochastic\nreaction networks, as exemplified by the use of antithetic integral feedback\ncontrollers. In [Gupta, Briat & Khammash, PLoS Comput. Biol., 2014], some\nergodicity and output controllability conditions for unimolecular and certain\nclasses of bimolecular reaction networks were obtained and formulated through\nlinear programs. To account for context dependence, these conditions were later\nextended in [Briat & Khammash, CDC, 2016] to reaction networks with uncertain\nrate parameters using simple and tractable, yet potentially conservative,\nmethods. Here we develop some exact theoretical methods for verifying, in a\nrobust setting, the original ergodicity and output controllability conditions\nbased on algebraic and polynomial techniques. Some examples are given for\nillustration. \n\n"}
{"id": "1703.00439", "contents": "Title: Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for\n  Regularized Empirical Risk Minimization Abstract: In this paper, we develop a new accelerated stochastic gradient method for\nefficiently solving the convex regularized empirical risk minimization problem\nin mini-batch settings. The use of mini-batches is becoming a golden standard\nin the machine learning community, because mini-batch settings stabilize the\ngradient estimate and can easily make good use of parallel computing. The core\nof our proposed method is the incorporation of our new \"double acceleration\"\ntechnique and variance reduction technique. We theoretically analyze our\nproposed method and show that our method much improves the mini-batch\nefficiencies of previous accelerated stochastic methods, and essentially only\nneeds size $\\sqrt{n}$ mini-batches for achieving the optimal iteration\ncomplexities for both non-strongly and strongly convex objectives, where $n$ is\nthe training set size. Further, we show that even in non-mini-batch settings,\nour method achieves the best known convergence rate for both non-strongly and\nstrongly convex objectives. \n\n"}
{"id": "1703.01368", "contents": "Title: Ebola Model and Optimal Control with Vaccination Constraints Abstract: The Ebola virus disease is a severe viral haemorrhagic fever syndrome caused\nby Ebola virus. This disease is transmitted by direct contact with the body\nfluids of an infected person and objects contaminated with virus or infected\nanimals, with a death rate close to 90% in humans. Recently, some mathematical\nmodels have been presented to analyse the spread of the 2014 Ebola outbreak in\nWest Africa. In this paper, we introduce vaccination of the susceptible\npopulation with the aim of controlling the spread of the disease and analyse\ntwo optimal control problems related with the transmission of Ebola disease\nwith vaccination. Firstly, we consider the case where the total number of\navailable vaccines in a fixed period of time is limited. Secondly, we analyse\nthe situation where there is a limited supply of vaccines at each instant of\ntime for a fixed interval of time. The optimal control problems have been\nsolved analytically. Finally, we have performed a number of numerical\nsimulations in order to compare the models with vaccination and the model\nwithout vaccination, which has recently been shown to fit the real data. Three\nvaccination scenarios have been considered for our numerical simulations,\nnamely: unlimited supply of vaccines; limited total number of vaccines; and\nlimited supply of vaccines at each instant of time. \n\n"}
{"id": "1703.01754", "contents": "Title: Optimal Contract with Moral Hazard for Public Private Partnerships Abstract: Public-Private Partnership (PPP) is a contract between a public entity and a\nconsortium, in which the public outsources the construction and the maintenance\nof an equipment (hospital, university, prison...). One drawback of this\ncontract is that the public may not be able to observe the effort of the\nconsortium but only its impact on the social welfare of the project. We aim to\ncharacterize the optimal contract for a PPP in this setting of asymmetric\ninformation between the two parties. This leads to a stochastic control under\npartial information and it is also related to principal-agent problems with\nmoral hazard. Considering a wider set of information for the public and using\nmartingale arguments in the spirit of Sannikov, the optimization problem can be\nreduced to a standard stochastic control problem, that is solved numerically.\nWe then prove that for the optimal contract, the effort of the consortium is\nexplicitly characterized. In particular, it is shown that the optimal rent is\nnot a linear function of the effort, contrary to some models of the economic\nliterature on PPP contracts. \n\n"}
{"id": "1703.04703", "contents": "Title: Variational obstacle avoidance problem on Riemannian manifolds Abstract: We introduce variational obstacle avoidance problems on Riemannian manifolds\nand derive necessary conditions for the existence of their normal extremals.\nThe problem consists of minimizing an energy functional depending on the\nvelocity and covariant acceleration, among a set of admissible curves, and also\ndepending on a navigation function used to avoid an obstacle on the workspace,\na Riemannian manifold.\n  We study two different scenarios, a general one on a Riemannian manifold and,\na sub-Riemannian problem. By introducing a left-invariant metric on a Lie\ngroup, we also study the variational obstacle avoidance problem on a Lie group.\nWe apply the results to the obstacle avoidance problem of a planar rigid body\nand an unicycle. \n\n"}
{"id": "1703.05696", "contents": "Title: Attitude and Gyro Bias Estimation Using GPS and IMU Measurements Abstract: We propose an attitude and gyro-bias estimation scheme for accelerated rigid\nbody systems using an inertial measurement unit (IMU) and a global positioning\nsystem (GPS). The proposed scheme allows to obtain attitude estimates directly\non the Special Orthogonal group $SO(3)$ while estimating the gyro bias and the\nunknown apparent acceleration of the vehicle. We prove semi-global exponential\nstability of the estimation errors. Furthermore, a new switching technique for\nthe attitude state is introduced which results in a velocity-aided hybrid\nattitude observer with proven global exponential stability. \n\n"}
{"id": "1703.07265", "contents": "Title: On the controllability of the Navier-Stokes equation in spite of\n  boundary layers Abstract: In this proceeding we expose a particular case of a recent result obtained by\nthe authors regarding the incompressible Navier-Stokes equations in a smooth\nbounded and simply connected bounded domain, either in 2D or in 3D, with a\nNavier slip-with-friction boundary condition except on a part of the boundary.\nThis under-determination encodes that one has control over the remaining part\nof the boundary. We prove that for any initial data, for any positive time,\nthere exists a weak Leray solution which vanishes at this given time. \n\n"}
{"id": "1703.07306", "contents": "Title: Controllability to Equilibria of the 1-D Fokker-Planck Equation with\n  Zero-Flux Boundary Condition Abstract: We consider the problem of controlling the spatiotemporal probability\ndistribution of a robotic swarm that evolves according to a reflected diffusion\nprocess, using the space- and time-dependent drift vector field parameter as\nthe control variable. In contrast to previous work on control of the\nFokker-Planck equation, a zero-flux boundary condition is imposed on the\npartial differential equation that governs the swarm probability distribution,\nand only bounded vector fields are considered to be admissible as control\nparameters. Under these constraints, we show that any initial probability\ndistribution can be transported to a target probability distribution under\ncertain assumptions on the regularity of the target distribution. In\nparticular, we show that if the target distribution is (essentially) bounded,\nhas bounded first-order and second-order partial derivatives, and is bounded\nfrom below by a strictly positive constant, then this distribution can be\nreached exactly using a drift vector field that is bounded in space and time.\nOur proof is constructive and based on classical linear semigroup theoretic\nconcepts. \n\n"}
{"id": "1703.07409", "contents": "Title: Inference, Prediction, and Control of Networked Epidemics Abstract: We develop a feedback control method for networked epidemic spreading\nprocesses. In contrast to most prior works which consider mean field, open-loop\ncontrol schemes, the present work develops a novel framework for feedback\ncontrol of epidemic processes which leverages incomplete observations of the\nstochastic epidemic process in order to control the exact dynamics of the\nepidemic outbreak. We develop an observation model for the epidemic process,\nand demonstrate that if the set of observed nodes is sufficiently well\nstructured, then the random variables which denote the process' infections are\nconditionally independent given the observations. We then leverage the attained\nconditional independence property to construct tractable mechanisms for the\ninference and prediction of the process state, avoiding the need to use mean\nfield approximations or combinatorial representations. We conclude by\nformulating a one-step lookahead controller for the discrete-time\nSusceptible-Infected-Susceptible (SIS) epidemic process which leverages the\ndeveloped Bayesian inference and prediction mechanisms, and causes the epidemic\nto die out at a chosen rate. \n\n"}
{"id": "1703.07693", "contents": "Title: Computation of Ground States of the Gross-Pitaevskii Functional via\n  Riemannian Optimization Abstract: In this paper we combine concepts from Riemannian Optimization and the theory\nof Sobolev gradients to derive a new conjugate gradient method for direct\nminimization of the Gross-Pitaevskii energy functional with rotation. The\nconservation of the number of particles constrains the minimizers to lie on a\nmanifold corresponding to the unit $L^2$ norm. The idea developed here is to\ntransform the original constrained optimization problem to an unconstrained\nproblem on this (spherical) Riemannian manifold, so that fast minimization\nalgorithms can be applied as alternatives to more standard constrained\nformulations. First, we obtain Sobolev gradients using an equivalent definition\nof an $H^1$ inner product which takes into account rotation. Then, the\nRiemannian gradient (RG) steepest descent method is derived based on projected\ngradients and retraction of an intermediate solution back to the constraint\nmanifold. Finally, we use the concept of the Riemannian vector transport to\npropose a Riemannian conjugate gradient (RCG) method for this problem. It is\nderived at the continuous level based on the \"optimize-then-discretize\"\nparadigm instead of the usual \"discretize-then-optimize\" approach, as this\nensures robustness of the method when adaptive mesh refinement is performed in\ncomputations. We evaluate various design choices inherent in the formulation of\nthe method and conclude with recommendations concerning selection of the best\noptions. Numerical tests demonstrate that the proposed RCG method outperforms\nthe simple gradient descent (RG) method in terms of rate of convergence. While\non simple problems a Newton-type method implemented in the {\\tt Ipopt} library\nexhibits a faster convergence than the (RCG) approach, the two methods perform\nsimilarly on more complex problems requiring the use of mesh adaptation. At the\nsame time the (RCG) approach has far fewer tunable parameters. \n\n"}
{"id": "1703.07802", "contents": "Title: Optimizing Curbside Parking Resources Subject to Congestion Constraints Abstract: To gain theoretical insight into the relationship between parking scarcity\nand congestion, we describe block-faces of curbside parking as a network of\nqueues. Due to the nature of this network, canonical queueing network results\nare not available to us. We present a new kind of queueing network subject to\ncustomer rejection due to the lack of available servers. We provide conditions\nfor such networks to be stable, a computationally tractable \"single node\" view\nof such a network, and show that maximizing the occupancy through price control\nof such queues, and subject to constraints on the allowable congestion between\nqueues searching for an available server, is a convex optimization problem. We\ndemonstrate an application of this method in the Mission District of San\nFrancisco; our results suggest congestion due to drivers searching for parking\nstems from an inefficient spatial utilization of parking resources. \n\n"}
{"id": "1703.07824", "contents": "Title: Optimal Regulation Response of Batteries Under Cycle Aging Mechanisms Abstract: When providing frequency regulation in a pay-for-performance market,\nbatteries need to carefully balance the trade-off between following regulation\nsignals and their degradation costs in real-time. Existing battery control\nstrategies either do not consider mismatch penalties in pay-for-performance\nmarkets, or cannot accurately account for battery cycle aging mechanism during\noperation. This paper derives an online control policy that minimizes a battery\nowner's operating cost for providing frequency regulation in a\npay-for-performance market. The proposed policy considers an accurate\nelectrochemical battery cycle aging model, and is applicable to most types of\nbattery cells. It has a threshold structure, and achieves near-optimal\nperformance with respect to an offline controller that has complete future\ninformation. We explicitly characterize this gap and show it is independent of\nthe duration of operation. Simulation results with both synthetic and real\nregulation traces are conducted to illustrate the theoretical results. \n\n"}
{"id": "1703.09377", "contents": "Title: Distributed Average Tracking of Heterogeneous Physical Second-order\n  Agents With No Input Signals Constraint Abstract: This paper addresses distributed average tracking of physical second-order\nagents with heterogeneous nonlinear dynamics, where there is no constraint on\ninput signals. The nonlinear terms in agents' dynamics are heterogeneous,\nsatisfying a Lipschitz-like condition that will be defined later and is more\ngeneral than the Lipschitz condition. In the proposed algorithm, a control\ninput and a filter are designed for each agent. Each agent's filter has two\noutputs and the idea is that the first output estimates the average of the\ninput signals and the second output estimates the average of the input\nvelocities asymptotically. In parallel, each agent's position and velocity are\ndriven to track, respectively, the first and the second outputs. Having\nheterogeneous nonlinear terms in agents' dynamics necessitates designing the\nfilters for agents. Since the nonlinear terms in agents' dynamics can be\nunbounded and the input signals are arbitrary, novel state-dependent\ntime-varying gains are employed in agents' filters and control inputs to\novercome these unboundedness effects. Finally the results are improved to\nachieve the distributed average tracking for a group of double-integrator\nagents, where there is no constraint on input signals and the filter is not\nrequired anymore. Numerical simulations are also presented to illustrate the\ntheoretical results. \n\n"}
{"id": "1704.00427", "contents": "Title: Galerkin approximations of nonlinear optimal control problems in Hilbert\n  spaces Abstract: Nonlinear optimal control problems in Hilbert spaces are considered for which\nwe derive approximation theorems for Galerkin approximations. Approximation\ntheorems are available in the literature. The originality of our approach\nrelies on the identification of a set of natural assumptions that allows us to\ndeal with a broad class of nonlinear evolution equations and cost functionals\nfor which we derive convergence of the value functions associated with the\noptimal control problem of the Galerkin approximations. This convergence result\nholds for a broad class of nonlinear control strategies as well. In particular,\nwe show that the framework applies to the optimal control of semilinear heat\nequations posed on a general compact manifold without boundary. The framework\nis then shown to apply to geoengineering and mitigation of greenhouse gas\nemissions formulated for the first time in terms of optimal control of energy\nbalance climate models posed on the sphere $\\mathbb{S}^2$. \n\n"}
{"id": "1704.00805", "contents": "Title: On the Properties of the Softmax Function with Application in Game\n  Theory and Reinforcement Learning Abstract: In this paper, we utilize results from convex analysis and monotone operator\ntheory to derive additional properties of the softmax function that have not\nyet been covered in the existing literature. In particular, we show that the\nsoftmax function is the monotone gradient map of the log-sum-exp function. By\nexploiting this connection, we show that the inverse temperature parameter\ndetermines the Lipschitz and co-coercivity properties of the softmax function.\nWe then demonstrate the usefulness of these properties through an application\nin game-theoretic reinforcement learning. \n\n"}
{"id": "1704.00989", "contents": "Title: Learning Filter Functions in Regularisers by Minimising Quotients Abstract: Learning approaches have recently become very popular in the field of inverse\nproblems. A large variety of methods has been established in recent years,\nranging from bi-level learning to high-dimensional machine learning techniques.\nMost learning approaches, however, only aim at fitting parametrised models to\nfavourable training data whilst ignoring misfit training data completely. In\nthis paper, we follow up on the idea of learning parametrised regularisation\nfunctions by quotient minimisation as established in [3]. We extend the model\ntherein to include higher-dimensional filter functions to be learned and allow\nfor fit- and misfit-training data consisting of multiple functions. We first\npresent results resembling behaviour of well-established derivative-based\nsparse regularisers like total variation or higher-order total variation in\none-dimension. Our second and main contribution is the introduction of novel\nfamilies of non-derivative-based regularisers. This is accomplished by learning\nfavourable scales and geometric properties while at the same time avoiding\nunfavourable ones. \n\n"}
{"id": "1704.01785", "contents": "Title: Geometry of Policy Improvement Abstract: We investigate the geometry of optimal memoryless time independent decision\nmaking in relation to the amount of information that the acting agent has about\nthe state of the system. We show that the expected long term reward, discounted\nor per time step, is maximized by policies that randomize among at most $k$\nactions whenever at most $k$ world states are consistent with the agent's\nobservation. Moreover, we show that the expected reward per time step can be\nstudied in terms of the expected discounted reward. Our main tool is a\ngeometric version of the policy improvement lemma, which identifies a\npolyhedral cone of policy changes in which the state value function increases\nfor all states. \n\n"}
{"id": "1704.02138", "contents": "Title: On Approximate Diagnosability of Nonlinear Systems Abstract: This paper deals with diagnosability of discrete-time nonlinear systems with\nunknown inputs and quantized outputs. We propose a novel notion of\ndiagnosability that we term approximate diagnosability, corresponding to the\npossibility of detecting within a finite delay and within a given accuracy if a\nset of faulty states is reached or not. Addressing diagnosability in an\napproximate sense is primarily motivated by the fact that system outputs in\nconcrete applications are measured by sensors that introduce measurement\nerrors. Consequently, it is not possible to detect exactly if the state of the\nsystem has reached or not the set of faulty states. In order to check\napproximate diagnosability on the class of nonlinear systems we use tools from\nformal methods. We first derive a symbolic model approximating the original\nsystem within any desired accuracy. This step allows us to check approximate\ndiagnosability of the symbolic model. We then establish the relation between\napproximate diagnosability of the symbolic model and of the original nonlinear\nsystem. \n\n"}
{"id": "1704.02718", "contents": "Title: Distributed Learning for Cooperative Inference Abstract: We study the problem of cooperative inference where a group of agents\ninteract over a network and seek to estimate a joint parameter that best\nexplains a set of observations. Agents do not know the network topology or the\nobservations of other agents. We explore a variational interpretation of the\nBayesian posterior density, and its relation to the stochastic mirror descent\nalgorithm, to propose a new distributed learning algorithm. We show that, under\nappropriate assumptions, the beliefs generated by the proposed algorithm\nconcentrate around the true parameter exponentially fast. We provide explicit\nnon-asymptotic bounds for the convergence rate. Moreover, we develop explicit\nand computationally efficient algorithms for observation models belonging to\nexponential families. \n\n"}
{"id": "1704.02836", "contents": "Title: The quadratic M-convexity testing problem Abstract: M-convex functions, which are a generalization of valuated matroids, play a\ncentral role in discrete convex analysis. Quadratic M-convex functions\nconstitute a basic and important subclass of M-convex functions, which has a\nclose relationship with phylogenetics as well as valued constraint satisfaction\nproblems. In this paper, we consider the quadratic M-convexity testing problem\n(QMCTP), which is the problem of deciding whether a given quadratic function on\n$\\{0,1\\}^n$ is M-convex. We show that QMCTP is co-NP-complete in general, but\nis polynomial-time solvable under a natural assumption. Furthermore, we propose\nan $O(n^2)$-time algorithm for solving QMCTP in the polynomial-time solvable\ncase. \n\n"}
{"id": "1704.03443", "contents": "Title: Solving the L1 regularized least square problem via a box-constrained\n  smooth minimization Abstract: In this paper, an equivalent smooth minimization for the L1 regularized least\nsquare problem is proposed. The proposed problem is a convex box-constrained\nsmooth minimization which allows applying fast optimization methods to find its\nsolution. Further, it is investigated that the property \"the dual of dual is\nprimal\" holds for the L1 regularized least square problem. A solver for the\nsmooth problem is proposed, and its affinity to the proximal gradient is shown.\nFinally, the experiments on L1 and total variation regularized problems are\nperformed, and the corresponding results are reported. \n\n"}
{"id": "1704.04118", "contents": "Title: From Data to Decisions: Distributionally Robust Optimization is Optimal Abstract: We study stochastic programs where the decision-maker cannot observe the\ndistribution of the exogenous uncertainties but has access to a finite set of\nindependent samples from this distribution. In this setting, the goal is to\nfind a procedure that transforms the data to an estimate of the expected cost\nfunction under the unknown data-generating distribution, i.e., a predictor, and\nan optimizer of the estimated cost function that serves as a near-optimal\ncandidate decision, i.e., a prescriptor. As functions of the data, predictors\nand prescriptors constitute statistical estimators. We propose a\nmeta-optimization problem to find the least conservative predictors and\nprescriptors subject to constraints on their out-of-sample disappointment. The\nout-of-sample disappointment quantifies the probability that the actual\nexpected cost of the candidate decision under the unknown true distribution\nexceeds its predicted cost. Leveraging tools from large deviations theory, we\nprove that this meta-optimization problem admits a unique solution: The best\npredictor-prescriptor pair is obtained by solving a distributionally robust\noptimization problem over all distributions within a given relative entropy\ndistance from the empirical distribution of the data. \n\n"}
{"id": "1704.04578", "contents": "Title: On Synchronous, Asynchronous, and Randomized Best-Response schemes for\n  computing equilibria in Stochastic Nash games Abstract: This work considers a stochastic Nash game in which each player solves a\nparameterized stochastic optimization problem. In deterministic regimes,\nbest-response schemes have been shown to be convergent under a suitable\nspectral property associated with the proximal best-response map. However, a\ndirect application of this scheme to stochastic settings requires obtaining\nexact solutions to stochastic optimization at each iteration. Instead, we\npropose an inexact generalization in which an inexact solution is computed via\nan increasing number of projected stochastic gradient steps. Based on this\nframework, we present three inexact best-response schemes: (i) First, we\npropose a synchronous scheme where all players simultaneously update their\nstrategies; (ii) Subsequently, we extend this to a randomized setting where a\nsubset of players is randomly chosen to their update strategies while the\nothers keep their strategies invariant; (iii) Finally, we propose an\nasynchronous scheme, where each player determines its own update frequency and\nmay use outdated rival-specific data in updating its strategy. Under a suitable\ncontractive property of the proximal best-response map, we derive a.s.\nconvergence of the iterates for (i) and (ii) and mean-convergence for (i) --\n(iii). In addition, we show that for (i) -- (iii), the iterates converge to the\nunique equilibrium in mean at a prescribed linear rate. Finally, we establish\nthe overall iteration complexity in terms of projected stochastic gradient\nsteps for computing an $\\epsilon-$Nash equilibrium and in all settings, the\niteration complexity is ${\\cal O}(1/\\epsilon^{2(1+c) + \\delta})$ where $c = 0$\nin the context of (i) and represents the positive cost of randomization (in\n(ii)) and asynchronicity and delay (in (iii)). The schemes are further extended\nto linear and quadratic recourse-based stochastic Nash games. \n\n"}
{"id": "1704.04853", "contents": "Title: Differential Evolution and Bayesian Optimisation for Hyper-Parameter\n  Selection in Mixed-Signal Neuromorphic Circuits Applied to UAV Obstacle\n  Avoidance Abstract: The Lobula Giant Movement Detector (LGMD) is a an identified neuron of the\nlocust that detects looming objects and triggers its escape responses.\nUnderstanding the neural principles and networks that lead to these fast and\nrobust responses can lead to the design of efficient facilitate obstacle\navoidance strategies in robotic applications. Here we present a neuromorphic\nspiking neural network model of the LGMD driven by the output of a neuromorphic\nDynamic Vision Sensor (DVS), which has been optimised to produce robust and\nreliable responses in the face of the constraints and variability of its mixed\nsignal analogue-digital circuits. As this LGMD model has many parameters, we\nuse the Differential Evolution (DE) algorithm to optimise its parameter space.\nWe also investigate the use of Self-Adaptive Differential Evolution (SADE)\nwhich has been shown to ameliorate the difficulties of finding appropriate\ninput parameters for DE. We explore the use of two biological mechanisms:\nsynaptic plasticity and membrane adaptivity in the LGMD. We apply DE and SADE\nto find parameters best suited for an obstacle avoidance system on an unmanned\naerial vehicle (UAV), and show how it outperforms state-of-the-art Bayesian\noptimisation used for comparison. \n\n"}
{"id": "1704.05429", "contents": "Title: Distributed Event-Triggered Control for Global Consensus of Multi-Agent\n  Systems with Input Saturation Abstract: We consider the global consensus problem for multi-agent systems with input\nsaturation over digraphs. Under a mild connectivity condition that the\nunderlying digraph has a directed spanning tree, we use Lyapunov methods to\nshow that the widely used distributed consensus protocol, which solves the\nconsensus problem for the case without input saturation constraints, also\nsolves the global consensus problem for the case with input saturation\nconstraints. In order to reduce the overall need of communication and system\nupdates, we then propose a distributed event-triggered control law. Global\nconsensus is still realized and Zeno behavior is excluded. Numerical\nsimulations are provided to illustrate the effectiveness of the theoretical\nresults. \n\n"}
{"id": "1704.05434", "contents": "Title: Distributed Dynamic Event-Triggered Control for Multi-Agent Systems Abstract: We propose two distributed dynamic triggering laws to solve the consensus\nproblem for multi-agent systems with event-triggered control. Compared with\nexisting triggering laws, the proposed triggering laws involve internal dynamic\nvariables which play an essential role to guarantee that the triggering time\nsequence does not exhibit Zeno behavior. Some existing triggering laws are\nspecial cases of our dynamic triggering laws. Under the condition that the\nunderlying graph is undirected and connected, it is proven that the proposed\ndynamic triggering laws together with the event-triggered control make the\nstate of each agent converges exponentially to the average of the agents'\ninitial states. Numerical simulations illustrate the effectiveness of the\ntheoretical results and show that the dynamic triggering laws lead to reduction\nof actuation updates and inter-agent communications. \n\n"}
{"id": "1704.05947", "contents": "Title: Guaranteed Fault Detection and Isolation for Switched Affine Models Abstract: This paper considers the problem of fault detection and isolation (FDI) for\nswitched affine models. We first study the model invalidation problem and its\napplication to guaranteed fault detection. Novel and intuitive\noptimization-based formulations are proposed for model invalidation and\nT-distinguishability problems, which we demonstrate to be computationally more\nefficient than an earlier formulation that required a complicated change of\nvariables. Moreover, we introduce a distinguishability index as a measure of\nseparation between the system and fault models, which offers a practical method\nfor finding the smallest receding time horizon that is required for fault\ndetection, and for finding potential design recommendations for ensuring\nT-distinguishability. Then, we extend our fault detection guarantees to the\nproblem of fault isolation with multiple fault models, i.e., the identification\nof the type and location of faults, by introducing the concept of\nI-isolability. An efficient way to implement the FDI scheme is also proposed,\nwhose run-time does not grow with the number of fault models that are\nconsidered. Moreover, we derive bounds on detection and isolation delays and\npresent an adaptive scheme for reducing isolation delays. Finally, the\neffectiveness of the proposed method is illustrated using several examples,\nincluding an HVAC system model with multiple faults. \n\n"}
{"id": "1704.08227", "contents": "Title: Accelerating Stochastic Gradient Descent For Least Squares Regression Abstract: There is widespread sentiment that it is not possible to effectively utilize\nfast gradient methods (e.g. Nesterov's acceleration, conjugate gradient, heavy\nball) for the purposes of stochastic optimization due to their instability and\nerror accumulation, a notion made precise in d'Aspremont 2008 and Devolder,\nGlineur, and Nesterov 2014. This work considers these issues for the special\ncase of stochastic approximation for the least squares regression problem, and\nour main result refutes the conventional wisdom by showing that acceleration\ncan be made robust to statistical errors. In particular, this work introduces\nan accelerated stochastic gradient method that provably achieves the minimax\noptimal statistical risk faster than stochastic gradient descent. Critical to\nthe analysis is a sharp characterization of accelerated stochastic gradient\ndescent as a stochastic process. We hope this characterization gives insights\ntowards the broader question of designing simple and effective accelerated\nstochastic methods for more general convex and non-convex optimization\nproblems. \n\n"}
{"id": "1704.08926", "contents": "Title: Necessary conditions for linear convergence of iterated expansive,\n  set-valued mappings with application to alternating projections Abstract: We present necessary conditions for monotonicity, in one form or another, of\nfixed point iterations of mappings that violate the usual nonexpansive\nproperty. We show that most reasonable notions of linear-type monotonicity of\nfixed point sequences imply {\\em metric subregularity}. This is specialized to\nthe alternating projections iteration where the metric subregularity property\ntakes on a distinct geometric characterization of sets at points of\nintersection called {\\em subtransversality}. Our more general results for fixed\npoint iterations are specialized to establish the necessity of\nsubtransversality for consistent feasibility with a number of reasonable types\nof sequential monotonicity, under varying degrees of assumptions on the\nregularity of the sets. \n\n"}
{"id": "1705.00772", "contents": "Title: A Semismooth Newton Method for Fast, Generic Convex Programming Abstract: We introduce Newton-ADMM, a method for fast conic optimization. The basic\nidea is to view the residuals of consecutive iterates generated by the\nalternating direction method of multipliers (ADMM) as a set of fixed point\nequations, and then use a nonsmooth Newton method to find a solution; we apply\nthe basic idea to the Splitting Cone Solver (SCS), a state-of-the-art method\nfor solving generic conic optimization problems. We demonstrate theoretically,\nby extending the theory of semismooth operators, that Newton-ADMM converges\nrapidly (i.e., quadratically) to a solution; empirically, Newton-ADMM is\nsignificantly faster than SCS on a number of problems. The method also has\nessentially no tuning parameters, generates certificates of primal or dual\ninfeasibility, when appropriate, and can be specialized to solve specific\nconvex problems. \n\n"}
{"id": "1705.02502", "contents": "Title: Linearized ADMM for Non-convex Non-smooth Optimization with Convergence\n  Analysis Abstract: Linearized alternating direction method of multipliers (ADMM) as an extension\nof ADMM has been widely used to solve linearly constrained problems in signal\nprocessing, machine leaning, communications, and many other fields. Despite its\nbroad applications in nonconvex optimization, for a great number of nonconvex\nand nonsmooth objective functions, its theoretical convergence guarantee is\nstill an open problem. In this paper, we propose a two-block linearized ADMM\nand a multi-block parallel linearized ADMM for problems with nonconvex and\nnonsmooth objectives. Mathematically, we present that the algorithms can\nconverge for a broader class of objective functions under less strict\nassumptions compared with previous works. Furthermore, our proposed algorithm\ncan update coupled variables in parallel and work for less restrictive\nnonconvex problems, where the traditional ADMM may have difficulties in solving\nsubproblems. \n\n"}
{"id": "1705.02853", "contents": "Title: Geometric Properties of Isostables and Basins of Attraction of Monotone\n  Systems Abstract: In this paper, we study geometric properties of basins of attraction of\nmonotone systems. Our results are based on a combination of monotone systems\ntheory and spectral operator theory. We exploit the framework of the Koopman\noperator, which provides a linear infinite-dimensional description of nonlinear\ndynamical systems and spectral operator-theoretic notions such as eigenvalues\nand eigenfunctions. The sublevel sets of the dominant eigenfunction form a\nfamily of nested forward-invariant sets and the basin of attraction is the\nlargest of these sets. The boundaries of these sets, called isostables, allow\nstudying temporal properties of the system. Our first observation is that the\ndominant eigenfunction is increasing in every variable in the case of monotone\nsystems. This is a strong geometric property which simplifies the computation\nof isostables. We also show how variations in basins of attraction can be\nbounded under parametric uncertainty in the vector field of monotone systems.\nFinally, we study the properties of the parameter set for which a monotone\nsystem is multistable. Our results are illustrated on several systems of two to\nfour dimensions. \n\n"}
{"id": "1705.03952", "contents": "Title: Superlinearly Convergent Asynchronous Distributed Network Newton Method Abstract: The problem of minimizing a sum of local convex objective functions over a\nnetworked system captures many important applications and has received much\nattention in the distributed optimization field. Most of existing work focuses\non development of fast distributed algorithms under the presence of a central\nclock. The only known algorithms with convergence guarantees for this problem\nin asynchronous setup could achieve either sublinear rate under totally\nasynchronous setting or linear rate under partially asynchronous setting (with\nbounded delay). In this work, we built upon existing literature to develop and\nanalyze an asynchronous Newton based approach for solving a penalized version\nof the problem. We show that this algorithm converges almost surely with global\nlinear rate and local superlinear rate in expectation. Numerical studies\nconfirm superior performance against other existing asynchronous methods. \n\n"}
{"id": "1705.04814", "contents": "Title: Networks of open systems Abstract: Many systems of interest in science and engineering are made up of\ninteracting subsystems. These subsystems, in turn, could be made up of\ncollections of smaller interacting subsystems and so on. In a series of papers\nDavid Spivak with collaborators formalized these kinds of structures (systems\nof systems) as algebras over presentable colored operads. It is also very\nuseful to consider maps between dynamical systems, which in effect amounts to\nviewing dynamical systems as objects in an appropriate category. This is the\npoint of view taken by DeVille and Lerman in the study of dynamics on networks.\nThe goal of this paper is to describe an algebraic structure that encompasses\nboth approaches to systems of systems. This allows us, on one hand, build new\nlarge open systems out of collections of smaller open subsystems and on the\nother keep track of maps between open systems. Consequently we obtain synchrony\nresults for open systems which generalize the synchrony results of Golubitsky,\nStewart and their collaborators for groupoid invariant vector fields on coupled\ncell networks. \n\n"}
{"id": "1705.05286", "contents": "Title: Convergence analysis of a family of robust Kalman filters based on the\n  contraction principle Abstract: In this paper we analyze the convergence of a family of robust Kalman\nfilters. For each filter of this family the model uncertainty is tuned\naccording to the so called tolerance parameter. Assuming that the corresponding\nstate-space model is reachable and observable, we show that the corresponding\nRiccati-like mapping is strictly contractive provided that the tolerance is\nsufficiently small, accordingly the filter converges. \n\n"}
{"id": "1705.06048", "contents": "Title: Minimization of fraction function penalty in compressed sensing Abstract: In the paper, we study the minimization problem of a non-convex sparsity\npromoting penalty function\n$$P_{a}(x)=\\sum_{i=1}^{n}p_{a}(x_{i})=\\sum_{i=1}^{n}\\frac{a|x_{i}|}{1+a|x_{i}|}$$\nin compressed sensing, which is called fraction function. Firstly, we discuss\nthe equivalence of $\\ell_{0}$ minimization and fraction function minimization.\nIt is proved that there corresponds a constant $a^{**}>0$ such that, whenever\n$a>a^{**}$, every solution to $(FP_{a})$ also solves $(P_{0})$, that the\nuniqueness of global minimizer of $(FP_{a})$ and its equivalence to $(P_{0})$\nif the sensing matrix $A$ satisfies a restricted isometry property (RIP) and,\nlast but the most important, that the optimal solution to the regularization\nproblem $(FP_{a}^\\lambda)$ also solves $(FP_{a})$ if the certain condition is\nsatisfied, which is similar to the regularization problem in convex optimal\ntheory. Secondly, we study the properties of the optimal solution to the\nregularization problem $(FP^{\\lambda}_{a})$ including the first-order and the\nsecond optimality condition and the lower and upper bound of the absolute value\nfor its nonzero entries. Finally, we derive the closed form representation of\nthe optimal solution to the regularization problem ($FP_{a}^{\\lambda}$) for all\npositive values of parameter $a$, and propose an iterative $FP$ thresholding\nalgorithm to solve the regularization problem $(FP_{a}^{\\lambda})$. We also\nprovide a series of experiments to assess performance of the $FP$ algorithm,\nand the experiment results show that, compared with soft thresholding algorithm\nand half thresholding algorithms, the $FP$ algorithm performs the best in\nsparse signal recovery with and without measurement noise. \n\n"}
{"id": "1705.06431", "contents": "Title: Vehicle Routing with Drones Abstract: We introduce a package service model where trucks as well as drones can\ndeliver packages. Drones can travel on trucks or fly; but while flying, drones\ncan only carry one package at a time and have to return to a truck to charge\nafter each delivery. We present a heuristic algorithm to solve the problem of\nfinding a good schedule for all drones and trucks. The algorithm is based on\ntwo nested local searches, thus the definition of suitable neighbourhoods of\nsolutions is crucial for the algorithm. Empirical tests show that our algorithm\nperforms significantly better than a natural Greedy algorithm. Moreover, the\nsavings compared to solutions without drones turn out to be substantial,\nsuggesting that delivery systems might considerably benefit from using drones\nin addition to trucks. \n\n"}
{"id": "1705.06671", "contents": "Title: Efficient optimization of the quantum relative entropy Abstract: Many quantum information measures can be written as an optimization of the\nquantum relative entropy between sets of states. For example, the relative\nentropy of entanglement of a state is the minimum relative entropy to the set\nof separable states. The various capacities of quantum channels can also be\nwritten in this way. We propose a unified framework to numerically compute\nthese quantities using off-the-shelf semidefinite programming solvers,\nexploiting the approximation method proposed in [Fawzi, Saunderson, Parrilo,\nSemidefinite approximations of the matrix logarithm, arXiv:1705.00812]. As a\nnotable application, this method allows us to provide numerical counterexamples\nfor a proposed lower bound on the quantum conditional mutual information in\nterms of the relative entropy of recovery. \n\n"}
{"id": "1705.06693", "contents": "Title: Limited-Memory Matrix Adaptation for Large Scale Black-box Optimization Abstract: The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is a popular\nmethod to deal with nonconvex and/or stochastic optimization problems when the\ngradient information is not available. Being based on the CMA-ES, the recently\nproposed Matrix Adaptation Evolution Strategy (MA-ES) provides a rather\nsurprising result that the covariance matrix and all associated operations\n(e.g., potentially unstable eigendecomposition) can be replaced in the CMA-ES\nby a updated transformation matrix without any loss of performance. In order to\nfurther simplify MA-ES and reduce its $\\mathcal{O}\\big(n^2\\big)$ time and\nstorage complexity to $\\mathcal{O}\\big(n\\log(n)\\big)$, we present the\nLimited-Memory Matrix Adaptation Evolution Strategy (LM-MA-ES) for efficient\nzeroth order large-scale optimization. The algorithm demonstrates\nstate-of-the-art performance on a set of established large-scale benchmarks. We\nexplore the algorithm on the problem of generating adversarial inputs for a\n(non-smooth) random forest classifier, demonstrating a surprising vulnerability\nof the classifier. \n\n"}
{"id": "1705.07038", "contents": "Title: The Landscape of Deep Learning Algorithms Abstract: This paper studies the landscape of empirical risk of deep neural networks by\ntheoretically analyzing its convergence behavior to the population risk as well\nas its stationary points and properties. For an $l$-layer linear neural\nnetwork, we prove its empirical risk uniformly converges to its population risk\nat the rate of $\\mathcal{O}(r^{2l}\\sqrt{d\\log(l)}/\\sqrt{n})$ with training\nsample size of $n$, the total weight dimension of $d$ and the magnitude bound\n$r$ of weight of each layer. We then derive the stability and generalization\nbounds for the empirical risk based on this result. Besides, we establish the\nuniform convergence of gradient of the empirical risk to its population\ncounterpart. We prove the one-to-one correspondence of the non-degenerate\nstationary points between the empirical and population risks with convergence\nguarantees, which describes the landscape of deep neural networks. In addition,\nwe analyze these properties for deep nonlinear neural networks with sigmoid\nactivation functions. We prove similar results for convergence behavior of\ntheir empirical risks as well as the gradients and analyze properties of their\nnon-degenerate stationary points.\n  To our best knowledge, this work is the first one theoretically\ncharacterizing landscapes of deep learning algorithms. Besides, our results\nprovide the sample complexity of training a good deep neural network. We also\nprovide theoretical understanding on how the neural network depth $l$, the\nlayer width, the network size $d$ and parameter magnitude determine the neural\nnetwork landscapes. \n\n"}
{"id": "1705.07176", "contents": "Title: Accelerated Distributed Nesterov Gradient Descent Abstract: This paper considers the distributed optimization problem over a network,\nwhere the objective is to optimize a global function formed by a sum of local\nfunctions, using only local computation and communication. We develop an\nAccelerated Distributed Nesterov Gradient Descent (Acc-DNGD) method. When the\nobjective function is convex and $L$-smooth, we show that it achieves a\n$O(\\frac{1}{t^{1.4-\\epsilon}})$ convergence rate for all $\\epsilon\\in(0,1.4)$.\nWe also show the convergence rate can be improved to $O(\\frac{1}{t^2})$ if the\nobjective function is a composition of a linear map and a strongly-convex and\nsmooth function. When the objective function is $\\mu$-strongly convex and\n$L$-smooth, we show that it achieves a linear convergence rate of $O([ 1 - C\n(\\frac{\\mu}{L})^{5/7} ]^t)$, where $\\frac{L}{\\mu}$ is the condition number of\nthe objective, and $C>0$ is some constant that does not depend on\n$\\frac{L}{\\mu}$. \n\n"}
{"id": "1705.07765", "contents": "Title: Exact Recovery with Symmetries for the Doubly-Stochastic Relaxation Abstract: Graph matching or quadratic assignment, is the problem of labeling the\nvertices of two graphs so that they are as similar as possible. A common method\nfor approximately solving the NP-hard graph matching problem is relaxing it to\na convex optimization problem over the set of doubly stochastic (DS) matrices.\nRecent analysis has shown that for almost all pairs of isomorphic and\nasymmetric graphs, the DS relaxation succeeds in correctly retrieving the\nisomorphism between the graphs. Our goal in this paper is to analyze the case\nof symmetric isomorphic graphs. This goal is motivated by shape matching\napplications where the graphs of interest usually have reflective symmetry.\n  For symmetric problems the graph matching problem has multiple isomorphisms\nand so convex relaxations admit all convex combinations of these isomorphisms\nas viable solutions. If the convex relaxation does not admit any additional\nsuperfluous solution we say that it is convex exact. In this case there are\ntractable algorithms to retrieve an isomorphism from the convex relaxation.\n  We show that convex exactness depends strongly on the symmetry group of the\ngraphs; For a fixed symmetry group $G$, either the DS relaxation will be convex\nexact for almost all pairs of isomorphic graphs with symmetry group $G$, or the\nDS relaxation will fail for all such pairs. We show that for reflective groups\nwith at least one full orbit convex exactness holds almost everywhere, and\nprovide some simple examples of non-reflective symmetry groups for which convex\nexactness always fails.\n  When convex exactness holds, the isomorphisms of the graphs are the extreme\npoints of the convex solution set. We suggest an efficient algorithm for\nretrieving an isomorphism in this case. We also show that the \"convex to\nconcave\" projection method will also retrieve an isomorphism in this case. \n\n"}
{"id": "1705.08253", "contents": "Title: Lifting Markov Chains To Mix Faster: Limits and Opportunities Abstract: Lifted Markov chains are Markov chains on graphs with added local \"memory\"\nand can be used to mix towards a target distribution faster than their\nmemoryless counterparts. Upper and lower bounds on the achievable performance\nhave been provided under specific assumptions. In this paper, we analyze which\nassumptions and constraints are relevant for mixing, and how changing these\nassumptions affects those bounds. Explicitly, we find that requesting mixing on\neither the original or the full lifted graph, and allowing for reducible lifted\nchains or not, have no essential influence on mixing time bounds. On the other\nhand, allowing for suitable initialization of the lifted dynamics and/or\nimposing invariance of the target distribution for any initialization do\nsignificantly affect the convergence performance. The achievable convergence\nspeed for a lifted chain goes from diameter-time to no acceleration over a\nstandard Markov chain, with conductance bounds limiting the effectiveness of\nthe intermediate cases. In addition, we show that the relevance of imposing\nergodic flows depends on the other criteria. The presented analysis allows us\nto clarify in which scenarios designing lifted dynamics can lead to better\nmixing, and provide a flexible framework to compare lifted walks with other\nacceleration methods. \n\n"}
{"id": "1705.08657", "contents": "Title: Combinatorial n-fold Integer Programming and Applications Abstract: Many fundamental NP-hard problems can be formulated as integer linear\nprograms (ILPs). A famous algorithm by Lenstra solves ILPs in time that is\nexponential only in the dimension of the program, and polynomial in the size of\nthe ILP. That algorithm became a ubiquitous tool in the design of\nfixed-parameter algorithms for NP-hard problems, where one wishes to isolate\nthe hardness of a problemby some parameter. However, in many cases using\nLenstra's algorithm has two drawbacks: First, the run time of the resulting\nalgorithms is often doubly-exponential in the parameter, and second, an ILP\nformulation in small dimension cannot easily express problems involving many\ndifferent costs.\n  Inspired by the work of Hemmecke, Onn and Romanchuk [Math. Prog. 2013], we\ndevelop a single-exponential algorithm for so-called combinatorial n-fold\ninteger programs, which are remarkably similar to prior ILP formulations for\nvarious problems, but unlike them, also allow variable dimension. We then apply\nour algorithm to a few representative problems like Closest String, Swap\nBribery, Weighted Set Multicover, and obtain exponential speedups in the\ndependence on the respective parameters, the input size, or both.\n  Unlike Lenstra's algorithm, which is essentially a bounded search tree\nalgorithm, our result uses the technique of augmenting steps. At its heart is a\ndeep result stating that in combinatorial n-fold IPs, existence of an\naugmenting step implies existence of a \\local\" augmenting step, which can be\nfound using dynamic programming. Our results provide an important insight into\nmany problems by showing that they exhibit this phenomenon, and highlights the\nimportance of augmentation techniques. \n\n"}
{"id": "1705.09340", "contents": "Title: Rates of convergence for inexact Krasnosel'skii-Mann iterations in\n  Banach spaces Abstract: We study the convergence of an inexact version of the classical\nKrasnosel'skii-Mann iteration for computing fixed points of nonexpansive maps.\nOur main result establishes a new metric bound for the fixed-point residuals,\nfrom which we derive their rate of convergence as well as the convergence of\nthe iterates towards a fixed point. The results are applied to three variants\nof the basic iteration: infeasible iterations with approximate projections, the\nIshikawa iteration, and diagonal Krasnosels'kii-Mann schemes. The results are\nalso extended to continuous time in order to study the asymptotics of\nnonautonomous evolution equations governed by nonexpansive operators. \n\n"}
{"id": "1705.09383", "contents": "Title: Uniqueness of optimal solutions for semi-discrete transport with p-norm\n  cost functions Abstract: Semi-discrete transport can be characterized in terms of real-valued shifts.\nOften, but not always, the solution to the shift-characterized problem\npartitions the continuous region. This paper gives examples of when\npartitioning fails, and offers a large class of semi-discrete transport\nproblems where the shift-characterized solution is always a partition. \n\n"}
{"id": "1705.09396", "contents": "Title: Approximate and Stochastic Greedy Optimization Abstract: We consider two greedy algorithms for minimizing a convex function in a\nbounded convex set: an algorithm by Jones [1992] and the Frank-Wolfe (FW)\nalgorithm. We first consider approximate versions of these algorithms. For\nsmooth convex functions, we give sufficient conditions for convergence, a\nunified analysis for the well-known convergence rate of O(1/k) together with a\nresult showing that this rate is the best obtainable from the proof technique,\nand an equivalence result for the two algorithms. We also consider approximate\nstochastic greedy algorithms for minimizing expectations. We show that\nreplacing the full gradient by a single stochastic gradient can fail even on\nsmooth convex functions. We give a convergent approximate stochastic Jones\nalgorithm and a convergent approximate stochastic FW algorithm for smooth\nconvex functions. In addition, we give a convergent approximate stochastic FW\nalgorithm for nonsmooth convex functions. Convergence rates for these\nalgorithms are given and proved. \n\n"}
{"id": "1705.10412", "contents": "Title: Gradient Descent Can Take Exponential Time to Escape Saddle Points Abstract: Although gradient descent (GD) almost always escapes saddle points\nasymptotically [Lee et al., 2016], this paper shows that even with fairly\nnatural random initialization schemes and non-pathological functions, GD can be\nsignificantly slowed down by saddle points, taking exponential time to escape.\nOn the other hand, gradient descent with perturbations [Ge et al., 2015, Jin et\nal., 2017] is not slowed down by saddle points - it can find an approximate\nlocal minimizer in polynomial time. This result implies that GD is inherently\nslower than perturbed GD, and justifies the importance of adding perturbations\nfor efficient non-convex optimization. While our focus is theoretical, we also\npresent experiments that illustrate our theoretical findings. \n\n"}
{"id": "1706.00074", "contents": "Title: Free energy-based reinforcement learning using a quantum processor Abstract: Recent theoretical and experimental results suggest the possibility of using\ncurrent and near-future quantum hardware in challenging sampling tasks. In this\npaper, we introduce free energy-based reinforcement learning (FERL) as an\napplication of quantum hardware. We propose a method for processing a quantum\nannealer's measured qubit spin configurations in approximating the free energy\nof a quantum Boltzmann machine (QBM). We then apply this method to perform\nreinforcement learning on the grid-world problem using the D-Wave 2000Q quantum\nannealer. The experimental results show that our technique is a promising\nmethod for harnessing the power of quantum sampling in reinforcement learning\ntasks. \n\n"}
{"id": "1706.00078", "contents": "Title: Low-Rank Matrix Approximation in the Infinity Norm Abstract: The low-rank matrix approximation problem with respect to the entry-wise\n$\\ell_{\\infty}$-norm is the following: given a matrix $M$ and a factorization\nrank $r$, find a matrix $X$ whose rank is at most $r$ and that minimizes\n$\\max_{i,j} |M_{ij} - X_{ij}|$. In this paper, we prove that the decision\nvariant of this problem for $r=1$ is NP-complete using a reduction from the\nproblem `not all equal 3SAT'. We also analyze several cases when the problem\ncan be solved in polynomial time, and propose a simple practical heuristic\nalgorithm which we apply on the problem of the recovery of a quantized low-rank\nmatrix. \n\n"}
{"id": "1706.00733", "contents": "Title: Stochastic Model Predictive Control: Output-Feedback, Duality and\n  Guaranteed Performance Abstract: A new formulation of Stochastic Model Predictive Output Feedback Control is\npresented and analyzed as a translation of Stochastic Optimal Output Feedback\nControl into a receding horizon setting. This requires lifting the design into\na framework involving propagation of the conditional state density, the\ninformation state, via the Bayesian Filter and solution of the Stochastic\nDynamic Programming Equation for an optimal feedback policy, both stages of\nwhich are computationally challenging in the general, nonlinear setup. The\nupside is that the clearance of three bottleneck aspects of Model Predictive\nControl is connate to the optimality: output feedback is incorporated\nnaturally; dual regulation and probing of the control signal is inherent;\nclosed-loop performance relative to infinite-horizon optimal control is\nguaranteed. While the methods are numerically formidable, our aim is to develop\nan approach to Stochastic Model Predictive Control with guarantees and, from\nthere, to seek a less onerous approximation. To this end, we discuss in\nparticular the class of Partially Observable Markov Decision Processes, to\nwhich our results extend seamlessly, and demonstrate applicability with an\nexample in healthcare decision making, where duality and associated optimality\nin the control signal are required for satisfactory closed-loop behavior. \n\n"}
{"id": "1706.01254", "contents": "Title: Moral hazard in welfare economics: on the advantage of Planner's advices\n  to manage employees' actions Abstract: In this paper, we study moral hazard problems in contract theory by adding an\nexogenous Planner to manage the actions of Agents hired by a Principal. We\nprovide conditions ensuring that Pareto optima exist for the Agents using the\nscalarization method associated with the multi-objective optimization problem\nand we solve the problem of the Principal by finding optimal remunerations\ngiven to the Agents. We illustrate our study with a linear-quadratic model by\ncomparing the results obtained when we add a Planner in the\nPrincipal/multi-Agents problem with the results obtained in the classical\nsecond-best case. More particularly in this example, we give necessary and\nsufficient conditions ensuring that Pareto optima are Nash equilibria and we\nprove that the Principal takes the benefit of the action of the Planner in some\ncases \n\n"}
{"id": "1706.01445", "contents": "Title: Batched Large-scale Bayesian Optimization in High-dimensional Spaces Abstract: Bayesian optimization (BO) has become an effective approach for black-box\nfunction optimization problems when function evaluations are expensive and the\noptimum can be achieved within a relatively small number of queries. However,\nmany cases, such as the ones with high-dimensional inputs, may require a much\nlarger number of observations for optimization. Despite an abundance of\nobservations thanks to parallel experiments, current BO techniques have been\nlimited to merely a few thousand observations. In this paper, we propose\nensemble Bayesian optimization (EBO) to address three current challenges in BO\nsimultaneously: (1) large-scale observations; (2) high dimensional input\nspaces; and (3) selections of batch queries that balance quality and diversity.\nThe key idea of EBO is to operate on an ensemble of additive Gaussian process\nmodels, each of which possesses a randomized strategy to divide and conquer. We\nshow unprecedented, previously impossible results of scaling up BO to tens of\nthousands of observations within minutes of computation. \n\n"}
{"id": "1706.01665", "contents": "Title: Stochastic Multi-objective Optimization on a Budget: Application to\n  multi-pass wire drawing with quantified uncertainties Abstract: Design optimization of engineering systems with multiple competing objectives\nis a painstakingly tedious process especially when the objective functions are\nexpensive-to-evaluate computer codes with parametric uncertainties. The\neffectiveness of the state-of-the-art techniques is greatly diminished because\nthey require a large number of objective evaluations, which makes them\nimpractical for problems of the above kind. Bayesian global optimization (BGO),\nhas managed to deal with these challenges in solving single-objective\noptimization problems and has recently been extended to multi-objective\noptimization (MOO). BGO models the objectives via probabilistic surrogates and\nuses the epistemic uncertainty to define an information acquisition function\n(IAF) that quantifies the merit of evaluating the objective at new designs.\nThis iterative data acquisition process continues until a stopping criterion is\nmet. The most commonly used IAF for MOO is the expected improvement over the\ndominated hypervolume (EIHV) which in its original form is unable to deal with\nparametric uncertainties or measurement noise. In this work, we provide a\nsystematic reformulation of EIHV to deal with stochastic MOO problems. The\nprimary contribution of this paper lies in being able to filter out the noise\nand reformulate the EIHV without having to observe or estimate the stochastic\nparameters. An addendum of the probabilistic nature of our methodology is that\nit enables us to characterize our confidence about the predicted Pareto front.\nWe verify and validate the proposed methodology by applying it to synthetic\ntest problems with known solutions. We demonstrate our approach on an\nindustrial problem of die pass design for a steel wire drawing process. \n\n"}
{"id": "1706.02654", "contents": "Title: Derivation and Analysis of the Primal-Dual Method of Multipliers Based\n  on Monotone Operator Theory Abstract: In this paper we present a novel derivation for an existing node-based\nalgorithm for distributed optimisation termed the primal-dual method of\nmultipliers (PDMM). In contrast to its initial derivation, in this work\nmonotone operator theory is used to connect PDMM with other first-order methods\nsuch as Douglas-Rachford splitting and the alternating direction method of\nmultipliers thus providing insight to the operation of the scheme. In\nparticular, we show how PDMM combines a lifted dual form in conjunction with\nPeaceman-Rachford splitting to remove the need for collaboration between nodes\nper iteration. We demonstrate sufficient conditions for strong primal\nconvergence for a general class of functions while under the assumption of\nstrong convexity and functional smoothness, we also introduce a primal\ngeometric convergence bound. Finally we introduce a distributed method of\nparameter selection in the geometric convergent case, requiring only finite\ntransmissions to implement regardless of network topology. \n\n"}
{"id": "1706.03606", "contents": "Title: Eigenvector Method and rank reversal in group decision making revisited Abstract: It has been shown recently that the Eigenvector Method may lead to strong\nrank reversal in group decision making, that is, the alternative with the\nhighest priority according to all individual vectors may lose its position when\nevaluations are derived from the aggregated group comparison matrix. We give a\nminimal counterexample and prove that this negative result is a consequence of\nthe difference of the rankings induced by the right and inverse left\neigenvectors. \n\n"}
{"id": "1706.04072", "contents": "Title: A Polynomial-Time Algorithm for Solving the Minimal Observability\n  Problem in Conjunctive Boolean Networks Abstract: Many complex systems in biology, physics, and engineering include a large\nnumber of state-variables, and measuring the full state of the system is often\nimpossible. Typically, a set of sensors is used to measure part of the\nstate-variables. A system is called observable if these measurements allow to\nreconstruct the entire state of the system. When the system is not observable,\nan important and practical problem is how to add a \\emph{minimal} number of\nsensors so that the system becomes observable. This minimal observability\nproblem is practically useful and theoretically interesting, as it pinpoints\nthe most informative nodes in the system. We consider the minimal observability\nproblem for an important special class of Boolean networks, called conjunctive\nBoolean networks (CBNs). Using a graph-theoretic approach, we provide a\nnecessary and sufficient condition for observability of a CBN with $n$\nstate-variables, and an efficient~$O(n^2)$-time algorithm for solving the\nminimal observability problem. We demonstrate the usefulness of these results\nby studying the properties of a class of random CBNs. \n\n"}
{"id": "1706.05120", "contents": "Title: On Structural Controllability of Symmetric (Brain) Networks Abstract: The question of controllability of natural and man-made network systems has\nrecently received considerable attention. In the context of the human brain,\nthe study of controllability may not only shed light into the organization and\nfunction of different neural circuits, but also inform the design and\nimplementation of minimally invasive yet effective intervention protocols to\ntreat neurological disorders. While the characterization of brain\ncontrollability is still in its infancy, some results have recently appeared\nand given rise to scientific debate. Among these, [1] has numerically shown\nthat a class of brain networks constructed from DSI/DTI imaging data are\ncontrollable from one brain region. That is, a single brain region is\ntheoretically capable of moving the whole brain network towards any desired\ntarget state. In this note we provide evidence supporting controllability of\nbrain networks from a single region as discussed in [1], thus contradicting the\nmain conclusion and methods developed in [2]. \n\n"}
{"id": "1706.05572", "contents": "Title: Information Structure Design in Team Decision Problems Abstract: We consider a problem of information structure design in team decision\nproblems and team games. We propose simple, scalable greedy algorithms for\nadding a set of extra information links to optimize team performance and\nresilience to non-cooperative and adversarial agents. We show via a simple\ncounterexample that the set function mapping additional information links to\nteam performance is in general not supermodular. Although this implies that the\ngreedy algorithm is not accompanied by worst-case performance guarantees, we\nillustrate through numerical experiments that it can produce effective and\noften optimal or near optimal information structure modifications. \n\n"}
{"id": "1706.05671", "contents": "Title: Rate of convergence of the Nesterov accelerated gradient method in the\n  subcritical case $\\alpha \\leq 3$ Abstract: In a Hilbert space setting $\\mathcal H$, given $\\Phi: \\mathcal H \\to \\mathbb\nR$ a convex continuously differentiable function, and $\\alpha$ a positive\nparameter, we consider the inertial system with Asymptotic Vanishing Damping\n\\begin{equation*}\n  \\mbox{(AVD)}_{\\alpha} \\quad \\quad \\ddot{x}(t) + \\frac{\\alpha}{t} \\dot{x}(t) +\n\\nabla \\Phi (x(t)) =0. \\end{equation*}\n  Depending on the value of $ \\alpha $ with respect to 3, we give a complete\npicture of the convergence properties as $t \\to + \\infty$ of the trajectories\ngenerated by $\\mbox{(AVD)}_{\\alpha}$, as well as iterations of the\ncorresponding algorithms. Our main result concerns the subcritical case $\\alpha\n\\leq 3$, where we show that $\\Phi (x(t))-\\min \\Phi = \\mathcal O\n(t^{-\\frac{2}{3}\\alpha})$.\n  Then we examine the convergence of trajectories to optimal solutions. As a\nnew result, in the one-dimensional framework, for the critical value $\\alpha =\n3 $, we prove the convergence of the trajectories without any restrictive\nhypothesis on the convex function $\\Phi $. In the second part of this paper, we\nstudy the convergence properties of the associated forward-backward inertial\nalgorithms. They aim to solve structured convex minimization problems of the\nform $\\min \\left\\lbrace \\Theta:= \\Phi + \\Psi \\right\\rbrace$, with $\\Phi$ smooth\nand $\\Psi$ nonsmooth. The continuous dynamics serves as a guideline for this\nstudy. We obtain a similar rate of convergence for the sequence of iterates\n$(x_k)$: for $\\alpha \\leq 3$ we have $\\Theta (x_k)-\\min \\Theta = \\mathcal O\n(k^{-p})$ for all $p <\\frac{2\\alpha}{3}$ , and for $\\alpha > 3$ \\ $\\Theta\n(x_k)-\\min \\Theta = o (k^{-2})$ . We conclude this study by showing that the\nresults are robust with respect to external perturbations. \n\n"}
{"id": "1706.06066", "contents": "Title: On Quadratic Convergence of DC Proximal Newton Algorithm for Nonconvex\n  Sparse Learning in High Dimensions Abstract: We propose a DC proximal Newton algorithm for solving nonconvex regularized\nsparse learning problems in high dimensions. Our proposed algorithm integrates\nthe proximal Newton algorithm with multi-stage convex relaxation based on the\ndifference of convex (DC) programming, and enjoys both strong computational and\nstatistical guarantees. Specifically, by leveraging a sophisticated\ncharacterization of sparse modeling structures/assumptions (i.e., local\nrestricted strong convexity and Hessian smoothness), we prove that within each\nstage of convex relaxation, our proposed algorithm achieves (local) quadratic\nconvergence, and eventually obtains a sparse approximate local optimum with\noptimal statistical properties after only a few convex relaxations. Numerical\nexperiments are provided to support our theory. \n\n"}
{"id": "1706.07401", "contents": "Title: A Geometric Analysis of Power System Loadability Regions Abstract: Understanding the feasible power flow region is of central importance to\npower system analysis. In this paper, we propose a geometric view of the power\nsystem loadability problem. By using rectangular coordinates for complex\nvoltages, we provide an integrated geometric understanding of active and\nreactive power flow equations on loadability boundaries. Based on such an\nunderstanding, we develop a linear programming framework to 1) verify if an\noperating point is on the loadability boundary, 2) compute the margin of an\noperating point to the loadability boundary, and 3) calculate a loadability\nboundary point of any direction. The proposed method is computationally more\nefficient than existing methods since it does not require solving nonlinear\noptimization problems or calculating the eigenvalues of the power flow\nJacobian. Standard IEEE test cases demonstrate the capability of the new method\ncompared to the current state-of-the-art methods. \n\n"}
{"id": "1706.08459", "contents": "Title: Preasymptotic Convergence of Randomized Kaczmarz Method Abstract: Kaczmarz method is one popular iterative method for solving inverse problems,\nespecially in computed tomography. Recently, it was established that a\nrandomized version of the method enjoys an exponential convergence for\nwell-posed problems, and the convergence rate is determined by a variant of the\ncondition number. In this work, we analyze the preasymptotic convergence\nbehavior of the randomized Kaczmarz method, and show that the low-frequency\nerror (with respect to the right singular vectors) decays faster during first\niterations than the high-frequency error. Under the assumption that the inverse\nsolution is smooth (e.g., sourcewise representation), the result explains the\nfast empirical convergence behavior, thereby shedding new insights into the\nexcellent performance of the randomized Kaczmarz method in practice. Further,\nwe propose a simple strategy to stabilize the asymptotic convergence of the\niteration by means of variance reduction. We provide extensive numerical\nexperiments to confirm the analysis and to elucidate the behavior of the\nalgorithms. \n\n"}
{"id": "1706.08800", "contents": "Title: On the R-superlinear convergence of the KKT residues generated by the\n  augmented Lagrangian method for convex composite conic programming Abstract: Due to the possible lack of primal-dual-type error bounds, the superlinear\nconvergence for the Karush-Kuhn-Tucker (KKT) residues of the sequence generated\nby augmented Lagrangian method (ALM) for solving convex composite conic\nprogramming (CCCP) has long been an outstanding open question. In this paper,\nwe aim to resolve this issue by first conducting convergence rate analysis for\nthe ALM with Rockafellar's stopping criteria under only a mild quadratic growth\ncondition on the dual of CCCP. More importantly, by further assuming that the\nRobinson constraint qualification holds, we establish the R-superlinear\nconvergence of the KKT residues of the iterative sequence under\neasy-to-implement stopping criteria {for} the augmented Lagrangian subproblems.\nEquipped with this discovery, we gain insightful interpretations on the\nimpressive numerical performance of several recently developed semismooth\nNewton-CG based ALM solvers for solving linear and convex quadratic\nsemidefinite programming. \n\n"}
{"id": "1706.09835", "contents": "Title: Linear Estimation of Treatment Effects in Demand Response: An\n  Experimental Design Approach Abstract: Demand response aims to stimulate electricity consumers to modify their loads\nat critical time periods. In this paper, we consider signals in demand response\nprograms as a binary treatment to the customers and estimate the average\ntreatment effect, which is the average change in consumption under the demand\nresponse signals. More specifically, we propose to estimate this effect by\nlinear regression models and derive several estimators based on the different\nmodels. From both synthetic and real data, we show that including more\ninformation about the customers does not always improve estimation accuracy:\nthe interaction between the side information and the demand response signal\nmust be carefully modeled. In addition, we compare the traditional linear\nregression model with the modified covariate method which models the\ninteraction between treatment effect and covariates. We analyze the variances\nof these estimators and discuss different cases where each respective estimator\nworks the best. The purpose of these comparisons is not to claim the\nsuperiority of the different methods, rather we aim to provide practical\nguidance on the most suitable estimator to use under different settings. Our\nresults are validated using data collected by Pecan Street and EnergyPlus. \n\n"}
{"id": "1707.00389", "contents": "Title: Convolutional Dictionary Learning: Acceleration and Convergence Abstract: Convolutional dictionary learning (CDL or sparsifying CDL) has many\napplications in image processing and computer vision. There has been growing\ninterest in developing efficient algorithms for CDL, mostly relying on the\naugmented Lagrangian (AL) method or the variant alternating direction method of\nmultipliers (ADMM). When their parameters are properly tuned, AL methods have\nshown fast convergence in CDL. However, the parameter tuning process is not\ntrivial due to its data dependence and, in practice, the convergence of AL\nmethods depends on the AL parameters for nonconvex CDL problems. To moderate\nthese problems, this paper proposes a new practically feasible and convergent\nBlock Proximal Gradient method using a Majorizer (BPG-M) for CDL. The\nBPG-M-based CDL is investigated with different block updating schemes and\nmajorization matrix designs, and further accelerated by incorporating some\nmomentum coefficient formulas and restarting techniques. All of the methods\ninvestigated incorporate a boundary artifacts removal (or, more generally,\nsampling) operator in the learning model. Numerical experiments show that,\nwithout needing any parameter tuning process, the proposed BPG-M approach\nconverges more stably to desirable solutions of lower objective values than the\nexisting state-of-the-art ADMM algorithm and its memory-efficient variant do.\nCompared to the ADMM approaches, the BPG-M method using a multi-block updating\nscheme is particularly useful in single-threaded CDL algorithm handling large\ndatasets, due to its lower memory requirement and no polynomial computational\ncomplexity. Image denoising experiments show that, for relatively strong\nadditive white Gaussian noise, the filters learned by BPG-M-based CDL\noutperform those trained by the ADMM approach. \n\n"}
{"id": "1707.00481", "contents": "Title: Proximity results and faster algorithms for Integer Programming using\n  the Steinitz Lemma Abstract: We consider integer programming problems in standard form $\\max \\{c^Tx : Ax =\nb, \\, x\\geq 0, \\, x \\in Z^n\\}$ where $A \\in Z^{m \\times n}$, $b \\in Z^m$ and $c\n\\in Z^n$. We show that such an integer program can be solved in time $(m\n\\Delta)^{O(m)} \\cdot \\|b\\|_\\infty^2$, where $\\Delta$ is an upper bound on each\nabsolute value of an entry in $A$. This improves upon the longstanding best\nbound of Papadimitriou (1981) of $(m\\cdot \\Delta)^{O(m^2)}$, where in addition,\nthe absolute values of the entries of $b$ also need to be bounded by $\\Delta$.\nOur result relies on a lemma of Steinitz that states that a set of vectors in\n$R^m$ that is contained in the unit ball of a norm and that sum up to zero can\nbe ordered such that all partial sums are of norm bounded by $m$. We also use\nthe Steinitz lemma to show that the $\\ell_1$-distance of an optimal integer and\nfractional solution, also under the presence of upper bounds on the variables,\nis bounded by $m \\cdot (2\\,m \\cdot \\Delta+1)^m$. Here $\\Delta$ is again an\nupper bound on the absolute values of the entries of $A$. The novel strength of\nour bound is that it is independent of $n$. We provide evidence for the\nsignificance of our bound by applying it to general knapsack problems where we\nobtain structural and algorithmic results that improve upon the recent\nliterature. \n\n"}
{"id": "1707.01173", "contents": "Title: B tensors and tensor complementarity problems Abstract: In this paper, one of our main purposes is to prove the boundedness of\nsolution set of tensor complementarity problem with B tensor such that the\nspecific bounds only depend on the structural properties of tensor. To achieve\nthis purpose, firstly, we present that each B tensor is strictly semi-positive\nand each B$_0$ tensor is semi-positive. Subsequencely, the strictly lower and\nupper bounds of different operator norms are given for two positively\nhomogeneous operators defined by B tensor. Finally, with the help of the upper\nbounds of different operator norms, we show the strcitly lower bound of\nsolution set of tensor complementarity problem with B tensor. Furthermore, the\nupper bounds of spectral radius and $E$-spectral radius of B (B$_0$) tensor are\nobtained, respectively, which achieves our another objective. In particular,\nsuch the upper bounds only depend on the principal diagonal entries of tensors. \n\n"}
{"id": "1707.01454", "contents": "Title: Variational discretization of a control-constrained parabolic bang-bang\n  optimal control problem Abstract: We consider a control-constrained parabolic optimal control problem without\nTikhonov term in the tracking functional. For the numerical treatment, we use\nvariational discretization of its Tikhonov regularization: For the state and\nthe adjoint equation, we apply Petrov-Galerkin schemes from [Daniels et al\n2015] in time and usual conforming finite elements in space. We prove a-priori\nestimates for the error between the discretized regularized problem and the\nlimit problem. Since these estimates are not robust if the regularization\nparameter tends to zero, we establish robust estimates, which --- depending on\nthe problem's regularity --- enhance the previous ones. In the special case of\nbang-bang solutions, these estimates are further improved. A numerical example\nconfirms our analytical findings. \n\n"}
{"id": "1707.01647", "contents": "Title: Convergence Analysis of Optimization Algorithms Abstract: The regret bound of an optimization algorithms is one of the basic criteria\nfor evaluating the performance of the given algorithm. By inspecting the\ndifferences between the regret bounds of traditional algorithms and adaptive\none, we provide a guide for choosing an optimizer with respect to the given\ndata set and the loss function. For analysis, we assume that the loss function\nis convex and its gradient is Lipschitz continuous. \n\n"}
{"id": "1707.02444", "contents": "Title: Global optimality conditions for deep neural networks Abstract: We study the error landscape of deep linear and nonlinear neural networks\nwith the squared error loss. Minimizing the loss of a deep linear neural\nnetwork is a nonconvex problem, and despite recent progress, our understanding\nof this loss surface is still incomplete. For deep linear networks, we present\nnecessary and sufficient conditions for a critical point of the risk function\nto be a global minimum. Surprisingly, our conditions provide an efficiently\ncheckable test for global optimality, while such tests are typically\nintractable in nonconvex optimization. We further extend these results to deep\nnonlinear neural networks and prove similar sufficient conditions for global\noptimality, albeit in a more limited function space setting. \n\n"}
{"id": "1707.02503", "contents": "Title: Demand Shaping in Cellular Networks Abstract: Demand shaping is a promising way to mitigate the wireless cellular capacity\nshortfall in the presence of ever-increasing wireless data demand. In this\npaper, we formulate demand shaping as an optimization problem that minimizes\nthe variation in aggregate traffic. We design a distributed and randomized\noffline demand shaping algorithm under complete traffic information and prove\nits almost surely convergence. We further consider a more realistic setting\nwhere the traffic information is incomplete but the future traffic can be\npredicted to a certain degree of accuracy. We design an online demand shaping\nalgorithm that updates the schedules of deferrable applications (DAs) each time\nwhen new information is available, based on solving at each timeslot an\noptimization problem over a shrinking horizon from the current time to the end\nof the day. We compare the performance of the online algorithm against the\noptimal offline algorithm, and provide numerical examples to complement the\ntheoretical analysis. \n\n"}
{"id": "1707.02568", "contents": "Title: Solving high-dimensional partial differential equations using deep\n  learning Abstract: Developing algorithms for solving high-dimensional partial differential\nequations (PDEs) has been an exceedingly difficult task for a long time, due to\nthe notoriously difficult problem known as the \"curse of dimensionality\". This\npaper introduces a deep learning-based approach that can handle general\nhigh-dimensional parabolic PDEs. To this end, the PDEs are reformulated using\nbackward stochastic differential equations and the gradient of the unknown\nsolution is approximated by neural networks, very much in the spirit of deep\nreinforcement learning with the gradient acting as the policy function.\nNumerical results on examples including the nonlinear Black-Scholes equation,\nthe Hamilton-Jacobi-Bellman equation, and the Allen-Cahn equation suggest that\nthe proposed algorithm is quite effective in high dimensions, in terms of both\naccuracy and cost. This opens up new possibilities in economics, finance,\noperational research, and physics, by considering all participating agents,\nassets, resources, or particles together at the same time, instead of making ad\nhoc assumptions on their inter-relationships. \n\n"}
{"id": "1707.02950", "contents": "Title: Relaxing Integrity Requirements for Attack-Resilient Cyber-Physical\n  Systems Abstract: The increase in network connectivity has also resulted in several\nhigh-profile attacks on cyber-physical systems. An attacker that manages to\naccess a local network could remotely affect control performance by tampering\nwith sensor measurements delivered to the controller. Recent results have shown\nthat with network-based attacks, such as Man-in-the-Middle attacks, the\nattacker can introduce an unbounded state estimation error if measurements from\na suitable subset of sensors contain false data when delivered to the\ncontroller. While these attacks can be addressed with the standard\ncryptographic tools that ensure data integrity, their continuous use would\nintroduce significant communication and computation overhead. Consequently, we\nstudy effects of intermittent data integrity guarantees on system performance\nunder stealthy attacks. We consider linear estimators equipped with a general\ntype of residual-based intrusion detectors (including $\\chi^2$ and SPRT\ndetectors), and show that even when integrity of sensor measurements is\nenforced only intermittently, the attack impact is significantly limited;\nspecifically, the state estimation error is bounded or the attacker cannot\nremain stealthy. Furthermore, we present methods to: (1) evaluate the effects\nof any given integrity enforcement policy in terms of reachable\nstate-estimation errors for any type of stealthy attacks, and (2) design an\nenforcement policy that provides the desired estimation error guarantees under\nattack. Finally, on three automotive case studies we show that even with less\nthan 10% of authenticated messages we can ensure satisfiable control\nperformance in the presence of attacks. \n\n"}
{"id": "1707.03686", "contents": "Title: Methodology for Multi-stage, Operations- and Uncertainty-Aware Placement\n  and Sizing of FACTS Devices in a Large Power Transmission System Abstract: We develop new optimization methodology for planning installation of Flexible\nAlternating Current Transmission System (FACTS) devices of the parallel and\nshunt types into large power transmission systems, which allows to delay or\navoid installations of generally much more expensive power lines. Methodology\ntakes as an input projected economic development, expressed through a paced\ngrowth of the system loads, as well as uncertainties, expressed through\nmultiple scenarios of the growth. We price new devices according to their\ncapacities. Installation cost contributes to the optimization objective in\ncombination with the cost of operations integrated over time and averaged over\nthe scenarios. The multi-stage (-time-frame) optimization aims to achieve a\ngradual distribution of new resources in space and time. Constraints on the\ninvestment budget, or equivalently constraint on building capacity, is\nintroduced at each time frame. Our approach adjusts operationally not only\nnewly installed FACTS devices but also other already existing flexible degrees\nof freedom. This complex optimization problem is stated using the most general\nAC Power Flows. Non-linear, non-convex, multiple-scenario and multi-time-frame\noptimization is resolved via efficient heuristics, consisting of a sequence of\nalternating Linear Programmings or Quadratic Programmings (depending on the\ngeneration cost) and AC-PF solution steps designed to maintain operational\nfeasibility for all scenarios. Computational scalability and application of the\nnewly developed approach is illustrated on the example of the 2736-nodes large\nPolish system. One most important advantage of the framework is that the\noptimal capacity of FACTS is build up gradually at each time frame in a limited\nnumber of locations, thus allowing to prepare the system better for possible\ncongestion due to future economic and other uncertainties. \n\n"}
{"id": "1707.04268", "contents": "Title: Linear complementarity problems on extended second order cones Abstract: In this paper, we study the linear complementarity problems on extended\nsecond order cones. We convert a linear complementarity problem on an extended\nsecond order cone into a mixed complementarity problem on the non-negative\northant. We state necessary and sufficient conditions for a point to be a\nsolution of the converted problem. We also present solution strategies for this\nproblem, such as the Newton method and Levenberg-Marquardt algorithm. Finally,\nwe present some numerical examples. \n\n"}
{"id": "1707.07112", "contents": "Title: Switching and Data Injection Attacks on Stochastic Cyber-Physical\n  Systems: Modeling, Resilient Estimation and Attack Mitigation Abstract: In this paper, we consider the problem of attack-resilient state estimation,\nthat is to reliably estimate the true system states despite two classes of\nattacks: (i) attacks on the switching mechanisms and (ii) false data injection\nattacks on actuator and sensor signals, in the presence of unbounded stochastic\nprocess and measurement noise signals. We model the systems under attack as\nhidden mode stochastic switched linear systems with unknown inputs and propose\nthe use of a multiple-model inference algorithm to tackle these security\nissues. Moreover, we characterize fundamental limitations to resilient\nestimation (e.g., upper bound on the number of tolerable signal attacks) and\ndiscuss the topics of attack detection, identification and mitigation under\nthis framework. Simulation examples of switching and false data injection\nattacks on a benchmark system and an IEEE 68-bus test system show the efficacy\nof our approach to recover resilient (i.e., asymptotically unbiased) state\nestimates as well as to identify and mitigate the attacks. \n\n"}
{"id": "1707.07349", "contents": "Title: Stability and instability in saddle point dynamics -- Part I Abstract: We consider the problem of convergence to a saddle point of a concave-convex\nfunction via gradient dynamics. Since first introduced by Arrow, Hurwicz and\nUzawa in [1] such dynamics have been extensively used in diverse areas, there\nare, however, features that render their analysis non trivial. These include\nthe lack of convergence guarantees when the function considered is not strictly\nconcave-convex and also the non-smoothness of subgradient dynamics. Our aim in\nthis two part paper is to provide an explicit characterization to the\nasymptotic behaviour of general gradient and subgradient dynamics applied to a\ngeneral concave-convex function. We show that despite the nonlinearity and\nnon-smoothness of these dynamics their $\\omega$-limit set is comprised of\ntrajectories that solve only explicit linear ODEs that are characterized within\nthe paper.\n  More precisely, in Part I an exact characterization is provided to the\nasymptotic behaviour of unconstrained gradient dynamics. We also show that when\nconvergence to a saddle point is not guaranteed then the system behaviour can\nbe problematic, with arbitrarily small noise leading to an unbounded variance.\nIn Part II we consider a general class of subgradient dynamics that restrict\ntrajectories in an arbitrary convex domain, and show that when an equilibrium\npoint exists their limiting trajectories are solutions of subgradient dynamics\non only affine subspaces. The latter is a smooth class of dynamics with an\nasymptotic behaviour exactly characterized in Part I, as solutions to explicit\nlinear ODEs. These results are used to formulate corresponding convergence\ncriteria and are demonstrated with several examples and applications presented\nin Part II. \n\n"}
{"id": "1707.07351", "contents": "Title: Stability and instability in saddle point dynamics Part II: The\n  subgradient method Abstract: In part I we considered the problem of convergence to a saddle point of a\nconcave-convex function via gradient dynamics and an exact characterization was\ngiven to their asymptotic behaviour. In part II we consider a general class of\nsubgradient dynamics that provide a restriction in an arbitrary convex domain.\nWe show that despite the nonlinear and non-smooth character of these dynamics\ntheir $\\omega$-limit set is comprised of solutions to only linear ODEs. In\nparticular, we show that the latter are solutions to subgradient dynamics on\naffine subspaces which is a smooth class of dynamics the asymptotic properties\nof which have been exactly characterized in part I. Various convergence\ncriteria are formulated using these results and several examples and\napplications are also discussed throughout the manuscript. \n\n"}
{"id": "1707.08055", "contents": "Title: On the Exponential Rate of Convergence of Fictitious Play in Potential\n  Games Abstract: The paper studies fictitious play (FP) learning dynamics in continuous time.\nIt is shown that in almost every potential game, and for almost every initial\ncondition, the rate of convergence of FP is exponential. In particular, the\npaper focuses on studying the behavior of FP in potential games in which all\nequilibria of the game are regular, as introduced by Harsanyi. Such games are\nreferred to as regular potential games. Recently it has been shown that almost\nall potential games (in the sense of the Lebesgue measure) are regular. In this\npaper it is shown that in any regular potential game (and hence, in almost\nevery potential game), FP converges to the set of Nash equilibria at an\nexponential rate from almost every initial condition. \n\n"}
{"id": "1707.09169", "contents": "Title: An application of proof mining to the proximal point algorithm in CAT(0)\n  spaces Abstract: We compute, using techniques originally introduced by Kohlenbach, the first\nauthor and Nicolae, uniform rates of metastability for the proximal point\nalgorithm in the context of CAT(0) spaces (as first considered by Bacak),\nspecifically for the case where the ambient space is totally bounded. This\nresult is part of the program of proof mining, which aims to apply methods of\nmathematical logic with the purpose of extracting quantitative information out\nof ordinary mathematical proofs, which may not be necessarily constructive. \n\n"}
{"id": "1707.09676", "contents": "Title: Model-Free Renewable Scenario Generation Using Generative Adversarial\n  Networks Abstract: Scenario generation is an important step in the operation and planning of\npower systems with high renewable penetrations. In this work, we proposed a\ndata-driven approach for scenario generation using generative adversarial\nnetworks, which is based on two interconnected deep neural networks. Compared\nwith existing methods based on probabilistic models that are often hard to\nscale or sample from, our method is data-driven, and captures renewable energy\nproduction patterns in both temporal and spatial dimensions for a large number\nof correlated resources. For validation, we use wind and solar times-series\ndata from NREL integration data sets. We demonstrate that the proposed method\nis able to generate realistic wind and photovoltaic power profiles with full\ndiversity of behaviors. We also illustrate how to generate scenarios based on\ndifferent conditions of interest by using labeled data during training. For\nexample, scenarios can be conditioned on weather events~(e.g. high wind day) or\ntime of the year~(e,g. solar generation for a day in July). Because of the\nfeedforward nature of the neural networks, scenarios can be generated extremely\nefficiently without sophisticated sampling techniques. \n\n"}
{"id": "1708.00475", "contents": "Title: An Inexact Regularized Newton Framework with a Worst-Case Iteration\n  Complexity of $\\mathcal{O}(\\epsilon^{-3/2})$ for Nonconvex Optimization Abstract: An algorithm for solving smooth nonconvex optimization problems is proposed\nthat, in the worst-case, takes $\\mathcal{O}(\\epsilon^{-3/2})$ iterations to\ndrive the norm of the gradient of the objective function below a prescribed\npositive real number $\\epsilon$ and can take $\\mathcal{O}(\\epsilon^{-3})$\niterations to drive the leftmost eigenvalue of the Hessian of the objective\nabove $-\\epsilon$. The proposed algorithm is a general framework that covers a\nwide range of techniques including quadratically and cubically regularized\nNewton methods, such as the Adaptive Regularisation using Cubics (ARC) method\nand the recently proposed Trust-Region Algorithm with Contractions and\nExpansions (TRACE). The generality of our method is achieved through the\nintroduction of generic conditions that each trial step is required to satisfy,\nwhich in particular allow for inexact regularized Newton steps to be used.\nThese conditions center around a new subproblem that can be approximately\nsolved to obtain trial steps that satisfy the conditions. A new instance of the\nframework, distinct from ARC and TRACE, is described that may be viewed as a\nhybrid between quadratically and cubically regularized Newton methods.\nNumerical results demonstrate that our hybrid algorithm outperforms a cublicly\nregularized Newton method. \n\n"}
{"id": "1708.01544", "contents": "Title: Log-barrier interior point methods are not strongly polynomial Abstract: We prove that primal-dual log-barrier interior point methods are not strongly\npolynomial, by constructing a family of linear programs with $3r+1$\ninequalities in dimension $2r$ for which the number of iterations performed is\nin $\\Omega(2^r)$. The total curvature of the central path of these linear\nprograms is also exponential in $r$, disproving a continuous analogue of the\nHirsch conjecture proposed by Deza, Terlaky and Zinchenko. Our method is to\ntropicalize the central path in linear programming. The tropical central path\nis the piecewise-linear limit of the central paths of parameterized families of\nclassical linear programs viewed through logarithmic glasses. This allows us to\nprovide combinatorial lower bounds for the number of iterations and the total\ncurvature, in a general setting. \n\n"}
{"id": "1708.01690", "contents": "Title: Efficient Rank Minimization to Tighten Semidefinite Programming for\n  Unconstrained Binary Quadratic Optimization Abstract: We propose a method for low-rank semidefinite programming in application to\nthe semidefinite relaxation of unconstrained binary quadratic problems. The\nmethod improves an existing solution of the semidefinite programming relaxation\nto achieve a lower rank solution. This procedure is computationally efficient\nas it does not require projecting on the cone of positive-semidefinite\nmatrices. Its performance in terms of objective improvement and rank reduction\nis tested over multiple graphs of large-scale Gset graph collection and over\nbinary optimization problems from the Biq Mac collection. \n\n"}
{"id": "1708.02192", "contents": "Title: Dynamic Programming Principles for Optimal Stopping with Expectation\n  Constraint Abstract: We analyze an optimal stopping problem with a constraint on the expected\ncost. When the reward function and cost function are Lipschitz continuous in\nstate variable, we show that the value of such an optimal stopping problem is a\ncontinuous function in current state and in budget level. Then we derive a\ndynamic programming principle (DPP) for the value function in which the\nconditional expected cost acts as an additional state process. As the optimal\nstopping problem with expectation constraint can be transformed to a stochastic\noptimization problem with supermartingale controls, we explore a second DPP of\nthe value function and thus resolve an open question recently raised in [S.\nAnkirchner, M. Klein, and T. Kruse, A verification theorem for optimal stopping\nproblems with expectation constraints, Appl. Math. Optim., 2017, pp. 1-33].\nBased on these two DPPs, we characterize the value function as a viscosity\nsolution to the related fully non-linear parabolic Hamilton-Jacobi-Bellman\nequation. \n\n"}
{"id": "1708.03277", "contents": "Title: On the convergence rate of distributed gradient methods for finite-sum\n  optimization under communication delays Abstract: Motivated by applications in machine learning and statistics, we study\ndistributed optimization problems over a network of processors, where the goal\nis to optimize a global objective composed of a sum of local functions. In\nthese problems, due to the large scale of the data sets, the data and\ncomputation must be distributed over processors resulting in the need for\ndistributed algorithms. In this paper, we consider a popular distributed\ngradient-based consensus algorithm, which only requires local computation and\ncommunication. An important problem in this area is to analyze the convergence\nrate of such algorithms in the presence of communication delays that are\ninevitable in distributed systems. We prove the convergence of the\ngradient-based consensus algorithm in the presence of uniform, but possibly\narbitrarily large, communication delays between the processors. Moreover, we\nobtain an upper bound on the rate of convergence of the algorithm as a function\nof the network size, topology, and the inter-processor communication delays. \n\n"}
{"id": "1708.03549", "contents": "Title: Dynamic controllers for column synchronization of rotation matrices: a\n  QR-factorization approach Abstract: In the multi-agent systems setting, this paper addresses continuous-time\ndistributed synchronization of columns of rotation matrices. More precisely, k\nspecific columns shall be synchronized and only the corresponding k columns of\nthe relative rotations between the agents are assumed to be available for the\ncontrol design. When one specific column is considered, the problem is\nequivalent to synchronization on the (d-1)-dimensional unit sphere and when all\nthe columns are considered, the problem is equivalent to synchronization on\nSO(d). We design dynamic control laws for these synchronization problems. The\ncontrol laws are based on the introduction of auxiliary variables in\ncombination with a QR-factorization approach. The benefit of this\nQR-factorization approach is that we can decouple the dynamics for the k\ncolumns from the remaining d-k ones. Under the control scheme, the closed loop\nsystem achieves almost global convergence to synchronization for quasi-strong\ninteraction graph topologies. \n\n"}
{"id": "1708.03981", "contents": "Title: PSSE Redux: Convex Relaxation, Decentralized, Robust, and Dynamic\n  Approaches Abstract: This chapter aspires to glean some of the recent advances in power system\nstate estimation (PSSE), though our collection is not exhaustive by any means.\nThe Cram{\\'e}r-Rao bound, a lower bound on the (co)variance of any unbiased\nestimator, is first derived for the PSSE setup. After reviewing the classical\nGauss-Newton iterations, contemporary PSSE solvers leveraging relaxations to\nconvex programs and successive convex approximations are explored. A\ndisciplined paradigm for distributed and decentralized schemes is subsequently\nexemplified under linear(ized) and exact grid models. Novel bad data processing\nmodels and fresh perspectives linking critical measurements to cyber-attacks on\nthe state estimator are presented. Finally, spurred by advances in online\nconvex optimization, model-free and model-based state trackers are reviewed. \n\n"}
{"id": "1708.07190", "contents": "Title: Decentralized Computation of Effective Resistances and Acceleration of\n  Consensus Algorithms Abstract: The effective resistance between a pair of nodes in a weighted undirected\ngraph is defined as the potential difference induced between them when a unit\ncurrent is injected at the first node and extracted at the second node,\ntreating edge weights as the conductance values of edges. The effective\nresistance is a key quantity of interest in many applications and fields\nincluding solving linear systems, Markov Chains and continuous-time averaging\nnetworks. We develop an efficient linearly convergent distributed algorithm for\ncomputing effective resistances and demonstrate its performance through\nnumerical studies. We also apply our algorithm to the consensus problem where\nthe aim is to compute the average of node values in a distributed manner. We\nshow that the distributed algorithm we developed for effective resistances can\nbe used to accelerate the convergence of the classical consensus iterations\nconsiderably by a factor depending on the network structure. \n\n"}
{"id": "1708.07620", "contents": "Title: Fenchel Dual Gradient Methods for Distributed Convex Optimization over\n  Time-varying Networks Abstract: In the large collection of existing distributed algorithms for convex\nmulti-agent optimization, only a handful of them provide convergence rate\nguarantees on agent networks with time-varying topologies, which, however,\nrestrict the problem to be unconstrained. Motivated by this, we develop a\nfamily of distributed Fenchel dual gradient methods for solving constrained,\nstrongly convex but not necessarily smooth multi-agent optimization problems\nover time-varying undirected networks. The proposed algorithms are constructed\nbased on the application of weighted gradient methods to the Fenchel dual of\nthe multi-agent optimization problem, and can be implemented in a fully\ndecentralized fashion. We show that the proposed algorithms drive all the\nagents to both primal and dual optimality asymptotically under a minimal\nconnectivity condition and at sublinear rates under a standard connectivity\ncondition. Finally, the competent convergence performance of the distributed\nFenchel dual gradient methods is demonstrated via simulations. \n\n"}
{"id": "1709.00106", "contents": "Title: First and Second Order Methods for Online Convolutional Dictionary\n  Learning Abstract: Convolutional sparse representations are a form of sparse representation with\na structured, translation invariant dictionary. Most convolutional dictionary\nlearning algorithms to date operate in batch mode, requiring simultaneous\naccess to all training images during the learning process, which results in\nvery high memory usage and severely limits the training data that can be used.\nVery recently, however, a number of authors have considered the design of\nonline convolutional dictionary learning algorithms that offer far better\nscaling of memory and computational cost with training set size than batch\nmethods. This paper extends our prior work, improving a number of aspects of\nour previous algorithm; proposing an entirely new one, with better performance,\nand that supports the inclusion of a spatial mask for learning from incomplete\ndata; and providing a rigorous theoretical analysis of these methods. \n\n"}
{"id": "1709.00537", "contents": "Title: Communication-efficient Algorithm for Distributed Sparse Learning via\n  Two-way Truncation Abstract: We propose a communicationally and computationally efficient algorithm for\nhigh-dimensional distributed sparse learning. At each iteration, local machines\ncompute the gradient on local data and the master machine solves one shifted\n$l_1$ regularized minimization problem. The communication cost is reduced from\nconstant times of the dimension number for the state-of-the-art algorithm to\nconstant times of the sparsity number via Two-way Truncation procedure.\nTheoretically, we prove that the estimation error of the proposed algorithm\ndecreases exponentially and matches that of the centralized method under mild\nassumptions. Extensive experiments on both simulated data and real data verify\nthat the proposed algorithm is efficient and has performance comparable with\nthe centralized method on solving high-dimensional sparse learning problems. \n\n"}
{"id": "1709.01307", "contents": "Title: Distributed second order methods with increasing number of working nodes Abstract: Recently, an idling mechanism has been introduced in the context of\ndistributed \\emph{first order} methods for minimization of a sum of nodes'\nlocal convex costs over a generic, connected network. With the idling\nmechanism, each node $i$, at each iteration $k$, is active -- updates its\nsolution estimate and exchanges messages with its network neighborhood -- with\nprobability $p_k$, and it stays idle with probability $1-p_k$, while the\nactivations are independent both across nodes and across iterations. In this\npaper, we demonstrate that the idling mechanism can be successfully\nincorporated in \\emph{distributed second order methods} also. Specifically, we\napply the idling mechanism to the recently proposed Distributed Quasi Newton\nmethod (DQN). We first show theoretically that, when $p_k$ grows to one across\niterations in a controlled manner, DQN with idling exhibits very similar\ntheoretical convergence and convergence rates properties as the standard DQN\nmethod, thus achieving the same order of convergence rate (R-linear) as the\nstandard DQN, but with significantly cheaper updates. Simulation examples\nconfirm the benefits of incorporating the idling mechanism, demonstrate the\nmethod's flexibility with respect to the choice of the $p_k$'s, and compare the\nproposed idling method with related algorithms from the literature. \n\n"}
{"id": "1709.01670", "contents": "Title: Parameterized complexity of machine scheduling: 15 open problems Abstract: Machine scheduling problems are a long-time key domain of algorithms and\ncomplexity research. A novel approach to machine scheduling problems are\nfixed-parameter algorithms. To stimulate this thriving research direction, we\npropose 15 open questions in this area whose resolution we expect to lead to\nthe discovery of new approaches and techniques both in scheduling and\nparameterized complexity theory. \n\n"}
{"id": "1709.01905", "contents": "Title: Nonzero-sum games of optimal stopping and generalised Nash equilibrium Abstract: In the nonzero-sum setting, we establish a connection between Nash equilibria\nin games of optimal stopping (Dynkin games) and generalised Nash equilibrium\nproblems (GNEP). In the Dynkin game this reveals novel equilibria of threshold\ntype and of more complex types, and leads to novel uniqueness and stability\nresults. \n\n"}
{"id": "1709.02117", "contents": "Title: Metric methods for heteroclinic connections in infinite dimensional\n  spaces Abstract: We consider the minimal action problem min \\int\\_R 1/2 |$\\gamma$'|^2 +\nW($\\gamma$) dt among curves lying in a non-locally-compact metric space and\nconnecting two given zeros of W $\\ge$ 0. For this problem, the optimal curves\nare usually called heteroclinic connections. We reduce it, following a standard\nmethod, to a geodesic problem of the form min \\int\\_0^1 K($\\gamma$)|$\\gamma$'|\ndt with K = (2W)^(1/2). We then prove existence of curves minimizing this new\naction under some suitable compactness assumptions on K, which are minimal. The\nmethod allows to solve some PDE problems in unbounded domains, in particular in\ntwo variables x, y, when y = t and when the metric space is an L^2 space in the\nfirst variable x, and the potential W includes a Dirichlet energy in the same\nvariable. We then apply this technique to the problem of connecting, in a\nfunctional space, two different heteroclinic connections between two points of\nthe Euclidean space, as it was previously studied by Alama-Bronsard-Gui and by\nSchatzman more than fifteen years ago. With a very different technique, we are\nable to recover the same results, and to weaken some assumptions. \n\n"}
{"id": "1709.02593", "contents": "Title: On quasi-stationary Mean Field Games models Abstract: We explore a mechanism of decision-making in Mean Field Games with myopic\nplayers. At each instant, agents set a strategy which optimizes their expected\nfuture cost by assuming their environment as immutable. As the system evolves,\nthe players observe the evolution of the system and adapt to their new\nenvironment without anticipating. With a specific cost structures, these models\ngive rise to coupled systems of partial differential equations of\nquasi-stationary nature. We provide sufficient conditions for the existence and\nuniqueness of classical solutions for these systems, and give a rigorous\nderivation of these systems from N-players stochastic differential games\nmodels. Finally, we show that the population can self-organize and converge\nexponentially fast to the ergodic Mean Field Games equilibrium, if the initial\ndistribution is sufficiently close to it and the Hamiltonian is quadratic. \n\n"}
{"id": "1709.02726", "contents": "Title: A Modular Analysis of Adaptive (Non-)Convex Optimization: Optimism,\n  Composite Objectives, and Variational Bounds Abstract: Recently, much work has been done on extending the scope of online learning\nand incremental stochastic optimization algorithms. In this paper we contribute\nto this effort in two ways: First, based on a new regret decomposition and a\ngeneralization of Bregman divergences, we provide a self-contained, modular\nanalysis of the two workhorses of online learning: (general) adaptive versions\nof Mirror Descent (MD) and the Follow-the-Regularized-Leader (FTRL) algorithms.\nThe analysis is done with extra care so as not to introduce assumptions not\nneeded in the proofs and allows to combine, in a straightforward way, different\nalgorithmic ideas (e.g., adaptivity, optimism, implicit updates) and learning\nsettings (e.g., strongly convex or composite objectives). This way we are able\nto reprove, extend and refine a large body of the literature, while keeping the\nproofs concise. The second contribution is a byproduct of this careful\nanalysis: We present algorithms with improved variational bounds for smooth,\ncomposite objectives, including a new family of optimistic MD algorithms with\nonly one projection step per round. Furthermore, we provide a simple extension\nof adaptive regret bounds to practically relevant non-convex problem settings\nwith essentially no extra effort. \n\n"}
{"id": "1709.03374", "contents": "Title: When to arrive at a queue with earliness, tardiness and waiting costs Abstract: We consider a queueing facility where customers decide when to arrive. All\ncustomers have the same desired arrival time (w.l.o.g.\\ time zero). There is\none server, and the service times are independent and exponentially\ndistributed. The total number of customers that demand service is random, and\nfollows the Poisson distribution. Each customer wishes to minimize the sum of\nthree costs: earliness, tardiness and waiting. We assume that all three costs\nare linear with time and are defined as follows. Earliness is the time between\narrival and time zero, if there is any. Tardiness is simply the time of\nentering service, if it is after time zero. Waiting time is the time from\narrival until entering service. We focus on customers' rational behaviour,\nassuming that each customer wants to minimize his total cost, and in\nparticular, we seek a symmetric Nash equilibrium strategy. We show that such a\nstrategy is mixed, unless trivialities occur. We construct a set of equations\nthat its solution provides the symmetric Nash equilibrium. The solution is a\ncontinuous distribution on the real line. We also compare the socially optimal\nsolution (that is, the one that minimizes total cost across all customers) to\nthe overall cost resulting from the Nash equilibrium. \n\n"}
{"id": "1709.03892", "contents": "Title: Optimal velocity control of a convective Cahn-Hilliard system with\n  double obstacles and dynamic boundary conditions: a `deep quench' approach Abstract: In this paper, we investigate a distributed optimal control problem for a\nconvective viscous Cahn-Hilliard system with dynamic boundary conditions. Such\nsystems govern phase separation processes between two phases taking place in an\nincompressible fluid in a container and, at the same time, on the container\nboundary. The cost functional is of standard tracking type, while the control\nis exerted by the velocity of the fluid in the bulk. In this way, the coupling\nbetween the state (given by the associated order parameter and chemical\npotential) and control variables in the governing system of nonlinear partial\ndifferential equations is bilinear, which presents a difficulty for the\nanalysis. In contrast to the previous paper arXiv:1709.02335 [math.AP] by the\nsame authors, the bulk and surface free energies are of double obstacle type,\nwhich renders the state constraint nondifferentiable. It is well known that for\nsuch cases standard constraint qualifications are not satisfied so that\nstandard methods do not apply to yield the existence of Lagrange multipliers.\nIn this paper, we overcome this difficulty by taking advantage of results\nestablished in the quoted paper for logarithmic nonlinearities, using a\nso-called `deep quench approximation'. We derive results concerning the\nexistence of optimal controls and the first-order necessary optimality\nconditions in terms of a variational inequality and the associated adjoint\nsystem. \n\n"}
{"id": "1709.03962", "contents": "Title: A first-order splitting method for solving a large-scale composite\n  convex optimization problem Abstract: The forward-backward operator splitting algorithm is one of the most\nimportant methods for solving the optimization problem of the sum of two convex\nfunctions, where one is differentiable with a Lipschitz continuous gradient and\nthe other is possibly nonsmooth but proximable. It is convenient to solve some\noptimization problems in the form of dual or primal-dual problems. Both methods\nare mature in theory. In this paper, we construct several efficient first-order\nsplitting algorithms for solving a multi-block composite convex optimization\nproblem. The objective function includes a smooth function with a Lipschitz\ncontinuous gradient, a proximable convex function that may be nonsmooth, and a\nfinite sum of a composition of a proximable function and a bounded linear\noperator. To solve such an optimization problem, we transform it into the sum\nof three convex functions by defining an appropriate inner product space. On\nthe basis of the dual forward-backward splitting algorithm and the primal-dual\nforward-backward splitting algorithm, we develop several iterative algorithms\nthat involve only computing the gradient of the differentiable function and\nproximity operators of related convex functions. These iterative algorithms are\nmatrix-inversion-free and completely splitting algorithms. Finally, we employ\nthe proposed iterative algorithms to solve a regularized general prior image\nconstrained compressed sensing (PICCS) model that is derived from computed\ntomography (CT) image reconstruction under sparse sampling of projection\nmeasurements. Numerical results show that the proposed iterative algorithms\noutperform other algorithms. \n\n"}
{"id": "1709.04221", "contents": "Title: Policy Evaluation in Continuous MDPs with Efficient Kernelized Gradient\n  Temporal Difference Abstract: We consider policy evaluation in infinite-horizon discounted Markov decision\nproblems (MDPs) with infinite spaces. We reformulate this task a compositional\nstochastic program with a function-valued decision variable that belongs to a\nreproducing kernel Hilbert space (RKHS). We approach this problem via a new\nfunctional generalization of stochastic quasi-gradient methods operating in\ntandem with stochastic sparse subspace projections. The result is an extension\nof gradient temporal difference learning that yields nonlinearly parameterized\nvalue function estimates of the solution to the Bellman evaluation equation.\nOur main contribution is a memory-efficient non-parametric stochastic method\nguaranteed to converge exactly to the Bellman fixed point with probability $1$\nwith attenuating step-sizes. Further, with constant step-sizes, we obtain mean\nconvergence to a neighborhood and that the value function estimates have finite\ncomplexity. In the Mountain Car domain, we observe faster convergence to lower\nBellman error solutions than existing approaches with a fraction of the\nrequired memory. \n\n"}
{"id": "1709.04718", "contents": "Title: The Impact of Local Geometry and Batch Size on Stochastic Gradient\n  Descent for Nonconvex Problems Abstract: In several experimental reports on nonconvex optimization problems in machine\nlearning, stochastic gradient descent (SGD) was observed to prefer minimizers\nwith flat basins in comparison to more deterministic methods, yet there is very\nlittle rigorous understanding of this phenomenon. In fact, the lack of such\nwork has led to an unverified, but widely-accepted stochastic mechanism\ndescribing why SGD prefers flatter minimizers to sharper minimizers. However,\nas we demonstrate, the stochastic mechanism fails to explain this phenomenon.\nHere, we propose an alternative deterministic mechanism that can accurately\nexplain why SGD prefers flatter minimizers to sharper minimizers. We derive\nthis mechanism based on a detailed analysis of a generic stochastic quadratic\nproblem, which generalizes known results for classical gradient descent.\nFinally, we verify the predictions of our deterministic mechanism on two\nnonconvex problems. \n\n"}
{"id": "1709.05380", "contents": "Title: The Uncertainty Bellman Equation and Exploration Abstract: We consider the exploration/exploitation problem in reinforcement learning.\nFor exploitation, it is well known that the Bellman equation connects the value\nat any time-step to the expected value at subsequent time-steps. In this paper\nwe consider a similar \\textit{uncertainty} Bellman equation (UBE), which\nconnects the uncertainty at any time-step to the expected uncertainties at\nsubsequent time-steps, thereby extending the potential exploratory benefit of a\npolicy beyond individual time-steps. We prove that the unique fixed point of\nthe UBE yields an upper bound on the variance of the posterior distribution of\nthe Q-values induced by any policy. This bound can be much tighter than\ntraditional count-based bonuses that compound standard deviation rather than\nvariance. Importantly, and unlike several existing approaches to optimism, this\nmethod scales naturally to large systems with complex generalization.\nSubstituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN\nperformance on 51 out of 57 games in the Atari suite. \n\n"}
{"id": "1709.05850", "contents": "Title: Dual Prediction-Correction Methods for Linearly Constrained Time-Varying\n  Convex Programs Abstract: Devising efficient algorithms to solve continuously-varying strongly convex\noptimization programs is key in many applications, from control systems to\nsignal processing and machine learning. In this context, solving means to find\nand track the optimizer trajectory of the continuously-varying convex\noptimization program. Recently, a novel prediction-correction methodology has\nbeen put forward to set up iterative algorithms that sample the\ncontinuously-varying optimization program at discrete time steps and perform a\nlimited amount of computations to correct their approximate optimizer with the\nnew sampled problem and predict how the optimizer will change at the next time\nstep. Prediction-correction algorithms have been shown to outperform more\nclassical strategies, i.e., correction-only methods. Typically,\nprediction-correction methods have asymptotic tracking errors of the order of\n$h^2$, where $h$ is the sampling period, whereas classical strategies have\norder of $h$. Up to now, Prediction-correction algorithms have been developed\nin the primal space, both for unconstrained and simply constrained convex\nprograms. In this paper, we show how to tackle linearly constrained\ncontinuously-varying problem by prediction-correction in the dual space and we\nprove similar asymptotic error bounds as their primal versions. \n\n"}
{"id": "1709.06466", "contents": "Title: Evaluation of the Rate of Convergence in the PIA Abstract: Folklore says that Howard's Policy Improvement Algorithm converges\nextraordinarily fast, even for controlled diffusion settings.\n  In a previous paper, we proved that approximations of the solution of a\nparticular parabolic partial differential equation obtained via the policy\nimprovement algorithm show a quadratic local convergence.\n  In this paper, we show that we obtain the same rate of convergence of the\nalgorithm in a more general setup. This provides some explanation as to why the\nalgorithm converges fast.\n  We provide an example by solving a semilinear elliptic partial differential\nequation numerically by applying the algorithm and check how the approximations\nconverge to the analytic solution. \n\n"}
{"id": "1709.06679", "contents": "Title: Controllability and data-driven identification of bipartite consensus on\n  nonlinear signed networks Abstract: Nonlinear networked systems are of interest in several areas of research,\nsuch as multi-agent systems and social networks. In this paper, we examine the\ncontrollability of several classes of nonlinear networked dynamics on which the\nunderlying graph admits negative weights. Such signed networks exhibit\nbipartite clustering when the underlying graph is structurally balanced. We\nshow that structural balance is the key ingredient inducing uncontrollability\nwhen combined with a leader-node symmetry and a certain type of dynamical\nsymmetry. We then examine the problem of extracting the bipartite structure of\nsuch graphs from data using Extended Dynamic Mode Decomposition to approximate\nthe corresponding Koopman operator. \n\n"}
{"id": "1709.07379", "contents": "Title: Distributed Submodular Minimization And Motion Coordination Over\n  Discrete State Space Abstract: We develop a framework for the distributed minimization of submodular\nfunctions. Submodular functions are a discrete analog of convex functions and\nare extensively used in large-scale combinatorial optimization problems. While\nthere has been significant interest in the distributed formulations of convex\noptimization problems, distributed minimization of submodular functions has\nreceived relatively little research attention. Our framework relies on an\nequivalent convex reformulation of a submodular minimization problem, which is\nefficiently computable. We then use this relaxation to exploit methods for the\ndistributed optimization of convex functions. The proposed framework is\napplicable to submodular set functions as well as to a wider class of\nsubmodular functions defined over certain lattices. We also propose an approach\nfor solving distributed motion coordination problems in discrete state space\nbased on submodular function minimization. We establish through a challenging\nsetup of capture the flag game that submodular functions over lattices can be\nused to design artificial potential fields over discrete state space in which\nthe agents are attracted towards their goals and are repulsed from obstacles\nand from each other for collision avoidance. \n\n"}
{"id": "1709.09049", "contents": "Title: From a monotone probabilistic scheme to a probabilistic max-plus\n  algorithm for solving Hamilton-Jacobi-Bellman equations Abstract: In a previous work (Akian, Fodjo, 2016), we introduced a lower complexity\nprobabilistic max-plus numerical method for solving fully nonlinear\nHamilton-Jacobi-Bellman equations associated to diffusion control problems\ninvolving a finite set-valued (or switching) control and possibly a\ncontinuum-valued control. This method was based on the idempotent expansion\nproperties obtained by McEneaney, Kaise and Han (2011) and on the numerical\nprobabilistic method proposed by Fahim, Touzi and Warin (2011) for solving some\nfully nonlinear parabolic partial differential equations. A difficulty of the\nalgorithm of Fahim, Touzi and Warin is in the critical constraints imposed on\nthe Hamiltonian to ensure the monotonicity of the scheme, hence the convergence\nof the algorithm. Here, we propose a new \"probabilistic scheme\" which is\nmonotone under rather weak assumptions, including the case of strongly elliptic\nPDE with bounded coefficients. This allows us to apply our probabilistic\nmax-plus method in more general situations. We illustrate this on the\nevaluation of the superhedging price of an option under uncertain correlation\nmodel with several underlying stocks and changing sign cross gamma, and\nconsider in particular the case of 5 stocks leading to a PDE in dimension 5. \n\n"}
{"id": "1709.09642", "contents": "Title: On the Circuit Diameter of some Combinatorial Polytopes Abstract: The combinatorial diameter of a polytope $P$ is the maximum value of a\nshortest path between two vertices of $P$, where the path uses the edges of $P$\nonly. In contrast to the combinatorial diameter, the circuit diameter of $P$ is\ndefined as the maximum value of a shortest path between two vertices of $P$,\nwhere the path uses potential edge directions of $P$ i.e., all edge directions\nthat can arise by translating some of the facets of $P$.\n  In this paper, we study the circuit diameter of polytopes corresponding to\nclassical combinatorial optimization problems, such as the Matching polytope,\nthe Traveling Salesman polytope and the Fractional Stable Set polytope. \n\n"}
{"id": "1709.10345", "contents": "Title: Control of Time-Varying Epidemic-Like Stochastic Processes and Their\n  Mean-Field Limits Abstract: The optimal control of epidemic-like stochastic processes is important both\nhistorically and for emerging applications today, where it can be especially\nimportant to include time-varying parameters that impact viral epidemic-like\npropagation. We connect the control of such stochastic processes with\ntime-varying behavior to the stochastic shortest path problem and obtain\nsolutions for various cost functions. Then, under a mean-field scaling, this\ngeneral class of stochastic processes is shown to converge to a corresponding\ndynamical system. We analogously establish that the optimal control of this\nclass of processes converges to the optimal control of the limiting dynamical\nsystem. Consequently, we study the optimal control of the dynamical system\nwhere the comparison of both controlled systems renders various important\nmathematical properties of interest. \n\n"}
{"id": "1709.10485", "contents": "Title: Designing Real-Time Prices to Reduce Load Variability with HVAC Abstract: Utilities use demand response to shift or reduce electricity usage of\nflexible loads, to better match electricity demand to power generation. A\ncommon mechanism is peak pricing (PP), where consumers pay reduced (increased)\nprices for electricity during periods of low (high) demand, and its simplicity\nallows consumers to understand how their consumption affects costs. However,\nnew consumer technologies like internet-connected smart thermostats simplify\nreal-time pricing (RP), because such devices can automate the tradeoff between\ncosts and consumption. These devices enable consumer choice under RP by\nabstracting this tradeoff into a question of quality of service (e.g., comfort)\nversus price. This paper uses a principal-agent framework to design PP and RP\nrates for heating, ventilation, and air-conditioning (HVAC) to address adverse\nselection due to variations in consumer comfort preferences. We formulate the\npricing problem as a stochastic bilevel program, and numerically solve it by\nreformulation as a mixed integer program (MIP). Last, we compare the\neffectiveness of different pricing schemes on reductions of peak load or load\nvariability. We find that PP pricing induces HVAC consumption to spike high\n(before), spike low (during), and spike high (after) the PP event, whereas RP\nachieves reductions in peak loads and load variability while preventing large\nspikes in electricity usage. \n\n"}
{"id": "1710.00194", "contents": "Title: Where computer vision can aid physics: dynamic cloud motion forecasting\n  from satellite images Abstract: This paper describes a new algorithm for solar energy forecasting from a\nsequence of Cloud Optical Depth (COD) images. The algorithm is based on the\nfollowing simple observation: the dynamics of clouds represented by COD images\nresembles the motion (transport) of a density in a fluid flow. This suggests\nthat, to forecast the motion of COD images, it is sufficient to forecast the\nflow. The latter, in turn, can be accomplished by fitting a parametric model of\nthe fluid flow to the COD images observed in the past. Namely, the learning\nphase of the algorithm is composed of the following steps: (i) given a sequence\nof COD images, the snapshots of the optical flow are estimated from two\nconsecutive COD images; (ii) these snapshots are then assimilated into a\nNavier-Stokes Equation (NSE), i.e. an initial velocity field for NSE is\nselected so that the corresponding NSE' solution is as close as possible to the\noptical flow snapshots. The prediction phase consists of utilizing a linear\ntransport equation, which describes the propagation of COD images in the fluid\nflow predicted by NSE, to estimate the future motion of the COD images. The\nalgorithm has been tested on COD images provided by two geostationary\noperational environmental satellites from NOAA serving the west-hemisphere. \n\n"}
{"id": "1710.00328", "contents": "Title: The Width and Integer Optimization on Simplices With Bounded Minors of\n  the Constraint Matrices Abstract: In this paper, we will show that the width of simplices defined by systems of\nlinear inequalities can be computed in polynomial time if some minors of their\nconstraint matrices are bounded. Additionally, we present some\nquasi-polynomial-time and polynomial-time algorithms to solve the integer\nlinear optimization problem defined on simplices minus all their integer\nvertices assuming that some minors of the constraint matrices of the simplices\nare bounded. \n\n"}
{"id": "1710.01816", "contents": "Title: Source Coding Optimization for Distributed Average Consensus Abstract: Consensus is a common method for computing a function of the data distributed\namong the nodes of a network. Of particular interest is distributed average\nconsensus, whereby the nodes iteratively compute the sample average of the data\nstored at all the nodes of the network using only near-neighbor communications.\nIn real-world scenarios, these communications must undergo quantization, which\nintroduces distortion to the internode messages. In this thesis, a model for\nthe evolution of the network state statistics at each iteration is developed\nunder the assumptions of Gaussian data and additive quantization error. It is\nshown that minimization of the communication load in terms of aggregate source\ncoding rate can be posed as a generalized geometric program, for which an\nequivalent convex optimization can efficiently solve for the global minimum.\nOptimization procedures are developed for rate-distortion-optimal vector\nquantization, uniform entropy-coded scalar quantization, and fixed-rate uniform\nquantization. Numerical results demonstrate the performance of these\napproaches. For small numbers of iterations, the fixed-rate optimizations are\nverified using exhaustive search. Comparison to the prior art suggests\ncompetitive performance under certain circumstances but strongly motivates the\nincorporation of more sophisticated coding strategies, such as differential,\npredictive, or Wyner-Ziv coding. \n\n"}
{"id": "1710.02236", "contents": "Title: Primal-Dual Optimization Algorithms over Riemannian Manifolds: an\n  Iteration Complexity Analysis Abstract: In this paper we study nonconvex and nonsmooth multi-block optimization over\nRiemannian manifolds with coupled linear constraints. Such optimization\nproblems naturally arise from machine learning, statistical learning,\ncompressive sensing, image processing, and tensor PCA, among others. We develop\nan ADMM-like primal-dual approach based on decoupled solvable subroutines such\nas linearized proximal mappings. First, we introduce the optimality conditions\nfor the afore-mentioned optimization models. Then, the notion of\n$\\epsilon$-stationary solutions is introduced as a result. The main part of the\npaper is to show that the proposed algorithms enjoy an iteration complexity of\n$O(1/\\epsilon^2)$ to reach an $\\epsilon$-stationary solution. For prohibitively\nlarge-size tensor or machine learning models, we present a sampling-based\nstochastic algorithm with the same iteration complexity bound in expectation.\nIn case the subproblems are not analytically solvable, a feasible curvilinear\nline-search variant of the algorithm based on retraction operators is proposed.\nFinally, we show specifically how the algorithms can be implemented to solve a\nvariety of practical problems such as the NP-hard maximum bisection problem,\nthe $\\ell_q$ regularized sparse tensor principal component analysis and the\ncommunity detection problem. Our preliminary numerical results show great\npotentials of the proposed methods. \n\n"}
{"id": "1710.03530", "contents": "Title: Cross-Dimensional Linear Systems Abstract: Semi-tensor product(STP) or matrix (M-) product of matrices turns the set of\nmatrices with arbitrary dimensions into a monoid $({\\cal M},\\ltimes)$. A matrix\n(M-) addition is defined over subsets of a partition of ${\\cal M}$, and a\nmatrix (M-) equivalence is proposed. Eventually, some quotient spaces are\nobtained as vector spaces of matrices. Furthermore, a set of formal polynomials\nis constructed, which makes the quotient space of $({\\cal M},\\ltimes)$, denoted\nby $(\\Sigma, \\ltimes)$, a vector space and a monoid.\n  Similarly, a vector addition (V-addition) and a vector equivalence\n(V-equivalence) are defined on ${\\cal V}$, the set of vectors of arbitrary\ndimensions. Then the quotient space of vectors, $\\Omega$, is also obtained as a\nvector space.\n  The action of monoid $({\\cal M},\\ltimes)$ on ${\\cal V}$ (or $(\\Sigma,\n\\ltimes)$ on $\\Omega$) is defined as a vector (V-) product, which becomes a\npseudo-dynamic system, called the cross-dimensional linear system (CDLS). Both\nthe discrete time and the continuous time CDLSs have been investigated. For\ncertain time-invariant case, the solutions (trajectories) are presented.\nFurthermore, the corresponding cross-dimensional linear control systems are\nalso proposed and the controllability and observability are discussed.\n  Both M-product and V-product are generalizations of the conventional matrix\nproduct, that is, when the dimension matching condition required by the\nconventional matrix product is satisfied they coincide with the conventional\nmatrix product. Both M-addition and V-addition are generalizations of\nconventional matrix addition. Hence, the dynamics discussed in this paper is a\ngeneralization of conventional linear system theory. \n\n"}
{"id": "1710.04077", "contents": "Title: Projection and Convolution Operations for Integrally Convex Functions Abstract: This paper considers projection and convolution operations for integrally\nconvex functions, which constitute a fundamental function class in discrete\nconvex analysis. It is shown that the class of integrally convex functions is\nstable under projection, and this is also the case with the subclasses of\nintegrally convex functions satisfying local or global discrete midpoint\nconvexity. As is known in the literature, the convolution of two integrally\nconvex functions may possibly fail to be integrally convex. We show that the\nconvolution of an integrally convex function with a separable convex function\nremains integrally convex. We also point out in terms of examples that the\nsimilar statement is false for integrally convex functions with local or global\ndiscrete midpoint convexity. \n\n"}
{"id": "1710.05080", "contents": "Title: DSCOVR: Randomized Primal-Dual Block Coordinate Algorithms for\n  Asynchronous Distributed Optimization Abstract: Machine learning with big data often involves large optimization models. For\ndistributed optimization over a cluster of machines, frequent communication and\nsynchronization of all model parameters (optimization variables) can be very\ncostly. A promising solution is to use parameter servers to store different\nsubsets of the model parameters, and update them asynchronously at different\nmachines using local datasets. In this paper, we focus on distributed\noptimization of large linear models with convex loss functions, and propose a\nfamily of randomized primal-dual block coordinate algorithms that are\nespecially suitable for asynchronous distributed implementation with parameter\nservers. In particular, we work with the saddle-point formulation of such\nproblems which allows simultaneous data and model partitioning, and exploit its\nstructure by doubly stochastic coordinate optimization with variance reduction\n(DSCOVR). Compared with other first-order distributed algorithms, we show that\nDSCOVR may require less amount of overall computation and communication, and\nless or no synchronization. We discuss the implementation details of the DSCOVR\nalgorithms, and present numerical experiments on an industrial distributed\ncomputing system. \n\n"}
{"id": "1710.05521", "contents": "Title: On the Hybrid Minimum Principle Abstract: The Hybrid Minimum Principle (HMP) is established for the optimal control of\ndeterministic hybrid systems with both autonomous and controlled switchings and\njumps where state jumps at the switching instants are permitted to be\naccompanied by changes in the dimension of the state space. First order\nvariational analysis is performed via the needle variation methodology and the\nnecessary optimality conditions are established in the form of the HMP. A\nfeature of special interest in this work is the explicit presentations of\nboundary conditions on the Hamiltonians and the adjoint processes before and\nafter switchings and jumps. In addition to an analytic example, the HMP results\nare illustrated for the optimal control of an electric vehicle with\ntransmission, where the modelling of the powertrain requires the consideration\nof both autonomous and controlled switchings accompanied by dimension changes. \n\n"}
{"id": "1710.05778", "contents": "Title: A successive difference-of-convex approximation method for a class of\n  nonconvex nonsmooth optimization problems Abstract: We consider a class of nonconvex nonsmooth optimization problems whose\nobjective is the sum of a smooth function and a finite number of nonnegative\nproper closed possibly nonsmooth functions (whose proximal mappings are easy to\ncompute), some of which are further composed with linear maps. This kind of\nproblems arises naturally in various applications when different regularizers\nare introduced for inducing simultaneous structures in the solutions. Solving\nthese problems, however, can be challenging because of the coupled nonsmooth\nfunctions: the corresponding proximal mapping can be hard to compute so that\nstandard first-order methods such as the proximal gradient algorithm cannot be\napplied efficiently. In this paper, we propose a successive\ndifference-of-convex approximation method for solving this kind of problems. In\nthis algorithm, we approximate the nonsmooth functions by their Moreau\nenvelopes in each iteration. Making use of the simple observation that Moreau\nenvelopes of nonnegative proper closed functions are continuous {\\em\ndifference-of-convex} functions, we can then approximately minimize the\napproximation function by first-order methods with suitable majorization\ntechniques. These first-order methods can be implemented efficiently thanks to\nthe fact that the proximal mapping of {\\em each} nonsmooth function is easy to\ncompute. Under suitable assumptions, we prove that the sequence generated by\nour method is bounded and any accumulation point is a stationary point of the\nobjective. We also discuss how our method can be applied to concrete\napplications such as nonconvex fused regularized optimization problems and\nsimultaneously structured matrix optimization problems, and illustrate the\nperformance numerically for these two specific applications. \n\n"}
{"id": "1710.07460", "contents": "Title: The Importance of System-Level Information in Multiagent Systems Design:\n  Cardinality and Covering Problems Abstract: A fundamental challenge in multiagent systems is to design local control\nalgorithms to ensure a desirable collective behaviour. The information\navailable to the agents, gathered either through communication or sensing,\nnaturally restricts the achievable performance. Hence, it is fundamental to\nidentify what piece of information is valuable and can be exploited to design\ncontrol laws with enhanced performance guarantees. This paper studies the case\nwhen such information is uncertain or inaccessible for a class of submodular\nresource allocation problems termed covering problems. In the first part of\nthis work we pinpoint a fundamental risk-reward tradeoff faced by the system\noperator when conditioning the control design on a valuable but uncertain piece\nof information, which we refer to as the cardinality, that represents the\nmaximum number of agents that can simultaneously select any given resource.\nBuilding on this analysis, we propose a distributed algorithm that allows\nagents to learn the cardinality while adjusting their behaviour over time. This\nalgorithm is proved to perform on par or better to the optimal design obtained\nwhen the exact cardinality is known a priori. \n\n"}
{"id": "1710.07657", "contents": "Title: Locally Optimal Control of Complex Networks Abstract: It has recently been shown that the minimum energy solution of the control\nproblem for a linear system produces a control trajectory that is nonlocal. An\nissue then arises when the dynamics represents a linearization of the\nunderlying nonlinear dynamics of the system where the linearization is only\nvalid in a local region of the state space. Here we provide a solution to the\nproblem of optimally controlling a linearized system by deriving a time-varying\nset that represents all possible control trajectories parameterized by time and\nenergy. As long as the control action terminus is defined within this set, the\ncontrol trajectory is guaranteed to be local. If the desired terminus of the\ncontrol action is far from the initial state, a series of local control actions\ncan be performed in series, re-linearizing the dynamics at each new position. \n\n"}
{"id": "1710.07737", "contents": "Title: Dynamic mode decomposition for compressive system identification Abstract: Dynamic mode decomposition has emerged as a leading technique to identify\nspatiotemporal coherent structures from high-dimensional data, benefiting from\na strong connection to nonlinear dynamical systems via the Koopman operator. In\nthis work, we integrate and unify two recent innovations that extend DMD to\nsystems with actuation [Proctor et al., 2016] and systems with heavily\nsubsampled measurements [Brunton et al., 2015]. When combined, these methods\nyield a novel framework for compressive system identification [code is publicly\navailable at: https://github.com/zhbai/cDMDc]. It is possible to identify a\nlow-order model from limited input-output data and reconstruct the associated\nfull-state dynamic modes with compressed sensing, adding interpretability to\nthe state of the reduced-order model. Moreover, when full-state data is\navailable, it is possible to dramatically accelerate downstream computations by\nfirst compressing the data. We demonstrate this unified framework on two model\nsystems, investigating the effects of sensor noise, different types of\nmeasurements (e.g., point sensors, Gaussian random projections, etc.),\ncompression ratios, and different choices of actuation (e.g., localized,\nbroadband, etc.). In the first example, we explore this architecture on a test\nsystem with known low-rank dynamics and an artificially inflated state\ndimension. The second example consists of a real-world engineering application\ngiven by the fluid flow past a pitching airfoil at low Reynolds number. This\nexample provides a challenging and realistic test-case for the proposed method,\nand results demonstrate that the dominant coherent structures are well\ncharacterized despite actuation and heavily subsampled data. \n\n"}
{"id": "1710.08737", "contents": "Title: Nonlinear Predictive Control on a Heterogeneous Computing Platform Abstract: We propose an implementation of an interior-point-based nonlinear predictive\ncontroller on a heterogeneous processor. The workload can be split between a\ngeneral-purpose CPU and a field-programmable gate array to trade off the\ncontradicting design objectives of control performance and computational\nresource usage. A new way of exploiting the structure of the KKT matrix yields\nsignificant memory savings. We report an 18x memory saving, compared to\nexisting approaches, and a 36x speedup over a software implementation with an\nARM Cortex-A9 processor. We also introduce a new release of Protoip, which\nabstracts low-level details of heterogeneous programming and allows\nprocessor-in-the-loop verification. \n\n"}
{"id": "1710.08936", "contents": "Title: Curvature-aided Incremental Aggregated Gradient Method Abstract: We propose a new algorithm for finite sum optimization which we call the\ncurvature-aided incremental aggregated gradient (CIAG) method. Motivated by the\nproblem of training a classifier for a d-dimensional problem, where the number\nof training data is $m$ and $m \\gg d \\gg 1$, the CIAG method seeks to\naccelerate incremental aggregated gradient (IAG) methods using aids from the\ncurvature (or Hessian) information, while avoiding the evaluation of matrix\ninverses required by the incremental Newton (IN) method. Specifically, our idea\nis to exploit the incrementally aggregated Hessian matrix to trace the full\ngradient vector at every incremental step, therefore achieving an improved\nlinear convergence rate over the state-of-the-art IAG methods. For strongly\nconvex problems, the fast linear convergence rate requires the objective\nfunction to be close to quadratic, or the initial point to be close to optimal\nsolution. Importantly, we show that running one iteration of the CIAG method\nyields the same improvement to the optimality gap as running one iteration of\nthe full gradient method, while the complexity is $O(d^2)$ for CIAG and $O(md)$\nfor the full gradient. Overall, the CIAG method strikes a balance between the\nhigh computation complexity incremental Newton-type methods and the slow IAG\nmethod. Our numerical results support the theoretical findings and show that\nthe CIAG method often converges with much fewer iterations than IAG, and\nrequires much shorter running time than IN when the problem dimension is high. \n\n"}
{"id": "1710.08994", "contents": "Title: Variable Partitioning for Distributed Optimization Abstract: This paper is about how to partition decision variables while decomposing a\nlarge-scale optimization problem for the best performance of distributed\nsolution methods. Solving a large-scale optimization problem sequen- tially can\nbe computationally challenging. One classic approach is to decompose the\nproblem into smaller sub-problems and solve them in a distributed fashion.\nHowever, there is little discussion in the literature on which variables should\nbe grouped together to form the sub-problems, especially when the optimization\nformulation involves complex constraints. We focus on one of the most popular\ndistributed approaches, dual decomposition and distributed sub-gradient\nmethods. Based on a theoretical guarantee on its convergence rate, we explain\nthat a partition of variables can critically affect the speed of convergence\nand highlight the importance of the number of dualized constraints. Then, we\nintroduce a novel approach to find a partition that reduces the number of\ndualized constraints by utilizing a community detection algorithm from physics\nliterature. Roughly speaking, the proposed method groups decision variables\nthat appear together in con- straints and solves the resulting sub-problems\nwith blocks of variables in parallel. Empirical experiments on a real\napplication show that the proposed method significantly accelerates the\nconvergence of the distributed sub-gradient method. The advantage of our\napproach becomes more significant as the size of the problem increases and each\nconstraint involves more variables. \n\n"}
{"id": "1710.09447", "contents": "Title: Stochastic Non-convex Optimization with Strong High Probability\n  Second-order Convergence Abstract: In this paper, we study stochastic non-convex optimization with non-convex\nrandom functions. Recent studies on non-convex optimization revolve around\nestablishing second-order convergence, i.e., converging to a nearly\nsecond-order optimal stationary points. However, existing results on stochastic\nnon-convex optimization are limited, especially with a high probability\nsecond-order convergence. We propose a novel updating step (named NCG-S) by\nleveraging a stochastic gradient and a noisy negative curvature of a stochastic\nHessian, where the stochastic gradient and Hessian are based on a proper\nmini-batch of random functions. Building on this step, we develop two\nalgorithms and establish their high probability second-order convergence. To\nthe best of our knowledge, the proposed stochastic algorithms are the first\nwith a second-order convergence in {\\it high probability} and a time complexity\nthat is {\\it almost linear} in the problem's dimensionality. \n\n"}
{"id": "1710.09554", "contents": "Title: Duality-free Methods for Stochastic Composition Optimization Abstract: We consider the composition optimization with two expected-value functions in\nthe form of $\\frac{1}{n}\\sum\\nolimits_{i = 1}^n F_i(\\frac{1}{m}\\sum\\nolimits_{j\n= 1}^m G_j(x))+R(x)$, { which formulates many important problems in statistical\nlearning and machine learning such as solving Bellman equations in\nreinforcement learning and nonlinear embedding}. Full Gradient or classical\nstochastic gradient descent based optimization algorithms are unsuitable or\ncomputationally expensive to solve this problem due to the inner expectation\n$\\frac{1}{m}\\sum\\nolimits_{j = 1}^m G_j(x)$. We propose a duality-free based\nstochastic composition method that combines variance reduction methods to\naddress the stochastic composition problem. We apply SVRG and SAGA based\nmethods to estimate the inner function, and duality-free method to estimate the\nouter function. We prove the linear convergence rate not only for the convex\ncomposition problem, but also for the case that the individual outer functions\nare non-convex while the objective function is strongly-convex. We also provide\nthe results of experiments that show the effectiveness of our proposed methods. \n\n"}
{"id": "1710.10122", "contents": "Title: RRT-CoLearn: towards kinodynamic planning without numerical trajectory\n  optimization Abstract: Sampling-based kinodynamic planners, such as Rapidly-exploring Random Trees\n(RRTs), pose two fundamental challenges: computing a reliable (pseudo-)metric\nfor the distance between two randomly sampled nodes, and computing a steering\ninput to connect the nodes. The core of these challenges is a Two Point\nBoundary Value Problem, which is known to be NP-hard. Recently, the distance\nmetric has been approximated using supervised learning, reducing computation\ntime drastically. The previous work on such learning RRTs use direct optimal\ncontrol to generate the data for supervised learning. This paper proposes to\nuse indirect optimal control instead, because it provides two benefits: it\nreduces the computational effort to generate the data, and it provides a low\ndimensional parametrization of the action space. The latter allows us to learn\nboth the distance metric and the steering input to connect two nodes. This\neliminates the need for a local planner in learning RRTs. Experimental results\non a pendulum swing up show 10-fold speed-up in both the offline data\ngeneration and the online planning time, leading to at least a 10-fold speed-up\nin the overall planning time. \n\n"}
{"id": "1710.10452", "contents": "Title: Criteria for input-to-state practical stability Abstract: For a broad class of infinite-dimensional systems, we characterize\ninput-to-state practical stability (ISpS) using the uniform limit property and\nin terms of input-to-state stability. We specialize our results to the systems\nwith Lipschitz continuous flows and evolution equations in Banach spaces. Even\nfor the special case of ordinary differential equations our results are novel\nand improve existing criteria for ISpS. \n\n"}
{"id": "1710.10737", "contents": "Title: Linearly convergent stochastic heavy ball method for minimizing\n  generalization error Abstract: In this work we establish the first linear convergence result for the\nstochastic heavy ball method. The method performs SGD steps with a fixed\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\nminimizing the expected loss and not on finite-sum minimization, which is\ntypically a much harder problem. While in the analysis we constrain ourselves\nto quadratic loss, the overall objective is not necessarily strongly convex. \n\n"}
{"id": "1710.10770", "contents": "Title: Riemannian Optimization via Frank-Wolfe Methods Abstract: We study projection-free methods for constrained Riemannian optimization. In\nparticular, we propose the Riemannian Frank-Wolfe (RFW) method. We analyze\nnon-asymptotic convergence rates of RFW to an optimum for (geodesically) convex\nproblems, and to a critical point for nonconvex objectives. We also present a\npractical setting under which RFW can attain a linear convergence rate. As a\nconcrete example, we specialize RFW to the manifold of positive definite\nmatrices and apply it to two tasks: (i) computing the matrix geometric mean\n(Riemannian centroid); and (ii) computing the Bures-Wasserstein barycenter.\nBoth tasks involve geodesically convex interval constraints, for which we show\nthat the Riemannian \"linear\" oracle required by RFW admits a closed-form\nsolution; this result may be of independent interest. We further specialize RFW\nto the special orthogonal group and show that here too, the Riemannian \"linear\"\noracle can be solved in closed form. Here, we describe an application to the\nsynchronization of data matrices (Procrustes problem). We complement our\ntheoretical results with an empirical comparison of RFW against\nstate-of-the-art Riemannian optimization methods and observe that RFW performs\ncompetitively on the task of computing Riemannian centroids. \n\n"}
{"id": "1711.00571", "contents": "Title: Efficient $\\widetilde{O}(n/\\epsilon)$ Spectral Sketches for the\n  Laplacian and its Pseudoinverse Abstract: In this paper we consider the problem of efficiently computing\n$\\epsilon$-sketches for the Laplacian and its pseudoinverse. Given a Laplacian\nand an error tolerance $\\epsilon$, we seek to construct a function $f$ such\nthat for any vector $x$ (chosen obliviously from $f$), with high probability\n$(1-\\epsilon) x^\\top A x \\leq f(x) \\leq (1 + \\epsilon) x^\\top A x$ where $A$ is\neither the Laplacian or its pseudoinverse. Our goal is to construct such a\nsketch $f$ efficiently and to store it in the least space possible.\n  We provide nearly-linear time algorithms that, when given a Laplacian matrix\n$\\mathcal{L} \\in \\mathbb{R}^{n \\times n}$ and an error tolerance $\\epsilon$,\nproduce $\\tilde{O}(n/\\epsilon)$-size sketches of both $\\mathcal{L}$ and its\npseudoinverse. Our algorithms improve upon the previous best sketch size of\n$\\widetilde{O}(n / \\epsilon^{1.6})$ for sketching the Laplacian form by Andoni\net al (2015) and $O(n / \\epsilon^2)$ for sketching the Laplacian pseudoinverse\nby Batson, Spielman, and Srivastava (2008).\n  Furthermore we show how to compute all-pairs effective resistances from\n$\\widetilde{O}(n/\\epsilon)$ size sketch in $\\widetilde{O}(n^2/\\epsilon)$ time.\nThis improves upon the previous best running time of\n$\\widetilde{O}(n^2/\\epsilon^2)$ by Spielman and Srivastava (2008). \n\n"}
{"id": "1711.00851", "contents": "Title: Provable defenses against adversarial examples via the convex outer\n  adversarial polytope Abstract: We propose a method to learn deep ReLU-based classifiers that are provably\nrobust against norm-bounded adversarial perturbations on the training data. For\npreviously unseen examples, the approach is guaranteed to detect all\nadversarial examples, though it may flag some non-adversarial examples as well.\nThe basic idea is to consider a convex outer approximation of the set of\nactivations reachable through a norm-bounded perturbation, and we develop a\nrobust optimization procedure that minimizes the worst case loss over this\nouter region (via a linear program). Crucially, we show that the dual problem\nto this linear program can be represented itself as a deep network similar to\nthe backpropagation network, leading to very efficient optimization approaches\nthat produce guaranteed bounds on the robust loss. The end result is that by\nexecuting a few more forward and backward passes through a slightly modified\nversion of the original network (though possibly with much larger batch sizes),\nwe can learn a classifier that is provably robust to any norm-bounded\nadversarial attack. We illustrate the approach on a number of tasks to train\nclassifiers with robust adversarial guarantees (e.g. for MNIST, we produce a\nconvolutional classifier that provably has less than 5.8% test error for any\nadversarial attack with bounded $\\ell_\\infty$ norm less than $\\epsilon = 0.1$),\nand code for all experiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial. \n\n"}
{"id": "1711.01660", "contents": "Title: Conditional Gradient Method for Stochastic Submodular Maximization:\n  Closing the Gap Abstract: In this paper, we study the problem of \\textit{constrained} and\n\\textit{stochastic} continuous submodular maximization. Even though the\nobjective function is not concave (nor convex) and is defined in terms of an\nexpectation, we develop a variant of the conditional gradient method, called\n\\alg, which achieves a \\textit{tight} approximation guarantee. More precisely,\nfor a monotone and continuous DR-submodular function and subject to a\n\\textit{general} convex body constraint, we prove that \\alg achieves a\n$[(1-1/e)\\text{OPT} -\\eps]$ guarantee (in expectation) with\n$\\mathcal{O}{(1/\\eps^3)}$ stochastic gradient computations. This guarantee\nmatches the known hardness results and closes the gap between deterministic and\nstochastic continuous submodular maximization. By using stochastic continuous\noptimization as an interface, we also provide the first $(1-1/e)$ tight\napproximation guarantee for maximizing a \\textit{monotone but stochastic}\nsubmodular \\textit{set} function subject to a general matroid constraint. \n\n"}
{"id": "1711.01850", "contents": "Title: A universal modification of the linear coupling method Abstract: In the late sixties, N. Shor and B. Polyak independently proposed optimal\nfirst-order methods for non-smooth convex optimization problems. In 1982 A.\nNemirovski proposed optimal first-order methods for smooth convex optimization\nproblems, which utilized auxiliary line search. In 1985 A. Nemirovski and Yu.\nNesterov proposed a parametric family of optimal first-order methods for convex\noptimization problems with intermediate smoothness. In 2013 Yu. Nesterov\nproposed a universal gradient method which combined all the good properties of\nthe previous methods, except the possibility of using auxiliary line search.\nOne can typically observe that in practice auxiliary line search improves\nperformance for many tasks. In this paper, we propose the apparently first such\nmethod of non-smooth convex optimization allowing for the use of the line\nsearch procedure. Moreover, it is based on the universal gradient method, which\ndoes not require any a priori information about the actual degree of smoothness\nof the problem. Numerical experiments demonstrate that the proposed method is,\nin some cases, considerably faster than Nesterov's universal gradient method. \n\n"}
{"id": "1711.01851", "contents": "Title: Overrelaxed Sinkhorn-Knopp Algorithm for Regularized Optimal Transport Abstract: This article describes a set of methods for quickly computing the solution to\nthe regularized optimal transport problem. It generalizes and improves upon the\nwidely-used iterative Bregman projections algorithm (or Sinkhorn--Knopp\nalgorithm). We first propose to rely on regularized nonlinear acceleration\nschemes. In practice, such approaches lead to fast algorithms, but their global\nconvergence is not ensured. Hence, we next propose a new algorithm with\nconvergence guarantees. The idea is to overrelax the Bregman projection\noperators, allowing for faster convergence. We propose a simple method for\nestablishing global convergence by ensuring the decrease of a Lyapunov function\nat each step. An adaptive choice of overrelaxation parameter based on the\nLyapunov function is constructed. We also suggest a heuristic to choose a\nsuitable asymptotic overrelaxation parameter, based on a local convergence\nanalysis. Our numerical experiments show a gain in convergence speed by an\norder of magnitude in certain regimes. \n\n"}
{"id": "1711.02502", "contents": "Title: A feasibility approach for constructing combinatorial designs of\n  circulant type Abstract: In this work, we propose an optimization approach for constructing various\nclasses of circulant combinatorial designs that can be defined in terms of\nautocorrelations. The problem is formulated as a so-called feasibility problem\nhaving three sets, to which the Douglas-Rachford projection algorithm is\napplied. The approach is illustrated on three different classes of circulant\ncombinatorial designs: circulant weighing matrices, D-optimal matrices, and\nHadamard matrices with two circulant cores. Furthermore, we explicitly\nconstruct two new circulant weighing matrices, a $CW(126,64)$ and a\n$CW(198,100)$, whose existence was previously marked as unresolved in the most\nrecent version of Strassler's table. \n\n"}
{"id": "1711.03471", "contents": "Title: AC Transmission Network Expansion Planning: A Semidefinite Programming\n  Branch-and-Cut Approach Abstract: Transmission network expansion planning is a mixed-integer optimization\nproblem, whose solution is used to guide future investment in transmission\nequipment. An approach is presented to find the global solution of the\ntransmission planning problem using an AC network model. The approach builds on\nthe semidefinite relaxation of the AC optimal power flow problem (ACOPF); its\ncomputational engine is a new specialized branch-and-cut algorithm for\ntransmission expansion planning to deal with the underlying mixed-integer ACOPF\nproblem. Valid inequalities that are based on specific knowledge of the\nexpansion problem are employed to improve the solution quality at any node of\nthe search tree, and thus significantly reduce the overall computational effort\nof the branch-and-bound algorithm. Additionally, sparsity of the semidefinite\nrelaxation is exploited to further reduce the computation time at each node of\nthe branch-and-cut tree. Despite the vast number of publications on\ntransmission expansion planning, the proposed approach is the first to provide\nexpansion plans that are globally optimal using a solution approach for the\nmixed-integer ACOPF problem. The results on standard networks serve as\nimportant benchmarks to assess the solution quality from existing techniques\nand simplified models. \n\n"}
{"id": "1711.05519", "contents": "Title: Accelerated Alternating Projections for Robust Principal Component\n  Analysis Abstract: We study robust PCA for the fully observed setting, which is about separating\na low rank matrix $\\boldsymbol{L}$ and a sparse matrix $\\boldsymbol{S}$ from\ntheir sum $\\boldsymbol{D}=\\boldsymbol{L}+\\boldsymbol{S}$. In this paper, a new\nalgorithm, dubbed accelerated alternating projections, is introduced for robust\nPCA which significantly improves the computational efficiency of the existing\nalternating projections proposed in [Netrapalli, Praneeth, et al., 2014] when\nupdating the low rank factor. The acceleration is achieved by first projecting\na matrix onto some low dimensional subspace before obtaining a new estimate of\nthe low rank matrix via truncated SVD. Exact recovery guarantee has been\nestablished which shows linear convergence of the proposed algorithm. Empirical\nperformance evaluations establish the advantage of our algorithm over other\nstate-of-the-art algorithms for robust PCA. \n\n"}
{"id": "1711.06443", "contents": "Title: Best rank-$k$ approximations for tensors: generalizing Eckart-Young Abstract: Given a tensor $f$ in a Euclidean tensor space, we are interested in the\ncritical points of the distance function from $f$ to the set of tensors of rank\nat most $k$, which we call the critical rank-at-most-$k$ tensors for $f$. When\n$f$ is a matrix, the critical rank-one matrices for $f$ correspond to the\nsingular pairs of $f$. The critical rank-one tensors for $f$ lie in a linear\nsubspace $H_f$, the critical space of $f$. Our main result is that, for any\n$k$, the critical rank-at-most-$k$ tensors for a sufficiently general $f$ also\nlie in the critical space $H_f$. This is the part of Eckart-Young Theorem that\ngeneralizes from matrices to tensors. Moreover, we show that when the tensor\nformat satisfies the triangle inequalities, the critical space $H_f$ is spanned\nby the complex critical rank-one tensors. Since $f$ itself belongs to $H_f$, we\ndeduce that also $f$ itself is a linear combination of its critical rank-one\ntensors. \n\n"}
{"id": "1711.09761", "contents": "Title: Mitigating Blackout Risk via Maintenance : Inference from Simulation\n  Data Abstract: Whereas maintenance has been recognized as an important and effective means\nfor risk management in power systems, it turns out to be intractable if\ncascading blackout risk is considered due to the extremely high computational\ncomplexity. In this paper, based on the inference from the blackout simulation\ndata, we propose a methodology to efficiently identify the most influential\ncomponent(s) for mitigating cascading blackout risk in a large power system. To\nthis end, we first establish an analytic relationship between maintenance\nstrategies and blackout risk estimation by inferring from the data of cascading\noutage simulations. Then we formulate the component maintenance decision-making\nproblem as a nonlinear 0-1 programming. Afterwards, we quantify the credibility\nof blackout risk estimation, leading to an adaptive method to determine the\nleast required number of simulations, which servers as a crucial parameter of\nthe optimization model. Finally, we devise two heuristic algorithms to find\napproximate optimal solutions to the model with very high efficiency. Numerical\nexperiments well manifest the efficacy and high efficiency of our methodology. \n\n"}
{"id": "1711.09953", "contents": "Title: Online Stochastic Optimization of Networked Distributed Energy Resources Abstract: This paper investigates distributed control and incentive mechanisms to\ncoordinate distributed energy resources (DERs) with both continuous and\ndiscrete decision variables as well as device dynamics in distribution grids.\nWe formulate a multi-period social welfare maximization problem, and based on\nits convex relaxation propose a distributed stochastic dual gradient algorithm\nfor managing DERs. We further extend it to an online realtime setting with\ntime-varying operating conditions, asynchronous updates by devices, and\nfeedback being leveraged to account for nonlinear power flows as well as reduce\ncommunication overhead. The resulting algorithm provides a general online\nstochastic optimization algorithm for coordinating networked DERs with discrete\npower setpoints and dynamics to meet operational and economic objectives and\nconstraints. We characterize the convergence of the algorithm analytically and\nevaluate its performance numerically. \n\n"}
{"id": "1711.11578", "contents": "Title: Multi-agent decision-making dynamics inspired by honeybees Abstract: When choosing between candidate nest sites, a honeybee swarm reliably chooses\nthe most valuable site and even when faced with the choice between near-equal\nvalue sites, it makes highly efficient decisions. Value-sensitive\ndecision-making is enabled by a distributed social effort among the honeybees,\nand it leads to decision-making dynamics of the swarm that are remarkably\nrobust to perturbation and adaptive to change. To explore and generalize these\nfeatures to other networks, we design distributed multi-agent network dynamics\nthat exhibit a pitchfork bifurcation, ubiquitous in biological models of\ndecision-making. Using tools of nonlinear dynamics we show how the designed\nagent-based dynamics recover the high performing value-sensitive\ndecision-making of the honeybees and rigorously connect investigation of\nmechanisms of animal group decision-making to systematic, bio-inspired control\nof multi-agent network systems. We further present a distributed adaptive\nbifurcation control law and prove how it enhances the network decision-making\nperformance beyond that observed in swarms. \n\n"}
{"id": "1712.00984", "contents": "Title: Inertial Proximal Incremental Aggregated Gradient Method Abstract: In this paper, we introduce an inertial version of the Proximal Incremental\nAggregated Gradient method (PIAG) for minimizing the sum of smooth convex\ncomponent functions and a possibly nonsmooth convex regularization function.\nTheoretically, we show that the inertial Proximal Incremental Aggregated\nGradiend (iPIAG) method enjoys a global linear convergence under a quadratic\ngrowth condition, which is strictly weaker than strong convexity, provided that\nthe stepsize is not larger than a constant. Moreover, we present two numerical\nexpreiments which demonstrate that iPIAG outperforms the original PIAG. \n\n"}
{"id": "1712.01033", "contents": "Title: NEON+: Accelerated Gradient Methods for Extracting Negative Curvature\n  for Non-Convex Optimization Abstract: Accelerated gradient (AG) methods are breakthroughs in convex optimization,\nimproving the convergence rate of the gradient descent method for optimization\nwith smooth functions. However, the analysis of AG methods for non-convex\noptimization is still limited. It remains an open question whether AG methods\nfrom convex optimization can accelerate the convergence of the gradient descent\nmethod for finding local minimum of non-convex optimization problems. This\npaper provides an affirmative answer to this question. In particular, we\nanalyze two renowned variants of AG methods (namely Polyak's Heavy Ball method\nand Nesterov's Accelerated Gradient method) for extracting the negative\ncurvature from random noise, which is central to escaping from saddle points.\nBy leveraging the proposed AG methods for extracting the negative curvature, we\npresent a new AG algorithm with double loops for non-convex\noptimization~\\footnote{this is in contrast to a single-loop AG algorithm\nproposed in a recent manuscript~\\citep{AGNON}, which directly analyzed the\nNesterov's AG method for non-convex optimization and appeared online on\nNovember 29, 2017. However, we emphasize that our work is an independent work,\nwhich is inspired by our earlier work~\\citep{NEON17} and is based on a\ndifferent novel analysis.}, which converges to second-order stationary point\n$\\x$ such that $\\|\\nabla f(\\x)\\|\\leq \\epsilon$ and $\\nabla^2 f(\\x)\\geq\n-\\sqrt{\\epsilon} I$ with $\\widetilde O(1/\\epsilon^{1.75})$ iteration\ncomplexity, improving that of gradient descent method by a factor of\n$\\epsilon^{-0.25}$ and matching the best iteration complexity of second-order\nHessian-free methods for non-convex optimization. \n\n"}
{"id": "1712.02164", "contents": "Title: On the Singular Control of Exchange Rates Abstract: Consider the problem of a central bank that wants to manage the exchange rate\nbetween its domestic currency and a foreign one. The central bank can purchase\nand sell the foreign currency, and each intervention on the exchange market\nleads to a proportional cost whose instantaneous marginal value depends on the\ncurrent level of the exchange rate. The central bank aims at minimizing the\ntotal expected costs of interventions on the exchange market, plus a total\nexpected holding cost. We formulate this problem as an infinite time-horizon\nstochastic control problem with controls that have paths which are locally of\nbounded variation. The exchange rate evolves as a general linearly controlled\none-dimensional diffusion, and the two nondecreasing processes giving the\nminimal decomposition of a bounded-variation control model the cumulative\namount of foreign currency that has been purchased and sold by the central\nbank. We provide a complete solution to this problem by finding the explicit\nexpression of the value function and a complete characterization of the optimal\ncontrol. At each instant of time, the optimally controlled exchange rate is\nkept within a band whose size is endogenously determined as part of the\nsolution to the problem. We also study the expected exit time from the band,\nand the sensitivity of the width of the band with respect to the model's\nparameters in the case when the exchange rate evolves (in absence of any\nintervention) as an Ornstein-Uhlenbeck process, and the marginal costs of\ncontrols are constant. The techniques employed in the paper are those of the\ntheory of singular stochastic control and of one-dimensional diffusions. \n\n"}
{"id": "1712.03950", "contents": "Title: Saving Gradient and Negative Curvature Computations: Finding Local\n  Minima More Efficiently Abstract: We propose a family of nonconvex optimization algorithms that are able to\nsave gradient and negative curvature computations to a large extent, and are\nguaranteed to find an approximate local minimum with improved runtime\ncomplexity. At the core of our algorithms is the division of the entire domain\nof the objective function into small and large gradient regions: our algorithms\nonly perform gradient descent based procedure in the large gradient region, and\nonly perform negative curvature descent in the small gradient region. Our novel\nanalysis shows that the proposed algorithms can escape the small gradient\nregion in only one negative curvature descent step whenever they enter it, and\nthus they only need to perform at most $N_{\\epsilon}$ negative curvature\ndirection computations, where $N_{\\epsilon}$ is the number of times the\nalgorithms enter small gradient regions. For both deterministic and stochastic\nsettings, we show that the proposed algorithms can potentially beat the\nstate-of-the-art local minima finding algorithms. For the finite-sum setting,\nour algorithm can also outperform the best algorithm in a certain regime. \n\n"}
{"id": "1712.05911", "contents": "Title: Controlled Singular Volterra Integral Equations and Pontryagin Maximum\n  Principle Abstract: This paper is concerned with a class of controlled singular Volterra integral\nequations, which could be used to describe problems involving memories. The\nwell-known fractional order ordinary differential equations of the\nRiemann--Liouville or Caputo types are strictly special cases of the equations\nstudied in this paper. Well-posedness and some regularity results in proper\nspaces are established for such kind of questions. For the associated optimal\ncontrol problem, by using a Liapounoff's type theorem and the spike variation\ntechnique, we establish a Pontryagin's type maximum principle for optimal\ncontrols. Different from the existing literature, our method enables us to deal\nwith the problem without assuming regularity conditions on the controls, the\nconvexity condition on the control domain, and some additional unnecessary\nconditions on the nonlinear terms of the integral equation and the cost\nfunctional. \n\n"}
{"id": "1712.06038", "contents": "Title: The proximal point method revisited Abstract: In this short survey, I revisit the role of the proximal point method in\nlarge scale optimization. I focus on three recent examples: a proximally guided\nsubgradient method for weakly convex stochastic approximation, the prox-linear\nalgorithm for minimizing compositions of convex functions and smooth maps, and\nCatalyst generic acceleration for regularized Empirical Risk Minimization. \n\n"}
{"id": "1712.08622", "contents": "Title: Analysis and Implementation of a Hourly Billing Mechanism for Demand\n  Response Management Abstract: An important part of the Smart Grid literature on residential Demand Response\ndeals with game-theoretic consumption models. Among those papers, the hourly\nbilling model is of special interest as an intuitive and fair mechanism. We\nfocus on this model and answer to several theoretical and practical questions.\nFirst, we prove the uniqueness of the consumption profile corresponding to the\nNash equilibrium, and we analyze its efficiency by providing a bound on the\nPrice of Anarchy. Next, we address the computational issue of the equilibrium\nprofile by providing two algorithms: the cycling best response dynamics and a\nprojected gradient descent method, and by giving an upper bound on their\nconvergence rate to the equilibrium. Last, we simulate this demand response\nframework in a stochastic environment where the parameters depend on forecasts.\nWe show numerically the relevance of an online demand response procedure, which\nreduces the impact of inaccurate forecasts. \n\n"}
{"id": "1712.08923", "contents": "Title: The Support of Integer Optimal Solutions Abstract: The support of a vector is the number of nonzero-components. We show that\ngiven an integral $m\\times n$ matrix $A$, the integer linear optimization\nproblem $\\max\\left\\{\\boldsymbol{c}^T\\boldsymbol{x} : A\\boldsymbol{x} =\n\\boldsymbol{b}, \\, \\boldsymbol{x}\\ge\\boldsymbol{0},\n\\,\\boldsymbol{x}\\in\\mathbb{Z}^n\\right\\}$ has an optimal solution whose support\nis bounded by $2m \\, \\log (2 \\sqrt{m} \\| A \\|_\\infty)$, where $ \\| A \\|_\\infty$\nis the largest absolute value of an entry of $A$. Compared to previous bounds,\nthe one presented here is independent on the objective function. We furthermore\nprovide a nearly matching asymptotic lower bound on the support of optimal\nsolutions. \n\n"}
{"id": "1712.08942", "contents": "Title: A multi-material transport problem and its convex relaxation via\n  rectifiable $G$-currents Abstract: In this paper we study a variant of the branched transportation problem, that\nwe call multi-material transport problem. This is a transportation problem,\nwhere distinct commodities are transported simultaneously along a network. The\ncost of the transportation depends on the network used to move the masses, as\nit is common in models studied in branched transportation. The main novelty is\nthat in our model the cost per unit length of the network does not depend only\non the total flow, but on the actual quantity of each commodity. This allows to\ntake into account different interactions between the transported goods. We\npropose an Eulerian formulation of the discrete problem, describing the flow of\neach commodity through every point of the network. We provide minimal\nassumptions on the cost, under which existence of solutions can be proved.\nMoreover, we prove that, under mild additional assumptions, the problem can be\nrephrased as a mass minimization problem in a class of rectifiable currents\nwith coefficients in a group, allowing to introduce a notion of calibration.\nThe latter result is new even in the well studied framework of the\n\"single-material\" branched transportation. \n\n"}
{"id": "1712.09131", "contents": "Title: A Random Block-Coordinate Douglas-Rachford Splitting Method with Low\n  Computational Complexity for Binary Logistic Regression Abstract: In this paper, we propose a new optimization algorithm for sparse logistic\nregression based on a stochastic version of the Douglas-Rachford splitting\nmethod. Our algorithm sweeps the training set by randomly selecting a\nmini-batch of data at each iteration, and it allows us to update the variables\nin a block coordinate manner. Our approach leverages the proximity operator of\nthe logistic loss, which is expressed with the generalized Lambert W function.\nExperiments carried out on standard datasets demonstrate the efficiency of our\napproach w.r.t. stochastic gradient-like methods. \n\n"}
{"id": "1801.00444", "contents": "Title: Common Throughput Maximization in UAV-Enabled OFDMA Systems with Delay\n  Consideration Abstract: The use of unmanned aerial vehicles (UAVs) as communication platforms is of\ngreat practical significance in future wireless networks, especially for\non-demand deployment in temporary events and emergency situations. Although\nprior works have shown the performance improvement by exploiting the UAV's\nmobility, they mainly focus on delay-tolerant applications. As delay\nrequirements fundamentally limit the UAV's mobility, it remains unknown whether\nthe UAV is able to provide any performance gain in delay-constrained\ncommunication scenarios. Motivated by this, we study in this paper a\nUAV-enabled orthogonal frequency division multiple access (OFDMA) network where\na UAV is dispatched as a mobile base station (BS) to serve a group of users on\nthe ground. We consider a minimum-rate ratio (MRR) for each user, defined as\nthe minimum instantaneous rate required over the average achievable throughput,\nto flexibly adjust the percentage of its delay-constrained data traffic. Under\na given set of constraints on the users' MRRs, we aim to maximize the minimum\naverage throughput of all users by jointly optimizing the UAV trajectory and\nOFDMA resource allocation. First, we show that the max-min throughput in\ngeneral decreases as the users' MRR constraints become more stringent, which\nreveals a fundamental throughput-delay tradeoff in UAV-enabled communications.\nNext, we propose an iterative parameter-assisted block coordinate descent\nmethod to optimize the UAV trajectory and OFDMA resource allocation\nalternately, by applying the successive convex optimization and the Lagrange\nduality, respectively. Furthermore, an efficient and systematic UAV trajectory\ninitialization scheme is proposed based on a simple circular trajectory.\nFinally, simulation results are provided to verify our theoretical findings and\ndemonstrate the effectiveness of our proposed designs. \n\n"}
{"id": "1801.01208", "contents": "Title: Binary Extended Formulations Abstract: We analyze different ways of constructing binary extended formulations of\nmixed-integer problems with bounded integer variables and compare their\nrelative strength with respect to split cuts. We show that among all binary\nextended formulations where each bounded integer variable is represented by a\ndistinct collection of binary variables, what we call \"unimodular\" extended\nformulations are the strongest. We also compare the strength of some binary\nextended formulations from the literature. Finally, we study the behavior of\nbranch-and-bound on such extended formulations and show that branching on the\nnew binary variables leads to significantly smaller enumeration trees in some\ncases. \n\n"}
{"id": "1801.02179", "contents": "Title: Effective strong convergence of the proximal point algorithm in CAT(0)\n  spaces Abstract: We apply methods of proof mining to obtain uniform quantitative bounds on the\nstrong convergence of the proximal point algorithm for finding minimizers of\nconvex, lower semicontinuous proper functions in CAT(0) spaces. Thus, for\nuniformly convex functions we compute rates of convergence, while, for totally\nbounded CAT(0) spaces we apply methods introduced by Kohlenbach, the first\nauthor and Nicolae to compute rates of metastability. \n\n"}
{"id": "1801.04290", "contents": "Title: The Control Toolbox - An Open-Source C++ Library for Robotics, Optimal\n  and Model Predictive Control Abstract: We introduce the Control Toolbox (CT), an open-source C++ library for\nefficient modeling, control, estimation, trajectory optimization and Model\nPredictive Control. The CT is applicable to a broad class of dynamic systems\nbut features interfaces to modeling tools specifically designed for robotic\napplications. This paper outlines the general concept of the toolbox, its main\nbuilding blocks, and highlights selected application examples. The library\ncontains several tools to design and evaluate controllers, model dynamical\nsystems and solve optimal control problems. The CT was designed for intuitive\nmodeling of systems governed by ordinary differential or difference equations.\nIt supports rapid prototyping of cost functions and constraints and provides\nstandard interfaces for different optimal control solvers. To date, we support\nSingle Shooting, the iterative Linear-Quadratic Regulator, Gauss-Newton\nMultiple Shooting and classical Direct Multiple Shooting. We provide interfaces\nto general purpose NLP solvers and Riccati-based linear-quadratic optimal\ncontrol solvers. The CT was designed to solve large-scale optimal control and\nestimation problems efficiently and allows for online control of dynamic\nsystems. Some of the key features to enable fast run-time performance are full\ncompatibility with Automatic Differentiation, derivative code generation, and\nmulti-threading. Still, the CT is designed as a modular framework whose\nbuilding blocks can also be used for other control and estimation applications\nsuch as inverse dynamics control, extended Kalman filters or kinematic\nplanning. \n\n"}
{"id": "1801.07059", "contents": "Title: Uniform asymptotic stability of a fractional tuberculosis model Abstract: We propose a Caputo type fractional-order mathematical model for the\ntransmission dynamics of tuberculosis (TB). Uniform asymptotic stability of the\nunique endemic equilibrium of the fractional-order TB model is proved, for any\n$\\alpha \\in (0, 1)$. Numerical simulations for the stability of the endemic\nequilibrium are provided. \n\n"}
{"id": "1801.08704", "contents": "Title: Event-triggered stabilization of disturbed linear systems over digital\n  channels Abstract: We present an event-triggered control strategy for stabilizing a scalar,\ncontinuous-time, time-invariant, linear system over a digital communication\nchannel having bounded delay, and in the presence of bounded system\ndisturbance. We propose an encoding-decoding scheme, and determine lower bounds\non the packet size and on the information transmission rate which are\nsufficient for stabilization. We show that for small values of the delay, the\ntiming information implicit in the triggering events is enough to stabilize the\nsystem with any positive rate. In contrast, when the delay increases beyond a\ncritical threshold, the timing information alone is not enough to stabilize the\nsystem and the transmission rate begins to increase. Finally, large values of\nthe delay require transmission rates higher than what prescribed by the classic\ndata-rate theorem. The results are numerically validated using a linearized\nmodel of an inverted pendulum. \n\n"}
{"id": "1801.09155", "contents": "Title: A Notion of Total Dual Integrality for Convex, Semidefinite, and\n  Extended Formulations Abstract: Total dual integrality is a powerful and unifying concept in polyhedral\ncombinatorics and integer programming that enables the refinement of geometric\nmin-max relations given by linear programming Strong Duality into combinatorial\nmin-max theorems. The definition of total dual integrality (TDI) revolves\naround the existence of optimal dual solutions that are integral, and thus\nnaturally applies to a host of combinatorial optimization problems that are\ncast as integer programs whose LP relaxations have the TDIness property.\nHowever, when combinatorial problems are formulated using more general convex\nrelaxations, such as semidefinite programs (SDPs), it is not at all clear what\nan appropriate notion of integrality in the dual program is, thus inhibiting\nthe generalization of the theory to more general forms of structured convex\noptimization. (In fact, we argue that the rank-one constraint usually added to\nSDP relaxations is not adequate in the dual SDP.)\n  In this paper, we propose a notion of total dual integrality for SDPs that\ngeneralizes the notion for LPs, by relying on an \"integrality constraint\" for\nSDPs that is primal-dual symmetric. A key ingredient for the theory is a\ngeneralization to compact convex sets of a result of Hoffman for polytopes,\nfundamental for generalizing the polyhedral notion of total dual integrality\nintroduced by Edmonds and Giles. We study the corresponding theory applied to\nSDP formulations for stable sets in graphs using the Lov\\'asz theta function\nand show that total dual integrality in this case corresponds to the underlying\ngraph being perfect. We also relate dual integrality of an SDP formulation for\nthe maximum cut problem to bipartite graphs. Total dual integrality for\nextended formulations naturally comes into play in this context. \n\n"}
{"id": "1801.09507", "contents": "Title: The exit time finite state projection scheme: bounding exit\n  distributions and occupation measures of continuous-time Markov chains Abstract: We introduce the exit time finite state projection (ETFSP) scheme, a\ntruncation-based method that yields approximations to the exit distribution and\noccupation measure associated with the time of exit from a domain (i.e., the\ntime of first passage to the complement of the domain) of time-homogeneous\ncontinuous-time Markov chains. We prove that: (i) the computed approximations\nbound the measures from below; (ii) the total variation distances between the\napproximations and the measures decrease monotonically as states are added to\nthe truncation; and (iii) the scheme converges, in the sense that, as the\ntruncation tends to the entire state space, the total variation distances tend\nto zero. Furthermore, we give a computable bound on the total variation\ndistance between the exit distribution and its approximation, and we delineate\nthe cases in which the bound is sharp. We also revisit the related finite state\nprojection scheme and give a comprehensive account of its theoretical\nproperties. We demonstrate the use of the ETFSP scheme by applying it to two\nbiological examples: the computation of the first passage time associated with\nthe expression of a gene, and the fixation times of competing species subject\nto demographic noise. \n\n"}
{"id": "1801.10441", "contents": "Title: Weighted Nonlocal Total Variation in Image Processing Abstract: In this paper, a novel weighted nonlocal total variation (WNTV) method is\nproposed. Compared to the classical nonlocal total variation methods, our\nmethod modifies the energy functional to introduce a weight to balance between\nthe labeled sets and unlabeled sets. With extensive numerical examples in\nsemi-supervised clustering, image inpainting and image colorization, we\ndemonstrate that WNTV provides an effective and efficient method in many image\nprocessing and machine learning problems. \n\n"}
{"id": "1802.00130", "contents": "Title: Distributed Newton Methods for Deep Neural Networks Abstract: Deep learning involves a difficult non-convex optimization problem with a\nlarge number of weights between any two adjacent layers of a deep structure. To\nhandle large data sets or complicated networks, distributed training is needed,\nbut the calculation of function, gradient, and Hessian is expensive. In\nparticular, the communication and the synchronization cost may become a\nbottleneck. In this paper, we focus on situations where the model is\ndistributedly stored, and propose a novel distributed Newton method for\ntraining deep neural networks. By variable and feature-wise data partitions,\nand some careful designs, we are able to explicitly use the Jacobian matrix for\nmatrix-vector products in the Newton method. Some techniques are incorporated\nto reduce the running time as well as the memory consumption. First, to reduce\nthe communication cost, we propose a diagonalization method such that an\napproximate Newton direction can be obtained without communication between\nmachines. Second, we consider subsampled Gauss-Newton matrices for reducing the\nrunning time as well as the communication cost. Third, to reduce the\nsynchronization cost, we terminate the process of finding an approximate Newton\ndirection even though some nodes have not finished their tasks. Details of some\nimplementation issues in distributed environments are thoroughly investigated.\nExperiments demonstrate that the proposed method is effective for the\ndistributed training of deep neural networks. In compared with stochastic\ngradient methods, it is more robust and may give better test accuracy. \n\n"}
{"id": "1802.01499", "contents": "Title: An extreme function which is nonnegative and discontinuous everywhere Abstract: We consider Gomory and Johnson's infinite group model with a single row.\nValid inequalities for this model are expressed by valid functions and it has\nbeen recently shown that any valid function is dominated by some nonnegative\nvalid function, modulo the affine hull of the model. Within the set of\nnonnegative valid functions, extreme functions are the ones that cannot be\nexpressed as convex combinations of two distinct valid functions. In this paper\nwe construct an extreme function $\\pi:\\mathbb{R} \\to [0,1]$ whose graph is\ndense in $\\mathbb{R} \\times [0,1]$. Therefore, $\\pi$ is discontinuous\neverywhere. \n\n"}
{"id": "1802.02302", "contents": "Title: An example showing that A-lower semi-continuity is essential for minimax\n  continuity theorems Abstract: Recently Feinberg et al. [arXiv:1609.03990] established results on continuity\nproperties of minimax values and solution sets for a function of two variables\ndepending on a parameter. Such minimax problems appear in games with perfect\ninformation, when the second player knows the move of the first one, in\nturn-based games, and in robust optimization. Some of the results in\n[arXiv:1609.03990] are proved under the assumption that the multifunction,\ndefining the domains of the second variable, is $A$-lower semi-continuous. The\n$A$-lower semi-continuity property is stronger than lower semi-continuity, but\nin several important cases these properties coincide. This note provides an\nexample demonstrating that in general the $A$-lower semi-continuity assumption\ncannot be relaxed to lower semi-continuity. \n\n"}
{"id": "1802.02485", "contents": "Title: BROJA-2PID: A robust estimator for bivariate partial information\n  decomposition Abstract: Makkeh, Theis, and Vicente found in [8] that Cone Programming model is the\nmost robust to compute the Bertschinger et al. partial information decompostion\n(BROJA PID) measure [1]. We developed a production-quality robust software that\ncomputes the BROJA PID measure based on the Cone Programming model. In this\npaper, we prove the important property of strong duality for the Cone Program\nand prove an equivalence between the Cone Program and the original Convex\nproblem. Then describe in detail our software and how to use it.\\newline\\indent \n\n"}
{"id": "1802.02988", "contents": "Title: Stochastic subgradient method converges at the rate $O(k^{-1/4})$ on\n  weakly convex functions Abstract: We prove that the proximal stochastic subgradient method, applied to a weakly\nconvex problem, drives the gradient of the Moreau envelope to zero at the rate\n$O(k^{-1/4})$. As a consequence, we resolve an open question on the convergence\nrate of the proximal stochastic gradient method for minimizing the sum of a\nsmooth nonconvex function and a convex proximable function. \n\n"}
{"id": "1802.03284", "contents": "Title: Mini-Batch Stochastic ADMMs for Nonconvex Nonsmooth Optimization Abstract: With the large rising of complex data, the nonconvex models such as nonconvex\nloss function and nonconvex regularizer are widely used in machine learning and\npattern recognition. In this paper, we propose a class of mini-batch stochastic\nADMMs (alternating direction method of multipliers) for solving large-scale\nnonconvex nonsmooth problems. We prove that, given an appropriate mini-batch\nsize, the mini-batch stochastic ADMM without variance reduction (VR) technique\nis convergent and reaches a convergence rate of $O(1/T)$ to obtain a stationary\npoint of the nonconvex optimization, where $T$ denotes the number of\niterations. Moreover, we extend the mini-batch stochastic gradient method to\nboth the nonconvex SVRG-ADMM and SAGA-ADMM proposed in our initial manuscript\n\\cite{huang2016stochastic}, and prove these mini-batch stochastic ADMMs also\nreaches the convergence rate of $O(1/T)$ without condition on the mini-batch\nsize. In particular, we provide a specific parameter selection for step size\n$\\eta$ of stochastic gradients and penalty parameter $\\rho$ of augmented\nLagrangian function. Finally, extensive experimental results on both simulated\nand real-world data demonstrate the effectiveness of the proposed algorithms. \n\n"}
{"id": "1802.03296", "contents": "Title: Pointed Closed Convex Sets are the Intersection of All Rational\n  Supporting Closed Halfspaces Abstract: We prove that every pointed closed convex set in $\\mathbb{R}^n$ is the\nintersection of all the rational closed halfspaces that contain it. This\ngeneralizes a previous result by the authors for compact convex sets. \n\n"}
{"id": "1802.04332", "contents": "Title: Entropy Penalized Semidefinite Programming Abstract: Low-rank methods for semidefinite programming (SDP) have gained a lot of\ninterest recently, especially in machine learning applications. Their analysis\noften involves determinant-based or Schatten-norm penalties, which are hard to\nimplement in practice due to high computational efforts. In this paper, we\npropose Entropy Penalized Semi-definite programming (EP-SDP) which provides a\nunified framework for a wide class of penalty functions used in practice to\npromote a low-rank solution. We show that EP-SDP problems admit efficient\nnumerical algorithm having (almost) linear time complexity of the gradient\niteration which makes it useful for many machine learning and optimization\nproblems. We illustrate the practical efficiency of our approach on several\ncombinatorial optimization and machine learning problems. \n\n"}
{"id": "1802.05859", "contents": "Title: A Parameterized Strongly Polynomial Algorithm for Block Structured\n  Integer Programs Abstract: The theory of $n$-fold integer programming has been recently emerging as an\nimportant tool in parameterized complexity. The input to an $n$-fold integer\nprogram (IP) consists of parameter $A$, dimension $n$, and numerical data of\nbinary encoding length $L$. It was known for some time that such programs can\nbe solved in polynomial time using $O(n^{g(A)}L)$ arithmetic operations where\n$g$ is an exponential function of the parameter. In 2013 it was shown that it\ncan be solved in fixed-parameter tractable (FPT) time using $O(f(A)n^3L)$\narithmetic operations for a single-exponential function $f$. This, and a faster\nalgorithm for a special case of combinatorial $n$-fold IP, have led to several\nvery recent breakthroughs in the parameterized complexity of scheduling,\nstringology, and computational social choice. In 2015 it was shown that it can\nbe solved in strongly polynomial time using $O(n^{g(A)})$ arithmetic\noperations.\n  Here we establish a result which subsumes all three of the above results by\nshowing that $n$-fold IP can be solved in strongly polynomial FPT time using\n$O(f(A)n^3)$ arithmetic operations. In fact, our results are much more general,\nbriefly outlined as follows.\n  - There is a strongly polynomial algorithm for ILP whenever a so-called\nGraver-best oracle is realizable for it.\n  - Graver-best oracles for the large classes of multi-stage stochastic and\ntree-fold ILPs can be realized in FPT time. Together with the previous oracle\nalgorithm, this newly shows two large classes of ILP to be strongly polynomial;\nin contrast, only few classes of ILP were previously known to be strongly\npolynomial.\n  - We show that ILP is FPT parameterized by the largest coefficient\n$\\|A\\|_\\infty$ and the primal or dual treedepth of $A$, and that this\nparameterization cannot be relaxed, signifying substantial progress in\nunderstanding the parameterized complexity of ILP. \n\n"}
{"id": "1802.06575", "contents": "Title: On the Decidability of Reachability in Linear Time-Invariant Systems Abstract: We consider the decidability of state-to-state reachability in linear\ntime-invariant control systems over discrete time. We analyse this problem with\nrespect to the allowable control sets, which in general are assumed to be\ndefined by boolean combinations of linear inequalities. Decidability of the\nversion of the reachability problem in which control sets are affine subspaces\nof $\\mathbb{R}^n$ is a fundamental result in control theory. Our first result\nis that reachability is undecidable if the set of controls is a finite union of\naffine subspaces. We also consider versions of the reachability problem in\nwhich (i)~the set of controls consists of a single affine subspace together\nwith the origin and (ii)~the set of controls is a convex polytope. In these two\ncases we respectively show that the reachability problem is as hard as Skolem's\nProblem and the Positivity Problem for linear recurrence sequences (whose\ndecidability has been open for several decades). Our main contribution is to\nshow decidability of a version of the reachability problem in which control\nsets are convex polytopes, under certain spectral assumptions on the transition\nmatrix. \n\n"}
{"id": "1802.07372", "contents": "Title: Stochastic Variance-Reduced Cubic Regularization for Nonconvex\n  Optimization Abstract: Cubic regularization (CR) is an optimization method with emerging popularity\ndue to its capability to escape saddle points and converge to second-order\nstationary solutions for nonconvex optimization. However, CR encounters a high\nsample complexity issue for finite-sum problems with a large data size.\n%Various inexact variants of CR have been proposed to improve the sample\ncomplexity. In this paper, we propose a stochastic variance-reduced\ncubic-regularization (SVRC) method under random sampling, and study its\nconvergence guarantee as well as sample complexity. We show that the iteration\ncomplexity of SVRC for achieving a second-order stationary solution within\n$\\epsilon$ accuracy is $O(\\epsilon^{-3/2})$, which matches the state-of-art\nresult on CR types of methods. Moreover, our proposed variance reduction scheme\nsignificantly reduces the per-iteration sample complexity. The resulting total\nHessian sample complexity of our SVRC is ${\\Oc}(N^{2/3} \\epsilon^{-3/2})$,\nwhich outperforms the state-of-art result by a factor of $O(N^{2/15})$. We also\nstudy our SVRC under random sampling without replacement scheme, which yields a\nlower per-iteration sample complexity, and hence justifies its practical\napplicability. \n\n"}
{"id": "1802.09113", "contents": "Title: GPU Accelerated Sub-Sampled Newton's Method Abstract: First order methods, which solely rely on gradient information, are commonly\nused in diverse machine learning (ML) and data analysis (DA) applications. This\nis attributed to the simplicity of their implementations, as well as low\nper-iteration computational/storage costs. However, they suffer from\nsignificant disadvantages; most notably, their performance degrades with\nincreasing problem ill-conditioning. Furthermore, they often involve a large\nnumber of hyper-parameters, and are notoriously sensitive to parameters such as\nthe step-size. By incorporating additional information from the Hessian,\nsecond-order methods, have been shown to be resilient to many such adversarial\neffects. However, these advantages of using curvature information come at the\ncost of higher per-iteration costs, which in \\enquote{big data} regimes, can be\ncomputationally prohibitive.\n  In this paper, we show that, contrary to conventional belief, second-order\nmethods, when implemented appropriately, can be more efficient than first-order\nalternatives in many large-scale ML/ DA applications. In particular, in convex\nsettings, we consider variants of classical Newton\\textsf{'}s method in which\nthe Hessian and/or the gradient are randomly sub-sampled. We show that by\neffectively leveraging the power of GPUs, such randomized Newton-type\nalgorithms can be significantly accelerated, and can easily outperform state of\nthe art implementations of existing techniques in popular ML/ DA software\npackages such as TensorFlow. Additionally these randomized methods incur a\nsmall memory overhead compared to first-order methods. In particular, we show\nthat for million-dimensional problems, our GPU accelerated sub-sampled\nNewton\\textsf{'}s method achieves a higher test accuracy in milliseconds as\ncompared with tens of seconds for first order alternatives. \n\n"}
{"id": "1802.09933", "contents": "Title: Guaranteed Sufficient Decrease for Stochastic Variance Reduced Gradient\n  Optimization Abstract: In this paper, we propose a novel sufficient decrease technique for\nstochastic variance reduced gradient descent methods such as SVRG and SAGA. In\norder to make sufficient decrease for stochastic optimization, we design a new\nsufficient decrease criterion, which yields sufficient decrease versions of\nstochastic variance reduction algorithms such as SVRG-SD and SAGA-SD as a\nbyproduct. We introduce a coefficient to scale current iterate and to satisfy\nthe sufficient decrease property, which takes the decisions to shrink, expand\nor even move in the opposite direction, and then give two specific update rules\nof the coefficient for Lasso and ridge regression. Moreover, we analyze the\nconvergence properties of our algorithms for strongly convex problems, which\nshow that our algorithms attain linear convergence rates. We also provide the\nconvergence guarantees of our algorithms for non-strongly convex problems. Our\nexperimental results further verify that our algorithms achieve significantly\nbetter performance than their counterparts. \n\n"}
{"id": "1802.10235", "contents": "Title: Parametrized Accelerated Methods Free of Condition Number Abstract: Analyses of accelerated (momentum-based) gradient descent usually assume\nbounded condition number to obtain exponential convergence rates. However, in\nmany real problems, e.g., kernel methods or deep neural networks, the condition\nnumber, even locally, can be unbounded, unknown or mis-estimated. This poses\nproblems in both implementing and analyzing accelerated algorithms. In this\npaper, we address this issue by proposing parametrized accelerated methods by\nconsidering the condition number as a free parameter. We provide spectral-level\nanalysis for several important accelerated algorithms, obtain explicit\nexpressions and improve worst case convergence rates. Moreover, we show that\nthose algorithm converge exponentially even when the condition number is\nunknown or mis-estimated. \n\n"}
{"id": "1803.00190", "contents": "Title: On the Finite Number of Directional Stationary Values of Piecewise\n  Programs Abstract: Extending a fundamental result for (indefinite) quadratic programs, this\npaper shows that certain non-convex piecewise programs have only a finite\nnumber of directional stationary values, and thus, possess only finitely many\nlocally minimum values. We present various special cases of our main results,\nin particular, an application to a least-squares piecewise affine regression\nproblem for which every directional stationary point is locally minimizing. \n\n"}
{"id": "1803.00301", "contents": "Title: (Sub)Optimal feedback control of mean field multi-population dynamics Abstract: We study a multiscale approach for the control of agent-based, two-population\nmodels. The control variable acts over one population of leaders, which\ninfluence the population of followers via the coupling generated by their\ninteraction. We cast a quadratic optimal control problem for the large-scale\nmicroscale model, which is approximated via a Boltzmann approach. By sampling\nsolutions of the optimal control problem associated to binary two-population\ndynamics, we generate sub-optimal control laws for the kinetic limit of the\nmulti-population model. We present numerical experiments related to opinion\ndynamics assessing the performance of the proposed control design. \n\n"}
{"id": "1803.00420", "contents": "Title: Tractable and Scalable Schatten Quasi-Norm Approximations for Rank\n  Minimization Abstract: The Schatten quasi-norm was introduced to bridge the gap between the trace\nnorm and rank function. However, existing algorithms are too slow or even\nimpractical for large-scale problems. Motivated by the equivalence relation\nbetween the trace norm and its bilinear spectral penalty, we define two\ntractable Schatten norms, i.e.\\ the bi-trace and tri-trace norms, and prove\nthat they are in essence the Schatten-$1/2$ and $1/3$ quasi-norms,\nrespectively. By applying the two defined Schatten quasi-norms to various rank\nminimization problems such as MC and RPCA, we only need to solve much smaller\nfactor matrices. We design two efficient linearized alternating minimization\nalgorithms to solve our problems and establish that each bounded sequence\ngenerated by our algorithms converges to a critical point. We also provide the\nrestricted strong convexity (RSC) based and MC error bounds for our algorithms.\nOur experimental results verified both the efficiency and effectiveness of our\nalgorithms compared with the state-of-the-art methods. \n\n"}
{"id": "1803.00864", "contents": "Title: Game-theoretical model of cooperation between producers in a production\n  process: 3-agent interaction case Abstract: A network model of manufacturing system is considered. This is a network\nformation game where players are participants of a production process and their\nactions are their's requests for interaction. Production networks are formed as\na result of an interaction. Players' payoff functions are defined on the set of\nall possible networks. In this paper the special case of network formation\ngames is considered. Payoff functions are supposed to be additive and depend on\nsubsets of arcs. Two cases are considered. First, subsets of arcs are supposed\nto be not intersected. The necessary and sufficient conditions for equilibrium\nare given for this case. The second case is the one where subsets of arcs are\ndetermined by 3-agent coalitions. An illustrative example is given where\nequilibria and a compromise solution are found. \n\n"}
{"id": "1803.01451", "contents": "Title: Near-optimal planning using approximate dynamic programming to enhance\n  post-hazard community resilience management Abstract: The lack of a comprehensive decision-making approach at the community level\nis an important problem that warrants immediate attention. Network-level\ndecision-making algorithms need to solve large-scale optimization problems that\npose computational challenges. The complexity of the optimization problems\nincreases when various sources of uncertainty are considered. This research\nintroduces a sequential discrete optimization approach, as a decision-making\nframework at the community level for recovery management. The proposed\nmathematical approach leverages approximate dynamic programming along with\nheuristics for the determination of recovery actions. Our methodology overcomes\nthe curse of dimensionality and manages multi-state, large-scale infrastructure\nsystems following disasters. We also provide computational results showing that\nour methodology not only incorporates recovery policies of responsible public\nand private entities within the community but also substantially enhances the\nperformance of their underlying strategies with limited resources. The\nmethodology can be implemented efficiently to identify near-optimal recovery\ndecisions following a severe earthquake based on multiple objectives for an\nelectrical power network of a testbed community coarsely modeled after Gilroy,\nCalifornia, United States. The proposed optimization method supports\nrisk-informed community decision makers within chaotic post-hazard\ncircumstances. \n\n"}
{"id": "1803.01602", "contents": "Title: Feedback control of the acoustic pressure in ultrasonic wave propagation Abstract: Classical models for the propagation of ultrasound waves are the Westervelt\nequation, the Kuznetsov and the Khokhlov-Zabolotskaya-Kuznetsov equations. The\nJordan-Moore-Gibson-Thompson equation is a prominent example of a Partial\nDifferential Equation (PDE) model which describes the acoustic velocity\npotential in ultrasound wave propagation, where the paradox of infinite speed\nof propagation of thermal signals is eliminated; the use of the constitutive\nCattaneo law for the heat flux, in place of the Fourier law, accounts for its\nbeing of third order in time. Aiming at the understanding of the fully\nquasilinear PDE, a great deal of attention has been recently devoted to its\nlinearization -- referred to in the literature as the Moore-Gibson-Thompson\nequation -- whose mathematical analysis is also of independent interest, posing\nalready several questions and challenges. In this work we consider and solve a\nquadratic control problem associated with the linear equation, formulated\nconsistently with the goal of keeping the acoustic pressure close to a\nreference pressure during ultrasound excitation, as required in medical and\nindustrial applications. While optimal control problems with smooth controls\nhave been considered in the recent literature, we aim at relying on controls\nwhich are just $L^2$ in time; this leads to a singular control problem and to\nnon-standard Riccati equations. In spite of the unfavourable combination of the\nsemigroup describing the free dynamics that is not analytic, with the\nchallenging pattern displayed by the dynamics subject to boundary control, a\nfeedback synthesis of the optimal control as well as well-posedness of operator\nRiccati equations are established. \n\n"}
{"id": "1803.01764", "contents": "Title: On Multilateral Hierarchical Dynamic Decisions Abstract: Many decision problems in economics, information technology, and industry can\nbe transformed to an optimal stopping of adapted random vectors with some\nutility function over the set of Markov times with respect to filtration build\nby the decision maker's knowledge. The optimal stopping problem formulation is\nto find a stopping time which maximizes the expected value of the accepted\n(stopped) random vector's utility.\n  There are natural extensions of optimal stopping problem to stopping the\ngames-the problem of stopping random vectors by two or more decision makers.\nVarious approaches dependent on the information scheme and the aims of the\nagents in a considered model. This report unifies a group of non-cooperative\nstopping game models with forced cooperation by the role of the agents, their\naims and aspirations (v. Assaf & Samuel-Cahn(1998), Szajowski & Yasuda(1995))\nor extensions of the strategy sets (v. Ramsey & Szajowski(2008)). \n\n"}
{"id": "1803.01857", "contents": "Title: Universal Quantum Control through Deep Reinforcement Learning Abstract: Emerging reinforcement learning techniques using deep neural networks have\nshown great promise in control optimization. They harness non-local\nregularities of noisy control trajectories and facilitate transfer learning\nbetween tasks. To leverage these powerful capabilities for quantum control\noptimization, we propose a new control framework to simultaneously optimize the\nspeed and fidelity of quantum computation against both leakage and stochastic\ncontrol errors. For a broad family of two-qubit unitary gates that are\nimportant for quantum simulation of many-electron systems, we improve the\ncontrol robustness by adding control noise into training environments for\nreinforcement learning agents trained with trusted-region-policy-optimization.\nThe agent control solutions demonstrate a two-order-of-magnitude reduction in\naverage-gate-error over baseline stochastic-gradient-descent solutions and up\nto a one-order-of-magnitude reduction in gate time from optimal gate synthesis\ncounterparts. \n\n"}
{"id": "1803.02312", "contents": "Title: Dimensionality Reduction for Stationary Time Series via Stochastic\n  Nonconvex Optimization Abstract: Stochastic optimization naturally arises in machine learning. Efficient\nalgorithms with provable guarantees, however, are still largely missing, when\nthe objective function is nonconvex and the data points are dependent. This\npaper studies this fundamental challenge through a streaming PCA problem for\nstationary time series data. Specifically, our goal is to estimate the\nprinciple component of time series data with respect to the covariance matrix\nof the stationary distribution. Computationally, we propose a variant of Oja's\nalgorithm combined with downsampling to control the bias of the stochastic\ngradient caused by the data dependency. Theoretically, we quantify the\nuncertainty of our proposed stochastic algorithm based on diffusion\napproximations. This allows us to prove the asymptotic rate of convergence and\nfurther implies near optimal asymptotic sample complexity. Numerical\nexperiments are provided to support our analysis. \n\n"}
{"id": "1803.02461", "contents": "Title: Subgradient methods for sharp weakly convex functions Abstract: Subgradient methods converge linearly on a convex function that grows sharply\naway from its solution set. In this work, we show that the same is true for\nsharp functions that are only weakly convex, provided that the subgradient\nmethods are initialized within a fixed tube around the solution set. A variety\nof statistical and signal processing tasks come equipped with good\ninitialization, and provably lead to formulations that are both weakly convex\nand sharp. Therefore, in such settings, subgradient methods can serve as\ninexpensive local search procedures. We illustrate the proposed techniques on\nphase retrieval and covariance estimation problems. \n\n"}
{"id": "1803.02652", "contents": "Title: Solving large-scale general phase retrieval problems via a sequence of\n  convex relaxations Abstract: We present a convex relaxation-based algorithm for large-scale general phase\nretrieval problems. General phase retrieval problems include i.a. the\nestimation of the phase of the optical field in the pupil plane based on\nintensity measurements of a point source recorded in the image (focal) plane.\nThe non-convex problem of finding the complex field that generates the correct\nintensity is reformulated into a rank constraint problem. The nuclear norm is\nused to obtain the convex relaxation of the phase retrieval problem. A new\niterative method, indicated as Convex Optimization-based Phase Retrieval\n(COPR), is presented, with each iteration consisting of solving a convex\nproblem. In the noise-free case and for a class of phase retrieval problems the\nsolutions of the minimization problems converge linearly or faster towards a\ncorrect solution. Since the solutions to nuclear norm minimization problems can\nbe computed using semidefinite programming, and this tends to be an expensive\noptimization in terms of scalability, we provide a fast ADMM algorithm that\nexploits the problem structure. The performance of the COPR algorithm is\ndemonstrated in a realistic numerical simulation study, demonstrating its\nimprovements in reliability and speed with respect to state-of-the-art methods. \n\n"}
{"id": "1803.04895", "contents": "Title: Inverse source problem in a forced network Abstract: We address the nonlinear inverse source problem of identifying a\ntime-dependent source occurring in one node of a network governed by a wave\nequation. We prove that time records of the associated state taken at a\nstrategic set of two nodes yield uniqueness of the two unknown elements: the\nsource position and the emitted signal. We develop a non-iterative\nidentification method that localizes the source node by solving a set of well\nposed linear systems. Once the source node is localized, we identify the\nemitted signal using a deconvolution problem or a Fourier expansion. Numerical\nexperiments on a $5$ node graph confirm the effectiveness of the approach. \n\n"}
{"id": "1803.06510", "contents": "Title: Hidden Integrality and Semi-random Robustness of SDP Relaxation for\n  Sub-Gaussian Mixture Model Abstract: We consider the problem of estimating the discrete clustering structures\nunder the Sub-Gaussian Mixture Model. Our main results establish a hidden\nintegrality property of a semidefinite programming (SDP) relaxation for this\nproblem: while the optimal solution to the SDP is not integer-valued in\ngeneral, its estimation error can be upper bounded by that of an idealized\ninteger program. The error of the integer program, and hence that of the SDP,\nare further shown to decay exponentially in the signal-to-noise ratio. In\naddition, we show that the SDP relaxation is robust under the semi-random\nsetting in which an adversary can modify the data generated from the mixture\nmodel. In particular, we generalize the hidden integrality property to the\nsemi-random model and thereby show that SDP achieves the optimal error bound in\nthis setting. These results together highlight the \"global-to-local\" mechanism\nthat drives the performance of the SDP relaxation.\n  To the best of our knowledge, our result is the first exponentially decaying\nerror bound for convex relaxations of mixture models. A corollary of our\nresults shows that in certain regimes the SDP solutions are in fact integral\nand exact. More generally, our results establish sufficient conditions for the\nSDP to correctly recover the cluster memberships of $(1-\\delta)$ fraction of\nthe points for any $\\delta\\in(0,1)$. As a special case, we show that under the\n$d$-dimensional Stochastic Ball Model, SDP achieves non-trivial (sometimes\nexact) recovery when the center separation is as small as $\\sqrt{1/d}$, which\nimproves upon previous exact recovery results that require constant separation. \n\n"}
{"id": "1803.06523", "contents": "Title: Stochastic model-based minimization of weakly convex functions Abstract: We consider a family of algorithms that successively sample and minimize\nsimple stochastic models of the objective function. We show that under\nreasonable conditions on approximation quality and regularity of the models,\nany such algorithm drives a natural stationarity measure to zero at the rate\n$O(k^{-1/4})$. As a consequence, we obtain the first complexity guarantees for\nthe stochastic proximal point, proximal subgradient, and regularized\nGauss-Newton methods for minimizing compositions of convex functions with\nsmooth maps. The guiding principle, underlying the complexity guarantees, is\nthat all algorithms under consideration can be interpreted as approximate\ndescent methods on an implicit smoothing of the problem, given by the Moreau\nenvelope. Specializing to classical circumstances, we obtain the long-sought\nconvergence rate of the stochastic projected gradient method, without batching,\nfor minimizing a smooth function on a closed convex set. \n\n"}
{"id": "1803.07107", "contents": "Title: Computational performance of a projection and rescaling algorithm Abstract: This paper documents a computational implementation of a {\\em projection and\nrescaling algorithm} for finding most interior solutions to the pair of\nfeasibility problems \\[ \\text{find} \\; x\\in L\\cap\\mathbb{R}^n_{+} \\;\\;\\;\\;\n\\text{ and } \\; \\;\\;\\;\\; \\text{find} \\; \\hat x\\in L^\\perp\\cap\\mathbb{R}^n_{+},\n\\] where $L$ denotes a linear subspace in $\\mathbb{R}^n$ and $L^\\perp$ denotes\nits orthogonal complement. The projection and rescaling algorithm is a recently\ndeveloped method that combines a {\\em basic procedure} involving only low-cost\noperations with a periodic {\\em rescaling step.} We give a full description of\na MATLAB implementation of this algorithm and present multiple sets of\nnumerical experiments on synthetic problem instances with varied levels of\nconditioning. Our computational experiments provide promising evidence of the\neffectiveness of the projection and rescaling algorithm.\n  Our MATLAB code is publicly available. Furthermore, the simplicity of the\nalgorithm makes a computational implementation in other environments completely\nstraightforward. \n\n"}
{"id": "1803.07270", "contents": "Title: Optimal Control and Stabilization Problem for Discrete-time Markov Jump\n  Systems with Indefinite Weight Costs Abstract: It is well known that stability is the most fundamental nature with regard to\na control system, in view of this, the stabilization becomes an inevitable\ncontrol problem. This article mainly discusses the optimal control and\nstabilization problem for discrete-time systems involving Markov jump and\nmultiplicative noise. The state and control weighting matrices in the cost\nfunction are allowed to be indefinite. By solving the forward-backward\nstochastic difference equations with Markov jump (FBSDEs-MJ) derived from the\nmaximum principle, we conclude that the necessary and sufficient conditions of\nthe solvability of indefinite optimal control problem in finite-horizon, whose\nmethod is different from most previous works [13], etc. Furthermore, necessary\nand sufficient conditions that stabilize the Markov jump discrete- time systems\nin the mean square sense with indefinite weighting matrices in the cost are\nfirst developed under the basic assumption of exactly observable, which is\ndifferent from the previous works [12], [14] where an additional assumption of\nstabilization of systems is made. The key points of this article can be summed\nup as that an analytic solution to FBSDEs- MJ which makes the optimal\ncontroller to be explicitly expressed and the method of trans- formation, i.e.,\nthe stabilization problem of indefinite case is boiled down to a definite one\nwhose stabilization is expressed by defining Lyapunov function via the optimal\ncost subject to a new algebraic Riccati equation involving Markov jump\n(NGARE-MJ). \n\n"}
{"id": "1803.07818", "contents": "Title: Phase Retrieval via Sensor Network Localization Abstract: The problem of phase retrieval is revisited and studied from a fresh\nperspective. In particular, we establish a connection between the phase\nretrieval problem and the sensor network localization problem, which allows us\nto utilize the vast theoretical and algorithmic literature on the latter to\ntackle the former. Leveraging this connection, we develop a two-stage algorithm\nfor phase retrieval that can provably recover the desired signal. In both\nsparse and dense settings, our proposed algorithm improves upon prior\napproaches simultaneously in the number of required measurements for recovery\nand the reconstruction time. We present numerical results to corroborate our\ntheory and to demonstrate the efficiency of the proposed algorithm. As a side\nresult, we propose a new form of phase retrieval problem and connect it to the\ncomplex rigidity theory proposed by Gortler and Thurston. \n\n"}
{"id": "1803.08079", "contents": "Title: Spectrahedral Lifts of Convex Sets Abstract: Efficient representations of convex sets are of crucial importance for many\nalgorithms that work with them. It is well-known that sometimes, a complicated\nconvex set can be expressed as the projection of a much simpler set in higher\ndimensions called a lift of the original set. This is a brief survey of recent\ndevelopments in the topic of lifts of convex sets. Our focus will be on lifts\nthat arise from affine slices of real positive semidefinite cones known as psd\nor spectrahedral lifts. The main result is that projection representations of a\nconvex set are controlled by factorizations, through closed convex cones, of an\noperator that comes from the convex set. This leads to several research\ndirections and results that lie at the intersection of convex geometry,\ncombinatorics, real algebraic geometry, optimization, computer science and\nmore. \n\n"}
{"id": "1803.08832", "contents": "Title: Golden Ratio Algorithms for Variational Inequalities Abstract: The paper presents a fully explicit algorithm for monotone variational\ninequalities. The method uses variable stepsizes that are computed using two\nprevious iterates as an approximation of the local Lipschitz constant without\nrunning a linesearch. Thus, each iteration of the method requires only one\nevaluation of a monotone operator $F$ and a proximal mapping $g$. The operator\n$F$ need not be Lipschitz-continuous, which also makes the algorithm\ninteresting in the area of composite minimization where one cannot use the\ndescent lemma. The method exhibits an ergodic $O(1/k)$ convergence rate and\n$R$-linear rate, if $F, g$ satisfy the error bound condition. We discuss\npossible applications of the method to fixed point problems. We discuss\npossible applications of the method to fixed point problems as well as its\ndifferent generalizations. \n\n"}
{"id": "1803.08917", "contents": "Title: Byzantine Stochastic Gradient Descent Abstract: This paper studies the problem of distributed stochastic optimization in an\nadversarial setting where, out of the $m$ machines which allegedly compute\nstochastic gradients every iteration, an $\\alpha$-fraction are Byzantine, and\ncan behave arbitrarily and adversarially. Our main result is a variant of\nstochastic gradient descent (SGD) which finds $\\varepsilon$-approximate\nminimizers of convex functions in $T = \\tilde{O}\\big( \\frac{1}{\\varepsilon^2 m}\n+ \\frac{\\alpha^2}{\\varepsilon^2} \\big)$ iterations. In contrast, traditional\nmini-batch SGD needs $T = O\\big( \\frac{1}{\\varepsilon^2 m} \\big)$ iterations,\nbut cannot tolerate Byzantine failures. Further, we provide a lower bound\nshowing that, up to logarithmic factors, our algorithm is\ninformation-theoretically optimal both in terms of sampling complexity and time\ncomplexity. \n\n"}
{"id": "1803.08950", "contents": "Title: Asynchronous Gradient-Push Abstract: We consider a multi-agent framework for distributed optimization where each\nagent has access to a local smooth strongly convex function, and the collective\ngoal is to achieve consensus on the parameters that minimize the sum of the\nagents' local functions. We propose an algorithm wherein each agent operates\nasynchronously and independently of the other agents. When the local functions\nare strongly-convex with Lipschitz-continuous gradients, we show that the\niterates at each agent converge to a neighborhood of the global minimum, where\nthe neighborhood size depends on the degree of asynchrony in the multi-agent\nnetwork. When the agents work at the same rate, convergence to the global\nminimizer is achieved. Numerical experiments demonstrate that Asynchronous\nGradient-Push can minimize the global objective faster than state-of-the-art\nsynchronous first-order methods, is more robust to failing or stalling agents,\nand scales better with the network size. \n\n"}
{"id": "1803.09022", "contents": "Title: Controller Synthesis for Discrete-Time Polynomial Systems via Occupation\n  Measures Abstract: In this paper, we design nonlinear state feedback controllers for\ndiscrete-time polynomial dynamical systems via the occupation measure approach.\nWe propose the discrete-time controlled Liouville equation, and use it to\nformulate the controller synthesis problem as an infinite-dimensional linear\nprogramming problem on measures, which is then relaxed as finite-dimensional\nsemidefinite programming problems on moments of measures and their duals on\nsums-of-squares polynomials. Nonlinear controllers can be extracted from the\nsolutions to the relaxed problems. The advantage of the occupation measure\napproach is that we solve convex problems instead of generally non-convex\nproblems, and the computational complexity is polynomial in the state and input\ndimensions, and hence the approach is more scalable. In addition, we show that\nthe approach can be applied to over-approximating the backward reachable set of\ndiscrete-time autonomous polynomial systems and the controllable set of\ndiscrete-time polynomial systems under known state feedback control laws. We\nillustrate our approach on several dynamical systems. \n\n"}
{"id": "1803.09446", "contents": "Title: Convergent kernel-based methods for parabolic equations Abstract: We prove that the functions constructed by the kernel-based regressions with\nWendland kernels under $\\ell_1$-norm constraints converge to unique viscosity\nsolutions of the corresponding fully nonlinear parabolic equations. A key\ningredient in our proof is the max-min representations of the nonlinearities of\nthe equations. \n\n"}
{"id": "1803.10141", "contents": "Title: New concavity and convexity results for symmetric polynomials and their\n  ratios Abstract: We prove some \"power\" generalizations of Marcus-Lopes-style (including McLeod\nand Bullen) concavity inequalities for elementary symmetric polynomials, and\nconvexity inequalities (of McLeod and Baston) for complete homogeneous\nsymmetric polynomials. Finally, we present sundry concavity results for\nelementary symmetric polynomials, of which the main result is a concavity\ntheorem that among other implies a well-known log-convexity result of Muir\n(1972/74) for positive definite matrices. \n\n"}
{"id": "1803.10359", "contents": "Title: Achieving Linear Convergence in Distributed Asynchronous Multi-agent\n  Optimization Abstract: This papers studies multi-agent (convex and \\emph{nonconvex}) optimization\nover static digraphs. We propose a general distributed \\emph{asynchronous}\nalgorithmic framework whereby i) agents can update their local variables as\nwell as communicate with their neighbors at any time, without any form of\ncoordination; and ii) they can perform their local computations using\n(possibly) delayed, out-of-sync information from the other agents. Delays need\nnot be known to the agent or obey any specific profile, and can also be\ntime-varying (but bounded). The algorithm builds on a tracking mechanism that\nis robust against asynchrony (in the above sense), whose goal is to estimate\nlocally the average of agents' gradients. When applied to strongly convex\nfunctions, we prove that it converges at an R-linear (geometric) rate as long\nas the step-size is {sufficiently small}. A sublinear convergence rate is\nproved, when nonconvex problems and/or diminishing, {\\it uncoordinated}\nstep-sizes are considered. To the best of our knowledge, this is the first\ndistributed algorithm with provable geometric convergence rate in such a\ngeneral asynchronous setting. Preliminary numerical results demonstrate the\nefficacy of the proposed algorithm and validate our theoretical findings. \n\n"}
{"id": "1803.11309", "contents": "Title: Simulation Methods for Stochastic Storage Problems: A Statistical\n  Learning Perspective Abstract: We consider solution of stochastic storage problems through regression Monte\nCarlo (RMC) methods. Taking a statistical learning perspective, we develop the\ndynamic emulation algorithm (DEA) that unifies the different existing\napproaches in a single modular template. We then investigate the two central\naspects of regression architecture and experimental design that constitute DEA.\nFor the regression piece, we discuss various non-parametric approaches, in\nparticular introducing the use of Gaussian process regression in the context of\nstochastic storage. For simulation design, we compare the performance of\ntraditional design (grid discretization), against space-filling, and several\nadaptive alternatives. The overall DEA template is illustrated with multiple\nexamples drawing from natural gas storage valuation and optimal control of\nback-up generator in a microgrid. \n\n"}
{"id": "1804.01357", "contents": "Title: Binary Signaling under Subjective Priors and Costs as a Game Abstract: Many decentralized and networked control problems involve decision makers\nwhich have either misaligned criteria or subjective priors. In the context of\nsuch a setup, in this paper we consider binary signaling problems in which the\ndecision makers (the transmitter and the receiver) have subjective priors\nand/or misaligned objective functions. Depending on the commitment nature of\nthe transmitter to his policies, we formulate the binary signaling problem as a\nBayesian game under either Nash or Stackelberg equilibrium concepts and\nestablish equilibrium solutions and their properties. In addition, the effects\nof subjective priors and costs on Nash and Stackelberg equilibria are analyzed.\nIt is shown that there can be informative or non-informative equilibria in the\nbinary signaling game under the Stackelberg assumption, but there always exists\nan equilibrium. However, apart from the informative and non-informative\nequilibria cases, under certain conditions, there does not exist a Nash\nequilibrium when the receiver is restricted to use deterministic policies. For\nthe corresponding team setup, however, an equilibrium typically always exists\nand is always informative. Furthermore, we investigate the effects of small\nperturbations in priors and costs on equilibrium values around the team setup\n(with identical costs and priors), and show that the Stackelberg equilibrium\nbehavior is not robust to small perturbations whereas the Nash equilibrium is. \n\n"}
{"id": "1804.01829", "contents": "Title: Golden ratio algorithms for solving equilibrium problems in Hilbert\n  spaces Abstract: In this paper, we design a new iterative algorithm for solving pseudomonotone\nequilibrium problems in real Hilbert spaces. The advantage of our algorithm is\nthat it requires only one strongly convex programming problem at each\niteration. Under suitable conditions we establish the strong and weak\nconvergence of the proposed algorithm. The results presented in the paper\nextend and improve some recent results in the literature. The performances and\ncomparisons with some existing methods are presented through numerical\nexamples. \n\n"}
{"id": "1804.02579", "contents": "Title: Adaptive Proximal Method for Variational Inequalities Abstract: A new adaptive approach is proposed for variational inequalities with a\nLipschitz-continuous field. Estimates of the necessary number of iterations are\nobtained to achieve a given quality of the variational inequality solution. A\ngeneralization of the method under consideration to the case of a\nHolder-continuous field is considered. \n\n"}
{"id": "1804.02735", "contents": "Title: Improving QC Relaxations of OPF Problems via Voltage Magnitude\n  Difference Constraints and Envelopes for Trilinear Monomials Abstract: AC optimal power flow (AC~OPF) is a challenging non-convex optimization\nproblem that plays a crucial role in power system operation and control.\nRecently developed convex relaxation techniques provide new insights regarding\nthe global optimality of AC~OPF solutions. The quadratic convex (QC) relaxation\nis one promising approach that constructs convex envelopes around the\ntrigonometric and product terms in the polar representation of the power flow\nequations. This paper proposes two methods for tightening the QC relaxation.\nThe first method introduces new variables that represent the voltage magnitude\ndifferences between connected buses. Using \"bound tightening\" techniques, the\nbounds on the voltage magnitude difference variables can be significantly\nsmaller than the bounds on the voltage magnitudes themselves, so constraints\nbased on voltage magnitude differences can tighten the relaxation. Second,\nrather than a potentially weaker \"nested McCormick\" formulation, this paper\napplies \"Meyer and Floudas\" envelopes that yield the convex hull of the\ntrilinear monomials formed by the product of the voltage magnitudes and\ntrignometric terms in the polar form of the power flow equations. Comparison to\na state-of-the-art QC implementation demonstrates the advantages of these\nimprovements via smaller optimality gaps. \n\n"}
{"id": "1804.04051", "contents": "Title: On Geodesically Convex Formulations for the Brascamp-Lieb Constant Abstract: We consider two non-convex formulations for computing the optimal constant in\nthe Brascamp-Lieb inequality corresponding to a given datum, and show that they\nare geodesically log-concave on the manifold of positive definite matrices\nendowed with the Riemannian metric corresponding to the Hessian of the\nlog-determinant function. The first formulation is present in the work of Lieb\nand the second is inspired by the work of Bennett et al. Recent works of Garg\net al.and Allen-Zhu et al. also imply a geodesically log-concave formulation of\nthe Brascamp-Lieb constant through a reduction to the operator scaling problem.\nHowever, the dimension of the arising optimization problem in their reduction\ndepends exponentially on the number of bits needed to describe the\nBrascamp-Lieb datum. The formulations presented here have dimensions that are\npolynomial in the bit complexity of the input datum. \n\n"}
{"id": "1804.04248", "contents": "Title: Empirical Investigation of Non-Convexities in Optimal Power Flow\n  Problems Abstract: Optimal power flow (OPF) is a central problem in the operation of electric\npower systems. An OPF problem optimizes a specified objective function subject\nto constraints imposed by both the non-linear power flow equations and\nengineering limits. These constraints can yield non-convex feasible spaces that\nresult in significant computational challenges. Despite these non-convexities,\nlocal solution algorithms actually find the global optima of some practical OPF\nproblems. This suggests that OPF problems have a range of difficulty: some\nproblems appear to have convex or \"nearly convex\" feasible spaces in terms of\nthe voltage magnitudes and power injections, while other problems can exhibit\nsignificant non-convexities. Understanding this range of problem difficulty is\nhelpful for creating new test cases for algorithmic benchmarking purposes.\nLeveraging recently developed computational tools for exploring OPF feasible\nspaces, this paper first describes an empirical study that aims to characterize\nnon-convexities for small OPF problems. This paper then proposes and analyzes\nseveral medium-size test cases that challenge a variety of solution algorithms. \n\n"}
{"id": "1804.06384", "contents": "Title: Data-based Distributionally Robust Stochastic Optimal Power Flow, Part\n  II: Case studies Abstract: This is the second part of a two-part paper on data-based distributionally\nrobust stochastic optimal power flow (OPF). The general problem formulation and\nmethodology have been presented in Part I [1]. Here, we present extensive\nnumerical experiments in both distribution and transmission networks to\nillustrate the effectiveness and flexibility of the proposed methodology for\nbalancing efficiency, constraint violation risk, and out-of-sample performance.\nOn the distribution side, the method mitigates overvoltages due to high\nphotovoltaic penetration using local energy storage devices. On the\ntransmission side, the method reduces N-1 security line flow constraint risks\ndue to high wind penetration using reserve policies for controllable\ngenerators. In both cases, the data-based distributionally robust model\npredictive control (MPC) algorithm explicitly utilizes forecast error training\ndatasets, which can be updated online. The numerical results illustrate\ninherent tradeoffs between the operational costs, risks of constraints\nviolations, and out-of-sample performance, offering systematic techniques for\nsystem operators to balance these objectives. \n\n"}
{"id": "1804.06937", "contents": "Title: A sufficient optimality condition for non-linear delayed optimal control\n  problems Abstract: We prove a sufficient optimality condition for non-linear optimal control\nproblems with delays in both state and control variables. Our result requires\nthe verification of a Hamilton-Jacobi partial differential equation and is\nobtained through a transformation that allow us to rewrite a delayed optimal\ncontrol problem as an equivalent non-delayed one. \n\n"}
{"id": "1804.07332", "contents": "Title: Juniper: An Open-Source Nonlinear Branch-and-Bound Solver in Julia Abstract: Nonconvex mixed-integer nonlinear programs (MINLPs) represent a challenging\nclass of optimization problems that often arise in engineering and scientific\napplications. Because of nonconvexities, these programs are typically solved\nwith global optimization algorithms, which have limited scalability. However,\nnonlinear branch-and-bound has recently been shown to be an effective heuristic\nfor quickly finding high-quality solutions to large-scale nonconvex MINLPs,\nsuch as those arising in infrastructure network optimization. This work\nproposes Juniper, a Julia-based open-source solver for nonlinear\nbranch-and-bound. Leveraging the high-level Julia programming language makes it\neasy to modify Juniper's algorithm and explore extensions, such as branching\nheuristics, feasibility pumps, and parallelization. Detailed numerical\nexperiments demonstrate that the initial release of Juniper is comparable with\nother nonlinear branch-and-bound solvers, such as Bonmin, Minotaur, and Knitro,\nillustrating that Juniper provides a strong foundation for further exploration\nin utilizing nonlinear branch-and-bound algorithms as heuristics for nonconvex\nMINLPs. \n\n"}
{"id": "1804.07565", "contents": "Title: Moments and convex optimization for analysis and control of nonlinear\n  partial differential equations Abstract: This work presents a convex-optimization-based framework for analysis and\ncontrol of nonlinear partial differential equations. The approach uses a\nparticular weak embedding of the nonlinear PDE, resulting in a linear equation\nin the space of Borel measures. This equation is then used as a constraint of\nan infinite-dimensional linear programming problem (LP). This LP is then\napproximated by a hierarchy of convex, finite-dimensional, semidefinite\nprogramming problems (SDPs). In the case of analysis of uncontrolled PDEs, the\nsolutions to these SDPs provide bounds on a specified, possibly nonlinear,\nfunctional of the solutions to the PDE; in the case of PDE control, the\nsolutions to these SDPs provide bounds on the optimal value of a given optimal\ncontrol problem as well as suboptimal feedback controllers. The entire approach\nis based purely on convex optimization and does not rely on spatio-temporal\ngridding, even though the PDE addressed can be fully nonlinear. The approach is\napplicable to a very broad class nonlinear PDEs with polynomial data.\nComputational complexity is analyzed and several complexity reduction\nprocedures are described. Numerical examples demonstrate the approach. \n\n"}
{"id": "1804.07634", "contents": "Title: On a monotone scheme for nonconvex nonsmooth optimization with\n  applications to fracture mechanics Abstract: A general class of nonconvex optimization problems is considered, where the\npenalty is the composition of a linear operator with a nonsmooth nonconvex\nmapping, which is concave on the positive real line. The necessary optimality\ncondition of a regularized version of the original problem is solved by means\nof a monotonically convergent scheme. Such problems arise in continuum\nmechanics, as for instance cohesive fractures, where singular behaviour is\nusually modelled by nonsmooth nonconvex energies. The proposed algorithm is\nsuccessfully tested for fracture mechanics problems. Its performance is also\ncompared to two alternative algorithms for nonsmooth nonconvex optimization\narising in optimal control and mathematical imaging. \n\n"}
{"id": "1804.08697", "contents": "Title: Simultaneous shot inversion for nonuniform geometries using fast data\n  interpolation Abstract: Stochastic optimization is key to efficient inversion in PDE-constrained\noptimization. Using 'simultaneous shots', or random superposition of source\nterms, works very well in simple acquisition geometries where all sources see\nall receivers, but this rarely occurs in practice. We develop an approach that\ninterpolates data to an ideal acquisition geometry while solving the inverse\nproblem using simultaneous shots. The approach is formulated as a joint inverse\nproblem, combining ideas from low-rank interpolation with full-waveform\ninversion. Results using synthetic experiments illustrate the flexibility and\nefficiency of the approach. \n\n"}
{"id": "1804.09349", "contents": "Title: Stability Properties of Systems of Linear Stochastic Differential\n  Equations with Random Coefficients Abstract: This work is concerned with the stability properties of linear stochastic\ndifferential equations with random (drift and diffusion) coefficient matrices,\nand the stability of a corresponding random transition matrix (or exponential\nsemigroup). We consider a class of random matrix drift coefficients that\ninvolves random perturbations of an exponentially stable flow of deterministic\n(time-varying) drift matrices. In contrast with more conventional studies, our\nanalysis is not based on the existence of Lyapunov functions, and it does not\nrely on any ergodic properties. These approaches are often difficult to apply\nin practice when the drift/diffusion coefficients are random. We present rather\nweak and easily checked perturbation-type conditions for the asymptotic\nstability of time-varying and random linear stochastic differential equations.\nWe provide new log-Lyapunov estimates and exponential contraction inequalities\non any time horizon as soon as the fluctuation parameter is sufficiently small.\nThese seem to be the first results of this type for this class of linear\nstochastic differential equations with random coefficient matrices. \n\n"}
{"id": "1804.09554", "contents": "Title: Stochastic Conditional Gradient Methods: From Convex Minimization to\n  Submodular Maximization Abstract: This paper considers stochastic optimization problems for a large class of\nobjective functions, including convex and continuous submodular. Stochastic\nproximal gradient methods have been widely used to solve such problems;\nhowever, their applicability remains limited when the problem dimension is\nlarge and the projection onto a convex set is costly. Instead, stochastic\nconditional gradient methods are proposed as an alternative solution relying on\n(i) Approximating gradients via a simple averaging technique requiring a single\nstochastic gradient evaluation per iteration; (ii) Solving a linear program to\ncompute the descent/ascent direction. The averaging technique reduces the noise\nof gradient approximations as time progresses, and replacing projection step in\nproximal methods by a linear program lowers the computational complexity of\neach iteration. We show that under convexity and smoothness assumptions, our\nproposed method converges to the optimal objective function value at a\nsublinear rate of $O(1/t^{1/3})$. Further, for a monotone and continuous\nDR-submodular function and subject to a general convex body constraint, we\nprove that our proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with\n$O(1/\\eps^3)$ stochastic gradient computations. This guarantee matches the\nknown hardness results and closes the gap between deterministic and stochastic\ncontinuous submodular maximization. Additionally, we obtain $((1/e)OPT -\\eps)$\nguarantee after using $O(1/\\eps^3)$ stochastic gradients for the case that the\nobjective function is continuous DR-submodular but non-monotone and the\nconstraint set is down-closed. By using stochastic continuous optimization as\nan interface, we provide the first $(1-1/e)$ tight approximation guarantee for\nmaximizing a monotone but stochastic submodular set function subject to a\nmatroid constraint and $(1/e)$ approximation guarantee for the non-monotone\ncase. \n\n"}
{"id": "1804.10079", "contents": "Title: On stochastic optimization methods for Monte Carlo least-squares\n  problems Abstract: This work presents stochastic optimization methods targeted at least-squares\nproblems involving Monte Carlo integration. While the most common approach to\nsolving these problems is to apply stochastic gradient descent (SGD) or similar\nmethods such as AdaGrad and Adam, which involve estimating a stochastic\ngradient from a small number of Monte Carlo samples computed at each iteration,\nwe show that for this category of problems it is possible to achieve faster\nasymptotic convergence rates using an increasing number of samples per\niteration instead, a strategy we call increasing precision (IP). We then\nimprove pre-asymptotic convergence by introducing a hybrid approach that\ncombines the qualities of increasing precision and otherwise \"constant\"\nprecision, resulting in methods such as the IP-SGD hybrid and IP-AdaGrad\nhybrid, essentially by modifying their gradient estimators to have an\nequivalent effect to increasing precision. Finally, we observe that, in some\nproblems, incorporating a Gauss-Newton preconditioner to the IP-SGD hybrid\nmethod can provide much better convergence than employing a Quasi-Newton\napproach or covariance-preconditioning as in AdaGrad or Adam. \n\n"}
{"id": "1805.00681", "contents": "Title: ADMM-MCP Framework for Sparse Recovery with Global Convergence Abstract: In compressed sensing, the l0-norm minimization of sparse signal\nreconstruction is NP-hard. Recent work shows that compared with the best convex\nrelaxation (l1-norm), nonconvex penalties can better approximate the l0-norm\nand can reconstruct the signal based on fewer observations. In this paper, the\noriginal problem is relaxed by using minimax concave penalty (MCP). Then\nalternating direction method of multipliers (ADMM) and modified iterative hard\nthresholding method are used to solve the problem. Under certain reasonable\nassumptions, the global convergence of the proposed method is proved. The\nparameter setting is also discussed. Finally, through simulations and\ncomparisons with several state-of-the-art algorithms, the effectiveness of\nproposed method is confirmed. \n\n"}
{"id": "1805.01073", "contents": "Title: Strong Metric (Sub)regularity of KKT Mappings for Piecewise\n  Linear-Quadratic Convex-Composite Optimization Abstract: This work concerns the local convergence theory of Newton and quasi-Newton\nmethods for convex-composite optimization: minimize f(x):=h(c(x)), where h is\nan infinite-valued proper convex function and c is C^2-smooth. We focus on the\ncase where h is infinite-valued piecewise linear-quadratic and convex. Such\nproblems include nonlinear programming, mini-max optimization, estimation of\nnonlinear dynamics with non-Gaussian noise as well as many modern approaches to\nlarge-scale data analysis and machine learning. Our approach embeds the\noptimality conditions for convex-composite optimization problems into a\ngeneralized equation. We establish conditions for strong metric subregularity\nand strong metric regularity of the corresponding set-valued mappings. This\nallows us to extend classical convergence of Newton and quasi-Newton methods to\nthe broader class of non-finite valued piecewise linear-quadratic\nconvex-composite optimization problems. In particular we establish local\nquadratic convergence of the Newton method under conditions that parallel those\nin nonlinear programming when h is non-finite valued piecewise linear. \n\n"}
{"id": "1805.01914", "contents": "Title: Optimal time delays in a class of reaction-diffusion equations Abstract: A class of semilinear parabolic reaction diffusion equations with multiple\ntime delays is considered. These time delays and corresponding weights are to\nbe optimized such that the associated solution of the delay equation is the\nbest approximation of a desired state function. The differentiability of the\nmapping is proved that associates the solution of the delay equation to the\nvector of weights and delays. Based on an adjoint calculus, first-order\nnecessary optimality conditions are derived. Numerical test examples show the\napplicability of the concept of optimizing time delays. \n\n"}
{"id": "1805.01916", "contents": "Title: Analysis of nonsmooth stochastic approximation: the differential\n  inclusion approach Abstract: In this paper we address the convergence of stochastic approximation when the\nfunctions to be minimized are not convex and nonsmooth. We show that the\n\"mean-limit\" approach to the convergence which leads, for smooth problems, to\nthe ODE approach can be adapted to the non-smooth case. The limiting dynamical\nsystem may be shown to be, under appropriate assumption, a differential\ninclusion. Our results expand earlier works in this direction by Benaim et al.\n(2005) and provide a general framework for proving convergence for\nunconstrained and constrained stochastic approximation problems, with either\nexplicit or implicit updates. In particular, our results allow us to establish\nthe convergence of stochastic subgradient and proximal stochastic gradient\ndescent algorithms arising in a large class of deep learning and\nhigh-dimensional statistical inference with sparsity inducing penalties. \n\n"}
{"id": "1805.02338", "contents": "Title: Implementation of Stochastic Quasi-Newton's Method in PyTorch Abstract: In this paper, we implement the Stochastic Damped LBFGS (SdLBFGS) for\nstochastic non-convex optimization. We make two important modifications to the\noriginal SdLBFGS algorithm. First, by initializing the Hessian at each step\nusing an identity matrix, the algorithm converges better than original\nalgorithm. Second, by performing direction normalization we could gain stable\noptimization procedure without line search. Experiments on minimizing a 2D\nnon-convex function shows that our improved algorithm converges better than\noriginal algorithm, and experiments on the CIFAR10 and MNIST datasets show that\nour improved algorithm works stably and gives comparable or even better testing\naccuracies than first order optimizers SGD, Adagrad, and second order\noptimizers LBFGS in PyTorch. \n\n"}
{"id": "1805.02639", "contents": "Title: Viscosity Solutions to Parabolic Master Equations and McKean-Vlasov SDEs\n  with Closed-loop Controls Abstract: The master equation is a type of PDE whose state variable involves the\ndistribution of certain underlying state process. It is a powerful tool for\nstudying the limit behavior of large interacting systems, including mean field\ngames and systemic risk. It also appears naturally in stochastic control\nproblems with partial information and in time inconsistent problems. In this\npaper we propose a novel notion of viscosity solution for parabolic master\nequations, arising mainly from control problems, and establish its\nwellposedness. Our main innovation is to restrict the involved measures to\ncertain set of semimartingale measures which satisfy the desired compactness.\nAs an important example, we study the HJB master equation associated with the\ncontrol problems for McKean-Vlasov SDEs. Due to practical considerations, we\nconsider closed-loop controls. It turns out that the regularity of the value\nfunction becomes much more involved in this framework than the counterpart in\nthe standard control problems. Finally, we build the whole theory in the path\ndependent setting, which is often seen in applications. The main result in this\npart is an extension of Dupire \\cite{Dupire}'s functional It\\^{o} formula. This\nIt\\^{o} formula requires a special structure of the derivatives with respect to\nthe measures, which was originally due to Lions \\cite{Lions4} in the state\ndependent case. We provided an elementary proof for this well known result in\nthe short note \\cite{WZ}, and the same arguments work in the path dependent\nsetting here. \n\n"}
{"id": "1805.02954", "contents": "Title: Combinatorial Hopf algebra for interconnected nonlinear systems Abstract: A detailed expose of the Hopf algebra approach to interconnected input-output\nsystems in nonlinear control theory is presented. The focus is on input-output\nsystems that can been represented in terms of Chen-Fliess functional expansions\nor Fliess operators. This provides a starting point for a discrete-time version\nof this theory. In particular, the notion of a discrete-time Fliess operator is\ngiven and a class of parallel interconnections is described. \n\n"}
{"id": "1805.03090", "contents": "Title: Deception in Optimal Control Abstract: In this paper, we consider an adversarial scenario where one agent seeks to\nachieve an objective and its adversary seeks to learn the agent's intentions\nand prevent the agent from achieving its objective. The agent has an incentive\nto try to deceive the adversary about its intentions, while at the same time\nworking to achieve its objective. The primary contribution of this paper is to\nintroduce a mathematically rigorous framework for the notion of deception\nwithin the context of optimal control. The central notion introduced in the\npaper is that of a belief-induced reward: a reward dependent not only on the\nagent's state and action, but also adversary's beliefs. Design of an optimal\ndeceptive strategy then becomes a question of optimal control design on the\nproduct of the agent's state space and the adversary's belief space. The\nproposed framework allows for deception to be defined in an arbitrary control\nsystem endowed with a reward function, as well as with additional\nspecifications limiting the agent's control policy. In addition to defining\ndeception, we discuss design of optimally deceptive strategies under\nuncertainties in agent's knowledge about the adversary's learning process. In\nthe latter part of the paper, we focus on a setting where the agent's behavior\nis governed by a Markov decision process, and show that the design of optimally\ndeceptive strategies under lack of knowledge about the adversary naturally\nreduces to previously discussed problems in control design on partially\nobservable or uncertain Markov decision processes. Finally, we present two\nexamples of deceptive strategies: a \"cops and robbers\" scenario and an example\nwhere an agent may use camouflage while moving. We show that optimally\ndeceptive strategies in such examples follow the intuitive idea of how to\ndeceive an adversary in the above settings. \n\n"}
{"id": "1805.03809", "contents": "Title: Polyhedral-based Methods for Mixed-Integer SOCP in Tree Breeding Abstract: Optimal contribution selection (OCS) is a mathematical optimization problem\nthat aims to maximize the total benefit from selecting a group of individuals\nunder a constraint on genetic diversity. We are specifically focused on OCS as\napplied to forest tree breeding, when selected individuals will contribute\nequally to the gene pool. Since the diversity constraint in OCS can be\ndescribed with a second-order cone, equal deployment in OCS can be\nmathematically modeled as mixed-integer second-order cone programming\n(MI-SOCP). If we apply a general solver for MI-SOCP, non-linearity embedded in\nOCS requires a heavy computation cost. To address this problem, we propose an\nimplementation of lifted polyhedral programming (LPP) relaxation and a\ncone-decomposition method (CDM) to generate effective linear approximations for\nOCS. In particular, CDM successively solves OCS problems much faster than\ngeneric approaches for MI-SOCP. The approach of CDM is not limited to OCS, so\nthat we can also apply the approach to other MI-SOCP problems. \n\n"}
{"id": "1805.04965", "contents": "Title: A Matrix Representation of the Multiple Vehicle Routing Problem for\n  Pickup and Delivery Abstract: This paper develops a computationally efficient algorithm for the Multiple\nVehicle Pickup and Delivery Problem (MVPDP) with the objective of minimizing\nthe tour cost incurred while completing the task of pickup and delivery of\ncustomers. To this end, this paper constructs a novel 0-1 Integer Quadratic\nProgramming (IQP) problem to exactly solve the MVPDP. Compared to the\nstate-of-the-art Mixed Integer Linear Programming (MILP) formulation of the\nproblem, the one presented here requires fewer constraints and decision\nvariables. To ensure that this IQP formulation of the MVPDP can be solved in a\ncomputationally efficient manner, this paper devises a set of sufficient\nconditions to ensure convexity of this formulation when the integer variables\nare relaxed. In addition, this paper describes a transformation to map any\nnon-convex IQP formulation of the MVPDP into an equivalent convex one. The\nsuperior computational efficacy of this convex IQP method when compared to the\nstate-of-the-art MILP formulation is demonstrated through extensive simulated\nand real-world experiments. \n\n"}
{"id": "1805.05411", "contents": "Title: Accelerated Stochastic Algorithms for Nonconvex Finite-sum and\n  Multi-block Optimization Abstract: In this paper, we present new stochastic methods for solving two important\nclasses of nonconvex optimization problems. We first introduce a randomized\naccelerated proximal gradient (RapGrad) method for solving a class of nonconvex\noptimization problems consisting of the sum of $m$ component functions, and\nshow that it can significantly reduce the number of gradient computations\nespecially when the condition number $L/\\mu$ (i.e., the ratio between the\nLipschitz constant and negative curvature) is large. More specifically, RapGrad\ncan save up to ${\\cal O}(\\sqrt{m})$ gradient computations than existing\ndeterministic nonconvex accelerated gradient methods. Moreover, the number of\ngradient computations required by RapGrad can be ${\\cal O}(m^\\frac{1}{6}\nL^\\frac{1}{2} / \\mu^\\frac{1}{2})$ (at least ${\\cal O}(m^\\frac{2}{3})$) times\nsmaller than the best-known randomized nonconvex gradient methods when $L/\\mu\n\\ge m$. Inspired by RapGrad, we also develop a new randomized accelerated\nproximal dual (RapDual) method for solving a class of multi-block nonconvex\noptimization problems coupled with linear constraints. We demonstrate that\nRapDual can also save up to a factor of ${\\cal O}(\\sqrt{m})$ projection\nsubproblems than its deterministic counterpart, where $m$ denotes the number of\nblocks. To the best of our knowledge, all these complexity results associated\nwith RapGrad and RapDual seem to be new in the literature. We also illustrate\npotential advantages of these algorithms through our preliminary numerical\nexperiments. \n\n"}
{"id": "1805.05940", "contents": "Title: Finite mean field games: fictitious play and convergence to a first\n  order continuous mean field game Abstract: In this article we consider finite Mean Field Games (MFGs), i.e. with finite\ntime and finite states. We adopt the framework introduced in Gomes Mohr and\nSouza in 2010, and study two seemly unexplored subjects. In the first one, we\nanalyze the convergence of the fictitious play learning procedure, inspired by\nthe results in continuous MFGs. In the second one, we consider the relation of\nsome finite MFGs and continuous first order MFGs. Namely, given a continuous\nfirst order MFG problem and a sequence of refined space/time grids, we\nconstruct a sequence finite MFGs whose solutions admit limits points and every\nsuch limit point solves the continuous first order MFG problem. \n\n"}
{"id": "1805.06094", "contents": "Title: A Framework to Integrate Mode Choice in the Design of Mobility-on-Demand\n  Systems Abstract: Mobility-on-Demand (MoD) systems are generally designed and analyzed for a\nfixed and exogenous demand, but such frameworks fail to answer questions about\nthe impact of these services on the urban transportation system, such as the\neffect of induced demand and the implications for transit ridership. In this\nstudy, we propose a unified framework to design, optimize and analyze MoD\noperations within a multimodal transportation system where the demand for a\ntravel mode is a function of its level of service. An application of Bayesian\noptimization (BO) to derive the optimal supply-side MoD parameters (e.g., fleet\nsize and fare) is also illustrated. The proposed framework is calibrated using\nthe taxi demand data in Manhattan, New York. Travel demand is served by public\ntransit and MoD services of varying passenger capacities (1, 4 and 10), and\npassengers are predicted to choose travel modes according to a mode choice\nmodel. This choice model is estimated using stated preference data collected in\nNew York City. The convergence of the multimodal supply-demand system and the\nsuperiority of the BO-based optimization method over earlier approaches are\nestablished through numerical experiments. We finally consider a policy\nintervention where the government imposes a tax on the ride-hailing service and\nillustrate how the proposed framework can quantify the pros and cons of such\npolicies for different stakeholders. \n\n"}
{"id": "1805.06137", "contents": "Title: An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal\n  Extra-Gradient Method Abstract: We propose a novel algorithmic framework of Variable Metric Over-Relaxed\nHybrid Proximal Extra-gradient (VMOR-HPE) method with a global convergence\nguarantee for the maximal monotone operator inclusion problem. Its iteration\ncomplexities and local linear convergence rate are provided, which\ntheoretically demonstrate that a large over-relaxed step-size contributes to\naccelerating the proposed VMOR-HPE as a byproduct. Specifically, we find that a\nlarge class of primal and primal-dual operator splitting algorithms are all\nspecial cases of VMOR-HPE. Hence, the proposed framework offers a new insight\ninto these operator splitting algorithms. In addition, we apply VMOR-HPE to the\nKarush-Kuhn-Tucker (KKT) generalized equation of linear equality constrained\nmulti-block composite convex optimization, yielding a new algorithm, namely\nnonsymmetric Proximal Alternating Direction Method of Multipliers with a\npreconditioned Extra-gradient step in which the preconditioned metric is\ngenerated by a blockwise Barzilai-Borwein line search technique (PADMM-EBB). We\nalso establish iteration complexities of PADMM-EBB in terms of the KKT\nresidual. Finally, we apply PADMM-EBB to handle the nonnegative dual graph\nregularized low-rank representation problem. Promising results on synthetic and\nreal datasets corroborate the efficacy of PADMM-EBB. \n\n"}
{"id": "1805.06523", "contents": "Title: End-to-end Learning of a Convolutional Neural Network via Deep Tensor\n  Decomposition Abstract: In this paper we study the problem of learning the weights of a deep\nconvolutional neural network. We consider a network where convolutions are\ncarried out over non-overlapping patches with a single kernel in each layer. We\ndevelop an algorithm for simultaneously learning all the kernels from the\ntraining data. Our approach dubbed Deep Tensor Decomposition (DeepTD) is based\non a rank-1 tensor decomposition. We theoretically investigate DeepTD under a\nrealizable model for the training data where the inputs are chosen i.i.d. from\na Gaussian distribution and the labels are generated according to planted\nconvolutional kernels. We show that DeepTD is data-efficient and provably works\nas soon as the sample size exceeds the total number of convolutional weights in\nthe network. We carry out a variety of numerical experiments to investigate the\neffectiveness of DeepTD and verify our theoretical findings. \n\n"}
{"id": "1805.07194", "contents": "Title: Distributionally Robust Inverse Covariance Estimation: The Wasserstein\n  Shrinkage Estimator Abstract: We introduce a distributionally robust maximum likelihood estimation model\nwith a Wasserstein ambiguity set to infer the inverse covariance matrix of a\n$p$-dimensional Gaussian random vector from $n$ independent samples. The\nproposed model minimizes the worst case (maximum) of Stein's loss across all\nnormal reference distributions within a prescribed Wasserstein distance from\nthe normal distribution characterized by the sample mean and the sample\ncovariance matrix. We prove that this estimation problem is equivalent to a\nsemidefinite program that is tractable in theory but beyond the reach of\ngeneral purpose solvers for practically relevant problem dimensions $p$. In the\nabsence of any prior structural information, the estimation problem has an\nanalytical solution that is naturally interpreted as a nonlinear shrinkage\nestimator. Besides being invertible and well-conditioned even for $p>n$, the\nnew shrinkage estimator is rotation-equivariant and preserves the order of the\neigenvalues of the sample covariance matrix. These desirable properties are not\nimposed ad hoc but emerge naturally from the underlying distributionally robust\noptimization model. Finally, we develop a sequential quadratic approximation\nalgorithm for efficiently solving the general estimation problem subject to\nconditional independence constraints typically encountered in Gaussian\ngraphical models. \n\n"}
{"id": "1805.07474", "contents": "Title: Projection-Free Bandit Convex Optimization Abstract: In this paper, we propose the first computationally efficient projection-free\nalgorithm for bandit convex optimization (BCO). We show that our algorithm\nachieves a sublinear regret of $O(nT^{4/5})$ (where $T$ is the horizon and $n$\nis the dimension) for any bounded convex functions with uniformly bounded\ngradients. We also evaluate the performance of our algorithm against baselines\non both synthetic and real data sets for quadratic programming, portfolio\nselection and matrix completion problems. \n\n"}
{"id": "1805.07495", "contents": "Title: M-estimation with the Trimmed l1 Penalty Abstract: We study high-dimensional estimators with the trimmed $\\ell_1$ penalty, which\nleaves the $h$ largest parameter entries penalty-free. While optimization\ntechniques for this nonconvex penalty have been studied, the statistical\nproperties have not yet been analyzed. We present the first statistical\nanalyses for $M$-estimation and characterize support recovery, $\\ell_\\infty$\nand $\\ell_2$ error of the trimmed $\\ell_1$ estimates as a function of the\ntrimming parameter $h$. Our results show different regimes based on how $h$\ncompares to the true support size. Our second contribution is a new algorithm\nfor the trimmed regularization problem, which has the same theoretical\nconvergence rate as the difference of convex (DC) algorithms, but in practice\nis faster and finds lower objective values. Empirical evaluation of $\\ell_1$\ntrimming for sparse linear regression and graphical model estimation indicate\nthat trimmed $\\ell_1$ can outperform vanilla $\\ell_1$ and non-convex\nalternatives. Our last contribution is to show that the trimmed penalty is\nbeneficial beyond $M$-estimation, and yields promising results for two deep\nlearning tasks: input structures recovery and network sparsification. \n\n"}
{"id": "1805.08890", "contents": "Title: Step Size Matters in Deep Learning Abstract: Training a neural network with the gradient descent algorithm gives rise to a\ndiscrete-time nonlinear dynamical system. Consequently, behaviors that are\ntypically observed in these systems emerge during training, such as convergence\nto an orbit but not to a fixed point or dependence of convergence on the\ninitialization. Step size of the algorithm plays a critical role in these\nbehaviors: it determines the subset of the local optima that the algorithm can\nconverge to, and it specifies the magnitude of the oscillations if the\nalgorithm converges to an orbit. To elucidate the effects of the step size on\ntraining of neural networks, we study the gradient descent algorithm as a\ndiscrete-time dynamical system, and by analyzing the Lyapunov stability of\ndifferent solutions, we show the relationship between the step size of the\nalgorithm and the solutions that can be obtained with this algorithm. The\nresults provide an explanation for several phenomena observed in practice,\nincluding the deterioration in the training error with increased depth, the\nhardness of estimating linear mappings with large singular values, and the\ndistinct performance of deep residual networks. \n\n"}
{"id": "1805.09293", "contents": "Title: Learning to Optimize Contextually Constrained Problems for Real-Time\n  Decision-Generation Abstract: The topic of learning to solve optimization problems has received interest\nfrom both the operations research and machine learning communities. In this\nwork, we combine techniques from both fields to address the problem of learning\nto generate decisions to instances of continuous optimization problems where\nthe feasible set varies with contextual features. We propose a novel framework\nfor training a generative model to estimate optimal decisions by combining\ninterior point methods and adversarial learning, which we further embed within\nan data generation algorithm. Decisions generated by our model satisfy\nin-sample and out-of-sample optimality guarantees. Finally, we investigate case\nstudies in portfolio optimization and personalized treatment design,\ndemonstrating that our approach yields advantages over predict-then-optimize\nand supervised deep learning techniques, respectively. \n\n"}
{"id": "1805.09388", "contents": "Title: Regret Bounds for Robust Adaptive Control of the Linear Quadratic\n  Regulator Abstract: We consider adaptive control of the Linear Quadratic Regulator (LQR), where\nan unknown linear system is controlled subject to quadratic costs. Leveraging\nrecent developments in the estimation of linear systems and in robust\ncontroller synthesis, we present the first provably polynomial time algorithm\nthat provides high probability guarantees of sub-linear regret on this problem.\nWe further study the interplay between regret minimization and parameter\nestimation by proving a lower bound on the expected regret in terms of the\nexploration schedule used by any algorithm. Finally, we conduct a numerical\nstudy comparing our robust adaptive algorithm to other methods from the\nadaptive LQR literature, and demonstrate the flexibility of our proposed method\nby extending it to a demand forecasting problem subject to state constraints. \n\n"}
{"id": "1805.09453", "contents": "Title: Solving Large-Scale Optimization Problems with a Convergence Rate\n  Independent of Grid Size Abstract: We present a primal-dual method to solve L1-type non-smooth optimization\nproblems independently of the grid size. We apply these results to two\nimportant problems : the Rudin-Osher-Fatemi image denoising model and the L1\nearth mover's distance from optimal transport. Crucially, we provide analysis\nthat determines the choice of optimal step sizes and we prove that our method\nconverges independently of the grid size. Our approach allows us to solve these\nproblems on grids as large as 4096 by 4096 in a few minutes without\nparallelization. \n\n"}
{"id": "1805.09480", "contents": "Title: Optimal Algorithms for Continuous Non-monotone Submodular and\n  DR-Submodular Maximization Abstract: In this paper we study the fundamental problems of maximizing a continuous\nnon-monotone submodular function over the hypercube, both with and without\ncoordinate-wise concavity. This family of optimization problems has several\napplications in machine learning, economics, and communication systems. Our\nmain result is the first $\\frac{1}{2}$-approximation algorithm for continuous\nsubmodular function maximization; this approximation factor of $\\frac{1}{2}$ is\nthe best possible for algorithms that only query the objective function at\npolynomially many points. For the special case of DR-submodular maximization,\ni.e. when the submodular functions is also coordinate wise concave along all\ncoordinates, we provide a different $\\frac{1}{2}$-approximation algorithm that\nruns in quasilinear time. Both of these results improve upon prior work [Bian\net al, 2017, Soma and Yoshida, 2017].\n  Our first algorithm uses novel ideas such as reducing the guaranteed\napproximation problem to analyzing a zero-sum game for each coordinate, and\nincorporates the geometry of this zero-sum game to fix the value at this\ncoordinate. Our second algorithm exploits coordinate-wise concavity to identify\na monotone equilibrium condition sufficient for getting the required\napproximation guarantee, and hunts for the equilibrium point using binary\nsearch. We further run experiments to verify the performance of our proposed\nalgorithms in related machine learning applications. \n\n"}
{"id": "1805.11454", "contents": "Title: Distributed Stochastic Gradient Tracking Methods Abstract: In this paper, we study the problem of distributed multi-agent optimization\nover a network, where each agent possesses a local cost function that is smooth\nand strongly convex. The global objective is to find a common solution that\nminimizes the average of all cost functions. Assuming agents only have access\nto unbiased estimates of the gradients of their local cost functions, we\nconsider a distributed stochastic gradient tracking method (DSGT) and a\ngossip-like stochastic gradient tracking method (GSGT). We show that, in\nexpectation, the iterates generated by each agent are attracted to a\nneighborhood of the optimal solution, where they accumulate exponentially fast\n(under a constant stepsize choice). Under DSGT, the limiting (expected) error\nbounds on the distance of the iterates from the optimal solution decrease with\nthe network size $n$, which is a comparable performance to a centralized\nstochastic gradient algorithm. Moreover, we show that when the network is\nwell-connected, GSGT incurs lower communication cost than DSGT while\nmaintaining a similar computational cost. Numerical example further\ndemonstrates the effectiveness of the proposed methods. \n\n"}
{"id": "1805.12035", "contents": "Title: Optimal dividends with partial information and stopping of a degenerate\n  reflecting diffusion Abstract: We study the optimal dividend problem for a firm's manager who has partial\ninformation on the profitability of the firm. The problem is formulated as one\nof singular stochastic control with partial information on the drift of the\nunderlying process and with absorption. In the Markovian formulation, we have a\n2-dimensional degenerate diffusion, whose first component is singularly\ncontrolled and it is absorbed as it hits zero. The free boundary problem (FBP)\nassociated to the value function of the control problem is challenging from the\nanalytical point of view due to the interplay of degeneracy and absorption. We\nfind a probabilistic way to show that the value function of the dividend\nproblem is a smooth solution of the FBP and to construct an optimal dividend\nstrategy. Our approach establishes a new link between multidimensional singular\nstochastic control problems with absorption and problems of optimal stopping\nwith `creation'. One key feature of the stopping problem is that creation\noccurs at a state-dependent rate of the `local-time' of an auxiliary\n2-dimensional reflecting diffusion. \n\n"}
{"id": "1805.12452", "contents": "Title: Grid-side Flexibility of Power Systems in Integrating Large-scale\n  Renewable Generations: A Critical Review on Concepts, Formulations and\n  Solution Approaches Abstract: Though considerable effort has been devoted to exploiting generation-side and\ndemand-side operational flexibility in order to cope with uncertain renewable\ngenerations, grid-side operational flexibility has not been fully investigated.\nIn this review, we define grid-side flexibility as the ability of a power\nnetwork to deploy its flexibility resources to cope with the changes of power\nsystem state, particularly due to variation of renewable generation. Starting\nwith a survey on the metrics of operational flexibility, we explain the\ndefinition from both physical and mathematical point of views. Then conceptual\nexamples are presented to demonstrate the impacts of grid-side flexibility\ngraphically, providing a geometric interpretation for a better understanding of\nthe concepts. Afterwards the formulations and solution approaches in terms of\ngrid-side flexibility in power system operation and planning are reviewed,\nbased on which future research directions and challenges are outlined. \n\n"}
{"id": "1805.12534", "contents": "Title: A further study on the opioid epidemic dynamical model with random\n  perturbation Abstract: In this paper, we consider an opioid epidemic dynamical model with random\nperturbation that typically describes the interplay between regular\nprescription use, addictive use, and the process of rehabilitation from\naddiction and vice-versa. In particular, we provide two-sided bounds on the\nsolution of the transition density function for the Fokker-Planck equation that\ncorresponds to the opioid epidemic dynamical model, when a random perturbation\nenters only through the dynamics of the susceptible group in the compartmental\nmodel. Here, the proof for such bounds basically relies on the interpretation\nof the solution for the transition density function as the value function of a\ncertain optimal stochastic control problem. Finally, as a possible interesting\ndevelopment in this direction, we also provide an estimate for the attainable\nexit probability with which the solution for the randomly perturbed opioid\nepidemic dynamical model exits from a given bounded open domain during a\ncertain time interval. Note that such qualitative information on the first\nexit-time as well as two-sided bounds on the transition density function are\nuseful for developing effective and fact-informed intervention strategies that\nprimarily aim at curbing opioid epidemics or assisting in interpreting outcome\nresults from opioid-related policies. \n\n"}
{"id": "1806.00817", "contents": "Title: Convergence to the Mean Field Game Limit: A Case Study Abstract: We study the convergence of Nash equilibria in a game of optimal stopping. If\nthe associated mean field game has a unique equilibrium, any sequence of\n$n$-player equilibria converges to it as $n\\to\\infty$. However, both the finite\nand infinite player versions of the game often admit multiple equilibria. We\nshow that mean field equilibria satisfying a transversality condition are limit\npoints of $n$-player equilibria, but we also exhibit a remarkable class of mean\nfield equilibria that are not limits, thus questioning their interpretation as\n\"large $n$\" equilibria. \n\n"}
{"id": "1806.00900", "contents": "Title: Algorithmic Regularization in Learning Deep Homogeneous Models: Layers\n  are Automatically Balanced Abstract: We study the implicit regularization imposed by gradient descent for learning\nmulti-layer homogeneous functions including feed-forward fully connected and\nconvolutional deep neural networks with linear, ReLU or Leaky ReLU activation.\nWe rigorously prove that gradient flow (i.e. gradient descent with\ninfinitesimal step size) effectively enforces the differences between squared\nnorms across different layers to remain invariant without any explicit\nregularization. This result implies that if the weights are initially small,\ngradient flow automatically balances the magnitudes of all layers. Using a\ndiscretization argument, we analyze gradient descent with positive step size\nfor the non-convex low-rank asymmetric matrix factorization problem without any\nregularization. Inspired by our findings for gradient flow, we prove that\ngradient descent with step sizes $\\eta_t = O\\left(t^{-\\left(\n\\frac12+\\delta\\right)} \\right)$ ($0<\\delta\\le\\frac12$) automatically balances\ntwo low-rank factors and converges to a bounded global optimum. Furthermore,\nfor rank-$1$ asymmetric matrix factorization we give a finer analysis showing\ngradient descent with constant step size converges to the global minimum at a\nglobally linear rate. We believe that the idea of examining the invariance\nimposed by first order algorithms in learning homogeneous models could serve as\na fundamental building block for studying optimization for learning deep\nmodels. \n\n"}
{"id": "1806.00969", "contents": "Title: Observability of the heat equation, geometric constants in control\n  theory, and a conjecture of Luc Miller Abstract: This article is concerned in the first place with the short-time\nobservability constant of the heat equation from a subdomain $\\omega$ of a\nbounded domain $M$. The constant is of the form $e^{\\frac{K}{T}}$, where $K$\ndepends only on the geometry of $M$ and $\\omega$. Luc Miller (JDE, 2004)\nconjectured that $K$ is (universally) proportional to the square of the maximal\ndistance from $\\omega$ to a point of $M$. We show in particular geometries that\n$K$ may blow up like $|\\log(r)|^2$ when $\\omega$ is a ball of radius $r$, hence\ndisproving the conjecture. We then prove in the general case the associated\nupper bound on this blowup. We also show that the conjecture is true for\npositive solutions of the heat equation.\n  The proofs rely on the study of the maximal vanishing rate of (sums of)\neigenfunctions. They also yield lower and upper bounds for other geometric\nconstants appearing as tunneling constants or approximate control costs.\n  As an intermediate step in the proofs, we provide a uniform Carleman estimate\nfor Lipschitz metrics. The latter also implies uniform spectral inequalities\nand observability estimates for the heat equation in a bounded class of\nLipschitz metrics, which are of independent interest. \n\n"}
{"id": "1806.00992", "contents": "Title: Integrality of Subgradients and Biconjugates of Integrally Convex\n  Functions Abstract: Integrally convex functions constitute a fundamental function class in\ndiscrete convex analysis. This paper shows that an integer-valued integrally\nconvex function admits an integral subgradient and that the integral\nbiconjugate of an integer-valued integrally convex function coincides with\nitself. The proof is based on the Fourier-Motzkin elimination. The latter\nresult provides a unified proof of integral biconjugacy for various classes of\ninteger-valued discrete convex functions, including L-convex, M-convex,\nL$_{2}$-convex, M$_{2}$-convex, BS-convex, and UJ-convex functions as well as\nmultimodular functions. Our results of integral subdifferentiability and\nintegral biconjugacy make it possible to extend the theory of discrete DC\n(difference of convex) functions developed for L- and M-convex functions to\nthat for integrally convex functions, including an analogue of the\nToland--Singer duality for integrally convex functions. \n\n"}
{"id": "1806.02046", "contents": "Title: Implicit regularization and solution uniqueness in over-parameterized\n  matrix sensing Abstract: We consider whether algorithmic choices in over-parameterized linear matrix\nfactorization introduce implicit regularization. We focus on noiseless matrix\nsensing over rank-$r$ positive semi-definite (PSD) matrices in $\\mathbb{R}^{n\n\\times n}$, with a sensing mechanism that satisfies restricted isometry\nproperties (RIP). The algorithm we study is \\emph{factored gradient descent},\nwhere we model the low-rankness and PSD constraints with the factorization\n$UU^\\top$, for $U \\in \\mathbb{R}^{n \\times r}$. Surprisingly, recent work\nargues that the choice of $r \\leq n$ is not pivotal: even setting $U \\in\n\\mathbb{R}^{n \\times n}$ is sufficient for factored gradient descent to find\nthe rank-$r$ solution, which suggests that operating over the factors leads to\nan implicit regularization. In this contribution, we provide a different\nperspective to the problem of implicit regularization. We show that under\ncertain conditions, the PSD constraint by itself is sufficient to lead to a\nunique rank-$r$ matrix recovery, without implicit or explicit low-rank\nregularization. \\emph{I.e.}, under assumptions, the set of PSD matrices, that\nare consistent with the observed data, is a singleton, regardless of the\nalgorithm used. \n\n"}
{"id": "1806.02472", "contents": "Title: Prioritized Threshold Allocation for Distributed Frequency Response Abstract: Higher penetration of renewable generation will increase the demand for\nadequate (and cost-effective) controllable resources on the grid that can\nmitigate and contain the contingencies locally before it can cause a\nnetwork-wide collapse. However, end-use constraints can potentially lead to\nload unavailability when an event occurs, leading to unreliable demand response\nservices. Sensors measurements and knowledge of the local load dynamics could\nbe leveraged to improve the performance of load control algorithms. In the\ncontext of hierarchical frequency response using ensemble of switching loads,\nwe present a metric to evaluate the fitness of each device in successfully\nproviding the ancillary service. Furthermore a fitness-based assignment of\ncontrol set-points is formulated which achieves reliable performance under\ndifferent operating conditions. Monte Carlo simulations of ensembles of\nelectric water heaters and residential air-conditioners are performed to\nevaluate the proposed control algorithm. \n\n"}
{"id": "1806.02985", "contents": "Title: Continuous-time Value Function Approximation in Reproducing Kernel\n  Hilbert Spaces Abstract: Motivated by the success of reinforcement learning (RL) for discrete-time\ntasks such as AlphaGo and Atari games, there has been a recent surge of\ninterest in using RL for continuous-time control of physical systems (cf. many\nchallenging tasks in OpenAI Gym and DeepMind Control Suite). Since\ndiscretization of time is susceptible to error, it is methodologically more\ndesirable to handle the system dynamics directly in continuous time. However,\nvery few techniques exist for continuous-time RL and they lack flexibility in\nvalue function approximation. In this paper, we propose a novel framework for\nmodel-based continuous-time value function approximation in reproducing kernel\nHilbert spaces. The resulting framework is so flexible that it can accommodate\nany kind of kernel-based approach, such as Gaussian processes and kernel\nadaptive filters, and it allows us to handle uncertainties and nonstationarity\nwithout prior knowledge about the environment or what basis functions to\nemploy. We demonstrate the validity of the presented framework through\nexperiments. \n\n"}
{"id": "1806.05181", "contents": "Title: A Distributed Asynchronous Method of Multipliers for Constrained\n  Nonconvex Optimization Abstract: This paper presents a fully asynchronous and distributed approach for\ntackling optimization problems in which both the objective function and the\nconstraints may be nonconvex. In the considered network setting each node is\nactive upon triggering of a local timer and has access only to a portion of the\nobjective function and to a subset of the constraints. In the proposed\ntechnique, based on the method of multipliers, each node performs, when it\nwakes up, either a descent step on a local augmented Lagrangian or an ascent\nstep on the local multiplier vector. Nodes realize when to switch from the\ndescent step to the ascent one through an asynchronous distributed logic-AND,\nwhich detects when all the nodes have reached a predefined tolerance in the\nminimization of the augmented Lagrangian. It is shown that the resulting\ndistributed algorithm is equivalent to a block coordinate descent for the\nminimization of the global augmented Lagrangian. This allows one to extend the\nproperties of the centralized method of multipliers to the considered\ndistributed framework. Two application examples are presented to validate the\nproposed approach: a distributed source localization problem and the parameter\nestimation of a neural network. \n\n"}
{"id": "1806.06744", "contents": "Title: Sustainable Inventory with Robust Periodic-Affine Policies and\n  Application to Medical Supply Chains Abstract: We introduce a new class of adaptive policies called periodic-affine\npolicies, that allows a decision maker to optimally manage and control\nlarge-scale newsvendor networks in the presence of uncertain demand without\ndistributional assumptions. These policies are data-driven and model many\nfeatures of the demand such as correlation, and remain robust to parameter\nmis-specification. We present a model that can be generalized to multi-product\nsettings and extended to multi-period problems. This is accomplished by\nmodeling the uncertain demand via sets. In this way, it offers a natural\nframework to study competing policies such as base-stock, affine, and\napproximative approaches with respect to their profit, sensitivity to\nparameters and assumptions, and computational scalability. We show that the\nperiodic-affine policies are sustainable, i.e. time consistent, because they\nwarrant optimality both within subperiods and over the entire planning horizon.\nThis approach is tractable and free of distributional assumptions, and hence,\nsuited for real-world applications. We provide efficient algorithms to obtain\nthe optimal periodic-affine policies and demonstrate their advantages on the\nsales data from one of India's largest pharmacy retailers. \n\n"}
{"id": "1806.07435", "contents": "Title: Simpler derivation of bounded pitch inequalities for set covering, and\n  minimum knapsack sets Abstract: A valid inequality \\alpha^Tx \\ge \\alpha_0 for a set covering problem is said\nto have pitch <= k ( a positive integer) if the k smallest positive \\alpha_j\nsum to at least alpha_0. This paper presents a new, simple derivation of a\nrelaxation for set covering problems whose solutions satisfy all valid\ninequalities of pitch and is of polynomial size, for each fixed . We also\nconsider the minimum knapsack problem, and show that for each fixed integer p >\n0 and 0 < \\epsilon < 1 one can separate, within additive tolerance \\epsilon,\nfrom the relaxation defined by the valid inequalities with coefficients in {0,\n1, . . . , p} in time polynomial in the number of variables and 1/\\epsilon. \n\n"}
{"id": "1806.09810", "contents": "Title: On Representer Theorems and Convex Regularization Abstract: We establish a general principle which states that regularizing an inverse\nproblem with a convex function yields solutions which are convex combinations\nof a small number of atoms. These atoms are identified with the extreme points\nand elements of the extreme rays of the regularizer level sets. An extension to\na broader class of quasi-convex regularizers is also discussed. As a side\nresult, we characterize the minimizers of the total gradient variation, which\nwas still an unresolved problem. \n\n"}
{"id": "1806.10077", "contents": "Title: Random Shuffling Beats SGD after Finite Epochs Abstract: A long-standing problem in the theory of stochastic gradient descent (SGD) is\nto prove that its without-replacement version RandomShuffle converges faster\nthan the usual with-replacement version. We present the first (to our\nknowledge) non-asymptotic solution to this problem, which shows that after a\n\"reasonable\" number of epochs RandomShuffle indeed converges faster than SGD.\nSpecifically, we prove that under strong convexity and second-order smoothness,\nthe sequence generated by RandomShuffle converges to the optimal solution at\nthe rate O(1/T^2 + n^3/T^3), where n is the number of components in the\nobjective, and T is the total number of iterations. This result shows that\nafter a reasonable number of epochs RandomShuffle is strictly better than SGD\n(which converges as O(1/T)). The key step toward showing this better dependence\non T is the introduction of n into the bound; and as our analysis will show, in\ngeneral a dependence on n is unavoidable without further changes to the\nalgorithm. We show that for sparse data RandomShuffle has the rate O(1/T^2),\nagain strictly better than SGD. Furthermore, we discuss extensions to nonconvex\ngradient dominated functions, as well as non-strongly convex settings. \n\n"}
{"id": "1806.10773", "contents": "Title: Successive Convex Approximation Algorithms for Sparse Signal Estimation\n  with Nonconvex Regularizations Abstract: In this paper, we propose a successive convex approximation framework for\nsparse optimization where the nonsmooth regularization function in the\nobjective function is nonconvex and it can be written as the difference of two\nconvex functions. The proposed framework is based on a nontrivial combination\nof the majorization-minimization framework and the successive convex\napproximation framework proposed in literature for a convex regularization\nfunction. The proposed framework has several attractive features, namely, i)\nflexibility, as different choices of the approximate function lead to different\ntype of algorithms; ii) fast convergence, as the problem structure can be\nbetter exploited by a proper choice of the approximate function and the\nstepsize is calculated by the line search; iii) low complexity, as the\napproximate function is convex and the line search scheme is carried out over a\ndifferentiable function; iv) guaranteed convergence to a stationary point. We\ndemonstrate these features by two example applications in subspace learning,\nnamely, the network anomaly detection problem and the sparse subspace\nclustering problem. Customizing the proposed framework by adopting the\nbest-response type approximation, we obtain soft-thresholding with exact line\nsearch algorithms for which all elements of the unknown parameter are updated\nin parallel according to closed-form expressions. The attractive features of\nthe proposed algorithms are illustrated numerically. \n\n"}
{"id": "1807.01083", "contents": "Title: A Mean-Field Optimal Control Formulation of Deep Learning Abstract: Recent work linking deep neural networks and dynamical systems opened up new\navenues to analyze deep learning. In particular, it is observed that new\ninsights can be obtained by recasting deep learning as an optimal control\nproblem on difference or differential equations. However, the mathematical\naspects of such a formulation have not been systematically explored. This paper\nintroduces the mathematical formulation of the population risk minimization\nproblem in deep learning as a mean-field optimal control problem. Mirroring the\ndevelopment of classical optimal control, we state and prove optimality\nconditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type.\nThese mean-field results reflect the probabilistic nature of the learning\nproblem. In addition, by appealing to the mean-field Pontryagin's maximum\nprinciple, we establish some quantitative relationships between population and\nempirical learning problems. This serves to establish a mathematical foundation\nfor investigating the algorithmic and theoretical connections between optimal\ncontrol and deep learning. \n\n"}
{"id": "1807.01164", "contents": "Title: A Decoupled Data Based Approach to Stochastic Optimal Control Problems Abstract: This paper studies the stochastic optimal control problem for systems with\nunknown dynamics. A novel decoupled data based control (D2C) approach is\nproposed, which solves the problem in a decoupled \"open loop-closed loop\"\nfashion that is shown to be near-optimal. First, an open-loop deterministic\ntrajectory optimization problem is solved using a black-box simulation model of\nthe dynamical system using a standard nonlinear programming (NLP) solver. Then\na Linear Quadratic Regulator (LQR) controller is designed for the nominal\ntrajectory-dependent linearized system which is learned using input-output\nexperimental data. Computational examples are used to illustrate the\nperformance of the proposed approach with three benchmark problems. \n\n"}
{"id": "1807.01187", "contents": "Title: Variational Properties of Matrix Functions via the Generalized\n  Matrix-Fractional Function Abstract: We show that many important convex matrix functions can be represented as the\npartial infimal projection of the generalized matrix fractional (GMF) and a\nrelatively simple convex function. This representation provides conditions\nunder which such functions are closed and proper as well as formulas for the\nready computation of both their conjugates and subdifferentials. Special\nattention is given to support and indicator functions. Particular instances\nyield all weighted Ky Fan norms and squared gauges on $\\mathbb R^{n\\times m}$,\nand as an example we show that all variational Gram functions are representable\nas squares of gauges. Other instances yield weighted sums of the Frobenius and\nnuclear norms. The scope of applications is large and the range of variational\nproperties and insight is fascinating and fundamental. An important byproduct\nof these representations is that they lay the foundation for a smoothing\napproach to many matrix functions on the interior of the domain of the GMF\nfunction, which opens the door to a range of unexplored optimization methods. \n\n"}
{"id": "1807.01382", "contents": "Title: A simplex algorithm for rational cp-factorization Abstract: In this paper we provide an algorithm, similar to the simplex algorithm,\nwhich determines a rational cp-factorization of a given matrix, whenever the\nmatrix allows such a factorization. This algorithm can be used to show that\nevery integral completely positive $2 \\times 2$ matrix has an integral\ncp-factorization. \n\n"}
{"id": "1807.02629", "contents": "Title: Optimistic mirror descent in saddle-point problems: Going the extra\n  (gradient) mile Abstract: Owing to their connection with generative adversarial networks (GANs),\nsaddle-point problems have recently attracted considerable interest in machine\nlearning and beyond. By necessity, most theoretical guarantees revolve around\nconvex-concave (or even linear) problems; however, making theoretical inroads\ntowards efficient GAN training depends crucially on moving beyond this classic\nframework. To make piecemeal progress along these lines, we analyze the\nbehavior of mirror descent (MD) in a class of non-monotone problems whose\nsolutions coincide with those of a naturally associated variational inequality\n- a property which we call coherence. We first show that ordinary, \"vanilla\" MD\nconverges under a strict version of this condition, but not otherwise; in\nparticular, it may fail to converge even in bilinear models with a unique\nsolution. We then show that this deficiency is mitigated by optimism: by taking\nan \"extra-gradient\" step, optimistic mirror descent (OMD) converges in all\ncoherent problems. Our analysis generalizes and extends the results of\nDaskalakis et al. (2018) for optimistic gradient descent (OGD) in bilinear\nproblems, and makes concrete headway for establishing convergence beyond\nconvex-concave games. We also provide stochastic analogues of these results,\nand we validate our analysis by numerical experiments in a wide array of GAN\nmodels (including Gaussian mixture models, as well as the CelebA and CIFAR-10\ndatasets). \n\n"}
{"id": "1807.02736", "contents": "Title: Robust Learning of Trimmed Estimators via Manifold Sampling Abstract: We adapt a manifold sampling algorithm for the nonsmooth, nonconvex\nformulations of learning that arise when imposing robustness to outliers\npresent in the training data. We demonstrate the approach on objectives based\non trimmed loss. Empirical results show that the method has favorable scaling\nproperties. Although savings in time come at the expense of not certifying\noptimality, the algorithm consistently returns high-quality solutions on the\ntrimmed linear regression and multiclass classification problems tested. \n\n"}
{"id": "1807.03640", "contents": "Title: Representation of Hamilton-Jacobi equation in optimal control theory\n  with unbounded control set Abstract: In this paper we study the existence of sufficiently regular representations\nof Hamilton-Jacobi equations in the optimal control theory with unbounded\ncontrol set. We use a new method to construct representations for a wide class\nof Hamiltonians. This class is wider than any constructed before, because we do\nnot require Legendre-Fenchel conjugates of Hamiltonians to be bounded. However,\nin this case we obtain representations with unbounded control set. We apply the\nobtained results to study regularities of value functions and correlations\nbetween variational and optimal control problems. \n\n"}
{"id": "1807.05177", "contents": "Title: A collisionless singular Cucker-Smale model with decentralized formation\n  control Abstract: We address the design of decentralized feedback control laws inducing\nconsensus and prescribed spatial patterns over a singular interacting particle\nsystem of Cucker-Smale type. The control design consists of a feedback term\nregulating the distance between each agent and pre-assigned subset of\nneighbours. Such a design represents a multidimensional extension of existing\ncontrol laws for 1d platoon formation control. For the proposed controller we\nstudy consensus emergence, collision-avoidance and formation control features\nin terms of energy estimates for the closed-loop system. Numerical experiments\nin 1, 2 and 3 dimensions assess the different features of the proposed design. \n\n"}
{"id": "1807.05194", "contents": "Title: An Algorithmic Blend of LPs and Ring Equations for Promise CSPs Abstract: Promise CSPs are a relaxation of constraint satisfaction problems where the\ngoal is to find an assignment satisfying a relaxed version of the constraints.\nSeveral well-known problems can be cast as promise CSPs including approximate\ngraph coloring, discrepancy minimization, and interesting variants of\nsatisfiability. Similar to CSPs, the tractability of promise CSPs can be tied\nto the structure of operations on the solution space called polymorphisms,\nthough in the promise world these operations are much less constrained. Under\nthe thesis that non-trivial polymorphisms govern tractability, promise CSPs\ntherefore provide a fertile ground for the discovery of novel algorithms.\n  In previous work, we classified Boolean promise CSPs when the constraint\npredicates are symmetric. In this work, we vastly generalize these algorithmic\nresults. Specifically, we show that promise CSPs that admit a family of\n\"regional-periodic\" polymorphisms are in P, assuming that determining which\nregion a point is in can be computed in polynomial time. Such polymorphisms are\nquite general and are obtained by gluing together several functions that are\nperiodic in the Hamming weights in different blocks of the input.\n  Our algorithm is based on a novel combination of linear programming and\nsolving linear systems over rings. We also abstract a framework based on\nreducing a promise CSP to a CSP over an infinite domain, solving it there, and\nthen rounding the solution to an assignment for the promise CSP instance. The\nrounding step is intimately tied to the family of polymorphisms and clarifies\nthe connection between polymorphisms and algorithms in this context. As a key\ningredient, we introduce the technique of finding a solution to a linear\nprogram with integer coefficients that lies in a different ring (such as\n$\\mathbb Z[\\sqrt{2}]$) to bypass ad-hoc adjustments for lying on a rounding\nboundary. \n\n"}
{"id": "1807.07864", "contents": "Title: Output Selection and Observer Design for Boolean Control Networks: A\n  Sub-Optimal Polynomial-Complexity Algorithm Abstract: Using a graph-theoretic approach, we derive a new sufficient condition for\nobservability of a Boolean control network (BCN). Based on this condition, we\ndescribe two algorithms: the first selects a set of nodes so that observing\nthis set makes the BCN observable. The second algorithm builds an observer for\nthe observable BCN. Both algorithms are sub-optimal, as they are based on a\nsufficient but not necessary condition for observability. Yet their\ntime-complexity is linear in the length of the description of the BCN,\nrendering them feasible for large-scale networks. We discuss how these results\ncan be used to provide a sub-optimal yet polynomial-complexity algorithm for\nthe minimal observability problem in BCNs. Some of the theoretical results are\ndemonstrated using a BCN model of the core network regulating the mammalian\ncell cycle. \n\n"}
{"id": "1807.07994", "contents": "Title: A Stochastic Line Search Method with Convergence Rate Analysis Abstract: For deterministic optimization, line-search methods augment algorithms by\nproviding stability and improved efficiency. We adapt a classical backtracking\nArmijo line-search to the stochastic optimization setting. While traditional\nline-search relies on exact computations of the gradient and values of the\nobjective function, our method assumes that these values are available up to\nsome dynamically adjusted accuracy which holds with some sufficiently large,\nbut fixed, probability. We show the expected number of iterations to reach a\nnear stationary point matches the worst-case efficiency of typical first-order\nmethods, while for convex and strongly convex objective, it achieves rates of\ndeterministic gradient descent in function values. \n\n"}
{"id": "1807.09141", "contents": "Title: Necessary and Sufficient Topological Conditions for Identifiability of\n  Dynamical Networks Abstract: This paper deals with dynamical networks for which the relations between node\nsignals are described by proper transfer functions and external signals can\ninfluence each of the node signals. We are interested in graph-theoretic\nconditions for identifiability of such dynamical networks, where we assume that\nonly a subset of nodes is measured but the underlying graph structure of the\nnetwork is known. This problem has recently been investigated from a generic\nviewpoint. Roughly speaking, generic identifiability means that the transfer\nfunctions in the network can be identified for \"almost all\" network matrices\nassociated with the graph. In this paper, we investigate the stronger notion of\nidentifiability for all network matrices. To this end, we introduce a new\ngraph-theoretic concept called the graph simplification process. Based on this\nprocess, we provide necessary and sufficient topological conditions for\nidentifiability. Notably, we also show that these conditions can be verified by\npolynomial time algorithms. Finally, we explain how our results generalize\nexisting sufficient conditions for identifiability. \n\n"}
{"id": "1807.09722", "contents": "Title: (Probably) Concave Graph Matching Abstract: In this paper we address the graph matching problem. Following the recent\nworks of \\cite{zaslavskiy2009path,Vestner2017} we analyze and generalize the\nidea of concave relaxations. We introduce the concepts of conditionally concave\nand probably conditionally concave energies on polytopes and show that they\nencapsulate many instances of the graph matching problem, including matching\nEuclidean graphs and graphs on surfaces. We further prove that local minima of\nprobably conditionally concave energies on general matching polytopes (e.g.,\ndoubly stochastic) are with high probability extreme points of the matching\npolytope (e.g., permutations). \n\n"}
{"id": "1808.01266", "contents": "Title: A new dual for quadratic programming and its applications Abstract: The main outcomes of the paper are divided into two parts. First, we present\na new dual for quadratic programs, in which, the dual variables are affine\nfunctions, and we prove strong duality. Since the new dual is intractable, we\nconsider a modified version by restricting the feasible set. This leads to a\nnew bound for quadratic programs. We demonstrate that the dual of the bound is\na semi-definite relaxation of quadratic programs. In addition, we probe the\nrelationship between this bound and the well-known bounds. In the second part,\nthanks to the new bound, we propose a branch and cut algorithm for concave\nquadratic programs. We establish that the algorithm enjoys global convergence.\nThe effectiveness of the method is illustrated for numerical problem instances. \n\n"}
{"id": "1808.02543", "contents": "Title: Asynchronous Variance-reduced Block Schemes for Composite Nonconvex\n  Stochastic Optimization: Block-specific Steplengths and Adapted Batch-sizes Abstract: We consider the minimization of a sum of an expectation-valued\ncoordinate-wise $L_i$-smooth nonconvex function and a nonsmooth block-separable\nconvex regularizer. We propose an asynchronous variance-reduced algorithm,\nwhere in each iteration, a single block is randomly chosen to update its\nestimates by a proximal variable sample-size stochastic gradient scheme, while\nthe remaining blocks are kept invariant. Notably, each block employs a\nsteplength that is in accordance with its block-specific Lipschitz constant\nwhile block-specific batch-sizes are random variables updated at a rate that\ngrows either at a geometric or polynomial rate with the (random) number of\ntimes that block is selected. We show that every limit point for almost every\nsample path is a stationary point and establish the ergodic non-asymptotic rate\n$\\mathcal{O}(1/K) $. Iteration and oracle complexity to obtain an\n$\\epsilon$-stationary point are shown to be $\\mathcal{O}(1/\\epsilon)$ and\n$\\mathcal{O}(1/\\epsilon^2)$, respectively. Furthermore, under a $ \\mu\n$-proximal Polyak-{\\L}ojasiewicz (PL) condition with the batch size increasing\nat a geometric rate, we prove that the suboptimality diminishes at a {\\em\ngeometric} rate, the {\\em optimal} deterministic rate while iteration and\noracle complexity to obtain an $\\epsilon$-optimal solution are proven to be\n$\\mathcal{O}( (L_{\\rm max}/\\mu) \\ln(1/\\epsilon))$ and $\\mathcal{O}\\left((L_{\\rm\nave}/\\mu) (1/\\epsilon)^{1+c} \\right)$ with $c\\geq 0$, respectively. In pursuit\nof less aggressive sampling rates, when the batch sizes increase at a\npolynomial rate of degree $v \\geq 1$, suboptimality decays at a corresponding\npolynomial rate while the iteration and oracle complexity to obtain an\n$\\epsilon-$optimal solution are provably $\\mathcal{O} ( v(1/\\epsilon)^{1/v})$\nand $\\mathcal{O} \\left(e^v v^{2v+1}(1/\\epsilon)^{1+1/v}\\right)$, respectively. \n\n"}
{"id": "1808.02901", "contents": "Title: Lower complexity bounds of first-order methods for convex-concave\n  bilinear saddle-point problems Abstract: On solving a convex-concave bilinear saddle-point problem (SPP), there have\nbeen many works studying the complexity results of first-order methods. These\nresults are all about upper complexity bounds, which can determine at most how\nmany efforts would guarantee a solution of desired accuracy. In this paper, we\npursue the opposite direction by deriving lower complexity bounds of\nfirst-order methods on large-scale SPPs. Our results apply to the methods whose\niterates are in the linear span of past first-order information, as well as\nmore general methods that produce their iterates in an arbitrary manner based\non first-order information. We first work on the affinely constrained smooth\nconvex optimization that is a special case of SPP. Different from gradient\nmethod on unconstrained problems, we show that first-order methods on affinely\nconstrained problems generally cannot be accelerated from the known convergence\nrate $O(1/t)$ to $O(1/t^2)$, and in addition, $O(1/t)$ is optimal for convex\nproblems. Moreover, we prove that for strongly convex problems, $O(1/t^2)$ is\nthe best possible convergence rate, while it is known that gradient methods can\nhave linear convergence on unconstrained problems. Then we extend these results\nto general SPPs. It turns out that our lower complexity bounds match with\nseveral established upper complexity bounds in the literature, and thus they\nare tight and indicate the optimality of several existing first-order methods. \n\n"}
{"id": "1808.03198", "contents": "Title: Estimation of Location and Orientation for Underwater Vehicles from\n  Range Measurements Abstract: Localization is an important required task for enabling vehicle autonomy for\nunderwater vehicles. Localization entails the determination of position of the\ncenter of mass and orientation of a vehicle from the available measurements. In\nthis paper, we focus on localization by using One-Way Travel Time (OWTT)\nmeasurements available to a vehicle from the communication of its multiple\non-board receivers with acoustic beacons, more specifically, long baseline\n(LBL) beacons. Range can be inferred by multiplying the OWTT with speed of\nsound; however, water conditions can change spatially and temporally resulting\nin uncertainty in range measurement. The farther a beacon is from a receiver,\nthe larger is the uncertainty. The proposed method for localization accounts\ncaptures this uncertainty by bounding the true distance with an increasing\n(calibrating) function of the range measurement. Determination of this\ncalibration function is formulated as polynomial optimization problem and is a\ncrucial step for localization. The proposed two-step procedure for localization\nis as follows: based on the range measurements specific to a receiver from the\nbeacons, a convex optimization problem is proposed to estimate the location of\nthe receiver. The estimate is essentially a center of the set of possible\nlocations of the receiver. In the second step, the location estimates of the\nvehicle are corrected using rigid body motion constraints and the orientation\nof the rigid body is thus determined. Numerical examples and experimental\nresults provided at the end corroborate the procedures developed in this paper. \n\n"}
{"id": "1808.03215", "contents": "Title: Scalable Gaussian Process Computations Using Hierarchical Matrices Abstract: We present a kernel-independent method that applies hierarchical matrices to\nthe problem of maximum likelihood estimation for Gaussian processes. The\nproposed approximation provides natural and scalable stochastic estimators for\nits gradient and Hessian, as well as the expected Fisher information matrix,\nthat are computable in quasilinear $O(n \\log^2 n)$ complexity for a large range\nof models. To accomplish this, we (i) choose a specific hierarchical\napproximation for covariance matrices that enables the computation of their\nexact derivatives and (ii) use a stabilized form of the Hutchinson stochastic\ntrace estimator. Since both the observed and expected information matrices can\nbe computed in quasilinear complexity, covariance matrices for MLEs can also be\nestimated efficiently. After discussing the associated mathematics, we\ndemonstrate the scalability of the method, discuss details of its\nimplementation, and validate that the resulting MLEs and confidence intervals\nbased on the inverse Fisher information matrix faithfully approach those\nobtained by the exact likelihood. \n\n"}
{"id": "1808.03408", "contents": "Title: A Unified Analysis of AdaGrad with Weighted Aggregation and Momentum\n  Acceleration Abstract: Integrating adaptive learning rate and momentum techniques into SGD leads to\na large class of efficiently accelerated adaptive stochastic algorithms, such\nas AdaGrad, RMSProp, Adam, AccAdaGrad, \\textit{etc}. In spite of their\neffectiveness in practice, there is still a large gap in their theories of\nconvergences, especially in the difficult non-convex stochastic setting. To\nfill this gap, we propose \\emph{weighted AdaGrad with unified momentum}, dubbed\nAdaUSM, which has the main characteristics that (1) it incorporates a unified\nmomentum scheme which covers both the heavy ball momentum and the Nesterov\naccelerated gradient momentum; (2) it adopts a novel weighted adaptive learning\nrate that can unify the learning rates of AdaGrad, AccAdaGrad, Adam, and\nRMSProp. Moreover, when we take polynomially growing weights in AdaUSM, we\nobtain its $\\mathcal{O}(\\log(T)/\\sqrt{T})$ convergence rate in the non-convex\nstochastic setting. We also show that the adaptive learning rates of Adam and\nRMSProp correspond to taking exponentially growing weights in AdaUSM, thereby\nproviding a new perspective for understanding Adam and RMSProp. Lastly,\ncomparative experiments of AdaUSM against SGD with momentum, AdaGrad, AdaEMA,\nAdam, and AMSGrad on various deep learning models and datasets are also carried\nout. \n\n"}
{"id": "1808.04648", "contents": "Title: An Adaptive Primal-Dual Framework for Nonsmooth Convex Minimization Abstract: We propose a new self-adaptive, double-loop smoothing algorithm to solve\ncomposite, nonsmooth, and constrained convex optimization problems. Our\nalgorithm is based on Nesterov's smoothing technique via general Bregman\ndistance functions. It self-adaptively selects the number of iterations in the\ninner loop to achieve a desired complexity bound without requiring the accuracy\na priori as in variants of Augmented Lagrangian methods (ALM). We prove\n$\\BigO{\\frac{1}{k}}$-convergence rate on the last iterate of the outer sequence\nfor both unconstrained and constrained settings in contrast to ergodic rates\nwhich are common in ALM as well as alternating direction method-of-multipliers\nliterature. Compared to existing inexact ALM or quadratic penalty methods, our\nanalysis does not rely on the worst-case bounds of the subproblem solved by the\ninner loop. Therefore, our algorithm can be viewed as a restarting technique\napplied to the ASGARD method in \\cite{TranDinh2015b} but with rigorous\ntheoretical guarantees or as an inexact ALM with explicit inner loop\ntermination rules and adaptive parameters. Our algorithm only requires to\ninitialize the parameters once, and automatically update them during the\niteration process without tuning. We illustrate the superiority of our methods\nvia several examples as compared to the state-of-the-art. \n\n"}
{"id": "1808.05239", "contents": "Title: Control of Generalized Discrete-time SIS Epidemics via Submodular\n  Function Minimization Abstract: In this paper, we study a novel control method for a generalized SIS epidemic\nprocess. In particular, we use predictive control to design optimal protective\nresource distribution strategies which balance the need to eliminate the\nepidemic quickly against the need to limit the rate at which protective\nresources are used. We expect that such a controller may be useful in\nmitigating the spread of biological diseases which do not confer immunity to\nthose who have been infected previously, with sexually transmitted infections\nbeing a prominent example of such. Technically, this paper provides a novel\ncontribution in demonstrating that the particular combinatorial optimal control\nproblem used to design resource allocations has an objective function which is\nsubmodular, and so can be solved in polynomial time despite its combinatorial\nnature. We test the performance of the proposed controller with numerical\nsimulations, and provide some comments on directions for future work. \n\n"}
{"id": "1808.05776", "contents": "Title: Optimum Experimental Design for Interface Identification Problems Abstract: The identification of the interface of an inclusion in a diffusion process is\nconsidered. This task is viewed as a parameter identification problem in which\nthe parameter space bears the structure of a shape manifold. A corresponding\noptimum experimental design (OED) problem is formulated in which the activation\npattern of an array of sensors in space and time serves as experimental\ncondition. The goal is to improve the estimation precision within a certain\nsubspace of the infinite dimensional tangent space of shape variations to the\nmanifold, and to find those shape variations of best and worst identifiability.\nNumerical results for the OED problem obtained by a simplicial decomposition\nalgorithm are presented. \n\n"}
{"id": "1808.05933", "contents": "Title: Decentralized Dictionary Learning Over Time-Varying Digraphs Abstract: This paper studies Dictionary Learning problems wherein the learning task is\ndistributed over a multi-agent network, modeled as a time-varying directed\ngraph. This formulation is relevant, for instance, in Big Data scenarios where\nmassive amounts of data are collected/stored in different locations (e.g.,\nsensors, clouds) and aggregating and/or processing all data in a fusion center\nmight be inefficient or unfeasible, due to resource limitations, communication\noverheads or privacy issues. We develop a unified decentralized algorithmic\nframework for this class of nonconvex problems, which is proved to converge to\nstationary solutions at a sublinear rate. The new method hinges on Successive\nConvex Approximation techniques, coupled with a decentralized tracking\nmechanism aiming at locally estimating the gradient of the smooth part of the\nsum-utility. To the best of our knowledge, this is the first provably\nconvergent decentralized algorithm for Dictionary Learning and, more generally,\nbi-convex problems over (time-varying) (di)graphs. \n\n"}
{"id": "1808.07181", "contents": "Title: Efficient sparse semismooth Newton methods for the clustered lasso\n  problem Abstract: We focus on solving the clustered lasso problem, which is a least squares\nproblem with the $\\ell_1$-type penalties imposed on both the coefficients and\ntheir pairwise differences to learn the group structure of the regression\nparameters. Here we first reformulate the clustered lasso regularizer as a\nweighted ordered-lasso regularizer, which is essential in reducing the\ncomputational cost from $O(n^2)$ to $O(n\\log (n))$. We then propose an inexact\nsemismooth Newton augmented Lagrangian ({\\sc Ssnal}) algorithm to solve the\nclustered lasso problem or its dual via this equivalent formulation, depending\non whether the sample size is larger than the dimension of the features. An\nessential component of the {\\sc Ssnal} algorithm is the computation of the\ngeneralized Jacobian of the proximal mapping of the clustered lasso\nregularizer. Based on the new formulation, we derive an efficient procedure for\nits computation. Comprehensive results on the global convergence and local\nlinear convergence of the {\\sc Ssnal} algorithm are established. For the\npurpose of exposition and comparison, we also summarize/design several\nfirst-order methods that can be used to solve the problem under consideration,\nbut with the key improvement from the new formulation of the clustered lasso\nregularizer. As a demonstration of the applicability of our algorithms,\nnumerical experiments on the clustered lasso problem are performed. The\nexperiments show that the {\\sc Ssnal} algorithm substantially outperforms the\nbest alternative algorithm for the clustered lasso problem. \n\n"}
{"id": "1808.07749", "contents": "Title: A Smooth Inexact Penalty Reformulation of Convex Problems with Linear\n  Constraints Abstract: In this work, we consider a constrained convex problem with linear\ninequalities and provide an inexact penalty re-formulation of the problem. The\nnovelty is in the choice of the penalty functions, which are smooth and can\ninduce a non-zero penalty over some points in feasible region of the original\nconstrained problem. The resulting unconstrained penalized problem is\nparametrized by two penalty parameters which control the slope and the\ncurvature of the penalty function. With a suitable selection of these penalty\nparameters, we show that the solutions of the resulting penalized unconstrained\nproblem are \\emph{feasible} for the original constrained problem, under some\nassumptions. Also, we establish that, with suitable choices of penalty\nparameters, the solutions of the penalized unconstrained problem can achieve a\nsuboptimal value which is arbitrarily close to the optimal value of the\noriginal constrained problem. For the problems with a large number of linear\ninequality constraints, a particular advantage of such a smooth penalty-based\nreformulation is that it renders a penalized problem suitable for the\nimplementation of fast incremental gradient methods, which require only one\nsample from the inequality constraints at each iteration. We consider applying\nSAGA proposed in \\cite{saga} to solve the resulting penalized unconstrained\nproblem. Moreover, we propose an alternative approach to set up the penalized\nproblem. This approach is based on the time-varying penalty parameters and,\nthus, does not require knowledge about some problem-specific properties, that\nmight be difficult to estimate. We prove that the single-loop full\ngradient-based algorithm applied to the corresponding time-varying penalized\nproblem converges to the solution of the original constrained problem in the\ncase of the strongly convex objective function. \n\n"}
{"id": "1808.08161", "contents": "Title: Continuous time Gaussian process dynamical models in gene regulatory\n  network inference Abstract: One of the focus areas of modern scientific research is to reveal mysteries\nrelated to genes and their interactions. The dynamic interactions between genes\ncan be encoded into a gene regulatory network (GRN), which can be used to gain\nunderstanding on the genetic mechanisms behind observable phenotypes. GRN\ninference from time series data has recently been a focus area of systems\nbiology. Due to low sampling frequency of the data, this is a notoriously\ndifficult problem. We tackle the challenge by introducing the so-called\ncontinuous-time Gaussian process dynamical model, based on Gaussian process\nframework that has gained popularity in nonlinear regression problems arising\nin machine learning. The model dynamics are governed by a stochastic\ndifferential equation, where the dynamics function is modelled as a Gaussian\nprocess. We prove the existence and uniqueness of solutions of the stochastic\ndifferential equation. We derive the probability distribution for the Euler\ndiscretised trajectories and establish the convergence of the discretisation.\nWe develop a GRN inference method called BINGO, based on the developed\nframework. BINGO is based on MCMC sampling of trajectories of the GPDM and\nestimating the hyperparameters of the covariance function of the Gaussian\nprocess. Using benchmark data examples, we show that BINGO is superior in\ndealing with poor time resolution and it is computationally feasible. \n\n"}
{"id": "1808.09144", "contents": "Title: Weighted total variation based convex clustering Abstract: Data clustering is a fundamental problem with a wide range of applications.\nStandard methods, eg the $k$-means method, usually require solving a non-convex\noptimization problem. Recently, total variation based convex relaxation to the\n$k$-means model has emerged as an attractive alternative for data clustering.\nHowever, the existing results on its exact clustering property, ie, the\ncondition imposed on data so that the method can provably give correct\nidentification of all cluster memberships, is only applicable to very specific\ndata and is also much more restrictive than that of some other methods. This\npaper aims at the revisit of total variation based convex clustering, by\nproposing a weighted sum-of-$\\ell_1$-norm relating convex model. Its exact\nclustering property established in this paper, in both deterministic and\nprobabilistic context, is applicable to general data and is much sharper than\nthe existing results. These results provided good insights to advance the\nresearch on convex clustering. Moreover, the experiments also demonstrated that\nthe proposed convex model has better empirical performance when be compared to\nstandard clustering methods, and thus it can see its potential in practice. \n\n"}
{"id": "1808.09720", "contents": "Title: Stochastic Collocation with Non-Gaussian Correlated Process Variations:\n  Theory, Algorithms and Applications Abstract: Stochastic spectral methods have achieved great success in the uncertainty\nquantification of many engineering problems, including electronic and photonic\nintegrated circuits influenced by fabrication process variations. Existing\ntechniques employ a generalized polynomial-chaos expansion, and they almost\nalways assume that all random parameters are mutually independent or Gaussian\ncorrelated. However, this assumption is rarely true in real applications. How\nto handle non-Gaussian correlated random parameters is a long-standing and\nfundamental challenge. A main bottleneck is the lack of theory and\ncomputational methods to perform a projection step in a correlated uncertain\nparameter space. This paper presents an optimization-based approach to\nautomatically determinate the quadrature nodes and weights required in a\nprojection step, and develops an efficient stochastic collocation algorithm for\nsystems with non-Gaussian correlated parameters. We also provide some\ntheoretical proofs for the complexity and error bound of our proposed method.\nNumerical experiments on synthetic, electronic and photonic integrated circuit\nexamples show the nearly exponential convergence rate and excellent efficiency\nof our proposed approach. Many other challenging uncertainty-related problems\ncan be further solved based on this work. \n\n"}
{"id": "1808.10474", "contents": "Title: Fixed-Time Stable Gradient Flows: Applications to Continuous-Time\n  Optimization Abstract: This paper proposes novel gradient-flow schemes that yield convergence to the\noptimal point of a convex optimization problem within a \\textit{fixed} time\nfrom any given initial condition for unconstrained optimization, constrained\noptimization, and min-max problems. The application of the modified gradient\nflow to unconstrained optimization problems is studied under the assumption of\ngradient-dominance. Then, a modified Newton's method is presented that exhibits\nfixed-time convergence under some mild conditions on the objective function.\nBuilding upon this method, a novel technique for solving convex optimization\nproblems with linear equality constraints that yields convergence to the\noptimal point in fixed time is developed. More specifically, constrained\noptimization problems formulated as min-max problems are considered, and a\nnovel method for computing the optimal solution in fixed-time is proposed using\nthe Lagrangian dual. Finally, the general min-max problem is considered, and a\nmodified scheme to obtain the optimal solution of saddle-point dynamics in\nfixed time is developed. Numerical illustrations that compare the performance\nof the proposed method against Newton's method, rescaled-gradient method, and\nNesterov's accelerated method are included to corroborate the efficacy and\napplicability of the modified gradient flows in constrained and unconstrained\noptimization problems. \n\n"}
{"id": "1809.00512", "contents": "Title: A Bilevel Approach to Optimal Price-Setting of Time-and-Level-of-Use\n  Tariffs Abstract: Time-and-Level-of-Use (TLOU) is a recently proposed pricing policy for\nenergy, extending Time-of-Use with the addition of a capacity that users can\nbook for a given time frame, reducing their expected energy cost if they\nrespect this self-determined capacity limit. We introduce a variant of the TLOU\ndefined in the literature, aligned with the supplier interest to prevent\nunplanned over-consumption. The optimal price-setting problem of TLOU is\ndefined as a bilevel, bi-objective problem anticipating user choices in the\nsupplier decision. An efficient resolution scheme is developed, based on the\nspecific discrete structure of the lower-level user problem. Computational\nexperiments using consumption distributions estimated from historical data\nillustrate the effectiveness of the proposed framework. \n\n"}
{"id": "1809.01283", "contents": "Title: Routing for Traffic Networks with Mixed Autonomy Abstract: In this work we propose a macroscopic model for studying routing on networks\nshared between human-driven and autonomous vehicles that captures the effects\nof autonomous vehicles forming platoons. We use this to study inefficiency due\nto selfish routing and bound the Price of Anarchy (PoA), the maximum ratio\nbetween total delay experienced by selfish users and the minimum possible total\ndelay. To do so, we establish two road capacity models, each corresponding to\nan assumption regarding the platooning capabilities of autonomous vehicles.\nUsing these we develop a class of road delay functions, parameterized by the\nroad capacity, that are polynomial with respect to vehicle flow. We then bound\nthe PoA and the bicriteria, another measure of the inefficiency due to selfish\nrouting. We find these bounds depend on: 1) the degree of the polynomial in the\nroad cost function and 2) the degree of asymmetry, the difference in how\nhuman-driven and autonomous traffic affect congestion. We demonstrate that\nthese bounds recover the classical bounds when no asymmetry exists. We show the\nbounds are tight in certain cases and that the PoA bound is order-optimal with\nrespect to the degree of asymmetry. \n\n"}
{"id": "1809.01464", "contents": "Title: Portfolio diversification and model uncertainty: a robust dynamic\n  mean-variance approach Abstract: This paper focuses on a dynamic multi-asset mean-variance portfolio selection\nproblem under model uncertainty. We develop a continuous time framework for\ntaking into account ambiguity aversion about both expected return rates and\ncorrelation matrix of the assets, and for studying the join effects on\nportfolio diversification. The dynamic setting allows us to consider time\nvarying ambiguity sets, which include the cases where the drift and correlation\nare estimated on a rolling window of historical data or when the investor takes\ninto account learning on the ambiguity. In this context, we prove a general\nseparation principle for the associated robust control problem, which allows us\nto reduce the determination of the optimal dynamic strategy to the parametric\ncomputation of the minimal risk premium function. Our results provide a\njustification for under-diversification, as documented in empirical studies and\nin the static models [16], [34]. Furthermore, we explicitly quantify the degree\nof under-diversification in termsof correlation bounds and Sharpe ratios\nproximities, and emphasize the different features induced by drift and\ncorrelation ambiguity. In particular, we show that an investor with a poor\nconfidence in the expected return estimation does not hold any risky asset, and\non the other hand, trades only one risky asset when the level of ambiguity on\ncorrelation matrix is large. We also provide a complete picture of the\ndiversification for the optimal robust portfolio in the three-asset case JEL\nClassification: G11, C61 MSC Classification: 91G10, 91G80, 60H30 \n\n"}
{"id": "1809.01970", "contents": "Title: Graph-based algorithms for the efficient solution of a class of\n  optimization problems Abstract: In this paper, we address a class of specially structured problems that\ninclude speed planning, for mobile robots and robotic manipulators, and dynamic\nprogramming. We develop two new numerical procedures, that apply to the general\ncase and to the linear subcase. With numerical experiments, we show that the\nproposed algorithms outperform generic commercial solvers. \n\n"}
{"id": "1809.02267", "contents": "Title: Cloud-based Quadratic Optimization with Partially Homomorphic Encryption Abstract: The development of large-scale distributed control systems has led to the\noutsourcing of costly computations to cloud-computing platforms, as well as to\nconcerns about privacy of the collected sensitive data. This paper develops a\ncloud-based protocol for a quadratic optimization problem involving multiple\nparties, each holding information it seeks to maintain private. The protocol is\nbased on the projected gradient ascent on the Lagrange dual problem and\nexploits partially homomorphic encryption and secure multi-party computation\ntechniques. Using formal cryptographic definitions of indistinguishability, the\nprotocol is shown to achieve computational privacy, i.e., there is no\ncomputationally efficient algorithm that any involved party can employ to\nobtain private information beyond what can be inferred from the party's inputs\nand outputs only. In order to reduce the communication complexity of the\nproposed protocol, we introduced a variant that achieves this objective at the\nexpense of weaker privacy guarantees. We discuss in detail the computational\nand communication complexity properties of both algorithms theoretically and\nalso through implementations. We conclude the paper with a discussion on\ncomputational privacy and other notions of privacy such as the non-unique\nretrieval of the private information from the protocol outputs. \n\n"}
{"id": "1809.02923", "contents": "Title: Comparison-Based Algorithms for One-Dimensional Stochastic Convex\n  Optimization Abstract: Stochastic optimization finds a wide range of applications in operations\nresearch and management science. However, existing stochastic optimization\ntechniques usually require the information of random samples (e.g., demands in\nthe newsvendor problem) or the objective values at the sampled points (e.g.,\nthe lost sales cost), which might not be available in practice. In this paper,\nwe consider a new setup for stochastic optimization, in which the decision\nmaker has access to only comparative information between a random sample and\ntwo chosen decision points in each iteration. We propose a comparison-based\nalgorithm (CBA) to solve such problems in one dimension with convex objective\nfunctions. Particularly, the CBA properly chooses the two points in each\niteration and constructs an unbiased gradient estimate for the original\nproblem. We show that the CBA achieves the same convergence rate as the optimal\nstochastic gradient methods (with the samples observed). We also consider\nextensions of our approach to multi-dimensional quadratic problems as well as\nproblems with non-convex objective functions. Numerical experiments show that\nthe CBA performs well in test problems. \n\n"}
{"id": "1809.03066", "contents": "Title: Multi-agent online learning in time-varying games Abstract: We examine the long-run behavior of multi-agent online learning in games that\nevolve over time. Specifically, we focus on a wide class of policies based on\nmirror descent, and we show that the induced sequence of play (a) converges to\nNash equilibrium in time-varying games that stabilize in the long run to a\nstrictly monotone limit; and (b) it stays asymptotically close to the evolving\nequilibrium of the sequence of stage games (assuming they are strongly\nmonotone). Our results apply to both gradient-based and payoff-based feedback -\ni.e., the \"bandit feedback\" case where players only get to observe the payoffs\nof their chosen actions. \n\n"}
{"id": "1809.04198", "contents": "Title: Optimization with Non-Differentiable Constraints with Applications to\n  Fairness, Recall, Churn, and Other Goals Abstract: We show that many machine learning goals, such as improved fairness metrics,\ncan be expressed as constraints on the model's predictions, which we call rate\nconstraints. We study the problem of training non-convex models subject to\nthese rate constraints (or any non-convex and non-differentiable constraints).\nIn the non-convex setting, the standard approach of Lagrange multipliers may\nfail. Furthermore, if the constraints are non-differentiable, then one cannot\noptimize the Lagrangian with gradient-based methods. To solve these issues, we\nintroduce the proxy-Lagrangian formulation. This new formulation leads to an\nalgorithm that produces a stochastic classifier by playing a two-player\nnon-zero-sum game solving for what we call a semi-coarse correlated\nequilibrium, which in turn corresponds to an approximately optimal and feasible\nsolution to the constrained optimization problem. We then give a procedure\nwhich shrinks the randomized solution down to one that is a mixture of at most\n$m+1$ deterministic solutions, given $m$ constraints. This culminates in\nalgorithms that can solve non-convex constrained optimization problems with\npossibly non-differentiable and non-convex constraints with theoretical\nguarantees. We provide extensive experimental results enforcing a wide range of\npolicy goals including different fairness metrics, and other goals on accuracy,\ncoverage, recall, and churn. \n\n"}
{"id": "1809.05994", "contents": "Title: Approximate super-resolution of positive measures in all dimensions Abstract: We study the problem of reconstructing a positive discrete measure on a\ncompact set $K \\subseteq \\mathbb{R}^n$ from a finite set of moments (possibly\nknown only approximately) via convex optimization. We give new uniqueness\nresults, new quantitative estimates for approximate recovery and a new\nsum-of-squares based hierarchy for approximate super-resolution on compact\nsemi-algebraic sets. \n\n"}
{"id": "1809.06704", "contents": "Title: An Inexact First-order Method for Constrained Nonlinear Optimization Abstract: The primary focus of this paper is on designing an inexact first-order\nalgorithm for solving constrained nonlinear optimization problems. By\ncontrolling the inexactness of the subproblem solution, we can significantly\nreduce the computational cost needed for each iteration. A penalty parameter\nupdating strategy during the process of solving the subproblem enables the\nalgorithm to automatically detect infeasibility. Global convergence for both\nfeasible and infeasible cases are proved. Complexity analysis for the KKT\nresidual is also derived under mild assumptions. Numerical experiments exhibit\nthe ability of the proposed algorithm to rapidly find inexact optimal solution\nthrough cheap computational cost. \n\n"}
{"id": "1809.08139", "contents": "Title: Optimal investment and consumption for Ornstein-Uhlenbeck spread\n  financial markets with logarithmic utility Abstract: We consider a spread financial market defined by the multidimensional\nOrnstein--Uhlenbeck (OU) process. We study the optimal consumption/investment\nproblem for logarithmic utility functions in the base of stochastic dynamical\nprogramming method. We show a special Verification Theorem for this case. We\nfind the solution to the Hamilton--Jacobi--Bellman (HJB) equation in explicit\nform and as a consequence we construct the optimal financial strategies.\nMoreover, we study the constructed strategy by numerical simulations. \n\n"}
{"id": "1809.09037", "contents": "Title: Optimal Distributed Control of a Cahn-Hilliard-Darcy System with Mass\n  Sources Abstract: In this paper, we study an optimal control problem for a two-dimensional\nCahn-Hilliard-Darcy system with mass sources that arises in the modeling of\ntumor growth. The aim is to monitor the tumor fraction in a finite time\ninterval in such a way that both the tumor fraction, measured in terms of a\ntracking type cost functional, is kept under control and minimal harm is\ninflicted to the patient by administering the control, which could either be a\ndrug or nutrition. We first prove that the optimal control problem admits a\nsolution. Then we show that the control-to-state operator is Fr\\'echet\ndifferentiable between suitable Banach spaces and derive the first-order\nnecessary optimality conditions in terms of the adjoint variables and the usual\nvariational inequality. \n\n"}
{"id": "1809.09716", "contents": "Title: Sampling-based Polytopic Trees for Approximate Optimal Control of\n  Piecewise Affine Systems Abstract: Piecewise affine (PWA) systems are widely used to model highly nonlinear\nbehaviors such as contact dynamics in robot locomotion and manipulation.\nExisting control techniques for PWA systems have computational drawbacks, both\nin offline design and online implementation. In this paper, we introduce a\nmethod to obtain feedback control policies and a corresponding set of\nadmissible initial conditions for discrete-time PWA systems such that all the\nclosed-loop trajectories reach a goal polytope, while a cost function is\noptimized. The idea is conceptually similar to LQR-trees \\cite{tedrake2010lqr},\nwhich consists of 3 steps: (1) open-loop trajectory optimization, (2) feedback\ncontrol for computation of \"funnels\" of states around trajectories, and (3)\nrepeating (1) and (2) in a way that the funnels are grown backward from the\ngoal in a tree fashion and fill the state-space as much as possible. We show\nPWA dynamics can be exploited to combine step (1) and (2) into a single step\nthat is tackled using mixed-integer convex programming, which makes the method\nsuitable for dealing with hard constraints. Illustrative examples on\ncontact-based dynamics are presented. \n\n"}
{"id": "1809.09809", "contents": "Title: Penalized Parabolic Relaxation for Optimal Power Flow Problem Abstract: This paper is concerned with optimal power flow (OPF), which is the problem\nof optimizing the transmission of electricity in power systems. Our main\ncontributions are as follows: (i) we propose a novel parabolic relaxation,\nwhich transforms non-convex OPF problems into convex quadratically-constrained\nquadratic programs (QCQPs) and can serve as an alternative to the common\npractice semidefinite programming (SDP) and second-order cone programming\n(SOCP) relaxations, (ii) we propose a penalization technique which is\ncompatible with the SDP, SOCP, and parabolic relaxations and guarantees the\nrecovery of feasible solutions for OPF, under certain assumptions. The proposed\npenalized convex relaxation can be used sequentially to find feasible and\nnear-globally optimal solutions for challenging instances of OPF. Extensive\nnumerical experiments on small and large-scale benchmark systems corroborate\nthe efficacy of the proposed approach. By solving a few rounds of penalized\nconvex relaxation, fully feasible solutions are obtained for benchmark test\ncases from [1]-[3] with as many as 13659 buses. In all cases, the solutions\nobtained are not more than 0.32% worse than the best-known solutions. \n\n"}
{"id": "1809.09891", "contents": "Title: A Partition-Based Implementation of the Relaxed ADMM for Distributed\n  Convex Optimization over Lossy Networks Abstract: In this paper we propose a distributed implementation of the relaxed\nAlternating Direction Method of Multipliers algorithm (R-ADMM) for optimization\nof a separable convex cost function, whose terms are stored by a set of\ninteracting agents, one for each agent. Specifically the local cost stored by\neach node is in general a function of both the state of the node and the states\nof its neighbors, a framework that we refer to as `partition-based'\noptimization. This framework presents a great flexibility and can be adapted to\na large number of different applications. We show that the partition-based\nR-ADMM algorithm we introduce is linked to the relaxed Peaceman-Rachford\nSplitting (R-PRS) operator which, historically, has been introduced in the\nliterature to find the zeros of sum of functions. Interestingly, making use of\nnon expansive operator theory, the proposed algorithm is shown to be provably\nrobust against random packet losses that might occur in the communication\nbetween neighboring nodes. Finally, the effectiveness of the proposed algorithm\nis confirmed by a set of compelling numerical simulations run over random\ngeometric graphs subject to i.i.d. random packet losses. \n\n"}
{"id": "1810.00092", "contents": "Title: The Partially Observable Games We Play for Cyber Deception Abstract: Progressively intricate cyber infiltration mechanisms have made conventional\nmeans of defense, such as firewalls and malware detectors, incompetent. These\nsophisticated infiltration mechanisms can study the defender's behavior,\nidentify security caveats, and modify their actions adaptively. To tackle these\nsecurity challenges, cyber-infrastructures require active defense techniques\nthat incorporate cyber deception, in which the defender (deceiver) implements a\nstrategy to mislead the infiltrator. To this end, we use a two-player partially\nobservable stochastic game (POSG) framework, wherein the deceiver has full\nobservability over the states of the POSG, and the infiltrator has partial\nobservability. Then, the deception problem is to compute a strategy for the\ndeceiver that minimizes the expected cost of deception against all strategies\nof the infiltrator. We first show that the underlying problem is a robust\nmixed-integer linear program, which is intractable to solve in general. Towards\na scalable approach, we compute optimal finite-memory strategies for the\ninfiltrator by a reduction to a series of synthesis problems for parametric\nMarkov decision processes. We use these infiltration strategies to find robust\nstrategies for the deceiver using mixed-integer linear programming. We\nillustrate the performance of our technique on a POSG model for network\nsecurity. Our experiments demonstrate that the proposed approach handles\nscenarios considerably larger than those of the state-of-the-art methods. \n\n"}
{"id": "1810.01066", "contents": "Title: PDE Acceleration: A convergence rate analysis and applications to\n  obstacle problems Abstract: This paper provides a rigorous convergence rate and complexity analysis for a\nrecently introduced framework, called PDE acceleration, for solving problems in\nthe calculus of variations, and explores applications to obstacle problems. PDE\nacceleration grew out of a variational interpretation of momentum methods, such\nas Nesterov's accelerated gradient method and Polyak's heavy ball method, that\nviews acceleration methods as equations of motion for a generalized Lagrangian\naction. Its application to convex variational problems yields equations of\nmotion in the form of a damped nonlinear wave equation rather than nonlinear\ndiffusion arising from gradient descent. These accelerated PDE's can be\nefficiently solved with simple explicit finite difference schemes where\nacceleration is realized by an improvement in the CFL condition from $dt\\sim\ndx^2$ for diffusion equations to $dt\\sim dx$ for wave equations. In this paper,\nwe prove a linear convergence rate for PDE acceleration for strongly convex\nproblems, provide a complexity analysis of the discrete scheme, and show how to\noptimally select the damping parameter for linear problems. We then apply PDE\nacceleration to solve minimal surface obstacle problems, including double\nobstacles with forcing, and stochastic homogenization problems with obstacles,\nobtaining state of the art computational results. \n\n"}
{"id": "1810.02022", "contents": "Title: Convergence of the Expectation-Maximization Algorithm Through\n  Discrete-Time Lyapunov Stability Theory Abstract: In this paper, we propose a dynamical systems perspective of the\nExpectation-Maximization (EM) algorithm. More precisely, we can analyze the EM\nalgorithm as a nonlinear state-space dynamical system. The EM algorithm is\nwidely adopted for data clustering and density estimation in statistics,\ncontrol systems, and machine learning. This algorithm belongs to a large class\nof iterative algorithms known as proximal point methods. In particular, we\nre-interpret limit points of the EM algorithm and other local maximizers of the\nlikelihood function it seeks to optimize as equilibria in its dynamical system\nrepresentation. Furthermore, we propose to assess its convergence as asymptotic\nstability in the sense of Lyapunov. As a consequence, we proceed by leveraging\nrecent results regarding discrete-time Lyapunov stability theory in order to\nestablish asymptotic stability (and thus, convergence) in the dynamical system\nrepresentation of the EM algorithm. \n\n"}
{"id": "1810.02463", "contents": "Title: Comparing Averaged Relaxed Cutters and Projection Methods: Theory and\n  Examples Abstract: We focus on the convergence analysis of averaged relaxations of cutters,\nspecifically for variants that---depending upon how parameters are\nchosen---resemble \\emph{alternating projections}, the \\emph{Douglas--Rachford\nmethod}, \\emph{relaxed reflect-reflect}, or the \\emph{Peaceman--Rachford}\nmethod. Such methods are frequently used to solve convex feasibility problems.\nThe standard convergence analyses of projection algorithms are based on the\n\\emph{firm nonexpansivity} property of the relevant operators. However if the\nprojections onto the constraint sets are replaced by cutters (projections onto\nseparating hyperplanes), the firm nonexpansivity is lost. We provide a proof of\nconvergence for a family of related averaged relaxed cutter methods under\nreasonable assumptions, relying on a simple geometric argument. This allows us\nto clarify fine details related to the allowable choice of the relaxation\nparameters, highlighting the distinction between the exact (firmly\nnonexpansive) and approximate (strongly quasi-nonexpansive) settings. We\nprovide illustrative examples and discuss practical implementations of the\nmethod. \n\n"}
{"id": "1810.02677", "contents": "Title: Convex Clustering: Model, Theoretical Guarantee and Efficient Algorithm Abstract: Clustering is a fundamental problem in unsupervised learning. Popular methods\nlike K-means, may suffer from poor performance as they are prone to get stuck\nin its local minima. Recently, the sum-of-norms (SON) model (also known as the\nclustering path) has been proposed in Pelckmans et al. (2005), Lindsten et al.\n(2011) and Hocking et al. (2011). The perfect recovery properties of the convex\nclustering model with uniformly weighted all pairwise-differences\nregularization have been proved by Zhu et al. (2014) and Panahi et al. (2017).\nHowever, no theoretical guarantee has been established for the general weighted\nconvex clustering model, where better empirical results have been observed. In\nthe numerical optimization aspect, although algorithms like the alternating\ndirection method of multipliers (ADMM) and the alternating minimization\nalgorithm (AMA) have been proposed to solve the convex clustering model (Chi\nand Lange, 2015), it still remains very challenging to solve large-scale\nproblems. In this paper, we establish sufficient conditions for the perfect\nrecovery guarantee of the general weighted convex clustering model, which\ninclude and improve existing theoretical results as special cases. In addition,\nwe develop a semismooth Newton based augmented Lagrangian method for solving\nlarge-scale convex clustering problems. Extensive numerical experiments on both\nsimulated and real data demonstrate that our algorithm is highly efficient and\nrobust for solving large-scale problems. Moreover, the numerical results also\nshow the superior performance and scalability of our algorithm comparing to the\nexisting first-order methods. In particular, our algorithm is able to solve a\nconvex clustering problem with 200,000 points in $\\mathbb{R}^3$ in about 6\nminutes. \n\n"}
{"id": "1810.02893", "contents": "Title: Optimization on Spheres: Models and Proximal Algorithms with\n  Computational Performance Comparisons Abstract: We present a unified treatment of the abstract problem of finding the best\napproximation between a cone and spheres in the image of affine\ntransformations. Prominent instances of this problem are phase retrieval and\nsource localization. The common geometry binding these problems permits a\ngeneric application of algorithmic ideas and abstract convergence results for\nnonconvex optimization. We organize variational models for this problem into\nthree different classes and derive the main algorithmic approaches within these\nclasses (13 in all). We identify the central ideas underlying these methods and\nprovide thorough numerical benchmarks comparing their performance on synthetic\nand laboratory data. The software and data of our experiments are all publicly\naccessible. We also introduce one new algorithm, a cyclic relaxed\nDouglas-Rachford algorithm, which outperforms all other algorithms by every\nmeasure: speed, stability and accuracy. The analysis of this algorithm remains\nopen. \n\n"}
{"id": "1810.03125", "contents": "Title: Decomposition of completely symmetric states states Abstract: In this paper, we consider a subclass of quantum states in the multipartite\nsystem, namely, the supersymmetric states. We investigate the problem whether\nthey admit the symmetrically separable decomposition, i.e., each term in this\ndecomposition is a supersymmetric pure product state $|x,x\\rangle\\langle x,x|$,\nwhich are called S-separable. We conjecture that any supersymmetric states are\nS-separable and we prove that this conjecture holds when the rank is less than\nor equal to 3 or $N$. Moreover, we propose another weaker conjecture that any\nseparable supersymmetric states are S-separable. It was proved to be true when\nthe rank is less than or equal to $4$ or $N+1$. We also propose a numerical\nalgorithm which is able to detect S-separability. Besides, we analysis the\nconvergence behavior of this algorithm. Some numerical examples are tested to\nshow the effectiveness of the algorithm. \n\n"}
{"id": "1810.03724", "contents": "Title: Optimal Steady-State Control for Linear Time-Invariant Systems Abstract: We consider the problem of designing a feedback controller that guides the\ninput and output of a linear time-invariant system to a minimizer of a convex\noptimization problem. The system is subject to an unknown disturbance that\ndetermines the feasible set defined by the system equilibrium constraints. Our\nproposed design enforces the Karush-Kuhn-Tucker optimality conditions in\nsteady-state without incorporating dual variables into the controller. We prove\nthat the input and output variables achieve optimality in equilibrium and\noutline two procedures for designing controllers that stabilize the closed-loop\nsystem. We explore key ideas through simple examples and simulations. \n\n"}
{"id": "1810.04055", "contents": "Title: Testing hyperbolicity of real polynomials Abstract: Hyperbolic polynomials are real multivariate polynomials with only real roots\nalong a fixed pencil of lines. Testing whether a given polynomial is hyperbolic\nis a difficult task in general. We examine different ways of translating\nhyperbolicity into nonnegativity conditions, which can then be tested via\nsum-of-squares relaxations. \n\n"}
{"id": "1810.04100", "contents": "Title: Characterization of Convex Objective Functions and Optimal Expected\n  Convergence Rates for SGD Abstract: We study Stochastic Gradient Descent (SGD) with diminishing step sizes for\nconvex objective functions. We introduce a definitional framework and theory\nthat defines and characterizes a core property, called curvature, of convex\nobjective functions. In terms of curvature we can derive a new inequality that\ncan be used to compute an optimal sequence of diminishing step sizes by solving\na differential equation. Our exact solutions confirm known results in\nliterature and allows us to fully characterize a new regularizer with its\ncorresponding expected convergence rates. \n\n"}
{"id": "1810.04352", "contents": "Title: Stability-constrained Optimization for Nonlinear Systems based on Convex\n  Lyapunov Functions Abstract: This paper presents a novel scalable framework to solve the optimization of a\nnonlinear system with differential algebraic equation (DAE) constraints that\nenforce the asymptotic stability of the underlying dynamic model with respect\nto certain disturbances. Existing solution approaches to analogous\nDAE-constrained problems are based on discretization of DAE system into a large\nset of nonlinear algebraic equations representing the time-marching schemes.\nThese approaches are not scalable to large size models. The proposed framework,\nbased on LaSalle's invariance principle, uses convex Lyapunov functions to\ndevelop a novel stability certificate which consists of a limited number of\nalgebraic constraints. We develop specific algorithms for two major types of\nnonlinearities, namely Lur'e, and quasi-polynomial systems. Quadratic and\nconvex-sum-of-square Lyapunov functions are constructed for the Lur'e-type and\nquasi-polynomial systems respectively. A numerical experiment is performed on a\n3-generator power network to obtain a solution for\ntransient-stability-constrained optimal power flow. \n\n"}
{"id": "1810.05471", "contents": "Title: Safe Grid Search with Optimal Complexity Abstract: Popular machine learning estimators involve regularization parameters that\ncan be challenging to tune, and standard strategies rely on grid search for\nthis task. In this paper, we revisit the techniques of approximating the\nregularization path up to predefined tolerance $\\epsilon$ in a unified\nframework and show that its complexity is $O(1/\\sqrt[d]{\\epsilon})$ for\nuniformly convex loss of order $d \\geq 2$ and $O(1/\\sqrt{\\epsilon})$ for\nGeneralized Self-Concordant functions. This framework encompasses least-squares\nbut also logistic regression, a case that as far as we know was not handled as\nprecisely in previous works. We leverage our technique to provide refined\nbounds on the validation error as well as a practical algorithm for\nhyperparameter tuning. The latter has global convergence guarantee when\ntargeting a prescribed accuracy on the validation set. Last but not least, our\napproach helps relieving the practitioner from the (often neglected) task of\nselecting a stopping criterion when optimizing over the training set: our\nmethod automatically calibrates this criterion based on the targeted accuracy\non the validation set. \n\n"}
{"id": "1810.06177", "contents": "Title: Revisit Batch Normalization: New Understanding from an Optimization View\n  and a Refinement via Composition Optimization Abstract: Batch Normalization (BN) has been used extensively in deep learning to\nachieve faster training process and better resulting models. However, whether\nBN works strongly depends on how the batches are constructed during training\nand it may not converge to a desired solution if the statistics on a batch are\nnot close to the statistics over the whole dataset. In this paper, we try to\nunderstand BN from an optimization perspective by formulating the optimization\nproblem which motivates BN. We show when BN works and when BN does not work by\nanalyzing the optimization problem. We then propose a refinement of BN based on\ncompositional optimization techniques called Full Normalization (FN) to\nalleviate the issues of BN when the batches are not constructed ideally. We\nprovide convergence analysis for FN and empirically study its effectiveness to\nrefine BN. \n\n"}
{"id": "1810.07222", "contents": "Title: Optimal Network Topology Design in Composite Systems with Constrained\n  Neighbors for Structural Controllability Abstract: Composite systems are large complex systems con- sisting of interconnected\nagents (subsystems). Agents in a com- posite system interact with each other\ntowards performing an in- tended goal. Controllability is essential to achieve\ndesired system performance in linear time-invariant composite systems. Agents\nin a composite system are often uncontrollable individually, further, only a\nfew agents receive input. In such a case, the agents share/communicate their\nprivate state information with pre-specified neighboring agents so as to\nachieve controllability. Our objective in this paper is to identify an optimal\nnetwork topology, optimal in the sense of minimum cardinality information\ntransfer between agents to guarantee the controllability of the composite\nsystem when the possible neighbor set of each agent is pre-specified. We focus\non graph-theoretic analysis referred to as structural controllability as\nnumerical entries of system matrices in complex systems are mostly unknown. We\nfirst prove that given a set of agents and the possible set of neighbors,\nfinding a minimum cardinality set of information (interconnections) that must\nbe shared to accomplish structural controllability of the composite system is\nNP-hard. Subsequently, we present a polynomial-time algorithm that finds a\n2-optimal solution to this NP-hard problem. Our algorithm combines a minimum\nweight bipartite matching algorithm and a minimum spanning tree algorithm and\ngives a subset of interconnections which when established guarantees structural\ncontrollability, such that the worst-case performance is 2-optimal. Finally, we\nshow that our approach directly extends to weighted constrained optimal net-\nwork topology design problem and constrained optimal network topology design\nproblem in switched linear systems. \n\n"}
{"id": "1810.07393", "contents": "Title: Optimization over time-varying directed graphs with row and\n  column-stochastic matrices Abstract: In this paper, we provide a distributed optimization algorithm, termed as\nTV-$\\mathcal{AB}$, that minimizes a sum of convex functions over time-varying,\nrandom directed graphs. Contrary to the existing work, the algorithm we propose\ndoes not require eigenvector estimation to estimate the (non-$\\mathbf{1}$)\nPerron eigenvector of a stochastic matrix. Instead, the proposed approach\nrelies on a novel information mixing approach that exploits both row- and\ncolumn-stochastic weights to achieve agreement towards the optimal solution\nwhen the underlying graph is directed. We show that TV-$\\mathcal{AB}$ converges\nlinearly to the optimal solution when the global objective is smooth and\nstrongly-convex, and the underlying time-varying graphs exhibit bounded\nconnectivity, i.e., a union of every $C$ consecutive graphs is\nstrongly-connected. We derive the convergence results based on the stability\nanalysis of a linear system of inequalities along with a matrix perturbation\nargument. Simulations confirm the findings in this paper. \n\n"}
{"id": "1810.08907", "contents": "Title: Understanding the Acceleration Phenomenon via High-Resolution\n  Differential Equations Abstract: Gradient-based optimization algorithms can be studied from the perspective of\nlimiting ordinary differential equations (ODEs). Motivated by the fact that\nexisting ODEs do not distinguish between two fundamentally different\nalgorithms---Nesterov's accelerated gradient method for strongly convex\nfunctions (NAG-SC) and Polyak's heavy-ball method---we study an alternative\nlimiting process that yields high-resolution ODEs. We show that these ODEs\npermit a general Lyapunov function framework for the analysis of convergence in\nboth continuous and discrete time. We also show that these ODEs are more\naccurate surrogates for the underlying algorithms; in particular, they not only\ndistinguish between NAG-SC and Polyak's heavy-ball method, but they allow the\nidentification of a term that we refer to as \"gradient correction\" that is\npresent in NAG-SC but not in the heavy-ball method and is responsible for the\nqualitative difference in convergence of the two methods. We also use the\nhigh-resolution ODE framework to study Nesterov's accelerated gradient method\nfor (non-strongly) convex functions, uncovering a hitherto unknown\nresult---that NAG-C minimizes the squared gradient norm at an inverse cubic\nrate. Finally, by modifying the high-resolution ODE of NAG-C, we obtain a\nfamily of new optimization methods that are shown to maintain the accelerated\nconvergence rates of NAG-C for smooth convex functions. \n\n"}
{"id": "1810.09872", "contents": "Title: Non-convex approach to binary compressed sensing Abstract: We propose a new approach to the recovery of binary signals in compressed\nsensing, based on the local minimization of a non-convex cost functional. The\ndesired signal is proved to be a local minimum of the functional under mild\nconditions on the sensing matrix and on the number of measurements. We develop\na procedure to achieve the desired local minimum, and, finally, we propose\nnumerical experiments that show the improvement obtained by the proposed\napproach with respect to the classical convex approach, i.e., Lasso. \n\n"}
{"id": "1810.10085", "contents": "Title: A Proximal Zeroth-Order Algorithm for Nonconvex Nonsmooth Problems Abstract: In this paper, we focus on solving an important class of nonconvex\noptimization problems which includes many problems for example signal\nprocessing over a networked multi-agent system and distributed learning over\nnetworks. Motivated by many applications in which the local objective function\nis the sum of smooth but possibly nonconvex part, and non-smooth but convex\npart subject to a linear equality constraint, this paper proposes a proximal\nzeroth-order primal dual algorithm (PZO-PDA) that accounts for the information\nstructure of the problem. This algorithm only utilize the zeroth-order\ninformation (i.e., the functional values) of smooth functions, yet the\nflexibility is achieved for applications that only noisy information of the\nobjective function is accessible, where classical methods cannot be applied. We\nprove convergence and rate of convergence for PZO-PDA. Numerical experiments\nare provided to validate the theoretical results. \n\n"}
{"id": "1810.10207", "contents": "Title: First-order Convergence Theory for Weakly-Convex-Weakly-Concave Min-max\n  Problems Abstract: In this paper, we consider first-order convergence theory and algorithms for\nsolving a class of non-convex non-concave min-max saddle-point problems, whose\nobjective function is weakly convex in the variables of minimization and weakly\nconcave in the variables of maximization. It has many important applications in\nmachine learning including training Generative Adversarial Nets (GANs). We\npropose an algorithmic framework motivated by the inexact proximal point\nmethod, where the weakly monotone variational inequality (VI) corresponding to\nthe original min-max problem is solved through approximately solving a sequence\nof strongly monotone VIs constructed by adding a strongly monotone mapping to\nthe original gradient mapping. We prove first-order convergence to a nearly\nstationary solution of the original min-max problem of the generic algorithmic\nframework and establish different rates by employing different algorithms for\nsolving each strongly monotone VI. Experiments verify the convergence theory\nand also demonstrate the effectiveness of the proposed methods on training\nGANs. \n\n"}
{"id": "1810.11831", "contents": "Title: Latency-Reliability Tradeoffs for State Estimation Abstract: The emerging interest in low-latency high-reliability applications, such as\nconnected vehicles, necessitates a new abstraction between communication and\ncontrol. Thanks to advances in cyber-physical systems over the past decades, we\nunderstand this interface for classical bit-rate models of channels as well as\npacket-loss-type channels. This work proposes a new abstraction characterized\nas a tradeoff curve between latency, reliability and rate. Our aim is to\nunderstand: Do we (control engineers) prefer faster but less reliable\ncommunications (with shorter codes), or slower but more reliable communications\n(with longer codes)? In this paper we examine the tradeoffs between latency and\nreliability for the problem of estimating dynamical systems over communication\nchannels. Employing different latency-reliability curves derived from practical\ncoding schemes, we develop a co-design methodology, i.e., select the code\nlength depending on the system dynamics to optimize system performance. \n\n"}
{"id": "1810.12036", "contents": "Title: Small noise limit and convexity for generalized incompressible flows,\n  Schr\\\"odinger problems, and optimal transport Abstract: This paper is concerned with six variational problems and their mutual\nconnections: The quadratic Monge-Kantorovich optimal transport, the\nSchr\\\"odinger problem, Brenier's relaxed model for incompressible fluids, the\nso-called Br\\\"odinger problem recently introduced by M. Arnaudon & al. [3], the\nmultiphase Brenier model, and the multiphase Br\\\"odinger problem. All of them\ninvolve the minimization of a kinetic action and/or a relative entropy of some\npath measures with respect to the reversible Brownian motion. As the viscosity\nparameter $\\nu\\to 0$ we establish Gamma-convergence relations between the\ncorresponding problems, and prove the convergence of the associated pressures\narising from the incompressibility constraints. We also present new results on\nthe time-convexity of the entropy for some of the dynamical interpolations.\nAlong the way we extend previous results by H. Lavenant [30] and J-D. Benamou &\nal. [10]. \n\n"}
{"id": "1810.12240", "contents": "Title: Eco-PANDA: A Computationally Economic, Geometrically Converging, Dual\n  Optimization Method on Time-Varying Undirected Graphs Abstract: In this paper we consider distributed convex optimization over time-varying\nundirected graphs. We propose a linearized version of primarily averaged\nnetwork dual ascent (PANDA) while requiring less computational costs. The\nproposed method, economic primarily averaged network dual ascent (Eco-PANDA),\nprovably converges at R-linear rate to the optimal point given that the agents'\nobjective functions are strongly convex and have Lipschitz continuous\ngradients. Therefore, the method is competitive, in terms of type of rate, with\nboth DIGing and PANDA. The proposed method halves the communication costs of\nmethods like DIGing while still converging R-linearly and having the same per\niterate complexity. \n\n"}
{"id": "1810.12817", "contents": "Title: Nonlocal $p$-Laplacian Variational problems on graphs Abstract: In this paper, we study a nonlocal variational problem which consists of\nminimizing in $L^2$ the sum of a quadratic data fidelity and a regularization\nterm corresponding to the $L^p$-norm of the nonlocal gradient. In particular,\nwe study convergence of the numerical solution to a discrete version of this\nnonlocal variational problem to the unique solution of the continuum one. To do\nso, we derive an error bound and highlight the role of the initial data and the\nkernel governing the nonlocal interactions. When applied to variational problem\non graphs, this error bound allows us to show the consistency of the\ndiscretized variational problem as the number of vertices goes to infinity.\nMore precisely, for networks in convergent graph sequences (simple and weighted\ndeterministic dense graphs as well as random inhomogeneous graphs), we prove\nconvergence and provide rate of convergence of solutions for the discrete\nmodels to the solution of the continuum problem as the number of vertices\ngrows. \n\n"}
{"id": "1810.12870", "contents": "Title: A stochastic algorithm for deterministic multistage optimization\n  problems Abstract: Several attempts to dampen the curse of dimensionnality problem of the\nDynamic Programming approach for solving multistage optimization problems have\nbeen investigated. One popular way to address this issue is the Stochastic Dual\nDynamic Programming method (SDDP) introduced by Perreira and Pinto in 1991 for\nMarkov Decision Processes. Assuming that the value function is convex (for a\nminimization problem), one builds a non-decreasing sequence of lower (or outer)\nconvex approximations of the value function. Those convex approximations are\nconstructed as a supremum of affine cuts. On continuous time deterministic\noptimal control problems, assuming that the value function is semiconvex, Zheng\nQu, inspired by the work of McEneaney, introduced in 2013 a stochastic max-plus\nscheme that builds upper (or inner) non-increasing approximations of the value\nfunction. In this note, we build a common framework for both the SDDP and a\ndiscrete time version of Zheng Qu's algorithm to solve deterministic multistage\noptimization problems. Our algorithm generates monotone approximations of the\nvalue functions as a pointwise supremum, or infimum, of basic (affine or\nquadratic for example) functions which are randomly selected. We give\nsufficient conditions on the way basic functions are selected in order to\nensure almost sure convergence of the approximations to the value function on a\nset of interest. \n\n"}
{"id": "1811.00444", "contents": "Title: A Polyhedral Model for Enumeration and Optimization over the Set of\n  Circuits Abstract: Circuits play a fundamental role in polyhedral theory and linear programming.\nFor instance, circuits are used as step directions in various augmentation\nschemes for solving linear programs or to leave degenerate vertices while\nrunning the simplex method. However, there are significant challenges when\nimplementing these approaches: The set of circuits of a polyhedron may be of\nexponential size and is highly sensitive to the representation of the\npolyhedron.\n  In this paper, we provide a universal framework for enumerating the set of\ncircuits and optimizing over sets of circuits of a polyhedron in any\nrepresentation - we propose a polyhedral model in which the circuits of the\noriginal polyhedron are encoded as extreme rays or vertices. Many methods in\nthe literature and software assume that a polyhedron is in standard form; our\nframework is a direct generalization. We demonstrate its value by showing that\nthe conversion of a general representation to standard form may introduce\nexponentially many new circuits.\n  We then discuss the main advantages of the generalized polyhedral model. It\nenables the direct enumeration of useful subsets of circuits such as strictly\nfeasible circuits or sign-compatible circuits, as well as optimization over\nthese sets. In particular, this leads to the efficient computation of a\nsteepest-descent circuit, which can be used in an augmentation scheme for\nsolving linear programs or the construction of sign-compatible circuit walks\nwith additional \n\n"}
{"id": "1811.01383", "contents": "Title: An Algorithm for Integer Least-squares with Equality, Sparsity and Rank\n  Constraints Abstract: In this work, we deal with rank-constrained integer least-squares\noptimization problems arising in low-rank matrix factorization related\napplications. We propose a solution for constrained integer least-squares\nproblem subject to equality, sparsity, and rank constraints. The algorithm\ncombines the Fincke-Pohst enumeration (or sphere decoding algorithm) with rank\nconstraints and sparse solutions of Diophantine equations to arrive at an\noptimal solution. The proposed approach consists of two steps as follows: (i)\nfind the solution set for Diophantine equations arising from the linear and\nsparsity constraints, (ii) find the matrix which minimizes the integer\nleast-squares objective and satisfying the rank constraints using the solution\nset obtained in the step 1. The proposed algorithm is illustrated using a\nsimple example. Then, we perform experiments to study the computational aspects\nof different steps of the proposed algorithm. \n\n"}
{"id": "1811.01420", "contents": "Title: Continuity of Utility Maximization under Weak Convergence Abstract: In this paper we find tight sufficient conditions for the continuity of the\nvalue of the utility maximization problem from terminal wealth with respect to\nthe convergence in distribution of the underlying processes. We also establish\na weak convergence result for the terminal wealths of the optimal portfolios.\nFinally, we apply our results to the computation of the minimal expected\nshortfall (shortfall risk) in the Heston model by building an appropriate\nlattice approximation. \n\n"}
{"id": "1811.01940", "contents": "Title: Dynamic Programming Deconstructed: Transformations of the Bellman\n  Equation and Computational Efficiency Abstract: Some approaches to solving challenging dynamic programming problems, such as\nQ-learning, begin by transforming the Bellman equation into an alternative\nfunctional equation, in order to open up a new line of attack. Our paper\nstudies this idea systematically, with a focus on boosting computational\nefficiency. We provide a characterization of the set of valid transformations\nof the Bellman equation, where validity means that the transformed Bellman\nequation maintains the link to optimality held by the original Bellman\nequation. We then examine the solutions of the transformed Bellman equations\nand analyze correspondingly transformed versions of the algorithms used to\nsolve for optimal policies. These investigations yield new approaches to a\nvariety of discrete time dynamic programming problems, including those with\nfeatures such as recursive preferences or desire for robustness. Increased\ncomputational efficiency is demonstrated via time complexity arguments and\nnumerical experiments. \n\n"}
{"id": "1811.02811", "contents": "Title: Remarks on Nash equilibria in mean field game models with a major player Abstract: For a mean field game model with a major and infinite minor players, we\ncharacterize a notion of Nash equilibrium via a system of so-called master\nequations, namely a system of nonlinear transport equations in the space of\nmeasures. Then, for games with a finite number N of minor players and a major\nplayer, we prove that the solution of the corresponding Nash system converges\nto the solution of the system of master equations as N tends to infinity. \n\n"}
{"id": "1811.03761", "contents": "Title: RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed\n  Learning from Heterogeneous Datasets Abstract: In this paper, we propose a class of robust stochastic subgradient methods\nfor distributed learning from heterogeneous datasets at presence of an unknown\nnumber of Byzantine workers. The Byzantine workers, during the learning\nprocess, may send arbitrary incorrect messages to the master due to data\ncorruptions, communication failures or malicious attacks, and consequently bias\nthe learned model. The key to the proposed methods is a regularization term\nincorporated with the objective function so as to robustify the learning task\nand mitigate the negative effects of Byzantine attacks. The resultant\nsubgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation\nmethods, justifying our acronym RSA used henceforth. In contrast to most of the\nexisting algorithms, RSA does not rely on the assumption that the data are\nindependent and identically distributed (i.i.d.) on the workers, and hence fits\nfor a wider class of applications. Theoretically, we show that: i) RSA\nconverges to a near-optimal solution with the learning error dependent on the\nnumber of Byzantine workers; ii) the convergence rate of RSA under Byzantine\nattacks is the same as that of the stochastic gradient descent method, which is\nfree of Byzantine attacks. Numerically, experiments on real dataset corroborate\nthe competitive performance of RSA and a complexity reduction compared to the\nstate-of-the-art alternatives. \n\n"}
{"id": "1811.05890", "contents": "Title: Data-Enabled Predictive Control: In the Shallows of the DeePC Abstract: We consider the problem of optimal trajectory tracking for unknown systems. A\nnovel data-enabled predictive control (DeePC) algorithm is presented that\ncomputes optimal and safe control policies using real-time feedback driving the\nunknown system along a desired trajectory while satisfying system constraints.\nUsing a finite number of data samples from the unknown system, our proposed\nalgorithm uses a behavioural systems theory approach to learn a non-parametric\nsystem model used to predict future trajectories. The DeePC algorithm is shown\nto be equivalent to the classical and widely adopted Model Predictive Control\n(MPC) algorithm in the case of deterministic linear time-invariant systems. In\nthe case of nonlinear stochastic systems, we propose regularizations to the\nDeePC algorithm. Simulations are provided to illustrate performance and compare\nthe algorithm with other methods. \n\n"}
{"id": "1811.08937", "contents": "Title: Acceleration of Primal-Dual Methods by Preconditioning and Simple\n  Subproblem Procedures Abstract: Primal-Dual Hybrid Gradient (PDHG) and Alternating Direction Method of\nMultipliers (ADMM) are two widely-used first-order optimization methods. They\nreduce a difficult problem to simple subproblems, so they are easy to implement\nand have many applications. As first-order methods, however, they are sensitive\nto problem conditions and can struggle to reach the desired accuracy. To\nimprove their performance, researchers have proposed techniques such as\ndiagonal preconditioning and inexact subproblems. This paper realizes\nadditional speedup about one order of magnitude.\n  Specifically, we choose non-diagonal preconditioners that are much more\neffective than diagonal ones. Because of this, we lose closed-form solutions to\nsome subproblems, but we found simple procedures to replace them such as a few\nproximal-gradient iterations or a few epochs of proximal block-coordinate\ndescent, which are in closed forms. We show global convergence while fixing the\nnumber of those steps in every outer iteration. Therefore, our method is\nreliable and straightforward.\n  Our method opens the choices of preconditioners and maintains both low\nper-iteration cost and global convergence. Consequently, on several typical\napplications of primal-dual first-order methods, we obtain 4-95$\\times$ speedup\nover the existing state-of-the-art. \n\n"}
{"id": "1811.09120", "contents": "Title: Obstacle Avoidance Problem for Second Degree Nonholonomic Systems Abstract: In this paper, we propose a new control design scheme for solving the\nobstacle avoidance problem for nonlinear driftless control-affine systems. The\nclass of systems under consideration satisfies controllability conditions with\niterated Lie brackets up to the second order. The time-varying control strategy\nis defined explicitly in terms of the gradient of a potential function. It is\nshown that the limit behavior of the closed-loop system is characterized by the\nset of critical points of the potential function. The proposed control design\nmethod can be used under rather general assumptions on potential functions, and\nparticular applications with navigation functions are illustrated by numerical\nexamples. \n\n"}
{"id": "1811.09311", "contents": "Title: Solving Chance Constrained Optimization under Non-Parametric Uncertainty\n  Through Hilbert Space Embedding Abstract: In this paper, we present an efficient algorithm for solving a class of\nchance constrained optimization under non-parametric uncertainty. Our algorithm\nis built on the possibility of representing arbitrary distributions as\nfunctions in Reproducing Kernel Hilbert Space (RKHS). We use this foundation to\nformulate chance constrained optimization as one of minimizing the distance\nbetween a desired distribution and the distribution of the constraint functions\nin the RKHS. We provide a systematic way of constructing the desired\ndistribution based on a notion of scenario approximation. Furthermore, we use\nthe kernel trick to show that the computational complexity of our reformulated\noptimization problem is comparable to solving a deterministic variant of the\nchance-constrained optimization. We validate our formulation on two important\nrobotic/control applications: (i) reactive collision avoidance of mobile robots\nin uncertain dynamic environments and (ii) inverse dynamics based path tracking\nof manipulators under perception uncertainty. In both these applications, the\nunderlying chance constraints are defined over highly non-linear and non-convex\nfunctions of the uncertain parameters and possibly also decision variables. We\nalso benchmark our formulation with the existing approaches in terms of sample\ncomplexity and the achieved optimal cost highlighting significant improvements\nin both these metrics. \n\n"}
{"id": "1811.10105", "contents": "Title: Inexact SARAH Algorithm for Stochastic Optimization Abstract: We develop and analyze a variant of the SARAH algorithm, which does not\nrequire computation of the exact gradient. Thus this new method can be applied\nto general expectation minimization problems rather than only finite sum\nproblems. While the original SARAH algorithm, as well as its predecessor, SVRG,\nrequire an exact gradient computation on each outer iteration, the inexact\nvariant of SARAH (iSARAH), which we develop here, requires only stochastic\ngradient computed on a mini-batch of sufficient size. The proposed method\ncombines variance reduction via sample size selection and iterative stochastic\ngradient updates. We analyze the convergence rate of the algorithms for\nstrongly convex and non-strongly convex cases, under smooth assumption with\nappropriate mini-batch size selected for each case. We show that with an\nadditional, reasonable, assumption iSARAH achieves the best known complexity\namong stochastic methods in the case of non-strongly convex stochastic\nfunctions. \n\n"}
{"id": "1811.10423", "contents": "Title: Dynamic Ecological System Measures Abstract: The system decomposition theory has recently been developed for the dynamic\nanalysis of nonlinear compartmental systems. The application of this theory to\nthe ecosystem analysis has also been introduced in a separate article. Based on\nthis methodology, multiple new dynamic ecological system measures and indices\nof matrix, vector, and scalar types are systematically introduced in the\npresent paper. These mathematical system analysis tools are quantitative\necological indicators that monitor the flow distribution and storage\norganization, quantify the direct, indirect, acyclic, cycling, and transfer\n(diact) effects and utilities of one compartment on another, identify the\nsystem efficiencies and stress, measure the compartmental exposures to system\nflows, determine the residence times and compartmental activity levels, and\nascertain the system resilience and resistance in the case of disturbances. The\nproposed dynamic system measures and indices, thus, extract detailed\ninformation about ecosystems' characteristics, as well as their functions,\nproperties, behaviors, and various other system attributes that are potentially\nhidden in and even obscured by data. A dynamic technique for the quantitative\ncharacterization and classification of main interspecific interactions and the\ndetermination of their strength within food webs is also developed based on the\ndiact effect and utility indices. Moreover, major concepts and quantities in\nthe current static network analyses are also extended to nonlinear dynamic\nsettings and integrated with the proposed dynamic measures and indices in this\nunifying mathematical framework. We consider that the proposed methodology\nbrings a novel complex system theory to the service of urgent and challenging\nenvironmental problems of the day and has the potential to lead the way to a\nmore formalistic ecological science. \n\n"}
{"id": "1812.00274", "contents": "Title: Positive semidefinite approximations to the cone of copositive kernels Abstract: It has been shown that the maximum stable set problem in some infinite\ngraphs, and the kissing number problem in particular, reduces to a minimization\nproblem over the cone of copositive kernels. Optimizing over this infinite\ndimensional cone is not tractable, and approximations of this cone have been\nhardly considered in literature. We propose two convergent hierarchies of\nsubsets of copositive kernels, in terms of non-negative and positive definite\nkernels. We use these hierarchies and representation theorems for invariant\npositive definite kernels on the sphere to construct new SDP-based bounds on\nthe kissing number. This results in fast-to-compute upper bounds on the kissing\nnumber that lie between the currently existing LP and SDP bounds. \n\n"}
{"id": "1812.00445", "contents": "Title: Distributed averaging integral Nash equilibrium seeking on networks Abstract: Continuous-time gradient-based Nash equilibrium seeking algorithms enjoy a\npassivity property under a suitable monotonicity assumption. This feature has\nbeen exploited to design distributed algorithms that converge to Nash\nequilibria and use local information only. We further exploit the passivity\nproperty to interconnect the algorithms with distributed averaging integral\ncontrollers that tune on-line the weights of the communication graph. The main\nadvantage is to guarantee convergence to a Nash equilibrium without requiring a\nstrong coupling condition on the algebraic connectivity of the communication\ngraph over which the players exchange information, nor a global high-gain. \n\n"}
{"id": "1812.00558", "contents": "Title: Subregularity of subdifferential mappings relative to the critical set\n  and KL property of exponent 1/2 Abstract: For a proper extended real-valued function, this work focuses on the\nrelationship between the subregularity of its subdifferential mapping relative\nto the critical set and its KL property of exponent 1/2. When the function is\nlsc convex, we establish the equivalence between them under the continuous\nassumption on the critical set. Then, for the uniformly prox-regular function,\nunder its continuity on the local minimum set, the KL property of exponent 1/2\non the local minimum set is shown to be equivalent to the subregularity of its\nsubdifferential relative to this set. Moreover, for this class of nonconvex\nfunctions, under a separation assumption of stationary values, we show that the\nsubregularity of its subdifferential relative to the critical set also implies\nits KL property of exponent $1/2$. These results provide a bridge for the two\nkinds of regularity, and their application is illustrated by examples. \n\n"}
{"id": "1812.01552", "contents": "Title: Exploration versus exploitation in reinforcement learning: a stochastic\n  control approach Abstract: We consider reinforcement learning (RL) in continuous time and study the\nproblem of achieving the best trade-off between exploration of a black box\nenvironment and exploitation of current knowledge. We propose an\nentropy-regularized reward function involving the differential entropy of the\ndistributions of actions, and motivate and devise an exploratory formulation\nfor the feature dynamics that captures repetitive learning under exploration.\nThe resulting optimization problem is a revitalization of the classical relaxed\nstochastic control. We carry out a complete analysis of the problem in the\nlinear--quadratic (LQ) setting and deduce that the optimal feedback control\ndistribution for balancing exploitation and exploration is Gaussian. This in\nturn interprets and justifies the widely adopted Gaussian exploration in RL,\nbeyond its simplicity for sampling. Moreover, the exploitation and exploration\nare captured, respectively and mutual-exclusively, by the mean and variance of\nthe Gaussian distribution. We also find that a more random environment contains\nmore learning opportunities in the sense that less exploration is needed. We\ncharacterize the cost of exploration, which, for the LQ case, is shown to be\nproportional to the entropy regularization weight and inversely proportional to\nthe discount rate. Finally, as the weight of exploration decays to zero, we\nprove the convergence of the solution of the entropy-regularized LQ problem to\nthe one of the classical LQ problem. \n\n"}
{"id": "1812.01574", "contents": "Title: Optimal Sensor and Actuator Selection using Balanced Model Reduction Abstract: Optimal sensor and actuator selection is a central challenge in\nhigh-dimensional estimation and control. Nearly all subsequent control\ndecisions are affected by these sensor/actuator locations, and optimal\nplacement amounts to an intractable brute-force search among the combinatorial\npossibilities. In this work, we exploit balanced model reduction and greedy\noptimization to efficiently determine sensor and actuator selections that\noptimize observability and controllability. In particular, we determine\nlocations that optimize scalar measures of observability and controllability\nvia greedy matrix QR pivoting on the dominant modes of the direct and adjoint\nbalancing transformations. Pivoting runtime scales linearly with the state\ndimension, making this method tractable for high-dimensional systems. The\nresults are demonstrated on the linearized Ginzburg-Landau system, for which\nour algorithm approximates known optimal placements computed using costly\ngradient descent methods. \n\n"}
{"id": "1812.02419", "contents": "Title: On the Properties of Convex Functions over Open Sets Abstract: We consider the class of smooth convex functions defined over an open convex\nset. We show that this class is essentially different than the class of smooth\nconvex functions defined over the entire linear space by exhibiting a function\nthat belongs to the former class but cannot be extended to the entire linear\nspace while keeping its properties. We proceed by deriving new properties of\nthe class under consideration, including an inequality that is strictly\nstronger than the classical Descent Lemma. \n\n"}
{"id": "1812.03051", "contents": "Title: Robust MPC for temperature management on electrical transmission lines Abstract: In the current context of high integration of renewable energies, maximizing\ninfrastructures capabilities for electricity transmission is a general need for\nTransmission System Operators (TSO). The French TSO, RTE, is developing levers\nto control power flows in real-time: renewable production curtailment is\nalready employed and large battery storage systems are planned to be installed\nfor congestion management in early 2020. The combination of these levers with\nthe use of Dynamic Line Rating (DLR) helps exploiting the lines at the closest\nof their limit by managing their temperature in real-time. Unnecessary margins\ncan be reduced, avoiding congestion and excessive generation curtailment. In\nparticular, there is a possible interesting correlation between the transits\nincrease due to high wind farms generation and the cooling effect of wind on\npower lines in the same area. In order to optimize the electrical transmission\nnetwork capacities, the present paper advocates the use of a temperature\nmanagement model, mixing production curtailment and large batteries as control\nvariables. A robust Model Predictive Control framework for local control on\nelectrical lines temperature is presented based on the regulation within tubes\nof trajectories. Simulations on the French electrical network are conducted to\nshow the effectiveness of the optimization-based control design. \n\n"}
{"id": "1812.04300", "contents": "Title: Deep neural networks algorithms for stochastic control problems on\n  finite horizon: convergence analysis Abstract: This paper develops algorithms for high-dimensional stochastic control\nproblems based on deep learning and dynamic programming. Unlike classical\napproximate dynamic programming approaches, we first approximate the optimal\npolicy by means of neural networks in the spirit of deep reinforcement\nlearning, and then the value function by Monte Carlo regression. This is\nachieved in the dynamic programming recursion by performance or hybrid\niteration, and regress now methods from numerical probabilities. We provide a\ntheoretical justification of these algorithms. Consistency and rate of\nconvergence for the control and value function estimates are analyzed and\nexpressed in terms of the universal approximation error of the neural networks,\nand of the statistical error when estimating network function, leaving aside\nthe optimization error. Numerical results on various applications are presented\nin a companion paper (arxiv.org/abs/1812.05916) and illustrate the performance\nof the proposed algorithms. \n\n"}
{"id": "1812.04941", "contents": "Title: A semi-proximal augmented Lagrangian based decomposition method for\n  primal block angular convex composite quadratic conic programming problems Abstract: We propose a semi-proximal augmented Lagrangian based decomposition method\nfor convex composite quadratic conic programming problems with primal block\nangular structures. Using our algorithmic framework, we are able to naturally\nderive several well known augmented Lagrangian based decomposition methods for\nstochastic programming such as the diagonal quadratic approximation method of\nMulvey and Ruszczy\\'{n}ski. Moreover, we are able to derive novel enhancements\nand generalizations of these well known methods. We also propose a\nsemi-proximal symmetric Gauss-Seidel based alternating direction method of\nmultipliers for solving the corresponding dual problem. Numerical results show\nthat our algorithms can perform well even for very large instances of primal\nblock angular convex QP problems. For example, one instance with more than\n$300,000$ linear constraints and $12,500,000$ nonnegative variables is solved\nin less than a minute whereas Gurobi took more than 3 hours, and another\ninstance {\\tt qp-gridgen1} with more than $331,000$ linear constraints and\n$986,000$ nonnegative variables is solved in about 5 minutes whereas Gurobi\ntook more than 35 minutes. \n\n"}
{"id": "1812.05217", "contents": "Title: Tight Analyses for Non-Smooth Stochastic Gradient Descent Abstract: Consider the problem of minimizing functions that are Lipschitz and strongly\nconvex, but not necessarily differentiable. We prove that after $T$ steps of\nstochastic gradient descent, the error of the final iterate is $O(\\log(T)/T)$\nwith high probability. We also construct a function from this class for which\nthe error of the final iterate of deterministic gradient descent is\n$\\Omega(\\log(T)/T)$. This shows that the upper bound is tight and that, in this\nsetting, the last iterate of stochastic gradient descent has the same general\nerror rate (with high probability) as deterministic gradient descent. This\nresolves both open questions posed by Shamir (2012).\n  An intermediate step of our analysis proves that the suffix averaging method\nachieves error $O(1/T)$ with high probability, which is optimal (for any\nfirst-order optimization method). This improves results of Rakhlin (2012) and\nHazan and Kale (2014), both of which achieved error $O(1/T)$, but only in\nexpectation, and achieved a high probability error bound of $O(\\log\n\\log(T)/T)$, which is suboptimal.\n  We prove analogous results for functions that are Lipschitz and convex, but\nnot necessarily strongly convex or differentiable. After $T$ steps of\nstochastic gradient descent, the error of the final iterate is\n$O(\\log(T)/\\sqrt{T})$ with high probability, and there exists a function for\nwhich the error of the final iterate of deterministic gradient descent is\n$\\Omega(\\log(T)/\\sqrt{T})$. \n\n"}
{"id": "1812.05509", "contents": "Title: Weak Feller Property of Non-linear Filters Abstract: Weak Feller property of controlled and control-free Markov chains lead to\nmany desirable properties. In control-free setups this leads to the existence\nof invariant probability measures for compact spaces and applicability of\nnumerical approximation methods. For controlled setups, this leads to existence\nand approximation results for optimal control policies. We know from stochastic\ncontrol theory that partially observed systems can be converted to fully\nobserved systems by replacing the original state space with a probability\nmeasure-valued state space, with the corresponding kernel acting on probability\nmeasures known as the non-linear filter (belief) process. Establishing\nsufficient conditions for the weak Feller property for such processes is a\nsignificant problem, studied under various assumptions and setups in the\nliterature. In this paper, we prove the weak Feller property of the non-linear\nfilter process (i) first under weak continuity of the transition probability of\ncontrolled Markov chain and total variation continuity of its observation\nchannel, and then, (ii) under total variation continuity of the transition\nprobability of controlled Markov chain. The former result (i) has first\nappeared in Feinberg et. al. [Math. Oper. Res. 41(2) (2016) 656-681]. Here, we\npresent a concise and easy to follow alternative proof for this existing\nresult. The latter result (ii) establishes weak Feller property of non-linear\nfilter process under conditions, which have not been previously reported in the\nliterature. \n\n"}
{"id": "1812.05971", "contents": "Title: Single molecule localization by $\\ell_2-\\ell_0$ constrained optimization Abstract: Single Molecule Localization Microscopy (SMLM) enables the acquisition of\nhigh-resolution images by alternating between activation of a sparse subset of\nfluorescent molecules present in a sample and localization. In this work, the\nlocalization problem is formulated as a constrained sparse approximation\nproblem which is resolved by rewriting the $\\ell_0$ pseudo-norm using an\nauxiliary term. In the preliminary experiments with the simulated ISBI datasets\nthe algorithm yields as good results as the state-of-the-art in high-density\nmolecule localization algorithms. \n\n"}
{"id": "1812.06352", "contents": "Title: An efficient adaptive accelerated inexact proximal point method for\n  solving linearly constrained nonconvex composite problems Abstract: This paper proposes an efficient adaptive variant of a quadratic penalty\naccelerated inexact proximal point (QP-AIPP) method proposed earlier by the\nauthors. Both the QP-AIPP method and its variant solve linearly set constrained\nnonconvex composite optimization problems using a quadratic penalty approach\nwhere the generated penalized subproblems are solved by a variant of the\nunderlying AIPP method. The variant, in turn, solves a given penalized\nsubproblem by generating a sequence of proximal subproblems which are then\nsolved by an accelerated composite gradient algorithm. The main difference\nbetween AIPP and its variant is that the proximal subproblems in the former are\nalways convex while the ones in the latter are not necessarily convex due to\nthe fact that their prox parameters are chosen as aggressively as possible so\nas to improve efficiency. The possibly nonconvex proximal subproblems generated\nby the AIPP variant are also tentatively solved by a novel adaptive accelerated\ncomposite gradient algorithm based on the validity of some key convergence\ninequalities. As a result, the variant generates a sequence of proximal\nsubproblems where the stepsizes are adaptively changed according to the\nresponses obtained from the calls to the accelerated composite gradient\nalgorithm. Finally, numerical results are given to demonstrate the efficiency\nof the proposed AIPP and QP-AIPP variants. \n\n"}
{"id": "1812.07186", "contents": "Title: Representation and Stability Analysis of PDE-ODE Coupled Systems Abstract: In this work, we present a scalable Linear Matrix Inequality (LMI) based\nframework to verify the stability of a set of linear Partial Differential\nEquations (PDEs) in one spatial dimension coupled with a set of Ordinary\nDifferential Equations (ODEs) via input-output based interconnection. Our\napproach extends the newly developed state space representation and stability\nanalysis of coupled PDEs that allows parametrizing the Lyapunov function on\n$L_2$ with multipliers and integral operators using polynomial kernels of\nsemi-separable class. In particular, under arbitrary well-posed boundary\nconditions, we define the linear operator inequalities on $\\mathbb{R}^n \\times\nL_2$ and cast the stability condition as a feasibility problem constrained by\nLMIs. In this framework, no discretization or approximation is required to\nverify the stability conditions of PDE-ODE coupled systems. The developed\nalgorithm has been implemented in MATLAB where the stability of example PDE-ODE\ncoupled systems are verified. \n\n"}
{"id": "1812.07534", "contents": "Title: Value of Information in Feedback Control: Quantification Abstract: Although transmission of a data packet containing sensory information in a\nnetworked control system improves the quality of regulation, it has indeed a\nprice from the communication perspective. It is, therefore, rational that such\na data packet be transmitted only if it is valuable in the sense of a\ncost-benefit analysis. Yet, the fact is that little is known so far about this\nvaluation of information and its connection with traditional event-triggered\ncommunication. In the present article, we study this intrinsic property of\nnetworked control systems by formulating a rate-regulation tradeoff between the\npacket rate and the regulation cost with an event trigger and a controller as\ntwo distributed decision makers, and show that the valuation of information is\nconceivable and quantifiable grounded on this tradeoff. In particular, we\ncharacterize an equilibrium in the rate-regulation tradeoff, and quantify the\nvalue of information $\\text{VoI}_k$ there as the variation in a so-called value\nfunction with respect to a piece of sensory information that can be\ncommunicated to the controller at each time $k$. We prove that, for a\nmulti-dimensional Gauss-Markov process, $\\text{VoI}_k$ is a symmetric function\nof the discrepancy between the state estimates at the event trigger and the\ncontroller, and that a data packet containing sensory information at time $k$\nshould be transmitted to the controller only if $\\text{VoI}_k$ is nonnegative.\nMoreover, we discuss that $\\text{VoI}_k$ can be computed with arbitrary\naccuracy, and that it can be approximated by a closed-form quadratic function\nwith a performance guarantee. \n\n"}
{"id": "1812.07846", "contents": "Title: Exponential Convergence and stability of Howards's Policy Improvement\n  Algorithm for Controlled Diffusions Abstract: Optimal control problems are inherently hard to solve as the optimization\nmust be performed simultaneously with updating the underlying system. Starting\nfrom an initial guess, Howard's policy improvement algorithm separates the step\nof updating the trajectory of the dynamical system from the optimization and\niterations of this should converge to the optimal control. In the discrete\nspace-time setting this is often the case and even rates of convergence are\nknown. In the continuous space-time setting of controlled diffusion the\nalgorithm consists of solving a linear PDE followed by maximization problem.\nThis has been shown to converge, in some situations, however no global rate of\nis known. The first main contribution of this paper is to establish global rate\nof convergence for the policy improvement algorithm and a variant, called here\nthe gradient iteration algorithm. The second main contribution is the proof of\nstability of the algorithms under perturbations to both the accuracy of the\nlinear PDE solution and the accuracy of the maximization step. The proof\ntechnique is new in this context as it uses the theory of backward stochastic\ndifferential equations. \n\n"}
{"id": "1812.09398", "contents": "Title: Guaranteed Performance of Nonlinear Attitude Filters on the Special\n  Orthogonal Group SO(3) Abstract: This paper proposes two novel nonlinear attitude filters evolved directly on\nthe Special Orthogonal Group SO(3) able to ensure prescribed measures of\ntransient and steady-state performance. The tracking performance of the\nnormalized Euclidean distance of attitude error is trapped to initially start\nwithin a large set and converge systematically and asymptotically to the origin\nfrom almost any initial condition. The convergence rate is guaranteed to be\nless than the prescribed value and the steady-state error does not exceed a\npredefined small value. The first filter uses a set of vectorial measurements\nwith the need for attitude reconstruction. The second filter instead uses only\na rate gyroscope measurement and two or more vectorial measurements. These\nfilters provide good attitude estimates with superior convergence properties\nand can be applied to measurements obtained from low cost inertial measurement\nunits (IMUs). Simulation results illustrate the robustness and effectiveness of\nthe proposed attitude filters with guaranteed performance considering high\nlevel of uncertainty in angular velocity along with body-frame vector\nmeasurements. Keywords: Attitude, estimate, estimator, observer, filter,\nnonlinear deterministic attitude filter, special orthogonal group, Euler\nangles, angle-axis, Rodrigues vector, mapping, parameterization, prescribed\nperformance, representation, robust, Multiplicative Extended Kalman Filter, KF,\nEKF, MEKF, asymptotic stability, almost global asymptotic, noise, rotational\nmatrix, identity, origin, orientation, body frame, inertial frame, rigid body,\nthree dimensional, 3D, space, micro electromechanical systems, sensor, MEMS,\nroll, pitch, yaw, UAVs, QUAV, SVD, fixed, moving, vehicles, robot, robotic\nsystem, spacecraft, submarine, underwater vehicle, passive complementary\nfilter, explicit complementary filter, autonomous, comparative study, SO(3). \n\n"}
{"id": "1812.09437", "contents": "Title: An efficient threshold dynamics method for topology optimization for\n  fluids Abstract: We propose an efficient threshold dynamics method for topology optimization\nfor fluids modeled with the Stokes equation. The proposed algorithm is based on\nminimization of an objective energy function that consists of the dissipation\npower in the fluid and the perimeter approximated by nonlocal energy, subject\nto a fluid volume constraint and the incompressibility condition. We show that\nthe minimization problem can be solved with an iterative scheme in which the\nStokes equation is approximated by a Brinkman equation. The indicator functions\nof the fluid-solid regions are then updated according to simple convolutions\nfollowed by a thresholding step. We demonstrate mathematically that the\niterative algorithm has the total energy decaying property. The proposed\nalgorithm is simple and easy to implement. A simple adaptive time strategy is\nalso used to accelerate the convergence of the iteration. Extensive numerical\nexperiments in both two and three dimensions show that the proposed iteration\nalgorithm converges in much fewer iterations and is more efficient than many\nexisting methods. In addition, the numerical results show that the algorithm is\nvery robust and insensitive to the initial guess and the parameters in the\nmodel. \n\n"}
{"id": "1812.09701", "contents": "Title: Nonlinear Robust Filtering of Sampled-Data Dynamical Systems Abstract: This work is concerned with robust filtering of nonlinear sampled-data\nsystems with and without exact discrete-time models. A linear matrix inequality\n(LMI) based approach is proposed for the design of robust $H_{\\infty}$\nobservers for a class of Lipschitz nonlinear systems. Two type of systems are\nconsidered, Lipschitz nonlinear discrete-time systems and Lipschitz nonlinear\nsampled-data systems with Euler approximate discrete-time models. Observer\nconvergence when the exact discrete-time model of the system is available is\nshown. Then, practical convergence of the proposed observer is proved using the\nEuler approximate discrete-time model. As an additional feature, maximizing the\nadmissible Lipschitz constant, the solution of the proposed LMI optimization\nproblem guaranties robustness against some nonlinear uncertainty. The robust\nH_infty observer synthesis problem is solved for both cases. The maximum\ndisturbance attenuation level is achieved through LMI optimization. At the end,\na path to extending the results to higher-order approximate discretizations is\nprovided. \n\n"}
{"id": "1812.09884", "contents": "Title: Nonzero-Sum Submodular Monotone-Follower Games: Existence and\n  Approximation of Nash Equilibria Abstract: We consider a class of N-player stochastic games of multi-dimensional\nsingular control, in which each player faces a minimization problem of\nmonotone-follower type with submodular costs. We call these games\n\"monotone-follower games\". In a not necessarily Markovian setting, we establish\nthe existence of Nash equilibria. Moreover, we introduce a sequence of\napproximating games by restricting, for each natural number n, the players'\nadmissible strategies to the set of Lipschitz processes with Lipschitz constant\nbounded by n. We prove that, for each n, there exists a Nash equilibrium of the\napproximating game and that the sequence of Nash equilibria converges, in the\nMeyer-Zheng sense, to a weak (distributional) Nash equilibrium of the original\ngame of singular control. As a byproduct, such a convergence also provides\napproximation results of the equilibrium values across the two classes of\ngames. We finally show how our findings can be employed to prove existence of\nopen-loop Nash equilibria in an N-player stochastic differential game with\nsingular controls, and we propose an algorithm to determine a Nash equilibrium\nfor the monotone-follower game. \n\n"}
{"id": "1812.10004", "contents": "Title: Overparameterized Nonlinear Learning: Gradient Descent Takes the\n  Shortest Path? Abstract: Many modern learning tasks involve fitting nonlinear models to data which are\ntrained in an overparameterized regime where the parameters of the model exceed\nthe size of the training dataset. Due to this overparameterization, the\ntraining loss may have infinitely many global minima and it is critical to\nunderstand the properties of the solutions found by first-order optimization\nschemes such as (stochastic) gradient descent starting from different\ninitializations. In this paper we demonstrate that when the loss has certain\nproperties over a minimally small neighborhood of the initial point, first\norder methods such as (stochastic) gradient descent have a few intriguing\nproperties: (1) the iterates converge at a geometric rate to a global optima\neven when the loss is nonconvex, (2) among all global optima of the loss the\niterates converge to one with a near minimal distance to the initial point, (3)\nthe iterates take a near direct route from the initial point to this global\noptima. As part of our proof technique, we introduce a new potential function\nwhich captures the precise tradeoff between the loss function and the distance\nto the initial point as the iterations progress. For Stochastic Gradient\nDescent (SGD), we develop novel martingale techniques that guarantee SGD never\nleaves a small neighborhood of the initialization, even with rather large\nlearning rates. We demonstrate the utility of our general theory for a variety\nof problem domains spanning low-rank matrix recovery to neural network\ntraining. Underlying our analysis are novel insights that may have implications\nfor training and generalization of more sophisticated learning problems\nincluding those involving deep neural network architectures. \n\n"}
{"id": "1812.10160", "contents": "Title: The convex hull of a quadratic constraint over a polytope Abstract: A quadratically constrained quadratic program (QCQP) is an optimization\nproblem in which the objective function is a quadratic function and the\nfeasible region is defined by quadratic constraints. Solving non-convex QCQP to\nglobal optimality is a well-known NP-hard problem and a traditional approach is\nto use convex relaxations and branch-and-bound algorithms. This paper makes a\ncontribution in this direction by showing that the exact convex hull of a\ngeneral quadratic equation intersected with any bounded polyhedron is\nsecond-order cone representable. We present a simple constructive proof of this\nresult. \n\n"}
{"id": "1812.10469", "contents": "Title: A note on the global stochastic maximum principle for fully coupled\n  forward-backward stochastic systems Abstract: Hu et. al 2018 studied a stochastic optimal control problem for fully coupled\nforward-backward stochastic control systems with a nonempty control domain. By\nassuming a weakly coupled condition, they established an approach to obtain the\nfirst-order, second-order variational equations and the adjoint equations for\nthe states X, Y and Z and deduced the global maximum principle. But it is well\nknown that there are several different conditions such as monotonicity\ncondition, weakly coupled condition and other conditions which can guarantee\nthe existence and uniqueness of the solution to fully coupled FBSDEs. In this\nnote, to overcome the limitations of assuming a specific condition, we propose\ntwo kinds of assumptions which can guarantee that the approach developed in Hu\net. al 2018 is still applicable. Under these two kinds of assumptions, we\nobtain the global stochastic maximum principle. \n\n"}
{"id": "1812.11583", "contents": "Title: A Gramian Description of the Degree 4 Generalized Elliptope Abstract: One of the most widely studied convex relaxations in combinatorial\noptimization is the relaxation of the cut polytope $\\mathscr C^N$ to the\nelliptope $\\mathscr E^N$, which corresponds to the degree 2 sum-of-squares\n(SOS) relaxation of optimizing a quadratic form over the hypercube $\\{\\pm\n1\\}^N$. We study the extension of this classical idea to degree 4 SOS, which\ngives an intermediate relaxation we call the degree 4 generalized elliptope\n$\\mathscr E_4^N$. Our main result is a necessary and sufficient condition for\nthe Gram matrix of a collection of vectors to belong to $\\mathscr E_4^N$.\nConsequences include a tight rank inequality between degree 2 and degree 4\npseudomoment matrices, and a guarantee that the only extreme points of\n$\\mathscr E^N$ also in $\\mathscr E_4^N$ are the cut matrices; that is,\n$\\mathscr E^N$ and $\\mathscr E_4^N$ share no \"spurious\" extreme point.\n  For Gram matrices of equiangular tight frames, we give a simple criterion for\nmembership in $\\mathscr{E}_4^N$. This yields new inequalities satisfied in\n$\\mathscr{E}_4^N$ but not $\\mathscr{E}^N$ whose structure is related to the\nSchl\\\"{a}fli graph and which cannot be obtained as linear combinations of\ntriangle inequalities. We also give a new proof of the restriction to degree 4\nof a result of Laurent showing that $\\mathscr{E}_4^N$ does not satisfy certain\ncut polytope inequalities capturing parity constraints. Though limited to this\nspecial case, our proof of the positive semidefiniteness of Laurent's\npseudomoment matrix is short and elementary.\n  Our techniques also suggest that membership in $\\mathscr{E}_4^N$ is closely\nrelated to the partial transpose operation on block matrices, which has\npreviously played an important role in the study of quantum entanglement. To\nillustrate, we present a correspondence between certain entangled bipartite\nquantum states and the matrices of $\\mathscr{E}_4^N\\setminus\\mathscr{C}^N$. \n\n"}
{"id": "1812.11708", "contents": "Title: The Facets of the Subtours Elimination Polytope Abstract: Let $G=(V, E)$ be an undirected graph. The subtours elimination polytope\n$P(G)$ is the set of $x\\in \\mathbb{R}^E$ such that: $0\\leq x(e)\\leq 1$ for any\nedge $e\\in E$, $x(\\delta (v))=2$ for any vertex $v\\in V$, and $x(\\delta\n(U))\\geq 2$ for any nonempty and proper subset $U$ of $V$. $P(G)$ is a\nrelaxation of the Traveling Salesman Polytope, i.e., the convex hull of the\nHamiton circuits of $G$. Maurras \\cite{Maurras 1975} and Gr\\\"{o}tschel and\nPadberg \\cite{Grotschel and Padberg 1979b} characterize the facets of $P(G)$\nwhen $G$ is a complete graph. In this paper we generalize their result by\ngiving a minimal description of $P(G)$ in the general case and by presenting a\nshort proof of it. \n\n"}
{"id": "1901.00214", "contents": "Title: Clustering with Distributed Data Abstract: We consider $K$-means clustering in networked environments (e.g., internet of\nthings (IoT) and sensor networks) where data is inherently distributed across\nnodes and processing power at each node may be limited. We consider a\nclustering algorithm referred to as networked $K$-means, or $NK$-means, which\nrelies only on local neighborhood information exchange. Information exchange is\nlimited to low-dimensional statistics and not raw data at the agents. The\nproposed approach develops a parametric family of multi-agent clustering\nobjectives (parameterized by $\\rho$) and associated distributed $NK$-means\nalgorithms (also parameterized by $\\rho$). The $NK$-means algorithm with\nparameter $\\rho$ converges to a set of fixed points relative to the associated\nmulti-agent objective (designated as `generalized minima'). By appropriate\nchoice of $\\rho$, the set of generalized minima may be brought arbitrarily\nclose to the set of Lloyd's minima. Thus, the $NK$-means algorithm may be used\nto compute Lloyd's minima of the collective dataset up to arbitrary accuracy. \n\n"}
{"id": "1901.00424", "contents": "Title: Consumption, Investment, and Healthcare with Aging Abstract: This paper solves the problem of optimal dynamic consumption, investment, and\nhealthcare spending with isoelastic utility, when natural mortality grows\nexponentially to reflect Gompertz' law and investment opportunities are\nconstant. Healthcare slows the natural growth of mortality, indirectly\nincreasing utility from consumption through longer lifetimes. Optimal\nconsumption and healthcare imply an endogenous mortality law that is\nasymptotically exponential in the old-age limit, with lower growth rate than\nnatural mortality. Healthcare spending steadily increases with age, both in\nabsolute terms and relative to total spending. The optimal stochastic control\nproblem reduces to a nonlinear ordinary differential equation with a unique\nsolution, which has an explicit expression in the old-age limit. The main\nresults are obtained through a novel version of Perron's method. \n\n"}
{"id": "1901.00696", "contents": "Title: The Extended Kalman Filter is a Natural Gradient Descent in Trajectory\n  Space Abstract: The extended Kalman filter is perhaps the most standard tool to estimate in\nreal time the state of a dynamical system from noisy measurements of some\nfunction of the system, with extensive practical applications (such as position\ntracking via GPS). While the plain Kalman filter for linear systems is\nwell-understood, the extended Kalman filter relies on linearizations which have\nbeen debated.\n  We recover the exact extended Kalman filter equations from first principles\nin statistical learning: the extended Kalman filter is equal to Amari's online\nnatural gradient, applied in the space of trajectories of the system. Namely,\neach possible trajectory of the dynamical system defines a probability law over\npossible observations. In principle this makes it possible to treat the\nunderlying trajectory as the parameter of a statistical model of the\nobservations. Then the parameter can be learned by gradient ascent on the\nlog-likelihood of observations, as they become available. Using Amari's natural\ngradient from information geometry (a gradient descent preconditioned with the\nFisher matrix, which provides parameterization-invariance) exactly recovers the\nextended Kalman filter.\n  This applies only to a particular choice of process noise in the Kalman\nfilter, namely, taking noise proportional to the posterior covariance - a\ncanonical choice in the absence of specific model information. \n\n"}
{"id": "1901.02505", "contents": "Title: An optional decomposition of $\\mathscr{Y}^{g,\\xi}-submartingales$ and\n  applications to the hedging of American options in incomplete markets Abstract: In the recent paper \\cite{DESZ}, the notion of\n$\\mathscr{Y}^{g,\\xi}$-submartingale processes has been introduced. Within a\njump-diffusion model, we prove here that a process $X$ which satisfies the\nsimultaneous $\\mathscr{Y}^{\\mathbb{Q},g,\\xi}$ -submartingale property under a\nsuitable family of equivalent probability measures $\\mathbb{Q}$, admits a\n\\textit{nonlinear optional decomposition}. This is an analogous result to the\nwell known optional decomposition of simultaneous (classical and\n$\\mathscr{E}^g$-)supermartingales. We then apply this decomposition to the\nsuper-hedging problem of an American option in a jump-diffusion model, from the\nbuyer's point of view. We obtain an \\textit{infinitesimal characterization} of\nthe buyer's superhedging price, this result being completely new in the\nliterature. Indeed, it is well known that the seller's superheding price of an\nAmerican option admits an infinitesimal representation in terms of the\n\\textit{minimal supersolution of a constrained reflected BSDE}. To the best of\nour knowledge, no analogous result has been established for the buyer of the\nAmerican option in an incomplete market. Our results fill this gap, and show\nthat the buyer's super-hedging price admits an infinitesimal charcaterization\nin terms of the \\textit{maximal subsolution of a constrained reflected BSDE}. \n\n"}
{"id": "1901.03747", "contents": "Title: Small gain theorems for general networks of heterogeneous\n  infinite-dimensional systems Abstract: We prove a small-gain theorem for interconnections of $n$ nonlinear\nheterogeneous input-to-state stable (ISS) control systems of a general nature,\ncovering partial, delay and ordinary differential equations. Furthermore, for\nthe same class of control systems, we derive small-gain theorems for asymptotic\ngain, uniform global stability and weak input-to-state stability properties. We\nshow that our technique is applicable for different formulations of ISS\nproperty (summation, maximum, semimaximum) and discuss tightness of achieved\nsmall-gain theorems. Finally, we introduce variations of uniform asymptotic\ngain and uniform limit properties, which are particularly useful for small-gain\narguments and characterize ISS in terms of these notions. \n\n"}
{"id": "1901.04120", "contents": "Title: Acquisition of Project-Specific Assets with Bayesian Updating Abstract: We study the impact of learning on the optimal policy and the\ntime-to-decision in an infinite-horizon Bayesian sequential decision model with\ntwo irreversible alternatives, exit and expansion. In our model, a firm\nundertakes a small-scale pilot project so as to learn, via Bayesian updating,\nabout the project\\textquoteright s profitability, which is known to be in one\nof two possible states. The firm continuously observes the\nproject\\textquoteright s cumulative profit, but the true state of the\nprofitability is not immediately revealed because of the inherent noise in the\nprofit stream. The firm bases its exit or expansion decision on the posterior\nprobability distribution of the profitability. The optimal policy is\ncharacterized by a pair of thresholds for the posterior probability. We find\nthat the time-to-decision does not necessarily have a monotonic relation with\nthe arrival rate of new information. \n\n"}
{"id": "1901.04921", "contents": "Title: Semidefinite programming formulations for the completely bounded norm of\n  a tensor Abstract: We show that a certain tensor norm, the completely bounded norm, can be\nexpressed by a semidefinite program. This tensor norm recently attracted\nattention in the field of quantum computing, where it was used by Arunachalam,\nBri\\\"{e}t and Palazuelos for characterizing the quantum query complexity of\nBoolean functions. Combined with their results, we obtain a new\ncharacterization of the quantum query complexity through semidefinite\nprogramming. Using the duality theory of semidefinite programming we obtain a\nnew type of certificates for large query complexity. We show that our class of\ncertificates encompasses the linear programming certificates corresponding to\nthe approximate degree of a Boolean function. \n\n"}
{"id": "1901.05522", "contents": "Title: Stabilising the Metzler matrices with applications to dynamical systems Abstract: Metzler matrices play a crucial role in positive linear dynamical systems.\nFinding the closest stable Metzler matrix to an unstable one (and vice versa)\nis an important issue with many applications. The stability considered here is\nin the sense of Hurwitz, and the distance between matrices is measured in\n$l_\\infty,\\ l_1$, and in the max norms. We provide either explicit solutions or\nefficient algorithms for obtaining the closest (un)stable matrix. The procedure\nfor finding the closest stable Metzler matrix is based on the recently\nintroduced selective greedy spectral method for optimizing the Perron\neigenvalue. Originally intended for non-negative matrices, here is generalized\nto Metzler matrices. The efficiency of the new algorithms is demonstrated in\nexamples and by numerical experiments in the dimension of up to 2000.\nApplications to dynamical systems, linear switching systems, and sign-matrices\nare considered. \n\n"}
{"id": "1901.06005", "contents": "Title: Minimal time for the exact controllability of one-dimensional\n  first-order linear hyperbolic systems by one-sided boundary controls Abstract: In this article we study the minimal time for the exact controllability of\none-dimensional first-order linear hyperbolic systems when all the controls are\nacting on the same side of the boundary. We establish an explicit and\neasy-to-compute formula for this time with respect to all the coupling\nparameters of the system. The proof relies on the introduction of a canonical\n$UL$-decomposition and the compactness-uniqueness method. \n\n"}
{"id": "1901.06287", "contents": "Title: Distributed control and game design: From strategic agents to\n  programmable machines Abstract: Large scale systems are forecasted to greatly impact our future lives thanks\nto their wide ranging applications including cooperative robotics, mobility on\ndemand, resource allocation, supply chain management. While technological\ndevelopments have paved the way for the realization of such futuristic systems,\nwe have a limited grasp on how to coordinate the individual components to\nachieve the desired global objective. This thesis deals with the analysis and\ncoordination of large scale systems without the need of a centralized\nauthority.\n  In the first part of this thesis, we consider non-cooperative decision making\nproblems where each agent's objective is a function of the aggregate behavior\nof the population. First, we compare the performance of an equilibrium\nallocation with that of an optimal allocation and propose conditions under\nwhich all equilibrium allocations are efficient. Towards this goal, we prove a\nnovel result bounding the distance between the strategies at a Nash and Wardrop\nequilibrium that might be of independent interest. Second, we show how to\nderive scalable algorithms that guide agents towards an equilibrium allocation.\n  In the second part of this thesis, we consider large-scale cooperative\nproblems, where a number of agents need to be allocated to a set of resources\nwith the goal of jointly maximizing a given submodular or supermodular set\nfunction. Since this class of problems is computationally intractable, we aim\nat deriving tractable algorithms for attaining approximate solutions. We\napproach the problem from a game-theoretic perspective and ask the following:\nhow should we design agents' utilities so that any equilibrium configuration is\nalmost optimal? To answer this question we introduce a novel framework that\nallows to characterize and optimize the system performance as a function of the\nchosen utilities by means of a tractable linear program. \n\n"}
{"id": "1901.06453", "contents": "Title: Holographic Phase Retrieval and Reference Design Abstract: A general mathematical framework and recovery algorithm is presented for the\nholographic phase retrieval problem. In this problem, which arises in\nholographic coherent diffraction imaging, a \"reference\" portion of the signal\nto be recovered via phase retrieval is a priori known from experimental design.\nA generic formula is also derived for the expected recovery error when the\nmeasurement data is corrupted by Poisson shot noise. This facilitates an\noptimization perspective towards reference design and analysis. We employ this\noptimization perspective towards quantifying the performance of various\nreference choices. \n\n"}
{"id": "1901.07935", "contents": "Title: Predicting Tactical Solutions to Operational Planning Problems under\n  Imperfect Information Abstract: This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict tactical solutions to a given operational problem. In this\ncontext, the tactical solution is less detailed than the operational one but it\nhas to be computed in very short time and under imperfect information. The\nproblem is of importance in various applications where tactical and operational\nplanning problems are interrelated and information about the operational\nproblem is revealed over time. This is for instance the case in certain\ncapacity planning and demand management systems.\n  We formulate the problem as a two-stage optimal prediction stochastic program\nwhose solution we predict with a supervised machine learning algorithm. The\ntraining data set consists of a large number of deterministic (second stage)\nproblems generated by controlled probabilistic sampling. The labels are\ncomputed based on solutions to the deterministic problems (solved independently\nand offline) employing appropriate aggregation and subselection methods to\naddress uncertainty. Results on our motivating application in load planning for\nrail transportation show that deep learning algorithms produce highly accurate\npredictions in very short computing time (milliseconds or less). The prediction\naccuracy is comparable to solutions computed by sample average approximation of\nthe stochastic program. \n\n"}
{"id": "1901.08227", "contents": "Title: Trajectory Normalized Gradients for Distributed Optimization Abstract: Recently, researchers proposed various low-precision gradient compression,\nfor efficient communication in large-scale distributed optimization. Based on\nthese work, we try to reduce the communication complexity from a new direction.\nWe pursue an ideal bijective mapping between two spaces of gradient\ndistribution, so that the mapped gradient carries greater information entropy\nafter the compression. In our setting, all servers should share a reference\ngradient in advance, and they communicate via the normalized gradients, which\nare the subtraction or quotient, between current gradients and the reference.\nTo obtain a reference vector that yields a stronger signal-to-noise ratio,\ndynamically in each iteration, we extract and fuse information from the past\ntrajectory in hindsight, and search for an optimal reference for compression.\nWe name this to be the trajectory-based normalized gradients (TNG). It bridges\nthe research from different societies, like coding, optimization, systems, and\nlearning. It is easy to implement and can universally combine with existing\nalgorithms. Our experiments on benchmarking hard non-convex functions, convex\nproblems like logistic regression demonstrate that TNG is more\ncompression-efficient for communication of distributed optimization of general\nfunctions. \n\n"}
{"id": "1901.08235", "contents": "Title: Multi-Frequency Phase Synchronization Abstract: We propose a novel formulation for phase synchronization -- the statistical\nproblem of jointly estimating alignment angles from noisy pairwise comparisons\n-- as a nonconvex optimization problem that enforces consistency among the\npairwise comparisons in multiple frequency channels. Inspired by harmonic\nretrieval in signal processing, we develop a simple yet efficient two-stage\nalgorithm that leverages the multi-frequency information. We demonstrate in\ntheory and practice that the proposed algorithm significantly outperforms\nstate-of-the-art phase synchronization algorithms, at a mild computational\ncosts incurred by using the extra frequency channels. We also extend our\nalgorithmic framework to general synchronization problems over compact Lie\ngroups. \n\n"}
{"id": "1901.09149", "contents": "Title: Escaping Saddle Points with Adaptive Gradient Methods Abstract: Adaptive methods such as Adam and RMSProp are widely used in deep learning\nbut are not well understood. In this paper, we seek a crisp, clean and precise\ncharacterization of their behavior in nonconvex settings. To this end, we first\nprovide a novel view of adaptive methods as preconditioned SGD, where the\npreconditioner is estimated in an online manner. By studying the preconditioner\non its own, we elucidate its purpose: it rescales the stochastic gradient noise\nto be isotropic near stationary points, which helps escape saddle points.\nFurthermore, we show that adaptive methods can efficiently estimate the\naforementioned preconditioner. By gluing together these two components, we\nprovide the first (to our knowledge) second-order convergence result for any\nadaptive method. The key insight from our analysis is that, compared to SGD,\nadaptive methods escape saddle points faster, and can converge faster overall\nto second-order stationary points. \n\n"}
{"id": "1901.09437", "contents": "Title: 99% of Distributed Optimization is a Waste of Time: The Issue and How to\n  Fix it Abstract: Many popular distributed optimization methods for training machine learning\nmodels fit the following template: a local gradient estimate is computed\nindependently by each worker, then communicated to a master, which subsequently\nperforms averaging. The average is broadcast back to the workers, which use it\nto perform a gradient-type step to update the local version of the model. It is\nalso well known that many such methods, including SGD, SAGA, and accelerated\nSGD for over-parameterized models, do not scale well with the number of\nparallel workers. In this paper we observe that the above template is\nfundamentally inefficient in that too much data is unnecessarily communicated\nby the workers, which slows down the overall system. We propose a fix based on\na new update-sparsification method we develop in this work, which we suggest be\nused on top of existing methods. Namely, we develop a new variant of parallel\nblock coordinate descent based on independent sparsification of the local\ngradient estimates before communication. We demonstrate that with only $m/n$\nblocks sent by each of $n$ workers, where $m$ is the total number of parameter\nblocks, the theoretical iteration complexity of the underlying distributed\nmethods is essentially unaffected. As an illustration, this means that when\n$n=100$ parallel workers are used, the communication of $99\\%$ blocks is\nredundant, and hence a waste of time. Our theoretical claims are supported\nthrough extensive numerical experiments which demonstrate an almost perfect\nmatch with our theory on a number of synthetic and real datasets. \n\n"}
{"id": "1901.09671", "contents": "Title: ErasureHead: Distributed Gradient Descent without Delays Using\n  Approximate Gradient Coding Abstract: We present ErasureHead, a new approach for distributed gradient descent (GD)\nthat mitigates system delays by employing approximate gradient coding. Gradient\ncoded distributed GD uses redundancy to exactly recover the gradient at each\niteration from a subset of compute nodes. ErasureHead instead uses approximate\ngradient codes to recover an inexact gradient at each iteration, but with\nhigher delay tolerance. Unlike prior work on gradient coding, we provide a\nperformance analysis that combines both delay and convergence guarantees. We\nestablish that down to a small noise floor, ErasureHead converges as quickly as\ndistributed GD and has faster overall runtime under a probabilistic delay\nmodel. We conduct extensive experiments on real world datasets and distributed\nclusters and demonstrate that our method can lead to significant speedups over\nboth standard and gradient coded GD. \n\n"}
{"id": "1901.09731", "contents": "Title: Convergence of a Relaxed Variable Splitting Coarse Gradient Descent\n  Method for Learning Sparse Weight Binarized Activation Neural Networks Abstract: Sparsification of neural networks is one of the effective complexity\nreduction methods to improve efficiency and generalizability. Binarized\nactivation offers an additional computational saving for inference. Due to\nvanishing gradient issue in training networks with binarized activation, coarse\ngradient (a.k.a. straight through estimator) is adopted in practice. In this\npaper, we study the problem of coarse gradient descent (CGD) learning of a one\nhidden layer convolutional neural network (CNN) with binarized activation\nfunction and sparse weights. It is known that when the input data is Gaussian\ndistributed, no-overlap one hidden layer CNN with ReLU activation and general\nweight can be learned by GD in polynomial time at high probability in\nregression problems with ground truth. We propose a relaxed variable splitting\nmethod integrating thresholding and coarse gradient descent. The sparsity in\nnetwork weight is realized through thresholding during the CGD training\nprocess. We prove that under threshholding of $\\ell_1, \\ell_0,$ and\ntransformed-$\\ell_1$ penalties, no-overlap binary activation CNN can be learned\nwith high probability, and the iterative weights converge to a global limit\nwhich is a transformation of the true weight under a novel sparsifying\noperation. We found explicit error estimates of sparse weights from the true\nweights. \n\n"}
{"id": "1901.09847", "contents": "Title: Error Feedback Fixes SignSGD and other Gradient Compression Schemes Abstract: Sign-based algorithms (e.g. signSGD) have been proposed as a biased gradient\ncompression technique to alleviate the communication bottleneck in training\nlarge neural networks across multiple workers. We show simple convex\ncounter-examples where signSGD does not converge to the optimum. Further, even\nwhen it does converge, signSGD may generalize poorly when compared with SGD.\nThese issues arise because of the biased nature of the sign compression\noperator. We then show that using error-feedback, i.e. incorporating the error\nmade by the compression operator into the next step, overcomes these issues. We\nprove that our algorithm EF-SGD with arbitrary compression operator achieves\nthe same rate of convergence as SGD without any additional assumptions. Thus\nEF-SGD achieves gradient compression for free. Our experiments thoroughly\nsubstantiate the theory and show that error-feedback improves both convergence\nand generalization. Code can be found at\n\\url{https://github.com/epfml/error-feedback-SGD}. \n\n"}
{"id": "1901.10382", "contents": "Title: Tikhonov Regularization Within Ensemble Kalman Inversion Abstract: Ensemble Kalman inversion is a parallelizable methodology for solving inverse\nor parameter estimation problems. Although it is based on ideas from Kalman\nfiltering, it may be viewed as a derivative-free optimization method. In its\nmost basic form it regularizes ill-posed inverse problems through the subspace\nproperty: the solution found is in the linear span of the initial ensemble\nemployed. In this work we demonstrate how further regularization can be\nimposed, incorporating prior information about the underlying unknown. In\nparticular we study how to impose Tikhonov-like Sobolev penalties. As well as\nintroducing this modified ensemble Kalman inversion methodology, we also study\nits continuous-time limit, proving ensemble collapse; in the language of\nmulti-agent optimization this may be viewed as reaching consensus. We also\nconduct a suite of numerical experiments to highlight the benefits of Tikhonov\nregularization in the ensemble inversion context. \n\n"}
{"id": "1901.11150", "contents": "Title: Memory-Efficient Adaptive Optimization Abstract: Adaptive gradient-based optimizers such as Adagrad and Adam are crucial for\nachieving state-of-the-art performance in machine translation and language\nmodeling. However, these methods maintain second-order statistics for each\nparameter, thus introducing significant memory overheads that restrict the size\nof the model being used as well as the number of examples in a mini-batch. We\ndescribe an effective and flexible adaptive optimization method with greatly\nreduced memory overhead. Our method retains the benefits of per-parameter\nadaptivity while allowing significantly larger models and batch sizes. We give\nconvergence guarantees for our method, and demonstrate its effectiveness in\ntraining very large translation and language models with up to 2-fold speedups\ncompared to the state-of-the-art. \n\n"}
{"id": "cond-mat/9901353", "contents": "Title: Extremal Optimization of Graph Partitioning at the Percolation Threshold Abstract: The benefits of a recently proposed method to approximate hard optimization\nproblems are demonstrated on the graph partitioning problem. The performance of\nthis new method, called Extremal Optimization, is compared to Simulated\nAnnealing in extensive numerical simulations. While generally a complex\n(NP-hard) problem, the optimization of the graph partitions is particularly\ndifficult for sparse graphs with average connectivities near the percolation\nthreshold. At this threshold, the relative error of Simulated Annealing for\nlarge graphs is found to diverge relative to Extremal Optimization at equalized\nruntime. On the other hand, Extremal Optimization, based on the extremal\ndynamics of self-organized critical systems, reproduces known results about\noptimal partitions at this critical point quite well. \n\n"}
{"id": "hep-th/9811118", "contents": "Title: Tree Structures: A Variational Approach to Shannon--Wiener Information Abstract: Entanglement measures based on a logarithmic functional form naturally emerge\nin any attempt to quantify the degree of entanglement in the state of a\nmultipartite quantum system. These measures can be regarded as generalizations\nof the classical Shannon-Wiener information of a probability distribution into\nthe quantum regime. In the present work we introduce a previously unknown\napproach to the Shannon-Wiener information which provides an intuitive\ninterpretation for its functional form as well as putting all entanglement\nmeasures with a similar structure into a new context: By formalizing the\nprocess of information gaining in a set-theoretical language we arrive at a\nmathematical structure which we call ''tree structures'' over a given set. On\neach tree structure, a tree function can be defined, reflecting the degree of\nsplitting and branching in the given tree. We show in detail that the\nminimization of the tree function on, possibly constrained, sets of tree\nstructures renders the functional form of the Shannon-Wiener information. This\nfinding demonstrates that entropy-like information measures may themselves be\nunderstood as the result of a minimization process on a more general underlying\nmathematical structure, thus providing an entirely new interpretational\nframework to entropy-like measures of information and entanglement. We suggest\nthree natural axioms for defining tree structures, which turn out to be related\nto the axioms describing neighbourhood topologies on a topological space. The\nsame minimization that renders the functional form of the Shannon-Wiener\ninformation from the tree function then assigns a preferred topology to the\nunderlying set, hinting at a deep relation between entropy-like measures and\nneighbourhood topologies. \n\n"}
{"id": "math/0002113", "contents": "Title: Structure and Stability of Certain Chemical Networks and Applications to\n  the Kinetic Proofreading Model of T-Cell Receptor Signal Transduction Abstract: This paper deals with the theory of structure, stability, robustness, and\nstabilization for an appealing class of nonlinear systems which arises in the\nanalysis of chemical networks.\n  The results given here extend, but are also heavily based upon, certain\nprevious work by Feinberg, Horn, and Jackson, of which a self-contained and\nstreamlined exposition is included.\n  The theoretical conclusions are illustrated through an application to the\nkinetic proofreading model proposed by McKeithan for T-cell receptor signal\ntransduction. (Update includes, among other topics, remarks on extensions to\ncertain systems with Michaelis-Menten kinetics.) \n\n"}
{"id": "math/0101080", "contents": "Title: Idempotent interval analysis and optimization problems Abstract: Many problems in optimization theory are strongly nonlinear in the\ntraditional sense but possess a hidden linear structure over suitable\nidempotent semirings. After an overview of `Idempotent Mathematics' with an\nemphasis on matrix theory, interval analysis over idempotent semirings is\ndeveloped. The theory is applied to construction of exact interval solutions to\nthe interval discrete stationary Bellman equation. Solution of an interval\nsystem is typically NP-hard in the traditional interval linear algebra; in the\nidempotent case it is polynomial. A generalization to the case of positive\nsemirings is outlined. \n\n"}
{"id": "math/0106031", "contents": "Title: Gomory Integer Programs Abstract: The set of all group relaxations of an integer program contains certain\nspecial members called Gomory relaxations. A family of integer programs with a\nfixed coefficient matrix and cost vector but varying right hand sides is a\nGomory family if every program in the family can be solved by one of its Gomory\nrelaxations. In this paper, we characterize Gomory families. Every TDI system\ngives a Gomory family, and we construct Gomory families from matrices whose\ncolumns form a Hilbert basis for the cone they generate. The existence of\nGomory families is related to the Hilbert covering problems that arose from the\nconjectures of Sebo. Connections to commutative algebra are outlined at the\nend. \n\n"}
{"id": "math/0108070", "contents": "Title: On the lambda-equations for matching control laws Abstract: We discuss matching control laws for underactuated systems. We previously\nshowed that this class of matching control laws is completely charactarized by\na linear system of first order partial differential equations for one set of\nvariables followed by a linear system of first order PDEs for a second set of\nvariables. Here we derive a new first order system of partial differential\nequations that encodes all compatibility conditions for the lambda-equations.\nWe give four examples illustrating different features of matching control laws.\nThe last example is a system with two unactuated degrees of freedom that admits\nonly basic solutions to the matching equations. There are systems with many\nmatching control laws where only basic solutions are potentially useful. We\nintroduce a rank condition indicating when this is likely to be the case. \n\n"}
{"id": "math/0110034", "contents": "Title: An Algebraic Perspective of Group Relaxations Abstract: This is an expository article on recent developments in the theory of group\nrelaxations in integer programming from an algebraic perspective. \n\n"}
{"id": "math/0301268", "contents": "Title: Improving Search Algorithms by Using Intelligent Coordinates Abstract: We consider the problem of designing a set of computational agents so that as\nthey all pursue their self-interests a global function G of the collective\nsystem is optimized. Three factors govern the quality of such design. The first\nrelates to conventional exploration-exploitation search algorithms for finding\nthe maxima of such a global function, e.g., simulated annealing. Game-theoretic\nalgorithms instead are related to the second of those factors, and the third is\nrelated to techniques from the field of machine learning. Here we demonstrate\nhow to exploit all three factors by modifying the search algorithm's\nexploration stage so that rather than by random sampling, each coordinate of\nthe underlying search space is controlled by an associated\nmachine-learning-based ``player'' engaged in a non-cooperative game.\nExperiments demonstrate that this modification improves SA by up to an order of\nmagnitude for bin-packing and for a model of an economic process run over an\nunderlying network. These experiments also reveal novel small worlds phenomena. \n\n"}
{"id": "math/0304255", "contents": "Title: Matrosov's theorem using a family of auxiliary functions: an analysis\n  tool to aid time-varying nonlinear control design Abstract: We present a new result on uniform attractivity of the origin for nonlinear\ntime-varying systems. Our theorem generalizes Matrosov's theorem which extends,\nin a certain manner, Krasovskii-LaSalle invariance principle to the case of\ngeneral nonlinear time-varying systems. We show the utility of our theorem by\naddressing a control problem of port interconnected driftless systems. The\nlatter includes as special case, the control of chained-form nonholonomic\nsystems which has been extensively studied in the literature. \n\n"}
{"id": "math/0402346", "contents": "Title: Applications of Lefschetz numbers in control theory Abstract: We develop some applications of techniques of the Lefschetz coincidence\ntheory in control theory. The topics are existence of equilibria and their\nrobustness, controllability and its robustness. \n\n"}
{"id": "math/0404474", "contents": "Title: Combinatorial and algorithmic aspects of hyperbolic polynomials Abstract: Let $p(x_1,...,x_n) =\\sum_{(r_1,...,r_n) \\in I_{n,n}} a_{(r_1,...,r_n)}\n\\prod_{1 \\leq i \\leq n} x_{i}^{r_{i}}$ be homogeneous polynomial of degree $n$\nin $n$ real variables with integer nonnegative coefficients. The support of\nsuch polynomial $p(x_1,...,x_n)$ is defined as $supp(p) = \\{(r_1,...,r_n) \\in\nI_{n,n} : a_{(r_1,...,r_n)} \\neq 0 \\}$ . The convex hull $CO(supp(p))$ of\n$supp(p)$ is called the Newton polytope of $p$ . We study the following\ndecision problems, which are far-reaching generalizations of the classical\nperfect matching problem : {itemize} {\\bf Problem 1 .} Consider a homogeneous\npolynomial $p(x_1,...,x_n)$ of degree $n$ in $n$ real variables with\nnonnegative integer coefficients given as a black box (oracle) . {\\it Is it\ntrue that $(1,1,..,1) \\in supp(p)$ ?} {\\bf Problem 2 .} Consider a homogeneous\npolynomial $p(x_1,...,x_n)$ of degree $n$ in $n$ real variables with\nnonnegative integer coefficients given as a black box (oracle) . {\\it Is it\ntrue that $(1,1,..,1) \\in CO(supp(p))$ ?} {itemize} We prove that for\nhyperbolic polynomials these two problems are equivalent and can be solved by\ndeterministic polynomial-time oracle algorithms . This result is based on a\n\"hyperbolic\" generalization of Rado theorem . \n\n"}
{"id": "math/0406284", "contents": "Title: Barvinok's Rational Functions: Algorithms and Applications to\n  Optimization, Statistics, and Algebra Abstract: The main theme of this dissertation is the study of the lattice points in a\nrational convex polyhedron and their encoding in terms of Barvinok's short\nrational functions. The first part of this thesis looks into theoretical\napplications of these rational functions to Optimization, Statistics, and\nComputational Algebra. The main theorem on Chapter 2 concerns the computation\nof the \\emph{toric ideal} $I_A$ of an integral $n \\times d$ matrix $A$. We\nencode the binomials belonging to the toric ideal $I_A$ associated with $A$\nusing Barvinok's rational functions. If we fix $d$ and $n$, this representation\nallows us to compute a universal Gr\\\"obner basis and the reduced Gr\\\"obner\nbasis of the ideal $I_A$, with respect to any term order, in polynomial time.\nWe derive a polynomial time algorithm for normal form computations which\nreplaces in this new encoding the usual reductions of the division algorithm.\nChapter 3 presents three ways to use Barvinok's rational functions to solve\nInteger Programs.\n  The second part of the thesis is experimental and consists mainly of the\nsoftware package {\\tt LattE}, the first implementation of Barvinok's algorithm.\nWe report on experiments with families of well-known rational polytopes:\nmultiway contingency tables, knapsack type problems, and rational polygons. We\nalso developed a new algorithm, {\\em the homogenized Barvinok's algorithm} to\ncompute the generating function for a rational polytope. We showed that it runs\nin polynomial time in fixed dimension. With the homogenized Barvinok's\nalgorithm, we obtained new combinatorial formulas: the generating function for\nthe number of $5\\times 5$ magic squares and the generating function for the\nnumber of $3\\times 3 \\times 3 \\times 3$ magic cubes as rational functions. \n\n"}
{"id": "math/0407406", "contents": "Title: Newton's aerodynamic problem in media of chaotically moving particles Abstract: We study the problem of minimal resistance for a body moving with constant\nvelocity in a rarefied medium of chaotically moving point particles, in\nEuclidean space R^d. The particles distribution over velocities is radially\nsymmetric. Under some additional assumptions on the distribution function, the\ncomplete classification of bodies of least resistance is made. In the case of\nthree and more dimensions there are two kinds of solutions: a body similar to\nthe solution of classical Newton's problem and a union of two such bodies\n``glued together'' by rear parts of their surfaces. In the two-dimensional case\nthere are solutions of five different types: (a) a trapezium; (b) an isosceles\ntriangle; (c) the union of a triangle and a trapezium with common base; (d) the\nunion of two isosceles triangles with common base; (e) the union of two\ntriangles and a trapezium. The cases (a)--(d) are realized for any distribution\nof particles over velocities, and the case (e) is only realized for some\ndistributions. Two limit cases are considered, where the average velocity of\nparticles is big and where it is small as compared to the body's velocity.\nFinally, using the obtained analytical results, we study numerically a\nparticular case: the problem of body's motion in a rarefied homogeneous\nmonatomic ideal gas of positive temperature in R^2 and in R^3. \n\n"}
{"id": "math/0410111", "contents": "Title: Integer Polynomial Optimization in Fixed Dimension Abstract: We classify, according to their computational complexity, integer\noptimization problems whose constraints and objective functions are polynomials\nwith integer coefficients and the number of variables is fixed. For the\noptimization of an integer polynomial over the lattice points of a convex\npolytope, we show an algorithm to compute lower and upper bounds for the\noptimal value. For polynomials that are non-negative over the polytope, these\nsequences of bounds lead to a fully polynomial-time approximation scheme for\nthe optimization problem. \n\n"}
{"id": "math/0410111", "contents": "Title: Integer Polynomial Optimization in Fixed Dimension Abstract: We classify, according to their computational complexity, integer\noptimization problems whose constraints and objective functions are polynomials\nwith integer coefficients and the number of variables is fixed. For the\noptimization of an integer polynomial over the lattice points of a convex\npolytope, we show an algorithm to compute lower and upper bounds for the\noptimal value. For polynomials that are non-negative over the polytope, these\nsequences of bounds lead to a fully polynomial-time approximation scheme for\nthe optimization problem. \n\n"}
{"id": "math/0502078", "contents": "Title: Finiteness theorems in stochastic integer programming Abstract: We study Graver test sets for families of linear multi-stage stochastic\ninteger programs with varying number of scenarios. We show that these test sets\ncan be decomposed into finitely many ``building blocks'', independent of the\nnumber of scenarios, and we give an effective procedure to compute these\nbuilding blocks. The paper includes an introduction to Nash-Williams' theory of\nbetter-quasi-orderings, which is used to show termination of our algorithm. We\nalso apply this theory to finiteness results for Hilbert functions. \n\n"}
{"id": "math/0504444", "contents": "Title: Computing the Ehrhart quasi-polynomial of a rational simplex Abstract: We present a polynomial time algorithm to compute any fixed number of the\nhighest coefficients of the Ehrhart quasi-polynomial of a rational simplex.\nPreviously such algorithms were known for integer simplices and for rational\npolytopes of a fixed dimension. The algorithm is based on the formula relating\nthe kth coefficient of the Ehrhart quasi-polynomial of a rational polytope to\nvolumes of sections of the polytope by affine lattice subspaces parallel to\nk-dimensional faces of the polytope. We discuss possible extensions and open\nquestions. \n\n"}
{"id": "math/0506619", "contents": "Title: PIIPTI, or the Principle of Increasing Irrelevance of Preference Type\n  Information Abstract: It is shown that in the case of a single decision maker who optimizes several\npossibly conflicting objectives, the amount of information available in\npreference relations among pairs of possible decisions, when compared with all\nother possible information, is tending to zero exponentially with the number of\nthose different objectives. Consequently, in the case of a larger number of\nconflicting objectives, the only way to obtain a satisfactory amount of\ninformation is by the use of non-preference type relations among possible\ndecisions. \n\n"}
{"id": "math/0508023", "contents": "Title: Steering laws for motion camouflage Abstract: Motion camouflage is a stealth strategy observed in nature. We formulate the\nproblem as a feedback system for particles moving at constant speed, and define\nwhat it means for the system to be in a state of motion camouflage. (Here we\nfocus on the planar setting, although the results can be generalized to\nthree-dimensional motion.) We propose a biologically plausible feedback law,\nand use a high-gain limit to prove accessibility of a motion camouflage state\nin finite time. We discuss connections to work in missile guidance. We also\npresent simulation results to explore the performance of the motion camouflage\nfeedback law for a variety of settings. \n\n"}
{"id": "math/0509536", "contents": "Title: A Discrete Variational Integrator for Optimal Control Problems on SO(3) Abstract: In this paper we study a discrete variational optimal control problem for the\nrigid body. The cost to be minimized is the external torque applied to move the\nrigid body from an initial condition to a pre-specified terminal condition.\nInstead of discretizing the equations of motion, we use the discrete equations\nobtained from the discrete Lagrange--d'Alembert principle, a process that\nbetter approximates the equations of motion. Within the discrete-time setting,\nthese two approaches are not equivalent in general. The kinematics are\ndiscretized using a natural Lie-algebraic formulation that guarantees that the\nflow remains on the Lie group SO(3) and its algebra so(3). We use Lagrange's\nmethod for constrained problems in the calculus of variations to derive the\ndiscrete-time necessary conditions. We give a numerical example for a\nthree-dimensional rigid body maneuver. \n\n"}
{"id": "math/0511355", "contents": "Title: Quadratures of Pontryagin Extremals for Optimal Control Problems Abstract: We obtain a method to compute effective first integrals by combining\nNoether's principle with the Kozlov-Kolesnikov integrability theorem. A\nsufficient condition for the integrability by quadratures of optimal control\nproblems with controls taking values on open sets is obtained. We illustrate\nour approach on some problems taken from the literature. An alternative proof\nof the integrability of the sub-Riemannian nilpotent Lie group of type (2,3,5)\nis also given. \n\n"}
{"id": "math/0601648", "contents": "Title: The maximum entropy ansatz in the absence of a time arrow: fractional\n  pole models Abstract: The maximum entropy ansatz, as it is often invoked in the context of\ntime-series analysis, suggests the selection of a power spectrum which is\nconsistent with autocorrelation data and corresponds to a random process least\npredictable from past observations. We introduce and compare a class of spectra\nwith the property that the underlying random process is least predictable at\nany given point from the complete set of past and future observations. In this\ncontext, randomness is quantified by the size of the corresponding smoothing\nerror and deterministic processes are characterized by integrability of the\ninverse of their power spectral densities--as opposed to the log-integrability\nin the classical setting. The power spectrum which is consistent with a partial\nautocorrelation sequence and corresponds to the most random process in this new\nsense, is no longer rational but generated by finitely many fractional-poles. \n\n"}
{"id": "math/0603619", "contents": "Title: The max-plus finite element method for solving deterministic optimal\n  control problems: basic properties and convergence analysis Abstract: We introduce a max-plus analogue of the Petrov-Galerkin finite element method\nto solve finite horizon deterministic optimal control problems. The method\nrelies on a max-plus variational formulation. We show that the error in the sup\nnorm can be bounded from the difference between the value function and its\nprojections on max-plus and min-plus semimodules, when the max-plus analogue of\nthe stiffness matrix is exactly known. In general, the stiffness matrix must be\napproximated: this requires approximating the operation of the Lax-Oleinik\nsemigroup on finite elements. We consider two approximations relying on the\nHamiltonian. We derive a convergence result, in arbitrary dimension, showing\nthat for a class of problems, the error estimate is of order $\\delta+\\Delta\nx(\\delta)^{-1}$ or $\\sqrt{\\delta}+\\Delta x(\\delta)^{-1}$, depending on the\nchoice of the approximation, where $\\delta$ and $\\Delta x$ are respectively the\ntime and space discretization steps. We compare our method with another\nmax-plus based discretization method previously introduced by Fleming and\nMcEneaney. We give numerical examples in dimension 1 and 2. \n\n"}
{"id": "math/0605242", "contents": "Title: N-Fold Integer Programming Abstract: In this article we study a broad class of integer programming problems in\nvariable dimension. We show that these so-termed {\\em n-fold integer\nprogramming problems} are polynomial time solvable. Our proof involves two\nheavy ingredients discovered recently: the equivalence of linear optimization\nand so-called directed augmentation, and the stabilization of certain Graver\nbases.\n  We discuss several applications of our algorithm to multiway transportation\nproblems and to packing problems. One important consequence of our results is a\npolynomial time algorithm for the $d$-dimensional integer transportation\nproblem for long multiway tables. Another interesting application is a new\nalgorithm for the classical cutting stock problem. \n\n"}
{"id": "math/0607026", "contents": "Title: Distances between power spectral densities Abstract: We present several natural notions of distance between spectral density\nfunctions of (discrete-time) random processes. They are motivated by certain\nfiltering problems. First we quantify the degradation of performance of a\npredictor which is designed for a particular spectral density function and then\nit is used to predict the values of a random process having a different\nspectral density. The logarithm of the ratio between the variance of the error,\nover the corresponding minimal (optimal) variance, produces a measure of\ndistance between the two power spectra with several desirable properties.\nAnalogous quantities based on smoothing problems produce alternative distances\nand suggest a class of measures based on fractions of generalized means of\nratios of power spectral densities. These distance measures endow the manifold\nof spectral density functions with a (pseudo) Riemannian metric. We pursue one\nof the possible options for a distance measure, characterize the relevant\ngeodesics, and compute corresponding distances. \n\n"}
{"id": "math/0609038", "contents": "Title: A variational problem on Stiefel manifolds Abstract: In their paper on discrete analogues of some classical systems such as the\nrigid body and the geodesic flow on an ellipsoid, Moser and Veselov introduced\ntheir analysis in the general context of flows on Stiefel manifolds. We\nconsider here a general class of continuous time, quadratic cost, optimal\ncontrol problems on Stiefel manifolds, which in the extreme dimensions again\nyield these classical physical geodesic flows. We have already shown that this\noptimal control setting gives a new symmetric representation of the rigid body\nflow and in this paper we extend this representation to the geodesic flow on\nthe ellipsoid and the more general Stiefel manifold case. The metric we choose\non the Stiefel manifolds is the same as that used in the symmetric\nrepresentation of the rigid body flow and that used by Moser and Veselov. In\nthe extreme cases of the ellipsoid and the rigid body, the geodesic flows are\nknown to be integrable. We obtain the extremal flows using both variational and\noptimal control approaches and elucidate the structure of the flows on general\nStiefel manifolds. \n\n"}
{"id": "math/0610854", "contents": "Title: Convergence speed of unsteady distributed consensus: decay estimate\n  along the settling spanning-trees Abstract: Results for estimating the convergence rate of non-stationary distributed\nconsensus algorithms are provided, on the basis of qualitative (mainly\ntopological) as well as basic quantitative information (lower-bounds on the\nmatrix entries). The results appear to be tight in a number of instances and\nare illustrated through simple as well as more sophisticated examples. The main\nidea is to follow propagation of information along certain spanning trees which\narise in the communication graph. \n\n"}
{"id": "math/0611531", "contents": "Title: Orbitopal Fixing Abstract: The topic of this paper are integer programming models in which a subset of\n0/1-variables encode a partitioning of a set of objects into disjoint subsets.\nSuch models can be surprisingly hard to solve by branch-and-cut algorithms if\nthe order of the subsets of the partition is irrelevant, since this kind of\nsymmetry unnecessarily blows up the search tree. We present a general tool,\ncalled orbitopal fixing, for enhancing the capabilities of branch-and-cut\nalgorithms in solving such symmetric integer programming models. We devise a\nlinear time algorithm that, applied at each node of the search tree, removes\nredundant parts of the tree produced by the above mentioned symmetry. The\nmethod relies on certain polyhedra, called orbitopes, which have been\nintroduced bei Kaibel and Pfetsch (Math. Programm. A, 114 (2008), 1-36). It\ndoes, however, not explicitly add inequalities to the model. Instead, it uses\ncertain fixing rules for variables. We demonstrate the computational power of\norbitopal fixing at the example of a graph partitioning problem. \n\n"}
{"id": "math/0612615", "contents": "Title: Truncated Markov bases and Gr\\\"obner bases for Integer Programming Abstract: We present a new algorithm for computing a truncated Markov basis of a\nlattice. In general, this new algorithm is faster than existing methods. We\nthen extend this new algorithm so that it solves the linear integer feasibility\nproblem with promising results for equality knapsack problems. We also present\na novel Groebner basis approach to solve a particular integer linear program as\nopposed to previous Groebner basis methods that effectively solved many\ndifferent integer linear programs simultaneously. Initial results indicate that\nthis optimisation algorithm performs better than previous Groebner basis\nmethods. \n\n"}
{"id": "math/0612682", "contents": "Title: Convergence Speed in Distributed Consensus and Control Abstract: We study the convergence speed of distributed iterative algorithms for the\nconsensus and averaging problems, with emphasis on the latter. We first\nconsider the case of a fixed communication topology. We show that a simple\nadaptation of a consensus algorithm leads to an averaging algorithm. We prove\nlower bounds on the worst-case convergence time for various classes of linear,\ntime-invariant, distributed consensus methods, and provide an algorithm that\nessentially matches those lower bounds. We then consider the case of a\ntime-varying topology, and provide a polynomial-time averaging algorithm. \n\n"}
{"id": "math/0703079", "contents": "Title: Least-Squares Prices of Games Abstract: What are the prices of random variables? In this paper, we define the\nleast-squares prices of coin-flipping games, which are proved to be minimal,\npositive linear, and arbitrage-free. These prices depend both on a set of games\nthat are available for investing simultaneously and on a risk-free interest\nrate. In addition, we show a case where the mean-variance portfolio theory is\ninappropriate. \n\n"}
{"id": "math/0703575", "contents": "Title: Convex Discrete Optimization Abstract: We develop an algorithmic theory of convex optimization over discrete sets.\nUsing a combination of algebraic and geometric tools we are able to provide\npolynomial time algorithms for solving broad classes of convex combinatorial\noptimization problems and convex integer programming problems in variable\ndimension. We discuss some of the many applications of this theory including to\nquadratic programming, matroids, bin packing and cutting-stock problems, vector\npartitioning and clustering, multiway transportation problems, and privacy and\nconfidential statistical data disclosure. Highlights of our work include a\nstrongly polynomial time algorithm for convex and linear combinatorial\noptimization over any family presented by a membership oracle when the\nunderlying polytope has few edge-directions; a new theory of so-termed n-fold\ninteger programming, yielding polynomial time solution of important and natural\nclasses of convex and linear integer programming problems in variable\ndimension; and a complete complexity classification of high dimensional\ntransportation problems, with practical applications to fundamental problems in\nprivacy and confidential statistical data disclosure. \n\n"}
{"id": "math/9702218", "contents": "Title: Some Remarks on Real and Complex Output Feedback Abstract: We provide some new necessary and sufficient conditions which guarantee\narbitrary pole placement of a particular linear system over the complex\nnumbers. We exhibit a non-trivial real linear system which is not controllable\nby real static output feedback and discuss a conjecture from algebraic geometry\nconcerning the existence of real linear systems for which all static feedback\nlaws are real. \n\n"}
