{"id": "0704.2857", "contents": "Title: Modern Coding Theory: The Statistical Mechanics and Computer Science\n  Point of View Abstract: These are the notes for a set of lectures delivered by the two authors at the\nLes Houches Summer School on `Complex Systems' in July 2006. They provide an\nintroduction to the basic concepts in modern (probabilistic) coding theory,\nhighlighting connections with statistical mechanics. We also stress common\nconcepts with other disciplines dealing with similar problems that can be\ngenerically referred to as `large graphical models'.\n  While most of the lectures are devoted to the classical channel coding\nproblem over simple memoryless channels, we present a discussion of more\ncomplex channel models. We conclude with an overview of the main open\nchallenges in the field. \n\n"}
{"id": "0705.3995", "contents": "Title: On Undetected Error Probability of Binary Matrix Ensembles Abstract: In this paper, an analysis of the undetected error probability of ensembles\nof binary matrices is presented. The ensemble called the Bernoulli ensemble\nwhose members are considered as matrices generated from i.i.d. Bernoulli source\nis mainly considered here. The main contributions of this work are (i)\nderivation of the error exponent of the average undetected error probability\nand (ii) closed form expressions for the variance of the undetected error\nprobability. It is shown that the behavior of the exponent for a sparse\nensemble is somewhat different from that for a dense ensemble. Furthermore, as\na byproduct of the proof of the variance formula, simple covariance formula of\nthe weight distribution is derived. \n\n"}
{"id": "0707.1099", "contents": "Title: Worst-Case Interactive Communication and Enhancing Sensor Network\n  Lifetime Abstract: We are concerned with the problem of maximizing the worst-case lifetime of a\ndata-gathering wireless sensor network consisting of a set of sensor nodes\ndirectly communicating with a base-station.We propose to solve this problem by\nmodeling sensor node and base-station communication as the interactive\ncommunication between multiple correlated informants (sensor nodes) and a\nrecipient (base-station). We provide practical and scalable interactive\ncommunication protocols for data gathering in sensor networks and demonstrate\ntheir efficiency compared to traditional approaches.\n  In this paper, we first develop a formalism to address the problem of\nworst-case interactive communication between a set of multiple correlated\ninformants and a recipient. We realize that there can be different objectives\nto achieve in such a communication scenario and compute the optimal number of\nmessages and bits exchanged to realize these objectives. Then, we propose to\nadapt these results in the context of single-hop data-gathering sensor\nnetworks. Finally, based on this proposed formalism, we propose a clustering\nbased communication protocol for large sensor networks and demonstrate its\nsuperiority over a traditional clustering protocol. \n\n"}
{"id": "0708.0271", "contents": "Title: Capacity Region of the Finite-State Multiple Access Channel with and\n  without Feedback Abstract: The capacity region of the Finite-State Multiple Access Channel (FS-MAC) with\nfeedback that may be an arbitrary time-invariant function of the channel output\nsamples is considered. We characterize both an inner and an outer bound for\nthis region, using Masseys's directed information. These bounds are shown to\ncoincide, and hence yield the capacity region, of FS-MACs where the state\nprocess is stationary and ergodic and not affected by the inputs.\n  Though `multi-letter' in general, our results yield explicit conclusions when\napplied to specific scenarios of interest. E.g., our results allow us to:\n  - Identify a large class of FS-MACs, that includes the additive mod-2 noise\nMAC where the noise may have memory, for which feedback does not enlarge the\ncapacity region.\n  - Deduce that, for a general FS-MAC with states that are not affected by the\ninput, if the capacity (region) without feedback is zero, then so is the\ncapacity (region) with feedback.\n  - Deduce that the capacity region of a MAC that can be decomposed into a\n`multiplexer' concatenated by a point-to-point channel (with, without, or with\npartial feedback), the capacity region is given by $\\sum_{m} R_m \\leq C$, where\nC is the capacity of the point to point channel and m indexes the encoders.\nMoreover, we show that for this family of channels source-channel coding\nseparation holds. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0708.4214", "contents": "Title: High Rate Single-Symbol Decodable Precoded DSTBCs for Cooperative\n  Networks Abstract: Distributed Orthogonal Space-Time Block Codes (DOSTBCs) achieving full\ndiversity order and single-symbol ML decodability have been introduced recently\nfor cooperative networks and an upper-bound on the maximal rate of such codes\nalong with code constructions has been presented. In this report, we introduce\na new class of Distributed STBCs called Semi-orthogonal Precoded Distributed\nSingle-Symbol Decodable STBCs (S-PDSSDC) wherein, the source performs\nco-ordinate interleaving of information symbols appropriately before\ntransmitting it to all the relays. It is shown that DOSTBCs are a special case\nof S-PDSSDCs. A special class of S-PDSSDCs having diagonal covariance matrix at\nthe destination is studied and an upper bound on the maximal rate of such codes\nis derived. The bounds obtained are approximately twice larger than that of the\nDOSTBCs. A systematic construction of S-PDSSDCs is presented when the number of\nrelays $K \\geq 4$. The constructed codes are shown to achieve the upper-bound\non the rate when $K$ is of the form 0 modulo 4 or 3 modulo 4. For the rest of\nthe values of $K$, the constructed codes are shown to have rates higher than\nthat of DOSTBCs. It is also shown that S-PDSSDCs cannot be constructed with any\nform of linear processing at the relays when the source doesn't perform\nco-ordinate interleaving of the information symbols. \n\n"}
{"id": "0708.4328", "contents": "Title: Dualities Between Entropy Functions and Network Codes Abstract: This paper provides a new duality between entropy functions and network\ncodes. Given a function $g\\geq 0$ defined on all proper subsets of $N$ random\nvariables, we provide a construction for a network multicast problem which is\nsolvable if and only if $g$ is entropic. The underlying network topology is\nfixed and the multicast problem depends on $g$ only through edge capacities and\nsource rates. Relaxing the requirement that the domain of $g$ be subsets of\nrandom variables, we obtain a similar duality between polymatroids and the\nlinear programming bound. These duality results provide an alternative proof of\nthe insufficiency of linear (and abelian) network codes, and demonstrate the\nutility of non-Shannon inequalities to tighten outer bounds on network coding\ncapacity regions. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0710.5161", "contents": "Title: Decomposable Subspaces, Linear Sections of Grassmann Varieties, and\n  Higher Weights of Grassmann Codes Abstract: Given a homogeneous component of an exterior algebra, we characterize those\nsubspaces in which every nonzero element is decomposable. In geometric terms,\nthis corresponds to characterizing the projective linear subvarieties of the\nGrassmann variety with its Plucker embedding. When the base field is finite, we\nconsider the more general question of determining the maximum number of points\non sections of Grassmannians by linear subvarieties of a fixed (co)dimension.\nThis corresponds to a known open problem of determining the complete weight\nhierarchy of linear error correcting codes associated to Grassmann varieties.\nWe recover most of the known results as well as prove some new results. In the\nprocess we obtain, and utilize, a simple generalization of the Griesmer-Wei\nbound for arbitrary linear codes. \n\n"}
{"id": "0711.0237", "contents": "Title: Zero-rate feedback can achieve the empirical capacity Abstract: The utility of limited feedback for coding over an individual sequence of\nDMCs is investigated. This study complements recent results showing how limited\nor noisy feedback can boost the reliability of communication. A strategy with\nfixed input distribution $P$ is given that asymptotically achieves rates\narbitrarily close to the mutual information induced by $P$ and the\nstate-averaged channel. When the capacity achieving input distribution is the\nsame over all channel states, this achieves rates at least as large as the\ncapacity of the state averaged channel, sometimes called the empirical\ncapacity. \n\n"}
{"id": "0711.1056", "contents": "Title: Bounds on the Number of Iterations for Turbo-Like Ensembles over the\n  Binary Erasure Channe Abstract: This paper provides simple lower bounds on the number of iterations which is\nrequired for successful message-passing decoding of some important families of\ngraph-based code ensembles (including low-density parity-check codes and\nvariations of repeat-accumulate codes). The transmission of the code ensembles\nis assumed to take place over a binary erasure channel, and the bounds refer to\nthe asymptotic case where we let the block length tend to infinity. The\nsimplicity of the bounds derived in this paper stems from the fact that they\nare easily evaluated and are expressed in terms of some basic parameters of the\nensemble which include the fraction of degree-2 variable nodes, the target bit\nerasure probability and the gap between the channel capacity and the design\nrate of the ensemble. This paper demonstrates that the number of iterations\nwhich is required for successful message-passing decoding scales at least like\nthe inverse of the gap (in rate) to capacity, provided that the fraction of\ndegree-2 variable nodes of these turbo-like ensembles does not vanish (hence,\nthe number of iterations becomes unbounded as the gap to capacity vanishes). \n\n"}
{"id": "0711.3152", "contents": "Title: Multipath Channels of Bounded Capacity Abstract: The capacity of discrete-time, non-coherent, multipath fading channels is\nconsidered. It is shown that if the delay spread is large in the sense that the\nvariances of the path gains do not decay faster than geometrically, then\ncapacity is bounded in the signal-to-noise ratio. \n\n"}
{"id": "0803.2262", "contents": "Title: Constant-Rank Codes and Their Connection to Constant-Dimension Codes Abstract: Constant-dimension codes have recently received attention due to their\nsignificance to error control in noncoherent random linear network coding. What\nthe maximal cardinality of any constant-dimension code with finite dimension\nand minimum distance is and how to construct the optimal constant-dimension\ncode (or codes) that achieves the maximal cardinality both remain open research\nproblems. In this paper, we introduce a new approach to solving these two\nproblems. We first establish a connection between constant-rank codes and\nconstant-dimension codes. Via this connection, we show that optimal\nconstant-dimension codes correspond to optimal constant-rank codes over\nmatrices with sufficiently many rows. As such, the two aforementioned problems\nare equivalent to determining the maximum cardinality of constant-rank codes\nand to constructing optimal constant-rank codes, respectively. To this end, we\nthen derive bounds on the maximum cardinality of a constant-rank code with a\ngiven minimum rank distance, propose explicit constructions of optimal or\nasymptotically optimal constant-rank codes, and establish asymptotic bounds on\nthe maximum rate of a constant-rank code. \n\n"}
{"id": "0804.0611", "contents": "Title: Channel State Feedback Schemes for Multiuser MIMO-OFDM Downlink Abstract: Channel state feedback schemes for the MIMO broadcast downlink have been\nwidely studied in the frequency-flat case. This work focuses on the more\nrelevant frequency selective case, where some important new aspects emerge. We\nconsider a MIMO-OFDM broadcast channel and compare achievable ergodic rates\nunder three channel state feedback schemes: analog feedback, direction\nquantized feedback and \"time-domain\" channel quantized feedback. The first two\nschemes are direct extensions of previously proposed schemes. The third scheme\nis novel, and it is directly inspired by rate-distortion theory of Gaussian\ncorrelated sources. For each scheme we derive the conditions under which the\nsystem achieves full multiplexing gain. The key difference with respect to the\nwidely treated frequency-flat case is that in MIMO-OFDM the frequency-domain\nchannel transfer function is a Gaussian correlated source. The new time-domain\nquantization scheme takes advantage of the channel frequency correlation\nstructure and outperforms the other schemes. Furthermore, it is by far simpler\nto implement than complicated spherical vector quantization. In particular, we\nobserve that no structured codebook design and vector quantization is actually\nneeded for efficient channel state information feedback. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0804.2469", "contents": "Title: On analytic properties of entropy rate Abstract: Entropy rate is a real valued functional on the space of discrete random\nsources which lacks a closed formula even for subclasses of sources which have\nintuitive parameterizations. A good way to overcome this problem is to examine\nits analytic properties relative to some reasonable topology. A canonical\nchoice of a topology is that of the norm of total variation as it immediately\narises with the idea of a discrete random source as a probability measure on\nsequence space. It is shown that entropy rate is Lipschitzian relative to this\ntopology, which, by well known facts, is close to differentiability. An\napplication of this theorem leads to a simple and elementary proof of the\nexistence of entropy rate of random sources with finite evolution dimension.\nThis class of sources encompasses arbitrary hidden Markov sources and quantum\nrandom walks. \n\n"}
{"id": "0804.2998", "contents": "Title: OFDM based Distributed Space Time Coding for Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time block code (DSTBC) structure that admit its application\nin the proposed transmission scheme are identified and it is pointed out that\nthe recently proposed full diversity four group decodable DSTBCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time block codes applicable in this new transmission scheme\nfor power of two number of relays are also provided. \n\n"}
{"id": "0805.1857", "contents": "Title: The Gaussian Many-Help-One Distributed Source Coding Problem Abstract: Jointly Gaussian memoryless sources are observed at N distinct terminals. The\ngoal is to efficiently encode the observations in a distributed fashion so as\nto enable reconstruction of any one of the observations, say the first one, at\nthe decoder subject to a quadratic fidelity criterion. Our main result is a\nprecise characterization of the rate-distortion region when the covariance\nmatrix of the sources satisfies a \"tree-structure\" condition. In this\nsituation, a natural analog-digital separation scheme optimally trades off the\ndistributed quantization rate tuples and the distortion in the reconstruction:\neach encoder consists of a point-to-point Gaussian vector quantizer followed by\na Slepian-Wolf binning encoder. We also provide a partial converse that\nsuggests that the tree structure condition is fundamental. \n\n"}
{"id": "0806.3650", "contents": "Title: Recursive Code Construction for Random Networks Abstract: A modification of Koetter-Kschischang codes for random networks is presented\n(these codes were also studied by Wang et al. in the context of authentication\nproblems). The new codes have higher information rate, while maintaining the\nsame error-correcting capabilities. An efficient error-correcting algorithm is\nproposed for these codes. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0807.2724", "contents": "Title: An Asymptotic Analysis of the MIMO BC under Linear Filtering Abstract: We investigate the MIMO broadcast channel in the high SNR regime when linear\nfiltering is applied instead of dirty paper coding. Using a user-wise rate\nduality where the streams of every single user are not treated as\nself-interference as in the hitherto existing stream-wise rate dualities for\nlinear filtering, we solve the weighted sum rate maximization problem of the\nbroadcast channel in the dual multiple access channel. Thus, we can exactly\nquantify the asymptotic rate loss of linear filtering compared to dirty paper\ncoding for any channel realization. Having converted the optimum covariance\nmatrices to the broadcast channel by means of the duality, we observe that the\noptimal covariance matrices in the broadcast channel feature quite complicated\nbut still closed form expressions although the respective transmit covariance\nmatrices in the dual multiple access channel share a very simple structure. We\nimmediately come to the conclusion that block-diagonalization is the\nasymptotically optimum transmit strategy in the broadcast channel. Out of the\nset of block-diagonalizing precoders, we present the one which achieves the\nlargest sum rate and thus corresponds to the optimum solution found in the dual\nmultiple access channel. Additionally, we quantify the ergodic rate loss of\nlinear coding compared to dirty paper coding for Gaussian channels with\ncorrelations at the mobiles. \n\n"}
{"id": "0807.3222", "contents": "Title: The two-user Gaussian interference channel: a deterministic view Abstract: This paper explores the two-user Gaussian interference channel through the\nlens of a natural deterministic channel model. The main result is that the\ndeterministic channel uniformly approximates the Gaussian channel, the capacity\nregions differing by a universal constant. The problem of finding the capacity\nof the Gaussian channel to within a constant error is therefore reduced to that\nof finding the capacity of the far simpler deterministic channel. Thus, the\npaper provides an alternative derivation of the recent constant gap capacity\ncharacterization of Etkin, Tse, and Wang. Additionally, the deterministic model\ngives significant insight towards the Gaussian channel. \n\n"}
{"id": "0808.0548", "contents": "Title: How could the replica method improve accuracy of performance assessment\n  of channel coding? Abstract: We explore the relation between the techniques of statistical mechanics and\ninformation theory for assessing the performance of channel coding. We base our\nstudy on a framework developed by Gallager in {\\em IEEE Trans. Inform. Theory}\n{\\bf 11}, 3 (1965), where the minimum decoding error probability is\nupper-bounded by an average of a generalized Chernoff's bound over a code\nensemble. We show that the resulting bound in the framework can be directly\nassessed by the replica method, which has been developed in statistical\nmechanics of disordered systems, whereas in Gallager's original methodology\nfurther replacement by another bound utilizing Jensen's inequality is\nnecessary. Our approach associates a seemingly {\\em ad hoc} restriction with\nrespect to an adjustable parameter for optimizing the bound with a phase\ntransition between two replica symmetric solutions, and can improve the\naccuracy of performance assessments of general code ensembles including low\ndensity parity check codes, although its mathematical justification is still\nopen. \n\n"}
{"id": "0808.1495", "contents": "Title: The finite harmonic oscillator and its applications to sequences,\n  communication and radar Abstract: A novel system, called the oscillator system, consisting of order of p^3\nfunctions (signals) on the finite field F_p; with p an odd prime, is described\nand studied. The new functions are proved to satisfy good auto-correlation,\ncross-correlation and low peak-to-average power ratio properties. Moreover, the\noscillator system is closed under the operation of discrete Fourier transform.\nApplications of the oscillator system for discrete radar and digital\ncommunication theory are explained. Finally, an explicit algorithm to construct\nthe oscillator system is presented. \n\n"}
{"id": "0808.2515", "contents": "Title: Provably efficient instanton search algorithm for LP decoding of LDPC\n  codes over the BSC Abstract: We consider Linear Programming (LP) decoding of a fixed Low-Density\nParity-Check (LDPC) code over the Binary Symmetric Channel (BSC). The LP\ndecoder fails when it outputs a pseudo-codeword which is not a codeword. We\ndesign an efficient algorithm termed the Instanton Search Algorithm (ISA)\nwhich, given a random input, generates a set of flips called the BSC-instanton.\nWe prove that: (a) the LP decoder fails for any set of flips with support\nvector including an instanton; (b) for any input, the algorithm outputs an\ninstanton in the number of steps upper-bounded by twice the number of flips in\nthe input. Repeated sufficient number of times, the ISA outcomes the number of\nunique instantons of different sizes. \n\n"}
{"id": "0809.0099", "contents": "Title: Degrees of Freedom of the $K$ User $M \\times N$ MIMO Interference\n  Channel Abstract: We provide innerbound and outerbound for the total number of degrees of\nfreedom of the $K$ user multiple input multiple output (MIMO) Gaussian\ninterference channel with $M$ antennas at each transmitter and $N$ antennas at\neach receiver if the channel coefficients are time-varying and drawn from a\ncontinuous distribution. The bounds are tight when the ratio\n$\\frac{\\max(M,N)}{\\min(M,N)}=R$ is equal to an integer. For this case, we show\nthat the total number of degrees of freedom is equal to $\\min(M,N)K$ if $K \\leq\nR$ and $\\min(M,N)\\frac{R}{R+1}K$ if $K > R$. Achievability is based on\ninterference alignment. We also provide examples where using interference\nalignment combined with zero forcing can achieve more degrees of freedom than\nmerely zero forcing for some MIMO interference channels with constant channel\ncoefficients. \n\n"}
{"id": "0809.2446", "contents": "Title: High-Rate Space-Time Coded Large MIMO Systems: Low-Complexity Detection\n  and Channel Estimation Abstract: In this paper, we present a low-complexity algorithm for detection in\nhigh-rate, non-orthogonal space-time block coded (STBC) large-MIMO systems that\nachieve high spectral efficiencies of the order of tens of bps/Hz. We also\npresent a training-based iterative detection/channel estimation scheme for such\nlarge STBC MIMO systems. Our simulation results show that excellent bit error\nrate and nearness-to-capacity performance are achieved by the proposed\nmultistage likelihood ascent search (M-LAS) detector in conjunction with the\nproposed iterative detection/channel estimation scheme at low complexities. The\nfact that we could show such good results for large STBCs like 16x16 and 32x32\nSTBCs from Cyclic Division Algebras (CDA) operating at spectral efficiencies in\nexcess of 20 bps/Hz (even after accounting for the overheads meant for pilot\nbased training for channel estimation and turbo coding) establishes the\neffectiveness of the proposed detector and channel estimator. We decode perfect\ncodes of large dimensions using the proposed detector. With the feasibility of\nsuch a low-complexity detection/channel estimation scheme, large-MIMO systems\nwith tens of antennas operating at several tens of bps/Hz spectral efficiencies\ncan become practical, enabling interesting high data rate wireless\napplications. \n\n"}
{"id": "0809.3731", "contents": "Title: Uncertainty Relations for Shift-Invariant Analog Signals Abstract: The past several years have witnessed a surge of research investigating\nvarious aspects of sparse representations and compressed sensing. Most of this\nwork has focused on the finite-dimensional setting in which the goal is to\ndecompose a finite-length vector into a given finite dictionary. Underlying\nmany of these results is the conceptual notion of an uncertainty principle: a\nsignal cannot be sparsely represented in two different bases. Here, we extend\nthese ideas and results to the analog, infinite-dimensional setting by\nconsidering signals that lie in a finitely-generated shift-invariant (SI)\nspace. This class of signals is rich enough to include many interesting special\ncases such as multiband signals and splines. By adapting the notion of\ncoherence defined for finite dictionaries to infinite SI representations, we\ndevelop an uncertainty principle similar in spirit to its finite counterpart.\nWe demonstrate tightness of our bound by considering a bandlimited lowpass\ntrain that achieves the uncertainty principle. Building upon these results and\nsimilar work in the finite setting, we show how to find a sparse decomposition\nin an overcomplete dictionary by solving a convex optimization problem. The\ndistinguishing feature of our approach is the fact that even though the problem\nis defined over an infinite domain with infinitely many variables and\nconstraints, under certain conditions on the dictionary spectrum our algorithm\ncan find the sparsest representation by solving a finite-dimensional problem. \n\n"}
{"id": "0810.2336", "contents": "Title: A Mordell Inequality for Lattices over Maximal Orders Abstract: In this paper we prove an analogue of Mordell's inequality for lattices in\nfinite-dimensional complex or quaternionic Hermitian space that are modules\nover a maximal order in an imaginary quadratic number field or a totally\ndefinite rational quaternion algebra. This inequality implies that the\n16-dimensional Barnes-Wall lattice has optimal density among all 16-dimensional\nlattices with Hurwitz structures. \n\n"}
{"id": "0810.5203", "contents": "Title: Monotonic Convergence in an Information-Theoretic Law of Small Numbers Abstract: An \"entropy increasing to the maximum\" result analogous to the entropic\ncentral limit theorem (Barron 1986; Artstein et al. 2004) is obtained in the\ndiscrete setting. This involves the thinning operation and a Poisson limit.\nMonotonic convergence in relative entropy is established for general discrete\ndistributions, while monotonic increase of Shannon entropy is proved for the\nspecial class of ultra-log-concave distributions. Overall we extend the\nparallel between the information-theoretic central limit theorem and law of\nsmall numbers explored by Kontoyiannis et al. (2005) and Harremo\\\"es et al.\\\n(2007, 2008). Ingredients in the proofs include convexity, majorization, and\nstochastic orders. \n\n"}
{"id": "0811.0726", "contents": "Title: Improved Capacity Scaling in Wireless Networks With Infrastructure Abstract: This paper analyzes the impact and benefits of infrastructure support in\nimproving the throughput scaling in networks of $n$ randomly located wireless\nnodes. The infrastructure uses multi-antenna base stations (BSs), in which the\nnumber of BSs and the number of antennas at each BS can scale at arbitrary\nrates relative to $n$. Under the model, capacity scaling laws are analyzed for\nboth dense and extended networks. Two BS-based routing schemes are first\nintroduced in this study: an infrastructure-supported single-hop (ISH) routing\nprotocol with multiple-access uplink and broadcast downlink and an\ninfrastructure-supported multi-hop (IMH) routing protocol. Then, their\nachievable throughput scalings are analyzed. These schemes are compared against\ntwo conventional schemes without BSs: the multi-hop (MH) transmission and\nhierarchical cooperation (HC) schemes. It is shown that a linear throughput\nscaling is achieved in dense networks, as in the case without help of BSs. In\ncontrast, the proposed BS-based routing schemes can, under realistic network\nconditions, improve the throughput scaling significantly in extended networks.\nThe gain comes from the following advantages of these BS-based protocols.\nFirst, more nodes can transmit simultaneously in the proposed scheme than in\nthe MH scheme if the number of BSs and the number of antennas are large enough.\nSecond, by improving the long-distance signal-to-noise ratio (SNR), the\nreceived signal power can be larger than that of the HC, enabling a better\nthroughput scaling under extended networks. Furthermore, by deriving the\ncorresponding information-theoretic cut-set upper bounds, it is shown under\nextended networks that a combination of four schemes IMH, ISH, MH, and HC is\norder-optimal in all operating regimes. \n\n"}
{"id": "0811.4227", "contents": "Title: Entanglement-assisted communication of classical and quantum information Abstract: We consider the problem of transmitting classical and quantum information\nreliably over an entanglement-assisted quantum channel. Our main result is a\ncapacity theorem that gives a three-dimensional achievable rate region. Points\nin the region are rate triples, consisting of the classical communication rate,\nthe quantum communication rate, and the entanglement consumption rate of a\nparticular coding scheme. The crucial protocol in achieving the boundary points\nof the capacity region is a protocol that we name the classically-enhanced\nfather protocol. The classically-enhanced father protocol is more general than\nother protocols in the family tree of quantum Shannon theoretic protocols, in\nthe sense that several previously known quantum protocols are now child\nprotocols of it. The classically-enhanced father protocol also shows an\nimprovement over a time-sharing strategy for the case of a qubit dephasing\nchannel--this result justifies the need for simultaneous coding of classical\nand quantum information over an entanglement-assisted quantum channel. Our\ncapacity theorem is of a multi-letter nature (requiring a limit over many uses\nof the channel), but it reduces to a single-letter characterization for at\nleast three channels: the completely depolarizing channel, the quantum erasure\nchannel, and the qubit dephasing channel. \n\n"}
{"id": "0812.0972", "contents": "Title: Network Protection Codes: Providing Self-healing in Autonomic Networks\n  Using Network Coding Abstract: Agile recovery from link failures in autonomic communication networks is\nessential to increase robustness, accessibility, and reliability of data\ntransmission. However, this must be done with the least amount of protection\nresources, while using simple management plane functionality. Recently, network\ncoding has been proposed as a solution to provide agile and cost efficient\nnetwork self-healing against link failures, in a manner that does not require\ndata rerouting, packet retransmission, or failure localization, hence leading\nto simple control and management planes. To achieve this, separate paths have\nto be provisioned to carry encoded packets, hence requiring either the addition\nof extra links, or reserving some of the resources for this purpose.\n  In this paper we introduce autonomic self-healing strategies for autonomic\nnetworks in order to protect against link failures. The strategies are based on\nnetwork coding and reduced capacity, which is a technique that we call network\nprotection codes (NPC). In these strategies, an autonomic network is able to\nprovide self-healing from various network failures affecting network operation.\nThe techniques improve service and enhance reliability of autonomic\ncommunication.\n  Network protection codes are extended to provide self-healing from multiple\nlink failures in autonomic networks. We provide implementation aspects of the\nproposed strategies. We present bounds and network protection code\nconstructions. Finally, we study the construction of such codes over the binary\nfield. The paper also develops an Integer Linear Program formulation to\nevaluate the cost of provisioning connections using the proposed strategies. \n\n"}
{"id": "0812.2275", "contents": "Title: Secrecy capacity of a class of orthogonal relay eavesdropper channels Abstract: The secrecy capacity of relay channels with orthogonal components is studied\nin the presence of an additional passive eavesdropper node. The relay and\ndestination receive signals from the source on two orthogonal channels such\nthat the destination also receives transmissions from the relay on its channel.\nThe eavesdropper can overhear either one or both of the orthogonal channels.\nInner and outer bounds on the secrecy capacity are developed for both the\ndiscrete memoryless and the Gaussian channel models. For the discrete\nmemoryless case, the secrecy capacity is shown to be achieved by a partial\ndecode-and-forward (PDF) scheme when the eavesdropper can overhear only one of\nthe two orthogonal channels. Two new outer bounds are presented for the\nGaussian model using recent capacity results for a Gaussian multi-antenna\npoint-to-point channel with a multi-antenna eavesdropper. The outer bounds are\nshown to be tight for two sub-classes of channels. The first sub-class is one\nin which the source and relay are clustered and the and the eavesdropper\nreceives signals only on the channel from the source and the relay to the\ndestination, for which the PDF strategy is optimal. The second is a sub-class\nin which the source does not transmit to the relay, for which a\nnoise-forwarding strategy is optimal. \n\n"}
{"id": "0812.2379", "contents": "Title: On the Decoder Error Probability of Rank Metric Codes and\n  Constant-Dimension Codes Abstract: Rank metric codes and constant-dimension codes (CDCs) have been considered\nfor error control in random network coding. Since decoder errors are more\ndetrimental to system performance than decoder failures, in this paper we\ninvestigate the decoder error probability (DEP) of bounded distance decoders\n(BDDs) for rank metric codes and CDCs. For rank metric codes, we consider a\nchannel motivated by network coding, where errors with the same row space are\nequiprobable. Over such channels, we establish upper bounds on the DEPs of\nBDDs, determine the exact DEP of BDDs for maximum rank distance (MRD) codes,\nand show that MRD codes have the greatest DEPs up to a scalar. To evaluate the\nDEPs of BDDs for CDCs, we first establish some fundamental geometric properties\nof the projective space. Using these geometric properties, we then consider\nBDDs in both subspace and injection metrics and derive analytical expressions\nof their DEPs for CDCs, over a symmetric operator channel, as functions of\ntheir distance distributions. Finally, we focus on CDCs obtained by lifting\nrank metric codes and establish two important results: First, we derive\nasymptotically tight upper bounds on the DEPs of BDDs in both metrics; Second,\nwe show that the DEPs for KK codes are the greatest up to a scalar among all\nCDCs obtained by lifting rank metric codes. \n\n"}
{"id": "0901.0269", "contents": "Title: Random Linear Network Coding For Time Division Duplexing: Energy\n  Analysis Abstract: We study the energy performance of random linear network coding for time\ndivision duplexing channels. We assume a packet erasure channel with nodes that\ncannot transmit and receive information simultaneously. The sender transmits\ncoded data packets back-to-back before stopping to wait for the receiver to\nacknowledge the number of degrees of freedom, if any, that are required to\ndecode correctly the information. Our analysis shows that, in terms of mean\nenergy consumed, there is an optimal number of coded data packets to send\nbefore stopping to listen. This number depends on the energy needed to transmit\neach coded packet and the acknowledgment (ACK), probabilities of packet and ACK\nerasure, and the number of degrees of freedom that the receiver requires to\ndecode the data. We show that its energy performance is superior to that of a\nfull-duplex system. We also study the performance of our scheme when the number\nof coded packets is chosen to minimize the mean time to complete transmission\nas in [1]. Energy performance under this optimization criterion is found to be\nclose to optimal, thus providing a good trade-off between energy and time\nrequired to complete transmissions. \n\n"}
{"id": "0901.1473", "contents": "Title: Communication over Individual Channels Abstract: We consider the problem of communicating over a channel for which no\nmathematical model is specified. We present achievable rates as a function of\nthe channel input and output known a-posteriori for discrete and continuous\nchannels, as well as a rate-adaptive scheme employing feedback which achieves\nthese rates asymptotically without prior knowledge of the channel behavior. \n\n"}
{"id": "0901.1988", "contents": "Title: Many-Help-One Problem for Gaussian Sources with a Tree Structure on\n  their Correlation Abstract: In this paper we consider the separate coding problem for $L+1$ correlated\nGaussian memoryless sources. We deal with the case where $L$ separately encoded\ndata of sources work as side information at the decoder for the reconstruction\nof the remaining source. The determination problem of the rate distortion\nregion for this system is the so called many-help-one problem and has been\nknown as a highly challenging problem. The author determined the rate\ndistortion region in the case where the $L$ sources working as partial side\ninformation are conditionally independent if the remaining source we wish to\nreconstruct is given. This condition on the correlation is called the CI\ncondition. In this paper we extend the author's previous result to the case\nwhere $L+1$ sources satisfy a kind of tree structure on their correlation. We\ncall this tree structure of information sources the TS condition, which\ncontains the CI condition as a special case. In this paper we derive an\nexplicit outer bound of the rate distortion region when information sources\nsatisfy the TS condition. We further derive an explicit sufficient condtion for\nthis outer bound to be tight. In particular, we determine the sum rate part of\nthe rate distortion region for the case where information sources satisfy the\nTS condition. For some class of Gaussian sources with the TS condition we\nderive an explicit recursive formula of this sum rate part. \n\n"}
{"id": "0901.4898", "contents": "Title: Effective Delay Control in Online Network Coding Abstract: Motivated by streaming applications with stringent delay constraints, we\nconsider the design of online network coding algorithms with timely delivery\nguarantees. Assuming that the sender is providing the same data to multiple\nreceivers over independent packet erasure channels, we focus on the case of\nperfect feedback and heterogeneous erasure probabilities. Based on a general\nanalytical framework for evaluating the decoding delay, we show that existing\nARQ schemes fail to ensure that receivers with weak channels are able to\nrecover from packet losses within reasonable time. To overcome this problem, we\nre-define the encoding rules in order to break the chains of linear\ncombinations that cannot be decoded after one of the packets is lost. Our\nresults show that sending uncoded packets at key times ensures that all the\nreceivers are able to meet specific delay requirements with very high\nprobability. \n\n"}
{"id": "0902.2370", "contents": "Title: Outer Bounds on the Admissible Source Region for Broadcast Channels with\n  Dependent Sources Abstract: Outer bounds on the admissible source region for broadcast channels with\ndependent sources are developed and used to prove capacity results for several\nclasses of sources and channels. \n\n"}
{"id": "0902.2438", "contents": "Title: Capacity of the Gaussian Two-way Relay Channel to within 1/2 Bit Abstract: In this paper, a Gaussian two-way relay channel, where two source nodes\nexchange messages with each other through a relay, is considered. We assume\nthat all nodes operate in full-duplex mode and there is no direct channel\nbetween the source nodes. We propose an achievable scheme composed of nested\nlattice codes for the uplink and structured binning for the downlink. We show\nthat the scheme achieves within 1/2 bit from the cut-set bound for all channel\nparameters and becomes asymptotically optimal as the signal to noise ratios\nincrease. \n\n"}
{"id": "0903.4434", "contents": "Title: Random Linear Network Coding for Time-Division Duplexing: Queueing\n  Analysis Abstract: We study the performance of random linear network coding for time division\nduplexing channels with Poisson arrivals. We model the system as a bulk-service\nqueue with variable bulk size. A full characterization for random linear\nnetwork coding is provided for time division duplexing channels [1] by means of\nthe moment generating function. We present numerical results for the mean\nnumber of packets in the queue and consider the effect of the range of\nallowable bulk sizes. We show that there exists an optimal choice of this range\nthat minimizes the mean number of data packets in the queue. \n\n"}
{"id": "0905.4164", "contents": "Title: Iterative Decoding on Multiple Tanner Graphs Using Random Edge Local\n  Complementation Abstract: In this paper, we propose to enhance the performance of the sum-product\nalgorithm (SPA) by interleaving SPA iterations with a random local graph update\nrule. This rule is known as edge local complementation (ELC), and has the\neffect of modifying the Tanner graph while preserving the code. We have\npreviously shown how the ELC operation can be used to implement an iterative\npermutation group decoder (SPA-PD)--one of the most successful iterative\nsoft-decision decoding strategies at small blocklengths. In this work, we\nexploit the fact that ELC can also give structurally distinct parity-check\nmatrices for the same code. Our aim is to describe a simple iterative decoder,\nrunning SPA-PD on distinct structures, based entirely on random usage of the\nELC operation. This is called SPA-ELC, and we focus on small blocklength codes\nwith strong algebraic structure. In particular, we look at the extended Golay\ncode and two extended quadratic residue codes. Both error rate performance and\naverage decoding complexity, measured by the average total number of messages\nrequired in the decoding, significantly outperform those of the standard SPA,\nand compares well with SPA-PD. However, in contrast to SPA-PD, which requires a\nglobal action on the Tanner graph, we obtain a performance improvement via\nlocal action alone. Such localized algorithms are of mathematical interest in\ntheir own right, but are also suited to parallel/distributed realizations. \n\n"}
{"id": "0906.0037", "contents": "Title: Asymptotic Capacity and Optimal Precoding in MIMO Multi-Hop Relay\n  Networks Abstract: A multi-hop relaying system is analyzed where data sent by a multi-antenna\nsource is relayed by successive multi-antenna relays until it reaches a\nmulti-antenna destination. Assuming correlated fading at each hop, each relay\nreceives a faded version of the signal from the previous level, performs linear\nprecoding and retransmits it to the next level. Using free probability theory\nand assuming that the noise power at relaying levels-- but not at destination--\nis negligible, the closed-form expression of the asymptotic instantaneous\nend-to-end mutual information is derived as the number of antennas at all\nlevels grows large. The so-obtained deterministic expression is independent\nfrom the channel realizations while depending only on channel statistics.\nMoreover, it also serves as the asymptotic value of the average end-to-end\nmutual information. The optimal singular vectors of the precoding matrices that\nmaximize the average mutual information with finite number of antennas at all\nlevels are also provided. It turns out that the optimal precoding singular\nvectors are aligned to the eigenvectors of the channel correlation matrices.\nThus they can be determined using only the known channel statistics. As the\noptimal precoding singular vectors are independent from the system size, they\nare also optimal in the asymptotic regime. \n\n"}
{"id": "0906.3736", "contents": "Title: Weight Optimization for Consensus Algorithms with Correlated Switching\n  Topology Abstract: We design the weights in consensus algorithms with spatially correlated\nrandom topologies. These arise with: 1) networks with spatially correlated\nrandom link failures and 2) networks with randomized averaging protocols. We\nshow that the weight optimization problem is convex for both symmetric and\nasymmetric random graphs. With symmetric random networks, we choose the\nconsensus mean squared error (MSE) convergence rate as optimization criterion\nand explicitly express this rate as a function of the link formation\nprobabilities, the link formation spatial correlations, and the consensus\nweights. We prove that the MSE convergence rate is a convex, nonsmooth function\nof the weights, enabling global optimization of the weights for arbitrary link\nformation probabilities and link correlation structures. We extend our results\nto the case of asymmetric random links. We adopt as optimization criterion the\nmean squared deviation (MSdev) of the nodes states from the current average\nstate. We prove that MSdev is a convex function of the weights. Simulations\nshow that significant performance gain is achieved with our weight design\nmethod when compared with methods available in the literature. \n\n"}
{"id": "0906.5394", "contents": "Title: Wireless Network Information Flow: A Deterministic Approach Abstract: In a wireless network with a single source and a single destination and an\narbitrary number of relay nodes, what is the maximum rate of information flow\nachievable? We make progress on this long standing problem through a two-step\napproach. First we propose a deterministic channel model which captures the key\nwireless properties of signal strength, broadcast and superposition. We obtain\nan exact characterization of the capacity of a network with nodes connected by\nsuch deterministic channels. This result is a natural generalization of the\ncelebrated max-flow min-cut theorem for wired networks. Second, we use the\ninsights obtained from the deterministic analysis to design a new\nquantize-map-and-forward scheme for Gaussian networks. In this scheme, each\nrelay quantizes the received signal at the noise level and maps it to a random\nGaussian codeword for forwarding, and the final destination decodes the\nsource's message based on the received signal. We show that, in contrast to\nexisting schemes, this scheme can achieve the cut-set upper bound to within a\ngap which is independent of the channel parameters. In the case of the relay\nchannel with a single relay as well as the two-relay Gaussian diamond network,\nthe gap is 1 bit/s/Hz. Moreover, the scheme is universal in the sense that the\nrelays need no knowledge of the values of the channel parameters to\n(approximately) achieve the rate supportable by the network. We also present\nextensions of the results to multicast networks, half-duplex networks and\nergodic networks. \n\n"}
{"id": "0907.1523", "contents": "Title: Theoretical Performance Analysis of Eigenvalue-based Detection Abstract: In this paper we develop a complete analytical framework based on Random\nMatrix Theory for the performance evaluation of Eigenvalue-based Detection.\nWhile, up to now, analysis was limited to false-alarm probability, we have\nobtained an analytical expression also for the probability of missed detection,\nby using the theory of spiked population models. A general scenario with\nmultiple signals present at the same time is considered. The theoretical\nresults of this paper allow to predict the error probabilities, and to set the\ndecision threshold accordingly, by means of a few mathematical formulae. In\nthis way the design of an eigenvalue-based detector is made conceptually\nidentical to that of a traditional energy detector. As additional results, the\npaper discusses the conditions of signal identifiability for single and\nmultiple sources. All the analytical results are validated through numerical\nsimulations, covering also convergence, identifiabilty and non-Gaussian\npractical modulations. \n\n"}
{"id": "0907.3666", "contents": "Title: Various thresholds for $\\ell_1$-optimization in compressed sensing Abstract: Recently, \\cite{CRT,DonohoPol} theoretically analyzed the success of a\npolynomial $\\ell_1$-optimization algorithm in solving an under-determined\nsystem of linear equations. In a large dimensional and statistical context\n\\cite{CRT,DonohoPol} proved that if the number of equations (measurements in\nthe compressed sensing terminology) in the system is proportional to the length\nof the unknown vector then there is a sparsity (number of non-zero elements of\nthe unknown vector) also proportional to the length of the unknown vector such\nthat $\\ell_1$-optimization succeeds in solving the system. In this paper, we\nprovide an alternative performance analysis of $\\ell_1$-optimization and obtain\nthe proportionality constants that in certain cases match or improve on the\nbest currently known ones from \\cite{DonohoPol,DT}. \n\n"}
{"id": "0908.1457", "contents": "Title: General Scheme for Perfect Quantum Network Coding with Free Classical\n  Communication Abstract: This paper considers the problem of efficiently transmitting quantum states\nthrough a network. It has been known for some time that without additional\nassumptions it is impossible to achieve this task perfectly in general --\nindeed, it is impossible even for the simple butterfly network. As additional\nresource we allow free classical communication between any pair of network\nnodes. It is shown that perfect quantum network coding is achievable in this\nmodel whenever classical network coding is possible over the same network when\nreplacing all quantum capacities by classical capacities. More precisely, it is\nproved that perfect quantum network coding using free classical communication\nis possible over a network with $k$ source-target pairs if there exists a\nclassical linear (or even vector linear) coding scheme over a finite ring. Our\nproof is constructive in that we give explicit quantum coding operations for\neach network node. This paper also gives an upper bound on the number of\nclassical communication required in terms of $k$, the maximal fan-in of any\nnetwork node, and the size of the network. \n\n"}
{"id": "0908.2676", "contents": "Title: Deterministic Construction of Binary, Bipolar and Ternary Compressed\n  Sensing Matrices Abstract: In this paper we establish the connection between the Orthogonal Optical\nCodes (OOC) and binary compressed sensing matrices. We also introduce\ndeterministic bipolar $m\\times n$ RIP fulfilling $\\pm 1$ matrices of order $k$\nsuch that $m\\leq\\mathcal{O}\\big(k (\\log_2 n)^{\\frac{\\log_2 k}{\\ln \\log_2\nk}}\\big)$. The columns of these matrices are binary BCH code vectors where the\nzeros are replaced by -1. Since the RIP is established by means of coherence,\nthe simple greedy algorithms such as Matching Pursuit are able to recover the\nsparse solution from the noiseless samples. Due to the cyclic property of the\nBCH codes, we show that the FFT algorithm can be employed in the reconstruction\nmethods to considerably reduce the computational complexity. In addition, we\ncombine the binary and bipolar matrices to form ternary sensing matrices\n($\\{0,1,-1\\}$ elements) that satisfy the RIP condition. \n\n"}
{"id": "0908.3562", "contents": "Title: Another Look at the Physics of Large Deviations With Application to\n  Rate-Distortion Theory Abstract: We revisit and extend the physical interpretation recently given to a certain\nidentity between large--deviations rate--functions (as well as applications of\nthis identity to Information Theory), as an instance of thermal equilibrium\nbetween several physical systems that are brought into contact. Our new\ninterpretation, of mechanical equilibrium between these systems, is shown to\nhave several advantages relative to that of thermal equilibrium. This physical\npoint of view also provides a trigger to the development of certain alternative\nrepresentations of the rate--distortion function and channel capacity, which\nare new to the best knowledge of the author. \n\n"}
{"id": "0908.4208", "contents": "Title: Performance Analysis over Slow Fading Channels of a Half-Duplex\n  Single-Relay Protocol: Decode or Quantize and Forward Abstract: In this work, a new static relaying protocol is introduced for half duplex\nsingle-relay networks, and its performance is studied in the context of\ncommunications over slow fading wireless channels. The proposed protocol is\nbased on a Decode or Quantize and Forward (DoQF) approach. In slow fading\nscenarios, two performance metrics are relevant and complementary, namely the\noutage probability gain and the Diversity-Multiplexing Tradeoff (DMT).\n  First, we analyze the behavior of the outage probability P_o associated with\nthe proposed protocol as the SNR tends to infinity. In this case, we prove that\nSNR^2 P_o converges to a constant. We refer to this constant as the outage gain\nand we derive its closed-form expression for a general class of wireless\nchannels that includes the Rayleigh and the Rice channels as particular cases.\nWe furthermore prove that the DoQF protocol has the best achievable outage gain\nin the wide class of half-duplex static relaying protocols. A method for\nminimizing the outage gain with respect to the power distribution between the\nsource and the relay, and with respect to the durations of the slots is also\nprovided.\n  Next, we focus on Rayleigh distributed fading channels to derive the DMT\nassociated with the proposed DoQF protocol. Our results show that the DMT of\nDoQF achieves the 2 by 1 MISO upper-bound for multiplexing gains r < 0.25. \n\n"}
{"id": "0909.0588", "contents": "Title: Receding horizon decoding of convolutional codes Abstract: Decoding of convolutional codes poses a significant challenge for coding\ntheory. Classical methods, based on e.g. Viterbi decoding, suffer from being\ncomputationally expensive and are restricted therefore to codes of small\ncomplexity. Based on analogies with model predictive optimal control, we\npropose a new iterative method for convolutional decoding that is cheaper to\nimplement than established algorithms, while still offering significant error\ncorrection capabilities. The algorithm is particularly well-suited for decoding\nspecial types of convolutional codes, such as e.g. cyclic convolutional codes. \n\n"}
{"id": "0909.2622", "contents": "Title: Transmitter Optimization for Achieving Secrecy Capacity in Gaussian MIMO\n  Wiretap Channels Abstract: We consider a Gaussian multiple-input multiple-output (MIMO) wiretap channel\nmodel, where there exists a transmitter, a legitimate receiver and an\neavesdropper, each node equipped with multiple antennas. We study the problem\nof finding the optimal input covariance matrix that achieves secrecy capacity\nsubject to a power constraint, which leads to a non-convex optimization problem\nthat is in general difficult to solve. Existing results for this problem\naddress the case in which the transmitter and the legitimate receiver have two\nantennas each and the eavesdropper has one antenna. For the general cases, it\nhas been shown that the optimal input covariance matrix has low rank when the\ndifference between the Grams of the eavesdropper and the legitimate receiver\nchannel matrices is indefinite or semi-definite, while it may have low rank or\nfull rank when the difference is positive definite. In this paper, the\naforementioned non-convex optimization problem is investigated. In particular,\nfor the multiple-input single-output (MISO) wiretap channel, the optimal input\ncovariance matrix is obtained in closed form. For general cases, we derive the\nnecessary conditions for the optimal input covariance matrix consisting of a\nset of equations. For the case in which the transmitter has two antennas, the\nderived necessary conditions can result in a closed form solution; For the case\nin which the difference between the Grams is indefinite and has all negative\neigenvalues except one positive eigenvalue, the optimal input covariance matrix\nhas rank one and can be obtained in closed form; For other cases, the solution\nis proved to be a fixed point of a mapping from a convex set to itself and an\niterative procedure is provided to search for it. Numerical results are\npresented to illustrate the proposed theoretical findings. \n\n"}
{"id": "0909.3392", "contents": "Title: On the communication complexity of XOR functions Abstract: An XOR function is a function of the form g(x,y) = f(x + y), for some boolean\nfunction f on n bits. We study the quantum and classical communication\ncomplexity of XOR functions. In the case of exact protocols, we completely\ncharacterise one-way communication complexity for all f. We also show that,\nwhen f is monotone, g's quantum and classical complexities are quadratically\nrelated, and that when f is a linear threshold function, g's quantum complexity\nis Theta(n). More generally, we make a structural conjecture about the Fourier\nspectra of boolean functions which, if true, would imply that the quantum and\nclassical exact communication complexities of all XOR functions are\nasymptotically equivalent. We give two randomised classical protocols for\ngeneral XOR functions which are efficient for certain functions, and a third\nprotocol for linear threshold functions with high margin. These protocols\noperate in the symmetric message passing model with shared randomness. \n\n"}
{"id": "0909.4828", "contents": "Title: Optimal Feedback Communication via Posterior Matching Abstract: In this paper we introduce a fundamental principle for optimal communication\nover general memoryless channels in the presence of noiseless feedback, termed\nposterior matching. Using this principle, we devise a (simple, sequential)\ngeneric feedback transmission scheme suitable for a large class of memoryless\nchannels and input distributions, achieving any rate below the corresponding\nmutual information. This provides a unified framework for optimal feedback\ncommunication in which the Horstein scheme (BSC) and the Schalkwijk-Kailath\nscheme (AWGN channel) are special cases. Thus, as a corollary, we prove that\nthe Horstein scheme indeed attains the BSC capacity, settling a longstanding\nconjecture. We further provide closed form expressions for the error\nprobability of the scheme over a range of rates, and derive the achievable\nrates in a mismatch setting where the scheme is designed according to the wrong\nchannel model. Several illustrative examples of the posterior matching scheme\nfor specific channels are given, and the corresponding error probability\nexpressions are evaluated. The proof techniques employed utilize novel\nrelations between information rates and contraction properties of iterated\nfunction systems. \n\n"}
{"id": "0909.5457", "contents": "Title: Guaranteed Rank Minimization via Singular Value Projection Abstract: Minimizing the rank of a matrix subject to affine constraints is a\nfundamental problem with many important applications in machine learning and\nstatistics. In this paper we propose a simple and fast algorithm SVP (Singular\nValue Projection) for rank minimization with affine constraints (ARMP) and show\nthat SVP recovers the minimum rank solution for affine constraints that satisfy\nthe \"restricted isometry property\" and show robustness of our method to noise.\nOur results improve upon a recent breakthrough by Recht, Fazel and Parillo\n(RFP07) and Lee and Bresler (LB09) in three significant ways:\n  1) our method (SVP) is significantly simpler to analyze and easier to\nimplement,\n  2) we give recovery guarantees under strictly weaker isometry assumptions\n  3) we give geometric convergence guarantees for SVP even in presense of noise\nand, as demonstrated empirically, SVP is significantly faster on real-world and\nsynthetic problems.\n  In addition, we address the practically important problem of low-rank matrix\ncompletion (MCP), which can be seen as a special case of ARMP. We empirically\ndemonstrate that our algorithm recovers low-rank incoherent matrices from an\nalmost optimal number of uniformly sampled entries. We make partial progress\ntowards proving exact recovery and provide some intuition for the strong\nperformance of SVP applied to matrix completion by showing a more restricted\nisometry property. Our algorithm outperforms existing methods, such as those of\n\\cite{RFP07,CR08,CT09,CCS08,KOM09,LB09}, for ARMP and the matrix-completion\nproblem by an order of magnitude and is also significantly more robust to\nnoise. \n\n"}
{"id": "0910.1511", "contents": "Title: Cooperation with an Untrusted Relay: A Secrecy Perspective Abstract: We consider the communication scenario where a source-destination pair wishes\nto keep the information secret from a relay node despite wanting to enlist its\nhelp. For this scenario, an interesting question is whether the relay node\nshould be deployed at all. That is, whether cooperation with an untrusted relay\nnode can ever be beneficial. We first provide an achievable secrecy rate for\nthe general untrusted relay channel, and proceed to investigate this question\nfor two types of relay networks with orthogonal components. For the first\nmodel, there is an orthogonal link from the source to the relay. For the second\nmodel, there is an orthogonal link from the relay to the destination. For the\nfirst model, we find the equivocation capacity region and show that answer is\nnegative. In contrast, for the second model, we find that the answer is\npositive. Specifically, we show by means of the achievable secrecy rate based\non compress-and-forward, that, by asking the untrusted relay node to relay\ninformation, we can achieve a higher secrecy rate than just treating the relay\nas an eavesdropper. For a special class of the second model, where the relay is\nnot interfering itself, we derive an upper bound for the secrecy rate using an\nargument whose net effect is to separate the eavesdropper from the relay. The\nmerit of the new upper bound is demonstrated on two channels that belong to\nthis special class. The Gaussian case of the second model mentioned above\nbenefits from this approach in that the new upper bound improves the previously\nknown bounds. For the Cover-Kim deterministic relay channel, the new upper\nbound finds the secrecy capacity when the source-destination link is not worse\nthan the source-relay link, by matching with the achievable rate we present. \n\n"}
{"id": "0910.2066", "contents": "Title: A Lossless Fuzzy Binary AND/OR Compressor Abstract: In this report, a new fuzzy 2bit-AND parallel-to-OR, or simply, a fuzzy\nbinary AND/OR (FBAR) text data compression model as an algorithm is suggested\nfor bettering spatial locality limits on nodes during database transactions.\nThe current model incorporates a four-layer application technique:\nstring-to-AND/OR pairwise binary bit + fuzzy quantum with noise conversions.\nThis technique promotes a lossless data compression ratio of 2:1 up to values\napproximately = 3:1, generating a spatially-efficient compressed data file\ncompared to nowadays data compressors. Data decompression/specific data\nreconstruction initiates an AND/OR pattern match technique in respect of fuzzy\nquantum indicators in the binary function field. The reconstruction of data\noccurs in the 4th layer using encryption methods. It is hypothesized that\nsignificant data compression ratio of 2n:1 for n>3:1 ratios, e.g., 32~64:1 are\nachievable via fuzzy qubit indexing over classical byte blocks for every bit\nposition fragmented into a (1/2 upper +1/2 lower)-bit noise frequency parallel\nto its counterpart signal comprised of AND/ORed-bit polarity orientation, ready\nfor an identical data decompression. \n\n"}
{"id": "0911.2346", "contents": "Title: Asymmetric Multilevel Diversity Coding and Asymmetric Gaussian Multiple\n  Descriptions Abstract: We consider the asymmetric multilevel diversity (A-MLD) coding problem, where\na set of $2^K-1$ information sources, ordered in a decreasing level of\nimportance, is encoded into $K$ messages (or descriptions). There are $2^K-1$\ndecoders, each of which has access to a non-empty subset of the encoded\nmessages. Each decoder is required to reproduce the information sources up to a\ncertain importance level depending on the combination of descriptions available\nto it. We obtain a single letter characterization of the achievable rate region\nfor the 3-description problem. In contrast to symmetric multilevel diversity\ncoding, source-separation coding is not sufficient in the asymmetric case, and\nideas akin to network coding need to be used strategically. Based on the\nintuitions gained in treating the A-MLD problem, we derive inner and outer\nbounds for the rate region of the asymmetric Gaussian multiple description (MD)\nproblem with three descriptions. Both the inner and outer bounds have a similar\ngeometric structure to the rate region template of the A-MLD coding problem,\nand moreover, we show that the gap between them is small, which results in an\napproximate characterization of the asymmetric Gaussian three description rate\nregion. \n\n"}
{"id": "0911.3256", "contents": "Title: Enumerative Coding for Grassmannian Space Abstract: The Grassmannian space $\\Gr$ is the set of all $k-$dimensional subspaces of\nthe vector space~\\smash{$\\F_q^n$}. Recently, codes in the Grassmannian have\nfound an application in network coding. The main goal of this paper is to\npresent efficient enumerative encoding and decoding techniques for the\nGrassmannian. These coding techniques are based on two different orders for the\nGrassmannian induced by different representations of $k$-dimensional subspaces\nof $\\F_q^n$. One enumerative coding method is based on a Ferrers diagram\nrepresentation and on an order for $\\Gr$ based on this representation. The\ncomplexity of this enumerative coding is $O(k^{5/2} (n-k)^{5/2})$ digit\noperations. Another order of the Grassmannian is based on a combination of an\nidentifying vector and a reduced row echelon form representation of subspaces.\nThe complexity of the enumerative coding, based on this order, is\n$O(nk(n-k)\\log n\\log\\log n)$ digits operations. A combination of the two\nmethods reduces the complexity on average by a constant factor. \n\n"}
{"id": "0911.4530", "contents": "Title: MIMO Z-Interference Channels: Capacity Under Strong and Noisy\n  Interference Abstract: The capacity regions of multiple-input multiple-output Gaussian\nZ-interference channels are established for the very strong interference and\naligned strong interference cases. The sum-rate capacity of such channels is\nestablished under noisy interference. These results generalize known results\nfor scalar Gaussian Z-interference channels. \n\n"}
{"id": "0911.4880", "contents": "Title: An Estimation Theoretic Approach for Sparsity Pattern Recovery in the\n  Noisy Setting Abstract: Compressed sensing deals with the reconstruction of sparse signals using a\nsmall number of linear measurements. One of the main challenges in compressed\nsensing is to find the support of a sparse signal. In the literature, several\nbounds on the scaling law of the number of measurements for successful support\nrecovery have been derived where the main focus is on random Gaussian\nmeasurement matrices. In this paper, we investigate the noisy support recovery\nproblem from an estimation theoretic point of view, where no specific\nassumption is made on the underlying measurement matrix. The linear\nmeasurements are perturbed by additive white Gaussian noise. We define the\noutput of a support estimator to be a set of position values in increasing\norder. We set the error between the true and estimated supports as the\n$\\ell_2$-norm of their difference. On the one hand, this choice allows us to\nuse the machinery behind the $\\ell_2$-norm error metric and on the other hand,\nconverts the support recovery into a more intuitive and geometrical problem.\nFirst, by using the Hammersley-Chapman-Robbins (HCR) bound, we derive a\nfundamental lower bound on the performance of any \\emph{unbiased} estimator of\nthe support set. This lower bound provides us with necessary conditions on the\nnumber of measurements for reliable $\\ell_2$-norm support recovery, which we\nspecifically evaluate for uniform Gaussian measurement matrices. Then, we\nanalyze the maximum likelihood estimator and derive conditions under which the\nHCR bound is achievable. This leads us to the number of measurements for the\noptimum decoder which is sufficient for reliable $\\ell_2$-norm support\nrecovery. Using this framework, we specifically evaluate sufficient conditions\nfor uniform Gaussian measurement matrices. \n\n"}
{"id": "0911.5508", "contents": "Title: Codes on graphs: Duality and MacWilliams identities Abstract: A conceptual framework involving partition functions of normal factor graphs\nis introduced, paralleling a similar recent development by Al-Bashabsheh and\nMao. The partition functions of dual normal factor graphs are shown to be a\nFourier transform pair, whether or not the graphs have cycles. The original\nnormal graph duality theorem follows as a corollary. Within this framework,\nMacWilliams identities are found for various local and global weight generating\nfunctions of general group or linear codes on graphs; this generalizes and\nprovides a concise proof of the MacWilliams identity for linear time-invariant\nconvolutional codes that was recently found by Gluesing-Luerssen and Schneider.\nFurther MacWilliams identities are developed for terminated convolutional\ncodes, particularly for tail-biting codes, similar to those studied recently by\nBocharova, Hug, Johannesson and Kudryashov. \n\n"}
{"id": "0912.0597", "contents": "Title: Constructing Optimal Authentication Codes with Perfect Multi-fold\n  Secrecy Abstract: We establish a construction of optimal authentication codes achieving perfect\nmulti-fold secrecy by means of combinatorial designs. This continues the\nauthor's work (ISIT 2009) and answers an open question posed therein. As an\napplication, we present the first infinite class of optimal codes that provide\ntwo-fold security against spoofing attacks and at the same time perfect two-\nfold secrecy. \n\n"}
{"id": "0912.1790", "contents": "Title: A Note on the Injection Distance Abstract: Koetter and Kschischang showed in [R. Koetter and F.R. Kschischang, \"Coding\nfor Errors and Erasures in Random Network Coding,\" IEEE Trans. Inform. Theory,\n{54(8), 2008] that the network coding counterpart of Gabidulin codes performs\nasymptotically optimal with respect to the subspace distance. Recently, Silva\nand Kschischang introduced in [D. Silva and F.R. Kschischang, \"On Metrics for\nError Correction in Network Coding,\" To appear in IEEE Trans. Inform. Theory,\nArXiv: 0805.3824v4[cs.IT], 2009] the injection distance to give a detailed\npicture of what happens in noncoherent network coding. We show that the above\ncodes are also asymptotically optimal with respect to this distance. \n\n"}
{"id": "0912.3245", "contents": "Title: Structured Error Recovery for Codeword-Stabilized Quantum Codes Abstract: Codeword stabilized (CWS) codes are, in general, non-additive quantum codes\nthat can correct errors by an exhaustive search of different error patterns,\nsimilar to the way that we decode classical non-linear codes. For an n-qubit\nquantum code correcting errors on up to t qubits, this brute-force approach\nconsecutively tests different errors of weight t or less, and employs a\nseparate n-qubit measurement in each test. In this paper, we suggest an error\ngrouping technique that allows to simultaneously test large groups of errors in\na single measurement. This structured error recovery technique exponentially\nreduces the number of measurements by about 3^t times. While it still leaves\nexponentially many measurements for a generic CWS code, the technique is\nequivalent to syndrome-based recovery for the special case of additive CWS\ncodes. \n\n"}
{"id": "0912.3981", "contents": "Title: Multiplexing Gain of Amplify-Forward Relaying in Wireless Multi-Antenna\n  Relay Networks Abstract: This paper studies the general multi-antenna multiple-relay network. Every\ntwo nodes of the network are either connected together through a Rayleigh\nfading channel or disconnected. We study the ergodic capacity of the network in\nthe high SNR regime. We prove that the traditional amplify-forward relaying\nachieves the maximum multiplexing gain of the network. Furthermore, we show\nthat the maximum multiplexing gain of the network is equal to the minimum\nvertex cut-set of the underlying graph of the network, which can be computed in\npolynomial time in terms of the number of network nodes. Finally, the argument\nis extended to the multicast and multi-access scenarios. \n\n"}
{"id": "0912.4995", "contents": "Title: 1-State Error-Trellis Decoding of LDPC Convolutional Codes Based on\n  Circulant Matrices Abstract: We consider the decoding of convolutional codes using an error trellis\nconstructed based on a submatrix of a given check matrix. In the proposed\nmethod, the syndrome-subsequence computed using the remaining submatrix is\nutilized as auxiliary information for decoding. Then the ML error path is\ncorrectly decoded using the degenerate error trellis. We also show that the\ndecoding complexity of the proposed method is basically identical with that of\nthe conventional one based on the original error trellis. Next, we apply the\nmethod to check matrices with monomial entries proposed by Tanner et al. By\nchoosing any row of the check matrix as the submatrix for error-trellis\nconstruction, a 1-state error trellis is obtained. Noting the fact that a\nlikelihood-concentration on the all-zero state and the states with many 0's\noccurs in the error trellis, we present a simplified decoding method based on a\n1-state error trellis, from which decoding-complexity reduction is realized. \n\n"}
{"id": "1001.0210", "contents": "Title: Achieving the Secrecy Capacity of Wiretap Channels Using Polar Codes Abstract: Suppose Alice wishes to send messages to Bob through a communication channel\nC_1, but her transmissions also reach an eavesdropper Eve through another\nchannel C_2. The goal is to design a coding scheme that makes it possible for\nAlice to communicate both reliably and securely. Reliability is measured in\nterms of Bob's probability of error in recovering the message, while security\nis measured in terms of Eve's equivocation ratio. Wyner showed that the\nsituation is characterized by a single constant C_s, called the secrecy\ncapacity, which has the following meaning: for all $\\epsilon > 0$, there exist\ncoding schemes of rate $R \\ge C_s - \\epsilon$ that asymptotically achieve both\nthe reliability and the security objectives. However, his proof of this result\nis based upon a nonconstructive random-coding argument. To date, despite a\nconsiderable research effort, the only case where we know how to construct\ncoding schemes that achieve secrecy capacity is when Eve's channel C_2 is an\nerasure channel, or a combinatorial variation thereof.\n  Polar codes were recently invented by Arikan; they approach the capacity of\nsymmetric binary-input discrete memoryless channels with low encoding and\ndecoding complexity. Herein, we use polar codes to construct a coding scheme\nthat achieves the secrecy capacity for a wide range of wiretap channels. Our\nconstruction works for any instantiation of the wiretap channel model, as long\nas both C_1 and C_2 are symmetric and binary-input, and C_2 is degraded with\nrespect to C_1. Moreover, we show how to modify our construction in order to\nprovide strong security, in the sense defined by Maurer, while still operating\nat a rate that approaches the secrecy capacity. In this case, we cannot\nguarantee that the reliability condition will be satisfied unless the main\nchannel C_1 is noiseless, although we believe it can be always satisfied in\npractice. \n\n"}
{"id": "1001.0723", "contents": "Title: MacWilliams Identities for Terminated Convolutional Codes Abstract: Shearer and McEliece [1977] showed that there is no MacWilliams identity for\nthe free distance spectra of orthogonal linear convolutional codes. We show\nthat on the other hand there does exist a MacWilliams identity between the\ngenerating functions of the weight distributions per unit time of a linear\nconvolutional code C and its orthogonal code C^\\perp, and that this\ndistribution is as useful as the free distance spectrum for estimating code\nperformance. These observations are similar to those made recently by\nBocharova, Hug, Johannesson and Kudryashov; however, we focus on terminating by\ntail-biting rather than by truncation. \n\n"}
{"id": "1001.1826", "contents": "Title: Threshold Saturation via Spatial Coupling: Why Convolutional LDPC\n  Ensembles Perform so well over the BEC Abstract: Convolutional LDPC ensembles, introduced by Felstrom and Zigangirov, have\nexcellent thresholds and these thresholds are rapidly increasing as a function\nof the average degree. Several variations on the basic theme have been proposed\nto date, all of which share the good performance characteristics of\nconvolutional LDPC ensembles. We describe the fundamental mechanism which\nexplains why \"convolutional-like\" or \"spatially coupled\" codes perform so well.\nIn essence, the spatial coupling of the individual code structure has the\neffect of increasing the belief-propagation (BP) threshold of the new ensemble\nto its maximum possible value, namely the maximum-a-posteriori (MAP) threshold\nof the underlying ensemble. For this reason we call this phenomenon \"threshold\nsaturation.\" This gives an entirely new way of approaching capacity. One\nsignificant advantage of such a construction is that one can create\ncapacity-approaching ensembles with an error correcting radius which is\nincreasing in the blocklength. Our proof makes use of the area theorem of the\nBP-EXIT curve and the connection between the MAP and BP threshold recently\npointed out by Measson, Montanari, Richardson, and Urbanke. Although we prove\nthe connection between the MAP and the BP threshold only for a very specific\nensemble and only for the binary erasure channel, empirically a threshold\nsaturation phenomenon occurs for a wide class of ensembles and channels. More\ngenerally, we conjecture that for a large range of graphical systems a similar\nsaturation of the \"dynamical\" threshold occurs once individual components are\ncoupled sufficiently strongly. This might give rise to improved algorithms as\nwell as to new techniques for analysis. \n\n"}
{"id": "1001.1873", "contents": "Title: Optimal incorporation of sparsity information by weighted $\\ell_1$\n  optimization Abstract: Compressed sensing of sparse sources can be improved by incorporating prior\nknowledge of the source. In this paper we demonstrate a method for optimal\nselection of weights in weighted $L_1$ norm minimization for a noiseless\nreconstruction model, and show the improvements in compression that can be\nachieved. \n\n"}
{"id": "1001.2421", "contents": "Title: Outage Efficient Strategies for Network MIMO with Partial CSIT Abstract: We consider a multi-cell MIMO downlink (network MIMO) where $B$ base-stations\n(BS) with $M$ antennas connected to a central station (CS) serve $K$\nsingle-antenna user terminals (UT). Although many works have shown the\npotential benefits of network MIMO, the conclusion critically depends on the\nunderlying assumptions such as channel state information at transmitters (CSIT)\nand backhaul links. In this paper, by focusing on the impact of partial CSIT,\nwe propose an outage-efficient strategy. Namely, with side information of all\nUT's messages and local CSIT, each BS applies zero-forcing (ZF) beamforming in\na distributed manner. For a small number of UTs ($K\\leq M$), the ZF beamforming\ncreates $K$ parallel MISO channels. Based on the statistical knowledge of these\nparallel channels, the CS performs a robust power allocation that\nsimultaneously minimizes the outage probability of all UTs and achieves a\ndiversity gain of $B(M-K+1)$ per UT. With a large number of UTs ($K \\geq M$),\nwe propose a so-called distributed diversity scheduling (DDS) scheme to select\na subset of $\\Ks$ UTs with limited backhaul communication. It is proved that\nDDS achieves a diversity gain of $B\\frac{K}{\\Ks}(M-\\Ks+1)$, which scales\noptimally with the number of cooperative BSs $B$ as well as UTs. Numerical\nresults confirm that even under realistic assumptions such as partial CSIT and\nlimited backhaul communications, network MIMO can offer high data rates with a\nsufficient reliability to individual UTs. \n\n"}
{"id": "1001.3717", "contents": "Title: Multistage Relaying Using Interference Networks Abstract: Wireless networks with multiple nodes that relay information from a source to\na destination are expected to be deployed in many applications. Therefore,\nunderstanding their design and performance under practical constraints is\nimportant. In this work, we propose and study three multihopping decode and\nforward (MDF) protocols for multistage half-duplex relay networks with no\ndirect link between the source and destination nodes. In all three protocols,\nwe assume no cooperation across relay nodes for encoding and decoding.\nNumerical evaluation in illustrative example networks and comparison with cheap\nrelay cut-set bounds for half-duplex networks show that the proposed MDF\nprotocols approach capacity in some ranges of channel gains. The main idea in\nthe design of the protocols is the use of coding in interference networks that\nare created in different states or modes of a half-duplex network. Our results\nsuggest that multistage half-duplex relaying with practical constraints on\ncooperation is comparable to point-to-point links and full-duplex relay\nnetworks, if there are multiple non-overlapping paths from source to\ndestination and if suitable coding is employed in interference network states. \n\n"}
{"id": "1001.5113", "contents": "Title: Worst Configurations (Instantons) for Compressed Sensing over Reals: a\n  Channel Coding Approach Abstract: We consider the Linear Programming (LP) solution of the Compressed Sensing\n(CS) problem over reals, also known as the Basis Pursuit (BasP) algorithm. The\nBasP allows interpretation as a channel-coding problem, and it guarantees\nerror-free reconstruction with a properly chosen measurement matrix and\nsufficiently sparse error vectors. In this manuscript, we examine how the BasP\nperforms on a given measurement matrix and develop an algorithm to discover the\nsparsest vectors for which the BasP fails. The resulting algorithm is a\ngeneralization of our previous results on finding the most probable\nerror-patterns degrading performance of a finite size Low-Density Parity-Check\n(LDPC) code in the error-floor regime. The BasP fails when its output is\ndifferent from the actual error-pattern. We design a CS-Instanton Search\nAlgorithm (ISA) generating a sparse vector, called a CS-instanton, such that\nthe BasP fails on the CS-instanton, while the BasP recovery is successful for\nany modification of the CS-instanton replacing a nonzero element by zero. We\nalso prove that, given a sufficiently dense random input for the error-vector,\nthe CS-ISA converges to an instanton in a small finite number of steps. The\nperformance of the CS-ISA is illustrated on a randomly generated $120\\times\n512$ matrix. For this example, the CS-ISA outputs the shortest instanton (error\nvector) pattern of length 11. \n\n"}
{"id": "1002.0777", "contents": "Title: Polar Codes for the m-User MAC Abstract: In this paper, polar codes for the $m$-user multiple access channel (MAC)\nwith binary inputs are constructed. It is shown that Ar{\\i}kan's polarization\ntechnique applied individually to each user transforms independent uses of a\n$m$-user binary input MAC into successive uses of extremal MACs. This\ntransformation has a number of desirable properties: (i) the `uniform sum rate'\nof the original MAC is preserved, (ii) the extremal MACs have uniform rate\nregions that are not only polymatroids but matroids and thus (iii) their\nuniform sum rate can be reached by each user transmitting either uncoded or\nfixed bits; in this sense they are easy to communicate over. A polar code can\nthen be constructed with an encoding and decoding complexity of $O(n \\log n)$\n(where $n$ is the block length), a block error probability of $o(\\exp(- n^{1/2\n- \\e}))$, and capable of achieving the uniform sum rate of any binary input MAC\nwith arbitrary many users. An application of this polar code construction to\ncommunicating on the AWGN channel is also discussed. \n\n"}
{"id": "1002.0852", "contents": "Title: High-Dimensional Matched Subspace Detection When Data are Missing Abstract: We consider the problem of deciding whether a highly incomplete signal lies\nwithin a given subspace. This problem, Matched Subspace Detection, is a\nclassical, well-studied problem when the signal is completely observed. High-\ndimensional testing problems in which it may be prohibitive or impossible to\nobtain a complete observation motivate this work. The signal is represented as\na vector in R^n, but we only observe m << n of its elements. We show that\nreliable detection is possible, under mild incoherence conditions, as long as m\nis slightly greater than the dimension of the subspace in question. \n\n"}
{"id": "1002.1436", "contents": "Title: Constant-Weight Gray Codes for Local Rank Modulation Abstract: We consider the local rank-modulation scheme in which a sliding window going\nover a sequence of real-valued variables induces a sequence of permutations.\nThe local rank-modulation, as a generalization of the rank-modulation scheme,\nhas been recently suggested as a way of storing information in flash memory.\n  We study constant-weight Gray codes for the local rank-modulation scheme in\norder to simulate conventional multi-level flash cells while retaining the\nbenefits of rank modulation. We provide necessary conditions for the existence\nof cyclic and cyclic optimal Gray codes. We then specifically study codes of\nweight 2 and upper bound their efficiency, thus proving that there are no such\nasymptotically-optimal cyclic codes. In contrast, we study codes of weight 3\nand efficiently construct codes which are asymptotically-optimal. \n\n"}
{"id": "1003.2782", "contents": "Title: Reduced ML-Decoding Complexity, Full-Rate STBCs for $2^a$ Transmit\n  Antenna Systems Abstract: For an $n_t$ transmit, $n_r$ receive antenna system ($n_t \\times n_r$\nsystem), a {\\it{full-rate}} space time block code (STBC) transmits $n_{min} =\nmin(n_t,n_r)$ complex symbols per channel use and in general, has an\nML-decoding complexity of the order of $M^{n_tn_{min}}$ (considering square\ndesigns), where $M$ is the constellation size. In this paper, a scheme to\nobtain a full-rate STBC for $2^a$ transmit antennas and any $n_r$, with reduced\nML-decoding complexity of the order of $M^{n_t(n_{min}-3/4)}$, is presented.\nThe weight matrices of the proposed STBC are obtained from the unitary matrix\nrepresentations of a Clifford Algebra. For any value of $n_r$, the proposed\ndesign offers a reduction from the full ML-decoding complexity by a factor of\n$M^{3n_t/4}}$. The well known Silver code for 2 transmit antennas is a special\ncase of the proposed scheme. Further, it is shown that the codes constructed\nusing the scheme have higher ergodic capacity than the well known punctured\nPerfect codes for $n_r < n_t$. Simulation results of the symbol error rates are\nshown for $8 \\times 2$ systems, where the comparison of the proposed code is\nwith the punctured Perfect code for 8 transmit antennas. The proposed code\nmatches the punctured perfect code in error performance, while having reduced\nML-decoding complexity and higher ergodic capacity. \n\n"}
{"id": "1003.2822", "contents": "Title: Innovation Rate Sampling of Pulse Streams with Application to Ultrasound\n  Imaging Abstract: Signals comprised of a stream of short pulses appear in many applications\nincluding bio-imaging and radar. The recent finite rate of innovation\nframework, has paved the way to low rate sampling of such pulses by noticing\nthat only a small number of parameters per unit time are needed to fully\ndescribe these signals. Unfortunately, for high rates of innovation, existing\nsampling schemes are numerically unstable. In this paper we propose a general\nsampling approach which leads to stable recovery even in the presence of many\npulses. We begin by deriving a condition on the sampling kernel which allows\nperfect reconstruction of periodic streams from the minimal number of samples.\nWe then design a compactly supported class of filters, satisfying this\ncondition. The periodic solution is extended to finite and infinite streams,\nand is shown to be numerically stable even for a large number of pulses. High\nnoise robustness is also demonstrated when the delays are sufficiently\nseparated. Finally, we process ultrasound imaging data using our techniques,\nand show that substantial rate reduction with respect to traditional ultrasound\nsampling schemes can be achieved. \n\n"}
{"id": "1003.3765", "contents": "Title: Design of Nested LDGM-LDPC Codes for Compress-and-Forward in Relay\n  Channel Abstract: A three terminal relay system with binary erasure channel (BEC) was\nconsidered, in which a source forwarded information to a destination with a\nrelay's \"assistance\". The nested LDGM (Low-density generator-matrix) -LDPC\n(low-density parity-check) was designed to realize Compress-and-forward (CF) at\nthe relay. LDGM coding compressed the received signals losslessly and LDPC\nrealized the binning for Slepian-Wolf coding. Firstly a practical coding scheme\nwas proposed to achieve the cut-set bound on the capacity of the system,\nemploying LDPC and Nested LDGM-LDPC codes at the source and relay respectively.\nThen, the degree distribution of LDGM and LDPC codes was optimized with a given\nrate bound, which ensured that the iterative belief propagation (BP) decoding\nalgorithm at the destination was convergent. Finally, simulations results show\nthat the performance achieved based on nested codes is very close to\nSlepian-Wolf theoretical limit. \n\n"}
{"id": "1003.4879", "contents": "Title: Large Constant Dimension Codes and Lexicodes Abstract: Constant dimension codes, with a prescribed minimum distance, have found\nrecently an application in network coding. All the codewords in such a code are\nsubspaces of $\\F_q^n$ with a given dimension. A computer search for large\nconstant dimension codes is usually inefficient since the search space domain\nis extremely large. Even so, we found that some constant dimension lexicodes\nare larger than other known codes. We show how to make the computer search more\nefficient. In this context we present a formula for the computation of the\ndistance between two subspaces, not necessarily of the same dimension. \n\n"}
{"id": "1004.2434", "contents": "Title: The Multi-way Relay Channel Abstract: The multiuser communication channel, in which multiple users exchange\ninformation with the help of a relay terminal, termed the multi-way relay\nchannel (mRC), is introduced. In this model, multiple interfering clusters of\nusers communicate simultaneously, where the users within the same cluster wish\nto exchange messages among themselves. It is assumed that the users cannot\nreceive each other's signals directly, and hence the relay terminal in this\nmodel is the enabler of communication. In particular, restricted encoders,\nwhich ignore the received channel output and use only the corresponding\nmessages for generating the channel input, are considered. Achievable rate\nregions and an outer bound are characterized for the Gaussian mRC, and their\ncomparison is presented in terms of exchange rates in a symmetric Gaussian\nnetwork scenario. It is shown that the compress-and-forward (CF) protocol\nachieves exchange rates within a constant bit offset of the exchange capacity\nindependent of the power constraints of the terminals in the network. A finite\nbit gap between the exchange rates achieved by the CF and the\namplify-and-forward (AF) protocols is also shown. The two special cases of the\nmRC, the full data exchange model, in which every user wants to receive\nmessages of all other users, and the pairwise data exchange model which\nconsists of multiple two-way relay channels, are investigated in detail. In\nparticular for the pairwise data exchange model, in addition to the proposed\nrandom coding based achievable schemes, a nested lattice coding based scheme is\nalso presented and is shown to achieve exchange rates within a constant bit gap\nof the exchange capacity. \n\n"}
{"id": "1004.5195", "contents": "Title: On Perfect Codes in the Johnson Graph Abstract: In this paper we consider the existence of nontrivial perfect codes in the\nJohnson graph J(n,w). We present combinatorial and number theory techniques to\nprovide necessary conditions for existence of such codes and reduce the range\nof parameters in which 1-perfect and 2-perfect codes may exist. \n\n"}
{"id": "1004.5421", "contents": "Title: Interference Mitigation through Limited Transmitter Cooperation Abstract: Interference limits performance in wireless networks, and cooperation among\nreceivers or transmitters can help mitigate interference by forming distributed\nMIMO systems. Earlier work shows how limited receiver cooperation helps\nmitigate interference. The scenario with transmitter cooperation, however, is\nmore difficult to tackle. In this paper we study the two-user Gaussian\ninterference channel with conferencing transmitters to make progress towards\nthis direction. We characterize the capacity region to within 6.5 bits/s/Hz,\nregardless of channel parameters. Based on the constant-to-optimality result,\nwe show that there is an interesting reciprocity between the scenario with\nconferencing transmitters and the scenario with conferencing receivers, and\ntheir capacity regions are within a constant gap to each other. Hence in the\ninterference-limited regime, the behavior of the benefit brought by transmitter\ncooperation is the same as that by receiver cooperation. \n\n"}
{"id": "1005.0117", "contents": "Title: On the Separation of Lossy Source-Network Coding and Channel Coding in\n  Wireline Networks Abstract: This paper proves the separation between source-network coding and channel\ncoding in networks of noisy, discrete, memoryless channels. We show that the\nset of achievable distortion matrices in delivering a family of dependent\nsources across such a network equals the set of achievable distortion matrices\nfor delivering the same sources across a distinct network which is built by\nreplacing each channel by a noiseless, point-to-point bit-pipe of the\ncorresponding capacity. Thus a code that applies source-network coding across\nlinks that are made almost lossless through the application of independent\nchannel coding across each link asymptotically achieves the optimal performance\nacross the network as a whole. \n\n"}
{"id": "1005.0167", "contents": "Title: A digital interface for Gaussian relay and interference networks:\n  Lifting codes from the discrete superposition model Abstract: For every Gaussian network, there exists a corresponding deterministic\nnetwork called the discrete superposition network. We show that this discrete\nsuperposition network provides a near-optimal digital interface for operating a\nclass consisting of many Gaussian networks in the sense that any code for the\ndiscrete superposition network can be naturally lifted to a corresponding code\nfor the Gaussian network, while achieving a rate that is no more than a\nconstant number of bits lesser than the rate it achieves for the discrete\nsuperposition network. This constant depends only on the number of nodes in the\nnetwork and not on the channel gains or SNR. Moreover the capacities of the two\nnetworks are within a constant of each other, again independent of channel\ngains and SNR. We show that the class of Gaussian networks for which this\ninterface property holds includes relay networks with a single\nsource-destination pair, interference networks, multicast networks, and the\ncounterparts of these networks with multiple transmit and receive antennas.\n  The code for the Gaussian relay network can be obtained from any code for the\ndiscrete superposition network simply by pruning it. This lifting scheme\nestablishes that the superposition model can indeed potentially serve as a\nstrong surrogate for designing codes for Gaussian relay networks.\n  We present similar results for the K x K Gaussian interference network, MIMO\nGaussian interference networks, MIMO Gaussian relay networks, and multicast\nnetworks, with the constant gap depending additionally on the number of\nantennas in case of MIMO networks. \n\n"}
{"id": "1005.1594", "contents": "Title: Channel State Feedback over the MIMO-MAC Abstract: We consider the problem of designing low latency and low complexity schemes\nfor channel state feedback over the MIMO-MAC (multiple-input multiple-output\nmultiple access channel). We develop a framework for analyzing this problem in\nterms of minimizing the MSE distortion, and come up with separated\nsource-channel schemes and joint source-channel schemes that perform better\nthan analog feedback. We also develop a strikingly simple code design based on\nscalar quantization and uncoded QAM modulation that achieves the theoretical\nasymptotic performance limit of the separated approach with very low complexity\nand latency, in the case of single-antenna users. \n\n"}
{"id": "1006.0619", "contents": "Title: Spectrum Sharing in Cognitive Radio with Quantized Channel Information Abstract: We consider a wideband spectrum sharing system where a secondary user can\nshare a number of orthogonal frequency bands where each band is licensed to an\nindividual primary user. We address the problem of optimum secondary transmit\npower allocation for its ergodic capacity maximization subject to an average\nsum (across the bands) transmit power constraint and individual average\ninterference constraints on the primary users. The major contribution of our\nwork lies in considering quantized channel state information (CSI)(for the\nvector channel space consisting of all secondary-to-secondary and\nsecondary-to-primary channels) at the secondary transmitter. It is assumed that\na band manager or a cognitive radio service provider has access to the full CSI\ninformation from the secondary and primary receivers and designs (offline) an\noptimal power codebook based on the statistical information (channel\ndistributions) of the channels and feeds back the index of the codebook to the\nsecondary transmitter for every channel realization in real-time, via a\ndelay-free noiseless limited feedback channel. A modified Generalized\nLloyds-type algorithm (GLA) is designed for deriving the optimal power\ncodebook. An approximate quantized power allocation (AQPA) algorithm is also\npresented, that performs very close to its GLA based counterpart for large\nnumber of feedback bits and is significantly faster. We also present an\nextension of the modified GLA based quantized power codebook design algorithm\nfor the case when the feedback channel is noisy. Numerical studies illustrate\nthat with only 3-4 bits of feedback, the modified GLA based algorithms provide\nsecondary ergodic capacity very close to that achieved by full CSI and with\nonly as little as 4 bits of feedback, AQPA provides a comparable performance,\nthus making it an attractive choice for practical implementation. \n\n"}
{"id": "1006.1426", "contents": "Title: Classification of delocalization power of global unitary operations in\n  terms of LOCC one-piece relocalization Abstract: We study how two pieces of localized quantum information can be delocalized\nacross a composite Hilbert space when a global unitary operation is applied. We\nclassify the delocalization power of global unitary operations on quantum\ninformation by investigating the possibility of relocalizing one piece of the\nquantum information without using any global quantum resource. We show that\none-piece relocalization is possible if and only if the global unitary\noperation is local unitary equivalent of a controlled-unitary operation. The\ndelocalization power turns out to reveal different aspect of the non-local\nproperties of global unitary operations characterized by their entangling\npower. \n\n"}
{"id": "1006.2565", "contents": "Title: State-Dependent Relay Channel with Private Messages with Partial Causal\n  and Non-Causal Channel State Information Abstract: In this paper, we introduce a discrete memoryless State-Dependent Relay\nChannel with Private Messages (SD-RCPM) as a generalization of the\nstate-dependent relay channel. We investigate two main cases: SD-RCPM with\nnon-causal Channel State Information (CSI), and SD-RCPM with causal CSI. In\neach case, it is assumed that partial CSI is available at the source and relay.\nFor non-causal case, we establish an achievable rate region using\nGel'fand-Pinsker type coding scheme at the nodes informed of CSI, and\nCompress-and-Forward (CF) scheme at the relay. Using Shannon's strategy and CF\nscheme, an achievable rate region for causal case is obtained. As an example,\nthe Gaussian version of SD-RCPM is considered, and an achievable rate region\nfor Gaussian SD-RCPM with non-causal perfect CSI only at the source, is\nderived. Providing numerical examples, we illustrate the comparison between\nachievable rate regions derived using CF and Decode-and-Forward (DF) schemes. \n\n"}
{"id": "1006.4386", "contents": "Title: Collaborative Relay Beamforming for Secrecy Abstract: In this paper, collaborative use of relays to form a beamforming system and\nprovide physical-layer security is investigated. In particular,\ndecode-and-forward (DF) and amplify-and-forward (AF) relay beamforming designs\nunder total and individual relay power constraints are studied with the goal of\nmaximizing the secrecy rates when perfect channel state information (CSI) is\navailable. In the DF scheme, the total power constraint leads to a closed-form\nsolution, and in this case, the optimal beamforming structure is identified in\nthe low and high signal-to-noise ratio (SNR) regimes. The beamforming design\nunder individual relay power constraints is formulated as an optimization\nproblem which is shown to be easily solved using two different approaches,\nnamely semidefinite programming and second-order cone programming. A simplified\nand suboptimal technique which reduces the computation complexity under\nindividual power constraints is also presented. In the AF scheme, not having\nanalytical solutions for the optimal beamforming design under both total and\nindividual power constraints, an iterative algorithm is proposed to numerically\nobtain the optimal beamforming structure and maximize the secrecy rates.\nFinally, robust beamforming designs in the presence of imperfect CSI are\ninvestigated for DF-based relay beamforming, and optimization frameworks are\nprovided \n\n"}
{"id": "1006.5271", "contents": "Title: Construction of Slepian-Wolf Source Code and Broadcast Channel Code\n  Based on Hash Property Abstract: The aim of this paper is to prove theorems for the Slepian-Wolf source coding\nand the broadcast channel coding (independent messages and no common message)\nbased on the the notion of a stronger version of the hash property for an\nensemble of functions. Since an ensemble of sparse matrices has a strong hash\nproperty, codes using sparse matrices can realize the achievable rate region.\nFurthermore, extensions to the multiple source coding and multiple output\nbroadcast channel coding are investigated. \n\n"}
{"id": "1006.5445", "contents": "Title: Technical Report: MIMO B-MAC Interference Network Optimization under\n  Rate Constraints by Polite Water-filling and Duality Abstract: We take two new approaches to design efficient algorithms for transmitter\noptimization under rate constraints to guarantee the Quality of Service in\ngeneral MIMO interference networks, named B-MAC Networks, which is a\ncombination of multiple interfering broadcast channels (BC) and multiaccess\nchannels (MAC). Two related optimization problems, maximizing the minimum of\nweighted rates under a sum-power constraint and minimizing the sum-power under\nrate constraints, are considered. The first approach takes advantage of\nexisting efficient algorithms for SINR problems by building a bridge between\nrate and SINR through the design of optimal mappings between them so that the\nproblems can be converted to SINR constraint problems. The approach can be\napplied to other optimization problems as well. The second approach employs\npolite water-filling, which is the optimal network version of water-filling\nthat we recently found. It replaces almost all generic optimization algorithms\ncurrently used for networks and reduces the complexity while demonstrating\nsuperior performance even in non-convex cases. Both centralized and distributed\nalgorithms are designed and the performance is analyzed in addition to numeric\nexamples. \n\n"}
{"id": "1007.1243", "contents": "Title: New Results on the Capacity of the Gaussian Cognitive Interference\n  Channel Abstract: The capacity of the two-user Gaussian cognitive interference channel, a\nvariation of the classical interference channel where one of the transmitters\nhas knowledge of both messages, is known in several parameter regimes but\nremains unknown in general. In this paper, we consider the following achievable\nscheme: the cognitive transmitter pre-codes its message against the\ninterference created at its intended receiver by the primary user, and the\ncognitive receiver only decodes its intended message, similar to the optimal\nscheme for \"weak interference\"; the primary decoder decodes both messages,\nsimilar to the optimal scheme for \"very strong interference\". Although the\ncognitive message is pre-coded against the primary message, by decoding it, the\nprimary receiver obtains information about its own message, thereby improving\nits rate. We show: (1) that this proposed scheme achieves capacity in what we\nterm the \"primary decodes cognitive\" regime, i.e., a subset of the \"strong\ninterference\" regime that is not included in the \"very strong interference\"\nregime for which capacity was known; (2) that this scheme is within one\nbit/s/Hz, or a factor two, of capacity for a much larger set of parameters,\nthus improving the best known constant gap result; (3) we provide insights into\nthe trade-off between interference pre-coding at the cognitive encoder and\ninterference decoding at the primary receiver based on the analysis of the\napproximate capacity results. \n\n"}
{"id": "1007.2827", "contents": "Title: Data processing theorems and the second law of thermodynamics Abstract: We draw relationships between the generalized data processing theorems of\nZakai and Ziv (1973 and 1975) and the dynamical version of the second law of\nthermodynamics, a.k.a. the Boltzmann H-Theorem, which asserts that the Shannon\nentropy, $H(X_t)$, pertaining to a finite--state Markov process $\\{X_t\\}$, is\nmonotonically non-decreasing as a function of time $t$, provided that the\nsteady-state distribution of this process is uniform across the state space\n(which is the case when the process designates an isolated system). It turns\nout that both the generalized data processing theorems and the Boltzmann\nH-Theorem can be viewed as special cases of a more general principle concerning\nthe monotonicity (in time) of a certain generalized information measure applied\nto a Markov process. This gives rise to a new look at the generalized data\nprocessing theorem, which suggests to exploit certain degrees of freedom that\nmay lead to better bounds, for a given choice of the convex function that\ndefines the generalized mutual information. \n\n"}
{"id": "1007.3384", "contents": "Title: Relative entropy via non-sequential recursive pair substitutions Abstract: The entropy of an ergodic source is the limit of properly rescaled 1-block\nentropies of sources obtained applying successive non-sequential recursive\npairs substitutions (see P. Grassberger 2002 ArXiv:physics/0207023 and D.\nBenedetto, E. Caglioti and D. Gabrielli 2006 Jour. Stat. Mech. Theo. Exp. 09\ndoi:10.1088/1742.-5468/2006/09/P09011). In this paper we prove that the cross\nentropy and the Kullback-Leibler divergence can be obtained in a similar way. \n\n"}
{"id": "1008.1284", "contents": "Title: Ideal forms of Coppersmith's theorem and Guruswami-Sudan list decoding Abstract: We develop a framework for solving polynomial equations with size constraints\non solutions. We obtain our results by showing how to apply a technique of\nCoppersmith for finding small solutions of polynomial equations modulo integers\nto analogous problems over polynomial rings, number fields, and function\nfields. This gives us a unified view of several problems arising naturally in\ncryptography, coding theory, and the study of lattices. We give (1) a\npolynomial-time algorithm for finding small solutions of polynomial equations\nmodulo ideals over algebraic number fields, (2) a faster variant of the\nGuruswami-Sudan algorithm for list decoding of Reed-Solomon codes, and (3) an\nalgorithm for list decoding of algebraic-geometric codes that handles both\nsingle-point and multi-point codes. Coppersmith's algorithm uses lattice basis\nreduction to find a short vector in a carefully constructed lattice; powerful\nanalogies from algebraic number theory allow us to identify the appropriate\nanalogue of a lattice in each application and provide efficient algorithms to\nfind a suitably short vector, thus allowing us to give completely parallel\nproofs of the above theorems. \n\n"}
{"id": "1008.3146", "contents": "Title: Exact Localization and Superresolution with Noisy Data and Random\n  Illumination Abstract: This paper studies the problem of exact localization of sparse (point or\nextended) objects with noisy data. The crux of the proposed approach consists\nof random illumination. Several recovery methods are analyzed: the Lasso, BPDN\nand the One-Step Thresholding (OST). For independent random probes, it is shown\nthat both recovery methods can localize exactly $s=\\cO(m)$, up to a logarithmic\nfactor, objects where $m$ is the number of data. Moreover, when the number of\nrandom probes is large the Lasso with random illumination has a performance\nguarantee for superresolution, beating the Rayleigh resolution limit. Numerical\nevidence confirms the predictions and indicates that the performance of the\nLasso is superior to that of the OST for the proposed set-up with random\nillumination. \n\n"}
{"id": "1008.3705", "contents": "Title: Techniques for Enhanced Physical-Layer Security Abstract: Information-theoretic security--widely accepted as the strictest notion of\nsecurity--relies on channel coding techniques that exploit the inherent\nrandomness of propagation channels to strengthen the security of communications\nsystems. Within this paradigm, we explore strategies to improve secure\nconnectivity in a wireless network. We first consider the intrinsically secure\ncommunications graph (iS-graph), a convenient representation of the links that\ncan be established with information-theoretic security on a large-scale\nnetwork. We then propose and characterize two techniques--sectorized\ntransmission and eavesdropper neutralization--which are shown to dramatically\nenhance the connectivity of the iS-graph. \n\n"}
{"id": "1009.0289", "contents": "Title: Direct spreading measures of Laguerre polynomials Abstract: The direct spreading measures of the Laguerre polynomials, which quantify the\ndistribution of its Rakhmanov probability density along the positive real line\nin various complementary and qualitatively different ways, are investigated.\nThese measures include the familiar root-mean-square or standard deviation and\nthe information-theoretic lengths of Fisher, Renyi and Shannon types. The\nFisher length is explicitly given. The Renyi length of order q (such that 2q is\na natural number) is also found in terms of the polynomials parameters by means\nof two error-free computing approaches; one makes use of the Lauricella\nfunctions, which is based on the Srivastava-Niukkanen linearization relation of\nLaguerre polynomials, and another one which utilizes the multivariate Bell\npolynomials of Combinatorics. The Shannon length cannot be exactly calculated\nbecause of its logarithmic-functional form, but its asymptotics is provided and\nsharp bounds are obtained by use of an information-theoretic optimization\nprocedure. Finally, all these spreading measures are mutually compared and\ncomputationally analyzed; in particular, it is found that the apparent\nquasi-linear relation between the Shannon length and the standard deviation\nbecomes rigorously linear only asymptotically (i.e. for n>>1). \n\n"}
{"id": "1009.5760", "contents": "Title: Secret Key Agreement from Vector Gaussian Sources by Rate Limited Public\n  Communication Abstract: We investigate the secret key agreement from correlated vector Gaussian\nsources in which the legitimate parties can use the public communication with\nlimited rate. For the class of protocols with the one-way public communication,\nwe show that the optimal trade-off between the rate of key generation and the\nrate of the public communication is characterized as an optimization problem of\na Gaussian random variable. The characterization is derived by using the\nenhancement technique introduced by Weingarten et.al. for MIMO Gaussian\nbroadcast channel. \n\n"}
{"id": "1009.6079", "contents": "Title: A Multi-Interference-Channel Matrix Pair Beamformer for CDMA Systems Abstract: Matrix pair beamformer (MPB) is a promising blind beamformer which exploits\nthe temporal signature of the signal of interest (SOI) to acquire its spatial\nstatistical information. It does not need any knowledge of directional\ninformation or training sequences. However, the major problem of the existing\nMPBs is that they have serious threshold effects and the thresholds will grow\nas the interference power increases or even approach infinity. In particular,\nthis issue prevails in scenarios with structured interference, such as,\nperiodically repeated white noise, tones, or MAIs in multipath channels. In\nthis paper, we will first present the principles for designing the projection\nspace of the MPB which are closely correlated with the ability of suppressing\nstructured interference and system finite sample performance. Then a\nmultiple-interference-channel based matrix pair beamformer (MIC-MPB) for CDMA\nsystems is developed according to the principles. In order to adapt to dynamic\nchannels, an adaptive algorithm for the beamformer is also proposed.\nTheoretical analysis and simulation results show that the proposed beamformer\nhas a small and bounded threshold when the interference power increases.\nPerformance comparisons of the MIC-MPB and the existing MPBs in various\nscenarios via a number of numerical examples are also presented. \n\n"}
{"id": "1010.0316", "contents": "Title: Two-User Gaussian Interference Channel with Finite Constellation Input\n  and FDMA Abstract: In the two-user Gaussian Strong Interference Channel (GSIC) with finite\nconstellation inputs, it is known that relative rotation between the\nconstellations of the two users enlarges the Constellation Constrained (CC)\ncapacity region. In this paper, a metric for finding the approximate angle of\nrotation (with negligibly small error) to maximally enlarge the CC capacity for\nthe two-user GSIC is presented. In the case of Gaussian input alphabets with\nequal powers for both the users and the modulus of both the cross-channel gains\nbeing equal to unity, it is known that the FDMA rate curve touches the capacity\ncurve of the GSIC. It is shown that, with unequal powers for both the users\nalso, when the modulus of one of the cross-channel gains being equal to one and\nthe modulus of the other cross-channel gain being greater than or equal to one,\nthe FDMA rate curve touches the capacity curve of the GSIC. On the contrary, it\nis shown that, under finite constellation inputs, with both the users using the\nsame constellation, the FDMA rate curve strictly lies within (never touches)\nthe enlarged CC capacity region throughout the strong-interference regime. This\nmeans that using FDMA it is impossible to go close to the CC capacity. It is\nwell known that for the Gaussian input alphabets, the FDMA inner-bound, at the\noptimum sum-rate point, is always better than the simultaneous-decoding\ninner-bound throughout the weak-interference regime. For a portion of the weak\ninterference regime, it is shown that with identical finite constellation\ninputs for both the users, the simultaneous-decoding inner-bound, enlarged by\nrelative rotation between the constellations, is strictly better than the FDMA\ninner-bound. \n\n"}
{"id": "1010.1322", "contents": "Title: A New Upper Bound on the Average Error Exponent for Multiple-Access\n  Channels Abstract: A new lower bound for the average probability or error for a two-user\ndiscrete memoryless (DM) multiple-access channel (MAC) is derived. This bound\nhas a structure very similar to the well-known sphere packing packing bound\nderived by Haroutunian. However, since explicitly imposes independence of the\nusers' input distributions (conditioned on the time-sharing auxiliary variable)\nresults in a tighter sphere-packing exponent in comparison to Haroutunian's.\nAlso, the relationship between average and maximal error probabilities is\nstudied. Finally, by using a known sphere packing bound on the maximal\nprobability of error, a lower bound on the average error probability is\nderived. \n\n"}
{"id": "1010.1331", "contents": "Title: Improved Combinatorial Algorithms for Wireless Information Flow Abstract: The work of Avestimehr et al. '07 has recently proposed a deterministic model\nfor wireless networks and characterized the unicast capacity C of such networks\nas the minimum rank of the adjacency matrices describing all possible\nsource-destination cuts. Amaudruz & Fragouli first proposed a polynomial-time\nalgorithm for finding the unicast capacity of a linear deterministic wireless\nnetwork in their 2009 paper. In this work, we improve upon Amaudruz &\nFragouli's work and further reduce the computational complexity of the\nalgorithm by fully exploring the useful combinatorial features intrinsic in the\nproblem. Our improvement applies generally with any size of finite fields\nassociated with the channel model. Comparing with other algorithms on solving\nthe same problem, our improved algorithm is very competitive in terms of\ncomplexity. \n\n"}
{"id": "1010.2441", "contents": "Title: Note on Noisy Group Testing: Asymptotic Bounds and Belief Propagation\n  Reconstruction Abstract: An information theoretic perspective on group testing problems has recently\nbeen proposed by Atia and Saligrama, in order to characterise the optimal\nnumber of tests. Their results hold in the noiseless case, where only false\npositives occur, and where only false negatives occur. We extend their results\nto a model containing both false positives and false negatives, developing\nsimple information theoretic bounds on the number of tests required. Based on\nthese bounds, we obtain an improved order of convergence in the case of false\nnegatives only. Since these results are based on (computationally infeasible)\njoint typicality decoding, we propose a belief propagation algorithm for the\ndetection of defective items and compare its actual performance to the\ntheoretical bounds. \n\n"}
{"id": "1010.2831", "contents": "Title: On the Construction of Finite Oscillator Dictionary Abstract: A finite oscillator dictionary which has important applications in sequences\ndesigns and the compressive sensing was introduced by Gurevich, Hadani and\nSochen. In this paper, we first revisit closed formulae of the finite split\noscillator dictionary $\\mathfrak{S}^s$ by a simple proof. Then we study the\nnon-split tori of the group $SL(2,\\mathbb{F}_p)$. Finally, An explicit\nalgorithm for computing the finite non-split oscillator dictionary\n$\\mathfrak{S}^{ns}$ is described. \n\n"}
{"id": "1010.4751", "contents": "Title: Sparse coding and dictionary learning based on the MDL principle Abstract: The power of sparse signal coding with learned dictionaries has been\ndemonstrated in a variety of applications and fields, from signal processing to\nstatistical inference and machine learning. However, the statistical properties\nof these models, such as underfitting or overfitting given sets of data, are\nstill not well characterized in the literature. This work aims at filling this\ngap by means of the Minimum Description Length (MDL) principle -- a well\nestablished information-theoretic approach to statistical inference. The\nresulting framework derives a family of efficient sparse coding and modeling\n(dictionary learning) algorithms, which by virtue of the MDL principle, are\ncompletely parameter free. Furthermore, such framework allows to incorporate\nadditional prior information in the model, such as Markovian dependencies, in a\nnatural way. We demonstrate the performance of the proposed framework with\nresults for image denoising and classification tasks. \n\n"}
{"id": "1010.5416", "contents": "Title: Capacity of Fading Gaussian Channel with an Energy Harvesting Sensor\n  Node Abstract: Network life time maximization is becoming an important design goal in\nwireless sensor networks. Energy harvesting has recently become a preferred\nchoice for achieving this goal as it provides near perpetual operation. We\nstudy such a sensor node with an energy harvesting source and compare various\narchitectures by which the harvested energy is used. We find its Shannon\ncapacity when it is transmitting its observations over a fading AWGN channel\nwith perfect/no channel state information provided at the transmitter. We\nobtain an achievable rate when there are inefficiencies in energy storage and\nthe capacity when energy is spent in activities other than transmission. \n\n"}
{"id": "1011.1677", "contents": "Title: Convergence Rate Analysis of Distributed Gossip (Linear Parameter)\n  Estimation: Fundamental Limits and Tradeoffs Abstract: The paper considers gossip distributed estimation of a (static) distributed\nrandom field (a.k.a., large scale unknown parameter vector) observed by\nsparsely interconnected sensors, each of which only observes a small fraction\nof the field. We consider linear distributed estimators whose structure\ncombines the information \\emph{flow} among sensors (the \\emph{consensus} term\nresulting from the local gossiping exchange among sensors when they are able to\ncommunicate) and the information \\emph{gathering} measured by the sensors (the\n\\emph{sensing} or \\emph{innovations} term.) This leads to mixed time scale\nalgorithms--one time scale associated with the consensus and the other with the\ninnovations. The paper establishes a distributed observability condition\n(global observability plus mean connectedness) under which the distributed\nestimates are consistent and asymptotically normal. We introduce the\ndistributed notion equivalent to the (centralized) Fisher information rate,\nwhich is a bound on the mean square error reduction rate of any distributed\nestimator; we show that under the appropriate modeling and structural network\ncommunication conditions (gossip protocol) the distributed gossip estimator\nattains this distributed Fisher information rate, asymptotically achieving the\nperformance of the optimal centralized estimator. Finally, we study the\nbehavior of the distributed gossip estimator when the measurements fade (noise\nvariance grows) with time; in particular, we consider the maximum rate at which\nthe noise variance can grow and still the distributed estimator being\nconsistent, by showing that, as long as the centralized estimator is\nconsistent, the distributed estimator remains consistent. \n\n"}
{"id": "1011.3588", "contents": "Title: Distributed Interference Cancellation in Multiple Access Channels Abstract: In this paper, we consider a Gaussian multiple access channel with multiple\nindependent additive white Gaussian interferences. Each interference is known\nto exactly one transmitter non-causally. The capacity region is characterized\nto within a constant gap regardless of channel parameters. These results are\nbased on a layered modulo-lattice scheme which realizes distributed\ninterference cancellation. \n\n"}
{"id": "1011.3854", "contents": "Title: A probabilistic and RIPless theory of compressed sensing Abstract: This paper introduces a simple and very general theory of compressive\nsensing. In this theory, the sensing mechanism simply selects sensing vectors\nindependently at random from a probability distribution F; it includes all\nmodels - e.g. Gaussian, frequency measurements - discussed in the literature,\nbut also provides a framework for new measurement strategies as well. We prove\nthat if the probability distribution F obeys a simple incoherence property and\nan isotropy property, one can faithfully recover approximately sparse signals\nfrom a minimal number of noisy measurements. The novelty is that our recovery\nresults do not require the restricted isometry property (RIP) - they make use\nof a much weaker notion - or a random model for the signal. As an example, the\npaper shows that a signal with s nonzero entries can be faithfully recovered\nfrom about s log n Fourier coefficients that are contaminated with noise. \n\n"}
{"id": "1011.3867", "contents": "Title: Interference Alignment Through User Cooperation for Two-cell MIMO\n  Interfering Broadcast Channels Abstract: This paper focuses on two-cell multiple-input multiple-output (MIMO) Gaussian\ninterfering broadcast channels (MIMO-IFBC) with $K$ cooperating users on the\ncell-boundary of each BS. It corresponds to a downlink scenario for cellular\nnetworks with two base stations (BSs), and $K$ users equipped with Wi-Fi\ninterfaces enabling to cooperate among users on a peer-to-peer basis. In this\nscenario, we propose a novel interference alignment (IA) technique exploiting\nuser cooperation. Our proposed algorithm obtains the achievable degrees of\nfreedom (DoF) of 2K when each BS and user have $M=K+1$ transmit antennas and\n$N=K$ receive antennas, respectively. Furthermore, the algorithm requires only\na small amount of channel feedback information with the aid of the user\ncooperation channels. The simulations demonstrate that not only are the\nanalytical results valid, but the achievable DoF of our proposed algorithm also\noutperforms those of conventional techniques. \n\n"}
{"id": "1012.4161", "contents": "Title: Lattice Code Design for the Rayleigh Fading Wiretap Channel Abstract: It has been shown recently that coding for the Gaussian Wiretap Channel can\nbe done with nested lattices. A fine lattice intended to the legitimate user\nmust be designed as a usual lattice code for the Gaussian Channel, while a\ncoarse lattice is added to introduce confusion at the eavesdropper, whose theta\nseries must be minimized. We present a design criterion for both the fine and\ncoarse lattice to obtain wiretap lattice codes for the Rayleigh fading Wiretap\nChannel. \n\n"}
{"id": "1012.5041", "contents": "Title: Jensen divergence based on Fisher's information Abstract: The measure of Jensen-Fisher divergence between probability distributions is\nintroduced and its theoretical grounds set up. This quantity, in contrast to\nthe remaining Jensen divergences, is very sensitive to the fluctuations of the\nprobability distributions because it is controlled by the (local) Fisher\ninformation, which is a gradient functional of the distribution. So, it is\nappropriate and informative when studying the similarity of distributions,\nmainly for those having oscillatory character. The new Jensen-Fisher divergence\nshares with the Jensen-Shannon divergence the following properties:\nnon-negativity, additivity when applied to an arbitrary number of probability\ndensities, symmetry under exchange of these densities, vanishing if and only if\nall the densities are equal, and definiteness even when these densities present\nnon-common zeros. Moreover, the Jensen-Fisher divergence is shown to be\nexpressed in terms of the relative Fisher information as the Jensen-Shannon\ndivergence does in terms of the Kullback-Leibler or relative Shannon entropy.\nFinally the Jensen-Shannon and Jensen-Fisher divergences are compared for the\nfollowing three large, non-trivial and qualitatively different families of\nprobability distributions: the sinusoidal, generalized gamma-like and\nRakhmanov-Hermite distributions. \n\n"}
{"id": "1101.3285", "contents": "Title: A note on the multiple unicast capacity of directed acyclic networks Abstract: We consider the multiple unicast problem under network coding over directed\nacyclic networks with unit capacity edges. There is a set of n source-terminal\n(s_i - t_i) pairs that wish to communicate at unit rate over this network. The\nconnectivity between the s_i - t_i pairs is quantified by means of a\nconnectivity level vector, [k_1 k_2 ... k_n] such that there exist k_i\nedge-disjoint paths between s_i and t_i. Our main aim is to characterize the\nfeasibility of achieving this for different values of n and [k_1 ... k_n]. For\n3 unicast connections (n = 3), we characterize several achievable and\nunachievable values of the connectivity 3-tuple. In addition, in this work, we\nhave found certain network topologies, and capacity characterizations that are\nuseful in understanding the case of general n. \n\n"}
{"id": "1101.3824", "contents": "Title: Series Expansion for Interference in Wireless Networks Abstract: The spatial correlations in transmitter node locations introduced by common\nmultiple access protocols makes the analysis of interference, outage, and other\nrelated metrics in a wireless network extremely difficult. Most works therefore\nassume that nodes are distributed either as a Poisson point process (PPP) or a\ngrid, and utilize the independence properties of the PPP (or the regular\nstructure of the grid) to analyze interference, outage and other metrics.\nBut,the independence of node locations makes the PPP a dubious model for\nnontrivial MACs which intentionally introduce correlations, e.g. spatial\nseparation, while the grid is too idealized to model real networks. In this\npaper, we introduce a new technique based on the factorial moment expansion of\nfunctionals of point processes to analyze functions of interference, in\nparticular outage probability. We provide a Taylor-series type expansion of\nfunctions of interference, wherein increasing the number of terms in the series\nprovides a better approximation at the cost of increased complexity of\ncomputation. Various examples illustrate how this new approach can be used to\nfind outage probability in both Poisson and non-Poisson wireless networks. \n\n"}
{"id": "1101.4279", "contents": "Title: Low-Complexity Detection/Equalization in Large-Dimension MIMO-ISI\n  Channels Using Graphical Models Abstract: In this paper, we deal with low-complexity near-optimal\ndetection/equalization in large-dimension multiple-input multiple-output\ninter-symbol interference (MIMO-ISI) channels using message passing on\ngraphical models. A key contribution in the paper is the demonstration that\nnear-optimal performance in MIMO-ISI channels with large dimensions can be\nachieved at low complexities through simple yet effective\nsimplifications/approximations, although the graphical models that represent\nMIMO-ISI channels are fully/densely connected (loopy graphs). These include 1)\nuse of Markov Random Field (MRF) based graphical model with pairwise\ninteraction, in conjunction with {\\em message/belief damping}, and 2) use of\nFactor Graph (FG) based graphical model with {\\em Gaussian approximation of\ninterference} (GAI). The per-symbol complexities are $O(K^2n_t^2)$ and\n$O(Kn_t)$ for the MRF and the FG with GAI approaches, respectively, where $K$\nand $n_t$ denote the number of channel uses per frame, and number of transmit\nantennas, respectively. These low-complexities are quite attractive for large\ndimensions, i.e., for large $Kn_t$. From a performance perspective, these\nalgorithms are even more interesting in large-dimensions since they achieve\nincreasingly closer to optimum detection performance for increasing $Kn_t$.\nAlso, we show that these message passing algorithms can be used in an iterative\nmanner with local neighborhood search algorithms to improve the\nreliability/performance of $M$-QAM symbol detection. \n\n"}
{"id": "1101.4435", "contents": "Title: Solutions for the MIMO Gaussian Wiretap Channel with a Cooperative\n  Jammer Abstract: We study the Gaussian MIMO wiretap channel with a transmitter, a legitimate\nreceiver, an eavesdropper and an external helper, each equipped with multiple\nantennas. The transmitter sends confidential messages to its intended receiver,\nwhile the helper transmits jamming signals independent of the source message to\nconfuse the eavesdropper. The jamming signal is assumed to be treated as noise\nat both the intended receiver and the eavesdropper. We obtain a closed-form\nexpression for the structure of the artificial noise covariance matrix that\nguarantees no decrease in the secrecy capacity of the wiretap channel. We also\ndescribe how to find specific realizations of this covariance matrix expression\nthat provide good secrecy rate performance, even when there is no non-trivial\nnull space between the helper and the intended receiver. Unlike prior work, our\napproach considers the general MIMO case, and is not restricted to SISO or MISO\nscenarios. \n\n"}
{"id": "1101.4477", "contents": "Title: Limited Feedback Over Temporally Correlated Channels for the Downlink of\n  a Femtocell Network Abstract: Heterogeneous networks are a flexible deployment model that rely on low power\nnodes to improve the user broadband experience in a cost effective manner.\nFemtocells are an integral part of heterogeneous networks, whose main purpose\nis to improve the indoor capacity. When restricting access to home users,\nfemtocells cause a substantial interference problem that cannot be mitigated\nthrough coordination with the macrocell base station. In this paper, we analyze\nmultiple antenna communication on the downlink of a macrocell network, with\nfemtocell overlay. We evaluate the feasibility of limited feedback beamforming\ngiven delay on the feedback channel, quantization error and uncoordinated\ninterference from the femtocells. We model the femtocell spatial distribution\nas a Poisson point process and the temporal correlation of the channel\naccording to a Gauss-Markov model. We derive the probability of outage at the\nmacrocell users as a function of the temporal correlation, the femtocell\ndensity, and the feedback rate. We propose rate backoff to maximize the average\nachievable rate in the network. Simulation results show that limited feedback\nbeamforming is a viable solution for femtocell networks despite the CSI\ninaccuracy and the interference. They illustrate how properly designed rate\nbackoff improves the achievable rate of the macrocell system. \n\n"}
{"id": "1102.0316", "contents": "Title: Partition Functions of Normal Factor Graphs Abstract: One of the most common types of functions in mathematics, physics, and\nengineering is a sum of products, sometimes called a partition function. After\n\"normalization,\" a sum of products has a natural graphical representation,\ncalled a normal factor graph (NFG), in which vertices represent factors, edges\nrepresent internal variables, and half-edges represent the external variables\nof the partition function. In physics, so-called trace diagrams share similar\nfeatures. We believe that the conceptual framework of representing sums of\nproducts as partition functions of NFGs is an important and intuitive paradigm\nthat, surprisingly, does not seem to have been introduced explicitly in the\nprevious factor graph literature. Of particular interest are NFG modifications\nthat leave the partition function invariant. A simple subclass of such NFG\nmodifications offers a unifying view of the Fourier transform, tree-based\nreparameterization, loop calculus, and the Legendre transform. \n\n"}
{"id": "1102.0424", "contents": "Title: Design of Finite-Length Irregular Protograph Codes with Low Error Floors\n  over the Binary-Input AWGN Channel Using Cyclic Liftings Abstract: We propose a technique to design finite-length irregular low-density\nparity-check (LDPC) codes over the binary-input additive white Gaussian noise\n(AWGN) channel with good performance in both the waterfall and the error floor\nregion. The design process starts from a protograph which embodies a desirable\ndegree distribution. This protograph is then lifted cyclically to a certain\nblock length of interest. The lift is designed carefully to satisfy a certain\napproximate cycle extrinsic message degree (ACE) spectrum. The target ACE\nspectrum is one with extremal properties, implying a good error floor\nperformance for the designed code. The proposed construction results in\nquasi-cyclic codes which are attractive in practice due to simple encoder and\ndecoder implementation. Simulation results are provided to demonstrate the\neffectiveness of the proposed construction in comparison with similar existing\nconstructions. \n\n"}
{"id": "1102.0755", "contents": "Title: Message and State Cooperation in a Relay Channel When the Relay Has\n  Strictly Causal State Information Abstract: A state-dependent relay channel is studied in which strictly causal channel\nstate information is available at the relay and no state information is\navailable at the source and destination. Source and relay are connected via two\nunidirectional out-of-band orthogonal links of finite capacity, and a\nstate-dependent memoryless channel connects source and relay, on one side, and\nthe destination, on the other. Via the orthogonal links, the source can convey\ninformation about the message to be delivered to the destination to the relay\nwhile the relay can forward state information to the source. This exchange\nenables cooperation between source and relay on both transmission of message\nand state information to the destination. First, an achievable scheme, inspired\nby noisy network coding, is proposed that exploits both message and state\ncooperation. Next, based on the given achievable rate and appropriate upper\nbounds, capacity results are identified for some special cases. Finally, a\nGaussian model is studied, along with corresponding numerical results that\nilluminate the relative merits of state and message cooperation. \n\n"}
{"id": "1102.4580", "contents": "Title: Gaussian bosonic synergy: quantum communication via realistic channels\n  of zero quantum capacity Abstract: As with classical information, error-correcting codes enable reliable\ntransmission of quantum information through noisy or lossy channels. In\ncontrast to the classical theory, imperfect quantum channels exhibit a strong\nkind of synergy: there exist pairs of discrete memoryless quantum channels,\neach of zero quantum capacity, which acquire positive quantum capacity when\nused together. Here we show that this \"superactivation\" phenomenon also occurs\nin the more realistic setting of optical channels with attenuation and Gaussian\nnoise. This paves the way for its experimental realization and application in\nreal-world communications systems. \n\n"}
{"id": "1102.4810", "contents": "Title: Distributed SNR Estimation using Constant Modulus Signaling over\n  Gaussian Multiple-Access Channels Abstract: A sensor network is used for distributed joint mean and variance estimation,\nin a single time snapshot. Sensors observe a signal embedded in noise, which\nare phase modulated using a constant-modulus scheme and transmitted over a\nGaussian multiple-access channel to a fusion center, where the mean and\nvariance are estimated jointly, using an asymptotically minimum-variance\nestimator, which is shown to decouple into simple individual estimators of the\nmean and the variance. The constant-modulus phase modulation scheme ensures a\nfixed transmit power, robust estimation across several sensing noise\ndistributions, as well as an SNR estimate that requires a single set of\ntransmissions from the sensors to the fusion center, unlike the\namplify-and-forward approach. The performance of the estimators of the mean and\nvariance are evaluated in terms of asymptotic variance, which is used to\nevaluate the performance of the SNR estimator in the case of Gaussian, Laplace\nand Cauchy sensing noise distributions. For each sensing noise distribution,\nthe optimal phase transmission parameters are also determined. The asymptotic\nrelative efficiency of the mean and variance estimators is evaluated. It is\nshown that among the noise distributions considered, the estimators are\nasymptotically efficient only when the noise distribution is Gaussian.\nSimulation results corroborate analytical results. \n\n"}
{"id": "1103.0967", "contents": "Title: Intensionality and Two-steps Interpretations Abstract: In this paper we considered the extension of the First-order Logic (FOL) by\nBealer's intensional abstraction operator. Contemporary use of the term\n'intension' derives from the traditional logical Frege-Russell's doctrine that\nan idea (logic formula) has both an extension and an intension. Although there\nis divergence in formulation, it is accepted that the extension of an idea\nconsists of the subjects to which the idea applies, and the intension consists\nof the attributes implied by the idea. From the Montague's point of view, the\nmeaning of an idea can be considered as particular extensions in different\npossible worlds. In the case of the pure FOL we obtain commutative homomorphic\ndiagram that holds in each given possible world of the intensional FOL, from\nthe free algebra of the FOL syntax, toward its intensional algebra of concepts,\nand, successively, to the new extensional relational algebra (different from\nCylindric algebras). Then we show that it corresponds to the Tarski's\ninterpretation of the standard extensional FOL in this possible world. \n\n"}
{"id": "1103.3641", "contents": "Title: On the Pseudocodeword Redundancy of Binary Linear Codes Abstract: The AWGNC, BSC, and max-fractional pseudocodeword redundancies of a binary\nlinear code are defined to be the smallest number of rows in a parity-check\nmatrix such that the corresponding minimum pseudoweight is equal to the minimum\nHamming distance of the code. It is shown that most codes do not have a finite\npseudocodeword redundancy. Also, upper bounds on the pseudocodeword redundancy\nfor some families of codes, including codes based on designs, are provided. The\npseudocodeword redundancies for all codes of small length (at most 9) are\ncomputed. Furthermore, comprehensive results are provided on the cases of\ncyclic codes of length at most 250 for which the eigenvalue bound of Vontobel\nand Koetter is sharp. \n\n"}
{"id": "1103.4086", "contents": "Title: Lattice Codes for the Wiretap Gaussian Channel: Construction and\n  Analysis Abstract: We consider the Gaussian wiretap channel, where two legitimate players Alice\nand Bob communicate over an additive white Gaussian noise (AWGN) channel, while\nEve is eavesdropping, also through an AWGN channel. We propose a coding\nstrategy based on lattice coset encoding. We analyze Eve's probability of\ndecoding, from which we define the secrecy gain as a design criterion for\nwiretap lattice codes, expressed in terms of the lattice theta series, which\ncharacterizes Eve's confusion as a function of the channel parameters. The\nsecrecy gain is studied for even unimodular lattices, and an asymptotic\nanalysis shows that it grows exponentially in the dimension of the lattice.\nExamples of wiretap lattice codes are given. Interestingly, minimizing Eve's\nprobability of error involves the same optimization of the theta series as does\nthe flatness factor, another newly defined code design that characterizes\nlattice codes that achieve strong secrecy. \n\n"}
{"id": "1103.4774", "contents": "Title: Full-Rate Full-Diversity Achieving MIMO Precoding with Partial CSIT Abstract: In this paper, we consider a $n_t\\times n_r$ multiple-input multiple-output\n(MIMO) channel subjected to block fading. Reliability (in terms of achieved\ndiversity order) and rate (in number of symbols transmitted per channel use)\nare of interest in such channels. We propose a new precoding scheme which\nachieves both full diversity ($n_tn_r$th order diversity) as well as full rate\n($n_t$ symbols per channel use) using partial channel state information at the\ntransmitter (CSIT), applicable in MIMO systems including $n_r<n_t$ asymmetric\nMIMO. The proposed scheme achieves full diversity and improved coding gain\nthrough an optimization over the choice of constellation sets. The optimization\nmaximizes $d_{min}^2$ for our precoding scheme subject to an energy constraint.\nThe scheme requires feedback of $n_t-1$ angle parameter values, compared to\n$2n_tn_r$ real coefficients in case of full CSIT. Error rate performance\nresults for $3\\times 1$, $3\\times 2$, $4\\times 1$, $8\\times 1$ precoded MIMO\nsystems (with $n_t=3,3,4,8$ symbols per channel use, respectively) show that\nthe proposed precoding achieves 3rd, 6th, 4th and 8th order diversities,\nrespectively. These performances are shown to be better than other precoding\nschemes in the literature; the better performance is due to the choice of the\nsignal sets and the feedback angles in the proposed scheme. \n\n"}
{"id": "1103.5426", "contents": "Title: Interference Channels with Rate-Limited Feedback Abstract: We consider the two-user interference channel with rate-limited feedback.\nRelated prior works focus on the case where feedback links have infinite\ncapacity, while no research has been done for the rate-limited feedback\nproblem. Several new challenges arise due to the capacity limitations of the\nfeedback links, both in deriving inner-bounds and outer-bounds. We study this\nproblem under three different interference models: the El Gamal-Costa\ndeterministic model, the linear deterministic model, and the Gaussian model.\nFor the first two models, we develop an achievable scheme that employs three\ntechniques: Han-Kobayashi message splitting, quantize-and-binning, and\ndecode-and-forward. We also derive new outer-bounds for all three models and we\nshow the optimality of our scheme under the linear deterministic model. In the\nGaussian case, we propose a transmission strategy that incorporates lattice\ncodes, inspired by the ideas developed in the first two models. For symmetric\nchannel gains, we prove that the gap between the achievable sum-rate of the\nproposed scheme and our new outer-bounds is bounded by a constant number of\nbits, independent of the channel gains. \n\n"}
{"id": "1103.5535", "contents": "Title: A Lattice Compress-and-Forward Scheme Abstract: We present a nested lattice-code-based strategy that achieves the\nrandom-coding based Compress-and-Forward (CF) rate for the three node Gaussian\nrelay channel. To do so, we first outline a lattice-based strategy for the\n$(X+Z_1,X+Z_2)$ Wyner-Ziv lossy source-coding with side-information problem in\nGaussian noise, a re-interpretation of the nested lattice-code-based Gaussian\nWyner-Ziv scheme presented by Zamir, Shamai, and Erez. We use the notation\n$(X+Z_1,X+Z_2)$ Wyner-Ziv to mean that the source is of the form $X+ Z_1$ and\nthe side-information at the receiver is of the form $X+ Z_2$, for independent\nGaussian $X, Z_1$ and $Z_2$. We next use this $(X+Z_1,X+Z_2)$ Wyner-Ziv scheme\nto implement a \"structured\" or lattice-code-based CF scheme which achieves the\nclassic CF rate for Gaussian relay channels. This suggests that lattice codes\nmay not only be useful in point-to-point single-hop source and channel coding,\nin multiple access and broadcast channels, but that they may also be useful in\nlarger relay networks. The usage of lattice codes in larger networks is\nmotivated by their structured nature (possibly leading to rate gains) and\ndecoding (relatively simple) being more practically realizable than their\nrandom coding based counterparts. We furthermore expect the proposed\nlattice-based CF scheme to constitute a first step towards a generic structured\nachievability scheme for networks such as a structured version of the recently\nintroduced \"noisy network coding\". \n\n"}
{"id": "1104.1823", "contents": "Title: Which weighted circulant networks have perfect state transfer? Abstract: The question of perfect state transfer existence in quantum spin networks\nbased on weighted graphs has been recently presented by many authors. We give a\nsimple condition for characterizing weighted circulant graphs allowing perfect\nstate transfer in terms of their eigenvalues. This is done by extending the\nresults about quantum periodicity existence in the networks obtained by Saxena,\nSeverini and Shparlinski and characterizing integral graphs among weighted\ncirculant graphs. Finally, classes of weighted circulant graphs supporting\nperfect state transfer are found. These classes completely cover the class of\ncirculant graphs having perfect state transfer in the unweighted case. In fact,\nwe show that there exists an weighted integral circulant graph with $n$\nvertices having perfect state transfer if and only if $n$ is even. Moreover we\nprove the non-existence of perfect state transfer for several other classes of\nweighted integral circulant graphs of even order. \n\n"}
{"id": "1104.1910", "contents": "Title: Tails of Random Matrix Diagonal Elements: The Case of the Wishart\n  Inverse Abstract: We analytically compute the large-deviation probability of a diagonal matrix\nelement of two cases of random matrices, namely $\\beta=[\\vec H^\\dagger\\vec\nH]^{-1}_{11}$ and $\\gamma=[\\vec I_N+\\rho\\vec H^\\dagger\\vec H]^{-1}_{11}$, where\n$\\vec H$ is a $M\\times N$ complex Gaussian matrix with independent entries and\n$M\\geq N$. These diagonal entries are related to the \"signal to interference\nand noise ratio\" (SINR) in multi-antenna communications. They depend not only\non the eigenvalues but also on the corresponding eigenfunction weights, which\nwe are able to evaluate on average constrained on the value of the SINR. We\nalso show that beyond a lower and upper critical value of $\\beta$, $\\gamma$,\nthe maximum and minimum eigenvalues, respectively, detach from the bulk.\nResponsible for this detachment is the fact that the corresponding eigenvalue\nweight becomes macroscopic (i.e. O(1)), and hence exerts a strong repulsion to\nthe eigenvalue. \n\n"}
{"id": "1104.2108", "contents": "Title: Stability of Modified-CS and LS-CS for Recursive Reconstruction of\n  Sparse Signal Sequences Abstract: In this work, we obtain sufficient conditions for the \"stability\" of our\nrecently proposed algorithms, Least Squares Compressive Sensing residual\n(LS-CS) and modified-CS, for recursively reconstructing sparse signal sequences\nfrom noisy measurements. By \"stability\" we mean that the number of misses from\nthe current support estimate and the number of extras in it remain bounded by a\ntime-invariant value at all times. We show that, for a signal model with fixed\nsignal power and support set size; support set changes allowed at every time;\nand gradual coefficient magnitude increase/decrease, \"stability\" holds under\nmild assumptions -- bounded noise, high enough minimum nonzero coefficient\nmagnitude increase rate, and large enough number of measurements at every time.\nA direct corollary is that the reconstruction error is also bounded by a\ntime-invariant value at all times. If the support set of the sparse signal\nsequence changes slowly over time, our results hold under weaker assumptions\nthan what simple compressive sensing (CS) needs for the same error bound. Also,\nour support error bounds are small compared to the support size. Our discussion\nis backed up by Monte Carlo simulation based comparisons. \n\n"}
{"id": "1105.2988", "contents": "Title: Anatomy of a Bit: Information in a Time Series Observation Abstract: Appealing to several multivariate information measures---some familiar, some\nnew here---we analyze the information embedded in discrete-valued stochastic\ntime series. We dissect the uncertainty of a single observation to demonstrate\nhow the measures' asymptotic behavior sheds structural and semantic light on\nthe generating process's internal information dynamics. The measures scale with\nthe length of time window, which captures both intensive (rates of growth) and\nsubextensive components. We provide interpretations for the components,\ndeveloping explicit relationships between them. We also identify the\ninformational component shared between the past and the future that is not\ncontained in a single observation. The existence of this component directly\nmotivates the notion of a process's effective (internal) states and indicates\nwhy one must build models. \n\n"}
{"id": "1105.3879", "contents": "Title: Non-Malleable Codes from the Wire-Tap Channel Abstract: Recently, Dziembowski et al. introduced the notion of non-malleable codes\n(NMC), inspired from the notion of non-malleability in cryptography and the\nwork of Gennaro et al. in 2004 on tamper proof security. Informally, when using\nNMC, if an attacker modifies a codeword, decoding this modified codeword will\nreturn either the original message or a completely unrelated value.\n  The definition of NMC is related to a family of modifications authorized to\nthe attacker. In their paper, Dziembowski et al. propose a construction valid\nfor the family of all bit-wise independent functions.\n  In this article, we study the link between the second version of the Wire-Tap\n(WT) Channel, introduced by Ozarow and Wyner in 1984, and NMC. Using\ncoset-coding, we describe a new construction for NMC w.r.t. a subset of the\nfamily of bit-wise independent functions. Our scheme is easier to build and\nmore efficient than the one proposed by Dziembowski et al. \n\n"}
{"id": "1105.5476", "contents": "Title: Feedback-Topology Designs for Interference Alignment in MIMO\n  Interference Channels Abstract: Interference alignment (IA) is a joint-transmission technique that achieves\nthe capacity of the interference channel for high signal-to-noise ratios\n(SNRs). Most prior work on IA is based on the impractical assumption that\nperfect and global channel-state information(CSI) is available at all\ntransmitters. To implement IA, each receiver has to feed back CSI to all\ninterferers, resulting in overwhelming feedback overhead. In particular, the\nsum feedback rate of each receiver scales quadratically with the number of\nusers even if the quantized CSI is fed back. To substantially suppress feedback\noverhead, this paper focuses on designing efficient arrangements of feedback\nlinks, called feedback topologies, under the IA constraint. For the\nmultiple-input-multiple-output (MIMO) K-user interference channel, we propose\nthe feedback topology that supports sequential CSI exchange (feedback and\nfeedforward) between transmitters and receivers so as to achieve IA\nprogressively. This feedback topology is shown to reduce the network feedback\noverhead from a cubic function of K to a linear one. To reduce the delay in the\nsequential CSI exchange, an alternative feedback topology is designed for\nsupporting two-hop feedback via a control station, which also achieves the\nlinear feedback scaling with K. Next, given the proposed feedback topologies,\nthe feedback-bit allocation algorithm is designed for allocating feedback bits\nby each receiver to different feedback links so as to regulate the residual\ninterference caused by the finite-rate feedback. Simulation results demonstrate\nthat the proposed bit allocation leads to significant throughput gains\nespecially in strong interference environments. \n\n"}
{"id": "1105.5895", "contents": "Title: Percolation and Connectivity on the Signal to Interference Ratio Graph Abstract: A wireless communication network is considered where any two nodes are\nconnected if the signal-to-interference ratio (SIR) between them is greater\nthan a threshold. Assuming that the nodes of the wireless network are\ndistributed as a Poisson point process (PPP), percolation (unbounded connected\ncluster) on the resulting SIR graph is studied as a function of the density of\nthe PPP. For both the path-loss as well as path-loss plus fading model of\nsignal propagation, it is shown that for a small enough threshold, there exists\na closed interval of densities for which percolation happens with non-zero\nprobability. Conversely, for the path-loss model of signal propagation, it is\nshown that for a large enough threshold, there exists a closed interval of\ndensities for which the probability of percolation is zero. Restricting all\nnodes to lie in an unit square, connectivity properties of the SIR graph are\nalso studied. Assigning separate frequency bands or time-slots proportional to\nthe logarithm of the number of nodes to different nodes for\ntransmission/reception is sufficient to guarantee connectivity in the SIR\ngraph. \n\n"}
{"id": "1105.6164", "contents": "Title: How to Construct Polar Codes Abstract: A method for efficiently constructing polar codes is presented and analyzed.\nAlthough polar codes are explicitly defined, straightforward construction is\nintractable since the resulting polar bit-channels have an output alphabet that\ngrows exponentially with he code length. Thus the core problem that needs to be\nsolved is that of faithfully approximating a bit-channel with an intractably\nlarge alphabet by another channel having a manageable alphabet size. We devise\ntwo approximation methods which \"sandwich\" the original bit-channel between a\ndegraded and an upgraded version thereof. Both approximations can be\nefficiently computed, and turn out to be extremely close in practice. We also\nprovide theoretical analysis of our construction algorithms, proving that for\nany fixed $\\epsilon > 0$ and all sufficiently large code lengths $n$, polar\ncodes whose rate is within $\\epsilon$ of channel capacity can be constructed in\ntime and space that are both linear in $n$. \n\n"}
{"id": "1106.0070", "contents": "Title: Modeling and Information Rates for Synchronization Error Channels Abstract: We propose a new channel model for channels with synchronization errors.\nUsing this model, we give simple, non-trivial and, in some cases, tight lower\nbounds on the capacity for certain synchronization error channels. \n\n"}
{"id": "1106.1474", "contents": "Title: Simple Bounds for Recovering Low-complexity Models Abstract: This note presents a unified analysis of the recovery of simple objects from\nrandom linear measurements. When the linear functionals are Gaussian, we show\nthat an s-sparse vector in R^n can be efficiently recovered from 2s log n\nmeasurements with high probability and a rank r, n by n matrix can be\nefficiently recovered from r(6n-5r) with high probability. For sparse vectors,\nthis is within an additive factor of the best known nonasymptotic bounds. For\nlow-rank matrices, this matches the best known bounds. We present a parallel\nanalysis for block sparse vectors obtaining similarly tight bounds. In the case\nof sparse and block sparse signals, we additionally demonstrate that our bounds\nare only slightly weakened when the measurement map is a random sign matrix.\nOur results are based on analyzing a particular dual point which certifies\noptimality conditions of the respective convex programming problem. Our\ncalculations rely only on standard large deviation inequalities and our\nanalysis is self-contained. \n\n"}
{"id": "1106.3713", "contents": "Title: Source-Channel Coding Theorems for the Multiple-Access Relay Channel Abstract: We study reliable transmission of arbitrarily correlated sources over\nmultiple-access relay channels (MARCs) and multiple-access broadcast relay\nchannels (MABRCs). In MARCs only the destination is interested in\nreconstructing the sources, while in MABRCs both the relay and the destination\nwant to reconstruct them. In addition to arbitrary correlation among the source\nsignals at the users, both the relay and the destination have side information\ncorrelated with the source signals. Our objective is to determine whether a\ngiven pair of sources can be losslessly transmitted to the destination for a\ngiven number of channel symbols per source sample, defined as the\nsource-channel rate. Sufficient conditions for reliable communication based on\noperational separation, as well as necessary conditions on the achievable\nsource-channel rates are characterized. Since operational separation is\ngenerally not optimal for MARCs and MABRCs, sufficient conditions for reliable\ncommunication using joint source-channel coding schemes based on a combination\nof the correlation preserving mapping technique with Slepian-Wolf source coding\nare also derived. For correlated sources transmitted over fading Gaussian MARCs\nand MABRCs, we present conditions under which separation (i.e., separate and\nstand-alone source and channel codes) is optimal. This is the first time\noptimality of separation is proved for MARCs and MABRCs. \n\n"}
{"id": "1107.1535", "contents": "Title: Multilevel Polarization of Polar Codes Over Arbitrary Discrete\n  Memoryless Channels Abstract: It is shown that polar codes achieve the symmetric capacity of discrete\nmemoryless channels with arbitrary input alphabet sizes. It is shown that in\ngeneral, channel polarization happens in several, rather than only two levels\nso that the synthesized channels are either useless, perfect or \"partially\nperfect\". Any subset of the channel input alphabet which is closed under\naddition, induces a coset partition of the alphabet through its shifts. For any\nsuch partition of the input alphabet, there exists a corresponding partially\nperfect channel whose outputs uniquely determine the coset to which the channel\ninput belongs. By a slight modification of the encoding and decoding rules, it\nis shown that perfect transmission of certain information symbols over\npartially perfect channels is possible. Our result is general regarding both\nthe cardinality and the algebraic structure of the channel input alphabet; i.e\nwe show that for any channel input alphabet size and any Abelian group\nstructure on the alphabet, polar codes are optimal. It is also shown through an\nexample that polar codes when considered as group/coset codes, do not achieve\nthe capacity achievable using coset codes over arbitrary channels. \n\n"}
{"id": "1107.1829", "contents": "Title: Medium Access Control for Wireless Networks with Peer-to-Peer State\n  Exchange Abstract: Distributed medium access control (MAC) protocols are proposed for wireless\nnetworks assuming that one-hop peers can periodically exchange a small amount\nof state information. Each station maintains a state and makes state\ntransitions and transmission decisions based on its state and recent state\ninformation collected from its one-hop peers. A station can adapt its packet\nlength and the size of its state space to the amount of traffic in its\nneighborhood. It is shown that these protocols converge to a steady state,\nwhere stations take turns to transmit in each neighborhood without collision.\nIn other words, an efficient time-division multiple access (TDMA) like schedule\nis formed in a distributed manner, as long as the topology of the network\nremains static or changes slowly with respect to the execution of the protocol. \n\n"}
{"id": "1108.3415", "contents": "Title: Frequency-Hopping Sequence Sets With Low Average and Maximum Hamming\n  Correlation Abstract: In frequency-hopping multiple-access (FHMA) systems, the average Hamming\ncorrelation (AHC) among frequency-hopping sequences (FHSs) as well as the\nmaximum Hamming correlation (MHC) is an important performance measure.\nTherefore, it is a challenging problem to design FHS sets with good AHC and MHC\nproperties for application. In this paper, we analyze the AHC properties of an\nFHS set, and present new constructions for FHS sets with optimal AHC. We first\ncalculate the AHC of some known FHS sets with optimal MHC, and check their\noptimalities. We then prove that any uniformly distributed FHS set has optimal\nAHC. We also present two constructions of FHS sets with optimal AHC based on\ncyclotomy. Finally, we show that if an FHS set is obtained from another FHS set\nwith optimal AHC by an interleaving, it has optimal AHC. \n\n"}
{"id": "1108.3652", "contents": "Title: Coordination using Implicit Communication Abstract: We explore a basic noise-free signaling scenario where coordination and\ncommunication are naturally merged. A random signal X_1,...,X_n is processed to\nproduce a control signal or action sequence A_1,...,A_n, which is observed and\nfurther processed (without access to X_1,...,X_n) to produce a third sequence\nB_1,...,B_n. The object of interest is the set of empirical joint distributions\np(x,a,b) that can be achieved in this setting. We show that H(A) >= I(X;A,B) is\nthe necessary and sufficient condition for achieving p(x,a,b) when no causality\nconstraints are enforced on the encoders. We also give results for various\ncausality constraints.\n  This setting sheds light on the embedding of digital information in analog\nsignals, a concept that is exploited in digital watermarking, steganography,\ncooperative communication, and strategic play in team games such as bridge. \n\n"}
{"id": "1109.0351", "contents": "Title: Directed Information, Causal Estimation, and Communication in Continuous\n  Time Abstract: A notion of directed information between two continuous-time processes is\nproposed. A key component in the definition is taking an infimum over all\npossible partitions of the time interval, which plays a role no less\nsignificant than the supremum over \"space\" partitions inherent in the\ndefinition of mutual information. Properties and operational interpretations in\nestimation and communication are then established for the proposed notion of\ndirected information. For the continuous-time additive white Gaussian noise\nchannel, it is shown that Duncan's classical relationship between causal\nestimation and information continues to hold in the presence of feedback upon\nreplacing mutual information by directed information. A parallel result is\nestablished for the Poisson channel. The utility of this relationship is then\ndemonstrated in computing the directed information rate between the input and\noutput processes of a continuous-time Poisson channel with feedback, where the\nchannel input process is constrained to be constant between events at the\nchannel output. Finally, the capacity of a wide class of continuous-time\nchannels with feedback is established via directed information, characterizing\nthe fundamental limit on reliable communication. \n\n"}
{"id": "1109.2782", "contents": "Title: Two Classes of Broadcast Channels With Side-Information: Capacity Outer\n  Bounds Abstract: In this paper, we derive outer bounds on the capacity region of two classes\nof the general two-user discrete memoryless broadcast channels with\nside-information at the transmitter. The first class comprises the classical\nbroadcast channel where a sender transmits two independent messages to two\nreceivers. A constraint that each message must be kept confidential from the\nunintended receiver constitutes the second class. For both classes, the\nconditional distribution characterizing the channel depends on a state process\nand the encoder has side-information provided to it in a noncausal manner. For\nthe first class of channels, an outer bound is derived employing techniques\nused to prove the converse theorem for the Gel'fand-Pinsker's channel with\nrandom parameters; the bounds are tight for individual rate constraints, but\ncan be improved upon for the sum rate. The technique for deriving outer bounds\nfor the second class of channels hinges on the confidentiality requirements; we\nalso derive a genie-aided outer bound, where a hypothetical genie gives the\nunintended message to a receiver which treats it as side-information during\nequivocation computation. For both classes of channels, Csisz\\'{a}r's sum\nidentity plays a central role in establishing the capacity outer bounds. \n\n"}
{"id": "1109.4995", "contents": "Title: Quantum emulation of classical dynamics Abstract: In statistical mechanics, it is well known that finite-state classical\nlattice models can be recast as quantum models, with distinct classical\nconfigurations identified with orthogonal basis states. This mapping makes\nclassical statistical mechanics on a lattice a special case of quantum\nstatistical mechanics, and classical combinatorial entropy a special case of\nquantum entropy.\n  In a similar manner, finite-state classical dynamics can be recast as\nfinite-energy quantum dynamics. This mapping translates continuous quantities,\nconcepts and machinery of quantum mechanics into a simplified finite-state\ncontext in which they have a purely classical and combinatorial interpretation.\nFor example, in this mapping quantum average energy becomes the classical\nupdate rate.\n  Interpolation theory and communication theory help explain the truce achieved\nhere between perfect classical determinism and quantum uncertainty, and between\ndiscrete and continuous dynamics. \n\n"}
{"id": "1109.5222", "contents": "Title: Completion Time in Multi-Access Channel: An Information Theoretic\n  Perspective Abstract: In a multi-access channel, completion time refers to the number of channel\nuses required for users, each with some given fixed bit pool, to complete the\ntransmission of all their data bits. In this paper, the characterization of the\ncompletion time region is based on the concept of constrained rates, where\nusers' rates are defined over possibly different number of channel uses. An\ninformation theoretic formulation of completion time is given and the\ncompletion time region is then established for two-user Gaussian multi-access\nchannel, which, analogous to capacity region, characterizes all possible\ntrade-offs between users' completion times. \n\n"}
{"id": "1109.5415", "contents": "Title: Shannon Meets Nyquist: Capacity of Sampled Gaussian Channels Abstract: We explore two fundamental questions at the intersection of sampling theory\nand information theory: how channel capacity is affected by sampling below the\nchannel's Nyquist rate, and what sub-Nyquist sampling strategy should be\nemployed to maximize capacity. In particular, we derive the capacity of sampled\nanalog channels for three prevalent sampling strategies: sampling with\nfiltering, sampling with filter banks, and sampling with modulation and filter\nbanks. These sampling mechanisms subsume most nonuniform sampling techniques\napplied in practice. Our analyses illuminate interesting connections between\nunder-sampled channels and multiple-input multiple-output channels. The optimal\nsampling structures are shown to extract out the frequencies with the highest\nSNR from each aliased frequency set, while suppressing aliasing and out-of-band\nnoise. We also highlight connections between undersampled channel capacity and\nminimum mean-squared error (MSE) estimation from sampled data. In particular,\nwe show that the filters maximizing capacity and the ones minimizing MSE are\nequivalent under both filtering and filter-bank sampling strategies. These\nresults demonstrate the effect upon channel capacity of sub-Nyquist sampling\ntechniques, and characterize the tradeoff between information rate and sampling\nrate. \n\n"}
{"id": "1110.1930", "contents": "Title: Statistical Mechanical Analysis of Low-Density Parity-Check Codes on\n  General Markov Channel Abstract: Low-density parity-check (LDPC) codes on symmetric memoryless channels have\nbeen analyzed using statistical physics by several authors. In this paper,\nstatistical mechanical analysis of LDPC codes is performed for asymmetric\nmemoryless channels and general Markov channels. It is shown that the saddle\npoint equations of the replica symmetric solution for a Markov channel is\nequivalent to the density evolution of the belief propagation on the factor\ngraph representing LDPC codes on the Markov channel. The derivation uses the\nmethod of types for Markov chain. \n\n"}
{"id": "1110.2227", "contents": "Title: Average Interpolating Wavelets on Point Clouds and Graphs Abstract: We introduce a new wavelet transform suitable for analyzing functions on\npoint clouds and graphs. Our construction is based on a generalization of the\naverage interpolating refinement scheme of Donoho. The most important\ningredient of the original scheme that needs to be altered is the choice of the\ninterpolant. Here, we define the interpolant as the minimizer of a smoothness\nfunctional, namely a generalization of the Laplacian energy, subject to the\naveraging constraints. In the continuous setting, we derive a formula for the\noptimal solution in terms of the poly-harmonic Green's function. The form of\nthis solution is used to motivate our construction in the setting of graphs and\npoint clouds. We highlight the empirical convergence of our refinement scheme\nand the potential applications of the resulting wavelet transform through\nexperiments on a number of data stets. \n\n"}
{"id": "1111.0663", "contents": "Title: On Identity Testing of Tensors, Low-rank Recovery and Compressed Sensing Abstract: We study the problem of obtaining efficient, deterministic, black-box\npolynomial identity testing algorithms for depth-3 set-multilinear circuits\n(over arbitrary fields). This class of circuits has an efficient,\ndeterministic, white-box polynomial identity testing algorithm (due to Raz and\nShpilka), but has no known such black-box algorithm. We recast this problem as\na question of finding a low-dimensional subspace H, spanned by rank 1 tensors,\nsuch that any non-zero tensor in the dual space ker(H) has high rank. We obtain\nexplicit constructions of essentially optimal-size hitting sets for tensors of\ndegree 2 (matrices), and obtain quasi-polynomial sized hitting sets for\narbitrary tensors (but this second hitting set is less explicit).\n  We also show connections to the task of performing low-rank recovery of\nmatrices, which is studied in the field of compressed sensing. Low-rank\nrecovery asks (say, over the reals) to recover a matrix M from few\nmeasurements, under the promise that M is rank <=r. We also give a formal\nconnection between low-rank recovery and the task of sparse (vector) recovery:\nany sparse-recovery algorithm that exactly recovers vectors of length n and\nsparsity 2r, using m non-adaptive measurements, yields a low-rank recovery\nscheme for exactly recovering nxn matrices of rank <=r, making 2nm non-adaptive\nmeasurements. Furthermore, if the sparse-recovery algorithm runs in time \\tau,\nthen the low-rank recovery algorithm runs in time O(rn^2+n\\tau). We obtain this\nreduction using linear-algebraic techniques, and not using convex optimization,\nwhich is more commonly seen in compressed sensing algorithms. By using a dual\nReed-Solomon code, we are able to (deterministically) construct low-rank\nrecovery schemes taking 4nr measurements over the reals, such that the\nmeasurements can be all rank-1 matrices, or all sparse matrices. \n\n"}
{"id": "1111.1051", "contents": "Title: Multiuser Diversity in Interfering Broadcast Channels: Achievable\n  Degrees of Freedom and User Scaling Law Abstract: This paper investigates how multiuser dimensions can effectively be exploited\nfor target degrees of freedom (DoF) in interfering broadcast channels (IBC)\nconsisting of K-transmitters and their user groups. First, each transmitter is\nassumed to have a single antenna and serve a singe user in its user group where\neach user has receive antennas less than K. In this case, a K-transmitter\nsingle-input multiple-output (SIMO) interference channel (IC) is constituted\nafter user selection. Without help of multiuser diversity, K-1 interfering\nsignals cannot be perfectly removed at each user since the number of receive\nantennas is smaller than or equal to the number of interferers. Only with\nproper user selection, non-zero DoF per transmitter is achievable as the number\nof users increases. Through geometric interpretation of interfering channels,\nwe show that the multiuser dimensions have to be used first for reducing the\nDoF loss caused by the interfering signals, and then have to be used for\nincreasing the DoF gain from its own signal. The sufficient number of users for\nthe target DoF is derived. We also discuss how the optimal strategy of\nexploiting multiuser diversity can be realized by practical user selection\nschemes. Finally, the single transmit antenna case is extended to the\nmultiple-input multiple-output (MIMO) IBC where each transmitter with multiple\nantennas serves multiple users. \n\n"}
{"id": "1111.1788", "contents": "Title: Robust PCA as Bilinear Decomposition with Outlier-Sparsity\n  Regularization Abstract: Principal component analysis (PCA) is widely used for dimensionality\nreduction, with well-documented merits in various applications involving\nhigh-dimensional data, including computer vision, preference measurement, and\nbioinformatics. In this context, the fresh look advocated here permeates\nbenefits from variable selection and compressive sampling, to robustify PCA\nagainst outliers. A least-trimmed squares estimator of a low-rank bilinear\nfactor analysis model is shown closely related to that obtained from an\n$\\ell_0$-(pseudo)norm-regularized criterion encouraging sparsity in a matrix\nexplicitly modeling the outliers. This connection suggests robust PCA schemes\nbased on convex relaxation, which lead naturally to a family of robust\nestimators encompassing Huber's optimal M-class as a special case. Outliers are\nidentified by tuning a regularization parameter, which amounts to controlling\nsparsity of the outlier matrix along the whole robustification path of (group)\nleast-absolute shrinkage and selection operator (Lasso) solutions. Beyond its\nneat ties to robust statistics, the developed outlier-aware PCA framework is\nversatile to accommodate novel and scalable algorithms to: i) track the\nlow-rank signal subspace robustly, as new data are acquired in real time; and\nii) determine principal components robustly in (possibly) infinite-dimensional\nfeature spaces. Synthetic and real data tests corroborate the effectiveness of\nthe proposed robust PCA schemes, when used to identify aberrant responses in\npersonality assessment surveys, as well as unveil communities in social\nnetworks, and intruders from video surveillance data. \n\n"}
{"id": "1111.2837", "contents": "Title: On Compress-Forward without Wyner-Ziv Binning for Relay Networks Abstract: Noisy network coding is recently proposed for the general multi-source\nnetwork by Lim, Kim, El Gamal and Chung. This scheme builds on compress-forward\n(CF) relaying but involves three new ideas, namely no Wyner-Ziv binning,\nrelaxed simultaneous decoding and message repetition. In this paper, using the\ntwo-way relay channel as the underlining example, we analyze the impact of each\nof these ideas on the achievable rate region of relay networks. First, CF\nwithout binning but with joint decoding of both the message and compression\nindex can achieve a larger rate region than the original CF scheme for\nmulti-destination relay networks. With binning and successive decoding, the\ncompression rate at each relay is constrained by the weakest link from the\nrelay to a destination; but without binning, this constraint is relaxed.\nSecond, simultaneous decoding of all messages over all blocks without uniquely\ndecoding the compression indices can remove the constraints on compression rate\ncompletely, but is still subject to the message block boundary effect. Third,\nmessage repetition is necessary to overcome this boundary effect and achieve\nthe noisy network coding region for multi-source networks. The rate region is\nenlarged with increasing repetition times. We also apply CF without binning\nspecifically to the one-way and two-way relay channels and analyze the rate\nregions in detail. For the one-way relay channel, it achieves the same rate as\nthe original CF and noisy network coding but has only 1 block decoding delay.\nFor the two-way relay channel, we derive the explicit channel conditions in the\nGaussian and fading cases for CF without binning to achieve the same rate\nregion or sum rate as noisy network coding. These analyses may be appealing to\npractical implementation because of the shorter encoding and decoding delay in\nCF without binning. \n\n"}
{"id": "1111.3752", "contents": "Title: Single-User Beamforming in Large-Scale MISO Systems with Per-Antenna\n  Constant-Envelope Constraints: The Doughnut Channel Abstract: Large antenna arrays at the base station (BS) has recently been shown to\nachieve remarkable intra-cell interference suppression at low complexity.\nHowever, building large arrays in practice, would require the use of\npower-efficient RF amplifiers, which generally have poor linearity\ncharacteristics and hence would require the use of input signals with a very\nsmall peak-to-average power ratio (PAPR). In this paper, we consider the\nsingle-user Multiple-Input Single-Output (MISO) downlink channel for the case\nwhere the BS antennas are constrained to transmit signals having constant\nenvelope (CE). We show that, with per-antenna CE transmission the effective\nchannel seen by the receiver is a SISO AWGN channel with its input constrained\nto lie in a doughnut-shaped region. For single-path direct-line-of-sight (DLOS)\nand general i.i.d. fading channels, analysis of the effective doughnut channel\nshows that under a per-antenna CE input constraint, i) compared to an\naverage-only total transmit power constrained MISO channel, the extra total\ntransmit power required to achieve a desired information rate is small and\nbounded, ii) with N base station antennas an O(N) array power gain is\nachievable, and iii) for a desired information rate, using power-efficient\namplifiers with CE inputs would require significantly less total transmit power\nwhen compared to using highly linear (power-inefficient) amplifiers with high\nPAPR inputs. \n\n"}
{"id": "1112.0708", "contents": "Title: Information-Theoretically Optimal Compressed Sensing via Spatial\n  Coupling and Approximate Message Passing Abstract: We study the compressed sensing reconstruction problem for a broad class of\nrandom, band-diagonal sensing matrices. This construction is inspired by the\nidea of spatial coupling in coding theory. As demonstrated heuristically and\nnumerically by Krzakala et al. \\cite{KrzakalaEtAl}, message passing algorithms\ncan effectively solve the reconstruction problem for spatially coupled\nmeasurements with undersampling rates close to the fraction of non-zero\ncoordinates.\n  We use an approximate message passing (AMP) algorithm and analyze it through\nthe state evolution method. We give a rigorous proof that this approach is\nsuccessful as soon as the undersampling rate $\\delta$ exceeds the (upper)\nR\\'enyi information dimension of the signal, $\\uRenyi(p_X)$. More precisely,\nfor a sequence of signals of diverging dimension $n$ whose empirical\ndistribution converges to $p_X$, reconstruction is with high probability\nsuccessful from $\\uRenyi(p_X)\\, n+o(n)$ measurements taken according to a band\ndiagonal matrix.\n  For sparse signals, i.e., sequences of dimension $n$ and $k(n)$ non-zero\nentries, this implies reconstruction from $k(n)+o(n)$ measurements. For\n`discrete' signals, i.e., signals whose coordinates take a fixed finite set of\nvalues, this implies reconstruction from $o(n)$ measurements. The result is\nrobust with respect to noise, does not apply uniquely to random signals, but\nrequires the knowledge of the empirical distribution of the signal $p_X$. \n\n"}
{"id": "1112.3471", "contents": "Title: A Nonstochastic Information Theory for Communication and State\n  Estimation Abstract: In communications, unknown variables are usually modelled as random\nvariables, and concepts such as independence, entropy and information are\ndefined in terms of the underlying probability distributions. In contrast,\ncontrol theory often treats uncertainties and disturbances as bounded unknowns\nhaving no statistical structure. The area of networked control combines both\nfields, raising the question of whether it is possible to construct meaningful\nanalogues of stochastic concepts such as independence, Markovness, entropy and\ninformation without assuming a probability space. This paper introduces a\nframework for doing so, leading to the construction of a maximin information\nfunctional for nonstochastic variables. It is shown that the largest maximin\ninformation rate through a memoryless, error-prone channel in this framework\ncoincides with the block-coding zero-error capacity of the channel. Maximin\ninformation is then used to derive tight conditions for uniformly estimating\nthe state of a linear time-invariant system over such a channel, paralleling\nrecent results of Matveev and Savkin. \n\n"}
{"id": "1112.3599", "contents": "Title: Cooperative Network Navigation: Fundamental Limit and its Geometrical\n  Interpretation Abstract: Localization and tracking of moving nodes via network navigation gives rise\nto a new paradigm, where nodes exploit both temporal and spatial cooperation to\ninfer their positions based on intra- and inter-node measurements. While such\ncooperation can significantly improve the performance, it imposes intricate\ninformation processing that impedes network design and operation. In this\npaper, we establish a theoretical framework for cooperative network navigation\nand determine the fundamental limits of navigation accuracy using equivalent\nFisher information analysis. We then introduce the notion of carry-over\ninformation, and provide a geometrical interpretation of the navigation\ninformation and its evolution in time. Our framework unifies the navigation\ninformation obtained from temporal and spatial cooperation, leading to a deep\nunderstanding of information evolution in the network and benefit of\ncooperation. \n\n"}
{"id": "1201.2462", "contents": "Title: The minimax risk of truncated series estimators for symmetric convex\n  polytopes Abstract: We study the optimality of the minimax risk of truncated series estimators\nfor symmetric convex polytopes. We show that the optimal truncated series\nestimator is within $O(\\log m)$ factor of the optimal if the polytope is\ndefined by $m$ hyperplanes. This represents the first such bounds towards\ngeneral convex bodies. In proving our result, we first define a geometric\nquantity, called the \\emph{approximation radius}, for lower bounding the\nminimax risk. We then derive our bounds by establishing a connection between\nthe approximation radius and the Kolmogorov width, the quantity that provides\nupper bounds for the truncated series estimator. Besides, our proof contains\nseveral ingredients which might be of independent interest: 1. The notion of\napproximation radius depends on the volume of the body. It is an intuitive\nnotion and is flexible to yield strong minimax lower bounds; 2. The connection\nbetween the approximation radius and the Kolmogorov width is a consequence of a\nnovel duality relationship on the Kolmogorov width, developed by utilizing some\ndeep results from convex geometry. \n\n"}
{"id": "1201.3698", "contents": "Title: Energy Efficiency Scaling Law for MIMO Broadcasting Channels Abstract: This letter investigates the energy efficiency (EE) scaling law for the\nbroadcasting channels (BC) with many users, in which the non-ideal transmit\nindependent power consumption is taken into account. We first consider the\nsingle antenna case with $K$ users, and derive that the EE scales as\n$\\frac{{\\log_2 \\ln K}}{\\alpha}$ when $\\alpha > 0$ and $\\log_2 K$ when $\\alpha =\n0$, where $\\alpha$ is the normalized transmit independent power. After that, we\nextend it to the general MIMO BC case with a $M$-antenna transmitter and $K$\nusers each with $N$ antennas. The scaling law becomes $\\frac{{M \\log_2 \\ln\nNK}}{\\alpha}$ when $\\alpha > 0$ and $ \\log_2 NK$ when $\\alpha = 0$. \n\n"}
{"id": "1202.0325", "contents": "Title: Quantum wiretap channel with non-uniform random number and its exponent\n  and equivocation rate of leaked information Abstract: A usual code for quantum wiretap channel requires an auxiliary random\nvariable subject to the perfect uniform distribution. However, it is difficult\nto prepare such an auxiliary random variable. We propose a code that requires\nonly an auxiliary random variable subject to a non-uniform distribution instead\nof the perfect uniform distribution. Further, we evaluate the exponential\ndecreasing rate of leaked information and derive its equivocation rate. For\npractical constructions, we also discuss the security when our code consists of\na linear error correcting code. \n\n"}
{"id": "1202.0366", "contents": "Title: Blind Null-Space Learning for MIMO Underlay Cognitive Radio Networks Abstract: This paper proposes a blind technique for MIMO cognitive radio Secondary\nUsers (SU) to transmit in the same band simultaneously with a Primary User (PU)\nunder a maximum interference constraint. In the proposed technique, the SU is\nable to meet the interference constraint of the PU without explicitly\nestimating the interference channel matrix to the PU and without burdening the\nPU with any interaction with the SU.\n  The only condition required of the PU is that for a short time interval it\nuses a power control scheme such that its transmitted power is a monotonic\nfunction of the interference inflicted by the SU. During this time interval,\nthe SU iteratively modifies the spatial orientation of its transmitted signal\nand measures the effect of this modification on the PU's total transmit power.\nThe entire process is based on energy measurements which is very desirable from\nan implementation point of view. \n\n"}
{"id": "1202.0655", "contents": "Title: Central Approximation in Statistical Physics and Information Theory Abstract: In statistical physics and information theory, although the exponent of the\npartition function is often of our primary interest, there are cases where one\nneeds more detailed information. In this paper, we present a general framework\nto study more precise asymptotic behaviors of the partition function, using the\ncentral approximation in conjunction with the method of types. \n\n"}
{"id": "1202.0932", "contents": "Title: Error-Correction in Flash Memories via Codes in the Ulam Metric Abstract: We consider rank modulation codes for flash memories that allow for handling\narbitrary charge-drop errors. Unlike classical rank modulation codes used for\ncorrecting errors that manifest themselves as swaps of two adjacently ranked\nelements, the proposed \\emph{translocation rank codes} account for more general\nforms of errors that arise in storage systems. Translocations represent a\nnatural extension of the notion of adjacent transpositions and as such may be\nanalyzed using related concepts in combinatorics and rank modulation coding.\nOur results include derivation of the asymptotic capacity of translocation rank\ncodes, construction techniques for asymptotically good codes, as well as simple\ndecoding methods for one class of constructed codes. As part of our exposition,\nwe also highlight the close connections between the new code family and\npermutations with short common subsequences, deletion and insertion\nerror-correcting codes for permutations, and permutation codes in the Hamming\ndistance. \n\n"}
{"id": "1202.0934", "contents": "Title: Action Dependent Strictly Causal State Communication Abstract: The problem of communication and state estimation is considered in the\ncontext of channels with actiondependent states. Given the message to be\ncommunicated, the transmitter chooses an action sequence that affects the\nformation of the channel states, and then creates the channel input sequence\nbased on the state sequence. The decoder estimates the channel to some\ndistortion as well as decodes the message. The capacity-distortion tradeoff of\nsuch a channel is characterized for the case when the state information is\navailable strictly causally at the channel encoder. The problem setting extends\nthe action dependent framework of [1] and as a special case recovers the\nresults of few previously considered joint communication and estimation\nscenarios in [2], [3], [4]. The scenario when the action is also allowed to\ndepend on the past observed states (adaptive action) is also considered. It is\nshown that such adaptive action yields an improved capacity-distortion\nfunction. \n\n"}
{"id": "1202.0979", "contents": "Title: Spatially-Coupled Binary MacKay-Neal Codes for Channels with Non-Binary\n  Inputs and Affine Subspace Outputs Abstract: We study LDPC codes for the channel with $2^m$-ary input $\\underline{x}\\in\n\\mathbb{F}_2^m$ and output $\\underline{y}=\\underline{x}+\\underline{z}\\in\n\\mathbb{F}_2^m$. The receiver knows a subspace $V\\subset \\mathbb{F}_2^m$ from\nwhich $\\underline{z}=\\underline{y}-\\underline{x}$ is uniformly chosen. Or\nequivalently, the receiver receives an affine subspace $\\underline{y}-V$ where\n$\\underline{x}$ lies. We consider a joint iterative decoder involving the\nchannel detector and the LDPC decoder. The decoding system considered in this\npaper can be viewed as a simplified model of the joint iterative decoder over\nnon-binary modulated signal inputs e.g., $2^m$-QAM. We evaluate the performance\nof binary spatially-coupled MacKay-Neal codes by density evolution. The\niterative decoding threshold is seriously degraded by increasing $m$. EXIT-like\nfunction curve calculations reveal that this degradation is caused by wiggles\nand can be mitigated by increasing the randomized window size. The resultant\niterative decoding threshold values are very close to the Shannon limit. \n\n"}
{"id": "1202.2251", "contents": "Title: Hierarchies of Local-Optimality Characterizations in Decoding of Tanner\n  Codes Abstract: Recent developments in decoding of Tanner codes with maximum-likelihood\ncertificates are based on a sufficient condition called local-optimality. We\ndefine hierarchies of locally-optimal codewords with respect to two parameters.\nOne parameter is related to the minimum distance of the local codes in Tanner\ncodes. The second parameter is related to the finite number of iterations used\nin iterative decoding. We show that these hierarchies satisfy inclusion\nproperties as these parameters are increased. In particular, this implies that\na codeword that is decoded with a certificate using an iterative decoder after\n$h$ iterations is decoded with a certificate after $k\\cdot h$ iterations, for\nevery integer $k$. \n\n"}
{"id": "1202.2414", "contents": "Title: Optimal Linear Codes with a Local-Error-Correction Property Abstract: Motivated by applications to distributed storage, Gopalan \\textit{et al}\nrecently introduced the interesting notion of information-symbol locality in a\nlinear code. By this it is meant that each message symbol appears in a\nparity-check equation associated with small Hamming weight, thereby enabling\nrecovery of the message symbol by examining a small number of other code\nsymbols. This notion is expanded to the case when all code symbols, not just\nthe message symbols, are covered by such \"local\" parity. In this paper, we\nextend the results of Gopalan et. al. so as to permit recovery of an erased\ncode symbol even in the presence of errors in local parity symbols. We present\ntight bounds on the minimum distance of such codes and exhibit codes that are\noptimal with respect to the local error-correction property. As a corollary, we\nobtain an upper bound on the minimum distance of a concatenated code. \n\n"}
{"id": "1202.2826", "contents": "Title: Error Floor Approximation for LDPC Codes in the AWGN Channel Abstract: This paper addresses the prediction of error floors of low-density\nparity-check (LDPC) codes with variable nodes of constant degree in the\nadditive white Gaussian noise (AWGN) channel. Specifically, we focus on the\nperformance of the sum-product algorithm (SPA) decoder formulated in the\nlog-likelihood ratio (LLR) domain. We hypothesize that several published error\nfloor levels are due to the manner in which decoder implementations handled the\nLLRs at high SNRs. We employ an LLR-domain SPA decoder that does not saturate\nnear-certain messages and find the error rates of our decoder to be lower by at\nleast several orders of magnitude. We study the behavior of trapping sets (or\nnear-codewords) that are the dominant cause of the reported error floors.\n  We develop a refined linear model, based on the work of Sun and others, that\naccurately predicts error floors caused by elementary tapping sets for\nsaturating decoders. Performance results of several codes at several levels of\ndecoder saturation are presented. \n\n"}
{"id": "1202.4959", "contents": "Title: Lossy Source Coding via Spatially Coupled LDGM Ensembles Abstract: We study a new encoding scheme for lossy source compression based on\nspatially coupled low-density generator-matrix codes. We develop a\nbelief-propagation guided-decimation algorithm, and show that this algorithm\nallows to approach the optimal distortion of spatially coupled ensembles.\nMoreover, using the survey propagation formalism, we also observe that the\noptimal distortions of the spatially coupled and individual code ensembles are\nthe same. Since regular low-density generator-matrix codes are known to achieve\nthe Shannon rate-distortion bound under optimal encoding as the degrees grow,\nour results suggest that spatial coupling can be used to reach the\nrate-distortion bound, under a {\\it low complexity} belief-propagation\nguided-decimation algorithm.\n  This problem is analogous to the MAX-XORSAT problem in computer science. \n\n"}
{"id": "1203.1528", "contents": "Title: A Two-Dimensional Signal Space for Intensity-Modulated Channels Abstract: A two-dimensional signal space for intensity- modulated channels is\npresented. Modulation formats using this signal space are designed to maximize\nthe minimum distance between signal points while satisfying average and peak\npower constraints. The uncoded, high-signal-to-noise ratio, power and spectral\nefficiencies are compared to those of the best known formats. The new formats\nare simpler than existing subcarrier formats, and are superior if the bandwidth\nis measured as 90% in-band power. Existing subcarrier formats are better if the\nbandwidth is measured as 99% in-band power. \n\n"}
{"id": "1203.1804", "contents": "Title: Near-Optimal Compressive Binary Search Abstract: We propose a simple modification to the recently proposed compressive binary\nsearch. The modification removes an unnecessary and suboptimal factor of log\nlog n from the SNR requirement, making the procedure optimal (up to a small\nconstant). Simulations show that the new procedure performs significantly\nbetter in practice as well. We also contrast this problem with the more well\nknown problem of noisy binary search. \n\n"}
{"id": "1203.2468", "contents": "Title: Diversity, Coding, and Multiplexing Trade-Off of Network-Coded\n  Cooperative Wireless Networks Abstract: In this paper, we study the performance of network-coded cooperative\ndiversity systems with practical communication constraints. More specifically,\nwe investigate the interplay between diversity, coding, and multiplexing gain\nwhen the relay nodes do not act as dedicated repeaters, which only forward data\npackets transmitted by the sources, but they attempt to pursue their own\ninterest by forwarding packets which contain a network-coded version of\nreceived and their own data. We provide a very accurate analysis of the Average\nBit Error Probability (ABEP) for two network topologies with three and four\nnodes, when practical communication constraints, i.e., erroneous decoding at\nthe relays and fading over all the wireless links, are taken into account.\nFurthermore, diversity and coding gain are studied, and advantages and\ndisadvantages of cooperation and binary Network Coding (NC) are highlighted.\nOur results show that the throughput increase introduced by NC is offset by a\nloss of diversity and coding gain. It is shown that there is neither a coding\nnor a diversity gain for the source node when the relays forward a\nnetwork-coded version of received and their own data. Compared to other results\navailable in the literature, the conclusion is that binary NC seems to be more\nuseful when the relay nodes act only on behalf of the source nodes, and do not\nmix their own packets to the received ones. Analytical derivation and findings\nare substantiated through extensive Monte Carlo simulations. \n\n"}
{"id": "1203.3002", "contents": "Title: A Proximal-Gradient Homotopy Method for the Sparse Least-Squares Problem Abstract: We consider solving the $\\ell_1$-regularized least-squares ($\\ell_1$-LS)\nproblem in the context of sparse recovery, for applications such as compressed\nsensing. The standard proximal gradient method, also known as iterative\nsoft-thresholding when applied to this problem, has low computational cost per\niteration but a rather slow convergence rate. Nevertheless, when the solution\nis sparse, it often exhibits fast linear convergence in the final stage. We\nexploit the local linear convergence using a homotopy continuation strategy,\ni.e., we solve the $\\ell_1$-LS problem for a sequence of decreasing values of\nthe regularization parameter, and use an approximate solution at the end of\neach stage to warm start the next stage. Although similar strategies have been\nstudied in the literature, there have been no theoretical analysis of their\nglobal iteration complexity. This paper shows that under suitable assumptions\nfor sparse recovery, the proposed homotopy strategy ensures that all iterates\nalong the homotopy solution path are sparse. Therefore the objective function\nis effectively strongly convex along the solution path, and geometric\nconvergence at each stage can be established. As a result, the overall\niteration complexity of our method is $O(\\log(1/\\epsilon))$ for finding an\n$\\epsilon$-optimal solution, which can be interpreted as global geometric rate\nof convergence. We also present empirical results to support our theoretical\nanalysis. \n\n"}
{"id": "1203.3037", "contents": "Title: Expanding the Transfer Entropy to Identify Information Subgraphs in\n  Complex Systems Abstract: We propose a formal expansion of the transfer entropy to put in evidence\nirreducible sets of variables which provide information for the future state of\neach assigned target. Multiplets characterized by a large contribution to the\nexpansion are associated to informational circuits present in the system, with\nan informational character which can be associated to the sign of the\ncontribution. For the sake of computational complexity, we adopt the assumption\nof Gaussianity and use the corresponding exact formula for the conditional\nmutual information. We report the application of the proposed methodology on\ntwo EEG data sets. \n\n"}
{"id": "1203.3269", "contents": "Title: Physical Layer Network Coding for Two-Way Relaying with QAM and Latin\n  Squares Abstract: The design of modulation schemes for the physical layer network-coded two way\nrelaying scenario has been extensively studied recently with the protocol which\nemploys two phases: Multiple access (MA) Phase and Broadcast (BC) Phase. It was\nobserved by Koike-Akino et al. that adaptively changing the network coding map\nused at the relay according to the channel conditions greatly reduces the\nimpact of multiple access interference which occurs at the relay during the MA\nPhase and all these network coding maps should satisfy a requirement called the\nexclusive law. Only the scenario in which the end nodes use M-PSK signal sets\nis extensively studied in \\cite{NVR} using Latin Sqaures. In this paper, we\naddress the case in which the end nodes use M-QAM signal sets (where M is of\nthe form $2^{2\\lambda}$, $\\lambda$ being any positive integer). In a fading\nscenario, for certain channel conditions $\\gamma e^{j \\theta}$, termed singular\nfade states, the MA phase performance is greatly reduced. We show that the\nsquare QAM signal sets give lesser number of singular fade states compared to\nPSK signal sets. Because of this, the complexity at the relay is enormously\nreduced. Moreover, lesser number of overhead bits are required in the BC phase.\nThe fade state $\\gamma e^{j \\theta}=1$ is singular for all constellations of\narbitrary size including PSK and QAM. For arbitrary PSK constellation it is\nwell known that the Latin Square obtained by bit-wise XOR mapping removes this\nsingularity. We show that XOR mapping fails to remove this singularity for QAM\nof size more greater than 4 and show that a doubly block circulant Latin Square\nremoves this singularity. Simulation results are presented to show the\nsuperiority of QAM over PSK. \n\n"}
{"id": "1203.3322", "contents": "Title: A note on Shannon entropy Abstract: We present a somewhat different way of looking on Shannon entropy. This leads\nto an axiomatisation of Shannon entropy that is essentially equivalent to that\nof Fadeev. In particular we give a new proof of Fadeev theorem. \n\n"}
{"id": "1203.4882", "contents": "Title: Large-System Analysis of Joint User Selection and Vector Precoding with\n  Zero-Forcing Transmit Beamforming for MIMO Broadcast Channels Abstract: Multiple-input multiple-output (MIMO) broadcast channels (BCs) (MIMO-BCs)\nwith perfect channel state information (CSI) at the transmitter are considered.\nAs joint user selection (US) and vector precoding (VP) (US-VP) with\nzero-forcing transmit beamforming (ZF-BF), US and continuous VP (CVP) (US-CVP)\nand data-dependent US (DD-US) are investigated. The replica method, developed\nin statistical physics, is used to analyze the energy penalties for the two\nUS-VP schemes in the large-system limit, where the number of users, the number\nof selected users, and the number of transmit antennas tend to infinity with\ntheir ratios kept constant. Four observations are obtained in the large-system\nlimit: First, the assumptions of replica symmetry (RS) and 1-step replica\nsymmetry breaking (1RSB) for DD-US can provide acceptable approximations for\nlow and moderate system loads, respectively. Secondly, DD-US outperforms CVP\nwith random US in terms of the energy penalty for low-to-moderate system loads.\nThirdly, the asymptotic energy penalty of DD-US is indistinguishable from that\nof US-CVP for low system loads. Finally, a greedy algorithm of DD-US proposed\nin authors' previous work can achieve nearly optimal performance for\nlow-to-moderate system loads. \n\n"}
{"id": "1203.5362", "contents": "Title: Throughput Optimal Scheduling with Dynamic Channel Feedback Abstract: It is well known that opportunistic scheduling algorithms are throughput\noptimal under full knowledge of channel and network conditions. However, these\nalgorithms achieve a hypothetical achievable rate region which does not take\ninto account the overhead associated with channel probing and feedback required\nto obtain the full channel state information at every slot. We adopt a channel\nprobing model where $\\beta$ fraction of time slot is consumed for acquiring the\nchannel state information (CSI) of a single channel. In this work, we design a\njoint scheduling and channel probing algorithm named SDF by considering the\noverhead of obtaining the channel state information. We first analytically\nprove SDF algorithm can support $1+\\epsilon$ fraction of of the full rate\nregion achieved when all users are probed where $\\epsilon$ depends on the\nexpected number of users which are not probed. Then, for homogenous channel, we\nshow that when the number of users in the network is greater than 3, $\\epsilon\n> 0$, i.e., we guarantee to expand the rate region. In addition, for\nheterogenous channels, we prove the conditions under which SDF guarantees to\nincrease the rate region. We also demonstrate numerically in a realistic\nsimulation setting that this rate region can be achieved by probing only less\nthan 50% of all channels in a CDMA based cellular network utilizing high data\nrate protocol under normal channel conditions. \n\n"}
{"id": "1203.5915", "contents": "Title: On the Feasibility of Network Alignment for Three-Source\n  Three-Destination Multiple Unicast Networks with Delays Abstract: A transform approach to network coding was introduced by Bavirisetti et al.\n(arXiv:1103.3882v3 [cs.IT]) as a tool to view wireline networks with delays as\n$k$-instantaneous networks (for some large $k$). When the local encoding\nkernels (LEKs) of the network are varied with every time block of length $k >\n1$, the network is said to use block time varying LEKs. In this work, we\npropose a Precoding Based Network Alignment (PBNA) scheme based on transform\napproach and block time varying LEKs for three-source three-destination\nmultiple unicast network with delays (3-S 3-D MUN-D). In a recent work, Meng et\nal. (arXiv:1202.3405v1 [cs.IT]) reduced the infinite set of sufficient\nconditions for feasibility of PBNA in a three-source three-destination\ninstantaneous multiple unicast network as given by Das et al.\n(arXiv:1008.0235v1 [cs.IT]) to a finite set and also showed that the conditions\nare necessary. We show that the conditions of Meng et al. are also necessary\nand sufficient conditions for feasibility of PBNA based on transform approach\nand block time varying LEKs for 3-S 3-D MUN-D. \n\n"}
{"id": "1203.6318", "contents": "Title: Optimal Linear Joint Source-Channel Coding with Delay Constraint Abstract: The problem of joint source-channel coding is considered for a stationary\nremote (noisy) Gaussian source and a Gaussian channel. The encoder and decoder\nare assumed to be causal and their combined operations are subject to a delay\nconstraint. It is shown that, under the mean-square error distortion metric, an\noptimal encoder-decoder pair from the linear and time-invariant (LTI) class can\nbe found by minimization of a convex functional and a spectral factorization.\nThe functional to be minimized is the sum of the well-known cost in a\ncorresponding Wiener filter problem and a new term, which is induced by the\nchannel noise and whose coefficient is the inverse of the channel's\nsignal-to-noise ratio. This result is shown to also hold in the case of\nvector-valued signals, assuming parallel additive white Gaussian noise\nchannels. It is also shown that optimal LTI encoders and decoders generally\nrequire infinite memory, which implies that approximations are necessary. A\nnumerical example is provided, which compares the performance to the lower\nbound provided by rate-distortion theory. \n\n"}
{"id": "1203.6791", "contents": "Title: Relative Information Loss - An Introduction Abstract: We introduce a relative variant of information loss to characterize the\nbehavior of deterministic input-output systems. We show that the relative loss\nis closely related to Renyi's information dimension. We provide an upper bound\nfor continuous input random variables and an exact result for a class of\nfunctions (comprising quantizers) with infinite absolute information loss. A\nconnection between relative information loss and reconstruction error is\ninvestigated. \n\n"}
{"id": "1204.0173", "contents": "Title: On The Achievable Rate Region of a New Wiretap Channel With Side\n  Information Abstract: A new applicable wiretap channel with separated side information is\nconsidered here which consist of a sender, a legitimate receiver and a\nwiretapper. In the considered scenario, the links from the transmitter to the\nlegitimate receiver and the eavesdropper experience different conditions or\nchannel states. So, the legitimate receiver and the wiretapper listen to the\ntransmitted signal through the channels with different channel states which may\nhave some correlation to each other. It is assumed that the transmitter knows\nthe state of the main channel non-causally and uses this knowledge to encode\nits message. The state of the wiretap channel is not known anywhere. An\nachievable equivocation rate region is derived for this model and is compared\nto the existing works. In some special cases, the results are extended to the\nGaussian wiretap channel. \n\n"}
{"id": "1204.2035", "contents": "Title: Wireless Information Transfer with Opportunistic Energy Harvesting Abstract: Energy harvesting is a promising solution to prolong the operation of\nenergy-constrained wireless networks. In particular, scavenging energy from\nambient radio signals, namely wireless energy harvesting (WEH), has recently\ndrawn significant attention. In this paper, we consider a point-to-point\nwireless link over the narrowband flat-fading channel subject to time-varying\nco-channel interference. It is assumed that the receiver has no fixed power\nsupplies and thus needs to replenish energy opportunistically via WEH from the\nunintended interference and/or the intended signal sent by the transmitter. We\nfurther assume a single-antenna receiver that can only decode information or\nharvest energy at any time due to the practical circuit limitation. Therefore,\nit is important to investigate when the receiver should switch between the two\nmodes of information decoding (ID) and energy harvesting (EH), based on the\ninstantaneous channel and interference condition. In this paper, we derive the\noptimal mode switching rule at the receiver to achieve various trade-offs\nbetween wireless information transfer and energy harvesting. Specifically, we\ndetermine the minimum transmission outage probability for delay-limited\ninformation transfer and the maximum ergodic capacity for no-delay-limited\ninformation transfer versus the maximum average energy harvested at the\nreceiver, which are characterized by the boundary of so-called \"outage-energy\"\nregion and \"rate-energy\" region, respectively. Moreover, for the case when the\nchannel state information (CSI) is known at the transmitter, we investigate the\njoint optimization of transmit power control, information and energy transfer\nscheduling, and the receiver's mode switching. Our results provide useful\nguidelines for the efficient design of emerging wireless communication systems\npowered by opportunistic WEH. \n\n"}
{"id": "1204.3742", "contents": "Title: Distributed Iterative Processing for Interference Channels with Receiver\n  Cooperation Abstract: We propose a framework for the derivation and evaluation of distributed\niterative algorithms for receiver cooperation in interference-limited wireless\nsystems. Our approach views the processing within and collaboration between\nreceivers as the solution to an inference problem in the probabilistic model of\nthe whole system. The probabilistic model is formulated to explicitly\nincorporate the receivers' ability to share information of a predefined type.\nWe employ a recently proposed unified message-passing tool to infer the\nvariables of interest in the factor graph representation of the probabilistic\nmodel. The exchange of information between receivers arises in the form of\npassing messages along some specific edges of the factor graph; the rate of\nupdating and passing these messages determines the communication overhead\nassociated with cooperation. Simulation results illustrate the high performance\nof the proposed algorithm even with a low number of message exchanges between\nreceivers. \n\n"}
{"id": "1205.1173", "contents": "Title: Subset Typicality Lemmas and Improved Achievable Regions in\n  Multiterminal Source Coding Abstract: Consider the following information theoretic setup wherein independent\ncodebooks of N correlated random variables are generated according to their\nrespective marginals. The problem of determining the conditions on the rates of\ncodebooks to ensure the existence of at least one codeword tuple which is\njointly typical with respect to a given joint density (called the multivariate\ncovering lemma) has been studied fairly well and the associated rate regions\nhave found applications in several source coding scenarios. However, several\nmultiterminal source coding applications, such as the general multi-user\nGray-Wyner network, require joint typicality only within subsets of codewords\ntransmitted. Motivated by such applications, we ask ourselves the conditions on\nthe rates to ensure the existence of at least one codeword tuple which is\njointly typical within subsets according to given per subset joint densities.\nThis report focuses primarily on deriving a new achievable rate region for this\nproblem which strictly improves upon the direct extension of the multivariate\ncovering lemma, which has quite popularly been used in several earlier work.\nTowards proving this result, we derive two important results called `subset\ntypicality lemmas' which can potentially have broader applicability in more\ngeneral scenarios beyond what is considered in this report. We finally apply\nthe results therein to derive a new achievable region for the general\nmulti-user Gray-Wyner network. \n\n"}
{"id": "1205.5729", "contents": "Title: Blind Reconciliation Abstract: Information reconciliation is a crucial procedure in the classical\npost-processing of quantum key distribution (QKD). Poor reconciliation\nefficiency, revealing more information than strictly needed, may compromise the\nmaximum attainable distance, while poor performance of the algorithm limits the\npractical throughput in a QKD device. Historically, reconciliation has been\nmainly done using close to minimal information disclosure but heavily\ninteractive procedures, like Cascade, or using less efficient but also less\ninteractive -just one message is exchanged- procedures, like the ones based in\nlow-density parity-check (LDPC) codes. The price to pay in the LDPC case is\nthat good efficiency is only attained for very long codes and in a very narrow\nrange centered around the quantum bit error rate (QBER) that the code was\ndesigned to reconcile, thus forcing to have several codes if a broad range of\nQBER needs to be catered for. Real world implementations of these methods are\nthus very demanding, either on computational or communication resources or\nboth, to the extent that the last generation of GHz clocked QKD systems are\nfinding a bottleneck in the classical part. In order to produce compact, high\nperformance and reliable QKD systems it would be highly desirable to remove\nthese problems. Here we analyse the use of short-length LDPC codes in the\ninformation reconciliation context using a low interactivity, blind, protocol\nthat avoids an a priori error rate estimation. We demonstrate that 2x10^3 bits\nlength LDPC codes are suitable for blind reconciliation. Such codes are of high\ninterest in practice, since they can be used for hardware implementations with\nvery high throughput. \n\n"}
{"id": "1206.0773", "contents": "Title: Changepoint Detection over Graphs with the Spectral Scan Statistic Abstract: We consider the change-point detection problem of deciding, based on noisy\nmeasurements, whether an unknown signal over a given graph is constant or is\ninstead piecewise constant over two connected induced subgraphs of relatively\nlow cut size. We analyze the corresponding generalized likelihood ratio (GLR)\nstatistics and relate it to the problem of finding a sparsest cut in a graph.\nWe develop a tractable relaxation of the GLR statistic based on the\ncombinatorial Laplacian of the graph, which we call the spectral scan\nstatistic, and analyze its properties. We show how its performance as a testing\nprocedure depends directly on the spectrum of the graph, and use this result to\nexplicitly derive its asymptotic properties on few significant graph\ntopologies. Finally, we demonstrate both theoretically and by simulations that\nthe spectral scan statistic can outperform naive testing procedures based on\nedge thresholding and $\\chi^2$ testing. \n\n"}
{"id": "1206.2459", "contents": "Title: R\\'enyi Divergence and Kullback-Leibler Divergence Abstract: R\\'enyi divergence is related to R\\'enyi entropy much like Kullback-Leibler\ndivergence is related to Shannon's entropy, and comes up in many settings. It\nwas introduced by R\\'enyi as a measure of information that satisfies almost the\nsame axioms as Kullback-Leibler divergence, and depends on a parameter that is\ncalled its order. In particular, the R\\'enyi divergence of order 1 equals the\nKullback-Leibler divergence.\n  We review and extend the most important properties of R\\'enyi divergence and\nKullback-Leibler divergence, including convexity, continuity, limits of\n$\\sigma$-algebras and the relation of the special order 0 to the Gaussian\ndichotomy and contiguity. We also show how to generalize the Pythagorean\ninequality to orders different from 1, and we extend the known equivalence\nbetween channel capacity and minimax redundancy to continuous channel inputs\n(for all orders) and present several other minimax results. \n\n"}
{"id": "1206.2961", "contents": "Title: Epistemic view of quantum states and communication complexity of quantum\n  channels Abstract: The communication complexity of a quantum channel is the minimal amount of\nclassical communication required for classically simulating a process of state\npreparation, transmission through the channel and subsequent measurement. It\nestablishes a limit on the power of quantum communication in terms of classical\nresources. We show that classical simulations employing a finite amount of\ncommunication can be derived from a special class of hidden variable theories\nwhere quantum states represent statistical knowledge about the classical state\nand not an element of reality. This special class has attracted strong interest\nvery recently. The communication cost of each derived simulation is given by\nthe mutual information between the quantum state and the classical state of the\nparent hidden variable theory. Finally, we find that the communication\ncomplexity for single qubits is smaller than 1.28 bits. The previous known\nupper bound was 1.85 bits. \n\n"}
{"id": "1206.3138", "contents": "Title: On Modulo-Sum Computation over an Erasure Multiple Access Channel Abstract: We study computation of a modulo-sum of two binary source sequences over a\ntwo-user erasure multiple access channel. The channel is modeled as a\nbinary-input, erasure multiple access channel, which can be in one of three\nstates - either the channel output is a modulo-sum of the two input symbols, or\nthe channel output equals the input symbol on the first link and an erasure on\nthe second link, or vice versa. The associated state sequence is independent\nand identically distributed. We develop a new upper bound on the sum-rate by\nrevealing only part of the state sequence to the transmitters. Our coding\nscheme is based on the compute and forward and the decode and forward\ntechniques. When a (strictly) causal feedback of the channel state is available\nto the encoders, we show that the modulo-sum capacity is increased. Extensions\nto the case of lossy reconstruction of the modulo-sum and to channels involving\nadditional states are also treated briefly. \n\n"}
{"id": "1206.5144", "contents": "Title: Signal Processing and Optimal Resource Allocation for the Interference\n  Channel Abstract: In this article, we examine several design and complexity aspects of the\noptimal physical layer resource allocation problem for a generic interference\nchannel (IC). The latter is a natural model for multi-user communication\nnetworks. In particular, we characterize the computational complexity, the\nconvexity as well as the duality of the optimal resource allocation problem.\nMoreover, we summarize various existing algorithms for resource allocation and\ndiscuss their complexity and performance tradeoff. We also mention various open\nresearch problems throughout the article. \n\n"}
{"id": "1206.5184", "contents": "Title: Symmetry of Information: A Closer Look Abstract: Symmetry of information establishes a relation between the information that x\nhas about y (denoted I(x : y)) and the information that y has about x (denoted\nI(y : x)). In classical information theory, the two are exactly equal, but in\nalgorithmical information theory, there is a small excess quantity of\ninformation that differentiates the two terms, caused by the necessity of\npackaging information in a way that makes it accessible to algorithms. It was\nshown in [Zim11] that in the case of strings with simple complexity (that is\nthe Kolmogorov complexity of their Kolmogorov complexity is small), the\nrelevant information can be packed in a very economical way, which leads to a\ntighter relation between I(x : y) and I(y : x) than the one provided in the\nclassical symmetry-of-information theorem of Kolmogorov and Levin. We give here\na simpler proof of this result, using a suggestion of Alexander Shen. This\nresult implies a van Lambalgen- type theorem for finite strings and plain\ncomplexity: If x is c-random and y is c-random relative to x, then xy is\nO(c)-random. We show that a similar result holds for prefix-free complexity and\nweak-K-randomness. \n\n"}
{"id": "1206.6918", "contents": "Title: Source-Channel Coding for the Multiple-Access Relay Channel Abstract: This work considers reliable transmission of general correlated sources over\nthe multiple-access relay channel (MARC) and the multiple-access broadcast\nrelay channel (MABRC). In MARCs only the destination is interested in a\nreconstruction of the sources, while in MABRCs both the relay and the\ndestination want to reconstruct the sources. We assume that both the relay and\nthe destination have correlated side information. We find sufficient conditions\nfor reliable communication based on operational separation, as well as\nnecessary conditions on the achievable source-channel rate. For correlated\nsources transmitted over fading Gaussian MARCs and MABRCs we find conditions\nunder which informational separation is optimal. \n\n"}
{"id": "1207.2079", "contents": "Title: Compressed Sensing of Approximately-Sparse Signals: Phase Transitions\n  and Optimal Reconstruction Abstract: Compressed sensing is designed to measure sparse signals directly in a\ncompressed form. However, most signals of interest are only \"approximately\nsparse\", i.e. even though the signal contains only a small fraction of relevant\n(large) components the other components are not strictly equal to zero, but are\nonly close to zero. In this paper we model the approximately sparse signal with\na Gaussian distribution of small components, and we study its compressed\nsensing with dense random matrices. We use replica calculations to determine\nthe mean-squared error of the Bayes-optimal reconstruction for such signals, as\na function of the variance of the small components, the density of large\ncomponents and the measurement rate. We then use the G-AMP algorithm and we\nquantify the region of parameters for which this algorithm achieves optimality\n(for large systems). Finally, we show that in the region where the GAMP for the\nhomogeneous measurement matrices is not optimal, a special \"seeding\" design of\na spatially-coupled measurement matrix allows to restore optimality. \n\n"}
{"id": "1207.3269", "contents": "Title: The Price of Privacy in Untrusted Recommendation Engines Abstract: Recent increase in online privacy concerns prompts the following question:\ncan a recommender system be accurate if users do not entrust it with their\nprivate data? To answer this, we study the problem of learning item-clusters\nunder local differential privacy, a powerful, formal notion of data privacy. We\ndevelop bounds on the sample-complexity of learning item-clusters from\nprivatized user inputs. Significantly, our results identify a sample-complexity\nseparation between learning in an information-rich and an information-scarce\nregime, thereby highlighting the interaction between privacy and the amount of\ninformation (ratings) available to each user.\n  In the information-rich regime, where each user rates at least a constant\nfraction of items, a spectral clustering approach is shown to achieve a\nsample-complexity lower bound derived from a simple information-theoretic\nargument based on Fano's inequality. However, the information-scarce regime,\nwhere each user rates only a vanishing fraction of items, is found to require a\nfundamentally different approach both for lower bounds and algorithms. To this\nend, we develop new techniques for bounding mutual information under a notion\nof channel-mismatch, and also propose a new algorithm, MaxSense, and show that\nit achieves optimal sample-complexity in this setting.\n  The techniques we develop for bounding mutual information may be of broader\ninterest. To illustrate this, we show their applicability to $(i)$ learning\nbased on 1-bit sketches, and $(ii)$ adaptive learning, where queries can be\nadapted based on answers to past queries. \n\n"}
{"id": "1207.5010", "contents": "Title: The GDOF of 3-user MIMO Gaussian interference channel Abstract: The paper establishes the optimal generalized degrees of freedom (GDOF) of\n3-user $M \\times N$ multiple-input multiple-output (MIMO) Gaussian interference\nchannel (GIC) in which each transmitter has $M$ antennas and each receiver has\n$N$ antennas. A constraint of $2M \\leq N$ is imposed so that random coding with\nmessage-splitting achieves the optimal GDOF. Unlike symmetric case, two cross\nchannels to unintended receivers from each transmitter can have different\nstrengths, and hence, well known Han-Kobayashi common-private message splitting\nwould not achieve the optimal GDOF. Instead, splitting each user's message into\nthree parts is shown to achieve the optimal GDOF. The capacity of the\ncorresponding deterministic model is first established which provides\nsystematic way of determining side information for converse. Although this\ndeterministic model is philosophically similar to the one considered by Gou and\nJafar, additional constraints are imposed so that capacity description of the\ndeterministic model only contains the essential terms for establishing the GDOF\nof Gaussian case. Based on this, the optimal GDOF of Gaussian case is\nestablished with $\\mathcal{O}(1)$ capacity approximation. The behavior of the\nGDOF is interestingly different from that of the corresponding symmetric case.\nRegarding the converse, several multiuser outer bounds which are suitable for\nasymmetric case are derived by non-trivial generalization of the symmetric\ncase. \n\n"}
{"id": "1207.5216", "contents": "Title: A colouring protocol for the generalized Russian cards problem Abstract: In the generalized Russian cards problem, Alice, Bob and Cath draw $a$, $b$\nand $c$ cards, respectively, from a deck of size $a+b+c$. Alice and Bob must\nthen communicate their entire hand to each other, without Cath learning the\nowner of a single card she does not hold. Unlike many traditional problems in\ncryptography, however, they are not allowed to encode or hide the messages they\nexchange from Cath. The problem is then to find methods through which they can\nachieve this. We propose a general four-step solution based on finite vector\nspaces, and call it the \"colouring protocol\", as it involves colourings of\nlines.\n  Our main results show that the colouring protocol may be used to solve the\ngeneralized Russian cards problem in cases where $a$ is a power of a prime,\n$c=O(a^2)$ and $b=O(c^2)$. This improves substantially on the set of parameters\nfor which solutions are known to exist; in particular, it had not been shown\npreviously that the problem could be solved in cases where the eavesdropper has\nmore cards than one of the communicating players. \n\n"}
{"id": "1207.5660", "contents": "Title: Achieving the Capacity of the N-Relay Gaussian Diamond Network Within\n  log N Bits Abstract: We consider the N-relay Gaussian diamond network where a source node\ncommunicates to a destination node via N parallel relays through a cascade of a\nGaussian broadcast (BC) and a multiple access (MAC) channel. Introduced in 2000\nby Schein and Gallager, the capacity of this relay network is unknown in\ngeneral. The best currently available capacity approximation, independent of\nthe coefficients and the SNR's of the constituent channels, is within an\nadditive gap of 1.3 N bits, which follows from the recent capacity\napproximations for general Gaussian relay networks with arbitrary topology.\n  In this paper, we approximate the capacity of this network within 2 log N\nbits. We show that two strategies can be used to achieve the\ninformation-theoretic cutset upper bound on the capacity of the network up to\nan additive gap of O(log N) bits, independent of the channel configurations and\nthe SNR's. The first of these strategies is simple partial decode-and-forward.\nHere, the source node uses a superposition codebook to broadcast independent\nmessages to the relays at appropriately chosen rates; each relay decodes its\nintended message and then forwards it to the destination over the MAC channel.\nA similar performance can be also achieved with compress-and-forward type\nstrategies (such as quantize-map-and-forward and noisy network coding) that\nprovide the 1.3 N-bit approximation for general Gaussian networks, but only if\nthe relays quantize their observed signals at a resolution inversely\nproportional to the number of relay nodes N. This suggest that the\nrule-of-thumb to quantize the received signals at the noise level in the\ncurrent literature can be highly suboptimal. \n\n"}
{"id": "1208.1151", "contents": "Title: Classical-Quantum Arbitrarily Varying Wiretap Channel Abstract: We derive a lower bound on the capacity of classical-quantum arbitrarily\nvarying wiretap channel and determine the capacity of the classicalquantum\narbitrarily varying wiretap channel with channel state information at the\ntransmitter. \n\n"}
{"id": "1208.3790", "contents": "Title: Secret Key Generation from Sparse Wireless Channels: Ergodic Capacity\n  and Secrecy Outage Abstract: This paper investigates generation of a secret key from a reciprocal wireless\nchannel. In particular we consider wireless channels that exhibit sparse\nstructure in the wideband regime and the impact of the sparsity on the secret\nkey capacity. We explore this problem in two steps. First, we study key\ngeneration from a state-dependent discrete memoryless multiple source. The\nstate of source captures the effect of channel sparsity. Secondly, we consider\na wireless channel model that captures channel sparsity and correlation between\nthe legitimate users' channel and the eavesdropper's channel. Such dependency\ncan significantly reduce the secret key capacity.\n  According to system delay requirements, two performance measures are\nconsidered: (i) ergodic secret key capacity and (ii) outage probability. We\nshow that in the wideband regime when a white sounding sequence is adopted, a\nsparser channel can achieve a higher ergodic secret key rate than a richer\nchannel can. For outage performance, we show that if the users generate secret\nkeys at a fraction of the ergodic capacity, the outage probability will decay\nexponentially in signal bandwidth. Moreover, a larger exponent is achieved by a\nricher channel. \n\n"}
{"id": "1208.3984", "contents": "Title: On the Capacity of the Cognitive Interference Channel with a Common\n  Cognitive Message Abstract: In this paper the cognitive interference channel with a common message, a\nvariation of the classical cognitive interference channel in which the\ncognitive message is decoded at both receivers, is studied. For this channel\nmodel new outer and inner bounds are developed as well as new capacity results\nfor both the discrete memoryless and the Gaussian case. The outer bounds are\nderived using bounding techniques originally developed by Sato for the\nclassical interference channel and Nair and El Gamal for the broadcast channel.\nA general inner bound is obtained combining rate-splitting, superposition\ncoding and binning. Inner and outer bounds are shown to coincide in the \"very\nstrong interference\" and the \"primary decodes cognitive\" regimes. The first\nregime consists of channels in which there is no loss of optimality in having\nboth receivers decode both messages while in the latter regime interference\npre-cancellation at the cognitive receiver achieves capacity. Capacity for the\nGaussian channel is shown to within a constant additive gap and a constant\nmultiplicative factor. \n\n"}
{"id": "1209.0047", "contents": "Title: The Degrees of Freedom Region of the MIMO Interference Channel with\n  Hybrid CSIT Abstract: The degrees of freedom (DoF) region of the two-user MIMO (multiple-input\nmultiple-output) interference channel is established under a new model termed\nas hybrid CSIT. In this model, one transmitter has delayed channel state\ninformation (CSI) and the other transmitter has instantaneous CSIT, of incoming\nchannel matrices at the respective unpaired receivers, and neither transmitter\nhas any knowledge of the incoming channel matrices of its respective paired\nreceiver. The DoF region for hybrid CSIT, and consequently that of\n$2\\times2\\times3^{5}$ CSIT models, is completely characterized, and a new\nachievable scheme based on a combination of transmit beamforming and\nretrospective interference alignment is developed. Conditions are obtained on\nthe numbers of antennas at each of the four terminals such that the DoF region\nunder hybrid CSIT is equal to that under (a) global and instantaneous CSIT and\n(b) global and delayed CSIT, with the remaining cases resulting in a DoF region\nwith hybrid CSIT that lies somewhere in between the DoF regions under the\ninstantaneous and delayed CSIT settings. Further synergistic benefits accruing\nfrom switching between the two hybrid CSIT models are also explored. \n\n"}
{"id": "1209.1150", "contents": "Title: On dually flat Randers metrics Abstract: In this paper, I will show how to use beta-deformations to deal with dual\nflatness of Randers metrics. beta-deformations is a new method in\nRiemann-Finsler geometry, it is introduced by the author(see arxiv:1209.0845).\nLater on I will provide more applications of the new kind of deformations in\nFinsler geometry. \n\n"}
{"id": "1209.1679", "contents": "Title: Bayesian Quantized Network Coding via Belief Propagation Abstract: In this paper, we propose an alternative for routing based packet forwarding,\nwhich uses network coding to increase transmission efficiency, in terms of both\ncompression and error resilience. This non-adaptive encoding is called\nquantized network coding, which involves random linear mapping in the real\nfield, followed by quantization to cope with the finite capacity of the links.\nAt the gateway node, which collects received quantized network coder packets,\nminimum mean squared error decoding is performed, by using belief propagation\nin the factor graph representation. Our simulation results show a significant\nimprovement, in terms of the number of required packets to recover the\nmessages, which can be interpreted as an embedded distributed source coding for\ncorrelated messages. \n\n"}
{"id": "1209.2887", "contents": "Title: Decoding of Subspace Codes, a Problem of Schubert Calculus over Finite\n  Fields Abstract: Schubert calculus provides algebraic tools to solve enumerative problems.\nThere have been several applied problems in systems theory, linear algebra and\nphysics which were studied by means of Schubert calculus. The method is most\npowerful when the base field is algebraically closed. In this article we first\nreview some of the successes Schubert calculus had in the past. Then we show\nhow the problem of decoding of subspace codes used in random network coding can\nbe formulated as a problem in Schubert calculus. Since for this application the\nbase field has to be assumed to be a finite field new techniques will have to\nbe developed in the future. \n\n"}
{"id": "1209.3137", "contents": "Title: Diophantine Approach to Blind Interference Alignment of Homogeneous\n  K-user 2x1 MISO Broadcast Channels Abstract: Although the sufficient condition for a blindly interference-aligned (BIA)\n2-user 2x1 broadcast channel (BC) in homogeneous fading to achieve its maximal\n4/3 DoF is well understood, its counterpart for the general K-user 2x1 MISO BC\nin homogeneous block fading to achieve the corresponding 2k/(2+K-1) (DoF)\nremains unsolved and is, thus, the focus of this paper. An interference channel\nis said BIA-feasible if it achieves its maximal DoF only via BIA. In this\npaper, we cast this general feasibility problem in the framework of finding\ninteger solutions for a system of linear Diophantine equations. By assuming\nindependent user links each of the same coherence time and by studying the\nsolvability of the Diophantine system, we derive the sufficient and necessary\nconditions on the K users' fading block offsets to ensure the BIA feasibility\nof the K-user BC. If the K offsets are independent and uniformly distributed\nover a coherence block, we can further prove that 11 users are enough for one\nto find, with certainty of 95%, 3 users among them to form a BIA-feasible\n3-user 2x1 BC. \n\n"}
{"id": "1209.3505", "contents": "Title: Cognitive Energy Harvesting and Transmission from a Network Perspective Abstract: Wireless networks can be self-sustaining by harvesting energy from\nradio-frequency (RF) signals. Building on classic cognitive radio networks, we\npropose a novel method for network coexisting where mobiles from a secondary\nnetwork, called secondary transmitters (STs), either harvest energy from\ntransmissions by nearby transmitters from a primary network, called primary\ntransmitters (PTs), or transmit information if PTs are sufficiently far away;\nSTs store harvested energy in rechargeable batteries with finite capacity and\nuse all available energy for subsequent transmission when batteries are fully\ncharged. In this model, each PT is centered at a guard zone and a harvesting\nzone that are disks with given radiuses; a ST harvests energy if it lies in\nsome harvesting zone, transmits fixed-power signals if it is outside all guard\nzones or else idles. Based on this model, the spatial throughput of the\nsecondary network is maximized using a stochastic-geometry model where PTs and\nSTs are modeled as independent homogeneous Poisson point processes (HPPPs),\nunder the outage constraints for coexisting networks and obtained in a simple\nclosed-form. It is observed from the result that the maximum secondary\nthroughput decreases linearly with the growing PT density, and the optimal ST\ndensity is inversely proportional to the derived transmission probability for\nSTs. \n\n"}
{"id": "1209.4238", "contents": "Title: The Capacity of the Gaussian Cooperative Two-user Multiple Access\n  Channel to within a Constant Gap Abstract: The capacity region of the cooperative two-user Multiple Access Channel (MAC)\nin Gaussian noise is determined to within a constant gap for both the\nFull-Duplex (FD) and Half-Duplex (HD) case. The main contributions are: (a) for\nboth FD and HD: unilateral cooperation suffices to achieve capacity to within a\nconstant gap where only the user with the strongest link to the destination\nneeds to engage in cooperation, (b) for both FD and HD: backward joint decoding\nis not necessary to achieve capacity to within a constant gap, and (c) for HD:\ntime sharing between the case where the two users do not cooperate and the case\nwhere the user with the strongest link to the destination acts as pure relay\nfor the other user suffices to achieve capacity to within a constant gap. These\nfindings show that simple achievable strategies are approximately optimal for\nall channel parameters with interesting implications for practical cooperative\nschemes. \n\n"}
{"id": "1209.5221", "contents": "Title: Design of APSK Constellations for Coherent Optical Channels with\n  Nonlinear Phase Noise Abstract: We study the design of amplitude phase-shift keying (APSK) constellations for\na coherent fiber-optical communication system where nonlinear phase noise\n(NLPN) is the main system impairment. APSK constellations can be regarded as a\nunion of phase-shift keying (PSK) signal sets with different amplitude levels.\nA practical two-stage (TS) detection scheme is analyzed, which performs close\nto optimal detection for high enough input power. We optimize APSK\nconstellations with 4, 8, and 16 points in terms of symbol error probability\n(SEP) under TS detection for several combinations of input power and fiber\nlength. Our results show that APSK is a promising modulation format in order to\ncope with NLPN. As an example, for 16 points, performance gains of 3.2 dB can\nbe achieved at a SEP of 10^-2 compared to 16-QAM by choosing an optimized APSK\nconstellation. We also demonstrate that in the presence of severe nonlinear\ndistortions, it may become beneficial to sacrifice a constellation point or an\nentire constellation ring to reduce the average SEP. Finally, we discuss the\nproblem of selecting a good binary labeling for the found constellations. For\nthe class of rectangular APSK a labeling design method is proposed, resulting\nin near-optimal bit error probability. \n\n"}
{"id": "1209.5807", "contents": "Title: Fundamental Limits of Caching Abstract: Caching is a technique to reduce peak traffic rates by prefetching popular\ncontent into memories at the end users. Conventionally, these memories are used\nto deliver requested content in part from a locally cached copy rather than\nthrough the network. The gain offered by this approach, which we term local\ncaching gain, depends on the local cache size (i.e, the memory available at\neach individual user). In this paper, we introduce and exploit a second,\nglobal, caching gain not utilized by conventional caching schemes. This gain\ndepends on the aggregate global cache size (i.e., the cumulative memory\navailable at all users), even though there is no cooperation among the users.\n  To evaluate and isolate these two gains, we introduce an\ninformation-theoretic formulation of the caching problem focusing on its basic\nstructure. For this setting, we propose a novel coded caching scheme that\nexploits both local and global caching gains, leading to a multiplicative\nimprovement in the peak rate compared to previously known schemes. In\nparticular, the improvement can be on the order of the number of users in the\nnetwork. Moreover, we argue that the performance of the proposed scheme is\nwithin a constant factor of the information-theoretic optimum for all values of\nthe problem parameters. \n\n"}
{"id": "1209.6412", "contents": "Title: Integer-Forcing MIMO Linear Receivers Based on Lattice Reduction Abstract: A new architecture called integer-forcing (IF) linear receiver has been\nrecently proposed for multiple-input multiple-output (MIMO) fading channels,\nwherein an appropriate integer linear combination of the received symbols has\nto be computed as a part of the decoding process. In this paper, we propose a\nmethod based on Hermite-Korkine-Zolotareff (HKZ) and Minkowski lattice basis\nreduction algorithms to obtain the integer coefficients for the IF receiver. We\nshow that the proposed method provides a lower bound on the ergodic rate, and\nachieves the full receive diversity. Suitability of complex\nLenstra-Lenstra-Lovasz (LLL) lattice reduction algorithm (CLLL) to solve the\nproblem is also investigated. Furthermore, we establish the connection between\nthe proposed IF linear receivers and lattice reduction-aided MIMO detectors\n(with equivalent complexity), and point out the advantages of the former class\nof receivers over the latter. For the $2 \\times 2$ and $4\\times 4$ MIMO\nchannels, we compare the coded-block error rate and bit error rate of the\nproposed approach with that of other linear receivers. Simulation results show\nthat the proposed approach outperforms the zero-forcing (ZF) receiver, minimum\nmean square error (MMSE) receiver, and the lattice reduction-aided MIMO\ndetectors. \n\n"}
{"id": "1210.2592", "contents": "Title: New Generalizations of the Bethe Approximation via Asymptotic Expansion Abstract: The Bethe approximation, discovered in statistical physics, gives an\nefficient algorithm called belief propagation (BP) for approximating a\npartition function. BP empirically gives an accurate approximation for many\nproblems, e.g., low-density parity-check codes, compressed sensing, etc.\nRecently, Vontobel gives a novel characterization of the Bethe approximation\nusing graph cover. In this paper, a new approximation based on the Bethe\napproximation is proposed. The new approximation is derived from Vontobel's\ncharacterization using graph cover, and expressed by using the edge zeta\nfunction, which is related with the Hessian of the Bethe free energy as shown\nby Watanabe and Fukumizu. On some conditions, it is proved that the new\napproximation is asymptotically better than the Bethe approximation. \n\n"}
{"id": "1210.2592", "contents": "Title: New Generalizations of the Bethe Approximation via Asymptotic Expansion Abstract: The Bethe approximation, discovered in statistical physics, gives an\nefficient algorithm called belief propagation (BP) for approximating a\npartition function. BP empirically gives an accurate approximation for many\nproblems, e.g., low-density parity-check codes, compressed sensing, etc.\nRecently, Vontobel gives a novel characterization of the Bethe approximation\nusing graph cover. In this paper, a new approximation based on the Bethe\napproximation is proposed. The new approximation is derived from Vontobel's\ncharacterization using graph cover, and expressed by using the edge zeta\nfunction, which is related with the Hessian of the Bethe free energy as shown\nby Watanabe and Fukumizu. On some conditions, it is proved that the new\napproximation is asymptotically better than the Bethe approximation. \n\n"}
{"id": "1210.2748", "contents": "Title: Quantifying Causal Coupling Strength: A Lag-specific Measure For\n  Multivariate Time Series Related To Transfer Entropy Abstract: While it is an important problem to identify the existence of causal\nassociations between two components of a multivariate time series, a topic\naddressed in Runge et al. (2012), it is even more important to assess the\nstrength of their association in a meaningful way. In the present article we\nfocus on the problem of defining a meaningful coupling strength using\ninformation theoretic measures and demonstrate the short-comings of the\nwell-known mutual information and transfer entropy. Instead, we propose a\ncertain time-delayed conditional mutual information, the momentary information\ntransfer (MIT), as a measure of association that is general, causal and\nlag-specific, reflects a well interpretable notion of coupling strength and is\npractically computable. MIT is based on the fundamental concept of source\nentropy, which we utilize to yield a notion of coupling strength that is,\ncompared to mutual information and transfer entropy, well interpretable, in\nthat for many cases it solely depends on the interaction of the two components\nat a certain lag. In particular, MIT is thus in many cases able to exclude the\nmisleading influence of autodependency within a process in an\ninformation-theoretic way. We formalize and prove this idea analytically and\nnumerically for a general class of nonlinear stochastic processes and\nillustrate the potential of MIT on climatological data. \n\n"}
{"id": "1210.6730", "contents": "Title: Measure What Should be Measured: Progress and Challenges in Compressive\n  Sensing Abstract: Is compressive sensing overrated? Or can it live up to our expectations? What\nwill come after compressive sensing and sparsity? And what has Galileo Galilei\ngot to do with it? Compressive sensing has taken the signal processing\ncommunity by storm. A large corpus of research devoted to the theory and\nnumerics of compressive sensing has been published in the last few years.\nMoreover, compressive sensing has inspired and initiated intriguing new\nresearch directions, such as matrix completion. Potential new applications\nemerge at a dazzling rate. Yet some important theoretical questions remain\nopen, and seemingly obvious applications keep escaping the grip of compressive\nsensing. In this paper I discuss some of the recent progress in compressive\nsensing and point out key challenges and opportunities as the area of\ncompressive sensing and sparse representations keeps evolving. I also attempt\nto assess the long-term impact of compressive sensing. \n\n"}
{"id": "1210.6764", "contents": "Title: Universal decoding for arbitrary channels relative to a given class of\n  decoding metrics Abstract: We consider the problem of universal decoding for arbitrary unknown channels\nin the random coding regime. For a given random coding distribution and a given\nclass of metric decoders, we propose a generic universal decoder whose average\nerror probability is, within a sub-exponential multiplicative factor, no larger\nthan that of the best decoder within this class of decoders. Since the optimum,\nmaximum likelihood (ML) decoder of the underlying channel is not necessarily\nassumed to belong to the given class of decoders, this setting suggests a\ncommon generalized framework for: (i) mismatched decoding, (ii) universal\ndecoding for a given family of channels, and (iii) universal coding and\ndecoding for deterministic channels using the individual-sequence approach. The\nproof of our universality result is fairly simple, and it is demonstrated how\nsome earlier results on universal decoding are obtained as special cases. We\nalso demonstrate how our method extends to more complicated scenarios, like\nincorporation of noiseless feedback, and the multiple access channel. \n\n"}
{"id": "1210.6954", "contents": "Title: Optimal Locally Repairable and Secure Codes for Distributed Storage\n  Systems Abstract: This paper aims to go beyond resilience into the study of security and\nlocal-repairability for distributed storage systems (DSS). Security and\nlocal-repairability are both important as features of an efficient storage\nsystem, and this paper aims to understand the trade-offs between resilience,\nsecurity, and local-repairability in these systems. In particular, this paper\nfirst investigates security in the presence of colluding eavesdroppers, where\neavesdroppers are assumed to work together in decoding stored information.\nSecond, the paper focuses on coding schemes that enable optimal local repairs.\nIt further brings these two concepts together, to develop locally repairable\ncoding schemes for DSS that are secure against eavesdroppers.\n  The main results of this paper include: a. An improved bound on the secrecy\ncapacity for minimum storage regenerating codes, b. secure coding schemes that\nachieve the bound for some special cases, c. a new bound on minimum distance\nfor locally repairable codes, d. code construction for locally repairable codes\nthat attain the minimum distance bound, and e. repair-bandwidth-efficient\nlocally repairable codes with and without security constraints. \n\n"}
{"id": "1211.1265", "contents": "Title: From Bits to Images: Inversion of Local Binary Descriptors Abstract: Local Binary Descriptors are becoming more and more popular for image\nmatching tasks, especially when going mobile. While they are extensively\nstudied in this context, their ability to carry enough information in order to\ninfer the original image is seldom addressed.\n  In this work, we leverage an inverse problem approach to show that it is\npossible to directly reconstruct the image content from Local Binary\nDescriptors. This process relies on very broad assumptions besides the\nknowledge of the pattern of the descriptor at hand. This generalizes previous\nresults that required either a prior learning database or non-binarized\nfeatures.\n  Furthermore, our reconstruction scheme reveals differences in the way\ndifferent Local Binary Descriptors capture and encode image information. Hence,\nthe potential applications of our work are multiple, ranging from privacy\nissues caused by eavesdropping image keypoints streamed by mobile devices to\nthe design of better descriptors through the visualization and the analysis of\ntheir geometric content. \n\n"}
{"id": "1211.1621", "contents": "Title: Cram\\'er-Rao bounds for synchronization of rotations Abstract: Synchronization of rotations is the problem of estimating a set of rotations\nR_i in SO(n), i = 1, ..., N, based on noisy measurements of relative rotations\nR_i R_j^T. This fundamental problem has found many recent applications, most\nimportantly in structural biology. We provide a framework to study\nsynchronization as estimation on Riemannian manifolds for arbitrary n under a\nlarge family of noise models. The noise models we address encompass zero-mean\nisotropic noise, and we develop tools for Gaussian-like as well as heavy-tail\ntypes of noise in particular. As a main contribution, we derive the\nCram\\'er-Rao bounds of synchronization, that is, lower-bounds on the variance\nof unbiased estimators. We find that these bounds are structured by the\npseudoinverse of the measurement graph Laplacian, where edge weights are\nproportional to measurement quality. We leverage this to provide interpretation\nin terms of random walks and visualization tools for these bounds in both the\nanchored and anchor-free scenarios. Similar bounds previously established were\nlimited to rotations in the plane and Gaussian-like noise. \n\n"}
{"id": "1211.3729", "contents": "Title: Data-Efficient Quickest Change Detection in Minimax Settings Abstract: The classical problem of quickest change detection is studied with an\nadditional constraint on the cost of observations used in the detection\nprocess. The change point is modeled as an unknown constant, and minimax\nformulations are proposed for the problem. The objective in these formulations\nis to find a stopping time and an on-off observation control policy for the\nobservation sequence, to minimize a version of the worst possible average\ndelay, subject to constraints on the false alarm rate and the fraction of time\nobservations are taken before change. An algorithm called DE-CuSum is proposed\nand is shown to be asymptotically optimal for the proposed formulations, as the\nfalse alarm rate goes to zero. Numerical results are used to show that the\nDE-CuSum algorithm has good trade-off curves and performs significantly better\nthan the approach of fractional sampling, in which the observations are skipped\nusing the outcome of a sequence of coin tosses, independent of the observation\nprocess. This work is guided by the insights gained from an earlier study of a\nBayesian version of this problem. \n\n"}
{"id": "1211.5058", "contents": "Title: Compressed Sensing of Simultaneous Low-Rank and Joint-Sparse Matrices Abstract: In this paper we consider the problem of recovering a high dimensional data\nmatrix from a set of incomplete and noisy linear measurements. We introduce a\nnew model that can efficiently restrict the degrees of freedom of the problem\nand is generic enough to find a lot of applications, for instance in\nmultichannel signal compressed sensing (e.g. sensor networks, hyperspectral\nimaging) and compressive sparse principal component analysis (s-PCA). We assume\ndata matrices have a simultaneous low-rank and joint sparse structure, and we\npropose a novel approach for efficient compressed sensing (CS) of such data.\nOur CS recovery approach is based on a convex minimization problem that\nincorporates this restrictive structure by jointly regularizing the solutions\nwith their nuclear (trace) norm and l2/l1 mixed norm. Our theoretical analysis\nuses a new notion of restricted isometry property (RIP) and shows that, for\nsampling schemes satisfying RIP, our approach can stably recover all low-rank\nand joint-sparse matrices. For a certain class of random sampling schemes\nsatisfying a particular concentration bound (e.g. the subgaussian ensembles) we\nderive a lower bound on the number of CS measurements indicating the\nnear-optimality of our recovery approach as well as a significant enhancement\ncompared to the state-of-the-art. We introduce an iterative algorithm based on\nproximal calculus in order to solve the joint nuclear and l2/l1 norms\nminimization problem and, finally, we illustrate the empirical recovery phase\ntransition of this approach by series of numerical experiments. \n\n"}
{"id": "1212.2696", "contents": "Title: Towards the full information chain theory: answer depth and source\n  models Abstract: A problem of optimal information acquisition for its use in general decision\nmaking problems is considered. This motivates the need for developing\nquantitative measures of information sources' capabilities for supplying\naccurate information depending on the particular content of the latter. A\ncompanion article developed the notion of a question difficulty functional for\nquestions concerning input data for a decision making problem. Here, answers\nwhich an information source may provide in response to such questions are\nconsidered. In particular, a real valued answer depth functional measuring the\ndegree of accuracy of such answers is introduced and its overall form is\nderived under the assumption of isotropic knowledge structure of the\ninformation source. Additionally, information source models that relate answer\ndepth to question difficulty are discussed. It turns out to be possible to\nintroduce a notion of an information source capacity as the highest value of\nthe answer depth the source is capable of providing. \n\n"}
{"id": "1212.3177", "contents": "Title: Information Capacity of an Energy Harvesting Sensor Node Abstract: Energy harvesting sensor nodes are gaining popularity due to their ability to\nimprove the network life time and are becoming a preferred choice supporting\n'green communication'. In this paper we focus on communicating reliably over an\nAWGN channel using such an energy harvesting sensor node. An important part of\nthis work involves appropriate modeling of the energy harvesting, as done via\nvarious practical architectures. Our main result is the characterization of the\nShannon capacity of the communication system. The key technical challenge\ninvolves dealing with the dynamic (and stochastic) nature of the (quadratic)\ncost of the input to the channel. As a corollary, we find close connections\nbetween the capacity achieving energy management policies and the queueing\ntheoretic throughput optimal policies. \n\n"}
{"id": "1212.4899", "contents": "Title: New inequalities of Mill's ratio and Its Application to The Inverse\n  Q-function Approximation Abstract: In this paper, we investigate the Mill's ratio estimation problem and get two\nnew inequalities. Compared to the well known results obtained by Gordon, they\nbecomes tighter. Furthermore, we also discuss the inverse Q-function\napproximation problem and present some useful results on the inverse solution.\nNumerical results confirm the validness of our theoretical analysis. In\naddition, we also present a conjecture on the bounds of inverse solution on\nQ-function. \n\n"}
{"id": "1212.4902", "contents": "Title: On the Capacity Region and the Generalized Degrees of Freedom Region for\n  the MIMO Interference Channel with Feedback Abstract: In this paper, we study the effect of feedback on two-user MIMO interference\nchannels. The capacity region of MIMO interference channels with feedback is\ncharacterized within a constant number of bits, where this constant is\nindependent of the channel matrices. Further, it is shown that the capacity\nregion of a MIMO interference channel with feedback and its reciprocal\ninterference channel are within a constant number of bits. Finally, the\ngeneralized degrees of freedom region for the MIMO interference channel with\nfeedback is characterized. \n\n"}
{"id": "1212.6465", "contents": "Title: Quantized Iterative Message Passing Decoders with Low Error Floor for\n  LDPC Codes Abstract: The error floor phenomenon observed with LDPC codes and their graph-based,\niterative, message-passing (MP) decoders is commonly attributed to the\nexistence of error-prone substructures -- variously referred to as near\ncodewords, trapping sets, absorbing sets, or pseudocodewords -- in a Tanner\ngraph representation of the code. Many approaches have been proposed to lower\nthe error floor by designing new LDPC codes with fewer such substructures or by\nmodifying the decoding algorithm. Using a theoretical analysis of iterative MP\ndecoding in an idealized trapping set scenario, we show that a contributor to\nthe error floors observed in the literature may be the imprecise implementation\nof decoding algorithms and, in particular, the message quantization rules used.\nWe then propose a new quantization method -- (q+1)-bit quasi-uniform\nquantization -- that efficiently increases the dynamic range of messages,\nthereby overcoming a limitation of conventional quantization schemes. Finally,\nwe use the quasi-uniform quantizer to decode several LDPC codes that suffer\nfrom high error floors with traditional fixed-point decoder implementations.\nThe performance simulation results provide evidence that the proposed\nquantization scheme can, for a wide variety of codes, significantly lower error\nfloors with minimal increase in decoder complexity. \n\n"}
{"id": "1212.6734", "contents": "Title: Pushing the Limits of LTE: A Survey on Research Enhancing the Standard Abstract: Cellular networks are an essential part of todays communication\ninfrastructure. The ever-increasing demand for higher data-rates calls for a\nclose cooperation between researchers and industry/standardization experts\nwhich hardly exists in practice. In this article we give an overview about our\nefforts in trying to bridge this gap. Our research group provides a\nstandard-compliant open-source simulation platform for 3GPP LTE that enables\nreproducible research in a well-defined environment. We demonstrate that much\ninnovative research under the confined framework of a real-world standard is\nstill possible, sometimes even encouraged. With examplary samples of our\nresearch work we investigate on the potential of several important research\nareas under typical practical conditions. \n\n"}
{"id": "1301.0373", "contents": "Title: Compressed Sensing Matrices from Fourier Matrices Abstract: The class of Fourier matrices is of special importance in compressed sensing\n(CS). This paper concerns deterministic construction of compressed sensing\nmatrices from Fourier matrices. By using Katz' character sum estimation, we are\nable to design a deterministic procedure to select rows from a Fourier matrix\nto form a good compressed sensing matrix for sparse recovery. The sparsity\nbound in our construction is similar to that of binary CS matrices constructed\nby DeVore which greatly improves previous results for CS matrices from Fourier\nmatrices. Our approach also provides more flexibilities in terms of the\ndimension of CS matrices. As a consequence, our construction yields an\napproximately mutually unbiased bases from Fourier matrices which is of\nparticular interest to quantum information theory. This paper also contains a\nuseful improvement to Katz' character sum estimation for quadratic extensions,\nwith an elementary and transparent proof. Some numerical examples are included. \n\n"}
{"id": "1301.0901", "contents": "Title: Compressed Sensing under Matrix Uncertainty: Optimum Thresholds and\n  Robust Approximate Message Passing Abstract: In compressed sensing one measures sparse signals directly in a compressed\nform via a linear transform and then reconstructs the original signal. However,\nit is often the case that the linear transform itself is known only\napproximately, a situation called matrix uncertainty, and that the measurement\nprocess is noisy. Here we present two contributions to this problem: first, we\nuse the replica method to determine the mean-squared error of the Bayes-optimal\nreconstruction of sparse signals under matrix uncertainty. Second, we consider\na robust variant of the approximate message passing algorithm and demonstrate\nnumerically that in the limit of large systems, this algorithm matches the\noptimal performance in a large region of parameters. \n\n"}
{"id": "1301.0926", "contents": "Title: Source Coding with in-Block Memory and Causally Controllable Side\n  Information Abstract: The recently proposed set-up of source coding with a side information\n\"vending machine\" allows the decoder to select actions in order to control the\nquality of the side information. The actions can depend on the message received\nfrom the encoder and on the previously measured samples of the side\ninformation, and are cost constrained. Moreover, the final estimate of the\nsource by the decoder is a function of the encoder's message and depends\ncausally on the side information sequence. Previous work by Permuter and\nWeissman has characterized the rate-distortion-cost function in the special\ncase in which the source and the \"vending machine\" are memoryless. In this\nwork, motivated by the related channel coding model introduced by Kramer, the\nrate-distortion-cost function characterization is extended to a model with\nin-block memory. Various special cases are studied including block-feedforward\nand side information repeat request models. \n\n"}
{"id": "1301.3375", "contents": "Title: On the Identifiability of Overcomplete Dictionaries via the Minimisation\n  Principle Underlying K-SVD Abstract: This article gives theoretical insights into the performance of K-SVD, a\ndictionary learning algorithm that has gained significant popularity in\npractical applications. The particular question studied here is when a\ndictionary $\\Phi\\in \\mathbb{R}^{d \\times K}$ can be recovered as local minimum\nof the minimisation criterion underlying K-SVD from a set of $N$ training\nsignals $y_n =\\Phi x_n$. A theoretical analysis of the problem leads to two\ntypes of identifiability results assuming the training signals are generated\nfrom a tight frame with coefficients drawn from a random symmetric\ndistribution. First, asymptotic results showing, that in expectation the\ngenerating dictionary can be recovered exactly as a local minimum of the K-SVD\ncriterion if the coefficient distribution exhibits sufficient decay. Second,\nbased on the asymptotic results it is demonstrated that given a finite number\nof training samples $N$, such that $N/\\log N = O(K^3d)$, except with\nprobability $O(N^{-Kd})$ there is a local minimum of the K-SVD criterion within\ndistance $O(KN^{-1/4})$ to the generating dictionary. \n\n"}
{"id": "1301.4016", "contents": "Title: On the Classification of Exceptional Planar Functions over\n  $\\mathbb{F}_{p}$ Abstract: We will present many strong partial results towards a classification of\nexceptional planar/PN monomial functions on finite fields. The techniques we\nuse are the Weil bound, Bezout's theorem, and Bertini's theorem. \n\n"}
{"id": "1301.4240", "contents": "Title: Hypothesis Testing in High-Dimensional Regression under the Gaussian\n  Random Design Model: Asymptotic Theory Abstract: We consider linear regression in the high-dimensional regime where the number\nof observations $n$ is smaller than the number of parameters $p$. A very\nsuccessful approach in this setting uses $\\ell_1$-penalized least squares\n(a.k.a. the Lasso) to search for a subset of $s_0< n$ parameters that best\nexplain the data, while setting the other parameters to zero. Considerable\namount of work has been devoted to characterizing the estimation and model\nselection problems within this approach.\n  In this paper we consider instead the fundamental, but far less understood,\nquestion of \\emph{statistical significance}. More precisely, we address the\nproblem of computing p-values for single regression coefficients.\n  On one hand, we develop a general upper bound on the minimax power of tests\nwith a given significance level. On the other, we prove that this upper bound\nis (nearly) achievable through a practical procedure in the case of random\ndesign matrices with independent entries. Our approach is based on a debiasing\nof the Lasso estimator. The analysis builds on a rigorous characterization of\nthe asymptotic distribution of the Lasso estimator and its debiased version.\nOur result holds for optimal sample size, i.e., when $n$ is at least on the\norder of $s_0 \\log(p/s_0)$.\n  We generalize our approach to random design matrices with i.i.d. Gaussian\nrows $x_i\\sim N(0,\\Sigma)$. In this case we prove that a similar distributional\ncharacterization (termed `standard distributional limit') holds for $n$ much\nlarger than $s_0(\\log p)^2$.\n  Finally, we show that for optimal sample size, $n$ being at least of order\n$s_0 \\log(p/s_0)$, the standard distributional limit for general Gaussian\ndesigns can be derived from the replica heuristics in statistical physics. \n\n"}
{"id": "1301.4441", "contents": "Title: Communication Complexity of Channels in General Probabilistic Theories Abstract: The communication complexity of a quantum channel is the minimal amount of\nclassical communication required for classically simulating the process of\npreparation, transmission through the channel, and subsequent measurement of a\nquantum state. At present, only little is known about this quantity. In this\npaper, we present a procedure for systematically evaluating the communication\ncomplexity of channels in any general probabilistic theory, in particular\nquantum theory. The procedure is constructive and provides the most efficient\nclassical protocols. We illustrate this procedure by evaluating the\ncommunication complexity of a quantum depolarizing channel with some finite\nsets of quantum states and measurements. \n\n"}
{"id": "1301.5044", "contents": "Title: Performance Analysis of Heterogeneous Feedback Design in an OFDMA\n  Downlink with Partial and Imperfect Feedback Abstract: Current OFDMA systems group resource blocks into subband to form the basic\nfeedback unit. Homogeneous feedback design with a common subband size is not\naware of the heterogeneous channel statistics among users. Under a general\ncorrelated channel model, we demonstrate the gain of matching the subband size\nto the underlying channel statistics motivating heterogeneous feedback design\nwith different subband sizes and feedback resources across clusters of users.\nEmploying the best-M partial feedback strategy, users with smaller subband size\nwould convey more partial feedback to match the frequency selectivity. In order\nto develop an analytical framework to investigate the impact of partial\nfeedback and potential imperfections, we leverage the multi-cluster subband\nfading model. The perfect feedback scenario is thoroughly analyzed, and the\nclosed form expression for the average sum rate is derived for the\nheterogeneous partial feedback system. We proceed to examine the effect of\nimperfections due to channel estimation error and feedback delay, which leads\nto additional consideration of system outage. Two transmission strategies: the\nfix rate and the variable rate, are considered for the outage analysis. We also\ninvestigate how to adapt to the imperfections in order to maximize the average\ngoodput under heterogeneous partial feedback. \n\n"}
{"id": "1301.6157", "contents": "Title: High-Rate Regenerating Codes Through Layering Abstract: In this paper, we provide explicit constructions for a class of exact-repair\nregenerating codes that possess a layered structure. These regenerating codes\ncorrespond to interior points on the storage-repair-bandwidth tradeoff, and\ncompare very well in comparison to scheme that employs space-sharing between\nMSR and MBR codes. For the parameter set $(n,k,d=k)$ with $n < 2k-1$, we\nconstruct a class of codes with an auxiliary parameter $w$, referred to as\ncanonical codes. With $w$ in the range $n-k < w < k$, these codes operate in\nthe region between the MSR point and the MBR point, and perform significantly\nbetter than the space-sharing line. They only require a field size greater than\n$w+n-k$. For the case of $(n,n-1,n-1)$, canonical codes can also be shown to\nachieve an interior point on the line-segment joining the MSR point and the\nnext point of slope-discontinuity on the storage-repair-bandwidth tradeoff.\nThus we establish the existence of exact-repair codes on a point other than the\nMSR and the MBR point on the storage-repair-bandwidth tradeoff. We also\nconstruct layered regenerating codes for general parameter set $(n,k<d,k)$,\nwhich we refer to as non-canonical codes. These codes also perform\nsignificantly better than the space-sharing line, though they require a\nsignificantly higher field size. All the codes constructed in this paper are\nhigh-rate, can repair multiple node-failures and do not require any computation\nat the helper nodes. We also construct optimal codes with locality in which the\nlocal codes are layered regenerating codes. \n\n"}
{"id": "1301.6209", "contents": "Title: On the achievable region for interference networks with point-to-point\n  codes Abstract: This paper studies evaluation of the capacity region for interference\nnetworks with point-to-point (p2p) capacity-achieving codes. Such capacity\nregion has recently been characterized as union of several sub-regions each of\nwhich has distinctive operational characteristics. Detailed evaluation of this\nregion, therefore, can be accomplished in a very simple manner by acknowledging\nsuch characteristics, which, in turn, provides an insight for a simple\nimplementation scenario. Completely generalized message assignment which is\nalso practically relevant is considered in this paper, and it is shown to\nprovide strictly larger achievable rates than what traditional message\nassignment does when a receiver with joint decoding capability is used. \n\n"}
{"id": "1301.6295", "contents": "Title: Fixed Points of Generalized Approximate Message Passing with Arbitrary\n  Matrices Abstract: The estimation of a random vector with independent components passed through\na linear transform followed by a componentwise (possibly nonlinear) output map\narises in a range of applications. Approximate message passing (AMP) methods,\nbased on Gaussian approximations of loopy belief propagation, have recently\nattracted considerable attention for such problems. For large random\ntransforms, these methods exhibit fast convergence and admit precise analytic\ncharacterizations with testable conditions for optimality, even for certain\nnon-convex problem instances. However, the behavior of AMP under general\ntransforms is not fully understood. In this paper, we consider the generalized\nAMP (GAMP) algorithm and relate the method to more common optimization\ntechniques. This analysis enables a precise characterization of the GAMP\nalgorithm fixed-points that applies to arbitrary transforms. In particular, we\nshow that the fixed points of the so-called max-sum GAMP algorithm for MAP\nestimation are critical points of a constrained maximization of the posterior\ndensity. The fixed-points of the sum-product GAMP algorithm for estimation of\nthe posterior marginals can be interpreted as critical points of a certain free\nenergy. \n\n"}
{"id": "1301.6302", "contents": "Title: Simultaneous Information and Energy Transfer: A Two-User MISO\n  Interference Channel Case Abstract: This paper considers the sum rate maximization problem of a two-user\nmultiple-input single-output interference channel with receivers that can\nscavenge energy from the radio signals transmitted by the transmitters. We\nfirst study the optimal transmission strategy for an ideal scenario where the\ntwo receivers can simultaneously decode the information signal and harvest\nenergy. Then, considering the limitations of the current circuit technology, we\npropose two practical schemes based on TDMA, where, at each time slot, the\nreceiver either operates in the energy harvesting mode or in the information\ndetection mode. Optimal transmission strategies for the two practical schemes\nare respectively investigated. Simulation results show that the three schemes\nexhibit interesting tradeoff between achievable sum rate and energy harvesting\nrequirement, and do not dominate each other in terms of maximum achievable sum\nrate. \n\n"}
{"id": "1301.6393", "contents": "Title: Precoded Integer-Forcing Universally Achieves the MIMO Capacity to\n  Within a Constant Gap Abstract: An open-loop single-user multiple-input multiple-output communication scheme\nis considered where a transmitter, equipped with multiple antennas, encodes the\ndata into independent streams all taken from the same linear code. The coded\nstreams are then linearly precoded using the encoding matrix of a perfect\nlinear dispersion space-time code. At the receiver side, integer-forcing\nequalization is applied, followed by standard single-stream decoding. It is\nshown that this communication architecture achieves the capacity of any\nGaussian multiple-input multiple-output channel up to a gap that depends only\non the number of transmit antennas. \n\n"}
{"id": "1301.6412", "contents": "Title: Random Access and Source-Channel Coding Error Exponents for Multiple\n  Access Channels Abstract: A new universal coding/decoding scheme for random access with collision\ndetection is given in the case of two senders. The result is used to give an\nachievable joint source-channel coding error exponent for multiple access\nchannels in the case of independent sources. This exponent is improved in a\nmodified model that admits error free 0 rate communication between the senders. \n\n"}
{"id": "1301.6599", "contents": "Title: An Upper Bound on the Capacity of non-Binary Deletion Channels Abstract: We derive an upper bound on the capacity of non-binary deletion channels.\nAlthough binary deletion channels have received significant attention over the\nyears, and many upper and lower bounds on their capacity have been derived,\nsuch studies for the non-binary case are largely missing. The state of the art\nis the following: as a trivial upper bound, capacity of an erasure channel with\nthe same input alphabet as the deletion channel can be used, and as a lower\nbound the results by Diggavi and Grossglauser are available. In this paper, we\nderive the first non-trivial non-binary deletion channel capacity upper bound\nand reduce the gap with the existing achievable rates. To derive the results we\nfirst prove an inequality between the capacity of a 2K-ary deletion channel\nwith deletion probability $d$, denoted by $C_{2K}(d)$, and the capacity of the\nbinary deletion channel with the same deletion probability, $C_2(d)$, that is,\n$C_{2K}(d)\\leq C_2(d)+(1-d)\\log(K)$. Then by employing some existing upper\nbounds on the capacity of the binary deletion channel, we obtain upper bounds\non the capacity of the 2K-ary deletion channel. We illustrate via examples the\nuse of the new bounds and discuss their asymptotic behavior as $d \\rightarrow\n0$. \n\n"}
{"id": "1302.0189", "contents": "Title: Non-adaptive pooling strategies for detection of rare faulty items Abstract: We study non-adaptive pooling strategies for detection of rare faulty items.\nGiven a binary sparse N-dimensional signal x, how to construct a sparse binary\nMxN pooling matrix F such that the signal can be reconstructed from the\nsmallest possible number M of measurements y=Fx? We show that a very low number\nof measurements is possible for random spatially coupled design of pools F. Our\ndesign might find application in genetic screening or compressed genotyping. We\nshow that our results are robust with respect to the uncertainty in the matrix\nF when some elements are mistaken. \n\n"}
{"id": "1302.0614", "contents": "Title: Outage Capacity for the Optical MIMO Channel Abstract: MIMO processing techniques in fiber optical communications have been proposed\nas a promising approach to meet increasing demand for information throughput.\nIn this context, the multiple channels correspond to the multiple modes and/or\nmultiple cores in the fiber. In this paper we characterize the distribution of\nthe mutual information with Gaussian input in a simple channel model for this\nsystem. Assuming significant cross talk between cores, negligible\nbackscattering and near-lossless propagation in the fiber, we model the\ntransmission channel as a random complex unitary matrix. The loss in the\ntransmission may be parameterized by a number of unutilized channels in the\nfiber. We analyze the system in a dual fashion. First, we evaluate a\nclosed-form expression for the outage probability, which is handy for small\nmatrices. We also apply the asymptotic approach, in particular the Coulomb gas\nmethod from statistical mechanics, to obtain closed-form results for the\nergodic mutual information, its variance as well as the outage probability for\nGaussian input in the limit of large number of cores/modes. By comparing our\nanalytic results to simulations, we see that, despite the fact that this method\nis nominally valid for large number of modes, our method is quite accurate even\nfor small to modest number of channels. \n\n"}
{"id": "1302.2875", "contents": "Title: Information Transmission using the Nonlinear Fourier Transform, Part\n  III: Spectrum Modulation Abstract: Motivated by the looming \"capacity crunch\" in fiber-optic networks,\ninformation transmission over such systems is revisited. Among numerous\ndistortions, inter-channel interference in multiuser wavelength-division\nmultiplexing (WDM) is identified as the seemingly intractable factor limiting\nthe achievable rate at high launch power. However, this distortion and similar\nones arising from nonlinearity are primarily due to the use of methods suited\nfor linear systems, namely WDM and linear pulse-train transmission, for the\nnonlinear optical channel. Exploiting the integrability of the nonlinear\nSchr\\\"odinger (NLS) equation, a nonlinear frequency-division multiplexing\n(NFDM) scheme is presented, which directly modulates non-interacting signal\ndegrees-of-freedom under NLS propagation. The main distinction between this and\nprevious methods is that NFDM is able to cope with the nonlinearity, and thus,\nas the the signal power or transmission distance is increased, the new method\ndoes not suffer from the deterministic cross-talk between signal components\nwhich has degraded the performance of previous approaches. In this paper,\nemphasis is placed on modulation of the discrete component of the nonlinear\nFourier transform of the signal and some simple examples of achievable spectral\nefficiencies are provided. \n\n"}
{"id": "1302.3492", "contents": "Title: Outer Bounds for Multiterminal Source Coding via a Strong Data\n  Processing Inequality Abstract: An intuitive outer bound for the multiterminal source coding problem is\ngiven. The proposed bound explicitly couples the rate distortion functions for\neach source and correlation measures which derive from a \"strong\" data\nprocessing inequality. Unlike many standard outer bounds, the proposed bound is\nnot parameterized by a continuous family of auxiliary random variables, but\ninstead only requires maximizing two ratios of divergences which do not depend\non the distortion functions under consideration. \n\n"}
{"id": "1302.6521", "contents": "Title: Imperfect and Unmatched CSIT is Still Useful for the Frequency\n  Correlated MISO Broadcast Channel Abstract: Since Maddah-Ali and Tse showed that the completely stale transmitter-side\nchannel state information (CSIT) still benefits the Degrees of Freedom (DoF) of\nthe Multiple-Input-Multiple-Output (MISO) Broadcast Channel (BC), there has\nbeen much interest in the academic literature to investigate the impact of\nimperfect CSIT on \\emph{DoF} region of time correlated broadcast channel. Even\nthough the research focus has been on time correlated channels so far, a\nsimilar but different problem concerns the frequency correlated channels.\nIndeed, the imperfect CSIT also impacts the DoF region of frequency correlated\nchannels, as exemplified by current multi-carrier wireless systems.\n  This contribution, for the first time in the literature, investigates a\ngeneral frequency correlated setting where a two-antenna transmitter has\nimperfect knowledge of CSI of two single-antenna users on two adjacent\nsubbands. A new scheme is derived as an integration of Zero-Forcing Beamforming\n(ZFBF) and the scheme proposed by Maddah-Ali and Tse. The achievable DoF region\nresulted by this scheme is expressed as a function of the qualities of CSIT. \n\n"}
{"id": "1302.6660", "contents": "Title: Optimal rate algebraic list decoding using narrow ray class fields Abstract: We use class field theory, specifically Drinfeld modules of rank 1, to\nconstruct a family of asymptotically good algebraic-geometric (AG) codes over\nfixed alphabets. Over a field of size $\\ell^2$, these codes are within\n$2/(\\sqrt{\\ell}-1)$ of the Singleton bound. The functions fields underlying\nthese codes are subfields with a cyclic Galois group of the narrow ray class\nfield of certain function fields. The resulting codes are \"folded\" using a\ngenerator of the Galois group. This generalizes earlier work by the first\nauthor on folded AG codes based on cyclotomic function fields. Using the\nChebotarev density theorem, we argue the abundance of inert places of large\ndegree in our cyclic extension, and use this to devise a linear-algebraic\nalgorithm to list decode these folded codes up to an error fraction approaching\n$1-R$ where $R$ is the rate. The list decoding can be performed in polynomial\ntime given polynomial amount of pre-processed information about the function\nfield.\n  Our construction yields algebraic codes over constant-sized alphabets that\ncan be list decoded up to the Singleton bound --- specifically, for any desired\nrate $R \\in (0,1)$ and constant $\\eps > 0$, we get codes over an alphabet size\n$(1/\\eps)^{O(1/\\eps^2)}$ that can be list decoded up to error fraction\n$1-R-\\eps$ confining close-by messages to a subspace with $N^{O(1/\\eps^2)}$\nelements. Previous results for list decoding up to error-fraction $1-R-\\eps$\nover constant-sized alphabets were either based on concatenation or involved\ntaking a carefully sampled subcode of algebraic-geometric codes. In contrast,\nour result shows that these folded algebraic-geometric codes {\\em themselves}\nhave the claimed list decoding property. \n\n"}
{"id": "1302.6866", "contents": "Title: Vandermonde-subspace Frequency Division Multiplexing for Two-Tiered\n  Cognitive Radio Networks Abstract: Vandermonde-subspace frequency division multiplexing (VFDM) is an overlay\nspectrum sharing technique for cognitive radio. VFDM makes use of a precoder\nbased on a Vandermonde structure to transmit information over a secondary\nsystem, while keeping an orthogonal frequency division multiplexing\n(OFDM)-based primary system interference-free. To do so, VFDM exploits\nfrequency selectivity and the use of cyclic prefixes by the primary system.\nHerein, a global view of VFDM is presented, including also practical aspects\nsuch as linear receivers and the impact of channel estimation. We show that\nVFDM provides a spectral efficiency increase of up to 1 bps/Hz over cognitive\nradio systems based on unused band detection. We also present some key design\nparameters for its future implementation and a feasible channel estimation\nprotocol. Finally we show that, even when some of the theoretical assumptions\nare relaxed, VFDM provides non-negligible rates while protecting the primary\nsystem. \n\n"}
{"id": "1303.1209", "contents": "Title: Sample-Optimal Average-Case Sparse Fourier Transform in Two Dimensions Abstract: We present the first sample-optimal sublinear time algorithms for the sparse\nDiscrete Fourier Transform over a two-dimensional sqrt{n} x sqrt{n} grid. Our\nalgorithms are analyzed for /average case/ signals. For signals whose spectrum\nis exactly sparse, our algorithms use O(k) samples and run in O(k log k) time,\nwhere k is the expected sparsity of the signal. For signals whose spectrum is\napproximately sparse, our algorithm uses O(k log n) samples and runs in O(k\nlog^2 n) time; the latter algorithm works for k=Theta(sqrt{n}). The number of\nsamples used by our algorithms matches the known lower bounds for the\nrespective signal models.\n  By a known reduction, our algorithms give similar results for the\none-dimensional sparse Discrete Fourier Transform when n is a power of a small\ncomposite number (e.g., n = 6^t). \n\n"}
{"id": "1303.1915", "contents": "Title: Spatially Selective Artificial-Noise Aided Transmit Optimization for\n  MISO Multi-Eves Secrecy Rate Maximization Abstract: Consider an MISO channel overheard by multiple eavesdroppers. Our goal is to\ndesign an artificial noise (AN)-aided transmit strategy, such that the\nachievable secrecy rate is maximized subject to the sum power constraint.\nAN-aided secure transmission has recently been found to be a promising approach\nfor blocking eavesdropping attempts. In many existing studies, the confidential\ninformation transmit covariance and the AN covariance are not simultaneously\noptimized. In particular, for design convenience, it is common to prefix the AN\ncovariance as a specific kind of spatially isotropic covariance. This paper\nconsiders joint optimization of the transmit and AN covariances for secrecy\nrate maximization (SRM), with a design flexibility that the AN can take any\nspatial pattern. Hence, the proposed design has potential in jamming the\neavesdroppers more effectively, based upon the channel state information (CSI).\nWe derive an optimization approach to the SRM problem through both analysis and\nconvex conic optimization machinery. We show that the SRM problem can be recast\nas a single-variable optimization problem, and that resultant problem can be\nefficiently handled by solving a sequence of semidefinite programs. Our\nframework deals with a general setup of multiple multi-antenna eavesdroppers,\nand can cater for additional constraints arising from specific application\nscenarios, such as interference temperature constraints in interference\nnetworks. We also generalize the framework to an imperfect CSI case where a\nworst-case robust SRM formulation is considered. A suboptimal but safe solution\nto the outage-constrained robust SRM design is also investigated. Simulation\nresults show that the proposed AN-aided SRM design yields significant secrecy\nrate gains over an optimal no-AN design and the isotropic AN design, especially\nwhen there are more eavesdroppers. \n\n"}
{"id": "1303.2257", "contents": "Title: A stochastic gradient approach on compressive sensing signal\n  reconstruction based on adaptive filtering framework Abstract: Based on the methodological similarity between sparse signal reconstruction\nand system identification, a new approach for sparse signal reconstruction in\ncompressive sensing (CS) is proposed in this paper. This approach employs a\nstochastic gradient-based adaptive filtering framework, which is commonly used\nin system identification, to solve the sparse signal reconstruction problem.\nTwo typical algorithms for this problem: $l_0$-least mean square ($l_0$-LMS)\nalgorithm and $l_0$-exponentially forgetting window LMS ($l_0$-EFWLMS)\nalgorithm are hence introduced here. Both the algorithms utilize a zero\nattraction method, which has been implemented by minimizing a continuous\napproximation of $l_0$ norm of the studied signal. To improve the performances\nof these proposed algorithms, an $l_0$-zero attraction projection ($l_0$-ZAP)\nalgorithm is also adopted, which has effectively accelerated their convergence\nrates, making them much faster than the other existing algorithms for this\nproblem. Advantages of the proposed approach, such as its robustness against\nnoise etc., are demonstrated by numerical experiments. \n\n"}
{"id": "1303.2817", "contents": "Title: A Tutorial on the Optimization of Amplify-and-Forward MIMO Relay Systems Abstract: The remarkable promise of multiple-input multiple-output (MIMO) wireless\nchannels has motivated an intense research activity to characterize the\ntheoretical and practical issues associated with the design of transmit\n(source) and receive (destination) processing matrices under different\noperating conditions. This activity was primarily focused on point-to-point\n(single-hop) communications but more recently there has been an extensive work\non two-hop or multi-hop settings in which single or multiple relays are used to\ndeliver the information from the source to the destination. The aim of this\ntutorial is to provide an up-to-date overview of the fundamental results and\npractical implementation issues of designing amplify-and-forward MIMO relay\nsystems. \n\n"}
{"id": "1303.3625", "contents": "Title: Quantum logic under semi-classical limit: information loss Abstract: We consider quantum computation efficiency from a new perspective. The\nefficiency is reduced to its classical counterpart by imposing the\nsemi-classical limit. We show that this reduction is caused by the fact that\nany elementary quantum logic operation (gate) suffers information loss during\ntransition to its classical analogue. Amount of the information lost is\nestimated for any gate from the complete set. The largest loss is obtained for\nnon-commuting gates that allows to consider them as quantum computational\nspeed-up resource. Our method allows to quantify advantages of quantum\ncomputation as compared to the classical one by direct analysis of the basic\nlogic involved. The obtained results are illustrated by application to quantum\ndiscrete Fourier transform and Grover search algorithms. \n\n"}
{"id": "1303.5526", "contents": "Title: On active information storage in input-driven systems Abstract: Information theory and the framework of information dynamics have been used\nto provide tools to characterise complex systems. In particular, we are\ninterested in quantifying information storage, information modification and\ninformation transfer as characteristic elements of computation. Although these\nquantities are defined for autonomous dynamical systems, information dynamics\ncan also help to get a \"wholistic\" understanding of input-driven systems such\nas neural networks. In this case, we do not distinguish between the system\nitself, and the effects the input has to the system. This may be desired in\nsome cases, but it will change the questions we are able to answer, and is\nconsequently an important consideration, for example, for biological systems\nwhich perform non-trivial computations and also retain a short-term memory of\npast inputs. Many other real world systems like cortical networks are also\nheavily input-driven, and application of tools designed for autonomous dynamic\nsystems may not necessarily lead to intuitively interpretable results.\n  The aim of our work is to extend the measurements used in the information\ndynamics framework for input-driven systems. Using the proposed input-corrected\ninformation storage we hope to better quantify system behaviour, which will be\nimportant for heavily input-driven systems like artificial neural networks to\nabstract from specific benchmarks, or for brain networks, where intervention is\ndifficult, individual components cannot be tested in isolation or with\narbitrary input data. \n\n"}
{"id": "1303.6167", "contents": "Title: Second-Order Rate Region of Constant-Composition Codes for the\n  Multiple-Access Channel Abstract: This paper studies the second-order asymptotics of coding rates for the\ndiscrete memoryless multiple-access channel with a fixed target error\nprobability. Using constant-composition random coding, coded time-sharing, and\na variant of Hoeffding's combinatorial central limit theorem, an inner bound on\nthe set of locally achievable second-order coding rates is given for each point\non the boundary of the capacity region. It is shown that the inner bound for\nconstant-composition random coding includes that recovered by i.i.d. random\ncoding, and that the inclusion may be strict. The inner bound is extended to\nthe Gaussian multiple-access channel via an increasingly fine quantization of\nthe inputs. \n\n"}
{"id": "1303.7030", "contents": "Title: Energy Efficient Cooperative Strategies for Relay-Assisted Downlink\n  Cellular Systems, Part I: Theoretical Framework Abstract: The impact of cognition on the energy efficiency of a downlink cellular\nsystem in which multiple relays assist the transmission of the base station is\nconsidered. The problem is motivated by the practical importance of\nrelay-assisted solutions in mobile networks, such as LTE-A, in which\ncooperation among relays holds the promise of greatly improving the energy\nefficiency of the system. We study the fundamental tradeoff between the power\nconsumption at the base station and the level of cooperation and cognition at\nthe relay nodes. By distributing the same message to multiple relays, the base\nstation consumes more power but it enables cooperation among the relays, thus\nmaking the transmission between relays to destination a multiuser cognitive\nchannel. Cooperation among the relays allows for a reduction of the power used\nto transmit from the relays to the end users due to interference management and\nthe coherent combining gains. These gain are present even in the case of\npartial or unidirectional transmitter cooperation, which is the case in\ncognitive channels such as the cognitive interference channel and the\ninterference channel with a cognitive relay. We therefore address the problem\nof determining the optimal level of cooperation at the relays which results in\nthe smallest total power consumption when accounting for the power reduction\ndue to cognition. A practical design examples and numerical simulation are\npresented in a companion paper (part II). \n\n"}
{"id": "1304.0110", "contents": "Title: A Signal Constellation for Pilotless Communications Over Wiener Phase\n  Noise Channels Abstract: Many satellite communication systems operating today employ low cost\nupconverters or downconverters which create phase noise. This noise can\nseverely limit the information rate of the system and pose a serious challenge\nfor the detection systems. Moreover, simple solutions for phase noise tracking\nsuch as PLL either require low phase noise or otherwise require many pilot\nsymbols which reduce the effective data rate. In order to increase the\neffective information rate, we propose a signal constellation which does not\nrequire pilots, at all, in order to converge in the decoding process. In this\ncontribution, we will present a signal constellation which does not require\npilot sequences, but we require a signal that does not present rotational\nsymmetry. For example a simple MPSK cannot be used.Moreover, we will provide a\nmethod to analyze the proposed constellations and provide a figure of merit for\ntheir performance when iterative decoding algorithms are used. \n\n"}
{"id": "1304.1405", "contents": "Title: Homogeneous Weights of Matrix Product Codes over Finite Principal Ideal\n  Rings Abstract: In this paper, the homogeneous weights of matrix product codes over finite\nprincipal ideal rings are studied and a lower bound for the minimum homogeneous\nweights of such matrix product codes is obtained. \n\n"}
{"id": "1304.6133", "contents": "Title: On Maximal Correlation, Hypercontractivity, and the Data Processing\n  Inequality studied by Erkip and Cover Abstract: In this paper we provide a new geometric characterization of the\nHirschfeld-Gebelein-R\\'{e}nyi maximal correlation of a pair of random $(X,Y)$,\nas well as of the chordal slope of the nontrivial boundary of the\nhypercontractivity ribbon of $(X,Y)$ at infinity. The new characterizations\nlead to simple proofs for some of the known facts about these quantities. We\nalso provide a counterexample to a data processing inequality claimed by Erkip\nand Cover, and find the correct tight constant for this kind of inequality. \n\n"}
{"id": "1304.6743", "contents": "Title: A Combinatorial Approach to Quantum Error Correcting Codes Abstract: Motivated from the theory of quantum error correcting codes, we investigate a\ncombinatorial problem that involves a symmetric $n$-vertices colourable graph\nand a group of operations (colouring rules) on the graph: find the minimum\nsequence of operations that maps between two given graph colourings. We provide\nan explicit algorithm for computing the solution of our problem, which in turn\nis directly related to computing the distance (performance) of an underlying\nquantum error correcting code. Computing the distance of a quantum code is a\nhighly non-trivial problem and our method may be of use in the construction of\nbetter codes. \n\n"}
{"id": "1304.7344", "contents": "Title: On feedback in Gaussian multi-hop networks Abstract: The study of feedback has been mostly limited to single-hop communication\nsettings. In this paper, we consider Gaussian networks where sources and\ndestinations can communicate with the help of intermediate relays over multiple\nhops. We assume that links in the network can be bidirected providing\nopportunities for feedback. We ask the following question: can the information\ntransfer in both directions of a link be critical to maximizing the end-to-end\ncommunication rates in the network? Equivalently, could one of the directions\nin each bidirected link (and more generally at least one of the links forming a\ncycle) be shut down and the capacity of the network still be approximately\nmaintained? We show that in any arbitrary Gaussian network with bidirected\nedges and cycles and unicast traffic, we can always identify a directed acyclic\nsubnetwork that approximately maintains the capacity of the original network.\nFor Gaussian networks with multiple-access and broadcast traffic, an acyclic\nsubnetwork is sufficient to achieve every rate point in the capacity region of\nthe original network, however, there may not be a single acyclic subnetwork\nthat maintains the whole capacity region. For networks with multicast and\nmultiple unicast traffic, on the other hand, bidirected information flow across\ncertain links can be critically needed to maximize the end-to-end capacity\nregion. These results can be regarded as generalizations of the conclusions\nregarding the usefulness of feedback in various single-hop Gaussian settings\nand can provide opportunities for simplifying operation in Gaussian multi-hop\nnetworks. \n\n"}
{"id": "1304.7539", "contents": "Title: Compressive parameter estimation in AWGN Abstract: Compressed sensing is by now well-established as an effective tool for\nextracting sparsely distributed information, where sparsity is a discrete\nconcept, referring to the number of dominant nonzero signal components in some\nbasis for the signal space. In this paper, we establish a framework for\nestimation of continuous-valued parameters based on compressive measurements on\na signal corrupted by additive white Gaussian noise (AWGN). While standard\ncompressed sensing based on naive discretization has been shown to suffer from\nperformance loss due to basis mismatch, we demonstrate that this is not an\ninherent property of compressive measurements. Our contributions are summarized\nas follows: (a) We identify the isometries required to preserve fundamental\nestimation-theoretic quantities such as the Ziv-Zakai bound (ZZB) and the\nCramer-Rao bound (CRB). Under such isometries, compressive projections can be\ninterpreted simply as a reduction in \"effective SNR.\" (b) We show that the\nthreshold behavior of the ZZB provides a criterion for determining the minimum\nnumber of measurements for \"accurate\" parameter estimation. (c) We provide\ndetailed computations of the number of measurements needed for the isometries\nin (a) to hold for the problem of frequency estimation in a mixture of\nsinusoids. We show via simulations that the design criterion in (b) is accurate\nfor estimating the frequency of a single sinusoid. \n\n"}
{"id": "1305.3054", "contents": "Title: The Degrees of Freedom of the MIMO Y-channel Abstract: The degrees of freedom (DoF) of the MIMO Y-channel, a multi-way communication\nnetwork consisting of 3 users and a relay, are characterized for arbitrary\nnumber of antennas. The converse is provided by cut-set bounds and novel\ngenie-aided bounds. The achievability is shown by a scheme that uses\nbeamforming to establish network coding on-the-fly at the relay in the uplink,\nand zero-forcing pre-coding in the downlink. It is shown that the network has\nmin{2M_2+2M_3,M_1+M_2+M_3,2N} DoF, where M_j and N represent the number of\nantennas at user j and the relay, respectively. Thus, in the extreme case where\nM_1+M_2+M_3 dominates the DoF expression and is smaller than N, the network has\nthe same DoF as the MAC between the 3 users and the relay. In this case, a\ndecode and forward strategy is optimal. In the other extreme where 2N\ndominates, the DoF of the network is twice that of the aforementioned MAC, and\nhence network coding is necessary. As a byproduct of this work, it is shown\nthat channel output feedback from the relay to the users has no impact on the\nDoF of this channel. \n\n"}
{"id": "1305.4314", "contents": "Title: Secure Cascade Channel Synthesis Abstract: We investigate channel synthesis in a cascade setting where nature provides\nan iid sequence $X^n$ at node 1. Node 1 can send a message at rate $R_1$ to\nnode 2 and node 2 can send a message at rate $R_2$ to node 3. Additionally, all\n3 nodes share bits of common randomness at rate $R_0$. We want to generate\nsequences $Y^n$ and $Z^n$ along nodes in the cascade such that $(X^n,Y^n,Z^n)$\nappears to be appropriately correlated and iid even to an eavesdropper who is\ncognizant of the messages being sent. We characterize the optimal tradeoff\nbetween the amount of common randomness used and the required rates of\ncommunication. We also solve the problem for arbitrarily long cascades and\nprovide an inner bound for cascade channel synthesis without an eavesdropper. \n\n"}
{"id": "1305.4755", "contents": "Title: Large-System Analysis of Correlated MIMO Multiple Access Channels with\n  Arbitrary Signaling in the Presence of Interference Abstract: Presence of multiple antennas on both sides of a communication channel\npromises significant improvements in system throughput and power efficiency. In\neffect, a new class of large multiple-input multiple-output (MIMO)\ncommunication systems has recently emerged and attracted both scientific and\nindustrial attention. To analyze these systems in realistic scenarios, one has\nto include such aspects as co-channel interference, multiple access and spatial\ncorrelation. In this paper, we study the properties of correlated MIMO\nmultiple-access channels in the presence of external interference. Using the\nreplica method from statistical physics, we derive the ergodic sum-rate of the\ncommunication for arbitrary signal constellations when the numbers of antennas\nat both ends of the channel grow large. Based on these asymptotic expressions,\nwe also address the problem of sum-rate maximization using statistical channel\ninformation and linear precoding. The numerical results demonstrate that when\nthe interfering terminals use discrete constellations, the resulting\ninterference becomes easier to handle compared to Gaussian signals. Thus, it\nmay be possible to accommodate more interfering transmitter-receiver pairs\nwithin the same area as compared to the case of Gaussian signals. In addition,\nwe demonstrate numerically for the Gaussian and QPSK signaling schemes that it\nis possible to design precoder matrices that significantly improve the\nachievable rates at low-to-mid range of signal-to-noise ratios when compared to\nisotropic precoding. \n\n"}
{"id": "1305.4976", "contents": "Title: Noncoherent Trellis Coded Quantization: A Practical Limited Feedback\n  Technique for Massive MIMO Systems Abstract: Accurate channel state information (CSI) is essential for attaining\nbeamforming gains in single-user (SU) multiple-input multiple-output (MIMO) and\nmultiplexing gains in multi-user (MU) MIMO wireless communication systems.\nState-of-the-art limited feedback schemes, which rely on pre-defined codebooks\nfor channel quantization, are only appropriate for a small number of transmit\nantennas and low feedback overhead. In order to scale informed transmitter\nschemes to emerging massive MIMO systems with a large number of transmit\nantennas at the base station, one common approach is to employ time division\nduplexing (TDD) and to exploit the implicit feedback obtained from channel\nreciprocity. However, most existing cellular deployments are based on frequency\ndivision duplexing (FDD), hence it is of great interest to explore backwards\ncompatible massive MIMO upgrades of such systems. For a fixed feedback rate per\nantenna, the number of codewords for quantizing the channel grows exponentially\nwith the number of antennas, hence generating feedback based on look-up from a\nstandard vector quantized codebook does not scale. In this paper, we propose\nnoncoherent trellis-coded quantization (NTCQ), whose encoding complexity scales\nlinearly with the number of antennas. The approach exploits the duality between\nsource encoding in a Grassmannian manifold and noncoherent sequence detection.\nFurthermore, since noncoherent detection can be realized near-optimally using a\nbank of coherent detectors, we obtain a low-complexity implementation of NTCQ\nencoding using an off-the-shelf Viterbi algorithm applied to standard trellis\ncoded quantization. We also develop advanced NTCQ schemes which utilize various\nchannel properties such as temporal/spatial correlations. Simulation results\nshow the proposed NTCQ and its extensions can achieve near-optimal performance\nwith moderate complexity and feedback overhead. \n\n"}
{"id": "1305.4996", "contents": "Title: Base Station Sleeping and Resource Allocation in Renewable Energy\n  Powered Cellular Networks Abstract: We consider energy-efficient wireless resource management in cellular\nnetworks where BSs are equipped with energy harvesting devices, using\nstatistical information for traffic intensity and harvested energy. The problem\nis formulated as adapting BSs' on-off states, active resource blocks (e.g.\nsubcarriers) as well as power allocation to minimize the average grid power\nconsumption in a given time period while satisfying the users' quality of\nservice (blocking probability) requirements. It is transformed into an\nunconstrained optimization problem to minimize a weighted sum of grid power\nconsumption and blocking probability. A two-stage dynamic programming (DP)\nalgorithm is then proposed to solve this optimization problem, by which the\nBSs' on-off states are optimized in the first stage, and the active BS's\nresource blocks are allocated iteratively in the second stage. Compared with\nthe optimal joint BSs' on-off states and active resource blocks allocation\nalgorithm, the proposed algorithm greatly reduces the computational complexity,\nwhile at the same time achieves close to the optimal energy saving performance. \n\n"}
{"id": "1305.5082", "contents": "Title: Performance of Joint Channel and Physical Network Coding Based on\n  Alamouti STBC Abstract: This work considers the protograph-coded physical network coding (PNC) based\non Alamouti space-time block coding (STBC) over Nakagami-fading two-way relay\nchannels, in which both the two sources and relay possess two antennas. We\nfirst propose a novel precoding scheme at the two sources so as to implement\nthe iterative decoder efficiently at the relay. We further address a simplified\nupdating rule of the log-likelihood-ratio (LLR) in such a decoder. Based on the\nsimplified LLR-updating rule and Gaussian approximation, we analyze the\ntheoretical bit-error-rate (BER) of the system, which is shown to be consistent\nwith the decoding thresholds and simulated results. Moreover, the theoretical\nanalysis has lower computational complexity than the protograph extrinsic\ninformation transfer (PEXIT) algorithm. Consequently, the analysis not only\nprovides a simple way to evaluate the error performance but also facilitates\nthe design of the joint channel-and-PNC (JCNC) in wireless communication\nscenarios. \n\n"}
{"id": "1305.7252", "contents": "Title: Joint Spatial Division and Multiplexing: Opportunistic Beamforming and\n  User Grouping Abstract: Joint Spatial Division and Multiplexing (JSDM) is a recently proposed scheme\nto enable massive MIMO like gains and simplified system operations for\nFrequency Division Duplexing (FDD) systems. The key idea lies in partitioning\nthe users into groups with approximately similar covariances, and use a two\nstage downlink beamforming: a pre-beamformer that depends on the channel\ncovariances and minimizes interference across groups and a multiuser MIMO\nprecoder for the effective channel after pre-beamforming, to counteract\ninterference within a group. We first focus on the regime of a fixed number of\nantennas and large number of users, and show that opportunistic beamforming\nwith user selection yields significant gain, and thus, channel correlation may\nyield a capacity improvement over the uncorrelated \"isotropic\" channel result\nof Sharif and Hassibi. We prove that in the presence of different correlations\namong groups, a block diagonalization approach for the design of\npre-beamformers achieves the optimal sum-rate scaling. Next, we consider the\nregime of large number of antennas and users, where user selection does not\nprovide significant gain. Here, we propose a simplified user grouping algorithm\nto cluster users into groups when the number of antennas becomes very large, in\na realistic setting where users are randomly distributed and have different\nangles of arrival and angular spreads depending on the propagation environment.\nOur subsequent analysis leads to a probabilistic scheduling algorithm, where\nusers within each group are preselected at random based on probabilities\nderived from the large system analysis, depending on the fairness criterion.\nThis is advantageous since only the selected users are required to feedback\ntheir channel state information (CSIT). \n\n"}
{"id": "1306.0626", "contents": "Title: Provable Inductive Matrix Completion Abstract: Consider a movie recommendation system where apart from the ratings\ninformation, side information such as user's age or movie's genre is also\navailable. Unlike standard matrix completion, in this setting one should be\nable to predict inductively on new users/movies. In this paper, we study the\nproblem of inductive matrix completion in the exact recovery setting. That is,\nwe assume that the ratings matrix is generated by applying feature vectors to a\nlow-rank matrix and the goal is to recover back the underlying matrix.\nFurthermore, we generalize the problem to that of low-rank matrix estimation\nusing rank-1 measurements. We study this generic problem and provide conditions\nthat the set of measurements should satisfy so that the alternating\nminimization method (which otherwise is a non-convex method with no convergence\nguarantees) is able to recover back the {\\em exact} underlying low-rank matrix.\n  In addition to inductive matrix completion, we show that two other low-rank\nestimation problems can be studied in our framework: a) general low-rank matrix\nsensing using rank-1 measurements, and b) multi-label regression with missing\nlabels. For both the problems, we provide novel and interesting bounds on the\nnumber of measurements required by alternating minimization to provably\nconverges to the {\\em exact} low-rank matrix. In particular, our analysis for\nthe general low rank matrix sensing problem significantly improves the required\nstorage and computational cost than that required by the RIP-based matrix\nsensing methods \\cite{RechtFP2007}. Finally, we provide empirical validation of\nour approach and demonstrate that alternating minimization is able to recover\nthe true matrix for the above mentioned problems using a small number of\nmeasurements. \n\n"}
{"id": "1306.1922", "contents": "Title: Collaborative 20 Questions for Target Localization Abstract: We consider the problem of 20 questions with noise for multiple players under\nthe minimum entropy criterion in the setting of stochastic search, with\napplication to target localization. Each player yields a noisy response to a\nbinary query governed by a certain error probability. First, we propose a\nsequential policy for constructing questions that queries each player in\nsequence and refines the posterior of the target location. Second, we consider\na joint policy that asks all players questions in parallel at each time instant\nand characterize the structure of the optimal policy for constructing the\nsequence of questions. This generalizes the single player probabilistic\nbisection method for stochastic search problems. Third, we prove an equivalence\nbetween the two schemes showing that, despite the fact that the sequential\nscheme has access to a more refined filtration, the joint scheme performs just\nas well on average. Fourth, we establish convergence rates of the mean-square\nerror (MSE) and derive error exponents. Lastly, we obtain an extension to the\ncase of unknown error probabilities. This framework provides a mathematical\nmodel for incorporating a human in the loop for active machine learning\nsystems. \n\n"}
{"id": "1306.3529", "contents": "Title: Scalable Successive-Cancellation Hardware Decoder for Polar Codes Abstract: Polar codes, discovered by Ar{\\i}kan, are the first error-correcting codes\nwith an explicit construction to provably achieve channel capacity,\nasymptotically. However, their error-correction performance at finite lengths\ntends to be lower than existing capacity-approaching schemes. Using the\nsuccessive-cancellation algorithm, polar decoders can be designed for very long\ncodes, with low hardware complexity, leveraging the regular structure of such\ncodes. We present an architecture and an implementation of a scalable hardware\ndecoder based on this algorithm. This design is shown to scale to code lengths\nof up to N = 2^20 on an Altera Stratix IV FPGA, limited almost exclusively by\nthe amount of available SRAM. \n\n"}
{"id": "1306.3801", "contents": "Title: Towards a better compressed sensing Abstract: In this paper we look at a well known linear inverse problem that is one of\nthe mathematical cornerstones of the compressed sensing field. In seminal works\n\\cite{CRT,DOnoho06CS} $\\ell_1$ optimization and its success when used for\nrecovering sparse solutions of linear inverse problems was considered.\nMoreover, \\cite{CRT,DOnoho06CS} established for the first time in a statistical\ncontext that an unknown vector of linear sparsity can be recovered as a known\nexisting solution of an under-determined linear system through $\\ell_1$\noptimization. In \\cite{DonohoPol,DonohoUnsigned} (and later in\n\\cite{StojnicCSetam09,StojnicUpper10}) the precise values of the linear\nproportionality were established as well. While the typical $\\ell_1$\noptimization behavior has been essentially settled through the work of\n\\cite{DonohoPol,DonohoUnsigned,StojnicCSetam09,StojnicUpper10}, we in this\npaper look at possible upgrades of $\\ell_1$ optimization. Namely, we look at a\ncouple of algorithms that turn out to be capable of recovering a substantially\nhigher sparsity than the $\\ell_1$. However, these algorithms assume a bit of\n\"feedback\" to be able to work at full strength. This in turn then translates\nthe original problem of improving upon $\\ell_1$ to designing algorithms that\nwould be able to provide output needed to feed the $\\ell_1$ upgrades considered\nin this papers. \n\n"}
{"id": "1306.4355", "contents": "Title: Blind Calibration in Compressed Sensing using Message Passing Algorithms Abstract: Compressed sensing (CS) is a concept that allows to acquire compressible\nsignals with a small number of measurements. As such it is very attractive for\nhardware implementations. Therefore, correct calibration of the hardware is a\ncentral is- sue. In this paper we study the so-called blind calibration, i.e.\nwhen the training signals that are available to perform the calibration are\nsparse but unknown. We extend the approximate message passing (AMP) algorithm\nused in CS to the case of blind calibration. In the calibration-AMP, both the\ngains on the sensors and the elements of the signals are treated as unknowns.\nOur algorithm is also applica- ble to settings in which the sensors distort the\nmeasurements in other ways than multiplication by a gain, unlike previously\nsuggested blind calibration algorithms based on convex relaxations. We study\nnumerically the phase diagram of the blind calibration problem, and show that\neven in cases where convex relaxation is pos- sible, our algorithm requires a\nsmaller number of measurements and/or signals in order to perform well. \n\n"}
{"id": "1306.6116", "contents": "Title: Distributed Estimation and Detection with Bounded Transmissions over\n  Gaussian Multiple Access Channels Abstract: A distributed inference scheme which uses bounded transmission functions over\na Gaussian multiple access channel is considered. When the sensor measurements\nare decreasingly reliable as a function of the sensor index, the conditions on\nthe transmission functions under which consistent estimation and reliable\ndetection are possible is characterized. For the distributed estimation\nproblem, an estimation scheme that uses bounded transmission functions is\nproved to be strongly consistent provided that the variance of the noise\nsamples are bounded and that the transmission function is one-to-one. The\nproposed estimation scheme is compared with the amplify-and-forward technique\nand its robustness to impulsive sensing noise distributions is highlighted. In\ncontrast to amplify-and-forward schemes, it is also shown that bounded\ntransmissions suffer from inconsistent estimates if the sensing noise variance\ngoes to infinity. For the distributed detection problem, similar results are\nobtained by studying the deflection coefficient. Simulations corroborate our\nanalytical results. \n\n"}
{"id": "1306.6265", "contents": "Title: Towards Secure Two-Party Computation from the Wire-Tap Channel Abstract: We introduce a new protocol for secure two-party computation of linear\nfunctions in the semi-honest model, based on coding techniques. We first\nestablish a parallel between the second version of the wire-tap channel model\nand secure two-party computation. This leads us to our protocol, that combines\nlinear coset coding and oblivious transfer techniques. Our construction\nrequires the use of binary intersecting codes or $q$-ary minimal codes, which\nare also studied in this paper. \n\n"}
{"id": "1307.1630", "contents": "Title: Power Allocation Strategies in Energy Harvesting Wireless Cooperative\n  Networks Abstract: In this paper, a wireless cooperative network is considered, in which\nmultiple source-destination pairs communicate with each other via an energy\nharvesting relay. The focus of this paper is on the relay's strategies to\ndistribute the harvested energy among the multiple users and their impact on\nthe system performance. Specifically, a non-cooperative strategy is to use the\nenergy harvested from the i-th source as the relay transmission power to the\ni-th destination, to which asymptotic results show that its outage performance\ndecays as logSNR over SNR. A faster decaying rate, 1 over SNR, can be achieved\nby the two centralized strategies proposed this the paper, where the water\nfilling based one can achieve optimal performance with respect to several\ncriteria, with a price of high complexity. An auction based power allocation\nscheme is also proposed to achieve a better tradeoff between the system\nperformance and complexity. Simulation results are provided to confirm the\naccuracy of the developed analytical results and facilitate a better\nperformance comparison. \n\n"}
{"id": "1307.2136", "contents": "Title: Near-Optimal Encoding for Sigma-Delta Quantization of Finite Frame\n  Expansions Abstract: In this paper we investigate encoding the bit-stream resulting from coarse\nSigma-Delta quantization of finite frame expansions (i.e., overdetermined\nrepresentations) of vectors. We show that for a wide range of finite-frames,\nincluding random frames and piecewise smooth frames, there exists a simple\nencoding algorithm ---acting only on the Sigma-Delta bit stream--- and an\nassociated decoding algorithm that together yield an approximation error which\ndecays exponentially in the number of bits used. The encoding strategy consists\nof applying a discrete random operator to the Sigma-Delta bit stream and\nassigning a binary codeword to the result. The reconstruction procedure is\nessentially linear and equivalent to solving a least squares minimization\nproblem. \n\n"}
{"id": "1307.4149", "contents": "Title: Self-Interference Cancellation with Phase Noise Induced ICI Suppression\n  for Full-Duplex Systems Abstract: One of the main bottlenecks in practical full-duplex systems is the\noscillator phase noise, which bounds the possible cancellable self-interference\npower. In this paper, a digitaldomain self-interference cancellation scheme for\nfull-duplex orthogonal frequency division multiplexing systems is proposed. The\nproposed scheme increases the amount of cancellable selfinterference power by\nsuppressing the effect of both transmitter and receiver oscillator phase noise.\nThe proposed scheme consists of two main phases, an estimation phase and a\ncancellation phase. In the estimation phase, the minimum mean square error\nestimator is used to jointly estimate the transmitter and receiver phase noise\nassociated with the incoming self-interference signal. In the cancellation\nphase, the estimated phase noise is used to suppress the intercarrier\ninterference caused by the phase noise associated with the incoming\nself-interference signal. The performance of the proposed scheme is numerically\ninvestigated under different operating conditions. It is demonstrated that the\nproposed scheme could achieve up to 9dB more self-interference cancellation\nthan the existing digital-domain cancellation schemes that ignore the\nintercarrier interference suppression. \n\n"}
{"id": "1307.4502", "contents": "Title: Universally Elevating the Phase Transition Performance of Compressed\n  Sensing: Non-Isometric Matrices are Not Necessarily Bad Matrices Abstract: In compressed sensing problems, $\\ell_1$ minimization or Basis Pursuit was\nknown to have the best provable phase transition performance of recoverable\nsparsity among polynomial-time algorithms. It is of great theoretical and\npractical interest to find alternative polynomial-time algorithms which perform\nbetter than $\\ell_1$ minimization. \\cite{Icassp reweighted l_1}, \\cite{Isit\nreweighted l_1}, \\cite{XuScaingLaw} and \\cite{iterativereweightedjournal} have\nshown that a two-stage re-weighted $\\ell_1$ minimization algorithm can boost\nthe phase transition performance for signals whose nonzero elements follow an\namplitude probability density function (pdf) $f(\\cdot)$ whose $t$-th derivative\n$f^{t}(0) \\neq 0$ for some integer $t \\geq 0$. However, for signals whose\nnonzero elements are strictly suspended from zero in distribution (for example,\nconstant-modulus, only taking values `$+d$' or `$-d$' for some nonzero real\nnumber $d$), no polynomial-time signal recovery algorithms were known to\nprovide better phase transition performance than plain $\\ell_1$ minimization,\nespecially for dense sensing matrices. In this paper, we show that a\npolynomial-time algorithm can universally elevate the phase-transition\nperformance of compressed sensing, compared with $\\ell_1$ minimization, even\nfor signals with constant-modulus nonzero elements. Contrary to conventional\nwisdoms that compressed sensing matrices are desired to be isometric, we show\nthat non-isometric matrices are not necessarily bad sensing matrices. In this\npaper, we also provide a framework for recovering sparse signals when sensing\nmatrices are not isometric. \n\n"}
{"id": "1307.5296", "contents": "Title: First-Come-First-Served for Online Slot Allocation and Huffman Coding Abstract: Can one choose a good Huffman code on the fly, without knowing the underlying\ndistribution? Online Slot Allocation (OSA) models this and similar problems:\nThere are n slots, each with a known cost. There are n items. Requests for\nitems are drawn i.i.d. from a fixed but hidden probability distribution p.\nAfter each request, if the item, i, was not previously requested, then the\nalgorithm (knowing the slot costs and the requests so far, but not p) must\nplace the item in some vacant slot j(i). The goal is to minimize the sum, over\nthe items, of the probability of the item times the cost of its assigned slot.\n  The optimal offline algorithm is trivial: put the most probable item in the\ncheapest slot, the second most probable item in the second cheapest slot, etc.\nThe optimal online algorithm is First Come First Served (FCFS): put the first\nrequested item in the cheapest slot, the second (distinct) requested item in\nthe second cheapest slot, etc. The optimal competitive ratios for any online\nalgorithm are 1+H(n-1) ~ ln n for general costs and 2 for concave costs. For\nlogarithmic costs, the ratio is, asymptotically, 1: FCFS gives cost opt + O(log\nopt).\n  For Huffman coding, FCFS yields an online algorithm (one that allocates\ncodewords on demand, without knowing the underlying probability distribution)\nthat guarantees asymptotically optimal cost: at most opt + 2 log(1+opt) + 2. \n\n"}
{"id": "1307.6125", "contents": "Title: Interference alignment using finite and dependent channel extensions:\n  the single beam case Abstract: Vector space interference alignment (IA) is known to achieve high degrees of\nfreedom (DoF) with infinite independent channel extensions, but its performance\nis largely unknown for a finite number of possibly dependent channel\nextensions. In this paper, we consider a $K$-user $M_t \\times M_r$ MIMO\ninterference channel (IC) with arbitrary number of channel extensions $T$ and\narbitrary channel diversity order $L$ (i.e., each channel matrix is a generic\nlinear combination of $L$ fixed basis matrices). We study the maximum DoF\nachievable via vector space IA in the single beam case (i.e. each user sends\none data stream). We prove that the total number of users $K$ that can\ncommunicate interference-free using linear transceivers is upper bounded by\n$NL+N^2/4$, where $N = \\min\\{M_tT, M_rT \\}$. An immediate consequence of this\nupper bound is that for a SISO IC the DoF in the single beam case is no more\nthan $\\min\\left\\{\\sqrt{ 5K/4}, L + T/4\\right\\}$. When the channel extensions\nare independent, i.e. $ L$ achieves the maximum $M_r M_t T $, we show that this\nmaximum DoF lies in $[M_r+M_t-1, M_r+M_t]$ regardless of $T$. Unlike the\nwell-studied constant MIMO IC case, the main difficulty is how to deal with a\nhybrid system of equations (zero-forcing condition) and inequalities (full rank\ncondition). Our approach combines algebraic tools that deal with equations with\nan induction analysis that indirectly considers the inequalities. \n\n"}
{"id": "1307.6458", "contents": "Title: Distinguisher-Based Attacks on Public-Key Cryptosystems Using\n  Reed-Solomon Codes Abstract: Because of their interesting algebraic properties, several authors promote\nthe use of generalized Reed-Solomon codes in cryptography. Niederreiter was the\nfirst to suggest an instantiation of his cryptosystem with them but Sidelnikov\nand Shestakov showed that this choice is insecure. Wieschebrink proposed a\nvariant of the McEliece cryptosystem which consists in concatenating a few\nrandom columns to a generator matrix of a secretly chosen generalized\nReed-Solomon code. More recently, new schemes appeared which are the\nhomomorphic encryption scheme proposed by Bogdanov and Lee, and a variation of\nthe McEliece cryptosystem proposed by Baldi et \\textit{al.} which hides the\ngeneralized Reed-Solomon code by means of matrices of very low rank.\n  In this work, we show how to mount key-recovery attacks against these\npublic-key encryption schemes. We use the concept of distinguisher which aims\nat detecting a behavior different from the one that one would expect from a\nrandom code. All the distinguishers we have built are based on the notion of\ncomponent-wise product of codes. It results in a powerful tool that is able to\nrecover the secret structure of codes when they are derived from generalized\nReed-Solomon codes. Lastly, we give an alternative to Sidelnikov and Shestakov\nattack by building a filtration which enables to completely recover the support\nand the non-zero scalars defining the secret generalized Reed-Solomon code. \n\n"}
{"id": "1307.6843", "contents": "Title: Optimal Quantization for Distribution Synthesis Abstract: Finite precision approximations of discrete probability distributions are\nconsidered, applicable for distribution synthesis, e.g., probabilistic shaping.\nTwo algorithms are presented that find the optimal $M$-type approximation $Q$\nof a distribution $P$ in terms of the variational distance $| Q-P|_1$ and the\ninformational divergence $\\mathbb{D}(Q| P)$. Bounds on the approximation errors\nare derived and shown to be asymptotically tight. Several examples illustrate\nthat the variational distance optimal approximation can be quite different from\nthe informational divergence optimal approximation. \n\n"}
{"id": "1309.0088", "contents": "Title: Caching Gain in Wireless Networks with Fading: A Multi-User Diversity\n  Perspective Abstract: We consider the effect of caching in wireless networks where fading is the\ndominant channel effect. First, we propose a one-hop transmission strategy for\ncache-enabled wireless networks, which is based on exploiting multi-user\ndiversity gain. Then, we derive a closed-form result for throughput scaling of\nthe proposed scheme in large networks, which reveals the inherent trade-off\nbetween cache memory size and network throughput. Our results show that\nsubstantial throughput improvements are achievable in networks with sources\nequipped with large cache size. We also verify our analytical result through\nsimulations. \n\n"}
{"id": "1309.0186", "contents": "Title: A Solution to the Network Challenges of Data Recovery in Erasure-coded\n  Distributed Storage Systems: A Study on the Facebook Warehouse Cluster Abstract: Erasure codes, such as Reed-Solomon (RS) codes, are being increasingly\nemployed in data centers to combat the cost of reliably storing large amounts\nof data. Although these codes provide optimal storage efficiency, they require\nsignificantly high network and disk usage during recovery of missing data. In\nthis paper, we first present a study on the impact of recovery operations of\nerasure-coded data on the data-center network, based on measurements from\nFacebook's warehouse cluster in production. To the best of our knowledge, this\nis the first study of its kind available in the literature. Our study reveals\nthat recovery of RS-coded data results in a significant increase in network\ntraffic, more than a hundred terabytes per day, in a cluster storing multiple\npetabytes of RS-coded data.\n  To address this issue, we present a new storage code using our recently\nproposed \"Piggybacking\" framework, that reduces the network and disk usage\nduring recovery by 30% in theory, while also being storage optimal and\nsupporting arbitrary design parameters. The implementation of the proposed code\nin the Hadoop Distributed File System (HDFS) is underway. We use the\nmeasurements from the warehouse cluster to show that the proposed code would\nlead to a reduction of close to fifty terabytes of cross-rack traffic per day. \n\n"}
{"id": "1309.1976", "contents": "Title: Source Broadcasting to the Masses: Separation has a Bounded Loss Abstract: This work discusses the source broadcasting problem, i.e. transmitting a\nsource to many receivers via a broadcast channel. The optimal rate-distortion\nregion for this problem is unknown. The separation approach divides the problem\ninto two complementary problems: source successive refinement and broadcast\nchannel transmission. We provide bounds on the loss incorporated by applying\ntime-sharing and separation in source broadcasting. If the broadcast channel is\ndegraded, it turns out that separation-based time-sharing achieves at least a\nfactor of the joint source-channel optimal rate, and this factor has a positive\nlimit even if the number of receivers increases to infinity. For the AWGN\nbroadcast channel a better bound is introduced, implying that all achievable\njoint source-channel schemes have a rate within one bit of the separation-based\nachievable rate region for two receivers, or within $\\log_2 T$ bits for $T$\nreceivers. \n\n"}
{"id": "1309.2473", "contents": "Title: Interference Alignment with Diversity for the $2 \\times 2$ $X$-Network\n  with three antennas Abstract: Interference alignment is known to achieve the maximum sum DoF of\n$\\frac{4M}{3}$ in the $2 \\times 2$ $X$-Network (i.e., two-transmitter (Tx)\ntwo-receiver (Rx) $X$-Network) with $M$ antennas at each node, as demonstrated\nby Jafar and Shamai. Recently, an Alamouti code based transmission scheme,\nwhich we call the Li-Jafarkhani-Jafar (LJJ) scheme, was proposed for the $2\n\\times 2$ $X$-Network with two antennas at each node. This scheme achieves a\nsum degrees of freedom (DoF) of $\\frac{8}{3}$ and also a diversity gain of two\nwhen fixed finite constellations are employed at each Tx. In the LJJ scheme,\neach Tx required the knowledge of only its own channel unlike the Jafar-Shamai\nscheme which required global CSIT to achieve the maximum possible sum DoF of\n$\\frac{8}{3}$. Bit error rate (BER) is an important performance metric when the\ncoding length is finite. This work first proposes a new STBC for a three\ntransmit antenna single user MIMO system. Building on this STBC, we extend the\nLJJ scheme to the $2 \\times 2$ $X$-Network with three antennas at each node.\nLocal channel knowledge is assumed at each Tx. It is shown that the proposed\nscheme achieves the maximum possible sum DoF of 4. A diversity gain of 3 is\nalso guaranteed when fixed finite constellation inputs are used. \n\n"}
{"id": "1309.4942", "contents": "Title: HetNets and Massive MIMO: Modeling, Potential Gains, and Performance\n  Analysis Abstract: We consider a heterogeneous cellular network (HetNet) where a macrocell tier\nwith a large antenna array base station (BS) is overlaid with a dense tier of\nsmall cells (SCs). We investigate the potential benefits of incorporating a\nmassive MIMO BS in a TDD-based HetNet and we provide analytical expressions for\nthe coverage probability and the area spectral efficiency using stochastic\ngeometry. The duplexing mode in which SCs should operate during uplink\nmacrocell transmissions is optimized. Furthermore, we consider a reverse TDD\nscheme, in which the massive MIMO BS can estimate the SC interference\ncovariance matrix. Our results suggest that significant throughput improvement\ncan be achieved by exploiting interference nulling and implicit coordination\nacross the tiers due to flexible and asymmetric TDD operation. \n\n"}
{"id": "1309.6073", "contents": "Title: Improved Analyses for SP and CoSaMP Algorithms in Terms of Restricted\n  Isometry Constants Abstract: In the context of compressed sensing (CS), both Subspace Pursuit (SP) and\nCompressive Sampling Matching Pursuit (CoSaMP) are very important iterative\ngreedy recovery algorithms which could reduce the recovery complexity greatly\ncomparing with the well-known $\\ell_1$-minimization. Restricted isometry\nproperty (RIP) and restricted isometry constant (RIC) of measurement matrices\nwhich ensure the convergency of iterative algorithms play key roles for the\nguarantee of successful reconstructions. In this paper, we show that for the\n$s$-sparse recovery, the RICs are enlarged to $\\delta_{3s}<0.4859$ for SP and\n$\\delta_{4s}<0.5$ for CoSaMP, which improve the known results significantly.\nThe proposed results also apply to almost sparse signal and corrupted\nmeasurements. \n\n"}
{"id": "1309.6200", "contents": "Title: On the Dispersions of the Gel'fand-Pinsker Channel and Dirty Paper\n  Coding Abstract: This paper studies second-order coding rates for memoryless channels with a\nstate sequence known non-causally at the encoder. In the case of finite\nalphabets, an achievability result is obtained using constant-composition\nrandom coding, and by using a small fraction of the block to transmit the type\nof the state sequence. For error probabilities less than 1/2, it is shown that\nthe second-order rate improves on an existing one based on i.i.d. random\ncoding. In the Gaussian case (dirty paper coding) with an almost-sure power\nconstraint, an achievability result is obtained used using random coding over\nthe surface of a sphere, and using a small fraction of the block to transmit a\nquantized description of the state power. It is shown that the second-order\nasymptotics are identical to the single-user Gaussian channel of the same input\npower without a state. \n\n"}
{"id": "1309.7528", "contents": "Title: Finite-Length Analyses for Source and Channel Coding on Markov Chains Abstract: We study finite-length bounds for source coding with side information for\nMarkov sources and channel coding for channels with conditional Markovian\nadditive noise. For this purpose, we propose two criteria for finite-length\nbounds. One is the asymptotic optimality and the other is the efficient\ncomputability of the bound. Then, we derive finite-length upper and lower\nbounds for coding length in both settings so that their computational\ncomplexity is efficient. To discuss the first criterion, we derive the large\ndeviation bounds, the moderate deviation bounds, and second order bounds for\nthese two topics, and show that these finite-length bounds achieves the\nasymptotic optimality in these senses. For this discussion, we introduce\nseveral kinds of information measure for transition matrices. \n\n"}
{"id": "1310.0677", "contents": "Title: DVB-S2 Spectrum Efficiency Improvement with Hierarchical Modulation Abstract: We study the design of a DVB-S2 system in order to maximise spectrum\nefficiency. This task is usually challenging due to channel variability. Modern\nsatellite communications systems such as DVB-SH and DVB-S2 rely mainly on a\ntime sharing strategy to optimise the spectrum efficiency. Recently, we showed\nthat combining time sharing with hierarchical modulation can provide\nsignificant gains (in terms of spectrum efficiency) compared to the best time\nsharing strategy. However, our previous design does not improve the DVB-S2\nperformance when all the receivers experience low or large signal-to-noise\nratios. In this article, we introduce and study a hierarchical QPSK and a\nhierarchical 32-APSK to overcome the previous limitations.We show in a\nrealistic case based on DVB-S2 that the hierarchical QPSK provides an\nimprovement when the receivers experience poor channel condition, while the\n32-APSK increases the spectrum efficiency when the receivers experience good\nchannel condition. \n\n"}
{"id": "1310.1510", "contents": "Title: Massive MU-MIMO Downlink TDD Systems with Linear Precoding and Downlink\n  Pilots Abstract: We consider a massive MU-MIMO downlink time-division duplex system where a\nbase station (BS) equipped with many antennas serves several single-antenna\nusers in the same time-frequency resource. We assume that the BS uses linear\nprecoding for the transmission. To reliably decode the signals transmitted from\nthe BS, each user should have an estimate of its channel. In this work, we\nconsider an efficient channel estimation scheme to acquire CSI at each user,\ncalled beamforming training scheme. With the beamforming training scheme, the\nBS precodes the pilot sequences and forwards to all users. Then, based on the\nreceived pilots, each user uses minimum mean-square error channel estimation to\nestimate the effective channel gains. The channel estimation overhead of this\nscheme does not depend on the number of BS antennas, and is only proportional\nto the number of users. We then derive a lower bound on the capacity for\nmaximum-ratio transmission and zero-forcing precoding techniques which enables\nus to evaluate the spectral efficiency taking into account the spectral\nefficiency loss associated with the transmission of the downlink pilots.\nComparing with previous work where each user uses only the statistical channel\nproperties to decode the transmitted signals, we see that the proposed\nbeamforming training scheme is preferable for moderate and low-mobility\nenvironments. \n\n"}
{"id": "1310.1571", "contents": "Title: Transmit Beamforming for MIMO Communication Systems with Low Precision\n  ADC at the Receiver Abstract: Multiple antenna systems have been extensively used by standards designing\nmulti-gigabit communication systems operating in bandwidth of several GHz. In\nthis paper, we study the use of transmitter (Tx) beamforming techniques to\nimprove the performance of a MIMO system with a low precision ADC. We motivate\nan approach to use eigenmode transmit beamforming (which imposes a diagonal\nstructure in the complete MIMO system) and use an eigenmode power allocation\nwhich minimizes the uncoded BER of the finite precision system. Although we\ncannot guarantee optimality of this approach, we observe that even low with\nprecision ADC, it performs comparably to full precision system with no\neigenmode power allocation. For example, in a high throughput MIMO system with\na finite precision ADC at the receiver, simulation results show that for a 3/4\nLDPC coded 2x2 MIMO OFDM 16-QAM system with 3-bit precision ADC at the\nreceiver, a BER of 0.0001 is achieved at an SNR of 26 dB. This is 1 dB better\nthan that required for the same system with full precision but equal eigenmode\npower allocation. \n\n"}
{"id": "1310.3724", "contents": "Title: Spatially Coupled Sparse Codes on Graphs - Theory and Practice Abstract: Since the discovery of turbo codes 20 years ago and the subsequent\nre-discovery of low-density parity-check codes a few years later, the field of\nchannel coding has experienced a number of major advances. Up until that time,\ncode designers were usually happy with performance that came within a few\ndecibels of the Shannon Limit, primarily due to implementation complexity\nconstraints, whereas the new coding techniques now allow performance within a\nsmall fraction of a decibel of capacity with modest encoding and decoding\ncomplexity. Due to these significant improvements, coding standards in\napplications as varied as wireless mobile transmission, satellite TV, and deep\nspace communication are being updated to incorporate the new techniques. In\nthis paper, we review a particularly exciting new class of low-density\nparity-check codes, called spatially-coupled codes, which promise excellent\nperformance over a broad range of channel conditions and decoded error rate\nrequirements. \n\n"}
{"id": "1310.6817", "contents": "Title: Systematic Error-Correcting Codes for Rank Modulation Abstract: The rank-modulation scheme has been recently proposed for efficiently storing\ndata in nonvolatile memories. Error-correcting codes are essential for rank\nmodulation, however, existing results have been limited. In this work we\nexplore a new approach, \\emph{systematic error-correcting codes for rank\nmodulation}. Systematic codes have the benefits of enabling efficient\ninformation retrieval and potentially supporting more efficient encoding and\ndecoding procedures. We study systematic codes for rank modulation under\nKendall's $\\tau$-metric as well as under the $\\ell_\\infty$-metric.\n  In Kendall's $\\tau$-metric we present $[k+2,k,3]$-systematic codes for\ncorrecting one error, which have optimal rates, unless systematic perfect codes\nexist. We also study the design of multi-error-correcting codes, and provide\ntwo explicit constructions, one resulting in $[n+1,k+1,2t+2]$ systematic codes\nwith redundancy at most $2t+1$. We use non-constructive arguments to show the\nexistence of $[n,k,n-k]$-systematic codes for general parameters. Furthermore,\nwe prove that for rank modulation, systematic codes achieve the same capacity\nas general error-correcting codes.\n  Finally, in the $\\ell_\\infty$-metric we construct two $[n,k,d]$ systematic\nmulti-error-correcting codes, the first for the case of $d=O(1)$, and the\nsecond for $d=\\Theta(n)$. In the latter case, the codes have the same\nasymptotic rate as the best codes currently known in this metric. \n\n"}
{"id": "1311.1888", "contents": "Title: D$^3$PO - Denoising, Deconvolving, and Decomposing Photon Observations Abstract: The analysis of astronomical images is a non-trivial task. The D3PO algorithm\naddresses the inference problem of denoising, deconvolving, and decomposing\nphoton observations. Its primary goal is the simultaneous but individual\nreconstruction of the diffuse and point-like photon flux given a single photon\ncount image, where the fluxes are superimposed. In order to discriminate\nbetween these morphologically different signal components, a probabilistic\nalgorithm is derived in the language of information field theory based on a\nhierarchical Bayesian parameter model. The signal inference exploits prior\ninformation on the spatial correlation structure of the diffuse component and\nthe brightness distribution of the spatially uncorrelated point-like sources. A\nmaximum a posteriori solution and a solution minimizing the Gibbs free energy\nof the inference problem using variational Bayesian methods are discussed.\nSince the derivation of the solution is not dependent on the underlying\nposition space, the implementation of the D3PO algorithm uses the NIFTY package\nto ensure applicability to various spatial grids and at any resolution. The\nfidelity of the algorithm is validated by the analysis of simulated data,\nincluding a realistic high energy photon count image showing a 32 x 32 arcmin^2\nobservation with a spatial resolution of 0.1 arcmin. In all tests the D3PO\nalgorithm successfully denoised, deconvolved, and decomposed the data into a\ndiffuse and a point-like signal estimate for the respective photon flux\ncomponents. \n\n"}
{"id": "1311.2369", "contents": "Title: The matching polytope has exponential extension complexity Abstract: A popular method in combinatorial optimization is to express polytopes P,\nwhich may potentially have exponentially many facets, as solutions of linear\nprograms that use few extra variables to reduce the number of constraints down\nto a polynomial. After two decades of standstill, recent years have brought\namazing progress in showing lower bounds for the so called extension\ncomplexity, which for a polytope P denotes the smallest number of inequalities\nnecessary to describe a higher dimensional polytope Q that can be linearly\nprojected on P.\n  However, the central question in this field remained wide open: can the\nperfect matching polytope be written as an LP with polynomially many\nconstraints?\n  We answer this question negatively. In fact, the extension complexity of the\nperfect matching polytope in a complete n-node graph is 2^Omega(n). By a known\nreduction this also improves the lower bound on the extension complexity for\nthe TSP polytope from 2^Omega(n^1/2) to 2^Omega(n). \n\n"}
{"id": "1311.2669", "contents": "Title: Distance-based and continuum Fano inequalities with applications to\n  statistical estimation Abstract: In this technical note, we give two extensions of the classical Fano\ninequality in information theory. The first extends Fano's inequality to the\nsetting of estimation, providing lower bounds on the probability that an\nestimator of a discrete quantity is within some distance $t$ of the quantity.\nThe second inequality extends our bound to a continuum setting and provides a\nvolume-based bound. We illustrate how these inequalities lead to direct and\nsimple proofs of several statistical minimax lower bounds. \n\n"}
{"id": "1311.3485", "contents": "Title: A New Algorithm for Distributed Nonparametric Sequential Detection Abstract: We consider nonparametric sequential hypothesis testing problem when the\ndistribution under the null hypothesis is fully known but the alternate\nhypothesis corresponds to some other unknown distribution with some loose\nconstraints. We propose a simple algorithm to address the problem. These\nproblems are primarily motivated from wireless sensor networks and spectrum\nsensing in Cognitive Radios. A decentralized version utilizing spatial\ndiversity is also proposed. Its performance is analysed and asymptotic\nproperties are proved. The simulated and analysed performance of the algorithm\nis compared with an earlier algorithm addressing the same problem with similar\nassumptions. We also modify the algorithm for optimizing performance when\ninformation about the prior probabilities of occurrence of the two hypotheses\nare known. \n\n"}
{"id": "1311.3887", "contents": "Title: Relating different quantum generalizations of the conditional Renyi\n  entropy Abstract: Recently a new quantum generalization of the Renyi divergence and the\ncorresponding conditional Renyi entropies was proposed. Here we report on a\nsurprising relation between conditional Renyi entropies based on this new\ngeneralization and conditional Renyi entropies based on the quantum relative\nRenyi entropy that was used in previous literature. Our result generalizes the\nwell-known duality relation H(A|B) + H(A|C) = 0 of the conditional von Neumann\nentropy for tripartite pure states to Renyi entropies of two different kinds.\n  As a direct application, we prove a collection of inequalities that relate\ndifferent conditional Renyi entropies and derive a new entropic uncertainty\nrelation. \n\n"}
{"id": "1311.3918", "contents": "Title: Sum Secrecy Rate in Full-Duplex Wiretap Channel with Imperfect CSI Abstract: In this paper, we consider the achievable sum secrecy rate in full-duplex\nwiretap channel in the presence of an eavesdropper and imperfect channel state\ninformation (CSI). We assume that the users participating in full-duplex\ncommunication and the eavesdropper have single antenna each. The users have\nindividual transmit power constraints. They also transmit jamming signals to\nimprove the secrecy rates. We obtain the achievable perfect secrecy rate region\nby maximizing the sum secrecy rate. We also obtain the corresponding optimum\npowers of the message signals and the jamming signals. Numerical results that\nshow the impact of imperfect CSI on the achievable secrecy rate region are\npresented. \n\n"}
{"id": "1311.4096", "contents": "Title: Distributed Data Storage Systems with Opportunistic Repair Abstract: The reliability of erasure-coded distributed storage systems, as measured by\nthe mean time to data loss (MTTDL), depends on the repair bandwidth of the\ncode. Repair-efficient codes provide reliability values several orders of\nmagnitude better than conventional erasure codes. Current state of the art\ncodes fix the number of helper nodes (nodes participating in repair) a priori.\nIn practice, however, it is desirable to allow the number of helper nodes to be\nadaptively determined by the network traffic conditions. In this work, we\npropose an opportunistic repair framework to address this issue. It is shown\nthat there exists a threshold on the storage overhead, below which such an\nopportunistic approach does not lose any efficiency from the optimal\nstorage-repair-bandwidth tradeoff; i.e. it is possible to construct a code\nsimultaneously optimal for different numbers of helper nodes. We further\nexamine the benefits of such opportunistic codes, and derive the MTTDL\nimprovement for two repair models: one with limited total repair bandwidth and\nthe other with limited individual-node repair bandwidth. In both settings, we\nshow orders of magnitude improvement in MTTDL. Finally, the proposed framework\nis examined in a network setting where a significant improvement in MTTDL is\nobserved. \n\n"}
{"id": "1312.0914", "contents": "Title: Characterizing the Rate Region of the (4,3,3) Exact-Repair Regenerating\n  Codes Abstract: Exact-repair regenerating codes are considered for the case (n,k,d)=(4,3,3),\nfor which a complete characterization of the rate region is provided. This\ncharacterization answers in the affirmative the open question whether there\nexists a non-vanishing gap between the optimal bandwidth-storage tradeoff of\nthe functional-repair regenerating codes (i.e., the cut-set bound) and that of\nthe exact-repair regenerating codes. To obtain an explicit information\ntheoretic converse, a computer-aided proof (CAP) approach based on primal and\ndual relation is developed. This CAP approach extends Yeung's linear\nprogramming (LP) method, which was previously only used on information\ntheoretic problems with a few random variables due to the exponential growth of\nthe number of variables in the corresponding LP problem. The symmetry in the\nexact-repair regenerating code problem allows an effective reduction of the\nnumber of variables, and together with several other problem-specific\nreductions, the LP problem is reduced to a manageable scale. For the\nachievability, only one non-trivial corner point of the rate region needs to be\naddressed in this case, for which an explicit binary code construction is\ngiven. \n\n"}
{"id": "1312.1577", "contents": "Title: On Coordinating Ultra-Dense Wireless Access Networks: Optimization\n  Modeling, Algorithms and Insights Abstract: Network densification along with universal resources reuse is expected to\nplay a key role in the realization of 5G radio access as an enabler for\ndelivering most of the anticipated network capacity improvements. On the one\nhand, neither the expected additional spectrum allocation nor the forthcoming\nnovel air-interface processing techniques will be sufficient for sustaining the\nanticipated exponentially-increasing mobile data traffic. On the other hand,\nenhanced ultra-dense infrastructure deployments are expected to provide\nremarkable capacity gains, regardless of the evolutionary or revolutionary\napproach followed towards 5G development. In this work, we thoroughly examine\nglobal network coordination as the main enabler for future 5G large dense\nsmall-cell deployments. We propose a powerful radio resources coordination\nframework through which interference management is handled network-wise and\njointly over multiple dimensions. In particular, we explore strategies for\npairing serving and served access nodes, partitioning the available network\nresources, as well as dynamically allocating power per pair, towards optimizing\nsystem performance and guaranteeing individual minimum performance levels. We\ndevelop new optimization formulations, providing network scaling performance\nupper bounds, along with lower complexity algorithmic solutions tailored to\nlarge networks. We apply the proposed solutions to dense network deployments,\nin order to obtain useful insights on network performance and optimization,\nsuch as rate scaling, infrastructure density, optimal bandwidth partitioning\nand spatial reuse factor optimization. \n\n"}
{"id": "1312.1830", "contents": "Title: Quantization and Greed are Good: One bit Phase Retrieval, Robustness and\n  Greedy Refinements Abstract: In this paper, we study the problem of robust phase recovery. We investigate\na novel approach based on extremely quantized (one-bit) phase-less measurements\nand a corresponding recovery scheme. The proposed approach has surprising\nrobustness and stability properties and, unlike currently available methods,\nallows to efficiently perform phase recovery from measurements affected by\nsevere (possibly unknown) non-linear perturbations, such as distortions (e.g.\nclipping). Beyond robustness, we show how our approach can be used within\ngreedy approaches based on alternating minimization. In particular, we propose\nnovel initialization schemes for the alternating minimization achieving\nfavorable convergence properties with improved sample complexity. \n\n"}
{"id": "1312.2183", "contents": "Title: Maximum Likelihood Estimation from Sign Measurements with Sensing Matrix\n  Perturbation Abstract: The problem of estimating an unknown deterministic parameter vector from sign\nmeasurements with a perturbed sensing matrix is studied in this paper. We\nanalyze the best achievable mean square error (MSE) performance by exploring\nthe corresponding Cram\\'{e}r-Rao Lower Bound (CRLB). To estimate the parameter,\nthe maximum likelihood (ML) estimator is utilized and its consistency is\nproved. We show that the perturbation on the sensing matrix exacerbates the\nperformance of ML estimator in most cases. However, suitable perturbation may\nimprove the performance in some special cases. Then we reformulate the original\nML estimation problem as a convex optimization problem, which can be solved\nefficiently. Furthermore, theoretical analysis implies that the\nperturbation-ignored estimation is a scaled version with the same direction of\nthe ML estimation. Finally, numerical simulations are performed to validate our\ntheoretical analysis. \n\n"}
{"id": "1312.2785", "contents": "Title: An efficient length- and rate-preserving concatenation of polar and\n  repetition codes Abstract: We improve the method in \\cite{Seidl:10} for increasing the finite-lengh\nperformance of polar codes by protecting specific, less reliable symbols with\nsimple outer repetition codes. Decoding of the scheme integrates easily in the\nknown successive decoding algorithms for polar codes. Overall rate and block\nlength remain unchanged, the decoding complexity is at most doubled. A\ncomparison to related methods for performance improvement of polar codes is\ndrawn. \n\n"}
{"id": "1312.3662", "contents": "Title: Partially Overlapping Tones for Uncoordinated Networks Abstract: In an uncoordinated network, the link performance between the devices might\ndegrade significantly due to the interference from other links in the network\nsharing the same spectrum. As a solution, in this study, the concept of\npartially overlapping tones (POT) is introduced. The interference energy\nobserved at the victim receiver is mitigated by partially overlapping the\nindividual subcarriers via an intentional carrier frequency offset between the\nlinks. Also, it is shown that while orthogonal transformations at the receiver\ncannot mitigate the other-user interference without losing spectral efficiency,\nnon-orthogonal transformations are able to mitigate the other-user interference\nwithout any spectral efficiency loss at the expense of self-interference. Using\nspatial Poisson point process, a tractable bit error rate analysis is provided\nto demonstrate potential benefits emerging from POT. \n\n"}
{"id": "1312.4378", "contents": "Title: Is Non-Unique Decoding Necessary? Abstract: In multi-terminal communication systems, signals carrying messages meant for\ndifferent destinations are often observed together at any given destination\nreceiver. Han and Kobayashi (1981) proposed a receiving strategy which performs\na joint unique decoding of messages of interest along with a subset of messages\nwhich are not of interest. It is now well-known that this provides an\nachievable region which is, in general, larger than if the receiver treats all\nmessages not of interest as noise. Nair and El Gamal (2009) and Chong, Motani,\nGarg, and El Gamal (2008) independently proposed a generalization called\nindirect or non-unique decoding where the receiver uses the codebook structure\nof the messages to uniquely decode only its messages of interest. Non-unique\ndecoding has since been used in various scenarios.\n  The main result in this paper is to provide an interpretation and a\nsystematic proof technique for why non-unique decoding, in all known cases\nwhere it has been employed, can be replaced by a particularly designed joint\nunique decoding strategy, without any penalty from a rate region viewpoint. \n\n"}
{"id": "1312.7198", "contents": "Title: Opportunistic Downlink Interference Alignment Abstract: In this paper, we propose an opportunistic downlink interference alignment\n(ODIA) for interference-limited cellular downlink, which intelligently combines\nuser scheduling and downlink IA techniques. The proposed ODIA not only\nefficiently reduces the effect of inter-cell interference from other-cell base\nstations (BSs) but also eliminates intra-cell interference among spatial\nstreams in the same cell. We show that the minimum number of users required to\nachieve a target degrees-of-freedom (DoF) can be fundamentally reduced, i.e.,\nthe fundamental user scaling law can be improved by using the ODIA, compared\nwith the existing downlink IA schemes. In addition, we adopt a limited feedback\nstrategy in the ODIA framework, and then analyze the required number of\nfeedback bits leading to the same performance as that of the ODIA assuming\nperfect feedback. We also modify the original ODIA in order to further improve\nsum-rate, which achieves the optimal multiuser diversity gain, i.e., $\\log \\log\nN$, per spatial stream even in the presence of downlink inter-cell\ninterference, where $N$ denotes the number of users in a cell. Simulation\nresults show that the ODIA significantly outperforms existing interference\nmanagement techniques in terms of sum-rate in realistic cellular environments.\nNote that the ODIA operates in a distributed and decoupled manner, while\nrequiring no information exchange among BSs and no iterative beamformer\noptimization between BSs and users, thus leading to an easier implementation. \n\n"}
{"id": "1401.1106", "contents": "Title: Structured random measurements in signal processing Abstract: Compressed sensing and its extensions have recently triggered interest in\nrandomized signal acquisition. A key finding is that random measurements\nprovide sparse signal reconstruction guarantees for efficient and stable\nalgorithms with a minimal number of samples. While this was first shown for\n(unstructured) Gaussian random measurement matrices, applications require\ncertain structure of the measurements leading to structured random measurement\nmatrices. Near optimal recovery guarantees for such structured measurements\nhave been developed over the past years in a variety of contexts. This article\nsurveys the theory in three scenarios: compressed sensing (sparse recovery),\nlow rank matrix recovery, and phaseless estimation. The random measurement\nmatrices to be considered include random partial Fourier matrices, partial\nrandom circulant matrices (subsampled convolutions), matrix completion, and\nphase estimation from magnitudes of Fourier type measurements. The article\nconcludes with a brief discussion of the mathematical techniques for the\nanalysis of such structured random measurements. \n\n"}
{"id": "1401.1467", "contents": "Title: The sum $2^{\\mathit{KA}(x)-\\mathit{KP}(x)}$ over all prefixes $x$ of\n  some binary sequence can be infinite Abstract: We consider two quantities that measure complexity of binary strings:\n$\\mathit{KA}(x)$ is defined as the minus logarithm of continuous a priori\nprobability on the binary tree, and $\\mathit{KP}(x)$ denotes prefix complexity\nof a binary string $x$. In this paper we answer a question posed by Joseph\nMiller and prove that there exists an infinite binary sequence $\\omega$ such\nthat the sum of $2^{\\mathit{KA}(x)-\\mathit{KP}(x)}$ over all prefixes $x$ of\n$\\omega$ is infinite. Such a sequence can be chosen among characteristic\nsequences of computably enumerable sets. \n\n"}
{"id": "1401.1671", "contents": "Title: Distributed Energy Efficient Channel Allocation Abstract: Design of energy efficient protocols for modern wireless systems has become\nan important area of research. In this paper, we propose a distributed\noptimization algorithm for the channel assignment problem for multiple\ninterfering transceiver pairs that cannot communicate with each other. We first\nmodify the auction algorithm for maximal energy efficiency and show that the\nproblem can be solved without explicit message passing using the carrier sense\nmultiple access (CSMA) protocols. We then develop a novel scheme by converting\nthe channel assignment problem into perfect matchings on bipartite graphs. The\nproposed scheme improves the energy efficiency and does not require any\nexplicit message passing or a shared memory between the users. We derive bounds\non the convergence rate and show that the proposed algorithm converges faster\nthan the distributed auction algorithm and achieves near-optimal performance\nunder Rayleigh fading channels. We also present an asymptotic performance\nanalysis of the fast matching algorithm for energy efficient resource\nallocation and prove the optimality for large enough number of users and number\nof channels. Finally, we provide numerical assessments that confirm the energy\nefficiency gains compared to the state of the art. \n\n"}
{"id": "1401.2507", "contents": "Title: Characteristic-Dependent Linear Rank Inequalities with Applications to\n  Network Coding Abstract: Two characteristic-dependent linear rank inequalities are given for eight\nvariables. Specifically, the first inequality holds for all finite fields whose\ncharacteristic is not three and does not in general hold over characteristic\nthree. The second inequality holds for all finite fields whose characteristic\nis three and does not in general hold over characteristics other than three.\nApplications of these inequalities to the computation of capacity upper bounds\nin network coding are demonstrated. \n\n"}
{"id": "1401.2548", "contents": "Title: Mutual Information Rate-Based Networks in Financial Markets Abstract: In the last years efforts in econophysics have been shifted to study how\nnetwork theory can facilitate understanding of complex financial markets. Main\npart of these efforts is the study of correlation-based hierarchical networks.\nThis is somewhat surprising as the underlying assumptions of research looking\nat financial markets is that they behave chaotically. In fact it's common for\neconophysicists to estimate maximal Lyapunov exponent for log returns of a\ngiven financial asset to confirm that prices behave chaotically. Chaotic\nbehaviour is only displayed by dynamical systems which are either non-linear or\ninfinite-dimensional. Therefore it seems that non-linearity is an important\npart of financial markets, which is proved by numerous studies confirming\nfinancial markets display significant non-linear behaviour, yet network theory\nis used to study them using almost exclusively correlations and partial\ncorrelations, which are inherently dealing with linear dependencies only. In\nthis paper we introduce a way to incorporate non-linear dynamics and\ndependencies into hierarchical networks to study financial markets using mutual\ninformation and its dynamical extension: the mutual information rate. We\nestimate it using multidimensional Lempel-Ziv complexity and then convert it\ninto an Euclidean metric in order to find appropriate topological structure of\nnetworks modelling financial markets. We show that this approach leads to\ndifferent results than correlation-based approach used in most studies, on the\nbasis of 15 biggest companies listed on Warsaw Stock Exchange in the period of\n2009-2012 and 91 companies listed on NYSE100 between 2003 and 2013, using\nminimal spanning trees and planar maximally filtered graphs. \n\n"}
{"id": "1401.3250", "contents": "Title: Half-Duplex Relaying for the Multiuser Channel Abstract: This work focuses on studying the half-duplex (HD) relaying in the Multiple\nAccess Relay Channel (MARC) and the Compound Multiple Access Channel with a\nRelay (cMACr). A generalized Quantize-and-Forward (GQF) has been proposed to\nestablish the achievable rate regions. Such scheme is developed based on the\nvariation of the Quantize-and-Forward (QF) scheme and single block with two\nslots coding structure. The results in this paper can also be considered as a\nsignificant extension of the achievable rate region of Half-Duplex Relay\nChannel (HDRC). Furthermore, the rate regions based on GQF scheme is extended\nto the Gaussian channel case. The scheme performance is shown through some\nnumerical examples. \n\n"}
{"id": "1401.3781", "contents": "Title: Random Number Conversion and LOCC Conversion via Restricted Storage Abstract: We consider random number conversion (RNC) through random number storage with\nrestricted size. We clarify the relation between the performance of RNC and the\nsize of storage in the framework of first- and second- order asymptotics, and\nderive their rate regions. Then, we show that the results for RNC with\nrestricted storage recover those for conventional RNC without storage in the\nlimit of storage size. To treat RNC via restricted storage, we introduce a new\nkind of probability distributions named generalized Rayleigh-normal\ndistributions. Using the generalized Rayleigh-normal distributions, we can\ndescribe the second-order asymptotic behaviour of RNC via restricted storage in\na unified manner. As an application to quantum information theory, we analyze\nLOCC conversion via entanglement storage with restricted size. Moreover, we\nderive the optimal LOCC compression rate under a constraint of conversion\naccuracy. \n\n"}
{"id": "1401.3814", "contents": "Title: Information Geometry Approach to Parameter Estimation in Markov Chains Abstract: We consider the parameter estimation of Markov chain when the unknown\ntransition matrix belongs to an exponential family of transition matrices.\nThen, we show that the sample mean of the generator of the exponential family\nis an asymptotically efficient estimator. Further, we also define a curved\nexponential family of transition matrices. Using a transition matrix version of\nthe Pythagorean theorem, we give an asymptotically efficient estimator for a\ncurved exponential family. \n\n"}
{"id": "1401.4161", "contents": "Title: Strong converse for the classical capacity of optical quantum\n  communication channels Abstract: We establish the classical capacity of optical quantum channels as a sharp\ntransition between two regimes---one which is an error-free regime for\ncommunication rates below the capacity, and the other in which the probability\nof correctly decoding a classical message converges exponentially fast to zero\nif the communication rate exceeds the classical capacity. This result is\nobtained by proving a strong converse theorem for the classical capacity of all\nphase-insensitive bosonic Gaussian channels, a well-established model of\noptical quantum communication channels, such as lossy optical fibers, amplifier\nand free-space communication. The theorem holds under a particular\nphoton-number occupation constraint, which we describe in detail in the paper.\nOur result bolsters the understanding of the classical capacity of these\nchannels and opens the path to applications, such as proving the security of\nnoisy quantum storage models of cryptography with optical links. \n\n"}
{"id": "1401.4532", "contents": "Title: Polar Lattices for Strong Secrecy Over the Mod-$\\Lambda$ Gaussian\n  Wiretap Channel Abstract: Polar lattices, which are constructed from polar codes, are provably good for\nthe additive white Gaussian noise (AWGN) channel. In this work, we propose a\nnew polar lattice construction that achieves the secrecy capacity under the\nstrong secrecy criterion over the mod-$\\Lambda$ Gaussian wiretap channel. This\nconstruction leads to an AWGN-good lattice and a secrecy-good lattice\nsimultaneously. The design methodology is mainly based on the equivalence in\nterms of polarization between the $\\Lambda/\\Lambda'$ channel in lattice coding\nand the equivalent channel derived from the chain rule of mutual information in\nmultilevel coding. \n\n"}
{"id": "1401.4642", "contents": "Title: On the Capacity of Memoryless Adversary Abstract: In this paper, we study a model of communication under adversarial noise. In\nthis model, the adversary makes online decisions on whether to corrupt a\ntransmitted bit based on only the value of that bit. Like the usual binary\nsymmetric channel of information theory or the fully adversarial channel of\ncombinatorial coding theory, the adversary can, with high probability,\nintroduce at most a given fraction of error.\n  It is shown that, the capacity (maximum rate of reliable information\ntransfer) of such memoryless adversary is strictly below that of the binary\nsymmetric channel. We give new upper bound on the capacity of such channel --\nthe tightness of this upper bound remains an open question. The main component\nof our proof is the careful examination of error-correcting properties of a\ncode with skewed distance distribution. \n\n"}
{"id": "1401.5037", "contents": "Title: Achieving SK Capacity in the Source Model: When Must All Terminals Talk? Abstract: In this paper, we address the problem of characterizing the instances of the\nmultiterminal source model of Csisz\\'ar and Narayan in which communication from\nall terminals is needed for establishing a secret key of maximum rate. We give\nan information-theoretic sufficient condition for identifying such instances.\nWe believe that our sufficient condition is in fact an exact characterization,\nbut we are only able to prove this in the case of the three-terminal source\nmodel. We also give a relatively simple criterion for determining whether or\nnot our condition holds for a given multiterminal source model. \n\n"}
{"id": "1401.5582", "contents": "Title: Beyond One-Way Communication: Degrees of Freedom of Multi-Way Relay MIMO\n  Interference Networks Abstract: We characterize the degrees of freedom (DoF) of multi-way relay MIMO\ninterference networks. In particular, we consider a wireless network consisting\nof 4 user nodes, each with M antennas, and one N-antenna relay node. In this\nnetwork, each user node sends one independent message to each of the other user\nnodes, and there are no direct links between any two user nodes, i.e., all\ncommunication must pass through the relay node. For this network, we show that\nthe symmetric DoF value per message is given by max(min(M/3,N/7),min(2M/7,N/6))\nnormalized by space dimensions, i.e., piecewise linear depending on M and N\nalternatively. While the information theoretic DoF upper bound is established\nfor every M and N, the achievability relying on linear signal subspace\nalignment is established in the spatially-normalized sense in general. In\naddition, by deactivating 4 messages to form a two-way relay MIMO X channel, we\nalso present the DoF result in the similar piecewise linear type. The central\nnew insight to emerge from this work is the notion of inter-user signal\nsubspace alignment incorporating the idea of network coding, which is the key\nto achieve the optimal DoF for multi-way relay interference networks. Moreover,\nthis work also settles the feasibility of linear interference alignment that\nextends the feasibility framework from one-way to multi-way relay interference\nnetworks. \n\n"}
{"id": "1401.6039", "contents": "Title: Constant Compositions in the Sphere Packing Bound for Classical-Quantum\n  Channels Abstract: The sphere packing bound, in the form given by Shannon, Gallager and\nBerlekamp, was recently extended to classical-quantum channels, and it was\nshown that this creates a natural setting for combining probabilistic\napproaches with some combinatorial ones such as the Lov\\'asz theta function. In\nthis paper, we extend the study to the case of constant composition codes. We\nfirst extend the sphere packing bound for classical-quantum channels to this\ncase, and we then show that the obtained result is related to a variation of\nthe Lov\\'asz theta function studied by Marton. We then propose a further\nextension to the case of varying channels and codewords with a constant\nconditional composition given a particular sequence. This extension is then\napplied to auxiliary channels to deduce a bound which can be interpreted as an\nextension of the Elias bound. \n\n"}
{"id": "1401.6258", "contents": "Title: Rate Region of the Vector Gaussian CEO Problem with the Trace Distortion\n  Constraint Abstract: We establish a new extremal inequality, which is further leveraged to give a\ncomplete characterization of the rate region of the vector Gaussian CEO problem\nwith the trace distortion constraint. The proof of this extremal inequality\nhinges on a careful analysis of the Karush-Kuhn-Tucker necessary conditions for\nthe non-convex optimization problem associated with the Berger-Tung scheme,\nwhich enables us to integrate the perturbation argument by Wang and Chen with\nthe distortion projection method by Rahman and Wagner. \n\n"}
{"id": "1401.6354", "contents": "Title: Local Identification of Overcomplete Dictionaries Abstract: This paper presents the first theoretical results showing that stable\nidentification of overcomplete $\\mu$-coherent dictionaries $\\Phi \\in\n\\mathbb{R}^{d\\times K}$ is locally possible from training signals with sparsity\nlevels $S$ up to the order $O(\\mu^{-2})$ and signal to noise ratios up to\n$O(\\sqrt{d})$. In particular the dictionary is recoverable as the local maximum\nof a new maximisation criterion that generalises the K-means criterion. For\nthis maximisation criterion results for asymptotic exact recovery for sparsity\nlevels up to $O(\\mu^{-1})$ and stable recovery for sparsity levels up to\n$O(\\mu^{-2})$ as well as signal to noise ratios up to $O(\\sqrt{d})$ are\nprovided. These asymptotic results translate to finite sample size recovery\nresults with high probability as long as the sample size $N$ scales as $O(K^3dS\n\\tilde \\varepsilon^{-2})$, where the recovery precision $\\tilde \\varepsilon$\ncan go down to the asymptotically achievable precision. Further, to actually\nfind the local maxima of the new criterion, a very simple Iterative\nThresholding and K (signed) Means algorithm (ITKM), which has complexity\n$O(dKN)$ in each iteration, is presented and its local efficiency is\ndemonstrated in several experiments. \n\n"}
{"id": "1401.6380", "contents": "Title: Properties of spatial coupling in compressed sensing Abstract: In this paper we address a series of open questions about the construction of\nspatially coupled measurement matrices in compressed sensing. For hardware\nimplementations one is forced to depart from the limiting regime of parameters\nin which the proofs of the so-called threshold saturation work. We investigate\nquantitatively the behavior under finite coupling range, the dependence on the\nshape of the coupling interaction, and optimization of the so-called seed to\nminimize distance from optimality. Our analysis explains some of the properties\nobserved empirically in previous works and provides new insight on spatially\ncoupled compressed sensing. \n\n"}
{"id": "1401.6384", "contents": "Title: On Convergence of Approximate Message Passing Abstract: Approximate message passing is an iterative algorithm for compressed sensing\nand related applications. A solid theory about the performance and convergence\nof the algorithm exists for measurement matrices having iid entries of zero\nmean. However, it was observed by several authors that for more general\nmatrices the algorithm often encounters convergence problems. In this paper we\nidentify the reason of the non-convergence for measurement matrices with iid\nentries and non-zero mean in the context of Bayes optimal inference. Finally we\ndemonstrate numerically that when the iterative update is changed from parallel\nto sequential the convergence is restored. \n\n"}
{"id": "1401.6437", "contents": "Title: On Phase Noise Suppression in Full-Duplex Systems Abstract: Oscillator phase noise has been shown to be one of the main performance\nlimiting factors in full-duplex systems. In this paper, we consider the problem\nof self-interference cancellation with phase noise suppression in full-duplex\nsystems. The feasibility of performing phase noise suppression in full-duplex\nsystems in terms of both complexity and achieved gain is analytically and\nexperimentally investigated. First, the effect of phase noise on full-duplex\nsystems and the possibility of performing phase noise suppression are studied.\nTwo different phase noise suppression techniques with a detailed complexity\nanalysis are then proposed. For each suppression technique, both free-running\nand phase locked loop based oscillators are considered. Due to the fact that\nfull-duplex system performance highly depends on hardware impairments,\nexperimental analysis is essential for reliable results. In this paper, the\nperformance of the proposed techniques is experimentally investigated in a\ntypical indoor environment. The experimental results are shown to confirm the\nresults obtained from numerical simulations on two different experimental\nresearch platforms. At the end, the tradeoff between the required complexity\nand the gain achieved using phase noise suppression is discussed. \n\n"}
{"id": "1401.6500", "contents": "Title: Holographic Transformation for Quantum Factor Graphs Abstract: Recently, a general tool called a holographic transformation, which\ntransforms an expression of the partition function to another form, has been\nused for polynomial-time algorithms and for improvement and understanding of\nthe belief propagation. In this work, the holographic transformation is\ngeneralized to quantum factor graphs. \n\n"}
{"id": "1401.7485", "contents": "Title: Superimposed Codes and Threshold Group Testing Abstract: We will discuss superimposed codes and non-adaptive group testing designs\narising from the potentialities of compressed genotyping models in molecular\nbiology. The given paper was motivated by the 30th anniversary of\nD'yachkov-Rykov recurrent upper bound on the rate of superimposed codes\npublished in 1982. We were also inspired by recent results obtained for\nnon-adaptive threshold group testing which develop the theory of superimposed\ncodes \n\n"}
{"id": "1402.0017", "contents": "Title: Capacity of Binary State Symmetric Channel with and without Feedback and\n  Transmission Cost Abstract: We consider a unit memory channel, called Binary State Symmetric Channel\n(BSSC), in which the channel state is the modulo2 addition of the current\nchannel input and the previous channel output. We derive closed form\nexpressions for the capacity and corresponding channel input distribution, of\nthis BSSC with and without feedback and transmission cost. We also show that\nthe capacity of the BSSC is not increased by feedback, and it is achieved by a\nfirst order symmetric Markov process. \n\n"}
{"id": "1402.0648", "contents": "Title: Linear Network Coding for Multiple Groupcast Sessions: An Interference\n  Alignment Approach Abstract: We consider the problem of linear network coding over communication networks,\nrepresentable by directed acyclic graphs, with multiple groupcast sessions: the\nnetwork comprises of multiple destination nodes, each desiring messages from\nmultiple sources. We adopt an interference alignment perspective, providing new\ninsights into designing practical network coding schemes as well as the impact\nof network topology on the complexity of the alignment scheme. In particular,\nwe show that under certain (polynomial-time checkable) constraints on networks\nwith $K$ sources, it is possible to achieve a rate of $1/(L+d+1)$ per source\nusing linear network coding coupled with interference alignment, where each\ndestination receives messages from $L$ sources ($L < K$), and $d$ is a\nparameter, solely dependent on the network topology, that satisfies $0 \\leq d <\nK-L$. \n\n"}
{"id": "1402.1384", "contents": "Title: Variational Free Energies for Compressed Sensing Abstract: We consider the variational free energy approach for compressed sensing. We\nfirst show that the na\\\"ive mean field approach performs remarkably well when\ncoupled with a noise learning procedure. We also notice that it leads to the\nsame equations as those used for iterative thresholding. We then discuss the\nBethe free energy and how it corresponds to the fixed points of the approximate\nmessage passing algorithm. In both cases, we test numerically the direct\noptimization of the free energies as a converging sparse-estimationalgorithm. \n\n"}
{"id": "1402.1572", "contents": "Title: New Outer Bounds for the Interference Channel with Unilateral Source\n  Cooperation Abstract: This paper studies the two-user interference channel with unilateral source\ncooperation, which consists of two source-destination pairs that share the same\nchannel and where one full-duplex source can overhear the other source through\na noisy in-band link. Novel outer bounds of the type 2Rp+Rc/Rp+2Rc are\ndeveloped for the class of injective semi-deterministic channels with\nindependent noises at the different source-destination pairs. The bounds are\nthen specialized to the Gaussian noise case. Interesting insights are provided\nabout when these types of bounds are active, or in other words, when unilateral\ncooperation is too weak and leaves \"holes\" in the system resources. \n\n"}
{"id": "1402.2461", "contents": "Title: Distributions of Upper PAPR and Lower PAPR of OFDM Signals in Visible\n  Light Communications Abstract: Orthogonal frequency-division multiplexing (OFDM) in visible light\ncommunications (VLC) inherits the disadvantage of high peak-to-average power\nratio (PAPR) from OFDM in radio frequency (RF) communications. The upper peak\npower and lower peak power of real-valued VLC-OFDM signals are both limited by\nthe dynamic constraints of light emitting diodes (LEDs). The efficiency and\ntransmitted electrical power are directly related with the upper PAPR (UPAPR)\nand lower PAPR (LPAPR) of VLC-OFDM. In this paper, we will derive the\ncomplementary cumulative distribution function (CCDF) of UPAPR and LPAPR, and\ninvestigate the joint distribution of UPAPR and LPAPR. \n\n"}
{"id": "1402.3392", "contents": "Title: Interleaved entropy coders Abstract: The ANS family of arithmetic coders developed by Jarek Duda has the unique\nproperty that encoder and decoder are completely symmetric in the sense that a\ndecoder reading bits will be in the exact same state that the encoder was in\nwhen writing those bits---all \"buffering\" of information is explicitly part of\nthe coder state and identical between encoder and decoder. As a consequence,\nthe output from multiple ABS/ANS coders can be interleaved into the same\nbitstream without any additional metadata. This allows for very efficient\nencoding and decoding on CPUs supporting superscalar execution or SIMD\ninstructions, as well as GPU implementations. We also show how interleaving\nwithout additional metadata can be implemented for any entropy coder, at some\nincrease in encoder complexity. \n\n"}
{"id": "1402.3801", "contents": "Title: On Heterogeneous Regenerating Codes and Capacity of Distributed Storage\n  Systems Abstract: Heterogeneous Distributed Storage Systems (DSS) are close to real world\napplications for data storage. Internet caching system and peer-to-peer storage\nclouds are the examples of such DSS. In this work, we calculate the capacity\nformula for such systems where each node store different number of packets and\neach having a different repair bandwidth (node can be repaired by contacting a\nspecific set of nodes). The tradeoff curve between storage and repair bandwidth\nis studied for such heterogeneous DSS. By analyzing the capacity formula new\nminimum bandwidth regenerating (MBR) and minimum storage regenerating (MBR)\npoints are obtained on the curve. It is shown that in some cases these are\nbetter than the homogeneous DSS. \n\n"}
{"id": "1402.4225", "contents": "Title: Information Theory of Matrix Completion Abstract: Matrix completion is a fundamental problem that comes up in a variety of\napplications like the Netflix problem, collaborative filtering, computer\nvision, and crowdsourcing. The goal of the problem is to recover a k-by-n\nunknown matrix from a subset of its noiseless (or noisy) entries. We define an\ninformation-theoretic notion of completion capacity C that quantifies the\nmaximum number of entries that one observation of an entry can resolve. This\nnumber provides the minimum number m of entries required for reliable\nreconstruction: m=kn/C. Translating the problem into a distributed joint\nsource-channel coding problem with encoder restriction, we characterize the\ncompletion capacity for a wide class of stochastic models of the unknown matrix\nand the observation process. Our achievability proof is inspired by that of the\nSlepian-Wolf theorem. For an arbitrary stochastic matrix, we derive an upper\nbound on the completion capacity. \n\n"}
{"id": "1402.5076", "contents": "Title: Robust Binary Fused Compressive Sensing using Adaptive Outlier Pursuit Abstract: We propose a new method, {\\it robust binary fused compressive sensing}\n(RoBFCS), to recover sparse piece-wise smooth signals from 1-bit compressive\nmeasurements. The proposed method is a modification of our previous {\\it binary\nfused compressive sensing} (BFCS) algorithm, which is based on the {\\it binary\niterative hard thresholding} (BIHT) algorithm. As in BIHT, the data term of the\nobjective function is a one-sided $\\ell_1$ (or $\\ell_2$) norm. Experiments show\nthat the proposed algorithm is able to take advantage of the piece-wise\nsmoothness of the original signal and detect sign flips and correct them,\nachieving more accurate recovery than BFCS and BIHT. \n\n"}
{"id": "1402.5730", "contents": "Title: Power Efficient and Secure Multiuser Communication Systems with Wireless\n  Information and Power Transfer Abstract: In this paper, we study resource allocation algorithm design for power\nefficient secure communication with simultaneous wireless information and power\ntransfer (WIPT) in multiuser communication systems. In particular, we focus on\npower splitting receivers which are able to harvest energy and decode\ninformation from the received signals. The considered problem is modeled as an\noptimization problem which takes into account a minimum required\nsignal-to-interference-plus-noise ratio (SINR) at multiple desired receivers, a\nmaximum tolerable data rate at multiple multi-antenna potential eavesdroppers,\nand a minimum required power delivered to the receivers. The proposed problem\nformulation facilitates the dual use of artificial noise in providing efficient\nenergy transfer and guaranteeing secure communication. We aim at minimizing the\ntotal transmit power by jointly optimizing transmit beamforming vectors, power\nsplitting ratios at the desired receivers, and the covariance of the artificial\nnoise. The resulting non-convex optimization problem is transformed into a\nsemidefinite programming (SDP) and solved by SDP relaxation. We show that the\nadopted SDP relaxation is tight and achieves the global optimum of the original\nproblem. Simulation results illustrate the significant power saving obtained by\nthe proposed optimal algorithm compared to suboptimal baseline schemes. \n\n"}
{"id": "1402.6294", "contents": "Title: Frankl-R\\\"odl type theorems for codes and permutations Abstract: We give a new proof of the Frankl-R\\\"odl theorem on forbidden intersections,\nvia the probabilistic method of dependent random choice. Our method extends to\ncodes with forbidden distances, where over large alphabets our bound is\nsignificantly better than that obtained by Frankl and R\\\"odl. We also apply our\nbound to a question of Ellis on sets of permutations with forbidden distances,\nand to establish a weak form of a conjecture of Alon, Shpilka and Umans on\nsunflowers. \n\n"}
{"id": "1402.6771", "contents": "Title: On Linear Codes over $\\mathbb{Z}_4+v\\mathbb{Z}_4$ Abstract: Linear codes are considered over the ring $\\mathbb{Z}_4+v\\mathbb{Z}_4$, where\n$v^2=v$. Gray weight, Gray maps for linear codes are defined and MacWilliams\nidentity for the Gray weight enumerator is given. Self-dual codes, construction\nof Euclidean isodual codes, unimodular complex lattices, MDS codes and MGDS\ncodes over $\\mathbb{Z}_4+v\\mathbb{Z}_4$ are studied. Cyclic codes and quadratic\nresidue codes are also considered. Finally, some examples for illustrating the\nmain work are given. \n\n"}
{"id": "1402.7350", "contents": "Title: Phase Retrieval with Application to Optical Imaging Abstract: This review article provides a contemporary overview of phase retrieval in\noptical imaging, linking the relevant optical physics to the information\nprocessing methods and algorithms. Its purpose is to describe the current state\nof the art in this area, identify challenges, and suggest vision and areas\nwhere signal processing methods can have a large impact on optical imaging and\non the world of imaging at large, with applications in a variety of fields\nranging from biology and chemistry to physics and engineering. \n\n"}
{"id": "1403.0957", "contents": "Title: On the Symmetric $K$-user Interference Channels with Limited Feedback Abstract: In this paper, we develop achievability schemes for symmetric $K$-user\ninterference channels with a rate-limited feedback from each receiver to the\ncorresponding transmitter. We study this problem under two different channel\nmodels: the linear deterministic model, and the Gaussian model. For the\ndeterministic model, the proposed scheme achieves a symmetric rate that is the\nminimum of the symmetric capacity with infinite feedback, and the sum of the\nsymmetric capacity without feedback and the symmetric amount of feedback. For\nthe Gaussian interference channel, we use lattice codes to propose a\ntransmission strategy that incorporates the techniques of Han-Kobayashi message\nsplitting, interference decoding, and decode and forward. This strategy\nachieves a symmetric rate which is within a constant number of bits to the\nminimum of the symmetric capacity with infinite feedback, and the sum of the\nsymmetric capacity without feedback and the amount of symmetric feedback. This\nconstant is obtained as a function of the number of users, $K$. The symmetric\nachievable rate is used to characterize the achievable generalized degrees of\nfreedom which exhibits a gradual increase from no feedback to perfect feedback\nin the presence of feedback links with limited capacity. \n\n"}
{"id": "1403.2779", "contents": "Title: Erasure codes with simplex locality Abstract: We focus on erasure codes for distributed storage. The distributed storage\nsetting imposes locality requirements because of easy repair demands on the\ndecoder. We first establish the characterization of various locality properties\nin terms of the generator matrix of the code. These lead to bounds on locality\nand notions of optimality. We then examine the locality properties of a family\nof non-binary codes with simplex structure. We investigate their optimality and\ndesign several easy repair decoding methods. In particular, we show that any\ncorrectable erasure pattern can be solved by easy repair. \n\n"}
{"id": "1403.3786", "contents": "Title: Universal Decoding for Gaussian Intersymbol Interference Channels Abstract: A universal decoding procedure is proposed for the intersymbol interference\n(ISI) Gaussian channels. The universality of the proposed decoder is in the\nsense of being independent of the various channel parameters, and at the same\ntime, attaining the same random coding error exponent as the optimal\nmaximum-likelihood (ML) decoder, which utilizes full knowledge of these unknown\nparameters. The proposed decoding rule can be regarded as a frequency domain\nversion of the universal maximum mutual information (MMI) decoder. Contrary to\npreviously suggested universal decoders for ISI channels, our proposed decoding\nmetric can easily be evaluated. \n\n"}
{"id": "1403.5315", "contents": "Title: A Deterministic Annealing Optimization Approach for Witsenhausen's and\n  Related Decentralized Control Settings Abstract: This paper studies the problem of mapping optimization in decentralized\ncontrol problems. A global optimization algorithm is proposed based on the\nideas of ``deterministic annealing\" - a powerful non-convex optimization\nframework derived from information theoretic principles with analogies to\nstatistical physics. The key idea is to randomize the mappings and control the\nShannon entropy of the system during optimization. The entropy constraint is\ngradually relaxed in a deterministic annealing process while tracking the\nminimum, to obtain the ultimate deterministic mappings. Deterministic annealing\nhas been successfully employed in several problems including clustering, vector\nquantization, regression, as well as the Witsenhausen's counterexample in our\nrecent work[1]. We extend our method to a more involved setting, a variation of\nWitsenhausen's counterexample, where there is a side channel between the two\ncontrollers. The problem can be viewed as a two stage cancellation problem. We\ndemonstrate that there exist complex strategies that can exploit the side\nchannel efficiently, obtaining significant gains over the best affine and known\nnon-linear strategies. \n\n"}
{"id": "1403.5711", "contents": "Title: Large-Scale MIMO Detection for 3GPP LTE: Algorithms and FPGA\n  Implementations Abstract: Large-scale (or massive) multiple-input multiple-output (MIMO) is expected to\nbe one of the key technologies in next-generation multi-user cellular systems,\nbased on the upcoming 3GPP LTE Release 12 standard, for example. In this work,\nwe propose - to the best of our knowledge - the first VLSI design enabling\nhigh-throughput data detection in single-carrier frequency-division multiple\naccess (SC-FDMA)-based large-scale MIMO systems. We propose a new approximate\nmatrix inversion algorithm relying on a Neumann series expansion, which\nsubstantially reduces the complexity of linear data detection. We analyze the\nassociated error, and we compare its performance and complexity to those of an\nexact linear detector. We present corresponding VLSI architectures, which\nperform exact and approximate soft-output detection for large-scale MIMO\nsystems with various antenna/user configurations. Reference implementation\nresults for a Xilinx Virtex-7 XC7VX980T FPGA show that our designs are able to\nachieve more than 600 Mb/s for a 128 antenna, 8 user 3GPP LTE-based large-scale\nMIMO system. We finally provide a performance/complexity trade-off comparison\nusing the presented FPGA designs, which reveals that the detector circuit of\nchoice is determined by the ratio between BS antennas and users, as well as the\ndesired error-rate performance. \n\n"}
{"id": "1403.5735", "contents": "Title: Cooperative Energy Trading in CoMP Systems Powered by Smart Grids Abstract: This paper studies the energy management in the coordinated multi-point\n(CoMP) systems powered by smart grids, where each base station (BS) with local\nrenewable energy generation is allowed to implement the two-way energy trading\nwith the grid. Due to the uneven renewable energy supply and communication\nenergy demand over distributed BSs as well as the difference in the prices for\ntheir buying/selling energy from/to the gird, it is beneficial for the\ncooperative BSs to jointly manage their energy trading with the grid and energy\nconsumption in CoMP based communication for reducing the total energy cost.\nSpecifically, we consider the downlink transmission in one CoMP cluster by\njointly optimizing the BSs' purchased/sold energy units from/to the grid and\ntheir cooperative transmit precoding, so as to minimize the total energy cost\nsubject to the given quality of service (QoS) constraints for the users. First,\nwe obtain the optimal solution to this problem by developing an algorithm based\non techniques from convex optimization and the uplink-downlink duality. Next,\nwe propose a sub-optimal solution of lower complexity than the optimal\nsolution, where zero-forcing (ZF) based precoding is implemented at the BSs.\nFinally, through extensive simulations, we show the performance gain achieved\nby our proposed joint energy trading and communication cooperation schemes in\nterms of energy cost reduction, as compared to conventional schemes that\nseparately design communication cooperation and energy trading. \n\n"}
{"id": "1403.6192", "contents": "Title: Quantum Synchronizable Codes From Quadratic Residue Codes and Their\n  Supercodes Abstract: Quantum synchronizable codes are quantum error-correcting codes designed to\ncorrect the effects of both quantum noise and block synchronization errors.\nWhile it is known that quantum synchronizable codes can be constructed from\ncyclic codes that satisfy special properties, only a few classes of cyclic\ncodes have been proved to give promising quantum synchronizable codes. In this\npaper, using quadratic residue codes and their supercodes, we give a simple\nconstruction for quantum synchronizable codes whose synchronization\ncapabilities attain the upper bound. The method is applicable to cyclic codes\nof prime length. \n\n"}
{"id": "1404.0660", "contents": "Title: Waterfilling Theorems in the Time-Frequency Plane for the Heat Channel\n  and a Related Source Abstract: The capacity of the heat channel, a linear time-varying (LTV) filter with\nadditive white Gaussian noise (AWGN), is characterized by waterfilling in the\ntime-frequency plane. Similarly, the rate distortion function for a related\nnonstationary source is characterized by reverse waterfilling in the\ntime-frequency plane. The source is formed by the white Gaussian noise response\nof the same LTV filter as before. The proofs of both waterfilling theorems rely\non a specific Szego theorem for a positive definite operator associated with\nthe filter. An essentially self-contained proof of the Szego theorem is given.\nThe waterfilling theorems compare well with classical results of Gallager and\nBerger. In case of the nonstationary source it is observed that the part of the\nclassical power spectral density (PSD) is taken by the Wigner-Ville spectrum\n(WVS). \n\n"}
{"id": "1404.0864", "contents": "Title: Generalized Signal Alignment For Arbitrary MIMO Two-Way Relay Channels Abstract: In this paper, we consider the arbitrary MIMO two-way relay channels, where\nthere are $K$ source nodes, each equipped with $M_i$ antennas, for\n$i=1,2,\\cdots,K$, and one relay node, equipped with $N$ antennas. Each source\nnode can exchange independent messages with arbitrary other source nodes\nassisted by the relay. We extend our newly-proposed transmission scheme,\ngeneralized signal alignment (GSA) in [1], to arbitrary MIMO two-way relay\nchannels when $N>M_i+M_j$, $\\forall i \\neq j$. The key idea of GSA is to cancel\nthe interference for each data pair in its specific subspace by two steps. This\nis realized by jointly designing the precoding matrices at all source nodes and\nthe processing matrix at the relay node. Moreover, the aligned subspaces are\northogonal to each other. By applying the GSA, we show that a necessary\ncondition on the antenna configuration to achieve the DoF upper bound $\\min\n\\{\\sum_{i=1}^K M_i, 2\\sum_{i=2}^K M_i,2N\\}$ is $N \\geq \\max\\{\\sum_{i=1}^K\nM_i-M_s-M_t+d_{s,t}\\mid \\forall s,t\\}$. Here, $d_{s,t}$ denotes the DoF of the\nmessage exchanged between source node $s$ and $t$. In the special case when the\narbitrary MIMO two-way relay channel reduces to the $K$-user MIMO Y channel, we\nshow that our achievable region of DoF upper bound is larger than the previous\nwork. \n\n"}
{"id": "1404.2819", "contents": "Title: Decoding of Quasi-Cyclic Codes up to A New Lower Bound on the Minimum\n  Distance Abstract: A new lower bound on the minimum Hamming distance of linear quasi-cyclic\ncodes over finite fields is proposed. It is based on spectral analysis and\ngeneralizes the Semenov- Trifonov bound in a similar way as the Hartmann-Tzeng\nbound extends the BCH approach for cyclic codes. Furthermore, a syndrome-based\nalgebraic decoding algorithm is given. \n\n"}
{"id": "1404.3378", "contents": "Title: Complexity theoretic limitations on learning DNF's Abstract: Using the recently developed framework of [Daniely et al, 2014], we show that\nunder a natural assumption on the complexity of refuting random K-SAT formulas,\nlearning DNF formulas is hard. Furthermore, the same assumption implies the\nhardness of learning intersections of $\\omega(\\log(n))$ halfspaces,\nagnostically learning conjunctions, as well as virtually all (distribution\nfree) learning problems that were previously shown hard (under complexity\nassumptions). \n\n"}
{"id": "1404.3411", "contents": "Title: Achievable Secrecy Rates over MIMOME Gaussian Channels with GMM Signals\n  in Low-Noise Regime Abstract: We consider a wiretap multiple-input multiple-output multiple-eavesdropper\n(MIMOME) channel, where agent Alice aims at transmitting a secret message to\nagent Bob, while leaking no information on it to an eavesdropper agent Eve. We\nassume that Alice has more antennas than both Bob and Eve, and that she has\nonly statistical knowledge of the channel towards Eve. We focus on the\nlow-noise regime, and assess the secrecy rates that are achievable when the\nsecret message determines the distribution of a multivariate Gaussian mixture\nmodel (GMM) from which a realization is generated and transmitted over the\nchannel. In particular, we show that if Eve has fewer antennas than Bob, secret\ntransmission is always possible at low-noise. Moreover, we show that in the\nlow-noise limit the secrecy capacity of our scheme coincides with its\nunconstrained capacity, by providing a class of covariance matrices that allow\nto attain such limit without the need of wiretap coding. \n\n"}
{"id": "1404.5236", "contents": "Title: Sum-of-squares proofs and the quest toward optimal algorithms Abstract: In order to obtain the best-known guarantees, algorithms are traditionally\ntailored to the particular problem we want to solve. Two recent developments,\nthe Unique Games Conjecture (UGC) and the Sum-of-Squares (SOS) method,\nsurprisingly suggest that this tailoring is not necessary and that a single\nefficient algorithm could achieve best possible guarantees for a wide range of\ndifferent problems.\n  The Unique Games Conjecture (UGC) is a tantalizing conjecture in\ncomputational complexity, which, if true, will shed light on the complexity of\na great many problems. In particular this conjecture predicts that a single\nconcrete algorithm provides optimal guarantees among all efficient algorithms\nfor a large class of computational problems.\n  The Sum-of-Squares (SOS) method is a general approach for solving systems of\npolynomial constraints. This approach is studied in several scientific\ndisciplines, including real algebraic geometry, proof complexity, control\ntheory, and mathematical programming, and has found applications in fields as\ndiverse as quantum information theory, formal verification, game theory and\nmany others.\n  We survey some connections that were recently uncovered between the Unique\nGames Conjecture and the Sum-of-Squares method. In particular, we discuss new\ntools to rigorously bound the running time of the SOS method for obtaining\napproximate solutions to hard optimization problems, and how these tools give\nthe potential for the sum-of-squares method to provide new guarantees for many\nproblems of interest, and possibly to even refute the UGC. \n\n"}
{"id": "1404.6472", "contents": "Title: Parallel Gaussian Networks with a Common State-Cognitive Helper Abstract: A class of state-dependent parallel networks with a common state-cognitive\nhelper, in which $K$ transmitters wish to send $K$ messages to their\ncorresponding receivers over $K$ state-corrupted parallel channels, and a\nhelper who knows the state information noncausally wishes to assist these\nreceivers to cancel state interference. Furthermore, the helper also has its\nown message to be sent simultaneously to its corresponding receiver. Since the\nstate information is known only to the helper, but not to the corresponding\ntransmitters $1,\\dots,K$, transmitter-side state cognition and receiver-side\nstate interference are mismatched. Our focus is on the high state power regime,\ni.e., the state power goes to infinity. Three (sub)models are studied. Model I\nserves as a basic model, which consists of only one transmitter-receiver (with\nstate corruption) pair in addition to a helper that assists the receiver to\ncancel state in addition to transmitting its own message. Model II consists of\ntwo transmitter-receiver pairs in addition to a helper, and only one receiver\nis interfered by a state sequence. Model III generalizes model I include\nmultiple transmitter-receiver pairs with each receiver corrupted by independent\nstate. For all models, inner and outer bounds on the capacity region are\nderived, and comparison of the two bounds leads to characterization of either\nfull or partial boundary of the capacity region under various channel\nparameters. \n\n"}
{"id": "1404.6512", "contents": "Title: Cellular Interference Alignment: Omni-Directional Antennas and\n  Asymmetric Configurations Abstract: Although interference alignment (IA) can theoretically achieve the optimal\ndegrees of freedom (DoFs) in the $K$-user Gaussian interference channel, its\ndirect application comes at the prohibitive cost of precoding over\nexponentially-many signaling dimensions. On the other hand, it is known that\npractical \"one-shot\" IA precoding (i.e., linear schemes without symbol\nexpansion) provides a vanishing DoFs gain in large fully-connected networks\nwith generic channel coefficients. In our previous work, we introduced the\nconcept of \"Cellular IA\" for a network topology induced by hexagonal cells with\nsectors and nearest-neighbor interference. Assuming that neighboring sectors\ncan exchange decoded messages (and not received signal samples) in the uplink,\nwe showed that linear one-shot IA precoding over $M$ transmit/receive antennas\ncan achieve the optimal $M/2$ DoFs per user. In this paper we extend this\nframework to networks with omni-directional (non-sectorized) cells and consider\nthe practical scenario where users have $2$ antennas, and base-stations have\n$2$, $3$ or $4$ antennas. In particular, we provide linear one-shot IA schemes\nfor the $2\\times 2$, $2\\times3$ and $2\\times 4$ cases, and show the\nachievability of $3/4$, $1$ and $7/6$ DoFs per user, respectively. DoFs\nconverses for one-shot schemes require the solution of a discrete optimization\nproblem over a number of variables that grows with the network size. We develop\na new approach to transform such challenging optimization problem into a\ntractable linear program (LP) with significantly fewer variables. This approach\nis used to show that the achievable $3/4$ DoFs per user are indeed optimal for\na large (extended) cellular network with $2\\times 2$ links. \n\n"}
{"id": "1404.6563", "contents": "Title: Coded Caching for Multi-level Popularity and Access Abstract: To address the exponentially rising demand for wireless content, use of\ncaching is emerging as a potential solution. It has been recently established\nthat joint design of content delivery and storage (coded caching) can\nsignificantly improve performance over conventional caching. Coded caching is\nwell suited to emerging heterogeneous wireless architectures which consist of a\ndense deployment of local-coverage wireless access points (APs) with high data\nrates, along with sparsely-distributed, large-coverage macro-cell base stations\n(BS). This enables design of coded caching-and-delivery schemes that equip APs\nwith storage, and place content in them in a way that creates coded-multicast\nopportunities for combining with macro-cell broadcast to satisfy users even\nwith different demands. Such coded-caching schemes have been shown to be\norder-optimal with respect to the BS transmission rate, for a system with\nsingle-level content, i.e., one where all content is uniformly popular. In this\nwork, we consider a system with non-uniform popularity content which is divided\ninto multiple levels, based on varying degrees of popularity. The main\ncontribution of this work is the derivation of an order-optimal scheme which\njudiciously shares cache memory among files with different popularities. To\nshow order-optimality we derive new information-theoretic lower bounds, which\nuse a sliding-window entropy inequality, effectively creating a non-cutset\nbound. We also extend the ideas to when users can access multiple caches along\nwith the broadcast. Finally we consider two extreme cases of user distribution\nacross caches for the multi-level popularity model: a single user per cache\n(single-user setup) versus a large number of users per cache (multi-user\nsetup), and demonstrate a dichotomy in the order-optimal strategies for these\ntwo extreme cases. \n\n"}
{"id": "1404.6683", "contents": "Title: Scheduling of Multicast and Unicast Services under Limited Feedback by\n  using Rateless Codes Abstract: Many opportunistic scheduling techniques are impractical because they require\naccurate channel state information (CSI) at the transmitter. In this paper, we\ninvestigate the scheduling of unicast and multicast services in a downlink\nnetwork with a very limited amount of feedback information. Specifically,\nunicast users send imperfect (or no) CSI and infrequent acknowledgements (ACKs)\nto a base station, and multicast users only report infrequent ACKs to avoid\nfeedback implosion. We consider the use of physical-layer rateless codes, which\nnot only combats channel uncertainty, but also reduces the overhead of ACK\nfeedback. A joint scheduling and power allocation scheme is developed to\nrealize multiuser diversity gain for unicast service and multicast gain for\nmulticast service. We prove that our scheme achieves a near-optimal throughput\nregion. Our simulation results show that our scheme significantly improves the\nnetwork throughput over schemes employing fixed-rate codes or using only\nunicast communications. \n\n"}
{"id": "1404.6945", "contents": "Title: Zero-Outage Cellular Downlink with Fixed-Rate D2D Underlay Abstract: Two of the emerging trends in wireless cellular systems are Device-to-Device\n(D2D) and Machine-to-Machine (M2M) communications. D2D enables efficient reuse\nof the licensed spectrum to support localized transmissions, while M2M\nconnections are often characterized by fixed and low transmission rates. D2D\nconnections can be instrumental in localized aggregation of uplink M2M traffic\nto a more capable cellular device, before being finally delivered to the Base\nStation (BS). In this paper we show that a fixed M2M rate is an enabler of\nefficient Machine-Type D2D underlay operation taking place simultaneously with\nanother \\emph{downlink} cellular transmission. In the considered scenario, a BS\n$B$ transmits to a user $U$, while there are $N_M$ Machine-Type Devices (MTDs)\nattached to $U$, all sending simultaneously to $U$ and each using the same rate\n$R_M$. While assuming that $B$ knows the channel $B-U$, but not the interfering\nchannels from the MTDs to $U$, we prove that there is a positive downlink rate\nthat can always be decoded by $U$, leading to zero-outage of the downlink\nsignal. This is a rather surprising consequence of the features of the multiple\naccess channel and the fixed rate $R_M$. We also consider the case of a\nsimpler, single-user decoder at $U$ with successive interference cancellation.\nHowever, with single-user decoder, a positive zero-outage rate exists only when\n$N_M=1$ and is zero when $N_M>1$. This implies that joint decoding is\ninstrumental in enabling fixed-rate underlay operation. \n\n"}
{"id": "1404.7022", "contents": "Title: Scaling Laws for Infrastructure Single and Multihop Wireless Networks in\n  Wideband Regimes Abstract: With millimeter wave bands emerging as a strong candidate for 5G cellular\nnetworks, next-generation systems may be in a unique position where spectrum is\nplentiful. To assess the potential value of this spectrum, this paper derives\nscaling laws on the per mobile downlink feasible rate with large bandwidth and\nnumber of nodes, for both Infrastructure Single Hop (ISH) and Infrastructure\nMulti-Hop (IMH) architectures. It is shown that, for both cases, there exist\n\\emph{critical bandwidth scalings} above which increasing the bandwidth no\nlonger increases the feasible rate per node. These critical thresholds coincide\nexactly with the bandwidths where, for each architecture, the network\ntransitions from being degrees-of-freedom-limited to power-limited. For ISH,\nthis critical bandwidth threshold is lower than IMH when the number of users\nper base station grows with network size. This result suggests that multi-hop\ntransmissions may be necessary to fully exploit large bandwidth degrees of\nfreedom in deployments with growing number of users per cell. \n\n"}
{"id": "1405.0931", "contents": "Title: Universal Memcomputing Machines Abstract: We introduce the notion of universal memcomputing machines (UMMs): a class of\nbrain-inspired general-purpose computing machines based on systems with memory,\nwhereby processing and storing of information occur on the same physical\nlocation. We analytically prove that the memory properties of UMMs endow them\nwith universal computing power - they are Turing-complete -, intrinsic\nparallelism, functional polymorphism, and information overhead, namely their\ncollective states can support exponential data compression directly in memory.\nWe also demonstrate that a UMM has the same computational power as a\nnon-deterministic Turing machine, namely it can solve NP--complete problems in\npolynomial time. However, by virtue of its information overhead, a UMM needs\nonly an amount of memory cells (memprocessors) that grows polynomially with the\nproblem size. As an example we provide the polynomial-time solution of the\nsubset-sum problem and a simple hardware implementation of the same. Even\nthough these results do not prove the statement NP=P within the Turing\nparadigm, the practical realization of these UMMs would represent a paradigm\nshift from present von Neumann architectures bringing us closer to brain-like\nneural computation. \n\n"}
{"id": "1405.1117", "contents": "Title: On the Two-user Interference Channel with Lack of Knowledge of the\n  Interference Codebook at one Receiver Abstract: In multi-user information theory it is often assumed that every node in the\nnetwork possesses all codebooks used in the network. This assumption may be\nimpractical in distributed ad-hoc, cognitive or heterogeneous networks. This\nwork considers the two-user Interference Channel with one Oblivious Receiver\n(IC-OR), i.e., one receiver lacks knowledge of the interfering cookbook while\nthe other receiver knows both codebooks. The paper asks whether, and if so how\nmuch, the channel capacity of the IC-OR is reduced compared to that of the\nclassical IC where both receivers know all codebooks. A novel outer bound is\nderived and shown to be achievable to within a gap for the class of injective\nsemi-deterministic IC-ORs; the gap is shown to be zero for injective fully\ndeterministic IC-ORs. For the linear deterministic IC-OR that models the\nGaussian noise channel at high SNR, non i.i.d. Bernoulli(1/2) input bits are\nshown to achieve points not achievable by i.i.d. Bernoulli(1/2) input bits used\nin the same achievability scheme. For the real-valued Gaussian IC-OR the gap is\nshown to be at most 1/2 bit per channel use, even though the set of optimal\ninput distributions for the derived outer bound could not be determined.\nTowards understanding the Gaussian IC-OR, an achievability strategy is\nevaluated in which the input alphabets at the non-oblivious transmitter are a\nmixture of discrete and Gaussian random variables, where the cardinality of the\ndiscrete part is appropriately chosen as a function of the channel parameters.\nSurprisingly, as the oblivious receiver intuitively should not be able to\n'jointly decode' the intended and interfering messages (whose codebook is\nunavailable), it is shown that with this choice of input, the capacity region\nof the symmetric Gaussian IC-OR is to within 3.34 bits (per channel use per\nuser) of an outer bound for the classical Gaussian IC with full codebook\nknowledge. \n\n"}
{"id": "1405.1365", "contents": "Title: Spectral Efficiency of Dynamic Coordinated Beamforming: A Stochastic\n  Geometry Approach Abstract: This paper characterizes the performance of coordinated beamforming with\ndynamic clustering. A downlink model based on stochastic geometry is put forth\nto analyze the performance of such base station (BS) coordination strategy.\nAnalytical expressions for the complementary cumulative distribution function\n(CCDF) of the instantaneous signal-to-interference ratio (SIR) are derived in\nterms of relevant system parameters, chiefly the number of BSs forming the\ncoordination clusters, the number of antennas per BS, and the pathloss\nexponent. Utilizing this CCDF, with pilot overheads further incorporated into\nthe analysis, we formulate the optimization of the BS coordination clusters for\na given fading coherence. Our results indicate that (i) coordinated beamforming\nis most beneficial to users that are in the outer part of their cells yet in\nthe inner part of their coordination cluster, and that (ii) the optimal cluster\ncardinality for the typical user is small and it scales with the fading\ncoherence. Simulation results verify the exactness of the SIR distributions\nderived for stochastic geometries, which are further compared with the\ncorresponding distributions for deterministic grid networks. \n\n"}
{"id": "1405.2092", "contents": "Title: Full-Duplex Cloud Radio Access Networks: An Information-Theoretic\n  Viewpoint Abstract: The conventional design of cellular systems prescribes the separation of\nuplink and downlink transmissions via time-division or frequency-division\nduplex. Recent advances in analog and digital domain self-interference\ninterference cancellation challenge the need for this arrangement and open up\nthe possibility to operate base stations, especially low-power ones, in a\nfull-duplex mode. As a means to cope with the resulting downlink-to-uplink\ninterference among base stations, this letter investigates the impact of the\nCloud Radio Access Network (C-RAN) architecture. The analysis follows an\ninformation theoretic approach based on the classical Wyner model. The\nanalytical results herein confirm the significant potential advantages of the\nC-RAN architecture in the presence of full-duplex base stations, as long as\nsufficient fronthaul capacity is available and appropriate mobile station\nscheduling, or successive interference cancellation at the mobile stations, is\nimplemented. \n\n"}
{"id": "1405.4345", "contents": "Title: Wiener Filters in Gaussian Mixture Signal Estimation with Infinity-Norm\n  Error Abstract: Consider the estimation of a signal ${\\bf x}\\in\\mathbb{R}^N$ from noisy\nobservations ${\\bf r=x+z}$, where the input~${\\bf x}$ is generated by an\nindependent and identically distributed (i.i.d.) Gaussian mixture source, and\n${\\bf z}$ is additive white Gaussian noise (AWGN) in parallel Gaussian\nchannels. Typically, the $\\ell_2$-norm error (squared error) is used to\nquantify the performance of the estimation process. In contrast, we consider\nthe $\\ell_\\infty$-norm error (worst case error). For this error metric, we\nprove that, in an asymptotic setting where the signal dimension $N\\to\\infty$,\nthe $\\ell_\\infty$-norm error always comes from the Gaussian component that has\nthe largest variance, and the Wiener filter asymptotically achieves the optimal\nexpected $\\ell_\\infty$-norm error. The i.i.d. Gaussian mixture case is easily\napplicable to i.i.d. Bernoulli-Gaussian distributions, which are often used to\nmodel sparse signals. Finally, our results can be extended to linear mixing\nsystems with i.i.d. Gaussian mixture inputs, in settings where a linear mixing\nsystem can be decoupled to parallel Gaussian channels. \n\n"}
{"id": "1405.5887", "contents": "Title: Performance Guarantees for ReProCS -- Correlated Low-Rank Matrix Entries\n  Case Abstract: Online or recursive robust PCA can be posed as a problem of recovering a\nsparse vector, $S_t$, and a dense vector, $L_t$, which lies in a slowly\nchanging low-dimensional subspace, from $M_t:= S_t + L_t$ on-the-fly as new\ndata comes in. For initialization, it is assumed that an accurate knowledge of\nthe subspace in which $L_0$ lies is available. In recent works, Qiu et al\nproposed and analyzed a novel solution to this problem called recursive\nprojected compressed sensing or ReProCS. In this work, we relax one limiting\nassumption of Qiu et al's result. Their work required that the $L_t$'s be\nmutually independent over time. However this is not a practical assumption,\ne.g., in the video application, $L_t$ is the background image sequence and one\nwould expect it to be correlated over time. In this work we relax this and\nallow the $L_t$'s to follow an autoregressive model. We are able to show that\nunder mild assumptions and under a denseness assumption on the unestimated part\nof the changed subspace, with high probability (w.h.p.), ReProCS can exactly\nrecover the support set of $S_t$ at all times; the reconstruction errors of\nboth $S_t$ and $L_t$ are upper bounded by a time invariant and small value; and\nthe subspace recovery error decays to a small value within a finite delay of a\nsubspace change time. Because the last assumption depends on an algorithm\nestimate, this result cannot be interpreted as a correctness result but only a\nuseful step towards it. \n\n"}
{"id": "1405.6286", "contents": "Title: Exploiting User Mobility for Wireless Content Delivery Abstract: We consider the problem of storing segments of encoded versions of content\nfiles in a set of base stations located in a communication cell. These base\nstations work in conjunction with the main base station of the cell. Users move\nrandomly across the space based on a discrete-time Markov chain model. At each\ntime slot each user accesses a single base station based on it's current\nposition and it can download only a part of the content stored in it, depending\non the time slot duration. We assume that file requests must be satisfied\nwithin a given time deadline in order to be successful. If the amount of the\ndownloaded (encoded) data by the accessed base stations when the time deadline\nexpires does not suffice to recover the requested file, the main base station\nof the cell serves the request. Our aim is to find the storage allocation that\nminimizes the probability of using the main base station for file delivery.\nThis problem is intractable in general. However, we show that the optimal\nsolution of the problem can be efficiently attained in case that the time\ndeadline is small. To tackle the general case, we propose a distributed\napproximation algorithm based on large deviation inequalities. Systematic\nexperiments on a real world data set demonstrate the effectiveness of our\nproposed algorithms. Index Terms: Mobility-aware Caching, Markov Chain, MDS\nCoding, Small-cell Networks \n\n"}
{"id": "1405.6544", "contents": "Title: Continuous Compressed Sensing With a Single or Multiple Measurement\n  Vectors Abstract: We consider the problem of recovering a single or multiple frequency-sparse\nsignals, which share the same frequency components, from a subset of regularly\nspaced samples. The problem is referred to as continuous compressed sensing\n(CCS) in which the frequencies can take any values in the normalized domain\n[0,1). In this paper, a link between CCS and low rank matrix completion (LRMC)\nis established based on an $\\ell_0$-pseudo-norm-like formulation, and\ntheoretical guarantees for exact recovery are analyzed. Practically efficient\nalgorithms are proposed based on the link and convex and nonconvex relaxations,\nand validated via numerical simulations. \n\n"}
{"id": "1406.1055", "contents": "Title: Lattice Codes for the Binary Deletion Channel Abstract: The construction of deletion codes for the Levenshtein metric is reduced to\nthe construction of codes over the integers for the Manhattan metric by run\nlength coding. The latter codes are constructed by expurgation of translates of\nlattices. These lattices, in turn, are obtained from Construction~A applied to\nbinary codes and $\\Z_4-$codes. A lower bound on the size of our codes for the\nManhattan distance are obtained through generalized theta series of the\ncorresponding lattices. \n\n"}
{"id": "1406.2255", "contents": "Title: Energy-Efficient Cooperative Cognitive Relaying Schemes for Cognitive\n  Radio Networks Abstract: We investigate a cognitive radio network in which a primary user (PU) may\ncooperate with a cognitive radio user (i.e., a secondary user (SU)) for\ntransmissions of its data packets. The PU is assumed to be a buffered node\noperating in a time-slotted fashion where the time is partitioned into\nequal-length slots. We develop two schemes which involve cooperation between\nprimary and secondary users. To satisfy certain quality of service (QoS)\nrequirements, users share time slot duration and channel frequency bandwidth.\nMoreover, the SU may leverage the primary feedback message to further increase\nboth its data rate and satisfy the PU QoS requirements. The proposed\ncooperative schemes are designed such that the SU data rate is maximized under\nthe constraint that the PU average queueing delay is maintained less than the\naverage queueing delay in case of non-cooperative PU. In addition, the proposed\nschemes guarantee the stability of the PU queue and maintain the average energy\nemitted by the SU below a certain value. The proposed schemes also provide more\nrobust and potentially continuous service for SUs compared to the conventional\npractice in cognitive networks where SUs transmit in the spectrum holes and\nsilence sessions of the PUs. We include primary source burstiness, sensing\nerrors, and feedback decoding errors to the analysis of our proposed\ncooperative schemes. The optimization problems are solved offline and require a\nsimple 2-dimensional grid-based search over the optimization variables.\nNumerical results show the beneficial gains of the cooperative schemes in terms\nof SU data rate and PU throughput, average PU queueing delay, and average PU\nenergy savings. \n\n"}
{"id": "1406.4852", "contents": "Title: Outer bounds for exact repair codes Abstract: We address the open problem of establishing the rate region for exact-repair\nregenerating codes for given parameters (n,k,d). Tian determined the rate\nregion for a (4,3,3) code and found that it lies strictly within the\nfunctional-repair rate region. Using different methods, Sasidharan, Senthoor\nand Kumar proved a non-vanishing gap between the functional-repair outer bound\nand the exact-repair outer bound for codes with k>=3. Our main results are two\nimproved outer bounds for exact-repair regenerating codes. They capture and\nthen extend essential parts in the proofs by Tian and by Sasidharan, Senthoor\nand Kumar. We show that the bounds can be combined for further improvements. \n\n"}
{"id": "1406.4943", "contents": "Title: \"Infographics\" team: Selecting Control Parameters via Maximal Fisher\n  Information Abstract: Team description paper for RoboCup 2014 Soccer Simulation League 2D. \n\n"}
{"id": "1406.5988", "contents": "Title: Large System Analysis of the Energy Consumption Distribution in\n  Multi-User MIMO Systems with Mobility Abstract: In this work, we consider the downlink of a single-cell multi-user MIMO\nsystem in which the base station (BS) makes use of $N$ antennas to communicate\nwith $K$ single-antenna user equipments (UEs). The UEs move around in the cell\naccording to a random walk mobility model. We aim at determining the energy\nconsumption distribution when different linear precoding techniques are used at\nthe BS to guarantee target rates within a finite time interval $T$. The\nanalysis is conducted in the asymptotic regime where $N$ and $K$ grow large\nwith fixed ratio under the assumption of perfect channel state information\n(CSI). Both recent and standard results from large system analysis are used to\nprovide concise formulae for the asymptotic transmit powers and beamforming\nvectors for all considered schemes. These results are eventually used to\nprovide a deterministic approximation of the energy consumption and to study\nits fluctuations around this value in the form of a central limit theorem.\nClosed-form expressions for the asymptotic means and variances are given.\nNumerical results are used to validate the accuracy of the theoretical analysis\nand to make comparisons. We show how the results can be used to approximate the\nprobability that a battery-powered BS runs out of energy and also to design the\ncell radius for minimizing the energy consumption per unit area. The imperfect\nCSI case is also briefly considered. \n\n"}
{"id": "1406.6170", "contents": "Title: Distributed Storage Systems based on Equidistant Subspace Codes Abstract: Distributed storage systems based on equidistant constant dimension codes are\npresented. These equidistant codes are based on the Pl\\\"{u}cker embedding,\nwhich is essential in the repair and the reconstruction algorithms. These\nsystems posses several useful properties such as high failure resilience,\nminimum bandwidth, low storage, simple algebraic repair and reconstruction\nalgorithms, good locality, and compatibility with small fields. \n\n"}
{"id": "1406.7435", "contents": "Title: Compression in the Space of Permutations Abstract: We investigate lossy compression (source coding) of data in the form of\npermutations. This problem has direct applications in the storage of ordinal\ndata or rankings, and in the analysis of sorting algorithms. We analyze the\nrate-distortion characteristic for the permutation space under the uniform\ndistribution, and the minimum achievable rate of compression that allows a\nbounded distortion after recovery. Our analysis is with respect to different\npractical and useful distortion measures, including Kendall-tau distance,\nSpearman's footrule, Chebyshev distance and inversion-$\\ell_1$ distance. We\nestablish equivalence of source code designs under certain distortions and show\nsimple explicit code designs that incur low encoding/decoding complexities and\nare asymptotically optimal. Finally, we show that for the Mallows model, a\npopular nonuniform ranking model on the permutation space, both the entropy and\nthe maximum distortion at zero rate are much lower than the uniform\ncounterparts, which motivates the future design of efficient compression\nschemes for this model. \n\n"}
{"id": "1407.0474", "contents": "Title: Recent Advances in Joint Wireless Energy and Information Transfer Abstract: In this paper, we provide an overview of the recent advances in\nmicrowave-enabled wireless energy transfer (WET) technologies and their\napplications in wireless communications. Specifically, we divide our\ndiscussions into three parts. First, we introduce the state-of-the-art WET\ntechnologies and the signal processing techniques to maximize the energy\ntransfer efficiency. Then, we discuss an interesting paradigm named\nsimultaneous wireless information and power transfer (SWIPT), where energy and\ninformation are jointly transmitted using the same radio waveform. At last, we\nreview the recent progress in wireless powered communication networks (WPCN),\nwhere wireless devices communicate using the power harvested by means of WET.\nExtensions and future directions are also discussed in each of these areas. \n\n"}
{"id": "1407.0524", "contents": "Title: Analysis and Augmented Spatial Processing for Uplink OFDMA MU-MIMO\n  Receiver with Transceiver I/Q Imbalance and External Interference Abstract: We address receiver (RX) signal processing in MIMO systems under\nin-phase/quadrature (I/Q) imbalance, which causes cross-talk of\nmirror-subcarriers in OFDM systems. We extend the typically reported\nsingle-user studies to uplink OFDMA-based multiuser MIMO, with simultaneous\nuser multiplexing in frequency and spatial domains. We also incorporate\nmultiple external interferers, for modeling challenging conditions in\nheterogeneous networks. In the signal processing developments, we exploit the\naugmented subcarrier processing, which processes each subcarrier jointly with\nits counterpart at the image subcarrier, and jointly across RX antennas.\nFurthermore, we derive an augmented LMMSE RX. The novel approach integrates the\nI/Q imbalance mitigation, interference suppression and data stream separation\ninto a single processing stage, thus avoiding a separate transceiver\ncalibration. Our numerical results show the signal-to-interference-plus-noise\nratio and symbol-error rate of an arbitrary data stream after RX processing as\na function of different system parameters. The per-subcarrier processing is\nshown to suffer heavily under I/Q imbalances, and being particularly sensitive\nto external interferers, whereas the augmented method provides efficient data\nstream separation and interference suppression. Finally, we extend the studies\nto massive MIMO framework and show that the per-subcarrier processing still\nsuffers from performance degradation, whereas the augmented approach can fully\nexploit the array gain. \n\n"}
{"id": "1407.1424", "contents": "Title: Cross Layer Provision of Future Cellular Networks Abstract: To cope with the growing demand for wireless data and to extend service\ncoverage, future 5G networks will increasingly rely on the use of low powered\nnodes to support massive connectivity in diverse set of applications and\nservices [1]. To this end, virtualized and mass-scale cloud architectures are\nproposed as promising technologies for 5G in which all the nodes are connected\nvia a backhaul network and managed centrally by such cloud centers. The\nsignificant computing power made available by the cloud technologies has\nenabled the implementation of sophisticated signal processing algorithms,\nespecially by way of parallel processing, for both interference management and\nnetwork provision. The latter two are among the major signal processing tasks\nfor 5G due to increased level of frequency sharing, node density, interference\nand network congestion. This article outlines several theoretical and practical\naspects of joint interference management and network provisioning for future 5G\nnetworks. A cross-layer optimization framework is proposed for joint user\nadmission, user-base station association, power control, user grouping,\ntransceiver design as well as routing and flow control. We show that many of\nthese cross-layer tasks can be treated in a unified way and implemented in a\nparallel manner using an efficient algorithmic framework called WMMSE (Weighted\nMMSE). Some recent developments in this area are highlighted and future\nresearch directions are identified. \n\n"}
{"id": "1407.1492", "contents": "Title: Joint Beamforming Design for Multi-User Wireless Information and Power\n  Transfer Abstract: In this paper, we propose a joint beamforming algorithm for a multiuser\nwireless information and power transfer (MU-WIPT) system that is compatible\nwith the conventional multiuser multiple input multiple output (MU-MIMO)\nsystem. The proposed joint beamforming vectors are initialized using the well\nestablished MU-MIMO zero-forcing beamforming (ZFBF) and are further updated to\nmaximize the total harvested energy of energy harvesting (EH) users and\nguarantee the signal to interference plus noise ratio (SINR) constraints of the\nco-scheduled information decoding (ID) users. When ID and EH users are\nsimultaneously served by joint beamforming vectors, the harvested energy can be\nincreased at the cost of an SINR loss for ID users. To characterize the SINR\nloss, the target SINR ratio,u, is introduced as the target SINR (i.e., SINR\nconstraint) normalized by the received SINR achievable with ZFBF. Based on that\nratio, the sum rate and harvested energy obtained from the proposed algorithm\nare analyzed under perfect/imperfect channel state information at the\ntransmitter (CSIT). Through simulations and numerical results, we validate the\nderived analyses and demonstrate the EH and ID performance compared to both\nstate of the art and conventional schemes. \n\n"}
{"id": "1407.4884", "contents": "Title: A new construction of differentially 4-uniform permutations over\n  $F_{2^{2k}}$ Abstract: Permutations over $F_{2^{2k}}$ with low differential uniform, high algebraic\ndegree and high nonlinearity are of great cryptographical importance since they\ncan be chosen as the substitution boxes (S-boxes) for many block ciphers. A\nwell known example is that the Advanced Encryption Standard (AES) chooses a\ndifferentially 4-uniform permutation, the multiplicative inverse function, as\nits S-box. In this paper, we present a new construction of differentially\n4-uniformity permutations over even characteristic finite fields and obtain\nmany new CCZ-inequivalent functions. All the functions are switching neighbors\nin the narrow sense of the multiplicative inverse function and have the optimal\nalgebraic degree and high nonlinearity. \n\n"}
{"id": "1407.5355", "contents": "Title: Secure Wireless Information and Power Transfer in Large-Scale MIMO\n  Relaying Systems with Imperfect CSI Abstract: In this paper, we address the problem of secure wireless information and\npower transfer in a large-scale multiple-input multiple-output (LS-MIMO)\namplify-and-forward (AF) relaying system. The advantage of LS-MIMO relay is\nexploited to enhance wireless security, transmission rate and energy\nefficiency. In particular, the challenging issues incurred by short\ninterception distance and long transfer distance are well addressed\nsimultaneously. Under very practical assumptions, i.e., no eavesdropper's\nchannel state information (CSI) and imperfect legitimate channel CSI, this\npaper investigates the impact of imperfect CSI, and obtains an explicit\nexpression of the secrecy outage capacity in terms of transmit power and\nchannel condition. Then, we propose an optimal power splitting scheme at the\nrelay to maximize the secrecy outage capacity. Finally, our theoretical claims\nare validated by simulation results. \n\n"}
{"id": "1408.0377", "contents": "Title: Layered, Exact-Repair Regenerating Codes Via Embedded Error Correction\n  and Block Designs Abstract: A new class of exact-repair regenerating codes is constructed by stitching\ntogether shorter erasure correction codes, where the stitching pattern can be\nviewed as block designs. The proposed codes have the \"help-by-transfer\"\nproperty where the helper nodes simply transfer part of the stored data\ndirectly, without performing any computation. This embedded error correction\nstructure makes the decoding process straightforward, and in some cases the\ncomplexity is very low. We show that this construction is able to achieve\nperformance better than space-sharing between the minimum storage regenerating\ncodes and the minimum repair-bandwidth regenerating codes, and it is the first\nclass of codes to achieve this performance. In fact, it is shown that the\nproposed construction can achieve a non-trivial point on the optimal\nfunctional-repair tradeoff, and it is asymptotically optimal at high rate,\ni.e., it asymptotically approaches the minimum storage and the minimum\nrepair-bandwidth simultaneously. \n\n"}
{"id": "1408.0581", "contents": "Title: Parametric Schemes for Prediction of Wideband MIMO Wireless Channels Abstract: Information on the future state of time varying frequency selective channels\ncan significantly enhance the effectiveness of feedback in adaptive and limited\nfeedback MIMO-OFDM systems. This paper investigates the parametric\nextrapolation of wideband MIMO channels using variations of the double\ndirectional MIMO model. We propose three predictors which estimate parameters\nof the channel using 4D, 3D and 2D extensions of the ESPRIT algorithm and\npredict future states of the channel using the models. Furthermore, using the\nvector formulation of the Cramer Rao lower bound for functions of parameters,\nwe derive a bound on the prediction error in wideband MIMO channels. Numerical\nsimulations are used to evaluate the performance of the proposed algorithms\nunder different channel and transmission conditions, and a comparison is made\nwith the derived error bound. \n\n"}
{"id": "1408.1338", "contents": "Title: The Boolean Model in the Shannon Regime: Three Thresholds and Related\n  Asymptotics Abstract: Consider a family of Boolean models, indexed by integers $n \\ge 1$, where the\n$n$-th model features a Poisson point process in ${\\mathbb{R}}^n$ of intensity\n$e^{n \\rho_n}$ with $\\rho_n \\to \\rho$ as $n \\to \\infty$, and balls of\nindependent and identically distributed radii distributed like $\\bar X_n\n\\sqrt{n}$, with $\\bar X_n$ satisfying a large deviations principle. It is shown\nthat there exist three deterministic thresholds: $\\tau_d$ the degree threshold;\n$\\tau_p$ the percolation threshold; and $\\tau_v$ the volume fraction threshold;\nsuch that asymptotically as $n$ tends to infinity, in a sense made precise in\nthe paper: (i) for $\\rho < \\tau_d$, almost every point is isolated, namely its\nball intersects no other ball; (ii) for $\\tau_d< \\rho< \\tau_p$, almost every\nball intersects an infinite number of balls and nevertheless there is no\npercolation; (iii) for $\\tau_p< \\rho< \\tau_v$, the volume fraction is 0 and\nnevertheless percolation occurs; (iv) for $\\tau_d< \\rho< \\tau_v$, almost every\nball intersects an infinite number of balls and nevertheless the volume\nfraction is 0; (v) for $\\rho > \\tau_v$, the whole space covered. The analysis\nof this asymptotic regime is motivated by related problems in information\ntheory, and may be of interest in other applications of stochastic geometry. \n\n"}
{"id": "1408.2232", "contents": "Title: Interference-Aware RZF Precoding for Multi Cell Downlink Systems Abstract: Recently, a structure of an optimal linear precoder for multi cell downlink\nsystems has been described in [1, Eq (3.33)]. Other references (e.g., [2,3])\nhave used simplified versions of the precoder to obtain promising performance\ngains. These gains have been hypothesized to stem from the additional degrees\nof freedom that allow for interference mitigation through interference\nrelegation to orthogonal subspaces. However, no conclusive or rigorous\nunderstanding has yet been developed. In this paper, we build on an intuitive\ninterference induction trade-off and the aforementioned precoding structure to\npropose an interference aware RZF (iaRZF) precoding scheme for multi cell\ndownlink systems and we analyze its rate performance. Special emphasis is\nplaced on the induced interference mitigation mechanism of iaRZF. For example,\nwe will verify the intuitive expectation that the precoder structure can either\ncompletely remove induced inter-cell or intra-cell interference. We state new\nresults from large-scale random matrix theory that make it possible to give\nmore intuitive and insightful explanations of the precoder behavior, also for\ncases involving imperfect channel state information (CSI). We remark especially\nthat the interference-aware precoder makes use of all available information\nabout interfering channels to improve performance. Even very poor CSI allows\nfor significant sum-rate gains. Our obtained insights are then used to propose\nheuristic precoder parameters for arbitrary systems, whose effectiveness are\nshown in more involved system scenarios. Furthermore, calculation and\nimplementation of these parameters does not require explicit inter base station\ncooperation. \n\n"}
{"id": "1408.2779", "contents": "Title: A Probabilistic MAC for Cognitive Radio Systems with Energy Harvesting\n  Nodes Abstract: In this paper, we consider a cognitive radio (CR) system where the secondary\nuser (SU) harvests energy from both the nature resources and the primary user\n(PU) radio frequency(RF) signal. We propose an energy-based probabilistic\naccess scheme in which SU probabilistically accesses and senses the primary\nchannel. The decision is based on the available energy and the PU's activity.\nWe investigate the problem of maximizing the SU's success rate provided that\nthe PU average quality of service (QoS) constraint is satisfied. We also assume\nmulti-packet reception (MPR) capability and sensing errors under a Rayleigh\nfading channel. Numerical results show the effectiveness of the proposed\nprobabilistic access scheme. \n\n"}
{"id": "1408.4994", "contents": "Title: Interference Alignment for Multicell Multiuser MIMO Uplink Channels Abstract: This paper proposes a linear interference alignment (IA) scheme which can be\nused for uplink channels in a general multicell multiuser MIMO cellular\nnetwork. The proposed scheme aims to align interference caused by signals from\na set of transmitters into a subspace which is established by the signals from\nonly a subset of those transmitters, thereby effectively reducing the number of\ninterfering transmitters. The total degrees of freedom (DoF) achievable by the\nproposed scheme is given in closed-form expression, and a numerical analysis\nshows that the proposed scheme can achieve the optimal DoF in certain scenarios\nand provides a higher total DoF than other related schemes in most cases. \n\n"}
{"id": "1408.5250", "contents": "Title: Compressed Sensing with Prior Information: Optimal Strategies, Geometry,\n  and Bounds Abstract: We address the problem of compressed sensing (CS) with prior information:\nreconstruct a target CS signal with the aid of a similar signal that is known\nbeforehand, our prior information. We integrate the additional knowledge of the\nsimilar signal into CS via L1-L1 and L1-L2 minimization. We then establish\nbounds on the number of measurements required by these problems to successfully\nreconstruct the original signal. Our bounds and geometrical interpretations\nreveal that if the prior information has good enough quality, L1-L1\nminimization improves the performance of CS dramatically. In contrast, L1-L2\nminimization has a performance very similar to classical CS and brings no\nsignificant benefits. All our findings are illustrated with experimental\nresults. \n\n"}
{"id": "1408.6927", "contents": "Title: Non-existence of a ternary constant weight $(16, 5, 15; 2048)$ diameter\n  perfect code Abstract: Ternary constant weight codes of length $n=2^m$, weight $n-1$, cardinality\n$2^n$ and distance $5$ are known to exist for every $m$ for which there exists\nan APN permutation of order $2^m$, that is, at least for all odd $m \\geq 3$ and\nfor $m=6$. We show the non-existence of such codes for $m=4$ and prove that any\ncodes with the parameters above are diameter perfect. \n\n"}
{"id": "1409.2048", "contents": "Title: Quantum Belief Propagation Algorithm versus Suzuki-Trotter approach in\n  the one-dimensional Heisenberg chains Abstract: Quantum systems are the future candidates for computers and information\nprocessing devices. Information about quantum states and processes may be\nincomplete and scattered in these systems. We use a quantum version of Belief\nPropagation(BP) Algorithm to integrate the distributed information. In this\nalgorithm the distributed information, which is in the form of density matrix,\ncan be approximated to local structures. The validity of this algorithm is\nmeasured in comparison with Suzuki-Trotter(ST) method, using simulated\ninformation. ST in 3-body Heisenberg example gives a more accurate answer,\nhowever Quantum Belief Propagation (QBP) runs faster based on complexity. In\norder to develop it in the future, we should be looking for ways to increase\nthe accuracy of QBP. \n\n"}
{"id": "1409.2177", "contents": "Title: The Large Margin Mechanism for Differentially Private Maximization Abstract: A basic problem in the design of privacy-preserving algorithms is the private\nmaximization problem: the goal is to pick an item from a universe that\n(approximately) maximizes a data-dependent function, all under the constraint\nof differential privacy. This problem has been used as a sub-routine in many\nprivacy-preserving algorithms for statistics and machine-learning.\n  Previous algorithms for this problem are either range-dependent---i.e., their\nutility diminishes with the size of the universe---or only apply to very\nrestricted function classes. This work provides the first general-purpose,\nrange-independent algorithm for private maximization that guarantees\napproximate differential privacy. Its applicability is demonstrated on two\nfundamental tasks in data mining and machine learning. \n\n"}
{"id": "1409.3900", "contents": "Title: Cooperative Local Repair in Distributed Storage Abstract: Erasure-correcting codes, that support local repair of codeword symbols, have\nattracted substantial attention recently for their application in distributed\nstorage systems. This paper investigates a generalization of the usual locally\nrepairable codes. In particular, this paper studies a class of codes with the\nfollowing property: any small set of codeword symbols can be reconstructed\n(repaired) from a small number of other symbols. This is referred to as\ncooperative local repair. The main contribution of this paper is bounds on the\ntrade-off of the minimum distance and the dimension of such codes, as well as\nexplicit constructions of families of codes that enable cooperative local\nrepair. Some other results regarding cooperative local repair are also\npresented, including an analysis for the well-known Hadamard/Simplex codes. \n\n"}
{"id": "1409.4744", "contents": "Title: An Efficient List Decoder Architecture for Polar Codes Abstract: Long polar codes can achieve the symmetric capacity of arbitrary binary-input\ndiscrete memoryless channels under a low complexity successive cancelation (SC)\ndecoding algorithm. However, for polar codes with short and moderate code\nlength, the decoding performance of the SC algorithm is inferior. The cyclic\nredundancy check (CRC) aided successive cancelation list (SCL) decoding\nalgorithm has better error performance than the SC algorithm for short or\nmoderate polar codes. In this paper, we propose an efficient list decoder\narchitecture for the CRC aided SCL algorithm, based on both algorithmic\nreformulations and architectural techniques. In particular, an area efficient\nmessage memory architecture is proposed to reduce the area of the proposed\ndecoder architecture. An efficient path pruning unit suitable for large list\nsize is also proposed. For a polar code of length 1024 and rate $\\frac{1}{2}$,\nwhen list size $L=2$ and 4, the proposed list decoder architecture is\nimplemented under a TSMC 90nm CMOS technology. Compared with the list decoders\nin the literature, our decoder achieves 1.33 to 1.96 times hardware efficiency. \n\n"}
{"id": "1409.5505", "contents": "Title: Low-Dimensional Topology of Information Fusion Abstract: We provide an axiomatic characterization of information fusion, on the basis\nof which we define an information fusion network. Our construction is\nreminiscent of tangle diagrams in low dimensional topology. Information fusion\nnetworks come equipped with a natural notion of equivalence. Equivalent\nnetworks `contain the same information', but differ locally. When fusing\nstreams of information, an information fusion network may adaptively optimize\nitself inside its equivalence class. This provides a fault tolerance mechanism\nfor such networks. \n\n"}
{"id": "1409.6902", "contents": "Title: Sign-Compute-Resolve for Random Access Abstract: We present an approach to random access that is based on three elements:\nphysical-layer network coding, signature codes and tree splitting. Upon\noccurrence of a collision, physical-layer network coding enables the receiver\nto decode the sum of the information that was transmitted by the individual\nusers. For each user this information consists of the data that the user wants\nto communicate as well as the user's signature. As long as no more than $K$\nusers collide, their identities can be recovered from the sum of their\nsignatures. A splitting protocol is used to deal with the case that more than\n$K$ users collide. We measure the performance of the proposed method in terms\nof user resolution rate as well as overall throughput of the system. The\nresults show that our approach significantly increases the performance of the\nsystem even compared to coded random access, where collisions are not wasted,\nbut are reused in successive interference cancellation. \n\n"}
{"id": "1409.7458", "contents": "Title: Beyond Maximum Likelihood: from Theory to Practice Abstract: Maximum likelihood is the most widely used statistical estimation technique.\nRecent work by the authors introduced a general methodology for the\nconstruction of estimators for functionals in parametric models, and\ndemonstrated improvements - both in theory and in practice - over the maximum\nlikelihood estimator (MLE), particularly in high dimensional scenarios\ninvolving parameter dimension comparable to or larger than the number of\nsamples. This approach to estimation, building on results from approximation\ntheory, is shown to yield minimax rate-optimal estimators for a wide class of\nfunctionals, implementable with modest computational requirements. In a\nnutshell, a message of this recent work is that, for a wide class of\nfunctionals, the performance of these essentially optimal estimators with $n$\nsamples is comparable to that of the MLE with $n \\ln n$ samples.\n  In the present paper, we highlight the applicability of the aforementioned\nmethodology to statistical problems beyond functional estimation, and show that\nit can yield substantial gains. For example, we demonstrate that for learning\ntree-structured graphical models, our approach achieves a significant reduction\nof the required data size compared with the classical Chow--Liu algorithm,\nwhich is an implementation of the MLE, to achieve the same accuracy. The key\nstep in improving the Chow--Liu algorithm is to replace the empirical mutual\ninformation with the estimator for mutual information proposed by the authors.\nFurther, applying the same replacement approach to classical Bayesian network\nclassification, the resulting classifiers uniformly outperform the previous\nclassifiers on 26 widely used datasets. \n\n"}
{"id": "1409.8434", "contents": "Title: Pilot Beam Sequence Design for Channel Estimation in Millimeter-Wave\n  MIMO Systems: A POMDP Framework Abstract: In this paper, adaptive pilot beam sequence design for channel estimation in\nlarge millimeter-wave (mmWave) MIMO systems is considered. By exploiting the\nsparsity of mmWave MIMO channels with the virtual channel representation and\nimposing a Markovian random walk assumption on the physical movement of the\nline-of-sight (LOS) and reflection clusters, it is shown that the sparse\nchannel estimation problem in large mmWave MIMO systems reduces to a sequential\ndetection problem that finds the locations and values of the non-zero-valued\nbins in a two-dimensional rectangular grid, and the optimal adaptive pilot\ndesign problem can be cast into the framework of a partially observable Markov\ndecision process (POMDP). Under the POMDP framework, an optimal adaptive pilot\nbeam sequence design method is obtained to maximize the accumulated\ntransmission data rate for a given period of time. Numerical results are\nprovided to validate our pilot signal design method and they show that the\nproposed method yields good performance. \n\n"}
{"id": "1409.8653", "contents": "Title: The capacity of non-identical adaptive group testing Abstract: We consider the group testing problem, in the case where the items are\ndefective independently but with non-constant probability. We introduce and\nanalyse an algorithm to solve this problem by grouping items together\nappropriately. We give conditions under which the algorithm performs\nessentially optimally in the sense of information-theoretic capacity. We use\nconcentration of measure results to bound the probability that this algorithm\nrequires many more tests than the expected number. This has applications to the\nallocation of spectrum to cognitive radios, in the case where a database gives\nprior information that a particular band will be occupied. \n\n"}
{"id": "1410.0989", "contents": "Title: On the Effective Measure of Dimension in the Analysis Cosparse Model Abstract: Many applications have benefited remarkably from low-dimensional models in\nthe recent decade. The fact that many signals, though high dimensional, are\nintrinsically low dimensional has given the possibility to recover them stably\nfrom a relatively small number of their measurements. For example, in\ncompressed sensing with the standard (synthesis) sparsity prior and in matrix\ncompletion, the number of measurements needed is proportional (up to a\nlogarithmic factor) to the signal's manifold dimension.\n  Recently, a new natural low-dimensional signal model has been proposed: the\ncosparse analysis prior. In the noiseless case, it is possible to recover\nsignals from this model, using a combinatorial search, from a number of\nmeasurements proportional to the signal's manifold dimension. However, if we\nask for stability to noise or an efficient (polynomial complexity) solver, all\nthe existing results demand a number of measurements which is far removed from\nthe manifold dimension, sometimes far greater. Thus, it is natural to ask\nwhether this gap is a deficiency of the theory and the solvers, or if there\nexists a real barrier in recovering the cosparse signals by relying only on\ntheir manifold dimension. Is there an algorithm which, in the presence of\nnoise, can accurately recover a cosparse signal from a number of measurements\nproportional to the manifold dimension? In this work, we prove that there is no\nsuch algorithm. Further, we show through numerical simulations that even in the\nnoiseless case convex relaxations fail when the number of measurements is\ncomparable to the manifold dimension. This gives a practical counter-example to\nthe growing literature on compressed acquisition of signals based on manifold\ndimension. \n\n"}
{"id": "1410.2687", "contents": "Title: Second-Order Coding Rates for Conditional Rate-Distortion Abstract: This paper characterizes the second-order coding rates for lossy source\ncoding with side information available at both the encoder and the decoder. We\nfirst provide non-asymptotic bounds for this problem and then specialize the\nnon-asymptotic bounds for three different scenarios: discrete memoryless\nsources, Gaussian sources, and Markov sources. We obtain the second-order\ncoding rates for these settings. It is interesting to observe that the\nsecond-order coding rate for Gaussian source coding with Gaussian side\ninformation available at both the encoder and the decoder is the same as that\nfor Gaussian source coding without side information. Furthermore, regardless of\nthe variance of the side information, the dispersion is $1/2$ nats squared per\nsource symbol. \n\n"}
{"id": "1410.2867", "contents": "Title: Multiuser Joint Energy-Bandwidth Allocation with Energy Harvesting -\n  Part II: Multiple Broadcast Channels & Proportional Fairness Abstract: In this paper, we consider the energy-bandwidth allocation for a network with\nmultiple broadcast channels, where the transmitters access the network\northogonally on the assigned frequency band and each transmitter communicates\nwith multiple receivers orthogonally or non-orthogonally. We assume that the\nenergy harvesting state and channel gain of each transmitter can be predicted\nfor $K$ slots {\\em a priori}. To maximize the weighted throughput, we formulate\nan optimization problem with $O(MK)$ constraints, where $M$ is the number of\nthe receivers, and decompose it into the energy and bandwidth allocation\nsubproblems. In order to use the iterative algorithm proposed in [1] to solve\nthe problem, we propose efficient algorithms to solve the two subproblems, so\nthat the optimal energy-bandwidth allocation can be obtained with an overall\ncomplexity of ${\\cal O}(MK^2)$, even though the problem is non-convex when the\nbroadcast channel is non-orthogonal. For the orthogonal broadcast channel, we\nfurther formulate a proportionally-fair (PF) throughput maximization problem\nand derive the equivalence conditions such that the optimal solution can be\nobtained by solving a weighted throughput maximization problem. Further, the\nalgorithm to obtain the proper weights is proposed. Simulation results show\nthat the proposed algorithm can make efficient use of the harvested energy and\nthe available bandwidth, and achieve significantly better performance than some\nheuristic policies for energy and bandwidth allocation. Moreover, it is seen\nthat with energy-harvesting transmitters, non-orthogonal broadcast offers\nlimited gain over orthogonal broadcast. \n\n"}
{"id": "1410.2881", "contents": "Title: The Henchman Problem: Measuring Secrecy by the Minimum Distortion in a\n  List Abstract: We introduce a new measure of information-theoretic secrecy based on\nrate-distortion theory and study it in the context of the Shannon cipher\nsystem. Whereas rate-distortion theory is traditionally concerned with a single\nreconstruction sequence, in this work we suppose that an eavesdropper produces\na list of $2^{nR_{\\sf L}}$ reconstruction sequences and measure secrecy by the\nminimum distortion over the entire list. We show that this setting is\nequivalent to one in which an eavesdropper must reconstruct a single sequence,\nbut also receives side information about the source sequence and public message\nfrom a rate-limited henchman (a helper for an adversary). We characterize the\noptimal tradeoff of secret key rate, list rate, and eavesdropper distortion.\nThe solution hinges on a problem of independent interest: lossy compression of\na codeword drawn uniformly from a random codebook. We also characterize the\nsolution to the lossy communication version of the problem in which distortion\nis allowed at the legitimate receiver. The analysis in both settings is greatly\naided by a recent technique for proving source coding results with the use of a\nlikelihood encoder. \n\n"}
{"id": "1410.3422", "contents": "Title: Achieving Secrecy Capacity of the Wiretap Channel and Broadcast Channel\n  with a Confidential Component Abstract: The wiretap channel model of Wyner is one of the first communication models\nwith both reliability and security constraints. Capacity-achieving schemes for\nvarious models of the wiretap channel have received considerable attention in\nrecent literature. In this paper, we show that capacity of the general (not\nnecessarily degraded or symmetric) wiretap channel under a \"strong secrecy\nconstraint\" can be achieved using a transmission scheme based on polar codes.\nWe also extend our construction to the case of broadcast channels with\nconfidential messages defined by Csisz{\\'a}r and K{\\\"orner}, achieving the\nentire capacity region of this communication model. \n\n"}
{"id": "1410.3542", "contents": "Title: Asymmetric Error Correction and Flash-Memory Rewriting using Polar Codes Abstract: We propose efficient coding schemes for two communication settings: 1.\nasymmetric channels, and 2. channels with an informed encoder. These settings\nare important in non-volatile memories, as well as optical and broadcast\ncommunication. The schemes are based on non-linear polar codes, and they build\non and improve recent work on these settings. In asymmetric channels, we tackle\nthe exponential storage requirement of previously known schemes, that resulted\nfrom the use of large Boolean functions. We propose an improved scheme, that\nachieves the capacity of asymmetric channels with polynomial computational\ncomplexity and storage requirement.\n  The proposed non-linear scheme is then generalized to the setting of channel\ncoding with an informed encoder, using a multicoding technique. We consider\nspecific instances of the scheme for flash memories, that incorporate\nerror-correction capabilities together with rewriting. Since the considered\ncodes are non-linear, they eliminate the requirement of previously known\nschemes (called polar write-once-memory codes) for shared randomness between\nthe encoder and the decoder. Finally, we mention that the multicoding scheme is\nalso useful for broadcast communication in Marton's region, improving upon\nprevious schemes for this setting. \n\n"}
{"id": "1410.5107", "contents": "Title: The DoF of the Asymmetric MIMO Interference Channel with Square Direct\n  Link Channel Matrices Abstract: This paper studies the sum Degrees of Freedom (DoF) of $K$-user {\\em\nasymmetric} MIMO Interference Channel (IC) with square direct link channel\nmatrices, that is, the $u$-th transmitter and its intended receiver have\n$M_u\\in\\mathbb{N}$ antennas each, where $M_u$ need not be the same for all\n$u\\in[1:K]$.\n  Starting from a $3$-user example, it is shown that existing cooperation-based\nouter bounds are insufficient to characterize the DoF. Moreover, it is shown\nthat two distinct operating regimes exist. With a {\\it dominant} user, i.e., a\nuser that has more antennas than the other two users combined, %(say $M_1\\geq\nM_2+M_3$), it is DoF optimal to let that user transmit alone on the IC.\nOtherwise, it is DoF optimal to {\\em decompose} and operate the 3-user MIMO IC\nas an $(M_1+ M_2+M_3)$-user SISO IC. This indicates that MIMO operations are\nuseless from a DoF perspective in systems without a dominant user.\n  The main contribution of the paper is the derivation of a novel outer bound\nfor the general $K$-user case that is tight in the regime where a dominant user\nis not present; this is done by generalizing the insights from the 3-user\nexample to an arbitrary number of users. \n\n"}
{"id": "1410.8349", "contents": "Title: Graph Guessing Games and non-Shannon Information Inequalities Abstract: Guessing games for directed graphs were introduced by Riis for studying\nmultiple unicast network coding problems. In a guessing game, the players toss\ngeneralised dice and can see some of the other outcomes depending on the\nstructure of an underlying digraph. They later guess simultaneously the outcome\nof their own die. Their objective is to find a strategy which maximises the\nprobability that they all guess correctly. The performance of the optimal\nstrategy for a graph is measured by the guessing number of the digraph.\n  Christofides and Markstr\\\"om studied guessing numbers of undirected graphs\nand defined a strategy which they conjectured to be optimal. One of the main\nresults of this paper is a disproof of this conjecture.\n  The main tool so far for computing guessing numbers of graphs is information\ntheoretic inequalities. In the paper we show that Shannon's information\ninequalities, which work particularly well for a wide range of graph classes,\nare not sufficient for computing the guessing number.\n  Finally we pose a few more interesting questions some of which we can answer\nand some which we leave as open problems. \n\n"}
{"id": "1410.8805", "contents": "Title: Correlated Source Coded Sequences with Compromised Channel and Source\n  Symbols using Shannon's Cipher System Abstract: Correlated sources are present in communication systems where protocols\nensure that there is some predetermined information for sources to transmit.\nHere, two correlated sources across a channel with eavesdroppers are\ninvestigated, and conditions for perfect secrecy when some channel information\nand some source data symbols (the predetermined information) have been\nwiretapped are determined. The adversary in this situation has access to more\ninformation than if a link is wiretapped only and can thus determine more about\na particular source. This scenario caters for an application where the\neavesdropper has access to some preexisting information. We provide bounds for\nthe channel and key rates for this scenario. Further, we provide a method to\nreduce the key lengths required for perfect secrecy. \n\n"}
{"id": "1411.0336", "contents": "Title: Uplink User-Assisted Relaying in Cellular Networks Abstract: We use stochastic geometry to analyze the performance of a partial\ndecode-and-forward (PDF) relaying scheme applied in a user-assisted relaying\nsetting, where an active user relays data through another idle user in uplink\ncellular communication. We present the geometric model of a network deploying\nuser-assisted relaying and propose two geometric cooperation policies for fast\nand slow fading channels. We analytically derive the cooperation probability\nfor both policies. This cooperation probability is further used in the\nanalytical derivation of the moments of inter-cell interference power caused by\nsystem-wide deployment of this user-assisted PDF relaying. We then model the\ninter-cell interference power statistics using the Gamma distribution by\nmatching the first two moments analytically derived. This cooperation and\ninterference analysis provides the theoretical basis for quantitatively\nevaluating the performance impact of user-assisted relaying in cellular\nnetworks. We then numerically evaluate the average transmission rate\nperformance and show that user-assisted relaying can significantly improve\nper-user transmission rate despite of increased inter-cell interference. This\ntransmission rate gain is significant for active users near the cell edge and\nfurther increases with higher idle user density, supporting user-assisted\nrelaying as a viable solution to crowded population areas. \n\n"}
{"id": "1411.0724", "contents": "Title: Bounds for complexity of syndrome decoding for poset metrics Abstract: In this work we show how to decompose a linear code relatively to any given\nposet metric. We prove that the complexity of syndrome decoding is determined\nby a maximal (primary) such decomposition and then show that a refinement of a\npartial order leads to a refinement of the primary decomposition. Using this\nand considering already known results about hierarchical posets, we can\nestablish upper and lower bounds for the complexity of syndrome decoding\nrelatively to a poset metric. \n\n"}
{"id": "1411.3061", "contents": "Title: Full-Duplex Wireless-Powered Relay with Self-Energy Recycling Abstract: This letter studies a wireless-powered amplify-and-forward relaying system,\nwhere an energy-constrained relay node assists the information transmission\nfrom the source to the destination using the energy harvested from the source.\nWe propose a novel two-phase protocol for efficient energy transfer and\ninformation relaying, in which the relay operates in full-duplex mode with\nsimultaneous energy harvesting and information transmission. Compared with the\nexisting protocols, the proposed design possesses two main advantages: i) it\nensures uninterrupted information transmission since no time switching or power\nsplitting is needed at the relay for energy harvesting; ii) it enables the\nso-called self-energy recycling, i.e., part of the energy (loop energy) that is\nused for information transmission by the relay can be harvested and reused in\naddition to the dedicated energy sent by the source. Under the multiple-input\nsingle-output (MISO) channel setup, the optimal power allocation and\nbeamforming design at the relay are derived. Numerical results show a\nsignificant throughput gain achieved by our proposed design over the existing\ntime switching-based relay protocol. \n\n"}
{"id": "1411.3857", "contents": "Title: Statistical physics of random binning Abstract: We consider the model of random binning and finite-temperature decoding for\nSlepian-Wolf codes, from a statistical-mechanical perspective. While ordinary\nrandom channel coding is intimately related to the random energy model (REM) -\na statistical-mechanical model of disordered magnetic materials, it turns out\nthat random binning (for Slepian-Wolf coding) is analogous to another, related\nstatistical mechanical model of strong disorder, which we call the random\ndilution model (RDM). We use the latter analogy to characterize phase\ntransitions pertaining to finite- temperature Slepian-Wolf decoding, which are\nsomewhat similar, but not identical, to those of finite-temperature channel\ndecoding. We then provide the exact random coding exponent of the bit error\nrate (BER) as a function of the coding rate and the decoding temperature, and\ndiscuss its properties. Finally, a few modifications and extensions of our\nresults are outlined and discussed. \n\n"}
{"id": "1411.4139", "contents": "Title: Cost-Aware Green Cellular Networks with Energy and Communication\n  Cooperation Abstract: Energy cost of cellular networks is ever-increasing to match the surge of\nwireless data traffic, and the saving of this cost is important to reduce the\noperational expenditure (OPEX) of wireless operators in future. The recent\nadvancements of renewable energy integration and two-way energy flow in smart\ngrid provide potential new solutions to save the cost. However, they also\nimpose challenges, especially on how to use the stochastically and spatially\ndistributed renewable energy harvested at cellular base stations (BSs) to\nreliably supply time- and space-varying wireless traffic over cellular\nnetworks. To overcome these challenges, in this article we present three\napproaches, namely, {\\emph{energy cooperation, communication cooperation, and\njoint energy and communication cooperation}}, in which different BSs\nbidirectionally trade or share energy via the aggregator in smart grid, and/or\nshare wireless resources and shift loads with each other to reduce the total\nenergy cost. \n\n"}
{"id": "1411.4182", "contents": "Title: Interference Reduction in Multi-Cell Massive MIMO Systems I: Large-Scale\n  Fading Precoding and Decoding Abstract: A wireless massive MIMO system entails a large number (tens or hundreds) of\nbase station antennas serving a much smaller number of users, with large gains\nin spectral-efficiency and energy-efficiency compared with conventional MIMO\ntechnology. Until recently it was believed that in multi-cellular massive MIMO\nsystem, even in the asymptotic regime, as the number of service antennas tends\nto infinity, the performance is limited by directed inter-cellular\ninterference. This interference results from unavoidable re-use of reverse-link\ntraining sequences (pilot contamination) by users in different cells.\n  We devise a new concept that leads to the effective elimination of inter-cell\ninterference in massive MIMO systems. This is achieved by outer multi-cellular\nprecoding, which we call Large-Scale Fading Precoding (LSFP). The main idea of\nLSFP is that each base station linearly combines messages aimed to users from\ndifferent cells that re-use the same training sequence. Crucially, the\ncombining coefficients depend only on the slow-fading coefficients between the\nusers and the base stations. Each base station independently transmits its\nLSFP-combined symbols using conventional linear precoding that is based on\nestimated fast-fading coefficients. Further, we derive estimates for downlink\nand uplink SINRs and capacity lower bounds for the case of massive MIMO systems\nwith LSFP and a finite number of base station antennas. \n\n"}
{"id": "1411.4591", "contents": "Title: Number field lattices achieve Gaussian and Rayleigh channel capacity\n  within a constant gap Abstract: This paper proves that a family of number field lattice codes simultaneously\nachieves a constant gap to capacity in Rayleigh fast fading and Gaussian\nchannels.\n  The key property in the proof is the existence of infinite towers of Hilbert\nclass fields with bounded root discriminant. The gap to capacity of the\nproposed families is determined by the root discriminant.\n  The comparison between the Gaussian and fading case reveals that in Rayleigh\nfading channels the normalized minimum product distance plays an analogous role\nto the Hermite invariant in Gaussian channels. \n\n"}
{"id": "1411.5187", "contents": "Title: Statistical Recovery of Simultaneously Sparse Time-Varying Signals from\n  Multiple Measurement Vectors Abstract: In this paper, we propose a new sparse signal recovery algorithm, referred to\nas sparse Kalman tree search (sKTS), that provides a robust reconstruction of\nthe sparse vector when the sequence of correlated observation vectors are\navailable. The proposed sKTS algorithm builds on expectation-maximization (EM)\nalgorithm and consists of two main operations: 1) Kalman smoothing to obtain\nthe a posteriori statistics of the source signal vectors and 2) greedy tree\nsearch to estimate the support of the signal vectors. Through numerical\nexperiments, we demonstrate that the proposed sKTS algorithm is effective in\nrecovering the sparse signals and performs close to the Oracle (genie-based)\nKalman estimator. \n\n"}
{"id": "1411.6792", "contents": "Title: Conditional probability calculations for the nonlinear Schr\\\"odinger\n  equation with additive noise Abstract: The method for computation of conditional probability density function for\nthe nonlinear Schr\\\"odinger equation with additive noise is developed. We\npresent in a constructive form the conditional probability density function in\nthe limit of a small noise and analytically derive it in a weakly nonlinear\ncase. The general theory results are illustrated using fibre-optic\ncommunications as a particular, albeit practically very important, example. \n\n"}
{"id": "1412.0823", "contents": "Title: Topological Interference Management with Transmitter Cooperation Abstract: Interference networks with no channel state information at the transmitter\n(CSIT) except for the knowledge of the connectivity graph have been recently\nstudied under the topological interference management (TIM) framework. In this\npaper, we consider a similar problem with topological knowledge but in a\ndistributed broadcast channel setting, i.e. a network where transmitter\ncooperation is enabled. We show that the topological information can also be\nexploited in this case to strictly improve the degrees of freedom (DoF) as long\nas the network is not fully connected, which is a reasonable assumption in\npractice. Achievability schemes based on selective graph coloring, interference\nalignment, and hypergraph covering, are proposed. Together with outer bounds\nbuilt upon generator sequence, the concept of compound channel settings, and\nthe relation to index coding, we characterize the symmetric DoF for so-called\nregular networks with constant number of interfering links, and identify the\nsufficient and/or necessary conditions for the arbitrary network topologies to\nachieve a certain amount of symmetric DoF. \n\n"}
{"id": "1412.1257", "contents": "Title: Fast-Decodable Space-Time Codes for the $N$-Relay and Multiple-Access\n  MIMO Channel Abstract: In this article, the first general constructions of fast-decodable, more\nspecifically (conditionally) $g$-group decodable, space-time block codes for\nthe Nonorthogonal Amplify and Forward (NAF) Multiple-Input Multiple-Output\n(MIMO) relay channel under the half-duplex constraint are proposed. In this\nscenario, the source and the intermediate relays used for data amplification\nare allowed to employ multiple antennas for data transmission and reception.\nThe worst-case decoding complexity of the obtained codes is reduced by up to\n$75%$. In addition to being fast-decodable, the proposed codes achieve\nfull-diversity and have nonvanishing determinants, which has been shown to be\nuseful for achieving the optimal Diversity-Multiplexing Tradeoff (DMT) of the\nNAF channel.\n  Further, it is shown that the same techniques as in the cooperative scenario\ncan be utilized to achieve fast-decodability for $K$-user MIMO Multiple-Access\nChannel (MAC) space-time block codes. The resulting codes in addition exhibit\nthe conditional nonvanishing determinant property which, for its part, has been\nshown to be useful for achieving the optimal MAC-DMT. \n\n"}
{"id": "1412.1723", "contents": "Title: Communication complexity and the reality of the wave-function Abstract: In this review, we discuss a relation between quantum communication\ncomplexity and a long-standing debate in quantum foundation concerning the\ninterpretation of the quantum state. Is the quantum state a physical element of\nreality as originally interpreted by Schrodinger? Or is it an abstract\nmathematical object containing statistical information about the outcome of\nmeasurements as interpreted by Born? Although these questions sound\nphilosophical and pointless, they can be made precise in the framework of what\nwe call classical theories of quantum processes, which are a reword of quantum\nphenomena in the language of classical probability theory. In 2012, Pusey,\nBarrett and Rudolph (PBR) proved, under an assumption of preparation\nindependence, a theorem supporting the original interpretation of Schrodinger\nin the classical framework. Recently, we showed that these questions are\nrelated to a practical problem in quantum communication complexity, namely,\nquantifying the minimal amount of classical communication required in the\nclassical simulation of a two-party quantum communication process. In\nparticular, we argued that the statement of the PBR theorem can be proved if\nthe classical communication cost of simulating the communication of n qubits\ngrows more than exponentially in 'n'. Our argument is based on an assumption\nthat we call probability equipartition property. This property is somehow\nweaker than the preparation independence property used in the PBR theorem, as\nthe former can be justified by the latter and the asymptotic equipartition\nproperty of independent stochastic sources. The equipartition property is a\ngeneral and natural hypothesis that can be assumed even if the preparation\nindependence hypothesis is dropped. In this review, we further develop our\nargument into the form of a theorem. \n\n"}
{"id": "1412.2192", "contents": "Title: Optimal algorithms for universal random number generation from finite\n  memory sources Abstract: We study random number generators (RNGs), both in the fixed to\nvariable-length (FVR) and the variable to fixed-length (VFR) regimes, in a\nuniversal setting in which the input is a finite memory source of arbitrary\norder and unknown parameters, with arbitrary input and output (finite) alphabet\nsizes. Applying the method of types, we characterize essentially unique optimal\nuniversal RNGs that maximize the expected output (respectively, minimize the\nexpected input) length in the FVR (respectively, VFR) case. For the FVR case,\nthe RNG studied is a generalization of Elias's scheme, while in the VFR case\nthe general scheme is new. We precisely characterize, up to an additive\nconstant, the corresponding expected lengths, which include second-order terms\nsimilar to those encountered in universal data compression and universal\nsimulation. Furthermore, in the FVR case, we consider also a \"twice-universal\"\nsetting, in which the Markov order k of the input source is also unknown. \n\n"}
{"id": "1412.3284", "contents": "Title: Exact recovery of Dirac ensembles from the projection onto spaces of\n  spherical harmonics Abstract: In this work we consider the problem of recovering an ensemble of Diracs on\nthe sphere from its projection onto spaces of spherical harmonics. We show that\nunder an appropriate separation condition on the unknown locations of the\nDiracs, the ensemble can be recovered through Total Variation norm\nminimization. The proof of the uniqueness of the solution uses the method of\n`dual' interpolating polynomials and is based on [8], where the theory was\ndeveloped for trigonometric polynomials. We also show that in the special case\nof non-negative ensembles, a sparsity condition is sufficient for exact\nrecovery. \n\n"}
{"id": "1412.5240", "contents": "Title: Minimization of Transformed $L_1$ Penalty: Closed Form Representation\n  and Iterative Thresholding Algorithms Abstract: The transformed $l_1$ penalty (TL1) functions are a one parameter family of\nbilinear transformations composed with the absolute value function. When acting\non vectors, the TL1 penalty interpolates $l_0$ and $l_1$ similar to $l_p$ norm\n($p \\in (0,1)$). In our companion paper, we showed that TL1 is a robust\nsparsity promoting penalty in compressed sensing (CS) problems for a broad\nrange of incoherent and coherent sensing matrices. Here we develop an explicit\nfixed point representation for the TL1 regularized minimization problem. The\nTL1 thresholding functions are in closed form for all parameter values. In\ncontrast, the $l_p$ thresholding functions ($p \\in [0,1]$) are in closed form\nonly for $p=0,1,1/2,2/3$, known as hard, soft, half, and 2/3 thresholding\nrespectively. The TL1 threshold values differ in subcritical (supercritical)\nparameter regime where the TL1 threshold functions are continuous\n(discontinuous) similar to soft-thresholding (half-thresholding) functions. We\npropose TL1 iterative thresholding algorithms and compare them with hard and\nhalf thresholding algorithms in CS test problems. For both incoherent and\ncoherent sensing matrices, a proposed TL1 iterative thresholding algorithm with\nadaptive subcritical and supercritical thresholds consistently performs the\nbest in sparse signal recovery with and without measurement noise. \n\n"}
{"id": "1412.6058", "contents": "Title: A Distributed, Asynchronous and Incremental Algorithm for Nonconvex\n  Optimization: An ADMM Based Approach Abstract: The alternating direction method of multipliers (ADMM) has been popular for\nsolving many signal processing problems, convex or nonconvex. In this paper, we\nstudy an asynchronous implementation of the ADMM for solving a nonconvex\nnonsmooth optimization problem, whose objective is the sum of a number of\ncomponent functions. The proposed algorithm allows the problem to be solved in\na distributed, asynchronous and incremental manner. First, the component\nfunctions can be distributed to different computing nodes, who perform the\nupdates asynchronously without coordinating with each other. Two sources of\nasynchrony are covered by our algorithm: one is caused by the heterogeneity of\nthe computational nodes, and the other arises from unreliable communication\nlinks. Second, the algorithm can be viewed as implementing an incremental\nalgorithm where at each step the (possibly delayed) gradients of only a subset\nof component functions are update d. We show that when certain bounds are put\non the level of asynchrony, the proposed algorithm converges to the set of\nstationary solutions (resp. optimal solutions) for the nonconvex (resp. convex)\nproblem. To the best of our knowledge, the proposed ADMM implementation can\ntolerate the highest degree of asynchrony, among all known asynchronous\nvariants of the ADMM. Moreover, it is the first ADMM implementation that can\ndeal with nonconvexity and asynchrony at the same time. \n\n"}
{"id": "1412.7188", "contents": "Title: Layered Interference Alignment: Achieving the Total DoF of MIMO X\n  Channels Abstract: The $K\\times 2$ and $2\\times K$, Multiple-Input Multiple-Output (MIMO) X\nchannel with constant channel coefficients available at all transmitters and\nreceivers is considered. A new alignment scheme, named \\emph{layered\ninterference alignment}, is proposed in which both vector and real interference\nalignment are exploited, in conjunction with joint processing at receiver\nsides. Data streams with fractional multiplexing gains are sent in the desired\ndirections to align the interfering signals at receivers. To decode the\nintended messages at receivers, a joint processing/simultaneous decoding\ntechnique, which exploits the availability of several receive antennas, is\nproposed. This analysis is subsequently backed up by metrical results for\nsystems of linear forms. In particular, for such linear forms,\nKhintchine--Groshev type theorems are proved over real and complex numbers. It\nis observed that $K\\times 2$ and $2\\times K$, X channels with $M$ antennas at\nall transmitters/receivers enjoy duality in Degrees of Freedom (DoF). It is\nshown that incorporating the layered interference alignment is essential to\ncharacterize the total DoF of $\\frac{2KM}{K+1}$ in the $K\\times 2$ and $2\\times\nK$, $M$ antenna X channels. \n\n"}
{"id": "1501.01019", "contents": "Title: Protocol for making a $2$-qutrit entangling gate in the Kauffman-Jones\n  version of $SU(2)_4$ Abstract: The following paper provides a protocol to physically generate a $2$-qutrit\nentangling gate in the Kauffman-Jones version of $SU(2)$ Chern-Simons theory at\nlevel $4$. The protocol uses elementary operations on anyons consisting of\nbraids, interferometric measurements, fusions and unfusions and ancilla pair\ncreation. \n\n"}
{"id": "1501.02377", "contents": "Title: Fast Phase Retrieval from Local Correlation Measurements Abstract: We develop a fast phase retrieval method which can utilize a large class of\nlocal phaseless correlation-based measurements in order to recover a given\nsignal ${\\bf x} \\in \\mathbb{C}^d$ (up to an unknown global phase) in\nnear-linear $\\mathcal{O} \\left( d \\log^4 d \\right)$-time. Accompanying\ntheoretical analysis proves that the proposed algorithm is guaranteed to\ndeterministically recover all signals ${\\bf x}$ satisfying a natural flatness\n(i.e., non-sparsity) condition for a particular choice of deterministic\ncorrelation-based measurements. A randomized version of these same measurements\nis then shown to provide nonuniform probabilistic recovery guarantees for\narbitrary signals ${\\bf x} \\in \\mathbb{C}^d$. Numerical experiments demonstrate\nthe method's speed, accuracy, and robustness in practice -- all code is made\npublicly available.\n  Finally, we conclude by developing an extension of the proposed method to the\nsparse phase retrieval problem; specifically, we demonstrate a sublinear-time\ncompressive phase retrieval algorithm which is guaranteed to recover a given\n$s$-sparse vector ${\\bf x} \\in \\mathbb{C}^d$ with high probability in just\n$\\mathcal{O}(s \\log^5 s \\cdot \\log d)$-time using only $\\mathcal{O}(s \\log^4 s\n\\cdot \\log d)$ magnitude measurements. In doing so we demonstrate the existence\nof compressive phase retrieval algorithms with near-optimal linear-in-sparsity\nruntime complexities. \n\n"}
{"id": "1501.02428", "contents": "Title: Dynamic Weighted Bit-Flipping Decoding Algorithms for LDPC Codes Abstract: Bit-flipping (BF) decoding of low-density parity-check codes is of low\ncomplexity but gives inferior performance in general. To improve performance\nand provide new BF decoder options for complexity-performance tradeoffs, we\npropose new designs for the flipping function (FF), the flipped bit selection\n(FBS) rule and the checksum weight updating schedule. The new FF adjusts the\nchecksum weights in every iteration while our FBS rules take more information\ninto account. These two modifications represent efforts to track more closely\nthe evolutions of both check and variable nodes' reliabilities. Two selective\nupdate schedules are proposed to offer more performance and complexity\ntradeoffs.\n  The combinations of the new FBS rule and known FFs result in new BF decoders\nwith improved performance and a modest complexity increase. On the other hand,\ncombining the new FF and FBS rule gives a new decoder with performance\ncomparable to that of the normalized min-sum algorithm while if we use a much\nsimpler FBS rule instead, the decoder suffers little performance loss with\nreduced complexity. We also present a simple decision-theoretical argument to\njustify the new checksum weight formula and a time-expanded factor graph model\nto explain the proposed selective weight-updating schedules. \n\n"}
{"id": "1501.04183", "contents": "Title: Holographic Transformation, Belief Propagation and Loop Calculus for\n  Generalized Probabilistic Theories Abstract: The holographic transformation, belief propagation and loop calculus are\ngeneralized to problems in generalized probabilistic theories including quantum\nmechanics. In this work, the partition function of classical factor graph is\nrepresented by an inner product of two high-dimensional vectors both of which\ncan be decomposed to tensor products of low-dimensional vectors. On the\nrepresentation, the holographic transformation is clearly understood by using\nadjoint linear maps. Furthermore, on the formulation using inner product, the\nbelief propagation is naturally defined from the derivation of the loop\ncalculus formula. As a consequence, the holographic transformation, the belief\npropagation and the loop calculus are generalized to measurement problems in\nquantum mechanics and generalized probabilistic theories. \n\n"}
{"id": "1501.04705", "contents": "Title: Symbol-Decision Successive Cancellation List Decoder for Polar Codes Abstract: Polar codes are of great interests because they provably achieve the capacity\nof both discrete and continuous memoryless channels while having an explicit\nconstruction. Most existing decoding algorithms of polar codes are based on\nbit-wise hard or soft decisions. In this paper, we propose symbol-decision\nsuccessive cancellation (SC) and successive cancellation list (SCL) decoders\nfor polar codes, which use symbol-wise hard or soft decisions for higher\nthroughput or better error performance. First, we propose to use a recursive\nchannel combination to calculate symbol-wise channel transition probabilities,\nwhich lead to symbol decisions. Our proposed recursive channel combination also\nhas a lower complexity than simply combining bit-wise channel transition\nprobabilities. The similarity between our proposed method and Arikan's channel\ntransformations also helps to share hardware resources between calculating bit-\nand symbol-wise channel transition probabilities. Second, a two-stage list\npruning network is proposed to provide a trade-off between the error\nperformance and the complexity of the symbol-decision SCL decoder. Third, since\nmemory is a significant part of SCL decoders, we propose a pre-computation\nmemory-saving technique to reduce memory requirement of an SCL decoder.\nFinally, to evaluate the throughput advantage of our symbol-decision decoders,\nwe design an architecture based on a semi-parallel successive cancellation list\ndecoder. In this architecture, different symbol sizes, sorting implementations,\nand message scheduling schemes are considered. Our synthesis results show that\nin terms of area efficiency, our symbol-decision SCL decoders outperform both\nbit- and symbol-decision SCL decoders. \n\n"}
{"id": "1501.04817", "contents": "Title: Support Recovery with Orthogonal Matching Pursuit in the Presence of\n  Noise: A New Analysis Abstract: Support recovery of sparse signals from compressed linear measurements is a\nfundamental problem in compressed sensing (CS). In this paper, we study the\northogonal matching pursuit (OMP) algorithm for the recovery of support under\nnoise. We consider two signal-to-noise ratio (SNR) settings: i) the SNR depends\non the sparsity level $K$ of input signals, and ii) the SNR is an absolute\nconstant independent of $K$. For the first setting, we establish necessary and\nsufficient conditions for the exact support recovery with OMP, expressed as\nlower bounds on the SNR. Our results indicate that in order to ensure the exact\nsupport recovery of all $K$-sparse signals with the OMP algorithm, the SNR must\nat least scale linearly with the sparsity level $K$. In the second setting,\nsince the necessary condition on the SNR is not fulfilled, the exact support\nrecovery with OMP is impossible. However, our analysis shows that recovery with\nan arbitrarily small but constant fraction of errors is possible with the OMP\nalgorithm. This result may be useful for some practical applications where\nobtaining some large fraction of support positions is adequate. \n\n"}
{"id": "1501.05371", "contents": "Title: Multistatic Cloud Radar Systems: Joint Sensing and Communication Design Abstract: In a multistatic cloud radar system, receive sensors measure signals sent by\na transmit element and reflected from a target and possibly clutter, in the\npresence of interference and noise. The receive sensors communicate over\nnon-ideal backhaul links with a fusion center, or cloud processor, where the\npresence or absence of the target is determined. The backhaul architecture can\nbe characterized either by an orthogonal-access channel or by a non-orthogonal\nmultiple-access channel. Two backhaul transmission strategies are considered,\nnamely compress-and-forward (CF), which is well suited for the\northogonal-access backhaul, and amplify-and-forward (AF), which leverages the\nsuperposition property of the non-orthogonal multiple-access channel. In this\npaper, the joint optimization of the sensing and backhaul communication\nfunctions of the cloud radar system is studied. Specifically, the transmitted\nwaveform is jointly optimized with backhaul quantization in the case of CF\nbackhaul transmission and with the amplifying gains of the sensors for the AF\nbackhaul strategy. In both cases, the information-theoretic criterion of the\nBhattacharyya distance is adopted as a metric for the detection performance.\nAlgorithmic solutions based on successive convex approximation are developed\nunder different assumptions on the available channel state information (CSI).\nNumerical results demonstrate that the proposed schemes outperform conventional\nsolutions that perform separate optimizations of the waveform and backhaul\noperation, as well as the standard distributed detection approach. \n\n"}
{"id": "1501.05683", "contents": "Title: Polar Lattices for Lossy Compression Abstract: Polar lattices, which are constructed from polar codes, have recently been\nproved to be able to achieve the capacity of the additive white Gaussian noise\n(AWGN) channel. In this work, we propose a new construction of polar lattices\nto solve the dual problem, i.e., achieving the rate-distortion bound of a\nmemoryless Gaussian source, which means that polar lattices can also be good\nfor the lossy compression of continuous sources. The structure of the proposed\npolar lattices enables us to integrate the post-entropy coding process into the\nlattice quantizer, which simplifies the quantization process. The overall\ncomplexity of encoding and decoding complexity is $O(N \\log^2 N)$ for a\nsub-exponentially decaying excess distortion. Moreover, the nesting structure\nof polar lattices further provides solutions for some multi-terminal coding\nproblems. The Wyner-Ziv coding problem for a Gaussian source can be solved by\nan AWGN capacity-achieving polar lattice nested in a rate-distortion bound\nachieving one, and the Gelfand-Pinsker problem can be solved in a reversed\nmanner. \n\n"}
{"id": "1501.05978", "contents": "Title: Linear independence of rank 1 matrices and the dimension of *-products\n  of codes Abstract: We show that with high probability, random rank 1 matrices over a finite\nfield are in (linearly) general position, at least provided their shape k x l\nis not excessively unbalanced. This translates into saying that the dimension\nof the *-product of two [n, k] and [n, l] random codes is equal to min(n, kl),\nas one would have expected. Our work is inspired by a similar result of\nCascudo-Cramer-Mirandola-Zemor dealing with *-squares of codes, which it\ncomplements, especially regarding applications to the analysis of McEliece-type\ncryptosystems. We also briefly mention the case of higher *-powers, which\nrequire to take the Frobenius into account. We then conclude with some open\nproblems. \n\n"}
{"id": "1501.06026", "contents": "Title: Energy Harvesting Wireless Communications: A Review of Recent Advances Abstract: This article summarizes recent contributions in the broad area of energy\nharvesting wireless communications. In particular, we provide the current state\nof the art for wireless networks composed of energy harvesting nodes, starting\nfrom the information-theoretic performance limits to transmission scheduling\npolicies and resource allocation, medium access and networking issues. The\nemerging related area of energy transfer for self-sustaining energy harvesting\nwireless networks is considered in detail covering both energy cooperation\naspects and simultaneous energy and information transfer. Various potential\nmodels with energy harvesting nodes at different network scales are reviewed as\nwell as models for energy consumption at the nodes. \n\n"}
{"id": "1501.06216", "contents": "Title: S-AMP for Non-linear Observation Models Abstract: Recently we extended Approximate message passing (AMP) algorithm to be able\nto handle general invariant matrix ensembles. In this contribution we extend\nour S-AMP approach to non-linear observation models. We obtain generalized AMP\n(GAMP) algorithm as the special case when the measurement matrix has zero-mean\niid Gaussian entries. Our derivation is based upon 1) deriving expectation\npropagation (EP) like algorithms from the stationary-points equations of the\nGibbs free energy under first- and second-moment constraints and 2) applying\nadditive free convolution in free probability theory to get low-complexity\nupdates for the second moment quantities. \n\n"}
{"id": "1501.06521", "contents": "Title: Noisy Tensor Completion via the Sum-of-Squares Hierarchy Abstract: In the noisy tensor completion problem we observe $m$ entries (whose location\nis chosen uniformly at random) from an unknown $n_1 \\times n_2 \\times n_3$\ntensor $T$. We assume that $T$ is entry-wise close to being rank $r$. Our goal\nis to fill in its missing entries using as few observations as possible. Let $n\n= \\max(n_1, n_2, n_3)$. We show that if $m = n^{3/2} r$ then there is a\npolynomial time algorithm based on the sixth level of the sum-of-squares\nhierarchy for completing it. Our estimate agrees with almost all of $T$'s\nentries almost exactly and works even when our observations are corrupted by\nnoise. This is also the first algorithm for tensor completion that works in the\novercomplete case when $r > n$, and in fact it works all the way up to $r =\nn^{3/2-\\epsilon}$.\n  Our proofs are short and simple and are based on establishing a new\nconnection between noisy tensor completion (through the language of Rademacher\ncomplexity) and the task of refuting random constant satisfaction problems.\nThis connection seems to have gone unnoticed even in the context of matrix\ncompletion. Furthermore, we use this connection to show matching lower bounds.\nOur main technical result is in characterizing the Rademacher complexity of the\nsequence of norms that arise in the sum-of-squares relaxations to the tensor\nnuclear norm. These results point to an interesting new direction: Can we\nexplore computational vs. sample complexity tradeoffs through the\nsum-of-squares hierarchy? \n\n"}
{"id": "1501.07439", "contents": "Title: The Arbitrarily Varying Wiretap Channel - Secret Randomness, Stability\n  and Super-Activation Abstract: We define the common randomness assisted capacity of an arbitrarily varying\nchannel (AVWC) when the Eavesdropper is kept ignorant about the common\nrandomness. We prove a multi-letter capacity formula for this model. We prove\nthat, if enough common randomness is used, the capacity formula can be given a\nsingle-shot form again. We then consider the opposite extremal case, where no\ncommon randomness is available. It is known that the capacity of the system can\nbe discontinuous under these circumstances. We prove here that it is still\nstable in the sense that it is continuous around its positivity points. We\nfurther prove that discontinuities can only arise if the legal link is\nsymmetrizable and characterize the points where it is positive. These results\nshed new light on the design principles of communication systems with embedded\nsecurity features. At last we investigate the effect of super-activation of the\nmessage transmission capacity of AVWCs under the average error criterion. We\ngive a complete characterization of those AVWCs that may be super-activated.\nThe effect is thereby also related to the (conjectured) super-activation of the\ncommon randomness assisted capacity of AVWCs with an eavesdropper that gets to\nknow the common randomness. Super-activation is based on the idea of \"wasting\"\na few bits of non-secret messages in order to enable provably secret\ntransmission of a large bulk of data, a concept that may prove to be of further\nimportance in the design of communication systems. In this work we provide\nfurther insight into this phenomenon by providing a class of codes that is\ncapacity-achieving and does not convey any information to the Eavesdropper. \n\n"}
{"id": "1501.07440", "contents": "Title: Limits on Support Recovery with Probabilistic Models: An\n  Information-Theoretic Framework Abstract: The support recovery problem consists of determining a sparse subset of a set\nof variables that is relevant in generating a set of observations, and arises\nin a diverse range of settings such as compressive sensing, and subset\nselection in regression, and group testing. In this paper, we take a unified\napproach to support recovery problems, considering general probabilistic models\nrelating a sparse data vector to an observation vector. We study the\ninformation-theoretic limits of both exact and partial support recovery, taking\na novel approach motivated by thresholding techniques in channel coding. We\nprovide general achievability and converse bounds characterizing the trade-off\nbetween the error probability and number of measurements, and we specialize\nthese to the linear, 1-bit, and group testing models. In several cases, our\nbounds not only provide matching scaling laws in the necessary and sufficient\nnumber of measurements, but also sharp thresholds with matching constant\nfactors. Our approach has several advantages over previous approaches: For the\nachievability part, we obtain sharp thresholds under broader scalings of the\nsparsity level and other parameters (e.g., signal-to-noise ratio) compared to\nseveral previous works, and for the converse part, we not only provide\nconditions under which the error probability fails to vanish, but also\nconditions under which it tends to one. \n\n"}
{"id": "1502.00348", "contents": "Title: A Novel Statistical Channel Model for Turbulence-Induced Fading in\n  Free-Space Optical Systems Abstract: In this paper, we propose a new probability distribution function which\naccurately describes turbulence-induced fading under a wide range of turbulence\nconditions. The proposed model, termed Double Generalized Gamma (Double GG), is\nbased on a doubly stochastic theory of scintillation and developed via the\nproduct of two Generalized Gamma (GG) distributions. The proposed Double GG\ndistribution generalizes many existing turbulence channel models and provides\nan excellent fit to the published plane and spherical waves simulation data.\nUsing this new statistical channel model, we derive closed form expressions for\nthe outage probability and the average bit error as well as corresponding\nasymptotic expressions of free-space optical communication systems over\nturbulence channels. We demonstrate that our derived expressions cover many\nexisting results in the literature earlier reported for Gamma-Gamma,\nDouble-Weibull and K channels as special cases. \n\n"}
{"id": "1502.00536", "contents": "Title: Quantum Tomography Protocols with Positivity are Compressed Sensing\n  Protocols Abstract: Characterizing complex quantum systems is a vital task in quantum information\nscience. Quantum tomography, the standard tool used for this purpose, uses a\nwell-designed measurement record to reconstruct quantum states and processes.\nIt is, however, notoriously inefficient. Recently, the classical signal\nreconstruction technique known as \"compressed sensing\" has been ported to\nquantum information science to overcome this challenge: accurate tomography can\nbe achieved with substantially fewer measurement settings, thereby greatly\nenhancing the efficiency of quantum tomography. Here we show that compressed\nsensing tomography of quantum systems is essentially guaranteed by a special\nproperty of quantum mechanics itself---that the mathematical objects that\ndescribe the system in quantum mechanics are matrices with nonnegative\neigenvalues. This result has an impact on the way quantum tomography is\nunderstood and implemented. In particular, it implies that the information\nobtained about a quantum system through compressed sensing methods exhibits a\nnew sense of \"informational completeness.\" This has important consequences on\nthe efficiency of data taking for quantum tomography, and enables us to\nconstruct informationally complete measurements that are robust to noise and\nmodeling errors. Moreover, our result shows that one can expand the numerical\ntool-box used in quantum tomography and employ highly efficient algorithms\ndeveloped to handle large dimensional matrices on a large dimensional Hilbert\nspace. While we mainly present our results in the context of quantum\ntomography, they apply to the general case of positive semidefinite matrix\nrecovery. \n\n"}
{"id": "1502.01885", "contents": "Title: Linearized Reed-Solomon codes and linearized Wenger graphs Abstract: A codeword is associated to a linearized polynomial. The weight distribution\nof the codewords is determined as the linearized polynomial varies in a family\nof fixed degree. There is a corresponding result on Wenger graphs from\nlinearized polynomials. \n\n"}
{"id": "1502.05516", "contents": "Title: Outage Capacity of Rayleigh Product Channels: a Free Probability\n  Approach Abstract: The Rayleigh product channel model is useful in capturing the performance\ndegradation due to rank deficiency of MIMO channels. In this paper, such a\nperformance degradation is investigated via the channel outage probability\nassuming slowly varying channel with delay-constrained decoding. Using\ntechniques of free probability theory, the asymptotic variance of channel\ncapacity is derived when the dimensions of the channel matrices approach\ninfinity. In this asymptotic regime, the channel capacity is rigorously proven\nto be Gaussian distributed. Using the obtained results, a fundamental tradeoff\nbetween multiplexing gain and diversity gain of Rayleigh product channels can\nbe characterized by closed-form expression at any finite signal-to-noise ratio.\nNumerical results are provided to compare the relative outage performance\nbetween Rayleigh product channels and conventional Rayleigh MIMO channels. \n\n"}
{"id": "1502.05773", "contents": "Title: Multipartite Monotones for Secure Sampling by Public Discussion From\n  Noisy Correlations Abstract: We address the problem of quantifying the cryptographic content of\nprobability distributions, in relation to an application to secure multi-party\nsampling against a passive t-adversary. We generalize a recently introduced\nnotion of assisted common information of a pair of correlated sources to that\nof K sources and define a family of monotone rate regions indexed by K. This\nallows for a simple characterization of all t-private distributions that can be\nstatistically securely sampled without any auxiliary setup of pre-shared noisy\ncorrelations. We also give a new monotone called the residual total correlation\nthat admits a simple operational interpretation. Interestingly, for sampling\nwith non-trivial setups (K > 2) in the public discussion model, our definition\nof a monotone region differs from the one by Prabhakaran and Prabhakaran (ITW\n2012). \n\n"}
{"id": "1502.05789", "contents": "Title: Location Identification of Power Line Outages Using PMU Measurements\n  with Bad Data Abstract: The use of phasor angle measurements provided by phasor measurement units\n(PMUs) in fault detection is regarded as a promising method in identifying\nlocations of power line outages. However, communication errors or system\nmalfunctions may introduce errors to the measurements and thus yield bad data.\nMost of the existing methods on line outage identification fail to consider\nsuch error. This paper develops a framework for identifying multiple power line\noutages based on the PMUs' measurements in the presence of bad data. In\nparticular, we design an algorithm to identify locations of line outage and\nrecover the faulty measurements simultaneously. The proposed algorithm does not\nrequire any prior information on the number of line outages and the noise\nvariance. Case studies carried out on test systems of different sizes validate\nthe effectiveness and efficiency of the proposed approach. \n\n"}
{"id": "1502.06945", "contents": "Title: New extremal binary self-dual codes of lengths 66 and 68 from codes over\n  r_k,m Abstract: In this work, four circulant and quadratic double circulant (QDC)\nconstructions are applied to the family of the rings R_k,m. Self-dual binary\ncodes are obtained as the Gray images of self-dual QDC codes over R_k,m.\nExtremal binary self-dual codes of length 64 are obtained as Gray images of\n?-four circulant codes over R_2,1 and R_2,2. Extremal binary self-dual codes of\nlengths 66 and 68 are constructed by applying extension theorems to the F_2 and\nR_2,1 images of these codes. More precisely, 11 new codes of length 66 and 39\nnew codes of length 68 are discovered. The codes with these weight enumerators\nare constructed for the first time in literature. The results are tabulated. \n\n"}
{"id": "1503.00338", "contents": "Title: Phase Transitions in Sparse PCA Abstract: We study optimal estimation for sparse principal component analysis when the\nnumber of non-zero elements is small but on the same order as the dimension of\nthe data. We employ approximate message passing (AMP) algorithm and its state\nevolution to analyze what is the information theoretically minimal mean-squared\nerror and the one achieved by AMP in the limit of large sizes. For a special\ncase of rank one and large enough density of non-zeros Deshpande and Montanari\n[1] proved that AMP is asymptotically optimal. We show that both for low\ndensity and for large rank the problem undergoes a series of phase transitions\nsuggesting existence of a region of parameters where estimation is information\ntheoretically possible, but AMP (and presumably every other polynomial\nalgorithm) fails. The analysis of the large rank limit is particularly\ninstructive. \n\n"}
{"id": "1503.03231", "contents": "Title: Adaptive-Rate Sparse Signal Reconstruction With Application in\n  Compressive Background Subtraction Abstract: We propose and analyze an online algorithm for reconstructing a sequence of\nsignals from a limited number of linear measurements. The signals are assumed\nsparse, with unknown support, and evolve over time according to a generic\nnonlinear dynamical model. Our algorithm, based on recent theoretical results\nfor $\\ell_1$-$\\ell_1$ minimization, is recursive and computes the number of\nmeasurements to be taken at each time on-the-fly. As an example, we apply the\nalgorithm to compressive video background subtraction, a problem that can be\nstated as follows: given a set of measurements of a sequence of images with a\nstatic background, simultaneously reconstruct each image while separating its\nforeground from the background. The performance of our method is illustrated on\nsequences of real images: we observe that it allows a dramatic reduction in the\nnumber of measurements with respect to state-of-the-art compressive background\nsubtraction schemes. \n\n"}
{"id": "1503.04360", "contents": "Title: Quadratic Multi-Dimensional Signaling Games and Affine Equilibria Abstract: This paper studies the decentralized quadratic cheap talk and signaling game\nproblems when an encoder and a decoder, viewed as two decision makers, have\nmisaligned objective functions. The main contributions of this study are the\nextension of Crawford and Sobel's cheap talk formulation to multi-dimensional\nsources and to noisy channel setups. We consider both (simultaneous) Nash\nequilibria and (sequential) Stackelberg equilibria. We show that for arbitrary\nscalar sources, in the presence of misalignment, the quantized nature of all\nequilibrium policies holds for Nash equilibria in the sense that all Nash\nequilibria are equivalent to those achieved by quantized encoder policies. On\nthe other hand, all Stackelberg equilibria policies are fully informative. For\nmulti-dimensional setups, unlike the scalar case, Nash equilibrium policies may\nbe of non-quantized nature, and even linear. In the noisy setup, a Gaussian\nsource is to be transmitted over an additive Gaussian channel. The goals of the\nencoder and the decoder are misaligned by a bias term and encoder's cost also\nincludes a penalty term on signal power. Conditions for the existence of affine\nNash equilibria as well as general informative equilibria are presented. For\nthe noisy setup, the only Stackelberg equilibrium is the linear equilibrium\nwhen the variables are scalar. Our findings provide further conditions on when\naffine policies may be optimal in decentralized multi-criteria control problems\nand lead to conditions for the presence of active information transmission in\nstrategic environments. \n\n"}
{"id": "1503.06381", "contents": "Title: Balancing Communication for Multi-party Interactive Coding Abstract: We consider interactive coding in a setting where $n$ parties wish to compute\na joint function of their inputs via an interactive protocol over imperfect\nchannels. We assume that adversarial errors can comprise a\n$\\mathcal{O}(\\frac{1}{n})$ fraction of the total communication, occurring\nanywhere on the communication network. Our goal is to maintain a constant\nmultiplicative overhead in the total communication required, as compared to the\nerror-free setting, and also to balance the workload over the different\nparties. We build upon the prior protocol of Jain, Kalai, and Lewko, but while\nthat protocol relies on a single coordinator to shoulder a heavy burden\nthroughout the protocol, we design a mechanism to pass the coordination duties\nfrom party to party, resulting in a more even distribution of communication\nover the course of the computation. \n\n"}
{"id": "1503.08227", "contents": "Title: Harmonized Cellular and Distributed Massive MIMO: Load Balancing and\n  Scheduling Abstract: Multi-tier networks with large-array base stations (BSs) that are able to\noperate in the \"massive MIMO\" regime are envisioned to play a key role in\nmeeting the exploding wireless traffic demands. Operated over small cells with\nreciprocity-based training, massive MIMO promises large spectral efficiencies\nper unit area with low overheads. Also, near-optimal user-BS association and\nresource allocation are possible in cellular massive MIMO HetNets using simple\nadmission control mechanisms and rudimentary BS schedulers, since scheduled\nuser rates can be predicted a priori with massive MIMO.\n  Reciprocity-based training naturally enables coordinated multi-point\ntransmission (CoMP), as each uplink pilot inherently trains antenna arrays at\nall nearby BSs. In this paper we consider a distributed-MIMO form of CoMP,\nwhich improves cell-edge performance without requiring channel state\ninformation exchanges among cooperating BSs. We present methods for harmonized\noperation of distributed and cellular massive MIMO in the downlink that\noptimize resource allocation at a coarser time scale across the network. We\nalso present scheduling policies at the resource block level which target\napproaching the optimal allocations. Simulations reveal that the proposed\nmethods can significantly outperform the network-optimized cellular-only\nmassive MIMO operation (i.e., operation without CoMP), especially at the cell\nedge. \n\n"}
{"id": "1503.08644", "contents": "Title: On the Capacity of the Wiener Phase-Noise Channel: Bounds and Capacity\n  Achieving Distributions Abstract: In this paper, the capacity of the additive white Gaussian noise (AWGN)\nchannel, affected by time-varying Wiener phase noise is investigated. Tight\nupper and lower bounds on the capacity of this channel are developed. The upper\nbound is obtained by using the duality approach, and considering a specific\ndistribution over the output of the channel. In order to lower-bound the\ncapacity, first a family of capacity-achieving input distributions is found by\nsolving a functional optimization of the channel mutual information. Then,\nlower bounds on the capacity are obtained by drawing samples from the proposed\ndistributions through Monte-Carlo simulations. The proposed capacity-achieving\ninput distributions are circularly symmetric, non-Gaussian, and the input\namplitudes are correlated over time. The evaluated capacity bounds are tight\nfor a wide range of signal-to-noise-ratio (SNR) values, and thus they can be\nused to quantify the capacity. Specifically, the bounds follow the well-known\nAWGN capacity curve at low SNR, while at high SNR, they coincide with the\nhigh-SNR capacity result available in the literature for the phase-noise\nchannel. \n\n"}
{"id": "1503.08696", "contents": "Title: Graded quantization for multiple description coding of compressive\n  measurements Abstract: Compressed sensing (CS) is an emerging paradigm for acquisition of compressed\nrepresentations of a sparse signal. Its low complexity is appealing for\nresource-constrained scenarios like sensor networks. However, such scenarios\nare often coupled with unreliable communication channels and providing robust\ntransmission of the acquired data to a receiver is an issue. Multiple\ndescription coding (MDC) effectively combats channel losses for systems without\nfeedback, thus raising the interest in developing MDC methods explicitly\ndesigned for the CS framework, and exploiting its properties. We propose a\nmethod called Graded Quantization (CS-GQ) that leverages the democratic\nproperty of compressive measurements to effectively implement MDC, and we\nprovide methods to optimize its performance. A novel decoding algorithm based\non the alternating directions method of multipliers is derived to reconstruct\nsignals from a limited number of received descriptions. Simulations are\nperformed to assess the performance of CS-GQ against other methods in presence\nof packet losses. The proposed method is successful at providing robust coding\nof CS measurements and outperforms other schemes for the considered test\nmetrics. \n\n"}
{"id": "1504.00203", "contents": "Title: Deterministic Cramer-Rao bound for strictly non-circular sources and\n  analytical analysis of the achievable gains Abstract: Recently, several high-resolution parameter estimation algorithms have been\ndeveloped to exploit the structure of strictly second-order (SO) non-circular\n(NC) signals. They achieve a higher estimation accuracy and can resolve up to\ntwice as many signal sources compared to the traditional methods for arbitrary\nsignals. In this paper, as a benchmark for these NC methods, we derive the\nclosed-form deterministic R-D NC Cramer-Rao bound (NC CRB) for the\nmulti-dimensional parameter estimation of strictly non-circular (rectilinear)\nsignal sources. Assuming a separable centro-symmetric R-D array, we show that\nin some special cases, the deterministic R-D NC CRB reduces to the existing\ndeterministic R-D CRB for arbitrary signals. This suggests that no gain from\nstrictly non-circular sources (NC gain) can be achieved in these cases. For\nmore general scenarios, finding an analytical expression of the NC gain for an\narbitrary number of sources is very challenging. Thus, in this paper, we\nsimplify the derived NC CRB and the existing CRB for the special case of two\nclosely-spaced strictly non-circular sources captured by a uniform linear array\n(ULA). Subsequently, we use these simplified CRB expressions to analytically\ncompute the maximum achievable asymptotic NC gain for the considered two source\ncase. The resulting expression only depends on the various physical parameters\nand we find the conditions that provide the largest NC gain for two sources.\nOur analysis is supported by extensive simulation results. \n\n"}
{"id": "1504.01052", "contents": "Title: Fast algorithms for morphological operations using run-length encoded\n  binary images Abstract: This paper presents innovative algorithms to efficiently compute erosions and\ndilations of run-length encoded (RLE) binary images with arbitrary shaped\nstructuring elements. An RLE image is given by a set of runs, where a run is a\nhorizontal concatenation of foreground pixels. The proposed algorithms extract\nthe skeleton of the structuring element and build distance tables of the input\nimage, which are storing the distance to the next background pixel on the left\nand right hand sides. This information is then used to speed up the\ncalculations of the erosion and dilation operator by enabling the use of\ntechniques which allow to skip the analysis of certain pixels whenever a hit or\nmiss occurs. Additionally the input image gets trimmed during the preprocessing\nsteps on the base of two primitive criteria. Experimental results show the\nadvantages over other algorithms. The source code of our algorithms is\navailable in C++. \n\n"}
{"id": "1504.01661", "contents": "Title: An original Propagator for large array Abstract: In this paper, we demonstrate that when the ratio $n$ of the number of\nantenna elements $N$ to the number $P$ of radiating sources is superior or\nequal to $2$, then it is possible to choose a propagator from a set of\n$n(n+1)/2-1$ operators to compute the Angles of Arrival (AoA) of the narrowband\nincoming waves. This new non eigenbased approach is efficient when the Signal\nto Noise Ratio (SNR) is moderate, and gives multitude of possibilities, that\nare dependent of the random data, to construct the complex sets whose columns\nare orthogonal to the signal subspace generated by the radiating sources.\nElementary examples are given for $n=3$, $n=4$ and $n=6$. The simulation\nresults are presented to illustrate the performance of the proposed\ncomputational methods. \n\n"}
{"id": "1504.01799", "contents": "Title: Spectral Graph Theoretic Analysis of Tsallis Entropy-based Dissimilarity\n  Measure Abstract: In this paper we introduce a nonextensive quantum information theoretic\nmeasure which may be defined between any arbitrary number of density matrices,\nand we analyze its fundamental properties in the spectral graph-theoretic\nframework. Unlike other entropic measures, the proposed quantum divergence is\nsymmetric, matrix-convex, theoretically upper-bounded, and has the advantage of\nbeing generalizable to any arbitrary number of density matrices, with a\npossibility of assigning weights to these densities. \n\n"}
{"id": "1504.03632", "contents": "Title: Caching with Unknown Popularity Profiles in Small Cell Networks Abstract: A heterogenous network is considered where the base stations (BSs), small\nbase stations (SBSs) and users are distributed according to independent Poisson\npoint processes (PPPs). We let the SBS nodes to posses high storage capacity\nand are assumed to form a distributed caching network. Popular data files are\nstored in the local cache of SBS, so that users can download the desired files\nfrom one of the SBS in the vicinity subject to availability. The\noffloading-loss is captured via a cost function that depends on a random\ncaching strategy proposed in this paper. The cost function depends on the\npopularity profile, which is, in general, unknown. In this work, the popularity\nprofile is estimated at the BS using the available instantaneous demands from\nthe users in a time interval $[0,\\tau]$. This is then used to find an estimate\nof the cost function from which the optimal random caching strategy is devised.\nThe main results of this work are the following: First it is shown that the\nwaiting time $\\tau$ to achieve an $\\epsilon>0$ difference between the achieved\nand optimal costs is finite, provided the user density is greater than a\npredefined threshold. In this case, $\\tau$ is shown to scale as $N^2$, where\n$N$ is the support of the popularity profile. Secondly, a transfer\nlearning-based approach is proposed to obtain an estimate of the popularity\nprofile used to compute the empirical cost function. A condition is derived\nunder which the proposed transfer learning-based approach performs better than\nthe random caching strategy. \n\n"}
{"id": "1504.05628", "contents": "Title: Key Rate of the B92 Quantum Key Distribution Protocol with Finite Qubits Abstract: The key rate of the B92 quantum key distribution protocol had not been\nreported before this research when the number of qubits is finite. We compute\nit by using the security analysis framework proposed by Scarani and Renner in\n2008. \n\n"}
{"id": "1504.05756", "contents": "Title: A Large Deviations Approach to Secure Lossy Compression Abstract: We consider a Shannon cipher system for memoryless sources, in which\ndistortion is allowed at the legitimate decoder. The source is compressed using\na rate distortion code secured by a shared key, which satisfies a constraint on\nthe compression rate, as well as a constraint on the exponential rate of the\nexcess-distortion probability at the legitimate decoder. Secrecy is measured by\nthe exponential rate of the exiguous-distortion probability at the\neavesdropper, rather than by the traditional measure of equivocation. We define\nthe perfect secrecy exponent as the maximal exiguous-distortion exponent\nachievable when the key rate is unlimited. Under limited key rate, we prove\nthat the maximal achievable exiguous-distortion exponent is equal to the\nminimum between the average key rate and the perfect secrecy exponent, for a\nfairly general class of variable key rate codes. \n\n"}
{"id": "1504.05764", "contents": "Title: The $\\kappa$-$\\mu$ Shadowed Fading Model: Unifying the $\\kappa$-$\\mu$\n  and $\\eta$-$\\mu$ Distributions Abstract: This paper shows that the recently proposed $\\kappa$-$\\mu$ shadowed fading\nmodel includes, besides the $\\kappa$-$\\mu$ model, the $\\eta$-$\\mu$ fading model\nas a particular case. This has important relevance in practice, as it allows\nfor the unification of these popular fading distributions through a more\ngeneral, yet equally tractable, model. The convenience of new underlying\nphysical models is discussed. Then, we derive simple and novel closed-form\nexpressions for the asymptotic ergodic capacity in $\\kappa$-$\\mu$ shadowed\nfading channels, which illustrate the effects of the different fading\nparameters on the system performance. By exploiting the unification here\nunveiled, the asymptotic capacity expressions for the $\\kappa$-$\\mu$ and\n$\\eta$-$\\mu$ fading models are also obtained in closed-form as special cases. \n\n"}
{"id": "1504.05862", "contents": "Title: Compute-and-Forward Can Buy Secrecy Cheap Abstract: We consider a Gaussian multiple access channel with $K$ transmitters, a\n(intended) receiver and an external eavesdropper. The transmitters wish to\nreliably communicate with the receiver while concealing their messages from the\neavesdropper. This scenario has been investigated in prior works using two\ndifferent coding techniques; the random i.i.d. Gaussian coding and the signal\nalignment coding. Although, the latter offers promising results in a very high\nSNR regime, extending these results to the finite SNR regime is a challenging\ntask. In this paper, we propose a new lattice alignment scheme based on the\ncompute-and-forward framework which works at any finite SNR. We show that our\nachievable secure sum rate scales with $\\log(\\mathrm{SNR})$ and hence, in most\nSNR regimes, our scheme outperforms the random coding scheme in which the\nsecure sum rate does not grow with power. Furthermore, we show that our result\nmatches the prior work in the infinite SNR regime. Additionally, we analyze our\nresult numerically. \n\n"}
{"id": "1504.06782", "contents": "Title: An Approximately Optimal Algorithm for Scheduling Phasor Data\n  Transmissions in Smart Grid Networks Abstract: In this paper, we devise a scheduling algorithm for ordering transmission of\nsynchrophasor data from the substation to the control center in as short a time\nframe as possible, within the realtime hierarchical communications\ninfrastructure in the electric grid. The problem is cast in the framework of\nthe classic job scheduling with precedence constraints. The optimization setup\ncomprises the number of phasor measurement units (PMUs) to be installed on the\ngrid, a weight associated with each PMU, processing time at the control center\nfor the PMUs, and precedence constraints between the PMUs. The solution to the\nPMU placement problem yields the optimum number of PMUs to be installed on the\ngrid, while the processing times are picked uniformly at random from a\npredefined set. The weight associated with each PMU and the precedence\nconstraints are both assumed known. The scheduling problem is provably NP-hard,\nso we resort to approximation algorithms which provide solutions that are\nsuboptimal yet possessing polynomial time complexity. A lower bound on the\noptimal schedule is derived using branch and bound techniques, and its\nperformance evaluated using standard IEEE test bus systems. The scheduling\npolicy is power grid-centric, since it takes into account the electrical\nproperties of the network under consideration. \n\n"}
{"id": "1505.01462", "contents": "Title: Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology\n  Dependence Abstract: Data in the form of pairwise comparisons arises in many domains, including\npreference elicitation, sporting competitions, and peer grading among others.\nWe consider parametric ordinal models for such pairwise comparison data\ninvolving a latent vector $w^* \\in \\mathbb{R}^d$ that represents the\n\"qualities\" of the $d$ items being compared; this class of models includes the\ntwo most widely used parametric models--the Bradley-Terry-Luce (BTL) and the\nThurstone models. Working within a standard minimax framework, we provide tight\nupper and lower bounds on the optimal error in estimating the quality score\nvector $w^*$ under this class of models. The bounds depend on the topology of\nthe comparison graph induced by the subset of pairs being compared via its\nLaplacian spectrum. Thus, in settings where the subset of pairs may be chosen,\nour results provide principled guidelines for making this choice. Finally, we\ncompare these error rates to those under cardinal measurement models and show\nthat the error rates in the ordinal and cardinal settings have identical\nscalings apart from constant pre-factors. \n\n"}
{"id": "1505.01920", "contents": "Title: Will the Area Spectral Efficiency Monotonically Grow as Small Cells Go\n  Dense? Abstract: In this paper, we introduce a sophisticated path loss model into the\nstochastic geometry analysis incorporating both line-of-sight (LoS) and\nnon-line-of-sight (NLoS) transmissions to study their performance impact in\nsmall cell networks (SCNs). Analytical results are obtained on the coverage\nprobability and the area spectral efficiency (ASE) assuming both a general path\nloss model and a special case of path loss model recommended by the 3rd\nGeneration Partnership Project (3GPP) standards. The performance impact of LoS\nand NLoS transmissions in SCNs in terms of the coverage probability and the ASE\nis shown to be significant both quantitatively and qualitatively, compared with\nprevious work that does not differentiate LoS and NLoS transmissions.\nParticularly, our analysis demonstrates that when the density of small cells is\nlarger than a threshold, the network coverage probability will decrease as\nsmall cells become denser, which in turn makes the ASE suffer from a slow\ngrowth or even a notable decrease. For practical regime of small cell density,\nthe performance results derived from our analysis are distinctively different\nfrom previous results, and shed new insights on the design and deployment of\nfuture dense/ultra-dense SCNs. \n\n"}
{"id": "1505.03257", "contents": "Title: Optimal linear estimation under unknown nonlinear transform Abstract: Linear regression studies the problem of estimating a model parameter\n$\\beta^* \\in \\mathbb{R}^p$, from $n$ observations\n$\\{(y_i,\\mathbf{x}_i)\\}_{i=1}^n$ from linear model $y_i = \\langle\n\\mathbf{x}_i,\\beta^* \\rangle + \\epsilon_i$. We consider a significant\ngeneralization in which the relationship between $\\langle \\mathbf{x}_i,\\beta^*\n\\rangle$ and $y_i$ is noisy, quantized to a single bit, potentially nonlinear,\nnoninvertible, as well as unknown. This model is known as the single-index\nmodel in statistics, and, among other things, it represents a significant\ngeneralization of one-bit compressed sensing. We propose a novel spectral-based\nestimation procedure and show that we can recover $\\beta^*$ in settings (i.e.,\nclasses of link function $f$) where previous algorithms fail. In general, our\nalgorithm requires only very mild restrictions on the (unknown) functional\nrelationship between $y_i$ and $\\langle \\mathbf{x}_i,\\beta^* \\rangle$. We also\nconsider the high dimensional setting where $\\beta^*$ is sparse ,and introduce\na two-stage nonconvex framework that addresses estimation challenges in high\ndimensional regimes where $p \\gg n$. For a broad class of link functions\nbetween $\\langle \\mathbf{x}_i,\\beta^* \\rangle$ and $y_i$, we establish minimax\nlower bounds that demonstrate the optimality of our estimators in both the\nclassical and high dimensional regimes. \n\n"}
{"id": "1505.05800", "contents": "Title: Complexity Theoretic Limitations on Learning Halfspaces Abstract: We study the problem of agnostically learning halfspaces which is defined by\na fixed but unknown distribution $\\mathcal{D}$ on $\\mathbb{Q}^n\\times \\{\\pm\n1\\}$. We define $\\mathrm{Err}_{\\mathrm{HALF}}(\\mathcal{D})$ as the least error\nof a halfspace classifier for $\\mathcal{D}$. A learner who can access\n$\\mathcal{D}$ has to return a hypothesis whose error is small compared to\n$\\mathrm{Err}_{\\mathrm{HALF}}(\\mathcal{D})$.\n  Using the recently developed method of the author, Linial and Shalev-Shwartz\nwe prove hardness of learning results under a natural assumption on the\ncomplexity of refuting random $K$-$\\mathrm{XOR}$ formulas. We show that no\nefficient learning algorithm has non-trivial worst-case performance even under\nthe guarantees that $\\mathrm{Err}_{\\mathrm{HALF}}(\\mathcal{D}) \\le \\eta$ for\narbitrarily small constant $\\eta>0$, and that $\\mathcal{D}$ is supported in\n$\\{\\pm 1\\}^n\\times \\{\\pm 1\\}$. Namely, even under these favorable conditions\nits error must be $\\ge \\frac{1}{2}-\\frac{1}{n^c}$ for every $c>0$. In\nparticular, no efficient algorithm can achieve a constant approximation ratio.\nUnder a stronger version of the assumption (where $K$ can be poly-logarithmic\nin $n$), we can take $\\eta = 2^{-\\log^{1-\\nu}(n)}$ for arbitrarily small\n$\\nu>0$. Interestingly, this is even stronger than the best known lower bounds\n(Arora et. al. 1993, Feldamn et. al. 2006, Guruswami and Raghavendra 2006) for\nthe case that the learner is restricted to return a halfspace classifier (i.e.\nproper learning). \n\n"}
{"id": "1505.06878", "contents": "Title: Computationally efficient MIMO system identification using Signal\n  Matched Synthesis Filter Bank Abstract: We propose a multi input multi output(MIMO) system identification framework\nby interpreting the MIMO system in terms of a multirate synthesis filter bank.\nThe proposed methodology is discussed in two steps: in the first step the MIMO\nsystem is interpreted as a synthesis filter bank and the second step is to\nconvert the MIMO system into a SISO system \"without any loss of information\",\nwhich re-structures the system identification problem into a SISO form. The\nsystem identification problem, in its new form, is identical to the problem of\nobtaining the signal matched synthesis filter bank (SMSFB) as proposed in Part\nII. Since we have developed fast algorithms to obtain the filter bank\ncoefficients in Part II, for \"the given data case\" as well as \"the given\nstatistics case\", we can use these algorithm for the MIMO system identification\nas well. This framework can have an adaptive as well as block processing\nimplementation. The algorithms, used here, involve only scalar computations,\nunlike the conventional MIMO system identification algorithms where one\nrequires matrix computations. These order recursive algorithm can also be used\nto obtain approximate smaller order model for large order systems without using\nany model order reduction algorithm. The proposed identification framework can\nalso be used for SISO LPTV system identification and also for a SIMO or MISO\nsystem. The efficacy of the proposed scheme is validated and its performance in\nthe presence of measurement noise is illustrated using simulation results. \n\n"}
{"id": "1505.07206", "contents": "Title: Uplink Downlink Rate Balancing in Cooperating Cellular Networks Abstract: Broadcast MIMO techniques can significantly increase the throughput in the\ndownlink of cellular networks, at the price of channel state information (CSI)\nfeedback from the mobiles, sent over the uplink. Thus, it creates a mechanism\nthat can tradeoff some uplink capacity for increased downlink capacity. In this\nwork we quantify this tradeoff and study the exchange ratio between the\nfeedback rate (over the uplink) and the downlink rate. We study both finite and\ninfinite networks, and show that for high enough (but finite) SNR, the uplink\nrate can be exchanged for increased downlink rate with a favorable exchange\nratio. This exchange ratio is an increasing function of the channel coherence\ntime, and a decreasing function of the number of measured base stations. We\nalso show that devoting a constant fraction of the uplink to CSI feedback can\nincrease the downlink multiplexing gain continuously from 0 to 1, in finite\nnetworks. On the other hand, in infinite networks (with infinite connectivity)\nour bounds can only show doubly logarithmic scaling of the rate with SNR. The\npresented results prove that the adaptation of the feedback rate can control\nthe balance between the uplink and downlink rates. This capability is very\nimportant in modern cellular networks, where the operators need to respond to\ncontinuously changing user demands. \n\n"}
{"id": "1506.00154", "contents": "Title: Resolvability in E{\\gamma} with Applications to Lossy Compression and\n  Wiretap Channels Abstract: We study the amount of randomness needed for an input process to approximate\na given output distribution of a channel in the $E_{\\gamma}$ distance. A\ngeneral one-shot achievability bound for the precision of such an approximation\nis developed. In the i.i.d.~setting where $\\gamma=\\exp(nE)$, a (nonnegative)\nrandomness rate above $\\inf_{Q_{\\sf U}: D(Q_{\\sf X}||\\pi_{\\sf X})\\le E}\n\\{D(Q_{\\sf X}||\\pi_{\\sf X})+I(Q_{\\sf U},Q_{\\sf X|U})-E\\}$ is necessary and\nsufficient to asymptotically approximate the output distribution $\\pi_{\\sf\nX}^{\\otimes n}$ using the channel $Q_{\\sf X|U}^{\\otimes n}$, where $Q_{\\sf\nU}\\to Q_{\\sf X|U}\\to Q_{\\sf X}$. The new resolvability result is then used to\nderive a one-shot upper bound on the error probability in the rate distortion\nproblem, and a lower bound on the size of the eavesdropper list to include the\nactual message in the wiretap channel problem. Both bounds are asymptotically\ntight in i.i.d.~settings. \n\n"}
{"id": "1506.02751", "contents": "Title: Guaranteed Blind Sparse Spikes Deconvolution via Lifting and Convex\n  Optimization Abstract: Neural recordings, returns from radars and sonars, images in astronomy and\nsingle-molecule microscopy can be modeled as a linear superposition of a small\nnumber of scaled and delayed copies of a band-limited or diffraction-limited\npoint spread function, which is either determined by the nature or designed by\nthe users; in other words, we observe the convolution between a point spread\nfunction and a sparse spike signal with unknown amplitudes and delays. While it\nis of great interest to accurately resolve the spike signal from as few samples\nas possible, however, when the point spread function is not known a priori,\nthis problem is terribly ill-posed. This paper proposes a convex optimization\nframework to simultaneously estimate the point spread function as well as the\nspike signal, by mildly constraining the point spread function to lie in a\nknown low-dimensional subspace. By applying the lifting trick, we obtain an\nunderdetermined linear system of an ensemble of signals with joint spectral\nsparsity, to which atomic norm minimization is applied. Under mild randomness\nassumptions of the low-dimensional subspace as well as a separation condition\nof the spike signal, we prove the proposed algorithm, dubbed as AtomicLift, is\nguaranteed to recover the spike signal up to a scaling factor as soon as the\nnumber of samples is large enough. The extension of AtomicLift to handle noisy\nmeasurements is also discussed. Numerical examples are provided to validate the\neffectiveness of the proposed approaches. \n\n"}
{"id": "1506.04583", "contents": "Title: On the Benefits of Edge Caching for MIMO Interference Alignment Abstract: In this contribution, we jointly investigate the benefits of caching and\ninterference alignment (IA) in multiple-input multiple-output (MIMO)\ninterference channel under limited backhaul capacity. In particular, total\naverage transmission rate is derived as a function of various system parameters\nsuch as backhaul link capacity, cache size, number of active\ntransmitter-receiver pairs as well as the quantization bits for channel state\ninformation (CSI). Given the fact that base stations are equipped both with\ncaching and IA capabilities and have knowledge of content popularity profile,\nwe then characterize an operational regime where the caching is beneficial.\nSubsequently, we find the optimal number of transmitter-receiver pairs that\nmaximizes the total average transmission rate. When the popularity profile of\nrequested contents falls into the operational regime, it turns out that caching\nsubstantially improves the throughput as it mitigates the backhaul usage and\nallows IA methods to take benefit of such limited backhaul. \n\n"}
{"id": "1506.06822", "contents": "Title: I/Q Imbalance Aware Widely-Linear Receiver for Uplink Multi-Cell Massive\n  MIMO Systems Abstract: In-phase/quadrature-phase (I/Q) imbalance is one of the most important\nhardware impairments in communication systems. It arises in the analogue parts\nof direct conversion radio frequency (RF) transceivers and can cause severe\nperformance losses. In this paper, I/Q imbalance (IQI) aware widely-linear (WL)\nchannel estimation and data detection schemes for uplink multi-cell massive\nmultiple-input multiple-output (MIMO) systems are proposed. The resulting\nreceiver is a WL extension of the minimum mean square error (MMSE) receiver and\njointly mitigates multi-user interference and IQI by processing the real and\nthe imaginary parts of the received signal separately. The IQI arising at both\nthe base station (BS) and the user terminals (UTs) is then taken into account.\nThe considered channel state information (CSI) acquisition model includes the\neffects of both estimation errors and pilot contamination, which is caused by\nthe reuse of the same training sequences in neighboring cells. We apply results\nfrom random matrix theory to derive analytical expressions for the achievable\nsum rates of the proposed IQI aware and conventional IQI unaware receivers. Our\nsimulation results show that the performance of the proposed IQI aware WLMMSE\nreceiver in a system with IQI is close to that of the MMSE receiver in an ideal\nsystem without IQI. Moreover, our results for the sum rate of the IQI unaware\nMMSE receiver reveal that the performance loss due to IQI can be large and, if\nleft unattended, does not vanish for large numbers of BS antennas. \n\n"}
{"id": "1506.06988", "contents": "Title: From Entropy to Information: Biased Typewriters and the Origin of Life Abstract: The origin of life can be understood mathematically to be the origin of\ninformation that can replicate. The likelihood that entropy spontaneously\nbecomes information can be calculated from first principles, and depends\nexponentially on the amount of information that is necessary for replication.\nWe do not know what the minimum amount of information for self-replication is\nbecause it must depend on the local chemistry, but we can study how this\nlikelihood behaves in different known chemistries, and we can study ways in\nwhich this likelihood can be enhanced. Here we present evidence from numerical\nsimulations (using the digital life chemistry \"Avida\") that using a biased\nprobability distribution for the creation of monomers (the \"biased typewriter\")\ncan exponentially increase the likelihood of spontaneous emergence of\ninformation from entropy. We show that this likelihood may depend on the length\nof the sequence that the information is embedded in, but in a non-trivial\nmanner: there may be an optimum sequence length that maximizes the likelihood.\nWe conclude that the likelihood of spontaneous emergence of self-replication is\nmuch more malleable than previously thought, and that the biased probability\ndistributions of monomers that are the norm in biochemistry may significantly\nenhance these likelihoods \n\n"}
{"id": "1506.08895", "contents": "Title: Sensing/Decision-Based Cooperative Relaying Schemes With Multi-Access\n  Transmission: Stability Region And Average Delay Characterization Abstract: We consider a cooperative relaying system which consists of a number of\nsource terminals, one shared relay, and a common destination with multi-packet\nreception (MPR) capability. In this paper, we study the stability and delay\nanalysis for two cooperative relaying schemes; the sensing-based cooperative\n(SBC) scheme and the decision-based cooperative (DBC) scheme. In the SBC\nscheme, the relay senses the channel at the beginning of each time slot. In the\nidle time slots, the relay transmits the packet at the head of its queue, while\nin the busy one, the relay decides either to transmit simultaneously with the\nsource terminal or to listen to the source transmission. The SBC scheme is a\nnovel paradigm that utilizes the spectrum more efficiently than the other\ncooperative schemes because the relay not only exploits the idle time slots,\nbut also has the capability to mildly interfere with the source terminal. On\nthe other hand, in the DBC scheme, the relay does not sense the channel and it\ndecides either to transmit or to listen according to certain probabilities.\nNumerical results reveal that the two proposed schemes outperform existing\ncooperative schemes that restrict the relay to send only in the idle time\nslots. Moreover, we show how the MPR capability at the destination can\ncompensate for the sensing need at the relay, i.e., the DBC scheme achieves\nalmost the same stability region as that of the SBC scheme. Furthermore, we\nderive the condition under which the two proposed schemes achieve the same\nmaximum stable throughput. \n\n"}
{"id": "1507.02874", "contents": "Title: On the Public Communication Needed to Achieve SK Capacity in the\n  Multiterminal Source Model Abstract: The focus of this paper is on the public communication required for\ngenerating a maximal-rate secret key (SK) within the multiterminal source model\nof Csisz{\\'a}r and Narayan. Building on the prior work of Tyagi for the\ntwo-terminal scenario, we derive a lower bound on the communication complexity,\n$R_{\\text{SK}}$, defined to be the minimum rate of public communication needed\nto generate a maximal-rate SK. It is well known that the minimum rate of\ncommunication for omniscience, denoted by $R_{\\text{CO}}$, is an upper bound on\n$R_{\\text{SK}}$. For the class of pairwise independent network (PIN) models\ndefined on uniform hypergraphs, we show that a certain \"Type $\\mathcal{S}$\"\ncondition, which is verifiable in polynomial time, guarantees that our lower\nbound on $R_{\\text{SK}}$ meets the $R_{\\text{CO}}$ upper bound. Thus, PIN\nmodels satisfying our condition are $R_{\\text{SK}}$-maximal, meaning that the\nupper bound $R_{\\text{SK}} \\le R_{\\text{CO}}$ holds with equality. This allows\nus to explicitly evaluate $R_{\\text{SK}}$ for such PIN models. We also give\nseveral examples of PIN models that satisfy our Type $\\mathcal S$ condition.\nFinally, we prove that for an arbitrary multiterminal source model, a stricter\nversion of our Type $\\mathcal S$ condition implies that communication from\n\\emph{all} terminals (\"omnivocality\") is needed for establishing a SK of\nmaximum rate. For three-terminal source models, the converse is also true:\nomnivocality is needed for generating a maximal-rate SK only if the strict Type\n$\\mathcal S$ condition is satisfied. Counterexamples exist that show that the\nconverse is not true in general for source models with four or more terminals. \n\n"}
{"id": "1507.03843", "contents": "Title: Minimum Energy to Send $k$ Bits Over Multiple-Antenna Fading Channels Abstract: This paper investigates the minimum energy required to transmit $k$\ninformation bits with a given reliability over a multiple-antenna Rayleigh\nblock-fading channel, with and without channel state information (CSI) at the\nreceiver. No feedback is assumed. It is well known that the ratio between the\nminimum energy per bit and the noise level converges to $-1.59$ dB as $k$ goes\nto infinity, regardless of whether CSI is available at the receiver or not.\nThis paper shows that lack of CSI at the receiver causes a slowdown in the\nspeed of convergence to $-1.59$ dB as $k\\to\\infty$ compared to the case of\nperfect receiver CSI. Specifically, we show that, in the no-CSI case, the gap\nto $-1.59$ dB is proportional to $((\\log k) /k)^{1/3}$, whereas when perfect\nCSI is available at the receiver, this gap is proportional to $1/\\sqrt{k}$. In\nboth cases, the gap to $-1.59$ dB is independent of the number of transmit\nantennas and of the channel's coherence time. Numerically, we observe that,\nwhen the receiver is equipped with a single antenna, to achieve an energy per\nbit of $ - 1.5$ dB in the no-CSI case, one needs to transmit at least $7\\times\n10^7$ information bits, whereas $6\\times 10^4$ bits suffice for the case of\nperfect CSI at the receiver. \n\n"}
{"id": "1507.03857", "contents": "Title: MMSE of probabilistic low-rank matrix estimation: Universality with\n  respect to the output channel Abstract: This paper considers probabilistic estimation of a low-rank matrix from\nnon-linear element-wise measurements of its elements. We derive the\ncorresponding approximate message passing (AMP) algorithm and its state\nevolution. Relying on non-rigorous but standard assumptions motivated by\nstatistical physics, we characterize the minimum mean squared error (MMSE)\nachievable information theoretically and with the AMP algorithm. Unlike in\nrelated problems of linear estimation, in the present setting the MMSE depends\non the output channel only trough a single parameter - its Fisher information.\nWe illustrate this striking finding by analysis of submatrix localization, and\nof detection of communities hidden in a dense stochastic block model. For this\nexample we locate the computational and statistical boundaries that are not\nequal for rank larger than four. \n\n"}
{"id": "1507.07628", "contents": "Title: LP-decodable multipermutation codes Abstract: In this paper, we introduce a new way of constructing and decoding\nmultipermutation codes. Multipermutations are permutations of a multiset that\ngenerally consist of duplicate entries. We first introduce a class of binary\nmatrices called multipermutation matrices, each of which corresponds to a\nunique and distinct multipermutation. By enforcing a set of linear constraints\non these matrices, we define a new class of codes that we term LP-decodable\nmultipermutation codes. In order to decode these codes using a linear program\n(LP), thereby enabling soft decoding, we characterize the convex hull of\nmultipermutation matrices. This characterization allows us to relax the coding\nconstraints to a polytope and to derive two LP decoding problems. These two\nproblems are respectively formulated by relaxing the maximum likelihood\ndecoding problem and the minimum Chebyshev distance decoding problem.\n  Because these codes are non-linear, we also study efficient encoding and\ndecoding algorithms. We first describe an algorithm that maps consecutive\nintegers, one by one, to an ordered list of multipermutations. Based on this\nalgorithm, we develop an encoding algorithm for a code proposed by Shieh and\nTsai, a code that falls into our class of LP-decodable multipermutation codes.\nRegarding decoding algorithms, we propose an efficient distributed decoding\nalgorithm based on the alternating direction method of multipliers (ADMM).\nFinally, we observe from simulation results that the soft decoding techniques\nwe introduce can significantly outperform hard decoding techniques that are\nbased on quantized channel outputs. \n\n"}
{"id": "1507.08254", "contents": "Title: Efficient Compressive Phase Retrieval with Constrained Sensing Vectors Abstract: We propose a robust and efficient approach to the problem of compressive\nphase retrieval in which the goal is to reconstruct a sparse vector from the\nmagnitude of a number of its linear measurements. The proposed framework relies\non constrained sensing vectors and a two-stage reconstruction method that\nconsists of two standard convex programs that are solved sequentially.\n  In recent years, various methods are proposed for compressive phase\nretrieval, but they have suboptimal sample complexity or lack robustness\nguarantees. The main obstacle has been that there is no straightforward convex\nrelaxations for the type of structure in the target. Given a set of\nunderdetermined measurements, there is a standard framework for recovering a\nsparse matrix, and a standard framework for recovering a low-rank matrix.\nHowever, a general, efficient method for recovering a jointly sparse and\nlow-rank matrix has remained elusive.\n  Deviating from the models with generic measurements, in this paper we show\nthat if the sensing vectors are chosen at random from an incoherent subspace,\nthen the low-rank and sparse structures of the target signal can be effectively\ndecoupled. We show that a recovery algorithm that consists of a low-rank\nrecovery stage followed by a sparse recovery stage will produce an accurate\nestimate of the target when the number of measurements is\n$\\mathsf{O}(k\\,\\log\\frac{d}{k})$, where $k$ and $d$ denote the sparsity level\nand the dimension of the input signal. We also evaluate the algorithm through\nnumerical simulation. \n\n"}
{"id": "1507.08268", "contents": "Title: Consistent Basis Pursuit for Signal and Matrix Estimates in Quantized\n  Compressed Sensing Abstract: This paper focuses on the estimation of low-complexity signals when they are\nobserved through $M$ uniformly quantized compressive observations. Among such\nsignals, we consider 1-D sparse vectors, low-rank matrices, or compressible\nsignals that are well approximated by one of these two models. In this context,\nwe prove the estimation efficiency of a variant of Basis Pursuit Denoise,\ncalled Consistent Basis Pursuit (CoBP), enforcing consistency between the\nobservations and the re-observed estimate, while promoting its low-complexity\nnature. We show that the reconstruction error of CoBP decays like $M^{-1/4}$\nwhen all parameters but $M$ are fixed. Our proof is connected to recent bounds\non the proximity of vectors or matrices when (i) those belong to a set of small\nintrinsic \"dimension\", as measured by the Gaussian mean width, and (ii) they\nshare the same quantized (dithered) random projections. By solving CoBP with a\nproximal algorithm, we provide some extensive numerical observations that\nconfirm the theoretical bound as $M$ is increased, displaying even faster error\ndecay than predicted. The same phenomenon is observed in the special, yet\nimportant case of 1-bit CS. \n\n"}
{"id": "1507.08685", "contents": "Title: Asymptotic Mutual Information for the Two-Groups Stochastic Block Model Abstract: We develop an information-theoretic view of the stochastic block model, a\npopular statistical model for the large-scale structure of complex networks. A\ngraph $G$ from such a model is generated by first assigning vertex labels at\nrandom from a finite alphabet, and then connecting vertices with edge\nprobabilities depending on the labels of the endpoints. In the case of the\nsymmetric two-group model, we establish an explicit `single-letter'\ncharacterization of the per-vertex mutual information between the vertex labels\nand the graph.\n  The explicit expression of the mutual information is intimately related to\nestimation-theoretic quantities, and --in particular-- reveals a phase\ntransition at the critical point for community detection. Below the critical\npoint the per-vertex mutual information is asymptotically the same as if edges\nwere independent. Correspondingly, no algorithm can estimate the partition\nbetter than random guessing. Conversely, above the threshold, the per-vertex\nmutual information is strictly smaller than the independent-edges upper bound.\nIn this regime there exists a procedure that estimates the vertex labels better\nthan random guessing. \n\n"}
{"id": "1508.00522", "contents": "Title: Explicit Frames for Deterministic Phase Retrieval via PhaseLift Abstract: We explicitly give a frame of cardinality $5n-6$ such that every signal in\n$\\mathbb{C}^n$ can be recovered up to a phase from its associated intensity\nmeasurements via the PhaseLift approach. Furthermore, we give explicit linear\nmeasurements with $4r(n-r)+n-2r$ outcomes that enable the recovery of every\npositive semidefinite $n\\times n$ matrix of rank at most $r$. \n\n"}
{"id": "1508.00545", "contents": "Title: Connectivity in Secure Wireless Sensor Networks under Transmission\n  Constraints Abstract: In wireless sensor networks (WSNs), the Eschenauer-Gligor (EG) key\npre-distribution scheme is a widely recognized way to secure communications.\nAlthough connectivity properties of secure WSNs with the EG scheme have been\nextensively investigated, few results address physical transmission\nconstraints. These constraints reflect real-world implementations of WSNs in\nwhich two sensors have to be within a certain distance from each other to\ncommunicate. In this paper, we present zero-one laws for connectivity in WSNs\nemploying the EG scheme under transmission constraints. These laws help specify\nthe critical transmission ranges for connectivity. Our analytical findings are\nconfirmed via numerical experiments. In addition to secure WSNs, our\ntheoretical results are also applied to frequency hopping in wireless networks. \n\n"}
{"id": "1508.04227", "contents": "Title: Second-Order Region for Gray-Wyner Network Abstract: The coding problem over the Gray-Wyner network is studied from the\nsecond-order coding rates perspective. A tilted information density for this\nnetwork is introduced in the spirit of Kostina-Verd\\'u, and, under a certain\nregularity condition, the second-order region is characterized in terms of the\nvariance of this tilted information density and the tangent vector of the\nfirst-order region. The second-order region is proved by the type method: the\nachievability part is proved by the type-covering argument, and the converse\npart is proved by a refinement of the perturbation approach that was used by\nGu-Effros to show the strong converse of the Gray-Wyner network. This is the\nfirst instance that the second-order region is characterized for a\nmulti-terminal problem where the characterization of the first-order region\ninvolves an auxiliary random variable. \n\n"}
{"id": "1508.04485", "contents": "Title: SAFFRON: A Fast, Efficient, and Robust Framework for Group Testing based\n  on Sparse-Graph Codes Abstract: Group testing tackles the problem of identifying a population of $K$\ndefective items from a set of $n$ items by pooling groups of items efficiently\nin order to cut down the number of tests needed. The result of a test for a\ngroup of items is positive if any of the items in the group is defective and\nnegative otherwise. The goal is to judiciously group subsets of items such that\ndefective items can be reliably recovered using the minimum number of tests,\nwhile also having a low-complexity decoding procedure.\n  We describe SAFFRON (Sparse-grAph codes Framework For gROup testiNg), a\nnon-adaptive group testing paradigm that recovers at least a\n$(1-\\epsilon)$-fraction (for any arbitrarily small $\\epsilon > 0$) of $K$\ndefective items with high probability with $m=6C(\\epsilon)K\\log_2{n}$ tests,\nwhere $C(\\epsilon)$ is a precisely characterized constant that depends only on\n$\\epsilon$. For instance, it can provably recover at least $(1-10^{-6})K$\ndefective items with $m \\simeq 68 K \\log_2{n}$ tests. The computational\ncomplexity of the decoding algorithm of SAFFRON is $\\mathcal{O}(K\\log n)$,\nwhich is order-optimal. Further, we robustify SAFFRON such that it can reliably\nrecover the set of $K$ defective items even in the presence of erroneous or\nnoisy test results. We also propose Singleton-Only-SAFFRON, a variant of\nSAFFRON, that recovers all the $K$ defective items with $m=2e(1+\\alpha)K\\log K\n\\log_2 n$ tests with probability\n$1-\\mathcal{O}{\\left(\\frac{1}{K^\\alpha}\\right)}$, where $\\alpha>0$ is a\nconstant. By leveraging powerful design and analysis tools from modern\nsparse-graph coding theory, SAFFRON is the first approach to reliable,\nlarge-scale probabilistic group testing that offers both precisely\ncharacterizable number of tests needed (down to the constants) together with\norder-optimal decoding complexity. \n\n"}
{"id": "1508.04742", "contents": "Title: A short note on estimation of WCRE and WCE Abstract: In this note the author uses order statistics to estimate WCRE and WCE in\nterms of empirical and survival functions. An example in both cases normal and\nexponential WFs is analyzed. \n\n"}
{"id": "1508.05703", "contents": "Title: Impact of CFO Estimation on the Performance of ZF Receiver in Massive\n  MU-MIMO Systems Abstract: In this paper, we study the impact of carrier frequency offset (CFO)\nestimation/compensation on the information rate performance of the zero-forcing\n(ZF) receiver in the uplink of a multi-user massive multiple-input\nmultiple-output (MIMO) system. Analysis of the derived closed-form expression\nof the per-user information rate reveals that with increasing number of BS\nantennas $M$, an $\\mathcal{O}(\\sqrt{M})$ array gain is achievable, which is\nsame as that achieved in the ideal zero CFO scenario. Also it is observed that\ncompared to the ideal zero CFO case, the performance degradation in the\npresence of residual CFO (after CFO compensation) is the same for both ZF and\nMRC. \n\n"}
{"id": "1508.06746", "contents": "Title: A New Energy Efficient Beamforming Strategy for MISO Interfering\n  Broadcast Channels based on Large Systems Analysis Abstract: In this paper, we propose a new beamforming design to maximize energy\nefficiency (EE) for multiple input single output interfering broadcast channels\n(IFBC). Under this model, the EE problem is non-convex in general due to the\ncoupled interference and its fractional form, and thus it is difficult to solve\nthe problem. Conventional algorithms which address this problem have adopted an\niterative method for each channel realization, which requires high\ncomputational complexity. In order to reduce the computational complexity, we\nparameterize the beamforming vector by scalar parameters related to beam\ndirection and power. Then, by employing asymptotic results of random matrix\ntheory with this parametrization, we identify the optimal parameters to\nmaximize the EE in the large system limit assuming that the number of transmit\nantennas and users are large with a fixed ratio. In the asymptotic regime, our\nsolutions depend only on the second order channel statistics, which yields\nsignificantly reduced computational complexity and system overhead compared to\nthe conventional approaches. Hence, the beamforming vector to maximize the EE\nperformance can be determined with local channel state information and the\noptimized parameters. Based on the asymptotic results, the proposed scheme can\nprovide insights on the average EE performance, and a simple yet efficient\nbeamforming strategy is introduced for the finite system case. Numerical\nresults confirm that the proposed scheme shows a negligible performance loss\ncompared to the best result achieved by the conventional approaches even with\nsmall system dimensions, with much reduced system complexity. \n\n"}
{"id": "1508.07269", "contents": "Title: Missing Spectrum-Data Recovery in Cognitive Radio Networks Using\n  Piecewise Constant Nonnegative Matrix Factorization Abstract: In this paper, we propose a missing spectrum data recovery technique for\ncognitive radio (CR) networks using Nonnegative Matrix Factorization (NMF). It\nis shown that the spectrum measurements collected from secondary users (SUs)\ncan be factorized as product of a channel gain matrix times an activation\nmatrix. Then, an NMF method with piecewise constant activation coefficients is\nintroduced to analyze the measurements and estimate the missing spectrum data.\nThe proposed optimization problem is solved by a Majorization-Minimization\ntechnique. The numerical simulation verifies that the proposed technique is\nable to accurately estimate the missing spectrum data in the presence of noise\nand fading. \n\n"}
{"id": "1508.07433", "contents": "Title: A General MIMO Framework for NOMA Downlink and Uplink Transmission Based\n  on Signal Alignment Abstract: The application of multiple-input multiple-output (MIMO) techniques to\nnon-orthogonal multiple access (NOMA) systems is important to enhance the\nperformance gains of NOMA. In this paper, a novel MIMO-NOMA framework for\ndownlink and uplink transmission is proposed by applying the concept of signal\nalignment. By using stochastic geometry, closed-form analytical results are\ndeveloped to facilitate the performance evaluation of the proposed framework\nfor randomly deployed users and interferers. The impact of different power\nallocation strategies, such as fixed power allocation and cognitive radio\ninspired power allocation, on the performance of MIMO-NOMA is also\ninvestigated. Computer simulation results are provided to demonstrate the\nperformance of the proposed framework and the accuracy of the developed\nanalytical results. \n\n"}
{"id": "1509.00453", "contents": "Title: PLC-to-DSL Interference: Statistical Model and Impact on DSL Abstract: Newly available standards for broadband access using Digital Subscriber Lines\n(DSL) have a high degree of spectrum overlap with home networking technologies\nusing broadband Power Line Communications (BB-PLC) and this overlap leads to\nElectromagnetic Compatibility issues that may cause performance degradation in\nDSL systems. This paper studies the characteristics of measured PLC-to-DSL\ninterference and presents novel results on its statistical characterization.\nThe frequency-dependent couplings between power line cables and twisted-pairs\nare estimated from measurements and a statistical model based on a mixture of\ntwo truncated Gaussian distributions is set forth. The proposed statistical\nmodel allows the accurate evaluation of the impact of BB-PLC interference on\nvarious DSL technologies, in terms of both average and worst-case impacts on\ndata rate. This paper further provides an extensive assessment of the impact of\nPLC-to-DSL interference at various loop lengths and for multiple profiles of\nVery-high rate Digital Subscriber Lines (VDSL2), Vectored VDSL2 (V-VDSL2), and\nG.fast. The results of this paper confirm that the impact of PLC interference\nvaries with loop length and whether vectoring is used or not. Furthermore, the\naverage impact is found to be generally small but worst-case couplings can lead\nto substantial degradation of DSL. \n\n"}
{"id": "1509.00715", "contents": "Title: Constant Compositions in the Sphere Packing Bound for Classical-Quantum\n  Channels Abstract: The sphere packing bound, in the form given by Shannon, Gallager and\nBerlekamp, was recently extended to classical-quantum channels, and it was\nshown that this creates a natural setting for combining probabilistic\napproaches with some combinatorial ones such as the Lov\\'asz theta function. In\nthis paper, we extend the study to the case of constant composition codes. We\nfirst extend the sphere packing bound for classical-quantum channels to this\ncase, and we then show that the obtained result is related to a variation of\nthe Lov\\'asz theta function studied by Marton. We then propose a further\nextension to the case of varying channels and codewords with a constant\nconditional composition given a particular sequence. This extension is then\napplied to auxiliary channels to deduce a bound which can be interpreted as an\nextension of the Elias bound. \n\n"}
{"id": "1509.01332", "contents": "Title: Lattice Codes Achieve the Capacity of Common Message Gaussian Broadcast\n  Channels with Coded Side Information Abstract: Lattices possess elegant mathematical properties which have been previously\nused in the literature to show that structured codes can be efficient in a\nvariety of communication scenarios, including coding for the additive white\nGaussian noise (AWGN) channel, dirty-paper channel, Wyner-Ziv coding, coding\nfor relay networks and so forth. We consider the family of single-transmitter\nmultiple-receiver Gaussian channels where the source transmits a set of common\nmessages to all the receivers (multicast scenario), and each receiver has\n'coded side information', i.e., prior information in the form of linear\ncombinations of the messages. This channel model is motivated by applications\nto multi-terminal networks where the nodes may have access to coded versions of\nthe messages from previous signal hops or through orthogonal channels. The\ncapacity of this channel is known and follows from the work of Tuncel (2006),\nwhich is based on random coding arguments. In this paper, following the\napproach of Erez and Zamir, we design lattice codes for this family of channels\nwhen the source messages are symbols from a finite field 'Fp' of prime size.\nOur coding scheme utilizes Construction A lattices designed over the same prime\nfield 'Fp', and uses algebraic binning at the decoders to expurgate the channel\ncode and obtain good lattice subcodes, for every possible set of linear\ncombinations available as side information. The achievable rate of our coding\nscheme is a function of the size 'p' of underlying prime field, and approaches\nthe capacity as 'p' tends to infinity. \n\n"}
{"id": "1509.01371", "contents": "Title: Complete Weight Enumerators of a Family of Three-Weight Linear Codes Abstract: Linear codes have been an interesting topic in both theory and practice for\nmany years. In this paper, for an odd prime $p$, we present the explicit\ncomplete weight enumerator of a family of $p$-ary linear codes constructed with\ndefining set. The weight enumerator is an mmediate result of the complete\nweight enumerator, which shows that the codes proposed in this paper are\nthree-weight linear codes. Additionally, all nonzero codewords are minimal and\nthus they are suitable for secret sharing. \n\n"}
{"id": "1509.01703", "contents": "Title: Newton-like method with diagonal correction for distributed optimization Abstract: We consider distributed optimization problems where networked nodes\ncooperatively minimize the sum of their locally known convex costs. A popular\nclass of methods to solve these problems are the distributed gradient methods,\nwhich are attractive due to their inexpensive iterations, but have a drawback\nof slow convergence rates. This motivates the incorporation of second-order\ninformation in the distributed methods, but this task is challenging: although\nthe Hessians which arise in the algorithm design respect the sparsity of the\nnetwork, their inverses are dense, hence rendering distributed implementations\ndifficult. We overcome this challenge and propose a class of distributed\nNewton-like methods, which we refer to as Distributed Quasi Newton (DQN). The\nDQN family approximates the Hessian inverse by: 1) splitting the Hessian into\nits diagonal and off-diagonal part, 2) inverting the diagonal part, and 3)\napproximating the inverse of the off-diagonal part through a weighted linear\nfunction. The approximation is parameterized by the tuning variables which\ncorrespond to different splittings of the Hessian and by different weightings\nof the off-diagonal Hessian part. Specific choices of the tuning variables give\nrise to different variants of the proposed general DQN method -- dubbed DQN-0,\nDQN-1 and DQN-2 -- which mutually trade-off communication and computational\ncosts for convergence. Simulations demonstrate the effectiveness of the\nproposed DQN methods. \n\n"}
{"id": "1509.01931", "contents": "Title: The Approximate Capacity of the MIMO Relay Channel Abstract: Capacity bounds are studied for the multiple-antenna complex Gaussian relay\nchannel with t1 transmitting antennas at the sender, r2 receiving and t2\ntransmitting antennas at the relay, and r3 receiving antennas at the receiver.\nIt is shown that the partial decode-forward coding scheme achieves within\nmin(t1,r2) bits from the cutset bound and at least one half of the cutset\nbound, establishing a good approximate expression of the capacity. A similar\nadditive gap of min(t1 + t2, r3) + r2 bits is shown to be achieved by the\ncompress-forward coding scheme. \n\n"}
{"id": "1509.02190", "contents": "Title: Extended inequalities for weighted Renyi entropy involving generalized\n  Gaussian densities Abstract: In this paper the author analyses the weighted Renyi entropy in order to\nderive several inequalities in weighted case. Furthermore, using the proposed\nnotions $\\alpha$-th generalized derivation and ($\\alpha$; p)-th weighted Fisher\ninformation, extended versions of the moment-entropy, Fisher information and\nCramer-Rao inequalities in terms of generalized Gaussian densities are given. \n\n"}
{"id": "1509.04805", "contents": "Title: Energy-Efficient Cell Activation, User Association, and Spectrum\n  Allocation in Heterogeneous Networks Abstract: Next generation (5G) cellular networks are expected to be supported by an\nextensive infrastructure with many-fold increase in the number of cells per\nunit area compared to today. The total energy consumption of base transceiver\nstations (BTSs) is an important issue for both economic and environmental\nreasons. In this paper, an optimization-based framework is proposed for\nenergy-efficient global radio resource management in heterogeneous wireless\nnetworks. Specifically, with stochastic arrivals of known rates intended for\nusers, the smallest set of BTSs is activated with jointly optimized user\nassociation and spectrum allocation to stabilize the network first and then\nminimize the delay. The scheme can be carried out periodically on a relatively\nslow timescale to adapt to aggregate traffic variations and average channel\nconditions. Numerical results show that the proposed scheme significantly\nreduces the energy consumption and increases the quality of service compared to\nexisting schemes in the literature. \n\n"}
{"id": "1509.05668", "contents": "Title: Waterfilling Theorems for Linear Time-Varying Channels and Related\n  Nonstationary Sources Abstract: The capacity of the linear time-varying (LTV) channel, a continuous-time LTV\nfilter with additive white Gaussian noise, is characterized by waterfilling in\nthe time-frequency plane. Similarly, the rate distortion function for a related\nnonstationary source is characterized by reverse waterfilling in the\ntime-frequency plane. Constraints on the average energy or on the squared-error\ndistortion, respectively, are used. The source is formed by the white Gaussian\nnoise response of the same LTV filter as before. The proofs of both\nwaterfilling theorems rely on a Szego theorem for a class of operators\nassociated with the filter. A self-contained proof of the Szego theorem is\ngiven. The waterfilling theorems compare well with the classical results of\nGallager and Berger. In the case of a nonstationary source, it is observed that\nthe part of the classical power spectral density is taken by the Wigner-Ville\nspectrum. The present approach is based on the spread Weyl symbol of the LTV\nfilter, and is asymptotic in nature. For the spreading factor, a lower bound is\nsuggested by means of an uncertainty inequality. \n\n"}
{"id": "1509.08001", "contents": "Title: Approaching Single-Hop Performance in Multi-Hop Networks: End-To-End\n  Known-Interference Cancellation (E2E-KIC) Abstract: To improve the efficiency of wireless data communications, new physical-layer\ntransmission methods based on known-interference cancellation (KIC) have been\ndeveloped. These methods share the common idea that the interference can be\ncancelled when the content of it is known. Existing work on KIC mainly focuses\non single-hop or two-hop networks, with physical-layer network coding (PNC) and\nfull-duplex (FD) communications as typical examples. This paper extends the\nidea of KIC to general multi-hop networks, and proposes an end-to-end KIC\n(E2E-KIC) transmission method together with its MAC design. With E2E-KIC,\nmultiple nodes in a flow passing through a few nodes in an arbitrary topology\ncan simultaneously transmit and receive on the same channel. We first present a\ntheoretical analysis on the effectiveness of E2E-KIC in an idealized case.\nThen, to support E2E-KIC in multi-hop networks with arbitrary topology, we\npropose an E2E-KIC-supported MAC protocol (E2E-KIC MAC), which is based on an\nextension of the Request-to-Send/Clear-to-Send (RTS/CTS) mechanism in the IEEE\n802.11 MAC. We also analytically analyze the performance of the proposed\nE2E-KIC MAC in the presence of hidden terminals. Simulation results illustrate\nthat the proposed E2E-KIC MAC protocol can improve the network throughput and\nreduce the end-to-end delay. \n\n"}
{"id": "1509.08836", "contents": "Title: Experimental Demonstration of Capacity Increase and Rate-Adaptation by\n  Probabilistically Shaped 64-QAM Abstract: We implemented a flexible transmission system operating at adjustable data\nrate and fixed bandwidth, baudrate, constellation and overhead using\nprobabilistic shaping. We demonstrated in a transmission experiment up to 15%\ncapacity and 43% reach increase versus 200 Gbit/s 16-QAM. \n\n"}
{"id": "1509.09059", "contents": "Title: Message-Passing Receiver for Joint Channel Estimation and Decoding in 3D\n  Massive MIMO-OFDM Systems Abstract: In this paper, we address the message-passing receiver design for the 3D\nmassive MIMO-OFDM systems. With the aid of the central limit argument and\nTaylor-series approximation, a computationally efficient receiver that performs\njoint channel estimation and decoding is devised by the framework of\nexpectation propagation. Specially, the local belief defined at the channel\ntransition function is expanded up to the second order with Wirtinger calculus,\nto transform the messages sent by the channel transition function to a\ntractable form. As a result, the channel impulse response (CIR) between each\npair of antennas is estimated by Gaussian message passing. In addition, a\nvariational expectation-maximization (EM)-based method is derived to learn the\nchannel power-delay-profile (PDP). The proposed joint algorithm is assessed in\n3D massive MIMO systems with spatially correlated channels, and the empirical\nresults corroborate its superiority in terms of performance and complexity. \n\n"}
{"id": "1510.00252", "contents": "Title: RF Lens-Embedded Massive MIMO Systems: Fabrication Issues and Codebook\n  Design Abstract: In this paper, we investigate a radio frequency (RF) lens-embedded massive\nmultiple-input multiple-output (MIMO) system and evaluate the system\nperformance of limited feedback by utilizing a technique for generating a\nsuitable codebook for the system. We fabricate an RF lens that operates on a 77\nGHz (mmWave) band. Experimental results show a proper value of amplitude gain\nand an appropriate focusing property. In addition, using a simple numerical\ntechnique--beam propagation method (BPM)--we estimate the power profile of the\nRF lens and verify its accordance with experimental results. We also design a\ncodebook--multi-variance codebook quantization (MVCQ)--for limited feedback by\nconsidering the characteristics of the RF lens antenna for massive MIMO\nsystems. Numerical results confirm that the proposed system shows significant\nperformance enhancement over a conventional massive MIMO system without an RF\nlens. \n\n"}
{"id": "1510.00504", "contents": "Title: Stable recovery of low-dimensional cones in Hilbert spaces: One RIP to\n  rule them all Abstract: Many inverse problems in signal processing deal with the robust estimation of\nunknown data from underdetermined linear observations. Low dimensional models,\nwhen combined with appropriate regularizers, have been shown to be efficient at\nperforming this task. Sparse models with the 1-norm or low rank models with the\nnuclear norm are examples of such successful combinations. Stable recovery\nguarantees in these settings have been established using a common tool adapted\nto each case: the notion of restricted isometry property (RIP). In this paper,\nwe establish generic RIP-based guarantees for the stable recovery of cones\n(positively homogeneous model sets) with arbitrary regularizers. These\nguarantees are illustrated on selected examples. For block structured sparsity\nin the infinite dimensional setting, we use the guarantees for a family of\nregularizers which efficiency in terms of RIP constant can be controlled,\nleading to stronger and sharper guarantees than the state of the art. \n\n"}
{"id": "1510.00609", "contents": "Title: Frequency Selective Hybrid Precoding for Limited Feedback Millimeter\n  Wave Systems Abstract: Hybrid analog/digital precoding offers a compromise between hardware\ncomplexity and system performance in millimeter wave (mmWave) systems. This\ntype of precoding allows mmWave systems to leverage large antenna array gains\nthat are necessary for sufficient link margin, while permitting low cost and\npower consumption hardware. Most prior work has focused on hybrid precoding for\nnarrowband mmWave systems, with perfect or estimated channel knowledge at the\ntransmitter. MmWave systems, however, will likely operate on wideband channels\nwith frequency selectivity. Therefore, this paper considers wideband mmWave\nsystems with a limited feedback channel between the transmitter and receiver.\nFirst, the optimal hybrid precoding design for a given RF codebook is derived.\nThis provides a benchmark for any other heuristic algorithm and gives useful\ninsights into codebook designs. Second, efficient hybrid analog/digital\ncodebooks are developed for spatial multiplexing in wideband mmWave systems.\nFinally, a low-complexity yet near-optimal greedy frequency selective hybrid\nprecoding algorithm is proposed based on Gram-Schmidt orthogonalization.\nSimulation results show that the developed hybrid codebooks and precoder\ndesigns achieve very good performance compared with the unconstrained solutions\nwhile requiring much less complexity. \n\n"}
{"id": "1510.01413", "contents": "Title: BER Analysis of the box relaxation for BPSK Signal Recovery Abstract: We study the problem of recovering an $n$-dimensional vector of $\\{\\pm1\\}^n$\n(BPSK) signals from $m$ noise corrupted measurements\n$\\mathbf{y}=\\mathbf{A}\\mathbf{x}_0+\\mathbf{z}$. In particular, we consider the\nbox relaxation method which relaxes the discrete set $\\{\\pm1\\}^n$ to the convex\nset $[-1,1]^n$ to obtain a convex optimization algorithm followed by hard\nthresholding. When the noise $\\mathbf{z}$ and measurement matrix $\\mathbf{A}$\nhave iid standard normal entries, we obtain an exact expression for the\nbit-wise probability of error $P_e$ in the limit of $n$ and $m$ growing and\n$\\frac{m}{n}$ fixed. At high SNR our result shows that the $P_e$ of box\nrelaxation is within 3dB of the matched filter bound MFB for square systems,\nand that it approaches MFB as $m $ grows large compared to $n$. Our results\nalso indicates that as $m,n\\rightarrow\\infty$, for any fixed set of size $k$,\nthe error events of the corresponding $k$ bits in the box relaxation method are\nindependent. \n\n"}
{"id": "1510.05742", "contents": "Title: Joint Deployment of Small Cells and Wireless Backhaul Links in\n  Next-Generation Networks Abstract: In this paper, a novel approach for optimizing the joint deployment of small\ncell base stations and wireless backhaul links is proposed. This joint\ndeployment scenario is cast as a multi-objective optimization problem under the\nconstraints of limited backhaul capacity and outage probability. To address the\nproblem,a novel adaptive algorithm that integrates $\\epsilon$-method,\nLagrangian relaxation and tabu search is proposed to obtain the Pareto optimal\nsolution set. Simulation results show that the proposed algorithm is quite\neffective in finding the optimal solutions. The proposed joint deployment model\ncan be used for planning small cell networks. \n\n"}
{"id": "1510.06166", "contents": "Title: There is exactly one Z2Z4-cyclic 1-perfect code Abstract: Let ${\\cal C}$ be a ${\\mathbb{Z}}_2{\\mathbb{Z}}_4$-additive code of length $n\n> 3$. We prove that if the binary Gray image of ${\\cal C}$, $C=\\Phi({\\cal C})$,\nis a 1-perfect nonlinear code, then ${\\cal C}$ cannot be a\n${\\mathbb{Z}}_2{\\mathbb{Z}}_4$-cyclic code except for one case of length\n$n=15$. Moreover, we give a parity check matrix for this cyclic code. Adding an\neven parity check coordinate to a ${\\mathbb{Z}}_2{\\mathbb{Z}}_4$-additive\n1-perfect code gives an extended 1-perfect code. We also prove that any such\ncode cannot be ${\\mathbb{Z}}_2{\\mathbb{Z}}_4$-cyclic. \n\n"}
{"id": "1510.06454", "contents": "Title: Many Access for Small Packets Based on Precoding and Sparsity-aware\n  Recovery Abstract: Modern mobile terminals produce massive small data packets. For these\nshort-length packets, it is inefficient to follow the current multiple access\nschemes to allocate transmission resources due to heavy signaling overhead. We\npropose a non-orthogonal many-access scheme that is well suited for the future\ncommunication systems equipped with many receive antennas. The system is\nmodeled as having a block-sparsity pattern with unknown sparsity level (i.e.,\nunknown number of transmitted messages). Block precoding is employed at each\nsingle-antenna transmitter to enable the simultaneous transmissions of many\nusers. The number of simultaneously served active users is allowed to be even\nmore than the number of receive antennas. Sparsity-aware recovery is designed\nat the receiver for joint user detection and symbol demodulation. To reduce the\neffects of channel fading on signal recovery, normalized block orthogonal\nmatching pursuit (BOMP) algorithm is introduced, and based on its approximate\nperformance analysis, we develop interference cancellation based BOMP (ICBOMP)\nalgorithm. The ICBOMP performs error correction and detection in each iteration\nof the normalized BOMP. Simulation results demonstrate the effectiveness of the\nproposed scheme in small packet services, as well as the advantages of ICBOMP\nin improving signal recovery accuracy and reducing computational cost. \n\n"}
{"id": "1510.07865", "contents": "Title: Optimal Caching Placement for D2D Assisted Wireless Caching Networks Abstract: In this paper, we devise the optimal caching placement to maximize the\noffloading probability for a two-tier wireless caching system, where the\nhelpers and a part of users have caching ability. The offloading comes from the\nlocal caching, D2D sharing and the helper transmission. In particular, to\nmaximize the offloading probability we reformulate the caching placement\nproblem for users and helpers into a difference of convex (DC) problem which\ncan be effectively solved by DC programming. Moreover, we analyze the two\nextreme cases where there is only help-tier caching network and only user-tier.\nSpecifically, the placement problem for the helper-tier caching network is\nreduced to a convex problem, and can be effectively solved by the classical\nwater-filling method. We notice that users and helpers prefer to cache popular\ncontents under low node density and prefer to cache different contents evenly\nunder high node density. Simulation results indicate a great performance gain\nof the proposed caching placement over existing approaches. \n\n"}
{"id": "1510.07932", "contents": "Title: Downlink Power Control in Two-Tier Cellular Networks with\n  Energy-Harvesting Small Cells as Stochastic Games Abstract: Energy harvesting in cellular networks is an emerging technique to enhance\nthe sustainability of power-constrained wireless devices. This paper considers\nthe co-channel deployment of a macrocell overlaid with small cells. The small\ncell base stations (SBSs) harvest energy from environmental sources whereas the\nmacrocell base station (MBS) uses conventional power supply. Given a stochastic\nenergy arrival process for the SBSs, we derive a power control policy for the\ndownlink transmission of both MBS and SBSs such that they can achieve their\nobjectives (e.g., maintain the signal-to-interference-plus-noise ratio (SINR)\nat an acceptable level) on a given transmission channel. We consider a\ncentralized energy harvesting mechanism for SBSs, i.e., there is a central\nenergy storage (CES) where energy is harvested and then distributed to the\nSBSs. When the number of SBSs is small, the game between the CES and the MBS is\nmodeled as a single-controller stochastic game and the equilibrium policies are\nobtained as a solution of a quadratic programming problem. However, when the\nnumber of SBSs tends to infinity (i.e., a highly dense network), the\ncentralized scheme becomes infeasible, and therefore, we use a mean field\nstochastic game to obtain a distributed power control policy for each SBS. By\nsolving a system of partial differential equations, we derive the power control\npolicy of SBSs given the knowledge of mean field distribution and the available\nharvested energy levels in the batteries of the SBSs. \n\n"}
{"id": "1510.08202", "contents": "Title: Oblivious Fronthaul-Constrained Relay for a Gaussian Channel Abstract: We consider systems in which the transmitter conveys messages to the receiver\nthrough a capacity-limited relay station. The channel between the transmitter\nand the relay-station is assumed to be a frequency selective additive Gaussian\nnoise channel. It is assumed that the transmitter can shape the spectrum and\nadapt the coding technique so as to optimize performance. The relay operation\nis oblivious (nomadic transmitters), that is, the specific codebooks used are\nunknown. We find the reliable information rate that can be achieved with\nGaussian signaling in this setting, and to that end, employ Gaussian bottleneck\nresults combined with Shannon's incremental frequency approach. We also prove\nthat, unlike classical water-pouring, the allocated spectrum (power and\nbit-rate) of the optimal solution could frequently be discontinuous. These\nresults can be applied to a MIMO transmission scheme. We also investigate the\ncase of an entropy limited relay. We present lower and upper bounds on the\noptimal performance (in terms of mutual information), and derive an analytical\napproximation. \n\n"}
{"id": "1510.08592", "contents": "Title: A Lifting Construction for Scalar Linear Index Codes Abstract: This paper deals with scalar linear index codes for canonical multiple\nunicast index coding problems where there is a source with K messages and there\nare K receivers each wanting a unique message and having symmetric (with\nrespect to the receiver index) antidotes (side information). Optimal scalar\nlinear index codes for several such instances of this class of problems have\nbeen reported in \\cite{MRRarXiv}. These codes can be viewed as special cases of\nthe symmetric unicast index coding problems discussed in \\cite{MCJ}. In this\npaper a lifting construction is given which constructs a sequence of multiple\nunicast index problems starting from a given multiple unicast index coding\nproblem. Also, it is shown that if an optimal scalar linear index code is known\nfor the problem given starting problem then optimal scalar linear index codes\ncan be obtained from the known code for all the problems arising from the\nproposed lifting construction. For several of the known classes of multiple\nunicast problems our construction is used to obtain several sequences of\nmultiple unicast problem with optimal scalar linear index codes. \n\n"}
{"id": "1511.01650", "contents": "Title: Statistical physics and approximate message-passing algorithms for\n  sparse linear estimation problems in signal processing and coding theory Abstract: This thesis is interested in the application of statistical physics methods\nand inference to sparse linear estimation problems. The main tools are the\ngraphical models and approximate message-passing algorithm together with the\ncavity method. We will also use the replica method of statistical physics of\ndisordered systems which allows to associate to the studied problems a cost\nfunction referred as the potential of free entropy in physics. It allows to\npredict the different phases of typical complexity of the problem as a function\nof external parameters such as the noise level or the number of measurements\none has about the signal: the inference can be typically easy, hard or\nimpossible. We will see that the hard phase corresponds to a regime of\ncoexistence of the actual solution together with another unwanted solution of\nthe message passing equations. In this phase, it represents a metastable state\nwhich is not the true equilibrium solution. This phenomenon can be linked to\nsupercooled water blocked in the liquid state below its freezing critical\ntemperature. We will use a method that allows to overcome the metastability\nmimicing the strategy adopted by nature itself for supercooled water: the\nnucleation and spatial coupling. In supercooled water, a weak localized\nperturbation is enough to create a crystal nucleus that will propagate in all\nthe medium thanks to the physical couplings between closeby atoms. The same\nprocess will help the algorithm to find the signal, thanks to the introduction\nof a nucleus containing local information about the signal. It will then spread\nas a \"reconstruction wave\" similar to the crystal in the water. After an\nintroduction to statistical inference and sparse linear estimation, we will\nintroduce the necessary tools. Then we will move to applications of these\nnotions to signal processing and coding theory problems. \n\n"}
{"id": "1511.01953", "contents": "Title: Weighted Sum-Throughput Maximization for MIMO Broadcast Channel: Energy\n  Harvesting Under System Imperfection Abstract: In this work, a MIMO broadcast channel under the energy harvesting (EH)\nconstraint and the peak power constraint is investigated. The transmitter is\nequipped with a hybrid energy storage system consisting of a perfect super\ncapacitor (SC) and an inefficient battery, where both elements have limited\nenergy storage capacities. In addition, the effect of data processing circuit\npower consumption is also addressed. To be specific, two extreme cases are\nstudied here, where the first assumes ideal/zero circuit power consumption and\nthe second considers a positive constant circuit power consumption where the\ncircuit is always operating at its highest power level. The performance of\nthese two extreme cases hence serve as the upper bound and the lower bound of\nthe system performance in practice, respectively. In this setting, the offline\nscheduling with ideal and maximum circuit power consumptions are investigated.\nThe associated optimization problems are formulated and solved in terms of\nweighted throughput optimization. Further, we extend to a general circuit power\nconsumption model. To complement this work, some intuitive online policies are\npresented for all cases. Interestingly, for the case with maximum circuit power\nconsumption, a close-to-optimal online policy is presented and its performance\nis shown to be comparable to its offline counterpart in the numerical results. \n\n"}
{"id": "1511.02150", "contents": "Title: A Split-Reduced Successive Cancellation List Decoder for Polar Codes Abstract: This paper focuses on low complexity successive cancellation list (SCL)\ndecoding of polar codes. In particular, using the fact that splitting may be\nunnecessary when the reliability of decoding the unfrozen bit is sufficiently\nhigh, a novel splitting rule is proposed. Based on this rule, it is conjectured\nthat, if the correct path survives at some stage, it tends to survive till\ntermination without splitting with high probability. On the other hand, the\nincorrect paths are more likely to split at the following stages. Motivated by\nthese observations, a simple counter that counts the successive number of\nstages without splitting is introduced for each decoding path to facilitate the\nidentification of correct and incorrect path. Specifically, any path with\ncounter value larger than a predefined threshold \\omega is deemed to be the\ncorrect path, which will survive at the decoding stage, while other paths with\ncounter value smaller than the threshold will be pruned, thereby reducing the\ndecoding complexity. Furthermore, it is proved that there exists a unique\nunfrozen bit u_{N-K_1+1}, after which the successive cancellation decoder\nachieves the same error performance as the maximum likelihood decoder if all\nthe prior unfrozen bits are correctly decoded, which enables further complexity\nreduction. Simulation results demonstrate that the proposed low complexity SCL\ndecoder attains performance similar to that of the conventional SCL decoder,\nwhile achieving substantial complexity reduction. \n\n"}
{"id": "1511.02307", "contents": "Title: On the Capacity Achieving Probability Measures for Molecular Receivers Abstract: In this paper, diffusion-based molecular commu- nication with ligand receptor\nreceivers is studied. Information messages are assumed to be encoded via\nvariations of the con- centration of molecules. The randomness in the ligand\nreception process induces uncertainty in the communication; limiting the rate\nof information decoding. We model the ligand receptor receiver by a set of\nfinite-state Markov channels and study the general capacity of such a receiver.\nFurthermore, the i.i.d. capacity of the receiver is characterized as a lower\nbound for the general capacity. It is also proved that a finite support\nprobability measure can achieve the i.i.d. capacity of the receiver. Moreover,\na bound on the number of points in the support of the probability measure is\nobtained. \n\n"}
{"id": "1511.05201", "contents": "Title: The capacity of Bernoulli nonadaptive group testing Abstract: We consider nonadaptive group testing with Bernoulli tests, where each item\nis placed in each test independently with some fixed probability. We give a\ntight threshold on the maximum number of tests required to find the defective\nset under optimal Bernoulli testing. Achievability is given by a result of\nScarlett and Cevher; here we give a converse bound showing that this result is\nbest possible. Our new converse requires three parts: a typicality bound\ngeneralising the trivial counting bound, a converse on the COMP algorithm of\nChan et al, and a bound on the SSS algorithm similar to that given by Aldridge,\nBaldassini, and Johnson. Our result has a number of important corollaries, in\nparticular that, in denser cases, Bernoulli nonadaptive group testing is\nstrictly worse than the best adaptive strategies. \n\n"}
{"id": "1511.06146", "contents": "Title: RIP-like Properties in Subsampled Blind Deconvolution Abstract: We derive near optimal performance guarantees for subsampled blind\ndeconvolution. Blind deconvolution is an ill-posed bilinear inverse problem and\nadditional subsampling makes the problem even more challenging. Sparsity and\nspectral flatness priors on unknown signals are introduced to overcome these\ndifficulties. While being crucial for deriving desired near optimal performance\nguarantees, unlike the sparsity prior with a nice union-of-subspaces structure,\nthe spectral flatness prior corresponds to a nonconvex cone structure, which is\nnot preserved by elementary set operations. This prohibits the operator arising\nin subsampled blind deconvolution from satisfying the standard restricted\nisometry property (RIP) at near optimal sample complexity, which motivated us\nto study other RIP-like properties. Combined with the performance guarantees\nderived using these RIP-like properties in a companion paper, we show that\nsubsampled blind deconvolution is provably solved at near optimal sample\ncomplexity by a practical algorithm. \n\n"}
{"id": "1511.06266", "contents": "Title: Semi-dynamic Green Resource Management in Downlink Heterogeneous\n  Networks by Group Sparse Power Control Abstract: This paper addresses the energy-saving problem for the downlink of\nheterogeneous networks, which aims at minimizing the total base stations (BSs)\npower consumption while each user's rate requirement is supported. The basic\nidea of this work is to make use of the flexibility and scalability of the\nsystem such that more benefits can be gained by efficient resource management.\nThis motivates us to propose a flexible BS power consumption model, which can\ncontrol system resources, such as antennas, frequency carriers and transmit\npower allocation in an energy efficient manner rather than the \"on/off\" binary\nsleep mode for BSs. To denote these power-saving modes, we employ the group\nsparsity of the transmit power vector instead of the {0, 1} variables. Based on\nthis power model, a semi-dynamic green resource management mechanism is\nproposed, which can jointly solve a series of resource management problems,\nincluding BS association, frequency carriers (FCs) assignment, and the transmit\npower allocation, by group sparse power control based on the large scale fading\nvalues. In particular, the successive convex approximation (SCA)-based\nalgorithm is applied to solve a stationary solution to the original non-convex\nproblem. Simulation results also verify the proposed BS power model and the\ngreen resource management mechanism. \n\n"}
{"id": "1511.07542", "contents": "Title: Caching-Aided Coded Multicasting with Multiple Random Requests Abstract: The capacity of caching networks has received considerable attention in the\npast few years. A particularly studied setting is the shared link caching\nnetwork, in which a single source with access to a file library communicates\nwith multiple users, each having the capability to store segments (packets) of\nthe library files, over a shared multicast link. Each user requests one file\nfrom the library according to a common demand distribution and the server sends\na coded multicast message to satisfy all users at once. The problem consists of\nfinding the smallest possible average codeword length to satisfy such requests.\nIn this paper, we consider the generalization to the case where each user\nplaces L >= 1 independent requests according to the same common demand\ndistribution. We propose an achievable scheme based on random vector\n(packetized) caching placement and multiple groupcast index coding, shown to be\norder-optimal in the asymptotic regime in which the number of packets per file\nB goes to infinity. We then show that the scalar (B = 1) version of the\nproposed scheme can still preserve order-optimality when the number of per-user\nrequests L is large enough. Our results provide the first order-optimal\ncharacterization of the shared link caching network with multiple random\nrequests, revealing the key effects of L on the performance of caching-aided\ncoded multicast schemes. \n\n"}
{"id": "1511.07568", "contents": "Title: Multi-Cell Multiuser Massive MIMO Networks: User Capacity Analysis and\n  Pilot Design Abstract: We propose a novel pilot sequence design to mitigate pilot contamination in\nmulti-cell multiuser massive multiple-input multiple-output networks. Our\nproposed design generates pilot sequences in the multi-cell network and devises\npower allocation at base stations (BSs) for downlink transmission. The pilot\nsequences together with the power allocation ensure that the user capacity of\nthe network is achieved and the pre-defined signal-to-interference-plus-noise\nratio (SINR) requirements of all users are met. To realize our design, we first\nderive new closed-form expressions for the user capacity and the user capacity\nregion. Built upon these expressions, we then develop a new algorithm to obtain\nthe required pilot sequences and power allocation. We further determine the\nminimum number of antennas required at BSs to achieve certain SINR requirements\nof all users. Numerical results are presented to corroborate our analysis and\nto examine the impact of key parameters, such as the pilot sequence length and\nthe total number of users, on the network performance. A pivotal conclusion is\nreached that our design achieves a larger user capacity region than the\nexisting designs and needs less antennas at the BS to fulfill the pre-defined\nSINR requirements of all users in the network than the existing designs. \n\n"}
{"id": "1511.08084", "contents": "Title: Layered Downlink Precoding for C-RAN Systems with Full Dimensional MIMO Abstract: The implementation of a Cloud Radio Access Network (C-RAN) with Full\nDimensional (FD)-MIMO is faced with the challenge of controlling the fronthaul\noverhead for the transmission of baseband signals as the number of horizontal\nand vertical antennas grows larger. This work proposes to leverage the special\nlow-rank structure of FD-MIMO channel, which is characterized by a\ntime-invariant elevation component and a time-varying azimuth component, by\nmeans of a layered precoding approach, so as to reduce the fronthaul overhead.\nAccording to this scheme, separate precoding matrices are applied for the\nazimuth and elevation channel components, with different rates of adaptation to\nthe channel variations and correspondingly different impacts on the fronthaul\ncapacity. Moreover, we consider two different Central Unit (CU) - Radio Unit\n(RU) functional splits at the physical layer, namely the conventional C-RAN\nimplementation and an alternative one in which coding and precoding are\nperformed at the RUs. Via numerical results, it is shown that the layered\nschemes significantly outperform conventional non-layered schemes, especially\nin the regime of low fronthaul capacity and large number of vertical antennas. \n\n"}
{"id": "1511.08975", "contents": "Title: Compressive Sampling using Annihilating Filter-based Low-Rank\n  Interpolation Abstract: While the recent theory of compressed sensing provides an opportunity to\novercome the Nyquist limit in recovering sparse signals, a solution approach\nusually takes a form of inverse problem of the unknown signal, which is\ncrucially dependent on specific signal representation. In this paper, we\npropose a drastically different two-step Fourier compressive sampling framework\nin continuous domain that can be implemented as a measurement domain\ninterpolation, after which a signal reconstruction can be done using classical\nanalytic reconstruction methods. The main idea is originated from the\nfundamental duality between the sparsity in the primary space and the\nlow-rankness of a structured matrix in the spectral domain, which shows that a\nlow-rank interpolator in the spectral domain can enjoy all the benefit of\nsparse recovery with performance guarantees. Most notably, the proposed\nlow-rank interpolation approach can be regarded as a generalization of recent\nspectral compressed sensing to recover large class of finite rate of\ninnovations (FRI) signals at near optimal sampling rate. Moreover, for the case\nof cardinal representation, we can show that the proposed low-rank\ninterpolation will benefit from inherent regularization and the optimal\nincoherence parameter. Using the powerful dual certificates and golfing scheme,\nwe show that the new framework still achieves the near-optimal sampling rate\nfor general class of FRI signal recovery, and the sampling rate can be further\nreduced for the class of cardinal splines. Numerical results using various type\nof FRI signals confirmed that the proposed low-rank interpolation approach has\nsignificant better phase transition than the conventional CS approaches. \n\n"}
{"id": "1512.01290", "contents": "Title: On the Feasibility of Sharing Spectrum Licenses in mmWave Cellular\n  Systems Abstract: The highly directional and adaptive antennas used in mmWave communication\nopen up the possibility of uncoordinated sharing of spectrum licenses between\ncommercial cellular operators. There are several advantages to sharing\nincluding a reduction in license costs and an increase in spectrum utilization.\nIn this paper, we establish the theoretical feasibility of spectrum license\nsharing among mmWave cellular operators. We consider a heterogeneous\nmulti-operator system containing multiple independent cellular networks, each\nowned by an operator. We then compute the SINR and rate distribution for\ndownlink mobile users of each network. Using the analysis, we compare systems\nwith fully shared licenses and exclusive licenses for different access rules\nand explore the trade-offs between system performance and spectrum cost. We\nshow that sharing spectrum licenses increases the per-user rate when antennas\nhave narrow beams and is also favored when there is a low density of users. We\nalso consider a multi-operator system where BSs of all the networks are\nco-located to show that the simultaneous sharing of spectrum and infrastructure\nis also feasible. We show that all networks can share licenses with less\nbandwidth and still achieve the same per-user median rate as if they each had\nan exclusive license to spectrum with more bandwidth. \n\n"}
{"id": "1512.01907", "contents": "Title: An algorithm to compute CVTs for finitely generated Cantor distributions Abstract: Centroidal Voronoi tessellations (CVTs) are Voronoi tessellations of a region\nsuch that the generating points of the tessellations are also the centroids of\nthe corresponding Voronoi regions with respect to a given probability measure.\nCVT is a fundamental notion that has a wide spectrum of applications in\ncomputational science and engineering. In this paper, an algorithm is given to\nobtain the CVTs with $n$-generators to level $m$, for any positive integers $m$\nand $n$, of any Cantor set generated by a pair of self-similar mappings given\nby $S_1(x)=r_1x$ and $S_2(x)=r_2x+(1-r_2)$ for $x\\in \\mathbb R$, where $r_1,\nr_2>0$ and $r_1+r_2<1$, with respect to any probability distribution $P$ such\nthat $P=p_1 P\\circ S_1^{-1}+p_2 P\\circ S_2^{-1}$, where $p_1, p_2>0$ and\n$p_1+p_2=1$. \n\n"}
{"id": "1512.02515", "contents": "Title: Projection Theorems for the R\\'enyi Divergence on $\\alpha$-Convex Sets Abstract: This paper studies forward and reverse projections for the R\\'{e}nyi\ndivergence of order $\\alpha \\in (0, \\infty)$ on $\\alpha$-convex sets. The\nforward projection on such a set is motivated by some works of Tsallis {\\em et\nal.} in statistical physics, and the reverse projection is motivated by robust\nstatistics. In a recent work, van Erven and Harremo\\\"es proved a Pythagorean\ninequality for R\\'{e}nyi divergences on $\\alpha$-convex sets under the\nassumption that the forward projection exists. Continuing this study, a\nsufficient condition for the existence of forward projection is proved for\nprobability measures on a general alphabet. For $\\alpha \\in (1, \\infty)$, the\nproof relies on a new Apollonius theorem for the Hellinger divergence, and for\n$\\alpha \\in (0,1)$, the proof relies on the Banach-Alaoglu theorem from\nfunctional analysis. Further projection results are then obtained in the finite\nalphabet setting. These include a projection theorem on a specific\n$\\alpha$-convex set, which is termed an {\\em $\\alpha$-linear family},\ngeneralizing a result by Csisz\\'ar for $\\alpha \\neq 1$. The solution to this\nproblem yields a parametric family of probability measures which turns out to\nbe an extension of the exponential family, and it is termed an {\\em\n$\\alpha$-exponential family}. An orthogonality relationship between the\n$\\alpha$-exponential and $\\alpha$-linear families is established, and it is\nused to turn the reverse projection on an $\\alpha$-exponential family into a\nforward projection on a $\\alpha$-linear family. This paper also proves a\nconvergence result of an iterative procedure used to calculate the forward\nprojection on an intersection of a finite number of $\\alpha$-linear families. \n\n"}
{"id": "1512.03324", "contents": "Title: Mapping the Region of Entropic Vectors with Support Enumeration &\n  Information Geometry Abstract: The region of entropic vectors is a convex cone that has been shown to be at\nthe core of many fundamental limits for problems in multiterminal data\ncompression, network coding, and multimedia transmission. This cone has been\nshown to be non-polyhedral for four or more random variables, however its\nboundary remains unknown for four or more discrete random variables. Methods\nfor specifying probability distributions that are in faces and on the boundary\nof the convex cone are derived, then utilized to map optimized inner bounds to\nthe unknown part of the entropy region. The first method utilizes tools and\nalgorithms from abstract algebra to efficiently determine those supports for\nthe joint probability mass functions for four or more random variables that\ncan, for some appropriate set of non-zero probabilities, yield entropic vectors\nin the gap between the best known inner and outer bounds. These supports are\nutilized, together with numerical optimization over non-zero probabilities, to\nprovide inner bounds to the unknown part of the entropy region. Next,\ninformation geometry is utilized to parameterize and study the structure of\nprobability distributions on these supports yielding entropic vectors in the\nfaces of entropy and in the unknown part of the entropy region. \n\n"}
{"id": "1512.04243", "contents": "Title: Trigonometric dictionary based codec for music compression with high\n  quality recovery Abstract: A codec for compression of music signals is proposed. The method belongs to\nthe class of transform lossy compression. It is conceived to be applied in the\nhigh quality recovery range though. The transformation, endowing the codec with\nits distinctive feature, relies on the ability to construct high quality sparse\napproximation of music signals. This is achieved by a redundant trigonometric\ndictionary and a dedicated pursuit strategy. The potential of the approach is\nillustrated by comparison with the OGG Vorbis format, on a sample consisting of\nclips of melodic music. The comparison evidences remarkable improvements in\ncompression performance for the identical quality of the decompressed signal. \n\n"}
{"id": "1512.07103", "contents": "Title: A Class of Linear Codes with a Few Weights Abstract: Linear codes have been an interesting subject of study for many years, as\nlinear codes with few weights have applications in secrete sharing,\nauthentication codes, association schemes, and strongly regular graphs. In this\npaper, a class of linear codes with a few weights over the finite field\n$\\gf(p)$ are presented and their weight distributions are also determined,\nwhere $p$ is an odd prime. Some of the linear codes obtained are optimal in the\nsense that they meet certain bounds on linear codes. \n\n"}
{"id": "1512.07735", "contents": "Title: Communication and Randomness Lower Bounds for Secure Computation Abstract: In secure multiparty computation (MPC), mutually distrusting users\ncollaborate to compute a function of their private data without revealing any\nadditional information about their data to other users. While it is known that\ninformation theoretically secure MPC is possible among $n$ users (connected by\nsecure and noiseless links and have access to private randomness) against the\ncollusion of less than $n/2$ users in the honest-but-curious model, relatively\nless is known about the communication and randomness complexity of secure\ncomputation.\n  In this work, we employ information theoretic techniques to obtain lower\nbounds on the amount of communication and randomness required for secure MPC.\nWe restrict ourselves to a concrete interactive setting involving 3 users under\nwhich all functions are securely computable against corruption of a single user\nin the honest-but-curious model. We derive lower bounds for both the perfect\nsecurity case (i.e., zero-error and no leakage of information) and asymptotic\nsecurity (where the probability of error and information leakage vanish as\nblock-length goes to $\\infty$).\n  Our techniques include the use of a data processing inequality for residual\ninformation (i.e., the gap between mutual information and G\\'acs-K\\\"orner\ncommon information), a new information inequality for 3-user protocols, and the\nidea of distribution switching. Our lower bounds are shown to be tight for\nvarious functions of interest. In particular, we show concrete functions which\nhave \"communication-ideal\" protocols, i.e., which achieve the minimum\ncommunication simultaneously on all links in the network, and also use minimum\namount of randomness. Also, we obtain the first explicit example of a function\nthat incurs a higher communication cost than the input length in the secure\ncomputation model of \"Feige, Kilian, and Naor [STOC, 1994]\", who had shown that\nsuch functions exist. \n\n"}
{"id": "1512.08309", "contents": "Title: Identifying Seizure Onset Zone from the Causal Connectivity Inferred\n  Using Directed Information Abstract: In this paper, we developed a model-based and a data-driven estimator for\ndirected information (DI) to infer the causal connectivity graph between\nelectrocorticographic (ECoG) signals recorded from brain and to identify the\nseizure onset zone (SOZ) in epileptic patients. Directed information, an\ninformation theoretic quantity, is a general metric to infer causal\nconnectivity between time-series and is not restricted to a particular class of\nmodels unlike the popular metrics based on Granger causality or transfer\nentropy. The proposed estimators are shown to be almost surely convergent.\nCausal connectivity between ECoG electrodes in five epileptic patients is\ninferred using the proposed DI estimators, after validating their performance\non simulated data. We then proposed a model-based and a data-driven SOZ\nidentification algorithm to identify SOZ from the causal connectivity inferred\nusing model-based and data-driven DI estimators respectively. The data-driven\nSOZ identification outperforms the model-based SOZ identification algorithm\nwhen benchmarked against visual analysis by neurologist, the current clinical\ngold standard. The causal connectivity analysis presented here is the first\nstep towards developing novel non-surgical treatments for epilepsy. \n\n"}
{"id": "1601.01502", "contents": "Title: The Expurgation-Augmentation Method for Constructing Good Plane Subspace\n  Codes Abstract: As shown in [28], one of the five isomorphism types of optimal binary\nsubspace codes of size 77 for packet length v=6, constant dimension k=3 and\nminimum subspace distance d=4 can be constructed by first expurgating and then\naugmenting the corresponding lifted Gabidulin code in a fairly simple way. The\nmethod was refined in [32,26] to yield an essentially computer-free\nconstruction of a currently best-known plane subspace code of size 329 for\n(v,k,d)=(7,3,4). In this paper we generalize the expurgation-augmentation\napproach to arbitrary packet length v, providing both a detailed theoretical\nanalysis of our method and computational results for small parameters. As it\nturns out, our method is capable of producing codes larger than those obtained\nby the echelon-Ferrers construction and its variants. We are able to prove this\nobservation rigorously for packet lengths v = 3 mod 4. \n\n"}
{"id": "1601.03712", "contents": "Title: Super-Resolution of Complex Exponentials from Modulations with Unknown\n  Waveforms Abstract: Super-resolution is generally referred to as the task of recovering fine\ndetails from coarse information. Motivated by applications such as\nsingle-molecule imaging, radar imaging, etc., we consider parameter estimation\nof complex exponentials from their modulations with unknown waveforms, allowing\nfor non-stationary blind super-resolution. This problem, however, is ill-posed\nsince both the parameters associated with the complex exponentials and the\nmodulating waveforms are unknown. To alleviate this, we assume that the unknown\nwaveforms live in a common low-dimensional subspace. Using a lifting trick, we\nrecast the blind super-resolution problem as a structured low-rank matrix\nrecovery problem. Atomic norm minimization is then used to enforce the\nstructured low-rankness, and is reformulated as a semidefinite program that is\nsolvable in polynomial time. We show that, up to scaling ambiguities, exact\nrecovery of both of the complex exponential parameters and the unknown\nwaveforms is possible when the waveform subspace is random and the number of\nmeasurements is proportional to the number of degrees of freedom in the\nproblem. Numerical simulations support our theoretical findings, showing that\nnon-stationary blind super-resolution using atomic norm minimization is\npossible. \n\n"}
{"id": "1601.03793", "contents": "Title: Stochastic Geometry Analysis of Multi-Antenna Two-Tier Cellular Networks Abstract: In this paper, we study the key properties of multi-antenna two-tier networks\nunder different system configurations. Based on stochastic geometry, we derive\nthe expressions and approximations for the users' average data rate. Through\nthe more tractable approximations, the theoretical analysis can be greatly\nsimplified. We find that the differences in density and transmit power between\ntwo tiers, together with range expansion bias significantly affect the users'\ndata rate. Besides, for the purpose of area spectral efficiency (ASE)\nmaximization, we find that the optimal number of active users for each tier is\napproximately fixed portion of the sum of the number of antennas plus one.\nInterestingly, the optimal settings are insensitive to different configurations\nbetween two tiers. Last but not the least, if the number of antennas of macro\nbase stations (MBSs) is sufficiently larger than that of small cell base\nstations (SBSs), we find that range expansion will improve ASE. \n\n"}
{"id": "1601.04453", "contents": "Title: Some results of linear codes over the ring\n  $\\mathbb{Z}_4+u\\mathbb{Z}_4+v\\mathbb{Z}_4+uv\\mathbb{Z}_4$ Abstract: In this paper, we mainly study the theory of linear codes over the ring $R\n=\\mathbb{Z}_4+u\\mathbb{Z}_4+v\\mathbb{Z}_4+uv\\mathbb{Z}_4$. By the Chinese\nRemainder Theorem, we have $R$ is isomorphic to the direct sum of four rings\n$\\mathbb{Z}_4$. We define a Gray map $\\Phi$ from $R^{n}$ to\n$\\mathbb{Z}_4^{4n}$, which is a distance preserving map. The Gray image of a\ncyclic code over $R^{n}$ is a linear code over $\\mathbb{Z}_4$. Furthermore, we\nstudy the MacWilliams identities of linear codes over $R$ and give the the\ngenerator polynomials of cyclic codes over $R$. Finally, we discuss some\nproperties of MDS codes over $R$. \n\n"}
{"id": "1601.04689", "contents": "Title: Reed-Muller Codes Achieve Capacity on Erasure Channels Abstract: We introduce a new approach to proving that a sequence of deterministic\nlinear codes achieves capacity on an erasure channel under maximum a posteriori\ndecoding. Rather than relying on the precise structure of the codes our method\nexploits code symmetry. In particular, the technique applies to any sequence of\nlinear codes where the blocklengths are strictly increasing, the code rates\nconverge, and the permutation group of each code is doubly transitive. In other\nwords, we show that symmetry alone implies near-optimal performance.\n  An important consequence of this result is that a sequence of Reed-Muller\ncodes with increasing blocklength and converging rate achieves capacity. This\npossibility has been suggested previously in the literature but it has only\nbeen proven for cases where the limiting code rate is 0 or 1. Moreover, these\nresults extend naturally to all affine-invariant codes and, thus, to extended\nprimitive narrow-sense BCH codes. This also resolves, in the affirmative, the\nexistence question for capacity-achieving sequences of binary cyclic codes. The\nprimary tools used in the proof are the sharp threshold property for symmetric\nmonotone boolean functions and the area theorem for extrinsic information\ntransfer functions. \n\n"}
{"id": "1601.04884", "contents": "Title: Z2-Triple cyclic codes and their duals Abstract: A Z2-triple cyclic code of block length (r,s,t) is a binary code of length\nr+s+t such that the code is partitioned into three parts of lengthsr,s andt\nsuch that each of the three parts is invariant under the cyclic shifts of the\ncoordinates. Such a code can be viewed as Z2[x]-submodules of\nZ_2[x]/<x^r-1>xZ_2[x]/<x^s-1>xZ_2[x]/<x^t-1>, in polynomial representation. In\nthis paper, we determine the structure of these codes. We have obtained the\nform of the generators for such codes. Further, a minimal generating set for\nsuch a code is obtained. Also, we study the structure of the duals of these\ncodes via the generators of the codes. \n\n"}
{"id": "1601.05563", "contents": "Title: Unconstrained distillation capacities of a pure-loss bosonic broadcast\n  channel Abstract: Bosonic channels are important in practice as they form a simple model for\nfree-space or fiber-optic communication. Here we consider a single-sender\ntwo-receiver pure-loss bosonic broadcast channel and determine the\nunconstrained capacity region for the distillation of bipartite entanglement\nand secret key between the sender and each receiver, whenever they are allowed\narbitrary public classical communication. We show how the state merging\nprotocol leads to achievable rates in this setting, giving an inner bound on\nthe capacity region. We also evaluate an outer bound on the region by using the\nrelative entropy of entanglement and a `reduction by teleportation' technique.\nThe outer bounds match the inner bounds in the infinite-energy limit, thereby\nestablishing the unconstrained capacity region for such channels. Our result\ncould provide a useful benchmark for implementing a broadcasting of\nentanglement and secret key through such channels. An important open question\nrelevant to practice is to determine the capacity region in both this setting\nand the single-sender single-receiver case when there is an energy constraint\non the transmitter. \n\n"}
{"id": "1601.05880", "contents": "Title: A Beta-Beta Achievability Bound with Applications Abstract: A channel coding achievability bound expressed in terms of the ratio between\ntwo Neyman-Pearson $\\beta$ functions is proposed. This bound is the dual of a\nconverse bound established earlier by Polyanskiy and Verd\\'{u} (2014). The new\nbound turns out to simplify considerably the analysis in situations where the\nchannel output distribution is not a product distribution, for example due to a\ncost constraint or a structural constraint (such as orthogonality or constant\ncomposition) on the channel inputs. Connections to existing bounds in the\nliterature are discussed. The bound is then used to derive 1) an achievability\nbound on the channel dispersion of additive non-Gaussian noise channels with\nrandom Gaussian codebooks, 2) the channel dispersion of the exponential-noise\nchannel, 3) a second-order expansion for the minimum energy per bit of an AWGN\nchannel, and 4) a lower bound on the maximum coding rate of a multiple-input\nmultiple-output Rayleigh-fading channel with perfect channel state information\nat the receiver, which is the tightest known achievability result. \n\n"}
{"id": "1601.05921", "contents": "Title: Edge Agreement of Second-order Multi-agent System with Dynamic\n  Quantization via Directed Edge Laplacian Abstract: This work explores the edge agreement problem of second-order multi-agent\nsystem with dynamic quantization under directed communication. To begin with,\nby virtue of the directed edge laplacian, we derive a model reduction\nrepresentation of the closed-loop multi-agent system depended on the spanning\ntree subgraph. Considering the limitations of the finite bandwidth channels,\nthe quantization effects of second-order multi-agent system under directed\ngraph are considered. Motivated by the observation that the static quantizer\nalways lead to the practical stability rather than the asymptotic stability,\nthe dynamic quantized communication strategy referring to the rooming\nin-rooming out scheme is employed. Based on the reduced model associated with\nthe essential edge Laplacian, the asymptotic stability of second-order\nmulti-agent system under dynamic quantized effects with only finite\nquantization level can be guaranteed. Finally, simulation results are provided\nto verify the theoretical analysis. \n\n"}
{"id": "1601.06016", "contents": "Title: Multi-Library Coded Caching Abstract: We study the problem of coded caching when the server has access to several\nlibraries and each user makes independent requests from every library. The\nsingle-library scenario has been well studied and it has been proved that coded\ncaching can significantly improve the delivery rate compared to uncoded\ncaching. In this work we show that when all the libraries have the same number\nof files, memory-sharing is optimal and the delivery rate cannot be improved\nvia coding across files from different libraries. In this setting, the optimal\nmemory-sharing strategy is one that divides the cache of each user proportional\nto the size of the files in different libraries. As for the general case, when\nthe number of files in different libraries are arbitrary, we propose an\ninner-bound based on memory-sharing and an outer-bound based on concatenation\nof files from different libraries. \n\n"}
{"id": "1601.06412", "contents": "Title: A New Information Theoretical Concept: Information-Weighted Heavy-tailed\n  Distributions Abstract: Given an arbitrary continuous probability density function, it is introduced\na conjugated probability density, which is defined through the Shannon\ninformation associated with its cumulative distribution function. These new\ndensities are computed from a number of standard distributions, including\nuniform, normal, exponential, Pareto, logistic, Kumaraswamy, Rayleigh, Cauchy,\nWeibull, and Maxwell-Boltzmann. The case of joint information-weighted\nprobability distribution is assessed. An additive property is derived in the\ncase of independent variables. One-sided and two-sided information-weighting\nare considered. The asymptotic behavior of the tail of the new distributions is\nexamined. It is proved that all probability densities proposed here define\nheavy-tailed distributions. It is shown that the weighting of distributions\nregularly varying with extreme-value index $\\alpha > 0$ still results in a\nregular variation distribution with the same index. This approach can be\nparticularly valuable in applications where the tails of the distribution play\na major role. \n\n"}
{"id": "1601.06978", "contents": "Title: On Media-based Modulation using RF Mirrors Abstract: Media-based modulation (MBM) is a recently proposed modulation scheme which\nuses radio frequency (RF) mirrors at the transmit antenna(s) in order to create\ndifferent channel fade realizations based on their ON/OFF status. These complex\nfade realizations constitute the modulation alphabet. MBM has the advantage of\nincreased spectral efficiency and performance. In this paper, we investigate\nthe performance of some physical layer techniques when applied to MBM.\nParticularly, we study the performance of $i)$ MBM with generalized spatial\nmodulation (GSM), $ii)$ MBM with mirror activation pattern (MAP) selection\nbased on an Euclidean distance (ED) based metric, and $iii)$ MBM with feedback\nbased phase compensation and constellation rotation. Our results show that, for\nthe same spectral efficiency, GSM-MBM can achieve better performance compared\nto MIMO-MBM. Also, it is found that MBM with ED-based MAP selection results in\nimproved bit error performance, and that phase compensation and MBM\nconstellation rotation increases the ED between the MBM constellation points\nand improves the performance significantly. We also analyze the diversity\norders achieved by the ED-based MAP selection scheme and the phase compensation\nand constellation rotation (PC-CR) scheme. The diversity orders predicted by\nthe analysis are validated through simulations. \n\n"}
{"id": "1601.07024", "contents": "Title: Asymptotic analysis of downlink MIMO systems over Rician fading channels Abstract: In this work, we focus on the ergodic sum rate in the downlink of a\nsingle-cell large-scale multi-user MIMO system in which the base station\nemploys N antennas to communicate with $K$ single-antenna user equipments. A\nregularized zero-forcing (RZF) scheme is used for precoding under the\nassumption that each link forms a spatially correlated MIMO Rician fading\nchannel. The analysis is conducted assuming $N$ and $K$ grow large with a non\ntrivial ratio and perfect channel state information is available at the base\nstation. Recent results from random matrix theory and large system analysis are\nused to compute an asymptotic expression of the signal-to-interference-\nplus-noise ratio as a function of the system parameters, the spatial\ncorrelation matrix and the Rician factor. Numerical results are used to\nevaluate the performance gap in the finite system regime under different\noperating conditions. \n\n"}
{"id": "1601.07865", "contents": "Title: Grid Energy Consumption and QoS Tradeoff in Hybrid Energy Supply\n  Wireless Networks Abstract: Hybrid energy supply (HES) wireless networks have recently emerged as a new\nparadigm to enable green networks, which are powered by both the electric grid\nand harvested renewable energy. In this paper, we will investigate two critical\nbut conflicting design objectives of HES networks, i.e., the grid energy\nconsumption and quality of service (QoS). Minimizing grid energy consumption by\nutilizing the harvested energy will make the network environmentally friendly,\nbut the achievable QoS may be degraded due to the intermittent nature of energy\nharvesting. To investigate the tradeoff between these two aspects, we introduce\nthe total service cost as the performance metric, which is the weighted sum of\nthe grid energy cost and the QoS degradation cost. Base station assignment and\npower control is adopted as the main strategy to minimize the total service\ncost, while both cases with non-causal and causal side information are\nconsidered. With non-causal side information, a Greedy Assignment algorithm\nwith low complexity and near-optimal performance is proposed. With causal side\ninformation, the design problem is formulated as a discrete Markov decision\nproblem. Interesting solution structures are derived, which shall help to\ndevelop an efficient monotone backward induction algorithm. To further reduce\ncomplexity, a Look-Ahead policy and a Threshold-based Heuristic policy are also\nproposed. Simulation results shall validate the effectiveness of the proposed\nalgorithms and demonstrate the unique grid energy consumption and QoS tradeoff\nin HES networks. \n\n"}
{"id": "1602.01716", "contents": "Title: Decentralized Prediction-Correction Methods for Networked Time-Varying\n  Convex Optimization Abstract: We develop algorithms that find and track the optimal solution trajectory of\ntime-varying convex optimization problems which consist of local and\nnetwork-related objectives. The algorithms are derived from the\nprediction-correction methodology, which corresponds to a strategy where the\ntime-varying problem is sampled at discrete time instances and then a sequence\nis generated via alternatively executing predictions on how the optimizers at\nthe next time sample are changing and corrections on how they actually have\nchanged. Prediction is based on how the optimality conditions evolve in time,\nwhile correction is based on a gradient or Newton method, leading to\nDecentralized Prediction-Correction Gradient (DPC-G) and Decentralized\nPrediction-Correction Newton (DPC-N). We extend these methods to cases where\nthe knowledge on how the optimization programs are changing in time is only\napproximate and propose Decentralized Approximate Prediction-Correction\nGradient (DAPC-G) and Decentralized Approximate Prediction-Correction Newton\n(DAPC-N). Convergence properties of all the proposed methods are studied and\nempirical performance is shown on an application of a resource allocation\nproblem in a wireless network. We observe that the proposed methods outperform\nexisting running algorithms by orders of magnitude. The numerical results\nshowcase a trade-off between convergence accuracy, sampling period, and network\ncommunications. \n\n"}
{"id": "1602.02648", "contents": "Title: Coding in the fork network in the framework of Kolmogorov complexity Abstract: Many statements from the classic information theory (the theory of Shannon's\nentropy) have natural counterparts in the algorithmic information theory (in\nthe framework of Kolmogorov complexity). In this paper we discuss one simple\ninstance of the parallelism between Shannon's and Kolmogorov's theories: we\nprove in the setting of Kolmogorov complexity a version of Wolf's\ncharacterization of admissible rates for the fork network. \n\n"}
{"id": "1602.02673", "contents": "Title: On Sparsity by NUV-EM, Gaussian Message Passing, and Kalman Smoothing Abstract: Normal priors with unknown variance (NUV) have long been known to promote\nsparsity and to blend well with parameter learning by expectation maximization\n(EM). In this paper, we advocate this approach for linear state space models\nfor applications such as the estimation of impulsive signals, the detection of\nlocalized events, smoothing with occasional jumps in the state space, and the\ndetection and removal of outliers. The actual computations boil down to\nmultivariate-Gaussian message passing algorithms that are closely related to\nKalman smoothing. We give improved tables of Gaussian-message computations from\nwhich such algorithms are easily synthesized, and we point out two preferred\nsuch algorithms. \n\n"}
{"id": "1602.02737", "contents": "Title: Low-Rank Positive Semidefinite Matrix Recovery from Corrupted Rank-One\n  Measurements Abstract: We study the problem of estimating a low-rank positive semidefinite (PSD)\nmatrix from a set of rank-one measurements using sensing vectors composed of\ni.i.d. standard Gaussian entries, which are possibly corrupted by arbitrary\noutliers. This problem arises from applications such as phase retrieval,\ncovariance sketching, quantum space tomography, and power spectrum estimation.\nWe first propose a convex optimization algorithm that seeks the PSD matrix with\nthe minimum $\\ell_1$-norm of the observation residual. The advantage of our\nalgorithm is that it is free of parameters, therefore eliminating the need for\ntuning parameters and allowing easy implementations. We establish that with\nhigh probability, a low-rank PSD matrix can be exactly recovered as soon as the\nnumber of measurements is large enough, even when a fraction of the\nmeasurements are corrupted by outliers with arbitrary magnitudes. Moreover, the\nrecovery is also stable against bounded noise. With the additional information\nof an upper bound of the rank of the PSD matrix, we propose another non-convex\nalgorithm based on subgradient descent that demonstrates excellent empirical\nperformance in terms of computational efficiency and accuracy. \n\n"}
{"id": "1602.03305", "contents": "Title: Coverage and capacity scaling laws in downlink ultra-dense cellular\n  networks Abstract: Driven by new types of wireless devices and the proliferation of\nbandwidth-intensive applications, data traffic and the corresponding network\nload are increasing dramatically. Network densification has been recognized as\na promising and efficient way to provide higher network capacity and enhanced\ncoverage. Most prior work on performance analysis of ultra-dense networks\n(UDNs) has focused on random spatial deployment with idealized singular path\nloss models and Rayleigh fading. In this paper, we consider a more precise and\ngeneral model, which incorporates multi-slope path loss and general fading\ndistributions. We derive the tail behavior and scaling laws for the coverage\nprobability and the capacity considering strongest base station association in\na Poisson field network. Our analytical results identify the regimes in which\nthe signal-to-interference-plus-noise ratio (SINR) either asymptotically grows,\nsaturates, or decreases with increasing network density. We establish general\nresults on when UDNs lead to worse or even zero SINR coverage and capacity, and\nwe provide crisp insights on the fundamental limits of wireless network\ndensification. \n\n"}
{"id": "1602.03768", "contents": "Title: MISO Networks with Imperfect CSIT: A Topological Rate-Splitting Approach Abstract: Recently, the Degrees-of-Freedom (DoF) region of multiple-input-single-output\n(MISO) networks with imperfect channel state information at the transmitter\n(CSIT) has attracted significant attentions. An achievable scheme is known as\nrate-splitting (RS) that integrates common-message-multicasting and\nprivate-message-unicasting. In this paper, focusing on the general $K$-cell\nMISO IC where the CSIT of each interference link has an arbitrary quality of\nimperfectness, we firstly identify the DoF region achieved by RS. Secondly, we\nintroduce a novel scheme, so called Topological RS (TRS), whose novelties\ncompared to RS lie in a multi-layer structure and transmitting multiple common\nmessages to be decoded by groups of users rather than all users. The design of\nTRS is motivated by a novel interpretation of the $K$-cell IC with imperfect\nCSIT as a weighted-sum of a series of partially connected networks. We show\nthat the DoF region achieved by TRS covers that achieved by RS. Also, we find\nthe maximal sum DoF achieved by TRS via hypergraph fractional packing, which\nyields the best sum DoF so far. Lastly, for a realistic scenario where each\nuser is connected to three dominant transmitters, we identify the sufficient\ncondition where TRS strictly outperforms conventional schemes. \n\n"}
{"id": "1602.05462", "contents": "Title: DOA Parameter Estimation with 1-bit Quantization - Bounds, Methods and\n  the Exponential Replacement Abstract: While 1-bit analog-to-digital conversion (ADC) allows to significantly reduce\nthe analog complexity of wireless receive systems, using the exact likelihood\nfunction of the hard-limiting system model in order to obtain efficient\nalgorithms in the digital domain can make 1-bit signal processing challenging.\nIf the signal model before the quantizer consists of correlated Gaussian random\nvariables, the tail probability for a multivariate Gaussian distribution with N\ndimensions (general orthant probability) is required in order to formulate the\nlikelihood function of the quantizer output. As a closed-form expression for\nthe general orthant probability is an open mathematical problem, formulation of\nefficient processing methods for correlated and quantized data and an\nanalytical performance assessment have, despite their high practical relevance,\nonly found limited attention in the literature on quantized estimation theory.\nHere we review the approach of replacing the original system model by an\nequivalent distribution within the exponential family. For 1-bit signal\nprocessing, this allows to circumvent calculation of the general orthant\nprobability and gives access to a conservative approximation of the receive\nlikelihood. For the application of blind direction-of-arrival (DOA) parameter\nestimation with an array of K sensors, each performing 1-bit quantization, we\ndemonstrate how the exponential replacement enables to formulate a pessimistic\nversion of the Cram\\'er-Rao lower bound (CRLB) and to derive an asymptotically\nachieving conservative maximum-likelihood estimator (CMLE). The 1-bit DOA\nperformance analysis based on the pessimistic CRLB points out that a\nlow-complexity radio front-end design with 1-bit ADC is in particular suitable\nfor blind wireless DOA estimation with a large number of array elements\noperating in the medium SNR regime. \n\n"}
{"id": "1602.07225", "contents": "Title: Strictly Positive and Continuous Random Fibonacci Sequences and Network\n  Theory Applications Abstract: We motivate the study of a certain class of random Fibonacci sequences -\nwhich we call continuous random Fibonacci sequences - by demonstrating that\ntheir exponential growth rate can be used to establish capacity and power\nscaling laws for multihop cooperative amplify-and-forward (AF) relay networks.\nWith these laws, we show that it is possible to construct multihop cooperative\nAF networks that simultaneously avoid 1) exponential capacity decay and 2)\nexponential transmit power growth across the network. This is achieved by\nensuring the network's Lyapunov exponent is zero. \n\n"}
{"id": "1602.08273", "contents": "Title: Globally Optimal Base Station Clustering in Interference Alignment-Based\n  Multicell Networks Abstract: Coordinated precoding based on interference alignment is a promising\ntechnique for improving the throughputs in future wireless multicell networks.\nIn small networks, all base stations can typically jointly coordinate their\nprecoding. In large networks however, base station clustering is necessary due\nto the otherwise overwhelmingly high channel state information (CSI)\nacquisition overhead. In this work, we provide a branch and bound algorithm for\nfinding the globally optimal base station clustering. The algorithm is mainly\nintended for benchmarking existing suboptimal clustering schemes. We propose a\ngeneral model for the user throughputs, which only depends on the long-term CSI\nstatistics. The model assumes intracluster interference alignment and is able\nto account for the CSI acquisition overhead. By enumerating a search tree using\na best-first search and pruning sub-trees in which the optimal solution\nprovably cannot be, the proposed method converges to the optimal solution. The\npruning is done using specifically derived bounds, which exploit some assumed\nstructure in the throughput model. It is empirically shown that the proposed\nmethod has an average complexity which is orders of magnitude lower than that\nof exhaustive search. \n\n"}
{"id": "1602.08549", "contents": "Title: Improved Cryptanalysis of Rank Metric Schemes Based on Gabidulin Codes Abstract: We prove that any variant of the GPT cryptosystem which uses a right column\nscrambler over the extension field as advocated by the works of Gabidulin et\nal. with the goal to resist to Overbeck's structural attack are actually still\nvulnerable to that attack. We show that by applying the Frobenius operator\nappropriately on the public key, it is possible to build a Gabidulin code\nhaving the same dimension as the original secret Gabidulin code but with a\nlower length. In particular, the code obtained by this way correct less errors\nthan the secret one but its error correction capabilities are beyond the number\nof errors added by a sender, and consequently an attacker is able to decrypt\nany ciphertext with this degraded Gabidulin code. We also considered the case\nwhere an isometric transformation is applied in conjunction with a right column\nscrambler which has its entries in the extension field. We proved that this\nprotection is useless both in terms of performance and security. Consequently,\nour results show that all the existing techniques aiming to hide the inherent\nalgebraic structure of Gabidulin codes have failed. \n\n"}
{"id": "1602.09039", "contents": "Title: Dynamic Channel Allocation for Interference Mitigation in Relay-assisted\n  Wireless Body Networks Abstract: We focus on interference mitigation and energy conservation within a single\nwireless body area network (WBAN). We adopt two-hop communication scheme\nsupported by the the IEEE 802.15.6 standard (2012). In this paper, we propose a\ndynamic channel allocation scheme, namely DCAIM to mitigate node-level\ninterference amongst the coexisting regions of a WBAN. At the time, the sensors\nare in the radius communication of a relay, they form a relay region (RG)\ncoordinated by that relay using time division multiple access (TDMA). In the\nproposed scheme, each RG creates a table consisting of interfering sensors\nwhich it broadcasts to its neighboring sensors. This broadcast allows each pair\nof RGs to create an interference set (IS). Thus, the members of IS are assigned\northogonal sub-channels whereas other sonsors that do not belong to IS can\ntransmit using the same time slots. Experimental results show that our proposal\nmitigates node-level interference and improves node and WBAN energy savings.\nThese results are then compared to the results of other schemes. As a result,\nour scheme outperforms in all cases. Node-level signal to interference and\nnoise ratio (SINR) improved by 11dB whilst, the energy consumption decreased\nsignificantly. We further present a probabilistic method and analytically show\nthe outage probability can be effectively reduced to the minimal. \n\n"}
{"id": "1603.01420", "contents": "Title: Capacity Results for the Multicast Cognitive Interference Channel Abstract: The capacity region of the Multicast Cognitive Interference Channel (CIFC) is\ninvestigated. This channel consists of two independent transmitters that wish\nto multicast two different messages, each of them to a different set of users.\nIn addition, one of the transmitters --commonly referred to as the cognitive\ntransmitter-- has prior non-causal knowledge of both messages to be\ntransmitted. This scenario combines difficulties and challenges arising in the\nInterference Channel, the Broadcast Channel and multicasting communications.\nOur aim concerns the derivation of optimal interference mitigation techniques\nin such a challenging communication setup. We investigate to this end the\nmulti-primary CIFC and its dual multi-secondary CIFC under various interference\nregimes as an attempt to build a thorough understanding for the more general\nsetting. It is shown that, for some regimes, well-known coding techniques for\nthe conventional CIFC remain still optimal in the presence of multicasting.\nWhile in other regimes, evolved encoding and/or decoding strategies are\ncrucial. A careful use of these coding schemes and new outer bounding\ntechniques allows us to characterize the capacity region for several classes of\ndiscrete memoryless and Gaussian channels in different interference regimes. \n\n"}
{"id": "1603.02701", "contents": "Title: Transport Layer Performance in 5G mmWave Cellular Abstract: The millimeter wave (mmWave) bands are likely to play a significant role in\nnext generation cellular systems due to the possibility of very high throughput\nthanks to the availability of massive bandwidth and high-dimensional antennas.\nEspecially in Non-Line-of-Sight conditions, significant variations in the\nreceived RF power can occur as a result of the scattering from nearby building\nand terrain surfaces. Scattering objects come and go as the user moves through\nthe local environment. At the higher end of the mmWave band, rough surface\nscatter generates cluster-based small-scale fading, where signal levels can\nvary by more than 20 dB over just a few wavelengths. This high level of channel\nvariability may present significant challenges for congestion control. Using\nour recently developed end-to-end mmWave ns3-based framework, this paper\npresents the first performance evaluation of TCP congestion control in\nnext-generation mmWave networks. Importantly, the framework can incorporate\ndetailed models of the mmWave channel, beam- forming and tracking algorithms,\nand builds on statistical channel models derived from real measurements in New\nYork City, as well as detailed ray traces. \n\n"}
{"id": "1603.07327", "contents": "Title: Constellation Shaping for WDM systems using 256QAM/1024QAM with\n  Probabilistic Optimization Abstract: In this paper, probabilistic shaping is numerically and experimentally\ninvestigated for increasing the transmission reach of wavelength division\nmultiplexed (WDM) optical communication system employing quadrature amplitude\nmodulation (QAM). An optimized probability mass function (PMF) of the QAM\nsymbols is first found from a modified Blahut-Arimoto algorithm for the optical\nchannel. A turbo coded bit interleaved coded modulation system is then applied,\nwhich relies on many-to-one labeling to achieve the desired PMF, thereby\nachieving shaping gain. Pilot symbols at rate at most 2% are used for\nsynchronization and equalization, making it possible to receive input\nconstellations as large as 1024QAM. The system is evaluated experimentally on a\n10 GBaud, 5 channels WDM setup. The maximum system reach is increased w.r.t.\nstandard 1024QAM by 20% at input data rate of 4.65 bits/symbol and up to 75% at\n5.46 bits/symbol. It is shown that rate adaptation does not require changing of\nthe modulation format. The performance of the proposed 1024QAM shaped system is\nvalidated on all 5 channels of the WDM signal for selected distances and rates.\nFinally, it was shown via EXIT charts and BER analysis that iterative\ndemapping, while generally beneficial to the system, is not a requirement for\nachieving the shaping gain. \n\n"}
{"id": "1603.07628", "contents": "Title: On Communication through a Gaussian Channel with an MMSE Disturbance\n  Constraint Abstract: This paper considers a Gaussian channel with one transmitter and two\nreceivers. The goal is to maximize the communication rate at the\nintended/primary receiver subject to a disturbance constraint at the\nunintended/secondary receiver. The disturbance is measured in terms of minimum\nmean square error (MMSE) of the interference that the transmission to the\nprimary receiver inflicts on the secondary receiver.\n  The paper presents a new upper bound for the problem of maximizing the mutual\ninformation subject to an MMSE constraint. The new bound holds for vector\ninputs of any length and recovers a previously known limiting (when the length\nof vector input tends to infinity) expression from the work of Bustin\n$\\textit{et al.}$ The key technical novelty is a new upper bound on the MMSE.\nThis bound allows one to bound the MMSE for all signal-to-noise ratio (SNR)\nvalues $\\textit{below}$ a certain SNR at which the MMSE is known (which\ncorresponds to the disturbance constraint). This bound complements the\n`single-crossing point property' of the MMSE that upper bounds the MMSE for all\nSNR values $\\textit{above}$ a certain value at which the MMSE value is known.\nThe MMSE upper bound provides a refined characterization of the\nphase-transition phenomenon which manifests, in the limit as the length of the\nvector input goes to infinity, as a discontinuity of the MMSE for the problem\nat hand.\n  For vector inputs of size $n=1$, a matching lower bound, to within an\nadditive gap of order $O \\left( \\log \\log \\frac{1}{\\sf MMSE} \\right)$ (where\n${\\sf MMSE}$ is the disturbance constraint), is shown by means of the mixed\ninputs technique recently introduced by Dytso $\\textit{et al.}$ \n\n"}
{"id": "1603.08106", "contents": "Title: Mining DNA Sequences Based on Spatially Coded Technique Using Spatial\n  Light Modulator Abstract: In this paper, we present an optical computing method for string data\nalignment applicable to genome information analysis. By applying moire\ntechnique to spatial encoding patterns of deoxyribonucleic acid (DNA)\nsequences, association information of the genome and the expressed phenotypes\ncould more effectively be extracted. Such moire fringes reveal occurrence of\nmatching, deletion and insertion between DNA sequences providing useful\nvisualized information for prediction of gene function and classification of\nspecies. Furthermore, by applying a cylindrical lens, a new technique is\nproposed to map two-dimensional (2D) association information to a\none-dimensional (1D) column of pixels, where each pixel in the column is\nrepresentative of superposition of all bright and dark pixels in the\ncorresponding row. By such a time-consuming preprocessing, local similarities\nbetween two intended patterns can readily be found by just using a 1D array of\nphotodetectors and postprocessing could be performed on specified parts in the\ninitial 2D pattern. We also evaluate our proposed circular encoding adapted for\npoor data alignment condition. Our simulation results together with\nexperimental implementation verify the effectiveness of our dynamic proposed\nmethods which significantly improve system parameters such as processing gain\nand signal to noise ratio (SNR). \n\n"}
{"id": "1603.08113", "contents": "Title: Reconstructing undirected graphs from eigenspaces Abstract: In this paper, we aim at recovering an undirected weighted graph of $N$\nvertices from the knowledge of a perturbed version of the eigenspaces of its\nadjacency matrix $W$. For instance, this situation arises for stationary\nsignals on graphs or for Markov chains observed at random times. Our approach\nis based on minimizing a cost function given by the Frobenius norm of the\ncommutator $\\mathsf{A} \\mathsf{B}-\\mathsf{B} \\mathsf{A}$ between symmetric\nmatrices $\\mathsf{A}$ and $\\mathsf{B}$.\n  In the Erd\\H{o}s-R\\'enyi model with no self-loops, we show that\nidentifiability (i.e., the ability to reconstruct $W$ from the knowledge of its\neigenspaces) follows a sharp phase transition on the expected number of edges\nwith threshold function $N\\log N/2$.\n  Given an estimation of the eigenspaces based on a $n$-sample, we provide\nsupport selection procedures from theoretical and practical point of views. In\nparticular, when deleting an edge from the active support, our study unveils\nthat our test statistic is the order of $\\mathcal O(1/n)$ when we overestimate\nthe true support and lower bounded by a positive constant when the estimated\nsupport is smaller than the true support. This feature leads to a powerful\npractical support estimation procedure. Simulated and real life numerical\nexperiments assert our new methodology. \n\n"}
{"id": "1603.08578", "contents": "Title: Analysis of k-Nearest Neighbor Distances with Application to Entropy\n  Estimation Abstract: Estimating entropy and mutual information consistently is important for many\nmachine learning applications. The Kozachenko-Leonenko (KL) estimator\n(Kozachenko & Leonenko, 1987) is a widely used nonparametric estimator for the\nentropy of multivariate continuous random variables, as well as the basis of\nthe mutual information estimator of Kraskov et al. (2004), perhaps the most\nwidely used estimator of mutual information in this setting. Despite the\npractical importance of these estimators, major theoretical questions regarding\ntheir finite-sample behavior remain open. This paper proves finite-sample\nbounds on the bias and variance of the KL estimator, showing that it achieves\nthe minimax convergence rate for certain classes of smooth functions. In\nproving these bounds, we analyze finite-sample behavior of k-nearest neighbors\n(k-NN) distance statistics (on which the KL estimator is based). We derive\nconcentration inequalities for k-NN distances and a general expectation bound\nfor statistics of k-NN distances, which may be useful for other analyses of\nk-NN methods. \n\n"}
{"id": "1603.09263", "contents": "Title: Universal Lattice Codes for MIMO Channels Abstract: We propose a coding scheme that achieves the capacity of the compound MIMO\nchannel with algebraic lattices. Our lattice construction exploits the\nmultiplicative structure of number fields and their group of units to absorb\nill-conditioned channel realizations. To shape the constellation, a discrete\nGaussian distribution over the lattice points is applied. These techniques,\nalong with algebraic properties of the proposed lattices, are then used to\nconstruct a sub-optimal de-coupled coding schemes that achieves a gap to\ncompound capacity by decoding in a lattice that does not depend of the channel\nrealization. The gap is characterized in terms of algebraic invariants of the\ncodes, and shown to be significantly smaller than previous schemes in the\nliterature. We also exhibit alternative algebraic constructions that achieve\nthe capacity of ergodic fading channels. \n\n"}
{"id": "1603.09376", "contents": "Title: On the Secure Degrees of Freedom of the K-user MAC and 2-user\n  Interference Channels Abstract: We investigate the secure degrees of freedom (SDoF) of the K-user MIMO\nmultiple access (MAC) and the two user MIMO interference channel. An unknown\nnumber of eavesdroppers are trying to decode the messages sent by the\ntransmitters. Each eavesdropper is equipped with a number of antennas less than\nor equal to a known value NE. The legitimate transmitters and receivers are\nassumed to have global channel knowledge. We present the sum SDoF of the two\nuser MIMO interference channel. We derive an upperbound on the sum SDoF of the\nK-user MAC channel and present an achievable scheme that partially meets the\nderived upperbound. \n\n"}
{"id": "1604.00135", "contents": "Title: On the Performance of RF-FSO Links with and without Hybrid ARQ Abstract: This paper studies the performance of hybrid radio-frequency (RF) and\nfree-space optical (FSO) links assuming perfect channel state information (CSI)\nat the receiver. Considering the cases with and without hybrid automatic repeat\nrequest (HARQ), we derive closed-form expressions for the message decoding\nprobabilities as well as the throughput and the outage probability of the\nRF-FSO setups. We also evaluate the effect of adaptive power allocation and\ndifferent channel conditions on the throughput and the outage probability. The\nresults show the efficiency of the RF-FSO links in different conditions. \n\n"}
{"id": "1604.01835", "contents": "Title: Exploiting Full-duplex Receivers for Achieving Secret Communications in\n  Multiuser MISO Networks Abstract: We consider a broadcast channel, in which a multi-antenna transmitter (Alice)\nsends $K$ confidential information signals to $K$ legitimate users (Bobs) in\nthe presence of $L$ eavesdroppers (Eves). Alice uses MIMO precoding to generate\nthe information signals along with her own (Tx-based) friendly jamming.\nInterference at each Bob is removed by MIMO zero-forcing. This, however, leaves\na \"vulnerability region\" around each Bob, which can be exploited by a nearby\nEve. We address this problem by augmenting Tx-based friendly jamming (TxFJ)\nwith Rx-based friendly jamming (RxFJ), generated by each Bob. Specifically,\neach Bob uses self-interference suppression (SIS) to transmit a friendly\njamming signal while simultaneously receiving an information signal over the\nsame channel. We minimize the powers allocated to the information, TxFJ, and\nRxFJ signals under given guarantees on the individual secrecy rate for each\nBob. The problem is solved for the cases when the eavesdropper's channel state\ninformation is known/unknown. Simulations show the effectiveness of the\nproposed solution. Furthermore, we discuss how to schedule transmissions when\nthe rate requirements need to be satisfied on average rather than\ninstantaneously. Under special cases, a scheduling algorithm that serves only\nthe strongest receivers is shown to outperform the one that schedules all\nreceivers. \n\n"}
{"id": "1604.03006", "contents": "Title: Demystifying Fixed k-Nearest Neighbor Information Estimators Abstract: Estimating mutual information from i.i.d. samples drawn from an unknown joint\ndensity function is a basic statistical problem of broad interest with\nmultitudinous applications. The most popular estimator is one proposed by\nKraskov and St\\\"ogbauer and Grassberger (KSG) in 2004, and is nonparametric and\nbased on the distances of each sample to its $k^{\\rm th}$ nearest neighboring\nsample, where $k$ is a fixed small integer. Despite its widespread use (part of\nscientific software packages), theoretical properties of this estimator have\nbeen largely unexplored. In this paper we demonstrate that the estimator is\nconsistent and also identify an upper bound on the rate of convergence of the\nbias as a function of number of samples. We argue that the superior performance\nbenefits of the KSG estimator stems from a curious \"correlation boosting\"\neffect and build on this intuition to modify the KSG estimator in novel ways to\nconstruct a superior estimator. As a byproduct of our investigations, we obtain\nnearly tight rates of convergence of the $\\ell_2$ error of the well known fixed\n$k$ nearest neighbor estimator of differential entropy by Kozachenko and\nLeonenko. \n\n"}
{"id": "1604.03888", "contents": "Title: Fundamental Limits of Coded Caching: Improved Delivery Rate-Cache\n  Capacity Trade-off Abstract: A centralized coded caching system, consisting of a server delivering N\npopular files, each of size F bits, to K users through an error-free shared\nlink, is considered. It is assumed that each user is equipped with a local\ncache memory with capacity MF bits, and contents can be proactively cached into\nthese caches over a low traffic period; however, without the knowledge of the\nuser demands. During the peak traffic period each user requests a single file\nfrom the server. The goal is to minimize the number of bits delivered by the\nserver over the shared link, known as the delivery rate, over all user demand\ncombinations. A novel coded caching scheme for the cache capacity of M= (N-1)/K\nis proposed. It is shown that the proposed scheme achieves a smaller delivery\nrate than the existing coded caching schemes in the literature when K > N >= 3.\nFurthermore, we argue that the delivery rate of the proposed scheme is within a\nconstant multiplicative factor of 2 of the optimal delivery rate for cache\ncapacities 1/K <= M <= (N-1)/K, when K > N >= 3. \n\n"}
{"id": "1604.06293", "contents": "Title: Asymptotic and Finite Frame Length Analysis of Frame Asynchronous Coded\n  Slotted ALOHA Abstract: We consider a frame-asynchronous coded slotted ALOHA (FA-CSA) system where\nusers become active according to a Poisson random process. In contrast to\nstandard frame-synchronous CSA (FS-CSA), users transmit a first replica of\ntheir message in the slot following their activation and other replicas\nuniformly at random in a number of subsequent slots. We derive the\n(approximate) density evolution that characterizes the asymptotic performance\nof FA-CSA when the frame length goes to infinity. We show that, if users can\nmonitor the system before they start transmitting, a boundary-effect similar to\nthat of spatially-coupled codes occurs, which greatly improves the decoding\nthreshold as compared to FS-CSA. We also derive analytical approximations of\nthe error floor (EF) in the finite frame length regime. We show that FA-CSA\nyields in general lower EF, better performance in the waterfall region, and\nlower average delay, as compared to FS-CSA. \n\n"}
{"id": "1605.00058", "contents": "Title: Strongly Refuting Random CSPs Below the Spectral Threshold Abstract: Random constraint satisfaction problems (CSPs) are known to exhibit threshold\nphenomena: given a uniformly random instance of a CSP with $n$ variables and\n$m$ clauses, there is a value of $m = \\Omega(n)$ beyond which the CSP will be\nunsatisfiable with high probability. Strong refutation is the problem of\ncertifying that no variable assignment satisfies more than a constant fraction\nof clauses; this is the natural algorithmic problem in the unsatisfiable regime\n(when $m/n = \\omega(1)$).\n  Intuitively, strong refutation should become easier as the clause density\n$m/n$ grows, because the contradictions introduced by the random clauses become\nmore locally apparent. For CSPs such as $k$-SAT and $k$-XOR, there is a\nlong-standing gap between the clause density at which efficient strong\nrefutation algorithms are known, $m/n \\ge \\widetilde O(n^{k/2-1})$, and the\nclause density at which instances become unsatisfiable with high probability,\n$m/n = \\omega (1)$.\n  In this paper, we give spectral and sum-of-squares algorithms for strongly\nrefuting random $k$-XOR instances with clause density $m/n \\ge \\widetilde\nO(n^{(k/2-1)(1-\\delta)})$ in time $\\exp(\\widetilde O(n^{\\delta}))$ or in\n$\\widetilde O(n^{\\delta})$ rounds of the sum-of-squares hierarchy, for any\n$\\delta \\in [0,1)$ and any integer $k \\ge 3$. Our algorithms provide a smooth\ntransition between the clause density at which polynomial-time algorithms are\nknown at $\\delta = 0$, and brute-force refutation at the satisfiability\nthreshold when $\\delta = 1$. We also leverage our $k$-XOR results to obtain\nstrong refutation algorithms for SAT (or any other Boolean CSP) at similar\nclause densities. Our algorithms match the known sum-of-squares lower bounds\ndue to Grigoriev and Schonebeck, up to logarithmic factors.\n  Additionally, we extend our techniques to give new results for certifying\nupper bounds on the injective tensor norm of random tensors. \n\n"}
{"id": "1605.00668", "contents": "Title: Hybrid Architectures with Few-Bit ADC Receivers: Achievable Rates and\n  Energy-Rate Tradeoffs Abstract: Hybrid analog/digital architectures and receivers with low-resolution\nanalog-to-digital converters (ADCs) are two low power solutions for wireless\nsystems with large antenna arrays, such as millimeter wave and massive MIMO\nsystems. Most prior work represents two extreme cases in which either a small\nnumber of RF chains with full-resolution ADCs, or low resolution ADC with a\nnumber of RF chains equal to the number of antennas is assumed. In this paper,\na generalized hybrid architecture with a small number of RF chains and finite\nnumber of ADC bits is proposed. For this architecture, achievable rates with\nchannel inversion and SVD based transmission methods are derived. Results show\nthat the achievable rate is comparable to that obtained by full-precision ADC\nreceivers at low and medium SNRs. A trade-off between the achievable rate and\npower consumption for different numbers of bits and RF chains is devised. This\nenables us to draw some conclusions on the number of ADC bits needed to\nmaximize the system energy efficiency. Numerical simulations show that coarse\nADC quantization is optimal under various system configurations. This means\nthat hybrid combining with coarse quantization achieves better energy-rate\ntrade-off compared to both hybrid combining with full-resolutions ADCs and\n1-bit ADC combining. \n\n"}
{"id": "1605.02233", "contents": "Title: On the Capacity of the Beta-Binomial Channel Model for Multi-Level Cell\n  Flash Memories Abstract: The beta-binomial (BBM) channel model was recently proposed to model the\noverdispersed statistics of empirically observed bit errors in multi-level cell\n(MLC) flash memories. In this paper, we study the capacity of the BBM channel\nmodel for MLC flash memories. Using the compound channel approach, we first\nshow that the BBM channel model capacity is zero. However, through empirical\nobservation, this appears to be a very pessimistic estimate of the flash memory\nchannel capacity. We propose a refined channel model called the\ntruncated-support beta-binomial (TS-BBM) channel model and derive its capacity.\nUsing empirical error statistics from 1X-nm and 2Y-nm MLC flash memories, we\nnumerically estimate the TS-BBM channel model capacity as a function of the\nprogram/erase (P/E) cycling stress. The capacity of the 2-TS-BBM channel model\nprovides an upper bound on the coding rates for the flash memory chip assuming\na single binary error correction code is used. \n\n"}
{"id": "1605.05037", "contents": "Title: Cloud-Based Topological Interference Management: A Case with No\n  Cooperative Transmission Gain Abstract: We study the problem of managing interference in linear networks, with\nbackhaul constraints that admit centralized allocation of messages to\ntransmitters through the cloud. Our setting is that of a generic channel, where\nno channel state information is available at the transmitters. Knowing only the\nnetwork topology, we characterize the optimal decisions for assigning messages\nto transmitters, given that each receiver is interested in one message that can\nbe available at N transmitters. We show that using linear cooperation schemes,\nthe per user degrees of freedom does not increase as we increase N beyond\nunity. Hence, we conclude for the considered problem that linear cooperative\ntransmission does not increase the degrees of freedom. \n\n"}
{"id": "1605.05819", "contents": "Title: Exponentially concave functions and a new information geometry Abstract: A function is exponentially concave if its exponential is concave. We\nconsider exponentially concave functions on the unit simplex. In a previous\npaper we showed that gradient maps of exponentially concave functions provide\nsolutions to a Monge-Kantorovich optimal transport problem and give a better\ngradient approximation than those of ordinary concave functions. The\napproximation error, called L-divergence, is different from the usual Bregman\ndivergence. Using tools of information geometry and optimal transport, we show\nthat L-divergence induces a new information geometry on the simplex consisting\nof a Riemannian metric and a pair of dually coupled affine connections which\ndefines two kinds of geodesics. We show that the induced geometry is dually\nprojectively flat but not flat. Nevertheless, we prove an analogue of the\ncelebrated generalized Pythagorean theorem from classical information geometry.\nOn the other hand, we consider displacement interpolation under a Lagrangian\nintegral action that is consistent with the optimal transport problem and show\nthat the action minimizing curves are dual geodesics. The Pythagorean theorem\nis also shown to have an interesting application of determining the optimal\ntrading frequency in stochastic portfolio theory. \n\n"}
{"id": "1605.07684", "contents": "Title: On Non-Orthogonal Multiple Access in Downlink Abstract: Non orthogonal multiple access (NOMA) in the downlink is discussed in this\nletter. When combined with soft frequency reuse, NOMA is detrimental to user\nfairness by increasing the data rate of a near user at the cost of data rate of\na far user. \n\n"}
{"id": "1605.08346", "contents": "Title: Distributed Sequence Memory of Multidimensional Inputs in Recurrent\n  Networks Abstract: Recurrent neural networks (RNNs) have drawn interest from machine learning\nresearchers because of their effectiveness at preserving past inputs for\ntime-varying data processing tasks. To understand the success and limitations\nof RNNs, it is critical that we advance our analysis of their fundamental\nmemory properties. We focus on echo state networks (ESNs), which are RNNs with\nsimple memoryless nodes and random connectivity. In most existing analyses, the\nshort-term memory (STM) capacity results conclude that the ESN network size\nmust scale linearly with the input size for unstructured inputs. The main\ncontribution of this paper is to provide general results characterizing the STM\ncapacity for linear ESNs with multidimensional input streams when the inputs\nhave common low-dimensional structure: sparsity in a basis or significant\nstatistical dependence between inputs. In both cases, we show that the number\nof nodes in the network must scale linearly with the information rate and\npoly-logarithmically with the ambient input dimension. The analysis relies on\nadvanced applications of random matrix theory and results in explicit\nnon-asymptotic bounds on the recovery error. Taken together, this analysis\nprovides a significant step forward in our understanding of the STM properties\nin RNNs. \n\n"}
{"id": "1605.08487", "contents": "Title: On The 2D Phase Retrieval Problem Abstract: The recovery of a signal from the magnitude of its Fourier transform, also\nknown as phase retrieval, is of fundamental importance in many scientific\nfields. It is well known that due to the loss of Fourier phase the problem in\n1D is ill-posed. Without further constraints, there is no unique solution to\nthe problem. In contrast, uniqueness up to trivial ambiguities very often\nexists in higher dimensions, with mild constraints on the input. In this paper\nwe focus on the 2D phase retrieval problem and provide insight into this\nuniqueness property by exploring the connection between the 2D and 1D\nformulations. In particular, we show that 2D phase retrieval can be cast as a\n1D problem with additional constraints, which limit the solution space. We then\nprove that only one additional constraint is sufficient to reduce the many\nfeasible solutions in the 1D setting to a unique solution for almost all\nsignals. These results allow to obtain an analytical approach (with\ncombinatorial complexity) to solve the 2D phase retrieval problem when it is\nunique. \n\n"}
{"id": "1605.08515", "contents": "Title: Uplink Spectral Efficiency Analysis of Decoupled Access in Multiuser\n  MIMO Communications Abstract: In a heterogeneous network consisting of macro base stations (MBSs) and small\nbase stations (SBSs), the traditional cell association policy, i.e., coupled\naccess (CA), is far from optimal, due to the significant difference between the\ncoverage and transmit powers of MBSs and SBSs. Hence, users may choose to\nassociate with different types of BSs in downlink (DL) and uplink (UL), i.e.,\ndecoupled access (DA), to enhance spectral efficiency. In this paper, DA in\nmultiuser MIMO communications is investigated in terms of UL spectral\nefficiency. Firstly, we obtain the UL association probabilities. In contrast to\nthe CA scenario, association probabilities for DA scenario only depend on the\ndensities of BSs. Hence, DA allows UL and DL to be totally independent.\nSecondly, we derive lower bounds on the spectral efficiency. The lower bounds\nshow that, different from CA, the UL spectral efficiency for DA scenario is\nirrelative with the transmit powers of BSs, which implies DA allows users to\nassociate with any BSs that can achieve the highest UL spectral efficiency.\nFinally, the spectral efficiencies for DA and CA scenarios are compared via\nsimulation results, where it can be concluded that the spectral efficiency in\nmultiuser MIMO systems is improved by DA. \n\n"}
{"id": "1605.08851", "contents": "Title: A Simplified Sub-Nyquist Receiver Architecture for Joint DOA and\n  Frequency Estimation Abstract: Joint estimation of carrier frequency and direction of arrival (DOA) for\nmultiple signals has been found in many practical applications such as\nCognitive Radio (CR). However, Nyquist sampling mechanism is costly or\nimplemented due to wide spectrum range. Taking advantage of sub-Nyquist\nsampling technology, some array receiver architectures are proposed to realize\njoint estimation of carrier frequency and DOA. To further decrease equivalent\nsampling rate and hardware complexity, we propose a simplifying receiver\narchitecture based on our previous work. We come up with joint DOA and\nfrequency estimation algorithms for the novel architecture. The simulations\ndemonstrate that the receiver architecture and the proposed approaches are\nfeasible. \n\n"}
{"id": "1605.09598", "contents": "Title: On Quantum Tensor Product Codes Abstract: We present a general framework for the construction of quantum tensor product\ncodes (QTPC). In a classical tensor product code (TPC), its parity check matrix\nis con- structed via the tensor product of parity check matrices of the two\ncomponent codes. We show that by adding some constraints on the component\ncodes, several classes of dual-containing TPCs can be obtained. By selecting\ndifferent types of component codes, the proposed method enables the\nconstruction of a large family of QTPCs and they can provide a wide variety of\nquantum error control abilities. In particular, if one of the component codes\nis selected as a burst-error-correction code, then QTPCs have quantum\nmultiple-burst-error-correction abilities, provided these bursts fall in\ndistinct subblocks. Compared with concatenated quantum codes (CQC), the\ncomponent code selections of QTPCs are much more exible than those of CQCs\nsince only one of the component codes of QTPCs needs to satisfy the\ndual-containing restriction. We show that it is possible to construct QTPCs\nwith parameters better than other classes of quantum error-correction codes\n(QECC), e.g., CQCs and quantum BCH codes. Many QTPCs are obtained with\nparameters better than previously known quantum codes available in the\nliterature. Several classes of QTPCs that can correct multiple quantum bursts\nof errors are constructed based on reversible cyclic codes and\nmaximum-distance-separable (MDS) codes. \n\n"}
{"id": "1606.00397", "contents": "Title: Duplication-Correcting Codes for Data Storage in the DNA of Living\n  Organisms Abstract: The ability to store data in the DNA of a living organism has applications in\na variety of areas including synthetic biology and watermarking of patented\ngenetically-modified organisms. Data stored in this medium is subject to errors\narising from various mutations, such as point mutations, indels, and tandem\nduplication, which need to be corrected to maintain data integrity. In this\npaper, we provide error-correcting codes for errors caused by tandem\nduplications, which create a copy of a block of the sequence and insert it in a\ntandem manner, i.e., next to the original. In particular, we present two\nfamilies of codes for correcting errors due to tandem-duplications of a fixed\nlength, the first family can correct any number of errors while the second\ncorrects a bounded number of errors. We also study codes for correcting tandem\nduplications of length up to a given constant $k$, where we are primarily\nfocused on the cases of $k=2,3$. Finally, we provide a full classification of\nthe sets of lengths allowed in tandem duplication that result in a unique root\nfor all sequences. \n\n"}
{"id": "1606.00629", "contents": "Title: RankSign: an efficient signature algorithm based on the rank metric Abstract: In this paper we propose a new approach to code-based signatures that makes\nuse in particular of rank metric codes. When the classical approach consists in\nfinding the unique preimage of a syndrome through a decoding algorithm, we\npropose to introduce the notion of mixed decoding of erasures and errors for\nbuilding signature schemes. In that case the difficult problem becomes, as is\nthe case in lattice-based cryptography, finding a preimage of weight above the\nGilbert-Varshamov bound (case where many solutions occur) rather than finding a\nunique preimage of weight below the Gilbert-Varshamov bound. The paper\ndescribes RankSign: a new signature algorithm for the rank metric based on a\nnew mixed algorithm for decoding erasures and errors for the recently\nintroduced Low Rank Parity Check (LRPC) codes. We explain how it is possible\n(depending on choices of parameters) to obtain a full decoding algorithm which\nis able to find a preimage of reasonable rank weight for any random syndrome\nwith a very strong probability. We study the semantic security of our signature\nalgorithm and show how it is possible to reduce the unforgeability to direct\nattacks on the public matrix, so that no information leaks through signatures.\nFinally, we give several examples of parameters for our scheme, some of which\nwith public key of size $11,520$ bits and signature of size $1728$ bits.\nMoreover the scheme can be very fast for small base fields. \n\n"}
{"id": "1606.01505", "contents": "Title: Basis entropy: A useful physical quantity about projective measurement Abstract: Projective measurement can increase the entropy of a state $\\rho$, the\nincreased entropy is not only up to the basis of projective measurement, but\nalso has something to do with the properties of the state itself. In this paper\nwe define this increased entropy as basis entropy. And then we discuss the\nusefulness of this new concept by showing its application in deciding whether a\nstate is pure or not and detecting the existence of quantum discord. And as\nshown in the paper, this new concept can also be used to describe decoherence. \n\n"}
{"id": "1606.01799", "contents": "Title: Modular non-repeating codes for DNA storage Abstract: We describe a strategy for constructing codes for DNA-based information\nstorage by serial composition of weighted finite-state transducers. The\nresulting state machines can integrate correction of substitution errors;\nsynchronization by interleaving watermark and periodic marker signals;\nconversion from binary to ternary, quaternary or mixed-radix sequences via an\nefficient block code; encoding into a DNA sequence that avoids homopolymer,\ndinucleotide, or trinucleotide runs and other short local repeats; and\ndetection/correction of errors (including local duplications, burst deletions,\nand substitutions) that are characteristic of DNA sequencing technologies. We\npresent software implementing these codes, available at\ngithub.com/ihh/dnastore, with simulation results demonstrating that the\ngenerated DNA is free of short repeats and can be accurately decoded even in\nthe presence of substitutions, short duplications and deletions. \n\n"}
{"id": "1606.03668", "contents": "Title: Spatial and Social Paradigms for Interference and Coverage Analysis in\n  Underlay D2D Network Abstract: The homogeneous Poisson point process (PPP) is widely used to model spatial\ndistribution of base stations and mobile terminals. The same process can be\nused to model underlay device-to-device (D2D) network, however, neglecting\nhomophilic relation for D2D pairing presents underestimated system insights. In\nthis paper, we model both spatial and social distributions of interfering D2D\nnodes as proximity based independently marked homogeneous Poisson point\nprocess. The proximity considers physical distance between D2D nodes whereas\nsocial relationship is modeled as Zipf based marks. We apply these two\nparadigms to analyze the effect of interference on coverage probability of\ndistance-proportional power-controlled cellular user. Effectively, we apply two\ntype of functional mappings (physical distance, social marks) to Laplace\nfunctional of PPP. The resulting coverage probability has no closed-form\nexpression, however for a subset of social marks, the mark summation converges\nto digamma and polygamma functions. This subset constitutes the upper and lower\nbounds on coverage probability. We present numerical evaluation of these bounds\non coverage probability by varying number of different parameters. The results\nshow that by imparting simple power control on cellular user, ultra-dense\nunderlay D2D network can be realized without compromising the coverage\nprobability of cellular user. \n\n"}
{"id": "1606.04804", "contents": "Title: Ambiguities in one-dimensional phase retrieval from magnitudes of a\n  linear canonical transform Abstract: Phase retrieval problems occur in a wide range of applications in physics and\nengineering. Usually, these problems consist in the recovery of an unknown\nsignal from the magnitudes of its Fourier transform. In some applications,\nhowever, the given intensity arises from a different transformation such as the\nFresnel or fractional Fourier transform. More generally, we here consider the\nphase retrieval of an unknown signal from the magnitudes of an arbitrary linear\ncanonical transform. Using the close relation between the Fourier and the\nlinear canonical transform, we investigate the arising ambiguities of these\nphase retrieval problems and transfer the well-known characterizations of the\nsolution sets from the classical Fourier phase retrieval problem to the new\nsetting. \n\n"}
{"id": "1606.05306", "contents": "Title: Exact Recovery of Discrete Measures from Wigner D-Moments Abstract: In this paper, we show the possibility of recovering a sum of Dirac measures\non the rotation group $SO(3)$ from its low degree moments with respect to\nWigner D-functions only. The main Theorem of the paper states, that exact\nrecovery from moments up to degree $N$ is possible, if the support set of the\nmeasure obeys a separation distance of $\\frac{36}{N+1}$. In this case, the\nsought measure is the unique solution of a total variation minimization. The\nproof of the uniqueness requires localization estimates for interpolation\nkernels and corresponding derivatives on the rotation group $SO(3)$ with\nexplicit constants. \n\n"}
{"id": "1606.06408", "contents": "Title: Convergence Analysis and Assurance for Gaussian Message Passing\n  Iterative Detector in Massive MU-MIMO Systems Abstract: This paper considers a low-complexity Gaussian Message Passing Iterative\nDetection (GMPID) algorithm for massive Multiuser Multiple-Input\nMultiple-Output (MU-MIMO) system, in which a base station with $M$ antennas\nserves $K$ Gaussian sources simultaneously. Both $K$ and $M$ are very large\nnumbers, and we consider the cases that $K<M$. The GMPID is a low-complexity\nmessage passing algorithm based on a fully connected loopy graph, which is well\nunderstood to be not convergent in some cases. As it is hard to analyse the\nGMPID directly, the large-scale property of the massive MU-MIMO is used to\nsimplify the analysis. Firstly, we prove that the variances of the GMPID\ndefinitely converge to the mean square error of Minimum Mean Square Error\n(MMSE) detection. Secondly, we propose two sufficient conditions that the means\nof the GMPID converge to those of the MMSE detection. However, the means of\nGMPID may not converge when $ K/M\\geq (\\sqrt{2}-1)^2$. Therefore, a new\nconvergent GMPID called SA-GMPID (scale-and-add GMPID) , which converges to the\nMMSE detection in mean and variance for any $K<M$ and has a faster convergence\nspeed than the GMPID, but has no higher complexity than the GMPID, is proposed.\nFinally, numerical results are provided to verify the validity and accuracy of\nthe theoretical results. \n\n"}
{"id": "1606.07561", "contents": "Title: On (Secure) Information flow for Multiple-Unicast Sessions: Analysis\n  with Butterfly Network Abstract: This paper considers a class of wireline networks, derived from the\nwell-known butterfly network, over which two independent unicast sessions take\nplace simultaneously. The main objectives are to understand when network coding\ntype of operations are beneficial with and without security considerations and\nto derive the ultimate gains that cooperation among sources and sinks can\nbring. Towards these goals, the capacity region of the butterfly network with\narbitrary edge capacities is first derived. It is then shown that no rate can\nbe guaranteed over this network under security considerations, when an\neavesdropper wiretaps any of the links. Three variants of the butterfly\nnetwork, such as the case of co-located sources, are analyzed as well and their\nsecure and non-secure capacity regions are characterized. By using the\nbutterfly network and its variants as building blocks, these results can be\nused to design high-throughput achieving transmission schemes for general\nmultiple-unicast networks. \n\n"}
{"id": "1606.09552", "contents": "Title: Proximity Operators of Discrete Information Divergences Abstract: Information divergences allow one to assess how close two distributions are\nfrom each other. Among the large panel of available measures, a special\nattention has been paid to convex $\\varphi$-divergences, such as\nKullback-Leibler, Jeffreys-Kullback, Hellinger, Chi-Square, Renyi, and\nI$_{\\alpha}$ divergences. While $\\varphi$-divergences have been extensively\nstudied in convex analysis, their use in optimization problems often remains\nchallenging. In this regard, one of the main shortcomings of existing methods\nis that the minimization of $\\varphi$-divergences is usually performed with\nrespect to one of their arguments, possibly within alternating optimization\ntechniques. In this paper, we overcome this limitation by deriving new\nclosed-form expressions for the proximity operator of such two-variable\nfunctions. This makes it possible to employ standard proximal methods for\nefficiently solving a wide range of convex optimization problems involving\n$\\varphi$-divergences. In addition, we show that these proximity operators are\nuseful to compute the epigraphical projection of several functions of practical\ninterest. The proposed proximal tools are numerically validated in the context\nof optimal query execution within database management systems, where the\nproblem of selectivity estimation plays a central role. Experiments are carried\nout on small to large scale scenarios. \n\n"}
{"id": "1607.00550", "contents": "Title: Information-Theoretic Lower Bounds on Bayes Risk in Decentralized\n  Estimation Abstract: We derive lower bounds on the Bayes risk in decentralized estimation, where\nthe estimator does not have direct access to the random samples generated\nconditionally on the random parameter of interest, but only to the data\nreceived from local processors that observe the samples. The received data are\nsubject to communication constraints, due to quantization and the noise in the\ncommunication channels from the processors to the estimator. We first derive\ngeneral lower bounds on the Bayes risk using information-theoretic quantities,\nsuch as mutual information, information density, small ball probability, and\ndifferential entropy. We then apply these lower bounds to the decentralized\ncase, using strong data processing inequalities to quantify the contraction of\ninformation due to communication constraints. We treat the cases of a single\nprocessor and of multiple processors, where the samples observed by different\nprocessors may be conditionally dependent given the parameter, for\nnoninteractive and interactive communication protocols. Our results recover and\nimprove recent lower bounds on the Bayes risk and the minimax risk for certain\ndecentralized estimation problems, where previously only conditionally\nindependent sample sets and noiseless channels have been considered. Moreover,\nour results provide a general way to quantify the degradation of estimation\nperformance caused by distributing resources to multiple processors, which is\nonly discussed for specific examples in existing works. \n\n"}
{"id": "1607.00866", "contents": "Title: The Primal versus the Dual Ising Model Abstract: We represent the Ising model of statistical physics by normal factor graphs\nin the primal and in the dual domains. By analogy with Kirchhoff's voltage and\ncurrent laws, we show that in the primal normal factor graphs, the dependency\namong the variables is along the cycles, whereas in the dual normal factor\ngraphs, the dependency is on the cutsets. In the primal (resp. dual) domain,\ndependent variables can be computed via their fundamental cycles (resp.\nfundamental cutsets). Using Onsager's closed form solution, we illustrate the\nopposite behavior of the uniform sampling estimator for estimating the\npartition function in the primal and in the dual of the homogeneous Ising model\non a two-dimensional torus. \n\n"}
{"id": "1607.02009", "contents": "Title: Working Locally Thinking Globally - Part II: Stability and Algorithms\n  for Convolutional Sparse Coding Abstract: The convolutional sparse model has recently gained increasing attention in\nthe signal and image processing communities, and several methods have been\nproposed for solving the pursuit problem emerging from it -- in particular its\nconvex relaxation, Basis Pursuit. In the first of this two-part work, we have\nprovided a theoretical back-bone for this model, providing guarantees for the\nuniqueness of the sparsest solution and for the success of pursuit algorithms\nby introducing the notion of stripe sparsity and other related measures.\nHerein, we extend the analysis to a noisy regime, thereby considering signal\nperturbations and model deviations. We address questions of stability of the\nsparsest solutions and the success of pursuit algorithms, both greedy and\nconvex. Classical definitions such as the RIP are generalized to the\nconvolutional model, and existing notions such as the ERC are connected to our\nsetting. On the algorithmic side, we demonstrate how to solve the global\npursuit problem by using simple local processing, thus offering a first of its\nkind bridge between global modeling of signals and their patch-based local\ntreatment. \n\n"}
{"id": "1607.02298", "contents": "Title: On Channel Resolvability in Presence of Feedback Abstract: We study the problem of generating an approximately i.i.d. string at the\noutput of a discrete memoryless channel using a limited amount of randomness at\nits input in presence of causal noiseless feedback. Feedback does not decrease\nthe channel resolution, the minimum entropy rate required to achieve an\naccurate approximation of an i.i.d. output string. However, we show that, at\nleast over a binary symmetric channel, a significantly larger resolvability\nexponent (the exponential decay rate of the divergence between the output\ndistribution and product measure), compared to the best known achievable\nresolvability exponent in a system without feedback, is possible. We show that\nby employing a variable-length resolvability scheme and using an average number\nof coin-flips per channel use, the average divergence between the distribution\nof the output sequence and product measure decays exponentially fast in the\naverage length of output sequence with an exponent equal to $[R-I(U;V)]^+$\nwhere $I(U;V)$ is the mutual information developed across the channel. \n\n"}
{"id": "1607.02317", "contents": "Title: Power-Availability-Aware Cell Association for Energy-Harvesting\n  Small-Cell Base Stations Abstract: Energy harvesting brings a key solution to the increasing energy bill and\nenvironmental concerns but, at the same time, the network availability may be\ndeteriorated due to potential energy shortage. In this paper, we analyze the\nperformance of off-grid small-cell base stations (scBS) with finite battery\ncapacity and design a new power-availability-aware cell association based on\nperiodical broadcast of the scBS battery level. Each mobile terminal (MT)\ntargets its own set of available scBSs before association, i.e. the set of\nscBSs that can guarantee service provided (i) the scBS battery level, (ii) the\npower required to satisfy a received power constraint at each MT, given the\nscBS-MT distance and the shadowing attenuation, and (iii) the estimated power\nconsumed to serve other MTs potentially associated to the same scBS, which is\ncomputed using stochastic geometry tools. Next, we develop for it a tractable\nperformance analysis and derive closed-form expressions for the probability of\npower outage and the coverage probability. By dynamically adapting to the\nfluctuations of the base station battery and user power requirement, the\nproposed cell association allows a more even distribution of the available\nenergy in the network, brings robustness against harvesting impairment and\nthereby, significantly outperforms conventional strategies. \n\n"}
{"id": "1607.02381", "contents": "Title: On the Optimal Boolean Function for Prediction under Quadratic Loss Abstract: Suppose $Y^{n}$ is obtained by observing a uniform Bernoulli random vector\n$X^{n}$ through a binary symmetric channel. Courtade and Kumar asked how large\nthe mutual information between $Y^{n}$ and a Boolean function\n$\\mathsf{b}(X^{n})$ could be, and conjectured that the maximum is attained by a\ndictator function. An equivalent formulation of this conjecture is that\ndictator minimizes the prediction cost in a sequential prediction of $Y^{n}$\nunder logarithmic loss, given $\\mathsf{b}(X^{n})$. In this paper, we study the\nquestion of minimizing the sequential prediction cost under a different\n(proper) loss function - the quadratic loss. In the noiseless case, we show\nthat majority asymptotically minimizes this prediction cost among all Boolean\nfunctions. We further show that for weak noise, majority is better than\ndictator, and that for strong noise dictator outperforms majority. We\nconjecture that for quadratic loss, there is no single sequence of Boolean\nfunctions that is simultaneously (asymptotically) optimal at all noise levels. \n\n"}
{"id": "1607.02699", "contents": "Title: At Every Corner: Determining Corner Points of Two-User Gaussian\n  Interference Channels Abstract: The corner points of the capacity region of the two-user Gaussian\ninterference channel under strong or weak interference are determined using the\nnotions of almost Gaussian random vectors, almost lossless addition of random\nvectors, and almost linearly dependent random vectors. In particular, the\n\"missing\" corner point problem is solved in a manner that differs from previous\nworks in that it avoids the use of integration over a continuum of SNR values\nor of Monge-Kantorovitch transportation problems. \n\n"}
{"id": "1607.03948", "contents": "Title: Making recommendations bandwidth aware Abstract: This paper asks how much we can gain in terms of bandwidth and user\nsatisfaction, if recommender systems became bandwidth aware and took into\naccount not only the user preferences, but also the fact that they may need to\nserve these users under bandwidth constraints, as is the case over wireless\nnetworks. We formulate this as a new problem in the context of index coding: we\nrelax the index coding requirements to capture scenarios where each client has\npreferences associated with messages. The client is satisfied to receive any\nmessage she does not already have, with a satisfaction proportional to her\npreference for that message. We consistently find, over a number of scenarios\nwe sample, that although the optimization problems are in general NP-hard,\nsignificant bandwidth savings are possible even when restricted to polynomial\ntime algorithms. \n\n"}
{"id": "1607.04352", "contents": "Title: Ergodic Spectral Efficiency in MIMO Cellular Networks Abstract: This paper shows how the application of stochastic geometry to the analysis\nof wireless networks is greatly facilitated by (i) a clear separation of time\nscales, (ii) the abstraction of small-scale effects via ergodicity, and (iii)\nan interference model that reflects the receiver's lack of knowledge of how\neach individual interference term is faded. These procedures render the\nanalysis both more manageable and more precise, as well as more amenable to the\nincorporation of subsequent features. In particular, the paper presents\nanalytical characterizations of the ergodic spectral efficiency of cellular\nnetworks with single-user multiple-input multiple-output (MIMO) and\nsectorization. These characterizations, in the form of easy-to-evaluate\nexpressions, encompass the coverage, the distribution of spectral efficiency\nover the network locations, and the average thereof. \n\n"}
{"id": "1607.05222", "contents": "Title: Information-theoretic bounds and phase transitions in clustering, sparse\n  PCA, and submatrix localization Abstract: We study the problem of detecting a structured, low-rank signal matrix\ncorrupted with additive Gaussian noise. This includes clustering in a Gaussian\nmixture model, sparse PCA, and submatrix localization. Each of these problems\nis conjectured to exhibit a sharp information-theoretic threshold, below which\nthe signal is too weak for any algorithm to detect. We derive upper and lower\nbounds on these thresholds by applying the first and second moment methods to\nthe likelihood ratio between these \"planted models\" and null models where the\nsignal matrix is zero. Our bounds differ by at most a factor of root two when\nthe rank is large (in the clustering and submatrix localization problems, when\nthe number of clusters or blocks is large) or the signal matrix is very sparse.\nMoreover, our upper bounds show that for each of these problems there is a\nsignificant regime where reliable detection is information- theoretically\npossible but where known algorithms such as PCA fail completely, since the\nspectrum of the observed matrix is uninformative. This regime is analogous to\nthe conjectured 'hard but detectable' regime for community detection in sparse\ngraphs. \n\n"}
{"id": "1607.05345", "contents": "Title: Low-Complexity Recursive Convolutional Precoding for OFDM-based\n  Large-Scale Antenna System Abstract: Large-scale antenna (LSA) has gained a lot of attention recently since it can\nsignificantly improve the performance of wireless systems. Similar to\nmultiple-input multiple-output (MIMO) orthogonal frequency division\nmultiplexing (OFDM) or MIMO-OFDM, LSA can be also combined with OFDM to deal\nwith frequency selectivity in wireless channels. However, such combination\nsuffers from substantially increased complexity proportional to the number of\nantennas in LSA systems. For the conventional implementation of LSA-OFDM, the\nnumber of inverse fast Fourier transforms (IFFTs) increases with the antenna\nnumber since each antenna requires an IFFT for OFDM modulation. Furthermore,\nzero-forcing (ZF) precoding is required in LSA systems to support more users,\nand the required matrix inversion leads to a huge computational burden. In this\npaper, we propose a low-complexity recursive convolutional precoding to address\nthe issues above. The traditional ZF precoding can be implemented through the\nrecursive convolutional precoding in the time domain so that only one IFFT is\nrequired for each user and the matrix inversion can be also avoided. Simulation\nresults show that the proposed approach can achieve the same performance as\nthat of ZF but with much lower complexity. \n\n"}
{"id": "1607.07234", "contents": "Title: Doubly Massive mmWave MIMO Systems: Using Very Large Antenna Arrays at\n  Both Transmitter and Receiver Abstract: One of the key features of next generation wireless communication systems\nwill be the use of frequencies in the range 10-100GHz (aka mmWave band) in\ndensely populated indoor and outdoor scenarios. Due to the reduced wavelength,\nantenna arrays with a large number of antennas can be packed in very small\nvolumes, making thus it possible to consider, at least in principle,\ncommunication links wherein not only the base-station, but also the user\ndevice, are equipped with very large antenna arrays. We denote this\nconfiguration as a \"doubly-massive\" MIMO wireless link. This paper introduces\nthe concept of doubly massive MIMO systems at mmWave, showing that at mmWave\nthe fundamentals of the massive MIMO regime are completely different from what\nhappens at conventional sub-6 GHz cellular frequencies. It is shown for\ninstance that the multiplexing capabilities of the channel and its rank are no\nlonger ruled by the number of transmit and receive antennas, but rather by the\nnumber of scattering clusters in the surrounding environment. The implications\nof the doubly massive MIMO regime on the transceiver processing, on the system\nenergy efficiency and on the system throughput are also discussed. \n\n"}
{"id": "1607.08025", "contents": "Title: Mutual Information Optimally Local Private Discrete Distribution\n  Estimation Abstract: Consider statistical learning (e.g. discrete distribution estimation) with\nlocal $\\epsilon$-differential privacy, which preserves each data provider's\nprivacy locally, we aim to optimize statistical data utility under the privacy\nconstraints. Specifically, we study maximizing mutual information between a\nprovider's data and its private view, and give the exact mutual information\nbound along with an attainable mechanism: $k$-subset mechanism as results. The\nmutual information optimal mechanism randomly outputs a size $k$ subset of the\noriginal data domain with delicate probability assignment, where $k$ varies\nwith the privacy level $\\epsilon$ and the data domain size $d$. After analysing\nthe limitations of existing local private mechanisms from mutual information\nperspective, we propose an efficient implementation of the $k$-subset mechanism\nfor discrete distribution estimation, and show its optimality guarantees over\nexisting approaches. \n\n"}
{"id": "1608.00698", "contents": "Title: Covert Communication in the Presence of an Uninformed Jammer Abstract: Recent work has established that when transmitter Alice wishes to communicate\nreliably to recipient Bob without detection by warden Willie, with additive\nwhite Gaussian noise (AWGN) channels between all parties, communication is\nlimited to $\\mathcal{O}(\\sqrt{n})$ bits in $n$ channel uses. However, this\nassumes Willie has an accurate statistical characterization of the channel.\nWhen Willie has uncertainty about such and his receiver is limited to a\nthreshold test on the received power, Alice can transmit covertly with a power\nthat does not decrease with $n$, thus conveying $\\mathcal{O}(n)$ bits covertly\nand reliably in $n$ uses of an AWGN channel. Here, we consider covert\ncommunication of $\\mathcal{O}(n)$ bits in $n$ channel uses while generalizing\nthe environment and removing any restrictions on Willie's receiver. We assume\nan uninformed \"jammer\" is present to help Alice, and we consider AWGN and block\nfading channels. In some scenarios, Willie's optimal detector is a threshold\ntest on the received power. When the channel between the jammer and Willie has\nmultiple fading blocks per codeword, a threshold test on the received power is\nnot optimal. However, we establish that Alice can remain covert with a transmit\npower that does not decrease with $n$ even when Willie employs an optimal\ndetector. \n\n"}
{"id": "1608.02337", "contents": "Title: Large-Scale Cloud Radio Access Networks with Practical Constraints:\n  Asymptotic Analysis and Its Implications Abstract: Large-scale cloud radio access network (LS-CRAN) is a highly promising\nnext-generation cellular network architecture whereby lots of base stations\n(BSs) equipped with a massive antenna array are connected to a cloud-computing\nbased central processor unit via digital front/backhaul links. This paper\nstudies an asymptotic behavior of downlink (DL) performance of a LS-CRAN with\nthree practical constraints: 1) limited transmit power, 2) limited\nfront/backhaul capacity, and 3) limited pilot resource. As an asymptotic\nperformance measure, the scaling exponent of the\nsignal-to-interference-plus-noise-ratio (SINR) is derived for interference-free\n(IF), maximum-ratio transmission (MRT), and zero-forcing (ZF) operations. Our\nasymptotic analysis reveals four fundamental operating regimes and the\nperformances of both MRT and ZF operations are fundamentally limited by the UL\ntransmit power for estimating user's channel state information, not the DL\ntransmit power. We obtain the conditions that MRT or ZF operation becomes\ninterference-free, i.e., order-optimal with three practical constraints.\nSpecifically, as higher UL transmit power is provided, more users can be\nassociated and the data rate per user can be increased simultaneously while\nkeeping the order-optimality as long as the total front/backhaul overhead is\n$\\Omega(N^{\\eta_{\\rm{bs}}+\\eta_{\\rm{ant}}+\\eta_{\\rm{user}}+\\frac{2}{\\alpha}\\rho^{\\rm{ul}}})$\nand $\\Omega(N^{\\eta_{\\rm{user}}-\\eta_{\\rm{bs}}})$ pilot resources are\navailable. It is also shown that how the target quality-of-service (QoS) in\nterms of SINR and the number of users satisfying the target QoS can\nsimultaneously grow as the network size increases and the way how the network\nsize increases under the practical constraints, which can provide meaningful\ninsights for future cellular systems. \n\n"}
{"id": "1608.03638", "contents": "Title: Downlink Performance of Pilot-Reused HetNet with Large-Scale Antenna\n  Arrays Abstract: Considering a heterogeneous network (HetNet) where both macro base station\n(BS) and small cell (SC) nodes are equipped with massive antennas, this paper\nstudies the performance for multiple-input multiple-output (MIMO) downlinks\nwhen the macro and small cells share the same spectrum and hence interfere with\neach other. Suppose that the large-scale antenna arrays at both macro BS and SC\nnodes employ maximum-ratio transmission (MRT) or zero-forcing transmission\n(ZFT) precoding, and transmit data streams to the served users simultaneously.\nA new pilot reuse pattern among SCs is proposed for channel estimation. Taking\ninto account imperfect channel state information (CSI), capacity lower bounds\nfor MRT and ZFT are derived, respectively, in closed-form expressions involving\nonly statistical CSI. Then asymptotic analyses for massive arrays are presented\nunder specific power scaling laws. Subsequently, two user scheduling\nalgorithms, greedy scheduling algorithm and asymptotical scheduling algorithm\n(ASA), are proposed based on derived capacity lower bounds and asymptotic\nanalyses, respectively. ASA is demonstrated to be a near optimal in the\nasymptotic regime and has low complexity. Finally, the derived closed-form\nexpressions are verified to be accurate predictors of the system performance by\nMonte-Carlo simulations. Numerical results demonstrate the effectiveness of\nasymptotic analysis and proposed user scheduling schemes. \n\n"}
{"id": "1608.03875", "contents": "Title: Sensor Selection and Power Allocation Strategies for Energy Harvesting\n  Wireless Sensor Networks Abstract: In this paper, we investigate the problem of jointly selecting a predefined\nnumber of energy-harvesting (EH) sensors and computing the optimal power\nallocation. The ultimate goal is to minimize the reconstruction distortion at\nthe fusion center. This optimization problem is, unfortunately, non-convex. To\ncircumvent that, we propose two suboptimal strategies: (i) a joint sensor\nselection and power allocation (JSS-EH) scheme that, we prove, is capable of\niteratively finding a stationary solution of the original problem from a\nsequence of surrogate convex problems; and (ii) a separate sensor selection and\npower allocation (SS-EH) scheme, on which basis we can identify a sensible\nsensor selection and analytically find a power allocation policy by solving a\nconvex problem. We also discuss the interplay between the two strategies.\nPerformance in terms of reconstruction distortion, impact of initialization,\nactual subsets of selected sensors and computed power allocation policies,\netc., is assessed by means of computer simulations. To that aim, an EH-agnostic\nsensor selection strategy, a lower bound on distortion, and an online version\nof the SS-EH and JSS-EH schemes are derived and used for benchmarking. \n\n"}
{"id": "1608.04141", "contents": "Title: Low Rank Phase Retrieval Abstract: We develop two iterative algorithms for solving the low rank phase retrieval\n(LRPR) problem. LRPR refers to recovering a low-rank matrix $\\X$ from\nmagnitude-only (phaseless) measurements of random linear projections of its\ncolumns. Both methods consist of a spectral initialization step followed by an\niterative algorithm to maximize the observed data likelihood. We obtain sample\ncomplexity bounds for our proposed initialization approach to provide a good\napproximation of the true $\\X$. When the rank is low enough, these bounds are\nsignificantly lower than what existing single vector phase retrieval algorithms\nneed. Via extensive experiments, we show that the same is also true for the\nproposed complete algorithms. \n\n"}
{"id": "1608.04460", "contents": "Title: Microcanonical thermodynamics in general physical theories Abstract: Microcanonical thermodynamics studies the operations that can be performed on\nsystems with well-defined energy. So far, this approach has been applied to\nclassical and quantum systems. Here we extend it to arbitrary physical\ntheories, proposing two requirements for the development of a general\nmicrocanonical framework. We then formulate three resource theories,\ncorresponding to three different sets of basic operations: i) random reversible\noperations, resulting from reversible dynamics with fluctuating parameters, ii)\nnoisy operations, generated by the interaction with ancillas in the\nmicrocanonical state, and iii) unital operations, defined as the operations\nthat preserve the microcanonical state. We focus our attention on a class of\nphysical theories, called sharp theories with purification, where these three\nsets of operations exhibit remarkable properties. Firstly, each set is\ncontained into the next. Secondly, the convertibility of states by unital\noperations is completely characterised by a majorisation criterion. Thirdly,\nthe three sets are equivalent in terms of state convertibility if and only if\nthe dynamics allowed by theory satisfy a suitable condition, which we call\nunrestricted reversibility. Under this condition, we derive a duality between\nthe resource theory of microcanonical thermodynamics and the resource theory of\npure bipartite entanglement. \n\n"}
{"id": "1609.00833", "contents": "Title: An Upper Bound on the Sum Capacity of the Downlink Multicell Processing\n  with Finite Backhaul Capacity Abstract: In this paper, we study upper bounds on the sum capacity of the downlink\nmulticell processing model with finite backhaul capacity for the simple case of\n2 base stations and 2 mobile users. It is modelled as a two-user multiple\naccess diamond channel. It consists of a first hop from the central processor\nto the base stations via orthogonal links of finite capacity, and the second\nhop from the base stations to the mobile users via a Gaussian interference\nchannel. The converse is derived using the converse tools of the multiple\naccess diamond channel and that of the Gaussian MIMO broadcast channel. Through\nnumerical results, it is shown that our upper bound improves upon the existing\nupper bound greatly in the medium backhaul capacity range, and as a result, the\ngap between the upper bounds and the sum rate of the time-sharing of the known\nachievable schemes is significantly reduced. \n\n"}
{"id": "1609.01233", "contents": "Title: Multivariate Dependence Beyond Shannon Information Abstract: Accurately determining dependency structure is critical to discovering a\nsystem's causal organization. We recently showed that the transfer entropy\nfails in a key aspect of this---measuring information flow---due to its\nconflation of dyadic and polyadic relationships. We extend this observation to\ndemonstrate that this is true of all such Shannon information measures when\nused to analyze multivariate dependencies. This has broad implications,\nparticularly when employing information to express the organization and\nmechanisms embedded in complex systems, including the burgeoning efforts to\ncombine complex network theory with information theory. Here, we do not suggest\nthat any aspect of information theory is wrong. Rather, the vast majority of\nits informational measures are simply inadequate for determining the meaningful\ndependency structure within joint probability distributions. Therefore, such\ninformation measures are inadequate for discovering intrinsic causal relations.\nWe close by demonstrating that such distributions exist across an arbitrary set\nof variables. \n\n"}
{"id": "1609.02411", "contents": "Title: Velocity-Aware Handover Management in Two-Tier Cellular Networks Abstract: While network densification is considered an important solution to cater the\never-increasing capacity demand, its effect on the handover (HO) rate is\noverlooked. In dense 5G networks, HO delays may neutralize or even negate the\ngains offered by network densification. Hence, user mobility imposes a\nnontrivial challenge to harvest capacity gains via network densification. In\nthis paper, we propose a velocity-aware HO management scheme for two-tier\ndownlink cellular network to mitigate the HO effect on the foreseen\ndensification throughput gains. The proposed HO scheme sacrifices the best BS\nconnectivity, by skipping HO to some BSs along the user's trajectory, to\nmaintain longer connection durations and reduce HO rates. Furthermore, the\nproposed scheme enables cooperative BS service and strongest interference\ncancellation to compensate for skipping the best connectivity. To this end, we\nconsider different HO skipping scenarios and develop a velocity-aware\nmathematical model, via stochastic geometry, to quantify the performance of the\nproposed HO scheme in terms of the coverage probability and user throughput.\nThe results highlight the HO rate problem in dense cellular environments and\nshow the importance of the proposed HO schemes. Finally, the value of BS\ncooperation along with handover skipping is quantified for different user\nmobility profiles. \n\n"}
{"id": "1609.03142", "contents": "Title: Exact Dimensionality Reduction for Partial Line Spectra Estimation\n  Problems Abstract: Line spectral estimation theory aims to estimate the off-the-grid spectral\ncomponents of a time signal with optimal precision. Recent results have shown\nthat it is possible to recover signals having sparse line spectra from few\ntemporal observations via the use of convex programming. However, the\ncomputational cost of such approaches remains the major flaw to their\napplication to practical systems. This work investigates the recovery of\nspectrally sparse signal from low-dimensional partial measurements. It is shown\nin the first part of this paper that, under a light assumption on the\nsub-sampling matrix, the partial line spectral estimation problems can be\nrelaxed into a low-dimensional semidefinite program. The proof technique relies\non a novel extension of the Gram parametrization to subspaces of trigonometric\npolynomials.\n  The second part of this work focuses on the analysis of two particular\nsub-sampling patterns: multirate sampling and random selection sampling. It is\nshown that those sampling patterns guarantee perfect recovery of the line\nspectra, and that the reconstruction can be achieved in a poly-logarithmic time\nwith respect to the full observation case. Moreover, the sub-Nyquist recovery\ncapabilities of such sampling patterns are highlighted. The atomic soft\nthresholding method is adapted in the presented framework to estimate sparse\nspectra in noisy environments, and a scalable algorithm for its resolution is\nproposed. \n\n"}
{"id": "1609.03258", "contents": "Title: Joint Power and Subcarrier Allocation for Multicarrier Full-Duplex\n  Systems Abstract: In this paper, we investigate resource allocation for multicarrier\ncommunication systems employing a full-duplex base station for serving multiple\nhalf-duplex downlink and uplink users simultaneously. We study the joint power\nand subcarrier allocation design for the maximization of the weighted sum\nthroughput of the system. The algorithm design is formulated as a mixed\ncombinatorial non-convex optimization problem and obtaining the globally\noptimal solution may require prohibitively high computational complexity.\nTherefore, a low computational complexity suboptimal iterative algorithm\nexploiting successive convex approximation is proposed to obtain a locally\noptimal solution. Simulation results confirm that the proposed suboptimal\nalgorithm obtains a substantial improvement in system throughput compared to\nvarious existing baseline schemes. \n\n"}
{"id": "1609.03836", "contents": "Title: Robust Resource Allocation for MIMO Wireless Powered Communication\n  Networks Based on a Non-linear EH Model Abstract: In this paper, we consider a multiple-input multiple-output wireless powered\ncommunication network (MIMO-WPCN), where multiple users harvest energy from a\ndedicated power station in order to be able to transmit their information\nsignals to an information receiving station. Employing a practical non-linear\nenergy harvesting (EH) model, we propose a joint time allocation and power\ncontrol scheme, which takes into account the uncertainty regarding the channel\nstate information (CSI) and provides robustness against imperfect CSI\nknowledge. In particular, we formulate two non-convex optimization problems for\ndifferent objectives, namely system sum throughput maximization and\nmaximization of the minimum individual throughput across all wireless powered\nusers. To overcome the non-convexity, we apply several transformations along\nwith a one-dimensional search to obtain an efficient resource allocation\nalgorithm. Numerical results reveal that a significant performance gain can be\nachieved when the resource allocation is designed based on the adopted\nnon-linear EH model instead of the conventional linear EH model. Besides,\nunlike a non-robust baseline scheme designed for perfect CSI, the proposed\nresource allocation schemes are shown to be robust against imperfect CSI\nknowledge. \n\n"}
{"id": "1609.05080", "contents": "Title: Block Compressed Sensing Based Distributed Device Detection for M2M\n  Communications Abstract: In this work, we utilize the framework of compressed sensing (CS) for\ndistributed device detection and resource allocation in large-scale\nmachine-to-machine (M2M) communication networks. The devices deployed in the\nnetwork are partitioned into clusters according to some pre-defined criteria.\nMoreover, the devices in each cluster are assigned a unique signature of a\nparticular design that can be used to indicate their active status to the\nnetwork. The proposed scheme in this work mainly consists of two essential\nsteps: (i) The base station (BS) detects the active clusters and the number of\nactive devices in each cluster using a novel block sketching algorithm, and\nthen assigns a certain amount of resources accordingly. (ii) Each active device\ndetects its ranking among all the active devices in its cluster using an\nenhanced greedy algorithm and accesses the corresponding resource for\ntransmission based on the ranking. By exploiting the correlation in the device\nbehaviors and the sparsity in the activation pattern of the M2M devices, the\ndevice detection problem is thus tackled as a CS support recovery procedure for\na particular binary block-sparse signal $x\\in\\mathbb{B}^N$ -- with block\nsparsity $K_B$ and in-block sparsity $K_I$ over block size $d$. Theoretical\nanalysis shows that the activation pattern of the M2M devices can be reliably\nreconstructed within an acquisition time of $\\mathcal{O}(\\max\\{K_B\\log N,\nK_BK_I\\log d\\})$, which achieves a better scaling and less computational\ncomplexity of $\\mathcal{O}(N(K_I^2+\\log N))$ compared with standard CS\nalgorithms. Moreover, extensive simulations confirm the robustness of the\nproposed scheme in the detection process, especially in terms of higher\ndetection probability and reduced access delay when compared with conventional\nschemes like LTE random access (RA) procedure and classic cluster-based access\napproaches. \n\n"}
{"id": "1609.06432", "contents": "Title: Polar Coding for Empirical Coordination of Signals and Actions over\n  Noisy Channels Abstract: -We develop a polar coding scheme for empirical coordination in a two-node\nnetwork with a noisy link in which the input and output signals have to be\ncoordinated with the source and the reconstruction. In the case of non-causal\nencoding and decoding, we show that polar codes achieve the best known inner\nbound for the empirical coordination region, provided that a vanishing rate of\ncommon randomness is available. This scheme provides a constructive alternative\nto random binning and coding proofs. \n\n"}
{"id": "1609.08182", "contents": "Title: Availability-Aware Cell Association for Hybrid Power Supply Networks\n  with Adaptive Bias Abstract: New challenges have emerged from the integration of renewable energy sources\nwithin the conventional electrical grid which powers base stations (BS).\nEnergy-aware traffic offloading brings a promising solution to maintain the\nuser performance while reducing the carbon footprint. Focusing on downlink\ncellular networks consisting of on-grid, off-grid and hybrid BSs, we propose a\nnovel power-aware biased cell association where each user independently\npartitions BSs into two sets and applies different association biases for each,\ndepending on the type of power, renewable or not, that can be requested for\nservice. The gain provided by such strategy regarding the probability of power\noutage and the average grid power consumption is investigated. To capture their\ndual nature, the bias applied for association with a hybrid BS is not constant\namong users nor over time, and is dynamically tailored to the fluctuations of\nthe BS battery level, the user power requirement and the estimated power\nconsumed to serve other users potentially associated with the same BS. Such\napproach allows to efficiently share the available energy among BSs and turns\nhigh heterogeneity in the BS powering into advantage. \n\n"}
{"id": "1609.08813", "contents": "Title: Reduced-Complexity SCL Decoding of Multi-CRC-Aided Polar Codes Abstract: Cyclic redundancy check (CRC) aided polar codes are capable of achieving\nbetter performance than low-density parity-check (LDPC) codes under the\nsuccessive cancelation list (SCL) decoding scheme. However, the SCL decoding\nscheme suffers from very high space and time complexities. Especially, the high\nspace complexity is a major concern for adopting polar codes in modern mobile\ncommunication standards. In this paper, we propose a novel reduced-complexity\nsuccessive cancelation list (R-SCL) decoding scheme which is effective to\nreduce the space complexity. Simulation results show that, with a (2048, 1024)\nCRC-aided polar code, the R-SCL decoders with 25% reduction of space complexity\nand 8% reduction of time complexity can still achieve almost the same\nperformance levels as those decoded by SCL decoders. To further reduce the\ncomplexity, we propose a multi-CRC coding scheme for polar codes. Simulation\nresults show that, with a (16384, 8192) multi-CRC-aided polar code, a R-SCL\ndecoder with about 85% reduction of space complexity and 20% reduction of time\ncomplexity results in a worst performance loss of only 0.04dB. \n\n"}
{"id": "1609.09530", "contents": "Title: Fast L1-L2 minimization via a proximal operator Abstract: This paper aims to develop new and fast algorithms for recovering a sparse\nvector from a small number of measurements, which is a fundamental problem in\nthe field of compressive sensing (CS). Currently, CS favors incoherent systems,\nin which any two measurements are as little correlated as possible. In reality,\nhowever, many problems are coherent, and conventional methods such as $L_1$\nminimization do not work well. Recently, the difference of the $L_1$ and $L_2$\nnorms, denoted as $L_1$-$L_2$, is shown to have superior performance over the\nclassic $L_1$ method, but it is computationally expensive. We derive an\nanalytical solution for the proximal operator of the $L_1$-$L_2$ metric, and it\nmakes some fast $L_1$ solvers such as forward-backward splitting (FBS) and\nalternating direction method of multipliers (ADMM) applicable for $L_1$-$L_2$.\nWe describe in details how to incorporate the proximal operator into FBS and\nADMM and show that the resulting algorithms are convergent under mild\nconditions. Both algorithms are shown to be much more efficient than the\noriginal implementation of $L_1$-$L_2$ based on a difference-of-convex approach\nin the numerical experiments. \n\n"}
{"id": "1610.00287", "contents": "Title: Iterative Null-space Projection Method with Adaptive Thresholding in\n  Sparse Signal Recovery and Matrix Completion Abstract: Adaptive thresholding methods have proved to yield high SNRs and fast\nconvergence in finding the solution to the Compressed Sensing (CS) problems.\nRecently, it was observed that the robustness of a class of iterative sparse\nrecovery algorithms such as Iterative Method with Adaptive Thresholding (IMAT)\nhas outperformed the well-known LASSO algorithm in terms of reconstruction\nquality, convergence speed, and the sensitivity to the noise. In this paper, we\nintroduce a new method towards solving the CS problem. The logic of this method\nis based on iterative projections of the thresholded signal onto the null-space\nof the sensing matrix. The thresholding is carried out by recovering the\nsupport of the desired signal by projection on thresholding subspaces. The\nsimulations reveal that the proposed method has the capability of yielding\nnoticeable output SNR values with about as many samples as twice the sparsity\nnumber, while other methods fail to recover the signals when approaching the\nalgebraic bound for the number of samples required. The computational\ncomplexity of our method is also comparable to other methods as observed in the\nsimulations. We have also extended our Algorithm to Matrix Completion (MC)\nscenarios and compared its efficiency to other well-reputed approaches for MC\nin the literature. \n\n"}
{"id": "1610.02512", "contents": "Title: Location-Aided Pilot Contamination Avoidance for Massive MIMO Systems Abstract: Pilot contamination, defined as the interference during the channel\nestimation process due to reusing the same pilot sequences in neighboring\ncells, can severely degrade the performance of massive multiple-input\nmultiple-output systems. In this paper, we propose a location-based approach to\nmitigating the pilot contamination problem for uplink multiple-input\nmultiple-output systems. Our approach makes use of the approximate locations of\nmobile devices to provide good estimates of the channel statistics between the\nmobile devices and their corresponding base stations. Specifically, we aim at\navoiding pilot contamination even when the number of base station antennas is\nnot very large, and when multiple users from different cells, or even in the\nsame cell, are assigned the same pilot sequence. First, we characterize a\ndesired angular region of the target user at the serving base station based on\nthe number of base station antennas and the location of the target user, and\nmake the observation that in this region the interference is close to zero due\nto the spatial separability. Second, based on this observation, we propose\npilot coordination methods for multi-user multi-cell scenarios to avoid pilot\ncontamination. The numerical results indicate that the proposed pilot\ncontamination avoidance schemes enhance the quality of the channel estimation\nand thereby improve the per-cell sum rate offered by target base stations. \n\n"}
{"id": "1610.06098", "contents": "Title: Leveraging Diversity and Sparsity in Blind Deconvolution Abstract: This paper considers recovering $L$-dimensional vectors $\\boldsymbol{w}$, and\n$\\boldsymbol{x}_1,\\boldsymbol{x}_2, \\ldots, \\boldsymbol{x}_N$ from their\ncircular convolutions $\\boldsymbol{y}_n = \\boldsymbol{w}*\\boldsymbol{x}_n, \\ n\n= 1,2,3, \\ldots, N$. The vector $\\boldsymbol{w}$ is assumed to be $S$-sparse in\na known basis that is spread out in the Fourier domain, and each input\n$\\boldsymbol{x}_n$ is a member of a known $K$-dimensional random subspace.\n  We prove that whenever $K + S\\log^2S \\lesssim L /\\log^4(LN)$, the problem can\nbe solved effectively by using only the nuclear-norm minimization as the convex\nrelaxation, as long as the inputs are sufficiently diverse and obey $N \\gtrsim\n\\log^2(LN)$. By \"diverse inputs\", we mean that the $\\boldsymbol{x}_n$'s belong\nto different, generic subspaces. To our knowledge, this is the first\ntheoretical result on blind deconvolution where the subspace to which\n$\\boldsymbol{w}$ belongs is not fixed, but needs to be determined.\n  We discuss the result in the context of multipath channel estimation in\nwireless communications. Both the fading coefficients, and the delays in the\nchannel impulse response $\\boldsymbol{w}$ are unknown. The encoder codes the\n$K$-dimensional message vectors randomly and then transmits coded messages\n$\\boldsymbol{x}_n$'s over a fixed channel one after the other. The decoder then\ndiscovers all of the messages and the channel response when the number of\nsamples taken for each received message are roughly greater than\n$(K+S\\log^2S)\\log^4(LN)$, and the number of messages is roughly at least\n$\\log^2(LN)$. \n\n"}
{"id": "1610.07297", "contents": "Title: Channel capacity of polar coding with a given polar mismatched\n  successive cancellation decoder Abstract: Ar{\\i}kan's polar coding, is by now a well studied technique that allows\nachieving the symmetric capacity of binary input memoryless channels with low\ncomplexity encoding and decoding, provided that the polar decoding architecture\nis used and the decoding metric is matched to the true channel. In this paper,\nwe analyze communication rates that are achievable when the polar\ncoding/decoding architecture is used with the decoder using an incorrect model\nof the channel. We define the `polar mismatched capacity' as an analogue of the\nclassical mismatched capacity, give an expression for it, and derive bounds on\nit. \n\n"}
{"id": "1610.07576", "contents": "Title: Node Isolation of Secure Wireless Sensor Networks under a Heterogeneous\n  Channel Model Abstract: We investigate the secure connectivity of wireless sensor networks under a\nheterogeneous random key predistribution scheme and a heterogeneous channel\nmodel. In particular, we study a random graph formed by the intersection of an\ninhomogeneous random key graph with an inhomogeneous Erd\\H{o}s-R\\'enyi graph.\nThe former graph is naturally induced by the heterogeneous random key\npredistribution scheme while the latter graph constitutes a heterogeneous\non/off channel model; wherein, the wireless channel between a class-$i$ node\nand a class-$j$ node is on with probability $\\alpha_{ij}$ independently. We\npresent conditions (in the form of zero-one laws) on how to scale the\nparameters of the intersection model so that it has no isolated node with high\nprobability as the number of nodes gets large. We also present numerical\nresults to support these zero-one laws in the finite-node regime. \n\n"}
{"id": "1610.08004", "contents": "Title: On Fractional Linear Network Coding Solution of Multiple-Unicast\n  Networks Abstract: It is known that there exists a multiple-unicast network which has a rate $1$\nlinear network coding solution if and only if the characteristic of the finite\nfield belongs to a given finite or co-finite set of primes. In this paper, we\nshow that for any non-zero positive rational number $\\frac{k}{n}$, there exists\na multiple-unicast network which has a rate $\\frac{k}{n}$ fractional linear\nnetwork coding solution if and only if the characteristic of the finite field\nbelongs to a given finite or co-finite set of primes. \n\n"}
{"id": "1610.08070", "contents": "Title: Low rank matrix recovery from Clifford orbits Abstract: We prove that low-rank matrices can be recovered efficiently from a small\nnumber of measurements that are sampled from orbits of a certain matrix group.\nAs a special case, our theory makes statements about the phase retrieval\nproblem. Here, the task is to recover a vector given only the amplitudes of its\ninner product with a small number of vectors from an orbit. Variants of the\ngroup in question have appeared under different names in many areas of\nmathematics. In coding theory and quantum information, it is the complex\nClifford group; in time-frequency analysis the oscillator group; and in\nmathematical physics the metaplectic group. It affords one particularly small\nand highly structured orbit that includes and generalizes the discrete Fourier\nbasis: While the Fourier vectors have coefficients of constant modulus and\nphases that depend linearly on their index, the vectors in said orbit have\nphases with a quadratic dependence. In quantum information, the orbit is used\nextensively and is known as the set of stabilizer states. We argue that due to\ntheir rich geometric structure and their near-optimal recovery properties,\nstabilizer states form an ideal model for structured measurements for phase\nretrieval. Our results hold for $m\\geq C \\kappa_r r d \\log(d)$ measurements,\nwhere the oversampling factor k varies between $\\kappa_r=1$ and $\\kappa_r =\nr^2$ depending on the orbit. The reconstruction is stable towards both additive\nnoise and deviations from the assumption of low rank. If the matrices of\ninterest are in addition positive semidefinite, reconstruction may be performed\nby a simple constrained least squares regression. Our proof methods could be\nadapted to cover orbits of other groups. \n\n"}
{"id": "1610.09312", "contents": "Title: User Cooperation for Enhanced Throughput Fairness in Wireless Powered\n  Communication Networks Abstract: This paper studies a novel user cooperation method in a wireless powered\ncooperative communication network (WPCN) in which a pair of distributed\nterminal users first harvest wireless energy broadcasted by one energy node\n(EN) and then use the harvested energy to transmit information to a destination\nnode (DN). In particular, the two cooperating users exchange their independent\ninformation with each other so as to form a virtual antenna array and transmit\njointly to the DN. By allowing the users to share their harvested energy to\ntransmit each other's information, the proposed method can effectively mitigate\nthe inherent user unfairness problem in WPCN, where one user may suffer from\nvery low data rate due to poor energy harvesting performance and high data\ntransmission consumptions. Depending on the availability of channel state\ninformation at the transmitters, we consider the two users cooperating using\neither coherent or non-coherent data transmissions. In both cases, we derive\nthe maximum common throughput achieved by the cooperation schemes through\noptimizing the time allocation on wireless energy transfer, user message\nexchange, and joint information transmissions in a fixed-length time slot. We\nalso perform numerical analysis to study the impact of channel conditions on\nthe system performance. By comparing with some existing benchmark schemes, our\nresults demonstrate the effectiveness of the proposed user cooperation in a\nWPCN under different application scenarios. \n\n"}
{"id": "1611.01278", "contents": "Title: Topological Interference Management: Linear Cooperation is not useful\n  for Wyner's Networks Abstract: In this work, we study the value of cooperative transmission in wireless\nnetworks if no channel state information is available at the transmitters (no\nCSIT). Our focus is on large locally connected networks, where each transmitter\nis connected to the receiver that has the same index as well as L succeeding\nreceivers. The cases of L=1 and L=2 represent Wyner's asymmetric and symmetric\nnetwork models, respectively. The considered rate criterion is the per user\nDegrees of Freedom (puDoF) as the number of transmitter-receiver pairs goes to\ninfinity. For the case when L=1, it was shown in previous work that linear\ncooperation schemes do not increases the puDoF value, and that the optimal\nscheme relies on assigning each message to a single transmitter and using\northogonal access (TDMA). Here, we extend this conclusion to the case where\nL=2, by proving optimality of TDMA in this case as well. We conclude by\ndiscussing whether increasing the value of L can create a value for linear\ncooperation schemes from a DoF perspective. \n\n"}
{"id": "1611.01428", "contents": "Title: Almost universal codes for MIMO wiretap channels Abstract: Despite several works on secrecy coding for fading and MIMO wiretap channels\nfrom an error probability perspective, the construction of\ninformation-theoretically secure codes over such channels remains an open\nproblem. In this paper, we consider a fading wiretap channel model where the\ntransmitter has only partial statistical channel state information. Our channel\nmodel includes static channels, i.i.d. block fading channels, and ergodic\nstationary fading with fast decay of large deviations for the eavesdropper's\nchannel.\n  We extend the flatness factor criterion from the Gaussian wiretap channel to\nfading and MIMO wiretap channels, and establish a simple design criterion where\nthe normalized product distance / minimum determinant of the lattice and its\ndual should be maximized simultaneously.\n  Moreover, we propose concrete lattice codes satisfying this design criterion,\nwhich are built from algebraic number fields with constant root discriminant in\nthe single-antenna case, and from division algebras centered at such number\nfields in the multiple-antenna case. The proposed lattice codes achieve strong\nsecrecy and semantic security for all rates $R<C_b-C_e-\\kappa$, where $C_b$ and\n$C_e$ are Bob and Eve's channel capacities respectively, and $\\kappa$ is an\nexplicit constant gap. Furthermore, these codes are almost universal in the\nsense that a fixed code is good for secrecy for a wide range of fading models.\n  Finally, we consider a compound wiretap model with a more restricted\nuncertainty set, and show that rates $R<\\bar{C}_b-\\bar{C}_e-\\kappa$ are\nachievable, where $\\bar{C}_b$ is a lower bound for Bob's capacity and\n$\\bar{C}_e$ is an upper bound for Eve's capacity for all the channels in the\nset. \n\n"}
{"id": "1611.01579", "contents": "Title: Decentralized Caching and Coded Delivery with Distinct Cache Capacities Abstract: Decentralized proactive caching and coded delivery is studied in a content\ndelivery network, where each user is equipped with a cache memory, not\nnecessarily of equal capacity. Cache memories are filled in advance during the\noff-peak traffic period in a decentralized manner, i.e., without the knowledge\nof the number of active users, their identities, or their particular demands.\nUser demands are revealed during the peak traffic period, and are served\nsimultaneously through an error-free shared link. The goal is to find the\nminimum delivery rate during the peak traffic period that is sufficient to\nsatisfy all possible demand combinations. A group-based decentralized caching\nand coded delivery scheme is proposed, and it is shown to improve upon the\nstate-of-the-art in terms of the minimum required delivery rate when there are\nmore users in the system than files. Numerical results indicate that the\nimprovement is more significant as the cache capacities of the users become\nmore skewed. A new lower bound on the delivery rate is also presented, which\nprovides a tighter bound than the classical cut-set bound. \n\n"}
{"id": "1611.01879", "contents": "Title: Linear Sketching over $\\mathbb F_2$ Abstract: We initiate a systematic study of linear sketching over $\\mathbb F_2$. For a\ngiven Boolean function $f \\colon \\{0,1\\}^n \\to \\{0,1\\}$ a randomized $\\mathbb\nF_2$-sketch is a distribution $\\mathcal M$ over $d \\times n$ matrices with\nelements over $\\mathbb F_2$ such that $\\mathcal Mx$ suffices for computing\n$f(x)$ with high probability. We study a connection between $\\mathbb\nF_2$-sketching and a two-player one-way communication game for the\ncorresponding XOR-function. Our results show that this communication game\ncharacterizes $\\mathbb F_2$-sketching under the uniform distribution (up to\ndependence on error). Implications of this result include: 1) a composition\ntheorem for $\\mathbb F_2$-sketching complexity of a recursive majority\nfunction, 2) a tight relationship between $\\mathbb F_2$-sketching complexity\nand Fourier sparsity, 3) lower bounds for a certain subclass of symmetric\nfunctions. We also fully resolve a conjecture of Montanaro and Osborne\nregarding one-way communication complexity of linear threshold functions by\ndesigning an $\\mathbb F_2$-sketch of optimal size.\n  Furthermore, we show that (non-uniform) streaming algorithms that have to\nprocess random updates over $\\mathbb F_2$ can be constructed as $\\mathbb\nF_2$-sketches for the uniform distribution with only a minor loss. In contrast\nwith the previous work of Li, Nguyen and Woodruff (STOC'14) who show an\nanalogous result for linear sketches over integers in the adversarial setting\nour result doesn't require the stream length to be triply exponential in $n$\nand holds for streams of length $\\tilde O(n)$ constructed through uniformly\nrandom updates. Finally, we state a conjecture that asks whether optimal\none-way communication protocols for XOR-functions can be constructed as\n$\\mathbb F_2$-sketches with only a small loss. \n\n"}
{"id": "1611.03169", "contents": "Title: On $\\mathbb{Z}_{2}\\mathbb{Z}_{2}[u]$-$(1+u)$-additive constacyclic Abstract: In this paper, we study $\\mathbb{Z}_{2}\\mathbb{Z}_{2}[u]$-$(1+u)$-additive\nconstacyclic code of arbitrary length. Firstly, we study the algebraic\nstructure of this family of codes and a set of generator polynomials for this\nfamily as a $(\\mathbb{Z}_{2}+u\\mathbb{Z}_{2})[x]$-submodule of the ring\n$R_{\\alpha,\\beta}$. Secondly, we give the minimal generating sets of this\nfamily codes, and we determine the relationship of generators between the\n$\\mathbb{Z}_{2}\\mathbb{Z}_{2}[u]$-$(1+u)$-additive constacyclic codes and its\ndual and give the parameters in terms of the degrees of the generator\npolynomials of the code. Lastly, we also study\n$\\mathbb{Z}_{2}\\mathbb{Z}_{2}[u]$-$(1+u)$-additive constacyclic code in terms\nof the Gray images. \n\n"}
{"id": "1611.03274", "contents": "Title: Constructions and bounds for separating hash families Abstract: In this paper, we present a new construction for strong separating hash\nfamilies by using hypergraphs and obtain some optimal separating hash families.\n  We also improve some previously known bounds of separating hash families. \n\n"}
{"id": "1611.06924", "contents": "Title: The Sphere Packing Bound via Augustin's Method Abstract: A sphere packing bound (SPB) with a prefactor that is polynomial in the block\nlength $n$ is established for codes on a length $n$ product channel $W_{[1,n]}$\nassuming that the maximum order $1/2$ Renyi capacity among the component\nchannels, i.e. $\\max_{t\\in[1,n]} C_{1/2,W_{t}}$, is $\\mathit{O}(\\ln n)$. The\nreliability function of the discrete stationary product channels with feedback\nis bounded from above by the sphere packing exponent. Both results are proved\nby first establishing a non-asymptotic SPB. The latter result continues to hold\nunder a milder stationarity hypothesis. \n\n"}
{"id": "1611.09914", "contents": "Title: Batch and PIR Codes and Their Connections to Locally Repairable Codes Abstract: In this survey, two related families of codes are discussed: batch codes and\ncodes for private information retrieval. These two families can be viewed as\nnatural generalizations of locally repairable codes, which were extensively\nstudied in the context of coding for fault tolerance in distributed data\nstorage systems. Bounds on the parameters of the codes, as well as basic\nconstructions, are presented. Connections between different code families are\ndiscussed. \n\n"}
{"id": "1611.09964", "contents": "Title: Performance Limits of Energy Detection Systems with Massive Receiver\n  Arrays Abstract: Energy detection (ED) is an attractive technique for symbol detection at\nreceivers equipped with a large number of antennas, for example in millimeter\nwave communication systems. This paper investigates the performance bounds of\nED with pulse amplitude modulation (PAM) in large antenna arrays under single\nstream transmission and fast fading assumptions. The analysis leverages\ninformation-theoretic tools and semi-numerical approach to provide bounds on\nthe information rate, which are shown to be tight in the low and high\nsignal-to-noise ratio (SNR) regimes, respectively. For a fixed constellation\nsize, the impact of the number of antennas and SNR on the achievable\ninformation rate is investigated. Based on the results, heuristics are provided\nfor the choice of the cardinality of the adaptive modulation scheme as a\nfunction of the SNR and the number of antennas. \n\n"}
{"id": "1611.09981", "contents": "Title: Decoding from Pooled Data: Sharp Information-Theoretic Bounds Abstract: Consider a population consisting of n individuals, each of whom has one of d\ntypes (e.g. their blood type, in which case d=4). We are allowed to query this\ndatabase by specifying a subset of the population, and in response we observe a\nnoiseless histogram (a d-dimensional vector of counts) of types of the pooled\nindividuals. This measurement model arises in practical situations such as\npooling of genetic data and may also be motivated by privacy considerations. We\nare interested in the number of queries one needs to unambiguously determine\nthe type of each individual. In this paper, we study this information-theoretic\nquestion under the random, dense setting where in each query, a random subset\nof individuals of size proportional to n is chosen. This makes the problem a\nparticular example of a random constraint satisfaction problem (CSP) with a\n\"planted\" solution. We establish almost matching upper and lower bounds on the\nminimum number of queries m such that there is no solution other than the\nplanted one with probability tending to 1 as n tends to infinity. Our proof\nrelies on the computation of the exact \"annealed free energy\" of this model in\nthe thermodynamic limit, which corresponds to the exponential rate of decay of\nthe expected number of solution to this planted CSP. As a by-product of the\nanalysis, we show an identity of independent interest relating the Gaussian\nintegral over the space of Eulerian flows of a graph to its spanning tree\npolynomial. \n\n"}
{"id": "1612.00128", "contents": "Title: Trace Codes with Few Weights over $\\mathbb{F}_p+u\\mathbb{F}_p$ Abstract: We construct an infinite family of two-Lee-weight and three-Lee-weight codes\nover the chain ring $\\mathbb{F}_p+u\\mathbb{F}_p.$ They have the algebraic\nstructure of abelian codes. Their Lee weight distribution is computed by using\nGauss sums. Then by using a linear Gray map, we obtain an infinite family of\nabelian codes with few weights over $\\mathbb{F}_p$. In particular, we obtain an\ninfinite family of two-weight codes which meets the Griesmer bound with\nequality. Finally, an application to secret sharing schemes is given. \n\n"}
{"id": "1612.01464", "contents": "Title: Finite blocklength and moderate deviation analysis of hypothesis testing\n  of correlated quantum states and application to classical-quantum channels\n  with memory Abstract: Martingale concentration inequalities constitute a powerful mathematical tool\nin the analysis of problems in a wide variety of fields ranging from\nprobability and statistics to information theory and machine learning. Here we\napply techniques borrowed from this field to quantum hypothesis testing, which\nis the problem of discriminating quantum states belonging to two different\nsequences $\\{\\rho_n\\}_{n}$ and $\\{\\sigma_n\\}_n$. We obtain upper bounds on the\nfinite blocklength type II Stein- and Hoeffding errors, which, for i.i.d.\nstates, are in general tighter than the corresponding bounds obtained by\nAudenaert, Mosonyi and Verstraete [Journal of Mathematical Physics, 53(12),\n2012]. We also derive finite blocklength bounds and moderate deviation results\nfor pairs of sequences of correlated states satisfying a (non-homogeneous)\nfactorization property. Examples of such sequences include Gibbs states of spin\nchains with translation-invariant finite range interaction, as well as finitely\ncorrelated quantum states. We apply our results to find bounds on the capacity\nof a certain class of classical-quantum channels with memory, which satisfy a\nso-called channel factorization property- both in the finite blocklength and\nmoderate deviation regimes. \n\n"}
{"id": "1612.03841", "contents": "Title: Locally Recoverable Codes with Availability $t\\geq 2$ from Fiber\n  Products of Curves Abstract: We generalize the construction of locally recoverable codes on algebraic\ncurves given by Barg, Tamo and Vl\\u{a}du\\c{t} to those with arbitrarily many\nrecovery sets by exploiting the structure of fiber products of curves.\nEmploying maximal curves, we create several new families of locally recoverable\ncodes with multiple recovery sets, including codes with two recovery sets from\nthe generalized Giulietti and Korchm\\'{a}ros (GK) curves and the Suzuki curves,\nand new locally recoverable codes with many recovery sets based on the\nHermitian curve, using a fiber product construction of van der Geer and van der\nVlugt. In addition, we consider the relationship between local error recovery\nand global error correction as well as the availability required to locally\nrecover any pattern of a fixed number of erasures. \n\n"}
{"id": "1612.04176", "contents": "Title: Jointly Broadcasting Data and Power with Quality of Service Guarantees Abstract: In this work, we consider a scenario wherein an energy harvesting wireless\nradio equipment sends information to multiple receivers alongside powering\nthem. In addition to harvesting the incoming radio frequency (RF) energy, the\nreceivers also harvest energy from {its environment (e.g., solar energy)}. This\ncommunication framework is captured by a fading Gaussian Broadcast Channel\n(GBC) with energy harvesting transmitter and receivers. In order to ensure\n{some quality of service (QoS)} in data reception among the receivers, we\nimpose a \\textit{minimum-rate} requirement on data transmission. For the\nsetting in place, we characterize the fundamental limits in jointly\ntransmitting information and power subject to a QoS guarantee, for three\ncardinal receiver structures namely, \\textit{ideal}, \\textit{time-switching}\nand \\textit{power-splitting}. We show that a time-switching receiver can\n{switch} between {information reception mode} and {energy harvesting mode},\n\\textit{without} the transmitter's knowledge of the same and \\textit{without}\nany extra \\textit{rate loss}. We also prove that, for the same amount of power\ntransferred, on average, a power-splitting receiver supports higher data rates\ncompared to a time-switching receiver. \n\n"}
{"id": "1612.04703", "contents": "Title: Lexicodes over Finite Principal Left Ideal Rings Abstract: Let R be a finite principal left ideal ring. Via a total ordering of the ring\nelements and an ordered basis a lexicographic ordering of the module R^n is\nproduced. This is used to set up a greedy algorithm that selects vectors for\nwhich all linear combination with the previously selected vectors satisfy a\npre-specified selection property and updates the to-be-constructed code to the\nlinear hull of the vectors selected so far. The output is called a lexicode.\nThis process was discussed earlier in the literature for fields and chain\nrings. In this paper we investigate the properties of such lexicodes over\nfinite principal left ideal rings and show that the total ordering of the ring\nelements has to respect containment of ideals in order for the algorithm to\nproduce meaningful results. Only then it is guaranteed that the algorithm is\nexhaustive and thus produces codes that are maximal with respect to inclusion.\nIt is further illustrated that the output of the algorithm heavily depends on\nthe total ordering and chosen basis. \n\n"}
{"id": "1612.04775", "contents": "Title: Operating Massive MIMO in Unlicensed Bands for Enhanced Coexistence and\n  Spatial Reuse Abstract: We propose to operate massive multiple-input multiple output (MIMO) cellular\nbase stations (BSs) in unlicensed bands. We denote such system as massive MIMO\nunlicensed (mMIMO-U). We design the key procedures required at a cellular BS to\nguarantee coexistence with nearby Wi-Fi devices operating in the same band. In\nparticular, spatial reuse is enhanced by actively suppressing interference\ntowards neighboring Wi-Fi devices. Wi-Fi interference rejection is also\nperformed during an enhanced listen-before-talk (LBT) phase. These operations\nenable Wi-Fi devices to access the channel as though no cellular BSs were\ntransmitting, and vice versa. Under concurrent Wi-Fi and BS transmissions, the\ndownlink rates attainable by cellular user equipment (UEs) are degraded by the\nWi-Fi-generated interference. To mitigate this effect, we select a suitable set\nof UEs to be served in the unlicensed band accounting for a measure of the\nWi-Fi/UE proximity. Our results show that the so-designed mMIMO-U allows\nsimultaneous cellular and Wi-Fi transmissions by keeping their mutual\ninterference below the regulatory threshold. Compared to a system without\ninterference suppression, Wi-Fi devices enjoy a median interference power\nreduction of between 3 dB with 16 antennas and 18 dB with 128 antennas. With\nmMIMO-U, cellular BSs can also achieve large data rates without significantly\ndegrading the performance of Wi-Fi networks deployed within their coverage\narea. \n\n"}
{"id": "1612.04943", "contents": "Title: Antenna Selection in MIMO Non-orthogonal Multiple Access Systems Abstract: This paper considers the joint antenna selection (AS) problem for a classical\ntwo-user MIMO non-orthogonal multiple access (NOMA) system, where both the base\nstation (BS) and users (UEs) are equipped with multiple antennas. Specifically,\nseveral computationally-efficient AS algorithms are developed for two\ncommonly-used NOMA scenarios: fixed power allocation NOMA (F-NOMA) and\ncognitive radio-inspired NOMA (CR-NOMA). For the F-NOMA system, two novel AS\nschemes, namely max-max-max AS (A$^3$-AS) and max-min-max AS (AIA-AS), are\nproposed to maximize the system sum-rate, without and with the consideration of\nuser fairness, respectively. In the CR-NOMA network, a novel AS algorithm,\ntermed maximum-channel-gain-based AS (MCG-AS), is proposed to maximize the\nachievable rate of the secondary user, under the condition that the primary\nuser's quality of service requirement is satisfied. The asymptotic closed-form\nexpressions of the average sum-rate for A$^3$-AS and AIA-AS and that of the\naverage rate of the secondary user for MCG-AS are derived, respectively.\nNumerical results demonstrate that the AIA-AS provides better user-fairness,\nwhile the A$^3$-AS achieves a near-optimal sum-rate in F-NOMA systems. For the\nCR-NOMA scenario, MCG-AS achieves a near-optimal performance in a wide SNR\nregime. Furthermore, all the proposed AS algorithms yield a significant\ncomputational complexity reduction, compared to exhaustive search-based\ncounterparts. \n\n"}
{"id": "1612.07289", "contents": "Title: Full-Duplex MIMO Small-Cell Networks with Interference Cancellation Abstract: Full-duplex (FD) technology is envisaged as a key component for future mobile\nbroadband networks due to its ability to boost the spectral efficiency. FD\nsystems can transmit and receive simultaneously on the same frequency at the\nexpense of residual self-interference (SI) and additional interference to the\nnetwork compared with half-duplex (HD) transmission. This paper analyzes the\nperformance of wireless networks with FD multi-antenna base stations (BSs) and\nHD user equipments (UEs) using stochastic geometry. Our analytical results\nquantify the success probability and the achievable spectral efficiency and\nindicate the amount of SI cancellation needed for beneficial FD operation. The\nadvantages of multi-antenna BSs/UEs are shown and the performance gains\nachieved by balancing desired signal power increase and interference\ncancellation are derived. The proposed framework aims at shedding light on the\nsystem-level gains of FD mode with respect to HD mode in terms of network\nthroughput, and provides design guidelines for the practical implementation of\nFD technology in large small-cell networks. \n\n"}
{"id": "1612.07417", "contents": "Title: Cache-induced Hierarchical Cooperation in Wireless Device-to-Device\n  Caching Networks Abstract: We consider a wireless device-to-device (D2D) caching network where n nodes\nare placed on a regular grid of area A(n). Each node caches L_C*F (coded) bits\nfrom a library of size L*F bits, where L is the number of files and F is the\nsize of each file. Each node requests a file from the library independently\naccording to a popularity distribution. Under a commonly used \"physical model\"\nand Zipf popularity distribution, we characterize the optimal per-node capacity\nscaling law for extended networks (i.e., A(n). Moreover, we propose a\ncache-induced hierarchical cooperation scheme and associated cache content\nplacement optimization algorithm to achieve the optimal per-node capacity\nscaling law. When the path loss exponent \\alpha<3, the optimal per-node\ncapacity scaling law achieved by the cache-induced hierarchical cooperation can\nbe significantly better than that achieved by the existing state-of-the-art\nschemes. To the best of our knowledge, this is the first work that completely\ncharacterizes the per-node capacity scaling law for wireless caching networks\nunder the physical model and Zipf distribution with an arbitrary skewness\nparameter \\tau. While scaling law analysis yields clean results, it may not\naccurately reflect the throughput performance of a large network with a finite\nnumber of nodes. Therefore, we also analyze the throughput of the proposed\ncache-induced hierarchical cooperation for networks of practical size. The\nanalysis and simulations verify that cache-induced hierarchical cooperation can\nalso achieve a large throughput gain over the cache-assisted multihop scheme\nfor networks of practical size. \n\n"}
{"id": "1612.08785", "contents": "Title: Non-Linear Programming: Maximize SNR for Designing Spreading Sequence -\n  Part II: Conditions for Optimal Spreading Sequences Abstract: Signal to Noise Ratio (SNR) is an important index for wireless\ncommunications. In CDMA systems, spreading sequences are utilized. This series\nof papers show the method to derive spreading sequences as the solutions of\nnon-linear programming: maximize SNR. In this paper, we derive the optimization\nproblems with the expression SNR derived in Part I and the necessary conditions\nfor the global solutions. We numerically solve the problems and evaluate the\nsolutions with two factors, mean-square correlations and maximum mean-square\ncorrelations. \n\n"}
{"id": "1612.09495", "contents": "Title: The $(n,m,k,\\lambda)$-Strong External Difference Family with $m \\geq 5$\n  Exists Abstract: The notion of strong external difference family (SEDF) in a finite abelian\ngroup $(G,+)$ is raised by M. B. Paterson and D. R. Stinson [5] in 2016 and\nmotivated by its application in communication theory to construct $R$-optimal\nregular algebraic manipulation detection code. A series of\n$(n,m,k,\\lambda)$-SEDF's have been constructed in [5, 4, 2, 1] with $m=2$. In\nthis note we present an example of (243, 11, 22, 20)-SEDF in finite field\n$\\mathbb{F}_q$ $(q=3^5=243).$ This is an answer for the following problem\nraised in [5] and continuously asked in [4, 2, 1]: if there exists an\n$(n,m,k,\\lambda)$-SEDF for $m\\geq 5$. \n\n"}
{"id": "1701.00858", "contents": "Title: Constrained Low-rank Matrix Estimation: Phase Transitions, Approximate\n  Message Passing and Applications Abstract: This article is an extended version of previous work of the authors [40, 41]\non low-rank matrix estimation in the presence of constraints on the factors\ninto which the matrix is factorized. Low-rank matrix factorization is one of\nthe basic methods used in data analysis for unsupervised learning of relevant\nfeatures and other types of dimensionality reduction. We present a framework to\nstudy the constrained low-rank matrix estimation for a general prior on the\nfactors, and a general output channel through which the matrix is observed. We\ndraw a paralel with the study of vector-spin glass models - presenting a\nunifying way to study a number of problems considered previously in separate\nstatistical physics works. We present a number of applications for the problem\nin data analysis. We derive in detail a general form of the low-rank\napproximate message passing (Low- RAMP) algorithm, that is known in statistical\nphysics as the TAP equations. We thus unify the derivation of the TAP equations\nfor models as different as the Sherrington-Kirkpatrick model, the restricted\nBoltzmann machine, the Hopfield model or vector (xy, Heisenberg and other) spin\nglasses. The state evolution of the Low-RAMP algorithm is also derived, and is\nequivalent to the replica symmetric solution for the large class of vector-spin\nglass models. In the section devoted to result we study in detail phase\ndiagrams and phase transitions for the Bayes-optimal inference in low-rank\nmatrix estimation. We present a typology of phase transitions and their\nrelation to performance of algorithms such as the Low-RAMP or commonly used\nspectral methods. \n\n"}
{"id": "1701.01010", "contents": "Title: Divergence and Sufficiency for Convex Optimization Abstract: Logarithmic score and information divergence appear in information theory,\nstatistics, statistical mechanics, and portfolio theory. We demonstrate that\nall these topics involve some kind of optimization that leads directly to\nregret functions and such regret functions are often given by a Bregman\ndivergence. If the regret function also fulfills a sufficiency condition it\nmust be proportional to information divergence. We will demonstrate that\nsufficiency is equivalent to the apparently weaker notion of locality and it is\nalso equivalent to the apparently stronger notion of monotonicity. These\nsufficiency conditions have quite different relevance in the different areas of\napplication, and often they are not fulfilled. Therefore sufficiency conditions\ncan be used to explain when results from one area can be transferred directly\nto another and when one will experience differences. \n\n"}
{"id": "1701.01103", "contents": "Title: Minimax R\\'enyi Redundancy Abstract: The redundancy for universal lossless compression of discrete memoryless\nsources in Campbell's setting is characterized as a minimax R\\'enyi divergence,\nwhich is shown to be equal to the maximal $\\alpha$-mutual information via a\ngeneralized redundancy-capacity theorem. Special attention is placed on the\nanalysis of the asymptotics of minimax R\\'enyi divergence, which is determined\nup to a term vanishing in blocklength. \n\n"}
{"id": "1701.01800", "contents": "Title: Variable-Length Lossy Compression Allowing Positive Overflow and Excess\n  Distortion Probabilities Abstract: This paper investigates the problem of variable-length lossy source coding\nallowing a positive excess distortion probability and an overflow probability\nof codeword lengths. Novel one-shot achievability and converse bounds of the\noptimal rate are established by a new quantity based on the smooth max entropy\n(the smooth R\\'enyi entropy of order zero). To derive the achievability bounds,\nwe give an explicit code construction based on a distortion ball instead of\nusing the random coding argument. The basic idea of the code construction is\nsimilar to the optimal code construction in the variable-length lossless source\ncoding. Our achievability bounds are slightly different, depending on whether\nthe encoder is stochastic or deterministic. One-shot results yield a general\nformula of the optimal rate for blocklength $n$. In addition, our general\nformula is applied to asymptotic analysis for a stationary memoryless source.\nAs a result, we derive a single-letter characterization of the optimal rate by\nusing the rate-distortion and rate-dispersion functions. \n\n"}
{"id": "1701.01952", "contents": "Title: Joint Optimization of Power Splitting and Allocation for SWIPT in\n  Interference Alignment Networks Abstract: Interference alignment (IA) is a promising solution for interference\nmanagement in wireless networks. On the other hand, simultaneous wireless\ninformation and power transfer (SWIPT) has become an emerging technique.\nAlthough some works have been done on IA and SWIPT, these two important areas\nhave traditionally been addressed separately in the literature. In this paper,\nwe propose to use a common framework to jointly study IA and SWIPT. We analyze\nthe performance of SWIPT in IA networks. Specifically, we derive the upper\nbound of the power that can be harvested in IA networks. In addition, we show\nthat, to improve the performance of wireless power transfer and information\ntransmission, users should be dynamically selected as energy harvesting (EH) or\ninformation decoding (ID) terminals. Furthermore, we design two\neasy-implemented SWIPT-user selection (SWIPT-US) algorithms in IA networks. To\noptimize the ID and EH performance of SWIPT in IA networks, a power-splitting\noptimization (PSO) algorithm is proposed when power splitters are available,\nand its closed-form optimal solutions are derived. Power allocation in the PSO\nalgorithm is also studied to further optimize the performance. Simulation\nresults are presented to show the effectiveness of the proposed algorithms. \n\n"}
{"id": "1701.02081", "contents": "Title: A Decentralized Optimization Framework for Energy Harvesting Devices Abstract: Designing decentralized policies for wireless communication networks is a\ncrucial problem, which has only been partially solved in the literature so far.\nIn this paper, we propose the Decentralized Markov Decision Process (Dec-MDP)\nframework to analyze a wireless sensor network with multiple users which access\na common wireless channel. We consider devices with energy harvesting\ncapabilities, so that they aim at balancing the energy arrivals with the data\ndepartures and with the probability of colliding with other nodes. Randomly\nover time, an access point triggers a SYNC slot, wherein it recomputes the\noptimal transmission parameters of the whole network, and distributes this\ninformation. Every node receives its own policy, which specifies how it should\naccess the channel in the future, and, thereafter, proceeds in a fully\ndecentralized fashion, without interacting with other entities in the network.\nWe propose a multi-layer Markov model, where an external MDP manages the jumps\nbetween SYNC slots, and an internal Dec-MDP computes the optimal policy in the\nnear future. We numerically show that, because of the harvesting, a fully\northogonal scheme (e.g., TDMA-like) is suboptimal in energy harvesting\nscenarios, and the optimal trade-off lies between an orthogonal and a random\naccess system. \n\n"}
{"id": "1701.03515", "contents": "Title: Multiple Illumination Phaseless Super-Resolution (MIPS) with\n  Applications To Phaseless DOA Estimation and Diffraction Imaging Abstract: Phaseless super-resolution is the problem of recovering an unknown signal\nfrom measurements of the magnitudes of the low frequency Fourier transform of\nthe signal. This problem arises in applications where measuring the phase, and\nmaking high-frequency measurements, are either too costly or altogether\ninfeasible. The problem is especially challenging because it combines the\ndifficult problems of phase retrieval and classical super-resolution \n\n"}
{"id": "1701.04301", "contents": "Title: Generalized Expectation Consistent Signal Recovery for Nonlinear\n  Measurements Abstract: In this paper, we propose a generalized expectation consistent signal\nrecovery algorithm to estimate the signal $\\mathbf{x}$ from the nonlinear\nmeasurements of a linear transform output $\\mathbf{z}=\\mathbf{A}\\mathbf{x}$.\nThis estimation problem has been encountered in many applications, such as\ncommunications with front-end impairments, compressed sensing, and phase\nretrieval. The proposed algorithm extends the prior art called generalized\nturbo signal recovery from a partial discrete Fourier transform matrix\n$\\mathbf{A}$ to a class of general matrices. Numerical results show the\nexcellent agreement of the proposed algorithm with the theoretical\nBayesian-optimal estimator derived using the replica method. \n\n"}
{"id": "1701.04318", "contents": "Title: The Velocity of the Propagating Wave for Spatially Coupled Systems with\n  Applications to LDPC Codes Abstract: We consider the dynamics of message passing for spatially coupled codes and,\nin particular, the set of density evolution equations that tracks the profile\nof decoding errors along the spatial direction of coupling. It is known that,\nfor suitable boundary conditions and after a transient phase, the error profile\nexhibits a \"solitonic behavior\". Namely, a uniquely-shaped wavelike solution\ndevelops, that propagates with constant velocity. Under this assumption we\nderive an analytical formula for the velocity in the framework of a continuum\nlimit of the spatially coupled system. The general formalism is developed for\nspatially coupled low-density parity-check codes on general binary memoryless\nsymmetric channels which form the main system of interest in this work. We\napply the formula for special channels and illustrate that it matches the\ndirect numerical evaluation of the velocity for a wide range of noise values. A\npossible application of the velocity formula to the evaluation of finite size\nscaling law parameters is also discussed. We conduct a similar analysis for\ngeneral scalar systems and illustrate the findings with applications to\ncompressive sensing and generalized low-density parity-check codes on the\nbinary erasure or binary symmetric channels. \n\n"}
{"id": "1701.04439", "contents": "Title: Dandelion: Redesigning the Bitcoin Network for Anonymity Abstract: Bitcoin and other cryptocurrencies have surged in popularity over the last\ndecade. Although Bitcoin does not claim to provide anonymity for its users, it\nenjoys a public perception of being a `privacy-preserving' financial system. In\nreality, cryptocurrencies publish users' entire transaction histories in\nplaintext, albeit under a pseudonym; this is required for transaction\nvalidation. Therefore, if a user's pseudonym can be linked to their human\nidentity, the privacy fallout can be significant. Recently, researchers have\ndemonstrated deanonymization attacks that exploit weaknesses in the Bitcoin\nnetwork's peer-to-peer (P2P) networking protocols. In particular, the P2P\nnetwork currently forwards content in a structured way that allows observers to\ndeanonymize users. In this work, we redesign the P2P network from first\nprinciples with the goal of providing strong, provable anonymity guarantees. We\npropose a simple networking policy called Dandelion, which achieves\nnearly-optimal anonymity guarantees at minimal cost to the network's utility.\nWe also provide a practical implementation of Dandelion. \n\n"}
{"id": "1701.04954", "contents": "Title: Bounds on the Size and Asymptotic Rate of Subblock-Constrained Codes Abstract: The study of subblock-constrained codes has recently gained attention due to\ntheir application in diverse fields. We present bounds on the size and\nasymptotic rate for two classes of subblock-constrained codes. The first class\nis binary constant subblock-composition codes (CSCCs), where each codeword is\npartitioned into equal sized subblocks, and every subblock has the same fixed\nweight. The second class is binary subblock energy-constrained codes (SECCs),\nwhere the weight of every subblock exceeds a given threshold. We present novel\nupper and lower bounds on the code sizes and asymptotic rates for binary CSCCs\nand SECCs. For a fixed subblock length and small relative distance, we show\nthat the asymptotic rate for CSCCs (resp. SECCs) is strictly lower than the\ncorresponding rate for constant weight codes (CWCs) (resp. heavy weight codes\n(HWCs)). Further, for codes with high weight and low relative distance, we show\nthat the asymptotic rates for CSCCs is strictly lower than that of SECCs, which\ncontrasts that the asymptotic rate for CWCs is equal to that of HWCs. We also\nprovide a correction to an earlier result by Chee et al. (2014) on the\nasymptotic CSCC rate. Additionally, we present several numerical examples\ncomparing the rates for CSCCs and SECCs with those for constant weight codes\nand heavy weight codes. \n\n"}
{"id": "1701.06610", "contents": "Title: The Augustin Center and The Sphere Packing Bound For Memoryless Channels Abstract: For any channel with a convex constraint set and finite Augustin capacity,\nexistence of a unique Augustin center and associated Erven-Harremoes bound are\nestablished. Augustin-Legendre capacity, center, and radius are introduced and\nproved to be equal to the corresponding Renyi-Gallager entities. Sphere packing\nbounds with polynomial prefactors are derived for codes on two families of\nchannels: (possibly non-stationary) memoryless channels with multiple additive\ncost constraints and stationary memoryless channels with convex constraints on\nthe empirical distribution of the input codewords. \n\n"}
{"id": "1701.06981", "contents": "Title: Multi-Layer Generalized Linear Estimation Abstract: We consider the problem of reconstructing a signal from multi-layered\n(possibly) non-linear measurements. Using non-rigorous but standard methods\nfrom statistical physics we present the Multi-Layer Approximate Message Passing\n(ML-AMP) algorithm for computing marginal probabilities of the corresponding\nestimation problem and derive the associated state evolution equations to\nanalyze its performance. We also give the expression of the asymptotic free\nenergy and the minimal information-theoretically achievable reconstruction\nerror. Finally, we present some applications of this measurement model for\ncompressed sensing and perceptron learning with structured matrices/patterns,\nand for a simple model of estimation of latent variables in an auto-encoder. \n\n"}
{"id": "1701.07098", "contents": "Title: A novel alternative to Cloud RAN for throughput densification: Coded\n  pilots and fast user-packet scheduling at remote radio heads Abstract: We consider wireless networks of remote radio heads (RRH) with large\nantenna-arrays, operated in TDD, with uplink (UL) training and\nchannel-reciprocity based downlink (DL) transmission. To achieve large area\nspectral efficiencies, we advocate the use of methods that rely on rudimentary\nscheduling, decentralized operation at each RRH and user-centric DL\ntransmission.\n  A slotted system is assumed, whereby users are randomly scheduled (e.g., via\nshuffled round robin) in slots and across the limited pilot dimensions per\nslot. As a result, multiple users in the vicinity of an RRH can simultaneously\ntransmit pilots on the same pilot dimension (and thus interfering with one\nanother). Each RRH performs rudimentary processing of the pilot observations in\n\"sectors\". In a sector, the RRH is able to resolve a scheduled user's channel\nwhen that user is determined to be the only one among the scheduled users (on\nthe same pilot dimension) with significant received power in the sector.\nSubsequently, only the subset of scheduled users whose channels are resolved in\nat least one sector can be served by the system.\n  We consider a spatially consistent evaluation of the area multiplexing gains\nby means of a Poisson Point Process (PPP) problem formulation where RRHs,\nblockers, scatterers and scheduled user terminals are all PPPs with individual\nintensities. Also, we study directional training at the user terminals. Our\nsimulations suggest that, by controlling the intensity of the scheduled user\nPPP and the user-pilot beam-width, many fold improvements can be expected in\narea multiplexing gains with respect to conventional spatial pilot reuse\nsystems. \n\n"}
{"id": "1701.07118", "contents": "Title: Repairing Reed-Solomon Codes With Two Erasures Abstract: Despite their exceptional error-correcting properties, Reed-Solomon (RS)\ncodes have been overlooked in distributed storage applications due to the\ncommon belief that they have poor repair bandwidth: A naive repair approach\nwould require the whole file to be reconstructed in order to recover a single\nerased codeword symbol. In a recent work, Guruswami and Wootters (STOC'16)\nproposed a single-erasure repair method for RS codes that achieves the optimal\nrepair bandwidth amongst all linear encoding schemes. We extend their trace\ncollection technique to cope with two erasures. \n\n"}
{"id": "1701.07245", "contents": "Title: Optimal Binary $(5,3)$ Projective Space Codes from Maximal Partial\n  Spreads Abstract: Recently a construction of optimal non-constant dimension subspace codes,\nalso termed projective space codes, has been reported in a paper of\nHonold-Kiermaier-Kurz. Restricted to binary codes in a 5-dimensional ambient\nspace with minimum subspace distance 3, these optimal codes were interpreted in\nterms of maximal partial spreads of 2-dimensional subspaces. In a parallel\ndevelopment, an optimal binary (5,3) code was obtained by a minimal change\nstrategy on a nearly optimal example of Etzion and Vardy. In this article, we\nreport several examples of optimal binary (5,3) codes obtained by the\napplication of this strategy combined with changes to the spread structure of\nexisting codes. We also establish that, based on the types of constituent\nspreads, our examples lie outside the framework of the existing construction. \n\n"}
{"id": "1701.07340", "contents": "Title: Locally Repairable Codes with Unequal Local Erasure Correction Abstract: When a node in a distributed storage system fails, it needs to be promptly\nrepaired to maintain system integrity. While typical erasure codes can provide\na significant storage advantage over replication, they suffer from poor repair\nefficiency. Locally repairable codes (LRCs) tackle this issue by reducing the\nnumber of nodes participating in the repair process (locality), at the cost of\nreduced minimum distance. In this paper, we study the tradeoff between locality\nand minimum distance of LRCs with local codes that have arbitrary distance\nrequirements. Unlike existing methods where both the locality and the local\ndistance requirements imposed on every node are identical, we allow the\nrequirements to vary arbitrarily from node to node. Such a property can be an\nadvantage for distributed storage systems with non-homogeneous characteristics.\nWe present Singleton-type distance upper bounds and also provide an optimal\ncode construction with respect to these bounds. In addition, the feasible rate\nregion is characterized by dimension upper bounds that do not depend on the\ndistance. \n\n"}
{"id": "1701.07501", "contents": "Title: Locality and Availability of Array Codes Constructed from Subspaces Abstract: Ever-increasing amounts of data are created and processed in internet-scale\ncompanies such as Google, Facebook, and Amazon. The efficient storage of such\ncopious amounts of data has thus become a fundamental and acute problem in\nmodern computing. No single machine can possibly satisfy such immense storage\ndemands. Therefore, distributed storage systems (DSS), which rely on tens of\nthousands of storage nodes, are the only viable solution. Such systems are\nbroadly used in all modern internet-scale systems. However, the design of a DSS\nposes a number of crucial challenges, markedly different from single-user\nstorage systems. Such systems must be able to reconstruct the data efficiently,\nto overcome failure of servers, to correct errors, etc. Lots of research was\ndone in the last few years to answer these challenges and the research is\nincreasing in parallel to the increasing amount of stored data.\n  The main goal of this paper is to consider codes which have two of the most\nimportant features of distributed storage systems, namely, locality and\navailability. Our codes are array codes which are based on subspaces of a\nlinear space over a finite field. We present several constructions of such\ncodes which are $q$-analog to some of the known block codes. Some of these\ncodes possess independent intellectual merit. We examine the locality and\navailability of the constructed codes. In particular we distinguish between two\ntypes of locality and availability, node vs.~symbol, locality and availability.\nTo our knowledge this is the first time that such a distinction is given in the\nliterature. \n\n"}
{"id": "1701.07522", "contents": "Title: Joint Uplink-Downlink Cell Associations for Interference Networks with\n  Local Connectivity Abstract: We study information theoretic models of interference networks that consist\nof K Base Station (BS) - Mobile Terminal (MT) pairs. Each BS is connected to\nthe MT carrying the same index as well as L following MTs, where the\nconnectivity parameter L >= 1. We fix the value of L and study large networks\nas K goes to infinity. We assume that each MT can be associated with Nc BSs,\nand these associations are determined by a cloud-based controller that has a\nglobal view of the network. An MT has to be associated with a BS, in order for\nthe BS to transmit its message in the downlink, or decode its message in the\nuplink. In previous work, the cell associations that maximize the average\nuplink-downlink per user degrees of freedom (puDoF) were identified for the\ncase when L=1. Further, when only the downlink is considered, the problem was\nsettled for all values of L when we are restricted to use only zero-forcing\ninterference cancellation schemes. In this work, we first propose puDoF inner\nbounds for arbitrary values of L when only the uplink is considered, and\ncharacterize the uplink puDoF value when only zero-forcing schemes are allowed.\nWe then introduce new achievable average uplink-downlink puDoF values. We show\nthat the new scheme is optimal for the range when Nc <= L/2 when we restrict\nour attention to zero forcing schemes. Additionally we conjecture that the\nhaving unity puDoF during uplink is optimal when Nc >= L. \n\n"}
{"id": "1702.01940", "contents": "Title: One shot entanglement assisted classical and quantum communication over\n  noisy quantum channels: A hypothesis testing and convex split approach Abstract: Capacity of a quantum channel characterizes the limits of reliable\ncommunication through a noisy quantum channel. This fundamental information\ntheoretic question is very well studied specially in the setting of many\nindependent uses of the channel. An important scenario, both from practical and\nconceptual point of view, is when the channel can be used only once. This is\nknown as the one-shot channel coding problem. We provide a tight\ncharacterization of the one-shot entanglement assisted classical capacity of a\nquantum channel. We arrive at our result by introducing a simple decoding\ntechnique which we refer to as position-based decoding. We also consider two\nother important quantum network scenarios: quantum channel with a jammer and\nquantum broadcast channel. For these problems, we use the recently introduced\nconvex split technique [Anshu, Devabathini and Jain 2014] in addition to\nposition based decoding. Our approach exhibits that the simultaneous use of\nthese two techniques provides a uniform and conceptually simple framework for\ndesigning communication protocols for quantum networks. \n\n"}
{"id": "1702.03372", "contents": "Title: The Connectivity of Millimeter-Wave Networks in Urban Environments\n  Modeled Using Random Lattices Abstract: Millimeter-wave (mmWave) communication opens up tens of giga-hertz (GHz)\nspectrum in the mmWave band for use by next-generation wireless systems,\nthereby solving the problem of spectrum scarcity. Maintaining connectivity\nstands out to be a key design challenge for mmWave networks deployed in urban\nregions due to the blockage effect characterizing mmWave propagation.\nSpecifically, mmWave signals can be blocked by buildings and other large urban\nobjects. In this paper, we set out to investigate the blockage effect on the\nconnectivity of mmWave networks in a Manhattan-type urban region modeled using\na random regular lattice while base stations (BSs) are Poisson distributed in\nthe plane. In particular, we analyze the connectivity probability that a\ntypical user is within the transmission range of a BS and connected by a\nline-of-sight. Using random lattice and stochastic geometry theories, different\nlower bounds on the connectivity probability are derived as functions of the\nbuildings' size and probability of a lattice cell being occupied by a building\nas well as BS density and transmission range. The asymptotic connectivity\nprobability is also derived for cases of dense buildings. Last, the results are\nextended to heterogeneous networks. Our study yields closed-form relations\nbetween the parameters of the building process and the BS process, providing\nuseful guidelines for practical mmWave network deployment. \n\n"}
{"id": "1702.03590", "contents": "Title: On the Capacity of a Class of Signal-Dependent Noise Channels Abstract: In some applications, the variance of additive measurement noise depends on\nthe signal that we aim to measure. For instance, additive Gaussian\nsignal-dependent noise (AGSDN) channel models are used in molecular and optical\ncommunication. Herein we provide lower and upper bounds on the capacity of\nadditive signal-dependent noise (ASDN) channels. The idea of the first lower\nbound is the extension of the majorization inequality, and for the second one,\nit uses some calculations based on the fact that $h(Y) > h (Y|Z)$. Both of them\nare valid for all additive signal-dependent noise (ASDN) channels defined in\nthe paper. The upper bound is based on a previous idea of the authors\n(\"symmetric relative entropy\") and is used for the additive Gaussian\nsignal-dependent noise (AGSDN) channels. These bounds indicate that in ASDN\nchannels (unlike the classical AWGN channels), the capacity does not\nnecessarily become larger by making the variance function of the noise smaller.\nWe also provide sufficient conditions under which the capacity becomes\ninfinity. This is complemented by a number of conditions that imply capacity is\nfinite and a unique capacity achieving measure exists (in the sense of the\noutput measure). \n\n"}
{"id": "1702.04563", "contents": "Title: Characterizing the Rate-Memory Tradeoff in Cache Networks within a\n  Factor of 2 Abstract: We consider a basic caching system, where a single server with a database of\n$N$ files (e.g. movies) is connected to a set of $K$ users through a shared\nbottleneck link. Each user has a local cache memory with a size of $M$ files.\nThe system operates in two phases: a placement phase, where each cache memory\nis populated up to its size from the database, and a following delivery phase,\nwhere each user requests a file from the database, and the server is\nresponsible for delivering the requested contents. The objective is to design\nthe two phases to minimize the load (peak or average) of the bottleneck link.\nWe characterize the rate-memory tradeoff of the above caching system within a\nfactor of $2.00884$ for both the peak rate and the average rate (under uniform\nfile popularity), improving state of the arts that are within a factor of $4$\nand $4.7$ respectively. Moreover, in a practically important case where the\nnumber of files ($N$) is large, we exactly characterize the tradeoff for\nsystems with no more than $5$ users, and characterize the tradeoff within a\nfactor of $2$ otherwise. To establish these results, we develop two new\nconverse bounds that improve over the state of the art. \n\n"}
{"id": "1702.04707", "contents": "Title: Comparison of Polar Decoders with Existing Low-Density Parity-Check and\n  Turbo Decoders Abstract: Polar codes are a recently proposed family of provably capacity-achieving\nerror-correction codes that received a lot of attention. While their\ntheoretical properties render them interesting, their practicality compared to\nother types of codes has not been thoroughly studied. Towards this end, in this\npaper, we perform a comparison of polar decoders against LDPC and Turbo\ndecoders that are used in existing communications standards. More specifically,\nwe compare both the error-correction performance and the hardware efficiency of\nthe corresponding hardware implementations. This comparison enables us to\nidentify applications where polar codes are superior to existing\nerror-correction coding solutions as well as to determine the most promising\nresearch direction in terms of the hardware implementation of polar decoders. \n\n"}
{"id": "1702.05018", "contents": "Title: Cross-Mode Interference Characterization in Cellular Networks with\n  Voronoi Guard Regions Abstract: Advances in cellular networks such as device-to-device communications and\nfull-duplex radios, as well as the inherent elimination of intra-cell\ninterference achieved by network-controlled multiple access schemes, motivates\nthe investigation of the cross-mode interference properties under a guard\nregion corresponding to the Voronoi cell of an access point (AP). By modeling\nthe positions of interfering APs and user equipments (UEs) as Poisson\ndistributed, analytical expressions for the statistics of the cross-mode\ninterference generated by either APs or UEs are obtained based on appropriately\ndefined density functions. The considered system model and analysis are general\nenough to capture many operational scenarios of practical interest, including\nconventional downlink/uplink transmissions with nearest AP association, as well\nas transmissions where not both communicating nodes lie within the same cell.\nAnalysis provides insights on the level of protection offered by a Voronoi\nguard region and its dependence on type of interference and receiver position.\nNumerical examples demonstrate the validity/accuracy of the analysis in\nobtaining the system coverage probability for operational scenarios of\npractical interest. \n\n"}
{"id": "1702.05411", "contents": "Title: Block- and Rank-Sparse Recovery for Direction Finding in Partly\n  Calibrated Arrays Abstract: A sparse recovery approach for direction finding in partly calibrated arrays\ncomposed of subarrays with unknown displacements is introduced. The proposed\nmethod is based on mixed nuclear norm and 1 norm minimization and exploits\nblock-sparsity and low-rank structure in the signal model. For efficient\nimplementation a compact equivalent problem reformulation is presented. The new\ntechnique is applicable to subarrays of arbitrary topologies and grid-based\nsampling of the subarray manifolds. In the special case of subarrays with a\ncommon baseline our new technique admits extension to a gridless\nimplementation. As shown by simulations, our new block- and rank-sparse\ndirection finding technique for partly calibrated arrays outperforms the state\nof the art method RARE in difficult scenarios of low sample numbers, low\nsignal-to-noise ratio or correlated signals. \n\n"}
{"id": "1702.05574", "contents": "Title: Sample complexity of population recovery Abstract: The problem of population recovery refers to estimating a distribution based\non incomplete or corrupted samples. Consider a random poll of sample size $n$\nconducted on a population of individuals, where each pollee is asked to answer\n$d$ binary questions. We consider one of the two polling impediments: (a) in\nlossy population recovery, a pollee may skip each question with probability\n$\\epsilon$, (b) in noisy population recovery, a pollee may lie on each question\nwith probability $\\epsilon$. Given $n$ lossy or noisy samples, the goal is to\nestimate the probabilities of all $2^d$ binary vectors simultaneously within\naccuracy $\\delta$ with high probability.\n  This paper settles the sample complexity of population recovery. For lossy\nmodel, the optimal sample complexity is\n$\\tilde\\Theta(\\delta^{-2\\max\\{\\frac{\\epsilon}{1-\\epsilon},1\\}})$, improving the\nstate of the art by Moitra and Saks in several ways: a lower bound is\nestablished, the upper bound is improved and the result depends at most on the\nlogarithm of the dimension. Surprisingly, the sample complexity undergoes a\nphase transition from parametric to nonparametric rate when $\\epsilon$ exceeds\n$1/2$. For noisy population recovery, the sharp sample complexity turns out to\nbe more sensitive to dimension and scales as $\\exp(\\Theta(d^{1/3}\n\\log^{2/3}(1/\\delta)))$ except for the trivial cases of $\\epsilon=0,1/2$ or\n$1$.\n  For both models, our estimators simply compute the empirical mean of a\ncertain function, which is found by pre-solving a linear program (LP).\nCuriously, the dual LP can be understood as Le Cam's method for lower-bounding\nthe minimax risk, thus establishing the statistical optimality of the proposed\nestimators. The value of the LP is determined by complex-analytic methods. \n\n"}
{"id": "1702.06237", "contents": "Title: Exact tensor completion with sum-of-squares Abstract: We obtain the first polynomial-time algorithm for exact tensor completion\nthat improves over the bound implied by reduction to matrix completion. The\nalgorithm recovers an unknown 3-tensor with $r$ incoherent, orthogonal\ncomponents in $\\mathbb R^n$ from $r\\cdot \\tilde O(n^{1.5})$ randomly observed\nentries of the tensor. This bound improves over the previous best one of\n$r\\cdot \\tilde O(n^{2})$ by reduction to exact matrix completion. Our bound\nalso matches the best known results for the easier problem of approximate\ntensor completion (Barak & Moitra, 2015).\n  Our algorithm and analysis extends seminal results for exact matrix\ncompletion (Candes & Recht, 2009) to the tensor setting via the sum-of-squares\nmethod. The main technical challenge is to show that a small number of randomly\nchosen monomials are enough to construct a degree-3 polynomial with precisely\nplanted orthogonal global optima over the sphere and that this fact can be\ncertified within the sum-of-squares proof system. \n\n"}
{"id": "1702.07498", "contents": "Title: Secure Clustered Distributed Storage Against Eavesdroppers Abstract: This paper considers the security issue of practical distributed storage\nsystems (DSSs) which consist of multiple clusters of storage nodes. Noticing\nthat actual storage nodes constituting a DSS are distributed in multiple\nclusters, two novel eavesdropper models - the node-restricted model and the\ncluster-restricted model - are suggested which reflect the clustered nature of\nDSSs. In the node-restricted model, an eavesdropper cannot access the\nindividual nodes, but can eavesdrop incoming/outgoing data for $L_c$\ncompromised clusters. In the cluster-restricted model, an eavesdropper can\naccess a total of $l$ individual nodes but the number of accessible clusters is\nlimited to $L_c$. We provide an upper bound on the securely storable data for\neach model, while a specific network coding scheme which achieves the upper\nbound is obtained for the node-restricted model, given some mild condition on\nthe node storage size. \n\n"}
{"id": "1702.07881", "contents": "Title: On the Performance of Wireless Powered Communication With Non-linear\n  Energy Harvesting Abstract: In this paper, we analyze the performance of a time-slotted multi-antenna\nwireless powered communication (WPC) system, where a wireless device first\nharvests radio frequency (RF) energy from a power station (PS) in the downlink\nto facilitate information transfer to an information receiving station (IRS) in\nthe uplink. The main goal of this paper is to provide insights and guidelines\nfor the design of practical WPC systems. To this end, we adopt a recently\nproposed parametric non-linear RF energy harvesting (EH) model, which has been\nshown to accurately model the end-to-end non-linearity of practical RF EH\ncircuits. In order to enhance the RF power transfer efficiency, maximum ratio\ntransmission is adopted at the PS to focus the energy signals on the wireless\ndevice. Furthermore, at the IRS, maximum ratio combining is used. We analyze\nthe outage probability and the average throughput of information transfer,\nassuming Nakagami-$m$ fading uplink and downlink channels. Moreover, we study\nthe system performance as a function of the number of PS transmit antennas, the\nnumber of IRS receive antennas, the transmit power of the PS, the fading\nseverity, the transmission rate of the wireless device, and the EH time\nduration. In addition, we obtain a fixed point equation for the optimal\ntransmission rate and the optimal EH time duration that maximize the asymptotic\nthroughput for high PS transmit powers. All analytical results are corroborated\nby simulations. \n\n"}
{"id": "1702.07945", "contents": "Title: Global Optimality in Low-rank Matrix Optimization Abstract: This paper considers the minimization of a general objective function $f(X)$\nover the set of rectangular $n\\times m$ matrices that have rank at most $r$. To\nreduce the computational burden, we factorize the variable $X$ into a product\nof two smaller matrices and optimize over these two matrices instead of $X$.\nDespite the resulting nonconvexity, recent studies in matrix completion and\nsensing have shown that the factored problem has no spurious local minima and\nobeys the so-called strict saddle property (the function has a directional\nnegative curvature at all critical points but local minima). We analyze the\nglobal geometry for a general and yet well-conditioned objective function\n$f(X)$ whose restricted strong convexity and restricted strong smoothness\nconstants are comparable. In particular, we show that the reformulated\nobjective function has no spurious local minima and obeys the strict saddle\nproperty. These geometric properties imply that a number of iterative\noptimization algorithms (such as gradient descent) can provably solve the\nfactored problem with global convergence. \n\n"}
{"id": "1702.08130", "contents": "Title: Multiuser Precoding and Channel Estimation for Hybrid Millimeter Wave\n  MIMO Systems Abstract: In this paper, we develop a low-complexity channel estimation for hybrid\nmillimeter wave (mmWave) systems, where the number of radio frequency (RF)\nchains is much less than the number of antennas equipped at each transceiver.\nThe proposed channel estimation algorithm aims to estimate the strongest\nangle-of-arrivals (AoAs) at both the base station (BS) and the users. Then all\nthe users transmit orthogonal pilot symbols to the BS via these estimated\nstrongest AoAs to facilitate the channel estimation. The algorithm does not\nrequire any explicit channel state information (CSI) feedback from the users\nand the associated signalling overhead of the algorithm is only proportional to\nthe number of users, which is significantly less compared to various existing\nschemes. Besides, the proposed algorithm is applicable to both non-sparse and\nsparse mmWave channel environments. Based on the estimated CSI, zero-forcing\n(ZF) precoding is adopted for multiuser downlink transmission. In addition, we\nderive a tight achievable rate upper bound of the system. Our analytical and\nsimulation results show that the proposed scheme offer a considerable\nachievable rate gain compared to fully digital systems, where the number of RF\nchains equipped at each transceiver is equal to the number of antennas.\nFurthermore, the achievable rate performance gap between the considered hybrid\nmmWave systems and the fully digital system is characterized, which provides\nuseful system design insights. \n\n"}
{"id": "1702.08483", "contents": "Title: The computational landscape of general physical theories Abstract: There is good evidence that quantum computers are more powerful than\nclassical computers, and that various simple modifications of quantum theory\nyield computational power that is dramatically greater still. However, these\nmodifications also violate fundamental physical principles. This raises the\nquestion of whether there exists a physical theory, allowing computation more\npowerful than quantum, but which still respects those fundamental physical\nprinciples. Prior work by two of us introduced this question within a suitable\nframework for theories that make good operational sense, and showed that in any\ntheory satisfying tomographic locality, the class of problems that can be\nsolved efficiently is contained in the complexity class AWPP. Here, we show\nthat this bound is tight, in the sense that there exists a theory, satisfying\ntomographic locality, as well as a basic principle of causality, which can\nefficiently decide everything in AWPP. Hence this theory can efficiently\nsimulate any computation in this framework, including quantum computation. \n\n"}
{"id": "1702.08531", "contents": "Title: Practical issues in decoy-state quantum key distribution based on the\n  central limit theorem Abstract: Decoy-state quantum key distribution is a standard tool for long-distance\nquantum communications. An important issue in this field is processing the\ndecoy-state statistics taking into account statistical fluctuations (or\n\"finite-key effects\"). In this work, we propose and analyze an option for decoy\nstatistics processing, which is based on the central limit theorem. We discuss\nsuch practical issues as an inclusion of the failure probability of the\ndecoy-states statistical estimates in the total failure probability of a QKD\nprotocol and also taking into account the deviations of the binomially\ndistributed random variables used in the estimations from the Gaussian\ndistribution. The results of numerical simulations show that the obtained\nestimations are quite tight. The proposed technique can be used as a part of\npost-processing procedures for industrial quantum key distribution systems. \n\n"}
{"id": "1702.08800", "contents": "Title: Jamming-Resistant Receivers for the Massive MIMO Uplink Abstract: We design a jamming-resistant receiver scheme to enhance the robustness of a\nmassive MIMO uplink system against jamming. We assume that a jammer attacks the\nsystem both in the pilot and data transmission phases. The key feature of the\nproposed scheme is that, in the pilot phase, we estimate not only the\nlegitimate channel, but also the jamming channel by exploiting a purposely\nunused pilot sequence. The jamming channel estimate is used to constructed\nlinear receive filters that reject the impact of the jamming signal. The\nperformance of the proposed scheme is analytically evaluated using asymptotic\nproperties of massive MIMO. The optimal regularized zero-forcing receiver and\nthe optimal power allocation are also studied. Numerical results are provided\nto verify our analysis and show that the proposed scheme greatly improves the\nachievable rates, as compared to conventional receivers. Interestingly, the\nproposed scheme works particularly well under strong jamming attacks, since the\nimproved estimate of the jamming channel outweighs the extra jamming power. \n\n"}
{"id": "1703.00332", "contents": "Title: Design and Analysis of Time-Invariant SC-LDPC Convolutional Codes With\n  Small Constraint Length Abstract: In this paper, we deal with time-invariant spatially coupled low-density\nparity-check convolutional codes (SC-LDPC-CCs). Classic design approaches\nusually start from quasi-cyclic low-density parity-check (QC-LDPC) block codes\nand exploit suitable unwrapping procedures to obtain SC-LDPC-CCs. We show that\nthe direct design of the SC-LDPC-CCs syndrome former matrix or, equivalently,\nthe symbolic parity-check matrix, leads to codes with smaller syndrome former\nconstraint lengths with respect to the best solutions available in the\nliterature. We provide theoretical lower bounds on the syndrome former\nconstraint length for the most relevant families of SC-LDPC-CCs, under\nconstraints on the minimum length of cycles in their Tanner graphs. We also\npropose new code design techniques that approach or achieve such theoretical\nlimits. \n\n"}
{"id": "1703.03617", "contents": "Title: Symbol-level and Multicast Precoding for Multiuser Multiantenna\n  Downlink: A Survey, Classification and Challenges Abstract: Precoding has been conventionally considered as an effective means of\nmitigating the interference and efficiently exploiting the available in the\nmultiantenna downlink channel, where multiple users are simultaneously served\nwith independent information over the same channel resources. The early works\nin this area were focused on transmitting an individual information stream to\neach user by constructing weighted linear combinations of symbol blocks\n(codewords). However, more recent works have moved beyond this traditional view\nby: i) transmitting distinct data streams to groups of users and ii) applying\nprecoding on a symbol-per-symbol basis. In this context, the current survey\npresents a unified view and classification of precoding techniques with respect\nto two main axes: i) the switching rate of the precoding weights, leading to\nthe classes of block- and symbol-level precoding, ii) the number of users that\neach stream is addressed to, hence unicast-/multicast-/broadcast- precoding.\nFurthermore, the classified techniques are compared through representative\nnumerical results to demonstrate their relative performance and uncover\nfundamental insights. Finally, a list of open theoretical problems and\npractical challenges are presented to inspire further research in this area. \n\n"}
{"id": "1703.03706", "contents": "Title: Quantum reading capacity: General definition and bounds Abstract: Quantum reading refers to the task of reading out classical information\nstored in a read-only memory device. In any such protocol, the transmitter and\nreceiver are in the same physical location, and the goal of such a protocol is\nto use these devices (modeled by independent quantum channels), coupled with a\nquantum strategy, to read out as much information as possible from a memory\ndevice, such as a CD or DVD. As a consequence of the physical setup of quantum\nreading, the most natural and general definition for quantum reading capacity\nshould allow for an adaptive operation after each call to the channel, and this\nis how we define quantum reading capacity in this paper. We also establish\nseveral bounds on quantum reading capacity, and we introduce an\nenvironment-parametrized memory cell with associated environment states,\ndelivering second-order and strong converse bounds for its quantum reading\ncapacity. We calculate the quantum reading capacities for some exemplary memory\ncells, including a thermal memory cell, a qudit erasure memory cell, and a\nqudit depolarizing memory cell. We finally provide an explicit example to\nillustrate the advantage of using an adaptive strategy in the context of\nzero-error quantum reading capacity. \n\n"}
{"id": "1703.04006", "contents": "Title: Waveform Optimization for Radio-Frequency Wireless Power Transfer Abstract: In this paper, we study the waveform design problem for a single-input\nsingle-output (SISO) radio-frequency (RF) wireless power transfer (WPT) system\nin frequency-selective channels. First, based on the actual non-linear\ncurrent-voltage model of the diode at the energy receiver, we derive a\nsemi-closed-form expression for the deliverable DC voltage in terms of the\nincident RF signal and hence obtain the average harvested power. Next, by\nadopting a multisine waveform structure for the transmit signal of the energy\ntransmitter, we jointly design the multisine signal amplitudes and phases\noverall frequency tones according to the channel state information (CSI) to\nmaximize the deliverable DC voltage or harvested power. Although our formulated\nproblem is non-convex and difficult to solve, we propose two suboptimal\nsolutions to it, based on the frequency-domain maximal ratio transmission (MRT)\nprinciple and the sequential convex optimization (SCP) technique, respectively.\nUsing various simulations, the performance gain of our solutions over the\nexisting waveform designs is shown. \n\n"}
{"id": "1703.04072", "contents": "Title: Resource Allocation for a Full-Duplex Base Station Aided OFDMA System Abstract: Exploiting full-duplex (FD) technology on base stations (BSs) is a promising\nsolution to enhancing the system performance. Motivated by this, we revisit a\nfull-duplex base station (FD-BS) aided OFDMA system, which consists of one BS,\nseveral uplink/downlink users and multiple subcarriers. A joint 3-dimensional\n(3D) mapping scheme among subcarriers, down-link users (DUEs), uplink users\n(UUEs) is considered as well as an associated power allocation optimization. In\ndetail, we first decompose the complex 3D mapping problem into three\n2-dimensional sub ones and solve them by using the iterative Hungarian method,\nrespectively. Then based on the Lagrange dual method, we sequentially solve the\npower allocation and 3- dimensional mapping problem by fixing a dual point.\nFinally, the optimal solution can be obtained by utilizing the sub-gradient\nmethod. Unlike existing work that only solves either 3D mapping or power\nallocation problem but with a high computation complexity, we tackle both of\nthem and have successfully reduced computation complexity from exponential to\npolynomial order. Numerical simulations are conducted to verify the proposed\nscheme. \n\n"}
{"id": "1703.04209", "contents": "Title: Virtual Reality over Wireless Networks: Quality-of-Service Model and\n  Learning-Based Resource Management Abstract: In this paper, the problem of resource management is studied for a network of\nwireless virtual reality (VR) users communicating over small cell networks\n(SCNs). In order to capture the VR users' quality-of-service (QoS) in SCNs, a\nnovel VR model, based on multi-attribute utility theory, is proposed. This\nmodel jointly accounts for VR metrics such as tracking accuracy, processing\ndelay, and transmission delay. In this model, the small base stations (SBSs)\nact as the VR control centers that collect the tracking information from VR\nusers over the cellular uplink. Once this information is collected, the SBSs\nwill then send the three dimensional images and accompanying surround stereo\naudio to the VR users over the downlink. Therefore, the resource allocation\nproblem in VR wireless networks must jointly consider both the uplink and\ndownlink. This problem is then formulated as a noncooperative game and a\ndistributed algorithm based on the machine learning framework of echo state\nnetworks (ESNs) is proposed to find the solution of this game. The use of the\nproposed ESN algorithm enables the SBSs to predict the VR QoS of each SBS and\nguarantees the convergence to a mixed-strategy Nash equilibrium. The analytical\nresult shows that each user's VR QoS jointly depends on both VR tracking\naccuracy and wireless resource allocation. Simulation results show that the\nproposed algorithm yields significant gains, in terms of total utility value of\nVR QoS, that reach up to 22.2% and 37.5%, respectively, compared to Q-learning\nand a baseline proportional fair algorithm. The results also show that the\nproposed algorithm has a faster convergence time than Q-learning and can\nguarantee low delays for VR services. \n\n"}
{"id": "1703.04886", "contents": "Title: Information Theoretic Optimal Learning of Gaussian Graphical Models Abstract: What is the optimal number of independent observations from which a sparse\nGaussian Graphical Model can be correctly recovered? Information-theoretic\narguments provide a lower bound on the minimum number of samples necessary to\nperfectly identify the support of any multivariate normal distribution as a\nfunction of model parameters. For a model defined on a sparse graph with $p$\nnodes, a maximum degree $d$ and minimum normalized edge strength $\\kappa$, this\nnecessary number of samples scales at least as $d \\log p/\\kappa^2$. The sample\ncomplexity requirements of existing methods for perfect graph reconstruction\nexhibit dependency on additional parameters that do not enter in the lower\nbound. The question of whether the lower bound is tight and achievable by a\npolynomial time algorithm remains open. In this paper, we constructively answer\nthis question and propose an algorithm, termed DICE, whose sample complexity\nmatches the information-theoretic lower bound up to a universal constant\nfactor. We also propose a related algorithm SLICE that has a slightly higher\nsample complexity, but can be implemented as a mixed integer quadratic program\nwhich makes it attractive in practice. Importantly, SLICE retains a critical\nadvantage of DICE in that its sample complexity only depends on quantities\npresent in the information theoretic lower bound. We anticipate that this\nresult will stimulate future search of computationally efficient sample-optimal\nalgorithms. \n\n"}
{"id": "1703.04923", "contents": "Title: Greedy-Merge Degrading has Optimal Power-Law Abstract: Consider a channel with a given input alphabet size and a given input\ndistribution. Our aim is to degrade or upgrade it to a channel with at most L\noutput letters.\n  The paper contains four main results. The first result, from which the paper\ntitle is derived, deals with the so called \"greedy-merge\" algorithm. We derive\nan upper bound on the reduction in mutual information between input and output.\nThis upper bound is within a constant factor of an algorithm-independent lower\nbound. Thus, we establish that greedy-merge is optimal in the power-law sense.\n  The other main results deal with upgrading. The second result shows that a\ncertain sequence of channels that was previously shown to be \"hard\" for\ndegrading, displays the same hardness in the context of upgrading. That is,\nsuppose we are given such a channel and a corresponding input distribution. If\nwe upgrade (degrade) to a new channel with L output letters, we incur an\nincrease (decrease) in mutual information between input and output. We show\nthat a previously derived bound on the decrease in mutual information for the\ndegrading case is also a lower bound on the increase for the upgrading case.\n  The third result is an efficient algorithm for optimal upgrading, in the\nbinary-input case. That is, we are given a channel and an input distribution.\nWe must find an upgraded channel with L output letters, for which the increase\nin mutual information is minimal. We give a simple characterization of such a\nchannel, which implies an efficient algorithm.\n  The fourth result is an analog of the first result for the upgrading case,\nwhen the input is binary. That is, we first present a sub-optimal algorithm for\nthe setting considered in the third result. By analyzing the algorithm, we show\nthat the increase incurred in mutual information is within a constant factor of\nthe lower bound derived in the second result. \n\n"}
{"id": "1703.04925", "contents": "Title: Heralded Channel Holevo Superadditivity Bounds from Entanglement\n  Monogamy Abstract: We show that for a particular class of quantum channels, which we call\nheralded channels, monogamy of squashed entanglement limits the superadditivity\nof Holevo capacity. Heralded channels provide a means to understand the quantum\nerasure channel composed with an arbitrary other quantum channel, as well as\ncommon situations in experimental quantum information that involve frequent\nloss of qubits or failure of trials. We also show how entanglement monogamy\napplies to non-classicality in quantum games, and we consider how faithful,\nmonogamous entanglement measures may bound other entanglement-dependent\nquantities in many-party scenarios. \n\n"}
{"id": "1703.05690", "contents": "Title: Enhancing Coexistence in the Unlicensed Band with Massive MIMO Abstract: We consider cellular base stations (BSs) equipped with a large number of\nantennas and operating in the unlicensed band. We denote such system as massive\nMIMO unlicensed (mMIMO-U). We design the key procedures required to guarantee\ncoexistence between a cellular BS and nearby Wi-Fi devices. These include:\nneighboring Wi-Fi channel covariance estimation, allocation of spatial degrees\nof freedom for interference suppression, and enhanced channel sensing and data\ntransmission phases. We evaluate the performance of the so-designed mMIMO-U,\nshowing that it allows simultaneous cellular and Wi-Fi transmissions by keeping\ntheir mutual interference below the regulatory threshold. The same is not true\nfor conventional listen-before-talk (LBT) operations. As a result, mMIMO-U\nboosts the aggregate cellular-plus-Wi-Fi data rate in the unlicensed band with\nrespect to conventional LBT, exhibiting increasing gains as the number of BS\nantennas grows. \n\n"}
{"id": "1703.07912", "contents": "Title: Toward Traffic Patterns in High-speed Railway Communication Systems:\n  Power Allocation and Antenna Selection Abstract: In high-speed railway (HSR) communication systems, distributed antenna is\nusually employed to support frequent handover and enhance the signal to noise\nratio to user equipments. In this case, dynamic time-domain power allocation\nand antenna selection (PAWAS) could be jointly optimized to improve the system\nperformances. This paper consider this problem in such a simple way where\ndynamic switching between multiple-input-multiple-output (MIMO) and\nsingle-input-multiple-output (SIMO) is allowed and exclusively utilized, while\nthe channel states and traffic demand are taken into account. The channel\nstates includes sparse and rich scattering terrains, and the traffic patterns\nincludes delay-sensitive and delay-insensitive as well as hybrid. Some\nimportant results are obtained in theory. In sparse scattering terrains, for\ndelay-sensitive traffic, the PAWAS can be viewed as the generalization of\nchannel-inversion associated with transmit antenna selection. On the contrary,\nfor delay-insensitive traffic, the power allocation with MIMO can be viewed as\nchannel-inversion, but with SIMO, it is traditional water-filling. For the\nhybrid traffic, the PAWAS can be partitioned as delay-sensitive and\ndelay-insensitive parts by some specific strategies. In rich scattering\nterrains, the corresponding PAWAS is derived by some amendments in sparse\nscattering terrains and similar results are then presented. \n\n"}
{"id": "1703.07967", "contents": "Title: Nonconvex Regularization Based Sparse Recovery and Demixing with\n  Application to Color Image Inpainting Abstract: This work addresses the recovery and demixing problem of signals that are\nsparse in some general dictionary. Involved applications include source\nseparation, image inpainting, super-resolution, and restoration of signals\ncorrupted by clipping, saturation, impulsive noise, or narrowband interference.\nWe employ the $\\ell_q$-norm ($0 \\le q < 1$) for sparsity inducing and propose a\nconstrained $\\ell_q$-minimization formulation for the recovery and demixing\nproblem. This nonconvex formulation is approximately solved by two efficient\nfirst-order algorithms based on proximal coordinate descent and alternative\ndirection method of multipliers (ADMM), respectively. The new algorithms are\nconvergent in the nonconvex case under some mild conditions and scale well for\nhigh-dimensional problems. A convergence condition of the new ADMM algorithm\nhas been derived. Furthermore, extension of the two algorithms for\nmulti-channels joint recovery has been presented, which can further exploit the\njoint sparsity pattern among multi-channel signals. Various numerical\nexperiments showed that the new algorithms can achieve considerable performance\ngain over the $\\ell_1$-regularized algorithms. \n\n"}
{"id": "1703.08784", "contents": "Title: A Unified Ensemble of Concatenated Convolutional Codes Abstract: We introduce a unified ensemble for turbo-like codes (TCs) that contains the\nfour main classes of TCs: parallel concatenated codes, serially concatenated\ncodes, hybrid concatenated codes, and braided convolutional codes. We show that\nfor each of the original classes of TCs, it is possible to find an equivalent\nensemble by proper selection of the design parameters in the unified ensemble.\nWe also derive the density evolution (DE) equations for this ensemble over the\nbinary erasure channel. The thresholds obtained from the DE indicate that the\nTC ensembles from the unified ensemble have similar asymptotic behavior to the\noriginal TC ensembles. \n\n"}
{"id": "1704.00116", "contents": "Title: Stochastic L-BFGS: Improved Convergence Rates and Practical Acceleration\n  Strategies Abstract: We revisit the stochastic limited-memory BFGS (L-BFGS) algorithm. By\nproposing a new framework for the convergence analysis, we prove improved\nconvergence rates and computational complexities of the stochastic L-BFGS\nalgorithms compared to previous works. In addition, we propose several\npractical acceleration strategies to speed up the empirical performance of such\nalgorithms. We also provide theoretical analyses for most of the strategies.\nExperiments on large-scale logistic and ridge regression problems demonstrate\nthat our proposed strategies yield significant improvements vis-\\`a-vis\ncompeting state-of-the-art algorithms. \n\n"}
{"id": "1704.01101", "contents": "Title: On Resource-bounded versions of the van Lambalgen theorem Abstract: The van Lambalgen theorem is a surprising result in algorithmic information\ntheory concerning the symmetry of relative randomness. It establishes that for\nany pair of infinite sequences $A$ and $B$, $B$ is Martin-L\\\"of random and $A$\nis Martin-L\\\"of random relative to $B$ if and only if the interleaved sequence\n$A \\uplus B$ is Martin-L\\\"of random. This implies that $A$ is relative random\nto $B$ if and only if $B$ is random relative to $A$ \\cite{vanLambalgen},\n\\cite{Nies09}, \\cite{HirschfeldtBook}. This paper studies the validity of this\nphenomenon for different notions of time-bounded relative randomness.\n  We prove the classical van Lambalgen theorem using martingales and Kolmogorov\ncompressibility. We establish the failure of relative randomness in these\nsettings, for both time-bounded martingales and time-bounded Kolmogorov\ncomplexity. We adapt our classical proofs when applicable to the time-bounded\nsetting, and construct counterexamples when they fail. The mode of failure of\nthe theorem may depend on the notion of time-bounded randomness. \n\n"}
{"id": "1704.01992", "contents": "Title: An efficient algorithm for compression-based compressed sensing Abstract: Modern image and video compression codes employ elaborate structures existing\nin such signals to encode them into few number of bits. Compressed sensing\nrecovery algorithms on the other hand use such signals' structures to recover\nthem from few linear observations. Despite the steady progress in the field of\ncompressed sensing, structures that are often used for signal recovery are\nstill much simpler than those employed by state-of-the-art compression codes.\nThe main goal of this paper is to bridge this gap through answering the\nfollowing question: Can one employ a given compression code to build an\nefficient (polynomial time) compressed sensing recovery algorithm? In response\nto this question, the compression-based gradient descent (C-GD) algorithm is\nproposed. C-GD, which is a low-complexity iterative algorithm, is able to\nemploy a generic compression code for compressed sensing and therefore elevates\nthe scope of structures used in compressed sensing to those used by compression\ncodes. The convergence performance of C-GD and its required number of\nmeasurements in terms of the rate-distortion performance of the compression\ncode are theoretically analyzed. It is also shown that C-GD is robust to\nadditive white Gaussian noise. Finally, the presented simulation results show\nthat combining C-GD with commercial image compression codes such as JPEG2000\nyields state-of-the-art performance in imaging applications. \n\n"}
{"id": "1704.02673", "contents": "Title: Lattice Gaussian Sampling by Markov Chain Monte Carlo: Bounded Distance\n  Decoding and Trapdoor Sampling Abstract: Sampling from the lattice Gaussian distribution plays an important role in\nvarious research fields. In this paper, the Markov chain Monte Carlo\n(MCMC)-based sampling technique is advanced in several fronts. Firstly, the\nspectral gap for the independent Metropolis-Hastings-Klein (MHK) algorithm is\nderived, which is then extended to Peikert's algorithm and rejection sampling;\nwe show that independent MHK exhibits faster convergence. Then, the performance\nof bounded distance decoding using MCMC is analyzed, revealing a flexible\ntrade-off between the decoding radius and complexity. MCMC is further applied\nto trapdoor sampling, again offering a trade-off between security and\ncomplexity. Finally, the independent multiple-try Metropolis-Klein (MTMK)\nalgorithm is proposed to enhance the convergence rate. The proposed algorithms\nallow parallel implementation, which is beneficial for practical applications. \n\n"}
{"id": "1704.02806", "contents": "Title: Serving Distance and Coverage in a Closed Access PHP-Based Heterogeneous\n  Cellular Network Abstract: Heterogeneous cellular networks (HCNs) usually exhibit spatial separation\namongst base stations (BSs) of different types (termed tiers in this paper).\nFor instance, operators will usually not deploy a picocell in close proximity\nto a macrocell, thus inducing separation amongst the locations of pico and\nmacrocells. This separation has recently been captured by modeling the small\ncell locations by a Poisson Hole Process (PHP) with the hole centers being the\nlocations of the macrocells. Due to the presence of exclusion zones, the\nanalysis of the resulting model is significantly more complex compared to the\nmore popular Poisson Point Process (PPP) based models. In this paper, we derive\na tight bound on the distribution of the distance of a typical user to the\nclosest point of a PHP. Since the exact distribution of this distance is not\nknown, it is often approximated in the literature. For this model, we then\nprovide tight characterization of the downlink coverage probability for a\ntypical user in a two-tier closed-access HCN under two cases: (i) typical user\nis served by the closest macrocell, and (ii) typical user is served by its\nclosest small cell. The proposed approach can be extended to analyze other\nrelevant cases of interest, e.g., coverage in a PHP-based open access HCN. \n\n"}
{"id": "1704.03286", "contents": "Title: Phase Retrieval via Sparse Wirtinger Flow Abstract: Phase retrieval(PR) problem is a kind of ill-condition inverse problem which\ncan be found in various of applications. Utilizing the sparse priority, an\nalgorithm called SWF(Sparse Wirtinger Flow) is proposed in this paper to deal\nwith sparse PR problem based on the Wirtinger flow method. SWF firstly recovers\nthe support of the signal and then updates the evaluation by hard thresholding\nmethod with an elaborate initialization. Theoretical analyses show that SWF has\na geometric convergence for any $k$ sparse $n$ length signal with the sampling\ncomplexity $\\mathcal{O}(k^2\\mathrm{log}n)$. To get $\\varepsilon$ accuracy, the\ncomputational complexity of SWF is\n$\\mathcal{O}(k^3n\\mathrm{log}n\\mathrm{log}\\frac{1}{\\varepsilon})$.\n  Numerical tests also demonstrate that SWF performs better than\nstate-of-the-art methods especially when we have no priori knowledge about\nsparsity $k$. Moreover, SWF is also robust to the noise \n\n"}
{"id": "1704.04946", "contents": "Title: Covert Communication in Wireless Relay Networks Abstract: Covert communication aims to shield the very existence of wireless\ntransmissions in order to guarantee a strong security in wireless networks. In\nthis work, for the first time we examine the possibility and achievable\nperformance of covert communication in one-way relay networks. Specifically,\nthe relay opportunistically transmits its own information to the destination\ncovertly on top of forwarding the source's message, while the source tries to\ndetect this covert transmission to discover the illegitimate usage of the\nrecourse (e.g., power, spectrum) allocated only for the purpose of forwarding\nsource's information. The necessary condition that the relay can transmit\ncovertly without being detected is identified and the source's detection limit\nis derived in terms of the false alarm and miss detection rates. Our analysis\nindicates that boosting the forwarding ability of the relay (e.g., increasing\nits maximum transmit power) also increases its capacity to perform the covert\ncommunication in terms of achieving a higher effective covert rate subject to\nsome specific requirement on the source's detection performance. \n\n"}
{"id": "1704.05186", "contents": "Title: Capacity of Cellular Wireless Network Abstract: Earlier definitions of capacity for wireless networks, e.g., transport or\ntransmission capacity, for which exact theoretical results are known, are well\nsuited for ad hoc networks but are not directly applicable for cellular\nwireless networks, where large-scale basestation (BS) coordination is not\npossible, and retransmissions/ARQ under the SINR model is a universal feature.\n  In this paper, cellular wireless networks, where both BS locations and mobile\nuser (MU) locations are distributed as independent Poisson point processes are\nconsidered, and each MU connects to its nearest BS. With ARQ, under the SINR\nmodel, the effective downlink rate of packet transmission is the reciprocal of\nthe expected delay (number of retransmissions needed till success), which we\nuse as our network capacity definition after scaling it with the BS density.\n  Exact characterization of this natural capacity metric for cellular wireless\nnetworks is derived. The capacity is shown to first increase polynomially with\nthe BS density in the low BS density regime and then scale inverse\nexponentially with the increasing BS density. Two distinct upper bounds are\nderived that are relevant for the low and the high BS density regimes. A single\npower control strategy is shown to achieve the upper bounds in both the\nregimes. This result is fundamentally different from the well known capacity\nresults for ad hoc networks, such as transport and transmission capacity that\nscale as the square root of the (high) BS density. Our results show that the\nstrong temporal correlations of SINRs with PPP distributed BS locations is\nlimiting, and the realizable capacity in cellular wireless networks in high-BS\ndensity regime is much smaller than previously thought. A byproduct of our\nanalysis shows that the capacity of the ALOHA strategy with retransmissions is\nzero. \n\n"}
{"id": "1704.05334", "contents": "Title: On Low Complexity Detection for QAM Isomorphic Constellations Abstract: Despite of the known gap from the Shannon's capacity, several standards are\nstill employing QAM or star shape constellations, mainly due to the existing\nlow complexity detectors. In this paper, we investigate the low complexity\ndetection for a family of QAM isomorphic constellations. These constellations\nare known to perform very close to the peak-power limited capacity,\noutperforming the DVB-S2X standard constellations. The proposed strategy is to\nfirst remap the received signals to the QAM constellation using the existing\nisomorphism and then break the log likelihood ratio computations to two one\ndimensional PAM constellations. Gains larger than 0.6 dB with respect to QAM\ncan be obtained over the peak power limited channels without any increase in\ndetection complexity. Our scheme also provides a systematic way to design\nconstellations with low complexity one dimensional detectors. Several open\nproblems are discussed at the end of the paper. \n\n"}
{"id": "1704.06124", "contents": "Title: An Achievable Rate for an Optical Channel with Finite Memory Abstract: A fiber optic channel is modeled in a variety of ways; from the simple\nadditive white complex Gaussian noise model, to models that incorporate memory\nin the channel. Because of Kerr nonlinearity, a simple model is not a good\napproximation to an optical fiber. Hence we study a fiber optic channel with\nfinite memory and provide an achievable bound on channel capacity that improves\nupon a previously known bound. \n\n"}
{"id": "1704.06531", "contents": "Title: Asymptotic Performance Analysis of Spatially Reconfigurable Antenna\n  Arrays Abstract: A spatially reconfigurable antenna arrays consists of an antenna array of\nfinite length and fixed geometry which is displaced within a given area. Using\nthese reconfigurable components, the performance of MIMO systems is remarkably\nimproved by effectively positioning the array in its displacement area. This\npaper studies the large-system performance of MIMO setups with spatially\nreconfigurable antenna arrays when the displacement area is large. Considering\nfading channels, the distribution of the input-output mutual information is\nderived, and the asymptotic hardening property is demonstrated to hold. As the\nsize of the displacement area grows large, the mutual information is shown to\nconverge in distribution to a type-one Gumbel random variable whose mean grows\nlarge proportional to the displacement size, and whose variance tends to zero.\nOur numerical investigations depict that the type-one Gumbel approximation\nclosely tracks the empirical distribution even for a finite displacement size. \n\n"}
{"id": "1704.07114", "contents": "Title: Regular Decomposition: an information and graph theoretic approach to\n  stochastic block models Abstract: A method for compression of large graphs and non-negative matrices to a block\nstructure is proposed. Szemer\\'edi's regularity lemma is used as heuristic\nmotivation of the significance of stochastic block models. Another ingredient\nof the method is Rissanen's minimum description length principle (MDL). We\npropose practical algorithms and provide theoretical results on the accuracy of\nthe method. \n\n"}
{"id": "1704.08920", "contents": "Title: Interference Exploitation for Radar and Cellular Coexistence: The\n  Power-Efficient Approach Abstract: We propose a novel approach to enable the coexistence between\nMulti-Input-Multi-Output (MIMO) radar and downlink multi-user\nMulti-Input-Single-Output (MU-MISO) communication system. By exploiting the\nconstructive multi-user interference (MUI), the proposed approach trades-off\nuseful MUI power for reducing the transmit power, to obtain a power efficient\ntransmission. This paper focuses on two optimization problems: a) Transmit\npower minimization at the base station (BS) while guaranteeing the receive\nsignal-to-interference-plus-noise ratio (SINR) level of downlink users and the\ninterference-to-noise ratio (INR) level to radar; b) Minimization of the\ninterference from BS to radar for a given requirement of downlink SINR and\ntransmit power budget. To reduce the computational overhead of the proposed\nscheme in practice, an algorithm based on gradient projection is designed to\nsolve the power minimization problem. In addition, we investigate the trade-off\nbetween the performance of radar and communication, and analytically derive the\nkey metrics for MIMO radar in the presence of the interference from the BS.\nFinally, a robust power minimization problem is formulated to ensure the\neffectiveness of the proposed method in the case of imperfect Channel State\nInformation (CSI). Numerical results show that the proposed method achieves a\nsignificant power saving compared to conventional approaches, while obtaining a\nfavorable performance-complexity trade-off. \n\n"}
{"id": "1705.01002", "contents": "Title: Robust Location-Aided Beam Alignment in Millimeter Wave Massive MIMO Abstract: Location-aided beam alignment has been proposed recently as a potential\napproach for fast link establishment in millimeter wave (mmWave) massive MIMO\n(mMIMO) communications. However, due to mobility and other imperfections in the\nestimation process, the spatial information obtained at the base station (BS)\nand the user (UE) is likely to be noisy, degrading beam alignment performance.\nIn this paper, we introduce a robust beam alignment framework in order to\nexhibit resilience with respect to this problem. We first recast beam alignment\nas a decentralized coordination problem where BS and UE seek coordination on\nthe basis of correlated yet individual position information. We formulate the\noptimum beam alignment solution as the solution of a Bayesian team decision\nproblem. We then propose a suite of algorithms to approach optimality with\nreduced complexity. The effectiveness of the robust beam alignment procedure,\ncompared with classical designs, is then verified on simulation settings with\nvarying location information accuracies. \n\n"}
{"id": "1705.01484", "contents": "Title: Some New Permutation Polynomials over Finite Fields Abstract: In this paper, we construct a new class of complete permutation monomials and\nseveral classes of permutation polynomials. Further, by giving another\ncharacterization of o-polynomials, we obtain a class of permutation polynomials\nof the form $G(x)+ \\gamma Tr(H(x))$, where G(X) is neither a permutation nor a\nlinearized polynomial. This is an answer to the open problem 1 of Charpin and\nKyureghyan in [P. Charpin and G. Kyureghyan, When does $G(x)+ \\gamma Tr(H(x))$\npermute $\\mathbb{F}_{p^n}$?, Finite Fields and Their Applications 15 (2009)\n615--632]. \n\n"}
{"id": "1705.03429", "contents": "Title: Incentive Mechanism Design for Cache-Assisted D2D Communications: A\n  Mobility-Aware Approach Abstract: Caching popular contents at mobile devices, assisted by device-to-device\n(D2D) communications, is considered as a promising technique for mobile content\ndelivery. It can effectively reduce backhaul traffic and service cost, as well\nas improving the spectrum efficiency. However, due to the selfishness of mobile\nusers, incentive mechanisms will be needed to motivate device caching. In this\npaper, we investigate incentive mechanism design in cache-assisted D2D\nnetworks, taking advantage of the user mobility information. An inter-contact\nmodel is adopted to capture the average time between two consecutive contacts\nof each device pair. A Stackelberg game is formulated, where each user plays as\na follower aiming at maximizing its own utility and the mobile network operator\n(MNO) plays as a leader aiming at minimizing the cost. Assuming that user\nresponses can be predicted by the MNO, a cost minimization problem is\nformulated. Since this problem is NP-hard, we reformulate it as a non-negative\nsubmodular maximization problem and develop\n$(\\frac{1}{4+\\epsilon})$-approximation local search algorithm to solve it. In\nthe simulation, we demonstrate that the local search algorithm provides near\noptimal performance. By comparing with other caching strategies, we validate\nthe effectiveness of the proposed incentive-based mobility-aware caching\nstrategy. \n\n"}
{"id": "1705.04070", "contents": "Title: Coded Multicast Fronthauling and Edge Caching for Multi-Connectivity\n  Transmission in Fog Radio Access Networks Abstract: This work studies the advantages of coded multicasting for the downlink of a\nFog Radio Access Network (F-RAN) system equipped with a multicast fronthaul\nlink. In this system, a control unit (CU) in the baseband processing unit (BBU)\npool is connected to distributed edge nodes (ENs) through a multicast fronthaul\nlink of finite capacity, and the ENs have baseband processing and caching\ncapabilities. Each user equipment (UE) requests a file in a content library\nwhich is available at the CU, and the requested files are served by the closest\nENs based on the cached contents and on the information received on the\nmulticast fronthaul link. The performance of coded multicast fronthauling is\ninvestigated in terms of the delivery latency of the requested contents under\nthe assumption of pipelined transmission on the fronthaul and edge links and of\nsingle-user encoding and decoding strategies based on the hard transfer of\nfiles on the fronthaul links. Extensive numerical results are provided to\nvalidate the advantages of the coded multicasting scheme compared to uncoded\nunicast and multicast strategies. \n\n"}
{"id": "1705.05213", "contents": "Title: Weierstrass Pure Gaps From a Quotient of the Hermitian Curve Abstract: In this paper, by employing the results over Kummer extensions, we give an\narithmetic characterization of pure gaps at many totally ramified places over\nthe quotients of Hermitian curves, including the well-studied Hermitian curves\nas special cases. The cardinality of these pure gaps is explicitly\ninvestigated. In particular, the numbers of gaps and pure gaps at a pair of\ndistinct places are determined precisely, which can be regarded as an extension\nof the previous work by Matthews (2001) considered Hermitian curves.\nAdditionally, some concrete examples are provided to illustrate our results. \n\n"}
{"id": "1705.06799", "contents": "Title: Joint Uplink and Downlink Coverage Analysis of Cellular-based RF-powered\n  IoT Network Abstract: Ambient radio frequency (RF) energy harvesting has emerged as a promising\nsolution for powering small devices and sensors in massive Internet of Things\n(IoT) ecosystem due to its ubiquity and cost efficiency. In this paper, we\nstudy joint uplink and downlink coverage of cellular-based ambient RF energy\nharvesting IoT where the cellular network is assumed to be the only source of\nRF energy. We consider a time division-based approach for power and information\ntransmission where each time-slot is partitioned into three sub-slots: (i)\ncharging sub-slot during which the cellular base stations (BSs) act as RF\nchargers for the IoT devices, which then use the energy harvested in this\nsub-slot for information transmission and/or reception during the remaining two\nsub-slots, (ii) downlink sub-slot during which the IoT device receives\ninformation from the associated BS, and (iii) uplink sub-slot during which the\nIoT device transmits information to the associated BS. For this setup, we\ncharacterize the joint coverage probability, which is the joint probability of\nthe events that the typical device harvests sufficient energy in the given time\nslot and is under both uplink and downlink signal-to-interference-plus-noise\nratio (SINR) coverage with respect to its associated BS. This metric\nsignificantly generalizes the prior art on energy harvesting communications,\nwhich usually focused on downlink or uplink coverage separately. The key\ntechnical challenge is in handling the correlation between the amount of energy\nharvested in the charging sub-slot and the information signal quality (SINR) in\nthe downlink and uplink sub-slots. Dominant BS-based approach is developed to\nderive tight approximation for this joint coverage probability. Several system\ndesign insights including comparison with regularly powered IoT network and\nthroughput-optimal slot partitioning are also provided. \n\n"}
{"id": "1705.06891", "contents": "Title: Energy-Efficient Resource Allocation for Elastic Optical Networks using\n  Convex Optimization Abstract: We propose a two-stage algorithm for energy-efficient resource allocation\nconstrained to QoS and physical requirements in OFDM-based EONs. The first\nstage deals with routing, grooming and traffic ordering and aims at minimizing\namplifier power consumption and number of active transponders. We provide a\nheuristic procedure which yields an acceptable solution for the complex ILP\nformulation of the routing and grooming. In the second stage, we optimize\ntransponder configuration including spectrum and transmit power parameters to\nminimize transponder power consumption. We show how QoS and transponder power\nconsumption are represented by convex expressions and use the results to\nformulate a convex problem for configuring transponders in which transmit\noptical power is an optimization variable. Simulation results demonstrate that\nthe power consumption is reduced by 9% when the proposed routing and grooming\nalgorithm is applied to European Cost239 network with aggregate traffic 60\nTbps. It is shown that our convex formulation for transponder parameter\nassignment is considerably faster than its MINLP counterpart and its ability to\noptimize transmit optical power improves transponder power consumption by 8%\nfor aggregate traffic 60 Tbps. Furthermore, we investigate the effect of\nadaptive modulation assignment and transponder capacity on inherent tradeoff\nbetween network CAPEX and OPEX. \n\n"}
{"id": "1705.06960", "contents": "Title: Technical Report - MillimeterWave Communication in Vehicular Networks:\n  Coverage and Connectivity Analysis Abstract: In this technical report (TR), we describe the mathematical model we\ndeveloped to carry out a preliminary coverage and connectivity analysis in an\nautomotive communication scenario based on mmWave links. The purpose is to\nexemplify some of the complex and interesting tradeoffs that have to be\nconsidered when designing solutions for mmWave automotive scenarios. \n\n"}
{"id": "1705.08055", "contents": "Title: Nearly optimal codebooks based on generalized Jacobi sums Abstract: Codebooks with small inner-product correlation are applied in many practical\napplications including direct spread code division multiple access (CDMA)\ncommunications, space-time codes and compressed sensing. It is extremely\ndifficult to construct codebooks achieving the Welch bound or the Levenshtein\nbound. Constructing nearly optimal codebooks such that the ratio of its maximum\ncross-correlation amplitude to the corresponding bound approaches 1 is also an\ninteresting research topic. In this paper, we firstly study a family of\ninteresting character sums called generalized Jacobi sums over finite fields.\nThen we apply the generalized Jacobi sums and their related character sums to\nobtain two infinite classes of nearly optimal codebooks with respect to the\nWelch or Levenshtein bound. The codebooks can be viewed as generalizations of\nsome known ones and contain new ones with very flexible parameters. \n\n"}
{"id": "1705.08394", "contents": "Title: Information Theoretic Principles of Universal Discrete Denoising Abstract: Today, the internet makes tremendous amounts of data widely available. Often,\nthe same information is behind multiple different available data sets. This\nlends growing importance to latent variable models that try to learn the hidden\ninformation from the available imperfect versions. For example, social media\nplatforms can contain an abundance of pictures of the same person or object,\nyet all of which are taken from different perspectives. In a simplified\nscenario, one may consider pictures taken from the same perspective, which are\ndistorted by noise. This latter application allows for a rigorous mathematical\ntreatment, which is the content of this contribution. We apply a recently\ndeveloped method of dependent component analysis to image denoising when\nmultiple distorted copies of one and the same image are available, each being\ncorrupted by a different and unknown noise process. In a simplified scenario,\nwe assume that the distorted image is corrupted by noise that acts\nindependently on each pixel. We answer completely the question of how to\nperform optimal denoising, when at least three distorted copies are available:\nFirst we define optimality of an algorithm in the presented scenario, and then\nwe describe an aymptotically optimal universal discrete denoising algorithm\n(UDDA). In the case of binary data and binary symmetric noise, we develop a\nsimplified variant of the algorithm, dubbed BUDDA, which we prove to attain\nuniversal denoising uniformly. \n\n"}
{"id": "1705.09468", "contents": "Title: On Time-Bandwidth Product of Multi-Soliton Pulses Abstract: Multi-soliton pulses are potential candidates for fiber optical transmission\nwhere the information is modulated and recovered in the so-called nonlinear\nFourier domain. While this is an elegant technique to account for the channel\nnonlinearity, the obtained spectral efficiency, so far, is not competitive with\nthe classic Nyquist-based schemes. In this paper, we study the evolution of the\ntime-bandwidth product of multi-solitons as they propagate along the optical\nfiber. For second and third order soliton pulses, we numerically optimize the\npulse shapes to achieve the smallest time-bandwidth product when the phase of\nthe spectral amplitudes is used for modulation. Moreover, we analytically\nestimate the pulse-duration and bandwidth of multi-solitons in some practically\nimportant cases. Those estimations enable us to approximate the time-bandwidth\nproduct for higher order solitons. \n\n"}
{"id": "1706.00163", "contents": "Title: Coding Method for Parallel Iterative Linear Solver Abstract: Computationally intensive distributed and parallel computing is often\nbottlenecked by a small set of slow workers known as stragglers. In this paper,\nwe utilize the emerging idea of \"coded computation\" to design a novel\nerror-correcting-code inspired technique for solving linear inverse problems\nunder specific iterative methods in a parallelized implementation affected by\nstragglers. Example applications include inverse problems in machine learning\non graphs, such as personalized PageRank and sampling on graphs. We provably\nshow that our coded-computation technique can reduce the mean-squared error\nunder a computational deadline constraint. In fact, the ratio of mean-squared\nerror of replication-based and coded techniques diverges to infinity as the\ndeadline increases. Our experiments for personalized PageRank performed on real\nsystems and real social networks show that this ratio can be as large as\n$10^4$. Further, unlike coded-computation techniques proposed thus far, our\nstrategy combines outputs of all workers, including the stragglers, to produce\nmore accurate estimates at the computational deadline. This also ensures that\nthe accuracy degrades \"gracefully\" in the event that the number of stragglers\nis large. \n\n"}
{"id": "1706.00752", "contents": "Title: Double-Edge Factor Graphs: Definition, Properties, and Examples Abstract: Some of the most interesting quantities associated with a factor graph are\nits marginals and its partition sum. For factor graphs \\emph{without cycles}\nand moderate message update complexities, the sum-product algorithm (SPA) can\nbe used to efficiently compute these quantities exactly. Moreover, for various\nclasses of factor graphs \\emph{with cycles}, the SPA has been successfully\napplied to efficiently compute good approximations to these quantities. Note\nthat in the case of factor graphs with cycles, the local functions are usually\nnon-negative real-valued functions. In this paper we introduce a class of\nfactor graphs, called double-edge factor graphs (DE-FGs), which allow local\nfunctions to be complex-valued and only require them, in some suitable sense,\nto be positive semi-definite. We discuss various properties of the SPA when\nrunning it on DE-FGs and we show promising numerical results for various\nexample DE-FGs, some of which have connections to quantum information\nprocessing. \n\n"}
{"id": "1706.01941", "contents": "Title: Upper bounds on the smallest size of a complete cap in\n  $\\mathrm{PG}(N,q)$, $N\\ge3$, under a certain probabilistic conjecture Abstract: In the projective space $\\mathrm{PG}(N,q)$ over the Galois field of order\n$q$, $N\\ge3$, an iterative step-by-step construction of complete caps by adding\na new point on every step is considered. It is proved that uncovered points are\nevenly placed on the space. A natural conjecture on an estimate of the number\nof new covered points on every step is done. For a part of the iterative\nprocess, this estimate is proved rigorously. Under the conjecture mentioned,\nnew upper bounds on the smallest size $t_{2}(N,q)$ of a complete cap in\n$\\mathrm{PG}(N,q)$ are obtained, in particular, \\begin{align*}\nt_{2}(N,q)<\\frac{\\sqrt{q^{N+1}}}{q-1}\\left(\\sqrt{(N+1)\\ln\nq}+1\\right)+2\\thicksim q^\\frac{N-1}{2}\\sqrt{(N+1)\\ln q},\\quad N\\ge3.\n\\end{align*} A connection with the Birthday problem is noted. The effectiveness\nof the new bounds is illustrated by comparison with sizes of complete caps\nobtained by computer in wide regions of $q$. \n\n"}
{"id": "1706.03183", "contents": "Title: Battery Recharge Time of a Stochastic Linear and Non-Linear Energy\n  Harvesting System Abstract: Systems harvesting energy from a stochastic source have been widely studied\nin the literature. However, we are not aware of any work that deals with the\ntime it takes for a battery to recharge up to a given level, when the energy\nsource is discrete stochastic. This letter aims to examine the recharge time of\na perfect battery. We examine the cases when the energy arrival is a Poisson\nprocess, and more generally, a renewal process. We obtain formulas for the\ndistribution of the recharge time as well as the expected value of the recharge\ntime. Using these, we find the switching time of the system, which is then\napplied to the design of a harvest-then-transmit protocol for green\ncommunications. Monte-Carlo simulations verify the obtained formulas. \n\n"}
{"id": "1706.04635", "contents": "Title: Information Potential Auto-Encoders Abstract: In this paper, we suggest a framework to make use of mutual information as a\nregularization criterion to train Auto-Encoders (AEs). In the proposed\nframework, AEs are regularized by minimization of the mutual information\nbetween input and encoding variables of AEs during the training phase. In order\nto estimate the entropy of the encoding variables and the mutual information,\nwe propose a non-parametric method. We also give an information theoretic view\nof Variational AEs (VAEs), which suggests that VAEs can be considered as\nparametric methods that estimate entropy. Experimental results show that the\nproposed non-parametric models have more degree of freedom in terms of\nrepresentation learning of features drawn from complex distributions such as\nMixture of Gaussians, compared to methods which estimate entropy using\nparametric approaches, such as Variational AEs. \n\n"}
{"id": "1706.05773", "contents": "Title: Optimal Status Update for Age of Information Minimization with an Energy\n  Harvesting Source Abstract: In this paper, we consider a scenario where an energy harvesting sensor\ncontinuously monitors a system and sends time-stamped status updates to a\ndestination. The destination keeps track of the system status through the\nreceived updates. We use the metric Age of Information (AoI), the time that has\nelapsed since the last received update was generated, to measure the\n\"freshness\" of the status information available at the destination. We assume\nenergy arrives randomly at the sensor according to a Poisson process, and each\nstatus update consumes one unit of energy. Our objective is to design optimal\nonline status update policies to minimize the long-term average AoI, subject to\nthe energy causality constraint at the sensor. We consider three scenarios,\ni.e., the battery size is infinite, finite, and one unit only, respectively.\n  For the infinite battery scenario, we adopt a best-effort uniform status\nupdate policy and show that it minimizes the long-term average AoI. For the\nfinite battery scenario, we adopt an energy-aware adaptive status update\npolicy, and prove that it is asymptotically optimal when the battery size goes\nto infinity. For the last scenario where the battery size is one, we first show\nthat within a broadly defined class of online policies, the optimal policy\nshould have a renewal structure, i.e., the status update epochs form a renewal\nprocess, and the length of each renewal interval depends on the first energy\narrival over that interval only. We then focus on a renewal interval, and prove\nthat if the AoI in the system is below a threshold when the first energy\narrives, the sensor should store the energy and hold status update until the\nAoI reaches the threshold, otherwise, it updates the status immediately. We\nanalytically characterize the long-term average AoI under such a\nthreshold-based policy, and explicitly identify the optimal threshold. \n\n"}
{"id": "1706.07582", "contents": "Title: Fundamental Limits of Universal Variable-to-Fixed Length Coding of\n  Parametric Sources Abstract: Universal variable-to-fixed (V-F) length coding of $d$-dimensional\nexponential family of distributions is considered. We propose an achievable\nscheme consisting of a dictionary, used to parse the source output stream,\nmaking use of the previously-introduced notion of quantized types. The\nquantized type class of a sequence is based on partitioning the space of\nminimal sufficient statistics into cuboids. Our proposed dictionary consists of\nsequences in the boundaries of transition from low to high quantized type class\nsize. We derive the asymptotics of the $\\epsilon$-coding rate of our coding\nscheme for large enough dictionaries. In particular, we show that the\nthird-order coding rate of our scheme is $H\\frac{d}{2}\\frac{\\log\\log M}{\\log\nM}$, where $H$ is the entropy of the source and $M$ is the dictionary size. We\nfurther provide a converse, showing that this rate is optimal up to the\nthird-order term. \n\n"}
{"id": "1706.07627", "contents": "Title: Fundamental Limits on Delivery Time in Cloud- and Cache-Aided\n  Heterogeneous Networks Abstract: A Fog radio access network is considered as a network architecture candidate\nto meet the soaring demand in terms of reliability, spectral efficiency, and\nlatency in next generation wireless networks. This architecture combines the\nbenefits associated with centralized cloud processing and wireless edge caching\nenabling primarily low-latency transmission under moderate fronthaul capacity\nrequirements. The F-RAN we consider in this paper is composed of a centralized\ncloud server which is connected through fronthaul links to two edge nodes\nserving two mobile users through a Z-shaped partially connected wireless\nnetwork. We define an information-theoretic metric, the delivery time per bit\n(DTB), that captures the worst-case per-bit delivery latency for conveying any\nrequested content to the users. For the cases when cloud and wireless\ntransmission occur either sequentially or in parallel, we establish coinciding\nlower and upper bounds on the DTB as a function of cache size, backhaul\ncapacity and wireless channel parameters. Through optimized rate allocation,\nour achievability scheme determines the best combination of private, common\nsignalling and interference neutralization that matches the converse. Our\nconverse bounds use subsets of wireless, fronthaul and caching resources of the\nF-RAN as side information that enable a single receiver to decode either one or\nboth users' requested files. We show the optimality on the DTB for all channel\nregimes. In case of serial transmission, the functional DTB-behavior changes at\nfronthaul capacity thresholds. In this context, we combine multiple channel\nregimes to classes of channel regimes which share the same fronthaul capacity\nthresholds and as such the same DTB-functional. In total, our analysis\nidentifies four classes; in only three of those edge caching and cloud\nprocessing can provide nontrivial synergestic and non-synergestic performance\ngains. \n\n"}
{"id": "1706.08199", "contents": "Title: A Proof of Vivo-Pato-Oshanin's Conjecture on the Fluctuation of von\n  Neumann Entropy Abstract: It was recently conjectured by Vivo, Pato, and Oshanin [Phys. Rev. E 93,\n052106 (2016)] that for a quantum system of Hilbert dimension $mn$ in a pure\nstate, the variance of the von Neumann entropy of a subsystem of dimension\n$m\\leq n$ is given by \\begin{equation*}\n-\\psi_{1}\\left(mn+1\\right)+\\frac{m+n}{mn+1}\\psi_{1}\\left(n\\right)-\\frac{(m+1)(m+2n+1)}{4n^{2}(mn+1)},\n\\end{equation*} where $\\psi_{1}(\\cdot)$ is the trigamma function. We give a\nproof of this formula. \n\n"}
{"id": "1706.09387", "contents": "Title: Asynchronous Massive Access and Neighbor Discovery Using OFDMA Abstract: The fundamental communication problem in the wireless Internet of Things\n(IoT) is to discover a massive number of devices and to allow them reliable\naccess to shared channels. Oftentimes these devices transmit short messages\nrandomly and sporadically. This paper proposes a novel signaling scheme for\ngrant-free massive access, where each device encodes its identity and/or\ninformation in a sparse set of tones. Such transmissions are implemented in the\nform of orthogonal frequency-division multiple access (OFDMA). Under some mild\nconditions and assuming device delays to be bounded unknown multiples of symbol\nintervals, sparse OFDMA is proved to enable arbitrarily reliable asynchronous\ndevice identification and message decoding with a codelength that is O(K(log K\n+ log S + log N)), where N denotes the device population, K denotes the actual\nnumber of active devices, and log S is essentially equal to the number of bits\na device can send (including its identity). By exploiting the Fast Fourier\nTransform (FFT), the computational complexity for discovery and decoding can be\nmade to be sub-linear in the total device population. To prove the concept, a\nspecific design is proposed to identify up to 100 active devices out of\n$2^{38}$ possible devices with up to 20 symbols of delay and moderate\nsignal-to-noise ratios and fading. The codelength compares much more favorably\nwith those of standard slotted ALOHA and carrier-sensing multiple access (CSMA)\nschemes. \n\n"}
{"id": "1706.09607", "contents": "Title: A sharp recovery condition for sparse signals with partial support\n  information via orthogonal matching pursuit Abstract: This paper considers the exact recovery of $k$-sparse signals in the\nnoiseless setting and support recovery in the noisy case when some prior\ninformation on the support of the signals is available. This prior support\nconsists of two parts. One part is a subset of the true support and another\npart is outside of the true support. For $k$-sparse signals $\\mathbf{x}$ with\nthe prior support which is composed of $g$ true indices and $b$ wrong indices,\nwe show that if the restricted isometry constant (RIC) $\\delta_{k+b+1}$ of the\nsensing matrix $\\mathbf{A}$ satisfies \\begin{eqnarray*}\n\\delta_{k+b+1}<\\frac{1}{\\sqrt{k-g+1}}, \\end{eqnarray*} then orthogonal matching\npursuit (OMP) algorithm can perfectly recover the signals $\\mathbf{x}$ from\n$\\mathbf{y}=\\mathbf{Ax}$ in $k-g$ iterations. Moreover, we show the above\nsufficient condition on the RIC is sharp. In the noisy case, we achieve the\nexact recovery of the remainder support (the part of the true support outside\nof the prior support) for the $k$-sparse signals $\\mathbf{x}$ from\n$\\mathbf{y}=\\mathbf{Ax}+\\mathbf{v}$ under appropriate conditions. For the\nremainder support recovery, we also obtain a necessary condition based on the\nminimum magnitude of partial nonzero elements of the signals $\\mathbf{x}$. \n\n"}
{"id": "1706.09615", "contents": "Title: Recovery of signals by a weighted $\\ell_2/\\ell_1$ minimization under\n  arbitrary prior support information Abstract: In this paper, we introduce a weighted $\\ell_2/\\ell_1$ minimization to\nrecover block sparse signals with arbitrary prior support information. When\npartial prior support information is available, a sufficient condition based on\nthe high order block RIP is derived to guarantee stable and robust recovery of\nblock sparse signals via the weighted $\\ell_2/\\ell_1$ minimization. We then\nshow if the accuracy of arbitrary prior block support estimate is at least\n$50\\%$, the sufficient recovery condition by the weighted $\\ell_2/\\ell_{1}$\nminimization is weaker than that by the $\\ell_2/\\ell_{1}$ minimization, and the\nweighted $\\ell_2/\\ell_{1}$ minimization provides better upper bounds on the\nrecovery error in terms of the measurement noise and the compressibility of the\nsignal. Moreover, we illustrate the advantages of the weighted $\\ell_2/\\ell_1$\nminimization approach in the recovery performance of block sparse signals under\nuniform and non-uniform prior information by extensive numerical experiments.\nThe significance of the results lies in the facts that making explicit use of\nblock sparsity and partial support information of block sparse signals can\nachieve better recovery performance than handling the signals as being in the\nconventional sense, thereby ignoring the additional structure and prior support\ninformation in the problem. \n\n"}
{"id": "1707.00519", "contents": "Title: MU-MIMO Communications with MIMO Radar: From Co-existence to Joint\n  Transmission Abstract: Beamforming techniques are proposed for a joint multi-input-multi-output\n(MIMO) radar-communication (RadCom) system, where a single device acts both as\na radar and a communication base station (BS) by simultaneously communicating\nwith downlink users and detecting radar targets. Two operational options are\nconsidered, where we first split the antennas into two groups, one for radar\nand the other for communication. Under this deployment, the radar signal is\ndesigned to fall into the null-space of the downlink channel. The communication\nbeamformer is optimized such that the beampattern obtained matches the radar's\nbeampattern while satisfying the communication performance requirements. To\nreduce the optimizations' constraints, we consider a second operational option,\nwhere all the antennas transmit a joint waveform that is shared by both radar\nand communications. In this case, we formulate an appropriate probing\nbeampattern, while guaranteeing the performance of the downlink communications.\nBy incorporating the SINR constraints into objective functions as penalty\nterms, we further simplify the original beamforming designs to weighted\noptimizations, and solve them by efficient manifold algorithms. Numerical\nresults show that the shared deployment outperforms the separated case\nsignificantly, and the proposed weighted optimizations achieve a similar\nperformance to the original optimizations, despite their significantly lower\ncomputational complexity. \n\n"}
{"id": "1707.01205", "contents": "Title: The minimal measurement number problem in phase retrieval: a review of\n  recent developments Abstract: Phase retrieval is to recover the signals from phaseless measurements which\nis raised in many areas. A fundamental problem in phase retrieval is to\ndetermine the minimal measurement number $m$ so that one can recover\n$d$-dimensional signals from $m$ phaseless measurements. This problem attracts\nmuch attention of experts from different areas. In this paper, we review the\nrecent development on the minimal measurement number and also raise many\ninteresting open questions. \n\n"}
{"id": "1707.01673", "contents": "Title: Energy Efficient Resource Allocation for Hybrid Services with Future\n  Channel Gains Abstract: In this paper, we propose a framework to maximize energy efficiency (EE) of a\nsystem supporting real-time (RT) and non-real-time services by exploiting\nfuture average channel gains of mobile users, which change in the timescale of\nseconds and are reported predictable within a minute-long time window. To\ndemonstrate the potential of improving EE by jointly optimizing resource\nallocation for both services by harnessing both future average channel gains\nand current instantaneous channel gains, we optimize a two-timescale policy\nwith perfect prediction, by taking orthogonal frequency division multiple\naccess system serving RT and video-on-demand (VoD) users as an example.\nConsidering that fine-grained prediction for every user is with high cost, we\npropose a heuristic policy that only needs to predict the median of average\nchannel gains of VoD users. Simulation results show that the optimal policy\noutperforms relevant counterparts, indicating the necessity of the joint\noptimization for both services and for two timescales. Besides, the heuristic\npolicy performs closely to the optimal policy with perfect prediction while\nbecomes superior with large prediction errors. This suggests that the EE gain\nover non-predictive policies can be captured with coarse-grained prediction. \n\n"}
{"id": "1707.05199", "contents": "Title: Online codes for analog signals Abstract: This paper revisits a classical scenario in communication theory: a waveform\nsampled at regular intervals is to be encoded so as to minimize distortion in\nits reconstruction, despite noise. This transformation must be online (causal),\nto enable real-time signaling; and should use no more power than the original\nsignal. The noise model we consider is an \"atomic norm\" convex relaxation of\nthe standard (discrete alphabet) Hamming-weight-bounded model: namely,\nadversarial $\\ell_1$-bounded. In the \"block coding\" (noncausal) setting, such\nencoding is possible due to the existence of large almost-Euclidean sections in\n$\\ell_1$ spaces, a notion first studied in the work of Dvoretzky in 1961. Our\nmain result is that an analogous result is achievable even causally.\nEquivalently, our work may be seen as a \"lower triangular\" version of $\\ell_1$\nDvoretzky theorems. In terms of communication, the guarantees are expressed in\nterms of certain time-weighted norms: the time-weighted $\\ell_2$ norm imposed\non the decoder forces increasingly accurate reconstruction of the distant past\nsignal, while the time-weighted $\\ell_1$ norm on the noise ensures vanishing\ninterference from distant past noise. Encoding is linear (hence easy to\nimplement in analog hardware). Decoding is performed by an LP analogous to\nthose used in compressed sensing. \n\n"}
{"id": "1707.06444", "contents": "Title: Consistent Tomography under Partial Observations over Adaptive Networks Abstract: This work studies the problem of inferring whether an agent is directly\ninfluenced by another agent over an adaptive diffusion network. Agent i\ninfluences agent j if they are connected (according to the network topology),\nand if agent j uses the data from agent i to update its online statistic. The\nsolution of this inference task is challenging for two main reasons. First,\nonly the output of the diffusion learning algorithm is available to the\nexternal observer that must perform the inference based on these indirect\nmeasurements. Second, only output measurements from a fraction of the network\nagents is available, with the total number of agents itself being also unknown.\nThe main focus of this article is ascertaining under these demanding conditions\nwhether consistent tomography is possible, namely, whether it is possible to\nreconstruct the interaction profile of the observable portion of the network,\nwith negligible error as the network size increases. We establish a critical\nachievability result, namely, that for symmetric combination policies and for\nany given fraction of observable agents, the interacting and non-interacting\nagent pairs split into two separate clusters as the network size increases.\nThis remarkable property then enables the application of clustering algorithms\nto identify the interacting agents influencing the observations. We provide a\nset of numerical experiments that verify the results for finite network sizes\nand time horizons. The numerical experiments show that the results hold for\nasymmetric combination policies as well, which is particularly relevant in the\ncontext of causation. \n\n"}
{"id": "1707.09753", "contents": "Title: Polar Code Construction for List Decoding Abstract: A heuristic construction of polar codes for successive cancellation list\n(SCL) decoding with a given list size is proposed to balance the trade-off\nbetween performance measured in frame error rate (FER) and decoding complexity.\nFurthermore, a construction based on dynamically frozen bits with constraints\namong the \"low weight bits\" (LWB) is presented. Simulation results show that\nthe LWB-polar codes outperform the CRC-polar codes and the eBCH-polar codes\nunder SCL decoding. \n\n"}
{"id": "1708.00430", "contents": "Title: Breaking the curse of dimensionality in regression Abstract: Models with many signals, high-dimensional models, often impose structures on\nthe signal strengths. The common assumption is that only a few signals are\nstrong and most of the signals are zero or close (collectively) to zero.\nHowever, such a requirement might not be valid in many real-life applications.\nIn this article, we are interested in conducting large-scale inference in\nmodels that might have signals of mixed strengths. The key challenge is that\nthe signals that are not under testing might be collectively non-negligible\n(although individually small) and cannot be accurately learned. This article\ndevelops a new class of tests that arise from a moment matching formulation. A\nvirtue of these moment-matching statistics is their ability to borrow strength\nacross features, adapt to the sparsity size and exert adjustment for testing\ngrowing number of hypothesis. GRoup-level Inference of Parameter, GRIP, test\nharvests effective sparsity structures with hypothesis formulation for an\nefficient multiple testing procedure. Simulated data showcase that GRIPs error\ncontrol is far better than the alternative methods. We develop a minimax\ntheory, demonstrating optimality of GRIP for a broad range of models, including\nthose where the model is a mixture of a sparse and high-dimensional dense\nsignals. \n\n"}
{"id": "1708.01398", "contents": "Title: Signal Recovery in Perturbed Fourier Compressed Sensing Abstract: In many applications in compressed sensing, the measurement matrix is a\nFourier matrix, i.e., it measures the Fourier transform of the underlying\nsignal at some specified `base' frequencies $\\{u_i\\}_{i=1}^M$, where $M$ is the\nnumber of measurements. However due to system calibration errors, the system\nmay measure the Fourier transform at frequencies $\\{u_i + \\delta_i\\}_{i=1}^M$\nthat are different from the base frequencies and where $\\{\\delta_i\\}_{i=1}^M$\nare unknown. Ignoring perturbations of this nature can lead to major errors in\nsignal recovery. In this paper, we present a simple but effective alternating\nminimization algorithm to recover the perturbations in the frequencies \\emph{in\nsitu} with the signal, which we assume is sparse or compressible in some known\nbasis. In many cases, the perturbations $\\{\\delta_i\\}_{i=1}^M$ can be expressed\nin terms of a small number of unique parameters $P \\ll M$. We demonstrate that\nin such cases, the method leads to excellent quality results that are several\ntimes better than baseline algorithms (which are based on existing off-grid\nmethods in the recent literature on direction of arrival (DOA) estimation,\nmodified to suit the computational problem in this paper). Our results are also\nrobust to noise in the measurement values. We also provide theoretical results\nfor (1) the convergence of our algorithm, and (2) the uniqueness of its\nsolution under some restrictions. \n\n"}
{"id": "1708.03030", "contents": "Title: Above and Beyond the Landauer Bound: Thermodynamics of Modularity Abstract: Information processing typically occurs via the composition of modular units,\nsuch as universal logic gates. The benefit of modular information processing,\nin contrast to globally integrated information processing, is that complex\nglobal computations are more easily and flexibly implemented via a series of\nsimpler, localized information processing operations which only control and\nchange local degrees of freedom. We show that, despite these benefits, there\nare unavoidable thermodynamic costs to modularity---costs that arise directly\nfrom the operation of localized processing and that go beyond Landauer's\ndissipation bound for erasing information. Integrated computations can achieve\nLandauer's bound, however, when they globally coordinate the control of all of\nan information reservoir's degrees of freedom. Unfortunately, global\ncorrelations among the information-bearing degrees of freedom are easily lost\nby modular implementations. This is costly since such correlations are a\nthermodynamic fuel. We quantify the minimum irretrievable dissipation of\nmodular computations in terms of the difference between the change in global\nnonequilibrium free energy, which captures these global correlations, and the\nlocal (marginal) change in nonequilibrium free energy, which bounds modular\nwork production. This modularity dissipation is proportional to the amount of\nadditional work required to perform the computational task modularly. It has\nimmediate consequences for physically embedded transducers, known as\ninformation ratchets. We show how to circumvent modularity dissipation by\ndesigning internal ratchet states that capture the global correlations and\npatterns in the ratchet's information reservoir. Designed in this way,\ninformation ratchets match the optimum thermodynamic efficiency of globally\nintegrated computations. \n\n"}
{"id": "1708.03059", "contents": "Title: Opportunistic Scheduling of Machine Type Communications as Underlay to\n  Cellular Networks Abstract: In this paper we present a simple method to exploit the diversity of\ninterference in heterogenous wireless communication systems with large number\nof machine-type-devices (MTD). We consider a system with a\nmachine-type-aggregator (MTA) as underlay to cellular network with a multi\nantenna base station (BS). Cellular users share uplink radio resources with\nMTDs. Handling the interference from MTDs on the BS is the focus of this\narticle. Our method takes advantage of received interference diversity on BS at\neach time on each resource block and allocates the radio resources to the MTD\nwith the minimum interference on the BS. In this method, BS does not need to\ntake the interference from MTD into account in the design of the receive\nbeamformer for uplink cellular user, hence, the degrees of freedom is not used\nfor interference management. Our simulation results show that each resource\nblock can be shared between a cellular user and an MTD, with almost no harmful\ninterference on the cellular user. \n\n"}
{"id": "1708.05932", "contents": "Title: Fundamental Limits of Weak Recovery with Applications to Phase Retrieval Abstract: In phase retrieval we want to recover an unknown signal $\\boldsymbol\nx\\in\\mathbb C^d$ from $n$ quadratic measurements of the form $y_i =\n|\\langle{\\boldsymbol a}_i,{\\boldsymbol x}\\rangle|^2+w_i$ where $\\boldsymbol\na_i\\in \\mathbb C^d$ are known sensing vectors and $w_i$ is measurement noise.\nWe ask the following weak recovery question: what is the minimum number of\nmeasurements $n$ needed to produce an estimator $\\hat{\\boldsymbol\nx}(\\boldsymbol y)$ that is positively correlated with the signal $\\boldsymbol\nx$? We consider the case of Gaussian vectors $\\boldsymbol a_i$. We prove that -\nin the high-dimensional limit - a sharp phase transition takes place, and we\nlocate the threshold in the regime of vanishingly small noise. For $n\\le\nd-o(d)$ no estimator can do significantly better than random and achieve a\nstrictly positive correlation. For $n\\ge d+o(d)$ a simple spectral estimator\nachieves a positive correlation. Surprisingly, numerical simulations with the\nsame spectral estimator demonstrate promising performance with realistic\nsensing matrices. Spectral methods are used to initialize non-convex\noptimization algorithms in phase retrieval, and our approach can boost the\nperformance in this setting as well.\n  Our impossibility result is based on classical information-theory arguments.\nThe spectral algorithm computes the leading eigenvector of a weighted empirical\ncovariance matrix. We obtain a sharp characterization of the spectral\nproperties of this random matrix using tools from free probability and\ngeneralizing a recent result by Lu and Li. Both the upper and lower bound\ngeneralize beyond phase retrieval to measurements $y_i$ produced according to a\ngeneralized linear model. As a byproduct of our analysis, we compare the\nthreshold of the proposed spectral method with that of a message passing\nalgorithm. \n\n"}
{"id": "1708.06077", "contents": "Title: ExSIS: Extended Sure Independence Screening for Ultrahigh-dimensional\n  Linear Models Abstract: Statistical inference can be computationally prohibitive in\nultrahigh-dimensional linear models. Correlation-based variable screening, in\nwhich one leverages marginal correlations for removal of irrelevant variables\nfrom the model prior to statistical inference, can be used to overcome this\nchallenge. Prior works on correlation-based variable screening either impose\nstatistical priors on the linear model or assume specific post-screening\ninference methods. This paper first extends the analysis of correlation-based\nvariable screening to arbitrary linear models and post-screening inference\ntechniques. In particular, (i) it shows that a condition---termed the screening\ncondition---is sufficient for successful correlation-based screening of linear\nmodels, and (ii) it provides insights into the dependence of marginal\ncorrelation-based screening on different problem parameters. Numerical\nexperiments confirm that these insights are not mere artifacts of analysis;\nrather, they are reflective of the challenges associated with marginal\ncorrelation-based variable screening. Second, the paper explicitly derives the\nscreening condition for arbitrary (random or deterministic) linear models and,\nin the process, it establishes that---under appropriate conditions---it is\npossible to reduce the dimension of an ultrahigh-dimensional, arbitrary linear\nmodel to almost the sample size even when the number of active variables scales\nalmost linearly with the sample size. Third, it specializes the screening\ncondition to sub-Gaussian linear models and contrasts the final results to\nthose existing in the literature. This specialization formally validates the\nclaim that the main result of this paper generalizes existing ones on\ncorrelation-based screening. \n\n"}
{"id": "1708.07961", "contents": "Title: Ultra-Dense Networks: A New Look at the Proportional Fair Scheduler Abstract: In this paper, we theoretically study the proportional fair (PF) scheduler in\nthe context of ultra-dense networks (UDNs). Analytical results are obtained for\nthe coverage probability and the area spectral efficiency (ASE) performance of\ndense small cell networks (SCNs) with the PF scheduler employed at base\nstations (BSs). The key point of our analysis is that the typical user is no\nlonger a random user as assumed in most studies in the literature. Instead, a\nuser with the maximum PF metric is chosen by its serving BS as the typical\nuser. By comparing the previous results of the round-robin (RR) scheduler with\nour new results of the PF scheduler, we quantify the loss of the multi-user\ndiversity of the PF scheduler with the network densification, which casts a new\nlook at the role of the PF scheduler in UDNs. Our conclusion is that the RR\nscheduler should be used in UDNs to simplify the radio resource management\n(RRM). \n\n"}
{"id": "1708.09354", "contents": "Title: Quantum-enhanced reinforcement learning for finite-episode games with\n  discrete state spaces Abstract: Quantum annealing algorithms belong to the class of metaheuristic tools,\napplicable for solving binary optimization problems. Hardware implementations\nof quantum annealing, such as the quantum annealing machines produced by D-Wave\nSystems, have been subject to multiple analyses in research, with the aim of\ncharacterizing the technology's usefulness for optimization and sampling tasks.\nHere, we present a way to partially embed both Monte Carlo policy iteration for\nfinding an optimal policy on random observations, as well as how to embed (n)\nsub-optimal state-value functions for approximating an improved state-value\nfunction given a policy for finite horizon games with discrete state spaces on\na D-Wave 2000Q quantum processing unit (QPU). We explain how both problems can\nbe expressed as a quadratic unconstrained binary optimization (QUBO) problem,\nand show that quantum-enhanced Monte Carlo policy evaluation allows for finding\nequivalent or better state-value functions for a given policy with the same\nnumber episodes compared to a purely classical Monte Carlo algorithm.\nAdditionally, we describe a quantum-classical policy learning algorithm. Our\nfirst and foremost aim is to explain how to represent and solve parts of these\nproblems with the help of the QPU, and not to prove supremacy over every\nexisting classical policy evaluation algorithm. \n\n"}
{"id": "1708.09433", "contents": "Title: A Scalable and Statistically Robust Beam Alignment Technique for mm-Wave\n  Systems Abstract: Millimeter-Wave (mm-Wave) frequency bands provide an opportunity for much\nwider channel bandwidth compared with the traditional sub-6 GHz band.\nCommunication at mm-Waves is, however, quite challenging due to the severe\npropagation path loss. To cope with this problem, directional beamforming both\nat the Base Station (BS) side and at the user side is necessary in order to\nestablish a strong path conveying enough signal power. Finding such beamforming\ndirections is referred to as the Beam Alignment (BA) and is known to be a\nchallenging problem. This paper presents a new scheme for efficient BA, based\non the estimated second order channel statistics. As a result, our proposed\nalgorithm is highly robust to variations of the channel time-dynamics compared\nwith other proposed approaches based on the estimation of the channel\ncoefficients, rather than of their second-order statistics. In the proposed\nscheme, the BS probes the channel in the Downlink (DL) letting each user to\nestimate its own path direction. All the users within the BS coverage are\ntrained simultaneously, without requiring \"beam refinement\" with multiple\ninteractive rounds of Downlink/Uplink (DL/UL) transmissions, as done in other\nschemes. Thus, the training overhead of the proposed BA scheme is independent\nof the number of users in the system. We pose the channel estimation at the\nuser side as a Compressed Sensing (CS) of a non-negative signal and use the\nrecently developed Non-Negative Least Squares(NNLS) technique to solve it\nefficiently. The performance of our proposed algorithm is assessed via computer\nsimulation in a relevant mm-Wave scenario. The results illustrate that our\napproach is superior to the state-of-the-art BA schemes proposed in the\nliterature in terms of training overhead in multi-user scenarios and robustness\nto variations in the channel dynamics. \n\n"}
{"id": "1709.01347", "contents": "Title: Random Pilot and Data Access in Massive MIMO for Machine-type\n  Communications Abstract: A massive MIMO system, represented by a base station with hundreds of\nantennas, is capable of spatially multiplexing many devices and thus naturally\nsuited to serve dense crowds of wireless devices in emerging applications, such\nas machine-type communications. Crowd scenarios pose new challenges in the\npilot-based acquisition of channel state information and call for pilot access\nprotocols that match the intermittent pattern of device activity. A joint pilot\nassignment and data transmission protocol based on random access is proposed in\nthis paper for the uplink of a massive MIMO system. The protocol relies on the\naveraging across multiple transmission slots of the pilot collision events that\nresult from the random access process. We derive new uplink sum rate\nexpressions that take pilot collisions, intermittent device activity, and\ninterference into account. Simplified bounds are obtained and used to optimize\nthe device activation probability and pilot length. A performance analysis\nindicates how performance scales as a function of the number of antennas and\nthe transmission slot duration. \n\n"}
{"id": "1709.01447", "contents": "Title: Conditional independence testing based on a nearest-neighbor estimator\n  of conditional mutual information Abstract: Conditional independence testing is a fundamental problem underlying causal\ndiscovery and a particularly challenging task in the presence of nonlinear and\nhigh-dimensional dependencies. Here a fully non-parametric test for continuous\ndata based on conditional mutual information combined with a local permutation\nscheme is presented. Through a nearest neighbor approach, the test efficiently\nadapts also to non-smooth distributions due to strongly nonlinear dependencies.\nNumerical experiments demonstrate that the test reliably simulates the null\ndistribution even for small sample sizes and with high-dimensional conditioning\nsets. The test is better calibrated than kernel-based tests utilizing an\nanalytical approximation of the null distribution, especially for non-smooth\ndensities, and reaches the same or higher power levels. Combining the local\npermutation scheme with the kernel tests leads to better calibration, but\nsuffers in power. For smaller sample sizes and lower dimensions, the test is\nfaster than random fourier feature-based kernel tests if the permutation scheme\nis (embarrassingly) parallelized, but the runtime increases more sharply with\nsample size and dimensionality. Thus, more theoretical research to analytically\napproximate the null distribution and speed up the estimation for larger sample\nsizes is desirable. \n\n"}
{"id": "1709.02625", "contents": "Title: Decentralized Robust Transceiver Designs for MISO SWIPT Interference\n  Channel Abstract: This paper considers a $K$-user multiple-input single-output (MISO)\ninterference channels for simultaneous wireless information and power transfer\n(SWIPT), where each multi-antenna transmitter serves a single-antenna receiver\nper user pair. All receivers perform simultaneously information processing and\nenergy harvesting (EH) based on the receive power-splitting (PS) architectures.\nAssuming imperfect channel state information (CSI) at the transmitters, we\ndevelop an optimal robust transceiver design scheme that minimizes the total\ntransmission power under the worst-case signal-to-interference-plus-noise ratio\n(SINR) and energy harvesting (EH) constraints at the receivers, by jointly\noptimizing transmit beamforming and receive PS ratio per receiver. When the CSI\nuncertainties are bounded by ellipsoidal regions, it is shown that the\nworst-case SINR and EH constraints per receiver can be recast into quadratic\nmatrix inequality forms. Leveraging semidefinite relaxation technique, the\nintended robust beamforming and PS (BFPS) problem can be relaxed as a tractable\n(centralized) semidefinite program (SDP). More importantly, relying on the\nstate-of-the-art alternating direction method of multipliers (ADMM) in convex\noptimization, we propose a {\\em decentralized} algorithm capable of computing\nthe optimal robust BFPS scheme with local CSI and limited information exchange\namong the transmitters. It is shown the proposed decentralized algorithm is\nguaranteed to converge to the optimal centralized solution. Numerical results\nare provided to demonstrate the merits of the proposed approaches. \n\n"}
{"id": "1709.02969", "contents": "Title: Optimization of Massive Full-Dimensional MIMO for Positioning and\n  Communication Abstract: Massive Full-Dimensional multiple-input multiple-output (FD-MIMO) base\nstations (BSs) have the potential to bring multiplexing and coverage gains by\nmeans of three-dimensional (3D) beamforming. Key technical challenges for their\ndeployment include the presence of limited-resolution front ends and the\nacquisition of channel state information (CSI) at the BSs. This paper\ninvestigates the use of FD-MIMO BSs to provide simultaneously high-rate data\ncommunication and mobile 3D positioning in the downlink. The analysis\nconcentrates on the problem of beamforming design by accounting for imperfect\nCSI acquisition via Time Division Duplex (TDD)-based training and for the\nfinite resolution of analog-to-digital converter (ADC) and digital-to-analog\nconverter (DAC) at the BSs. Both \\textit{unstructured beamforming} and a\nlow-complexity \\textit{Kronecker beamforming} solution are considered, where\nfor the latter the beamforming vectors are decomposed into separate azimuth and\nelevation components. The proposed algorithmic solutions are based on Bussgang\ntheorem, rank-relaxation and successive convex approximation (SCA) methods.\nComprehensive numerical results demonstrate that the proposed schemes can\neffectively cater to both data communication and positioning services,\nproviding only minor performance degradations as compared to the more\nconventional cases in which either function is implemented. Moreover, the\nproposed low-complexity Kronecker beamforming solutions are seen to guarantee a\nlimited performance loss in the presence of a large number of BS antennas. \n\n"}
{"id": "1709.05789", "contents": "Title: On the Restricted Isometry of the Columnwise Khatri-Rao Product Abstract: The columnwise Khatri-Rao product of two matrices is an important matrix\ntype, reprising its role as a structured sensing matrix in many fundamental\nlinear inverse problems. Robust signal recovery in such inverse problems is\noften contingent on proving the restricted isometry property (RIP) of a certain\nsystem matrix expressible as a Khatri-Rao product of two matrices. In this\nwork, we analyze the RIP of a generic columnwise Khatri-Rao product matrix by\nderiving two upper bounds for its $k^{\\text{th}}$ order Restricted Isometry\nConstant ($k$-RIC) for different values of $k$. The first RIC bound is computed\nin terms of the individual RICs of the input matrices participating in the\nKhatri-Rao product. The second RIC bound is probabilistic, and is specified in\nterms of the input matrix dimensions. We show that the Khatri-Rao product of a\npair of $m \\times n$ sized random matrices comprising independent and\nidentically distributed subgaussian entries satisfies $k$-RIP with arbitrarily\nhigh probability, provided $m$ exceeds $O(k \\log n)$. Our RIC bounds confirm\nthat the Khatri-Rao product exhibits stronger restricted isometry compared to\nits constituent matrices for the same RIP order. The proposed RIC bounds are\npotentially useful in the sample complexity analysis of several sparse recovery\nproblems. \n\n"}
{"id": "1709.05907", "contents": "Title: A Generalized Framework for Kullback-Leibler Markov Aggregation Abstract: This paper proposes an information-theoretic cost function for aggregating a\nMarkov chain via a (possibly stochastic) mapping. The cost function is\nmotivated by two objectives: 1) The process obtained by observing the Markov\nchain through the mapping should be close to a Markov chain, and 2) the\naggregated Markov chain should retain as much of the temporal dependence\nstructure of the original Markov chain as possible. We discuss properties of\nthis parameterized cost function and show that it contains the cost functions\npreviously proposed by Deng et al., Xu et al., and Geiger et al. as special\ncases. We moreover discuss these special cases providing a better understanding\nand highlighting potential shortcomings: For example, the cost function\nproposed by Geiger et al. is tightly connected to approximate probabilistic\nbisimulation, but leads to trivial solutions if optimized without\nregularization. We furthermore propose a simple heuristic to optimize our cost\nfunction for deterministic aggregations and illustrate its performance on a set\nof synthetic examples. \n\n"}
{"id": "1709.07860", "contents": "Title: VLSI Designs for Joint Channel Estimation and Data Detection in Large\n  SIMO Wireless Systems Abstract: Channel estimation errors have a critical impact on the reliability of\nwireless communication systems. While virtually all existing wireless receivers\nseparate channel estimation from data detection, it is well known that joint\nchannel estimation and data detection (JED) significantly outperforms\nconventional methods at the cost of high computational complexity. In this\npaper, we propose a novel JED algorithm and corresponding VLSI designs for\nlarge single-input multiple-output (SIMO) wireless systems that use\nconstant-modulus constellations. The proposed algorithm is referred to as\nPRojection Onto conveX hull (PrOX) and relies on biconvex relaxation (BCR),\nwhich enables us to efficiently compute an approximate solution of the\nmaximum-likelihood JED problem. Since BCR solves a biconvex problem via\nalternating optimization, we provide a theoretical convergence analysis for\nPrOX. We design a scalable, high-throughput VLSI architecture that uses a\nlinear array of processing elements to minimize hardware complexity. We develop\ncorresponding field-programmable gate array (FPGA) and application-specific\nintegrated circuit (ASIC) designs, and we demonstrate that PrOX significantly\noutperforms the only other existing JED design in terms of throughput,\nhardware-efficiency, and energy-efficiency. \n\n"}
{"id": "1709.10280", "contents": "Title: Non-parametric Message Important Measure: Storage Code Design and\n  Transmission Planning for Big Data Abstract: Storage and transmission in big data are discussed in this paper, where\nmessage importance is taken into account. Similar to Shannon Entropy and Renyi\nEntropy, we define non-parametric message important measure (NMIM) as a measure\nfor the message importance in the scenario of big data, which can characterize\nthe uncertainty of random events. It is proved that the proposed NMIM can\nsufficiently describe two key characters of big data: rare events finding and\nlarge diversities of events. Based on NMIM, we first propose an effective\ncompressed encoding mode for data storage, and then discuss the channel\ntransmission over some typical channel models. Numerical simulation results\nshow that using our proposed strategy occupies less storage space without\nlosing too much message importance, and there are growth region and saturation\nregion for the maximum transmission, which contributes to designing of better\npractical communication system. \n\n"}
{"id": "1710.01874", "contents": "Title: Efficiently repairing algebraic geometry codes Abstract: Minimum storage regenerating codes have minimum storage of data in each node\nand therefore are maximal distance separable (MDS for short) codes. Thus, the\nnumber of nodes is upper bounded by $2^{\\fb}$, where $\\fb$ is the bits of data\nstored in each node. From both theoretical and practical points of view (see\nthe details in Section 1), it is natural to consider regenerating codes that\nnearly have minimum storage of data, and meanwhile the number of nodes is\nunbounded. One of the candidates for such regenerating codes is an algebraic\ngeometry code. In this paper, we generalize the repairing algorithm of\nReed-Solomon codes given in \\cite[STOC2016]{GW16} to algebraic geometry codes\nand present an efficient repairing algorithm for arbitrary one-point algebraic\ngeometry codes. By applying our repairing algorithm to the one-point algebraic\ngeometry codes based on the Garcia-Stichtenoth tower, one can repair a code of\nrate $1-\\Ge$ and length $n$ over $\\F_{q}$ with bandwidth $(n-1)(1-\\Gt)\\log q$\nfor any $\\Ge=2^{(\\Gt-1/2)\\log q}$ with a real $\\tau\\in(0,1/2)$. In addition,\nstorage in each node for an algebraic geometry code is close to the minimum\nstorage. Due to nice structures of Hermitian curves, repairing of Hermitian\ncodes is also investigated. As a result, we are able to show that algebraic\ngeometry codes are regenerating codes with good parameters. An example reveals\nthat Hermitian codes outperform Reed-Solomon codes for certain parameters. \n\n"}
{"id": "1710.02048", "contents": "Title: Tightness of a new and enhanced semidefinite relaxation for MIMO\n  detection Abstract: In this paper, we consider a fundamental problem in modern digital\ncommunications known as multi-input multi-output (MIMO) detection, which can be\nformulated as a complex quadratic programming problem subject to unit-modulus\nand discrete argument constraints. Various semidefinite relaxation (SDR) based\nalgorithms have been proposed to solve the problem in the literature. In this\npaper, we first show that the conventional SDR is generally not tight for the\nproblem. Then, we propose a new and enhanced SDR and show its tightness under\nan easily checkable condition, which essentially requires the level of the\nnoise to be below a certain threshold. The above results have answered an open\nquestion posed by So in [35]. Numerical simulation results show that our\nproposed SDR significantly outperforms the conventional SDR in terms of the\nrelaxation gap. \n\n"}
{"id": "1710.02903", "contents": "Title: Finite Size Corrections and Likelihood Ratio Fluctuations in the Spiked\n  Wigner Model Abstract: In this paper we study principal components analysis in the regime of high\ndimensionality and high noise. Our model of the problem is a rank-one\ndeformation of a Wigner matrix where the signal-to-noise ratio (SNR) is of\nconstant order, and we are interested in the fundamental limits of detection of\nthe spike. Our main goal is to gain a fine understanding of the asymptotics for\nthe log-likelihood ratio process, also known as the free energy, as a function\nof the SNR. Our main results are twofold. We first prove that the free energy\nhas a finite-size correction to its limit---the replica-symmetric\nformula---which we explicitly compute. This provides a formula for the\nKullback-Leibler divergence between the planted and null models. Second, we\nprove that below the reconstruction threshold, where it becomes impossible to\nreconstruct the spike, the log-likelihood ratio has fluctuations of constant\norder and converges in distribution to a Gaussian under both the planted and\n(under restrictions) the null model. As a consequence, we provide a general\nproof of contiguity between these two distributions that holds up to the\nreconstruction threshold, and is valid for an arbitrary separable prior on the\nspike. Formulae for the total variation distance, and the Type-I and Type-II\nerrors of the optimal test are also given. Our proofs are based on Gaussian\ninterpolation methods and a rigorous incarnation of the cavity method, as\ndevised by Guerra and Talagrand in their study of the Sherrington--Kirkpatrick\nspin-glass model. \n\n"}
{"id": "1710.05234", "contents": "Title: Phase Retrieval via Linear Programming: Fundamental Limits and\n  Algorithmic Improvements Abstract: A recently proposed convex formulation of the phase retrieval problem\nestimates the unknown signal by solving a simple linear program. This new\nscheme, known as PhaseMax, is computationally efficient compared to standard\nconvex relaxation methods based on lifting techniques. In this paper, we\npresent an exact performance analysis of PhaseMax under Gaussian measurements\nin the large system limit. In contrast to previously known performance bounds\nin the literature, our results are asymptotically exact and they also reveal a\nsharp phase transition phenomenon. Furthermore, the geometrical insights gained\nfrom our analysis led us to a novel nonconvex formulation of the phase\nretrieval problem and an accompanying iterative algorithm based on successive\nlinearization and maximization over a polytope. This new algorithm, which we\ncall PhaseLamp, has provably superior recovery performance over the original\nPhaseMax method. \n\n"}
{"id": "1710.05312", "contents": "Title: Deep Learning for Wireless Physical Layer: Opportunities and Challenges Abstract: Machine learning (ML) has been widely applied to the upper layers of wireless\ncommunication systems for various purposes, such as deployment of cognitive\nradio and communication network. However, its application to the physical layer\nis hampered by sophisticated channel environments and limited learning ability\nof conventional ML algorithms. Deep learning (DL) has been recently applied for\nmany fields, such as computer vision and natural language processing, given its\nexpressive capacity and convenient optimization capability. The potential\napplication of DL to the physical layer has also been increasingly recognized\nbecause of the new features for future communications, such as complex\nscenarios with unknown channel models, high speed and accurate processing\nrequirements; these features challenge conventional communication theories.\nThis paper presents a comprehensive overview of the emerging studies on\nDL-based physical layer processing, including leveraging DL to redesign a\nmodule of the conventional communication system (for modulation recognition,\nchannel decoding, and detection) and replace the communication system with a\nradically new architecture based on an autoencoder. These DL-based methods show\npromising performance improvements but have certain limitations, such as lack\nof solid analytical tools and use of architectures that are specifically\ndesigned for communication and implementation research, thereby motivating\nfuture research in this field. \n\n"}
{"id": "1710.05602", "contents": "Title: On Fast-Decodable Algebraic Space--Time Codes Abstract: In the near future, the $5^{th}$ generation (5G) wireless systems will be\nestablished. They will consist of an integration of different techniques,\nincluding distributed antenna systems and massive multiple-input\nmultiple-output systems, and the overall performance will highly depend on the\nchannel coding techniques employed. Due to the nature of future wireless\nnetworks, space--time codes are no longer merely an object of choice, but will\noften appear naturally in the communications setting. However, as the involved\ncommunication devices often exhibit a modest computational power, the\ncomplexity of the codes to be utilised should be reasonably low for possible\npractical implementation.\n  Fast-decodable codes enjoy reduced complexity of maximum-likelihood (ML)\ndecoding due to a smart inner structure allowing for parallelisation in the ML\nsearch. The complexity reductions considered in this chapter are entirely owing\nto the algebraic structure of the considered codes, and could be further\nimproved by employing non-ML decoding methods, however yielding suboptimal\nperformance.\n  The aim of this chapter is twofold. First, we provide a tutorial introduction\nto space--time coding and study powerful algebraic tools for their design and\nconstruction. Secondly, we revisit algebraic techniques used for reducing the\nworst-case decoding complexity of both single-user and multiuser space-time\ncodes, alongside with general code families and illustrative examples. \n\n"}
{"id": "1710.07576", "contents": "Title: A Short Survey on Bounding the Union Probability using Partial\n  Information Abstract: This is a short survey on existing upper and lower bounds on the probability\nof the union of a finite number of events using partial information given in\nterms of the individual or pairwise event probabilities (or their sums). New\nproofs for some of the existing bounds are provided and new observations\nregarding the existing Gallot--Kounias bound are given. \n\n"}
{"id": "1710.10669", "contents": "Title: Wideband Channel Estimation for Hybrid Beamforming Millimeter Wave\n  Communication Systems with Low-Resolution ADCs Abstract: A potential tremendous spectrum resource makes millimeter wave (mmWave)\ncommunications a promising technology. High power consumption due to a large\nnumber of antennas and analog-to-digital converters (ADCs) for beamforming to\novercome the large propagation losses is problematic in practice. As a hybrid\nbeamforming architecture and low-resolution ADCs are considered to reduce power\nconsumption, estimation of mmWave channels becomes challenging. We evaluate\nseveral channel estimation algorithms for wideband mmWave systems with hybrid\nbeamforming and low-resolution ADCs. Through simulation, we show that 1)\ninfinite bit ADCs with least-squares estimation have worse channel estimation\nperformance than do one-bit ADCs with orthogonal matching pursuit (OMP) in an\nSNR range of interest, 2) three- and four-bit quantizers can achieve channel\nestimation performance close to the unquantized case when using OMP, 3) a\nreceiver with a single RF chain can yield better estimates than that with four\nRF chains if enough frames are exploited, and 4) for one-bit ADCs, exploitation\nof higher transmit power and more frames for performance enhancement adversely\naffects estimation performance after a certain point. \n\n"}
{"id": "1710.10718", "contents": "Title: An Approximation Algorithm for Optimal Clique Cover Delivery in Coded\n  Caching Abstract: Coded caching can significantly reduce the communication bandwidth\nrequirement for satisfying users' demands by utilizing the multicasting gain\namong multiple users. Most existing works assume that the users follow the\nprescriptions for content placement made by the system. However, users may\nprefer to decide what files to cache. To address this issue, we consider a\nnetwork consisting of a file server connected through a shared link to $K$\nusers, each equipped with a cache which has been already filled arbitrarily.\nGiven an arbitrary content placement, the goal is to find a delivery strategy\nfor the server that minimizes the load of the shared link. In this paper, we\nfocus on a specific class of coded multicasting delivery schemes known as the\n\"clique cover delivery scheme\". We first formulate the optimal clique cover\ndelivery problem as a combinatorial optimization problem. Using a connection\nwith the weighted set cover problem, we propose an approximation algorithm and\nshow that it provides an approximation ratio of $(1 + \\log K)$, while the\napproximation ratio for the existing coded delivery schemes is linear in $K$.\nNumerical simulations show that our proposed algorithm provides a considerable\nbandwidth reduction over the existing coded delivery schemes for almost all\ncontent placement schemes. \n\n"}
{"id": "1711.00968", "contents": "Title: Deep Reinforcement Learning for Resource Allocation in V2V\n  Communications Abstract: In this article, we develop a decentralized resource allocation mechanism for\nvehicle-to-vehicle (V2V) communication systems based on deep reinforcement\nlearning. Each V2V link is considered as an agent, making its own decisions to\nfind optimal sub-band and power level for transmission. Since the proposed\nmethod is decentralized, the global information is not required for each agent\nto make its decisions, hence the transmission overhead is small. From the\nsimulation results, each agent can learn how to satisfy the V2V constraints\nwhile minimizing the interference to vehicle-to-infrastructure (V2I)\ncommunications. \n\n"}
{"id": "1711.01941", "contents": "Title: Codes for Correcting Localized Deletions Abstract: We consider the problem of constructing binary codes for correcting deletions\nthat are localized within certain parts of the codeword that are unknown a\npriori. The model that we study is when $\\delta \\leq w$ deletions are localized\nin a window of size $w$ bits. These $\\delta$ deletions do not necessarily occur\nin consecutive positions, but are restricted to the window of size $w$. The\nlocalized deletions model is a generalization of the bursty model, in which all\nthe deleted bits are consecutive. In this paper, we construct new explicit\ncodes for the localized model, based on the family of Guess & Check codes which\nwas previously introduced by the authors. The codes that we construct can\ncorrect, with high probability, $\\delta \\leq w$ deletions that are localized in\na single window of size $w$, where $w$ grows with the block length. Moreover,\nthese codes are systematic; have low redundancy; and have efficient\ndeterministic encoding and decoding algorithms. We also generalize these codes\nto deletions that are localized within multiple windows in the codeword. \n\n"}
{"id": "1711.02141", "contents": "Title: Optimal rates of entropy estimation over Lipschitz balls Abstract: We consider the problem of minimax estimation of the entropy of a density\nover Lipschitz balls. Dropping the usual assumption that the density is bounded\naway from zero, we obtain the minimax rates $(n\\ln n)^{-s/(s+d)} + n^{-1/2}$\nfor $0<s\\leq 2$ for densities supported on $[0,1]^d$, where $s$ is the\nsmoothness parameter and $n$ is the number of independent samples. We\ngeneralize the results to densities with unbounded support: given an Orlicz\nfunctions $\\Psi$ of rapid growth (such as the sub-exponential and sub-Gaussian\nclasses), the minimax rates for densities with bounded $\\Psi$-Orlicz norm\nincrease to $(n\\ln n)^{-s/(s+d)} (\\Psi^{-1}(n))^{d(1-d/p(s+d))} + n^{-1/2}$,\nwhere $p$ is the norm parameter in the Lipschitz ball. We also show that the\nintegral-form plug-in estimators with kernel density estimates fail to achieve\nthe minimax rates, and characterize their worst case performances over the\nLipschitz ball.\n  One of the key steps in analyzing the bias relies on a novel application of\nthe Hardy-Littlewood maximal inequality, which also leads to a new inequality\non the Fisher information that may be of independent interest. \n\n"}
{"id": "1711.03031", "contents": "Title: Location-Aided Coordinated Analog Precoding for Uplink Multi-User\n  Millimeter Wave Systems Abstract: Millimeter wave (mmWave) communication is expected to play an important role\nin next generation cellular networks, aiming to cope with the bandwidth\nshortage affecting conventional wireless carriers. Using side-information has\nbeen proposed as a potential approach to accelerate beam selection in mmWave\nmassive MIMO (m-MIMO) communications. However, in practice, such information is\nnot error-free, leading to performance degradation. In the multi-user case, a\nwrong beam choice might result in irreducible inter-user interference at the\nbase station (BS) side. In this paper, we consider location-aided precoder\ndesign in a mmWave uplink scenario with multiple users (UEs). Assuming the\nexistence of direct device-to-device (D2D) links, we propose a decentralized\ncoordination mechanism for robust fast beam selection. The algorithm allows for\nimproved treatment of interference at the BS side and in turn leads to greater\nspectral efficiencies. \n\n"}
{"id": "1711.03784", "contents": "Title: Z2Z4-Additive Cyclic Codes: Kernel and Rank Abstract: A Z2Z4-additive code C subset of Z_2^alpha x Z_4^beta is called cyclic if the\nset of coordinates can be partitioned into two subsets, the set of Z_2 and the\nset of Z_4 coordinates, such that any cyclic shift of the coordinates of both\nsubsets leaves the code invariant. Let Phi(C) be the binary Gray image of C. We\nstudy the rank and the dimension of the kernel of a Z2Z4-additive cyclic code\nC, that is, the dimensions of the binary linear codes <Phi(C)> and ker(Phi(C)).\nWe give upper and lower bounds for these parameters. It is known that the codes\n<Phi(C)> and ker(Phi(C)) are binary images of Z2Z4-additive codes R(C) and\nK(C), respectively. Moreover, we show that R(C) and K(C) are also cyclic and we\ndetermine the generator polynomials of these codes in terms of the generator\npolynomials of the code C. \n\n"}
{"id": "1711.03798", "contents": "Title: Centralized Coded Caching of Correlated Contents Abstract: Coded caching and delivery is studied taking into account the correlations\namong the contents in the library. Correlations are modeled as common parts\nshared by multiple contents; that is, each file in the database is composed of\na group of subfiles, where each subfile is shared by a different subset of\nfiles. The number of files that include a certain subfile is defined as the\nlevel of commonness of this subfile. First, a correlation-aware uncoded caching\nscheme is proposed, and it is shown that the optimal placement for this scheme\ngives priority to the subfiles with the highest levels of commonness. Then a\ncorrelation-aware coded caching scheme is presented, and the cache capacity\nallocated to subfiles with different levels of commonness is optimized in order\nto minimize the delivery rate. The proposed correlation-aware coded caching\nscheme is shown to remarkably outperform state-of-the-art correlation-ignorant\nsolutions, indicating the benefits of exploiting content correlations in coded\ncaching and delivery in networks. \n\n"}
{"id": "1711.05356", "contents": "Title: An Efficient Construction of Rate-Compatible Punctured Polar (RCPP)\n  Codes Using Hierarchical Puncturing Abstract: In this paper, we present an efficient method to construct a good\nrate-compatible punctured polar (RCPP) code. One of the major challenges on the\nconstruction of a RCPP code is to design a common information set which is good\nfor all the codes in the family. In the proposed construction, a common\ninformation set is simply optimized for the highest-rate punctured polar code\nin the family and then, this set is updated for each other code by satisfying\nthe condition that information bits are unchanged during retransmissions. This\nis enabled by presenting a novel hierarchical puncturing and information-copy\ntechnique. To be specific, some information bits are copied to frozen-bit\nchannels, which yields an information-dependent frozen vector. Then, the\nupdated information sets are obtained by appropriately combining the common\ninformation set and an information-dependent frozen vector. Moreover, the\nimpact of unknown frozen bits are resolved using the proposed hierarchical\npuncturing. Simulation results demonstrate that the proposed RCPP code attains\na significant performance gain (about 2dB) over a benchmark RCPP code where\nboth codes use the same puncturing patterns but the latter uses the\nconventional all-zero frozen vector. Therefore, the proposed method would be\ncrucial to construct a good RCPP code. \n\n"}
{"id": "1711.05403", "contents": "Title: Sparse Combinatorial Group Testing Abstract: In combinatorial group testing (CGT), the objective is to identify the set of\nat most $d$ defective items from a pool of $n$ items using as few tests as\npossible. The celebrated result for the CGT problem is that the number of tests\n$t$ can be made logarithmic in $n$ when $d=O(poly(\\log n))$. However,\nstate-of-the-art GT codes require the items to be tested $w=\\Omega(d\\log n)$\ntimes and tests to include $\\rho=\\Omega(n/d)$ items (within log factors). In\nmany applications, items can only participate in a limited number of tests and\ntests are constrained to include a limited number of items.\n  In this paper, we study the \"sparse\" regime for the group testing problem\nwhere we restrict the number of tests each item can participate in by\n$w_{\\max}$ or the number of items each test can include by $\\rho_{\\max}$ in\nboth noiseless and noisy settings. These constraints lead to an unexplored\nregime where $t$ is a fractional power of $n$. Our results characterize the\nnumber of tests $t$ as a function of $w_{\\max} (\\rho_{\\max})$ and show, for\nexample, that $t$ decreases drastically when $w_{\\max}$ is increased beyond a\nbare minimum. In particular, if $w_{\\max}\\leq d$, then we must have $t=n$,\ni.e., individual testing is optimal. We show that if $w_{\\max}=d+1$, this\ndecreases suddenly to $t=\\Theta(d\\sqrt{n})$. The order-optimal construction is\nobtained via a modification of the Kautz-Singleton construction, which is known\nto be suboptimal for the classical GT problem. For more general case, when\n$w_{\\max}=ld+1$ for $l>1$, the modified K-S construction requires $t=\\Theta(d\nn^{\\frac{1}{l+1}})$ tests, which we prove to be near order-optimal. We show\nthat our constructions have a favorable encoding and decoding complexity. We\nfinally discuss an application of our results to the construction of\nenergy-limited random access schemes for IoT networks, which provided the\ninitial motivation for our work. \n\n"}
{"id": "1711.06642", "contents": "Title: Nonparametric independence testing via mutual information Abstract: We propose a test of independence of two multivariate random vectors, given a\nsample from the underlying population. Our approach, which we call MINT, is\nbased on the estimation of mutual information, whose decomposition into joint\nand marginal entropies facilitates the use of recently-developed efficient\nentropy estimators derived from nearest neighbour distances. The proposed\ncritical values, which may be obtained from simulation (in the case where one\nmarginal is known) or resampling, guarantee that the test has nominal size, and\nwe provide local power analyses, uniformly over classes of densities whose\nmutual information satisfies a lower bound. Our ideas may be extended to\nprovide a new goodness-of-fit tests of normal linear models based on assessing\nthe independence of our vector of covariates and an appropriately-defined\nnotion of an error vector. The theory is supported by numerical studies on both\nsimulated and real data. \n\n"}
{"id": "1711.07307", "contents": "Title: Performance of In-band Transmission of System Information in Massive\n  MIMO Systems Abstract: We consider transmission of system information in massive MIMO. This\ninformation needs to be reliably delivered to inactive users in the cell\nwithout any channel state information at the base station. Downlink\ntransmission entails the use of downlink pilots and a special type of precoding\nthat aims to reduce the dimension of the downlink channel and the pilot\noverhead, which would otherwise scale with the number of base station antennas.\nWe consider a scenario in which the base station transmits over a small number\nof coherence intervals, providing little time/frequency diversity. The system\ninformation is transmitted with orthogonal space-time block codes to increase\nreliability and performance is measured using outage rates. Several different\ncodes are compared, both for spatially correlated and uncorrelated channels and\nfor varying amount of time/frequency diversity. We show that a massive MIMO\nbase station can outperform a single-antenna base station in all considered\nscenarios. \n\n"}
{"id": "1711.07771", "contents": "Title: Ultra-Reliable Low Latency Communication (URLLC) using Interface\n  Diversity Abstract: An important ingredient of the future 5G systems will be Ultra-Reliable\nLow-Latency Communication (URLLC). A way to offer URLLC without intervention in\nthe baseband/PHY layer design is to use interface diversity and integrate\nmultiple communication interfaces, each interface based on a different\ntechnology. In this work, we propose to use coding to seamlessly distribute\ncoded payload and redundancy data across multiple available communication\ninterfaces. We formulate an optimization problem to find the payload allocation\nweights that maximize the reliability at specific target latency values. In\norder to estimate the performance in terms of latency and reliability of such\nan integrated communication system, we propose an analysis framework that\ncombines traditional reliability models with technology-specific latency\nprobability distributions. Our model is capable to account for failure\ncorrelation among interfaces/technologies. By considering different scenarios,\nwe find that optimized strategies can in some cases significantly outperform\nstrategies based on $k$-out-of-$n$ erasure codes, where the latter do not\naccount for the characteristics of the different interfaces. The model has been\nvalidated through simulation and is supported by experimental results. \n\n"}
{"id": "1711.08452", "contents": "Title: Combating Computational Heterogeneity in Large-Scale Distributed\n  Computing via Work Exchange Abstract: Owing to data-intensive large-scale applications, distributed computation\nsystems have gained significant recent interest, due to their ability of\nrunning such tasks over a large number of commodity nodes in a time efficient\nmanner. One of the major bottlenecks that adversely impacts the time efficiency\nis the computational heterogeneity of distributed nodes, often limiting the\ntask completion time due to the slowest worker.\n  In this paper, we first present a lower bound on the expected computation\ntime based on the work-conservation principle. We then present our approach of\nwork exchange to combat the latency problem, in which faster workers can be\nreassigned additional leftover computations that were originally assigned to\nslower workers. We present two variations of the work exchange approach: a)\nwhen the computational heterogeneity knowledge is known a priori; and b) when\nheterogeneity is unknown and is estimated in an online manner to assign tasks\nto distributed workers. As a baseline, we also present and analyze the use of\nan optimized Maximum Distance Separable (MDS) coded distributed computation\nscheme over heterogeneous nodes. Simulation results also compare the proposed\napproach of work exchange, the baseline MDS coded scheme and the lower bound\nobtained via work-conservation principle. We show that the work exchange scheme\nachieves time for computation which is very close to the lower bound with\nlimited coordination and communication overhead even when the knowledge about\nheterogeneity levels is not available. \n\n"}
{"id": "1711.08824", "contents": "Title: The Nearest Neighbor Information Estimator is Adaptively Near Minimax\n  Rate-Optimal Abstract: We analyze the Kozachenko--Leonenko (KL) nearest neighbor estimator for the\ndifferential entropy. We obtain the first uniform upper bound on its\nperformance over H\\\"older balls on a torus without assuming any conditions on\nhow close the density could be from zero. Accompanying a new minimax lower\nbound over the H\\\"older ball, we show that the KL estimator is achieving the\nminimax rates up to logarithmic factors without cognizance of the smoothness\nparameter $s$ of the H\\\"older ball for $s\\in (0,2]$ and arbitrary dimension\n$d$, rendering it the first estimator that provably satisfies this property. \n\n"}
{"id": "1711.09173", "contents": "Title: Echo State Transfer Learning for Data Correlation Aware Resource\n  Allocation in Wireless Virtual Reality Abstract: In this paper, the problem of data correlation-aware resource management is\nstudied for a network of wireless virtual reality (VR) users communicating over\ncloud-based small cell networks (SCNs). In the studied model, small base\nstations (SBSs) with limited computational resources act as VR control centers\nthat collect the tracking information from VR users over the cellular uplink\nand send them to the VR users over the downlink. In such a setting, VR users\nmay send or request correlated or similar data (panoramic images and tracking\ndata). This potential spatial data correlation can be factored into the\nresource allocation problem to reduce the traffic load in both uplink and\ndownlink. This VR resource allocation problem is formulated as a noncooperative\ngame that allows jointly optimizing the computational and spectrum resources,\nwhile being cognizant of the data correlation. To solve this game, a transfer\nlearning algorithm based on the machine learning framework of echo state\nnetworks (ESNs) is proposed. Unlike conventional reinforcement learning\nalgorithms that must be executed each time the environment changes, the\nproposed algorithm can intelligently transfer information on the learned\nutility, across time, to rapidly adapt to environmental dynamics due to factors\nsuch as changes in the users' content or data correlation. Simulation results\nshow that the proposed algorithm achieves up to 16.7% and 18.2% gains in terms\nof delay compared to the Q-learning with data correlation and Q-learning\nwithout data correlation. The results also show that the proposed algorithm has\na faster convergence time than Q-learning and can guarantee low delays. \n\n"}
{"id": "1711.10079", "contents": "Title: Towards Provably Invisible Network Flow Fingerprints Abstract: Network traffic analysis reveals important information even when messages are\nencrypted. We consider active traffic analysis via flow fingerprinting by\ninvisibly embedding information into packet timings of flows. In particular,\nassume Alice wishes to embed fingerprints into flows of a set of network input\nlinks, whose packet timings are modeled by Poisson processes, without being\ndetected by a watchful adversary Willie. Bob, who receives the set of\nfingerprinted flows after they pass through the network modeled as a collection\nof independent and parallel $M/M/1$ queues, wishes to extract Alice's embedded\nfingerprints to infer the connection between input and output links of the\nnetwork. We consider two scenarios: 1) Alice embeds fingerprints in all of the\nflows; 2) Alice embeds fingerprints in each flow independently with probability\n$p$. Assuming that the flow rates are equal, we calculate the maximum number of\nflows in which Alice can invisibly embed fingerprints while having those\nfingerprints successfully decoded by Bob. Then, we extend the construction and\nanalysis to the case where flow rates are distinct, and discuss the extension\nof the network model. \n\n"}
{"id": "1712.00764", "contents": "Title: Arbitrarily Varying Wiretap Channel with State Sequence Known or Unknown\n  at the Receiver Abstract: The secrecy capacity problems over the general arbitrarily varying wiretap\nchannel (AVWC), with respect to the maximal decoding error probability and\nstrong secrecy criterion, are considered, where the channel state sequence may\nbe known or unknown at the receiver. In the mean time, it is always assumed\nthat the channel state sequence is known at the eavesdropper and unknown at the\ntransmitter. Capacity results of both stochastic code (with random encoder and\ndeterministic decoder) and random code (with random encoder and decoder) are\ndiscussed. This model includes the previous models of classic AVWC as special\ncases. Single-letter lower bounds on the secrecy capacities are given, which\nare proved to be the secrecy capacities when the main channel is less noisy\nthan the wiretap channel. The coding scheme is based on Csiszar's almost\nindependent coloring scheme and Ahlswede's elimination technique. Moreover, a\nnew kind of typical sequence with respect to states is defined for this coding\nscheme. It is concluded that the secrecy capacity of stochastic code is\nidentical to that of random code when the receiver knows the state sequence.\nMeanwhile, random code may achieve larger secrecy capacity when the state\nsequence is unknown by the receiver. \n\n"}
{"id": "1712.00908", "contents": "Title: Joint User Scheduling and Power optimization in Full-Duplex Cells with\n  Successive Interference Cancellation Abstract: This paper considers a cellular system with a full-duplex base station and\nhalf-duplex users. The base station can activate one user in uplink or downlink\n(half-duplex mode), or two different users one in each direction simultaneously\n(full-duplex mode). Simultaneous transmissions in uplink and downlink causes\nself-interference at the base station and uplink-to-downlink interference at\nthe downlink user. Although uplink-to-downlink interference is typically\ntreated as noise, it is shown that successive interference decoding and\ncancellation (SIC mode) can lead to significant improvement in network utility,\nespecially when user distribution is concentrated around a few hotspots. The\nproposed temporal fair user scheduling algorithm and corresponding power\noptimization utilizes full-duplex and SIC modes as well as half-duplex\ntransmissions based on their impact on network utility. Simulation results\nreveal that the proposed strategy can achieve up to 95% average cell throughput\nimprovement in typical indoor scenarios with respect to a conventional network\nin which the base station is half-duplex. \n\n"}
{"id": "1712.02265", "contents": "Title: Polyadic Entropy, Synergy and Redundancy among Statistically Independent\n  Processes in Nonlinear Statistical Physics with Microphysical Codependence Abstract: The information shared among observables representing processes of interest\nis traditionally evaluated in terms of macroscale measures characterizing\naggregate properties of the underlying processes and their interactions.\nTraditional information measures are grounded on the assumption that the\nobservable represents a memoryless process without any interaction among\nmicrostates. Generalized entropy measures have been formulated in non-extensive\nstatistical mechanics aiming to take microphysical codependence into account in\nentropy quantification. By taking them into consideration when formulating\ninformation measures, the question is raised on whether and if so how much\ninformation permeates across scales to impact on the macroscale information\nmeasures. The present study investigates and quantifies the emergence of\nmacroscale information from microscale codependence among microphysics. In\norder to isolate the information emergence coming solely from the nonlinearly\ninteracting microphysics, redundancy and synergy are evaluated among macroscale\nvariables that are statistically independent from each other but not\nnecessarily so within their own microphysics. Synergistic and redundant\ninformation are found when microphysical interactions take place, even if the\nstatistical distributions are factorable. These findings stress the added value\nof nonlinear statistical physics to information theory in coevolutionary\nsystems. \n\n"}
{"id": "1712.03310", "contents": "Title: Maximum entropy low-rank matrix recovery Abstract: We propose in this paper a novel, information-theoretic method, called\nMaxEnt, for efficient data acquisition for low-rank matrix recovery. This\nproposed method has important applications to a wide range of problems,\nincluding image processing and text document indexing. Fundamental to our\ndesign approach is the so-called maximum entropy principle, which states that\nthe measurement masks which maximize the entropy of observations, also maximize\nthe information gain on the unknown matrix $\\mathbf{X}$. Coupled with a\nlow-rank stochastic model for $\\mathbf{X}$, such a principle (i) reveals novel\nconnections between information-theoretic sampling and subspace packings, and\n(ii) yields efficient mask construction algorithms for matrix recovery, which\nsignificantly outperforms random measurements. We illustrate the effectiveness\nof MaxEnt in simulation experiments, and demonstrate its usefulness in two\nreal-world applications on image recovery and text document indexing. \n\n"}
{"id": "1712.04930", "contents": "Title: Combination Networks with or without Secrecy Constraints: The Impact of\n  Caching Relays Abstract: This paper considers a two-hop network architecture known as a combination\nnetwork, where a layer of relay nodes connects a server to a set of end users.\nIn particular, a new model is investigated where the intermediate relays employ\ncaches in addition to the end users. First, a new centralized coded caching\nscheme is developed that utilizes maximum distance separable (MDS) coding,\njointly optimizes cache placement and delivery phase, and enables decomposing\nthe combination network into a set virtual multicast sub-networks. It is shown\nthat if the sum of the memory of an end user and its connected relay nodes is\nsufficient to store the database, then the server can disengage in the delivery\nphase and all the end users' requests can be satisfied by the caches in the\nnetwork. Lower bounds on the normalized delivery load using genie-aided cut-set\narguments are presented along with second hop optimality. Next recognizing the\ninformation security concerns of coded caching, this new model is studied under\nthree different secrecy settings: 1) secure delivery where we require an\nexternal entity must not gain any information about the database files by\nobserving the transmitted signals over the network links, 2) secure caching,\nwhere we impose the constraint that end users must not be able to obtain any\ninformation about files that they did not request, and 3) both secure delivery\nand secure caching, simultaneously. We demonstrate how network topology affects\nthe system performance under these secrecy requirements. Finally, we provide\nnumerical results demonstrating the system performance in each of the settings\nconsidered. \n\n"}
{"id": "1712.07365", "contents": "Title: Intelligent Power Control for Spectrum Sharing in Cognitive Radios: A\n  Deep Reinforcement Learning Approach Abstract: We consider the problem of spectrum sharing in a cognitive radio system\nconsisting of a primary user and a secondary user. The primary user and the\nsecondary user work in a non-cooperative manner. Specifically, the primary user\nis assumed to update its transmit power based on a pre-defined power control\npolicy. The secondary user does not have any knowledge about the primary user's\ntransmit power, or its power control strategy. The objective of this paper is\nto develop a learning-based power control method for the secondary user in\norder to share the common spectrum with the primary user. To assist the\nsecondary user, a set of sensor nodes are spatially deployed to collect the\nreceived signal strength information at different locations in the wireless\nenvironment. We develop a deep reinforcement learning-based method, which the\nsecondary user can use to intelligently adjust its transmit power such that\nafter a few rounds of interaction with the primary user, both users can\ntransmit their own data successfully with required qualities of service. Our\nexperimental results show that the secondary user can interact with the primary\nuser efficiently to reach a goal state (defined as a state in which both users\ncan successfully transmit their data) from any initial states within a few\nnumber of steps. \n\n"}
{"id": "1712.07733", "contents": "Title: A Unified Asymptotic Analysis of Area Spectral Efficiency in Ultradense\n  Cellular Networks Abstract: This paper studies the asymptotic properties of average area spectral\nefficiency (ASE) of a downlink cellular network in the limit of very dense base\nstation (BS) and user densities. This asymptotic analysis relies on three\nassumptions: (1) interference is treated as noise; (2) the BS locations are\ndrawn from a Poisson point process; (3) the path loss function is bounded above\nsatisfying mild regularity conditions. We consider three possible definitions\nof the average ASE, all of which give units of bits per second per unit\nbandwidth per unit area. When there is no constraint on the minimum operational\nsignal-to-interference-plus-noise ratio (SINR) and instantaneous full channel\nstate information (CSI) is available at the transmitter, the average ASE is\nproven to saturate to a constant, which we derive in a closed form. For the\nother two ASE definitions, wherein either a minimum SINR is enforced or CSI is\nnot available, the average ASE is instead shown to collapse to zero at high BS\ndensity. We provide several familiar case studies for the class of considered\npath loss models, and demonstrate that our results cover most previous models\nand results on ultradense networks as special cases. \n\n"}
{"id": "1712.07863", "contents": "Title: On the Information Dimension of Multivariate Gaussian Processes Abstract: The authors have recently defined the R\\'enyi information dimension rate\n$d(\\{X_t\\})$ of a stationary stochastic process $\\{X_t,\\,t\\in\\mathbb{Z}\\}$ as\nthe entropy rate of the uniformly-quantized process divided by minus the\nlogarithm of the quantizer step size $1/m$ in the limit as $m\\to\\infty$ (B.\nGeiger and T. Koch, \"On the information dimension rate of stochastic\nprocesses,\" in Proc. IEEE Int. Symp. Inf. Theory (ISIT), Aachen, Germany, June\n2017). For Gaussian processes with a given spectral distribution function\n$F_X$, they showed that the information dimension rate equals the Lebesgue\nmeasure of the set of harmonics where the derivative of $F_X$ is positive. This\npaper extends this result to multivariate Gaussian processes with a given\nmatrix-valued spectral distribution function $F_{\\mathbf{X}}$. It is\ndemonstrated that the information dimension rate equals the average rank of the\nderivative of $F_{\\mathbf{X}}$. As a side result, it is shown that the scale\nand translation invariance of information dimension carries over from random\nvariables to stochastic processes. \n\n"}
{"id": "1712.10291", "contents": "Title: Communications and Control for Wireless Drone-Based Antenna Array Abstract: In this paper, the effective use of multiple quadrotor drones as an aerial\nantenna array that provides wireless service to ground users is investigated.\nIn particular, under the goal of minimizing the airborne service time needed\nfor communicating with ground users, a novel framework for deploying and\noperating a drone-based antenna array system whose elements are single-antenna\ndrones is proposed. In the considered model, the service time is minimized by\nminimizing the wireless transmission time as well as the control time that is\nneeded for movement and stabilization of the drones. To minimize the\ntransmission time, first, the antenna array gain is maximized by optimizing the\ndrone spacing within the array. In this case, using perturbation techniques,\nthe drone spacing optimization problem is addressed by solving successive,\nperturbed convex optimization problems. Then, the optimal locations of the\ndrones around the array's center are derived such that the transmission time\nfor the user is minimized. Given the determined optimal locations of drones,\nthe drones must spend a control time to adjust their positions dynamically so\nas to serve multiple users. To minimize this control time of the quadrotor\ndrones, the speed of rotors is optimally adjusted based on both the\ndestinations of the drones and external forces (e.g., wind and gravity). In\nparticular, using bang-bang control theory, the optimal rotors' speeds as well\nas the minimum control time are derived in closed-form. Simulation results show\nthat the proposed approach can significantly reduce the service time to ground\nusers compared to a fixed-array case in which the same number of drones form a\nfixed uniform antenna array. The results also show that, in comparison with the\nfixed-array case, the network's spectral efficiency can be improved by 32%\nwhile leveraging the drone antenna array system. \n\n"}
{"id": "1801.00310", "contents": "Title: On Binary Distributed Hypothesis Testing Abstract: We consider the problem of distributed binary hypothesis testing of two\nsequences that are generated by an i.i.d. doubly-binary symmetric source. Each\nsequence is observed by a different terminal. The two hypotheses correspond to\ndifferent levels of correlation between the two source components, i.e., the\ncrossover probability between the two. The terminals communicate with a\ndecision function via rate-limited noiseless links. We analyze the tradeoff\nbetween the exponential decay of the two error probabilities associated with\nthe hypothesis test and the communication rates. We first consider the\nside-information setting where one encoder is allowed to send the full\nsequence. For this setting, previous work exploits the fact that a decoding\nerror of the source does not necessarily lead to an erroneous decision upon the\nhypothesis. We provide improved achievability results by carrying out a tighter\nanalysis of the effect of binning error; the results are also more complete as\nthey cover the full exponent tradeoff and all possible correlations. We then\nturn to the setting of symmetric rates for which we utilize Korner-Marton\ncoding to generalize the results, with little degradation with respect to the\nperformance with a one-sided constraint (side-information setting). \n\n"}
{"id": "1801.00552", "contents": "Title: Performance Limits with Additive Error Metrics in Noisy\n  Multi-Measurement Vector Problem Abstract: Real-world applications such as magnetic resonance imaging with multiple\ncoils, multi-user communication, and diffuse optical tomography often assume a\nlinear model where several sparse signals sharing common sparse supports are\nacquired by several measurement matrices and then contaminated by noise.\nMulti-measurement vector (MMV) problems consider the estimation or\nreconstruction of such signals. In different applications, the estimation error\nthat we want to minimize could be the mean squared error or other metrics such\nas the mean absolute error and the support set error. Seeing that minimizing\ndifferent error metrics is useful in MMV problems, we study\ninformation-theoretic performance limits for MMV signal estimation with\narbitrary additive error metrics. We also propose a message passing algorithmic\nframework that achieves the optimal performance, and rigorously prove the\noptimality of our algorithm for a special case. We further conjecture the\noptimality of our algorithm for some general cases, and back it up through\nnumerical examples. As an application of our MMV algorithm, we propose a novel\nsetup for active user detection in multi-user communication and demonstrate the\npromise of our proposed setup. \n\n"}
{"id": "1801.00606", "contents": "Title: Secrecy Capacity-Memory Tradeoff of Erasure Broadcast Channels Abstract: This paper derives upper and lower bounds on the secrecy capacity-memory\ntradeoff of a wiretap erasure broadcast channel (BC) with Kw weak receivers and\nKs strong receivers, where weak receivers, respectively strong receivers, have\nsame erasure probabilities and cache sizes. The lower bounds are achieved by\nschemes that meticulously combine joint cache-channel coding with wiretap\ncoding and key-aided one-time pads. The presented upper bound holds more\ngenerally for arbitrary degraded BCs and arbitrary cache sizes. When only weak\nreceivers have cache memories, upper and lower bounds coincide for small and\nlarge cache memories, thus providing the exact secrecy capacity-memory tradeoff\nfor this setup. The derived bounds allow to further conclude that the secrecy\ncapacity is positive even when the eavesdropper is stronger than all the\nlegitimate receivers with cache memories. Moreover, they show that the secrecy\ncapacity-memory tradeoff can be significantly smaller than its non-secure\ncounterpart, but it grows much faster when cache memories are small. The paper\nalso presents a lower bound on the global secrecy capacity-memory tradeoff\nwhere one is allowed to optimize the cache assignment subject to a total cache\nbudget. It is close to the best known lower bound without secrecy constraint.\nFor small total cache budget, the global secrecy capacity-memory tradeoff is\nachieved by assigning all the available cache memory uniformly over all\nreceivers if the eavesdropper is stronger than all legitimate receivers, and it\nis achieved by assigning the cache memory uniformly only over the weak\nreceivers if the eavesdropper is weaker than the strong receivers. \n\n"}
{"id": "1801.01593", "contents": "Title: Estimation in the spiked Wigner model: A short proof of the replica\n  formula Abstract: We consider the problem of estimating a rank-one perturbation of a Wigner\nmatrix in a setting of low signal-to-noise ratio. This serves as a simple model\nfor principal component analysis in high dimensions. The mutual information per\nvariable between the spike and the observed matrix, or equivalently, the\nnormalized Kullback-Leibler divergence between the planted and null models are\nknown to converge to the so-called {\\em replica-symmetric} formula, the\nproperties of which determine the fundamental limits of estimation in this\nmodel. We provide in this note a short and transparent proof of this formula,\nbased on simple executions of Gaussian interpolations and standard\nconcentration-of-measure arguments. The \\emph{Franz-Parisi potential}, that is,\nthe free entropy at a fixed overlap, plays an important role in our proof.\nFurthermore, our proof can be generalized straightforwardly to spiked tensor\nmodels of even order. \n\n"}
{"id": "1801.02324", "contents": "Title: Building Capacity-Achieving PIR Schemes with Optimal Sub-Packetization\n  over Small Fields Abstract: Suppose a database containing $M$ records is replicated across $N$ servers,\nand a user wants to privately retrieve one record by accessing the servers such\nthat identity of the retrieved record is secret against any up to $T$ servers.\nA scheme designed for this purpose is called a $T$-private information\nretrieval ($T$-PIR) scheme. Three indexes are concerned for PIR schemes:\n(1)rate, indicating the amount of retrieved information per unit of downloaded\ndata. The highest achievable rate is characterized by the capacity; (2)\nsub-packetization, reflexing the implementation complexity for linear schemes;\n(3) field size. We consider linear schemes over a finite field. In this paper,\na general $T$-PIR scheme simultaneously attaining the optimality of almost all\nof the three indexes is presented. Specifically, we design a linear\ncapacity-achieving $T$-PIR scheme with sub-packetization $\\!dn^{M-1}\\!$ over a\nfinite field $\\mathbb{F}_q$, $q\\geq N$. The sub-packetization $\\!dn^{M-1}\\!$,\nwhere $\\!d\\!=\\!{\\rm gcd}(N,T)\\!$ and $\\!n\\!=\\!N/d$, has been proved to be\noptimal in our previous work. The field size of all existing capacity-achieving\n$T$-PIR schemes must be larger than $Nt^{M-2}$ where $t=T/d$, while our scheme\nreduces the field size by an exponential factor. \n\n"}
{"id": "1801.02329", "contents": "Title: Grassmannian Codes with New Distance Measures for Network Coding Abstract: Grassmannian codes are known to be useful in error-correction for random\nnetwork coding. Recently, they were used to prove that vector network codes\noutperform scalar linear network codes, on multicast networks, with respect to\nthe alphabet size. The multicast networks which were used for this purpose are\ngeneralized combination networks. In both the scalar and the vector network\ncoding solutions, the subspace distance is used as the distance measure for the\ncodes which solve the network coding problem in the generalized combination\nnetworks. In this work we show that the subspace distance can be replaced with\ntwo other possible distance measures which generalize the subspace distance.\nThese two distance measures are shown to be equivalent under an orthogonal\ntransformation. It is proved that the Grassmannian codes with the new distance\nmeasures generalize the Grassmannian codes with the subspace distance and the\nsubspace designs with the strength of the design. Furthermore, optimal\nGrassmannian codes with the new distance measureshave minimal requirements for\nnetwork coding solutions of some generalized combination networks. The coding\nproblems related to these two distance measures, especially with respect to\nnetwork coding, are discussed. Finally, by using these new concepts it is\nproved that codes in the Hamming scheme form a subfamily of the Grassmannian\ncodes. \n\n"}
{"id": "1801.02505", "contents": "Title: Optimal Utility-Privacy Trade-off with Total Variation Distance as a\n  Privacy Measure Abstract: The total variation distance is proposed as a privacy measure in an\ninformation disclosure scenario when the goal is to reveal some information\nabout available data in return of utility, while retaining the privacy of\ncertain sensitive latent variables from the legitimate receiver. The total\nvariation distance is introduced as a measure of privacy-leakage by showing\nthat: i) it satisfies the post-processing and linkage inequalities, which makes\nit consistent with an intuitive notion of a privacy measure; ii) the optimal\nutility-privacy trade-off can be solved through a standard linear program when\ntotal variation distance is employed as the privacy measure; iii) it provides a\nbound on the privacy-leakage measured by mutual information, maximal leakage,\nor the improvement in an inference attack with a bounded cost function. \n\n"}
{"id": "1801.02782", "contents": "Title: UAV-Aided Wireless Communication Designs With Propulsion Energy\n  Limitations Abstract: This paper studies unmanned aerial vehicle (UAV) aided wireless communication\nsystems where a UAV supports uplink communications of multiple ground nodes\n(GNs) while flying over the area of the interest. In this system, the\npropulsion energy consumption at the UAV is taken into account so that the\nUAV's velocity and acceleration should not exceed a certain threshold. We\nformulate the minimum average rate maximization problem and the energy\nefficiency (EE) maximization problem by jointly optimizing the trajectory,\nvelocity, and acceleration of the UAV and the uplink transmit power at the GNs.\nAs these problems are non-convex in general, we employ the successive convex\napproximation (SCA) techniques. To this end, proper convex approximations for\nthe non-convex constraints are derived, and iterative algorithms are proposed\nwhich converge to a local optimal point. Numerical results demonstrate that the\nproposed algorithms outperform baseline schemes for both problems. Especially\nfor the EE maximization problem, the proposed algorithm exhibits about 109 %\ngain over the baseline scheme. \n\n"}
{"id": "1801.03714", "contents": "Title: Multi-Band Covariance Interpolation with Applications in Massive MIMO Abstract: In this paper, we study the problem of multi-band (frequency-variant)\ncovariance interpolation with a particular emphasis towards massive MIMO\napplications. In a massive MIMO system, the communication between each BS with\n$M \\gg 1$ antennas and each single-antenna user occurs through a collection of\nscatterers in the environment, where the channel vector of each user at BS\nantennas consists in a weighted linear combination of the array responses of\nthe scatterers, where each scatterer has its own angle of arrival (AoA) and\ncomplex channel gain. The array response at a given AoA depends on the\nwavelength of the incoming planar wave and is naturally frequency dependent.\nThis results in a frequency-dependent distortion where the second order\nstatistics, i.e., the covariance matrix, of the channel vectors varies with\nfrequency. In this paper, we show that although this effect is generally\nnegligible for a small number of antennas $M$, it results in a considerable\ndistortion of the covariance matrix and especially its dominant signal subspace\nin the massive MIMO regime where $M \\to \\infty$, and can generally incur a\nserious degradation of the performance especially in frequency division\nduplexing (FDD) massive MIMO systems where the uplink (UL) and the downlink\n(DL) communication occur over different frequency bands. We propose a novel\nUL-DL covariance interpolation technique that is able to recover the covariance\nmatrix in the DL from an estimate of the covariance matrix in the UL under a\nmild reciprocity condition on the angular power spread function (PSF) of the\nusers. We analyze the performance of our proposed scheme mathematically and\nprove its robustness under a sufficiently large spatial oversampling of the\narray. We also propose several simple off-the-shelf algorithms for UL-DL\ncovariance interpolation and evaluate their performance via numerical\nsimulations. \n\n"}
{"id": "1801.04973", "contents": "Title: Two-Stage LASSO ADMM Signal Detection Algorithm For Large Scale MIMO Abstract: This paper explores the benefit of using some of the machine learning\ntechniques and Big data optimization tools in approximating maximum likelihood\n(ML) detection of Large Scale MIMO systems. First, large scale MIMO detection\nproblem is formulated as a LASSO (Least Absolute Shrinkage and Selection\nOperator) optimization problem. Then, Alternating Direction Method of\nMultipliers (ADMM) is considered in solving this problem. The choice of ADMM is\nmotivated by its ability of solving convex optimization problems by breaking\nthem into smaller sub-problems, each of which are then easier to handle.\nFurther improvement is obtained using two stages of LASSO with interference\ncancellation from the first stage. The proposed algorithm is investigated at\nvarious modulation techniques with different number of antennas. It is also\ncompared with widely used algorithms in this field. Simulation results\ndemonstrate the efficacy of the proposed algorithm for both uncoded and coded\ncases. \n\n"}
{"id": "1801.05522", "contents": "Title: Coded Computing for Distributed Graph Analytics Abstract: Performance of distributed graph processing systems significantly suffers\nfrom 'communication bottleneck' as a large number of messages are exchanged\namong servers at each step of the computation. Motivated by graph based\nMapReduce, we propose a coded computing framework that leverages computation\nredundancy to alleviate the communication bottleneck in distributed graph\nprocessing. We develop a novel 'coding' scheme that systematically injects\nstructured redundancy in computation phase to enable 'coded' multicasting\nopportunities during message exchange between servers, reducing communication\nload substantially in large-scale graph processing. For theoretical analysis,\nwe consider random graph models, and prove that our proposed scheme enables an\n(asymptotically) inverse-linear trade-off between 'computation load' and\n'average communication load' for two popular random graph models -- Erdos-Renyi\nmodel, and power law model. Particularly, for a given computation load r, (i.e.\nwhen each graph vertex is carefully stored at r servers), the proposed scheme\nslashes the average communication load by (nearly) a multiplicative factor of\nr. For the Erdos-Renyi model, our proposed scheme is optimal asymptotically as\nthe graph size increases by providing an information-theoretic converse. To\nillustrate the benefits of our scheme in practice, we implement PageRank over\nAmazon EC2, using artificial as well as real-world datasets, demonstrating\nsignificant gains over conventional PageRank. We also specialize our scheme and\nextend our theoretical results to two other random graph models -- random\nbi-partite model, and stochastic block model. They asymptotically enable\ninverse-linear trade-offs between computation and communication loads in\ndistributed graph processing for these popular random graph models as well. We\ncomplement the achievability results with converse bounds for both of these\nmodels. \n\n"}
{"id": "1801.06623", "contents": "Title: Promises and Caveats of Uplink IoT Ultra-Dense Networks Abstract: In this paper, by means of simulations, we evaluate the uplink (UL)\nperformance of an Internet of Things (IoT) capable ultra-dense network (UDN) in\nterms of the coverage probability and the density of reliably working user\nequipments (UEs). From our study, we show the benefits and challenges that UL\nIoT UDNs will bring about in the future. In more detail, for a low-reliability\ncriterion, such as achieving a UL signal-to-interference-plus-noise ratio\n(SINR) above 0 dB, the density of reliably working UEs grows quickly with the\nnetwork densification, showing the potential of UL IoT UDNs. In contrast, for a\nhigh-reliability criterion, such as achieving a UL SINR above 10 dB, the\ndensity of reliably working UEs remains to be low in UDNs due to excessive\ninter-cell interference, which should be considered when operating UL IoT UDNs.\nMoreover, considering the existence of a non-zero antenna height difference\nbetween base stations (BSs) and UEs, the density of reliably working UEs could\neven decrease as we deploy more BSs. This calls for the usage of sophisticated\ninterference management schemes and/or beam steering/shaping technologies in UL\nIoT UDNs. \n\n"}
{"id": "1801.07419", "contents": "Title: Optimality of Simple Layered Superposition Coding in the 3 User MISO BC\n  with Finite Precision CSIT Abstract: We study the $K=3$ user multiple input single output (MISO) broadcast channel\n(BC) with $M=3$ antennas at the transmitter and $1$ antenna at each receiver,\nfrom the generalized degrees of freedom (GDoF) perspective, under the\nassumption that the channel state information at the transmitter (CSIT) is\nlimited to finite precision. In particular, our goal is to identify a parameter\nregime where a simple layered superposition (SLS) coding scheme achieves the\nentire GDoF region. With $\\alpha_{ij}$ representing the channel strength\nparameter for the link from the $j^{th}$ antenna of the transmitter to the\n$i^{th}$ receiver, we prove that SLS is GDoF optimal without the need for\ntime-sharing if $\\max(\\alpha_{ki},\\alpha_{im})\\leq\\alpha_{ii}$ and\n$\\alpha_{ki}+\\alpha_{im}\\le\\alpha_{ii}+\\alpha_{km}$ for all\n$i,k\\in[3],m\\in[M]$. The GDoF region under this condition is a convex\npolyhedron. The result generalizes to arbitrary $M\\geq 3$. \n\n"}
{"id": "1801.09109", "contents": "Title: Spectral and Energy Efficient Wireless Powered IoT Networks: NOMA or\n  TDMA? Abstract: Wireless powered communication networks (WPCNs), where multiple\nenergy-limited devices first harvest energy in the downlink and then transmit\ninformation in the uplink, have been envisioned as a promising solution for the\nfuture Internet-of-Things (IoT). Meanwhile, non-orthogonal multiple access\n(NOMA) has been proposed to improve the system spectral efficiency (SE) of the\nfifth-generation (5G) networks by allowing concurrent transmissions of multiple\nusers in the same spectrum. As such, NOMA has been recently considered for the\nuplink of WPCNs based IoT networks with a massive number of devices. However,\nsimultaneous transmissions in NOMA may also incur more transmit energy\nconsumption as well as circuit energy consumption in practice which is critical\nfor energy constrained IoT devices. As a result, compared to orthogonal\nmultiple access schemes such as time-division multiple access (TDMA), whether\nthe SE can be improved and/or the total energy consumption can be reduced with\nNOMA in such a scenario still remains unknown. To answer this question, we\nfirst derive the optimal time allocations for maximizing the SE of a TDMA-based\nWPCN (T-WPCN) and a NOMA-based WPCN (N-WPCN), respectively. Subsequently, we\nanalyze the total energy consumption as well as the maximum SE achieved by\nthese two networks. Surprisingly, it is found that N-WPCN not only consumes\nmore energy, but also is less spectral efficient than T-WPCN. Simulation\nresults verify our theoretical findings and unveil the fundamental performance\nbottleneck, i.e., \"worst user bottleneck problem\", in multiuser NOMA systems. \n\n"}
{"id": "1801.09383", "contents": "Title: Wireless Powered Asynchronous Backscatter Networks with Sporadic Short\n  Packets: Performance Analysis and Optimization Abstract: In the fifth generation era, the pervasive applications of Internet of Things\nand massive machine-type communications have initiated increasing research\ninterests on the backscatter wireless powered communication (B-WPC) technique\ndue to its ultra high energy efficiency and low cost. The ubiquitous B-WPC\nnetwork is characterized by nodes with dynamic spatial positions and sporadic\nshort packets, of which the performance has not been fully investigated. In\nthis paper, we give a comprehensive analysis of a multi-antenna B-WPC network\nwith sporadic short packets under a stochastic geometry framework. By\nexploiting a time-space Poisson point process model, the behavior of the\nnetwork is well captured in a decentralized and asynchronous transmission way.\nWe then analyze the energy and information outage performance in the energy\nharvest and backscatter modulation phases of the backscatter network,\nrespectively. The optimal transmission slot length and division are obtained by\nmaximizing the network-wide spatial throughput. Moreover, we find an\ninteresting result that there exists the optimal tradeoff between the durations\nof the energy harvest and backscatter modulation phases for spatial throughput\nmaximization. Numerical results are demonstrated to verify our analytical\nfindings and show that this tradeoff region gets shrunk when the outage\nconstraints become more stringent. \n\n"}
{"id": "1802.00104", "contents": "Title: On the Achievability Region of Regenerating Codes for Multiple Erasures Abstract: We study the problem of centralized exact repair of multiple failures in\ndistributed storage. We describe constructions that achieve a new set of\ninterior points under exact repair. The constructions build upon the layered\ncode construction by Tian et al., designed for exact repair of single failure.\nWe firstly improve upon the layered construction for general system parameters.\nThen, we extend the improved construction to support the repair of multiple\nfailures, with varying number of helpers. In particular, we prove the\noptimality of one point on the functional repair tradeoff of multiple failures\nfor some parameters. Finally, considering minimum bandwidth cooperative repair\n(MBCR) codes as centralized repair codes, we determine explicitly the best\nachievable region obtained by space-sharing among all known points, including\nthe MBCR point. \n\n"}
{"id": "1802.00107", "contents": "Title: Predicting Wireless Channel Features using Neural Networks Abstract: We investigate the viability of using machine-learning techniques for\nestimating user-channel features at a large-array base station (BS). In the\nscenario we consider, user-pilot broadcasts are observed and processed by the\nBS to extract angle-of-arrival (AoA) specific information about\npropagation-channel features, such as received signal strength and relative\npath delay. The problem of interest involves using this information to predict\nthe angle-of-departure (AoD) of the dominant propagation paths in the user\nchannels, i.e., channel features not directly observable at the BS. To\naccomplish this task, the data collected in the same propagation environment\nare used to train neural networks. Our studies rely on ray-tracing channel data\nthat have been calibrated against measurements from Shinjuku Square, a famous\nhotspot in Tokyo, Japan. We demonstrate that the observed features at the BS\nside are correlated with the angular features at the user side. We train neural\nnetworks that exploit different combinations of measured features at the BS to\ninfer the unknown parameters at the users. The evaluation based on standard\nstatistical performance metrics suggests that such data-driven methods have the\npotential to predict unobserved channel features from observed ones. \n\n"}
{"id": "1802.00263", "contents": "Title: Robust Sequential Detection in Distributed Sensor Networks Abstract: We consider the problem of sequential binary hypothesis testing with a\ndistributed sensor network in a non-Gaussian noise environment. To this end, we\npresent a general formulation of the Consensus + Innovations Sequential\nProbability Ratio Test (CISPRT). Furthermore, we introduce two different\nconcepts for robustifying the CISPRT and propose four different algorithms,\nnamely, the Least-Favorable-Density-CISPRT, the Median-CISPRT, the M-CISPRT,\nand the Myriad-CISPRT. Subsequently, we analyze their suitability for different\nbinary hypothesis tests before verifying and evaluating their performance in a\nshift-in-mean and a shift-in-variance scenario. \n\n"}
{"id": "1802.00880", "contents": "Title: Study of SIC and RLS Channel Estimation for Large-Scale Antenna Systems\n  with 1-Bit ADCs Abstract: We propose a novel low-resolution-aware recursive least squares channel\nestimation algorithm for uplink multi-user multiple-input multiple-output\nsystems. In order to reduce the energy consumption, 1-bit ADCs are used on each\nreceive antenna. The loss of performance can be recovered by the large-scale\nantenna arrays at the receiver. The proposed adaptive channel estimator can\nmitigate the distortions due to the coarse quantization. Moreover, we propose a\nlow-resolution-aware minimum mean square error based successive interference\ncanceler to successively mitigate the multiuser interference. Simulation\nresults show good performance of the system in terms of mean square error and\nbit error rate. \n\n"}
{"id": "1802.00918", "contents": "Title: Typicality Matching for Pairs of Correlated Graphs Abstract: In this paper, the problem of matching pairs of correlated random graphs with\nmulti-valued edge attributes is considered. Graph matching problems of this\nnature arise in several settings of practical interest including social network\nde-anonymization, study of biological data, web graphs, etc. An achievable\nregion for successful matching is derived by analyzing a new matching algorithm\nthat we refer to as typicality matching. The algorithm operates by\ninvestigating the joint typicality of the adjacency matrices of the two\ncorrelated graphs. Our main result shows that the achievable region depends on\nthe mutual information between the variables corresponding to the edge\nprobabilities of the two graphs. The result is based on bounds on the\ntypicality of permutations of sequences of random variables that might be of\nindependent interest. \n\n"}
{"id": "1802.02049", "contents": "Title: A Distance Between Channels: the average error of mismatched channels Abstract: Two channels are equivalent if their maximum likelihood (ML) decoders\ncoincide for every code. We show that this equivalence relation partitions the\nspace of channels into a generalized hyperplane arrangement. With this, we\ndefine a coding distance between channels in terms of their ML-decoders which\nis meaningful from the decoding point of view, in the sense that the closer two\nchannels are, the larger is the probability of them sharing the same\nML-decoder. We give explicit formulas for these probabilities. \n\n"}
{"id": "1802.03271", "contents": "Title: Enhancing Performance of Random Caching in Large-Scale Heterogeneous\n  Wireless Networks with Random Discontinuous Transmission Abstract: To make better use of file diversity provided by random caching and improve\nthe successful transmission probability (STP) of a file, we consider\nretransmissions with random discontinuous transmission (DTX) in a large-scale\ncache-enabled heterogeneous wireless network (HetNet) employing random caching.\nWe analyze and optimize the STP in two mobility scenarios, i.e., the high\nmobility scenario and the static scenario. First, in each scenario, by using\ntools from stochastic geometry, we obtain the closed-form expressions for the\nSTP in the general and low signal-to-interference ratio (SIR) threshold\nregimes, respectively. The analysis shows that a larger caching probability\ncorresponds to a higher STP in both scenarios; random DTX can improve the STP\nin the static scenario and its benefit gradually diminishes when mobility\nincreases. Then, in each scenario, we consider the maximization of the STP with\nrespect to the caching probability and the BS activity probability, which is a\nchallenging non-convex optimization problem. In particular, in the high\nmobility scenario, we obtain a globally optimal solution using interior point\nmethod. In the static scenario, we develop a low-complexity iterative algorithm\nto obtain a stationary point using alternating optimization. Finally, numerical\nresults show that the proposed solutions achieve significant gains over\nexisting baseline schemes and can well adapt to the changes of the system\nparameters to wisely utilize storage resources and transmission opportunities. \n\n"}
{"id": "1802.03906", "contents": "Title: UAV-Enabled Mobile Edge Computing: Offloading Optimization and\n  Trajectory Design Abstract: With the emergence of diverse mobile applications (such as augmented\nreality), the quality of experience of mobile users is greatly limited by their\ncomputation capacity and finite battery lifetime. Mobile edge computing (MEC)\nand wireless power transfer are promising to address this issue. However, these\ntwo techniques are susceptible to propagation delay and loss. Motivated by the\nchance of short-distance line-of-sight achieved by leveraging unmanned aerial\nvehicle (UAV) communications, an UAV-enabled wireless powered MEC system is\nstudied. A power minimization problem is formulated subject to the constraints\non the number of the computation bits and energy harvesting causality. The\nproblem is non-convex and challenging to tackle. An alternative optimization\nalgorithm is proposed based on sequential convex optimization. Simulation\nresults show that our proposed design is superior to other benchmark schemes\nand the proposed algorithm is efficient in terms of the convergence. \n\n"}
{"id": "1802.04031", "contents": "Title: Rack-Aware Regenerating Codes for Data Centers Abstract: Erasure coding is widely used for massive storage in data centers to achieve\nhigh fault tolerance and low storage redundancy. Since the cross-rack\ncommunication cost is often high, it is critical to design erasure codes that\nminimize the cross-rack repair bandwidth during failure repair. In this paper,\nwe analyze the optimal trade-off between storage redundancy and cross-rack\nrepair bandwidth specifically for data centers, subject to the condition that\nthe original data can be reconstructed from a sufficient number of any\nnon-failed nodes. We characterize the optimal trade-off curve under functional\nrepair, and propose a general family of erasure codes called rack-aware\nregenerating codes (RRC), which achieve the optimal trade-off. We further\npropose exact repair constructions of RRC that have minimum storage redundancy\nand minimum cross-rack repair bandwidth, respectively. We show that (i) the\nminimum storage redundancy constructions support a wide range of parameters and\nhave cross-rack repair bandwidth that is strictly less than that of the\nclassical minimum storage regenerating codes in most cases, and (ii) the\nminimum cross-rack repair bandwidth constructions support all the parameters\nand have less cross-rack repair bandwidth than that of the minimum bandwidth\nregenerating codes for almost all of the parameters. \n\n"}
{"id": "1802.04497", "contents": "Title: A Dimension-Independent discriminant between distributions Abstract: Henze-Penrose divergence is a non-parametric divergence measure that can be\nused to estimate a bound on the Bayes error in a binary classification problem.\nIn this paper, we show that a cross-match statistic based on optimal weighted\nmatching can be used to directly estimate Henze-Penrose divergence. Unlike an\nearlier approach based on the Friedman-Rafsky minimal spanning tree statistic,\nthe proposed method is dimension-independent. The new approach is evaluated\nusing simulation and applied to real datasets to obtain Bayes error estimates. \n\n"}
{"id": "1802.05567", "contents": "Title: Rate-Splitting for Multi-Antenna Non-Orthogonal Unicast and Multicast\n  Transmission Abstract: In a superimposed unicast and multicast transmission system, one layer of\nSuccessive Interference Cancellation (SIC) is required at each receiver to\nremove the multicast stream before decoding the unicast stream. In this paper,\nwe show that a linearly-precoded Rate-Splitting (RS) strategy at the\ntransmitter can efficiently exploit this existing SIC receiver architecture. By\nsplitting the unicast message into common and private parts and encoding the\ncommon parts along with the multicast message into a super-common stream\ndecoded by all users, the SIC is used for the dual purpose of separating the\nunicast and multicast streams as well as better managing the multi-user\ninterference between the unicast streams. The precoders are designed with the\nobjective of maximizing the Weighted Sum Rate (WSR) of the unicast messages\nsubject to a Quality of Service (QoS) requirement of the multicast message and\na sum power constraint. Numerical results show that RS outperforms existing\nMulti-User Linear-Precoding (MU-LP) and power-domain Non-Orthogonal Multiple\nAccess (NOMA) in a wide range of user deployments (with a diversity of channel\ndirections and channel strengths). Moreover, since one layer of SIC is required\nto separate the unicast and multicast streams, the performance gain of RS comes\nwithout any increase in the receiver complexity compared with MU-LP. Hence, in\nsuch non-orthogonal unicast and multicast transmissions, RS provides rate and\nQoS enhancements at no extra cost for the receivers. \n\n"}
{"id": "1802.05973", "contents": "Title: Information Rates and Error Exponents for Probabilistic Amplitude\n  Shaping Abstract: Probabilistic Amplitude Shaping (PAS) is a coded-modulation scheme in which\nthe encoder is a concatenation of a distribution matcher with a systematic\nForward Error Correction (FEC) code. For reduced computational complexity the\ndecoder can be chosen as a concatenation of a mismatched FEC decoder and\ndematcher. This work studies the theoretic limits of PAS. The classical joint\nsource-channel coding (JSCC) setup is modified to include systematic FEC and\nthe mismatched FEC decoder. At each step error exponents and achievable rates\nfor the corresponding setup are derived. \n\n"}
{"id": "1802.07458", "contents": "Title: Non-Asymptotic Bounds and a General Formula for the Rate-Distortion\n  Region of the Successive Refinement Problem Abstract: In the successive refinement problem, a fixed-length sequence emitted from an\ninformation source is encoded into two codewords by two encoders in order to\ngive two reconstructions of the sequence. One of two reconstructions is\nobtained by one of two codewords, and the other reconstruction is obtained by\nall two codewords. For this coding problem, we give non-asymptotic inner and\nouter bounds on pairs of numbers of codewords of two encoders such that each\nprobability that a distortion exceeds a given distortion level is less than a\ngiven probability level. We also give a general formula for the rate-distortion\nregion for general sources, where the rate-distortion region is the set of rate\npairs of two encoders such that each maximum value of possible distortions is\nless than a given distortion level. \n\n"}
{"id": "1802.07851", "contents": "Title: Data Privacy for a $\\rho$-Recoverable Function Abstract: A user's data is represented by a finite-valued random variable. Given a\nfunction of the data, a querier is required to recover, with at least a\nprescribed probability, the value of the function based on a query response\nprovided by the user. The user devises the query response, subject to the\nrecoverability requirement, so as to maximize privacy of the data from the\nquerier. Privacy is measured by the probability of error incurred by the\nquerier in estimating the data from the query response. We analyze single and\nmultiple independent query responses, with each response satisfying the\nrecoverability requirement, that provide maximum privacy to the user. In the\nformer setting, we also consider privacy for a predicate of the user's data.\nAchievability schemes with explicit randomization mechanisms for query\nresponses are given and their privacy compared with converse upper bounds. \n\n"}
{"id": "1802.08464", "contents": "Title: The geometry of off-the-grid compressed sensing Abstract: This paper presents a sharp geometric analysis of the recovery performance of\nsparse regularization. More specifically, we analyze the BLASSO method which\nestimates a sparse measure (sum of Dirac masses) from randomized sub-sampled\nmeasurements. This is a \"continuous\", often called off-the-grid, extension of\nthe compressed sensing problem, where the $\\ell^1$ norm is replaced by the\ntotal variation of measures. This extension is appealing from a numerical\nperspective because it avoids to discretize the the space by some grid. But\nmore importantly, it makes explicit the geometry of the problem since the\npositions of the Diracs can now freely move over the parameter space. On a\nmethodological level, our contribution is to propose the Fisher geodesic\ndistance on this parameter space as the canonical metric to analyze\nsuper-resolution in a way which is invariant to reparameterization of this\nspace. Switching to the Fisher metric allows us to take into account\nmeasurement operators which are not translation invariant, which is crucial for\napplications such as Laplace inversion in imaging, Gaussian mixtures estimation\nand training of multilayer perceptrons with one hidden layer. On a theoretical\nlevel, our main contribution shows that if the Fisher distance between spikes\nis larger than a Rayleigh separation constant, then the BLASSO recovers in a\nstable way a stream of Diracs, provided that the number of measurements is\nproportional (up to log factors) to the number of Diracs. We measure the\nstability using an optimal transport distance constructed on top of the Fisher\ngeodesic distance. Our result is (up to log factor) sharp and does not require\nany randomness assumption on the amplitudes of the underlying measure. Our\nproof technique relies on an infinite-dimensional extension of the so-called\n\"golfing scheme\" which operates over the space of measures and is of general\ninterest. \n\n"}
{"id": "1802.09766", "contents": "Title: Learning Representations for Neural Network-Based Classification Using\n  the Information Bottleneck Principle Abstract: In this theory paper, we investigate training deep neural networks (DNNs) for\nclassification via minimizing the information bottleneck (IB) functional. We\nshow that the resulting optimization problem suffers from two severe issues:\nFirst, for deterministic DNNs, either the IB functional is infinite for almost\nall values of network parameters, making the optimization problem ill-posed, or\nit is piecewise constant, hence not admitting gradient-based optimization\nmethods. Second, the invariance of the IB functional under bijections prevents\nit from capturing properties of the learned representation that are desirable\nfor classification, such as robustness and simplicity. We argue that these\nissues are partly resolved for stochastic DNNs, DNNs that include a (hard or\nsoft) decision rule, or by replacing the IB functional with related, but more\nwell-behaved cost functions. We conclude that recent successes reported about\ntraining DNNs using the IB framework must be attributed to such solutions. As a\nside effect, our results indicate limitations of the IB framework for the\nanalysis of DNNs. We also note that rather than trying to repair the inherent\nproblems in the IB functional, a better approach may be to design regularizers\non latent representation enforcing the desired properties directly. \n\n"}
{"id": "1803.00690", "contents": "Title: Throughput Maximization for Laser-Powered UAV Wireless Communication\n  Systems Abstract: Laser power has become a viable solution to provide convenient and\nsustainable energy supply to unmanned aerial vehicles (UAVs). In this paper, we\nstudy a laser-powered UAV wireless communication system, where a laser\ntransmitter sends laser beams to charge a fixed-wing UAV in flight, and the UAV\nuses the harvested laser energy to communicate with a ground station. To\nmaintain the UAV's sustainable operation, its total energy consumption cannot\nexceed that harvested from the laser transmitter. Under such a laser energy\nharvesting constraint, we maximize the downlink communication throughput from\nthe UAV to the ground station over a finite time duration, by jointly\noptimizing the UAV's trajectory and its transmit power allocation. However, due\nto the complicated UAV energy consumption model, this problem is non-convex and\ndifficult to be solved. To tackle the problem, we first consider a special case\nwith a double-circular UAV trajectory which balances the tradeoff between\nmaximizing the performance of laser energy harvesting versus wireless\ncommunication at the UAV. Next, based on the obtained double-circular\ntrajectory, we propose an efficient solution to the general problem, by\napplying the techniques of alternating optimization and sequential convex\nprogramming (SCP). Finally, numerical results are provided to validate the\ncommunication throughput performance of the proposed design. \n\n"}
{"id": "1803.00884", "contents": "Title: Physical Layer Security for RF Satellite Channels in the Finite-length\n  Regime Abstract: Secure communications is becoming increasingly relevant in the development of\nspace technology. Well established cryptographic technology is already in place\nand is expected to continue to be so. On the other hand, information\ntheoretical security emerges as a post-quantum versatile candidate to\ncomplement overall security strength. In order to prove such potential,\nperformance analysis methods are needed that consider realistic legitimate and\neavesdropper system assumptions and non-asymptotic coding lengths. In this\npaper we propose the design of secure radio frequency (RF) satellite links with\nrealistic system assumptions. Our contribution is three-fold. First, we propose\na wiretap channel model for the finite-length regime. The model includes an\nstochastic wiretap encoding method using existing practical linear error\ncorrecting codes and hash codes. Secrecy is provided with privacy\namplification, for which the finite-length secrecy metric is given that upper\nbounds semantic secrecy. Second, we derive a novel RF (broadcast) satellite\nwiretap channel model that parameterizes the stochastic degraded channel around\nthe legitimate channel, a necessary condition to enable secure communication.\nFinally, we show the design of a secure satellite physical layer and\nfinite-length performance evaluation. In doing so, we define as sacrifice rate\nthe fixed fraction of the overall coding rate budget for reliability that needs\nto be allocated to secrecy. Our methodology does not make use of channel side\ninformation of the eavesdropper, only assumes worst case system assumptions. We\nillustrate our proposed design method with numerical results using practical\nerror correcting codes in current standards of satellite communication. \n\n"}
{"id": "1803.02945", "contents": "Title: Comparison of Noisy Channels and Reverse Data-Processing Theorems Abstract: This paper considers the comparison of noisy channels from the viewpoint of\nstatistical decision theory. Various orderings are discussed, all formalizing\nthe idea that one channel is \"better\" than another for information\ntransmission. The main result is an equivalence relation that is proved for\nclassical channels, quantum channels with classical encoding, and quantum\nchannels with quantum encoding. \n\n"}
{"id": "1803.03752", "contents": "Title: Optimum Linear Codes with Support Constraints over Small Fields Abstract: We consider the problem of designing optimal linear codes (in terms of having\nthe largest minimum distance) subject to a support constraint on the generator\nmatrix. We show that the largest minimum distance can be achieved by a subcode\nof a Reed-Solomon code of small field size. As a by-product of this result, we\nsettle the GM-MDS conjecture of Dau et. al. in the affirmative. \n\n"}
{"id": "1803.04038", "contents": "Title: Updating Beamformers to Respond to Changes in Users Abstract: We consider a multi-user multiple-input single-output downlink system that\nprovides each user with a prespecified level of quality-of-service. The base\nstation (BS) designs the beamformers so that each user receives a certain\nsignal-to-interference-and-noise ratio (SINR). In contrast to most of the\navailable literature in the beamforming field, we focus on the required\nmodifications when the system changes. We specifically study three cases: (i)\nuser entering the system, (ii) user leaving the system, and (iii) a change in\nthe SINR target. We do so in order to avoid designing the entire system from\nscratch for every change in the requirements. In each of the three cases, we\ndescribe the modifications required to the beamforming directions and the power\nloading. We consider maximum ratio transmission (MRT), zero-forcing (ZF) and\nthe optimal beamformers. The proposed modifications provide performance that is\neither exact or very close to that obtained when we redesign the entire system,\nwhile having much lower computational cost. \n\n"}
{"id": "1803.04725", "contents": "Title: Storage and Repair Bandwidth Tradeoff for Distributed Storage Systems\n  with Clusters and Separate Nodes Abstract: The optimal tradeoff between node storage and repair bandwidth is an\nimportant issue for distributed storage systems (DSSs). As for realistic DSSs\nwith clusters, when repairing a failed node, it is more efficient to download\nmore data from intra-cluster nodes than from cross-cluster nodes. Therefore, it\nis meaningful to differentiate the repair bandwidth from intra-cluster and\ncross-cluster. For cluster DSSs the tradeoff has been considered with special\nrepair assumptions where all the alive nodes are utilized to repair a failed\nnode. In this paper, we investigate the optimal tradeoff for cluster DSSs under\nmore general storage/repair parameters. Furthermore, a regenerating code\nconstruction strategy achieving the points in the optimal tradeoff curve is\nproposed for cluster DSSs with specific parameters as a numerical example.\nMoreover, the influence of separate nodes for the tradeoff is also considered\nfor DSSs with clusters and separated nodes. \n\n"}
{"id": "1803.06123", "contents": "Title: On Combination Networks with Cache-aided Relays and Users Abstract: Caching is an efficient way to reduce peak hour network traffic congestion by\nstoring some contents at the user's cache without knowledge of later demands.\nCoded caching strategy was originally proposed by Maddah-Ali and Niesen to give\nan additional coded caching gain compared the conventional uncoded scheme.\nUnder practical consideration, the caching model was recently considered in\nrelay network, in particular the combination network, where the central server\ncommunicates with $K=\\binom{H}{r}$ users (each is with a cache of $M$ files)\nthrough $H$ immediate relays, and each user is connected to a different\n$r-$subsets of relays. Several inner bounds and outer bounds were proposed for\ncombination networks with end-user-caches. This paper extends the recent work\nby the authors on centralized combination networks with end-user caches to a\nmore general setting, where both relays and users have caches. In contrast to\nthe existing schemes in which the packets transmitted from the server are\nindependent of the cached contents of relays, we propose a novel caching scheme\nby creating an additional coded caching gain to the transmitted load from the\nserver with the help of the cached contents in relays. We also show that the\nproposed scheme outperforms the state-of-the-art approaches. \n\n"}
{"id": "1803.06746", "contents": "Title: Experimental Verification of Rate Flexibility and Probabilistic Shaping\n  by 4D Signaling Abstract: The rate flexibility and probabilistic shaping gain of $4$-dimensional\nsignaling is experimentally tested for short-reach, unrepeated transmission. A\nrate granularity of 0.5 bits/QAM symbol is achieved with a distribution matcher\nbased on a simple look-up table. \n\n"}
{"id": "1803.06760", "contents": "Title: A Machine Learning Approach for Power Allocation in HetNets Considering\n  QoS Abstract: There is an increase in usage of smaller cells or femtocells to improve\nperformance and coverage of next-generation heterogeneous wireless networks\n(HetNets). However, the interference caused by femtocells to neighboring cells\nis a limiting performance factor in dense HetNets. This interference is being\nmanaged via distributed resource allocation methods. However, as the density of\nthe network increases so does the complexity of such resource allocation\nmethods. Yet, unplanned deployment of femtocells requires an adaptable and\nself-organizing algorithm to make HetNets viable. As such, we propose to use a\nmachine learning approach based on Q-learning to solve the resource allocation\nproblem in such complex networks. By defining each base station as an agent, a\ncellular network is modelled as a multi-agent network. Subsequently,\ncooperative Q-learning can be applied as an efficient approach to manage the\nresources of a multi-agent network. Furthermore, the proposed approach\nconsiders the quality of service (QoS) for each user and fairness in the\nnetwork. In comparison with prior work, the proposed approach can bring more\nthan a four-fold increase in the number of supported femtocells while using\ncooperative Q-learning to reduce resource allocation overhead. \n\n"}
{"id": "1803.07395", "contents": "Title: Max-Min Fairness User Scheduling and Power Allocation in Full-Duplex\n  OFDMA Systems Abstract: In a full-duplex (FD) multi-user network, the system performance is not only\nlimited by the self-interference but also by the co-channel interference due to\nthe simultaneous uplink and downlink transmissions. Joint design of the\nuplink/downlink transmission direction of users and the power allocation is\ncrucial for achieving high system performance in the FD multi-user network. In\nthis paper, we investigate the joint uplink/downlink transmission direction\nassignment (TDA), user paring (UP) and power allocation problem for maximizing\nthe system max-min fairness (MMF) rate in a FD multi-user orthogonal frequency\ndivision multiple access (OFDMA) system. The problem is formulated with a\ntwo-time-scale structure where the TDA and the UP variables are for optimizing\na long-term MMF rate while the power allocation is for optimizing an\ninstantaneous MMF rate during each channel coherence interval. We show that the\nstudied joint MMF rate maximization problem is NP-hard in general. To obtain\nhigh-quality suboptimal solutions, we propose efficient methods based on simple\nrelaxation and greedy rounding techniques. Simulation results are presented to\nshow that the proposed algorithms are effective and achieve higher MMF rates\nthan the existing heuristic methods. \n\n"}
{"id": "1803.07505", "contents": "Title: Non-Asymptotic Classical Data Compression with Quantum Side Information Abstract: In this paper, we analyze classical data compression with quantum side\ninformation (also known as the classical-quantum Slepian-Wolf protocol) in the\nso-called large and moderate deviation regimes. In the non-asymptotic setting,\nthe protocol involves compressing classical sequences of finite length $n$ and\ndecoding them with the assistance of quantum side information. In the large\ndeviation regime, the compression rate is fixed, and we obtain bounds on the\nerror exponent function, which characterizes the minimal probability of error\nas a function of the rate. Devetak and Winter showed that the asymptotic data\ncompression limit for this protocol is given by a conditional entropy. For any\nprotocol with a rate below this quantity, the probability of error converges to\none asymptotically and its speed of convergence is given by the strong converse\nexponent function. We obtain finite blocklength bounds on this function, and\ndetermine exactly its asymptotic value. In the moderate deviation regime for\nthe compression rate, the latter is no longer considered to be fixed. It is\nallowed to depend on the blocklength $n$, but assumed to decay slowly to the\nasymptotic data compression limit. Starting from a rate above this limit, we\ndetermine the speed of convergence of the error probability to zero and show\nthat it is given in terms of the conditional information variance. Our results\ncomplement earlier results obtained by Tomamichel and Hayashi, in which they\nanalyzed the so-called small deviation regime of this protocol. \n\n"}
{"id": "1803.09012", "contents": "Title: Message passing-based joint CFO and channel estimation in millimeter\n  wave systems with one-bit ADCs Abstract: Channel estimation at millimeter wave (mmWave) is challenging when large\nantenna arrays are used. Prior work has leveraged the sparse nature of mmWave\nchannels via compressed sensing based algorithms for channel estimation. Most\nof these algorithms, though, assume perfect synchronization and are vulnerable\nto phase errors that arise due to carrier frequency offset (CFO) and phase\nnoise. Recently sparsity-aware, non-coherent beamforming algorithms that are\nrobust to phase errors were proposed for narrowband phased array systems with\nfull resolution analog-to-digital converters (ADCs). Such energy based\nalgorithms, however, are not robust to heavy quantization at the receiver. In\nthis paper, we develop a joint CFO and wideband channel estimation algorithm\nthat is scalable across different mmWave architectures. Our method exploits the\nsparsity of mmWave MIMO channel in the angle-delay domain, in addition to\ncompressibility of the phase error vector. We formulate the joint estimation as\na sparse bilinear optimization problem and then use message passing for\nrecovery. We also give an efficient implementation of a generalized bilinear\nmessage passing algorithm for the joint estimation in mmWave systems with\none-bit ADCs. Simulation results show that our method is able to recover the\nCFO and the channel compressively, even in the presence of phase noise. \n\n"}
{"id": "1803.09190", "contents": "Title: Bayesian Optimal Data Detector for Hybrid mmWave MIMO-OFDM Systems with\n  Low-Resolution ADCs Abstract: Hybrid analog-digital precoding architectures and low-resolution\nanalog-to-digital converter (ADC) receivers are two solutions to reduce\nhardware cost and power consumption for millimeter wave (mmWave) multiple-input\nmultiple-output (MIMO) communication systems with large antenna arrays. In this\nstudy, we consider a mmWave MIMO-OFDM receiver with a generalized hybrid\narchitecture in which a small number of radio-frequency (RF) chains and\nlow-resolution ADCs are employed simultaneously. Owing to the strong\nnonlinearity introduced by low-resolution ADCs, the task of data detection is\nchallenging, particularly achieving a Bayesian optimal data detector. This\nstudy aims to fill this gap. By using generalized expectation consistent signal\nrecovery technique, we propose a computationally efficient data detection\nalgorithm that provides a minimum mean-square error estimate on data symbols\nand is extended to a mixed-ADC architecture. Considering particular structure\nof MIMO-OFDM channel matirx, we provide a lowcomplexity realization in which\nonly FFT operation and matrixvector multiplications are required. Furthermore,\nwe present an analytical framework to study the theoretical performance of the\ndetector in the large-system limit, which can precisely evaluate the\nperformance expressions such as mean-square error and symbol error rate. Based\non this optimal detector, the potential of adding a few low-resolution RF\nchains and high-resolution ADCs for mixed-ADC architecture is investigated.\nSimulation results confirm the accuracy of our theoretical analysis and can be\nused for system design rapidly. The results reveal that adding a few\nlow-resolution RF chains to original unquantized systems can obtain significant\ngains. \n\n"}
{"id": "1803.09408", "contents": "Title: Efficient File Delivery for Coded Prefetching in Shared Cache Networks\n  with Multiple Requests Per User Abstract: We consider a centralized caching network, where a server serves several\ngroups of users, each having a common shared homogeneous fixed-size cache and\nrequesting arbitrary multiple files. An existing coded prefetching scheme is\nemployed where each file is broken into multiple fragments and each cache\nstores multiple coded packets each formed by XORing fragments from different\nfiles. For such a system, we propose an efficient file delivery scheme with\nexplicit constructions by the server to meet the arbitrary multi-requests of\nall user-groups. Specifically, the stored coded packets of each cache are\nclassified into four types based on the composition of the file fragments\nencoded. A delivery strategy is developed, which separately delivers part of\neach packet type first and then combinatorially delivers the remaining\ndifferent packet types in the last stage. The rate as well as the worst rate of\nthe proposed delivery scheme are analyzed. We show that our caching model and\ndelivery scheme can incorporate some existing coded caching schemes as special\ncases. Moreover, for the special case of uniform requests and uncoded\nprefetching, we make a comparison with existing results, and show that our\napproach can achieve a lower delivery rate. We also provide numerical results\non the delivery rate for the proposed scheme. \n\n"}
{"id": "1803.09467", "contents": "Title: A Switch to the Concern of User: Importance Coefficient in Utility\n  Distribution and Message Importance Measure Abstract: This paper mainly focuses on the utilization frequency in receiving end of\ncommunication systems, which shows the inclination of the user about different\nsymbols. When the average number of use is limited, a specific utility\ndistribution is proposed on the best effort in term of fairness, which is also\nthe closest one to occurring probability in the relative entropy. Similar to a\nswitch, its parameter can be selected to make it satisfy different users'\nrequirements: negative parameter means the user focus on high-probability\nevents and positive parameter means the user is interested in small-probability\nevents. In fact, the utility distribution is a measure of message importance in\nessence. It illustrates the meaning of message importance measure (MIM), and\nextend it to the general case by selecting the parameter. Numerical results\nshow that this utility distribution characterizes the message importance like\nMIM and its parameter determines the concern of users. \n\n"}
{"id": "1804.00108", "contents": "Title: Learning tensors from partial binary measurements Abstract: In this paper we generalize the 1-bit matrix completion problem to higher\norder tensors. We prove that when $r=O(1)$ a bounded rank-$r$, order-$d$ tensor\n$T$ in $\\mathbb{R}^{N} \\times \\mathbb{R}^{N} \\times \\cdots \\times\n\\mathbb{R}^{N}$ can be estimated efficiently by only $m=O(Nd)$ binary\nmeasurements by regularizing its max-qnorm and M-norm as surrogates for its\nrank. We prove that similar to the matrix case, i.e., when $d=2$, the sample\ncomplexity of recovering a low-rank tensor from 1-bit measurements of a subset\nof its entries is the same as recovering it from unquantized measurements.\nMoreover, we show the advantage of using 1-bit tensor completion over\nmatricization both theoretically and numerically. Specifically, we show how the\n1-bit measurement model can be used for context-aware recommender systems. \n\n"}
{"id": "1804.00486", "contents": "Title: Benefit of Joint DOA and Delay Estimation with Application to Indoor\n  Localization in WiFi and 5G Abstract: Accurate indoor localization has long been a challenging problem due to the\npresence of multipath. Joint direction-of-arrival (DOA) and time delay (TD)\nestimation is a promising technique for accurate indoor Localization in next\ngeneration WiFi and 5G, as it has the capability of separating the\nline-of-sight (LOS) signal from multipath signals in the TD space. Although the\nbenefit of joint DOA and TD estimation over DOA-only estimation has been\nempirically shown long ago, it has not been theoretically justified yet. In\nthis paper, we provide a theoretical proof of the benefit of joint DOA and TD\nestimation over DOA-only estimation. Further, experimental results with\nsimulated WiFi setting have been provided to demonstrate the theoretical\nfinding. Matlab code is available at \\textbf{https://github.com/FWen/JADE.git}. \n\n"}
{"id": "1804.00576", "contents": "Title: Cooperative Localization in Visible Light Networks: Theoretical Limits\n  and Distributed Algorithms Abstract: Light emitting diode (LED) based visible light positioning (VLP) networks can\nprovide accurate location information in indoor environments. In this\nmanuscript, we propose to employ cooperative localization for visible light\nnetworks by designing a VLP system configuration that involves multiple LED\ntransmitters with known locations (e.g., on the ceiling) and visible light\ncommunication (VLC) units equipped with both LEDs and photodetectors (PDs) for\nthe purpose of cooperation. First, we derive the Cram\\'er-Rao lower bound\n(CRLB) and the maximum likelihood estimator (MLE) for the localization of VLC\nunits in the proposed cooperative scenario. To tackle the nonconvex structure\nof the MLE, we adopt a set-theoretic approach by formulating the problem of\ncooperative localization as a quasiconvex feasibility problem, where the aim is\nto find a point inside the intersection of convex constraint sets constructed\nas the sublevel sets of quasiconvex functions resulting from the Lambertian\nformula. Next, we devise two feasibility-seeking algorithms based on iterative\ngradient projections to solve the feasibility problem. Both algorithms are\namenable to distributed implementation, thereby avoiding high-complexity\ncentralized approaches. Capitalizing on the concept of quasi-Fej\\'er convergent\nsequences, we carry out a formal convergence analysis to prove that the\nproposed algorithms converge to a solution of the feasibility problem in the\nconsistent case. Numerical examples illustrate the improvements in localization\nperformance achieved via cooperation among VLC units and evidence the\nconvergence of the proposed algorithms to true VLC unit locations in both the\nconsistent and inconsistent cases. \n\n"}
{"id": "1804.00598", "contents": "Title: Small-d MSR Codes with Optimal Access, Optimal Sub-Packetization and\n  Linear Field Size Abstract: This paper presents an explicit construction of a class of optimal-access,\nminimum storage regenerating (MSR) codes, for small values of the number $d$ of\nhelper nodes. The construction is valid for any parameter set $(n,k,d)$ with $d\n\\in \\{k+1, k+2, k+3\\}$ and employs a finite field $\\mathbb{F}_q$ of size\n$q=O(n)$. We will refer to the constructed codes as Small-d MSR codes. The\nsub-packetization level $\\alpha$ is given by $\\alpha =\ns^{{\\lceil\\frac{n}{s}\\rceil}}$, where $s=d-k+1$. By an earlier result on the\nsub-packetization level for optimal-access MSR codes, this is the smallest\nvalue possible. \n\n"}
{"id": "1804.00930", "contents": "Title: Symbol-Level Precoding Design Based on Distance Preserving Constructive\n  Interference Regions Abstract: In this paper, we investigate the symbol-level precoding (SLP) design problem\nin the downlink of a multiuser multiple-input single-output (MISO) channel. We\nconsider generic constellations with any arbitrary shape and size, and confine\nourselves to one of the main categories of constructive interference regions\n(CIR), namely, distance preserving CIR (DPCIR). We provide a comprehensive\nstudy of DPCIRs and derive some properties for these regions. Using these\nproperties, we first show that any signal in a given DPCIR has a norm greater\nthan or equal to the norm of the corresponding constellation point if and only\nif the convex hull of the constellation contains the origin. It is followed by\nproving that the power of the noiseless received signal lying on a DPCIR is a\nmonotonic strictly increasing function of two parameters relating to the\ninfinite Voronoi edges. Using the convex description of DPCIRs and their\nproperties, we formulate two design problems, namely, the SLP power\nminimization with signal-to-interference-plus-noise ratio (SINR) constraints,\nand the SLP SINR balancing problem under max-min fairness criterion. The SLP\npower minimization based on DPCIRs can straightforwardly be written as a\nquadratic program (QP). We provide a simplified reformulation of this problem\nwhich is less computationally complex. The SLP max-min SINR, however, is\nnon-convex in its original form, and hence difficult to tackle. We propose\nseveral alternative optimization approaches, including semidefinite program\n(SDP) formulation and block coordinate descent (BCD) optimization. We discuss\nand evaluate the loss due to the proposed alternative methods through extensive\nsimulation results. \n\n"}
{"id": "1804.04580", "contents": "Title: On The Efficiency of Widely Linear Precoding and Symbol Extension in\n  Cellular Uplink Abstract: We investigate Gaussian widely linear precoding known as improper Gaussian\nsignaling for the cellular uplink with inter-cell interference, known as\ninterference multiple access channel (IMAC). This transmission scheme provides\nextra degrees of freedom by treating the real and imaginary components of the\ncomplex Gaussian signal differently. Since current standards mainly utilize\nlinear beamforming for waveform generation, we highlight the benefits of widely\nlinear beamforming over multiple temporal dimensions (symbol extension in time)\nin the IMAC. This scheme achieves significantly higher information rates\ncompared to conventional proper Gaussian signaling at the expense of extra\ncomplexity at the transmission phase. We study the sum-power minimization\nproblem under rate constraints. This problem is a difference of concave\nfunctions (DC) program, hence, a non-convex problem. By numerical simulations,\nwe observe the benefits of improper Gaussian signaling alongside symbol\nextension in power consumption for both single-antenna and multi-antenna base\nstations. Interestingly, we observe that at strong interference scenarios, the\nefficiency of improper Gaussian signaling outperforms conventional proper\nGaussian signaling at low rate demands. Moreover, in such scenarios the\nsum-power required for achieving particular rate demands is significantly\nreduced. \n\n"}
{"id": "1804.05057", "contents": "Title: 5G Wireless Network Slicing for eMBB, URLLC, and mMTC: A\n  Communication-Theoretic View Abstract: The grand objective of 5G wireless technology is to support three generic\nservices with vastly heterogeneous requirements: enhanced mobile broadband\n(eMBB), massive machine-type communications (mMTC), and ultra-reliable\nlow-latency communications (URLLC). Service heterogeneity can be accommodated\nby network slicing, through which each service is allocated resources to\nprovide performance guarantees and isolation from the other services. Slicing\nof the Radio Access Network (RAN) is typically done by means of orthogonal\nresource allocation among the services. This work studies the potential\nadvantages of allowing for non-orthogonal sharing of RAN resources in uplink\ncommunications from a set of eMBB, mMTC and URLLC devices to a common base\nstation. The approach is referred to as Heterogeneous Non-Orthogonal Multiple\nAccess (H-NOMA), in contrast to the conventional NOMA techniques that involve\nusers with homogeneous requirements and hence can be investigated through a\nstandard multiple access channel. The study devises a communication-theoretic\nmodel that accounts for the heterogeneous requirements and characteristics of\nthe three services. The concept of reliability diversity is introduced as a\ndesign principle that leverages the different reliability requirements across\nthe services in order to ensure performance guarantees with non-orthogonal RAN\nslicing. This study reveals that H-NOMA can lead, in some regimes, to\nsignificant gains in terms of performance trade-offs among the three generic\nservices as compared to orthogonal slicing. \n\n"}
{"id": "1804.05814", "contents": "Title: Multidimensional Constellations for Uplink SCMA Systems --- A\n  Comparative Study Abstract: Sparse code multiple access (SCMA) is a class of non-orthogonal multiple\naccess (NOMA) that is proposed to support uplink machine-type communication\nservices. In an SCMA system, designing multidimensional constellation plays an\nimportant role in the performance of the system. Since the behaviour of\nmultidimensional constellations highly depends on the type of the channel, it\nis crucial to employ a constellation that is suitable for a certain\napplication. In this paper, we first highlight and review the key performance\nindicators (KPIs) of multidimensional constellations that should be considered\nin their design process for various channel scenarios. We then provide a survey\non the known multidimensional constellations in the context of SCMA systems\nwith their design criteria. The performance of some of those constellations are\nevaluated for uncoded, high-rate, and low-rate LTE turbo-coded SCMA systems\nunder different channel conditions through extensive simulations. All\nturbo-coded comparisons are performed for bit-interleaved coded modulation,\nwith a concatenated detection and decoding scheme. Simulation results confirm\nthat multidimensional constellations that satisfy KPIs of a certain channel\nscenario outperform others. Moreover, the bit error rate performance of uncoded\nsystems, and the performance of the coded systems are coupled to their\nbit-labeling. The performance of the systems also remarkably depends on the\nbehavior of the multi-user detector at different signal-to-noise ratio regions. \n\n"}
{"id": "1804.06334", "contents": "Title: On $f$-Divergences: Integral Representations, Local Behavior, and\n  Inequalities Abstract: This paper is focused on $f$-divergences, consisting of three main\ncontributions. The first one introduces integral representations of a general\n$f$-divergence by means of the relative information spectrum. The second part\nprovides a new approach for the derivation of $f$-divergence inequalities, and\nit exemplifies their utility in the setup of Bayesian binary hypothesis\ntesting. The last part of this paper further studies the local behavior of\n$f$-divergences. \n\n"}
{"id": "1804.07491", "contents": "Title: MIMO Channel Hardening: A Physical Model based Analysis Abstract: In a multiple-input-multiple-output (MIMO) communication system, the\nmultipath fading is averaged over radio links. This well-known channel\nhardening phenomenon plays a central role in the design of massive MIMO\nsystems. The aim of this paper is to study channel hardening using a physical\nchannel model in which the influences of propagation rays and antenna array\ntopologies are highlighted. A measure of channel hardening is derived through\nthe coefficient of variation of the channel gain. Our analyses and closed form\nresults based on the used physical model are consistent with those of the\nliterature relying on more abstract Rayleigh fading models, but offer further\ninsights on the relationship with channel characteristics. \n\n"}
{"id": "1804.07985", "contents": "Title: Capacity of Multiple One-Bit Transceivers in a Rayleigh Environment Abstract: We analyze the channel capacity of a system with a large number of one-bit\ntransceivers in a classical Rayleigh environment with perfect channel\ninformation at the receiver. With $M$ transmitters and $N=\\alpha M$ receivers,\nwe derive an expression of the capacity per transmitter $\\mathcal{C}$, where\n$\\mathcal{C}\\leq\\min(1,\\alpha)$, as a function of $\\alpha$ and signal-to-noise\nratio (SNR) $\\rho$, when $M\\to\\infty$. We show that our expression is a good\napproximation for small $M$, and provide simple approximations of $\\mathcal{C}$\nfor various ranges of $\\alpha$ and SNR $\\rho$. We conclude that at high SNR,\n$\\mathcal{C}$ reaches its upper limit of one only if the ratio $\\alpha>1.24$.\nExpressions for determining when $\\mathcal{C}$ \"saturates\" as a function of\n$\\alpha$ and $\\rho$ are given. \n\n"}
{"id": "1804.09016", "contents": "Title: Modular Arithmetic Erasure Channels and Their Multilevel Channel\n  Polarization Abstract: This study proposes \\emph{modular arithmetic erasure channels} (MAECs), a\nnovel class of erasure-like channels with an input alphabet that need not be\nbinary. This class contains the binary erasure channel (BEC) and some other\nknown erasure-like channels as special cases. For MAECs, we provide recursive\nformulas of Ar{\\i}kan-like polar transform to simulate channel polarization. In\nother words, we show that the synthetic channels of MAECs are equivalent to\nother MAECs. This is a generalization of well-known recursive formulas of the\npolar transform for BECs. Using our recursive formulas, we also show that a\nrecursive application of the polar transform for MAECs results in\n\\emph{multilevel channel polarization,} which is an asymptotic phenomenon that\nis characteristic of non-binary polar codes. Specifically, we establish a\nmethod to calculate the limiting proportions of the partially noiseless and\nnoisy channels that are generated as a result of multilevel channel\npolarization for MAECs. In the particular case of MAECs, this calculation\nmethod solves an open problem posed by Nasser (2017) in the study of non-binary\npolar codes. \n\n"}
{"id": "1804.09212", "contents": "Title: On the construction of sparse matrices from expander graphs Abstract: We revisit the asymptotic analysis of probabilistic construction of adjacency\nmatrices of expander graphs proposed in [4]. With better bounds we derived a\nnew reduced sample complexity for the number of nonzeros per column of these\nmatrices, precisely $d = \\mathcal{O}\\left(\\log_s(N/s) \\right)$; as opposed to\nthe standard $d = \\mathcal{O}\\left(\\log(N/s) \\right)$. This gives insights into\nwhy using small $d$ performed well in numerical experiments involving such\nmatrices. Furthermore, we derive quantitative sampling theorems for our\nconstructions which show our construction outperforming the existing\nstate-of-the-art. We also used our results to compare performance of sparse\nrecovery algorithms where these matrices are used for linear sketching. \n\n"}
{"id": "1804.10335", "contents": "Title: Communication, Computing and Caching for Mobile VR Delivery: Modeling\n  and Trade-off Abstract: Mobile virtual reality (VR) delivery is gaining increasing attention from\nboth industry and academia due to its ability to provide an immersive\nexperience. However, achieving mobile VR delivery requires ultra-high\ntransmission rate, deemed as a first killer application for 5G wireless\nnetworks. In this paper, in order to alleviate the traffic burden over wireless\nnetworks, we develop an implementation framework for mobile VR delivery by\nutilizing caching and computing capabilities of mobile VR device. We then\njointly optimize the caching and computation offloading policy for minimizing\nthe required average transmission rate under the latency and local average\nenergy consumption constraints. In a symmetric scenario, we obtain the optimal\njoint policy and the closed-form expression of the minimum average transmission\nrate. Accordingly, we analyze the tradeoff among communication, computing and\ncaching, and then reveal analytically the fact that the communication overhead\ncan be traded by the computing and caching capabilities of mobile VR device,\nand also what conditions must be met for it to happen. Finally, we discuss the\noptimization problem in a heterogeneous scenario, and propose an efficient\nsuboptimal algorithm with low computation complexity, which is shown to achieve\ngood performance in the numerical results. \n\n"}
{"id": "1804.11136", "contents": "Title: Proof of spending in block-chain systems Abstract: We introduce proof of spending in a block-chain system. In this system the\nprobability for a node to create a legal block is proportional to the total\namount of coins it has spent in history. \n\n"}
{"id": "1805.00225", "contents": "Title: Elevation Beamforming with Full Dimension MIMO Architectures in 5G\n  Systems: A Tutorial Abstract: Full dimension (FD) multiple-input multiple-output (MIMO) technology has\nattracted substantial research attention from both wireless industry and\nacademia in the last few years as a promising technique for next-generation\nwireless communication networks. FD-MIMO scenarios utilize a planar\ntwo-dimensional active antenna system (AAS) that not only allows a large number\nof antenna elements to be placed within feasible base station (BS) form\nfactors, but also provides the ability of adaptive electronic beam control over\nboth the elevation and the traditional azimuth dimensions. This paper presents\na tutorial on elevation beamforming analysis for cellular networks utilizing FD\nMassive MIMO antenna arrays. In contrast to existing works that focus on the\nstandardization of FD-MIMO in the 3rd Generation Partnership Project (3GPP),\nthis tutorial is distinguished by its depth with respect to the theoretical\naspects of antenna array and 3D channel modeling. In an attempt to bridge the\ngap between industry and academia, this preliminary tutorial introduces the\nrelevant array and transceiver architecture designs proposed in the 3GPP\nRelease 13 that enable elevation beamforming. Then it presents and compares two\ndifferent 3D channel modeling approaches that can be utilized for the\nperformance analysis of elevation beamforming techniques. The spatial\ncorrelation in FD-MIMO arrays is characterized and compared based on both\nchannel modeling approaches and some insights into the impact of different\nchannel and array parameters on the correlation are drawn. All these aspects\nare put together to provide a mathematical framework for the design of\nelevation beamforming schemes in single-cell and multi-cell scenarios.\nSimulation examples associated with comparisons and discussions are also\npresented. To this end, this paper highlights the state-of-the-art research and\npoints out future research directions. \n\n"}
{"id": "1805.00706", "contents": "Title: On the Structure of Interlinked Cycle Structures with Interlocked Outer\n  Cycles Abstract: For index coding problems with special structure on the side-information\ngraphs called Interlinked Cycle (IC) structures index codes have been proposed\nin the literature (C. Thapa, L. Ong, and S. Johnson, \"Interlinked Cycles for\nIndex Coding: Generalizing Cycles and Cliques\", in IEEE Trans. Inf. Theory,\nvol. 63, no. 6, Jun. 2017, with a correction in \"Interlinked Cycles for Index\nCoding: Generalizing Cycles and Cliques\", in arxiv (arxiv:1603.00092v2 [cs.IT]\n25 Feb 2018)). Recently (S. Sasi and B.S. Rajan, \"On Optimal Index Codes for\nInterlinked Cycle Structures with Outer Cycles,\" in arxiv (arXiv:1804.09120v1\n[cs.IT]), 24 Apr 2018) for a generalization of IC structures called IC\nstructures with interlocked outer cycles optimal length index codes have been\nreported and it is shown that the optimal length depends on the maximum number\nof disjoint outer cycles. In this paper we discuss certain structural\nproperties of IC structures with interlocked outer cycles and provide a simple\nalgorithm to find the maximum number of disjoint outer cycles. \n\n"}
{"id": "1805.03043", "contents": "Title: Binary Sparse Bayesian Learning Algorithm for One-bit Compressed Sensing Abstract: In this letter, a binary sparse Bayesian learning (BSBL) algorithm is\nproposed to slove the one-bit compressed sensing (CS) problem in both single\nmeasurement vector (SMV) and multiple measurement vectors (MMVs). By utilising\nthe Bussgang-like decomposition, the one-bit CS problem can be approximated as\na standard linear model. Consequently, the standard SBL algorithm can be\nnaturally incorporated. Numerical results demonstrate the effectiveness of the\nBSBL algorithm. \n\n"}
{"id": "1805.05069", "contents": "Title: A Two-stage Approach to Estimate CFO and Channel with One-bit ADCs Abstract: In this letter, we propose a two-stage approach to estimate the carrier\nfrequency offset (CFO) and channel with one-bit analog-to-digital converters\n(ADCs). Firstly, a simple metric which is only a function of the CFO is\nproposed, and the CFO is estimated via solving the one-dimensional optimization\nproblem. Secondly, the generalized approximate message passing (GAMP) algorithm\ncombined with expectation maximization (EM) method is utilized to estimate the\nchannel. In order to provide a benchmark of our proposed algorithm in terms of\nthe CFO estimation, the corresponding Cram\\'er-Rao bound (CRB) is derived.\nFurthermore, numerical results demonstrate the effectiveness of the proposed\napproach when applied to the general Gaussian channel and mmWave channel. \n\n"}
{"id": "1805.05929", "contents": "Title: Reinforcement Learning based Multi-Access Control and Battery Prediction\n  with Energy Harvesting in IoT Systems Abstract: Energy harvesting (EH) is a promising technique to fulfill the long-term and\nself-sustainable operations for Internet of things (IoT) systems. In this\npaper, we study the joint access control and battery prediction problems in a\nsmall-cell IoT system including multiple EH user equipments (UEs) and one base\nstation (BS) with limited uplink access channels. Each UE has a rechargeable\nbattery with finite capacity. The system control is modeled as a Markov\ndecision process without complete prior knowledge assumed at the BS, which also\ndeals with large sizes in both state and action spaces. First, to handle the\naccess control problem assuming causal battery and channel state information,\nwe propose a scheduling algorithm that maximizes the uplink transmission sum\nrate based on reinforcement learning (RL) with deep Q-network (DQN)\nenhancement. Second, for the battery prediction problem, with a fixed\nround-robin access control policy adopted, we develop a RL based algorithm to\nminimize the prediction loss (error) without any model knowledge about the\nenergy source and energy arrival process. Finally, the joint access control and\nbattery prediction problem is investigated, where we propose a two-layer RL\nnetwork to simultaneously deal with maximizing the sum rate and minimizing the\nprediction loss: the first layer is for battery prediction, the second layer\ngenerates the access policy based on the output from the first layer.\nExperiment results show that the three proposed RL algorithms can achieve\nbetter performances compared with existing benchmarks. \n\n"}
{"id": "1805.07022", "contents": "Title: Maximum Likelihood Upper Bounds on the Capacities of Discrete\n  Information Stable Channels Abstract: Motivated by a greedy approach for generating {\\it{information stable}}\nprocesses, we prove a universal maximum likelihood (ML) upper bound on the\ncapacities of discrete information stable channels, including the binary\nerasure channel (BEC), the binary symmetric channel (BSC) and the binary\ndeletion channel (BDC). The bound is derived leveraging a system of equations\nobtained via the Karush-Kuhn-Tucker conditions. Intriguingly, for some\nmemoryless channels, e.g., the BEC and BSC, the resulting upper bounds are\ntight and equal to their capacities. For the BDC, the universal upper bound is\nrelated to a function counting the number of possible ways that a length-$\\lo$\nbinary subsequence can be obtained by deleting $n-m$ bits (with $n-m$ close to\n$nd$ and $d$ denotes the {\\it{deletion probability}}) of a length-$n$ binary\nsequence. To get explicit upper bounds from the universal upper bound, it\nrequires to compute a maximization of the matching functions over a Hamming\ncube containing all length-$n$ binary sequences. Calculating the maximization\nexactly is hard. Instead, we provide a combinatorial formula approximating it.\nUnder certain assumptions, several approximations and an {\\it{explicit}} upper\nbound for deletion probability $d\\geq 1/2$ are derived. \n\n"}
{"id": "1805.07166", "contents": "Title: The Thermodynamics of Network Coding, and an Algorithmic Refinement of\n  the Principle of Maximum Entropy Abstract: The principle of maximum entropy (Maxent) is often used to obtain prior\nprobability distributions as a method to obtain a Gibbs measure under some\nrestriction giving the probability that a system will be in a certain state\ncompared to the rest of the elements in the distribution. Because classical\nentropy-based Maxent collapses cases confounding all distinct degrees of\nrandomness and pseudo-randomness, here we take into consideration the\ngenerative mechanism of the systems considered in the ensemble to separate\nobjects that may comply with the principle under some restriction and whose\nentropy is maximal but may be generated recursively from those that are\nactually algorithmically random offering a refinement to classical Maxent. We\ntake advantage of a causal algorithmic calculus to derive a thermodynamic-like\nresult based on how difficult it is to reprogram a computer code. Using the\ndistinction between computable and algorithmic randomness we quantify the cost\nin information loss associated with reprogramming. To illustrate this we apply\nthe algorithmic refinement to Maxent on graphs and introduce a Maximal\nAlgorithmic Randomness Preferential Attachment (MARPA) Algorithm, a\ngeneralisation over previous approaches. We discuss practical implications of\nevaluation of network randomness. Our analysis provides insight in that the\nreprogrammability asymmetry appears to originate from a non-monotonic\nrelationship to algorithmic probability. Our analysis motivates further\nanalysis of the origin and consequences of the aforementioned asymmetries,\nreprogrammability, and computation. \n\n"}
{"id": "1805.07776", "contents": "Title: Reducing Cubic Metric of Circularly Pulse-Shaped OFDM Signals Through\n  Constellation Shaping Optimization With Performance Constraints Abstract: Circularly pulse-shaped orthogonal frequency division multiplexing (CPS-OFDM)\nis one of the most promising 5G waveforms that addresses two physical layer\nsignal requirements of low out-of-subband emission (OSBE) and low\npeak-to-average power ratio (PAPR) with flexibility in parameter adaptation. In\nthis paper, a constellation shaping optimization method is proposed to further\nreduce the cubic metric (CM) of CPS-OFDM signals for the case that demands\nrather high power amplifier (PA) efficiency at the transmitter. Simulation\nresults demonstrate the superiority of the proposed scheme in CM reduction, and\nthe corresponding benefits of spectral regrowth mitigation and spectral\nefficiency improvement. \n\n"}
{"id": "1805.07784", "contents": "Title: Adaptive Recovery of Dictionary-sparse Signals using Binary Measurements Abstract: One-bit compressive sensing (CS) is an advanced version of sparse recovery in\nwhich the sparse signal of interest can be recovered from extremely quantized\nmeasurements. Namely, only the sign of each measurement is available to us. In\nmany applications, the ground-truth signal is not sparse itself, but can be\nrepresented in a redundant dictionary. A strong line of research has addressed\nconventional CS in this signal model including its extension to one-bit\nmeasurements. However, one-bit CS suffers from the extremely large number of\nrequired measurements to achieve a predefined reconstruction error level. A\ncommon alternative to resolve this issue is to exploit adaptive schemes.\nAdaptive sampling acts on the acquired samples to trace the signal in an\nefficient way. In this work, we utilize an adaptive sampling strategy to\nrecover dictionary-sparse signals from binary measurements. For this task, a\nmulti-dimensional threshold is proposed to incorporate the previous signal\nestimates into the current sampling procedure. This strategy substantially\nreduces the required number of measurements for exact recovery. Our proof\napproach is based on the recent tools in high dimensional geometry in\nparticular random hyperplane tessellation and Gaussian width. We show through\nrigorous and numerical analysis that the proposed algorithm considerably\noutperforms state of the art approaches. Further, our algorithm reaches an\nexponential error decay in terms of the number of quantized measurements. \n\n"}
{"id": "1805.08026", "contents": "Title: A Correlation Measure Based on Vector-Valued $L_p$-Norms Abstract: In this paper, we introduce a new measure of correlation for bipartite\nquantum states. This measure depends on a parameter $\\alpha$, and is defined in\nterms of vector-valued $L_p$-norms. The measure is within a constant of the\nexponential of $\\alpha$-R\\'enyi mutual information, and reduces to the trace\nnorm (total variation distance) for $\\alpha=1$. We will prove some decoupling\ntype theorems in terms of this measure of correlation, and present some\napplications in privacy amplification as well as in bounding the random coding\nexponents. In particular, we establish a bound on the secrecy exponent of the\nwiretap channel (under the total variation metric) in terms of the\n$\\alpha$-R\\'enyi mutual information according to \\emph{Csisz\\'ar's proposal}. \n\n"}
{"id": "1805.08342", "contents": "Title: Nearest neighbor density functional estimation from inverse Laplace\n  transform Abstract: A new approach to $L_2$-consistent estimation of a general density functional\nusing $k$-nearest neighbor distances is proposed, where the functional under\nconsideration is in the form of the expectation of some function $f$ of the\ndensities at each point. The estimator is designed to be asymptotically\nunbiased, using the convergence of the normalized volume of a $k$-nearest\nneighbor ball to a Gamma distribution in the large-sample limit, and naturally\ninvolves the inverse Laplace transform of a scaled version of the function $f.$\nSome instantiations of the proposed estimator recover existing $k$-nearest\nneighbor based estimators of Shannon and R\\'enyi entropies and\nKullback--Leibler and R\\'enyi divergences, and discover new consistent\nestimators for many other functionals such as logarithmic entropies and\ndivergences. The $L_2$-consistency of the proposed estimator is established for\na broad class of densities for general functionals, and the convergence rate in\nmean squared error is established as a function of the sample size for smooth,\nbounded densities. \n\n"}
{"id": "1805.08956", "contents": "Title: Hypergraph Spectral Clustering in the Weighted Stochastic Block Model Abstract: Spectral clustering is a celebrated algorithm that partitions objects based\non pairwise similarity information. While this approach has been successfully\napplied to a variety of domains, it comes with limitations. The reason is that\nthere are many other applications in which only \\emph{multi}-way similarity\nmeasures are available. This motivates us to explore the multi-way measurement\nsetting. In this work, we develop two algorithms intended for such setting:\nHypergraph Spectral Clustering (HSC) and Hypergraph Spectral Clustering with\nLocal Refinement (HSCLR). Our main contribution lies in performance analysis of\nthe poly-time algorithms under a random hypergraph model, which we name the\nweighted stochastic block model, in which objects and multi-way measures are\nmodeled as nodes and weights of hyperedges, respectively. Denoting by $n$ the\nnumber of nodes, our analysis reveals the following: (1) HSC outputs a\npartition which is better than a random guess if the sum of edge weights (to be\nexplained later) is $\\Omega(n)$; (2) HSC outputs a partition which coincides\nwith the hidden partition except for a vanishing fraction of nodes if the sum\nof edge weights is $\\omega(n)$; and (3) HSCLR exactly recovers the hidden\npartition if the sum of edge weights is on the order of $n \\log n$. Our results\nimprove upon the state of the arts recently established under the model and\nthey firstly settle the order-wise optimal results for the binary edge weight\ncase. Moreover, we show that our results lead to efficient sketching algorithms\nfor subspace clustering, a computer vision application. Lastly, we show that\nHSCLR achieves the information-theoretic limits for a special yet practically\nrelevant model, thereby showing no computational barrier for the case. \n\n"}
{"id": "1805.09409", "contents": "Title: Non-Gaussian Hyperplane Tessellations and Robust One-Bit Compressed\n  Sensing Abstract: We show that a tessellation generated by a small number of random affine\nhyperplanes can be used to approximate Euclidean distances between any two\npoints in an arbitrary bounded set $T$, where the random hyperplanes are\ngenerated by subgaussian or heavy-tailed normal vectors and uniformly\ndistributed shifts. We derive quantitative bounds on the number of hyperplanes\nneeded for constructing such tessellations in terms of natural metric\ncomplexity measures of $T$ and the desired approximation error. Our work\nextends significantly prior results in this direction, which were restricted to\nGaussian hyperplane tessellations of subsets of the Euclidean unit sphere.\n  As an application, we obtain new reconstruction results in memoryless one-bit\ncompressed sensing with non-Gaussian measurement matrices. We show that by\nquantizing at uniformly distributed thresholds, it is possible to accurately\nreconstruct low-complexity signals from a small number of one-bit quantized\nmeasurements, even if the measurement vectors are drawn from a heavy-tailed\ndistribution. Our reconstruction results are uniform in nature and robust in\nthe presence of pre-quantization noise on the analog measurements as well as\nadversarial bit corruptions in the quantization process. Moreover we show that\nif the measurement matrix is subgaussian then accurate recovery can be achieved\nvia a convex program. \n\n"}
{"id": "1805.09549", "contents": "Title: Finite Blocklength Communications in Smart Grids for Dynamic Spectrum\n  Access and Locally Licensed Scenarios Abstract: This work focuses on the performance analysis of short blocklength\ncommunication with application in smart grids. We use stochastic geometry to\ncompute in closed form the success probability of a typical message\ntransmission as a function of its size (i.e. blocklength), the number of\ninformation bits and the density of interferers. Two different scenarios are\ninvestigated: (i) dynamic spectrum access where the licensed and unlicensed\nusers, share the uplink channel frequency band and (ii) local licensing\napproach using the so called micro operator, which holds an exclusive license\nof its own. Approximated outage probability expression is derived for the\ndynamic spectrum access scenario, while a closed-form solution is attained for\nthe micro-operator. The analysis also incorporates the use of retransmissions\nwhen messages are detected in error. Our numerical results show how reliability\nand delay are related in either scenarios. \n\n"}
{"id": "1805.09871", "contents": "Title: Confidence Region of Singular Subspaces for Low-rank Matrix Regression Abstract: Low-rank matrix regression refers to the instances of recovering a low-rank\nmatrix based on specially designed measurements and the corresponding noisy\noutcomes. In the last decade, numerous statistical methodologies have been\ndeveloped for efficiently recovering the unknown low-rank matrices. However, in\nsome applications, the unknown singular subspace is scientifically more\nimportant than the low-rank matrix itself. In this article, we revisit the\nlow-rank matrix regression model and introduce a two-step procedure to\nconstruct confidence regions of the singular subspace. The procedure involves\nthe de-biasing for the typical low-rank estimators after which we calculate the\nempirical singular vectors. We investigate the distribution of the joint\nprojection distance between the empirical singular subspace and the unknown\ntrue singular subspace. We specifically prove the asymptotical normality of the\njoint projection distance with data-dependent centering and normalization when\n$r^{3/2}(m_1+m_2)^{3/2}=o(n/\\log n)$ where $m_1, m_2$ denote the matrix row and\ncolumn sizes, $r$ is the rank and $n$ is the number of independent random\nmeasurements. Consequently, we propose data-dependent confidence regions of the\ntrue singular subspace which attains any pre-determined confidence level\nasymptotically. In addition, non-asymptotical convergence rates are also\nestablished. Numerical results are presented to demonstrate the merits of our\nmethods. \n\n"}
{"id": "1805.10025", "contents": "Title: The Error Probability of Generalized Perfect Codes via the Meta-Converse Abstract: We introduce a definition of perfect and quasi-perfect codes for symmetric\nchannels parametrized by an auxiliary output distribution. This notion\ngeneralizes previous definitions of perfect and quasi-perfect codes and\nencompasses maximum distance separable codes. The error probability of these\ncodes, whenever they exist, is shown to coincide with the estimate provided by\nthe meta-converse lower bound. We illustrate how the proposed definition\nnaturally extends to cover almost-lossless source-channel coding and lossy\ncompression. \n\n"}
{"id": "1805.11748", "contents": "Title: Sublinear decoding schemes for non-adaptive group testing with\n  inhibitors Abstract: Identification of up to $d$ defective items and up to $h$ inhibitors in a set\nof $n$ items is the main task of non-adaptive group testing with inhibitors. To\nefficiently reduce the cost of this Herculean task, a subset of the $n$ items\nis formed and then tested. This is called \\textit{group testing}. A test\noutcome on a subset of items is positive if the subset contains at least one\ndefective item and no inhibitors, and negative otherwise. We present two\ndecoding schemes for efficiently identifying the defective items and the\ninhibitors in the presence of $e$ erroneous outcomes in time $\\mathsf{poly}(d,\nh, e, \\log_2{n})$, which is sublinear to the number of items $n$. This decoding\ncomplexity significantly improves the state-of-the-art schemes in which the\ndecoding time is linear to the number of items $n$, i.e., $\\mathsf{poly}(d, h,\ne, n)$. Moreover, each column of the measurement matrices associated with the\nproposed schemes can be nonrandomly generated in polynomial order of the number\nof rows. As a result, one can save space for storing them. Simulation results\nconfirm our theoretical analysis. When the number of items is sufficiently\nlarge, the decoding time in our proposed scheme is smallest in comparison with\nexisting work. In addition, when some erroneous outcomes are allowed, the\nnumber of tests in the proposed scheme is often smaller than the number of\ntests in existing work. \n\n"}
{"id": "1805.11915", "contents": "Title: Iterative Antenna Selection for Secrecy Enhancement in Massive MIMO\n  Wiretap Channels Abstract: The growth of interest in massive MIMO systems is accompanied with hardware\ncost and computational complexity. Antenna selection is an efficient approach\nto overcome this cost-plus-complexity issue which also enhances the secrecy\nperformance in wiretap settings. Optimal antenna selection requires exhaustive\nsearch which is computationally infeasible for settings with large dimensions.\nThis paper develops an iterative algorithm for antenna selection in massive\nmultiuser MIMO wiretap settings. The algorithm takes a stepwise approach to\nfind a suitable subset of transmit antennas. Numerical investigations depict a\nsignificant enhancement in the secrecy performance. \n\n"}
{"id": "1805.12345", "contents": "Title: Optimal cyclic $(r,\\delta)$ locally repairable codes with unbounded\n  length Abstract: Locally repairable codes with locality $r$ ($r$-LRCs for short) were\nintroduced by Gopalan et al. \\cite{1} to recover a failed node of the code from\nat most other $r$ available nodes. And then $(r,\\delta)$ locally repairable\ncodes ($(r,\\delta)$-LRCs for short) were produced by Prakash et al. \\cite{2}\nfor tolerating multiple failed nodes. An $r$-LRC can be viewed as an\n$(r,2)$-LRC. An $(r,\\delta)$-LRC is called optimal if it achieves the\nSingleton-type bound. It has been a great challenge to construct $q$-ary\noptimal $(r,\\delta)$-LRCs with length much larger than $q$. Surprisingly, Luo\net al. \\cite{3} presented a construction of $q$-ary optimal $r$-LRCs of minimum\ndistances 3 and 4 with unbounded lengths (i.e., lengths of these codes are\nindependent of $q$) via cyclic codes.\n  In this paper, inspired by the work of \\cite{3}, we firstly construct two\nclasses of optimal cyclic $(r,\\delta)$-LRCs with unbounded lengths and minimum\ndistances $\\delta+1$ or $\\delta+2$, which generalize the results about the\n$\\delta=2$ case given in \\cite{3}. Secondly, with a slightly stronger\ncondition, we present a construction of optimal cyclic $(r,\\delta)$-LRCs with\nunbounded length and larger minimum distance $2\\delta$. Furthermore, when\n$\\delta=3$, we give another class of optimal cyclic $(r,3)$-LRCs with unbounded\nlength and minimum distance $6$. \n\n"}
{"id": "1805.12542", "contents": "Title: Decoding Algorithms for Hypergraph Subsystem Codes and Generalized\n  Subsystem Surface Codes Abstract: Topological subsystem codes can combine the advantages of both topological\ncodes and subsystem codes. Suchara et al. proposed a framework based on\nhypergraphs for construction of such codes. They also studied the performance\nof some subsystem codes. Later Bravyi et al. proposed a subsystem surface code.\nBuilding upon these works, we propose efficient decoding algorithms for large\nclasses of subsystem codes on hypergraphs and surfaces. We also propose a\nconstruction of the subsystem surface codes that includes the code proposed by\nBravyi et al. Our simulations for the subsystem code on the square octagon\nlattice resulted in a noise threshold of 1.75%. This is comparable to previous\nresult of 2% by Bombin et al. who used a different algorithm. \n\n"}
{"id": "1806.01799", "contents": "Title: Survey and Taxonomy of Lossless Graph Compression and Space-Efficient\n  Graph Representations Abstract: Various graphs such as web or social networks may contain up to trillions of\nedges. Compressing such datasets can accelerate graph processing by reducing\nthe amount of I/O accesses and the pressure on the memory subsystem. Yet,\nselecting a proper compression method is challenging as there exist a plethora\nof techniques, algorithms, domains, and approaches in compressing graphs. To\nfacilitate this, we present a survey and taxonomy on lossless graph compression\nthat is the first, to the best of our knowledge, to exhaustively analyze this\ndomain. Moreover, our survey does not only categorize existing schemes, but\nalso explains key ideas, discusses formal underpinning in selected works, and\ndescribes the space of the existing compression schemes using three dimensions:\nareas of research (e.g., compressing web graphs), techniques (e.g., gap\nencoding), and features (e.g., whether or not a given scheme targets dynamic\ngraphs). Our survey can be used as a guide to select the best lossless\ncompression scheme in a given setting. \n\n"}
{"id": "1806.02197", "contents": "Title: Cache Placement in Two-Tier HetNets with Limited Storage Capacity: Cache\n  or Buffer? Abstract: In this paper, we aim to minimize the average file transmission delay via\nbandwidth allocation and cache placement in two-tier heterogeneous networks\nwith limited storage capacity, which consists of cache capacity and buffer\ncapacity. For average delay minimization problem with fixed bandwidth\nallocation, although this problem is nonconvex, the optimal solution is\nobtained in closed form by comparing all locally optimal solutions calculated\nfrom solving the Karush-Kuhn-Tucker conditions. To jointly optimize bandwidth\nallocation and cache placement, the optimal bandwidth allocation is first\nderived and then substituted into the original problem. The structure of the\noptimal caching strategy is presented, which shows that it is optimal to cache\nthe files with high popularity instead of the files with big size. Based on\nthis optimal structure, we propose an iterative algorithm with low complexity\nto obtain a suboptimal solution, where the closed-from expression is obtained\nin each step. Numerical results show the superiority of our solution compared\nto the conventional cache strategy without considering cache and buffer\ntradeoff in terms of delay. \n\n"}
{"id": "1806.03343", "contents": "Title: Resource Allocation for Low-Latency Vehicular Communications with Packet\n  Retransmission Abstract: Vehicular communications have stringent latency requirements on\nsafety-critical information transmission. However, lack of instantaneous\nchannel state information due to high mobility poses a great challenge to meet\nthese requirements and the situation gets more complicated when packet\nretransmission is considered. Based on only the obtainable large-scale fading\nchannel information, this paper performs spectrum and power allocation to\nmaximize the ergodic capacity of vehicular-to-infrastructure (V2I) links while\nguaranteeing the latency requirements of vehicular-to-vehicular (V2V) links.\nFirst, for each possible spectrum reusing pair of a V2I link and a V2V link, we\nobtain the closed-form expression of the packets' average sojourn time (the\nqueueing time plus the service time) for the V2V link. Then, an optimal power\nallocation is derived for each possible spectrum reusing pair. Afterwards, we\noptimize the spectrum reusing pattern by addressing a polynomial time solvable\nbipartite matching problem. Numerical results show that the proposed queueing\nanalysis is accurate in terms of the average packet sojourn time. Moreover, the\ndeveloped resource allocation always guarantees the V2V links' requirements on\nlatency. \n\n"}
{"id": "1806.04364", "contents": "Title: Downlink Analysis in Unmanned Aerial Vehicle (UAV) Assisted Cellular\n  Networks with Clustered Users Abstract: The use of unmanned aerial vehicles (UAVs) operating as aerial base stations\n(BSs) has emerged as a promising solution especially in scenarios requiring\nrapid deployments (e.g., in the cases of crowded hotspots, sporting events,\nemergencies, natural disasters) in order to assist the ground BSs. In this\npaper, an analytical framework is provided to analyze the\nsignal-to-interference-plus-noise ratio (SINR) coverage probability of unmanned\naerial vehicle (UAV) assisted cellular networks with clustered user equipments\n(UEs). Locations of UAVs and ground BSs are modeled as Poison point processes\n(PPPs), and UEs are assumed to be distributed according to a Poisson cluster\nprocess (PCP) around the projections of UAVs on the ground. Initially, the\ncomplementary cumulative distribution function (CCDF) and probability density\nfunction (PDF) of path losses for both UAV and ground BS tiers are derived.\nSubsequently, association probabilities with each tier are obtained. SINR\ncoverage probability is derived for the entire network using tools from\nstochastic geometry. Finally, area spectral efficiency (ASE) of the entire\nnetwork is determined, and SINR coverage probability expression for a more\ngeneral model is presented by considering that UAVs are located at different\nheights. Via numerical results, we have shown that UAV height and path-loss\nexponents play important roles on the coverage performance. Moreover, coverage\nprobability can be improved with smaller number of UAVs, while better area\nspectral efficiency is achieved by employing more UAVs and having UEs more\ncompactly clustered around the UAVs. \n\n"}
{"id": "1806.05712", "contents": "Title: Permutation polynomials and complete permutation polynomials over\n  $\\mathbb{F}_{q^{3}}$ Abstract: Motivated by many recent constructions of permutation polynomials over\n$\\mathbb{F}_{q^2}$, we study permutation polynomials over $\\mathbb{F}_{q^3}$ in\nterms of their coefficients. Based on the multivariate method and resultant\nelimination, we construct several new classes of sparse permutation polynomials\nover $\\mathbb{F}_{q^3}$, $q=p^{k}$, $p\\geq3$. Some of them are complete\nmappings. \n\n"}
{"id": "1806.06163", "contents": "Title: A Micro-Scale Mobile-Enabled Implantable Medical Sensor Abstract: Micro-scale implantable medical devices (IMDs) extend the immense benefits of\nsensors used in health management. However, their development is limited by\nmany requirements and challenges, such as the use of safe materials, size\nrestrictions, safe and efficient powering, and selection of suitable wireless\ncommunication technologies. Some of the proposed wireless communication\ntechnologies are the terahertz (THz) radio frequency (RF), and ultrasound. This\npaper investigates the use of {\\em magnetic induction-based backscatter\ncommunication} as an alternative technology. In particular, the goal is to\nprovide a practical design for a micro-scale IMD, referred to as a \"biomote\"\nhere, that can communicate with a wearable or handheld device such as a cell\nphone, tablet, or smart watch.First, it is demonstrated that communication via\nmagnetic induction can be established between a biomote and such an external\nreader. Then, low-power modulation and error-correction coding schemes that can\nbe implemented in micro-scale are explored for the mote. With the aim of\nincreasing reliability and accuracy of measurements through mass deployment of\nbiomotes, suitable low-power media access control (MAC) schemes are proposed,\nand the feasibility of their implementation in micro-scale is highlighted.\nNext, assuming that the human body is an additive white Gaussian noise (AWGN)\nchannel, the performance of the mote is simulated and analyzed. Results of this\nanalysis asserts that a communication range of at least few centimeters is\nachievable with an acceptable bit error rate. Finally, from the analysis of the\nMAC schemes, the optimum number of motes to be deployed for various read delays\nand transmission rates is obtained. \n\n"}
{"id": "1806.07800", "contents": "Title: Full Coded Caching Gains for Cache-less Users Abstract: Within the context of coded caching, the work reveals the interesting\nconnection between having multiple transmitters and having heterogeneity in the\ncache sizes of the receivers. Our work effectively shows that having multiple\ntransmit antennas -- while providing full multiplexing gains -- can also\nsimultaneously completely remove the performance penalties that are typically\nassociated to cache-size unevenness. Focusing on the multiple-input\nsingle-output Broadcast Channel, the work first identifies the performance\nlimits of the extreme case where cache-aided users coincide with users that do\nnot have caches, and then expands the analysis to the case where both user\ngroups are cache-aided but with heterogeneous cache-sizes. In the first case,\nthe main contribution is a new algorithm that employs perfect matchings on a\nbipartite graph to offer full multiplexing as well as full coded-caching gains\nto both cache-aided as well as cache-less users. An interesting conclusion is\nthat, starting from a single-stream centralized coded caching setting with\nnormalized cache size $\\gamma$, then adding $L$ antennas allows for the\naddition of {up to} approximately $L/\\gamma$ extra cache-less users, at no\nadded delay costs. Similarly surprising is the finding that, {beginning} with a\nsingle-antenna hybrid system (with both cache-less and cache-aided users), then\nadding {$L-1$} antennas to the transmitter, as well as endowing the cache-less\nusers with a cumulative normalized cache size $\\Gamma_2$, increases the Degrees\nof Freedom by a \\emph{multiplicative} factor of up to $\\Gamma_{2}+L$. \n\n"}
{"id": "1806.08968", "contents": "Title: A Modulo-Based Architecture for Analog-to-Digital Conversion Abstract: Systems that capture and process analog signals must first acquire them\nthrough an analog-to-digital converter. While subsequent digital processing can\nremove statistical correlations present in the acquired data, the dynamic range\nof the converter is typically scaled to match that of the input analog signal.\nThe present paper develops an approach for analog-to-digital conversion that\naims at minimizing the number of bits per sample at the output of the\nconverter. This is attained by reducing the dynamic range of the analog signal\nby performing a modulo operation on its amplitude, and then quantizing the\nresult. While the converter itself is universal and agnostic of the statistics\nof the signal, the decoder operation on the output of the quantizer can exploit\nthe statistical structure in order to unwrap the modulo folding. The\nperformance of this method is shown to approach information theoretical limits,\nas captured by the rate-distortion function, in various settings. An\narchitecture for modulo analog-to-digital conversion via ring oscillators is\nsuggested, and its merits are numerically demonstrated. \n\n"}
{"id": "1806.10333", "contents": "Title: A Generalized Data Representation and Training-Performance Analysis for\n  Deep Learning-Based Communications Systems Abstract: Deep learning (DL)-based autoencoder is a potential architecture to implement\nend-to-end communication systems. In this letter, we first give a brief\nintroduction to the autoencoder-represented communication system. Then, we\npropose a novel generalized data representation (GDR) aiming to improve the\ndata rate of DL-based communication systems. Finally, simulation results show\nthat the proposed GDR scheme has lower training complexity, comparable block\nerror rate performance and higher channel capacity than the conventional\none-hot vector scheme. Furthermore, we investigate the effect of\nsignal-to-noise ratio (SNR) in DL-based communication systems and prove that\ntraining at a high SNR could produce a good training performance for\nautoencoder. \n\n"}
{"id": "1806.10903", "contents": "Title: On Low-Complexity Decoding of Product Codes for High-Throughput\n  Fiber-Optic Systems Abstract: We study low-complexity iterative decoding algorithms for product codes. We\nrevisit two algorithms recently proposed by the authors based on bounded\ndistance decoding (BDD) of the component codes that improve the performance of\nconventional iterative BDD (iBDD). We then propose a novel decoding algorithm\nthat is based on generalized minimum distance decoding of the component codes.\nThe proposed algorithm closes over 50% of the performance gap between iBDD and\nturbo product decoding (TPD) based on the Chase-Pyndiah algorithm. Moreover,\nthe algorithm only leads to a limited increase in complexity with respect to\niBDD and has significantly lower complexity than TPD. The studied algorithms\nare particularly interesting for high-throughput fiber-optic communications. \n\n"}
{"id": "1806.11250", "contents": "Title: Energy Optimization for Cellular-Connected Multi-UAV Mobile Edge\n  Computing Systems with Multi-Access Schemes Abstract: In this paper, a cellular-connected unmanned aerial vehicles (UAV) mobile\nedge computing system is studied in which the multiple UAVs are served by\nterrestrial base station (TBS) for computation task offloading. Our goal is to\nminimize the total UAVs energy consumption, including propulsion energy,\ncomputation energy and communication energy, while ensuring that the total\nnumber of bits of UAVs are completely computed. For tackling the large amount\nof bits for computation, we propose a resource partitioning strategy where one\nportion of tasks is migrated to TBS for computation and the other portion of\ntasks is locally computed at UAV. For deeply comprehending the impacts of\naccess manners on the system performance, we consider four access schemes in\nthe uplink transmission, i.e., time division multiple access (TDMA), orthogonal\nfrequency division multiple access (OFDMA), One-by-One access and\nnon-orthogonal multiple access (NOMA). The problem of jointly optimizing bit\nallocation, power allocation, resource partitioning as well as UAV trajectory\nunder TBS's energy budget is formulated and tackled by means of successive\nconvex approximation (SCA) technique. The numerical results show that the\nproposed schemes save much energy compared with benchmark schemes. \n\n"}
{"id": "1807.00655", "contents": "Title: On the Tradeoff Between Accuracy and Complexity in Blind Detection of\n  Polar Codes Abstract: Polar codes are a recent family of error-correcting codes with a number of\ndesirable characteristics. Their disruptive nature is illustrated by their\nrapid adoption in the $5^{th}$-generation mobile-communication standard, where\nthey are used to protect control messages. In this work, we describe a\ntwo-stage system tasked with identifying the location of control messages that\nconsists of a detection and selection stage followed by a decoding one. The\nfirst stage spurs the need for polar-code detection algorithms with variable\neffort to balance complexity between the two stages. We illustrate this idea of\nvariable effort for multiple detection algorithms aimed at the first stage. We\npropose three novel blind detection methods based on belief-propagation\ndecoding inspired by early-stopping criteria. Then we show how their\nreliability improves with the number of decoding iterations to highlight the\npossible tradeoffs between accuracy and complexity. Additionally, we show\nsimilar tradeoffs for a detection method from previous work. In a setup where\nonly one block encoded with the polar code of interest is present among many\nother blocks, our results notably show that, depending on the complexity\nbudget, a variable number of undesirable blocks can be dismissed while\nachieving a missed-detection rate in line with the block-error rate of a\ncomplex decoding algorithm. \n\n"}
{"id": "1807.00682", "contents": "Title: Dynamic Power Allocation and User Scheduling for Power-Efficient and\n  Low-Latency Communications Abstract: In this paper, we propose a joint dynamic power control and user pairing\nalgorithm for power-efficient and low-latency hybrid multiple access systems.\nIn a hybrid multiple access system, user pairing determines whether the\ntransmitter should serve a certain user by orthogonal multiple access (OMA) or\nnon-orthogonal multiple access (NOMA). The proposed optimization framework\nminimizes the long-term time-average transmit power expenditure while reducing\nthe queueing delay and satisfying time-average data rate requirements. The\nproposed technique observes channel and queue state information and adjusts\nqueue backlogs to avoid an excessive queueing delay by appropriate user pairing\nand power allocation. Further, user scheduling for determining the activation\nof a given user link as well as flexible use of resources are captured in the\nproposed algorithm. Data-intensive simulation results show that the proposed\nscheme guarantees an end-to-end delay smaller than 1 ms with high\npower-efficiency and high reliability, based on the short frame structure\ndesigned for ultra-reliable low-latency communications (URLLC). \n\n"}
{"id": "1807.01251", "contents": "Title: Training behavior of deep neural network in frequency domain Abstract: Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization. \n\n"}
{"id": "1807.01747", "contents": "Title: Shannon entropy for intuitionistic fuzzy information Abstract: The paper presents an extension of Shannon fuzzy entropy for intuitionistic\nfuzzy one. Firstly, we presented a new formula for calculating the distance and\nsimilarity of intuitionistic fuzzy information. Then, we constructed measures\nfor information features like score, certainty and uncertainty. Also, a new\nconcept was introduced, namely escort fuzzy information. Then, using the escort\nfuzzy information, Shannon's formula for intuitionistic fuzzy information was\nobtained. It should be underlined that Shannon's entropy for intuitionistic\nfuzzy information verifies the four defining conditions of intuitionistic fuzzy\nuncertainty. The measures of its two components were also identified: fuzziness\n(ambiguity) and incompleteness (ignorance). \n\n"}
{"id": "1807.02494", "contents": "Title: Joint Channel-Estimation/Decoding with Frequency-Selective Channels and\n  Few-Bit ADCs Abstract: We propose a fast and near-optimal approach to joint channel-estimation,\nequalization, and decoding of coded single-carrier (SC) transmissions over\nfrequency-selective channels with few-bit analog-to-digital converters (ADCs).\nOur approach leverages parametric bilinear generalized approximate message\npassing (PBiGAMP) to reduce the implementation complexity of joint channel\nestimation and (soft) symbol decoding to that of a few fast Fourier transforms\n(FFTs). Furthermore, it learns and exploits sparsity in the channel impulse\nresponse. Our work is motivated by millimeter-wave systems with bandwidths on\nthe order of Gsamples/sec, where few-bit ADCs, SC transmissions, and fast\nprocessing all lead to significant reductions in power consumption and\nimplementation cost. We numerically demonstrate our approach using signals and\nchannels generated according to the IEEE 802.11ad wireless local area network\n(LAN) standard, in the case that the receiver uses analog beamforming and a\nsingle ADC. \n\n"}
{"id": "1807.04851", "contents": "Title: A New Millimeter Wave MIMO System for 5G Networks Abstract: Millimeter Wave (mmWave) band provides a large spectrum to meet the\nhigh-demand capacity by the 5th generation (5G) wireless networks. However, to\nfully exploit the available spectrum, obstacles such as high path loss, channel\nsparsity, and hardware complexity should be overcome. To this end, the present\npaper aims to design a new multiple-input multiple-output (MIMO) system using\nlens-based multi-beam reconfigurable antennas. The proposed MIMO system uses\ncomplete lens at the transmitter and incomplete lens at the receiver. To reduce\nhardware complexity, we utilize an optimal beam selection technique. Our\nanalysis demonstrates that the proposed MIMO system along with the optimal beam\nselection technique increases the average signal-to-noise ratio (SNR). Also,\nsimulations show that the system achieves full-diversity gain. \n\n"}
{"id": "1807.08127", "contents": "Title: Distributed Federated Learning for Ultra-Reliable Low-Latency Vehicular\n  Communications Abstract: In this paper, the problem of joint power and resource allocation (JPRA) for\nultra-reliable low-latency communication (URLLC) in vehicular networks is\nstudied. Therein, the network-wide power consumption of vehicular users (VUEs)\nis minimized subject to high reliability in terms of probabilistic queuing\ndelays. Using extreme value theory, a new reliability measure is defined to\ncharacterize extreme events pertaining to vehicles' queue lengths exceeding a\npredefined threshold. To learn these extreme events, assuming they are\nindependently and identically distributed over VUEs, a novel distributed\napproach based on federated learning (FL) is proposed to estimate the tail\ndistribution of the queue lengths. Considering the communication delays\nincurred by FL over wireless links, Lyapunov optimization is used to derive the\nJPRA policies enabling URLLC for each VUE in a distributed manner. The proposed\nsolution is then validated via extensive simulations using a Manhattan mobility\nmodel. Simulation results show that FL enables the proposed method to estimate\nthe tail distribution of queues with an accuracy that is close to a centralized\nsolution with up to 79% reductions in the amount of exchanged data.\nFurthermore, the proposed method yields up to 60% reductions of VUEs with large\nqueue lengths, while reducing the average power consumption by two folds,\ncompared to an average queue-based baseline. \n\n"}
{"id": "1807.08905", "contents": "Title: Pilot Spoofing Attack by Multiple Eavesdroppers Abstract: In this paper, we investigate the design of a pilot spoofing attack (PSA)\ncarried out by multiple single-antenna eavesdroppers (Eves) in a downlink\ntime-division duplex (TDD) system, where a multiple antenna base station (BS)\ntransmits confidential information to a single-antenna legitimate user (LU).\nDuring the uplink channel training phase, multiple Eves collaboratively impair\nthe channel acquisition of the legitimate link, aiming at maximizing the\nwiretapping signal-to-noise ratio (SNR) in the subsequent downlink data\ntransmission phase. Two different scenarios are investigated: (1) the BS is\nunaware of the PSA, and (2) the BS attempts to detect the presence of the PSA.\nFor both scenarios, we formulate wiretapping SNR maximization problems. For the\nsecond scenario, we also investigate the probability of successful detection\nand constrain it to remain below a pre-designed threshold. The two resulting\noptimization problems can be unified into a more general non-convex\noptimization problem, and we propose an efficient algorithm based on the\nminorization-maximization (MM) method and the alternating direction method of\nmultipliers (ADMM) to solve it. The proposed MM-ADMM algorithm is shown to\nconverge to a stationary point of the general problem. In addition, we propose\na semidefinite relaxation (SDR) method as a benchmark to evaluate the\nefficiency of the MM-ADMM algorithm. Numerical results show that the MM-ADMM\nalgorithm achieves near-optimal performance and is computationally more\nefficient than the SDRbased method. \n\n"}
{"id": "1807.09662", "contents": "Title: Game-Theoretic Optimization for Machine-Type Communications Under QoS\n  Guarantee Abstract: Massive machine-type communication (mMTC) is a new focus of services in fifth\ngeneration (5G) communication networks. The associated stringent delay\nrequirement of end-to-end (E2E) service deliveries poses technical challenges.\nIn this paper, we propose a joint random access and data transmission protocol\nfor mMTC to guarantee E2E service quality of different traffic types. First, we\ndevelop a priority-queueing-based access class barring (ACB) model and a novel\neffective capacity is derived. Then, we model the priority-queueing-based ACB\npolicy as a non-cooperative game, where utility is defined as the difference\nbetween effective capacity and access penalty price. We prove the existence and\nuniqueness of Nash equilibrium (NE) of the non-cooperative game, which is also\na sub-modular utility maximization problem and can be solved by a greedy\nupdating algorithm with convergence to the unique NE. To further improve the\nefficiency, we present a price-update algorithm, which converges to a local\noptimum. Simulations demonstrate the performance of the derived effective\ncapacity and the effectiveness of the proposed algorithms. \n\n"}
{"id": "1807.09908", "contents": "Title: On the Capacity of Single-Server Multi-Message Private Information\n  Retrieval with Side Information Abstract: We study Private Information Retrieval with Side Information (PIR-SI) in the\nsingle-server multi-message setting. In this setting, a user wants to download\n$D$ messages from a database of $K\\geq D$ messages, stored on a single server,\nwithout revealing any information about the identities of the demanded messages\nto the server. The goal of the user is to achieve information-theoretic privacy\nby leveraging the side information about the database. The side information\nconsists of a random subset of $M$ messages in the database which could have\nbeen obtained in advance from other users or from previous interactions with\nthe server. The identities of the messages forming the side information are\ninitially unknown to the server. Our goal is to characterize the capacity of\nthis setting, i.e., the maximum achievable download rate.\n  In our previous work, we have established the PIR-SI capacity for the special\ncase in which the user wants a single message, i.e., $D=1$ and showed that the\ncapacity can be achieved through the Partition and Code (PC) scheme. In this\npaper, we focus on the case when the user wants multiple messages, i.e., $D>1$.\nOur first result is that if the user wants more messages than what they have as\nside information, i.e., $D>M$, then the capacity is $\\frac{D}{K-M}$, and it can\nbe achieved using a scheme based on the Generalized Reed-Solomon (GRS) codes.\nIn this case, the user must learn all the messages in the database in order to\nobtain the desired messages. Our second result shows that this may not be\nnecessary when $D\\leq M$, and the capacity in this case can be higher. We\npresent a lower bound on the capacity based on an achievability scheme which we\ncall Generalized Partition and Code (GPC). \n\n"}
{"id": "1807.10459", "contents": "Title: IDTxl: The Information Dynamics Toolkit xl: a Python package for the\n  efficient analysis of multivariate information dynamics in networks Abstract: The Information Dynamics Toolkit xl (IDTxl) is a comprehensive software\npackage for efficient inference of networks and their node dynamics from\nmultivariate time series data using information theory. IDTxl provides\nfunctionality to estimate the following measures:\n  1) For network inference: multivariate transfer entropy (TE)/Granger\ncausality (GC), multivariate mutual information (MI), bivariate TE/GC,\nbivariate MI\n  2) For analysis of node dynamics: active information storage (AIS), partial\ninformation decomposition (PID)\n  IDTxl implements estimators for discrete and continuous data with parallel\ncomputing engines for both GPU and CPU platforms. Written for Python3.4.3+. \n\n"}
{"id": "1808.00519", "contents": "Title: Orthogonal Time Frequency Space Modulation Abstract: This paper introduces a new two-dimensional modulation technique called\nOrthogonal Time Frequency Space (OTFS) modulation. OTFS has the novel and\nimportant feature of being designed in the delay-Doppler domain. When coupled\nwith a suitable equalizer, OTFS modulation is able to exploit the full channel\ndiversity over both time and frequency. Moreover, it converts the fading,\ntime-varying wireless channel experienced by modulated signals such as OFDM\ninto a time-independent channel with a complex channel gain that is essentially\nconstant for all symbols.\n  This design obviates the need for transmitter adaptation, and greatly\nsimplifies system operation. The paper describes the basic operating principles\nof OTFS as well as a possible implementation as an overlay to current or\nanticipated standardized systems. OTFS is shown to provide significant\nperformance improvement in systems with high Doppler, short packets, and/or\nlarge antenna array. In particular, simulation results indicate at least\nseveral dB of block error rate performance improvement for OTFS over OFDM in\nall of these settings. \n\n"}
{"id": "1808.01700", "contents": "Title: Effective Resource Sharing in Mobile-Cell Environments Abstract: The mobile users on board vehicles often experience low quality of service\ndue to the vehicular penetration effect, especially at the cell edges. The\nso-called mobile-cells are installed inside public transport vehicles to serve\nthe commuters. On one end, the mobile-cells have a wireless backhaul connection\nwith the nearest base station, and on the other, they connect wirelessly to the\nin-vehicle users over access links. This paper integrates the mobile-cells\nwithin the cellular networks by reusing their sub-channels. Firstly, this paper\nproposes an algorithm that allows spectrum sharing for access-link with\nout-of-vehicle cellular users or MC's backhaul-links. Secondly, it proposes a\nscheme for controlling the transmit power over the access link to mitigate\ninterference to the backhaul-link, while maintaining high link quality for\nin-vehicle users. \n\n"}
{"id": "1808.01720", "contents": "Title: Energy-Age Tradeoff in Status Update Communication Systems with\n  Retransmission Abstract: Age-of-information is a novel performance metric in communication systems to\nindicate the freshness of the latest received data, which has wide applications\nin monitoring and control scenarios. Another important performance metric in\nthese applications is energy consumption, since monitors or sensors are usually\nenergy constrained. In this paper, we study the energy-age tradeoff in a status\nupdate system where data transmission from a source to a receiver may encounter\nfailure due to channel error. As the status sensing process consumes energy,\nwhen a transmission failure happens, the source may either retransmit the\nexisting data to save energy for sensing, or sense and transmit a new update to\nminimize age-of-information. A threshold-based retransmission policy is\nconsidered where each update is allowed to be transmitted no more than M times.\nClosed-form average age-of-information and energy consumption is derived and\nexpressed as a function of channel failure probability and maximum number of\nretransmissions M. Numerical simulations validate our analytical results, and\nillustrate the tradeoff between average age-of-information and energy\nconsumption. \n\n"}
{"id": "1808.01750", "contents": "Title: Beyond the Central Limit Theorem: Universal and Non-universal\n  Simulations of Random Variables by General Mappings Abstract: Motivated by the Central Limit Theorem, in this paper, we study both\nuniversal and non-universal simulations of random variables with an arbitrary\ntarget distribution $Q_{Y}$ by general mappings, not limited to linear ones (as\nin the Central Limit Theorem). We derive the fastest convergence rate of the\napproximation errors for such problems. Interestingly, we show that for\ndiscontinuous or absolutely continuous $P_{X}$, the approximation error for the\nuniversal simulation is almost as small as that for the non-universal one; and\nmoreover, for both universal and non-universal simulations, the approximation\nerrors by general mappings are strictly smaller than those by linear mappings.\nFurthermore, we also generalize these results to simulation from Markov\nprocesses, and simulation of random elements (or general random variables). \n\n"}
{"id": "1808.02477", "contents": "Title: Coded Caching in the Presence of a Wire and a Cache Tapping Adversary of\n  Type II Abstract: This paper introduces the notion of cache-tapping into the information\ntheoretic models of coded caching. The wiretap channel II in the presence of\nmultiple receivers equipped with fixed-size cache memories, and an adversary\nwhich selects symbols to tap into from cache placement and/or delivery is\nintroduced. The legitimate terminals know neither whether placement, delivery,\nor both are tapped, nor the positions in which they are tapped. Only the size\nof the overall tapped set is known. For two receivers and two files, the strong\nsecrecy capacity -- the maximum achievable file rate while keeping the overall\nlibrary strongly secure -- is identified. Lower and upper bounds on the strong\nsecrecy file rate are derived when the library has more than two files.\nAchievability relies on a code design which combines wiretap coding, security\nembedding codes, one-time pad keys, and coded caching. A genie-aided upper\nbound, in which the transmitter is provided with user demands before placement,\nestablishes the converse for the two-files case. For more than two files, the\nupper bound is constructed by three successive channel transformations. Our\nresults establish provable security guarantees against a powerful adversary\nwhich optimizes its tapping over both phases of communication in a cache-aided\nsystem. \n\n"}
{"id": "1808.02780", "contents": "Title: Cache Aided Communications with Multiple Antennas at Finite SNR Abstract: We study the problem of cache-aided communication for cellular networks with\nmulti-user and multiple antennas at finite signal-to-noise ratio. Users are\nassumed to have non-symmetric links, modeled by wideband fading channels. We\nshow that the problem can be formulated as a linear program, whose solution\nprovides a joint cache allocation along with pre-fetching and fetching schemes\nthat minimize the duration of the communication in the delivery phase. The\nsuggested scheme uses zero-forcing and cached interference subtraction and\nhence allow each user to be served at the rate of its own channel. Thus, this\nscheme is better than the previously published schemes that are compromised by\nthe poorest user in the communication group. We also consider a special case of\nthe parameters for which we can derive a closed form solution and formulate the\noptimal power, rate and cache optimization. This special case shows that the\ngain of MIMO coded caching goes beyond the throughput. In particular, it is\nshown that in this case, the cache is used to balance the users such that\nfairness and throughput are no longer contradicting. More specifically, in this\ncase, strict fairness is achieved jointly with maximizing the network\nthroughput. \n\n"}
{"id": "1808.03074", "contents": "Title: Necessary Field Size and Probability for MDP and Complete MDP\n  Convolutional Codes Abstract: It has been shown that maximum distance profile (MDP) convolutional codes\nhave optimal recovery rate for windows of a certain length, when transmitting\nover an erasure channel. In addition, the subclass of complete MDP\nconvolutional codes has the ability to reduce the waiting time during decoding.\nIn this paper, we derive upper bounds on the necessary field size for the\nexistence of MDP and complete MDP convolutional codes and show that these\nbounds improve the already existing ones. Moreover, we derive lower bounds for\nthe probability that a random code is MDP respective complete MDP. \n\n"}
{"id": "1808.03821", "contents": "Title: Constant overhead quantum fault-tolerance with quantum expander codes Abstract: We prove that quantum expander codes can be combined with quantum\nfault-tolerance techniques to achieve constant overhead: the ratio between the\ntotal number of physical qubits required for a quantum computation with faulty\nhardware and the number of logical qubits involved in the ideal computation is\nasymptotically constant, and can even be taken arbitrarily close to 1 in the\nlimit of small physical error rate. This improves on the polylogarithmic\noverhead promised by the standard threshold theorem.\n  To achieve this, we exploit a framework introduced by Gottesman together with\na family of constant rate quantum codes, quantum expander codes. Our main\ntechnical contribution is to analyze an efficient decoding algorithm for these\ncodes and prove that it remains robust in the presence of noisy syndrome\nmeasurements, a property which is crucial for fault-tolerant circuits. We also\nestablish two additional features of the decoding algorithm that make it\nattractive for quantum computation: it can be parallelized to run in\nlogarithmic depth, and is single-shot, meaning that it only requires a single\nround of noisy syndrome measurement. \n\n"}
{"id": "1808.03880", "contents": "Title: Parallelization does not Accelerate Convex Optimization: Adaptivity\n  Lower Bounds for Non-smooth Convex Minimization Abstract: In this paper we study the limitations of parallelization in convex\noptimization. A convenient approach to study parallelization is through the\nprism of \\emph{adaptivity} which is an information theoretic measure of the\nparallel runtime of an algorithm [BS18]. Informally, adaptivity is the number\nof sequential rounds an algorithm needs to make when it can execute\npolynomially-many queries in parallel at every round. For combinatorial\noptimization with black-box oracle access, the study of adaptivity has recently\nled to exponential accelerations in parallel runtime and the natural question\nis whether dramatic accelerations are achievable for convex optimization.\n  For the problem of minimizing a non-smooth convex function $f:[0,1]^n\\to\n\\mathbb{R}$ over the unit Euclidean ball, we give a tight lower bound that\nshows that even when $\\texttt{poly}(n)$ queries can be executed in parallel,\nthere is no randomized algorithm with $\\tilde{o}(n^{1/3})$ rounds of adaptivity\nthat has convergence rate that is better than those achievable with a\none-query-per-round algorithm. A similar lower bound was obtained by Nemirovski\n[Nem94], however that result holds for the $\\ell_{\\infty}$-setting instead of\n$\\ell_2$. In addition, we also show a tight lower bound that holds for\nLipschitz and strongly convex functions.\n  At the time of writing this manuscript we were not aware of Nemirovski's\nresult. The construction we use is similar to the one in [Nem94], though our\nanalysis is different. Due to the close relationship between this work and\n[Nem94], we view the research contribution of this manuscript limited and it\nshould serve as an instructful approach to understanding lower bounds for\nparallel optimization. \n\n"}
{"id": "1808.04618", "contents": "Title: On Robustness of Massive MIMO Systems Against Passive Eavesdropping\n  under Antenna Selection Abstract: In massive MIMO wiretap settings, the base station can significantly suppress\neavesdroppers by narrow beamforming toward legitimate terminals. Numerical\ninvestigations show that by this approach, secrecy is obtained at no\nsignificant cost. We call this property of massive MIMO systems `secrecy for\nfree' and show that it not only holds when all the transmit antennas at the\nbase station are employed, but also when only a single antenna is set active.\nUsing linear precoding, the information leakage to the eavesdroppers can be\nsufficiently diminished, when the total number of available transmit antennas\nat the base station grows large, even when only a fixed number of them are\nselected. This result indicates that passive eavesdropping has no significant\nimpact on massive MIMO systems, regardless of the number of active transmit\nantennas. \n\n"}
{"id": "1808.05797", "contents": "Title: Single-Server Multi-Message Private Information Retrieval with Side\n  Information Abstract: We study the problem of single-server multi-message private information\nretrieval with side information. One user wants to recover $N$ out of $K$\nindependent messages which are stored at a single server. The user initially\npossesses a subset of $M$ messages as side information. The goal of the user is\nto download the $N$ demand messages while not leaking any information about the\nindices of these messages to the server. In this paper, we characterize the\nminimum number of required transmissions. We also present the optimal linear\ncoding scheme which enables the user to download the demand messages and\npreserves the privacy of their indices. Moreover, we show that the trivial MDS\ncoding scheme with $K-M$ transmissions is optimal if $N>M$ or $N^2+N \\ge K-M$.\nThis means if one wishes to privately download more than the square-root of the\nnumber of files in the database, then one must effectively download the full\ndatabase (minus the side information), irrespective of the amount of side\ninformation one has available. \n\n"}
{"id": "1808.06190", "contents": "Title: Non-Asymptotic Fundamental Limits of Guessing Subject to Distortion Abstract: This paper investigates the problem of guessing subject to distortion, which\nwas introduced by Arikan and Merhav. While the primary concern of the previous\nstudy was asymptotic analysis, our primary concern is non-asymptotic analysis.\nWe prove non-asymptotic achievability and converse bounds of the moment of the\nnumber of guesses without side information (resp. with side information) by\nusing a quantity based on the R\\'enyi entropy (resp. the Arimoto-R\\'enyi\nconditional entropy). Also, we introduce an error probability and show similar\nresults. Further, from our bounds, we derive a single-letter characterization\nof the asymptotic exponent of guessing moment for a stationary memoryless\nsource. \n\n"}
{"id": "1808.07732", "contents": "Title: An Exact Upper Bound on the $L^p$ Lebesgue Constant and The\n  $\\infty$-R\\'enyi Entropy Power Inequality for Integer Valued Random Variables Abstract: In this paper, we proved an exact asymptotically sharp upper bound of the\n$L^p$ Lebesgue Constant (i.e. the $L^p$ norm of Dirichlet kernel) for $p\\ge 2$.\nAs an application, we also verified the implication of a new $\\infty $-R\\'enyi\nentropy power inequality for integer valued random variables. \n\n"}
{"id": "1808.08520", "contents": "Title: No lattice tiling of $\\mathbb{Z}^n$ by Lee Sphere of radius 2 Abstract: We prove the nonexistence of lattice tilings of $\\mathbb{Z}^n$ by Lee spheres\nof radius $2$ for all dimensions $n\\geq 3$. This implies that the Golomb-Welch\nconjecture is true when the common radius of the Lee spheres equals $2$ and\n$2n^2+2n+1$ is a prime. As a direct consequence, we also answer an open\nquestion in the degree-diameter problem of graph theory: the order of any\nabelian Cayley graph of diameter $2$ and degree larger than $5$ cannot meet the\nabelian Cayley Moore bound. \n\n"}
{"id": "1809.00872", "contents": "Title: Private Information Retrieval From a Cellular Network With Caching at\n  the Edge Abstract: We consider the problem of downloading content from a cellular network where\ncontent is cached at the wireless edge while achieving privacy. In particular,\nwe consider private information retrieval (PIR) of content from a library of\nfiles, i.e., the user wishes to download a file and does not want the network\nto learn any information about which file she is interested in. To reduce the\nbackhaul usage, content is cached at the wireless edge in a number of\nsmall-cell base stations (SBSs) using maximum distance separable codes. We\npropose a PIR scheme for this scenario that achieves privacy against a number\nof spy SBSs that (possibly) collaborate. The proposed PIR scheme is an\nextension of a recently introduced scheme by Kumar et al. to the case of\nmultiple code rates, suitable for the scenario where files have different\npopularities. We then derive the backhaul rate and optimize the content\nplacement to minimize it. We prove that uniform content placement is optimal,\ni.e., all files that are cached should be stored using the same code rate. This\nis in contrast to the case where no PIR is required. Furthermore, we show\nnumerically that popular content placement is optimal for some scenarios. \n\n"}
{"id": "1809.03005", "contents": "Title: Distribution-aware Block-sparse Recovery via Convex Optimization Abstract: We study the problem of reconstructing a block-sparse signal from\ncompressively sampled measurements. In certain applications, in addition to the\ninherent block-sparse structure of the signal, some prior information about the\nblock support, i.e. blocks containing non-zero elements, might be available.\nAlthough many block-sparse recovery algorithms have been investigated in\nBayesian framework, it is still unclear how to incorporate the information\nabout the probability of occurrence into regularization-based block-sparse\nrecovery in an optimal sense. In this work, we bridge between these fields by\nthe aid of a new concept in conic integral geometry. Specifically, we solve a\nweighted optimization problem when the prior distribution about the block\nsupport is available. Moreover, we obtain the unique weights that minimize the\nexpected required number of measurements. Our simulations on both synthetic and\nreal data confirm that these weights considerably decrease the required sample\ncomplexity. \n\n"}
{"id": "1809.06648", "contents": "Title: Local Reconstruction Codes: A Class of MDS-PIR Capacity-Achieving Codes Abstract: We prove that a class of distance-optimal local reconstruction codes (LRCs),\nan important family of repair-efficient codes for distributed storage systems,\nachieve the maximum distance separable private information retrieval capacity\nfor the case of noncolluding nodes. This particular class of codes includes\nPyramid codes and other LRCs proposed in the literature. \n\n"}
{"id": "1809.08116", "contents": "Title: On the Optimal Broadcast Rate of the Two-Sender Unicast Index Coding\n  Problem with Fully-Participated Interactions Abstract: The problem of two-sender unicast index coding consists of two senders and a\nset of receivers. Each receiver demands a unique message and possesses some of\nthe messages demanded by other receivers as its side-information. Every\ndemanded message is present with at least one of the senders. Senders avail the\nknowledge of the side-information at the receivers to reduce the number of\nbroadcast transmissions. Solution to this problem consists of finding the\noptimal number of coded transmissions from the two senders. One important class\nof the two-sender problem consists of the messages at the senders and the\nside-information at the receivers satisfying \\emph{fully-participated\ninteractions}. This paper provides the optimal broadcast rates, for all the\nunsolved cases of the two-sender problem with fully-participated interactions\nwhen the associated \\emph{interaction digraphs} contain cycles. The optimal\nbroadcast rates are provided in terms of those of the three independent\nsingle-sender problems associated with the two-sender problem. This paper also\nprovides an achievable broadcast rate with $t$-bit messages for any finite $t$\nand any two-sender problem with fully-participated interactions belonging to\n$(i)$ any one of the six instances (classes) of the two-sender problem when the\nassociated interaction digraph does not contain any cycle, and $(ii)$ one of\nthe classes of the two-sender problem when the associated interaction digraph\ncontains cycles. The achievable broadcast rates are obtained by exploiting the\nsymmetries of the confusion graph to color the same according to the two-sender\ngraph coloring. \n\n"}
{"id": "1809.10677", "contents": "Title: Optimal Multicast of Tiled 360 VR Video in OFDMA Systems Abstract: In this letter, we study optimal multicast of tiled 360 virtual reality (VR)\nvideo from one server (base station or access point) to multiple users in an\northogonal frequency division multiple access (OFDMA) system. For given video\nquality, we optimize the subcarrier, transmission power and transmission rate\nallocation to minimize the total transmission power. For given transmission\npower budget, we optimize the subcarrier, transmission power and transmission\nrate allocation to maximize the received video quality. These two optimization\nproblems are non-convex problems. We obtain a globally optimal closed-form\nsolution and a near optimal solution of the two problems, separately, both\nrevealing important design insights for multicast of tiled 360 VR video in\nOFDMA systems. \n\n"}
{"id": "1810.06475", "contents": "Title: Caching in Heterogeneous Networks with Per-File Rate Constraints Abstract: We study the problem of caching optimization in heterogeneous networks with\nmutual interference and per-file rate constraints from an energy efficiency\nperspective. A setup is considered in which two cache-enabled transmitter nodes\nand a coordinator node serve two users.\n  We analyse and compare two approaches: (i) a cooperative approach where each\nof the transmitters might serve either of the users and (ii) a non-cooperative\napproach in which each transmitter serves only the respective user. We\nformulate the cache allocation optimization problem so that the overall system\npower consumption is minimized while the use of the link from the master node\nto the end users is spared whenever possible. We also propose a low-complexity\noptimization algorithm and show that it outperforms the considered benchmark\nstrategies.\n  Our results indicate that significant gains both in terms of power saving and\nsparing of master node's resources can be obtained when full cooperation\nbetween the transmitters is in place. Interestingly, we show that in some cases\nstoring the most popular files is not the best solution from a power efficiency\nperspective. \n\n"}
{"id": "1810.07014", "contents": "Title: Bregman Divergence Bounds and Universality Properties of the Logarithmic\n  Loss Abstract: A loss function measures the discrepancy between the true values and their\nestimated fits, for a given instance of data. In classification problems, a\nloss function is said to be proper if a minimizer of the expected loss is the\ntrue underlying probability. We show that for binary classification, the\ndivergence associated with smooth, proper, and convex loss functions is upper\nbounded by the Kullback-Leibler (KL) divergence, to within a normalization\nconstant. This implies that by minimizing the logarithmic loss associated with\nthe KL divergence, we minimize an upper bound to any choice of loss from this\nset. As such the logarithmic loss is universal in the sense of providing\nperformance guarantees with respect to a broad class of accuracy measures.\nImportantly, this notion of universality is not problem-specific, enabling its\nuse in diverse applications, including predictive modeling, data clustering and\nsample complexity analysis. Generalizations to arbitrary finite alphabets are\nalso developed. The derived inequalities extend several well-known\n$f$-divergence results. \n\n"}
{"id": "1810.07281", "contents": "Title: List Decoding of Deletions Using Guess & Check Codes Abstract: Guess & Check (GC) codes are systematic binary codes that can correct\nmultiple deletions, with high probability. GC codes have logarithmic redundancy\nin the length of the message $k$, and the encoding and decoding algorithms of\nthese codes are deterministic and run in polynomial time for a constant number\nof deletions $\\delta$. The unique decoding properties of GC codes were examined\nin a previous work by the authors. In this paper, we investigate the list\ndecoding performance of these codes. Namely, we study the average size and the\nmaximum size of the list obtained by a GC decoder for a constant number of\ndeletions $\\delta$. The theoretical results show that: (i) the average size of\nthe list approaches $1$ as $k$ grows; and (ii) there exists an infinite\nsequence of GC codes indexed by $k$, whose maximum list size in upper bounded\nby a constant that is independent of $k$. We also provide numerical simulations\non the list decoding performance of GC codes for multiple values of $k$ and\n$\\delta$. \n\n"}
{"id": "1810.09070", "contents": "Title: On the Conditional Smooth Renyi Entropy and its Applications in Guessing\n  and Source Coding Abstract: A novel definition of the conditional smooth Renyi entropy, which is\ndifferent from that of Renner and Wolf, is introduced. It is shown that our\ndefinition of the conditional smooth Renyi entropy is appropriate to give lower\nand upper bounds on the optimal guessing moment in a guessing problem where the\nguesser is allowed to stop guessing and declare an error. Further a general\nformula for the optimal guessing exponent is given. In particular, a\nsingle-letterized formula for mixture of i.i.d. sources is obtained. Another\napplication in the problem of source coding with the common side-information\navailable at the encoder and decoder is also demonstrated. \n\n"}
{"id": "1811.01745", "contents": "Title: Unique Information and Secret Key Agreement Abstract: The partial information decomposition (PID) is a promising framework for\ndecomposing a joint random variable into the amount of influence each source\nvariable Xi has on a target variable Y, relative to the other sources. For two\nsources, influence breaks down into the information that both X0 and X1\nredundantly share with Y, what X0 uniquely shares with Y, what X1 uniquely\nshares with Y, and finally what X0 and X1 synergistically share with Y.\nUnfortunately, considerable disagreement has arisen as to how these four\ncomponents should be quantified. Drawing from cryptography, we consider the\nsecret key agreement rate as an operational method of quantifying unique\ninformations. Secret key agreement rate comes in several forms, depending upon\nwhich parties are permitted to communicate. We demonstrate that three of these\nfour forms are inconsistent with the PID. The remaining form implies certain\ninterpretations as to the PID's meaning---interpretations not present in PID's\ndefinition but that, we argue, need to be explicit. These reveal an\ninconsistency between third-order connected information, two-way secret key\nagreement rate, and synergy. Similar difficulties arise with a popular PID\nmeasure in light the results here as well as from a maximum entropy viewpoint.\nWe close by reviewing the challenges facing the PID. \n\n"}
{"id": "1811.03220", "contents": "Title: Secrecy Outage Analysis for Cooperative NOMA Systems with Relay\n  Selection Scheme Abstract: This paper considers the secrecy outage performance of a multiple-relay\nassisted non-orthogonal multiple access (NOMA) network over Nakagami-$m$ fading\nchannels. Two slots are utilized to transmit signals from the base station to\ndestination. At the first slot, the base station broadcasts the superposition\nsignal of the two users to all decode-and-forward relays by message mapping\nstrategy. Then the selected relay transmits superposition signal to the two\nusers via power-domain NOMA technology. Three relay selection (RS) schemes,\ni.e., optimal single relay selection (OSRS) scheme, two-step single relay\nselection (TSRS) scheme, and optimal dual relay selection (ODRS) scheme, are\nproposed and the secrecy outage performance are analyzed. As a benchmark, we\nalso examine the secrecy outage performance of the NOMA systems with\ntraditional multiple relays combining (TMRC) scheme in which all the relay that\nsuccessfully decode signals from the source forward signals to the NOMA users\nwith equal power. Considering the correlation between the secrecy capacity of\ntwo users and different secrecy requirement for two NOMA users, the closed-form\nexpressions for the security outage probability (SOP) of the proposed OSRS,\nTSRS, and ODRS schemes along with the TMRC scheme are derived and validated via\nsimulations. To get more insights, we also derive the closed-form expressions\nfor the asymptotic SOP for all the schemes with fixed and dynamic power\nallocations. Furthermore, the secrecy diversity order (SDO) of cooperative NOMA\nsystems is obtained. The results demonstrate that our proposed schemes can\nsignificantly enhance the secrecy performance compared to the TMRC scheme and\nthat all the RS schemes with fixed power allocation obtain zero SDO and the\nOSRS scheme with dynamic power allocation obtains the same SDO as TMRC. \n\n"}
{"id": "1811.03946", "contents": "Title: Broadcasting on Random Directed Acyclic Graphs Abstract: We study a generalization of the well-known model of broadcasting on trees.\nConsider a directed acyclic graph (DAG) with a unique source vertex $X$, and\nsuppose all other vertices have indegree $d\\geq 2$. Let the vertices at\ndistance $k$ from $X$ be called layer $k$. At layer $0$, $X$ is given a random\nbit. At layer $k\\geq 1$, each vertex receives $d$ bits from its parents in\nlayer $k-1$, which are transmitted along independent binary symmetric channel\nedges, and combines them using a $d$-ary Boolean processing function. The goal\nis to reconstruct $X$ with probability of error bounded away from $1/2$ using\nthe values of all vertices at an arbitrarily deep layer. This question is\nclosely related to models of reliable computation and storage, and information\nflow in biological networks.\n  In this paper, we analyze randomly constructed DAGs, for which we show that\nbroadcasting is only possible if the noise level is below a certain degree and\nfunction dependent critical threshold. For $d\\geq 3$, and random DAGs with\nlayer sizes $\\Omega(\\log k)$ and majority processing functions, we identify the\ncritical threshold. For $d=2$, we establish a similar result for NAND\nprocessing functions. We also prove a partial converse for odd $d\\geq 3$\nillustrating that the identified thresholds are impossible to improve by\nselecting different processing functions if the decoder is restricted to using\na single vertex.\n  Finally, for any noise level, we construct explicit DAGs (using expander\ngraphs) with bounded degree and layer sizes $\\Theta(\\log k)$ admitting\nreconstruction. In particular, we show that such DAGs can be generated in\ndeterministic quasi-polynomial time or randomized polylogarithmic time in the\ndepth. These results portray a doubly-exponential advantage for storing a bit\nin DAGs compared to trees, where $d=1$ but layer sizes must grow exponentially\nwith depth in order to enable broadcasting. \n\n"}
{"id": "1811.06057", "contents": "Title: On the Robustness of Information-Theoretic Privacy Measures and\n  Mechanisms Abstract: Consider a data publishing setting for a dataset composed by both private and\nnon-private features. The publisher uses an empirical distribution, estimated\nfrom $n$ i.i.d. samples, to design a privacy mechanism which is applied to new\nfresh samples afterward. In this paper, we study the discrepancy between the\nprivacy-utility guarantees for the empirical distribution, used to design the\nprivacy mechanism, and those for the true distribution, experienced by the\nprivacy mechanism in practice. We first show that, for any privacy mechanism,\nthese discrepancies vanish at speed $O(1/\\sqrt{n})$ with high probability.\nThese bounds follow from our main technical results regarding the Lipschitz\ncontinuity of the considered information leakage measures. Then we prove that\nthe optimal privacy mechanisms for the empirical distribution approach the\ncorresponding mechanisms for the true distribution as the sample size $n$\nincreases, thereby establishing the statistical consistency of the optimal\nprivacy mechanisms. Finally, we introduce and study uniform privacy mechanisms\nwhich, by construction, provide privacy to all the distributions within a\nneighborhood of the estimated distribution and, thereby, guarantee privacy for\nthe true distribution with high probability. \n\n"}
{"id": "1811.06472", "contents": "Title: Oversampled Adaptive Sensing with Random Projections: Analysis and\n  Algorithmic Approaches Abstract: Oversampled adaptive sensing (OAS) is a recently proposed Bayesian framework\nwhich sequentially adapts the sensing basis. In OAS, estimation quality is, in\neach step, measured by conditional mean squared errors (MSEs), and the basis\nfor the next sensing step is adapted accordingly. For given average sensing\ntime, OAS reduces the MSE compared to non-adaptive schemes, when the signal is\nsparse. This paper studies the asymptotic performance of Bayesian OAS, for\nunitarily invariant random projections. For sparse signals, it is shown that\nOAS with Bayesian recovery and hard adaptation significantly outperforms the\nminimum MSE bound for non-adaptive sensing. To address implementational\naspects, two computationally tractable algorithms are proposed, and their\nperformances are compared against the state-of-the-art non-adaptive algorithms\nvia numerical simulations. Investigations depict that these low-complexity OAS\nalgorithms, despite their suboptimality, outperform well-known non-adaptive\nschemes for sparse recovery, such as LASSO, with rather small oversampling\nfactors. This gain grows, as the compression rate increases. \n\n"}
{"id": "1811.08308", "contents": "Title: Economics of disagreement -- financial intuition for the R\\'enyi\n  divergence Abstract: Disagreement is an essential element of science and life in general. The\nlanguage of probabilities and statistics is often used to describe\ndisagreements quantitatively. In practice, however, we want much more than\nthat. We want disagreements to be resolved. This leaves us with a substantial\nknowledge gap which is often perceived as a lack of practical intuition\nregarding probabilistic and statistical concepts.\n  Take for instance the R\\'enyi divergence which is a well-known statistical\nquantity specifically designed as a measure of disagreement between\nprobabilistic models. Despite its widespread use in science and engineering,\nthe R\\'enyi divergence remains a highly abstract axiomatically-motivated\nmeasure. Certainly, it offers no practical insight as to how disagreements can\nbe resolved.\n  Here we propose to address disagreements using the methods of financial\neconomics. In particular, we show how a large class of disagreements can be\ntransformed into investment opportunities. The expected financial performance\nof such investments quantifies the amount of disagreement in a tangible way.\nThis provides intuition for statistical concepts such as the R\\'enyi divergence\nwhich becomes connected to the financial performance of optimized investments.\nInvestment optimization takes into account individual opinions as well as\nattitudes towards risk. The result is a market-like social mechanism by which\nfunds flow naturally to support a more accurate view. Such social mechanisms\ncan help us with difficult disagreements (e.g., financial arguments concerning\nthe future climate).\n  In terms of scientific validation, we used the findings of independent\nneurophysiological experiments as well as our own research on the equity\npremium. \n\n"}
{"id": "1811.08602", "contents": "Title: On-off Switched Interference Alignment for Diversity Multiplexing\n  Tradeoff Improvement in the 2-User X-Network with Two Antennas Abstract: To improve diversity gain in an interference channel and hence to maximize\ndiversity multiplexing tradeoff (DMT), we propose on-off switched interference\nalignment (IA) where IA is intermittently utilized by switching IA on/off. For\non-off switching, either IA with symbol extension or IA with Alamouti coding is\nadopted in this paper. Deriving and analyzing DMT of the proposed schemes, we\nreveal that the intermittent utilization of IA with simultaneous non-unique\ndecoding can improve DMT in the 2-user X-channel with two antennas. Both the\nproposed schemes are shown to achieve diversity gain of 4 and DoF per user of\n$\\frac{4}{3}$. In particular, the on-off switched IA with Alamouti coding, to\nthe best of our knowledge, surpasses any other existing schemes for the 2-user\nX-channel with two antennas and nearly approaches the ideal DMT. \n\n"}
{"id": "1811.09652", "contents": "Title: Generalised Entropies and Metric-Invariant Optimal Countermeasures for\n  Information Leakage under Symmetric Constraints Abstract: We introduce a novel generalization of entropy and conditional entropy from\nwhich most definitions from the literature can be derived as particular cases.\nWithin this general framework, we investigate the problem of designing\ncountermeasures for information leakage. In particular, we seek\nmetric-invariant solutions, i.e., they are robust against the choice of entropy\nfor quantifying the leakage. The problem can be modelled as an information\nchannel from the system to an adversary, and the countermeasures can be seen as\nmodifying this channel in order to minimise the amount of information that the\noutputs reveal about the inputs. Our main result is to fully solve the problem\nunder the highly symmetrical design constraint that the number of inputs that\ncan produce the same output is capped. Our proof is constructive and the\noptimal channels and the minimum leakage are derived in closed form. \n\n"}
{"id": "1811.09973", "contents": "Title: Joint State Estimation and Communication over a State-Dependent Gaussian\n  Multiple Access Channel Abstract: A hybrid communication network with a common analog signal and an independent\ndigital data stream as input to each node in a multiple access network is\nconsidered. The receiver/base-station has to estimate the analog signal with a\ngiven fidelity, and decode the digital streams with a low error probability.\nTreating the analog signal as a common state process, we set up a joint state\nestimation and communication problem in a Gaussian multiple access channel\n(MAC) with additive state. The transmitters have non-causal knowledge of the\nstate process, and need to communicate independent data streams in addition to\nfacilitating state estimation at the receiver. We first provide a complete\ncharacterization of the optimal trade-off between mean squared error distortion\nperformance in estimating the state and the data rates for the message streams\nfrom two transmitting nodes. This is then generalized to an N-sender MAC. To\nthis end, we show a natural connection between the state-dependent MAC model\nand a hybrid multi-sensor network in which a common source phenomenon is\nobserved at N transmitting nodes. Each node encodes the source observations as\nwell as an independent message stream over a Gaussian MAC without any state\nprocess. The receiver is interested estimating the source and all the messages.\nAgain the distortion-rate performance is characterized. \n\n"}
{"id": "1811.10315", "contents": "Title: Investigation of Nonlinear Communication Channel with Small Dispersion\n  via Stochastic Correlator Approach Abstract: We consider the optical fiber channel modelled by the nonlinear\nSchr\\\"{o}dinger equation with additive white Gaussian noise and with large\nsignal-to-noise ratio. For the small dispersion case we present the approach to\nanalyze the stochastic nonlinear Schr\\\"{o}dinger equation. Taking into account\nthe averaging procedure (frequency filtering) of the output signal detector we\nfind the first corrections in small dispersion parameter to the correlators of\nthe input signal recovered by the backward propagation. These correlators are\nthe important ingredients for the calculation of the channel capacity and the\noptimal input signal distribution. We assert that the information channel\ncharacteristics essentially depend on the procedures of the output signal\nfiltering and the recovery of the transmitted signal. \n\n"}
{"id": "1811.11923", "contents": "Title: Soft-Output Detection Methods for Sparse Millimeter Wave MIMO Systems\n  with Low-Precision ADCs Abstract: The use of low-precision analog-to-digital converters (ADCs) is a low-cost\nand power-efficient solution for a millimeter wave (mmWave) multiple-input\nmultiple-output (MIMO) system operating at sampling rates higher than a few\nGsample/sec. This solution, however, can make significant frame-error-rates\n(FERs) degradation due to inter-subcarrier interference when applying\nconventional frequency-domain equalization techniques. In this paper, we\npropose computationally-efficient yet near-optimal soft-output detection\nmethods for the coded mmWave MIMO systems with low-precision ADCs. The\nunderlying idea of the proposed methods is to construct an extremely sparse\ninter-symbol-interference (ISI) channel model by jointly exploiting the\ndelay-domain sparsity in mmWave channels and a high quantization noise caused\nby low-precision ADCs. Then we harness this sparse channel model to create a\ntrellis diagram with a reduced number of states or a factor graph with very\nsparse edge connections. Using the reduced trellis diagram, we present a\nsoft-output detection method that computes the log-likelihood ratios (LLRs) of\ncoded bits by optimally combining the quantized received signals obtained from\nmultiple receive antennas using a forward-and-backward algorithm. To reduce the\ncomputational complexity further, we also present a low-complexity detection\nmethod using the sparse factor graph to compute the LLRs in an iterative\nfashion based on a belief propagation algorithm. Simulations results\ndemonstrate that the proposed soft-output detection methods provide significant\nFER gains compared to the existing frequency-domain equalization techniques in\na coded mmWave MIMO system using one- or two-bit ADCs. \n\n"}
{"id": "1812.03031", "contents": "Title: Information-Distilling Quantizers Abstract: Let $X$ and $Y$ be dependent random variables. This paper considers the\nproblem of designing a scalar quantizer for $Y$ to maximize the mutual\ninformation between the quantizer's output and $X$, and develops fundamental\nproperties and bounds for this form of quantization, which is connected to the\nlog-loss distortion criterion. The main focus is the regime of low $I(X;Y)$,\nwhere it is shown that, if $X$ is binary, a constant fraction of the mutual\ninformation can always be preserved using $\\mathcal{O}(\\log(1/I(X;Y)))$\nquantization levels, and there exist distributions for which this many\nquantization levels are necessary. Furthermore, for larger finite alphabets $2\n< |\\mathcal{X}| < \\infty$, it is established that an $\\eta$-fraction of the\nmutual information can be preserved using roughly $(\\log(| \\mathcal{X} |\n/I(X;Y)))^{\\eta\\cdot(|\\mathcal{X}| - 1)}$ quantization levels. \n\n"}
{"id": "1812.04355", "contents": "Title: Convex Regularization and Representer Theorems Abstract: We establish a result which states that regularizing an inverse problem with\nthe gauge of a convex set $C$ yields solutions which are linear combinations of\na few extreme points or elements of the extreme rays of $C$. These can be\nunderstood as the \\textit{atoms} of the regularizer. We then explicit that\ngeneral principle by using a few popular applications. In particular, we relate\nit to the common wisdom that total gradient variation minimization favors the\nreconstruction of piecewise constant images. \n\n"}
{"id": "1812.05333", "contents": "Title: Computation Over NOMA: Improved Achievable Rate Through Sub-Function\n  Superposition Abstract: Massive numbers of nodes will be connected in future wireless networks. This\nbrings great difficulty to collect a large amount of data. Instead of\ncollecting the data individually, computation over multi-access channel (CoMAC)\nprovides an intelligent solution by computing a desired function over the air\nbased on the signal-superposition property of wireless channel. To improve the\nspectrum efficiency in conventional CoMAC, we propose the use of non-orthogonal\nmultiple access (NOMA) for functions in CoMAC. The desired functions are\ndecomposed into several sub-functions, and multiple sub-functions are selected\nto be superposed over each resource block (RB). The corresponding achievable\nrate is derived based on sub-function superposition, which prevents a vanishing\ncomputation rate for large numbers of nodes. In order to gain more insights, we\nfurther study the limiting case when the number of nodes goes to infinity. An\nexact expression of the rate is derived which provides a lower bound on the\ncomputation rate. Compared with existing CoMAC, the NOMA-based CoMAC\n(NOMA-CoMAC) not only achieves a higher computation rate, but also provides an\nimproved non-vanishing rate. Furthermore, the diversity order of the\ncomputation rate of NOMA-CoMAC is derived, and it shows that the system\nperformance is dominated by the node with the worst channel gain among these\nsub-functions in each RB. \n\n"}
{"id": "1812.05867", "contents": "Title: Multi-edge-type LDPC code design with G-EXIT charts for\n  continuous-variable quantum key distribution Abstract: Continuous-variable quantum key distribution utilizes an ensemble of coherent\nstates of light to distribute secret encryption keys between two parties. One\nof the challenges is thereby the requirement of capacity approaching error\ncorrecting codes in the low signal-to-noise (SNR) regime (SNR < 0 dB).\nMultilevel coding (MLC) combined with multistage decoding (MSD) can solve this\nchallenge in combination with multi-edge-type low-density parity-check\n(MET-LDPC) codes which are ideal for low code rates in the low SNR regime due\nto degree-one variable nodes. However, the complexity of designing such highly\nefficient codes remains an open issue. Here, we introduce the concept of\ngeneralized extrinsic information transfer (G-EXIT) charts for MET-LDPC codes\nand demonstrate how this tool can be used to analyze their convergence\nbehavior. We calculate the capacity for each level in the MLC-MSD scheme and\nuse G-EXIT charts to exemplary find codes for some given rates which provide a\nbetter decoding threshold compared to previously reported codes. In comparison\nto the traditional density evolution method, G-EXIT charts offer a simple and\nfast asymptotic analysis tool for MET-LDPC codes. \n\n"}
{"id": "1812.05957", "contents": "Title: The lengths of projective triply-even binary codes Abstract: It is shown that there does not exist a binary projective triply-even code of\nlength $59$. This settles the last open length for projective triply-even\nbinary codes. Therefore, projective triply-even binary codes exist precisely\nfor lengths $15$, $16$, $30$, $31$, $32$, $45$--$51$, and $\\ge 60$. \n\n"}
{"id": "1812.06369", "contents": "Title: Provable limitations of deep learning Abstract: As the success of deep learning reaches more grounds, one would like to also\nenvision the potential limits of deep learning. This paper gives a first set of\nresults proving that certain deep learning algorithms fail at learning certain\nefficiently learnable functions. The results put forward a notion of\ncross-predictability that characterizes when such failures take place. Parity\nfunctions provide an extreme example with a cross-predictability that decays\nexponentially, while a mere super-polynomial decay of the cross-predictability\nis shown to be sufficient to obtain failures. Examples in community detection\nand arithmetic learning are also discussed.\n  Recall that it is known that the class of neural networks (NNs) with\npolynomial network size can express any function that can be implemented in\npolynomial time, and that their sample complexity scales polynomially with the\nnetwork size. The challenge is with the optimization error (the ERM is\nNP-hard), and the success behind deep learning is to train deep NNs with\ndescent algorithms. The failures shown in this paper apply to training\npoly-size NNs on function distributions of low cross-predictability with a\ndescent algorithm that is either run with limited memory per sample or that is\ninitialized and run with enough randomness. We further claim that such types of\nconstraints are necessary to obtain failures, in that exact SGD with careful\nnon-random initialization can be shown to learn parities. The\ncross-predictability in our results plays a similar role the statistical\ndimension in statistical query (SQ) algorithms, with distinctions explained in\nthe paper. The proof techniques are based on exhibiting algorithmic constraints\nthat imply a statistical indistinguishability between the algorithm's output on\nthe test model v.s.\\ a null model, using information measures to bound the\ntotal variation distance. \n\n"}
{"id": "1812.07026", "contents": "Title: State Leakage and Coordination with Causal State Knowledge at the\n  Encoder Abstract: We revisit the problems of state masking and state amplification through the\nlens of empirical coordination. Specifically, we characterize the\nrate-equivocation-coordination trade-offs regions of a state-dependent channel\nin which the encoder has causal and strictly causal state knowledge. We also\nextend this characterization to the cases of two-sided state information and\nnoisy channel feedback. Our approach is based on the notion of core of the\nreceiver's knowledge, which we introduce to capture what the decoder can infer\nabout all the signals involved in the model. Finally, we exploit the\naforementioned results to solve a channel state estimation zero-sum game in\nwhich the encoder prevents the decoder to estimate the channel state\naccurately. \n\n"}
{"id": "1812.07389", "contents": "Title: Exploiting Full/Half-Duplex User Relaying in NOMA Systems Abstract: In this paper, a novel cooperative non-orthogonal multiple access (NOMA)\nsystem is proposed, where one near user is employed as decode-and-forward (DF)\nrelaying switching between full-duplex (FD) and half-duplex (HD) mode to help a\nfar user. Two representative cooperative relaying scenarios are investigated\ninsightfully. The \\emph{first scenario} is that no direct link exists between\nthe base station (BS) and far user. The \\emph{second scenario} is that the\ndirect link exists between the BS and far user. To characterize the performance\nof potential gains brought by FD NOMA in two considered scenarios, three\nperformance metrics outage probability, ergodic rate and energy efficiency are\ndiscussed. More particularly, we derive new closed-form expressions for both\nexact and asymptotic outage probabilities as well as delay-limited throughput\nfor two NOMA users. Based on the derived results, the diversity orders achieved\nby users are obtained. We confirm that the use of direct link overcomes zero\ndiversity order of far NOMA user inherent to FD relaying. Additionally, we\nderive new closed-form expressions for asymptotic ergodic rates. Based on\nthese, the high signal-to-noise radio (SNR) slopes of two users for FD NOMA are\nobtained. Simulation results demonstrate that: 1) FD NOMA is superior to HD\nNOMA in terms of outage probability and ergodic sum rate in the low SNR region;\nand 2) In delay-limited transmission mode, FD NOMA has higher energy efficiency\nthan HD NOMA in the low SNR region; However, in delay-tolerant transmission\nmode, the system energy efficiency of HD NOMA exceeds FD NOMA in the high SNR\nregion. \n\n"}
{"id": "1812.08898", "contents": "Title: Capacity Scaling of Massive MIMO in Strong Spatial Correlation Regimes Abstract: This paper investigates the capacity scaling of multicell massive MIMO\nsystems in the presence of spatially correlated fading. In particular, we focus\non the strong spatial correlation regimes where the covariance matrix of each\nuser channel vector has a rank that scales sublinearly with the number of base\nstation antennas, as the latter grows to infinity. We also consider the case\nwhere the covariance eigenvectors corresponding to the non-zero eigenvalues\nspan randomly selected subspaces. For this channel model, referred to as the\n\"random sparse angular support\" model, we characterize the asymptotic capacity\nscaling law in the limit of large number of antennas. To achieve the asymptotic\ncapacity results, statistical spatial despreading based on the second-order\nchannel statistics plays a pivotal role in terms of pilot decontamination and\ninterference suppression. A remarkable result is that even when the number of\nusers scales linearly with base station antennas, a linear growth of the\ncapacity with respect to the number of antennas is achievable under the sparse\nangular support model. We note that the achievable rate lower bound based on\nmassive MIMO \"channel hardening\", widely used in the massive MIMO literature,\nyields rather loose results in the strong spatial correlation regimes and may\nsignificantly underestimate the achievable rate of massive MIMO. This work\ntherefore considers an alternative bounding technique which is better suited to\nthe strong correlation regimes. In fading channels with sparse angular support,\nit is further shown that spatial despreading (spreading) in uplink (downlink)\nhas a more prominent impact on the performance of massive MIMO than channel\nhardening. \n\n"}
{"id": "1812.10525", "contents": "Title: The K-User DM Broadcast Channel with Two Groupcast Messages: Achievable\n  Rate Regions and the Combination Network as a Case Study Abstract: A novel class of achievable rate regions is obtained for the K-receiver\nbroadcast channel with two groupcast messages. The associated achievability\nschemes are parameterized by an expansion of the message set which then\ndetermines how random coding techniques are employed, which include generalized\nversions of {\\em up-set} message-splitting, the generation of possibly multiple\nauxiliary codebooks for certain compositions of split messages using\nsuperposition coding, partial interference decoding at all receivers, and joint\nunique and non-unique decoding.\n  New capacity results are established for certain partially ordered classes of\ngeneral broadcast channels for certain two non-nested messages. Moreover, when\nspecialized to the combination network (CN), some of the inner bounds are\nshown, via converse results, to result in the capacity region for (a) the two\nmessages intended for two sets of K-1 receivers each and (b) two nested\nmessages in which one message is intended for one or (c) two (common)\nreceivers. In the latter two cases, we hence recover previous results by\nBidokhti et al obtained therein using network coding schemes based on\nrate-splitting and linear superposition coding. Furthermore, we show the\nachievability of rate pairs in two examples of CNs, with three and four common\nreceivers each, used in the previous literature to show the sub-optimality of\nrate-splitting and linear superposition coding, and to motivate a pre-encoding\ntechnique and a block-Markov linear superposition coding for the CN, with the\nlatter then lifted to the general broadcast channel. Our results suggest that\nthe proposed framework here, when specialized to the CN, is strong enough to\nincorporate the enhancements afforded by those two latter techniques, thereby\nsuggesting among other things, that perhaps block-Markov superposition coding\nis not necessary for the general broadcast channel. \n\n"}
{"id": "1812.11292", "contents": "Title: Adaptive Short-time Fourier Transform and Synchrosqueezing Transform for\n  Non-stationary Signal Separation Abstract: The synchrosqueezing transform, a kind of reassignment method, aims to\nsharpen the time-frequency representation and to separate the components of a\nmulticomponent non-stationary signal. In this paper, we consider the short-time\nFourier transform (STFT) with a time-varying parameter, called the adaptive\nSTFT. Based on the local approximation of linear frequency modulation mode, we\nanalyze the well-separated condition of non-stationary multicomponent signals\nusing the adaptive STFT with the Gaussian window function. We propose the\nSTFT-based synchrosqueezing transform (FSST) with a time-varying parameter,\nnamed the adaptive FSST, to enhance the time-frequency concentration and\nresolution of a multicomponent signal, and to separate its components more\naccurately. In addition, we also propose the 2nd-order adaptive FSST to further\nimprove the adaptive FSST for the non-stationary signals with fast-varying\nfrequencies. Furthermore, we present a localized optimization algorithm based\non our well-separated condition to estimate the time-varying parameter\nadaptively and automatically. Simulation results on synthetic signals and the\nbat echolocation signal are provided to demonstrate the effectiveness and\nrobustness of the proposed method. \n\n"}
{"id": "1901.00354", "contents": "Title: A Deep Learning Framework for Optimization of MISO Downlink Beamforming Abstract: Beamforming is an effective means to improve the quality of the received\nsignals in multiuser multiple-input-single-output (MISO) systems.\nTraditionally, finding the optimal beamforming solution relies on iterative\nalgorithms, which introduces high computational delay and is thus not suitable\nfor real-time implementation. In this paper, we propose a deep learning\nframework for the optimization of downlink beamforming. In particular, the\nsolution is obtained based on convolutional neural networks and exploitation of\nexpert knowledge, such as the uplink-downlink duality and the known structure\nof optimal solutions. Using this framework, we construct three beamforming\nneural networks (BNNs) for three typical optimization problems, i.e., the\nsignal-to-interference-plus-noise ratio (SINR) balancing problem, the power\nminimization problem, and the sum rate maximization problem. For the former two\nproblems the BNNs adopt the supervised learning approach, while for the sum\nrate maximization problem a hybrid method of supervised and unsupervised\nlearning is employed. Simulation results show that the BNNs can achieve\nnear-optimal solutions to the SINR balancing and power minimization problems,\nand a performance close to that of the weighted minimum mean squared error\nalgorithm for the sum rate maximization problem, while in all cases enjoy\nsignificantly reduced computational complexity. In summary, this work paves the\nway for fast realization of optimal beamforming in multiuser MISO systems. \n\n"}
{"id": "1901.00798", "contents": "Title: Scalable Information-Flow Analysis of Secure Three-Party Affine\n  Computations Abstract: Elaborate protocols in Secure Multi-party Computation enable several\nparticipants to compute a public function of their own private inputs while\nensuring that no undesired information leaks about the private inputs, and\nwithout resorting to any trusted third party. However, the public output of the\ncomputation inevitably leaks some information about the private inputs. Recent\nworks have introduced a framework and proposed some techniques for quantifying\nsuch information flow. Yet, owing to their complexity, those methods do not\nscale to practical situations that may involve large input spaces. The main\ncontribution of the work reported here is to formally investigate the\ninformation flow captured by the min-entropy in the particular case of secure\nthree-party computations of affine functions in order to make its\nquantification scalable to realistic scenarios. To this end, we mathematically\nderive an explicit formula for this entropy under uniform prior beliefs about\nthe inputs. We show that this closed-form expression can be computed in time\nconstant in the inputs sizes and logarithmic in the coefficients of the affine\nfunction. Finally, we formulate some theoretical bounds for this privacy leak\nin the presence of non-uniform prior beliefs. \n\n"}
{"id": "1901.01573", "contents": "Title: Optimal Age over Erasure Channels Abstract: Previous works on age of information and erasure channels have dealt with\nspecific models and computed the average age or average peak age for certain\nsettings. In this paper, given a source that produces a letter every $T_s$\nseconds and an erasure channel that can be used every $T_c$ seconds, we ask\nwhat is the coding strategy that minimizes the time-average age of information\nthat an observer of the channel output incurs. We first analyze the case where\nthe source alphabet and the channel-input alphabet have the same size. We show\nthat a trivial coding strategy is optimal and a closed form expression for the\nage can be derived. We then analyze the case where the alphabets have different\nsizes. We use a random coding argument to bound the average age and show that\nthe average age achieved using random codes converges to the optimal average\nage of linear block codes as the source alphabet becomes large. \n\n"}
{"id": "1901.01605", "contents": "Title: Bounds on the Length of Functional PIR and Batch codes Abstract: A functional $k$-PIR code of dimension $s$ consists of $n$ servers storing\nlinear combinations of $s$ linearly independent information symbols. Any linear\ncombination of the $s$ information symbols can be recovered by $k$ disjoint\nsubsets of servers. The goal is to find the smallest number of servers for\ngiven $k$ and $s$. We provide lower bounds on the number of servers and\nconstructions which yield upper bounds on this number. For $k \\leq 4$, exact\nbounds on the number of servers are proved. Furthermore, we provide some\nasymptotic bounds. The problem coincides with the well known private\ninformation retrieval problem based on a coded database to reduce the storage\noverhead, when each linear combination contains exactly one information symbol.\n  If any multiset of size $k$ of linear combinations from the linearly\nindependent information symbols can be recovered by $k$ disjoint subset of\nservers, then the servers form a functional $k$-batch code. A~functional\n$k$-batch code is a functional $k$-PIR code, where all the $k$ linear\ncombinations in the multiset are equal. We provide some bounds on the number of\nservers for functional $k$-batch codes. In particular we present a random\nconstruction and a construction based on simplex codes, WOM codes, and RIO\ncodes. \n\n"}
{"id": "1901.02283", "contents": "Title: Improved encoding and decoding for non-adaptive threshold group testing Abstract: The goal of threshold group testing is to identify up to $d$ defective items\namong a population of $n$ items, where $d$ is usually much smaller than $n$. A\ntest is positive if it has at least $u$ defective items and negative otherwise.\nOur objective is to identify defective items in sublinear time the number of\nitems, e.g., $\\mathrm{poly}(d, \\ln{n}),$ by using the number of tests as low as\npossible. In this paper, we reduce the number of tests to $O \\left( h \\times\n\\frac{d^2 \\ln^2{n}}{\\mathsf{W}^2(d \\ln{n})} \\right)$ and the decoding time to\n$O \\left( \\mathrm{dec}_0 \\times h \\right),$ where $\\\\mathrm{dec}_0 = O \\left(\n\\frac{d^{3.57} \\ln^{6.26}{n}}{\\mathsf{W}^{6.26}(d \\ln{n})} \\right) + O \\left(\n\\frac{d^6 \\ln^4{n}}{\\mathsf{W}^4(d \\ln{n})} \\right)$, $h = O\\left( \\frac{d_0^2\n\\ln{\\frac{n}{d_0}}}{(1-p)^2} \\right)$ , $d_0 = \\max\\{u, d - u \\}$, $p \\in [0,\n1),$ and $\\mathsf{W}(x) = \\Theta \\left( \\ln{x} - \\ln{\\ln{x}} \\right).$ If the\nnumber of tests is increased to $O\\left( h \\times\n\\frac{d^2\\ln^3{n}}{\\mathsf{W}^2(d \\ln{n})} \\right),$ the decoding complexity is\nreduced to $O \\left(\\mathrm{dec}_1 \\times h \\right),$ where $\\mathrm{dec}_1 =\n\\max \\left\\{ \\frac{d^2 \\ln^3{n}}{\\mathsf{W}^2(d \\ln{n})}, \\frac{ud\n\\ln^4{n}}{\\mathsf{W}^3(d \\ln{n})} \\right\\}.$ Moreover, our proposed scheme is\ncapable of handling errors in test outcomes. \n\n"}
{"id": "1901.02867", "contents": "Title: Maximally Recoverable Codes with Hierarchical Locality Abstract: Maximally recoverable codes are a class of codes which recover from all\npotentially recoverable erasure patterns given the locality constraints of the\ncode. In earlier works, these codes have been studied in the context of codes\nwith locality. The notion of locality has been extended to hierarchical\nlocality, which allows for locality to gradually increase in levels with the\nincrease in the number of erasures. We consider the locality constraints\nimposed by codes with two-level hierarchical locality and define maximally\nrecoverable codes with data-local and local hierarchical locality. We derive\ncertain properties related to their punctured codes and minimum distance. We\ngive a procedure to construct hierarchical data-local MRCs from hierarchical\nlocal MRCs. We provide a construction of hierarchical local MRCs for all\nparameters. For the case of one global parity, we provide a different\nconstruction of hierarchical local MRC over a lower field size. \n\n"}
{"id": "1901.03216", "contents": "Title: On Secure Capacity of Multiple Unicast Traffic over Separable Networks Abstract: This paper studies the problem of information theoretic secure communication\nwhen a source has private messages to transmit to $m$ destinations, in the\npresence of a passive adversary who eavesdrops an unknown set of $k$ edges. The\ninformation theoretic secure capacity is derived over unit-edge capacity\nseparable networks, for the cases when $k=1$ and $m$ is arbitrary, or $m=3$ and\n$k$ is arbitrary. This is achieved by first showing that there exists a secure\npolynomial-time code construction that matches an outer bound over two-layer\nnetworks, followed by a deterministic mapping between two-layer and arbitrary\nseparable networks. \n\n"}
{"id": "1901.04078", "contents": "Title: Periodic Analog Channel Estimation Aided Beamforming for Massive MIMO\n  Systems Abstract: Analog beamforming is an attractive and cost-effective solution to exploit\nthe benefits of massive multiple-input-multiple-output systems, by requiring\nonly one up/down-conversion chain. However, the presence of only one chain\nimposes a significant overhead in estimating the channel state information\nrequired for beamforming, when conventional digital channel estimation (CE)\napproaches are used. As an alternative, this paper proposes a novel CE\ntechnique, called periodic analog CE (PACE), that can be performed by analog\nhardware. By avoiding digital processing, the estimation overhead is\nsignificantly lowered and does not scale with number of antennas. PACE involves\nperiodic transmission of a sinusoidal reference signal by the transmitter,\nestimation of its amplitude and phase at each receive antenna via analog\nhardware, and using these estimates for beamforming. To enable such non-trivial\noperation, two reference tone recovery techniques and a novel receiver\narchitecture for PACE are proposed and analyzed, both theoretically and via\nsimulations. Results suggest that in sparse, wide-band channels and above a\ncertain signal-to-noise ratio, PACE aided beamforming suffers only a small loss\nin beamforming gain and enjoys a much lower CE overhead, in comparison to\nconventional approaches. Benefits of using PACE aided beamforming during the\ninitial access phase are also discussed. \n\n"}
{"id": "1901.04241", "contents": "Title: Linear complementary dual, maximum distance separable codes Abstract: Linear complementary dual (LCD) maximum distance separable (MDS) codes are\nconstructed to given specifications. For given $n$ and $r<n$, with $n$ or $r$\n(or both) odd, MDS LCD $(n,r)$ codes are constructed over finite fields whose\ncharacteristic does not divide $n$. Series of LCD MDS codes are constructed to\nrequired rate and required error-correcting capability. Given the field $GF(q)$\nand $n/(q-1)$, LCD MDS codes of length $n$ and dimension $r$ are explicitly\nconstructed over $GF(q)$ for all $r<n$ when $n$ is odd and for all odd $r<n$\nwhen $n$ is even. For given dimension and given error-correcting capability LCD\nMDS codes are constructed to these specifications with smallest possible\nlength. Series of asymptotically good LCD MDS codes are explicitly constructed.\nEfficient encoding and decoding algorithms exist for all the constructed codes.\n  Linear complementary dual codes have importance in data storage,\ncommunications' systems and security. \n\n"}
{"id": "1901.05459", "contents": "Title: Permutation Decoding of Polar Codes Abstract: A new permutation decoding approach for polar codes is presented. The\ncomplexity of the algorithm is similar to that of a successive cancellation\nlist (SCL) decoder, while it can be implemented with the latency of a\nsuccessive cancellation decoder. As opposed to the SCL algorithm, the sorting\noperation is not used in the proposed method. It is shown that the error\ncorrection performance of the algorithm is similar to that of the SCL decoder\nfor polar codes. Moreover, a new construction aiming to improve the error\ncorrection performance of polar codes under the proposed algorithm is\npresented. \n\n"}
{"id": "1901.05647", "contents": "Title: Deep Learning for Joint MIMO Detection and Channel Decoding Abstract: We propose a deep-learning approach for the joint MIMO detection and channel\ndecoding problem. Conventional MIMO receivers adopt a model-based approach for\nMIMO detection and channel decoding in linear or iterative manners. However,\ndue to the complex MIMO signal model, the optimal solution to the joint MIMO\ndetection and channel decoding problem (i.e., the maximum likelihood decoding\nof the transmitted codewords from the received MIMO signals) is computationally\ninfeasible. As a practical measure, the current model-based MIMO receivers all\nuse suboptimal MIMO decoding methods with affordable computational\ncomplexities. This work applies the latest advances in deep learning for the\ndesign of MIMO receivers. In particular, we leverage deep neural networks (DNN)\nwith supervised training to solve the joint MIMO detection and channel decoding\nproblem. We show that DNN can be trained to give much better decoding\nperformance than conventional MIMO receivers do. Our simulations show that a\nDNN implementation consisting of seven hidden layers can outperform\nconventional model-based linear or iterative receivers. This performance\nimprovement points to a new direction for future MIMO receiver design. \n\n"}
{"id": "1901.05732", "contents": "Title: On Coded Caching with Correlated Files Abstract: This paper studies the fundamental limits of the shared-link coded caching\nproblem with correlated files, where a server with a library of $N$ files\ncommunicates with $K$ users who can locally cache $M$ files. Given an integer\n$r \\in [N]$, correlation is modeled as follows: each r-subset of files contains\na unique common block. The tradeoff between the cache size and the average\ntransmitted load is considered. First, a converse bound under the constraint of\nuncoded cache placement (i.e., each user directly stores a subset of the\nlibrary bits) is derived. Then, a caching scheme for the case where every user\ndemands a distinct file (possible for $N \\geq K$) is shown to be optimal under\nthe constraint of uncoded cache placement. This caching scheme is further\nproved to be decodable and optimal under the constraint of uncoded cache\nplacement when (i) $KrM \\leq 2N$ or $KrM \\geq (K - 1)N $or $r \\in \\{1,2,N-\n1,N\\}$ for every demand type (i.e., when the demanded file are not necessarily\ndistinct), and (ii) when the number of distinct demanded files is no larger\nthan four. Finally, a two-phase delivery scheme based on interference alignment\nis shown to be optimal to within a factor of 2 under the constraint of uncoded\ncache placement for every possible demands. As a by-product, the proposed\ninterference alignment scheme is shown to reduce the (worst-case or average)\nload of state-of-the-art schemes for the coded caching problem where the users\ncan request multiple files. \n\n"}
{"id": "1901.06010", "contents": "Title: Degrees of Freedom Region of the $(M,N_1,N_2)$ MIMO Broadcast Channel\n  with Partial CSIT: An Application of Sum-set Inequalities Based on Aligned\n  Image Sets Abstract: The degrees of freedom (DoF) region is characterized for the $2$-user\nmultiple input multiple output (MIMO) broadcast channel (BC), where the\ntransmitter is equipped with $M$ antennas, the two receivers are equipped with\n$N_1$ and $N_2$ antennas, and the levels of channel state information at the\ntransmitter (CSIT) for the two users are parameterized by $\\beta_1, \\beta_2$,\nrespectively. The achievability of the DoF region was established by Hao,\nRassouli and Clerckx, but no proof of optimality was heretofore available. The\nproof of optimality is provided in this work with the aid of sum-set\ninequalities based on the aligned image sets (AIS) approach. \n\n"}
{"id": "1901.06368", "contents": "Title: Outage in Motorway Multi-Lane VANETs with Hardcore Headway Distance\n  Using Synthetic Traces Abstract: In this paper we analyze synthetic mobility traces generated for three-lane\nunidirectional motorway traffic to find that the locations of vehicles along a\nlane are better modeled by a hardcore point process instead of the\nwidely-accepted Poisson point process (PPP). In order to capture the repulsion\nbetween successive vehicles while maintaining a level of analytical\ntractability, we make a simple extension to PPP: We model the inter-vehicle\ndistance along a lane equal to the sum of a constant hardcore distance and an\nexponentially distributed random variable. We calculate the J-function and the\nRipley's K-function for this hardcore point process. We fit its parameters to\nthe available traces, and we illustrate that the higher the average speed along\na lane, the more prominent the hardcore component becomes. In addition, we\nconsider a transmitter-receiver link on the same lane, and we generate simple\nformulae for the moments of interference under reduced Palm measure for that\nlane, and without conditioning for other lanes. We illustrate that under\nRayleigh fading a shifted-gamma approximation for the distribution of\ninterference per lane provides a very good fit to the simulated outage\nprobability using the synthetic traces, while the fit using the PPP is poor. \n\n"}
{"id": "1901.06629", "contents": "Title: A Submodularity-based Agglomerative Clustering Algorithm for the Privacy\n  Funnel Abstract: For the privacy funnel (PF) problem, we propose an efficient iterative\nagglomerative clustering algorithm based on the minimization of the difference\nof submodular functions (IAC-MDSF). For a data curator that wants to share the\ndata $X$ correlated with the sensitive information $S$, the PF problem is to\ngenerate the sanitized data $\\hat{X}$ that maintains a specified\nutility/fidelity threshold on $I(X; \\hat{X})$ while minimizing the privacy\nleakage $I(S; \\hat{X})$. Our IAC-MDSF algorithm starts with the original\nalphabet $\\hat{\\mathcal{X}} := \\mathcal{X}$ and iteratively merges the elements\nin the current alphabet $\\hat{\\mathcal{X}}$ that minimizes the Lagrangian\nfunction $ I(S;\\hat{X}) - \\lambda I(X;\\hat{X}) $. We prove that the best merge\nin each iteration of IAC-MDSF can be searched efficiently over all subsets of\n$\\hat{\\mathcal{X}}$ by the existing MDSF algorithms. We show that the IAC-MDSF\nalgorithm also applies to the information bottleneck (IB), a dual problem to\nPF. By varying the value of the Lagrangian multiplier $\\lambda$, we obtain the\nexperimental results on a heart disease data set in terms of the Pareto\nfrontier: $ I(S;\\hat{X})$ vs. $- I(X;\\hat{X})$. We show that our IAC-MDSF\nalgorithm outperforms the existing iterative pairwise merge approaches for both\nPF and IB and is computationally much less complex. \n\n"}
{"id": "1901.06644", "contents": "Title: Modeling and Analysis of Two-Way Relay Non-Orthogonal Multiple Access\n  Systems Abstract: A two-way relay non-orthogonal multiple access (TWR-NOMA) system is\ninvestigated, where two groups of NOMA users exchange messages with the aid of\none half-duplex (HD) decode-and-forward (DF) relay. Since the\nsignal-plus-interference-to-noise ratios (SINRs) of NOMA signals mainly depend\non effective successive interference cancellation (SIC) schemes, imperfect SIC\n(ipSIC) and perfect SIC (pSIC) are taken into account. In order to characterize\nthe performance of TWR-NOMA systems, we first derive closed-form expressions\nfor both exact and asymptotic outage probabilities of NOMA users' signals with\nipSIC/pSIC. Based on the derived results, the diversity order and throughput of\nthe system are examined. Then we study the ergodic rates of users' signals by\nproviding the asymptotic analysis in high SNR regimes. Lastly, numerical\nsimulations are provided to verify the analytical results and show that: 1)\nTWR-NOMA is superior to TWR-OMA in terms of outage probability in low SNR\nregimes; 2) Due to the impact of interference signal (IS) at the relay, error\nfloors and throughput ceilings exist in outage probabilities and ergodic rates\nfor TWR-NOMA, respectively; and 3) In delay-limited transmission mode, TWR-NOMA\nwith ipSIC and pSIC have almost the same energy efficiency. However, in\ndelay-tolerant transmission mode, TWR-NOMA with pSIC is capable of achieving\nlarger energy efficiency compared to TWR-NOMA with ipSIC. \n\n"}
{"id": "1901.06738", "contents": "Title: On the Number of Bins in Equilibria for Signaling Games Abstract: We investigate the equilibrium behavior for the decentralized quadratic cheap\ntalk problem in which an encoder and a decoder, viewed as two decision makers,\nhave misaligned objective functions. In prior work, we have shown that the\nnumber of bins under any equilibrium has to be at most countable, generalizing\na classical result due to Crawford and Sobel who considered sources with\ndensity supported on $[0,1]$. In this paper, we refine this result in the\ncontext of exponential and Gaussian sources. For exponential sources, a\nrelation between the upper bound on the number of bins and the misalignment in\nthe objective functions is derived, the equilibrium costs are compared, and it\nis shown that there also exist equilibria with infinitely many bins under\ncertain parametric assumptions. For Gaussian sources, it is shown that there\nexist equilibria with infinitely many bins. \n\n"}
{"id": "1901.06795", "contents": "Title: Active Hypothesis Testing: Beyond Chernoff-Stein Abstract: An active hypothesis testing problem is formulated. In this problem, the\nagent can perform a fixed number of experiments and then decide on one of the\nhypotheses. The agent is also allowed to declare its experiments inconclusive\nif needed. The objective is to minimize the probability of making an incorrect\ninference (misclassification probability) while ensuring that the true\nhypothesis is declared conclusively with moderately high probability. For this\nproblem, lower and upper bounds on the optimal misclassification probability\nare derived and these bounds are shown to be asymptotically tight. In the\nanalysis, a sub-problem, which can be viewed as a generalization of the\nChernoff-Stein lemma, is formulated and analyzed. A heuristic approach to\nstrategy design is proposed and its relationship with existing heuristic\nstrategies is discussed. \n\n"}
{"id": "1901.07105", "contents": "Title: Robustness of Maximal $\\alpha$-Leakage to Side Information Abstract: Maximal $\\alpha$-leakage is a tunable measure of information leakage based on\nthe accuracy of guessing an arbitrary function of private data based on public\ndata. The parameter $\\alpha$ determines the loss function used to measure the\naccuracy of a belief, ranging from log-loss at $\\alpha=1$ to the probability of\nerror at $\\alpha=\\infty$. To study the effect of side information on this\nmeasure, we introduce and define conditional maximal $\\alpha$-leakage. We show\nthat, for a chosen mapping (channel) from the actual (viewed as private) data\nto the released (public) data and some side information, the conditional\nmaximal $\\alpha$-leakage is the supremum (over all side information) of the\nconditional Arimoto channel capacity where the conditioning is on the side\ninformation. We prove that if the side information is conditionally independent\nof the public data given the private data, the side information cannot increase\nthe information leakage. \n\n"}
{"id": "1901.07303", "contents": "Title: Hybrid Precoder Design for Cache-enabled Millimeter Wave Radio Access\n  Networks Abstract: In this paper, we study the design of a hybrid precoder, consisting of an\nanalog and a digital precoder, for the delivery phase of downlink cache-enabled\nmillimeter wave (mmWave) radio access networks (CeMm-RANs). In CeMm-RANs,\nenhanced remote radio heads (eRRHs), which are equipped with local cache and\nbaseband signal processing capabilities in addition to the basic\nfunctionalities of conventional RRHs, are connected to the baseband processing\nunit via fronthaul links. Two different fronthaul information transfer\nstrategies are considered, namely, hard fronthaul information transfer, where\nhard information of uncached requested files is transmitted via the fronthaul\nlinks to a subset of eRRHs, and soft fronthaul information transfer, where the\nfronthaul links are used to transmit quantized baseband signals of uncached\nrequested files. The hybrid precoder is optimized for maximization of the\nminimum user rate under a fronthaul capacity constraint, an eRRH transmit power\nconstraint, and a constant-modulus constraint on the analog precoder. The\nresulting optimization problem is non-convex, and hence the global optimal\nsolution is difficult to obtain. Therefore, convex approximation methods are\nemployed to tackle the non-convexity of the achievable user rate, the fronthaul\ncapacity constraint, and the constant modulus constraint on the analog\nprecoder. Then, an effective algorithm with provable convergence is developed\nto solve the approximated optimization problem. Simulation results are provided\nto evaluate the performance of the proposed algorithms, where fully digital\nprecoding is used as benchmark. The results reveal that except for the case of\na large fronthaul link capacity, soft fronthaul information transfer is\npreferable for CeMm-RANs. \n\n"}
{"id": "1901.07509", "contents": "Title: Single-Server Multi-Message Individually-Private Information Retrieval\n  with Side Information Abstract: We consider a multi-user variant of the private information retrieval problem\ndescribed as follows. Suppose there are $D$ users, each of which wants to\nprivately retrieve a distinct message from a server with the help of a trusted\nagent. We assume that the agent has a random subset of $M$ messages that is not\nknown to the server. The goal of the agent is to collectively retrieve the\nusers' requests from the server. For protecting the privacy of users, we\nintroduce the notion of individual-privacy -- the agent is required to protect\nthe privacy only for each individual user (but may leak some correlations among\nuser requests). We refer to this problem as Individually-Private Information\nRetrieval with Side Information (IPIR-SI).\n  We first establish a lower bound on the capacity, which is defined as the\nmaximum achievable download rate, of the IPIR-SI problem by presenting a novel\nachievability protocol. Next, we characterize the capacity of IPIR-SI problem\nfor $M = 1$ and $D = 2$. In the process of characterizing the capacity for\narbitrary $M$ and $D$ we present a novel combinatorial conjecture, that may be\nof independent interest. \n\n"}
{"id": "1901.07535", "contents": "Title: Neural Decoder for Topological Codes using Pseudo-Inverse of Parity\n  Check Matrix Abstract: Recent developments in the field of deep learning have motivated many\nresearchers to apply these methods to problems in quantum information. Torlai\nand Melko first proposed a decoder for surface codes based on neural networks.\nSince then, many other researchers have applied neural networks to study a\nvariety of problems in the context of decoding. An important development in\nthis regard was due to Varsamopoulos et al. who proposed a two-step decoder\nusing neural networks. Subsequent work of Maskara et al. used the same concept\nfor decoding for various noise models. We propose a similar two-step neural\ndecoder using inverse parity-check matrix for topological color codes. We show\nthat it outperforms the state-of-the-art performance of non-neural decoders for\nindependent Pauli errors noise model on a 2D hexagonal color code. Our final\ndecoder is independent of the noise model and achieves a threshold of $10 \\%$.\nOur result is comparable to the recent work on neural decoder for quantum error\ncorrection by Maskara et al.. It appears that our decoder has significant\nadvantages with respect to training cost and complexity of the network for\nhigher lengths when compared to that of Maskara et al.. Our proposed method can\nalso be extended to arbitrary dimension and other stabilizer codes. \n\n"}
{"id": "1901.10028", "contents": "Title: Optimal Multiuser Loading in Quantized Massive MIMO under Spatially\n  Correlated Channels Abstract: Low-resolution digital-to-analog converter (DAC) has shown great potential in\nfacilitating cost- and power-efficient implementation of massive multiple-input\nmultiple-output (MIMO) systems. We investigate the performance of a massive\nMIMO downlink network with low-resolution DACs using regularized zero-forcing\n(RZF) precoding. It serves multiple receivers equipped with finite-resolution\nanalog-to-digital converters (ADCs). By taking the quantization errors at both\nthe transmitter and receivers into account under spatially correlated channels,\nthe regularization parameter for RZF is optimized with a closed-form solution\nby applying the asymptotic random matrix theory. The optimal regularization\nparameter increases linearly with respect to the user loading ratio while\nindependent of the ADC quantization resolution and the channel correlation.\nFurthermore, asymptotic sum rate performance is characterized and a closed-form\nexpression for the optimal user loading ratio is obtained at low\nsignal-to-noise ratio. The optimal ratio increases with the DAC resolution\nwhile it decreases with the ADC resolution. Numerical simulations verify our\nobservations. \n\n"}
{"id": "cond-mat/0506037", "contents": "Title: Diagnosis of weaknesses in modern error correction codes: a physics\n  approach Abstract: One of the main obstacles to the wider use of the modern error-correction\ncodes is that, due to the complex behavior of their decoding algorithms, no\nsystematic method which would allow characterization of the Bit-Error-Rate\n(BER) is known. This is especially true at the weak noise where many systems\noperate and where coding performance is difficult to estimate because of the\ndiminishingly small number of errors. We show how the instanton method of\nphysics allows one to solve the problem of BER analysis in the weak noise range\nby recasting it as a computationally tractable minimization problem. \n\n"}
{"id": "cs/0411014", "contents": "Title: Rate Distortion and Denoising of Individual Data Using Kolmogorov\n  complexity Abstract: We examine the structure of families of distortion balls from the perspective\nof Kolmogorov complexity. Special attention is paid to the canonical\nrate-distortion function of a source word which returns the minimal Kolmogorov\ncomplexity of all distortion balls containing that word subject to a bound on\ntheir cardinality. This canonical rate-distortion function is related to the\nmore standard algorithmic rate-distortion function for the given distortion\nmeasure. Examples are given of list distortion, Hamming distortion, and\nEuclidean distortion. The algorithmic rate-distortion function can behave\ndifferently from Shannon's rate-distortion function. To this end, we show that\nthe canonical rate-distortion function can and does assume a wide class of\nshapes (unlike Shannon's); we relate low algorithmic mutual information to low\nKolmogorov complexity (and consequently suggest that certain aspects of the\nmutual information formulation of Shannon's rate-distortion function behave\ndifferently than would an analogous formulation using algorithmic mutual\ninformation); we explore the notion that low Kolmogorov complexity distortion\nballs containing a given word capture the interesting properties of that word\n(which is hard to formalize in Shannon's theory) and this suggests an approach\nto denoising; and, finally, we show that the different behavior of the\nrate-distortion curves of individual source words to some extent disappears\nafter averaging over the source words. \n\n"}
{"id": "cs/0412111", "contents": "Title: On the asymptotic accuracy of the union bound Abstract: A new lower bound on the error probability of maximum likelihood decoding of\na binary code on a binary symmetric channel was proved in Barg and McGregor\n(2004, cs.IT/0407011). It was observed in that paper that this bound leads to a\nnew region of code rates in which the random coding exponent is asymptotically\ntight, giving a new region in which the reliability of the BSC is known\nexactly. The present paper explains the relation of these results to the union\nbound on the error probability. \n\n"}
{"id": "cs/0506040", "contents": "Title: A Fixed-Length Coding Algorithm for DNA Sequence Compression Abstract: While achieving a compression ratio of 2.0 bits/base, the new algorithm codes\nnon-N bases in fixed length. It dramatically reduces the time of coding and\ndecoding than previous DNA compression algorithms and some universal\ncompression programs. \n\n"}
{"id": "cs/0511039", "contents": "Title: The Generalized Area Theorem and Some of its Consequences Abstract: There is a fundamental relationship between belief propagation and maximum a\nposteriori decoding. The case of transmission over the binary erasure channel\nwas investigated in detail in a companion paper. This paper investigates the\nextension to general memoryless channels (paying special attention to the\nbinary case). An area theorem for transmission over general memoryless channels\nis introduced and some of its many consequences are discussed. We show that\nthis area theorem gives rise to an upper-bound on the maximum a posteriori\nthreshold for sparse graph codes. In situations where this bound is tight, the\nextrinsic soft bit estimates delivered by the belief propagation decoder\ncoincide with the correct a posteriori probabilities above the maximum a\nposteriori threshold. More generally, it is conjectured that the fundamental\nrelationship between the maximum a posteriori and the belief propagation\ndecoder which was observed for transmission over the binary erasure channel\ncarries over to the general case. We finally demonstrate that in order for the\ndesign rate of an ensemble to approach the capacity under belief propagation\ndecoding the component codes have to be perfectly matched, a statement which is\nwell known for the special case of transmission over the binary erasure\nchannel. \n\n"}
{"id": "cs/0512006", "contents": "Title: Capacity-Achieving Ensembles of Accumulate-Repeat-Accumulate Codes for\n  the Erasure Channel with Bounded Complexity Abstract: The paper introduces ensembles of accumulate-repeat-accumulate (ARA) codes\nwhich asymptotically achieve capacity on the binary erasure channel (BEC) with\n{\\em bounded complexity}, per information bit, of encoding and decoding. It\nalso introduces symmetry properties which play a central role in the\nconstruction of capacity-achieving ensembles for the BEC with bounded\ncomplexity. The results here improve on the tradeoff between performance and\ncomplexity provided by previous constructions of capacity-achieving ensembles\nof codes defined on graphs. The superiority of ARA codes with moderate to large\nblock length is exemplified by computer simulations which compare their\nperformance with those of previously reported capacity-achieving ensembles of\nLDPC and IRA codes. The ARA codes also have the advantage of being systematic. \n\n"}
{"id": "cs/0602072", "contents": "Title: Turbo Decoding on the Binary Erasure Channel: Finite-Length Analysis and\n  Turbo Stopping Sets Abstract: This paper is devoted to the finite-length analysis of turbo decoding over\nthe binary erasure channel (BEC). The performance of iterative\nbelief-propagation (BP) decoding of low-density parity-check (LDPC) codes over\nthe BEC can be characterized in terms of stopping sets. We describe turbo\ndecoding on the BEC which is simpler than turbo decoding on other channels. We\nthen adapt the concept of stopping sets to turbo decoding and state an exact\ncondition for decoding failure. Apply turbo decoding until the transmitted\ncodeword has been recovered, or the decoder fails to progress further. Then the\nset of erased positions that will remain when the decoder stops is equal to the\nunique maximum-size turbo stopping set which is also a subset of the set of\nerased positions. Furthermore, we present some improvements of the basic turbo\ndecoding algorithm on the BEC. The proposed improved turbo decoding algorithm\nhas substantially better error performance as illustrated by the given\nsimulation results. Finally, we give an expression for the turbo stopping set\nsize enumerating function under the uniform interleaver assumption, and an\nefficient enumeration algorithm of small-size turbo stopping sets for a\nparticular interleaver. The solution is based on the algorithm proposed by\nGarello et al. in 2001 to compute an exhaustive list of all low-weight\ncodewords in a turbo code. \n\n"}
{"id": "cs/0602091", "contents": "Title: Feedback Capacity of Stationary Gaussian Channels Abstract: The feedback capacity of additive stationary Gaussian noise channels is\ncharacterized as the solution to a variational problem. Toward this end, it is\nproved that the optimal feedback coding scheme is stationary. When specialized\nto the first-order autoregressive moving average noise spectrum, this\nvariational characterization yields a closed-form expression for the feedback\ncapacity. In particular, this result shows that the celebrated\nSchalkwijk-Kailath coding scheme achieves the feedback capacity for the\nfirst-order autoregressive moving average Gaussian channel, positively\nanswering a long-standing open problem studied by Butman, Schalkwijk-Tiernan,\nWolfowitz, Ozarow, Ordentlich, Yang-Kavcic-Tatikonda, and others. More\ngenerally, it is shown that a k-dimensional generalization of the\nSchalkwijk-Kailath coding scheme achieves the feedback capacity for any\nautoregressive moving average noise spectrum of order k. Simply put, the\noptimal transmitter iteratively refines the receiver's knowledge of the\nintended message. \n\n"}
{"id": "cs/0603095", "contents": "Title: A Turbo Coding System for High Speed Communications Abstract: Conventional turbo codes (CTCs) usually employ a block-oriented interleaving\nso that each block is separately encoded and decoded. As interleaving and\nde-interleaving are performed within a block, the message-passing process\nassociated with an iterative decoder is limited to proceed within the\ncorresponding range. This paper presents a new turbo coding scheme that uses a\nspecial interleaver structure and a multiple-round early termination test\ninvolving both sign check and a CRC code. The new interleaver structure is\nnaturally suited for high speed parallel processing and the resulting coding\nsystem offers new design options and tradeoffs that are not available to CTCs.\nIn particular, it becomes possible for the decoder to employ an efficient\ninter-block collaborative decoding algorithm, passing the information obtained\nfrom termination test proved blocks to other unproved blocks. It also becomes\nimportant to have a proper decoding schedule. The combined effect is improved\nperformance and reduction in the average decoding delay (whence the required\ncomputing power). A memory (storage) management mechanism is included as a\ncritical part of the decoder so as to provide additional design tradeoff\nbetween performance and memory size. It is shown that the latter has a\nmodular-like effect in that additional memory units render enhanced performance\ndue not only to less forced early terminations but to possible increases of the\ninterleaving depth. Depending on the decoding schedule, the degree of\nparallelism and other decoding resources available, the proposed scheme admits\na variety of decoder architectures that meet a large range of throughput and\nperformance demands. \n\n"}
{"id": "cs/0603123", "contents": "Title: Towards the Optimal Amplify-and-Forward Cooperative Diversity Scheme Abstract: In a slow fading channel, how to find a cooperative diversity scheme that\nachieves the transmit diversity bound is still an open problem. In fact, all\npreviously proposed amplify-and-forward (AF) and decode-and-forward (DF)\nschemes do not improve with the number of relays in terms of the diversity\nmultiplexing tradeoff (DMT) for multiplexing gains r higher than 0.5. In this\nwork, we study the class of slotted amplify-and-forward (SAF) schemes. We first\nestablish an upper bound on the DMT for any SAF scheme with an arbitrary number\nof relays N and number of slots M. Then, we propose a sequential SAF scheme\nthat can exploit the potential diversity gain in the high multiplexing gain\nregime. More precisely, in certain conditions, the sequential SAF scheme\nachieves the proposed DMT upper bound which tends to the transmit diversity\nbound when M goes to infinity. In particular, for the two-relay case, the\nthree-slot sequential SAF scheme achieves the proposed upper bound and\noutperforms the two-relay non-orthorgonal amplify-and-forward (NAF) scheme of\nAzarian et al. for multiplexing gains r < 2/3. Numerical results reveal a\nsignificant gain of our scheme over the previously proposed AF schemes,\nespecially in high spectral efficiency and large network size regime. \n\n"}
{"id": "cs/0607095", "contents": "Title: Gallager's Exponent for MIMO Channels: A Reliability-Rate Tradeoff Abstract: In this paper, we derive Gallager's random coding error exponent for\nmultiple-input multiple-output (MIMO) channels, assuming no channel-state\ninformation (CSI) at the transmitter and perfect CSI at the receiver. This\nmeasure gives insight into a fundamental tradeoff between the communication\nreliability and information rate of MIMO channels, enabling to determine the\nrequired codeword length to achieve a prescribed error probability at a given\nrate below the channel capacity. We quantify the effects of the number of\nantennas, channel coherence time, and spatial fading correlation on the MIMO\nexponent. In addition, general formulae for the ergodic capacity and the cutoff\nrate in the presence of spatial correlation are deduced from the exponent\nexpressions. These formulae are applicable to arbitrary structures of transmit\nand receive correlation, encompassing all the previously known results as\nspecial cases of our expressions. \n\n"}
{"id": "cs/0609148", "contents": "Title: Pseudo-Codeword Performance Analysis for LDPC Convolutional Codes Abstract: Message-passing iterative decoders for low-density parity-check (LDPC) block\ncodes are known to be subject to decoding failures due to so-called\npseudo-codewords. These failures can cause the large signal-to-noise ratio\nperformance of message-passing iterative decoding to be worse than that\npredicted by the maximum-likelihood decoding union bound. In this paper we\naddress the pseudo-codeword problem from the convolutional-code perspective. In\nparticular, we compare the performance of LDPC convolutional codes with that of\ntheir ``wrapped'' quasi-cyclic block versions and we show that the minimum\npseudo-weight of an LDPC convolutional code is at least as large as the minimum\npseudo-weight of an underlying quasi-cyclic code. This result, which parallels\na well-known relationship between the minimum Hamming weight of convolutional\ncodes and the minimum Hamming weight of their quasi-cyclic counterparts, is due\nto the fact that every pseudo-codeword in the convolutional code induces a\npseudo-codeword in the block code with pseudo-weight no larger than that of the\nconvolutional code's pseudo-codeword. This difference in the weight spectra\nleads to improved performance at low-to-moderate signal-to-noise ratios for the\nconvolutional code, a conclusion supported by simulation results. \n\n"}
{"id": "cs/0610047", "contents": "Title: Capacity of the Trapdoor Channel with Feedback Abstract: We establish that the feedback capacity of the trapdoor channel is the\nlogarithm of the golden ratio and provide a simple communication scheme that\nachieves capacity. As part of the analysis, we formulate a class of dynamic\nprograms that characterize capacities of unifilar finite-state channels. The\ntrapdoor channel is an instance that admits a simple analytic solution. \n\n"}
{"id": "cs/0612012", "contents": "Title: Geographic Gossip on Geometric Random Graphs via Affine Combinations Abstract: In recent times, a considerable amount of work has been devoted to the\ndevelopment and analysis of gossip algorithms in Geometric Random Graphs. In a\nrecently introduced model termed \"Geographic Gossip,\" each node is aware of its\nposition but possesses no further information. Traditionally, gossip protocols\nhave always used convex linear combinations to achieve averaging. We develop a\nnew protocol for Geographic Gossip, in which counter-intuitively, we use {\\it\nnon-convex affine combinations} as updates in addition to convex combinations\nto accelerate the averaging process. The dependence of the number of\ntransmissions used by our algorithm on the number of sensors $n$ is $n\n\\exp(O(\\log \\log n)^2) = n^{1 + o(1)}$. For the previous algorithm, this\ndependence was $\\tilde{O}(n^{1.5})$. The exponent 1+ o(1) of our algorithm is\nasymptotically optimal. Our algorithm involves a hierarchical structure of\n$\\log \\log n$ depth and is not completely decentralized. However, the extent of\ncontrol exercised by a sensor on another is restricted to switching the other\non or off. \n\n"}
{"id": "cs/0701038", "contents": "Title: Approximate Eigenstructure of LTV Channels with Compactly Supported\n  Spreading Abstract: In this article we obtain estimates on the approximate eigenstructure of\nchannels with a spreading function supported only on a set of finite measure\n$|U|$.Because in typical application like wireless communication the spreading\nfunction is a random process corresponding to a random Hilbert--Schmidt channel\noperator $\\BH$ we measure this approximation in terms of the ratio of the\n$p$--norm of the deviation from variants of the Weyl symbol calculus to the\n$a$--norm of the spreading function itself. This generalizes recent results\nobtained for the case $p=2$ and $a=1$. We provide a general approach to this\ntopic and consider then operators with $|U|<\\infty$ in more detail. We show the\nrelation to pulse shaping and weighted norms of ambiguity functions. Finally we\nderive several necessary conditions on $|U|$, such that the approximation error\nis below certain levels. \n\n"}
{"id": "cs/0701084", "contents": "Title: Pseudo-codeword Landscape Abstract: We discuss the performance of Low-Density-Parity-Check (LDPC) codes decoded\nby means of Linear Programming (LP) at moderate and large\nSignal-to-Noise-Ratios (SNR). Utilizing a combination of the previously\nintroduced pseudo-codeword-search method and a new \"dendro\" trick, which allows\nus to reduce the complexity of the LP decoding, we analyze the dependence of\nthe Frame-Error-Rate (FER) on the SNR. Under Maximum-A-Posteriori (MAP)\ndecoding the dendro-code, having only checks with connectivity degree three,\nperforms identically to its original code with high-connectivity checks. For a\nnumber of popular LDPC codes performing over the Additive-White-Gaussian-Noise\n(AWGN) channel we found that either an error-floor sets at a relatively low\nSNR, or otherwise a transient asymptote, characterized by a faster decay of FER\nwith the SNR increase, precedes the error-floor asymptote. We explain these\nregimes in terms of the pseudo-codeword spectra of the codes. \n\n"}
{"id": "cs/0701086", "contents": "Title: Loop Calculus and Belief Propagation for q-ary Alphabet: Loop Tower Abstract: Loop Calculus introduced in [Chertkov, Chernyak '06] constitutes a new\ntheoretical tool that explicitly expresses the symbol Maximum-A-Posteriori\n(MAP) solution of a general statistical inference problem via a solution of the\nBelief Propagation (BP) equations. This finding brought a new significance to\nthe BP concept, which in the past was thought of as just a loop-free\napproximation. In this paper we continue a discussion of the Loop Calculus. We\nintroduce an invariant formulation which allows to generalize the Loop Calculus\napproach to a q-are alphabet. \n\n"}
{"id": "cs/0701123", "contents": "Title: Feasible Depth Abstract: This paper introduces two complexity-theoretic formulations of Bennett's\nlogical depth: finite-state depth and polynomial-time depth. It is shown that\nfor both formulations, trivial and random infinite sequences are shallow, and a\nslow growth law holds, implying that deep sequences cannot be created easily\nfrom shallow sequences. Furthermore, the E analogue of the halting language is\nshown to be polynomial-time deep, by proving a more general result: every\nlanguage to which a nonnegligible subset of E can be reduced in uniform\nexponential time is polynomial-time deep. \n\n"}
{"id": "cs/0702018", "contents": "Title: Estimation of the Rate-Distortion Function Abstract: Motivated by questions in lossy data compression and by theoretical\nconsiderations, we examine the problem of estimating the rate-distortion\nfunction of an unknown (not necessarily discrete-valued) source from empirical\ndata. Our focus is the behavior of the so-called \"plug-in\" estimator, which is\nsimply the rate-distortion function of the empirical distribution of the\nobserved data. Sufficient conditions are given for its consistency, and\nexamples are provided to demonstrate that in certain cases it fails to converge\nto the true rate-distortion function. The analysis of its performance is\ncomplicated by the fact that the rate-distortion function is not continuous in\nthe source distribution; the underlying mathematical problem is closely related\nto the classical problem of establishing the consistency of maximum likelihood\nestimators. General consistency results are given for the plug-in estimator\napplied to a broad class of sources, including all stationary and ergodic ones.\nA more general class of estimation problems is also considered, arising in the\ncontext of lossy data compression when the allowed class of coding\ndistributions is restricted; analogous results are developed for the plug-in\nestimator in that case. Finally, consistency theorems are formulated for\nmodified (e.g., penalized) versions of the plug-in, and for estimating the\noptimal reproduction distribution. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "math/0509325", "contents": "Title: On $Z_{2^k}$-Dual Binary Codes Abstract: A new generalization of the Gray map is introduced. The new generalization\n$\\Phi: Z_{2^k}^n \\to Z_{2}^{2^{k-1}n}$ is connected with the known generalized\nGray map $\\phi$ in the following way: if we take two dual linear\n$Z_{2^k}$-codes and construct binary codes from them using the generalizations\n$\\phi$ and $\\Phi$ of the Gray map, then the weight enumerators of the binary\ncodes obtained will satisfy the MacWilliams identity. The classes of\n$Z_{2^k}$-linear Hadamard codes and co-$Z_{2^k}$-linear extended 1-perfect\ncodes are described, where co-$Z_{2^k}$-linearity means that the code can be\nobtained from a linear $Z_{2^k}$-code with the help of the new generalized Gray\nmap. Keywords: Gray map, Hadamard codes, MacWilliams identity, perfect codes,\n$Z_{2^k}$-linearity \n\n"}
{"id": "math/9910175", "contents": "Title: Polynomial method in coding and information theory Abstract: Polynomial, or Delsarte's, method in coding theory accounts for a variety of\nstructural results on, and bounds on the size of, extremal configurations\n(codes and designs) in various metric spaces. In recent works of the authors\nthe applicability of the method was extended to cover a wider range of problems\nin coding and information theory. In this paper we present a general framework\nfor the method which includes previous results as particular cases. We explain\nhow this generalization leads to new asymptotic bounds on the performance of\ncodes in binary-input memoryless channels and the Gaussian channel, which\nimprove the results of Shannon et al. of 1959-67, and to a number of other\nresults in combinatorial coding theory. \n\n"}
{"id": "quant-ph/0501159", "contents": "Title: Implausible Consequences of Superstrong Nonlocality Abstract: This Letter looks at the consequences of so-called 'superstrong nonlocal\ncorrelations', which are hypothetical violations of Bell/CHSH inequalities that\nare stronger than quantum mechanics allows, yet weak enough to prohibit\nfaster-than-light communication. It is shown that the existence of maximally\nsuperstrong correlated bits implies that all distributed computations can be\nperformed with a trivial amount of communication, i.e. with one bit. If one\nbelieves that Nature does not allow such a computational 'free lunch', then the\nresult in the Letter gives a reason why superstrong correlation are indeed not\npossible. \n\n"}
{"id": "quant-ph/0603135", "contents": "Title: Interaction in Quantum Communication Abstract: In some scenarios there are ways of conveying information with many fewer,\neven exponentially fewer, qubits than possible classically. Moreover, some of\nthese methods have a very simple structure--they involve only few message\nexchanges between the communicating parties. It is therefore natural to ask\nwhether every classical protocol may be transformed to a ``simpler'' quantum\nprotocol--one that has similar efficiency, but uses fewer message exchanges.\n  We show that for any constant k, there is a problem such that its k+1 message\nclassical communication complexity is exponentially smaller than its k message\nquantum communication complexity. This, in particular, proves a round hierarchy\ntheorem for quantum communication complexity, and implies, via a simple\nreduction, an Omega(N^{1/k}) lower bound for k message quantum protocols for\nSet Disjointness for constant k.\n  Enroute, we prove information-theoretic lemmas, and define a related measure\nof correlation, the informational distance, that we believe may be of\nsignificance in other contexts as well. \n\n"}
{"id": "quant-ph/0703113", "contents": "Title: Quantum Convolutional BCH Codes Abstract: Quantum convolutional codes can be used to protect a sequence of qubits of\narbitrary length against decoherence. We introduce two new families of quantum\nconvolutional codes. Our construction is based on an algebraic method which\nallows to construct classical convolutional codes from block codes, in\nparticular BCH codes. These codes have the property that they contain their\nEuclidean, respectively Hermitian, dual codes. Hence, they can be used to\ndefine quantum convolutional codes by the stabilizer code construction. We\ncompute BCH-like bounds on the free distances which can be controlled as in the\ncase of block codes, and establish that the codes have non-catastrophic\nencoders. \n\n"}
