{"id": "0704.3684", "contents": "Title: Dynamics of Quantum Dot Nuclear Spin Polarization Controlled by a Single\n  Electron Abstract: We present an experimental study of the dynamics underlying the buildup and\ndecay of dynamical nuclear spin polarization in a single semiconductor quantum\ndot. Our experiment shows that the nuclei can be polarized on a time scale of a\nfew milliseconds, while their decay dynamics depends drastically on external\nparameters. We show that a single electron can very efficiently depolarize the\nnuclear spins and discuss two processes that can cause this depolarization.\nConversely, in the absence of a quantum dot electron, the lifetime of nuclear\nspin polarization is on the time scale of a second, most likely limited by the\nnon-secular terms of the nuclear dipole-dipole interaction. We can further\nsuppress this depolarization rate by 1-2 orders of magnitude by applying an\nexternal magnetic field exceeding 1 mT. \n\n"}
{"id": "0705.1718", "contents": "Title: Cosmological Constraints from Type Ia Supernovae Peculiar Velocity\n  Measurements Abstract: We detect the correlated peculiar velocities of nearby type Ia supernovae\n(SNe), while highlighting an error in some of the literature. We find\nsigma_8=0.79 +/- 0.22 from SNe, and examine the potential of this method to\nconstrain cosmological parameters in the future. We demonstrate that a survey\nof 300 low-z SNe (such as the nearby SNfactory) will underestimate the errors\non w by about 35% if the coherent peculiar velocities are not included. \n\n"}
{"id": "0705.3547", "contents": "Title: Electrical coherent control of nuclear spins in a breakdown regime of\n  quantum Hall effect Abstract: Using a conventional Hall-bar geometry with a micro-metal strip on top of the\nsurface, we demonstrate an electrical coherent control of nuclear spins in an\nAlGaAs/GaAs semiconductor heterostructure. A breakdown of integer quantum Hall\n(QH) effect is utilized to dynamically polarize nuclear spins. By applying a\npulse rf magnetic field with the metal strip, the quantum state of the nuclear\nspins shows Rabi oscillations, which is detected by measuring longitudinal\nvoltage of the QH conductor. \n\n"}
{"id": "0706.1367", "contents": "Title: Anharmonic behavior in Microwave-driven resistivity oscillations in Hall\n  bars Abstract: We analyzed the magnetoresistivity of a two-dimensional electron system\nexcited by microwave radiation in a regime of high intensities and low\nfrequencies. In such a regime, recent experiments show that different features\nappear in the magnetoresistivity response which suggest an anharmonic behavior.\nThese features consist mainly in distorted oscillations and new resonance peaks\nat the subharmonics of the cyclotron frequency. We follow the model of\nmicrowave-driven electron orbits motion which become anharmonic when the ratio\nof microwave intensity to microwave frequency is large enough. \n\n"}
{"id": "0706.2607", "contents": "Title: Kinematic effect in gravitational lensing by clusters of galaxies Abstract: Gravitational lensing provides an efficient tool for the investigation of\nmatter structures, independent of the dynamical or hydrostatic equilibrium\nproperties of the deflecting system. However, it depends on the kinematic\nstatus. In fact, either a translational motion or a coherent rotation of the\nmass distribution can affect the lensing properties. Here, light deflection by\ngalaxy clusters in motion is considered. Even if gravitational lensing mass\nmeasurements of galaxy clusters are regarded as very reliable estimates, the\nkinematic effect should be considered. A typical peculiar motion with respect\nto the Hubble flow brings about a systematic error < 0.3%, independent of the\nmass of the cluster. On the other hand, the effect of the spin increases with\nthe total mass. For cluster masses ~ 10^{15}M_{sun}, the effect of the\ngravitomagnetic term is < 0.04% on strong lensing estimates and < 0.5% in the\nweak lensing analyses. The total kinematic effect on the mass estimate is then\n< 1%, which is negligible in current statistical studies. In the weak lensing\nregime, the rotation imprints a typical angular modulation in the tangential\nshear distortion. This would allow in principle a detection of the\ngravitomagnetic field and a direct measurement of the angular velocity of the\ncluster but the required background source densities are well beyond current\ntecnological capabilities. \n\n"}
{"id": "0706.3060", "contents": "Title: N-Body Simulations on GPUs Abstract: Commercial graphics processors (GPUs) have high compute capacity at very low\ncost, which makes them attractive for general purpose scientific computing. In\nthis paper we show how graphics processors can be used for N-body simulations\nto obtain improvements in performance over current generation CPUs. We have\ndeveloped a highly optimized algorithm for performing the O(N^2) force\ncalculations that constitute the major part of stellar and molecular dynamics\nsimulations. In some of the calculations, we achieve sustained performance of\nnearly 100 GFlops on an ATI X1900XTX. The performance on GPUs is comparable to\nspecialized processors such as GRAPE-6A and MDGRAPE-3, but at a fraction of the\ncost. Furthermore, the wide availability of GPUs has significant implications\nfor cluster computing and distributed computing efforts like Folding@Home. \n\n"}
{"id": "0707.1023", "contents": "Title: Screening of a hypercritical charge in graphene Abstract: Screening of a large external charge in graphene is studied. The charge is\nassumed to be displaced away or smeared over a finite region of the graphene\nplane. The initial decay of the screened potential with distance is shown to\nfollow the 3/2 power. It gradually changes to the Coulomb law outside of a\nhypercritical core whose radius is proportional to the external charge. \n\n"}
{"id": "0708.0522", "contents": "Title: Quasi-stationary distributions as centrality measures of reducible\n  graphs Abstract: Random walk can be used as a centrality measure of a directed graph. However,\nif the graph is reducible the random walk will be absorbed in some subset of\nnodes and will never visit the rest of the graph. In Google PageRank the\nproblem was solved by introduction of uniform random jumps with some\nprobability. Up to the present, there is no clear criterion for the choice this\nparameter. We propose to use parameter-free centrality measure which is based\non the notion of quasi-stationary distribution. Specifically we suggest four\nquasi-stationary based centrality measures, analyze them and conclude that they\nproduce approximately the same ranking. The new centrality measures can be\napplied in spam detection to detect ``link farms'' and in image search to find\nphoto albums. \n\n"}
{"id": "0708.1124", "contents": "Title: Warp diffusion in accretion discs: a numerical investigation Abstract: In this paper we explore numerically the evolution of a warped accretion\ndisc. Here, we focus here on the regime where the warp evolves diffusively. By\ncomparing the numerical results to a simple diffusion model, we are able to\ndetermine the diffusion coefficient of the warp, $\\alpha_2$, as a function of\nthe relevant disc parameters. We find that while in general the disc behaviour\nis well reproduced by the diffusion model and for relatively large viscosities\nthe warp diffusion is well described by the linear theory (in particular\nconfirming that the warp diffusion coefficient is inversely proportional to\nviscosity), significant non-linear effects are present as the viscosity becomes\nsmaller, but still dominates over wave-propagation effects. In particular, we\nfind that the inverse dependence of the diffusion coefficient on viscosity\nbreaks down at low viscosities, so that $\\alpha_2$ never becomes larger than a\nsaturation value $\\alpha_{\\rm max}$ of order unity. This can have major\nconsequences in the evolution of systems where a warped disc is present. In\nparticular, it affects the location of the warp radius in the Bardeen-Petterson\neffect and therefore the spin up (or spin down) of supermassive black holes in\nthe nuclei of galaxies. Additionally, we also find that while the rate of warp\ndiffusion does not depend significantly on the detailed viscosity formulation,\nthe rate of internal precession generated by the warp is strongly affected by\nit. Such effects should be considered with care when modeling the evolution of\nwarped discs. This emphasises the need to test the above results using\ndifferent numerical schemes, and with higher resolution, in order to\ninvestigate the degree to which numerical simulations are able to provide\naccurate modeling of the complex fluid dynamics of warped discs. (Abridged) \n\n"}
{"id": "0708.3338", "contents": "Title: Ergodic properties of a class of non-Markovian processes Abstract: We study a fairly general class of time-homogeneous stochastic evolutions\ndriven by noises that are not white in time. As a consequence, the resulting\nprocesses do not have the Markov property. In this setting, we obtain\nconstructive criteria for the uniqueness of stationary solutions that are very\nclose in spirit to the existing criteria for Markov processes.\n  In the case of discrete time, where the driving noise consists of a\nstationary sequence of Gaussian random variables, we give optimal conditions on\nthe spectral measure for our criteria to be applicable. In particular, we show\nthat under a certain assumption on the spectral density, our assumptions can be\nchecked in virtually the same way as one would check that the Markov process\nobtained by replacing the driving sequence by a sequence of independent\nidentically distributed Gaussian random variables is strong Feller and\ntopologically irreducible. The results of the present article are based on\nthose obtained previously in the continuous time context of diffusions driven\nby fractional Brownian motion. \n\n"}
{"id": "0709.0333", "contents": "Title: Dynamic nuclear polarisation in biased quantum wires with spin-orbit\n  interaction Abstract: We propose a new method for dynamic nuclear polarisation in a quasi\none-dimensional quantum wire utilising the spin-orbit interaction, the\nhyperfine interaction, and a finite source-drain potential difference. In\ncontrast with current methods, our scheme does not rely on external magnetic or\noptical sources which makes independent control of closely placed devices much\nmore feasible. Using this method, a significant polarisation of a few per cent\nis possible in currently available InAs wires which may be detected by\nconductance measurements. This may prove useful for nuclear-magnetic-resonance\nstudies in nanoscale systems as well as in spin-based devices where external\nmagnetic and optical sources will not be suitable. \n\n"}
{"id": "0709.2301", "contents": "Title: Constraints on decaying Dark Matter from XMM-Newton observations of M31 Abstract: We derive constraints on parameters of the radiatively decaying Dark Matter\n(DM) particles, using XMM-Newton EPIC spectra of the Andromeda galaxy (M31).\nUsing the observations of the outer (5'-13') parts of M31 we improve the\nexisting constraints. For the case of sterile neutrino DM, combining our\nconstraints with the latest computation of abundances of sterile neutrino in\nthe Dodelson-Widrow (DW) scenario, we obtain the lower mass limit m_s < 4 keV,\nwhich is stronger than the previous one m_s < 6 kev, obtained recently by Asaka\net al. (2007) [hep-ph/0612182]. Comparing this limit with the most recent\nresults on Lyman-alpha forest analysis of Viel et al. (2007) [arXiv:0709.0131]\n(m_s > 5.6 kev), we argue that the scenario in which all the DM is produced via\nDW mechanism is ruled out. We discuss however other production mechanisms and\nnote that the sterile neutrino remains a viable candidate of Dark Matter,\neither warm or cold. \n\n"}
{"id": "0710.1565", "contents": "Title: Ballistic Transport at Uniform Temperature Abstract: A paradigm for isothermal, mechanical rectification of stochastic\nfluctuations is introduced in this paper. The central idea is to transform\nenergy injected by random perturbations into rigid-body rotational kinetic\nenergy. The prototype considered in this paper is a mechanical system\nconsisting of a set of rigid bodies in interaction through magnetic fields. The\nsystem is stochastically forced by white noise and dissipative through\nmechanical friction. The Gibbs-Boltzmann distribution at a specific temperature\ndefines the unique invariant measure under the flow of this stochastic process\nand allows us to define ``the temperature'' of the system. This measure is also\nergodic and weakly mixing. Although the system does not exhibit global directed\nmotion, it is shown that global ballistic motion is possible (the mean-squared\ndisplacement grows like t squared). More precisely, although work cannot be\nextracted from thermal energy by the second law of thermodynamics, it is shown\nthat ballistic transport from thermal energy is possible. In particular, the\ndynamics is characterized by a meta-stable state in which the system exhibits\ndirected motion over random time scales. This phenomenon is caused by\ninteraction of three attributes of the system: a non flat (yet bounded)\npotential energy landscape, a rigid body effect (coupling translational\nmomentum and angular momentum through friction) and the degeneracy of the\nnoise/friction tensor on the momentums (the fact that noise is not applied to\nall degrees of freedom). \n\n"}
{"id": "0710.2336", "contents": "Title: Constraints on mSUGRA through entropy and abundance criteria Abstract: We derive an expression for the entropy of a present dark matter halo\ndescribed by a Navarro-Frenk-White modified model with a central core. The\ncomparison of this entropy with the one of the halo at the freeze-out era\nallows us to obtain an expression for the relic abundance of neutralinos, which\nin turn is used to constrain the parameter space in mSUGRA models, when used\nwith the WMAP observations. Moreover, by joning these results with the ones\nobtained from the usual abundance criteria, we are able to clearly discriminate\nvalidity regions among tan beta values of the mSUGRA model, by demanding both\ncriteria to be consistent with the 2 sigma bounds of the WMAP observations for\nthe relic density: 0.112 < Omega h^2 < 0.122. We found that for sign mu\npositive, small values of tan beta are not favored; only for tan beta ~ 50 are\nboth criteria significantly consistent. The use of both criteria also allows us\nto put a lower bound on the neutralino mass of > 151 GeV. \n\n"}
{"id": "0710.3415", "contents": "Title: Modified gravity and the origin of inertia Abstract: Modified gravity theory is known to violate Birkhoff's theorem. We explore a\nkey consequence of this violation, the effect of distant matter in the Universe\non the motion of test particles. We find that when a particle is accelerated, a\nforce is experienced that is proportional to the particle's mass and\nacceleration and acts in the direction opposite to that of the acceleration. We\nidentify this force with inertia. At very low accelerations, our inertial law\ndeviates slightly from that of Newton, yielding a testable prediction that may\nbe verified with relatively simple experiments. Our conclusions apply to all\ngravity theories that reduce to a Yukawa-like force in the weak field\napproximation. \n\n"}
{"id": "0710.4928", "contents": "Title: Quantum Hall effect in graphene: A functional determinant approach Abstract: We start the paper with a brief presentation of the main characteristics of\ngraphene, and of the Dirac theory of massless fermions in 2+1 dimensions\nobtained as the associated low-momentum effective theory, in the absence of\nexternal fields. We then summarize the main steps needed to obtain the Hall\nconductivity in the effective theory at finite temperature and density, with\nemphasis on its dependence on the phase of the Dirac determinant selected\nduring the evaluation of the effective action. Finally, we discuss the\nbehavior, under gauge transformations, of the contribution due to the lowest\nLandau level, and interpret gauge transformations as rotations of the\ncorresponding spinors around the magnetic field. \n\n"}
{"id": "0711.0180", "contents": "Title: Recalibration of Data in the VDFS Science Archives Abstract: The VDFS comprises the system to pipeline process and archive the data from\ninfrared observations taken by both the WFCAM instrument on UKIRT and the\nforthcoming VISTA telescope. These include the largest near-IR surveys to date,\nsuch as UKIDSS, which produce terabyte sized catalogues of over 10^9 rows. Such\nlarge data volumes present a performance challenge when the catalogue data,\nstored in a relational database, require many iterations of astrometric and\nphotometric recalibration. Here we present the VDFS recalibration solution that\nwill be employed in the WSA from the forthcoming UKIDSS Data Release 4 and VSA\nfrom its inception. \n\n"}
{"id": "0711.1249", "contents": "Title: Contributions to Random Energy Models Abstract: In this thesis, we consider several Random Energy Models. This includes\nDerrida's Random Energy Model (REM) and Generalized Random Energy Model (GREM)\nand a nonhierarchical version (BK-GREM) by Bolthausen and Kistler. The limiting\nfree energy in all these models along with Word GREM, a model proposed by us,\nturn out to be a cute consequence of large deviation principle (LDP). This LDP\nargument allows us to consider non-Gaussian driving distributions as well as\nexternal field. We could also consider random trees as the underlying tree\nstructure in GREM. In all these models, as expected, limiting free energy is\nnot 'universal' unlike the SK model. However it is 'rate specific'.\nConsideration of non-Gaussian driving distribution as well as different driving\ndistributions for the different levels of the underlying trees in GREM leads to\ninteresting phenomena. For example in REM, if the Hamiltonian is Binomial with\nparameter $N$ and $p$ then the existence of phase transition depends on the\nparameter $p$. More precisely, phase transition takes place only when\n$p>{1/2}$. For another example, consider a 2 level GREM with exponential\ndriving distribution at the first level and Gaussian in the second with equal\nweights at both the levels. Then even if the limiting ratio for the second\nlevel particles, $p_2$ is 0.00001 (very small), the system reduces to a\nGaussian REM. On the other hand, if we consider a 2 level GREM with Gaussian\ndriving distribution at the first level and exponential in the second, the\nsystem will never reduce to a Gaussian REM. In either case, the system will\nnever reduce to that of an exponential REM. etc. \n\n"}
{"id": "0711.2618", "contents": "Title: A System for Distributed Mechanisms: Design, Implementation and\n  Applications Abstract: We describe here a structured system for distributed mechanism design\nappropriate for both Intranet and Internet applications. In our approach the\nplayers dynamically form a network in which they know neither their neighbours\nnor the size of the network and interact to jointly take decisions. The only\nassumption concerning the underlying communication layer is that for each pair\nof processes there is a path of neighbours connecting them. This allows us to\ndeal with arbitrary network topologies.\n  We also discuss the implementation of this system which consists of a\nsequence of layers. The lower layers deal with the operations that implement\nthe basic primitives of distributed computing, namely low level communication\nand distributed termination, while the upper layers use these primitives to\nimplement high level communication among players, including broadcasting and\nmulticasting, and distributed decision making.\n  This yields a highly flexible distributed system whose specific applications\nare realized as instances of its top layer. This design is implemented in Java.\n  The system supports at various levels fault-tolerance and includes a\nprovision for distributed policing the purpose of which is to exclude\n`dishonest' players. Also, it can be used for repeated creation of dynamically\nformed networks of players interested in a joint decision making implemented by\nmeans of a tax-based mechanism. We illustrate its flexibility by discussing a\nnumber of implemented examples. \n\n"}
{"id": "0712.1776", "contents": "Title: Reflection-Free One-Way Edge Modes in a Gyromagnetic Photonic Crystal Abstract: We point out that electromagnetic one-way edge modes analogous to quantum\nHall edge states, originally predicted by Raghu and Haldane in 2D gyroelectric\nphotonic crystals possessing Dirac point-derived bandgaps, can appear in more\ngeneral settings. In particular, we show that the TM modes in a gyromagnetic\nphotonic crystal can be formally mapped to electronic wavefunctions in a\nperiodic electromagnetic field, so that the only requirement for the existence\nof one-way edge modes is that the Chern number for all bands below a gap is\nnon-zero. In a square-lattice gyromagnetic Yttrium-Iron-Garnet photonic crystal\noperating at microwave frequencies, which lacks Dirac points, time-reversal\nbreaking is strong enough that the effect should be easily observable. For\nrealistic material parameters, the edge modes occupy a 10% band gap. Numerical\nsimulations of a one-way waveguide incorporating this crystal show 100%\ntransmission across strong defects, such as perfect conductors several lattice\nconstants wide, larger than the width of the waveguide. \n\n"}
{"id": "0712.2880", "contents": "Title: The evolution of the mass-metallicity relation at z~3 Abstract: We present preliminary results of an ESO-VLT large programme (AMAZE) aimed at\ndetermining the evolution of the mass-metallicity relation at z~3 by means of\ndeep near-IR spectroscopy. Gas metallicities and stellar masses are measured\nfor an initial sample of nine star forming galaxies at z~3.3. When compared\nwith previous surveys, the mass-metallicity relation inferred at z~3.3 shows an\nevolution significantly stronger than observed at lower redshifts. There are\nalso some indications that the metallicity evolution of low mass galaxies is\nstronger relative to high mass systems, an effect which can be considered as\nthe chemical version of the galaxy downsizing. The mass-metallicity relation\nobserved at z~3.3 is difficult to reconcile with the predictions of some\nhierarchical evolutionary models. We shortly discuss the possible implications\nof such discrepancies. \n\n"}
{"id": "0712.2907", "contents": "Title: STM tunneling through a quantum wire with a side-attached impurity Abstract: The STM tunneling through a quantum wire (QW) with a side-attached impurity\n(atom, island) is investigated using a tight-binding model and the\nnonequilibrium Keldysh Green function method. The impurity can be coupled to\none or more QW atoms. The presence of the impurity strongly modifies the local\ndensity of states of the wire atoms, thus influences the STM tunneling through\nall the wire atoms. The transport properties of the impurity itself are also\ninvestigated mainly as a function of the wire length and the way it is coupled\nto the wire. It is shown that the properties of the impurity itself and the way\nit is coupled to the wire strongly influence the STM tunneling which is\nreflected in the density of states and differential conductance. \n\n"}
{"id": "0712.3779", "contents": "Title: Non-Gaussian Density Fluctuations from Entropically Generated Curvature\n  Perturbations in Ekpyrotic Models Abstract: We analyze the non-gaussian density perturbations generated in\nekpyrotic/cyclic models based on heterotic M-theory. In this picture, two\nscalar fields produce nearly scale-invariant entropic perturbations during an\nekpyrotic phase that are converted into curvature modes {\\it after the\nekpyrotic phase is complete} and just before the big bang. Both intrinsic\nnon-linearity in the entropy perturbation and the conversion process contribute\nto non-gaussianity. The range of the non-gaussianity parameter $f_{NL}$ depends\non how gradual the conversion process is and the steepness of the scalar field\npotential during the ekpyrotic phase. Although a wider range is possible, in\nprinciple, natural values of the ekpyrotic parameters combined with a gradual\nconversion process lead to values of $-60 \\lesssim f_{NL} \\lesssim +80$,\ntypically much greater than slow-roll inflation but within the current\nobservational bounds. \n\n"}
{"id": "0801.4419", "contents": "Title: Spin-Hall effects in a Josephson contact Abstract: The Josephson tunneling through a 2D normal contact with the spin-orbit split\nconduction band has been studied in the diffusive regime. Linearized Usadel\nequations for triplet components of the pairing function revealed a striking\nsimilarity to the equations of spin diffusion driven by the electric field in\nnormal metals. Consequently, we predict that the out-of-plane spin-Hall\npolarization accumulates towards lateral sample edges and the in-plane\npolarization is finite throughout the entire normal region. At the same time,\nthe spin-Hall current is absent in the considered case of the stationary\nJosephson effect. \n\n"}
{"id": "0802.2808", "contents": "Title: Charge-memory polaron effect in molecular junctions Abstract: The charge-memory effect, bistability and switching between charged and\nneutral states of a molecular junction, as observed in recent STM experiments,\nis considered within a minimal polaron model. We show that in the case of\nstrong electron-vibron interaction the rate of spontaneous quantum switching\nbetween charged and neutral states is exponentially suppressed at zero bias\nvoltage but can be tuned through a wide range of finite switching timescales\nupon changing the bias. We further find that, while junctions with symmetric\nvoltage drop give rise to random switching at finite bias, asymmetric junctions\nexhibit hysteretic behavior enabling controlled switching. Lifetimes and\ncharge-voltage curves are calculated by the master equation method for weak\ncoupling to the leads and at stronger coupling by the equation-of-motion method\nfor nonequilibrium Green functions. \n\n"}
{"id": "0803.2816", "contents": "Title: The infrared conductivity of graphene Abstract: We study the infrared conductivity of graphene at finite chemical potential\nand temperature taking into account the effect of phonons and disorder due to\ncharged impurities and unitary scatterers. The screening of the long-range\nCoulomb potential is treated using the random phase approximation coupled to\nthe coherent potential approximation. The effect of the electron-phonon\ncoupling is studied in second-order perturbation theory. The theory has\nessentially one free parameter, namely, the number of charge impurities per\ncarbon, n^{{\\rm C}}_i. We find an anomalous enhancement of the conductivity in\na frequency region that is blocked by Pauli exclusion and an impurity\nbroadening of the conductivity threshold. We also find that phonons induce\nStokes and anti-Stokes lines that produce an excess conductivity, when compared\nto the far infrared value of \\sigma_0 = (\\pi/2) e^2/h. \n\n"}
{"id": "0803.3042", "contents": "Title: Product-form stationary distributions for deficiency zero chemical\n  reaction networks Abstract: We consider stochastically modeled chemical reaction systems with mass-action\nkinetics and prove that a product-form stationary distribution exists for each\nclosed, irreducible subset of the state space if an analogous deterministically\nmodeled system with mass-action kinetics admits a complex balanced equilibrium.\nFeinberg's deficiency zero theorem then implies that such a distribution exists\nso long as the corresponding chemical network is weakly reversible and has a\ndeficiency of zero. The main parameter of the stationary distribution for the\nstochastically modeled system is a complex balanced equilibrium value for the\ncorresponding deterministically modeled system. We also generalize our main\nresult to some non-mass-action kinetics. \n\n"}
{"id": "0803.3762", "contents": "Title: Prospects for cosmic neutrino detection in tritium experiments in the\n  case of hierarchical neutrino masses Abstract: We discuss the effects of neutrino mixing and the neutrino mass hierarchy\nwhen considering the capture of the cosmic neutrino background (CNB) on\nradioactive nuclei. The implications of mixing and hierarchy at future\ngenerations of tritium decay experiments are considered. We find that the CNB\nshould be detectable at these experiments provided that the resolution for the\nkinetic energy of the outgoing electron can be pushed to a few 0.01 eV for the\nscenario with inverted neutrino mass hierarchy, about an order of magnitude\nbetter than that of the upcoming KATRIN experiment. Another order of magnitude\nimprovement is needed in the case of normal neutrino mass hierarchy. We also\nnote that mixing effects generally make the prospects for CNB detection worse\ndue to an increased maximum energy of the normal beta decay background. \n\n"}
{"id": "0804.0299", "contents": "Title: Diffuse stellar emission in X-ray luminous galaxy clusters at z~0.3 I.\n  Is the diffuse optical light boosted and rejuvenated in merging clusters? Abstract: [Abridged] We searched for diffuse stellar emission around BCGs in three of\nthe most X-ray luminous clusters found at z~0.3 in the REFLEX cluster survey\nand observed with XMM-Newton. These systems (RXCJ0014.3-3022, RXCJ0232.2-4420,\nand RXCJ2308.3-0211) are in different dynamical states, as witnessed by their\nX-ray morphology and optical appearence (e.g. multiplicity of BCGs). [Abridged]\nDiffuse stellar emission is robustly detected down to a surface brightness of\n26 R-mag/arcsec^2 (observed frame) around a total of seven BCGs, extending up\nto galactocentric distances of ~100 kpc. In particular, it surrounds a pair of\nBCGs in RXCJ0232.2-4420, while it bridges two BCGs associated with the minor\nsubcomponent of the merging cluster RXCJ0014.3-3022. The diffuse light detected\nat the greatest distances from the BCGs of the rather regular clusters\nRXCJ0232.2-4420 and RXCJ2308.3-0211 follows the ICM distribution. Its B-R\ncolour is consistent with the colours measured within the BCG effective radii.\nThe diffuse light around the two pairs of BCGs in RXCJ0014.3-3022 exhibits\nbluer colours than the BCG central regions by up to 0.5 mag. If the\ncontribution of the intracluster light (ICL) to the detected diffuse light\naround BCGs is not negligible, ICL and BCGs have similar stellar populations in\nrelatively relaxed clusters. Merging on a cluster scale eventually adds\ngravitational stresses to BCGs and other galaxies in subcluster cores. This\nevent may affect the properties of the diffuse stellar emission around BCGs.\nShredding of star-forming, low-metallicity dwarf galaxies is favoured as the\ncause of the bluer B-R colours of the diffuse stellar component around the two\npairs of BCGs in the merging cluster RXCJ0014.3-3022. \n\n"}
{"id": "0804.2191", "contents": "Title: Push & Pull: autonomous deployment of mobile sensors for a complete\n  coverage Abstract: Mobile sensor networks are important for several strategic applications\ndevoted to monitoring critical areas. In such hostile scenarios, sensors cannot\nbe deployed manually and are either sent from a safe location or dropped from\nan aircraft. Mobile devices permit a dynamic deployment reconfiguration that\nimproves the coverage in terms of completeness and uniformity.\n  In this paper we propose a distributed algorithm for the autonomous\ndeployment of mobile sensors called Push&Pull. According to our proposal,\nmovement decisions are made by each sensor on the basis of locally available\ninformation and do not require any prior knowledge of the operating conditions\nor any manual tuning of key parameters.\n  We formally prove that, when a sufficient number of sensors are available,\nour approach guarantees a complete and uniform coverage. Furthermore, we\ndemonstrate that the algorithm execution always terminates preventing movement\noscillations.\n  Numerous simulations show that our algorithm reaches a complete coverage\nwithin reasonable time with moderate energy consumption, even when the target\narea has irregular shapes. Performance comparisons between Push&Pull and one of\nthe most acknowledged algorithms show how the former one can efficiently reach\na more uniform and complete coverage under a wide range of working scenarios. \n\n"}
{"id": "0804.3499", "contents": "Title: Contribution of dielectrics to frequency and noise of NbTiN\n  superconducting resonators Abstract: We study NbTiN resonators by measurements of the temperature dependent\nresonance frequency and frequency noise. Additionally, resonators are studied\ncovered with SiOx dielectric layers of various thicknesses. The resonance\nfrequency develops a non-monotonic temperature dependence with increasing SiOx\nlayer thickness. The increase in the noise is independent of the SiOx\nthickness, demonstrating that the noise is not dominantly related to the low\ntemperature resonance frequency deviations. \n\n"}
{"id": "0805.0513", "contents": "Title: Reply to Melott's Comment on ``Discreteness Effects in Lambda Cold Dark\n  Matter Simulations: A Wavelet-Statistical View'' by Romeo et al Abstract: Melott has made pioneering studies of the effects of particle discreteness in\nN-body simulations, a fundamental point that needs careful thought and analysis\nsince all such simulations suffer from numerical noise arising from the use of\nfinite-mass particles. Melott (arXiv:0804.0589) claims that the conclusions of\nour paper (arXiv:0804.0294) are essentially equivalent to those of his earlier\nwork. Melott is wrong: he has jumped onto one of our conclusions and\ninterpreted that in his own way. Here we point out the whys and the wherefores. \n\n"}
{"id": "0805.0708", "contents": "Title: Observation of Very High Energy Gamma Rays from HESS J1804-216 with\n  CANGAROO-III Telescopes Abstract: We observed the unidentified TeV gamma-ray source HESS J1804-216 with the\nCANGAROO-III atmospheric Cerenkov telescopes from May to July in 2006. We\ndetected very high energy gamma rays above 600 GeV at the 10 sigma level in an\neffective exposure of 76 hr. We obtained a differential flux of\n(5.0+/-1.5_{stat}+/-1.6_{sys})\\times 10^{-12}(E/1 TeV)^{-\\alpha}\ncm^{-2}s^{-1}TeV^{-1} with a photon index \\alpha of 2.69 +/- 0.30_{stat} +/-\n0.34_{sys}, which is consistent with that of the H.E.S.S. observation in 2004.\nWe also confirm the extended morphology of the source. By combining our result\nwith multi-wavelength observations, we discuss the possible counterparts of\nHESS J1804-216 and the radiation mechanism based on leptonic and hadronic\nprocesses for a supernova remnant and a pulsar wind nebula. \n\n"}
{"id": "0805.1981", "contents": "Title: P&P protocol: local coordination of mobile sensors for self-deployment Abstract: The use of mobile sensors is of great relevance for a number of strategic\napplications devoted to monitoring critical areas where sensors can not be\ndeployed manually. In these networks, each sensor adapts its position on the\nbasis of a local evaluation of the coverage efficiency, thus permitting an\nautonomous deployment.\n  Several algorithms have been proposed to deploy mobile sensors over the area\nof interest. The applicability of these approaches largely depends on a proper\nformalization of rigorous rules to coordinate sensor movements, solve local\nconflicts and manage possible failures of communications and devices.\n  In this paper we introduce P&P, a communication protocol that permits a\ncorrect and efficient coordination of sensor movements in agreement with the\nPUSH&PULL algorithm. We deeply investigate and solve the problems that may\noccur when coordinating asynchronous local decisions in the presence of an\nunreliable transmission medium and possibly faulty devices such as in the\ntypical working scenario of mobile sensor networks.\n  Simulation results show the performance of our protocol under a range of\noperative settings, including conflict situations, irregularly shaped target\nareas, and node failures. \n\n"}
{"id": "0807.0781", "contents": "Title: The redshift distribution of the X-ray background Abstract: The X-ray background (XRB) is produced by a large number of faint sources\ndistributed over a wide range of redshifts. The XRB carries information on the\nspatial distribution and evolution of these sources. The goals of the paper\nare: 1. to determine the redshift distribution of the soft X-ray background\nphotons produced by all types of extragalactic sources, in order to relate\nfluctuations of the background to the large scale structures, 2. to determine\nthe redshift distribution of the soft XRB produced by AGN in order to calculate\nthe evolution of the AGN X-ray luminosity density. A set of major X-ray surveys\nis used to determine the redshift distributions of the X-ray sources selected\nat various flux levels. Simple analytic fits to the data allow us to determine\nthe smooth relationship between the redshift distribution and the source flux.\nThe redshift distribution of the integral XRB flux is obtained by averaging the\nfits over the source counts. It is shown that the distribution of extragalactic\nXRB photons in the 0.5-2 keV band is adequately represented by the function:\ndn/dlog z = 5.24 z^1.52 exp(-z/0.63). The huge voids postulated to explain the\ncold spots in the CMB maps create dips in the total XRB flux. However, the\nexpected magnitude of the effect is comparable to the fluctuation amplitude of\nthe XRB generated by the individual sources contributing to the background. The\ncosmic evolution of the AGN X-ray luminosity density up to redshift of ~5 is\ncalculated in an elegant and straightforward way. Systematic uncertainties of\nthe present method are assessed and shown to be small. At redshift greater than\none the present results could be compared directly with some recent estimates\nobtained in a standard way and the agreement between both methods is very good. \n\n"}
{"id": "0808.0906", "contents": "Title: Divergent resistance at the Dirac point in graphene: Evidence for a\n  transition in a high magnetic field Abstract: We have investigated the behavior of the resistance of graphene at the $n=0$\nLandau Level in an intense magnetic field $H$. Employing a low-dissipation\ntechnique (with power $P<$3 fW), we find that, at low temperature $T$, the\nresistance at the Dirac point $R_0(H)$ undergoes a 1000-fold increase from\n$\\sim$10 k$\\Omega$ to 40 M$\\Omega$ within a narrow interval of field. The\nabruptness of the increase suggests that a transition to an insulating, ordered\nstate occurs at the critical field $H_c$. Results from 5 samples show that\n$H_c$ depends systematically on the disorder, as measured by the offset gate\nvoltage $V_0$. Samples with small $V_0$ display a smaller critical field $H_c$.\nEmpirically, the steep increase in $R_0$ fits acccurately a\nKosterlitz-Thouless-type correlation length over 3 decades. The curves of $R_0$\nvs. $T$ at fixed $H$ approach the thermal-activation form with a gap\n$\\Delta\\sim$15 K as $H\\to H_c^{-}$, consistent with a field-induced insulating\nstate. \n\n"}
{"id": "0809.2541", "contents": "Title: Getting in the Zone for Successful Scalability Abstract: The universal scalability law (USL) is an analytic model used to quantify\napplication scaling. It is universal because it subsumes Amdahl's law and\nGustafson linearized scaling as special cases. Using simulation, we show: (i)\nthat the USL is equivalent to synchronous queueing in a load-dependent machine\nrepairman model and (ii) how USL, Amdahl's law, and Gustafson scaling can be\nregarded as boundaries defining three scalability zones. Typical throughput\nmeasurements lie across all three zones. Simulation scenarios provide deeper\ninsight into queueing effects and thus provide a clearer indication of which\napplication features should be tuned to get into the optimal performance zone. \n\n"}
{"id": "0809.3100", "contents": "Title: On the relationship between BL Lacertae objects and radio galaxies Abstract: We present deep radio images at 1.4 GHz of a large and complete sample of BL\nLacertae objects (BL Lacs) selected from the Deep X-ray Radio Blazar Survey\n(DXRBS). We have observed 24 northern sources with the Very Large Array (VLA)\nin both its A and C configurations and 15 southern sources with the Australia\nTelescope Compact Array (ATCA) in its largest configuration. We find that in\nthe DXRBS, as in the 1-Jy survey, which has a radio flux limit roughly ten\ntimes higher than the DXRBS, a considerable number (about a third) of BL Lacs\ncan be identified with the relativistically beamed counterparts of\nFanaroff-Riley type II (FR II) radio galaxies. We attribute the existence of FR\nII-BL Lacs, which is not accounted for by current unified schemes, to an\ninconsistency in our classification scheme for radio-loud active galactic\nnuclei (AGN). Taking the extended radio power as a suitable measure of\nintrinsic jet power, we find similar average values for low- (LBL) and\nhigh-energy peaked BL Lacs (HBL), contrary to the predictions of the blazar\nsequence. \n\n"}
{"id": "0810.4509", "contents": "Title: Spontaneous clustering in theoretical and some empirical stationary\n  processes Abstract: In a stationary ergodic process, clustering is defined as the tendency of\nevents to appear in series of increased frequency separated by longer breaks.\nSuch behavior, contradicting the theoretical \"unbiased behavior\" with\nexponential distribution of the gaps between appearances, is commonly observed\nin experimental processes and often difficult to explain. In the last section\nwe relate one such empirical example of clustering, in the area of marine\ntechnology. In the theoretical part of the paper we prove, using ergodic theory\nand the notion of category, that clustering (even very strong) is in fact\ntypical for \"rare events\" defined as long cylinder sets in processes generated\nby a finite partition of an arbitrary (infinite aperiodic) ergodic measure\npreserving transformation. \n\n"}
{"id": "0811.1680", "contents": "Title: MAGIC upper limits to the VHE gamma-ray flux of 3C454.3 in high emission\n  state Abstract: We report upper limits to the very high energy flux (E>100 GeV) of the flat\nspectrum radio quasar 3C454.3 (z=0.859) derived by the Cherenkov telescope\nMAGIC during the high states of July/August and November/December 2007. We\ncompare the upper limits derived in both time slots with the available\nquasi-simultaneous MeV-GeV data from the AGILE gamma-ray satellite and\ninterpret the observational results in the context of leptonic emission models.\nThe source was observed with the MAGIC telescope during the active phases of\nJuly-August 2007 and November-December 2007 and the data were analyzed with the\nMAGIC standard analysis tools. For the periods around the ends of July and\nNovember, characterized by the most complete multifrequency coverage, we\nconstructed the spectral energy distributions using our data together with\nnearly simultaneous multifrequency (optical, UV, X-ray and GeV) data. Only\nupper limits can be derived from the MAGIC data. The upper limits, once\ncorrected for the expected absorption by the extragalactic background light,\ntogether with nearly simultaneous multifrequency data, allow us to constrain\nthe spectral energy distribution of 3C454.3. The data are consistent with the\nmodel expectations based on the inverse Compton scattering of the ambient\nphotons from the broad line region by relativistic electrons, which robustly\npredicts a sharp cut-off above 20-30 GeV. \n\n"}
{"id": "0901.0568", "contents": "Title: Diffuse neutrino flux from failed supernovae Abstract: I study the diffuse flux of electron antineutrinos from stellar collapses\nwith direct black hole formation (failed supernovae). This flux is more\nenergetic than that from successful supernovae, and therefore it might\ncontribute substantially to the total diffuse flux above realistic detection\nthresholds. The total flux might be considerably higher than previously\nthought, and approach the sensitivity of SuperKamiokande. For more conservative\nvalues of the parameters, the flux from failed supernovae dominates for\nantineutrino energies above 30-45 MeV, with potential to give an observable\nspectral distortion at Megaton detectors. \n\n"}
{"id": "0902.0711", "contents": "Title: Physics of stars and measurement data Abstract: Astrophysics = the star physics was beginning its development without a\nsupporting of measurement data, which could not be obtained then. Still\nastrophysics exists without this support, although now astronomers collected a\nlot of valuable information. This is the main difference of astrophysics from\nall other branches of physics, for which foundations are measurement data. The\ncreation of the theory of stars, which is based on the astronomical\nmeasurements data, is one of the main goals of modern astrophysics. Below the\nprincipal elements of star physics based on data of astronomical measurements\nare described.\n  The theoretical description of a hot star interior is obtained. It explains\nthe distribution of stars over their masses, mass-radius-temperature and\nmass-luminosity dependencies. The theory of the apsidal rotation of binary\nstars and the spectrum of solar oscillation is considered. All theoretical\npredictions are in a good agreement with the known measurement data, which\nconfirms the validity of this consideration. \n\n"}
{"id": "0902.2590", "contents": "Title: The Case for Deep, Wide-Field Cosmology Abstract: Much of the science case for the next generation of deep, wide-field\noptical/infrared surveys has been driven by the further study of dark energy.\nThis is a laudable goal (and the subject of a companion white paper by Zhan et\nal.). However, one of the most important lessons of the current generation of\nsurveys is that the interesting science questions at the end of the survey are\nquite different than they were when the surveys were being planned. The current\nsurveys succeeded in this evolving terrain by being very general tools that\ncould be applied to a number of very fundamental measurements. Likewise, the\naccessibility of the data enabled the broader cosmological and astronomical\ncommunity to generate more science than the survey collaborations could alone.\nWith that in mind, we should consider some of the basic physical and\ncosmological questions that surveys like LSST and JDEM-Wide will be able to\naddress. \n\n"}
{"id": "0902.3288", "contents": "Title: Origin and evolution of cosmic accelerators - the unique discovery\n  potential of an UHE neutrino telescope: Astronomy Decadal Survey (2010-2020)\n  Science White Paper Abstract: One of the most tantalizing questions in astronomy and astrophysics, namely\nthe origin and the evolution of the cosmic accelerators that produce the\nhighest energy cosmic rays (UHECR), may be best addressed through the\nobservation of ultra high energy (UHE) cosmogenic neutrinos. Neutrinos travel\nfrom their source undeflected by magnetic fields and unimpeded by interactions\nwith the cosmic microwave background. At high energies, neutrinos could be\ndetected in dense, radio frequency (RF) transparent media via the Askaryan\neffect. The abundant cold ice covering the geographic South Pole, with its\nexceptional RF clarity, has been host to several pioneering efforts to develop\nthis approach, including RICE and ANITA. Building on the expertise gained in\nthese efforts, and the infrastructure developed in the construction of the\nIceCube optical Cherenkov observatory, a low-cost array of radio frequency\nantenna stations could be deployed near the Pole to efficiently detect a\nsignificant number of UHE neutrinos with degree scale angular resolution within\nthe next decade. Such an array, if installed in close proximity to IceCube,\ncould allow cross-calibration on a small but invaluable subset of neutrino\nevents detected by both the optical and radio methods. In addition to providing\ncritical information in the identification of the source of UHECRs, such an\nobservatory could also provide a unique probe of long baseline high energy\nneutrino interactions unattainable in any man-made neutrino beam. \n\n"}
{"id": "0903.0694", "contents": "Title: Digital Ecosystems in the Clouds: Towards Community Cloud Computing Abstract: Cloud Computing is rising fast, with its data centres growing at an\nunprecedented rate. However, this has come with concerns of privacy, efficiency\nat the expense of resilience, and environmental sustainability, because of the\ndependence on Cloud vendors such as Google, Amazon, and Microsoft. Community\nCloud Computing makes use of the principles of Digital Ecosystems to provide a\nparadigm for Clouds in the community, offering an alternative architecture for\nthe use cases of Cloud Computing. It is more technically challenging to deal\nwith issues of distributed computing, such as latency, differential resource\nmanagement, and additional security requirements. However, these are not\ninsurmountable challenges, and with the need to retain control over our digital\nlives and the potential environmental consequences, it is a challenge we must\npursue. \n\n"}
{"id": "0903.4100", "contents": "Title: Decentralized Management of Bi-modal Network Resources in a Distributed\n  Stream Processing Platform Abstract: This paper presents resource management techniques for allocating\ncommunication and computational resources in a distributed stream processing\nplatform. The platform is designed to exploit the synergy of two classes of\nnetwork connections -- dedicated and opportunistic. Previous studies we\nconducted have demonstrated the benefits of such bi-modal resource organization\nthat combines small pools of dedicated computers with a very large pool of\nopportunistic computing capacities of idle computers to serve high throughput\ncomputing applications. This paper extends the idea of bi-modal resource\norganization into the management of communication resources. Since distributed\nstream processing applications demand large volume of data transmission between\nprocessing sites at a consistent rate, adequate control over the network\nresources is important to assure a steady flow of processing. The system model\nused in this paper is a platform where stream processing servers at distributed\nsites are interconnected with a combination of dedicated and opportunistic\ncommunication links. Two pertinent resource allocation problems are analyzed in\ndetails and solved using decentralized algorithms. One is the mapping of the\nstream processing tasks on the processing and the communication resources. The\nother is the adaptive re-allocation of the opportunistic communication links\ndue to the variations in their capacities. Overall optimization goal is higher\ntask throughput and better utilization of the expensive dedicated links. The\nevaluation demonstrates that the algorithms are able to exploit the synergy of\nbi-modal communication links towards achieving the optimization goals. \n\n"}
{"id": "0904.3807", "contents": "Title: Pedestrian index theorem a la Aharonov-Casher for bulk threshold modes\n  in corrugated multilayer graphene Abstract: Zero-modes, their topological degeneracy and relation to index theorems have\nattracted attention in the study of single- and bilayer graphene. For\nnegligible scalar potentials, index theorems explain why the degeneracy of the\nzero-energy Landau level of a Dirac hamiltonian is not lifted by gauge field\ndisorder, for example due to ripples, whereas other Landau levels become\nbroadened by the inhomogenous effective magnetic field. That also the bilayer\nhamiltonian supports such protected bulk zero-modes was proved formally by\nKatsnelson and Prokhorova to hold on a compact manifold by using the\nAtiyah-Singer index theorem. Here we complement and generalize this result in a\npedestrian way by pointing out that the simple argument by Aharonov and Casher\nfor degenerate zero-modes of a Dirac hamiltonian in the infinite plane extends\nnaturally to the multilayer case. The degeneracy remains, though at nonzero\nenergy, also in the presence of a gap. These threshold modes make the spectrum\nasymmetric. The rest of the spectrum, however, remains symmetric even in\narbitrary gauge fields, a fact related to supersymmetry. Possible benefits of\nthis connection are discussed. \n\n"}
{"id": "0904.4612", "contents": "Title: Regulating atomic imbalance in double-well lattices Abstract: An insulating optical lattice with double-well sites is considered. In the\ncase of the unity filling factor, an effective Hamiltonian in the pseudospin\nrepresentation is derived. A method is suggested for manipulating the\nproperties of the system by varying the shape of the double-well potential. In\nparticular, it is shown that the atomic imbalance can be varied at will and a\nkind of the Morse-alphabet sequences can be created. \n\n"}
{"id": "0904.4842", "contents": "Title: Stabilization of Skyrmion textures by uniaxial distortions in\n  noncentrosymmetric cubic helimagnets Abstract: In cubic noncentrosymmetric ferromagnets uniaxial distortions suppress the\nhelical states and stabilize Skyrmion lattices in a broad range of\nthermodynamical parameters. Using a phenomenological theory for modulated and\nlocalized states in chiral magnets, the equilibrium parameters of the Skyrmion\nand helical states are derived as functions of the applied magnetic field and\ninduced uniaxial anisotropy. These results show that due to a combined effect\nof induced uniaxial anisotropy and an applied magnetic field Skyrmion lattices\ncan be formed as thermodynamically stable states in large intervals of magnetic\nfield and temperatures in cubic helimagnets, e.g., in intermetallic compounds\nMnSi, FeGe, (Fe,Co)Si. We argue that this mechanism is responsible for the\nformation of Skyrmion states recently observed in thin layers of\nFe_{0.5}Co_{0.5}Si [X.Z.Yu et al., Nature \\textbf{465}(2010) 901]. \n\n"}
{"id": "0905.0198", "contents": "Title: Pair-breaking effect on mesoscopic persistent currents Abstract: We consider the contribution of superconducting fluctuations to the\nmesoscopic persistent current (PC) of an ensemble of normal metallic rings,\nmade of a superconducting material whose low bare transition temperature\n$T^{0}_{c}$ is much smaller than the Thouless energy $E_{c}$. The effect of\npair breaking is introduced via the example of magnetic impurities. We find\nthat over a rather broad range of pair-breaking strength $\\hbar/\\tau_{s}$, such\nthat $T_c^0 \\lesssim \\hbar/\\tau_s \\lesssim E_c$, the superconducting transition\ntemperature is normalized down to minute values or zero while the PC is hardly\naffected. This may provide an explanation for the magnitude of the average PC's\nin copper and gold, as well as a way to determine their $T^0_c$'s. The\ndependence of the current and the dominant superconducting fluctuations on\n$E_c\\tau_s$ and on the ratio between $E_c$ and the temperature is analyzed. The\nmeasured PC's in copper (gold) correspond to $T^0_c$ of a few (a fraction of)\nmK. \n\n"}
{"id": "0905.0527", "contents": "Title: Viscous Ricci Dark Energy Abstract: We investigate the viscous Ricci dark energy (RDE) model by assuming that\nthere is bulk viscosity in the linear barotropic fluid and the RDE. In the RDE\nmodel without bulk viscosity, the universe is younger than some old objects at\nsome redshifts. Since the age of the universe should be longer than any objects\nin the universe, the RDE model suffers the age problem, especially when we\nconsider the object APM 08279+5255 at $z=3.91$, whose age is $t = 2.1$ Gyr. In\nthis letter, we find that once the viscosity is taken into account, this age\nproblem is alleviated. \n\n"}
{"id": "0906.3075", "contents": "Title: Proton-Air Cross Section and Extensive Air Showers Abstract: Hadronic cross sections at ultra-high energy have a significant impact on the\ndevelopment of extensive air shower cascades. Therefore the interpretation of\nair shower data depends critically on hadronic interaction models that\nextrapolate the cross section from accelerator measurements to the highest\ncosmic ray energies. We discuss how extreme scenarios of cross section\nextrapolations can affect the interpretation of air shower data. We find that\nthe theoretical uncertainty of the extrapolated proton-air cross section at\nultra-high energies is much larger than suggested by the existing spread of\navailable Monte Carlo model predictions. The impact on the depth of the shower\nmaximum is demonstrated. \n\n"}
{"id": "0907.1185", "contents": "Title: Convergence to L\\'evy stable processes under some weak dependence\n  conditions Abstract: For a strictly stationary sequence of random vectors in $\\mathbb{R}^d$ we\nstudy convergence of partial sum processes to L\\'evy stable process in the\nSkorohod space with $J_1$-topology. We identify necessary and sufficient\nconditions for such convergence and provide sufficient conditions when the\nstationary sequence is strongly mixing. \n\n"}
{"id": "0907.1843", "contents": "Title: The close circumstellar environment of Betelgeuse - Adaptive optics\n  spectro-imaging in the near-IR with VLT/NACO Abstract: Context: Betelgeuse is one the largest stars in the sky in terms of angular\ndiameter. Structures on the stellar photosphere have been detected in the\nvisible and near-infrared as well as a compact molecular environment called the\nMOLsphere. Mid-infrared observations have revealed the nature of some of the\nmolecules in the MOLsphere, some being the precursor of dust. Aims: Betelgeuse\nis an excellent candidate to understand the process of mass loss in red\nsupergiants. Using diffraction-limited adaptive optics (AO) in the\nnear-infrared, we probe the photosphere and close environment of Betelgeuse to\nstudy the wavelength dependence of its extension, and to search for\nasymmetries. Methods: We obtained AO images with the VLT/NACO instrument,\ntaking advantage of the \"cube\" mode of the CONICA camera to record separately a\nlarge number of short-exposure frames. This allowed us to adopt a \"lucky\nimaging\" approach for the data reduction, and obtain diffraction-limited images\nover the spectral range 1.04-2.17 $\\mu$m in 10 narrow-band filters. Results: In\nall filters, the photosphere of Betelgeuse appears partly resolved. We identify\nan asymmetric envelope around the star, with in particular a relatively bright\n\"plume\" extending in the southwestern quadrant up to a radius of approximately\nsix times the photosphere. The CN molecule provides an excellent match to the\n1.09 mic bandhead in absorption in front of the stellar photosphere, but the\nemission spectrum of the plume is more difficult to interpret. Conclusions: Our\nAO images show that the envelope surrounding Betelgeuse has a complex and\nirregular structure. We propose that the southwestern plume is linked either to\nthe presence of a convective hot spot on the photosphere, or to the rotation of\nthe star. \n\n"}
{"id": "0907.2485", "contents": "Title: Community Cloud Computing Abstract: Cloud Computing is rising fast, with its data centres growing at an\nunprecedented rate. However, this has come with concerns over privacy,\nefficiency at the expense of resilience, and environmental sustainability,\nbecause of the dependence on Cloud vendors such as Google, Amazon and\nMicrosoft. Our response is an alternative model for the Cloud\nconceptualisation, providing a paradigm for Clouds in the community, utilising\nnetworked personal computers for liberation from the centralised vendor model.\nCommunity Cloud Computing (C3) offers an alternative architecture, created by\ncombing the Cloud with paradigms from Grid Computing, principles from Digital\nEcosystems, and sustainability from Green Computing, while remaining true to\nthe original vision of the Internet. It is more technically challenging than\nCloud Computing, having to deal with distributed computing issues, including\nheterogeneous nodes, varying quality of service, and additional security\nconstraints. However, these are not insurmountable challenges, and with the\nneed to retain control over our digital lives and the potential environmental\nconsequences, it is a challenge we must pursue. \n\n"}
{"id": "0907.3255", "contents": "Title: First Direct Simulation of Brown Dwarf Formation in a Compact Cloud Core Abstract: Brown dwarf formation and star formation efficiency are studied using a\nnested grid simulation that covers five orders of magnitude in spatial scale\n(10^4 - 0.1AU). Starting with a rotating magnetized compact cloud with a mass\nof 0.22 M_sun, we follow the cloud evolution until the end of main accretion\nphase. Outflow of about 5 km/s emerges about 100 yr before the protostar\nformation and does not disappear until the end of the calculation. The mass\naccretion rate declines from 10^-6 M_sun/yr to 10^-8 - 10^-12 M_sun/yr in a\nshort time (about 10^4 yr) after the protostar formation. This is because (1) a\nlarge fraction of mass is ejected from the host cloud by the protostellar\noutflow and (2) the gas escapes from the host cloud by the thermal pressure. At\nthe end of the calculation, 74% (167 M_Jup) of the total mass (225 M_Jup) is\noutflowing from the protostar, in which 34% (77 M_Jup) of the total mass is\nejected by the protostellar outflow with supersonic velocity and 40% (90 M_Jup)\nescapes with subsonic velocity. On the other hand, 20% (45 M_Jup) is converted\ninto the protostar and 6% (13 M_Jup) remains as the circumstellar disk. Thus,\nthe star formation efficiency is epsilon = 0.2. The resultant protostellar mass\nis in the mass range of brown dwarfs. Our results indicate that brown dwarfs\ncan be formed in compact cores in the same manner as hydrogen-burning stars,\nand the magnetic field and protostellar outflow are essential in determining\nthe star formation efficiency and stellar mass. \n\n"}
{"id": "0907.4161", "contents": "Title: The Physics of the FIR-Radio Correlation: I. Calorimetry, Conspiracy,\n  and Implications Abstract: (Abridged) The far-infrared (FIR) and radio luminosities of star-forming\ngalaxies are linearly correlated over a very wide range in star formation rate,\nfrom normal spirals like the Milky Way to the most intense starbursts. Using\none-zone models of cosmic ray (CR) injection, cooling, and escape in\nstar-forming galaxies, we attempt to reproduce the observed FIR-radio\ncorrelation over its entire span. We show that ~2% of the kinetic energy from\nsupernova explosions must go into primary CR electrons and that ~10 - 20% must\ngo into primary CR protons. Secondary electrons and positrons are likely\ncomparable to or dominate primary electrons in dense starburst galaxies. We\ndiscuss the implications of our models for the magnetic field strengths of\nstarbursts, the detectability of starbursts by Fermi, and cosmic ray feedback.\nOverall, our models indicate that both CR protons and electrons escape from low\nsurface density galaxies, but lose most of their energy before escaping dense\nstarbursts. The FIR-radio correlation is caused by a combination of the\nefficient cooling of CR electrons (calorimetry) in starbursts and a conspiracy\nof several factors. For lower surface density galaxies, the decreasing radio\nemission caused by CR escape is balanced by the decreasing FIR emission caused\nby the low effective UV dust opacity. In starbursts, bremsstrahlung,\nionization, and Inverse Compton cooling decrease the radio emission, but they\nare countered by secondary electrons/positrons and the decreasing critical\nsynchrotron frequency, which both increase the radio emission. Our conclusions\nhold for a broad range of variations on our fiducial model. \n\n"}
{"id": "0907.5402", "contents": "Title: Optimal Scheduling for Fair Resource Allocation in Ad Hoc Networks with\n  Elastic and Inelastic Traffic Abstract: This paper studies the problem of congestion control and scheduling in ad hoc\nwireless networks that have to support a mixture of best-effort and real-time\ntraffic. Optimization and stochastic network theory have been successful in\ndesigning architectures for fair resource allocation to meet long-term\nthroughput demands. However, to the best of our knowledge, strict packet delay\ndeadlines were not considered in this framework previously. In this paper, we\npropose a model for incorporating the quality of service (QoS) requirements of\npackets with deadlines in the optimization framework. The solution to the\nproblem results in a joint congestion control and scheduling algorithm which\nfairly allocates resources to meet the fairness objectives of both elastic and\ninelastic flows, and per-packet delay requirements of inelastic flows. \n\n"}
{"id": "0908.1887", "contents": "Title: Spin susceptibility of degenerate quark matter Abstract: The expression for the spin susceptibility $\\chi$ of degenerate quark matter\nis derived with corrections upto $ {\\cal O}(g^4\\ln g^2)$. It is shown that at\nlow density, $\\chi^{-1}$ changes sign and turns negative indicating a\nferromagnetic phase transition. To this order, we also calculate sound velocity\n$c_1$ and incompressibility $K$ with arbitrary spin polarization. The estimated\nvalues of $c_1$ and $K$ show that the equation of state of the polarized matter\nis stiffer than the unpolarized one. Finally we determine the finite\ntemperature corrections to the exchange energy and derive corresponding results\nfor the spin susceptibility. \n\n"}
{"id": "0908.4228", "contents": "Title: Transition from ballistic to diffusive behavior of graphene ribbons in\n  the presence of warping and charged impurities Abstract: We study the effects of the long-range disorder potential and warping on the\nconductivity and mobility of graphene ribbons using the Landauer formalism and\nthe tight-binding p-orbital Hamiltonian. We demonstrate that as the length of\nthe structure increases the system undergoes a transition from the ballistic to\nthe diffusive regime. This is reflected in the calculated electron density\ndependencies of the conductivity and the mobility. In particular, we show that\nthe mobility of graphene ribbons varies as mu(n) n^(-lambda), with\n0<lambda<0.5. The exponent lambda depends on the length of the system with\nlambda=0.5 corresponding to short structures in the ballistic regime, whereas\nthe diffusive regime lambda=0 (when the mobility is independent on the electron\ndensity) is reached for sufficiently long structures. Our results can be used\nfor the interpretation of experimental data when the value of lambda can be\nused to distinguish the transport regime of the system (i.e. ballistic,\nquasi-ballistic or diffusive). Based on our findings we discuss available\nexperimental results. \n\n"}
{"id": "0910.4507", "contents": "Title: ScotGrid: Providing an Effective Distributed Tier-2 in the LHC Era Abstract: ScotGrid is a distributed Tier-2 centre in the UK with sites in Durham,\nEdinburgh and Glasgow. ScotGrid has undergone a huge expansion in hardware in\nanticipation of the LHC and now provides more than 4MSI2K and 500TB to the LHC\nVOs. Scaling up to this level of provision has brought many challenges to the\nTier-2 and we show in this paper how we have adopted new methods of organising\nthe centres, from fabric management and monitoring to remote management of\nsites to management and operational procedures, to meet these challenges. We\ndescribe how we have coped with different operational models at the sites,\nwhere Glagsow and Durham sites are managed \"in house\" but resources at\nEdinburgh are managed as a central university resource. This required the\nadoption of a different fabric management model at Edinburgh and a special\nengagement with the cluster managers. Challenges arose from the different job\nmodels of local and grid submission that required special attention to resolve.\nWe show how ScotGrid has successfully provided an infrastructure for ATLAS and\nLHCb Monte Carlo production. Special attention has been paid to ensuring that\nuser analysis functions efficiently, which has required optimisation of local\nstorage and networking to cope with the demands of user analysis. Finally,\nalthough these Tier-2 resources are pledged to the whole VO, we have\nestablished close links with our local physics user communities as being the\nbest way to ensure that the Tier-2 functions effectively as a part of the LHC\ngrid computing framework.. \n\n"}
{"id": "0910.4704", "contents": "Title: Performance of Joint Spectrum Sensing and MAC Algorithms for\n  Multichannel Opportunistic Spectrum Access Ad Hoc Networks Abstract: We present an analytical framework to assess the link layer throughput of\nmultichannel Opportunistic Spectrum Access (OSA) ad hoc networks. Specifically,\nwe focus on analyzing various combinations of collaborative spectrum sensing\nand Medium Access Control (MAC) protocol abstractions. We decompose\ncollaborative spectrum sensing into layers, parametrize each layer, classify\nexisting solutions, and propose a new protocol called Truncated Time Division\nMultiple Access (TTDMA) that supports efficient distribution of sensing results\nin \"k out of N\" fusion rule. In case of multichannel MAC protocols we evaluate\ntwo main approaches of control channel design with (i) dedicated and (ii)\nhopping channel. We propose to augment these protocols with options of handling\nsecondary user (SU) connections preempted by primary user (PU) by (i)\nconnection buffering until PU departure and (ii) connection switching to a\nvacant PU channel. By comparing and optimizing different design combinations we\nshow that (i) it is generally better to buffer preempted SU connections than to\nswitch them to PU vacant channels and (ii) TTDMA is a promising design option\nfor collaborative spectrum sensing process when k does not change over time. \n\n"}
{"id": "0911.0746", "contents": "Title: Tidal mechanism as an impossible cause of the observed secular increase\n  of the astronomical unit Abstract: Krasinsky and Brumberg (2004 Celest. Mech. Dyn. Astron., 90, 267) reported a\nsecular increase of the astronomical unit (AU) of 15 meters per century.\nRecently, Miura et al. (2009, PASJ, 61) proposed that a possible angular\nmomentum transfer from the rotation of the Sun to the orbital motion of the\nsolar system planets may explain the observed increase of the AU. They assumed\nthat the tidal effect between the planets and the Sun is the cause of this\ntransfer. Here we claim that tidal effect cannot be a cause of this type of the\ntransfer to explain the increase of the AU. \n\n"}
{"id": "0911.1972", "contents": "Title: People-Sensing Spatial Characteristics of RF Sensor Networks Abstract: An \"RF sensor\" network can monitor RSS values on links in the network and\nperform device-free localization, i.e., locating a person or object moving in\nthe area in which the network is deployed. This paper provides a statistical\nmodel for the RSS variance as a function of the person's position w.r.t. the\ntransmitter (TX) and receiver (RX). We show that the ensemble mean of the RSS\nvariance has an approximately linear relationship with the expected total\naffected power (ETAP). We then use analysis to derive approximate expressions\nfor the ETAP as a function of the person's position, for both scattering and\nreflection. Counterintuitively, we show that reflection, not scattering, causes\nthe RSS variance contours to be shaped like Cassini ovals. Experimental tests\nreported here and in past literature are shown to validate the analysis. \n\n"}
{"id": "0911.3202", "contents": "Title: Combining dynamical decoupling with fault-tolerant quantum computation Abstract: We study how dynamical decoupling (DD) pulse sequences can improve the\nreliability of quantum computers. We prove upper bounds on the accuracy of\nDD-protected quantum gates and derive sufficient conditions for DD-protected\ngates to outperform unprotected gates. Under suitable conditions,\nfault-tolerant quantum circuits constructed from DD-protected gates can\ntolerate stronger noise, and have a lower overhead cost, than fault-tolerant\ncircuits constructed from unprotected gates. Our accuracy estimates depend on\nthe dynamics of the bath that couples to the quantum computer, and can be\nexpressed either in terms of the operator norm of the bath's Hamiltonian or in\nterms of the power spectrum of bath correlations; we explain in particular how\nthe performance of recursively generated concatenated pulse sequences can be\nanalyzed from either viewpoint. Our results apply to Hamiltonian noise models\nwith limited spatial correlations. \n\n"}
{"id": "0911.5377", "contents": "Title: Poisson Thickening Abstract: Let X be a Poisson point process of intensity lambda on the real line. A\nthickening of it is a (deterministic) measurable function f such that the union\nof X and f(X) is a Poisson point process of intensity lambda' where\nlambda'>lambda. An equivariant thickening is a thickening which commutes with\nall shifts of the line. We show that a thickening exists but an equivariant\nthickening does not. We prove similar results for thickenings which commute\nonly with integer shifts and in the discrete and multi-dimensional settings.\nThis answers 3 questions of Holroyd, Lyons and Soo.\n  We briefly consider also a much more general setup in which we ask for the\nexistence of a deterministic coupling satisfying a relation between two\nprobability measures. We present a conjectured sufficient condition for the\nexistence of such couplings. \n\n"}
{"id": "0912.0261", "contents": "Title: The impact of correlated projections on weak lensing cluster counts Abstract: Large-scale structure projections are an obstacle in converting the shear\nsignal of clusters detected in weak-lensing maps into virial masses. However,\nthis step is not necessary for constraining cosmology with the shear-peak\nabundance, if we are able to predict its amplitude. We generate a large\nensemble of N-body simulations spanning four cosmological models, with total\nvolume V~1 (Gpc/h)^3 per model. Variations to the matter density parameter and\namplitude of fluctuations are considered. We measure the abundance of peaks in\nthe mass density projected in ~100 Mpc/h slabs to determine the impact of\nstructures spatially correlated with the simulation clusters, identified by the\n3D friends-of-friends algorithm. The halo model shows that the choice of the\nsmoothing filter for the density field is important in reducing the\ncontribution of correlated projections to individual halo masses. Such\ncontributions are less than 2% in the case of the optimal, compensated filter\nused throughout this analysis. We measure the change in the mass of peaks when\nprojected in slabs of various thicknesses. Peaks in slabs of 26 Mpc/h and 102\nMpc/h suffer an average mass change of less than 2% compared to their mass in\nslabs of 51 Mpc/h. We then explore the cosmology dependence of the\nprojected-peak mass function, and find that, for a wide range of slab\nthicknesses (<500 Mpc/h), it scales with cosmology in exactly the same way as\nthe 3D friends-of-friends mass function and the Sheth-Tormen formula. This\nextends the earlier result of Marian et al. (2009). Finally, we show that for\nall cosmological models considered, the low and intermediate mass bins of the\npeak abundance can be described using a modified Sheth-Tormen functional form\nto within 10%-20% accuracy. \n\n"}
{"id": "0912.0338", "contents": "Title: Correlation Decay in Random Decision Networks Abstract: We consider a decision network on an undirected graph in which each node\ncorresponds to a decision variable, and each node and edge of the graph is\nassociated with a reward function whose value depends only on the variables of\nthe corresponding nodes. The goal is to construct a decision vector which\nmaximizes the total reward. This decision problem encompasses a variety of\nmodels, including maximum-likelihood inference in graphical models (Markov\nRandom Fields), combinatorial optimization on graphs, economic team theory and\nstatistical physics. The network is endowed with a probabilistic structure in\nwhich costs are sampled from a distribution. Our aim is to identify sufficient\nconditions to guarantee average-case polynomiality of the underlying\noptimization problem. We construct a new decentralized algorithm called Cavity\nExpansion and establish its theoretical performance for a variety of models.\nSpecifically, for certain classes of models we prove that our algorithm is able\nto find near optimal solutions with high probability in a decentralized way.\nThe success of the algorithm is based on the network exhibiting a correlation\ndecay (long-range independence) property. Our results have the following\nsurprising implications in the area of average case complexity of algorithms.\nFinding the largest independent (stable) set of a graph is a well known NP-hard\noptimization problem for which no polynomial time approximation scheme is\npossible even for graphs with largest connectivity equal to three, unless P=NP.\nWe show that the closely related maximum weighted independent set problem for\nthe same class of graphs admits a PTAS when the weights are i.i.d. with the\nexponential distribution. Namely, randomization of the reward function turns an\nNP-hard problem into a tractable one. \n\n"}
{"id": "0912.3618", "contents": "Title: Fermi observations of Cassiopeia and Cepheus: diffuse gamma-ray emission\n  in the outer Galaxy Abstract: We present the analysis of the interstellar gamma-ray emission measured by\nthe Fermi Large Area Telescope toward a region in the second Galactic quadrant\nat 100 deg < l < 145 deg and -15 deg < b < +30 deg. This region encompasses the\nprominent Gould-Belt clouds of Cassiopeia, Cepheus and the Polaris flare, as\nwell as atomic and molecular complexes at larger distances, like that\nassociated with NGC 7538 in the Perseus arm. The good kinematic separation in\nvelocity between the local, Perseus, and outer arms, and the presence of\nmassive complexes in each of them make this region well suited to probe cosmic\nrays and the interstellar medium beyond the solar circle. The gamma-ray\nemissivity spectrum of the gas in the Gould Belt is consistent with\nexpectations based on the locally measured cosmic-ray spectra. The gamma-ray\nemissivity decreases from the Gould Belt to the Perseus arm, but the measured\ngradient is flatter than expectations for cosmic-ray sources peaking in the\ninner Galaxy as suggested by pulsars. The Xco=N(H2)/W(CO) conversion factor is\nfound to increase from (0.87 +- 0.05) 10^20 cm^-2 (K km s^-1)^-1 in the Gould\nBelt to (1.9 +- 0.2) 10^20 cm^-2 (K km s^-1)^-1 in the Perseus arm. We derive\nmasses for the molecular clouds under study. Dark gas, not properly traced by\nradio and microwave surveys, is detected in the Gould Belt through a correlated\nexcess of dust and gamma-ray emission: its mass amounts to ~50% of the\nCO-traced mass. \n\n"}
{"id": "0912.3824", "contents": "Title: Highly accelerated simulations of glassy dynamics using GPUs: caveats on\n  limited floating-point precision Abstract: Modern graphics processing units (GPUs) provide impressive computing\nresources, which can be accessed conveniently through the CUDA programming\ninterface. We describe how GPUs can be used to considerably speed up molecular\ndynamics (MD) simulations for system sizes ranging up to about 1 million\nparticles. Particular emphasis is put on the numerical long-time stability in\nterms of energy and momentum conservation, and caveats on limited\nfloating-point precision are issued. Strict energy conservation over 10^8 MD\nsteps is obtained by double-single emulation of the floating-point arithmetic\nin accuracy-critical parts of the algorithm. For the slow dynamics of a\nsupercooled binary Lennard-Jones mixture, we demonstrate that the use of\nsingle-floating point precision may result in quantitatively and even\nphysically wrong results. For simulations of a Lennard-Jones fluid, the\ndescribed implementation shows speedup factors of up to 80 compared to a serial\nimplementation for the CPU, and a single GPU was found to compare with a\nparallelised MD simulation using 64 distributed cores. \n\n"}
{"id": "1001.2398", "contents": "Title: Dark Energy in vector-tensor theories of gravity Abstract: We consider a general class of vector-tensor theories of gravity and show\nthat solutions with accelerated expansion and a future type III singularity are\na common feature in these models. We also show that there are only six\nvector-tensor theories with the same small scales behavior as General\nRelativity and, in addition, only two of them can be made completely free from\ninstabilities. Finally, two particular models as candidates for dark energy are\nproposed: on one hand, a cosmic vector that allows to alleviate the usual\nnaturalness and coincidence problems and, on the other hand, the\nelectromagnetic field is shown to give rise to an effective cosmological\nconstant on large scales whose value can be explained in terms of inflation at\nthe electroweak scale. \n\n"}
{"id": "1001.2402", "contents": "Title: Weak Lensing Mass Measurements of Substructures in COMA Cluster with\n  Subaru/Suprime-Cam Abstract: We obtain the projected mass distributions for two Subaru/Suprime-Cam fields\nin the southwest region (r\\simlt 60') of the Coma cluster (z=0.0236) by weak\nlensing analysis and detect eight subclump candidates. We quantify the\ncontribution of background large-scale structure (LSS) on the projected mass\ndistributions using SDSS multi-bands and photometric data, under the assumption\nof mass-to-light ratio for field galaxies. We find that one of eight subclump\ncandidates, which is not associated with any member galaxies, is significantly\naffected by LSS lensing. The mean projected mass for seven subclumps extracted\nfrom the main cluster potential is <M_2D^(corr)> = (5.06\\pm1.30)10^12h^-1 M_sun\nafter a LSS correction. A tangential distortion profile over an ensemble of\nsubclumps is well described by a truncated singular-isothermal sphere model and\na truncated NFW model. A typical truncated radius of subclumps, r_t\\simeq 35\nh^-1 kpc, is derived without assuming any relations between mass and light for\nmember galaxies. The radius coincides well with the tidal radius, \\sim42 h^-1\nkpc, of the gravitational force of the main cluster. Taking into account the\nincompleteness of data area, a projection effect and spurious lensing peaks, it\nis expected that mass of cluster substructures account for 19 percent of the\nvirial mass, with 13 percent statistical error. The mass fraction of cluster\nsubstructures is in rough agreement with numerical simulations. \n\n"}
{"id": "1001.2569", "contents": "Title: Virtual Private Overlays: Secure Group Commounication in NAT-Constrained\n  Environments Abstract: Structured P2P overlays provide a framework for building distributed\napplications that are self-configuring, scalable, and resilient to node\nfailures. Such systems have been successfully adopted in large-scale Internet\nservices such as content delivery networks and file sharing; however,\nwidespread adoption in small/medium scales has been limited due in part to\nsecurity concerns and difficulty bootstrapping in NAT-constrained environments.\nNonetheless, P2P systems can be designed to provide guaranteed lookup times,\nNAT traversal, point-to-point overlay security, and distributed data stores. In\nthis paper we propose a novel way of creating overlays that are both secure and\nprivate and a method to bootstrap them using a public overlay. Private overlay\nnodes use the public overlay's distributed data store to discover each other,\nand the public overlay's connections to assist with NAT hole punching and as\nrelays providing STUN and TURN NAT traversal techniques. The security framework\nutilizes groups, which are created and managed by users through a web based\nuser interface. Each group acts as a Public Key Infrastructure (PKI) relying on\nthe use of a centrally-managed web site providing an automated Certificate\nAuthority (CA). We present a reference implementation which has been used in a\nP2P VPN (Virtual Private Network). To evaluate our contributions, we apply our\ntechniques to an overlay network modeler, event-driven simulations using\nsimulated time delays, and deployment in the PlanetLab wide-area testbed. \n\n"}
{"id": "1001.4153", "contents": "Title: Optical nanoprobing via spin-orbit interaction of light Abstract: We show, both theoretically and experimentally, that high-numerical-aperture\n(NA) optical microscopy is accompanied by strong spin-orbit interaction of\nlight, which translates fine infomation about the specimen to the polarization\ndegrees of freedom of light. An 80nm gold nano-particle scattering the light in\nthe focus of a high-NA objective generates angular momentum conversion which is\nseen as a non-uniform polarization distribution at the exit pupil. We\ndemonstrate remarkable sensitivity of the effect to the position of the\nnano-particle: Its subwavelength displacement produces the giant spin-Hall\neffect, i.e., macro-separation of spins in the outgoing light. This brings\nforth a far-field optical nanoprobing technique based on the spin-orbit\ninteraction of light. \n\n"}
{"id": "1001.4168", "contents": "Title: Edge States of Monolayer and Bilayer Graphene Nanoribbons Abstract: On the basis of tight-binding lattice model, the edge states of monolayer and\nbilayer graphene nanoribbons (GNRs) with different edge terminations are\nstudied. The effects of edge-hopping modulation, spin-orbital coupling (SOC),\nand bias voltage on bilayer GNRs are discussed. We observe the following: (i)\nSome new extra edge states can be created by edge-hopping modulation for\nmonolayer GNRs. (ii) Intralayer Rashba SOC plays a role in depressing the band\nenergy gap $E_g$ opened by intrinsic SOC for both monolayer and bilayer GNRs.\nAn almost linear dependent relation, i.e., $E_g\\sim \\lambda_R$, is found. (iii)\nAlthough the bias voltage favors a bulk energy gap for bilayer graphene without\nintrinsic SOC, it tends to reduce the gap induced by intrinsic SOC. (iv) The\ntopological phase of the quantum spin Hall effect can be destroyed completely\nby interlayer Rashba SOC for bilayer GNRs. \n\n"}
{"id": "1003.2148", "contents": "Title: Structure and deformations of strongly magnetized neutron stars with\n  twisted torus configurations Abstract: We construct general relativistic models of stationary, strongly magnetized\nneutron stars. The magnetic field configuration, obtained by solving the\nrelativistic Grad-Shafranov equation, is a generalization of the twisted torus\nmodel recently proposed in the literature; the stellar deformations induced by\nthe magnetic field are computed by solving the perturbed Einstein's equations;\nstellar matter is modeled using realistic equations of state. We find that in\nthese configurations the poloidal field dominates over the toroidal field and\nthat, if the magnetic field is sufficiently strong during the first phases of\nthe stellar life, it can produce large deformations. \n\n"}
{"id": "1003.2717", "contents": "Title: Strain-induced pseudo-magnetic field for novel graphene electronics Abstract: Particular strain geometry in graphene could leads to a uniform\npseudo-magnetic field of order 10T and might open up interesting applications\nin graphene nano-electronics. Through quantum transport calculations of\nrealistic strained graphene flakes of sizes of 100nm, we examine possible means\nof exploiting this effect for practical electronics and valleytronics devices.\nFirst, we found that elastic backscattering at rough edges leads to the\nformation of well defined transport gaps of order 100meV under moderate maximum\nstrain of 10%. Second, the application of a real magnetic field induced a\nseparation, in space and energy, of the states arising from different valleys,\nleading to a way of inducing bulk valley polarization which is insensitive to\nshort range scattering. \n\n"}
{"id": "1003.5238", "contents": "Title: An efficient algorithm for the parallel solution of high-dimensional\n  differential equations Abstract: The study of high-dimensional differential equations is challenging and\ndifficult due to the analytical and computational intractability. Here, we\nimprove the speed of waveform relaxation (WR), a method to simulate\nhigh-dimensional differential-algebraic equations. This new method termed\nadaptive waveform relaxation (AWR) is tested on a communication network\nexample. Further we propose different heuristics for computing graph partitions\ntailored to adaptive waveform relaxation. We find that AWR coupled with\nappropriate graph partitioning methods provides a speedup by a factor between 3\nand 16. \n\n"}
{"id": "1003.5779", "contents": "Title: Effect of electric field of the electrosphere on photon emission from\n  quark stars Abstract: We investigate the photon emission from the electrosphere of a quark star. It\nis shown that at temperatures $T\\sim 0.1-1$ MeV the dominating mechanism is the\nbremsstrahlung due to bending of electron trajectories in the mean Coulomb\nfield of the electrosphere. The radiated energy flux from this mechanism\nexceeds considerably both the contribution from the bremsstrahlung due to\nelectron-electron interaction and the tunnel $e^{+}e^{-}$ pair creation. \n\n"}
{"id": "1004.0974", "contents": "Title: Non-Gaussianity in the HILC foreground-reduced three-year WMAP CMB map Abstract: A detection or nondetection of primordial non-Gaussianity in the CMB data is\nessential not only to test alternative models of the physics of the early\nuniverse but also to discriminate among classes of inflationary models. Given\nthis far reaching consequences of such a non-Gaussianity detection for our\nunderstanding of the physics of the early universe, it is important to employ\nalternative indicators in order to have further information about the\nGaussianity features of CMB that may be helpful for identifying their origins.\nIn this way, a considerable effort has recently gone into the design of\nnon-Gaussianity indicators, and in their application in the search for\ndeviation from Gaussianity in the CMB data. Recently we have proposed two new\nlarge-angle non-Gaussianity indicators which provide measures of the departure\nfrom Gaussianity on large angular scales. We have used these indicators to\ncarry out analyses of Gaussianity of the single frequency bands and of the\navailable foreground-reduced {\\it five-year} maps with and without the KQ75\nmask. Here we extend and complement these studies by performing a new analysis\nof deviation from Gaussianity of the {\\it three-year} harmonic ILC (HILC)\nforeground-reduced full-sky and KQ75 masked maps obtained from WMAP data. We\nshow that this full-sky foreground-reduced maps presents a significant\ndeviation from Gaussianity, which is brought down to a level of consistency\nwith Gaussianity when the KQ75 mask is employed. \n\n"}
{"id": "1004.2308", "contents": "Title: Addressing the P2P Bootstrap Problem for Small Networks Abstract: P2P overlays provide a framework for building distributed applications\nconsisting of few to many resources with features including self-configuration,\nscalability, and resilience to node failures. Such systems have been\nsuccessfully adopted in large-scale services for content delivery networks,\nfile sharing, and data storage. In small-scale systems, they can be useful to\naddress privacy concerns and for network applications that lack dedicated\nservers. The bootstrap problem, finding an existing peer in the overlay,\nremains a challenge to enabling these services for small-scale P2P systems. In\nlarge networks, the solution to the bootstrap problem has been the use of\ndedicated services, though creating and maintaining these systems requires\nexpertise and resources, which constrain their usefulness and make them\nunappealing for small-scale systems. This paper surveys and summarizes\nrequirements that allow peers potentially constrained by network connectivity\nto bootstrap small-scale overlays through the use of existing public overlays.\nIn order to support bootstrapping, a public overlay must support the following\nrequirements: a method for reflection in order to obtain publicly reachable\naddresses, so peers behind network address translators and firewalls can\nreceive incoming connection requests; communication relaying to share public\naddresses and communicate when direct communication is not feasible; and\nrendezvous for discovering remote peers, when the overlay lacks stable\nmembership. After presenting a survey of various public overlays, we identify\ntwo overlays that match the requirements: XMPP overlays, such as Google Talk\nand Live Journal Talk, and Brunet, a structured overlay based upon Symphony. We\npresent qualitative experiences with prototypes that demonstrate the ability to\nbootstrap small-scale private structured overlays from public Brunet or XMPP\ninfrastructures. \n\n"}
{"id": "1004.3678", "contents": "Title: Peierls-type Instability and Tunable Band Gap in Functionalized Graphene Abstract: Functionalizing graphene was recently shown to have a dramatic effect on the\nelectronic properties of this material. Here we investigate spatial ordering of\nadatoms driven by the RKKY-type interactions. In the ordered state, which\narises via a Peierls-instability-type mechanism, the adatoms reside mainly on\none of the two graphene sublattices. Bragg scattering of electron waves induced\nby sublattice symmetry breaking results in a band gap opening, whereby Dirac\nfermions acquire a finite mass. The band gap is found to be immune to the\nadatoms' positional disorder, with only an exponentially small number of\nlocalized states residing in the gap. The gapped state is stabilized in a wide\nrange of electron doping. Our findings show that controlled adsorption of\nadatoms or molecules provides a route to engineering a tunable band gap in\ngraphene. \n\n"}
{"id": "1004.3713", "contents": "Title: Large deviations for the local fluctuations of random walks and new\n  insights into the \"randomness\" of Pi Abstract: We establish large deviations properties valid for almost every sample path\nof a class of stationary mixing processes $(X_1,..., X_n,...)$. These\nproperties are inherited from those of $S_n=\\sum_{i=1}^nX_i$ and describe how\nthe local fluctuations of almost every realization of $S_n$ deviate from the\nalmost sure behavior. These results apply to the fluctuations of Brownian\nmotion, Birkhoff averages on hyperbolic dynamics, as well as branching random\nwalks. Also, they lead to new insights into the \"randomness\" of the digits of\nexpansions in integer bases of Pi. We formulate a new conjecture, supported by\nnumerical experiments, implying the normality of Pi. \n\n"}
{"id": "1005.2265", "contents": "Title: Stochastic dynamical systems with weak contractivity properties (with a\n  chapter featuring results of Martin Benda) Abstract: Consider a proper metric space X and a sequence of i.i.d. random continuous\nmappings F_n from X to X. It induces the stochastic dynamical system (SDS)\nX_n^x = F_n(X_{n-1}^x) starting at x in X. In this paper, we study existence\nand uniqueness of invariant measures, as well as recurrence and ergodicity of\nthis process. In the first part, we elaborate, improve and complete the\nunpublished work of Martin Benda on local contractivity, which merits publicity\nand provides an important tool for studying stochastic iterations. We consider\nthe case when the F_n are contractions and, in particular, discuss recurrence\ncriteria and their sharpness for reflected random walk.\n  In the second part, we consider the case where the F_n are Lipschitz\nmappings. The main results concern the case when the associated Lipschitz\nconstants are log-centered. Prinicpal tools are the Chacon-Ornstein theorem and\na hyperbolic extension of the space X as well as the process (X_n^x). The\nresults are applied to the reflected affine stochastic recursion on the\nnon-negative half-line. \n\n"}
{"id": "1005.5568", "contents": "Title: The primordial non-Gaussianity of local type (f_NL) in the WMAP 5-year\n  data: the length distribution of CMB skeleton Abstract: We present skeleton studies of non-Gaussianity in the CMB temperature\nanisotropy observed in the WMAP5 data. The local skeleton is traced on the 2D\nsphere by cubic spline interpolation which leads to more accurate estimation of\nthe intersection positions between the skeleton and the secondary pixels than\nconventional linear interpolation. We demonstrate that the skeleton-based\nestimator of non-Gaussianity of the local type (f_NL) - the departure of the\nlength distribution from the corresponding Gaussian expectation - yields an\nunbiased and sufficiently converged f_NL-likelihood.\n  We analyse the skeleton statistics in the WMAP5 combined V- and W-band data\noutside the Galactic base-mask determined from the KQ75 sky-coverage. The\nresults are consistent with Gaussian simulations of the the best-fitting\ncosmological model, but deviate from the previous results determined using the\nWMAP1 data. We show that it is unlikely that the improved skeleton tracing\nmethod, the omission of Q-band data, the modification of the\nforeground-template fitting method or the absence of 6 extended regions in the\nnew mask contribute to such a deviation. However, the application of the Kp0\nbase-mask in data processing does improve the consistency with the WMAP1\nresults.\n  The f_NL-likelihoods of the data are estimated at 9 different smoothing\nlevels. It is unexpected that the best-fit values show positive correlation\nwith the smoothing scales. Further investigation argues against a point-source\nor goodness-of-fit explanation but finds that about 30% of either Gaussian or\nf_NL samples having better goodness-of-fit than the WMAP5 show a similar\ncorrelation. We present the estimate f_NL=47.3+/-34.9 (1sigma error) determined\nfrom the first four smoothing angles and f_NL=76.8+/-43.1 for the combination\nof all nine. The former result may be overestimated at the 0.21sigma-level\nbecause of point sources. \n\n"}
{"id": "1006.0106", "contents": "Title: From dwarf spheroidals to cDs: Simulating the galaxy population in a\n  LCDM cosmology Abstract: We apply updated semi-analytic galaxy formation models simultaneously to the\nstored halo/subhalo merger trees of the Millennium and Millennium-II\nsimulations. These differ by a factor of 125 in mass resolution, allowing\nexplicit testing of resolution effects on predicted galaxy properties. We have\nrevised the treatments of the transition between the rapid infall and cooling\nflow regimes of gas accretion, of the sizes of bulges and of gaseous and\nstellar disks, of supernova feedback, of the transition between central and\nsatellite status as galaxies fall into larger systems, and of gas and star\nstripping once they become satellites. Plausible values of efficiency and\nscaling parameters yield an excellent fit not only to the observed abundance of\nlow-redshift galaxies over 5 orders of magnitude in stellar mass and 9\nmagnitudes in luminosity, but also to the observed abundance of Milky Way\nsatellites. This suggests that reionisation effects may not be needed to solve\nthe \"missing satellite\" problem except, perhaps, for the faintest objects. The\nsame model matches the observed large-scale clustering of galaxies as a\nfunction of stellar mass and colour. The fit remains excellent down to ~30kpc\nfor massive galaxies. For M* < 6 x 10^10Msun, however, the model overpredicts\nclustering at scales below 1 Mpc, suggesting that the sigma_8 adopted in the\nsimulations (0.9) is too high. Galaxy distributions within rich clusters agree\nbetween the simulations and match those observed, but only if galaxies without\ndark matter subhalos (so-called orphans) are included. Our model predicts a\nlarger passive fraction among low-mass galaxies than is observed, as well as an\noverabundance of ~10^10Msun galaxies beyond z~0.6, reflecting deficiencies in\nthe way star-formation rates are modelled. \n\n"}
{"id": "1006.0633", "contents": "Title: Long-term & large-scale viscous evolution of dense planetary rings Abstract: We investigate the long-term and large-scale viscous evolution of dense\nplanetary rings using a simple 1D numerical code. We use a physically realistic\nviscosity model derived from N-body simulations (Daisaka et al., 2001), and\ndependent on the disk's local properties (surface mass density, particle size,\ndistance to the planet). Particularly, we include the effects of gravitational\ninstabilities (wakes) that importantly enhance the disk's viscosity. We show\nthat common estimates of the disk's spreading time-scales with constant\nviscosity significantly underestimate the rings' lifetime. With a realistic\nviscosity model, an initially narrow ring undergoes two successive evolutionary\nstages: (1) a transient rapid spreading when the disk is self-gravitating, with\nthe formation of a density peak inward and an outer region marginally\ngravitationally stable, and with an emptying time-scale proportional to 1/M_0^2\n(where M_0 is the disk's initial mass) (2) an asymptotic regime where the\nspreading rate continuously slows down as larger parts of the disk become\nnot-self-gravitating due to the decrease of the surface density, until the disk\nbecomes completely not-self-gravitating. At this point its evolution\ndramatically slows down, with an emptying time-scale proportional to 1/M_0,\nwhich significantly increases the disk's lifetime compared to the case with\nconstant viscosity. We show also that the disk's width scales like t^{1/4} with\nthe realistic viscosity model, while it scales like t^{1/2} in the case of\nconstant viscosity, resulting in much larger evolutionary time-scales in our\nmodel. We find however that the present shape of Saturn's rings looks like a\n100 million-years old disk in our simulations. Concerning Jupiter's, Uranus'\nand Neptune's rings that are faint today, it is not likely that they were much\nmore massive in the past and lost most of their mass due to viscous spreading\nalone. \n\n"}
{"id": "1006.0670", "contents": "Title: Astronomy 3.0 Style Abstract: Over the next decade we will witness the development of a new infrastructure\nin support of data-intensive scientific research, which includes Astronomy.\nThis new networked environment will offer both challenges and opportunities to\nour community and has the potential to transform the way data are described,\ncurated and preserved. Based on the lessons learned during the development and\nmanagement of the ADS, a case is made for adopting the emerging technologies\nand practices of the Semantic Web to support the way Astronomy research will be\nconducted. Examples of how small, incremental steps can, in the aggregate, make\na significant difference in the provision and repurposing of astronomical data\nare provided. \n\n"}
{"id": "1006.2766", "contents": "Title: Scaling Limit for the Diffusion Exit Problem in the Levinson Case Abstract: The exit problem for small perturbations of a dynamical system in a domain is\nconsidered. It is assumed that the unperturbed dynamical system and the domain\nsatisfy the Levinson conditions. We assume that the random perturbation affects\nthe driving vector field and the initial condition, and each of the components\nof the perturbation follows a scaling limit. We derive the joint scaling limit\nfor the random exit time and exit point. We use this result to study the\nasymptotics of the exit time for 1-d diffusions conditioned on rare events. \n\n"}
{"id": "1007.2986", "contents": "Title: Variable length Markov chains and dynamical sources Abstract: Infinite random sequences of letters can be viewed as stochastic chains or as\nstrings produced by a source, in the sense of information theory. The\nrelationship between Variable Length Markov Chains (VLMC) and probabilistic\ndynamical sources is studied. We establish a probabilistic frame for context\ntrees and VLMC and we prove that any VLMC is a dynamical source for which we\nexplicitly build the mapping. On two examples, the ``comb'' and the ``bamboo\nblossom'', we find a necessary and sufficient condition for the existence and\nthe unicity of a stationary probability measure for the VLMC. These two\nexamples are detailed in order to provide the associated Dirichlet series as\nwell as the generating functions of word occurrences. \n\n"}
{"id": "1007.3716", "contents": "Title: Resonant tunneling through superconducting double barrier structures in\n  graphene Abstract: We study resonant tunneling through a superconducting double barrier\nstructure in graphene as a function of the system parameters. At each barrier,\ndue to the proximity effect, an incident electron can either reflect as an\nelectron or a hole (specular as well as retro Andreev reflection in graphene).\nSimilarly, transport across the barriers can occur via electrons as well as via\nthe crossed (specular and/or retro) Andreev channel, where a hole is\ntransmitted nonlocally to the other lead. In this geometry, in the subgap\nregime, we find resonant suppression of Andreev reflection at certain energies,\ndue to the formation of Andreev bound levels between the two superconducting\nbarriers, where the transmission probability T for electrons incident on the\ndouble barrier structure becomes unity. The evolution of the transport through\nthe superconducting double barrier geometry as a function of the incident\nenergy for various angles of incidence shows the damping of the resonance as\nnormal reflection between the barriers increases. \n\n"}
{"id": "1007.3746", "contents": "Title: Towards an improved understanding of the relative scintillation\n  efficiency of nuclear recoils in liquid xenon Abstract: Liquid xenon (LXe) particle detectors are a powerful technology in the field\nof dark matter direct detection, having shown impressive results in recent\nyears and holding strong possibility for leading the field in sensitivity to\ngalactic weakly interacting massive particles (WIMPs) in the future. The search\nfor WIMPs requires the capability to detect the recoiling nuclei that result\nwhen these particles interact with normal matter. In order to make meaningful\nstatements about an observed signal, or lack thereof, the energy scale of\nrecoiling nuclei in LXe must be known. Our understanding of this energy scale\nis contained in a quantity called the relative scintillation efficiency of\nnuclear recoils, or L_eff, and has been studied extensively in the literature,\nproducing seemingly contradictory results. I examine all the measurements of\nL_eff that exist, both direct and indirect, and extract the energy dependent\nbehavior that is statistically consistent globally with all values.\nAdditionally, I examine the measurements covering low energies (>~10 keV, where\nthe largest disagreements exist) and attempt to diagnose the systematic effects\nthat have led to the observed inconsistencies. I show that virtually all major\ndisparity arises due to efficiency roll-off of the detectors at the low\nenergies, and, when taking this into account, find that the observed behavior\nof L_eff supports a slowly and smoothly decreasing value with decreasing\nenergy. Finally, I discuss the prospects for future measurements, and derive a\npractical limit to what can be achieved. \n\n"}
{"id": "1008.0646", "contents": "Title: Towards the use of asteroseismology to investigate the nature of dark\n  matter Abstract: The annihilation of huge quantities of captured dark matter (DM) particles\ninside low-mass stars has been shown to change some of the stellar properties,\nsuch as the star's effective temperature or the way the energy is transported\nthroughout the star. While in the classical picture, without DM, a star of 1\nM_sun is expected to have a radiative interior during the main sequence, the\nsame star evolving in a halo of DM with a density rho_x > 10^8 GeV cm^-3 will\ndevelop a convective core in order to evacuate the energy from DM annihilation\nin a more efficient way. This convective core leaves a discontinuity in the\ndensity and sound-speed profiles that can be detected by the analysis of the\nstellar oscillations. In this paper we present an approach towards the use of\nasteroseismology to detect the signature produced by the presence of DM inside\na star, and we propose a new methodology to infer the properties of a DM halo\nfrom the stellar oscillations (such as the product of the DM density and the DM\nparticle-nucleon scattering cross-section). \n\n"}
{"id": "1008.1350", "contents": "Title: Extremal Index, Hitting Time Statistics and periodicity Abstract: We give conditions to prove the existence of an Extremal Index for general\nstationary stochastic processes by detecting the presence of one or more\nunderlying periodic phenomena. This theory, besides giving general useful tools\nto identify the extremal index, is also tailored to dynamical systems. In fact,\nwe apply this idea to analyse the possible Extreme Value Laws for the\nstochastic process generated by observations taken along dynamical orbits with\nrespect to various measures. As in the authors' previous works on this topic,\nthe analogy of these laws in the context of hitting time statistics is\nexplained and exploited extensively. \n\n"}
{"id": "1008.3392", "contents": "Title: How to Falsify the GR+LambdaCDM Model with Galaxy Redshift Surveys Abstract: A wide range of models describing modifications to General Relativity have\nbeen proposed, but no fundamental parameter set exists to describe them.\nSimilarly, no fundamental theory exists for dark energy to parameterize its\npotential deviation from a cosmological constant. This motivates a\nmodel-independent search for deviations from the concordance GR+LambdaCDM\ncosmological model in large galaxy redshift surveys. We describe two\nmodel-independent tests of the growth of cosmological structure, in the form of\nquantities that must equal one if GR+LambdaCDM is correct. The first, epsilon,\nwas introduced previously as a scale-independent consistency check between the\nexpansion history and structure growth. The second, upsilon, is introduced here\nas a test of scale-dependence in the linear evolution of matter density\nperturbations. We show that the ongoing and near-future galaxy redshift surveys\nWiggleZ, BOSS, and HETDEX will constrain these quantities at the 5-10% level,\nrepresenting a stringent test of concordance cosmology at different redshifts.\nWhen redshift space distortions are used to probe the growth of cosmological\nstructure, galaxies at higher redshift with lower bias are found to be most\npowerful in detecting deviations from the GR+LambdaCDM model. \n\n"}
{"id": "1009.0507", "contents": "Title: On the exchange of intersection and supremum of sigma-fields in\n  filtering theory Abstract: We construct a stationary Markov process with trivial tail sigma-field and a\nnondegenerate observation process such that the corresponding nonlinear\nfiltering process is not uniquely ergodic. This settles in the negative a\nconjecture of the author in the ergodic theory of nonlinear filters arising\nfrom an erroneous proof in the classic paper of H. Kunita (1971), wherein an\nexchange of intersection and supremum of sigma-fields is taken for granted. \n\n"}
{"id": "1009.1341", "contents": "Title: Component Specification in the Cactus Framework: The Cactus\n  Configuration Language Abstract: Component frameworks are complex systems that rely on many layers of\nabstraction to function properly. One essential requirement is a consistent\nmeans of describing each individual component and how it relates to both other\ncomponents and the whole framework. As component frameworks are designed to be\nflexible by nature, the description method should be simultaneously powerful,\nlead to efficient code, and be easy to use, so that new users can quickly adapt\ntheir own code to work with the framework. In this paper, we discuss the Cactus\nConfiguration Language (CCL) which is used to describe components (\"thorns'')\nin the Cactus Framework. The CCL provides a description language for the\nvariables, parameters, functions, scheduling and compilation of a component and\nincludes concepts such as interface and implementation which allow thorns\nproviding the same capabilities to be easily interchanged. We include several\napplication examples which illustrate how community toolkits use the CCL and\nCactus and identify needed additions to the language. \n\n"}
{"id": "1009.3920", "contents": "Title: Formation of Population III Stars in a flat FLRW Universe Abstract: Contrarily to general believe, a first-order cosmological perturbation theory\nbased on Einstein's General Theory of Relativity explains the formation of\nmassive primeval stars in a flat Friedmann-Lemaitre-Robertson-Walker universe\nafter decoupling of matter and radiation, whether or not Cold Dark Matter is\npresent. The growth rate of a density perturbation depends on the heat loss of\na perturbation during the contraction, but is independent of the particle mass.\nThe relativistic Jeans mass does depend on the particle mass. If the Cold Dark\nMatter particle mass is equal to the proton mass, then the relativistic Jeans\nmass is equal to 3500 solar masses, whereas the classical Jeans mass is a\nfactor 145 larger. \n\n"}
{"id": "1009.6057", "contents": "Title: Network Flows for Functions Abstract: We consider in-network computation of an arbitrary function over an arbitrary\ncommunication network. A network with capacity constraints on the links is\ngiven. Some nodes in the network generate data, e.g., like sensor nodes in a\nsensor network. An arbitrary function of this distributed data is to be\nobtained at a terminal node. The structure of the function is described by a\ngiven computation schema, which in turn is represented by a directed tree. We\ndesign computing and communicating schemes to obtain the function at the\nterminal at the maximum rate. For this, we formulate linear programs to\ndetermine network flows that maximize the computation rate. We then develop\nfast combinatorial primal-dual algorithm to obtain $\\epsilon$-approximate\nsolutions to these linear programs. We then briefly describe extensions of our\ntechniques to the cases of multiple terminals wanting different functions,\nmultiple computation schemas for a function, computation with a given desired\nprecision, and to networks with energy constraints at nodes. \n\n"}
{"id": "1010.0045", "contents": "Title: Contactless measurement of electrical conductance of a thin film of\n  amorphous germanium Abstract: We present a contactless method for measuring charge in a thin film of\namorphous germanium (a-Ge) with a nanoscale silicon MOSFET charge sensor. This\nmethod enables the measurement of conductance of the a-Ge film even in the\npresence of blocking contacts. At high bias voltage, the resistance of the\ncontacts becomes negligible and a direct measurement of current gives a\nconductance that agrees with that from the measurement of charge. This\ncharge-sensing technique is used to measure the temperature- and\nfield-dependence of the conductance, and they both agree with a model of Mott\nvariable-range hopping. From the model, we obtain a density of states at the\nFermi energy of 1.6 x 10^18 eV^-1 cm^-3 and a localization length of 1.06 nm.\nThis technique enables the measurement of conductance as low as 10^-19 S. \n\n"}
{"id": "1010.0476", "contents": "Title: Interference Alignment as a Rank Constrained Rank Minimization Abstract: We show that the maximization of the sum degrees-of-freedom for the static\nflat-fading multiple-input multiple-output (MIMO) interference channel is\nequivalent to a rank constrained rank minimization problem (RCRM), when the\nsignal spaces span all available dimensions. The rank minimization corresponds\nto maximizing interference alignment (IA) so that interference spans the lowest\ndimensional subspace possible. The rank constraints account for the useful\nsignal spaces spanning all available spatial dimensions. That way, we\nreformulate all IA requirements to requirements involving ranks. Then, we\npresent a convex relaxation of the RCRM problem inspired by recent results in\ncompressed sensing and low-rank matrix completion theory that rely on\napproximating rank with the nuclear norm. We show that the convex envelope of\nthe sum of ranks of the interference matrices is the normalized sum of their\ncorresponding nuclear norms and introduce tractable constraints that are\nasymptotically equivalent to the rank constraints for the initial problem. We\nalso show that our heuristic relaxation can be tuned for the multi-cell\ninterference channel. Furthermore, we experimentally show that in many cases\nthe proposed algorithm attains perfect interference alignment and in some cases\noutperforms previous approaches for finding precoding and zero-forcing matrices\nfor interference alignment. \n\n"}
{"id": "1010.0558", "contents": "Title: Analyzing Network Coding Gossip Made Easy Abstract: We give a new technique to analyze the stopping time of gossip protocols that\nare based on random linear network coding (RLNC). Our analysis drastically\nsimplifies, extends and strengthens previous results. We analyze RLNC gossip in\na general framework for network and communication models that encompasses and\nunifies the models used previously in this context. We show, in most settings\nfor the first time, that it converges with high probability in the\ninformation-theoretically optimal time. Most stopping times are of the form O(k\n+ T) where k is the number of messages to be distributed and T is the time it\ntakes to disseminate one message. This means RLNC gossip achieves \"perfect\npipelining\". Our analysis directly extends to highly dynamic networks in which\nthe topology can change completely at any time. This remains true even if the\nnetwork dynamics are controlled by a fully adaptive adversary that knows the\ncomplete network state. Virtually nothing besides simple O(kT) sequential\nflooding protocols was previously known for such a setting. While RLNC gossip\nworks in this wide variety of networks its analysis remains the same and\nextremely simple. This contrasts with more complex proofs that were put forward\nto give less strong results for various special cases. \n\n"}
{"id": "1010.4261", "contents": "Title: Supersymmetric Monojets at the Large Hadron Collider Abstract: Supersymmetric monojets may be produced at the Large Hadron Collider by the\nprocess qg -> squark neutralino_1 -> q neutralino_1 neutralino_1, leading to a\njet recoiling against missing transverse momentum. We discuss the feasibility\nand utility of the supersymmetric monojet signal. In particular, we examine the\npossible precision with which one can ascertain the neutralino_1-squark-quark\ncoupling via the rate for monojet events. Such a coupling contains information\non the composition of the neutralino_1 and helps bound dark matter direct\ndetection cross-sections and the dark matter relic density of the neutralino_1.\nIt also provides a check of the supersymmetric relation between gauge couplings\nand gaugino-quark-squark couplings. \n\n"}
{"id": "1010.4858", "contents": "Title: S-MATE: Secure Coding-based Multipath Adaptive Traffic Engineering Abstract: There have been several approaches to provisioning traffic between core\nnetwork nodes in Internet Service Provider (ISP) networks. Such approaches aim\nto minimize network delay, increase network capacity, and enhance network\nsecurity services. MATE (Multipath Adaptive Traffic Engineering) protocol has\nbeen proposed for multipath adaptive traffic engineering between an ingress\nnode (source) and an egress node (destination). Its novel idea is to avoid\nnetwork congestion and attacks that might exist in edge and node disjoint paths\nbetween two core network nodes.\n  This paper builds an adaptive, robust, and reliable traffic engineering\nscheme for better performance of communication network operations. This will\nalso provision quality of service (QoS) and protection of traffic engineering\nto maximize network efficiency. Specifically, we present a new approach, S-MATE\n(secure MATE) is developed to protect the network traffic between two core\nnodes (routers or switches) in a cloud network. S-MATE secures against a single\nlink attack/failure by adding redundancy in one of the operational paths\nbetween the sender and receiver. The proposed scheme can be built to secure\ncore networks such as optical and IP networks. \n\n"}
{"id": "1011.5064", "contents": "Title: Optimal Placement Algorithms for Virtual Machines Abstract: Cloud computing provides a computing platform for the users to meet their\ndemands in an efficient, cost-effective way. Virtualization technologies are\nused in the clouds to aid the efficient usage of hardware. Virtual machines\n(VMs) are utilized to satisfy the user needs and are placed on physical\nmachines (PMs) of the cloud for effective usage of hardware resources and\nelectricity in the cloud. Optimizing the number of PMs used helps in cutting\ndown the power consumption by a substantial amount.\n  In this paper, we present an optimal technique to map virtual machines to\nphysical machines (nodes) such that the number of required nodes is minimized.\nWe provide two approaches based on linear programming and quadratic programming\ntechniques that significantly improve over the existing theoretical bounds and\nefficiently solve the problem of virtual machine (VM) placement in data\ncenters. \n\n"}
{"id": "1012.2798", "contents": "Title: A strong invariance principle for nonconventional sums Abstract: This paper deals with strong invariance principles (known also as strong\napproximation theorems) for sums of the form\n$\\sum_{n=1}^{[Nt]}F\\big(X(n),X(2n),...,X(kn), X(q_{k+1}(n)),X(q_{k+2}(n)),...,\nX(q_\\ell(n))\\big)$ \n\n"}
{"id": "1012.5184", "contents": "Title: Floquet theory of Cooper pair pumping Abstract: In this work we derive a general formula for the charge pumped in a\nsuperconducting nanocircuit. Our expression generalizes previous results in\nseveral ways, it is applicable both in the adiabatic and in the non-adiabatic\nregimes and it takes into account also the effect of an external environment.\nMore specifically, by applying Floquet theory to Cooper pair pumping, we show\nthat under a cyclic evolution the total charge transferred through the circuit\nis proportional to the derivative of the associated Floquet quasi-energy with\nrespect to the superconducting phase difference. In the presence of an external\nenvironment the expression for the transferred charge acquires a transparent\nform in the Floquet representation. It is given by the weighted sum of the\ncharge transferred in each Floquet state, the weights being the diagonal\ncomponents of the stationary density matrix of the system expressed in the\nFloquet basis. In order to test the power of this formulation we apply it to\nthe study of pumping in a Cooper pair sluice. We reproduce the known results in\nthe adiabatic regime and we show new data in the non-adiabatic case. \n\n"}
{"id": "1101.3520", "contents": "Title: Error-Free Multi-Valued Consensus with Byzantine Failures Abstract: In this paper, we present an efficient deterministic algorithm for consensus\nin presence of Byzantine failures. Our algorithm achieves consensus on an\n$L$-bit value with communication complexity $O(nL + n^4 L^{0.5} + n^6)$ bits,\nin a network consisting of $n$ processors with up to $t$ Byzantine failures,\nsuch that $t<n/3$. For large enough $L$, communication complexity of the\nproposed algorithm approaches $O(nL)$ bits. In other words, for large $L$, the\ncommunication complexity is linear in the number of processors in the network.\nThis is an improvement over the work of Fitzi and Hirt (from PODC 2006), who\nproposed a probabilistically correct multi-valued Byzantine consensus algorithm\nwith a similar complexity for large $L$. In contrast to the algorithm by Fitzi\nand Hirt, our algorithm is guaranteed to be always error-free. Our algorithm\nrequire no cryptographic technique, such as authentication, nor any secret\nsharing mechanism. To the best of our knowledge, we are the first to show that,\nfor large $L$, error-free multi-valued Byzantine consensus on an $L$-bit value\nis achievable with $O(nL)$ bits of communication. \n\n"}
{"id": "1101.4340", "contents": "Title: Outflow in Overlooked Luminous Quasar: Subaru Observations of AKARI\n  J1757+5907 Abstract: We present Subaru observations of the newly discovered luminous quasar AKARI\nJ1757+5907, which shows an absorption outflow in its spectrum. The absorption\nconsists of 9 distinct troughs, and our analysis focuses on the troughs at ~\n-1000$ km s^{-1} for which we can measure accurate column densities of He I*,\nFe II and Mg II. We use photoionization models to constrain the ionization\nparameter, total hydrogen column density, and the number density of the\noutflowing gas. These constraints yield lower limits for the distance, mass\nflow rate and kinetic luminosity for the outflow of 3.7 kpc, 70 M_{sun}\nyr^{-1}, and 2.0 x 10^{43} ergs s^{-1}, respectively. Such mass flow rate value\ncan contribute significantly to the metal enrichment of the intra-cluster\nmedium. We find that this moderate velocity outflow is similar to those\nrecently discovered in massive post-starburst galaxies. Finally, we describe\nthe scientific potential of future observations targeting this object. \n\n"}
{"id": "1101.5923", "contents": "Title: Spectral evolution and the onset of the X-ray GRB afterglow Abstract: Based on light curves from the Swift Burst Analyser, we investigate whether a\n`dip' feature commonly seen in the early-time hardness ratios of Swift-XRT data\ncould arise from the juxtaposition of the decaying prompt emission and rising\nafterglow. We are able to model the dip as such a feature, assuming the\nafterglow rises as predicted by Sari & Piran (1999). Using this model we\nmeasure the initial bulk Lorentz factor of the fireball. For a sample of 23\nGRBs we find a median value of Gamma_0=225, assuming a constant-density\ncircumburst medium; or Gamma_0=93 if we assume a wind-like medium. \n\n"}
{"id": "1102.1068", "contents": "Title: Interaction of Electromagnetic P-Wave with Metal Films Located Between\n  Two Dielectric Mediums Abstract: Generalization of the theory of interaction of the electromagnetic P-waves\nwith a metal film on a case of the film concluded between two dielectric\nenvironments is carried out. \n\n"}
{"id": "1102.4336", "contents": "Title: The origin of variability of the intermediate-mass black-hole ULX system\n  HLX-1 in ESO 243-49 Abstract: The ultra-luminous intermediate-mass black-hole system HLX-1 in the ESO\n243-49 galaxy exhibits variability with a possible recurrence time of a few\nhundred days. Finding the origin of this variability would constrain the still\nlargely unknown properties of this extraordinary object. Since it exhibits an\nintensity-hardness behavior characteristic of black-hole X-ray transients, we\nhave analyzed the variability of HLX-1 in the framework of the disk instability\nmodel that explains outbursts of such systems. We find that the long-term\nvariability of HLX-1 is unlikely to be explained by a model in which outbursts\nare triggered by thermal-viscous instabilities in an accretion disc. Possible\nalternatives include the instability in a radiation-pressure dominated disk but\nwe argue that a more likely explanation is a modulated mass-transfer due to\ntidal stripping of a star on an eccentric orbit around the intermediate-mass\nblack hole. We consider an evolutionary scenario leading to the creation of\nsuch a system and estimate the probability of its observation. We conclude,\nusing a simplified dynamical model of the post-collapse cluster, that no more\nthan 1/100 to 1/10 of Mbh < 10^4 Msun IMBHs - formed by run-away stellar\nmergers in the dense collapsed cores of young clusters - could have a few times\n1 Msun Main-Sequence star evolve to an AGB on an orbit eccentric enough for\nmass transfer at periapse, while avoiding collisional destruction or being\nscattered into the IMBH by 2-body encounters. The finite but low probability of\nthis configuration is consistent with the uniqueness of HLX-1. We note,\nhowever, that the actual response of a standard accretion disk to bursts of\nmass transfer may be too slow to explain the observations unless the orbit is\nclose to parabolic (and hence even rarer) and/or additional heating, presumably\nlinked to the highly time-dependent gravitational potential, are invoked. \n\n"}
{"id": "1103.2289", "contents": "Title: A Token Based Algorithm to Distributed Computation in Sensor Networks Abstract: We consider distributed algorithms for data aggregation and function\ncomputation in sensor networks. The algorithms perform pairwise computations\nalong edges of an underlying communication graph. A token is associated with\neach sensor node, which acts as a transmission permit. Nodes with active tokens\nhave transmission permits; they generate messages at a constant rate and send\neach message to a randomly selected neighbor. By using different strategies to\ncontrol the transmission permits we can obtain tradeoffs between message and\ntime complexity. Gossip corresponds to the case when all nodes have permits all\nthe time. We study algorithms where permits are revoked after transmission and\nrestored upon reception. Examples of such algorithms include Simple-Random\nWalk(SRW), Coalescent-Random-Walk(CRW) and Controlled Flooding(CFLD) and their\nhybrid variants. SRW has a single node permit, which is passed on in the\nnetwork. CRW, initially initially has a permit for each node but these permits\nare revoked gradually. The final result for SRW and CRW resides at a single(or\nfew) random node(s) making a direct comparison with GOSSIP difficult. A hybrid\ntwo-phase algorithm switching from CRW to CFLD at a suitable pre-determined\ntime can be employed to achieve consensus. We show that such hybrid variants\nachieve significant gains in both message and time complexity. The per-node\nmessage complexity for n-node graphs, such as 2D mesh, torii, and Random\ngeometric graphs, scales as $O(polylog(n))$ and the corresponding time\ncomplexity scales as O(n). The reduced per-node message complexity leads to\nreduced energy utilization in sensor networks. \n\n"}
{"id": "1103.2662", "contents": "Title: Cost Analysis of Redundancy Schemes for Distributed Storage Systems Abstract: Distributed storage infrastructures require the use of data redundancy to\nachieve high data reliability. Unfortunately, the use of redundancy introduces\nstorage and communication overheads, which can either reduce the overall\nstorage capacity of the system or increase its costs. To mitigate the storage\nand communication overhead, different redundancy schemes have been proposed.\nHowever, due to the great variety of underlaying storage infrastructures and\nthe different application needs, optimizing these redundancy schemes for each\nstorage infrastructure is cumbersome. The lack of rules to determine the\noptimal level of redundancy for each storage configuration leads developers in\nindustry to often choose simpler redundancy schemes, which are usually not the\noptimal ones. In this paper we analyze the cost of different redundancy schemes\nand derive a set of rules to determine which redundancy scheme minimizes the\nstorage and the communication costs for a given system configuration.\nAdditionally, we use simulation to show that theoretically-optimal schemes may\nnot be viable in a realistic setting where nodes can go off-line and repairs\nmay be delayed. In these cases, we identify which are the trade-offs between\nthe storage and communication overheads of the redundancy scheme and its data\nreliability. \n\n"}
{"id": "1103.2768", "contents": "Title: Reconstruction of supernova {\\nu}_{\\mu}, {\\nu}_{\\tau}, anti-{\\nu}_{\\mu},\n  and anti-{\\nu}_{\\tau} neutrino spectra at scintillator detectors Abstract: We present a new technique to directly reconstruct the spectra of mu/tau\nneutrinos and antineutrinos from a supernova, using neutrino-proton elastic\nscattering events (nu+p to nu+p) at scintillator detectors. These neutrinos,\nunlike electron neutrinos and antineutrinos, have only neutral current\ninteractions, which makes it very challenging, with any reaction, to detect\nthem and measure their energies. With updated inputs from theory and\nexperiments, we show that this channel provides a robust and sensitive measure\nof their spectra. Given the low yields and lack of spectral information in\nother neutral current channels, this is perhaps the only realistic way to\nextract such information. This will be indispensable for understanding flavor\noscillations of SN neutrinos, as it is likely to be impossible to disentangle\nneutrino mixing from astrophysical uncertainties in a SN without adequate\nspectral coverage of all flavors. We emphasize that scintillator detectors,\ne.g., Borexino, KamLAND, and SNO+, have the capability to observe these events,\nbut they must be adequately prepared with a trigger for a burst of low-energy\nevents. We also highlight the capabilities of a larger detector like LENA. \n\n"}
{"id": "1104.5243", "contents": "Title: Pushing the limits for medical image reconstruction on recent standard\n  multicore processors Abstract: Volume reconstruction by backprojection is the computational bottleneck in\nmany interventional clinical computed tomography (CT) applications. Today\nvendors in this field replace special purpose hardware accelerators by standard\nhardware like multicore chips and GPGPUs. Medical imaging algorithms are on the\nverge of employing High Performance Computing (HPC) technology, and are\ntherefore an interesting new candidate for optimization. This paper presents\nlow-level optimizations for the backprojection algorithm, guided by a thorough\nperformance analysis on four generations of Intel multicore processors\n(Harpertown, Westmere, Westmere EX, and Sandy Bridge).\n  We choose the RabbitCT benchmark, a standardized testcase well supported in\nindustry, to ensure transparent and comparable results. Our aim is to provide\nnot only the fastest possible implementation but also compare to performance\nmodels and hardware counter data in order to fully understand the results. We\nseparate the influence of algorithmic optimizations, parallelization, SIMD\nvectorization, and microarchitectural issues and pinpoint problems with current\nSIMD instruction set extensions on standard CPUs (SSE, AVX). The use of\nassembly language is mandatory for best performance. Finally we compare our\nresults to the best GPGPU implementations available for this open competition\nbenchmark. \n\n"}
{"id": "1105.1278", "contents": "Title: Mixed-mode oscillations and interspike interval statistics in the\n  stochastic FitzHugh-Nagumo model Abstract: We study the stochastic FitzHugh-Nagumo equations, modelling the dynamics of\nneuronal action potentials, in parameter regimes characterised by mixed-mode\noscillations. The interspike time interval is related to the random number of\nsmall-amplitude oscillations separating consecutive spikes. We prove that this\nnumber has an asymptotically geometric distribution, whose parameter is related\nto the principal eigenvalue of a substochastic Markov chain. We provide\nrigorous bounds on this eigenvalue in the small-noise regime, and derive an\napproximation of its dependence on the system's parameters for a large range of\nnoise intensities. This yields a precise description of the probability\ndistribution of observed mixed-mode patterns and interspike intervals. \n\n"}
{"id": "1105.2243", "contents": "Title: More about Base Station Location Games Abstract: This paper addresses the problem of locating base stations in a certain area\nwhich is highly populated by mobile stations; each mobile station is assumed to\nselect the closest base station. Base stations are modeled by players who\nchoose their best location for maximizing their uplink throughput. The approach\nof this paper is to make some simplifying assumptions in order to get\ninterpretable analytical results and insights to the problem under study.\nSpecifically, a relatively complete Nash equilibrium (NE) analysis is conducted\n(existence, uniqueness, determination, and efficiency). Then, assuming that the\nbase station location can be adjusted dynamically, the best-response dynamics\nand reinforcement learning algorithm are applied, discussed, and illustrated\nthrough numerical results. \n\n"}
{"id": "1106.1681", "contents": "Title: Inhibited spontaneous emission of quantum dots observed in a 3D photonic\n  band gap Abstract: We present time-resolved emission experiments of semiconductor quantum dots\nin silicon 3D inverse-woodpile photonic band gap crystals. A systematic study\nis made of crystals with a range of pore radii to tune the band gap relative to\nthe emission frequency. The decay rates averaged over all dipole orientations\nare inhibited by a factor of 10 in the photonic band gap and enhanced up to 2?\noutside the gap, in agreement with theory. We discuss the effects of spatial\ninhomogeneity, nonradiative decay, and transition dipole orientations on the\nobserved inhibition in the band gap. \n\n"}
{"id": "1106.2275", "contents": "Title: Byzantine Fault Tolerance of Regenerating Codes Abstract: Recent years have witnessed a slew of coding techniques custom designed for\nnetworked storage systems. Network coding inspired regenerating codes are the\nmost prolifically studied among these new age storage centric codes. A lot of\neffort has been invested in understanding the fundamental achievable trade-offs\nof storage and bandwidth usage to maintain redundancy in presence of different\nmodels of failures, showcasing the efficacy of regenerating codes with respect\nto traditional erasure coding techniques. For practical usability in open and\nadversarial environments, as is typical in peer-to-peer systems, we need\nhowever not only resilience against erasures, but also from (adversarial)\nerrors. In this paper, we study the resilience of generalized regenerating\ncodes (supporting multi-repairs, using collaboration among newcomers) in the\npresence of two classes of Byzantine nodes, relatively benign selfish\n(non-cooperating) nodes, as well as under more active, malicious polluting\nnodes. We give upper bounds on the resilience capacity of regenerating codes,\nand show that the advantages of collaborative repair can turn to be detrimental\nin the presence of Byzantine nodes. We further exhibit that system mechanisms\ncan be combined with regenerating codes to mitigate the effect of rogue nodes. \n\n"}
{"id": "1106.3186", "contents": "Title: Casimir force for cosmological domain walls Abstract: We calculate the vacuum fluctuations that may affect the evolution of\ncosmological domain walls. Considering domain walls, which are classically\nstable and have interaction with a scalar field, we show that explicit symmetry\nviolation in the interaction may cause quantum bias that can solve the\ncosmological domain wall problem. \n\n"}
{"id": "1106.5918", "contents": "Title: Emission line - radio correlation for Low Luminosity Compact sources.\n  Evolution schemes Abstract: We present radio and optical analysis of a sample of Low Luminosity Compact\n(LLC) objects, selected from FIRST survey and observed with MERLIN at L-band\nand C-band. The main criterion used for selection was luminosity of the objects\nand approximately one third of the CSS sources from the new sample have a value\nof radio luminosity comparable to FR\\,Is.The analysis of a radio properties of\nLLC sources show they occupy the space in radio power versus linear size\ndiagram below the main evolutionary path of radio objects. We suggest that many\nof them might be short-lived objects, and their radio emission may be disrupted\nseveral times before becoming FR\\,IIs. The optical analysis of the LLC sources\nwere made based on the available SDSS images and spectra. We have classified\nthe sources as high and low excitation galaxies (HEG and LEG, respectively).\nThe optical and radio properties of the LLC sample are in general consistent\nwith brighter CSSs and large-scale radio sources. However, when LLC are added\nto the other samples, HEG and LEG seem to follow independent, parallel\nevolutionary tracks. LLC and luminous CSS behave like FR\\,II sources, while\nFR\\,I seem to belong to a different group of objects, concerning ionization\nmechanisms. Based on our results, we propose the independent, parallel\nevolutionary tracks for HEG and LEG sources, evolving from GPS - CSS - FR. \n\n"}
{"id": "1106.6008", "contents": "Title: Random walks in random environments without ellipticity Abstract: We consider random walks in random environments on Z^d. Under a transitivity\nhypothesis that is much weaker than the customary ellipticity condition, and\nassuming an absolutely continuous invariant measure on the space of the\nenvironments, we prove the ergodicity of the annealed process w.r.t. the\ndynamics \"from the point of view of the particle\". This implies in particular\nthat the environment viewed from the particle is ergodic. As an example of\napplication of this result, we give a general form of the quenched Invariance\nPrinciple for walks in doubly stochastic environments with zero local drift\n(martingale condition). \n\n"}
{"id": "1106.6017", "contents": "Title: The effect of extreme confinement on the nonlinear-optical response of\n  quantum wires Abstract: This work focuses on understanding the nonlinear-optical response of a 1-D\nquantum wire embedded in 2-D space when quantum-size effects in the transverse\ndirection are minimized using an extremely weighted delta function potential.\nOur aim is to establish the fundamental basis for understanding the effect of\ngeometry on the nonlinear-optical response of quantum loops that are formed\ninto a network of quantum wires. Using the concept of leaky quantum wires, it\nis shown that in the limit of full confinement, the sum rules are obeyed when\nthe transverse infinite-energy continuum states are included. While the\ncontinuum states associated with the transverse wavefunction do not contribute\nto the nonlinear optical response, they are essential to preserving the\nvalidity of the sum rules. This work is a building block for future studies of\nnonlinear-optical enhancement of quantum graphs (which include loops and bent\nwires) based on their geometry. These properties are important in quantum\nmechanical modeling of any response function of quantum-confined systems,\nincluding the nonlinear-optical response of any system in which there is\nconfinement in at leat one dimension, such as nanowires, which provide\nconfinement in two dimensions. \n\n"}
{"id": "1108.1551", "contents": "Title: Nearby low-luminosity GRBs as the sources of ultra-high energy cosmic\n  rays revisited Abstract: Low-luminosity gamma-ray bursts (GRBs) with luminosity . 10^49erg/s probably\nconsititute a distinct population from the classic high-luminosity GRBs. They\nare the most luminous objects detected so far within ~ 100 Mpc, the horizon\ndistance of ultra-high energy cosmic rays (UHECRs), so they are considered to\nbe candidate sources of UHECRs. It was recently argued that the energy\nproduction rate in UHECRs is much larger than that in gamma-ray photons of long\nGRBs measured by the Fermi satellite, which, if true, would challenge the view\nthat GRBs can be the sources of UHECRs. We here suggest that many of the low\nluminosity GRBs, due to their low luminosity, can not trigger the current GRB\ndetectors and hence their contribution to the local gamma-ray energy production\nrate is missing. We find that the real local energy production rate by\nlow-luminosity GRBs, taking into account the missing part, which constitutes a\ndominant fraction of the total amount, could be sufficient to account for the\nflux of UHECRs. Due to the low-luminosity, only intermediate-mass or heavy\nnuclei can be accelerated to ~ 10^20 eV. We discuss the acceleration and\nsurvival of these UHE nuclei in low-luminosity GRBs, especially in those\nmissing low-luminosity GRBs. At last, the accompanying diffuse neutrino flux\nfrom the whole low-luminosity GRB population is calculated. \n\n"}
{"id": "1108.4471", "contents": "Title: Synchrony vs. Causality in Asynchronous Petri Nets Abstract: Given a synchronous system, we study the question whether the behaviour of\nthat system can be exhibited by a (non-trivially) distributed and hence\nasynchronous implementation. In this paper we show, by counterexample, that\nsynchronous systems cannot in general be implemented in an asynchronous fashion\nwithout either introducing an infinite implementation or changing the causal\nstructure of the system behaviour. \n\n"}
{"id": "1108.4910", "contents": "Title: Dynamical Tides in Compact White Dwarf Binaries: Tidal Synchronization\n  and Dissipation Abstract: In compact white dwarf (WD) binary systems (with periods ranging from minutes\nto hours), dynamical tides involving the excitation and dissipation of gravity\nwaves play a dominant role in determining the physical conditions of the WDs\nprior to mass transfer or binary merger. We calculate the amplitude of the\ntidally excited gravity waves as a function of the tidal forcing frequency\n\\omega=2(\\Omega-\\Omega_s) (where \\Omega is the orbital frequency and \\Omega_s\nis the spin frequency) for several realistic carbon-oxygen WD models, assuming\nthat the waves are efficiently dissipated in the outer layer of the star by\nnonlinear effects or radiative damping. The mechanism of wave excitation in WDs\nis complex due to the sharp features associated with composition changes inside\nthe WD, and in our WD models gravity waves are launched just below the\nhelium-carbon boundary. We find that the tidal torque on the WD and the related\ntidal energy transfer rate, \\dot E_{\\rm tide}, depend on \\omega in an erratic\nway. On average, \\dot E_{\\rm tide} scales approximately as \\Omega^5\\omega^5 for\na large range of tidal frequencies. We also study the effects of dynamical\ntides on the long-term evolution of WD binaries. Above a critical orbital\nfrequency \\Omega_c, corresponding to an orbital period of order one hour\n(depending on WD models), dynamical tides efficiently drive \\Omega_s toward\n\\Omega, although a small, almost constant degree of asynchronization\n(\\Omega-\\Omega_s\\sim {\\rm constant}) is maintained even at the smallest binary\nperiods. While the orbital decay is always dominated by gravitational\nradiation, the tidal energy transfer can induce significant phase error in the\nlow-frequency gravitational waveforms, detectable by the planned LISA project.\nTidal dissipation may also lead to significant heating of the WD envelope and\nbrightening of the system long before binary merger. \n\n"}
{"id": "1108.5893", "contents": "Title: Edge-preserving self-healing: keeping network backbones densely\n  connected Abstract: Healing algorithms play a crucial part in distributed P2P networks where\nfailures occur continuously and frequently. Several self-healing algorithms\nhave been suggested recently [IPDPS'08, PODC'08, PODC'09, PODC'11] in a line of\nwork that has yielded gradual improvements in the properties ensured on the\ngraph. This work motivates a strong general phenomenon of edge-preserving\nhealing that aims at obtaining self-healing algorithms with the constraint that\nall original edges in the graph (not deleted by the adversary), be retained in\nevery intermediate graph.\n  The previous algorithms, in their nascent form, are not explicitly edge\npreserving. In this paper, we show they can be suitably modified (We introduce\nXheal+, an edge-preserving version of Xheal[PODC'11]). Towards this end, we\npresent a general self-healing model that unifies the previous models. The main\ncontribution of this paper is not in the technical complexity, rather in the\nsimplicity with which the edge-preserving property can be ensured and the\nmessage that this is a crucial property with several benefits. In particular,\nwe highlight this by showing that, almost as an immediate corollary, subgraph\ndensities are preserved or increased. Maintaining density is a notion motivated\nby the fact that in certain distributed networks, certain nodes may require and\ninitially have a larger number of inter-connections. It is vital that a healing\nalgorithm, even amidst failures, respect these requirements. Our suggested\nmodifications yield such subgraph density preservation as a by product. In\naddition, edge preservation helps maintain any subgraph induced property that\nis monotonic. Also, algorithms that are edge-preserving require minimal\nalteration of edges which can be an expensive cost in healing - something that\nhas not been modeled in any of the past work. \n\n"}
{"id": "1109.0206", "contents": "Title: Sub-shot noise sensitivities without entanglement Abstract: It is commonly maintained that entanglement is necessary to beat the shot\nnoise limit in the sensitivity with which certain parameters can be measured in\ninterferometric experiments. Here we show that, with a fluctuating number of\ntwo-mode bosons, the shot-noise limit can be beaten by non-entangled bosonic\nstates with all bosons in one mode. For a given finite maximum number of\nbosons, we calculate the optimal one- and two-mode bosonic states, and show\nthat in the absence of losses, NOON states are the optimal two-mode bosonic\nstates. \n\n"}
{"id": "1109.1130", "contents": "Title: Multi-wavelength observations of Proxima Centauri Abstract: We report simultaneous observations of the nearby flare star Proxima Centauri\nwith VLT/UVES and XMM-Newton over three nights in March 2009. Our optical and\nX-ray observations cover the star's quiescent state, as well as its flaring\nactivity and allow us to probe the stellar atmospheric conditions from the\nphotosphere into the chromosphere, and then the corona during its different\nactivity stages. Using the X-ray data, we investigate variations in coronal\ndensities and abundances and infer loop properties for an intermediate-sized\nflare. The optical data are used to investigate the magnetic field and its\npossible variability, to construct an emission line list for the chromosphere,\nand use certain emission lines to construct physical models of Proxima\nCentauri's chromosphere.\n  We report the discovery of a weak optical forbidden Fe xiii line at 3388 AA\nduring the more active states of Proxima Centauri. For the intermediate flare,\nwe find two secondary flare events that may originate in neighbouring loops,\nand discuss the line asymmetries observed during this flare in H i, He i, and\nCa ii lines. The high time-resolution in the H alpha line highlights strong\ntemporal variations in the observed line asymmetries, which re-appear during a\nsecondary flare event. We also present theoretical modelling with the stellar\natmosphere code PHOENIX to construct flaring chromospheric models. \n\n"}
{"id": "1109.2046", "contents": "Title: Solvent induced current-voltage hysteresis and negative differential\n  resistance in molecular junctions Abstract: We consider a single molecule circuit embedded into solvent. The Born\ndielectric solvation model is combined with Keldysh nonequilibrium Green's\nfunctions to describe the electron transport properties of the system.\nDepending on the dielectric constant, the solvent induces multiple\nnonequilibrium steady states with corresponding hysteresis in molecular\ncurrent-voltage characteristics as well as negative differential resistance. We\nidentify the physical range of solvent and molecular parameters where the\neffects are present. The position of the negative differential resistance peak\ncan be controlled by the dielectric constant of the solvent. \n\n"}
{"id": "1110.4156", "contents": "Title: Secure Execution of Distributed Session Programs Abstract: The development of the SJ Framework for session-based distributed programming\nis part of recent and ongoing research into integrating session types and\npractical, real-world programming languages. SJ programs featuring session\ntypes (protocols) are statically checked by the SJ compiler to verify the key\nproperty of communication safety, meaning that parties engaged in a session\nonly communicate messages, including higher-order communications via session\ndelegation, that are compatible with the message types expected by the\nrecipient.\n  This paper presents current work on security aspects of the SJ Framework.\nFirstly, we discuss our implementation experience from improving the SJ Runtime\nplatform with security measures to protect and augment communication safety at\nruntime. We implement a transport component for secure session execution that\nuses a modified TLS connection with authentication based on the Secure Remote\nPassword (SRP) protocol. The key technical point is the delicate treatment of\nsecure session delegation to counter a previous vulnerability. We find that the\nmodular design of the SJ Runtime, based on the notion of an Abstract Transport\nfor session communication, supports rapid extension to utilise additional\ntransports whilst separating this concern from the application-level session\nprogramming task. In the second part of this abstract, we formally prove the\ntarget security properties by modelling the extended SJ delegation protocols in\nthe pi-calculus. \n\n"}
{"id": "1110.4744", "contents": "Title: A search for possible dark matter subhalos as IACT targets in the First\n  Fermi-LAT Source Catalog Abstract: We present a systematic search for potential dark matter subhalos in our\nGalaxy among the 630 unassociated sources included in the First Fermi-LAT\nSource Catalog. Assuming a hypothetical dark matter particle that could\ngenerate observable gamma-ray photons beyond the Fermi energy range through\nself-annihilation, we look for reasonable targets for ground-based Imaging\nAtmospheric Cherenkov Telescopes at energies E > 100 GeV. In order to narrow\nthe origin of these enigmatic sources, we look for their possible counterparts\nin other wavelengths including X-ray, radio, and optical spectroscopy. We find\nthat the synergy between Fermi and Cherenkov telescopes, along with\nmultiwavelength observations, could play a key role in indirect searches for\ndark matter. \n\n"}
{"id": "1111.2915", "contents": "Title: Ultrafast all-optical switching by single photons Abstract: An outstanding goal in quantum optics is the realization of fast optical\nnon-linearities at the single-photon level. Such non-linearities would allow\nfor the realization of optical devices with new functionalities such as a\nsingle-photon switch/transistor or a controlled-phase gate, which could form\nthe basis of future quantum optical technologies. While non-linear optics\neffects at the single-emitter level have been demonstrated in different\nsystems, including atoms coupled to Fabry-Perot or toroidal micro-cavities,\nsuper-conducting qubits in strip-line resonators or quantum dots (QDs) in\nnano-cavities, none of these experiments so far has demonstrated single-photon\nswitching on ultrafast timescales. Here, we demonstrate that in a strongly\ncoupled QD-cavity system the presence of a single photon on one of the\nfundamental polariton transitions can turn on light scattering on a transition\nfrom the first to the second Jaynes-Cummings manifold with a switching time of\n20 ps. As an additional device application, we use this non-linearity to\nimplement a single-photon pulse-correlator. Our QD-cavity system could form the\nbuilding-block of future high-bandwidth photonic networks operating in the\nquantum regime. \n\n"}
{"id": "1111.5596", "contents": "Title: Accelerating QDP++/Chroma on GPUs Abstract: Extensions to the C++ implementation of the QCD Data Parallel Interface are\nprovided enabling acceleration of expression evaluation on NVIDIA GPUs. Single\nexpressions are off-loaded to the device memory and execution domain leveraging\nthe Portable Expression Template Engine and using Just-in-Time compilation\ntechniques. Memory management is automated by a software implementation of a\ncache controlling the GPU's memory. Interoperability with existing Krylov space\nsolvers is demonstrated and special attention is paid on 'Chroma readiness'.\nNon-kernel routines in lattice QCD calculations typically not subject of\nhand-tuned optimisations are accelerated which can reduce the effects otherwise\nsuffered from Amdahl's Law. \n\n"}
{"id": "1111.7315", "contents": "Title: Resonance fluorescence in a waveguide geometry Abstract: We show how to calculate the first- and second-order statistics of the\nscattered fields for an arbitrary intensity coherent state light field\ninteracting with a two-level system in a waveguide geometry. Specifically, we\ncalculate the resonance fluorescence from the qubit, using input-output\nformalism. We derive the transmission and reflection coefficients, and\nillustrate the bunching and anti-bunching of light that is scattered in the\nforward and backward directions, respectively. Our results agree with previous\ncalculations on one- and two-photon scattering as well as those that are based\non the master equation approach. \n\n"}
{"id": "1112.3040", "contents": "Title: Faint Submillimeter Galaxies behind the Massive Lensing Cluster A2390 Abstract: Current studies on Submillimeter Galaxies (SMGs) mostly focus on bright\nsources with 850 micron flux greater than 2 mJy, and the results have shown\nthat they are likely high redshift mergers with z > 2 and could be a dominant\npopulation on star formation in the early Universe. However, bright SMGs only\ncontributes 20-30% of the 850 micron extragalactic background light (EBL),\nmeaning the bulk of the cosmic star formation still hidden by dust and our\ncurrent understanding is biased. We have started a program to study an unbiased\nsample of highly-amplified and intrinsically faint SCUBA detected SMGs in the\nfield of massive lensing clusters. Here we report the newly obtained SMA\nobservations at 850 micron on one of our sample source, A2390-5, behind the\nmassive lensing cluster A2390. We successfully detect the source with a flux of\n3.95 mJy. Surprisingly, it does not have any counterpart in any other\nwavelengths even though there are tentative candidates, which implies a very\ndusty and high-z nature. With less than 1\" positional accuracy and the adoption\nof z = 5, we obtain the amplification factor of 12 using current lensing model,\nwhich makes A2390-5 a faint SMG with a de-lensed flux of 0.33 mJy. Together\nwith our previous detection on another faint SMG, both of them have no\ncounterpart in other wavelengths and their properties are very different than\npreviously thought from the single-dish data. We emphasize the importance of\ndirect submillimeter high-resolution studies on faint SMGs, which could be the\ndominant population of the high-z star formation. \n\n"}
{"id": "1112.4978", "contents": "Title: Fully coupled forward-backward stochastic dynamics and functional\n  differential systems Abstract: This article introduces and solves a general class of fully coupled\nforward-backward stochastic dynamics by investigating the associated system of\nfunctional differential equations. As a consequence, we are able to solve many\ndifferent types of forward-backward stochastic differential equations (FBSDEs)\nthat do not fit in the classical setting. In our approach, the equations are\nrunning in the same time direction rather than in a forward and backward way,\nand the conflicting nature of the structure of FBSDEs is therefore avoided. \n\n"}
{"id": "1112.5816", "contents": "Title: XMM-Newton observation of PSR B2224+65 and its jet Abstract: We have investigated the pulsar PSR B2224+65 and its X-ray jet with\nXMM-Newton. Apart from the long X-ray jet which is almost perpendicular to the\ndirection of proper motion, a putative extended feature at the pulsar position,\nwhich oriented in the opposite direction of the proper motion, is also\nsuggested by this deep X-ray imaging. Non-detection of any coherent X-ray\npulsation disfavors the magnetospheric origin of the X-rays observed from the\nposition of PSR B2224+65 and hence suggest that the interpretation of pulsar\nwind nebula is more viable. We have also probed the origin of PSR B2224+65 and\nidentified a runaway star, which possibly originated from the Cygnus OB9\nassociation, as a candidate for the former binary companion of the neutron\nstar's progenitor. \n\n"}
{"id": "1201.0329", "contents": "Title: Random walks on random horospheric products Abstract: By developing the entropy theory of random walks on equivalence relations and\nanalyzing the asymptotic geometry of horospheric products we describe the\nPoisson boundary for random walks on random horospheric products of trees. \n\n"}
{"id": "1201.2937", "contents": "Title: Opportunistic Adaptive Relaying in Cognitive Radio Networks Abstract: Combining cognitive radio technology with user cooperation could be\nadvantageous to both primary and secondary transmissions. In this paper, we\npropose a first relaying scheme for cognitive radio networks (called \"Adaptive\nrelaying scheme 1\"), where one relay node can assist the primary or the\nsecondary transmission with the objective of improving the outage probability\nof the secondary transmission with respect to a primary outage probability\nthreshold. Upper bound expressions of the secondary outage probability using\nthe proposed scheme are derived over Rayleigh fading channels. Numerical and\nsimulation results show that the secondary outage probability using the\nproposed scheme is lower than that of other relaying schemes. Then, we extend\nthe proposed scheme to the case where the relay node has the ability to decode\nboth the primary and secondary signals and also can assist simultaneously both\ntransmissions. Simulations show the performance improvement that can be\nobtained due to this extension in terms of secondary outage probability. \n\n"}
{"id": "1201.5866", "contents": "Title: A Borel-Cantelli lemma and its applications Abstract: We give a version of the Borel-Cantelli lemma. As an application, we prove an\nalmost sure local central limit theorem. As another application, we prove a\ndynamical Borel-Cantelli lemma for systems with sufficiently fast decay of\ncorrelations with respect to Lipschitz observables. \n\n"}
{"id": "1202.0006", "contents": "Title: Magnetic Response in the Holographic Insulator/Superconductor Transition Abstract: We study the magnetic response of holographic superconductors exhibiting an\ninsulating \"normal\" phase. These materials can be realized as a CFT\ncompactified on a circle, which is dual to the AdS Soliton geometry. We study\nthe response under i) magnetic fields and ii) a Wilson line on the circle.\nMagnetic fields lead to formation of vortices and allows one to infer that the\nsuperconductor is of type II. The response to a Wilson line is in the form of\nAharonov-Bohm-like effects. These are suppressed in the holographic\nconductor/superconductor transition but, instead, they are unsuppressed for the\ninsulator case. Holography, thus, predicts that generically insulators display\nstronger Aharonov-Bohm effects than conductors. In the fluid-mechanical limit\nthe AdS Soliton is interpreted as a supersolid. Our results imply that\nsupersolids display unsuppressed Aharonov-Bohm (or \"Sagnac\") effects - stronger\nthan in superfluids. \n\n"}
{"id": "1202.2466", "contents": "Title: Self-healing systems and virtual structures Abstract: Modern networks are large, highly complex and dynamic. Add to that the\nmobility of the agents comprising many of these networks. It is difficult or\neven impossible for such systems to be managed centrally in an efficient\nmanner. It is imperative for such systems to attain a degree of\nself-management. Self-healing i.e. the capability of a system in a good state\nto recover to another good state in face of an attack, is desirable for such\nsystems. In this paper, we discuss the self-healing model for dynamic\nreconfigurable systems. In this model, an omniscient adversary inserts or\ndeletes nodes from a network and the algorithm responds by adding a limited\nnumber of edges in order to maintain invariants of the network. We look at some\nof the results in this model and argue for their applicability and further\nextensions of the results and the model. We also look at some of the techniques\nwe have used in our earlier work, in particular, we look at the idea of\nmaintaining virtual graphs mapped over the existing network and assert that\nthis may be a useful technique to use in many problem domains. \n\n"}
{"id": "1202.3084", "contents": "Title: On Dynamic Distributed Computing Abstract: This paper shows for the first time that distributed computing can be both\nreliable and efficient in an environment that is both highly dynamic and\nhostile. More specifically, we show how to maintain clusters of size $O(\\log\nN)$, each containing more than two thirds of honest nodes with high\nprobability, within a system whose size can vary \\textit{polynomially} with\nrespect to its initial size. Furthermore, the communication cost induced by\neach node arrival or departure is polylogarithmic with respect to $N$, the\nmaximal size of the system. Our clustering can be achieved despite the presence\nof a Byzantine adversary controlling a fraction $\\bad \\leq \\{1}{3}-\\epsilon$ of\nthe nodes, for some fixed constant $\\epsilon > 0$, independent of $N$. So far,\nsuch a clustering could only be performed for systems who size can vary\nconstantly and it was not clear whether that was at all possible for polynomial\nvariances. \n\n"}
{"id": "1202.5945", "contents": "Title: A Note on Interference in Random Point Sets Abstract: The (maximum receiver-centric) interference of a geometric graph (von\nRickenbach etal (2005)) is studied. It is shown that, with high probability,\nthe following results hold for a set, V, of n points independently and\nuniformly distributed in the unit d-cube, for constant dimension d: (1) there\nexists a connected graph with vertex set V that has interference O((log\nn)^{1/3}); (2) no connected graph with vertex set V has interference o((log\nn)^{1/4}); and (3) the minimum spanning tree of $V$ has interference\nTheta((\\log n)^{1/2}). \n\n"}
{"id": "1203.1715", "contents": "Title: D-iteration: Evaluation of a Dynamic Partition Strategy Abstract: The aim of this paper is to present a first evaluation of a dynamic partition\nstrategy associated to the recently proposed asynchronous distributed\ncomputation scheme based on the D-iteration approach. The D-iteration is a\nfluid diffusion point of view based iteration method to solve numerically\nlinear equations. Using a simple static partition strategy, it has been shown\nthat, when the computation is distributed over K virtual machines (PIDs), the\nmemory size to be handled by each virtual machine decreases linearly with K and\nthe computation speed increases almost linearly with K with a slope becoming\ncloser to one when the number N of linear equations to be solved increases.\nHere, we want to evaluate how further those results can be improved when a\nsimple dynamic partition strategy is deployed and to show that the dynamic\npartition strategy allows one to control and equalize the computation load\nbetween PIDs without any deep analysis of the matrix or of the underlying graph\nstructure. \n\n"}
{"id": "1203.1888", "contents": "Title: Matrix Representation of Iterative Approximate Byzantine Consensus in\n  Directed Graphs Abstract: This paper presents a proof of correctness of an iterative approximate\nByzantine consensus (IABC) algorithm for directed graphs. The iterative\nalgorithm allows fault- free nodes to reach approximate conensus despite the\npresence of up to f Byzantine faults. Necessary conditions on the underlying\nnetwork graph for the existence of a correct IABC algorithm were shown in our\nrecent work [15, 16]. [15] also analyzed a specific IABC algorithm and showed\nthat it performs correctly in any network graph that satisfies the necessary\ncondition, proving that the necessary condition is also sufficient. In this\npaper, we present an alternate proof of correctness of the IABC algorithm,\nusing a familiar technique based on transition matrices [9, 3, 17, 19].\n  The key contribution of this paper is to exploit the following observation:\nfor a given evolution of the state vector corresponding to the state of the\nfault-free nodes, many alternate state transition matrices may be chosen to\nmodel that evolution cor- rectly. For a given state evolution, we identify one\napproach to suitably \"design\" the transition matrices so that the standard\ntools for proving convergence can be applied to the Byzantine fault-tolerant\nalgorithm as well. In particular, the transition matrix for each iteration is\ndesigned such that each row of the matrix contains a large enough number of\nelements that are bounded away from 0. \n\n"}
{"id": "1203.4536", "contents": "Title: Observation of a Slater-type metal-to-insulator transition in\n  Sr$_2$IrO$_4$ from time-resolved photo-carrier dynamics Abstract: We perform a time-resolved optical study of Sr$_2$IrO$_4$ to understand the\ninfluence of magnetic ordering on the low energy electronic structure of a\nstrongly spin-orbit coupled $J_{eff}$=1/2 Mott insulator. By studying the\nrecovery dynamics of photo-carriers excited across the Mott gap, we find that\nupon cooling through the N\\'{e}el temperature $T_N$ the system evolves\ncontinuously from a metal-like phase with fast ($\\sim$50 fs) and excitation\ndensity independent relaxation dynamics to a gapped phase characterized by\nslower ($\\sim$500 fs) excitation density dependent bimolecular recombination\ndynamics. The development of the insulating gap is accompanied by a transfer of\nin-gap spectral weight to energies far in excess of the gap and occurs over an\nunusually broad temperature window, which suggests Sr$_2$IrO$_4$ to be a\nSlater- rather than Mott-Hubbard type insulator and naturally explains the\nabsence of anomalies at $T_N$ in transport and thermodynamic measurements. \n\n"}
{"id": "1203.4751", "contents": "Title: Optimism for Boosting Concurrency Abstract: Modern concurrent programming benefits from a large variety of\nsynchronization techniques. These include conventional pessimistic locking, as\nwell as optimistic techniques based on conditional synchronization primitives\nor transactional memory. Yet, it is unclear which of these approaches better\nleverage the concurrency inherent to multi-cores.\n  In this paper, we compare the level of concurrency one can obtain by\nconverting a sequential program into a concurrent one using optimistic or\npessimistic techniques. To establish fair comparison of such implementations,\nwe introduce a new correctness criterion for concurrent programs, defined\nindependently of the synchronization techniques they use.\n  We treat a program's concurrency as its ability to accept a concurrent\nschedule, a metric inspired by the theories of both databases and transactional\nmemory. We show that pessimistic locking can provide strictly higher\nconcurrency than transactions for some applications whereas transactions can\nprovide strictly higher concurrency than pessimistic locks for others. Finally,\nwe show that combining the benefits of the two synchronization techniques can\nprovide strictly more concurrency than any of them individually. We propose a\nlist-based set algorithm that is optimal in the sense that it accepts all\ncorrect concurrent schedules. As we show via experimentation, the optimality in\nterms of concurrency is reflected by scalability gains. \n\n"}
{"id": "1203.6478", "contents": "Title: An exact quantification of backreaction in relativistic cosmology Abstract: An important open question in cosmology is the degree to which the\nFriedmann-Lemaitre-Robertson-Walker (FLRW) solutions of Einstein's equations\nare able to model the large-scale behaviour of the locally inhomogeneous\nobservable universe. We investigate this problem by considering a range of\nexact n-body solutions of Einstein's constraint equations. These solutions\ncontain discrete masses, and so allow arbitrarily large density contrasts to be\nmodelled. We restrict our study to regularly arranged distributions of masses\nin topological 3-spheres. This has the benefit of allowing straightforward\ncomparisons to be made with FLRW solutions, as both spacetimes admit a discrete\ngroup of symmetries. It also provides a time-symmetric hypersurface at the\nmoment of maximum expansion that allows the constraint equations to be solved\nexactly. We find that when all the mass in the universe is condensed into a\nsmall number of objects (<10) then the amount of backreaction in dust models\ncan be large, with O(1) deviations from the predictions of the corresponding\nFLRW solutions. When the number of masses is large (>100), however, then our\nmeasures of backreaction become small (<1%). This result does not rely on any\naveraging procedures, which are notoriously hard to define uniquely in general\nrelativity, and so provides (to the best of our knowledge) the first exact and\nunambiguous demonstration of backreaction in general relativistic cosmological\nmodelling. Discrete models such as these can therefore be used as laboratories\nto test ideas about backreaction that could be applied in more complicated and\nrealistic settings. \n\n"}
{"id": "1204.1042", "contents": "Title: The Fractional Quantum Hall Effect of Tachyons in a Topological\n  Insulator Junction Abstract: We have studied the tachyonic excitations in the junction of two topological\ninsulators in the presence of an external magnetic field. The Landau levels,\nevaluated from an effective two-dimensional model for tachyons, and from the\njunction states of two topological insulators, show some unique properties not\nseen in conventional electrons systems or in graphene. The $\\nu=1/3$ fractional\nquantum Hall effect has also a strong presence in the tachyon system. \n\n"}
{"id": "1204.1106", "contents": "Title: Message Passing for Dynamic Network Energy Management Abstract: We consider a network of devices, such as generators, fixed loads, deferrable\nloads, and storage devices, each with its own dynamic constraints and\nobjective, connected by lossy capacitated lines. The problem is to minimize the\ntotal network objective subject to the device and line constraints, over a\ngiven time horizon. This is a large optimization problem, with variables for\nconsumption or generation in each time period for each device. In this paper we\ndevelop a decentralized method for solving this problem. The method is\niterative: At each step, each device exchanges simple messages with its\nneighbors in the network and then solves its own optimization problem,\nminimizing its own objective function, augmented by a term determined by the\nmessages it has received. We show that this message passing method converges to\na solution when the device objective and constraints are convex. The method is\ncompletely decentralized, and needs no global coordination other than\nsynchronizing iterations; the problems to be solved by each device can\ntypically be solved extremely efficiently and in parallel. The method is fast\nenough that even a serial implementation can solve substantial problems in\nreasonable time frames. We report results for several numerical experiments,\ndemonstrating the method's speed and scaling, including the solution of a\nproblem instance with over 30 million variables in 52 minutes for a serial\nimplementation; with decentralized computing, the solve time would be less than\none second. \n\n"}
{"id": "1204.1939", "contents": "Title: Random walks which prefer unvisited edges. Exploring high girth even\n  degree expanders in linear time Abstract: We consider a modified random walk which uses unvisited edges whenever\npossible, and makes a simple random walk otherwise. We call such a walk an\nedge-process. We assume there is a rule A, which tells the walk which unvisited\nedge to use whenever there is a choice. In the simplest case, A is a uniform\nrandom choice over unvisited edges incident with the current walk position.\nHowever we do not exclude arbitrary choices of rule A. For example, the rule\ncould be determined on-line by an adversary, or could vary from vertex to\nvertex.\n  For even degree expander graphs, of bounded maximum degree, we have the\nfollowing result. Let G be an n vertex even degree expander graph, for which\nevery vertex is in at least one vertex induced cycle of length L. Any\nedge-process on G has cover time (n+ (n log n)/L). This result is independent\nof the rule A used to select the order of the unvisited edges, which can be\nchosen on-line by an adversary.\n  As an example, With high probability, random r-regular graphs, (r at least 4,\neven), are expanders for which L = Omega(log n). Thus, for almost all such\ngraphs, the vertex cover time of the edge-process is Theta(n). This improves\nthe vertex cover time of such graphs by a factor of log n, compared to the\nOmega(n log n) cover time of any weighted random walk. \n\n"}
{"id": "1204.2280", "contents": "Title: Bonsai: A GPU Tree-Code Abstract: We present a gravitational hierarchical N-body code that is designed to run\nefficiently on Graphics Processing Units (GPUs). All parts of the algorithm are\nexecuted on the GPU which eliminates the need for data transfer between the\nCentral Processing Unit (CPU) and the GPU. Our tests indicate that the\ngravitational tree-code outperforms tuned CPU code for all parts of the\nalgorithm and show an overall performance improvement of more than a factor 20,\nresulting in a processing rate of more than 2.8 million particles per second. \n\n"}
{"id": "1204.2766", "contents": "Title: The remarkable solar twin HIP 56948: a prime target in the quest for\n  other Earths Abstract: We study HIP 56948, the best solar twin known to date, to determine with an\nunparalleled precision how similar is to the Sun in its physical properties,\nchemical composition and planet architecture. We explore whether the abundances\nanomalies may be due to pollution from stellar ejecta or to terrestrial planet\nformation.\n  We perform a differential abundance analysis (both in LTE and NLTE) using\nhigh resolution (R = 100,000) high S/N (600) Keck HIRES spectra of the Sun and\nHIP 56948. We use precise radial velocity data from the McDonald and Keck\nobservatories to search for planets around this star.\n  We achieve a precision of sigma = 0.003 dex for several elements. Including\nerrors in stellar parameters the total uncertainty is as low as sigma = 0.005\ndex (1 %), which is unprecedented in elemental abundance studies.\n  The similarities between HIP 56948 and the Sun are astonishing. HIP 56948 is\nonly 17+/-7 K hotter than the Sun, and log g, [Fe/H] and microturbulence are\nonly +0.02+/-0.02 dex, +0.02+/-0.01 dex and +0.01+/-0.01 km/s higher than\nsolar, respectively. HIP 56948 has a mass of 1.02+/-0.02M_Sun and is 1 Gyr\nyounger than the Sun. Both stars show a chemical abundance pattern that differs\nfrom most solar twins. The trend with T_cond in differential abundances (twins\n- HIP56948) can be reproduced very well by adding 3 M_Earth of a mix of Earth\nand meteoritic material, to the convection zone of HIP 56948. From our radial\nvelocity monitoring we find no indications of giant planets interior to or\nwithin the habitable zone of HIP 56948.\n  We conclude that HIP 56948 is an excellent candidate to host a planetary\nsystem like our own, including the possible presence of inner terrestrial\nplanets. Its striking similarity to the Sun and its mature age makes HIP 56948\na prime target in the quest for other Earths and SETI endeavors. \n\n"}
{"id": "1204.3357", "contents": "Title: On the soft X-ray emission of M82 Abstract: We present a spatial analysis of the soft X-ray and H{\\alpha} emissions from\nthe outflow of the starburst galaxy M82. We find that the two emissions are\ntightly correlated on various scales. The O VII triplet of M82, as resolved by\nX-ray grating observations of XMM-Newton, is dominated by the forbidden line,\ninconsistent with the thermal prediction. The O VII triplet also shows some\nspatial variations. We discuss three possible explanations for the observed O\nVII triplet, including the charge exchange at interfaces between the hot\noutflow and neutral cool gas, a collisional non-equilibrium-ionization\nrecombining plasma, and resonance scattering. \n\n"}
{"id": "1204.3439", "contents": "Title: Sequences with long range exclusions Abstract: Given an alphabet $S$, we consider the size of the subsets of the full\nsequence space $S^{\\rm {\\bf Z}}$ determined by the additional restriction that\n$x_i\\not=x_{i+f(n)},\\ i\\in {\\rm {\\bf Z}},\\ n\\in {\\rm {\\bf N}}.$ Here $f$ is a\npositive, strictly increasing function. We review an other, graph theoretic,\nformulation and then the known results covering various combinations of $f$ and\nthe alphabet size. In the second part of the paper we turn to the fine\nstructure of the allowed sequences in the particular case where $f$ is a\nsuitable polynomial. The generation of sequences leads naturally to consider\nthe problem of their maximal length, which turns out highly random\nasymptotically in the alphabet size. \n\n"}
{"id": "1204.4130", "contents": "Title: Observation of Majorana Fermions in a Nb-InSb Nanowire-Nb Hybrid Quantum\n  Device Abstract: We report on the observation of excitation of Majorana fermions in a Nb-InSb\nnanowire quantum dot-Nb hybrid system. The InSb nanowire quantum dot is formed\nbetween the two Nb contacts by weak Schottky barriers and is thus in the regime\nof strong couplings to the contacts. Due to the proximity effect, the InSb\nnanowire segments covered by superconductor Nb contacts turn to superconductors\nwith a superconducting energy gap $\\Delta^*$. Under an applied magnetic field\nlarger than a critical value for which the Zeeman energy in the InSb nanowire\nis $E_z\\sim \\Delta^*$, the entire InSb nanowire is found to be in a nontrivial\ntopological superconductor phase, supporting a pair of Majorana fermions, and\nCooper pairs can transport between the superconductor Nb contacts via the\nMajorana fermion states. This transport process will be suppressed when the\napplied magnetic field becomes larger than a second critical value at which the\ntransition to a trivial topological superconductor phase occurs in the system.\nThis physical scenario has been observed in our experiment. We have found that\nthe measured zero-bias conductance for our hybrid device shows a conductance\nplateau in a range of the applied magnetic field in quasi-particle Coulomb\nblockade regions. \n\n"}
{"id": "1204.4143", "contents": "Title: Qualitative properties of certain piecewise deterministic Markov\n  processes Abstract: We study a class of Piecewise Deterministic Markov Processes with state space\nRd x E where E is a finite set. The continuous component evolves according to a\nsmooth vector field that is switched at the jump times of the discrete\ncoordinate. The jump rates may depend on the whole position of the process.\nWorking under the general assumption that the process stays in a compact set,\nwe detail a possible construction of the process and characterize its support,\nin terms of the solutions set of a differential inclusion. We establish results\non the long time behaviour of the process, in relation to a certain set of\naccessible points, which is shown to be strongly linked to the support of\ninvariant measures. Under H\\\"ormander-type bracket conditions, we prove that\nthere exists a unique invariant measure and that the processes converges to\nequilibrium in total variation. Finally we give examples where the bracket\ncondition does not hold, and where there may be one or many invariant measures,\ndepending on the jump rates between the flows. \n\n"}
{"id": "1204.4219", "contents": "Title: An Absence of Neutrinos Associated with Cosmic Ray Acceleration in\n  Gamma-Ray Bursts Abstract: Gamma-Ray Bursts (GRBs) have been proposed as a leading candidate for\nacceleration of ultra high-energy cosmic rays, which would be accompanied by\nemission of TeV neutrinos produced in proton-photon interactions during\nacceleration in the GRB fireball. Two analyses using data from two years of the\nIceCube detector produced no evidence for this neutrino emission, placing\nstrong constraints on models of neutrino and cosmic-ray production in these\nsources. \n\n"}
{"id": "1205.0282", "contents": "Title: A Distributed GPU-based Framework for real-time 3D Volume Rendering of\n  Large Astronomical Data Cubes Abstract: We present a framework to interactively volume-render three-dimensional data\ncubes using distributed ray-casting and volume bricking over a cluster of\nworkstations powered by one or more graphics processing units (GPUs) and a\nmulti-core CPU. The main design target for this framework is to provide an\nin-core visualization solution able to provide three-dimensional interactive\nviews of terabyte-sized data cubes. We tested the presented framework using a\ncomputing cluster comprising 64 nodes with a total of 128 GPUs. The framework\nproved to be scalable to render a 204 GB data cube with an average of 30 frames\nper second. Our performance analyses also compare between using NVIDIA Tesla\n1060 and 2050 GPU architectures and the effect of increasing the visualization\noutput resolution on the rendering performance. Although our initial focus, and\nthe examples presented in this work, is volume rendering of spectral data cubes\nfrom radio astronomy, we contend that our approach has applicability to other\ndisciplines where close to real-time volume rendering of terabyte-order 3D data\nsets is a requirement. \n\n"}
{"id": "1205.2282", "contents": "Title: A Discussion on Parallelization Schemes for Stochastic Vector\n  Quantization Algorithms Abstract: This paper studies parallelization schemes for stochastic Vector Quantization\nalgorithms in order to obtain time speed-ups using distributed resources. We\nshow that the most intuitive parallelization scheme does not lead to better\nperformances than the sequential algorithm. Another distributed scheme is\ntherefore introduced which obtains the expected speed-ups. Then, it is improved\nto fit implementation on distributed architectures where communications are\nslow and inter-machines synchronization too costly. The schemes are tested with\nsimulated distributed architectures and, for the last one, with Microsoft\nWindows Azure platform obtaining speed-ups up to 32 Virtual Machines. \n\n"}
{"id": "1206.0115", "contents": "Title: Pipelining the Fast Multipole Method over a Runtime System Abstract: Fast Multipole Methods (FMM) are a fundamental operation for the simulation\nof many physical problems. The high performance design of such methods usually\nrequires to carefully tune the algorithm for both the targeted physics and the\nhardware. In this paper, we propose a new approach that achieves high\nperformance across architectures. Our method consists of expressing the FMM\nalgorithm as a task flow and employing a state-of-the-art runtime system,\nStarPU, in order to process the tasks on the different processing units. We\ncarefully design the task flow, the mathematical operators, their Central\nProcessing Unit (CPU) and Graphics Processing Unit (GPU) implementations, as\nwell as scheduling schemes. We compute potentials and forces of 200 million\nparticles in 48.7 seconds on a homogeneous 160 cores SGI Altix UV 100 and of 38\nmillion particles in 13.34 seconds on a heterogeneous 12 cores Intel Nehalem\nprocessor enhanced with 3 Nvidia M2090 Fermi GPUs. \n\n"}
{"id": "1206.0147", "contents": "Title: Nonlinear nanomechanical resonators for quantum optoelectromechanics Abstract: We present a scheme for tuning and controlling nano mechanical resonators by\nsubjecting them to electrostatic gradient fields, provided by nearby tip\nelectrodes. We show that this approach enables access to a novel regime of\noptomechanics, where the intrinsic nonlinearity of the nanoresonator can be\nexplored. In this regime, one or several laser driven cavity modes coupled to\nthe nanoresonator and suitably adjusted gradient fields allow to control the\nmotional state of the nanoresonator at the single phonon level. Some\napplications of this platform have been presented previously [New J. Phys. 14,\n023042 (2012), Phys. Rev. Lett. 110, 120503 (2013)]. Here, we provide a\ndetailed description of the corresponding setup and its optomechanical coupling\nmechanisms, together with an in-depth analysis of possible sources of damping\nor decoherence and a discussion of the readout of the nanoresonator state. \n\n"}
{"id": "1206.0347", "contents": "Title: Delayed Onset of High-Energy Emissions in Leptonic and Hadronic Models\n  of Gamma-Ray Bursts Abstract: The temporal--spectral evolution of the prompt emission of gamma-ray bursts\n(GRBs) is simulated numerically for both leptonic and hadronic models. For weak\nenough magnetic fields, leptonic models can reproduce the few seconds delay of\nthe onset of GeV photon emission observed by Fermi-LAT, due to the slow growth\nof the target photon field for inverse Compton scattering. However, even for\nstronger magnetic fields, the GeV delay can be explained with hadronic models,\ndue to the long acceleration timescale of protons and the continuous photopion\nproduction after the end of the particle injection. While the FWHMs of the MeV\nand GeV lightcurves are almost the same in one-zone leptonic models, the FWHM\nof the 1--30 GeV lightcurves in hadronic models are significantly wider than\nthose of the 0.1--1 MeV lightcurves. The amount of the GeV delay depends on the\nimportance of the Klein--Nishina effect in both the leptonic and hadronic\nmodels. In our examples of hadronic models the energies of the escaped neutrons\nare comparable to the gamma-ray energy, although their contribution to the\nultra high-energy cosmic rays is still subdominant. The resulting neutrino\nspectra are hard enough to avoid the flux limit constraint from IceCube. The\ndelay of the neutrino emission onset is up to several times longer than the\ncorresponding delay of the GeV photon emission onset. The quantitative\ndifferences in the lightcurves for various models may be further tested with\nfuture atmospheric Cherenkov telescopes whose effective area is larger than\nthat of Fermi-LAT, such as CTA. \n\n"}
{"id": "1206.2224", "contents": "Title: Topological Kondo effect with Majorana fermions Abstract: The Kondo effect is a striking consequence of the coupling of itinerant\nelectrons to a quantum spin with degenerate energy levels. While degeneracies\nare commonly thought to arise from symmetries or fine-tuning of parameters, the\nrecent emergence of Majorana fermions has brought to the fore an entirely\ndifferent possibility: a \"topological degeneracy\" which arises from the\nnonlocal character of Majorana fermions. Here we show that nonlocal quantum\nspins formed from these degrees of freedom give rise to a novel \"topological\nKondo effect\". This leads to a robust non-Fermi liquid behavior, known to be\ndifficult to achieve in the conventional Kondo context. Focusing on mesoscopic\nsuperconductor devices, we predict several unique transport signatures of this\nKondo effect, which would demonstrate the non-local quantum dynamics of\nMajorana fermions, and validate their potential for topological quantum\ncomputation. \n\n"}
{"id": "1206.4903", "contents": "Title: Empirical processes of iterated maps that contract on average Abstract: We consider a Markov chain obtained by random iterations of Lipschitz maps\n$T_i$ chosen with a probability $p_i(x)$ depending on the current position $x$.\nWe assume this system has a property of \"contraction on average\", that is\n$\\sum_i d(T_ix,T_iy)p_i(x) < \\rho d(x,y)$ for some $\\rho<1$. In the present\nnote, we study the weak convergence of the empirical process associated to this\nMarkov chain. \n\n"}
{"id": "1206.5211", "contents": "Title: Non-Equilibrium Transport Through a Gate-Controlled Barrier on the\n  Quantum Spin Hall Edge Abstract: The Quantum Spin Hall insulator is characterized by the presence of gapless\nhelical edge states where the spin of the charge carriers is locked to their\ndirection of motion. In order to probe the properties of the edge modes, we\npropose a design of a tunable quantum impurity realized by a local gate under\nan external magnetic field. Using the integrability of the impurity model, the\nconductance is computed for arbitrary interactions, temperatures and voltages,\nincluding the effect of Fermi liquid leads. The result can be used to infer the\nstrength of interactions from transport experiments \n\n"}
{"id": "1207.0581", "contents": "Title: Persistence of phase boundaries between a topological and trivial Z2\n  insulator Abstract: When time reversal symmetry is present there is a sharp distinction between\ntopological and trivial band insulators which ensures that, as parameters are\nvaried, these phases are separated by a phase transition at which the bulk gap\ncloses. Surprisingly we find that even in the absence of time reversal\nsymmetry, gapless regions originating from the phase boundaries persist.\nMoreover the critical line generically opens up to enclose Chern insulating\nphases that are thin but of finite extent in the phase diagram. We explain the\ntopological origin of this effect in terms of quantized charge pumping, showing\nin particular that it is robust to the effect of disorder and interactions. \n\n"}
{"id": "1207.4772", "contents": "Title: Circumstellar matter studied by spectrally-resolved interferometry Abstract: This paper describes some generalities about spectro-interferometry and the\nrole it has played in the last decade for the better understanding of\ncircumstellar matter. I provide a small history of the technique and its\norigins, and recall the basics of differential phase and its central role for\nthe recent discoveries. I finally provide a small set of simple interpretations\nof differential phases for specific astrophysical cases, and intend to provide\na \"cookbook\" for the other cases. \n\n"}
{"id": "1207.5606", "contents": "Title: Metal nanoparticles with sharp corners: Universal properties of plasmon\n  resonances Abstract: We predict the simultaneous occurrence of two fundamental phenomena for metal\nnanoparticles possessing sharp corners: First, the main plasmonic dipolar mode\nexperiences strong red shift with decreasing corner curvature radius; its\nresonant frequency is controlled by the apex angle of the corner and the\nnormalized (to the particle size) corner curvature. Second, the split-off\nplasmonic mode experiences strong localization at the corners. Altogether, this\npaves the way for tailoring of metal nano-structures providing\nwavelength-selective excitation of localized plasmons and a strong near-field\nenhancement of linear and nonlinear optical phenomena. \n\n"}
{"id": "1207.6757", "contents": "Title: Femtosecond nonlinear ultrasonics in gold probed with ultrashort surface\n  plasmons Abstract: Fundamental interactions induced by lattice vibrations on ultrafast time\nscales become increasingly important for modern nanoscience and technology.\nExperimental access to the physical properties of acoustic phonons in the THz\nfrequency range and over the entire Brillouin zone is crucial for understanding\nelectric and thermal transport in solids and their compounds. Here, we report\non the generation and nonlinear propagation of giant (1 percent) acoustic\nstrain pulses in hybrid gold/cobalt bilayer structures probed with ultrafast\nsurface plasmon interferometry. This new technique allows for unambiguous\ncharacterization of arbitrary ultrafast acoustic transients. The giant acoustic\npulses experience substantial nonlinear reshaping already after a propagation\ndistance of 100 nm in a crystalline gold layer. Excellent agreement with the\nKorteveg-de Vries model points to future quantitative nonlinear femtosecond\nTHz-ultrasonics at the nano-scale in metals at room temperature. \n\n"}
{"id": "1207.6793", "contents": "Title: Infinite Determinantal Measures Abstract: Infinite determinantal measures introduced in this note are inductive limits\nof determinantal measures on an exhausting family of subsets of the phase\nspace. Alternatively, an infinite determinantal measure can be described as a\nproduct of a determinantal process and a convergent, but not integrable,\nmultiplicative functional.\n  Theorem 2, the main result announced in this note, gives an explicit\ndescription for the ergodic decomposition of infinite Pickrell measures on the\nspaces of infinite complex matrices in terms of infinite determinantal measures\nobtained by finite-rank perturbations of Bessel point processes. \n\n"}
{"id": "1208.3994", "contents": "Title: Coordination in Network Security Games: a Monotone Comparative Statics\n  Approach Abstract: Malicious softwares or malwares for short have become a major security\nthreat. While originating in criminal behavior, their impact are also\ninfluenced by the decisions of legitimate end users. Getting agents in the\nInternet, and in networks in general, to invest in and deploy security features\nand protocols is a challenge, in particular because of economic reasons arising\nfrom the presence of network externalities.\n  In this paper, we focus on the question of incentive alignment for agents of\na large network towards a better security. We start with an economic model for\na single agent, that determines the optimal amount to invest in protection. The\nmodel takes into account the vulnerability of the agent to a security breach\nand the potential loss if a security breach occurs. We derive conditions on the\nquality of the protection to ensure that the optimal amount spent on security\nis an increasing function of the agent's vulnerability and potential loss. We\nalso show that for a large class of risks, only a small fraction of the\nexpected loss should be invested.\n  Building on these results, we study a network of interconnected agents\nsubject to epidemic risks. We derive conditions to ensure that the incentives\nof all agents are aligned towards a better security. When agents are strategic,\nwe show that security investments are always socially inefficient due to the\nnetwork externalities. Moreover alignment of incentives typically implies a\ncoordination problem, leading to an equilibrium with a very high price of\nanarchy. \n\n"}
{"id": "1208.4895", "contents": "Title: Broadcast Gossip Algorithms for Consensus on Strongly Connected Digraphs Abstract: We study a general framework for broadcast gossip algorithms which use\ncompanion variables to solve the average consensus problem. Each node maintains\nan initial state and a companion variable. Iterative updates are performed\nasynchronously whereby one random node broadcasts its current state and\ncompanion variable and all other nodes receiving the broadcast update their\nstate and companion variable. We provide conditions under which this scheme is\nguaranteed to converge to a consensus solution, where all nodes have the same\nlimiting values, on any strongly connected directed graph. Under stronger\nconditions, which are reasonable when the underlying communication graph is\nundirected, we guarantee that the consensus value is equal to the average, both\nin expectation and in the mean-squared sense. Our analysis uses tools from\nnon-negative matrix theory and perturbation theory. The perturbation results\nrely on a parameter being sufficiently small. We characterize the allowable\nupper bound as well as the optimal setting for the perturbation parameter as a\nfunction of the network topology, and this allows us to characterize the\nworst-case rate of convergence. Simulations illustrate that, in comparison to\nexisting broadcast gossip algorithms, the approaches proposed in this paper\nhave the advantage that they simultaneously can be guaranteed to converge to\nthe average consensus and they converge in a small number of broadcasts. \n\n"}
{"id": "1208.6125", "contents": "Title: Bounded-Contention Coding for Wireless Networks in the High SNR Regime Abstract: Efficient communication in wireless networks is typically challenged by the\npossibility of interference among several transmitting nodes. Much important\nresearch has been invested in decreasing the number of collisions in order to\nobtain faster algorithms for communication in such networks.\n  This paper proposes a novel approach for wireless communication, which\nembraces collisions rather than avoiding them, over an additive channel. It\nintroduces a coding technique called Bounded-Contention Coding (BCC) that\nallows collisions to be successfully decoded by the receiving nodes into the\noriginal transmissions and whose complexity depends on a bound on the\ncontention among the transmitters.\n  BCC enables deterministic local broadcast in a network with n nodes and at\nmost a transmitters with information of l bits each within O(a log n + al) bits\nof communication with full-duplex radios, and O((a log n + al)(log n)) bits,\nwith high probability, with half-duplex radios. When combined with random\nlinear network coding, BCC gives global broadcast within O((D + a + log n)(a\nlog n + l)) bits, with high probability. This also holds in dynamic networks\nthat can change arbitrarily over time by a worst-case adversary. When no bound\non the contention is given, it is shown how to probabilistically estimate it\nand obtain global broadcast that is adaptive to the true contention in the\nnetwork. \n\n"}
{"id": "1209.6538", "contents": "Title: Mean-field description of multicomponent exciton-polariton superfluids Abstract: This is a review of spin-dependent (polarization) properties of\nmulticomponent exciton-polariton condensates in conditions when\nquasi-equilibrium mean-field Gross-Pitaevskii description can be applied.\nMainly two-component (spin states $\\pm1$) polariton condensates are addressed,\nbut some properties of four-component exciton condensates, having both the\nbright (spin $\\pm1$) and the dark (spin $\\pm2$) components, are discussed.\nChange of polarization state of the condensate and phase transitions in applied\nZeeman field are described. The properties of fractional vortices are given, in\nparticular, I present recent results on the warping of the field around\nhalf-vortices in the presence of longitudinal-transverse splitting of bare\npolariton bands, and discuss the geometrical features of warped half-vortices\n(in the framework of the lemon, monstar, and star classification). \n\n"}
{"id": "1210.3171", "contents": "Title: Data Interpolation: An Efficient Sampling Alternative for Big Data\n  Aggregation Abstract: Given a large set of measurement sensor data, in order to identify a simple\nfunction that captures the essence of the data gathered by the sensors, we\nsuggest representing the data by (spatial) functions, in particular by\npolynomials. Given a (sampled) set of values, we interpolate the datapoints to\ndefine a polynomial that would represent the data. The interpolation is\nchallenging, since in practice the data can be noisy and even Byzantine, where\nthe Byzantine data represents an adversarial value that is not limited to being\nclose to the correct measured data. We present two solutions, one that extends\nthe Welch-Berlekamp technique in the case of multidimensional data, and copes\nwith discrete noise and Byzantine data, and the other based on Arora and Khot\ntechniques, extending them in the case of multidimensional noisy and Byzantine\ndata. \n\n"}
{"id": "1210.3277", "contents": "Title: Shortest, Fastest, and Foremost Broadcast in Dynamic Networks Abstract: Highly dynamic networks rarely offer end-to-end connectivity at a given time.\nYet, connectivity in these networks can be established over time and space,\nbased on temporal analogues of multi-hop paths (also called {\\em journeys}).\nAttempting to optimize the selection of the journeys in these networks\nnaturally leads to the study of three cases: shortest (minimum hop), fastest\n(minimum duration), and foremost (earliest arrival) journeys. Efficient\ncentralized algorithms exists to compute all cases, when the full knowledge of\nthe network evolution is given.\n  In this paper, we study the {\\em distributed} counterparts of these problems,\ni.e. shortest, fastest, and foremost broadcast with termination detection\n(TDB), with minimal knowledge on the topology.\n  We show that the feasibility of each of these problems requires distinct\nfeatures on the evolution, through identifying three classes of dynamic graphs\nwherein the problems become gradually feasible: graphs in which the\nre-appearance of edges is {\\em recurrent} (class R), {\\em bounded-recurrent}\n(B), or {\\em periodic} (P), together with specific knowledge that are\nrespectively $n$ (the number of nodes), $\\Delta$ (a bound on the recurrence\ntime), and $p$ (the period). In these classes it is not required that all pairs\nof nodes get in contact -- only that the overall {\\em footprint} of the graph\nis connected over time.\n  Our results, together with the strict inclusion between $P$, $B$, and $R$,\nimplies a feasibility order among the three variants of the problem, i.e.\nTDB[foremost] requires weaker assumptions on the topology dynamics than\nTDB[shortest], which itself requires less than TDB[fastest]. Reversely, these\ndifferences in feasibility imply that the computational powers of $R_n$,\n$B_\\Delta$, and $P_p$ also form a strict hierarchy. \n\n"}
{"id": "1210.4303", "contents": "Title: Microwave Quantum Optics with an Artificial Atom Abstract: We address the recent advances on microwave quantum optics with artificial\natoms. This field relies on the fact that the coupling between a\nsuperconducting artificial atom and propagating microwave photons in a 1D open\ntransmission line can be made strong enough to observe quantum coherent\neffects, without using any cavity to confine the microwave photons. We\ninvestigate the scattering properties in such a system with resonant coherent\nmicrowaves. We observe the strong nonlinearity of the artificial atom and under\nstrong driving we observe the Mollow triplet. By applying two resonant tones,\nwe also observe the Autler-Townes splitting. By exploiting these effects, we\ndemonstrate two quantum devices at the single-photon level in the microwave\nregime: the single-photon router and the photon-number filter. These devices\nprovide essential steps towards the realization of an on-chip quantum network. \n\n"}
{"id": "1210.4446", "contents": "Title: Wireless Network Stability in the SINR Model Abstract: We study the stability of wireless networks under stochastic arrival\nprocesses of packets, and design efficient, distributed algorithms that achieve\nstability in the SINR (Signal to Interference and Noise Ratio) interference\nmodel.\n  Specifically, we make the following contributions. We give a distributed\nalgorithm that achieves $\\Omega(\\frac{1}{\\log^2 n})$-efficiency on all networks\n(where $n$ is the number of links in the network), for all length monotone,\nsub-linear power assignments. For the power control version of the problem, we\ngive a distributed algorithm with $\\Omega(\\frac{1}{\\log n(\\log n + \\log \\log\n\\Delta)})$-efficiency (where $\\Delta$ is the length diversity of the link set). \n\n"}
{"id": "1210.5802", "contents": "Title: What if CLIQUE were fast? Maximum Cliques in Information Networks and\n  Strong Components in Temporal Networks Abstract: Exact maximum clique finders have progressed to the point where we can\ninvestigate cliques in million-node social and information networks, as well as\nfind strongly connected components in temporal networks. We use one such finder\nto study a large collection of modern networks emanating from biological,\nsocial, and technological domains. We show inter-relationships between maximum\ncliques and several other common network properties, including network density,\nmaximum core, and number of triangles. In temporal networks, we find that the\nlargest temporal strong components have around 20-30% of the vertices of the\nentire network. These components represent groups of highly communicative\nindividuals. In addition, we discuss and improve the performance and utility of\nthe maximum clique finder itself. \n\n"}
{"id": "1210.8433", "contents": "Title: Green Cellular Wireless Networks: Where to Begin? Abstract: Conventional cellular wireless networks were designed with the purpose of\nproviding high throughput for the user and high capacity for the service\nprovider, without any provisions of energy efficiency. As a result, these\nnetworks have an enormous Carbon footprint. In this note, we describe the\nsources of the inefficiencies in such networks. First we quantify how much\nCarbon footprint such networks generate. We also discuss how much more mobile\ntraffic is expected to increase so that this Carbon footprint will even\nincrease tremendously more. We then discuss specific sources of inefficiency\nand potential sources of improvement at the physical layer as well as higher\nlayers of the communication protocol hierarchy. In particular, considering that\nmost of the energy inefficiency in wireless cellular networks is at the base\nstations, we discuss multi-tier networks and point to the potential of\nexploiting mobility patterns in order to use base station energy judiciously. \n\n"}
{"id": "1211.0184", "contents": "Title: Testing the interaction model with cosmological data and gamma-ray\n  bursts Abstract: We use the new gamma-ray bursts (GRBs) data, combined with the baryon\nacoustic oscillation(BAO) observation from the spectroscopic Sloan Digital Sky\nSurvey (SDSS) data release, the newly obtained $A$ parameter at $z=0.6$ from\nthe WiggleZ Dark Energy Survey, the cosmic microwave background (CMB)\nobservations from the 7-Year Wilkinson Microwave Anisotropy Probe (WMAP7)\nresults, and the type Ia supernovae (SNeIa) from Union2 set, to constrain a\nphenomenological model describing possible interactions between dark energy and\ndark matter, which was proposed to alleviate the coincidence problem of the\nstandard $\\Lambda$CDM model. By using the Markov Chain Monte Carlo (MCMC)\nmethod, we obtain the marginalized $1\\sigma$ constraints\n$\\Omega_{m}=0.2886\\pm{0.0135}$, $r_m=-0.0047\\pm{0.0046}$, and\n$w_X=-1.0658\\pm{0.0564}$. We also consider other combinations of these data for\ncomparison. These results show that: (1) the energy of dark matter is slightly\ntransferring to that of dark energy; (2) even though the GRBs+BAO+CMB data\npresent less stringent constraints than SNe+BAO+CMB data do, the GRBs can help\neliminate the degeneracies among parameters. \n\n"}
{"id": "1211.0458", "contents": "Title: High-Contrast Electro-Optic Modulation of a Photonic Crystal Nanocavity\n  by Electrical Gating of Graphene Abstract: We demonstrate a high-contrast electro-optic modulation of a photonic crystal\nnanocavity integrated with an electrically gated monolayer graphene. A high\nquality (Q) factor air-slot nanocavity design is employed for high overlap\nbetween the optical field and graphene sheet. Tuning of graphene's Fermi level\nup to 0.8 eV enables efficient control of its complex dielectric constant,\nwhich allows modulation of the cavity reflection in excess of 10 dB for a swing\nvoltage of only 1.5 V. We also observe a controllable resonance wavelength\nshift close to 2 nm around a wavelength of 1570 nm and a Q factor modulation in\nexcess of three. These observations allow cavity-enhanced measurements of the\ngraphene complex dielectric constant under different chemical potentials, in\nagreement with a theoretical model of the graphene dielectric constant under\ngating. This graphene-based nanocavity modulation demonstrates the feasibility\nof high-contrast, low-power frequency-selective electro-optic nanocavity\nmodulators in graphene-integrated silicon photonic chips. \n\n"}
{"id": "1211.1247", "contents": "Title: A generalized Polya's urn with graph based interactions Abstract: Given a finite connected graph G, place a bin at each vertex. Two bins are\ncalled a pair if they share an edge of G. At discrete times, a ball is added to\neach pair of bins. In a pair of bins, one of the bins gets the ball with\nprobability proportional to its current number of balls raised by some fixed\npower a>0. We characterize the limiting behavior of the proportion of balls in\nthe bins.\n  The proof uses a dynamical approach to relate the proportion of balls to a\nvector field. Our main result is that the limit set of the proportion of balls\nis contained in the equilibria set of the vector field. We also prove that if\na<1 then there is a single point v=v(G,a) with nonzero entries such that the\nproportion converges to v almost surely.\n  A special case is when G is regular and a is at most 1. We show e.g. that if\nG is non-bipartite then the proportion of balls in the bins converges to the\nuniform measure almost surely. \n\n"}
{"id": "1211.1608", "contents": "Title: Cavity-enhanced optical detection of carbon nanotube Brownian motion Abstract: Optical cavities with small mode volume are well-suited to detect the\nvibration of sub-wavelength sized objects. Here we employ a fiber-based,\nhigh-finesse optical microcavity to detect the Brownian motion of a freely\nsuspended carbon nanotube at room temperature under vacuum. The optical\ndetection resolves deflections of the oscillating tube down to 50pm/Hz^1/2. A\nfull vibrational spectrum of the carbon nanotube is obtained and confirmed by\ncharacterization of the same device in a scanning electron microscope. Our work\nsuccessfully extends the principles of high-sensitivity optomechanical\ndetection to molecular scale nanomechanical systems. \n\n"}
{"id": "1211.2963", "contents": "Title: Flexible composition and execution of high performance, high fidelity\n  multiscale biomedical simulations Abstract: Multiscale simulations are essential in the biomedical domain to accurately\nmodel human physiology. We present a modular approach for designing,\nconstructing and executing multiscale simulations on a wide range of resources,\nfrom desktops to petascale supercomputers, including combinations of these. Our\nwork features two multiscale applications, in-stent restenosis and\ncerebrovascular bloodflow, which combine multiple existing single-scale\napplications to create a multiscale simulation. These applications can be\nefficiently coupled, deployed and executed on computers up to the largest\n(peta) scale, incurring a coupling overhead of 1 to 10% of the total execution\ntime. \n\n"}
{"id": "1211.4896", "contents": "Title: Tera-scale Astronomical Data Analysis and Visualization Abstract: We present a high-performance, graphics processing unit (GPU)-based framework\nfor the efficient analysis and visualization of (nearly) terabyte (TB)-sized\n3-dimensional images. Using a cluster of 96 GPUs, we demonstrate for a 0.5 TB\nimage: (1) volume rendering using an arbitrary transfer function at 7--10\nframes per second; (2) computation of basic global image statistics such as the\nmean intensity and standard deviation in 1.7 s; (3) evaluation of the image\nhistogram in 4 s; and (4) evaluation of the global image median intensity in\njust 45 s. Our measured results correspond to a raw computational throughput\napproaching one teravoxel per second, and are 10--100 times faster than the\nbest possible performance with traditional single-node, multi-core CPU\nimplementations. A scalability analysis shows the framework will scale well to\nimages sized 1 TB and beyond. Other parallel data analysis algorithms can be\nadded to the framework with relative ease, and accordingly, we present our\nframework as a possible solution to the image analysis and visualization\nrequirements of next-generation telescopes, including the forthcoming Square\nKilometre Array pathfinder radiotelescopes. \n\n"}
{"id": "1211.5619", "contents": "Title: Correlating features in the primordial spectra Abstract: Heavy fields coupled to the inflaton reduce the speed of sound in the\neffective theory of the adiabatic mode each time the background inflationary\ntrajectory deviates from a geodesic. This can result in features in the\nprimordial spectra. We compute the corresponding bispectrum and show that if a\nvarying speed of sound induces features in the power spectrum, the change in\nthe bispectrum is given by a simple formula involving the change in the power\nspectrum and its derivatives. In this manner, we provide a uniquely\ndiscriminable signature of a varying sound speed for the adiabatic mode during\ninflation that indicates the influence of heavy fields. We find that features\nin the bispectrum peak in the equilateral limit and, in particular, in the\nsqueezed limit we find considerable enhancement entirely consistent with the\nsingle field consistency relation. From the perspective of the underlying\neffective theory, our results generalize to a wide variety of inflationary\nmodels where features are sourced by the time variation of background\nquantities. A positive detection of such correlated features would be\nunambiguous proof of the inflaton's nature as a single light scalar degree of\nfreedom embedded in a theory that is UV completable. \n\n"}
{"id": "1211.6986", "contents": "Title: Slowly Rotating Relativistic Stars in Scalar-Tensor Gravity Abstract: We consider the slowly rotating relativistic stars with a uniform angular\nvelocity in the scalar-tensor gravity, and examine the rotational effect around\nsuch compact objects. For this purpose, we derive a 2nd order differential\nequation describing the frame dragging in the scalar-tensor gravity and solve\nit numerically. As a result, we find that the total angular momentum is\nproportional to the angular velocity even in the scalar-tensor gravity. We also\nshow that one can observe the spontaneous scalarization in rotational effects\nas well as the other stellar properties, if the cosmological value of scalar\nfield is zero. On the other hand, if the cosmological value of scalar field is\nnonzero, the deviation from the general relativity can be seen in a wide range\nof the coupling constant. Additionally, we find that the deviation from the\ngeneral relativity becomes larger with more massive stellar models, which is\nindependent of the cosmological value of scalar field. Thus, via precise\nobservations of astronomical phenomena associated with rotating relativistic\nstars, one may be possible to probe not only the gravitational theory in the\nstrong-field regime, but also the existence of scalar field. \n\n"}
{"id": "1212.2529", "contents": "Title: On The Delays In Spiking Neural P Systems Abstract: In this work we extend and improve the results done in a previous work on\nsimulating Spiking Neural P systems (SNP systems in short) with delays using\nSNP systems without delays. We simulate the former with the latter over\nsequential, iteration, join, and split routing. Our results provide\nconstructions so that both systems halt at exactly the same time, start with\nonly one spike, and produce the same number of spikes to the environment after\nhalting. \n\n"}
{"id": "1212.5034", "contents": "Title: Optical Resonator Analog of a Two-Dimensional Topological Insulator Abstract: A lattice of optical ring resonators can exhibit a topological insulator\nphase, with the role of spin played by the direction of propagation of light\nwithin each ring. Unlike the system studied by Hafezi et al., topological\nprotection is achieved without fine-tuning the inter-resonator couplings, which\nare given the same periodicity as the underlying lattice. The topological\ninsulator phase occurs for strong couplings, when the tight-binding method is\ninapplicable. Using the transfer matrix method, we derive the bandstructure and\nphase diagram, and demonstrate the existence of robust edge states. When gain\nand loss are introduced, the system functions as a diode for coupled resonator\nmodes. \n\n"}
{"id": "1301.0204", "contents": "Title: Statistical measurements of quantum emitters coupled to\n  Anderson-localized modes in disordered photonic-crystal waveguides Abstract: Optical nanostructures have proven to be meritorious for tailoring the\nemission properties of quantum emitters. However, unavoidable fabrication\nimperfections may represent a nuisance. Quite remarkably, disorder offers new\nopportunities since light can be efficiently confined by random multiple\nscattering leading to Anderson localization. Here we investigate the effect of\nsuch disorder-induced cavities on the emission dynamics of single quantum dots\nembedded in disordered photonic-crystal waveguides. We present time-resolved\nmeasurements of both the total emission from Anderson-localized cavities and\nfrom single emitters that are coupled to the cavities. We observe both strongly\ninhibited and enhanced decay rates relative to the rate of spontaneous emission\nin a homogeneous medium. From a statistical analysis, we report an average\nPurcell factor of 2 in without any control on the quantum dot - cavity\ndetuning. By spectrally tuning individual quantum dots into resonance with\nAnderson-localized modes, a maximum Purcell factor of 23.8 is recorded, which\nlies at the onset of the strong coupling regime. The presented data quantify\nthe potential of naturally occurring Anderson-localized cavities for\ncontrolling and enhancing the light-matter interaction strength, which is of\nrelevance not only for cavity quantum-electrodynamics experiments but\npotentially also for efficient energy harvesting and controllable random\nlasing. \n\n"}
{"id": "1301.0672", "contents": "Title: Mixing of Poisson random measures under interacting transformations Abstract: We derive sufficient conditions for the mixing of all orders of interacting\ntransformations of a spatial Poisson point process, under a zero-type condition\nin probability and a generalized adaptedness condition. This extends a\nclassical result in the case of deterministic transformations of Poisson\nmeasures. The approach relies on moment and covariance identities for Poisson\nstochastic integrals with random integrands. \n\n"}
{"id": "1301.1294", "contents": "Title: FAST CLOUD: Pushing the Envelope on Delay Performance of Cloud Storage\n  with Coding Abstract: Our paper presents solutions that can significantly improve the delay\nperformance of putting and retrieving data in and out of cloud storage. We\nfirst focus on measuring the delay performance of a very popular cloud storage\nservice Amazon S3. We establish that there is significant randomness in service\ntimes for reading and writing small and medium size objects when assigned\ndistinct keys. We further demonstrate that using erasure coding, parallel\nconnections to storage cloud and limited chunking (i.e., dividing the object\ninto a few smaller objects) together pushes the envelope on service time\ndistributions significantly (e.g., 76%, 80%, and 85% reductions in mean, 90th,\nand 99th percentiles for 2 Mbyte files) at the expense of additional storage\n(e.g., 1.75x). However, chunking and erasure coding increase the load and hence\nthe queuing delays while reducing the supportable rate region in number of\nrequests per second per node. Thus, in the second part of our paper we focus on\nanalyzing the delay performance when chunking, FEC, and parallel connections\nare used together. Based on this analysis, we develop load adaptive algorithms\nthat can pick the best code rate on a per request basis by using off-line\ncomputed queue backlog thresholds. The solutions work with homogeneous services\nwith fixed object sizes, chunk sizes, operation type (e.g., read or write) as\nwell as heterogeneous services with mixture of object sizes, chunk sizes, and\noperation types. We also present a simple greedy solution that\nopportunistically uses idle connections and picks the erasure coding rate\naccordingly on the fly. Both backlog and greedy solutions support the full rate\nregion and provide best mean delay performance when compared to the best fixed\ncoding rate policy. Our evaluations show that backlog based solutions achieve\nbetter delay performance at higher percentile values than the greedy solution. \n\n"}
{"id": "1301.3255", "contents": "Title: Nonlinearities in modified gravity cosmology. II. Impacts of modified\n  gravity on the halo properties Abstract: The statistics of dark matter halos is an essential component of\nunderstanding the nonlinear evolution in modified gravity cosmology. Based on a\nseries of modified gravity N-body simulations, we investigate the halo mass\nfunction, concentration and bias. We model the impact of modified gravity by a\nsingle parameter \\zeta, which determines the enhancement of particle\nacceleration with respect to GR, given the identical mass distribution (\\zeta=1\nin GR). We select snapshot redshifts such that the linear matter power spectra\nof different gravity models are identical, in order to isolate the impact of\ngravity beyond modifying the linear growth rate. At the baseline redshift\ncorresponding to z_S=1.2 in the standard \\Lambda CDM, for a 10% deviation from\nGR(|\\zeta-1|=0.1), the measured halo mass function can differ by about 5-10%,\nthe halo concentration by about 10-20%, while the halo bias differs\nsignificantly less. These results demonstrate that the halo mass function\nand/or the halo concentration are sensitive to the nature of gravity and may be\nused to make interesting constraints along this line. \n\n"}
{"id": "1301.4304", "contents": "Title: Dynamics of dissipative multiple exciton generation in nanocrystals Abstract: The population dynamics of single- and bi-exciton states in semiconductor\nnanocrystals is modeled numerically in the presence of Coulomb coupling between\nsingle- and two-exciton states and a dissipation channel in order to study the\ntransient bi-exciton population that occurs in an optically excited\nsemiconductor nanocrystal. The results show that the system evolution strongly\nchanges if the dissipation is included. In a certain range of parameters, the\ngrowth of the exciton number (MEG process) is fast (on picosecond time scale)\nand the following decay (Auger process) is much slower (hundreds of\npicoseconds). In some cases, the maximum occupation of the bi-exciton state\nincreases when dissipation is included. The dynamics of an ensemble of\nnanocrystals with a certain size dispersion is studied by averaging over the\nenergy of the bi-exciton state which can be different for each single\nnanocrystal. The validity of Markov and secular approximation is also verified. \n\n"}
{"id": "1301.5034", "contents": "Title: Downlink MIMO HetNets: Modeling, Ordering Results and Performance\n  Analysis Abstract: We develop a general downlink model for multi-antenna heterogeneous cellular\nnetworks (HetNets), where base stations (BSs) across tiers may differ in terms\nof transmit power, target signal-to-interference-ratio (SIR), deployment\ndensity, number of transmit antennas and the type of multi-antenna\ntransmission. In particular, we consider and compare space division multiple\naccess (SDMA), single user beamforming (SU-BF), and baseline single-input\nsingle-output (SISO) transmission. For this general model, the main\ncontributions are: (i) ordering results for both coverage probability and per\nuser rate in closed form for any BS distribution for the three considered\ntechniques, using novel tools from stochastic orders, (ii) upper bounds on the\ncoverage probability assuming a Poisson BS distribution, and (iii) a comparison\nof the area spectral efficiency (ASE). The analysis concretely demonstrates,\nfor example, that for a given total number of transmit antennas in the network,\nit is preferable to spread them across many single-antenna BSs vs. fewer\nmulti-antenna BSs. Another observation is that SU-BF provides higher coverage\nand per user data rate than SDMA, but SDMA is in some cases better in terms of\nASE. \n\n"}
{"id": "1302.0552", "contents": "Title: Adaptation in a stochastic multi-resources chemostat model Abstract: We are interested in modeling the Darwinian evolution resulting from the\ninterplay of phenotypic variation and natural selection through ecological\ninteractions, in the specific scales of the biological framework of adaptive\ndynamics. Adaptive dynamics so far has been put on a rigorous footing only for\ndirect competition models (Lotka-Volterra models) involving a competition\nkernel which describes the competition pressure from one individual to another\none. We extend this to a multi-resources chemostat model, where the competition\nbetween individuals results from the sharing of several resources which have\ntheir own dynamics. Starting from a stochastic birth and death process model,\nwe prove that, when advantageous mutations are rare, the population behaves on\nthe mutational time scale as a jump process moving between equilibrium states\n(the polymorphic evolution sequence of the adaptive dynamics literature). An\nessential technical ingredient is the study of the long time behavior of a\nchemostat multi-resources dynamical system. In the small mutational steps limit\nthis process in turn gives rise to a differential equation in phenotype space\ncalled canonical equation of adaptive dynamics. From this canonical equation\nand still assuming small mutation steps, we prove a rigorous characterization\nof the evolutionary branching points. \n\n"}
{"id": "1302.0948", "contents": "Title: Non-monetary fair scheduling---a cooperative game theory approach Abstract: We consider a multi-organizational system in which each organization\ncontributes processors to the global pool but also jobs to be processed on the\ncommon resources. The fairness of the scheduling algorithm is essential for the\nstability and even for the existence of such systems (as organizations may\nrefuse to join an unfair system).\n  We consider on-line, non-clairvoyant scheduling of sequential jobs. The\nstarted jobs cannot be stopped, canceled, preempted, or moved to other\nprocessors. We consider identical processors, but most of our results can be\nextended to related or unrelated processors.\n  We model the fair scheduling problem as a cooperative game and we use the\nShapley value to determine the ideal fair schedule. In contrast to the current\nliterature, we do not use money to assess the relative utilities of jobs.\nInstead, to calculate the contribution of an organization, we determine how the\npresence of this organization influences the performance of other\norganizations. Our approach can be used with arbitrary utility function (e.g.,\nflow time, tardiness, resource utilization), but we argue that the utility\nfunction should be strategy resilient. The organizations should be discouraged\nfrom splitting, merging or delaying their jobs. We present the unique (to\nwithin a multiplicative and additive constants) strategy resilient utility\nfunction.\n  We show that the problem of fair scheduling is NP-hard and hard to\napproximate. However, for unit-size jobs, we present an FPRAS. Also, we show\nthat the problem parametrized with the number of organizations is FPT. Although\nfor the large number of the organizations the problem is computationally hard,\nthe presented exponential algorithm can be used as a fairness benchmark. \n\n"}
{"id": "1302.5616", "contents": "Title: Large Deviations for Nonlocal Stochastic Neural Fields Abstract: We study the effect of additive noise on integro-differential neural field\nequations. In particular, we analyze an Amari-type model driven by a $Q$-Wiener\nprocess and focus on noise-induced transitions and escape. We argue that\nproving a sharp Kramers' law for neural fields poses substanial difficulties\nbut that one may transfer techniques from stochastic partial differential\nequations to establish a large deviation principle (LDP). Then we demonstrate\nthat an efficient finite-dimensional approximation of the stochastic neural\nfield equation can be achieved using a Galerkin method and that the resulting\nfinite-dimensional rate function for the LDP can have a multi-scale structure\nin certain cases. These results form the starting point for an efficient\npractical computation of the LDP. Our approach also provides the technical\nbasis for further rigorous study of noise-induced transitions in neural fields\nbased on Galerkin approximations. \n\n"}
{"id": "1303.5275", "contents": "Title: Achieving Efficient Strong Scaling with PETSc using Hybrid MPI/OpenMP\n  Optimisation Abstract: The increasing number of processing elements and decreas- ing memory to core\nratio in modern high-performance platforms makes efficient strong scaling a key\nrequirement for numerical algorithms. In order to achieve efficient scalability\non massively parallel systems scientific software must evolve across the entire\nstack to exploit the multiple levels of parallelism exposed in modern\narchitectures. In this paper we demonstrate the use of hybrid MPI/OpenMP\nparallelisation to optimise parallel sparse matrix-vector multiplication in\nPETSc, a widely used scientific library for the scalable solution of partial\ndifferential equations. Using large matrices generated by Fluidity, an open\nsource CFD application code which uses PETSc as its linear solver engine, we\nevaluate the effect of explicit communication overlap using task-based\nparallelism and show how to further improve performance by explicitly load\nbalancing threads within MPI processes. We demonstrate a significant speedup\nover the pure-MPI mode and efficient strong scaling of sparse matrix-vector\nmultiplication on Fujitsu PRIMEHPC FX10 and Cray XE6 systems. \n\n"}
{"id": "1303.7032", "contents": "Title: A Massively Parallel Associative Memory Based on Sparse Neural Networks Abstract: Associative memories store content in such a way that the content can be\nlater retrieved by presenting the memory with a small portion of the content,\nrather than presenting the memory with an address as in more traditional\nmemories. Associative memories are used as building blocks for algorithms\nwithin database engines, anomaly detection systems, compression algorithms, and\nface recognition systems. A classical example of an associative memory is the\nHopfield neural network. Recently, Gripon and Berrou have introduced an\nalternative construction which builds on ideas from the theory of error\ncorrecting codes and which greatly outperforms the Hopfield network in\ncapacity, diversity, and efficiency. In this paper we implement a variation of\nthe Gripon-Berrou associative memory on a general purpose graphical processing\nunit (GPU). The work of Gripon and Berrou proposes two retrieval rules,\nsum-of-sum and sum-of-max. The sum-of-sum rule uses only matrix-vector\nmultiplication and is easily implemented on the GPU. The sum-of-max rule is\nmuch less straightforward to implement because it involves non-linear\noperations. However, the sum-of-max rule gives significantly better retrieval\nerror rates. We propose a hybrid rule tailored for implementation on a GPU\nwhich achieves a 880-fold speedup without sacrificing any accuracy. \n\n"}
{"id": "1304.0040", "contents": "Title: Manipulation of skyrmions in nanodisks with a current pulse and skyrmion\n  rectifier Abstract: A skyrmion in a nanosized disk of a chiral magnet can be used as a bit of\ninformation. To this end, it is desirable to control the creation and removal\nof a skyrmion only by currents without using external magnetic fields. Here we\npropose to create a skyrmion by applying a current pulse to a nanodisk. The\nskyrmion can be removed from the disk by applying a dc current. We show that\nthe dynamics of the created skyrmion can lead to a rectification effect, in\nwhich a dc voltage is generated by the motion of skyrmion in the presence of an\nac current. \n\n"}
{"id": "1304.0425", "contents": "Title: Analytic Solutions for Navarro--Frenk--White Lens Models for Low\n  Characteristic Convergences Abstract: The Navarro-Frenk-White (NFW) density profile is often used to model\ngravitational lenses. For low values of the characteristic convergence\n($\\kappa_s \\ll 1$) of this model - corresponding to galaxy and galaxy group\nmass scales - a high numerical precision is required in order to accurately\ncompute several quantities in the strong lensing regime. An alternative for\nfast and accurate computations is to derive analytic approximations in this\nlimit. In this work we obtain analytic solutions for several lensing quantities\nfor elliptical (ENFW) and pseudo-elliptical (PNFW) NFW lens models on the\ntypical scales where gravitational arcs are expected to be formed, in the\n$\\kappa_s \\ll 1$ limit, establishing their domain of validity. We derive\nanalytic solutions for the convergence and shear for these models, obtaining\nexplicit expressions for the iso-convergence contours and constant distortion\ncurves (including the tangential critical curve). We also compute the\ndeformation cross section, which is given in closed form for the circular NFW\nmodel and in terms of a one-dimensional integral for the elliptical ones. In\naddition, we provide a simple expression for the ellipticity of the\niso-convergence contours of the pseudo-elliptical models and the connection of\ncharacteristic convergences among the PNFW and ENFW models. We conclude that\nthe set of solutions derived here is generally accurate for $\\kappa_s \\lesssim\n0.1$. For low ellipticities, values up to $\\kappa_s \\simeq 0.18$ are allowed.\nOn the other hand, the mapping between PNFW and the ENFW models is valid up to\n$\\kappa_s \\simeq 0.4$. The solutions derived in this work can be used to speed\nup numerical codes and ensure their accuracy in the low $\\kappa_s$ regime,\nincluding applications to arc statistics and other strong lensing observables.\n(Abridged) \n\n"}
{"id": "1304.0516", "contents": "Title: Unusual Brownian motion of photons in open absorbing media Abstract: Very recent experiments have discovered that localized light in strongly\nabsorbing media displays intriguing diffusive phenomena. Here we develop a\nfirst-principles theory of light propagation in open media with arbitrary\nabsorption strength and sample length. We show analytically that photons in\nlocalized open absorbing media exhibit unusual Brownian motion. Specifically,\nwave transport follows the diffusion equation with the diffusion coefficient\nexhibiting spatial resolution. Most strikingly, despite that the system is\ncontrolled by two parameters -- the ratio of the localization (absorption)\nlength to the sample length -- the spatially resolved diffusion coefficient\ndisplays novel single parameter scaling: it depends on the space via the\nreturning probability. Our analytic predictions for this diffusion coefficient\nare confirmed by numerical simulations. In the strong absorption limit they\nagree well with the experimental results. \n\n"}
{"id": "1304.0539", "contents": "Title: A Real-time Group Auction System for Efficient Allocation of Cloud\n  Internet Applications Abstract: Increasing number of the cloud-based Internet applications demands for\nefficient resource and cost management. This paper proposes a real-time group\nauction system for the cloud instance market. The system is designed based on a\ncombinatorial double auction, and its applicability and effectiveness are\nevaluated in terms of resource efficiency and monetary benefits to auction\nparticipants (e.g., cloud users and providers). The proposed auction system\nassists them to decide when and how providers allocate their resources to which\nusers. Furthermore, we propose a distributed algorithm using a group formation\ngame that determines which users and providers will trade resources by their\ncooperative decisions. To find how to allocate the resources, the utility\noptimization problem is formulated as a binary integer programming problem, and\nthe nearly optimal solution is obtained by a heuristic algorithm with quadratic\ntime complexity. In comparison studies, the proposed real-time group auction\nsystem with cooperation outperforms an individual auction in terms of the\nresource efficiency (e.g., the request acceptance rate for users and resource\nutilization for providers) and monetary benefits (e.g., average payments for\nusers and total profits for providers). \n\n"}
{"id": "1304.3717", "contents": "Title: Linking X-ray AGN with dark matter halos: a model compatible with AGN\n  luminosity function and large-scale clustering properties Abstract: Our goal is to find a minimalistic model that describes the luminosity\nfunction and large-scale clustering bias of the X-ray-selected AGN in the\ngeneral framework of the concordance LCDM model. We assume that a simple\npopulation-averaged scaling relation between the AGN X-ray luminosity L_X and\nthe host dark matter halo mass M_h exists. With such a relation, the AGN X-ray\nluminosity function can be computed from the halo mass function. Using the\nconcordance LCDM halo mass function for the latter, we obtain the M_h-L_X\nrelation required to match the redshift-dependent AGN X-ray luminosity function\nknown from X-ray observations. We find that with a simple power-law-scaling M_h\n\\propto L_X^\\Gamma(z), our model can successfully reproduce the observed X-ray\nluminosity function. Furthermore, we automatically obtain predictions for the\nlarge-scale AGN clustering amplitudes and their dependence on the luminosity\nand redshift, which seem to be compatible with AGN clustering measurements. Our\nmodel also includes the redshift-dependent AGN duty cycle which peaks at the\nredshift z ~ 1, and its peak value is consistent with unity, suggesting that on\naverage there is no more than one AGN per dark matter halo. For a typical\nX-ray-selected AGN at z ~ 1, our best-fit M_h-L_X scaling implies low Eddington\nratio L_X/L_Edd ~ 10^{-4}-10^{-3} (2-10 keV band, no bolometric correction\napplied) and correspondingly large mass growth e-folding times, suggesting that\nthe typical X-ray AGN are dominantly fueled via relatively inefficient\n'hot-halo' accretion mode. \n\n"}
{"id": "1304.6277", "contents": "Title: Localization properties of squeezed quantum states in nanoscale space\n  domains Abstract: We construct families of squeezed quantum states on an interval (depending on\nboundary conditions, we interpret the interval as a circle or as the infinite\nsquare potential well) and obtain estimates of position and momentum\ndispersions for these states. A particular attention is paid to the possibility\nof proper localization of a particle in nanoscale space domains. One of the\nconstructed family of squeezed states is based on the theta function. It is a\ngeneralization of the known coherent and squeezed states on the circle. Also we\nconstruct a family of squeezed states based on truncated Gaussian functions and\na family of wave packets based on the discretization of an arbitrary continuous\nmomentum probability distribution.\n  The problem of finiteness of the energy dispersion for the squeezed states in\nthe infinite well is discussed. Finally, we perform the limit of large interval\nlength and the semiclassical limit.\n  As a supplementary general result, we show that an arbitrary physical\nquantity has a finite dispersion if and only if the wave function of a quantum\nsystem belongs to the domain of the corresponding self-adjoint operator. This\ncan be regarded as a physical meaning of the domain of a self-adjoint operator. \n\n"}
{"id": "1304.7301", "contents": "Title: Percolation and disorder-resistance in cellular automata Abstract: We rigorously prove a form of disorder-resistance for a class of\none-dimensional cellular automaton rules, including some that arise as boundary\ndynamics of two-dimensional solidification rules. Specifically, when started\nfrom a random initial seed on an interval of length $L$, with probability\ntending to one as $L\\to\\infty$, the evolution is a replicator. That is, a\nregion of space-time of density one is filled with a spatially and temporally\nperiodic pattern, punctuated by a finite set of other finite patterns repeated\nat a fractal set of locations. On the other hand, the same rules exhibit\nprovably more complex evolution from some seeds, while from other seeds their\nbehavior is apparently chaotic. A principal tool is a new variant of\npercolation theory, in the context of additive cellular automata from random\ninitial states. \n\n"}
{"id": "1305.2475", "contents": "Title: Rayleigh-Taylor instability in an ionized medium Abstract: We study linear theory of the magnetized Rayleigh-Taylor instability in a\nsystem consisting of ions and neutrals. Both components are affected by a\nuniform vertical gravitational field. We consider ions and neutrals as two\nseparate fluid systems where they can exchange momentum through collisions.\nHowever, ions have direct interaction with the magnetic field lines but\nneutrals are not affected by the field directly. The equations of our two-fluid\nmodel are linearized and by applying a set of proper boundary conditions, a\ngeneral dispersion relation is derived for our two superposed fluids separated\nby a horizontal boundary. We found two unstable modes for a range of the\nwavenumbers. It seems that one of the unstable modes corresponds to the ions\nand the other one is for the neutrals. Both modes are reduced with increasing\nthe collision rate of the particles and the ionization fraction. We show that\nif the two-fluid nature is considered, RT instability would not be suppressed\nand also show that the growth time of the perturbations increases. As an\nexample, we apply our analysis to the Local clouds which seems to have arisen\nbecause of the RT instability. Assuming that the clouds are partially ionized,\nwe find that the growth rate of these clouds increases in comparison to a fully\nionized case. \n\n"}
{"id": "1305.3945", "contents": "Title: On the Delay-Storage Trade-off in Content Download from Coded\n  Distributed Storage Systems Abstract: In this paper we study how coding in distributed storage reduces expected\ndownload time, in addition to providing reliability against disk failures. The\nexpected download time is reduced because when a content file is encoded to add\nredundancy and distributed across multiple disks, reading only a subset of the\ndisks is sufficient to reconstruct the content. For the same total storage\nused, coding exploits the diversity in storage better than simple replication,\nand hence gives faster download. We use a novel fork-join queuing framework to\nmodel multiple users requesting the content simultaneously, and derive bounds\non the expected download time. Our system model and results are a novel\ngeneralization of the fork-join system that is studied in queueing theory\nliterature. Our results demonstrate the fundamental trade-off between the\nexpected download time and the amount of storage space. This trade-off can be\nused for design of the amount of redundancy required to meet the delay\nconstraints on content delivery. \n\n"}
{"id": "1305.3945", "contents": "Title: On the Delay-Storage Trade-off in Content Download from Coded\n  Distributed Storage Systems Abstract: In this paper we study how coding in distributed storage reduces expected\ndownload time, in addition to providing reliability against disk failures. The\nexpected download time is reduced because when a content file is encoded to add\nredundancy and distributed across multiple disks, reading only a subset of the\ndisks is sufficient to reconstruct the content. For the same total storage\nused, coding exploits the diversity in storage better than simple replication,\nand hence gives faster download. We use a novel fork-join queuing framework to\nmodel multiple users requesting the content simultaneously, and derive bounds\non the expected download time. Our system model and results are a novel\ngeneralization of the fork-join system that is studied in queueing theory\nliterature. Our results demonstrate the fundamental trade-off between the\nexpected download time and the amount of storage space. This trade-off can be\nused for design of the amount of redundancy required to meet the delay\nconstraints on content delivery. \n\n"}
{"id": "1305.5520", "contents": "Title: Distributed Minimum Cut Approximation Abstract: We study the problem of computing approximate minimum edge cuts by\ndistributed algorithms. We use a standard synchronous message passing model\nwhere in each round, $O(\\log n)$ bits can be transmitted over each edge (a.k.a.\nthe CONGEST model). We present a distributed algorithm that, for any weighted\ngraph and any $\\epsilon \\in (0, 1)$, with high probability finds a cut of size\nat most $O(\\epsilon^{-1}\\lambda)$ in $O(D) + \\tilde{O}(n^{1/2 + \\epsilon})$\nrounds, where $\\lambda$ is the size of the minimum cut. This algorithm is based\non a simple approach for analyzing random edge sampling, which we call the\nrandom layering technique. In addition, we also present another distributed\nalgorithm, which is based on a centralized algorithm due to Matula [SODA '93],\nthat with high probability computes a cut of size at most $(2+\\epsilon)\\lambda$\nin $\\tilde{O}((D+\\sqrt{n})/\\epsilon^5)$ rounds for any $\\epsilon>0$.\n  The time complexities of both of these algorithms almost match the\n$\\tilde{\\Omega}(D + \\sqrt{n})$ lower bound of Das Sarma et al. [STOC '11], thus\nleading to an answer to an open question raised by Elkin [SIGACT-News '04] and\nDas Sarma et al. [STOC '11].\n  Furthermore, we also strengthen the lower bound of Das Sarma et al. by\nextending it to unweighted graphs. We show that the same lower bound also holds\nfor unweighted multigraphs (or equivalently for weighted graphs in which\n$O(w\\log n)$ bits can be transmitted in each round over an edge of weight $w$),\neven if the diameter is $D=O(\\log n)$. For unweighted simple graphs, we show\nthat even for networks of diameter $\\tilde{O}(\\frac{1}{\\lambda}\\cdot\n\\sqrt{\\frac{n}{\\alpha\\lambda}})$, finding an $\\alpha$-approximate minimum cut\nin networks of edge connectivity $\\lambda$ or computing an\n$\\alpha$-approximation of the edge connectivity requires $\\tilde{\\Omega}(D +\n\\sqrt{\\frac{n}{\\alpha\\lambda}})$ rounds. \n\n"}
{"id": "1305.5857", "contents": "Title: Metamaterial Van Hove Singularity Abstract: We introduce the photonic analogue of electronic Van Hove singularities (VHS)\nin artificial media (metamaterials) with hyperbolic dispersion. Unlike photonic\nand electronic crystals, the VHS in metamaterials is unrelated to the\nunderlying periodicity and occurs due to slow light modes in the structure. We\nshow that the VHS characteristics are manifested in the near-field local\ndensity of optical states in spite of the losses, dispersion and finite unit\ncell size of the hyperbolic metamaterial. Finally we show that this work should\nlead to quantum, thermal, nano-lasing and biosensing applications of Van Hove\nsingularities in hyperbolic metamaterials achievable by current fabrication\ntechnology. \n\n"}
{"id": "1305.6414", "contents": "Title: Generation of hyper-entangled photon pairs in coupled microcavities Abstract: We propose and theoretically analyze a new scheme for generating\nhyper-entangled photon pairs in a system of polaritons in coupled planar\nmicrocavities. Starting from a microscopic model, we evaluate the relevant\nparametric scattering processes and numerically simulate the phonon-induced\nnoise background under continuous-wave excitation. Our results show that,\ncompared to other polariton entanglement proposals, our scheme enables the\ngeneration of photon pairs that are entangled in both path and polarization\ndegrees of freedom, and simultaneously leads to a strong reduction of the\nphotoluminesence noise background. This can significantly improve the fidelity\nof the entangled photon pairs under realistic experimental conditions. \n\n"}
{"id": "1305.6566", "contents": "Title: Almost local generation of EPR entanglement in non-equilibrium Abstract: The generation of entanglement is studied in a minimal model consisting of\ntwo independent Gaussian parties embedded in a common heat bath and subject to\nlocal control signals. Neither the reservoir alone nor the external driving can\ninduce quantum non-locality but only the cooperative impact of both in\nnon-equilibrium. It is shown that this corresponds to a dynamical symmetry\nbreaking between the modes. By applying optimal control protocols substantial\nentanglement is generated even for single-site control and at higher\ntemperatures and is preserved after the control is switched off. \n\n"}
{"id": "1305.6811", "contents": "Title: Observation of the cosmic-ray shadow of the Moon with IceCube Abstract: We report on the observation of a significant deficit of cosmic rays from the\ndirection of the Moon with the IceCube detector. The study of this \"Moon\nshadow\" is used to characterize the angular resolution and absolute pointing\ncapabilities of the detector. The detection is based on data taken in two\nperiods before the completion of the detector: between April 2008 and May 2009,\nwhen IceCube operated in a partial configuration with 40 detector strings\ndeployed in the South Pole ice, and between May 2009 and May 2010 when the\ndetector operated with 59 strings. Using two independent analysis methods, the\nMoon shadow has been observed to high significance (> 6 sigma) in both detector\nconfigurations. The observed location of the shadow center is within 0.2\ndegrees of its expected position when geomagnetic deflection effects are taken\ninto account. This measurement validates the directional reconstruction\ncapabilities of IceCube. \n\n"}
{"id": "1305.7225", "contents": "Title: CMB Faraday rotation as seen through the Milky Way Abstract: Faraday Rotation (FR) of CMB polarization, as measured through mode-coupling\ncorrelations of E and B modes, can be a promising probe of a stochastic\nprimordial magnetic field (PMF). While the existence of a PMF is still\nhypothetical, there will certainly be a contribution to CMB FR from the\nmagnetic field of the Milky Way. We use existing estimates of the Milky Way\nrotation measure (RM) to forecast its detectability with upcoming and future\nCMB experiments. We find that the galactic RM will not be seen in polarization\nmeasurements by Planck, but that it will need to be accounted for by CMB\nexperiments capable of detecting the weak lensing contribution to the B-mode.\nWe then discuss prospects for constraining the PMF in the presence of FR due to\nthe galaxy under various assumptions that include partial de-lensing and\npartial subtraction of the galactic FR. We find that a realistic future\nsub-orbital experiment, covering a patch of the sky near the galactic poles,\ncan detect a scale-invariant PMF of 0.1 nano-Gauss at better than 95%\nconfidence level, while a dedicated space-based experiment can detect even\nsmaller fields. \n\n"}
{"id": "1306.1556", "contents": "Title: Diversity Polynomials for the Analysis of Temporal Correlations in\n  Wireless Networks Abstract: The interference in wireless networks is temporally correlated, since the\nnode or user locations are correlated over time and the interfering\ntransmitters are a subset of these nodes. For a wireless network where\n(potential) interferers form a Poisson point process and use ALOHA for channel\naccess, we calculate the joint success and outage probabilities of n\ntransmissions over a reference link. The results are based on the diversity\npolynomial, which captures the temporal interference correlation. The joint\noutage probability is used to determine the diversity gain (as the SIR goes to\ninfinity), and it turns out that there is no diversity gain in simple\nretransmission schemes, even with independent Rayleigh fading over all links.\nWe also determine the complete joint SIR distribution for two transmissions and\nthe distribution of the local delay, which is the time until a repeated\ntransmission over the reference link succeeds. \n\n"}
{"id": "1306.3143", "contents": "Title: Surface plasmon polaritons on soft-boundary graphene nanoribbons and\n  their application as voltage controlled plasmonic switches and frequency\n  demultiplexers Abstract: A graphene sheet gated with a ridged ground plane, creating a soft-boundary\n(SB) graphene nanoribbon, is considered. By adjusting the ridge parameters and\nbias voltage a channel can be created on the graphene which can guide TM\nsurface plasmon polaritons (SPP). Two types of modes are found; fundemental and\nhigher-order modes with no apparent cutoff frequency and with energy\ndistributed over the created channel, and edge modes with energy concen-trated\nat the soft-boundary edge. Dispersion curves, electric near-field patterns, and\ncurrent distributions of these modes are determined. Since the location where\nenergy is concentrated in the edge modes can be easily controlled\nelectronically by the bias voltage and frequency, the edge-mode phenomena is\nused to propose a novel voltage controlled plasmonic switch and a plasmonic\nfrequency demultiplexer. \n\n"}
{"id": "1306.4200", "contents": "Title: Effects of quasiparticle tunneling in a circuit-QED realization of a\n  strongly driven two-level system Abstract: We experimentally and theoretically study the frequency shift of a driven\ncavity coupled to a superconducting charge qubit. In addition to previous\nstudies, we here also consider drive strengths large enough to energetically\nallow for quasiparticle creation. Quasiparticle tunneling leads to the\ninclusion of more than two charge states in the dynamics. To explain the\nobserved effects, we develop a master equation for the microwave dressed charge\nstates, including quasiparticle tunneling. A bimodal behavior of the frequency\nshift as a function of gate voltage can be used for sensitive charge detection.\nHowever, at weak drives the charge sensitivity is significantly reduced by\nnon-equilibrium quasiparticles, which induce transitions to a non-sensitive\nstate. Unexpectedly, at high enough drives, quasiparticle tunneling enables a\nvery fast relaxation channel to the sensitive state. In this regime, the charge\nsensitivity is thus robust against externally injected quasiparticles and the\ndesired dynamics prevail over a broad range of temperatures. We find very good\nagreement between theory and experiment over a wide range of drive strengths\nand temperatures. \n\n"}
{"id": "1306.5743", "contents": "Title: Cosmological perturbations of massive gravity coupled to DBI Galileons Abstract: Certain scalar fields with higher derivative interactions and novel classical\nand quantum mechanical properties - the Galileons - can be naturally\ncovariantized by coupling to nonlinear massive gravity in such a way that their\nsymmetries and number of degrees of freedom are unchanged. We study the\npropagating degrees of freedom in these models around cosmologically\ninteresting backgrounds. We identify the conditions necessary for such a theory\nto remain ghost free, and consider when tachyonic instabilities can be avoided.\nWe show that on the self-accelerating branch of solutions, the kinetic terms\nfor the vector and scalar modes of the massive graviton vanish, as in the case\nof pure massive gravity. \n\n"}
{"id": "1306.6116", "contents": "Title: Distributed Estimation and Detection with Bounded Transmissions over\n  Gaussian Multiple Access Channels Abstract: A distributed inference scheme which uses bounded transmission functions over\na Gaussian multiple access channel is considered. When the sensor measurements\nare decreasingly reliable as a function of the sensor index, the conditions on\nthe transmission functions under which consistent estimation and reliable\ndetection are possible is characterized. For the distributed estimation\nproblem, an estimation scheme that uses bounded transmission functions is\nproved to be strongly consistent provided that the variance of the noise\nsamples are bounded and that the transmission function is one-to-one. The\nproposed estimation scheme is compared with the amplify-and-forward technique\nand its robustness to impulsive sensing noise distributions is highlighted. In\ncontrast to amplify-and-forward schemes, it is also shown that bounded\ntransmissions suffer from inconsistent estimates if the sensing noise variance\ngoes to infinity. For the distributed detection problem, similar results are\nobtained by studying the deflection coefficient. Simulations corroborate our\nanalytical results. \n\n"}
{"id": "1307.0433", "contents": "Title: 'Mutual Watch-dog Networking': Distributed Awareness of Faults and\n  Critical Events in Petascale/Exascale systems Abstract: Many tile systems require techniques to be applied to increase components\nresilience and control the FIT (Failures In Time) rate. When scaling to peta-\nexa-scale systems the FIT rate may become unacceptable due to component\nnumerosity, requiring more systemic countermeasures. Thus, the ability to be\nfault aware, i.e. to detect and collect information about fault and critical\nevents, is a necessary feature that large scale distributed architectures must\nprovide in order to apply systemic fault tolerance techniques. In this context,\nthe LO|FA|MO approach is a way to obtain systemic fault awareness, by\nimplementing a mutual watchdog mechanism and guaranteeing fault detection in a\nno-single-point-of-failure fashion. This document contains specification and\nimplementation details about this approach, in the shape of a technical report. \n\n"}
{"id": "1307.1549", "contents": "Title: Effect of the Pauli principle on photoelectron spin transport in $p^+$\n  GaAs Abstract: In p+ GaAs thin films, the effect of photoelectron degeneracy on spin\ntransport is investigated theoretically and experimentally by imaging the spin\npolarization profile as a function of distance from a tightly-focussed light\nexcitation spot. Under degeneracy of the electron gas (high concentration, low\ntemperature), a dip at the center of the polarization profile appears with a\npolarization maximum at a distance of about $2 \\; \\mu m$ from the center. This\ncounterintuitive result reveals that photoelectron diffusion depends on spin,\nas a direct consequence of the Pauli principle. This causes a concentration\ndependence of the spin stiffness while the spin dependence of the mobility is\nfound to be weak in doped material. The various effects which can modify spin\ntransport in a degenerate electron gas under local laser excitation are\nconsidered. A comparison of the data with a numerical solution of the coupled\ndiffusion equations reveals that ambipolar coupling with holes increases the\nsteady-state photo-electron density at the excitation spot and therefore the\namplitude of the degeneracy-induced polarization dip. Thermoelectric currrents\nare predicted to depend on spin under degeneracy (spin Soret currents), but\nthese currents are negligible except at very high excitation power where they\nplay a relatively small role. Coulomb spin drag and bandgap renormalization are\nnegligible due to electrostatic screening by the hole gas. \n\n"}
{"id": "1307.3154", "contents": "Title: Phase-change radiative thermal diode Abstract: A thermal diode transports heat mainly in one preferential direction rather\nthan in the opposite direction. This behavior is generally due to the\nnon-linear dependence of certain physical properties with respect to the\ntemperature. Here we introduce a radiative thermal diode which rectifies heat\ntransport thanks to the phase transitions of materials. Rectification\ncoefficients greater than 70% and up to 90% are shown, even for small\ntemperature differences. This result could have important applications in the\ndevelopment of futur contactless thermal circuits or in the conception of\nradiative coatings for thermal management. \n\n"}
{"id": "1307.6658", "contents": "Title: A Reputation Based Framework to Avoid Free-riding in Unstructured\n  Peer-to-Peer network Abstract: Free riding is a major problem in peer-to-peer networks. Reputation\nmanagement systems are generally proposed to overcome this problem. In this\npaper we have discussed a possible way of resource allocation on the basis of\nreputation management system i.e. probabilistic allocation based on reputation.\nThis seems to be a better way for allocation of resources because in this case\nnodes that do not have very good reputation about each other, may also serve\neach other at least some amount of resource with finite probability. This\navoids disconnect between them. Algorithms are presented for optimizing the\nshared capacity, reputation based probabilistic allocation that is optimal for\na node, and formation of interest groups on the basis of similarity between\ninterests of nodes. \n\n"}
{"id": "1307.6983", "contents": "Title: Blueshift of the surface plasmon resonance in silver nanoparticles:\n  substrate effects Abstract: We study the blueshift of the surface plasmon (SP) resonance energy of\nisolated Ag nanoparticles with decreasing particle diameter, which we recently\nmeasured using electron energy loss spectroscopy (EELS). As the particle\ndiameter decreases from 26 down to 3.5 nm, a large blueshift of 0.5 eV of the\nSP resonance energy is observed. In this paper, we base our theoretical\ninterpretation of our experimental findings on the nonlocal hydrodynamic model,\nand compare the effect of the substrate on the SP resonance energy to the\napproach of an effective homogeneous background permittivity. We derive the\nnonlocal polarizability of a small metal sphere embedded in a homogeneous\ndielectric environment, leading to the nonlocal generalization of the classical\nClausius-Mossotti factor. We also present an exact formalism based on multipole\nexpansions and scattering matrices to determine the optical response of a metal\nsphere on a dielectric substrate of finite thickness, taking into account\nretardation and nonlocal effects. We find that the substrate-based calculations\nshow a similar-sized blueshift as calculations based on a sphere in a\nhomogeneous environment, and that they both agree qualitatively with the EELS\nmeasurements. \n\n"}
{"id": "1307.7527", "contents": "Title: Screening-induced negative differential conductance in the Franck-Condon\n  blockade regime Abstract: Screening effects in nanoscale junctions with strong electron-phonon coupling\nopen new physical scenarios. We propose an accurate many-body approach to deal\nwith the simultaneous occurrence of the Franck-Condon blockade and the\nscreening-induced enhancement of the polaron mobility. We derive a transparent\nanalytic expression for the electrical current: transient and steady-state\nfeatures are directly interpreted and explained. Moreover, the interplay\nbetween phononic and electronic excitations gives rise to a novel mechanism of\nnegative differential conductance. Experimental setup to observe this\nphenomenon are discussed. \n\n"}
{"id": "1307.7737", "contents": "Title: Exact deterministic representation of Markovian SIR epidemics on\n  networks with and without loops Abstract: In a previous paper Sharkey et al. [13] proved the exactness of closures at\nthe level of triples for Markovian SIR (susceptible-infected-removed) dynamics\non tree-like networks. This resulted in a deterministic representation of the\nepidemic dynamics on the network that can be numerically evaluated. In this\npaper, we extend this modelling framework to certain classes of networks\nexhibiting loops. We show that closures where the loops are kept intact are\nexact, and lead to a simplified and numerically solvable system of ODEs\n(ordinary-differential-equations). The findings of the paper lead us to a\ngeneralisation of closures that are based on partitioning the network around\nnodes that are cut-vertices (i.e. the removal of such a node leads to the\nnetwork breaking down into at least two disjointed components or subnetworks).\nExploiting this structural property of the network yields some natural\nclosures, where the evolution of a particular state can typically be exactly\ngiven in terms of the corresponding or projected sates on the subnetworks and\nthe cut-vertex. A byproduct of this analysis is an alternative probabilistic\nproof of the exactness of the closures for tree-like networks presented in\nSharkey et al. [13]. In this paper we also elaborate on how the main result can\nbe applied to more realistic networks, for which we write down the ODEs\nexplicitly and compare output from these to results from simulation.\nFurthermore, we give a general, recipe-like method of how to apply the\nreduction by closures technique for arbitrary networks, and give an upper bound\non the maximum number of equations needed for an exact representation. \n\n"}
{"id": "1308.0178", "contents": "Title: Coded Caching with Nonuniform Demands Abstract: We consider a network consisting of a file server connected through a shared\nlink to a number of users, each equipped with a cache. Knowing the popularity\ndistribution of the files, the goal is to optimally populate the caches such as\nto minimize the expected load of the shared link. For a single cache, it is\nwell known that storing the most popular files is optimal in this setting.\nHowever, we show here that this is no longer the case for multiple caches.\nIndeed, caching only the most popular files can be highly suboptimal. Instead,\na fundamentally different approach is needed, in which the cache contents are\nused as side information for coded communication over the shared link. We\npropose such a coded caching scheme and prove that it is close to optimal. \n\n"}
{"id": "1308.0379", "contents": "Title: Example of a Non-standard Extreme Value Law Abstract: It has been shown that sufficiently well mixing dynamical systems with\npositive entropy have extreme value laws which in the limit converge to one of\nthe three standard distributions known for i.i.d. processes, namely Gumbel,\nFr\\'echet and Weibull distributions. In this short note we give an example\nwhich has a non-standard limiting distribution for its extreme values.\nRotations of the circle by irrational numbers are used and it will be shown\nthat the limiting distribution is a step function where the limit has to be\ntaken along a suitable sequence given by the convergents. \n\n"}
{"id": "1308.0930", "contents": "Title: Calibrating and Controlling the Quantum Efficiency Distribution of\n  Inhomogeneously Broadened Quantum Rods Using a Mirror Ball Abstract: We demonstrate that a simple silver coated ball lens can be used to\naccurately measure the entire distribution of radiative transition rates of\nquantum dot nanocrystals. This simple and cost-effective implementation of\nDrexhage's method that uses nanometer-controlled optical mode density\nvariations near a mirror, not only allows to extract calibrated\nensemble-averaged rates, but for the first time also to quantify the full\ninhomogeneous dispersion of radiative and non radiative decay rates across\nthousands of nanocrystals. We apply the technique to novel ultra-stable\nCdSe/CdS dot-in-rod emitters. The emitters are of large current interest due to\ntheir improved stability and reduced blinking. We retrieve a room-temperature\nensemble average quantum efficiency of 0.87+-0.08 at a mean lifetime around 20\nns. We confirm a log-normal distribution of decay rates as often assumed in\nliterature and we show that the rate distribution-width, that amounts to about\n30% of the mean decay rate, is strongly dependent on the local density of\noptical states. \n\n"}
{"id": "1308.1395", "contents": "Title: Bilayer graphene with parallel magnetic field and twisting: Phases and\n  phase transitions in a highly tunable Dirac system Abstract: The effective theory for bilayer graphene (BLG), subject to parallel/in-plane\nmagnetic fields, is derived. With a sizable magnetic field the trigonal warping\nbecomes irrelevant, and one ends up with two Dirac points in the vicinity of\neach valley in the low-energy limit, similar to the twisted BLG. Combining\ntwisting and parallel field thus gives rise to a Dirac system with tunable\nFermi velocity and cutoff. If the interactions are sufficiently strong, several\nfully gapped states can be realized in these systems, in addition to the ones\nin a pristine setup. Transformations of the order parameters under various\nsymmetry operations are analyzed. The quantum critical behavior of various\nphase transitions driven by the twisting and the magnetic field is reported.\nThe effects of an additional perpendicular fields, and possible ways to realize\nthe new massive phases is highlighted. \n\n"}
{"id": "1308.2694", "contents": "Title: A Super-Fast Distributed Algorithm for Bipartite Metric Facility\n  Location Abstract: The \\textit{facility location} problem consists of a set of\n\\textit{facilities} $\\mathcal{F}$, a set of \\textit{clients} $\\mathcal{C}$, an\n\\textit{opening cost} $f_i$ associated with each facility $x_i$, and a\n\\textit{connection cost} $D(x_i,y_j)$ between each facility $x_i$ and client\n$y_j$. The goal is to find a subset of facilities to \\textit{open}, and to\nconnect each client to an open facility, so as to minimize the total facility\nopening costs plus connection costs. This paper presents the first\nexpected-sub-logarithmic-round distributed O(1)-approximation algorithm in the\n$\\mathcal{CONGEST}$ model for the \\textit{metric} facility location problem on\nthe complete bipartite network with parts $\\mathcal{F}$ and $\\mathcal{C}$. Our\nalgorithm has an expected running time of $O((\\log \\log n)^3)$ rounds, where $n\n= |\\mathcal{F}| + |\\mathcal{C}|$. This result can be viewed as a continuation\nof our recent work (ICALP 2012) in which we presented the first\nsub-logarithmic-round distributed O(1)-approximation algorithm for metric\nfacility location on a \\textit{clique} network. The bipartite setting presents\nseveral new challenges not present in the problem on a clique network. We\npresent two new techniques to overcome these challenges. (i) In order to deal\nwith the problem of not being able to choose appropriate probabilities (due to\nlack of adequate knowledge), we design an algorithm that performs a random walk\nover a probability space and analyze the progress our algorithm makes as the\nrandom walk proceeds. (ii) In order to deal with a problem of quickly\ndisseminating a collection of messages, possibly containing many duplicates,\nover the bipartite network, we design a probabilistic hashing scheme that\ndelivers all of the messages in expected-$O(\\log \\log n)$ rounds. \n\n"}
{"id": "1308.3969", "contents": "Title: Topological superconducting phase in helical Shiba chains Abstract: Recently, it has been suggested that topological superconductivity and\nMajorana end states can be realized in a chain of magnetic impurities on the\nsurface of an s-wave superconductor when the magnetic moments form a spin helix\nas a result of the RKKY interaction mediated by the superconducting substrate.\nHere, we investigate this scenario theoretically by developing a tight-binding\nBogoliubov-de Gennes description starting from the Shiba bound states induced\nby the individual magnetic impurities. While the resulting model Hamiltonian\nhas similarities with the Kitaev model for one-dimensional spinless p-wave\nsuperconductors, there are also important differences, most notably the\nlong-range nature of hopping and pairing as well as the complex hopping\namplitudes. We use both analytical and numerical approaches to explore the\nconsequences of these differences for the phase diagram and the localization\nproperties of the Majorana end states when the Shiba chain is in a topological\nsuperconducting phase. \n\n"}
{"id": "1309.0186", "contents": "Title: A Solution to the Network Challenges of Data Recovery in Erasure-coded\n  Distributed Storage Systems: A Study on the Facebook Warehouse Cluster Abstract: Erasure codes, such as Reed-Solomon (RS) codes, are being increasingly\nemployed in data centers to combat the cost of reliably storing large amounts\nof data. Although these codes provide optimal storage efficiency, they require\nsignificantly high network and disk usage during recovery of missing data. In\nthis paper, we first present a study on the impact of recovery operations of\nerasure-coded data on the data-center network, based on measurements from\nFacebook's warehouse cluster in production. To the best of our knowledge, this\nis the first study of its kind available in the literature. Our study reveals\nthat recovery of RS-coded data results in a significant increase in network\ntraffic, more than a hundred terabytes per day, in a cluster storing multiple\npetabytes of RS-coded data.\n  To address this issue, we present a new storage code using our recently\nproposed \"Piggybacking\" framework, that reduces the network and disk usage\nduring recovery by 30% in theory, while also being storage optimal and\nsupporting arbitrary design parameters. The implementation of the proposed code\nin the Hadoop Distributed File System (HDFS) is underway. We use the\nmeasurements from the warehouse cluster to show that the proposed code would\nlead to a reduction of close to fifty terabytes of cross-rack traffic per day. \n\n"}
{"id": "1309.1488", "contents": "Title: Stellar granulation as seen in disk-integrated intensity. II.\n  Theoretical scaling relations compared with observations Abstract: A large set of stars observed by CoRoT and Kepler shows clear evidence for\nthe presence of a stellar background, which is interpreted to arise from\nsurface convection, i.e., granulation. These observations show that the\ncharacteristic time-scale (tau_eff) and the root-mean-square (rms) brightness\nfluctuations (sigma) associated with the granulation scale as a function of the\npeak frequency (nu_max) of the solar-like oscillations. We aim at providing a\ntheoretical background to the observed scaling relations based on a model\ndeveloped in the companion paper. We computed for each 3D model the theoretical\npower density spectrum (PDS) associated with the granulation as seen in\ndisk-integrated intensity on the basis of the theoretical model. For each PDS\nwe derived tau_eff and sigma and compared these theoretical values with the\ntheoretical scaling relations derived from the theoretical model and the Kepler\nmeasurements. We derive theoretical scaling relations for tau_eff and sigma,\nwhich show the same dependence on nu_max as the observed scaling relations. In\naddition, we show that these quantities also scale as a function of the\nturbulent Mach number (Ma) estimated at the photosphere. The theoretical\nscaling relations for tau_eff and sigma match the observations well on a global\nscale. Our modelling provides additional theoretical support for the observed\nvariations of sigma and tau_eff with nu_m max. It also highlights the important\nrole of Ma in controlling the properties of the stellar granulation. However,\nthe observations made with Kepler on a wide variety of stars cannot confirm the\ndependence of our scaling relations on Ma. Measurements of the granulation\nbackground and detections of solar-like oscillations in a statistically\nsufficient number of cool dwarf stars will be required for confirming the\ndependence of the theoretical scaling relations with Ma. \n\n"}
{"id": "1309.2019", "contents": "Title: Alfv\\'en waves in simulations of solar photospheric vortices Abstract: Using advanced numerical magneto-hydrodynamic simulations of the magnetised\nsolar photosphere, including non-grey radiative transport and a non-ideal\nequation of state, we analyse plasma motions in photospheric magnetic vortices.\nWe demonstrate that apparent vortex-like motions in photospheric magnetic field\nconcentrations do not exhibit \"tornado\"-like behaviour or a \"bath-tub\" effect.\nWhile at each time instance the velocity field lines in the upper layers of the\nsolar photosphere show swirls, the test particles moving with the\ntime-dependent velocity field do not demonstrate such structures. Instead, they\nmove in a wave-like fashion with rapidly changing and oscillating velocity\nfield, determined mainly by magnetic tension in the magnetised intergranular\ndownflows. Using time-distance diagrams, we identify horizontal motions in the\nmagnetic flux tubes as torsional Alfv\\'en perturbations propagating along the\nnearly vertical magnetic field lines with local Alfv\\'en speed. \n\n"}
{"id": "1309.2321", "contents": "Title: Photon Emission Rate Engineering using Graphene Nanodisc Cavities Abstract: In this work, we present a systematic study of the plasmon modes in a system\nof vertically stacked pair of graphene discs. Quasistatic approximation is used\nto model the eigenmodes of the system. Eigen-response theory is employed to\nexplain the spatial dependence of the coupling between the plasmon modes and a\nquantum emitter. These results show a good match between the semi-analytical\ncalculation and full-wave simulations. Secondly, we have shown that it is\npossible to engineer the decay rates of a quantum emitter placed inside and\nnear this cavity, using Fermi level tuning, via gate voltages and variation of\nemitter location and polarization. We highlighted that by coupling to the\nbright plasmon mode, the radiative efficiency of the emitter can be enhanced\ncompared to the single graphene disc case, whereas the dark plasmon mode\nsuppresses the radiative efficiency. \n\n"}
{"id": "1309.3783", "contents": "Title: SWIFT: Fast algorithms for multi-resolution SPH on multi-core\n  architectures Abstract: This paper describes a novel approach to neighbour-finding in Smoothed\nParticle Hydrodynamics (SPH) simulations with large dynamic range in smoothing\nlength. This approach is based on hierarchical cell decompositions, sorted\ninteractions, and a task-based formulation. It is shown to be faster than\ntraditional tree-based codes, and to scale better than domain\ndecomposition-based approaches on shared-memory parallel architectures such as\nmulti-cores. \n\n"}
{"id": "1309.6635", "contents": "Title: The Neutron Star Mass Distribution Abstract: In recent years, the number of pulsars with secure mass measurements has\nincreased to a level that allows us to probe the underlying neutron star (NS)\nmass distribution in detail. We critically review the radio pulsar mass\nmeasurements. For the first time, we are able to analyze a sizable population\nof NSs with a flexible modeling approach that can effectively accommodate a\nskewed underlying distribution and asymmetric measurement errors. We find that\nNSs that have evolved through different evolutionary paths reflect distinctive\nsignatures through dissimilar distribution peak and mass cutoff values. NSs in\ndouble neutron star and neutron star-white dwarf systems show consistent\nrespective peaks at 1.33 Msun and 1.55 Msun suggesting significant mass\naccretion (delta m~0.22 Msun) has occurred during the spin-up phase. The width\nof the mass distribution implied by double NS systems is indicative of a tight\ninitial mass function while the inferred mass range is significantly wider for\nNSs that have gone through recycling. We find a mass cutoff at ~2.1 Msun for\nNSs with white dwarf companions which establishes a firm lower bound for the\nmaximum NS mass. This rules out the majority of strange quark and soft equation\nof state models as viable configurations for NS matter. The lack of truncation\nclose to the maximum mass cutoff along with the skewed nature of the inferred\nmass distribution both enforce the suggestion that the 2.1 Msun limit is set by\nevolutionary constraints rather than nuclear physics or general relativity, and\nthe existence of rare super-massive NSs is possible. \n\n"}
{"id": "1310.1537", "contents": "Title: SIMD Parallel MCMC Sampling with Applications for Big-Data Bayesian\n  Analytics Abstract: Computational intensity and sequential nature of estimation techniques for\nBayesian methods in statistics and machine learning, combined with their\nincreasing applications for big data analytics, necessitate both the\nidentification of potential opportunities to parallelize techniques such as\nMCMC sampling, and the development of general strategies for mapping such\nparallel algorithms to modern CPUs in order to elicit the performance up the\ncompute-based and/or memory-based hardware limits. Two opportunities for\nSingle-Instruction Multiple-Data (SIMD) parallelization of MCMC sampling for\nprobabilistic graphical models are presented. In exchangeable models with many\nobservations such as Bayesian Generalized Linear Models, child-node\ncontributions to the conditional posterior of each node can be calculated\nconcurrently. In undirected graphs with discrete nodes, concurrent sampling of\nconditionally-independent nodes can be transformed into a SIMD form.\nHigh-performance libraries with multi-threading and vectorization capabilities\ncan be readily applied to such SIMD opportunities to gain decent speedup, while\na series of high-level source-code and runtime modifications provide further\nperformance boost by reducing parallelization overhead and increasing data\nlocality for NUMA architectures. For big-data Bayesian GLM graphs, the\nend-result is a routine for evaluating the conditional posterior and its\ngradient vector that is 5 times faster than a naive implementation using\n(built-in) multi-threaded Intel MKL BLAS, and reaches within the striking\ndistance of the memory-bandwidth-induced hardware limit. The proposed\noptimization strategies improve the scaling of performance with number of cores\nand width of vector units (applicable to many-core SIMD processors such as\nIntel Xeon Phi and GPUs), resulting in cost-effectiveness, energy efficiency,\nand higher speed on multi-core x86 processors. \n\n"}
{"id": "1310.2216", "contents": "Title: SPICA as a probe of cosmic reionization Abstract: Current data indicate that the reionization of the Universe was complete by\nredshift z~6-7, and while the sources responsible for this process have yet to\nbe identified, star-forming galaxies are often considered the most likely\ncandidates. However, the contribution from z>6 galaxies to cosmic reionization\ncritically depends on the fraction of ionizing (Lyman continuum, LyC) photons\nescaping from these objects and into the intergalactic medium. At z<4, the\nescaping LyC flux can be measured directly, but the opacity of the neutral\nintergalactic medium precludes such measurements at higher redshifts. In a\nrecent paper, we argue that since the LyC escape fraction regulates the\ncontribution of nebular emission to the rest-frame optical/UV spectra of\ngalaxies, the James Webb Space Telescope should be able to indirectly assess\nthe LyC escape fraction for galaxies at z~6-9. JWST can, on the other hand, not\nconstrain the fraction of LyC photons directly absorbed by dust, and this is\nwhere SPICA comes in. The dust continuum emission from gravitationally lensed\nLyC-leakers at z=6 may in principle be detectable with SPICA, thereby\nconstraining the level of LyC extinction in these objects. \n\n"}
{"id": "1310.3107", "contents": "Title: SwiftCloud: Fault-Tolerant Geo-Replication Integrated all the Way to the\n  Client Machine Abstract: Client-side logic and storage are increasingly used in web and mobile\napplications to improve response time and availability. Current approaches tend\nto be ad-hoc and poorly integrated with the server-side logic. We present a\nprincipled approach to integrate client- and server-side storage. We support\nmergeable and strongly consistent transactions that target either client or\nserver replicas and provide access to causally-consistent snapshots\nefficiently. In the presence of infrastructure faults, a client-assisted\nfailover solution allows client execution to resume immediately and seamlessly\naccess consistent snapshots without waiting. We implement this approach in\nSwiftCloud, the first transactional system to bring geo-replication all the way\nto the client machine. Example applications show that our programming model is\nuseful across a range of application areas. Our experimental evaluation shows\nthat SwiftCloud provides better fault tolerance and at the same time can\nimprove both latency and throughput by up to an order of magnitude, compared to\nclassical geo-replication techniques. \n\n"}
{"id": "1310.4503", "contents": "Title: Stellar Spin-Orbit Misalignment in a Multiplanet System Abstract: Stars hosting hot Jupiters are often observed to have high obliquities,\nwhereas stars with multiple co-planar planets have been seen to have low\nobliquities. This has been interpreted as evidence that hot-Jupiter formation\nis linked to dynamical disruption, as opposed to planet migration through a\nprotoplanetary disk. We used asteroseismology to measure a large obliquity for\nKepler-56, a red giant star hosting two transiting co-planar planets. These\nobservations show that spin-orbit misalignments are not confined to hot-Jupiter\nsystems. Misalignments in a broader class of systems had been predicted as a\nconsequence of torques from wide-orbiting companions, and indeed\nradial-velocity measurements revealed a third companion in a wide orbit in the\nKepler-56 system. \n\n"}
{"id": "1310.4907", "contents": "Title: Message and time efficient multi-broadcast schemes Abstract: We consider message and time efficient broadcasting and multi-broadcasting in\nwireless ad-hoc networks, where a subset of nodes, each with a unique rumor,\nwish to broadcast their rumors to all destinations while minimizing the total\nnumber of transmissions and total time until all rumors arrive to their\ndestination. Under centralized settings, we introduce a novel approximation\nalgorithm that provides almost optimal results with respect to the number of\ntransmissions and total time, separately. Later on, we show how to efficiently\nimplement this algorithm under distributed settings, where the nodes have only\nlocal information about their surroundings. In addition, we show multiple\napproximation techniques based on the network collision detection capabilities\nand explain how to calibrate the algorithms' parameters to produce optimal\nresults for time and messages. \n\n"}
{"id": "1310.5182", "contents": "Title: Massively parallel approximate Gaussian process regression Abstract: We explore how the big-three computing paradigms -- symmetric multi-processor\n(SMC), graphical processing units (GPUs), and cluster computing -- can together\nbe brought to bare on large-data Gaussian processes (GP) regression problems\nvia a careful implementation of a newly developed local approximation scheme.\nOur methodological contribution focuses primarily on GPU computation, as this\nrequires the most care and also provides the largest performance boost.\nHowever, in our empirical work we study the relative merits of all three\nparadigms to determine how best to combine them. The paper concludes with two\ncase studies. One is a real data fluid-dynamics computer experiment which\nbenefits from the local nature of our approximation; the second is a synthetic\ndata example designed to find the largest design for which (accurate) GP\nemulation can performed on a commensurate predictive set under an hour. \n\n"}
{"id": "1310.5276", "contents": "Title: Bidirectional and efficient conversion between microwave and optical\n  light Abstract: Converting low-frequency electrical signals into much higher frequency\noptical signals has enabled modern communications networks to leverage both the\nstrengths of microfabricated electrical circuits and optical fiber\ntransmission, allowing information networks to grow in size and complexity. A\nmicrowave-to-optical converter in a quantum information network could provide\nsimilar gains by linking quantum processors via low-loss optical fibers and\nenabling a large-scale quantum network. However, no current technology can\nconvert low-frequency microwave signals into high-frequency optical signals\nwhile preserving their fragile quantum state. For this demanding application, a\nconverter must provide a near-unitary transformation between different\nfrequencies; that is, the ideal transformation is reversible, coherent, and\nlossless. Here we demonstrate a converter that reversibly, coherently, and\nefficiently links the microwave and optical portions of the electromagnetic\nspectrum. We use our converter to transfer classical signals between microwave\nand optical light with conversion efficiencies of ~10%, and achieve performance\nsufficient to transfer quantum states if the device were further precooled from\nits current 4 kelvin operating temperature to below 40 millikelvin. The\nconverter uses a mechanically compliant membrane to interface optical light\nwith superconducting microwave circuitry, and this unique combination of\ntechnologies may provide a way to link distant nodes of a quantum information\nnetwork. \n\n"}
{"id": "1310.6309", "contents": "Title: NoSOCS in SDSS. IV. The Role of Environment Beyond the Extent of Galaxy\n  Clusters Abstract: We are able to extend the investigation of the\ncolor-morphology-density-radius relations, for bright and faint galaxies, to $R\n\\gtrsim 3 \\times R_{200}$ and to very low density regions, probing the\ntransition region between cluster and field galaxies, and finding a smooth\nvariation between these two populations. We investigate the environmental\nvariation of galaxy properties (and their relations), such as color, spectral\ntype and concentration. Our sample comprises 6,415 galaxies that were\npreviously selected as cluster members from 152 systems with $z \\le 0.100$. Our\nmain findings are: (i) The fraction of discs is generally higher than the ones\nfor blue and star-forming galaxies, indicating a faster transformation of color\nand star-formation compared to structural parameters. (ii) Regarding the\ndistance to the cluster center we find a small variation in the galaxy\npopulations outside the virial radius. Once within that radius the fractions of\neach population change fast, decreasing even faster within $R \\sim 0.3 \\times\nR_{200}$. (iii) We also find a small increase in the fraction of blue faint\ngalaxies within $R \\sim 0.4 \\times R_{200}$, before decreasing again to the\nmost central bin. (iv) Our results do not indicate a significant dependence on\ncluster mass, except for the disc fraction in the core of clusters. (v) The\nrelations between galaxy properties also point to no dependence on cluster\nmass, except for the scatter of the color stellar mass relation. Our results\ncorroborate a scenario on which pre-processing in groups leads to a strong\nevolution in galaxy properties, before they are accreted by large clusters\n(abridged). \n\n"}
{"id": "1310.6542", "contents": "Title: SensorCloud: Towards the Interdisciplinary Development of a Trustworthy\n  Platform for Globally Interconnected Sensors and Actuators Abstract: Although Cloud Computing promises to lower IT costs and increase users'\nproductivity in everyday life, the unattractive aspect of this new technology\nis that the user no longer owns all the devices which process personal data. To\nlower scepticism, the project SensorCloud investigates techniques to understand\nand compensate these adoption barriers in a scenario consisting of cloud\napplications that utilize sensors and actuators placed in private places. This\nwork provides an interdisciplinary overview of the social and technical core\nresearch challenges for the trustworthy integration of sensor and actuator\ndevices with the Cloud Computing paradigm. Most importantly, these challenges\ninclude i) ease of development, ii) security and privacy, and iii) social\ndimensions of a cloud-based system which integrates into private life. When\nthese challenges are tackled in the development of future cloud systems, the\nattractiveness of new use cases in a sensor-enabled world will considerably be\nincreased for users who currently do not trust the Cloud. \n\n"}
{"id": "1310.7946", "contents": "Title: Measuring topological invariants in photonic systems Abstract: Motivated by the recent theoretical and experimental progress in implementing\ntopological orders with photons, we analyze photonic systems with different\ntopologies and present a scheme to probe their topological features.\nSpecifically, we propose a scheme to modify the boundary phases to manipulate\nedge state dynamics. Such a scheme allows one to measure the winding number of\nthe edge states. Furthermore, we discuss the effect of loss and disorder on the\nvalidity of our approach. \n\n"}
{"id": "1310.8230", "contents": "Title: Cosmic Rays from Heavy Dark Matter from the Galactic Center Abstract: The gamma-ray fluxes observed by the High Energy Stereoscopic System (HESS)\nfrom the J1745-290 Galactic Center source is well fitted by the secondary\nphotons coming from Dark Matter (DM) annihilation in particle-antiparticle\nstandard model pairs over a diffuse power-law background. The spectral features\nof the signal are consistent with different channels: light quarks,\nelectro-weak gauge bosons and top-antitop production. The amount of photons and\nmorphology of the signal localized within a region of few parsecs, require\ncompressed DM profiles as those resulting from baryonic contraction, which\noffer large enhancements in the signal over DM alone simulations. The fits\nreturn a heavy WIMP, with a mass above 10 TeV, but well below the unitarity\nlimit for thermal relic annihilation. The fitted background spectral index is\ncompatible with the Fermi-Large Area Telescope (LAT) data from the same region.\nThis possibility can be potentially tested with the observations of other high\nenergy cosmic rays. \n\n"}
{"id": "1311.2851", "contents": "Title: When Do Redundant Requests Reduce Latency ? Abstract: Several systems possess the flexibility to serve requests in more than one\nway. For instance, a distributed storage system storing multiple replicas of\nthe data can serve a request from any of the multiple servers that store the\nrequested data, or a computational task may be performed in a compute-cluster\nby any one of multiple processors. In such systems, the latency of serving the\nrequests may potentially be reduced by sending \"redundant requests\": a request\nmay be sent to more servers than needed, and it is deemed served when the\nrequisite number of servers complete service. Such a mechanism trades off the\npossibility of faster execution of at least one copy of the request with the\nincrease in the delay due to an increased load on the system. Due to this\ntradeoff, it is unclear when redundant requests may actually help. Several\nrecent works empirically evaluate the latency performance of redundant requests\nin diverse settings.\n  This work aims at an analytical study of the latency performance of redundant\nrequests, with the primary goals of characterizing under what scenarios sending\nredundant requests will help (and under what scenarios they will not help), as\nwell as designing optimal redundant-requesting policies. We first present a\nmodel that captures the key features of such systems. We show that when service\ntimes are i.i.d. memoryless or \"heavier\", and when the additional copies of\nalready-completed jobs can be removed instantly, redundant requests reduce the\naverage latency. On the other hand, when service times are \"lighter\" or when\nservice times are memoryless and removal of jobs is not instantaneous, then not\nhaving any redundancy in the requests is optimal under high loads. Our results\nhold for arbitrary arrival processes. \n\n"}
{"id": "1311.4150", "contents": "Title: Towards Big Topic Modeling Abstract: To solve the big topic modeling problem, we need to reduce both time and\nspace complexities of batch latent Dirichlet allocation (LDA) algorithms.\nAlthough parallel LDA algorithms on the multi-processor architecture have low\ntime and space complexities, their communication costs among processors often\nscale linearly with the vocabulary size and the number of topics, leading to a\nserious scalability problem. To reduce the communication complexity among\nprocessors for a better scalability, we propose a novel communication-efficient\nparallel topic modeling architecture based on power law, which consumes orders\nof magnitude less communication time when the number of topics is large. We\ncombine the proposed communication-efficient parallel architecture with the\nonline belief propagation (OBP) algorithm referred to as POBP for big topic\nmodeling tasks. Extensive empirical results confirm that POBP has the following\nadvantages to solve the big topic modeling problem: 1) high accuracy, 2)\ncommunication-efficient, 3) fast speed, and 4) constant memory usage when\ncompared with recent state-of-the-art parallel LDA algorithms on the\nmulti-processor architecture. \n\n"}
{"id": "1311.5904", "contents": "Title: The IceProd Framework: Distributed Data Processing for the IceCube\n  Neutrino Observatory Abstract: IceCube is a one-gigaton instrument located at the geographic South Pole,\ndesigned to detect cosmic neutrinos, iden- tify the particle nature of dark\nmatter, and study high-energy neutrinos themselves. Simulation of the IceCube\ndetector and processing of data require a significant amount of computational\nresources. IceProd is a distributed management system based on Python, XML-RPC\nand GridFTP. It is driven by a central database in order to coordinate and\nadmin- ister production of simulations and processing of data produced by the\nIceCube detector. IceProd runs as a separate layer on top of other middleware\nand can take advantage of a variety of computing resources, including grids and\nbatch systems such as CREAM, Condor, and PBS. This is accomplished by a set of\ndedicated daemons that process job submission in a coordinated fashion through\nthe use of middleware plugins that serve to abstract the details of job\nsubmission and job management from the framework. \n\n"}
{"id": "1311.7095", "contents": "Title: Optomechanical Metamaterials: Dirac polaritons, Gauge fields, and\n  Instabilities Abstract: Freestanding photonic crystals can be used to trap both light and mechanical\nvibrations. These \"optomechanical crystal\" structures have already been\nexperimentally demonstrated to yield strong coupling between a photon mode and\na phonon mode, co-localized at a single defect site. Future devices may feature\na regular superlattice of such defects, turning them into \"optomechanical\narrays\". In this letter we predict that tailoring the optomechanical band\nstructure of such arrays can be used to implement Dirac physics of photons and\nphonons, to create a photonic gauge field via mechanical vibrations, and to\nobserve a novel optomechanical instability. \n\n"}
{"id": "1312.1319", "contents": "Title: Implementing generalized measurements with superconducting qubits Abstract: We describe a method to perform any generalized purity-preserving measurement\nof a qubit with techniques tailored to superconducting systems. First, we\nconsider two methods for realizing a two-outcome partial projection: using a\nthresholded continuous measurement in the circuit QED setup, or using an\nindirect ancilla qubit measurement. Second, we decompose an arbitrary\npurity-preserving two-outcome measurement into single qubit unitary rotations\nand a partial projection. Third, we systematically reduce any multiple-outcome\nmeasurement to a sequence of such two-outcome measurements and unitary\noperations. Finally, we consider how to define suitable fidelity measures for\nmultiple-outcome generalized measurements. \n\n"}
{"id": "1312.2454", "contents": "Title: Broadband nanoelectromechanical phase shifting of light on a chip Abstract: We demonstrate an optomechanical phase shifter. By electrostatically\ndeflecting the nanofabricated mechanical structure, the effective index of a\nnearby waveguide is changed and the resulting phase shift is measured using an\nintegrated Mach-Zehnder interferometer. Comparing to thermo-optical phase\nshifters, our device does not consume power in static operation and also it can\noperate over large frequency, wavelength, and power ranges. Operation in the\nMHz range and sub-$\\mu$s pulses are demonstrated. \n\n"}
{"id": "1312.4196", "contents": "Title: A detailed balanced reaction network is sufficient but not necessary for\n  its Markov chain to be detailed balanced Abstract: Certain chemical reaction networks (CRNs) when modeled as a deterministic\ndynamical system taken with mass-action kinetics have the property of reaction\nnetwork detailed balance (RNDB) which is achieved by imposing network-related\nconstraints on the reaction rate constants. Markov chains (whether arising as\nmodels of CRNs or otherwise) have their own notion of detailed balance, imposed\nby the network structure of the graph of the transition matrix of the Markov\nchain. When considering Markov chains arising from chemical reaction networks\nwith mass-action kinetics, we will refer to this property as Markov chain\ndetailed balance (MCDB). Finally, we refer to the stochastic analog of RNDB as\nWhittle stochastic detailed balance (WSDB). It is known that RNDB and WSDB are\nequivalent. We prove that WSDB and MCDB are also intimately related but are not\nequivalent. While RNDB implies MCDB, the converse is not true. The conditions\non rate constants that result in networks with MCDB but without RNDB are\nstringent, and thus examples of this phenomenon are rare, a notable exception\nis a network whose Markov chain is a birth and death process. We give a new\nalgorithm to find conditions on the rate constants that are required for MCDB. \n\n"}
{"id": "1312.4867", "contents": "Title: Detection of weak stochastic force in a parametrically stabilized micro\n  opto-mechanical system Abstract: Measuring a weak force is an important task for micro-mechanical systems,\nboth when using devices as sensitive detectors and, particularly, in\nexperiments of quantum mechanics. The optimal strategy for resolving a weak\nstochastic signal force on a huge background (typically given by thermal noise)\nis a crucial and debated topic, and the stability of the mechanical resonance\nis a further, related critical issue. We introduce and analyze the parametric\ncontrol of the optical spring, that allows to stabilize the resonance and\nprovides a phase reference for the oscillator motion, yet conserving a free\nevolution in one quadrature of the phase space. We also study quantitatively\nthe characteristics of our micro opto-mechanical system as detector of\nstochastic force for short measurement times (for quick, high resolution\nmonitoring) as well as for the longer term observations that optimize the\nsensitivity. We compare a simple, naive strategy based on the evaluation of the\nvariance of the displacement (that is a widely used technique) with an optimal\nWiener-Kolmogorov data analysis. We show that, thanks to the parametric\nstabilization of the effective susceptibility, we can more efficiently\nimplement Wiener filtering, and we investigate how this strategy improves the\nperformance of our system. We finally demonstrate the possibility to resolve\nstochastic force variations well below 1% of the thermal noise. \n\n"}
{"id": "1401.1639", "contents": "Title: Optimal consumption and portfolio choice with ambiguity Abstract: We consider optimal consumption and portfolio choice in the presence of\nKnightian uncertainty in continuous-time. We embed the problem into the new\nframework of stochastic calculus for such settings, dealing in particular with\nthe issue of non-equivalent multiple priors. We solve the problem completely by\nidentifying the worst--case measure. Our setup also allows to consider interest\nrate uncertainty; we show that under some robust parameter constellations, the\ninvestor optimally puts all his wealth into the asset market, and does not save\nor borrow at all. \n\n"}
{"id": "1401.4082", "contents": "Title: Stochastic Backpropagation and Approximate Inference in Deep Generative\n  Models Abstract: We marry ideas from deep neural networks and approximate Bayesian inference\nto derive a generalised class of deep, directed generative models, endowed with\na new algorithm for scalable inference and learning. Our algorithm introduces a\nrecognition model to represent approximate posterior distributions, and that\nacts as a stochastic encoder of the data. We develop stochastic\nback-propagation -- rules for back-propagation through stochastic variables --\nand use this to develop an algorithm that allows for joint optimisation of the\nparameters of both the generative and recognition model. We demonstrate on\nseveral real-world data sets that the model generates realistic samples,\nprovides accurate imputations of missing data and is a useful tool for\nhigh-dimensional data visualisation. \n\n"}
{"id": "1401.6014", "contents": "Title: Exponential stability of nonhomogeneous matrix-valued Markovian chains Abstract: In this paper, we characterize the stability of matrix-valued Markovian\nchains by periodic data. \n\n"}
{"id": "1401.6145", "contents": "Title: On Stochastic Geometry Modeling of Cellular Uplink Transmission with\n  Truncated Channel Inversion Power Control Abstract: Using stochastic geometry, we develop a tractable uplink modeling paradigm\nfor outage probability and spectral efficiency in both single and multi-tier\ncellular wireless networks. The analysis accounts for per user equipment (UE)\npower control as well as the maximum power limitations for UEs. More\nspecifically, for interference mitigation and robust uplink communication, each\nUE is required to control its transmit power such that the average received\nsignal power at its serving base station (BS) is equal to a certain threshold\n$\\rho_o$. Due to the limited transmit power, the UEs employ a truncated channel\ninversion power control policy with a cutoff threshold of $\\rho_o$. We show\nthat there exists a transfer point in the uplink system performance that\ndepends on the tuple: BS intensity ($\\lambda$), maximum transmit power of UEs\n($P_u$), and $\\rho_o$. That is, when $P_u$ is a tight operational constraint\nwith respect to [w.r.t.] $\\lambda$ and $\\rho_o$, the uplink outage probability\nand spectral efficiency highly depend on the values of $\\lambda$ and $\\rho_o$.\nIn this case, there exists an optimal cutoff threshold $\\rho^*_o$, which\ndepends on the system parameters, that minimizes the outage probability. On the\nother hand, when $P_u$ is not a binding operational constraint w.r.t. $\\lambda$\nand $\\rho_o$, the uplink outage probability and spectral efficiency become\nindependent of $\\lambda$ and $\\rho_o$. We obtain approximate yet accurate\nsimple expressions for outage probability and spectral efficiency which reduce\nto closed-forms in some special cases. \n\n"}
{"id": "1402.0125", "contents": "Title: Automated Classification of Periodic Variable Stars detected by the\n  Wide-field Infrared Survey Explorer Abstract: We describe a methodology to classify periodic variable stars identified\nusing photometric time-series measurements constructed from the Wide-field\nInfrared Survey Explorer (WISE) full-mission single-exposure Source Databases.\nThis will assist in the future construction of a WISE Variable Source Database\nthat assigns variables to specific science classes as constrained by the WISE\nobserving cadence with statistically meaningful classification probabilities.\nWe have analyzed the WISE light curves of 8273 variable stars identified in\nprevious optical variability surveys (MACHO, GCVS, and ASAS) and show that\nFourier decomposition techniques can be extended into the mid-IR to assist with\ntheir classification. Combined with other periodic light-curve features, this\nsample is then used to train a machine-learned classifier based on the random\nforest (RF) method. Consistent with previous classification studies of variable\nstars in general, the RF machine-learned classifier is superior to other\nmethods in terms of accuracy, robustness against outliers, and relative\nimmunity to features that carry little or redundant class information. For the\nthree most common classes identified by WISE: Algols, RR Lyrae, and W Ursae\nMajoris type variables, we obtain classification efficiencies of 80.7%, 82.7%,\nand 84.5% respectively using cross-validation analyses, with 95% confidence\nintervals of approximately +/-2%. These accuracies are achieved at purity (or\nreliability) levels of 88.5%, 96.2%, and 87.8% respectively, similar to that\nachieved in previous automated classification studies of periodic variable\nstars. \n\n"}
{"id": "1402.1325", "contents": "Title: Synchronized Switching in a Josephson Junction Crystal Abstract: We consider a superconducting coplanar waveguide resonator where the central\nconductor is interrupted by a series of uniformly spaced Josephson junctions.\nThe device forms an extended medium that is optically nonlinear on the single\nphoton level with normal modes that inherit the full nonlinearity of the\njunctions but are nonetheless accessible via the resonator ports. For specific\nplasma frequencies of the junctions a set of normal modes clusters in a narrow\nband and eventually become entirely degenerate. Upon increasing the intensity\nof a red detuned drive on these modes, we observe a sharp and synchronized\nswitching from low occupation quantum states to high occupation classical\nfields, accompanied by a pronounced jump from low to high output intensity. \n\n"}
{"id": "1402.1515", "contents": "Title: Dictionary Learning over Distributed Models Abstract: In this paper, we consider learning dictionary models over a network of\nagents, where each agent is only in charge of a portion of the dictionary\nelements. This formulation is relevant in Big Data scenarios where large\ndictionary models may be spread over different spatial locations and it is not\nfeasible to aggregate all dictionaries in one location due to communication and\nprivacy considerations. We first show that the dual function of the inference\nproblem is an aggregation of individual cost functions associated with\ndifferent agents, which can then be minimized efficiently by means of diffusion\nstrategies. The collaborative inference step generates dual variables that are\nused by the agents to update their dictionaries without the need to share these\ndictionaries or even the coefficient models for the training data. This is a\npowerful property that leads to an effective distributed procedure for learning\ndictionaries over large networks (e.g., hundreds of agents in our experiments).\nFurthermore, the proposed learning strategy operates in an online manner and is\nable to respond to streaming data, where each data sample is presented to the\nnetwork once. \n\n"}
{"id": "1402.1761", "contents": "Title: On Scalability of Wireless Networks: A Practical Primer for Large Scale\n  Cooperation Abstract: An intuitive overview of the scalability of a variety of types of wireless\nnetworks is presented. Simple heuris- tic arguments are demonstrated here for\nscaling laws presented in other works, as well as for conditions not previously\nconsidered in the literature. Unicast and multicast messages, topology,\nhierarchy, and effects of reliability protocols are discussed. We show how two\nkey factors, bottlenecks and erasures, can often domi- nate the network scaling\nbehavior. Scaling of through- put or delay with the number of transmitting\nnodes, the number of receiving nodes, and the file size is described. \n\n"}
{"id": "1402.2368", "contents": "Title: Gate-tunable coherent perfect absorption of terahertz radiation in\n  graphene Abstract: Perfect absorption of radiation in a graphene sheet may play a pivotal role\nin the realization of technologically relevant optoelectronic devices. In\nparticular, perfect absorption of radiation in the terahertz (THz) spectral\nrange would tremendously boost the utility of graphene in this difficult range\nof photon energies, which still lacks cheap and robust devices operating at\nroom temperature. In this work we show that unpatterned graphene flakes\ndeposited on appropriate substrates can display gate-tunable coherent perfect\nabsorption (CPA) in the THz spectral range. We present theoretical estimates\nfor the CPA operating frequency as a function of doping, which take into\naccount the presence of common sources of disorder in graphene samples. \n\n"}
{"id": "1402.2549", "contents": "Title: Local Approximability of Minimum Dominating Set on Planar Graphs Abstract: We show that there is no deterministic local algorithm (constant-time\ndistributed graph algorithm) that finds a $(7-\\epsilon)$-approximation of a\nminimum dominating set on planar graphs, for any positive constant $\\epsilon$.\nIn prior work, the best lower bound on the approximation ratio has been\n$5-\\epsilon$; there is also an upper bound of $52$. \n\n"}
{"id": "1402.3551", "contents": "Title: Milky Way rotation curve from proper motions of red clump giants Abstract: We derive the stellar rotation curve of the Galaxy in the range of\nGalactocentric radii of R=4-16 kpc at different vertical heights from the\nGalactic plane of z between -2 and +2 kpc. We used the PPMXL survey, which\ncontains the USNO-B1 proper motions catalog cross-correlated with the\nastrometry and near-infrared photometry of the 2MASS Point Source Catalog. To\nimprove the accuracy of the proper motions, we calculated the average proper\nmotions of quasars to know their systematic shift from zero in this PPMXL\nsurvey, and we applied the corresponding correction to the proper motions of\nthe whole survey, which reduces the systematic error. We selected from the CM\ndiagram K vs. (J-K) the red clump giants and used the information of their\nproper motions to build a map of the rotation speed of our Galaxy.\n  We obtain an almost flat rotation curve with a slight decrease for higher\nvalues of R or |z|. The most puzzling result is obtained for the farthest\nremoved and most off-plane regions, where a significant deviation from a null\naverage proper motion (~4 mas/yr) in the Galactic longitude direction for the\nanticenter regions can be directly translated into a rotation speed much lower\nthan in the solar Galactocentric radius: an average speed of\n82+/-5(stat.)+/-58(syst.) km/s. A scenario with a rotation speed lower than 150\nkm/s in these regions of our explored zone is intriguing, and invites one to\nreconsider different possibilities for the dark matter distribution. However,\ngiven the high systematic errors, we cannot conclude about this. Hence, more\nmeasurements of the proper motions at high R and |z| are necessary to validate\nthe exotic scenario that would arise if this low speed were confirmed. \n\n"}
{"id": "1402.4475", "contents": "Title: Strong Coupling in Hyperbolic Metamaterials Abstract: Nanoscale light-matter interaction in the weak-coupling regime has been\nachieved with unique hyperbolic metamaterial modes possessing a high density of\nstates. Here, we show strong coupling between intersubband transitions (ISBTs)\nof a multiple quantum well (MQW) slab and the bulk polariton modes of a\nhyperbolic metamaterial (HMM). These HMM modes have large wave vectors (high-k\nmodes) and are normally evanescent in conventional materials. We analyze a\nmetal-dielectric practical multilayer HMM structure consisting of a highly\ndoped semiconductor acting as a metallic layer and an active multiple quantum\nwell dielectric slab. We observe delocalized metamaterial mode interaction with\nthe active materials distributed throughout the structure. Strong coupling and\ncharacteristic anticrossing with a maximum Rabi splitting (RS) energy of up to\n52 meV is predicted between the high-k mode of the HMMand the ISBT, a value\napproximately 10.5 times greater than the ISBT linewidth and 4.5 times greater\nthan the material loss of the structure. The scalability and tunability of the\nRS energy in an active semiconductor metamaterial device have potential\napplications in quantum well infrared photodetectors and intersubband\nlight-emitting devices. \n\n"}
{"id": "1402.6964", "contents": "Title: Scalable methods for nonnegative matrix factorizations of near-separable\n  tall-and-skinny matrices Abstract: Numerous algorithms are used for nonnegative matrix factorization under the\nassumption that the matrix is nearly separable. In this paper, we show how to\nmake these algorithms efficient for data matrices that have many more rows than\ncolumns, so-called \"tall-and-skinny matrices\". One key component to these\nimproved methods is an orthogonal matrix transformation that preserves the\nseparability of the NMF problem. Our final methods need a single pass over the\ndata matrix and are suitable for streaming, multi-core, and MapReduce\narchitectures. We demonstrate the efficacy of these algorithms on\nterabyte-sized synthetic matrices and real-world matrices from scientific\ncomputing and bioinformatics. \n\n"}
{"id": "1402.7254", "contents": "Title: Generalizations of the distributed Deutsch-Jozsa promise problem Abstract: In the {\\em distributed Deutsch-Jozsa promise problem}, two parties are to\ndetermine whether their respective strings $x,y\\in\\{0,1\\}^n$ are at the {\\em\nHamming distance} $H(x,y)=0$ or $H(x,y)=\\frac{n}{2}$. Buhrman et al. (STOC' 98)\nproved that the exact {\\em quantum communication complexity} of this problem is\n${\\bf O}(\\log {n})$ while the {\\em deterministic communication complexity} is\n${\\bf \\Omega}(n)$. This was the first impressive (exponential) gap between\nquantum and classical communication complexity.\n  In this paper, we generalize the above distributed Deutsch-Jozsa promise\nproblem to determine, for any fixed $\\frac{n}{2}\\leq k\\leq n$, whether\n$H(x,y)=0$ or $H(x,y)= k$, and show that an exponential gap between exact\nquantum and deterministic communication complexity still holds if $k$ is an\neven such that $\\frac{1}{2}n\\leq k<(1-\\lambda) n$, where $0<\n\\lambda<\\frac{1}{2}$ is given. We also deal with a promise version of the\nwell-known {\\em disjointness} problem and show also that for this promise\nproblem there exists an exponential gap between quantum (and also\nprobabilistic) communication complexity and deterministic communication\ncomplexity of the promise version of such a disjointness problem. Finally, some\napplications to quantum, probabilistic and deterministic finite automata of the\nresults obtained are demonstrated. \n\n"}
{"id": "1403.0124", "contents": "Title: An Ising-Glauber Spin Cluster Model for Temperature Dependent\n  Magnetization Noise in SQUIDs Abstract: Clusters of interacting two-level-systems (TLS),likely due to $F^+$ centers\nat the metal-insulator interface, are shown to self consistently lead to\n$1/f^{\\alpha }$ magnetization noise in SQUIDs. By introducing a\ncorrelation-function calculation method and without any a priori assumptions on\nthe distribution of fluctuation rates, it is shown why the flux noise is only\nweakly temperature dependent with $\\alpha\\lesssim 1$, while the inductance\nnoise has a huge temperature dependence seen in experiment, even though the\nmechanism producing both spectra is the same. Though both ferromagnetic- RKKY\nand short-range-interactions (SRI) lead to strong flux-inductance-noise\ncross-correlations seen in experiment, the flux noise varies a lot with\ntemperature for SRI. Hence it is unlikely that the TLS's time reversal symmetry\nis broken by the same mechanism which mediates surface ferromagnetism in\nnanoparticles and thin films of the same insulator materials. \n\n"}
{"id": "1403.3337", "contents": "Title: Bulk transport through superconducting hybrid structures in HgTe quantum\n  wells Abstract: We investigate the subgap bulk transport through short and wide\nsuperconducting hybrid structures based on HgTe quantum wells (QWs). We show\nthat the differential conductance of a normal metal-insulator-superconductor\n(NIS) proximity structure behaves in a qualitatively different way with respect\nto the topological phase of the HgTe QW. We compare the differential\nconductance for the NIS structure within the wave-matching method based on the\nBogoliubov-de Gennes equation and the matrix method based on the normal-state\nscattering matrix and find that the two models agree for highly-doped N and S\ncontacts. We also show that the effect of a possible Rashba spin-orbit\ninteraction on the differential conductance can be significant for weakly doped\nN and S contacts. Our findings should be important in samples with a large\naspect ratio where bulk contributions in transport are dominant. \n\n"}
{"id": "1403.4308", "contents": "Title: Deep Broadband Observations of the Distant Gamma-ray Blazar PKS 1424+240 Abstract: We present deep VERITAS observations of the blazar PKS 1424+240, along with\ncontemporaneous Fermi Large Area Telescope, Swift X-ray Telescope and Swift UV\nOptical Telescope data between 2009 February 19 and 2013 June 8. This blazar\nresides at a redshift of $z\\ge0.6035$, displaying a significantly attenuated\ngamma-ray flux above 100 GeV due to photon absorption via pair-production with\nthe extragalactic background light. We present more than 100 hours of VERITAS\nobservations from three years, a multiwavelength light curve and the\ncontemporaneous spectral energy distributions. The source shows a higher flux\nof (2.1$\\pm0.3$)$\\times10^{-7}$ ph m$^{-2}$s$^{-1}$ above 120 GeV in 2009 and\n2011 as compared to the flux measured in 2013, corresponding to\n(1.02$\\pm0.08$)$\\times10^{-7}$ ph m$^{-2}$s$^{-1}$ above 120 GeV. The measured\ndifferential very high energy (VHE; $E\\ge100$ GeV) spectral indices are\n$\\Gamma=$3.8$\\pm$0.3, 4.3$\\pm$0.6 and 4.5$\\pm$0.2 in 2009, 2011 and 2013,\nrespectively. No significant spectral change across the observation epochs is\ndetected. We find no evidence for variability at gamma-ray opacities of greater\nthan $\\tau=2$, where it is postulated that any variability would be small and\noccur on longer than year timescales if hadronic cosmic-ray interactions with\nextragalactic photon fields provide a secondary VHE photon flux. The data\ncannot rule out such variability due to low statistics. \n\n"}
{"id": "1403.4318", "contents": "Title: Cosmological model of the interaction between dark matter and dark\n  energy Abstract: In this paper, we test the dark matter-dark energy interacting cosmological\nmodel with a dynamic equation of state $w_{DE}(z)=w_{0}+w_{1}z/(1+z)$, using\ntype Ia supernovae (SNe Ia), Hubble parameter data, baryonic acoustic\noscillation (BAO) measurements, and the cosmic microwave background (CMB)\nobservation. This interacting cosmological model has not been studied before.\nThe best-fitted parameters with $1 \\sigma$ uncertainties are $\\delta=-0.022 \\pm\n0.006$, $\\Omega_{DM}^{0}=0.213 \\pm 0.008$, $w_0 =-1.210 \\pm 0.033$ and\n$w_1=0.872 \\pm 0.072$ with $\\chi^2_{min}/dof = 0.990$. At the $1 \\sigma$\nconfidence level, we find $\\delta<0$, which means that the energy transfer\nprefers from dark matter to dark energy. We also find that the SNe Ia are in\ntension with the combination of CMB, BAO and Hubble parameter data. The\nevolution of $\\rho_{DM}/\\rho_{DE}$ indicates that this interacting model is a\ngood approach to solve the coincidence problem, because the $\\rho_{DE}$\ndecrease with scale factor $a$. The transition redshift is $z_{tr}=0.63 \\pm\n0.07$ in this model. \n\n"}
{"id": "1403.5007", "contents": "Title: On Throughput-Delay Optimal Access to Storage Clouds via Load Adaptive\n  Coding and Chunking Abstract: Recent literature including our past work provide analysis and solutions for\nusing (i) erasure coding, (ii) parallelism, or (iii) variable slicing/chunking\n(i.e., dividing an object of a specific size into a variable number of smaller\nchunks) in speeding the I/O performance of storage clouds. However, a\ncomprehensive approach that considers all three dimensions together to achieve\nthe best throughput-delay trade-off curve had been lacking. This paper presents\nthe first set of solutions that can pick the best combination of coding rate\nand object chunking/slicing options as the load dynamically changes. Our\nspecific contributions are as follows: (1) We establish via measurement that\ncombining variable coding rate and chunking is mostly feasible over a popular\npublic cloud. (2) We relate the delay optimal values for chunking level and\ncode rate to the queue backlogs via an approximate queueing analysis. (3) Based\non this analysis, we propose TOFEC that adapts the chunking level and coding\nrate against the queue backlogs. Our trace-driven simulation results show that\nTOFEC's adaptation mechanism converges to an appropriate code that provides the\noptimal throughput-delay trade-off without reducing system capacity. Compared\nto a non-adaptive strategy optimized for throughput, TOFEC delivers $2.5\\times$\nlower latency under light workloads; compared to a non-adaptive strategy\noptimized for latency, TOFEC can scale to support over $3\\times$ as many\nrequests. (4) We propose a simpler greedy solution that performs on a par with\nTOFEC in average delay performance, but exhibits significantly more performance\nvariations. \n\n"}
{"id": "1403.5828", "contents": "Title: A Survey on Network Tomography with Network Coding Abstract: The overhead of internal network monitoring motivates techniques of network\ntomography. Network coding (NC) presents a new opportunity for network\ntomography as NC introduces topology-dependent correlation that can be further\nexploited in topology estimation. Compared with traditional methods, network\ntomography with NC has many advantages such as the improvement of tomography\naccuracy and the reduction of complexity in choosing monitoring paths. In this\npaper we first introduce the problem of tomography with NC and then propose the\ntaxonomy criteria to classify various methods. We also present existing\nsolutions and future trend. We expect that our comprehensive review on network\ntomography with NC can serve as a good reference for researchers and\npractitioners working in the area. \n\n"}
{"id": "1403.7393", "contents": "Title: Noise-induced phase slips, log-periodic oscillations, and the Gumbel\n  distribution Abstract: When two synchronised phase oscillators are perturbed by weak noise, they\ndisplay occasional losses of synchrony, called phase slips. The slips can be\ncharacterised by their location in phase space and their duration. We show that\nwhen properly normalised, their location converges, in the vanishing noise\nlimit, to the sum of an asymptotically geometric random variable and a Gumbel\nrandom variable. The duration also converges to a Gumbel variable with\ndifferent parameters. We relate these results to recent works on the phenomenon\nof log-periodic oscillations and on links between transition path theory and\nextreme-value theory. \n\n"}
{"id": "1404.0957", "contents": "Title: Noise-Induced Stabilization of Planar Flows I Abstract: We show that the complex-valued ODE\n  \\begin{equation*}\n  \\dot z_t = a_{n+1} z^{n+1} + a_n z^n+\\cdots+a_0,\n  \\end{equation*} which necessarily has trajectories along which the dynamics\nblows up in finite time, can be stabilized by the addition of an arbitrarily\nsmall elliptic, additive Brownian stochastic term. We also show that the\nstochastic perturbation has a unique invariant measure which is heavy-tailed\nyet is uniformly, exponentially attracting. The methods turn on the\nconstruction of Lyapunov functions. The techniques used in the construction are\ngeneral and can likely be used in other settings where a Lyapunov function is\nneeded. This is a two-part paper. This paper, Part I, focuses on general\nLyapunov methods as applied to a special, simplified version of the problem.\nPart II of this paper extends the main results to the general setting. \n\n"}
{"id": "1404.2024", "contents": "Title: The Link between Magnetic Fields and Cloud/Star Formation Abstract: The question whether magnetic fields play an important role in the processes\nof molecular cloud and star formation has been debated for decades. Recent\nobservations have revealed a simple picture that may help illuminate these\nquestions: magnetic fields have a tendency to preserve their orientation at all\nscales that have been probed - from 100-pc scale inter-cloud media down to\nsub-pc scale cloud cores. This ordered morphology has implications for the way\nin which self-gravity and turbulence interact with magnetic fields: both\ngravitational contraction and turbulent velocities should be anisotropic, due\nto the influence of dynamically important magnetic fields. Such anisotropy is\nnow observed. Here we review these recent observations and discuss how they can\nimprove our understanding of cloud/star formation. \n\n"}
{"id": "1404.2387", "contents": "Title: Fast Structuring of Radio Networks for Multi-Message Communications Abstract: We introduce collision free layerings as a powerful way to structure radio\nnetworks. These layerings can replace hard-to-compute BFS-trees in many\ncontexts while having an efficient randomized distributed construction. We\ndemonstrate their versatility by using them to provide near optimal distributed\nalgorithms for several multi-message communication primitives.\n  Designing efficient communication primitives for radio networks has a rich\nhistory that began 25 years ago when Bar-Yehuda et al. introduced fast\nrandomized algorithms for broadcasting and for constructing BFS-trees. Their\nBFS-tree construction time was $O(D \\log^2 n)$ rounds, where $D$ is the network\ndiameter and $n$ is the number of nodes. Since then, the complexity of a\nbroadcast has been resolved to be $T_{BC} = \\Theta(D \\log \\frac{n}{D} + \\log^2\nn)$ rounds. On the other hand, BFS-trees have been used as a crucial building\nblock for many communication primitives and their construction time remained a\nbottleneck for these primitives.\n  We introduce collision free layerings that can be used in place of BFS-trees\nand we give a randomized construction of these layerings that runs in nearly\nbroadcast time, that is, w.h.p. in $T_{Lay} = O(D \\log \\frac{n}{D} +\n\\log^{2+\\epsilon} n)$ rounds for any constant $\\epsilon>0$. We then use these\nlayerings to obtain: (1) A randomized algorithm for gathering $k$ messages\nrunning w.h.p. in $O(T_{Lay} + k)$ rounds. (2) A randomized $k$-message\nbroadcast algorithm running w.h.p. in $O(T_{Lay} + k \\log n)$ rounds. These\nalgorithms are optimal up to the small difference in the additive\npoly-logarithmic term between $T_{BC}$ and $T_{Lay}$. Moreover, they imply the\nfirst optimal $O(n \\log n)$ round randomized gossip algorithm. \n\n"}
{"id": "1404.4422", "contents": "Title: How gravitational lensing helps gamma-ray photons avoid $\\gamma -\n  \\gamma$ absorption Abstract: We investigate potential $\\gamma-\\gamma$ absorption of gamma-ray emission\nfrom blazars arising from inhomogeneities along the line of sight, beyond the\ndiffuse Extragalactic Background Light (EBL). As plausible sources of excess\n$\\gamma-\\gamma$ opacity, we consider (1) foreground galaxies, including cases\nin which this configuration leads to strong gravitational lensing, (2)\nindividual stars within these foreground galaxies, and (3) individual stars\nwithin our own galaxy, which may act as lenses for microlensing events. We\nfound that intervening galaxies close to the line-of-sight are unlikely to lead\nto significant excess $\\gamma-\\gamma$ absorption. This opens up the prospect of\ndetecting lensed gamma-ray blazars at energies above 10 GeV with their\ngamma-ray spectra effectively only affected by the EBL. The most luminous stars\nlocated either in intervening galaxy or in our galaxy provides an environment\nin which these gamma-rays could, in principle, be significantly absorbed.\nHowever, despite a large microlensing probability due to stars located in\nintervening galaxies, gamma-rays avoid absorption by being deflected by the\ngravitational potentials of such intervening stars to projected distances\n(\"impact parameters\"') where the resulting $\\gamma-\\gamma$ opacities are\nnegligible. Thus, neither of the intervening excess photon fields considered\nhere, provide a substantial source of excess $\\gamma-\\gamma$ opacity beyond the\nEBL, even in the case of very close alignments between the background blazar\nand a foreground star or galaxy. \n\n"}
{"id": "1404.6621", "contents": "Title: Almost periodic solutions for stochastic differential equations with\n  exponential dichotomy driven by Levy noise Abstract: In this paper, we study almost periodic solutions for semilinear stochastic\ndifferential equations driven by L\\'{e}vy noise with exponential dichotomy\nproperty. Under suitable conditions on the coefficients, we obtain the\nexistence and uniqueness of bounded solutions. Furthermore, this unique bounded\nsolution is almost periodic in distribution under slightly stronger conditions.\nWe also give two examples to illustrate our results. \n\n"}
{"id": "1404.6687", "contents": "Title: When Queueing Meets Coding: Optimal-Latency Data Retrieving Scheme in\n  Storage Clouds Abstract: In this paper, we study the problem of reducing the delay of downloading data\nfrom cloud storage systems by leveraging multiple parallel threads, assuming\nthat the data has been encoded and stored in the clouds using fixed rate\nforward error correction (FEC) codes with parameters (n, k). That is, each file\nis divided into k equal-sized chunks, which are then expanded into n chunks\nsuch that any k chunks out of the n are sufficient to successfully restore the\noriginal file. The model can be depicted as a multiple-server queue with\narrivals of data retrieving requests and a server corresponding to a thread.\nHowever, this is not a typical queueing model because a server can terminate\nits operation, depending on when other servers complete their service (due to\nthe redundancy that is spread across the threads). Hence, to the best of our\nknowledge, the analysis of this queueing model remains quite uncharted.\n  Recent traces from Amazon S3 show that the time to retrieve a fixed size\nchunk is random and can be approximated as a constant delay plus an i.i.d.\nexponentially distributed random variable. For the tractability of the\ntheoretical analysis, we assume that the chunk downloading time is i.i.d.\nexponentially distributed. Under this assumption, we show that any\nwork-conserving scheme is delay-optimal among all on-line scheduling schemes\nwhen k = 1. When k > 1, we find that a simple greedy scheme, which allocates\nall available threads to the head of line request, is delay optimal among all\non-line scheduling schemes. We also provide some numerical results that point\nto the limitations of the exponential assumption, and suggest further research\ndirections. \n\n"}
{"id": "1405.2410", "contents": "Title: Tunable double optomechanically induced transparency in an\n  optomechanical system Abstract: We study the dynamics of a driven optomechanical cavity coupled to a charged\nnanomechanical resonator via Coulomb interaction, in which the tunable double\noptomechanically induced transparency (OMIT) can be observed from the output\nfield at the probe frequency by controlling the strength of the Coulomb\ninteraction. We calculate the splitting of the two transparency windows, which\nvaries near linearly with the Coulomb coupling strength in a robust way against\nthe cavity decay. Our double-OMIT is much different from previously mentioned\ndouble-EIT and can be applied to measure Coulomb coupling strength. \n\n"}
{"id": "1405.4120", "contents": "Title: On Energy-efficiency in Wireless Networks: A Game-theoretic Approach to\n  Cooperation Inspired by Evolutionary Biology Abstract: We develop a game-theoretic framework to investigate the effect of\ncooperation on the energy efficiency in wireless networks. We address two\nexamples of network architectures, resembling ad-hoc network and network with\ncentral infrastructure node. Most present approaches address the issue of\nenergy efficiency in communication networks by using complex algorithms to\nenforce cooperation in the network, followed by extensive signal processing at\nthe network nodes. Instead, we address cooperative communication scenarios\nwhich are governed by simple, evolutionary-like, local rules, and do not\nrequire strategic complexity of the network nodes. The approach is motivated by\nrecent results in evolutionary biology which suggest that cooperation can\nemerge in Nature by evolution, i. e. can be favoured by natural selection, if\ncertain mechanism is at work. As result, we are able to show by experiments\nthat cooperative behavior can indeed emerge and persist in wireless networks,\neven if the behavior of the individual nodes is driven by selfish decision\nmaking. The results from this work indicate that uncomplicated local rules,\nfollowed by simple fitness evaluation, can promote cooperation and generate\nnetwork behavior which yields global energy efficiency in certain wireless\nnetworks. \n\n"}
{"id": "1405.4608", "contents": "Title: Two-Tier Precoding for FDD Multi-cell Massive MIMO Time-Varying\n  Interference Networks (Full Version) Abstract: Massive MIMO is a promising technology in future wireless communication\nnetworks. However, it raises a lot of implementation challenges, for example,\nthe huge pilot symbols and feedback overhead, requirement of real-time global\nCSI, large number of RF chains needed and high computational complexity. We\nconsider a two-tier precoding strategy for multi-cell massive MIMO interference\nnetworks, with an outer precoder for inter-cell/inter-cluster interference\ncancellation, and an inner precoder for intra-cell multiplexing. In particular,\nto combat with the computational complexity issue of the outer precoding, we\npropose a low complexity online iterative algorithm to track the outer precoder\nunder time-varying channels. We follow an optimization technique and formulate\nthe problem on the Grassmann manifold. We develop a low complexity iterative\nalgorithm, which converges to the global optimal solution under static\nchannels. In time-varying channels, we propose a compensation technique to\noffset the variation of the time-varying optimal solution. We show with our\ntheoretical result that, under some mild conditions, perfect tracking of the\ntarget outer precoder using the proposed algorithm is possible. Numerical\nresults demonstrate that the two-tier precoding with the proposed iterative\ncompensation algorithm can achieve a good performance with a significant\ncomplexity reduction compared with the conventional two-tier precoding\ntechniques in the literature. \n\n"}
{"id": "1405.5326", "contents": "Title: Secure Anonymous Broadcast Abstract: In anonymous broadcast, one or more parties want to anonymously send messages\nto all parties. This problem is increasingly important as a black-box in many\nprivacy-preserving applications such as anonymous communication, distributed\nauctions, and multi-party computation. In this paper, we design decentralized\nprotocols for anonymous broadcast that require each party to send (and compute)\na polylogarithmic number of bits (and operations) per anonymous bit delivered\nwith $O(\\log n)$ rounds of communication. Our protocol is provably secure\nagainst traffic analysis, does not require any trusted party, and is completely\nload-balanced. The protocol tolerates up to $n/6$ statically-scheduled\nByzantine parties that are controlled by a computationally unbounded adversary.\nOur main strategy for achieving scalability is to perform local communications\n(and computations) among a logarithmic number of parties. We provide simulation\nresults to show that our protocol improves significantly over previous work. We\nfinally show that using a common cryptographic tool in our protocol one can\nachieve practical results for anonymous broadcast. \n\n"}
{"id": "1405.6305", "contents": "Title: Averaging along foliated L\\'evy diffusions Abstract: This article studies the dynamics of the strong solution of a SDE driven by a\ndiscontinuous L\\'evy process taking values in a smooth foliated manifold with\ncompact leaves. It is assumed that it is \\textit{foliated} in the sense that\nits trajectories stay on the leaf of their initial value for all times a.s.. %\nSuch a system is called a \\textit{foliated L\\'evy diffusion}. Under a generic\nergodicity assumption for each leaf, % and a continuous variation of the\nergodic measures among each others, we determine the effective behaviour of the\nsystem subject to a small smooth perturbation of order $\\e>0$, which acts\ntransversal to the leaves. The main result states that, on average, the\ntransversal component of the perturbed SDE converges uniformly to the solution\nof a deterministic ODE as $\\e$ tends to zero. This transversal ODE is generated\nby the average of the perturbing vector field with respect to the invariant\nmeasures of the unperturbed system and varies with the transversal height of\nthe leaves. We give upper bounds for the rates of convergence % The right-hand\nside of this ODE is given as the average of the perturbing vector field % with\nrespect to the unique invariant measures of the unperturbed system on the\nleaves. % We give upper bounds for the rates of convergence. and illustrate\nthese results for the random rotations on the circle. This article %which are\nproved for pure jump L\\'evy processes complements the results by Gargate and\nRuffino for SDEs of Stratonovich type to general L\\'evy driven SDEs of Marcus\ntype. \n\n"}
{"id": "1405.6689", "contents": "Title: Modeling Multi-mode D2D Communications in LTE Abstract: In this work we propose a roadmap towards the analytical understanding of\nDevice-to-Device (D2D) communications in LTE-A networks. Various D2D solutions\nhave been proposed, which include inband and outband D2D transmission modes,\neach of which exhibits different pros and cons in terms of complexity,\ninterference, and spectral efficiency achieved. We go beyond traditional mode\noptimization and mode-selection schemes. Specifically, we formulate a general\nproblem for the joint per-user mode selection, connection activation and\nresource scheduling of connections. \n\n"}
{"id": "1405.7936", "contents": "Title: BINGO - A novel method to detect BAOs using a total-power radio\n  telescope Abstract: BINGO is a novel single-dish total-power telescope that will map the\nredshifted HI sky in a ~15 degree strip, at frequencies of 960-1260 MHz\n(z=0.12-0.48). BINGO will have the sensitivity to accurately measure the HI\npower spectrum and to detect Baryon Acoustic Oscillations (BAOs) for the first\ntime at radio wavelengths. This will provide complementary cosmological\ninformation to existing surveys and will measure the acoustic scale to ~2 %\nprecision. We provide an update on BINGO including an improved two-mirror\noptical configuration, final site selection and foreground removal simulations. \n\n"}
{"id": "1406.0449", "contents": "Title: Strongly reinforced P\\'olya urns with graph-based competition Abstract: We introduce a class of reinforcement models where, at each time step $t$,\none first chooses a random subset $A_t$ of colours (independent of the past)\nfrom $n$ colours of balls, and then chooses a colour $i$ from this subset with\nprobability proportional to the number of balls of colour $i$ in the urn raised\nto the power $\\alpha>1$. We consider stability of equilibria for such models\nand establish the existence of phase transitions in a number of examples,\nincluding when the colours are the edges of a graph, a context which is a toy\nmodel for the formation and reinforcement of neural connections. \n\n"}
{"id": "1406.2019", "contents": "Title: Relationship of Time Reversal Symmetry Breaking with Optical Kerr\n  Rotation Abstract: We prove an instance of the Reciprocity Theorem that demonstrates that Kerr\nrotation, also known as the magneto-optical Kerr effect, may only arise in\nmaterials that break microscopic time reversal symmetry. This argument applies\nin the linear response regime, and only fails for nonlinear effects. Recent\nmeasurements with a modified Sagnac Interferometer have found finite Kerr\nrotation in a variety of superconductors. The Sagnac Interferometer is a probe\nfor nonreciprocity, so it must be that time reversal symmetry is broken in\nthese materials. \n\n"}
{"id": "1406.2675", "contents": "Title: Front Propagation in Stochastic Neural Fields: A Rigorous Mathematical\n  Framework Abstract: We develop a complete and rigorous mathematical framework for the analysis of\nstochastic neural field equations under the influence of spatially extended\nadditive noise. By comparing a solution to a fixed deterministic front profile\nit is possible to realise the difference as strong solution to an\n$L^2(\\mathbb{R})$-valued SDE. A multiscale analysis of this process then allows\nus to obtain rigorous stability results. Here a new representation formula for\nstochastic convolutions in the semigroup approach to linear function-valued SDE\nwith adapted random drift is applied. Additionally, we introduce a dynamic\nphase-adaption process of gradient type. \n\n"}
{"id": "1406.3535", "contents": "Title: 3D Cavity quantum electrodynamics with a rare-earth spin ensemble Abstract: We present cavity QED experiments with an Er:YSO crystal magnetically coupled\nto a 3D cylindrical sapphire loaded copper resonator. Such waveguide cavities\nare promising for the realization of a superconducting quantum processor. Here,\nwe demonstrate the coherent integration of a rare-earth spin ensemble with the\n3D architecture. The collective coupling strength of the Er$^{3+}$ spins to the\n3D cavity is 21 MHz. The cylindrical sapphire loaded resonator allowed us to\nexplore the anisotropic collective coupling between the rare-earth doped\ncrystal and the cavity. This work shows the potential of spin doped solids in\n3D quantum circuits for application as microwave quantum memories as well as\nfor prospective microwave to optical interfaces. \n\n"}
{"id": "1406.3791", "contents": "Title: Fluctuational electrodynamics of hyperbolic metamaterials Abstract: We give a detailed account of equilibrium and non-equilibrium fluctuational\nelectrodynamics of hyperbolic metamaterials. We show the unifying aspects of\ntwo different approaches; one utilizes the second kind of fluctuation\ndissipation theorem and the other makes use of the scattering method. We\nanalyze the near-field of hyperbolic media at finite temperatures and show that\nthe lack of spatial coherence can be attributed to the multi-modal nature of\nsuper-Planckian thermal emission. We also adopt the analysis to\nphonon-polaritonic super-lattice metamaterials and describe the regimes\nsuitable for experimental verification of our predicted effects. The results\nreveal that far-field thermal emission spectra are dominated by\nepsilon-near-zero and epsilon-near-pole responses as expected from Kirchoff's\nlaws. Our work should aid both theorists and experimentalists to study complex\nmedia and engineer equilibrium and non-equilibrium fluctuations for\napplications in thermal photonics. \n\n"}
{"id": "1406.5507", "contents": "Title: PSR J1756$-$2251: a pulsar with a low-mass neutron star companion Abstract: The pulsar PSR J1756$-$2251 resides in a relativistic double neutron star\n(DNS) binary system with a 7.67-hr orbit. We have conducted long-term precision\ntiming on more than 9 years of data acquired from five telescopes, measuring\nfive post-Keplerian parameters. This has led to several independent tests of\ngeneral relativity (GR), the most constraining of which shows agreement with\nthe prediction of GR at the 4% level. Our measurement of the orbital decay rate\ndisagrees with that predicted by GR, likely due to systematic observational\nbiases. We have derived the pulsar distance from parallax and orbital decay\nmeasurements to be 0.73$_{-0.24}^{+0.60}$ kpc (68%) and < 1.2 kpc (95% upper\nlimit), respectively; these are significantly discrepant from the distance\nestimated using Galactic electron density models. We have found the pulsar mass\nto be 1.341$\\pm$0.007 M$_\\odot$, and a low neutron star (NS) companion mass of\n1.230$\\pm$0.007 M$_\\odot$. We also determined an upper limit to the spin-orbit\nmisalignment angle of 34{\\deg} (95%) based on a system geometry fit to\nlong-term profile width measurements. These and other observed properties have\nled us to hypothesize an evolution involving a low mass loss, symmetric\nsupernova progenitor to the second-formed NS companion, as is thought to be the\ncase for the double pulsar system PSR J0737$-$3039A/B. This would make PSR\nJ1756$-$2251 the second compact binary system providing concrete evidence for\nthis type of NS formation channel. \n\n"}
{"id": "1407.0319", "contents": "Title: Galactic space-times in modified theories of gravity Abstract: We study Bertrand space-times (BSTs), which have been proposed as viable\nmodels of space-times seeded by galactic dark matter, in modified theories of\ngravity. We first critically examine the issue of galactic rotation curves in\nGeneral Relativity, and establish the usefulness of BSTs to fit experimental\ndata in this context. We then study BSTs in metric $f(R)$ gravity and in\nBrans-Dicke theories. For the former, the nature of the Newtonian potential is\nestablished, and we also compute the effective equation of state and show that\nit can provide good fits to some recent experimental results. For the latter,\nwe calculate the Brans-Dicke scalar analytically in some limits and numerically\nin general, and find interesting constraints on the parameters of the theory.\nOur results provide evidence for the physical nature of Bertrand space-times in\nmodified theories of gravity. \n\n"}
{"id": "1407.1239", "contents": "Title: RepNet: Cutting Tail Latency in Data Center Networks with Flow\n  Replication Abstract: Data center networks need to provide low latency, especially at the tail, as\ndemanded by many interactive applications. To improve tail latency, existing\napproaches require modifications to switch hardware and/or end-host operating\nsystems, making them difficult to be deployed. We present the design,\nimplementation, and evaluation of RepNet, an application layer transport that\ncan be deployed today. RepNet exploits the fact that only a few paths among\nmany are congested at any moment in the network, and applies simple flow\nreplication to mice flows to opportunistically use the less congested path.\nRepNet has two designs for flow replication: (1) RepSYN, which only replicates\nSYN packets and uses the first connection that finishes TCP handshaking for\ndata transmission, and (2) RepFlow which replicates the entire mice flow. We\nimplement RepNet on {\\tt node.js}, one of the most commonly used platforms for\nnetworked interactive applications. {\\tt node}'s single threaded event-loop and\nnon-blocking I/O make flow replication highly efficient. Performance evaluation\non a real network testbed and in Mininet reveals that RepNet is able to reduce\nthe tail latency of mice flows, as well as application completion times, by\nmore than 50\\%. \n\n"}
{"id": "1407.1404", "contents": "Title: Limits on the neutrino magnetic dipole moment from the luminosity\n  function of hot white dwarfs Abstract: Recent determinations of the white dwarf luminosity function (WDLF) from very\nlarge surveys have extended our knowledge of the WDLF to very high\nluminosities. This, together with the availability of new full evolutionary\nwhite dwarf models that are reliable at high luminosities, have opened the\npossibility of testing particle emission in the core of very hot white dwarfs,\nwhere neutrino processes are dominant. We use the available WDLFs from the\nSloan Digital Sky Survey and the SuperCOSMOS Sky Survey to constrain the value\nof the neutrino magnetic dipole moment ($\\mu_\\nu$). We constructed theoretical\nWDLFs for different values of $\\mu_\\nu$ and performed a $\\chi^2$-test to derive\nconstraints on the value of $\\mu_\\nu$. We also constructed a unified WDLF by\naveraging the SDSS and SSS and estimated the uncertainties by taking into\naccount the differences between the WDLF at each magnitude bin. Then we\ncompared all WDLFs with theoretical WDLFs.Comparison between theoretical WDLFs\nand both the SDSS and the averaged WDLF indicates that $\\mu_\\nu$ should be\n$\\mu_\\nu<5\\times 10^{-12}\\, e\\hbar/(2m_e c)$. In particular, a $\\chi^2$-test on\nthe averaged WDLF suggests that observations of the disk WDLF exclude values of\n$\\mu_\\nu>5\\times 10^{-12}e\\hbar/(2m_e c)$ at more than a 95\\% confidence level,\neven when conservative estimates of the uncertainties are adopted. Our study\nshows that modern WDLFs, which extend to the high-luminosity regime, are an\nexcellent tool for constraining the emission of particles in the core of hot\nwhite dwarfs. However, discrepancies between different WDLFs suggest there\nmight be some relevant unaccounted systematic errors. A larger set of\ncompletely independent WDLFs, as well as more detailed studies of the\ntheoretical WDLFs and their own uncertainties, is desirable to explore the\nsystematic uncertainties behind this constraint. \n\n"}
{"id": "1407.2565", "contents": "Title: Plurality Consensus in the Gossip Model Abstract: We study Plurality Consensus in the Gossip Model over a network of $n$\nanonymous agents. Each agent supports an initial opinion or color. We assume\nthat at the onset, the number of agents supporting the plurality color exceeds\nthat of the agents supporting any other color by a sufficiently-large bias. The\ngoal is to provide a protocol that, with high probability, brings the system\ninto the configuration in which all agents support the (initial) plurality\ncolor. We consider the Undecided-State Dynamics, a well-known protocol which\nuses just one more state (the undecided one) than those necessary to store\ncolors. We show that the speed of convergence of this protocol depends on the\ninitial color configuration as a whole, not just on the gap between the\nplurality and the second largest color community. This dependence is best\ncaptured by a novel notion we introduce, namely, the monochromatic distance\n${md}(\\bar{\\mathbf{c}})$ which measures the distance of the initial color\nconfiguration $\\bar{ \\mathbf {c}}$ from the closest monochromatic one. In the\ncomplete graph, we prove that, for a wide range of the input parameters, this\ndynamics converges within $O({md}(\\bar {\\mathbf {c}}) \\log {n})$ rounds. We\nprove that this upper bound is almost tight in the strong sense: Starting from\nany color configuration $\\bar {\\mathbf {c}}$, the convergence time is\n$\\Omega({md}(\\bar {\\mathbf {c}}))$. Finally, we adapt the Undecided-State\nDynamics to obtain a fast, random walk-based protocol for plurality consensus\non regular expanders. This protocol converges in $O({md}(\\bar {\\mathbf {c}})\n\\mathrm{polylog}(n))$ rounds using only $\\mathrm{polylog}(n)$ local memory. A\nkey-ingredient to achieve the above bounds is a new analysis of the maximum\nnode congestion that results from performing $n$ parallel random walks on\nregular expanders. All our bounds hold with high probability. \n\n"}
{"id": "1407.2728", "contents": "Title: Bounding the Solutions to Some SDEs via Ergodic Theory Abstract: In this note we consider autonomous SDEs admitting smooth invariant measures.\nWe present a method in finding (almost everywhere) good bounds for $\\sup\n\\{\\|X_t\\|: t \\in [0, T]\\}$ for strong solutions $X_{\\cdot}$ to such SDEs, which\nin many cases are optimal bounds. In some situation (especially in\none-dimensional SDEs' cases), the discarded measure-zero set can be chosen to\nbe a measure-zero set of the underlying Brownian motion uniform for all initial\npoints $X_0=x$. \n\n"}
{"id": "1407.4504", "contents": "Title: Hybrid Random/Deterministic Parallel Algorithms for Nonconvex Big Data\n  Optimization Abstract: We propose a decomposition framework for the parallel optimization of the sum\nof a differentiable {(possibly nonconvex)} function and a nonsmooth (possibly\nnonseparable), convex one. The latter term is usually employed to enforce\nstructure in the solution, typically sparsity. The main contribution of this\nwork is a novel \\emph{parallel, hybrid random/deterministic} decomposition\nscheme wherein, at each iteration, a subset of (block) variables is updated at\nthe same time by minimizing local convex approximations of the original\nnonconvex function. To tackle with huge-scale problems, the (block) variables\nto be updated are chosen according to a \\emph{mixed random and deterministic}\nprocedure, which captures the advantages of both pure deterministic and random\nupdate-based schemes. Almost sure convergence of the proposed scheme is\nestablished. Numerical results show that on huge-scale problems the proposed\nhybrid random/deterministic algorithm outperforms both random and deterministic\nschemes. \n\n"}
{"id": "1407.6876", "contents": "Title: On Partial Wait-Freedom in Transactional Memory Abstract: Transactional memory (TM) is a convenient synchronization tool that allows\nconcurrent threads to declare sequences of instructions on shared data as\nspeculative \\emph{transactions} with \"all-or-nothing\" semantics. It is known\nthat dynamic transactional memory cannot provide \\emph{wait-free} progress in\nthe sense that every transaction commits in a finite number of its own steps.\nIn this paper, we explore the costs of providing wait-freedom to only a\n\\emph{subset} of transactions. Since most transactional workloads are believed\nto be read-dominated, we require that read-only transactions commit in the\nwait-free manner, while updating transactions are guaranteed to commit only if\nthey run in the absence of concurrency. We show that this kind of partial\nwait-freedom, combined with attractive requirements like read invisibility or\ndisjoint-access parallelism, incurs considerable complexity costs. \n\n"}
{"id": "1407.7061", "contents": "Title: A Parallel Branch and Bound Algorithm for the Maximum Labelled Clique\n  Problem Abstract: The maximum labelled clique problem is a variant of the maximum clique\nproblem where edges in the graph are given labels, and we are not allowed to\nuse more than a certain number of distinct labels in a solution. We introduce a\nnew branch-and-bound algorithm for the problem, and explain how it may be\nparallelised. We evaluate an implementation on a set of benchmark instances,\nand show that it is consistently faster than previously published results,\nsometimes by four or five orders of magnitude. \n\n"}
{"id": "1407.7961", "contents": "Title: Tunable terahertz coherent perfect absorption in a monolayer graphene Abstract: Coherent perfect absorber (CPA) was proposed as the time-reversed counterpart\nto laser: a resonator containing lossy medium instead of gain medium can absorb\nthe coherent optical fields completely. Here, we exploit a monolayer graphene\nto realize the CPA in a non-resonant manner. It is found that quasi-CPA point\nexists in the terahertz regime for suspending monolayer graphene, and the CPA\ncan be implemented with the assistant of proper phase modulation among two\nincident beams at the quasi-CPA frequencies. The graphene based CPA is found of\nbroadband angular selectivity: CPA point splits into two frequency bands for\nthe orthogonal $s$ and $p$ polarizations at oblique incidence, and the two\nbands cover a wide frequency range starting from zero frequency. Furthermore,\nthe coherent absorption can be tuned substantially by varying the\ngate-controlled Fermi energy. The findings of CPA with non-resonant graphene\nsheet can be generalized for potential applications in terahertz/infrared\ndetections and signal processing with two-dimensional optoelectronic materials. \n\n"}
{"id": "1407.8340", "contents": "Title: Maximizing the purity of a qubit evolving in an anisotropic environment Abstract: We provide a general method to calculate and maximize the purity of a qubit\ninteracting with an anisotropic non-Markovian environment. Counter to\nintuition, we find that the purity is often maximized by preparing and storing\nthe qubit in a superposition of non-interacting eigenstates. For a model\nrelevant to decoherence of a heavy-hole spin qubit in a quantum dot or for a\nsinglet-triplet qubit for two electrons in a double quantum dot, we show that\npreparation of the qubit in its non-interacting ground state can actually be\nthe worst choice to maximize purity. We further give analytical results for\nspin-echo envelope modulations of arbitrary spin components of a hole spin in a\nquantum dot, going beyond a standard secular approximation. We account for\ngeneral dynamics in the presence of a pure-dephasing process and identify a\ncrossover timescale at which it is again advantageous to initialize the qubit\nin the non-interacting ground state. Finally, we consider a general two-axis\ndynamical decoupling sequence and determine initial conditions that maximize\npurity, minimizing leakage to the environment. \n\n"}
{"id": "1408.0979", "contents": "Title: Distributed Markov Chains Abstract: The formal verification of large probabilistic models is important and\nchallenging. Exploiting the concurrency that is often present is one way to\naddress this problem. Here we study a restricted class of asynchronous\ndistributed probabilistic systems in which the synchronizations determine the\nprobability distribution for the next moves of the participating agents. The\nkey restriction we impose is that the synchronizations are deterministic, in\nthe sense that any two simultaneously enabled synchronizations must involve\ndisjoint sets of agents. As a result, this network of agents can be viewed as a\nsuccinct and distributed presentation of a large global Markov chain. A rich\nclass of Markov chains can be represented this way.\n  We define an interleaved semantics for our model in terms of the local\nsynchronization actions. The network structure induces an independence relation\non these actions, which, in turn, induces an equivalence relation over the\ninterleaved runs in the usual way. We construct a natural probability measure\nover these equivalence classes of runs by exploiting Mazurkiewicz trace theory\nand the probability measure space of the associated global Markov chain.\n  It turns out that verification of our model, called DMCs (distributed Markov\nchains), can often be efficiently carried out by exploiting the partial order\nnature of the interleaved semantics. To demonstrate this, we develop a\nstatistical model checking (SMC) procedure and use it to verify two large\ndistributed probabilistic networks. \n\n"}
{"id": "1408.1540", "contents": "Title: Quantum Byzantine Agreement via Hardy correlations and entanglement\n  swapping Abstract: We present a device-independent quantum scheme for the {\\em Byzantine\nGenerals} problem. The protocol is for three parties. Party $C$ is to send two\nidentical one bit messages to parties $A$ and $B$. The receivers $A$ and $B$\nmay exchange two one bit messages informing the other party on the message\nreceived from $C$. A bit flipping error in one of the transmissions, does not\nallow the receiving parties to establish what was the message of $C$. Our\nquantum scheme has the feature that if the messages of the Byzantine protocol\nare readable (that is give an unambiguous bit value for any of the receivers),\nthen any error by $C$ (cheating by one of the commanding general) is\nimpossible. $A$ and $B$ do not have to exchange protocol messages to be sure of\nthis. \n\n"}
{"id": "1408.1808", "contents": "Title: Measurement of a topological edge invariant in a microwave network Abstract: We report on the measurement of topological invariants in an electromagnetic\ntopological insulator analog formed by a microwave network, consisting of the\nwinding numbers of scattering matrix eigenvalues. The experiment can be\nregarded as a variant of a topological pump, with non-zero winding implying the\nexistence of topological edge states. In microwave networks, unlike most other\nsystems exhibiting topological insulator physics, the winding can be directly\nobserved. The effects of loss on the experimental results, and on the\ntopological edge states, is discussed. \n\n"}
{"id": "1408.2826", "contents": "Title: Inflation with Fayet-Iliopoulos Terms Abstract: Two of the most attractive realizations of inflation in supergravity are\nbased upon the presence of a constant Fayet-Iliopoulos (FI) term. In D-term\nhybrid inflation it is the FI term itself which sets the energy scale of\ninflation. Alternatively, the breaking of a U(1) symmetry induced by the FI\nterm can dynamically generate the quadratic potential of chaotic inflation. The\npurpose of this note is to study the possible UV embedding of these schemes in\nterms of the `field-dependent FI term' related to a string modulus field which\nis stabilized by a non-perturbative superpotential. We find that in settings\nwhere the FI term drives inflation, gauge invariance prevents a decoupling of\nthe modulus from the inflationary dynamics. The resulting inflation models\ngenerically contain additional dynamical degrees of freedom compared to D-term\nhybrid inflation. However, the dynamical realization of chaotic inflation can\nbe obtained in complete analogy to the case of a constant FI term. We present a\nsimple string-inspired toy model of this type. \n\n"}
{"id": "1408.3079", "contents": "Title: A Lightweight Approach for Improving the Lookup Performance in\n  Kademlia-type Systems Abstract: Discovery of nodes and content in large-scale distributed systems is\ngenerally based on Kademlia, today. Understanding Kademlia-type systems to\nimprove their performance is essential for maintaining a high service quality\nfor an increased number of participants, particularly when those systems are\nadopted by latency-sensitive applications.\n  This paper contributes to the understanding of Kademlia by studying the\nimpact of \\emph{diversifying} neighbours' identifiers within each routing table\nbucket on the lookup performance. We propose a new, yet backward-compatible,\nneighbour selection scheme that attempts to maximize the aforementioned\ndiversity. The scheme does not cause additional overhead except negligible\ncomputations for comparing the diversity of identifiers. We present a\ntheoretical model for the actual impact of the new scheme on the lookup's hop\ncount and validate it against simulations of three exemplary Kademlia-type\nsystems. We also measure the performance gain enabled by a partial deployment\nfor the scheme in the real KAD system. The results confirm the superiority of\nthe systems that incorporate our scheme. \n\n"}
{"id": "1408.5131", "contents": "Title: The coupling to matter in Massive, Bi- and Multi-Gravity Abstract: In this paper we construct a family of ways in which matter can couple to one\nor more `metrics'/spin-2 fields in the vielbein formulation. We do so subject\nto requiring the weak equivalence principle and the absence of ghosts from pure\nspin-2 interactions generated by the matter action. Results are presented for\nMassive, Bi- and Multi-Gravity theories and we give explicit expressions for\nthe effective matter metric in all of these cases. \n\n"}
{"id": "1409.0263", "contents": "Title: The cosmic evolution of radio-AGN feedback to z=1 Abstract: This paper presents the first measurement of the radio luminosity function of\n'jet-mode' (radiatively-inefficient) radio-AGN out to z=1, in order to\ninvestigate the cosmic evolution of radio-AGN feedback. Eight radio source\nsamples are combined to produce a catalogue of 211 radio-loud AGN with\n0.5<z<1.0, which are spectroscopically classified into jet-mode and\nradiative-mode (radiatively-efficient) AGN classes. Comparing with large\nsamples of local radio-AGN from the Sloan Digital Sky Survey, the cosmic\nevolution of the radio luminosity function of each radio-AGN class is\nindependently derived. Radiative-mode radio-AGN show an order of magnitude\nincrease in space density out to z~1 at all luminosities, consistent with these\nAGN being fuelled by cold gas. In contrast, the space density of jet-mode\nradio-AGN decreases with increasing redshift at low radio luminosities (L_1.4 <\n1e24 W/Hz) but increases at higher radio luminosities. Simple models are\ndeveloped to explain the observed evolution. In the best-fitting models, the\ncharacteristic space density of jet-mode AGN declines with redshift in\naccordance with the declining space density of massive quiescent galaxies,\nwhich fuel them via cooling of gas in their hot haloes. A time delay of 1.5-2\nGyr may be present between the quenching of star formation and the onset of\njet-mode radio-AGN activity. The behaviour at higher radio luminosities can be\nexplained either by an increasing characteristic luminosity of jet-mode\nradio-AGN activity with redshift (roughly as (1+z) cubed) or if the jet-mode\nradio-AGN population also includes some contribution of cold-gas-fuelled\nsources seen at a time when their accretion rate was low. Higher redshifts\nmeasurements would distinguish between these possibilities. \n\n"}
{"id": "1409.1369", "contents": "Title: A holographic model for the fractional quantum Hall effect Abstract: Experimental data for fractional quantum Hall systems can to a large extent\nbe explained by assuming the existence of a modular symmetry group commuting\nwith the renormalization group flow and hence mapping different phases of\ntwo-dimensional electron gases into each other. Based on this insight, we\nconstruct a phenomenological holographic model which captures many features of\nthe fractional quantum Hall effect. Using an SL(2,Z)-invariant\nEinstein-Maxwell-axio-dilaton theory capturing the important modular\ntransformation properties of quantum Hall physics, we find dyonic diatonic\nblack hole solutions which are gapped and have a Hall conductivity equal to the\nfilling fraction, as expected for quantum Hall states. We also provide several\ntechnical results on the general behavior of the gauge field fluctuations\naround these dyonic dilatonic black hole solutions: We specify a sufficient\ncriterion for IR normalizability of the fluctuations, demonstrate the\npreservation of the gap under the SL(2,Z) action, and prove that the\nsingularity of the fluctuation problem in the presence of a magnetic field is\nan accessory singularity. We finish with a preliminary investigation of the\npossible IR scaling solutions of our model and some speculations on how they\ncould be important for the observed universality of quantum Hall transitions. \n\n"}
{"id": "1409.2835", "contents": "Title: Power Estimation in LTE systems with the General Framework of Standard\n  Interference Mappings Abstract: We devise novel techniques to obtain the downlink power inducing a given load\nin long-term evolution (LTE) systems, where we define load as the fraction of\nresource blocks in the time-frequency grid being requested by users from a\ngiven base station. These techniques are particularly important because\nprevious studies have proved that the data rate requirement of users can be\nsatisfied with lower transmit energy if we allow the load to increase. Those\nstudies have also shown that obtaining the power assignment from a desired load\nprofile can be posed as a fixed point problem involving standard interference\nmappings, but so far the mappings have not been obtained explicitly. One of our\nmain contributions in this study is to close this gap. We derive an\ninterference mapping having as its fixed point the power assignment inducing a\ndesired load, assuming that such an assignment exists. Having this mapping in\nclosed form, we simplify the proof of the aforementioned known results, and we\nalso devise novel iterative algorithms for power computation that have many\nnumerical advantages over previous methods. \n\n"}
{"id": "1409.3232", "contents": "Title: Charge-Swapping Q-balls Abstract: Q-balls are non-topological solitonic solutions to a wide class of field\ntheories that possess global symmetries. Here we show that in these same\ntheories there also exists a tower of novel composite Q-ball solutions where,\nwithin one composite Q-ball, positive and negative charges co-exist and swap at\na frequency lower than the natural frequency of an individual Q-ball. These\ncharge-swapping Q-balls are constructed by assembling Q-balls and anti-Q-balls\ntightly such that their nonlinear cores overlap. We explain why charge-swapping\nQ-balls can form and why they swap charges. \n\n"}
{"id": "1409.6198", "contents": "Title: Moving boundary and photoelastic coupling in GaAs optomechanical\n  resonators Abstract: Chip-based cavity optomechanical systems are being considered for\napplications in sensing, metrology, and quantum information science. Critical\nto their development is an understanding of how the optical and mechanical\nmodes interact, quantified by the coupling rate $g_{0}$. Here, we develop GaAs\noptomechanical resonators and investigate the moving dielectric boundary and\nphotoelastic contributions to $g_{0}$. First, we consider coupling between the\nfundamental radial breathing mechanical mode and a 1550 nm band optical\nwhispering gallery mode in microdisks. For decreasing disk radius from $R=5$\n$\\mu$m to $R=1$ $\\mu$m, simulations and measurements show that $g_{0}$ changes\nfrom being dominated by the moving boundary contribution to having an equal\nphotoelastic contribution. Next, we design and demonstrate nanobeam\noptomechanical crystals in which a $2.5$ GHz mechanical breathing mode couples\nto a 1550 nm optical mode predominantly through the photoelastic effect. We\nshow a significant (30 $\\%$) dependence of $g_{0}$ on the device's in-plane\norientation, resulting from the difference in GaAs photoelastic coefficients\nalong different crystalline axes, with fabricated devices exhibiting\n$g_{\\text{0}}/2\\pi$ as high as 1.1 MHz for orientation along the [110] axis.\nGaAs nanobeam optomechanical crystals are a promising system which can combine\nthe demonstrated large optomechanical coupling strength with additional\nfunctionality, such as piezoelectric actuation and incorporation of optical\ngain media. \n\n"}
{"id": "1410.0707", "contents": "Title: A Full Characterization of Irrelevant Components in Diameter Constrained\n  Reliability Abstract: In classical network reliability analysis, the system under study is a\nnetwork with perfect nodes but imperfect link, that fail stochastically and\nindependently. There, the goal is to find the probability that the resulting\nrandom graph is connected, called \\emph{reliability}. Although the exact\nreliability computation belongs to the class of $\\mathcal{NP}$-Hard problems,\nthe literature offers three exact methods for exact reliability computation, to\nknow, Sum of Disjoint Products (SDPs), Inclusion-Exclusion and Factorization.\n  Inspired in delay-sensitive applications in telecommunications, H\\'ector\nCancela and Louis Petingi defined in 2001 the diameter-constrained reliability,\nwhere terminals are required to be connected by $d$ hops or less, being $d$ a\npositive integer, called diameter.\n  Factorization theory in classical network reliability is a mature area.\nHowever, an extension to the diameter-constrained context requires at least the\nrecognition of irrelevant links, and an extension of deletion-contraction\nformula. In this paper, we fully characterize the determination of irrelevant\nlinks. Diameter-constrained reliability invariants are presented, which,\ntogether with the recognition of irrelevant links, represent the\nbuilding-blocks for a new factorization theory. The paper is closed with a\ndiscussion of trends for future work. \n\n"}
{"id": "1410.4477", "contents": "Title: Analysis of incremental augmented affine projection algorithm for\n  distributed estimation of complex signals Abstract: This paper considers the problem of distributed estimation in an incremental\nnetwork when the measurements taken by the node follow a widely linear model.\nThe proposed algorithm which we refer to it as incremental augmented affine\nprojection algorithm (incAAPA) utilizes the full second order statistical\ninformation in the complex domain. Moreover, it exploits spatio-temporal\ndiversity to improve the estimation performance. We derive steady-state\nperformance metric of the incAAPA in terms of the mean-square deviation (MSD).\nWe further derive sufficient conditions to ensure mean-square convergence. Our\nanalysis illustrate that the proposed algorithm is able to process both second\norder circular (proper) and noncircular (improper) signals. The validity of the\ntheoretical results and the good performance of the proposed algorithm are\ndemonstrated by several computer simulations. \n\n"}
{"id": "1410.4820", "contents": "Title: Lyapunov functions, stationary distributions, and non-equilibrium\n  potential for chemical reaction networks Abstract: We consider the relationship between stationary distributions for stochastic\nmodels of reaction systems and Lyapunov functions for their deterministic\ncounterparts. Specifically, we derive the well known Lyapunov function of\nreaction network theory as a scaling limit of the non-equilibrium potential of\nthe stationary distribution of stochastically modeled complex balanced systems.\nWe extend this result to general birth-death models and demonstrate via example\nthat similar scaling limits can yield Lyapunov functions even for models that\nare not complex or detailed balanced, and may even have multiple equilibria. \n\n"}
{"id": "1410.4876", "contents": "Title: A GPU-based parallel algorithm for enumerating all chordless cycles in\n  graphs Abstract: In a finite undirected simple graph, a chordless cycle is an induced subgraph\nwhich is a cycle. We propose a GPU parallel algorithm for enumerating all\nchordless cycles of such a graph. The algorithm, implemented in OpenCL, is\nbased on a previous sequential algorithm developed by the current authors for\nthe same problem. It uses a more compact data structure for solution\nrepresentation which is suitable for the memory-size limitation of a GPU.\nMoreover, for graphs with a sufficiently large amount of chordless cycles, the\nalgorithm presents a significant improvement in execution time that outperforms\nthe sequential method. \n\n"}
{"id": "1410.7256", "contents": "Title: Interactive Consistency in practical, mostly-asynchronous systems Abstract: Interactive consistency is the problem in which n nodes, where up to t may be\nbyzantine, each with its own private value, run an algorithm that allows all\nnon-faulty nodes to infer the values of each other node. This problem is\nrelevant to critical applications that rely on the combination of the opinions\nof multiple peers to provide a service. Examples include monitoring a content\nsource to prevent equivocation or to track variability in the content provided,\nand resolving divergent state amongst the nodes of a distributed system.\nPrevious works assume a fully synchronous system, where one can make strong\nassumptions such as negligible message delivery delays and/or detection of\nabsent messages. However, practical, real-world systems are mostly\nasynchronous, i.e., they exhibit only some periods of synchrony during which\nmessage delivery is timely, thus requiring a different approach. In this paper,\nwe present a thorough study on practical interactive consistency. We leverage\nthe vast prior work on broadcast and byzantine consensus algorithms to design,\nimplement and evaluate a set of algorithms, with varying timing assumptions and\nmessage complexity, that can be used to achieve interactive consistency in\nreal-world distributed systems. We provide a complete, open-source\nimplementation of each proposed interactive consistency algorithm by building a\nmulti-layered stack of protocols that include several broadcast protocols, as\nwell as a binary and a multi-valued consensus protocol. Most of these protocols\nhave never been implemented and evaluated in a real system before. We analyze\nthe performance of our suite of algorithms experimentally by engaging in both\nsingle instance and multiple parallel instances of each alternative. \n\n"}
{"id": "1411.3844", "contents": "Title: Infrared signature of active massive black holes in nearby dwarf\n  galaxies Abstract: We investigate the possible presence of active galactic nuclei (AGN) in dwarf\ngalaxies and other nearby galaxies to identify candidates for follow-up\nconfirmation and dynamical mass measurements. We use the Wide-field Infrared\nSurvey Explorer (WISE) All-Sky Release Source Catalog and examine the infrared\ncolours of a sample of dwarf galaxies and other nearby galaxies in order to\nidentify both unobscured and obscured candidate AGN by applying the infrared\ncolour diagnostic. Stellar masses of galaxies are obtained using a combination\nof three independent methods. Black hole masses are estimated using the\nbolometric luminosity of the AGN candidates and computed for three cases of the\nbolometric-to-Eddington luminosity ratio. We identify 303 candidate AGN, of\nwhich 276 were subsequently found to have been independently identified as AGN\nvia other methods. The remaining 9% require follow-up observations for\nconfirmation. The activity is detected in galaxies with stellar masses from ~\n10^6 to 10^9 solar masses; assuming the candidates are AGN, the black hole\nmasses are estimated to be ~ 10^3 - 10^6 solar masses, adopting L_bol = 0.1\nL_Edd. The black hole masses probed are several orders of magnitude smaller\nthan previously reported for centrally located massive black holes. We examine\nthe stellar mass versus black hole mass relationship in this low galaxy mass\nregime. We find that it is consistent with the existing relation extending\nlinearly (in log-log space) into the lower mass regime. These findings suggest\nthat CMBH are present in low-mass galaxies and in the Local Universe, and\nprovide new impetus for follow-up dynamical studies of quiescent black holes in\nlocal dwarf galaxies. \n\n"}
{"id": "1411.5023", "contents": "Title: The ages, metallicities and element abundance ratios of massive quenched\n  galaxies at z~1.6 Abstract: We investigate the stellar population properties of a sample of 24 massive\nquenched galaxies at $1.25<z_\\mathrm{spec}<2.09$ identified in the COSMOS field\nwith our Subaru/MOIRCS near-IR spectroscopic observations. Tracing the stellar\npopulation properties as close to their major formation epoch as possible, we\ntry to put constraints on the star formation history, post-quenching evolution,\nand possible progenitor star-forming populations for such massive quenched\ngalaxies. By using a set of Lick absorption line indices on a rest-frame\noptical composite spectrum, the average age, metallicity [Z/H], and\n$\\alpha$-to-iron element abundance ratio [$\\alpha$/Fe] are derived as\n$\\log(\\mathrm{age}/\\mathrm{Gyr})=0.04_{-0.08}^{+0.10}$,\n$\\mathrm{[Z/H]}=0.24_{-0.14}^{+0.20}$, and\n$[\\alpha/\\mathrm{Fe}]=0.31_{-0.12}^{+0.12}$, respectively. If our sample of\nquenched galaxies at $\\langle z \\rangle = 1.6$ is evolved passively to $z=0$,\ntheir stellar population properties will align in excellent agreement with\nlocal counterparts at similar stellar velocity dispersions, which qualifies\nthem as progenitors of local massive early-type galaxies. Redshift evolution of\nstellar population ages in quenched galaxies combined with low redshift\nmeasurements from the literature suggests a formation redshift of $z_\\mathrm{f}\n\\sim 2.3$ around which the bulk of stars in these galaxies have been formed.\nThe measured [$\\alpha$/Fe] value indicates a star formation timescale of\n$\\lesssim 1$ Gyr, which can be translated into a specific star formation rate\nof $\\simeq 1\\,\\mathrm{Gyr}^{-1}$ prior to quenching. Based on these findings,\nwe discuss identifying possible progenitor star-forming galaxies at $z \\simeq\n2.3$. We identify normal star-forming galaxies, i.e, those on the star-forming\nmain sequence, followed by a rapid quenching event, as likely precursors of the\nquenched galaxies at $\\langle z \\rangle = 1.6$ presented here. \n\n"}
{"id": "1411.5433", "contents": "Title: Using Volunteer Computing for Mounting SAT-based Cryptographic Attacks Abstract: In this paper we describe the volunteer computing project SAT@home, developed\nand maintained by us. This project is aimed at solving hard instances of the\nBoolean satisfiability problem (SAT). We believe that this project can be a\nuseful tool for computational study of inversion problems of some cryptographic\nfunctions. In particular we describe a series of experiments performed in\nSAT@home on the cryptanalysis of the widely known keystream generator A5/1. In\nall experiments we analyzed one known burst (114 bits) of keystream produced by\nA5/1. Before the cryptanalysis itself there is a stage on which the\npartitioning of the original problem to a family of subproblems is carried out.\nEach of subproblems should be easy enough so that it could be solved in\nrelatively small amount of time by volunteer's PC. We construct such\npartitioning using the special technique based on the Monte Carlo method and\ndiscrete optimization algorithms for special predictive functions. Besides this\nin the paper we describe the technique for reducing inversion problems of\ncryptographic functions to SAT. \n\n"}
{"id": "1412.0041", "contents": "Title: FairCache: Introducing Fairness to ICN Caching - Technical Report Abstract: Information-centric networking extensively uses universal in-network caching.\nHowever, developing an efficient and fair collaborative caching algorithm for\nselfish caches is still an open question. In addition, the communication\noverhead induced by collaboration is especially poorly understood in a general\nnetwork setting such as realistic ISP and Autonomous System networks. In this\npaper, we address these two problems by modeling the in-network caching problem\nas a Nash bargaining game. We show that the game is a convex optimization\nproblem and further derive the corresponding distributed algorithm. We\nanalytically investigate the collaboration overhead on general graph\ntopologies, and theoretically show that collaboration has to be constrained\nwithin a small neighborhood due to its cost growing exponentially. Our proposed\nalgorithm achieves at least 16% performance gain over its competitors on\ndifferent network topologies in the evaluation, and guarantees provable\nconvergence, Pareto efficiency and proportional fairness. \n\n"}
{"id": "1412.1107", "contents": "Title: Lotka Volterra in fluctuating environment or \"how switching between\n  beneficial environments can make survival harder\" Abstract: We consider two dimensional Lotka-Volterra systems in fluctuating\nenvironment. Relying on recent results on stochastic persistence and piecewise\ndeterministic Markov processes, we show that random switching between two\nenvironments both favorable to the same species can lead to the extinction of\nthis species or coexistence of the species. \n\n"}
{"id": "1412.1949", "contents": "Title: Dynamical Tuning of Energy Transfer Efficiency on a Graphene Monolayer Abstract: We present in this contribution a theoretical investigation of the\nspontaneous emission and energy transfer rates between quantum systems placed\nabove a monolayer of conducting graphene. The conditions for strong and weak\ncoupling between a quantum system and the surface plasmon-polariton of graphene\nare determined and, subsequently, we focus exclusively on the weak coupling\nregime. We then calculate the dispersion relation of the surface plasmon mode\non graphene and, by varying the chemical potential, show a good control of its\nresonance frequency. Using a Green's tensor formalism, we calculate the\nspontaneous emission and energy transfer rates of quantum systems placed near\nthe graphene monolayer. The spontaneous emission rate of a single quantum\nsystem is enhanced by several orders of magnitude close to the graphene\nmonolayer and we show that this enhancement is due almost exclusively to\nexcitation of the surface plasmon mode. When considering the energy transfer\nrate between two quantum systems, we find a similar enhancement of several\norders of magnitude close to the graphene monolayer. The direct interaction\nbetween the donor and acceptor dominates when they are close to each other, but\nis modified from its free-space behavior due to the presence of the graphene\nmonolayer. As the donor-acceptor separation is increased, their direct\ninteraction is overshadowed by the interaction via the surface plasmon mode.\nDue to the large propagation length of surface plasmon mode on graphene --\nhundreds of nanometers -- this enhancement of the energy transfer rate holds\nover large donor-acceptor separations along the graphene monolayer. \n\n"}
{"id": "1412.2123", "contents": "Title: Distributed Multi-Depot Routing without Communications Abstract: We consider and formulate a class of distributed multi-depot routing\nproblems, where servers are to visit a set of requests, with the aim of\nminimizing the total distance travelled by all servers. These problems fall\ninto two categories: distributed offline routing problems where all the\nrequests that need to be visited are known from the start; distributed online\nrouting problems where the requests come to be known incrementally. A critical\nand novel feature of our formulations is that communications are not allowed\namong the servers, hence posing an interesting and challenging question: what\nperformance can be achieved in comparison to the best possible solution\nobtained from an omniscience planner with perfect communication capabilities?\nThe worst-case (over all possible request-set instances) performance metrics\nare given by the approximation ratio (offline case) and the competitive ratio\n(online case).\n  Our first result indicates that the online and offline problems are\neffectively equivalent: for the same request-set instance, the approximation\nratio and the competitive ratio differ by at most an additive factor of 2,\nirrespective of the release dates in the online case. Therefore, we can\nrestrict our attention to the offline problem. For the offline problem, we show\nthat the approximation ratio given by the Voronoi partition is m (the number of\nservers). For two classes of depot configurations, when the depots form a line\nand when the ratios between the distances of pairs of depots are upper bounded\nby a sublinear function f(m) (i.e., f(m) = o(m)), we give partition schemes\nwith sublinear approximation ratios O(log m) and {\\Theta}(f(m)) respectively.\nWe also discuss several interesting open problems in our formulations: in\nparticular, how our initial results (on the two deliberately chosen classes of\ndepots) shape our conjecture on the open problems. \n\n"}
{"id": "1412.3022", "contents": "Title: Fast Product-Matrix Regenerating Codes Abstract: Distributed storage systems support failures of individual devices by the use\nof replication or erasure correcting codes. While erasure correcting codes\noffer a better storage efficiency than replication for similar fault tolerance,\nthey incur higher CPU consumption, higher network consumption and higher disk\nI/Os. To address these issues, codes specific to storage systems have been\ndesigned. Their main feature is the ability to repair a single lost disk\nefficiently. In this paper, we focus on one such class of codes that minimize\nnetwork consumption during repair, namely regenerating codes. We implement the\noriginal Product-Matrix Regenerating codes as well as a new optimization we\npropose and show that the resulting optimized codes allow achieving 790 MB/s\nfor encoding in typical settings. Reported speeds are significantly higher than\nprevious studies, highlighting that regenerating codes can be used with little\nCPU penalty. \n\n"}
{"id": "1412.5185", "contents": "Title: Minimum Core Masses for Giant Planet Formation With Realistic Equations\n  of State and Opacities Abstract: Giant planet formation by core accretion requires a core that is sufficiently\nmassive to trigger runaway gas accretion in less that the typical lifetime of\nprotoplanetary disks. We explore how the minimum required core mass, M_crit,\ndepends on a non-ideal equation of state and on opacity changes due to grain\ngrowth, across a range of stellocentric distances from 5-100 AU. This minimum\nM_crit applies when planetesimal accretion does not substantially heat the\natmosphere. Compared to an ideal gas polytrope, the inclusion of molecular\nhydrogen (H_2) dissociation and variable occupation of H_2 rotational states\nincreases M_crit. Specifically, M_crit increases by a factor of ~2 if the H_2\nspin isomers, ortho- and parahydrogen, are in thermal equilibrium, and by a\nfactor of ~2-4 if the ortho-to-para ratio is fixed at 3:1. Lower opacities due\nto grain growth reduce M_crit. For a standard disk model around a Solar mass\nstar, we calculate M_crit ~ 8 M_Earth at 5 AU, decreasing to ~5 M_Earth at 100\nAU, for a realistic EOS with an equilibrium ortho-to-para ratio and for grain\ngrowth to cm-sizes. If grain coagulation is taken into account, M_crit may\nfurther reduce by up to one order of magnitude. These results for the minimum\ncritical core mass are useful for the interpretation of surveys that find\nexoplanets at a range of orbital distances. \n\n"}
{"id": "1412.7116", "contents": "Title: Online Distributed ADMM on Networks Abstract: This paper examines online distributed Alternating Direction Method of\nMultipliers (ADMM). The goal is to distributively optimize a global objective\nfunction over a network of decision makers under linear constraints. The global\nobjective function is composed of convex cost functions associated with each\nagent. The local cost functions, on the other hand, are assumed to have been\ndecomposed into two distinct convex functions, one of which is revealed to the\ndecision makers over time and one known a priori. In addition, the agents must\nachieve consensus on the global variable that relates to the private local\nvariables via linear constraints. In this work, we extend online ADMM to a\ndistributed setting based on dual-averaging and distributed gradient descent.\nWe then propose a performance metric for such online distributed algorithms and\nexplore the performance of the sequence of decisions generated by the algorithm\nas compared with the best fixed decision in hindsight. This performance metric\nis called the social regret. A sub-linear upper bound on the social regret of\nthe proposed algorithm is then obtained that underscores the role of the\nunderlying network topology and certain condition measures associated with the\nlinear constraints. The online distributed ADMM algorithm is then applied to a\nformation acquisition problem demonstrating the application of the proposed\nsetup in distributed robotics. \n\n"}
{"id": "1412.7935", "contents": "Title: Bitcoin Meets Strong Consistency Abstract: The Bitcoin system only provides eventual consistency. For everyday life, the\ntime to confirm a Bitcoin transaction is prohibitively slow. In this paper we\npropose a new system, built on the Bitcoin blockchain, which enables strong\nconsistency. Our system, PeerCensus, acts as a certification authority, manages\npeer identities in a peer-to-peer network, and ultimately enhances Bitcoin and\nsimilar systems with strong consistency. Our extensive analysis shows that\nPeerCensus is in a secure state with high probability. We also show how\nDiscoin, a Bitcoin variant that decouples block creation and transaction\nconfirmation, can be built on top of PeerCensus, enabling real-time payments.\nUnlike Bitcoin, once transactions in Discoin are committed, they stay\ncommitted. \n\n"}
{"id": "1412.8324", "contents": "Title: A Constructive Proof on the Compositionality of Linearizability Abstract: Linearizability is the strongest correctness property for both shared memory\nand message passing systems. One of its useful features is the\ncompositionality: a history (execution) is linearizable if and only if each\nobject (component) subhistory is linearizable. In this paper, we propose a new\nhierarchical system model to address challenges in modular development of cloud\nsystems. Object are defined by induction from the most fundamental atomic\nBoolean registers, and histories are represented as countable well-ordered\nstructures of events to deal with both finite and infinite executions. Then, we\npresent a new constructive proof on the compositionality theorem of\nlinearizability inspired by Multiway Merge. This proof deduces a theoretically\nefficient algorithm which generates linearization in O(N*logP) running time\nwith O(N) space, where P and N are process/event numbers respectively. \n\n"}
{"id": "1501.00203", "contents": "Title: Small Cell Traffic Balancing Over Licensed and Unlicensed Bands Abstract: The 3rd Generation Partnership Project (3GPP) recently started standardizing\nthe \"Licensed-Assisted Access using LTE\" for small cells, referred to as Dual\nBand Femtocell (DBF) in this paper, which uses LTE air interface in both\nlicensed and unlicensed bands based on the Long Term Evolution (LTE) carrier\naggregation feature. Alternatively, the Small Cell Forum introduced the\nIntegrated Femto-WiFi (IFW) small cell which simultaneously accesses both the\nlicensed band (via cellular interface) and the unlicensed band (via WiFi\ninterface). In this paper, a practical algorithm for IFW and DBF to\nautomatically balance their traffic in licensed and unlicensed bands, based on\nthe real-time channel, interference and traffic conditions of both bands is\ndescribed. The algorithm considers the fact that some \"smart\" devices\n(sDevices) have both cellular and WiFi radios while some WiFi-only devices\n(wDevices) may only have WiFi radio. In addition, the algorithm considers a\nrealistic scenario where a single small cell user may simultaneously use\nmultiple sDevices and wDevices via either the IFW, or the DBF in conjunction\nwith a Wireless Local Area Network (WLAN). The goal is to maximize the total\nuser satisfaction/utility of the small cell user, while keeping the\ninterference from small cell to macrocell below predefined thresholds. The\nalgorithm can be implemented at the Radio Link Control (RLC) or the network\nlayer of the IFW and DBF small cell base stations. Results demonstrate that the\nproposed traffic-balancing algorithm applied to either IFW or DBF significantly\nincreases sum utility of all macrocell and small cell users, compared with the\ncurrent practices. Finally, various implementation issues of IFW and DBF are\naddressed. \n\n"}
{"id": "1501.00846", "contents": "Title: Effective Dark Matter Halo catalog in $f(R)$ gravity Abstract: We introduce the idea of {\\it effective} dark matter halo catalog in $f(R)$\ngravity, which is built using the {\\it effective} density field. Using a suite\nof high resolution N-body simulations, we find that the dynamical properties of\nhalos, such as the distribution of density, velocity dispersion, specific\nangular momentum and spin, in the effective catalog of $f(R)$ gravity closely\nmimic those in the $\\Lambda$CDM model. Thus, when using effective halos, an\n$f(R)$ model can be viewed as a $\\Lambda$CDM model. This effective catalog\ntherefore provides a convenient way for studying the baryonic physics, the\ngalaxy halo occupation distribution and even semi-analytical galaxy formation\nin $f(R)$ cosmologies. \n\n"}
{"id": "1501.02729", "contents": "Title: On the Energy Proportionality of Scale-Out Workloads Abstract: Our increasing reliance on the cloud has led to the emergence of scale-out\nworkloads. These scale-out workloads are latency-sensitive as they are user\ndriven. In order to meet strict latency constraints, they require massive\ncomputing infrastructure, which consume significant amount of energy and\ncontribute to operational costs. This cost is further aggravated by the lack of\nenergy proportionality in servers. As Internet services become even more\nubiquitous, scale-out workloads will need increasingly larger cluster\ninstallations. As such, we desire an investigation into the energy\nproportionality and the mechanisms to improve the power consumption of\nscale-out workloads.\n  Therefore, in this paper, we study the energy proportionality and power\nconsumption of clusters in the context of scale-out workloads. Towards this\nend, we evaluate the potential of power and resource provisioning to improve\nthe energy proportionality for this class of workloads. Using data serving, web\nsearching and data caching as our representative workloads, we first analyze\nthe component-level power distribution on a cluster. Second, we characterize\nhow these workloads utilize the cluster. Third, we analyze the potential of\npower provisioning techniques (i.e., active low-power, turbo and idle low-power\nmodes) to improve the energy proportionality of scale-out workloads. We then\ndescribe the ability of active low-power modes to provide trade-offs in power\nand latency. Finally, we compare and contrast power provisioning and resource\nprovisioning techniques. Our study reveals various insights which will help\nimprove the energy proportionality and power consumption of scale-out\nworkloads. \n\n"}
{"id": "1501.04037", "contents": "Title: Sine-Gordon breathers generation in driven long Josephson junctions Abstract: We consider a long Josephson junction excited by a suitable external\nac-signal, in order to generate control and detect breathers. Studying the\nnonlinear supratransmission phenomenon in a nonlinear sine-Gordon chain\nsinusoidally driven, Geniet and Leon explored the bifurcation of the energy\ntransmitted into the chain and calculated a threshold $A (\\omega)$ for the\nexternal driving signal amplitude, at which the energy flows into the system by\nbreathers modes. I numerically study the continuous sine-Gordon model,\ndescribing the dynamics of the phase difference in a long Josephson junction,\nin order to deeply investigate the \"continuous limit\" modifications to this\nthreshold. Wherever the energy flows into the system due to the nonlinear\nsupratransmission, a peculiar breather localization areas appear in a $(A,\n\\omega)$ parameters space. The emergence of these areas depends on the damping\nparameter value, the bias current, and the waveform of driving external signal.\nThe robustness of generated breathers is checked by introducing into the model\na thermal noise source to mimic the environmental fluctuations. Presented\nresults allows one to consider a cryogenic experiment for creation and\ndetection of Josephson breathers. \n\n"}
{"id": "1501.04784", "contents": "Title: Global finite element matrix construction based on a CPU-GPU\n  implementation Abstract: The finite element method (FEM) has several computational steps to\nnumerically solve a particular problem, to which many efforts have been\ndirected to accelerate the solution stage of the linear system of equations.\nHowever, the finite element matrix construction, which is also time-consuming\nfor unstructured meshes, has been less investigated. The generation of the\nglobal finite element matrix is performed in two steps, computing the local\nmatrices by numerical integration and assembling them into a global system,\nwhich has traditionally been done in serial computing. This work presents a\nfast technique to construct the global finite element matrix that arises by\nsolving the Poisson's equation in a three-dimensional domain. The proposed\nmethodology consists in computing the numerical integration, due to its\nintrinsic parallel opportunities, in the graphics processing unit (GPU) and\ncomputing the matrix assembly, due to its intrinsic serial operations, in the\ncentral processing unit (CPU). In the numerical integration, only the lower\ntriangular part of each local stiffness matrix is computed thanks to its\nsymmetry, which saves GPU memory and computing time. As a result of symmetry,\nthe global sparse matrix also contains non-zero elements only in its lower\ntriangular part, which reduces the assembly operations and memory usage. This\nmethodology allows generating the global sparse matrix from any unstructured\nfinite element mesh size on GPUs with little memory capacity, only limited by\nthe CPU memory. \n\n"}
{"id": "1501.06663", "contents": "Title: On Longest Repeat Queries Using GPU Abstract: Repeat finding in strings has important applications in subfields such as\ncomputational biology. The challenge of finding the longest repeats covering\nparticular string positions was recently proposed and solved by \\.{I}leri et\nal., using a total of the optimal $O(n)$ time and space, where $n$ is the\nstring size. However, their solution can only find the \\emph{leftmost} longest\nrepeat for each of the $n$ string position. It is also not known how to\nparallelize their solution. In this paper, we propose a new solution for\nlongest repeat finding, which although is theoretically suboptimal in time but\nis conceptually simpler and works faster and uses less memory space in practice\nthan the optimal solution. Further, our solution can find \\emph{all} longest\nrepeats of every string position, while still maintaining a faster processing\nspeed and less memory space usage. Moreover, our solution is\n\\emph{parallelizable} in the shared memory architecture (SMA), enabling it to\ntake advantage of the modern multi-processor computing platforms such as the\ngeneral-purpose graphics processing units (GPU). We have implemented both the\nsequential and parallel versions of our solution. Experiments with both\nbiological and non-biological data show that our sequential and parallel\nsolutions are faster than the optimal solution by a factor of 2--3.5 and 6--14,\nrespectively, and use less memory space. \n\n"}
{"id": "1501.07800", "contents": "Title: Locality-aware parallel block-sparse matrix-matrix multiplication using\n  the Chunks and Tasks programming model Abstract: We present a method for parallel block-sparse matrix-matrix multiplication on\ndistributed memory clusters. By using a quadtree matrix representation, data\nlocality is exploited without prior information about the matrix sparsity\npattern. A distributed quadtree matrix representation is straightforward to\nimplement due to our recent development of the Chunks and Tasks programming\nmodel [Parallel Comput. 40, 328 (2014)]. The quadtree representation combined\nwith the Chunks and Tasks model leads to favorable weak and strong scaling of\nthe communication cost with the number of processes, as shown both\ntheoretically and in numerical experiments.\n  Matrices are represented by sparse quadtrees of chunk objects. The leaves in\nthe hierarchy are block-sparse submatrices. Sparsity is dynamically detected by\nthe matrix library and may occur at any level in the hierarchy and/or within\nthe submatrix leaves. In case graphics processing units (GPUs) are available,\nboth CPUs and GPUs are used for leaf-level multiplication work, thus making use\nof the full computing capacity of each node.\n  The performance is evaluated for matrices with different sparsity structures,\nincluding examples from electronic structure calculations. Compared to methods\nthat do not exploit data locality, our locality-aware approach reduces\ncommunication significantly, achieving essentially constant communication per\nnode in weak scaling tests. \n\n"}
{"id": "1502.01788", "contents": "Title: Single crystal diamond nanobeam waveguide optomechanics Abstract: Optomechanical devices sensitively transduce and actuate motion of\nnanomechanical structures using light. Single--crystal diamond promises to\nimprove the performance of optomechanical devices, while also providing\nopportunities to interface nanomechanics with diamond color center spins and\nrelated quantum technologies. Here we demonstrate dissipative\nwaveguide--optomechanical coupling exceeding 35 GHz/nm to diamond nanobeams\nsupporting both optical waveguide modes and mechanical resonances, and use this\noptomechanical coupling to measure nanobeam displacement with a sensitivity of\n$9.5$ fm/$\\sqrt{\\text{Hz}}$ and optical bandwidth $>150$nm. The nanobeams are\nfabricated from bulk optical grade single--crystal diamond using a scalable\nundercut etching process, and support mechanical resonances with quality factor\n$2.5 \\times 10^5$ at room temperature, and $7.2 \\times 10^5$ in cryogenic\nconditions (5K). Mechanical self--oscillations, resulting from interplay\nbetween photothermal and optomechanical effects, are observed with amplitude\nexceeding 200 nm for sub-$\\mu$W absorbed optical power, demonstrating the\npotential for optomechanical excitation and manipulation of diamond\nnanomechanical structures. \n\n"}
{"id": "1502.02117", "contents": "Title: Simulations of reflected radio signals from cosmic ray induced air\n  showers Abstract: We present the calculation of coherent radio pulses emitted by extensive air\nshowers induced by ultra-high energy cosmic rays accounting for reflection on\nthe Earth's surface. Results have been obtained with a simulation program that\ncalculates the contributions from shower particles after reflection at a\nsurface plane. The properties of the radiation are discussed in detail\nemphasizing the effects of reflection. The shape of the frequency spectrum is\nshown to be closely related to the angle of the observer with respect to shower\naxis, becoming hardest in the Cherenkov direction. The intensity of the flux at\na fixed observation angle is shown to scale with the square of the primary\nparticle energy to very good accuracy indicating the coherent aspect of the\nemission. The simulation methods of this paper provide the foundations for\nenergy reconstruction of experiments looking at the Earth from balloons and\nsatellites. They can also be used in dedicated studies of existing and future\nexperimental proposals. \n\n"}
{"id": "1502.03504", "contents": "Title: Locally-Oriented Programming: A Simple Programming Model for\n  Stencil-Based Computations on Multi-Level Distributed Memory Architectures Abstract: Emerging hybrid accelerator architectures for high performance computing are\noften suited for the use of a data-parallel programming model. Unfortunately,\nprogrammers of these architectures face a steep learning curve that frequently\nrequires learning a new language (e.g., OpenCL). Furthermore, the distributed\n(and frequently multi-level) nature of the memory organization of clusters of\nthese machines provides an additional level of complexity. This paper presents\npreliminary work examining how programming with a local orientation can be\nemployed to provide simpler access to accelerator architectures. A\nlocally-oriented programming model is especially useful for the solution of\nalgorithms requiring the application of a stencil or convolution kernel. In\nthis programming model, a programmer codes the algorithm by modifying only a\nsingle array element (called the local element), but has read-only access to a\nsmall sub-array surrounding the local element. We demonstrate how a\nlocally-oriented programming model can be adopted as a language extension using\nsource-to-source program transformations. \n\n"}
{"id": "1502.03645", "contents": "Title: Numerical simulation of skin transport using Parareal Abstract: In-silico investigation of skin permeation is an important but also\ncomputationally demanding problem. To resolve all scales involved in full\ndetail will not only require exascale computing capacities but also suitable\nparallel algorithms. This article investigates the applicability of the\ntime-parallel Parareal algorithm to a brick and mortar setup, a precursory\nproblem to skin permeation. The C++ library Lib4PrM implementing Parareal is\ncombined with the UG4 simulation framework, which provides the spatial\ndiscretization and parallelization. The combination's performance is studied\nwith respect to convergence and speedup. It is confirmed that anisotropies in\nthe domain and jumps in diffusion coefficients only have a minor impact on\nParareal's convergence. The influence of load imbalances in time due to\ndifferences in number of iterations required by the spatial solver as well as\nspatio-temporal weak scaling is discussed. \n\n"}
{"id": "1502.05968", "contents": "Title: Scheduling Storms and Streams in the Cloud Abstract: Motivated by emerging big streaming data processing paradigms (e.g., Twitter\nStorm, Streaming MapReduce), we investigate the problem of scheduling graphs\nover a large cluster of servers. Each graph is a job, where nodes represent\ncompute tasks and edges indicate data-flows between these compute tasks. Jobs\n(graphs) arrive randomly over time, and upon completion, leave the system. When\na job arrives, the scheduler needs to partition the graph and distribute it\nover the servers to satisfy load balancing and cost considerations.\nSpecifically, neighboring compute tasks in the graph that are mapped to\ndifferent servers incur load on the network; thus a mapping of the jobs among\nthe servers incurs a cost that is proportional to the number of \"broken edges\".\nWe propose a low complexity randomized scheduling algorithm that, without\nservice preemptions, stabilizes the system with graph arrivals/departures; more\nimportantly, it allows a smooth trade-off between minimizing average\npartitioning cost and average queue lengths. Interestingly, to avoid service\npreemptions, our approach does not rely on a Gibbs sampler; instead, we show\nthat the corresponding limiting invariant measure has an interpretation\nstemming from a loss system. \n\n"}
{"id": "1502.07118", "contents": "Title: Local Linearizability Abstract: The semantics of concurrent data structures is usually given by a sequential\nspecification and a consistency condition. Linearizability is the most popular\nconsistency condition due to its simplicity and general applicability.\nNevertheless, for applications that do not require all guarantees offered by\nlinearizability, recent research has focused on improving performance and\nscalability of concurrent data structures by relaxing their semantics.\n  In this paper, we present local linearizability, a relaxed consistency\ncondition that is applicable to container-type concurrent data structures like\npools, queues, and stacks. While linearizability requires that the effect of\neach operation is observed by all threads at the same time, local\nlinearizability only requires that for each thread T, the effects of its local\ninsertion operations and the effects of those removal operations that remove\nvalues inserted by T are observed by all threads at the same time. We\ninvestigate theoretical and practical properties of local linearizability and\nits relationship to many existing consistency conditions. We present a generic\nimplementation method for locally linearizable data structures that uses\nexisting linearizable data structures as building blocks. Our implementations\nshow performance and scalability improvements over the original building blocks\nand outperform the fastest existing container-type implementations. \n\n"}
{"id": "1503.03044", "contents": "Title: Unifying Brillouin scattering and cavity optomechanics Abstract: So far, Brillouin scattering and cavity optomechanics were mostly\ndisconnected branches of research -- although both deal with photon-phonon\ncoupling. This begs for the development of a broader theory that contains both\nfields. Here, we derive the dynamics of optomechanical cavities from that of\nBrillouin-active waveguides. This explicit transition elucidates the link\nbetween phenomena such as Brillouin amplification and electromagnetically\ninduced transparency. It proves that effects familiar from cavity optomechanics\nall have traveling-wave partners, but not vice versa. We reveal a close\nconnection between two parameters of central importance in these fields: the\nBrillouin gain coefficient and the zero-point optomechanical coupling rate.\nThis enables comparisons between systems as diverse as ultracold atom clouds,\nplasmonic Raman cavities and nanoscale silicon waveguides. In addition,\nback-of-the-envelope calculations show that unobserved effects, such as\nphoton-assisted amplification of traveling phonons, are now accessible in\nexisting systems. Finally, we formulate both circuit- and cavity-oriented\noptomechanics in terms of vacuum coupling rates, cooperativities and gain\ncoefficients, thus reflecting the similarities in the underlying physics. \n\n"}
{"id": "1503.03172", "contents": "Title: Distinguishing types of compact-object binaries using the\n  gravitational-wave signatures of their mergers Abstract: We analyze the distinguishability of populations of coalescing binary neutron\nstars, neutron-star black-hole binaries, and binary black holes, whose\ngravitational-wave signatures are expected to be observed by the advanced\nnetwork of ground-based interferometers LIGO and Virgo. We consider\npopulation-synthesis predictions for plausible merging binary distributions in\nmass space, along with measurement accuracy estimates from the main\ngravitational-wave parameter-estimation pipeline. We find that for our model\ncompact-object binary mass distribution, we can always distinguish binary\nneutron stars and black-hole--neutron-star binaries, but not necessarily\nblack-hole--neutron-star binaries and binary black holes; however, with a few\ntens of detections, we can accurately identify the three subpopulations and\nmeasure their respective rates. \n\n"}
{"id": "1503.05434", "contents": "Title: Compressed Differential Erasure Codes for Efficient Archival of\n  Versioned Data Abstract: In this paper, we study the problem of storing an archive of versioned data\nin a reliable and efficient manner in distributed storage systems. We propose a\nnew storage technique called differential erasure coding (DEC) where the\ndifferences (deltas) between subsequent versions are stored rather than the\nwhole objects, akin to a typical delta encoding technique. However, unlike\ndelta encoding techniques, DEC opportunistically exploits the sparsity (i.e.,\nwhen the differences between two successive versions have few non-zero entries)\nin the updates to store the deltas using compressed sensing techniques applied\nwith erasure coding. We first show that DEC provides significant savings in the\nstorage size for versioned data whenever the update patterns are characterized\nby in-place alterations. Subsequently, we propose a practical DEC framework so\nas to reap storage size benefits against not just in-place alterations but also\nreal-world update patterns such as insertions and deletions that alter the\noverall data sizes. We conduct experiments with several synthetic workloads to\ndemonstrate that the practical variant of DEC provides significant reductions\nin storage overhead (up to 60\\% depending on the workload) compared to baseline\nstorage system which incorporates concepts from Rsync, a delta encoding\ntechnique to store and synchronize data across a network. \n\n"}
{"id": "1503.06994", "contents": "Title: Global dynamics and asymptotics for monomial scalar field potentials and\n  perfect fluids Abstract: We consider a minimally coupled scalar field with a monomial potential and a\nperfect fluid in flat FLRW cosmology. We apply local and global dynamical\nsystems techniques to a new three-dimensional dynamical systems reformulation\nof the field equations on a compact state space. This leads to a visual global\ndescription of the solution space and asymptotic behavior. At late times we\nemploy averaging techniques to prove statements about how the relationship\nbetween the equation of state of the fluid and the monomial exponent of the\nscalar field affects asymptotic source dominance and asymptotic manifest\nself-similarity breaking. We also situate the `attractor' solution in the\nthree-dimensional state space and show that it corresponds to the\none-dimensional unstable center manifold of a de Sitter fixed point, located on\nan unphysical boundary associated with the dynamics at early times. By deriving\na center manifold expansion we obtain approximate expressions for the attractor\nsolution. We subsequently improve the accuracy and range of the approximation\nby means of Pad\\'e approximants and compare with the slow-roll approximation. \n\n"}
{"id": "1503.07683", "contents": "Title: Application of the Hamiltonian formulation to nonlinear light-envelope\n  propagations Abstract: A new approach, which is based on the new canonical equations of Hamilton\nfound by us recently, is presented to analytically obtain the approximate\nsolution of the nonlocal nonlinear Schr\\\"{o}dinger equation (NNLSE). The\napproximate analytical soliton solution of the NNLSE can be obtained, and the\nstability of the soliton can be analytically analysed in the simple way as\nwell, all of which are consistent with the results published earlier. For the\nsingle light-envelope propagated in nonlocal nonlinear media modeled by the\nNNLSE, the Hamiltonian of the system can be constructed, which is the sum of\nthe generalized kinetic energy and the generalized potential. The extreme point\nof the generalized potential corresponds to the soliton solution of the NNLSE.\nThe soliton is stable when the generalized potential has the minimum, and\nunstable otherwise. In addition, the rigorous proof of the equivalency between\nthe NNLSE and the Euler-Lagrange equation is given on the premise of the\nresponse function with even symmetry. \n\n"}
{"id": "1504.00938", "contents": "Title: Surface plasmon-polaritons in periodic arrays of V-grooves strongly\n  coupled to quantum emitters Abstract: We investigate the optical response of a system consisting of periodic silver\nV-grooves interacting with quantum emitters. Two surface plasmon-polariton\nresonances are identified in the reflection spectrum of bare silver grooves,\nwith the intensity of one resonance being localized near the bottom of the\ngroove and that of the other resonance being distributed throughout the entire\ngroove. The linear response of the hybrid silver-emitter system is thoroughly\nanalyzed by considering the coupling between surface plasmon polaritons and\nemitters as the geometry of the grooves and the spatial distribution of\nemitters within the grooves are varied. The nonlinear response of the system is\nalso considered by pumping the emitters with a short, high-intensity pulse. By\nchanging the duration or the intensity of the pump, the population of emitters\nin the ground state at the end of the pump is varied, and it is found (upon\nprobing with a short pulse) that an increase in the fraction of emitters in the\nground state corresponds to an increase in Rabi splitting. Spatial variations\nin the ground state population throughout the emitter region are shown to be a\nresult of field retardation. \n\n"}
{"id": "1504.01452", "contents": "Title: The Performance Analysis of Coded Cache in Wireless Fading Channel Abstract: The rapid growth of data volume and the accompanying congestion problems over\nthe wireless networks have been critical issues to content providers. A novel\ntechnique, termed as coded cache, is proposed to relieve the burden. Through\ncreating coded-multicasting opportunities, the coded-cache scheme can provide\nextra performance gain over the conventional push technique that simply\npre-stores contents at local caches during the network idle period. But\nexisting works on the coded caching scheme assumed the availability of an\nerror-free shared channel accessible by each user. This paper considers the\nmore realistic scenario where each user may experience different link quality.\nIn this case, the system performance would be restricted by the user with the\nworst channel condition. And the corresponding resource allocation schemes\naimed at breaking this obstacles are developed. Specifically, we employ the\ncoded caching scheme in time division and frequency division transmission mode\nand formulate the sub-optimal problems. Power and bandwidth are allocated\nrespectively to maximum the system throughput. The simulation results show that\nthe throughput of the technique in wireless scenario will be limited and would\ndecrease as the number of users becomes sufficiently large. \n\n"}
{"id": "1504.01828", "contents": "Title: A Cloud Infrastructure Service Recommendation System for Optimizing\n  Real-time QoS Provisioning Constraints Abstract: Proliferation of cloud computing has revolutionized hosting and delivery of\nInternet-based application services. However, with the constant launch of new\ncloud services and capabilities almost every month by both big (e.g., Amazon\nWeb Service, Microsoft Azure) and small companies (e.g. Rackspace, Ninefold),\ndecision makers (e.g. application developers, CIOs) are likely to be\noverwhelmed by choices available. The decision making problem is further\ncomplicated due to heterogeneous service configurations and application\nprovisioning Quality of Service (QoS) constraints. To address this hard\nchallenge, in our previous work we developed a semi-automated, extensible, and\nontology-based approach to infrastructure service discovery and selection based\non only design time constraints (e.g., renting cost, datacentre location,\nservice feature, etc.). In this paper, we extend our approach to include the\nreal-time (run-time) QoS (endto- end message latency, end-to-end message\nthroughput) in the decision making process. Hosting of next generation\napplications in domain of on-line interactive gaming, large scale sensor\nanalytics, and real-time mobile applications on cloud services necessitates\noptimization of such real-time QoS constraints for meeting Service Level\nAgreements (SLAs). To this end, we present a real-time QoS aware multi-criteria\ndecision making technique that builds over well known Analytics Hierarchy\nProcess (AHP) method. The proposed technique is applicable to selecting\nInfrastructure as a Service (IaaS) cloud offers, and it allows users to define\nmultiple design-time and real-time QoS constraints or requirements. These\nrequirements are then matched against our knowledge base to compute possible\nbest fit combinations of cloud services at IaaS layer. We conducted extensive\nexperiments to prove the feasibility of our approach. \n\n"}
{"id": "1504.01845", "contents": "Title: Possible Signatures of Ejecta-Companion Interaction in iPTF 13bvn Abstract: We investigate the possible effects of the supernova ejecta hitting the\ncompanion star in iPTF 13bvn, focusing on the observable features when it\nbecomes visible. iPTF 13bvn is a type Ib supernova that may become the first\ncase that its progenitor is identified as a binary by near future observations.\nAccording to calculations by Bersten et al. (2014), the progenitor should have\na mass $\\approx3.5M_\\odot$ to reproduce the supernova light curve, and such\ncompact stars could only be produced via binary evolution. This is one of the\nreasons that we expect the progenitor to be a binary, but it should be\nconfirmed by observing the remaining companion after the supernova. Their\nevolutionary calculations suggest that the companion star will be an\noverluminous OB star at the moment of supernova. With a combination of\nhydrodynamical and evolutionary simulations, we find that the secondary star\nwill be heated by the supernova ejecta and expand to have larger luminosities\nand lower surface effective temperatures. The star will look rather like a red\nsuper giant, and this should be taken into account when searching for the\ncompanion star in the supernova ejecta in future observations. \n\n"}
{"id": "1504.02130", "contents": "Title: 2-dimensional hyperbolic medium for electrons and photons based on the\n  array of tunnel-coupled graphene nanoribbons Abstract: We study the electronic band structure and optical conductivity of an array\nof tunnel-coupled array of graphene nanoribbons. We show that due to the\ncoupling of electronic edge states for the zigzag nanoribbon structure, the\nFermi surface can become a hyperbola similarly to the case of the layered\nmetal-dielectric structures, where the hyperbolic isofrequency contours\noriginate from the coupling of localized surface plasmon polaritons. Moreover,\nwe show that for both types of the ribbon edge, the optical response of the\nstructure can be characterized by a uniaxial conductivity tensor, having\nprincipal components of the different signs. Therefore, the tunnel-coupled\nnanoribbon array can be regarded as a tunable hyperbolic metasurface. \n\n"}
{"id": "1504.02147", "contents": "Title: Unwrapping ADMM: Efficient Distributed Computing via Transpose Reduction Abstract: Recent approaches to distributed model fitting rely heavily on consensus\nADMM, where each node solves small sub-problems using only local data. We\npropose iterative methods that solve {\\em global} sub-problems over an entire\ndistributed dataset. This is possible using transpose reduction strategies that\nallow a single node to solve least-squares over massive datasets without\nputting all the data in one place. This results in simple iterative methods\nthat avoid the expensive inner loops required for consensus methods. To\ndemonstrate the efficiency of this approach, we fit linear classifiers and\nsparse linear models to datasets over 5 Tb in size using a distributed\nimplementation with over 7000 cores in far less time than previous approaches. \n\n"}
{"id": "1504.03452", "contents": "Title: Electronic transport in graphene nanoribbons with sublattice-asymmetric\n  doping Abstract: Recent experimental findings and theoretical predictions suggest that\nnitrogen-doped CVD-grown graphene may give rise to electronic band gaps due to\nimpurity distributions which favour segregation on a single sublattice. Here we\ndemonstrate theoretically that such distributions give rise to more complex\nbehaviour in the presence of edges, where geometry determines whether electrons\nin the sample view the impurities as a gap-opening average potential or as\nscatterers. Zigzag edges give rise to the latter case, and remove the\nelectronic bandgaps predicted in extended graphene samples. We predict that\nsuch behaviour will give rise to leakage near grain boundaries with a similar\ngeometry or in zigzag-edged etched devices. Furthermore, we examine the\nformation of one-dimensional metallic channels at interfaces between different\nsublattice domains, which should be observable experimentally and offer\nintriguing waveguiding possibilities. \n\n"}
{"id": "1504.03583", "contents": "Title: The role of real-space micromotion for bosonic and fermionic Floquet\n  fractional Chern insulators Abstract: Fractional Chern insulators are the proposed phases of matter mimicking the\nphysics of fractional quantum Hall states on a lattice without an overall\nmagnetic field. The notion of Floquet fractional Chern insulators refers to the\npotential possibilities to generate the underlying topological bandstructure by\nmeans of Floquet engineering. In these schemes, a highly controllable and\nstrongly interacting system is periodically driven by an external force at a\nfrequency such that double tunneling events during one forcing period become\nimportant and contribute to shaping the required effective energy bands. We\nshow that in the described circumstances it is necessary to take into account\nalso third order processes combining two tunneling events with interactions.\nReferring to the obtained contributions as micromotion-induced interactions, we\nfind that those interactions tend to have a negative impact on the stability of\nof fractional Chern insulating phases and discuss implications for future\nexperiments. \n\n"}
{"id": "1504.07056", "contents": "Title: A Deterministic Almost-Tight Distributed Algorithm for Approximating\n  Single-Source Shortest Paths Abstract: We present a deterministic $(1+o(1))$-approximation\n$(n^{1/2+o(1)}+D^{1+o(1)})$-time algorithm for solving the single-source\nshortest paths problem on distributed weighted networks (the CONGEST model);\nhere $n$ is the number of nodes in the network and $D$ is its (hop) diameter.\nThis is the first non-trivial deterministic algorithm for this problem. It also\nimproves (i) the running time of the randomized $(1+o(1))$-approximation\n$\\tilde O(n^{1/2}D^{1/4}+D)$-time algorithm of Nanongkai [STOC 2014] by a\nfactor of as large as $n^{1/8}$, and (ii) the $O(\\epsilon^{-1}\\log\n\\epsilon^{-1})$-approximation factor of Lenzen and Patt-Shamir's $\\tilde\nO(n^{1/2+\\epsilon}+D)$-time algorithm [STOC 2013] within the same running time.\nOur running time matches the known time lower bound of $\\Omega(n^{1/2}/\\log n +\nD)$ [Elkin STOC 2004] up to subpolynomial factors, thus essentially settling\nthe status of this problem which was raised at least a decade ago [Elkin SIGACT\nNews 2004]. It also implies a $(2+o(1))$-approximation\n$(n^{1/2+o(1)}+D^{1+o(1)})$-time algorithm for approximating a network's\nweighted diameter which almost matches the lower bound by Holzer and Pinsker\n[OPODIS 2015]. In achieving this result, we develop two techniques which might\nbe of independent interest and useful in other settings: (i) a deterministic\nprocess that replaces the \"hitting set argument\" commonly used for shortest\npaths computation in various settings, and (ii) a simple, deterministic,\nconstruction of an $(n^{o(1)}, o(1))$-hop set of size $n^{1+o(1)}$. We combine\nthese techniques with many distributed algorithmic techniques, some of which\nfrom problems that are not directly related to shortest paths, e.g., ruling\nsets [Goldberg et al. STOC 1987], source detection [Lenzen and Peleg PODC\n2013], and partial distance estimation [Lenzen and Patt-Shamir PODC 2015]. \n\n"}
{"id": "1505.00127", "contents": "Title: All-Optical Generation of Surface Plasmons in Graphene Abstract: Here we present an all-optical plasmon coupling scheme, utilising the\nintrinsic nonlinear optical response of graphene. We demonstrate coupling of\nfree-space, visible light pulses to the surface plasmons in a planar,\nun-patterned graphene sheet by using nonlinear wave mixing to match both the\nwavevector and energy of the surface wave. By carefully controlling the\nphase-matching conditions, we show that one can excite surface plasmons with a\ndefined wavevector and direction across a large frequency range, with an\nestimated photon efficiency in our experiments approaching $10^{-5}$. \n\n"}
{"id": "1505.02836", "contents": "Title: Theory and experiments of disorder-induced resonance shifts and mode\n  edge broadening in deliberately disordered photonic crystal waveguides Abstract: We study both theoretically and experimentally the effects of introducing\ndeliberate disorder in a slow-light photonic crystal waveguide on the photon\ndensity of states. We first introduce a theoretical model that includes both\ndeliberate disorder through statistically moving the hole centres in the\nphotonic crystal lattice and intrinsic disorder caused by manufacturing\nimperfections. We demonstrate a disorder-induced mean blueshift and an overall\nbroadening of the photonic density of states for various amounts of deliberate\ndisorder. By comparing with measurements from a GaAs photonic crystal\nwaveguide, we find good qualitative agreement between theory and experiment\nwhich highlights the importance of carefully including local field effects for\nmodelling high-index contrast perturbations. Our work also demonstrates the\nimportance of using asymmetric dielectric polarizabilities for modelling\npositive and negative dielectric perturbations when modelling a perturbed\ndielectric interface in photonic crystal platforms. \n\n"}
{"id": "1505.03460", "contents": "Title: Performance Analysis of Ambient RF Energy Harvesting with Repulsive\n  Point Process Modeling Abstract: Ambient RF (Radio Frequency) energy harvesting technique has recently been\nproposed as a potential solution to provide proactive energy replenishment for\nwireless devices. This paper aims to analyze the performance of a battery-free\nwireless sensor powered by ambient RF energy harvesting using a stochastic\ngeometry approach. Specifically, we consider the point-to-point uplink\ntransmission of a wireless sensor in a stochastic geometry network, where\nambient RF sources, such as mobile transmit devices, access points and base\nstations, are distributed as a Ginibre alpha-determinantal point process (DPP).\nThe DPP is able to capture repulsion among points, and hence, it is more\ngeneral than the Poisson point process (PPP). We analyze two common receiver\narchitectures: separated receiver and time-switching architectures. For each\narchitecture, we consider the scenarios with and without co-channel\ninterference for information transmission. We derive the expectation of the RF\nenergy harvesting rate in closed form and also compute its variance. Moreover,\nwe perform a worst-case study which derives the upper bound of both power and\ntransmission outage probabilities. Additionally, we provide guidelines on the\nsetting of optimal time-switching coefficient in the case of the time-switching\narchitecture. Numerical results verify the correctness of the analysis and show\nvarious tradeoffs between parameter setting. Lastly, we prove that the sensor\nis more efficient when the distribution of the ambient sources exhibits\nstronger repulsion. \n\n"}
{"id": "1505.03509", "contents": "Title: Investigating the Cost of Anonymity on Dynamic Networks Abstract: In this paper we study the difficulty of counting nodes in a synchronous\ndynamic network where nodes share the same identifier, they communicate by\nusing a broadcast with unlimited bandwidth and, at each synchronous round,\nnetwork topology may change. To count in such setting, it has been shown that\nthe presence of a leader is necessary. We focus on a particularly interesting\nsubset of dynamic networks, namely \\textit{Persistent Distance} - ${\\cal\nG}($PD$)_{h}$, in which each node has a fixed distance from the leader across\nrounds and such distance is at most $h$. In these networks the dynamic diameter\n$D$ is at most $2h$. We prove the number of rounds for counting in ${\\cal\nG}($PD$)_{2}$ is at least logarithmic with respect to the network size $|V|$.\nThanks to this result, we show that counting on any dynamic anonymous network\nwith $D$ constant w.r.t. $|V|$ takes at least $D+ \\Omega(\\text{log}\\, |V| )$\nrounds where $\\Omega(\\text{log}\\, |V|)$ represents the additional cost to be\npayed for handling anonymity. At the best of our knowledge this is the fist non\ntrivial, i.e. different from $\\Omega(D)$, lower bounds on counting in anonymous\ninterval connected networks with broadcast and unlimited bandwith. \n\n"}
{"id": "1505.03721", "contents": "Title: Decomposition of the Kantorovich problem and Wasserstein distances on\n  simplexes Abstract: Let $X$ be a Polish space, $\\mathcal{P}(X)$ be the set of Borel probability\nmeasures on $X$, and $T\\colon X\\to X$ be a homeomorphism. We prove that for the\nsimplex $\\mathrm{Dom} \\subseteq \\mathcal{P}(X)$ of all $T$-invariant measures,\nthe Kantorovich metric on $\\mathrm{Dom}$ can be reconstructed from its values\non the set of extreme points. This fact is closely related to the following\nresult: the invariant optimal transportation plan is a mixture of invariant\noptimal transportation plans between extreme points of the simplex. The latter\nresult can be generalized to the case of the Kantorovich problem with\nadditional linear constraints and the class of ergodic decomposable simplexes. \n\n"}
{"id": "1505.03799", "contents": "Title: Distributed House-Hunting in Ant Colonies Abstract: We introduce the study of the ant colony house-hunting problem from a\ndistributed computing perspective. When an ant colony's nest becomes unsuitable\ndue to size constraints or damage, the colony must relocate to a new nest. The\ntask of identifying and evaluating the quality of potential new nests is\ndistributed among all ants. The ants must additionally reach consensus on a\nfinal nest choice and the full colony must be transported to this single new\nnest. Our goal is to use tools and techniques from distributed computing theory\nin order to gain insight into the house-hunting process.\n  We develop a formal model for the house-hunting problem inspired by the\nbehavior of the Temnothorax genus of ants. We then show a \\Omega(log n) lower\nbound on the time for all n ants to agree on one of k candidate nests. We also\npresent two algorithms that solve the house-hunting problem in our model. The\nfirst algorithm solves the problem in optimal O(log n) time but exhibits some\nfeatures not characteristic of natural ant behavior. The second algorithm runs\nin O(k log n) time and uses an extremely simple and natural rule for each ant\nto decide on the new nest. \n\n"}
{"id": "1505.03819", "contents": "Title: Performance Analysis and Efficient Execution on Systems with multi-core\n  CPUs, GPUs and MICs Abstract: We carry out a comparative performance study of multi-core CPUs, GPUs and\nIntel Xeon Phi (Many Integrated Core - MIC) with a microscopy image analysis\napplication. We experimentally evaluate the performance of computing devices on\ncore operations of the application. We correlate the observed performance with\nthe characteristics of computing devices and data access patterns, computation\ncomplexities, and parallelization forms of the operations. The results show a\nsignificant variability in the performance of operations with respect to the\ndevice used. The performances of operations with regular data access are\ncomparable or sometimes better on a MIC than that on a GPU. GPUs are more\nefficient than MICs for operations that access data irregularly, because of the\nlower bandwidth of the MIC for random data accesses. We propose new\nperformance-aware scheduling strategies that consider variabilities in\noperation speedups. Our scheduling strategies significantly improve application\nperformance compared to classic strategies in hybrid configurations. \n\n"}
{"id": "1505.04694", "contents": "Title: Thread Parallelism for Highly Irregular Computation in Anisotropic Mesh\n  Adaptation Abstract: Thread-level parallelism in irregular applications with mutable data\ndependencies presents challenges because the underlying data is extensively\nmodified during execution of the algorithm and a high degree of parallelism\nmust be realized while keeping the code race-free. In this article we describe\na methodology for exploiting thread parallelism for a class of graph-mutating\nworklist algorithms, which guarantees safe parallel execution via processing in\nrounds of independent sets and using a deferred update strategy to commit\nchanges in the underlying data structures. Scalability is assisted by atomic\nfetch-and-add operations to create worklists and work-stealing to balance the\nshared-memory workload. This work is motivated by mesh adaptation algorithms,\nfor which we show a parallel efficiency of 60% and 50% on Intel(R) Xeon(R)\nSandy Bridge and AMD Opteron(tm) Magny-Cours systems, respectively, using these\ntechniques. \n\n"}
{"id": "1505.06107", "contents": "Title: Communicating with Beeps Abstract: The \\emph{beep model} is a very weak communications model in which devices in\na network can communicate only via beeps and silence. As a result of its weak\nassumptions, it has broad applicability to many different implementations of\ncommunications networks. This comes at the cost of a restrictive environment\nfor algorithm design.\n  Despite being only recently introduced, the beep model has received\nconsiderable attention, in part due to its relationship with other\ncommunication models such as that of ad-hoc radio networks. However, there has\nbeen no definitive published result for several fundamental tasks in the model.\nWe aim to rectify this with our paper.\n  We present algorithms and lower bounds for a variety of fundamental global\ncommunications tasks in the model. \n\n"}
{"id": "1505.06111", "contents": "Title: Interfacial Coupling and Electronic Structure of Two-Dimensional Silicon\n  Grown on the Ag(111) Surface at High Temperature Abstract: Freestanding silicene, a monolayer of Si arranged in a honeycomb structure,\nhas been predicted to give rise to massless Dirac fermions, akin to graphene.\nHowever, Si structures grown on a supporting substrate can show properties that\nstrongly deviate from the freestanding case. Here, combining scanning tunneling\nmicroscopy/spectroscopy and differential conductance mapping, we show that the\nelectrical properties of the ($\\sqrt{3}\\times\\sqrt{3}$) phase of few-layer Si\ngrown on Ag(111) strongly depend on film thickness, where the electron phase\ncoherence length decreases and the free-electron-like surface state gradually\ndiminishes when approaching the interface. These features are presumably\nattributable to the inelastic inter-band electron-electron scattering\noriginating from the overlap between the surface state, interface state and the\nbulk state of the substrate. We further demonstrate that the intrinsic\nelectronic structure of the as grown ($\\sqrt{3}\\times\\sqrt{3}$) phase is\nidentical to that of the ($\\sqrt{3}\\times\\sqrt{3}$)R$30^{\\circ}$ reconstructed\nAg on Si(111), both of which exhibit the parabolic energy-momentum dispersion\nrelation with comparable electron effective masses. These findings highlight\nthe essential role of interfacial coupling on the properties of two-dimensional\nSi structures grown on supporting substrates, which should be thoroughly\nscrutinized in pursuit of silicene. \n\n"}
{"id": "1505.06928", "contents": "Title: Phase diagram for hard-core $\\mathbb{Z}_3$ anyons on the ladder Abstract: Studies of free particles in low-dimensional quantum systems such as two-leg\nladders provide insight into the influence of statistics on collective\nbehaviour. The behaviours of bosons and fermions are well understood, but\ntwo-dimensional systems also admit excitations with alternative statistics\nknown as anyons. Numerical analysis of hard-core $\\mathbb{Z}_3$ anyons on the\nladder reveals qualitatively distinct behaviour, including a novel phase\ntransition associated with crystallisation of hole degrees of freedom into a\nperiodic foam. Qualitative predictions are extrapolated for all Abelian\n$\\mathbb{Z}_q$ anyon models. \n\n"}
{"id": "1506.00272", "contents": "Title: Synapse: Synthetic Application Profiler and Emulator Abstract: We introduce Synapse motivated by the needs to estimate and emulate workload\nexecution characteristics on high-performance and distributed heterogeneous\nresources. Synapse has a platform independent application profiler, and the\nability to emulate profiled workloads on a variety of heterogeneous resources.\nSynapse is used as a proxy application (or \"representative application\") for\nreal workloads, with the added advantage that it can be tuned at arbitrary\nlevels of granularity in ways that are simply not possible using real\napplications. Experiments show that automated profiling using Synapse\nrepresents application characteristics with high fidelity. Emulation using\nSynapse can reproduce the application behavior in the original runtime\nenvironment, as well as reproducing properties when used in a different\nrun-time environments. \n\n"}
{"id": "1506.02176", "contents": "Title: Active magneto-optical control of spontaneous emission in graphene Abstract: We investigate the spontaneous emission rate of a two-level quantum emitter\nnear a graphene-coated substrate under the influence of an external magnetic\nfield or strain induced pseudo-magnetic field. We demonstrate that the\napplication of the magnetic field can substantially increase or decrease the\ndecay rate. We show that a suppression as large as 99$\\%$ in the Purcell factor\nis achieved even for moderate magnetic fields. The emitter's lifetime is a\ndiscontinuous function of $|{\\bf B}|$, which is a direct consequence of the\noccurrence of discrete Landau levels in graphene. We demonstrate that, in the\nnear-field regime, the magnetic field enables an unprecedented control of the\ndecay pathways into which the photon/polariton can be emitted. Our findings\nstrongly suggest that a magnetic field could act as an efficient agent for\non-demand, active control of light-matter interactions in graphene at the\nquantum level. \n\n"}
{"id": "1506.02554", "contents": "Title: DUAL-LOCO: Distributing Statistical Estimation Using Random Projections Abstract: We present DUAL-LOCO, a communication-efficient algorithm for distributed\nstatistical estimation. DUAL-LOCO assumes that the data is distributed\naccording to the features rather than the samples. It requires only a single\nround of communication where low-dimensional random projections are used to\napproximate the dependences between features available to different workers. We\nshow that DUAL-LOCO has bounded approximation error which only depends weakly\non the number of workers. We compare DUAL-LOCO against a state-of-the-art\ndistributed optimization method on a variety of real world datasets and show\nthat it obtains better speedups while retaining good accuracy. \n\n"}
{"id": "1506.05837", "contents": "Title: Cooling and Autonomous Feedback in a Bose-Hubbard chain with Attractive\n  Interactions Abstract: We engineer a quantum bath that enables entropy and energy exchange with a\none-dimensional Bose-Hubbard lattice with attractive on-site interactions. We\nimplement this in an array of three superconducting transmon qubits coupled to\na single cavity mode; the transmons represent lattice sites and their\nexcitation quanta embody bosonic particles. Our cooling protocol preserves\nparticle number--realizing a canonical ensemble-- and also affords the\nefficient preparation of dark states which, due to symmetry, cannot be prepared\nvia coherent drives on the cavity. Furthermore, by applying continuous\nmicrowave radiation, we also realize autonomous feedback to indefinitely\nstabilize particular eigenstates of the array. \n\n"}
{"id": "1506.07168", "contents": "Title: Asymptotic Efficiency in OLEDS Abstract: Asymptotic efficiency (high output without droop) was recently reported for\nOLEDS in which a thin emitter layer is located at the anti-node in a resonant\nmicrocavity. Here we extend our theoretical analysis to treat multi-mode\ndevices with isotropic emitter orientation. We recover our efficiency equations\nfor the limiting cases with an isotropic emitter layer located at the anti-node\nwhere output is linear in current, and for an isotropic emitter located at the\nnode where output can exhibit second order losses with an overall efficiency\ncoefficient that depends on loss terms in competition with a cavity factor.\nAdditional scenarios are described where output is driven by spontaneous\nemission, or mixed spontaneous and stimulated emission, with stimulated\nemission present in a loss mode, potentially resulting in cavity driven droop\nor output clamping, and where the emitter layer is a host-guest system. \n\n"}
{"id": "1506.07180", "contents": "Title: Supernova Feedback and the Hot Gas Filling Fraction of the Interstellar\n  Medium Abstract: Supernovae (SN), the most energetic stellar feedback mechanism, are crucial\nfor regulating the interstellar medium (ISM) and launching galactic winds. We\nexplore how supernova remnants (SNRs) create a multiphase medium by performing\n3D hydrodynamical simulations at various SN rates, $S$, and ISM average\ndensities, $\\bar{n}$. The evolution of a SNR in a self-consistently generated\nthree-phase ISM is qualitatively different from that in a uniform or a\ntwo-phase warm/cold medium. By travelling faster and further in the low-density\nhot phase, the domain of a SNR increases by $>10^{2.5}$. Varying $\\bar{n}$ and\n$S$, we find that a steady state can only be achieved when the hot gas volume\nfraction $f_{\\rm{V,hot}}\\lesssim 0.6 \\pm 0.1 $. Above that level, overlapping\nSNRs render connecting topology of the hot gas, and the ISM is subjected to\nthermal runaway. Photoelectric heating (PEH) has a surprisingly strong impact\non $f_{\\rm{V,hot}}$. For $\\bar{n}\\gtrsim 3 \\cm-3 $, a reasonable PEH rate is\nable to suppress the thermal runaway. Overall, we determine the critical SN\nrate for the onset of thermal runaway to be $S_{\\rm{crit}} = 200\n(\\bar{n}/1\\cm-3)^k (E_{\\rm{SN}}/10^{51}\\erg)^{-1} \\kpc^{-3} \\myr-1$, where $k =\n(1.2,2.7)$ for $\\bar{n} \\leq 1$ and $> 1\\cm-3 $, respectively. We present a\nfitting formula of the ISM pressure $P(\\bar{n}$, $S$), which can be used as an\neffective equation of state in cosmological simulations. Despite the 5 orders\nof magnitude span of $(\\bar{n},S)$, the average Mach number varies little:\n$\\mathcal{M} \\approx \\ 0.5\\pm 0.2, \\ 1.2\\pm 0.3,\\ 2.3\\pm 0.9$ for the hot, warm\nand cold phases, respectively. \n\n"}
{"id": "1506.07952", "contents": "Title: Tradeoffs Between Cost and Information for Rendezvous and Treasure Hunt Abstract: In rendezvous, two agents traverse network edges in synchronous rounds and\nhave to meet at some node. In treasure hunt, a single agent has to find a\nstationary target situated at an unknown node of the network. We study\ntradeoffs between the amount of information ($\\mathit{advice}$) available\n$\\mathit{a\\ priori}$ to the agents and the cost (number of edge traversals) of\nrendezvous and treasure hunt. Our goal is to find the smallest size of advice\nwhich enables the agents to solve these tasks at some cost $C$ in a network\nwith $e$ edges. This size turns out to depend on the initial distance $D$ and\non the ratio $\\frac{e}{C}$, which is the $\\mathit{relative\\ cost\\ gain}$ due to\nadvice. For arbitrary graphs, we give upper and lower bounds of $O(D\\log(D\\cdot\n\\frac{e}{C}) +\\log\\log e)$ and $\\Omega(D\\log \\frac{e}{C})$, respectively, on\nthe optimal size of advice. For the class of trees, we give nearly tight upper\nand lower bounds of $O(D\\log \\frac{e}{C} + \\log\\log e)$ and $\\Omega (D\\log\n\\frac{e}{C})$, respectively. \n\n"}
{"id": "1506.08258", "contents": "Title: Trigger detection for adaptive scientific workflows using percentile\n  sampling Abstract: Increasing complexity of scientific simulations and HPC architectures are\ndriving the need for adaptive workflows, where the composition and execution of\ncomputational and data manipulation steps dynamically depend on the\nevolutionary state of the simulation itself. Consider for example, the\nfrequency of data storage. Critical phases of the simulation should be captured\nwith high frequency and with high fidelity for post-analysis, however we cannot\nafford to retain the same frequency for the full simulation due to the high\ncost of data movement. We can instead look for triggers, indicators that the\nsimulation will be entering a critical phase and adapt the workflow\naccordingly.\n  We present a method for detecting triggers and demonstrate its use in direct\nnumerical simulations of turbulent combustion using S3D. We show that chemical\nexplosive mode analysis (CEMA) can be used to devise a noise-tolerant indicator\nfor rapid increase in heat release. However, exhaustive computation of CEMA\nvalues dominates the total simulation, thus is prohibitively expensive. To\novercome this bottleneck, we propose a quantile-sampling approach. Our\nalgorithm comes with provable error/confidence bounds, as a function of the\nnumber of samples. Most importantly, the number of samples is independent of\nthe problem size, thus our proposed algorithm offers perfect scalability. Our\nexperiments on homogeneous charge compression ignition (HCCI) and reactivity\ncontrolled compression ignition (RCCI) simulations show that the proposed\nmethod can detect rapid increases in heat release, and its computational\noverhead is negligible. Our results will be used for dynamic workflow decisions\nabout data storage and mesh resolution in future combustion simulations.\nProposed framework is generalizable and we detail how it could be applied to a\nbroad class of scientific simulation workflows. \n\n"}
{"id": "1507.00075", "contents": "Title: Wigner time delay and related concepts -- Application to transport in\n  coherent conductors Abstract: The concepts of Wigner time delay and Wigner-Smith matrix allow to\ncharacterize temporal aspects of a quantum scattering process. The article\nreviews the statistical properties of the Wigner time delay for disordered\nsystems; the case of disorder in 1D with a chiral symmetry is discussed and the\nrelation with exponential functionals of the Brownian motion underlined.\nAnother approach for the analysis of time delay statistics is the random matrix\napproach, from which we review few results. As a pratical illustration, we\nbriefly outline a theory of nonlinear transport and AC transport developed by\nB\\\"uttiker and coworkers, where the concept of Wigner-Smith time delay matrix\nis a central piece allowing to describe screening properties in\nout-of-equilibrium coherent conductors. \n\n"}
{"id": "1507.06707", "contents": "Title: Probabilistic Self-Stabilization Abstract: By using concrete scenarios, we present and discuss a new concept of\nprobabilistic Self-Stabilization in Distributed Systems. \n\n"}
{"id": "1507.08461", "contents": "Title: Spontaneous hot-electron light emission from electron-fed optical\n  antennas Abstract: Nanoscale electronics and photonics are among the most promising research\nareas providing functional nano-components for data transfer and signal\nprocessing. By adopting metal-based optical antennas as a disruptive\ntechnological vehicle, we demonstrate that these two device-generating\ntechnologies can be interfaced to create an electronically-driven self-emitting\nunit. This nanoscale plasmonic transmitter operates by injecting electrons in a\ncontacted tunneling antenna feedgap. Under certain operating conditions, we\nshow that the antenna enters a highly nonlinear regime in which the energy of\nthe emitted photons exceeds the quantum limit imposed by the applied bias. We\npropose a model based upon the spontaneous emission of hot electrons that\ncorrectly reproduces the experimental findings. The electron-fed optical\nantennas described here are critical devices for interfacing electrons and\nphotons, enabling thus the development of optical transceivers for on-chip\nwireless broadcasting of information at the nanoscale. \n\n"}
{"id": "1507.08550", "contents": "Title: Modelling dust extinction in the Magellanic Clouds Abstract: We model the extinction profiles observed in the Small and Large Magellanic\nclouds with a synthetic population of dust grains consisting by core-mantle\nparticles and a collection of free-flying polycyclic aromatic hydrocarbons. All\ndifferent flavors of the extinction curves observed in the Magellanic Clouds\ncan be described by the present model, that has been previously (successfully)\napplied to a large sample of diffuse and translucent lines of sight in the\nMilky Way. We find that in the Magellanic Clouds the extinction produced by\nclassic grains is generally larger than absorption by polycyclic aromatic\nhydrocarbons. Within this model, the non-linear far-UV rise is accounted for by\npolycyclic aromatic hydrocarbons, whose presence in turn is always associated\nto a gap in the size distribution of classical particles. This hints either a\nphysical connection between (e.g., a common cause for) polycyclic aromatic\nhydrocarbons and the absence of middle-sized dust particles, or the need for an\nadditional component in the model, that can account for the non-linear far-UV\nrise without contributing to the UV bump at $\\sim$217 nm, e.g., nanodiamonds. \n\n"}
{"id": "1507.08834", "contents": "Title: Response-Time-Optimised Service Deployment: MILP Formulations of\n  Piece-wise Linear Functions Approximating Non-linear Bivariate Mixed-integer\n  Functions Abstract: A current trend in networking and cloud computing is to provide compute\nresources at widely dispersed places; this is exemplified by developments such\nas Network Function Virtualisation. This paves the way for wide-area service\ndeployments with improved service quality: e.g, a nearby server can reduce the\nuser-perceived response times. But always using the nearest server can be a bad\ndecision if that server is already highly utilised. This paper formalises the\ntwo related problems of allocating resources at different locations and\nassigning users to them with the goal of minimising the response times for a\ngiven number of resources to use -- a non-linear capacitated facility location\nproblem with integrated queuing systems. To efficiently handle the\nnon-linearity, we introduce five linear problem approximations and adapt the\ncurrently best heuristic for a similar problem to our scenario. All six\napproaches are compared in experiments for solution quality and solving time.\nSurprisingly, our best optimisation formulation outperforms the heuristic in\nboth time and quality. Additionally, we evaluate the influence ot resource\ndistributions in the network on the response time: Cut by half for some\nconfigurations. The presented formulations are applicable to a broader\noptimisation domain. \n\n"}
{"id": "1508.01032", "contents": "Title: Performance of a radiatively cooled system for quantum optomechanical\n  experiments in space Abstract: The performance of a radiatively cooled instrument is investigated in the\ncontext of optomechanical quantum experiments, where the environment of a\nmacroscopic particle in a quantum-superposition has to be cooled to less than\n20\\,K in deep space. A heat-transfer analysis between the components of the\ninstrument as well as a transfer-function analysis on thermal oscillations\ninduced by the spacecraft interior and by dissipative sources is performed. The\nthermal behaviour of the instrument in an orbit around a Lagrangian point and\nin a highly elliptical Earth orbit is discussed. Finally, we investigate\nfurther possible design improvements aiming at lower temperatures of the\nenvironment of the macroscopic particle. These include a mirror-based design of\nthe imaging system on the optical bench and the extension of the heat shields. \n\n"}
{"id": "1508.01171", "contents": "Title: Meta-MapReduce: A Technique for Reducing Communication in MapReduce\n  Computations Abstract: MapReduce has proven to be one of the most useful paradigms in the revolution\nof distributed computing, where cloud services and cluster computing become the\nstandard venue for computing. The federation of cloud and big data activities\nis the next challenge where MapReduce should be modified to avoid (big) data\nmigration across remote (cloud) sites. This is exactly our scope of research,\nwhere only the very essential data for obtaining the result is transmitted,\nreducing communication, processing and preserving data privacy as much as\npossible. In this work, we propose an algorithmic technique for MapReduce\nalgorithms, called Meta-MapReduce, that decreases the communication cost by\nallowing us to process and move metadata to clouds and from the map phase to\nreduce phase. In Meta-MapReduce, the reduce phase fetches only the required\ndata at required iterations, which in turn, assists in preserving the data\nprivacy. \n\n"}
{"id": "1508.01486", "contents": "Title: Coherent coupling between radio frequency, optical, and acoustic waves\n  in piezo-optomechanical circuits Abstract: The interaction of optical and mechanical modes in nanoscale optomechanical\nsystems has been widely studied for applications ranging from sensing to\nquantum information science. Here, we develop a platform for cavity\noptomechanical circuits in which localized and interacting 1550 nm photons and\n2.4 GHz phonons are combined with photonic and phononic waveguides. Working in\nGaAs facilitates manipulation of the localized mechanical mode either with a\nradio frequency field through the piezo-electric effect, or optically through\nthe strong photoelastic effect. We use this to demonstrate a novel acoustic\nwave interference effect, analogous to coherent population trapping in atomic\nsystems, in which the coherent mechanical motion induced by the electrical\ndrive can be completely cancelled out by the optically-driven motion. The\nability to manipulate cavity optomechanical systems with equal facility through\neither photonic or phononic channels enables new device and system\narchitectures for signal transduction between the optical, electrical, and\nmechanical domains. \n\n"}
{"id": "1508.02668", "contents": "Title: Modeling and Performance Analysis of Clustered Device-to-Device Networks Abstract: Device-to-device (D2D) communication enables direct communication between\nproximate devices thereby improving the overall spectrum utilization and\noffloading traffic from cellular networks. This paper develops a new spatial\nmodel for D2D networks in which the device locations are modeled as a Poisson\ncluster process. Using this model, we study the performance of a typical D2D\nreceiver in terms of coverage probability under two realistic content\navailability setups: (i) content of interest for a typical device is available\nat a device chosen uniformly at random from the same cluster, which we term\nuniform content availability, and (ii) content of interest is available at the\n$k^{th}$ closest device from the typical device inside the same cluster, which\nwe term $k$-closest content availability. Using these coverage probability\nresults, we also characterize the area spectral efficiency (ASE) of the whole\nnetwork for the two setups. A key intermediate step in this analysis is the\nderivation of the distributions of distances from a typical device to both the\nintra- and inter-cluster devices. Our analysis reveals that an optimum number\nof D2D transmitters must be simultaneously activated per cluster in order to\nmaximize ASE. This can be interpreted as the classical tradeoff between more\naggressive frequency reuse and higher interference power. The optimum number of\nsimultaneously transmitting devices and the resulting ASE increase as the\ncontent is made available closer to the receivers. Our analysis also quantifies\nthe best and worst case performance of clustered D2D networks both in terms of\ncoverage and ASE. \n\n"}
{"id": "1508.03985", "contents": "Title: Topologically protected defect states in open photonic systems with\n  non-hermitian charge-conjugation and parity-time symmetry Abstract: We show that topologically protected defect states can exist in open (leaky\nor lossy) systems even when these systems are topologically trivial in the\nclosed limit. The states appear from within the continuum, thus in absence of a\nband gap, and are generated via exceptional points (a spectral transition that\noccurs in open wave and quantum systems with a generalized time-reversal\nsymmetry), or via a degeneracy induced by charge-conjugation-symmetry (which is\nrelated to the pole transition of Majorana zero modes). We demonstrate these\nfindings for a leaking passive coupled-resonator optical waveguide with\nasymmmetric internal scattering, where the required symmetries (non-hermitian\nversions of time-reversal symmetry, chirality and charge-conjugation) emerge\ndynamically. \n\n"}
{"id": "1508.05208", "contents": "Title: 12CO emission from EP Aqr: Another example of an axi-symmetric AGB wind? Abstract: The CO(1-0) and (2-1) emission of the circumstellar envelope of the AGB star\nEP Aqr has been observed using the IRAM PdBI and the IRAM 30-m telescope. The\nline profiles reveal the presence of two distinct components centered on the\nstar velocity, a broad component extending up to ~10 km/s and a narrow\ncomponent indicating an expansion velocity of ~2 km/s. An early analysis of\nthese data was performed under the assumption of isotropic winds. The present\nstudy revisits this interpretation by assuming instead a bipolar outflow nearly\naligned with the line of sight. A satisfactory description of the observed flux\ndensities is obtained with a radial expansion velocity increasing from ~2 km/s\nat the equator to ~10 km/s near the poles. The angular aperture of the bipolar\noutflow is ~45 deg with respect to the star axis, which makes an angle of ~13\ndeg with the line of sight. A detailed study of the CO(1-0) to CO(2-1) flux\nratio reveals a significant dependence of the temperature on the star latitude,\nsmaller and steeper at the poles than at the equator at large distances from\nthe star. Under the hypothesis of radial expansion and of rotation invariance\nabout the star axis, the effective density has been evaluated in space as a\nfunction of star coordinates. Evidence is found for an enhancement of the\neffective density in the northern hemisphere of the star at angular distances\nin excess of ~3\" and covering the whole longitudinal range. The peak velocity\nof the narrow component is observed to vary slightly with position on the sky,\na variation consistent with the model and understood as the effect of the\ninclination of the star axis with respect to the line of sight. While the\nphenomenological model presented here reproduces well the general features of\nthe observations, significant differences are also revealed, which would\nrequire a better spatial resolution to be properly described. \n\n"}
{"id": "1508.06489", "contents": "Title: Large-scale anomalies in the cosmic microwave background as signatures\n  of non-Gaussianity Abstract: We derive a general expression for the probability of observing deviations\nfrom statistical isotropy in the cosmic microwave background (CMB) if the\nprimordial fluctuations are non-Gaussian and extend to superhorizon scales. The\nprimary motivation is to properly characterize the monopole and dipole\nmodulations of the primordial power spectrum that are generated by the coupling\nbetween superhorizon and subhorizon perturbations. Unlike previous proposals\nfor generating the hemispherical power asymmetry, we do not assume that the\npower asymmetry results from a single large superhorizon mode. Instead, we\nextrapolate the observed power spectrum to superhorizon scales and compute the\npower asymmetry that would result from a specific realization of non-Gaussian\nperturbations on scales larger than the observable universe. Our study\nencompasses many of the scenarios that have been put forward as possible\nexplanations for the CMB hemispherical power asymmetry. We confirm our analytic\npredictions for the probability of a given power asymmetry by comparing them to\nnumerical realizations of CMB maps. We find that non-local models of\nnon-Gaussianity and scale-dependent local non-Gaussianity produce\nscale-dependent modulations of the power spectrum, thereby potentially\nproducing both a monopolar and a dipolar power modulation on large scales. We\nthen provide simple examples of finding the posterior distributions for the\nparameters of the bispectrum from the observed monopole and dipole modulations. \n\n"}
{"id": "1509.00940", "contents": "Title: Wireless Charging Technologies: Fundamentals, Standards, and Network\n  Applications Abstract: Wireless charging is a technology of transmitting power through an air gap to\nelectrical devices for the purpose of energy replenishment. The recent progress\nin wireless charging techniques and development of commercial products have\nprovided a promising alternative way to address the energy bottleneck of\nconventionally portable battery-powered devices. However, the incorporation of\nwireless charging into the existing wireless communication systems also brings\nalong a series of challenging issues with regard to implementation, scheduling,\nand power management. In this article, we present a comprehensive overview of\nwireless charging techniques, the developments in technical standards, and\ntheir recent advances in network applications. In particular, with regard to\nnetwork applications, we review the mobile charger dispatch strategies, static\ncharger scheduling strategies and wireless charger deployment strategies.\nAdditionally, we discuss open issues and challenges in implementing wireless\ncharging technologies. Finally, we envision some practical future network\napplications of wireless charging. \n\n"}
{"id": "1509.01596", "contents": "Title: Inter-Layer Per-Mobile Optimization of Cloud Mobile Computing: A\n  Message-Passing Approach Abstract: Cloud mobile computing enables the offloading of computation-intensive\napplications from a mobile device to a cloud processor via a wireless\ninterface. In light of the strong interplay between offloading decisions at the\napplication layer and physical-layer parameters, which determine the energy and\nlatency associated with the mobile-cloud communication, this paper investigates\nthe inter-layer optimization of fine-grained task offloading across both\nlayers. In prior art, this problem was formulated, under a serial\nimplementation of processing and communication, as a mixed integer program,\nentailing a complexity that is exponential in the number of tasks. In this\nwork, instead, algorithmic solutions are proposed that leverage the structure\nof the call graphs of typical applications by means of message passing on the\ncall graph, under both serial and parallel implementations of processing and\ncommunication. For call trees, the proposed solutions have a linear complexity\nin the number of tasks, and efficient extensions are presented for more general\ncall graphs that include \"map\" and \"reduce\"-type tasks. Moreover, the proposed\nschemes are optimal for the serial implementation, and provide principled\nheuristics for the parallel implementation. Extensive numerical results yield\ninsights into the impact of inter-layer optimization and on the comparison of\nthe two implementations. \n\n"}
{"id": "1509.01921", "contents": "Title: Meron deconfinement in the quantum Hall bilayer at intermediate\n  distances Abstract: Quantum Hall bilayer phase diagram with respect to interlayer distance bears\na remarkable similarity with phase diagrams of strongly correlated systems as a\nfunction of doping, with magnetic ordering on the one end and Fermi-liquid-like\nbehaviour on the other. Moreover, it has been suggested [PRL 101, 176803\n(2008)] that a BCS correlated state of composite fermions with p-wave pairing\nmay exist in the intermediate region. In the same region, an exact\ndiagonalization study in the torus geometry [PRB 69, 045319 (2004)] pointed out\nthe existence of state(s) with pseudospin spiraling order. Here we reconcile\nthese two descriptions of the intermediate state by considering the underlying\nbosonic representation of the composite fermion paired state in the long\ndistance limit, and by performing extensive exact diagonalizations on the\ntorus. We argue that the spiraling states belong to the manifold of degenerate\nground state(s), and are a consequence of Bose condensation of the\nquasiparticles (with critical algebraic correlations) at non-zero momenta in\nthe two pseudospin states. The spiraling states, generated in this way as\nspin-textures, can be identified with meron-antimeron constructions. Thus,\nmerons -- the fractionally charged vortex excitations of the XY magnetically\nordered state -- constitute some of the topological sectors. It follows that\nmerons are deconfined in the intermediate state, and allow for a smooth\ntransition between the magnetically ordered and Fermi-liquid-like phases, in\nwhich they are bound in pairs. \n\n"}
{"id": "1509.02464", "contents": "Title: Characterizing and Adapting the Consistency-Latency Tradeoff in\n  Distributed Key-value Stores Abstract: The CAP theorem is a fundamental result that applies to distributed storage\nsystems. In this paper, we first present and prove two CAP-like impossibility\ntheorems. To state these theorems, we present probabilistic models to\ncharacterize the three important elements of the CAP theorem: consistency (C),\navailability or latency (A), and partition tolerance (P). The theorems show the\nun-achievable envelope, i.e., which combinations of the parameters of the three\nmodels make them impossible to achieve together. Next, we present the design of\na class of systems called PCAP that perform close to the envelope described by\nour theorems. In addition, these systems allow applications running on a single\ndata-center to specify either a latency SLA or a consistency SLA. The PCAP\nsystems automatically adapt, in real-time and under changing network\nconditions, to meet the SLA while optimizing the other C/A metric. We\nincorporate PCAP into two popular key-value stores -- Apache Cassandra and\nRiak. Our experiments with these two deployments, under realistic workloads,\nreveal that the PCAP system satisfactorily meets SLAs, and performs close to\nthe achievable envelope. We also extend PCAP from a single data-center to\nmultiple geo-distributed data-centers. \n\n"}
{"id": "1509.04028", "contents": "Title: Topological properties of Fibonacci quasicrystals : A scattering\n  analysis of Chern numbers Abstract: We report on a study of topological properties of Fibonacci quasicrystals.\nChern numbers which label the dense set of spectral gaps, are shown to be\nrelated to the underlying palindromic symmetry. Topological and spectral\nfeatures are related to the two independent phases of the scattering matrix:\nthe total phase shift describing the frequency spectrum and the chiral phase\nsensitive to topological features. Conveniently designed gap modes with\nspectral properties directly related to the Chern numbers allow to scan these\nphases. An effective topological Fabry-Perot cavity is presented. \n\n"}
{"id": "1509.04627", "contents": "Title: A tetrahedral space-filling curve for non-conforming adaptive meshes Abstract: We introduce a space-filling curve for triangular and tetrahedral\nred-refinement that can be computed using bitwise interleaving operations\nsimilar to the well-known Z-order or Morton curve for cubical meshes. To store\nsufficient information for random access, we define a low-memory encoding using\n10 bytes per triangle and 14 bytes per tetrahedron. We present algorithms that\ncompute the parent, children, and face-neighbors of a mesh element in constant\ntime, as well as the next and previous element in the space-filling curve and\nwhether a given element is on the boundary of the root simplex or not. Our\npresentation concludes with a scalability demonstration that creates and adapts\nselected meshes on a large distributed-memory system. \n\n"}
{"id": "1509.04975", "contents": "Title: Chiral filtering in graphene with coupled valleys Abstract: We analyze the problem of electronic transmission through different regions\nof a graphene sheet that are characterized by different types of connections\nbetween the Dirac points. These valley symmetry breaking Hamiltonians might\narise from electronic self-interaction mediated by the dielectric environment\nof distinct parts of the substrate on which the graphene sheet is placed. We\nshow that it is possible to have situations in which we can use these regions\nto select or filter states of one desired chirality. \n\n"}
{"id": "1509.07448", "contents": "Title: Davie's type uniqueness for a class of SDEs with jumps Abstract: A result of A.M. Davie [Int. Math. Res. Not. 2007] states that a\nmultidimensional stochastic equation $dX_t = b(t, X_t)\\,dt + dW_t$, $X_0=x$,\ndriven by a Wiener process $W= (W_t)$ with a coefficient $b$ which is only\nbounded and measurable has a unique solution for almost all choices of the\ndriving Brownian path. We consider a similar problem when $W$ is replaced by a\nL\\'evy process $L= (L_t)$ and $b$ is $\\beta$-H\\\"older continuous in the space\nvariable, $ \\beta \\in (0,1)$. We assume that $L_1$ has a finite moment of order\n$\\theta$, for some ${\\theta}>0$. Using also a new c\\`adl\\`ag regularity result\nfor strong solutions, we prove that strong existence and uniqueness for the SDE\ntogether with $L^p$-Lipschitz continuity of the strong solution with respect to\n$x $ imply a Davie's type uniqueness result for almost all choices of the\nL\\'evy paths. We apply this result to a class of SDEs driven by non-degenerate\n$\\alpha$-stable L\\'evy processes, $\\alpha \\in (0,2)$ and $\\beta > 1 -\n\\alpha/2$. \n\n"}
{"id": "1509.07802", "contents": "Title: Poisson suspensions and Sushis Abstract: In this paper, we prove that ergodic point processes with moments of all\norders, driven by particular infinite measure preserving transformations, have\nto be a superposition of shifted Poisson processes. This rigidity result has a\nlot of implications in terms of joining and disjointness for the corresponding\nPoisson suspension. In particular, we prove that its ergodic self-joinings are\nPoisson joinings, which provides an analog, in the Poissonian context, of the\nGAG property for Gaussian dynamical systems. \n\n"}
{"id": "1509.07989", "contents": "Title: Resource allocation in Peer-to-Peer Networks: A Control-Theoretical\n  Perspective Abstract: P2P system rely on voluntary allocation of resources by its members due to\nabsence of any central controlling authority. This resource allocation can be\nviewed as classical control problem where feedback is the amount of resource\nreceived, which controls the output i.e. the amount of resources shared back to\nthe network by the node. The motivation behind the use of control system in\nresource allocation is to exploit already existing tools in control theory to\nimprove the overall allocation process and thereby solving the problem of\nfreeriding and whitewashing in the network. At the outset, we have derived the\ntransfer function to model the P2P system. Subsequently, through the simulation\nresults we have shown that transfer function was able to provide optimal value\nof resource sharing for the peers during the normal as well as high degree of\noverloading in the network. Thereafter we verified the accuracy of the transfer\nfunction derived by comparing its output with the simulated P2P network. To\ndemonstrate how control system reduces free riding it has been shown through\nsimulations how the control systems penalizes the nodes indulging in different\nlevels of freeriding. Our proposed control system shows considerable gain over\nexisting state of art algorithm. This improvement is achieved through PI action\nof controller. Since low reputation peers usually subvert reputation system by\nwhitewashing. We propose and substantiate a technique modifying transfer\nfunction such that systems' sluggishness becomes adaptive in such a way that it\nencourage genuine new comers to enter network and discourages member peers to\nwhitewash. \n\n"}
{"id": "1509.08001", "contents": "Title: Approaching Single-Hop Performance in Multi-Hop Networks: End-To-End\n  Known-Interference Cancellation (E2E-KIC) Abstract: To improve the efficiency of wireless data communications, new physical-layer\ntransmission methods based on known-interference cancellation (KIC) have been\ndeveloped. These methods share the common idea that the interference can be\ncancelled when the content of it is known. Existing work on KIC mainly focuses\non single-hop or two-hop networks, with physical-layer network coding (PNC) and\nfull-duplex (FD) communications as typical examples. This paper extends the\nidea of KIC to general multi-hop networks, and proposes an end-to-end KIC\n(E2E-KIC) transmission method together with its MAC design. With E2E-KIC,\nmultiple nodes in a flow passing through a few nodes in an arbitrary topology\ncan simultaneously transmit and receive on the same channel. We first present a\ntheoretical analysis on the effectiveness of E2E-KIC in an idealized case.\nThen, to support E2E-KIC in multi-hop networks with arbitrary topology, we\npropose an E2E-KIC-supported MAC protocol (E2E-KIC MAC), which is based on an\nextension of the Request-to-Send/Clear-to-Send (RTS/CTS) mechanism in the IEEE\n802.11 MAC. We also analytically analyze the performance of the proposed\nE2E-KIC MAC in the presence of hidden terminals. Simulation results illustrate\nthat the proposed E2E-KIC MAC protocol can improve the network throughput and\nreduce the end-to-end delay. \n\n"}
{"id": "1509.08346", "contents": "Title: UB-ANC Drone: A Flexible Airborne Networking and Communications Testbed Abstract: We present the University at Buffalo's Airborne Networking and Communications\nTestbed (UB-ANC Drone). UB-ANC Drone is an open software/hardware platform that\naims to facilitate rapid testing and repeatable comparative evaluation of\nairborne networking and communications protocols at different layers of the\nprotocol stack. It combines quadcopters capable of autonomous flight with\nsophisticated command and control capabilities and embedded software-defined\nradios (SDRs), which enable flexible deployment of novel communications and\nnetworking protocols. This is in contrast to existing airborne network\ntestbeds, which rely on standard inflexible wireless technologies, e.g., Wi-Fi\nor Zigbee. UB-ANC Drone is designed with emphasis on modularity and\nextensibility, and is built around popular open-source projects and standards\ndeveloped by the research and hobby communities. This makes UB-ANC Drone highly\ncustomizable, while also simplifying its adoption. In this paper, we describe\nUB-ANC Drone's hardware and software architecture. \n\n"}
{"id": "1510.03145", "contents": "Title: Elastic Resource Allocation for Distributed Graph Processing Platforms Abstract: Distributed graph platforms like Pregel have used vertex- centric programming\nmodels to process the growing corpus of graph datasets using commodity\nclusters. The irregular structure of graphs cause load imbalances across\nmachines operating on graph partitions, and this is exacerbated for\nnon-stationary graph algorithms such as traversals, where not all parts of the\ngraph are active at the same time. As a result, such graph platforms, even as\nthey scale, do not make efficient use of distributed resources. Clouds offer\nelastic virtual machines that can be leveraged to improve the resource\nutilization for such platforms and hence reduce the monetary cost for their\nexecution. In this paper, we propose strategies for elastic placement of graph\npartitions on Cloud VMs for subgraphcentric programming model to reduce the\ncost of execution compared to a static placement, even as we minimize the\nincrease in makespan. These strategies are innovative in modeling the graph\nalgorithms behavior. We validate our strategies for several graphs, using\nruntime tra- ces for their distributed execution of a Breadth First Search\n(BFS) algorithms on our subgraph-centric GoFFish graph platform. Our strategies\nare able to reduce the cost of exe- cution by up to 42%, compared to a static\nplacement, while achieving a makespan that is within 29% of the optimal \n\n"}
{"id": "1510.07357", "contents": "Title: Distributed Bare-Bones Communication in Wireless Networks Abstract: We consider wireless networks operating under the SINR model of interference.\nNodes have limited individual knowledge and capabilities: they do not know\ntheir positions in a coordinate system in the plane, further they do not know\ntheir neighborhoods, nor do they know the size of the network $n$, and finally\nthey cannot sense collisions resulting from simultaneous transmissions by at\nleast two neighbors. Each node is equipped with a unique integer name, where\n$N$ as an upper bound on the a range of names. We refer as a backbone to a\nsubnetwork induced by a diameter-preserving dominating set of nodes. Let\n$\\Delta$ denote a maximum number of nodes that can successfully receive a\nmessage transmitted by a node when no other nodes transmit concurrently. We\nstudy distributed algorithms for communication problems in three settings. In\nthe single-node-start case, when one node starts an execution and other nodes\nare awoken by receiving messages from already awoken nodes, we present a\nrandomized broadcast algorithm that wakes up all nodes in $O(n \\log^2 N)$\nrounds with high probability. For the synchronized-start case, when all nodes\nstart an execution simultaneously, we give a randomized algorithm computing a\nbackbone in $O(\\Delta\\log^{7} N)$ rounds with high probability. In the\npartly-coordinated-start case, when a number of nodes start an execution\ntogether and other nodes are awoken by receiving messages from the already\nawoken nodes, we develop an algorithm that creates a backbone in time\n$O(n\\log^2 N +\\Delta\\log^{7} N)$ with high probability. \n\n"}
{"id": "1510.08919", "contents": "Title: Random Perturbations of a Periodically Driven Nonlinear Oscillator:\n  Escape from a resonance zone Abstract: The phase space for a periodically driven nonlinear oscillator consists of\nmany resonance zones. Let the strength of periodic excitation and the strength\nof the damping be indexed by a small parameter $\\varepsilon$. It is well known\nthat, as $\\varepsilon \\to 0$, the measure of the set of initial conditions\nwhich lead to 'capture in a resonance zone' goes to zero. In this paper we\nstudy the effect of weak noise on the escape from a resonance zone. \n\n"}
{"id": "1510.09096", "contents": "Title: Weak synchronization for isotropic flows Abstract: We study Brownian flows on manifolds for which the associated Markov process\nis strongly mixing with respect to an invariant probability measure and for\nwhich the distance process for each pair of trajectories is a diffusion $r$. We\nprovide a sufficient condition on the boundary behavior of $r$ at $0$ which\nguarantees that the statistical equilibrium of the flow is almost surely a\nsingleton and its support is a weak point attractor. The condition is fulfilled\nin the case of negative top Lyapunov exponent, but it is also fulfilled in some\ncases when the top Lyapunov exponent is zero. Particular examples are isotropic\nBrownian flows on $S^{d-1}$ as well as isotropic Ornstein-Uhlenbeck flows on\n$\\mathbb{R}^d$. \n\n"}
{"id": "1511.03121", "contents": "Title: Dilaton assisted two-field inflation from no-scale supergravity Abstract: We present a two-field inflation model where inflaton field has a\nnon-canonical kinetic term due to the presence of a dilaton field. It is a\ntwo-parameter generalization of one-parameter Brans-Dicke gravity in the\nEinstein frame. We show that in such an inflation model the quartic and\nquadratic inflaton potentials, which are otherwise ruled out by the present\nPlanck-{\\it Keck}/BICEP2 data, yield scalar spectral index and tensor-to-scalar\nratio in accordance with the present data. Such a model yield tensor-to-scalar\nratio of the order of $10^{-2}$ which is within the reach of $B-$mode\nexperiments like {\\it Keck}/BICEP3, CMBPol and thus can be put to test in the\nnear future. This model yields negligible non-Gaussianity and no isocurvature\nperturbations upto slow-roll approximation. Finally, we show that such a model\ncan be realised in the realm of no-scale supergravity. \n\n"}
{"id": "1511.04217", "contents": "Title: A Survey on Reproducibility in Parallel Computing Abstract: We summarize the results of a survey on reproducibility in parallel\ncomputing, which was conducted during the Euro-Par conference in August 2015.\nThe survey form was handed out to all participants of the conference and the\nworkshops. The questionnaire, which specifically targeted the parallel\ncomputing community, contained questions in four different categories: general\nquestions on reproducibility, the current state of reproducibility, the\nreproducibility of the participants' own papers, and questions about the\nparticipants' familiarity with tools, software, or open-source software\nlicenses used for reproducible research. \n\n"}
{"id": "1511.04895", "contents": "Title: Asymptotics of surface-plasmon redshift saturation at sub-nanometric\n  separations Abstract: Many promising nanophotonics endeavours hinge upon the unique plasmonic\nproperties of nanometallic structures with narrow non-metallic gaps, which\nsupport super-concentrated bonding modes that singularly redshift with\ndecreasing separations. In this letter, we present a descriptive physical\npicture, complemented by elementary asymptotic formulae, of a nonlocal\nmechanism for plasmon-redshift saturation at subnanometric gap widths. Thus, by\nconsidering the electron-charge and field distributions in the close vicinity\nof the metal-vacuum interface, we show that nonlocality is asymptotically\nmanifested as an effective potential discontinuity. For bonding modes in the\nnear-contact limit, the latter discontinuity is shown to be effectively\nequivalent to a widening of the gap. As a consequence, the resonance-frequency\nnear-contact asymptotics are a renormalisation of the corresponding local ones.\nSpecifically, the renormalisation furnishes an asymptotic plasmon-frequency\nlower bound that scales with the $1/4$-power of the Fermi wavelength. We\ndemonstrate these remarkable features in the prototypical cases of nanowire and\nnanosphere dimers, showing agreement between our elementary expressions and\npreviously reported numerical computations. \n\n"}
{"id": "1511.05152", "contents": "Title: Inferring Planetary Obliquity Using Rotational & Orbital Photometry Abstract: The obliquity of a terrestrial planet is an important clue about its\nformation and critical to its climate. Previous studies using simulated\nphotometry of Earth show that continuous observations over most of a planet's\norbit can be inverted to infer obliquity. However, few studies of more general\nplanets with arbitrary albedo markings have been made and, in particular, a\nsimple theoretical understanding of why it is possible to extract obliquity\nfrom light curves is missing. Reflected light seen by a distant observer is the\nproduct of a planet's albedo map, its host star's illumination, and the\nvisibility of different regions. It is useful to treat the product of\nillumination and visibility as the kernel of a convolution. Time-resolved\nphotometry constrains both the albedo map and the kernel, the latter of which\nsweeps over the planet due to rotational and orbital motion. The kernel's\nmovement distinguishes prograde from retrograde rotation for planets with\nnon-zero obliquity on inclined orbits. We demonstrate that the kernel's\nlongitudinal width and mean latitude are distinct functions of obliquity and\naxial orientation. Notably, we find that a planet's spin axis affects the\nkernel -- and hence time-resolved photometry -- even if this planet is\nEast-West uniform or spinning rapidly, or if it is North-South uniform. We find\nthat perfect knowledge of the kernel at 2-4 orbital phases is usually\nsufficient to uniquely determine a planet's spin axis. Surprisingly, we predict\nthat East-West albedo contrast is more useful for constraining obliquity than\nNorth-South contrast. \n\n"}
{"id": "1511.05923", "contents": "Title: Dynamical fine-tuning of initial conditions for small field inflations Abstract: Small-field inflation (SFI) is widely considered to be unnatural because an\nextreme fine-tuning of the initial condition is necessary for sufficiently\nlarge e-folding. In this paper, we show that the unnaturally-looking initial\ncondition can be dynamically realised without any fine-tuning if the SFI occurs\nafter rapid oscillations of the inflaton field and particle creations by\npreheating. In fact, if the inflaton field $\\phi$ is coupled to another scalar\nfield $\\chi$ through the interaction $g^2 \\chi^2 \\phi^2$ and the vacuum energy\nduring the small field inflation is given by $\\lambda M^4$, the initial value\ncan be dynamically set at $(\\sqrt{\\lambda}/g) M^2/M_{\\rm pl}$, which is much\nsmaller than the typical scale of the potential $M.$ This solves the initial\ncondition problem in the new inflation model or some classes of the hilltop\ninflation models. \n\n"}
{"id": "1511.06033", "contents": "Title: EigenRec: Generalizing PureSVD for Effective and Efficient Top-N\n  Recommendations Abstract: We introduce EigenRec; a versatile and efficient Latent-Factor framework for\nTop-N Recommendations that includes the well-known PureSVD algorithm as a\nspecial case. EigenRec builds a low dimensional model of an inter-item\nproximity matrix that combines a similarity component, with a scaling operator,\ndesigned to control the influence of the prior item popularity on the final\nmodel. Seeing PureSVD within our framework provides intuition about its inner\nworkings, exposes its inherent limitations, and also, paves the path towards\npainlessly improving its recommendation performance. A comprehensive set of\nexperiments on the MovieLens and the Yahoo datasets based on widely applied\nperformance metrics, indicate that EigenRec outperforms several\nstate-of-the-art algorithms, in terms of Standard and Long-Tail recommendation\naccuracy, exhibiting low susceptibility to sparsity, even in its most extreme\nmanifestations -- the Cold-Start problems. At the same time EigenRec has an\nattractive computational profile and it can apply readily in large-scale\nrecommendation settings. \n\n"}
{"id": "1511.06051", "contents": "Title: SparkNet: Training Deep Networks in Spark Abstract: Training deep networks is a time-consuming process, with networks for object\nrecognition often requiring multiple days to train. For this reason, leveraging\nthe resources of a cluster to speed up training is an important area of work.\nHowever, widely-popular batch-processing computational frameworks like\nMapReduce and Spark were not designed to support the asynchronous and\ncommunication-intensive workloads of existing distributed deep learning\nsystems. We introduce SparkNet, a framework for training deep networks in\nSpark. Our implementation includes a convenient interface for reading data from\nSpark RDDs, a Scala interface to the Caffe deep learning framework, and a\nlightweight multi-dimensional tensor library. Using a simple parallelization\nscheme for stochastic gradient descent, SparkNet scales well with the cluster\nsize and tolerates very high-latency communication. Furthermore, it is easy to\ndeploy and use with no parameter tuning, and it is compatible with existing\nCaffe models. We quantify the dependence of the speedup obtained by SparkNet on\nthe number of machines, the communication frequency, and the cluster's\ncommunication overhead, and we benchmark our system's performance on the\nImageNet dataset. \n\n"}
{"id": "1511.06825", "contents": "Title: EMinRET: Heuristic for Energy-Aware VM Placement with Fixed Intervals\n  and Non-preemption Abstract: Infrastructure-as-a-Service (IaaS) clouds have become more popular enabling\nusers to run applications under virtual machines. This paper investigates the\nenergy-aware virtual machine (VM) allocation problems in IaaS clouds along\ncharacteristics: multiple resources, and fixed interval times and\nnon-preemption of virtual machines. Many previous works proposed to use a\nminimum number of physical machines, however, this is not necessarily a good\nsolution to minimize total energy consumption in the VM placement with multiple\nresources, fixed interval times and non-preemption. We observed that minimizing\ntotal energy consumption of physical machines is equivalent to minimize the sum\nof total completion time of all physical machines. Based on the observation, we\npropose EMinRET algorithm. The EMinRET algorithm swaps an allocating VM with a\nsuitable overlapped VM, which is of the same VM type and is allocated on the\nsame physical machine, to minimize total completion time of all physical\nmachines. The EMinRET uses resource utilization during executing time period of\na physical machine as the evaluation metric, and will then choose a host that\nminimizes the metric to allocate a new VM. In addition, this work studies some\nheuristics for sorting the list of virtual machines (e.g., sorting by the\nearliest starting time, or the longest duration time first, etc.) to allocate\nVM. Using the realistic log-trace in the Parallel Workloads Archive, our\nsimulation results show that the EMinRET algorithm could reduce from 25% to 45%\nenergy consumption compared with power-aware best-fit decreasing (PABFD)) and\nvector bin-packing norm-based greedy algorithms. Moreover, the EMinRET\nheuristic has also less total energy consumption than our previous heuristics\n(e.g. MinDFT and EPOBF) in the simulations (using same virtual machines sorting\nmethod). \n\n"}
{"id": "1511.07261", "contents": "Title: A Python Extension for the Massively Parallel Multiphysics Simulation\n  Framework waLBerla Abstract: We present a Python extension to the massively parallel HPC simulation\ntoolkit waLBerla. waLBerla is a framework for stencil based algorithms\noperating on block-structured grids, with the main application field being\nfluid simulations in complex geometries using the lattice Boltzmann method.\nCareful performance engineering results in excellent node performance and good\nscalability to over 400,000 cores. To increase the usability and flexibility of\nthe framework, a Python interface was developed. Python extensions are used at\nall stages of the simulation pipeline: They simplify and automate scenario\nsetup, evaluation, and plotting. We show how our Python interface outperforms\nthe existing text-file-based configuration mechanism, providing features like\nautomatic nondimensionalization of physical quantities and handling of complex\nparameter dependencies. Furthermore, Python is used to process and evaluate\nresults while the simulation is running, leading to smaller output files and\nthe possibility to adjust parameters dependent on the current simulation state.\nC++ data structures are exported such that a seamless interfacing to other\nnumerical Python libraries is possible. The expressive power of Python and the\nperformance of C++ make development of efficient code with low time effort\npossible. \n\n"}
{"id": "1511.07506", "contents": "Title: Centred quadratic stochastic operators Abstract: We study the weak convergence of iterates of so-called centred kernel\nquadratic stochastic operators. These iterations, in a population evolution\nsetting, describe the additive perturbation of the arithmetic mean of the\ntraits of an individual's parents and correspond to certain weighted sums of\nindependent random variables. We show that one can obtain weak convergence\nresults under rather mild assumptions on the kernel. Essentially it is\nsufficient for the distribution of the perturbing random variable to have a\nfinite variance or have tails controlled by a power function. The advantage of\nthese conditions is that in many cases they are easily verifiable by an applied\nuser. Additionally, the representation by sums of random variables implies an\nefficient simulation algorithm to obtain random variables approximately\nfollowing the law of the iterates of the quadratic stochastic operator, with\nfull control of the degree of approximation. Our results also indicate where\nlies an intrinsic difficulty in the analysis of the behaviour of quadratic\nstochastic operators. \n\n"}
{"id": "1512.01499", "contents": "Title: Microscale electromagnetic heating in heterogeneous energetic materials\n  based on X-ray CT imaging Abstract: Electromagnetic stimulation of energetic materials provides a noninvasive and\nnondestructive tool for detecting and identifying explosives. We combine\nstructural information based on X-ray computed tomography, experimental\ndielectric data, and electromagnetic full-wave simulations, to study microscale\nelectromagnetic heating of realistic three-dimensional heterogeneous\nexplosives. We analyze the formation of electromagnetic hot spots and thermal\ngradients in the explosive-binder meso-structures, and compare the heating rate\nfor various binder systems. \n\n"}
{"id": "1512.01625", "contents": "Title: Coded MapReduce Abstract: MapReduce is a commonly used framework for executing data-intensive jobs on\ndistributed server clusters. We introduce a variant implementation of\nMapReduce, namely \"Coded MapReduce\", to substantially reduce the inter-server\ncommunication load for the shuffling phase of MapReduce, and thus accelerating\nits execution. The proposed Coded MapReduce exploits the repetitive mapping of\ndata blocks at different servers to create coding opportunities in the\nshuffling phase to exchange (key,value) pairs among servers much more\nefficiently. We demonstrate that Coded MapReduce can cut down the total\ninter-server communication load by a multiplicative factor that grows linearly\nwith the number of servers in the system and it achieves the minimum\ncommunication load within a constant multiplicative factor. We also analyze the\ntradeoff between the \"computation load\" and the \"communication load\" of Coded\nMapReduce. \n\n"}
{"id": "1512.01998", "contents": "Title: Energy Efficiency of Massive MIMO: Coping with Daily Load Variation Abstract: Massive MIMO is a promising technique to meet the exponential growth of\nmobile traffic demand. However, contrary to the current systems, energy\nconsumption of next generation networks is required to be load adaptive as the\nnetwork load varies significantly throughout the day. In this paper, we propose\na load adaptive multi-cell massive MIMO system where each base station (BS)\nadapts the number of antennas to the daily load profile (DLP) in order to\nmaximize the downlink energy efficiency (EE). In order to incorporate the DLP,\nthe load at each BS is modeled as an M/G/m/m state dependent queue under the\nassumption that the network is dimensioned to serve a maximum number of users\nat the peak load. The EE maximization problem is formulated in a game theoretic\nframework where the number of antennas to be used by a BS is determined through\nbest response iteration. This load adaptive system achieves around 24% higher\nEE and saves around 40% energy compared to a baseline system where the BSs\nalways run with the fixed number of antennas that is most energy efficient at\nthe peak load and that can be switched off when there is no traffic. \n\n"}
{"id": "1512.02737", "contents": "Title: Using Symmetry to Schedule Classical Matrix Multiplication Abstract: Presented with a new machine with a specific interconnect topology, algorithm\ndesigners use intuition about the symmetry of the algorithm to design time and\ncommunication-efficient schedules that map the algorithm to the machine. Is\nthere a systematic procedure for designing schedules? We present a new\ntechnique to design schedules for algorithms with no non-trivial dependencies,\nfocusing on the classical matrix multiplication algorithm.\n  We model the symmetry of algorithm with the set of instructions $X$ as the\naction of the group formed by the compositions of bijections from the set $X$\nto itself. We model the machine as the action of the group $N\\times \\Delta$,\nwhere $N$ and $\\Delta$ represent the interconnect topology and time increments\nrespectively, on the set $P\\times T$ of processors iterated over time steps. We\nmodel schedules as symmetry-preserving equivariant maps between the set $X$ and\na subgroup of its symmetry and the set $P\\times T$ with the symmetry\n$N\\times\\Delta$. Such equivariant maps are the solutions of a set of algebraic\nequations involving group homomorphisms. We associate time and communication\ncosts with the solutions to these equations.\n  We solve these equations for the classical matrix multiplication algorithm\nand show that equivariant maps correspond to time- and communication-efficient\nschedules for many topologies. We recover well known variants including the\nCannon's algorithm and the communication-avoiding \"2.5D\" algorithm for toroidal\ninterconnects, systolic computation for planar hexagonal VLSI arrays, recursive\nalgorithms for fat-trees, the cache-oblivious algorithm for the ideal cache\nmodel, and the space-bounded schedule for the parallel memory hierarchy model.\nThis suggests that the design of a schedule for a new class of machines can be\nmotivated by solutions to algebraic equations. \n\n"}
{"id": "1512.04622", "contents": "Title: Disk Dispersal: Theoretical Understanding and Observational Constraints Abstract: Protoplanetary disks dissipate rapidly after the central star forms, on\ntime-scales comparable to those inferred for planet formation. In order to\nallow the formation of planets, disks must survive the dispersive effects of UV\nand X-ray photoevaporation for at least a few Myr. Viscous accretion depletes\nsignificant amounts of the mass in gas and solids, while photoevaporative flows\ndriven by internal and external irradiation remove most of the gas. A\nreasonably large fraction of the mass in solids and some gas get incorporated\ninto planets. Here, we review our current understanding of disk evolution and\ndispersal, and discuss how these might affect planet formation. We also discuss\nexisting observational constraints on dispersal mechanisms and future\ndirections. \n\n"}
{"id": "1512.05172", "contents": "Title: On the performance overhead tradeoff of distributed principal component\n  analysis via data partitioning Abstract: Principal component analysis (PCA) is not only a fundamental dimension\nreduction method, but is also a widely used network anomaly detection\ntechnique. Traditionally, PCA is performed in a centralized manner, which has\npoor scalability for large distributed systems, on account of the large network\nbandwidth cost required to gather the distributed state at a fusion center.\nConsequently, several recent works have proposed various distributed PCA\nalgorithms aiming to reduce the communication overhead incurred by PCA without\nlosing its inferential power. This paper evaluates the tradeoff between\ncommunication cost and solution quality of two distributed PCA algorithms on a\nreal domain name system (DNS) query dataset from a large network. We also apply\nthe distributed PCA algorithm in the area of network anomaly detection and\ndemonstrate that the detection accuracy of both distributed PCA-based methods\nhas little degradation in quality, yet achieves significant savings in\ncommunication bandwidth. \n\n"}
{"id": "1601.00792", "contents": "Title: Ergodic decompositions of stationary max-stable processes in terms of\n  their spectral functions Abstract: We revisit conservative/dissipative and positive/null decompositions of\nstationary max-stable processes. Originally, both decompositions were defined\nin an abstract way based on the underlying non-singular flow representation. We\nprovide simple criteria which allow to tell whether a given spectral function\nbelongs to the conservative/dissipative or positive/null part of the de Haan\nspectral representation. Specifically, we prove that a spectral function is\nnull-recurrent iff it converges to $0$ in the Ces\\`{a}ro sense. For processes\nwith locally bounded sample paths we show that a spectral function is\ndissipative iff it converges to $0$. Surprisingly, for such processes a\nspectral function is integrable a.s. iff it converges to $0$ a.s. Based on\nthese results, we provide new criteria for ergodicity, mixing, and existence of\na mixed moving maximum representation of a stationary max-stable process in\nterms of its spectral functions. In particular, we study a decomposition of\nmax-stable processes which characterizes the mixing property. \n\n"}
{"id": "1601.04059", "contents": "Title: Parallel and Distributed Methods for Nonconvex Optimization--Part II:\n  Applications Abstract: In Part I of this paper, we proposed and analyzed a novel algorithmic\nframework for the minimization of a nonconvex (smooth) objective function,\nsubject to nonconvex constraints, based on inner convex approximations. This\nPart II is devoted to the application of the framework to some resource\nallocation problems in communication networks. In particular, we consider two\nnon-trivial case-study applications, namely: (generalizations of) i) the rate\nprofile maximization in MIMO interference broadcast networks; and the ii) the\nmax-min fair multicast multigroup beamforming problem in a multi-cell\nenvironment. We develop a new class of algorithms enjoying the following\ndistinctive features: i) they are \\emph{distributed} across the base stations\n(with limited signaling) and lead to subproblems whose solutions are computable\nin closed form; and ii) differently from current relaxation-based schemes\n(e.g., semidefinite relaxation), they are proved to always converge to\nd-stationary solutions of the aforementioned class of nonconvex problems.\nNumerical results show that the proposed (distributed) schemes achieve larger\nworst-case rates (resp. signal-to-noise interference ratios) than\nstate-of-the-art centralized ones while having comparable computational\ncomplexity. \n\n"}
{"id": "1601.04947", "contents": "Title: The Morphologies and Alignments of Gas, Mass, and the Central Galaxies\n  of CLASH Clusters of Galaxies Abstract: Morphology is often used to infer the state of relaxation of galaxy clusters.\nThe regularity, symmetry, and degree to which a cluster is centrally\nconcentrated inform quantitative measures of cluster morphology. The Cluster\nLensing and Supernova survey with Hubble Space Telescope (CLASH) used weak and\nstrong lensing to measure the distribution of matter within a sample of 25\nclusters, 20 of which were deemed to be relaxed based on their X-ray morphology\nand alignment of the X-ray emission with the BCG. Towards a quantitative\ncharacterization of this important sample of clusters, we present uniformly\nestimated X-ray morphological statistics for all 25 CLASH clusters. We compare\nX-ray morphologies of CLASH clusters with those identically measured for a\nlarge sample of simulated clusters from the MUSIC-2 simulations, selected by\nmass. We confirm a threshold in X-ray surface brightness concentration of C>0.4\nfor cool-core clusters, where C is the ratio of X-ray emission inside 100\nkpc/h70 compared to inside 500 kpc/h70. We report and compare morphologies of\nthese clusters inferred from Sunyaev-Zeldovich Effect (SZE) maps of the hot gas\nand in from projected mass maps based on strong and weak lensing. We find a\nstrong agreement in alignments of the orientation of major axes for the\nlensing, X-ray, and SZE maps of nearly all of the CLASH clusters at radii of\n500 kpc (approximately 0.5R500 for these clusters). We also find a striking\nalignment of clusters shapes at the 500 kpc scale, as measured with X-ray, SZE,\nand lensing, with that of the near-infrared stellar light at 10 kpc scales for\nthe 20 \"relaxed\" clusters. This strong alignment indicates a powerful coupling\nbetween the cluster- and galaxy-scale galaxy formation processes. \n\n"}
{"id": "1601.05166", "contents": "Title: Conical intersections for light and matter waves Abstract: We review the design, theory, and applications of two dimensional periodic\nlattices hosting conical intersections in their energy-momentum spectrum. The\nbest known example is the Dirac cone, where propagation is governed by an\neffective Dirac equation, with electron spin replaced by a \"fermionic\"\nhalf-integer pseudospin. However, in many systems such as metamaterials, modal\nsymmetries result in the formation of higher order conical intersections with\ninteger or \"bosonic\" pseudospin. The ability to engineer lattices with these\nqualitatively different singular dispersion relations opens up many\napplications, including superior slab lasers, generation of orbital angular\nmomentum, zero-index metamaterials, and quantum simulation of exotic phases of\nrelativistic matter. \n\n"}
{"id": "1601.05439", "contents": "Title: RepEx: A Flexible Framework for Scalable Replica Exchange Molecular\n  Dynamics Simulations Abstract: Replica Exchange (RE) simulations have emerged as an important algorithmic\ntool for the molecular sciences. RE simulations involve the concurrent\nexecution of independent simulations which infrequently interact and exchange\ninformation. The next set of simulation parameters are based upon the outcome\nof the exchanges.\n  Typically RE functionality is integrated into the molecular simulation\nsoftware package. A primary motivation of the tight integration of RE\nfunctionality with simulation codes has been performance. This is limiting at\nmultiple levels. First, advances in the RE methodology are tied to the\nmolecular simulation code. Consequently these advances remain confined to the\nmolecular simulation code for which they were developed. Second, it is\ndifficult to extend or experiment with novel RE algorithms, since expertise in\nthe molecular simulation code is typically required.\n  In this paper, we propose the RepEx framework which address these\naforementioned shortcomings of existing approaches, while striking the balance\nbetween flexibility (any RE scheme) and scalability (tens of thousands of\nreplicas) over a diverse range of platforms. RepEx is designed to use a\npilot-job based runtime system and support diverse RE Patterns and Execution\nModes. RE Patterns are concerned with synchronization mechanisms in RE\nsimulation, and Execution Modes with spatial and temporal mapping of workload\nto the CPU cores. We discuss how the design and implementation yield the\nfollowing primary contributions of the RepEx framework: (i) its ability to\nsupport different RE schemes independent of molecular simulation codes, (ii)\nprovide the ability to execute different exchange schemes and replica counts\nindependent of the specific availability of resources, (iii) provide a runtime\nsystem that has first-class support for task-level parallelism, and (iv)\nrequired scalability along multiple dimensions. \n\n"}
{"id": "1601.05904", "contents": "Title: Improving GPU-accelerated Adaptive IDW Interpolation Algorithm Using\n  Fast kNN Search Abstract: This paper presents an efficient parallel Adaptive Inverse Distance Weighting\n(AIDW) interpolation algorithm on modern Graphics Processing Unit (GPU). The\npresented algorithm is an improvement of our previous GPU-accelerated AIDW\nalgorithm by adopting fast k-Nearest Neighbors (kNN) search. In AIDW, it needs\nto find several nearest neighboring data points for each interpolated point to\nadaptively determine the power parameter; and then the desired prediction value\nof the interpolated point is obtained by weighted interpolating using the power\nparameter. In this work, we develop a fast kNN search approach based on the\nspace-partitioning data structure, even grid, to improve the previous\nGPU-accelerated AIDW algorithm. The improved algorithm is composed of the\nstages of kNN search and weighted interpolating. To evaluate the performance of\nthe improved algorithm, we perform five groups of experimental tests.\nExperimental results show that: (1) the improved algorithm can achieve a\nspeedup of up to 1017 over the corresponding serial algorithm; (2) the improved\nalgorithm is at least two times faster than our previous GPU-accelerated AIDW\nalgorithm; and (3) the utilization of fast kNN search can significantly improve\nthe computational efficiency of the entire GPU-accelerated AIDW algorithm. \n\n"}
{"id": "1601.06043", "contents": "Title: The Past, Present, and Future of Transport-Layer Multipath Abstract: Multipathing in communication networks is gaining momentum due to its\nattractive features of increased reliability, throughput, fault tolerance, and\nload balancing capabilities. In particular, wireless environments and\ndatacenters are envisioned to become largely dependent on the power of\nmultipathing for seamless handovers, virtual machine (VM) migration and in\ngeneral, pooling less proficient resources together for achieving overall high\nproficiency. The transport layer, with its knowledge about end-to-end path\ncharacteristics, is well placed to enhance performance through better\nutilization of multiple paths. Realizing the importance of transport-layer\nmultipath, this paper investigates the modernization of traditional connection\nestablishment, flow control, sequence number splitting, acknowledgement, and\nflow scheduling mechanisms for use with multiple paths. Since congestion\ncontrol defines a fundamental feature of the transport layer, we study the\nworking of multipath rate control and analyze its stability and convergence. We\nalso discuss how various multipath congestion control algorithms differ in\ntheir window increase and decrease functions, their TCP-friendliness, and\nresponsiveness. To the best of our knowledge, this is the first in-depth survey\npaper that has chronicled the evolution of the transport layer of the Internet\nfrom the traditional single-path TCP to the recent development of the modern\nmultipath TCP (MPTCP) protocol. Along with describing the history of this\nevolution, we also highlight in this paper the remaining challenges and\nresearch issues. \n\n"}
{"id": "1601.07420", "contents": "Title: A Workflow for Fast Evaluation of Mapping Heuristics Targeting Cloud\n  Infrastructures Abstract: Resource allocation is today an integral part of cloud infrastructures\nmanagement to efficiently exploit resources. Cloud infrastructures centers\ngenerally use custom built heuristics to define the resource allocations. It is\nan immediate requirement for the management tools of these centers to have a\nfast yet reasonably accurate simulation and evaluation platform to define the\nresource allocation for cloud applications. This work proposes a framework\nallowing users to easily specify mappings for cloud applications described in\nthe AMALTHEA format used in the context of the DreamCloud European project and\nto assess the quality for these mappings. The two quality metrics provided by\nthe framework are execution time and energy consumption. \n\n"}
{"id": "1602.00628", "contents": "Title: Ultrafast Depopulation of a Quantum Dot by LA-phonon-assisted Stimulated\n  Emission Abstract: We demonstrate ultrafast incoherent depopulation of a quantum dot from above\nto below the transparency point using LA-phonon-assisted emission stimulated by\na redshifted laser pulse. The QD is turned from a weakly vibronic system into a\nstrongly vibronic one by laser driving which enables the phonon-assisted\nrelaxation between the excitonic components of two dressed states. The\ndepopulation is achieved within a laser pulse-width-limited time of 20 ps and\nexhibits a broad tuning range of a few meV. Our experimental results are well\nreproduced by path-integral calculations. \n\n"}
{"id": "1602.01074", "contents": "Title: Photocurrents in Bi2Se3: bulk versus surface, and injection versus shift\n  currents Abstract: Optical injection and detection of charge currents can complement\nconventional transport and photoemission measurements without the necessity of\ninvasive contact that may disturb the system being examined. This is a\nparticular concern for the surface states of a topological insulator. In this\nwork one- and two-color sources of photocurrents are examined in epitaxial,\nthin films of Bi2Se3. We demonstrate that optical excitation and terahertz\ndetection simultaneously captures one- and two- color photocurrent\ncontributions, as previously not required in other material systems. A method\nis devised to isolate the two components, and in doing so each can be related\nto surface or bulk excitations through symmetry. This strategy allows surface\nstates to be examined in a model system, where they have independently been\nverified with angle-resolved photoemission spectroscopy. \n\n"}
{"id": "1602.01720", "contents": "Title: $L^2$-Stability of Traveling Wave Solutions to Nonlocal Evolution\n  Equations Abstract: Stability of the traveling wave solution to a general class of\none-dimensional nonlocal evolution equations is studied in $L^2$-spaces,\nthereby providing an alternative approach to the usual spectral analysis with\nrespect to the supremum norm. We prove that the linearization around the\ntraveling wave solution satisfies a Lyapunov-type stability condition in a\nweighted space $L^2(\\rho)$ for a naturally associated density $\\rho$. The\nresult can be applied to obtain stability of the traveling wave solution under\nstochastic perturbations of additive or multiplicative type. For small wave\nspeeds, we also prove an alternative Lyapunov-type stability condition in\n$L^2(\\mathfrak{m})$, where $\\mathfrak{m}$ is the symmetrizing density for the\ntraveling wave operator, which allows to derive a long-term stochastic\nstability result. \n\n"}
{"id": "1602.03156", "contents": "Title: Dielectric response and novel electromagnetic modes in three-dimensional\n  Dirac semimetal films Abstract: Using the Kubo formalism we have calculated the local dynamic conductivity of\na bulk, i.e., three-dimensional (3D), Dirac semimetal (BDS). We obtain that at\nfrequencies lower than Fermi energy the metallic response in a BDS film\nmanifests in the existence of surface-plasmon polaritons, but at higher\nfrequencies the dielectric response is dominated and it occurs that a BDS film\nbehaves as a dielectric waveguide. At this dielectric regime we predict the\nexistence inside a BDS film of novel electromagnetic modes, a 3D analog of the\ntransverse electric waves in graphene. We also find that the dielectric\nresponse manifests as the wide-angle passband in the mid-infrared (IR)\ntransmission spectrum of light incident on a BDS film, which can be used for\nthe interferenceless omnidirectional mid-IR filtering. The tuning of the Fermi\nlevel of the system allows us to switch between the metallic and the dielectric\nregimes and to change the frequency range of the predicted modes. This makes\nBDSs promising materials for photonics and plasmonics. \n\n"}
{"id": "1602.04419", "contents": "Title: Minimizing Message Size in Stochastic Communication Patterns: Fast\n  Self-Stabilizing Protocols with 3 bits Abstract: This paper considers the basic $\\mathcal{PULL}$ model of communication, in\nwhich in each round, each agent extracts information from few randomly chosen\nagents. We seek to identify the smallest amount of information revealed in each\ninteraction (message size) that nevertheless allows for efficient and robust\ncomputations of fundamental information dissemination tasks. We focus on the\nMajority Bit Dissemination problem that considers a population of $n$ agents,\nwith a designated subset of source agents. Each source agent holds an input bit\nand each agent holds an output bit. The goal is to let all agents converge\ntheir output bits on the most frequent input bit of the sources (the majority\nbit). Note that the particular case of a single source agent corresponds to the\nclassical problem of Broadcast. We concentrate on the severe fault-tolerant\ncontext of self-stabilization, in which a correct configuration must be reached\neventually, despite all agents starting the execution with arbitrary initial\nstates.\n  We first design a general compiler which can essentially transform any\nself-stabilizing algorithm with a certain property that uses $\\ell$-bits\nmessages to one that uses only $\\log \\ell$-bits messages, while paying only a\nsmall penalty in the running time. By applying this compiler recursively we\nthen obtain a self-stabilizing Clock Synchronization protocol, in which agents\nsynchronize their clocks modulo some given integer $T$, within $\\tilde O(\\log\nn\\log T)$ rounds w.h.p., and using messages that contain $3$ bits only.\n  We then employ the new Clock Synchronization tool to obtain a\nself-stabilizing Majority Bit Dissemination protocol which converges in $\\tilde\nO(\\log n)$ time, w.h.p., on every initial configuration, provided that the\nratio of sources supporting the minority opinion is bounded away from half.\nMoreover, this protocol also uses only 3 bits per interaction. \n\n"}
{"id": "1602.05224", "contents": "Title: A simple and general proof for the convergence of Markov processes to\n  their mean-field limits Abstract: Mean-field models approximate large stochastic systems by simpler\ndifferential equations that are supposed to approximate the mean of the larger\nsystem. It is generally assumed that as the stochastic systems get larger\n(i.e., more people or particles), they converge to the mean-field models.\nMean-field models are common in many fields, but their convergence is rarely\nproved. The existing approaches rely on operator semigroups, martingales, PDEs,\nor infinite systems of ODEs. We give a general proof for their convergence\nusing only Taylor's theorem and basic ODE results. We hope this allows applied\nresearchers to routinely show convergence of their mean-field models, putting\ntheir work on a stronger foundation. \n\n"}
{"id": "1602.05893", "contents": "Title: On the recovery of ISW fluctuations using large-scale structure tracers\n  and CMB temperature and polarization anisotropies Abstract: In this work we present a method to extract the signal induced by the\nintegrated Sachs-Wolfe (ISW) effect in the cosmic microwave background (CMB).\nIt makes use of the Linear Covariance-Based filter introduced by Barreiro et\nal., and combines CMB data with any number of large-scale structure (LSS)\nsurveys and lensing information. It also exploits CMB polarization to reduce\ncosmic variance. The performance of the method has been thoroughly tested with\nsimulations taking into account the impact of non-ideal conditions such as\nincomplete sky coverage or the presence of noise. In particular, three galaxy\nsurveys are simulated, whose redshift distributions peak at low ($z \\simeq\n0.3$), intermediate ($z \\simeq 0.6$) and high redshift ($z \\simeq 0.9$). The\ncontribution of each of the considered data sets as well as the effect of a\nmask and noise in the reconstructed ISW map is studied in detail. When\ncombining all the considered data sets (CMB temperature and polarization, the\nthree galaxy surveys and the lensing map), the proposed filter successfully\nreconstructs a map of the weak ISW signal, finding a perfect correlation with\nthe input signal for the ideal case and around 80 per cent, on average, in the\npresence of noise and incomplete sky coverage. We find that including CMB\npolarization improves the correlation between input and reconstruction although\nonly at a small level. Nonetheless, given the weakness of the ISW signal, even\nmodest improvements can be of importance. In particular, in realistic\nsituations, in which less information is available from the LSS tracers, the\neffect of including polarisation is larger. For instance, for the case in which\nthe ISW signal is recovered from CMB plus only one survey, and taking into\naccount the presence of noise and incomplete sky coverage, the improvement in\nthe correlation coefficient can be as large as 10 per cent. \n\n"}
{"id": "1602.08166", "contents": "Title: An Exponential Separation Between Randomized and Deterministic\n  Complexity in the LOCAL Model Abstract: Over the past 30 years numerous algorithms have been designed for symmetry\nbreaking problems in the LOCAL model, such as maximal matching, MIS, vertex\ncoloring, and edge-coloring. For most problems the best randomized algorithm is\nat least exponentially faster than the best deterministic algorithm. In this\npaper we prove that these exponential gaps are necessary and establish\nconnections between the deterministic and randomized complexities in the LOCAL\nmodel. Each result has a very compelling take-away message:\n  1. Fast $\\Delta$-coloring of trees requires random bits: Building on the\nrecent lower bounds of Brandt et al., we prove that the randomized complexity\nof $\\Delta$-coloring a tree with maximum degree $\\Delta\\ge 55$ is\n$\\Theta(\\log_\\Delta\\log n)$, whereas its deterministic complexity is\n$\\Theta(\\log_\\Delta n)$ for any $\\Delta\\ge 3$. This also establishes a large\nseparation between the deterministic complexity of $\\Delta$-coloring and\n$(\\Delta+1)$-coloring trees.\n  2. Randomized lower bounds imply deterministic lower bounds: We prove that\nany deterministic algorithm for a natural class of problems that runs in\n$O(1)+o(\\log_\\Delta n)$ rounds can be transformed to run in\n$O(\\log^*n-\\log^*\\Delta+1)$ rounds. If the transformed algorithm violates a\nlower bound (even allowing randomization), then one can conclude that the\nproblem requires $\\Omega(\\log_\\Delta n)$ time deterministically.\n  3. Deterministic lower bounds imply randomized lower bounds: We prove that\nthe randomized complexity of any natural problem on instances of size $n$ is at\nleast its deterministic complexity on instances of size $\\sqrt{\\log n}$. This\nshows that a deterministic $\\Omega(\\log_\\Delta n)$ lower bound for any problem\nimplies a randomized $\\Omega(\\log_\\Delta\\log n)$ lower bound. It also\nillustrates that the graph shattering technique is absolutely essential to the\nLOCAL model. \n\n"}
{"id": "1602.09039", "contents": "Title: Dynamic Channel Allocation for Interference Mitigation in Relay-assisted\n  Wireless Body Networks Abstract: We focus on interference mitigation and energy conservation within a single\nwireless body area network (WBAN). We adopt two-hop communication scheme\nsupported by the the IEEE 802.15.6 standard (2012). In this paper, we propose a\ndynamic channel allocation scheme, namely DCAIM to mitigate node-level\ninterference amongst the coexisting regions of a WBAN. At the time, the sensors\nare in the radius communication of a relay, they form a relay region (RG)\ncoordinated by that relay using time division multiple access (TDMA). In the\nproposed scheme, each RG creates a table consisting of interfering sensors\nwhich it broadcasts to its neighboring sensors. This broadcast allows each pair\nof RGs to create an interference set (IS). Thus, the members of IS are assigned\northogonal sub-channels whereas other sonsors that do not belong to IS can\ntransmit using the same time slots. Experimental results show that our proposal\nmitigates node-level interference and improves node and WBAN energy savings.\nThese results are then compared to the results of other schemes. As a result,\nour scheme outperforms in all cases. Node-level signal to interference and\nnoise ratio (SINR) improved by 11dB whilst, the energy consumption decreased\nsignificantly. We further present a probabilistic method and analytically show\nthe outage probability can be effectively reduced to the minimal. \n\n"}
{"id": "1603.00307", "contents": "Title: A Graph-Based Semantics Workbench for Concurrent Asynchronous Programs Abstract: A number of novel programming languages and libraries have been proposed that\noffer simpler-to-use models of concurrency than threads. It is challenging,\nhowever, to devise execution models that successfully realise their\nabstractions without forfeiting performance or introducing unintended\nbehaviours. This is exemplified by SCOOP---a concurrent object-oriented\nmessage-passing language---which has seen multiple semantics proposed and\nimplemented over its evolution. We propose a \"semantics workbench\" with fully\nand semi-automatic tools for SCOOP, that can be used to analyse and compare\nprograms with respect to different execution models. We demonstrate its use in\nchecking the consistency of semantics by applying it to a set of representative\nprograms, and highlighting a deadlock-related discrepancy between the principal\nexecution models of the language. Our workbench is based on a modular and\nparameterisable graph transformation semantics implemented in the GROOVE tool.\nWe discuss how graph transformations are leveraged to atomically model\nintricate language abstractions, and how the visual yet algebraic nature of the\nmodel can be used to ascertain soundness. \n\n"}
{"id": "1603.02526", "contents": "Title: Testing fine-grained parallelism for the ADMM on a factor-graph Abstract: There is an ongoing effort to develop tools that apply distributed\ncomputational resources to tackle large problems or reduce the time to solve\nthem. In this context, the Alternating Direction Method of Multipliers (ADMM)\narises as a method that can exploit distributed resources like the dual ascent\nmethod and has the robustness and improved convergence of the augmented\nLagrangian method. Traditional approaches to accelerate the ADMM using multiple\ncores are problem-specific and often require multi-core programming. By\ncontrast, we propose a problem-independent scheme of accelerating the ADMM that\ndoes not require the user to write any parallel code. We show that this scheme,\nan interpretation of the ADMM as a message-passing algorithm on a factor-graph,\ncan automatically exploit fine-grained parallelism both in GPUs and\nshared-memory multi-core computers and achieves significant speedup in such\ndiverse application domains as combinatorial optimization, machine learning,\nand optimal control. Specifically, we obtain 10-18x speedup using a GPU, and\n5-9x using multiple CPU cores, over a serial, optimized C-version of the ADMM,\nwhich is similar to the typical speedup reported for existing GPU-accelerated\nlibraries, including cuFFT (19x), cuBLAS (17x), and cuRAND (8x). \n\n"}
{"id": "1603.04612", "contents": "Title: Microcavity with saturable nonlinearity under simultaneous resonant and\n  nonresonant pumping: multistability, Hopf bifurcations and chaotic behaviour Abstract: We studied optical response of microcavity non-equilibrium exciton-polariton\nBose-Einstein condensate with saturable nonlinearity under simultaneous\nresonant and non-resonant pumping. We demonstrated the emergence of\nmultistabile behavior due to the satutration of the excitonic absorbtion.\nStable periodic Rabi- type oscillations of the excitonic and photonic\ncondensate components in the regime of the stationary pump and their transition\nto the chaotic dynamics through the cascade of Hopf bifurcations by tuning of\nthe electrical pump are revealed. \n\n"}
{"id": "1603.05752", "contents": "Title: Optimal Response to Burstable Billing under Demand Uncertainty Abstract: Burstable billing is widely adopted in practice, e.g., by colocation data\ncenter providers, to charge for their users, e.g., data centers, for data\ntransferring. However, there is still a lack of research on what the best way\nis for a user to manage its workload in response to burstable billing. To\novercome this shortcoming, we propose a novel method to optimally respond to\nburstable billing under demand uncertainty. First, we develop a tractable\nmathematical expression to calculate the 95th percentile usage of a user, who\nis charged by provider via burstable billing for bandwidth usage. This model is\nthen used to formulate a new bandwidth allocation problem to maximize the\nuser's surplus, i.e., its net utility minus cost. Additionally, we examine\ndifferent non-convex solution methods for the formulated stochastic\noptimization problem. We also extend our design to the case where a user can\nreceive service from multiple providers, who all employ burstable billing.\nUsing real-world workload traces, we show that our proposed method can reduce\nuser's bandwidth cost by 26% and increase its total surplus by 23%, compared to\nthe current practice of allocating bandwidth on-demand. \n\n"}
{"id": "1603.07322", "contents": "Title: On Delay-Optimal Scheduling in Queueing Systems with Replications Abstract: In modern computer systems, jobs are divided into short tasks and executed in\nparallel. Empirical observations in practical systems suggest that the task\nservice times are highly random and the job service time is bottlenecked by the\nslowest straggling task. One common solution for straggler mitigation is to\nreplicate a task on multiple servers and wait for one replica of the task to\nfinish early. The delay performance of replications depends heavily on the\nscheduling decisions of when to replicate, which servers to replicate on, and\nwhich job to serve first. So far, little is understood on how to optimize these\nscheduling decisions for minimizing the delay to complete the jobs. In this\npaper, we present a comprehensive study on delay-optimal scheduling of\nreplications in both centralized and distributed multi-server systems.\nLow-complexity scheduling policies are designed and are proven to be\ndelay-optimal or near delay-optimal in stochastic ordering among all causal and\nnon-preemptive policies. These theoretical results are established for general\nsystem settings and delay metrics that allow for arbitrary arrival processes,\narbitrary job sizes, arbitrary due times, and heterogeneous servers with data\nlocality constraints. Novel sample-path tools are developed to prove these\nresults. \n\n"}
{"id": "1604.00689", "contents": "Title: Observation of pair tunneling and coherent destruction of tunneling in\n  arrays of optical waveguides Abstract: We report on the experimental realization of a photonic system that simulates\nthe one-dimensional two-particle Hubbard model. This analogy is realized by\nmeans of two-dimensional arrays of coupled optical waveguides, fabricated using\nfemtosecond laser inscription. By tuning the analogous \"interaction strength\",\nwe reach the strongly-interacting regime of the Hubbard Hamiltonian, and\ndemonstrate the suppression of standard tunneling for individual \"particles\".\nIn this regime, the formation of bound states is identified through the direct\nobservation of pair tunneling. We then demonstrate the coherent destruction of\ntunneling (CDT) for the paired particles in the presence of an engineered\noscillating force of high frequency. The precise control over the analogous\n\"interaction strength\" and driving force offered by our experimental system\nopens an exciting route towards quantum simulation of few-body physics in\nphotonics. \n\n"}
{"id": "1604.02475", "contents": "Title: Performance Limits for Noisy Multi-Measurement Vector Problems Abstract: Compressed sensing (CS) demonstrates that sparse signals can be estimated\nfrom under-determined linear systems. Distributed CS (DCS) further reduces the\nnumber of measurements by considering joint sparsity within signal ensembles.\nDCS with jointly sparse signals has applications in multi-sensor acoustic\nsensing, magnetic resonance imaging with multiple coils, remote sensing, and\narray signal processing. Multi-measurement vector (MMV) problems consider the\nestimation of jointly sparse signals under the DCS framework. Two related MMV\nsettings are studied. In the first setting, each signal vector is measured by a\ndifferent independent and identically distributed (i.i.d.) measurement matrix,\nwhile in the second setting, all signal vectors are measured by the same i.i.d.\nmatrix. Replica analysis is performed for these two MMV settings, and the\nminimum mean squared error (MMSE), which turns out to be identical for both\nsettings, is obtained as a function of the noise variance and number of\nmeasurements. To showcase the application of MMV models, the MMSE's of complex\nCS problems with both real and complex measurement matrices are also analyzed.\nMultiple performance regions for MMV are identified where the MMSE behaves\ndifferently as a function of the noise variance and the number of measurements.\n  Belief propagation (BP) is a CS signal estimation framework that often\nachieves the MMSE asymptotically. A phase transition for BP is identified. This\nphase transition, verified by numerical results, separates the regions where BP\nachieves the MMSE and where it is suboptimal. Numerical results also illustrate\nthat more signal vectors in the jointly sparse signal ensemble lead to a better\nphase transition. \n\n"}
{"id": "1604.03410", "contents": "Title: High-level GPU programming in Julia Abstract: GPUs are popular devices for accelerating scientific calculations. However,\nas GPU code is usually written in low-level languages, it breaks the\nabstractions of high-level languages popular with scientific programmers. To\novercome this, we present a framework for CUDA GPU programming in the\nhigh-level Julia programming language. This framework compiles Julia source\ncode for GPU execution, and takes care of the necessary low-level interactions\nusing modern code generation techniques to avoid run-time overhead.\n  Evaluating the framework and its APIs on a case study comprising the trace\ntransform from the field of image processing, we find that the impact on\nperformance is minimal, while greatly increasing programmer productivity. The\nmetaprogramming capabilities of the Julia language proved invaluable for\nenabling this. Our framework significantly improves usability of GPUs, making\nthem accessible for a wide range of programmers. It is available as free and\nopen-source software licensed under the MIT License. \n\n"}
{"id": "1604.04259", "contents": "Title: Optical-nanofiber-based interface for single molecules Abstract: Optical interfaces for quantum emitters are a prerequisite for implementing\nquantum networks. Here, we couple single molecules to the guided modes of an\noptical nanofiber. The molecules are embedded within a crystal that provides\nphotostability and, due to the inhomogeneous broadening, a means to spectrally\naddress single molecules. Single molecules are excited and detected solely via\nthe nanofiber interface without the requirement of additional optical access.\nIn this way, we realize a fully fiber-integrated system that is scalable and\nmay become a versatile constituent for quantum hybrid systems. \n\n"}
{"id": "1604.05612", "contents": "Title: Experimental observation of anomalous topological edge modes in a\n  slowly-driven photonic lattice Abstract: The discovery of the quantised Hall effect, and its subsequent topological\nexplanation, demonstrated the important role topology can play in determining\nthe properties of quantum systems. This realisation led to the development of\ntopological band theory, where, in addition to band index and quasimomentum,\nBloch bands are also characterised by a set of topological invariants. This\ntopological theory can be readily extended to periodically-driven systems. In\nthe limit of fast driving, the topology of the system can still be captured by\nthe topological invariants used to describe static systems. In the limit of\nslow driving, however, situations can arise where standard topological\ninvariants are zero, but yet, topologically protected edge modes are still\nobserved. These \"anomalous\" topological edge modes have no static analogue, and\nare associated with a distinct topological invariant, which takes into account\nthe full time-evolution over a driving period. Here we demonstrate the first\nexperimental observation of such anomalous topological edge modes in an\nultrafast-laser-inscribed photonic lattice. This inscription technique allows\none to address each bond of a lattice independently and dynamically, generating\na rich band structure with robust anomalous chiral edge modes and the potential\nfor perfectly localised bulk states. \n\n"}
{"id": "1604.06853", "contents": "Title: Adaptive Content-based Routing using Subscription Subgrouping in\n  Structured Overlays Abstract: Cyclic or general overlays may provide multiple paths between publishers and\nsubscribers. However, an advertisement tree and a matching subscription\nactivates only one path for notifications routing in publish/subscribe systems.\nThis poses serious challenges in handling network conditions like congestion,\nand link or broker failures. Further, content-based dynamic routing of\nnotifications requires instantaneous updates in routing paths, which is not a\nscalable option. This paper introduces a clustering approach with a bit-vector\ntechnique for inter-cluster dynamic routing of notifications in a structured\ncyclic topology that provides multiple paths between publishers and interested\nsubscribers. The advertisement forwarding process exploits the structured\nnature of the overlay topology to generate advertisement trees of length 1\nwithout generating duplicate messages in the advertisement forwarding process.\nIssued subscriptions are divided into multiple disjoint subgropus, where each\nsubscription is broadcast to a cluster, which is a limited part of the\nstructured cyclic overlay network. We implemented novel static and\nintra-cluster dynamic routing algorithms in the proposed overlay topology for\nour advertisement-based publish/subscribe system, called OctopiA. We also\nperformed a pragmatic comparison of our two algorithms with the\nstate-of-the-art. Experiments on a cluster testbed show that our approach\ngenerates fewer inter-broker messages, and is scalable. \n\n"}
{"id": "1604.07086", "contents": "Title: A Fundamental Tradeoff between Computation and Communication in\n  Distributed Computing Abstract: How can we optimally trade extra computing power to reduce the communication\nload in distributed computing? We answer this question by characterizing a\nfundamental tradeoff between computation and communication in distributed\ncomputing, i.e., the two are inversely proportional to each other.\n  More specifically, a general distributed computing framework, motivated by\ncommonly used structures like MapReduce, is considered, where the overall\ncomputation is decomposed into computing a set of \"Map\" and \"Reduce\" functions\ndistributedly across multiple computing nodes. A coded scheme, named \"Coded\nDistributed Computing\" (CDC), is proposed to demonstrate that increasing the\ncomputation load of the Map functions by a factor of $r$ (i.e., evaluating each\nfunction at $r$ carefully chosen nodes) can create novel coding opportunities\nthat reduce the communication load by the same factor.\n  An information-theoretic lower bound on the communication load is also\nprovided, which matches the communication load achieved by the CDC scheme. As a\nresult, the optimal computation-communication tradeoff in distributed computing\nis exactly characterized.\n  Finally, the coding techniques of CDC is applied to the Hadoop TeraSort\nbenchmark to develop a novel CodedTeraSort algorithm, which is empirically\ndemonstrated to speed up the overall job execution by $1.97\\times$ -\n$3.39\\times$, for typical settings of interest. \n\n"}
{"id": "1604.08618", "contents": "Title: Stringer: Balancing Latency and Resource Usage in Service Function Chain\n  Provisioning Abstract: Network Functions Virtualization, or NFV, enables telecommunications\ninfrastructure providers to replace special-purpose networking equipment with\ncommodity servers running virtualized network functions (VNFs). A service\nprovider utilizing NFV technology faces the SFC provisioning problem of\nassigning VNF instances to nodes in the physical infrastructure (e.g., a\ndatacenter), and routing Service Function Chains (sequences of functions\nrequired by customers, a.k.a. SFCs) in the physical network. In doing so, the\nprovider must balance between various competing goals of performance and\nresource usage. We present an approach for SFC provisioning, consisting of\nthree elements. The first element is a fast, scalable round-robin heuristic.\nThe second element is a Mixed Integer Programming (MIP) based approach. The\nthird element is a queueing-theoretic model to estimate the average latency\nassociated with any SFC provisioning solution. Combined, these elements create\nan approach that generates a set of SFC provisioning solutions, reflecting\ndifferent tradeoffs between resource usage and performance. \n\n"}
{"id": "1605.00539", "contents": "Title: Introduction to Quantum-limited Parametric Amplification of Quantum\n  Signals with Josephson Circuits Abstract: This short and opinionated review starts with a concept of quantum signals at\nmicrowave frequencies and focuses on the principle of linear parametric\namplification. The amplification process arises from the dispersive\nnonlinearity of Josephson junctions driven with appropriate tones. We discuss\ntwo defining characteristics of these amplifiers: the number of modes receiving\nthe signal, idler and pump waves and the number of independent ports through\nwhich these waves enter into the circuit. \n\n"}
{"id": "1605.02782", "contents": "Title: Hall viscosity and electromagnetic response of electrons in graphene Abstract: We derive an analytic expression for the geometric Hall viscosity of\nnon-interacting electrons in a single graphene layer in the presence of a\nperpendicular magnetic field. We show that a recently-derived formula in [C.\nHoyos and D. T. Son, Phys. Rev. Lett. {\\bf 108}, 066805 (2012)], which connects\nthe coefficient of $q^2$ in the wave vector expansion of the Hall conductivity\n$\\sigma_{xy}(q)$ of the two-dimensional electron gas (2DEG) to the Hall\nviscosity and the orbital diamagnetic susceptibility of that system, continues\nto hold for graphene -- in spite of the lack of Galilean invariance -- with a\nsuitable definition of the effective mass. We also show that, for a\nsufficiently large number of occupied Landau levels in the positive energy\nsector, the Hall conductivity of electrons in graphene reduces to that of a\nGalilean-invariant 2DEG with an effective mass given by $\\hbar k_F/v_F$\n(cyclotron mass). Even in the most demanding case, i.e. when the chemical\npotential falls between the zero-th and the first Landau level, the cyclotron\nmass formula gives results accurate to better than 1$\\%$. The connection\nbetween the Hall conductivity and the viscosity provides a possible avenue to\nmeasure the Hall viscosity in graphene. \n\n"}
{"id": "1605.03138", "contents": "Title: Nanocavity optomechanical torque magnetometry and radiofrequency\n  susceptometry Abstract: Nanophotonic optomechanical devices allow observation of nanoscale vibrations\nwith sensitivity that has dramatically advanced metrology of nanomechanical\nstructures [1-9] and has the potential to impact studies of nanoscale physical\nsystems in a similar manner [10, 11]. Here we demonstrate this potential with a\nnanophotonic optomechanical torque magnetometer and radiofrequency (RF)\nmagnetic susceptometer. Exquisite readout sensitivity provided by a nanocavity\nintegrated within a torsional nanomechanical resonator enables observations of\nthe unique net magnetization and RF-driven responses of single mesoscopic\nmagnetic structures in ambient conditions. The magnetic moment resolution is\nsufficient for observation of Barkhausen steps in the magnetic hysteresis of a\nlithographically patterned permalloy island [12]. In addition, significantly\nenhanced RF susceptibility is found over narrow field ranges and attributed to\nthermally assisted driven hopping of a magnetic vortex core between neighboring\npinning sites [13]. The on-chip magneto-susceptometer scheme offers a promising\npath to powerful integrated cavity optomechanical devices for quantitative\ncharacterization of magnetic micro- and nanosystems in science and technology. \n\n"}
{"id": "1605.03874", "contents": "Title: Dimension of harmonic measures in hyperbolic spaces Abstract: We show exact dimensionality of harmonic measures associated with random\nwalks on groups acting on a hyperbolic space under finite first moment\ncondition, and establish the dimension formula by the entropy over the drift.\nWe also treat the case when a group acts on a non-proper hyperbolic space\nacylindrically. Applications of this formula include continuity of the\nHausdorff dimension with respect to driving measures and Brownian motions on\nregular coverings of a finite volume Riemannian manifold. \n\n"}
{"id": "1605.04447", "contents": "Title: A New Method for Parallel Monte Carlo Tree Search Abstract: In recent years there has been much interest in the Monte Carlo tree search\nalgorithm, a new, adaptive, randomized optimization algorithm. In fields as\ndiverse as Artificial Intelligence, Operations Research, and High Energy\nPhysics, research has established that Monte Carlo tree search can find good\nsolutions without domain dependent heuristics. However, practice shows that\nreaching high performance on large parallel machines is not so successful as\nexpected. This paper proposes a new method for parallel Monte Carlo tree search\nbased on the pipeline computation pattern. \n\n"}
{"id": "1605.07307", "contents": "Title: Revealing and Characterizing Dark Excitons Through Coherent\n  Multidimensional Spectroscopy Abstract: Dark excitons are of fundamental importance in a broad range of contexts, but\nare difficult to study using conventional optical spectroscopy due to their\nweak interaction with light. We show how coherent multidimensional spectroscopy\ncan reveal and characterize dark states. Using this approach, we identify\ndifferent types of dark excitons in InGaAs/GaAs quantum wells and determine\ndetails regarding lifetimes, homogeneous and inhomogeneous linewidths,\nbroadening mechanisms and coupling strengths. The observations of coherent\ncoupling between bright and dark excitons hint at a role for a multi-step\nprocess by which excitons in the barrier can relax into the quantum wells. \n\n"}
{"id": "1605.08023", "contents": "Title: Online Placement of Multi-Component Applications in Edge Computing\n  Environments Abstract: Mobile edge computing is a new cloud computing paradigm which makes use of\nsmall-sized edge-clouds to provide real-time services to users. These mobile\nedge-clouds (MECs) are located in close proximity to users, thus enabling users\nto seamlessly access applications running on MECs. Due to the co-existence of\nthe core (centralized) cloud, users, and one or multiple layers of MECs, an\nimportant problem is to decide where (on which computational entity) to place\ndifferent components of an application. This problem, known as the application\nor workload placement problem, is notoriously hard, and therefore, heuristic\nalgorithms without performance guarantees are generally employed in common\npractice, which may unknowingly suffer from poor performance as compared to the\noptimal solution. In this paper, we address the application placement problem\nand focus on developing algorithms with provable performance bounds. We model\nthe user application as an application graph and the physical computing system\nas a physical graph, with resource demands/availabilities annotated on these\ngraphs. We first consider the placement of a linear application graph and\npropose an algorithm for finding its optimal solution. Using this result, we\nthen generalize the formulation and obtain online approximation algorithms with\npolynomial-logarithmic (poly-log) competitive ratio for tree application graph\nplacement. We jointly consider node and link assignment, and incorporate\nmultiple types of computational resources at nodes. \n\n"}
{"id": "1605.08447", "contents": "Title: Operation of a semiconductor microcavity under electric excitation Abstract: We present a microscopic theory for the description of the bias-controlled\noperation of an exciton-polariton-based heterostructure, in particular, the\npolariton laser. Combining together the Poisson equations for the scalar\nelectric potential and Fermi quasi-energies of electrons and holes in a\nsemiconductor heterostructure, the Boltzmann equation for the incoherent\nexcitonic reservoir and the Gross-Pitaevskii equation for the exciton-polariton\nmean field, we simulate the dynamics of the system minimising the number of\nfree parameters and for the first time build a theoretical threshold\ncharacteristics: number of particles vs applied bias. This approach, which also\naccounts for the nonlinear (exciton-exciton) interaction, particle lifetime,\nand which can, in principle, account for any relaxation mechanisms for the\ncarriers of charge inside the heterostructure or polariton loss, allows to\ncompletely describe modern experiments on polariton transport and model new\ndevices. \n\n"}
{"id": "1605.08695", "contents": "Title: TensorFlow: A system for large-scale machine learning Abstract: TensorFlow is a machine learning system that operates at large scale and in\nheterogeneous environments. TensorFlow uses dataflow graphs to represent\ncomputation, shared state, and the operations that mutate that state. It maps\nthe nodes of a dataflow graph across many machines in a cluster, and within a\nmachine across multiple computational devices, including multicore CPUs,\ngeneral-purpose GPUs, and custom designed ASICs known as Tensor Processing\nUnits (TPUs). This architecture gives flexibility to the application developer:\nwhereas in previous \"parameter server\" designs the management of shared state\nis built into the system, TensorFlow enables developers to experiment with\nnovel optimizations and training algorithms. TensorFlow supports a variety of\napplications, with particularly strong support for training and inference on\ndeep neural networks. Several Google services use TensorFlow in production, we\nhave released it as an open-source project, and it has become widely used for\nmachine learning research. In this paper, we describe the TensorFlow dataflow\nmodel in contrast to existing systems, and demonstrate the compelling\nperformance that TensorFlow achieves for several real-world applications. \n\n"}
{"id": "1605.08822", "contents": "Title: Two-Dimensionally Confined Topological Edge States in Photonic Crystals Abstract: We present an all-dielectric photonic crystal structure that supports\ntwo-dimensionally confined helical topological edge states. The topological\nproperties of the system are controlled by the crystal parameters. An interface\nbetween two regions of differing band topologies gives rise to topological edge\nstates confined in a dielectric slab that propagate around sharp corners\nwithout backscattering. Three dimensional finite-difference time-domain\ncalculations show these edges to be confined in the out-of-plane direction by\ntotal internal reflection. Such nanoscale photonic crystal architectures could\nenable strong interactions between photonic edge states and quantum emitters. \n\n"}
{"id": "1605.09033", "contents": "Title: Non-radiating sources, dynamic anapole and Aharonov-Bohm effect Abstract: We show that for a particular choice of gauge the vector potential of any\nnon-radiating source is spatially localized along with its electric and\nmagnetic fields. Important on its own, this special property of non-radiating\nsources dramatically simplifies the analysis of their quantitative aspects, and\nenables the interpretation of non-radiating sources as distributions of the\nelementary dynamic anapoles. Using the developed approach we identify and\ndiscuss a possible scenario for observing the time-dependent version of the\nAharonov-Bohm effect in such systems. \n\n"}
{"id": "1605.09501", "contents": "Title: Edge Solitons in Nonlinear Photonic Topological Insulators Abstract: We show theoretically that a photonic topological insulator can support edge\nsolitons that are strongly self-localized and propagate unidirectionally along\nthe lattice edge. The photonic topological insulator consists of a Floquet\nlattice of coupled helical waveguides, in a medium with local Kerr\nnonlinearity. The soliton behavior is strongly affected by the topological\nphase of the linear lattice. The topologically nontrivial phase gives a\ncontinuous family of solitons, while the topologically trivial phase gives an\nembedded soliton that occurs at a single power, and arises from a self-induced\nlocal nonlinear shift in the inter-site coupling. The solitons can be used for\nnonlinear switching and logical operations, functionalities that have not yet\nbeen explored in topological photonics. We demonstrate using solitons to\nperform selective filtering via propagation through a narrow channel, and using\nsoliton collisions for optical switching. \n\n"}
{"id": "1605.09645", "contents": "Title: Light-Sound Interaction in Nanoscale Silicon Waveguides Abstract: This thesis studies the interaction between near-infrared light and gigahertz\nsound in nanoscale silicon waveguides. Chapter 2 introduces photon-phonon\ncoupling and its theoretical description, describing basic mechanisms and\ndeveloping a quantum field theory of the process. Chapter 3 explores the\ndynamical effects in both waveguides and cavities. It also proves a connection\nbetween the Brillouin gain coefficient and the vacuum coupling rate. Chapter 4\ndeals with the observation of Brillouin scattering in nanoscale silicon\nwaveguides. The waveguides tightly confine $193 \\, \\text{THz}$ light and $10 \\,\n\\text{GHz}$ acoustic vibrations. The acoustic quality factor remains limited to\nabout $300$ because of leakage into silica substrate. These waveguides are\noptically transparent in a narrow band of frequencies at a pump power of $25 \\,\n\\text{mW}$. Besides this amplification, we translate a $10 \\, \\text{GHz}$\nmicrowave signal across $1 \\, \\text{THz}$. Chapter 5 extends the experimental\nwork of chapter 4 by fabricating a cascade of fully suspended nanowires held by\nsilica anchors. This enhances the mechanical quality factor from $300$ to\n$1000$, enabling the observation of Brillouin amplification exceeding the\npropagation losses in silicon. The amount of amplification is mostly limited by\na rapid drop in acoustic quality as the number of suspensions increases. We\npropose a mechanism to cancel this inhomogeneous broadening. Chapter 6 looks at\nthe potential of narrow silicon slot waveguides to enhance the optomechanical\ncoupling. For certain dimensions, these waveguides support opto-acoustic modes\nwith an interaction efficiency simulated an order of magnitude above those of\nsingle-nanobeam systems. \n\n"}
{"id": "1606.01581", "contents": "Title: Big Data Caching for Networking: Moving from Cloud to Edge Abstract: In order to cope with the relentless data tsunami in $5G$ wireless networks,\ncurrent approaches such as acquiring new spectrum, deploying more base stations\n(BSs) and increasing nodes in mobile packet core networks are becoming\nineffective in terms of scalability, cost and flexibility. In this regard,\ncontext-aware $5$G networks with edge/cloud computing and exploitation of\n\\emph{big data} analytics can yield significant gains to mobile operators. In\nthis article, proactive content caching in $5$G wireless networks is\ninvestigated in which a big data-enabled architecture is proposed. In this\npractical architecture, vast amount of data is harnessed for content popularity\nestimation and strategic contents are cached at the BSs to achieve higher\nusers' satisfaction and backhaul offloading. To validate the proposed solution,\nwe consider a real-world case study where several hours of mobile data traffic\nis collected from a major telecom operator in Turkey and a big data-enabled\nanalysis is carried out leveraging tools from machine learning. Based on the\navailable information and storage capacity, numerical studies show that several\ngains are achieved both in terms of users' satisfaction and backhaul\noffloading. For example, in the case of $16$ BSs with $30\\%$ of content ratings\nand $13$ Gbyte of storage size ($78\\%$ of total library size), proactive\ncaching yields $100\\%$ of users' satisfaction and offloads $98\\%$ of the\nbackhaul. \n\n"}
{"id": "1606.02942", "contents": "Title: Analysis of buffering effects on hard real-time priority-preemptive\n  wormhole networks Abstract: There are several approaches to analyse the worst-case response times of\nsporadic packets transmitted over priority-preemptive wormhole networks. In\nthis paper, we provide an overview of the different approaches, discuss their\nstrengths and weaknesses, and propose an approach that captures all effects\nconsidered by previous approaches while providing tight yet safe upper bounds\nfor packet response times. We specifically address the problems created by\nbuffering and backpressure in wormhole networks, which amplifies the problem of\nindirect interference in a way that has not been considered by the early\nanalysis approaches. Didactic examples and large-scale experiments with\nsynthetically generated packet flow sets provide evidence of the strength of\nthe proposed approach. \n\n"}
{"id": "1606.03614", "contents": "Title: Femtosecond spin current pulses generated by the non-thermal\n  spin-dependent Seebeck effect and interacting with ferromagnets in spin\n  valves Abstract: Using the sensitivity of magneto-induced second harmonic generation to spin\ncurrents (SC), we demonstrate in Fe/Au/Fe/MgO(001) pseudo spin valves the\ngeneration of 250 fs-long SC pulses. Their temporal profile indicates that\nsuperdiffusive hot electron transport across a sub-100~nm Au layer is close to\nthe ballistic limit and the pulse duration is primarily determined by the\nthermalization time of laser-excited hot carriers in Fe. Considering the\ncalculated spin-dependent Fe/Au interface transmittance we conclude that a\nnon-thermal spin-dependent Seebeck effect is responsible for the generation of\nultrashort SC pulses. We also show that hot electron spins rotate upon\ninteraction with non-collinear magnetization at the Au/Fe interface, which\nholds high potential for future spintronic devices. \n\n"}
{"id": "1606.05673", "contents": "Title: User-Centric Mobility Management in Ultra-Dense Cellular Networks under\n  Spatio-Temporal Dynamics Abstract: This article investigates the mobility management of an ultra dense cellular\nnetwork (UDN) from an energy-efficiency (EE) point of view. Many dormant base\nstations (BSs) in a UDN do not transmit signals, and thus a received power\nbased handover (HO) approach as in traditional cellular networks is hardly\napplicable. In addition, the limited front/backhaul capacity compared to a huge\nnumber of BSs makes it difficult to implement a centralized HO and power\ncontrol. For these reasons, a novel user-centric association rule is proposed,\nwhich jointly optimizes HO and power control for maximizing EE. The proposed\nmobility management is able to cope not only with the spatial randomness of\nuser movement but also with temporally correlated wireless channels. The\nproposed approach is implemented over a HO time window and tractable power\ncontrol policy by exploiting mean-field game (MFG) and stochastic geometry\n(SG). Compared to a baseline with a fixed HO interval and transmit power, the\nproposed approach achieves the 1.2 times higher long-term average EE at a\ntypical active BS. \n\n"}
{"id": "1606.05838", "contents": "Title: Strong coupling between Tamm plasmon polariton and two dimensional\n  semiconductor excitons Abstract: Two dimensional (2D) semiconductor materials of transition-metal\ndichalcogenides (TMDCs) manifest many peculiar physical phenomena in the\nlight-matter interaction. Due to their ultrathin property, strong interaction\nwith light and the robust excitons at room temperature, they provide a perfect\nplatform for studying the physics of strong coupling in low dimension and at\nroom temperature. Here we report the strong coupling between 2D semiconductor\nexcitons and Tamm plasmon polaritons (TPPs). We observe a Rabi splitting of\nabout 54 meV at room temperature by measuring the angle resolved differential\nreflectivity spectra and simulate the theoretical results by using the transfer\nmatrix method. Our results will promote the realization of the TPP based\nultrathin polariton devices at room temperature. \n\n"}
{"id": "1606.06321", "contents": "Title: Path-dependent SDEs in Hilbert spaces Abstract: We study path-dependent SDEs in Hilbert spaces. By using methods based on\ncontractions in Banach spaces, we prove existence and uniqueness of mild\nsolutions, continuity of mild solutions with respect to perturbations of all\nthe data of the system, G\\^ateaux differentiability of generic order n of mild\nsolutions with respect to the starting point, continuity of the G\\^ateaux\nderivatives with respect to all the data. The analysis is performed for generic\nspaces of paths that do not necessarily coincide with the space of continuous\nfunctions. \n\n"}
{"id": "1606.06887", "contents": "Title: Minimal but non-minimal inflation and electroweak symmetry breaking Abstract: We consider the most minimal scale invariant extension of the standard model\nthat allows for successful radiative electroweak symmetry breaking and\ninflation. The framework involves an extra scalar singlet, that plays the\nr\\^ole of the inflaton, and is compatibile with current experimental bounds\nowing to the non-minimal coupling of the latter to gravity. This inflationary\nscenario predicts a very low tensor-to-scalar ratio $r \\approx 10^{-3}$,\ntypical of Higgs-inflation models, but in contrast yields a scalar spectral\nindex $n_s \\simeq 0.97$ which departs from the Starobinsky limit. We briefly\ndiscuss the collider phenomenology of the framework. \n\n"}
{"id": "1606.07490", "contents": "Title: Enhancing Accountability and Trust in Distributed Ledgers Abstract: Permisionless decentralized ledgers (\"blockchains\") such as the one\nunderlying the cryptocurrency Bitcoin allow anonymous participants to maintain\nthe ledger, while avoiding control or \"censorship\" by any single entity. In\ncontrast, permissioned decentralized ledgers exploit real-world trust and\naccountability, allowing only explicitly authorized parties to maintain the\nledger. Permissioned ledgers support more flexible governance and a wider\nchoice of consensus mechanisms. Both kinds of decentralized ledgers may be\nsusceptible to manipulation by participants who favor some transactions over\nothers. The real-world accountability underlying permissioned ledgers provides\nan opportunity to impose fairness constraints that can be enforced by\npenalizing violators after-the- fact. To date, however, this opportunity has\nnot been fully exploited, unnecessarily leaving participants latitude to\nmanipulate outcomes undetectably. This paper draws attention to this issue, and\nproposes design principles to make such manipulation more difficult, as well as\nspecific mechanisms to make it easier to detect when violations occur. \n\n"}
{"id": "1606.08343", "contents": "Title: Raman scattering with strongly coupled vibron-polaritons Abstract: Strong coupling between cavity photons and molecular vibrations can lead to\nthe formation of vibron-polaritons. In a recent experiment with PVAc molecules\nin a metal-metal microcavity [A.Shalabney et al., Ang.Chem.Int.Ed. 54 7971\n(2015)], such a coupling was observed to enhance the Raman scattering\nprobability by several orders of magnitude. Inspired by this, we theoretically\nanalyze the effect of strong photon-vibron coupling on the Raman scattering\namplitude of organic molecules. This problem has recently been addressed in\n[J.del Pino, J.Feist and F.J.Garcia-Vidal; J.Phys.Chem.C 119 29132 (2015)]\nusing exact numerics for a small number of molecules. In this paper we derive\ncompact analytic results for any number of molecules, also including the\nultra-strong coupling regime. Our calculations predict a division of the Raman\nsignal into upper and lower polariton modes,with some enhancement to the lower\npolariton Raman amplitude due to the mode softening under strong coupling. \n\n"}
{"id": "1606.09059", "contents": "Title: Large linear magnetoresistance from neutral defects in Bi$_2$Se$_3$ Abstract: The chalcogenide Bi$_2$Se$_3$ can attain the three dimensional (3D) Dirac\nsemimetal state under the influence of strain and microstrain. Here we report\nthe presnece of large linear magnetoresistance in such a Bi$_2$Se$_3$ crystal.\nThe magnetoresistance has quadratic form at low fields which crossovers to\nlinear above 4 T. The temperature dependence of magnetoresistance scales with\ncarrier mobility and the crossover field scales with inverse of mobility. Our\nanalysis suggest that the linear magnetoresistance in our system has a\nclassical origin and arises from the scattering of high mobility 3D Dirac\nelectrons from crystalline inhomogeneities. We observe that the charged\nselenium vacancies are strongly screened by high mobility Dirac electrons and\nthe neutral crystalline defects are the main scattering center for transport\nmechanism. Our analysis suggests that both the resistivity and the\nmagnetoresistance have their origin in scattering of charge carriers from\nneutral defects. \n\n"}
{"id": "1606.09262", "contents": "Title: Improved superconducting qubit coherence with high-temperature substrate\n  annealing Abstract: We assess independently the impact of high-temperature substrate annealing\nand metal deposition conditions on the coherence of transmon qubits in the\nstandard 2D circuit-QED architecture. We restrict our study to devices made\nwith aluminum interdigital capacitors on sapphire substrates. We record more\nthan an order-of-magnitude improvement in the relaxation time of devices made\nwith an annealed substrate, independent of whether a conventional evaporator or\nmolecular beam epitaxy chamber was used to deposit the aluminum. We also infer\nsimilar levels of flux noise and photon shot noise through dephasing\nmeasurements on these devices. Our results indicate that substrate annealing\nplays a primary role in fabricating low-loss qubits, consistent with the\nhypothesis that substrate-air and substrate-metal interfaces are essential\nfactors limiting the qubit lifetimes in superconducting circuits. \n\n"}
{"id": "1607.00307", "contents": "Title: Optimal Tree Hash Modes: the Case of Trees Having their Leaves at All\n  the Levels Abstract: A recent work shows how we can optimize a tree based mode of operation for a\nhash function where the sizes of input message blocks and digest are the same,\nsubject to the constraint that the involved tree structure has all its leaves\nat the same depth. In this work, we show that we can further optimize the\nrunning time of such a mode by using a tree having leaves at all its levels. We\nmake the assumption that the input message block has a size a multiple of that\nof the digest and denote by $d$ the ratio block size over digest size. The\nrunning time is evaluated in terms of number of operations performed by the\nhash function, i.e. the number of calls to its underlying function. It turns\nout that a digest can be computed in $\\lceil \\log_{d+1} (l/2) \\rceil+2$\nevaluations of the underlying function using $\\lceil l/2 \\rceil$ processors,\nwhere $l$ is the number of blocks of the message. Other results of interest are\ndiscussed, such as the optimization of the parallel running time for a tree of\nrestricted height. \n\n"}
{"id": "1607.00322", "contents": "Title: HATS-19b, HATS-20b, HATS-21b: Three Transiting Hot-Saturns Discovered by\n  the HATSouth Survey Abstract: We report the discovery by the HATSouth exoplanet survey of three hot-Saturn\ntransiting exoplanets: HATS-19b, HATS-20b, and HATS-21b. The planet host\nHATS-19 is a slightly evolved V = 13.0 G0 star with [Fe/H] = 0.240, a mass of\n1.303 Msun, and a radius of 1.75 Rsun. HATS-19b is in an eccentric orbit (e =\n0.30) around this star with an orbital period of 4.5697 days and has a mass of\n0.427 Mjup and a highly inflated radius of 1.66 Rjup. The planet HATS-20b has a\nSaturn-like mass and radius of 0.273 Mjup and 0.776 Rjup respectively. It\norbits the V = 13.8 G9V star HATS-20 (Ms = 0.910 Msun; Rs = 0.892 Rsun) with a\nperiod of 3.7993 days. Finally, HATS-21 is a V = 12.2 G4V star with [Fe/H] =\n0.300, a mass of 1.080 Msun, and a radius of 1.021 Rsun. Its accompanying\nplanet HATS-21b has a 3.5544-day orbital period, a mass of 0.332 Mjup, and a\nmoderately inflated radius of 1.123 Rjup. With the addition of these three very\ndifferent planets to the growing sample of hot-Saturns, we re-examine the\nrelations between the observed giant planet radii, stellar irradiation, and\nhost metallicity. We find a significant positive correlation between planet\nequilibrium temperature and radius, and a weak negative correlation between\nhost metallicity and radius. To assess the relative influence of various\nphysical parameters on observed planet radii, we train and fit models using\nRandom Forest regression. We find that for hot-Saturns (0.1 < Mp < 0.5 Mjup),\nthe planetary mass and equilibrium temperature play dominant roles in\ndetermining radii. For hot-Jupiters (0.5 < Mp < 2.0 Mjup), the most important\nparameter is equilibrium temperature alone. Finally, for irradiated higher-mass\nplanets (Mp > 2.0 Mjup), we find that equilibrium temperature dominates in\ninfluence, with smaller contributions from planet mass and host metallicity. \n\n"}
{"id": "1607.02480", "contents": "Title: Real-Time Anomaly Detection for Streaming Analytics Abstract: Much of the worlds data is streaming, time-series data, where anomalies give\nsignificant information in critical situations. Yet detecting anomalies in\nstreaming data is a difficult task, requiring detectors to process data in\nreal-time, and learn while simultaneously making predictions. We present a\nnovel anomaly detection technique based on an on-line sequence memory algorithm\ncalled Hierarchical Temporal Memory (HTM). We show results from a live\napplication that detects anomalies in financial metrics in real-time. We also\ntest the algorithm on NAB, a published benchmark for real-time anomaly\ndetection, where our algorithm achieves best-in-class results. \n\n"}
{"id": "1607.02985", "contents": "Title: Triple-resonant Brillouin light scattering in magneto-optical cavities Abstract: An enhancement in Brillouin light scattering of optical photons with magnons\nis demonstrated in magneto-optical whispering gallery mode resonators tuned to\na triple resonance point. This occurs when both the input and output optical\nmodes are resonant with those of the whispering gallery resonator, with a\nseparation given by the ferromagnetic resonance (FMR) frequency. The\nidentification and excitation of specific optical modes allows us to gain a\nclear understanding of the mode-matching conditions. A selection rule due to\nwavevector matching leads to an intrinsic single-sideband excitation. Strong\nsuppression of one sideband is essential for one-to-one frequency mapping in\ncoherent optical-to-microwave conversion. \n\n"}
{"id": "1607.03607", "contents": "Title: Cloud Empowered Self-Managing WSNs Abstract: Wireless Sensor Networks (WSNs) are composed of low powered and\nresource-constrained wireless sensor nodes that are not capable of performing\nhigh-complexity algorithms. Integrating these networks into the Internet of\nThings (IoT) facilitates their real-time optimization based on remote data\nvisualization and analysis. This work describes the design and implementation\nof a scalable system architecture that integrates WSNs and cloud services to\nwork autonomously in an IoT environment. The implementation relies on Software\nDefined Networking features to simplify the WSN management and exploits data\nanalytics tools to execute a reinforcement learning algorithm that takes\ndecisions based on the environment's evolution. It can automatically configure\nwireless sensor nodes to measure and transmit the temperature only at periods\nwhen the environment changes more often. Without any human intervention, the\nsystem could reduce nearly 85% the number of transmissions, showing the\npotential of this mechanism to extend WSNs lifetime without compromising the\ndata quality. Besides attending to similar use cases, such a WSN autonomic\nmanagement could promote a new business model to offer sensing tasks as a\nservice, which is also introduced in this work. \n\n"}
{"id": "1607.03906", "contents": "Title: Predictions of the atmospheric composition of GJ 1132b Abstract: GJ 1132 b is a nearby Earth-sized exoplanet transiting an M dwarf, and is\namongst the most highly characterizable small exoplanets currently known. In\nthis paper we study the interaction of a magma ocean with a water-rich\natmosphere on GJ 1132b and determine that it must have begun with more than 5\nwt% initial water in order to still retain a water-based atmosphere. We also\ndetermine the amount of O2 that can build up in the atmosphere as a result of\nhydrogen dissociation and loss. We find that the magma ocean absorbs at most\n~10% of the O2 produced, whereas more than 90% is lost to space through\nhydrodynamic drag. The most common outcome for GJ 1132 b from our simulations\nis a tenuous atmosphere dominated by O2, although for very large initial water\nabundances atmospheres with several thousands of bars of O2 are possible. A\nsubstantial steam envelope would indicate either the existence of an earlier H2\nenvelope or low XUV flux over the system's lifetime. A steam atmosphere would\nalso imply the continued existence of a magma ocean on GJ 1132 b. Further\nmodeling is needed to study the evolution of CO2 or N2-rich atmospheres on GJ\n1132 b. \n\n"}
{"id": "1608.00039", "contents": "Title: Distributed Learning for Stochastic Generalized Nash Equilibrium\n  Problems Abstract: This work examines a stochastic formulation of the generalized Nash\nequilibrium problem (GNEP) where agents are subject to randomness in the\nenvironment of unknown statistical distribution. We focus on fully-distributed\nonline learning by agents and employ penalized individual cost functions to\ndeal with coupled constraints. Three stochastic gradient strategies are\ndeveloped with constant step-sizes. We allow the agents to use heterogeneous\nstep-sizes and show that the penalty solution is able to approach the Nash\nequilibrium in a stable manner within $O(\\mu_\\text{max})$, for small step-size\nvalue $\\mu_\\text{max}$ and sufficiently large penalty parameters. The operation\nof the algorithm is illustrated by considering the network Cournot competition\nproblem. \n\n"}
{"id": "1608.00726", "contents": "Title: Infinite Unlimited Churn Abstract: We study unlimited infinite churn in peer-to-peer overlay networks. Under\nthis churn, arbitrary many peers may concurrently request to join or leave the\noverlay network; moreover these requests may never stop coming. We prove that\nunlimited adversarial churn, where processes may just exit the overlay network,\nis unsolvable. We focus on cooperative churn where exiting processes\nparticipate in the churn handling algorithm. We define the problem of unlimited\ninfinite churn in this setting. We distinguish the fair version of the problem,\nwhere each request is eventually satisfied, from the unfair version that just\nguarantees progress. We focus on local solutions to the problem, and prove that\na local solution to the Fair Infinite Unlimited Churn is impossible. We then\npresent and prove correct an algorithm UIUC that solves the Unfair Infinite\nUnlimited Churn Problem for a linearized peer-to-peer overlay network. We\nextend this solution to skip lists and skip graphs. \n\n"}
{"id": "1608.01791", "contents": "Title: Towards boolean operations with thermal photons Abstract: The Boolean algebra is the natural theoretical framework for a classical\ninformation treatment. The basic logical operations are usually performed using\nlogic gates. In this Letter we demonstrate that NOT, OR and AND gates can be\nrealized exploiting the near-field radiative interaction in N-body systems with\nphase change materials. With the recent development of a photon thermal\ntransistor and thermal memory, this result paves the way for a full information\ntreatment and smart solutions for active thermal management at nanoscale with\nphotons. \n\n"}
{"id": "1608.02032", "contents": "Title: Unique coverage in Boolean models Abstract: Consider a wireless cellular network consisting of small, densely scattered\nbase stations. A user $u$ is {\\em uniquely covered} by a base station $b$ if\n$u$ is the only user within distance $r$ of $b$. This makes it possible to\nassign the user $u$ to the base station $b$ without interference from any other\nuser $u'$. We investigate the maximum possible proportion of users who are\nuniquely covered. We solve this problem completely in one dimension and provide\nbounds, approximations and simulation results for the two-dimensional case. \n\n"}
{"id": "1608.02427", "contents": "Title: Maximum-Likelihood Detection for Energy-Efficient Timing Acquisition in\n  NB-IoT Abstract: Initial timing acquisition in narrow-band IoT (NB-IoT) devices is done by\ndetecting a periodically transmitted known sequence. The detection has to be\ndone at lowest possible latency, because the RF-transceiver, which dominates\ndownlink power consumption of an NB-IoT modem, has to be turned on throughout\nthis time. Auto-correlation detectors show low computational complexity from a\nsignal processing point of view at the price of a higher detection latency. In\ncontrast a maximum likelihood cross-correlation detector achieves low latency\nat a higher complexity as shown in this paper. We present a hardware\nimplementation of the maximum likelihood cross-correlation detection. The\ndetector achieves an average detection latency which is a factor of two below\nthat of an auto-correlation method and is able to reduce the required energy\nper timing acquisition by up to 34%. \n\n"}
{"id": "1608.02437", "contents": "Title: 3D $Z_2$ Topological Nodes in Nonsymmorphic Photonic Crystals:\n  Ultrastrong Coupling and Anomalous Refraction Abstract: We propose to simulate 3D Dirac points and line-nodes with nontrivial $Z_2$\ntopology in nonsymmorphic all-dielectric photonic-crystals with space-time\nreversal symmetry, which can be realized at infrared and microwave frequencies.\nDouble degeneracy of all Bloch states in high symmetry planes is achieved via\nnonsymmorphic screw symmetries despite the fundamental obstacle of no Kramers\ndegeneracy in photonic crystals. Two orthogonal screw axes lead to 3D $Z_2$\nDirac points on high symmetry Brillouin zone boundary lines. On the other hand,\n$Z_2$ line-nodes emerge as protected twofold degeneracy of Bloch bands with\nopposite mirror parities on the $k_z=0$ plane. The lowest frequency line-node\nis deterministic because of a degenerate-partner switching mechanism guaranteed\nby the fundamental properties of Maxwell equations and the nonsymmorphic screw\nsymmetry. A pair of Fermi arcs with opposite chirality due to $Z_2$ topological\nDirac points emerge below the light-line on (100) and (010)\nphotonic-crystal-air interfaces. These robust surface states offer an unique\nopportunity to realize an \"open cavity\" with strong interaction between quantum\nemitters and engineered vacuum with nontrivial Berry phases --- an important\nstep toward topological states of strongly interacting bosons. Realistic\ncalculation for resonant coupling between cavity-photons and phonons in boron\nnitride thin film yields ultrastrong coupling with vacuum Rabi splitting\nreaching to $23\\%$ of photon frequency. We also show that type-II Dirac cones\nhave anomalous valley selective refraction: birefringence with both positive\nand negative refractions for one valley, while no refraction for the other. \n\n"}
{"id": "1608.02839", "contents": "Title: Detecting binarity of GW150914-like lenses in gravitational microlensing\n  events Abstract: The recent discovery of gravitational waves (GWs) from stellar-mass binary\nblack holes (BBHs) provided direct evidence of the existence of these systems.\nBBH lenses would have gravitational microlensing signatures that are distinct\nfrom single-lens signals. We apply Bayesian statistics to examine the\ndistinguishability of BBH microlensing events from single-lens events under\nideal observing conditions, using the photometric capabilities of the Korean\nMicrolensing Telescope Network. Given one year of observations, a source star\nat the Galactic Centre, a GW150914-like BBH lens (total mass 65M$_\\odot$, mass\nratio 0.8) at half that distance, and an impact parameter of 0.4 Einstein\nradii, we find that binarity is detectable for BBHs with separations down to\n0.0250 Einstein radii, which is nearly 3.5 times greater than the maximum\nseparation for which such BBHs would merge within the age of the Universe.\nMicrolensing searches are thus sensitive to more widely separated BBHs than GW\nsearches, perhaps allowing the discovery of BBH populations produced in\ndifferent channels of binary formation. \n\n"}
{"id": "1608.03630", "contents": "Title: Distributed-memory large deformation diffeomorphic 3D image registration Abstract: We present a parallel distributed-memory algorithm for large deformation\ndiffeomorphic registration of volumetric images that produces large isochoric\ndeformations (locally volume preserving). Image registration is a key\ntechnology in medical image analysis. Our algorithm uses a partial differential\nequation constrained optimal control formulation. Finding the optimal\ndeformation map requires the solution of a highly nonlinear problem that\ninvolves pseudo-differential operators, biharmonic operators, and pure\nadvection operators both forward and back- ward in time. A key issue is the\ntime to solution, which poses the demand for efficient optimization methods as\nwell as an effective utilization of high performance computing resources. To\naddress this problem we use a preconditioned, inexact, Gauss-Newton- Krylov\nsolver. Our algorithm integrates several components: a spectral discretization\nin space, a semi-Lagrangian formulation in time, analytic adjoints, different\nregularization functionals (including volume-preserving ones), a spectral\npreconditioner, a highly optimized distributed Fast Fourier Transform, and a\ncubic interpolation scheme for the semi-Lagrangian time-stepping. We\ndemonstrate the scalability of our algorithm on images with resolution of up to\n$1024^3$ on the \"Maverick\" and \"Stampede\" systems at the Texas Advanced\nComputing Center (TACC). The critical problem in the medical imaging\napplication domain is strong scaling, that is, solving registration problems of\na moderate size of $256^3$---a typical resolution for medical images. We are\nable to solve the registration problem for images of this size in less than\nfive seconds on 64 x86 nodes of TACC's \"Maverick\" system. \n\n"}
{"id": "1608.04579", "contents": "Title: Endpoint-transparent Multipath Transport with Software-defined Networks Abstract: Multipath forwarding consists of using multiple paths simultaneously to\ntransport data over the network. While most such techniques require endpoint\nmodifications, we investigate how multipath forwarding can be done inside the\nnetwork, transparently to endpoint hosts. With such a network-centric approach,\npacket reordering becomes a critical issue as it may cause critical performance\ndegradation.\n  We present a Software Defined Network architecture which automatically sets\nup multipath forwarding, including solutions for reordering and performance\nimprovement, both at the sending side through multipath scheduling algorithms,\nand the receiver side, by resequencing out-of-order packets in a dedicated\nin-network buffer.\n  We implemented a prototype with commonly available technology and evaluated\nit in both emulated and real networks. Our results show consistent throughput\nimprovements, thanks to the use of aggregated path capacity. We give\ncomparisons to Multipath TCP, where we show our approach can achieve a similar\nperformance while offering the advantage of endpoint transparency. \n\n"}
{"id": "1608.08521", "contents": "Title: Profitable Task Allocation in Mobile Cloud Computing Abstract: We propose a game theoretic framework for task allocation in mobile cloud\ncomputing that corresponds to offloading of compute tasks to a group of nearby\nmobile devices. Specifically, in our framework, a distributor node holds a\nmultidimensional auction for allocating the tasks of a job among nearby mobile\nnodes based on their computational capabilities and also the cost of\ncomputation at these nodes, with the goal of reducing the overall job\ncompletion time. Our proposed auction also has the desired incentive\ncompatibility property that ensures that mobile devices truthfully reveal their\ncapabilities and costs and that those devices benefit from the task allocation.\nTo deal with node mobility, we perform multiple auctions over adaptive time\nintervals. We develop a heuristic approach to dynamically find the best time\nintervals between auctions to minimize unnecessary auctions and the\naccompanying overheads. We evaluate our framework and methods using both real\nworld and synthetic mobility traces. Our evaluation results show that our game\ntheoretic framework improves the job completion time by a factor of 2-5 in\ncomparison to the time taken for executing the job locally, while minimizing\nthe number of auctions and the accompanying overheads. Our approach is also\nprofitable for the nearby nodes that execute the distributor's tasks with these\nnodes receiving a compensation higher than their actual costs. \n\n"}
{"id": "1608.08660", "contents": "Title: Tunable QoS-Aware Network Survivability Abstract: Coping with network failures has been recognized as an issue of major\nimportance in terms of social security, stability and prosperity. It has become\nclear that current networking standards fall short of coping with the complex\nchallenge of surviving failures. The need to address this challenge has become\na focal point of networking research. In particular, the concept of\n\\textbf{\\emph{tunable survivability}} offers major performance improvements\nover traditional approaches. Indeed, while the traditional approach aims at\nproviding full (100\\%) protection against network failures through disjoint\npaths, it was realized that this requirement is too restrictive in practice.\nTunable survivability provides a quantitative measure for specifying the\ndesired level (0\\%-100\\%) of survivability and offers flexibility in the choice\nof the routing paths. Previous work focused on the simpler class of\n\"bottleneck\" criteria, such as bandwidth. In this study, we focus on the\nimportant and much more complex class of \\emph{additive} criteria, such as\ndelay and cost. First, we establish some (in part, counter-intuitive)\nproperties of the optimal solution. Then, we establish efficient algorithmic\nschemes for optimizing the level of survivability under additive end-to-end QoS\nbounds. Subsequently, through extensive simulations, we show that, at the price\nof \\emph{negligible} reduction in the level of survivability, a major\nimprovement (up to a factor of $2$) is obtained in terms of end-to-end QoS\nperformance. Finally, we exploit the above findings in the context of a network\ndesign problem, in which, for a given investment budget, we aim to improve the\nsurvivability of the network links. \n\n"}
{"id": "1609.00024", "contents": "Title: Thermal chiral vortical and magnetic waves: new excitation modes in\n  chiral fluids Abstract: In certain circumstances, chiral (parity-violating) medium can be described\nhydrodynamically as a chiral fluid with microscopic quantum anomalies. Possible\nexamples of such systems include strongly coupled quark-gluon plasma, liquid\nhelium 3He-A, neutron stars and the Early Universe. We study first-order\nhydrodynamics of a chiral fluid on a vortex background and in an external\nmagnetic field. We show that there are two previously undiscovered modes\ndescribing heat waves propagating along the vortex and magnetic field. We call\nthem the Thermal Chiral Vortical Wave and Thermal Chiral Magnetic Wave. We also\nidentify known gapless excitations of density (chiral vortical and chiral\nmagnetic waves) and transverse velocity (chiral Alfven wave). We demonstrate\nthat the velocity of the chiral vortical wave is zero, when the full\nhydrodynamic framework is applied, and hence the wave is absent and the\nexcitation reduces to the charge diffusion mode. We also comment on the\nframe-dependent contributions to the obtained propagation velocities. \n\n"}
{"id": "1609.02104", "contents": "Title: A Consumer-Centric Market for Database Computation in the Cloud Abstract: The availability of public computing resources in the cloud has\nrevolutionized data analysis, but requesting cloud resources often involves\ncomplex decisions for consumers. Under the current pricing mechanisms, cloud\nservice providers offer several service options and charge consumers based on\nthe resources they use. Before they can decide which cloud resources to\nrequest, consumers have to estimate the completion time and cost of their\ncomputational tasks for different service options and possibly for different\nservice providers. This estimation is challenging even for expert cloud users.\nWe propose a new market-based framework for pricing computational tasks in the\ncloud. Our framework introduces an agent between consumers and cloud providers.\nThe agent takes data and computational tasks from users, estimates time and\ncost for evaluating the tasks, and returns to consumers contracts that specify\nthe price and completion time. Our framework can be applied directly to\nexisting cloud markets without altering the way cloud providers offer and price\nservices. In addition, it simplifies cloud use for consumers by allowing them\nto compare contracts, rather than choose resources directly. We present design,\nanalytical, and algorithmic contributions focusing on pricing computation\ncontracts, analyzing their properties, and optimizing them in complex\nworkflows. We conduct an experimental evaluation of our market framework over a\nreal-world cloud service and demonstrate empirically that our market ensures\nthree key properties: competitiveness, fairness, and resilience. Finally, we\npresent a fine-grained pricing mechanism for complex workflows and show that it\ncan increase agent profits by more than an order of magnitude in some cases. \n\n"}
{"id": "1609.02305", "contents": "Title: Survey of Consistent Software-Defined Network Updates Abstract: Computer networks have become a critical infrastructure. In fact, networks\nshould not only meet strict requirements in terms of correctness, availability,\nand performance, but they should also be very flexible and support fast\nupdates, e.g., due to policy changes, increasing traffic, or failures. This\npaper presents a structured survey of mechanism and protocols to update\ncomputer networks in a fast and consistent manner. In particular, we identify\nand discuss the different desirable consistency properties that should be\nprovided throughout a network update, the algorithmic techniques which are\nneeded to meet these consistency properties, and the implications on the speed\nand costs at which updates can be performed. We also explain the relationship\nbetween consistent network update problems and classic algorithmic optimization\nones. While our survey is mainly motivated by the advent of Software-Defined\nNetworks (SDNs) and their primary need for correct and efficient update\ntechniques, the fundamental underlying problems are not new, and we provide a\nhistorical perspective of the subject as well. \n\n"}
{"id": "1609.05767", "contents": "Title: Minimizing Total Busy Time with Application to Energy-efficient\n  Scheduling of Virtual Machines in IaaS clouds Abstract: Infrastructure-as-a-Service (IaaS) clouds have become more popular enabling\nusers to run applications under virtual machines. Energy efficiency for IaaS\nclouds is still challenge. This paper investigates the energy-efficient\nscheduling problems of virtual machines (VMs) onto physical machines (PMs) in\nIaaS clouds along characteristics: multiple resources, fixed intervals and\nnon-preemption of virtual machines. The scheduling problems are NP-hard. Most\nof existing works on VM placement reduce the total energy consumption by using\nthe minimum number of active physical machines. There, however, are cases using\nthe minimum number of physical machines results in longer the total busy time\nof the physical machines. For the scheduling problems, minimizing the total\nenergy consumption of all physical machines is equivalent to minimizing total\nbusy time of all physical machines. In this paper, we propose an scheduling\nalgorithm, denoted as EMinTRE-LFT, for minimizing the total energy consumption\nof physical machines in the scheduling problems. Our extensive simulations\nusing parallel workload models in Parallel Workload Archive show that the\nproposed algorithm has the least total energy consumption compared to the\nstate-of-the art algorithms. \n\n"}
{"id": "1609.08332", "contents": "Title: Nano-scale thermal transfer -- an invitation to fluctuation\n  electrodynamics Abstract: An electromagnetic theory of thermal radiation is outlined, based on the\nfluctuation electrodynamics of Rytov and co-workers. We discuss the basic\nconcepts and the status of different approximations. The physical content is\nillustrated with a few examples on near-field heat transfer. \n\n"}
{"id": "1609.08888", "contents": "Title: Flexible Dual-Connectivity Spectrum Aggregation for Decoupled Uplink and\n  Downlink Access in 5G Heterogeneous Systems Abstract: Maintaining multiple wireless connections is a promising solution to boost\ncapacity in fifth-generation (5G) networks, where user equipment is able to\nconsume radio resources of several serving cells simultaneously and potentially\naggregate bandwidth across all of them. The emerging dual connectivity paradigm\ncan be regarded as an attractive access mechanism in dense heterogeneous 5G\nnetworks, where bandwidth sharing and cooperative techniques are evolving to\nmeet the increased capacity requirements. Dual connectivity in the uplink\nremained highly controversial, since the user device has a limited power budget\nto share between two different access points, especially when located close to\nthe cell edge. On the other hand, in an attempt to enhance the uplink\ncommunications performance, the concept of uplink and downlink decoupling has\nrecently been introduced. Leveraging these latest developments, our work\nsignificantly advances prior art by proposing and investigating the concept of\nflexible cell association in dual connectivity scenarios, where users are able\nto aggregate resources from more than one serving cell. In this setup, the\npreferred association policies for the uplink may differ from those for the\ndownlink, thereby allowing for a truly decoupled access. With the use of\nstochastic geometry, the dual connectivity association regions for decoupled\naccess are derived and the resultant performance is evaluated in terms of\ncapacity gains over the conventional downlink received power access policies. \n\n"}
{"id": "1610.00624", "contents": "Title: CDSFA Stochastic Frontier Analysis Approach to Revenue Modeling in Large\n  Cloud Data Centers Abstract: Enterprises are investing heavily in cloud data centers to meet the ever\nsurging business demand. Data Center is a facility, which houses computer\nsystems and associated components, such as telecommunications and storage\nsystems. It generally includes power supply equipment, communication\nconnections and cooling equipment. A large data center can use as much\nelectricity as a small town. Due to the emergence of data center based\ncomputing services, it has become necessary to examine how the costs associated\nwith data centers evolve over time, mainly in view of efficiency issues. We\nhave presented a quasi form of Cobb Douglas model, which addresses revenue and\nprofit issues in running large data centers. The stochastic form has been\nintroduced and explored along with the quasi Cobb Douglas model to understand\nthe behavior of the model in depth. Harrod neutrality and Solow neutrality are\nincorporated in the model to identify the technological progress in cloud data\ncenters. This allows us to shed light on the stochastic uncertainty of cloud\ndata center operations. A general approach to optimizing the revenue cost of\ndata centers using Cobb Douglas Stochastic Frontier Analysis,CDSFA is\npresented. Next, we develop the optimization model for large data centers. The\nmathematical basis of CDSFA has been utilized for cost optimization and profit\nmaximization in data centers. The results are found to be quite useful in view\nof production reorganization in large data centers around the world. \n\n"}
{"id": "1610.01033", "contents": "Title: Experimental observation of optical Weyl points Abstract: Weyl fermions are hypothetical two-component massless relativistic particles\nin three-dimensional (3D) space, proposed by Hermann Weyl in 1929. Their\nband-crossing points, called 'Weyl points,' carry a topological charge and are\ntherefore highly robust. There has been much excitement over recent\nobservations of Weyl points in microwave photonic crystals and the semimetal\nTaAs. Here, we report on the first experimental observation of Weyl points of\nlight at optical frequencies. These are also the first observations of\n'type-II' Weyl points for photons, which have strictly positive group velocity\nalong one spatial direction. We use a 3D structure consisting of laser-written\nwaveguides, and show the presence of type-II Weyl points by (1) observing\nconical diffraction along one axis when the frequency is tuned to the Weyl\npoint; and (2) observing the associated Fermi arc surface states. The\nrealization of Weyl points at optical frequencies allow these novel\nelectromagnetic modes to be further explored in the context of linear,\nnonlinear, and quantum optics. \n\n"}
{"id": "1610.01140", "contents": "Title: Reasoning about identifier spaces: How to make Chord correct Abstract: The Chord distributed hash table (DHT) is well-known and often used to\nimplement peer-to-peer systems. Chord peers find other peers, and access their\ndata, through a ring-shaped pointer structure in a large identifier space.\nDespite claims of proven correctness, i.e., eventual reachability, previous\nwork has shown that the Chord ring-maintenance protocol is not correct under\nits original operating assumptions. Previous work has not, however, discovered\nwhether Chord could be made correct under the same assumptions. The\ncontribution of this paper is to provide the first specification of correct\noperations and initialization for Chord, an inductive invariant that is\nnecessary and sufficient to support a proof of correctness, and two independent\nproofs of correctness. One proof is informal and intuitive, and applies to\nnetworks of any size. The other proof is based on a formal model in Alloy, and\nuses fully automated analysis to prove the assertions for networks of bounded\nsize. The two proofs complement each other in several important ways. \n\n"}
{"id": "1610.02084", "contents": "Title: Computational Tradeoffs in Biological Neural Networks: Self-Stabilizing\n  Winner-Take-All Networks Abstract: We initiate a line of investigation into biological neural networks from an\nalgorithmic perspective. We develop a simplified but biologically plausible\nmodel for distributed computation in stochastic spiking neural networks and\nstudy tradeoffs between computation time and network complexity in this model.\nOur aim is to abstract real neural networks in a way that, while not capturing\nall interesting features, preserves high-level behavior and allows us to make\nbiologically relevant conclusions.\n  In this paper, we focus on the important `winner-take-all' (WTA) problem,\nwhich is analogous to a neural leader election unit: a network consisting of\n$n$ input neurons and $n$ corresponding output neurons must converge to a state\nin which a single output corresponding to a firing input (the `winner') fires,\nwhile all other outputs remain silent. Neural circuits for WTA rely on\ninhibitory neurons, which suppress the activity of competing outputs and drive\nthe network towards a converged state with a single firing winner. We attempt\nto understand how the number of inhibitors used affects network convergence\ntime.\n  We show that it is possible to significantly outperform naive WTA\nconstructions through a more refined use of inhibition, solving the problem in\n$O(\\theta)$ rounds in expectation with just $O(\\log^{1/\\theta} n)$ inhibitors\nfor any $\\theta$. An alternative construction gives convergence in\n$O(\\log^{1/\\theta} n)$ rounds with $O(\\theta)$ inhibitors. We compliment these\nupper bounds with our main technical contribution, a nearly matching lower\nbound for networks using $\\ge \\log\\log n$ inhibitors. Our lower bound uses\nfamiliar indistinguishability and locality arguments from distributed computing\ntheory. It lets us derive a number of interesting conclusions about the\nstructure of any network solving WTA with good probability, and the use of\nrandomness and inhibition within such a network. \n\n"}
{"id": "1610.02233", "contents": "Title: Modeling dark matter subhalos in a constrained galaxy: Global mass and\n  boosted annihilation profiles Abstract: The interaction properties of cold dark matter (CDM) particle candidates,\nsuch as those of weakly interacting massive particles (WIMPs), generically lead\nto the structuring of dark matter on scales much smaller than typical galaxies,\npotentially down to $\\sim 10^{-10}M_\\odot$. This clustering translates into a\nvery large population of subhalos in galaxies and affects the predictions for\ndirect and indirect dark matter searches (gamma rays and antimatter cosmic\nrays). In this paper, we elaborate on previous analytic works to model the\nGalactic subhalo population, while consistently with current observational\ndynamical constraints on the Milky Way. In particular, we propose a\nself-consistent method to account for tidal effects induced by both dark matter\nand baryons. Our model does not strongly rely on cosmological simulations as\nthey can hardly be fully matched to the real Milky Way, but for setting the\ninitial subhalo mass fraction. Still, it allows to recover the main qualitative\nfeatures of simulated systems. It can further be easily adapted to any change\nin the dynamical constraints, and be used to make predictions or derive\nconstraints on dark matter candidates from indirect or direct searches. We\ncompute the annihilation boost factor, including the subhalo-halo\ncross-product. We confirm that tidal effects induced by the baryonic components\nof the Galaxy play a very important role, resulting in a local average subhalo\nmass density $\\lesssim 1\\%$ of the total local dark matter mass density, while\nselecting in the most concentrated objects and leading to interesting features\nin the overall annihilation profile in the case of a sharp subhalo mass\nfunction. Values of global annihilation boost factors range from $\\sim 2$ to\n$\\sim 20$, while the local annihilation rate is about half as much boosted. \n\n"}
{"id": "1610.02318", "contents": "Title: Gibbsian On-Line Distributed Content Caching Strategy for Cellular\n  Networks Abstract: We develop Gibbs sampling based techniques for learning the optimal content\nplacement in a cellular network. A collection of base stations are scattered on\nthe space, each having a cell (possibly overlapping with other cells). Mobile\nusers request for downloads from a finite set of contents according to some\npopularity distribution. Each base station can store only a strict subset of\nthe contents at a time; if a requested content is not available at any serving\nbase station, it has to be downloaded from the backhaul. Thus, there arises the\nproblem of optimal content placement which can minimize the download rate from\nthe backhaul, or equivalently maximize the cache hit rate. Using similar ideas\nas Gibbs sampling, we propose simple sequential content update rules that\ndecide whether to store a content at a base station based on the knowledge of\ncontents in neighbouring base stations. The update rule is shown to be\nasymptotically converging to the optimal content placement for all nodes. Next,\nwe extend the algorithm to address the situation where content popularities and\ncell topology are initially unknown, but are estimated as new requests arrive\nto the base stations. Finally, improvement in cache hit rate is demonstrated\nnumerically. \n\n"}
{"id": "1610.02327", "contents": "Title: Causally consistent dynamic slicing Abstract: We offer a lattice-theoretic account of dynamic slicing for {\\pi}-calculus,\nbuilding on prior work in the sequential setting. For any run of a concurrent\nprogram, we exhibit a Galois connection relating forward slices of the start\nconfiguration to backward slices of the end configuration. We prove that, up to\nlattice isomorphism, the same Galois connection arises for any causally\nequivalent execution, allowing an efficient concurrent implementation of\nslicing via a standard interleaving semantics. Our approach has been formalised\nin the dependently-typed language Agda. \n\n"}
{"id": "1610.03007", "contents": "Title: Scalable Construction of Text Indexes Abstract: The suffix array is the key to efficient solutions for myriads of string\nprocessing problems in different applications domains, like data compression,\ndata mining, or Bioinformatics. With the rapid growth of available data, suffix\narray construction algorithms had to be adapted to advanced computational\nmodels such as external memory and distributed computing. In this article, we\npresent five suffix array construction algorithms utilizing the new algorithmic\nbig data batch processing framework Thrill, which allows us to process input\nsizes in orders of magnitude that have not been considered before. \n\n"}
{"id": "1610.07184", "contents": "Title: Hybrid-DCA: A Double Asynchronous Approach for Stochastic Dual\n  Coordinate Ascent Abstract: In prior works, stochastic dual coordinate ascent (SDCA) has been\nparallelized in a multi-core environment where the cores communicate through\nshared memory, or in a multi-processor distributed memory environment where the\nprocessors communicate through message passing. In this paper, we propose a\nhybrid SDCA framework for multi-core clusters, the most common high performance\ncomputing environment that consists of multiple nodes each having multiple\ncores and its own shared memory. We distribute data across nodes where each\nnode solves a local problem in an asynchronous parallel fashion on its cores,\nand then the local updates are aggregated via an asynchronous across-node\nupdate scheme. The proposed double asynchronous method converges to a global\nsolution for $L$-Lipschitz continuous loss functions, and at a linear\nconvergence rate if a smooth convex loss function is used. Extensive empirical\ncomparison has shown that our algorithm scales better than the best known\nshared-memory methods and runs faster than previous distributed-memory methods.\nBig datasets, such as one of 280 GB from the LIBSVM repository, cannot be\naccommodated on a single node and hence cannot be solved by a parallel\nalgorithm. For such a dataset, our hybrid algorithm takes 30 seconds to achieve\na duality gap of $10^{-6}$ on 16 nodes each using 8 cores, which is\nsignificantly faster than the best known distributed algorithms, such as\nCoCoA+, that take more than 300 seconds on 16 nodes. \n\n"}
{"id": "1610.07394", "contents": "Title: Possibilities of Recursive GPU Mapping for Discrete Orthogonal Simplices Abstract: The problem of parallel thread mapping is studied for the case of discrete\northogonal $m$-simplices. The possibility of a $O(1)$ time recursive\nblock-space map $\\lambda: \\mathbb{Z}^m \\mapsto \\mathbb{Z}^m$ is analyzed from\nthe point of view of parallel space efficiency and potential performance\nimprovement. The $2$-simplex and $3$-simplex are analyzed as special cases,\nwhere constant time maps are found, providing a potential improvement of up to\n$2\\times$ and $6\\times$ more efficient than a bounding-box approach,\nrespectively. For the general case it is shown that finding an efficient\nrecursive parallel space for an $m$-simplex depends of the choice of two\nparameters, for which some insights are provided which can lead to a volume\nthat matches the $m$-simplex for $n>n_0$, making parallel space approximately\n$m!$ times more efficient than a bounding-box. \n\n"}
{"id": "1610.08048", "contents": "Title: Landau levels for electromagnetic wave Abstract: In this paper we show that the frequencies of propagating electromagnetic\nwave (photon) in rotating dielectric medium obey Landau quantization. We show\nthat the degeneracy of right and left helicities of photons is broken on the\nlowest Landau level. In homogeneous space this level is shown to be helical,\ni.e. left and right helical photons counter-propagate. This leads to helical\nvortical effect for photons. \n\n"}
{"id": "1610.08812", "contents": "Title: Optical beam shifts in graphene and single-layer boron-nitride Abstract: Optical beam shifts from a free-standing two-dimensional atomic crystal are\ninvestigated. In contrast to a three-dimensional crystal the magnitude of the\nGoos-H$\\rm \\ddot{a}$nchen shift depends on the surface susceptibility of the\ncrystal and not on the wavelength of the incident light beam. The surface\nconductivity of the atomically thin crystal is less important in this context\nbecause it enters in the expression of the shifts only as a second order\nparameter. In analogy to a three-dimensional crystal the magnitudes of the\nImbert-Fedorov shift and of the angular shifts depend respectively on the\nwavelength and on the square of the beam angular aperture. \n\n"}
{"id": "1611.00404", "contents": "Title: Per-Server Dominant-Share Fairness (PS-DSF): A Multi-Resource Fair\n  Allocation Mechanism for Heterogeneous Servers Abstract: Users of cloud computing platforms pose different types of demands for\nmultiple resources on servers (physical or virtual machines). Besides\ndifferences in their resource capacities, servers may be additionally\nheterogeneous in their ability to service users - certain users' tasks may only\nbe serviced by a subset of the servers. We identify important shortcomings in\nexisting multi-resource fair allocation mechanisms - Dominant Resource Fairness\n(DRF) and its follow up work - when used in such environments. We develop a new\nfair allocation mechanism called Per-Server Dominant-Share Fairness (PS-DSF)\nwhich we show offers all desirable sharing properties that DRF is able to offer\nin the case of a single \"resource pool\" (i.e., if the resources of all servers\nwere pooled together into one hypothetical server). We evaluate the performance\nof PS-DSF through simulations. Our evaluation shows the enhanced efficiency of\nPS-DSF compared to the existing allocation mechanisms. We argue how our\nproposed allocation mechanism is applicable in cloud computing networks and\nespecially large scale data-centers. \n\n"}
{"id": "1611.00452", "contents": "Title: Matter Equation of State in General Relativity Abstract: We study how a strong gravity affects the equation of state of matters. For\nthis purpose, we employ a canonical ensemble of classical monoatomic ideal gas\ninside a box in a Rindler spacetime. The total energy decreases monotonically\nwith the increase of the external gravity representing its attractiveness. It\nis however bounded below, which is different from that of the Newtonian gravity\ncase. As for the entropy, it decreases with the external gravity in the\nNewtonian regime. However, in the presence of strong gravity or\nultra-relativistic high temperature, the entropy increases with the gravity.\nThis result can be a resolution of the negative entropy problem of the ideal\ngas in the Newtonian gravity. In the presence of strong gravity, the bottom of\nthe box is very close to the event horizon of the Rindler spacetime mimicking a\nblackhole and the gas behaves as if it is on an effective two dimensional\nsurface located at the bottom of the box. Investigating the equation of state\nin the strong gravity regime, the temperature of the system is found to be not\na free parameter but to approach a fixed value proportional to the external\ngravity, which is reminiscent of the Unruh temperature. \n\n"}
{"id": "1611.01567", "contents": "Title: Thermal Brillouin noise observed in silicon optomechanical waveguide Abstract: Stimulated Brillouin scattering was recently observed in nanoscale silicon\nwaveguides. Surprisingly, thermally-driven photon-phonon conversion in these\nstructures had not yet been reported. Here, we inject an optical probe in a\nsuspended silicon waveguide and measure its phase fluctuations at the output.\nWe observe mechanical resonances around 8 GHz with a scattering efficiency of\n$10^{-5} \\, \\text{m}^{-1}$ and a signal-to-noise ratio of 2. The observations\nare in agreement with a theory of noise in these waveguides as well as with\nstimulated measurements. Our scheme may simplify measurements of mechanical\nsignatures in nanoscale waveguides and is a step towards a better grasp of\nthermal noise in these new continuum optomechanical systems. \n\n"}
{"id": "1611.02101", "contents": "Title: Distributed Coordinate Descent for Generalized Linear Models with\n  Regularization Abstract: Generalized linear model with $L_1$ and $L_2$ regularization is a widely used\ntechnique for solving classification, class probability estimation and\nregression problems. With the numbers of both features and examples growing\nrapidly in the fields like text mining and clickstream data analysis\nparallelization and the use of cluster architectures becomes important. We\npresent a novel algorithm for fitting regularized generalized linear models in\nthe distributed environment. The algorithm splits data between nodes by\nfeatures, uses coordinate descent on each node and line search to merge results\nglobally. Convergence proof is provided. A modifications of the algorithm\naddresses slow node problem. For an important particular case of logistic\nregression we empirically compare our program with several state-of-the art\napproaches that rely on different algorithmic and data spitting methods.\nExperiments demonstrate that our approach is scalable and superior when\ntraining on large and sparse datasets. \n\n"}
{"id": "1611.04200", "contents": "Title: Electron-nuclear spin dynamics of Ga$^{2+}$ paramagnetic centers probed\n  by spin dependent recombination: A master equation approach Abstract: Similar to nitrogen-vacancy centers in diamond and impurity atoms in silicon,\ninterstitial gallium deep paramagnetic centers in GaAsN have been proven to\nhave useful characteristics for the development of spintronic devices. Among\nother interesting properties, under circularly polarized light, gallium centers\nin GaAsN act as spin filters that dynamically polarize free and bound electrons\nreaching record spin polarizations (100\\%). Furthermore, the recent observation\nof the amplification of the spin filtering effect under a Faraday configuration\nmagnetic field has suggested that the hyperfine interaction that couples bound\nelectrons and nuclei permits the optical manipulation of its nuclear spin\npolarization. Even though the mechanisms behind the nuclear spin polarization\nin gallium centers are fairly well understood, the origin of nuclear spin\nrelaxation and the formation of an Overhauser-like magnetic field remain\nelusive. In this work we develop a model based on the master equation approach\nto describe the evolution of electronic and nuclear spin polarizations of\ngallium centers interacting with free electrons and holes. Our results are in\ngood agreement with existing experimental observations. In regard to the\nnuclear spin relaxation, the roles of nuclear dipolar and quadrupolar\ninteractions are discussed. Our findings show that, besides the hyperfine\ninteraction, the spin relaxation mechanisms are key to understand the\namplification of the spin filtering effect and the appearance of the\nOverhauser-like magnetic field. Based on our model's results we propose an\nexperimental protocol based on time resolved spectroscopy. It consists of a\npump-probe photoluminescence scheme that would allow the detection and the\ntracing of the electron-nucleus flip-flops through time resolved PL\nmeasurements. \n\n"}
{"id": "1611.04352", "contents": "Title: Geometry dependence of surface lattice resonances in plasmonic\n  nanoparticle arrays Abstract: Plasmonic nanoarrays which support collective surface lattice resonances\n(SLRs) have become an exciting frontier in plasmonics. Compared with the\nlocalized surface plasmon resonance (LSPR) in individual particles, these\ncollective modes have appealing advantages such as angle-dependent dispersions\nand much narrower linewidths. Here, we investigate systematically how the\ngeometry of the lattice affects the SLRs supported by metallic nanoparticles.\nWe present a general theoretical framework from which the various SLR modes of\na given geometry can be straightforwardly obtained by a simple comparison of\nthe diffractive order (DO) vectors and orientation of the nanoparticle dipole\ngiven by the polarization of the incident field. Our experimental measurements\nshow that while square, hexagonal, rectangular, honeycomb and Lieb lattice\narrays have similar spectra near the $\\Gamma$-point ($k=0$), they have\nremarkably different SLR dispersions. Furthermore, their dispersions are highly\ndependent on the polarization. Numerical simulations are performed to elucidate\nthe field profiles of the different modes. Our findings extend the diversity of\nSLRs in plasmonic nanoparticle arrays, and the theoretical framework provides a\nsimple model for interpreting the SLRs features, and vice versa, for designing\nthe geometrical patterns. \n\n"}
{"id": "1611.04869", "contents": "Title: Spectral theory for random Poincar\\'e maps Abstract: We consider stochastic differential equations, obtained by adding weak\nGaussian white noise to ordinary differential equations admitting $N$\nasymptotically stable periodic orbits. We construct a discrete-time,\ncontinuous-space Markov chain, called a random Poincar\\'e map, which encodes\nthe metastable behaviour of the system. We show that this process admits\nexactly $N$ eigenvalues which are exponentially close to $1$, and provide\nexpressions for these eigenvalues and their left and right eigenfunctions in\nterms of committor functions of neighbourhoods of periodic orbits. The\neigenvalues and eigenfunctions are well-approximated by principal eigenvalues\nand quasistationary distributions of processes killed upon hitting some of\nthese neighbourhoods. The proofs rely on Feynman--Kac-type representation\nformulas for eigenfunctions, Doob's $h$-transform, spectral theory of compact\noperators, and a recently discovered detailed-balance property satisfied by\ncommittor functions. \n\n"}
{"id": "1611.06231", "contents": "Title: ALMA observations of the nearby AGB star L2 Puppis - I. Mass of the\n  central star and detection of a candidate planet Abstract: Six billion years from now, while evolving on the asymptotic giant branch\n(AGB), the Sun will metamorphose from a red giant into a beautiful planetary\nnebula. This spectacular evolution will impact the Solar System planets, but\nobservational confirmations of the predictions of evolution models are still\nelusive as no planet orbiting an AGB star has yet been discovered. The nearby\nAGB red giant L2 Puppis (d = 64 pc) is surrounded by an almost edge-on\ncircumstellar dust disk. We report new observations with ALMA at very high\nangular resolution (18 x 15 mas) in band 7 (f ~ 350 GHz) that allow us to\nresolve the velocity profile of the molecular disk. We establish that the gas\nvelocity profile is Keplerian within the central cavity of the dust disk,\nallowing us to derive the mass of the central star L2 Pup A, mA = 0.659 +/-\n0.011 +/- 0.041 Msun (+/- 6.6%). From evolutionary models, we determine that L2\nPup A had a near-solar main sequence mass, and is therefore a close analog of\nthe future Sun in 5 to 6 Gyr. The continuum map reveals the presence of a\nsecondary source (B) at a radius of 2 AU contributing fB/ fA = 1.3 +/- 0.1% of\nthe flux of the AGB star. L2 Pup B is also detected in CO emission lines at a\nradial velocity of vB = 12.2 +/- 1.0 km/s. The close coincidence of the center\nof rotation of the gaseous disk with the position of the continuum emission\nfrom the AGB star allows us to constrain the mass of the companion to mB = 12\n+/- 16 MJup. L2 Pup B is most likely a planet or low mass brown dwarf with an\norbital period around 5 years. Its continuum brightness and molecular emission\nsuggest that it may be surrounded by an extended molecular atmosphere or an\naccretion disk. L2 Pup therefore emerges as a promising vantage point on the\ndistant future of our Solar System. \n\n"}
{"id": "1611.06971", "contents": "Title: Combining micro- and macroscopic probes to untangle single-ion and\n  spatial exchange anisotropies in a $S = 1$ quantum antiferromagnet Abstract: The magnetic ground state of the quasi-one-dimensional spin-1\nantiferromagnetic chain is sensitive to the relative sizes of the single-ion\nanisotropy ($D$) and the intrachain ($J$) and interchain ($J'$) exchange\ninteractions. The ratios $D/J$ and $J'/J$ dictate the material's placement in\none or other of three competing phases: a Haldane gapped phase, a quantum\nparamagnet and an XY-ordered state, with a quantum critical point at their\njunction. We have identified [Ni(HF)$_2$(pyz)$_2]$SbF$_6$, where pyz =\npyrazine, as a candidate in which this behavior can be explored in detail.\nCombining neutron scattering (elastic and inelastic) in applied magnetic fields\nof up to 10~tesla and magnetization measurements in fields of up to 60~tesla\nwith numerical modeling of experimental observables, we are able to obtain\naccurate values of all of the parameters of the Hamiltonian [$D = 13.3(1)$~K,\n$J = 10.4(3)$~K and $J' = 1.4(2)$~K], despite the polycrystalline nature of the\nsample. Density-functional theory calculations result in similar couplings ($J\n= 9.2$~K, $J' = 1.8$~K) and predict that the majority of the total spin\npopulation of resides on the Ni(II) ion, while the remaining spin density is\ndelocalized over both ligand types. The general procedures outlined in this\npaper permit phase boundaries and quantum-critical points to be explored in\nanisotropic systems for which single crystals are as yet unavailable. \n\n"}
{"id": "1611.07223", "contents": "Title: On Limiting Behavior of Stationary Measures for Stochastic Evolution\n  Systems with Small Noise Intensity Abstract: The limiting behavior of stochastic evolution processes with small noise\nintensity $\\epsilon$ is investigated in distribution-based approach. Let\n$\\mu^{\\epsilon}$ be stationary measure for stochastic process $X^{\\epsilon}$\nwith small $\\epsilon$ and $X^{0}$ be a semiflow on a Polish space. Assume that\n$\\{\\mu^{\\epsilon}: 0<\\epsilon\\leq\\epsilon_0\\}$ is tight. Then all their limits\nin weak sense are $X^0-$invariant and their supports are contained in Birkhoff\ncenter of $X^0$. Applications are made to various stochastic evolution systems,\nincluding stochastic ordinary differential equations, stochastic partial\ndifferential equations, stochastic functional differential equations driven by\nBrownian motion or L\\'{e}vy process. \n\n"}
{"id": "1611.08650", "contents": "Title: Topological Crystalline Magnets: Symmetry-Protected Topological Phases\n  of Fermions Abstract: We introduce a novel class of interaction-enabled topological crystalline\ninsulators in two- and three-dimensional electronic systems, which we call\n\"topological crystalline magnet.\" It is protected by the product of the\ntime-reversal symmetry $\\mathcal{T}$ and a mirror symmetry or a rotation\nsymmetry $\\mathcal{R}$. A topological crystalline magnet exhibits two\nintriguing features: (i) it cannot be adiabatically connected to any Slater\ninsulator and (ii) the edge state is robust against coupling electrons to the\nedge. These features are protected by the anomalous symmetry transformation\nproperty $(\\mathcal{R} \\mathcal{T})^2=-1$ of the edge state. An anisotropic\nresponse to the external magnetic field can be an experimental signature. \n\n"}
{"id": "1611.09723", "contents": "Title: Mean-field limits for large-scale random-access networks Abstract: We establish mean-field limits for large-scale random-access networks with\nbuffer dynamics and arbitrary interference graphs. While saturated-buffer\nscenarios have been widely investigated and yield useful throughput estimates\nfor persistent sessions, they fail to capture the fluctuations in buffer\ncontents over time, and provide no insight in the delay performance of flows\nwith intermittent packet arrivals. Motivated by that issue, we explore in the\npresent paper random-access networks with buffer dynamics, where flows with\nempty buffers refrain from competition for the medium. The occurrence of empty\nbuffers thus results in a complex dynamic interaction between activity states\nand buffer contents, which severely complicates the performance analysis. Hence\nwe focus on a many-sources regime where the total number of nodes grows large,\nwhich not only offers mathematical tractability but is also highly relevant\nwith the densification of wireless networks as the Internet of Things emerges.\nWe exploit time scale separation properties to prove that the properly scaled\nbuffer occupancy process converges to the solution of a deterministic\ninitial-value problem, and establish the existence and uniqueness of the\nassociated fixed point. This approach simplifies the performance analysis of\nnetworks with huge numbers of nodes to a low-dimensional fixed-point\ncalculation. For the case of a complete interference graph, we demonstrate\nasymptotic stability, provide a simple closed-form expression for the fixed\npoint, and prove interchange of the mean-field and steady-state limits. This\nyields asymptotically exact approximations for key performance metrics, in\nparticular the stationary buffer content and packet delay distributions. The\nmethodological framework that we develop easily extends to various model\nrefinements as will be illustrated by several examples. \n\n"}
{"id": "1612.00434", "contents": "Title: Stationary coalescing walks on the lattice Abstract: We consider translation invariant measures on families of nearest-neighbor\nsemi-infinite walks on the integer lattice. We assume that once walks meet,\nthey coalesce. In $2d$, we classify the collective behavior of these walks\nunder mild assumptions: they either coalesce almost surely or form bi-infinite\ntrajectories. Bi-infinite trajectories form measure-preserving dynamical\nsystems, have a common asymptotic direction in $2d$, and possess other nice\nproperties. We use our theory to classify the behavior of compatible families\nof semi-infinite geodesics in stationary first- and last-passage percolation.\nWe also partially answer a question raised by C. Hoffman about the limiting\nempirical measure of weights seen by geodesics. We construct several examples:\nour main example is a standard first-passage percolation model where geodesics\ncoalesce almost surely, but have no asymptotic direction or average weight. \n\n"}
{"id": "1612.03898", "contents": "Title: Internal Delensing of Cosmic Microwave Background Acoustic Peaks Abstract: We present a method to delens the acoustic peaks of the CMB temperature and\npolarization power spectra internally, using lensing maps reconstructed from\nthe CMB itself. We find that when delensing CMB acoustic peaks with a lensing\npotential map derived from the same CMB sky, a large bias arises in the\ndelensed power spectrum. The cause of this bias is that the noise in the\nreconstructed potential map is derived from, and hence correlated with, the CMB\nmap when delensing. This bias is more significant relative to the signal than\nan analogous bias found when delensing CMB B modes. We calculate the leading\nterm of this bias, which is present even in the absence of lensing. We also\ndemonstrate one method to remove this bias, using reconstructions from CMB\nangular scales within given ranges to delens CMB scales outside of those\nranges. Some details relevant for a realistic analysis are also discussed, such\nas the importance of removing mask-induced effects for successful delensing,\nand a useful null test, obtained from randomizing the phases of the\nreconstructed potential. Our findings should help current and next-generation\nCMB experiments obtain tighter parameter constraints via the internal removal\nof lensing-induced smoothing from temperature and E-mode acoustic peaks. \n\n"}
{"id": "1612.05544", "contents": "Title: Measurement of the linear thermo-optical coefficient of\n  Ga$_{0.51}$In$_{0.49}$P using photonic crystal nanocavities Abstract: Ga$_{0.51}$In$_{0.49}$P is a promising candidate for thermally tunable\nnanophotonic devices due to its low thermal conductivity. In this work we study\nits thermo-optical response. We obtain the linear thermo-optical coefficient\n$dn/dT=2.0\\pm0.3\\cdot 10^{-4}\\,\\rm{K}^{-1}$ by investigating the transmission\nproperties of a single mode-gap photonic crystal nanocavity. \n\n"}
{"id": "1612.06302", "contents": "Title: Hybrid Transactional Replication: State-Machine and Deferred-Update\n  Replication Combined Abstract: We propose Hybrid Transactional Replication (HTR), a novel replication scheme\nfor highly dependable services. It combines two schemes: a transaction is\nexecuted either optimistically by only one service replica in the deferred\nupdate mode (DU), or deterministically by all replicas in the state machine\nmode (SM); the choice is made by an oracle. The DU mode allows for parallelism\nand thus takes advantage of multicore hardware. In contrast to DU, the SM mode\nguarantees abort-free execution, so it is suitable for irrevocable operations\nand transactions generating high contention. For expressiveness, transactions\ncan be discarded or retried on demand. We formally prove that the higher\nflexibility of the scheme does not come at the cost of weaker guarantees for\nclients: HTR satisfies strong consistency guarantees akin to those provided by\nother popular transactional replication schemes such as Deferred Update\nReplication. We developed HTR-enabled Paxos STM, an object-based distributed\ntransactional memory system, and evaluated it thoroughly under various\nworkloads. We show the benefits of using a novel oracle, which relies on\nmachine learning techniques for automatic adaptation to changing conditions. In\nour tests, the ML-based oracle provides up to 50% improvement in throughput\nwhen compared to the system running with DU-only or SM-only oracles. Our\napproach is inspired by a well known algorithm used in the context of the\nmulti-armed bandit problem. \n\n"}
{"id": "1612.09426", "contents": "Title: The Balance Attack Against Proof-Of-Work Blockchains: The R3 Testbed as\n  an Example Abstract: In this paper, we identify a new form of attack, called the Balance attack,\nagainst proof-of-work blockchain systems. The novelty of this attack consists\nof delaying network communications between multiple subgroups of nodes with\nbalanced mining power. Our theoretical analysis captures the precise tradeoff\nbetween the network delay and the mining power of the attacker needed to double\nspend in Ethereum with high probability.\n  We quantify our probabilistic analysis with statistics taken from the R3\nconsortium, and show that a single machine needs 20 minutes to attack the\nconsortium. Finally, we run an Ethereum private chain in a distributed system\nwith similar settings as R3 to demonstrate the feasibility of the approach, and\ndiscuss the application of the Balance attack to Bitcoin. Our results clearly\nconfirm that main proof-of-work blockchain protocols can be badly suited for\nconsortium blockchains. \n\n"}
{"id": "1701.02986", "contents": "Title: Enhancing Near-Field Radiative Heat Transfer with Si-based Metasurfaces Abstract: We demonstrate in this work that the use of metasurfaces provides a viable\nstrategy to largely tune and enhance near-field radiative heat transfer between\nextended structures. In particular, using a rigorous coupled wave analysis, we\npredict that Si-based metasurfaces featuring two-dimensional periodic arrays of\nholes can exhibit a room-temperature near-field radiative heat conductance much\nlarger than any unstructured material to date. We show that this enhancement,\nwhich takes place in a broad range of separations, relies on the possibility to\nlargely tune the properties of the surface plasmon polaritons that dominate the\nradiative heat transfer in the near-field regime. \n\n"}
{"id": "1701.03039", "contents": "Title: Nonclassical Light Generation from III-V and Group-IV Solid-State Cavity\n  Quantum Systems Abstract: In this chapter, we present the state-of-the-art in the generation of\nnonclassical states of light using semiconductor cavity quantum electrodynamics\n(QED) platforms. Our focus is on the photon blockade effects that enable the\ngeneration of indistinguishable photon streams with high purity and efficiency.\nStarting with the leading platform of InGaAs quantum dots in optical\nnanocavities, we review the physics of a single quantum emitter strongly\ncoupled to a cavity. Furthermore, we propose a complete model for photon\nblockade and tunneling in III-V quantum dot cavity QED systems. Turning toward\nquantum emitters with small inhomogeneous broadening, we propose a direction\nfor novel experiments for nonclassical light generation based on group-IV\ncolor-center systems. We present a model of a multi-emitter cavity QED\nplatform, which features richer dressed-states ladder structures, and show how\nit can offer opportunities for studying new regimes of high-quality photon\nblockade. \n\n"}
{"id": "1701.03247", "contents": "Title: Scalable Spectrum Allocation and User Association in Networks with Many\n  Small Cells Abstract: A scalable framework is developed to allocate radio resources across a large\nnumber of densely deployed small cells with given traffic statistics on a slow\ntimescale. Joint user association and spectrum allocation is first formulated\nas a convex optimization problem by dividing the spectrum among all possible\ntransmission patterns of active access points (APs). To improve scalability\nwith the number of APs, the problem is reformulated using local patterns of\ninterfering APs. To maintain global consistency among local patterns,\ninter-cluster interaction is characterized as hyper-edges in a hyper-graph with\nnodes corresponding to neighborhoods of APs. A scalable solution is obtained by\niteratively solving a convex optimization problem for bandwidth allocation with\nreduced complexity and constructing a global spectrum allocation using\nhyper-graph coloring. Numerical results demonstrate the proposed solution for a\nnetwork with 100 APs and several hundred user equipments. For a given quality\nof service (QoS), the proposed scheme can increase the network capacity several\nfold compared to assigning each user to the strongest AP with full-spectrum\nreuse. \n\n"}
{"id": "1701.05945", "contents": "Title: Exploiting the Cloud Control Plane for Fun and Profit Abstract: Cloud providers typically charge for their services. There are diverse\npricing models which often follow a pay-per-use paradigm. The consumers'\npayments are expected to cover all cost which incurs to the provider for\nprocessing, storage, bandwidth, data centre operation and engineering efforts,\namong others. In contrast, the consumer management interfaces are free of\ncharge as they are expected to cause only a minority of the load compared to\nthe actual computing services. With new service models and more complex and\npowerful management abilities, it is time to rethink this decision. The paper\nshows how to exploit the control plane of AWS Lambda to implement stateful\nservices practically for free and under some circumstances even guaranteed for\nfree which if widely deployed would cause a monetary loss for the provider. It\nalso elaborates on the consistency model for AWS Lambda. \n\n"}
{"id": "1701.05986", "contents": "Title: Distributed Random-Fixed Projected Algorithm for Constrained\n  Optimization Over Digraphs Abstract: This paper is concerned with a constrained optimization problem over a\ndirected graph (digraph) of nodes, in which the cost function is a sum of local\nobjectives, and each node only knows its local objective and constraints. To\ncollaboratively solve the optimization, most of the existing works require the\ninteraction graph to be balanced or \"doubly-stochastic\", which is quite\nrestrictive and not necessary as shown in this paper. We focus on an epigraph\nform of the original optimization to resolve the \"unbalanced\" problem, and\ndesign a novel two-step recursive algorithm with a simple structure. Under\nstrongly connected digraphs, we prove that each node asymptotically converges\nto some common optimal solution. Finally, simulations are performed to\nillustrate the effectiveness of the proposed algorithms. \n\n"}
{"id": "1701.06051", "contents": "Title: The Economics of Competition and Cooperation Between MNOs and MVNOs Abstract: In this work, we consider the economics of the interaction between Mobile\nVirtual Network Operators (MVNOs) and Mobile Network Operators (MNOs). We\ninvestigate the incentives of an MNO for offering some of her resources to an\nMVNO instead of using the resources for her own. We formulate the problem as a\nsequential game. We consider a market with one MNO and one MVNO, and a\ncontinuum of undecided end-users. We assume that EUs have different preferences\nfor the MNO and the MVNO. These preferences can be because of the differences\nin the service they are offering or the reluctance of an EU to buy her plan\nfrom one of them. We assume that the preferences also depend on the investment\nlevel the MNO and the MVNO. We show that there exists a unique interior SPNE,\ni.e. the SPNE by which both SPs receive a positive mass of EUs, and\ncharacterize it. We also consider a benchmark case in which the MNO and the\nMVNO do not cooperate, characterize the unique SPNE of this case, and compare\nthe results of our model to the benchmark case to assess the incentive of the\nMNO to invest in her infrastructure and to offer it to the MVNO. \n\n"}
{"id": "1701.06853", "contents": "Title: Synchronization, Lyapunov exponents and stable manifolds for random\n  dynamical systems Abstract: During the past decades, the question of existence and properties of a random\nattractor of a random dynamical system generated by an S(P)DE has received\nconsiderable attention, for example by the work of Gess and R\\\"ockner. Recently\nsome authors investigated sufficient conditions which guarantee\nsynchronization, i.e. existence of a random attractor which is a singleton. It\nis reasonable to conjecture that synchronization and negativity (or\nnon-positivity) of the top Lyapunov exponent of the system should be closely\nrelated since both mean that the system is contracting in some sense. Based on\nclassical results by Ruelle, we formulate positive results in this direction.\nFinally we provide two very simple but striking examples of one-dimensional\nmonotone random dynamical systems for which 0 is a fixed point. In the first\nexample, the Lyapunov exponent is strictly negative but nevertheless all\ntrajectories starting outside of 0 diverge to $\\infty$ or $-\\infty$. In\nparticular, there is no synchronization (not even locally). In the second\nexample (which is just the time reversal of the first), the Lyapunov exponent\nis strictly positive but nevertheless there is synchronization. \n\n"}
{"id": "1701.06913", "contents": "Title: Geodesics around oscillatons made of exponential scalar field potential Abstract: Oscillatons are spherically symmetric solutions to the Einstein Klein Gordon\n(EKG) equations for soliton stars made of real time dependent scalar fields.\nThese equations are non singular and satisfy flatness conditions asymptotically\nwith periodic time dependency. In this paper, we investigate the geodesic\nmotion of particles moving around an oscillaton related to a time dependent\nscalar field. Bound orbital is found for these particles under the condition of\nparticular values of angular momentum L and initial radial position. We discuss\nthis topic for an exponential scalar field potential which could be of the\nexponential form with a scalar field and investigate whether the radial\ncoordinates of such particles oscillate in time or not and thereby we could\npredict the corresponding oscillating period as well as amplitude. It is\nnecessary to recall, in general relativity, a geodesic generalizes the notion\nof a straight line to curved space time. Importantly, the world line of a\nparticle free from all external, non gravitational forces, is a particular type\nof geodesic. In other words, a freely moving or falling particle always moves\nalong a geodesic. In general relativity, gravity can be regarded as not a force\nbut a consequence of a curved space time geometry where the source of curvature\nis the stress energy tensor (representing matter, for instance). Thus, for\nexample, the path of a planet orbiting around a star is the projection of a\ngeodesic of the curved 4D space time geometry around the star onto 3D space. \n\n"}
{"id": "1701.07248", "contents": "Title: Distributed methods for synchronization of orthogonal matrices over\n  graphs Abstract: This paper addresses the problem of synchronizing orthogonal matrices over\ndirected graphs. For synchronized transformations (or matrices), composite\ntransformations over loops equal the identity. We formulate the synchronization\nproblem as a least-squares optimization problem with nonlinear constraints. The\nsynchronization problem appears as one of the key components in applications\nranging from 3D-localization to image registration. The main contributions of\nthis work can be summarized as the introduction of two novel algorithms; one\nfor symmetric graphs and one for graphs that are possibly asymmetric. Under\ngeneral conditions, the former has guaranteed convergence to the solution of a\nspectral relaxation to the synchronization problem. The latter is stable for\nsmall step sizes when the graph is quasi-strongly connected. The proposed\nmethods are verified in numerical simulations. \n\n"}
{"id": "1701.08680", "contents": "Title: Fog-Assisted wIoT: A Smart Fog Gateway for End-to-End Analytics in\n  Wearable Internet of Things Abstract: Today, wearable internet-of-things (wIoT) devices continuously flood the\ncloud data centers at an enormous rate. This increases a demand to deploy an\nedge infrastructure for computing, intelligence, and storage close to the\nusers. The emerging paradigm of fog computing could play an important role to\nmake wIoT more efficient and affordable. Fog computing is known as the cloud on\nthe ground. This paper presents an end-to-end architecture that performs data\nconditioning and intelligent filtering for generating smart analytics from\nwearable data. In wIoT, wearable sensor devices serve on one end while the\ncloud backend offers services on the other end. We developed a prototype of\nsmart fog gateway (a middle layer) using Intel Edison and Raspberry Pi. We\ndiscussed the role of the smart fog gateway in orchestrating the process of\ndata conditioning, intelligent filtering, smart analytics, and selective\ntransfer to the cloud for long-term storage and temporal variability\nmonitoring. We benchmarked the performance of developed prototypes on\nreal-world data from smart e-textile gloves. Results demonstrated the usability\nand potential of proposed architecture for converting the real-world data into\nuseful analytics while making use of knowledge-based models. In this way, the\nsmart fog gateway enhances the end-to-end interaction between wearables (sensor\ndevices) and the cloud. \n\n"}
{"id": "1701.09011", "contents": "Title: Overlay Routing for Fast Video Transfers in CDN Abstract: Content Delivery Networks (CDN) are witnessing the outburst of video\nstreaming (e.g., personal live streaming or Video-on-Demand) where the video\ncontent, produced or accessed by mobile phones, must be quickly transferred\nfrom a point to another of the network. Whenever a user requests a video not\ndirectly available at the edge server, the CDN network must 1) identify the\nbest location in the network where the content is stored, 2) set up a\nconnection and 3) deliver the video as quickly as possible. For this reason,\nexisting CDNs are adopting an overlay structure to reduce latency, leveraging\nthe flexibility introduced by the Software Defined Networking (SDN) paradigm.\nIn order to guarantee a satisfactory Quality of Experience (QoE) to users, the\nconnection must respect several Quality of Service (QoS) constraints. In this\npaper, we focus on the sub-problem 2), by presenting an approach to efficiently\ncompute and maintain paths in the overlay network. Our approach allows to speed\nup the transfer of video segments by finding minimum delay overlay paths under\nconstraints on hop count, jitter, packet loss and relay processing capacity.\nThe proposed algorithm provides a near-optimal solution, while drastically\nreducing the execution time. We show on traces collected in a real CDN that our\nsolution allows to maximize the number of fast video transfers. \n\n"}
{"id": "1702.00393", "contents": "Title: Maxima of stable random fields, nonsingular actions and finitely\n  generated abelian groups: A survey Abstract: This is a self-contained introduction to the applications of ergodic theory\nof nonsingular (also known as quasi-invariant) group actions and the structure\ntheorem for finitely generated abelian groups on the extreme values of\nstationary symmetric stable random fields indexed by $\\mathbb{Z}^d$. It is\nbased on a mini course given in the Eighth Lectures on Probability and\nStochastic Processes (held in the Bangalore Centre of Indian Statistical\nInstitute during December 6-10, 2013) except that a few recent references have\nbeen added in the concluding part. This article is a survey of existing work\nand the proofs are therefore skipped or briefly outlined. \n\n"}
{"id": "1702.01862", "contents": "Title: Definition of Polaritonic Fluctuations in Natural Hyperbolic Media:\n  Applications to Hexagonal Boron Nitride, Bismuth Selenide and the Spontaneous\n  Emission Sum Rule Abstract: The discovery of photonic hyperbolic dispersion surfaces in certain van der\nWaals bonded solids, such as hexagonal boron nitride and bismuth selenide (a\ntopological insulator), offers intriguing possibilities for creating strongly\nmodified light-matter interactions. However, open problems exist in quantifying\nelectromagnetic field fluctuations in these media, complicating typical\napproaches for modeling photonic characteristics. Here, we address this issue\nby linking the identifying traits of hyperbolic response to a coupling between\nlongitudinal and transverse fields that can not occur in isotropic media. This\ndescription allows us to calculate the influence of hyperbolic response on\nelectromagnetic fluctuations without explicitly imposing a characteristic size\n(model of nonlocality), leading to formally bounded expressions so long as\nmaterial absorption is included. We then apply this framework to two exemplary\nareas: the optical sum rule for modified spontaneous emission enhancement in a\ngeneral uniaxial medium, and thermal electromagnetic field fluctuations in\nhexagonal boron nitride and bismuth selenide. We find that while the sum rule\nis satisfied, it does not constrain the enhancement of light-matter\ninteractions in either case. We also show that both hexagonal boron nitride and\nbismuth selenide possess broad spectral regions where the magnitude of\nelectromagnetic field fluctuations are over 120 times larger, and over 800\ntimes larger along specific angular directions, than they are in vacuum. \n\n"}
{"id": "1702.02455", "contents": "Title: Deterministic Protocols in the SINR Model without Knowledge of\n  Coordinates Abstract: Much work has been developed for studying the classical broadcasting problem\nin the SINR (Signal-to-Interference-plus-Noise-Ratio) model for wireless device\ntransmission. The setting typically studied is when all radio nodes transmit a\nsignal of the same strength. This work studies the challenging problem of\ndevising a distributed algorithm for multi-broadcasting, assuming a subset of\nnodes are initially awake, for the SINR model when each device only has access\nto knowledge about the total number of nodes in the network $n$, the range from\nwhich each node's label is taken $\\lbrace 1,\\dots,N \\rbrace$, and the label of\nthe device itself. Specifically, we assume no knowledge of the physical\ncoordinates of devices and also no knowledge of the neighborhood of each node.\n  We present a deterministic protocol for this problem in $O(n \\lg N \\lg n)$\nrounds. There is no known polynomial time deterministic algorithm in literature\nfor this setting, and it remains the principle open problem in this domain. A\nlower bound of $\\Omega(n \\lg N)$ rounds is known for deterministic broadcasting\nwithout local knowledge.\n  In addition to the above result, we present algorithms to achieve\nmulti-broadcast in $O(n \\lg N)$ rounds and create a backbone in $O(n \\lg N)$\nrounds, assuming that all nodes are initially awake. For a given backbone,\nmessages can be exchanged between every pair of connected nodes in the backbone\nin $O(\\lg N)$ rounds and between any node and its designated contact node in\nthe backbone in $O(\\Delta \\lg N)$ rounds. \n\n"}
{"id": "1702.02848", "contents": "Title: Distributed Domination on Graph Classes of Bounded Expansion Abstract: We provide a new constant factor approximation algorithm for the (connected)\ndistance-$r$ dominating set problem on graph classes of bounded expansion.\nClasses of bounded expansion include many familiar classes of sparse graphs\nsuch as planar graphs and graphs with excluded (topological) minors, and\nnotably, these classes form the most general subgraph closed classes of graphs\nfor which a sequential constant factor approximation algorithm for the\ndistance-$r$ dominating set problem is currently known. Our algorithm can be\nimplemented in the \\congestbc model of distributed computing and uses\n$\\mathcal{O}(r^2 \\log n)$ communication rounds.\n  Our techniques, which may be of independent interest, are based on a\ndistributed computation of sparse neighborhood covers of small radius on\nbounded expansion classes. We show how to compute an $r$-neighborhood cover of\nradius~$2r$ and overlap $f(r)$ on every class of bounded expansion in\n$\\mathcal{O}(r^2 \\log n)$ communication rounds for some function~$f$.% in the\n$\\mathcal{CONGEST}_{\\mathrm{BC}}$ model.\n  Finally, we show how to use the greater power of the $\\mathcal{LOCAL}$ model\nto turn any distance-$r$ dominating set into a constantly larger connected\ndistance-$r$ dominating set in $3r+1$ rounds on any class of bounded expansion.\nCombining this algorithm, e.g., with the constant factor approximation\nalgorithm for dominating sets on planar graphs of Lenzen et al.\\ gives a\nconstant factor approximation algorithm for connected dominating sets on planar\ngraphs in a constant number of rounds in the $\\mathcal{LOCAL}$ model, where the\napproximation ratio is only $6$ times larger than that of Lenzen et al.'s\nalgorithm. \n\n"}
{"id": "1702.03068", "contents": "Title: DBFT: Efficient Byzantine Consensus with a Weak Coordinator and its\n  Application to Consortium Blockchains Abstract: This paper introduces a deterministic Byzantine consensus algorithm that\nrelies on a new weak coordinator. As opposed to previous algorithms that cannot\nterminate in the presence of a faulty or slow coordinator, our algorithm can\nterminate even when its coordinator is faulty, hence the name weak coordinator.\nThe key idea is to allow processes to complete asynchronous rounds as soon as\nthey receive a threshold of messages, instead of having to wait for a message\nfrom a coordinator that may be slow.\n  The resulting algorithm assumes partial synchrony, is resilience optimal,\ntime optimal and does not need signatures. Our presentation is didactic: we\nfirst present a simple safe binary Byzantine consensus algorithm, modify it to\nensure termination, and finally present an optimized reduction from multivalue\nconsensus to binary consensus that may terminate in 4 message delays. To\nevaluate our algorithm, we deployed it on 100 machines distributed in 5\ndatacenters across different continents and compared its performance against\nthe randomized solution from Mostefaoui, Moumem and Raynal [PODC14] that\nterminates in O(1) rounds in expectation. Our algorithm always outperforms the\nlatter even in the presence of Byzantine behaviors. Our algorithm has a\nsubsecond average latency in most of our geo-distributed experiments, even when\nattacked by a well-engineered coalition of Byzantine processes. \n\n"}
{"id": "1702.04264", "contents": "Title: Beam Alignment for Millimetre Wave Links with Motion Prediction of\n  Autonomous Vehicles Abstract: Intelligent Transportation Systems (ITSs) require ultra-low end-to-end delays\nand multi-gigabit-per-second data transmission. Millimetre Waves (mmWaves)\ncommunications can fulfil these requirements. However, the increased mobility\nof Connected and Autonomous Vehicles (CAVs), requires frequent beamforming -\nthus introducing increased overhead. In this paper, a new beamforming algorithm\nis proposed able to achieve overhead-free beamforming training. Leveraging from\nthe CAVs sensory data, broadcast with Dedicated Short Range Communications\n(DSRC) beacons, the position and the motion of a CAV can be estimated and\nbeamform accordingly. To minimise the position errors, an analysis of the\ndistinct error components was presented. The network performance is further\nenhanced by adapting the antenna beamwidth with respect to the position error.\nOur algorithm outperforms the legacy IEEE 802.11ad approach proving it a viable\nsolution for the future ITS applications and services. \n\n"}
{"id": "1702.05126", "contents": "Title: Spectral performance of SKA Log-periodic Antennas I: Mitigating spectral\n  artefacts in SKA1-LOW 21-cm cosmology experiments Abstract: This paper is the first in a series of papers describing the impact of\nantenna instrumental artefacts on the 21-cm cosmology experiments to be carried\nout by the low frequency instrument (SKA1-LOW) of the Square Kilometre Array\ntelescope (SKA), i.e., the Cosmic Dawn (CD) and the Epoch of Reionization\n(EoR). The smoothness of the passband response of the current log-periodic\nantenna being developed for the SKA1-LOW is analyzed using numerical\nelectromagnetic simulations. The amplitude variations over the frequency range\nare characterized using low-order polynomials defined locally, in order to\nstudy the impact of the passband smoothness in the instrument calibration and\nCD/EoR Science. A solution is offered to correct a fast ripple found at 60~MHz\nduring a test campaign at the SKA site at the Murchison Radio-astronomy\nObservatory, Western Australia in September 2015 with a minor impact on the\ntelescope's performance and design. A comparison with the Hydrogen Epoch of\nReionization Array antenna is also shown demonstrating the potential use of the\nSKA1-LOW antenna for the Delay Spectrum technique to detect the EoR. \n\n"}
{"id": "1702.07403", "contents": "Title: Making Asynchronous Distributed Computations Robust to Noise Abstract: We consider the problem of making distributed computations robust to noise,\nin particular to worst-case (adversarial) corruptions of messages. We give a\ngeneral distributed interactive coding scheme which simulates any asynchronous\ndistributed protocol while tolerating an optimal corruption of a $\\Theta(1/n)$\nfraction of all messages while incurring a moderate blowup of $O(n\\log^2 n)$ in\nthe communication complexity.\n  Our result is the first fully distributed interactive coding scheme in which\nthe topology of the communication network is not known in advance. Prior work\nrequired either a coordinating node to be connected to all other nodes in the\nnetwork or assumed a synchronous network in which all nodes already know the\ncomplete topology of the network. \n\n"}
{"id": "1702.07514", "contents": "Title: Medical Image Retrieval Based On the Parallelization of the Cluster\n  Sampling Algorithm Abstract: In this paper we develop parallel cluster sampling algorithms and show that a\nmulti-chain version is embarrassingly parallel and can be used efficiently for\nmedical image retrieval among other applications. \n\n"}
{"id": "1702.08015", "contents": "Title: Polariton condensation in photonic crystals with high molecular\n  orientation Abstract: We study Frenkel exciton-polariton Bose-Einstein condensation in a\ntwo-dimensional defect-free triangular photonic crystal with an organic\nsemiconductor active medium containing bound excitons with dipole moments\noriented perpendicular to the layers. We find photonic Bloch modes of the\nstructure and consider their strong coupling regime with the excitonic\ncomponent. Using the Gross- Pitaevskii equation for exciton polaritons and the\nBoltzmann equation for the external exciton reservoir, we demonstrate the\nformation of condensate at the points in reciprocal space where photon group\nvelocity equals zero. Further, we demonstrate condensation at non-zero momentum\nstates for TM-polarized photons in the case of a system with incoherent\npumping, and show that the condensation threshold varies for different points\nin the reciprocal space, controlled by detuning. \n\n"}
{"id": "1702.08614", "contents": "Title: Testing redMaPPer centring probabilities using galaxy clustering and\n  galaxy-galaxy lensing Abstract: Galaxy cluster centring is a key issue for precision cosmology studies using\ngalaxy surveys. Mis-identification of central galaxies causes systematics in\nvarious studies such as cluster lensing, satellite kinematics, and galaxy\nclustering. The red-sequence Matched-filter Probabilistic Percolation\n(redMaPPer) estimates the probability that each member galaxy is central from\nphotometric information rather than specifying one central galaxy. The\nredMaPPer estimates can be used for calibrating the off-centring effect,\nhowever, the centring algorithm has not previously been well-tested. We test\nthe centring probabilities of redMaPPer cluster catalog using the projected\ncross correlation between redMaPPer clusters with photometric red galaxies and\ngalaxy-galaxy lensing. We focus on the subsample of redMaPPer clusters in which\nthe redMaPPer central galaxies (RMCGs) are not the brightest member galaxies\n(BMEM) and both of them have spectroscopic redshift. This subsample represents\nnearly 10% of the whole cluster sample. We find a clear difference in the\ncross-correlation measurements between RMCGs and BMEMs, and the estimated\ncentring probability is 74$\\pm$10% for RMCGs and 13$\\pm$4% for BMEMs in the\nGaussian offset model and 78$\\pm$9% for RMCGs and 5$\\pm$5% for BMEMs in the NFW\noffset model. These values are in agreement with the centring probability\nvalues reported by redMaPPer (75% for RMCG and 10% for BMEMs) within 1$\\sigma$.\nOur analysis provides a strong consistency test of the redMaPPer centring\nprobabilities. Our results suggest that redMaPPer centring probabilities are\nreliably estimated. We confirm that the brightest galaxy in the cluster is not\nalways the central galaxy as has been shown in previous works. \n\n"}
{"id": "1703.00690", "contents": "Title: Even better correction of genome sequencing data Abstract: We introduce an improved version of RECKONER, an error corrector for Illumina\nwhole genome sequencing data. By modifying its workflow we reduce the\ncomputation time even 10 times. We also propose a new method of determination\nof $k$-mer length, the key parameter of $k$-spectrum-based family of\ncorrectors. The correction algorithms are examined on huge data sets, i.e.,\nhuman and maize genomes for both Illumina HiSeq and MiSeq instruments. \n\n"}
{"id": "1703.01276", "contents": "Title: Surface - lattice resonances in 2d arrays of spheres: multipolar\n  interactions and a mode analysis Abstract: We present a multipolar model of surface - lattice resonances (SLRs) in 2d\narrays of spheres including the electric dipole, magnetic dipole, and electric\nquadrupole moments of the spheres. We identify SLRs of dipolar and multipolar\ncharacter, show the importance of non-resonant multipoles in their description,\nand discuss the sensitivity of SLRs to illumination conditions. We link SLRs to\nan excitation of modes supported by the array, and we propose a simplified\nmodel of the mode dispersion relations that explains the sensitivity of SLRs\nand the band gap in mode dispersion found at low frequencies. Finally we\ndiscuss the resonant features associated with a direct coupling to a mode which\ncan occur in addition to the diffractive coupling signalled by SLRs. \n\n"}
{"id": "1703.03924", "contents": "Title: Real-Time Machine Learning: The Missing Pieces Abstract: Machine learning applications are increasingly deployed not only to serve\npredictions using static models, but also as tightly-integrated components of\nfeedback loops involving dynamic, real-time decision making. These applications\npose a new set of requirements, none of which are difficult to achieve in\nisolation, but the combination of which creates a challenge for existing\ndistributed execution frameworks: computation with millisecond latency at high\nthroughput, adaptive construction of arbitrary task graphs, and execution of\nheterogeneous kernels over diverse sets of resources. We assert that a new\ndistributed execution framework is needed for such ML applications and propose\na candidate approach with a proof-of-concept architecture that achieves a 63x\nperformance improvement over a state-of-the-art execution framework for a\nrepresentative application. \n\n"}
{"id": "1703.04387", "contents": "Title: Mutual information decay for factors of IID Abstract: This paper is concerned with factor of i.i.d. processes on the $d$-regular\ntree for $d \\geq 3$. We study the mutual information of the values on two given\nvertices. If the vertices are neighbors (i.e., their distance is $1$), then a\nknown inequality between the entropy of a vertex and the entropy of an edge\nprovides an upper bound for the (normalized) mutual information. In this paper\nwe obtain upper bounds for vertices at an arbitrary distance $k$, of order\n$(d-1)^{-k/2}$. Although these bounds are sharp, we also show that an\ninteresting phenomenon occurs here: for any fixed process the rate of decay of\nthe mutual information is much faster, essentially of order $(d-1)^{-k}$. \n\n"}
{"id": "1703.04825", "contents": "Title: A Preferred Mass Range for Primordial Black Hole Formation and Black\n  Holes as Dark Matter Revisited Abstract: Bird, et. al. and Sasaki, et. al. have recently proposed the intriguing\npossibility that the black holes detected by LIGO could be all or part of the\ncosmological dark matter. This offers an alternative to WIMPs and axions, where\ndark matter could be comprised solely of Standard Model particles. The mass\nrange lies within an observationally viable window and the predicted merger\nrate can be tested by future LIGO observations. In this paper, we argue that\nnon-thermal histories favor production of black holes near this mass range --\nwith heavier ones unlikely to form in the early universe and lighter black\nholes being diluted through late-time entropy production. We discuss how this\nprediction depends on the primordial power spectrum, the likelihood of black\nhole formation, and the underlying model parameters. We find the prediction for\nthe preferred mass range to be rather robust assuming a blue spectral index\nless than two. We consider the resulting relic density in black holes, and\nusing recent observational constraints, establish whether they could account\nfor all of the dark matter today. \n\n"}
{"id": "1703.07364", "contents": "Title: The Waning of the WIMP? A Review of Models, Searches, and Constraints Abstract: Weakly Interacting Massive Particles (WIMPs) are among the best-motivated\ndark matter candidates. In light of no conclusive detection signal yet despite\nan extensive search program that combines, often in a complementary way,\ndirect, indirect, and collider probes, we find it timely to give a broad\noverview of the WIMP paradigm. In particular, we review here the theoretical\nfoundations of the WIMP paradigm, discuss status and prospects of various\ndetection strategies, and explore future experimental challenges and\nopportunities. \n\n"}
{"id": "1703.07551", "contents": "Title: MopEye: Opportunistic Monitoring of Per-app Mobile Network Performance Abstract: Crowdsourcing mobile user's network performance has become an effective way\nof understanding and improving mobile network performance and user\nquality-of-experience. However, the current measurement method is still based\non the landline measurement paradigm in which a measurement app measures the\npath to fixed (measurement or web) servers. In this work, we introduce a new\nparadigm of measuring per-app mobile network performance. We design and\nimplement MopEye, an Android app to measure network round-trip delay for each\napp whenever there is app traffic. This opportunistic measurement can be\nconducted automatically without users intervention. Therefore, it can\nfacilitate a large-scale and long-term crowdsourcing of mobile network\nperformance. In the course of implementing MopEye, we have overcome a suite of\nchallenges to make the continuous latency monitoring lightweight and accurate.\nWe have deployed MopEye to Google Play for an IRB-approved crowdsourcing study\nin a period of ten months, which obtains over five million measurements from\n6,266 Android apps on 2,351 smartphones. The analysis reveals a number of new\nfindings on the per-app network performance and mobile DNS performance. \n\n"}
{"id": "1703.08348", "contents": "Title: Video Streaming in Distributed Erasure-coded Storage Systems: Stall\n  Duration Analysis Abstract: The demand for global video has been burgeoning across industries. With the\nexpansion and improvement of video-streaming services, cloud-based video is\nevolving into a necessary feature of any successful business for reaching\ninternal and external audiences. This paper considers video streaming over\ndistributed systems where the video segments are encoded using an erasure code\nfor better reliability thus being the first work to our best knowledge that\nconsiders video streaming over erasure-coded distributed cloud systems. The\ndownload time of each coded chunk of each video segment is characterized and\nordered statistics over the choice of the erasure-coded chunks is used to\nobtain the playback time of different video segments. Using the playback times,\nbounds on the moment generating function on the stall duration is used to bound\nthe mean stall duration. Moment generating function based bounds on the ordered\nstatistics are also used to bound the stall duration tail probability which\ndetermines the probability that the stall time is greater than a pre-defined\nnumber. These two metrics, mean stall duration and the stall duration tail\nprobability, are important quality of experience (QoE) measures for the end\nusers. Based on these metrics, we formulate an optimization problem to jointly\nminimize the convex combination of both the QoE metrics averaged over all\nrequests over the placement and access of the video content. The non-convex\nproblem is solved using an efficient iterative algorithm. Numerical results\nshow significant improvement in QoE metrics for cloud-based video as compared\nto the considered baselines. \n\n"}
{"id": "1703.08370", "contents": "Title: A randomized primal distributed algorithm for partitioned and big-data\n  non-convex optimization Abstract: In this paper we consider a distributed optimization scenario in which the\naggregate objective function to minimize is partitioned, big-data and possibly\nnon-convex. Specifically, we focus on a set-up in which the dimension of the\ndecision variable depends on the network size as well as the number of local\nfunctions, but each local function handled by a node depends only on a (small)\nportion of the entire optimization variable. This problem set-up has been shown\nto appear in many interesting network application scenarios. As main paper\ncontribution, we develop a simple, primal distributed algorithm to solve the\noptimization problem, based on a randomized descent approach, which works under\nasynchronous gossip communication. We prove that the proposed asynchronous\nalgorithm is a proper, ad-hoc version of a coordinate descent method and thus\nconverges to a stationary point. To show the effectiveness of the proposed\nalgorithm, we also present numerical simulations on a non-convex quadratic\nprogram, which confirm the theoretical results. \n\n"}
{"id": "1703.08985", "contents": "Title: TCP in 5G mmWave Networks: Link Level Retransmissions and MP-TCP Abstract: MmWave communications, one of the cornerstones of future 5G mobile networks,\nare characterized at the same time by a potential multi-gigabit capacity and by\na very dynamic channel, sensitive to blockage, wide fluctuations in the\nreceived signal quality, and possibly also sudden link disruption. While the\nperformance of physical and MAC layer schemes that address these issues has\nbeen thoroughly investigated in the literature, the complex interactions\nbetween mmWave links and transport layer protocols such as TCP are still\nrelatively unexplored. This paper uses the ns-3 mmWave module, with its channel\nmodel based on real measurements in New York City, to analyze the performance\nof the Linux TCP/IP stack (i) with and without link-layer retransmissions,\nshowing that they are fundamental to reach a high TCP throughput on mmWave\nlinks and (ii) with Multipath TCP (MP-TCP) over multiple LTE and mmWave links,\nillustrating which are the throughput-optimal combinations of secondary paths\nand congestion control algorithms in different conditions. \n\n"}
{"id": "1703.09542", "contents": "Title: Palgol: A High-Level DSL for Vertex-Centric Graph Processing with Remote\n  Data Access Abstract: Pregel is a popular distributed computing model for dealing with large-scale\ngraphs. However, it can be tricky to implement graph algorithms correctly and\nefficiently in Pregel's vertex-centric model, especially when the algorithm has\nmultiple computation stages, complicated data dependencies, or even\ncommunication over dynamic internal data structures. Some domain-specific\nlanguages (DSLs) have been proposed to provide more intuitive ways to implement\ngraph algorithms, but due to the lack of support for remote access --- reading\nor writing attributes of other vertices through references --- they cannot\nhandle the above mentioned dynamic communication, causing a class of Pregel\nalgorithms with fast convergence impossible to implement.\n  To address this problem, we design and implement Palgol, a more declarative\nand powerful DSL which supports remote access. In particular, programmers can\nuse a more declarative syntax called chain access to naturally specify dynamic\ncommunication as if directly reading data on arbitrary remote vertices. By\nanalyzing the logic patterns of chain access, we provide a novel algorithm for\ncompiling Palgol programs to efficient Pregel code. We demonstrate the power of\nPalgol by using it to implement several practical Pregel algorithms, and the\nevaluation result shows that the efficiency of Palgol is comparable with that\nof hand-written code. \n\n"}
{"id": "1703.09678", "contents": "Title: Isolating Majorana fermions with finite Kitaev nanowires and\n  temperature: the universality of the zero-bias conductance Abstract: The zero-bias peak (ZBP) is understood as the definite signature of a\nMajorana bound state (MBS) when attached to a semi-infinite Kitaev nanowire\n(KNW) nearby zero temperature. However, such characteristics concerning the\nrealization of the KNW constitute a profound experimental challenge. We explore\ntheoretically a QD connected to a topological KNW of finite size at non-zero\ntemperatures and show that overlapped MBSs of the wire edges can become\neffectively decoupled from each other and the characteristic ZBP can be fully\nrecovered if one tunes the system into the leaked Majorana fermion fixed point.\nAt very low temperatures, the MBSs become strongly coupled similarly to what\nhappens in the Kondo effect. We derive universal features of the conductance as\na function of the temperature and the relevant crossover temperatures. Our\nfindings offer additional guides to identify signatures of MBSs in solid state\nsetups. \n\n"}
{"id": "1703.09707", "contents": "Title: Accelerating gravitational microlensing simulations using the Xeon Phi\n  coprocessor Abstract: Recently Graphics Processing Units (GPUs) have been used to speed up very\nCPU-intensive gravitational microlensing simulations. In this work, we use the\nXeon Phi coprocessor to accelerate such simulations and compare its performance\non a microlensing code with that of NVIDIA's GPUs. For the selected set of\nparameters evaluated in our experiment, we find that the speedup by Intel's\nKnights Corner coprocessor is comparable to that by NVIDIA's Fermi family of\nGPUs with compute capability 2.0, but less significant than GPUs with higher\ncompute capabilities such as the Kepler. However, the very recently released\nsecond generation Xeon Phi, Knights Landing, is about 5.8 times faster than the\nKnights Corner, and about 2.9 times faster than the Kepler GPU used in our\nsimulations. We conclude that the Xeon Phi is a very promising alternative to\nGPUs for modern high performance microlensing simulations. \n\n"}
{"id": "1703.09716", "contents": "Title: The splashback radius of halos from particle dynamics. II. Dependence on\n  mass, accretion rate, redshift, and cosmology Abstract: The splashback radius $R_{\\rm sp}$, the apocentric radius of particles on\ntheir first orbit after falling into a dark matter halo, has recently been\nsuggested as a physically motivated halo boundary that separates accreting from\norbiting material. Using the SPARTA code presented in Paper I, we analyze the\norbits of billions of particles in cosmological simulations of structure\nformation and measure $R_{\\rm sp}$ for a large sample of halos that span a mass\nrange from dwarf galaxy to massive cluster halos, reach redshift 8, and include\nWMAP, Planck, and self-similar cosmologies. We analyze the dependence of\n$R_{\\rm sp}/R_{\\rm 200m}$ and $M_{\\rm sp}/M_{\\rm 200m}$ on the mass accretion\nrate $\\Gamma$, halo mass, redshift, and cosmology. The scatter in these\nrelations varies between 0.02 and 0.1 dex. While we confirm the known trend\nthat $R_{\\rm sp}/R_{\\rm 200m}$ decreases with $\\Gamma$, the relationships turn\nout to be more complex than previously thought, demonstrating that $R_{\\rm sp}$\nis an independent definition of the halo boundary that cannot trivially be\nreconstructed from spherical overdensity definitions. We present fitting\nfunctions for $R_{\\rm sp}/R_{\\rm 200m}$ and $M_{\\rm sp}/M_{\\rm 200m}$ as a\nfunction of accretion rate, peak height, and redshift, achieving an accuracy of\n5% or better everywhere in the parameter space explored. We discuss the\nphysical meaning of the distribution of particle apocenters and show that the\npreviously proposed definition of $R_{\\rm sp}$ as the radius of the steepest\nlogarithmic density slope encloses roughly three-quarters of the apocenters.\nFinally, we conclude that no analytical model presented thus far can fully\nexplain our results. \n\n"}
{"id": "1703.09808", "contents": "Title: Dynamical engineering of interactions in qudit ensembles Abstract: We propose and analyze a method to engineer effective interactions in an\nensemble of d-level systems (qudits) driven by global control fields. In\nparticular, we present (i) a necessary and sufficient condition under which a\ngiven interaction can be turned off (decoupled), (ii) the existence of a\nuniversal sequence that decouples any (cancellable) interaction, and (iii) an\nefficient algorithm to engineer a target Hamiltonian from an initial\nHamiltonian (if possible). As examples, we provide a 6-pulse sequence that\ndecouples effective spin-1 dipolar interactions and demonstrate that a spin- 1\nIsing chain can be engineered to study transitions among three distinct\nsymmetry protected topological phases. \n\n"}
{"id": "1704.00705", "contents": "Title: Graph Partitioning with Acyclicity Constraints Abstract: Graphs are widely used to model execution dependencies in applications. In\nparticular, the NP-complete problem of partitioning a graph under constraints\nreceives enormous attention by researchers because of its applicability in\nmultiprocessor scheduling. We identified the additional constraint of acyclic\ndependencies between blocks when mapping computer vision and imaging\napplications to a heterogeneous embedded multiprocessor. Existing algorithms\nand heuristics do not address this requirement and deliver results that are not\napplicable for our use-case. In this work, we show that this more constrained\nversion of the graph partitioning problem is NP-complete and present heuristics\nthat achieve a close approximation of the optimal solution found by an\nexhaustive search for small problem instances and much better scalability for\nlarger instances. In addition, we can show a positive impact on the schedule of\na real imaging application that improves communication volume and execution\ntime. \n\n"}
{"id": "1704.00978", "contents": "Title: High-Throughput Computing on High-Performance Platforms: A Case Study Abstract: The computing systems used by LHC experiments has historically consisted of\nthe federation of hundreds to thousands of distributed resources, ranging from\nsmall to mid-size resource. In spite of the impressive scale of the existing\ndistributed computing solutions, the federation of small to mid-size resources\nwill be insufficient to meet projected future demands. This paper is a case\nstudy of how the ATLAS experiment has embraced Titan---a DOE leadership\nfacility in conjunction with traditional distributed high- throughput computing\nto reach sustained production scales of approximately 52M core-hours a years.\nThe three main contributions of this paper are: (i) a critical evaluation of\ndesign and operational considerations to support the sustained, scalable and\nproduction usage of Titan; (ii) a preliminary characterization of a next\ngeneration executor for PanDA to support new workloads and advanced execution\nmodes; and (iii) early lessons for how current and future experimental and\nobservational systems can be integrated with production supercomputers and\nother platforms in a general and extensible manner. \n\n"}
{"id": "1704.02560", "contents": "Title: Stable parity-time-symmetric nonlinear modes and excitations in a\n  derivative nonlinear Schrodinger equation Abstract: The effect of derivative nonlinearity and parity-time- (PT-) symmetric\npotentials on the wave propagation dynamics is investigated in the derivative\nnonlinear Schrodinger equation, where the physically interesting Scarff-II and\nhamonic-Hermite-Gaussian potentials are chosen. We study numerically the\nregions of unbroken/broken linear PT-symmetric phases and find some stable\nbright solitons of this model in a wide range of potential parameters even\nthough the corresponding linear PT-symmetric phases are broken. The\nsemi-elastic interactions between exact bright solitons and exotic incident\nwaves are illustrated such that we find that exact nonlinear modes almost keep\ntheir shapes after interactions even if the exotic incident waves have\nevidently been changed. Moreover, we exert the adiabatic switching on\nPT-symmetric potential parameters such that a stable nonlinear mode with the\nunbroken linear PT-symmetric phase can be excited to another stable nonlinear\nmode belonging to the broken linear PT-symmetric phase. \n\n"}
{"id": "1704.02770", "contents": "Title: Massively parallel implementation and approaches to simulate quantum\n  dynamics using Krylov subspace techniques Abstract: We have developed an application and implemented parallel algorithms in order\nto provide a computational framework suitable for massively parallel\nsupercomputers to study the unitary dynamics of quantum systems. We use\nrenowned parallel libraries such as PETSc/SLEPc combined with high-performance\ncomputing approaches in order to overcome the large memory requirements to be\nable to study systems whose Hilbert space dimension comprises over 9 billion\nindependent quantum states. Moreover, we provide descriptions on the parallel\napproach used for the three most important stages of the simulation: handling\nthe Hilbert subspace basis, constructing a matrix representation for a generic\nHamiltonian operator and the time evolution of the system by means of the\nKrylov subspace methods. We employ our setup to study the evolution of\nquasidisordered and clean many-body systems, focussing on the return\nprobability and related dynamical exponents: the large system sizes accessible\nprovide novel insights into their thermalization properties. \n\n"}
{"id": "1704.02775", "contents": "Title: Scale-Invariant Hidden Local Symmetry, Topology Change and Dense\n  Baryonic Matter II Abstract: Exploiting certain robust topological inputs from the skyrmion description of\ncompressed baryonic matter with a scale-chiral symmetric Lagrangian, we predict\nthe equation of state that is consistent with the properties of nuclear matter\nat the equilibrium density, supports the maximum mass of massive compact star\n$\\sim 2 M_\\odot$ and surprisingly gives the sound velocity close to the\n\"conformal velocity\" $1/\\sqrt{3}$ at densities $\\gtrsim 3 n_0$. At the core of\nthis result is the observation that parity-doubling occurs in the nucleon\nstructure as density goes above $\\sim 2n_0$ with a chiral-singlet mass $m_0\n\\sim (0.6-0.9) m_N$, hinting at a possible up-to-date unsuspected source of\nproton mass and an emergence at high density of scale symmetry and flavor local\nsymmetry, both hidden in the QCD vacuum. \n\n"}
{"id": "1704.02978", "contents": "Title: Field of Groves: An Energy-Efficient Random Forest Abstract: Machine Learning (ML) algorithms, like Convolutional Neural Networks (CNN),\nSupport Vector Machines (SVM), etc. have become widespread and can achieve high\nstatistical performance. However their accuracy decreases significantly in\nenergy-constrained mobile and embedded systems space, where all computations\nneed to be completed under a tight energy budget. In this work, we present a\nfield of groves (FoG) implementation of random forests (RF) that achieves an\naccuracy comparable to CNNs and SVMs under tight energy budgets. Evaluation of\nthe FoG shows that at comparable accuracy it consumes ~1.48x, ~24x, ~2.5x, and\n~34.7x lower energy per classification compared to conventional RF, SVM_RBF ,\nMLP, and CNN, respectively. FoG is ~6.5x less energy efficient than SVM_LR, but\nachieves 18% higher accuracy on average across all considered datasets. \n\n"}
{"id": "1704.03884", "contents": "Title: Made-to-measure modeling of observed galaxy dynamics Abstract: Among dynamical modeling techniques, the made-to-measure (M2M) method for\nmodeling steady-state systems is among the most flexible, allowing\nnon-parametric distribution functions in complex gravitational potentials to be\nmodeled efficiently using N-body particles. Here we propose and test various\nimprovements to the standard M2M method for modeling observed data, illustrated\nusing the simple setup of a one-dimensional harmonic oscillator. We demonstrate\nthat nuisance parameters describing the modeled system's orientation with\nrespect to the observer---e.g., an external galaxy's inclination or the Sun's\nposition in the Milky Way---as well as the parameters of an external\ngravitational field can be optimized simultaneously with the particle weights.\nWe develop a method for sampling from the high-dimensional uncertainty\ndistribution of the particle weights. We combine this in a Gibbs sampler with\nsamplers for the nuisance and potential parameters to explore the uncertainty\ndistribution of the full set of parameters. We illustrate our M2M improvements\nby modeling the vertical density and kinematics of F-type stars in Gaia DR1.\nThe novel M2M method proposed here allows full probabilistic modeling of\nsteady-state dynamical systems, allowing uncertainties on the non-parametric\ndistribution function and on nuisance parameters to be taken into account when\nconstraining the dark and baryonic masses of stellar systems. \n\n"}
{"id": "1704.04499", "contents": "Title: Empirical Determination of Dark Matter Velocities using Metal-Poor Stars Abstract: The Milky Way dark matter halo is formed from the accretion of smaller\nsubhalos. These sub-units also harbor stars---typically old and\nmetal-poor---that are deposited in the Galactic inner regions by disruption\nevents. In this Letter, we show that the dark matter and metal-poor stars in\nthe Solar neighborhood share similar kinematics due to their common origin.\nUsing the high-resolution Eris simulation, which traces the evolution of both\nthe dark matter and baryons in a realistic Milky-Way analog galaxy, we\ndemonstrate that metal-poor stars are indeed effective tracers for the local,\nvirialized dark matter velocity distribution. The local dark matter velocities\ncan therefore be inferred from observations of the stellar halo made by the\nSloan Digital Sky Survey within 4 kpc of the Sun. This empirical distribution\ndiffers from the Standard Halo Model in important ways and suggests that the\nbounds on the spin-independent scattering cross section may be weakened for\ndark matter masses below $\\sim$10 GeV. Data from Gaia will allow us to further\nrefine the expected distribution for the smooth dark matter component, and to\ntest for the presence of local substructure. \n\n"}
{"id": "1704.06004", "contents": "Title: Great Optically Luminous Dropout Research Using Subaru HSC (GOLDRUSH).\n  I. UV Luminosity Functions at $z \\sim 4-7$ Derived with the Half-Million\n  Dropouts on the 100 deg$^2$ Sky Abstract: We study the UV luminosity functions (LFs) at $z\\sim 4$, $5$, $6,$ and $7$\nbased on the deep large-area optical images taken by the Hyper Suprime-Cam\n(HSC) Subaru strategic program (SSP). On the 100 deg$^2$ sky of the HSC SSP\ndata available to date, we make enormous samples consisting of a total of\n579,565 dropout candidates at $z\\sim 4-7$ by the standard color selection\ntechnique, 358 out of which are spectroscopically confirmed by our follow-up\nspectroscopy and other studies. We obtain UV LFs at $z \\sim 4-7$ that span a\nvery wide UV luminosity range of $\\sim 0.002 - 100 \\, L_{\\rm UV}^\\ast$ ($-26 <\nM_{\\rm UV} < -14$ mag) by combining LFs from our program and the ultra-deep\nHubble Space Telescope legacy surveys. We derive three parameters of the\nbest-fit Schechter function, $\\phi^\\ast$, $M_{\\rm UV}^\\ast$, and $\\alpha$, of\nthe UV LFs in the magnitude range where the AGN contribution is negligible, and\nfind that $\\alpha$ and $\\phi^\\ast$ decrease from $z\\sim 4$ to $7$ with no\nsignificant evolution of $M_{\\rm UV}^\\ast$. Because our HSC SSP data bridge the\nLFs of galaxies and AGNs with great statistical accuracy, we carefully\ninvestigate the bright end of the galaxy UV LFs that are estimated by the\nsubtraction of the AGN contribution either aided with spectroscopy or the\nbest-fit AGN UV LFs. We find that the bright end of the galaxy UV LFs cannot be\nexplained by the Schechter function fits at $> 2 \\sigma$ significance, and\nrequire either double power-law functions or modified Schechter functions that\nconsider a magnification bias due to gravitational lensing. \n\n"}
{"id": "1704.06738", "contents": "Title: Towards Distributed Machine Learning in Shared Clusters: A\n  Dynamically-Partitioned Approach Abstract: Many cluster management systems (CMSs) have been proposed to share a single\ncluster with multiple distributed computing systems. However, none of the\nexisting approaches can handle distributed machine learning (ML) workloads\ngiven the following criteria: high resource utilization, fair resource\nallocation and low sharing overhead. To solve this problem, we propose a new\nCMS named Dorm, incorporating a dynamically-partitioned cluster management\nmechanism and an utilization-fairness optimizer. Specifically, Dorm uses the\ncontainer-based virtualization technique to partition a cluster, runs one\napplication per partition, and can dynamically resize each partition at\napplication runtime for resource efficiency and fairness. Each application\ndirectly launches its tasks on the assigned partition without petitioning for\nresources frequently, so Dorm imposes flat sharing overhead. Extensive\nperformance evaluations showed that Dorm could simultaneously increase the\nresource utilization by a factor of up to 2.32, reduce the fairness loss by a\nfactor of up to 1.52, and speed up popular distributed ML applications by a\nfactor of up to 2.72, compared to existing approaches. Dorm's sharing overhead\nis less than 5% in most cases. \n\n"}
{"id": "1705.00059", "contents": "Title: Random dynamical systems generated by coalescing stochastic flows on\n  $\\mathbb{R}$ Abstract: Existence of random dynamical systems for a class of coalescing stochastic\nflows on $\\mathbb{R}$ is proved. A new state space for coalescing flows is\nbuilt. As particular cases coalescing flows of solutions to stochastic\ndifferential equations independent before meeting time and coalescing Harris\nflows are considered. \n\n"}
{"id": "1705.00720", "contents": "Title: Computing Tropical Prevarieties in Parallel Abstract: The computation of the tropical prevariety is the first step in the\napplication of polyhedral methods to compute positive dimensional solution sets\nof polynomial systems. In particular, pretropisms are candidate leading\nexponents for the power series developments of the solutions. The computation\nof the power series may start as soon as one pretropism is available, so our\nparallel computation of the tropical prevariety has an application in a\npipelined solver.\n  We present a parallel implementation of dynamic enumeration. Our first\ndistributed memory implementation with forked processes achieved good speedups,\nbut quite often resulted in large variations in the execution times of the\nprocesses. The shared memory multithreaded version applies work stealing to\nreduce the variability of the run time. Our implementation applies the thread\nsafe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU\nMultiprecision Arithmetic Library (GMP), aided by the fast memory allocations\nof TCMalloc.\n  Our parallel implementation is capable of computing the tropical prevariety\nof the cyclic 16-roots problem. We also report on computational experiments on\nthe $n$-body and $n$-vortex problems; our computational results compare\nfavorably with Gfan. \n\n"}
{"id": "1705.02970", "contents": "Title: TaskUniVerse: A Task-Based Unified Interface for Versatile Parallel\n  Execution Abstract: Task based parallel programming has shown competitive outcomes in many\naspects of parallel programming such as efficiency, performance, productivity\nand scalability. Different approaches are used by different software\ndevelopment frameworks to provide these outcomes to the programmer, while\nmaking the underlying hardware architecture transparent to her. However, since\nprograms are not portable between these frameworks, using one framework or the\nother is still a vital decision by the programmer whose concerns are\nexpandability, adaptivity, maintainability and interoperability of the\nprograms. In this work, we propose a unified programming interface that a\nprogrammer can use for working with different task based parallel frameworks\ntransparently. In this approach we abstract the common concepts of task based\nparallel programming and provide them to the programmer in a single programming\ninterface uniformly for all frameworks. We have tested the interface by running\nprograms which implement matrix operations within frameworks that are optimized\nfor shared and distributed memory architectures and accelerators, while the\ncooperation between frameworks is configured externally with no need to modify\nthe programs. Further possible extensions of the interface and future potential\nresearch are also described. \n\n"}
{"id": "1705.03414", "contents": "Title: A Distributed Learning Dynamics in Social Groups Abstract: We study a distributed learning process observed in human groups and other\nsocial animals. This learning process appears in settings in which each\nindividual in a group is trying to decide over time, in a distributed manner,\nwhich option to select among a shared set of options. Specifically, we consider\na stochastic dynamics in a group in which every individual selects an option in\nthe following two-step process: (1) select a random individual and observe the\noption that individual chose in the previous time step, and (2) adopt that\noption if its stochastic quality was good at that time step. Various\ninstantiations of such distributed learning appear in nature, and have also\nbeen studied in the social science literature. From the perspective of an\nindividual, an attractive feature of this learning process is that it is a\nsimple heuristic that requires extremely limited computational capacities. But\nwhat does it mean for the group -- could such a simple, distributed and\nessentially memoryless process lead the group as a whole to perform optimally?\nWe show that the answer to this question is yes -- this distributed learning is\nhighly effective at identifying the best option and is close to optimal for the\ngroup overall. Our analysis also gives quantitative bounds that show fast\nconvergence of these stochastic dynamics. Prior to our work the only\ntheoretical work related to such learning dynamics has been either in\ndeterministic special cases or in the asymptotic setting. Finally, we observe\nthat our infinite population dynamics is a stochastic variant of the classic\nmultiplicative weights update (MWU) method. Consequently, we arrive at the\nfollowing interesting converse: the learning dynamics on a finite population\nconsidered here can be viewed as a novel distributed and low-memory\nimplementation of the classic MWU method. \n\n"}
{"id": "1705.03501", "contents": "Title: Socially Trusted Collaborative Edge Computing in Ultra Dense Networks Abstract: Small cell base stations (SBSs) endowed with cloud-like computing\ncapabilities are considered as a key enabler of edge computing (EC), which\nprovides ultra-low latency and location-awareness for a variety of emerging\nmobile applications and the Internet of Things. However, due to the limited\ncomputation resources of an individual SBS, providing computation services of\nhigh quality to its users faces significant challenges when it is overloaded\nwith an excessive amount of computation workload. In this paper, we propose\ncollaborative edge computing among SBSs by forming SBS coalitions to share\ncomputation resources with each other, thereby accommodating more computation\nworkload in the edge system and reducing reliance on the remote cloud. A novel\nSBS coalition formation algorithm is developed based on the coalitional game\ntheory to cope with various new challenges in small-cell-based edge systems,\nincluding the co-provisioning of radio access and computing services,\ncooperation incentives, and potential security risks. To address these\nchallenges, the proposed method (1) allows collaboration at both the user-SBS\nassociation stage and the SBS peer offloading stage by exploiting the ultra\ndense deployment of SBSs, (2) develops a payment-based incentive mechanism that\nimplements proportionally fair utility division to form stable SBS coalitions,\nand (3) builds a social trust network for managing security risks among SBSs\ndue to collaboration. Systematic simulations in practical scenarios are carried\nout to evaluate the efficacy and performance of the proposed method, which\nshows that tremendous edge computing performance improvement can be achieved. \n\n"}
{"id": "1705.03808", "contents": "Title: Physical properties and evolutionary status of the W-subtype contact\n  binary V502 Oph with a stellar companion Abstract: Multi-color ($B$ $V$ $R_c$ $I_c$) CCD photometric light curves of the contact\nbinary V502 Oph are analyzed using the Wilson-Devinney (W-D) program. The\nsolutions reveal that V502 Oph is a W-subtype contact ($f = 35.3\\,\\%$) binary\nsystem. The temperature difference between its two components is $240K$ and the\nmore massive star has a lower surface temperature. A cool spot is added in our\nmodel to account for the light curves' asymmetry (O'Connell effect) and third\nlight is detected for the first time in the light curves' modeling. Combining\nthe orbital inclination ($i = 76.4^{\\circ}$) with the published mass function\nof V502 Oph, the absolute physical parameters of the two components are\ndetermined, which are $M_1= 0.46(\\pm0.02)M_\\odot, M_2=1.37(\\pm0.02)M_\\odot,\nR_1=0.94(\\pm0.01)R_\\odot, R_2=1.51(\\pm0.01)R_\\odot, L_1=1.13(\\pm0.02)L_\\odot$\nand $L_2=2.49(\\pm0.03)L_\\odot$. The formation and evolutionary status of V502\nOph are discussed. All photoelectric and CCD times of light minimum about V502\nOph are gathered and its orbital period variations are analyzed. The results\nshow that the orbital period of V502 Oph is decreasing continuously at a rate\nof $dP/dt=-1.69\\times{10^{-7}}day\\cdot year^{-1}$, which corresponds to a\nconservative mass transfer rate of\n$\\frac{dM_{2}}{dt}=-3.01\\times{10^{-8}}M_\\odot/year$. The light-travel time\neffect (LTTE) is due to the presence of a close-in tertiary component with a\nperiod of $P_3=18.7$ years and an amplitute of 0.00402days. V502 Oph is an\nideal target to test the formation and evolution theories of binary and\nmultiple systems in which the light curves, $O - C$ curve and spectroscopic\nobservations are comprehensively researched. \n\n"}
{"id": "1705.04374", "contents": "Title: Optimal fidelity multi-level Monte Carlo for quantification of\n  uncertainty in simulations of cloud cavitation collapse Abstract: We quantify uncertainties in the location and magnitude of extreme pressure\nspots revealed from large scale multi-phase flow simulations of cloud\ncavitation collapse. We examine clouds containing 500 cavities and quantify\nuncertainties related to their initial spatial arrangement. The resulting\n2000-dimensional space is sampled using a non-intrusive and computationally\nefficient Multi-Level Monte Carlo (MLMC) methodology. We introduce novel\noptimal control variate coefficients to enhance the variance reduction in MLMC.\nThe proposed optimal fidelity MLMC leads to more than two orders of magnitude\nspeedup when compared to standard Monte Carlo methods. We identify large\nuncertainties in the location and magnitude of the peak pressure pulse and\npresent its statistical correlations and joint probability density functions\nwith the geometrical characteristics of the cloud. Characteristic properties of\nspatial cloud structure are identified as potential causes of significant\nuncertainties in exerted collapse pressures. \n\n"}
{"id": "1705.05491", "contents": "Title: Distributed Statistical Machine Learning in Adversarial Settings:\n  Byzantine Gradient Descent Abstract: We consider the problem of distributed statistical machine learning in\nadversarial settings, where some unknown and time-varying subset of working\nmachines may be compromised and behave arbitrarily to prevent an accurate model\nfrom being learned. This setting captures the potential adversarial attacks\nfaced by Federated Learning -- a modern machine learning paradigm that is\nproposed by Google researchers and has been intensively studied for ensuring\nuser privacy. Formally, we focus on a distributed system consisting of a\nparameter server and $m$ working machines. Each working machine keeps $N/m$\ndata samples, where $N$ is the total number of samples. The goal is to\ncollectively learn the underlying true model parameter of dimension $d$.\n  In classical batch gradient descent methods, the gradients reported to the\nserver by the working machines are aggregated via simple averaging, which is\nvulnerable to a single Byzantine failure. In this paper, we propose a Byzantine\ngradient descent method based on the geometric median of means of the\ngradients. We show that our method can tolerate $q \\le (m-1)/2$ Byzantine\nfailures, and the parameter estimate converges in $O(\\log N)$ rounds with an\nestimation error of $\\sqrt{d(2q+1)/N}$, hence approaching the optimal error\nrate $\\sqrt{d/N}$ in the centralized and failure-free setting. The total\ncomputational complexity of our algorithm is of $O((Nd/m) \\log N)$ at each\nworking machine and $O(md + kd \\log^3 N)$ at the central server, and the total\ncommunication cost is of $O(m d \\log N)$. We further provide an application of\nour general results to the linear regression problem.\n  A key challenge arises in the above problem is that Byzantine failures create\narbitrary and unspecified dependency among the iterations and the aggregated\ngradients. We prove that the aggregated gradient converges uniformly to the\ntrue gradient function. \n\n"}
{"id": "1705.05646", "contents": "Title: Quadratic and Near-Quadratic Lower Bounds for the CONGEST Model Abstract: We present the first super-linear lower bounds for natural graph problems in\nthe CONGEST model, answering a long-standing open question.\n  Specifically, we show that any exact computation of a minimum vertex cover or\na maximum independent set requires $\\Omega(n^2/\\log^2{n})$ rounds in the worst\ncase in the CONGEST model, as well as any algorithm for $\\chi$-coloring a\ngraph, where $\\chi$ is the chromatic number of the graph. We further show that\nsuch strong lower bounds are not limited to NP-hard problems, by showing two\nsimple graph problems in P which require a quadratic and near-quadratic number\nof rounds.\n  Finally, we address the problem of computing an exact solution to weighted\nall-pairs-shortest-paths (APSP), which arguably may be considered as a\ncandidate for having a super-linear lower bound. We show a simple $\\Omega(n)$\nlower bound for this problem, which implies a separation between the weighted\nand unweighted cases, since the latter is known to have a complexity of\n$\\Theta(n/\\log{n})$. We also formally prove that the standard Alice-Bob\nframework is incapable of providing a super-linear lower bound for exact\nweighted APSP, whose complexity remains an intriguing open question. \n\n"}
{"id": "1705.05839", "contents": "Title: Gauge-Transformation Properties of Cosmological Observables and its\n  Application to the Light-Cone Average Abstract: Theoretical descriptions of observable quantities in cosmological\nperturbation theory should be independent of coordinate systems. This statement\nis often referred to as gauge-invariance of observable quantities, and the\nsanity of their theoretical description is verified by checking its\ngauge-invariance. We argue that cosmological observables are invariant scalars\nunder diffeomorphisms and as a consequence their theoretical description is\ngauge-invariant, only at linear order in perturbations. Beyond linear order,\nthey are usually not gauge-invariant, and we provide the general law for the\ngauge-transformation that the perturbation part of an observable does obey. We\napply this finding to derive the second-order expression for the observational\nlight-cone average in cosmology and demonstrate that our expression is indeed\ninvariant under diffeomorphisms. \n\n"}
{"id": "1705.06215", "contents": "Title: Mixing MACs: An Introduction to Hybrid Radio Wireless Virtualization Abstract: This study presents the design of the hybrid wireless virtualization HWV\ncontroller based network architecture. Using a HWV controller, an unified\napproach can be taken for provisioning and management of virtualized\nheterogeneous radios, irrespective of their MAC and PHY layer mechanisms. It is\nshown that the airtime occupancy by transmissions from different slices or\ngroups can be used as a single metric for tying these virtualized platforms.\nThe HWV controller can account and dynamically reprovision slice quotas, which\ncan be used for maximizing the revenue of the network operator or aggregate\nsystem throughput performance. Results from simulations show that an HWV\ncontroller based infrastructure is able to improve the revenue generated from a\nsingle virtualized basestation and an AP by up to 40 percent under tested\nconditions. \n\n"}
{"id": "1705.07861", "contents": "Title: Symmetry Breaking in the Congest Model: Time- and Message-Efficient\n  Algorithms for Ruling Sets Abstract: We study local symmetry breaking problems in the CONGEST model, focusing on\nruling set problems, which generalize the fundamental Maximal Independent Set\n(MIS) problem. A $\\beta$-ruling set is an independent set such that every node\nin the graph is at most $\\beta$ hops from a node in the independent set. Our\nwork is motivated by the following central question: can we break the\n$\\Theta(\\log n)$ time complexity barrier and the $\\Theta(m)$ message complexity\nbarrier in the CONGEST model for MIS or closely-related symmetry breaking\nproblems? We present the following results:\n  - Time Complexity: We show that we can break the $O(\\log n)$ \"barrier\" for 2-\nand 3-ruling sets. We compute 3-ruling sets in $O\\left(\\frac{\\log n}{\\log \\log\nn}\\right)$ rounds with high probability (whp). More generally we show that\n2-ruling sets can be computed in $O\\left(\\log \\Delta \\cdot (\\log n)^{1/2 +\n\\varepsilon} + \\frac{\\log n}{\\log\\log n}\\right)$ rounds for any $\\varepsilon >\n0$, which is $o(\\log n)$ for a wide range of $\\Delta$ values (e.g., $\\Delta =\n2^{(\\log n)^{1/2-\\varepsilon}}$). These are the first 2- and 3-ruling set\nalgorithms to improve over the $O(\\log n)$-round complexity of Luby's algorithm\nin the CONGEST model.\n  - Message Complexity: We show an $\\Omega(n^2)$ lower bound on the message\ncomplexity of computing an MIS (i.e., 1-ruling set) which holds also for\nrandomized algorithms and present a contrast to this by showing a randomized\nalgorithm for 2-ruling sets that, whp, uses only $O(n \\log^2 n)$ messages and\nruns in $O(\\Delta \\log n)$ rounds. This is the first message-efficient\nalgorithm known for ruling sets, which has message complexity nearly linear in\n$n$ (which is optimal up to a polylogarithmic factor). \n\n"}
{"id": "1705.07947", "contents": "Title: Semiclassical theory of spin-orbit torques in disordered multiband\n  electron systems Abstract: We study spin-orbit torques (SOT) in non-degenerate multiband electron\nsystems in the weak disorder limit. In order to have better physical\ntransparency a semiclassical Boltzmann approach equivalent to the Kubo\ndiagrammatic approach in the non-crossing approximation is formulated. This\nsemiclassical framework accounts for the interband- coherence effects induced\nby both the electric field and static impurity scattering. Using the\ntwo-dimensional Rashba ferromagnet as a model system, we show that the\nantidamping-like SOT arising from disorder-induced interband-coherence effects\nis very sensitive to the spin structure of disorder and may have the same sign\nas the intrinsic SOT in the presence of spin-dependent disorder. While the\ncancellation of this SOT and the intrinsic one occurs only in the case of\nspin-independent short-range disorder. \n\n"}
{"id": "1705.10387", "contents": "Title: Tiny Groups Tackle Byzantine Adversaries Abstract: A popular technique for tolerating malicious faults in open distributed\nsystems is to establish small groups of participants, each of which has a\nnon-faulty majority. These groups are used as building blocks to design\nattack-resistant algorithms.\n  Despite over a decade of active research, current constructions require group\nsizes of $O(\\log n)$, where $n$ is the number of participants in the system.\nThis group size is important since communication and state costs scale\npolynomially with this parameter. Given the stubbornness of this logarithmic\nbarrier, a natural question is whether better bounds are possible.\n  Here, we consider an attacker that controls a constant fraction of the total\ncomputational resources in the system. By leveraging proof-of-work (PoW), we\ndemonstrate how to reduce the group size exponentially to $O(\\log\\log n)$ while\nmaintaining strong security guarantees. This reduction in group size yields a\nsignificant improvement in communication and state costs. \n\n"}
{"id": "1705.10554", "contents": "Title: Virtual Function Placement for Service Chaining with Partial Orders and\n  Anti-Affinity Rules Abstract: Software Defined Networking and Network Function Virtualization are two\nparadigms that offer flexible software-based network management. Service\nproviders are instantiating Virtualized Network Functions - e.g., firewalls,\nDPIs, gateways - to highly facilitate the deployment and reconfiguration of\nnetwork services with reduced time-to-value. They employ Service Function\nChaining technologies to dynamically reconfigure network paths traversing\nphysical and virtual network functions. Providing a cost-efficient virtual\nfunction deployment over the network for a set of service chains is a key\ntechnical challenge for service providers, and this problem has recently caught\nmuch attention from both Industry and Academia. In this paper, we propose a\nformulation of this problem as an Integer Linear Program that allows one to\nfind the best feasible paths and virtual function placement for a set of\nservices with respect to a total financial cost, while taking into account the\n(total or partial) order constraints for Service Function Chains of each\nservice and other constraints such as end-to-end latency, anti-affinity rules\nbetween network functions on the same physical node and resource limitations in\nterms of network and processing capacities. Furthermore, we propose a heuristic\nalgorithm based on a linear relaxation of the problem that performs close to\noptimum for large scale instances. \n\n"}
{"id": "1705.10591", "contents": "Title: Optimizing Memory Efficiency for Convolution Kernels on Kepler GPUs Abstract: Convolution is a fundamental operation in many applications, such as computer\nvision, natural language processing, image processing, etc. Recent successes of\nconvolutional neural networks in various deep learning applications put even\nhigher demand on fast convolution. The high computation throughput and memory\nbandwidth of graphics processing units (GPUs) make GPUs a natural choice for\naccelerating convolution operations. However, maximally exploiting the\navailable memory bandwidth of GPUs for convolution is a challenging task. This\npaper introduces a general model to address the mismatch between the memory\nbank width of GPUs and computation data width of threads. Based on this model,\nwe develop two convolution kernels, one for the general case and the other for\na special case with one input channel. By carefully optimizing memory access\npatterns and computation patterns, we design a communication-optimized kernel\nfor the special case and a communication-reduced kernel for the general case.\nExperimental data based on implementations on Kepler GPUs show that our kernels\nachieve 5.16X and 35.5% average performance improvement over the latest cuDNN\nlibrary, for the special case and the general case, respectively. \n\n"}
{"id": "1706.04235", "contents": "Title: A Hybrid Observer for a Distributed Linear System with a Changing\n  Neighbor Graph Abstract: A hybrid observer is described for estimating the state of an $m>0$ channel,\n$n$-dimensional, continuous-time, distributed linear system of the form\n$\\dot{x} = Ax,\\;y_i = C_ix,\\;i\\in\\{1,2,\\ldots, m\\}$. The system's state $x$ is\nsimultaneously estimated by $m$ agents assuming each agent $i$ senses $y_i$ and\nreceives appropriately defined data from each of its current neighbors.\nNeighbor relations are characterized by a time-varying directed graph\n$\\mathbb{N}(t)$ whose vertices correspond to agents and whose arcs depict\nneighbor relations. Agent $i$ updates its estimate $x_i$ of $x$ at \"event\ntimes\" $t_1,t_2,\\ldots $ using a local observer and a local parameter\nestimator. The local observer is a continuous time linear system whose input is\n$y_i$ and whose output $w_i$ is an asymptotically correct estimate of $L_ix$\nwhere $L_i$ a matrix with kernel equaling the unobservable space of $(C_i,A)$.\nThe local parameter estimator is a recursive algorithm designed to estimate,\nprior to each event time $t_j$, a constant parameter $p_j$ which satisfies the\nlinear equations $w_k(t_j-\\tau) =\nL_kp_j+\\mu_k(t_j-\\tau),\\;k\\in\\{1,2,\\ldots,m\\}$, where $\\tau$ is a small\npositive constant and $\\mu_k$ is the state estimation error of local observer\n$k$. Agent $i$ accomplishes this by iterating its parameter estimator state\n$z_i$, $q$ times within the interval $[t_j-\\tau, t_j)$, and by making use of\nthe state of each of its neighbors' parameter estimators at each iteration. The\nupdated value of $x_i$ at event time $t_j$ is then $x_i(t_j) =\ne^{A\\tau}z_i(q)$. Subject to the assumptions that (i) the neighbor graph\n$\\mathbb{N}(t)$ is strongly connected for all time, (ii) the system whose state\nis to be estimated is jointly observable, (iii) $q$ is sufficiently large, it\nis shown that each estimate $x_i$ converges to $x$ exponentially fast as\n$t\\rightarrow \\infty$ at a rate which can be controlled. \n\n"}
{"id": "1706.04937", "contents": "Title: Entropy inequalities for factors of IID Abstract: This paper is concerned with certain invariant random processes (called\nfactors of IID) on infinite trees. Given such a process, one can assign\nentropies to different finite subgraphs of the tree. There are linear\ninequalities between these entropies that hold for any factor of IID process\n(e.g. \"edge versus vertex\" or \"star versus edge\"). These inequalities turned\nout to be very useful: they have several applications already, the most recent\none is the Backhausz-Szegedy result on the eigenvectors of random regular\ngraphs.\n  We present new entropy inequalities in this paper. In fact, our approach\nprovides a general \"recipe\" for how to find and prove such inequalities. Our\nkey tool is a generalization of the edge-vertex inequality for a broader class\nof factor processes with fewer symmetries. \n\n"}
{"id": "1706.07191", "contents": "Title: High-Performance Out-of-core Block Randomized Singular Value\n  Decomposition on GPU Abstract: Fast computation of singular value decomposition (SVD) is of great interest\nin various machine learning tasks. Recently, SVD methods based on randomized\nlinear algebra have shown significant speedup in this regime. This paper\nattempts to further accelerate the computation by harnessing a modern computing\narchitecture, namely graphics processing unit (GPU), with the goal of\nprocessing large-scale data that may not fit in the GPU memory. It leads to a\nnew block randomized algorithm that fully utilizes the power of GPUs and\nefficiently processes large-scale data in an out-of- core fashion. Our\nexperiment shows that the proposed block randomized SVD (BRSVD) method\noutperforms existing randomized SVD methods in terms of speed with retaining\nthe same accuracy. We also show its application to convex robust principal\ncomponent analysis, which shows significant speedup in computer vision\napplications. \n\n"}
{"id": "1707.01714", "contents": "Title: On recurrence of the multidimensional Lindley process Abstract: A Lindley process arises from classical studies in queueing theory and it\nusually reflects waiting times of customers in single server models. In this\nnote we study recurrence of its higher dimensional counterpart under some mild\nassumptions on the tail behaviour of the underlying random walk. There are\nseveral links between the Lindley process and the associated random walk and we\nbuild upon such relations. We apply a method related to discrete subordination\nfor random walks on the integer lattice together with various facts from the\ntheory of fluctuations of random walks. \n\n"}
{"id": "1707.01873", "contents": "Title: Blockchain Consensus Protocols in the Wild Abstract: A blockchain is a distributed ledger for recording transactions, maintained\nby many nodes without central authority through a distributed cryptographic\nprotocol. All nodes validate the information to be appended to the blockchain,\nand a consensus protocol ensures that the nodes agree on a unique order in\nwhich entries are appended. Consensus protocols for tolerating Byzantine faults\nhave received renewed attention because they also address blockchain systems.\nThis work discusses the process of assessing and gaining confidence in the\nresilience of a consensus protocols exposed to faults and adversarial nodes. We\nadvocate to follow the established practice in cryptography and computer\nsecurity, relying on public reviews, detailed models, and formal proofs; the\ndesigners of several practical systems appear to be unaware of this. Moreover,\nwe review the consensus protocols in some prominent permissioned blockchain\nplatforms with respect to their fault models and resilience against attacks.\nThe protocol comparison covers Hyperledger Fabric, Tendermint, Symbiont,\nR3~Corda, Iroha, Kadena, Chain, Quorum, MultiChain, Sawtooth Lake, Ripple,\nStellar, and IOTA. \n\n"}
{"id": "1707.04618", "contents": "Title: Communication Lower Bounds of Bilinear Algorithms for Symmetric Tensor\n  Contractions Abstract: We introduce a new theoretical framework for deriving lower bounds on data\nmovement in bilinear algorithms. Bilinear algorithms are a general\nrepresentation of fast algorithms for bilinear functions, which include\ncomputation of matrix multiplication, convolution, and symmetric tensor\ncontractions. A bilinear algorithm is described by three matrices. Our\ncommunication lower bounds are based on quantifying the minimal matrix ranks of\nmatching subsets of columns of these matrices. This infrastructure yields new\ncommunication lower bounds for symmetric tensor contraction algorithms, which\nprovide qualitative new insights. Tensor symmetry (invariance under permutation\nof modes) is common to many applications of tensor computations (e.g., tensor\nrepresentation of hypergraphs, analysis of high order moments in data, as well\nas tensors modelling interactions of electrons in computational chemistry).\nTensor symmetry enables reduction in representation size as well as arithmetic\ncost of contractions by factors that scale with the number of equivalent\npermutations. However, we derive lower bounds showing that these arithmetic\ncost and memory reductions can necessitate increases in data movement by\nfactors that scale with the size of the tensors. \n\n"}
{"id": "1707.07452", "contents": "Title: Next Generation Cloud Computing: New Trends and Research Directions Abstract: The landscape of cloud computing has significantly changed over the last\ndecade. Not only have more providers and service offerings crowded the space,\nbut also cloud infrastructure that was traditionally limited to single provider\ndata centers is now evolving. In this paper, we firstly discuss the changing\ncloud infrastructure and consider the use of infrastructure from multiple\nproviders and the benefit of decentralising computing away from data centers.\nThese trends have resulted in the need for a variety of new computing\narchitectures that will be offered by future cloud infrastructure. These\narchitectures are anticipated to impact areas, such as connecting people and\ndevices, data-intensive computing, the service space and self-learning systems.\nFinally, we lay out a roadmap of challenges that will need to be addressed for\nrealising the potential of next generation cloud systems. \n\n"}
{"id": "1707.08484", "contents": "Title: MST in O(1) Rounds of the Congested Clique Abstract: We present a distributed randomized algorithm finding Minimum Spanning Tree\n(MST) of a given graph in O(1) rounds, with high probability, in the Congested\nClique model. The input graph in the Congested Clique model is a graph of n\nnodes, where each node initially knows only its incident edges. The\ncommunication graph is a clique with limited edge bandwidth: each two nodes\n(not necessarily neighbours in the input graph) can exchange $O(\\log n)$ bits.\n  As in previous works, the key part of the MST algorithm is an efficient\nConnected Components (CC) algorithm. However, unlike the former approaches, we\ndo not aim at simulating the standard Boruvka algorithm, at least at initial\nstages of the CC algorithm. Instead, we develop a new technique which combines\nconnected components of sample sparse subgraphs of the input graph in order to\naccelerate the process of uncovering connected components of the original input\ngraph. More specifically, we develop a sparsification technique which reduces\nan initial CC problem in $O(1)$ rounds to its two restricted instances. The\nformer instance has a graph with maximal degree $O(\\log \\log n)$ as the input\n-- here our sample-combining technique helps. In the latter instance, a\npartition of the input graph into $O(n/\\log \\log n)$ connected components is\nknown. This gives an opportunity to apply previous algorithms to determine\nconnected components in $O(1)$ rounds.\n  Our result addresses the problem from and the $O(\\log \\log n)$ algorithm of\nLotker et al. [SPAA 2003; SICOMP 2005], improves over previous $O(\\log* n)$\nalgorithm of Ghaffari et al. [PODC 2016] and $O(\\log \\log \\log n)$ algorithm of\nHegeman et al. [PODC 2015] . It also determines $\\Theta(1)$ round complexity in\nthe congested clique for MST, as well as other graph problems, including\nbipartiteness, cut verification, s-t connectivity and cycle containment. \n\n"}
{"id": "1708.00898", "contents": "Title: Seating Assignment Using Constrained Signed Spectral Clustering Abstract: In this paper, we present a novel method for constrained cluster size signed\nspectral clustering which allows us to subdivide large groups of people based\non their relationships. In general, signed clustering only requires K hard\nclusters and does not constrain the cluster sizes. We extend signed clustering\nto include cluster size constraints. Using an example of seating assignment, we\nefficiently find groups of people with high social affinity while mitigating\nawkward social interaction between people who dislike each other. \n\n"}
{"id": "1708.01285", "contents": "Title: Proof of Work Without All the Work: Computationally Efficient\n  Attack-Resistant Systems Abstract: Proof-of-work (PoW) is an algorithmic tool used to secure networks by\nimposing a computational cost on participating devices. Unfortunately,\ntraditional PoW schemes require that correct devices perform computational work\nperpetually, even when the system is not under attack.\n  We address this issue by designing a general PoW protocol that ensures two\nproperties. First, the network stays secure. In particular, the fraction of\nidentities in the system that are controlled by an attacker is always less than\n1/2. Second, our protocol's computational cost is commensurate with the cost of\nan attacker. In particular, the total computational cost of correct devices is\na linear function of the attacker's computational cost plus the number of\ncorrect devices that have joined the system. Consequently, if the network is\nattacked, we ensure security with cost that grows linearly with the attacker's\ncost; and, in the absence of attack, our computational cost remains small. We\nprove similar guarantees for bandwidth cost.\n  Our results hold in a dynamic, decentralized system where participants join\nand depart over time, and where the total computational power of the attacker\nis up to a constant fraction of the total computational power of correct\ndevices. We demonstrate how to leverage our results to address important\nsecurity problems in distributed computing including: Sybil attacks, Byzantine\nconsensus, and Committee election. \n\n"}
{"id": "1708.02188", "contents": "Title: PowerAI DDL Abstract: As deep neural networks become more complex and input datasets grow larger,\nit can take days or even weeks to train a deep neural network to the desired\naccuracy. Therefore, distributed Deep Learning at a massive scale is a critical\ncapability, since it offers the potential to reduce the training time from\nweeks to hours. In this paper, we present a software-hardware co-optimized\ndistributed Deep Learning system that can achieve near-linear scaling up to\nhundreds of GPUs. The core algorithm is a multi-ring communication pattern that\nprovides a good tradeoff between latency and bandwidth and adapts to a variety\nof system configurations. The communication algorithm is implemented as a\nlibrary for easy use. This library has been integrated into Tensorflow, Caffe,\nand Torch. We train Resnet-101 on Imagenet 22K with 64 IBM Power8 S822LC\nservers (256 GPUs) in about 7 hours to an accuracy of 33.8 % validation\naccuracy. Microsoft's ADAM and Google's DistBelief results did not reach 30 %\nvalidation accuracy for Imagenet 22K. Compared to Facebook AI Research's recent\npaper on 256 GPU training, we use a different communication algorithm, and our\ncombined software and hardware system offers better communication overhead for\nResnet-50. A PowerAI DDL enabled version of Torch completed 90 epochs of\ntraining on Resnet 50 for 1K classes in 50 minutes using 64 IBM Power8 S822LC\nservers (256 GPUs). \n\n"}
{"id": "1708.02983", "contents": "Title: Scaling Deep Learning on GPU and Knights Landing clusters Abstract: The speed of deep neural networks training has become a big bottleneck of\ndeep learning research and development. For example, training GoogleNet by\nImageNet dataset on one Nvidia K20 GPU needs 21 days. To speed up the training\nprocess, the current deep learning systems heavily rely on the hardware\naccelerators. However, these accelerators have limited on-chip memory compared\nwith CPUs. To handle large datasets, they need to fetch data from either CPU\nmemory or remote processors. We use both self-hosted Intel Knights Landing\n(KNL) clusters and multi-GPU clusters as our target platforms. From an\nalgorithm aspect, current distributed machine learning systems are mainly\ndesigned for cloud systems. These methods are asynchronous because of the slow\nnetwork and high fault-tolerance requirement on cloud systems. We focus on\nElastic Averaging SGD (EASGD) to design algorithms for HPC clusters. Original\nEASGD used round-robin method for communication and updating. The communication\nis ordered by the machine rank ID, which is inefficient on HPC clusters.\n  First, we redesign four efficient algorithms for HPC systems to improve\nEASGD's poor scaling on clusters. Async EASGD, Async MEASGD, and Hogwild EASGD\nare faster \\textcolor{black}{than} their existing counterparts (Async SGD,\nAsync MSGD, and Hogwild SGD, resp.) in all the comparisons. Finally, we design\nSync EASGD, which ties for the best performance among all the methods while\nbeing deterministic. In addition to the algorithmic improvements, we use some\nsystem-algorithm codesign techniques to scale up the algorithms. By reducing\nthe percentage of communication from 87% to 14%, our Sync EASGD achieves 5.3x\nspeedup over original EASGD on the same platform. We get 91.5% weak scaling\nefficiency on 4253 KNL cores, which is higher than the state-of-the-art\nimplementation. \n\n"}
{"id": "1708.03389", "contents": "Title: A Logical Approach to Cloud Federation Abstract: Federated clouds raise a variety of challenges for managing identity,\nresource access, naming, connectivity, and object access control. This paper\nshows how to address these challenges in a comprehensive and uniform way using\na data-centric approach. The foundation of our approach is a trust logic in\nwhich participants issue authenticated statements about principals, objects,\nattributes, and relationships in a logic language, with reasoning based on\ndeclarative policy rules. We show how to use the logic to implement a trust\ninfrastructure for cloud federation that extends the model of NSF GENI, a\nfederated IaaS testbed. It captures shared identity management, GENI authority\nservices, cross-site interconnection using L2 circuits, and a naming and access\ncontrol system similar to AWS Identity and Access Management (IAM), but\nextended to a federated system without central control. \n\n"}
{"id": "1708.06127", "contents": "Title: Practical Minimum Cut Algorithms Abstract: The minimum cut problem for an undirected edge-weighted graph asks us to\ndivide its set of nodes into two blocks while minimizing the weight sum of the\ncut edges. Here, we introduce a linear-time algorithm to compute near-minimum\ncuts. Our algorithm is based on cluster contraction using label propagation and\nPadberg and Rinaldi's contraction heuristics [SIAM Review, 1991]. We give both\nsequential and shared-memory parallel implementations of our algorithm.\nExtensive experiments on both real-world and generated instances show that our\nalgorithm finds the optimal cut on nearly all instances significantly faster\nthan other state-of-the-art algorithms while our error rate is lower than that\nof other heuristic algorithms. In addition, our parallel algorithm shows good\nscalability. \n\n"}
{"id": "1708.06248", "contents": "Title: GraphR: Accelerating Graph Processing Using ReRAM Abstract: This paper presents GRAPHR, the first ReRAM-based graph processing\naccelerator. GRAPHR follows the principle of near-data processing and explores\nthe opportunity of performing massive parallel analog operations with low\nhardware and energy cost. The analog computation is suit- able for graph\nprocessing because: 1) The algorithms are iterative and could inherently\ntolerate the imprecision; 2) Both probability calculation (e.g., PageRank and\nCollaborative Filtering) and typical graph algorithms involving integers (e.g.,\nBFS/SSSP) are resilient to errors. The key insight of GRAPHR is that if a\nvertex program of a graph algorithm can be expressed in sparse matrix vector\nmultiplication (SpMV), it can be efficiently performed by ReRAM crossbar. We\nshow that this assumption is generally true for a large set of graph\nalgorithms. GRAPHR is a novel accelerator architecture consisting of two\ncomponents: memory ReRAM and graph engine (GE). The core graph computations are\nperformed in sparse matrix format in GEs (ReRAM crossbars). The\nvector/matrix-based graph computation is not new, but ReRAM offers the unique\nopportunity to realize the massive parallelism with unprecedented energy\nefficiency and low hardware cost. With small subgraphs processed by GEs, the\ngain of performing parallel operations overshadows the wastes due to sparsity.\nThe experiment results show that GRAPHR achieves a 16.01x (up to 132.67x)\nspeedup and a 33.82x energy saving on geometric mean compared to a CPU baseline\nsystem. Com- pared to GPU, GRAPHR achieves 1.69x to 2.19x speedup and consumes\n4.77x to 8.91x less energy. GRAPHR gains a speedup of 1.16x to 4.12x, and is\n3.67x to 10.96x more energy efficiency compared to PIM-based architecture. \n\n"}
{"id": "1708.06566", "contents": "Title: Increased Fluorescence of PbS Quantum Dots in Photonic Crystals by\n  Excitation Enhancement Abstract: We report on enhanced fluorescence of lead sulfide quantum dots interacting\nwith leaky modes of slab-type silicon photonic crystals. The photonic crystal\nslabs were fabricated supporting leaky modes in the near infrared wavelength\nrange. Lead sulfite quantum dots which are resonant the same spectral range\nwere prepared in a thin layer above the slab. We selectively excited the leaky\nmodes by tuning wavelength and angle of incidence of the laser source and\nmeasured distinct resonances of enhanced fluorescence. By an appropriate\nexperiment design, we ruled out directional light extraction effects and\ndetermined the impact of enhanced excitation. Three-dimensional numerical\nsimulations consistently explain the experimental findings by strong near-field\nenhancements in the vicinity of the photonic crystal surface. Our study\nprovides a basis for systematic tailoring of photonic crystals used in\nbiological applications such as biosensing and single molecule detection, as\nwell as quantum dot solar cells and spectral conversion applications. \n\n"}
{"id": "1708.07013", "contents": "Title: Characterization of the sub-micrometer hierarchy levels in the\n  twist-bend nematic phase with nanometric helices via photopolymerization.\n  Explanation for the sign reversal in the polar response Abstract: Photo-polymerization of a reactive mesogen mixed with a mesogenic dimer,\nshown to exhibit the twist-bend nematic phase ($N_{TB}$), reveals the complex\nstructure of the self-deformation patterns observed in planar cells. The\npolymerized reactive mesogen retains the structure formed by liquid crystalline\nmolecules in the twist bend phase, thus enabling observation by Scanning\nElectron Microscope (SEM). Hierarchical ordering scales from tens of nanometers\nto micrometers are imaged in detail. Submicron features, anticipated from\nearlier X-ray experiments, are visualized directly. In the self-deformation\nstripes formed in the $N_{TB}$ phase, the average director field is found\ntilted in the cell plane by an angle of up to 45$^{\\circ}$ from the cell\nrubbing direction. This tilting explains the sign inversion being observed in\nthe electro-optical studies. \n\n"}
{"id": "1708.07704", "contents": "Title: Extragalactic source population studies at very high energies in the\n  Cherenkov Telescope Array era Abstract: The Cherenkov Telescope Array (CTA) is the next generation ground-based\n$\\gamma$-ray observatory. It will provide an order of magnitude better\nsensitivity and an extended energy coverage, 20 GeV - 300 TeV, relative to\ncurrent Imaging Atmospheric Cherenkov Telescopes (IACTs). IACTs, despite\nfeaturing an excellent sensitivity, are characterized by a limited field of\nview that makes the blind search of new sources very time inefficient.\nFortunately, the $\\textit{Fermi}$-LAT collaboration recently released a new\ncatalog of 1,556 sources detected in the 10 GeV - 2 TeV range by the Large Area\nTelescope (LAT) in the first 7 years of its operation (the 3FHL catalog). This\ncatalog is currently the most appropriate description of the sky that will be\nenergetically accessible to CTA. Here, we discuss a detailed analysis of the\nextragalactic source population (mostly blazars) that will be studied in the\nnear future by CTA. This analysis is based on simulations built from the\nexpected array configurations and information reported in the 3FHL catalog.\nThese results show the improvements that CTA will provide on the extragalactic\nTeV source population studies, which will be carried out by Key Science\nProjects as well as dedicated proposals. \n\n"}
{"id": "1708.08810", "contents": "Title: Computation Rate Maximization for Wireless Powered Mobile-Edge Computing\n  with Binary Computation Offloading Abstract: In this paper, we consider a multi-user mobile edge computing (MEC) network\npowered by wireless power transfer (WPT), where each energy-harvesting WD\nfollows a binary computation offloading policy, i.e., data set of a task has to\nbe executed as a whole either locally or remotely at the MEC server via task\noffloading. In particular, we are interested in maximizing the (weighted) sum\ncomputation rate of all the WDs in the network by jointly optimizing the\nindividual computing mode selection (i.e., local computing or offloading) and\nthe system transmission time allocation (on WPT and task offloading). The major\ndifficulty lies in the combinatorial nature of multi-user computing mode\nselection and its strong coupling with transmission time allocation. To tackle\nthis problem, we first consider a decoupled optimization, where we assume that\nthe mode selection is given and propose a simple bi-section search algorithm to\nobtain the conditional optimal time allocation. On top of that, a coordinate\ndescent method is devised to optimize the mode selection. The method is simple\nin implementation but may suffer from high computational complexity in a\nlarge-size network. To address this problem, we further propose a joint\noptimization method based on the ADMM (alternating direction method of\nmultipliers) decomposition technique, which enjoys much slower increase of\ncomputational complexity as the networks size increases. Extensive simulations\nshow that both the proposed methods can efficiently achieve near-optimal\nperformance under various network setups, and significantly outperform the\nother representative benchmark methods considered. \n\n"}
{"id": "1708.09138", "contents": "Title: Cellular Network Architectures for the Society in Motion Abstract: Due to rising mobility worldwide, a growing number of people utilizes\ncellular network services while on the move. Persistent urbanization trends\nraise the number of daily commuters, leading to a situation where\ntelecommunication requirements are mainly dictated by two categories of users:\n1) Static users inside buildings, demanding instantaneous and virtually\nbandwidth unlimited access to the Internet and Cloud services; 2) moving users\noutside, expecting ubiquitous and seamless mobility even at high velocity.\nWhile most work on future mobile communications is motivated by the first\ncategory of users, we outline in this article a layered cellular network\narchitecture that has the potential to efficiently support both user groups\nsimultaneously. We deduce novel transceiver architectures and derive research\nquestions that need to be tackled to effectively maintain wireless connectivity\nfor the envisioned Society in Motion. \n\n"}
{"id": "1708.09419", "contents": "Title: Proposal for a fully decentralized blockchain and proof-of-work\n  algorithm for solving NP-complete problems Abstract: We propose a proof-of-work algorithm that rewards blockchain miners for using\ncomputational resources to solve NP-complete puzzles. The resulting blockchain\nwill publicly store and improve solutions to problems with real world\napplications while maintaining a secure and fully functional transaction\nledger. \n\n"}
{"id": "1708.09495", "contents": "Title: Integer sorting on multicores: some (experiments and) observations Abstract: There have been many proposals for sorting integers on multicores/GPUs that\ninclude radix-sort and its variants or other approaches that exploit\nspecialized hardware features of a particular multicore architecture.\nComparison-based algorithms have also been used. Network-based algorithms have\nalso been used with primary example Batcher's bitonic sorting algorithm.\nAlthough such a latter approach is theoretically \"inefficient\", if there are\nfew keys to sort, it can lead to better running times as it has low overhead\nand is simple to implement.\n  In this work we perform an experimental study of integer sorting on multicore\nprocessors using not only multithreading but also multiprocessing parallel\nprogramming approaches. Our implementations work under Open MPI, MulticoreBSP,\nand BSPlib. We have implemented serial and parallel radix-sort for various\nradixes and also some previously little explored or unexplored variants of\nbitonic-sort and odd-even transposition sort.\n  We offer our observations on a performance evaluation using the MBSP model of\nsuch algorithm implementations on multiple platforms and architectures and\nmultiple programming libraries. If we can conclude anything is that modeling\ntheir performance by taking into consideration architecture dependent features\nsuch as the structure and characteristics of multiple memory hierarchies is\ndifficult and more often than not unsuccessful or unreliable. However we can\nstill draw some very simple conclusions using traditional architecture\nindependent parallel modeling. \n\n"}
{"id": "1709.00844", "contents": "Title: Optimizing Networks for Internet Access Using Tethering Abstract: We investigate scenarios where Internet access to a user device (node) is\navailable only via the cellular network. However, not every node may connect\ndirectly to it. Instead, some may use tethering to connect over WiFi to a node\nsharing its Internet connection. In effect, nodes split into hotspots and\nclients. Hotspots are nodes that connect directly to the cellular network and\ncan provide Internet connectivity to other nodes to whom they are connected\nover WiFi. Clients connect to the cellular network only via hotspots. In this\nwork, we consider the problem of determining the split of hotspots and clients,\nand the association between them, which maximizes the sum of the rates of all\nnodes, subject to the constraint that any node gets at least the rate it gets\nwhen all nodes are directly connected to the cellular network. Via tractable\nnetworks, we provide insights into the interplay between WiFi connectivity\namongst nodes and rates of their links to the cellular tower, the splits that\nmaximize sum rate, with provably optimal splits for a few cases. We propose a\nnovel heuristic approach to split any network and provide a detailed exposition\nof gains available from tethering, via simulations. \n\n"}
{"id": "1709.01494", "contents": "Title: Latency Optimal Broadcasting in Noisy Wireless Mesh Networks Abstract: In this paper, we adopt a new noisy wireless network model introduced very\nrecently by Censor-Hillel et al. in [ACM PODC 2017, CHHZ17]. More specifically,\nfor a given noise parameter $p\\in [0,1],$ any sender has a probability of $p$\nof transmitting noise or any receiver of a single transmission in its\nneighborhood has a probability $p$ of receiving noise.\n  In this paper, we first propose a new asymptotically latency-optimal\napproximation algorithm (under faultless model) that can complete\nsingle-message broadcasting task in $D+O(\\log^2 n)$ time units/rounds in any\nWMN of size $n,$ and diameter $D$. We then show this diameter-linear\nbroadcasting algorithm remains robust under the noisy wireless network model\nand also improves the currently best known result in CHHZ17 by a\n$\\Theta(\\log\\log n)$ factor.\n  In this paper, we also further extend our robust single-message broadcasting\nalgorithm to $k$ multi-message broadcasting scenario and show it can broadcast\n$k$ messages in $O(D+k\\log n+\\log^2 n)$ time rounds. This new robust\nmulti-message broadcasting scheme is not only asymptotically optimal but also\nanswers affirmatively the problem left open in CHHZ17 on the existence of an\nalgorithm that is robust to sender and receiver faults and can broadcast $k$\nmessages in $O(D+k\\log n + polylog(n))$ time rounds. \n\n"}
{"id": "1709.01672", "contents": "Title: Throughput Optimal Decentralized Scheduling of Multi-Hop Networks with\n  End-to-End Deadline Constraints: II Wireless Networks with Interference Abstract: Consider a multihop wireless network serving multiple flows in which wireless\nlink interference constraints are described by a link interference graph. For\nsuch a network, we design routing-scheduling policies that maximize the\nend-to-end timely throughput of the network. Timely throughput of a flow $f$ is\ndefined as the average rate at which packets of flow $f$ reach their\ndestination node $d_f$ within their deadline.\n  Our policy has several surprising characteristics. Firstly, we show that the\noptimal routing-scheduling decision for an individual packet that is present at\na wireless node $i\\in V$ is solely a function of its location, and \"age\". Thus,\na wireless node $i$ does not require the knowledge of the \"global\" network\nstate in order to maximize the timely throughput. We notice that in comparison,\nunder the backpressure routing policy, a node $i$ requires only the knowledge\nof its neighbours queue lengths in order to guarantee maximal stability, and\nhence is decentralized. The key difference arises due to the fact that in our\nset-up the packets loose their utility once their \"age\" has crossed their\ndeadline, thus making the task of optimizing timely throughput much more\nchallenging than that of ensuring network stability. Of course, due to this key\ndifference, the decision process involved in maximizing the timely throughput\nis also much more complex than that involved in ensuring network-wide queue\nstabilization. In view of this, our results are somewhat surprising. \n\n"}
{"id": "1709.06127", "contents": "Title: Diluting the Scalability Boundaries: Exploring the Use of Disaggregated\n  Architectures for High-Level Network Data Analysis Abstract: Traditional data centers are designed with a rigid architecture of\nfit-for-purpose servers that provision resources beyond the average workload in\norder to deal with occasional peaks of data. Heterogeneous data centers are\npushing towards more cost-efficient architectures with better resource\nprovisioning. In this paper we study the feasibility of using disaggregated\narchitectures for intensive data applications, in contrast to the monolithic\napproach of server-oriented architectures. Particularly, we have tested a\nproactive network analysis system in which the workload demands are highly\nvariable. In the context of the dReDBox disaggregated architecture, the results\nshow that the overhead caused by using remote memory resources is significant,\nbetween 66\\% and 80\\%, but we have also observed that the memory usage is one\norder of magnitude higher for the stress case with respect to average\nworkloads. Therefore, dimensioning memory for the worst case in conventional\nsystems will result in a notable waste of resources. Finally, we found that,\nfor the selected use case, parallelism is limited by memory. Therefore, using a\ndisaggregated architecture will allow for increased parallelism, which, at the\nsame time, will mitigate the overhead caused by remote memory. \n\n"}
{"id": "1709.06175", "contents": "Title: Blocking Versus Non-Blocking Halo Exchange Abstract: This report describes the design, implementation and analysis of a\nnon-blocking halo exchange routine as an alternative to the blocking halo\nexchange routine in the lattice Boltzmann code Ludwig. The alternative,\nnon-blocking, routine is implemented in such a way to allow work-communication\noverlap. Detailed benchmarks in this report show that the non-blocking version\nis a good alternative even without any work-communication overlap.\nWork-Communication overlap can be used to improve the performance of the\nnon-blocking routine. Development and benchmarking were conducted on the UK\nnational supercomputer, ARCHER. \n\n"}
{"id": "1709.06622", "contents": "Title: Distributed Training Large-Scale Deep Architectures Abstract: Scale of data and scale of computation infrastructures together enable the\ncurrent deep learning renaissance. However, training large-scale deep\narchitectures demands both algorithmic improvement and careful system\nconfiguration. In this paper, we focus on employing the system approach to\nspeed up large-scale training. Via lessons learned from our routine\nbenchmarking effort, we first identify bottlenecks and overheads that hinter\ndata parallelism. We then devise guidelines that help practitioners to\nconfigure an effective system and fine-tune parameters to achieve desired\nspeedup. Specifically, we develop a procedure for setting minibatch size and\nchoosing computation algorithms. We also derive lemmas for determining the\nquantity of key components such as the number of GPUs and parameter servers.\nExperiments and examples show that these guidelines help effectively speed up\nlarge-scale deep learning training. \n\n"}
{"id": "1709.07822", "contents": "Title: Planar Graph Perfect Matching is in NC Abstract: Is perfect matching in NC? That is, is there a deterministic fast parallel\nalgorithm for it? This has been an outstanding open question in theoretical\ncomputer science for over three decades, ever since the discovery of RNC\nmatching algorithms. Within this question, the case of planar graphs has\nremained an enigma: On the one hand, counting the number of perfect matchings\nis far harder than finding one (the former is #P-complete and the latter is in\nP), and on the other, for planar graphs, counting has long been known to be in\nNC whereas finding one has resisted a solution.\n  In this paper, we give an NC algorithm for finding a perfect matching in a\nplanar graph. Our algorithm uses the above-stated fact about counting matchings\nin a crucial way. Our main new idea is an NC algorithm for finding a face of\nthe perfect matching polytope at which $\\Omega(n)$ new conditions, involving\nconstraints of the polytope, are simultaneously satisfied. Several other ideas\nare also needed, such as finding a point in the interior of the minimum weight\nface of this polytope and finding a balanced tight odd set in NC. \n\n"}
{"id": "1709.09491", "contents": "Title: Flexible Support for Fast Parallel Commutative Updates Abstract: Privatizing data is a useful strategy for increasing parallelism in a shared\nmemory multithreaded program. Independent cores can compute independently on\nduplicates of shared data, combining their results at the end of their\ncomputations. Conventional approaches to privatization, however, rely on\nexplicit static or dynamic memory allocation for duplicated state, increasing\nmemory footprint and contention for cache resources, especially in shared\ncaches. In this work, we describe CCache, a system for on-demand privatization\nof data manipulated by commutative operations. CCache garners the benefits of\nprivatization, without the increase in memory footprint or cache occupancy.\nEach core in CCache dynamically privatizes commutatively manipulated data,\noperating on a copy. Periodically or at the end of its computation, the core\nmerges its value with the value resident in memory, and when all cores have\nmerged, the in-memory copy contains the up-to-date value. We describe a\nlow-complexity architectural implementation of CCache that extends a\nconventional multicore to support on-demand privatization without using\nadditional memory for private copies. We evaluate CCache on several high-value\napplications, including random access key-value store, clustering, breadth\nfirst search and graph ranking, showing speedups upto 3.2X. \n\n"}
{"id": "1709.09601", "contents": "Title: On the Design of Communication and Transaction Anonymity in\n  Blockchain-Based Transactive Microgrids Abstract: Transactive microgrids are emerging as a transformative solution for the\nproblems faced by distribution system operators due to an increase in the use\nof distributed energy resources and a rapid acceleration in renewable energy\ngeneration, such as wind and solar power. Distributed ledgers have recently\nfound widespread interest in this domain due to their ability to provide\ntransactional integrity across decentralized computing nodes. However, the\nexisting state of the art has not focused on the privacy preservation\nrequirement of these energy systems -- the transaction level data can provide\nmuch greater insights into a prosumer's behavior compared to smart meter data.\nThere are specific safety requirements in transactive microgrids to ensure the\nstability of the grid and to control the load. To fulfil these requirements,\nthe distribution system operator needs transaction information from the grid,\nwhich poses a further challenge to the privacy-goals. This problem is made\nworse by requirement for off-blockchain communication in these networks. In\nthis paper, we extend a recently developed trading workflow called PETra and\ndescribe our solution for communication and transactional anonymity. \n\n"}
{"id": "1710.02507", "contents": "Title: Improved bound on isotropic Lorentz violation in the photon sector from\n  extensive air showers Abstract: Cosmic rays have extremely high particle energies (up to $10^{20} \\;\n\\text{eV}$) and can be used to search for violations of Lorentz invariance. We\nconsider isotropic nonbirefringent Lorentz violation in the photon sector for\nthe case of a photon velocity larger than the maximum attainable velocity of\nthe standard fermions. Up to now, Earth-based bounds on this type of Lorentz\nviolation have been determined from observations of TeV gamma rays. Here, we\nelaborate on a novel approach to test Lorentz invariance with greatly improved\nsensitivity. This approach is based on investigating extensive air showers\nwhich are induced by cosmic-ray particles in the Earth's atmosphere. We study\nthe impact of two Lorentz-violating decay processes on the longitudinal\ndevelopment of air showers, notably the atmospheric depth of the shower maximum\n$X_\\text{max}$. Specifically, the two Lorentz-violating decay processes\nconsidered are photon decay into an electron-positron pair and modified\nneutral-pion decay into two photons. We use Monte Carlo simulations performed\nwith the CONEX code which was extended to include these two Lorentz-violating\ndecay processes at a magnitude allowed by the best previous Earth-based bound.\nCompared to standard physics, these Lorentz-violating decay processes reduce\nthe average $X_\\text{max}$ for showers with primary energies above\n$10^{18}\\;\\text{eV}$ by an amount that is significantly larger than the average\nresolution of current air shower experiments. Comparing the simulations of the\naverage $X_\\text{max}$ to observations, new Earth-based bounds on this type of\nLorentz violation are obtained, which are better than the previous bounds by\nmore than three orders of magnitude. Prospects of further studies are also\ndiscussed. \n\n"}
{"id": "1710.02553", "contents": "Title: Artificial life, complex systems and cloud computing: a short review Abstract: Cloud computing is the prevailing mode of designing, creating and deploying\ncomplex applications nowadays. Its underlying assumptions include distributed\ncomputing, but also new concepts that need to be incorporated in the different\nfields. In this short paper we will make a review of how the world of cloud\ncomputing has intersected the complex systems and artificial life field, and\nhow it has been used as inspiration for new models or implementation of new and\npowerful algorithms \n\n"}
{"id": "1710.03194", "contents": "Title: Quantum transport across van der Waals domain walls in bilayer graphene Abstract: Bilayer graphene can exhibit deformations such that the two graphene sheets\nare locally detached from each other resulting in a structure consisting of\ndomains with different inter-layer coupling. Here we investigate how the\npresence of these domains affect the transport properties of bilayer graphene.\nWe derive analytical expressions for the transmission probability, and the\ncorresponding conductance, across walls separating different inter-layer\ncoupling domain. We find that the transmission can exhibit a valley-dependent\nlayer asymmetry and that the domain walls have a considerable effect on the\nchiral tunnelling properties of the charge carriers. We show that transport\nmeasurements allow one to obtain the strength with which the two layers are\ncoupled. We performed numerical calculations for systems with two domain walls\nand find that the availability of multiple transport channels in bilayer\ngraphene modifies significantly the conductance dependence on inter-layer\npotential asymmetry. \n\n"}
{"id": "1710.03307", "contents": "Title: Nanoscale mapping of ultrafast magnetization dynamics with femtosecond\n  Lorentz microscopy Abstract: Novel time-resolved imaging techniques for the investigation of ultrafast\nnanoscale magnetization dynamics are indispensable for further developments in\nlight-controlled magnetism. Here, we introduce femtosecond Lorentz microscopy,\nachieving a spatial resolution below 100 nm and a temporal resolution of 700\nfs, which gives access to the transiently excited state of the spin system on\nfemtosecond timescales and its subsequent relaxation dynamics. We demonstrate\nthe capabilities of this technique by spatio-temporally mapping the\nlight-induced demagnetization of a single magnetic vortex structure and\nquantitatively extracting the evolution of the magnetization field after\noptical excitation. Tunable electron imaging conditions allow for an\noptimization of spatial resolution or field sensitivity, enabling future\ninvestigations of ultrafast internal dynamics of magnetic topological defects\non 10-nanometer length scales. \n\n"}
{"id": "1710.03451", "contents": "Title: Geometric frustration in polygons of polariton condensates creating\n  vortices of varying topological charge Abstract: Vorticity is a key ingredient to a broad variety of fluid phenomena, and its\nquantised version is considered to be the hallmark of superfluidity.\nCirculating flows that correspond to vortices of a large topological charge,\ntermed giant vortices, are notoriously difficult to realise and even when\nexternally imprinted, they are unstable, breaking into many vortices of a\nsingle charge. In spite of many theoretical proposals on the formation and\nstabilisation of giant vortices in ultra-cold atomic Bose-Einstein condensates\nand other superfluid systems, their experimental realisation remains elusive.\nPolariton condensates stand out from other superfluid systems due to their\nparticularly strong interparticle interactions combined with their\nnon-equilibrium nature, and as such provide an alternative testbed for the\nstudy of vortices. Here, we non-resonantly excite an odd number of polariton\ncondensates at the vertices of a regular polygon and we observe the formation\nof a stable discrete vortex state with a large topological charge as a\nconsequence of antibonding frustration between nearest neighbouring\ncondensates. \n\n"}
{"id": "1710.05399", "contents": "Title: Towards a Floquet-Network Theory of Non-Reciprocal Transport Abstract: We develop a theoretical framework that lays out the fundamental rules under\nwhich a periodic (Floquet) driving scheme can induce non-reciprocal transport.\nOur approach utilizes an extended Hilbert space where a Floquet network with an\nextra (frequency) dimension naturally arises. The properties of this network\n(its on-site potential and the intersite couplings) are in one-to-one\ncorrespondence with the initial driving scheme. Its proper design allows for a\ncontrol of the multipath scattering processes and the associated interferences.\nWe harness this degree of freedom to realize driving schemes with narrow or\nbroad-band non-reciprocal transport. \n\n"}
{"id": "1710.05425", "contents": "Title: Graphically balanced equilibria and stationary measures of reaction\n  networks Abstract: The graph-related symmetries of a reaction network give rise to certain\nspecial equilibria (such as complex balanced equilibria) in deterministic\nmodels of dynamics of the reaction network. Correspondingly, in the stochastic\nsetting, when modeled as a continuous-time Markov chain, these symmetries give\nrise to certain special stationary measures. Previous work by Anderson, Craciun\nand Kurtz identified stationary distributions of a complex balanced network;\nlater Cappelletti and Wiuf developed the notion of complex balancing for\nstochastic systems. We define and establish the relations between reaction\nbalanced measure, complex balanced measure, reaction vector balanced measure,\nand cycle balanced measure and prove that with mild additional hypotheses, the\nformer two are stationary distributions. Furthermore, in spirit of earlier work\nby Joshi, we give sufficient conditions under which detailed balance of the\nstationary distribution of Markov chain models implies the existence of\npositive detailed balance equilibria for the related deterministic reaction\nnetwork model. Finally, we provide a complete map of the implications between\nbalancing properties of deterministic and corresponding stochastic reaction\nsystems, such as complex balance, reaction balance, reaction vector balance and\ncycle balance. \n\n"}
{"id": "1710.07898", "contents": "Title: Meta-Key: A Secure Data-Sharing Protocol under Blockchain-Based\n  Decentralised Storage Architecture Abstract: In this letter we propose Meta-key, a data-sharing mechanism that enables\nusers share their encrypted data under a blockchain-based decentralized storage\narchitecture. All the data-encryption keys are encrypted by the owner's public\nkey and put onto the blockchain for safe and secure storage and easy\nkey-management. Encrypted data are stored in dedicated storage nodes and proxy\nre-encryption mechanism is used to ensure secure data-sharing in the untrusted\nenvironment. Security analysis of our model shows that the proxy re-encryption\nadopted in our system is naturally free from collusion-attack due to the\nspecific architecture of Meta-key. \n\n"}
{"id": "1710.08214", "contents": "Title: Parametric channel estimation for massive MIMO Abstract: Channel state information is crucial to achieving the capacity of\nmulti-antenna (MIMO) wireless communication systems. It requires estimating the\nchannel matrix. This estimation task is studied, considering a sparse channel\nmodel particularly suited to millimeter wave propagation, as well as a general\nmeasurement model taking into account hybrid architectures. The contribution is\ntwofold. First, the Cram{\\'e}r-Rao bound in this context is derived. Second,\ninterpretation of the Fisher Information Matrix structure allows to assess the\nrole of system parameters, as well as to propose asymptotically optimal and\ncomputationally efficient estimation algorithms. \n\n"}
{"id": "1710.08381", "contents": "Title: Near-Optimal Clustering in the $k$-machine model Abstract: The clustering problem, in its many variants, has numerous applications in\noperations research and computer science (e.g., in applications in\nbioinformatics, image processing, social network analysis, etc.). As sizes of\ndata sets have grown rapidly, researchers have focused on designing algorithms\nfor clustering problems in models of computation suited for large-scale\ncomputation such as MapReduce, Pregel, and streaming models. The $k$-machine\nmodel (Klauck et al., SODA 2015) is a simple, message-passing model for\nlarge-scale distributed graph processing. This paper considers three of the\nmost prominent examples of clustering problems: the uncapacitated facility\nlocation problem, the $p$-median problem, and the $p$-center problem and\npresents $O(1)$-factor approximation algorithms for these problems running in\n$\\tilde{O}(n/k)$ rounds in the $k$-machine model. These algorithms are optimal\nup to polylogarithmic factors because this paper also shows\n$\\tilde{\\Omega}(n/k)$ lower bounds for obtaining polynomial-factor\napproximation algorithms for these problems. These are the first results for\nclustering problems in the $k$-machine model.\n  We assume that the metric provided as input for these clustering problems in\nonly implicitly provided, as an edge-weighted graph and in a nutshell, our main\ntechnical contribution is to show that constant-factor approximation algorithms\nfor all three clustering problems can be obtained by learning only a small\nportion of the input metric. \n\n"}
{"id": "1710.08456", "contents": "Title: Magnetic Sensitivity of AlMn TESes and Shielding Considerations for\n  Next-Generation CMB Surveys Abstract: In the next decade, new ground-based Cosmic Microwave Background (CMB)\nexperiments such as Simons Observatory (SO), CCAT-prime, and CMB-S4 will\nincrease the number of detectors observing the CMB by an order of magnitude or\nmore, dramatically improving our understanding of cosmology and astrophysics.\nThese projects will deploy receivers with as many as hundreds of thousands of\ntransition edge sensor (TES) bolometers coupled to Superconducting Quantum\nInterference Device (SQUID)-based readout systems. It is well known that\nsuperconducting devices such as TESes and SQUIDs are sensitive to magnetic\nfields. However, the effects of magnetic fields on TESes are not easily\npredicted due to the complex behavior of the superconducting transition, which\nmotivates direct measurements of the magnetic sensitivity of these devices. We\npresent comparative four-lead measurements of the critical temperature versus\napplied magnetic field of AlMn TESes varying in geometry, doping, and leg\nlength, including Advanced ACT (AdvACT) and POLARBEAR-2/Simons Array\nbolometers. Molybdenum-copper bilayer ACTPol TESes are also tested and are\nfound to be more sensitive to magnetic fields than the AlMn devices. We present\nan observation of weak-link-like behavior in AlMn TESes at low critical\ncurrents. We also compare measurements of magnetic sensitivity for time\ndivision multiplexing SQUIDs and frequency division multiplexing microwave\nrf-SQUIDs. We discuss the implications of our measurements on the magnetic\nshielding required for future experiments that aim to map the CMB to\nnear-fundamental limits. \n\n"}
{"id": "1710.09771", "contents": "Title: Exit time asymptotics for small noise stochastic delay differential\n  equations Abstract: Dynamical system models with delayed dynamics and small noise arise in a\nvariety of applications in science and engineering. In many applications,\nstable equilibrium or periodic behavior is critical to a well functioning\nsystem. Sufficient conditions for the stability of equilibrium points or\nperiodic orbits of certain deterministic dynamical systems with delayed\ndynamics are known and it is of interest to understand the sample path behavior\nof such systems under the addition of small noise. We consider a small noise\nstochastic delay differential equation (SDDE) with coefficients that depend on\nthe history of the process over a finite delay interval. We obtain asymptotic\nestimates, as the noise vanishes, on the time it takes a solution of the\nstochastic equation to exit a bounded domain that is attracted to a stable\nequilibrium point or periodic orbit of the corresponding deterministic\nequation. To obtain these asymptotics, we prove a sample path large deviation\nprinciple (LDP) for the SDDE that is uniform over initial conditions in bounded\nsets. The proof of the uniform sample path LDP uses a variational\nrepresentation for exponential functionals of strong solutions of the SDDE. We\nanticipate that the overall approach may be useful in proving uniform sample\npath LDPs for a broad class of infinite-dimensional small noise stochastic\nequations. \n\n"}
{"id": "1710.10356", "contents": "Title: Optimal Control of Wireless Computing Networks Abstract: Augmented information (AgI) services allow users to consume information that\nresults from the execution of a chain of service functions that process source\ninformation to create real-time augmented value. Applications include real-time\nanalysis of remote sensing data, real-time computer vision, personalized video\nstreaming, and augmented reality, among others. We consider the problem of\noptimal distribution of AgI services over a wireless computing network, in\nwhich nodes are equipped with both communication and computing resources. We\ncharacterize the wireless computing network capacity region and design a joint\nflow scheduling and resource allocation algorithm that stabilizes the\nunderlying queuing system while achieving a network cost arbitrarily close to\nthe minimum, with a tradeoff in network delay. Our solution captures the unique\nchaining and flow scaling aspects of AgI services, while exploiting the use of\nthe broadcast approach coding scheme over the wireless channel. \n\n"}
{"id": "1710.10911", "contents": "Title: Device-centric Energy Optimization for Edge Cloud Offloading Abstract: A wireless system is considered, where, computationally complex algorithms\nare offloaded from user devices to an edge cloud server, for the purpose of\nefficient battery usage. The main focus of this paper is to characterize and\nanalyze, the trade-off between the energy consumed for processing the data\nlocally, and for offloading. An analytical framework is presented, that\nminimizes the in-device energy consumption, by providing an optimal offloading\ndecision for multiple user devices. A closed form solution is obtained for the\noffloading decision. The solution also provides the amount of computational\ndata that should be offloaded, for the given computational and communication\nresources. Consequently, reduction in the energy consumption is observed. \n\n"}
{"id": "1710.11284", "contents": "Title: Some regularity and convergence results for parabolic\n  Hamilton-Jacobi-Bellman equations in bounded domains Abstract: We study the approximation of parabolic Hamilton-Jacobi-Bellman (HJB)\nequations in bounded domains with strong Dirichlet boundary conditions. We work\nunder the assumption of the existence of a sufficiently regular barrier\nfunction for the problem to obtain well-posedness and regularity of a related\nswitching system and the convergence of its components to the HJB equation. In\nparticular, we show existence of a viscosity solution to the switching system\nby a novel construction of sub- and supersolutions and application of Perron's\nmethod. Error bounds for monotone schemes for the HJB equation are then derived\nfrom estimates near the boundary, where the standard regularisation procedure\nfor viscosity solutions is not applicable, and are found to be of the same\norder as known results for the whole space. We deduce error bounds for some\ncommon finite difference and truncated semi-Lagrangian schemes. \n\n"}
{"id": "1711.00705", "contents": "Title: Efficient Training of Convolutional Neural Nets on Large Distributed\n  Systems Abstract: Deep Neural Networks (DNNs) have achieved im- pressive accuracy in many\napplication domains including im- age classification. Training of DNNs is an\nextremely compute- intensive process and is solved using variants of the\nstochastic gradient descent (SGD) algorithm. A lot of recent research has\nfocussed on improving the performance of DNN training. In this paper, we\npresent optimization techniques to improve the performance of the data parallel\nsynchronous SGD algorithm using the Torch framework: (i) we maintain data\nin-memory to avoid file I/O overheads, (ii) we present a multi-color based MPI\nAllreduce algorithm to minimize communication overheads, and (iii) we propose\noptimizations to the Torch data parallel table framework that handles\nmulti-threading. We evaluate the performance of our optimizations on a Power 8\nMinsky cluster with 32 nodes and 128 NVidia Pascal P100 GPUs. With our\noptimizations, we are able to train 90 epochs of the ResNet-50 model on the\nImagenet-1k dataset using 256 GPUs in just 48 minutes. This significantly\nimproves on the previously best known performance of training 90 epochs of the\nResNet-50 model on the same dataset using 256 GPUs in 65 minutes. To the best\nof our knowledge, this is the best known training performance demonstrated for\nthe Imagenet- 1k dataset. \n\n"}
{"id": "1711.00903", "contents": "Title: Acceleration of tensor-product operations for high-order finite element\n  methods Abstract: This paper is devoted to GPU kernel optimization and performance analysis of\nthree tensor-product operators arising in finite element methods. We provide a\nmathematical background to these operations and implementation details.\nAchieving close-to-the-peak performance for these operators requires extensive\noptimization because of the operators' properties: low arithmetic intensity,\ntiered structure, and the need to store intermediate results inside the kernel.\nWe give a guided overview of optimization strategies and we present a\nperformance model that allows us to compare the efficacy of these optimizations\nagainst an empirically calibrated roofline. \n\n"}
{"id": "1711.01110", "contents": "Title: A Rudimentary Model for Low-Latency Anonymous Communication Systems Abstract: In this paper we present a rudimentary model for low-latency anonymous\ncommunication systems. Specifically, we study distributed OR algorithm as an\nabstract of the system. Based on our model, we give several satisfactory lower\nbounds of anonymity leakage of a deterministic OR algorithm. Some of them\nreveal a trade-off between anonymity and communication complexity. For the\nrandomized OR algorithm, we only give a relatively trivial but possibly tight\nlower bound when leaving out communication complexity. And we find the\nrelationship between our model and some open case in the study of secret\nsharing scheme, if considering communication complexity. \n\n"}
{"id": "1711.01919", "contents": "Title: Fast Integral Histogram Computations on GPU for Real-Time Video\n  Analytics Abstract: In many Multimedia content analytics frameworks feature likelihood maps\nrepresented as histograms play a critical role in the overall algorithm.\nIntegral histograms provide an efficient computational framework for extracting\nmulti-scale histogram-based regional descriptors in constant time which are\nconsidered as the principle building blocks of many video content analytics\nframeworks. We evaluate four different mappings of the integral histogram\ncomputation onto Graphics Processing Units (GPUs) using different kernel\noptimization strategies. Our kernels perform cumulative sums on row and column\nhistograms in a cross-weave or wavefront scan order, use different data\norganization and scheduling methods that is shown to critically affect\nutilization of GPU resources (cores and shared memory). Tiling the 3-D array\ninto smaller regular data blocks significantly speeds up the efficiency of the\ncomputation compared to a strip-based organization. The tiled integral\nhistogram using a diagonal wavefront scan has the best performance of about\n300.4 frames/sec for 640 x 480 images and 32 bins with a speedup factor of\nabout 120 using GTX Titan X graphics card compared to a single threaded\nsequential CPU implementation. Double-buffering has been exploited to overlap\ncomputation and communication across sequence of images. Mapping integral\nhistogram bins computations onto multiple GPUs enables us to process 32 giga\nbytes integral histogram data (of 64MB Image and 128 bins) with a frame rate of\n0.73 Hz and speedup factor of 153X over single-threaded CPU implementation and\nthe speedup of 45X over 16-threaded CPU implementation. \n\n"}
{"id": "1711.02939", "contents": "Title: Constrained portfolio-consumption strategies with uncertain parameters\n  and borrowing costs Abstract: This paper studies the properties of the optimal portfolio-consumption\nstrategies in a {finite horizon} robust utility maximization framework with\ndifferent borrowing and lending rates. In particular, we allow for constraints\non both investment and consumption strategies, and model uncertainty on both\ndrift and volatility. With the help of explicit solutions, we quantify the\nimpacts of uncertain market parameters, portfolio-consumption constraints and\nborrowing costs on the optimal strategies and their time monotone properties. \n\n"}
{"id": "1711.05453", "contents": "Title: Geometric effects resulting from square and circular confinements for a\n  particle constrained to a space curve Abstract: Investigating the geometric effects resulting from the detailed behaviors of\nthe confining potential, we consider square and circular confinements to\nconstrain a particle to a space curve. We find a torsion-induced geometric\npotential and a curvature-induced geometric momentum just in the square case,\nwhile a geometric gauge potential solely in the circular case. In the presence\nof electromagnetic field, a geometrically induced magnetic moment couples with\nmagnetic field as an induced Zeeman coupling only for the circular confinement,\nalso. As spin-orbit interaction is considered, we find some additional terms\nfor the spin-orbit coupling, which are induced not only by torsion, but also\ncurvature. Moreover, in the circular case, the spin also couples with an\nintrinsic angular momentum, which describes the azimuthal motions mapped on the\nspace curve. As an important conclusion for the thin-layer quantization\napproach, some substantial geometric effects result from the confinement\nboundaries. Finally, these results are proved on a helical wire. \n\n"}
{"id": "1711.08452", "contents": "Title: Combating Computational Heterogeneity in Large-Scale Distributed\n  Computing via Work Exchange Abstract: Owing to data-intensive large-scale applications, distributed computation\nsystems have gained significant recent interest, due to their ability of\nrunning such tasks over a large number of commodity nodes in a time efficient\nmanner. One of the major bottlenecks that adversely impacts the time efficiency\nis the computational heterogeneity of distributed nodes, often limiting the\ntask completion time due to the slowest worker.\n  In this paper, we first present a lower bound on the expected computation\ntime based on the work-conservation principle. We then present our approach of\nwork exchange to combat the latency problem, in which faster workers can be\nreassigned additional leftover computations that were originally assigned to\nslower workers. We present two variations of the work exchange approach: a)\nwhen the computational heterogeneity knowledge is known a priori; and b) when\nheterogeneity is unknown and is estimated in an online manner to assign tasks\nto distributed workers. As a baseline, we also present and analyze the use of\nan optimized Maximum Distance Separable (MDS) coded distributed computation\nscheme over heterogeneous nodes. Simulation results also compare the proposed\napproach of work exchange, the baseline MDS coded scheme and the lower bound\nobtained via work-conservation principle. We show that the work exchange scheme\nachieves time for computation which is very close to the lower bound with\nlimited coordination and communication overhead even when the knowledge about\nheterogeneity levels is not available. \n\n"}
{"id": "1712.00285", "contents": "Title: Locally-Iterative Distributed (Delta + 1)-Coloring below\n  Szegedy-Vishwanathan Barrier, and Applications to Self-Stabilization and to\n  Restricted-Bandwidth Models Abstract: We consider graph coloring and related problems in the distributed\nmessage-passing model. {Locally-iterative algorithms} are especially important\nin this setting. These are algorithms in which each vertex decides about its\nnext color only as a function of the current colors in its 1-hop neighborhood.\nIn STOC'93 Szegedy and Vishwanathan showed that any locally-iterative\n(Delta+1)-coloring algorithm requires Omega(Delta log Delta + log^* n) rounds,\nunless there is \"a very special type of coloring that can be very efficiently\nreduced\" \\cite{SV93}. In this paper we obtain this special type of coloring.\nSpecifically, we devise a locally-iterative (Delta+1)-coloring algorithm with\nrunning time O(Delta + log^* n), i.e., {below} Szegedy-Vishwanathan barrier.\nThis demonstrates that this barrier is not an inherent limitation for\nlocally-iterative algorithms. As a result, we also achieve significant\nimprovements for dynamic, self-stabilizing and bandwidth-restricted settings:\n  - We obtain self-stabilizing distributed algorithms for\n(Delta+1)-vertex-coloring, (2Delta-1)-edge-coloring, maximal independent set\nand maximal matching with O(Delta+log^* n) time. This significantly improves\npreviously-known results that have O(n) or larger running times \\cite{GK10}.\n  - We devise a (2Delta-1)-edge-coloring algorithm in the CONGEST model with\nO(Delta + log^* n) time and in the Bit-Round model with O(Delta + log n) time.\nPreviously-known algorithms had superlinear dependency on Delta for\n(2Delta-1)-edge-coloring in these models.\n  - We obtain an arbdefective coloring algorithm with running time O(\\sqrt\nDelta + log^* n). We employ it in order to compute proper colorings that\nimprove the recent state-of-the-art bounds of Barenboim from PODC'15 \\cite{B15}\nand Fraigniaud et al. from FOCS'16 \\cite{FHK16} by polylogarithmic factors.\n  - Our algorithms are applicable to the SET-LOCAL model of \\cite{HKMS15}. \n\n"}
{"id": "1712.02546", "contents": "Title: Distributed learning of CNNs on heterogeneous CPU/GPU architectures Abstract: Convolutional Neural Networks (CNNs) have shown to be powerful classification\ntools in tasks that range from check reading to medical diagnosis, reaching\nclose to human perception, and in some cases surpassing it. However, the\nproblems to solve are becoming larger and more complex, which translates to\nlarger CNNs, leading to longer training times that not even the adoption of\nGraphics Processing Units (GPUs) could keep up to. This problem is partially\nsolved by using more processing units and distributed training methods that are\noffered by several frameworks dedicated to neural network training. However,\nthese techniques do not take full advantage of the possible parallelization\noffered by CNNs and the cooperative use of heterogeneous devices with different\nprocessing capabilities, clock speeds, memory size, among others. This paper\npresents a new method for the parallel training of CNNs that can be considered\nas a particular instantiation of model parallelism, where only the\nconvolutional layer is distributed. In fact, the convolutions processed during\ntraining (forward and backward propagation included) represent from $60$-$90$\\%\nof global processing time. The paper analyzes the influence of network size,\nbandwidth, batch size, number of devices, including their processing\ncapabilities, and other parameters. Results show that this technique is capable\nof diminishing the training time without affecting the classification\nperformance for both CPUs and GPUs. For the CIFAR-10 dataset, using a CNN with\ntwo convolutional layers, and $500$ and $1500$ kernels, respectively, best\nspeedups achieve $3.28\\times$ using four CPUs and $2.45\\times$ with three GPUs.\nModern imaging datasets, larger and more complex than CIFAR-10 will certainly\nrequire more than $60$-$90$\\% of processing time calculating convolutions, and\nspeedups will tend to increase accordingly. \n\n"}
{"id": "1712.03038", "contents": "Title: Shrewd Selection Speeds Surfing: Use Smart EXP3! Abstract: In this paper, we explore the use of multi-armed bandit online learning\ntechniques to solve distributed resource selection problems. As an example, we\nfocus on the problem of network selection. Mobile devices often have several\nwireless networks at their disposal. While choosing the right network is vital\nfor good performance, a decentralized solution remains a challenge. The\nimpressive theoretical properties of multi-armed bandit algorithms, like EXP3,\nsuggest that it should work well for this type of problem. Yet, its real-word\nperformance lags far behind. The main reasons are the hidden cost of switching\nnetworks and its slow rate of convergence. We propose Smart EXP3, a novel\nbandit-style algorithm that (a) retains the good theoretical properties of\nEXP3, (b) bounds the number of switches, and (c) yields significantly better\nperformance in practice. We evaluate Smart EXP3 using simulations, controlled\nexperiments, and real-world experiments. Results show that it stabilizes at the\noptimal state, achieves fairness among devices and gracefully deals with\ntransient behaviors. In real world experiments, it can achieve 18% faster\ndownload over alternate strategies. We conclude that multi-armed bandit\nalgorithms can play an important role in distributed resource selection\nproblems, when practical concerns, such as switching costs and convergence\ntime, are addressed. \n\n"}
{"id": "1712.03530", "contents": "Title: Datacenter Traffic Control: Understanding Techniques and Trade-offs Abstract: Datacenters provide cost-effective and flexible access to scalable compute\nand storage resources necessary for today's cloud computing needs. A typical\ndatacenter is made up of thousands of servers connected with a large network\nand usually managed by one operator. To provide quality access to the variety\nof applications and services hosted on datacenters and maximize performance, it\ndeems necessary to use datacenter networks effectively and efficiently.\nDatacenter traffic is often a mix of several classes with different priorities\nand requirements. This includes user-generated interactive traffic, traffic\nwith deadlines, and long-running traffic. To this end, custom transport\nprotocols and traffic management techniques have been developed to improve\ndatacenter network performance.\n  In this tutorial paper, we review the general architecture of datacenter\nnetworks, various topologies proposed for them, their traffic properties,\ngeneral traffic control challenges in datacenters and general traffic control\nobjectives. The purpose of this paper is to bring out the important\ncharacteristics of traffic control in datacenters and not to survey all\nexisting solutions (as it is virtually impossible due to massive body of\nexisting research). We hope to provide readers with a wide range of options and\nfactors while considering a variety of traffic control mechanisms. We discuss\nvarious characteristics of datacenter traffic control including management\nschemes, transmission control, traffic shaping, prioritization, load balancing,\nmultipathing, and traffic scheduling. Next, we point to several open challenges\nas well as new and interesting networking paradigms. At the end of this paper,\nwe briefly review inter-datacenter networks that connect geographically\ndispersed datacenters which have been receiving increasing attention recently\nand pose interesting and novel research problems. \n\n"}
{"id": "1712.05878", "contents": "Title: An MPI-Based Python Framework for Distributed Training with Keras Abstract: We present a lightweight Python framework for distributed training of neural\nnetworks on multiple GPUs or CPUs. The framework is built on the popular Keras\nmachine learning library. The Message Passing Interface (MPI) protocol is used\nto coordinate the training process, and the system is well suited for job\nsubmission at supercomputing sites. We detail the software's features, describe\nits use, and demonstrate its performance on systems of varying sizes on a\nbenchmark problem drawn from high-energy physics research. \n\n"}
{"id": "1712.06139", "contents": "Title: TensorFlow-Serving: Flexible, High-Performance ML Serving Abstract: We describe TensorFlow-Serving, a system to serve machine learning models\ninside Google which is also available in the cloud and via open-source. It is\nextremely flexible in terms of the types of ML platforms it supports, and ways\nto integrate with systems that convey new models and updated versions from\ntraining to serving. At the same time, the core code paths around model lookup\nand inference have been carefully optimized to avoid performance pitfalls\nobserved in naive implementations. Google uses it in many production\ndeployments, including a multi-tenant model hosting service called TFS^2. \n\n"}
{"id": "1712.09552", "contents": "Title: Big Data and Fog Computing Abstract: Fog computing serves as a computing layer that sits between the edge devices\nand the cloud in the network topology. They have more compute capacity than the\nedge but much less so than cloud data centers. They typically have high uptime\nand always-on Internet connectivity. Applications that make use of the fog can\navoid the network performance limitation of cloud computing while being less\nresource constrained than edge computing. As a result, they offer a useful\nbalance of the current paradigms. This article explores various aspects of fog\ncomputing in the context of big data. \n\n"}
{"id": "1712.09686", "contents": "Title: Deviator Detection under Imperfect Monitoring Abstract: Grim-trigger strategies are a fundamental mechanism for sustaining equilibria\nin iterated games: the players cooperate along an agreed path, and as soon as\none player deviates, the others form a coalition to play him down to his minmax\nlevel. A precondition to triggering such a strategy is that the identity of the\ndeviating player becomes common knowledge among the other players. This can be\ndifficult or impossible to attain in games where the information structure\nallows only imperfect monitoring of the played actions or of the global state.\n  We study the problem of synthesising finite-state strategies for detecting\nthe deviator from an agreed strategy profile in games played on finite graphs\nwith different information structures. We show that the problem is undecidable\nin the general case where the global state cannot be monitored. On the other\nhand, we prove that under perfect monitoring of the global state and imperfect\nmonitoring of actions, the problem becomes decidable, and we present an\neffective synthesis procedure that covers infinitely repeated games with\nprivate monitoring. \n\n"}
{"id": "1712.10128", "contents": "Title: Structured decentralized control of positive systems with applications\n  to combination drug therapy and leader selection in directed networks Abstract: We study a class of structured optimal control problems in which the main\ndiagonal of the dynamic matrix is a linear function of the design variable.\nWhile such problems are in general challenging and nonconvex, for positive\nsystems we prove convexity of the $H_2$ and $H_\\infty$ optimal control\nformulations which allow for arbitrary convex constraints and regularization of\nthe control input. Moreover, we establish differentiability of the $H_\\infty$\nnorm when the graph associated with the dynamical generator is weakly connected\nand develop a customized algorithm for computing the optimal solution even in\nthe absence of differentiability. We apply our results to the problems of\nleader selection in directed consensus networks and combination drug therapy\nfor HIV treatment. In the context of leader selection, we address the\ncombinatorial challenge by deriving upper and lower bounds on optimal\nperformance. For combination drug therapy, we develop a customized subgradient\nmethod for efficient treatment of diseases whose mutation patterns are not\nconnected. \n\n"}
{"id": "1801.00667", "contents": "Title: A simulation-based analytic model of radio galaxies Abstract: I derive and discuss a simple semi-analytical model of the evolution of\npowerful radio galaxies which is not based on assumptions of self-similar\ngrowth, but rather implements some insights about the dynamics and energetics\nof these systems derived from numerical simulations, and can be applied to\narbitrary pressure/density profiles of the host environment. The model can\nqualitatively and quantitatively reproduce the source dynamics and synchrotron\nlight curves derived from numerical modelling. Approximate corrections for\nradiative and adiabatic losses allow it to predict the evolution of radio\nspectral index and of inverse-Compton emission both for active sources and for\n`remnant' sources after the jet has turned off. Code to implement the model is\npublicly available. Using a standard model with a light relativistic\n(electron-positron) jet, sub-equipartition magnetic fields, and a range of\nrealistic group/cluster environments, I simulate populations of sources and\nshow that the model can reproduce the range of properties of powerful radio\nsources as well as observed trends in the relationship between jet power and\nradio luminosity, and predicts their dependence on redshift and environment. I\nshow that the distribution of source lifetimes has a significant effect on both\nthe source length distribution and the fraction of remnant sources expected in\nobservations, and so can in principle be constrained by observations. The\nremnant fraction is expected to be low even at low redshift and low observing\nfrequency due to the rapid luminosity evolution of remnants, and to tend\nrapidly to zero at high redshift due to inverse-Compton losses. \n\n"}
{"id": "1801.00837", "contents": "Title: QuickCast: Fast and Efficient Inter-Datacenter Transfers using\n  Forwarding Tree Cohorts Abstract: Large inter-datacenter transfers are crucial for cloud service efficiency and\nare increasingly used by organizations that have dedicated wide area networks\nbetween datacenters. A recent work uses multicast forwarding trees to reduce\nthe bandwidth needs and improve completion times of point-to-multipoint\ntransfers. Using a single forwarding tree per transfer, however, leads to poor\nperformance because the slowest receiver dictates the completion time for all\nreceivers. Using multiple forwarding trees per transfer alleviates this\nconcern--the average receiver could finish early; however, if done naively,\nbandwidth usage would also increase and it is apriori unclear how best to\npartition receivers, how to construct the multiple trees and how to determine\nthe rate and schedule of flows on these trees. This paper presents QuickCast, a\nfirst solution to these problems. Using simulations on real-world network\ntopologies, we see that QuickCast can speed up the average receiver's\ncompletion time by as much as $10\\times$ while only using $1.04\\times$ more\nbandwidth; further, the completion time for all receivers also improves by as\nmuch as $1.6\\times$ faster at high loads. \n\n"}
{"id": "1801.02531", "contents": "Title: A Scale-out Blockchain for Value Transfer with Spontaneous Sharding Abstract: Bitcoin, as well as many of its successors, require the whole transaction\nrecord to be reliably acquired by all nodes to prevent double-spending.\nRecently, many blockchains have been proposed to achieve scale-out throughput\nby letting nodes only acquire a fraction of the whole transaction set. However,\nthese schemes, e.g., sharding and off-chain techniques, suffer from a\ndegradation in decentralization or the capacity of fault tolerance.\n  In this paper, we show that the complete set of transactions is not a\nnecessity for the prevention of double-spending if the properties of value\ntransfers is fully explored. In other words, we show that a value-transfer\nledger like Bitcoin has the potential to scale-out by its nature without\nsacrificing security or decentralization. Firstly, we give a formal definition\nfor the value-transfer ledger and its distinct features from a generic\ndatabase. Then, we introduce an off-chain based scheme with a shared main chain\nfor consensus and an individual chain for each node for recording transactions.\nA locally executable validation scheme is proposed with uncompromising validity\nand consistency. A beneficial consequence of our design is that nodes will\nspontaneously try to reduce their transmission cost by only providing the\ntransactions needed to show that their transactions are double-spending-proof.\nAs a result, the network is sharded as each node only acquires part of the\ntransaction record and a scale-out throughput could be achieved, which we call\n\"spontaneous sharding\". \n\n"}
{"id": "1801.04179", "contents": "Title: Arhuaco: Deep Learning and Isolation Based Security for Distributed\n  High-Throughput Computing Abstract: Grid computing systems require innovative methods and tools to identify\ncybersecurity incidents and perform autonomous actions i.e. without\nadministrator intervention. They also require methods to isolate and trace job\npayload activity in order to protect users and find evidence of malicious\nbehavior. We introduce an integrated approach of security monitoring via\nSecurity by Isolation with Linux Containers and Deep Learning methods for the\nanalysis of real time data in Grid jobs running inside virtualized\nHigh-Throughput Computing infrastructure in order to detect and prevent\nintrusions. A dataset for malware detection in Grid computing is described. We\nshow in addition the utilization of generative methods with Recurrent Neural\nNetworks to improve the collected dataset. We present Arhuaco, a prototype\nimplementation of the proposed methods. We empirically study the performance of\nour technique. The results show that Arhuaco outperforms other methods used in\nIntrusion Detection Systems for Grid Computing. The study is carried out in the\nALICE Collaboration Grid, part of the Worldwide LHC Computing Grid. \n\n"}
{"id": "1801.05705", "contents": "Title: Electromagnetic emission from blitzars and its impact on non-repeating\n  fast radio bursts Abstract: It has been suggested that a non-repeating fast radio burst (FRB) represents\nthe final signal of a magnetized neutron star collapsing to a black hole. In\nthis model, a supramassive neutron star supported by rapid rotation, will\ncollapse to a black hole several thousand to million years after its birth as a\nresult of spin down. The collapse violently snaps the magnetic-field lines\nanchored on the stellar surface, thus producing an electromagnetic pulse that\nwill propagate outwards and accelerate electrons producing a massive radio\nburst, i.e. a \"blitzar\". We present a systematic study of the gravitational\ncollapse of rotating and magnetised neutron stars with special attention to\nfar-field evolution at late times after the collapse. By considering a series\nof neutron stars with rotation ranging from zero to millisecond periods and\ndifferent magnetic-field strengths, we show that the blitzar emission is very\nrobust and always characterised by a series sub-millisecond pulses decaying\nexponentially in amplitude. The luminosity and energy released when the\nmagnetosphere is destroyed are well reproduced by a simple expression in terms\nof the stellar magnetic field and radius. Finally, we assess the occurrence of\npair production during a blitzar scenario, concluding that for typical\nmagnetic-field strengths of $10^{12}\\,{\\rm G}$ and spin frequencies of a few\nHz, pair production is suppressed. Overall, the very good match between the\nresults of the simulations and the luminosities normally observed for FRBs\nlends credibility to the blitzar model as a simple and yet plausible\nexplanation for the phenomenology of non-repeating FRBs. \n\n"}
{"id": "1801.06619", "contents": "Title: Machine Learning Methods for User Positioning With Uplink RSS in\n  Distributed Massive MIMO Abstract: We consider a machine learning approach based on Gaussian process regression\n(GP) to position users in a distributed massive multiple-input multiple-output\n(MIMO) system with the uplink received signal strength (RSS) data. We focus on\nthe scenario where noise-free RSS is available for training, but only noisy RSS\nis available for testing purposes. To estimate the test user locations and\ntheir 2{\\sigma} error-bars, we adopt two state-of-the-art GP methods, namely,\nthe conventional GP (CGP) and the numerical approximation GP (NaGP) methods. We\nfind that the CGP method, which treats the noisy test RSS vectors as\nnoise-free, provides unrealistically small 2{\\sigma} error-bars on the\nestimated locations. To alleviate this concern, we derive the true predictive\ndistribution for the test user locations and then employ the NaGP method to\nnumerically approximate it as a Gaussian with the same first and second order\nmoments. We also derive a Bayesian Cramer-Rao lower bound (BCRLB) on the\nachievable root- mean-squared-error (RMSE) performance of the two GP methods.\nSimulation studies reveal that: (i) the NaGP method indeed provides realistic\n2{\\sigma} error-bars on the estimated locations, (ii) operation in massive MIMO\nregime improves the RMSE performance, and (iii) the achieved RMSE performances\nare very close to the derived BCRLB. \n\n"}
{"id": "1801.07716", "contents": "Title: ASAS-SN Discovery of 4880 Bright RR Lyrae Variable Stars Abstract: We present a catalog of 4880 newly identified RR Lyrae variable stars (4433\nRRab, 446 RRc and 1 RRd) found during the search for supernovae by the All-Sky\nAutomated Survey for Supernovae (ASAS-SN). The light curves, classified using\nthe \"Upsilon\" random forest classifier and visually verified, are available\nthrough the ASAS-SN variable star database (https://asas-sn.osu.edu/variables).\nThe database also contains light curves for an expanding number of additional\nnew variables (~50,000 at present) and will begin to include the light curves\nof known variable stars in the near future. \n\n"}
{"id": "1801.10228", "contents": "Title: Hyperledger Fabric: A Distributed Operating System for Permissioned\n  Blockchains Abstract: Fabric is a modular and extensible open-source system for deploying and\noperating permissioned blockchains and one of the Hyperledger projects hosted\nby the Linux Foundation (www.hyperledger.org).\n  Fabric is the first truly extensible blockchain system for running\ndistributed applications. It supports modular consensus protocols, which allows\nthe system to be tailored to particular use cases and trust models. Fabric is\nalso the first blockchain system that runs distributed applications written in\nstandard, general-purpose programming languages, without systemic dependency on\na native cryptocurrency. This stands in sharp contrast to existing blockchain\nplatforms that require \"smart-contracts\" to be written in domain-specific\nlanguages or rely on a cryptocurrency. Fabric realizes the permissioned model\nusing a portable notion of membership, which may be integrated with\nindustry-standard identity management. To support such flexibility, Fabric\nintroduces an entirely novel blockchain design and revamps the way blockchains\ncope with non-determinism, resource exhaustion, and performance attacks.\n  This paper describes Fabric, its architecture, the rationale behind various\ndesign decisions, its most prominent implementation aspects, as well as its\ndistributed application programming model. We further evaluate Fabric by\nimplementing and benchmarking a Bitcoin-inspired digital currency. We show that\nFabric achieves end-to-end throughput of more than 3500 transactions per second\nin certain popular deployment configurations, with sub-second latency, scaling\nwell to over 100 peers. \n\n"}
{"id": "1802.00521", "contents": "Title: Multipath Communication with Finite Sliding Window Network Coding for\n  Ultra-Reliability and Low Latency Abstract: We use random linear network coding (RLNC) based scheme for multipath\ncommunication in the presence of lossy links with different delay\ncharacteristics to obtain ultra-reliability and low latency. A sliding window\nversion of RLNC is proposed where the coded packets are generated using packets\nin a window size and are inserted among systematic packets in different paths.\nThe packets are scheduled in the paths in a round robin fashion proportional to\nthe data rates. We use finite encoding and decoding window size and do not rely\non feedback for closing the sliding window, unlike the previous work. Our\nimplementation of two paths with LTE and WiFi characteristics shows that the\nproposed sliding window scheme achieves better latency compared to the block\nRLNC code. It is also shown that the proposed scheme achieves low latency\ncommunication through multiple paths compared to the individual paths for\nbursty traffic by translating the throughput on both the paths into latency\ngain. \n\n"}
{"id": "1802.00674", "contents": "Title: Helioseismology: Observations and Space Missions Abstract: The great success of Helioseismology resides in the remarkable progress\nachieved in the understanding of the structure and dynamics of the solar\ninterior. This success mainly relies on the ability to conceive, implement, and\noperate specific instrumentation with enough sensitivity to detect and measure\nsmall fluctuations (in velocity and/or intensity) on the solar surface that are\nwell below one meter per second or a few parts per million. Furthermore the\nlimitation of the ground observations imposing the day-night cycle (thus a\nperiodic discontinuity in the observations) was overcome with the deployment of\nground-based networks --properly placed at different longitudes all over the\nEarth-- allowing longer and continuous observations of the Sun and consequently\nincreasing their duty cycles. In this chapter, we start by a short historical\noverview of helioseismology. Then we describe the different techniques used to\ndo helioseismic analyses along with a description of the main instrumental\nconcepts. We in particular focus on the instruments that have been operating\nlong enough to study the solar magnetic activity. Finally, we give a highlight\nof the main results obtained with such high-duty cycle observations (>80%)\nlasting over the last few decades. \n\n"}
{"id": "1802.01593", "contents": "Title: The enhancement of rapidly quenched galaxies in distant clusters at\n  0.5<z<1.0 Abstract: We investigate the relationship between environment and galaxy evolution in\nthe redshift range $0.5 < z < 1.0$. Galaxy overdensities are selected using a\nFriends-of-Friends algorithm, applied to deep photometric data in the\nUltra-Deep Survey (UDS) field. A study of the resulting stellar mass functions\nreveals clear differences between cluster and field environments, with a strong\nexcess of low-mass rapidly quenched galaxies in cluster environments compared\nto the field. Cluster environments also show a corresponding deficit of young,\nlow-mass star-forming galaxies, which show a sharp radial decline towards\ncluster centres. By comparing mass functions and radial distributions, we\nconclude that young star-forming galaxies are rapidly quenched as they enter\noverdense environments, becoming post-starburst galaxies before joining the red\nsequence. Our results also point to the existence of two environmental\nquenching pathways operating in galaxy clusters, operating on different\ntimescales. Fast quenching acts on galaxies with high specific star-formation\nrates, operating on timescales shorter than the cluster dynamical time ($ < 1$\nGyr). In contrast, slow quenching affects galaxies with moderate specific\nstar-formation rates, regardless of their stellar mass, and acts on longer\ntimescales ($\\gtrsim 1$ Gyr). Of the cluster galaxies in the stellar mass range\n$9.0 < \\log(M_{*}/M_{\\odot}) < 10.5$ quenched during this epoch, we find that\n73% were transformed through fast quenching, while the remaining 27% followed\nthe slow quenching route. \n\n"}
{"id": "1802.03143", "contents": "Title: Solitons as candidates for energy carriers in Fermi-Pasta-Ulam lattices Abstract: Currently, effective phonons (renormalized or interacting phonons) rather\nthan solitary waves (for short, solitons) are regarded as the energy carriers\nin nonlinear lattices. In this work, by using the approximate soliton solutions\nof the corresponding equations of motion and adopting the Boltzmann\ndistribution for these solitons, the average velocities of solitons are\nobtained and are compared with the sound velocities of energy transfer.\nExcellent agreements with the numerical results and the predictions of other\nexisting theories are shown in both the symmetric Fermi-Pasta-Ulam-$\\beta$\nlattices and the asymmetric Fermi-Pasta-Ulam-$\\alpha \\beta$ lattices. These\nclearly indicate that solitons are suitable candidates for energy carriers in\nFermi-Pasta-Ulam lattices. In addition, the root-mean-square velocity of\nsolitons can be obtained from the effective phonons theory. \n\n"}
{"id": "1802.04112", "contents": "Title: Infrastructure Enabled Autonomy: A Distributed Intelligence Architecture\n  for Autonomous Vehicles Abstract: Multiple studies have illustrated the potential for dramatic societal,\nenvironmental and economic benefits from significant penetration of autonomous\ndriving. However, all the current approaches to autonomous driving require the\nautomotive manufacturers to shoulder the primary responsibility and liability\nassociated with replacing human perception and decision making with automation,\npotentially slowing the penetration of autonomous vehicles, and consequently\nslowing the realization of the societal benefits of autonomous vehicles. We\npropose here a new approach to autonomous driving that will re-balance the\nresponsibility and liabilities associated with autonomous driving between\ntraditional automotive manufacturers, infrastructure players, and third-party\nplayers. Our proposed distributed intelligence architecture leverages the\nsignificant advancements in connectivity and edge computing in the recent\ndecades to partition the driving functions between the vehicle, edge computers\non the road side, and specialized third-party computers that reside in the\nvehicle. Infrastructure becomes a critical enabler for autonomy. With this\nInfrastructure Enabled Autonomy (IEA) concept, the traditional automotive\nmanufacturers will only need to shoulder responsibility and liability\ncomparable to what they already do today, and the infrastructure and\nthird-party players will share the added responsibility and liabilities\nassociated with autonomous functionalities. We propose a Bayesian Network Model\nbased framework for assessing the risk benefits of such a distributed\nintelligence architecture. An additional benefit of the proposed architecture\nis that it enables \"autonomy as a service\" while still allowing for private\nownership of automobiles. \n\n"}
{"id": "1802.04245", "contents": "Title: Scalarization Methods for Many-Objective Virtual Machine Placement of\n  Elastic Infrastructures in Overbooked Cloud Computing Data Centers Under\n  Uncertainty Abstract: Cloud computing datacenters provide thousands to millions of virtual machines\n(VMs) on-demand in highly dynamic environments, requiring quick placement of\nrequested VMs into available physical machines (PMs). Due to the randomness of\ncustomer requests, the Virtual Machine Placement (VMP) should be formulated as\nan online optimization problem.\n  The first part of this work analyzes alternatives to solve the formulated\nproblem, an experimental comparison of five different online deterministic\nheuristics against an offline memetic algorithm with migration of VMs was\nperformed, considering several experimental workloads. Simulations indicate\nthat First-Fit Decreasing algorithm (A4) outperforms other evaluated heuristics\non average.\n  This work presents a two-phase schema formulation of a VMP problem\nconsidering the optimization of three objective functions in an IaaS\nenvironment with elasticity and overbooking capabilities. The two-phase schema\nformulation describes that the allocation of the VMs can be separated into two\nsub-problems, the incremental allocation (iVMP) and the reconfiguration of a\nplacement (VMPr).\n  To analyze alternatives to solve the formulated problem, an experimental\ncomparison of three different objective function scalarization methods as part\nof the iVMP and VMPr was performed considering several experimental workloads.\nSimulations indicate that the Euclidean distance to origin outperforms other\nevaluated scalarization methods on average.\n  In order to portray the dynamic nature of an IaaS environment a customizable\nworkload trace generator was developed to simulate uncertainty in the scenarios\nwith elasticity and overbooking of resources in VM requests.\n  Experimental results proved that the Euclidean distance is preferable over\nthe other scalarizatiom methods to improve the values of the power consumption\nobjective function. \n\n"}
{"id": "1802.05582", "contents": "Title: Distributed coloring in sparse graphs with fewer colors Abstract: This paper is concerned with efficiently coloring sparse graphs in the\ndistributed setting with as few colors as possible. According to the celebrated\nFour Color Theorem, planar graphs can be colored with at most 4 colors, and the\nproof gives a (sequential) quadratic algorithm finding such a coloring. A\nnatural problem is to improve this complexity in the distributed setting. Using\nthe fact that planar graphs contain linearly many vertices of degree at most 6,\nGoldberg, Plotkin, and Shannon obtained a deterministic distributed algorithm\ncoloring $n$-vertex planar graphs with 7 colors in $O(\\log n)$ rounds. Here, we\nshow how to color planar graphs with 6 colors in $\\mbox{polylog}(n)$ rounds.\nOur algorithm indeed works more generally in the list-coloring setting and for\nsparse graphs (for such graphs we improve by at least one the number of colors\nresulting from an efficient algorithm of Barenboim and Elkin, at the expense of\na slightly worst complexity). Our bounds on the number of colors turn out to be\nquite sharp in general. Among other results, we show that no distributed\nalgorithm can color every $n$-vertex planar graph with 4 colors in $o(n)$\nrounds. \n\n"}
{"id": "1802.06742", "contents": "Title: Distributed Recoloring Abstract: Given two colorings of a graph, we consider the following problem: can we\nrecolor the graph from one coloring to the other through a series of elementary\nchanges, such that the graph is properly colored after each step?\n  We introduce the notion of distributed recoloring: The input graph represents\na network of computers that needs to be recolored. Initially, each node is\naware of its own input color and target color. The nodes can exchange messages\nwith each other, and eventually each node has to stop and output its own\nrecoloring schedule, indicating when and how the node changes its color. The\nrecoloring schedules have to be globally consistent so that the graph remains\nproperly colored at each point, and we require that adjacent nodes do not\nchange their colors simultaneously.\n  We are interested in the following questions: How many communication rounds\nare needed (in the LOCAL model of distributed computing) to find a recoloring\nschedule? What is the length of the recoloring schedule? And how does the\npicture change if we can use extra colors to make recoloring easier?\n  The main contributions of this work are related to distributed recoloring\nwith one extra color in the following graph classes: trees, $3$-regular graphs,\nand toroidal grids. \n\n"}
{"id": "1802.07209", "contents": "Title: Distributed Symmetry-Breaking Algorithms for Congested Cliques Abstract: The {Congested Clique} is a distributed-computing model for single-hop\nnetworks with restricted bandwidth that has been very intensively studied\nrecently. It models a network by an $n$-vertex graph in which any pair of\nvertices can communicate one with another by transmitting $O(\\log n )$ bits in\neach round. Various problems have been studied in this setting, but for some of\nthem the best-known results are those for general networks. In this paper we\ndevise significantly improved algorithms for various symmetry-breaking\nproblems, such as forests-decompositions, vertex-colorings, and maximal\nindependent set.\n  We analyze the running time of our algorithms as a function of the arboricity\n$a$ of a clique subgraph that is given as input. Our algorithms are especially\nefficient in Trees, planar graphs, graphs with constant genus, and many other\ngraphs that have bounded arboricity, but unbounded size. We obtain\n$O(a)$-forest-decomposition algorithm with $O(\\log a)$ time that improves the\npreviously-known $O(\\log n)$ time, $O(a^{2 + \\epsilon})$-coloring in $O(\\log^*\nn)$ time that improves upon an $O(\\log n)$-time algorithm, $O(a)$-coloring in\n$O(a^{\\epsilon})$-time that improves upon several previous algorithms, and a\nmaximal independent set algorithm with $O(\\sqrt a)$ time that improves at least\nquadratically upon the state-of-the-art for small and moderate values of $a$.\n  Those results are achieved using several techniques. First, we produce a\nforest decomposition with a helpful structure called {$H$-partition} within\n$O(\\log a)$ rounds. In general graphs this structure requires $\\Theta(\\log n)$\ntime, but in Congested Cliques we are able to compute it faster. We employ this\nstructure in conjunction with partitioning techniques that allow us to solve\nvarious symmetry-breaking problems efficiently. \n\n"}
{"id": "1802.08253", "contents": "Title: A 5D, polarised, Bethe-Heitler event generator for $\\gamma \\to e^+e^-$\n  conversion Abstract: We describe a new version of the 5D, exact, polarised, Bethe-Heitler event\ngenerator of $\\gamma$-ray conversions to $e^+e^-$, developed in the context of\nthe HARPO project, that is able to simulate successive events with different\nphoton energies and on different atomic targets without any substantial CPU\noverhead. The strong correlation between kinematic variables in the divergence\nof the five-dimensional differential cross section are mitigated by performing\neach step of the conversion in the appropriate Lorentz frame. We extend the\nverification range down to 1 keV above threshold and up to 1 EeV. This work\ncould pave the way to the precise simulation of the high-performance\n$\\gamma$-ray telescopes and polarimeters of the post-Fermi-LAT area. \n\n"}
{"id": "1802.09080", "contents": "Title: Minimizing Flow Completion Times using Adaptive Routing over\n  Inter-Datacenter Wide Area Networks Abstract: Inter-datacenter networks connect dozens of geographically dispersed\ndatacenters and carry traffic flows with highly variable sizes and different\nclasses. Adaptive flow routing can improve efficiency and performance by\nassigning paths to new flows according to network status and flow properties. A\npopular approach widely used for traffic engineering is based on current\nbandwidth utilization of links. We propose an alternative that reduces\nbandwidth usage by up to at least 50% and flow completion times by up to at\nleast 40% across various scheduling policies and flow size distributions. \n\n"}
{"id": "1803.00989", "contents": "Title: Secure and Privacy-Aware Data Dissemination for Cloud-Based Applications Abstract: In this paper we propose a data dissemination platform that supports data\nsecurity and different privacy levels even when the platform and the data are\nhosted by untrusted infrastructures. The proposed system aims at enabling an\napplication ecosystem that uses off-the-shelf trusted platforms (in this case,\nIntel SGX), so that users may allow or disallow third parties to access the\nlive data stream with a specific sensitivity-level. Moreover, this approach\ndoes not require users to manage the encryption keys directly. Our experiments\nshow that such an approach is indeed practical for medium scale systems, where\nparticipants disseminate small volumes of data at a time, such as in smart\ngrids and IoT environments. \n\n"}
{"id": "1803.01015", "contents": "Title: The Dirac equation as a quantum walk over the honeycomb and triangular\n  lattices Abstract: A discrete-time Quantum Walk (QW) is essentially an operator driving the\nevolution of a single particle on the lattice, through local unitaries. Some\nQWs admit a continuum limit, leading to well-known physics partial differential\nequations, such as the Dirac equation. We show that these simulation results\nneed not rely on the grid: the Dirac equation in $(2+1)$--dimensions can also\nbe simulated, through local unitaries, on the honeycomb or the triangular\nlattice. The former is of interest in the study of graphene-like materials. The\nlatter, we argue, opens the door for a generalization of the Dirac equation to\narbitrary discrete surfaces. \n\n"}
{"id": "1803.02720", "contents": "Title: Byzantine Preferential Voting Abstract: In the Byzantine agreement problem, n nodes with possibly different input\nvalues aim to reach agreement on a common value in the presence of t < n/3\nByzantine nodes which represent arbitrary failures in the system. This paper\nintroduces a generalization of Byzantine agreement, where the input values of\nthe nodes are preference rankings of three or more candidates. We show that\nconsensus on preferences, which is an important question in social choice\ntheory, complements already known results from Byzantine agreement. In addition\npreferential voting raises new questions about how to approximate consensus\nvectors. We propose a deterministic algorithm to solve Byzantine agreement on\nrankings under a generalized validity condition, which we call Pareto-Validity.\nThese results are then extended by considering a special voting rule which\nchooses the Kemeny median as the consensus vector. For this rule, we derive a\nlower bound on the approximation ratio of the Kemeny median that can be\nguaranteed by any deterministic algorithm. We then provide an algorithm\nmatching this lower bound. To our knowledge, this is the first non-trivial\nmulti-dimensional approach which can tolerate a constant fraction of Byzantine\nnodes. \n\n"}
{"id": "1803.02811", "contents": "Title: Accelerated Methods for Deep Reinforcement Learning Abstract: Deep reinforcement learning (RL) has achieved many recent successes, yet\nexperiment turn-around time remains a key bottleneck in research and in\npractice. We investigate how to optimize existing deep RL algorithms for modern\ncomputers, specifically for a combination of CPUs and GPUs. We confirm that\nboth policy gradient and Q-value learning algorithms can be adapted to learn\nusing many parallel simulator instances. We further find it possible to train\nusing batch sizes considerably larger than are standard, without negatively\naffecting sample complexity or final performance. We leverage these facts to\nbuild a unified framework for parallelization that dramatically hastens\nexperiments in both classes of algorithm. All neural network computations use\nGPUs, accelerating both data collection and training. Our results include using\nan entire DGX-1 to learn successful strategies in Atari games in mere minutes,\nusing both synchronous and asynchronous algorithms. \n\n"}
{"id": "1803.03031", "contents": "Title: Redundancy in Distributed Proofs Abstract: Distributed proofs are mechanisms enabling the nodes of a network to\ncollectivity and efficiently check the correctness of Boolean predicates on the\nstructure of the network, or on data-structures distributed over the nodes\n(e.g., spanning trees or routing tables). We consider mechanisms consisting of\ntwo components: a \\emph{prover} assigning a \\emph{certificate} to each node,\nand a distributed algorithm called \\emph{verifier} that is in charge of\nverifying the distributed proof formed by the collection of all certificates.\n  In this paper, we show that many network predicates have distributed proofs\noffering a high level of redundancy, explicitly or implicitly. We use this\nremarkable property of distributed proofs for establishing perfect tradeoffs\nbetween the \\emph{size of the certificate} stored at every node, and the\n\\emph{number of rounds} of the verification protocol. If we allow every node to\ncommunicate to distance at most $t$, one might expect that the certificate\nsizes can be reduced by a multiplicative factor of at least~$t$. In trees,\ncycles and grids, we show that such tradeoffs can be established for \\emph{all}\nnetwork predicates, i.e., it is always possible to linearly decrease the\ncertificate size. In arbitrary graphs, we show that any part of the\ncertificates common to all nodes can be evenly redistributed among these nodes,\nachieving even a better tradeoff: this common part of the certificate can be\nreduced by the size of a smallest ball of radius $t$ in the network.\n  In addition to these general results, we establish several upper and lower\nbounds on the certificate sizes used for distributed proofs for spanning trees,\nminimum-weight spanning trees, diameter, additive and multiplicative spanners,\nand more, improving and generalizing previous results from the literature. \n\n"}
{"id": "1803.03456", "contents": "Title: A user-friendly condition for exponential ergodicity in randomly\n  switched environments Abstract: We consider random switching between finitely many vector fields leaving\npositively invariant a compact set. Recently, Li, Liu and Cui showed that if\none the vector fields has a globally asymptotically stable (G.A.S.) equilibrium\nfrom which one can reach a point satisfying a weak H\\\"ormander-bracket\ncondition, then the process converges in total variation to a unique invariant\nprobability measure. In this note, adapting the proof of Li, Liu and Cui and\nusing results of Bena\\\"im, Le Borgne, Malrieu and Zitt, the assumption of a\nG.A.S. equilibrium is weakened to the existence of an accessible point at which\na barycentric combination of the vector fields vanishes. Some examples are\ngiven which demonstrate the usefulness of this condition. \n\n"}
{"id": "1803.05069", "contents": "Title: HotStuff: BFT Consensus in the Lens of Blockchain Abstract: We present HotStuff, a leader-based Byzantine fault-tolerant replication\nprotocol for the partially synchronous model. Once network communication\nbecomes synchronous, HotStuff enables a correct leader to drive the protocol to\nconsensus at the pace of actual (vs. maximum) network delay--a property called\nresponsiveness--and with communication complexity that is linear in the number\nof replicas. To our knowledge, HotStuff is the first partially synchronous BFT\nreplication protocol exhibiting these combined properties. HotStuff is built\naround a novel framework that forms a bridge between classical BFT foundations\nand blockchains. It allows the expression of other known protocols (DLS, PBFT,\nTendermint, Casper), and ours, in a common framework.\n  Our deployment of HotStuff over a network with over 100 replicas achieves\nthroughput and latency comparable to that of BFT-SMaRt, while enjoying linear\ncommunication footprint during leader failover (vs. quadratic with BFT-SMaRt). \n\n"}
{"id": "1803.05587", "contents": "Title: Micky: A Cheaper Alternative for Selecting Cloud Instances Abstract: Most cloud computing optimizers explore and improve one workload at a time.\nWhen optimizing many workloads, the single-optimizer approach can be\nprohibitively expensive. Accordingly, we examine \"collective optimizer\" that\nconcurrently explore and improve a set of workloads significantly reducing the\nmeasurement costs. Our large-scale empirical study shows that there is often a\nsingle cloud configuration which is surprisingly near-optimal for most\nworkloads. Consequently, we create a collective-optimizer, MICKY, that\nreformulates the task of finding the near-optimal cloud configuration as a\nmulti-armed bandit problem. MICKY efficiently balances exploration (of new\ncloud configurations) and exploitation (of known good cloud configuration). Our\nexperiments show that MICKY can achieve on average 8.6 times reduction in\nmeasurement cost as compared to the state-of-the-art method while finding\nnear-optimal solutions.\n  Hence we propose MICKY as the basis of a practical collective optimization\nmethod for finding good cloud configurations (based on various constraints such\nas budget and tolerance to near-optimal configurations). \n\n"}
{"id": "1803.06061", "contents": "Title: Inverse Design of Compact Multimode Cavity Couplers Abstract: Efficient coupling between on-chip sources and cavities plays a key role in\nsilicon photonics. However, despite the importance of this basic functionality,\nthere are few systematic design tools to simultaneously control coupling\nbetween multiple modes in a compact resonator and a single waveguide. Here, we\npropose a large-scale adjoint optimization approach to produce wavelength-scale\nwaveguide--cavity couplers operating over tunable and broad frequency bands. We\nnumerically demonstrate couplers discovered by this method that can achieve\ncritical, or nearly critical, coupling between multi-ring cavities and a single\nwaveguide at up to six widely separated wavelengths spanning the\n$560$--$1500$~nm range of interest for on-chip nonlinear optical devices. \n\n"}
{"id": "1803.06333", "contents": "Title: Snap ML: A Hierarchical Framework for Machine Learning Abstract: We describe a new software framework for fast training of generalized linear\nmodels. The framework, named Snap Machine Learning (Snap ML), combines recent\nadvances in machine learning systems and algorithms in a nested manner to\nreflect the hierarchical architecture of modern computing systems. We prove\ntheoretically that such a hierarchical system can accelerate training in\ndistributed environments where intra-node communication is cheaper than\ninter-node communication. Additionally, we provide a review of the\nimplementation of Snap ML in terms of GPU acceleration, pipelining,\ncommunication patterns and software architecture, highlighting aspects that\nwere critical for achieving high performance. We evaluate the performance of\nSnap ML in both single-node and multi-node environments, quantifying the\nbenefit of the hierarchical scheme and the data streaming functionality, and\ncomparing with other widely-used machine learning software frameworks. Finally,\nwe present a logistic regression benchmark on the Criteo Terabyte Click Logs\ndataset and show that Snap ML achieves the same test loss an order of magnitude\nfaster than any of the previously reported results, including those obtained\nusing TensorFlow and scikit-learn. \n\n"}
{"id": "1803.06341", "contents": "Title: Distributed Transactions: Dissecting the Nightmare Abstract: Many distributed storage systems are transactional and a lot of work has been\ndevoted to optimizing their performance, especially the performance of\nread-only transactions that are considered the most frequent in practice. Yet,\nthe results obtained so far are rather disappointing, and some of the design\ndecisions seem contrived. This paper contributes to explaining this state of\naffairs by proving intrinsic limitations of transactional storage systems, even\nthose that need not ensure strong consistency but only causality.\n  We first consider general storage systems where some transactions are\nread-only and some also involve write operations. We show that even read-only\ntransactions cannot be \"fast\": their operations cannot be executed within one\nround-trip message exchange between a client seeking an object and the server\nstoring it. We then consider systems (as sometimes implemented today) where all\ntransactions are read-only, i.e., updates are performed as individual\noperations outside transactions. In this case, read-only transactions can\nindeed be \"fast\", but we prove that they need to be \"visible\". They induce\ninherent updates on the servers, which in turn impact their overall\nperformance. \n\n"}
{"id": "1803.07588", "contents": "Title: A Push-Pull Gradient Method for Distributed Optimization in Networks Abstract: In this paper, we focus on solving a distributed convex optimization problem\nin a network, where each agent has its own convex cost function and the goal is\nto minimize the sum of the agents' cost functions while obeying the network\nconnectivity structure. In order to minimize the sum of the cost functions, we\nconsider a new distributed gradient-based method where each node maintains two\nestimates, namely, an estimate of the optimal decision variable and an estimate\nof the gradient for the average of the agents' objective functions. From the\nviewpoint of an agent, the information about the decision variable is pushed to\nthe neighbors, while the information about the gradients is pulled from the\nneighbors (hence giving the name \"push-pull gradient method\"). The method\nunifies the algorithms with different types of distributed architecture,\nincluding decentralized (peer-to-peer), centralized (master-slave), and\nsemi-centralized (leader-follower) architecture. We show that the algorithm\nconverges linearly for strongly convex and smooth objective functions over a\ndirected static network. In our numerical test, the algorithm performs well\neven for time-varying directed networks. \n\n"}
{"id": "1803.07667", "contents": "Title: Edgeworth expansions for weakly dependent random variables Abstract: We discuss sufficient conditions that guarantee the existence of asymptotic\nexpansions for the Central Limit Theorem for weakly dependent random variables\nincluding observations arising from sufficiently chaotic dynamical systems like\npiece-wise expanding maps, and strongly ergodic Markov chains. We primarily use\nspectral techniques to obtain the results. \n\n"}
{"id": "1803.07877", "contents": "Title: A Case Study for Grain Quality Assurance Tracking based on a Blockchain\n  Business Network Abstract: One of the key processes in Agriculture is quality measurement throughout the\ntransportation of grains along its complex supply chain. This procedure is\nsuitable for failures, such as delays to final destinations, poor monitoring,\nand frauds. To address the grain quality measurement challenge through the\ntransportation chain, novel technologies, such as Distributed Ledger and\nBlockchain, can bring more efficiency and resilience to the process.\nParticularly, Blockchain is a new type of distributed database in which\ntransactions are securely appended using cryptography and hashed pointers.\nThose transactions can be generated and ruled by special network-embedded\nsoftware -- known as smart contracts -- that may be public to all nodes of the\nnetwork or may be private to a specific set of peer nodes. This paper analyses\nthe implementation of Blockchain technology targeting grain quality assurance\ntracking in a real scenario. Preliminary results support a potential demand for\na Blockchain-based certification that would lead to an added valuation of\naround 15% for GM-free soy in the scope of a Grain Exporter Business Network in\nBrazil. \n\n"}
{"id": "1803.08189", "contents": "Title: Can Decentralized Status Update Achieve Universally Near-Optimal\n  Age-of-Information in Wireless Multiaccess Channels? Abstract: In an Internet-of-Things system where status data are collected from sensors\nand actuators for time-critical applications, the freshness of data is vital\nand can be quantified by the recently proposed age-of-information (AoI) metric.\nIn this paper, we first consider a general scenario where multiple terminals\nshare a common channel to transmit or receive randomly generated status\npackets. The optimal scheduling problem to minimize AoI is formulated as a\nrestless multi-armed bandit problem. To solve the problem efficiently, we\nderive the Whittle's index in closed-form and establish the indexability\nthereof. Compared with existing work, we extend the index policy for AoI\noptimization to incorporate stochastic packet arrivals and optimal packet\nmanagement (buffering the latest packet). Inspired by the index policy which\nhas near-optimal performance but is centralized by nature, a decentralized\nstatus update scheme, i.e., the index-prioritized random access policy (IPRA),\nis further proposed, achieving universally near-optimal AoI performance and\noutperforming state-of-the-arts in the literature. \n\n"}
{"id": "1803.08246", "contents": "Title: Time-resolved quantum spin transport through an Aharonov-Casher ring Abstract: After obtaining an exact analytical time-varying solution for the\nAharonov-Casher conducting ring embedded in a textured static/dynamic electric\nfield, we investigate the spin-resolved quantum transport in the structure. It\nis shown that the interference patterns are governed by not only the\nAharonov-Casher geometry phase but also the instantaneous phase difference of\nspin precession through different traveling paths. This dynamic phase is\ndetermined by the strength of applied electric field and can have substantial\neffects on the charge/spin conductances, especially in the weak field regime as\nthe period of spin precession comparable to that of the orbital motion. Our\nstudies suggest that a low-frequency normal electric field with moderate\nstrength possesses more degrees of freedom for manipulating the spin\ninterference of incident electrons. \n\n"}
{"id": "1803.08568", "contents": "Title: Securing the Control-plane Channel and Cache of Pull-based ID/LOC\n  Protocols Abstract: Pull-based ID/LOC split protocols, such as LISP (RFC6830), retrieve mappings\nfrom a mapping system to encapsulate and forward packets. This is done by means\nof a control-plane channel. In this short paper we describe three attacks\nagainst this channel (Denial-of-Service and overflowing) as well as the against\nthe local cache used to store such mappings. We also provide a solution against\nsuch attacks that implements a per-source rate-limiter using a Count-Min Sketch\ndata-structure. \n\n"}
{"id": "1803.08690", "contents": "Title: Polariton hyperspectral imaging of two-dimensional semiconductor\n  crystals Abstract: Atomically thin crystals of transition metal dichalcogenides (TMDs) host\nexcitons with strong binding energies and sizable light-matter interactions.\nCoupled to optical cavities, monolayer TMDs routinely reach the regime of\nstrong light-matter coupling, where excitons and photons admix coherently to\nform quasiparticles known as polaritons up to room temperature. Here, we\nexplore the two-dimensional nature of TMD polaritons with cavity-assisted\nhyperspectral imaging. Using extended WS$_2$ monolayers, we establish the\nregime of strong coupling with a scanning microcavity to map out polariton\nproperties and correlate their spatial features with intrinsic and extrinsic\neffects. We find a high level of homogeneity, and show that polariton splitting\nvariations are correlated with intrinsic exciton properties such as oscillator\nstrength and linewidth. Moreover, we observe a deviation from thermal\nequilibrium in the resonant polariton population, which we ascribe to\nnon-perturbative polariton-phonon coupling. Our measurements reveal a\npromisingly consistent polariton landscape, and highlight the importance of\nphonons for future polaritonic devices. \n\n"}
{"id": "1803.08833", "contents": "Title: Gaussian and exponential lateral connectivity on distributed spiking\n  neural network simulation Abstract: We measured the impact of long-range exponentially decaying intra-areal\nlateral connectivity on the scaling and memory occupation of a distributed\nspiking neural network simulator compared to that of short-range Gaussian\ndecays. While previous studies adopted short-range connectivity, recent\nexperimental neurosciences studies are pointing out the role of longer-range\nintra-areal connectivity with implications on neural simulation platforms.\nTwo-dimensional grids of cortical columns composed by up to 11 M point-like\nspiking neurons with spike frequency adaption were connected by up to 30 G\nsynapses using short- and long-range connectivity models. The MPI processes\ncomposing the distributed simulator were run on up to 1024 hardware cores,\nhosted on a 64 nodes server platform. The hardware platform was a cluster of\nIBM NX360 M5 16-core compute nodes, each one containing two Intel Xeon Haswell\n8-core E5-2630 v3 processors, with a clock of 2.40 G Hz, interconnected through\nan InfiniBand network, equipped with 4x QDR switches. \n\n"}
{"id": "1804.00399", "contents": "Title: Towards Scaling Blockchain Systems via Sharding Abstract: Existing blockchain systems scale poorly because of their distributed\nconsensus protocols. Current attempts at improving blockchain scalability are\nlimited to cryptocurrency. Scaling blockchain systems under general workloads\n(i.e., non-cryptocurrency applications) remains an open question. In this work,\nwe take a principled approach to apply sharding, which is a well-studied and\nproven technique to scale out databases, to blockchain systems in order to\nimprove their transaction throughput at scale. This is challenging, however,\ndue to the fundamental difference in failure models between databases and\nblockchain. To achieve our goal, we first enhance the performance of Byzantine\nconsensus protocols, by doing so we improve individual shards' throughput.\nNext, we design an efficient shard formation protocol that leverages a trusted\nrandom beacon to securely assign nodes into shards. We rely on trusted\nhardware, namely Intel SGX, to achieve high performance for both consensus and\nshard formation protocol. Third, we design a general distributed transaction\nprotocol that ensures safety and liveness even when transaction coordinators\nare malicious. Finally, we conduct an extensive evaluation of our design both\non a local cluster and on Google Cloud Platform. The results show that our\nconsensus and shard formation protocols outperform state-of-the-art solutions\nat scale. More importantly, our sharded blockchain reaches a high throughput\nthat can handle Visa-level workloads, and is the largest ever reported in a\nrealistic environment. \n\n"}
{"id": "1804.02486", "contents": "Title: Evaluating virtual hosted desktops for graphics-intensive astronomy Abstract: Visualisation of data is critical to understanding astronomical phenomena.\nToday, many instruments produce datasets that are too big to be downloaded to a\nlocal computer, yet many of the visualisation tools used by astronomers are\ndeployed only on desktop computers. Cloud computing is increasingly used to\nprovide a computation and simulation platform in astronomy, but it also offers\ngreat potential as a visualisation platform. Virtual hosted desktops, with\ngraphics processing unit (GPU) acceleration, allow interactive,\ngraphics-intensive desktop applications to operate co-located with astronomy\ndatasets stored in remote data centres. By combining benchmarking and user\nexperience testing, with a cohort of 20 astronomers, we investigate the\nviability of replacing physical desktop computers with virtual hosted desktops.\nIn our work, we compare two Apple MacBook computers (one old and one new,\nrepresenting hardware and opposite ends of the useful lifetime) with two\nvirtual hosted desktops: one commercial (Amazon Web Services) and one in a\nprivate research cloud (the Australian Nectar Research Cloud). For\ntwo-dimensional image-based tasks and graphics-intensive three-dimensional\noperations -- typical of astronomy visualisation workflows -- we found that\nbenchmarks do not necessarily provide the best indication of performance. When\ncompared to typical laptop computers, virtual hosted desktops can provide a\nbetter user experience, even with lower performing graphics cards. We also\nfound that virtual hosted desktops are equally simple to use, provide greater\nflexibility in choice of configuration, and may actually be a more\ncost-effective option for typical usage profiles. \n\n"}
{"id": "1804.04864", "contents": "Title: Polarimetry with POLAR Abstract: In the first half year of operation the satellite borne POLAR instrument\ndetected a total of 55 Gamma-Ray Bursts about 10 of which were bright enough to\nallow for detailed polarization studies, thereby forming the start of the first\nGamma-Ray Burst polarization catalog. In this paper a brief overview of the\nprevious GRB polarization studies will be presented followed by an overview of\nthe POLAR detector along with the first result of the in-flight performance.\nThe detected Gamma-Ray bursts will be presented and finally prospects for\npolarization measurements of these events will be discussed. \n\n"}
{"id": "1804.05271", "contents": "Title: Adaptive Federated Learning in Resource Constrained Edge Computing\n  Systems Abstract: Emerging technologies and applications including Internet of Things (IoT),\nsocial networking, and crowd-sourcing generate large amounts of data at the\nnetwork edge. Machine learning models are often built from the collected data,\nto enable the detection, classification, and prediction of future events. Due\nto bandwidth, storage, and privacy concerns, it is often impractical to send\nall the data to a centralized location. In this paper, we consider the problem\nof learning model parameters from data distributed across multiple edge nodes,\nwithout sending raw data to a centralized place. Our focus is on a generic\nclass of machine learning models that are trained using gradient-descent based\napproaches. We analyze the convergence bound of distributed gradient descent\nfrom a theoretical point of view, based on which we propose a control algorithm\nthat determines the best trade-off between local update and global parameter\naggregation to minimize the loss function under a given resource budget. The\nperformance of the proposed algorithm is evaluated via extensive experiments\nwith real datasets, both on a networked prototype system and in a larger-scale\nsimulated environment. The experimentation results show that our proposed\napproach performs near to the optimum with various machine learning models and\ndifferent data distributions. \n\n"}
{"id": "1804.05614", "contents": "Title: Search for Extensive Photon Cascades with the Cosmic-Ray Extremely\n  Distributed Observatory Abstract: Although the photon structure is most efficiently studied with the\naccelerator instruments, there is also a scientifically complementary potential\nin investigations on photons produced in the outer space. This potential is\nalready being explored with gamma ray telescopes, ultra-high energy cosmic ray\nobservatories and, since very recently, by the Cosmic-Ray Extremely Distributed\nObservatory (CREDO). Unlike the former instruments focused on detection of\nsingle photons, CREDO aims at the detection of cascades (ensembles) of photons\noriginating even at astrophysical distances. If at least a part of such a\ncascade reaches Earth, it might produce a unique pattern composed of a number\nof air showers observable by an appropriately dense array of standard\ndetectors. If the energies of air showers constituting the pattern are\nrelatively low and if the typical distances between the neighbors are large,\nthe ensemble character of the whole phenomenon might remain uncovered, unless\nthe CREDO strategy is implemented. \n\n"}
{"id": "1804.06568", "contents": "Title: Walkman: A Communication-Efficient Random-Walk Algorithm for\n  Decentralized Optimization Abstract: This paper addresses consensus optimization problems in a multi-agent\nnetwork, where all agents collaboratively find a minimizer for the sum of their\nprivate functions. We develop a new decentralized algorithm in which each agent\ncommunicates only with its neighbors.\n  State-of-the-art decentralized algorithms use communications between either\nall pairs of adjacent agents or a random subset of them at each iteration.\nAnother class of algorithms uses a random walk incremental strategy, which\nsequentially activates a succession of nodes; these incremental algorithms\nrequire diminishing step sizes to converge to the solution, so their\nconvergence is relatively slow.\n  In this work, we propose a random walk algorithm that uses a fixed step size\nand converges faster than the existing random walk incremental algorithms. Our\nalgorithm is also communication efficient. Each iteration uses only one link to\ncommunicate the latest information for an agent to another. Since this\ncommunication rule mimics a man walking around the network, we call our new\nalgorithm Walkman. We establish convergence for convex and nonconvex\nobjectives. For decentralized least squares, we derive a linear rate of\nconvergence and obtain a better communication complexity than those of other\ndecentralized algorithms. Numerical experiments verify our analysis results. \n\n"}
{"id": "1804.07356", "contents": "Title: Challenges and pitfalls of partitioning blockchains Abstract: Blockchain has received much attention in recent years. This immense\npopularity has raised a number of concerns, scalability of blockchain systems\nbeing a common one. In this paper, we seek to understand how Ethereum, a\nwell-established blockchain system, would respond to sharding. Sharding is a\nprevalent technique to increase the scalability of distributed systems. To\nunderstand how sharding would affect Ethereum, we model Ethereum blockchain as\na graph and evaluate five methods to partition the graph. We analyze the\nresults using three metrics: the balance among shards, the number of\ntransactions that would involve multiple shards, and the amount of data that\nwould be relocated across shards upon a repartitioning of the system. \n\n"}
{"id": "1804.07598", "contents": "Title: OpenFPM: A scalable open framework for particle and particle-mesh codes\n  on parallel computers Abstract: Scalable and efficient numerical simulations continue to gain importance, as\ncomputation is firmly established as the third pillar of discovery, alongside\ntheory and experiment. Meanwhile, the performance of computing hardware grows\nthrough increasing heterogeneous parallelism, enabling simulations of ever more\ncomplex models. However, efficiently implementing scalable codes on\nheterogeneous, distributed hardware systems becomes the bottleneck. This\nbottleneck can be alleviated by intermediate software layers that provide\nhigher-level abstractions closer to the problem domain, hence allowing the\ncomputational scientist to focus on the simulation. Here, we present OpenFPM,\nan open and scalable framework that provides an abstraction layer for numerical\nsimulations using particles and/or meshes. OpenFPM provides transparent and\nscalable infrastructure for shared-memory and distributed-memory\nimplementations of particles-only and hybrid particle-mesh simulations of both\ndiscrete and continuous models, as well as non-simulation codes. This\ninfrastructure is complemented with portable implementations of frequently used\nnumerical routines, as well as interfaces to third-party libraries. We present\nthe architecture and design of OpenFPM, detail the underlying abstractions, and\nbenchmark the framework in applications ranging from Smoothed-Particle\nHydrodynamics (SPH) to Molecular Dynamics (MD), Discrete Element Methods (DEM),\nVortex Methods, stencil codes, high-dimensional Monte Carlo sampling (CMA-ES),\nand Reaction-Diffusion solvers, comparing it to the current state of the art\nand existing software frameworks. \n\n"}
{"id": "1804.08265", "contents": "Title: Deterministic and Randomized Diffusion based Iterative Generalized Hard\n  Thresholding (DiFIGHT) for Distributed Sparse Signal Recovery Abstract: In this paper we propose a distributed iterated hard thresholding algorithm\ntermed DiFIGHT over a network that is built on the diffusion mechanism and also\npropose a modification of the proposed algorithm, termed MoDiFIGHT, that has\nlow complexity in terms of communication in the network. We additionally\npropose four different strategies termed RP, RNP, RGP$_r$, and RGNP$_r$ that\nare used to randomly select a subset of nodes that are subsequently activated\nto take part in the distributed algorithm, so as to reduce the mean number of\ncommunications during the run of the distributed algorithm. We present\ntheoretical estimates of the long run communication per unit time for these\ndifferent strategies, when used by the two proposed algorithms. Also, we\npresent analysis of the two proposed algorithms and provide provable bounds on\ntheir recovery performance with or without using the random node selection\nstrategies. Finally we use numerical studies to show that both when the random\nstrategies are used as well as when they are not used, the proposed algorithms\ndisplay performances far superior to distributed IHT algorithm using consensus\nmechanism . \n\n"}
{"id": "1804.08548", "contents": "Title: Eigenvector Computation and Community Detection in Asynchronous Gossip\n  Models Abstract: We give a simple distributed algorithm for computing adjacency matrix\neigenvectors for the communication graph in an asynchronous gossip model. We\nshow how to use this algorithm to give state-of-the-art asynchronous community\ndetection algorithms when the communication graph is drawn from the\nwell-studied stochastic block model. Our methods also apply to a natural\nalternative model of randomized communication, where nodes within a community\ncommunicate more frequently than nodes in different communities. Our analysis\nsimplifies and generalizes prior work by forging a connection between\nasynchronous eigenvector computation and Oja's algorithm for streaming\nprincipal component analysis. We hope that our work serves as a starting point\nfor building further connections between the analysis of stochastic iterative\nmethods, like Oja's algorithm, and work on asynchronous and gossip-type\nalgorithms for distributed computation. \n\n"}
{"id": "1804.08787", "contents": "Title: Price and Performance of Cloud-hosted Virtual Network Functions:\n  Analysis and Future Challenges Abstract: The concept of Network Function Virtualization (NFV) has been introduced as a\nnew paradigm in the recent few years. NFV offers a number of benefits including\nsignificantly increased maintainability and reduced deployment overhead.\nSeveral works have been done to optimize deployment (also called embedding) of\nvirtual network functions (VNFs). However, no work to date has looked into\noptimizing the selection of cloud instances for a given VNF and its specific\nrequirements. In this paper, we evaluate the performance of VNFs when embedded\non different Amazon EC2 cloud instances. Specifically, we evaluate three VNFs\n(firewall, IDS, and NAT) in terms of arrival packet rate, resources\nutilization, and packet loss. Our results indicate that performance varies\nacross instance types, departing from the intuition of \"you get what you pay\nfor\" with cloud instances. We also find out that CPU is the critical resource\nfor the tested VNFs, although their peak packet processing capacities differ\nconsiderably from each other. Finally, based on the obtained results, we\nidentify key research challenges related to VNF instance selection and service\nchain provisioning. \n\n"}
{"id": "1804.09494", "contents": "Title: On Optimizing Distributed Tucker Decomposition for Sparse Tensors Abstract: The Tucker decomposition generalizes the notion of Singular Value\nDecomposition (SVD) to tensors, the higher dimensional analogues of matrices.\nWe study the problem of constructing the Tucker decomposition of sparse tensors\non distributed memory systems via the HOOI procedure, a popular iterative\nmethod. The scheme used for distributing the input tensor among the processors\n(MPI ranks) critically influences the HOOI execution time. Prior work has\nproposed different distribution schemes: an offline scheme based on\nsophisticated hypergraph partitioning method and simple, lightweight\nalternatives that can be used real-time. While the hypergraph based scheme\ntypically results in faster HOOI execution time, being complex, the time taken\nfor determining the distribution is an order of magnitude higher than the\nexecution time of a single HOOI iteration. Our main contribution is a\nlightweight distribution scheme, which achieves the best of both worlds. We\nshow that the scheme is near-optimal on certain fundamental metrics associated\nwith the HOOI procedure and as a result, near-optimal on the computational load\n(FLOPs). Though the scheme may incur higher communication volume, the\ncomputation time is the dominant factor and as the result, the scheme achieves\nbetter performance on the overall HOOI execution time. Our experimental\nevaluation on large real-life tensors (having up to 4 billion elements) shows\nthat the scheme outperforms the prior schemes on the HOOI execution time by a\nfactor of up to 3x. On the other hand, its distribution time is comparable to\nthe prior lightweight schemes and is typically lesser than the execution time\nof a single HOOI iteration. \n\n"}
{"id": "1804.09536", "contents": "Title: Fast parallel multidimensional FFT using advanced MPI Abstract: We present a new method for performing global redistributions of\nmultidimensional arrays essential to parallel fast Fourier (or similar)\ntransforms. Traditional methods use standard all-to-all collective\ncommunication of contiguous memory buffers, thus necessary requiring local data\nrealignment steps intermixed in-between redistribution and transform steps.\nInstead, our method takes advantage of subarray datatypes and generalized\nall-to-all scatter/gather from the MPI-2 standard to communicate discontiguous\nmemory buffers, effectively eliminating the need for local data realignments.\nDespite generalized all-to-all communication of discontiguous data being\ngenerally slower, our proposal economizes in local work. For a range of strong\nand weak scaling tests, we found the overall performance of our method to be on\npar and often better than well-established libraries like MPI-FFTW, P3DFFT, and\n2DECOMP&FFT. We provide compact routines implemented at the highest possible\nlevel using the MPI bindings for the C programming language. These routines\napply to any global redistribution, over any two directions of a\nmultidimensional array, decomposed on arbitrary Cartesian processor grids (1D\nslabs, 2D pencils, or even higher-dimensional decompositions). The high level\nimplementation makes the code easy to read, maintain, and eventually extend.\nOur approach enables for future speedups from optimizations in the internal\ndatatype handling engines within MPI implementations. \n\n"}
{"id": "1804.10140", "contents": "Title: Securing Distributed Gradient Descent in High Dimensional Statistical\n  Learning Abstract: We consider unreliable distributed learning systems wherein the training data\nis kept confidential by external workers, and the learner has to interact\nclosely with those workers to train a model. In particular, we assume that\nthere exists a system adversary that can adaptively compromise some workers;\nthe compromised workers deviate from their local designed specifications by\nsending out arbitrarily malicious messages.\n  We assume in each communication round, up to $q$ out of the $m$ workers\nsuffer Byzantine faults. Each worker keeps a local sample of size $n$ and the\ntotal sample size is $N=nm$. We propose a secured variant of the gradient\ndescent method that can tolerate up to a constant fraction of Byzantine\nworkers, i.e., $q/m = O(1)$. Moreover, we show the statistical estimation error\nof the iterates converges in $O(\\log N)$ rounds to $O(\\sqrt{q/N} +\n\\sqrt{d/N})$, where $d$ is the model dimension. As long as $q=O(d)$, our\nproposed algorithm achieves the optimal error rate $O(\\sqrt{d/N})$. Our results\nare obtained under some technical assumptions. Specifically, we assume\nstrongly-convex population risk. Nevertheless, the empirical risk (sample\nversion) is allowed to be non-convex. The core of our method is to robustly\naggregate the gradients computed by the workers based on the filtering\nprocedure proposed by Steinhardt et al. On the technical front, deviating from\nthe existing literature on robustly estimating a finite-dimensional mean\nvector, we establish a {\\em uniform} concentration of the sample covariance\nmatrix of gradients, and show that the aggregated gradient, as a function of\nmodel parameter, converges uniformly to the true gradient function. To get a\nnear-optimal uniform concentration bound, we develop a new matrix concentration\ninequality, which might be of independent interest. \n\n"}
{"id": "1804.10394", "contents": "Title: Why are classical bulges more common in S0 galaxies than in spiral\n  galaxies? Abstract: In this paper, we try to understand why the classical bulge fraction observed\nin S0 galaxies is significantly higher than that in spiral galaxies. We carry\nout a comparative study of the bulge and global properties of a sample of\nspiral and S0 galaxies in a fixed environment. Our sample is flux limited and\ncontains 262 spiral and 155 S0 galaxies drawn from the Sloan Digital Sky\nSurvey. We have classified bulges into classical and pseudobulge categories\nbased on their position on the Kormendy diagram. Dividing our sample into bins\nof galaxy stellar mass, we find that the fraction of S0 galaxies hosting a\nclassical bulge is significantly higher than the classical bulge fraction seen\nin spirals even at fixed stellar mass. We have compared the bulge and the\nglobal properties of spirals and S0 galaxies in our sample and find indications\nthat spiral galaxies which host a classical bulge, preferentially get converted\ninto S0 population as compared to pseudobulge hosting spirals. By studying the\nstar formation properties of our galaxies in the NUV-r color-mass diagram, we\nfind that the pseudobulge hosting spirals are mostly star forming while the\nmajority of classical bulge host spirals are in the green valley or in the\npassive sequence. We suggest that some internal process, such as AGN feedback\nor morphological quenching due to the massive bulge, quenches these classical\nbulge hosting spirals and transforms them into S0 galaxies, thus resulting in\nthe observed predominance of the classical bulge in S0 galaxies. \n\n"}
{"id": "1804.10654", "contents": "Title: Resolving SINR Queries in a Dynamic Setting Abstract: We consider a set of transmitters broadcasting simultaneously on the same\nfrequency under the SINR model. Transmission power may vary from one\ntransmitter to another, and a transmitter's signal strength at a given point is\nmodeled by the transmitter's power divided by some constant power $\\alpha$ of\nthe distance it traveled. Roughly, a receiver at a given location can hear a\nspecific transmitter only if the transmitter's signal is stronger by a\nspecified ratio than the signals of all other transmitters combined. An SINR\nquery is to determine whether a receiver at a given location can hear any\ntransmitter, and if yes, which one.\n  An approximate answer to an SINR query is such that one gets a definite YES\nor definite NO, when the ratio between the strongest signal and all other\nsignals combined is well above or well below the reception threshold, while the\nanswer in the intermediate range is allowed to be either YES or NO.\n  We describe compact data structures that support approximate SINR queries in\nthe plane in a dynamic context, i.e., where transmitters may be inserted and\ndeleted over time. We distinguish between two main variants --- uniform power\nand non-uniform power. In both variants the preprocessing time is $O(n\n\\mathop{\\textrm{polylog}} n)$ and the amortized update time is\n$O(\\mathop{\\textrm{polylog}} n)$, while the query time is\n$O(\\mathop{\\textrm{polylog}} n)$ for uniform power, and randomized time\n$O(\\sqrt{n} \\mathop{\\textrm{polylog}} n)$ with high probability for non-uniform\npower.\n  Finally, we observe that in the static context the latter data structure can\nbe implemented differently, so that the query time is also\n$O(\\mathop{\\textrm{polylog}} n)$, thus significantly improving all previous\nresults for this problem. \n\n"}
{"id": "1805.00004", "contents": "Title: Maximum Likelihood Coordinate Systems for Wireless Sensor Networks: from\n  physical coordinates to topology coordinates Abstract: Many WSN protocols require the location coordinates of the sensor nodes, as\nit is useful to consider the data collected by the sensors in the context of\nthe location from which they were collected. Thus, one of the major challenges\nin WSNs is to determine the coordinates of sensors while minimizing the\nhardware cost. To address this, numerous localization algorithms have been\nproposed in the literature. However, outcomes of these algorithms are affected\nby noise, fading, and interference. As a result, their levels of accuracy may\nbecome unacceptable in complex environments that contain obstacles and\nreflecting surfaces. The alternative is to use topological maps based only on\nconnectivity information. Since they do not contain information about physical\ndistances, however, they are not faithful representatives of the physical\nlayout. Thus, the primary goal of this research is to discover a topology map\nthat provides more accurate information about physical layouts. In doing so,\nthis research has resulted in four main contributions. First, a novel concept\nMaximum-Likelihood Topology Map for RF WSNs is presented. This topology map\nprovides a more accurate physical representation, by using the probability of\npacket reception. The second contribution is Millimetre wave Topology Map\ncalculation, which is a novel topology mapping algorithm based on maximum\nlikelihood estimation for millimetre wave WSNs. The third contribution is a\ndistributed algorithm being proposed to calculate the topology coordinates of\nsensors by themselves as two algorithms above calculate centrally, which\nrequires time. Since a topology map contains significant non-linear\ndistortions, two WSN applications i.e. target searching and extremum seeking,\nwhich use a proposed topology map to localize the sensors and perform its\nspecified task are presented as the final contribution of this dissertation. \n\n"}
{"id": "1805.00626", "contents": "Title: On and Off-Blockchain Enforcement Of Smart Contracts Abstract: In this paper we discuss how conventional business contracts can be converted\ninto smart contracts---their electronic equivalents that can be used to\nsystematically monitor and enforce contractual rights, obligations and\nprohibitions at run time. We explain that emerging blockchain technology is\ncertainly a promising platform for implementing smart contracts but argue that\nthere is a large class of applications, where blockchain is inadequate due to\nperformance, scalability, and consistency requirements, and also due to\nlanguage expressiveness and cost issues that are hard to solve. We explain that\nin some situations a centralised approach that does not rely on blockchain is a\nbetter alternative due to its simplicity, scalability, and performance. We\nsuggest that in applications where decentralisation and transparency are\nessential, developers can advantageously combine the two approaches into hybrid\nsolutions where some operations are enforced by enforcers deployed\non--blockchains and the rest by enforcers deployed on trusted third parties. \n\n"}
{"id": "1805.01081", "contents": "Title: LedgerGuard: Improving Blockchain Ledger Dependability Abstract: The rise of crypto-currencies has spawned great interest in their underlying\ntechnology, namely, Blockchain. The central component in a Blockchain is a\nshared distributed ledger. A ledger comprises series of blocks, which in turns\ncontains a series of transactions. An identical copy of the ledger is stored on\nall nodes in a blockchain network. Maintaining ledger integrity and security is\none of the crucial design aspects of any blockchain platform. Thus, there are\ntypically built-in validation mechanisms leveraging cryptography to ensure the\nvalidity of incoming blocks before committing them into the ledger. However, a\nblockchain node may run over an extended period of time, during which the\nblocks on the disk can may become corrupted due to software or hardware\nfailures, or due to malicious activity. This paper proposes LedgerGuard, a tool\nto maintain ledger integrity by detecting corrupted blocks and recovering these\nblocks by synchronizing with rest of the network. The experimental\nimplementation of LedgerGuard is based on Hyperledger Fabric, which is a\npopular open source permissioned blockchain platform. \n\n"}
{"id": "1805.01559", "contents": "Title: Computational Optimal Transport for 5G Massive C-RAN Device Association Abstract: The massive scale of future wireless networks will create computational\nbottlenecks in performance optimization. In this paper, we study the problem of\nconnecting mobile traffic to Cloud RAN (C-RAN) stations. To balance station\nload, we steer the traffic by designing device association rules. The baseline\nassociation rule connects each device to the station with the strongest signal,\nwhich does not account for interference or traffic hot spots, and leads to load\nimbalances and performance deterioration. Instead, we can formulate an\noptimization problem to decide centrally the best association rule at each time\ninstance. However, in practice this optimization has such high dimensions, that\neven linear programming solvers fail to solve. To address the challenge of\nmassive connectivity, we propose an approach based on the theory of optimal\ntransport, which studies the economical transfer of probability between two\ndistributions. Our proposed methodology can further inspire scalable algorithms\nfor massive optimization problems in wireless networks. \n\n"}
{"id": "1805.01715", "contents": "Title: 5G Island for Network Resilience and Autonomous Failsafe Operations Abstract: The resilience of 5G networks can be strongly challenged by central cloud\nvirtual network function (VNF) outages, which can be cause by server and\nbackhaul connection errors. This paper proposes a context-aware approach to\nmigrate VNF from central cloud to local edge cloud, in order to improve the\nnetwork resilience with minimized VNF migration cost. \n\n"}
{"id": "1805.01768", "contents": "Title: Work Stealing with latency Abstract: We study in this paper the impact of communication latency on the classical\nWork Stealing load balancing algorithm. Our approach considers existing\nperformance models and the underlying algorithms. We introduce a latency\nparameter in the model and study its overall impact by careful observations of\nsimulation results. Using this method we are able to derive a new expression of\nthe expected running time of divisible load applications. This expression\nenables us to predict under which conditions a given run will yield acceptable\nperformance. For instance, we can easily calibrate the maximal number of\nprocessors one should use for a given work platform combination. We also\nconsider the impact of several algorithmic variants like simultaneous transfers\nof work or thresholds for avoiding useless transfers. All our results are\nvalidated through simulation on a wide range of parameters. \n\n"}
{"id": "1805.01993", "contents": "Title: Compressed Coded Distributed Computing Abstract: Communication overhead is one of the major performance bottlenecks in\nlarge-scale distributed computing systems, in particular for machine learning\napplications. Conventionally, compression techniques are used to reduce the\nload of communication by combining intermediate results of the same computation\ntask as much as possible. Recently, via the development of coded distributed\ncomputing (CDC), it has been shown that it is possible to enable coding\nopportunities across intermediate results of different computation tasks to\nfurther reduce the communication load. We propose a new scheme, named\ncompressed coded distributed computing (in short, compressed CDC), which\njointly exploits the above two techniques (i.e., combining the intermediate\nresults of the same computation and coding across the intermediate results of\ndifferent computations) to significantly reduce the communication load for\ncomputations with linear aggregation (reduction) of intermediate results in the\nfinal stage that are prevalent in machine learning (e.g., distributed training\nalgorithms where partial gradients are computed distributedly and then averaged\nin the final stage). In particular, compressed CDC first compresses/combines\nseveral intermediate results for a single computation, and then utilizes\nmultiple such combined packets to create a coded multicast packet that is\nsimultaneously useful for multiple computations. We characterize the achievable\ncommunication load of compressed CDC and show that it substantially outperforms\nboth combining methods and CDC scheme. \n\n"}
{"id": "1805.02797", "contents": "Title: eBPF-based Content and Computation-aware Communication for Real-time\n  Edge Computing Abstract: By placing computation resources within a one-hop wireless topology, the\nrecent edge computing paradigm is a key enabler of real-time Internet of Things\n(IoT) applications. In the context of IoT scenarios where the same information\nfrom a sensor is used by multiple applications at different locations, the data\nstream needs to be replicated. However, the transportation of parallel streams\nmight not be feasible due to limitations in the capacity of the network\ntransporting the data. To address this issue, a content and computation-aware\ncommunication control framework is proposed based on the Software Defined\nNetwork (SDN) paradigm. The framework supports multi-streaming using the\nextended Berkeley Packet Filter (eBPF), where the traffic flow and packet\nreplication for each specific computation process is controlled by a program\nrunning inside an in-kernel Virtual Ma- chine (VM). The proposed framework is\ninstantiated to address a case-study scenario where video streams from multiple\ncameras are transmitted to the edge processor for real-time analysis. Numerical\nresults demonstrate the advantage of the proposed framework in terms of\nprogrammability, network bandwidth and system resource savings. \n\n"}
{"id": "1805.03564", "contents": "Title: Experimental observation of Aharonov-Bohm cages in photonic lattices Abstract: We report on the experimental realization of a uniform synthetic magnetic\nflux and the observation of Aharonov-Bohm cages in photonic lattices.\nConsidering a rhombic array of optical waveguides, we engineer\nmodulation-assisted tunneling processes that effectively produce non-zero\nmagnetic flux per plaquette. This synthetic magnetic field for light can be\ntuned at will by varying the phase of the modulation. In the regime where half\na flux quantum is realized in each plaquette, all the energy bands dramatically\ncollapse into non-dispersive (flat) bands and all eigenstates are completely\nlocalized. We demonstrate this Aharonov-Bohm caging by studying the propagation\nof light in the bulk of the photonic lattice. Besides, we explore the dynamics\non the edge of the lattice and discuss how the corresponding edge states can be\ncontinuously connected to the topological edge states of the Creutz ladder. Our\nphotonic lattice constitutes an appealing platform where the interplay between\nengineered gauge fields, frustration, localization and topological properties\ncan be finely studied. \n\n"}
{"id": "1805.03760", "contents": "Title: Observation and control of nonlinear electromagnetic topological edge\n  states Abstract: Topological photonics has recently emerged as a route to realize robust\noptical circuitry, and nonlinear effects are expected to enable tunability of\ntopological states with the light intensity. Here we realize experimentally\nnonlinear self-induced spectral tuning of the electromagnetic topological edge\nstates in an array of coupled nonlinear resonators in a pump-probe experiment.\nIn a weakly nonlinear regime, we observe that resonators frequencies exhibit\nspectral shifts, that are concentrated mainly at the edge mode affecting only\nweakly the bulk modes. For a strong pumping, we describe several scenarios of\nthe transformation of the edge states and their hybridization with bulk modes,\nand also predict a parametrically driven transition from topological to\nunstable regimes. \n\n"}
{"id": "1805.04148", "contents": "Title: Precise Limit Theorems for Lacunary Series Abstract: Lacunary trigonometric and Walsh series satisfy limiting results that are\ntypical for i.i.d. random variables such as the central limit theorem (Salem,\nZygmund 1947), the law of the iterated logarithm (Weiss 1959) and several\nprobability related limit theorems. For H\\\"older continuous, periodic functions\nthis phenomenon does not hold in general. Kac (1946, 1949) showed the validity\nof the central limit theorem for the sequence $\\left(f(2^k x)\\right)_k$ and in\nthe case of \"big gaps''. In this paper, we present an alternative approach to\nprove the above theorem based on martingale theory, which allows us to\ngeneralize the theorem to infinite product spaces of arbitrary probability\nspaces, equipped with the shift operator.\n  In addition, we show the local limit theorems for lacunary trigonometric and\nWalsh series, and for H\\\"older continuous, periodic functions in the case of\n\"big gaps''. We also establish Berry-Esseen bounds and moderate deviations for\nlacunary Walsh series. Furthermore, we identify the scale at which the validity\nof the Gaussian approximation for the tails breaks. To derive these limiting\nresults, the framework of mod-Gaussian convergence has been used. \n\n"}
{"id": "1805.04535", "contents": "Title: Construction of Forward Performance Processes in Stochastic Factor\n  Models and an Extension of Widder's Theorem Abstract: We consider the problem of optimal portfolio selection under forward\ninvestment performance criteria in an incomplete market. Given multiple traded\nassets, the prices of which depend on multiple observable stochastic factors,\nwe construct a large class of forward performance processes with power-utility\ninitial data, as well as the corresponding optimal portfolios. This is done by\nsolving the associated non-linear parabolic partial differential equations\n(PDEs) posed in the \"wrong\" time direction, for stock-factor correlation\nmatrices with eigenvalue equality (EVE) structure, which we introduce here.\nAlong the way we establish on domains an explicit form of the generalized\nWidder's theorem of Nadtochiy and Tehranchi [NT15, Theorem 3.12] and rely\nhereby on the Laplace inversion in time of the solutions to suitable linear\nparabolic PDEs posed in the \"right\" time direction. \n\n"}
{"id": "1805.04776", "contents": "Title: Almost Global Problems in the LOCAL Model Abstract: The landscape of the distributed time complexity is nowadays well-understood\nfor subpolynomial complexities. When we look at deterministic algorithms in the\nLOCAL model and locally checkable problems (LCLs) in bounded-degree graphs, the\nfollowing picture emerges:\n  - There are lots of problems with time complexities of $\\Theta(\\log^* n)$ or\n$\\Theta(\\log n)$.\n  - It is not possible to have a problem with complexity between $\\omega(\\log^*\nn)$ and $o(\\log n)$.\n  - In general graphs, we can construct LCL problems with infinitely many\ncomplexities between $\\omega(\\log n)$ and $n^{o(1)}$.\n  - In trees, problems with such complexities do not exist.\n  However, the high end of the complexity spectrum was left open by prior work.\nIn general graphs there are LCL problems with complexities of the form\n$\\Theta(n^\\alpha)$ for any rational $0 < \\alpha \\le 1/2$, while for trees only\ncomplexities of the form $\\Theta(n^{1/k})$ are known. No LCL problem with\ncomplexity between $\\omega(\\sqrt{n})$ and $o(n)$ is known, and neither are\nthere results that would show that such problems do not exist. We show that:\n  - In general graphs, we can construct LCL problems with infinitely many\ncomplexities between $\\omega(\\sqrt{n})$ and $o(n)$.\n  - In trees, problems with such complexities do not exist.\n  Put otherwise, we show that any LCL with a complexity $o(n)$ can be solved in\ntime $O(\\sqrt{n})$ in trees, while the same is not true in general graphs. \n\n"}
{"id": "1805.04781", "contents": "Title: Deploying Jupyter Notebooks at scale on XSEDE resources for Science\n  Gateways and workshops Abstract: Jupyter Notebooks have become a mainstream tool for interactive computing in\nevery field of science. Jupyter Notebooks are suitable as companion\napplications for Science Gateways, providing more flexibility and\npost-processing capability to the users. Moreover they are often used in\ntraining events and workshops to provide immediate access to a pre-configured\ninteractive computing environment. The Jupyter team released the JupyterHub web\napplication to provide a platform where multiple users can login and access a\nJupyter Notebook environment. When the number of users and memory requirements\nare low, it is easy to setup JupyterHub on a single server. However, setup\nbecomes more complicated when we need to serve Jupyter Notebooks at scale to\ntens or hundreds of users. In this paper we will present three strategies for\ndeploying JupyterHub at scale on XSEDE resources. All options share the\ndeployment of JupyterHub on a Virtual Machine on XSEDE Jetstream. In the first\nscenario, JupyterHub connects to a supercomputer and launches a single node job\non behalf of each user and proxies back the Notebook from the computing node\nback to the user's browser. In the second scenario, implemented in the context\nof a XSEDE consultation for the IRIS consortium for Seismology, we deploy\nDocker in Swarm mode to coordinate many XSEDE Jetstream virtual machines to\nprovide Notebooks with persistent storage and quota. In the last scenario we\ninstall the Kubernetes containers orchestration framework on Jetstream to\nprovide a fault-tolerant JupyterHub deployment with a distributed filesystem\nand capability to scale to thousands of users. In the conclusion section we\nprovide a link to step-by-step tutorials complete with all the necessary\ncommands and configuration files to replicate these deployments. \n\n"}
{"id": "1805.05034", "contents": "Title: A stochastic SIR model on a graph with epidemiological and population\n  dynamics occurring over the same time scale Abstract: We define and study an open stochastic SIR (Susceptible -- Infected --\nRemoved) model on a graph in order to describe the spread of an epidemic on a\ncattle trade network with epidemiological and demographic dynamics occurring\nover the same time scale. Population transition intensities are assumed to be\ndensity-dependent with a constant component, the amplitude of which determines\nthe overall scale of the population process. Standard branching approximation\nresults for the epidemic process are first given, along with a numerical\ncomputation method for the probability of a major epidemic outbreak. This\nprocedure is illustrated using real data on trade-related cattle movements from\na densely populated livestock farming region in western France (Finist\\`ere)\nand epidemiological parameters corresponding to an infectious epizootic\ndisease. Then we exhibit an exponential lower bound for the extinction time and\nthe total size of the epidemic in the stable endemic case as a scaling\nparameter goes to infinity using results inspired by the Freidlin-Wentzell\ntheory of large deviations from a dynamical system. \n\n"}
{"id": "1805.05608", "contents": "Title: Proposal for frequency-selective photodetector based on the resonant\n  photon drag effect in a condensate of indirect excitons Abstract: We present a microscopic theory of a photon drag effect that appears in a\nBose-Einstein condensate of neutral particles, considering indirect excitons in\na double quantum well nanostructure under the action of a circularly polarized\nelectromagnetic field. It is shown that the dynamical polarization of excitons\nresults in a resonant behavior of the exciton photon drag flux when the\nfrequency of light is close to the gap between two energy levels of internal\nexciton motion. Specifically, we consider the ground and first excited energy\nstates characterized by the angular momentum difference $\\pm 1$, and thus, the\nhelicity of light matters. We show that the resulting drag current is caused by\nboth Bose-condensed particles and the particles in the normal state. As a\nresult, the total current represents a superposition of thresholdlike and\nresonant contributions, - property, which can be used in frequency-selective\nphotodetection. \n\n"}
{"id": "1805.05874", "contents": "Title: Approximate Distributed Joins in Apache Spark Abstract: The join operation is a fundamental building block of parallel data\nprocessing. Unfortunately, it is very resource-intensive to compute an\nequi-join across massive datasets. The approximate computing paradigm allows\nusers to trade accuracy and latency for expensive data processing operations.\nThe equi-join operator is thus a natural candidate for optimization using\napproximation techniques. Although sampling-based approaches are widely used\nfor approximation, sampling over joins is a compelling but challenging task\nregarding the output quality. Naive approaches, which perform joins over\ndataset samples, would not preserve statistical properties of the join output.\n  To realize this potential, we interweave Bloom filter sketching and\nstratified sampling with the join computation in a new operator, ApproxJoin,\nthat preserves the statistical properties of the join output. ApproxJoin\nleverages a Bloom filter to avoid shuffling non-joinable data items around the\nnetwork and then applies stratified sampling to obtain a representative sample\nof the join output.\n  Our analysis shows that ApproxJoin scales well and significantly reduces data\nmovement, without sacrificing tight error bounds on the accuracy of the final\nresults. We implemented ApproxJoin in Apache Spark and evaluated ApproxJoin\nusing microbenchmarks and real-world case studies. The evaluation shows that\nApproxJoin achieves a speedup of 6-9x over unmodified Spark-based joins with\nthe same sampling rate. Furthermore, the speedup is accompanied by a\nsignificant reduction in the shuffled data volume, which is 5-82x less than\nunmodified Spark-based joins. \n\n"}
{"id": "1805.06217", "contents": "Title: Artificial Intelligence Inspired Self-Deployment of Wireless Networks Abstract: In this paper, we propose a self-deployment approach for finding the optimal\nplacement of extenders in which both the wireless back-haul and front-haul\nthroughput of the extender are optimized. We present an artificial intelligence\n(AI) case based reasoning (CBR) framework that enables autonomous\nself-deployment in which the network can learn the environment by means of\nsensing and perception. New actions, i.e. extender positions, are created by\nproblem-specific optimization and semi-supervised learning algorithms that\nbalance exploration and exploitation of the search space. An IEEE 802.11\nstandard compliant simulations are performed to evaluate the framework on a\nlarge scale and compare its performance against existing conventional coverage\nmaximization approaches. Experimental evaluation is also performed in an\nenterprise environment to demonstrate the competence of the proposed\nAI-framework in perceiving such a dense scenario and reason the extender\ndeployment that achieves user quality of service (QoS). Throughput fairness and\nubiquitous QoS satisfaction are achieved which provide a leap to apply\nAI-driven self-deployment in wireless networks. \n\n"}
{"id": "1805.06719", "contents": "Title: Fr\\'echet differentiable drift dependence of Perron--Frobenius and\n  Koopman operators for non-deterministic dynamics Abstract: We consider Perron-Frobenius and Koopman operators associated to\ntime-inhomogeneous ordinary stochastic differential equations, and establish\ntheir Fr\\'{e}chet differentiability with respect to the drift. This result\nrelies on a similar differentiability result for pathwise expectations of path\nfunctionals of the solution of the stochastic differential equation, which we\nestablish using Girsanov's formula. We demonstrate the significance of our\nresult in the context of dynamical systems and operator theory, by proving\ncontinuously differentiable drift dependence of the simple eigen- and singular\nvalues and the corresponding eigen- and singular functions of the stochastic\nPerron-Frobenius and Koopman operators. \n\n"}
{"id": "1805.07743", "contents": "Title: Joint Path Selection and Rate Allocation Framework for 5G\n  Self-Backhauled mmWave Networks Abstract: Owing to severe path loss and unreliable transmission over a long distance at\nhigher frequency bands, we investigate the problem of path selection and rate\nallocation for multi-hop self-backhaul millimeter wave (mmWave) networks.\nEnabling multi-hop mmWave transmissions raises a potential issue of increased\nlatency, and thus, in this work we aim at addressing the fundamental questions:\nhow to select the best multi-hop paths and how to allocate rates over these\npaths subject to latency constraints? In this regard, we propose a new system\ndesign, which exploits multiple antenna diversity, mmWave bandwidth, and\ntraffic splitting techniques to improve the downlink transmission. The studied\nproblem is cast as a network utility maximization, subject to an upper delay\nbound constraint, network stability, and network dynamics. By leveraging\nstochastic optimization, the problem is decoupled into: path selection and rate\nallocation sub-problems, whereby a framework which selects the best paths is\nproposed using reinforcement learning techniques. Moreover, the rate allocation\nis a nonconvex program, which is converted into a convex one by using the\nsuccessive convex approximation method. Via mathematical analysis, we provide a\ncomprehensive performance analysis and convergence proofs for the proposed\nsolution. Numerical results show that our approach ensures reliable\ncommunication with a guaranteed probability of up to $99.9999\\%$, and reduces\nlatency by $50.64\\%$ and $92.9\\%$ as compared to baseline models. Furthermore,\nthe results showcase the key trade-off between latency and network arrival\nrate. \n\n"}
{"id": "1805.08469", "contents": "Title: Gradient Energy Matching for Distributed Asynchronous Gradient Descent Abstract: Distributed asynchronous SGD has become widely used for deep learning in\nlarge-scale systems, but remains notorious for its instability when increasing\nthe number of workers. In this work, we study the dynamics of distributed\nasynchronous SGD under the lens of Lagrangian mechanics. Using this\ndescription, we introduce the concept of energy to describe the optimization\nprocess and derive a sufficient condition ensuring its stability as long as the\ncollective energy induced by the active workers remains below the energy of a\ntarget synchronous process. Making use of this criterion, we derive a stable\ndistributed asynchronous optimization procedure, GEM, that estimates and\nmaintains the energy of the asynchronous system below or equal to the energy of\nsequential SGD with momentum. Experimental results highlight the stability and\nspeedup of GEM compared to existing schemes, even when scaling to one hundred\nasynchronous workers. Results also indicate better generalization compared to\nthe targeted SGD with momentum. \n\n"}
{"id": "1805.08541", "contents": "Title: Blockchain and Trusted Computing: Problems, Pitfalls, and a Solution for\n  Hyperledger Fabric Abstract: A smart contract on a blockchain cannot keep a secret because its data is\nreplicated on all nodes in a network. To remedy this problem, it has been\nsuggested to combine blockchains with trusted execution environments (TEEs),\nsuch as Intel SGX, for executing applications that demand privacy. Untrusted\nblockchain nodes cannot get access to the data and computations inside the TEE.\n  This paper first explores some pitfalls that arise from the combination of\nTEEs with blockchains. Since TEEs are, in principle, stateless they are\nsusceptible to rollback attacks, which should be prevented to maintain privacy\nfor the application. However, in blockchains with non-final consensus\nprotocols, such as the proof-of-work in Ethereum and others, the contract\nexecution must handle rollbacks by design. This implies that TEEs for securing\nblockchain execution cannot be directly used for such blockchains; this\napproach works only when the consensus decisions are final.\n  Second, this work introduces an architecture and a prototype for\nsmart-contract execution within Intel SGX technology for Hyperledger Fabric, a\nprominent platform for enterprise blockchain applications. Our system resolves\ndifficulties posed by the execute-order-validate architecture of Fabric and\nprevents rollback attacks on TEE-based execution as far as possible. For\nincreasing security, our design encapsulates each application on the blockchain\nwithin its own enclave that shields it from the host system. An evaluation\nshows that the overhead moving execution into SGX is within 10%-20% for a\nsealed-bid auction application. \n\n"}
{"id": "1805.08639", "contents": "Title: Stamp-it: A more Thread-efficient, Concurrent Memory Reclamation Scheme\n  in the C++ Memory Model Abstract: We present Stamp-it, a new, concurrent, lock-less memory reclamation scheme\nwith amortized, constant-time (thread-count independent) reclamation overhead.\nStamp-it has been implemented and proved correct in the C++ memory model using\nas weak memory-consistency assumptions as possible. We have likewise\n(re)implemented six other comparable reclamation schemes. We give a detailed\nperformance comparison, showing that Stamp-it performs favorably (sometimes\nbetter, at least as good as) than most of these other schemes while being able\nto reclaim free memory nodes earlier. \n\n"}
{"id": "1805.08755", "contents": "Title: Energy-aware tree network formation among computationally weak nodes Abstract: We study the fundamental problem of distributed network formation among\nmobile agents of limited computational power that aim to achieve energy balance\nby wirelessly transmitting and receiving energy in a peer-to-peer manner.\nSpecifically, we design simple distributed protocols consisting of a small\nnumber of states and interaction rules for the formation of arbitrary and k-ary\ntree networks. Furthermore, we evaluate (theoretically and also using computer\nsimulations) a plethora of energy redistribution protocols that exploit\ndifferent levels of knowledge in order to achieve desired energy distributions\namong the agents which require that every agent has exactly or at least twice\nthe energy of the agents of higher depth, according to the structure of the\nnetwork. Our study shows that without using any knowledge about the network\nstructure, such energy distributions cannot be achieved in a timely manner,\nmeaning that there might be high energy loss during the redistribution process.\nOn the other hand, only a few extra bits of information seem to be enough to\nguarantee quick convergence to energy distributions that satisfy particular\nproperties, yielding low energy loss. \n\n"}
{"id": "1805.09687", "contents": "Title: Corpus Conversion Service: A machine learning platform to ingest\n  documents at scale [Poster abstract] Abstract: Over the past few decades, the amount of scientific articles and technical\nliterature has increased exponentially in size. Consequently, there is a great\nneed for systems that can ingest these documents at scale and make their\ncontent discoverable. Unfortunately, both the format of these documents (e.g.\nthe PDF format or bitmap images) as well as the presentation of the data (e.g.\ncomplex tables) make the extraction of qualitative and quantitive data\nextremely challenging. We present a platform to ingest documents at scale which\nis powered by Machine Learning techniques and allows the user to train custom\nmodels on document collections. We show precision/recall results greater than\n97% with regard to conversion to structured formats, as well as scaling\nevidence for each of the microservices constituting the platform. \n\n"}
{"id": "1805.09767", "contents": "Title: Local SGD Converges Fast and Communicates Little Abstract: Mini-batch stochastic gradient descent (SGD) is state of the art in large\nscale distributed training. The scheme can reach a linear speedup with respect\nto the number of workers, but this is rarely seen in practice as the scheme\noften suffers from large network delays and bandwidth limits. To overcome this\ncommunication bottleneck recent works propose to reduce the communication\nfrequency. An algorithm of this type is local SGD that runs SGD independently\nin parallel on different workers and averages the sequences only once in a\nwhile.\n  This scheme shows promising results in practice, but eluded thorough\ntheoretical analysis. We prove concise convergence rates for local SGD on\nconvex problems and show that it converges at the same rate as mini-batch SGD\nin terms of number of evaluated gradients, that is, the scheme achieves linear\nspeedup in the number of workers and mini-batch size. The number of\ncommunication rounds can be reduced up to a factor of T^{1/2}---where T denotes\nthe number of total steps---compared to mini-batch SGD. This also holds for\nasynchronous implementations. Local SGD can also be used for large scale\ntraining of deep learning models.\n  The results shown here aim serving as a guideline to further explore the\ntheoretical and practical aspects of local SGD in these applications. \n\n"}
{"id": "1805.11029", "contents": "Title: Subadditive stake systems Abstract: Stake systems which issue stakes as well as coins are proposed. Two\nsubadditive stake systems are studied: one is the radical stake system, the\nother is the logarithmic stake system. Securities of both systems are analysed. \n\n"}
{"id": "1806.03103", "contents": "Title: An Explicit Construction of Systematic MDS Codes with Small\n  Sub-packetization for All-Node Repair Abstract: An explicit construction of systematic MDS codes, called HashTag+ codes, with\narbitrary sub-packetization level for all-node repair is proposed. It is shown\nthat even for small sub-packetization levels, HashTag+ codes achieve the\noptimal MSR point for repair of any parity node, while the repair bandwidth for\na single systematic node depends on the sub-packetization level. Compared to\nother codes in the literature, HashTag+ codes provide from 20% to 40% savings\nin the average amount of data accessed and transferred during repair. \n\n"}
{"id": "1806.04193", "contents": "Title: Stochastic Geometric Coverage Analysis in mmWave Cellular Networks with\n  Realistic Channel and Antenna Radiation Models Abstract: Millimeter-wave (mmWave) bands will play an important role in 5G wireless\nsystems. The system performance can be assessed by using models from stochastic\ngeometry that cater for the directivity in the desired signal transmissions as\nwell as the interference, and by calculating the\nsignal-to-interference-plus-noise ratio (SINR) coverage. Nonetheless, the\ncorrectness of the existing coverage expressions derived through stochastic\ngeometry may be questioned, as it is not clear whether they capture the impact\nof the detailed mmWave channel and antenna features. In this study, we propose\nan SINR coverage analysis framework that includes realistic channel model (from\nNYU) and antenna element radiation patterns (with isotropic/directional\nradiation). We first introduce two parameters, aligned gain and misaligned\ngain, associated with the desired signal beam and the interfering signal beam,\nrespectively. We provide the distributions of the aligned and misaligned gains\nthrough curve fitting of system-simulation results. The distribution of these\ngains is used to determine the distribution of the SINR. We compare the\nobtained analytical SINR coverage with the corresponding SINR coverage\ncalculated via system-level simulations. The results show that both aligned and\nmisaligned gains can be modeled as exponential-logarithmically distributed\nrandom variables with the highest accuracy, and can further be approximated as\nexponentially distributed random variables with reasonable accuracy. These\napproximations are thus expected to be useful to evaluate the system\nperformance under ultra-reliable and low-latency communication (URLLC) and\nevolved mobile broadband (eMBB) scenarios, respectively. \n\n"}
{"id": "1806.06185", "contents": "Title: EdgeChain: An Edge-IoT Framework and Prototype Based on Blockchain and\n  Smart Contracts Abstract: The emerging Internet of Things (IoT) is facing significant scalability and\nsecurity challenges. On the one hand, IoT devices are \"weak\" and need external\nassistance. Edge computing provides a promising direction addressing the\ndeficiency of centralized cloud computing in scaling massive number of devices.\nOn the other hand, IoT devices are also relatively \"vulnerable\" facing\nmalicious hackers due to resource constraints. The emerging blockchain and\nsmart contracts technologies bring a series of new security features for IoT\nand edge computing. In this paper, to address the challenges, we design and\nprototype an edge-IoT framework named \"EdgeChain\" based on blockchain and smart\ncontracts. The core idea is to integrate a permissioned blockchain and the\ninternal currency or \"coin\" system to link the edge cloud resource pool with\neach IoT device' account and resource usage, and hence behavior of the IoT\ndevices. EdgeChain uses a credit-based resource management system to control\nhow much resource IoT devices can obtain from edge servers, based on\npre-defined rules on priority, application types and past behaviors. Smart\ncontracts are used to enforce the rules and policies to regulate the IoT device\nbehavior in a non-deniable and automated manner. All the IoT activities and\ntransactions are recorded into blockchain for secure data logging and auditing.\nWe implement an EdgeChain prototype and conduct extensive experiments to\nevaluate the ideas. The results show that while gaining the security benefits\nof blockchain and smart contracts, the cost of integrating them into EdgeChain\nis within a reasonable and acceptable range. \n\n"}
{"id": "1806.07476", "contents": "Title: CommunityWatch: The Swiss-Army Knife of BGP Anomaly Detection Abstract: We present CommunityWatch, an open-source system that enables timely and\naccurate detection of BGP routing anomalies. CommunityWatch leverages meta-data\nencoded by AS operators on their advertised routes through the BGP Communities\nattribute. The BGP Communities values lack standardized semantics, offering the\nflexibility to attach a wide range of information, including AS relationships,\nlocation data, and route redistribution policies. Therefore, parsing and\ncorrelating Community values and their dynamics enables the detection and\ntracking of a variety of routing anomalies. We exhibit the efficacy of\nCommunityWatch through the detection of three different types of anomalies:\ninfrastructure outages, route leaks, and traffic blackholing. \n\n"}
{"id": "1806.07840", "contents": "Title: Edge Intelligence: On-Demand Deep Learning Model Co-Inference with\n  Device-Edge Synergy Abstract: As the backbone technology of machine learning, deep neural networks (DNNs)\nhave have quickly ascended to the spotlight. Running DNNs on\nresource-constrained mobile devices is, however, by no means trivial, since it\nincurs high performance and energy overhead. While offloading DNNs to the cloud\nfor execution suffers unpredictable performance, due to the uncontrolled long\nwide-area network latency. To address these challenges, in this paper, we\npropose Edgent, a collaborative and on-demand DNN co-inference framework with\ndevice-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that\nadaptively partitions DNN computation between device and edge, in order to\nleverage hybrid computation resources in proximity for real-time DNN inference.\n(2) DNN right-sizing that accelerates DNN inference through early-exit at a\nproper intermediate DNN layer to further reduce the computation latency. The\nprototype implementation and extensive evaluations based on Raspberry Pi\ndemonstrate Edgent's effectiveness in enabling on-demand low-latency edge\nintelligence. \n\n"}
{"id": "1806.09466", "contents": "Title: Optimized Video Streaming over Cloud: A Stall-Quality Trade-off Abstract: As video-streaming services have expanded and improved, cloud-based video has\nevolved into a necessary feature of any successful business for reaching\ninternal and external audiences. In this paper, video streaming over\ndistributed storage is considered where the video segments are encoded using an\nerasure code for better reliability. There are multiple parallel streams\nbetween each server and the edge router. For each client request, we need to\ndetermine the subset of servers to get the data, as well as one of the parallel\nstream from each chosen server. In order to have this scheduling, this paper\nproposes a two-stage probabilistic scheduling. The selection of video quality\nis also chosen with a certain probability distribution. With these parameters,\nthe playback time of video segments is determined by characterizing the\ndownload time of each coded chunk for each video segment. Using the playback\ntimes, a bound on the moment generating function of the stall duration is used\nto bound the mean stall duration. Based on this, we formulate an optimization\nproblem to jointly optimize the convex combination of mean stall duration and\naverage video quality for all requests, where the two-stage probabilistic\nscheduling, probabilistic video quality selection, bandwidth split among\nparallel streams, and auxiliary bound parameters can be chosen. This non-convex\nproblem is solved using an efficient iterative algorithm. Evaluation results\nshow significant improvement in QoE metrics for cloud-based video as compared\nto the considered baselines. \n\n"}
{"id": "1806.09582", "contents": "Title: Traffic Differentiation in Dense WLANs with CSMA/ECA-DR MAC Protocol Abstract: In today's WLANs, scheduling of packet transmissions solely relies on the\ncollision and success a station may experience. To better support traffic\ndifferentiation in dense WLANs, in this paper, we propose a distributed\nreservation mechanism for the Carrier Sense Multiple Access Extended Collision\nAvoidance (CSMA/ECA) MAC protocol, termed CSMA/ECA-DR, based on which stations\ncan collaboratively achieve higher network performance. In addition, proper\nContention Window (CW) will be chosen based on the instantaneously estimated\nnumber of active contenders in the network. Simulation results from dense\nscenarios with traffic differentiation demonstrate that CSMA/ECA-DR can greatly\nimprove the efficiency of WLANs for traffic differentiation even with large\nnumbers of contenders. \n\n"}
{"id": "1806.10113", "contents": "Title: Improving tasks throughput on accelerators using OpenCL command\n  concurrency Abstract: A heterogeneous architecture composed by a host and an accelerator must\nfrequently deal with situations where several independent tasks are available\nto be offloaded onto the accelerator. These tasks can be generated by\nconcurrent applications executing in the host or, in case the host is a node of\na computer cluster, by applications running on other cluster nodes that are\nwilling to offload tasks in the accelerator connected to the host. In this work\nwe show that a runtime scheduler that selects the best execution order of a\ngroup of tasks on the accelerator can significantly reduce the total execution\ntime of the tasks and, consequently, increase the accelerator use. Our solution\nis based on a temporal execution model that is able to predict with high\naccuracy the execution time of a set of concurrent tasks launched on the\naccelerator. The execution model has been validated in AMD, NVIDIA, and Xeon\nPhi devices using synthetic benchmarks. Moreover, employing the temporal\nexecution model, a heuristic is proposed which is able to establish a\nnear-optimal tasks execution ordering that significantly reduces the total\nexecution time, including data transfers.The heuristic has been evaluated with\nfive different benchmarks composed of dominant kernel and dominant transfer\nreal tasks. Experiments indicate the heuristic is able to find always an\nordering with a better execution time than the average of every possible\nexecution order and, most times, it achieves a near-optimal ordering (very\nclose to the execution time of the best execution order) with a negligible\noverhead. Concretely, our heuristic obtains, on average for all the devices,\nbetween 84\\% and 96\\% of the improvement achieved by the best execution order. \n\n"}
{"id": "1806.10929", "contents": "Title: When Can a Distributed Ledger Replace a Trusted Third Party? Abstract: The functionality that distributed ledger technology provides, i.e., an\nimmutable and fraud-resistant registry with validation and verification\nmechanisms, has traditionally been implemented with a trusted third party. Due\nto the distributed nature of ledger technology, there is a strong recent trend\ntowards using ledgers to implement novel decentralized applications for a wide\nrange of use cases, e.g., in the financial sector and sharing economy. While\nthere can be several arguments for the use of a ledger, the key question is\nwhether it can fully replace any single trusted party in the system as\notherwise a (potentially simpler) solution can be built around the trusted\nparty. In this paper, we introduce an abstract view on ledger use cases and\npresent two fundamental criteria that must be met for any use case to be\nimplemented using a ledger-based approach without having to rely on any\nparticular party in the system. Moreover, we evaluate several ledger use cases\nthat have recently received considerable attention according to these criteria,\nrevealing that often participants need to trust each other despite using a\ndistributed ledger. Consequently, the potential of using a ledger as a\nreplacement for a trusted party is limited for these use cases. \n\n"}
{"id": "1807.00851", "contents": "Title: On Non-Preemptive VM Scheduling in the Cloud Abstract: We study the problem of scheduling VMs (Virtual Machines) in a distributed\nserver platform, motivated by cloud computing applications. The VMs arrive\ndynamically over time to the system, and require a certain amount of resources\n(e.g. memory, CPU, etc) for the duration of their service. To avoid costly\npreemptions, we consider non-preemptive scheduling: Each VM has to be assigned\nto a server which has enough residual capacity to accommodate it, and once a VM\nis assigned to a server, its service \\textit{cannot} be disrupted (preempted).\nPrior approaches to this problem either have high complexity, require\nsynchronization among the servers, or yield queue sizes/delays which are\nexcessively large. We propose a non-preemptive scheduling algorithm that\nresolves these issues. In general, given an approximation algorithm to Knapsack\nwith approximation ratio $r$, our scheduling algorithm can provide $r\\beta$\nfraction of the throughput region for $\\beta < r$. In the special case of a\ngreedy approximation algorithm to Knapsack, we further show that this condition\ncan be relaxed to $\\beta<1$. The parameters $\\beta$ and $r$ can be tuned to\nprovide a tradeoff between achievable throughput, delay, and computational\ncomplexity of the scheduling algorithm. Finally extensive simulation results\nusing both synthetic and real traffic traces are presented to verify the\nperformance of our algorithm. \n\n"}
{"id": "1807.01147", "contents": "Title: FastTrack: Minimizing Stalls for CDN-based Over-the-top Video Streaming\n  Systems Abstract: Traffic for internet video streaming has been rapidly increasing and is\nfurther expected to increase with the higher definition videos and IoT\napplications, such as 360 degree videos and augmented virtual reality\napplications. While efficient management of heterogeneous cloud resources to\noptimize the quality of experience is important, existing work in this problem\nspace often left out important factors. In this paper, we present a model for\ndescribing a today's representative system architecture for video streaming\napplications, typically composed of a centralized origin server and several CDN\nsites. Our model comprehensively considers the following factors: limited\ncaching spaces at the CDN sites, allocation of CDN for a video request, choice\nof different ports from the CDN, and the central storage and bandwidth\nallocation. With the model, we focus on minimizing a performance metric, stall\nduration tail probability (SDTP), and present a novel, yet efficient, algorithm\nto solve the formulated optimization problem. The theoretical bounds with\nrespect to the SDTP metric are also analyzed and presented. Our extensive\nsimulation results demonstrate that the proposed algorithms can significantly\nimprove the SDTP metric, compared to the baseline strategies. Small-scale video\nstreaming system implementation in a real cloud environment further validates\nour results. \n\n"}
{"id": "1807.02304", "contents": "Title: Broad-Band Negative Refraction via Simultaneous Multi-Electron\n  Transitions Abstract: We analyze different factors which influence the negative refraction in\nsolids and multi-atom molecules. We find that this negative refraction is\nsignificantly influenced by simultaneous multi-electron transitions with the\nsame transition frequency and dipole redistribution over different eigenstates.\nWe show that these simultaneous multi-electron transitions and enhanced\ntransition dipole broaden the bandwidth of the negative refraction by at least\none order of magnitude. This work provides additional connection between\nmetamaterials and Mobius strips. \n\n"}
{"id": "1807.02492", "contents": "Title: Dynamic Load Balancing for Compressible Multiphase Turbulence Abstract: CMT-nek is a new scientific application for performing high fidelity\npredictive simulations of particle laden explosively dispersed turbulent flows.\nCMT-nek involves detailed simulations, is compute intensive and is targeted to\nbe deployed on exascale platforms. The moving particles are the main source of\nload imbalance as the application is executed on parallel processors. In a\ndemonstration problem, all the particles are initially in a closed container\nuntil a detonation occurs and the particles move apart. If all processors get\nan equal share of the fluid domain, then only some of the processors get\nsections of the domain that are initially laden with particles, leading to\ndisparate load on the processors. In order to eliminate load imbalance in\ndifferent processors and to speedup the makespan, we present different load\nbalancing algorithms for CMT-nek on large scale multi-core platforms consisting\nof hundred of thousands of cores. The detailed process of the load balancing\nalgorithms are presented. The performance of the different load balancing\nalgorithms are compared and the associated overheads are analyzed. Evaluations\non the application with and without load balancing are conducted and these show\nthat with load balancing, simulation time becomes faster by a factor of up to\n$9.97$. \n\n"}
{"id": "1807.03454", "contents": "Title: Using Complex Network Theory for Temporal Locality in Network Traffic\n  Flows Abstract: Monitoring the interaction behaviors of network traffic flows and detecting\nunwanted Internet applications and anomalous flows have become a challenging\nproblem, since many applications obfuscate their network traffic flow using\nunregistered port numbers or payload encryption. In this paper, the temporal\nlocality complex network model--TLCN is proposed as a way to monitor, analyze\nand visualize network traffic flows. TLCNs model the interaction behaviors of\nlarge-scale network traffic flows, where the nodes and the edges can be defined\nto represent different flow levels and flow interactions separately. Then, the\nstatistical characteristics and dynamic behaviors of the TLCNs are studied to\nrepresent TLCN's structure representing ability to the flow interactions.\nAccording to the analysis of TLCN statistical characteristics with different\nInternet applications, we found that the weak interaction flows prefer to form\nthe small-world TLCN and the strong interaction flows prefer to the scale-free\nTLCN. In the studies of anomaly behaviors of TLCNs, the network structure of\nattacked TLCNs can have a remarkable feature for three attack patterns, and the\nevolution of TLCNs exhibits a good consistency between TLCN structure and\nattack process. With the introduction of TLCNs, we are able to harness a wealth\nof tools and graph modeling techniques from a diverse set of disciplines. \n\n"}
{"id": "1807.06179", "contents": "Title: Real-Time Index Authentication for Event-Oriented Surveillance Video\n  Query using Blockchain Abstract: Information from surveillance video is essential for situational awareness\n(SAW). Nowadays, a prohibitively large amount of surveillance data is being\ngenerated continuously by ubiquitously distributed video sensors. It is very\nchallenging to immediately identify the objects of interest or zoom in\nsuspicious actions from thousands of video frames. Making the big data\nindexable is critical to tackle this problem. It is ideal to generate pattern\nindexes in a real-time, on-site manner on the video streaming instead of\ndepending on the batch processing at the cloud centers. The modern\nedge-fog-cloud computing paradigm allows implementation of time sensitive tasks\nat the edge of the network. The on-site edge devices collect the information\nsensed in format of frames and extracts useful features. The near-site fog\nnodes conduct the contextualization and classification of the features. The\nremote cloud center is in charge of more data intensive and computing intensive\ntasks. However, exchanging the index information among devices in different\nlayers raises security concerns where an adversary can capture or tamper with\nfeatures to mislead the surveillance system. In this paper, a blockchain\nenabled scheme is proposed to protect the index data through an encrypted\nsecure channel between the edge and fog nodes. It reduces the chance of attacks\non the small edge and fog devices. The feasibility of the proposal is validated\nthrough intensive experimental analysis. \n\n"}
{"id": "1807.07487", "contents": "Title: A Microservice-enabled Architecture for Smart Surveillance using\n  Blockchain Technology Abstract: While the smart surveillance system enhanced by the Internet of Things (IoT)\ntechnology becomes an essential part of Smart Cities, it also brings new\nconcerns in security of the data. Compared to the traditional surveillance\nsystems that is built following a monolithic architecture to carry out lower\nlevel operations, such as monitoring and recording, the modern surveillance\nsystems are expected to support more scalable and decentralized solutions for\nadvanced video stream analysis at the large volumes of distributed edge\ndevices. In addition, the centralized architecture of the conventional\nsurveillance systems is vulnerable to single point of failure and privacy\nbreach owning to the lack of protection to the surveillance feed. This position\npaper introduces a novel secure smart surveillance system based on\nmicroservices architecture and blockchain technology. Encapsulating the video\nanalysis algorithms as various independent microservices not only isolates the\nvideo feed from different sectors, but also improve the system availability and\nrobustness by decentralizing the operations. The blockchain technology securely\nsynchronizes the video analysis databases among microservices across\nsurveillance domains, and provides tamper proof of data in the trustless\nnetwork environment. Smart contract enabled access authorization strategy\nprevents any unauthorized user from accessing the microservices and offers a\nscalable, decentralized and fine-grained access control solution for smart\nsurveillance systems. \n\n"}
{"id": "1807.08315", "contents": "Title: Accelerated Structure-Aware Reinforcement Learning for Delay-Sensitive\n  Energy Harvesting Wireless Sensors Abstract: We investigate an energy-harvesting wireless sensor transmitting\nlatency-sensitive data over a fading channel. The sensor injects captured data\npackets into its transmission queue and relies on ambient energy harvested from\nthe environment to transmit them. We aim to find the optimal scheduling policy\nthat decides whether or not to transmit the queue's head-of-line packet at each\ntransmission opportunity such that the expected packet queuing delay is\nminimized given the available harvested energy. No prior knowledge of the\nstochastic processes that govern the channel, captured data, or harvested\nenergy dynamics are assumed, thereby necessitating the use of online learning\nto optimize the scheduling policy. We formulate this scheduling problem as a\nMarkov decision process (MDP) and analyze the structural properties of its\noptimal value function. In particular, we show that it is non-decreasing and\nhas increasing differences in the queue backlog and that it is non-increasing\nand has increasing differences in the battery state. We exploit this structure\nto formulate a novel accelerated reinforcement learning (RL) algorithm to solve\nthe scheduling problem online at a much faster learning rate, while limiting\nthe induced computational complexity. Our experiments demonstrate that the\nproposed algorithm closely approximates the performance of an optimal offline\nsolution that requires a priori knowledge of the channel, captured data, and\nharvested energy dynamics. Simultaneously, by leveraging the value function's\nstructure, our approach achieves competitive performance relative to a\nstate-of-the-art RL algorithm, at potentially orders of magnitude lower\ncomplexity. Finally, considerable performance gains are demonstrated over the\nwell-known and widely used Q-learning algorithm. \n\n"}
{"id": "1807.10727", "contents": "Title: Connected Components at Scale via Local Contractions Abstract: As a fundamental tool in hierarchical graph clustering, computing connected\ncomponents has been a central problem in large-scale data mining. While many\nknown algorithms have been developed for this problem, they are either not\nscalable in practice or lack strong theoretical guarantees on the parallel\nrunning time, that is, the number of communication rounds. So far, the best\nproven guarantee is $\\Oh(\\log n)$, which matches the running time in the PRAM\nmodel.\n  In this paper, we aim to design a distributed algorithm for this problem that\nworks well in theory and practice. In particular, we present a simple algorithm\nbased on contractions and provide a scalable implementation of it in MapReduce.\nOn the theoretical side, in addition to showing $\\Oh(\\log n)$ convergence for\nall graphs, we prove an $\\Oh(\\log \\log n)$ parallel running time with high\nprobability for a certain class of random graphs. We work in the MPC model that\ncaptures popular parallel computing frameworks, such as MapReduce, Hadoop or\nSpark.\n  On the practical side, we show that our algorithm outperforms the\nstate-of-the-art MapReduce algorithms. To confirm its scalability, we report\nempirical results on graphs with several trillions of edges. \n\n"}
{"id": "1808.00667", "contents": "Title: Deep Learning for Radio Resource Allocation in Multi-Cell Networks Abstract: Increased complexity and heterogeneity of emerging 5G and beyond 5G (B5G)\nwireless networks will require a paradigm shift from traditional resource\nallocation mechanisms. Deep learning (DL) is a powerful tool where a\nmulti-layer neural network can be trained to model a resource management\nalgorithm using network data.Therefore, resource allocation decisions can be\nobtained without intensive online computations which would be required\notherwise for the solution of resource allocation problems. In this context,\nthis article focuses on the application of DL to obtain solutions for the radio\nresource allocation problems in multi-cell networks. Starting with a brief\noverview of a deep neural network (DNN) as a DL model, relevant DNN\narchitectures and the data training procedure, we provide an overview of\nexisting state-of-the-art applying DL in the context of radio resource\nallocation. A qualitative comparison is provided in terms of their objectives,\ninputs/outputs, learning and data training methods. Then, we present a\nsupervised DL model to solve the sub-band and power allocation problem in a\nmulti-cell network. Using the data generated by a genetic algorithm, we first\ntrain the model and then test the accuracy of the proposed model in predicting\nthe resource allocation solutions. Simulation results show that the trained DL\nmodel is able to provide the desired optimal solution 86.3% of time. \n\n"}
{"id": "1808.00735", "contents": "Title: Limit theorems for some skew products with mixing base maps Abstract: We obtain central limit theorem, local limit theorems and renewal theorems\nfor stationary processes generated by skew product maps $T(\\om,x)=(\\te\\om,T_\\om\nx)$ together with a $T$-invariant measure, whose base map $\\te$ satisfies\ncertain topological and mixing conditions and the maps $T_\\om$ on the fibers\nare certain non-singular distance expanding maps. Our results hold true when\n$\\te$ is either a sufficiently fast mixing Markov shift or a (non-uniform)\nYoung tower with at least one periodic point and polynomial tails. %In fact,\nour conditions will be satisfied %when $\\om$ is the whole orbit the towers. The\nproofs are based on the random complex Ruelle-Perron-Frobenius theorem from\n\\cite{book} applied with appropriate random transfer operators generated by\n$T_\\om$, together with certain regularity assumptions (as functions of $\\om$)\nof these operators. Limit theorems for deterministic processes whose\ndistributions on the fibers are generated by Markov chains with transition\noperators satisfying a random version of the Doeblin condition will also be\nobtained. The main innovation in this paper is that the results hold true even\nthough the spectral theory used in \\cite{Aimino} does not seem to be\napplicable, and the dual of the Koopman operator of $T$ (with respect to the\ninvariant measure) does not seem to have a spectral gap. \n\n"}
{"id": "1808.01561", "contents": "Title: Rapido: A Layer2 Payment System for Decentralized Currencies Abstract: Bitcoin blockchain faces the bitcoin scalability problem, for which bitcoin's\nblocks contain the transactions on the bitcoin network. The on-chain\ntransaction processing capacity of the bitcoin network is limited by the\naverage block creation time of 10 minutes and the block size limit. These\njointly constrain the network's throughput. The transaction processing capacity\nmaximum is estimated between 3.3 and 7 transactions per second (TPS). A Layer2\nNetwork, named Lightning Network, is proposed and activated solutions to\naddress this problem. LN operates on top of the bitcoin network as a cache to\nallow payments to be affected that are not immediately put on the blockchain.\nHowever, it also brings some drawbacks. In this paper, we observe a specific\npayment issue among current LN, which requires additional claims to blockchain\nand is time-consuming. We call the issue as shares issue. Therefore, we propose\nRapido to explicitly address the shares issue. Furthermore, a new smart\ncontract, D-HTLC, is equipped with Rapido as the payment protocol. We finally\nprovide a proof of concept implementation and simulation for both Rapido and\nLN, in which Rapdio not only mitigates the shares issue but also mitigates the\nskewness issue thus is proved to be more applicable for various transactions\nthan LN. \n\n"}
{"id": "1808.04761", "contents": "Title: Cache Telepathy: Leveraging Shared Resource Attacks to Learn DNN\n  Architectures Abstract: Deep Neural Networks (DNNs) are fast becoming ubiquitous for their ability to\nattain good accuracy in various machine learning tasks. A DNN's architecture\n(i.e., its hyper-parameters) broadly determines the DNN's accuracy and\nperformance, and is often confidential. Attacking a DNN in the cloud to obtain\nits architecture can potentially provide major commercial value. Further,\nattaining a DNN's architecture facilitates other, existing DNN attacks.\n  This paper presents Cache Telepathy: a fast and accurate mechanism to steal a\nDNN's architecture using the cache side channel. Our attack is based on the\ninsight that DNN inference relies heavily on tiled GEMM (Generalized Matrix\nMultiply), and that DNN architecture parameters determine the number of GEMM\ncalls and the dimensions of the matrices used in the GEMM functions. Such\ninformation can be leaked through the cache side channel.\n  This paper uses Prime+Probe and Flush+Reload to attack VGG and ResNet DNNs\nrunning OpenBLAS and Intel MKL libraries. Our attack is effective in helping\nobtain the architectures by very substantially reducing the search space of\ntarget DNN architectures. For example, for VGG using OpenBLAS, it reduces the\nsearch space from more than $10^{35}$ architectures to just 16. \n\n"}
{"id": "1808.05874", "contents": "Title: Optical second harmonic generation in encapsulated single-layer InSe Abstract: We report the observation of optical second harmonic generation (SHG) in\nsingle-layer indium selenide (InSe). We measure a second harmonic signal of\n$>10^3$ $\\textrm{cts/s}$ under nonresonant excitation using a home-built\nconfocal microscope and a standard pulsed pico-second laser. We demonstrate\nthat polarization-resolved SHG serves as a fast, non-invasive tool to determine\nthe crystal axes in single-layer InSe and to relate the sharp edges of the\nflake to the armchair and zigzag edges of the crystal structure. Our experiment\ndetermines these angles to an accuracy better than $\\pm$ $0.2^{\\circ}$.\nTreating the two-dimensional material as a nonlinear polarizable sheet, we\ndetermine a second-order nonlinear sheet polarizability $|\n\\chi_{\\textrm{sheet}}^{(2)}|=(17.9 \\pm 11.0)\\times 10^{-20}$ $\\textrm{m}^2\n\\textrm{V}^{-1}$ for single-layer InSe, corresponding to an effective nonlinear\nsusceptibility value of $| \\chi_\\textrm{eff}^{(2)}| \\approx (223 \\pm 138)\n\\times 10^{-12}$ $\\textrm{m} \\textrm{V}^{-1}$ accounting for the sheet\nthickness ($\\textrm{d} \\approx 0.8$ $\\textrm{nm}$). We demonstrate that the SHG\ntechnique can also be applied to encapsulated samples to probe their crystal\norientations. The method is therefore suitable for creating high quality van\nder Waals heterostructures with control over the crystal directions. \n\n"}
{"id": "1808.05969", "contents": "Title: Stationary points in coalescing stochastic flows on $\\mathbb{R}$ Abstract: This work is devoted to long-time properties of the Arratia flow with drift\n-- a stochastic flow on $\\mathbb{R}$ whose one-point motions are weak solutions\nto a stochastic differential equation $dX(t)=a(X(t))dt+dw(t)$ that move\nindependently before the meeting time and coalesce at the meeting time. We\nstudy special modification of such flow (constructed in \\cite{Riabov}) that\ngives rise to a random dynamical system and thus allows to discuss stationary\npoints. Existence of a unique stationary point is proved in the case of a\nstrictly monotone Lipschitz drift by developing a variant of a pullback\nprocedure. Connections between the existence of a stationary point and\nproperties of a dual flow are discussed. \n\n"}
{"id": "1808.06325", "contents": "Title: A transiting M-dwarf showing beaming effect in the field of Ruprecht 147 Abstract: We report the discovery and characterization of an eclipsing M5V dwarf star,\norbiting a slightly evolved F7V main sequence star.\n  In contrast to previous claims in the literature, we confirm that the system\ndoes not belong to the galactic open cluster Ruprecht 147. We determine its\nfundamental parameters combining K2 time-series data with spectroscopic\nobservations from the McDonald Observatory, FIES@NOT, and HIRES@KECK. The very\nprecise photometric data from the K2 mission allows us to measure variations\ncaused by the beaming effect (relativistic doppler boosting), ellipsoidal\nvariation, reflection, and the secondary eclipse. We determined the radial\nvelocity using spectroscopic observations and compare it to the radial velocity\ndetermined from the beaming effect observed in the photometric data. The M5V\nstar has a radius of $0.200 \\substack{+0.007 \\\\ -0.008}$ $R_{\\odot}$ and a mass\nof $0.187 \\substack{+0.012 \\\\ -0.013}$ $M_{\\odot}$. The primary star has radius\nof $1.518 \\substack{+0.038 \\\\ -0.049}$ $R_{\\odot}$ and a mass of $1.008\n\\substack{+0.081 \\\\ -0.097}$ $M_{\\odot}$. The orbital period is $ 5.441995 \\pm\n0.000007$ days. The system is one of the few eclipsing systems with observed\nbeaming effect and spectroscopic radial velocity measurements and it can be\nused as test case for the modelling of the beaming effect.\n  Current and forthcoming space missions such as TESS and PLATO might benefit\nof the analysis of the beaming effect to estimate the mass of transiting\ncompanions without the need for radial velocity follow up observations,\nprovided that the systematic sources of noise affecting this method are well\nunderstood. \n\n"}
{"id": "1808.07412", "contents": "Title: Ithemal: Accurate, Portable and Fast Basic Block Throughput Estimation\n  using Deep Neural Networks Abstract: Predicting the number of clock cycles a processor takes to execute a block of\nassembly instructions in steady state (the throughput) is important for both\ncompiler designers and performance engineers. Building an analytical model to\ndo so is especially complicated in modern x86-64 Complex Instruction Set\nComputer (CISC) machines with sophisticated processor microarchitectures in\nthat it is tedious, error prone, and must be performed from scratch for each\nprocessor generation. In this paper we present Ithemal, the first tool which\nlearns to predict the throughput of a set of instructions. Ithemal uses a\nhierarchical LSTM--based approach to predict throughput based on the opcodes\nand operands of instructions in a basic block. We show that Ithemal is more\naccurate than state-of-the-art hand-written tools currently used in compiler\nbackends and static machine code analyzers. In particular, our model has less\nthan half the error of state-of-the-art analytical models (LLVM's llvm-mca and\nIntel's IACA). Ithemal is also able to predict these throughput values just as\nfast as the aforementioned tools, and is easily ported across a variety of\nprocessor microarchitectures with minimal developer effort. \n\n"}
{"id": "1808.08356", "contents": "Title: Consensus-Before-Talk: Distributed Dynamic Spectrum Access via\n  Distributed Spectrum Ledger Technology Abstract: This paper proposes Consensus-Before-Talk (CBT), a spectrum etiquette\narchitecture leveraged by distributed ledger technology (DLT). In CBT,\nsecondary users' spectrum access requests reach a consensus in a distributed\nway, thereby enabling collision-free distributed dynamic spectrum access. To\nachieve this consensus, the secondary users need to pay for the extra request\nexchanging delays. Incorporating the consensus delay, the end-to-end latency\nunder CBT is investigated. Both the latency analysis and numerical evaluation\nvalidate that the proposed CBT achieves the lower end-to-end latency\nparticularly under severe secondary user traffic, compared to the\nListen-Before-Talk (LBT) benchmark scheme. \n\n"}
{"id": "1808.10284", "contents": "Title: An algebraic approach to FQHE variational wave functions Abstract: Consider a system of $N$ electrons projected onto the lowest Landau level\n(LLL) with filling factor of the form $n/(2pn\\pm1)<1/2$ and $N$ a multiple of\n$n$. We show that there always exists a two-dimensional symmetric correlation\nfactor (arising as a nonzero symmetrization) for such systems and hence one can\nalways write a variational wave function. This extends an earlier observation\nof Laughlin for an incompressible quantum liquid (IQL) state with filling\nfactor equal to the reciprocal of an odd integer $ \\geq 3$. To do so, we\nconstruct a family of $d$-regular multi-graphs on $N$ vertices for any $N$\nwhose graph-monomials have nonzero linear symmetrization and obtain, as special\ncases, the aforementioned nonzero correlations for the IQL state. The nonzero\nlinear symmetrization that is obtained is in fact an example of what is called\na binary invariant of type $(N,d)$. Thus, in addition to supplying new\nvariational wave functions for systems of interacting Fermions, our\nconstruction is of potential interest from both the graph and invariant\ntheoretic viewpoints. \n\n"}
{"id": "1808.10292", "contents": "Title: A study of integer sorting on multicores Abstract: Integer sorting on multicores and GPUs can be realized by a variety of\napproaches that include variants of distribution-based methods such as\nradix-sort, comparison-oriented algorithms such as deterministic regular\nsampling and random sampling parallel sorting, and network-based algorithms\nsuch as Batcher's bitonic sorting algorithm.\n  In this work we present an experimental study of integer sorting on multicore\nprocessors. We have implemented serial and parallel radix-sort for various\nradixes, deterministic regular oversampling and random oversampling parallel\nsorting, and also some previously little explored or unexplored variants of\nbitonic-sort and odd-even transposition sort.\n  The study uses multithreading and multiprocessing parallel programming\nlibraries with the C language implementations working under Open MPI,\nMulticoreBSP, and BSPlib utilizing the same source code.\n  A secondary objective is to attempt to model the performance of these\nalgorithm implementations under the MBSP (Multi-memory BSP) model. We first\nprovide some general high-level observations on the performance of these\nimplementations. If we can conclude anything is that accurate prediction of\nperformance by taking into consideration architecture dependent features such\nas the structure and characteristics of multiple memory hierarchies is\ndifficult and more often than not untenable. To some degree this is affected by\nthe overhead imposed by the high-level library used in the programming effort.\nWe can still draw however some reliable conclusions and reason about the\nperformance of these implementations using the MBSP model, thus making MBSP\nuseful and usable. \n\n"}
{"id": "1809.03201", "contents": "Title: Isocurvature fluctuations in the effective Newton's constant Abstract: We present a new isocurvature mode present in scalar-tensor theories of\ngravity that corresponds to a regular growing solution in which the energy of\nthe relativistic degrees of freedom and the scalar field that regulates the\ngravitational strength compensate during the radiation dominated epoch on\nscales much larger than the Hubble radius. We study this isocurvature mode and\nits impact on anisotropies of the cosmic microwave background for the simplest\nscalar-tensor theory, i.e. the extended Jordan-Brans-Dicke gravity, in which\nthe scalar field also drives the acceleration of the Universe. We use Planck\ndata to constrain the amplitude of this isocurvature mode in the case of fixed\ncorrelation with the adiabatic mode and we show how this mode could be\ngenerated in a simple two field inflation model. \n\n"}
{"id": "1809.04033", "contents": "Title: Collisions of cosmic strings with chiral currents Abstract: We present an analytic study of cosmic superconducting chiral string\ncollisions in Minkowski space, applying the kinematic constraints that arise\nfrom the relevant generalization of the Nambu-Goto action. In particular, we\nrevisit the solution for chiral superconducting cosmic strings and demonstrate\nthat Y junction production for such strings is possible. We consider the\ncollision of chiral current-carrying straight strings and obtain the region in\nangle-velocity space that allows the production of string junctions. This study\ncontributes to the understanding of the complex evolution of chiral\nsuperconducting string networks. \n\n"}
{"id": "1809.04371", "contents": "Title: Exceptional points for photon pairs bound by nonlinear dissipation in\n  cavity arrays Abstract: We study theoretically the dissipative Bose-Hubbard model describing array of\ntunneling-coupled cavities with non-conservative photon-photon interaction. Our\ncalculation of the complex energy spectrum for the photon pairs reveals\nexceptional points where the two-photon states bound by nonlinear dissipation\nare formed. This improves fundamental understanding of the interplay of\nnon-Hermiticity and interactions in the quantum structures and can be\npotentially used for on-demand nonlinear light generation in photonic lattices. \n\n"}
{"id": "1809.07014", "contents": "Title: Extreme Scale De Novo Metagenome Assembly Abstract: Metagenome assembly is the process of transforming a set of short,\noverlapping, and potentially erroneous DNA segments from environmental samples\ninto the accurate representation of the underlying microbiomes's genomes.\nState-of-the-art tools require big shared memory machines and cannot handle\ncontemporary metagenome datasets that exceed Terabytes in size. In this paper,\nwe introduce the MetaHipMer pipeline, a high-quality and high-performance\nmetagenome assembler that employs an iterative de Bruijn graph approach.\nMetaHipMer leverages a specialized scaffolding algorithm that produces long\nscaffolds and accommodates the idiosyncrasies of metagenomes. MetaHipMer is\nend-to-end parallelized using the Unified Parallel C language and therefore can\nrun seamlessly on shared and distributed-memory systems. Experimental results\nshow that MetaHipMer matches or outperforms the state-of-the-art tools in terms\nof accuracy. Moreover, MetaHipMer scales efficiently to large concurrencies and\nis able to assemble previously intractable grand challenge metagenomes. We\ndemonstrate the unprecedented capability of MetaHipMer by computing the first\nfull assembly of the Twitchell Wetlands dataset, consisting of 7.5 billion\nreads - size 2.6 TBytes. \n\n"}
{"id": "1809.08325", "contents": "Title: The Rise of Certificate Transparency and Its Implications on the\n  Internet Ecosystem Abstract: In this paper, we analyze the evolution of Certificate Transparency (CT) over\ntime and explore the implications of exposing certificate DNS names from the\nperspective of security and privacy. We find that certificates in CT logs have\nseen exponential growth. Website support for CT has also constantly increased,\nwith now 33% of established connections supporting CT. With the increasing\ndeployment of CT, there are also concerns of information leakage due to all\ncertificates being visible in CT logs. To understand this threat, we introduce\na CT honeypot and show that data from CT logs is being used to identify targets\nfor scanning campaigns only minutes after certificate issuance. We present and\nevaluate a methodology to learn and validate new subdomains from the vast\nnumber of domains extracted from CT logged certificates. \n\n"}
{"id": "1809.09470", "contents": "Title: SS5G: Collision Resolution Protocol for Delay and Energy Efficient LoRa\n  Networks Abstract: Future 5G and Internet of Things (IoT) applications will heavily rely on\nlong-range communication technologies such as low-power wireless area networks\n(LPWANs). In particular, LoRaWAN built on LoRa physical layer is gathering\nincreasing interests, both from academia and industries, for enabling low-cost\nenergy efficient IoT wireless sensor networks for, e.g., environmental\nmonitoring over wide areas. While its communication range may go up to 20\nkilometers, the achievable bit rates in LoRaWAN are limited to a few kilobits\nper second. In the event of collisions, the perceived rate is further reduced\ndue to packet loss and retransmissions. Firstly, to alleviate the harmful\nimpacts of collisions, we propose a decoding algorithm that enables to resolve\nseveral superposed LoRa signals. Our proposed method exploits the slight\ndesynchronization of superposed signals and specific features of LoRa physical\nlayer. Secondly, we design a full MAC protocol enabling collision resolution.\nThe simulation results demonstrate that the proposed method outperforms\nconventional LoRaWAN jointly in terms of system throughput, energy efficiency\nas well as delay. These results show that our scheme is well suited for 5G and\nIoT systems, as one of their major goals is to provide the best trade-off among\nthese performance objectives. \n\n"}
{"id": "1809.09858", "contents": "Title: Dissecting Tendermint Abstract: In this paper we analyze Tendermint proposed in [7], one of the most popular\nblockchains based on PBFT Consensus. The current paper dissects Tendermint\nunder various system communication models and Byzantine adversaries. Our\nmethodology consists in identifying the algorithmic principles of Tendermint\nnecessary for a specific combination of communication model-adversary. This\nmethodology allowed to identify bugs [3] in preliminary versions of the\nprotocol ([19], [7]) and to prove its correctness under the most adversarial\nconditions: an eventually synchronous communication model and asymmetric\nByzantine faults. \n\n"}
{"id": "1809.10559", "contents": "Title: Obladi: Oblivious Serializable Transactions in the Cloud Abstract: This paper presents the design and implementation of Obladi, the first system\nto provide ACID transactions while also hiding access patterns. Obladi uses as\nits building block oblivious RAM, but turns the demands of supporting\ntransactions into a performance opportunity. By executing transactions within\nepochs and delaying commit decisions until an epoch ends, Obladi reduces the\namortized bandwidth costs of oblivious storage and increases overall system\nthroughput. These performance gains, combined with new oblivious mechanisms for\nconcurrency control and recovery, allow Obladi to execute OLTP workloads with\nreasonable throughput: it comes within 5x to 12x of a non-oblivious baseline on\nthe TPC-C, SmallBank, and FreeHealth applications. Latency overheads, however,\nare higher (70x on TPC-C). \n\n"}
{"id": "1810.00550", "contents": "Title: The Fornax Deep Survey (FDS) with the VST: IV. A size and magnitude\n  limited catalog of dwarf galaxies in the area of the Fornax cluster Abstract: The Fornax Deep Survey (FDS), an imaging survey in the u', g', r', and\ni'-bands, has a supreme resolution and image depth compared to the previous\nspatially complete Fornax Cluster Catalog (FCC). Our new data allows us to\nstudy the galaxies down to r'-band magnitude m$_{r'}\\approx$21 mag\n(M$_{r'}\\approx$-10.5 mag). These data provide an important legacy dataset to\nstudy the Fornax cluster. We aim to present the Fornax Deep Survey (FDS) dwarf\ngalaxy catalog, focusing on explaining the data reduction and calibrations,\nassessing the quality of the data, and describing the methods used for defining\nthe cluster memberships for the catalog objects. As a first step we used the\nSExtractor fine-tuned for dwarf galaxy detection, to find galaxies from the FDS\ndata, covering a 26 deg$^2$ area of the main cluster, and the area around the\nFornax A substructure. We made 2D-decompositions of the identified galaxies\nusing GALFIT. We used color-magnitude, luminosity-radius and\nluminosity-concentration relations to separate the cluster galaxies from the\nbackground galaxies. We then divided the cluster galaxies into early- and\nlate-type galaxies according to their morphology and gave first order\nmorphological classifications. Our final catalog includes 14,095 galaxies. We\nclassify 590 galaxies as being likely Fornax cluster galaxies, of which 564 are\ndwarfs (M$_{r'}$ > -18.5 mag) consisting our Fornax dwarf catalog. Of the\ncluster dwarfs we classify 470 as early-types, and 94 as late-type galaxies.\nOur final catalog reaches its 50% completeness limit at magnitude M$_{r'}$ =\n-10.5 mag and surface brightness $\\bar{\\mu}_{e,r'}$ = 26 mag arcsec-2, which is\napproximately three magnitudes deeper than the FCC. Based on previous works and\ncomparison with a spectroscopically confirmed subsample, we estimate that our\nfinal Fornax dwarf galaxy catalog has < 10% contamination from the background\nobjects. \n\n"}
{"id": "1810.02672", "contents": "Title: Cavity control of Excitons in two dimensional Materials Abstract: We propose a robust and efficient way of controlling the optical spectra of\ntwo-dimensional materials and van der Waals heterostructures by quantum cavity\nembedding. The cavity light-matter coupling leads to the formation of\nexciton-polaritons, a superposition of photons and excitons. Our first\nprinciples study demonstrates a reordering and mixing of bright and dark\nexcitons spectral features and in the case of a type II van-der-Waals\nheterostructure an inversion of intra and interlayer excitonic resonances. We\nfurther show that the cavity light-matter coupling strongly depends on the\ndielectric environment and can be controlled by encapsulating the active 2D\ncrystal in another dielectric material. Our theoretical calculations are based\non a newly developed non-perturbative many-body framework to solve the coupled\nelectron-photon Schr\\\"odinger equation in a quantum-electrodynamical extension\nof the Bethe-Salpeter approach. This approach enables the ab-initio simulations\nof exciton-polariton states and their dispersion from weak to strong cavity\nlight-matter coupling regimes. Our method is then extended to treat van der\nWaals heterostructures and encapsulated 2D materials using a simplified\nMott-Wannier description of the excitons that can be applied to very large\nsystems beyond reach for fully ab-initio approaches. \n\n"}
{"id": "1810.02974", "contents": "Title: Alpha Entanglement Codes: Practical Erasure Codes to Archive Data in\n  Unreliable Environments Abstract: Data centres that use consumer-grade disks drives and distributed\npeer-to-peer systems are unreliable environments to archive data without enough\nredundancy. Most redundancy schemes are not completely effective for providing\nhigh availability, durability and integrity in the long-term. We propose alpha\nentanglement codes, a mechanism that creates a virtual layer of highly\ninterconnected storage devices to propagate redundant information across a\nlarge scale storage system. Our motivation is to design flexible and practical\nerasure codes with high fault-tolerance to improve data durability and\navailability even in catastrophic scenarios. By flexible and practical, we mean\ncode settings that can be adapted to future requirements and practical\nimplementations with reasonable trade-offs between security, resource usage and\nperformance. The codes have three parameters. Alpha increases storage overhead\nlinearly but increases the possible paths to recover data exponentially. Two\nother parameters increase fault-tolerance even further without the need of\nadditional storage. As a result, an entangled storage system can provide high\navailability, durability and offer additional integrity: it is more difficult\nto modify data undetectably. We evaluate how several redundancy schemes perform\nin unreliable environments and show that alpha entanglement codes are flexible\nand practical codes. Remarkably, they excel at code locality, hence, they\nreduce repair costs and become less dependent on storage locations with poor\navailability. Our solution outperforms Reed-Solomon codes in many disaster\nrecovery scenarios. \n\n"}
{"id": "1810.03089", "contents": "Title: MOND in galaxy groups Abstract: Galaxy groups, which have hardly been looked at in MOND, afford probing the\nacceleration discrepancies in regions of system-parameter space that are not\naccessible in well-studied galactic systems, such as galaxies, galaxy clusters,\nand dwarf-spheroidal satellites of galaxies. Groups are typically the size of\ngalaxy-cluster cores, but have masses typically only a few times that of a\nsingle galaxy. Accelerations in groups get far below those in galaxies, and far\nbelow the MOND acceleration. So much so, that many groups might be affected by\nthe external-field effect, which is unique to MOND, due to background\naccelerations. Here, I analyze the MOND dynamics of 53 galaxy groups, recently\ncatalogued in 3 lists. Their Newtonian, K-band, dynamical $M/L$ ratios are a\nfew tens to several hundreds solar units, with $\\langle{M_d/L_K}\\rangle= (56,\n25, 30)~M_{\\odot}/L_{\\odot}$, respectively for the 3 lists; thus evincing very\nlarge acceleration discrepancies. I find here that MOND requires dynamical\n$M_M/L_K$ values of order $1~M_{\\odot}/L_{\\odot}$, with\n$\\langle{M_M/L_K}\\rangle=(0.8, 0.56, 1.0) ~M_{\\odot}/L_{\\odot}$, for the 3\nlists, which are in good agreement with population-synthesis stellar values,\nand with those found in individual galaxies. MOND thus accounts for the\nobserved dynamics in those groups with baryons alone, and no need for dark\nmatter -- an important extension of MOND analysis from galaxies to galactic\nsystems, which, to boot, have characteristic sizes of several hundred\nkiloparsecs, and accelerations much lower than probed before -- only a few\npercent of MOND's $a_0$. The acceleration discrepancies evinced by these groups\nthus conform to the deep-MOND prediction: $g\\approx (g_Na_0)^{1/2}$, down to\nthese very low accelerations ($g$ is the measured, and $g_N$ the baryonic,\nNewtonian acceleration). \n\n"}
{"id": "1810.03488", "contents": "Title: A Droplet Approach Based on Raptor Codes for Distributed Computing With\n  Straggling Servers Abstract: We propose a coded distributed computing scheme based on Raptor codes to\naddress the straggler problem. In particular, we consider a scheme where each\nserver computes intermediate values, referred to as droplets, that are either\nstored locally or sent over the network. Once enough droplets are collected,\nthe computation can be completed. Compared to previous schemes in the\nliterature, our proposed scheme achieves lower computational delay when the\ndecoding time is taken into account. \n\n"}
{"id": "1810.04201", "contents": "Title: Towards Lattice Quantum Chromodynamics on FPGA devices Abstract: In this paper we describe a single-node, double precision Field Programmable\nGate Array (FPGA) implementation of the Conjugate Gradient algorithm in the\ncontext of Lattice Quantum Chromodynamics. As a benchmark of our proposal we\ninvert numerically the Dirac-Wilson operator on a 4-dimensional grid on three\nXilinx hardware solutions: Zynq Ultrascale+ evaluation board, the Alveo U250\naccelerator and the largest device available on the market, the VU13P device.\nIn our implementation we separate software/hardware parts in such a way that\nthe entire multiplication by the Dirac operator is performed in hardware, and\nthe rest of the algorithm runs on the host. We find out that the FPGA\nimplementation can offer a performance comparable with that obtained using\ncurrent CPU or Intel's many core Xeon Phi accelerators. A possible multiple\nnode FPGA-based system is discussed and we argue that power-efficient High\nPerformance Computing (HPC) systems can be implemented using FPGA devices only. \n\n"}
{"id": "1810.04475", "contents": "Title: All-optical radiofrequency modulation of Anderson-localized modes Abstract: All-optical modulation of light relies on exploiting intrinsic material\nnonlinearities. However, this optical control is rather challenging due to the\nweak dependence of the refractive index and absorption coefficients on the\nconcentration of free carriers in standard semiconductors. To overcome this\nlimitation, resonant structures with high spatial and spectral confinement are\ncarefully designed to enhance the stored electromagnetic energy, thereby\nrequiring lower excitation power to achieve significant nonlinear effects.\nSmall mode-volume and high quality (Q)-factor cavities also offer an efficient\ncoherent control of the light field and the targeted optical properties. Here,\nwe report on optical resonances reaching Q - 10^5 induced by disorder on novel\nphotonic/phononic crystal waveguides. At relatively low excitation powers\n(below 1 mW), these cavities exhibit nonlinear effects leading to periodic (up\nto - 35 MHz) oscillations of their resonant wavelength. Our system represents a\ntest-bed to study the interplay between structural complexity and material\nnonlinearities and their impact on localization phenomena and introduces a\nnovel functionality to the toolset of disordered photonics. \n\n"}
{"id": "1810.05341", "contents": "Title: Tails of exit times from unstable equilibria on the line Abstract: For a one-dimensional smooth vector field in a neighborhood of an unstable\nequilibrium, we consider the associated dynamics perturbed by small noise. We\ngive a revealing elementary proof of a result proved earlier using heavy\nmachinery from Malliavin calculus. In particular, we obtain precise vanishing\nnoise asymptotics for the tail of the exit time and for the exit distribution\nconditioned on atypically long exits. \n\n"}
{"id": "1810.06088", "contents": "Title: IN-SYNC. VIII. Primordial Disk Frequencies in NGC 1333, IC 348, and the\n  Orion A Molecular Cloud Abstract: In this paper, we address two issues related to primordial disk evolution in\nthree clusters (NGC 1333, IC 348, and Orion A) observed by the INfrared Spectra\nof Young Nebulous Clusters (IN-SYNC) project. First, in each cluster, averaged\nover the spread of age, we investigate how disk lifetime is dependent on\nstellar mass. The general relation in IC 348 and Orion A is that primordial\ndisks around intermediate mass stars (2--5$M_{\\odot}$) evolve faster than those\naround loss mass stars (0.1--1$M_{\\odot}$), which is consistent with previous\nresults. However, considering only low mass stars, we do not find a significant\ndependence of disk frequency on stellar mass. These results can help to better\nconstrain theories on gas giant planet formation timescales. Secondly, in the\nOrion A molecular cloud, in the mass range of 0.35--0.7$M_{\\odot}$, we provide\nthe most robust evidence to date for disk evolution within a single cluster\nexhibiting modest age spread. By using surface gravity as an age indicator and\nemploying 4.5 $\\mu m$ excess as a primordial disk diagnostic, we observe a\ntrend of decreasing disk frequency for older stars. The detection of\nintra-cluster disk evolution in NGC 1333 and IC 348 is tentative, since the\nslight decrease of disk frequency for older stars is a less than 1-$\\sigma$\neffect. \n\n"}
{"id": "1810.06331", "contents": "Title: Randomly switched vector fields sharing a zero on a common invariant\n  face Abstract: We consider a Piecewise Deterministic Markov Process given by random\nswitching between finitely many vector fields vanishing at $0$. It has been\nshown recently that the behaviour of this process is mainly determined by the\nsigns of Lyapunov exponents. However, results have only been given when all\nthese exponents have the same sign. In this note, we consider the degenerate\ncase where the process leaves invariant some face and results are stated when\nthe Lyapunov exponents are of opposite signs. Applications are given to Lorenz\nvector fields with switching, and to SIRS model in random environment. \n\n"}
{"id": "1810.06549", "contents": "Title: Exceptional Surfaces in PT-Symmetric Photonic Systems Abstract: Exceptional points in non-Hermitian systems have recently been shown to\npossess nontrivial topological properties, and to give rise to many exotic\nphysical phenomena. However, most studies thus far have focused on isolated\nexceptional points or one-dimensional lines of exceptional points. Here, we\nsubstantially expand the space of exceptional systems by designing\ntwo-dimensional surfaces of exceptional points, and find that symmetries are a\nkey element to protect such exceptional surfaces. We construct them using\nsymmetry-preserving non-Hermitian deformations of topological nodal lines, and\nanalyze the associated symmetry, topology, and physical consequences. As a\npotential realization, we simulate a parity-time-symmetric 3D photonic crystal\nand indeed find the emergence of exceptional surfaces. Our work paves the way\nfor future explorations of systems of exceptional points in higher dimensions. \n\n"}
{"id": "1810.06930", "contents": "Title: Feedforward Neural Networks for Caching: Enough or Too Much? Abstract: We propose a caching policy that uses a feedforward neural network (FNN) to\npredict content popularity. Our scheme outperforms popular eviction policies\nlike LRU or ARC, but also a new policy relying on the more complex recurrent\nneural networks. At the same time, replacing the FNN predictor with a naive\nlinear estimator does not degrade caching performance significantly,\nquestioning then the role of neural networks for these applications. \n\n"}
{"id": "1810.07751", "contents": "Title: Intelligence Beyond the Edge: Inference on Intermittent Embedded Systems Abstract: Energy-harvesting technology provides a promising platform for future IoT\napplications. However, since communication is very expensive in these devices,\napplications will require inference \"beyond the edge\" to avoid wasting precious\nenergy on pointless communication. We show that application performance is\nhighly sensitive to inference accuracy. Unfortunately, accurate inference\nrequires large amounts of computation and memory, and energy-harvesting systems\nare severely resource-constrained. Moreover, energy-harvesting systems operate\nintermittently, suffering frequent power failures that corrupt results and\nimpede forward progress.\n  This paper overcomes these challenges to present the first full-scale\ndemonstration of DNN inference on an energy-harvesting system. We design and\nimplement SONIC, an intermittence-aware software system with specialized\nsupport for DNN inference. SONIC introduces loop continuation, a new technique\nthat dramatically reduces the cost of guaranteeing correct intermittent\nexecution for loop-heavy code like DNN inference. To build a complete system,\nwe further present GENESIS, a tool that automatically compresses networks to\noptimally balance inference accuracy and energy, and TAILS, which exploits SIMD\nhardware available in some microcontrollers to improve energy efficiency. Both\nSONIC & TAILS guarantee correct intermittent execution without any hand-tuning\nor performance loss across different power systems. Across three neural\nnetworks on a commercially available microcontroller, SONIC & TAILS reduce\ninference energy by 6.9x and 12.2x, respectively, over the state-of-the-art. \n\n"}
{"id": "1810.09300", "contents": "Title: RCanopus: Making Canopus Resilient to Failures and Byzantine Faults Abstract: Distributed consensus is a key enabler for many distributed systems including\ndistributed databases and blockchains. Canopus is a scalable distributed\nconsensus protocol that ensures that live nodes in a system agree on an ordered\nsequence of operations (called transactions). Unlike most prior consensus\nprotocols, Canopus does not rely on a single leader. Instead, it uses a virtual\ntree overlay for message dissemination to limit network traffic across\noversubscribed links. It leverages hardware redundancies, both within a rack\nand inside the network fabric, to reduce both protocol complexity and\ncommunication overhead. These design decisions enable Canopus to support large\ndeployments without significant performance degradation.\n  The existing Canopus protocol is resilient in the face of node and\ncommunication failures, but its focus is primarily on performance, so does not\nrespond well to other types of failures. For example, the failure of a single\nrack of servers causes all live nodes to stall. The protocol is also open to\nattack by Byzantine nodes, which can cause different live nodes to conclude the\nprotocol with different transaction orders. In this paper, we describe RCanopus\n(`resilent Canopus') which extends Canopus to add liveness, that is, allowing\nlive nodes to make progress, when possible, despite many types of failures.\nThis requires RCanopus to accurately detect and recover from failure despite\nusing unreliable failure detectors, and tolerance of Byzantine attacks. Second,\nRCanopus guarantees safety, that is, agreement amongst live nodes of\ntransaction order, in the presence of Byzantine attacks and network\npartitioning. \n\n"}
{"id": "1810.09315", "contents": "Title: Topological and metric recurrence for general Markov chains Abstract: Using ideas borrowed from topological dynamics and ergodic theory we\nintroduce topological and metric versions of the recurrence property for\ngeneral Markov chains. The main question of interest here is how large is the\nset of recurrent points. We show that under some mild technical assumptions the\nset of non recurrent points is of zero reference measure. Necessary and\nsufficient conditions for a reference measure $m$ (which needs not to be\ndynamically invariant) to satisfy this property are obtained. These results are\nnew even in the purely deterministic setting. \n\n"}
{"id": "1810.10318", "contents": "Title: Topological circuits of inductors and capacitors Abstract: Alternating current (ac) circuits can have electromagnetic edge modes\nprotected by symmetries, analogous to topological band insulators or\nsemimetals. How to make such a topological circuit? This paper illustrates a\nparticular design idea by analyzing a series of topological circuits consisting\npurely of inductors (L) and capacitors (C) connected to each other by wires to\nform periodic lattices. All the examples are treated using a unifying approach\nbased on Lagrangians and the dynamical $H$-matrix. First, the building blocks\nand permutation wiring are introduced using simple circuits in one dimension,\nthe SSH transmission line and a braided ladder analogous to the ice-tray model\nalso known as the $\\pi$-flux ladder. Then, more general building blocks (loops\nand stars) and wiring schemes ($m$-shifts) are introduced. The key concepts of\nemergent pseudo-spin degrees of freedom and synthetic gauge fields are\ndiscussed, and the connection to quantum lattice Hamiltonians is clarified. A\ndiagrammatic notation is introduced to simplify the design and presentation of\nmore complicated circuits. These building blocks are then used to construct\ntopological circuits in higher dimensions. The examples include the circuit\nanalog of Haldane's Chern insulator in two dimensions and quantum Hall\ninsulator in four dimensions featuring finite second Chern numbers. The\ntopological invariants and symmetry protection of the edge modes are discussed\nbased on the $H$-matrix. \n\n"}
{"id": "1810.10413", "contents": "Title: Thorium in solar twins: implications for habitability in rocky planets Abstract: We have investigated the thorium (Th) abundance in a sample of 53 thin disc\nsolar twins covering a wide range of ages. These data provide constrains on the\nmantle energy budget of terrestrial planets that can be formed over the\nevolution of the Galaxy's thin disc. We have estimated Th abundances with an\naverage precision of 0.025\\,dex (in both [Th/H] and [Th/Fe]) through\ncomprehensive spectral synthesis of a Th\\,II line present at 4019.1290\\,{\\AA},\nusing very high resolution (R\\,=\\,115,000) high quality HARPS spectra obtained\nat the ESO La Silla Observatory. We have confirmed that there is a large energy\nbudget from Th decay for maintaining mantle convection inside potential rocky\nplanets around solar twins, from the Galactic thin disc formation until now,\nbecause the pristine [Th/H]$_{\\rm ZAMS}$ is super-solar on average under a\nuniform dispersion of 0.056\\,dex (varying from +0.037 up to +0.138\\,dex based\non linear fits against isochrone stellar age). Comparing to neodymium (Nd) and\neuropium (Eu), two others neutron-capture elements, the stellar pristine\nabundance of Th follows Eu along the Galactic thin disc evolution, but it does\nnot follow Nd, probably because neodymium has a significant contribution from\nthe $s$-process (about 60\\,per\\,cent). \n\n"}
{"id": "1810.10454", "contents": "Title: Boundary of the Range of a random walk and the F\\\"olner property Abstract: The range process $R_n$ of a random walk is the collection of sites visited\nby the random walk up to time $n$. In this work we deal with the question of\nwhether the range process of a random walk or the range process of a cocycle\nover an ergodic transformation is almost surely a F\\\"olner sequence and show\nthe following results: % (a) The size of the inner boundary $|\\partial R_n|$ of\nthe range of recurrent aperiodic random walks on $\\mathbb{Z}^2$ with finite\nvariance and aperiodic random walks in $\\mathbb{Z}$ in the standard domain of\nattraction of the Cauchy distribution, divided by $\\frac{n}{\\log^2(n)}$,\nconverges to a constant almost surely. % (b) We establish a formula for the\nF\\\"olner asymptotic of transient cocycles over an ergodic probability\npreserving transformation and use it to show that for transient random walk on\ngroups which are not virtually cyclic, for almost every path, the range is not\na F\\\"olner sequence. % (c) For aperiodic random walks in the domain of\nattraction of symmetric $\\alpha$- stable distributions with $1<\\alpha\\leq 2$,\nwe prove a sharp polynomial upper bound for the decay at infinity of $|\\partial\nR_n|/|R_n|$. This last result shows that the range process of these random\nwalks is almost surely a F\\\"olner sequence. \n\n"}
{"id": "1810.11787", "contents": "Title: A Hitchhiker's Guide On Distributed Training of Deep Neural Networks Abstract: Deep learning has led to tremendous advancements in the field of Artificial\nIntelligence. One caveat however is the substantial amount of compute needed to\ntrain these deep learning models. Training a benchmark dataset like ImageNet on\na single machine with a modern GPU can take upto a week, distributing training\non multiple machines has been observed to drastically bring this time down.\nRecent work has brought down ImageNet training time to a time as low as 4\nminutes by using a cluster of 2048 GPUs. This paper surveys the various\nalgorithms and techniques used to distribute training and presents the current\nstate of the art for a modern distributed training framework. More\nspecifically, we explore the synchronous and asynchronous variants of\ndistributed Stochastic Gradient Descent, various All Reduce gradient\naggregation strategies and best practices for obtaining higher throughout and\nlower latency over a cluster such as mixed precision training, large batch\ntraining and gradient compression. \n\n"}
{"id": "1810.11817", "contents": "Title: Pitch-Angle Diffusion and Bohm-type Approximations in Diffusive Shock\n  Acceleration Abstract: The problem of accelerating cosmic rays is one of fundamental importance,\nparticularly given the uncertainty in the conditions inside the acceleration\nsites. Here we examine Diffusive Shock Acceleration in arbitrary turbulent\nmagnetic fields, constructing a new model that is capable of bridging the gap\nbetween the very weak ($\\delta B/B_0 \\ll 1$) and the strong turbulence regimes.\nTo describe the diffusion we provide quantitative analytical description of the\n\"Bohm exponent\" in each regime. We show that our results converge to the well\nknown quasi-linear theory in the weak turbulence regime. In the strong regime,\nwe quantify the limitations of the Bohm-type models. Furthermore, our results\naccount for the anomalous diffusive behaviour which has been noted previously.\nFinally, we discuss the implications of our model in the study of possible\nacceleration sites in different astronomical objects. \n\n"}
{"id": "1810.12859", "contents": "Title: JavaScript Convolutional Neural Networks for Keyword Spotting in the\n  Browser: An Experimental Analysis Abstract: Used for simple commands recognition on devices from smart routers to mobile\nphones, keyword spotting systems are everywhere. Ubiquitous as well are web\napplications, which have grown in popularity and complexity over the last\ndecade with significant improvements in usability under cross-platform\nconditions. However, despite their obvious advantage in natural language\ninteraction, voice-enabled web applications are still far and few between. In\nthis work, we attempt to bridge this gap by bringing keyword spotting\ncapabilities directly into the browser. To our knowledge, we are the first to\ndemonstrate a fully-functional implementation of convolutional neural networks\nin pure JavaScript that runs in any standards-compliant browser. We also apply\nnetwork slimming, a model compression technique, to explore the\naccuracy-efficiency tradeoffs, reporting latency measurements on a range of\ndevices and software. Overall, our robust, cross-device implementation for\nkeyword spotting realizes a new paradigm for serving neural network\napplications, and one of our slim models reduces latency by 66% with a minimal\ndecrease in accuracy of 4% from 94% to 90%. \n\n"}
{"id": "1811.00834", "contents": "Title: Arbitrary Pattern Formation on Infinite Grid by Asynchronous Oblivious\n  Robots Abstract: The Arbitrary Pattern Formation problem asks to design a distributed\nalgorithm that allows a set of autonomous mobile robots to form any specific\nbut arbitrary geometric pattern given as input. The problem has been\nextensively studied in literature in continuous domains. This paper\ninvestigates a discrete version of the problem where the robots are operating\non a two dimensional infinite grid. The robots are assumed to be autonomous,\nidentical, anonymous and oblivious. They operate in Look-Compute-Move cycles\nunder a fully asynchronous scheduler. The robots do not agree on any common\nglobal coordinate system or chirality. We have shown that a set of robots can\nform any arbitrary pattern, if their starting configuration is asymmetric. \n\n"}
{"id": "1811.01235", "contents": "Title: Hardness of computing and approximating predicates and functions with\n  leaderless population protocols Abstract: Population protocols are a distributed computing model appropriate for\ndescribing massive numbers of agents with limited computational power. A\npopulation protocol \"has an initial leader\" if every valid initial\nconfiguration contains a single agent in a special \"leader\" state that helps to\ncoordinate the computation. Although the class of predicates and functions\ncomputable with probability 1 is the same whether or not there is an initial\nleader (semilinear functions and predicates), it is not known whether a leader\nis necessary for fast computation. Efficient population protocols are generally\ndefined as those computing in polylogarithmic in $n$ (parallel) time. We\nconsider leaderless population protocols, regarding the computation finished\nwhen a configuration is reached from which a different output is no longer\nreachable.\n  In this setting we show that a wide class of functions and predicates\ncomputable by population protocols are not efficiently computable (they require\nat least linear time to stabilize on a correct answer), nor are some linear\nfunctions even efficiently approximable. For example, the widely studied\nparity, majority, and equality predicates cannot be computed in sublinear time.\nMoreover, it requires at least linear time for a population protocol even to\napproximate any linear function with a coefficient outside of $\\mathbb{N}$: for\nsufficiently small $\\gamma > 0$, the output of a sublinear time protocol can\nstabilize outside the interval $f(m) (1 \\pm \\gamma)$ on infinitely many inputs\n$m$. We also show that it requires linear time to exactly compute a wide range\nof semilinear functions (e.g., $f(m)=m$ if $m$ is even and $2m$ if $m$ is odd).\n  Finally, we show that with a sufficiently large value of $\\gamma$, a\npopulation protocol can approximate any linear $f$ with nonnegative rational\ncoefficients, within approximation factor $\\gamma$, in $O(\\log n)$ time. \n\n"}
{"id": "1811.01950", "contents": "Title: Audible Axions Abstract: Conventional approaches to probing axions and axion-like particles (ALPs)\ntypically rely on a coupling to photons. However, if this coupling is extremely\nweak, ALPs become invisible and are effectively decoupled from the Standard\nModel. Here we show that such invisible axions, which are viable candidates for\ndark matter, can produce a stochastic gravitational wave background in the\nearly universe. This signal is generated in models where the invisible axion\ncouples to a dark gauge boson that experiences a tachyonic instability when the\naxion begins to oscillate. Incidentally, the same mechanism also widens the\nviable parameter space for axion dark matter. Quantum fluctuations amplified by\nthe exponentially growing gauge boson modes source chiral gravitational waves.\nFor axion decay constants $f \\gtrsim 10^{17}$ GeV, this signal is detectable by\neither pulsar timing arrays or space/ground-based gravitational wave detectors\nfor a broad range of axion masses, thus providing a new window to probe\ninvisible axion models. \n\n"}
{"id": "1811.02084", "contents": "Title: Mesh-TensorFlow: Deep Learning for Supercomputers Abstract: Batch-splitting (data-parallelism) is the dominant distributed Deep Neural\nNetwork (DNN) training strategy, due to its universal applicability and its\namenability to Single-Program-Multiple-Data (SPMD) programming. However,\nbatch-splitting suffers from problems including the inability to train very\nlarge models (due to memory constraints), high latency, and inefficiency at\nsmall batch sizes. All of these can be solved by more general distribution\nstrategies (model-parallelism). Unfortunately, efficient model-parallel\nalgorithms tend to be complicated to discover, describe, and to implement,\nparticularly on large clusters. We introduce Mesh-TensorFlow, a language for\nspecifying a general class of distributed tensor computations. Where\ndata-parallelism can be viewed as splitting tensors and operations along the\n\"batch\" dimension, in Mesh-TensorFlow, the user can specify any\ntensor-dimensions to be split across any dimensions of a multi-dimensional mesh\nof processors. A Mesh-TensorFlow graph compiles into a SPMD program consisting\nof parallel operations coupled with collective communication primitives such as\nAllreduce. We use Mesh-TensorFlow to implement an efficient data-parallel,\nmodel-parallel version of the Transformer sequence-to-sequence model. Using TPU\nmeshes of up to 512 cores, we train Transformer models with up to 5 billion\nparameters, surpassing state of the art results on WMT'14 English-to-French\ntranslation task and the one-billion-word language modeling benchmark.\nMesh-Tensorflow is available at https://github.com/tensorflow/mesh . \n\n"}
{"id": "1811.02419", "contents": "Title: Anisotropic diffusion and the cosmic ray anisotropy Abstract: We argue that the diffusion of cosmic rays in the Galactic magnetic field has\nto be strongly anisotropic. As a result, the number of CR sources contributing\nto the local CR flux is reduced by a factor $\\sim 200$. The CR density is\ntherefore less smooth, and the contribution of individual sources to the CR\ndipole anisotropy becomes more prominent. In the case of anisotropic diffusion,\nthe observed plateau in the CR dipole anisotropy around 2-20 TeV can be\nexplained by a 2-3 Myr old CR source which dominates the local CR flux in this\nenergy range. \n\n"}
{"id": "1811.03582", "contents": "Title: Comment on the article \"Anisotropies in the astrophysical\n  gravitational-wave background: The impact of black hole distributions\" by\n  A.C. Jenkins et al. [arXiv:1810.13435] Abstract: We investigate the discrepancy pointed out by Jenkins et al. in Ref. [1]\nbetween the predictions of anisotropies of the astrophysical gravitational wave\n(GW) background, derived using different methods in Cusin et al. [2] and in\nJenkins et al. [3]. We show that this discrepancy is not due to our treatment\nof galaxy clustering, contrary to the claim made in Ref. [1] and we show that\nour modeling of clustering gives results in very good agreement with\nobservations. Furthermore we show that the power law spectrum used in Refs. [1]\nand [3] to describe galaxy clustering is incorrect on large scales and leads to\na different scaling of the multipoles $C_\\ell$. Moreover, we also explain that\nthe analytic derivation of the gravitational wave background correlation\nfunction in Refs. [1] and [3] is mathematically ill-defined and predicts an\namplitude of the angular power spectrum which depends on the (arbitrary) choice\nof a non-physical cut-off. \n\n"}
{"id": "1811.03640", "contents": "Title: Black hole growth through hierarchical black hole mergers in dense star\n  clusters: implications for gravitational wave detections Abstract: In a star cluster with a sufficiently large escape velocity, black holes\n(BHs) that are produced by BH mergers can be retained, dynamically form new BH\nbinaries, and merge again. This process can repeat several times and lead to\nsignificant mass growth. In this paper, we calculate the mass of the largest BH\nthat can be formed through repeated mergers of stellar seed BHs and determine\nhow its value depends on the physical properties of the host cluster. We adopt\nan analytical model in which the energy generated by the black hole binaries in\nthe cluster core is assumed to be regulated by the process of two-body\nrelaxation in the bulk of the system. This principle is used to compute the\nhardening rate of the binaries and to relate this to the time-dependent global\nproperties of the parent cluster. We demonstrate that in clusters with initial\nescape velocity $\\gtrsim 300\\rm km\\ s^{-1}$ in the core and density $\\gtrsim\n10^5\\ M_\\odot\\rm pc^{-3}$, repeated mergers lead to the formation of BHs in the\nmass range $100-10^5 \\,M_\\odot$, populating any upper mass gap created by\npair-instability supernovae. This result is independent of cluster metallicity\nand the initial BH spin distribution. We show that about $10\\%$ of the\npresent-day nuclear star clusters meet these extreme conditions, and estimate\nthat BH binary mergers with total mass $\\gtrsim 100\\,M _\\odot$ should be\nproduced in these systems at a maximum rate $\\approx 0.05 \\,\\rm Gpc^{-3}\nyr^{-1}$, corresponding to one detectable event every few years with Advanced\nLIGO/VIRGO at design sensitivity. The contribution of globular clusters is\nlikely to be negligible instead because the first BH merger remnant escapes\nfollowing the relativistic kick. A possible connection of our results to the\nformation of massive BH seeds in galaxy nuclei and globular clusters is\ndiscussed. \n\n"}
{"id": "1811.05077", "contents": "Title: Task Graph Transformations for Latency Tolerance Abstract: The Integrative Model for Parallelism (IMP) derives a task graph from a\nhigher level description of parallel algorithms. In this note we show how task\ngraph transformations can be used to achieve latency tolerance in the program\nexecution. We give a formal derivation of the graph transformation, and show\nthrough simulation how latency tolerant algorithms can be faster than the naive\nexecution in a strong scaling scenario. \n\n"}
{"id": "1811.05948", "contents": "Title: EdgeBench: Benchmarking Edge Computing Platforms Abstract: The emerging trend of edge computing has led several cloud providers to\nrelease their own platforms for performing computation at the 'edge' of the\nnetwork. We compare two such platforms, Amazon AWS Greengrass and Microsoft\nAzure IoT Edge, using a new benchmark comprising a suite of performance\nmetrics. We also compare the performance of the edge frameworks to cloud-only\nimplementations available in their respective cloud ecosystems. Amazon AWS\nGreengrass and Azure IoT Edge use different underlying technologies, edge\nLambda functions vs. containers, and so we also elaborate on platform features\navailable to developers. Our study shows that both of these edge platforms\nprovide comparable performance, which nevertheless differs in important ways\nfor key types of workloads used in edge applications. Finally, we discuss\nseveral current issues and challenges we faced in deploying these platforms. \n\n"}
{"id": "1811.06062", "contents": "Title: Central limit theorems with a rate of convergence for sequences of\n  transformations Abstract: Using Stein's method, we prove an abstract result that yields multivariate\ncentral limit theorems with a rate of convergence for time-dependent dynamical\nsystems. As examples we study a model of expanding circle maps and a\nquasistatic model. In both models we prove multivariate central limit theorems\nwith a rate of convergence. \n\n"}
{"id": "1811.06793", "contents": "Title: Higher order asymptotics for large deviations -- Part I Abstract: For sequences of non-lattice weakly dependent random variables, we obtain\nasymptotic expansions for Large Deviation Principles. These expansions,\ncommonly referred to as strong large deviation results, are in the spirit of\nEdgeworth Expansions for the Central Limit Theorem. We apply our results to\nshow that Diophantine iid sequences, finite state Markov chains, strongly\nergodic Markov chains and Birkhoff sums of smooth expanding maps & subshifts of\nfinite type satisfy these strong large deviation results. \n\n"}
{"id": "1811.08197", "contents": "Title: Identifiers in Registers - Describing Network Algorithms with Logic Abstract: We propose a formal model of distributed computing based on register automata\nthat captures a broad class of synchronous network algorithms. The local memory\nof each process is represented by a finite-state controller and a fixed number\nof registers, each of which can store the unique identifier of some process in\nthe network. To underline the naturalness of our model, we show that it has the\nsame expressive power as a certain extension of first-order logic on graphs\nwhose nodes are equipped with a total order. Said extension lets us define new\nfunctions on the set of nodes by means of a so-called partial fixpoint\noperator. In spirit, our result bears close resemblance to a classical theorem\nof descriptive complexity theory that characterizes the complexity class PSPACE\nin terms of partial fixpoint logic (a proper superclass of the logic we\nconsider here). \n\n"}
{"id": "1811.09094", "contents": "Title: Rates in almost sure invariance principle for quickly mixing dynamical\n  systems Abstract: For a large class of quickly mixing dynamical systems, we prove that the\nerror in the almost sure approximation with a Brownian motion is of order\nO((log n)^a) with a $\\ge$ 2. Specifically, we consider nonuniformly expanding\nmaps with exponential and stretched exponential decay of correlations, with\none-dimensional H{\\\"o}lder continuous observables. \n\n"}
{"id": "1811.09221", "contents": "Title: The typical cell in anisotropic tessellations Abstract: The typical cell is a key concept for stochastic-geometry based modeling in\ncommunication networks, as it provides a rigorous framework for describing\nproperties of a serving zone associated with a component selected at random in\na large network. We consider a setting where network components are located on\na large street network. While earlier investigations were restricted to street\nsystems without preferred directions, in this paper we derive the distribution\nof the typical cell in Manhattan-type systems characterized by a pattern of\nhorizontal and vertical streets. We explain how the mathematical description\ncan be turned into a simulation algorithm and provide numerical results\nuncovering novel effects when compared to classical isotropic networks. \n\n"}
{"id": "1811.09878", "contents": "Title: Hydra: A Peer to Peer Distributed Training & Data Collection Framework Abstract: The world needs diverse and unbiased data to train deep learning models.\nCurrently data comes from a variety of sources that are unmoderated to a large\nextent. The outcomes of training neural networks with unverified data yields\nbiased models with various strains of homophobia, sexism and racism. Another\ntrend observed in the world of deep learning is the rise of distributed\ntraining. Although cloud companies provide high performance compute for\ntraining models in the form of GPU's connected with a low latency network,\nusing these services comes at a high cost. We propose Hydra, a system that\nseeks to solve both of these problems in a novel manner by proposing a\ndecentralized distributed framework which utilizes the substantial amount of\nidle compute of everyday electronic devices like smartphones and desktop\ncomputers for training and data collection purposes. Hydra couples a\nspecialized distributed training framework on a network of these low powered\ndevices with a reward scheme that incentivizes users to provide high quality\ndata to unleash the compute capability on this training framework. Such a\nsystem has the ability to capture data from a wide variety of diverse sources\nwhich has been an issue in the current scenario of deep learning. Hydra brings\nin several new innovations in training on low powered devices including a fault\ntolerant version of the All Reduce algorithm. Furthermore we introduce a\nreinforcement learning policy to decide the size of training jobs on different\nmachines on a heterogeneous cluster of devices with varying network latencies\nfor Synchronous SGD. The novel thing about such a network is the ability of\neach machine to shut down and resume training capabilities at any point of time\nwithout restarting the overall training. To enable such an asynchronous\nbehaviour we propose a communication framework inspired by the Bittorrent\nprotocol and the Kademlia DHT. \n\n"}
{"id": "1811.10617", "contents": "Title: Accessing electromagnetic properties of matter with cylindrical vector\n  beams Abstract: Cylindrical vector beam (CVB) is a structured lightwave characterized by its\ntopologically nontrivial nature of the optical polarization. The unique\nelectromagnetic field configuration of CVBs has been exploited to optical\ntweezers, laser accelerations, and so on. However, use of CVBs in research\nfields outside optics such as condensed matter physics has not progressed. In\nthis paper, we propose potential applications of CVBs to those fields based on\na general argument on their absorption by matter. We show that pulse azimuthal\nCVBs around terahertz (THz) or far-infrared frequencies can be a unique and\npowerful mean for time-resolved spectroscopy of magnetic properties of matter\nand claim that an azimuthal electric field of a pulse CVB would be a novel way\nof studying and controlling edge currents in topological materials. We also\ndemonstrate how powerful CVBs will be as a tool for Floquet engineering of\nnonequilibrium states of matter. \n\n"}
{"id": "1811.12417", "contents": "Title: Star formation and gas in the minor merger UGC 10214 Abstract: UGC 10214 is a minor merger in which a dwarf galaxy has interacted with a\nlarge spiral galaxy $\\sim$250 Myr ago and produced a perturbed disk and a giant\ntidal tail. We use a multiwavelength dataset in order to study the present and\npast star formation rate (SFR) and its relation to the gas and stellar mass at\na spatial resolution down to 4 kpc. UGC 10214 is a very massive (stellar mass\n$M_{{\\rm \\star}}$ = $1.28\\times 10^{11}$$M_\\odot$) galaxy with a low gas\nfraction ($M_{{\\rm gas}}$/$M_{{\\rm \\star}}$ = 0.24), a high molecular gas\nfraction ($M_{{\\rm H}_2}$/$M_{\\rm HI}$ = 0.4) and a modest SFR (2-5 $M_\\odot$\nyr$^{-1}$). The comparison of the molecular gas mass and current SFR gives a\nmolecular gas depletion time of about $\\sim$ 2 Gyr (based on H$\\alpha$),\ncomparable to those of normal spiral galaxies. Both from a comparison of the\nH$\\alpha$ emission, tracing the current SFR, and far-ultraviolet (FUV)\nemission, tracing the recent SFR during the past tens of Myr, as well as from\nspectral energy distribution (SED) fitting with CIGALE, we find that the SFR\nhas increased by a factor of about 2-3 during the recent past. This increase is\nparticularly noticeable in the centre of the galaxy. A pixel-to-pixel\ncomparison of the SFR, molecular gas mass and stellar mass shows that the\ncentral region has had a depressed FUV-traced SFR, both compared to the\nmolecular gas and the stellar mass, whereas the H$\\alpha$-traced SFR shows a\nnormal level. The atomic and molecular gas distribution is asymmetric, but the\nposition-velocity diagram along the major axis shows a pattern of regular\nrotation. We conclude that the minor merger has most likely caused variations\nin the SFR in the past resulting in a moderate increase of the SFR, but it has\nnot perturbed the gas significantly so that the molecular depletion time\nremains normal. \n\n"}
{"id": "1811.12628", "contents": "Title: OHIE: Blockchain Scaling Made Simple Abstract: Many blockchain consensus protocols have been proposed recently to scale the\nthroughput of a blockchain with available bandwidth. However, these protocols\nare becoming increasingly complex, making it more and more difficult to produce\nproofs of their security guarantees. We propose a novel permissionless\nblockchain protocol OHIE which explicitly aims for simplicity. OHIE composes as\nmany parallel instances of Bitcoin's original (and simple) backbone protocol as\nneeded to achieve excellent throughput. We formally prove the safety and\nliveness properties of OHIE. We demonstrate its performance with a prototype\nimplementation and large-scale experiments with up to 50,000 nodes. In our\nexperiments, OHIE achieves linear scaling with available bandwidth, providing\nabout 4-10 Mbps transaction throughput (under 8-20 Mbps per-node available\nbandwidth configurations) and at least about 20x better decentralization over\nprior works. \n\n"}
{"id": "1811.12706", "contents": "Title: The Approach to Managing Provenance Metadata and Data Access Rights in\n  Distributed Storage Using the Hyperledger Blockchain Platform Abstract: The paper suggests a new approach based on blockchain technologies and smart\ncontracts to creation of a distributed system for managing provenance metadata,\nas well as access rights to data in distributed storages, which is\nfault-tolerant, safe and secure from the point of view of preservation of\nmetadata records from accidental or intentional distortions. The implementation\nof the proposed approach is based on the permissioned blockchains and on the\nHyperledger Fabric blockchain platform in conjunction with Hyperledger\nComposer. \n\n"}
{"id": "1811.12742", "contents": "Title: Dynamic Load Balancing Techniques for Particulate Flow Simulations Abstract: Parallel multiphysics simulations often suffer from load imbalances\noriginating from the applied coupling of algorithms with spatially and\ntemporally varying workloads. It is thus desirable to minimize these imbalances\nto reduce the time to solution and to better utilize the available hardware\nresources. Taking particulate flows as an illustrating example application, we\npresent and evaluate load balancing techniques that tackle this challenging\ntask. This involves a load estimation step in which the currently generated\nworkload is predicted. We describe in detail how such a workload estimator can\nbe developed. In a second step, load distribution strategies like space-filling\ncurves or graph partitioning are applied to dynamically distribute the load\namong the available processes. To compare and analyze their performance, we\nemploy these techniques to a benchmark scenario and observe a reduction of the\nload imbalances by almost a factor of four. This results in a decrease of the\noverall runtime by 14% for space-filling curves. \n\n"}
{"id": "1811.12924", "contents": "Title: Joint Information Freshness and Completion Time Optimization for\n  Vehicular Networks Abstract: The demand for real-time cloud applications has seen an unprecedented growth\nover the past decade. These applications require rapidly data transfer and fast\ncomputations. This paper considers a scenario where multiple IoT devices update\ninformation on the cloud, and request a computation from the cloud at certain\ntimes. The time required to complete the request for computation includes the\ntime to wait for computation to start on busy virtual machines, performing the\ncomputation, waiting and service in the networking stage for delivering the\noutput to the end user. In this context, the freshness of the information is an\nimportant concern and is different from the completion time. This paper\nproposes novel scheduling strategies for both computation and networking\nstages. Based on these strategies, the age-of-information (AoI) metric and the\ncompletion time are characterized. A convex combination of the two metrics is\noptimized over the scheduling parameters. The problem is shown to be convex and\nthus can be solved optimally. Moreover, based on the offline policy, an online\nalgorithm for job scheduling is developed. Numerical results demonstrate\nsignificant improvement as compared to the considered baselines. \n\n"}
{"id": "1812.01823", "contents": "Title: Approximation with Error Bounds in Spark Abstract: We introduce a sampling framework to support approximate computing with\nestimated error bounds in Spark. Our framework allows sampling to be performed\nat the beginning of a sequence of multiple transformations ending in an\naggregation operation. The framework constructs a data provenance tree as the\ncomputation proceeds, then combines the tree with multi-stage sampling and\npopulation estimation theories to compute error bounds for the aggregation.\nWhen information about output keys are available early, the framework can also\nuse adaptive stratified reservoir sampling to avoid (or reduce) key losses in\nthe final output and to achieve more consistent error bounds across popular and\nrare keys. Finally, the framework includes an algorithm to dynamically choose\nsampling rates to meet user specified constraints on the CDF of error bounds in\nthe outputs. We have implemented a prototype of our framework called\nApproxSpark, and used it to implement five approximate applications from\ndifferent domains. Evaluation results show that ApproxSpark can (a)\nsignificantly reduce execution time if users can tolerate small amounts of\nuncertainties and, in many cases, loss of rare keys, and (b) automatically find\nsampling rates to meet user specified constraints on error bounds. We also\nexplore and discuss extensively trade-offs between sampling rates, execution\ntime, accuracy and key loss. \n\n"}
{"id": "1812.04000", "contents": "Title: Geometric response of quantum Hall states to electric fields Abstract: Exploiting novel aspects of the quantum geometry of charged particles in a\nmagnetic field via gauge-invariant variables, we provide tangible connections\nbetween the response of quantum Hall fluids to non-uniform electric fields and\nthe characteristic geometry of electronic motion in the presence of magnetic\nand electric fields. The geometric picture we provide motivates the following\nconjecture: non-uniform electric fields mimic the presence of spatial\ncurvature. Consequently, the gravitational coupling constant also appears in\nthe charge response to non-uniform electric fields. \n\n"}
{"id": "1812.04009", "contents": "Title: The Three Hundred Project: The evolution of galaxy cluster density\n  profiles Abstract: Recent numerical studies of the dark matter density profiles of massive\ngalaxy clusters ($M_{\\rm halo} > 10^{15}$M$_{\\odot}$) show that their median\nradial mass density profile remains unchanged up to $z > 1$, displaying a\nhighly self-similar evolution. We verify this by using the data set of the THE\nTHREE HUNDRED project, i.e. 324 cluster-sized haloes as found in full physics\nhydrodynamical simulations. We track the progenitors of the mass-complete\nsample of clusters at $z=0$, and find that their median shape is already in\nplace by $z=2.5$. However, selecting a dynamically relaxed subsample ($\\sim16$\nper cent of the clusters), we observe a shift of the scale radius $r_s$ towards\nlarger values at earlier times. Classifying the whole sample by formation time,\nthis evolution is understood as a result of a two-phase halo mass accretion\nprocess. Early-forming clusters -- identified as relaxed today -- have already\nentered their slow accretion phase, hence their mass growth occurs mostly at\nthe outskirts. Late-forming clusters -- which are still unrelaxed today -- are\nin their fast accretion phase, thus the central region of the clusters is still\ngrowing. We conclude that the density profile of galaxy clusters shows a\nprofound self-similarity out to redshifts $z\\sim2.5$. This result holds for\nboth gas and total density profiles when including baryonic physics, as\nreported here for two rather distinct sub-grid models. \n\n"}
{"id": "1812.04472", "contents": "Title: \"Cartesian light\": unconventional propagation of light in a 3D\n  superlattice of coupled cavities within a 3D photonic band gap Abstract: We explore the unconventional propagation of light in a three-dimensional\n(3D) superlattice of coupled resonant cavities in a 3D photonic band gap\ncrystal. Such a 3D cavity superlattice is the photonic analogue of the Anderson\nmodel for spins and electrons in the limit of zero disorder. Using the\nplane-wave expansion method, we calculate the dispersion relations of the 3D\ncavity superlattice with the cubic inverse woodpile structure that reveal five\ncoupled-cavity bands, typical of quadrupole-like resonances. For three out of\nfive bands, we observe that the dispersion bandwidth is significantly larger in\nthe $(k_x, k_z)$-diagonal directions than in other directions. To explain the\ndirectionality of the dispersion bandwidth, we employ the tight-binding method\nfrom which we derive coupling coefficients in 3D. For all converged\ncoupled-cavity bands, we find that light hops predominantly in a few\nhigh-symmetry directions including the Cartesian $(x, y, z)$ directions,\ntherefore we propose the name \"Cartesian light\". Such 3D Cartesian hopping of\nlight in a band gap yields propagation as superlattice Bloch modes that differ\nfundamentally from the conventional 3D spatially-extended Bloch wave\npropagation in crystals, from light tunneling through a band gap, from\ncoupled-resonator optical waveguiding, and also from light diffusing at the\nedge of a gap. \n\n"}
{"id": "1812.05352", "contents": "Title: Efficient Dispersion of Mobile Robots on Arbitrary Graphs and Grids Abstract: The mobile robot dispersion problem on graphs asks $k\\leq n$ robots placed\ninitially arbitrarily on the nodes of an $n$-node anonymous graph to reposition\nautonomously to reach a configuration in which each robot is on a distinct node\nof the graph. This problem is of significant interest due to its relationship\nto other fundamental robot coordination problems, such as exploration,\nscattering, load balancing, and relocation of self-driven electric cars\n(robots) to recharge stations (nodes). In this paper, we provide two novel\ndeterministic algorithms for dispersion, one for arbitrary graphs and another\nfor grid graphs, in a synchronous setting where all robots perform their\nactions in every time step. Our algorithm for arbitrary graphs has\n$O(\\min(m,k\\Delta) \\cdot \\log k)$ steps runtime using $O(\\log n)$ bits of\nmemory at each robot, where $m$ is the number of edges and $\\Delta$ is the\nmaximum degree of the graph. This is an exponential improvement over the\n$O(mk)$ steps best previously known algorithm. In particular, the runtime of\nour algorithm is optimal (up to a $O(\\log k)$ factor) in constant-degree\narbitrary graphs. Our algorithm for grid graphs has $O(\\min(k,\\sqrt{n}))$ steps\nruntime using $\\Theta(\\log k)$ bits at each robot. This is the first algorithm\nfor dispersion in grid graphs. Moreover, this algorithm is optimal for both\nmemory and time when $k=\\Omega(n)$. \n\n"}
{"id": "1812.06338", "contents": "Title: The Origin of the Multiwavelength Emission of PKS 0502+049 Abstract: The origin of the multiwavelength emission from PKS 0502+049 neighboring the\nfirst cosmic neutrino source TXS 0506+056 is studied using the data observed by\nFermi-LAT and Swift UVOT/XRT. This source was in a flaring state in the\nconsidered bands before and after the neutrino observations in 2014-2015,\ncharacterized by hard emission spectra in the X-ray and $\\gamma$-ray bands,\n$1.5-1.8$ and $\\leq2.0$, respectively. During the neutrino observations, the\n$\\gamma$-ray spectrum shows a deviation from a simple power-law shape,\nindicating a spectral cutoff at $E_c =8.50\\pm2.06$ GeV. The spectral energy\ndistributions of PKS 0502+049 are modeled within a one-zone leptonic scenario\nassuming that high energy $\\gamma$-ray emission is produced either by IC\nscattering of synchrotron or dusty torus photons by the electron population\nthat produce the radio-to-optical emission. Alternatively, the observed\n$\\gamma$-rays are modeled considering inelastic interaction of protons, when\nthe jet interacts with a dense gaseous target. During the neutrino\nobservations, the $\\gamma$-ray data are best described when the proton energy\ndistribution is $E_p^{-2.61}$ and if the protons are effectively accelerated up\nto 10 PeV, the expected neutrino rate is $\\sim1.1$ events within 110 days. In\nprinciple, if the $\\gamma$-ray emission with a hard photon index observed\nduring the flaring periods extends up to TeV, the expected rate can be somewhat\nhigher, but such conditions are hardly possible. Within the hadronic\ninterpretation, the $\\gamma$-ray data can be reproduced only when the accretion\nrate of PKS 0502+049 is in the supper-Eddington regime, as opposed to the\nleptonic scenario. From the point of view of the necessary energetics as well\nas considering that the required parameters are physically reasonable, when the\nneutrinos were observed, the broadband emission from PKS 0502+049 is most\nlikely of a leptonic origin. \n\n"}
{"id": "1812.07264", "contents": "Title: Worst-case Bounds and Optimized Cache on $M^{th}$ Request Cache\n  Insertion Policies under Elastic Conditions Abstract: Cloud services and other shared third-party infrastructures allow individual\ncontent providers to easily scale their services based on current resource\ndemands. In this paper, we consider an individual content provider that wants\nto minimize its delivery costs under the assumptions that the storage and\nbandwidth resources it requires are elastic, the content provider only pays for\nthe resources that it consumes, and costs are proportional to the resource\nusage. Within this context, we (i) derive worst-case bounds for the optimal\ncost and competitive cost ratios of different classes of \"cache on $M^{th}$\nrequest\" cache insertion policies, (ii) derive explicit average cost\nexpressions and bounds under arbitrary inter-request distributions, (iii)\nderive explicit average cost expressions and bounds for short-tailed\n(deterministic, Erlang, and exponential) and heavy-tailed (Pareto)\ninter-request distributions, and (iv) present numeric and trace-based\nevaluations that reveal insights into the relative cost performance of the\npolicies. Our results show that a window-based \"cache on $2^{nd}$ request\"\npolicy using a single threshold optimized to minimize worst-case costs provides\ngood average performance across the different distributions and the full\nparameter ranges of each considered distribution, making it an attractive\nchoice for a wide range of practical conditions where request rates of\nindividual file objects typically are not known and can change quickly. \n\n"}
{"id": "1812.07930", "contents": "Title: Fermionic time-reversal symmetry in a photonic topological insulator Abstract: Much of the recent enthusiasm directed towards topological insulators as a\nnew state of matter is motivated by their hallmark feature of protected chiral\nedge states. In fermionic systems, Kramers degeneracy gives rise to these\nentities in the presence of time-reversal symmetry (TRS). In contrast, bosonic\nsystems obeying TRS are generally assumed to be fundamentally precluded from\nsupporting edge states. In this work, we dispel this perception and\nexperimentally demonstrate counter-propagating chiral states at the edge of a\ntime-reversal-symmetric photonic waveguide structure. The pivotal step in our\napproach is encoding the effective spin of the propagating states as a degree\nof freedom of the underlying waveguide lattice, such that our photonic\ntopological insulator is characterised by a $\\mathbb{Z}_2$-type invariant. Our\nfindings allow for fermionic properties to be harnessed in bosonic systems,\nthereby opening new avenues for topological physics in photonics as well as\nacoustics, mechanics and even matter waves. \n\n"}
{"id": "1812.08446", "contents": "Title: Atomic Appends: Selling Cars and Coordinating Armies with Multiple\n  Distributed Ledgers Abstract: The various applications using Distributed Ledger Technologies (DLT) or\nblockchains, have led to the introduction of a new `marketplace' where multiple\ntypes of digital assets may be exchanged. As each blockchain is designed to\nsupport specific types of assets and transactions, and no blockchain will\nprevail, the need to perform interblockchain transactions is already pressing.\n  In this work we examine the fundamental problem of interoperable and\ninterconnected blockchains. In particular, we begin by introducing the\nMulti-Distributed Ledger Objects (MDLO), which is the result of aggregating\nmultiple Distributed Ledger Objects -- DLO (a DLO is a formalization of the\nblockchain) and that supports append and get operations of records (e.g.,\ntransactions) in them from multiple clients concurrently. Next, we define the\nAtomicAppends problem, which emerges when the exchange of digital assets\nbetween multiple clients may involve appending records in more than one DLO.\nSpecifically, AtomicAppend requires that either all records will be appended on\nthe involved DLOs or none. We examine the solvability of this problem assuming\nrational and risk-averse clients that may fail by crashing, and under different\nclient utility and append models, timing models, and client failure scenarios.\nWe show that for some cases the existence of an intermediary is necessary for\nthe problem solution. We propose the implementation of such intermediary over a\nspecialized blockchain, we term Smart DLO (SDLO), and we show how this can be\nused to solve the AtomicAppends problem even in an asynchronous, client\ncompetitive environment, where all the clients may crash. \n\n"}
{"id": "1812.08491", "contents": "Title: cuPC: CUDA-based Parallel PC Algorithm for Causal Structure Learning on\n  GPU Abstract: The main goal in many fields in the empirical sciences is to discover causal\nrelationships among a set of variables from observational data. PC algorithm is\none of the promising solutions to learn underlying causal structure by\nperforming a number of conditional independence tests. In this paper, we\npropose a novel GPU-based parallel algorithm, called cuPC, to execute an\norder-independent version of PC. The proposed solution has two variants, cuPC-E\nand cuPC-S, which parallelize PC in two different ways for multivariate normal\ndistribution. Experimental results show the scalability of the proposed\nalgorithms with respect to the number of variables, the number of samples, and\ndifferent graph densities. For instance, in one of the most challenging\ndatasets, the runtime is reduced from more than 11 hours to about 4 seconds. On\naverage, cuPC-E and cuPC-S achieve 500 X and 1300 X speedup, respectively,\ncompared to serial implementation on CPU. The source code of cuPC is available\nonline [1]. \n\n"}
{"id": "1812.10624", "contents": "Title: Stanza: Layer Separation for Distributed Training in Deep Learning Abstract: The parameter server architecture is prevalently used for distributed deep\nlearning. Each worker machine in a parameter server system trains the complete\nmodel, which leads to a hefty amount of network data transfer between workers\nand servers. We empirically observe that the data transfer has a non-negligible\nimpact on training time.\n  To tackle the problem, we design a new distributed training system called\nStanza. Stanza exploits the fact that in many models such as convolution neural\nnetworks, most data exchange is attributed to the fully connected layers, while\nmost computation is carried out in convolutional layers. Thus, we propose layer\nseparation in distributed training: the majority of the nodes just train the\nconvolutional layers, and the rest train the fully connected layers only.\nGradients and parameters of the fully connected layers no longer need to be\nexchanged across the cluster, thereby substantially reducing the data transfer\nvolume. We implement Stanza on PyTorch and evaluate its performance on Azure\nand EC2. Results show that Stanza accelerates training significantly over\ncurrent parameter server systems: on EC2 instances with Tesla V100 GPU and 10Gb\nbandwidth for example, Stanza is 1.34x--13.9x faster for common deep learning\nmodels. \n\n"}
{"id": "1812.10844", "contents": "Title: AT2: Asynchronous Trustworthy Transfers Abstract: Many blockchain-based protocols, such as Bitcoin, implement a decentralized\nasset transfer (or exchange) system. As clearly stated in the original paper by\nNakamoto, the crux of this problem lies in prohibiting any participant from\nengaging in double-spending. There seems to be a common belief that consensus\nis necessary for solving the double-spending problem. Indeed, whether it is for\na permissionless or a permissioned environment, the typical solution uses\nconsensus to build a totally ordered ledger of submitted transfers. In this\npaper we show that this common belief is false: consensus is not needed to\nimplement of a decentralized asset transfer system. We do so by introducing AT2\n(Asynchronous Trustworthy Transfers), a class of consensusless algorithms. To\nshow formally that consensus is unnecessary for asset transfers, we consider\nthis problem first in the shared-memory context. We introduce AT2$_{SM}$, a\nwait-free algorithm that asynchronously implements asset transfer in the\nread-write shared-memory model. In other words, we show that the consensus\nnumber of an asset-transfer object is one. In the message passing model with\nByzantine faults, we introduce a generic asynchronous algorithm called\nAT2$_{MP}$ and discuss two instantiations of this solution. First, AT2$_{D}$\nensures deterministic guarantees and consequently targets a small scale\ndeployment (tens to hundreds of nodes), typically for a permissioned\nenvironment. Second, AT2$_{P}$ provides probabilistic guarantees and scales\nwell to a very large system size (tens of thousands of nodes), ensuring\nlogarithmic latency and communication complexity. Instead of consensus, we\nconstruct AT2$_{D}$ and AT2$_{P}$ on top of a broadcast primitive with causal\nordering guarantees offering deterministic and probabilistic properties,\nrespectively. \n\n"}
{"id": "1901.00302", "contents": "Title: openCoT: The opensource Cloud of Things platform Abstract: In order to address the complexity and extensiveness of technology, Cloud\nComputing is utilized with four main service models. The most recent service\nmodel, function-as-a-service, enables developers to develop their application\nin a function-based structure and then deploy it to the Cloud. Using an optimum\nelastic auto-scaling, the performance of executing an application over FaaS\nCloud, overcomes the extra overhead and reduces the total cost. However,\nresearchers need a simple and well-documented FaaS Cloud manager in order to\nimplement their proposed Auto-scaling algorithms. In this paper, we represent\nthe openCoT platform and explain its building blocks and details. Experimental\nresults show that executing a function (invoking and passing arguments) and\nreturning the result using openCoT takes 21 ms over a remote connection. The\nsource code of openCoT is available in the GitHub repository of the project\n(\\code{www.github.com/adanayi/opencot}) for public usage. \n\n"}
{"id": "1901.00479", "contents": "Title: Towards the Locality of Vizing's Theorem Abstract: Vizing showed that it suffices to color the edges of a simple graph using\n$\\Delta + 1$ colors, where $\\Delta$ is the maximum degree of the graph.\nHowever, up to this date, no efficient distributed edge-coloring algorithms are\nknown for obtaining such a coloring, even for constant degree graphs. The\ncurrent algorithms that get closest to this number of colors are the randomized\n$(\\Delta + \\tilde{\\Theta}(\\sqrt{\\Delta}))$-edge-coloring algorithm that runs in\n$\\text{polylog}(n)$ rounds by Chang et al. (SODA '18) and the deterministic\n$(\\Delta + \\text{polylog}(n))$-edge-coloring algorithm that runs in\n$\\text{poly}(\\Delta, \\log n)$ rounds by Ghaffari et al. (STOC '18).\n  We present two distributed edge-coloring algorithms that run in\n$\\text{poly}(\\Delta,\\log n)$ rounds. The first algorithm, with randomization,\nuses only $\\Delta+2$ colors. The second algorithm is a deterministic algorithm\nthat uses $\\Delta+ O(\\log n/ \\log \\log n)$ colors. Our approach is to reduce\nthe distributed edge-coloring problem into an online, restricted version of\nballs-into-bins problem. If $\\ell$ is the maximum load of the bins, our\nalgorithm uses $\\Delta + 2\\ell - 1$ colors. We show how to achieve $\\ell = 1$\nwith randomization and $\\ell = O(\\log n / \\log \\log n)$ without randomization. \n\n"}
{"id": "1901.00963", "contents": "Title: Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:\n  Delay-Optimal Scheduling Abstract: Millimeter wave (mmWave) technologies have the potential to achieve very high\ndata rates, but suffer from intermittent connectivity. In this paper, we\nprovision an architecture to integrate sub-6 GHz and mmWave technologies, where\nwe incorporate the sub-6 GHz interface as a fallback data transfer mechanism to\ncombat blockage and intermittent connectivity of the mmWave communications. To\nthis end, we investigate the problem of scheduling data packets across the\nmmWave and sub-6 GHz interfaces such that the average delay of system is\nminimized. This problem can be formulated as Markov Decision Process. We first\ninvestigate the problem of discounted delay minimization, and prove that the\noptimal policy is of the threshold-type, i.e., data packets should always be\nrouted to the mmWave interface as long as the number of packets in the system\nis smaller than a threshold. Then, we show that the results of the discounted\ndelay problem hold for the average delay problem as well. Through numerical\nresults, we demonstrate that under heavy traffic, integrating sub-6 GHz with\nmmWave can reduce the average delay by up to 70%. Further, our scheduling\npolicy substantially reduces the delay over the celebrated MaxWeight policy. \n\n"}
{"id": "1901.01863", "contents": "Title: Beyond socket options: making the Linux TCP stack truly extensible Abstract: The Transmission Control Protocol (TCP) is one of the most important\nprotocols in today's Internet. Its specification and implementations have been\nrefined for almost forty years. The Linux TCP stack is one of the most widely\nused TCP stacks given its utilisation on servers and Android smartphones and\ntablets. However, TCP and its implementations evolve very slowly. In this\npaper, we demonstrate how to leverage the eBPF virtual machine that is part of\nthe recent versions of the Linux kernel to make the TCP stack easier to extend.\n  We demonstrate a variety of use cases where the eBPF code is injected inside\na running kernel to update or tune the TCP implementation. We first implement\nthe TCP User Timeout Option. Then we propose a new option that enables a client\nto request a server to use a specific congestion control scheme. Our third\nextension is a TCP option that sets the initial congestion window. We then\ndemonstrate how eBPF code can be used to tune the acknowledgment strategy. \n\n"}
{"id": "1901.02303", "contents": "Title: PMU-based Distributed Non-iterative Algorithm for Real-time Voltage\n  Stability Monitoring Abstract: The Phasor measurement unit (PMU) measurements are mandatory to monitor the\npower system's voltage stability margin in an online manner. Monitoring is key\nto the secure operation of the grid. Traditionally, online monitoring of\nvoltage stability using synchrophasors required a centralized communication\narchitecture, which leads to high investment cost and cyber-security concerns.\nThe increasing importance of cyber-security and low investment cost have\nrecently led to the development of distributed algorithms for online monitoring\nof the grid that are inherently less prone to malicious attacks. In this work,\na novel distributed non-iterative voltage stability index (VSI) is proposed by\nrecasting the power flow equations as circles. The online computations of VSI\nare simultaneously performed by the processors embedded at each bus in the\nsmart grid with the help of PMUs and communication of voltage phasors between\nneighboring buses. The distributed nature of the index enables the real-time\nidentification of the critical bus of the system with minimal communication\ninfrastructure. The effectiveness of the proposed distributed index is\ndemonstrated on IEEE test systems and contrasted with existing methods to show\nthe benefits of the proposed method in speed, interpretability, identification\nof outage location, and low sensitivity to noisy measurements. \n\n"}
{"id": "1901.03657", "contents": "Title: Shift-Symmetric Orbital Inflation: single field or multi-field? Abstract: We present a new class of two-field inflationary attractor models, known as\n`shift-symmetric orbital inflation', whose behaviour is strongly multi-field\nbut whose predictions are remarkably close to those of single-field inflation.\nIn these models, the field space metric and potential are such that the\ninflaton trajectory is along an `angular' isometry direction whose `radius' is\nconstant but arbitrary. As a result, the radial (isocurvature) perturbations\naway from the trajectory are exactly massless and they freeze on superhorizon\nscales. These models are the first exact realization of the `ultra-light\nisocurvature' scenario, previously described in the literature, where a\ncombined shift symmetry emerges between the curvature and isocurvature\nperturbations and results in primordial perturbation spectra that are entirely\nconsistent with current observations. Due to the turning trajectory, the radial\nperturbation sources the tangential (curvature) perturbation and makes it grow\nlinearly in time. As a result, only one degree of freedom (i.e. the one from\nisocurvature modes) is responsible for the primordial observables at the end of\ninflation, which yields the same phenomenology as in single-field inflation. In\nparticular, isocurvature perturbations and local non-Gaussianity are highly\nsuppressed here, even if the inflationary dynamics is truly multi-field. We\ncomment on the generalization to models with more than two fields. \n\n"}
{"id": "1901.06995", "contents": "Title: Distributed Nesterov gradient methods over arbitrary graphs Abstract: In this letter, we introduce a distributed Nesterov method, termed as\n$\\mathcal{ABN}$, that does not require doubly-stochastic weight matrices.\nInstead, the implementation is based on a simultaneous application of both row-\nand column-stochastic weights that makes this method applicable to arbitrary\n(strongly-connected) graphs. Since constructing column-stochastic weights needs\nadditional information (the number of outgoing neighbors at each agent), not\navailable in certain communication protocols, we derive a variation, termed as\nFROZEN, that only requires row-stochastic weights but at the expense of\nadditional iterations for eigenvector learning. We numerically study these\nalgorithms for various objective functions and network parameters and show that\nthe proposed distributed Nesterov methods achieve acceleration compared to the\ncurrent state-of-the-art methods for distributed optimization. \n\n"}
{"id": "1901.07043", "contents": "Title: Possible pressure-induced topological quantum phase transition in the\n  nodal line semimetal ZrSiS Abstract: ZrSiS has recently gained attention due to its unusual electronic properties:\nnearly perfect electron-hole compensation, large, anisotropic\nmagneto-resistance, multiple Dirac nodes near the Fermi level, and an extremely\nlarge range of linear dispersion of up to 2 eV. We have carried out a series of\nhigh pressure electrical resistivity measurements on single crystals of ZrSiS.\nShubnikov-de Haas measurements show two distinct oscillation frequencies. For\nthe smaller orbit, we observe a change in the phase of 0.5, which occurs\nbetween 0.16 - 0.5 GPa. This change in phase is accompanied by an abrupt\ndecrease of the cross-sectional area of this Fermi surface. We attribute this\nchange in phase to a possible topological quantum phase transition. The phase\nof the larger orbit exhibits a Berry phase of pi and remains roughly constant\nup to 2.3 GPa. Resistivity measurements to higher pressures show no evidence\nfor pressure-induced superconductivity to at least 20 GPa. \n\n"}
{"id": "1901.07302", "contents": "Title: IOTA-based Directed Acyclic Graphs without Orphans Abstract: Directed Acylic Graphs (DAGs) are emerging as an attractive alternative to\ntraditional blockchain architectures for distributed ledger technology (DLT).\nIn particular DAG ledgers with stochastic attachment mechanisms potentially\noffer many advantages over blockchain, including scalability and faster\ntransaction speeds. However, the random nature of the attachment mechanism\ncoupled with the requirement of protection against double-spend transactions\nleaves open the possibility that not all transactions will be eventually\nvalidated. Such transactions are said to be orphaned, and will never be\nvalidated. Our principal contribution is to propose a simple modification to\nthe attachment mechanism for the Tangle (the IOTA DAG architecture). This\nmodification ensures that all transactions are validated in finite time, and\npreserves essential features of the popular Monte-Carlo selection algorithm. In\norder to demonstrate these results we derive a fluid approximation for the\nTangle (in the limit of infinite arrival rate) and prove that this fluid model\nexhibits the desired behavior. We also present simulations which validate the\nresults for finite arrival rates. \n\n"}
{"id": "1901.07768", "contents": "Title: Cooperation Speeds Surfing: Use Co-Bandit! Abstract: In this paper, we explore the benefit of cooperation in adversarial bandit\nsettings. As a motivating example, we consider the problem of wireless network\nselection. Mobile devices are often required to choose the right network to\nassociate with for optimal performance, which is non-trivial. The excellent\ntheoretical properties of EXP3, a leading multi-armed bandit algorithm, suggest\nthat it should work well for this type of problem. Yet, it performs poorly in\npractice. A major limitation is its slow rate of stabilization. Bandit-style\nalgorithms perform better when global knowledge is available, i.e., when\ndevices receive feedback about all networks after each selection. But,\nunfortunately, communicating full information to all devices is expensive.\nTherefore, we address the question of how much information is adequate to\nachieve better performance. We propose Co-Bandit, a novel cooperative bandit\napproach, that allows devices to occasionally share their observations and\nforward feedback received from neighbors; hence, feedback may be received with\na delay. Devices perform network selection based on their own observation and\nfeedback from neighbors. As such, they speed up each other's rate of learning.\nWe prove that Co-Bandit is regret-minimizing and retains the convergence\nproperty of multiplicative weight update algorithms with full information.\nThrough simulation, we show that a very small amount of information, even with\na delay, is adequate to nudge each other to select the right network and yield\nsignificantly faster stabilization at the optimal state (about 630x faster than\nEXP3). \n\n"}
{"id": "1901.08166", "contents": "Title: Fundamental Limits of Approximate Gradient Coding Abstract: It has been established that when the gradient coding problem is distributed\namong $n$ servers, the computation load (number of stored data partitions) of\neach worker is at least $s+1$ in order to resists $s$ stragglers. This scheme\nincurs a large overhead when the number of stragglers $s$ is large. In this\npaper, we focus on a new framework called \\emph{approximate gradient coding} to\nmitigate stragglers in distributed learning. We show that, to exactly recover\nthe gradient with high probability, the computation load is lower bounded by\n$O(\\log(n)/\\log(n/s))$. We also propose a code that exactly matches such lower\nbound. We identify a fundamental three-fold tradeoff for any approximate\ngradient coding scheme $d\\geq O(\\log(1/\\epsilon)/\\log(n/s))$, where $d$ is the\ncomputation load, $\\epsilon$ is the error of gradient. We give an explicit code\nconstruction based on random edge removal process that achieves the derived\ntradeoff. We implement our schemes and demonstrate the advantage of the\napproaches over the current fastest gradient coding strategies. \n\n"}
{"id": "1901.08215", "contents": "Title: Fully Asynchronous Distributed Optimization with Linear Convergence in\n  Directed Networks Abstract: We consider the distributed optimization problem, the goal of which is to\nminimize the sum of local objective functions over a directed network. Though\nit has been widely studied recently, most of the existing algorithms are\ndesigned for synchronized or randomly activated implementation, which may\ncreate deadlocks in practice. In sharp contrast, we propose a \\emph{fully}\nasynchronous push-pull gradient algorithm (APPG) where each node updates\nwithout waiting for any other node by using (possibly stale) information from\nneighbors. Thus, it is both deadlock-free and robust to any bounded\ncommunication delay. Moreover, we construct two novel augmented networks to\ntheoretically evaluate its performance from the worst-case point of view and\nshow that if local functions have Lipschitz-continuous gradients and their sum\nsatisfies the Polyak-\\L ojasiewicz condition (convexity is not required), each\nnode of APPG converges to the same optimal solution at a linear rate of\n$\\mathcal{O}(\\lambda^k)$, where $\\lambda\\in(0,1)$ and the virtual counter $k$\nincreases by one no matter which node updates. This largely elucidates its\nlinear speedup efficiency and shows its advantage over the synchronous version.\nFinally, the performance of APPG is numerically validated via a logistic\nregression problem on the \\emph{Covertype} dataset. \n\n"}
{"id": "1901.08326", "contents": "Title: A stack-vector routing protocol for automatic tunneling Abstract: In a network, a tunnel is a part of a path where a protocol is encapsulated\nin another one. A tunnel starts with an encapsulation and ends with the\ncorresponding decapsulation. Several tunnels can be nested at some stage,\nforming a protocol stack. Tunneling is very important nowadays and it is\ninvolved in several tasks: IPv4/IPv6 transition, VPNs, security (IPsec, onion\nrouting), etc. However, tunnel establishment is mainly performed manually or by\nscript, which present obvious scalability issues. Some works attempt to\nautomate a part of the process (e.g., TSP, ISATAP, etc.). However, the\ndetermination of the tunnel(s) endpoints is not fully automated, especially in\nthe case of an arbitrary number of nested tunnels. The lack of routing\nprotocols performing automatic tunneling is due to the unavailability of path\ncomputation algorithms taking into account encapsulations and decapsulations.\nThere is a polynomial centralized algorithm to perform the task. However, to\nthe best of our knowledge, no fully distributed path computation algorithm is\nknown. Here, we propose the first fully distributed algorithm for path\ncomputation with automatic tunneling, i.e., taking into account encapsulation,\ndecapsulation and conversion of protocols. Our algorithm is a generalization of\nthe distributed Bellman-Ford algorithm, where the distance vector is replaced\nby a protocol stack vector. This allows to know how to route a packet with some\nprotocol stack. We prove that the messages size of our algorithm is polynomial,\neven if the shortest path can be of exponential length. We also prove that the\nalgorithm converges after a polynomial number of steps in a synchronized\nsetting. We adapt our algorithm into a proto-protocol for routing with\nautomatic tunneling and we show its efficiency through simulations. \n\n"}
{"id": "1901.08834", "contents": "Title: Uniform existence of the IDS on lattices and groups Abstract: We present a general framework for thermodynamic limits and its applications\nto a variety of models. In particular we will identify criteria such that the\nlimits are uniform in a parameter. All results are illustrated with the example\nof eigenvalue counting functions converging to the integrated density of\nstates. In this case, the convergence is uniform in the energy. \n\n"}
{"id": "1901.08919", "contents": "Title: Wireless Broadcast with short labelling Abstract: In this paper, we study the broadcast problem in wireless networks when the\nbroadcast is helped by a labelling scheme. We focus on two variants of\nbroadcast: broadcast without acknowledgment (i.e. the initiator of the\nbroadcast is not notified at the end of broadcast) and broadcast with\nacknowledgment. Our contribution is threefold. First, we improve in terms of\nmemory complexity a recent labelling-based broadcast scheme with acknowledgment\ndesigned for arbitrary networks.Second, we propose label optimal broadcast\nalgorithms in Level Separable Networks (a class of networks issued from recent\nstudies in Wireless Body Area Networks). In this class of networks we propose\nan acknowledgment-free broadcast strategy using 1-bit labels and broadcast with\nacknowledgment using 2-bits labels. In the class of level-separable networks,\nour algorithms finish within 2D rounds, where D is the eccentricity of the\nbroadcast initiator. Interestingly, the time complexity of broadcast in the\ncase of level-separable networks does not depend on the size of the network but\nrather on the initiator eccentricity which makes this class of graphs\ninteresting for further investigation. Finally, we study the hardness of\ndetermining that a graph is level separable. Our study shows that even though\nchecking that a separation is a level separation can be done in polynomial\ntime, determining that a graph has the level separable property is NP-complete.\nThis result opens interesting independent research directions. \n\n"}
{"id": "1901.09865", "contents": "Title: Asynchronous Accelerated Proximal Stochastic Gradient for Strongly\n  Convex Distributed Finite Sums Abstract: In this work, we study the problem of minimizing the sum of strongly convex\nfunctions split over a network of $n$ nodes. We propose the decentralized and\nasynchronous algorithm ADFS to tackle the case when local functions are\nthemselves finite sums with $m$ components. ADFS converges linearly when local\nfunctions are smooth, and matches the rates of the best known finite sum\nalgorithms when executed on a single machine. On several machines, ADFS enjoys\na $O (\\sqrt{n})$ or $O(n)$ speed-up depending on the leading complexity term as\nlong as the diameter of the network is not too big with respect to $m$. This\nalso leads to a $\\sqrt{m}$ speed-up over state-of-the-art distributed batch\nmethods, which is the expected speed-up for finite sum algorithms. In terms of\ncommunication times and network parameters, ADFS scales as well as optimal\ndistributed batch algorithms. As a side contribution, we give a generalized\nversion of the accelerated proximal coordinate gradient algorithm using\narbitrary sampling that we apply to a well-chosen dual problem to derive ADFS.\nYet, ADFS uses primal proximal updates that only require solving\none-dimensional problems for many standard machine learning applications.\nFinally, ADFS can be formulated for non-smooth objectives with equally good\nscaling properties. We illustrate the improvement of ADFS over state-of-the-art\napproaches with simulations. \n\n"}
{"id": "1901.09942", "contents": "Title: On transaction parallelizability in Ethereum Abstract: Ethereum clients execute transactions in a sequential order prescribed by the\nconsensus protocol. This is a safe and conservative approach to blockchain\ntransaction processing which forgoes running transactions in parallel even when\ndoing so would be beneficial and safe, e.g., when there is no intersection in\nthe sets of accounts that the transactions read or modify. In this work we\nstudy the degree of transaction parallelizability and present results from\nthree different simulations using real Ethereum transaction data. Our\nsimulations demonstrate that notable gains are achievable with parallelization,\nand suggest that the potential for parallelizability improves as transaction\nrates increase. \n\n"}
{"id": "1901.10008", "contents": "Title: The OoO VLIW JIT Compiler for GPU Inference Abstract: Current trends in Machine Learning~(ML) inference on hardware accelerated\ndevices (e.g., GPUs, TPUs) point to alarmingly low utilization. As ML inference\nis increasingly time-bounded by tight latency SLOs, increasing data parallelism\nis not an option. The need for better efficiency motivates GPU multiplexing.\nFurthermore, existing GPU programming abstractions force programmers to\nmicro-manage GPU resources in an early-binding, context-free fashion. We\npropose a VLIW-inspired Out-of-Order (OoO) Just-in-Time (JIT) compiler that\ncoalesces and reorders execution kernels at runtime for throughput-optimal\ndevice utilization while satisfying latency SLOs. We quantify the\ninefficiencies of space-only and time-only multiplexing alternatives and\ndemonstrate an achievable 7.7x opportunity gap through spatial coalescing. \n\n"}
{"id": "astro-ph/0001239", "contents": "Title: Modeling the X-ray - UV Correlations in NGC 7469 Abstract: We model the correlated X-ray - UV observations of NGC 7469, for which well\nsampled data in both these bands have been obtained recently in a\nmultiwavelength monitoring campaign. To this end we derive the transfer\nfunction in wavelength \\ls and time lag \\t, for reprocessing hard (X-ray)\nphotons from a point source to softer ones (UV-optical) by an infinite plane\n(representing a cool, thin accretion disk) located at a given distance below\nthe X-ray source, under the assumption that the X-ray flux is absorbed and\nemitted locally by the disk as a black body of temperature appropriate to the\nincident flux. Using the observed X-ray light curve as input we have computed\nthe expected continuum UV emission as a function of time at several wavelengths\n(\\l \\l 1315 \\AA, \\l \\l 6962 \\AA, \\l \\l 15000 \\AA, \\l \\l 30000 \\AA) assuming\nthat the X-ray source is located one \\sc radius above the disk plane, with the\nmass of the black hole $M$ and the latitude angle $\\theta$ of the observer\nrelative to the disk plane as free parameters. We have searched the parameter\nspace of black hole masses and observer azimuthal angles but we were unable to\nreproduce UV light curves which would resemble, even remotely, those observed.\nWe also explored whether particular combinations of the values of these\nparameters could lead to light curves whose statistical properties (i.e. the\nautocorrelation and cross correlation functions) would match those\ncorresponding to the observed UV light curve at \\l \\l 1315 \\AA. Even though we\nconsidered black hole masses as large as $10^9$ M$_{\\odot}$ no such match was\npossible. Our results indicate that some of the fundamental assumptions of this\nmodel will have to be modified to obtain even approximate agreement between the\nobserved and model X-ray - UV light curves. \n\n"}
{"id": "astro-ph/0001443", "contents": "Title: Scale Dependent Dimension of Luminous Matter in the Universe Abstract: We present a geometrical model of the distribution of luminous matter in the\nuniverse, derived from a very simple reaction-diffusion model of turbulent\nphenomena. The apparent dimension of luminous matter, $D(l)$, depends linearly\non the logarithm of the scale $l$ under which the universe is viewed: $D(l)\n\\sim 3\\log(l/l_0)/\\log(\\xi/l_0)$, where $\\xi$ is a correlation length.\nComparison with data from the SARS red-shift catalogue, and the LEDA database\nprovides a good fit with a correlation length $\\xi \\sim 300$ Mpc. The\ngeometrical interpretation is clear: At small distances, the universe is\nzero-dimensional and point-like. At distances of the order of 1 Mpc the\ndimension is unity, indicating a filamentary, string-like structure; when\nviewed at larger scales it gradually becomes 2-dimensional wall-like, and\nfinally, at and beyond the correlation length, it becomes uniform. \n\n"}
{"id": "astro-ph/0004234", "contents": "Title: Black Hole Emergence in Supernovae Abstract: If a black hole formed in a core-collapse supernova is accreting material\nfrom the base of the envelope, the accretion luminosity could be observable in\nthe supernova light curve. Here we continue the study of matter fall back onto\na black hole in the wake of a supernova and examine realistic supernovae models\nwhich allow for an early emergence of the accretion luminosity. Such cases may\nprovide a direct observational identification of the black hole formed in the\naftermath of the explosion. Our approach combines analytic estimates and fully\nrelativistic, radiation-hydrodynamic numerical computations. We employ a\nnumerical hydrodynamical scaling technique to accommodate the diverse range of\ndynamical time scales in a single simulation. We find that while in typical\nType II supernovae heating by radioactive decays dominates the late-time light\ncurve, low-energy explosions of more massive stars should provide an important\nexception where the accretion luminosity will emerge while it is still\nrelatively large. Our main focus is on the only current candidate for such an\nobservation, the very unusual SN1997D. Due to the low energy of the explosion\nand the very small ($2\\times10^{-3} M_\\sun$) inferred mass of Co56 in the\nejected envelope, we find that accretion should become the dominant source of\nits luminosity during the year 2000. The total luminosity at emergence is\nexpected to lie in the range $0.5-3\\times10^{36} $ ergs/s, potentially\ndetectable with HST. We also discuss the more favorable case of explosions\nwhich eject negligible amounts of radioactive isotopes and find that the black\nhole is likely to emerge a few tens of days after the explosion, with a\nluminosity of $\\sim 10^{37} $\\ergss. \n\n"}
{"id": "astro-ph/0004289", "contents": "Title: The Influence of Galactic Outflows on the Formation of Nearby Dwarf\n  Galaxies Abstract: We show that the gas in growing density perturbations is vulnerable to the\ninfluence of winds outflowing from nearby collapsed galaxies that have already\nformed stars. This suggests that the formation of nearby galaxies with masses\nless than 10^9 solar masses is likely to be suppressed, irrespective of the\ndetails of galaxy formation. An impinging wind may shock heat the gas of a\nnearby perturbation to above the virial temperature, thereby mechanically\nevaporating the gas, or the baryons may be stripped from the perturbation\nentirely if they are accelerated to above the escape velocity. We show that\nbaryonic stripping is the most effective of these two processes, because\nshock-heated clouds that are too large to be stripped are able to radiatively\ncool within a sound-crossing time, limiting evaporation. The intergalactic\nmedium temperatures and star-formation rates required for outflows to have a\nsignificant influence on the formation of low-mass galaxies are consistent with\ncurrent observations, but may soon be examined directly via associated\ndistortions in the cosmic microwave background, and with near-infrared\nobservations from the Next Generation Space Telescope, which may detect the\nsupernovae from early-forming stars. \n\n"}
{"id": "astro-ph/0006021", "contents": "Title: What if pulsars are born as strange stars? Abstract: The possibility and the implications of the idea, that pulsars are born as\nstrange stars, are explored. Strange stars are very likely to have atmospheres\nwith typical mass of $\\sim 5\\times 10^{-15}M_\\odot$ but bare polar caps almost\nthroughout their lifetimes, if they are produced during supernova explosions. A\ndirect consequence of the bare polar cap is that the binding energies of both\npositively and negatively charged particles at the bare quark surface are\nnearly infinity, so that the vacuum polar gap sparking scenario as proposed by\nRuderman & Sutherland should operate above the cap, regardless of the sense of\nthe magnetic pole with respect to the rotational pole. Heat can not accumulate\non the polar cap region due to the large thermal conductivity on the bare quark\nsurface. We test this ``bare polar cap strange star'' (BPCSS) idea with the\npresent broad band emission data of pulsars, and propose several possible\ncriteria to distinguish BPCSSs from neutron stars. \n\n"}
{"id": "astro-ph/0006397", "contents": "Title: Mass-to-Light Ratios of Groups and Clusters of Galaxies Abstract: We constrain the mass-to-light ratios, gas mass fractions, baryon mass\nfractions and the ratios of total to luminous mass for a sample of eight nearby\nrelaxed galaxy groups and clusters: A262, A426, A478, A1795, A2052, A2063,\nA2199 and MKW4s. We use ASCA spatially resolved spectroscopic X-ray\nobservations and ROSAT PSPC images to constrain the total and gas masses of\nthese clusters. To measure cluster luminosities we use galaxy catalogs\nresulting from the digitization and automated processing of the second\ngeneration Palomar Sky Survey plates calibrated with CCD images in the\nGunn-Thuan g, r, and i bands.\n  Under the assumption of hydrostatic equilibrium and spherical symmetry, we\ncan measure the total masses of clusters from their intra-cluster gas\ntemperature and density profiles. Spatially resolved ASCA spectra show that the\ngas temperature decreases with increasing distance from the center. By\ncomparison, the assumption that the gas is isothermal results in an\nunderestimate of the total mass at small radii, and an overestimate at large\ncluster radii.\n  We have obtained luminosity functions for all clusters in our sample. After\ncorrecting for background and foreground galaxies, we estimate the total\ncluster luminosity using Schechter function fits to the galaxy catalogs. In the\nthree lowest redshift clusters where we can sample to fainter absolute\nmagnitudes, we have detected a flattening of the luminosity function at\nintermediate magnitudes and a rise at the faint end. These clusters were fit\nwith a sum of two Schechter functions. The remaining clusters were well fit\nwith a single Schechter function. \n\n"}
{"id": "astro-ph/0011126", "contents": "Title: Star Formation History in the Solar Vicinity Abstract: The star formation history in the solar neighbourhood is inferred comparing a\nsample of field stars from the Hipparcos Catalog with synthetic CMDs. We\nconsidered separately the main sequence and the red giant region of the HR\ndiagram. The criteria for our best solutions are based on the $\\chi^{2}$\nminimization of star distributions in selected zones of the HR diagram. Our\nanalysis suggests that: a) the solutions are compatible with a Salpeter IMF and\nwith {\\sl a star formation rate increasing, in a broad sense, from the\nbeginning to the present time}; b) the deduced volume mass densities and the\ncorresponding absolute scale of the SFR solutions are strongly influenced by\nthe initial mass function slope of low mass stars (below 0.5 Mo); c) the\nstellar evolutionary models are not completely adequate: in fact {\\sl the\ntheoretical ratio between the He-burning and MS star numbers is always a factor\n1.5 greater than the observational value}. This fact could indicate the need of\na more efficient overshoot in the evolutionary models, or a different mixing\ntheory. \n\n"}
{"id": "astro-ph/0011506", "contents": "Title: MACHO Project Limits on Black Hole Dark Matter in the 1-30 Solar Mass\n  Range Abstract: We report on a search for long duration microlensing events towards the Large\nMagellanic Cloud. We find none, and therefore put limits on the contribution of\nhigh mass objects to the Galactic dark matter. At 95% confidence level we\nexclude objects in the mass range 0.3 solar masses to 30.0 solar masses from\ncontributing more than 4 times 10^11 solar masses to the Galactic halo.\nCombined with earlier results, this means that objects with masses under 30\nsolar masses cannot make up the entire dark matter halo if the halo is of\ntypical size. For a typical dark halo, objects with masses under 10 solar\nmasses contribute less than 40% of the dark matter. \n\n"}
{"id": "astro-ph/0012436", "contents": "Title: Galactic dynamos with captured magnetic flux and an accretion flow Abstract: We examine the behaviour of an axisymmetric galactic dynamo model with a\nradial accretion flow in the disc. We also introduce a vertical magnetic flux\nthrough the galactic midplane, to simulate the presence of a large scale\nmagnetic field trapped by the galaxy when forming. The trapped vertical flux is\nconserved and advected towards the disc centre by the radial flow. We confirm\nthat accretion flows of magnitude several km/s through a significant part of\nthe galactic disc can markedly inhibit dynamo action. Moreover, advection of\nthe vertical flux in general results in mixed parity galactic fields. However,\nthe effect is nonlinear and non-additive -- global magnetic field energies are\nusually significantly smaller that the sum of purely dynamo generated and\npurely advected field energies. For large inflow speeds, a form of\n`semi-dynamo' action may occur.\n  We apply our results to the accumulation and redistribution, by a radial\ninflow, of a vertical magnetic flux captured by the Galactic disc. Taking\nrepresentative values, it appears difficult to obtain mean vertical fields near\nthe centre of the Milky Way that are much in excess of 10 microgauss, largely\nbecause the galactic dynamo and turbulent magnetic diffusion modify the\nexternal magnetic field before it can reach the disc centre. \n\n"}
{"id": "astro-ph/0012495", "contents": "Title: Present Status of Diffusive Shock Acceleration Abstract: Diffusive shock acceleration (DSA) is now widely accepted as the model to\nexplain the production of cosmic rays (CRs) in a wide range of astrophysical\nenvironments. Despite initial successes of the theory in explaining the\nenergetics and the spectrum of CRs accelerated by supernova remnants, there\nstill remain some unresolved issues such as particle injection out of the\nthermal plasma at shocks, CR diffusion due to the self-generated MHD waves and\nyet-to-be-detected gamma-ray emission due to the ionic CRs. Recent technical\nadvancements to resolve these issues are reviewed. \n\n"}
{"id": "astro-ph/0101029", "contents": "Title: Galactic Chemical Abundances at z>3 I: First Results from the Echellette\n  Spectrograph and Imager Abstract: We present the first results from an ongoing survey to discover and measure\nthe metallicity of z>3 damped Lya systems with the Echellette Spectrograph and\nImager (ESI) on the Keck II telescope. Our motivation arises from a recent\nstudy on the damped Lya systems suggesting only mild evolution in the cosmic\nmetallicity from z~2 to 4. The Echellette Spectrograph and Imager, which\nprovides two complementary spectroscopic modes, is the ideal instrument for a\nz>3 damped Lya survey. We describe our observing strategy and report on the\ndiscovery and analysis of 5 new z>3 damped Lya systems acquired in a single\nnight of observing. These observations further support the principal\nconclusions of the previous study: (1) the cosmic metallicity in neutral gas\ninferred from the damped Lya systems does not evolve significantly from z~2 to\n4; (2) the unweighted metallicity exhibits a statistically significant decrease\nwith increasing redshift; and (3) not a single damped Lya system has a\nmetallicity below [Fe/H]=-3. We discuss the implications of these results and\ncomment on recent theoretical studies which attempt to explain the\nobservations. \n\n"}
{"id": "astro-ph/0104427", "contents": "Title: Near-infrared template spectra of normal galaxies: k-corrections, galaxy\n  models and stellar populations Abstract: We have observed 28 local galaxies in the wavelength range between 1 and 2.4\nmic in order to define template spectra of the normal galaxies along the Hubble\nsequence. Five galaxies per morphological type were observed in most cases, and\nthe resulting RMS spread of the normalized spectra of each class, including\nboth intrinsic differences and observational uncertainties, is about 1% in K,\n2% in H and 3% in J. Many absorption features can be accurately measured. The\ntarget galaxies and the spectroscopic aperture (7\"x53\") were chosen to be\nsimilar to those used by Kinney et al. (1996) to define template UV and optical\nspectra. The two data sets are matched in order to build representative spectra\nbetween 0.1 and 2.4 mic. The continuum shape of the optical spectra and the\nrelative normalization of the near-IR ones were set to fit the average\neffective colours of the galaxies of the various Hubble classes. The resulting\nspectra are used to compute the k-corrections of the normal galaxies in the\nnear-IR bands and to check the predictions of various spectral synthesis\nmodels: while the shape of the continuum is generally well predicted, large\ndiscrepancies are found in the absorption lines. Among the other possible\napplications, here we also show how these spectra can be used to place\nconstraints on the dominant stellar population in local galaxies. Spectra and\nk-corrections are publicly available and can be downloaded from the web site\nhttp://www.arcetri.astro.it/~filippo/spectra. \n\n"}
{"id": "astro-ph/0110650", "contents": "Title: Cosmic Background dipole measurements with Planck-High Frequency\n  Instrument Abstract: This paper discusses the Cosmic Background (CB) dipoles observations in the\nframework of the Planck mission. Dipoles observations can be used in three\nways: (i) It gives a measurement of the peculiar velocity of our Galaxy which\nis an important observation in large scale structures formation model. (ii)\nMeasuring the dipole can give unprecedent information on the monopole (that can\nbe in some cases hard to obtain due to large foreground contaminations). (iii)\nThe dipole can be an ideal absolute calibrator, easily detectable in\ncosmological experiments. Following the last two objectives, the main goal of\nthe work presented here is twofold. First, we study the accuracy of the\nPlanck-HFI calibration using the Cosmic Microwave Background (CMB) dipole\nmeasured by COBE as well as the Earth orbital motion dipole. We show that we\ncan reach for HFI, a relative calibration between rings of about 1% and an\nabsolute calibration better than 0.4% for the CMB channels (in the end, the\nabsolute calibration will be limited by the uncertainties on the CMB\ntemperature). We also show that Planck will be able to measure the CMB dipole\ndirection at better than 1.7 arcmin and improve on the amplitude. Second, we\ninvestigate the detection of the Cosmic Far-Infrared Background (FIRB) dipole.\nMeasuring this dipole could give a new and independent determination of the\nFIRB for which a direct determination is quite difficult due to Galactic dust\nemission contamination. We show that such a detection would require a Galactic\ndust emission removal at better than 1%, which will be very hard to achieve. \n\n"}
{"id": "astro-ph/0111378", "contents": "Title: A comment on the colour-colour diagrams of Low Mass X-ray Binaries Abstract: Disc accreting neutron stars come in two distinct varieties, atolls and Z\nsources, named after their differently shaped tracks on a colour-colour diagram\nas the source luminosity changes. Here we present analysis of three transient\natoll sources showing that there is an additional branch in the colour-colour\ndiagram of atoll sources which appears at very low luminosities. This new\nbranch connects to the top of previously known C-shaped (atoll) path, forming a\nhorizontal track where the average source flux decrease from right to left.\nThis turns the C-shape into a Z. Thus both atolls and Z sources share the same\ntopology on the colour-colour diagram, and evolve in similar way as a function\nof increasing averaged mass accretion rate. This strongly favours models in\nwhich the underlying geometry of these sources changes in similar ways. A\npossible scenario is one where the truncated disc approaches the neutron star\nwhen the accretion rate increases, but that in the atolls the disc is truncated\nby evaporation (similarly to black holes) whereas in the Z sources it is\ntruncated by the magnetic field. \n\n"}
{"id": "astro-ph/0202132", "contents": "Title: The 60-micron extragalactic background radiation intensity,\n  dust-enshrouded AGNs and the assembly of groups and clusters of galaxies Abstract: Submillimetre observations reveal a cosmologically significant population of\nhigh-redshift dust-enshrouded galaxies. The form of evolution inferred for this\npopulation can be reconciled easily with COBE FIRAS and DIRBE measurements of\nthe cosmic background radiation (CBR) at wavelengths >100 microns. At shorter\nwavelengths, however, the 60-micron CBR intensity reported by Finkbeiner et al.\nis less easily accounted for. Lagache et al. have proposed that this excess CBR\nemission is a warm Galactic component, and the detection of the highest-energy\ngamma-rays from blazars limits the CBR intensity at these wavelengths, but here\nwe investigate sources of this excess CBR emission, assuming that it has a\ngenuine extragalactic origin. We propose and test three explanations, each\ninvolving additional populations not readily detected in existing submm-wave\nsurveys. First, dust-enshrouded galaxies with hot dust temperatures, perhaps\ndust-enshrouded, Compton-thick AGN as suggested by recent deep Chandra surveys.\nSecondly, a population of relatively low-redshift dusty galaxies with SEDs more\ntypical of the existing submm-selected galaxies, which could plausibly be\nassociated with the assembly of groups and clusters of galaxies. Thirdly, a\npopulation of low-luminosity, cool, quiescent spiral galaxies. Hot AGN and the\nassembly of groups can account for the excess 60-micron background. There are\nsignificant problems with the cluster assembly scenario, in which too many\nbright IRAS sources are predicted. Spiral galaxies have the wrong SEDs to\naccount for the excess. Future wide-field far-IR surveys using SIRTF and\nHerschel will sample representative volumes of the distant Universe, allowing\nany hot population of dusty AGNs and forming groups to be detected. \n\n"}
{"id": "astro-ph/0204367", "contents": "Title: Interstellar Scintillation of PSR J0437-4715 on Two Scales Abstract: We sought to determine the scale of scintillation in the interstellar plasma\nof PSR J0437-4715. We used the Very Long Baseline Array to obtain scintillation\namplitude and phase data, from dynamic spectra at 327 MHz. We observe two\nscales of scintillation of pulsar PSR J0437-4715, differing by more than an\norder of magnitude in scintillation bandwidth. The wider-bandwidth scale of\nscintillation that we observe indicates less scattering for this pulsar than\nfor other nearby pulsars, except for PSR B0950+08. \n\n"}
{"id": "astro-ph/0205334", "contents": "Title: Period-doubling events in the light curve of R Cygni: evidence for\n  chaotic behaviour Abstract: A detailed analysis of the century long visual light curve of the long-period\nMira star R Cygni is presented and discussed. The data were collected from the\npublicly available databases of the AFOEV, the BAAVSS and the VSOLJ. The full\nlight curve consists of 26655 individual points obtained between 1901 and 2001.\nThe light curve and its periodicity were analysed with help of the O-C diagram,\nFourier analysis and time-frequency analysis. The results demonstrate the\nlimitations of these linear methods. The next step was to investigate the\npossible presence of low-dimensional chaos in the light curve. For this, a\nsmoothed and noise-filtered signal was created from the averaged data and with\nhelp of time delay embedding, we have tried to reconstruct the attractor of the\nsystem. The main result is that R Cygni shows such period-doubling events that\ncan be interpreted as caused by a repetitive bifurcation of the chaotic\nattractor between a period 2T orbit and chaos. The switch between these two\nstates occurs in a certain compact region of the phase space, where the light\ncurve is characterized by ~1500-days long transients. The Lyapunov spectrum was\ncomputed for various embedding parameters confirming the chaotic attractor,\nalthough the exponents suffer from quite high uncertainty because of the\napplied approximation. Finally, the light curve is compared with a simple one\nzone model generated by a third-order differential equation which exhibits\nwell-expressed period-doubling bifurcation. The strong resemblance is another\nargument for chaotic behaviour. Further studies should address the problem of\nglobal flow reconstruction, including the determination of the accurate\nLyapunov exponents and dimension. \n\n"}
{"id": "astro-ph/0208326", "contents": "Title: Expected Performance of CryoArray Abstract: WIMP-nucleon cross sections below 10^(-9) pb may be probed by ton-scale\nexperiments with low thresholds and background rates ~20 events per year. An\narray of cryogenic detectors (\"CryoArray\") could perform well enough to reach\nthis goal. Sufficient discrimination and background suppression of photons has\nalready been demonstrated. Reduction of neutron backgrounds may be achieved by\nsiting the experiment deep enough. Removal of the surface-electron backgrounds\nalone has not yet been demonstrated, but the reductions required even for this\ntroublesome background are quite modest and appear achieveable. \n\n"}
{"id": "astro-ph/0209236", "contents": "Title: Magnetic Flares on Asymptotic Giant Branch Stars Abstract: We investigate the consequences of magnetic flares on the surface of\nasymptotic giant branch (AGB) and similar stars. In contrast to the solar wind,\nin the winds of AGB stars the gas cooling time is much shorter than the outflow\ntime. As a result, we predict that energetic flaring will not inhibit, and may\neven enhance, dust formation around AGB stars. If magnetic flares do occur\naround such stars, we expect some AGB stars to exhibit X-ray emission; indeed\ncertain systems including AGB stars, such as Mira, have been detected in\nX-rays. However, in these cases, it is difficult to distinguish between\npotential AGB star X-ray emission and, e.g., X-ray emission from the vicinity\nof a binary companion. Analysis of an archival ROSAT X-ray spectrum of the Mira\nsystem suggests an intrinsic X-ray luminosity 2x10^{29} erg/sec and temperature\n10^7 K. These modeling results suggest that magnetic activity, either on the\nAGB star (Mira A) or on its nearby companion (Mira B), is the source of the\nX-rays, but do not rule out the possibility that the X-rays are generated by an\naccretion disk around Mira B. \n\n"}
{"id": "astro-ph/0209436", "contents": "Title: Nonthermal Particles and Radiation Produced by Cluster Merger Shocks Abstract: We have developed a numerical model for the temporal evolution of particle\nand photon spectra resulting from nonthermal processes at the shock fronts\nformed in merging clusters of galaxies. Fermi acceleration is approximated by\ninjecting power-law distributions of particles during a merger event, subject\nto constraints on maximum particle energies. We consider synchrotron,\nbremsstrahlung, Compton, and Coulomb processes for the electrons, nuclear,\nphotomeson, and Coulomb processes for the protons, and knock-on electron\nproduction during the merging process. The broadband radio through gamma-ray\nemission radiated by nonthermal protons and primary and secondary electrons is\ncalculated both during and after the merger event. Using ROSAT observations to\nestablish typical parameters for the matter density profile of clusters of\ngalaxies, we find that typical merger shocks are weak and accelerate particles\nwith relatively soft spectra. We consider the prospects for detecting\nnonthermal radio and gamma-ray emission from clusters of galaxies and\nimplications for the origin of ultra-high energy cosmic rays and the diffuse\ngamma-ray background. Our results suggest that only a few of the\nisotropically-distributed unidentified EGRET sources are due to shocks formed\nin cluster mergers, and that only a minor contribution to the diffuse\nextragalactic gamma-ray background can originate from cluster merger shocks.\nCluster merger shocks can accelerate protons to $\\lesssim 10^{19}$ eV for the\nstandard parameters considered here. We predict that {\\it GLAST} will detect\nseveral cluster mergers and, depending on the mean magnetic fields in the\nintracluster medium, the Low Frequency Array could detect anywhere from several\nto several hundred. \n\n"}
{"id": "astro-ph/0209561", "contents": "Title: Transit Target Selection Using Reduced Proper Motions Abstract: In searches for planetary transits in the field, well over half of the survey\nstars are typically giants or other stars that are too large to permit\nstraightforward detection of planets. For all-sky searches of bright V<~11\nstars, the fraction is ~90%. We show that the great majority of these\ncontaminants can be removed from the sample by analyzing their reduced proper\nmotions (RPMs): giants have much lower RPMs than dwarfs of the same color. We\nuse Hipparcos data to design a RPM selection function that eliminates most\nevolved stars, while rejecting only 9% of viable transit targets. Our method\ncan be applied using existing or soon-to-be-released all-sky data to stars\nV<12.5 in the northern hemisphere and V<12 in the south. The method degrades at\nfainter magnitudes, but does so gracefully. For example, at V=14 it can still\nbe used to eliminate giants redward of V-I~0.95, that is, the blue edge of the\nred giant clump. \n\n"}
{"id": "astro-ph/0212109", "contents": "Title: ISOCAM view of the starburst galaxies M82, NGC253, and NGC1808 Abstract: We present results of mid-infrared 5.0-16.5 micron spectrophotometric imaging\nof the starburst galaxies M82, NGC253, and NGC1808 from the ISOCAM instrument\non board the Infrared Space Observatory. The mid-infrared spectra of the three\ngalaxies are very similar in terms of features present. The > 11 micron\ncontinuum attributed to very small dust grains (VSGs) exhibits a large spread\nin intensity relative to the short-wavelength emission. We find that the 15\nmicron dust continuum flux density correlates well with the fine-structure\n[ArII] 6.99 micron line flux and thus provides a good quantitative indicator of\nthe level of star formation activity. By contrast, the 5-11 micron region\ndominated by emission from polycyclic aromatic hydrocarbons (PAHs) has a nearly\ninvariant shape. Variations in the relative intensities of the PAH features are\nnevertheless observed, at the 20%-100% level. We illustrate extinction effects\non the shape of the mid-infrared spectrum of obscured starbursts, emphasizing\nthe differences depending on the applicable extinction law and the consequences\nfor the interpretation of PAH ratios and extinction estimates. The relative\nspatial distributions of the PAH, VSG, and [ArII] 6.99 micron emission between\nthe three galaxies exhibit remarkable differences. The < 1 kpc size of the\nmid-infrared source is much smaller than the optical extent of our sample\ngalaxies and 70%-100% of the IRAS 12 micron flux is recovered within the ISOCAM\n< 1.5 arcmin squared field of view, indicating that the nuclear starburst\ndominates the total mid-infrared emission while diffuse light from quiescent\ndisk star formation contributes little. \n\n"}
{"id": "astro-ph/0212548", "contents": "Title: Chaotic infaltion with a quadratic potential in all dimensions Abstract: We study chaotic inflation with a quadratic potential in all dimensions. The\nspectral indices of scalar and tensor perturbations and also their running have\nbeen calculated in all dimensions. \n\n"}
{"id": "astro-ph/0302567", "contents": "Title: On the Angular Correlation Function of SZ Clusters : Extracting\n  cosmological information from a 2D catalog Abstract: We discuss the angular correlation function of Sunyaev-Zel'dovich\n(SZ)-detected galaxy clusters as a cosmological probe. As a projection of the\nreal-space cluster correlation function, the angular function samples the\nunderlying SZ catalog redshift distribution. It offers a way to study cosmology\nand cluster evolution directly with the two-dimensional catalog, even before\nextensive follow-up observations, thereby facilitating the immediate scientific\nreturn from SZ surveys. As a simple illustration of the information content of\nthe angular function, we examine its dependence on the parameter pair Om_m,\nsigma_8 in flat cosmologies. We discuss sources of modeling uncertainty and\nconsider application to the future Planck SZ catalog, showing how these two\nparameters and the normalization of the SZ flux-mass relation can be\nsimultaneously found when the local X-ray cluster abundance constraint is\nincluded. \n\n"}
{"id": "astro-ph/0304174", "contents": "Title: The First Substellar Subdwarf? Discovery of a Metal-poor L Dwarf with\n  Halo Kinematics Abstract: We present the discovery of the first L-type subdwarf, 2MASS\nJ05325346+8246465. This object exhibits enhanced collision-induced H$_2$\nabsorption, resulting in blue NIR colors ($J-K_s = 0.26{\\pm}0.16$). In\naddition, strong hydride bands in the red optical and NIR, weak TiO absorption,\nand an optical/J-band spectral morphology similar to the L7 DENIS 0205$-$1159AB\nimply a cool, metal-deficient atmosphere. We find that 2MASS 0532+8246 has both\na high proper motion, $\\mu$ = 2$\\farcs60\\pm0\\farcs$15 yr$^{-1}$, and a\nsubstantial radial velocity, $v_{rad} = -195{\\pm}11$ km s$^{-1}$, and its\nprobable proximity to the Sun (d = 10--30 pc) is consistent with halo\nmembership. Comparison to subsolar-metallicity evolutionary models strongly\nsuggests that 2MASS 0532+8246 is substellar, with a mass of 0.077 $\\lesssim$ M\n$\\lesssim$ 0.085 M$_{\\sun}$ for ages 10--15 Gyr and metallicities $Z =\n0.1-0.01$ $Z_{\\sun}$. The discovery of this object clearly indicates that star\nformation occurred below the Hydrogen burning mass limit at early times,\nconsistent with prior results indicating a flat or slightly rising mass\nfunction for the lowest-mass stellar subdwarfs. Furthermore, 2MASS 0532+8246\nserves as a prototype for a new spectral class of subdwarfs, additional\nexamples of which could be found in NIR proper motion surveys. \n\n"}
{"id": "astro-ph/0305400", "contents": "Title: An ISOCAM survey through gravitationally lensing galaxy clusters Abstract: ISOCAM was used to perform a deep survey through three gravitationally\nlensing clusters of galaxies. Nearly seventy sq. arcmin were covered over the\nclusters A370, A2218 and A2390. We present maps and photometry at 6.7 & 14.3\nmicrons, showing a total of 145 mid-IR sources and the associated source\ncounts. The 15 micron counts reach the faintest level yet recorded. All sources\nhave counterparts in the optical or near-IR. Models of the clusters were used\nto correct for the effects of lensing, which increases the sensitivity of the\nsurvey. Seven of fifteen SCUBA sources were detected at 15 microns. Five have\nredshift between 0.23 & 2.8, with a median of 0.9. The field sources were\ncounted to a lensing-corrected sensitivity of 30 microJy at 15 microns, and 14\nmicroJy at 7 microns. The counts, corrected for completeness, contamination by\ncluster sources and lensing, confirm and extend findings of an excess by a\nfactor of ten in the 15 micron population with respect to source models with no\nevolution. Source redshifts are mostly between 0.4 and 1.5. For the counts at 7\nmicrons, integrating from 14 microJy to 460 microJy, we resolve 0.49+/-0.2\nnW.m^(-2).sr^(-1) of the infrared background light (IBL) into discrete sources.\nAt 15 microns we include the counts from other ISOCAM surveys to integrate from\n30 microJy to 50 mJy, two to three times deeper than unlensed surveys, to\nresolve 2.7+/-0.62 nW.m^(-2).sr^(-1) of the IBL. These values are 10% and 55%,\nrespectively, of the upper limit to the IBL, derived from photon-photon pair\nproduction of the TeV gamma rays from BL-Lac sources on the IBL photons.\nHowever, recent detections of TeV gamma rays from the z=0.129 BL Lac H1426+428\nsuggest that the 15 micron background reported implies substantial absorption\nof TeV photons from that source. \n\n"}
{"id": "astro-ph/0310059", "contents": "Title: Simulations of dust-trapping vortices in protoplanetary discs Abstract: Local three-dimensional shearing box simulations of the compressible coupled\ndust-gas equations are used in the fluid approximation to study the evolution\nof different initial vortex configurations in a protoplanetary disc and their\ndust-trapping capabilities. The initial conditions for the gas are derived from\nan analytic solution to the compressible Euler equation and the continuity\nequation. The solution is valid if there is a vacuum outside the vortex. In the\nsimulations the vortex is either embedded in a hot corona, or it is extended in\na cylindrical fashion in the vertical direction. Both configurations are found\nto survive for at least one orbit and lead to accumulation of dust inside the\nvortex. This confirms earlier findings that dust accumulates in anticyclonic\nvortices, indicating that this is a viable mechanism for planetesimal\nformation. \n\n"}
{"id": "astro-ph/0310772", "contents": "Title: Powerful obscured AGN among X-ray hard, optically-dim serendipitous\n  Chandra sources Abstract: We present a small sample of Chandra X-ray sources selected from the fields\nof ACIS observations which probe fluxes around the break in the hard band\nsource counts. The targets of these fields include 9 nearby galaxy clusters, 1\ndistant cluster and 2 powerful radio galaxy fields. The follow-up of this\nserendipitous sample was biased towards X-ray hard and optically-dim sources\nmostly not seen on the Digitized Sky Survey; for these, we present X-ray\nfluxes, optical and near-infrared photometry leading to 51 photometric\nredshifts in all and 18 independently measured spectroscopic redshifts. Few\nsources are associated with the target fields themselves. Fifty-six of 58\nsources imaged in the K-band are detected at K<~20 with K_median=18, and of\nthese, 38 have hard X-ray count ratios and 24 of these are significantly hard\nwith most of the counts emerging about 2 keV. We find that almost all are AGN\nhosted in massive early-type host galaxies with a photometric redshift\ndistribution peaking at z~1. Two type 2 quasars with intrinsic X-ray luminosity\nL>~10^{45} erg/s, Fe K_alpha emission lines and absorbing column density\nnH>10^{23} cm^{-2} -- and nH>~10^{24} cm^{-2} in one case -- are discussed in\ndetail; the sample contains at least 12 potential type 2 quasars in all. We\ndiscuss various detection strategies for type 2 quasars and calculate their\ninferred space density. This combines and extends a number of results from\nsubsamples already published by us. \n\n"}
{"id": "astro-ph/0311490", "contents": "Title: The radio galaxy K-z relation: the 10^12 Msol mass limit; masses of\n  galaxies from the L_K luminosity, up to z >4 Abstract: The narrow K-z relation of powerful radio galaxies in the Hubble K diagram is\noften attributed to the stellar populations of massive elliptical galaxies.\nExtended over a large range of redshifts (0<z<4), it is difficult to estimate\nmasses at high z from galaxy evolution. In the present paper, we propose to\nestimate the stellar masses of galaxies using the galaxy evolution model\nPEGASE. We use star formation scenarios that successfully fit faint galaxy\ncounts and z=0 galaxy templates. They also allow to estimate valid photometric\nredshifts. The baryonic mass of the initial gas cloud M_bar is then derived.\nThe K-z relation is remarkably reproduced by our scenario for elliptical\ngalaxies of baryonic mass M_(bar,max)=10^12 Msol, at all z up to z=4.\nM_(bar,max) is also the maximum mass limit of all types of galaxies. Using\nanother IMF, even a top-heavy one, does not alter our conclusions. The high\nvalue of M_(bar,max) observed at z > 4 implies that massive clouds were already\nformed at early epochs. We also find that the M_(bar,max) limit is similar to\nthe critical mass M_crit of a self-gravitating cloud regulated by cooling (Rees\n& Ostriker, 1977; Silk, 1977). Moreover, the critical size r_crit = 75 Kpc is\nremarkably close to the typical diameter of Ly_alpha haloes surrounding distant\nradio galaxies. This confirms the validity of the method of baryonic mass\ndetermination based on the K-band luminosity. A puzzling question that remains\nto be answered is the short time-scale of mass-accumulation required to form\nsuch massive galaxies at z=4. We discuss the dispersion of the K-z relation and\nthe link between the active nucleus and a large stellar mass. \n\n"}
{"id": "astro-ph/0401599", "contents": "Title: Distribution of magnetically confined circumstellar matter in oblique\n  rotators Abstract: We consider the mechanical equilibrium and stability of matter trapped in the\nmagnetosphere of a rapidly rotating star. Assuming a dipolar magnetic field and\narbitrary inclination of the magnetic axis with respect to the axis of rotation\nwe find stable equilibrium positions a) in a (warped) disk roughly aligned with\nthe magnetic equatorial plane and b) at two locations above and below the disk,\nwhose distance from the star increases with decreasing inclination angle\nbetween dipole and rotation axis. The distribution of matter is not strongly\naffected by allowing for a spatial offset of the magnetic dipole. These results\nprovide a possible explanation for some observations of corotating localized\nmass concentrations in hot magnetic stars. \n\n"}
{"id": "astro-ph/0402083", "contents": "Title: High-Energy Neutrino Astronomy Abstract: Kilometer-scale neutrino detectors such as IceCube are discovery instruments\ncovering nuclear and particle physics, cosmology and astronomy. Examples of\ntheir multidisciplinary missions include the search for the particle nature of\ndark matter and for additional small dimensions of space. In the end, their\nconceptual design is very much anchored to the observational fact that Nature\naccelerates protons and photons to energies in excess of $10^{20}$ and\n$10^{13}$ eV, respectively. The cosmic ray connection sets the scale of cosmic\nneutrino fluxes. In this context, we discuss the first results of the completed\nAMANDA detector and the reach of its extension, IceCube. Similar experiments\nare under construction in the Mediterranean. Neutrino astronomy is also\nexpanding in new directions with efforts to detect air showers, acoustic and\nradio signals initiated by super-EeV neutrinos. \n\n"}
{"id": "astro-ph/0404439", "contents": "Title: The young stellar population in the Serpens Cloud Core: An ISOCAM survey Abstract: We present results from an ISOCAM survey in the two broad band filters LW2\n(5-8.5 mu) and LW3 (12-18 mu) of a 0.13 square degree coverage of the Serpens\nMain Cloud Core. A total of 392 sources were detected in the 6.7 mu band and\n139 in the 14.3 mu band to a limiting sensitivity of ~ 2 mJy. Only about 50% of\nthe mid-IR excess sources show excesses in the near-IR J-H/H-K diagram. In the\ncentral Cloud Core the Class I/Class II number ratio is 19/18, i.e. about 10\ntimes larger than in other young embedded clusters such as rho Ophiuchi or\nChamaeleon. The mid-IR fluxes of the Class I and flat-spectrum sources are\nfound to be on the average larger than those of Class II sources. Stellar\nluminosities are estimated for the Class II sample, and its luminosity function\nis compatible with a coeval population of about 2 Myr which follows a three\nsegment power-law IMF. For this age about 20% of the Class IIs are found to be\nyoung brown dwarf candidates. The YSOs are in general strongly clustered, the\nClass I sources more than the Class II sources, and there is an indication of\nsub-clustering. The sub-clustering of the protostar candidates has a spatial\nscale of 0.12 pc. These sub-clusters are found along the NW-SE oriented ridge\nand in very good agreement with the location of dense cores traced by\nmillimeter data. The smallest clustering scale for the Class II sources is\nabout 0.25 pc, similar to what was found for rho Ophiuchi. Our data show\nevidence that star formation in Serpens has proceeded in several phases, and\nthat a ``microburst'' of star formation has taken place very recently, probably\nwithin the last 10^5 yrs. \n\n"}
{"id": "astro-ph/0409239", "contents": "Title: Mass Models for Spiral Galaxies from 2-D Velocity Maps Abstract: We model the mass distributions of 40 high surface brightness spiral galaxies\ninside their optical radii, deriving parameters of mass models by matching the\npredicted velocities to observed velocity maps. We use constant mass-to-light\ndisk and bulge models, and we have tried fits with no halo and with three\ndifferent halo density profiles. The data require a halo in most, but not all,\ncases, while in others the best fit occurs with negligible mass in the luminous\ncomponent, which we regard as unphysical. All three adopted halo profiles lead\nto fits of about the same quality, and our data therefore do not constrain the\nfunctional form of the halo profile. The halo parameters display large\ndegeneracies for two of the three adopted halo functions, but the separate\nluminous and dark masses are better constrained. However, the fitted disk and\nhalo masses vary substantially between the adopted halo models, indicating that\neven high quality 2-D optical velocity maps do not provide significant\nconstraints on the dark matter content of a galaxy. We demonstrate that data\nfrom longslit observations are likely to provide still weaker constraints. We\nconclude that additional information is needed in order to constrain the\nseparate disk and halo masses in a galaxy. \n\n"}
{"id": "astro-ph/0409591", "contents": "Title: Exploring the Gamma Ray Horizon with the next generation of Gamma Ray\n  Telescopes. Part 3: Optimizing the observation schedule of gamma-ray sources\n  for the extraction of cosmological parameters Abstract: The optimization of the observation schedule of gamma-ray emitters by the new\ngeneration of Cherenkov Telescopes to extract cosmological parameters from the\nmeasurement of the Gamma Ray Horizon at different redshifts is discussed. It is\nshown that improvements over 30% in the expected cosmological parameter\nuncertainties can be achieved if instead of equal-observation time, dedicated\nobservation schedules are applied. \n\n"}
{"id": "astro-ph/0411529", "contents": "Title: Environmental Enhancement of DM Haloes Abstract: We study the properties of dark matter haloes of a LCDM model in different\nenvironments. Using the distance of the 5th nearest neighbour as an\nenvironmental density indicator, we show that haloes in a high density\nenvironment are more massive, richer, have larger radii and larger velocity\ndispersions than haloes in a low density environment. Haloes in high density\nregions move with larger velocities, and are more spherical than haloes in low\ndensity regions. In addition, low mass haloes in the vicinity of the most\nmassive haloes are themselves more massive, larger, and have larger rms\nvelocities and larger 3D velocities than low mass haloes far from massive\nhaloes. The velocities of low mass haloes near massive haloes increase with the\nparent halo mass. Our results are in agreement with recent findings about\nenvironmental effects for groups and clusters of galaxies from deep (SDSS and\nLCRS) surveys. \n\n"}
{"id": "astro-ph/0412234", "contents": "Title: Principal Component Analysis of PSF Variation in Weak Lensing Surveys Abstract: We introduce a new algorithm for interpolating measurements of the\npoint-spread function (PSF) using stars from many exposures. The principal\ncomponents of the variation in the PSF pattern from multiple exposures are used\nto solve for better fits for each individual exposure. These improved fits are\nthen used to correct the weak lensing shapes. Since we expect some degree of\ncorrelation in the PSF anisotropy across exposures, using information from\nstars in all exposures leads to a significant gain in the accuracy of the\nestimated PSF. It means that in general, the accuracy of PSF reconstruction is\nlimited not by the number density of stars per exposure, but by the stacked\nnumber density across all exposures in a given survey. This technique is\napplied to the 75 square degree CTIO lensing survey, and we find that the PSF\nvariation is well described by a small number of components. There is a\nsignificant improvement in the lensing measurements: the residual stellar PSF\ncorrelations are reduced by several orders of magnitude, and the measured\nB-mode in the two-point correlation is consistent with zero down to 1\narcminute. We also discuss the applications of the PCA technique to future\nsurveys. \n\n"}
{"id": "astro-ph/0412363", "contents": "Title: Shearing and embedding box simulations of the magnetorotational\n  instability Abstract: Two different computational approaches to the magnetorotational instability\n(MRI) are pursued: the shearing box approach which is suited for local\nsimulations and the embedding box approach whereby a Taylor Couette flow is\nembedded in a box so that numerical problems with the coordinate singularity\nare avoided. New shearing box simulations are presented and differences between\nregular and hyperviscosity are discussed. Preliminary simulations of spherical\nnonlinear Taylor Couette flow in an embedding box are presented and the effects\nof an axial field on the background flow are studied. \n\n"}
{"id": "astro-ph/0412546", "contents": "Title: Cascades from $\\nu_e$ above $10^{20}$ eV Abstract: At very high energies, the Landau-Pomeranchuk-Migdal effect reduces the cross\nsections for electron bremsstrahlung and photon $e^+e^-$ pair production. The\nfractional electron energy loss and pair production cross sections drop as the\nenergy increases. In contrast, the cross sections for photonuclear interactions\ngrow with energy. In solids and liquids, at energies above $10^{20}$ eV,\nphotonuclear reactions dominate, and showers that originate as photons or\nelectrons quickly become hadronic showers. These electron-initiated hadronic\nshowers are much shorter (due to the absence of the LPM effect), but wider than\npurely electromagnetic showers would be. This change in shape alters the\nspectrum of the electromagnetic and acoustic radiation emitted from the shower.\nThese alterations have important implications for existing and planned searches\nfor radiation from $\\nu_e$ induced showers above $10^{20}$ eV, and some\nexisting limits should be reevaluated. \n\n"}
{"id": "astro-ph/0501144", "contents": "Title: GaBoDS: The Garching-Bonn Deep Survey; IV. Methods for the Image\n  reduction of multi-chip Cameras Abstract: We present our image processing system for the reduction of optical imaging\ndata from multi-chip cameras. In the framework of the Garching Bonn Deep Survey\n(GaBoDS; Schirmer et al. 2003) consisting of about 20 square degrees of\nhigh-quality data from WFI@MPG/ESO 2.2m, our group developed an imaging\npipeline for the homogeneous and efficient processing of this large data set.\nHaving weak gravitational lensing as the main science driver, our algorithms\nare optimised to produce deep co-added mosaics from individual exposures\nobtained from empty field observations. However, the modular design of our\npipeline allows an easy adaption to different scientific applications. Our\nsystem has already been ported to a large variety of optical instruments and\nits products have been used in various scientific contexts. In this paper we\ngive a thorough description of the algorithms used and a careful evaluation of\nthe accuracies reached. This concerns the removal of the instrumental\nsignature, the astrometric alignment, photometric calibration and the\ncharacterisation of final co-added mosaics. In addition we give a more general\noverview on the image reduction process and comment on observing strategies\nwhere they have significant influence on the data quality. \n\n"}
{"id": "astro-ph/0502168", "contents": "Title: A fresh look at the unstable simulations of Bondi-Hoyle-Lyttleton\n  accretion Abstract: The instability of Bondi-Hoyle-Lyttleton accretion, observed in numerical\nsimulations, is analyzed through known physical mechanisms and possible\nnumerical artefacts. The mechanisms of the longitudinal and transverse\ninstabilities, established within the accretion line model, are clarified. They\ncannot account for the instability of BHL accretion at moderate Mach number\nwhen the pressure forces within the shock cone are taken into account. The\nadvective-acoustic instability is considered in the context of BHL accretion\nwhen the shock is detached from the accretor. This mechanism naturally explains\nthe stability of the flow when the shock is weak, and the instability when the\naccretor is small. In particular, it is a robust proof of the instability of 3D\naccretion when gamma=5/3 if the accretor is small enough, even for moderate\nshock strength (M sim 3). The numerical artefacts that may be present in\nexisting numerical simulations are reviewed, with particular attention paid to\nthe advection of entropy/vorticity perturbations and the artificial acoustic\nfeedback from the accretor boundary condition. Several numerical tests are\nproposed to test these mechanisms. \n\n"}
{"id": "astro-ph/0502222", "contents": "Title: A tensor-vector-scalar framework for modified dynamics and cosmic dark\n  matter Abstract: I describe a tensor-vector-scalar theory that reconciles the galaxy scale\nsuccess of modified Newtonian dynamics (MOND) with the cosmological scale\nevidence for CDM. The theory provides a cosmological basis for MOND in the\nsense that the predicted phenomenology only arises in a cosmological\nbackground. The theory contains an evolving effective potential, and scalar\nfield oscillations in this potential comprise the cold dark matter; the de\nBroglie wavelength of these soft bosons, however, is sufficiently large that\nthey cannot accumulate in galaxies. The theory predicts, inevitably, a constant\nanomalous acceleration in the outer solar system which, depending upon the\nchoice of parameters, can be consistent with that detected by the Pioneer\nspacecrafts. \n\n"}
{"id": "astro-ph/0503362", "contents": "Title: Bulk viscosity driving the acceleration of the Universe Abstract: The possibility that the present acceleration of the universe is driven by a\nkind of viscous fluid is exploited. At background level this model is similar\nto the generalized Chaplygin gas model (GCGM). But, at perturbative level, the\nviscous fluid exhibits interesting properties. In particular the oscillations\nin the power spectrum that plagues the GCGM are not present. Possible\nfundamental descriptions for this viscous dark energy are discussed. \n\n"}
{"id": "astro-ph/0509752", "contents": "Title: Template fitting and the large-angle CMB anomalies Abstract: We investigate two possible explanations for the large-angle anomalies in the\nCosmic Microwave Background (CMB): an intrinsically anisotropic model and an\ninhomogeneous model. We take as an example of the former a Bianchi model (which\nleaves a spiral pattern in the sky) and of the latter a background model that\nalready contains a non-linear long-wavelength plane wave (leaving a stripy\npattern in the sky). We make use of an adaptation of the ``template''\nformalism, previously designed to detect galactic foregrounds, to recognize\nthese patterns and produce confidence levels for their detection. The\n``corrected'' maps, from which these patterns have been removed, are free of\nanomalies, in particular their quadrupole and octupole are not planar and their\nintensities not low. We stress that although the ``template'' detections are\nnot found to be statistically significant they do correct statistically\nsignificant anomalies. \n\n"}
{"id": "astro-ph/0511071", "contents": "Title: Thermal neutrinos from hot GRB fireballs Abstract: We consider the physics of neutrinos in a fireball, i.e. a tightly coupled\nplasma of photons, positrons and electrons. Such a fireball is believed to form\nin the first stages of a gamma-ray burst. We assume the fireball is\nradiation-dominated and spherically symmetric. Energy considerations limit the\nallowed baryon density, from which it follows that the neutrino physics is\ndominated by leptonic processes. We find that, for quite general initial\nconditions, neutrinos start out in thermodynamic equilibrium with the fireball\nand follow the usual hydrodynamical evolution. As the fireball cools, the\nplasma becomes transparent to neutrinos which subsequently decouple from the\nplasma. Although a sizable fraction of the total energy is carried away, the\ndetection possibility of these neutrino bursts is limited due to the isotropic\noutflow and the relatively low mean energy of approximately 60 MeV. \n\n"}
{"id": "astro-ph/0511245", "contents": "Title: Possible evidence for the ejection of a supermassive black hole from an\n  ongoing merger of galaxies Abstract: Attempts of Magain et al (2005) to detect the host galaxy of the bright QSO\nHE0450--2958 have not been successful. We suggest that the supermassive black\nhole powering the QSO was ejected from the observed ULIRG at the same redshift\nand at 1.5 arcsec distance. Ejection could have either be caused by recoil due\nto gravitational wave emission from a coalescing binary of supermassive black\nholes or the gravitational slingshot of three or more supermassive black holes\nin the ongoing merger of galaxies which triggered the starburst activity in the\nULIRG. We discuss implications for the possible hierarchical build-up of\nsupermassive black holes from intermediate and/or stellar mass black holes, and\nfor the detection of coalescing supermassive binary black holes by LISA. \n\n"}
{"id": "astro-ph/0512646", "contents": "Title: Short-living supermassive magnetar model for the early X-ray flares\n  following short GRBs Abstract: We suggest a short-living supermassive magnetar model to account for the\nX-ray flares following short $\\gamma-$ray bursts. In this model, the central\nengine of the short $\\gamma-$ray bursts is a supermassive millisecond magnetar.\nThe X-ray flares are powered by the dipole radiation of the magnetar. When the\nmagnetar has lost a significant part of its angular momentum, it collapses to a\nblack hole and the X-ray flares disappear abruptly. Two important predictions\nof this model are (i) X-ray flares much more energetic than that detected in\nGRB 050724 may be detectable in the coming months and years by the XRT onboard\n{\\it Swift}. (ii) The short GRBs with X-ray flares may occur outside of their\nhost galaxy. \n\n"}
{"id": "astro-ph/0603348", "contents": "Title: On the mean field dynamo with Hall effect Abstract: We study in the present paper how Hall effect modifies the quenching process\nof the electromotive force (e.m.f.) in Mean Field Dynamo (MFD) theories. We\nwrite down the evolution equations for the e.m.f. and for the large and small\nscale magnetic helicity, treat Hall effect as a perturbation and integrate the\nresulting equations assuming boundary conditions such that the total\ndivergencies vanish. For force-free large scale magnetic fields, Hall effect\nacts by coupling the small scale velocity and magnetic fields. For the range of\nparameters considered, the overall effect is a stronger quenching of the e.m.f.\nthan in standard MHD and a damping of the inverse cascade of magnetic helicity.\nIn astrophysical environments characterized by the parameters considered here,\nHall effect would produce an earlier quenching of the e.m.f. and consequently a\nweaker large scale magnetic field. \n\n"}
{"id": "astro-ph/0603421", "contents": "Title: The OLS-lens survey: The discovery of five new galaxy-galaxy strong\n  lenses from the SDSS Abstract: Bright galaxy-galaxy strong lenses are much more powerful than lensed quasars\nfor measuring the mass profiles of galaxies, but until this year only a handful\nhave been known. Here we present five new examples, identified via the optimal\nline-of-sight gravitational lens search strategy applied to luminous red\ngalaxies in the Sloan Digital Sky Survey (SDSS). Our survey largely complements\na similar survey by Bolton et al., who recently presented several new lenses.\nThe lensed background galaxies are selected from the SDSS spectra via the\npresence of narrow emission line signatures, including the [OII] 3726,3729, Hb\nand [OIII] 4960,5008 lines, superposed on the spectra of the bright,\nintervening, deflector galaxies. Our five confirmed new systems include\ndeflector galaxies with redshifts z=0.17-0.28 and lensed galaxies with\nredshifts z=0.47-1.18. Simulations of moderately deep (few orbits) HST-ACS\nimaging of systems such as these, where the lensed source is brighter than\nr~23, are presented. These demonstrate the feasibility of measuring accurately\nthe inner slope of the dark matter halo to within an uncertainty\nsigma(gamma)~0.1, the dark matter fraction within the Einstein radius, and the\nmass-to-light ratio of the stars alone, independently of dynamical\nmeasurements. The high success rate of our search so far, >60%, and the\nrelatively modest observational resources necessary to confirm the\ngravitational lens nature of the candidates, demonstrate that compilation of a\nsample of ~100 galaxy-galaxy lenses from the SDSS is readily achievable,\nopening up a rich new field in dark matter studies. \n\n"}
{"id": "astro-ph/0606046", "contents": "Title: Bianchi Type VII_h Models and the WMAP 3-year Data Abstract: Context. A specific example of Bianchi Type VIIh models, i.e. those including\nuniversal rotation (vorticity) and differential expansion (shear), has been\nshown in Jaffe et al. (2005) to correlate unexpectedly with the WMAP first-year\ndata. Aims. We re-assess the signature of this model in the WMAP 3-year data.\nMethods. The cross-correlation methods are described in Jaffe et al. (2006a).\nWe use the WMAP 3-year data release, including maps for individual years, and\nperform additional comparisons to assess the influence of both noise and\nresidual foregrounds and eliminate potential non-cosmological sources for the\ncorrelation. Results. We confirm that the signal is detected in both the\ncombined 3-year data and the individual yearly sky maps at a level consistent\nwith our original analysis. The significance of the correlation is not affected\nby either noise or foreground residuals. Conclusions. The results of our\nprevious study are unchanged. \n\n"}
{"id": "astro-ph/0607227", "contents": "Title: Why anthropic reasoning cannot predict Lambda Abstract: We revisit anthropic arguments purporting to explain the measured value of\nthe cosmological constant. We argue that different ways of assigning\nprobabilities to candidate universes lead to totally different anthropic\npredictions. As an explicit example, we show that weighting different universes\nby the total number of possible observations leads to an extremely small\nprobability for observing a value of Lambda equal to or greater than what we\nnow measure. We conclude that anthropic reasoning within the framework of\nprobability as frequency is ill-defined and that in the absence of a\nfundamental motivation for selecting one weighting scheme over another the\nanthropic principle cannot be used to explain the value of Lambda, nor, likely,\nany other physical parameters. \n\n"}
{"id": "astro-ph/0608234", "contents": "Title: Interpreting Spectral Energy Distributions from Young Stellar Objects.\n  I. A grid of 200,000 YSO model SEDs Abstract: We present a grid of radiation transfer models of axisymmetric young stellar\nobjects (YSOs), covering a wide range of stellar masses (from 0.1Msun to\n50Msun) and evolutionary stages (from the early envelope infall stage to the\nlate disk-only stage). The grid consists of 20,000 YSO models, with spectral\nenergy distributions (SEDs) and polarization spectra computed at ten viewing\nangles for each model, resulting in a total of 200,000 SEDs. [...]. These\nmodels are publicly available on a dedicated WWW server:\nhttp://www.astro.wisc.edu/protostars/ . In this paper we summarize the main\nfeatures of our models, as well as the range of parameters explored. [...]. We\nexamine the dependence of the spectral indices of the model SEDs on envelope\naccretion rate and disk mass. In addition, we show variations of spectral\nindices with stellar temperature, disk inner radius, and disk flaring power for\na subset of disk-only models. We also examine how changing the wavelength range\nof data used to calculate spectral indices affects their values. We show sample\ncolor-color plots of the entire grid as well as simulated clusters at various\ndistances with typical {\\it Spitzer Space Telescope} sensitivities. We find\nthat young embedded sources generally occupy a large region of color-color\nspace due to inclination and stellar temperature effects. Disk sources occupy a\nsmaller region of color-color space, but overlap substantially with the region\noccupied by embedded sources, especially in the near- and mid-IR. We identify\nregions in color-color space where our models indicate that only sources at a\ngiven evolutionary stage should lie. [...]. \n\n"}
{"id": "astro-ph/0610856", "contents": "Title: Spitzer White Dwarf Planet Limits Abstract: We present preliminary limits on the presence of planets around white dwarf\nstars using the IRAC photometer on the Spitzer space telescope. Planets emit\nstrongly in the mid-infrared which allows their presence to be detected as an\nexcess at these wavelengths. We place limits of $5 M_J$ for 8 stars assuming\nages of $1 Gyr$, and $10 M_J$ for 23 stars.We describe our survey, present our\nresults and comment on approaches to improve our methodology. \n\n"}
{"id": "astro-ph/0610958", "contents": "Title: Multi-scale morphology of the galaxy distribution Abstract: Many statistical methods have been proposed in the last years for analyzing\nthe spatial distribution of galaxies. Very few of them, however, can handle\nproperly the border effects of complex observational sample volumes. In this\npaper, we first show how to calculate the Minkowski Functionals (MF) taking\ninto account these border effects. Then we present a multiscale extension of\nthe MF which gives us more information about how the galaxies are spatially\ndistributed. A range of examples using Gaussian random fields illustrate the\nresults. Finally we have applied the Multiscale Minkowski Functionals (MMF) to\nthe 2dF Galaxy Redshift Survey data. The MMF clearly indicates an evolution of\nmorphology with scale. We also compare the 2dF real catalog with mock catalogs\nand found that Lambda-CDM simulations roughly fit the data, except at the\nfinest scale. \n\n"}
{"id": "astro-ph/0611027", "contents": "Title: Proposal: The Neural Network Telescope Abstract: A neural network mechanism that can compensate for poor optical quality was\nrecently discovered in a biological context. We propose that this mechanism can\nand should be adopted for astronomical purposes. This would shift emphasis away\nfrom the quality of the optical equipment to information processing, hence\nshould decrease the cost and make larger instruments feasible. \n\n"}
{"id": "astro-ph/0612158", "contents": "Title: Direct imaging of the young spectroscopic binary HD 160934 Abstract: We report on the direct detection of a close companion to HD 160934, a young\nactive star, SB1 spectroscopic binary, and suggested member of the AB Doradus\nmoving group. High angular resolution at the Calar Alto 2.2m telescope was\nachieved by means of the Lucky Imaging technique, allowing direct imaging close\nto the diffraction limit in the SDSS z' band. Our results are combined with\npre-discovery HST archive data, own UBVRI broadband photometry, published JHK\nmagnitudes, and available radial velocity measurements to constrain the\nphysical properties of the HD 160934 close binary. We suggest that the direct\ndetection may be identical to the spectroscopically discovered companion. \n\n"}
{"id": "astro-ph/0612699", "contents": "Title: Neutrino Flux from Cosmic Ray Accelerators in the Cygnus Spiral Arm of\n  the Galaxy Abstract: Intriguing evidence has been accumulating for the production of cosmic rays\nin the Cygnus region of the Galactic plane. We here show that the IceCube\nexperiment can produce incontrovertible evidence for cosmic ray acceleration by\nobserving neutrinos from the decay of charged pions accompanying the TeV photon\nflux observed in the HEGRA, Whipple, Tibet and Milagro experiments. Our\nassumption is that the TeV photons observed are the decay products of neutral\npions produced by cosmic ray accelerators in the nearby spiral arm of the\nGalaxy. Because of the proximity of the sources, IceCube will obtain evidence\nat the 5sigma level in 15 years of observation. \n\n"}
{"id": "astro-ph/0703455", "contents": "Title: Non-isotropy in the CMB power spectrum in single field inflation Abstract: Contaldi et al. [1] have suggested that an initial period of kinetic energy\ndomination in single field inflation may explain the lack of CMB power at large\nangular scales. We note that in this situation it is natural that there also be\na spatial gradient in the initial value of the inflaton field, and that this\ncan provide a spatial asymmetry in the observed CMB power spectrum, manifest at\nlow multipoles. We investigate the nature of this asymmetry and comment on its\nrelation to possible anomalies at low multipoles. \n\n"}
{"id": "astro-ph/9708121", "contents": "Title: Light-cone effect on higher-order clustering in redshift surveys Abstract: We have evaluated a systematic effect on counts-in-cells analysis of deep,\nwide-field galaxy catalogues induced by the evolution of clustering within the\nsurvey volume. A multiplicative correction factor is explicitly presented,\nwhich can be applied after the higher order correlation functions have been\nextracted in the usual way, without taking into account the evolution. The\ngeneral theory of this effect combined with the ansatz describing the\nnon-linear evolution of clustering in simulations enables us to estimate the\nmagnitude of the correction factor in different cosmologies. In a series of\nnumerical calculations assuming an array of cold dark matter models, it is\nfound that, as long as galaxies are unbiased tracers of underlying density\nfield, the effect is relatively small ($ \\simeq 10%$) for the shallow surveys\n($z <0.2$), while it becomes significant (order of unity) in deep surveys ($z\n\\sim1$). Depending on the scales of interest, the required correction is\ncomparable to or smaller than the expected errors of on-going wide-field galaxy\nsurveys such as the SDSS and 2dF.\n  Therefore at present, the effect has to be taken into account for high\nprecision measurements at very small scales only, while in future deep surveys\nit amounts to a significant correction. \n\n"}
{"id": "astro-ph/9710302", "contents": "Title: Minkowski Functionals in Cosmology: An Overview Abstract: Minkowski functionals have recently been introduced into cosmology as novel\ntools for studying the large-scale distribution of matter in the Universe. We\npresent a brief overview of the method, including its mathematical foundations\nas well as some completed and upcoming applications. \n\n"}
{"id": "astro-ph/9801238", "contents": "Title: An X-ray Luminous, Dwarf Seyfert Companion of Mrk 273 Abstract: We report the discovery of the brightest X-ray source hosted by a faint\n(M_B=-16) dwarf galaxy in the immediate vicinity of the ultraluminous IRAS\nmerging galaxy Mrk 273. The dwarf galaxy, 1.3 arcmin away from Mrk 273, is at\nthe tip of a faint northeast plume of Mrk 273. Its spectrum exhibits strong\n[OIII], Halpha, [NII] emission lines, which establish the redshift of the dwarf\ngalaxy, $z=0.0376$, the same as that of Mrk 273. The emission line ratios are\ntypical of Seyfert galaxies. The X-ray emission is consistent with a point-like\nsource coincident with the center of the dwarf galaxy. The intrinsic X-ray\nluminosity, 6.3x10^{41} ergs, in the 0.1--2.4 keV energy range, is about seven\ntimes larger than the B band luminosity. The X-ray spectrum of the source can\nbe fit with a power-law. All the evidence is consistent with the source being a\nSeyfert galaxy. It is mysterious why out of $\\sim 10$ faint objects in the same\nfield only one is detected by ROSAT and its ratio of soft X-ray to optical\nluminosity is as high as those for BL Lac objects and few active galactic\nnuclei (AGNs). If there is a population of such dwarf AGNs hidden as companions\nof major merger galaxies (such as Mrk 273), they may contribute to the\nluminosity function of AGNs and the cosmic X-ray background at the faint end. \n\n"}
{"id": "astro-ph/9805256", "contents": "Title: Timing Noise Properties of GRO J0422+32 Abstract: OSSE observed the transient black hole candidate GRO J0422+32 (XN Per 92)\nbetween 1992 Aug 11 and 1992 Sep 17. High time resolution data were obtained in\nseveral energy bands over the 35-600 keV range with a sampling rate of 8 ms.\nPower spectra at energies below 175 keV show substantial low-frequency red\nnoise with a shoulder at a few tens of mHz, peaked noise with characteristic\nfrequency near 0.2 Hz, and a second shoulder at a few Hz. The frequencies of\nthe shoulders and the peak are independent of energy and source intensity. The\ncomplex cross spectrum indicates that photons in the 75-175 keV band lag\nphotons in the 35-60 keV band by a time roughly proportional to the inverse of\nthe Fourier frequency. The maximum lag observed is about 300 ms. The power and\nlag spectra are consistent with the production of the gamma rays through\nthermal Comptonization in an extended hot corona with a power-law density\nprofile. \n\n"}
{"id": "astro-ph/9806321", "contents": "Title: The Optical Gravitational Lensing Experiment. The Catalog of Clusters in\n  the Small Magellanic Cloud Abstract: We present the catalog of clusters found in the area of ~2.4 square degree in\nthe central regions of the Small Magellanic Cloud. The catalog contains data\nfor 238 clusters, 72 of them are new objects. For each cluster equatorial\ncoordinates, radii, approximate number of members, cross-identification,\nfinding chart and color magnitude diagrams: V-(B-V) and V-(V-I) are provided.\nPhotometric data for all clusters presented in the catalog are available from\nthe OGLE Internet archive. \n\n"}
{"id": "astro-ph/9809256", "contents": "Title: BeppoSAX detection of the Fe K line in the nearby starburst galaxy NGC\n  253 Abstract: We present BeppoSAX results on the nearby starburst galaxy NGC 253. Although\nextended, a large fraction of the X-ray emission comes from the nuclear region.\nPreliminary analysis of the LECS/MECS/PDS ~0.2-60 keV data from the central 4'\nregion indicates that the continuum is well fitted by two thermal models: a\n``soft'' component with kT ~ 0.9 keV, and a ``hard'' component with kT ~ 6 keV\nabsorbed by a column density of ~ 1.2 x10**22 cm-2. For the first time in this\nobject, the Fe K line at 6.7 keV is detected, with an equivalent width of ~ 300\neV. This detection, together with the shape of the 2--60 keV continuum, implies\nthat most of the hard X-ray emission is thermal in origin, and constrains the\niron abundances of this component to be ~0.25 of solar. Other lines clearly\ndetected are Si, S and Fe L/Ne, in agreement with previous ASCA results. We\ndiscuss our results in the context of the starburst-driven galactic superwind\nmodel. \n\n"}
{"id": "astro-ph/9812232", "contents": "Title: A Reply to \"Comment on 'Big Bang Nucleosynthesis and Active-Sterile\n  Neutrino Mixing: Evidence for Maximal $\\nu_\\mu\\leftrightarrow\\nu_\\tau$ Mixing\n  in Super Kamiokande?'\" Abstract: In the paper \"Big Bang Nucleosynthesis and Active-Sterile Neutrino Mixing:\nEvidence for Maximal Muon-Neutrino/Sterile-Neutrino Mixing in Super Kamiokande\"\n(astro-ph/9810075), we suggested that to evade the Big Bang Nucleosynthesis\nexclusion of the muon neutrino to sterile neutrino oscillation explanation of\nthe Super Kamiokande data, the tau neutrino must have a mass over about 15 eV\nand it must mix with a lighter sterile neutrino. A stable tau neutrino with\nthis mass is inconsistent with cosmological structure formation. In a comment\non our paper (astro-ph/9811067), Foot and Volkas argued that our result is\nincorrect and that the required tau neutrino mass should be much lower. Here we\nback up our original result with a more detailed calculation. We show that the\nargument of Foot and Volkas is invalid, most likely due to an insufficient\nenergy resolution in the low energy part of the neutrino spectrum. \n\n"}
{"id": "astro-ph/9907160", "contents": "Title: Constraints on the slope of the dark halo mass function by microlensing\n  observables Abstract: We investigate the dark halo lens mass function (MF) for a wide class of\nspheroidal non singular isothermal models comparing observed and observable\nmicrolensing quantities for MACHO observations towards LMC and taking into\naccount the detection efficiency. We evaluate the microlensing observable\nquantities, i.e. observable optical depth, number of events and mean duration,\nfor models with homogenous power - law MF changing the upper and lower mass\nlimits and the flattening of the dark halo. By applying the simple technique of\nthe inverse problem method we are then able to get some interesting constraints\non the slope $\\alpha$ of the MF and on the dark halo mass fraction f made out\nby MACHOs consistently with previous results. \n\n"}
{"id": "astro-ph/9907179", "contents": "Title: The K-band luminosity function of nearby field galaxies Abstract: We present a measurement of the K-band luminosity function (LF) of field\ngalaxies obtained from near-infrared imaging of a sample of 345 galaxies\nselected from the Stromlo-APM Redshift Survey. The LF is well-fitted over the\nten magnitude range -26 < M_K < -16 by a Schechter function with parameters\nalpha = -1.16 +- 0.19, M* = -23.58 +- 0.42, phi* = 0.012 +- 0.008 Mpc^-3\nassuming a Hubble constant of H_0 = 100 km/s/Mpc. We have also estimated the LF\nfor two subsets of galaxies subdivided by the equivalent width of the Halpha\nemission line at EW(Halpha) = 10A. There is no significant difference in LF\nshape between the two samples, although there is a hint (~1 sigma significance)\nthat emission line galaxies (ELGs) have M* roughly one magnitude fainter than\nnon-ELGs. Contrary to the optical LF, there is no difference in faint-end slope\nalpha between the two samples. \n\n"}
{"id": "astro-ph/9911238", "contents": "Title: Magnetic Field Limit on SGR 1900+14 Abstract: We measured the period and spin-down rate for SGR 1900+14 during the\nquiescient period two years before the recent interval of renewed burst\nactivity. We have shown that the spin-down age of SGR 1900+14 is consistent\nwith a braking index of ~1 which is appropriate for wind torques and not\nmagnetic dipole radiation. We have shown that a combination of dipole\nradiation, and wind luminosity, coupled with estimated ages and present spin\nparameters, imply that the magnetic field for SGR 1900+14 is less than 6 x\n10^13 G and that the efficiency for conversion of wind luminosity to x-ray\nluminosity is <2%. \n\n"}
{"id": "astro-ph/9911449", "contents": "Title: Galactic morning: the Atacama Large Millimeter Array (ALMA) and the\n  evolution of galaxies Abstract: The importance of the Atacama Large Millimeter Array (ALMA) to the study of\nhigh-redshift dusty gas-rich galaxies is described. ALMA will have dramatically\ngreater sensitivity and angular resolution than existing millimetre(mm) and\nsubmm-wave telescopes. Two key areas are emphasized: i) extremely deep galaxy\nsurveys down to flux densities of about 10 microJy, two orders of magnitude\ndeeper than can be reached using existing telescopes; ii) the study of known\nhigh-redshift galaxies, quasars and gravitational lenses. The sensitivity of\nALMA will allow very faint galaxies to be detected, while its angular resolving\npower avoids the problem of source confusion. Dust continuum emission,\nmolecular rotational line emission and atomic fine-structure line emission will\nall be detected from high-redshift galaxies. Both the spatial structure of\ncontinuum emission and the spatial and velocity structure of line emission will\nbe resolved, revealing the astrophysical processes at work in detail. These\nprograms are very complementary to surveys using the Next Generation Space\nTelescope (NGST) and Planck Surveyor. \n\n"}
{"id": "astro-ph/9912045", "contents": "Title: Fluctuations of Gravitational Wave Noise from Unresolved Extragalactic\n  Sources Abstract: Angular fluctuations of stochastic gravitational wave backgrounds (GWB)\nproduced by extragalactic astrophysical sources are calculated. The angular\nproperties of such backgrounds are determined by the large scale structure of\nUniverse (galaxy clustering). The evolution of star formation rate with\nredshift is taken into account. Fluctuations of the metric strain amplitude\nassociated with such noises at angular scales of about one degree are found to\nbe of order 5-20% slowly growing toward smaller angular scales. This feature\ncan be potentially used to separate astrophysical GWB from cosmological ones in\nfuture experiments. \n\n"}
{"id": "cond-mat/0001355", "contents": "Title: Phase interference of spin tunneling in an arbitrarily directed magnetic\n  field Abstract: We present an exact analytic study on the topological phase interference\neffect in resonant quantum tunneling of the magnetization between degenerate\nexcited levels for biaxial ferromagnets in an arbitrarily directed magnetic\nfield. We show that the topological phase interference effect depends on the\norientation of the field distinctly. The transition from classical to quantum\nbehavior is also discussed. \n\n"}
{"id": "cond-mat/0006174", "contents": "Title: Spin-transport in multi-terminal normal metal - ferromagnet systems with\n  non-collinear magnetizations Abstract: A theory of spin-transport in hybrid normal metal - ferromagnetic electronic\ncircuits is developed, taking into account non-collinear spin-accumulation.\nSpin-transport through resistive elements is described by 4 conductance\nparameters. Microscopic expression for these conductances are derived in terms\nof scattering matrices and explicitly calculated for simple models. The circuit\ntheory is applied to 2-terminal and 3-terminal devices attached to\nferromagnetic reservoirs. \n\n"}
{"id": "cond-mat/0007317", "contents": "Title: Granulated superconductors:from the nonlinear sigma model to the\n  Bose-Hubbard description Abstract: We modify a nonlinear sigma model (NLSM) for the description of a granulated\ndisordered system in the presence of both the Coulomb repulsion and the Cooper\npairing. We show that under certain controlled approximations this model is\nreduced to the Bose-Hubbard (or ``dirty-boson'') model with renormalized\ncoupling constants. We obtain a more general effective action (which is still\nsimpler than the full NLSM action) which can be applied in the region of\nparameters where the reduction to the Bose-Hubbard model is not justified. This\naction may lead to a different picture of the superconductor-insulator\ntransition in 2D systems. \n\n"}
{"id": "cond-mat/0008426", "contents": "Title: Peltier effect induced longitudinal resistivity of ideal 2D\n  electron(hole) gas in strong magnetic field Abstract: We demonstrate that in strong quantum limit the thermoelectric Peltier effect\ncould define the longitudinal resistivity of dissipationless two-dimensional\nelectron(hole) gas. The current results in heating(cooling) at first(second)\nHall bar sample contact due to Peltier effect. At small current the contacts\ntemperatures are different, the temperature gradient is linear on current. The\nvoltage swing downstream the current is proportional to Peltier effect induced\nthermopower. As a result, nonzero longitudinal resistivity is measured in\nexperiment. The above effect could exist in 3D case. \n\n"}
{"id": "cond-mat/0102415", "contents": "Title: Hall Coefficient and electron-electron interaction of 2D electrons in\n  Si-MOSFET's Abstract: Recent experiments in silicon MOSFETs indicate that the Hall coefficient is\nindependent of magnetic field applied at a small angle with respect to the\nplane. Below a scattering between spin-up and spin-down carriers is considered\nto be the main reason for the experimental observation. Comparison of two band\nmodel with experiment provides an upper limit for the electron-electron\nscattering time $\\tau_{ee}$ in the dilute 2D electron system as a function of\nelectron density $n_s$. The time $\\tau_{ee}$ increases gradually with $n_s$,\nbecoming much greater than the transport scattering time $\\tau_p$ for densities\n$n_s>4 \\times 10 ^{11}$ cm$^{-2}$. Strong electron-electron scattering is found\nfor $1.22 \\times 10 ^{11} <n_s<3 \\times 10 ^{11}$ cm$^{-2}$, the region which\nis near to the apparent metal insulator transition. \n\n"}
{"id": "cond-mat/0105081", "contents": "Title: The low-density spin susceptibility and effective mass of mobile\n  electrons in Si inversion layers Abstract: We studied the Shubnikov-de Haas (SdH) oscillations in high-mobility Si-MOS\nsamples over a wide range of carrier densities $n\\simeq (1-50) \\times\n10^{11}$cm$^{-2}$, which includes the vicinity of the apparent metal-insulator\ntransition in two dimensions (2D MIT). Using a novel technique of measuring the\nSdH oscillations in superimposed and independently controlled parallel and\nperpendicular magnetic fields, we determined the spin susceptibility $\\chi^*$,\nthe effective mass $m^*$, and the $g^*$-factor for mobile electrons. These\nquantities increase gradually with decreasing density; near the 2D MIT, we\nobserved enhancement of $\\chi^*$ by a factor of $\\sim 4.7$. \n\n"}
{"id": "cond-mat/0108492", "contents": "Title: Vortex phases in mesoscopic cylinders with suppressed surface\n  superconductivity Abstract: Vortex structures in mesoscopic cylinder placed in external magnetic field\nare studied under the general de Gennes boundary condition for the order\nparameter corresponding to the suppression of surface superconductivity. The\nGinzburg-Landau equations are solved based on trial functions for the order\nparameter for vortex-free, single-vortex, multivortex, and giant vortex phases.\nThe equilibrium vortex diagrams in the plane of external field and cylinder\nradius and magnetization curves are calculated at different values of de Gennes\n\"extrapolation length\" characterizing the boundary condition for the order\nparameter. The comparison of the obtained variational results with some\navailable exact solutions shows good accuracy of our approach. \n\n"}
{"id": "cond-mat/0112012", "contents": "Title: Kondo and anti-Kondo resonances in transport through nanoscale devices Abstract: We study the current through a quantum wire side coupled to a quantum dot,\nand compare it with the case of an embedded dot. The system is modeled by the\nAnderson Hamiltonian for a linear chain, with one atom either coupled to\n(side-dot) or substituted by (embedded dot) a magnetic impurity. For realistic\n(small) hopping of the dot to the rest of the system, an exact relationship\nbetween both conductivities holds. We calculate the temperature dependence for\nmoderate values of the Coulomb repulsion U using an interpolative perturbative\nscheme. For sufficiently large U and temperature greater than the Kondo\ntemperature, the conductance as a function of gate voltage displays two\nextrema. \n\n"}
{"id": "cond-mat/0210444", "contents": "Title: Energy level statistics in weakly disordered systems: from quantum to\n  diffusive regime Abstract: We calculate two-point energy level correlation function in weakly disorderd\nmetallic grain with taking account of localization corrections to the universal\nrandom matrix result. Using supersymmetric nonlinear sigma model and exactly\nintegrating out spatially homogeneous modes, we derive the expression valid for\narbitrary energy differences from quantum to diffusive regime for the system\nwith broken time reversal symmetry. Our result coincides with the one obtained\nby Andreev and Altshuler [Phys. Rev. Lett. 72, 902 (1995)] where homogeneous\nmodes are perturbatively treated. \n\n"}
{"id": "cond-mat/0212049", "contents": "Title: Tunneling measurement of quantum spin oscillations Abstract: We consider the problem of tunneling between two leads via a localized spin\n1/2 or any other microscopic system which can be modeled by a two-level\nHamiltonian. We assume that a constant magnetic field ${\\bf B}_0$ acts on the\nspin, that electrons in the leads are in the thermal equilibrium and that the\ntunneling electrons are coupled to the spin through exchange and spin-orbit\ninteractions. Using the non-equilibrium Keldysh formalism we find the\ndependence of the spin-spin and current-current correlation functions on the\napplied voltage between leads $V$, temperature $T$, ${\\bf B}_0$, and on the\ndegree and orientation ${\\bf m}_{\\alpha}$ of spin polarization of the electrons\nin the right ($\\alpha=$R) and left ($\\alpha=$L) leads. We compare our results\nof a full quantum-mechanical treatment of the tunneling-via-spin model with\nthose previously obtained in the quasi-classical approach, and discuss the\nexperimental results observed using STM dynamic probes of the localized spin. \n\n"}
{"id": "cond-mat/0302132", "contents": "Title: Phonon effects in molecular transistors Abstract: A rate equation formalism is used to determine the effect of electron-phonon\ncoupling on the conductance of a molecule. Interplay between the phonon-induced\nrenormalization of the density of states on the quantum dot and the\nphonon-induced renormalization of the dot-lead coupling is found to be\nimportant. Whether or not the phonons are able to equilibrate in a time rapid\ncompared to the transit time of an electron through the dot is found to affect\nthe conductance. Observable signatures of phonon equilibration are presented. \n\n"}
{"id": "cond-mat/0303630", "contents": "Title: Molecular conduction: paradigms and possibilities Abstract: We discuss the factors that determine the overall shape and magnitude of the\ncurrent-voltage (I-V) characteristics of a variety of molecular conductors\nsandwiched between two metallic contacts. We analyze the individual influences\nof the contact geometry, the molecular chemistry, the electrostatics of the\nenvironment, and charging on molecular conduction. Current conduction depends\nsensitively on the experimental geometry, as well as on the theoretical model\nfor the molecule and the contacts. Computing molecular I-V characteristics will\nthus require theoretical understanding on several fronts, in particular, (a) in\nthe scheme for calculating the molecular energy levels, as well as (b) on the\nposition of the contact Fermi energy relative to those levels. \n\n"}
{"id": "cond-mat/0305467", "contents": "Title: Theoretical analysis of continuously driven dissipative solid-state\n  qubits Abstract: We study a realistic model for driven qubits using the numerical solution of\nthe Bloch-Redfield equation as well as analytical approximations using a\nhigh-frequency scheme. Unlike in idealized rotating-wave models suitable for\nNMR or quantum optics, we study a driving term which neither is orthogonal to\nthe static term nor leaves the adiabatic energy value constant. We investigate\nthe underlying dynamics and analyze the spectroscopy peaks obtained in recent\nexperiments. We show, that unlike in the rotating-wave case, this system\nexhibits nonlinear driving effects.We study the width of spectroscopy peaks and\nshow, how a full analysis of the parameters of the system can be performed by\ncomparing the first and second resonance. We outline the limitations of the NMR\nlinewidth formula at low temperature and show, that spectrocopic peaks\nexperience a strong shift which goes much beyond the Bloch-Siegert shift of the\nEigenfrequency. \n\n"}
{"id": "cond-mat/0306001", "contents": "Title: Mesoscopic effects in adiabatic spin pumping Abstract: We show that temporal shape modulations (pumping) of a quantum dot in the\npresence of spin-orbital coupling lead to a finite dc spin current. Depending\non the strength of the spin-orbit coupling, the spin current is polarized\nperpendicular to the plane of the two-dimensional electron gas, or has an\narbitrary direction subject to mesoscopic fluctuations. We analyze the\nstatistics of the spin and charge currents in the adiabatic limit for the full\ncross-over from weak to strong spin-orbit coupling. \n\n"}
{"id": "cond-mat/0401229", "contents": "Title: On the Evolution of Time Horizons in Parallel and Grid Simulations Abstract: We analyze the evolution of the local simulation times (LST) in Parallel\nDiscrete Event Simulations. The new ingredients introduced are i) we associate\nthe LST with the nodes and not with the processing elements, and 2) we propose\nto minimize the exchange of information between different processing elements\nby freezing the LST on the boundaries between processing elements for some time\nof processing and then releasing them by a wide-stream memory exchange between\nprocessing elements. Highlights of our approach are i) it keeps the highest\nlevel of processor time utilization during the algorithm evolution, ii) it\ntakes a reasonable time for the memory exchange excluding the time-consuming\nand complicated process of message exchange between processors, and iii) the\ncommunication between processors is decoupled from the calculations performed\non a processor. The effectiveness of our algorithm grows with the number of\nnodes (or threads). This algorithm should be applicable for any parallel\nsimulation with short-range interactions, including parallel or grid\nsimulations of partial differential equations. \n\n"}
{"id": "cond-mat/0404366", "contents": "Title: Transport spectroscopy of Kondo quantum dots coupled by RKKY interaction Abstract: We develop the theory of conductance of a quantum dot which carries a spin\nand is coupled via RKKY interaction to another spin-carrying quantum dot. The\nfound dependence of the differential conductance on bias and magnetic field at\nfixed RKKY interaction strength may allow one to distinguish between the\npossible ground states of the system. Transitions between the ground states are\nachieved by tuning the RKKY interaction, and the nature of these transitions\ncan be extracted from the temperature dependence of the linear conductance. The\nfeasibility of the corresponding measurements is evidenced by recent\nexperiments by Craig et al. [cond-mat/0404213]. \n\n"}
{"id": "cond-mat/0407415", "contents": "Title: Generalized constraints on quantum amplification Abstract: We derive quantum constraints on the minimal amount of noise added in linear\namplification involving input or output signals whose component operators do\nnot necessarily have c-number commutators, as is the case for fermion currents.\nThis is a generalization of constraints derived for the amplification of\nbosonic fields whose components posses c-number commutators. \n\n"}
{"id": "cond-mat/0408679", "contents": "Title: Voltage dependent conductance and shot noise in quantum\n  microconstriction with single defects Abstract: The influence of the interference of electron waves, which are scattered by\nsingle impurities and by a barrier on nonlinear conductance and shot noise of\nmetallic microconstriction is studied theoretically. It is shown that the these\ncharacteristics are nonmonotonic functions on the applied bias. \n\n"}
{"id": "cond-mat/0410714", "contents": "Title: Spin-orbit-driven coherent oscillations in a few-electron quantum dot Abstract: We propose an experiment to observe coherent oscillations in a single quantum\ndot with the oscillations driven by spin-orbit interaction. This is achieved\nwithout spin-polarised leads, and relies on changing the strength of the\nspin-orbit coupling via an applied gate pulse. We derive an effective model of\nthis system which is formally equivalent to the Jaynes-Cummings model of\nquantum optics. For parameters relevant to a InGaAs dot, we calculate a Rabi\nfrequency of 2 GHz. \n\n"}
{"id": "cond-mat/0410775", "contents": "Title: How many electrons are needed to flip a local spin? Abstract: Considering the spin of a local magnetic atom as a quantum mechanical\noperator, we illustrate the dynamics of a local spin interacting with a\nballistic electron represented by a wave packet. This approach improves the\nsemi-classical approximation and provides a complete quantum mechanical\nunderstanding for spin transfer phenomena. Sending spin-polarized electrons\ntowards a local magnetic atom one after another, we estimate the minimum number\nof electrons needed to flip a local spin. \n\n"}
{"id": "cond-mat/0504121", "contents": "Title: Coherent transport in homojunction between excitonic insulator and\n  semimetal Abstract: From the solution of a two-band model, we predict that the thermal and\nelectrical transport across the junction of a semimetal and an excitonic\ninsulator will exhibit high resistance behavior and low entropy production at\nlow temperatures, distinct from a junction of a semimetal and a normal\nsemiconductor. This phenomenon, ascribed to the dissipationless exciton flow\nwhich dominates over the charge transport, is based on the much longer length\nscale of the change of the effective interface potential for electron\nscattering due to the coherence of the condensate than in the normal state. \n\n"}
{"id": "cond-mat/0509102", "contents": "Title: k-core organization of complex networks Abstract: We analytically describe the architecture of randomly damaged uncorrelated\nnetworks as a set of successively enclosed substructures -- k-cores. The k-core\nis the largest subgraph where vertices have at least k interconnections. We\nfind the structure of k-cores, their sizes, and their birth points -- the\nbootstrap percolation thresholds. We show that in networks with a finite mean\nnumber z_2 of the second-nearest neighbors, the emergence of a k-core is a\nhybrid phase transition. In contrast, if z_2 diverges, the networks contain an\ninfinite sequence of k-cores which are ultra-robust against random damage. \n\n"}
{"id": "cond-mat/0601274", "contents": "Title: Spectroscopy of the Kondo Problem in a Box Abstract: Motivated by experiments on double quantum dots, we study the problem of a\nsingle magnetic impurity confined in a finite metallic host. We prove an exact\ntheorem for the ground state spin, and use analytic and numerical arguments to\nmap out the spin structure of the excitation spectrum of the many-body\nKondo-correlated state, throughout the weak to strong coupling crossover. These\nexcitations can be probed in a simple tunneling-spectroscopy transport\nexperiment; for that situation we solve rate equations for the conductance. \n\n"}
{"id": "cond-mat/0604310", "contents": "Title: Threshold Current of Domain Wall Motion under Extrinsic Pinning,\n  $\\beta$-Term and Non-Adiabaticity Abstract: Threshold current of domain wall motion under spin-polarized electric current\nin ferromagnets is theoretically studied based on the equation of motion of a\nwall in terms of collective coordinates. Effects of non-adiabaticity and a\nso-called $\\beta$-term in Landau-Lifshitz equation, which are described by the\nsame term in the equation of motion of a wall, are taken into account as well\nas extrinsic pinning. It is demonstrated that there are four different regimes\ncharacterized by different dependence of threshold on extrinsic pinning,\nhard-axis magnetic anisotropy, non-adiabaticity and $\\beta$. \n\n"}
{"id": "cond-mat/0607036", "contents": "Title: On-chip detection of ferromagnetic resonance of a single submicron\n  permalloy strip Abstract: We measured ferromagnetic resonance of a single submicron ferromagnetic\nstrip, embedded in an on-chip microwave transmission line device. The method\nused is based on detection of the oscillating magnetic flux due to the\nmagnetization dynamics, with an inductive pick-up loop. The dependence of the\nresonance frequency on applied static magnetic field agrees very well with the\nKittel formula, demonstrating that the uniform magnetization precession mode is\nbeing driven. \n\n"}
{"id": "cond-mat/0607255", "contents": "Title: Quantum criticality in a double quantum-dot system Abstract: We discuss the realization of the quantum-critical non-Fermi liquid state,\noriginally discovered within the two-impurity Kondo model, in double\nquantum-dot systems. Contrary to the common belief, the corresponding fixed\npoint is robust against particle-hole and various other asymmetries, and is\nonly unstable to charge transfer between the two dots. We propose an\nexperimental set-up where such charge transfer processes are suppressed,\nallowing a controlled approach to the quantum critical state. We also discuss\ntransport and scaling properties in the vicinity of the critical point. \n\n"}
{"id": "cond-mat/0610795", "contents": "Title: Photon emission as a source of coherent behaviour of polaritons Abstract: We show that the combined effect of photon emission and Coulomb interactions\nmay drive an exciton-polariton system towards a dynamical coherent state, even\nwithout phonon thermalization or any other relaxation mechanism. Exact\ndiagonalization results for a finite system (a multilevel quantum dot\ninteracting with the lowest energy photon mode of a microcavity) are presented\nin support to this statement. \n\n"}
{"id": "cond-mat/0611518", "contents": "Title: Electron-Acoustic Phonon Energy Loss Rate in Multi-Component Electron\n  Systems with Symmetric and Asymmetric Coupling Constants Abstract: We consider electron-phonon (\\textit{e-ph}) energy loss rate in 3D and 2D\nmulti-component electron systems in semiconductors. We allow general asymmetry\nin the \\textit{e-ph} coupling constants (matrix elements), i.e., we allow that\nthe coupling depends on the electron sub-system index. We derive a\nmulti-component \\textit{e-ph}power loss formula, which takes into account the\nasymmetric coupling and links the total \\textit{e-ph} energy loss rate to the\ndensity response matrix of the total electron system. We write the density\nresponse matrix within mean field approximation, which leads to coexistence of\\\nsymmetric energy loss rate $F_{S}(T)$ and asymmetric energy loss rate\n$F_{A}(T)$ with total energy loss rate $ F(T)=F_{S}(T)+F_{A}(T)$ at temperature\n$T$. The symmetric component F_{S}(T) $ is equivalent to the conventional\nsingle-sub-system energy loss rate in the literature, and in the\nBloch-Gr\\\"{u}neisen limit we reproduce a set of well-known power laws\n$F_{S}(T)\\propto T^{n_{S}}$, where the prefactor and power $n_{S}$ depend on\nelectron system dimensionality and electron mean free path. For $F_{A}(T)$ we\nproduce a new set of power laws F_{A}(T)\\propto T^{n_{A}}$. Screening strongly\nreduces the symmetric coupling, but the asymmetric coupling is unscreened,\nprovided that the inter-sub-system Coulomb interactions are strong. The lack of\nscreening enhances $F_{A}(T)$ and the total energy loss rate $F(T)$.\nEspecially, in the strong screening limit we find $F_{A}(T)\\gg F_{S}(T)$. A\ncanonical example of strongly asymmetric \\textit{e-ph} matrix elements is the\ndeformation potential coupling in many-valley semiconductors. \n\n"}
{"id": "cond-mat/0612461", "contents": "Title: Theory of parametric amplification in in superlattices Abstract: We consider a high-frequency response of electrons in a single miniband of\nsuperlattice subject to dc and ac electric fields. We show that Bragg\nreflections in miniband result in a parametric resonance which is detectable\nusing ac probe field. We establish theoretical feasibility of phase-sensitive\nTHz amplification at the resonance. The parametric amplification does not\nrequire operation in conditions of negative differential conductance. This\nprevents a formation of destructive high-field domains inside the superlattice. \n\n"}
{"id": "cond-mat/9705079", "contents": "Title: Derivative relation for thermopower in the quantum Hall regime Abstract: Recently, Tieke et al (to be published in PRL) have observed the relation\nS_{yx} = alpha B dS_{xx}/dB for the components of the thermopower tensor in the\nquantum Hall regime, where alpha is a constant and B is the magnetic field.\nSimon and Halperin (PRL 73, 3278 (1994)) have suggested that an analogous\nrelation observed for the resistivity tensor R_{xx} = \\alpha B dR_{xy}/dB can\nbe explained with a model of classical transport in an inhomogeneous medium\nwhere the local Hall resistivity is a function of position and the local\ndissipative resistivity is a small constant. In the present paper, we show that\nthis new thermopower relation can be explained with a similar model. \n\n"}
{"id": "cond-mat/9712274", "contents": "Title: Exact Analytic Results for Composite Fermions in a Rajaraman-Sondhi like\n  formulation Abstract: We obtain the exact spectrum and the unique ground state of two composite\nfermions (in a Rajaraman - Sondhi like formulation) in an external magnetic\nfield $B$. We show that the energy eigenvalues decrease with increasing angular\nmomentum, thus making it energetically favourable for composite fermions to\nstay apart. Generalising this result to a gas of composite fermions, we provide\nan energetic justification of the Laughlin and Jain wave-functions. \n\n"}
{"id": "cond-mat/9802159", "contents": "Title: Mesoscopic charge fluctuations in the Coulomb blockade regime Abstract: We study mesoscopic fluctuations of the differential capacitance of a dot\nconnected to a lead by a single-mode quantum channel with adjustable\nconductance G. We show that the amplitude of the fluctuations reaches maximum\nat a partially opened channel, G\\lesssim e^2/\\pi\\hbar. Parametric correlations\nof fluctuations at different values of the applied voltage and magnetic field\ncan be studied experimentally, and we find the corresponding correlation\nfunctions for the differential capacitance. \n\n"}
{"id": "cond-mat/9910100", "contents": "Title: Negative Domain Wall Resistance in Ferromagnets Abstract: The electrical resistance of a diffusive ferromagnet with magnetic domain\nwalls is studied theoretically, taking into account the spatial dependence of\nthe magnetization. The semiclassical domain wall resistance is found to be\neither negative or positive depending on the difference between the\nspin-dependent scattering life-times. The predictions can be tested\nexperimentally by transport studies in doped ferromagnets. \n\n"}
{"id": "cond-mat/9912218", "contents": "Title: Conformal field theory and edge excitations for the principal series of\n  quantum Hall fluids Abstract: Motivated by recent experimental results, we reconsider the theory of the\nedge excitations for the fractional Hall effect at filling factors\n$\\nu=p/(2np+1)$. We propose to modify the standard $u(1)\\otimes su(p)$ edge\ntheory for this series by introducing twist fields which change the boundary\nconditions of the bosonic fields and simulate the effect of fractions of flux\nquanta $\\phi_0/p$. This has the effect of removing the conserved charges\nassociated to the neutral modes while keeping the right statistics of the\nparticles. The Green function of the electron in presence of twists decays at\nlong distance with an exponent varying continuously with $\\nu$. \n\n"}
{"id": "cs/0202008", "contents": "Title: CUP: Controlled Update Propagation in Peer-to-Peer Networks Abstract: Recently the problem of indexing and locating content in peer-to-peer\nnetworks has received much attention. Previous work suggests caching index\nentries at intermediate nodes that lie on the paths taken by search queries,\nbut until now there has been little focus on how to maintain these intermediate\ncaches. This paper proposes CUP, a new comprehensive architecture for\nControlled Update Propagation in peer-to-peer networks. CUP asynchronously\nbuilds caches of index entries while answering search queries. It then\npropagates updates of index entries to maintain these caches. Under unfavorable\nconditions, when compared with standard caching based on expiration times, CUP\nreduces the average miss latency by as much as a factor of three. Under\nfavorable conditions, CUP can reduce the average miss latency by more than a\nfactor of ten.\n  CUP refreshes intermediate caches, reduces query latency, and reduces network\nload by coalescing bursts of queries for the same item. CUP controls and\nconfines propagation to updates whose cost is likely to be recovered by\nsubsequent queries. CUP gives peer-to-peer nodes the flexibility to use their\nown incentive-based policies to determine when to receive and when to propagate\nupdates. Finally, the small propagation overhead incurred by CUP is more than\ncompensated for by its savings in cache misses. \n\n"}
{"id": "cs/0209023", "contents": "Title: Practical Load Balancing for Content Requests in Peer-to-Peer Networks Abstract: This paper studies the problem of load-balancing the demand for content in a\npeer-to-peer network across heterogeneous peer nodes that hold replicas of the\ncontent. Previous decentralized load balancing techniques in distributed\nsystems base their decisions on periodic updates containing information about\nload or available capacity observed at the serving entities. We show that these\ntechniques do not work well in the peer-to-peer context; either they do not\naddress peer node heterogeneity, or they suffer from significant load\noscillations. We propose a new decentralized algorithm, Max-Cap, based on the\nmaximum inherent capacities of the replica nodes and show that unlike previous\nalgorithms, it is not tied to the timeliness or frequency of updates. Yet,\nMax-Cap can handle the heterogeneity of a peer-to-peer environment without\nsuffering from load oscillations. \n\n"}
{"id": "cs/0303031", "contents": "Title: A Bird's eye view of Matrix Distributed Processing Abstract: We present Matrix Distributed Processing, a C++ library for fast development\nof efficient parallel algorithms. MDP is based on MPI and consists of a\ncollection of C++ classes and functions such as lattice, site and field. Once\nan algorithm is written using these components the algorithm is automatically\nparallel and no explicit call to communication functions is required. MDP is\nparticularly suitable for implementing parallel solvers for multi-dimensional\ndifferential equations and mesh-like problems. \n\n"}
{"id": "cs/0306055", "contents": "Title: BlueOx: A Java Framework for Distributed Data Analysis Abstract: High energy physics experiments including those at the Tevatron and the\nupcoming LHC require analysis of large data sets which are best handled by\ndistributed computation. We present the design and development of a distributed\ndata analysis framework based on Java. Analysis jobs run through three phases:\ndiscovery of data sets available, brokering/assignment of data sets to analysis\nservers, and job execution. Each phase is represented by a set of abstract\ninterfaces. These interfaces allow different techniques to be used without\nmodification to the framework. For example, the communications interface has\nbeen implemented by both a packet protocol and a SOAP-based scheme. User\nauthentication can be provided either through simple passwords or through a GSI\ncertificates system. Data from CMS HCAL Testbeams, the L3 LEP experiment, and a\nhypothetical high-energy linear collider experiment have been interfaced with\nthe framework. \n\n"}
{"id": "cs/0309049", "contents": "Title: Control and Debugging of Distributed Programs Using Fiddle Abstract: The main goal of Fiddle, a distributed debugging engine, is to provide a\nflexible platform for developing debugging tools. Fiddle provides a layered set\nof interfaces with a minimal set of debugging functionalities, for the\ninspection and control of distributed and multi-threaded applications.\n  This paper illustrates how Fiddle is used to support integrated testing and\ndebugging. The approach described is based on a tool, called Deipa, that\ninterprets sequences of commands read from an input file, generated by an\nindependent testing tool. Deipa acts as a Fiddle client, in order to enforce\nspecific execution paths in a distributed PVM program. Other Fiddle clients may\nbe used along with Deipa for the fine debugging at process level. Fiddle and\nDeipa functionalities and architectures are described, and a working example\nshows a step-by-step application of these tools. \n\n"}
{"id": "cs/0407066", "contents": "Title: ParFORM: Parallel Version of the Symbolic Manipulation Program FORM Abstract: After an introduction to the sequential version of FORM and the mechanisms\nbehind, we report on the status of our project of parallelization. We have now\na parallel version of FORM running on Cluster- and SMP-architectures. This\nversion can be used to run arbitrary FORM programs in parallel. \n\n"}
{"id": "cs/0411050", "contents": "Title: Utilizing Reconfigurable Hardware Processors via Grid Services Abstract: Computational grids typically consist of nodes utilizing ordinary processors\nsuch as the Intel Pentium. Field Programmable Gate Arrays (FPGAs) are able to\nperform certain compute-intensive tasks very well due to their inherent\nparallel architecture, often resulting in orders of magnitude speedups. This\npaper explores how FPGAs can be transparently exposed for remote use via grid\nservices, by integrating the Proteus Software Platform with the Globus Toolkit\n3.0. \n\n"}
{"id": "cs/0501021", "contents": "Title: Large-scale lattice Boltzmann simulations of complex fluids: advances\n  through the advent of computational grids Abstract: During the last two years the RealityGrid project has allowed us to be one of\nthe few scientific groups involved in the development of computational grids.\nSince smoothly working production grids are not yet available, we have been\nable to substantially influence the direction of software development and grid\ndeployment within the project. In this paper we review our results from large\nscale three-dimensional lattice Boltzmann simulations performed over the last\ntwo years. We describe how the proactive use of computational steering and\nadvanced job migration and visualization techniques enabled us to do our\nscientific work more efficiently. The projects reported on in this paper are\nstudies of complex fluid flows under shear or in porous media, as well as\nlarge-scale parameter searches, and studies of the self-organisation of liquid\ncubic mesophases.\n  Movies are available at\nhttp://www.ica1.uni-stuttgart.de/~jens/pub/05/05-PhilTransReview.html \n\n"}
{"id": "cs/0511007", "contents": "Title: K-core decomposition of Internet graphs: hierarchies, self-similarity\n  and measurement biases Abstract: We consider the $k$-core decomposition of network models and Internet graphs\nat the autonomous system (AS) level. The $k$-core analysis allows to\ncharacterize networks beyond the degree distribution and uncover structural\nproperties and hierarchies due to the specific architecture of the system. We\ncompare the $k$-core structure obtained for AS graphs with those of several\nnetwork models and discuss the differences and similarities with the real\nInternet architecture. The presence of biases and the incompleteness of the\nreal maps are discussed and their effect on the $k$-core analysis is assessed\nwith numerical experiments simulating biased exploration on a wide range of\nnetwork models. We find that the $k$-core analysis provides an interesting\ncharacterization of the fluctuations and incompleteness of maps as well as\ninformation helping to discriminate the original underlying structure. \n\n"}
{"id": "cs/0601082", "contents": "Title: Search in Complex Networks : a New Method of Naming Abstract: We suggest a method for routing when the source does not posses full\ninformation about the shortest path to the destination. The method is\nparticularly useful for scale-free networks, and exploits its unique\ncharacteristics. By assigning new (short) names to nodes (aka labelling) we are\nable to reduce significantly the memory requirement at the routers, yet we\nsucceed in routing with high probability through paths very close in distance\nto the shortest ones. \n\n"}
{"id": "cs/0606060", "contents": "Title: Complex Networks: New Concepts and Tools for Real-Time Imaging and\n  Vision Abstract: This article discusses how concepts and methods of complex networks can be\napplied to real-time imaging and computer vision. After a brief introduction of\ncomplex networks basic concepts, their use as means to represent and\ncharacterize images, as well as for modeling visual saliency, are briefly\ndescribed. The possibility to apply complex networks in order to model and\nsimulate the performance of parallel and distributed computing systems for\nperformance of visual methods is also proposed. \n\n"}
{"id": "cs/0607080", "contents": "Title: New Model of Internet Topology Using k-shell Decomposition Abstract: We introduce and use k-shell decomposition to investigate the topology of the\nInternet at the AS level. Our analysis separates the Internet into three\nsub-components: (a) a nucleus which is a small (~100 nodes) very well connected\nglobally distributed subgraph; (b) a fractal sub-component that is able to\nconnect the bulk of the Internet without congesting the nucleus, with self\nsimilar properties and critical exponents; and (c) dendrite-like structures,\nusually isolated nodes that are connected to the rest of the network through\nthe nucleus only. This unique decomposition is robust, and provides insight\ninto the underlying structure of the Internet and its functional consequences.\nOur approach is general and useful also when studying other complex networks. \n\n"}
{"id": "cs/0611128", "contents": "Title: Scale-Free Overlay Topologies with Hard Cutoffs for Unstructured\n  Peer-to-Peer Networks Abstract: In unstructured peer-to-peer (P2P) networks, the overlay topology (or\nconnectivity graph) among peers is a crucial component in addition to the\npeer/data organization and search. Topological characteristics have profound\nimpact on the efficiency of search on such unstructured P2P networks as well as\nother networks. It has been well-known that search on small-world topologies of\nN nodes can be as efficient as O(ln N), while scale-free (power-law) topologies\noffer even better search efficiencies like as good as O(lnln N) for a range of\ndegree distribution exponents. However, generation and maintenance of such\nscale-free topologies are hard to realize in a distributed and potentially\nuncooperative environments as in the P2P networks. A key limitation of\nscale-free topologies is the high load (i.e. high degree) on very few number of\nhub nodes. In a typical unstructured P2P network, peers are not willing to\nmaintain high degrees/loads as they may not want to store large number of\nentries for construction of the overlay topology. So, to achieve fairness and\npracticality among all peers, hard cutoffs on the number of entries are imposed\nby the individual peers, which limits scale-freeness of the overall topology.\nThus, efficiency of the flooding search reduces as the size of the hard cutoff\ndoes. We investigate construction of scale-free topologies with hard cutoffs\n(i.e. there are not any major hubs) and effect of these hard cutoffs on the\nsearch efficiency. Interestingly, we observe that the efficiency of normalized\nflooding and random walk search algorithms increases as the hard cutoff\ndecreases. \n\n"}
{"id": "gr-qc/0109084", "contents": "Title: Magnetic Brane-worlds Abstract: We investigate brane-worlds with a pure magnetic field and a perfect fluid.\nWe extend earlier work to brane-worlds, and find new properties of the Bianchi\ntype I brane-world. We find new asymptotic behaviours on approach to the\nsingularity and classify the critical points of the dynamical phase space. It\nis known that the Einstein equations for the magnetic Bianchi type I models are\nin general oscillatory and are believed to be chaotic, but in the brane-world\nmodel this chaotic behaviour does not seem to be possible. \n\n"}
{"id": "gr-qc/0307112", "contents": "Title: The Emergent Universe: An Explicit Construction Abstract: We provide a realisation of a singularity-free inflationary universe in the\nform of a simple cosmological model dominated at early times by a single\nminimally coupled scalar field with a physically based potential. The universe\nstarts asymptotically from an initial Einstein static state, which may be large\nenough to avoid the quantum gravity regime. It enters an expanding phase that\nleads to inflation followed by reheating and a standard hot Big Bang evolution.\nWe discuss the basic characteristics of this Emergent model and show that none\nis at odds with current observations. \n\n"}
{"id": "gr-qc/0410027", "contents": "Title: Patch dualities and remarks on nonstandard cosmologies Abstract: In this paper we establish dualities between inflationary, cyclic/ekpyrotic,\nand phantom cosmologies within the patch formalism approximating high-energy\neffects in scenarios with extra dimensions. The exact dualities relating the\nfour-dimensional spectra are broken in favour of their braneworld counterparts;\nthe dual solutions display new interesting features because of the modification\nof the effective Friedmann equation on the brane. We then address some\nqualitative issues about phantomlike cosmologies without phantom matter. \n\n"}
{"id": "gr-qc/0411104", "contents": "Title: Modelling the rotational curves of spiral galaxies with a scalar field Abstract: In a previous work (Mbelek 2001), we modelled the rotation curves (RC) of\nspiral galaxies by including in the equation of motion of the stars the\ndynamical terms from an external real self-interacting scalar field, $\\psi$,\nminimally coupled to gravity and which respects the equivalence principle in\nthe weak fields and low velocity approximation. This model appeared to have\nthree free parameters : the turnover radius, $r_{0}$, the maximum tangential\nvelocity, $v_{\\theta max} = v_{\\theta}(r_{0})$, plus a strictly positive\ninteger, $n$. Here, we propose a new improved version where the coupling of the\n$\\psi$-field to dark matter is emphasized at the expense of its\nself-interaction. This reformulation presents the very advantageous possibility\nthat the same potential is used for all galaxies. Using at the same time a\nquasi-isothermal dark matter density and the scalar field helps to better fit\nthe RC of spiral galaxies. In addition, new correlations are established. \n\n"}
{"id": "gr-qc/0510057", "contents": "Title: Mapping spacetimes with LISA: inspiral of a test-body in a `quasi-Kerr'\n  field Abstract: The future LISA detector will constitute the prime instrument for\nhigh-precision gravitational wave observations.LISA is expected to provide\ninformation for the properties of spacetime in the vicinity of massive black\nholes which reside in galactic nuclei.Such black holes can capture stellar-mass\ncompact objects, which afterwards slowly inspiral,radiating gravitational\nwaves.The body's orbital motion and the associated waveform carry information\nabout the spacetime metric of the massive black hole,and it is possible to\nextract this information and experimentally identify (or not!) a Kerr black\nhole.In this paper we lay the foundations for a practical `spacetime-mapping'\nframework. Our work is based on the assumption that the massive body is not\nnecessarily a Kerr black hole, and that the vacuum exterior spacetime is\nstationary axisymmetric,described by a metric which deviates slightly from the\nKerr metric. We first provide a simple recipe for building such a `quasi-Kerr'\nmetric by adding to the Kerr metric the deviation in the value of the\nquadrupole moment. We then study geodesic motion in this metric,focusing on\nequatorial orbits. We proceed by computing `kludge' waveforms which we compare\nwith their Kerr counterparts. We find that a modest deviation from the Kerr\nmetric is sufficient for producing a significant mismatch between the\nwaveforms, provided we fix the orbital parameters. This result suggests that an\nattempt to use Kerr waveform templates for studying EMRIs around a non-Kerr\nobject might result in serious loss of signal-to-noise ratio and total number\nof detected events. The waveform comparisons also unveil a `confusion' problem,\nthat is the possibility of matching a true non-Kerr waveform with a Kerr\ntemplate of different orbital parameters. \n\n"}
{"id": "gr-qc/0703028", "contents": "Title: Towards adiabatic waveforms for inspiral into Kerr black holes: I. A new\n  model of the source for the time domain perturbation equation Abstract: We revisit the problem of the emission of gravitational waves from a test\nmass orbiting and thus perturbing a Kerr black hole. The source term of the\nTeukolsky perturbation equation contains a Dirac delta function which\nrepresents a point particle. We present a technique to effectively model the\ndelta function and its derivatives using as few as four points on a numerical\ngrid. The source term is then incorporated into a code that evolves the\nTeukolsky equation in the time domain as a (2+1) dimensional PDE. The waveforms\nand energy fluxes are extracted far from the black hole. Our comparisons with\nearlier work show an order of magnitude gain in performance (speed) and\nnumerical errors less than 1% for a large fraction of parameter space. As a\nfirst application of this code, we analyze the effect of finite extraction\nradius on the energy fluxes. This paper is the first in a series whose goal is\nto develop adiabatic waveforms describing the inspiral of a small compact body\ninto a massive Kerr black hole. \n\n"}
{"id": "gr-qc/9807077", "contents": "Title: Gravitational radiation from Schwarzschild black holes: the second order\n  perturbation formalism Abstract: The perturbation theory of black holes has been useful recently for providing\nestimates of gravitational radiation from black hole collisions. Second order\nperturbation theory, relatively undeveloped until recently, has proved to be\nimportant both for providing refined estimates and for indicating the range of\nvalidity of perturbation theory. Here we present the second order formalism for\nperturbations of Schwarzschild spacetimes. The emphasis is on practical methods\nfor carrying out second order computations of outgoing radiation. General\nissues are illustrated throughout with examples from ``close-limit'' results,\nperturbation calculations in which black holes start from small separation. \n\n"}
{"id": "hep-lat/0308005", "contents": "Title: Parallel implementation of a lattice-gauge-theory code: studying quark\n  confinement on PC clusters Abstract: We consider the implementation of a parallel Monte Carlo code for\nhigh-performance simulations on PC clusters with MPI. We carry out tests of\nspeedup and efficiency. The code is used for numerical simulations of pure\nSU(2) lattice gauge theory at very large lattice volumes, in order to study the\ninfrared behavior of gluon and ghost propagators. This problem is directly\nrelated to the confinement of quarks and gluons in the physics of strong\ninteractions. \n\n"}
{"id": "hep-ph/0006015", "contents": "Title: Technique for Direct eV-Scale Measurements of the Mu and Tau Neutrino\n  Masses Using Supernova Neutrinos Abstract: Early black hole formation in a core-collapse supernova will abruptly\ntruncate the neutrino fluxes. The sharp cutoff can be used to make\nmodel-independent time-of-flight neutrino mass tests. Assuming a neutrino\nluminosity of $10^{52}$ erg/s per flavor at cutoff and a distance of 10 kpc,\nSuperKamiokande can detect an electron neutrino mass as small as 1.8 eV, and\nthe proposed OMNIS detector can detect mu and tau neutrino masses as small as 6\neV. This {\\it Letter} presents the first technique with direct sensitivity to\neV-scale mu and tau neutrino masses. \n\n"}
{"id": "hep-ph/0110105", "contents": "Title: Earth effects on supernova neutrinos and their implications for neutrino\n  parameters Abstract: We perform a detailed study of the Earth matter effects on supernova\nneutrinos with neutrino oscillation parameter LMA and small $\\theta_{13}$. The\nEarth effects show significant dependences on the neutrino path length inside\nthe Earth and the value of $\\Delta m^{2}_{12}$. We investigate rather\noptimistically a possibility that we can probe the value of $\\Delta m^{2}_{12}$\nby the Earth effects. We assume that $\\theta_{12}$ and the direction of the\nsupernova are known with enough accuracy and that the resonance that occurs at\nhigher density in supernova envelope is completely nonadiabatic. Further the\nneutrino spectra before neutrinos go through the Earth are assumed to be known.\nThen we show that making use of these dependences, we can obtain implication\nfor the value of $\\Delta m^{2}_{12}$ by comparing the observed energy spectrum\nto the predicted one. When SK detects neutrinos from supernova at 10kpc which\ntraveled through the Earth (nadir angle $<$ 80 degree), $\\Delta m^{2}_{12}$ can\nbe determined with an accuracy of $\\sim 10%$. In much of the\nneutrino-detection-time-$\\Delta m^{2}_{12}$ plane, $\\Delta m^{2}_{12}$ might be\ndetermined with an accuracy equal to or better than $\\pm 0.5 \\times 10^{-5}\n{\\rm eV}^{2}$. \n\n"}
{"id": "hep-ph/0301157", "contents": "Title: How to detect the cosmic neutrino background? Abstract: A measurement of the big bang relic neutrinos would open a new window to the\nearly universe. We review various possibilities to detect this cosmic neutrino\nbackground and substantiate the assertion that -- apart from the rather\nindirect evidence to be gained from cosmology and large-scale structure\nformation -- the annihilation of ultrahigh energy cosmic neutrinos with relic\nanti-neutrinos (or vice versa) on the Z-resonance is a unique process having\nsensititivy to the relic neutrinos, if a sufficient flux at E^res_{nu_i} =\nM_Z^2/(2 m_{nu_i}) = 4 x 10^{22} eV (0.1 eV/m_{nu_i}) exists. The associated\nabsorption dips in the ultrahigh energy cosmic neutrino spectrum may be\nsearched for at forthcoming neutrino and air shower detectors. The associated\nprotons and photons may have been seen already in form of the cosmic ray events\nabove the Greisen-Zatsepin-Kuzmin cutoff. \n\n"}
{"id": "hep-ph/0402200", "contents": "Title: D-term Inflation and Nonperturbative Kahler Potential of Dilaton Abstract: We study the $D$-term inflation scenario with a nonperturbative K\\\"ahler\npotential of the dilaton field. Although the FI term which leads an\ninflationary expansion is given by the derivative of the K\\\"ahler potential\nwith respect to the dilaton in heterotic string models with anomalous U(1), the\ntoo large magnitude is problematic for a viable $D$-term inflation. In this\npaper, we point out that the K\\\"ahler potential with a nonperturbative term can\nreduce the magnitude of FI term to desired values while both the dilaton\nstabilization and $D$-term domination in the potential are realized by\nnonperturbative superpotential. \n\n"}
{"id": "hep-ph/0504161", "contents": "Title: Relations between quark and lepton mixing angles and matrices Abstract: We discuss the relations between the mixing angles and the mixing matrices of\nquarks and leptons. With Raidal's numerical relations, we parametrize the\nlepton mixing (PMNS) matrix with the parameters of the quark mixing (CKM)\nmatrix, and calculate the products of $V_{\\mathrm{CKM}}U_{\\mathrm{PMNS}}$ and\n$U_{\\mathrm{PMNS}}V_{\\mathrm{CKM}}$. Also, under the conjectures\n$V_{\\mathrm{CKM}}U_{\\mathrm{PMNS}}=U_{\\mathrm{bimax}}$ or\n$U_{\\mathrm{PMNS}}V_{\\mathrm{CKM}}=U_{\\mathrm{bimax}}$, we get the PMNS matrix\nnaturally, and test Raidal's relations in these two different versions. The\nsimilarities and the differences between the different versions are discussed\nin detail. \n\n"}
{"id": "hep-ph/0608115", "contents": "Title: Effects of Cosmic Strings on Free Streaming Abstract: We study the effect of free streaming in a universe with cosmic strings with\ntime-varying tension as well as with constant tension. Although current\ncosmological observations suggest that fluctuation seeded by cosmic strings\ncannot be the primary source of cosmic density fluctuation, some contributions\nfrom them are still allowed. Since cosmic strings actively produce isocurvature\nfluctuation, the damping of small scale structure via free streaming by dark\nmatter particles with large velocity dispersion at the epoch of\nradiation-matter equality is less efficient than that in models with\nconventional adiabatic fluctuation. We discuss its implications to the\nconstraints on the properties of particles such as massive neutrinos and warm\ndark matter. \n\n"}
{"id": "hep-ph/9902439", "contents": "Title: Nucleosynthesis Constraints on a Scale-Dependent New Intermediate Range\n  Interaction Abstract: We derive constraints on the strength of a new intermediate range interaction\nthat couples to baryon number from primordial nucleosynthesis yields. The\nnucleosysnthesis limits here used arise from matching observations and\npredictions of standard and inhomogeneous primordial scenarios. We show that\nthe standard nucleosynthesis scenario is more restrictive ($\\alpha_5 \\lsim\n0.2$) when the range of the interaction is greater than about 1 m. We further\ndiscuss the implications of considering the scalar particle responsible for the\nnew interaction as the main component of the dark matter in the galactic halo\nsuch that its decay can account for the ionization of hydrogen in the\ninterstellar medium and the temperature of Lyman-$\\alpha$ clouds. \n\n"}
{"id": "hep-th/0201127", "contents": "Title: Strong Brane Gravity and the Radion at Low Energies Abstract: For the 2-brane Randall-Sundrum model, we calculate the bulk geometry for\nstrong gravity, in the low matter density regime, for slowly varying matter\nsources. This is relevant for astrophysical or cosmological applications. The\nwarped compactification means the radion can not be written as a homogeneous\nmode in the orbifold coordinate, and we introduce it by extending the\ncoordinate patch approach of the linear theory to the non-linear case. The\nnegative tension brane is taken to be in vacuum. For conformally invariant\nmatter on the positive tension brane, we solve the bulk geometry as a\nderivative expansion, formally summing the `Kaluza-Klein' contributions to all\norders. For general matter we compute the Einstein equations to leading order,\nfinding a scalar-tensor theory with $\\omega(\\Psi) \\propto \\Psi / (1 - \\Psi)$,\nand geometrically interpret the radion. We comment that this radion scalar may\nbecome large in the context of strong gravity with low density matter.\nEquations of state allowing $(\\rho - 3 P)$ to be negative, can exhibit behavior\nwhere the matter decreases the distance between the 2 branes, which we\nillustrate numerically for static star solutions using an incompressible fluid.\nFor increasing stellar density, the branes become close before the upper mass\nlimit, but after violation of the dominant energy condition. This raises the\ninteresting question of whether astrophysically reasonable matter, and initial\ndata, could cause branes to collide at low energy, such as in dynamical\ncollapse. \n\n"}
{"id": "hep-th/0405241", "contents": "Title: SUSY-Approach for Investigation of Two-Dimensional Quantum Mechanical\n  Systems Abstract: Different ways to incorporate two-dimensional systems, which are not amenable\nto separation of variables, into the framework of Supersymmetrical Quantum\nMechanics (SUSY QM) are analyzed. In particular, the direct generalization of\none-dimensional Witten's SUSY QM is based on the supercharges of first order in\nmomenta and allows to connect the eigenvalues and eigenfunctions of two scalar\nand one matrix Schr\\\"odinger operators. The use of second order supercharges\nleads to polynomial supersymmetry and relates a pair of scalar Hamiltonians,\ngiving a set of such partner systems with almost coinciding spectra. This class\nof systems can be studied by means of new method of $SUSY-$separation of\nvariables, where supercharges {\\bf allow} separation of variables, but\nHamiltonians {\\bf do not}. The method of shape invariance is generalized to\ntwo-dimensional models to construct purely algebraically a chain of eigenstates\nand eigenvalues for generalized Morse potential models in two dimensions. \n\n"}
{"id": "math/0204008", "contents": "Title: Geometric singular perturbation theory for stochastic differential\n  equations Abstract: We consider slow-fast systems of differential equations, in which both the\nslow and fast variables are perturbed by noise. When the deterministic system\nadmits a uniformly asymptotically stable slow manifold, we show that the sample\npaths of the stochastic system are concentrated in a neighbourhood of the slow\nmanifold, which we construct explicitly. Depending on the dynamics of the\nreduced system, the results cover time spans which can be exponentially long in\nthe noise intensity squared (that is, up to Kramers' time). We obtain\nexponentially small upper and lower bounds on the probability of exceptional\npaths. If the slow manifold contains bifurcation points, we show similar\nconcentration properties for the fast variables corresponding to\nnon-bifurcating modes. We also give conditions under which the system can be\napproximated by a lower-dimensional one, in which the fast variables contain\nonly bifurcating modes. \n\n"}
{"id": "math/0312344", "contents": "Title: Nonuniqueness for specifications in $\\ell^{2+\\epsilon}$ Abstract: For every $p>2$, we construct a regular and continuous specification\n($g$-function), which has a variation sequence that is in $l^p$ and which\nadmits multiple Gibbs measures. Combined with a recent result of Johansson and\nOberg, this determines the optimal modulus of continuity for a specification\nwhich admits multiple Gibbs measures. \n\n"}
{"id": "math/0405231", "contents": "Title: Non-Archimedean valued quasi-invariant descending at infinity measures Abstract: The article is devoted to the investigation of particular classes of\nquasi-invariant descending at infinity measures on linear spaces over\nnon-Archimedean fields such that measures are with values in non-Archimedean\nfields also. Their applications to stochastic processes and partial\npseudo-differential equations are given. \n\n"}
{"id": "math/0405458", "contents": "Title: Invariant Percolation and Harmonic Dirichlet Functions Abstract: The main goal of this paper is to answer question 1.10 and settle conjecture\n1.11 of Benjamini-Lyons-Schramm [BLS99] relating harmonic Dirichlet functions\non a graph to those of the infinite clusters in the uniqueness phase of\nBernoulli percolation. We extend the result to more general invariant\npercolations, including the Random-Cluster model. We prove the existence of the\nnonuniqueness phase for the Bernoulli percolation (and make some progress for\nRandom-Cluster model) on unimodular transitive locally finite graphs admitting\nnonconstant harmonic Dirichlet functions. This is done by using the device of\n$\\ell^2$ Betti numbers. \n\n"}
{"id": "math/0504247", "contents": "Title: Coding map for a contractive Markov system Abstract: In this paper, we develop the theory of contractive Markov systems initiated\nin \\cite{Wer1}.\n  We construct a coding map for such systems and investigate some of its\nproperties. \n\n"}
{"id": "math/0505011", "contents": "Title: Exchangeable, Gibbs and equilibrium measures for Markov subshifts Abstract: We study a class of strongly irreducible, multidimensional, topological\nMarkov shifts, comparing two notions of \"symmetric measure\": exchangeability\nand the Gibbs (or conformal) property. We show that equilibrium measures for\nsuch shifts (unique and weak Bernoulli in the one dimensional case) exhibit a\nvariety of spectral properties. \n\n"}
{"id": "math/0508054", "contents": "Title: A necessary condition for the uniqueness of the stationary state of a\n  Markov system Abstract: We continue the study of Markov systems started in \\cite{Wer1}. In this\npaper, we prove a generalization of Breiman's strong low of large numbers\n\\cite{Br} which implies a necessary condition for the uniqueness of the\nstationary state of a Markov system. \n\n"}
{"id": "math/0508533", "contents": "Title: On the cascade rollback synchronization Abstract: We consider a cascade model of $N$ different processors performing a\ndistributed parallel simulation. The main goal of the study is to show that the\nlong-time dynamics of the system has a cluster behavior. To attack this problem\nwe combine two methods: stochastic comparison and Foster-Lyapunov functions. \n\n"}
{"id": "math/0509120", "contents": "Title: Fundamental Markov systems Abstract: We continue development of the theory of Markov systems initiated in\n\\cite{Wer1}. In this paper, we introduce fundamental Markov systems associated\nwith random dynamical systems and show that the proof of the uniqueness and\nempiricalness of the stationary initial distribution of the random dynamical\nsystem reduces to that for the fundamental Markov system associated with it.\nThe stability criteria for the latter are much clearer. \n\n"}
{"id": "math/0510656", "contents": "Title: Lemme de coherence et th\\'{e}or\\`{e}me de Noether stochastique Abstract: The stochastic embedding procedure associates a stochastic Euler-Lagrange\nequation (SEL) to the standard Euler-Lagrange equation (EL). Can we derive\n(SEL) from a generalized least action principle? To address this question, we\ndevelop a stochastic calculus of variation initiated by Yasue. We give a\nstochastic analog F of the lagrangian action functional. We introduce a notion\nof stationarity according to which the solutions of (SEL) are the stationary\npoints of F. This notion of stationarity brings coherence to stochastic\ncalculus of variation with respect to stochastic embedding. Finally, we prove a\nstochastic Noether theorem which introduces an original notion of stochastic\nfirst integral. \n\n"}
{"id": "math/0605457", "contents": "Title: Hybrid dynamics for currency modeling Abstract: We present a simple hybrid dynamical model as a tool to investigate\nbehavioral strategies based on trend following. The multiplicative symbolic\ndynamics are generated using a lognormal diffusion model for the at-the-money\nimplied volatility term structure. Thus, are model exploits information from\nderivative markets to obtain qualititative properties of the return\ndistribution for the underlier. We apply our model to the JPY-USD exchange rate\nand the corresponding 1mo., 3mo., 6mo. and 1yr. implied volatilities. Our\nresults indicate that the modulation of autoregressive trend following using\nderivative-based signals significantly improves the fit to the distribution of\ntimes between successive sign flips in the underlier time series. \n\n"}
{"id": "math/0702100", "contents": "Title: Random walk in Markovian environment Abstract: We prove a quenched central limit theorem for random walks with bounded\nincrements in a randomly evolving environment on $\\mathbb{Z}^d$. We assume that\nthe transition probabilities of the walk depend not too strongly on the\nenvironment and that the evolution of the environment is Markovian with strong\nspatial and temporal mixing properties. \n\n"}
{"id": "physics/0308016", "contents": "Title: Modes of wave-chaotic dielectric resonators Abstract: Dielectric optical micro-resonators and micro-lasers represent a realization\nof a wave-chaotic system, where the lack of symmetry in the resonator shape\nleads to non-integrable ray dynamics. Modes of such resonators display a rich\nspatial structure, and cannot be classified through mode indices which would\nrequire additional constants of motion in the ray dynamics. Understanding and\ncontrolling the emission properties of such resonators requires the\ninvestigation of the correspondence between classical phase space structures of\nthe ray motion inside the resonator and resonant solutions of the wave\nequations. We first discuss the breakdown of the conventional eikonal\napproximation in the short wavelength limit, and motivate the use of\nphase-space ray tracing and phase space distributions. Next, we introduce an\nefficient numerical method to calculate the quasi-bound modes of dielectric\nresonators, which requires only two diagonalizations per N states, where N is\napproximately equal to the number of half-wavelengths along the perimeter. The\nrelationship between classical phase space structures and modes is displayed\nvia the Husimi projection technique. Observables related to the emission\npattern of the resonator are calculated with high efficiency. \n\n"}
{"id": "quant-ph/0412122", "contents": "Title: Robust Charge-based Qubit Encoding Abstract: We propose a simple encoding of charge-based quantum dot qubits which\nprotects against fluctuating electric fields by charge symmetry. We analyse the\nreduction of coupling to noise due to nearby charge traps and present single\nqubit gates. The relative advantage of the encoding increases with lower charge\ntrap density. \n\n"}
