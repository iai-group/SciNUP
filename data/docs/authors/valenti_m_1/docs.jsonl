{"id": "0705.3995", "contents": "Title: On Undetected Error Probability of Binary Matrix Ensembles Abstract: In this paper, an analysis of the undetected error probability of ensembles\nof binary matrices is presented. The ensemble called the Bernoulli ensemble\nwhose members are considered as matrices generated from i.i.d. Bernoulli source\nis mainly considered here. The main contributions of this work are (i)\nderivation of the error exponent of the average undetected error probability\nand (ii) closed form expressions for the variance of the undetected error\nprobability. It is shown that the behavior of the exponent for a sparse\nensemble is somewhat different from that for a dense ensemble. Furthermore, as\na byproduct of the proof of the variance formula, simple covariance formula of\nthe weight distribution is derived. \n\n"}
{"id": "0707.1099", "contents": "Title: Worst-Case Interactive Communication and Enhancing Sensor Network\n  Lifetime Abstract: We are concerned with the problem of maximizing the worst-case lifetime of a\ndata-gathering wireless sensor network consisting of a set of sensor nodes\ndirectly communicating with a base-station.We propose to solve this problem by\nmodeling sensor node and base-station communication as the interactive\ncommunication between multiple correlated informants (sensor nodes) and a\nrecipient (base-station). We provide practical and scalable interactive\ncommunication protocols for data gathering in sensor networks and demonstrate\ntheir efficiency compared to traditional approaches.\n  In this paper, we first develop a formalism to address the problem of\nworst-case interactive communication between a set of multiple correlated\ninformants and a recipient. We realize that there can be different objectives\nto achieve in such a communication scenario and compute the optimal number of\nmessages and bits exchanged to realize these objectives. Then, we propose to\nadapt these results in the context of single-hop data-gathering sensor\nnetworks. Finally, based on this proposed formalism, we propose a clustering\nbased communication protocol for large sensor networks and demonstrate its\nsuperiority over a traditional clustering protocol. \n\n"}
{"id": "0708.0271", "contents": "Title: Capacity Region of the Finite-State Multiple Access Channel with and\n  without Feedback Abstract: The capacity region of the Finite-State Multiple Access Channel (FS-MAC) with\nfeedback that may be an arbitrary time-invariant function of the channel output\nsamples is considered. We characterize both an inner and an outer bound for\nthis region, using Masseys's directed information. These bounds are shown to\ncoincide, and hence yield the capacity region, of FS-MACs where the state\nprocess is stationary and ergodic and not affected by the inputs.\n  Though `multi-letter' in general, our results yield explicit conclusions when\napplied to specific scenarios of interest. E.g., our results allow us to:\n  - Identify a large class of FS-MACs, that includes the additive mod-2 noise\nMAC where the noise may have memory, for which feedback does not enlarge the\ncapacity region.\n  - Deduce that, for a general FS-MAC with states that are not affected by the\ninput, if the capacity (region) without feedback is zero, then so is the\ncapacity (region) with feedback.\n  - Deduce that the capacity region of a MAC that can be decomposed into a\n`multiplexer' concatenated by a point-to-point channel (with, without, or with\npartial feedback), the capacity region is given by $\\sum_{m} R_m \\leq C$, where\nC is the capacity of the point to point channel and m indexes the encoders.\nMoreover, we show that for this family of channels source-channel coding\nseparation holds. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0708.4214", "contents": "Title: High Rate Single-Symbol Decodable Precoded DSTBCs for Cooperative\n  Networks Abstract: Distributed Orthogonal Space-Time Block Codes (DOSTBCs) achieving full\ndiversity order and single-symbol ML decodability have been introduced recently\nfor cooperative networks and an upper-bound on the maximal rate of such codes\nalong with code constructions has been presented. In this report, we introduce\na new class of Distributed STBCs called Semi-orthogonal Precoded Distributed\nSingle-Symbol Decodable STBCs (S-PDSSDC) wherein, the source performs\nco-ordinate interleaving of information symbols appropriately before\ntransmitting it to all the relays. It is shown that DOSTBCs are a special case\nof S-PDSSDCs. A special class of S-PDSSDCs having diagonal covariance matrix at\nthe destination is studied and an upper bound on the maximal rate of such codes\nis derived. The bounds obtained are approximately twice larger than that of the\nDOSTBCs. A systematic construction of S-PDSSDCs is presented when the number of\nrelays $K \\geq 4$. The constructed codes are shown to achieve the upper-bound\non the rate when $K$ is of the form 0 modulo 4 or 3 modulo 4. For the rest of\nthe values of $K$, the constructed codes are shown to have rates higher than\nthat of DOSTBCs. It is also shown that S-PDSSDCs cannot be constructed with any\nform of linear processing at the relays when the source doesn't perform\nco-ordinate interleaving of the information symbols. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0709.3921", "contents": "Title: Geographic Gossip: Efficient Averaging for Sensor Networks Abstract: Gossip algorithms for distributed computation are attractive due to their\nsimplicity, distributed nature, and robustness in noisy and uncertain\nenvironments. However, using standard gossip algorithms can lead to a\nsignificant waste in energy by repeatedly recirculating redundant information.\nFor realistic sensor network model topologies like grids and random geometric\ngraphs, the inefficiency of gossip schemes is related to the slow mixing times\nof random walks on the communication graph. We propose and analyze an\nalternative gossiping scheme that exploits geographic information. By utilizing\ngeographic routing combined with a simple resampling method, we demonstrate\nsubstantial gains over previously proposed gossip protocols. For regular graphs\nsuch as the ring or grid, our algorithm improves standard gossip by factors of\n$n$ and $\\sqrt{n}$ respectively. For the more challenging case of random\ngeometric graphs, our algorithm computes the true average to accuracy\n$\\epsilon$ using $O(\\frac{n^{1.5}}{\\sqrt{\\log n}} \\log \\epsilon^{-1})$ radio\ntransmissions, which yields a $\\sqrt{\\frac{n}{\\log n}}$ factor improvement over\nstandard gossip algorithms. We illustrate these theoretical results with\nexperimental comparisons between our algorithm and standard methods as applied\nto various classes of random fields. \n\n"}
{"id": "0710.5161", "contents": "Title: Decomposable Subspaces, Linear Sections of Grassmann Varieties, and\n  Higher Weights of Grassmann Codes Abstract: Given a homogeneous component of an exterior algebra, we characterize those\nsubspaces in which every nonzero element is decomposable. In geometric terms,\nthis corresponds to characterizing the projective linear subvarieties of the\nGrassmann variety with its Plucker embedding. When the base field is finite, we\nconsider the more general question of determining the maximum number of points\non sections of Grassmannians by linear subvarieties of a fixed (co)dimension.\nThis corresponds to a known open problem of determining the complete weight\nhierarchy of linear error correcting codes associated to Grassmann varieties.\nWe recover most of the known results as well as prove some new results. In the\nprocess we obtain, and utilize, a simple generalization of the Griesmer-Wei\nbound for arbitrary linear codes. \n\n"}
{"id": "0711.0237", "contents": "Title: Zero-rate feedback can achieve the empirical capacity Abstract: The utility of limited feedback for coding over an individual sequence of\nDMCs is investigated. This study complements recent results showing how limited\nor noisy feedback can boost the reliability of communication. A strategy with\nfixed input distribution $P$ is given that asymptotically achieves rates\narbitrarily close to the mutual information induced by $P$ and the\nstate-averaged channel. When the capacity achieving input distribution is the\nsame over all channel states, this achieves rates at least as large as the\ncapacity of the state averaged channel, sometimes called the empirical\ncapacity. \n\n"}
{"id": "0803.2262", "contents": "Title: Constant-Rank Codes and Their Connection to Constant-Dimension Codes Abstract: Constant-dimension codes have recently received attention due to their\nsignificance to error control in noncoherent random linear network coding. What\nthe maximal cardinality of any constant-dimension code with finite dimension\nand minimum distance is and how to construct the optimal constant-dimension\ncode (or codes) that achieves the maximal cardinality both remain open research\nproblems. In this paper, we introduce a new approach to solving these two\nproblems. We first establish a connection between constant-rank codes and\nconstant-dimension codes. Via this connection, we show that optimal\nconstant-dimension codes correspond to optimal constant-rank codes over\nmatrices with sufficiently many rows. As such, the two aforementioned problems\nare equivalent to determining the maximum cardinality of constant-rank codes\nand to constructing optimal constant-rank codes, respectively. To this end, we\nthen derive bounds on the maximum cardinality of a constant-rank code with a\ngiven minimum rank distance, propose explicit constructions of optimal or\nasymptotically optimal constant-rank codes, and establish asymptotic bounds on\nthe maximum rate of a constant-rank code. \n\n"}
{"id": "0804.0611", "contents": "Title: Channel State Feedback Schemes for Multiuser MIMO-OFDM Downlink Abstract: Channel state feedback schemes for the MIMO broadcast downlink have been\nwidely studied in the frequency-flat case. This work focuses on the more\nrelevant frequency selective case, where some important new aspects emerge. We\nconsider a MIMO-OFDM broadcast channel and compare achievable ergodic rates\nunder three channel state feedback schemes: analog feedback, direction\nquantized feedback and \"time-domain\" channel quantized feedback. The first two\nschemes are direct extensions of previously proposed schemes. The third scheme\nis novel, and it is directly inspired by rate-distortion theory of Gaussian\ncorrelated sources. For each scheme we derive the conditions under which the\nsystem achieves full multiplexing gain. The key difference with respect to the\nwidely treated frequency-flat case is that in MIMO-OFDM the frequency-domain\nchannel transfer function is a Gaussian correlated source. The new time-domain\nquantization scheme takes advantage of the channel frequency correlation\nstructure and outperforms the other schemes. Furthermore, it is by far simpler\nto implement than complicated spherical vector quantization. In particular, we\nobserve that no structured codebook design and vector quantization is actually\nneeded for efficient channel state information feedback. \n\n"}
{"id": "0804.0813", "contents": "Title: Spatial Interference Cancelation for Mobile Ad Hoc Networks: Perfect CSI Abstract: Interference between nodes directly limits the capacity of mobile ad hoc\nnetworks. This paper focuses on spatial interference cancelation with perfect\nchannel state information (CSI), and analyzes the corresponding network\ncapacity. Specifically, by using multiple antennas, zero-forcing beamforming is\napplied at each receiver for canceling the strongest interferers. Given spatial\ninterference cancelation, the network transmission capacity is analyzed in this\npaper, which is defined as the maximum transmitting node density under\nconstraints on outage and the signal-to-interference-noise ratio. Assuming the\nPoisson distribution for the locations of network nodes and spatially i.i.d.\nRayleigh fading channels, mathematical tools from stochastic geometry are\napplied for deriving scaling laws for transmission capacity. Specifically, for\nsmall target outage probability, transmission capacity is proved to increase\nfollowing a power law, where the exponent is the inverse of the size of antenna\narray or larger depending on the pass loss exponent. As shown by simulations,\nspatial interference cancelation increases transmission capacity by an order of\nmagnitude or more even if only one extra antenna is added to each node. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0805.1209", "contents": "Title: Scaling Laws for Overlaid Wireless Networks: A Cognitive Radio Network\n  vs. a Primary Network Abstract: We study the scaling laws for the throughputs and delays of two coexisting\nwireless networks that operate in the same geographic region. The primary\nnetwork consists of Poisson distributed legacy users of density n, and the\nsecondary network consists of Poisson distributed cognitive users of density m,\nwith m>n. The primary users have a higher priority to access the spectrum\nwithout particular considerations for the secondary users, while the secondary\nusers have to act conservatively in order to limit the interference to the\nprimary users. With a practical assumption that the secondary users only know\nthe locations of the primary transmitters (not the primary receivers), we first\nshow that both networks can achieve the same throughput scaling law as what\nGupta and Kumar [1] established for a stand-alone wireless network if proper\ntransmission schemes are deployed, where a certain throughput is achievable for\neach individual secondary user (i.e., zero outage) with high probability. By\nusing a fluid model, we also show that both networks can achieve the same\ndelay-throughput tradeoff as the optimal one established by El Gamal et al. [2]\nfor a stand-alone wireless network. \n\n"}
{"id": "0805.1857", "contents": "Title: The Gaussian Many-Help-One Distributed Source Coding Problem Abstract: Jointly Gaussian memoryless sources are observed at N distinct terminals. The\ngoal is to efficiently encode the observations in a distributed fashion so as\nto enable reconstruction of any one of the observations, say the first one, at\nthe decoder subject to a quadratic fidelity criterion. Our main result is a\nprecise characterization of the rate-distortion region when the covariance\nmatrix of the sources satisfies a \"tree-structure\" condition. In this\nsituation, a natural analog-digital separation scheme optimally trades off the\ndistributed quantization rate tuples and the distortion in the reconstruction:\neach encoder consists of a point-to-point Gaussian vector quantizer followed by\na Slepian-Wolf binning encoder. We also provide a partial converse that\nsuggests that the tree structure condition is fundamental. \n\n"}
{"id": "0806.3650", "contents": "Title: Recursive Code Construction for Random Networks Abstract: A modification of Koetter-Kschischang codes for random networks is presented\n(these codes were also studied by Wang et al. in the context of authentication\nproblems). The new codes have higher information rate, while maintaining the\nsame error-correcting capabilities. An efficient error-correcting algorithm is\nproposed for these codes. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0808.0234", "contents": "Title: DMT of Multi-hop Cooperative Networks - Part I: Basic Results Abstract: In this two-part paper, the DMT of cooperative multi-hop networks is\nexamined. The focus is on single-source single-sink (ss-ss) multi-hop relay\nnetworks having slow-fading links and relays that potentially possess multiple\nantennas. The present paper examines the two end-points of the DMT of\nfull-duplex networks. In particular, the maximum achievable diversity of\narbitrary multi-terminal wireless networks is shown to be equal to the min-cut.\nThe maximum multiplexing gain of arbitrary full-duplex ss-ss networks is shown\nto be equal to the min-cut rank, using a new connection to a deterministic\nnetwork. We also prove some basic results including a proof that the colored\nnoise encountered in AF protocols for cooperative networks can be treated as\nwhite noise for DMT computations. The DMT of a parallel channel with\nindependent MIMO links is also computed here. As an application of these basic\nresults, we prove that a linear tradeoff between maximum diversity and maximum\nmultiplexing gain is achievable for full-duplex networks with single antenna\nnodes. All protocols in this paper are explicit and rely only upon\namplify-and-forward (AF) relaying. Half duplex networks are studied, and\nexplicit codes for all protocols proposed in both parts, are provided in the\ncompanion paper. \n\n"}
{"id": "0808.0948", "contents": "Title: Capacity of a Class of Diamond Channels Abstract: We study a special class of diamond channels which was introduced by Schein\nin 2001. In this special class, each diamond channel consists of a transmitter,\na noisy relay, a noiseless relay and a receiver. We prove the capacity of this\nclass of diamond channels by providing an achievable scheme and a converse. The\ncapacity we show is strictly smaller than the cut-set bound. Our result also\nshows the optimality of a combination of decode-and-forward (DAF) and\ncompress-and-forward (CAF) at the noisy relay node. This is the first example\nwhere a combination of DAF and CAF is shown to be capacity achieving. Finally,\nwe note that there exists a duality between this diamond channel coding problem\nand the Kaspi-Berger source coding problem. \n\n"}
{"id": "0809.0009", "contents": "Title: Distributed Parameter Estimation in Sensor Networks: Nonlinear\n  Observation Models and Imperfect Communication Abstract: The paper studies distributed static parameter (vector) estimation in sensor\nnetworks with nonlinear observation models and noisy inter-sensor\ncommunication. It introduces \\emph{separably estimable} observation models that\ngeneralize the observability condition in linear centralized estimation to\nnonlinear distributed estimation. It studies two distributed estimation\nalgorithms in separably estimable models, the $\\mathcal{NU}$ (with its linear\ncounterpart $\\mathcal{LU}$) and the $\\mathcal{NLU}$. Their update rule combines\na \\emph{consensus} step (where each sensor updates the state by weight\naveraging it with its neighbors' states) and an \\emph{innovation} step (where\neach sensor processes its local current observation.) This makes the three\nalgorithms of the \\textit{consensus + innovations} type, very different from\ntraditional consensus. The paper proves consistency (all sensors reach\nconsensus almost surely and converge to the true parameter value,) efficiency,\nand asymptotic unbiasedness. For $\\mathcal{LU}$ and $\\mathcal{NU}$, it proves\nasymptotic normality and provides convergence rate guarantees. The three\nalgorithms are characterized by appropriately chosen decaying weight sequences.\nAlgorithms $\\mathcal{LU}$ and $\\mathcal{NU}$ are analyzed in the framework of\nstochastic approximation theory; algorithm $\\mathcal{NLU}$ exhibits mixed\ntime-scale behavior and biased perturbations, and its analysis requires a\ndifferent approach that is developed in the paper. \n\n"}
{"id": "0809.0686", "contents": "Title: Energy Scaling Laws for Distributed Inference in Random Fusion Networks Abstract: The energy scaling laws of multihop data fusion networks for distributed\ninference are considered. The fusion network consists of randomly located\nsensors distributed i.i.d. according to a general spatial distribution in an\nexpanding region. Among the class of data fusion schemes that enable optimal\ninference at the fusion center for Markov random field (MRF) hypotheses, the\nscheme with minimum average energy consumption is bounded below by average\nenergy of fusion along the minimum spanning tree, and above by a suboptimal\nscheme, referred to as Data Fusion for Markov Random Fields (DFMRF). Scaling\nlaws are derived for the optimal and suboptimal fusion policies. It is shown\nthat the average asymptotic energy of the DFMRF scheme is finite for a class of\nMRF models. \n\n"}
{"id": "0809.1258", "contents": "Title: Network Protection Codes Against Link Failures Using Network Coding Abstract: Protecting against link failures in communication networks is essential to\nincrease robustness, accessibility, and reliability of data transmission.\nRecently, network coding has been proposed as a solution to provide agile and\ncost efficient network protection against link failures, which does not require\ndata rerouting, or packet retransmission. To achieve this, separate paths have\nto be provisioned to carry encoded packets, hence requiring either the addition\nof extra links, or reserving some of the resources for this purpose. In this\npaper, we propose network protection codes against a single link failure using\nnetwork coding, where a separate path using reserved links is not needed. In\nthis case portions of the link capacities are used to carry the encoded\npackets.\n  The scheme is extended to protect against multiple link failures and can be\nimplemented at an overlay layer. Although this leads to reducing the network\ncapacity, the network capacity reduction is asymptotically small in most cases\nof practical interest. We demonstrate that such network protection codes are\nequivalent to error correcting codes for erasure channels. Finally, we study\nthe encoding and decoding operations of such codes over the binary field. \n\n"}
{"id": "0809.1366", "contents": "Title: Network Coding Security: Attacks and Countermeasures Abstract: By allowing intermediate nodes to perform non-trivial operations on packets,\nsuch as mixing data from multiple streams, network coding breaks with the\nruling store and forward networking paradigm and opens a myriad of challenging\nsecurity questions. Following a brief overview of emerging network coding\nprotocols, we provide a taxonomy of their security vulnerabilities, which\nhighlights the differences between attack scenarios in which network coding is\nparticularly vulnerable and other relevant cases in which the intrinsic\nproperties of network coding allow for stronger and more efficient security\nsolutions than classical routing. Furthermore, we give practical examples where\nnetwork coding can be combined with classical cryptography both for secure\ncommunication and secret key distribution. Throughout the paper we identify a\nnumber of research challenges deemed relevant towards the applicability of\nsecure network coding in practical networks. \n\n"}
{"id": "0809.3540", "contents": "Title: A Note on the Equivalence of Gibbs Free Energy and Information Theoretic\n  Capacity Abstract: The minimization of Gibbs free energy is based on the changes in work and\nfree energy that occur in a physical or chemical system. The maximization of\nmutual information, the capacity, of a noisy channel is determined based on the\nmarginal probabilities and conditional entropies associated with a\ncommunications system. As different as the procedures might first appear,\nthrough the exploration of a simple, \"dual use\" Ising model, it is seen that\nthe two concepts are in fact the same. In particular, the case of a binary\nsymmetric channel is calculated in detail. \n\n"}
{"id": "0809.4086", "contents": "Title: Learning Hidden Markov Models using Non-Negative Matrix Factorization Abstract: The Baum-Welsh algorithm together with its derivatives and variations has\nbeen the main technique for learning Hidden Markov Models (HMM) from\nobservational data. We present an HMM learning algorithm based on the\nnon-negative matrix factorization (NMF) of higher order Markovian statistics\nthat is structurally different from the Baum-Welsh and its associated\napproaches. The described algorithm supports estimation of the number of\nrecurrent states of an HMM and iterates the non-negative matrix factorization\n(NMF) algorithm to improve the learned HMM parameters. Numerical examples are\nprovided as well. \n\n"}
{"id": "0810.1808", "contents": "Title: A Central Limit Theorem for the SINR at the LMMSE Estimator Output for\n  Large Dimensional Signals Abstract: This paper is devoted to the performance study of the Linear Minimum Mean\nSquared Error estimator for multidimensional signals in the large dimension\nregime. Such an estimator is frequently encountered in wireless communications\nand in array processing, and the Signal to Interference and Noise Ratio (SINR)\nat its output is a popular performance index. The SINR can be modeled as a\nrandom quadratic form which can be studied with the help of large random matrix\ntheory, if one assumes that the dimension of the received and transmitted\nsignals go to infinity at the same pace. This paper considers the asymptotic\nbehavior of the SINR for a wide class of multidimensional signal models that\nincludes general multi-antenna as well as spread spectrum transmission models.\n  The expression of the deterministic approximation of the SINR in the large\ndimension regime is recalled and the SINR fluctuations around this\ndeterministic approximation are studied. These fluctuations are shown to\nconverge in distribution to the Gaussian law in the large dimension regime, and\ntheir variance is shown to decrease as the inverse of the signal dimension. \n\n"}
{"id": "0810.4658", "contents": "Title: Indexability of Restless Bandit Problems and Optimality of Whittle's\n  Index for Dynamic Multichannel Access Abstract: We consider a class of restless multi-armed bandit problems (RMBP) that\narises in dynamic multichannel access, user/server scheduling, and optimal\nactivation in multi-agent systems. For this class of RMBP, we establish the\nindexability and obtain Whittle's index in closed-form for both discounted and\naverage reward criteria. These results lead to a direct implementation of\nWhittle's index policy with remarkably low complexity. When these Markov chains\nare stochastically identical, we show that Whittle's index policy is optimal\nunder certain conditions. Furthermore, it has a semi-universal structure that\nobviates the need to know the Markov transition probabilities. The optimality\nand the semi-universal structure result from the equivalency between Whittle's\nindex policy and the myopic policy established in this work. For non-identical\nchannels, we develop efficient algorithms for computing a performance upper\nbound given by Lagrangian relaxation. The tightness of the upper bound and the\nnear-optimal performance of Whittle's index policy are illustrated with\nsimulation examples. \n\n"}
{"id": "0811.0196", "contents": "Title: Reduced-Complexity Reed--Solomon Decoders Based on Cyclotomic FFTs Abstract: In this paper, we reduce the computational complexities of partial and dual\npartial cyclotomic FFTs (CFFTs), which are discrete Fourier transforms where\nspectral and temporal components are constrained, based on their properties as\nwell as a common subexpression elimination algorithm. Our partial CFFTs achieve\nsmaller computational complexities than previously proposed partial CFFTs.\nUtilizing our CFFTs in both transform- and time-domain Reed--Solomon decoders,\nwe achieve significant complexity reductions. \n\n"}
{"id": "0812.0319", "contents": "Title: Secrecy Capacity of a Class of Broadcast Channels with an Eavesdropper Abstract: We study the security of communication between a single transmitter and\nmultiple receivers in a broadcast channel in the presence of an eavesdropper.\nWe consider several special classes of channels. As the first model, we\nconsider the degraded multi-receiver wiretap channel where the legitimate\nreceivers exhibit a degradedness order while the eavesdropper is more noisy\nwith respect to all legitimate receivers. We establish the secrecy capacity\nregion of this channel model. Secondly, we consider the parallel multi-receiver\nwiretap channel with a less noisiness order in each sub-channel, where this\norder is not necessarily the same for all sub-channels. We establish the common\nmessage secrecy capacity and sum secrecy capacity of this channel. Thirdly, we\nstudy a special class of degraded parallel multi-receiver wiretap channels and\nprovide a stronger result. In particular, we study the case with two\nsub-channels two users and one eavesdropper, where there is a degradedness\norder in each sub-channel such that in the first (resp. second) sub-channel the\nsecond (resp. first) receiver is degraded with respect to the first (resp.\nsecond) receiver, while the eavesdropper is degraded with respect to both\nlegitimate receivers in both sub-channels. We determine the secrecy capacity\nregion of this channel. Finally, we focus on a variant of this previous channel\nmodel where the transmitter can use only one of the sub-channels at any time.\nWe characterize the secrecy capacity region of this channel as well. \n\n"}
{"id": "0812.1629", "contents": "Title: An application of the O'Nan-Scott theorem to the group generated by the\n  round functions of an AES-like cipher Abstract: In a previous paper, we had proved that the permutation group generated by\nthe round functions of an AES-like cipher is primitive. Here we apply the O'Nan\nScott classification of primitive groups to prove that this group is the\nalternating group. \n\n"}
{"id": "0812.5104", "contents": "Title: On Quantum and Classical Error Control Codes: Constructions and\n  Applications Abstract: It is conjectured that quantum computers are able to solve certain problems\nmore quickly than any deterministic or probabilistic computer. A quantum\ncomputer exploits the rules of quantum mechanics to speed up computations.\nHowever, it is a formidable task to build a quantum computer, since the quantum\nmechanical systems storing the information unavoidably interact with their\nenvironment. Therefore, one has to mitigate the resulting noise and decoherence\neffects to avoid computational errors.\n  In this work, I study various aspects of quantum error control codes -- the\nkey component of fault-tolerant quantum information processing. I present the\nfundamental theory and necessary background of quantum codes and construct many\nfamilies of quantum block and convolutional codes over finite fields, in\naddition to families of subsystem codes over symmetric and asymmetric channels.\n  Particularly, many families of quantum BCH, RS, duadic, and convolutional\ncodes are constructed over finite fields. Families of subsystem codes and a\nclass of optimal MDS subsystem codes are derived over asymmetric and symmetric\nquantum channels. In addition, propagation rules and tables of upper bounds on\nsubsystem code parameters are established. Classes of quantum and classical\nLDPC codes based on finite geometries and Latin squares are constructed. \n\n"}
{"id": "0901.1869", "contents": "Title: Low-Complexity Near-ML Decoding of Large Non-Orthogonal STBCs Using PDA Abstract: Non-orthogonal space-time block codes (STBC) from cyclic division algebras\n(CDA) having large dimensions are attractive because they can simultaneously\nachieve both high spectral efficiencies (same spectral efficiency as in V-BLAST\nfor a given number of transmit antennas) {\\em as well as} full transmit\ndiversity. Decoding of non-orthogonal STBCs with hundreds of dimensions has\nbeen a challenge. In this paper, we present a probabilistic data association\n(PDA) based algorithm for decoding non-orthogonal STBCs with large dimensions.\nOur simulation results show that the proposed PDA-based algorithm achieves near\nSISO AWGN uncoded BER as well as near-capacity coded BER (within about 5 dB of\nthe theoretical capacity) for large non-orthogonal STBCs from CDA. We study the\neffect of spatial correlation on the BER, and show that the performance loss\ndue to spatial correlation can be alleviated by providing more receive spatial\ndimensions. We report good BER performance when a training-based iterative\ndecoding/channel estimation is used (instead of assuming perfect channel\nknowledge) in channels with large coherence times. A comparison of the\nperformances of the PDA algorithm and the likelihood ascent search (LAS)\nalgorithm (reported in our recent work) is also presented. \n\n"}
{"id": "0901.1936", "contents": "Title: A Lower Bound on the Capacity of Wireless Erasure Networks with Random\n  Node Locations Abstract: In this paper, a lower bound on the capacity of wireless ad hoc erasure\nnetworks is derived in closed form in the canonical case where $n$ nodes are\nuniformly and independently distributed in the unit area square. The bound\nholds almost surely and is asymptotically tight. We assume all nodes have fixed\ntransmit power and hence two nodes should be within a specified distance $r_n$\nof each other to overcome noise. In this context, interference determines\noutages, so we model each transmitter-receiver pair as an erasure channel with\na broadcast constraint, i.e. each node can transmit only one signal across all\nits outgoing links. A lower bound of $\\Theta(n r_n)$ for the capacity of this\nclass of networks is derived. If the broadcast constraint is relaxed and each\nnode can send distinct signals on distinct outgoing links, we show that the\ngain is a function of $r_n$ and the link erasure probabilities, and is at most\na constant if the link erasure probabilities grow sufficiently large with $n$.\nFinally, the case where the erasure probabilities are themselves random\nvariables, for example due to randomness in geometry or channels, is analyzed.\nWe prove somewhat surprisingly that in this setting, variability in erasure\nprobabilities increases network capacity. \n\n"}
{"id": "0902.2141", "contents": "Title: Extracting the Kolmogorov Complexity of Strings and Sequences from\n  Sources with Limited Independence Abstract: An infinite binary sequence has randomness rate at least $\\sigma$ if, for\nalmost every $n$, the Kolmogorov complexity of its prefix of length $n$ is at\nleast $\\sigma n$. It is known that for every rational $\\sigma \\in (0,1)$, on\none hand, there exists sequences with randomness rate $\\sigma$ that can not be\neffectively transformed into a sequence with randomness rate higher than\n$\\sigma$ and, on the other hand, any two independent sequences with randomness\nrate $\\sigma$ can be transformed into a sequence with randomness rate higher\nthan $\\sigma$. We show that the latter result holds even if the two input\nsequences have linear dependency (which, informally speaking, means that all\nprefixes of length $n$ of the two sequences have in common a constant fraction\nof their information). The similar problem is studied for finite strings. It is\nshown that from any two strings with sufficiently large Kolmogorov complexity\nand sufficiently small dependence, one can effectively construct a string that\nis random even conditioned by any one of the input strings. \n\n"}
{"id": "0902.2260", "contents": "Title: Network Coding with Two-Way Relaying: Achievable Rate Regions and\n  Diversity-Multiplexing Tradeoffs Abstract: This paper addresses the fundamental characteristics of information exchange\nvia multihop network coding over two-way relaying in a wireless ad hoc network.\nThe end-to-end rate regions achieved by time-division multihop (TDMH),\nMAC-layer network coding (MLNC) and PHY-layer network coding (PLNC) are first\ncharacterized. It is shown that MLNC does not always achieve better rates than\nTDMH, time sharing between TDMH and MLNC is able to achieve a larger rate\nregion, and PLNC dominates the rate regions achieved by TDMH and MLNC. An\nopportunistic scheduling algorithm for MLNC and PLNC is then proposed to\nstabilize the two-way relaying system for Poisson arrivals whenever the rate\npair is within the Shannon rate regions of MLNC and PLNC. To understand the\ntwo-way transmission limits of multihop network coding, the sum-rate\noptimization with or without certain traffic pattern and the end-to-end\ndiversity-multiplexing tradeoffs (DMTs) of two-way transmission over multiple\nrelay nodes are also analyzed. \n\n"}
{"id": "0903.3131", "contents": "Title: Matrix Completion With Noise Abstract: On the heels of compressed sensing, a remarkable new field has very recently\nemerged. This field addresses a broad range of problems of significant\npractical interest, namely, the recovery of a data matrix from what appears to\nbe incomplete, and perhaps even corrupted, information. In its simplest form,\nthe problem is to recover a matrix from a small sample of its entries, and\ncomes up in many areas of science and engineering including collaborative\nfiltering, machine learning, control, remote sensing, and computer vision to\nname a few.\n  This paper surveys the novel literature on matrix completion, which shows\nthat under some suitable conditions, one can recover an unknown low-rank matrix\nfrom a nearly minimal set of entries by solving a simple convex optimization\nproblem, namely, nuclear-norm minimization subject to data constraints.\nFurther, this paper introduces novel results showing that matrix completion is\nprovably accurate even when the few observed entries are corrupted with a small\namount of noise. A typical result is that one can recover an unknown n x n\nmatrix of low rank r from just about nr log^2 n noisy samples with an error\nwhich is proportional to the noise level. We present numerical results which\ncomplement our quantitative analysis and show that, in practice, nuclear norm\nminimization accurately fills in the many missing entries of large low-rank\nmatrices from just a few noisy samples. Some analogies between matrix\ncompletion and compressed sensing are discussed throughout. \n\n"}
{"id": "0905.3360", "contents": "Title: A Generalized Statistical Complexity Measure: Applications to Quantum\n  Systems Abstract: A two-parameter family of complexity measures $\\tilde{C}^{(\\alpha,\\beta)}$\nbased on the R\\'enyi entropies is introduced and characterized by a detailed\nstudy of its mathematical properties. This family is the generalization of a\ncontinuous version of the LMC complexity, which is recovered for $\\alpha=1$ and\n$\\beta=2$. These complexity measures are obtained by multiplying two quantities\nbringing global information on the probability distribution defining the\nsystem. When one of the parameters, $\\alpha$ or $\\beta$, goes to infinity, one\nof the global factors becomes a local factor. For this special case, the\ncomplexity is calculated on different quantum systems: H-atom, harmonic\noscillator and square well. \n\n"}
{"id": "0905.3689", "contents": "Title: Optimized Training and Feedback for MIMO Downlink Channels Abstract: We consider a MIMO fading broadcast channel where channel state information\nis acquired at user terminals via downlink training and channel feedback is\nused to provide transmitter channel state information (CSIT) to the base\nstation. The feedback channel (the corresponding uplink) is modeled as an AWGN\nchannel, orthogonal across users. The total bandwidth consumed is the sum of\nthe bandwidth/resources used for downlink training, channel feedback, and data\ntransmission. Assuming that the channel follows a block fading model and that\nzeroforcing beamforming is used, we optimize the net achievable rate for\nunquantized (analog) and quantized (digital) channel feedback. The optimal\nnumber of downlink training pilots is seen to be essentially the same for both\nfeedback techniques, but digital feedback is shown to provide a larger net rate\nthan analog feedback. \n\n"}
{"id": "0906.3192", "contents": "Title: Secured Communication over Frequency-Selective Fading Channels: a\n  practical Vandermonde precoding Abstract: In this paper, we study the frequency-selective broadcast channel with\nconfidential messages (BCC) in which the transmitter sends a confidential\nmessage to receiver 1 and a common message to receivers 1 and 2. In the case of\na block transmission of N symbols followed by a guard interval of L symbols,\nthe frequency-selective channel can be modeled as a N * (N+L) Toeplitz matrix.\nFor this special type of multiple-input multiple-output (MIMO) channels, we\npropose a practical Vandermonde precoding that consists of projecting the\nconfidential messages in the null space of the channel seen by receiver 2 while\nsuperposing the common message. For this scheme, we provide the achievable rate\nregion, i.e. the rate-tuple of the common and confidential messages, and\ncharacterize the optimal covariance inputs for some special cases of interest.\nIt is proved that the proposed scheme achieves the optimal degree of freedom\n(d.o.f) region. More specifically, it enables to send l <= L confidential\nmessages and N-l common messages simultaneously over a block of N+L symbols.\nInterestingly, the proposed scheme can be applied to secured multiuser\nscenarios such as the K+1-user frequency-selective BCC with K confidential\nmessages and the two-user frequency-selective BCC with two confidential\nmessages. For each scenario, we provide the achievable secrecy degree of\nfreedom (s.d.o.f.) region of the corresponding frequency-selective BCC and\nprove the optimality of the Vandermonde precoding. One of the appealing\nfeatures of the proposed scheme is that it does not require any specific\nsecrecy encoding technique but can be applied on top of any existing powerful\nencoding schemes. \n\n"}
{"id": "0906.3667", "contents": "Title: A Deterministic Equivalent for the Analysis of Correlated MIMO Multiple\n  Access Channels Abstract: In this article, novel deterministic equivalents for the Stieltjes transform\nand the Shannon transform of a class of large dimensional random matrices are\nprovided. These results are used to characterise the ergodic rate region of\nmultiple antenna multiple access channels, when each point-to-point propagation\nchannel is modelled according to the Kronecker model. Specifically, an\napproximation of all rates achieved within the ergodic rate region is derived\nand an approximation of the linear precoders that achieve the boundary of the\nrate region as well as an iterative water-filling algorithm to obtain these\nprecoders are provided. An original feature of this work is that the proposed\ndeterministic equivalents are proved valid even for strong correlation patterns\nat both communication sides. The above results are validated by Monte Carlo\nsimulations. \n\n"}
{"id": "0907.0472", "contents": "Title: Capacity Regions and Sum-Rate Capacities of Vector Gaussian Interference\n  Channels Abstract: The capacity regions of vector, or multiple-input multiple-output, Gaussian\ninterference channels are established for very strong interference and aligned\nstrong interference. Furthermore, the sum-rate capacities are established for Z\ninterference, noisy interference, and mixed (aligned weak/intermediate and\naligned strong) interference. These results generalize known results for scalar\nGaussian interference channels. \n\n"}
{"id": "0907.1788", "contents": "Title: FNT-based Reed-Solomon Erasure Codes Abstract: This paper presents a new construction of Maximum-Distance Separable (MDS)\nReed-Solomon erasure codes based on Fermat Number Transform (FNT). Thanks to\nFNT, these codes support practical coding and decoding algorithms with\ncomplexity O(n log n), where n is the number of symbols of a codeword. An\nopen-source implementation shows that the encoding speed can reach 150Mbps for\ncodes of length up to several 10,000s of symbols. These codes can be used as\nthe basic component of the Information Dispersal Algorithm (IDA) system used in\na several P2P systems. \n\n"}
{"id": "0908.0856", "contents": "Title: Outage Capacity of Incremental Relaying at Low Signal-to-Noise Ratios Abstract: We present the \\epsilon-outage capacity of incremental relaying at low\nsignal-to-noise ratios (SNR) in a wireless cooperative network with slow\nRayleigh fading channels. The relay performs decode-and-forward and repetition\ncoding is employed in the network, which is optimal in the low SNR regime. We\nderive an expression on the optimal relay location that maximizes the\n\\epsilon-outage capacity. It is shown that this location is independent of the\noutage probability and SNR but only depends on the channel conditions\nrepresented by a path-loss factor. We compare our results to the\n\\epsilon-outage capacity of the cut-set bound and demonstrate that the ratio\nbetween the \\epsilon-outage capacity of incremental relaying and the cut-set\nbound lies within 1/\\sqrt{2} and 1. Furthermore, we derive lower bounds on the\n\\epsilon-outage capacity for the case of K relays. \n\n"}
{"id": "0908.1916", "contents": "Title: Caching in Wireless Networks Abstract: We consider the problem of delivering content cached in a wireless network of\nn nodes randomly located on a square of area n. The network performance is\ndescribed by the n2^n-dimensional caching capacity region of the wireless\nnetwork. We provide an inner bound on this caching capacity region, and, in the\nhigh path-loss regime, a matching (in the scaling sense) outer bound. For large\npath-loss exponent, this provides an information-theoretic scaling\ncharacterization of the entire caching capacity region. The proposed\ncommunication scheme achieving the inner bound shows that the problems of cache\nselection and channel coding can be solved separately without loss of\norder-optimality. On the other hand, our results show that the common\narchitecture of nearest-neighbor cache selection can be arbitrarily bad,\nimplying that cache selection and load balancing need to be performed jointly. \n\n"}
{"id": "0908.2282", "contents": "Title: Real Interference Alignment: Exploiting the Potential of Single Antenna\n  Systems Abstract: In this paper, the available spatial Degrees-Of-Freedoms (DOF) in single\nantenna systems is exploited. A new coding scheme is proposed in which several\ndata streams having fractional multiplexing gains are sent by transmitters and\ninterfering streams are aligned at receivers. Viewed as a field over rational\nnumbers, a received signal has infinite fractional DOFs, allowing simultaneous\ninterference alignment of any finite number of signals at any finite number of\nreceivers. The coding scheme is backed up by a recent result in the field of\nDiophantine approximation, which states that the convergence part of the\nKhintchine-Groshev theorem holds for points on non-degenerate manifolds. The\nproposed coding scheme is proved to be optimal for three communication\nchannels, namely the Gaussian Interference Channel (GIC), the uplink channel in\ncellular systems, and the $X$ channel. It is proved that the total DOF of the\n$K$-user GIC is $\\frac{K}{2}$ almost surely, i.e. each user enjoys half of its\nmaximum DOF. Having $K$ cells and $M$ users within each cell in a cellular\nsystem, the total DOF of the uplink channel is proved to be $\\frac{KM}{M+1}$.\nFinally, the total DOF of the $X$ channel with $K$ transmitters and $M$\nreceivers is shown to be $\\frac{KM}{K+M-1}$. \n\n"}
{"id": "0908.3512", "contents": "Title: The Infinite-message Limit of Two-terminal Interactive Source Coding Abstract: A two-terminal interactive function computation problem with alternating\nmessages is studied within the framework of distributed block source coding\ntheory. For any finite number of messages, a single-letter characterization of\nthe sum-rate-distortion function was established in previous works using\nstandard information-theoretic techniques. This, however, does not provide a\nsatisfactory characterization of the infinite-message limit, which is a new,\nunexplored dimension for asymptotic-analysis in distributed block source coding\ninvolving potentially an infinite number of infinitesimal-rate messages. In\nthis paper, the infinite-message sum-rate-distortion function, viewed as a\nfunctional of the joint source pmf and the distortion levels, is characterized\nas the least element of a partially ordered family of functionals having\ncertain convex-geometric properties. The new characterization does not involve\nevaluating the infinite-message limit of a finite-message sum-rate-distortion\nexpression. This characterization leads to a family of lower bounds for the\ninfinite-message sum-rate-distortion expression and a simple criterion to test\nthe optimality of any achievable infinite-message sum-rate-distortion\nexpression. For computing the amplewise Boolean AND function, the\ninfinite-message minimum sum-rates are characterized in closed analytic form.\nThese sum-rates are shown to be achievable using infinitely many\ninfinitesimal-rate messages. The new convex-geometric characterization is used\nto develop an iterative algorithm for evaluating any finite-message\nsumrate-distortion function. It is also used to construct the first examples\nwhich demonstrate that for lossy source reproduction, two messages can strictly\nimprove the one-message Wyner-Ziv rate-distortion function settling an\nunresolved question from a 1985 paper. \n\n"}
{"id": "0909.1115", "contents": "Title: Capacity Region of Layered Erasure One-sided Interference Channels\n  without CSIT Abstract: This paper studies a layered erasure interference channel model, which is a\nsimplification of the Gaussian interference channel with fading using the\ndeterministic model approach. In particular, the capacity region of the layered\nerasure one-sided interference channel is completely determined, assuming that\nthe channel state information (CSI) is known to the receivers, but there is no\nCSI at transmitters (CSIT). The result holds for arbitrary fading statistics.\nPrevious results of Aggarwal, Sankar, Calderbank and Poor on the capacity\nregion or sum capacity under several interference configurations are shown to\nbe special cases of the capacity region shown in this paper. \n\n"}
{"id": "0909.4203", "contents": "Title: Error Exponents for the Gaussian Channel with Active Noisy Feedback Abstract: We study the best exponential decay in the blocklength of the probability of\nerror that can be achieved in the transmission of a single bit over the\nGaussian channel with an active noisy Gaussian feedback link. We impose an\n\\emph{expected} block power constraint on the forward link and study both\n\\emph{almost-sure} and \\emph{expected} block power constraints on the feedback\nlink. In both cases the best achievable error exponents are finite and grow\napproximately proportionally to the larger between the signal-to-noise ratios\non the forward and feedback links. The error exponents under almost-sure block\npower constraints are typically strictly smaller than under expected\nconstraints. Some of the results extend to communication at arbitrary rates\nbelow capacity and to general discrete memoryless channels. \n\n"}
{"id": "0909.4876", "contents": "Title: A Program in Dialectical Rough Set Theory Abstract: A dialectical rough set theory focussed on the relation between roughly\nequivalent objects and classical objects was introduced in \\cite{AM699} by the\npresent author. The focus of our investigation is on elucidating the minimal\nconditions on the nature of granularity, underlying semantic domain and nature\nof the general rough set theories (RST) involved for possible extension of the\nsemantics to more general RST on a paradigm. On this basis we also formulate a\nprogram in dialectical rough set theory. The dialectical approach provides\nbetter semantics in many difficult cases and helps in formalising a wide\nvariety of concepts and notions that remain untamed at meta levels in the usual\napproaches. This is a brief version of a more detailed forthcoming paper by the\npresent author. \n\n"}
{"id": "0910.0575", "contents": "Title: A Note on Functional Averages over Gaussian Ensembles Abstract: In this work we find a new formula for matrix averages over the Gaussian\nensemble. Let ${\\bf H}$ be an $n\\times n$ Gaussian random matrix with complex,\nindependent, and identically distributed entries of zero mean and unit\nvariance. Given an $n\\times n$ positive definite matrix ${\\bf A}$, and a\ncontinuous function $f:\\R^{+}\\to\\R$ such that $\\int_{0}^{\\infty}{e^{-\\alpha\nt}|f(t)|^2\\,dt}<\\infty$ for every $\\alpha>0$, we find a new formula for the\nexpectation $\\E[\\mathrm{Tr}(f({\\bf HAH^{*}}))]$. Taking $f(x)=\\log(1+x)$ gives\nanother formula for the capacity of the MIMO communication channel, and taking\n$f(x)=(1+x)^{-1}$ gives the MMSE achieved by a linear receiver. \n\n"}
{"id": "0910.1300", "contents": "Title: D-MG Tradeoff of DF and AF Relaying Protocols over Asynchronous PAM\n  Cooperative Networks Abstract: The diversity multiplexing tradeoff of a general two-hop asynchronous\ncooperative network is examined for various relaying protocols such as\nnon-orthogonal selection decode-and-forward (NSDF), orthogonal selection\ndecode-and-forward (OSDF), non-orthogonal amplify-and-forward (NAF), and\northogonal amplify-and-forward (OAF). The transmitter nodes are assumed to send\npulse amplitude modulation (PAM) signals asynchronously, in which information\nsymbols are linearly modulated by a shaping waveform to be sent to the\ndestination. We consider two different cases with respect to the length of the\nshaping waveforms in the time domain. In the theoretical case where the shaping\nwaveforms with infinite time support are used, it is shown that asynchronism\ndoes not affect the DMT performance of the system and the same DMT as that of\nthe corresponding synchronous network is obtained for all the aforementioned\nprotocols. In the practical case where finite length shaping waveforms are\nused, it is shown that better diversity gains can be achieved at the expense of\nbandwidth expansion. In the decode-and-forward (DF) type protocols, the\nasynchronous network provides better diversity gains than those of the\ncorresponding synchronous network throughout the range of the multiplexing\ngain. In the amplify-and-forward (AF) type protocols, the asynchronous network\nprovides the same DMT as that of the corresponding synchronous counterpart\nunder the OAF protocol; however, a better diversity gain is achieved under the\nNAF protocol throughout the range of the multiplexing gain. In particular, in\nthe single relay asynchronous network, the NAF protocol provides the same DMT\nas that of the 2 {\\times} 1 multiple-input single-output (MISO) channel. \n\n"}
{"id": "0911.1849", "contents": "Title: The Feasibility of Interference Alignment over Measured MIMO-OFDM\n  Channels Abstract: Interference alignment (IA) has been shown to achieve the maximum achievable\ndegrees of freedom in the interference channel. This results in sum rate\nscaling linearly with the number of users in the high signal-to-noise-ratio\n(SNR) regime. Linear scaling is achieved by precoding transmitted signals to\nalign interference subspaces at the receivers, given channel knowledge of all\ntransmit-receive pairs, effectively reducing the number of discernible\ninterferers. The theory of IA was derived under assumptions about the richness\nof scattering in the propagation channel; practical channels do not guarantee\nsuch ideal characteristics. This paper presents the first experimental study of\nIA in measured multiple-input multiple-output orthogonal frequency-division\nmultiplexing (MIMO-OFDM) interference channels. Our measurement campaign\nincludes a variety of indoor and outdoor measurement scenarios at The\nUniversity of Texas at Austin. We show that IA achieves the claimed scaling\nfactors, or degrees of freedom, in several measured channel settings for a 3\nuser, 2 antennas per node setup. In addition to verifying the claimed\nperformance, we characterize the effect of Kronecker spatial correlation on sum\nrate and present two other correlation measures, which we show are more tightly\nrelated to the achieved sum rate. \n\n"}
{"id": "0911.4167", "contents": "Title: Wyner-Ziv Coding over Broadcast Channels: Digital Schemes Abstract: This paper addresses lossy transmission of a common source over a broadcast\nchannel when there is correlated side information at the receivers, with\nemphasis on the quadratic Gaussian and binary Hamming cases. A digital scheme\nthat combines ideas from the lossless version of the problem, i.e.,\nSlepian-Wolf coding over broadcast channels, and dirty paper coding, is\npresented and analyzed. This scheme uses layered coding where the common layer\ninformation is intended for both receivers and the refinement information is\ndestined only for one receiver. For the quadratic Gaussian case, a quantity\ncharacterizing the overall quality of each receiver is identified in terms of\nchannel and side information parameters. It is shown that it is more\nadvantageous to send the refinement information to the receiver with \"better\"\noverall quality. In the case where all receivers have the same overall quality,\nthe presented scheme becomes optimal. Unlike its lossless counterpart, however,\nthe problem eludes a complete characterization. \n\n"}
{"id": "0911.4219", "contents": "Title: Message Passing Algorithms for Compressed Sensing: I. Motivation and\n  Construction Abstract: In a recent paper, the authors proposed a new class of low-complexity\niterative thresholding algorithms for reconstructing sparse signals from a\nsmall set of linear measurements \\cite{DMM}. The new algorithms are broadly\nreferred to as AMP, for approximate message passing. This is the first of two\nconference papers describing the derivation of these algorithms, connection\nwith the related literature, extensions of the original framework, and new\nempirical evidence.\n  In particular, the present paper outlines the derivation of AMP from standard\nsum-product belief propagation, and its extension in several directions. We\nalso discuss relations with formal calculations based on statistical mechanics\nmethods. \n\n"}
{"id": "0911.4521", "contents": "Title: On the equivalence between minimal sufficient statistics, minimal\n  typical models and initial segments of the Halting sequence Abstract: It is shown that the length of the algorithmic minimal sufficient statistic\nof a binary string x, either in a representation of a finite set, computable\nsemimeasure, or a computable function, has a length larger than the\ncomputational depth of x, and can solve the Halting problem for all programs\nwith length shorter than the m-depth of x. It is also shown that there are\nstrings for which the algorithmic minimal sufficient statistics can contain a\nsubstantial amount of information that is not Halting information. The weak\nsufficient statistic is introduced, and it is shown that a minimal weak\nsufficient statistic for x is equivalent to a minimal typical model of x, and\nto the Halting problem for all strings shorter than the BB-depth of x. \n\n"}
{"id": "0911.5106", "contents": "Title: A conversion between utility and information Abstract: Rewards typically express desirabilities or preferences over a set of\nalternatives. Here we propose that rewards can be defined for any probability\ndistribution based on three desiderata, namely that rewards should be\nreal-valued, additive and order-preserving, where the latter implies that more\nprobable events should also be more desirable. Our main result states that\nrewards are then uniquely determined by the negative information content. To\nanalyze stochastic processes, we define the utility of a realization as its\nreward rate. Under this interpretation, we show that the expected utility of a\nstochastic process is its negative entropy rate. Furthermore, we apply our\nresults to analyze agent-environment interactions. We show that the expected\nutility that will actually be achieved by the agent is given by the negative\ncross-entropy from the input-output (I/O) distribution of the coupled\ninteraction system and the agent's I/O distribution. Thus, our results allow\nfor an information-theoretic interpretation of the notion of utility and the\ncharacterization of agent-environment interactions in terms of entropy\ndynamics. \n\n"}
{"id": "0911.5509", "contents": "Title: Interference Alignment Under Limited Feedback for MIMO Interference\n  Channels Abstract: While interference alignment schemes have been employed to realize the full\nmultiplexing gain of $K$-user interference channels, the analyses performed so\nfar have predominantly focused on the case when global channel knowledge is\navailable at each node of the network. This paper considers the problem where\neach receiver knows its channels from all the transmitters and feeds back this\ninformation using a limited number of bits to all other terminals. In\nparticular, channel quantization over the composite Grassmann manifold is\nproposed and analyzed. It is shown, for $K$-user multiple-input,\nmultiple-output (MIMO) interference channels, that when the transmitters use an\ninterference alignment strategy as if the quantized channel estimates obtained\nvia this limited feedback are perfect, the full sum degrees of freedom of the\ninterference channel can be achieved as long as the feedback bit rate scales\nsufficiently fast with the signal-to-noise ratio. Moreover, this is only one\nextreme point of a continuous tradeoff between achievable degrees of freedom\nregion and user feedback rate scalings which are allowed to be non-identical.\nIt is seen that a slower scaling of feedback rate for any one user leads to\ncommensurately fewer degrees of freedom for that user alone. \n\n"}
{"id": "0911.5667", "contents": "Title: End-to-End Algebraic Network Coding for Wireless TCP/IP Networks Abstract: The Transmission Control Protocol (TCP) was designed to provide reliable\ntransport services in wired networks. In such networks, packet losses mainly\noccur due to congestion. Hence, TCP was designed to apply congestion avoidance\ntechniques to cope with packet losses. Nowadays, TCP is also utilized in\nwireless networks where, besides congestion, numerous other reasons for packet\nlosses exist. This results in reduced throughput and increased transmission\nround-trip time when the state of the wireless channel is bad. We propose a new\nnetwork layer, that transparently sits below the transport layer and hides non\ncongestion-imposed packet losses from TCP. The network coding in this new layer\nis based on the well-known class of Maximum Distance Separable (MDS) codes. \n\n"}
{"id": "0912.0868", "contents": "Title: Interference Alignment in Dense Wireless Networks Abstract: We consider arbitrary dense wireless networks, in which $n$ nodes are placed\nin an arbitrary (deterministic) manner on a square region of unit area and\ncommunicate with each other over Gaussian fading channels. We provide inner and\nouter bounds for the $n\\times n$-dimensional unicast and the $n\\times\n2^n$-dimensional multicast capacity regions of such a wireless network. These\ninner and outer bounds differ only by a factor $O(\\log(n))$, yielding a fairly\ntight scaling characterization of the entire regions. The communication schemes\nachieving the inner bounds use interference alignment as a central technique\nand are, at least conceptually, surprisingly simple. \n\n"}
{"id": "0912.2828", "contents": "Title: Pulse Shaping, Localization and the Approximate Eigenstructure of LTV\n  Channels Abstract: In this article we show the relation between the theory of pulse shaping for\nWSSUS channels and the notion of approximate eigenstructure for time-varying\nchannels. We consider pulse shaping for a general signaling scheme, called\nWeyl-Heisenberg signaling, which includes OFDM with cyclic prefix and\nOFDM/OQAM. The pulse design problem in the view of optimal WSSUS--averaged SINR\nis an interplay between localization and \"orthogonality\". The localization\nproblem itself can be expressed in terms of eigenvalues of localization\noperators and is intimately connected to the concept of approximate\neigenstructure of LTV channel operators. In fact, on the L_2-level both are\nequivalent as we will show. The concept of \"orthogonality\" in turn can be\nrelated to notion of tight frames. The right balance between these two sides is\nstill an open problem. However, several statements on achievable values of\ncertain localization measures and fundamental limits on SINR can already be\nmade as will be shown in the paper. \n\n"}
{"id": "0912.3245", "contents": "Title: Structured Error Recovery for Codeword-Stabilized Quantum Codes Abstract: Codeword stabilized (CWS) codes are, in general, non-additive quantum codes\nthat can correct errors by an exhaustive search of different error patterns,\nsimilar to the way that we decode classical non-linear codes. For an n-qubit\nquantum code correcting errors on up to t qubits, this brute-force approach\nconsecutively tests different errors of weight t or less, and employs a\nseparate n-qubit measurement in each test. In this paper, we suggest an error\ngrouping technique that allows to simultaneously test large groups of errors in\na single measurement. This structured error recovery technique exponentially\nreduces the number of measurements by about 3^t times. While it still leaves\nexponentially many measurements for a generic CWS code, the technique is\nequivalent to syndrome-based recovery for the special case of additive CWS\ncodes. \n\n"}
{"id": "0912.4995", "contents": "Title: 1-State Error-Trellis Decoding of LDPC Convolutional Codes Based on\n  Circulant Matrices Abstract: We consider the decoding of convolutional codes using an error trellis\nconstructed based on a submatrix of a given check matrix. In the proposed\nmethod, the syndrome-subsequence computed using the remaining submatrix is\nutilized as auxiliary information for decoding. Then the ML error path is\ncorrectly decoded using the degenerate error trellis. We also show that the\ndecoding complexity of the proposed method is basically identical with that of\nthe conventional one based on the original error trellis. Next, we apply the\nmethod to check matrices with monomial entries proposed by Tanner et al. By\nchoosing any row of the check matrix as the submatrix for error-trellis\nconstruction, a 1-state error trellis is obtained. Noting the fact that a\nlikelihood-concentration on the all-zero state and the states with many 0's\noccurs in the error trellis, we present a simplified decoding method based on a\n1-state error trellis, from which decoding-complexity reduction is realized. \n\n"}
{"id": "1001.0357", "contents": "Title: Orthogonal vs Non-Orthogonal Multiple Access with Finite Input Alphabet\n  and Finite Bandwidth Abstract: For a two-user Gaussian multiple access channel (GMAC), frequency division\nmultiple access (FDMA), a well known orthogonal-multiple-access (O-MA) scheme\nhas been preferred to non-orthogonal-multiple-access (NO-MA) schemes since FDMA\ncan achieve the sum-capacity of the channel with only single-user decoding\ncomplexity [\\emph{Chapter 14, Elements of Information Theory by Cover and\nThomas}]. However, with finite alphabets, in this paper, we show that NO-MA is\nbetter than O-MA for a two-user GMAC. We plot the constellation constrained\n(CC) capacity regions of a two-user GMAC with FDMA and time division multiple\naccess (TDMA) and compare them with the CC capacity regions with trellis coded\nmultiple access (TCMA), a recently introduced NO-MA scheme. Unlike the Gaussian\nalphabets case, it is shown that the CC capacity region with FDMA is strictly\ncontained inside the CC capacity region with TCMA. In particular, for a given\nbandwidth, the gap between the CC capacity regions with TCMA and FDMA is shown\nto increase with the increase in the average power constraint. Also, for a\ngiven power constraint, the gap between the CC capacity regions with TCMA and\nFDMA is shown to decrease with the increase in the bandwidth. Hence, for finite\nalphabets, a NO-MA scheme such as TCMA is better than the well known O-MAC\nschemes, FDMA and TDMA which makes NO-MA schemes worth pursuing in practice for\na two-user GMAC. \n\n"}
{"id": "1001.1679", "contents": "Title: Cascade and Triangular Source Coding with Side Information at the First\n  Two Nodes Abstract: We consider the cascade and triangular rate-distortion problem where side\ninformation is known to the source encoder and to the first user but not to the\nsecond user. We characterize the rate-distortion region for these problems. For\nthe quadratic Gaussian case, we show that it is sufficient to consider jointly\nGaussian distributions, a fact that leads to an explicit solution. \n\n"}
{"id": "1001.2228", "contents": "Title: Estimation with Random Linear Mixing, Belief Propagation and Compressed\n  Sensing Abstract: We apply Guo and Wang's relaxed belief propagation (BP) method to the\nestimation of a random vector from linear measurements followed by a\ncomponentwise probabilistic measurement channel. Relaxed BP uses a Gaussian\napproximation in standard BP to obtain significant computational savings for\ndense measurement matrices. The main contribution of this paper is to extend\nthe relaxed BP method and analysis to general (non-AWGN) output channels.\nSpecifically, we present detailed equations for implementing relaxed BP for\ngeneral channels and show that relaxed BP has an identical asymptotic large\nsparse limit behavior as standard BP, as predicted by the Guo and Wang's state\nevolution (SE) equations. Applications are presented to compressed sensing and\nestimation with bounded noise. \n\n"}
{"id": "1001.4120", "contents": "Title: Sum-Capacity and the Unique Separability of the Parallel Gaussian\n  MAC-Z-BC Network Abstract: It is known that the capacity of parallel (e.g., multi-carrier) Gaussian\npoint-to-point, multiple access and broadcast channels can be achieved by\nseparate encoding for each subchannel (carrier) subject to a power allocation\nacross carriers. Recent results have shown that parallel interference channels\nare not separable, i.e., joint coding is needed to achieve capacity in general.\nThis work studies the separability, from a sum-capacity perspective, of single\nhop Gaussian interference networks with independent messages and arbitrary\nnumber of transmitters and receivers. The main result is that the only network\nthat is always (for all values of channel coefficients) separable from a\nsum-capacity perspective is the MAC-Z-BC network, i.e., a network where a MAC\ncomponent and a BC component are linked by a Z component. The sum capacity of\nthis network is explicitly characterized. \n\n"}
{"id": "1001.5454", "contents": "Title: Non-Equilibrium Statistical Physics of Currents in Queuing Networks Abstract: We consider a stable open queuing network as a steady non-equilibrium system\nof interacting particles. The network is completely specified by its underlying\ngraphical structure, type of interaction at each node, and the Markovian\ntransition rates between nodes. For such systems, we ask the question ``What is\nthe most likely way for large currents to accumulate over time in a network\n?'', where time is large compared to the system correlation time scale. We\nidentify two interesting regimes. In the first regime, in which the\naccumulation of currents over time exceeds the expected value by a small to\nmoderate amount (moderate large deviation), we find that the large-deviation\ndistribution of currents is universal (independent of the interaction details),\nand there is no long-time and averaged over time accumulation of particles\n(condensation) at any nodes. In the second regime, in which the accumulation of\ncurrents over time exceeds the expected value by a large amount (severe large\ndeviation), we find that the large-deviation current distribution is sensitive\nto interaction details, and there is a long-time accumulation of particles\n(condensation) at some nodes. The transition between the two regimes can be\ndescribed as a dynamical second order phase transition. We illustrate these\nideas using the simple, yet non-trivial, example of a single node with\nfeedback. \n\n"}
{"id": "1002.2813", "contents": "Title: Distributed Rate Allocation for Wireless Networks Abstract: This paper develops a distributed algorithm for rate allocation in wireless\nnetworks that achieves the same throughput region as optimal centralized\nalgorithms. This cross-layer algorithm jointly performs medium access control\n(MAC) and physical-layer rate adaptation. The paper establishes that this\nalgorithm is throughput-optimal for general rate regions. In contrast to on-off\nscheduling, rate allocation enables optimal utilization of physical-layer\nschemes by scheduling multiple rate levels. The algorithm is based on local\nqueue-length information, and thus the algorithm is of significant practical\nvalue. The algorithm requires that each link can determine the global\nfeasibility of increasing its current data-rate. In many classes of networks,\nany one link's data-rate primarily impacts its neighbors and this impact decays\nwith distance. Hence, local exchanges can provide the information needed to\ndetermine feasibility. Along these lines, the paper discusses the potential use\nof existing physical-layer control messages to determine feasibility. This can\nbe considered as a technique analogous to carrier sensing in CSMA (Carrier\nSense Multiple Access) networks. An important application of this algorithm is\nin multiple-band multiple-radio throughput-optimal distributed scheduling for\nwhite-space networks. \n\n"}
{"id": "1002.4759", "contents": "Title: On the order bounds for one-point AG codes Abstract: The order bound for the minimum distance of algebraic geometry codes was\noriginally defined for the duals of one-point codes and later generalized for\narbitrary algebraic geometry codes. Another bound of order type for the minimum\ndistance of general linear codes, and for codes from order domains in\nparticular, was given in [H. Andersen and O. Geil, Evaluation codes from order\ndomain theory, Finite Fields and their Applications 14 (2008), pp. 92-123].\nHere we investigate in detail the application of that bound to one-point\nalgebraic geometry codes, obtaining a bound $d^*$ for the minimum distance of\nthese codes. We establish a connection between $d^*$ and the order bound and\nits generalizations. We also study the improved code constructions based on\n$d^*$. Finally we extend $d^*$ to all generalized Hamming weights. \n\n"}
{"id": "1003.2454", "contents": "Title: Decoding Complexity of Irregular LDGM-LDPC Codes Over the BISOM Channels Abstract: An irregular LDGM-LDPC code is studied as a sub-code of an LDPC code with\nsome randomly \\emph{punctured} output-bits. It is shown that the LDGM-LDPC\ncodes achieve rates arbitrarily close to the channel-capacity of the\nbinary-input symmetric-output memoryless (BISOM) channel with bounded\n\\emph{complexity}. The measure of complexity is the average-degree (per\ninformation-bit) of the check-nodes for the factor-graph of the code. A\nlower-bound on the average degree of the check-nodes of the irregular LDGM-LDPC\ncodes is obtained. The bound does not depend on the decoder used at the\nreceiver. The stability condition for decoding the irregular LDGM-LDPC codes\nover the binary-erasure channel (BEC) under iterative-decoding with\nmessage-passing is described. \n\n"}
{"id": "1003.2782", "contents": "Title: Reduced ML-Decoding Complexity, Full-Rate STBCs for $2^a$ Transmit\n  Antenna Systems Abstract: For an $n_t$ transmit, $n_r$ receive antenna system ($n_t \\times n_r$\nsystem), a {\\it{full-rate}} space time block code (STBC) transmits $n_{min} =\nmin(n_t,n_r)$ complex symbols per channel use and in general, has an\nML-decoding complexity of the order of $M^{n_tn_{min}}$ (considering square\ndesigns), where $M$ is the constellation size. In this paper, a scheme to\nobtain a full-rate STBC for $2^a$ transmit antennas and any $n_r$, with reduced\nML-decoding complexity of the order of $M^{n_t(n_{min}-3/4)}$, is presented.\nThe weight matrices of the proposed STBC are obtained from the unitary matrix\nrepresentations of a Clifford Algebra. For any value of $n_r$, the proposed\ndesign offers a reduction from the full ML-decoding complexity by a factor of\n$M^{3n_t/4}}$. The well known Silver code for 2 transmit antennas is a special\ncase of the proposed scheme. Further, it is shown that the codes constructed\nusing the scheme have higher ergodic capacity than the well known punctured\nPerfect codes for $n_r < n_t$. Simulation results of the symbol error rates are\nshown for $8 \\times 2$ systems, where the comparison of the proposed code is\nwith the punctured Perfect code for 8 transmit antennas. The proposed code\nmatches the punctured perfect code in error performance, while having reduced\nML-decoding complexity and higher ergodic capacity. \n\n"}
{"id": "1004.5070", "contents": "Title: Multichannel Sampling of Pulse Streams at the Rate of Innovation Abstract: We consider minimal-rate sampling schemes for infinite streams of delayed and\nweighted versions of a known pulse shape. The minimal sampling rate for these\nparametric signals is referred to as the rate of innovation and is equal to the\nnumber of degrees of freedom per unit time. Although sampling of infinite pulse\nstreams was treated in previous works, either the rate of innovation was not\nachieved, or the pulse shape was limited to Diracs. In this paper we propose a\nmultichannel architecture for sampling pulse streams with arbitrary shape,\noperating at the rate of innovation. Our approach is based on modulating the\ninput signal with a set of properly chosen waveforms, followed by a bank of\nintegrators. This architecture is motivated by recent work on sub-Nyquist\nsampling of multiband signals. We show that the pulse stream can be recovered\nfrom the proposed minimal-rate samples using standard tools taken from spectral\nestimation in a stable way even at high rates of innovation. In addition, we\naddress practical implementation issues, such as reduction of hardware\ncomplexity and immunity to failure in the sampling channels. The resulting\nscheme is flexible and exhibits better noise robustness than previous\napproaches. \n\n"}
{"id": "1005.0202", "contents": "Title: Dictionary Optimization for Block-Sparse Representations Abstract: Recent work has demonstrated that using a carefully designed dictionary\ninstead of a predefined one, can improve the sparsity in jointly representing a\nclass of signals. This has motivated the derivation of learning methods for\ndesigning a dictionary which leads to the sparsest representation for a given\nset of signals. In some applications, the signals of interest can have further\nstructure, so that they can be well approximated by a union of a small number\nof subspaces (e.g., face recognition and motion segmentation). This implies the\nexistence of a dictionary which enables block-sparse representations of the\ninput signals once its atoms are properly sorted into blocks. In this paper, we\npropose an algorithm for learning a block-sparsifying dictionary of a given set\nof signals. We do not require prior knowledge on the association of signals\ninto groups (subspaces). Instead, we develop a method that automatically\ndetects the underlying block structure. This is achieved by iteratively\nalternating between updating the block structure of the dictionary and updating\nthe dictionary atoms to better fit the data. Our experiments show that for\nblock-sparse data the proposed algorithm significantly improves the dictionary\nrecovery ability and lowers the representation error compared to dictionary\nlearning methods that do not employ block structure. \n\n"}
{"id": "1005.2839", "contents": "Title: Construction of Codes for Network Coding Abstract: Based on ideas of K\\\"otter and Kschischang we use constant dimension\nsubspaces as codewords in a network. We show a connection to the theory of\nq-analogues of a combinatorial designs, which has been studied in Braun, Kerber\nand Laue as a purely combinatorial object. For the construction of network\ncodes we successfully modified methods (construction with prescribed\nautomorphisms) originally developed for the q-analogues of a combinatorial\ndesigns. We then give a special case of that method which allows the\nconstruction of network codes with a very large ambient space and we also show\nhow to decode such codes with a very small number of operations. \n\n"}
{"id": "1005.4769", "contents": "Title: A Network Coding Approach to Loss Tomography Abstract: Network tomography aims at inferring internal network characteristics based\non measurements at the edge of the network. In loss tomography, in particular,\nthe characteristic of interest is the loss rate of individual links and\nmulticast and/or unicast end-to-end probes are typically used. Independently,\nrecent advances in network coding have shown that there are advantages from\nallowing intermediate nodes to process and combine, in addition to just\nforward, packets. In this paper, we study the problem of loss tomography in\nnetworks with network coding capabilities. We design a framework for estimating\nlink loss rates, which leverages network coding capabilities, and we show that\nit improves several aspects of tomography including the identifiability of\nlinks, the trade-off between estimation accuracy and bandwidth efficiency, and\nthe complexity of probe path selection. We discuss the cases of inferring link\nloss rates in a tree topology and in a general topology. In the latter case,\nthe benefits of our approach are even more pronounced compared to standard\ntechniques, but we also face novel challenges, such as dealing with cycles and\nmultiple paths between sources and receivers. Overall, this work makes the\nconnection between active network tomography and network coding. \n\n"}
{"id": "1005.5591", "contents": "Title: On the minimum weight problem of permutation codes under Chebyshev\n  distance Abstract: Permutation codes of length $n$ and distance $d$ is a set of permutations on\n$n$ symbols, where the distance between any two elements in the set is at least\n$d$. Subgroup permutation codes are permutation codes with the property that\nthe elements are closed under the operation of composition. In this paper,\nunder the distance metric $\\ell_{\\infty}$-norm, we prove that finding the\nminimum weight codeword for subgroup permutation code is NP-complete. Moreover,\nwe show that it is NP-hard to approximate the minimum weight within the factor\n$7/6-\\epsilon$ for any $\\epsilon>0$. \n\n"}
{"id": "1006.3360", "contents": "Title: Base station cooperation on the downlink: Large system analysis Abstract: This paper considers maximizing the network-wide minimum supported rate in\nthe downlink of a two-cell system, where each base station (BS) is endowed with\nmultiple antennas. This is done for different levels of cell cooperation. At\none extreme, we consider single cell processing where the BS is oblivious to\nthe interference it is creating at the other cell. At the other extreme, we\nconsider full cooperative macroscopic beamforming. In between, we consider\ncoordinated beamforming, which takes account of inter-cell interference, but\ndoes not require full cooperation between the BSs. We combine elements of\nLagrangian duality and large system analysis to obtain limiting SINRs and\nbit-rates, allowing comparison between the considered schemes. The main\ncontributions of the paper are theorems which provide concise formulas for\noptimal transmit power, beamforming vectors, and achieved signal to\ninterference and noise ratio (SINR) for the considered schemes. The formulas\nobtained are valid for the limit in which the number of users per cell, K, and\nthe number of antennas per base station, N, tend to infinity, with fixed ratio.\nThese theorems also provide expressions for the effective bandwidths occupied\nby users, and the effective interference caused in the adjacent cell, which\nallow direct comparisons between the considered schemes. \n\n"}
{"id": "1007.0267", "contents": "Title: Interference Channel with an Out-of-Band Relay Abstract: A Gaussian interference channel (IC) with a relay is considered. The relay is\nassumed to operate over an orthogonal band with respect to the underlying IC,\nand the overall system is referred to as IC with an out-of-band relay (IC-OBR).\nThe system can be seen as operating over two parallel interference-limited\nchannels: The first is a standard Gaussian IC and the second is a Gaussian\nrelay channel characterized by two sources and destinations communicating\nthrough the relay without direct links. We refer to the second parallel channel\nas OBR Channel (OBRC). The main aim of this work is to identify conditions\nunder which optimal operation, in terms of the capacity region of the IC-OBR,\nentails either signal relaying and/or interference forwarding by the relay,\nwith either a separable or non-separable use of the two parallel channels, IC\nand OBRC. Here \"separable\" refers to transmission of independent information\nover the two constituent channels. For a basic model in which the OBRC consists\nof four orthogonal channels from sources to relay and from relay to\ndestinations (IC-OBR Type-I), a condition is identified under which signal\nrelaying and separable operation is optimal. When this condition is not\nsatisfied, various scenarios are identified in which interference forwarding\nand non-separable operation are necessary to achieve optimal performance. In\nthese scenarios, the system exploits the \"excess capacity\" on the OBRC via\ninterference forwarding to drive the IC-OBR system in specific interference\nregimes (strong or mixed). The analysis is then turned to a more complex\nIC-OBR, in which the OBRC consists of only two orthogonal channels, one from\nsources to relay and one from relay to destinations (IC-OBR Type-II). For this\nchannel, some capacity resuls are derived that parallel the conclusions for\nIC-OBR Type-I. \n\n"}
{"id": "1007.0528", "contents": "Title: Binary Independent Component Analysis with OR Mixtures Abstract: Independent component analysis (ICA) is a computational method for separating\na multivariate signal into subcomponents assuming the mutual statistical\nindependence of the non-Gaussian source signals. The classical Independent\nComponents Analysis (ICA) framework usually assumes linear combinations of\nindependent sources over the field of realvalued numbers R. In this paper, we\ninvestigate binary ICA for OR mixtures (bICA), which can find applications in\nmany domains including medical diagnosis, multi-cluster assignment, Internet\ntomography and network resource management. We prove that bICA is uniquely\nidentifiable under the disjunctive generation model, and propose a\ndeterministic iterative algorithm to determine the distribution of the latent\nrandom variables and the mixing matrix. The inverse problem concerning\ninferring the values of latent variables are also considered along with noisy\nmeasurements. We conduct an extensive simulation study to verify the\neffectiveness of the propose algorithm and present examples of real-world\napplications where bICA can be applied. \n\n"}
{"id": "1007.1209", "contents": "Title: Prime Factor Cyclotomic Fourier Transforms with Reduced Complexity over\n  Finite Fields Abstract: Discrete Fourier transforms~(DFTs) over finite fields have widespread\napplications in error correction coding. Hence, reducing the computational\ncomplexities of DFTs is of great significance, especially for long DFTs as\nincreasingly longer error control codes are chosen for digital communication\nand storage systems. Since DFTs involve both multiplications and additions over\nfinite fields and multiplications are much more complex than additions,\nrecently proposed cyclotomic fast Fourier transforms (CFFTs) are promising due\nto their low multiplicative complexity. Unfortunately, they have very high\nadditive complexity. Techniques such as common subexpression elimination (CSE)\ncan be used to reduce the additive complexity of CFFTs, but their effectiveness\nfor long DFTs is limited by their complexity. In this paper, we propose prime\nfactor cyclotomic Fourier transforms (PFCFTs), which use CFFTs as sub-DFTs via\nthe prime factor algorithm. When the length of DFTs is prime, our PFCFTs reduce\nto CFFTs. When the length has co-prime factors, since the sub-DFTs have much\nshorter lengths, this allows us to use CSE to significantly reduce their\nadditive complexity. In comparison to previously proposed fast Fourier\ntransforms, our PFCFTs achieve reduced overall complexity when the length of\nDFTs is at least 255, and the improvement significantly increases as the length\ngrows. This approach also enables us to propose efficient DFTs with very long\nlength (e.g., 4095-point), first efficient DFTs of such lengths in the\nliterature. Finally, our PFCFTs are also advantageous for hardware\nimplementation due to their regular structure. \n\n"}
{"id": "1007.3424", "contents": "Title: Bacterial Community Reconstruction Using A Single Sequencing Reaction Abstract: Bacteria are the unseen majority on our planet, with millions of species and\ncomprising most of the living protoplasm. While current methods enable in-depth\nstudy of a small number of communities, a simple tool for breadth studies of\nbacterial population composition in a large number of samples is lacking. We\npropose a novel approach for reconstruction of the composition of an unknown\nmixture of bacteria using a single Sanger-sequencing reaction of the mixture.\nThis method is based on compressive sensing theory, which deals with\nreconstruction of a sparse signal using a small number of measurements.\nUtilizing the fact that in many cases each bacterial community is comprised of\na small subset of the known bacterial species, we show the feasibility of this\napproach for determining the composition of a bacterial mixture. Using\nsimulations, we show that sequencing a few hundred base-pairs of the 16S rRNA\ngene sequence may provide enough information for reconstruction of mixtures\ncontaining tens of species, out of tens of thousands, even in the presence of\nrealistic measurement noise. Finally, we show initial promising results when\napplying our method for the reconstruction of a toy experimental mixture with\nfive species. Our approach may have a potential for a practical and efficient\nway for identifying bacterial species compositions in biological samples. \n\n"}
{"id": "1007.3661", "contents": "Title: Non-Binary Polar Codes using Reed-Solomon Codes and Algebraic Geometry\n  Codes Abstract: Polar codes, introduced by Arikan, achieve symmetric capacity of any discrete\nmemoryless channels under low encoding and decoding complexity. Recently,\nnon-binary polar codes have been investigated. In this paper, we calculate\nerror probability of non-binary polar codes constructed on the basis of\nReed-Solomon matrices by numerical simulations. It is confirmed that 4-ary\npolar codes have significantly better performance than binary polar codes on\nbinary-input AWGN channel. We also discuss an interpretation of polar codes in\nterms of algebraic geometry codes, and further show that polar codes using\nHermitian codes have asymptotically good performance. \n\n"}
{"id": "1007.4002", "contents": "Title: Continuum Percolation in the Intrinsically Secure Communications Graph Abstract: The intrinsically secure communications graph (iS-graph) is a random graph\nwhich captures the connections that can be securely established over a\nlarge-scale network, in the presence of eavesdroppers. It is based on\nprinciples of information-theoretic security, widely accepted as the strictest\nnotion of security. In this paper, we are interested in characterizing the\nglobal properties of the iS-graph in terms of percolation on the infinite\nplane. We prove the existence of a phase transition in the Poisson iS-graph,\nwhereby an unbounded component of securely connected nodes suddenly arises as\nwe increase the density of legitimate nodes. Our work shows that long-range\ncommunication in a wireless network is still possible when a secrecy constraint\nis present. \n\n"}
{"id": "1008.0420", "contents": "Title: Modeling Network Coded TCP Throughput: A Simple Model and its Validation Abstract: We analyze the performance of TCP and TCP with network coding (TCP/NC) in\nlossy wireless networks. We build upon the simple framework introduced by\nPadhye et al. and characterize the throughput behavior of classical TCP as well\nas TCP/NC as a function of erasure rate, round-trip time, maximum window size,\nand duration of the connection. Our analytical results show that network coding\nmasks erasures and losses from TCP, thus preventing TCP's performance\ndegradation in lossy networks, such as wireless networks. It is further seen\nthat TCP/NC has significant throughput gains over TCP. In addition, we simulate\nTCP and TCP/NC to verify our analysis of the average throughput and the window\nevolution. Our analysis and simulation results show very close concordance and\nsupport that TCP/NC is robust against erasures. TCP/NC is not only able to\nincrease its window size faster but also to maintain a large window size\ndespite losses within the network, whereas TCP experiences window closing\nessentially because losses are mistakenly attributed to congestion. \n\n"}
{"id": "1008.0919", "contents": "Title: Compressive Sensing over Graphs Abstract: In this paper, motivated by network inference and tomography applications, we\nstudy the problem of compressive sensing for sparse signal vectors over graphs.\nIn particular, we are interested in recovering sparse vectors representing the\nproperties of the edges from a graph. Unlike existing compressive sensing\nresults, the collective additive measurements we are allowed to take must\nfollow connected paths over the underlying graph. For a sufficiently connected\ngraph with $n$ nodes, it is shown that, using $O(k \\log(n))$ path measurements,\nwe are able to recover any $k$-sparse link vector (with no more than $k$\nnonzero elements), even though the measurements have to follow the graph path\nconstraints. We further show that the computationally efficient $\\ell_1$\nminimization can provide theoretical guarantees for inferring such $k$-sparse\nvectors with $O(k \\log(n))$ path measurements from the graph. \n\n"}
{"id": "1008.1284", "contents": "Title: Ideal forms of Coppersmith's theorem and Guruswami-Sudan list decoding Abstract: We develop a framework for solving polynomial equations with size constraints\non solutions. We obtain our results by showing how to apply a technique of\nCoppersmith for finding small solutions of polynomial equations modulo integers\nto analogous problems over polynomial rings, number fields, and function\nfields. This gives us a unified view of several problems arising naturally in\ncryptography, coding theory, and the study of lattices. We give (1) a\npolynomial-time algorithm for finding small solutions of polynomial equations\nmodulo ideals over algebraic number fields, (2) a faster variant of the\nGuruswami-Sudan algorithm for list decoding of Reed-Solomon codes, and (3) an\nalgorithm for list decoding of algebraic-geometric codes that handles both\nsingle-point and multi-point codes. Coppersmith's algorithm uses lattice basis\nreduction to find a short vector in a carefully constructed lattice; powerful\nanalogies from algebraic number theory allow us to identify the appropriate\nanalogue of a lattice in each application and provide efficient algorithms to\nfind a suitably short vector, thus allowing us to give completely parallel\nproofs of the above theorems. \n\n"}
{"id": "1008.2529", "contents": "Title: Quantum f-divergences and error correction Abstract: Quantum f-divergences are a quantum generalization of the classical notion of\nf-divergences, and are a special case of Petz' quasi-entropies. Many well known\ndistinguishability measures of quantum states are given by, or derived from,\nf-divergences; special examples include the quantum relative entropy, the Renyi\nrelative entropies, and the Chernoff and Hoeffding measures. Here we show that\nthe quantum f-divergences are monotonic under the dual of Schwarz maps whenever\nthe defining function is operator convex. This extends and unifies all\npreviously known monotonicity results. We also analyze the case where the\nmonotonicity inequality holds with equality, and extend Petz' reversibility\ntheorem for a large class of f-divergences and other distinguishability\nmeasures. We apply our findings to the problem of quantum error correction, and\nshow that if a stochastic map preserves the pairwise distinguishability on a\nset of states, as measured by a suitable f-divergence, then its action can be\nreversed on that set by another stochastic map that can be constructed from the\noriginal one in a canonical way. We also provide an integral representation for\noperator convex functions on the positive half-line, which is the main\ningredient in extending previously known results on the monotonicity inequality\nand the case of equality. We also consider some special cases where the\nconvexity of f is sufficient for the monotonicity, and obtain the inverse\nHolder inequality for operators as an application. The presentation is\ncompletely self-contained and requires only standard knowledge of matrix\nanalysis. \n\n"}
{"id": "1008.3295", "contents": "Title: Optimal relay location and power allocation for low SNR broadcast relay\n  channels Abstract: We consider the broadcast relay channel (BRC), where a single source\ntransmits to multiple destinations with the help of a relay, in the limit of a\nlarge bandwidth. We address the problem of optimal relay positioning and power\nallocations at source and relay, to maximize the multicast rate from source to\nall destinations. To solve such a network planning problem, we develop a\nthree-faceted approach based on an underlying information theoretic model,\ncomputational geometric aspects, and network optimization tools. Firstly,\nassuming superposition coding and frequency division between the source and the\nrelay, the information theoretic framework yields a hypergraph model of the\nwideband BRC, which captures the dependency of achievable rate-tuples on the\nnetwork topology. As the relay position varies, so does the set of hyperarcs\nconstituting the hypergraph, rendering the combinatorial nature of optimization\nproblem. We show that the convex hull C of all nodes in the 2-D plane can be\ndivided into disjoint regions corresponding to distinct hyperarcs sets. These\nsets are obtained by superimposing all k-th order Voronoi tessellation of C. We\npropose an easy and efficient algorithm to compute all hyperarc sets, and prove\nthey are polynomially bounded. Using the switched hypergraph approach, we model\nthe original problem as a continuous yet non-convex network optimization\nprogram. Ultimately, availing on the techniques of geometric programming and\n$p$-norm surrogate approximation, we derive a good convex approximation. We\nprovide a detailed characterization of the problem for collinearly located\ndestinations, and then give a generalization for arbitrarily located\ndestinations. Finally, we show strong gains for the optimal relay positioning\ncompared to seemingly interesting positions. \n\n"}
{"id": "1008.3705", "contents": "Title: Techniques for Enhanced Physical-Layer Security Abstract: Information-theoretic security--widely accepted as the strictest notion of\nsecurity--relies on channel coding techniques that exploit the inherent\nrandomness of propagation channels to strengthen the security of communications\nsystems. Within this paradigm, we explore strategies to improve secure\nconnectivity in a wireless network. We first consider the intrinsically secure\ncommunications graph (iS-graph), a convenient representation of the links that\ncan be established with information-theoretic security on a large-scale\nnetwork. We then propose and characterize two techniques--sectorized\ntransmission and eavesdropper neutralization--which are shown to dramatically\nenhance the connectivity of the iS-graph. \n\n"}
{"id": "1009.3090", "contents": "Title: Open-Loop Spatial Multiplexing and Diversity Communications in Ad Hoc\n  Networks Abstract: This paper investigates the performance of open-loop multi-antenna\npoint-to-point links in ad hoc networks with slotted ALOHA medium access\ncontrol (MAC). We consider spatial multiplexing transmission with linear\nmaximum ratio combining and zero forcing receivers, as well as orthogonal space\ntime block coded transmission. New closed-form expressions are derived for the\noutage probability, throughput and transmission capacity. Our results\ndemonstrate that both the best performing scheme and the optimum number of\ntransmit antennas depend on different network parameters, such as the node\nintensity and the signal-to-interference-and-noise ratio operating value. We\nthen compare the performance to a network consisting of single-antenna devices\nand an idealized fully centrally coordinated MAC. These results show that\nmulti-antenna schemes with a simple decentralized slotted ALOHA MAC can\noutperform even idealized single-antenna networks in various practical\nscenarios. \n\n"}
{"id": "1009.4046", "contents": "Title: Channel-coded Collision Resolution by Exploiting Symbol Misalignment Abstract: In random-access networks, such as the IEEE 802.11 network, different users\nmay transmit their packets simultaneously, resulting in packet collisions.\nTraditionally, the collided packets are simply discarded. To improve\nperformance, advanced signal processing techniques can be applied to extract\nthe individual packets from the collided signals. Prior work of ours has shown\nthat the symbol misalignment among the collided packets can be exploited to\nimprove the likelihood of successfully extracting the individual packets.\nHowever, the failure rate is still unacceptably high. This paper investigates\nhow channel coding can be used to reduce the failure rate. We propose and\ninvestigate a decoding scheme that incorporates the exploitation of the\naforementioned symbol misalignment into the channel decoding process. This is a\nfine-grained integration at the symbol level. In particular, collision\nresolution and channel decoding are applied in an integrated manner. Simulation\nresults indicate that our method outperforms other schemes, including the\nstraightforward method in which collision resolution and channel coding are\napplied separately. \n\n"}
{"id": "1010.0694", "contents": "Title: Statistical inference optimized with respect to the observed sample for\n  single or multiple comparisons Abstract: The normalized maximum likelihood (NML) is a recent penalized likelihood that\nhas properties that justify defining the amount of discrimination information\n(DI) in the data supporting an alternative hypothesis over a null hypothesis as\nthe logarithm of an NML ratio, namely, the alternative hypothesis NML divided\nby the null hypothesis NML. The resulting DI, like the Bayes factor but unlike\nthe p-value, measures the strength of evidence for an alternative hypothesis\nover a null hypothesis such that the probability of misleading evidence\nvanishes asymptotically under weak regularity conditions and such that evidence\ncan support a simple null hypothesis. Unlike the Bayes factor, the DI does not\nrequire a prior distribution and is minimax optimal in a sense that does not\ninvolve averaging over outcomes that did not occur. Replacing a (possibly\npseudo-) likelihood function with its weighted counterpart extends the scope of\nthe DI to models for which the unweighted NML is undefined. The likelihood\nweights leverage side information, either in data associated with comparisons\nother than the comparison at hand or in the parameter value of a simple null\nhypothesis. Two case studies, one involving multiple populations and the other\ninvolving multiple biological features, indicate that the DI is robust to the\ntype of side information used when that information is assigned the weight of a\nsingle observation. Such robustness suggests that very little adjustment for\nmultiple comparisons is warranted if the sample size is at least moderate. \n\n"}
{"id": "1010.0781", "contents": "Title: Transmission Capacity of Spectrum Sharing Ad-hoc Networks with Multiple\n  Antennas Abstract: Two coexisting ad-hoc networks, primary and secondary, are considered, where\neach node of the primary network has a single antenna, while each node of the\nsecondary network is equipped with multiple antennas. Using multiple antennas,\neach secondary transmitter uses some of its spatial transmit degrees of freedom\n(STDOF) to null its interference towards the primary receivers, while each\nsecondary receiver employs interference cancelation using some of its spatial\nreceive degrees of freedom (SRDOF). This paper derives the optimal STDOF for\nnulling and SRDOF for interference cancelation that maximize the scaling of the\ntransmission capacity of the secondary network with respect to the number of\nantennas, when the secondary network operates under an outage constraint at the\nprimary receivers. With a single receive antenna, using a fraction of the total\nSTDOF for nulling at each secondary transmitter maximizes the transmission\ncapacity. With multiple transmit and receive antennas and fixing all but one\nSTDOF for nulling, using a fraction of the total SRDOF to cancel the nearest\ninterferers maximizes the transmission capacity of the secondary network. \n\n"}
{"id": "1010.1309", "contents": "Title: Probing Capacity Abstract: We consider the problem of optimal probing of states of a channel by\ntransmitter and receiver for maximizing rate of reliable communication. The\nchannel is discrete memoryless (DMC) with i.i.d. states. The encoder takes\nprobing actions dependent on the message. It then uses the state information\nobtained from probing causally or non-causally to generate channel input\nsymbols. The decoder may also take channel probing actions as a function of the\nobserved channel output and use the channel state information thus acquired,\nalong with the channel output, to estimate the message. We refer to the maximum\nachievable rate for reliable communication for such systems as the 'Probing\nCapacity'. We characterize this capacity when the encoder and decoder actions\nare cost constrained. To motivate the problem, we begin by characterizing the\ntrade-off between the capacity and fraction of channel states the encoder is\nallowed to observe, while the decoder is aware of channel states. In this\nsetting of 'to observe or not to observe' state at the encoder, we compute\ncertain numerical examples and note a pleasing phenomenon, where encoder can\nobserve a relatively small fraction of states and yet communicate at maximum\nrate, i.e. rate when observing states at encoder is not cost constrained. \n\n"}
{"id": "1010.1648", "contents": "Title: Large-System Analysis of Multiuser Detection with an Unknown Number of\n  Users: A High-SNR Approach Abstract: We analyze multiuser detection under the assumption that the number of users\naccessing the channel is unknown by the receiver. In this environment, users'\nactivity must be estimated along with any other parameters such as data, power,\nand location. Our main goal is to determine the performance loss caused by the\nneed for estimating the identities of active users, which are not known a\npriori. To prevent a loss of optimality, we assume that identities and data are\nestimated jointly, rather than in two separate steps. We examine the\nperformance of multiuser detectors when the number of potential users is large.\nStatistical-physics methodologies are used to determine the macroscopic\nperformance of the detector in terms of its multiuser efficiency. Special\nattention is paid to the fixed-point equation whose solution yields the\nmultiuser efficiency of the optimal (maximum a posteriori) detector in the\nlarge signal-to-noise ratio regime. Our analysis yields closed-form approximate\nbounds to the minimum mean-squared error in this regime. These illustrate the\nset of solutions of the fixed-point equation, and their relationship with the\nmaximum system load. Next, we study the maximum load that the detector can\nsupport for a given quality of service (specified by error probability). \n\n"}
{"id": "1010.2667", "contents": "Title: Virtual Full-Duplex Wireless Communication via Rapid On-Off-Division\n  Duplex Abstract: This paper introduces a novel paradigm for design- ing the physical and\nmedium access control (MAC) layers of mobile ad hoc or peer-to-peer networks\nformed by half-duplex radios. A node equipped with such a radio cannot\nsimultaneously transmit and receive useful signals at the same frequency.\nUnlike in conventional designs, where a node's transmission frames are\nscheduled away from its reception, each node transmits its signal through a\nrandomly generated on-off duplex mask (or signature) over every frame interval,\nand receive a signal through each of its own off-slots. This is called rapid\non-off- division duplex (RODD). Over the period of a single frame, every node\ncan transmit a message to some or all of its peers, and may simultaneously\nreceive a message from each peer. Thus RODD achieves virtual full-duplex\ncommunication using half-duplex radios and can simplify the design of higher\nlayers of a network protocol stack significantly. The throughput of RODD is\nevaluated under some general settings, which is significantly larger than that\nof ALOHA. RODD is especially efficient in case the dominant traffic is\nsimultaneous broadcast from nodes to their one-hop peers, such as in\nspontaneous wireless social networks, emergency situations or on battlefield.\nImportant design issues of peer discovery, distribution of on-off signatures,\nsynchronization and error-control coding are also addressed. \n\n"}
{"id": "1010.2686", "contents": "Title: How to Achieve the Optimal DMT of Selective Fading MIMO Channels? Abstract: In this paper, we consider a particular class of selective fading channel\ncorresponding to a channel that is selective either in time or in frequency.\nFor this class of channel, we propose a systematic way to achieve the optimal\nDMT derived in Coronel and B\\\"olcskei, IEEE ISIT, 2007 by extending the\nnon-vanishing determinant (NVD) criterion to the selective channel case. A new\ncode construction based on split NVD parallel codes is then proposed to satisfy\nthe NVD parallel criterion. This result is of significant interest not only in\nits own right, but also because it settles a long-standing debate in the\nliterature related to the optimal DMT of selective fading channels. \n\n"}
{"id": "1010.2731", "contents": "Title: A Unified Framework for High-Dimensional Analysis of M-Estimators with\n  Decomposable Regularizers Abstract: High-dimensional statistical inference deals with models in which the the\nnumber of parameters p is comparable to or larger than the sample size n. Since\nit is usually impossible to obtain consistent procedures unless\n$p/n\\rightarrow0$, a line of recent work has studied models with various types\nof low-dimensional structure, including sparse vectors, sparse and structured\nmatrices, low-rank matrices and combinations thereof. In such settings, a\ngeneral approach to estimation is to solve a regularized optimization problem,\nwhich combines a loss function measuring how well the model fits the data with\nsome regularization function that encourages the assumed structure. This paper\nprovides a unified framework for establishing consistency and convergence rates\nfor such regularized M-estimators under high-dimensional scaling. We state one\nmain theorem and show how it can be used to re-derive some existing results,\nand also to obtain a number of new results on consistency and convergence\nrates, in both $\\ell_2$-error and related norms. Our analysis also identifies\ntwo key properties of loss and regularization functions, referred to as\nrestricted strong convexity and decomposability, that ensure corresponding\nregularized M-estimators have fast convergence rates and which are optimal in\nmany well-studied cases. \n\n"}
{"id": "1010.2993", "contents": "Title: Broadcasting with an Energy Harvesting Rechargeable Transmitter Abstract: In this paper, we investigate the transmission completion time minimization\nproblem in a two-user additive white Gaussian noise (AWGN) broadcast channel,\nwhere the transmitter is able to harvest energy from the nature, using a\nrechargeable battery. The harvested energy is modeled to arrive at the\ntransmitter randomly during the course of transmissions. The transmitter has a\nfixed number of packets to be delivered to each receiver. Our goal is to\nminimize the time by which all of the packets for both users are delivered to\ntheir respective destinations. To this end, we optimize the transmit powers and\ntransmission rates intended for both users. We first analyze the structural\nproperties of the optimal transmission policy. We prove that the optimal total\ntransmit power has the same structure as the optimal single-user transmit\npower. We also prove that there exists a cut-off power level for the stronger\nuser. If the optimal total transmit power is lower than this cut-off level, all\ntransmit power is allocated to the stronger user, and when the optimal total\ntransmit power is larger than this cut-off level, all transmit power above this\nlevel is allocated to the weaker user. Based on these structural properties of\nthe optimal policy, we propose an algorithm that yields the globally optimal\noff-line scheduling policy. Our algorithm is based on the idea of reducing the\ntwo-user broadcast channel problem into a single-user problem as much as\npossible. \n\n"}
{"id": "1010.4237", "contents": "Title: Robust PCA via Outlier Pursuit Abstract: Singular Value Decomposition (and Principal Component Analysis) is one of the\nmost widely used techniques for dimensionality reduction: successful and\nefficiently computable, it is nevertheless plagued by a well-known,\nwell-documented sensitivity to outliers. Recent work has considered the setting\nwhere each point has a few arbitrarily corrupted components. Yet, in\napplications of SVD or PCA such as robust collaborative filtering or\nbioinformatics, malicious agents, defective genes, or simply corrupted or\ncontaminated experiments may effectively yield entire points that are\ncompletely corrupted.\n  We present an efficient convex optimization-based algorithm we call Outlier\nPursuit, that under some mild assumptions on the uncorrupted points (satisfied,\ne.g., by the standard generative assumption in PCA problems) recovers the exact\noptimal low-dimensional subspace, and identifies the corrupted points. Such\nidentification of corrupted points that do not conform to the low-dimensional\napproximation, is of paramount interest in bioinformatics and financial\napplications, and beyond. Our techniques involve matrix decomposition using\nnuclear norm minimization, however, our results, setup, and approach,\nnecessarily differ considerably from the existing line of work in matrix\ncompletion and matrix decomposition, since we develop an approach to recover\nthe correct column space of the uncorrupted matrix, rather than the exact\nmatrix itself. In any problem where one seeks to recover a structure rather\nthan the exact initial matrices, techniques developed thus far relying on\ncertificates of optimality, will fail. We present an important extension of\nthese methods, that allows the treatment of such problems. \n\n"}
{"id": "1010.5720", "contents": "Title: Information-theoretic inference of common ancestors Abstract: A directed acyclic graph (DAG) partially represents the conditional\nindependence structure among observations of a system if the local Markov\ncondition holds, that is, if every variable is independent of its\nnon-descendants given its parents. In general, there is a whole class of DAGs\nthat represents a given set of conditional independence relations. We are\ninterested in properties of this class that can be derived from observations of\na subsystem only. To this end, we prove an information theoretic inequality\nthat allows for the inference of common ancestors of observed parts in any DAG\nrepresenting some unknown larger system. More explicitly, we show that a large\namount of dependence in terms of mutual information among the observations\nimplies the existence of a common ancestor that distributes this information.\nWithin the causal interpretation of DAGs our result can be seen as a\nquantitative extension of Reichenbach's Principle of Common Cause to more than\ntwo variables. Our conclusions are valid also for non-probabilistic\nobservations such as binary strings, since we state the proof for an\naxiomatized notion of mutual information that includes the stochastic as well\nas the algorithmic version. \n\n"}
{"id": "1011.1295", "contents": "Title: A Markovian Model for Joint Observations, Bell's Inequality and Hidden\n  States Abstract: While the standard approach to quantum systems studies length preserving\nlinear transformations of wave functions, the Markov picture focuses on trace\npreserving operators on the space of Hermitian (self-adjoint) matrices. The\nMarkov approach extends the standard one and provides a refined analysis of\nmeasurements and quantum Markov chains. In particular, Bell's inequality\nbecomes structurally clear. It turns out that hidden state models are natural\nin the Markov context. In particular, a violation of Bell's inequality is seen\nto be compatible with the existence of hidden states. The Markov model moreover\nclarifies the role of the \"negative probabilities\" in Feynman's analysis of the\nEPR paradox. \n\n"}
{"id": "1011.2109", "contents": "Title: On Secure Transmission over Parallel Relay Eavesdropper Channel Abstract: We study a four terminal parallel relay-eavesdropper channel which consists\nof multiple independent relay-eavesdropper channels as subchannels. For the\ndiscrete memoryless case, we establish inner and outer bounds on the\nrate-equivocation region. For each subchannel, secure transmission is obtained\nthrough one of the two coding schemes at the relay: decoding-and-forwarding the\nsource message or confusing the eavesdropper through noise injection. The inner\nbound allows relay mode selection. For the Gaussian model we establish lower\nand upper bounds on the perfect secrecy rate. We show that the bounds meet in\nsome special cases, including when the relay does not hear the source. We\nillustrate the analytical results through some numerical examples. \n\n"}
{"id": "1011.2740", "contents": "Title: Deterministic Compressed Sensing Matrices from Multiplicative Character\n  Sequences Abstract: Compressed sensing is a novel technique where one can recover sparse signals\nfrom the undersampled measurements. In this paper, a $K \\times N$ measurement\nmatrix for compressed sensing is deterministically constructed via\nmultiplicative character sequences. Precisely, a constant multiple of a cyclic\nshift of an $M$-ary power residue or Sidelnikov sequence is arranged as a\ncolumn vector of the matrix, through modulating a primitive $M$-th root of\nunity. The Weil bound is then used to show that the matrix has asymptotically\noptimal coherence for large $K$ and $M$, and to present a sufficient condition\non the sparsity level for unique sparse solution. Also, the restricted isometry\nproperty (RIP) is statistically studied for the deterministic matrix. Numerical\nresults show that the deterministic compressed sensing matrix guarantees\nreliable matching pursuit recovery performance for both noiseless and noisy\nmeasurements. \n\n"}
{"id": "1011.2809", "contents": "Title: Multipath Parameter Estimation from OFDM Signals in Mobile Channels Abstract: We study multipath parameter estimation from orthogonal frequency division\nmultiplex signals transmitted over doubly dispersive mobile radio channels. We\nare interested in cases where the transmission is long enough to suffer time\nselectivity, but short enough such that the time variation can be accurately\nmodeled as depending only on per-tap linear phase variations due to Doppler\neffects. We therefore concentrate on the estimation of the complex gain, delay\nand Doppler offset of each tap of the multipath channel impulse response. We\nshow that the frequency domain channel coefficients for an entire packet can be\nexpressed as the superimposition of two-dimensional complex sinusoids. The\nmaximum likelihood estimate requires solution of a multidimensional non-linear\nleast squares problem, which is computationally infeasible in practice. We\ntherefore propose a low complexity suboptimal solution based on iterative\nsuccessive and parallel cancellation. First, initial delay/Doppler estimates\nare obtained via successive cancellation. These estimates are then refined\nusing an iterative parallel cancellation procedure. We demonstrate via Monte\nCarlo simulations that the root mean squared error statistics of our estimator\nare very close to the Cramer-Rao lower bound of a single two-dimensional\nsinusoid in Gaussian noise. \n\n"}
{"id": "1011.2835", "contents": "Title: Approximately Optimal Wireless Broadcasting Abstract: We study a wireless broadcast network, where a single source reliably\ncommunicates independent messages to multiple destinations, with the aid of\nrelays and cooperation between destinations. The wireless nature of the medium\nis captured by the broadcast nature of transmissions as well as the\nsuperposition of all transmit signals plus independent Gaussian noise at the\nreceived signal at any radio. We propose a scheme that can achieve rate tuples\nwithin a constant gap away from the cut-set bound, where the constant is\nindependent of channel coefficients and power constraints.\n  The proposed scheme operates in two steps. The inner code, in which the\nrelays perform a quantize-and-encode operation, is constructed by lifting a\nscheme designed for a corresponding discrete superposition network. The outer\ncode is a Marton code for the non-Gaussian vector broadcast channel induced by\nthe relaying scheme, and is constructed by adopting a ``receiver-centric''\nviewpoint. \n\n"}
{"id": "1011.6218", "contents": "Title: Coordinated Transmissions to Direct and Relayed Users in Wireless\n  Cellular Systems Abstract: The ideas of wireless network coding at the physical layer promise high\nthroughput gains in wireless systems with relays and multi-way traffic flows.\nThis gain can be ascribed to two principles: (1) joint transmission of multiple\ncommunication flows and (2) usage of \\emph{a priori} information to cancel the\ninterference. In this paper we use these principles to devise new transmission\nschemes in wireless cellular systems that feature both users served directly by\nthe base stations (direct users) and users served through relays (relayed\nusers). We present four different schemes for \\emph{coordinated transmission}\nof uplink and downlink traffic in which one direct and one relayed user are\nserved. These schemes are then used as building blocks in multi-user scenarios,\nwhere we present several schemes for scheduling pairs of users for coordinated\ntransmissions. The optimal scheme involves exhaustive search of the best user\npair in terms of overall rate. We propose several suboptimal scheduling\nschemes, which perform closely to the optimal scheme. The numerical results\nshow a substantial increase in the system--level rate with respect to the\nsystems with non--coordinated transmissions. \n\n"}
{"id": "1101.2728", "contents": "Title: Index Coding and Error Correction Abstract: A problem of index coding with side information was first considered by Y.\nBirk and T. Kol (IEEE INFOCOM, 1998). In the present work, a generalization of\nindex coding scheme, where transmitted symbols are subject to errors, is\nstudied. Error-correcting methods for such a scheme, and their parameters, are\ninvestigated. In particular, the following question is discussed: given the\nside information hypergraph of index coding scheme and the maximal number of\nerroneous symbols $\\delta$, what is the shortest length of a linear index code,\nsuch that every receiver is able to recover the required information? This\nquestion turns out to be a generalization of the problem of finding a\nshortest-length error-correcting code with a prescribed error-correcting\ncapability in the classical coding theory. The Singleton bound and two other\nbounds, referred to as the $\\alpha$-bound and the $\\kappa$-bound, for the\noptimal length of a linear error-correcting index code (ECIC) are established.\nFor large alphabets, a construction based on concatenation of an optimal index\ncode with an MDS classical code, is shown to attain the Singleton bound. For\nsmaller alphabets, however, this construction may not be optimal. A random\nconstruction is also analyzed. It yields another inexplicit bound on the length\nof an optimal linear ECIC. Finally, the decoding of linear ECIC's is discussed.\nThe syndrome decoding is shown to output the exact message if the weight of the\nerror vector is less or equal to the error-correcting capability of the\ncorresponding ECIC. \n\n"}
{"id": "1101.3070", "contents": "Title: Information and the arrow of time Abstract: This paper is a discussion about the relationship between time and\ninformation. We argue that the direction of arrow of time is related to the\ndirectivity of information copying that occurs in Nature. \n\n"}
{"id": "1101.3098", "contents": "Title: Quantum Convex Support Abstract: Convex support, the mean values of a set of random variables, is central in\ninformation theory and statistics. Equally central in quantum information\ntheory are mean values of a set of observables in a finite-dimensional\nC*-algebra A, which we call (quantum) convex support. The convex support can be\nviewed as a projection of the state space of A and it is a projection of a\nspectrahedron.\n  Spectrahedra are increasingly investigated at least since the 1990's boom in\nsemidefinite programming. We recall the geometry of the positive semi-definite\ncone and of the state space. We write a convex duality for general self-dual\nconvex cones. This restricts to projections of state spaces and connects them\nto results on spectrahedra.\n  Really new in this article is an analysis of the face lattice of convex\nsupport by mapping this lattice to a lattice of orthogonal projections, using\nnatural isomorphisms. The result encodes the face lattice of the convex support\ninto a set of projections in A and enables the integration of convex geometry\nwith matrix calculus or algebraic techniques. \n\n"}
{"id": "1101.5716", "contents": "Title: Zero-Delay Joint Source-Channel Coding for a Bivariate Gaussian on a\n  Gaussian MAC Abstract: In this paper, delay-free, low complexity, joint source-channel coding (JSCC)\nfor transmission of two correlated Gaussian memoryless sources over a Gaussian\nMultiple Access Channel (GMAC) is considered. The main contributions of the\npaper are two distributed JSCC schemes: one discrete scheme based on nested\nscalar quantization, and one hybrid discrete-analog scheme based on a scalar\nquantizer and a linear continuous mapping. The proposed schemes show promising\nperformance which improve with increasing correlation and are robust against\nvariations in noise level. Both schemes exhibit a constant gap to the\nperformance upper bound when the channel signal-to-noise ratio gets large. \n\n"}
{"id": "1101.5809", "contents": "Title: The Degrees of Freedom Region and Interference Alignment for the MIMO\n  Interference Channel with Delayed CSI Abstract: The degrees of freedom (DoF) region of the 2-user multiple-antenna or MIMO\n(multiple-input, multiple-output) interference channel (IC) is studied under\nfast fading and the assumption of {\\em delayed} channel state information (CSI)\nwherein all terminals know all (or certain) channel matrices perfectly, but\nwith a delay, and each receiver in addition knows its own incoming channels\ninstantaneously. The general MIMO IC is considered with an arbitrary number of\nantennas at each of the four terminals. Dividing it into several classes\ndepending on the relation between the numbers of antennas at the four\nterminals, the fundamental DoF regions are characterized under the delayed CSI\nassumption for {\\em all} possible values of number of antennas at the four\nterminals. In particular, an outer bound on the DoF region of the general MIMO\nIC is derived. This bound is then shown to be tight for all MIMO ICs by\ndeveloping interference alignment based achievability schemes for each class. A\ncomparison of these DoF regions under the delayed CSI assumption is made with\nthose of the idealistic `perfect CSI' assumption where perfect and\ninstantaneous CSI is available at all terminals on the one hand and with the\nDoF regions of the conservative `no CSI' assumption on the other, where CSI is\navailable at the receivers but not at all at the transmitters. \n\n"}
{"id": "1102.3288", "contents": "Title: Compressive MUSIC with optimized partial support for joint sparse\n  recovery Abstract: Multiple measurement vector (MMV) problem addresses the identification of\nunknown input vectors that share common sparse support. The MMV problems had\nbeen traditionally addressed either by sensor array signal processing or\ncompressive sensing. However, recent breakthrough in this area such as\ncompressive MUSIC (CS-MUSIC) or subspace-augumented MUSIC (SA-MUSIC) optimally\ncombines the compressive sensing (CS) and array signal processing such that\n$k-r$ supports are first found by CS and the remaining $r$ supports are\ndetermined by generalized MUSIC criterion, where $k$ and $r$ denote the\nsparsity and the independent snapshots, respectively. Even though such hybrid\napproach significantly outperforms the conventional algorithms, its performance\nheavily depends on the correct identification of $k-r$ partial support by\ncompressive sensing step, which often deteriorate the overall performance. The\nmain contribution of this paper is, therefore, to show that as long as $k-r+1$\ncorrect supports are included in any $k$-sparse CS solution, the optimal $k-r$\npartial support can be found using a subspace fitting criterion, significantly\nimproving the overall performance of CS-MUSIC. Furthermore, unlike the single\nmeasurement CS counterpart that requires infinite SNR for a perfect support\nrecovery, we can derive an information theoretic sufficient condition for the\nperfect recovery using CS-MUSIC under a {\\em finite} SNR scenario. \n\n"}
{"id": "1102.3617", "contents": "Title: Wireless Secrecy in Large-Scale Networks Abstract: The ability to exchange secret information is critical to many commercial,\ngovernmental, and military networks. The intrinsically secure communications\ngraph (iS-graph) is a random graph which describes the connections that can be\nsecurely established over a large-scale network, by exploiting the physical\nproperties of the wireless medium. This paper provides an overview of the main\nproperties of this new class of random graphs. We first analyze the local\nproperties of the iS-graph, namely the degree distributions and their\ndependence on fading, target secrecy rate, and eavesdropper collusion. To\nmitigate the effect of the eavesdroppers, we propose two techniques that\nimprove secure connectivity. Then, we analyze the global properties of the\niS-graph, namely percolation on the infinite plane, and full connectivity on a\nfinite region. These results help clarify how the presence of eavesdroppers can\ncompromise secure communication in a large-scale network. \n\n"}
{"id": "1102.3755", "contents": "Title: Cooperative Wideband Spectrum Sensing for the Centralized Cognitive\n  Radio Network Abstract: Various primary user (PU) radios have been allocated into fixed frequency\nbands in the whole spectrum. A cognitive radio network (CRN) should be able to\nperform the wideband spectrum sensing (WSS) to detect temporarily unoccupied\nfrequency bands. We summarize four occupancy features for the frequency bands.\n1. The occupancy is sparse; 2. The frequency band allocation information is\nfixed and common; 3. There are three categories for the frequency band usages;\n4. The occupied frequency bands are common in the CRN. For the first time, we\nconsider all features as the prior knowledge in the compressed sensing based\ncooperative WSS (CWSS) algorithm design for a centralized CRN. We propose a\nmodified orthogonal matching pursuit (Mod-OMP) algorithm and a modified\nsimultaneous orthogonal matching pursuit (Mod-SOMP) algorithm for the CWSS. We\ncompare the CWSS performance of Mod-OMP/Mod-SOMP with the original OMP/SOMP and\nshow the performance improvements. \n\n"}
{"id": "1102.5138", "contents": "Title: Low-Complexity Near-Optimal Codes for Gaussian Relay Networks Abstract: We consider the problem of information flow over Gaussian relay networks.\nSimilar to the recent work by Avestimehr \\emph{et al.} [1], we propose network\ncodes that achieve up to a constant gap from the capacity of such networks.\nHowever, our proposed codes are also computationally tractable. Our main\ntechnique is to use the codes of Avestimehr \\emph{et al.} as inner codes in a\nconcatenated coding scheme. \n\n"}
{"id": "1103.4223", "contents": "Title: A Stochastic-Geometry Approach to Coverage in Cellular Networks with\n  Multi-Cell Cooperation Abstract: Multi-cell cooperation is a promising approach for mitigating inter-cell\ninterference in dense cellular networks. Quantifying the performance of\nmulti-cell cooperation is challenging as it integrates physical-layer\ntechniques and network topologies. For tractability, existing work typically\nrelies on the over-simplified Wyner-type models. In this paper, we propose a\nnew stochastic-geometry model for a cellular network with multi-cell\ncooperation, which accounts for practical factors including the irregular\nlocations of base stations (BSs) and the resultant path-losses. In particular,\nthe proposed network-topology model has three key features: i) the cells are\nmodeled using a Poisson random tessellation generated by Poisson distributed\nBSs, ii) multi-antenna BSs are clustered using a hexagonal lattice and BSs in\nthe same cluster mitigate mutual interference by spatial interference\navoidance, iii) BSs near cluster edges access a different sub-channel from that\nby other BSs, shielding cluster-edge mobiles from strong interference. Using\nthis model and assuming sparse scattering, we analyze the shapes of the outage\nprobabilities of mobiles served by cluster-interior BSs as the average number\n$K$ of BSs per cluster increases. The outage probability of a mobile near a\ncluster center is shown to be proportional to $e^{-c(2-\\sqrt{\\nu})^2K}$ where\n$\\nu$ is the fraction of BSs lying in the interior of clusters and $c$ is a\nconstant. Moreover, the outage probability of a typical mobile is proved to\nscale proportionally with $e^{-c' (1-\\sqrt{\\nu})^2K}$ where $c'$ is a constant. \n\n"}
{"id": "1104.0862", "contents": "Title: Causal Rate Distortion Function and Relations to Filtering Theory Abstract: A causal rate distortion function is defined, its solution is described, and\nits relation to filtering theory is discussed. The relation to filtering is\nobtained via a causal constraint imposed on the reconstruction kernel to be\nrealizable. \n\n"}
{"id": "1104.3160", "contents": "Title: Robust 1-Bit Compressive Sensing via Binary Stable Embeddings of Sparse\n  Vectors Abstract: The Compressive Sensing (CS) framework aims to ease the burden on\nanalog-to-digital converters (ADCs) by reducing the sampling rate required to\nacquire and stably recover sparse signals. Practical ADCs not only sample but\nalso quantize each measurement to a finite number of bits; moreover, there is\nan inverse relationship between the achievable sampling rate and the bit depth.\nIn this paper, we investigate an alternative CS approach that shifts the\nemphasis from the sampling rate to the number of bits per measurement. In\nparticular, we explore the extreme case of 1-bit CS measurements, which capture\njust their sign. Our results come in two flavors. First, we consider ideal\nreconstruction from noiseless 1-bit measurements and provide a lower bound on\nthe best achievable reconstruction error. We also demonstrate that i.i.d.\nrandom Gaussian matrices describe measurement mappings achieving, with\noverwhelming probability, nearly optimal error decay. Next, we consider\nreconstruction robustness to measurement errors and noise and introduce the\nBinary $\\epsilon$-Stable Embedding (B$\\epsilon$SE) property, which\ncharacterizes the robustness measurement process to sign changes. We show the\nsame class of matrices that provide almost optimal noiseless performance also\nenable such a robust mapping. On the practical side, we introduce the Binary\nIterative Hard Thresholding (BIHT) algorithm for signal reconstruction from\n1-bit measurements that offers state-of-the-art performance. \n\n"}
{"id": "1104.5327", "contents": "Title: Xampling in Ultrasound Imaging Abstract: Recent developments of new medical treatment techniques put challenging\ndemands on ultrasound imaging systems in terms of both image quality and raw\ndata size. Traditional sampling methods result in very large amounts of data,\nthus, increasing demands on processing hardware and limiting the exibility in\nthe post-processing stages. In this paper, we apply Compressed Sensing (CS)\ntechniques to analog ultrasound signals, following the recently developed\nXampling framework. The result is a system with significantly reduced sampling\nrates which, in turn, means significantly reduced data size while maintaining\nthe quality of the resulting images. \n\n"}
{"id": "1105.2017", "contents": "Title: Potential Games for Energy-Efficient Resource Allocation in\n  Multipoint-to-Multipoint CDMA Wireless Data Networks Abstract: The problem of noncooperative resource allocation in a\nmultipoint-to-multipoint cellular network is considered in this paper. The\nconsidered scenario is general enough to represent several key instances of\nmodern wireless networks such as a multicellular network, a peer-to-peer\nnetwork (interference channel), and a wireless network equipped with\nfemtocells. In particular, the problem of joint transmit waveforms adaptation,\nlinear receiver design, and transmit power control is examined. Several utility\nfunctions to be maximized are considered, and, among them, we cite the received\nSINR, and the transmitter energy efficiency, which is measured in bit/Joule,\nand represents the number of successfully delivered bits for each energy unit\nused for transmission. Resorting to the theory of potential games,\nnoncooperative games admitting Nash equilibria in multipoint-to-multipoint\ncellular networks regardless of the channel coefficient realizations are\ndesigned. Computer simulations confirm that the considered games are\nconvergent, and show the huge benefits that resource allocation schemes can\nbring to the performance of wireless data networks. \n\n"}
{"id": "1105.3793", "contents": "Title: A lower bound on the average entropy of a function determined up to a\n  diagonal linear map on F_q^n Abstract: In this note, it is shown that if $f\\colon\\efq^n\\to\\efq^n$ is any function\nand $\\bA=(A_1,..., A_n)$ is uniformly distributed over $\\efq^n$, then the\naverage over $(k_1,...,k_n)\\in \\efq^n$ of the Renyi (and hence, of the Shannon)\nentropy of $f(\\bA)+(k_1A_1,...,k_nA_n)$ is at least about $\\log_2(q^n)-n$. In\nfact, it is shown that the average collision probability of\n$f(\\bA)+(k_1A_1,...,k_nA_n)$ is at most about $2^n/q^n$. \n\n"}
{"id": "1105.5215", "contents": "Title: Compressive Identification of Linear Operators Abstract: We consider the problem of identifying a linear deterministic operator from\nan input-output measurement. For the large class of continuous (and hence\nbounded) operators, under additional mild restrictions, we show that stable\nidentifiability is possible if the total support area of the operator's\nspreading function satisfies D <= 1/2. This result holds for arbitrary\n(possibly fragmented) support regions of the spreading function, does not\nimpose limitations on the total extent of the support region, and, most\nimportantly, does not require the support region of the spreading function to\nbe known prior to identification. Furthermore, we prove that asking for\nidentifiability of only almost all operators, stable identifiability is\npossible if D <= 1. This result is surprising as it says that there is no\npenalty for not knowing the support region of the spreading function prior to\nidentification. \n\n"}
{"id": "1105.6326", "contents": "Title: Two Unicast Information Flows over Linear Deterministic Networks Abstract: We investigate the two unicast flow problem over layered linear deterministic\nnetworks with arbitrary number of nodes. When the minimum cut value between\neach source-destination pair is constrained to be 1, it is obvious that the\ntriangular rate region {(R_1,R_2):R_1,R_2> 0, R_1+R_2< 1} can be achieved, and\nthat one cannot achieve beyond the square rate region {(R_1,R_2):R_1,R_2> 0,\nR_1< 1,R_2< 1}. Analogous to the work by Wang and Shroff for wired networks, we\nprovide the necessary and sufficient conditions for the capacity region to be\nthe triangular region and the necessary and sufficient conditions for it to be\nthe square region. Moreover, we completely characterize the capacity region and\nconclude that there are exactly three more possible capacity regions of this\nclass of networks, in contrast to the result in wired networks where only the\ntriangular and square rate regions are possible. Our achievability scheme is\nbased on linear coding over an extension field with at most four nodes\nperforming special linear coding operations, namely interference neutralization\nand zero forcing, while all other nodes perform random linear coding. \n\n"}
{"id": "1106.0027", "contents": "Title: On the geometry of wireless network multicast in 2-D Abstract: We provide a geometric solution to the problem of optimal relay positioning\nto maximize the multicast rate for low-SNR networks. The networks we consider,\nconsist of a single source, multiple receivers and the only intermediate and\nlocatable node as the relay. We construct network the hypergraph of the system\nnodes from the underlying information theoretic model of low-SNR regime that\noperates using superposition coding and FDMA in conjunction (which we call the\n\"achievable hypergraph model\"). We make the following contributions. 1) We show\nthat the problem of optimal relay positioning maximizing the multicast rate can\nbe completely decoupled from the flow optimization by noticing and exploiting\ngeometric properties of multicast flow. 2) All the flow maximizing the\nmulticast rate is sent over at most two paths, in succession. The relay\nposition is dependent only on one path (out of the two), irrespective of the\nnumber of receiver nodes in the system. Subsequently, we propose simple and\nefficient geometric algorithms to compute the optimal relay position. 3)\nFinally, we show that in our model at the optimal relay position, the\ndifference between the maximized multicast rate and the cut-set bound is\nminimum. We solve the problem for all (Ps,Pr) pairs of source and relay\ntransmit powers and the path loss exponent \\alpha greater than 2. \n\n"}
{"id": "1106.1250", "contents": "Title: Optimal Repair of MDS Codes in Distributed Storage via Subspace\n  Interference Alignment Abstract: It is well known that an (n,k) code can be used to store 'k' units of\ninformation in 'n' unit-capacity disks of a distributed data storage system. If\nthe code used is maximum distance separable (MDS), then the system can tolerate\nany (n-k) disk failures, since the original information can be recovered from\nany k surviving disks. The focus of this paper is the design of a systematic\nMDS code with the additional property that a single disk failure can be\nrepaired with minimum repair bandwidth, i.e., with the minimum possible amount\nof data to be downloaded for recovery of the failed disk. Previously, a lower\nbound of (n-1)/(n-k) units has been established by Dimakis et. al, on the\nrepair bandwidth for a single disk failure in an (n,k) MDS code . Recently, the\nexistence of asymptotic codes achieving this lower bound for arbitrary (n,k)\nhas been established by drawing connections to interference alignment. While\nthe existence of asymptotic constructions achieving this lower bound have been\nshown, finite code constructions achieving this lower bound existed in previous\nliterature only for the special (high-redundancy) scenario where $k \\leq\n\\max(n/2,3)$. The question of existence of finite codes for arbitrary values of\n(n,k) achieving the lower bound on the repair bandwidth remained open. In this\npaper, by using permutation coding sub-matrices, we provide the first known\nfinite MDS code which achieves the optimal repair bandwidth of (n-1)/(n-k) for\narbitrary (n,k), for recovery of a failed systematic disk. We also generalize\nour permutation matrix based constructions by developing a novel framework for\nrepair-bandwidth-optimal MDS codes based on the idea of subspace interference\nalignment - a concept previously introduced by Suh and Tse the context of\nwireless cellular networks. \n\n"}
{"id": "1106.3286", "contents": "Title: ReProCS: A Missing Link between Recursive Robust PCA and Recursive\n  Sparse Recovery in Large but Correlated Noise Abstract: This work studies the recursive robust principal components' analysis (PCA)\nproblem. Here, \"robust\" refers to robustness to both independent and correlated\nsparse outliers, although we focus on the latter. A key application where this\nproblem occurs is in video surveillance where the goal is to separate a slowly\nchanging background from moving foreground objects on-the-fly. The background\nsequence is well modeled as lying in a low dimensional subspace, that can\ngradually change over time, while the moving foreground objects constitute the\ncorrelated sparse outliers. In this and many other applications, the foreground\nis an outlier for PCA but is actually the \"signal of interest\" for the\napplication; where as the background is the corruption or noise. Thus our\nproblem can also be interpreted as one of recursively recovering a time\nsequence of sparse signals in the presence of large but spatially correlated\nnoise.\n  This work has two key contributions. First, we provide a new way of looking\nat this problem and show how a key part of our solution strategy involves\nsolving a noisy compressive sensing (CS) problem. Second, we show how we can\nutilize the correlation of the outliers to our advantage in order to even deal\nwith very large support sized outliers. The main idea is as follows. The\ncorrelation model applied to the previous support estimate helps predict the\ncurrent support. This prediction serves as \"partial support knowledge\" for\nsolving the modified-CS problem instead of CS. The support estimate of the\nmodified-CS reconstruction is, in turn, used to update the correlation model\nparameters using a Kalman filter (or any adaptive filter). We call the\nresulting approach \"support-predicted modified-CS\". \n\n"}
{"id": "1106.5387", "contents": "Title: Subspace Properties of Network Coding and their Applications Abstract: Systems that employ network coding for content distribution convey to the\nreceivers linear combinations of the source packets. If we assume randomized\nnetwork coding, during this process the network nodes collect random subspaces\nof the space spanned by the source packets. We establish several fundamental\nproperties of the random subspaces induced in such a system, and show that\nthese subspaces implicitly carry topological information about the network and\nits state that can be passively collected and inferred. We leverage this\ninformation towards a number of applications that are interesting in their own\nright, such as topology inference, bottleneck discovery in peer-to-peer systems\nand locating Byzantine attackers. We thus argue that, randomized network\ncoding, apart from its better known properties for improving information\ndelivery rate, can additionally facilitate network management and control. \n\n"}
{"id": "1106.5413", "contents": "Title: Accelerated Linearized Bregman Method Abstract: In this paper, we propose and analyze an accelerated linearized Bregman (ALB)\nmethod for solving the basis pursuit and related sparse optimization problems.\nThis accelerated algorithm is based on the fact that the linearized Bregman\n(LB) algorithm is equivalent to a gradient descent method applied to a certain\ndual formulation. We show that the LB method requires $O(1/\\epsilon)$\niterations to obtain an $\\epsilon$-optimal solution and the ALB algorithm\nreduces this iteration complexity to $O(1/\\sqrt{\\epsilon})$ while requiring\nalmost the same computational effort on each iteration. Numerical results on\ncompressed sensing and matrix completion problems are presented that\ndemonstrate that the ALB method can be significantly faster than the LB method. \n\n"}
{"id": "1106.5742", "contents": "Title: Wireless Network Coding with Local Network Views: Coded Layer Scheduling Abstract: One of the fundamental challenges in the design of distributed wireless\nnetworks is the large dynamic range of network state. Since continuous tracking\nof global network state at all nodes is practically impossible, nodes can only\nacquire limited local views of the whole network to design their transmission\nstrategies. In this paper, we study multi-layer wireless networks and assume\nthat each node has only a limited knowledge, namely 1-local view, where each\nS-D pair has enough information to perform optimally when other pairs do not\ninterfere, along with connectivity information for rest of the network. We\ninvestigate the information-theoretic limits of communication with such limited\nknowledge at the nodes. We develop a novel transmission strategy, namely Coded\nLayer Scheduling, that solely relies on 1-local view at the nodes and\nincorporates three different techniques: (1) per layer interference avoidance,\n(2) repetition coding to allow overhearing of the interference, and (3) network\ncoding to allow interference neutralization. We show that our proposed scheme\ncan provide a significant throughput gain compared with the conventional\ninterference avoidance strategies. Furthermore, we show that our strategy\nmaximizes the achievable normalized sum-rate for some classes of networks,\nhence, characterizing the normalized sum-capacity of those networks with\n1-local view. \n\n"}
{"id": "1106.6323", "contents": "Title: The Diversity Multiplexing Tradeoff of the MIMO Half-Duplex Relay\n  Channel Abstract: The fundamental diversity-multiplexing tradeoff of the three-node,\nmulti-input, multi-output (MIMO), quasi-static, Rayleigh faded, half-duplex\nrelay channel is characterized for an arbitrary number of antennas at each node\nand in which opportunistic scheduling (or dynamic operation) of the relay is\nallowed, i.e., the relay can switch between receive and transmit modes at a\nchannel dependent time. In this most general case, the diversity-multiplexing\ntradeoff is characterized as a solution to a simple, two-variable optimization\nproblem. This problem is then solved in closed form for special classes of\nchannels defined by certain restrictions on the numbers of antennas at the\nthree nodes. The key mathematical tool developed here that enables the explicit\ncharacterization of the diversity-multiplexing tradeoff is the joint eigenvalue\ndistribution of three mutually correlated random Wishart matrices. Previously,\nwithout actually characterizing the diversity-multiplexing tradeoff, the\noptimality in this tradeoff metric of the dynamic compress-and-forward (DCF)\nprotocol based on the classical compress-and-forward scheme of Cover and El\nGamal was shown by Yuksel and Erkip. However, this scheme requires global\nchannel state information (CSI) at the relay. In this work, the so-called\nquantize-map and forward (QMF) coding scheme due to Avestimehr {\\em et} {\\em\nal} is adopted as the achievability scheme with the added benefit that it\nachieves optimal tradeoff with only the knowledge of the (channel dependent)\nswitching time at the relay node. Moreover, in special classes of the MIMO\nhalf-duplex relay channel, the optimal tradeoff is shown to be attainable even\nwithout this knowledge. Such a result was previously known only for the\nhalf-duplex relay channel with a single antenna at each node, also via the QMF\nscheme. \n\n"}
{"id": "1107.2499", "contents": "Title: Improving Energy Efficiency Through Multimode Transmission in the\n  Downlink MIMO Systems Abstract: Adaptively adjusting system parameters including bandwidth, transmit power\nand mode to maximize the \"Bits per-Joule\" energy efficiency (BPJ-EE) in the\ndownlink MIMO systems with imperfect channel state information at the\ntransmitter (CSIT) is considered in this paper. By mode we refer to choice of\ntransmission schemes i.e. singular value decomposition (SVD) or block\ndiagonalization (BD), active transmit/receive antenna number and active user\nnumber. We derive optimal bandwidth and transmit power for each dedicated mode\nat first. During the derivation, accurate capacity estimation strategies are\nproposed to cope with the imperfect CSIT caused capacity prediction problem.\nThen, an ergodic capacity based mode switching strategy is proposed to further\nimprove the BPJ-EE, which provides insights on the preferred mode under given\nscenarios. Mode switching compromises different power parts, exploits the\ntradeoff between the multiplexing gain and the imperfect CSIT caused inter-user\ninterference, improves the BPJ-EE significantly. \n\n"}
{"id": "1107.4600", "contents": "Title: On the Capacity of the Interference Channel with a Cognitive Relay Abstract: The InterFerence Channel with a Cognitive Relay (IFC-CR) consists of the\nclassical interference channel with two independent source-destination pairs\nwhose communication is aided by an additional node, referred to as the\ncognitive relay, that has a priori knowledge of both sources' messages. This a\npriori message knowledge is termed cognition and idealizes the relay learning\nthe messages of the two sources from their transmissions over a wireless\nchannel. This paper presents new inner and outer bounds for the capacity region\nof the general memoryless IFC-CR that are shown to be tight for a certain class\nof channels. The new outer bound follows from arguments originally devised for\nbroadcast channels among which Sato's observation that the capacity region of\nchannels with non-cooperative receivers only depends on the channel output\nconditional marginal distributions. The new inner bound is shown to include all\npreviously proposed coding schemes and it is thus the largest known achievable\nrate region to date. The new inner and outer bounds coincide for a subset of\nchannel satisfying a strong interference condition. For these channels there is\nno loss in optimality if both destinations decode both messages. This result\nparallels analogous results for the classical IFC and for the cognitive IFC and\nis the first known capacity result for the general IFC-CR. Numerical\nevaluations of the proposed inner and outer bounds are presented for the\nGaussian noise case. \n\n"}
{"id": "1107.4705", "contents": "Title: A unified graphical approach to random coding for multi-terminal\n  networks Abstract: A unified approach to the derivation of rate regions for single-hop\nmemoryless networks is presented. A general transmission scheme for any\nmemoryless, single-hop, k-user channel with or without common information, is\ndefined through two steps. The first step is user virtualization: each user is\ndivided into multiple virtual sub-users according to a chosen rate-splitting\nstrategy which preserves the rates of the original messages. This results in an\nenhanced channel with a possibly larger number of users for which more coding\npossibilities are available. Moreover, user virtualization provides a simple\nmechanism to encode common messages to any subset of users. Following user\nvirtualization, the message of each user in the enhanced model is coded using a\nchosen combination of coded time-sharing, superposition coding and joint\nbinning. A graph is used to represent the chosen coding strategies: nodes in\nthe graph represent codewords while edges represent coding operations. This\ngraph is used to construct a graphical Markov model which illustrates the\nstatistical dependency among codewords that can be introduced by the\nsuperposition coding or joint binning. Using this statistical representation of\nthe overall codebook distribution, the error probability of the code is shown\nto vanish via a unified analysis. The rate bounds that define the achievable\nrate region are obtained by linking the error analysis to the properties of the\ngraphical Markov model. This proposed framework makes it possible to\nnumerically obtain an achievable rate region by specifying a user\nvirtualization strategy and describing a set of coding operations. The largest\nachievable rate region can be obtained by considering all the possible\nrate-splitting strategies and taking the union over all the possible ways to\nsuperimpose or bin codewords. \n\n"}
{"id": "1108.4257", "contents": "Title: Capacity Analysis of Linear Operator Channels over Finite Fields Abstract: Motivated by communication through a network employing linear network coding,\ncapacities of linear operator channels (LOCs) with arbitrarily distributed\ntransfer matrices over finite fields are studied. Both the Shannon capacity $C$\nand the subspace coding capacity $C_{\\text{SS}}$ are analyzed. By establishing\nand comparing lower bounds on $C$ and upper bounds on $C_{\\text{SS}}$, various\nnecessary conditions and sufficient conditions such that $C=C_{\\text{SS}}$ are\nobtained. A new class of LOCs such that $C=C_{\\text{SS}}$ is identified, which\nincludes LOCs with uniform-given-rank transfer matrices as special cases. It is\nalso demonstrated that $C_{\\text{SS}}$ is strictly less than $C$ for a broad\nclass of LOCs. In general, an optimal subspace coding scheme is difficult to\nfind because it requires to solve the maximization of a non-concave function.\nHowever, for a LOC with a unique subspace degradation, $C_{\\text{SS}}$ can be\nobtained by solving a convex optimization problem over rank distribution.\nClasses of LOCs with a unique subspace degradation are characterized. Since\nLOCs with uniform-given-rank transfer matrices have unique subspace\ndegradations, some existing results on LOCs with uniform-given-rank transfer\nmatrices are explained from a more general way. \n\n"}
{"id": "1108.4753", "contents": "Title: Differential properties of functions x -> x^{2^t-1} -- extended version Abstract: We provide an extensive study of the differential properties of the functions\n$x\\mapsto x^{2^t-1}$ over $\\F$, for $2 \\leq t \\leq n-1$. We notably show that\nthe differential spectra of these functions are determined by the number of\nroots of the linear polynomials $x^{2^t}+bx^2+(b+1)x$ where $b$ varies in\n$\\F$.We prove a strong relationship between the differential spectra of\n$x\\mapsto x^{2^t-1}$ and $x\\mapsto x^{2^{s}-1}$ for $s= n-t+1$. As a direct\nconsequence, this result enlightens a connection between the differential\nproperties of the cube function and of the inverse function. We also determine\nthe complete differential spectra of $x \\mapsto x^7$ by means of the value of\nsome Kloosterman sums, and of $x \\mapsto x^{2^t-1}$ for $t \\in \\{\\lfloor\nn/2\\rfloor, \\lceil n/2\\rceil+1, n-2\\}$. \n\n"}
{"id": "1109.0318", "contents": "Title: Compressive Matched-Field Processing Abstract: Source localization by matched-field processing (MFP) generally involves\nsolving a number of computationally intensive partial differential equations.\nThis paper introduces a technique that mitigates this computational workload by\n\"compressing\" these computations. Drawing on key concepts from the recently\ndeveloped field of compressed sensing, it shows how a low-dimensional proxy for\nthe Green's function can be constructed by backpropagating a small set of\nrandom receiver vectors. Then, the source can be located by performing a number\nof \"short\" correlations between this proxy and the projection of the recorded\nacoustic data in the compressed space. Numerical experiments in a Pekeris ocean\nwaveguide are presented which demonstrate that this compressed version of MFP\nis as effective as traditional MFP even when the compression is significant.\nThe results are particularly promising in the broadband regime where using as\nfew as two random backpropagations per frequency performs almost as well as the\ntraditional broadband MFP, but with the added benefit of generic applicability.\nThat is, the computationally intensive backpropagations may be computed offline\nindependently from the received signals, and may be reused to locate any source\nwithin the search grid area. \n\n"}
{"id": "1109.3887", "contents": "Title: An Algorithmic Approach to Information and Meaning Abstract: I will survey some matters of relevance to a philosophical discussion of\ninformation, taking into account developments in algorithmic information theory\n(AIT). I will propose that meaning is deep in the sense of Bennett's logical\ndepth, and that algorithmic probability may provide the stability needed for a\nrobust algorithmic definition of meaning, one that takes into consideration the\ninterpretation and the recipient's own knowledge encoded in the story attached\nto a message. \n\n"}
{"id": "1109.5373", "contents": "Title: Degrees of Freedom Region of the MIMO Interference Channel with Output\n  Feedback and Delayed CSIT Abstract: The two-user multiple-input multiple-output (MIMO) interference channel (IC)\nwith arbitrary number of antennas at each terminal is considered and the\ndegrees of freedom (DoF) region is characterized in the presence of noiseless\nchannel output feedback from each receiver to its respective transmitter and\navailability of delayed channel state information at the transmitters (CSIT).\nIt is shown that having output feedback and delayed CSIT can strictly enlarge\nthe DoF region of the MIMO IC when compared to the case in which only delayed\nCSIT is present. The proposed coding schemes that achieve the corresponding DoF\nregion with feedback and delayed CSIT utilize both resources, i.e., feedback\nand delayed CSIT in a non-trivial manner. It is also shown that the DoF region\nwith local feedback and delayed CSIT is equal to the DoF region with global\nfeedback and delayed CSIT, i.e., local feedback and delayed CSIT is equivalent\nto global feedback and delayed CSIT from the perspective of the degrees of\nfreedom region. The converse is proved for a stronger setting in which the\nchannels to the two receivers need not be statistically equivalent. \n\n"}
{"id": "1109.6269", "contents": "Title: Precoder Design for Physical Layer Multicasting Abstract: This paper studies the instantaneous rate maximization and the weighted sum\ndelay minimization problems over a K-user multicast channel, where multiple\nantennas are available at the transmitter as well as at all the receivers.\nMotivated by the degree of freedom optimality and the simplicity offered by\nlinear precoding schemes, we consider the design of linear precoders using the\naforementioned two criteria. We first consider the scenario wherein the linear\nprecoder can be any complex-valued matrix subject to rank and power\nconstraints. We propose cyclic alternating ascent based precoder design\nalgorithms and establish their convergence to respective stationary points.\nSimulation results reveal that our proposed algorithms considerably outperform\nknown competing solutions. We then consider a scenario in which the linear\nprecoder can be formed by selecting and concatenating precoders from a given\nfinite codebook of precoding matrices, subject to rank and power constraints.\nWe show that under this scenario, the instantaneous rate maximization problem\nis equivalent to a robust submodular maximization problem which is strongly NP\nhard. We propose a deterministic approximation algorithm and show that it\nyields a bicriteria approximation. For the weighted sum delay minimization\nproblem we propose a simple deterministic greedy algorithm, which at each step\nentails approximately maximizing a submodular set function subject to multiple\nknapsack constraints, and establish its performance guarantee. \n\n"}
{"id": "1110.5176", "contents": "Title: Demodulating Subsampled Direct Sequence Spread Spectrum Signals using\n  Compressive Signal Processing Abstract: We show that to lower the sampling rate in a spread spectrum communication\nsystem using Direct Sequence Spread Spectrum (DSSS), compressive signal\nprocessing can be applied to demodulate the received signal. This may lead to a\ndecrease in the power consumption or the manufacturing price of wireless\nreceivers using spread spectrum technology. The main novelty of this paper is\nthe discovery that in spread spectrum systems it is possible to apply\ncompressive sensing with a much simpler hardware architecture than in other\nsystems, making the implementation both simpler and more energy efficient. Our\ntheoretical work is exemplified with a numerical experiment using the IEEE\n802.15.4 standard's 2.4 GHz band specification. The numerical results support\nour theoretical findings and indicate that compressive sensing may be used\nsuccessfully in spread spectrum communication systems. The results obtained\nhere may also be applicable in other spread spectrum technologies, such as Code\nDivision Multiple Access (CDMA) systems. \n\n"}
{"id": "1110.6591", "contents": "Title: On some quasigroup cryptographical primitives Abstract: We propose modifications of known quasigroup based stream ciphers. Systems of\northogonal n-ary groupoids are used. \n\n"}
{"id": "1111.0084", "contents": "Title: Lattice codes for the Gaussian relay channel: Decode-and-Forward and\n  Compress-and-Forward Abstract: Lattice codes are known to achieve capacity in the Gaussian point-to-point\nchannel, achieving the same rates as independent, identically distributed\n(i.i.d.) random Gaussian codebooks. Lattice codes are also known to outperform\nrandom codes for certain channel models that are able to exploit their\nlinearity. In this work, we show that lattice codes may be used to achieve the\nsame performance as known i.i.d. Gaussian random coding techniques for the\nGaussian relay channel, and show several examples of how this may be combined\nwith the linearity of lattices codes in multi-source relay networks. In\nparticular, we present a nested lattice list decoding technique, by which,\nlattice codes are shown to achieve the Decode-and-Forward (DF) rate of single\nsource, single destination Gaussian relay channels with one or more relays. We\nnext present two examples of how this DF scheme may be combined with the\nlinearity of lattice codes to achieve new rate regions which for some channel\nconditions outperform analogous known Gaussian random coding techniques in\nmulti-source relay channels. That is, we derive a new achievable rate region\nfor the two-way relay channel with direct links and compare it to existing\nschemes, and derive another achievable rate region for the multiple access\nrelay channel. We furthermore present a lattice Compress-and-Forward (CF)\nscheme for the Gaussian relay channel which exploits a lattice Wyner-Ziv\nbinning scheme and achieves the same rate as the Cover-El Gamal CF rate\nevaluated for Gaussian random codes. These results suggest that\nstructured/lattice codes may be used to mimic, and sometimes outperform, random\nGaussian codes in general Gaussian networks. \n\n"}
{"id": "1111.1788", "contents": "Title: Robust PCA as Bilinear Decomposition with Outlier-Sparsity\n  Regularization Abstract: Principal component analysis (PCA) is widely used for dimensionality\nreduction, with well-documented merits in various applications involving\nhigh-dimensional data, including computer vision, preference measurement, and\nbioinformatics. In this context, the fresh look advocated here permeates\nbenefits from variable selection and compressive sampling, to robustify PCA\nagainst outliers. A least-trimmed squares estimator of a low-rank bilinear\nfactor analysis model is shown closely related to that obtained from an\n$\\ell_0$-(pseudo)norm-regularized criterion encouraging sparsity in a matrix\nexplicitly modeling the outliers. This connection suggests robust PCA schemes\nbased on convex relaxation, which lead naturally to a family of robust\nestimators encompassing Huber's optimal M-class as a special case. Outliers are\nidentified by tuning a regularization parameter, which amounts to controlling\nsparsity of the outlier matrix along the whole robustification path of (group)\nleast-absolute shrinkage and selection operator (Lasso) solutions. Beyond its\nneat ties to robust statistics, the developed outlier-aware PCA framework is\nversatile to accommodate novel and scalable algorithms to: i) track the\nlow-rank signal subspace robustly, as new data are acquired in real time; and\nii) determine principal components robustly in (possibly) infinite-dimensional\nfeature spaces. Synthetic and real data tests corroborate the effectiveness of\nthe proposed robust PCA schemes, when used to identify aberrant responses in\npersonality assessment surveys, as well as unveil communities in social\nnetworks, and intruders from video surveillance data. \n\n"}
{"id": "1111.4575", "contents": "Title: Information Theoretic Exemplification of the Impact of\n  Transmitter-Receiver Cognition on the Channel Capacity Abstract: In this paper, we study, information theoretically, the impact of transmitter\nand or receiver cognition on the channel capacity. The cognition can be\ndescribed by state information, dependent on the channel noise and or input.\nSpecifically, as a new idea, we consider the receiver cognition as a state\ninformation dependent on the noise and we derive a capacity theorem based on\nthe Gaussian version of the Cover-Chiang capacity theorem for two-sided state\ninformation channel. As intuitively expected, the receiver cognition increases\nthe channel capacity and our theorem shows this increase quantitatively. Also,\nour capacity theorem includes the famous Costa theorem as its special cases. \n\n"}
{"id": "1111.4768", "contents": "Title: Capacity of Multiple Unicast in Wireless Networks: A Polymatroidal\n  Approach Abstract: A classical result in undirected wireline networks is the near optimality of\nrouting (flow) for multiple-unicast traffic (multiple sources communicating\nindependent messages to multiple destinations): the min cut upper bound is\nwithin a logarithmic factor of the number of sources of the max flow. In this\npaper we \"extend\" the wireline result to the wireless context.\n  Our main result is the approximate optimality of a simple layering principle:\n{\\em local physical-layer schemes combined with global routing}. We use the\n{\\em reciprocity} of the wireless channel critically in this result. Our formal\nresult is in the context of channel models for which \"good\" local schemes, that\nachieve the cut-set bound, exist (such as Gaussian MAC and broadcast channels,\nbroadcast erasure networks, fast fading Gaussian networks).\n  Layered architectures, common in the engineering-design of wireless networks,\ncan have near-optimal performance if the {\\em locality} over which\nphysical-layer schemes should operate is carefully designed. Feedback is shown\nto play a critical role in enabling the separation between the physical and the\nnetwork layers. The key technical idea is the modeling of a wireless network by\nan undirected \"polymatroidal\" network, for which we establish a max-flow\nmin-cut approximation theorem. \n\n"}
{"id": "1111.5900", "contents": "Title: Cubature formulas and discrete fourier transform on compact manifolds Abstract: The goal of the paper is to describe essentially optimal cubature formulas on\ncompact Riemannian manifolds which are exact on spaces of band- limited\nfunctions. \n\n"}
{"id": "1112.0674", "contents": "Title: Analytical Evaluation of Fractional Frequency Reuse for Heterogeneous\n  Cellular Networks Abstract: Interference management techniques are critical to the performance of\nheterogeneous cellular networks, which will have dense and overlapping coverage\nareas, and experience high levels of interference. Fractional frequency reuse\n(FFR) is an attractive interference management technique due to its low\ncomplexity and overhead, and significant coverage improvement for\nlow-percentile (cell-edge) users. Instead of relying on system simulations\nbased on deterministic access point locations, this paper instead proposes an\nanalytical model for evaluating Strict FFR and Soft Frequency Reuse (SFR)\ndeployments based on the spatial Poisson point process. Our results both\ncapture the non-uniformity of heterogeneous deployments and produce tractable\nexpressions which can be used for system design with Strict FFR and SFR. We\nobserve that the use of Strict FFR bands reserved for the users of each tier\nwith the lowest average SINR provides the highest gains in terms of coverage\nand rate, while the use of SFR allows for more efficient use of shared spectrum\nbetween the tiers, while still mitigating much of the interference.\nAdditionally, in the context of multi-tier networks with closed access in some\ntiers, the proposed framework shows the impact of cross-tier interference on\nclosed access FFR, and informs the selection of key FFR parameters in open\naccess. \n\n"}
{"id": "1112.1770", "contents": "Title: Polar codes for the m-user multiple access channels Abstract: Polar codes are constructed for m-user multiple access channels (MAC) whose\ninput alphabet size is a prime number. The block error probability under\nsuccessive cancelation decoding decays exponentially with the square root of\nthe block length. Although the sum capacity is achieved by this coding scheme,\nsome points in the symmetric capacity region may not be achieved. In the case\nwhere the channel is a combination of linear channels, we provide a necessary\nand sufficient condition characterizing the channels whose symmetric capacity\nregion is preserved upon the polarization process. We also provide a sufficient\ncondition for having a total loss in the dominant face. \n\n"}
{"id": "1112.2493", "contents": "Title: Symbolic transfer entropy rate is equal to transfer entropy rate for\n  bivariate finite-alphabet stationary ergodic Markov processes Abstract: Transfer entropy is a measure of the magnitude and the direction of\ninformation flow between jointly distributed stochastic processes. In recent\nyears, its permutation analogues are considered in the literature to estimate\nthe transfer entropy by counting the number of occurrences of orderings of\nvalues, not the values themselves. It has been suggested that the method of\npermutation is easy to implement, computationally low cost and robust to noise\nwhen applying to real world time series data. In this paper, we initiate a\ntheoretical treatment of the corresponding rates. In particular, we consider\nthe transfer entropy rate and its permutation analogue, the symbolic transfer\nentropy rate, and show that they are equal for any bivariate finite-alphabet\nstationary ergodic Markov process. This result is an illustration of the\nduality method introduced in [T. Haruna and K. Nakajima, Physica D 240, 1370\n(2011)]. We also discuss the relationship among the transfer entropy rate, the\ntime-delayed mutual information rate and their permutation analogues. \n\n"}
{"id": "1112.2690", "contents": "Title: Multilevel Coding Schemes for Compute-and-Forward with Flexible Decoding Abstract: We consider the design of coding schemes for the wireless two-way relaying\nchannel when there is no channel state information at the transmitter. In the\nspirit of the compute and forward paradigm, we present a multilevel coding\nscheme that permits computation (or, decoding) of a class of functions at the\nrelay. The function to be computed (or, decoded) is then chosen depending on\nthe channel realization. We define such a class of functions which can be\ndecoded at the relay using the proposed coding scheme and derive rates that are\nuniversally achievable over a set of channel gains when this class of functions\nis used at the relay. We develop our framework with general modulation formats\nin mind, but numerical results are presented for the case where each node\ntransmits using the QPSK constellation. Numerical results with QPSK show that\nthe flexibility afforded by our proposed scheme results in substantially higher\nrates than those achievable by always using a fixed function or by adapting the\nfunction at the relay but coding over GF(4). \n\n"}
{"id": "1112.3471", "contents": "Title: A Nonstochastic Information Theory for Communication and State\n  Estimation Abstract: In communications, unknown variables are usually modelled as random\nvariables, and concepts such as independence, entropy and information are\ndefined in terms of the underlying probability distributions. In contrast,\ncontrol theory often treats uncertainties and disturbances as bounded unknowns\nhaving no statistical structure. The area of networked control combines both\nfields, raising the question of whether it is possible to construct meaningful\nanalogues of stochastic concepts such as independence, Markovness, entropy and\ninformation without assuming a probability space. This paper introduces a\nframework for doing so, leading to the construction of a maximin information\nfunctional for nonstochastic variables. It is shown that the largest maximin\ninformation rate through a memoryless, error-prone channel in this framework\ncoincides with the block-coding zero-error capacity of the channel. Maximin\ninformation is then used to derive tight conditions for uniformly estimating\nthe state of a linear time-invariant system over such a channel, paralleling\nrecent results of Matveev and Savkin. \n\n"}
{"id": "1112.4167", "contents": "Title: Iterative Deterministic Equivalents for the Performance Analysis of\n  Communication Systems Abstract: In this article, we introduce iterative deterministic equivalents as a novel\ntechnique for the performance analysis of communication systems whose channels\nare modeled by complex combinations of independent random matrices. This\ntechnique extends the deterministic equivalent approach for the study of\nfunctionals of large random matrices to a broader class of random matrix models\nwhich naturally arise as channel models in wireless communications. We present\ntwo specific applications: First, we consider a multi-hop amplify-and-forward\n(AF) MIMO relay channel with noise at each stage and derive deterministic\napproximations of the mutual information after the Kth hop. Second, we study a\nMIMO multiple access channel (MAC) where the channel between each transmitter\nand the receiver is represented by the double-scattering channel model. We\nprovide deterministic approximations of the mutual information, the\nsignal-to-interference-plus-noise ratio (SINR) and sum-rate with\nminimum-mean-square-error (MMSE) detection and derive the asymptotically\noptimal precoding matrices. In both scenarios, the approximations can be\ncomputed by simple and provably converging fixed-point algorithms and are shown\nto be almost surely tight in the limit when the number of antennas at each node\ngrows infinitely large. Simulations suggest that the approximations are\naccurate for realistic system dimensions. The technique of iterative\ndeterministic equivalents can be easily extended to other channel models of\ninterest and is, therefore, also a new contribution to the field of random\nmatrix theory. \n\n"}
{"id": "1201.0830", "contents": "Title: Wireless Network-Coded Accumulate-Compute and Forward Two-Way Relaying Abstract: The design of modulation schemes for the physical layer network-coded two way\nwireless relaying scenario is considered. It was observed by Koike-Akino et al.\nfor the two way relaying scenario, that adaptively changing the network coding\nmap used at the relay according to the channel conditions greatly reduces the\nimpact of multiple access interference which occurs at the relay during the MA\nPhase and all these network coding maps should satisfy a requirement called\nexclusive law. We extend this approach to an Accumulate-Compute and Forward\nprotocol which employs two phases: Multiple Access (MA) phase consisting of two\nchannel uses with independent messages in each channel use, and Broadcast (BC)\nphase having one channel use. Assuming that the two users transmit points from\nthe same 4-PSK constellation, every such network coding map that satisfies the\nexclusive law can be represented by a Latin Square with side 16, and\nconversely, this relationship can be used to get the network coding maps\nsatisfying the exclusive law. Two methods of obtaining this network coding map\nto be used at the relay are discussed. Using the structural properties of the\nLatin Squares for a given set of parameters, the problem of finding all the\nrequired maps is reduced to finding a small set of maps. Having obtained all\nthe Latin Squares, the set of all possible channel realizations is quantized,\ndepending on which one of the Latin Squares obtained optimizes the performance.\nThe quantization thus obtained, is shown to be the same as the one obtained in\n[7] for the 2-stage bidirectional relaying. \n\n"}
{"id": "1201.2868", "contents": "Title: On Ergodic Secrecy Capacity of Multiple Input Wiretap Channel with\n  Statistical CSIT Abstract: We consider the secure transmission in ergodic fast-Rayleigh fading\nmultiple-input single-output single-antennaeavesdropper (MISOSE) wiretap\nchannels. We assume that the statistics of both the legitimate and eavesdropper\nchannels is the only available channel state information at the transmitter\n(CSIT). By introducing a new secrecy capacity upper bound, we prove that the\nsecrecy capacity is achieved by Gaussian input without prefixing. To attain\nthis, we form another MISOSE channel for upper-bounding, and tighten the bound\nby finding the worst correlations between the legitimate and eavesdropper\nchannel coefficients. The resulting upper bound is tighter than the others in\nthe literature which are based on modifying the correlation between the noises\nat the legitimate receiver and eavesdropper. Next, we fully characterize the\nergodic secrecy capacity by showing that the optimal channel input covariance\nmatrix is a scaled identity matrix, with the transmit power allocated uniformly\namong the antennas. The key to solve such a complicated stochastic optimization\nproblem is by exploiting the completely monotone property of the ergodic\nsecrecy capacity to use the stochastic ordering theory. Finally, our simulation\nresults show that for the considered channel setting, the secrecy capacity is\nbounded in both the high signal-to-noise ratio and large number of transmit\nantenna regimes. \n\n"}
{"id": "1201.3088", "contents": "Title: An Adaptive Modulation Scheme for Two-user Fading MAC with Quantized\n  Fade State Feedback Abstract: With no CSI at the users, transmission over the two-user Gaussian Multiple\nAccess Channel with fading and finite constellation at the input, is not\nefficient because error rates will be high when the channel conditions are\npoor. However, perfect CSI at the users is an unrealistic assumption in the\nwireless scenario, as it would involve massive feedback overheads. In this\npaper we propose a scheme which uses only quantized knowledge of CSI at the\ntransmitters with the overhead being nominal. The users rotate their\nconstellation without varying their transmit power to adapt to the existing\nchannel conditions, in order to meet certain pre-determined minimum Euclidean\ndistance requirement in the equivalent constellation at the destination. The\noptimal modulation scheme has been described for the case when both the users\nuse symmetric M-PSK constellations at the input, where $ M=2^\\lambda $, $\n\\lambda $ being a positive integer. The strategy has been illustrated by\nconsidering examples where both users use QPSK or 8-PSK signal sets at the\ninput. It is shown that the proposed scheme has better throughput and error\nperformance compared to the conventional non-adaptive scheme, at the cost of a\nfeedback overhead of just $\\lceil \\log_2(\\frac{M^2}{8}-\\frac{M}{4}+2)\\rceil + 1\n$ bits, for the M-PSK case. \n\n"}
{"id": "1201.4615", "contents": "Title: Augmented L1 and Nuclear-Norm Models with a Globally Linearly Convergent\n  Algorithm Abstract: This paper studies the long-existing idea of adding a nice smooth function to\n\"smooth\" a non-differentiable objective function in the context of sparse\noptimization, in particular, the minimization of\n$||x||_1+1/(2\\alpha)||x||_2^2$, where $x$ is a vector, as well as the\nminimization of $||X||_*+1/(2\\alpha)||X||_F^2$, where $X$ is a matrix and\n$||X||_*$ and $||X||_F$ are the nuclear and Frobenius norms of $X$,\nrespectively. We show that they can efficiently recover sparse vectors and\nlow-rank matrices. In particular, they enjoy exact and stable recovery\nguarantees similar to those known for minimizing $||x||_1$ and $||X||_*$ under\nthe conditions on the sensing operator such as its null-space property,\nrestricted isometry property, spherical section property, or RIPless property.\nTo recover a (nearly) sparse vector $x^0$, minimizing\n$||x||_1+1/(2\\alpha)||x||_2^2$ returns (nearly) the same solution as minimizing\n$||x||_1$ almost whenever $\\alpha\\ge 10||x^0||_\\infty$. The same relation also\nholds between minimizing $||X||_*+1/(2\\alpha)||X||_F^2$ and minimizing\n$||X||_*$ for recovering a (nearly) low-rank matrix $X^0$, if $\\alpha\\ge\n10||X^0||_2$. Furthermore, we show that the linearized Bregman algorithm for\nminimizing $||x||_1+1/(2\\alpha)||x||_2^2$ subject to $Ax=b$ enjoys global\nlinear convergence as long as a nonzero solution exists, and we give an\nexplicit rate of convergence. The convergence property does not require a\nsolution solution or any properties on $A$. To our knowledge, this is the best\nknown global convergence result for first-order sparse optimization algorithms. \n\n"}
{"id": "1201.5608", "contents": "Title: Combinatorial Channel Signature Modulation for Wireless ad-hoc Networks Abstract: In this paper we introduce a novel modulation and multiplexing method which\nfacilitates highly efficient and simultaneous communication between multiple\nterminals in wireless ad-hoc networks. We term this method Combinatorial\nChannel Signature Modulation (CCSM). The CCSM method is particularly efficient\nin situations where communicating nodes operate in highly time dispersive\nenvironments. This is all achieved with a minimal MAC layer overhead, since all\nusers are allowed to transmit and receive at the same time/frequency (full\nsimultaneous duplex). The CCSM method has its roots in sparse modelling and the\nreceiver is based on compressive sampling techniques. Towards this end, we\ndevelop a new low complexity algorithm termed Group Subspace Pursuit. Our\nanalysis suggests that CCSM at least doubles the throughput when compared to\nthe state-of-the art. \n\n"}
{"id": "1201.6548", "contents": "Title: Orthogonal Multiple Access with Correlated Sources: Feasible Region and\n  Pragmatic Schemes Abstract: In this paper, we consider orthogonal multiple access coding schemes, where\ncorrelated sources are encoded in a distributed fashion and transmitted,\nthrough additive white Gaussian noise (AWGN) channels, to an access point (AP).\nAt the AP, component decoders, associated with the source encoders, iteratively\nexchange soft information by taking into account the source correlation. The\nfirst goal of this paper is to investigate the ultimate achievable performance\nlimits in terms of a multi-dimensional feasible region in the space of channel\nparameters, deriving insights on the impact of the number of sources. The\nsecond goal is the design of pragmatic schemes, where the sources use\n\"off-the-shelf\" channel codes. In order to analyze the performance of given\ncoding schemes, we propose an extrinsic information transfer (EXIT)-based\napproach, which allows to determine the corresponding multi-dimensional\nfeasible regions. On the basis of the proposed analytical framework, the\nperformance of pragmatic coded schemes, based on serially concatenated\nconvolutional codes (SCCCs), is discussed. \n\n"}
{"id": "1202.0168", "contents": "Title: On the Capacity of Large-MIMO Block-Fading Channels Abstract: We characterize the capacity of Rayleigh block-fading multiple-input\nmultiple-output (MIMO) channels in the noncoherent setting where transmitter\nand receiver have no a priori knowledge of the realizations of the fading\nchannel. We prove that unitary space-time modulation (USTM) is not\ncapacity-achieving in the high signal-to-noise ratio (SNR) regime when the\ntotal number of antennas exceeds the coherence time of the fading channel\n(expressed in multiples of the symbol duration), a situation that is relevant\nfor MIMO systems with large antenna arrays (large-MIMO systems). This result\nsettles a conjecture by Zheng & Tse (2002) in the affirmative. The\ncapacity-achieving input signal, which we refer to as Beta-variate space-time\nmodulation (BSTM), turns out to be the product of a unitary isotropically\ndistributed random matrix, and a diagonal matrix whose nonzero entries are\ndistributed as the square-root of the eigenvalues of a Beta-distributed random\nmatrix of appropriate size. Numerical results illustrate that using BSTM\ninstead of USTM in large-MIMO systems yields a rate gain as large as 13% for\nSNR values of practical interest. \n\n"}
{"id": "1202.0204", "contents": "Title: On the Capacity of Interference Channel with Causal and Non-causal\n  Generalized Feedback at the Cognitive Transmitter Abstract: In this paper, taking into account the effect of link delays, we investigate\nthe capacity region of the Cognitive Interference Channel (C-IFC), where\ncognition can be obtained from either causal or non-causal generalized\nfeedback. For this purpose, we introduce the Causal Cognitive Interference\nChannel With Delay (CC-IFC-WD) in which the cognitive user's transmission can\ndepend on $L$ future received symbols as well as the past ones. We show that\nthe CC-IFC-WD model is equivalent to a classical Causal C-IFC (CC-IFC) with\nlink delays. Moreover, CC-IFC-WD extends both genie-aided and causal cognitive\nradio channels and bridges the gap between them. First, we derive an outer\nbound on the capacity region for the arbitrary value of $L$ and specialize this\ngeneral outer bound to the strong interference case. Then, under strong\ninterference conditions, we tighten the outer bound. To derive the achievable\nrate regions, we concentrate on three special cases: 1) Classical CC-IFC (L=0),\n2) CC-IFC without delay (L=1), and 3) CC-IFC with unlimited look-ahead in which\nthe cognitive user non-causally knows its entire received sequence. In each\ncase, we obtain a new inner bound on the capacity region. Moreover, we show\nthat the coding strategy which we use to derive an achievable rate region for\nthe classical CC-IFC achieves the capacity for the classes of degraded and\nsemi-deterministic classical CC-IFC under strong interference conditions.\nFurthermore, we extend our achievable rate regions to the Gaussian case.\nProviding some numerical examples for Gaussian CC-IFC-WD, we compare the\nperformances of the different strategies and investigate the rate gain of the\ncognitive link for different delay values. \n\n"}
{"id": "1202.0343", "contents": "Title: How Fast Can Dense Codes Achieve the Min-Cut Capacity of Line Networks? Abstract: In this paper, we study the coding delay and the average coding delay of\nrandom linear network codes (dense codes) over line networks with deterministic\nregular and Poisson transmission schedules. We consider both lossless networks\nand networks with Bernoulli losses. The upper bounds derived in this paper,\nwhich are in some cases more general, and in some other cases tighter, than the\nexisting bounds, provide a more clear picture of the speed of convergence of\ndense codes to the min-cut capacity of line networks. \n\n"}
{"id": "1202.0864", "contents": "Title: Nested Lattice Codes for Arbitrary Continuous Sources and Channels Abstract: In this paper, we show that nested lattice codes achieve the capacity of\narbitrary channels with or without non-casual state information at the\ntransmitter. We also show that nested lattice codes are optimal for source\ncoding with or without non-causal side information at the receiver for\narbitrary continuous sources. \n\n"}
{"id": "1202.0866", "contents": "Title: List-decoding of Subspace Codes and Rank-Metric Codes up to Singleton\n  Bound Abstract: Subspace codes and rank-metric codes can be used to correct errors and\nerasures in network, with linear network coding. Subspace codes were introduced\nby Koetter and Kschischang to correct errors and erasures in networks where\ntopology is unknown (the noncoherent case). In a previous work, we have\ndeveloped a family of subspace codes, based upon the Koetter-Kschichang\nconstruction, which are efficiently list decodable. Using these codes, we\nachieved a better decoding radius than Koetter-Kschischiang codes at low rates.\nHerein, we introduce a new family of subspace codes based upon a different\napproach which leads to a linear-algebraic list-decoding algorithm. The\nresulting error correction radius can be expressed as follows: for any integer\n$s$, our list-decoder using $s+1$-interpolation polynomials guarantees\nsuccessful recovery of the message subspace provided the normalized dimension\nof errors is at most $s(1-sR)$. The same list-decoding algorithm can be used to\ncorrect erasures as well as errors. The size of output list is at most\n$Q^{s-1}$, where $Q$ is the size of the field that message symbols are chosen\nfrom. Rank-metric codes are suitable for error correction in the case where the\nnetwork topology and the underlying network code are known (the coherent case).\nGabidulin codes are a well-known class of algebraic rank-metric codes that meet\nthe Singleton bound on the minimum rank metric of a code. In this paper, we\nintroduce a folded version of Gabidulin codes analogous to the folded\nReed-Solomon codes of Guruswami and Rudra along with a list-decoding algorithm\nfor such codes. Our list-decoding algorithm makes it possible to recover the\nmessage provided that the normalized rank of error is at most $1-R-\\epsilon$,\nfor any $\\epsilon > 0$. Notably this achieves the information theoretic bound\non the decoding radius of a rank-metric code. \n\n"}
{"id": "1202.1572", "contents": "Title: Expansion coding: Achieving the capacity of an AEN channel Abstract: A general method of coding over expansions is proposed, which allows one to\nreduce the highly non-trivial problem of coding over continuous channels to a\nmuch simpler discrete ones. More specifically, the focus is on the additive\nexponential noise (AEN) channel, for which the (binary) expansion of the\n(exponential) noise random variable is considered. It is shown that each of the\nrandom variables in the expansion corresponds to independent Bernoulli random\nvariables. Thus, each of the expansion levels (of the underlying channel)\ncorresponds to a binary symmetric channel (BSC), and the coding problem is\nreduced to coding over these parallel channels while satisfying the channel\ninput constraint. This optimization formulation is stated as the achievable\nrate result, for which a specific choice of input distribution is shown to\nachieve a rate which is arbitrarily close to the channel capacity in the high\nSNR regime. Remarkably, the scheme allows for low-complexity capacity-achieving\ncodes for AEN channels, using the codes that are originally designed for BSCs.\nExtensions to different channel models and applications to other coding\nproblems are discussed. \n\n"}
{"id": "1202.2167", "contents": "Title: Abstract Representations and Frequent Pattern Discovery Abstract: We discuss the frequent pattern mining problem in a general setting. From an\nanalysis of abstract representations, summarization and frequent pattern\nmining, we arrive at a generalization of the problem. Then, we show how the\nproblem can be cast into the powerful language of algorithmic information\ntheory. This allows us to formulate a simple algorithm to mine for all frequent\npatterns. \n\n"}
{"id": "1202.4034", "contents": "Title: PAR-Aware Large-Scale Multi-User MIMO-OFDM Downlink Abstract: We investigate an orthogonal frequency-division multiplexing (OFDM)-based\ndownlink transmission scheme for large-scale multi-user (MU) multiple-input\nmultiple-output (MIMO) wireless systems. The use of OFDM causes a high\npeak-to-average (power) ratio (PAR), which necessitates expensive and\npower-inefficient radio-frequency (RF) components at the base station. In this\npaper, we present a novel downlink transmission scheme, which exploits the\nmassive degrees-of-freedom available in large-scale MU-MIMO-OFDM systems to\nachieve low PAR. Specifically, we propose to jointly perform MU precoding, OFDM\nmodulation, and PAR reduction by solving a convex optimization problem. We\ndevelop a corresponding fast iterative truncation algorithm (FITRA) and show\nnumerical results to demonstrate tremendous PAR-reduction capabilities. The\nsignificantly reduced linearity requirements eventually enable the use of\nlow-cost RF components for the large-scale MU-MIMO-OFDM downlink. \n\n"}
{"id": "1202.4425", "contents": "Title: Relay Channel with Orthogonal Components and Structured Interference\n  Known at the Source Abstract: A relay channel with orthogonal components that is affected by an\ninterference signal that is noncausally available only at the source is\nstudied. The interference signal has structure in that it is produced by\nanother transmitter communicating with its own destination. Moreover, the\ninterferer is not willing to adjust its communication strategy to minimize the\ninterference. Knowledge of the interferer's signal may be acquired by the\nsource, for instance, by exploiting HARQ retransmissions on the interferer's\nlink. The source can then utilize the relay not only for communicating its own\nmessage, but also for cooperative interference mitigation at the destination by\ninforming the relay about the interference signal. Proposed transmission\nstrategies are based on partial decode-and-forward (PDF) relaying and leverage\nthe interference structure. Achievable schemes are derived for discrete\nmemoryless models, Gaussian and Ricean fading channels. Furthermore, optimal\nstrategies are identified in some special cases. Finally, numerical results\nbring insight into the advantages of utilizing the interference structure at\nthe source, relay or destination. \n\n"}
{"id": "1202.6555", "contents": "Title: Adaptive sensing using deterministic partial Hadamard matrices Abstract: This paper investigates the construction of deterministic matrices preserving\nthe entropy of random vectors with a given probability distribution. In\nparticular, it is shown that for random vectors having i.i.d. discrete\ncomponents, this is achieved by selecting a subset of rows of a Hadamard matrix\nsuch that (i) the selection is deterministic (ii) the fraction of selected rows\nis vanishing. In contrast, it is shown that for random vectors with i.i.d.\ncontinuous components, no partial Hadamard matrix of reduced dimension allows\nto preserve the entropy. These results are in agreement with the results of\nWu-Verdu on almost lossless analog compression. This paper is however motivated\nby the complexity attribute of Hadamard matrices, which allows the use of\nefficient and stable reconstruction algorithms. The proof technique is based on\na polar code martingale argument and on a new entropy power inequality for\ninteger-valued random variables. \n\n"}
{"id": "1203.1304", "contents": "Title: Analytical Modeling of Uplink Cellular Networks Abstract: Cellular uplink analysis has typically been undertaken by either a simple\napproach that lumps all interference into a single deterministic or random\nparameter in a Wyner-type model, or via complex system level simulations that\noften do not provide insight into why various trends are observed. This paper\nproposes a novel middle way using point processes that is both accurate and\nalso results in easy-to-evaluate integral expressions based on the Laplace\ntransform of the interference. We assume mobiles and base stations are randomly\nplaced in the network with each mobile pairing up to its closest base station.\nCompared to related recent work on downlink analysis, the proposed uplink model\ndiffers in two key features. First, dependence is considered between user and\nbase station point processes to make sure each base station serves a single\nmobile in the given resource block. Second, per-mobile power control is\nincluded, which further couples the transmission of mobiles due to\nlocation-dependent channel inversion. Nevertheless, we succeed in deriving the\ncoverage (equivalently outage) probability of a typical link in the network.\nThis model can be used to address a wide variety of system design questions in\nthe future. In this paper we focus on the implications for power control and\nsee that partial channel inversion should be used at low\nsignal-to-interference-plus-noise ratio (SINR), while full power transmission\nis optimal at higher SINR. \n\n"}
{"id": "1203.1376", "contents": "Title: MIMO Multiple Access Channel with an Arbitrarily Varying Eavesdropper Abstract: A two-transmitter Gaussian multiple access wiretap channel with multiple\nantennas at each of the nodes is investigated. The channel matrices at the\nlegitimate terminals are fixed and revealed to all the terminals, whereas the\nchannel matrix of the eavesdropper is arbitrarily varying and only known to the\neavesdropper. The secrecy degrees of freedom (s.d.o.f.) region under a strong\nsecrecy constraint is characterized. A transmission scheme that orthogonalizes\nthe transmit signals of the two users at the intended receiver and uses a\nsingle-user wiretap code is shown to be sufficient to achieve the s.d.o.f.\nregion. The converse involves establishing an upper bound on a\nweighted-sum-rate expression. This is accomplished by using induction, where at\neach step one combines the secrecy and multiple-access constraints associated\nwith an adversary eavesdropping a carefully selected group of sub-channels. \n\n"}
{"id": "1203.1570", "contents": "Title: In-network Sparsity-regularized Rank Minimization: Algorithms and\n  Applications Abstract: Given a limited number of entries from the superposition of a low-rank matrix\nplus the product of a known fat compression matrix times a sparse matrix,\nrecovery of the low-rank and sparse components is a fundamental task subsuming\ncompressed sensing, matrix completion, and principal components pursuit. This\npaper develops algorithms for distributed sparsity-regularized rank\nminimization over networks, when the nuclear- and $\\ell_1$-norm are used as\nsurrogates to the rank and nonzero entry counts of the sought matrices,\nrespectively. While nuclear-norm minimization has well-documented merits when\ncentralized processing is viable, non-separability of the singular-value sum\nchallenges its distributed minimization. To overcome this limitation, an\nalternative characterization of the nuclear norm is adopted which leads to a\nseparable, yet non-convex cost minimized via the alternating-direction method\nof multipliers. The novel distributed iterations entail reduced-complexity\nper-node tasks, and affordable message passing among single-hop neighbors.\nInterestingly, upon convergence the distributed (non-convex) estimator provably\nattains the global optimum of its centralized counterpart, regardless of\ninitialization. Several application domains are outlined to highlight the\ngenerality and impact of the proposed framework. These include unveiling\ntraffic anomalies in backbone networks, predicting networkwide path latencies,\nand mapping the RF ambiance using wireless cognitive radios. Simulations with\nsynthetic and real network data corroborate the convergence of the novel\ndistributed algorithm, and its centralized performance guarantees. \n\n"}
{"id": "1203.2316", "contents": "Title: Near-optimal quantization and linear network coding for relay networks Abstract: We introduce a discrete network corresponding to any Gaussian wireless\nnetwork that is obtained by simply quantizing the received signals and\nrestricting the transmitted signals to a finite precision. Since signals in the\ndiscrete network are obtained from those of a Gaussian network, the Gaussian\nnetwork can be operated on the quantization-based digital interface defined by\nthe discrete network. We prove that this digital interface is near-optimal for\nGaussian relay networks and the capacities of the Gaussian and the discrete\nnetworks are within a bounded gap of O(M^2) bits, where M is the number of\nnodes.\n  We prove that any near-optimal coding strategy for the discrete network can\nbe naturally transformed into a near-optimal coding strategy for the Gaussian\nnetwork merely by quantization. We exploit this by designing a linear coding\nstrategy for the case of layered discrete relay networks. The linear coding\nstrategy is near-optimal for Gaussian and discrete networks and achieves rates\nwithin O(M^2) bits of the capacity, independent of channel gains or SNR. The\nlinear code is robust and the relays need not know the channel gains. The\ntransmit and receive signals at all relays are simply quantized to binary\ntuples of the same length $n$ . The linear network code requires all the relay\nnodes to collect the received binary tuples into a long binary vector and apply\na linear transformation on the long vector. The resulting binary vector is\nsplit into smaller binary tuples for transmission by the relays. The\nquantization requirements of the linear network code are completely defined by\nthe parameter $n$, which also determines the resolution of the\nanalog-to-digital and digital-to-analog convertors for operating the network\nwithin a bounded gap of the network's capacity. The linear network code\nexplicitly connects network coding for wireline networks with codes for\nGaussian networks. \n\n"}
{"id": "1203.3322", "contents": "Title: A note on Shannon entropy Abstract: We present a somewhat different way of looking on Shannon entropy. This leads\nto an axiomatisation of Shannon entropy that is essentially equivalent to that\nof Fadeev. In particular we give a new proof of Fadeev theorem. \n\n"}
{"id": "1203.3659", "contents": "Title: Cognitive Wyner Networks with Clustered Decoding Abstract: We study an interference network where equally-numbered transmitters and\nreceivers lie on two parallel lines, each transmitter opposite its intended\nreceiver. We consider two short-range interference models: the \"asymmetric\nnetwork,\" where the signal sent by each transmitter is interfered only by the\nsignal sent by its left neighbor (if present), and a \"symmetric network,\" where\nit is interfered by both its left and its right neighbors. Each transmitter is\ncognizant of its own message, the messages of the $t_\\ell$ transmitters to its\nleft, and the messages of the $t_r$ transmitters to its right. Each receiver\ndecodes its message based on the signals received at its own antenna, at the\n$r_\\ell$ receive antennas to its left, and the $r_r$ receive antennas to its\nright. For such networks we provide upper and lower bounds on the multiplexing\ngain, i.e., on the high-SNR asymptotic logarithmic growth of the sum-rate\ncapacity. In some cases our bounds meet, e.g., for the asymmetric network. Our\nresults exhibit an equivalence between the transmitter side-information\nparameters $t_\\ell, t_r$ and the receiver side-information parameters $r_\\ell,\nr_r$ in the sense that increasing/decreasing $t_\\ell$ or $t_r$ by a positive\ninteger $\\delta$ has the same effect on the multiplexing gain as\nincreasing/decreasing $r_\\ell$ or $r_r$ by $\\delta$. Moreover---even in\nasymmetric networks---there is an equivalence between the left side-information\nparameters $t_\\ell, r_\\ell$ and the right side-information parameters $t_r,\nr_r$. \n\n"}
{"id": "1203.4583", "contents": "Title: Multi-Antenna System Design with Bright Transmitters and Blind Receivers Abstract: This paper considers a scenario for multi-input multi-output (MIMO)\ncommunication systems when perfect channel state information at the transmitter\n(CSIT) is given while the equivalent channel state information at the receiver\n(CSIR) is not available. Such an assumption is valid for the downlink\nmulti-user MIMO systems with linear precoders that depend on channels to all\nreceivers. We propose a concept called dual systems with zero-forcing designs\nbased on the duality principle, originally proposed to relate Gaussian\nmulti-access channels (MACs) and Gaussian broadcast channels (BCs). For the\ntwo-user N*2 MIMO BC with N antennas at the transmitter and two antennas at\neach of the receivers, we design a downlink interference cancellation (IC)\ntransmission scheme using the dual of uplink MAC systems employing IC methods.\nThe transmitter simultaneously sends two precoded Alamouti codes, one for each\nuser. Each receiver can zero-force the unintended user's Alamouti codes and\ndecouple its own data streams using two simple linear operations independent of\nCSIR. Analysis shows that the proposed scheme achieves a diversity gain of\n2(N-1) for equal energy constellations with short-term power and rate\nconstraints. Power allocation between two users can also be performed, and it\nimproves the array gain but not the diversity gain. Numerical results\ndemonstrate that the bit error rate of the downlink IC scheme has a substantial\ngain compared to the block diagonalization method, which requires global\nchannel information at each node. \n\n"}
{"id": "1203.5362", "contents": "Title: Throughput Optimal Scheduling with Dynamic Channel Feedback Abstract: It is well known that opportunistic scheduling algorithms are throughput\noptimal under full knowledge of channel and network conditions. However, these\nalgorithms achieve a hypothetical achievable rate region which does not take\ninto account the overhead associated with channel probing and feedback required\nto obtain the full channel state information at every slot. We adopt a channel\nprobing model where $\\beta$ fraction of time slot is consumed for acquiring the\nchannel state information (CSI) of a single channel. In this work, we design a\njoint scheduling and channel probing algorithm named SDF by considering the\noverhead of obtaining the channel state information. We first analytically\nprove SDF algorithm can support $1+\\epsilon$ fraction of of the full rate\nregion achieved when all users are probed where $\\epsilon$ depends on the\nexpected number of users which are not probed. Then, for homogenous channel, we\nshow that when the number of users in the network is greater than 3, $\\epsilon\n> 0$, i.e., we guarantee to expand the rate region. In addition, for\nheterogenous channels, we prove the conditions under which SDF guarantees to\nincrease the rate region. We also demonstrate numerically in a realistic\nsimulation setting that this rate region can be achieved by probing only less\nthan 50% of all channels in a CDMA based cellular network utilizing high data\nrate protocol under normal channel conditions. \n\n"}
{"id": "1204.0590", "contents": "Title: Linear System Identification via Atomic Norm Regularization Abstract: This paper proposes a new algorithm for linear system identification from\nnoisy measurements. The proposed algorithm balances a data fidelity term with a\nnorm induced by the set of single pole filters. We pose a convex optimization\nproblem that approximately solves the atomic norm minimization problem and\nidentifies the unknown system from noisy linear measurements. This problem can\nbe solved efficiently with standard, freely available software. We provide\nrigorous statistical guarantees that explicitly bound the estimation error (in\nthe H_2-norm) in terms of the stability radius, the Hankel singular values of\nthe true system and the number of measurements. These results in turn yield\ncomplexity bounds and asymptotic consistency. We provide numerical experiments\ndemonstrating the efficacy of our method for estimating linear systems from a\nvariety of linear measurements. \n\n"}
{"id": "1204.0867", "contents": "Title: Optimal Index Codes for a Class of Multicast Networks with Receiver Side\n  Information Abstract: This paper studies a special class of multicast index coding problems where a\nsender transmits messages to multiple receivers, each with some side\ninformation. Here, each receiver knows a unique message a priori, and there is\nno restriction on how many messages each receiver requests from the sender. For\nthis class of multicast index coding problems, we obtain the optimal index\ncode, which has the shortest codelength for which the sender needs to send in\norder for all receivers to obtain their (respective) requested messages. This\nis the first class of index coding problems where the optimal index codes are\nfound. In addition, linear index codes are shown to be optimal for this class\nof index coding problems. \n\n"}
{"id": "1204.1595", "contents": "Title: Femtocaching and Device-to-Device Collaboration: A New Architecture for\n  Wireless Video Distribution Abstract: We present a new architecture to handle the ongoing explosive increase in the\ndemand for video content in wireless networks. It is based on distributed\ncaching of the content in femto-basestations with small or non-existing\nbackhaul capacity but with considerable storage space, called helper nodes. We\nalso consider using the mobile terminals themselves as caching helpers, which\ncan distribute video through device-to-device communications. This approach\nallows an improvement in the video throughput without deployment of any\nadditional infrastructure. The new architecture can improve video throughput by\none to two orders-of-magnitude. \n\n"}
{"id": "1204.4840", "contents": "Title: Energy-Delay Tradeoff and Dynamic Sleep Switching for Bluetooth-Like\n  Body-Area Sensor Networks Abstract: Wireless technology enables novel approaches to healthcare, in particular the\nremote monitoring of vital signs and other parameters indicative of people's\nhealth. This paper considers a system scenario relevant to such applications,\nwhere a smart-phone acts as a data-collecting hub, gathering data from a number\nof wireless-capable body sensors, and relaying them to a healthcare provider\nhost through standard existing cellular networks. Delay of critical data and\nsensors' energy efficiency are both relevant and conflicting issues. Therefore,\nit is important to operate the wireless body-area sensor network at some\ndesired point close to the optimal energy-delay tradeoff curve. This tradeoff\ncurve is a function of the employed physical-layer protocol: in particular, it\ndepends on the multiple-access scheme and on the coding and modulation schemes\navailable. In this work, we consider a protocol closely inspired by the\nwidely-used Bluetooth standard. First, we consider the calculation of the\nminimum energy function, i.e., the minimum sum energy per symbol that\nguarantees the stability of all transmission queues in the network. Then, we\napply the general theory developed by Neely to develop a dynamic scheduling\npolicy that approaches the optimal energy-delay tradeoff for the network at\nhand. Finally, we examine the queue dynamics and propose a novel policy that\nadaptively switches between connected and disconnected (sleeping) modes. We\ndemonstrate that the proposed policy can achieve significant gains in the\nrealistic case where the control \"NULL\" packets necessary to maintain the\nconnection alive, have a non-zero energy cost, and the data arrival statistics\ncorresponding to the sensed physical process are bursty. \n\n"}
{"id": "1204.5317", "contents": "Title: Correction Trees as an Alternative to Turbo Codes and Low Density Parity\n  Check Codes Abstract: The rapidly improving performance of modern hardware renders convolutional\ncodes obsolete, and allows for the practical implementation of more\nsophisticated correction codes such as low density parity check (LDPC) and\nturbo codes (TC). Both are decoded by iterative algorithms, which require a\ndisproportional computational effort for low channel noise. They are also\nunable to correct higher noise levels, still below the Shannon theoretical\nlimit. In this paper, we discuss an enhanced version of a convolutional-like\ndecoding paradigm which adopts very large spaces of possible system states, of\nthe order of $2^{64}$. Under such conditions, the traditional convolution\noperation is rendered useless and needs to be replaced by a carefully designed\nstate transition procedure. The size of the system state space completely\nchanges the correction philosophy, as state collisions are virtually impossible\nand the decoding procedure becomes a correction tree. The proposed decoding\nalgorithm is practically cost-free for low channel noise. As the channel noise\napproaches the Shannon limit, it is still possible to perform correction,\nalthough its cost increases to infinity. In many applications, the implemented\ndecoder can essentially outperform both LDPC and TC. This paper describes the\nproposed correction paradigm and theoretically analyzes the asymptotic\ncorrection performance. The considered encoder and decoder were verified\nexperimentally for the binary symmetric channel. The correction process remains\npractically cost-free for channel error rates below 0.05 and 0.13 for the 1/2\nand 1/4 rate codes, respectively. For the considered resource limit, the output\nbit error rates reach the order of $10^{-3}$ for channel error rates 0.08 and\n0.18. The proposed correction paradigm can be easily extended to other\ncommunication channels; the appropriate generalizations are also discussed in\nthis study. \n\n"}
{"id": "1204.5467", "contents": "Title: A new upper bound on the query complexity for testing generalized\n  Reed-Muller codes Abstract: Over a finite field $\\F_q$ the $(n,d,q)$-Reed-Muller code is the code given\nby evaluations of $n$-variate polynomials of total degree at most $d$ on all\npoints (of $\\F_q^n$). The task of testing if a function $f:\\F_q^n \\to \\F_q$ is\nclose to a codeword of an $(n,d,q)$-Reed-Muller code has been of central\ninterest in complexity theory and property testing. The query complexity of\nthis task is the minimal number of queries that a tester can make (minimum over\nall testers of the maximum number of queries over all random choices) while\naccepting all Reed-Muller codewords and rejecting words that are $\\delta$-far\nfrom the code with probability $\\Omega(\\delta)$. (In this work we allow the\nconstant in the $\\Omega$ to depend on $d$.) In this work we give a new upper\nbound of $(c q)^{(d+1)/q}$ on the query complexity, where $c$ is a universal\nconstant. In the process we also give new upper bounds on the \"spanning weight\"\nof the dual of the Reed-Muller code (which is also a Reed-Muller code). The\nspanning weight of a code is the smallest integer $w$ such that codewords of\nHamming weight at most $w$ span the code. \n\n"}
{"id": "1204.6537", "contents": "Title: Recovery of Low-Rank Plus Compressed Sparse Matrices with Application to\n  Unveiling Traffic Anomalies Abstract: Given the superposition of a low-rank matrix plus the product of a known fat\ncompression matrix times a sparse matrix, the goal of this paper is to\nestablish deterministic conditions under which exact recovery of the low-rank\nand sparse components becomes possible. This fundamental identifiability issue\narises with traffic anomaly detection in backbone networks, and subsumes\ncompressed sensing as well as the timely low-rank plus sparse matrix recovery\ntasks encountered in matrix decomposition problems. Leveraging the ability of\n$\\ell_1$- and nuclear norms to recover sparse and low-rank matrices, a convex\nprogram is formulated to estimate the unknowns. Analysis and simulations\nconfirm that the said convex program can recover the unknowns for sufficiently\nlow-rank and sparse enough components, along with a compression matrix\npossessing an isometry property when restricted to operate on sparse vectors.\nWhen the low-rank, sparse, and compression matrices are drawn from certain\nrandom ensembles, it is established that exact recovery is possible with high\nprobability. First-order algorithms are developed to solve the nonsmooth convex\noptimization problem with provable iteration complexity guarantees. Insightful\ntests with synthetic and real network data corroborate the effectiveness of the\nnovel approach in unveiling traffic anomalies across flows and time, and its\nability to outperform existing alternatives. \n\n"}
{"id": "1205.4266", "contents": "Title: Chernoff Bounds for Analysis of Rate-Compatible Sphere-Packing with\n  Numerous Transmissions Abstract: Recent results by Chen et al. and Polyanskiy et al. explore using feedback to\napproach capacity with short blocklengths. This paper explores Chernoff\nbounding techniques to extend the rate-compatible sphere-packing (RCSP)\nanalysis proposed by Chen et al. to scenarios involving numerous\nretransmissions and different step sizes in each incremental retransmission.\nWilliamson et al. employ exact RCSP computations for up to six transmissions.\nHowever, exact RCSP computation with more than six retransmissions becomes\nunwieldy because of joint error probabilities involving numerous chi-squared\ndistributions. This paper explores Chernoff approaches for upper and lower\nbounds to provide support for computations involving more than six\ntransmissions.\n  We present two versions of upper and lower bounds for the two-transmission\ncase. One of the versions is extended to the general case of $m$ transmissions\nwhere $m \\geq 1$. Computing the general bounds requires minimization of\nexponential functions with the auxiliary parameters, but is less complex and\nmore stable than multiple rounds of numerical integration. These bounds also\nprovide a good estimate of the expected throughput and expected latency, which\nare useful for optimization purposes. \n\n"}
{"id": "1205.4781", "contents": "Title: An Achievable Rate Region for Three-Pair Interference Channels with\n  Noise Abstract: An achievable rate region for certain noisy three-user-pair interference\nchannels is proposed. The channel class under consideration generalizes the\nthree-pair deterministic interference channel (3-DIC) in the same way as the\nTelatar-Tse noisy two-pair interference channel generalizes the El Gamal-Costa\ninjective channel. Specifically, arbitrary noise is introduced that acts on the\ncombined interference signal before it affects the desired signal. This class\nof channels includes the Gaussian case.\n  The rate region includes the best-known inner bound on the 3-DIC capacity\nregion, dominates treating interference as noise, and subsumes the\nHan-Kobayashi region for the two-pair case. \n\n"}
{"id": "1205.4856", "contents": "Title: Bounds on Minimum Number of Anchors for Iterative Localization and its\n  Connections to Bootstrap Percolation Abstract: Iterated localization is considered where each node of a network needs to get\nlocalized (find its location on 2-D plane), when initially only a subset of\nnodes have their location information. The iterated localization process\nproceeds as follows. Starting with a subset of nodes that have their location\ninformation, possibly using global positioning system (GPS) devices, any other\nnode gets localized if it has three or more localized nodes in its radio range.\nThe newly localized nodes are included in the subset of nodes that have their\nlocation information for the next iteration. This process is allowed to\ncontinue, until no new node can be localized. The problem is to find the\nminimum size of the initially localized subset to start with so that the whole\nnetwork is localized with high probability. There are intimate connections\nbetween iterated localization and bootstrap percolation, that is well studied\nin statistical physics. Using results known in bootstrap percolation, we find a\nsufficient condition on the size of the initially localized subset that\nguarantees the localization of all nodes in the network with high probability. \n\n"}
{"id": "1205.4988", "contents": "Title: Capacity of Diffusion-based Molecular Communication with Ligand\n  Receptors Abstract: A diffusion-based molecular communication system has two major components:\nthe diffusion in the medium, and the ligand-reception. Information bits,\nencoded in the time variations of the concentration of molecules, are conveyed\nto the receiver front through the molecular diffusion in the medium. The\nreceiver, in turn, measures the concentration of the molecules in its vicinity\nin order to retrieve the information. This is done via ligand-reception\nprocess. In this paper, we develop models to study the constraints imposed by\nthe concentration sensing at the receiver side and derive the maximum rate by\nwhich a ligand-receiver can receive information. Therefore, the overall\ncapacity of the diffusion channel with the ligand receptors can be obtained by\ncombining the results presented in this paper with our previous work on the\nachievable information rate of molecular communication over the diffusion\nchannel. \n\n"}
{"id": "1205.5465", "contents": "Title: Isometry and Automorphisms of Constant Dimension Codes Abstract: We define linear and semilinear isometry for general subspace codes, used for\nrandom network coding. Furthermore, some results on isometry classes and\nautomorphism groups of known constant dimension code constructions are derived. \n\n"}
{"id": "1206.0937", "contents": "Title: Detecting Activations over Graphs using Spanning Tree Wavelet Bases Abstract: We consider the detection of activations over graphs under Gaussian noise,\nwhere signals are piece-wise constant over the graph. Despite the wide\napplicability of such a detection algorithm, there has been little success in\nthe development of computationally feasible methods with proveable theoretical\nguarantees for general graph topologies. We cast this as a hypothesis testing\nproblem, and first provide a universal necessary condition for asymptotic\ndistinguishability of the null and alternative hypotheses. We then introduce\nthe spanning tree wavelet basis over graphs, a localized basis that reflects\nthe topology of the graph, and prove that for any spanning tree, this approach\ncan distinguish null from alternative in a low signal-to-noise regime. Lastly,\nwe improve on this result and show that using the uniform spanning tree in the\nbasis construction yields a randomized test with stronger theoretical\nguarantees that in many cases matches our necessary conditions. Specifically,\nwe obtain near-optimal performance in edge transitive graphs, $k$-nearest\nneighbor graphs, and $\\epsilon$-graphs. \n\n"}
{"id": "1206.3953", "contents": "Title: Probabilistic Reconstruction in Compressed Sensing: Algorithms, Phase\n  Diagrams, and Threshold Achieving Matrices Abstract: Compressed sensing is a signal processing method that acquires data directly\nin a compressed form. This allows one to make less measurements than what was\nconsidered necessary to record a signal, enabling faster or more precise\nmeasurement protocols in a wide range of applications. Using an\ninterdisciplinary approach, we have recently proposed in [arXiv:1109.4424] a\nstrategy that allows compressed sensing to be performed at acquisition rates\napproaching to the theoretical optimal limits. In this paper, we give a more\nthorough presentation of our approach, and introduce many new results. We\npresent the probabilistic approach to reconstruction and discuss its optimality\nand robustness. We detail the derivation of the message passing algorithm for\nreconstruction and expectation max- imization learning of signal-model\nparameters. We further develop the asymptotic analysis of the corresponding\nphase diagrams with and without measurement noise, for different distribution\nof signals, and discuss the best possible reconstruction performances\nregardless of the algorithm. We also present new efficient seeding matrices,\ntest them on synthetic data and analyze their performance asymptotically. \n\n"}
{"id": "1206.4226", "contents": "Title: Three-User Cognitive Interference Channel: Capacity Region with Strong\n  Interference Abstract: This study investigates the capacity region of a three-user cognitive radio\nnetwork with two primary users and one cognitive user. A three-user Cognitive\nInterference Channel (C-IFC) is proposed by considering a three-user\nInterference Channel (IFC) where one of the transmitters has cognitive\ncapabilities and knows the messages of the other two transmitters in a\nnon-causal manner. First, two inner bounds on the capacity region of the\nthree-user C-IFC are obtained based on using the schemes which allow all\nreceivers to decode all messages with two different orders. Next, two sets of\nconditions are derived, under which the capacity region of the proposed model\ncoincides with the capacity region of a three-user C-IFC in which all three\nmessages are required at all receivers. Under these conditions, referred to as\nstrong interference conditions, the capacity regions for the proposed\nthree-user C-IFC are characterized. Moreover, the Gaussian three-user C-IFC is\nconsidered and the capacity results are derived for the Gaussian case. Some\nnumerical examples are also provided. \n\n"}
{"id": "1206.4389", "contents": "Title: Improving Two-Way Selective Decode-and-forward Wireless Relaying with\n  Energy-Efficient One-bit Soft Forwarding Abstract: Motivated by applications such as battery-operated wireless sensor networks\n(WSN), we propose an easy-to-implement energy-efficient two-way relaying\nscheme. In particular, we address the challenge of improving the standard\ntwo-way selective decode-and-forward protocol (TW-SDF) in terms of\nblock-error-rate (BLER) with minor additional complexity and energy\nconsumption. By following the principle of soft relaying, our solution is the\ntwo-way one-bit soft forwarding (TW-1bSF) protocol in which the relay forwards\nthe one-bit quantization of a posterior information metric about the\ntransmitted bits, associated with an appropriately designed reliability\nparameter.\n  In WSN-related standards (such as IEEE802.15.6 and Bluetooth), block codes\nare adopted instead of convolutional and other sophisticated codes, due to\ntheir efficient decoder hardware implementation. As the second main\ncontribution, we derive tight upper bounds on the BLER performance for both\nTW-SDF and TW-1bSF, when the two-way relaying network employs block codes and\nhard decoding. The error probability analysis confirms the superiority of\nTW-1bSF. Moreover, we derive the asymptotic performance gain of TW-1bSF over\nTW-SDF, which further suggests that the proposed protocol is a good choice,\nespecially when long block codes are used. \n\n"}
{"id": "1206.6145", "contents": "Title: Two-way Networks: when Adaptation is Useless Abstract: In two-way networks, nodes act as both sources and destinations of messages.\nThis allows for \"adaptation\" at or \"interaction\" between the nodes - a node's\nchannel inputs may be functions of its message(s) and previously received\nsignals. How to best adapt is key to two-way communication, rendering it\nchallenging. However, examples exist of point-to-point channels where\nadaptation is not beneficial from a capacity perspective. We ask whether\nanalogous examples exist for multi-user two-way networks.\n  We first consider deterministic two-way channel models: the binary modulo-2\naddition channel and a generalization thereof, and the linear deterministic\nchannel. For these deterministic models we obtain the capacity region for the\ntwo-way multiple access/broadcast channel, the two-way Z channel and the\ntwo-way interference channel (IC). In all cases we permit all nodes to adapt\nchannel inputs to past outputs (except for portions of the linear deterministic\ntwo-way IC where we only permit 2 of the 4 nodes to fully adapt). However, we\nshow that this adaptation is useless from a capacity region perspective and\ncapacity is achieved by strategies where the channel inputs at each use do not\nadapt to previous inputs. Finally, we consider the Gaussian two-way IC, and\nshow that partial adaptation is useless when the interference is very strong.\nIn the strong and weak interference regimes, we show that the non-adaptive Han\nand Kobayashi scheme utilized in parallel in both directions achieves to within\na constant gap for the symmetric rate of the fully (some regimes) or partially\n(remaining regimes) adaptive models.\n  The central technical contribution is the derivation of new, computable outer\nbounds which allow for adaptation. Inner bounds follow from non-adaptive\nachievability schemes of the corresponding one-way channel models. \n\n"}
{"id": "1207.0273", "contents": "Title: Performance Analysis for Heterogeneous Cellular Systems with Range\n  Expansion Abstract: Recently heterogeneous base station structure has been adopted in cellular\nsystems to enhance system throughput and coverage. In this paper, the uplink\ncoverage probability for the heterogeneous cellular systems is analyzed and\nderived in closed-form. The randomness on the locations and number of mobile\nusers is taken into account in the analysis. Based on the analytical results,\nthe impacts of various system parameters on the uplink performance are\ninvestigated in detail. The correctness of the analytical results is also\nverified by simulation results. These analytical results can thus serve as a\nguidance for system design without the need of time consuming simulations. \n\n"}
{"id": "1207.1517", "contents": "Title: On the Feasibility of Linear Interference Alignment for MIMO\n  Interference Broadcast Channels with Constant Coefficients Abstract: In this paper, we analyze the feasibility of linear interference alignment\n(IA) for multi-input-multi-output (MIMO) interference broadcast channel\n(MIMO-IBC) with constant coefficients. We pose and prove the necessary\nconditions of linear IA feasibility for general MIMO-IBC. Except for the proper\ncondition, we find another necessary condition to ensure a kind of irreducible\ninterference to be eliminated. We then prove the necessary and sufficient\nconditions for a special class of MIMO-IBC, where the numbers of antennas are\ndivisible by the number of data streams per user. Since finding an invertible\nJacobian matrix is crucial for the sufficiency proof, we first analyze the\nimpact of sparse structure and repeated structure of the Jacobian matrix.\nConsidering that for the MIMO-IBC the sub-matrices of the Jacobian matrix\ncorresponding to the transmit and receive matrices have different repeated\nstructure, we find an invertible Jacobian matrix by constructing the two\nsub-matrices separately. We show that for the MIMO-IBC where each user has one\ndesired data stream, a proper system is feasible. For symmetric MIMO-IBC, we\nprovide proper but infeasible region of antenna configurations by analyzing the\ndifference between the necessary conditions and the sufficient conditions of\nlinear IA feasibility. \n\n"}
{"id": "1207.1563", "contents": "Title: Achievable Sum-Rates in Gaussian Multiple-Access Channels with\n  MIMO-AF-Relay and Direct Links Abstract: We consider a single-antenna Gaussian multiple-access channel (MAC) with a\nmultiple-antenna amplify-and-forward (AF) relay, where, contrary to many\nprevious works, also the direct links between transmitters and receiver are\ntaken into account. For this channel, we investigate two transmit schemes:\nSending and relaying all signals jointly or using a time-division\nmultiple-access (TDMA) structure, where only one transmitter uses the channel\nat a time. While the optimal relaying matrices and time slot durations are\nfound for the latter scheme, we provide upper and lower bounds on the\nachievable sum-rate for the former one. These bounds are evaluated by Monte\nCarlo simulations, where it turns out that they are very close to each other.\nMoreover, these bounds are compared to the sum-rates achieved by the TDMA\nscheme. For the asymptotic case of high available transmit power at the relay,\nan analytic expression is given, which allows to determine the superior scheme. \n\n"}
{"id": "1207.2094", "contents": "Title: The Capacity of More Capable Cognitive Interference Channels Abstract: We establish the capacity region for a class of discrete memoryless cognitive\ninterference channel (DM-CIC) called cognitive-more-capable channel, and we\nshow that superposition coding is the optimal encoding technique. This is the\nlargest capacity region for the DM-CIC to date, as the existing capacity\nresults are explicitly shown to be its subsets. \n\n"}
{"id": "1207.2103", "contents": "Title: Precoding Methods for MISO Broadcast Channel with Delayed CSIT Abstract: Recent information theoretic results suggest that precoding on the multi-user\ndownlink MIMO channel with delayed channel state information at the transmitter\n(CSIT) could lead to data rates much beyond the ones obtained without any CSIT,\neven in extreme situations when the delayed channel feedback is made totally\nobsolete by a feedback delay exceeding the channel coherence time. This\nsurprising result is based on the ideas of interference repetition and\nalignment which allow the receivers to reconstruct information symbols which\ncanceling out the interference completely, making it an optimal scheme in the\ninfinite SNR regime. In this paper, we formulate a similar problem, yet at\nfinite SNR. We propose a first construction for the precoder which matches the\nprevious results at infinite SNR yet reaches a useful trade-off between\ninterference alignment and signal enhancement at finite SNR, allowing for\nsignificant performance improvements in practical settings. We present two\ngeneral precoding methods with arbitrary number of users by means of virtual\nMMSE and mutual information optimization, achieving good compromise between\nsignal enhancement and interference alignment. Simulation results show\nsubstantial improvement due to the compromise between those two aspects. \n\n"}
{"id": "1207.2825", "contents": "Title: Guard Zones and the Near-Far Problem in DS-CDMA Ad Hoc Networks Abstract: The central issue in direct-sequence code-division multiple-access (DS-CDMA)\nad hoc networks is the prevention of a near-far problem. This paper considers\ntwo types of guard zones that may be used to control the near-far problem: a\nfundamental exclusion zone and an additional CSMA guard zone that may be\nestablished by the carrier-sense multiple-access (CSMA) protocol. In the\nexclusion zone, no mobiles are physically present, modeling the minimum\nphysical separation among mobiles that is always present in actual networks.\nPotentially interfering mobiles beyond a transmitting mobile's exclusion zone,\nbut within its CSMA guard zone, are deactivated by the protocol. This paper\nprovides an analysis of DS-CSMA networks with either or both types of guard\nzones. A network of finite extent with a finite number of mobiles is modeled as\na uniform clustering process. The analysis uses a closed-form expression for\nthe outage probability in the presence of Nakagami fading, conditioned on the\nnetwork geometry. By using the analysis developed in this paper, the tradeoffs\nbetween exclusion zones and CSMA guard zones are explored for DS-CDMA and\nunspread networks. \n\n"}
{"id": "1207.2829", "contents": "Title: Sparse Recovery with Graph Constraints Abstract: Sparse recovery can recover sparse signals from a set of underdetermined\nlinear measurements. Motivated by the need to monitor large-scale networks from\na limited number of measurements, this paper addresses the problem of\nrecovering sparse signals in the presence of network topological constraints.\nUnlike conventional sparse recovery where a measurement can contain any subset\nof the unknown variables, we use a graph to characterize the topological\nconstraints and allow an additive measurement over nodes (unknown variables)\nonly if they induce a connected subgraph. We provide explicit measurement\nconstructions for several special graphs, and the number of measurements by our\nconstruction is less than that needed by existing random constructions.\nMoreover, our construction for a line network is provably optimal in the sense\nthat it requires the minimum number of measurements. A measurement construction\nalgorithm for general graphs is also proposed and evaluated. For any given\ngraph $G$ with $n$ nodes, we derive bounds of the minimum number of\nmeasurements needed to recover any $k$-sparse vector over $G$ ($M^G_{k,n}$).\nUsing the Erd\\H{o}s-R\\'enyi random graph as an example, we characterize the\ndependence of $M^G_{k,n}$ on the graph structure. \n\n"}
{"id": "1207.4707", "contents": "Title: Correction to \"A Note on Gallager's Capacity Theorem for Waveform\n  Channels\" Abstract: We correct an alleged contradiction to Gallager's capacity theorem for\nwaveform channels as presented in a poster at the 2012 IEEE International\nSymposium on Information Theory. \n\n"}
{"id": "1207.6706", "contents": "Title: Wireless MIMO Switching: Weighted Sum Mean Square Error and Sum Rate\n  Optimization Abstract: This paper addresses joint transceiver and relay design for a wireless\nmultiple-input-multiple-output (MIMO) switching scheme that enables data\nexchange among multiple users. Here, a multi-antenna relay linearly precodes\nthe received (uplink) signals from multiple users before forwarding the signal\nin the downlink, where the purpose of precoding is to let each user receive its\ndesired signal with interference from other users suppressed. The problem of\noptimizing the precoder based on various design criteria is typically\nnon-convex and difficult to solve. The main contribution of this paper is a\nunified approach to solve the weighted sum mean square error (MSE) minimization\nand weighted sum rate maximization problems in MIMO switching. Specifically, an\niterative algorithm is proposed for jointly optimizing the relay's precoder and\nthe users' receive filters to minimize the weighted sum MSE. It is also shown\nthat the weighted sum rate maximization problem can be reformulated as an\niterated weighted sum MSE minimization problem and can therefore be solved\nsimilarly to the case of weighted sum MSE minimization. With properly chosen\ninitial values, the proposed iterative algorithms are asymptotically optimal in\nboth high and low signal-to-noise ratio (SNR) regimes for MIMO switching,\neither with or without self-interference cancellation (a.k.a., physical-layer\nnetwork coding). Numerical results show that the optimized MIMO switching\nscheme based on the proposed algorithms significantly outperforms existing\napproaches in the literature. \n\n"}
{"id": "1208.1977", "contents": "Title: Offloading in Heterogeneous Networks: Modeling, Analysis, and Design\n  Insights Abstract: Pushing data traffic from cellular to WiFi is an example of inter radio\naccess technology (RAT) offloading. While this clearly alleviates congestion on\nthe over-loaded cellular network, the ultimate potential of such offloading and\nits effect on overall system performance is not well understood. To address\nthis, we develop a general and tractable model that consists of $M$ different\nRATs, each deploying up to $K$ different tiers of access points (APs), where\neach tier differs in transmit power, path loss exponent, deployment density and\nbandwidth. Each class of APs is modeled as an independent Poisson point process\n(PPP), with mobile user locations modeled as another independent PPP, all\nchannels further consisting of i.i.d. Rayleigh fading. The distribution of rate\nover the entire network is then derived for a weighted association strategy,\nwhere such weights can be tuned to optimize a particular objective. We show\nthat the optimum fraction of traffic offloaded to maximize $\\SINR$ coverage is\nnot in general the same as the one that maximizes rate coverage, defined as the\nfraction of users achieving a given rate. \n\n"}
{"id": "1208.2387", "contents": "Title: Instantly Decodable versus Random Linear Network Coding: A Comparative\n  Framework for Throughput and Decoding Delay Performance Abstract: This paper studies the tension between throughput and decoding delay\nperformance of two widely-used network coding schemes: random linear network\ncoding (RLNC) and instantly decodable network coding (IDNC). A single-hop\nbroadcasting system model is considered that aims to deliver a block of packets\nto all receivers in the presence of packet erasures. For a fair and\nanalytically tractable comparison between the two coding schemes, the\ntransmission comprises two phases: a systematic transmission phase and a\nnetwork coded transmission phase which is further divided into rounds. After\nthe systematic transmission phase and given the same packet reception state,\nthree quantitative metrics are proposed and derived in each scheme: 1) the\nabsolute minimum number of transmissions in the first coded transmission round\n(assuming no erasures), 2) probability distribution of extra coded\ntransmissions in a subsequent round (due to erasures), and 3) average packet\ndecoding delay. This comparative study enables application-aware adaptive\nselection between IDNC and RLNC after systematic transmission phase.\n  One contribution of this paper is to provide a deep and systematic\nunderstanding of the IDNC scheme, to propose the notion of packet diversity and\nan optimal IDNC encoding scheme for minimizing metric 1. This is generally\nNP-hard, but nevertheless required for characterizing and deriving all the\nthree metrics. Analytical and numerical results show that there is no clear\nwinner between RLNC and IDNC if one is concerned with both throughput and\ndecoding delay performance. IDNC is more preferable than RLNC when the number\nof receivers is smaller than packet block size, and the case reverses when the\nnumber of receivers is much greater than the packet block size. In the middle\nregime, the choice can depend on the application and a specific instance of the\nproblem. \n\n"}
{"id": "1208.3806", "contents": "Title: Dynamic Rate Adaptation for Improved Throughput and Delay in Wireless\n  Network Coded Broadcast Abstract: In this paper we provide theoretical and simulation-based study of the\ndelivery delay performance of a number of existing throughput optimal coding\nschemes and use the results to design a new dynamic rate adaptation scheme that\nachieves improved overall throughput-delay performance.\n  Under a baseline rate control scheme, the receivers' delay performance is\nexamined. Based on their Markov states, the knowledge difference between the\nsender and receiver, three distinct methods for packet delivery are identified:\nzero state, leader state and coefficient-based delivery. We provide analyses of\neach of these and show that, in many cases, zero state delivery alone presents\na tractable approximation of the expected packet delivery behaviour.\nInterestingly, while coefficient-based delivery has so far been treated as a\nsecondary effect in the literature, we find that the choice of coefficients is\nextremely important in determining the delay, and a well chosen encoding scheme\ncan, in fact, contribute a significant improvement to the delivery delay.\n  Based on our delivery delay model, we develop a dynamic rate adaptation\nscheme which uses performance prediction models to determine the sender\ntransmission rate. Surprisingly, taking this approach leads us to the simple\nconclusion that the sender should regulate its addition rate based on the total\nnumber of undelivered packets stored at the receivers. We show that despite its\nsimplicity, our proposed dynamic rate adaptation scheme results in noticeably\nimproved throughput-delay performance over existing schemes in the literature. \n\n"}
{"id": "1208.6125", "contents": "Title: Bounded-Contention Coding for Wireless Networks in the High SNR Regime Abstract: Efficient communication in wireless networks is typically challenged by the\npossibility of interference among several transmitting nodes. Much important\nresearch has been invested in decreasing the number of collisions in order to\nobtain faster algorithms for communication in such networks.\n  This paper proposes a novel approach for wireless communication, which\nembraces collisions rather than avoiding them, over an additive channel. It\nintroduces a coding technique called Bounded-Contention Coding (BCC) that\nallows collisions to be successfully decoded by the receiving nodes into the\noriginal transmissions and whose complexity depends on a bound on the\ncontention among the transmitters.\n  BCC enables deterministic local broadcast in a network with n nodes and at\nmost a transmitters with information of l bits each within O(a log n + al) bits\nof communication with full-duplex radios, and O((a log n + al)(log n)) bits,\nwith high probability, with half-duplex radios. When combined with random\nlinear network coding, BCC gives global broadcast within O((D + a + log n)(a\nlog n + l)) bits, with high probability. This also holds in dynamic networks\nthat can change arbitrarily over time by a worst-case adversary. When no bound\non the contention is given, it is shown how to probabilistically estimate it\nand obtain global broadcast that is adaptive to the true contention in the\nnetwork. \n\n"}
{"id": "1209.0245", "contents": "Title: Diffusion maps for changing data Abstract: Graph Laplacians and related nonlinear mappings into low dimensional spaces\nhave been shown to be powerful tools for organizing high dimensional data. Here\nwe consider a data set X in which the graph associated with it changes\ndepending on some set of parameters. We analyze this type of data in terms of\nthe diffusion distance and the corresponding diffusion map. As the data changes\nover the parameter space, the low dimensional embedding changes as well. We\ngive a way to go between these embeddings, and furthermore, map them all into a\ncommon space, allowing one to track the evolution of X in its intrinsic\ngeometry. A global diffusion distance is also defined, which gives a measure of\nthe global behavior of the data over the parameter space. Approximation\ntheorems in terms of randomly sampled data are presented, as are potential\napplications. \n\n"}
{"id": "1209.1380", "contents": "Title: The Sample Complexity of Search over Multiple Populations Abstract: This paper studies the sample complexity of searching over multiple\npopulations. We consider a large number of populations, each corresponding to\neither distribution P0 or P1. The goal of the search problem studied here is to\nfind one population corresponding to distribution P1 with as few samples as\npossible. The main contribution is to quantify the number of samples needed to\ncorrectly find one such population. We consider two general approaches:\nnon-adaptive sampling methods, which sample each population a predetermined\nnumber of times until a population following P1 is found, and adaptive sampling\nmethods, which employ sequential sampling schemes for each population. We first\nderive a lower bound on the number of samples required by any sampling scheme.\nWe then consider an adaptive procedure consisting of a series of sequential\nprobability ratio tests, and show it comes within a constant factor of the\nlower bound. We give explicit expressions for this constant when samples of the\npopulations follow Gaussian and Bernoulli distributions. An alternative\nadaptive scheme is discussed which does not require full knowledge of P1, and\ncomes within a constant factor of the optimal scheme. For comparison, a lower\nbound on the sampling requirements of any non-adaptive scheme is presented. \n\n"}
{"id": "1209.1402", "contents": "Title: Joint Spatial Division and Multiplexing Abstract: We propose Joint Spatial Division and Multiplexing (JSDM), an approach to\nmultiuser MIMO downlink that exploits the structure of the correlation of the\nchannel vectors in order to allow for a large number of antennas at the base\nstation while requiring reduced-dimensional Channel State Information at the\nTransmitter (CSIT). This allows for significant savings both in the downlink\ntraining and in the CSIT feedback from the user terminals to the base station,\nthus making the use of a large number of base station antennas potentially\nsuitable also for Frequency Division Duplexing (FDD) systems, for which\nuplink/downlink channel reciprocity cannot be exploited. JSDM forms the\nmultiuser MIMO downlink precoder by concatenating a pre-beamforming matrix,\nwhich depends only on the channel second-order statistics, with a classical\nmultiuser precoder, based on the instantaneous knowledge of the resulting\nreduced dimensional effective channels. We prove a simple condition under which\nJSDM incurs no loss of optimality with respect to the full CSIT case. For\nlinear uniformly spaced arrays, we show that such condition is closely\napproached when the number of antennas is large. For this case, we use Szego\nasymptotic theory of large Toeplitz matrices to design a DFT-based\npre-beamforming scheme requiring only coarse information about the users angles\nof arrival and angular spread. Finally, we extend these ideas to the case of a\ntwo-dimensional base station antenna array, with 3-dimensional beamforming,\nincluding multiple beams in the elevation angle direction. We provide\nguidelines for the pre-beamforming optimization and calculate the system\nspectral efficiency under proportional fairness and maxmin fairness criteria,\nshowing extremely attractive performance. Our numerical results are obtained\nvia an asymptotic random matrix theory tool known as deterministic equivalent\napproximation. \n\n"}
{"id": "1209.2138", "contents": "Title: Optimality Properties, Distributed Strategies, and Measurement-Based\n  Evaluation of Coordinated Multicell OFDMA Transmission Abstract: The throughput of multicell systems is inherently limited by interference and\nthe available communication resources. Coordinated resource allocation is the\nkey to efficient performance, but the demand on backhaul signaling and\ncomputational resources grows rapidly with number of cells, terminals, and\nsubcarriers. To handle this, we propose a novel multicell framework with\ndynamic cooperation clusters where each terminal is jointly served by a small\nset of base stations. Each base station coordinates interference to neighboring\nterminals only, thus limiting backhaul signalling and making the framework\nscalable. This framework can describe anything from interference channels to\nideal joint multicell transmission.\n  The resource allocation (i.e., precoding and scheduling) is formulated as an\noptimization problem (P1) with performance described by arbitrary monotonic\nfunctions of the signal-to-interference-and-noise ratios (SINRs) and arbitrary\nlinear power constraints. Although (P1) is non-convex and difficult to solve\noptimally, we are able to prove: 1) Optimality of single-stream beamforming; 2)\nConditions for full power usage; and 3) A precoding parametrization based on a\nfew parameters between zero and one. These optimality properties are used to\npropose low-complexity strategies: both a centralized scheme and a distributed\nversion that only requires local channel knowledge and processing. We evaluate\nthe performance on measured multicell channels and observe that the proposed\nstrategies achieve close-to-optimal performance among centralized and\ndistributed solutions, respectively. In addition, we show that multicell\ninterference coordination can give substantial improvements in sum performance,\nbut that joint transmission is very sensitive to synchronization errors and\nthat some terminals can experience performance degradations. \n\n"}
{"id": "1209.3366", "contents": "Title: Implement Blind Interference Alignment over Homogeneous 3-user 2x1\n  Broadcast Channel Abstract: This paper first studies the homogeneous 3-user 2x1 broadcast channel (BC)\nwith no CSIT. We show a sufficient condition for it to achieve the optimal 3/2\ndegrees of freedom (DoF) by using Blind Interference Alignment (BIA). BIA\nrefers to the interference alignment method without the need of CSIT. It\nfurther studies the 2x1 broadcast network in which there are K>=3 homogeneous\nsingle-antenna users, and their coherence time offsets are independently and\nuniformly distributed. We show that, if K>=11, the two-antenna transmitter can\nfind, with more than 95% certainty, three users to form a BIA-feasible 3-user\nBC and achieve the optimal 3/2 DoF. \n\n"}
{"id": "1209.4414", "contents": "Title: On Cyclic DNA Codes Abstract: This paper considers cyclic DNA codes of arbitrary length over the ring\n$R=\\F_2[u]/u^4-1$. A mapping is given between the elements of $R$ and the\nalphabet $\\{A,C,G,T\\}$ which allows the additive stem distance to be extended\nto this ring. Cyclic codes over $R$ are designed such that their images under\nthe mapping are also cyclic or quasi-cyclic of index 2. The additive distance\nand hybridization energy are functions of the neighborhood energy. \n\n"}
{"id": "1209.5259", "contents": "Title: Entropy Bounds for Discrete Random Variables via Maximal Coupling Abstract: This paper derives new bounds on the difference of the entropies of two\ndiscrete random variables in terms of the local and total variation distances\nbetween their probability mass functions. The derivation of the bounds relies\non maximal coupling, and they apply to discrete random variables which are\ndefined over finite or countably infinite alphabets. Loosened versions of these\nbounds are demonstrated to reproduce some previously reported results. The use\nof the new bounds is exemplified for the Poisson approximation, where bounds on\nthe local and total variation distances follow from Stein's method. \n\n"}
{"id": "1209.5656", "contents": "Title: Learning Price-Elasticity of Smart Consumers in Power Distribution\n  Systems Abstract: Demand Response is an emerging technology which will transform the power grid\nof tomorrow. It is revolutionary, not only because it will enable peak load\nshaving and will add resources to manage large distribution systems, but mainly\nbecause it will tap into an almost unexplored and extremely powerful pool of\nresources comprised of many small individual consumers on distribution grids.\nHowever, to utilize these resources effectively, the methods used to engage\nthese resources must yield accurate and reliable control. A diversity of\nmethods have been proposed to engage these new resources. As opposed to direct\nload control, many methods rely on consumers and/or loads responding to\nexogenous signals, typically in the form of energy pricing, originating from\nthe utility or system operator. Here, we propose an open loop\ncommunication-lite method for estimating the price elasticity of many customers\ncomprising a distribution system. We utilize a sparse linear regression method\nthat relies on operator-controlled, inhomogeneous minor price variations, which\nwill be fair to all the consumers. Our numerical experiments show that reliable\nestimation of individual and thus aggregated instantaneous elasticities is\npossible. We describe the limits of the reliable reconstruction as functions of\nthe three key parameters of the system: (i) ratio of the number of\ncommunication slots (time units) per number of engaged consumers; (ii) level of\nsparsity (in consumer response); and (iii) signal-to-noise ratio. \n\n"}
{"id": "1209.6412", "contents": "Title: Integer-Forcing MIMO Linear Receivers Based on Lattice Reduction Abstract: A new architecture called integer-forcing (IF) linear receiver has been\nrecently proposed for multiple-input multiple-output (MIMO) fading channels,\nwherein an appropriate integer linear combination of the received symbols has\nto be computed as a part of the decoding process. In this paper, we propose a\nmethod based on Hermite-Korkine-Zolotareff (HKZ) and Minkowski lattice basis\nreduction algorithms to obtain the integer coefficients for the IF receiver. We\nshow that the proposed method provides a lower bound on the ergodic rate, and\nachieves the full receive diversity. Suitability of complex\nLenstra-Lenstra-Lovasz (LLL) lattice reduction algorithm (CLLL) to solve the\nproblem is also investigated. Furthermore, we establish the connection between\nthe proposed IF linear receivers and lattice reduction-aided MIMO detectors\n(with equivalent complexity), and point out the advantages of the former class\nof receivers over the latter. For the $2 \\times 2$ and $4\\times 4$ MIMO\nchannels, we compare the coded-block error rate and bit error rate of the\nproposed approach with that of other linear receivers. Simulation results show\nthat the proposed approach outperforms the zero-forcing (ZF) receiver, minimum\nmean square error (MMSE) receiver, and the lattice reduction-aided MIMO\ndetectors. \n\n"}
{"id": "1210.2182", "contents": "Title: Approximate Ergodic Capacity of a Class of Fading 2-user 2-hop Networks Abstract: We consider a fading AWGN 2-user 2-hop network where the channel coefficients\nare independent and identically distributed (i.i.d.) drawn from a continuous\ndistribution and vary over time. For a broad class of channel distributions, we\ncharacterize the ergodic sum capacity to within a constant number of\nbits/sec/Hz, independent of signal-to-noise ratio. The achievability follows\nfrom the analysis of an interference neutralization scheme where the relays are\npartitioned into $M$ pairs, and interference is neutralized separately by each\npair of relays. When $M=1$, the proposed ergodic interference neutralization\ncharacterizes the ergodic sum capacity to within $4$ bits/sec/Hz for i.i.d.\nuniform phase fading and approximately $4.7$ bits/sec/Hz for i.i.d. Rayleigh\nfading. We further show that this gap can be tightened to $4\\log \\pi-4$\nbits/sec/Hz (approximately $2.6$) for i.i.d. uniform phase fading and $4-4\\log(\n\\frac{3\\pi}{8})$ bits/sec/Hz (approximately $3.1$) for i.i.d. Rayleigh fading\nin the limit of large $M$. \n\n"}
{"id": "1210.3667", "contents": "Title: A New Analysis of the DS-CDMA Cellular Downlink Under Spatial\n  Constraints Abstract: The direct-sequence code-division multiple access (DS-CDMA) cellular downlink\nis modeled by a constrained random spatial model involving a fixed number of\nbase stations placed over a finite area with a minimum separation. The analysis\nis driven by a new closed-form expression for the conditional outage\nprobability at each mobile, where the conditioning is with respect to the\nnetwork realization. The analysis features a flexible channel model, accounting\nfor path loss, Nakagami fading, and shadowing. By generating many random\nnetworks and applying a given resource allocation policy, the distribution of\nthe rates provided to each user is obtained. In addition to determining the\naverage rate, the analysis can determine the transmission capacity of the\nnetwork and can characterize fairness in terms of the fraction of users that\nachieve a specified rate. The analysis is used to compare a rate-control policy\nagainst a power-control policy and investigate the influence of the minimum\nbase-station separation. \n\n"}
{"id": "1210.5424", "contents": "Title: Implementation of Distributed Time Exchange Based Cooperative Forwarding Abstract: In this paper, we design and implement time exchange (TE) based cooperative\nforwarding where nodes use transmission time slots as incentives for relaying.\nWe focus on distributed joint time slot exchange and relay selection in the sum\ngoodput maximization of the overall network. We formulate the design objective\nas a mixed integer nonlinear programming (MINLP) problem and provide a\npolynomial time distributed solution of the MINLP. We implement the designed\nalgorithm in the software defined radio enabled USRP nodes of the ORBIT indoor\nwireless testbed. The ORBIT grid is used as a global control plane for exchange\nof control information between the USRP nodes. Experimental results suggest\nthat TE can significantly increase the sum goodput of the network. We also\ndemonstrate the performance of a goodput optimization algorithm that is\nproportionally fair. \n\n"}
{"id": "1210.5470", "contents": "Title: The DoF of Network MIMO with Backhaul Delays Abstract: We consider the problem of downlink precoding for Network (multi-cell) MIMO\nnetworks where Transmitters (TXs) are provided with imperfect Channel State\nInformation (CSI). Specifically, each TX receives a delayed channel estimate\nwith the delay being specific to each channel component. This model is\nparticularly adapted to the scenarios where a user feeds back its CSI to its\nserving base only as it is envisioned in future LTE networks. We analyze the\nimpact of the delay during the backhaul-based CSI exchange on the rate\nperformance achieved by Network MIMO. We highlight how delay can dramatically\ndegrade system performance if existing precoding methods are to be used. We\npropose an alternative robust beamforming strategy which achieves the maximal\nperformance, in DoF sense. We verify by simulations that the theoretical DoF\nimprovement translates into a performance increase at finite Signal-to-Noise\nRatio (SNR) as well. \n\n"}
{"id": "1210.5503", "contents": "Title: Downlink Coordinated Multi-Point with Overhead Modeling in Heterogeneous\n  Cellular Networks Abstract: Coordinated multi-point (CoMP) communication is attractive for heterogeneous\ncellular networks (HCNs) for interference reduction. However, previous\napproaches to CoMP face two major hurdles in HCNs. First, they usually ignore\nthe inter-cell overhead messaging delay, although it results in an irreducible\nperformance bound. Second, they consider the grid or Wyner model for base\nstation locations, which is not appropriate for HCN BS locations which are\nnumerous and haphazard. Even for conventional macrocell networks without\noverlaid small cells, SINR results are not tractable in the grid model nor\naccurate in the Wyner model. To overcome these hurdles, we develop a novel\nanalytical framework which includes the impact of overhead delay for CoMP\nevaluation in HCNs. This framework can be used for a class of CoMP schemes\nwithout user data sharing. As an example, we apply it to downlink CoMP\nzero-forcing beamforming (ZFBF), and see significant divergence from previous\nwork. For example, we show that CoMP ZFBF does not increase throughput when the\noverhead channel delay is larger than 60% of the channel coherence time. We\nalso find that, in most cases, coordinating with only one other cell is nearly\noptimum for downlink CoMP ZFBF. \n\n"}
{"id": "1210.5991", "contents": "Title: Online Recovery Guarantees and Analytical Results for OMP Abstract: Orthogonal Matching Pursuit (OMP) is a simple, yet empirically competitive\nalgorithm for sparse recovery. Recent developments have shown that OMP\nguarantees exact recovery of K-sparse signals with K or more than K iterations\nif the observation matrix satisfies the restricted isometry property (RIP) with\nsome conditions. We develop RIP-based online guarantees for recovery of a\nK-sparse signal with more than K OMP iterations. Though these guarantees cannot\nbe generalized to all sparse signals a priori, we show that they can still hold\nonline when the state-of-the-art K-step recovery guarantees fail. In addition,\nwe present bounds on the number of correct and false indices in the support\nestimate for the derived condition to be less restrictive than the K-step\nguarantees. Under these bounds, this condition guarantees exact recovery of a\nK-sparse signal within 3K/2 iterations, which is much less than the number of\nsteps required for the state-of-the-art exact recovery guarantees with more\nthan K steps. Moreover, we present phase transitions of OMP in comparison to\nbasis pursuit and subspace pursuit, which are obtained after extensive recovery\nsimulations involving different sparse signal types. Finally, we empirically\nanalyse the number of false indices in the support estimate, which indicates\nthat these do not violate the developed upper bound in practice. \n\n"}
{"id": "1210.6673", "contents": "Title: Semantically Secure Lattice Codes for the Gaussian Wiretap Channel Abstract: We propose a new scheme of wiretap lattice coding that achieves semantic\nsecurity and strong secrecy over the Gaussian wiretap channel. The key tool in\nour security proof is the flatness factor which characterizes the convergence\nof the conditional output distributions corresponding to different messages and\nleads to an upper bound on the information leakage. We not only introduce the\nnotion of secrecy-good lattices, but also propose the {flatness factor} as a\ndesign criterion of such lattices. Both the modulo-lattice Gaussian channel and\nthe genuine Gaussian channel are considered. In the latter case, we propose a\nnovel secrecy coding scheme based on the discrete Gaussian distribution over a\nlattice, which achieves the secrecy capacity to within a half nat under mild\nconditions. No \\textit{a priori} distribution of the message is assumed, and no\ndither is used in our proposed schemes. \n\n"}
{"id": "1210.8253", "contents": "Title: Ranks of propelinear perfect binary codes Abstract: It is proven that for any numbers n=2^m-1, m >= 4 and r, such that n -\nlog(n+1)<= r <= n excluding n = r = 63, n = 127, r in {126,127} and n = r =\n2047 there exists a propelinear perfect binary code of length n and rank r. \n\n"}
{"id": "1211.0985", "contents": "Title: Interactive Interference Alignment Abstract: We study interference channels (IFC) where interaction among sources and\ndestinations is enabled, e.g., both sources and destinations can talk to each\nother using full-duplex radios. The interaction can come in two ways: 1) {\\em\nIn-band interaction:} sources and destinations can transmit and listen in the\nsame channel simultaneously, enabling interaction. 2) {\\em out-of-band\ninteraction:} destinations talk back to the sources on an out-of-band channel,\npossible from white-space channels. The flexibility afforded by interaction\namong sources and destinations allows for the derivation of interference\nalignment (IA) strategies that have desirable \"engineering properties\":\ninsensitivity to the rationality or irrationality of channel parameters, small\nblock lengths and finite SNR operations. We show that for several classes of\ninterference channels the interactive interference alignment scheme can achieve\nthe optimal degrees of freedom. In particular, we show the {\\em first simple\nscheme} (having finite block length, for channels having no diversity) for\n$K=3,4$ that can achieve the optimal degrees of freedom of $\\frac{K}{2}$ even\nafter accounting for the cost of interaction. We also give simulation results\non the finite SNR performance of interactive alignment under some settings.\n  On the technical side, we show using a Gr\\\"{o}bner basis argument that in a\ngeneral network potentially utilizing cooperation and feedback, the optimal\ndegrees of freedom under linear schemes of a fixed block length is the same for\nchannel coefficients with probability 1. Furthermore, a numerical method to\nestimate this value is also presented. These tools have potentially wider\nutility in studying other wireless networks as well. \n\n"}
{"id": "1211.3322", "contents": "Title: The Degrees of Freedom Region of Temporally-Correlated MIMO Networks\n  with Delayed CSIT Abstract: We consider the temporally-correlated Multiple-Input Multiple-Output (MIMO)\nbroadcast channels (BC) and interference channels (IC) where the transmitter(s)\nhas/have (i) delayed channel state information (CSI) obtained from a\nlatency-prone feedback channel as well as (ii) imperfect current CSIT,\nobtained, e.g., from prediction on the basis of these past channel samples\nbased on the temporal correlation. The degrees of freedom (DoF) regions for the\ntwo-user broadcast and interference MIMO networks with general antenna\nconfiguration under such conditions are fully characterized, as a function of\nthe prediction quality indicator. Specifically, a simple unified framework is\nproposed, allowing to attain optimal DoF region for the general antenna\nconfigurations and current CSIT qualities. Such a framework builds upon\nblock-Markov encoding with interference quantization, optimally combining the\nuse of both outdated and instantaneous CSIT. A striking feature of our work is\nthat, by varying the power allocation, every point in the DoF region can be\nachieved with one single scheme. As a result, instead of checking the\nachievability of every corner point of the outer bound region, as typically\ndone in the literature, we propose a new systematic way to prove the\nachievability. \n\n"}
{"id": "1211.4198", "contents": "Title: Degrees of Freedom of the 3-User Rank-Deficient MIMO Interference\n  Channel Abstract: We provide the degrees of freedom (DoF) characterization for the $3$-user\n$M_T\\times M_R$ multiple-input multiple-output (MIMO) interference channel (IC)\nwith \\emph{rank-deficient} channel matrices, where each transmitter is equipped\nwith $M_T$ antennas and each receiver with $M_R$ antennas, and the interfering\nchannel matrices from each transmitter to the other two receivers are of ranks\n$D_1$ and $D_2$, respectively. One important intermediate step for both the\nconverse and achievability arguments is to convert the fully-connected\nrank-deficient channel into an equivalent partially-connected full-rank MIMO-IC\nby invertible linear transformations. As such, existing techniques developed\nfor full-rank MIMO-IC can be incorporated to derive the DoF outer and inner\nbounds for the rank-deficient case. Our result shows that when the interfering\nlinks are weak in terms of the channel ranks, i.e., $D_1+D_2\\leq \\min(M_T,\nM_R)$, zero forcing is sufficient to achieve the optimal DoF. On the other\nhand, when $D_1+D_2> \\min(M_T, M_R)$, a combination of zero forcing and\ninterference alignment is in general required for DoF optimality. The DoF\ncharacterization obtained in this paper unifies several existing results in the\nliterature. \n\n"}
{"id": "1211.4392", "contents": "Title: Cost Efficient High Capacity Indoor Wireless Access: Denser Wi-Fi or\n  Coordinated Pico-cellular? Abstract: Rapidly increasing traffic demand has forced indoor operators to deploy more\nand more Wi-Fi access points (APs). As AP density increases, inter-AP\ninterference rises and may limit the capacity. Alternatively, cellular\ntechnologies using centralized interference coordination can provide the same\ncapacity with the fewer number of APs at the price of more expensive equipment\nand installation cost. It is still not obvious at what demand level more\nsophisticated coordination pays off in terms of total system cost. To make this\ncomparison, we assess the required AP density of three candidate systems for a\ngiven average demand: a Wi-Fi network, a conventional pico-cellular network\nwith frequency planning, and an advanced system employing multi-cell joint\nprocessing. Numerical results show that dense Wi-Fi is the cheapest solution at\na relatively low demand level. However, the AP density grows quickly at a\ncritical demand level regardless of propagation conditions. Beyond this Wi-Fi\nnetwork limit, the conventional pico-cellular network works and is cheaper than\nthe joint processing in obstructed environments, e.g., furnished offices with\nwalls. In line of sight condition such as stadiums, the joint processing\nbecomes the most viable solution. The drawback is that extremely accurate\nchannel state information at transmitters is needed. \n\n"}
{"id": "1211.5884", "contents": "Title: Low complexity sum rate maximization for single and multiple stream MIMO\n  AF relay networks Abstract: A multiple-antenna amplify-and-forward two-hop interference network with\nmultiple links and multiple relays is considered. We optimize transmit\nprecoders, receive decoders and relay AF matrices to maximize the achievable\nsum rate. Under per user and total relay sum power constraints, we propose an\nefficient algorithm to maximize the total signal to total interference plus\nnoise ratio (TSTINR). Computational complexity analysis shows that our proposed\nalgorithm for TSTINR has lower complexity than the existing weighted minimum\nmean square error (WMMSE) algorithm. We analyze and confirm by simulations that\nthe TSTINR, WMMSE and the total leakage interference plus noise (TLIN)\nminimization models with per user and total relay sum power constraints can\nonly transmit a single data stream for each user. Thus we propose a novel\nmultiple stream TSTINR model with requirement of orthogonal columns for\nprecoders, in order to support multiple data streams and thus utilize higher\nDegrees of Freedom. Multiple data streams and larger multiplexing gains are\nguaranteed. Simulation results show that for single stream models, our TSTINR\nalgorithm outperforms the TLIN algorithm generally and outperforms WMMSE in\nmedium to high Signal-to-Noise-Ratio scenarios; the system sum rate\nsignificantly benefits from multiple data streams in medium to high SNR\nscenarios. \n\n"}
{"id": "1211.5914", "contents": "Title: A survey of uncertainty principles and some signal processing\n  applications Abstract: The goal of this paper is to review the main trends in the domain of\nuncertainty principles and localization, emphasize their mutual connections and\ninvestigate practical consequences. The discussion is strongly oriented\ntowards, and motivated by signal processing problems, from which significant\nadvances have been made recently. Relations with sparse approximation and\ncoding problems are emphasized. \n\n"}
{"id": "1212.0877", "contents": "Title: Toeplitz Matrix Based Sparse Error Correction in System Identification:\n  Outliers and Random Noises Abstract: In this paper, we consider robust system identification under sparse outliers\nand random noises. In our problem, system parameters are observed through a\nToeplitz matrix. All observations are subject to random noises and a few are\ncorrupted with outliers. We reduce this problem of system identification to a\nsparse error correcting problem using a Toeplitz structured real-numbered\ncoding matrix. We prove the performance guarantee of Toeplitz structured matrix\nin sparse error correction. Thresholds on the percentage of correctable errors\nfor Toeplitz structured matrices are also established. When both outliers and\nobservation noise are present, we have shown that the estimation error goes to\n0 asymptotically as long as the probability density function for observation\nnoise is not \"vanishing\" around 0. \n\n"}
{"id": "1212.1283", "contents": "Title: A Tractable Framework for Exact Probability of Node Isolation and\n  Minimum Node Degree Distribution in Finite Multi-hop Networks Abstract: This paper presents a tractable analytical framework for the exact\ncalculation of probability of node isolation and minimum node degree\ndistribution when $N$ sensor nodes are independently and uniformly distributed\ninside a finite square region. The proposed framework can accurately account\nfor the boundary effects by partitioning the square into subregions, based on\nthe transmission range and the node location. We show that for each subregion,\nthe probability that a random node falls inside a disk centered at an arbitrary\nnode located in that subregion can be expressed analytically in closed-form.\nUsing the results for the different subregions, we obtain the exact probability\nof node isolation and minimum node degree distribution that serves as an upper\nbound for the probability of $k$-connectivity. Our theoretical framework is\nvalidated by comparison with the simulation results and shows that the minimum\nnode degree distribution serves as a tight upper bound for the probability of\n$k$-connectivity. The proposed framework provides a very useful tool to\naccurately account for the boundary effects in the design of finite wireless\nnetworks. \n\n"}
{"id": "1212.2537", "contents": "Title: Polar codes for private and quantum communication over arbitrary\n  channels Abstract: We construct new polar coding schemes for the transmission of quantum or\nprivate classical information over arbitrary quantum channels. In the former\ncase, our coding scheme achieves the symmetric coherent information and in the\nlatter the symmetric private information. Both schemes are built from a polar\ncoding construction capable of transmitting classical information over a\nquantum channel [Wilde and Guha, IEEE Transactions on Information Theory, in\npress]. Appropriately merging two such classical-quantum schemes, one for\ntransmitting \"amplitude\" information and the other for transmitting \"phase,\"\nleads to the new private and quantum coding schemes, similar to the\nconstruction for Pauli and erasure channels in [Renes, Dupuis, and Renner,\nPhysical Review Letters 109, 050504 (2012)]. The encoding is entirely similar\nto the classical case, and thus efficient. The decoding can also be performed\nby successive cancellation, as in the classical case, but no efficient\nsuccessive cancellation scheme is yet known for arbitrary quantum channels. An\nefficient code construction is unfortunately still unknown. Generally, our two\ncoding schemes require entanglement or secret-key assistance, respectively, but\nwe extend two known conditions under which the needed assistance rate vanishes.\nFinally, although our results are formulated for qubit channels, we show how\nthe scheme can be extended to multiple qubits. This then demonstrates a\nnear-explicit coding method for realizing one of the most striking phenomena in\nquantum information theory: the superactivation effect, whereby two quantum\nchannels which individually have zero quantum capacity can have a non-zero\nquantum capacity when used together. \n\n"}
{"id": "1212.6009", "contents": "Title: Distributed Sparse Signal Recovery For Sensor Networks Abstract: We propose a distributed algorithm for sparse signal recovery in sensor\nnetworks based on Iterative Hard Thresholding (IHT). Every agent has a set of\nmeasurements of a signal x, and the objective is for the agents to recover x\nfrom their collective measurements at a minimal communication cost and with low\ncomputational complexity. A naive distributed implementation of IHT would\nrequire global communication of every agent's full state in each iteration. We\nfind that we can dramatically reduce this communication cost by leveraging\nsolutions to the distributed top-K problem in the database literature.\nEvaluations show that our algorithm requires up to three orders of magnitude\nless total bandwidth than the best-known distributed basis pursuit method. \n\n"}
{"id": "1301.1760", "contents": "Title: Carrier phase and amplitude estimation for phase shift keying using\n  pilots and data Abstract: We consider least squares estimators of carrier phase and amplitude from a\nnoisy communications signal that contains both pilot signals, known to the\nreceiver, and data signals, unknown to the receiver. We focus on signaling\nconstellations that have symbols evenly distributed on the complex unit circle,\ni.e., M-ary phase shift keying. We show, under reasonably mild conditions on\nthe distribution of the noise, that the least squares estimator of carrier\nphase is strongly consistent and asymptotically normally distributed. However,\nthe amplitude estimator is not consistent, but converges to a positive real\nnumber that is a function of the true carrier amplitude, the noise distribution\nand the size of the constellation. Our theoretical results can also be applied\nto the case where no pilot symbols exist, i.e., noncoherent detection. The\nresults of Monte Carlo simulations are provided and these agree with the\ntheoretical results. \n\n"}
{"id": "1301.3106", "contents": "Title: Topological Interference Management through Index Coding Abstract: This work studies linear interference networks, both wired and wireless, with\nno channel state information at the transmitters (CSIT) except a coarse\nknowledge of the end-to-end one-hop topology of the network that only allows a\ndistinction between weak (zero) and significant (non-zero) channels and no\nfurther knowledge of the channel coefficients' realizations. The network\ncapacity (wired) and DoF (wireless) are found to be bounded above by the\ncapacity of an index coding problem for which the antidote graph is the\ncomplement of the given interference graph. The problems are shown to be\nequivalent under linear solutions. An interference alignment perspective is\nthen used to translate the existing index coding solutions into the wired\nnetwork capacity and wireless network DoF solutions, as well as to find new and\nunified solutions to different classes of all three problems. \n\n"}
{"id": "1301.3991", "contents": "Title: Generic Regular Decompositions for Parametric Polynomial Systems Abstract: This paper presents a generalization of our earlier work in [19]. In this\npaper, the two concepts, generic regular decomposition (GRD) and\nregular-decomposition-unstable (RDU) variety introduced in [19] for generic\nzero-dimensional systems, are extended to the case where the parametric systems\nare not necessarily zero-dimensional. An algorithm is provided to compute GRDs\nand the associated RDU varieties of parametric systems simultaneously on the\nbasis of the algorithm for generic zero-dimensional systems proposed in [19].\nThen the solutions of any parametric system can be represented by the solutions\nof finitely many regular systems and the decomposition is stable at any\nparameter value in the complement of the associated RDU variety of the\nparameter space. The related definitions and the results presented in [19] are\nalso generalized and a further discussion on RDU varieties is given from an\nexperimental point of view. The new algorithm has been implemented on the basis\nof DISCOVERER with Maple 16 and experimented with a number of benchmarks from\nthe literature. \n\n"}
{"id": "1301.5034", "contents": "Title: Downlink MIMO HetNets: Modeling, Ordering Results and Performance\n  Analysis Abstract: We develop a general downlink model for multi-antenna heterogeneous cellular\nnetworks (HetNets), where base stations (BSs) across tiers may differ in terms\nof transmit power, target signal-to-interference-ratio (SIR), deployment\ndensity, number of transmit antennas and the type of multi-antenna\ntransmission. In particular, we consider and compare space division multiple\naccess (SDMA), single user beamforming (SU-BF), and baseline single-input\nsingle-output (SISO) transmission. For this general model, the main\ncontributions are: (i) ordering results for both coverage probability and per\nuser rate in closed form for any BS distribution for the three considered\ntechniques, using novel tools from stochastic orders, (ii) upper bounds on the\ncoverage probability assuming a Poisson BS distribution, and (iii) a comparison\nof the area spectral efficiency (ASE). The analysis concretely demonstrates,\nfor example, that for a given total number of transmit antennas in the network,\nit is preferable to spread them across many single-antenna BSs vs. fewer\nmulti-antenna BSs. Another observation is that SU-BF provides higher coverage\nand per user data rate than SDMA, but SDMA is in some cases better in terms of\nASE. \n\n"}
{"id": "1301.5044", "contents": "Title: Performance Analysis of Heterogeneous Feedback Design in an OFDMA\n  Downlink with Partial and Imperfect Feedback Abstract: Current OFDMA systems group resource blocks into subband to form the basic\nfeedback unit. Homogeneous feedback design with a common subband size is not\naware of the heterogeneous channel statistics among users. Under a general\ncorrelated channel model, we demonstrate the gain of matching the subband size\nto the underlying channel statistics motivating heterogeneous feedback design\nwith different subband sizes and feedback resources across clusters of users.\nEmploying the best-M partial feedback strategy, users with smaller subband size\nwould convey more partial feedback to match the frequency selectivity. In order\nto develop an analytical framework to investigate the impact of partial\nfeedback and potential imperfections, we leverage the multi-cluster subband\nfading model. The perfect feedback scenario is thoroughly analyzed, and the\nclosed form expression for the average sum rate is derived for the\nheterogeneous partial feedback system. We proceed to examine the effect of\nimperfections due to channel estimation error and feedback delay, which leads\nto additional consideration of system outage. Two transmission strategies: the\nfix rate and the variable rate, are considered for the outage analysis. We also\ninvestigate how to adapt to the imperfections in order to maximize the average\ngoodput under heterogeneous partial feedback. \n\n"}
{"id": "1301.5848", "contents": "Title: Decentralized Coded Caching Attains Order-Optimal Memory-Rate Tradeoff Abstract: Replicating or caching popular content in memories distributed across the\nnetwork is a technique to reduce peak network loads. Conventionally, the main\nperformance gain of this caching was thought to result from making part of the\nrequested data available closer to end users. Instead, we recently showed that\na much more significant gain can be achieved by using caches to create\ncoded-multicasting opportunities, even for users with different demands,\nthrough coding across data streams. These coded-multicasting opportunities are\nenabled by careful content overlap at the various caches in the network,\ncreated by a central coordinating server.\n  In many scenarios, such a central coordinating server may not be available,\nraising the question if this multicasting gain can still be achieved in a more\ndecentralized setting. In this paper, we propose an efficient caching scheme,\nin which the content placement is performed in a decentralized manner. In other\nwords, no coordination is required for the content placement. Despite this lack\nof coordination, the proposed scheme is nevertheless able to create\ncoded-multicasting opportunities and achieves a rate close to the optimal\ncentralized scheme. \n\n"}
{"id": "1301.5973", "contents": "Title: Non-Adaptive Distributed Compression in Networks Abstract: In this paper, we discuss non-adaptive distributed compression of inter-node\ncorrelated real-valued messages. To do so, we discuss the performance of\nconventional packet forwarding via routing, in terms of the total network load\nversus the resulting quality of service (distortion level). As a better\nalternative for packet forwarding, we briefly describe our previously proposed\none-step Quantized Network Coding (QNC), and make motivating arguments on its\nadvantage when the appropriate marginal rates for distributed source coding are\nnot available at the encoder source nodes. We also derive analytic guarantees\non the resulting distortion of our one-step QNC scenario. Finally, we conclude\nthe paper by providing a mathematical comparison between the total network\nloads of one-step QNC and conventional packet forwarding, showing a significant\nreduction in the case of one-step QNC. \n\n"}
{"id": "1301.6199", "contents": "Title: Sample Complexity of Bayesian Optimal Dictionary Learning Abstract: We consider a learning problem of identifying a dictionary matrix D (M times\nN dimension) from a sample set of M dimensional vectors Y = N^{-1/2} DX, where\nX is a sparse matrix (N times P dimension) in which the density of non-zero\nentries is 0<rho< 1. In particular, we focus on the minimum sample size P_c\n(sample complexity) necessary for perfectly identifying D of the optimal\nlearning scheme when D and X are independently generated from certain\ndistributions. By using the replica method of statistical mechanics, we show\nthat P_c=O(N) holds as long as alpha = M/N >rho is satisfied in the limit of N\nto infinity. Our analysis also implies that the posterior distribution given Y\nis condensed only at the correct dictionary D when the compression rate alpha\nis greater than a certain critical value alpha_M(rho). This suggests that\nbelief propagation may allow us to learn D with a low computational complexity\nusing O(N) samples. \n\n"}
{"id": "1301.6209", "contents": "Title: On the achievable region for interference networks with point-to-point\n  codes Abstract: This paper studies evaluation of the capacity region for interference\nnetworks with point-to-point (p2p) capacity-achieving codes. Such capacity\nregion has recently been characterized as union of several sub-regions each of\nwhich has distinctive operational characteristics. Detailed evaluation of this\nregion, therefore, can be accomplished in a very simple manner by acknowledging\nsuch characteristics, which, in turn, provides an insight for a simple\nimplementation scenario. Completely generalized message assignment which is\nalso practically relevant is considered in this paper, and it is shown to\nprovide strictly larger achievable rates than what traditional message\nassignment does when a receiver with joint decoding capability is used. \n\n"}
{"id": "1301.6295", "contents": "Title: Fixed Points of Generalized Approximate Message Passing with Arbitrary\n  Matrices Abstract: The estimation of a random vector with independent components passed through\na linear transform followed by a componentwise (possibly nonlinear) output map\narises in a range of applications. Approximate message passing (AMP) methods,\nbased on Gaussian approximations of loopy belief propagation, have recently\nattracted considerable attention for such problems. For large random\ntransforms, these methods exhibit fast convergence and admit precise analytic\ncharacterizations with testable conditions for optimality, even for certain\nnon-convex problem instances. However, the behavior of AMP under general\ntransforms is not fully understood. In this paper, we consider the generalized\nAMP (GAMP) algorithm and relate the method to more common optimization\ntechniques. This analysis enables a precise characterization of the GAMP\nalgorithm fixed-points that applies to arbitrary transforms. In particular, we\nshow that the fixed points of the so-called max-sum GAMP algorithm for MAP\nestimation are critical points of a constrained maximization of the posterior\ndensity. The fixed-points of the sum-product GAMP algorithm for estimation of\nthe posterior marginals can be interpreted as critical points of a certain free\nenergy. \n\n"}
{"id": "1301.6397", "contents": "Title: Scalar Quantize-and-Forward for Symmetric Half-duplex Two-Way Relay\n  Channels Abstract: Scalar Quantize & Forward (QF) schemes are studied for the Two-Way Relay\nChannel. Different QF approaches are compared in terms of rates as well as\nrelay and decoder complexity. A coding scheme not requiring Slepian-Wolf coding\nat the relay is proposed and properties of the corresponding sum-rate\noptimization problem are presented. A numerical scheme similar to the\nBlahut-Arimoto algorithm is derived that guides optimized quantizer design. The\nresults are supported by simulations. \n\n"}
{"id": "1301.6599", "contents": "Title: An Upper Bound on the Capacity of non-Binary Deletion Channels Abstract: We derive an upper bound on the capacity of non-binary deletion channels.\nAlthough binary deletion channels have received significant attention over the\nyears, and many upper and lower bounds on their capacity have been derived,\nsuch studies for the non-binary case are largely missing. The state of the art\nis the following: as a trivial upper bound, capacity of an erasure channel with\nthe same input alphabet as the deletion channel can be used, and as a lower\nbound the results by Diggavi and Grossglauser are available. In this paper, we\nderive the first non-trivial non-binary deletion channel capacity upper bound\nand reduce the gap with the existing achievable rates. To derive the results we\nfirst prove an inequality between the capacity of a 2K-ary deletion channel\nwith deletion probability $d$, denoted by $C_{2K}(d)$, and the capacity of the\nbinary deletion channel with the same deletion probability, $C_2(d)$, that is,\n$C_{2K}(d)\\leq C_2(d)+(1-d)\\log(K)$. Then by employing some existing upper\nbounds on the capacity of the binary deletion channel, we obtain upper bounds\non the capacity of the 2K-ary deletion channel. We illustrate via examples the\nuse of the new bounds and discuss their asymptotic behavior as $d \\rightarrow\n0$. \n\n"}
{"id": "1302.2168", "contents": "Title: Optimal Throughput-Outage Trade-off in Wireless One-Hop Caching Networks Abstract: We consider a wireless device-to-device (D2D) network where the nodes have\ncached information from a library of possible files. Inspired by the current\ntrend in the standardization of the D2D mode for 4th generation wireless\nnetworks, we restrict to one-hop communication: each node place a request to a\nfile in the library, and downloads from some other node which has the requested\nfile in its cache through a direct communication link, without going through a\nbase station. We describe the physical layer communication through a simple\n\"protocol-model\", based on interference avoidance (independent set scheduling).\nFor this network we define the outage-throughput tradeoff problem and\ncharacterize the optimal scaling laws for various regimes where both the number\nof nodes and the files in the library grow to infinity. \n\n"}
{"id": "1302.2185", "contents": "Title: Passive Self-Interference Suppression for Full-Duplex Infrastructure\n  Nodes Abstract: Recent research results have demonstrated the feasibility of full-duplex\nwireless communication for short-range links. Although the focus of the\nprevious works has been active cancellation of the self-interference signal, a\nmajority of the overall self-interference suppression is often due to passive\nsuppression, i.e., isolation of the transmit and receive antennas. We present a\nmeasurement-based study of the capabilities and limitations of three key\nmechanisms for passive self-interference suppression: directional isolation,\nabsorptive shielding, and cross-polarization. The study demonstrates that more\nthan 70 dB of passive suppression can be achieved in certain environments, but\nalso establishes two results on the limitations of passive suppression: (1)\nenvironmental reflections limit the amount of passive suppression that can be\nachieved, and (2) passive suppression, in general, increases the frequency\nselectivity of the residual self-interference signal. These results suggest two\ndesign implications: (1) deployments of full-duplex infrastructure nodes should\nminimize near-antenna reflectors, and (2) active cancellation in concatenation\nwith passive suppression should employ higher-order filters or per-subcarrier\ncancellation. \n\n"}
{"id": "1302.5449", "contents": "Title: Nonparametric Basis Pursuit via Sparse Kernel-based Learning Abstract: Signal processing tasks as fundamental as sampling, reconstruction, minimum\nmean-square error interpolation and prediction can be viewed under the prism of\nreproducing kernel Hilbert spaces. Endowing this vantage point with\ncontemporary advances in sparsity-aware modeling and processing, promotes the\nnonparametric basis pursuit advocated in this paper as the overarching\nframework for the confluence of kernel-based learning (KBL) approaches\nleveraging sparse linear regression, nuclear-norm regularization, and\ndictionary learning. The novel sparse KBL toolbox goes beyond translating\nsparse parametric approaches to their nonparametric counterparts, to\nincorporate new possibilities such as multi-kernel selection and matrix\nsmoothing. The impact of sparse KBL to signal processing applications is\nillustrated through test cases from cognitive radio sensing, microarray data\nimputation, and network traffic prediction. \n\n"}
{"id": "1302.5945", "contents": "Title: Queue-Based Random-Access Algorithms: Fluid Limits and Stability Issues Abstract: We use fluid limits to explore the (in)stability properties of wireless\nnetworks with queue-based random-access algorithms. Queue-based random-access\nschemes are simple and inherently distributed in nature, yet provide the\ncapability to match the optimal throughput performance of centralized\nscheduling mechanisms in a wide range of scenarios. Unfortunately, the type of\nactivation rules for which throughput optimality has been established, may\nresult in excessive queue lengths and delays. The use of more\naggressive/persistent access schemes can improve the delay performance, but\ndoes not offer any universal maximum-stability guarantees. In order to gain\nqualitative insight and investigate the (in)stability properties of more\naggressive/persistent activation rules, we examine fluid limits where the\ndynamics are scaled in space and time. In some situations, the fluid limits\nhave smooth deterministic features and maximum stability is maintained, while\nin other scenarios they exhibit random oscillatory characteristics, giving rise\nto major technical challenges. In the latter regime, more aggressive access\nschemes continue to provide maximum stability in some networks, but may cause\ninstability in others. Simulation experiments are conducted to illustrate and\nvalidate the analytical results. \n\n"}
{"id": "1303.2087", "contents": "Title: Capacity Bounds and Sum Rate Capacities of a CLass of Discrete\n  Memoryless Interference Channels Abstract: This paper studies the capacity of a class of discrete memoryless\ninterference channels where interference is defined analogous to that of\nGaussian interference channel with one-sided weak interference. The sum-rate\ncapacity of this class of channels is determined. As with the Gaussian case,\nthe sum-rate capacity is achieved by letting the transceiver pair subject to\ninterference communicate at a rate such that its message can be decoded at the\nunintended receiver using single user detection. It is also established that\nthis class of discrete memoryless interference channels is equivalent in\ncapacity region to certain degraded interference channels. This allows the\nconstruction of capacity outer-bounds using the capacity regions of associated\ndegraded broadcast channels. The same technique is then used to determine the\nsum-rate capacity of discrete memoryless interference channels with mixed\ninterference as defined in the paper. The obtained capacity bounds and sum-rate\ncapacities are used to resolve the capacities of several new discrete\nmemoryless interference channels. \n\n"}
{"id": "1303.2636", "contents": "Title: Energy Cooperation in Energy Harvesting Communications Abstract: In energy harvesting communications, users transmit messages using energy\nharvested from nature during the course of communication. With an optimum\ntransmit policy, the performance of the system depends only on the energy\narrival profiles. In this paper, we introduce the concept of energy\ncooperation, where a user wirelessly transmits a portion of its energy to\nanother energy harvesting user. This enables shaping and optimization of the\nenergy arrivals at the energy-receiving node, and improves the overall system\nperformance, despite the loss incurred in energy transfer. We consider several\nbasic multi-user network structures with energy harvesting and wireless energy\ntransfer capabilities: relay channel, two-way channel and multiple access\nchannel. We determine energy management policies that maximize the system\nthroughput within a given duration using a Lagrangian formulation and the\nresulting KKT optimality conditions. We develop a two-dimensional directional\nwater-filling algorithm which optimally controls the flow of harvested energy\nin two dimensions: in time (from past to future) and among users (from\nenergy-transferring to energy-receiving) and show that a generalized version of\nthis algorithm achieves the boundary of the capacity region of the two-way\nchannel. \n\n"}
{"id": "1303.3165", "contents": "Title: Joint Optimization of Throughput and Packet Drop Rate for Delay\n  Sensitive Applications in TDD Satellite Network Coded Systems Abstract: In this paper, we consider the issue of throughput and packet drop rate (PDR)\noptimization as two performance metrics for delay sensitive applications in\nnetwork coded time division duplex (TDD) satellite systems with large round\ntrip times (RTT). We adopt random linear network coding (RLNC) under two\ndifferent scenarios, feedback-less and with feedback, and our goal is to\njointly optimize the mean throughputs and PDRs of users in the system. For this\npurpose, we propose a systematic framework and start with formulating and\noptimizing these performance metrics for the single-user case. This framework\nenables us to analytically compare the performance metrics under different\nsystem parameters and settings. By comparing RLNC schemes under feedback-less\nand feedback scenarios for different RTTs, we show that the feedback-less\nschemes outperform the schemes with feedback in TDD systems with large RTTs.\nThen, we extend the study of feedback-less RLNC schemes to the multi-user\nbroadcast case. Here, we consider a number of different broadcast scenarios and\noptimize the system parameters such that the best overall performance is\nachieved. Furthermore, the complicated interplay of the mean throughputs and\nPDRs of different users with different packet erasure conditions in each of the\nconsidered broadcast scenarios is discussed. \n\n"}
{"id": "1303.3247", "contents": "Title: Performance of a random-access wireless network with a mix of full- and\n  half-duplex stations Abstract: In this paper, we consider the performance of a random-access time-slotted\nwireless network with a single access point and a mix of half- and full- duplex\nstations. Full-duplex transmissions involve data transmitted simultaneously in\nboth directions, and this influences the dynamics of the queue at the access\npoint. Given the probabilities of channel access by the nodes, this paper\nprovides generalized analytical formulations for the throughputs for each\nstation. Special cases related to a 802.11 DCA based system as well as a\nfull-fairness system are discussed, which provide insights into the changes\nintroduced by the new technology of full-duplex wireless. \n\n"}
{"id": "1303.3625", "contents": "Title: Quantum logic under semi-classical limit: information loss Abstract: We consider quantum computation efficiency from a new perspective. The\nefficiency is reduced to its classical counterpart by imposing the\nsemi-classical limit. We show that this reduction is caused by the fact that\nany elementary quantum logic operation (gate) suffers information loss during\ntransition to its classical analogue. Amount of the information lost is\nestimated for any gate from the complete set. The largest loss is obtained for\nnon-commuting gates that allows to consider them as quantum computational\nspeed-up resource. Our method allows to quantify advantages of quantum\ncomputation as compared to the classical one by direct analysis of the basic\nlogic involved. The obtained results are illustrated by application to quantum\ndiscrete Fourier transform and Grover search algorithms. \n\n"}
{"id": "1303.5097", "contents": "Title: On the optimality of a L1/L1 solver for sparse signal recovery from\n  sparsely corrupted compressive measurements Abstract: This short note proves the $\\ell_2-\\ell_1$ instance optimality of a\n$\\ell_1/\\ell_1$ solver, i.e a variant of \\emph{basis pursuit denoising} with a\n$\\ell_1$ fidelity constraint, when applied to the estimation of sparse (or\ncompressible) signals observed by sparsely corrupted compressive measurements.\nThe approach simply combines two known results due to Y. Plan, R. Vershynin and\nE. Cand\\`es. \n\n"}
{"id": "1303.6387", "contents": "Title: Message Passing Algorithm for Distributed Downlink Regularized\n  Zero-forcing Beamforming with Cooperative Base Stations Abstract: Base station (BS) cooperation can turn unwanted interference to useful signal\nenergy for enhancing system performance. In the cooperative downlink,\nzero-forcing beamforming (ZFBF) with a simple scheduler is well known to obtain\nnearly the performance of the capacity-achieving dirty-paper coding. However,\nthe centralized ZFBF approach is prohibitively complex as the network size\ngrows. In this paper, we devise message passing algorithms for realizing the\nregularized ZFBF (RZFBF) in a distributed manner using belief propagation. In\nthe proposed methods, the overall computational cost is decomposed into many\nsmaller computation tasks carried out by groups of neighboring BSs and\ncommunications is only required between neighboring BSs. More importantly, some\nexchanged messages can be computed based on channel statistics rather than\ninstantaneous channel state information, leading to significant reduction in\ncomputational complexity. Simulation results demonstrate that the proposed\nalgorithms converge quickly to the exact RZFBF and much faster compared to\nconventional methods. \n\n"}
{"id": "1303.6672", "contents": "Title: Living on the edge: Phase transitions in convex programs with random\n  data Abstract: Recent research indicates that many convex optimization problems with random\nconstraints exhibit a phase transition as the number of constraints increases.\nFor example, this phenomenon emerges in the $\\ell_1$ minimization method for\nidentifying a sparse vector from random linear measurements. Indeed, the\n$\\ell_1$ approach succeeds with high probability when the number of\nmeasurements exceeds a threshold that depends on the sparsity level; otherwise,\nit fails with high probability.\n  This paper provides the first rigorous analysis that explains why phase\ntransitions are ubiquitous in random convex optimization problems. It also\ndescribes tools for making reliable predictions about the quantitative aspects\nof the transition, including the location and the width of the transition\nregion. These techniques apply to regularized linear inverse problems with\nrandom measurements, to demixing problems under a random incoherence model, and\nalso to cone programs with random affine constraints.\n  The applied results depend on foundational research in conic geometry. This\npaper introduces a summary parameter, called the statistical dimension, that\ncanonically extends the dimension of a linear subspace to the class of convex\ncones. The main technical result demonstrates that the sequence of intrinsic\nvolumes of a convex cone concentrates sharply around the statistical dimension.\nThis fact leads to accurate bounds on the probability that a randomly rotated\ncone shares a ray with a fixed cone. \n\n"}
{"id": "1303.7291", "contents": "Title: A framework to characterize performance of LASSO algorithms Abstract: In this paper we consider solving \\emph{noisy} under-determined systems of\nlinear equations with sparse solutions. A noiseless equivalent attracted\nenormous attention in recent years, above all, due to work of\n\\cite{CRT,CanRomTao06,DonohoPol} where it was shown in a statistical and large\ndimensional context that a sparse unknown vector (of sparsity proportional to\nthe length of the vector) can be recovered from an under-determined system via\na simple polynomial $\\ell_1$-optimization algorithm. \\cite{CanRomTao06} further\nestablished that even when the equations are \\emph{noisy}, one can, through an\nSOCP noisy equivalent of $\\ell_1$, obtain an approximate solution that is (in\nan $\\ell_2$-norm sense) no further than a constant times the noise from the\nsparse unknown vector. In our recent works\n\\cite{StojnicCSetam09,StojnicUpper10}, we created a powerful mechanism that\nhelped us characterize exactly the performance of $\\ell_1$ optimization in the\nnoiseless case (as shown in \\cite{StojnicEquiv10} and as it must be if the\naxioms of mathematics are well set, the results of\n\\cite{StojnicCSetam09,StojnicUpper10} are in an absolute agreement with the\ncorresponding exact ones from \\cite{DonohoPol}). In this paper we design a\nmechanism, as powerful as those from \\cite{StojnicCSetam09,StojnicUpper10},\nthat can handle the analysis of a LASSO type of algorithm (and many others)\nthat can be (or typically are) used for \"solving\" noisy under-determined\nsystems. Using the mechanism we then, in a statistical context, compute the\nexact worst-case $\\ell_2$ norm distance between the unknown sparse vector and\nthe approximate one obtained through such a LASSO. The obtained results match\nthe corresponding exact ones obtained in \\cite{BayMon10,DonMalMon10}. Moreover,\nas a by-product of our analysis framework we recognize existence of an SOCP\ntype of algorithm that achieves the same performance. \n\n"}
{"id": "1304.0036", "contents": "Title: Tight bound on relative entropy by entropy difference Abstract: We prove a lower bound on the relative entropy between two finite-dimensional\nstates in terms of their entropy difference and the dimension of the underlying\nspace. The inequality is tight in the sense that equality can be attained for\nany prescribed value of the entropy difference, both for quantum and classical\nsystems. We outline implications for information theory and thermodynamics,\nsuch as a necessary condition for a process to be close to thermodynamic\nreversibility, or an easily computable lower bound on the classical channel\ncapacity. Furthermore, we derive a tight upper bound, uniform for all states of\na given dimension, on the variance of the surprisal, whose thermodynamic\nmeaning is that of heat capacity. \n\n"}
{"id": "1304.0110", "contents": "Title: A Signal Constellation for Pilotless Communications Over Wiener Phase\n  Noise Channels Abstract: Many satellite communication systems operating today employ low cost\nupconverters or downconverters which create phase noise. This noise can\nseverely limit the information rate of the system and pose a serious challenge\nfor the detection systems. Moreover, simple solutions for phase noise tracking\nsuch as PLL either require low phase noise or otherwise require many pilot\nsymbols which reduce the effective data rate. In order to increase the\neffective information rate, we propose a signal constellation which does not\nrequire pilots, at all, in order to converge in the decoding process. In this\ncontribution, we will present a signal constellation which does not require\npilot sequences, but we require a signal that does not present rotational\nsymmetry. For example a simple MPSK cannot be used.Moreover, we will provide a\nmethod to analyze the proposed constellations and provide a figure of merit for\ntheir performance when iterative decoding algorithms are used. \n\n"}
{"id": "1304.3179", "contents": "Title: Joint Precoding and Multivariate Backhaul Compression for the Downlink\n  of Cloud Radio Access Networks Abstract: This work studies the joint design of precoding and backhaul compression\nstrategies for the downlink of cloud radio access networks. In these systems, a\ncentral encoder is connected to multiple multi-antenna base stations (BSs) via\nfinite-capacity backhaul links. At the central encoder, precoding is followed\nby compression in order to produce the rate-limited bit streams delivered to\neach BS over the corresponding backhaul link. In current state-of-the-art\napproaches, the signals intended for different BSs are compressed\nindependently. In contrast, this work proposes to leverage joint compression,\nalso referred to as multivariate compression, of the signals of different BSs\nin order to better control the effect of the additive quantization noises at\nthe mobile stations (MSs). The problem of maximizing the weighted sum-rate with\nrespect to both the precoding matrix and the joint correlation matrix of the\nquantization noises is formulated subject to power and backhaul capacity\nconstraints. An iterative algorithm is proposed that achieves a stationary\npoint of the problem. Moreover, in order to enable the practical implementation\nof multivariate compression across BSs, a novel architecture is proposed based\non successive steps of minimum mean-squared error (MMSE) estimation and per-BS\ncompression. Robust design with respect to imperfect channel state information\nis also discussed. From numerical results, it is confirmed that the proposed\njoint precoding and compression strategy outperforms conventional approaches\nbased on the separate design of precoding and compression or independent\ncompression across the BSs. \n\n"}
{"id": "1304.3826", "contents": "Title: Multi-Layer Transmission and Hybrid Relaying for Relay Channels with\n  Multiple Out-of-Band Relays Abstract: In this work, a relay channel is studied in which a source encoder\ncommunicates with a destination decoder through a number of out-of-band relays\nthat are connected to the decoder through capacity-constrained digital backhaul\nlinks. This model is motivated by the uplink of cloud radio access networks. In\nthis scenario, a novel transmission and relaying strategies are proposed in\nwhich multi-layer transmission is used, on the one hand, to adaptively leverage\nthe different decoding capabilities of the relays and, on the other hand, to\nenable hybrid decode-and-forward (DF) and compress-and-forward (CF) relaying.\nThe hybrid relaying strategy allows each relay to forward part of the decoded\nmessages and a compressed version of the received signal to the decoder. The\nproblem of optimizing the power allocation across the layers and the\ncompression test channels is formulated. Albeit non-convex, the derived problem\nis found to belong to the class of so called complementary geometric programs\n(CGPs). Using this observation, an iterative algorithm based on the homotopy\nmethod is proposed that achieves a stationary point of the original problem by\nsolving a sequence of geometric programming (GP), and thus convex, problems.\nNumerical results are provided that show the effectiveness of the proposed\nmulti-layer hybrid scheme in achieving performance close to a theoretical\n(cutset) upper bound. \n\n"}
{"id": "1304.6133", "contents": "Title: On Maximal Correlation, Hypercontractivity, and the Data Processing\n  Inequality studied by Erkip and Cover Abstract: In this paper we provide a new geometric characterization of the\nHirschfeld-Gebelein-R\\'{e}nyi maximal correlation of a pair of random $(X,Y)$,\nas well as of the chordal slope of the nontrivial boundary of the\nhypercontractivity ribbon of $(X,Y)$ at infinity. The new characterizations\nlead to simple proofs for some of the known facts about these quantities. We\nalso provide a counterexample to a data processing inequality claimed by Erkip\nand Cover, and find the correct tight constant for this kind of inequality. \n\n"}
{"id": "1304.7344", "contents": "Title: On feedback in Gaussian multi-hop networks Abstract: The study of feedback has been mostly limited to single-hop communication\nsettings. In this paper, we consider Gaussian networks where sources and\ndestinations can communicate with the help of intermediate relays over multiple\nhops. We assume that links in the network can be bidirected providing\nopportunities for feedback. We ask the following question: can the information\ntransfer in both directions of a link be critical to maximizing the end-to-end\ncommunication rates in the network? Equivalently, could one of the directions\nin each bidirected link (and more generally at least one of the links forming a\ncycle) be shut down and the capacity of the network still be approximately\nmaintained? We show that in any arbitrary Gaussian network with bidirected\nedges and cycles and unicast traffic, we can always identify a directed acyclic\nsubnetwork that approximately maintains the capacity of the original network.\nFor Gaussian networks with multiple-access and broadcast traffic, an acyclic\nsubnetwork is sufficient to achieve every rate point in the capacity region of\nthe original network, however, there may not be a single acyclic subnetwork\nthat maintains the whole capacity region. For networks with multicast and\nmultiple unicast traffic, on the other hand, bidirected information flow across\ncertain links can be critically needed to maximize the end-to-end capacity\nregion. These results can be regarded as generalizations of the conclusions\nregarding the usefulness of feedback in various single-hop Gaussian settings\nand can provide opportunities for simplifying operation in Gaussian multi-hop\nnetworks. \n\n"}
{"id": "1304.7886", "contents": "Title: Throughput Maximization in Wireless Powered Communication Networks Abstract: This paper studies the newly emerging wireless powered communication network\n(WPCN) in which one hybrid access point (H-AP) with constant power supply\ncoordinates the wireless energy/information transmissions to/from distributed\nusers that do not have energy sources. A \"harvest-then-transmit\" protocol is\nproposed where all users first harvest the wireless energy broadcast by the\nH-AP in the downlink (DL) and then send their independent information to the\nH-AP in the uplink (UL) by time-division-multiple-access (TDMA). First, we\nstudy the sum-throughput maximization of all users by jointly optimizing the\ntime allocation for the DL wireless power transfer versus the users' UL\ninformation transmissions given a total time constraint based on the users' DL\nand UL channels as well as their average harvested energy values. By applying\nconvex optimization techniques, we obtain the closed-form expressions for the\noptimal time allocations to maximize the sum-throughput. Our solution reveals\n\"doubly near-far\" phenomenon due to both the DL and UL distance-dependent\nsignal attenuation, where a far user from the H-AP, which receives less\nwireless energy than a nearer user in the DL, has to transmit with more power\nin the UL for reliable information transmission. Consequently, the maximum\nsum-throughput is achieved by allocating substantially more time to the near\nusers than the far users, thus resulting in unfair rate allocation among\ndifferent users. To overcome this problem, we furthermore propose a new\nperformance metric so-called common-throughput with the additional constraint\nthat all users should be allocated with an equal rate regardless of their\ndistances to the H-AP. We present an efficient algorithm to solve the\ncommon-throughput maximization problem. Simulation results demonstrate the\neffectiveness of the common-throughput approach for solving the new doubly\nnear-far problem in WPCNs. \n\n"}
{"id": "1305.3356", "contents": "Title: Analytical Evaluation of Coverage-Oriented Femtocell Network Deployment Abstract: This paper proposes a coverage-oriented femtocell network deployment scheme,\nin which the femtocell base stations (BSs) can decide whether to be active or\ninactive depending on their distances from the macrocell BSs. Specifically, as\nthe areas close to the macrocell BSs already have satisfactory cellular\ncoverage, the femtocell BSs located inside such areas are kept to be inactive.\nThus, all the active femtocells are located in the poor macrocell coverage\nareas. Based on a stochastic geometric framework, the coverage probability can\nbe analyzed with tractable results. Surprisingly, the results show that the\nproposed scheme, although with a lower defacto femtocell density, can achieve\nbetter coverage performance than that keeping all femtocells in the entire\nnetwork to be active. The analytical results further identify the achievable\noptimal performance of the new scheme, which provides mobile operators a\nguideline for femtocell deployment and operation. \n\n"}
{"id": "1305.3358", "contents": "Title: Symmetry in Distributed Storage Systems Abstract: The max-flow outer bound is achievable by regenerating codes for functional\nrepair distributed storage system. However, the capacity of exact repair\ndistributed storage system is an open problem. In this paper, the linear\nprogramming bound for exact repair distributed storage systems is formulated. A\nnotion of symmetrical sets for a set of random variables is given and\nequalities of joint entropies for certain subsets of random variables in a\nsymmetrical set is established. Concatenation coding scheme for exact repair\ndistributed storage systems is proposed and it is shown that concatenation\ncoding scheme is sufficient to achieve any admissible rate for any exact repair\ndistributed storage system. Equalities of certain joint entropies of random\nvariables induced by concatenation scheme is shown. These equalities of joint\nentropies are new tools to simplify the linear programming bound and to obtain\nstronger converse results for exact repair distributed storage systems. \n\n"}
{"id": "1305.3537", "contents": "Title: Cooperative Relaying in a Poisson Field of Interferers: A Diversity\n  Order Analysis Abstract: This work analyzes the gains of cooperative relaying in interference-limited\nnetworks, in which outages can be due to interference and fading. A stochastic\nmodel based on point process theory is used to capture the spatial randomness\npresent in contemporary wireless networks. Using a modification of the\ndiversity order metric, the reliability gain of selection decode-and-forward is\nstudied for several cases. The main results are as follows: the achievable\n\\emph{spatial-contention} diversity order (SC-DO) is equal to one irrespective\nof the type of channel which is due to the ineffectiveness of the relay in the\nMAC-phase (transmit diversity). In the BC-phase (receive diversity), the SC-DO\ndepends on the amount of fading and spatial interference correlation. In the\nabsence of fading, there is a hard transition between SC-DO of either one or\ntwo, depending on the system parameters. \n\n"}
{"id": "1305.3595", "contents": "Title: Binary Energy Harvesting Channel with Finite Energy Storage Abstract: We consider the capacity of an energy harvesting communication channel with a\nfinite-sized battery. As an abstraction of this problem, we consider a system\nwhere energy arrives at the encoder in multiples of a fixed quantity, and the\nphysical layer is modeled accordingly as a finite discrete alphabet channel\nbased on this fixed quantity. Further, for tractability, we consider the case\nof binary energy arrivals into a unit-capacity battery over a noiseless binary\nchannel. Viewing the available energy as state, this is a state-dependent\nchannel with causal state information available only at the transmitter.\nFurther, the state is correlated over time and the channel inputs modify the\nfuture states. We show that this channel is equivalent to an additive\ngeometric-noise timing channel with causal information of the noise available\nat the transmitter.We provide a single-letter capacity expression involving an\nauxiliary random variable, and evaluate this expression with certain auxiliary\nrandom variable selection, which resembles noise concentration and lattice-type\ncoding in the timing channel. We evaluate the achievable rates by the proposed\nauxiliary selection and extend our results to noiseless ternary channels. \n\n"}
{"id": "1305.5278", "contents": "Title: The second laws of quantum thermodynamics Abstract: The second law of thermodynamics tells us which state transformations are so\nstatistically unlikely that they are effectively forbidden. Its original\nformulation, due to Clausius, states that \"Heat can never pass from a colder to\na warmer body without some other change, connected therewith, occurring at the\nsame time\". The second law applies to systems composed of many particles\ninteracting; however, we are seeing that one can make sense of thermodynamics\nin the regime where we only have a small number of particles interacting with a\nheat bath. Is there a second law of thermodynamics in this regime? Here, we\nfind that for processes which are cyclic or very close to cyclic, the second\nlaw for microscopic systems takes on a very different form than it does at the\nmacroscopic scale, imposing not just one constraint on what state\ntransformations are possible, but an entire family of constraints. In\nparticular, we find a family of free energies which generalise the traditional\none, and show that they can never increase. We further find that there are\nthree regimes which determine which family of second laws govern state\ntransitions, depending on how cyclic the process is. In one regime one can\ncause an apparent violation of the usual second law, through a process of\nembezzling work from a large system which remains arbitrarily close to its\noriginal state. These second laws are not only relevant for small systems, but\nalso apply to individual macroscopic systems interacting via long-range\ninteractions, which only satisfy the ordinary second law on average. By making\nprecise the definition of thermal operations, the laws of thermodynamics take\non a simple form with the first law defining the class of thermal operations,\nthe zeroeth law emerging as a unique condition ensuring the theory is\nnontrivial, and the remaining laws being a monotonicity property of our\ngeneralised free energies. \n\n"}
{"id": "1305.5530", "contents": "Title: Optimal Scheduling for Energy Harvesting Transmitters with Hybrid Energy\n  Storage Abstract: We consider data transmission with an energy harvesting transmitter which has\na hybrid energy storage unit composed of a perfectly efficient super-capacitor\n(SC) and an inefficient battery. The SC has finite space for energy storage\nwhile the battery has unlimited space. The transmitter can choose to store the\nharvested energy in the SC or in the battery. The energy is drained from the SC\nand the battery simultaneously. In this setting, we consider the offline\nthroughput maximization problem by a deadline over a point-to-point channel. In\ncontrast to previous works, the hybrid energy storage model with finite and\nunlimited storage capacities imposes a generalized set of constraints on the\ntransmission policy. As such, we show that the solution generalizes that for a\nsingle battery and is obtained by applying directional water-filling algorithm\nmultiple times. \n\n"}
{"id": "1306.3478", "contents": "Title: Symplectic spreads, planar functions and mutually unbiased bases Abstract: In this paper we give explicit descriptions of complete sets of mutually\nunbiased bases (MUBs) and orthogonal decompositions of special Lie algebras\n$sl_n(\\mathbb{C})$ obtained from commutative and symplectic semifields, and\nfrom some other non-semifield symplectic spreads. Relations between various\nconstructions are also studied. We show that the automorphism group of a\ncomplete set of MUBs is isomorphic to the automorphism group of the\ncorresponding orthogonal decomposition of the Lie algebra $sl_n(\\mathbb{C})$.\nIn the case of symplectic spreads this automorphism group is determined by the\nautomorphism group of the spread. By using the new notion of pseudo-planar\nfunctions over fields of characteristic two we give new explicit constructions\nof complete sets of MUBs. \n\n"}
{"id": "1306.3610", "contents": "Title: Thresholds of Spatially Coupled Systems via Lyapunov's Method Abstract: The threshold, or saturation phenomenon of spatially coupled systems is\nrevisited in the light of Lyapunov's theory of dynamical systems. It is shown\nthat an application of Lyapunov's direct method can be used to quantitatively\ndescribe the threshold phenomenon, prove convergence, and compute threshold\nvalues. This provides a general proof methodology for the various systems\nrecently studied. Examples of spatially coupled systems are given and their\nthresholds are computed. \n\n"}
{"id": "1306.3774", "contents": "Title: Under-determined linear systems and $\\ell_q$-optimization thresholds Abstract: Recent studies of under-determined linear systems of equations with sparse\nsolutions showed a great practical and theoretical efficiency of a particular\ntechnique called $\\ell_1$-optimization. Seminal works \\cite{CRT,DOnoho06CS}\nrigorously confirmed it for the first time. Namely, \\cite{CRT,DOnoho06CS}\nshowed, in a statistical context, that $\\ell_1$ technique can recover sparse\nsolutions of under-determined systems even when the sparsity is linearly\nproportional to the dimension of the system. A followup \\cite{DonohoPol} then\nprecisely characterized such a linearity through a geometric approach and a\nseries of work\\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed\nstatements of \\cite{DonohoPol} through a purely probabilistic approach. A\ntheoretically interesting alternative to $\\ell_1$ is a more general version\ncalled $\\ell_q$ (with an essentially arbitrary $q$). While $\\ell_1$ is\ntypically considered as a first available convex relaxation of sparsity norm\n$\\ell_0$, $\\ell_q,0\\leq q\\leq 1$, albeit non-convex, should technically be a\ntighter relaxation of $\\ell_0$. Even though developing polynomial (or close to\nbe polynomial) algorithms for non-convex problems is still in its initial\nphases one may wonder what would be the limits of an $\\ell_q,0\\leq q\\leq 1$,\nrelaxation even if at some point one can develop algorithms that could handle\nits non-convexity. A collection of answers to this and a few realted questions\nis precisely what we present in this paper. \n\n"}
{"id": "1306.4748", "contents": "Title: New Analysis of Manifold Embeddings and Signal Recovery from Compressive\n  Measurements Abstract: Compressive Sensing (CS) exploits the surprising fact that the information\ncontained in a sparse signal can be preserved in a small number of compressive,\noften random linear measurements of that signal. Strong theoretical guarantees\nhave been established concerning the embedding of a sparse signal family under\na random measurement operator and on the accuracy to which sparse signals can\nbe recovered from noisy compressive measurements. In this paper, we address\nsimilar questions in the context of a different modeling framework. Instead of\nsparse models, we focus on the broad class of manifold models, which can arise\nin both parametric and non-parametric signal families. Using tools from the\ntheory of empirical processes, we improve upon previous results concerning the\nembedding of low-dimensional manifolds under random measurement operators. We\nalso establish both deterministic and probabilistic instance-optimal bounds in\n$\\ell_2$ for manifold-based signal recovery and parameter estimation from noisy\ncompressive measurements. In line with analogous results for sparsity-based CS,\nwe conclude that much stronger bounds are possible in the probabilistic\nsetting. Our work supports the growing evidence that manifold-based models can\nbe used with high accuracy in compressive signal processing. \n\n"}
{"id": "1306.6122", "contents": "Title: Downlink Rate Distribution in Heterogeneous Cellular Networks under\n  Generalized Cell Selection Abstract: Considering both small-scale fading and long-term shadowing, we characterize\nthe downlink rate distribution at a typical user equipment (UE) in a\nheterogeneous cellular network (HetNet), where shadowing, following any general\ndistribution, impacts cell selection while fading does not. Prior work either\nignores the impact of channel randomness on cell selection or lumps all the\nsources of randomness into a single variable, with cell selection based on the\ninstantaneous signal strength, which is unrealistic. As an application of the\nresults, we study the impact of shadowing on load balancing in terms of the\noptimal per-tier selection bias needed for rate maximization. \n\n"}
{"id": "1307.1101", "contents": "Title: Mixed-Timescale Precoding and Cache Control in Cached MIMO Interference\n  Network Abstract: Consider media streaming in MIMO interference networks whereby multiple base\nstations (BS) simultaneously deliver media to their associated users using\nfixed data rates. The performance is fundamentally limited by the cross-link\ninterference. We propose a cache-induced opportunistic cooperative MIMO (CoMP)\nfor interference mitigation. By caching a portion of the media files, the BSs\nopportunistically employ CoMP to transform the cross-link interference into\nspatial multiplexing gain. We study a mixed-timescale optimization of MIMO\nprecoding and cache control to minimize the transmit power under the rate\nconstraint. The cache control is to create more CoMP opportunities and is\nadaptive to the long-term popularity of the media files. The precoding is to\nguarantee the rate requirement and is adaptive to the channel state information\nand cache state at the BSs. The joint stochastic optimization problem is\ndecomposed into a short-term precoding and a long-term cache control problem.\nWe propose a precoding algorithm which converges to a stationary point of the\nshort-term problem. Based on this, we exploit the hidden convexity of the\nlong-term problem and propose a low complexity and robust solution using\nstochastic subgradient. The solution has significant gains over various\nbaselines and does not require explicit knowledge of the media popularity. \n\n"}
{"id": "1307.1524", "contents": "Title: Fundamentals of Heterogeneous Cellular Networks with Energy Harvesting Abstract: We develop a new tractable model for K-tier heterogeneous cellular networks\n(HetNets), where each base station (BS) is powered solely by a self-contained\nenergy harvesting module. The BSs across tiers differ in terms of the energy\nharvesting rate, energy storage capacity, transmit power and deployment\ndensity. Since a BS may not always have enough energy, it may need to be kept\nOFF and allowed to recharge while nearby users are served by neighboring BSs\nthat are ON. We show that the fraction of time a k^{th} tier BS can be kept ON,\ntermed availability \\rho_k, is a fundamental metric of interest. Using tools\nfrom random walk theory, fixed point analysis and stochastic geometry, we\ncharacterize the set of K-tuples (\\rho_1, \\rho_2, ... \\rho_K), termed the\navailability region, that is achievable by general uncoordinated operational\nstrategies, where the decision to toggle the current ON/OFF state of a BS is\ntaken independently of the other BSs. If the availability vector corresponding\nto the optimal system performance, e.g., in terms of rate, lies in this\navailability region, there is no performance loss due to the presence of\nunreliable energy sources. As a part of our analysis, we model the temporal\ndynamics of the energy level at each BS as a birth-death process, derive the\nenergy utilization rate, and use hitting/stopping time analysis to prove that\nthere exists a fundamental limit on \\rho_k that cannot be surpassed by any\nuncoordinated strategy. \n\n"}
{"id": "1307.2430", "contents": "Title: On The Fast Fading Multiple-Antenna Gaussian Broadcast Channel with\n  Confidential Messages and Partial CSIT Abstract: In wiretap channels the eavesdropper's channel state information (CSI) is\ncommonly assumed to be known at transmitter, fully or partially. However, under\nperfect secrecy constraint the eavesdropper may not be motivated to feedback\nany correct CSI. In this paper we consider a more feasible problem for the\ntransmitter to have eavesdropper's CSI. That is, the fast fading\nmultiple-antenna Gaussian broadcast channels (FMGBC-CM) with confidential\nmessages, where both receivers are legitimate users such that they both are\nwilling to feedback accurate CSI to maintain their secure transmission, and not\nto be eavesdropped by the other. We assume that only the statistics of the\nchannel state information are known by the transmitter. We first show the\nnecessary condition for the FMGBC-CM not to be degraded to the common wiretap\nchannels. Then we derive the achievable rate region for the FMGBC-CM where the\nchannel input covariance matrices and the inflation factor are left unknown and\nto be solved. After that we provide an analytical solution to the channel input\ncovariance matrices. We also propose an iterative algorithm to solve the\nchannel input covariance matrices and the inflation factor. Due to the\ncomplicated rate region formulae in normal SNR, we resort to low SNR analysis\nto investigate the characteristics of the channel. Finally, numerical examples\nshow that under perfect secrecy constraint both users can achieve positive\nrates simultaneously, which verifies our derived necessary condition. Numerical\nresults also elucidate the effectiveness of the analytic solution and proposed\nalgorithm of solving the channel input covariance matrices and the inflation\nfactor under different conditions. \n\n"}
{"id": "1307.4502", "contents": "Title: Universally Elevating the Phase Transition Performance of Compressed\n  Sensing: Non-Isometric Matrices are Not Necessarily Bad Matrices Abstract: In compressed sensing problems, $\\ell_1$ minimization or Basis Pursuit was\nknown to have the best provable phase transition performance of recoverable\nsparsity among polynomial-time algorithms. It is of great theoretical and\npractical interest to find alternative polynomial-time algorithms which perform\nbetter than $\\ell_1$ minimization. \\cite{Icassp reweighted l_1}, \\cite{Isit\nreweighted l_1}, \\cite{XuScaingLaw} and \\cite{iterativereweightedjournal} have\nshown that a two-stage re-weighted $\\ell_1$ minimization algorithm can boost\nthe phase transition performance for signals whose nonzero elements follow an\namplitude probability density function (pdf) $f(\\cdot)$ whose $t$-th derivative\n$f^{t}(0) \\neq 0$ for some integer $t \\geq 0$. However, for signals whose\nnonzero elements are strictly suspended from zero in distribution (for example,\nconstant-modulus, only taking values `$+d$' or `$-d$' for some nonzero real\nnumber $d$), no polynomial-time signal recovery algorithms were known to\nprovide better phase transition performance than plain $\\ell_1$ minimization,\nespecially for dense sensing matrices. In this paper, we show that a\npolynomial-time algorithm can universally elevate the phase-transition\nperformance of compressed sensing, compared with $\\ell_1$ minimization, even\nfor signals with constant-modulus nonzero elements. Contrary to conventional\nwisdoms that compressed sensing matrices are desired to be isometric, we show\nthat non-isometric matrices are not necessarily bad sensing matrices. In this\npaper, we also provide a framework for recovering sparse signals when sensing\nmatrices are not isometric. \n\n"}
{"id": "1307.7211", "contents": "Title: Physical Layer Security in Downlink Multi-Antenna Cellular Networks Abstract: In this paper, we study physical layer security for the downlink of cellular\nnetworks, where the confidential messages transmitted to each mobile user can\nbe eavesdropped by both (i) the other users in the same cell and (ii) the users\nin the other cells. The locations of base stations and mobile users are modeled\nas two independent two-dimensional Poisson point processes. Using the proposed\nmodel, we analyze the secrecy rates achievable by regularized channel inversion\n(RCI) precoding by performing a large-system analysis that combines tools from\nstochastic geometry and random matrix theory. We obtain approximations for the\nprobability of secrecy outage and the mean secrecy rate, and characterize\nregimes where RCI precoding achieves a nonzero secrecy rate. We find that\nunlike isolated cells, the secrecy rate in a cellular network does not grow\nmonotonically with the transmit power, and the network tends to be in secrecy\noutage if the transmit power grows unbounded. Furthermore, we show that there\nis an optimal value for the base station deployment density that maximizes the\nsecrecy rate, and this value is a decreasing function of the signal-to-noise\nratio. \n\n"}
{"id": "1308.3310", "contents": "Title: On the Capacity and Degrees of Freedom Regions of MIMO Interference\n  Channels with Limited Receiver Cooperation Abstract: This paper gives the approximate capacity region of a two-user MIMO\ninterference channel with limited receiver cooperation, where the gap between\nthe inner and outer bounds is in terms of the total number of receive antennas\nat the two receivers and is independent of the actual channel values. The\napproximate capacity region is then used to find the degrees of freedom region.\nFor the special case of symmetric interference channels, we also find the\namount of receiver cooperation in terms of the backhaul capacity beyond which\nthe degrees of freedom do not improve. Further, the generalized degrees of\nfreedom are found for MIMO interference channels with equal number of antennas\nat all nodes. It is shown that the generalized degrees of freedom improve\ngradually from a \"W\" curve to a \"V\" curve with increase in cooperation in terms\nof the backhaul capacity. \n\n"}
{"id": "1308.6007", "contents": "Title: Tree Codes and a Conjecture on Exponential Sums Abstract: We propose a new conjecture on some exponential sums. These particular sums\nhave not apparently been considered in the literature. Subject to the\nconjecture we obtain the first effective construction of asymptotically good\ntree codes. The available numerical evidence is consistent with the conjecture\nand is sufficient to certify codes for significant-length communications. \n\n"}
{"id": "1309.0482", "contents": "Title: Law of Log Determinant of Sample Covariance Matrix and Optimal\n  Estimation of Differential Entropy for High-Dimensional Gaussian\n  Distributions Abstract: Differential entropy and log determinant of the covariance matrix of a\nmultivariate Gaussian distribution have many applications in coding,\ncommunications, signal processing and statistical inference. In this paper we\nconsider in the high dimensional setting optimal estimation of the differential\nentropy and the log-determinant of the covariance matrix. We first establish a\ncentral limit theorem for the log determinant of the sample covariance matrix\nin the high dimensional setting where the dimension $p(n)$ can grow with the\nsample size $n$. An estimator of the differential entropy and the log\ndeterminant is then considered. Optimal rate of convergence is obtained. It is\nshown that in the case $p(n)/n \\rightarrow 0$ the estimator is asymptotically\nsharp minimax. The ultra-high dimensional setting where $p(n) > n$ is also\ndiscussed. \n\n"}
{"id": "1309.0799", "contents": "Title: Linear Degrees of Freedom of the X-Channel with Delayed CSIT Abstract: We establish the degrees of freedom of the two-user X-channel with delayed\nchannel knowledge at transmitters (i.e., delayed CSIT), assuming linear coding\nstrategies at the transmitters. We derive a new upper bound and characterize\nthe linear degrees of freedom of this network to be 6/5. The converse builds\nupon our development of a general lemma that shows that, if two distributed\ntransmitters employ linear strategies, the ratio of the dimensions of received\nlinear subspaces at the two receivers cannot exceed 3/2, due to delayed CSIT.\nAs a byproduct, we also apply this general lemma to the three-user interference\nchannel with delayed CSIT, thereby deriving a new upper bound of 9/7 on its\nlinear degrees of freedom. This is the first bound that captures the impact of\ndelayed CSIT on the degrees of freedom of this network, under the assumption of\nlinear encoding strategies. \n\n"}
{"id": "1309.0898", "contents": "Title: Two-Hop Interference Channels: Impact of Linear Schemes Abstract: We consider the two-hop interference channel (IC), which consists of two\nsource-destination pairs communicating with each other via two relays. We\nanalyze the degrees of freedom (DoF) of this network when the relays are\nrestricted to perform linear schemes, and the channel gains are constant (i.e.,\nslow fading). We show that, somewhat surprisingly, by using vector-linear\nstrategies at the relays, it is possible to achieve 4/3 sum-DoF when the\nchannel gains are real. The key achievability idea is to alternate relaying\ncoefficients across time, to create different end-to-end interference\nstructures (or topologies) at different times. Although each of these\ntopologies has only 1 sum-DoF, we manage to achieve 4/3 by coding across them.\nFurthermore, we develop a novel outer bound that matches our achievability,\nhence characterizing the sum-DoF of two-hop interference channels with linear\nschemes. As for the case of complex channel gains, we characterize the sum-DoF\nwith linear schemes to be 5/3. We also generalize the results to the\nmulti-antenna setting, characterizing the sum-DoF with linear schemes to be\n2M-1/3 (for complex channel gains), where M is the number of antennas at each\nnode. \n\n"}
{"id": "1309.1585", "contents": "Title: Network-Level Cooperation in Energy Harvesting Wireless Networks Abstract: We consider a two-hop communication network consisted of a source node, a\nrelay and a destination node in which the source and the relay node have\nexternal traffic arrivals. The relay forwards a fraction of the source node's\ntraffic to the destination and the cooperation is performed at the network\nlevel. In addition, both source and relay nodes have energy harvesting\ncapabilities and an unlimited battery to store the harvested energy. We study\nthe impact of the energy constraints on the stability region. Specifically, we\nprovide inner and outer bounds on the stability region of the two-hop network\nwith energy harvesting source and relay. \n\n"}
{"id": "1309.3792", "contents": "Title: Exact Complexity: The Spectral Decomposition of Intrinsic Computation Abstract: We give exact formulae for a wide family of complexity measures that capture\nthe organization of hidden nonlinear processes. The spectral decomposition of\noperator-valued functions leads to closed-form expressions involving the full\neigenvalue spectrum of the mixed-state presentation of a process's\nepsilon-machine causal-state dynamic. Measures include correlation functions,\npower spectra, past-future mutual information, transient and synchronization\ninformations, and many others. As a result, a direct and complete analysis of\nintrinsic computation is now available for the temporal organization of\nfinitary hidden Markov models and nonlinear dynamical systems with generating\npartitions and for the spatial organization in one-dimensional systems,\nincluding spin systems, cellular automata, and complex materials via chaotic\ncrystallography. \n\n"}
{"id": "1309.7540", "contents": "Title: Joint Power and Antenna Selection Optimization in Large Cloud Radio\n  Access Networks Abstract: Large multiple-input multiple-output (MIMO) networks promise high energy\nefficiency, i.e., much less power is required to achieve the same capacity\ncompared to the conventional MIMO networks if perfect channel state information\n(CSI) is available at the transmitter. However, in such networks, huge overhead\nis required to obtain full CSI especially for Frequency-Division Duplex (FDD)\nsystems. To reduce overhead, we propose a downlink antenna selection scheme,\nwhich selects S antennas from M>S transmit antennas based on the large scale\nfading to serve K\\leq S users in large distributed MIMO networks employing\nregularized zero-forcing (RZF) precoding. In particular, we study the joint\noptimization of antenna selection, regularization factor, and power allocation\nto maximize the average weighted sum-rate. This is a mixed combinatorial and\nnon-convex problem whose objective and constraints have no closed-form\nexpressions. We apply random matrix theory to derive asymptotically accurate\nexpressions for the objective and constraints. As such, the joint optimization\nproblem is decomposed into subproblems, each of which is solved by an efficient\nalgorithm. In addition, we derive structural solutions for some special cases\nand show that the capacity of very large distributed MIMO networks scales as\nO\\left(K\\textrm{log}M\\right) when M\\rightarrow\\infty with K,S fixed.\nSimulations show that the proposed scheme achieves significant performance gain\nover various baselines. \n\n"}
{"id": "1309.7964", "contents": "Title: A General Formula for the Mismatch Capacity Abstract: The fundamental limits of channels with mismatched decoding are addressed. A\ngeneral formula is established for the mismatch capacity of a general channel,\ndefined as a sequence of conditional distributions with a general decoding\nmetrics sequence. We deduce an identity between the Verd\\'{u}-Han general\nchannel capacity formula, and the mismatch capacity formula applied to Maximum\nLikelihood decoding metric. Further, several upper bounds on the capacity are\nprovided, and a simpler expression for a lower bound is derived for the case of\na non-negative decoding metric. The general formula is specialized to the case\nof finite input and output alphabet channels with a type-dependent metric. The\nclosely related problem of threshold mismatched decoding is also studied, and a\ngeneral expression for the threshold mismatch capacity is obtained. As an\nexample of threshold mismatch capacity, we state a general expression for the\nerasures-only capacity of the finite input and output alphabet channel. We\nobserve that for every channel there exists a (matched) threshold decoder which\nis capacity achieving. Additionally, necessary and sufficient conditions are\nstated for a channel to have a strong converse. Csisz\\'{a}r and Narayan's\nconjecture is proved for bounded metrics, providing a positive answer to the\nopen problem introduced in [1], i.e., that the \"product-space\" improvement of\nthe lower random coding bound, $C_q^{(\\infty)}(W)$, is indeed the mismatch\ncapacity of the discrete memoryless channel $W$. We conclude by presenting an\nidentity between the threshold capacity and $C_q^{(\\infty)}(W)$ in the DMC\ncase. \n\n"}
{"id": "1310.0720", "contents": "Title: A Survey on Device-to-Device Communication in Cellular Networks Abstract: Device-to-Device (D2D) communication was initially proposed in cellular\nnetworks as a new paradigm to enhance network performance. The emergence of new\napplications such as content distribution and location-aware advertisement\nintroduced new use-cases for D2D communications in cellular networks. The\ninitial studies showed that D2D communication has advantages such as increased\nspectral efficiency and reduced communication delay. However, this\ncommunication mode introduces complications in terms of interference control\noverhead and protocols that are still open research problems. The feasibility\nof D2D communications in LTE-A is being studied by academia, industry, and the\nstandardization bodies. To date, there are more than 100 papers available on\nD2D communications in cellular networks and, there is no survey on this field.\nIn this article, we provide a taxonomy based on the D2D communicating spectrum\nand review the available literature extensively under the proposed taxonomy.\nMoreover, we provide new insights to the over-explored and under-explored areas\nwhich lead us to identify open research problems of D2D communication in\ncellular networks. \n\n"}
{"id": "1310.1419", "contents": "Title: On Association Cells in Random Heterogeneous Networks Abstract: Characterizing user to access point (AP) association strategies in\nheterogeneous cellular networks (HetNets) is critical for their performance\nanalysis, as it directly influences the load across the network. In this\nletter, we introduce and analyze a class of association strategies, which we\nterm stationary association, and the resulting association cells. For random\nHetNets, where APs are distributed according to a stationary point process, the\narea of the resulting association cells are shown to be the marks of the\ncorresponding point process. Addressing the need of quantifying the load\nexperienced by a typical user, a \"Feller-paradox\" like relationship is\nestablished between the area of the association cell containing origin and that\nof a typical association cell. For the specific case of Poisson point process\nand max power/SINR association, the mean association area of each tier is\nderived and shown to increase with channel gain variance and decrease in the\npath loss exponents of the corresponding tier. \n\n"}
{"id": "1310.1635", "contents": "Title: Constellation Optimization in the Presence of Strong Phase Noise Abstract: In this paper, we address the problem of optimizing signal constellations for\nstrong phase noise. The problem is investigated by considering three\noptimization formulations, which provide an analytical framework for\nconstellation design. In the first formulation, we seek to design\nconstellations that minimize the symbol error probability (SEP) for an\napproximate ML detector in the presence of phase noise. In the second\nformulation, we optimize constellations in terms of mutual information (MI) for\nthe effective discrete channel consisting of phase noise, additive white\nGaussian noise, and the approximate ML detector. To this end, we derive the MI\nof this discrete channel. Finally, we optimize constellations in terms of the\nMI for the phase noise channel. We give two analytical characterizations of the\nMI of this channel, which are shown to be accurate for a wide range of\nsignal-to-noise ratios and phase noise variances. For each formulation, we\npresent a detailed analysis of the optimal constellations and their performance\nin the presence of strong phase noise. We show that the optimal constellations\nsignificantly outperform conventional constellations and those proposed in the\nliterature in terms of SEP, error floors, and MI. \n\n"}
{"id": "1310.3085", "contents": "Title: Source-Channel Matching for Sources with Memory Abstract: In this paper we analyze the probabilistic matching of sources with memory to\nchannels with memory so that symbol-by-symbol code with memory without\nanticipation are optimal, with respect to an average distortion and excess\ndistortion probability. We show achievability of such a symbolby- symbol code\nwith memory without anticipation, and we show matching for the Binary Symmetric\nMarkov source (BSMS(p)) over a first-order symmetric channel with a cost\nconstraint. \n\n"}
{"id": "1310.3482", "contents": "Title: Using Information Theory to Study the Efficiency and Capacity of Caching\n  in the Computer Networks Abstract: Nowadays computer networks use different kind of memory whose speeds and\ncapacities vary widely. There exist methods of a so-called caching which are\nintended to use the different kinds of memory in such a way that the frequently\nused data are stored in the faster memory, wheres the infrequent ones are\nstored in the slower memory. We address the problems of estimating the caching\nefficiency and its capacity. We define the efficiency and capacity of the\ncaching and suggest a method for their estimation based on the analysis of\nkinds of the accessible memory. \n\n"}
{"id": "1310.3724", "contents": "Title: Spatially Coupled Sparse Codes on Graphs - Theory and Practice Abstract: Since the discovery of turbo codes 20 years ago and the subsequent\nre-discovery of low-density parity-check codes a few years later, the field of\nchannel coding has experienced a number of major advances. Up until that time,\ncode designers were usually happy with performance that came within a few\ndecibels of the Shannon Limit, primarily due to implementation complexity\nconstraints, whereas the new coding techniques now allow performance within a\nsmall fraction of a decibel of capacity with modest encoding and decoding\ncomplexity. Due to these significant improvements, coding standards in\napplications as varied as wireless mobile transmission, satellite TV, and deep\nspace communication are being updated to incorporate the new techniques. In\nthis paper, we review a particularly exciting new class of low-density\nparity-check codes, called spatially-coupled codes, which promise excellent\nperformance over a broad range of channel conditions and decoded error rate\nrequirements. \n\n"}
{"id": "1310.4761", "contents": "Title: Towards Energy Neutrality in Energy Harvesting Wireless Sensor Networks:\n  A Case for Distributed Compressive Sensing? Abstract: This paper advocates the use of the emerging distributed compressive sensing\n(DCS) paradigm in order to deploy energy harvesting (EH) wireless sensor\nnetworks (WSN) with practical network lifetime and data gathering rates that\nare substantially higher than the state-of-the-art. In particular, we argue\nthat there are two fundamental mechanisms in an EH WSN: i) the energy diversity\nassociated with the EH process that entails that the harvested energy can vary\nfrom sensor node to sensor node, and ii) the sensing diversity associated with\nthe DCS process that entails that the energy consumption can also vary across\nthe sensor nodes without compromising data recovery. We also argue that such\nmechanisms offer the means to match closely the energy demand to the energy\nsupply in order to unlock the possibility for energy-neutral WSNs that leverage\nEH capability. A number of analytic and simulation results are presented in\norder to illustrate the potential of the approach. \n\n"}
{"id": "1310.5684", "contents": "Title: Linear tree codes and the problem of explicit constructions Abstract: We reduce the problem of constructing asymptotically good tree codes to the\nconstruction of triangular totally nonsingular matrices over fields with\npolynomially many elements. We show a connection of this problem to Birkhoff\ninterpolation in finite fields. \n\n"}
{"id": "1311.3045", "contents": "Title: Joint Power and Admission Control: Non-Convex $L_q$ Approximation and An\n  Effective Polynomial Time Deflation Approach Abstract: In an interference limited network, joint power and admission control (JPAC)\naims at supporting a maximum number of links at their specified signal to\ninterference plus noise ratio (SINR) targets while using a minimum total\ntransmission power. Various convex approximation deflation approaches have been\ndeveloped for the JPAC problem. In this paper, we propose an effective\npolynomial time non-convex approximation deflation approach for solving the\nproblem. The approach is based on the non-convex $\\ell_q$-minimization\napproximation of an equivalent sparse $\\ell_0$-minimization reformulation of\nthe JPAC problem where $q\\in(0,1).$ We show that, for any instance of the JPAC\nproblem, there exists a $\\bar q\\in(0,1)$ such that it can be exactly solved by\nsolving its $\\ell_q$-minimization approximation problem with any $q\\in(0, \\bar\nq]$. We also show that finding the global solution of the $\\ell_q$\napproximation problem is NP-hard. Then, we propose a potential reduction\ninterior-point algorithm, which can return an $\\epsilon$-KKT solution of the\nNP-hard $\\ell_q$-minimization approximation problem in polynomial time. The\nreturned solution can be used to check the simultaneous supportability of all\nlinks in the network and to guide an iterative link removal procedure,\nresulting in the polynomial time non-convex approximation deflation approach\nfor the JPAC problem. Numerical simulations show that the proposed approach\noutperforms the existing convex approximation approaches in terms of the number\nof supported links and the total transmission power, particularly exhibiting a\nquite good performance in selecting which subset of links to support. \n\n"}
{"id": "1311.3646", "contents": "Title: Online Coded Caching Abstract: We consider a basic content distribution scenario consisting of a single\norigin server connected through a shared bottleneck link to a number of users\neach equipped with a cache of finite memory. The users issue a sequence of\ncontent requests from a set of popular files, and the goal is to operate the\ncaches as well as the server such that these requests are satisfied with the\nminimum number of bits sent over the shared link. Assuming a basic Markov model\nfor renewing the set of popular files, we characterize approximately the\noptimal long-term average rate of the shared link. We further prove that the\noptimal online scheme has approximately the same performance as the optimal\noffline scheme, in which the cache contents can be updated based on the entire\nset of popular files before each new request. To support these theoretical\nresults, we propose an online coded caching scheme termed coded least-recently\nsent (LRS) and simulate it for a demand time series derived from the dataset\nmade available by Netflix for the Netflix Prize. For this time series, we show\nthat the proposed coded LRS algorithm significantly outperforms the popular\nleast-recently used (LRU) caching algorithm. \n\n"}
{"id": "1311.4310", "contents": "Title: Achievable Rate Region of the Bidirectional Buffer-Aided Relay Channel\n  with Block Fading Abstract: The bidirectional relay channel, in which two users communicate with each\nother through a relay node, is a simple but fundamental and practical network\narchitecture. In this paper, we consider the block fading bidirectional relay\nchannel and propose efficient transmission strategies that exploit the block\nfading property of the channel. Thereby, we consider a decode-and-forward relay\nand assume that a direct link between the two users is not present. Our aim is\nto characterize the long-term achievable rate region and to develop protocols\nwhich achieve all points of the obtained rate region. Specifically, in the\nbidirectional relay channel, there exist six possible transmission modes: four\npoint-to-point modes (user 1-to-relay, user 2-to-relay, relay-to-user 1,\nrelay-to-user 2), a multiple-access mode (both users to the relay), and a\nbroadcast mode (the relay to both users). Most existing protocols assume a\nfixed schedule for using a subset of the aforementioned transmission modes.\nMotivated by this limitation, we develop protocols which are not restricted to\nadhere to a predefined schedule for using the transmission modes. In fact,\nbased on the instantaneous channel state information (CSI) of the involved\nlinks, the proposed protocol selects the optimal transmission mode in each time\nslot to maximize the long-term achievable rate region. Thereby, we consider two\ndifferent types of transmit power constraints: 1) a joint long-term power\nconstraint for all nodes, and 2) a fixed transmit power for each node.\nFurthermore, to enable the use of a non-predefined schedule for transmission\nmode selection, the relay has to be equipped with two buffers for storage of\nthe information received from both users. As data buffering increases the\nend-to-end delay, we consider both delay-unconstrained and delay-constrained\ntransmission in the paper. \n\n"}
{"id": "1311.4809", "contents": "Title: Uplink Performance of Large Optimum-Combining Antenna Arrays in\n  Poisson-Cell Networks Abstract: The uplink of a wireless network with base stations distributed according to\na Poisson Point Process (PPP) is analyzed. The base stations are assumed to\nhave a large number of antennas and use linear minimum-mean-square-error (MMSE)\nspatial processing for multiple access. The number of active mobiles per cell\nis limited to permit channel estimation using pilot sequences that are\northogonal in each cell. The cumulative distribution function (CDF) of a\nrandomly located link in a typical cell of such a system is derived when\naccurate channel estimation is available. A simple bound is provided for the\nspectral efficiency when channel estimates suffer from pilot contamination. The\nresults provide insight into the performance of so-called massive\nMultiple-Input-Multiple-Output (MIMO) systems in spatially distributed cellular\nnetworks. \n\n"}
{"id": "1311.4947", "contents": "Title: A Framework of Constructions of Minimal Storage Regenerating Codes with\n  the Optimal Access/Update Property Abstract: In this paper, we present a generic framework for constructing systematic\nminimum storage regenerating codes with two parity nodes based on the invariant\nsubspace technique. Codes constructed in our framework not only contain some\nbest known codes as special cases, but also include some new codes with key\nproperties such as the optimal access property and the optimal update property.\nIn particular, for a given storage capacity of an individual node, one of the\nnew codes has the largest number of systematic nodes and two of the new codes\nhave the largest number of systematic nodes with the optimal update property. \n\n"}
{"id": "1312.0914", "contents": "Title: Characterizing the Rate Region of the (4,3,3) Exact-Repair Regenerating\n  Codes Abstract: Exact-repair regenerating codes are considered for the case (n,k,d)=(4,3,3),\nfor which a complete characterization of the rate region is provided. This\ncharacterization answers in the affirmative the open question whether there\nexists a non-vanishing gap between the optimal bandwidth-storage tradeoff of\nthe functional-repair regenerating codes (i.e., the cut-set bound) and that of\nthe exact-repair regenerating codes. To obtain an explicit information\ntheoretic converse, a computer-aided proof (CAP) approach based on primal and\ndual relation is developed. This CAP approach extends Yeung's linear\nprogramming (LP) method, which was previously only used on information\ntheoretic problems with a few random variables due to the exponential growth of\nthe number of variables in the corresponding LP problem. The symmetry in the\nexact-repair regenerating code problem allows an effective reduction of the\nnumber of variables, and together with several other problem-specific\nreductions, the LP problem is reduced to a manageable scale. For the\nachievability, only one non-trivial corner point of the rate region needs to be\naddressed in this case, for which an explicit binary code construction is\ngiven. \n\n"}
{"id": "1312.0972", "contents": "Title: Rank-Modulation Rewrite Coding for Flash Memories Abstract: The current flash memory technology focuses on the cost minimization of its\nstatic storage capacity. However, the resulting approach supports a relatively\nsmall number of program-erase cycles. This technology is effective for consumer\ndevices (e.g., smartphones and cameras) where the number of program-erase\ncycles is small. However, it is not economical for enterprise storage systems\nthat require a large number of lifetime writes. The proposed approach in this\npaper for alleviating this problem consists of the efficient integration of two\nkey ideas: (i) improving reliability and endurance by representing the\ninformation using relative values via the rank modulation scheme and (ii)\nincreasing the overall (lifetime) capacity of the flash device via rewriting\ncodes, namely, performing multiple writes per cell before erasure. This paper\npresents a new coding scheme that combines rank modulation with rewriting. The\nkey benefits of the new scheme include: (i) the ability to store close to 2\nbits per cell on each write with minimal impact on the lifetime of the memory,\nand (ii) efficient encoding and decoding algorithms that make use of\ncapacity-achieving write-once-memory (WOM) codes that were proposed recently. \n\n"}
{"id": "1312.2045", "contents": "Title: Joint Spatial Division and Multiplexing for mm-Wave Channels Abstract: Massive MIMO systems are well-suited for mm-Wave communications, as large\narrays can be built with reasonable form factors, and the high array gains\nenable reasonable coverage even for outdoor communications. One of the main\nobstacles for using such systems in frequency-division duplex mode, namely the\nhigh overhead for the feedback of channel state information (CSI) to the\ntransmitter, can be mitigated by the recently proposed JSDM (Joint Spatial\nDivision and Multiplexing) algorithm. In this paper we analyze the performance\nof this algorithm in some realistic propagation channels that take into account\nthe partial overlap of the angular spectra from different users, as well as the\nsparsity of mm-Wave channels. We formulate the problem of user grouping for two\ndifferent objectives, namely maximizing spatial multiplexing, and maximizing\ntotal received power, in a graph-theoretic framework. As the resulting problems\nare numerically difficult, we proposed (sub optimum) greedy algorithms as\nefficient solution methods. Numerical examples show that the different\nalgorithms may be superior in different settings.We furthermore develop a new,\n\"degenerate\" version of JSDM that only requires average CSI at the transmitter,\nand thus greatly reduces the computational burden. Evaluations in propagation\nchannels obtained from ray tracing results, as well as in measured outdoor\nchannels show that this low-complexity version performs surprisingly well in\nmm-Wave channels. \n\n"}
{"id": "1312.3961", "contents": "Title: Fundamental Limits of Caching with Secure Delivery Abstract: Caching is emerging as a vital tool for alleviating the severe capacity\ncrunch in modern content-centric wireless networks. The main idea behind\ncaching is to store parts of popular content in end-users' memory and leverage\nthe locally stored content to reduce peak data rates. By jointly designing\ncontent placement and delivery mechanisms, recent works have shown order-wise\nreduction in transmission rates in contrast to traditional methods. In this\nwork, we consider the secure caching problem with the additional goal of\nminimizing information leakage to an external wiretapper. The fundamental cache\nmemory vs. transmission rate trade-off for the secure caching problem is\ncharacterized. Rather surprisingly, these results show that security can be\nintroduced at a negligible cost, particularly for large number of files and\nusers. It is also shown that the rate achieved by the proposed caching scheme\nwith secure delivery is within a constant multiplicative factor from the\ninformation-theoretic optimal rate for almost all parameter values of practical\ninterest. \n\n"}
{"id": "1312.4716", "contents": "Title: More Classes of Complete Permutation Polynomials over $\\F_q$ Abstract: In this paper, by using a powerful criterion for permutation polynomials\ngiven by Zieve, we give several classes of complete permutation monomials over\n$\\F_{q^r}$. In addition, we present a class of complete permutation\nmultinomials, which is a generalization of recent work. \n\n"}
{"id": "1312.5486", "contents": "Title: Molecular communication networks with general molecular circuit\n  receivers Abstract: In a molecular communication network, transmitters may encode information in\nconcentration or frequency of signalling molecules. When the signalling\nmolecules reach the receivers, they react, via a set of chemical reactions or a\nmolecular circuit, to produce output molecules. The counts of output molecules\nover time is the output signal of the receiver. The aim of this paper is to\ninvestigate the impact of different reaction types on the information\ntransmission capacity of molecular communication networks. We realise this aim\nby using a general molecular circuit model. We derive general expressions of\nmean receiver output, and signal and noise spectra. We use these expressions to\ninvestigate the information transmission capacities of a number of molecular\ncircuits. \n\n"}
{"id": "1312.6911", "contents": "Title: QoS-Aware User Association for Load Balancing in Heterogeneous Cellular\n  Networks Abstract: To solve the problem that the low capacity in hot-spots and coverage holes of\nconventional cellular networks, the base stations (BSs) having lower transmit\npower are deployed to form heterogeneous cellular networks (HetNets). However,\nbecause of these introduced disparate power BSs, the user distributions among\nthem looked fairly unbalanced if an appropriate user association scheme hasn't\nbeen provided. For effectively tackling this problem, we jointly consider the\nload of each BS and user's achievable rate instead of only utilizing the latter\nwhen designing an association algorithm, and formulate it as a network-wide\nweighted utility maximization problem. Note that, the load mentioned above\nrelates to the amount of required subbands decided by actual rate requirements,\ni.e., QoS, but the number of associated users, thus it can reflect user's\nactual load level. As for the proposed problem, we give a maximum probability\n(max-probability) algorithm by relaxing variables as well as a low-complexity\ndistributed algorithm with a near-optimal solution that provides a theoretical\nperformance guarantee. Experimental results show that, compared with the\nassociation strategy advocated by Ye, our strategy has a speeder convergence\nrate, a lower call blocking probability and a higher load balancing level. \n\n"}
{"id": "1312.7135", "contents": "Title: Multihop Backhaul Compression for the Uplink of Cloud Radio Access\n  Networks Abstract: In cloud radio access networks (C-RANs), the baseband processing of the radio\nunits (RUs) is migrated to remote control units (CUs). This is made possible by\na network of backhaul links that connects RUs and CUs and that carries\ncompressed baseband signals. While prior work has focused mostly on single-hop\nbackhaul networks, this paper investigates efficient backhaul compression\nstrategies for the uplink of C-RANs with a general multihop backhaul topology.\nA baseline multiplex-and-forward (MF) scheme is first studied in which each RU\nforwards the bit streams received from the connected RUs without any\nprocessing. It is observed that this strategy may cause significant performance\ndegradation in the presence of a dense deployment of RUs with a well connected\nbackhaul network. To obviate this problem, a scheme is proposed in which each\nRU decompresses the received bit streams and performs linear in-network\nprocessing of the decompressed signals. For both the MF and the\ndecompress-process-and-recompress (DPR) backhaul schemes, the optimal design is\naddressed with the aim of maximizing the sum-rate under the backhaul capacity\nconstraints. Recognizing the significant demands of the optimal solution of the\nDPR scheme in terms of channel state information (CSI) at the RUs,\ndecentralized optimization algorithms are proposed under the assumption of\nlimited CSI at the RUs. Numerical results are provided to compare the\nperformance of the MF and DPR schemes, highlighting the potential advantage of\nin-network processing and the impact of CSI limitations. \n\n"}
{"id": "1312.7695", "contents": "Title: A discretization-free sparse and parametric approach for linear array\n  signal processing Abstract: Direction of arrival (DOA) estimation in array processing using\nuniform/sparse linear arrays is concerned in this paper. While sparse methods\nvia approximate parameter discretization have been popular in the past decade,\nthe discretization may cause problems, e.g., modeling error and increased\ncomputations due to dense sampling. In this paper, an exact discretization-free\nmethod, named as sparse and parametric approach (SPA), is proposed for uniform\nand sparse linear arrays. SPA carries out parameter estimation in the\ncontinuous range based on well-established covariance fitting criteria and\nconvex optimization. It guarantees to produce a sparse parameter estimate\nwithout discretization required by existing sparse methods. Theoretical\nanalysis shows that the SPA parameter estimator is a large-snapshot realization\nof the maximum likelihood estimator and is statistically consistent (in the\nnumber of snapshots) under uncorrelated sources. Other merits of SPA include\nimproved resolution, applicability to arbitrary number of snapshots, robustness\nto correlation of the sources and no requirement of user-parameters. Numerical\nsimulations are carried out to verify our analysis and demonstrate advantages\nof SPA compared to existing methods. \n\n"}
{"id": "1401.0061", "contents": "Title: On dually flat general $(\\alpha,\\beta)$-metrics Abstract: In this work, the dual flatness, which is connected with Statistics and\nInformation geometry, of general $(\\alpha,\\beta)$-metrics (a new class of\nFinsler metrics) is studied. A nice characterization for such metrics to be\ndually flat under some suitable conditions is provided and all the solutions\nare completely determined. By using an original kind of metrical deformations,\nmany non-trivial explicit examples are constructed. Moreover, the relationship\nof dual flatness and projective flatness of such metrics is shown. \n\n"}
{"id": "1401.1106", "contents": "Title: Structured random measurements in signal processing Abstract: Compressed sensing and its extensions have recently triggered interest in\nrandomized signal acquisition. A key finding is that random measurements\nprovide sparse signal reconstruction guarantees for efficient and stable\nalgorithms with a minimal number of samples. While this was first shown for\n(unstructured) Gaussian random measurement matrices, applications require\ncertain structure of the measurements leading to structured random measurement\nmatrices. Near optimal recovery guarantees for such structured measurements\nhave been developed over the past years in a variety of contexts. This article\nsurveys the theory in three scenarios: compressed sensing (sparse recovery),\nlow rank matrix recovery, and phaseless estimation. The random measurement\nmatrices to be considered include random partial Fourier matrices, partial\nrandom circulant matrices (subsampled convolutions), matrix completion, and\nphase estimation from magnitudes of Fourier type measurements. The article\nconcludes with a brief discussion of the mathematical techniques for the\nanalysis of such structured random measurements. \n\n"}
{"id": "1401.1467", "contents": "Title: The sum $2^{\\mathit{KA}(x)-\\mathit{KP}(x)}$ over all prefixes $x$ of\n  some binary sequence can be infinite Abstract: We consider two quantities that measure complexity of binary strings:\n$\\mathit{KA}(x)$ is defined as the minus logarithm of continuous a priori\nprobability on the binary tree, and $\\mathit{KP}(x)$ denotes prefix complexity\nof a binary string $x$. In this paper we answer a question posed by Joseph\nMiller and prove that there exists an infinite binary sequence $\\omega$ such\nthat the sum of $2^{\\mathit{KA}(x)-\\mathit{KP}(x)}$ over all prefixes $x$ of\n$\\omega$ is infinite. Such a sequence can be chosen among characteristic\nsequences of computably enumerable sets. \n\n"}
{"id": "1401.1711", "contents": "Title: Energy-Efficient Communication over the Unsynchronized Gaussian Diamond\n  Network Abstract: Communication networks are often designed and analyzed assuming tight\nsynchronization among nodes. However, in applications that require\ncommunication in the energy-efficient regime of low signal-to-noise ratios,\nestablishing tight synchronization among nodes in the network can result in a\nsignificant energy overhead. Motivated by a recent result showing that\nnear-optimal energy efficiency can be achieved over the AWGN channel without\nrequiring tight synchronization, we consider the question of whether the\npotential gains of cooperative communication can be achieved in the absence of\nsynchronization. We focus on the symmetric Gaussian diamond network and\nestablish that cooperative-communication gains are indeed feasible even with\nunsynchronized nodes. More precisely, we show that the capacity per unit energy\nof the unsynchronized symmetric Gaussian diamond network is within a constant\nfactor of the capacity per unit energy of the corresponding synchronized\nnetwork. To this end, we propose a distributed relaying scheme that does not\nrequire tight synchronization but nevertheless achieves most of the energy\ngains of coherent combining. \n\n"}
{"id": "1401.2220", "contents": "Title: Analog Network Coding for Multi-User Spread-Spectrum Communication\n  Systems Abstract: This work presents another look at an analog network coding scheme for\nmulti-user spread-spectrum communication systems. Our proposed system combines\ncoding and cooperation between a relay and users to boost the throughput and to\nexploit interference. To this end, each pair of users, $\\mathcal{A}$ and\n$\\mathcal{B}$, that communicate with each other via a relay $\\mathcal{R}$\nshares the same spreading code. The relay has two roles, it synchronizes\nnetwork transmissions and it broadcasts the combined signals received from\nusers. From user $\\mathcal{B}$'s point of view, the signal is decoded, and\nthen, the data transmitted by user $\\mathcal{A}$ is recovered by subtracting\nuser $\\mathcal{B}$'s own data. We derive the analytical performance of this\nsystem for an additive white Gaussian noise channel with the presence of\nmulti-user interference, and we confirm its accuracy by simulation. \n\n"}
{"id": "1401.2228", "contents": "Title: Multistage Compute-and-Forward with Multilevel Lattice Codes Based on\n  Product Constructions Abstract: A novel construction of lattices is proposed. This construction can be\nthought of as Construction A with codes that can be represented as the\nCartesian product of $L$ linear codes over\n$\\mathbb{F}_{p_1},\\ldots,\\mathbb{F}_{p_L}$, respectively; hence, is referred to\nas the product construction. The existence of a sequence of such lattices that\nare good for quantization and Poltyrev-good under multistage decoding is shown.\nThis family of lattices is then used to generate a sequence of nested lattice\ncodes which allows one to achieve the same computation rate of Nazer and\nGastpar for compute-and-forward under multistage decoding, which is referred to\nas lattice-based multistage compute-and-forward.\n  Motivated by the proposed lattice codes, two families of signal\nconstellations are then proposed for the separation-based compute-and-forward\nframework proposed by Tunali \\textit{et al.} together with a multilevel\ncoding/multistage decoding scheme tailored specifically for these\nconstellations. This scheme is termed separation-based multistage\ncompute-and-forward and is shown having a complexity of the channel coding\ndominated by the greatest common divisor of the constellation size (may not be\na prime number) instead of the constellation size itself. \n\n"}
{"id": "1401.3174", "contents": "Title: Comments on \"Optimal Utilization of a Cognitive Shared Channel with a\n  Rechargeable Primary Source Node\" Abstract: In a recent paper [1], the authors investigated the maximum stable throughput\nregion of a network composed of a rechargeable primary user and a secondary\nuser plugged to a reliable power supply. The authors studied the cases of an\ninfinite and a finite energy queue at the primary transmitter. However, the\nresults of the finite case are incorrect. We show that under the proposed\nenergy queue model (a decoupled ${\\rm M/D/1}$ queueing system with Bernoulli\narrivals and the consumption of one energy packet per time slot), the energy\nqueue capacity does not affect the stability region of the network. \n\n"}
{"id": "1401.3682", "contents": "Title: Broadcast Classical-Quantum Capacity Region of Two-Phase Bidirectional\n  Relaying Channel Abstract: We study a three-node quantum network which enables bidirectional\ncommunication between two nodes with a half-duplex relay node. A\ndecode-and-forward protocol is used to perform the communication in two phases.\nIn the first phase, the messages of two nodes are transmitted to the relay\nnode. In the second phase, the relay node broadcasts a re-encoded composition\nto the two nodes. We determine the capacity region of the broadcast phase. \n\n"}
{"id": "1401.3814", "contents": "Title: Information Geometry Approach to Parameter Estimation in Markov Chains Abstract: We consider the parameter estimation of Markov chain when the unknown\ntransition matrix belongs to an exponential family of transition matrices.\nThen, we show that the sample mean of the generator of the exponential family\nis an asymptotically efficient estimator. Further, we also define a curved\nexponential family of transition matrices. Using a transition matrix version of\nthe Pythagorean theorem, we give an asymptotically efficient estimator for a\ncurved exponential family. \n\n"}
{"id": "1401.4126", "contents": "Title: Lower bounds on the communication complexity of two-party (quantum)\n  processes Abstract: The process of state preparation, its transmission and subsequent measurement\ncan be classically simulated through the communication of some amount of\nclassical information. Recently, we proved that the minimal communication cost\nis the minimum of a convex functional over a space of suitable probability\ndistributions. It is now proved that this optimization problem is the dual of a\ngeometric programming maximization problem, which displays some appealing\nproperties. First, the number of variables grows linearly with the input size.\nSecond, the objective function is linear in the input parameters and the\nvariables. Finally, the constraints do not depend on the input parameters.\nThese properties imply that, once a feasible point is found, the computation of\na lower bound on the communication cost in any two-party process is linearly\ncomplex. The studied scenario goes beyond quantum processes and includes the\ncommunication complexity scenario introduced by Yao. We illustrate the method\nby analytically deriving some non-trivial lower bounds. Finally, we conjecture\nthe lower bound $n 2^n$ for a noiseless quantum channel with capacity $n$\nqubits. This bound can have an interesting consequence in the context of the\nrecent quantum-foundational debate on the reality of the quantum state. \n\n"}
{"id": "1401.5742", "contents": "Title: Diffusion-Based Adaptive Distributed Detection: Steady-State Performance\n  in the Slow Adaptation Regime Abstract: This work examines the close interplay between cooperation and adaptation for\ndistributed detection schemes over fully decentralized networks. The combined\nattributes of cooperation and adaptation are necessary to enable networks of\ndetectors to continually learn from streaming data and to continually track\ndrifts in the state of nature when deciding in favor of one hypothesis or\nanother. The results in the paper establish a fundamental scaling law for the\nsteady-state probabilities of miss-detection and false-alarm in the slow\nadaptation regime, when the agents interact with each other according to\ndistributed strategies that employ small constant step-sizes. The latter are\ncritical to enable continuous adaptation and learning. The work establishes\nthree key results. First, it is shown that the output of the collaborative\nprocess at each agent has a steady-state distribution. Second, it is shown that\nthis distribution is asymptotically Gaussian in the slow adaptation regime of\nsmall step-sizes. And third, by carrying out a detailed large deviations\nanalysis, closed-form expressions are derived for the decaying rates of the\nfalse-alarm and miss-detection probabilities. Interesting insights are gained.\nIn particular, it is verified that as the step-size $\\mu$ decreases, the error\nprobabilities are driven to zero exponentially fast as functions of $1/\\mu$,\nand that the error exponents increase linearly in the number of agents. It is\nalso verified that the scaling laws governing errors of detection and errors of\nestimation over networks behave very differently, with the former having an\nexponential decay proportional to $1/\\mu$, while the latter scales linearly\nwith decay proportional to $\\mu$. It is shown that the cooperative strategy\nallows each agent to reach the same detection performance, in terms of\ndetection error exponents, of a centralized stochastic-gradient solution. \n\n"}
{"id": "1401.6039", "contents": "Title: Constant Compositions in the Sphere Packing Bound for Classical-Quantum\n  Channels Abstract: The sphere packing bound, in the form given by Shannon, Gallager and\nBerlekamp, was recently extended to classical-quantum channels, and it was\nshown that this creates a natural setting for combining probabilistic\napproaches with some combinatorial ones such as the Lov\\'asz theta function. In\nthis paper, we extend the study to the case of constant composition codes. We\nfirst extend the sphere packing bound for classical-quantum channels to this\ncase, and we then show that the obtained result is related to a variation of\nthe Lov\\'asz theta function studied by Marton. We then propose a further\nextension to the case of varying channels and codewords with a constant\nconditional composition given a particular sequence. This extension is then\napplied to auxiliary channels to deduce a bound which can be interpreted as an\nextension of the Elias bound. \n\n"}
{"id": "1401.6145", "contents": "Title: On Stochastic Geometry Modeling of Cellular Uplink Transmission with\n  Truncated Channel Inversion Power Control Abstract: Using stochastic geometry, we develop a tractable uplink modeling paradigm\nfor outage probability and spectral efficiency in both single and multi-tier\ncellular wireless networks. The analysis accounts for per user equipment (UE)\npower control as well as the maximum power limitations for UEs. More\nspecifically, for interference mitigation and robust uplink communication, each\nUE is required to control its transmit power such that the average received\nsignal power at its serving base station (BS) is equal to a certain threshold\n$\\rho_o$. Due to the limited transmit power, the UEs employ a truncated channel\ninversion power control policy with a cutoff threshold of $\\rho_o$. We show\nthat there exists a transfer point in the uplink system performance that\ndepends on the tuple: BS intensity ($\\lambda$), maximum transmit power of UEs\n($P_u$), and $\\rho_o$. That is, when $P_u$ is a tight operational constraint\nwith respect to [w.r.t.] $\\lambda$ and $\\rho_o$, the uplink outage probability\nand spectral efficiency highly depend on the values of $\\lambda$ and $\\rho_o$.\nIn this case, there exists an optimal cutoff threshold $\\rho^*_o$, which\ndepends on the system parameters, that minimizes the outage probability. On the\nother hand, when $P_u$ is not a binding operational constraint w.r.t. $\\lambda$\nand $\\rho_o$, the uplink outage probability and spectral efficiency become\nindependent of $\\lambda$ and $\\rho_o$. We obtain approximate yet accurate\nsimple expressions for outage probability and spectral efficiency which reduce\nto closed-forms in some special cases. \n\n"}
{"id": "1401.6354", "contents": "Title: Local Identification of Overcomplete Dictionaries Abstract: This paper presents the first theoretical results showing that stable\nidentification of overcomplete $\\mu$-coherent dictionaries $\\Phi \\in\n\\mathbb{R}^{d\\times K}$ is locally possible from training signals with sparsity\nlevels $S$ up to the order $O(\\mu^{-2})$ and signal to noise ratios up to\n$O(\\sqrt{d})$. In particular the dictionary is recoverable as the local maximum\nof a new maximisation criterion that generalises the K-means criterion. For\nthis maximisation criterion results for asymptotic exact recovery for sparsity\nlevels up to $O(\\mu^{-1})$ and stable recovery for sparsity levels up to\n$O(\\mu^{-2})$ as well as signal to noise ratios up to $O(\\sqrt{d})$ are\nprovided. These asymptotic results translate to finite sample size recovery\nresults with high probability as long as the sample size $N$ scales as $O(K^3dS\n\\tilde \\varepsilon^{-2})$, where the recovery precision $\\tilde \\varepsilon$\ncan go down to the asymptotically achievable precision. Further, to actually\nfind the local maxima of the new criterion, a very simple Iterative\nThresholding and K (signed) Means algorithm (ITKM), which has complexity\n$O(dKN)$ in each iteration, is presented and its local efficiency is\ndemonstrated in several experiments. \n\n"}
{"id": "1401.7074", "contents": "Title: Phase Precoded Compute-and-Forward with Partial Feedback Abstract: In this work, we propose phase precoding for the compute-and-forward (CoF)\nprotocol. We derive the phase precoded computation rate and show that it is\ngreater than the original computation rate of CoF protocol without precoder. To\nmaximize the phase precoded computation rate, we need to 'jointly' find the\noptimum phase precoding matrix and the corresponding network equation\ncoefficients. This is a mixed integer programming problem where the optimum\nprecoders should be obtained at the transmitters and the network equation\ncoefficients have to be computed at the relays. To solve this problem, we\nintroduce phase precoded CoF with partial feedback. It is a quantized precoding\nsystem where the relay jointly computes both a quasi-optimal precoder from a\nfinite codebook and the corresponding network equations. The index of the\nobtained phase precoder within the codebook will then be fedback to the\ntransmitters. A \"deep hole phase precoder\" is presented as an example of such a\nscheme. We further simulate our scheme with a lattice code carved out of the\nGosset lattice and show that significant coding gains can be obtained in terms\nof equation error performance. \n\n"}
{"id": "1401.8022", "contents": "Title: Synchronizing Rankings via Interactive Communication Abstract: We consider the problem of exact synchronization of two rankings at remote\nlocations connected by a two-way channel. Such synchronization problems arise\nwhen items in the data are distinguishable, as is the case for playlists,\ntasklists, crowdvotes and recommender systems rankings. Our model accounts for\ndifferent constraints on the communication throughput of the forward and\nfeedback links, resulting in different anchoring, syndrome and checksum\ncomputation strategies. Information editing is assumed of the form of\ndeletions, insertions, block deletions/insertions, translocations and\ntranspositions. The protocols developed under the given model are order-optimal\nwith respect to genie aided lower bounds. \n\n"}
{"id": "1402.0729", "contents": "Title: Stability and Performance Issues of a Relay Assisted Multiple Access\n  Scheme with MPR Capabilities Abstract: In this work, we study the impact of a relay node to a network with a finite\nnumber of users-sources and a destination node. We assume that the users have\nsaturated queues and the relay node does not have packets of its own; we have\nrandom access of the medium and the time is slotted. The relay node stores a\nsource packet that it receives successfully in its queue when the transmission\nto the destination node has failed. The relay and the destination nodes have\nmulti-packet reception capabilities. We obtain analytical equations for the\ncharacteristics of the relay's queue such as average queue length, stability\nconditions etc. We also study the throughput per user and the aggregate\nthroughput for the network. \n\n"}
{"id": "1402.2011", "contents": "Title: Locality and Availability in Distributed Storage Abstract: This paper studies the problem of code symbol availability: a code symbol is\nsaid to have $(r, t)$-availability if it can be reconstructed from $t$ disjoint\ngroups of other symbols, each of size at most $r$. For example, $3$-replication\nsupports $(1, 2)$-availability as each symbol can be read from its $t= 2$ other\n(disjoint) replicas, i.e., $r=1$. However, the rate of replication must vanish\nlike $\\frac{1}{t+1}$ as the availability increases.\n  This paper shows that it is possible to construct codes that can support a\nscaling number of parallel reads while keeping the rate to be an arbitrarily\nhigh constant. It further shows that this is possible with the minimum distance\narbitrarily close to the Singleton bound. This paper also presents a bound\ndemonstrating a trade-off between minimum distance, availability and locality.\nOur codes match the aforementioned bound and their construction relies on\ncombinatorial objects called resolvable designs.\n  From a practical standpoint, our codes seem useful for distributed storage\napplications involving hot data, i.e., the information which is frequently\naccessed by multiple processes in parallel. \n\n"}
{"id": "1402.3074", "contents": "Title: Scheduling Advantages of Network Coded Storage in Point-to-Multipoint\n  Networks Abstract: We consider scheduling strategies for point-to-multipoint (PMP) storage area\nnetworks (SANs) that use network coded storage (NCS). In particular, we present\na simple SAN system model, two server scheduling algorithms for PMP networks,\nand analytical expressions for internal and external blocking probability. We\npoint to select scheduling advantages in NCS systems under normal operating\nconditions, where content requests can be temporarily denied owing to finite\nsystem capacity from drive I/O access or storage redundancy limitations. NCS\ncan lead to improvements in throughput and blocking probability due to\nincreased immediate scheduling options, and complements other well documented\nNCS advantages such as regeneration, and can be used as a guide for future\nstorage system design. \n\n"}
{"id": "1402.3215", "contents": "Title: Analysis of Compressed Sensing with Spatially-Coupled Orthogonal\n  Matrices Abstract: Recent development in compressed sensing (CS) has revealed that the use of a\nspecial design of measurement matrix, namely the spatially-coupled matrix, can\nachieve the information-theoretic limit of CS. In this paper, we consider the\nmeasurement matrix which consists of the spatially-coupled \\emph{orthogonal}\nmatrices. One example of such matrices are the randomly selected discrete\nFourier transform (DFT) matrices. Such selection enjoys a less memory\ncomplexity and a faster multiplication procedure. Our contributions are the\nreplica calculations to find the mean-square-error (MSE) of the Bayes-optimal\nreconstruction for such setup. We illustrate that the reconstruction thresholds\nunder the spatially-coupled orthogonal and Gaussian ensembles are quite\ndifferent especially in the noisy cases. In particular, the spatially coupled\northogonal matrices achieve the faster convergence rate, the lower measurement\nrate, and the reduced MSE. \n\n"}
{"id": "1402.4746", "contents": "Title: Near-optimal-sample estimators for spherical Gaussian mixtures Abstract: Statistical and machine-learning algorithms are frequently applied to\nhigh-dimensional data. In many of these applications data is scarce, and often\nmuch more costly than computation time. We provide the first sample-efficient\npolynomial-time estimator for high-dimensional spherical Gaussian mixtures.\n  For mixtures of any $k$ $d$-dimensional spherical Gaussians, we derive an\nintuitive spectral-estimator that uses\n$\\mathcal{O}_k\\bigl(\\frac{d\\log^2d}{\\epsilon^4}\\bigr)$ samples and runs in time\n$\\mathcal{O}_{k,\\epsilon}(d^3\\log^5 d)$, both significantly lower than\npreviously known. The constant factor $\\mathcal{O}_k$ is polynomial for sample\ncomplexity and is exponential for the time complexity, again much smaller than\nwhat was previously known. We also show that\n$\\Omega_k\\bigl(\\frac{d}{\\epsilon^2}\\bigr)$ samples are needed for any\nalgorithm. Hence the sample complexity is near-optimal in the number of\ndimensions.\n  We also derive a simple estimator for one-dimensional mixtures that uses\n$\\mathcal{O}\\bigl(\\frac{k \\log \\frac{k}{\\epsilon} }{\\epsilon^2} \\bigr)$ samples\nand runs in time\n$\\widetilde{\\mathcal{O}}\\left(\\bigl(\\frac{k}{\\epsilon}\\bigr)^{3k+1}\\right)$.\nOur other technical contributions include a faster algorithm for choosing a\ndensity estimate from a set of distributions, that minimizes the $\\ell_1$\ndistance to an unknown underlying distribution. \n\n"}
{"id": "1402.4881", "contents": "Title: Fixed Error Asymptotics For Erasure and List Decoding Abstract: We derive the optimum second-order coding rates, known as second-order\ncapacities, for erasure and list decoding. For erasure decoding for discrete\nmemoryless channels, we show that second-order capacity is\n$\\sqrt{V}\\Phi^{-1}(\\epsilon_t)$ where $V$ is the channel dispersion and\n$\\epsilon_t$ is the total error probability, i.e., the sum of the erasure and\nundetected errors. We show numerically that the expected rate at finite\nblocklength for erasures decoding can exceed the finite blocklength channel\ncoding rate. We also show that the analogous result also holds for lossless\nsource coding with decoder side information, i.e., Slepian-Wolf coding. For\nlist decoding, we consider list codes of deterministic size that scales as\n$\\exp(\\sqrt{n}l)$ and show that the second-order capacity is\n$l+\\sqrt{V}\\Phi^{-1}(\\epsilon)$ where $\\epsilon$ is the permissible error\nprobability. We also consider lists of polynomial size $n^\\alpha$ and derive\nbounds on the third-order coding rate in terms of the order of the polynomial\n$\\alpha$. These bounds are tight for symmetric and singular channels. The\ndirect parts of the coding theorems leverage on the simple threshold decoder\nand converses are proved using variants of the hypothesis testing converse. \n\n"}
{"id": "1402.5073", "contents": "Title: Exploiting Two-Dimensional Group Sparsity in 1-Bit Compressive Sensing Abstract: We propose a new approach, {\\it two-dimensional fused binary compressive\nsensing} (2DFBCS) to recover 2D sparse piece-wise signals from 1-bit\nmeasurements, exploiting 2D group sparsity for 1-bit compressive sensing\nrecovery. The proposed method is a modified 2D version of the previous {\\it\nbinary iterative hard thresholding} (2DBIHT) algorithm, where the objective\nfunction includes a 2D one-sided $\\ell_1$ (or $\\ell_2$) penalty function\nencouraging agreement with the observed data, an indicator function of\n$K$-sparsity, and a total variation (TV) or modified TV (MTV) constraint. The\nsubgradient of the 2D one-sided $\\ell_1$ (or $\\ell_2$) penalty and the\nprojection onto the $K$-sparsity and TV or MTV constraint can be computed\nefficiently, allowing the appliaction of algorithms of the {\\it\nforward-backward splitting} (a.k.a. {\\it iterative shrinkage-thresholding})\nfamily. Experiments on the recovery of 2D sparse piece-wise smooth signals show\nthat the proposed approach is able to take advantage of the piece-wise\nsmoothness of the original signal, achieving more accurate recovery than\n2DBIHT. More specifically, 2DFBCS with the MTV and the $\\ell_2$ penalty\nperforms best amongst the algorithms tested. \n\n"}
{"id": "1403.1757", "contents": "Title: Hilberg Exponents: New Measures of Long Memory in the Process Abstract: The paper concerns the rates of power-law growth of mutual information\ncomputed for a stationary measure or for a universal code. The rates are called\nHilberg exponents and four such quantities are defined for each measure and\neach code: two random exponents and two expected exponents. A particularly\ninteresting case arises for conditional algorithmic mutual information. In this\ncase, the random Hilberg exponents are almost surely constant on ergodic\nsources and are bounded by the expected Hilberg exponents. This property is a\n\"second-order\" analogue of the Shannon-McMillan-Breiman theorem, proved without\ninvoking the ergodic theorem. It carries over to Hilberg exponents for the\nunderlying probability measure via Shannon-Fano coding and Barron inequality.\nMoreover, the expected Hilberg exponents can be linked for different universal\ncodes. Namely, if one code dominates another, the expected Hilberg exponents\nare greater for the former than for the latter. The paper is concluded by an\nevaluation of Hilberg exponents for certain sources such as the mixture\nBernoulli process and the Santa Fe processes. \n\n"}
{"id": "1403.4333", "contents": "Title: Increasing Flash Memory Lifetime by Dynamic Voltage Allocation for\n  Constant Mutual Information Abstract: The read channel in Flash memory systems degrades over time because the\nFowler-Nordheim tunneling used to apply charge to the floating gate eventually\ncompromises the integrity of the cell because of tunnel oxide degradation.\nWhile degradation is commonly measured in the number of program/erase cycles\nexperienced by a cell, the degradation is proportional to the number of\nelectrons forced into the floating gate and later released by the erasing\nprocess. By managing the amount of charge written to the floating gate to\nmaintain a constant read-channel mutual information, Flash lifetime can be\nextended. This paper proposes an overall system approach based on information\ntheory to extend the lifetime of a flash memory device. Using the instantaneous\nstorage capacity of a noisy flash memory channel, our approach allocates the\nread voltage of flash cell dynamically as it wears out gradually over time. A\npractical estimation of the instantaneous capacity is also proposed based on\nsoft information via multiple reads of the memory cells. \n\n"}
{"id": "1403.4452", "contents": "Title: The Homogeneous Weight Partition and its Character-Theoretic Dual Abstract: The values of the normalized homogeneous weight are determined for arbitrary\nfinite Frobenius rings and expressed in a form that is independent from a\ngenerating character and the M\\\"obius function on the ring. The weight\nnaturally induces a partition of the ring, which is invariant under left or\nright multiplication by units. It is shown that the character-theoretic\nleft-sided dual of this partition coincides with the right-sided dual, and even\nmore, the left- and right-sided Krawtchouk coefficients coincide. An example is\nprovided showing that this is not the case for general invariant partitions if\nthe ring is not semisimple. \n\n"}
{"id": "1403.6150", "contents": "Title: Optimal Design of Energy-Efficient Multi-User MIMO Systems: Is Massive\n  MIMO the Answer? Abstract: Assume that a multi-user multiple-input multiple-output (MIMO) system is\ndesigned from scratch to uniformly cover a given area with maximal energy\nefficiency (EE). What are the optimal number of antennas, active users, and\ntransmit power? The aim of this paper is to answer this fundamental question.\nWe consider jointly the uplink and downlink with different processing schemes\nat the base station and propose a new realistic power consumption model that\nreveals how the above parameters affect the EE. Closed-form expressions for the\nEE-optimal value of each parameter, when the other two are fixed, are provided\nfor zero-forcing (ZF) processing in single-cell scenarios. These expressions\nprove how the parameters interact. For example, in sharp contrast to common\nbelief, the transmit power is found to increase (not to decrease) with the\nnumber of antennas. This implies that energy-efficient systems can operate in\nhigh signal-to-noise ratio regimes in which interference-suppressing signal\nprocessing is mandatory. Numerical and analytical results show that the maximal\nEE is achieved by a massive MIMO setup wherein hundreds of antennas are\ndeployed to serve a relatively large number of users using ZF processing. The\nnumerical results show the same behavior under imperfect channel state\ninformation and in symmetric multi-cell scenarios. \n\n"}
{"id": "1403.7012", "contents": "Title: On the Degrees of freedom of the K-user MISO Interference Channel with\n  imperfect delayed CSIT Abstract: This work investigates the degrees of freedom (DoF) of the K-user\nmultiple-input single-output (MISO) interference channel (IC) with imperfect\ndelayed channel state information at the transmitters (dCSIT). For this\nsetting, new DoF inner bonds are provided, and benchmarked with\ncooperation-based outer bounds. The achievability result is based on a\nprecoding scheme that aligns the interfering received signals through time,\nexploiting the concept of Retrospective Interference Alignment (RIA). The\nproposed approach outperforms all previous known schemes. Furthermore, we study\nthe proposed scheme under channel estimation errors (CEE) on the reported\ndCSIT, and derive a closed-form expression for the achievable DoF with\nimperfect dCSIT. \n\n"}
{"id": "1403.7802", "contents": "Title: Capacity Analysis of LTE-Advanced HetNets with Reduced Power Subframes\n  and Range Expansion Abstract: The time domain inter-cell interference coordination techniques specified in\nLTE Rel. 10 standard improves the throughput of picocell-edge users by\nprotecting them from macrocell interference. On the other hand, it also\ndegrades the aggregate capacity in macrocell because the macro base station\n(MBS) does not transmit data during certain subframes known as almost blank\nsubframes. The MBS data transmission using reduced power subframes was\nstandardized in LTE Rel. 11, which can improve the capacity in macrocell while\nnot causing high interference to the nearby picocells. In order to get maximum\nbenefit from the reduced power subframes, setting the key system parameters,\nsuch as the amount of power reduction, carries critical importance. Using\nstochastic geometry, this paper lays down a theoretical foundation for the\nperformance evaluation of heterogeneous networks with reduced power subframes\nand range expansion bias. The analytic expressions for average capacity and 5th\npercentile throughput are derived as a function of transmit powers, node\ndensities, and interference coordination parameters in a heterogeneous network\nscenario, and are validated through Monte Carlo simulations. Joint optimization\nof range expansion bias, power reduction factor, scheduling thresholds, and\nduty cycle of reduced power subframes are performed to study the trade-offs\nbetween aggregate capacity of a cell and fairness among the users. To validate\nour analysis, we also compare the stochastic geometry based theoretical results\nwith the real MBS deployment (in the city of London) and the hexagonal-grid\nmodel. Our analysis shows that with optimum parameter settings, the LTE Rel. 11\nwith reduced power subframes can provide substantially better performance than\nthe LTE Rel. 10 with almost blank subframes, in terms of both aggregate\ncapacity and fairness. \n\n"}
{"id": "1404.1443", "contents": "Title: Upper-Bounding the Capacity of Relay Communications - Part II Abstract: This paper focuses on the capacity of peer-to-peer relay communications\nwherein the transmitter are assisted by an arbitrary number of parallel relays,\ni.e. there is no link and cooperation between the relays themselves. We detail\nthe mathematical model of different relaying strategies including cutset and\namplify and forward strategies. The cutset upper bound capacity is presented as\na reference to compare another realistic strategy. We present its outer region\ncapacity which is lower than that in the existing literature. We show that a\nmultiple parallel relayed network achieves its maximum capacity by virtue of\nonly one relay or by virtue of all relays together. Adding a relay may even\ndecrease the overall capacity or may do not change it. We exemplify various\nouter region capacities of the addressed strategies with two different case\nstudies. The results exhibit that in low signal-to-noise ratio (SNR)\nenvironments the cutset outperforms the amplify and forward strategy and this\nis contrary in high SNR environments. \n\n"}
{"id": "1404.1547", "contents": "Title: Asymptotic Behavior of Ultra-Dense Cellular Networks and Its Economic\n  Impact Abstract: This paper investigates the relationship between base station (BS) density\nand average spectral efficiency (SE) in the downlink of a cellular network.\nThis relationship has been well known for sparse deployment, i.e. when the\nnumber of BSs is small compared to the number of users. In this case the SE is\nindependent of BS density. As BS density grows, on the other hand, it has\npreviously been shown that increasing the BS density increases the SE, but no\ntractable form for the SE-BS density relationship has yet been derived. In this\npaper we derive such a closed-form result that reveals the SE is asymptotically\na logarithmic function of BS density as the density grows. Further, we study\nthe impact of this result on the network operator's profit when user demand\nvaries, and derive the profit maximizing BS density and the optimal amount of\nspectrum to be utilized in closed forms. In addition, we provide deployment\nplanning guidelines that will aid the operator in his decision if he should\ninvest in densifying his network or in acquiring more spectrum. \n\n"}
{"id": "1404.2796", "contents": "Title: Linear Batch Codes Abstract: In an application, where a client wants to obtain many elements from a large\ndatabase, it is often desirable to have some load balancing. Batch codes\n(introduced by Ishai et al. in STOC 2004) make it possible to do exactly that:\nthe large database is divided between many servers, so that the client has to\nonly make a small number of queries to every server to obtain sufficient\ninformation to reconstruct all desired elements. Other important parameters of\nthe batch codes are total storage and the number of servers. Batch codes also\nhave applications in cryptography (namely, in the construction of multi-query\ncomputationally-private information retrieval protocols).\n  In this work, we initiate the study of linear batch codes. These codes, in\nparticular, are of potential use in distributed storage systems. We show that a\ngenerator matrix of a binary linear batch code is also a generator matrix of\nclassical binary linear error-correcting code. This immediately yields that a\nvariety of upper bounds, which were developed for error-correcting codes, are\napplicable also to binary linear batch codes. We also propose new methods to\nconstruct large linear batch codes from the smaller ones. \n\n"}
{"id": "1404.3010", "contents": "Title: On the Energy-Spectral Efficiency Trade-off of the MRC Receiver in\n  Massive MIMO Systems with Transceiver Power Consumption Abstract: We consider the uplink of a multiuser massive MIMO system wherein a base\nstation (BS) having $M$ antennas communicates coherently with $K$ single\nantenna user terminals (UTs). We study the energy efficiency of this system\nwhile taking the transceiver power consumption at the UTs and the BS into\nconsideration. For a given spectral efficiency $R$ and fixed transceiver power\nconsumption parameters, we propose and analyze the problem of maximizing the\nenergy efficiency as a function of $(M,K)$. For the maximum ratio combining\n(MRC) detector at the BS we show that with increasing $R$, $(M,K)$ can be\nadaptively increased in such a way that the energy efficiency converges to a\npositive constant as $R \\rightarrow \\infty$ ($(M,K)$ is increased in such a way\nthat a constant per-user spectral efficiency $R/K$ is maintained). This is in\ncontrast to the fixed $(M,K)$ scenario where the energy efficiency is known to\nconverge to zero as $R \\rightarrow \\infty$. We also observe that for large $R$,\nthe optimal $(M,K)$ maximizing the energy efficiency is such that, the total\npower consumed by the power amplifiers (PA) in all the $K$ UTs is a small\nfraction of the total system power consumption. \n\n"}
{"id": "1404.3637", "contents": "Title: A Game-Theoretic Framework for Decentralized Cooperative Data Exchange\n  using Network Coding Abstract: In this paper, we introduce a game theoretic framework for studying the\nproblem of minimizing the delay of instantly decodable network coding (IDNC)\nfor cooperative data exchange (CDE) in decentralized wireless network. In this\nconfiguration, clients cooperate with each other to recover the erased packets\nwithout a central controller. Game theory is employed herein as a tool for\nimproving the distributed solution by overcoming the need for a central\ncontroller or additional signaling in the system. We model the session by\nself-interested players in a non-cooperative potential game. The utility\nfunctions are designed such that increasing individual payoff results in a\ncollective behavior achieving both a desirable system performance in a shared\nnetwork environment and the Nash bargaining solution. Three games are\ndeveloped: the first aims to reduce the completion time, the second to reduce\nthe maximum decoding delay and the third the sum decoding delay. We improve\nthese formulations to include punishment policy upon collision occurrence and\nachieve the Nash bargaining solution. Through extensive simulations, our\nframework is tested against the best performance that could be found in the\nconventional point-to-multipoint (PMP) recovery process in numerous cases:\nfirst we simulate the problem with complete information. We, then, simulate\nwith incomplete information and finally we test it in lossy feedback scenario.\nNumerical results show that our formulation with complete information largely\noutperforms the conventional PMP scheme in most situations and achieves a lower\ndelay. They also show that the completion time formulation with incomplete\ninformation also outperforms the conventional PMP. \n\n"}
{"id": "1404.3881", "contents": "Title: Collision Tolerant Packet Scheduling for Underwater Acoustic\n  Localization Abstract: This article considers the joint problem of packet scheduling and\nself-localization in an underwater acoustic sensor network where sensor nodes\nare distributed randomly in an operating area. In terms of packet scheduling,\nour goal is to minimize the localization time, and to do so we consider two\npacket transmission schemes, namely a collision-free scheme (CFS), and a\ncollision-tolerant scheme (CTS). The required localization time is formulated\nfor these schemes, and through analytical results and numerical examples their\nperformances are shown to be generally comparable. However, when the packet\nduration is short (as is the case for a localization packet), and the operating\narea is large (above 3km in at least one dimension), the collision-tolerant\nscheme requires a smaller localization time than the collision-free scheme.\nAfter gathering enough measurements, an iterative Gauss-Newton algorithm is\nemployed by each sensor node for self-localization, and the Cramer Rao lower\nbound is evaluated as a benchmark. Although CTS consumes more energy for packet\ntransmission, it provides a better localization accuracy. Additionally, in this\nscheme the anchor nodes work independently of each other, and can operate\nasynchronously which leads to a simplified implementation. \n\n"}
{"id": "1404.5012", "contents": "Title: On the MacWilliams Identity for Classical and Quantum Convolutional\n  Codes Abstract: The weight generating functions associated with convolutional codes (CCs) are\nbased on state space realizations or the weight adjacency matrices (WAMs). The\nMacWilliams identity for CCs on the WAMs was first established by Gluesing-\nLuerssen and Schneider in the case of minimal encoders, and generalized by\nForney. We consider this problem in the viewpoint of constraint codes and\nobtain a simple and direct proof of this MacWilliams identity in the case of\nminimal encoders. For our purpose, we choose a different representation for the\nexact weight generating function (EWGF) of a block code, by defining it as a\nlinear combination of orthonormal vectors in Dirac bra-ket notation. This\nrepresentation provides great flexibility so that general split weight\ngenerating functions and their MacWilliams identities can be easily obtained\nfrom the MacWilliams identity for EWGFs. As a result, we also obtain the\nMacWilliams identity for the input-parity weight adjacency matrices of a\nsystematic convolutional code and its dual. Finally, paralleling the\ndevelopment of the classical case, we establish the MacWilliams identity for\nquantum convolutional codes. \n\n"}
{"id": "1404.5940", "contents": "Title: A strong converse for the quantum state merging protocol Abstract: The Polyanskiy-Verd\\'{u} paradigm provides an elegant way of using\ngeneralized-divergences to obtain strong converses and thus far has remained\nconfined to protocols involving channels (classical or quantum). In this paper,\ndrawing inspirations from it, we provide strong converses for protocols\ninvolving LOCC (local operations and classical communication). The key quantity\nthat we work with is the R\\'{e}nyi relative entropy of entanglement. We provide\na strong converse for the quantum state merging protocol that gives an\nexponential decay of the fidelity of the protocol for rates below the optimum\nwith the number of copies of the state and are provided both for entanglement\nrate with LOCC as well as for classical communication with one-way LOCC. As an\naside, the developments also yield short strong converses for the\nentanglement-concentration of pure states and the Schumacher compression. \n\n"}
{"id": "1404.6000", "contents": "Title: Robust and computationally feasible community detection in the presence\n  of arbitrary outlier nodes Abstract: Community detection, which aims to cluster $N$ nodes in a given graph into\n$r$ distinct groups based on the observed undirected edges, is an important\nproblem in network data analysis. In this paper, the popular stochastic block\nmodel (SBM) is extended to the generalized stochastic block model (GSBM) that\nallows for adversarial outlier nodes, which are connected with the other nodes\nin the graph in an arbitrary way. Under this model, we introduce a procedure\nusing convex optimization followed by $k$-means algorithm with $k=r$. Both\ntheoretical and numerical properties of the method are analyzed. A theoretical\nguarantee is given for the procedure to accurately detect the communities with\nsmall misclassification rate under the setting where the number of clusters can\ngrow with $N$. This theoretical result admits to the best-known result in the\nliterature of computationally feasible community detection in SBM without\noutliers. Numerical results show that our method is both computationally fast\nand robust to different kinds of outliers, while some popular computationally\nfast community detection algorithms, such as spectral clustering applied to\nadjacency matrices or graph Laplacians, may fail to retrieve the major clusters\ndue to a small portion of outliers. We apply a slight modification of our\nmethod to a political blogs data set, showing that our method is competent in\npractice and comparable to existing computationally feasible methods in the\nliterature. To the best of the authors' knowledge, our result is the first in\nthe literature in terms of clustering communities with fast growing numbers\nunder the GSBM where a portion of arbitrary outlier nodes exist. \n\n"}
{"id": "1404.6320", "contents": "Title: Demystifying the Scaling Laws of Dense Wireless Networks: No Linear\n  Scaling in Practice Abstract: We optimize the hierarchical cooperation protocol of Ozgur, Leveque and Tse,\nwhich is supposed to yield almost linear scaling of the capacity of a dense\nwireless network with the number of users $n$. Exploiting recent results on the\noptimality of \"treating interference as noise\" in Gaussian interference\nchannels, we are able to optimize the achievable average per-link rate and not\njust its scaling law. Our optimized hierarchical cooperation protocol\nsignificantly outperforms the originally proposed scheme. On the negative side,\nwe show that even for very large $n$, the rate scaling is far from linear, and\nthe optimal number of stages $t$ is less than 4, instead of $t \\rightarrow\n\\infty$ as required for almost linear scaling. Combining our results and the\nfact that, beyond a certain user density, the network capacity is fundamentally\nlimited by Maxwell laws, as shown by Francheschetti, Migliore and Minero, we\nargue that there is indeed no intermediate regime of linear scaling for dense\nnetworks in practice. \n\n"}
{"id": "1404.6512", "contents": "Title: Cellular Interference Alignment: Omni-Directional Antennas and\n  Asymmetric Configurations Abstract: Although interference alignment (IA) can theoretically achieve the optimal\ndegrees of freedom (DoFs) in the $K$-user Gaussian interference channel, its\ndirect application comes at the prohibitive cost of precoding over\nexponentially-many signaling dimensions. On the other hand, it is known that\npractical \"one-shot\" IA precoding (i.e., linear schemes without symbol\nexpansion) provides a vanishing DoFs gain in large fully-connected networks\nwith generic channel coefficients. In our previous work, we introduced the\nconcept of \"Cellular IA\" for a network topology induced by hexagonal cells with\nsectors and nearest-neighbor interference. Assuming that neighboring sectors\ncan exchange decoded messages (and not received signal samples) in the uplink,\nwe showed that linear one-shot IA precoding over $M$ transmit/receive antennas\ncan achieve the optimal $M/2$ DoFs per user. In this paper we extend this\nframework to networks with omni-directional (non-sectorized) cells and consider\nthe practical scenario where users have $2$ antennas, and base-stations have\n$2$, $3$ or $4$ antennas. In particular, we provide linear one-shot IA schemes\nfor the $2\\times 2$, $2\\times3$ and $2\\times 4$ cases, and show the\nachievability of $3/4$, $1$ and $7/6$ DoFs per user, respectively. DoFs\nconverses for one-shot schemes require the solution of a discrete optimization\nproblem over a number of variables that grows with the network size. We develop\na new approach to transform such challenging optimization problem into a\ntractable linear program (LP) with significantly fewer variables. This approach\nis used to show that the achievable $3/4$ DoFs per user are indeed optimal for\na large (extended) cellular network with $2\\times 2$ links. \n\n"}
{"id": "1404.7374", "contents": "Title: Explicit and almost sure conditions for K/2 degrees of freedom Abstract: It is well known that in K-user constant single-antenna interference channels\nK/2 degrees of freedom (DoF) can be achieved for almost all channel matrices.\nExplicit conditions on the channel matrix to admit K/2 DoF are, however, not\navailable. The purpose of this paper is to identify such explicit conditions,\nwhich are satisfied for almost all channel matrices. We also provide a\nconstruction of corresponding asymptotically DoF-optimal input distributions.\nThe main technical tool used is a recent breakthrough result by Hochman in\nfractal geometry. \n\n"}
{"id": "1404.7736", "contents": "Title: Massive MIMO with 1-bit ADC Abstract: We investigate massive multiple-input-multiple output (MIMO) uplink systems\nwith 1-bit analog-to-digital converters (ADCs) on each receiver antenna.\nReceivers that rely on 1-bit ADC do not need energy-consuming interfaces such\nas automatic gain control (AGC). This decreases both ADC building and\noperational costs. Our design is based on maximal ratio combining (MRC),\nzero-forcing (ZF), and least squares (LS) detection, taking into account the\neffects of the 1-bit ADC on channel estimation. Through numerical results, we\nshow good performance of the system in terms of mutual information and symbol\nerror rate (SER). Furthermore, we provide an analytical approach to calculate\nthe mutual information and SER of the MRC receiver. The analytical approach\nreduces complexity in the sense that a symbol and channel noise vectors Monte\nCarlo simulation is avoided. \n\n"}
{"id": "1405.0521", "contents": "Title: Blind MIMOME Wiretap Channel with Delayed CSIT Abstract: We study the Gaussian MIMOME wiretap channel where a transmitter wishes to\ncommunicate a confidential message to a legitimate receiver in the presence of\neavesdroppers, while the eavesdroppers should not be able to decode the\nconfidential message. Each node in the network is equipped with arbitrary\nnumber of antennas. Furthermore, channels are time varying, and there is no\nchannel state information available at the transmitter (CSIT) with respect to\neavesdroppers' channels; and transmitter only has access to delayed CSIT of the\nchannel to the legitimate receiver. The secure degrees of freedom (SDoF) for\nsuch network has only been characterized for special cases, and is unknown in\ngeneral. We completely characterize the SDoF of this network for all antenna\nconfigurations. In particular, we strictly improve the state-of-the-art\nachievable scheme for this network by proposing more efficient artificial noise\nalignment at the receivers. Furthermore, we develop a tight upper bound by\nutilizing 4 important inequalities that provide lower bounds on the received\nsignal dimensions at receivers which supply delayed CSIT or no CSIT, or at a\ncollection of receivers where some supply no CSIT. These inequalities together\nallow for analysis of signal dimensions in networks with asymmetric CSIT; and\nas a result, we present a converse proof that leads to characterization of SDoF\nfor all possible antenna configurations. \n\n"}
{"id": "1405.0894", "contents": "Title: Interactive Function Computation via Polar Coding Abstract: In a series of papers N. Ma and P. Ishwar (2011-13) considered a range of\ndistributed source coding problems that arise in the context of iterative\ncomputation of functions, characterizing the region of achievable communication\nrates. We consider the problems of interactive computation of functions by two\nterminals and interactive computation in a collocated network, showing that the\nrate regions for both these problems can be achieved using several rounds of\npolar-coded transmissions. \n\n"}
{"id": "1405.1665", "contents": "Title: On Communication Cost of Distributed Statistical Estimation and\n  Dimensionality Abstract: We explore the connection between dimensionality and communication cost in\ndistributed learning problems. Specifically we study the problem of estimating\nthe mean $\\vec{\\theta}$ of an unknown $d$ dimensional gaussian distribution in\nthe distributed setting. In this problem, the samples from the unknown\ndistribution are distributed among $m$ different machines. The goal is to\nestimate the mean $\\vec{\\theta}$ at the optimal minimax rate while\ncommunicating as few bits as possible. We show that in this setting, the\ncommunication cost scales linearly in the number of dimensions i.e. one needs\nto deal with different dimensions individually. Applying this result to\nprevious lower bounds for one dimension in the interactive setting\n\\cite{ZDJW13} and to our improved bounds for the simultaneous setting, we prove\nnew lower bounds of $\\Omega(md/\\log(m))$ and $\\Omega(md)$ for the bits of\ncommunication needed to achieve the minimax squared loss, in the interactive\nand simultaneous settings respectively. To complement, we also demonstrate an\ninteractive protocol achieving the minimax squared loss with $O(md)$ bits of\ncommunication, which improves upon the simple simultaneous protocol by a\nlogarithmic factor. Given the strong lower bounds in the general setting, we\ninitiate the study of the distributed parameter estimation problems with\nstructured parameters. Specifically, when the parameter is promised to be\n$s$-sparse, we show a simple thresholding based protocol that achieves the same\nsquared loss while saving a $d/s$ factor of communication. We conjecture that\nthe tradeoff between communication and squared loss demonstrated by this\nprotocol is essentially optimal up to logarithmic factor. \n\n"}
{"id": "1405.1782", "contents": "Title: When are dynamic relaying strategies necessary in half-duplex wireless\n  networks? Abstract: We study a simple question: when are dynamic relaying strategies essential in\noptimizing the diversity-multiplexing tradeoff (DMT) in half-duplex wireless\nrelay networks? This is motivated by apparently two contrasting results even\nfor a simple 3 node network, with a single half-duplex relay. When all channels\nare assumed to be i.i.d. fading, a static schedule where the relay listens half\nthe time and transmits half the time combined with quantize-map-forward (QMF)\nrelaying is known to achieve the full-duplex performance. However, when there\nis no direct link between source and destination, a dynamic-decode-forward\n(DDF) strategy is needed to achieve the optimal tradeoff. In this case, a\nstatic schedule is strictly suboptimal and the optimal tradeoff is\nsignificantly worse than the full-duplex performance. In this paper we study\nthe general case when the direct link is neither as strong as the other links\nnor fully non-existent, and identify regimes where dynamic schedules are\nnecessary and those where static schedules are enough. We identify 4\nqualitatively different regimes for the single relay channel where the tradeoff\nbetween diversity and multiplexing is significantly different. We show that in\nall these regimes one of the above two strategies is sufficient to achieve the\noptimal tradeoff by developing a new upper bound on the best achievable\ntradeoff under channel state information available only at the receivers. A\nnatural next question is whether these two strategies are sufficient to achieve\nthe DMT of more general half-duplex wireless networks. We propose a\ngeneralization of the two existing schemes through a dynamic QMF (DQMF)\nstrategy, where the relay listens for a fraction of time depending on received\nCSI but not long enough to be able to decode. We show that such a DQMF strategy\nis needed to achieve the optimal DMT in a parallel channel with two relays. \n\n"}
{"id": "1405.2562", "contents": "Title: $\\alpha$-divergence derived as the generalized rate function in a\n  power-law system Abstract: The generalized binomial distribution in Tsallis statistics (power-law\nsystem) is explicitly formulated from the precise $q$-Stirling's formula. The\n$\\alpha $-divergence (or $q$-divergence) is uniquely derived from the\ngeneralized binomial distribution in the sense that when $\\alpha\\rightarrow-1$\n(i.e., $q\\rightarrow1$) it recovers KL divergence obtained from the standard\nbinomial distribution. Based on these combinatorial considerations, it is shown\nthat $\\alpha$-divergence (or $q$-divergence) is appeared as the generalized\nrate function in the large deviation estimate in Tsallis statistics. \n\n"}
{"id": "1405.2820", "contents": "Title: A weight-distribution bound for entropy extractors using linear binary\n  codes Abstract: We consider a bound on the bias reduction of a random number generator by\nprocessing based on binary linear codes. We introduce a new bound on the total\nvariation distance of the processed output based on the weight distribution of\nthe code generated by the chosen binary matrix. Starting from this result we\nshow a lower bound for the entropy rate of the output of linear binary\nextractors. \n\n"}
{"id": "1405.2984", "contents": "Title: Multicell Coordinated Beamforming with Rate Outage Constraint--Part II:\n  Efficient Approximation Algorithms Abstract: This paper studies the coordinated beamforming (CoBF) design for the\nmultiple-input single-output interference channel, provided that only channel\ndistribution information is known to the transmitters. The problem under\nconsideration is a probabilistically constrained optimization problem which\nmaximizes a predefined system utility subject to constraints on rate outage\nprobability and power budget of each transmitter. Our recent analysis has shown\nthat the outage-constrained CoBF problem is intricately difficult, e.g.,\nNP-hard. Therefore, the focus of this paper is on suboptimal but\ncomputationally efficient algorithms. Specifically, by leveraging on the block\nsuccessive upper bound minimization (BSUM) method in optimization, we propose a\nGauss-Seidel type algorithm, called distributed BSUM algorithm, which can\nhandle differentiable, monotone and concave system utilities. By exploiting a\nweighted minimum mean-square error (WMMSE) reformulation, we further propose a\nJocobi-type algorithm, called distributed WMMSE algorithm, which can optimize\nthe weighted sum rate utility in a fully parallel manner. To provide a\nperformance benchmark, a relaxed approximation method based on polyblock outer\napproximation is also proposed. Simulation results show that the proposed\nalgorithms are significantly superior to the existing successive convex\napproximation method in both performance and computational efficiency, and can\nyield promising approximation performance. \n\n"}
{"id": "1405.4623", "contents": "Title: Training-Based SWIPT: Optimal Power Splitting at the Receiver Abstract: We consider a point-to-point system with simultaneous wireless information\nand power transfer (SWIPT) over a block fading channel. Each transmission block\nconsists of a training phase and a data transmission phase. Pilot symbols are\ntransmitted during the training phase for channel estimation at the receiver.\nTo enable SWIPT, the receiver adopts a power-splitting design, such that a\nportion of the received signal is used for channel estimation or data\ndetection, while the remaining is used for energy harvesting. We optimally\ndesign the power-splitting ratios for both training and data phases to achieve\nthe best ergodic capacity performance while maintaining a required energy\nharvesting rate. Our result shows how a power-splitting receiver can make the\nbest use of the received pilot and data signals to obtain the optimal SWIPT\nperformance. \n\n"}
{"id": "1405.5618", "contents": "Title: Compressive Phase Retrieval via Generalized Approximate Message Passing Abstract: In phase retrieval, the goal is to recover a signal\n$\\mathbf{x}\\in\\mathbb{C}^N$ from the magnitudes of linear measurements\n$\\mathbf{Ax}\\in\\mathbb{C}^M$. While recent theory has established that\n$M\\approx 4N$ intensity measurements are necessary and sufficient to recover\ngeneric $\\mathbf{x}$, there is great interest in reducing the number of\nmeasurements through the exploitation of sparse $\\mathbf{x}$, which is known as\ncompressive phase retrieval. In this work, we detail a novel, probabilistic\napproach to compressive phase retrieval based on the generalized approximate\nmessage passing (GAMP) algorithm. We then present a numerical study of the\nproposed PR-GAMP algorithm, demonstrating its excellent phase-transition\nbehavior, robustness to noise, and runtime. Our experiments suggest that\napproximately $M\\geq 2K\\log_2(N/K)$ intensity measurements suffice to recover\n$K$-sparse Bernoulli-Gaussian signals for $\\mathbf{A}$ with i.i.d Gaussian\nentries and $K\\ll N$. Meanwhile, when recovering a 6k-sparse 65k-pixel\ngrayscale image from 32k randomly masked and blurred Fourier intensity\nmeasurements at 30~dB measurement SNR, PR-GAMP achieved an output SNR of no\nless than 28~dB in all of 100 random trials, with a median runtime of only 7.3\nseconds. Compared to the recently proposed CPRL, sparse-Fienup, and GESPAR\nalgorithms, our experiments suggest that PR-GAMP has a superior phase\ntransition and orders-of-magnitude faster runtimes as the sparsity and problem\ndimensions increase. \n\n"}
{"id": "1405.5974", "contents": "Title: Living on the Edge: The Role of Proactive Caching in 5G Wireless\n  Networks Abstract: This article explores one of the key enablers of beyond $4$G wireless\nnetworks leveraging small cell network deployments, namely proactive caching.\nEndowed with predictive capabilities and harnessing recent developments in\nstorage, context-awareness and social networks, peak traffic demands can be\nsubstantially reduced by proactively serving predictable user demands, via\ncaching at base stations and users' devices. In order to show the effectiveness\nof proactive caching, we examine two case studies which exploit the spatial and\nsocial structure of the network, where proactive caching plays a crucial role.\nFirstly, in order to alleviate backhaul congestion, we propose a mechanism\nwhereby files are proactively cached during off-peak demands based on file\npopularity and correlations among users and files patterns. Secondly,\nleveraging social networks and device-to-device (D2D) communications, we\npropose a procedure that exploits the social structure of the network by\npredicting the set of influential users to (proactively) cache strategic\ncontents and disseminate them to their social ties via D2D communications.\nExploiting this proactive caching paradigm, numerical results show that\nimportant gains can be obtained for each case study, with backhaul savings and\na higher ratio of satisfied users of up to $22\\%$ and $26\\%$, respectively.\nHigher gains can be further obtained by increasing the storage capability at\nthe network edge. \n\n"}
{"id": "1405.7147", "contents": "Title: New extremal binary self-dual codes from F_4 + uF_4-lifts of quadratic\n  double circulant codes over F_4 Abstract: In this work, quadratic double and quadratic bordered double circulant\nconstructions are applied to F_4 + uF_4 as well as F_4, as a result of which\nextremal binary self-dual codes of length 56 and 64 are obtained. The binary\nextension theorems as well as the ring extension version are used to obtain 7\nextremal self-dual binary codes of length 58, 24 extremal self-dual binary\ncodes of length 66 and 29 extremal self-dual binary codes of length 68, all\nwith new weight enumerators, updating the list of all the known extremal\nself-dual codes in the literature. \n\n"}
{"id": "1406.1055", "contents": "Title: Lattice Codes for the Binary Deletion Channel Abstract: The construction of deletion codes for the Levenshtein metric is reduced to\nthe construction of codes over the integers for the Manhattan metric by run\nlength coding. The latter codes are constructed by expurgation of translates of\nlattices. These lattices, in turn, are obtained from Construction~A applied to\nbinary codes and $\\Z_4-$codes. A lower bound on the size of our codes for the\nManhattan distance are obtained through generalized theta series of the\ncorresponding lattices. \n\n"}
{"id": "1406.2255", "contents": "Title: Energy-Efficient Cooperative Cognitive Relaying Schemes for Cognitive\n  Radio Networks Abstract: We investigate a cognitive radio network in which a primary user (PU) may\ncooperate with a cognitive radio user (i.e., a secondary user (SU)) for\ntransmissions of its data packets. The PU is assumed to be a buffered node\noperating in a time-slotted fashion where the time is partitioned into\nequal-length slots. We develop two schemes which involve cooperation between\nprimary and secondary users. To satisfy certain quality of service (QoS)\nrequirements, users share time slot duration and channel frequency bandwidth.\nMoreover, the SU may leverage the primary feedback message to further increase\nboth its data rate and satisfy the PU QoS requirements. The proposed\ncooperative schemes are designed such that the SU data rate is maximized under\nthe constraint that the PU average queueing delay is maintained less than the\naverage queueing delay in case of non-cooperative PU. In addition, the proposed\nschemes guarantee the stability of the PU queue and maintain the average energy\nemitted by the SU below a certain value. The proposed schemes also provide more\nrobust and potentially continuous service for SUs compared to the conventional\npractice in cognitive networks where SUs transmit in the spectrum holes and\nsilence sessions of the PUs. We include primary source burstiness, sensing\nerrors, and feedback decoding errors to the analysis of our proposed\ncooperative schemes. The optimization problems are solved offline and require a\nsimple 2-dimensional grid-based search over the optimization variables.\nNumerical results show the beneficial gains of the cooperative schemes in terms\nof SU data rate and PU throughput, average PU queueing delay, and average PU\nenergy savings. \n\n"}
{"id": "1406.2738", "contents": "Title: Wireless Backhaul Networks: Capacity Bound, Scalability Analysis and\n  Design Guidelines Abstract: This paper studies the scalability of a wireless backhaul network modeled as\na random extended network with multi-antenna base stations (BSs), where the\nnumber of antennas per BS is allowed to scale as a function of the network\nsize. The antenna scaling is justified by the current trend towards the use of\nhigher carrier frequencies, which allows to pack large number of antennas in\nsmall form factors. The main goal is to study the per-BS antenna requirement\nthat ensures scalability of this network, i.e., its ability to deliver\nnon-vanishing rate to each source-destination pair. We first derive an\ninformation theoretic upper bound on the capacity of this network under a\ngeneral propagation model, which provides a lower bound on the per-BS antenna\nrequirement. Then, we characterize the scalability requirements for two\ncompeting strategies of interest: (i) long hop: each source-destination pair\nminimizes the number of hops by sacrificing multiplexing gain while achieving\nfull beamforming (power) gain over each hop, and (ii) short hop: each\nsource-destination pair communicates through a series of short hops, each\nachieving full multiplexing gain. While long hop may seem more intuitive in the\ncontext of massive multiple-input multiple-output (MIMO) transmission, we show\nthat the short hop strategy is significantly more efficient in terms of per-BS\nantenna requirement for throughput scalability. As a part of the proof, we\nconstruct a scalable short hop strategy and show that it does not violate any\nfundamental limits on the spatial degrees of freedom (DoFs). \n\n"}
{"id": "1406.4775", "contents": "Title: Non-negative Principal Component Analysis: Message Passing Algorithms\n  and Sharp Asymptotics Abstract: Principal component analysis (PCA) aims at estimating the direction of\nmaximal variability of a high-dimensional dataset. A natural question is: does\nthis task become easier, and estimation more accurate, when we exploit\nadditional knowledge on the principal vector? We study the case in which the\nprincipal vector is known to lie in the positive orthant. Similar constraints\narise in a number of applications, ranging from analysis of gene expression\ndata to spike sorting in neural signal processing.\n  In the unconstrained case, the estimation performances of PCA has been\nprecisely characterized using random matrix theory, under a statistical model\nknown as the `spiked model.' It is known that the estimation error undergoes a\nphase transition as the signal-to-noise ratio crosses a certain threshold.\nUnfortunately, tools from random matrix theory have no bearing on the\nconstrained problem. Despite this challenge, we develop an analogous\ncharacterization in the constrained case, within a one-spike model.\n  In particular: $(i)$~We prove that the estimation error undergoes a similar\nphase transition, albeit at a different threshold in signal-to-noise ratio that\nwe determine exactly; $(ii)$~We prove that --unlike in the unconstrained case--\nestimation error depends on the spike vector, and characterize the least\nfavorable vectors; $(iii)$~We show that a non-negative principal component can\nbe approximately computed --under the spiked model-- in nearly linear time.\nThis despite the fact that the problem is non-convex and, in general, NP-hard\nto solve exactly. \n\n"}
{"id": "1406.4928", "contents": "Title: Diversity Multiplexing Tradeoff of the Half-duplex Slow Fading Multiple\n  Access Channel based on Generalized Quantize-and-Forward Scheme Abstract: This paper investigates the Diversity Multiplexing Tradeoff (DMT) of the\ngeneralized quantize-and-forward (GQF) relaying scheme over the slow fading\nhalf-duplex multiple-access relay channel (HD-MARC). The compress-and-forward\n(CF) scheme has been shown to achieve the optimal DMT when the channel state\ninformation (CSI) of the relay-destination link is available at the relay.\nHowever, having the CSI of relay-destination link at relay is not always\npossible due to the practical considerations of the wireless system. In\ncontrast, in this work, the DMT of the GQF scheme is derived without\nrelay-destination link CSI at the relay. It is shown that even without\nknowledge of relay-destination CSI, the GQF scheme achieves the same DMT,\nachievable by CF scheme with full knowledge of CSI. \n\n"}
{"id": "1406.5582", "contents": "Title: Optimal Offline Packet Scheduling in Energy Harvesting 2-user Multiple\n  Access Channel with Common Data Abstract: The lifetime and the sustainability of the wireless sensor networks (WSNs)\ncan be increased with energy harvesting transmitters utilizing optimum packet\nscheduling. On the other hand, WSNs are observed to collect spatially or\ntemporally correlated data which should be taken into account for the optimum\npacket scheduling in an energy harvesting system. However, the solutions\navailable for 2-user multiple-access channel (MAC) systems with energy\nharvesting transmitters do not consider the common data or the correlation\namong the data. In this paper, optimal packet scheduling for energy harvesting\n2-user Gaussian MAC with common data is achieved by assuming deterministic\nknowledge of the data and energy packets, i.e., offline solution. The optimum\ndeparture region is found by using Karush- Kuhn-Tucker (KKT) conditions\ngeneralizing the solutions obtained for the MAC without common data. An\nefficient iterative backward water-filling algorithm is defined. The optimum\nsolution is numerically compared with the case of no scheduling, uniform power\nscheduling and the previous solutions defined for the MAC without common data\nby showing the improvement obtained with the optimization. \n\n"}
{"id": "1406.6321", "contents": "Title: Power-Optimal Feedback-Based Random Spectrum Access for an Energy\n  Harvesting Cognitive User Abstract: In this paper, we study and analyze cognitive radio networks in which\nsecondary users (SUs) are equipped with Energy Harvesting (EH) capability. We\ndesign a random spectrum sensing and access protocol for the SU that exploits\nthe primary link's feedback and requires less average sensing time. Unlike\nprevious works proposed earlier in literature, we do not assume perfect\nfeedback. Instead, we take into account the more practical possibilities of\noverhearing unreliable feedback signals and accommodate spectrum sensing\nerrors. Moreover, we assume an interference-based channel model where the\nreceivers are equipped with multi-packet reception (MPR) capability.\nFurthermore, we perform power allocation at the SU with the objective of\nmaximizing the secondary throughput under constraints that maintain certain\nquality-of-service (QoS) measures for the primary user (PU). \n\n"}
{"id": "1406.6514", "contents": "Title: SURE Information Criteria for Large Covariance Matrix Estimation and\n  Their Asymptotic Properties Abstract: Consider $n$ independent and identically distributed $p$-dimensional Gaussian\nrandom vectors with covariance matrix $\\Sigma.$ The problem of estimating\n$\\Sigma$ when $p$ is much larger than $n$ has received a lot of attention in\nrecent years. Yet little is known about the information criterion for\ncovariance matrix estimation. How to properly define such a criterion and what\nare the statistical properties? We attempt to answer these questions in the\npresent paper by focusing on the estimation of bandable covariance matrices\nwhen $p>n$ but $\\log(p)=o(n)$. Motivated by the deep connection between Stein's\nunbiased risk estimation (SURE) and AIC in regression models, we propose a\nfamily of generalized SURE ($\\text{SURE}_c$) indexed by $c$ for covariance\nmatrix estimation, where $c$ is some constant. When $c$ is 2, $\\text{SURE}_2$\nprovides an unbiased estimator of the Frobenious risk of the covariance matrix\nestimator. Furthermore, we show that by minimizing $\\text{SURE}_2$ over all\npossible banding covariance matrix estimators we attain the minimax optimal\nrate of convergence and the resulting estimator behaves like the covariance\nmatrix estimator obtained by the so-called oracle tuning. On the other hand, we\nalso show that $\\text{SURE}_2$ is selection inconsistent when the true\ncovariance matrix is exactly banded. To fix the selection inconsistency, we\nconsider using SURE with $c=\\log(n)$ and prove that by minimizing\n$\\text{SURE}_{\\log(n)}$ we select the true bandwith with probability tending to\none. Therefore, our analysis indicates that $\\text{SURE}_2$ and\n$\\text{SURE}_{\\log(n)}$ can be regarded as the AIC and BIC for large covariance\nmatrix estimation, respectively. \n\n"}
{"id": "1406.7264", "contents": "Title: Repairable Block Failure Resilient Codes Abstract: In large scale distributed storage systems (DSS) deployed in cloud computing,\ncorrelated failures resulting in simultaneous failure (or, unavailability) of\nblocks of nodes are common. In such scenarios, the stored data or a content of\na failed node can only be reconstructed from the available live nodes belonging\nto available blocks. To analyze the resilience of the system against such block\nfailures, this work introduces the framework of Block Failure Resilient (BFR)\ncodes, wherein the data (e.g., file in DSS) can be decoded by reading out from\na same number of codeword symbols (nodes) from each available blocks of the\nunderlying codeword. Further, repairable BFR codes are introduced, wherein any\ncodeword symbol in a failed block can be repaired by contacting to remaining\nblocks in the system. Motivated from regenerating codes, file size bounds for\nrepairable BFR codes are derived, trade-off between per node storage and repair\nbandwidth is analyzed, and BFR-MSR and BFR-MBR points are derived. Explicit\ncodes achieving these two operating points for a wide set of parameters are\nconstructed by utilizing combinatorial designs, wherein the codewords of the\nunderlying outer codes are distributed to BFR codeword symbols according to\nprojective planes. \n\n"}
{"id": "1407.1424", "contents": "Title: Cross Layer Provision of Future Cellular Networks Abstract: To cope with the growing demand for wireless data and to extend service\ncoverage, future 5G networks will increasingly rely on the use of low powered\nnodes to support massive connectivity in diverse set of applications and\nservices [1]. To this end, virtualized and mass-scale cloud architectures are\nproposed as promising technologies for 5G in which all the nodes are connected\nvia a backhaul network and managed centrally by such cloud centers. The\nsignificant computing power made available by the cloud technologies has\nenabled the implementation of sophisticated signal processing algorithms,\nespecially by way of parallel processing, for both interference management and\nnetwork provision. The latter two are among the major signal processing tasks\nfor 5G due to increased level of frequency sharing, node density, interference\nand network congestion. This article outlines several theoretical and practical\naspects of joint interference management and network provisioning for future 5G\nnetworks. A cross-layer optimization framework is proposed for joint user\nadmission, user-base station association, power control, user grouping,\ntransceiver design as well as routing and flow control. We show that many of\nthese cross-layer tasks can be treated in a unified way and implemented in a\nparallel manner using an efficient algorithmic framework called WMMSE (Weighted\nMMSE). Some recent developments in this area are highlighted and future\nresearch directions are identified. \n\n"}
{"id": "1407.1497", "contents": "Title: Content-Aware Network Coding over Device-to-Device Networks Abstract: Consider a scenario of broadcasting a common content to a group of\ncooperating mobile devices that are within proximity of each other. Devices in\nthis group may receive partial content from the source due to packet losses\nover wireless broadcast links. We further consider that packet losses are\ndifferent for different devices. The remaining missing content at each device\ncan then be recovered, thanks to cooperation among the devices by exploiting\ndevice-to-device (D2D) connections. In this context, the minimum amount of time\nthat can guarantee a complete acquisition of the common content at every device\nis referred to as the \"completion time\". It has been shown that instantly\ndecodable network coding (IDNC) reduces the completion time as compared to no\nnetwork coding in this scenario. Yet, for applications such as video streaming,\nnot all packets have the same importance and not all devices are interested in\nthe same quality of content. This problem is even more interesting when\nadditional, but realistic constraints, such as strict deadline, bandwidth, or\nlimited energy are added in the problem formulation. We assert that direct\napplication of IDNC in such a scenario yields poor performance in terms of\ncontent quality and completion time. In this paper, we propose a novel Content\nand Loss-Aware IDNC scheme that improves content quality and network coding\nopportunities jointly by taking into account importance of each packet towards\nthe desired quality of service (QoS) as well as the channel losses over D2D\nlinks. Our proposed Content and Loss-Aware IDNC (i) maximizes the quality under\nthe completion time constraint, and (ii) minimizes the completion time under\nthe quality constraint. We demonstrate the benefits of Content and Loss-Aware\nIDNC through simulations. \n\n"}
{"id": "1407.3257", "contents": "Title: Demystifying the Information Reconciliation Protocol Cascade Abstract: Cascade is an information reconciliation protocol proposed in the context of\nsecret key agreement in quantum cryptography. This protocol allows removing\ndiscrepancies in two partially correlated sequences that belong to distant\nparties, connected through a public noiseless channel. It is highly\ninteractive, thus requiring a large number of channel communications between\nthe parties to proceed and, although its efficiency is not optimal, it has\nbecome the de-facto standard for practical implementations of information\nreconciliation in quantum key distribution. The aim of this work is to analyze\nthe performance of Cascade, to discuss its strengths, weaknesses and\noptimization possibilities, comparing with some of the modified versions that\nhave been proposed in the literature. When looking at all design trade-offs, a\nnew view emerges that allows to put forward a number of guidelines and propose\nnear optimal parameters for the practical implementation of Cascade improving\nperformance significantly in comparison with all previous proposals. \n\n"}
{"id": "1407.4177", "contents": "Title: Power Control for Sum Rate Maximization on Interference Channels Under\n  Sum Power Constraint Abstract: In this paper, we consider the problem of power control for sum rate\nmaximization on multiple interfering links (TX-RX pairs)under sum power\nconstraint. We consider a single frequency network, where all pairs are\noperating in same frequency band,thereby creating interference for each other.\nWe study the power allocation problem for sum rate maximization with and\nwithout QoS requirements on individual links. When the objective is only sum\nrate maximization without QoS guarantees, we develop an analytic solution to\ndecide optimal power allocation for two TX-RX pair problem. We also develop a\nlow complexity iterative algorithm for three TX-RX pair problem. For a generic\nN>3 TX-RX pair problem, we develop two low-complexity sub-optimal power\nallocation algorithms. The first algorithm is based on the idea of making\nclusters of two or three TX-RX pairs and then leverage the power allocation\nresults obtained for two and three TX-RX pair problems. The second algorithm is\ndeveloped by using a high SINR approximation and this algorithm can also be\nimplemented in a distributed manner by individual TXs. We then consider the\nsame problem but with additional QoS guarantees for individual links. We again\ndevelop an analytic solution for two TX-RX pair problem, and a distributed\nalgorithm for N>2 TX-RX pairs. \n\n"}
{"id": "1407.5144", "contents": "Title: Lower Bounds on the Oracle Complexity of Nonsmooth Convex Optimization\n  via Information Theory Abstract: We present an information-theoretic approach to lower bound the oracle\ncomplexity of nonsmooth black box convex optimization, unifying previous lower\nbounding techniques by identifying a combinatorial problem, namely string\nguessing, as a single source of hardness. As a measure of complexity we use\ndistributional oracle complexity, which subsumes randomized oracle complexity\nas well as worst-case oracle complexity. We obtain strong lower bounds on\ndistributional oracle complexity for the box $[-1,1]^n$, as well as for the\n$L^p$-ball for $p \\geq 1$ (for both low-scale and large-scale regimes),\nmatching worst-case upper bounds, and hence we close the gap between\ndistributional complexity, and in particular, randomized complexity, and\nworst-case complexity. Furthermore, the bounds remain essentially the same for\nhigh-probability and bounded-error oracle complexity, and even for combination\nof the two, i.e., bounded-error high-probability oracle complexity. This\nconsiderably extends the applicability of known bounds. \n\n"}
{"id": "1407.6288", "contents": "Title: Subspace Learning From Bits Abstract: Networked sensing, where the goal is to perform complex inference using a\nlarge number of inexpensive and decentralized sensors, has become an\nincreasingly attractive research topic due to its applications in wireless\nsensor networks and internet-of-things. To reduce the communication, sensing\nand storage complexity, this paper proposes a simple sensing and estimation\nframework to faithfully recover the principal subspace of high-dimensional data\nstreams using a collection of binary measurements from distributed sensors,\nwithout transmitting the whole data. The binary measurements are designed to\nindicate comparison outcomes of aggregated energy projections of the data\nsamples over pairs of randomly selected directions. When the covariance matrix\nis a low-rank matrix, we propose a spectral estimator that recovers the\nprincipal subspace of the covariance matrix as the subspace spanned by the top\neigenvectors of a properly designed surrogate matrix, which is provably\naccurate as soon as the number of binary measurements is sufficiently large. An\nadaptive rank selection strategy based on soft thresholding is also presented.\nFurthermore, we propose a tailored spectral estimator when the covariance\nmatrix is additionally Toeplitz, and show reliable estimation can be obtained\nfrom a substantially smaller number of binary measurements. Our results hold\neven when a constant fraction of the binary measurements is randomly flipped.\nFinally, we develop a low-complexity online algorithm to track the principal\nsubspace when new measurements arrive sequentially. Numerical examples are\nprovided to validate the proposed approach. \n\n"}
{"id": "1407.7267", "contents": "Title: On Spectrum Sharing Between Energy Harvesting Cognitive Radio Users and\n  Primary Users Abstract: This paper investigates the maximum secondary throughput for a rechargeable\nsecondary user (SU) sharing the spectrum with a primary user (PU) plugged to a\nreliable power supply. The SU maintains a finite energy queue and harvests\nenergy from natural resources and primary radio frequency (RF) transmissions.\nWe propose a power allocation policy at the PU and analyze its effect on the\nthroughput of both the PU and SU. Furthermore, we study the impact of the\nbursty arrivals at the PU on the energy harvested by the SU from RF\ntransmissions. Moreover, we investigate the impact of the rate of energy\nharvesting from natural resources on the SU throughput. We assume fading\nchannels and compute exact closed-form expressions for the energy harvested by\nthe SU under fading. Results reveal that the proposed power allocation policy\nalong with the implemented RF energy harvesting at the SU enhance the\nthroughput of both primary and secondary links. \n\n"}
{"id": "1407.8246", "contents": "Title: Exponential decay of reconstruction error from binary measurements of\n  sparse signals Abstract: Binary measurements arise naturally in a variety of statistical and\nengineering applications. They may be inherent to the problem---e.g., in\ndetermining the relationship between genetics and the presence or absence of a\ndisease---or they may be a result of extreme quantization. In one-bit\ncompressed sensing it has recently been shown that the number of one-bit\nmeasurements required for signal estimation mirrors that of unquantized\ncompressed sensing. Indeed, $s$-sparse signals in $\\mathbb{R}^n$ can be\nestimated (up to normalization) from $\\Omega(s \\log (n/s))$ one-bit\nmeasurements. Nevertheless, controlling the precise accuracy of the error\nestimate remains an open challenge. In this paper, we focus on optimizing the\ndecay of the error as a function of the oversampling factor $\\lambda := m/(s\n\\log(n/s))$, where $m$ is the number of measurements. It is known that the\nerror in reconstructing sparse signals from standard one-bit measurements is\nbounded below by $\\Omega(\\lambda^{-1})$. Without adjusting the measurement\nprocedure, reducing this polynomial error decay rate is impossible. However, we\nshow that an adaptive choice of the thresholds used for quantization may lower\nthe error rate to $e^{-\\Omega(\\lambda)}$. This improves upon guarantees for\nother methods of adaptive thresholding as proposed in Sigma-Delta quantization.\nWe develop a general recursive strategy to achieve this exponential decay and\ntwo specific polynomial-time algorithms which fall into this framework, one\nbased on convex programming and one on hard thresholding. This work is inspired\nby the one-bit compressed sensing model, in which the engineer controls the\nmeasurement procedure. Nevertheless, the principle is extendable to signal\nreconstruction problems in a variety of binary statistical models as well as\nstatistical estimation problems like logistic regression. \n\n"}
{"id": "1407.8409", "contents": "Title: Joint Network and Gelfand-Pinsker Coding for 3-Receiver Gaussian\n  Broadcast Channels with Receiver Message Side Information Abstract: The problem of characterizing the capacity region for Gaussian broadcast\nchannels with receiver message side information appears difficult and remains\nopen for N >= 3 receivers. This paper proposes a joint network and\nGelfand-Pinsker coding method for 3-receiver cases. Using the method, we\nestablish a unified inner bound on the capacity region of 3-receiver Gaussian\nbroadcast channels under general message side information configuration. The\nachievability proof of the inner bound uses an idea of joint interference\ncancelation, where interference is canceled by using both dirty-paper coding at\nthe encoder and successive decoding at some of the decoders. We show that the\ninner bound is larger than that achieved by state of the art coding schemes. An\nouter bound is also established and shown to be tight in 46 out of all 64\npossible cases. \n\n"}
{"id": "1408.0377", "contents": "Title: Layered, Exact-Repair Regenerating Codes Via Embedded Error Correction\n  and Block Designs Abstract: A new class of exact-repair regenerating codes is constructed by stitching\ntogether shorter erasure correction codes, where the stitching pattern can be\nviewed as block designs. The proposed codes have the \"help-by-transfer\"\nproperty where the helper nodes simply transfer part of the stored data\ndirectly, without performing any computation. This embedded error correction\nstructure makes the decoding process straightforward, and in some cases the\ncomplexity is very low. We show that this construction is able to achieve\nperformance better than space-sharing between the minimum storage regenerating\ncodes and the minimum repair-bandwidth regenerating codes, and it is the first\nclass of codes to achieve this performance. In fact, it is shown that the\nproposed construction can achieve a non-trivial point on the optimal\nfunctional-repair tradeoff, and it is asymptotically optimal at high rate,\ni.e., it asymptotically approaches the minimum storage and the minimum\nrepair-bandwidth simultaneously. \n\n"}
{"id": "1408.1165", "contents": "Title: Noncommutative Uncertainty Principles Abstract: The classical uncertainty principles deal with functions on abelian groups.\nIn this paper, we discuss the uncertainty principles for finite index\nsubfactors which include the cases for finite groups and finite dimensional Kac\nalgebras. We prove the Hausdorff-Young inequality, Young's inequality, the\nHirschman-Beckner uncertainty principle, the Donoho-Stark uncertainty\nprinciple. We characterize the minimizers of the uncertainty principles. We\nalso prove that the minimizer is uniquely determined by the supports of itself\nand its Fourier transform. The proofs take the advantage of the analytic and\nthe categorial perspectives of subfactor planar algebras. Our method to prove\nthe uncertainty principles also works for more general cases, such as Popa's\n$\\lambda$-lattices, modular tensor categories etc. \n\n"}
{"id": "1408.2335", "contents": "Title: Wireless Powered Communication: Opportunities and Challenges Abstract: The performance of wireless communication is fundamentally constrained by the\nlimited battery life of wireless devices, whose operations are frequently\ndisrupted due to the need of manual battery replacement/recharging. The recent\nadvance in radio frequency (RF) enabled wireless energy transfer (WET)\ntechnology provides an attractive solution named wireless powered communication\n(WPC), where the wireless devices are powered by dedicated wireless power\ntransmitters to provide continuous and stable microwave energy over the air. As\na key enabling technology for truly perpetual communications, WPC opens up the\npotential to build a network with larger throughput, higher robustness, and\nincreased flexibility compared to its battery-powered counterpart. However, the\ncombination of wireless energy and information transmissions also raises many\nnew research problems and implementation issues to be addressed. In this\narticle, we provide an overview of state-of-the-art RF-enabled WET technologies\nand their applications to wireless communications, with highlights on the key\ndesign challenges, solutions, and opportunities ahead. \n\n"}
{"id": "1408.3469", "contents": "Title: Properties of an Aloha-like stability region Abstract: A well-known inner bound on the stability region of the finite-user slotted\nAloha protocol is the set of all arrival rates for which there exists some\nchoice of the contention probabilities such that the associated worst-case\nservice rate for each user exceeds the user's arrival rate, denoted $\\Lambda$.\nAlthough testing membership in $\\Lambda$ of a given arrival rate can be posed\nas a convex program, it is nonetheless of interest to understand the properties\nof this set. In this paper we develop new results of this nature, including\n$i)$ an equivalence between membership in $\\Lambda$ and the existence of a\npositive root of a given polynomial, $ii)$ a method to construct a vector of\ncontention probabilities to stabilize any stabilizable arrival rate vector,\n$iii)$ the volume of $\\Lambda$, $iv)$ explicit polyhedral, spherical, and\nellipsoid inner and outer bounds on $\\Lambda$, and $v)$ characterization of the\ngeneralized convexity properties of a natural ``excess rate'' function\nassociated with $\\Lambda$, including the convexity of the set of contention\nprobabilities that stabilize a given arrival rate vector. \n\n"}
{"id": "1408.3757", "contents": "Title: Tier Association Probability and Spectrum Partitioning for Maximum Rate\n  Coverage in Multi-tier Heterogeneous Networks Abstract: For a wireless multi-tier heterogeneous network with orthogonal spectrum\nallocation across tiers, we optimize the association probability and the\nfraction of spectrum allocated to each tier so as to maximize rate coverage. In\npractice, the association probability can be controlled using a biased received\nsignal power. The optimization problem is non-convex and we are forced to\nexplore locally optimal solutions. We make two contributions in this paper:\nfirst, we show that there exists a relation between the first derivatives of\nthe objective function with respect to each of the optimization variables. This\ncan be used to simplify numerical solutions to the optimization problem.\nSecond, we explore the optimality of the intuitive solution that the fraction\nof spectrum allocated to each tier should be equal to the tier association\nprobability. We show that, in this case, a closed-form solution exists.\nImportantly, our numerical results show that there is essentially zero\nperformance loss. The results also illustrate the significant gains possible by\njointly optimizing the user association and the resource allocation. \n\n"}
{"id": "1408.4528", "contents": "Title: Laplace Functional Ordering of Point Processes in Large-scale Wireless\n  Networks Abstract: Stochastic orders on point processes are partial orders which capture notions\nlike being larger or more variable. Laplace functional ordering of point\nprocesses is a useful stochastic order for comparing spatial deployments of\nwireless networks. It is shown that the ordering of point processes is\npreserved under independent operations such as marking, thinning, clustering,\nsuperposition, and random translation. Laplace functional ordering can be used\nto establish comparisons of several performance metrics such as coverage\nprobability, achievable rate, and resource allocation even when closed form\nexpressions of such metrics are unavailable. Applications in several network\nscenarios are also provided where tradeoffs between coverage and interference\nas well as fairness and peakyness are studied. Monte-Carlo simulations are used\nto supplement our analytical results. \n\n"}
{"id": "1408.5468", "contents": "Title: A Sytematic Piggybacking Design for Minimum Storage Regenerating Codes Abstract: Piggybacking is an efficient method to decrease the repair bandwidth of\nMaximum Distance Separable (MDS) codes or Minimum Storage Regenerating (MSR)\ncodes. In this paper, for minimizing the repair bandwidth of parity nodes of\nthe known MSR codes with high rate, which is usually the whole size of the\noriginal data, i.e., the maximal, a new systematic piggybacking design is\nproposed through an in-depth analysis of the design of piggybacking. As a\nresult, new MSR codes are obtained with almost optimal repair bandwidth of\nparity nodes while retaining the optimal repair bandwidth of systematic nodes.\nFurthermore, MSR codes with balanced download during node repair process are\npresented based on the new piggybacking design. \n\n"}
{"id": "1408.6385", "contents": "Title: Long term Throughput and Approximate Capacity of Transmitter-Receiver\n  Energy Harvesting Channel with Fading Abstract: We first consider an energy harvesting channel with fading, where only the\ntransmitter harvests energy from natural sources. We bound the optimal long\nterm throughput by a constant for a class of energy arrival distributions. The\nproposed method also gives a constant approximation to the capacity of the\nenergy harvesting channel with fading. Next, we consider a more general system\nwhere both the transmitter and the receiver employ energy harvesting to power\nthemselves. In this case, we show that finding an approximation to the optimal\nlong term throughput is far more difficult, and identify a special case of unit\nbattery capacity at both the transmitter and the receiver for which we obtain a\nuniversal bound on the ratio of the upper and lower bound on the long term\nthroughput. \n\n"}
{"id": "1409.1122", "contents": "Title: On $\\ell_p$-norm Computation over Multiple-Access Channels Abstract: This paper addresses some aspects of the general problem of information\ntransfer and distributed function computation in wireless networks. Many\napplications of wireless technology foresee networks of autonomous devices\nexecuting tasks that can be posed as distributed function computation. In\ntoday's wireless networks, the tasks of communication and (distributed)\ncomputation are performed separately, although an efficient network operation\ncalls for approaches in which the information transfer is dynamically adapted\nto time-varying computation objectives. Thus, wireless communications and\nfunction computation must be tightly coupled and it is shown in this paper that\ninformation theory may play a crucial role in the design of efficient\ncomputation-aware wireless communication and networking strategies. This is\nexplained in more detail by considering the problem of computing $\\ell_p$-norms\nover multiple access channels. \n\n"}
{"id": "1409.1184", "contents": "Title: Spectral Efficiency of the Cellular Two-Way Relaying with Large Antenna\n  Arrays Abstract: This paper considers a multiuser cellular two-way relay network (cTWRN) where\nmultiple users exchange information with a base station (BS) via a relay\nstation (RS). Each user is equipped with a single antenna, while both the BS\nand the RS are equipped with a very large antenna array. We investigate the\nperformance of the cTWRN with amplify-and-forward (AF) based physical-layer\nnetwork coding, and derive closed-form expression for the asymptotic spectral\nefficiency when both the number of antennas at the BS and the RS grow large. It\nis shown that the noise propagation of the non-regenerative relaying protocol\ncan be greatly suppressed, and the AF relaying scheme can approach the cut-set\nbound under certain conditions. We also investigate the performance of the AF\nrelaying scheme under two power-scaling cases, and show that the transmit power\nof the BS and each user can be made inversely proportional to the number of\nrelay antennas while maintaining a given quality-of-service. Numerical results\nare presented to verify the analytical results. \n\n"}
{"id": "1409.1556", "contents": "Title: Very Deep Convolutional Networks for Large-Scale Image Recognition Abstract: In this work we investigate the effect of the convolutional network depth on\nits accuracy in the large-scale image recognition setting. Our main\ncontribution is a thorough evaluation of networks of increasing depth using an\narchitecture with very small (3x3) convolution filters, which shows that a\nsignificant improvement on the prior-art configurations can be achieved by\npushing the depth to 16-19 weight layers. These findings were the basis of our\nImageNet Challenge 2014 submission, where our team secured the first and the\nsecond places in the localisation and classification tracks respectively. We\nalso show that our representations generalise well to other datasets, where\nthey achieve state-of-the-art results. We have made our two best-performing\nConvNet models publicly available to facilitate further research on the use of\ndeep visual representations in computer vision. \n\n"}
{"id": "1409.1606", "contents": "Title: Power Optimal Non-contiguous Spectrum Access in Multi Front End Radio\n  Enabled Point-to-Point Link Abstract: Non-contiguous spectrum chunks allow wireless links to flexibly access a wide\namount of bandwidth. Multi- Channel Multi-Radio (MC-MR) and Non-Contiguous\nOrthogonal Frequency Division Multiplexing (NC-OFDM) are the two commercially\nviable strategies to access non-contiguous spectrum chunks. MC-MR accesses\nmultiple non-contiguous chunks by activating multiple front ends which, in\nturn, increases the circuit power consumption of each of the activated front\nends. NC-OFDM accesses non-contiguous spectrum chunks with a single front end\nby nulling remaining subchannels but increases spectrum span which, in turn,\nincreases the power consumption of ADC and DAC. This work focuses on a\npoint-to-point link where transmitter and receiver have multiple front ends and\ncan employ NC-OFDM technology. We investigate optimal spectrum fragmentation in\neach front end from a system power (summation of transmit power and circuit\npower) perspective. We formulate a mixed integer non-linear program (MINLP) to\nperform power control and scheduling, and minimize system power by providing a\ngreedy algorithm (O(M^3 I)) where M and I denote the number of channels and\nradio front ends respectively. \n\n"}
{"id": "1409.2177", "contents": "Title: The Large Margin Mechanism for Differentially Private Maximization Abstract: A basic problem in the design of privacy-preserving algorithms is the private\nmaximization problem: the goal is to pick an item from a universe that\n(approximately) maximizes a data-dependent function, all under the constraint\nof differential privacy. This problem has been used as a sub-routine in many\nprivacy-preserving algorithms for statistics and machine-learning.\n  Previous algorithms for this problem are either range-dependent---i.e., their\nutility diminishes with the size of the universe---or only apply to very\nrestricted function classes. This work provides the first general-purpose,\nrange-independent algorithm for private maximization that guarantees\napproximate differential privacy. Its applicability is demonstrated on two\nfundamental tasks in data mining and machine learning. \n\n"}
{"id": "1409.2835", "contents": "Title: Power Estimation in LTE systems with the General Framework of Standard\n  Interference Mappings Abstract: We devise novel techniques to obtain the downlink power inducing a given load\nin long-term evolution (LTE) systems, where we define load as the fraction of\nresource blocks in the time-frequency grid being requested by users from a\ngiven base station. These techniques are particularly important because\nprevious studies have proved that the data rate requirement of users can be\nsatisfied with lower transmit energy if we allow the load to increase. Those\nstudies have also shown that obtaining the power assignment from a desired load\nprofile can be posed as a fixed point problem involving standard interference\nmappings, but so far the mappings have not been obtained explicitly. One of our\nmain contributions in this study is to close this gap. We derive an\ninterference mapping having as its fixed point the power assignment inducing a\ndesired load, assuming that such an assignment exists. Having this mapping in\nclosed form, we simplify the proof of the aforementioned known results, and we\nalso devise novel iterative algorithms for power computation that have many\nnumerical advantages over previous methods. \n\n"}
{"id": "1409.3246", "contents": "Title: Wideband Sensing and Optimization for Cognitive Radio Networks with\n  Noise Variance Uncertainty Abstract: This paper considers wide-band spectrum sensing and optimization for\ncognitive radio (CR) networks with noise variance uncertainty. It is assumed\nthat the considered wide-band contains one or more white sub-bands. Under this\nassumption, we consider throughput maximization of the CR network while\nappropriately protecting the primary network. We address this problem as\nfollows. First, we propose novel ratio based test statistics for detecting the\nedges of each sub-band. Second, we employ simple energy comparison approach to\nchoose one reference white sub-band. Third, we propose novel generalized energy\ndetector (GED) for examining each of the remaining sub-bands by exploiting the\nnoise information of the reference white sub-band. Finally, we optimize the\nsensing time ($T_o$) to maximize the CR network throughput using the detection\nand false alarm probabilities of the GED. The proposed GED does not suffer from\nsignal to noise ratio (SNR) wall and outperforms the existing signal detectors.\nMoreover, the relationship between the proposed GED and conventional energy\ndetector (CED) is quantified analytically. We show that the optimal $T_o$\ndepends on the noise variance information. In particular, with $10$TV bands,\nSNR=$-20$dB and $2$s frame duration, we found that the optimal $T_o$ is\n$28.5$ms ($50.6$ms) with perfect (imperfect) noise variance scenario. \n\n"}
{"id": "1409.3665", "contents": "Title: Monotone Measures for Non-Local Correlations Abstract: Non-locality is the phenomenon of observing strong correlations among the\noutcomes of local measurements of a multipartite physical system. No-signaling\nboxes are the abstract objects for studying non-locality, and wirings are local\noperations on the space of no-signaling boxes. This means that, no matter how\nnon-local the nature is, the set of physical non-local correlations must be\nclosed under wirings. Then, one approach to identify the non-locality of nature\nis to characterize closed sets of non-local correlations. Although non-trivial\nexamples of wirings of no-signaling boxes are known, there is no systematic way\nto study wirings. In particular, given a set of no-signaling boxes, we do not\nknow a general method to prove that it is closed under wirings. In this paper,\nwe propose the first general method to construct such closed sets of non-local\ncorrelations. We show that a well-known measure of correlation, called maximal\ncorrelation, when appropriately defined for non-local correlations, is\nmonotonically decreasing under wirings.\n  This establishes a conjecture about the impossibility of simulating isotropic\nboxes from each other, implying the existence of a continuum of closed sets of\nnon-local boxes under wirings. To prove our main result, we introduce some\nmathematical tools that may be of independent interest: we define a notion of\nmaximal correlation ribbon as a generalization of maximal correlation, and\nprovide a connection between it and a known object called hypercontractivity\nribbon; we show that these two ribbons are monotone under wirings too. \n\n"}
{"id": "1409.3836", "contents": "Title: Hardness of parameter estimation in graphical models Abstract: We consider the problem of learning the canonical parameters specifying an\nundirected graphical model (Markov random field) from the mean parameters. For\ngraphical models representing a minimal exponential family, the canonical\nparameters are uniquely determined by the mean parameters, so the problem is\nfeasible in principle. The goal of this paper is to investigate the\ncomputational feasibility of this statistical task. Our main result shows that\nparameter estimation is in general intractable: no algorithm can learn the\ncanonical parameters of a generic pair-wise binary graphical model from the\nmean parameters in time bounded by a polynomial in the number of variables\n(unless RP = NP). Indeed, such a result has been believed to be true (see the\nmonograph by Wainwright and Jordan (2008)) but no proof was known.\n  Our proof gives a polynomial time reduction from approximating the partition\nfunction of the hard-core model, known to be hard, to learning approximate\nparameters. Our reduction entails showing that the marginal polytope boundary\nhas an inherent repulsive property, which validates an optimization procedure\nover the polytope that does not use any knowledge of its structure (as required\nby the ellipsoid method and others). \n\n"}
{"id": "1409.7433", "contents": "Title: Throughput Analysis for Wireless Networks with Full-Duplex Radios Abstract: This paper investigates the throughput for wireless network with full-duplex\nradios using stochastic geometry. Full-duplex (FD) radios can exchange data\nsimultaneously with each other. On the other hand, the downside of FD\ntransmission is that it will inevitably cause extra interference to the network\ncompared to half-duplex (HD) transmission. In this paper, we focus on a\nwireless network of nodes with both HD and FD capabilities and derive and\noptimize the throughput in such a network. Our analytical result shows that if\nthe network is adapting an ALOHA protocol, the maximal throughput is always\nachieved by scheduling all concurrently transmitting nodes to work in FD mode\ninstead of a mixed FD/HD mode or HD mode regardless of the network\nconfigurations. Moreover, the throughput gain of using FD transmission over HD\ntransmission is analytically lower and upper bounded. \n\n"}
{"id": "1410.0952", "contents": "Title: Robust Binary Hypothesis Testing Under Contaminated Likelihoods Abstract: In hypothesis testing, the phenomenon of label noise, in which hypothesis\nlabels are switched at random, contaminates the likelihood functions. In this\npaper, we develop a new method to determine the decision rule when we do not\nhave knowledge of the uncontaminated likelihoods and contamination\nprobabilities, but only have knowledge of the contaminated likelihoods. In\nparticular we pose a minimax optimization problem that finds a decision rule\nrobust against this lack of knowledge. The method simplifies by application of\nlinear programming theory. Motivation for this investigation is provided by\nproblems encountered in workforce analytics. \n\n"}
{"id": "1410.1002", "contents": "Title: A Rate-Distortion Based Secrecy System with Side Information at the\n  Decoders Abstract: A secrecy system with side information at the decoders is studied in the\ncontext of lossy source compression over a noiseless broadcast channel. The\ndecoders have access to different side information sequences that are\ncorrelated with the source. The fidelity of the communication to the legitimate\nreceiver is measured by a distortion metric, as is traditionally done in the\nWyner-Ziv problem. The secrecy performance of the system is also evaluated\nunder a distortion metric. An achievable rate-distortion region is derived for\nthe general case of arbitrarily correlated side information. Exact bounds are\nobtained for several special cases in which the side information satisfies\ncertain constraints. An example is considered in which the side information\nsequences come from a binary erasure channel and a binary symmetric channel. \n\n"}
{"id": "1410.2861", "contents": "Title: Multiuser Joint Energy-Bandwidth Allocation with Energy Harvesting -\n  Part I: Optimum Algorithm & Multiple Point-to-Point Channels Abstract: In this paper, we develop optimal energy-bandwidth allocation algorithms in\nfading channels for multiple energy harvesting transmitters, each may\ncommunicate with multiple receivers via orthogonal channels. We first assume\nthat the side information of both the channel states and the energy harvesting\nstates is known for $K$ time slots {\\em a priori}, and the battery capacity and\nthe maximum transmission power in each time slot are bounded. The objective is\nto maximize the weighted sum-rate of all transmitters over the $K$ time slots\nby assigning the transmission power and bandwidth for each transmitter in each\nslot. The problem is formulated as a convex optimization problem with ${\\cal\nO}(MK)$ constraints, where $M$ is the number of the receivers, making it hard\nto solve with a generic convex solver. An iterative algorithm is proposed that\nalternatively solves two subproblems in each iteration. The convergence and the\noptimality of this algorithm are also shown. We then consider the special case\nthat each transmitter only communicates with one receiver and the objective is\nto maximize the total throughput. We develop efficient algorithms for solving\nthe two subproblems and the optimal energy-bandwidth allocation can be obtained\nwith an overall complexity of ${\\cal O}(MK^2)$. Moreover, a heuristic algorithm\nis also proposed for energy-bandwidth allocation based on causal information of\nchannel and energy harvesting states. \n\n"}
{"id": "1410.4986", "contents": "Title: Code Construction and Decoding Algorithms for Semi-Quantitative Group\n  Testing with Nonuniform Thresholds Abstract: We analyze a new group testing scheme, termed semi-quantitative group\ntesting, which may be viewed as a concatenation of an adder channel and a\ndiscrete quantizer. Our focus is on non-uniform quantizers with arbitrary\nthresholds. For the most general semi-quantitative group testing model, we\ndefine three new families of sequences capturing the constraints on the code\ndesign imposed by the choice of the thresholds. The sequences represent\nextensions and generalizations of Bh and certain types of super-increasing and\nlexicographically ordered sequences, and they lead to code structures amenable\nfor efficient recursive decoding. We describe the decoding methods and provide\nan accompanying computational complexity and performance analysis. \n\n"}
{"id": "1410.5373", "contents": "Title: Poisson Group Testing: A Probabilistic Model for Boolean Compressed\n  Sensing Abstract: We introduce a novel probabilistic group testing framework, termed Poisson\ngroup testing, in which the number of defectives follows a right-truncated\nPoisson distribution. The Poisson model has a number of new applications,\nincluding dynamic testing with diminishing relative rates of defectives. We\nconsider both nonadaptive and semi-adaptive identification methods. For\nnonadaptive methods, we derive a lower bound on the number of tests required to\nidentify the defectives with a probability of error that asymptotically\nconverges to zero; in addition, we propose test matrix constructions for which\nthe number of tests closely matches the lower bound. For semi-adaptive methods,\nwe describe a lower bound on the expected number of tests required to identify\nthe defectives with zero error probability. In addition, we propose a\nstage-wise reconstruction algorithm for which the expected number of tests is\nonly a constant factor away from the lower bound. The methods rely only on an\nestimate of the average number of defectives, rather than on the individual\nprobabilities of subjects being defective. \n\n"}
{"id": "1410.6339", "contents": "Title: Constructions and Properties of Linear Locally Repairable Codes Abstract: In this paper, locally repairable codes with all-symbol locality are studied.\nMethods to modify already existing codes are presented. Also, it is shown that\nwith high probability, a random matrix with a few extra columns guaranteeing\nthe locality property, is a generator matrix for a locally repairable code with\na good minimum distance. The proof of this also gives a constructive method to\nfind locally repairable codes. Constructions are given of three infinite\nclasses of optimal vector-linear locally repairable codes over an alphabet of\nsmall size, not depending on the size of the code. \n\n"}
{"id": "1410.6913", "contents": "Title: Low rank matrix recovery from rank one measurements Abstract: We study the recovery of Hermitian low rank matrices $X \\in \\mathbb{C}^{n\n\\times n}$ from undersampled measurements via nuclear norm minimization. We\nconsider the particular scenario where the measurements are Frobenius inner\nproducts with random rank-one matrices of the form $a_j a_j^*$ for some\nmeasurement vectors $a_1,...,a_m$, i.e., the measurements are given by $y_j =\n\\mathrm{tr}(X a_j a_j^*)$. The case where the matrix $X=x x^*$ to be recovered\nis of rank one reduces to the problem of phaseless estimation (from\nmeasurements, $y_j = |\\langle x,a_j\\rangle|^2$ via the PhaseLift approach,\nwhich has been introduced recently. We derive bounds for the number $m$ of\nmeasurements that guarantee successful uniform recovery of Hermitian rank $r$\nmatrices, either for the vectors $a_j$, $j=1,...,m$, being chosen independently\nat random according to a standard Gaussian distribution, or $a_j$ being sampled\nindependently from an (approximate) complex projective $t$-design with $t=4$.\nIn the Gaussian case, we require $m \\geq C r n$ measurements, while in the case\nof $4$-designs we need $m \\geq Cr n \\log(n)$. Our results are uniform in the\nsense that one random choice of the measurement vectors $a_j$ guarantees\nrecovery of all rank $r$-matrices simultaneously with high probability.\nMoreover, we prove robustness of recovery under perturbation of the\nmeasurements by noise. The result for approximate $4$-designs generalizes and\nimproves a recent bound on phase retrieval due to Gross, Kueng and Krahmer. In\naddition, it has applications in quantum state tomography. Our proofs employ\nthe so-called bowling scheme which is based on recent ideas by Mendelson and\nKoltchinskii. \n\n"}
{"id": "1410.7270", "contents": "Title: Capacity Analysis of Decoupled Downlink and Uplink Access in 5G\n  Heterogeneous Systems Abstract: Our traditional notion of a cell is changing dramatically given the\nincreasing degree of heterogeneity in 4G and emerging 5G systems. Rather than\nbelonging to a specific cell, a device would choose the most suitable\nconnection from the plethora of connections available. In such a setting, given\nthe transmission powers differ significantly between downlink (DL) and uplink\n(UL), a wireless device that sees multiple Base Stations (BSs) may access the\ninfrastructure in a way that it receives the downlink (DL) traffic from one BS\nand sends uplink (UL) traffic through another BS. This situation is referred to\nas Downlink and Uplink Decoupling (DUDe). In this paper, the capacity and\nthroughput gains brought by decoupling are rigorously derived using stochastic\ngeometry. Theoretical findings are then corroborated by means of simulation\nresults. A further constituent of this paper is the verification of the\ntheoretically derived results by means of a real-world system simulation\nplatform. Despite theoretical assumptions differing from the very complete\nsystem simulator, the trends in the association probabilities and capacity\ngains are similar. Based on the promising results, we then outline\narchitectural changes needed to facilitate the decoupling of DL and UL. \n\n"}
{"id": "1411.0114", "contents": "Title: On the Transmit Beamforming for MIMO Wiretap Channels: Large-System\n  Analysis Abstract: With the growth of wireless networks, security has become a fundamental issue\nin wireless communications due to the broadcast nature of these networks. In\nthis work, we consider MIMO wiretap channels in a fast fading environment, for\nwhich the overall performance is characterized by the ergodic MIMO secrecy\nrate. Unfortunately, the direct solution to finding ergodic secrecy rates is\nprohibitive due to the expectations in the rates expressions in this setting.\nTo overcome this difficulty, we invoke the large-system assumption, which\nallows a deterministic approximation to the ergodic mutual information.\nLeveraging results from random matrix theory, we are able to characterize the\nachievable ergodic secrecy rates. Based on this characterization, we address\nthe problem of covariance optimization at the transmitter. Our numerical\nresults demonstrate a good match between the large-system approximation and the\nactual simulated secrecy rates, as well as some interesting features of the\nprecoder optimization. \n\n"}
{"id": "1411.0281", "contents": "Title: Polar Coding for the Broadcast Channel with Confidential Messages: A\n  Random Binning Analogy Abstract: We develop a low-complexity polar coding scheme for the discrete memoryless\nbroadcast channel with confidential messages under strong secrecy and\nrandomness constraints. Our scheme extends previous work by using an optimal\nrate of uniform randomness in the stochastic encoder, and avoiding assumptions\nregarding the symmetry or degraded nature of the channels. The price paid for\nthese extensions is that the encoder and decoders are required to share a\nsecret seed of negligible size and to increase the block length through\nchaining. We also highlight a close conceptual connection between the proposed\npolar coding scheme and a random binning proof of the secrecy capacity region. \n\n"}
{"id": "1411.1801", "contents": "Title: Space-Time Encoded MISO Broadcast Channel with Outdated CSIT: An Error\n  Rate and Diversity Performance Analysis Abstract: Studies of the MISO Broadcast Channel (BC) with delayed Channel State\nInformation at the Transmitter (CSIT) have so far focused on the sum-rate and\nDegrees-of-Freedom (DoF) region analysis. In this paper, we investigate for the\nfirst time the error rate performance at finite SNR and the\ndiversity-multiplexing tradeoff (DMT) at infinite SNR of a space-time encoded\ntransmission over a two-user MISO BC with delayed CSIT. We consider the\nso-called MAT protocol obtained by Maddah-Ali and Tse, which was shown to\nprovide 33% DoF enhancement over TDMA. While the asymptotic DMT analysis shows\nthat MAT is always preferable to TDMA, the Pairwise Error Probability analysis\nat finite SNR shows that MAT is in fact not always a better alternative to\nTDMA. Benefits can be obtained over TDMA only at very high rate or once\nconcatenated with a full-rate full-diversity space-time code. The analysis is\nalso extended to spatially correlated channels and the influence of transmit\ncorrelation matrices and user pairing strategies on the performance are\ndiscussed. Relying on statistical CSIT, signal constellations are further\noptimized to improve the error rate performance of MAT and make it insensitive\nto user orthogonality. Finally, other transmission strategies relying on\ndelayed CSIT are discussed. \n\n"}
{"id": "1411.2417", "contents": "Title: Capacity Results for Multicasting Nested Message Sets over Combination\n  Networks Abstract: The problem of multicasting two nested messages is studied over a class of\nnetworks known as combination networks. A source multicasts two messages, a\ncommon and a private message, to several receivers. A subset of the receivers\n(called the public receivers) only demand the common message and the rest of\nthe receivers (called the private receivers) demand both the common and the\nprivate message. Three encoding schemes are discussed that employ linear\nsuperposition coding and their optimality is proved in special cases. The\nstandard linear superposition scheme is shown to be optimal for networks with\ntwo public receivers and any number of private receivers. When the number of\npublic receivers increases, this scheme stops being optimal. Two improvements\nare discussed: one using pre-encoding at the source, and one using a block\nMarkov encoding scheme. The rate-regions that are achieved by the two schemes\nare characterized in terms of feasibility problems. Both inner-bounds are shown\nto be the capacity region for networks with three (or fewer) public and any\nnumber of private receivers. Although the inner bounds are not comparable in\ngeneral, it is shown through an example that the region achieved by the block\nMarkov encoding scheme may strictly include the region achieved by the\npre-encoding/linear superposition scheme. Optimality results are founded on the\ngeneral framework of Balister and Bollob\\'as (2012) for sub-modularity of the\nentropy function. An equivalent graphical representation is introduced and a\nlemma is proved that might be of independent interest.\n  Motivated by the connections between combination networks and broadcast\nchannels, a new block Markov encoding scheme is proposed for broadcast channels\nwith two nested messages. The rate-region that is obtained includes the\npreviously known rate-regions. It remains open whether this inclusion is\nstrict. \n\n"}
{"id": "1411.4226", "contents": "Title: Roy's largest root under rank-one alternatives:The complex valued case\n  and applications Abstract: The largest eigenvalue of a Wishart matrix, known as Roy's largest root\n(RLR), plays an important role in a variety of applications. Most works to date\nderived approximations to its distribution under various asymptotic regimes,\nsuch as degrees of freedom, dimension, or both tending to infinity. However,\nseveral applications involve finite and relative small parameters, for which\nthe above approximations may be inaccurate. Recently, via a small noise\nperturbation approach with fixed dimension and degrees of freedom, Johnstone\nand Nadler derived simple yet accurate stochastic approximations to the\ndistribution of Roy's largest root in the real valued case, under a rank-one\nalternative. In this paper, we extend their results to the complex valued case.\nFurthermore, we analyze the behavior of the leading eigenvector by developing\nnew stochastic approximations. Specifically, we derive simple stochastic\napproximations to the distribution of the largest eigenvalue under five common\ncomplex single-matrix and double-matrix scenarios. We then apply these results\nto investigate several problems in signal detection and communications. In\nparticular, we analyze the performance of RLR detector in cognitive radio\nspectrum sensing and constant modulus signal detection in the high\nsignal-to-noise ratio (SNR) regime. Moreover, we address the problem of\ndetermining the optimal transmit-receive antenna configuration (here optimality\nis in the sense of outage minimization) for rank-one multiple-input\nmultiple-output Rician Fading channels at high SNR. \n\n"}
{"id": "1411.4253", "contents": "Title: Energy-efficient Decoders for Compressive Sensing: Fundamental Limits\n  and Implementations Abstract: The fundamental problem considered in this paper is \"What is the\n\\textit{energy} consumed for the implementation of a \\emph{compressive sensing}\ndecoding algorithm on a circuit?\". Using the \"information-friction\" framework,\nwe examine the smallest amount of \\textit{bit-meters} as a measure for the\nenergy consumed by a circuit. We derive a fundamental lower bound for the\nimplementation of compressive sensing decoding algorithms on a circuit. In the\nsetting where the number of measurements scales linearly with the sparsity and\nthe sparsity is sub-linear with the length of the signal, we show that the\n\\textit{bit-meters} consumption for these algorithms is order-tight, i.e., it\nmatches the lower bound asymptotically up to a constant factor. Our\nimplementations yield interesting insights into design of energy-efficient\ncircuits that are not captured by the notion of computational efficiency alone. \n\n"}
{"id": "1411.5326", "contents": "Title: Compress and Control Abstract: This paper describes a new information-theoretic policy evaluation technique\nfor reinforcement learning. This technique converts any compression or density\nmodel into a corresponding estimate of value. Under appropriate stationarity\nand ergodicity conditions, we show that the use of a sufficiently powerful\nmodel gives rise to a consistent value function estimator. We also study the\nbehavior of this technique when applied to various Atari 2600 video games,\nwhere the use of suboptimal modeling techniques is unavoidable. We consider\nthree fundamentally different models, all too limited to perfectly model the\ndynamics of the system. Remarkably, we find that our technique provides\nsufficiently accurate value estimates for effective on-policy control. We\nconclude with a suggestive study highlighting the potential of our technique to\nscale to large problems. \n\n"}
{"id": "1411.6137", "contents": "Title: Enhanced Multi-Parameter Cognitive Architecture for Future Wireless\n  Communications Abstract: The very original concept of cognitive radio (CR) raised by Mitola targets at\nall the environment parameters, including those in physical layer, MAC layer,\napplication layer as well as the information extracted from reasoning. Hence\nthe first CR is also referred to as \"full cognitive radio\". However, due to its\ndifficult implementation, FCC and Simon Haykin separately proposed a much more\nsimplified definition, in which CR mainly detects one single parameter, i.e.,\nspectrum occupancy, and is also called as \"spectrum sensing cognitive radio\".\nWith the rapid development of wireless communication, the infrastructure of a\nwireless system becomes much more complicated while the functionality at every\nnode is desired to be as intelligent as possible, say the self-organized\ncapability in the approaching 5G cellular networks. It is then interesting to\nre-look into Mitola's definition and think whether one could, besides obtaining\nthe \"on/off\" status of the licensed user only, achieve more parameters in a\ncognitive way. In this article, we propose a new cognitive architecture\ntargeting at multiple parameters in future cellular networks, which is a one\nstep further towards the \"full cognition\" compared to the most existing CR\nresearch. The new architecture is elaborated in detailed stages, and three\nrepresentative examples are provided based on the recent research progress to\nillustrate the feasibility as well as the validity of the proposed\narchitecture. \n\n"}
{"id": "1411.7632", "contents": "Title: Semidefinite Programming Approach to Gaussian Sequential Rate-Distortion\n  Trade-offs Abstract: Sequential rate-distortion (SRD) theory provides a framework for studying the\nfundamental trade-off between data-rate and data-quality in real-time\ncommunication systems. In this paper, we consider the SRD problem for\nmulti-dimensional time-varying Gauss-Markov processes under mean-square\ndistortion criteria. We first revisit the sensor-estimator separation\nprinciple, which asserts that considered SRD problem is equivalent to a joint\nsensor and estimator design problem in which data-rate of the sensor output is\nminimized while the estimator's performance satisfies the distortion criteria.\nWe then show that the optimal joint design can be performed by semidefinite\nprogramming. A semidefinite representation of the corresponding SRD function is\nobtained. Implications of the obtained result in the context of zero-delay\nsource coding theory and applications to networked control theory are also\ndiscussed. \n\n"}
{"id": "1411.7923", "contents": "Title: Learning Face Representation from Scratch Abstract: Pushing by big data and deep convolutional neural network (CNN), the\nperformance of face recognition is becoming comparable to human. Using private\nlarge scale training datasets, several groups achieve very high performance on\nLFW, i.e., 97% to 99%. While there are many open source implementations of CNN,\nnone of large scale face dataset is publicly available. The current situation\nin the field of face recognition is that data is more important than algorithm.\nTo solve this problem, this paper proposes a semi-automatical way to collect\nface images from Internet and builds a large scale dataset containing about\n10,000 subjects and 500,000 images, called CASIAWebFace. Based on the database,\nwe use a 11-layer CNN to learn discriminative representation and obtain\nstate-of-theart accuracy on LFW and YTF. The publication of CASIAWebFace will\nattract more research groups entering this field and accelerate the development\nof face recognition in the wild. \n\n"}
{"id": "1412.1538", "contents": "Title: Krylov Subspace Methods in Dynamical Sampling Abstract: Let $B$ be an unknown linear evolution process on $\\mathbb C^d\\simeq\nl^2(\\mathbb Z_d)$ driving an unknown initial state $x$ and producing the states\n$\\{B^\\ell x, \\ell = 0,1,\\ldots\\}$ at different time levels. The problem under\nconsideration in this paper is to find as much information as possible about\n$B$ and $x$ from the measurements $Y=\\{x(i)$, $Bx(i)$, $\\dots$,\n$B^{\\ell_i}x(i): i \\in \\Omega\\subset \\mathbb Z^d\\}$. If $B$ is a \"low-pass\"\nconvolution operator, we show that we can recover both $B$ and $x$, almost\nsurely, as long as we double the amount of temporal samples needed in\n\\cite{ADK13} to recover the signal propagated by a known operator $B$. For a\ngeneral operator $B$, we can recover parts or even all of its spectrum from\n$Y$. As a special case of our method, we derive the centuries old Prony's\nmethod \\cite{BDVMC08, P795, PP13} which recovers a vector with an $s$-sparse\nFourier transform from $2s$ of its consecutive components. \n\n"}
{"id": "1412.1898", "contents": "Title: Joint Rate and SINR Coverage Analysis for Decoupled Uplink-Downlink\n  Biased Cell Associations in HetNets Abstract: Load balancing by proactively offloading users onto small and otherwise\nlightly-loaded cells is critical for tapping the potential of dense\nheterogeneous cellular networks (HCNs). Offloading has mostly been studied for\nthe downlink, where it is generally assumed that a user offloaded to a small\ncell will communicate with it on the uplink as well. The impact of coupled\ndownlink-uplink offloading is not well understood. Uplink power control and\nspatial interference correlation further complicate the mathematical analysis\nas compared to the downlink. We propose an accurate and tractable model to\ncharacterize the uplink SINR and rate distribution in a multi-tier HCN as a\nfunction of the association rules and power control parameters. Joint\nuplink-downlink rate coverage is also characterized. Using the developed\nanalysis, it is shown that the optimal degree of channel inversion (for uplink\npower control) increases with load imbalance in the network. In sharp contrast\nto the downlink, minimum path loss association is shown to be optimal for\nuplink rate. Moreover, with minimum path loss association and full channel\ninversion, uplink SIR is shown to be invariant of infrastructure density. It is\nfurther shown that a decoupled association---employing differing association\nstrategies for uplink and downlink---leads to significant improvement in joint\nuplink-downlink rate coverage over the standard coupled association in HCNs. \n\n"}
{"id": "1412.2669", "contents": "Title: Two step recovery of jointly sparse and low-rank matrices: theoretical\n  guarantees Abstract: We introduce a two step algorithm with theoretical guarantees to recover a\njointly sparse and low-rank matrix from undersampled measurements of its\ncolumns. The algorithm first estimates the row subspace of the matrix using a\nset of common measurements of the columns. In the second step, the subspace\naware recovery of the matrix is solved using a simple least square algorithm.\nThe results are verified in the context of recovering CINE data from\nundersampled measurements; we obtain good recovery when the sampling conditions\nare satisfied. \n\n"}
{"id": "1412.4813", "contents": "Title: Opportunistic Relaying without CSI: Optimizing Variable-Rate HARQ Abstract: We analyze the opportunistic relaying based on HARQ transmission over the\nblock-fading channel with absence of channel state information (CSI) at the\ntransmitter nodes. We assume that both the source and the relay are allowed to\nvary their transmission rate between the HARQ transmission rounds. We solve the\nproblem of throughput maximization with respect to the transmission rates using\ndouble-recursive Dynamic Programming. Simplifications are also proposed to\ndiminish the complexity of the optimization. The numerical results confirm that\nthe variable-rate HARQ can increase the throughput significantly comparing to\nits fixed-rate counterpart. \n\n"}
{"id": "1412.5551", "contents": "Title: Statistical Modeling and Performance Characterization of an Ultrafast\n  Digital Lightwave Communication System Using a Power-Cubic Optical Nonlinear\n  Preprocessor (Extended Version) Abstract: In this paper, we present an analytical approach in obtaining the probability\ndensity function (pdf) of the random decision variable Y, formed at the output\nof power-cubic all-optical nonlinear preprocessor followed by the\nphotodetector. Our approach can be used to accurately evaluate the performance\nof ultrafast pulse detection in the presence of Gaussian noise. Through\nrigorous Monte-Carlo simulation, the accuracy of widely used Gaussian\napproximation of decision variable Y is refuted. However, in this paper we show\nthat the so called Log-Pearson type-3 probability density function (LP3 pdf) is\nan excellent representation for the decision variable Y . Three distinguishable\nparameters of the LP3 pdf are obtained through analytical derivation of three\nmoments of the decision variable Y . Furthermore, toward a more realistic\nmodel, in addition to ASE Gaussian noise, the effects of shot and thermal\nnoises are also included. Finally, using the presented analytical approach, it\nis shown that power-cubic preprocessor outperforms its quadratic counterparts,\ni.e., Second Harmonic Generation (SHG) and Two Photon Absorption (TPA) devices,\nin high power regime where shot and thermal noises can be neglected. \n\n"}
{"id": "1412.6135", "contents": "Title: Multi-Scale Stochastic Simulation for Diffusive Molecular Communication Abstract: Recently, hybrid models have emerged that combine microscopic and mesoscopic\nregimes in a single stochastic reaction-diffusion simulation. Microscopic\nsimulations track every individual molecule and are generally more accurate.\nMesoscopic simulations partition the environment into subvolumes, track when\nmolecules move between adjacent subvolumes, and are generally more\ncomputationally efficient. In this paper, we present the foundation of a\nmulti-scale stochastic simulator from the perspective of molecular\ncommunication, for both mesoscopic and hybrid models, where we emphasize\nsimulation accuracy at the receiver and efficiency in regions that are far from\nthe communication link. Our multi-scale models use subvolumes of different\nsizes, between which we derive the diffusion event transition rate. Simulation\nresults compare the accuracy and efficiency of traditional approaches with that\nof a regular hybrid method and with those of our proposed multi-scale methods. \n\n"}
{"id": "1412.6677", "contents": "Title: System Architecture and Key Technologies for 5G Heterogeneous Cloud\n  Radio Access Networks Abstract: Compared with the fourth generation (4G) cellular systems, the fifth\ngeneration wireless communication systems (5G) are anticipated to provide\nspectral and energy efficiency growth by a factor of at least 10, and the area\nthroughput growth by a factor of at least 25. To achieve these goals, a\nheterogeneous cloud radio access network (H-CRAN) is presented in this article\nas the advanced wireless access network paradigm, where cloud computing is used\nto fulfill the centralized large-scale cooperative processing for suppressing\nco-channel interferences. The state-of-the-art research achievements in aspects\nof system architecture and key technologies for H-CRANs are surveyed.\nParticularly, Node C as a new communication entity is defined to converge the\nexisting ancestral base stations and act as the base band unit (BBU) pool to\nmanage all accessed remote radio heads (RRHs), and the software-defined H-CRAN\nsystem architecture is presented to be compatible with software-defined\nnetworks (SDN). The principles, performance gains and open issues of key\ntechnologies including adaptive large-scale cooperative spatial signal\nprocessing, cooperative radio resource management, network function\nvirtualization, and self-organization are summarized. The major challenges in\nterms of fronthaul constrained resource allocation optimization and energy\nharvesting that may affect the promotion of H-CRANs are discussed as well. \n\n"}
{"id": "1412.6946", "contents": "Title: Probability Estimates for Fading and Wiretap Channels from Ideal Class\n  Zeta Functions Abstract: In this paper, new probability estimates are derived for ideal lattice codes\nfrom totally real number fields using ideal class Dedekind zeta functions. In\ncontrast to previous work on the subject, it is not assumed that the ideal in\nquestion is principal. In particular, it is shown that the corresponding\ninverse norm sum depends not only on the regulator and discriminant of the\nnumber field, but also on the values of the ideal class Dedekind zeta\nfunctions. Along the way, we derive an estimate of the number of elements in a\ngiven ideal with a certain algebraic norm within a finite hypercube. We provide\nseveral examples which measure the accuracy and predictive ability of our\ntheorems. \n\n"}
{"id": "1501.00035", "contents": "Title: Massive MIMO testbed - Implementation and Initial Results in System\n  Model Validation Abstract: This paper presents the design and implementation of a novel SDR based\nmassive MIMO testbed with up to 70 nodes built at Tennessee Technological\nUniversity. The deployment can reach a $30 \\times 30$ antenna MIMO scheme. With\nthis testbed, we are able to measure the channel matrix and compute the\nachievable rate of the massive MIMO system using experimental data. The\nmeasured channel capacity is linearly increasing with the number of antennas of\nthe base station. We also demonstrate the channel reciprocity including the\ncircuits impact from the transmitter and receiver. We show that the Vandermonde\nchannel model is more realistic to describe the massive MIMO architecture than\nthe widely used Gaussian channel model, in terms of capacity. By adjusting the\nrange for angle of arrival $\\alpha$ and the base station antenna distance $d$\nduring the simulation, we find out the Vandermonde model agrees with our\nmeasured capacity at a certain $\\alpha$ for each selected $d$ and the $\\alpha$\nis very close to that of the experiment deployment. It is the first time that\nthe feasibility of Vandermonde channel model is demonstrated by the experiment\nfor massive MIMO. \n\n"}
{"id": "1501.01742", "contents": "Title: LDPC Coded Modulation with Probabilistic Shaping for Optical Fiber\n  Systems Abstract: An LDPC coded modulation scheme with probabilistic shaping, optimized\ninterleavers and noniterative demapping is proposed. Full-field simulations\nshow an increase in transmission distance by 8% compared to uniformly\ndistributed input. \n\n"}
{"id": "1501.02046", "contents": "Title: Multiuser MIMO Wireless Energy Transfer With Coexisting Opportunistic\n  Communication Abstract: This letter considers spectrum sharing between a primary multiuser\nmultiple-input multiple-output (MIMO) wireless energy transfer (WET) system and\na coexisting secondary point-to-point MIMO wireless information transmission\n(WIT) system, where WET generates interference to WIT and degrades its\nthroughput performance. We show that due to the interference, the WIT system\nsuffers from a loss of the degrees of freedom (DoF) proportional to the number\nof energy beams sent by the energy transmitter (ET), which, in general, needs\nto be larger than one in order to optimize the multiuser WET with user fairness\nconsideration. To minimize the DoF loss in WIT, we further propose a new\nsingle-beam energy transmission scheme based on the principle of time sharing,\nwhere the ET transmits one of the optimal energy beams at each time. This new\nscheme achieves the same optimal performance for the WET system, and minimizes\nthe impact of its interference to the WIT system. \n\n"}
{"id": "1501.02419", "contents": "Title: Delay Minimizing User Association in Cellular Networks via\n  Hierarchically Well-Separated Trees Abstract: We study downlink delay minimization within the context of cellular user\nassociation policies that map mobile users to base stations. We note the delay\nminimum user association problem fits within a broader class of network utility\nmaximization and can be posed as a non-convex quadratic program. This\nnon-convexity motivates a split quadratic objective function that captures the\noriginal problem's inherent tradeoff: association with a station that provides\nthe highest signal-to-interference-plus-noise ratio (SINR) vs. a station that\nis least congested. We find the split-term formulation is amenable to\nlinearization by embedding the base stations in a hierarchically well-separated\ntree (HST), which offers a linear approximation with constant distortion. We\nprovide a numerical comparison of several problem formulations and find that\nwith appropriate optimization parameter selection, the quadratic reformulation\nproduces association policies with sum delays that are close to that of the\noriginal network utility maximization. We also comment on the more difficult\nproblem when idle base stations (those without associated users) are\ndeactivated. \n\n"}
{"id": "1501.02473", "contents": "Title: A Comparative Study of Polar Code Constructions for the AWGN Channel Abstract: We present a comparative study of the performance of various polar code\nconstructions in an additive white Gaussian noise (AWGN) channel. A polar code\nconstruction is any algorithm that selects $K$ best among $N$ possible polar\nbit-channels at the design signal-to-noise-ratio (design-SNR) in terms of bit\nerror rate (BER). Optimal polar code construction is hard and therefore many\nsuboptimal polar code constructions have been proposed at different\ncomputational complexities. Polar codes are also non-universal meaning the code\nchanges significantly with the design-SNR. However, it is not known which\nconstruction algorithm at what design-SNR constructs the best polar codes. We\nfirst present a comprehensive survey of all the well-known polar code\nconstructions along with their full implementations. We then propose a\nheuristic algorithm to find the best design-SNR for constructing best possible\npolar codes from a given construction algorithm. The proposed algorithm\ninvolves a search among several possible design-SNRs. We finally use our\nalgorithm to perform a comparison of different construction algorithms using\nextensive simulations. We find that all polar code construction algorithms\ngenerate equally good polar codes in an AWGN channel, if the design-SNR is\noptimized. \n\n"}
{"id": "1501.03407", "contents": "Title: User Association in Massive MIMO HetNets Abstract: Massive MIMO and small cell are both recognized as the key technologies for\nthe future 5G wireless systems. In this paper, we investigate the problem of\nuser association in a heterogeneous network (HetNet) with massive MIMO and\nsmall cells, where the macro base station (BS) is equipped with a massive MIMO\nand the picocell BS's are equipped with regular MIMOs. We first develop\ncentralized user association algorithms with proven optimality, considering\nvarious objectives such as rate maximization, proportional fairness, and joint\nuser association and resource allocation. We then model the massive MIMO HetNet\nas a repeated game, which leads to distributed user association algorithms with\nproven convergence to the Nash Equilibrium (NE). We demonstrate the efficacy of\nthese optimal schemes by comparison with several greedy algorithms through\nsimulations. \n\n"}
{"id": "1501.04703", "contents": "Title: Graph-based Framework for Flexible Baseband Function Splitting and\n  Placement in C-RAN Abstract: The baseband-up centralization architecture of radio access networks (C-RAN)\nhas recently been proposed to support efficient cooperative communications and\nreduce deployment and operational costs. However, the massive fronthaul\nbandwidth required to aggregate baseband samples from remote radio heads (RRHs)\nto the central office incurs huge fronthauling cost, and existing baseband\ncompression algorithms can hardly solve this issue. In this paper, we propose a\ngraphbased framework to effectively reduce fronthauling cost through properly\nsplitting and placing baseband processing functions in the network. Baseband\ntransceiver structures are represented with directed graphs, in which nodes\ncorrespond to baseband functions, and edges to the information flows between\nfunctions. By mapping graph weighs to computational and fronthauling costs, we\ntransform the problem of finding the optimum location to place some baseband\nfunctions into the problem of finding the optimum clustering scheme for graph\nnodes. We then solve this problem using a genetic algorithm with customized\nfitness function and mutation module. Simulation results show that proper\nsplitting and placement schemes can significantly reduce fronthauling cost at\nthe expense of increased computational cost. We also find that cooperative\nprocessing structures and stringent delay requirements will increase the\npossibility of centralized placement. \n\n"}
{"id": "1501.04721", "contents": "Title: Two-Stage Subspace Constrained Precoding in Massive MIMO Cellular\n  Systems Abstract: We propose a subspace constrained precoding scheme that exploits the spatial\nchannel correlation structure in massive MIMO cellular systems to fully unleash\nthe tremendous gain provided by massive antenna array with reduced channel\nstate information (CSI) signaling overhead. The MIMO precoder at each base\nstation (BS) is partitioned into an inner precoder and a Transmit (Tx) subspace\ncontrol matrix. The inner precoder is adaptive to the local CSI at each BS for\nspatial multiplexing gain. The Tx subspace control is adaptive to the channel\nstatistics for inter-cell interference mitigation and Quality of Service (QoS)\noptimization. Specifically, the Tx subspace control is formulated as a QoS\noptimization problem which involves an SINR chance constraint where the\nprobability of each user's SINR not satisfying a service requirement must not\nexceed a given outage probability. Such chance constraint cannot be handled by\nthe existing methods due to the two stage precoding structure. To tackle this,\nwe propose a bi-convex approximation approach, which consists of three key\ningredients: random matrix theory, chance constrained optimization and\nsemidefinite relaxation. Then we propose an efficient algorithm to find the\noptimal solution of the resulting bi-convex approximation problem. Simulations\nshow that the proposed design has significant gain over various baselines. \n\n"}
{"id": "1501.04775", "contents": "Title: Interference Aligned Space-Time Transmission with Diversity for the $2\n  \\times 2$ X-Network Abstract: The sum degrees of freedom (DoF) of the two-transmitter, two-receiver\nmultiple-input multiple-output (MIMO) X-Network ($2 \\times 2$ MIMO X-Network)\nwith $M$ antennas at each node is known to be $\\frac{4M}{3}$. Transmission\nschemes which couple local channel-state-information-at-the-transmitter (CSIT)\nbased precoding with space-time block coding to achieve the sum-DoF of this\nnetwork are known specifically for $M=2,4$. These schemes have been proven to\nguarantee a diversity gain of $M$ when a finite-sized input constellation is\nemployed. In this paper, an explicit transmission scheme that achieves the\n$\\frac{4M}{3}$ sum-DoF of the $2 \\times 2$ X-Network for arbitrary $M$ is\npresented. The proposed scheme needs only local CSIT unlike the Jafar-Shamai\nscheme which requires the availability of global CSIT in order to achieve the\n$\\frac{4M}{3}$ sum-DoF. Further, it is shown analytically that the proposed\nscheme guarantees a diversity gain of $M+1$ when finite-sized input\nconstellations are employed. \n\n"}
{"id": "1501.05683", "contents": "Title: Polar Lattices for Lossy Compression Abstract: Polar lattices, which are constructed from polar codes, have recently been\nproved to be able to achieve the capacity of the additive white Gaussian noise\n(AWGN) channel. In this work, we propose a new construction of polar lattices\nto solve the dual problem, i.e., achieving the rate-distortion bound of a\nmemoryless Gaussian source, which means that polar lattices can also be good\nfor the lossy compression of continuous sources. The structure of the proposed\npolar lattices enables us to integrate the post-entropy coding process into the\nlattice quantizer, which simplifies the quantization process. The overall\ncomplexity of encoding and decoding complexity is $O(N \\log^2 N)$ for a\nsub-exponentially decaying excess distortion. Moreover, the nesting structure\nof polar lattices further provides solutions for some multi-terminal coding\nproblems. The Wyner-Ziv coding problem for a Gaussian source can be solved by\nan AWGN capacity-achieving polar lattice nested in a rate-distortion bound\nachieving one, and the Gelfand-Pinsker problem can be solved in a reversed\nmanner. \n\n"}
{"id": "1501.06076", "contents": "Title: Fourier Analysis of MAC Polarization Abstract: One problem with MAC polar codes that are based on MAC polarization is that\nthey may not achieve the entire capacity region. The reason behind this problem\nis that MAC polarization sometimes induces a loss in the capacity region. This\npaper provides a single letter necessary and sufficient condition which\ncharacterizes all the MACs that do not lose any part of their capacity region\nby polarization. \n\n"}
{"id": "1501.06683", "contents": "Title: Codes With Hierarchical Locality Abstract: In this paper, we study the notion of {\\em codes with hierarchical locality}\nthat is identified as another approach to local recovery from multiple\nerasures. The well-known class of {\\em codes with locality} is said to possess\nhierarchical locality with a single level. In a {\\em code with two-level\nhierarchical locality}, every symbol is protected by an inner-most local code,\nand another middle-level code of larger dimension containing the local code. We\nfirst consider codes with two levels of hierarchical locality, derive an upper\nbound on the minimum distance, and provide optimal code constructions of low\nfield-size under certain parameter sets. Subsequently, we generalize both the\nbound and the constructions to hierarchical locality of arbitrary levels. \n\n"}
{"id": "1501.06851", "contents": "Title: Distributed Power Allocations in Heterogeneous Networks with Dual\n  Connectivity using Backhaul State Information Abstract: LTE release 12 proposes the use of dual connectivity in heterogeneous\ncellular networks, where a user equipment (UE) maintains parallel connections\nto a macro-cell node (base station) and to a low-tier node (pico base station\nor relay). In this paper, we propose a distributed multi-objective power\ncontrol scheme where each UE independently adapts its transmit power on its\ndual connections, possibly of unequal bandwidth, with non-ideal backhaul links.\nIn the proposed scheme, the UEs can dynamically switch their objectives between\ndata rate maximization and transmit power minimization as the backhaul load\nvaries. Given the coupling between interference and the backhaul load, we\npropose a low-overhead convergence mechanism which does not require explicit\ncoordination between autonomous nodes and also derive a closed-form expression\nof the transmit power levels at equilibrium. We illustrate a higher aggregate\nend-to-end data rate and significant power saving for our scheme over when the\noptimization is implemented through a greedy algorithm or when UEs only perform\nwaterfilling. \n\n"}
{"id": "1502.00714", "contents": "Title: Exploiting the Preferred Domain of FDD Massive MIMO Systems with Uniform\n  Planar Arrays Abstract: Massive multiple-input multiple-output (MIMO) systems hold the potential to\nbe an enabling technology for 5G cellular. Uniform planar array (UPA) antenna\nstructures are a focus of much commercial discussion because of their ability\nto enable a large number of antennas in a relatively small area. With UPA\nantenna structures, the base station can control the beam direction in both the\nhorizontal and vertical domains simultaneously. However, channel conditions may\ndictate that one dimension requires higher channel state information (CSI)\naccuracy than the other. We propose the use of an additional one bit of\nfeedback information sent from the user to the base station to indicate the\npreferred domain on top of the feedback overhead of CSI quantization in\nfrequency division duplexing (FDD) massive MIMO systems. Combined with\nvariable-rate CSI quantization schemes, the numerical studies show that the\nadditional one bit of feedback can increase the quality of CSI significantly\nfor UPA antenna structures. \n\n"}
{"id": "1502.02925", "contents": "Title: On the Finite Length Scaling of Ternary Polar Codes Abstract: The polarization process of polar codes over a ternary alphabet is studied.\nRecently it has been shown that the scaling of the blocklength of polar codes\nwith prime alphabet size scales polynomially with respect to the inverse of the\ngap between code rate and channel capacity. However, except for the binary\ncase, the degree of the polynomial in the bound is extremely large. In this\nwork, it is shown that a much lower degree polynomial can be computed\nnumerically for the ternary case. Similar results are conjectured for the\ngeneral case of prime alphabet size. \n\n"}
{"id": "1502.02973", "contents": "Title: A Distributed Tracking Algorithm for Reconstruction of Graph Signals Abstract: The rapid development of signal processing on graphs provides a new\nperspective for processing large-scale data associated with irregular domains.\nIn many practical applications, it is necessary to handle massive data sets\nthrough complex networks, in which most nodes have limited computing power.\nDesigning efficient distributed algorithms is critical for this task. This\npaper focuses on the distributed reconstruction of a time-varying bandlimited\ngraph signal based on observations sampled at a subset of selected nodes. A\ndistributed least square reconstruction (DLSR) algorithm is proposed to recover\nthe unknown signal iteratively, by allowing neighboring nodes to communicate\nwith one another and make fast updates. DLSR uses a decay scheme to annihilate\nthe out-of-band energy occurring in the reconstruction process, which is\ninevitably caused by the transmission delay in distributed systems. Proof of\nconvergence and error bounds for DLSR are provided in this paper, suggesting\nthat the algorithm is able to track time-varying graph signals and perfectly\nreconstruct time-invariant signals. The DLSR algorithm is numerically\nexperimented with synthetic data and real-world sensor network data, which\nverifies its ability in tracking slowly time-varying graph signals. \n\n"}
{"id": "1502.03124", "contents": "Title: Order-Optimal Rate of Caching and Coded Multicasting with Random Demands Abstract: We consider the canonical {\\em shared link network} formed by a source node,\nhosting a library of $m$ information messages (files), connected via a\nnoiseless common link to $n$ destination nodes (users), each with a cache of\nsize M files. Users request files at random and independently, according to a\ngiven a-priori demand distribution $\\qv$. A coding scheme for this network\nconsists of a caching placement (i.e., a mapping of the library files into the\nuser caches) and delivery scheme (i.e., a mapping for the library files and\nuser demands into a common multicast codeword) such that, after the codeword\ntransmission, all users can retrieve their requested file. The rate of the\nscheme is defined as the {\\em average} codeword length normalized with respect\nto the length of one file, where expectation is taken over the random user\ndemands. For the same shared link network, in the case of deterministic\ndemands, the optimal min-max rate has been characterized within a uniform\nbound, independent of the network parameters. In particular, fractional caching\n(i.e., storing file segments) and using linear network coding has been shown to\nprovide a min-max rate reduction proportional to 1/M with respect to standard\nschemes such as unicasting or \"naive\" uncoded multicasting. The case of random\ndemands was previously considered by applying the same order-optimal min-max\nscheme separately within groups of files requested with similar probability.\nHowever, no order-optimal guarantee was provided for random demands under the\naverage rate performance criterion. In this paper, we consider the random\ndemand setting and provide general achievability and converse results. In\nparticular, we consider a family of schemes that combine random fractional\ncaching according to a probability distribution $\\pv$ that depends on the\ndemand distribution $\\qv$, with a linear coded delivery scheme based on ... \n\n"}
{"id": "1502.03903", "contents": "Title: Coding for Network-Coded Slotted ALOHA Abstract: Slotted ALOHA can benefit from physical-layer network coding (PNC) by\ndecoding one or multiple linear combinations of the packets simultaneously\ntransmitted in a timeslot, forming a system of linear equations. Different\nsystems of linear equations are recovered in different timeslots. A message\ndecoder then recovers the original packets of all the users by jointly solving\nmultiple systems of linear equations obtained over different timeslots. We\npropose the batched BP decoding algorithm that combines belief propagation (BP)\nand local Gaussian elimination. Compared with pure Gaussian elimination\ndecoding, our algorithm reduces the decoding complexity from cubic to linear\nfunction of the number of users. Compared with the ordinary BP decoding\nalgorithm for low-density generator-matrix codes, our algorithm has better\nperformance and the same order of computational complexity. We analyze the\nperformance of the batched BP decoding algorithm by generalizing the tree-based\napproach and provide an approach to optimize the system performance. \n\n"}
{"id": "1502.04169", "contents": "Title: Computationally Tractable Algorithms for Finding a Subset of\n  Non-defective Items from a Large Population Abstract: In the classical non-adaptive group testing setup, pools of items are tested\ntogether, and the main goal of a recovery algorithm is to identify the\n\"complete defective set\" given the outcomes of different group tests. In\ncontrast, the main goal of a \"non-defective subset recovery\" algorithm is to\nidentify a \"subset\" of non-defective items given the test outcomes. In this\npaper, we present a suite of computationally efficient and analytically\ntractable non-defective subset recovery algorithms. By analyzing the\nprobability of error of the algorithms, we obtain bounds on the number of tests\nrequired for non-defective subset recovery with arbitrarily small probability\nof error. Our analysis accounts for the impact of both the additive noise\n(false positives) and dilution noise (false negatives). By comparing with the\ninformation theoretic lower bounds, we show that the upper bounds on the number\nof tests are order-wise tight up to a $\\log^2K$ factor, where $K$ is the number\nof defective items. We also provide simulation results that compare the\nrelative performance of the different algorithms and provide further insights\ninto their practical utility. The proposed algorithms significantly outperform\nthe straightforward approaches of testing items one-by-one, and of first\nidentifying the defective set and then choosing the non-defective items from\nthe complement set, in terms of the number of measurements required to ensure a\ngiven success rate. \n\n"}
{"id": "1502.04262", "contents": "Title: Information flow through a model of the C. elegans klinotaxis circuit Abstract: Understanding how information about external stimuli is transformed into\nbehavior is one of the central goals of neuroscience. Here we characterize the\ninformation flow through a complete sensorimotor circuit: from stimulus, to\nsensory neurons, to interneurons, to motor neurons, to muscles, to motion.\nSpecifically, we apply a recently developed framework for quantifying\ninformation flow to a previously published ensemble of models of salt\nklinotaxis in the nematode worm C. elegans. The models are grounded in the\nneuroanatomy and currently known neurophysiology of the worm. The unknown model\nparameters were optimized to reproduce the worm's behavior. Information flow\nanalysis reveals several key principles underlying how the models operate: (1)\nInterneuron class AIY is responsible for integrating information about positive\nand negative changes in concentration, and exhibits a strong left/right\ninformation asymmetry. (2) Gap junctions play a crucial role in the transfer of\ninformation responsible for the information symmetry observed in interneuron\nclass AIZ. (3) Neck motor neuron class SMB implements an information gating\nmechanism that underlies the circuit's state-dependent response. (4) The neck\ncarries non-uniform distribution about changes in concentration. Thus, not all\ndirections of movement are equally informative. Each of these findings\ncorresponds to an experimental prediction that could be tested in the worm to\ngreatly refine our understanding of the neural circuit underlying klinotaxis.\nInformation flow analysis also allows us to explore how information flow\nrelates to underlying electrophysiology. Despite large variations in the neural\nparameters of individual circuits, the overall information flow architecture\ncircuit is remarkably consistent across the ensemble, suggesting that\ninformation flow analysis captures general principles of operation for the\nklinotaxis circuit. \n\n"}
{"id": "1502.04806", "contents": "Title: On the Noisy Feedback Capacity of Gaussian Broadcast Channels Abstract: It is well known that, in general, feedback may enlarge the capacity region\nof Gaussian broadcast channels. This has been demonstrated even when the\nfeedback is noisy (or partial-but-perfect) and only from one of the receivers.\nThe only case known where feedback has been shown not to enlarge the capacity\nregion is when the channel is physically degraded (El Gamal 1978, 1981). In\nthis paper, we show that for a class of two-user Gaussian broadcast channels\n(not necessarily physically degraded), passively feeding back the stronger\nuser's signal over a link corrupted by Gaussian noise does not enlarge the\ncapacity region if the variance of feedback noise is above a certain threshold. \n\n"}
{"id": "1502.05789", "contents": "Title: Location Identification of Power Line Outages Using PMU Measurements\n  with Bad Data Abstract: The use of phasor angle measurements provided by phasor measurement units\n(PMUs) in fault detection is regarded as a promising method in identifying\nlocations of power line outages. However, communication errors or system\nmalfunctions may introduce errors to the measurements and thus yield bad data.\nMost of the existing methods on line outage identification fail to consider\nsuch error. This paper develops a framework for identifying multiple power line\noutages based on the PMUs' measurements in the presence of bad data. In\nparticular, we design an algorithm to identify locations of line outage and\nrecover the faulty measurements simultaneously. The proposed algorithm does not\nrequire any prior information on the number of line outages and the noise\nvariance. Case studies carried out on test systems of different sizes validate\nthe effectiveness and efficiency of the proposed approach. \n\n"}
{"id": "1502.06601", "contents": "Title: Optimization-Based Linear Network Coding for General Connections of\n  Continuous Flows Abstract: For general connections, the problem of finding network codes and optimizing\nresources for those codes is intrinsically difficult and little is known about\nits complexity. Most of the existing solutions rely on very restricted classes\nof network codes in terms of the number of flows allowed to be coded together,\nand are not entirely distributed. In this paper, we consider a new method for\nconstructing linear network codes for general connections of continuous flows\nto minimize the total cost of edge use based on mixing. We first formulate the\nminimumcost network coding design problem. To solve the optimization problem,\nwe propose two equivalent alternative formulations with discrete mixing and\ncontinuous mixing, respectively, and develop distributed algorithms to solve\nthem. Our approach allows fairly general coding across flows and guarantees no\ngreater cost than any solution without network coding. \n\n"}
{"id": "1502.06899", "contents": "Title: Towards a Tractable Analysis of Localization Fundamentals in Cellular\n  Networks Abstract: When dedicated positioning systems, such as GPS, are unavailable, a mobile\ndevice has no choice but to fall back on its cellular network for localization.\nDue to random variations in the channel conditions to its surrounding base\nstations (BS), the mobile device is likely to face a mix of both favorable and\nunfavorable geometries for localization. Analytical studies of localization\nperformance (e.g., using the Cram\\'{e}r-Rao lower bound) usually require that\none fix the BS geometry, and favorable geometries have always been the\npreferred choice in the literature. However, not only are the resulting\nanalytical results constrained to the selected geometry, this practice is\nlikely to lead to overly-optimistic expectations of typical localization\nperformance. Ideally, localization performance should be studied across all\npossible geometric setups, thereby also removing any selection bias. This,\nhowever, is known to be hard and has been carried out only in simulation. In\nthis paper, we develop a new tractable approach where we endow the BS locations\nwith a distribution by modeling them as a Poisson point process (PPP), and use\ntools from stochastic geometry to obtain easy-to-use expressions for key\nperformance metrics. In particular, we focus on the probability of detecting\nsome minimum number of BSs, which is shown to be closely coupled with a network\noperator's ability to obtain satisfactory localization performance (e.g., meet\nFCC E911 requirements). This metric is indifferent to the localization\ntechnique (e.g., TOA, TDOA, AOA, or hybrids thereof), though different\ntechniques will presumably lead to different BS hearability requirements. In\norder to mitigate excessive interference due to the presence of dominant\ninterferers in the form of other BSs, we incorporate both BS coordination and\nfrequency reuse in the proposed framework and quantify the resulting\nperformance gains analytically. \n\n"}
{"id": "1502.06945", "contents": "Title: New extremal binary self-dual codes of lengths 66 and 68 from codes over\n  r_k,m Abstract: In this work, four circulant and quadratic double circulant (QDC)\nconstructions are applied to the family of the rings R_k,m. Self-dual binary\ncodes are obtained as the Gray images of self-dual QDC codes over R_k,m.\nExtremal binary self-dual codes of length 64 are obtained as Gray images of\n?-four circulant codes over R_2,1 and R_2,2. Extremal binary self-dual codes of\nlengths 66 and 68 are constructed by applying extension theorems to the F_2 and\nR_2,1 images of these codes. More precisely, 11 new codes of length 66 and 39\nnew codes of length 68 are discovered. The codes with these weight enumerators\nare constructed for the first time in literature. The results are tabulated. \n\n"}
{"id": "1502.07966", "contents": "Title: Delay-Aware Uplink Fronthaul Allocation in Cloud Radio Access Networks Abstract: In cloud radio access networks (C-RANs), the baseband units and radio units\nof base stations are separated, which requires high-capacity fronthaul links\nconnecting both parts. In this paper, we consider the delay-aware fronthaul\nallocation problem for C-RANs. The stochastic optimization problem is\nformulated as an infinite horizon average cost Markov decision process. To deal\nwith the curse of dimensionality, we derive a closed-form approximate priority\nfunction and the associated error bound using perturbation analysis. Based on\nthe closed-form approximate priority function, we propose a low-complexity\ndelay-aware fronthaul allocation algorithm solving the per-stage optimization\nproblem. The proposed solution is further shown to be asymptotically optimal\nfor sufficiently small cross link path gains. Finally, the proposed fronthaul\nallocation algorithm is compared with various baselines through simulations,\nand it is shown that significant performance gain can be achieved. \n\n"}
{"id": "1503.00267", "contents": "Title: Distributed Cloud Association in Downlink Multicloud Radio Access\n  Networks Abstract: This paper considers a multicloud radio access network (M-CRAN), wherein each\ncloud serves a cluster of base-stations (BS's) which are connected to the\nclouds through high capacity digital links. The network comprises several\nremote users, where each user can be connected to one (and only one) cloud.\nThis paper studies the user-to-cloud-assignment problem by maximizing a\nnetwork-wide utility subject to practical cloud connectivity constraints. The\npaper solves the problem by using an auction-based iterative algorithm, which\ncan be implemented in a distributed fashion through a reasonable exchange of\ninformation between the clouds. The paper further proposes a centralized\nheuristic algorithm, with low computational complexity. Simulations results\nshow that the proposed algorithms provide appreciable performance improvements\nas compared to the conventional cloud-less assignment solutions. \n\n"}
{"id": "1503.00877", "contents": "Title: Modeling and Analysis of Wireless Channels via the Mixture of Gaussian\n  Distribution Abstract: Considerable efforts have been devoted to statistical modeling and the\ncharacterization of channels in a range of statistical models for fading\nchannels. In this paper, we consider a unified approach to model wireless\nchannels by the mixture of Gaussian (MoG) distribution. Simulations provided\nhave shown the new probability density function to accurately characterize\nmultipath fading as well as composite fading channels. We utilize the well\nknown expectation-maximization algorithm to estimate the parameters of the MoG\nmodel and further utilize the Kullback-Leibler divergence and the mean square\nerror criteria to demonstrate that our model provides both high accuracy and\nlow computational complexity, in comparison with existing results.\nAdditionally, we provide closed form expressions for several performance\nmetrics used in wireless communication systems, including the moment generating\nfunction, the raw moments, the amount of fading, the outage probability, the\naverage channel capacity, and the probability of energy detection for cognitive\nradio. Numerical Analysis and Monte-Carlo simulations are presented to\ncorroborate the analytical results and to provide detailed performance\ncomparisons with the other models in the literature. \n\n"}
{"id": "1503.01570", "contents": "Title: A proof of the Shepp-Olkin entropy concavity conjecture Abstract: We prove the Shepp--Olkin conjecture, which states that the entropy of the\nsum of independent Bernoulli random variables is concave in the parameters of\nthe individual random variables. Our proof is a refinement of an argument\npreviously presented by the same authors, which resolved the conjecture in the\nmonotonic case (where all the parameters are simultaneously increasing). In\nfact, we show that the monotonic case is the worst case, using a careful\nanalysis of concavity properties of the derivatives of the probability mass\nfunction. We propose a generalization of Shepp and Olkin's original conjecture,\nto consider Renyi and Tsallis entropies. \n\n"}
{"id": "1503.02339", "contents": "Title: Multiple and single snapshot compressive beamforming Abstract: For a sound field observed on a sensor array, compressive sensing (CS)\nreconstructs the direction-of-arrival (DOA) of multiple sources using a\nsparsity constraint. The DOA estimation is posed as an underdetermined problem\nby expressing the acoustic pressure at each sensor as a phase-lagged\nsuperposition of source amplitudes at all hypothetical DOAs. Regularizing with\nan $\\ell_1$-norm constraint renders the problem solvable with convex\noptimization, and promoting sparsity gives high-resolution DOA maps. Here, the\nsparse source distribution is derived using maximum a posteriori (MAP)\nestimates for both single and multiple snapshots. CS does not require inversion\nof the data covariance matrix and thus works well even for a single snapshot\nwhere it gives higher resolution than conventional beamforming. For multiple\nsnapshots, CS outperforms conventional high-resolution methods, even with\ncoherent arrivals and at low signal-to-noise ratio. The superior resolution of\nCS is demonstrated with vertical array data from the SWellEx96 experiment for\ncoherent multi-paths. \n\n"}
{"id": "1503.04604", "contents": "Title: Multi-Antenna Wireless Energy Transfer for Backscatter Communication\n  Systems Abstract: We study RF-enabled wireless energy transfer (WET) via energy beamforming,\nfrom a multi-antenna energy transmitter (ET) to multiple energy receivers (ERs)\nin a backscatter communication system, such as RFID, where each ER (or RFID\ntag) reflects back a portion of the incident signal to the ET (or RFID reader).\nFor such a system, the acquisition of the forward-channel (i.e., ET-to-ER)\nstate information (F-CSI) at the ET is challenging, since the ERs are typically\ntoo energy-and-hardware-constrained to estimate or feed back the F-CSI. The ET\nleverages its observed backscatter signals to estimate the backscatter-channel\n(i.e., ET-to-ER-to-ET) state information (BS-CSI) directly. We first analyze\nthe harvested energy obtained by using the estimated BS-CSI. Furthermore, we\noptimize the channel-training energy and the energy allocation weights for\ndifferent energy beams, for weighted-sum-energy (WSE) maximization and\nproportional-fair-energy (PFE) maximization. For WET to single ER, we obtain\nthe optimal channel-training energy in a semi-closed form. For WET to multiple\nERs, the optimal WET scheme for WSE maximization is shown to use only one\nenergy beam. For PFE maximization, we show it is a biconvex problem, and\npropose a block-coordinate-descent based algorithm to find the close-to-optimal\nsolution. Numerical results show that with the optimized solutions, the\nharvested energy suffers slight reduction of less than 10%, compared to that\nobtained by using the perfect F-CSI. Hence, energy beamforming by using the\nestimated BS-CSI is promising, as the complexity and energy requirement is\nshifted from the ERs to the ET. \n\n"}
{"id": "1503.05113", "contents": "Title: Quantifying Morphological Computation based on an Information\n  Decomposition of the Sensorimotor Loop Abstract: The question how an agent is affected by its embodiment has attracted growing\nattention in recent years. A new field of artificial intelligence has emerged,\nwhich is based on the idea that intelligence cannot be understood without\ntaking into account embodiment. We believe that a formal approach to\nquantifying the embodiment's effect on the agent's behaviour is beneficial to\nthe fields of artificial life and artificial intelligence. The contribution of\nan agent's body and environment to its behaviour is also known as morphological\ncomputation. Therefore, in this work, we propose a quantification of\nmorphological computation, which is based on an information decomposition of\nthe sensorimotor loop into shared, unique and synergistic information. In\nnumerical simulation based on a formal representation of the sensorimotor loop,\nwe show that the unique information of the body and environment is a good\nmeasure for morphological computation. The results are compared to our\npreviously derived quantification of morphological computation. \n\n"}
{"id": "1503.05365", "contents": "Title: Caching at the Edge: a Green Perspective for 5G Networks Abstract: Endowed with context-awareness and proactive capabilities, caching users'\ncontent locally at the edge of the network is able to cope with increasing data\ntraffic demand in 5G wireless networks. In this work, we focus on the energy\nconsumption aspects of cache-enabled wireless cellular networks, specifically\nin terms of area power consumption (APC) and energy efficiency (EE). We assume\nthat both base stations (BSs) and mobile users are distributed according to\nhomogeneous Poisson point processes (PPPs) and we introduce a detailed power\nmodel that takes into account caching. We study the conditions under which the\narea power consumption is minimized with respect to BS transmit power, while\nensuring a certain quality of service (QoS) in terms of coverage probability.\nFurthermore, we provide the optimal BS transmit power that maximizes the area\nspectral efficiency per unit total power spent. The main takeaway of this paper\nis that caching seems to be an energy efficient solution. \n\n"}
{"id": "1503.05448", "contents": "Title: A Transfer Learning Approach for Cache-Enabled Wireless Networks Abstract: Locally caching contents at the network edge constitutes one of the most\ndisruptive approaches in $5$G wireless networks. Reaping the benefits of edge\ncaching hinges on solving a myriad of challenges such as how, what and when to\nstrategically cache contents subject to storage constraints, traffic load,\nunknown spatio-temporal traffic demands and data sparsity. Motivated by this,\nwe propose a novel transfer learning-based caching procedure carried out at\neach small cell base station. This is done by exploiting the rich contextual\ninformation (i.e., users' content viewing history, social ties, etc.) extracted\nfrom device-to-device (D2D) interactions, referred to as source domain. This\nprior information is incorporated in the so-called target domain where the goal\nis to optimally cache strategic contents at the small cells as a function of\nstorage, estimated content popularity, traffic load and backhaul capacity. It\nis shown that the proposed approach overcomes the notorious data sparsity and\ncold-start problems, yielding significant gains in terms of users'\nquality-of-experience (QoE) and backhaul offloading, with gains reaching up to\n$22\\%$ in a setting consisting of four small cell base stations. \n\n"}
{"id": "1503.06675", "contents": "Title: The Fourier Decomposition Method for nonlinear and nonstationary time\n  series analysis Abstract: Since many decades, there is a general perception in literature that the\nFourier methods are not suitable for the analysis of nonlinear and\nnonstationary data. In this paper, we propose a Fourier Decomposition Method\n(FDM) and demonstrate its efficacy for the analysis of nonlinear (i.e. data\ngenerated by nonlinear systems) and nonstationary time series. The proposed FDM\ndecomposes any data into a small number of `Fourier intrinsic band functions'\n(FIBFs). The FDM presents a generalized Fourier expansion with variable\namplitudes and frequencies of a time series by the Fourier method itself. We\npropose an idea of zero-phase filter bank based multivariate FDM (MFDM)\nalgorithm, for the analysis of multivariate nonlinear and nonstationary time\nseries, from the FDM. We also present an algorithm to obtain cutoff frequencies\nfor MFDM. The MFDM algorithm is generating finite number of band limited\nmultivariate FIBFs (MFIBFs). The MFDM preserves some intrinsic physical\nproperties of the multivariate data, such as scale alignment, trend and\ninstantaneous frequency. The proposed methods produce the results in a\ntime-frequency-energy distribution that reveal the intrinsic structures of a\ndata. Simulations have been carried out and comparison is made with the\nEmpirical Mode Decomposition (EMD) methods in the analysis of various simulated\nas well as real life time series, and results show that the proposed methods\nare powerful tools for analyzing and obtaining the time-frequency-energy\nrepresentation of any data. \n\n"}
{"id": "1503.07455", "contents": "Title: Sum Secrecy Rate in MISO Full-Duplex Wiretap Channel with Imperfect CSI Abstract: In this paper, we consider the achievable sum secrecy rate in MISO\n(multiple-input-single-output) {\\em full-duplex} wiretap channel in the\npresence of a passive eavesdropper and imperfect channel state information\n(CSI). We assume that the users participating in full-duplex communication have\nmultiple transmit antennas, and that the users and the eavesdropper have single\nreceive antenna each. The users have individual transmit power constraints.\nThey also transmit jamming signals to improve the secrecy rates. We obtain the\nachievable perfect secrecy rate region by maximizing the worst case sum secrecy\nrate. We also obtain the corresponding transmit covariance matrices associated\nwith the message signals and the jamming signals. Numerical results that show\nthe impact of imperfect CSI on the achievable secrecy rate region are\npresented. \n\n"}
{"id": "1503.08627", "contents": "Title: Traffic Demand-Aware Topology Control for Enhanced Energy-Efficiency of\n  Cellular Networks Abstract: The service provided by mobile networks operated today is not adapted to\nspatio-temporal fluctuations in traffic demand, although such fluctuations\noffer opportunities for energy savings. In particular, significant gains in\nenergy efficiency are realizable by disengaging temporarily redundant hardware\ncomponents of base stations. We therefore propose a novel optimization\nframework that considers both the load-dependent energy radiated by the\nantennas and the remaining forms of energy needed for operating the base\nstations. The objective is to reduce the energy consumption of mobile networks,\nwhile ensuring that the data rate requirements of the users are met throughout\nthe coverage area. Building upon sparse optimization techniques, we develop a\nmajorization-minimization algorithm with the ability to identify\nenergy-efficient network configurations. The iterative algorithm is load-aware,\nhas low computational complexity, and can be implemented in an online fashion\nto exploit load fluctuations on a short time scale. Simulations show that the\nalgorithm can find network configurations with the energy consumption similar\nto that obtained with global optimization tools, which cannot be applied to\nreal large networks. Although we consider only one currently deployed cellular\ntechnology, the optimization framework is general, potentially applicable to a\nlarge class of access technologies. \n\n"}
{"id": "1503.08782", "contents": "Title: Robust Recovery of Positive Stream of Pulses Abstract: The problem of estimating the delays and amplitudes of a positive stream of\npulses appears in many applications, such as single-molecule microscopy. This\npaper suggests estimating the delays and amplitudes using a convex program,\nwhich is robust in the presence of noise (or model mismatch). Particularly, the\nrecovery error is proportional to the noise level. We further show that the\nerror grows exponentially with the density of the delays and also depends on\nthe localization properties of the pulse. \n\n"}
{"id": "1504.01123", "contents": "Title: Coded Caching with Heterogenous Cache Sizes Abstract: We investigate the coded caching scheme under heterogenous cache sizes. \n\n"}
{"id": "1504.02081", "contents": "Title: Hybrid Block Diagonalization for Massive Multiuser MIMO Systems Abstract: For a massive multiple-input multiple-output (MIMO) system, restricting the\nnumber of RF chains to far less than the number of antenna elements can\nsignificantly reduce the implementation cost compared to the full complexity RF\nchain configuration. In this paper, we consider the downlink communication of a\nmassive multiuser MIMO (MU-MIMO) system and propose a low-complexity hybrid\nblock diagonalization (Hy-BD) scheme to approach the capacity performance of\nthe traditional BD processing method. We aim to harvest the large array gain\nthrough the phase-only RF precoding and combining and then digital BD\nprocessing is performed on the equivalent baseband channel. The proposed Hy-BD\nscheme is examined in both the large Rayleigh fading channels and millimeter\nwave (mmWave) channels. A performance analysis is further conducted for\nsingle-path channels and large number of transmit and receive antennas.\nFinally, simulation results demonstrate that our Hy-BD scheme, with a lower\nimplementation and computational complexity, achieves a capacity performance\nthat is close to (sometimes even higher than) that of the traditional\nhigh-dimensional BD processing. \n\n"}
{"id": "1504.02530", "contents": "Title: Classifying Unrooted Gaussian Trees under Privacy Constraints Abstract: In this work, our objective is to find out how topological and algebraic\nproperties of unrooted Gaussian tree models determine their security\nrobustness, which is measured by our proposed max-min information (MaMI)\nmetric. Such metric quantifies the amount of common randomness extractable\nthrough public discussion between two legitimate nodes under an eavesdropper\nattack. We show some general topological properties that the desired max-min\nsolutions shall satisfy. Under such properties, we develop conditions under\nwhich comparable trees are put together to form partially ordered sets\n(posets). Each poset contains the most favorable structure as the poset leader,\nand the least favorable structure. Then, we compute the Tutte-like polynomial\nfor each tree in a poset in order to assign a polynomial to any tree in a\nposet. Moreover, we propose a novel method, based on restricted integer\npartitions, to effectively enumerate all poset leaders. The results not only\nhelp us understand the security strength of different Gaussian trees, which is\ncritical when we evaluate the information leakage issues for various jointly\nGaussian distributed measurements in networks, but also provide us both an\nalgebraic and a topological perspective in grasping some fundamental properties\nof such models. \n\n"}
{"id": "1504.03024", "contents": "Title: Almost Lossless Analog Compression without Phase Information Abstract: We propose an information-theoretic framework for phase retrieval.\nSpecifically, we consider the problem of recovering an unknown n-dimensional\nvector x up to an overall sign factor from m=Rn phaseless measurements with\ncompression rate R and derive a general achievability bound for R.\nSurprisingly, it turns out that this bound on the compression rate is the same\nas the one for almost lossless analog compression obtained by Wu and Verd\\'u\n(2010): Phaseless linear measurements are as good as linear measurements with\nfull phase information in the sense that ignoring the sign of m measurements\nonly leaves us with an ambiguity with respect to an overall sign factor of x. \n\n"}
{"id": "1504.03048", "contents": "Title: The weight distributions of two classes of p ary cyclic codes with few\n  weights Abstract: Cyclic codes have attracted a lot of research interest for decades as they\nhave efficient encoding and decoding algorithms.\n  In this paper, for an odd prime $p$, the weight distributions of two classes\nof $p$-ary cyclic codes are completely determined. We show that both codes have\nat most five nonzero weights. \n\n"}
{"id": "1504.04113", "contents": "Title: On the Performance of the Relay-ARQ Networks Abstract: This paper investigates the performance of relay networks in the presence of\nhybrid automatic repeat request (ARQ) feedback and adaptive power allocation.\nThe throughput and the outage probability of different hybrid ARQ protocols are\nstudied for independent and spatially-correlated fading channels. The results\nare obtained for the cases where there is a sum power constraint on the source\nand the relay or when each of the source and the relay are power-limited\nindividually. With adaptive power allocation, the results demonstrate the\nefficiency of relay-ARQ techniques in different conditions. \n\n"}
{"id": "1504.04419", "contents": "Title: Wasserstein continuity of entropy and outer bounds for interference\n  channels Abstract: It is shown that under suitable regularity conditions, differential entropy\nis a Lipschitz functional on the space of distributions on $n$-dimensional\nEuclidean space with respect to the quadratic Wasserstein distance. Under\nsimilar conditions, (discrete) Shannon entropy is shown to be Lipschitz\ncontinuous in distributions over the product space with respect to Ornstein's\n$\\bar d$-distance (Wasserstein distance corresponding to the Hamming distance).\nThese results together with Talagrand's and Marton's transportation-information\ninequalities allow one to replace the unknown multi-user interference with its\ni.i.d. approximations. As an application, a new outer bound for the two-user\nGaussian interference channel is proved, which, in particular, settles the\n\"missing corner point\" problem of Costa (1985). \n\n"}
{"id": "1504.06247", "contents": "Title: TC: Throughput Centric Successive Cancellation Decoder Hardware\n  Implementation for Polar Codes Abstract: This paper presents a hardware architecture of fast simplified successive\ncancellation (fast-SSC) algorithm for polar codes, which significantly reduces\nthe decoding latency and dramatically increases the throughput.\nAlgorithmically, fast-SSC algorithm suffers from the fact that its decoder\nscheduling and the consequent architecture depends on the code rate; this is a\nchallenge for rate-compatible system. However, by exploiting the\nhomogeneousness between the decoding processes of fast constituent polar codes\nand regular polar codes, the presented design is compatible with any rate. The\nscheduling plan and the intendedly designed process core are also described.\nResults show that, compared with the state-of-art decoder, proposed design can\nachieve at least 60% latency reduction for the codes with length N = 1024. By\nusing Nangate FreePDK 45nm process, proposed design can reach throughput up to\n5.81 Gbps and 2.01 Gbps for (1024, 870) and (1024, 512) polar code,\nrespectively. \n\n"}
{"id": "1504.06316", "contents": "Title: Interactive Communication with Unknown Noise Rate Abstract: Alice and Bob want to run a protocol over a noisy channel, where a certain\nnumber of bits are flipped adversarially. Several results take a protocol\nrequiring $L$ bits of noise-free communication and make it robust over such a\nchannel. In a recent breakthrough result, Haeupler described an algorithm that\nsends a number of bits that is conjectured to be near optimal in such a model.\nHowever, his algorithm critically requires $a \\ priori$ knowledge of the number\nof bits that will be flipped by the adversary.\n  We describe an algorithm requiring no such knowledge. If an adversary flips\n$T$ bits, our algorithm sends $L + O\\left(\\sqrt{L(T+1)\\log L} + T\\right)$ bits\nin expectation and succeeds with high probability in $L$. It does so without\nany $a \\ priori$ knowledge of $T$. Assuming a conjectured lower bound by\nHaeupler, our result is optimal up to logarithmic factors.\n  Our algorithm critically relies on the assumption of a private channel. We\nshow that privacy is necessary when the amount of noise is unknown. \n\n"}
{"id": "1505.00769", "contents": "Title: On Non-Interactive Simulation of Joint Distributions Abstract: We consider the following non-interactive simulation problem: Alice and Bob\nobserve sequences $X^n$ and $Y^n$ respectively where $\\{(X_i, Y_i)\\}_{i=1}^n$\nare drawn i.i.d. from $P(x,y),$ and they output $U$ and $V$ respectively which\nis required to have a joint law that is close in total variation to a specified\n$Q(u,v).$ It is known that the maximal correlation of $U$ and $V$ must\nnecessarily be no bigger than that of $X$ and $Y$ if this is to be possible.\nOur main contribution is to bring hypercontractivity to bear as a tool on this\nproblem. In particular, we show that if $P(x,y)$ is the doubly symmetric binary\nsource, then hypercontractivity provides stronger impossibility results than\nmaximal correlation. Finally, we extend these tools to provide impossibility\nresults for the $k$-agent version of this problem. \n\n"}
{"id": "1505.00810", "contents": "Title: Optimizing Data Aggregation for Uplink Machine-to-Machine Communication\n  Networks Abstract: Machine-to-machine (M2M) communication's severe power limitations challenge\nthe interconnectivity, access management, and reliable communication of data.\nIn densely deployed M2M networks, controlling and aggregating the generated\ndata is critical. We propose an energy efficient data aggregation scheme for a\nhierarchical M2M network. We develop a coverage probability-based optimal data\naggregation scheme for M2M devices to minimize the average total energy\nexpenditure per unit area per unit time or simply the {\\em energy density} of\nan M2M communication network. Our analysis exposes the key tradeoffs between\nthe energy density of the M2M network and the coverage characteristics for\nsuccessive and parallel transmission schemes that can be either half-duplex or\nfull-duplex. Comparing the rate and energy performances of the transmission\nmodels, we observe that successive mode and half-duplex parallel mode have\nbetter coverage characteristics compared to full-duplex parallel scheme.\nSimulation results show that the uplink coverage characteristics dominate the\ntrend of the energy consumption for both successive and parallel schemes. \n\n"}
{"id": "1505.01137", "contents": "Title: On the Reliability Function of Variable-Rate Slepian-Wolf Coding Abstract: The reliability function of variable-rate Slepian-Wolf coding is linked to\nthe reliability function of channel coding with constant composition codes,\nthrough which computable lower and upper bounds are derived. The bounds\ncoincide at rates close to the Slepian-Wolf limit, yielding a complete\ncharacterization of the reliability function in that rate regime. It is shown\nthat variable-rate Slepian-Wolf codes can significantly outperform fixed-rate\nSlepian-Wolf codes in terms of rate-error tradeoff. The reliability function of\nvariable-rate Slepian-Wolf coding with rate below the Slepian-Wolf limit is\ndetermined. In sharp contrast with fixed-rate Slepian-Wolf codes for which the\ncorrect decoding probability decays to zero exponentially fast if the rate is\nbelow the Slepian-Wolf limit, the correct decoding probability of variable-rate\nSlepian-Wolf codes can be bounded away from zero. \n\n"}
{"id": "1505.01619", "contents": "Title: Compressed sensing with structured sparsity and structured acquisition Abstract: Compressed Sensing (CS) is an appealing framework for applications such as\nMagnetic Resonance Imaging (MRI). However, up-to-date, the sensing schemes\nsuggested by CS theories are made of random isolated measurements, which are\nusually incompatible with the physics of acquisition. To reflect the physical\nconstraints of the imaging device, we introduce the notion of blocks of\nmeasurements: the sensing scheme is not a set of isolated measurements anymore,\nbut a set of groups of measurements which may represent any arbitrary shape\n(parallel or radial lines for instance). Structured acquisition with blocks of\nmeasurements are easy to implement, and provide good reconstruction results in\npractice. However, very few results exist on the theoretical guarantees of CS\nreconstructions in this setting. In this paper, we derive new CS results for\nstructured acquisitions and signals satisfying a prior structured sparsity. The\nobtained results provide a recovery probability of sparse vectors that\nexplicitly depends on their support. Our results are thus support-dependent and\noffer the possibility for flexible assumptions on the sparsity structure.\nMoreover, the results are drawing-dependent, since we highlight an explicit\ndependency between the probability of reconstructing a sparse vector and the\nway of choosing the blocks of measurements. Numerical simulations show that the\nproposed theory is faithful to experimental observations. \n\n"}
{"id": "1505.01753", "contents": "Title: Weighted Gaussian entropy and determinant inequalities Abstract: We produce a series of results extending information-theoretical inequalities\n(discussed by Dembo--Cover--Thomas in 1989-1991) to a weighted version of\nentropy. The resulting inequalities involve the Gaussian weighted entropy; they\nimply a number of new relations for determinants of positive-definite matrices. \n\n"}
{"id": "1505.03257", "contents": "Title: Optimal linear estimation under unknown nonlinear transform Abstract: Linear regression studies the problem of estimating a model parameter\n$\\beta^* \\in \\mathbb{R}^p$, from $n$ observations\n$\\{(y_i,\\mathbf{x}_i)\\}_{i=1}^n$ from linear model $y_i = \\langle\n\\mathbf{x}_i,\\beta^* \\rangle + \\epsilon_i$. We consider a significant\ngeneralization in which the relationship between $\\langle \\mathbf{x}_i,\\beta^*\n\\rangle$ and $y_i$ is noisy, quantized to a single bit, potentially nonlinear,\nnoninvertible, as well as unknown. This model is known as the single-index\nmodel in statistics, and, among other things, it represents a significant\ngeneralization of one-bit compressed sensing. We propose a novel spectral-based\nestimation procedure and show that we can recover $\\beta^*$ in settings (i.e.,\nclasses of link function $f$) where previous algorithms fail. In general, our\nalgorithm requires only very mild restrictions on the (unknown) functional\nrelationship between $y_i$ and $\\langle \\mathbf{x}_i,\\beta^* \\rangle$. We also\nconsider the high dimensional setting where $\\beta^*$ is sparse ,and introduce\na two-stage nonconvex framework that addresses estimation challenges in high\ndimensional regimes where $p \\gg n$. For a broad class of link functions\nbetween $\\langle \\mathbf{x}_i,\\beta^* \\rangle$ and $y_i$, we establish minimax\nlower bounds that demonstrate the optimality of our estimators in both the\nclassical and high dimensional regimes. \n\n"}
{"id": "1505.07283", "contents": "Title: Index Codes for the Gaussian Broadcast Channel using Quadrature\n  Amplitude Modulation Abstract: We propose index codes, based on multidimensional QAM constellations, for the\nGaussian broadcast channel, where every receiver demands all the messages from\nthe source. The efficiency with which an index code exploits receiver side\ninformation in this broadcast channel is characterised by a code design metric\ncalled \"side information gain\". The known index codes for this broadcast\nchannel enjoy large side information gains, but do not encode all the source\nmessages at the same rate, and do not admit message sizes that are powers of\ntwo. The index codes proposed in this letter, which are based on linear codes\nover integer rings, overcome both these drawbacks and yet provide large values\nof side information gain. With the aid of a computer search, we obtain QAM\nindex codes for encoding up to 5 messages with message sizes 2^m, m <= 6. We\nalso present the simulated performance of a new 16-QAM index code, concatenated\nwith an off-the-shelf LDPC code, which is observed to operate within 4.3 dB of\nthe broadcast channel capacity. \n\n"}
{"id": "1505.07717", "contents": "Title: Exploring multimodal data fusion through joint decompositions with\n  flexible couplings Abstract: A Bayesian framework is proposed to define flexible coupling models for joint\ntensor decompositions of multiple data sets. Under this framework, a natural\nformulation of the data fusion problem is to cast it in terms of a joint\nmaximum a posteriori (MAP) estimator. Data driven scenarios of joint posterior\ndistributions are provided, including general Gaussian priors and non Gaussian\ncoupling priors. We present and discuss implementation issues of algorithms\nused to obtain the joint MAP estimator. We also show how this framework can be\nadapted to tackle the problem of joint decompositions of large datasets. In the\ncase of a conditional Gaussian coupling with a linear transformation, we give\ntheoretical bounds on the data fusion performance using the Bayesian Cramer-Rao\nbound. Simulations are reported for hybrid coupling models ranging from simple\nadditive Gaussian models, to Gamma-type models with positive variables and to\nthe coupling of data sets which are inherently of different size due to\ndifferent resolution of the measurement devices. \n\n"}
{"id": "1506.00154", "contents": "Title: Resolvability in E{\\gamma} with Applications to Lossy Compression and\n  Wiretap Channels Abstract: We study the amount of randomness needed for an input process to approximate\na given output distribution of a channel in the $E_{\\gamma}$ distance. A\ngeneral one-shot achievability bound for the precision of such an approximation\nis developed. In the i.i.d.~setting where $\\gamma=\\exp(nE)$, a (nonnegative)\nrandomness rate above $\\inf_{Q_{\\sf U}: D(Q_{\\sf X}||\\pi_{\\sf X})\\le E}\n\\{D(Q_{\\sf X}||\\pi_{\\sf X})+I(Q_{\\sf U},Q_{\\sf X|U})-E\\}$ is necessary and\nsufficient to asymptotically approximate the output distribution $\\pi_{\\sf\nX}^{\\otimes n}$ using the channel $Q_{\\sf X|U}^{\\otimes n}$, where $Q_{\\sf\nU}\\to Q_{\\sf X|U}\\to Q_{\\sf X}$. The new resolvability result is then used to\nderive a one-shot upper bound on the error probability in the rate distortion\nproblem, and a lower bound on the size of the eavesdropper list to include the\nactual message in the wiretap channel problem. Both bounds are asymptotically\ntight in i.i.d.~settings. \n\n"}
{"id": "1506.00740", "contents": "Title: Asymmetric Lee Distance Codes for DNA-Based Storage Abstract: We consider a new family of codes, termed asymmetric Lee distance codes, that\narise in the design and implementation of DNA-based storage systems and systems\nwith parallel string transmission protocols. The codewords are defined over a\nquaternary alphabet, although the results carry over to other alphabet sizes;\nfurthermore, symbol confusability is dictated by their underlying binary\nrepresentation. Our contributions are two-fold. First, we demonstrate that the\nnew distance represents a linear combination of the Lee and Hamming distance\nand derive upper bounds on the size of the codes under this metric based on\nlinear programming techniques. Second, we propose a number of code\nconstructions which imply lower bounds. \n\n"}
{"id": "1506.02693", "contents": "Title: Approximate Message Passing Algorithm with Universal Denoising and\n  Gaussian Mixture Learning Abstract: We study compressed sensing (CS) signal reconstruction problems where an\ninput signal is measured via matrix multiplication under additive white\nGaussian noise. Our signals are assumed to be stationary and ergodic, but the\ninput statistics are unknown; the goal is to provide reconstruction algorithms\nthat are universal to the input statistics. We present a novel algorithmic\nframework that combines: (i) the approximate message passing (AMP) CS\nreconstruction framework, which solves the matrix channel recovery problem by\niterative scalar channel denoising; (ii) a universal denoising scheme based on\ncontext quantization, which partitions the stationary ergodic signal denoising\ninto independent and identically distributed (i.i.d.) subsequence denoising;\nand (iii) a density estimation approach that approximates the probability\ndistribution of an i.i.d. sequence by fitting a Gaussian mixture (GM) model. In\naddition to the algorithmic framework, we provide three contributions: (i)\nnumerical results showing that state evolution holds for non-separable Bayesian\nsliding-window denoisers; (ii) an i.i.d. denoiser based on a modified GM\nlearning algorithm; and (iii) a universal denoiser that does not need\ninformation about the range where the input takes values from or require the\ninput signal to be bounded. We provide two implementations of our universal CS\nrecovery algorithm with one being faster and the other being more accurate. The\ntwo implementations compare favorably with existing universal reconstruction\nalgorithms in terms of both reconstruction quality and runtime. \n\n"}
{"id": "1506.03144", "contents": "Title: Superresolution without Separation Abstract: This paper provides a theoretical analysis of diffraction-limited\nsuperresolution, demonstrating that arbitrarily close point sources can be\nresolved in ideal situations. Precisely, we assume that the incoming signal is\na linear combination of M shifted copies of a known waveform with unknown\nshifts and amplitudes, and one only observes a finite collection of evaluations\nof this signal. We characterize properties of the base waveform such that the\nexact translations and amplitudes can be recovered from 2M + 1 observations.\nThis recovery is achieved by solving a a weighted version of basis pursuit over\na continuous dictionary. Our methods combine classical polynomial interpolation\ntechniques with contemporary tools from compressed sensing. \n\n"}
{"id": "1506.03236", "contents": "Title: Fundamental Limits of Communication with Low Probability of Detection Abstract: This paper considers the problem of communication over a discrete memoryless\nchannel (DMC) or an additive white Gaussian noise (AWGN) channel subject to the\nconstraint that the probability that an adversary who observes the channel\noutputs can detect the communication is low. Specifically, the relative entropy\nbetween the output distributions when a codeword is transmitted and when no\ninput is provided to the channel must be sufficiently small. For a DMC whose\noutput distribution induced by the \"off\" input symbol is not a mixture of the\noutput distributions induced by other input symbols, it is shown that the\nmaximum amount of information that can be transmitted under this criterion\nscales like the square root of the blocklength. The same is true for the AWGN\nchannel. Exact expressions for the scaling constant are also derived. \n\n"}
{"id": "1506.04822", "contents": "Title: Some Improvements on Locally Repairable Codes Abstract: The locally repairable codes (LRCs) were introduced to correct erasures\nefficiently in distributed storage systems. LRCs are extensively studied\nrecently.\n  In this paper, we first deal with the open case remained in \\cite{q} and\nderive an improved upper bound for the minimum distances of LRCs. We also give\nan explicit construction for LRCs attaining this bound. Secondly, we consider\nthe constructions of LRCs with any locality and availability which have high\ncode rate and minimum distance as large as possible. We give a graphical model\nfor LRCs. By using the deep results from graph theory, we construct a family of\nLRCs with any locality $r$ and availability $2$ with code rate\n$\\frac{r-1}{r+1}$ and optimal minimum distance $O(\\log n)$ where $n$ is the\nlength of the code. \n\n"}
{"id": "1506.06199", "contents": "Title: Non-parametric Quickest Change Detection for Large Scale Random Matrices Abstract: The problem of quickest detection of a change in the distribution of a\n$n\\times p$ random matrix based on a sequence of observations having a single\nunknown change point is considered. The forms of the pre- and post-change\ndistributions of the rows of the matrices are assumed to belong to the family\nof elliptically contoured densities with sparse dispersion matrices but are\notherwise unknown. We propose a non-parametric stopping rule that is based on a\nnovel summary statistic related to k-nearest neighbor correlation between\ncolumns of each observed random matrix. In the large scale regime of\n$p\\rightarrow \\infty$ and $n$ fixed we show that, among all functions of the\nproposed summary statistic, the proposed stopping rule is asymptotically\noptimal under a minimax quickest change detection (QCD) model. \n\n"}
{"id": "1506.06296", "contents": "Title: On Modeling Heterogeneous Wireless Networks Using Non-Poisson Point\n  Processes Abstract: Future wireless networks are required to support 1000 times higher data rate,\nthan the current LTE standard. In order to meet the ever increasing demand, it\nis inevitable that, future wireless networks will have to develop seamless\ninterconnection between multiple technologies. A manifestation of this idea is\nthe collaboration among different types of network tiers such as macro and\nsmall cells, leading to the so-called heterogeneous networks (HetNets).\nResearchers have used stochastic geometry to analyze such networks and\nunderstand their real potential. Unsurprisingly, it has been revealed that\ninterference has a detrimental effect on performance, especially if not modeled\nproperly. Interference can be correlated in space and/or time, which has been\noverlooked in the past. For instance, it is normally assumed that the nodes are\nlocated completely independent of each other and follow a homogeneous Poisson\npoint process (PPP), which is not necessarily true in real networks since the\nnode locations are spatially dependent. In addition, the interference\ncorrelation created by correlated stochastic processes has mostly been ignored.\nTo this end, we take a different approach in modeling the interference where we\nuse non-PPP, as well as we study the impact of spatial and temporal correlation\non the performance of HetNets. To illustrate the impact of correlation on\nperformance, we consider three case studies from real-life scenarios.\nSpecifically, we use massive multiple-input multiple-output (MIMO) to\nunderstand the impact of spatial correlation; we use the random medium access\nprotocol to examine the temporal correlation; and we use cooperative relay\nnetworks to illustrate the spatial-temporal correlation. We present several\nnumerical examples through which we demonstrate the impact of various\ncorrelation types on the performance of HetNets. \n\n"}
{"id": "1506.06484", "contents": "Title: Cross-layer estimation and control for Cognitive Radio: Exploiting\n  Sparse Network Dynamics Abstract: In this paper, a cross-layer framework to jointly optimize spectrum sensing\nand scheduling in resource constrained agile wireless networks is presented. A\nnetwork of secondary users (SUs) accesses portions of the spectrum left unused\nby a network of licensed primary users (PUs). A central controller (CC)\nschedules the traffic of the SUs, based on distributed compressed measurements\ncollected by the SUs. Sensing and scheduling are jointly controlled to maximize\nthe SU throughput, with constraints on PU throughput degradation and SU cost.\nThe sparsity in the spectrum dynamics is exploited: leveraging a prior spectrum\noccupancy estimate, the CC needs to estimate only a residual uncertainty vector\nvia sparse recovery techniques. The high complexity entailed by the POMDP\nformulation is reduced by a low-dimensional belief representation via\nminimization of the Kullback-Leibler divergence. It is proved that the\noptimization of sensing and scheduling can be decoupled. A partially myopic\nscheduling strategy is proposed for which structural properties can be proved\nshowing that the myopic scheme allocates SU traffic to likely idle spectral\nbands. Simulation results show that this framework balances optimally the\nresources between spectrum sensing and data transmission. This framework\ndefines sensing-scheduling schemes most informative for network control,\nyielding energy efficient resource utilization. \n\n"}
{"id": "1506.07571", "contents": "Title: Indoor Location Estimation with Optical-based OFDM Communications Abstract: Visible Light Communication (VLC) using light emitting diodes (LEDs) has been\ngaining increasing attention in recent years as it is appealing for a wide\nrange of applications such as indoor positioning. Orthogonal frequency division\nmultiplexing (OFDM) has been applied to indoor wireless optical communications\nin order to mitigate the effect of multipath distortion of the optical channel\nas well as increasing data rate. In this paper, a novel OFDM VLC system is\nproposed which can be utilized for both communications and indoor positioning.\nA positioning algorithm based on power attenuation is used to estimate the\nreceiver coordinates. We further calculate the positioning errors in all the\nlocations of a room and compare them with those using single carrier modulation\nscheme, i.e., on-off keying (OOK) modulation. We demonstrate that OFDM\npositioning system outperforms its conventional counterpart. Finally, we\ninvestigate the impact of different system parameters on the positioning\naccuracy of the proposed OFDM VLC system. \n\n"}
{"id": "1506.08269", "contents": "Title: Construction $\\pi_A$ and $\\pi_D$ Lattices: Construction, Goodness, and\n  Decoding Algorithms Abstract: A novel construction of lattices is proposed. This construction can be\nthought of as a special class of Construction A from codes over finite rings\nthat can be represented as the Cartesian product of $L$ linear codes over\n$\\mathbb{F}_{p_1},\\ldots,\\mathbb{F}_{p_L}$, respectively, and hence is referred\nto as Construction $\\pi_A$. The existence of a sequence of such lattices that\nis good for channel coding (i.e., Poltyrev-limit achieving) under multistage\ndecoding is shown. A new family of multilevel nested lattice codes based on\nConstruction $\\pi_A$ lattices is proposed and its achievable rate for the\nadditive white Gaussian channel is analyzed. A generalization named\nConstruction $\\pi_D$ is also investigated which subsumes Construction A with\ncodes over prime fields, Construction D, and Construction $\\pi_A$ as special\ncases. \n\n"}
{"id": "1507.00071", "contents": "Title: Optimal time sharing in underlay cognitive radio systems with RF energy\n  harvesting Abstract: Due to the fundamental tradeoffs, achieving spectrum efficiency and energy\nefficiency are two contending design challenges for the future wireless\nnetworks. However, applying radio-frequency (RF) energy harvesting (EH) in a\ncognitive radio system could potentially circumvent this tradeoff, resulting in\na secondary system with limitless power supply and meaningful achievable\ninformation rates. This paper proposes an online solution for the optimal time\nallocation (time sharing) between the EH phase and the information transmission\n(IT) phase in an underlay cognitive radio system, which harvests the RF energy\noriginating from the primary system. The proposed online solution maximizes the\naverage achievable rate of the cognitive radio system, subject to the\n$\\varepsilon$-percentile protection criteria for the primary system. The\noptimal time sharing achieves significant gains compared to equal time\nallocation between the EH and IT phases. \n\n"}
{"id": "1507.00182", "contents": "Title: Modeling and Analysis of Content Caching in Wireless Small Cell Networks Abstract: Network densification with small cell base stations is a promising solution\nto satisfy future data traffic demands. However, increasing small cell base\nstation density alone does not ensure better users quality-of-experience and\nincurs high operational expenditures. Therefore, content caching on different\nnetwork elements has been proposed as a mean of offloading he backhaul by\ncaching strategic contents at the network edge, thereby reducing latency. In\nthis paper, we investigate cache-enabled small cells in which we model and\ncharacterize the outage probability, defined as the probability of not\nsatisfying users requests over a given coverage area. We analytically derive a\nclosed form expression of the outage probability as a function of\nsignal-to-interference ratio, cache size, small cell base station density and\nthreshold distance. By assuming the distribution of base stations as a Poisson\npoint process, we derive the probability of finding a specific content within a\nthreshold distance and the optimal small cell base station density that\nachieves a given target cache hit probability. Furthermore, simulation results\nare performed to validate the analytical model. \n\n"}
{"id": "1507.02444", "contents": "Title: Non-Asymptotic Achievable Rates for Energy-Harvesting Channels using\n  Save-and-Transmit Abstract: This paper investigates the information-theoretic limits of energy-harvesting\n(EH) channels in the finite blocklength regime. The EH process is characterized\nby a sequence of i.i.d. random variables with finite variances. We use the\nsave-and-transmit strategy proposed by Ozel and Ulukus (2012) together with\nShannon's non-asymptotic achievability bound to obtain lower bounds on the\nachievable rates for both additive white Gaussian noise channels and discrete\nmemoryless channels under EH constraints. The first-order terms of the lower\nbounds of the achievable rates are equal to $C$ and the second-order (backoff\nfrom capacity) terms are proportional to $-\\sqrt{ \\frac{\\log n}{n}}$, where $n$\ndenotes the blocklength and $C$ denotes the capacity of the EH channel, which\nis the same as the capacity without the EH constraints. The constant of\nproportionality of the backoff term is found and qualitative interpretations\nare provided. \n\n"}
{"id": "1507.02874", "contents": "Title: On the Public Communication Needed to Achieve SK Capacity in the\n  Multiterminal Source Model Abstract: The focus of this paper is on the public communication required for\ngenerating a maximal-rate secret key (SK) within the multiterminal source model\nof Csisz{\\'a}r and Narayan. Building on the prior work of Tyagi for the\ntwo-terminal scenario, we derive a lower bound on the communication complexity,\n$R_{\\text{SK}}$, defined to be the minimum rate of public communication needed\nto generate a maximal-rate SK. It is well known that the minimum rate of\ncommunication for omniscience, denoted by $R_{\\text{CO}}$, is an upper bound on\n$R_{\\text{SK}}$. For the class of pairwise independent network (PIN) models\ndefined on uniform hypergraphs, we show that a certain \"Type $\\mathcal{S}$\"\ncondition, which is verifiable in polynomial time, guarantees that our lower\nbound on $R_{\\text{SK}}$ meets the $R_{\\text{CO}}$ upper bound. Thus, PIN\nmodels satisfying our condition are $R_{\\text{SK}}$-maximal, meaning that the\nupper bound $R_{\\text{SK}} \\le R_{\\text{CO}}$ holds with equality. This allows\nus to explicitly evaluate $R_{\\text{SK}}$ for such PIN models. We also give\nseveral examples of PIN models that satisfy our Type $\\mathcal S$ condition.\nFinally, we prove that for an arbitrary multiterminal source model, a stricter\nversion of our Type $\\mathcal S$ condition implies that communication from\n\\emph{all} terminals (\"omnivocality\") is needed for establishing a SK of\nmaximum rate. For three-terminal source models, the converse is also true:\nomnivocality is needed for generating a maximal-rate SK only if the strict Type\n$\\mathcal S$ condition is satisfied. Counterexamples exist that show that the\nconverse is not true in general for source models with four or more terminals. \n\n"}
{"id": "1507.05371", "contents": "Title: Regret Guarantees for Item-Item Collaborative Filtering Abstract: There is much empirical evidence that item-item collaborative filtering works\nwell in practice. Motivated to understand this, we provide a framework to\ndesign and analyze various recommendation algorithms. The setup amounts to\nonline binary matrix completion, where at each time a random user requests a\nrecommendation and the algorithm chooses an entry to reveal in the user's row.\nThe goal is to minimize regret, or equivalently to maximize the number of +1\nentries revealed at any time. We analyze an item-item collaborative filtering\nalgorithm that can achieve fundamentally better performance compared to\nuser-user collaborative filtering. The algorithm achieves good \"cold-start\"\nperformance (appropriately defined) by quickly making good recommendations to\nnew users about whom there is little information. \n\n"}
{"id": "1507.05506", "contents": "Title: Cyclic codes from the second class two-prime Whiteman's generalized\n  cyclotomic sequence with order 6 Abstract: Let $n_1=ef+1$ and $n_2=ef'+1$ be two distinct odd primes with positive\nintegers $e,\\ f,\\ f'.$ In this paper, the two-prime Whiteman's generalized\ncyclotomic sequence of order $e=6$ is employed to construct several classes of\ncyclic codes over $\\mathrm{GF}(q)$ with length $n_1n_2$. The lower bounds on\nthe minimum distance of these cyclic codes are obtained. \n\n"}
{"id": "1507.05924", "contents": "Title: Multiuser Communication through Power Talk in DC MicroGrids Abstract: Power talk is a novel concept for communication among control units in\nMicroGrids (MGs), carried out without a dedicated modem, but by using power\nelectronics that interface the common bus. The information is transmitted by\nmodulating the parameters of the primary control, incurring subtle power\ndeviations that can be detected by other units. In this paper, we develop power\ntalk communication strategies for DC MG systems with arbitrary number of\ncontrol units that carry out all-to-all communication. We investigate two\nmultiple access strategies: 1) TDMA, where only one unit transmits at a time,\nand 2) full duplex, where all units transmit and receive simultaneously. We\nintroduce the notions of signaling space, where the power talk symbol\nconstellations are constructed, and detection space, where the demodulation of\nthe symbols is performed. The proposed communication technique is challenged by\nthe random changes of the bus parameters due to load variations in the system.\nTo this end, we employ a solution based on training sequences, which\nre-establishes the signaling and detection spaces and thus enables reliable\ninformation exchange. The presented results show that power talk is an\neffective solution for reliable communication among units in DC MG systems. \n\n"}
{"id": "1507.06737", "contents": "Title: The Degrees of Freedom of the Interference Channel with a Cognitive\n  Relay under Delayed Feedback Abstract: This paper studies the interference channel with a cognitive relay (ICCR)\nunder delayed feedback. Three types of delayed feedback are studied: delayed\nchannel state information at the transmitter (CSIT), delayed output feedback,\nand delayed Shannon feedback. Outer bounds are derived for the DoF region of\nthe two-user multiple-input multiple-output (MIMO) ICCR with delayed feedback\nas well as without feedback. For the single-input single-output (SISO)\nscenario, optimal schemes are proposed based on retrospective interference\nalignment. It is shown that while a cognitive relay without feedback cannot\nextend the sum-DoF beyond $1$ in the two-user SISO interference channel,\ndelayed feedback in the same scenario can extend the sum-DoF to $4/3$. For the\nMIMO case, achievable schemes are obtained via extensions of retrospective\ninterference alignment, leading to DoF regions that meet the respective upper\nbounds. \n\n"}
{"id": "1507.08979", "contents": "Title: Tractable Resource Management with Uplink Decoupled Millimeter-Wave\n  Overlay in Ultra-Dense Cellular Networks Abstract: The forthcoming 5G cellular network is expected to overlay millimeter-wave\n(mmW) transmissions with the incumbent micro-wave ({\\mu}W) architecture. The\noverall mm-{\\mu}W resource management should therefore harmonize with each\nother. This paper aims at maximizing the overall downlink (DL) rate with a\nminimum uplink (UL) rate constraint, and concludes: mmW tends to focus more on\nDL transmissions while {\\mu}W has high priority for complementing UL, under\ntime-division duplex (TDD) mmW operations. Such UL dedication of {\\mu}W results\nfrom the limited use of mmW UL bandwidth due to excessive power consumption\nand/or high peak-to-average power ratio (PAPR) at mobile users. To further\nrelieve this UL bottleneck, we propose mmW UL decoupling that allows each\nlegacy {\\mu}W base station (BS) to receive mmW signals. Its impact on mm-{\\mu}W\nresource management is provided in a tractable way by virtue of a novel\nclosed-form mm-{\\mu}W spectral efficiency (SE) derivation. In an ultra-dense\ncellular network (UDN), our derivation verifies mmW (or {\\mu}W) SE is a\nlogarithmic function of BS-to-user density ratio. This strikingly simple yet\npractically valid analysis is enabled by exploiting stochastic geometry in\nconjunction with real three dimensional (3D) building blockage statistics in\nSeoul, Korea. \n\n"}
{"id": "1508.00168", "contents": "Title: Completion Time in Two-user Channels: An Information-Theoretic\n  Perspective Abstract: In a two-user channel, completion time refers to the number of channel uses\nspent by each user to transmit a bit pool with some given size. In this paper,\nthe information-theoretic formulation of completion time is based on the\nconcept of constrained rates, where users are allowed to employ different\nnumbers of channel uses for transmission as opposed to the equal channel use of\nthe standard information-theoretic formulation. Analogous to the capacity\nregion, the completion time region characterizes all possible trade-offs among\nusers' completion times. For a multi-access channel, it is shown that the\ncompletion time region is achieved by operating the channel in two independent\nphases: a multi-access phase when both users are transmitting, and a\npoint-to-point phase when one user has finished and the other is still\ntransmitting. Using a similar two-phase approach, the completion time region\n(or inner and outer bounds) is established for a Gaussian broadcast channel and\na Gaussian interference channel. It is observed that although consisting of two\nconvex subregions, the completion time region may not be convex in general.\nFinally an optimization problem of minimizing the weighted sum completion time\nfor a Gaussian multi-access channel and a Gaussian broadcast channel is solved,\ndemonstrating the utility of the completion time approach. \n\n"}
{"id": "1508.00522", "contents": "Title: Explicit Frames for Deterministic Phase Retrieval via PhaseLift Abstract: We explicitly give a frame of cardinality $5n-6$ such that every signal in\n$\\mathbb{C}^n$ can be recovered up to a phase from its associated intensity\nmeasurements via the PhaseLift approach. Furthermore, we give explicit linear\nmeasurements with $4r(n-r)+n-2r$ outcomes that enable the recovery of every\npositive semidefinite $n\\times n$ matrix of rank at most $r$. \n\n"}
{"id": "1508.00527", "contents": "Title: On the Base Station Association Problem in HetSNets Abstract: The dense deployment of small-cell base stations in HetSNets requires\nefficient resource allocation techniques. More precisely, the problem of\nassociating users to SBSs must be revised and carefully studied. This problem\nis NP-hard and requires solving an integer optimization problem. In order to\nefficiently solve this problem, we model it using non-cooperative game theory.\nFirst, we design two non-cooperative games to solve the problem and show the\nexistence of pure Nash equilibria (PNE) in both games. These equilibria are\nshown to be far from the social optimum. Hence, we propose a better game design\nin order to approach this optimum. This new game is proved to have no PNE in\ngeneral. However, simulations show, for Rayleigh fading channels, that a PNE\nalways exists for all instances of the game. In addition, we show that its\nprices of anarchy and stability are close to one. We propose a best response\ndynamics (BRD) algorithm that converges to a PNE when it exists. Because of the\nhigh information exchange of BRD, a completely distributed algorithm, based on\nthe theory of learning, is proposed. Simulations show that this algorithm has\ntight-to-optimal performance and further it converges to a PNE (when existing)\nwith high probability. \n\n"}
{"id": "1508.01161", "contents": "Title: Pushing towards the Limit of Sampling Rate: Adaptive Chasing Sampling Abstract: Measurement samples are often taken in various monitoring applications. To\nreduce the sensing cost, it is desirable to achieve better sensing quality\nwhile using fewer samples. Compressive Sensing (CS) technique finds its role\nwhen the signal to be sampled meets certain sparsity requirements. In this\npaper we investigate the possibility and basic techniques that could further\nreduce the number of samples involved in conventional CS theory by exploiting\nlearning-based non-uniform adaptive sampling.\n  Based on a typical signal sensing application, we illustrate and evaluate the\nperformance of two of our algorithms, Individual Chasing and Centroid Chasing,\nfor signals of different distribution features. Our proposed learning-based\nadaptive sampling schemes complement existing efforts in CS fields and do not\ndepend on any specific signal reconstruction technique. Compared to\nconventional sparse sampling methods, the simulation results demonstrate that\nour algorithms allow $46\\%$ less number of samples for accurate signal\nreconstruction and achieve up to $57\\%$ smaller signal reconstruction error\nunder the same noise condition. \n\n"}
{"id": "1508.01842", "contents": "Title: New Guarantees for Blind Compressed Sensing Abstract: Blind Compressed Sensing (BCS) is an extension of Compressed Sensing (CS)\nwhere the optimal sparsifying dictionary is assumed to be unknown and subject\nto estimation (in addition to the CS sparse coefficients). Since the emergence\nof BCS, dictionary learning, a.k.a. sparse coding, has been studied as a matrix\nfactorization problem where its sample complexity, uniqueness and\nidentifiability have been addressed thoroughly. However, in spite of the strong\nconnections between BCS and sparse coding, recent results from the sparse\ncoding problem area have not been exploited within the context of BCS. In\nparticular, prior BCS efforts have focused on learning constrained and complete\ndictionaries that limit the scope and utility of these efforts. In this paper,\nwe develop new theoretical bounds for perfect recovery for the general\nunconstrained BCS problem. These unconstrained BCS bounds cover the case of\novercomplete dictionaries, and hence, they go well beyond the existing BCS\ntheory. Our perfect recovery results integrate the combinatorial theories of\nsparse coding with some of the recent results from low-rank matrix recovery. In\nparticular, we propose an efficient CS measurement scheme that results in\npractical recovery bounds for BCS. Moreover, we discuss the performance of BCS\nunder polynomial-time sparse coding algorithms. \n\n"}
{"id": "1508.02015", "contents": "Title: On cyclic DNA codes over the Ring $\\Z_4 + u \\Z_4$ Abstract: In this paper, we study the theory for constructing DNA cyclic codes of odd\nlength over $\\Z_4[u]/\\langle u^2 \\rangle$ which play an important role in DNA\ncomputing. Cyclic codes of odd length over $\\Z_4 + u \\Z_4$ satisfy the reverse\nconstraint and the reverse-complement constraint are studied in this paper. The\nstructure and existence of such codes are also studied. The paper concludes\nwith some DNA example obtained via the family of cyclic codes. \n\n"}
{"id": "1508.02556", "contents": "Title: Assessment of LTE Wireless Access for Monitoring of Energy Distribution\n  in the Smart Grid Abstract: While LTE is becoming widely rolled out for human-type services, it is also a\npromising solution for cost-efficient connectivity of the smart grid monitoring\nequipment. This is a type of machine-to-machine (M2M) traffic that consists\nmainly of sporadic uplink transmissions. In such a setting, the amount of\ntraffic that can be served in a cell is not constrained by the data capacity,\nbut rather by the signaling constraints in the random access channel and\ncontrol channel. In this paper we explore these limitations using a detailed\nsimulation of the LTE access reservation protocol (ARP). We find that 1)\nassigning more random access opportunities may actually worsen performance; and\n2) the additional signaling that follows the ARP has very large impact on the\ncapacity in terms of the number of supported devices; we observed a reduction\nin the capacity by almost a factor of 3. This suggests that a lightweight\naccess method, with a reduced number of signaling messages, needs to be\nconsidered in standardization for M2M applications. Additionally we propose a\ntractable analytical model to calculate the outage that can be rapidly\nimplemented and evaluated. The model accounts for the features of the random\naccess, control channel and uplink and downlink data channels, as well as\nretransmissions. \n\n"}
{"id": "1508.02820", "contents": "Title: STFT Phase Retrieval: Uniqueness Guarantees and Recovery Algorithms Abstract: The problem of recovering a signal from its Fourier magnitude is of paramount\nimportance in various fields of engineering and applied physics. Due to the\nabsence of Fourier phase information, some form of additional information is\nrequired in order to be able to uniquely, efficiently and robustly identify the\nunderlying signal. Inspired by practical methods in optical imaging, we\nconsider the problem of signal reconstruction from the Short-Time Fourier\nTransform (STFT) magnitude. We first develop conditions under which the STFT\nmagnitude is an almost surely unique signal representation. We then consider a\nsemidefinite relaxation-based algorithm (STliFT) and provide recovery\nguarantees. Numerical simulations complement our theoretical analysis and\nprovide directions for future work. \n\n"}
{"id": "1508.04030", "contents": "Title: Performance Characterization of Relay-Assisted Wireless Optical CDMA\n  Networks in Turbulent Underwater Channel Abstract: In this paper, we characterize the performance of relay-assisted underwater\nwireless optical code division multiple access (OCDMA) networks over turbulent\nchannels. In addition to scattering and absorption effects of underwater\nchannels, we also consider optical turbulence as a log-normal fading\ncoefficient in our analysis. To simultaneously and asynchronously share medium\namong many users, we assign a unique optical orthogonal code (OOC) to each user\nin order to actualize OCDMA-based underwater network. The most significant\nchallenge in underwater optical communication is in the ability to extend the\nshort range of its coverage. In order to expand the viable communication range,\nwe consider multi-hop transmission to the destination. Moreover, we evaluate\nthe performance of a relay-assisted point-to-point UWOC system as a special\ncase of the proposed relay-assisted OCDMA network. Our numerical results\nindicate significant performance improvement by employing intermediate relays,\ne.g., one can achieve $32$ {dB} improvement in the bit error rate (BER) of\n$10^{-6}$ using only a dual-hop transmission in a $90$ {m} point-to-point clear\nocean link. \n\n"}
{"id": "1508.04726", "contents": "Title: A Lower Bound on the per Soliton Capacity of the Nonlinear Optical Fibre\n  Channel Abstract: A closed-form expression for a lower bound on the per soliton capacity of the\nnonlinear optical fibre channel in the presence of (optical) amplifier\nspontaneous emission (ASE) noise is derived. This bound is based on a\nnon-Gaussian conditional probability density function for the soliton amplitude\njitter induced by the ASE noise and is proven to grow logarithmically as the\nsignal-to-noise ratio increases. \n\n"}
{"id": "1508.06381", "contents": "Title: Joint Transceiver Design Algorithms for Multiuser MISO Relay Systems\n  with Energy Harvesting Abstract: In this paper, we investigate a multiuser relay system with simultaneous\nwireless information and power transfer. Assuming that both base station (BS)\nand relay station (RS) are equipped with multiple antennas, this work studies\nthe joint transceiver design problem for the BS beamforming vectors, the RS\namplify-and-forward transformation matrix and the power splitting (PS) ratios\nat the single-antenna receivers. Firstly, an iterative algorithm based on\nalternating optimization (AO) and with guaranteed convergence is proposed to\nsuccessively optimize the transceiver coefficients. Secondly, a novel design\nscheme based on switched relaying (SR) is proposed that can significantly\nreduce the computational complexity and overhead of the AO based designs while\nmaintaining a similar performance. In the proposed SR scheme, the RS is\nequipped with a codebook of permutation matrices. For each permutation matrix,\na latent transceiver is designed which consists of BS beamforming vectors,\noptimally scaled RS permutation matrix and receiver PS ratios. For the given\nCSI, the optimal transceiver with the lowest total power consumption is\nselected for transmission. We propose a concave-convex procedure based and\nsubgradient-type iterative algorithms for the non-robust and robust latent\ntransceiver designs. Simulation results are presented to validate the\neffectiveness of all the proposed algorithms. \n\n"}
{"id": "1508.07590", "contents": "Title: New Classes of Permutation Binomials and Permutation Trinomials over\n  Finite Fields Abstract: Permutation polynomials over finite fields play important roles in finite\nfields theory. They also have wide applications in many areas of science and\nengineering such as coding theory, cryptography, combinatorial design,\ncommunication theory and so on. Permutation binomials and trinomials attract\npeople's interest due to their simple algebraic form and additional\nextraordinary properties. In this paper, several new classes of permutation\nbinomials and permutation trinomials are constructed. Some of these permutation\npolynomials are generalizations of known ones. \n\n"}
{"id": "1509.00453", "contents": "Title: PLC-to-DSL Interference: Statistical Model and Impact on DSL Abstract: Newly available standards for broadband access using Digital Subscriber Lines\n(DSL) have a high degree of spectrum overlap with home networking technologies\nusing broadband Power Line Communications (BB-PLC) and this overlap leads to\nElectromagnetic Compatibility issues that may cause performance degradation in\nDSL systems. This paper studies the characteristics of measured PLC-to-DSL\ninterference and presents novel results on its statistical characterization.\nThe frequency-dependent couplings between power line cables and twisted-pairs\nare estimated from measurements and a statistical model based on a mixture of\ntwo truncated Gaussian distributions is set forth. The proposed statistical\nmodel allows the accurate evaluation of the impact of BB-PLC interference on\nvarious DSL technologies, in terms of both average and worst-case impacts on\ndata rate. This paper further provides an extensive assessment of the impact of\nPLC-to-DSL interference at various loop lengths and for multiple profiles of\nVery-high rate Digital Subscriber Lines (VDSL2), Vectored VDSL2 (V-VDSL2), and\nG.fast. The results of this paper confirm that the impact of PLC interference\nvaries with loop length and whether vectoring is used or not. Furthermore, the\naverage impact is found to be generally small but worst-case couplings can lead\nto substantial degradation of DSL. \n\n"}
{"id": "1509.00777", "contents": "Title: A Note on the Convexity of $\\log \\det ( I + KX^{-1} )$ and its\n  Constrained Optimization Representation Abstract: This note provides another proof for the {\\em convexity} ({\\em strict\nconvexity}) of $\\log \\det ( I + KX^{-1} )$ over the positive definite cone for\nany given positive semidefinite matrix $K \\succeq 0$ (positive definite matrix\n$K \\succ 0$) and the {\\em strictly convexity} of $\\log \\det (K + X^{-1})$ over\nthe positive definite cone for any given $K \\succeq 0$. Equivalent optimization\nrepresentation with linear matrix inequalities (LMIs) for the functions $\\log\n\\det ( I + KX^{-1} )$ and $\\log \\det (K + X^{-1})$ are presented. Their\noptimization representations with LMI constraints can be particularly useful\nfor some related synthetic design problems. \n\n"}
{"id": "1509.01047", "contents": "Title: A Theory of Super-Resolution from Short-Time Fourier Transform\n  Measurements Abstract: While spike trains are obviously not band-limited, the theory of\nsuper-resolution tells us that perfect recovery of unknown spike locations and\nweights from low-pass Fourier transform measurements is possible provided that\nthe minimum spacing, $\\Delta$, between spikes is not too small. Specifically,\nfor a measurement cutoff frequency of $f_c$, Donoho [2] showed that exact\nrecovery is possible if the spikes (on $\\mathbb{R}$) lie on a lattice and\n$\\Delta > 1/f_c$, but does not specify a corresponding recovery method.\nCand$\\text{\\`e}$s and Fernandez-Granda [3, 4] provide a convex programming\nmethod for the recovery of periodic spike trains (i.e., spike trains on the\ntorus $\\mathbb{T}$), which succeeds provably if $\\Delta > 2/f_c$ and $f_c \\geq\n128$ or if $\\Delta > 1.26/f_c$ and $f_c \\geq 10^3$, and does not need the\nspikes within the fundamental period to lie on a lattice. In this paper, we\ndevelop a theory of super-resolution from short-time Fourier transform (STFT)\nmeasurements. Specifically, we present a recovery method similar in spirit to\nthe one in [3] for pure Fourier measurements. For a STFT Gaussian window\nfunction of width $\\sigma = 1/(4f_c)$ this method succeeds provably if $\\Delta\n> 1/f_c$, without restrictions on $f_c$. Our theory is based on a\nmeasure-theoretic formulation of the recovery problem, which leads to\nconsiderable generality in the sense of the results being grid-free and\napplying to spike trains on both $\\mathbb{R}$ and $\\mathbb{T}$. The case of\nspike trains on $\\mathbb{R}$ comes with significant technical challenges. For\nrecovery of spike trains on $\\mathbb{T}$ we prove that the correct solution can\nbe approximated---in weak-* topology---by solving a sequence of\nfinite-dimensional convex programming problems. \n\n"}
{"id": "1509.01187", "contents": "Title: Unmanned Aerial Vehicle with Underlaid Device-to-Device Communications:\n  Performance and Tradeoffs Abstract: In this paper, the deployment of an unmanned aerial vehicle (UAV) as a flying\nbase station used to provide on the fly wireless communications to a given\ngeographical area is analyzed. In particular, the co-existence between the UAV,\nthat is transmitting data in the downlink, and an underlaid device-todevice\n(D2D) communication network is considered. For this model, a tractable\nanalytical framework for the coverage and rate analysis is derived. Two\nscenarios are considered: a static UAV and a mobile UAV. In the first scenario,\nthe average coverage probability and the system sum-rate for the users in the\narea are derived as a function of the UAV altitude and the number of D2D users.\nIn the second scenario, using the disk covering problem, the minimum number of\nstop points that the UAV needs to visit in order to completely cover the area\nis computed. Furthermore, considering multiple retransmissions for the UAV and\nD2D users, the overall outage probability of the D2D users is derived.\nSimulation and analytical results show that, depending on the density of D2D\nusers, optimal values for the UAV altitude exist for which the system sum-rate\nand the coverage probability are maximized. Moreover, our results also show\nthat, by enabling the UAV to intelligently move over the target area, the total\nrequired transmit power of UAV while covering the entire area, is minimized.\nFinally, in order to provide a full coverage for the area of interest, the\ntradeoff between the coverage and delay, in terms of the number of stop points,\nis discussed. \n\n"}
{"id": "1509.01371", "contents": "Title: Complete Weight Enumerators of a Family of Three-Weight Linear Codes Abstract: Linear codes have been an interesting topic in both theory and practice for\nmany years. In this paper, for an odd prime $p$, we present the explicit\ncomplete weight enumerator of a family of $p$-ary linear codes constructed with\ndefining set. The weight enumerator is an mmediate result of the complete\nweight enumerator, which shows that the codes proposed in this paper are\nthree-weight linear codes. Additionally, all nonzero codewords are minimal and\nthus they are suitable for secret sharing. \n\n"}
{"id": "1509.01377", "contents": "Title: Generalized Multicast Multibeam Precoding for Satellite Communications Abstract: This paper deals with the problem of precoding in multibeam satellite\nsystems. In contrast to general multiuser multiple-input-multiple-output (MIMO)\ncellular schemes, multibeam satellite architectures suffer from different\nchallenges. First, satellite communications standards embed more than one user\nin each frame in order to increase the channel coding gain. This leads to the\ndifferent so-called multigroup multicast model, whose optimization requires\ncomputationally complex operations. Second, when the data traffic is generated\nby several Earth stations (gateways), the precoding matrix must be\ndistributively computed and attain additional payload restrictions. Third,\nsince the feedback channel is adverse (large delay and quantization errors),\nthe precoding must be able to deal with such uncertainties. In order to solve\nthe aforementioned problems, we propose a two-stage precoding design in order\nto both limit the multibeam interference and to enhance the intra-beam minimum\nuser signal power (i.e. the one that dictates the rate allocation per beam). A\nrobust version of the proposed precoder based on a first perturbation model is\npresented. This mechanism behaves well when the channel state information is\ncorrupted. Furthermore, we propose a per beam user grouping mechanism together\nwith its robust version in order to increase the precoding gain. Finally, a\nmethod for dealing with the multiple gateway architecture is presented, which\noffers high throughputs with a low inter-gateway communication. The conceived\ndesigns are evaluated in a close-to-real beam pattern and the latest broadband\ncommunication standard for satellite communications. \n\n"}
{"id": "1509.03411", "contents": "Title: Receiver Algorithm based on Differential Signaling for SIMO Phase Noise\n  Channels with Common and Separate Oscillator Configurations Abstract: In this paper, a receiver algorithm consisting of differential transmission\nand a two-stage detection for a single-input multiple-output (SIMO) phase-noise\nchannels is studied. Specifically, the phases of the QAM modulated data symbols\nare manipulated before transmission in order to make them more immune to the\nrandom rotational effects of phase noise. At the receiver, a two-stage detector\nis implemented, which first detects the amplitude of the transmitted symbols\nfrom a nonlinear combination of the received signal amplitudes. Then in the\nsecond stage, the detector performs phase detection. The studied signaling\nmethod does not require transmission of any known symbols that act as pilots.\nFurthermore, no phase noise estimator (or a tracker) is needed at the receiver\nto compensate the effect of phase noise. This considerably reduces the\ncomplexity of the receiver structure. Moreover, it is observed that the studied\nalgorithm can be used for the setups where a common local oscillator or\nseparate independent oscillators drive the radio-frequency circuitries\nconnected to each antenna. Due to the differential encoding/decoding of the\nphase, weighted averaging can be employed at a multi-antenna receiver, allowing\nfor phase noise suppression to leverage the large number of antennas. Hence, we\nobserve that the performance improves by increasing the number of antennas,\nespecially in the separate oscillator case. Further increasing the number of\nreceive antennas results in a performance error floor, which is a function of\nthe quality of the oscillator at the transmitter. \n\n"}
{"id": "1509.04303", "contents": "Title: Downlink Performance of Massive MIMO under General Channel Aging\n  Conditions Abstract: Massive multiple-input multiple-output (MIMO) is a promising technology\naiming at achieving high spectral efficiency by deploying a large number of\nbase station (BS) antennas using coherent combining. Channel aging due to user\nmobility is a significant degrading factor of such systems. In addition, cost\nefficiency of massive MIMO is a prerecuisite for their deployment, that leads\nto low cost antenna elements inducing high phase noise. Since phase is\ntime-dependent, it contributes to channel aging. For this reason, we present a\nnovel joint channel-phase noise model, that enables us to study the downlink of\nmassive MIMO with maximum ratio transmission (MRT) precoder under these\nconditions by means of the deterministic equivalent of the achievable sum-rate.\nAmong the noteworthy outcomes is that the degradation due to user mobility\ndominates over the effect of phase noise. Nevertheless, we demonstrate that the\njoint effects of phase noise and user mobility do not degrade the power scaling\nlaw $1/\\sqrt{M}$ ($M$ is the number of BS antennas), as has been established in\nmassive MIMO systems with imperfect channel state information. \n\n"}
{"id": "1509.04491", "contents": "Title: Sparse Multinomial Logistic Regression via Approximate Message Passing Abstract: For the problem of multi-class linear classification and feature selection,\nwe propose approximate message passing approaches to sparse multinomial\nlogistic regression (MLR). First, we propose two algorithms based on the Hybrid\nGeneralized Approximate Message Passing (HyGAMP) framework: one finds the\nmaximum a posteriori (MAP) linear classifier and the other finds an\napproximation of the test-error-rate minimizing linear classifier. Then we\ndesign computationally simplified variants of these two algorithms. Next, we\ndetail methods to tune the hyperparameters of their assumed statistical models\nusing Stein's unbiased risk estimate (SURE) and expectation-maximization (EM),\nrespectively. Finally, using both synthetic and real-world datasets, we\ndemonstrate improved error-rate and runtime performance relative to existing\nstate-of-the-art approaches to sparse MLR. \n\n"}
{"id": "1509.06611", "contents": "Title: Stochastic Content-Centric Multicast Scheduling for Cache-Enabled\n  Heterogeneous Cellular Networks Abstract: Caching at small base stations (SBSs) has demonstrated significant benefits\nin alleviating the backhaul requirement in heterogeneous cellular networks\n(HetNets). While many existing works focus on what contents to cache at each\nSBS, an equally important problem is what contents to deliver so as to satisfy\ndynamic user demands given the cache status. In this paper, we study optimal\ncontent delivery in cache-enabled HetNets by taking into account the inherent\nmulticast capability of wireless medium. We consider stochastic content\nmulticast scheduling to jointly minimize the average network delay and power\ncosts under a multiple access constraint. We establish a content-centric\nrequest queue model and formulate this stochastic optimization problem as an\ninfinite horizon average cost Markov decision process (MDP). By using\n\\emph{relative value iteration} and special properties of the request queue\ndynamics, we characterize some properties of the value function of the MDP.\nBased on these properties, we show that the optimal multicast scheduling policy\nis of threshold type. Then, we propose a structure-aware optimal algorithm to\nobtain the optimal policy. We also propose a low-complexity suboptimal policy,\nwhich possesses similar structural properties to the optimal policy, and\ndevelop a low-complexity algorithm to obtain this policy. \n\n"}
{"id": "1509.07223", "contents": "Title: Secure Transmission for Relay Wiretap Channels in the Presence of\n  Spatially Random Eavesdroppers Abstract: We propose a secure transmission scheme for a relay wiretap channel, where a\nsource communicates with a destination via a decode-and-forward relay in the\npresence of spatially random-distributed eavesdroppers. We assume that the\nsource is equipped with multiple antennas, whereas the relay, the destination,\nand the eavesdroppers are equipped with a single antenna each. In the proposed\nscheme, in addition to information signals, the source transmits artificial\nnoise signals in order to confuse the eavesdroppers. With the target of\nmaximizing the secrecy throughput of the relay wiretap channel, we derive a\nclosed-form expression for the transmission outage probability and an\neasy-to-compute expression for the secrecy outage probability. Using these\nexpressions, we determine the optimal power allocation factor and wiretap code\nrates that guarantee the maximum secrecy throughput, while satisfying a secrecy\noutage probability constraint. Furthermore, we examine the impact of source\nantenna number on the secrecy throughput, showing that adding extra transmit\nantennas at the source brings about a significant increase in the secrecy\nthroughput. \n\n"}
{"id": "1509.09222", "contents": "Title: On Jamming Against Wireless Networks Abstract: In this paper, we study jamming attacks against wireless networks.\nSpecifically, we consider a network of base stations (BS) or access points (AP)\nand investigate the impact of a fixed number of jammers that are randomly\ndeployed according to a Binomial point process. We shed light on the network\nperformance in terms of a) the outage probability and b) the error probability\nof a victim receiver in the downlink of this wireless network. We derive\nanalytical expressions for both these metrics and discuss in detail how the\njammer network must adapt to the various wireless network parameters in order\nto effectively attack the victim receivers. For instance, we will show that\nwith only 1 jammer per BS/AP a) the outage probability of the wireless network\ncan be increased from 1% (as seen in the non-jamming case) to 80% and b) when\nretransmissions are used, the jammers cause the effective network activity\nfactor (and hence the interference among the BSs) to be doubled. Furthermore,\nwe show that the behavior of the jammer network as a function of the BS/AP\ndensity is not obvious. In particular, an interesting concave-type behavior is\nseen which indicates that the number of jammers required to attack the wireless\nnetwork must scale with the BS density only until a certain value beyond which\nit decreases. In the context of error probability of the victim receiver, we\nstudy whether or not some recent results related to jamming in the\npoint-to-point link scenario can be extended to the case of jamming against\nwireless networks. Numerical results are presented to validate the theoretical\ninferences presented. \n\n"}
{"id": "1510.00252", "contents": "Title: RF Lens-Embedded Massive MIMO Systems: Fabrication Issues and Codebook\n  Design Abstract: In this paper, we investigate a radio frequency (RF) lens-embedded massive\nmultiple-input multiple-output (MIMO) system and evaluate the system\nperformance of limited feedback by utilizing a technique for generating a\nsuitable codebook for the system. We fabricate an RF lens that operates on a 77\nGHz (mmWave) band. Experimental results show a proper value of amplitude gain\nand an appropriate focusing property. In addition, using a simple numerical\ntechnique--beam propagation method (BPM)--we estimate the power profile of the\nRF lens and verify its accordance with experimental results. We also design a\ncodebook--multi-variance codebook quantization (MVCQ)--for limited feedback by\nconsidering the characteristics of the RF lens antenna for massive MIMO\nsystems. Numerical results confirm that the proposed system shows significant\nperformance enhancement over a conventional massive MIMO system without an RF\nlens. \n\n"}
{"id": "1510.02947", "contents": "Title: Concentration of Measure Inequalities and Their Communication and\n  Information-Theoretic Applications Abstract: During the last two decades, concentration of measure has been a subject of\nvarious exciting developments in convex geometry, functional analysis,\nstatistical physics, high-dimensional statistics, probability theory,\ninformation theory, communications and coding theory, computer science, and\nlearning theory. One common theme which emerges in these fields is\nprobabilistic stability: complicated, nonlinear functions of a large number of\nindependent or weakly dependent random variables often tend to concentrate\nsharply around their expected values. Information theory plays a key role in\nthe derivation of concentration inequalities. Indeed, both the entropy method\nand the approach based on transportation-cost inequalities are two major\ninformation-theoretic paths toward proving concentration.\n  This brief survey is based on a recent monograph of the authors in the\nFoundations and Trends in Communications and Information Theory (online\navailable at http://arxiv.org/pdf/1212.4663v8.pdf), and a tutorial given by the\nauthors at ISIT 2015. It introduces information theorists to three main\ntechniques for deriving concentration inequalities: the martingale method, the\nentropy method, and the transportation-cost inequalities. Some applications in\ninformation theory, communications, and coding theory are used to illustrate\nthe main ideas. \n\n"}
{"id": "1510.03510", "contents": "Title: Repeat-Accumulate Codes for Reconciliation in Continuous Variable\n  Quantum Key Distribution Abstract: This paper investigates the design of low-complexity error correction codes\nfor the verification step in continuous variable quantum key distribution\n(CVQKD) systems. We design new coding schemes based on quasi-cyclic\nrepeat-accumulate codes which demonstrate good performances for CVQKD\nreconciliation. \n\n"}
{"id": "1510.04455", "contents": "Title: A unified framework for information integration based on information\n  geometry Abstract: We propose a unified theoretical framework for quantifying spatio-temporal\ninteractions in a stochastic dynamical system based on information geometry. In\nthe proposed framework, the degree of interactions is quantified by the\ndivergence between the actual probability distribution of the system and a\nconstrained probability distribution where the interactions of interest are\ndisconnected. This framework provides novel geometric interpretations of\nvarious information theoretic measures of interactions, such as mutual\ninformation, transfer entropy, and stochastic interaction in terms of how\ninteractions are disconnected. The framework therefore provides an intuitive\nunderstanding of the relationships between the various quantities. By extending\nthe concept of transfer entropy, we propose a novel measure of integrated\ninformation which measures causal interactions between parts of a system.\nIntegrated information quantifies the extent to which the whole is more than\nthe sum of the parts and can be potentially used as a biological measure of the\nlevels of consciousness. \n\n"}
{"id": "1510.05205", "contents": "Title: Asymptotic Scaling Laws of Wireless Adhoc Network with Physical Layer\n  Caching Abstract: We propose a physical layer (PHY) caching scheme for wireless adhoc networks.\nThe PHY caching exploits cache-assisted multihop gain and cache-induced\ndual-layer CoMP gain, which substantially improves the throughput of wireless\nadhoc networks. In particular, the PHY caching scheme contains a novel PHY\ntransmission mode called the cache-induced dual-layer CoMP which can support\nhomogeneous opportunistic CoMP in the wireless adhoc network. Compared with\ntraditional per-node throughput scaling results of\n\\Theta\\left(1/\\sqrt{N}\\right), we can achieve O(1) per node throughput for a\ncached wireless adhoc network with N nodes. Moreover, we analyze the throughput\nof the PHY caching scheme for regular wireless adhoc networks and study the\nimpact of various system parameters on the PHY caching gain. \n\n"}
{"id": "1510.05938", "contents": "Title: Ultra Dense Networks: The New Wireless Frontier for Enabling 5G Access Abstract: The extreme traffic load that future wireless networks are expected to\naccommodate requires a re-thinking of the system design. Initial estimations\nindicate that, different from the evolutionary path of previous cellular\ngenerations that was based on spectral efficiency improvements, the most\nsubstantial amount of future system performance gains will be obtained by means\nof network infrastructure densification. By increasing the density of\noperator-deployed infrastructure elements, along with incorporation of\nuser-deployed access nodes and mobile user devices acting as \"infrastructure\nprosumers\", it is expected that having one or more access nodes exclusively\ndedicated to each user will become feasible, introducing the ultra dense\nnetwork (UDN) paradigm. Although it is clear that UDNs are able to take\nadvantage of the significant benefits provided by proximal transmissions and\nincreased spatial reuse of system resources, at the same time, large node\ndensity and irregular deployment introduce new challenges, mainly due to the\ninterference environment characteristics that are vastly different from\nprevious cellular deployments. This article attempts to provide insights on\nfundamental issues related to UDN deployment, such as determining the\ninfrastructure density required to support given traffic load requirements and\nthe benefits of network-wise coordination, demonstrating the potential of UDNs\nfor 5G wireless networks. \n\n"}
{"id": "1510.07176", "contents": "Title: On the Effect of Fronthaul Latency on ARQ in C-RAN Systems Abstract: In the Cloud Radio Access Network (C-RAN) architecture, a Control Unit (CU)\nimplements the baseband processing functionalities of a cluster of Base\nStations (BSs), which are connected to it through a fronthaul network. This\narchitecture enables centralized processing at the CU, and hence the\nimplementation of enhanced interference mitigation strategies, but it also\nentails an increased decoding latency due to the transport on the fronthaul\nnetwork. The fronthaul latency may offset the benefits of centralized\nprocessing when considering the performance of protocols at layer 2 and above.\nThis letter studies the impact of fronthaul latency on the performance of\nstandard Automatic Retransmission reQuest (ARQ) protocols, namely Stop and\nWait, Go-Back-N and Selective Repeat. The performance of the C-RAN architecture\nin terms of throughput and efficiency is compared to the that of a conventional\ncellular system with local processing, as well as with that of a proposed\nhybrid C-RAN system in which BSs can perform decoding. The dynamics of the\nsystem are modeled as a multi-dimensional Markov process that includes\nsub-chains to capture the temporal correlation of interference and channel\ngains. Numerical results yield insights into the impact of system parameters\nsuch as fronthaul latency and signal-to-interference ratio on different ARQ\nprotocols. \n\n"}
{"id": "1510.07295", "contents": "Title: Impact of Dual Slope Path Loss on User Association in HetNets Abstract: Intelligent load balancing is essential to fully realize the benefits of\ndense heterogeneous networks. Current techniques have largely been studied with\nsingle slope path loss models, though multi-slope models are known to more\nclosely match real deployments. This paper develops insight into the\nperformance of biasing and uplink/downlink decoupling for user association in\nHetNets with dual slope path loss models. It is shown that dual slope path loss\nmodels change the tradeoffs inherent in biasing and reduce gains from both\nbiasing and uplink/downlink decoupling. The results show that with the dual\nslope path loss models, the bias maximizing the median rate is not optimal for\nother users, e.g., edge users. Furthermore, optimal downlink biasing is shown\nto realize most of the gains from downlink-uplink decoupling. Moreover, the\nuser association gains in dense networks are observed to be quite sensitive to\nthe path loss exponent beyond the critical distance in a dual slope model. \n\n"}
{"id": "1510.07728", "contents": "Title: Design of Raptor Codes in the Low SNR Regime with Applications in\n  Quantum Key Distribution Abstract: The focus of this work is on the design of Raptor codes for continuous\nvariable Quantum key distribution (CV-QKD) systems. We design a highly\nefficient Raptor code for very low signal to noise ratios (SNRs), which enables\nCV-QKD systems to operate over long distances with a significantly higher\nsecret key rate compared to conventional fixed rate codes. The degree\ndistribution design of Raptor codes in the low SNR regime is formulated as a\nlinear program, where a set of optimized degree distributions are also obtained\nthrough linear programming. Simulation results show that the designed code\nachieves efficiencies higher than 94\\% for SNRs as low as -20 dB and -30 dB. We\nfurther propose a new error reconciliation protocol for CV-QKD systems by using\nRaptor codes and show that it can achieve higher secret key rates over long\ndistances compared to existing protocols. \n\n"}
{"id": "1510.08183", "contents": "Title: Raptor Codes in the Low SNR Regime Abstract: In this paper, we revisit the design of Raptor codes for binary input\nadditive white Gaussian noise (BIAWGN) channels, where we are interested in\nvery low signal to noise ratios (SNRs). A linear programming degree\ndistribution optimization problem is defined for Raptor codes in the low SNR\nregime through several approximations. We also provide an exact expression for\nthe polynomial representation of the degree distribution with infinite maximum\ndegree in the low SNR regime, which enables us to calculate the exact value of\nthe fractions of output nodes of small degrees. A more practical degree\ndistribution design is also proposed for Raptor codes in the low SNR regime,\nwhere we include the rate efficiency and the decoding complexity in the\noptimization problem, and an upper bound on the maximum rate efficiency is\nderived for given design parameters. Simulation results show that the Raptor\ncode with the designed degree distributions can approach rate efficiencies\nlarger than 0.95 in the low SNR regime. \n\n"}
{"id": "1511.00353", "contents": "Title: Universally Near Optimal Online Power Control for Energy Harvesting\n  Nodes Abstract: We consider online power control for an energy harvesting system with random\ni.i.d. energy arrivals and a finite size battery. We propose a simple online\npower control policy for this channel that requires minimal information\nregarding the distribution of the energy arrivals and prove that it is\nuniversally near-optimal for all parameter values. In particular, the policy\ndepends on the distribution of the energy arrival process only through its mean\nand it achieves the optimal long-term average throughput of the channel within\nboth constant additive and multiplicative gaps. Existing heuristics for online\npower control fail to achieve such universal performance. This result also\nallows us to approximate the long-term average throughput of the system with a\nsimple formula, which sheds some light on the qualitative behavior of the\nthroughput, namely how it depends on the distribution of the energy arrivals\nand the size of the battery. \n\n"}
{"id": "1511.00856", "contents": "Title: Designing dedicated data compression for physics experiments within FPGA\n  already used for data acquisition Abstract: Physics experiments produce enormous amount of raw data, counted in petabytes\nper day. Hence, there is large effort to reduce this amount, mainly by using\nsome filters. The situation can be improved by additionally applying some data\ncompression techniques: removing redundancy and optimally encoding the actual\ninformation. Preferably, both filtering and data compression should fit in FPGA\nalready used for data acquisition - reducing requirements of both data storage\nand networking architecture.\n  We will briefly explain and discuss some basic techniques, for a better focus\napplied to design a dedicated data compression system basing on a sample data\nfrom a prototype of a tracking detector: 10000 events for 48 channels. We will\nfocus on the time data here, which after neglecting the headers and applying\ndata filtering, requires on average 1170 bits/event using the current coding.\nEncoding relative times (differences) and grouping data by channels, reduces\nthis number to 798 bits/channel, still using fixed length coding: a fixed\nnumber of bits used for a given value. Using variable length Huffman coding to\nencode numbers of digital pulses for a channel and the most significant bits of\nvalues (simple binning) reduces further this number to 552 bits/event. Using\nadaptive binning: denser for frequent values, and an accurate entropy coder we\nget further down to 455 bits/event - this option can easily fit unused\nresources of FPGA currently used for data acquisition. Finally, using separate\nprobability distributions for different channels, what could be done by a\nsoftware compressor, leads to 437bits/event, what is 2.67 times less than the\noriginal 1170 bits/event. \n\n"}
{"id": "1511.01650", "contents": "Title: Statistical physics and approximate message-passing algorithms for\n  sparse linear estimation problems in signal processing and coding theory Abstract: This thesis is interested in the application of statistical physics methods\nand inference to sparse linear estimation problems. The main tools are the\ngraphical models and approximate message-passing algorithm together with the\ncavity method. We will also use the replica method of statistical physics of\ndisordered systems which allows to associate to the studied problems a cost\nfunction referred as the potential of free entropy in physics. It allows to\npredict the different phases of typical complexity of the problem as a function\nof external parameters such as the noise level or the number of measurements\none has about the signal: the inference can be typically easy, hard or\nimpossible. We will see that the hard phase corresponds to a regime of\ncoexistence of the actual solution together with another unwanted solution of\nthe message passing equations. In this phase, it represents a metastable state\nwhich is not the true equilibrium solution. This phenomenon can be linked to\nsupercooled water blocked in the liquid state below its freezing critical\ntemperature. We will use a method that allows to overcome the metastability\nmimicing the strategy adopted by nature itself for supercooled water: the\nnucleation and spatial coupling. In supercooled water, a weak localized\nperturbation is enough to create a crystal nucleus that will propagate in all\nthe medium thanks to the physical couplings between closeby atoms. The same\nprocess will help the algorithm to find the signal, thanks to the introduction\nof a nucleus containing local information about the signal. It will then spread\nas a \"reconstruction wave\" similar to the crystal in the water. After an\nintroduction to statistical inference and sparse linear estimation, we will\nintroduce the necessary tools. Then we will move to applications of these\nnotions to signal processing and coding theory problems. \n\n"}
{"id": "1511.02093", "contents": "Title: Evaluation of the Hamming weights of a class of linear codes based on\n  Gauss sums Abstract: Linear codes with a few weights have been widely investigated in recent\nyears. In this paper, we mainly use Gauss sums to represent the Hamming weights\nof a class of $q$-ary linear codes under some certain conditions, where $q$ is\na power of a prime. The lower bound of its minimum Hamming distance is\nobtained. In some special cases, we evaluate the weight distributions of the\nlinear codes by semi-primitive Gauss sums and obtain some one-weight,\ntwo-weight linear codes. It is quite interesting that we find new optimal codes\nachieving some bounds on linear codes. The linear codes in this paper can be\nused in secret sharing schemes, authentication codes and data storage systems. \n\n"}
{"id": "1511.03932", "contents": "Title: Distortion-Memory Tradeoffs in Cache-Aided Wireless Video Delivery Abstract: Mobile network operators are considering caching as one of the strategies to\nkeep up with the increasing demand for high-definition wireless video\nstreaming. By prefetching popular content into memory at wireless access points\nor end user devices, requests can be served locally, relieving strain on\nexpensive backhaul. In addition, using network coding allows the simultaneous\nserving of distinct cache misses via common coded multicast transmissions,\nresulting in significantly larger load reductions compared to those achieved\nwith conventional delivery schemes. However, prior work does not exploit the\nproperties of video and simply treats content as fixed-size files that users\nwould like to fully download. Our work is motivated by the fact that video can\nbe coded in a scalable fashion and that the decoded video quality depends on\nthe number of layers a user is able to receive. Using a Gaussian source model,\ncaching and coded delivery methods are designed to minimize the squared error\ndistortion at end user devices. Our work is general enough to consider\nheterogeneous cache sizes and video popularity distributions. \n\n"}
{"id": "1511.06149", "contents": "Title: Blind Recovery of Sparse Signals from Subsampled Convolution Abstract: Subsampled blind deconvolution is the recovery of two unknown signals from\nsamples of their convolution. To overcome the ill-posedness of this problem,\nsolutions based on priors tailored to specific application have been developed\nin practical applications. In particular, sparsity models have provided\npromising priors. However, in spite of empirical success of these methods in\nmany applications, existing analyses are rather limited in two main ways: by\ndisparity between the theoretical assumptions on the signal and/or measurement\nmodel versus practical setups; or by failure to provide a performance guarantee\nfor parameter values within the optimal regime defined by the information\ntheoretic limits. In particular, it has been shown that a naive sparsity model\nis not a strong enough prior for identifiability in the blind deconvolution\nproblem. Instead, in addition to sparsity, we adopt a conic constraint, which\nenforces spectral flatness of the signals. Under this prior, we provide an\niterative algorithm that achieves guaranteed performance in blind deconvolution\nat near optimal sample complexity. Numerical results show the empirical\nperformance of the iterative algorithm agrees with the performance guarantee. \n\n"}
{"id": "1511.06483", "contents": "Title: Directional Initial Access for Millimeter Wave Cellular Systems Abstract: The millimeter wave (mmWave) bands have recently attracted considerable\ninterest for next-generation cellular systems due to the massive available\nbandwidths at these frequencies. However, a key challenge in designing mmWave\ncellular systems is initial access -- the procedure by which a mobile\nestablishes an initial link-layer connection to a base station cell. MmWave\ncommunication relies on highly directional transmissions and the initial access\nprocedure must thus provide a mechanism by which initial transmission\ndirections can be searched in a potentially large angular space. Design options\nare compared considering different scanning and signaling procedures to\nevaluate access delay and system overhead. The channel structure and multiple\naccess issues are also considered. The analysis demonstrates significant\nbenefits of low-resolution fully digital architectures in comparison to single\nstream analog beamforming. \n\n"}
{"id": "1511.06518", "contents": "Title: Enhanced Transmit Antenna Selection Scheme for Secure Throughput\n  Maximization Without CSI at the Transmitter and its Applications on Smart\n  Grids Abstract: This paper addresses the establishment of secure communication links between\nsmart-meters (Alice) and an aggregator (Bob) in the presence of an eavesdropper\n(Eve). The proposed scenario assumes: (i) MIMOME wiretap channel; (ii) transmit\nantenna selection at the Alice; (iii) no channel state information at the\ntransmitter; (iv) fixed Wyner codes; and (v) guarantee of secure throughput by\nboth quality of service and secrecy outage constraints. We propose a simple\nprotocol to enhance security via transmit antenna selection, and then assess\nits performance in closed-form by means of secrecy outage and successful\ntransmission probabilities. We assume these probabilities are our constraints\nand then maximize the secure throughput, establishing a security-reliability\ntrade-off for the proposed scenario. Our numerical results illustrate the\neffect of this trade-off on the secure throughput as well as on the number of\nantennas at Alice, Bob and Eve. Interestingly, a small sacrifice in reliability\nallows secrecy enhancement in terms of secure bps/Hz. We apply this idea in our\nsmart grid application to exemplify that, although Eve may acquire some samples\nof the average power demand of a household, it is not enough to properly\nreconstruct such curve. \n\n"}
{"id": "1511.07533", "contents": "Title: Distributed Energy Beamforming with One-Bit Feedback Abstract: Energy beamforming (EB) is a key technique for achieving efficient\nradio-frequency (RF) transmission enabled wireless energy transfer (WET). By\noptimally designing the waveforms from multiple energy transmitters (ETs) over\nthe wireless channels, they are constructively combined at the energy receiver\n(ER) to achieve an EB gain that scales with the number of ETs. However, the\noptimal design of transmit waveforms requires accurate channel state\ninformation (CSI) at the ETs, which is challenging to obtain in practical WET\nsystems. In this paper, we propose a new channel training scheme to achieve\noptimal EB gain in a distributed WET system, where multiple separated ETs\nadjust their transmit phases to collaboratively send power to a single ER in an\niterative manner, based on one-bit feedback from the ER per training interval\nwhich indicates the increase/decrease of the received power level from one\nparticular ET over two preassigned transmit phases. The proposed EB algorithm\ncan be efficiently implemented in practical WET systems even with a large\nnumber of distributed ETs, and is analytically shown to converge quickly to the\noptimal EB design as the number of feedback intervals per ET increases.\nNumerical results are provided to evaluate the performance of the proposed\nalgorithm as compared to other distributed EB designs. \n\n"}
{"id": "1511.08631", "contents": "Title: Dynamic Clustering and ON/OFF Strategies for Wireless Small Cell\n  Networks Abstract: In this paper, a novel cluster-based approach for maximizing the energy\nefficiency of wireless small cell networks is proposed. A dynamic mechanism is\nproposed to group locally-coupled small cell base stations (SBSs) into clusters\nbased on location and traffic load. Within each formed cluster, SBSs coordinate\ntheir transmission parameters to minimize a cost function which captures the\ntradeoffs between energy efficiency and flow level performance, while\nsatisfying their users' quality-of-service requirements. Due to the lack of\ninter-cluster communications, clusters compete with one another in order to\nimprove the overall network's energy efficiency. This inter-cluster competition\nis formulated as a noncooperative game between clusters that seek to minimize\ntheir respective cost functions. To solve this game, a distributed learning\nalgorithm is proposed using which clusters autonomously choose their optimal\ntransmission strategies based on local information. It is shown that the\nproposed algorithm converges to a stationary mixed-strategy distribution which\nconstitutes an epsilon-coarse correlated equilibrium for the studied game.\nSimulation results show that the proposed approach yields significant\nperformance gains reaching up to 36% of reduced energy expenditures and up to\n41% of reduced fractional transfer time compared to conventional approaches. \n\n"}
{"id": "1512.00156", "contents": "Title: Covariance-domain Dictionary Learning for Overcomplete EEG Source\n  Identification Abstract: We propose an algorithm targeting the identification of more sources than\nchannels for electroencephalography (EEG). Our overcomplete source\nidentification algorithm, Cov-DL, leverages dictionary learning methods applied\nin the covariance-domain. Assuming that EEG sources are uncorrelated within\nmoving time-windows and the scalp mixing is linear, the forward problem can be\ntransferred to the covariance domain which has higher dimensionality than the\noriginal EEG channel domain. This allows for learning the overcomplete mixing\nmatrix that generates the scalp EEG even when there may be more sources than\nsensors active at any time segment, i.e. when there are non-sparse sources.\nThis is contrary to straight-forward dictionary learning methods that are based\non the assumption of sparsity, which is not a satisfied condition in the case\nof low-density EEG systems. We present two different learning strategies for\nCov-DL, determined by the size of the target mixing matrix. We demonstrate that\nCov-DL outperforms existing overcomplete ICA algorithms under various scenarios\nof EEG simulations and real EEG experiments. \n\n"}
{"id": "1512.07743", "contents": "Title: Cloud Radio Access Network: Virtualizing Wireless Access for Dense\n  Heterogeneous Systems Abstract: Cloud Radio Access Network (C-RAN) refers to the virtualization of base\nstation functionalities by means of cloud computing. This results in a novel\ncellular architecture in which low-cost wireless access points, known as radio\nunits (RUs) or remote radio heads (RRHs), are centrally managed by a\nreconfigurable centralized \"cloud\", or central, unit (CU). C-RAN allows\noperators to reduce the capital and operating expenses needed to deploy and\nmaintain dense heterogeneous networks. This critical advantage, along with\nspectral efficiency, statistical multiplexing and load balancing gains, make\nC-RAN well positioned to be one of the key technologies in the development of\n5G systems. In this paper, a succinct overview is presented regarding the state\nof the art on the research on C-RAN with emphasis on fronthaul compression,\nbaseband processing, medium access control, resource allocation, system-level\nconsiderations and standardization efforts. \n\n"}
{"id": "1512.08269", "contents": "Title: Statistical and Computational Guarantees for the Baum-Welch Algorithm Abstract: The Hidden Markov Model (HMM) is one of the mainstays of statistical modeling\nof discrete time series, with applications including speech recognition,\ncomputational biology, computer vision and econometrics. Estimating an HMM from\nits observation process is often addressed via the Baum-Welch algorithm, which\nis known to be susceptible to local optima. In this paper, we first give a\ngeneral characterization of the basin of attraction associated with any global\noptimum of the population likelihood. By exploiting this characterization, we\nprovide non-asymptotic finite sample guarantees on the Baum-Welch updates,\nguaranteeing geometric convergence to a small ball of radius on the order of\nthe minimax rate around a global optimum. As a concrete example, we prove a\nlinear rate of convergence for a hidden Markov mixture of two isotropic\nGaussians given a suitable mean separation and an initialization within a ball\nof large radius around (one of) the true parameters. To our knowledge, these\nare the first rigorous local convergence guarantees to global optima for the\nBaum-Welch algorithm in a setting where the likelihood function is nonconvex.\nWe complement our theoretical results with thorough numerical simulations\nstudying the convergence of the Baum-Welch algorithm and illustrating the\naccuracy of our predictions. \n\n"}
{"id": "1512.08419", "contents": "Title: Dynamic Transmit Covariance Design in MIMO Fading Systems With Unknown\n  Channel Distributions and Inaccurate Channel State Information Abstract: This paper considers dynamic transmit covariance design in point-to-point\nMIMO fading systems with unknown channel state distributions and inaccurate\nchannel state information subject to both long term and short term power\nconstraints. First, the case of instantaneous but possibly inaccurate channel\nstate information at the transmitter (CSIT) is treated. By extending the\ndrift-plus-penalty technique, a dynamic transmit covariance policy is developed\nand is shown to approach optimality with an $O(\\delta)$ gap, where $\\delta$ is\nthe inaccuracy measure of CSIT, regardless of the channel state distribution\nand without requiring knowledge of this distribution. Next, the case of delayed\nand inaccurate channel state information is considered. The optimal transmit\ncovariance solution that maximizes the ergodic capacity is fundamentally\ndifferent in this case, and a different online algorithm based on convex\nprojections is developed. The proposed algorithm for this delayed-CSIT case\nalso has an $O(\\delta)$ optimality gap, where $\\delta$ is again the inaccuracy\nmeasure of CSIT. \n\n"}
{"id": "1512.08650", "contents": "Title: An Importance Sampling Scheme for Models in a Strong External Field Abstract: We propose Monte Carlo methods to estimate the partition function of the\ntwo-dimensional Ising model in the presence of an external magnetic field. The\nestimation is done in the dual of the Forney factor graph representing the\nmodel. The proposed methods can efficiently compute an estimate of the\npartition function in a wide range of model parameters. As an example, we\nconsider models that are in a strong external field. \n\n"}
{"id": "1601.00549", "contents": "Title: A Novel Family of Boosted Online Regression Algorithms with Strong\n  Theoretical Bounds Abstract: We investigate boosted online regression and propose a novel family of\nregression algorithms with strong theoretical bounds. In addition, we implement\nseveral variants of the proposed generic algorithm. We specifically provide\ntheoretical bounds for the performance of our proposed algorithms that hold in\na strong mathematical sense. We achieve guaranteed performance improvement over\nthe conventional online regression methods without any statistical assumptions\non the desired data or feature vectors. We demonstrate an intrinsic\nrelationship, in terms of boosting, between the adaptive mixture-of-experts and\ndata reuse algorithms. Furthermore, we introduce a boosting algorithm based on\nrandom updates that is significantly faster than the conventional boosting\nmethods and other variants of our proposed algorithms while achieving an\nenhanced performance gain. Hence, the random updates method is specifically\napplicable to the fast and high dimensional streaming data. Specifically, we\ninvestigate Newton Method-based and Stochastic Gradient Descent-based linear\nregression algorithms in a mixture-of-experts setting and provide several\nvariants of these well-known adaptation methods. However, the proposed\nalgorithms can be extended to other base learners, e.g., nonlinear, tree-based\npiecewise linear. Furthermore, we provide theoretical bounds for the\ncomputational complexity of our proposed algorithms. We demonstrate substantial\nperformance gains in terms of mean square error over the base learners through\nan extensive set of benchmark real data sets and simulated examples. \n\n"}
{"id": "1601.02082", "contents": "Title: Mixed-ADC Massive MIMO Uplink in Frequency-Selective Channels Abstract: The aim of this paper is to investigate the recently developed mixed-ADC\narchitecture for frequency-selective channels. Multi-carrier techniques such as\northogonal frequency division multiplexing (OFDM) are employed to handle\ninter-symbol interference (ISI). A frequency-domain equalizer is designed for\nmitigating the inter-carrier interference (ICI) introduced by the nonlinearity\nof one-bit quantization. For static single-input-multiple-output (SIMO)\nchannels, a closed-form expression of the generalized mutual information (GMI)\nis derived, and based on which the linear frequency-domain equalizer is\noptimized. The analysis is then extended to ergodic time-varying SIMO channels\nwith estimated channel state information (CSI), where numerically tight lower\nand upper bounds of the GMI are derived. The analytical framework is naturally\napplicable to the multi-user scenario, for both static and time-varying\nchannels. Extensive numerical studies reveal that the mixed-ADC architecture\nwith a small proportion of high-resolution ADCs does achieve a dominant portion\nof the achievable rate of ideal conventional architecture, and that it\nremarkably improves the performance as compared with one-bit massive MIMO. \n\n"}
{"id": "1601.02480", "contents": "Title: Quantum probability and quantum decision making Abstract: A rigorous general definition of quantum probability is given, which is valid\nfor elementary events and for composite events, for operationally testable\nmeasurements as well as for inconclusive measurements, and also for\nnon-commuting observables in addition to commutative observables. Our proposed\ndefinition of quantum probability makes it possible to describe quantum\nmeasurements and quantum decision making on the same common mathematical\nfooting. Conditions are formulated for the case when quantum decision theory\nreduces to its classical counterpart and for the situation where the use of\nquantum decision theory is necessary. \n\n"}
{"id": "1601.03763", "contents": "Title: Compressed Sensing-based Pilot Assignment and Reuse for Mobile UEs in\n  mmWave Cellular Systems Abstract: Technologies for mmWave communication are at the forefront of investigations\nin both industry and academia, as the mmWave band offers the promise of orders\nof magnitude additional available bandwidths to what has already been allocated\nto cellular networks. The much larger number of antennas that can be supported\nin a small footprint at mmWave bands can be leveraged to harvest massive-MIMO\ntype beamforming and spatial multiplexing gains. Similar to LTE systems, two\nprerequisites for harvesting these benefits are detecting users and acquiring\nuser channel state information (CSI) in the training phase. However, due to the\nfact that mmWave channels encounter much harsher propagation and decorrelate\nmuch faster, the tasks of user detection and CSI acquisition are both\nimperative and much more challenging than in LTE bands.\n  In this paper, we investigate the problem of fast user detection and CSI\nacquisition in the downlink of small cell mmWave networks. We assume TDD\noperation and channel-reciprocity based CSI acquisition. To achieve\ndensification benefits we propose pilot designs and channel estimators that\nleverage a combination of aggressive pilot reuse with fast user detection at\nthe base station and compressed sensing channel estimation. As our simulations\nshow, the number of users that can be simultaneously served by the entire\nmmWave-band network with the proposed schemes increases substantially with\nrespect to traditional compressed sensing based approaches with conventional\npilot reuse. \n\n"}
{"id": "1601.04373", "contents": "Title: Rate Maximization of Decode-and-Forward Relaying Systems with RF Energy\n  Harvesting Abstract: We consider a three-node decode-and-forward (DF) half-duplex relaying system,\nwhere the source first harvests RF energy from the relay, and then uses this\nenergy to transmit information to the destination via the relay. We assume that\nthe information transfer and wireless power transfer phases alternate over time\nin the same frequency band, and their {\\it time fraction} (TF) may change or be\nfixed from one transmission epoch (fading state) to the next. For this system,\nwe maximize the achievable average data rate. Thereby, we propose two schemes:\n(1) jointly optimal power and TF allocation, and (2) optimal power allocation\nwith fixed TF. Due to the small amounts of harvested power at the source, the\ntwo schemes achieve similar information rates, but yield significant\nperformance gains compared to a benchmark system with fixed power and fixed TF\nallocation. \n\n"}
{"id": "1601.05596", "contents": "Title: An Approximation of Theta Functions with Applications to Communications Abstract: Computing the theta series of an arbitrary lattice, and more specifically a\nrelated quantity known as the flatness factor, has been recently shown to be\nimportant for lattice code design in various wireless communication setups.\nHowever, the theta series is in general not known in closed form, excluding a\nsmall set of very special lattices. In this article, motivated by the practical\napplications as well as the mathematical problem itself, a simple approximation\nof the theta series of a lattice is derived. A rigorous analysis of its\naccuracy is provided.\n  In relation to this, maximum-likelihood decoding in the context of\ncompute-and-forward relaying is studied. Following previous work, it is shown\nthat the related metric can exhibit a flat behavior, which can be characterized\nby the flatness factor of the decoding function. Contrary to common belief, we\nnote that the decoding metric can be rewritten as a sum over a random lattice\nonly when at most two sources are considered. Using a particular matrix\ndecomposition, a link between the random lattice and the code lattice employed\nat the transmitter is established, which leads to an explicit criterion for\ncode design, in contrast to implicit criteria derived previously. Finally,\ncandidate lattices are examined with respect to the proposed criterion using\nthe derived theta series approximation. \n\n"}
{"id": "1601.05661", "contents": "Title: Distortion Bounds for Source Broadcast Problems Abstract: This paper investigates the joint source-channel coding problem of sending a\nmemoryless source over a memoryless broadcast channel. An inner bound and\nseveral outer bounds on the admissible distortion region are derived, which\nrespectively generalize and unify several existing bounds. As a consequence, we\nalso obtain an inner bound and an outer bound for the degraded broadcast\nchannel case. When specialized to the Gaussian or binary source broadcast, the\ninner bound and outer bound not only recover the best known inner bound and\nouter bound in the literature, but also generate some new results. Besides, we\nalso extend the inner bound and outer bounds to the Wyner-Ziv source broadcast\nproblem, i.e., source broadcast with side information available at decoders.\nSome new bounds are obtained when specialized to the Wyner-Ziv Gaussian and\nWyner-Ziv binary cases. \n\n"}
{"id": "1601.05776", "contents": "Title: Wireless Network Simplification : Beyond Diamond Networks Abstract: We consider an arbitrary layered Gaussian relay network with $L$ layers of\n$N$ relays each, from which we select subnetworks with $K$ relays per layer. We\nprove that: (i) For arbitrary $L, N$ and $K = 1$, there always exists a\nsubnetwork that approximately achieves $\\frac{2}{(L-1)N + 4}$\n$\\left(\\mbox{resp.}\\frac{2}{LN+2}\\right)$ of the network capacity for odd $L$\n(resp. even $L$), (ii) For $L = 2, N = 3, K = 2$, there always exists a\nsubnetwork that approximately achieves $\\frac{1}{2}$ of the network capacity.\nWe also provide example networks where even the best subnetworks achieve\nexactly these fractions (up to additive gaps). Along the way, we derive some\nresults on MIMO antenna selection and capacity decomposition that may also be\nof independent interest. \n\n"}
{"id": "1601.06065", "contents": "Title: Adaptive CSMA under the SINR Model: Efficient Approximation Algorithms\n  for Throughput and Utility Maximization Abstract: We consider a Carrier Sense Multiple Access (CSMA) based scheduling algorithm\nfor a single-hop wireless network under a realistic\nSignal-to-interference-plus-noise ratio (SINR) model for the interference. We\npropose two local optimization based approximation algorithms to efficiently\nestimate certain attempt rate parameters of CSMA called fugacities. It is known\nthat adaptive CSMA can achieve throughput optimality by sampling feasible\nschedules from a Gibbs distribution, with appropriate fugacities.\nUnfortunately, obtaining these optimal fugacities is an NP-hard problem.\nFurther, the existing adaptive CSMA algorithms use a stochastic gradient\ndescent based method, which usually entails an impractically slow (exponential\nin the size of the network) convergence to the optimal fugacities. To address\nthis issue, we first propose an algorithm to estimate the fugacities, that can\nsupport a given set of desired service rates. The convergence rate and the\ncomplexity of this algorithm are independent of the network size, and depend\nonly on the neighborhood size of a link. Further, we show that the proposed\nalgorithm corresponds exactly to performing the well-known Bethe approximation\nto the underlying Gibbs distribution. Then, we propose another local algorithm\nto estimate the optimal fugacities under a utility maximization framework, and\ncharacterize its accuracy. Numerical results indicate that the proposed methods\nhave a good degree of accuracy, and achieve extremely fast convergence to\nnear-optimal fugacities, and often outperform the convergence rate of the\nstochastic gradient descent by a few orders of magnitude. \n\n"}
{"id": "1601.06280", "contents": "Title: Sub-Quadratic Decoding of Gabidulin Codes Abstract: This paper shows how to decode errors and erasures with Gabidulin codes in\nsub-quadratic time in the code length, improving previous algorithms which had\nat least quadratic complexity. The complexity reduction is achieved by\naccelerating operations on linearized polynomials. In particular, we present\nfast algorithms for division, multi-point evaluation and interpolation of\nlinearized polynomials and show how to efficiently compute minimal subspace\npolynomials. \n\n"}
{"id": "1601.06375", "contents": "Title: Linear code derived from the primage of quadratic function Abstract: Linear codes have been an interesting topic in both theory and practice for\nmany years. In this paper, for an odd prime power $q$, we construct some class\nof linear code over finite field $\\mathbb{F}_q$ with defining set be the\npreimage of general quadratic form function and determine the explicit complete\nweight enumerators of the linear codes. Our construction cover all the\ncorresponding result with quadratic form function and they may have\napplications in cryptography and secret sharing schemes. \n\n"}
{"id": "1601.06611", "contents": "Title: \"Pretty strong\" converse for the private capacity of degraded quantum\n  wiretap channels Abstract: In the vein of the recent \"pretty strong\" converse for the quantum and\nprivate capacity of degradable quantum channels [Morgan/Winter, IEEE Trans.\nInf. Theory 60(1):317-333, 2014], we use the same techniques, in particular the\ncalculus of min-entropies, to show a pretty strong converse for the private\ncapacity of degraded classical-quantum-quantum (cqq-)wiretap channels, which\ngeneralize Wyner's model of the degraded classical wiretap channel.\n  While the result is not completely tight, leaving some gap between the region\nof error and privacy parameters for which the converse bound holds, and a\nlarger no-go region, it represents a further step towards an understanding of\nstrong converses of wiretap channels [cf. Hayashi/Tyagi/Watanabe,\narXiv:1410.0443 for the classical case]. \n\n"}
{"id": "1601.06810", "contents": "Title: Variational formulas for the power of the binary hypothesis testing\n  problem with applications Abstract: Two variational formulas for the power of the binary hypothesis testing\nproblem are derived. The first is given as the Legendre transform of a certain\nfunction and the second, induced from the first, is given in terms of the\nCumulative Distribution Function (CDF) of the log-likelihood ratio. One\napplication of the first formula is an upper bound on the power of the binary\nhypothesis testing problem in terms of the Re'nyi divergence. The second\nformula provide a general framework for proving asymptotic and non-asymptotic\nexpressions for the power of the test utilizing corresponding expressions for\nthe CDF of the log-likelihood. The framework is demonstrated in the central\nlimit regime (i.e., for non-vanishing type I error) and in the large deviations\nregime. \n\n"}
{"id": "1601.06993", "contents": "Title: Rank equivalent and rank degenerate skew cyclic codes Abstract: Two skew cyclic codes can be equivalent for the Hamming metric only if they\nhave the same length, and only the zero code is degenerate. The situation is\ncompletely different for the rank metric, where lengths of codes correspond to\nthe number of outgoing links from the source when applying the code on a\nnetwork. We study rank equivalences between skew cyclic codes of different\nlengths and, with the aim of finding the skew cyclic code of smallest length\nthat is rank equivalent to a given one, we define different types of length for\na given skew cyclic code, relate them and compute them in most cases. We give\ndifferent characterizations of rank degenerate skew cyclic codes using\nconventional polynomials and linearized polynomials. Some known results on the\nrank weight hierarchy of cyclic codes for some lengths are obtained as\nparticular cases and extended to all lengths and to all skew cyclic codes.\nFinally, we prove that the smallest length of a linear code that is rank\nequivalent to a given skew cyclic code can be attained by a pseudo-skew cyclic\ncode. Throughout the paper, we find new relations between linear skew cyclic\ncodes and their Galois closures. \n\n"}
{"id": "1601.07322", "contents": "Title: On Optimal Geographical Caching in Heterogeneous Cellular Networks Abstract: In this work we investigate optimal geographical caching in heterogeneous\ncellular networks where different types of base stations (BSs) have different\ncache capacities. Users request files from a content library according to a\nknown probability distribution. The performance metric is the total hit\nprobability, which is the probability that a user at an arbitrary location in\nthe plane will find the content that it requires in one of the BSs that it is\ncovered by.\n  We consider the problem of optimally placing content in all BSs jointly. As\nthis problem is not convex, we provide a heuristic scheme by finding the\noptimal placement policy for one type of base station conditioned on the\nplacement in all other types. We demonstrate that these individual optimization\nproblems are convex and we provide an analytical solution. As an illustration,\nwe find the optimal placement policy of the small base stations (SBSs)\ndepending on the placement policy of the macro base stations (MBSs). We show\nhow the hit probability evolves as the deployment density of the SBSs varies.\nWe show that the heuristic of placing the most popular content in the MBSs is\nalmost optimal after deploying the SBSs with optimal placement policies. Also,\nfor the SBSs no such heuristic can be used; the optimal placement is\nsignificantly better than storing the most popular content. Finally, we show\nthat solving the individual problems to find the optimal placement policies for\ndifferent types of BSs iteratively, namely repeatedly updating the placement\npolicies, does not improve the performance. \n\n"}
{"id": "1601.07498", "contents": "Title: Equivalence of additive-combinatorial linear inequalities for Shannon\n  entropy and differential entropy Abstract: This paper addresses the correspondence between linear inequalities of\nShannon entropy and differential entropy for sums of independent group-valued\nrandom variables. We show that any balanced (with the sum of coefficients being\nzero) linear inequality of Shannon entropy holds if and only if its\ndifferential entropy counterpart also holds; moreover, any linear inequality\nfor differential entropy must be balanced. In particular, our result shows that\nrecently proved differential entropy inequalities by Kontoyiannis and Madiman\n\\cite{KM14} can be deduced from their discrete counterparts due to Tao\n\\cite{Tao10} in a unified manner. Generalizations to certain abelian groups are\nalso obtained.\n  Our proof of extending inequalities of Shannon entropy to differential\nentropy relies on a result of R\\'enyi \\cite{Renyi59} which relates the Shannon\nentropy of a finely discretized random variable to its differential entropy and\nalso helps in establishing the entropy of the sum of quantized random variables\nis asymptotically equal to that of the quantized sum; the converse uses the\nasymptotics of the differential entropy of convolutions with weak additive\nnoise. \n\n"}
{"id": "1602.00173", "contents": "Title: Wireless Caching: Technical Misconceptions and Business Barriers Abstract: Caching is a hot research topic and poised to develop into a key technology\nfor the upcoming 5G wireless networks. The successful implementation of caching\ntechniques however, crucially depends on joint research developments in\ndifferent scientific domains such as networking, information theory, machine\nlearning, and wireless communications. Moreover, there exist business barriers\nrelated to the complex interactions between the involved stakeholders, the\nusers, the cellular operators, and the Internet content providers. In this\narticle we discuss several technical misconceptions with the aim to uncover\nenabling research directions for caching in wireless systems. Ultimately we\nmake a speculative stakeholder analysis for wireless caching in 5G. \n\n"}
{"id": "1602.00721", "contents": "Title: Concentration of measure without independence: a unified approach via\n  the martingale method Abstract: The concentration of measure phenomenon may be summarized as follows: a\nfunction of many weakly dependent random variables that is not too sensitive to\nany of its individual arguments will tend to take values very close to its\nexpectation. This phenomenon is most completely understood when the arguments\nare mutually independent random variables, and there exist several powerful\ncomplementary methods for proving concentration inequalities, such as the\nmartingale method, the entropy method, and the method of transportation\ninequalities. The setting of dependent arguments is much less well understood.\nThis chapter focuses on the martingale method for deriving concentration\ninequalities without independence assumptions. In particular, we use the\nmachinery of so-called Wasserstein matrices to show that the Azuma-Hoeffding\nconcentration inequality for martingales with almost surely bounded\ndifferences, when applied in a sufficiently abstract setting, is powerful\nenough to recover and sharpen several known concentration results for\nnonproduct measures. Wasserstein matrices provide a natural formalism for\ncapturing the interplay between the metric and the probabilistic structures,\nwhich is fundamental to the concentration phenomenon. \n\n"}
{"id": "1602.01532", "contents": "Title: Optimal Transport Theory for Power-Efficient Deployment of Unmanned\n  Aerial Vehicles Abstract: In this paper, the optimal deployment of multiple unmanned aerial vehicles\n(UAVs) acting as flying base stations is investigated. Considering the downlink\nscenario, the goal is to minimize the total required transmit power of UAVs\nwhile satisfying the users' rate requirements. To this end, the optimal\nlocations of UAVs as well as the cell boundaries of their coverage areas are\ndetermined. To find those optimal parameters, the problem is divided into two\nsub-problems that are solved iteratively. In the first sub-problem, given the\ncell boundaries corresponding to each UAV, the optimal locations of the UAVs\nare derived using the facility location framework. In the second sub-problem,\nthe locations of UAVs are assumed to be fixed, and the optimal cell boundaries\nare obtained using tools from optimal transport theory. The analytical results\nshow that the total required transmit power is significantly reduced by\ndetermining the optimal coverage areas for UAVs. These results also show that,\nmoving the UAVs based on users' distribution, and adjusting their altitudes can\nlead to a minimum power consumption. Finally, it is shown that the proposed\ndeployment approach, can improve the system's power efficiency by a factor of\n20 compared to the classical Voronoi cell association technique with fixed UAVs\nlocations. \n\n"}
{"id": "1602.02201", "contents": "Title: The Rate-Distortion Risk in Estimation from Compressed Data Abstract: Consider the problem of estimating a latent signal from a lossy compressed\nversion of the data when the compressor is agnostic to the relation between the\nsignal and the data. This situation arises in a host of modern applications\nwhen data is transmitted or stored prior to determining the downstream\ninference task. Given a bitrate constraint and a distortion measure between the\ndata and its compressed version, let us consider the joint distribution\nachieving Shannon's rate-distortion (RD) function. Given an estimator and a\nloss function associated with the downstream inference task, define the\nrate-distortion risk as the expected loss under the RD-achieving distribution.\nWe provide general conditions under which the operational risk in estimating\nfrom the compressed data is asymptotically equivalent to the RD risk. The main\ntheoretical tools to prove this equivalence are transportation-cost\ninequalities in conjunction with properties of compression codes achieving\nShannon's RD function. Whenever such equivalence holds, a recipe for designing\nestimators from datasets undergoing lossy compression without specifying the\nactual compression technique emerges: design the estimator to minimize the RD\nrisk. Our conditions simplified in the special cases of discrete memoryless or\nmultivariate normal data. For these scenarios, we derive explicit expressions\nfor the RD risk of several estimators and compare them to the optimal source\ncoding performance associated with full knowledge of the relation between the\nlatent signal and the data. \n\n"}
{"id": "1602.02366", "contents": "Title: On the Degrees-of-Freedom of the Large-Scale Interfering Two-Way Relay\n  Network Abstract: Achievable degrees-of-freedom (DoF) of the large-scale interfering two-way\nrelay network is investigated. The network consists of $K$ pairs of\ncommunication nodes (CNs) and $N$ relay nodes (RNs). It is assumed that $K\\ll\nN$ and each pair of CNs communicates with each other through one of the $N$\nrelay nodes without a direct link between them. Interference among RNs is also\nconsidered. Assuming local channel state information (CSI) at each RN, a\ndistributed and opportunistic RN selection technique is proposed for the\nfollowing three promising relaying protocols: amplify--forward,\ndecode--forward, and compute--forward. As a main result, the asymptotically\nachievable DoF is characterized as $N$ increases for the three relaying\nprotocols. In particular, a sufficient condition on $N$ required to achieve the\ncertain DoF of the network is analyzed. Through extensive simulations, it is\nshown that the proposed RN selection techniques outperform conventional schemes\nin terms of achievable rate even in practical communication scenarios. Note\nthat the proposed technique operates with a distributed manner and requires\nonly local CSI, leading to easy implementation for practical wireless systems. \n\n"}
{"id": "1602.02612", "contents": "Title: Sign-Compute-Resolve for Tree Splitting Random Access Abstract: We present a framework for random access that is based on three elements:\nphysical-layer network coding (PLNC), signature codes and tree splitting. In\npresence of a collision, physical-layer network coding enables the receiver to\ndecode, i.e. compute, the sum of the packets that were transmitted by the\nindividual users. For each user, the packet consists of the user's signature,\nas well as the data that the user wants to communicate. As long as no more than\nK users collide, their identities can be recovered from the sum of their\nsignatures. This framework for creating and transmitting packets can be used as\na fundamental building block in random access algorithms, since it helps to\ndeal efficiently with the uncertainty of the set of contending terminals. In\nthis paper we show how to apply the framework in conjunction with a\ntree-splitting algorithm, which is required to deal with the case that more\nthan K users collide. We demonstrate that our approach achieves throughput that\ntends to 1 rapidly as K increases. We also present results on net data-rate of\nthe system, showing the impact of the overheads of the constituent elements of\nthe proposed protocol. We compare the performance of our scheme with an upper\nbound that is obtained under the assumption that the active users are a priori\nknown. Also, we consider an upper bound on the net data-rate for any PLNC based\nstrategy in which one linear equation per slot is decoded. We show that already\nat modest packet lengths, the net data-rate of our scheme becomes close to the\nsecond upper bound, i.e. the overhead of the contention resolution algorithm\nand the signature codes vanishes. \n\n"}
{"id": "1602.03115", "contents": "Title: Towards Robustness in Residue Number Systems Abstract: The problem of robustly reconstructing a large number from its erroneous\nremainders with respect to several moduli, namely the robust remaindering\nproblem, may occur in many applications including phase unwrapping, frequency\ndetection from several undersampled waveforms, wireless sensor networks, etc.\nAssuming that the dynamic range of the large number is the maximal possible\none, i.e., the least common multiple (lcm) of all the moduli, a method called\nrobust Chinese remainder theorem (CRT) for solving the robust remaindering\nproblem has been recently proposed. In this paper, by relaxing the assumption\nthat the dynamic range is fixed to be the lcm of all the moduli, a trade-off\nbetween the dynamic range and the robustness bound for two-modular systems is\nstudied. It basically says that a decrease in the dynamic range may lead to an\nincrease of the robustness bound. We first obtain a general condition on the\nremainder errors and derive the exact dynamic range with a closed-form formula\nfor the robustness to hold. We then propose simple closed-form reconstruction\nalgorithms. Furthermore, the newly obtained two-modular results are applied to\nthe robust reconstruction for multi-modular systems and generalized to real\nnumbers. Finally, some simulations are carried out to verify our proposed\ntheoretical results. \n\n"}
{"id": "1602.03536", "contents": "Title: Duality between erasures and defects Abstract: We investigate the duality of the binary erasure channel (BEC) and the binary\ndefect channel (BDC). This duality holds for channel capacities, capacity\nachieving schemes, minimum distances, and upper bounds on the probability of\nfailure to retrieve the original message. In addition, the relations between\nBEC, BDC, binary erasure quantization (BEQ), and write-once memory (WOM) are\ndescribed. From these relations we claim that the capacity of the BDC can be\nachieved by Reed-Muller (RM) codes under maximum a posterior (MAP) decoding.\nAlso, polar codes with a successive cancellation encoder achieve the capacity\nof the BDC.\n  Inspired by the duality between the BEC and the BDC, we introduce locally\nrewritable codes (LWC) for resistive memories, which are the counterparts of\nlocally repairable codes (LRC) for distributed storage systems. The proposed\nLWC can improve endurance limit and power efficiency of resistive memories. \n\n"}
{"id": "1602.03768", "contents": "Title: MISO Networks with Imperfect CSIT: A Topological Rate-Splitting Approach Abstract: Recently, the Degrees-of-Freedom (DoF) region of multiple-input-single-output\n(MISO) networks with imperfect channel state information at the transmitter\n(CSIT) has attracted significant attentions. An achievable scheme is known as\nrate-splitting (RS) that integrates common-message-multicasting and\nprivate-message-unicasting. In this paper, focusing on the general $K$-cell\nMISO IC where the CSIT of each interference link has an arbitrary quality of\nimperfectness, we firstly identify the DoF region achieved by RS. Secondly, we\nintroduce a novel scheme, so called Topological RS (TRS), whose novelties\ncompared to RS lie in a multi-layer structure and transmitting multiple common\nmessages to be decoded by groups of users rather than all users. The design of\nTRS is motivated by a novel interpretation of the $K$-cell IC with imperfect\nCSIT as a weighted-sum of a series of partially connected networks. We show\nthat the DoF region achieved by TRS covers that achieved by RS. Also, we find\nthe maximal sum DoF achieved by TRS via hypergraph fractional packing, which\nyields the best sum DoF so far. Lastly, for a realistic scenario where each\nuser is connected to three dominant transmitters, we identify the sufficient\ncondition where TRS strictly outperforms conventional schemes. \n\n"}
{"id": "1602.06215", "contents": "Title: Big Data Meets Telcos: A Proactive Caching Perspective Abstract: Mobile cellular networks are becoming increasingly complex to manage while\nclassical deployment/optimization techniques and current solutions (i.e., cell\ndensification, acquiring more spectrum, etc.) are cost-ineffective and thus\nseen as stopgaps. This calls for development of novel approaches that leverage\nrecent advances in storage/memory, context-awareness, edge/cloud computing, and\nfalls into framework of big data. However, the big data by itself is yet\nanother complex phenomena to handle and comes with its notorious 4V: velocity,\nvoracity, volume and variety. In this work, we address these issues in\noptimization of 5G wireless networks via the notion of proactive caching at the\nbase stations. In particular, we investigate the gains of proactive caching in\nterms of backhaul offloadings and request satisfactions, while tackling the\nlarge-amount of available data for content popularity estimation. In order to\nestimate the content popularity, we first collect users' mobile traffic data\nfrom a Turkish telecom operator from several base stations in hours of time\ninterval. Then, an analysis is carried out locally on a big data platform and\nthe gains of proactive caching at the base stations are investigated via\nnumerical simulations. It turns out that several gains are possible depending\non the level of available information and storage size. For instance, with 10%\nof content ratings and 15.4 Gbyte of storage size (87% of total catalog size),\nproactive caching achieves 100% of request satisfaction and offloads 98% of the\nbackhaul when considering 16 base stations. \n\n"}
{"id": "1602.06509", "contents": "Title: Orthogonal AMP Abstract: Approximate message passing (AMP) is a low-cost iterative signal recovery\nalgorithm for linear system models. When the system transform matrix has\nindependent identically distributed (IID) Gaussian entries, the performance of\nAMP can be asymptotically characterized by a simple scalar recursion called\nstate evolution (SE). However, SE may become unreliable for other matrix\nensembles, especially for ill-conditioned ones. This imposes limits on the\napplications of AMP.\n  In this paper, we propose an orthogonal AMP (OAMP) algorithm based on\nde-correlated linear estimation (LE) and divergence-free non-linear estimation\n(NLE). The Onsager term in standard AMP vanishes as a result of the\ndivergence-free constraint on NLE. We develop an SE procedure for OAMP and show\nnumerically that the SE for OAMP is accurate for general unitarily-invariant\nmatrices, including IID Gaussian matrices and partial orthogonal matrices. We\nfurther derive optimized options for OAMP and show that the corresponding SE\nfixed point coincides with the optimal performance obtained via the replica\nmethod. Our numerical results demonstrate that OAMP can be advantageous over\nAMP, especially for ill-conditioned matrices \n\n"}
{"id": "1602.07112", "contents": "Title: Multipath streaming: fundamental limits and efficient algorithms Abstract: We investigate streaming over multiple links. A file is split into small\nunits called chunks that may be requested on the various links according to\nsome policy, and received after some random delay. After a start-up time called\npre-buffering time, received chunks are played at a fixed speed. There is\nstarvation if the chunk to be played has not yet arrived. We provide lower\nbounds (fundamental limits) on the starvation probability of any policy. We\nfurther propose simple, order-optimal policies that require no feedback. For\ngeneral delay distributions, we provide tractable upper bounds for the\nstarvation probability of the proposed policies, allowing to select the\npre-buffering time appropriately. We specialize our results to: (i) links that\nemploy CSMA or opportunistic scheduling at the packet level, (ii) links shared\nwith a primary user (iii) links that use fair rate sharing at the flow level.\nWe consider a generic model so that our results give insight into the design\nand performance of media streaming over (a) wired networks with several paths\nbetween the source and destination, (b) wireless networks featuring spectrum\naggregation and (c) multi-homed wireless networks. \n\n"}
{"id": "1602.07731", "contents": "Title: Initial Access in 5G mm-Wave Cellular Networks Abstract: The massive amounts of bandwidth available at millimeter-wave frequencies\n(roughly above 10 GHz) have the potential to greatly increase the capacity of\nfifth generation cellular wireless systems. However, to overcome the high\nisotropic pathloss experienced at these frequencies, high directionality will\nbe required at both the base station and the mobile user equipment to establish\nsufficient link budget in wide area networks. This reliance on directionality\nhas important implications for control layer procedures. Initial access in\nparticular can be significantly delayed due to the need for the base station\nand the user to find the proper alignment for directional transmission and\nreception. This paper provides a survey of several recently proposed techniques\nfor this purpose. A coverage and delay analysis is performed to compare various\ntechniques including exhaustive and iterative search, and Context Information\nbased algorithms. We show that the best strategy depends on the target SNR\nregime, and provide guidelines to characterize the optimal choice as a function\nof the system parameters. \n\n"}
{"id": "1603.00644", "contents": "Title: A Novel Interleaving Scheme for Polar Codes Abstract: It's known that the bit errors of polar codes with successive cancellation\n(SC) decoding are coupled. We call the coupled information bits the correlated\nbits. In this paper, concatenation schemes are studied for polar codes (as\ninner codes) and LDPC codes (as outer codes). In a conventional concatenation\nscheme, to achieve a better BER performance, one can divide all $N_l$ bits in a\nLDPC block into $N_l$ polar blocks to completely de-correlate the possible\ncoupled errors. In this paper, we propose a novel interleaving scheme between a\nLDPC code and a polar code which breaks the correlation of the errors among the\ncorrelated bits. This interleaving scheme still keeps the simple SC decoding of\npolar codes while achieves a comparable BER performance at a much smaller delay\ncompared with a $N_l$-block delay scheme. \n\n"}
{"id": "1603.01115", "contents": "Title: Optimization of Energy-Constrained Wireless Powered Communication\n  Networks with Heterogeneous Nodes Abstract: In this paper, we study wireless networks where nodes have two energy\nsources, namely a battery and radio frequency (RF) energy harvesting circuitry.\nWe formulate two optimization problems with different objective functions,\nnamely maximizing the sum throughput and maximizing the minimum throughput, for\nenhanced fairness. Furthermore, we show the generality of the proposed system\nmodel through characterizing the conditions under which the two formulated\noptimization problems can be reduced to the corresponding problems of different\nknown wireless networks, namely, conventional wireless networks\n(battery-powered) and wireless powered communications networks (WPCNs) with\nonly RF energy harvesting nodes. In addition, we introduce WPCNs with two types\nof nodes, with and without RF energy harvesting capability, in which the nodes\nwithout RF energy harvesting are utilized to enhance the sum throughput, even\nbeyond WPCNs with all energy harvesting nodes. We establish the convexity of\nall formulated problems which opens room for efficient solution using standard\ntechniques. Our numerical results show that the two types of wireless networks,\nnamely WPCNs with only RF energy harvesting nodes and conventional wireless\nnetworks, are considered, respectively, as lower and upper bounds on the\nperformance of the generalized problem setting in terms of the maximum sum\nthroughput and the maxmin throughput. Moreover, the results reveal new insights\nand throughput-fairness trade-offs unique to our new problem setting. \n\n"}
{"id": "1603.01869", "contents": "Title: Physical Layer Security for Massive MIMO Systems Impaired by Phase Noise Abstract: In this paper, we investigate the impact of phase noise on the secrecy\nperformance of downlink massive MIMO systems in the presence of a passive\nmultiple-antenna eavesdropper. Thereby, for the base station (BS) and the\nlegitimate users, the effect of multiplicative phase noise is taken into\naccount, whereas the eavesdropper is assumed to employ ideal hardware. We\nderive a lower bound for the ergodic secrecy rate of a given user when matched\nfilter data precoding and artificial noise transmission are employed at the BS.\nBased on the derived analytical expression, we investigate the impact of the\nvarious system parameters on the secrecy rate. Our analytical and simulation\nresults reveal that distributively deployed local oscillators (LOs) can achieve\na better performance than one common LO for all BS antennas as long as a\nsufficient amount of power is assigned for data transmission. \n\n"}
{"id": "1603.01921", "contents": "Title: Optimal Geographic Caching in Finite Wireless Networks Abstract: Cache-enabled device-to-device (D2D) networks turn memory of the devices at\nthe network edge, such as smart phones and tablets, into bandwidth by enabling\nasynchronous content sharing directly between proximate devices. Limited\nstorage capacity of the mobile devices necessitates the determination of\noptimal set of contents to be cached on each device. In order to study the\nproblem of optimal cache placement, we model the locations of devices in a\nfinite region (e.g., coffee shop, sports bar, library) as a uniform binomial\npoint process (BPP). For this setup, we first develop a generic framework to\nanalyze the coverage probability of the target receiver (target-Rx) when the\nrequested content is available at the $k^{th}$ closest device to it. Using this\ncoverage probability result, we evaluate optimal caching probability of the\npopular content to maximize the total hit probability. Our analysis concretely\ndemonstrates that optimal caching probability strongly depends on the number of\nsimultaneously active devices in the network. \n\n"}
{"id": "1603.06286", "contents": "Title: A Generalized LDPC Framework for Robust and Sublinear Compressive\n  Sensing Abstract: Compressive sensing aims to recover a high-dimensional sparse signal from a\nrelatively small number of measurements. In this paper, a novel design of the\nmeasurement matrix is proposed. The design is inspired by the construction of\ngeneralized low-density parity-check codes, where the capacity-achieving\npoint-to-point codes serve as subcodes to robustly estimate the signal support.\nIn the case that each entry of the $n$-dimensional $k$-sparse signal lies in a\nknown discrete alphabet, the proposed scheme requires only $O(k \\log n)$\nmeasurements and arithmetic operations. In the case of arbitrary, possibly\ncontinuous alphabet, an error propagation graph is proposed to characterize the\nresidual estimation error. With $O(k \\log^2 n)$ measurements and computational\ncomplexity, the reconstruction error can be made arbitrarily small with high\nprobability. \n\n"}
{"id": "1603.07322", "contents": "Title: On Delay-Optimal Scheduling in Queueing Systems with Replications Abstract: In modern computer systems, jobs are divided into short tasks and executed in\nparallel. Empirical observations in practical systems suggest that the task\nservice times are highly random and the job service time is bottlenecked by the\nslowest straggling task. One common solution for straggler mitigation is to\nreplicate a task on multiple servers and wait for one replica of the task to\nfinish early. The delay performance of replications depends heavily on the\nscheduling decisions of when to replicate, which servers to replicate on, and\nwhich job to serve first. So far, little is understood on how to optimize these\nscheduling decisions for minimizing the delay to complete the jobs. In this\npaper, we present a comprehensive study on delay-optimal scheduling of\nreplications in both centralized and distributed multi-server systems.\nLow-complexity scheduling policies are designed and are proven to be\ndelay-optimal or near delay-optimal in stochastic ordering among all causal and\nnon-preemptive policies. These theoretical results are established for general\nsystem settings and delay metrics that allow for arbitrary arrival processes,\narbitrary job sizes, arbitrary due times, and heterogeneous servers with data\nlocality constraints. Novel sample-path tools are developed to prove these\nresults. \n\n"}
{"id": "1603.07650", "contents": "Title: Decoding and File Transfer Delay Balancing in Network Coding Broadcast Abstract: Network Coding is a packet encoding technique which has recently been shown\nto improve network performance (by reducing delays and increasing throughput)\nin broadcast and multicast communications. The cost for such an improvement\ncomes in the form of increased decoding complexity (and thus delay) at the\nreceivers end. Before delivering the file to higher layers, the receiver should\nfirst decode those packets. In our work we consider the broadcast transmission\nof a large file to N wireless users. The file is segmented into a number of\nblocks (each containing K packets - the Coding Window Size). The packets of\neach block are encoded using Random Linear Network Coding (RLNC).We obtain the\nminimum coding window size so that the completion time of the file transmission\nis upper bounded by a used defined delay constraint. \n\n"}
{"id": "1603.07758", "contents": "Title: A universal tradeoff between power, precision and speed in physical\n  communication Abstract: Maximizing the speed and precision of communication while minimizing power\ndissipation is a fundamental engineering design goal. Also, biological systems\nachieve remarkable speed, precision and power efficiency using poorly\nunderstood physical design principles. Powerful theories like information\ntheory and thermodynamics do not provide general limits on power, precision and\nspeed. Here we go beyond these classical theories to prove that the product of\nprecision and speed is universally bounded by power dissipation in any physical\ncommunication channel whose dynamics is faster than that of the signal.\nMoreover, our derivation involves a novel connection between friction and\ninformation geometry. These results may yield insight into both the engineering\ndesign of communication devices and the structure and function of biological\nsignaling systems. \n\n"}
{"id": "1603.08113", "contents": "Title: Reconstructing undirected graphs from eigenspaces Abstract: In this paper, we aim at recovering an undirected weighted graph of $N$\nvertices from the knowledge of a perturbed version of the eigenspaces of its\nadjacency matrix $W$. For instance, this situation arises for stationary\nsignals on graphs or for Markov chains observed at random times. Our approach\nis based on minimizing a cost function given by the Frobenius norm of the\ncommutator $\\mathsf{A} \\mathsf{B}-\\mathsf{B} \\mathsf{A}$ between symmetric\nmatrices $\\mathsf{A}$ and $\\mathsf{B}$.\n  In the Erd\\H{o}s-R\\'enyi model with no self-loops, we show that\nidentifiability (i.e., the ability to reconstruct $W$ from the knowledge of its\neigenspaces) follows a sharp phase transition on the expected number of edges\nwith threshold function $N\\log N/2$.\n  Given an estimation of the eigenspaces based on a $n$-sample, we provide\nsupport selection procedures from theoretical and practical point of views. In\nparticular, when deleting an edge from the active support, our study unveils\nthat our test statistic is the order of $\\mathcal O(1/n)$ when we overestimate\nthe true support and lower bounded by a positive constant when the estimated\nsupport is smaller than the true support. This feature leads to a powerful\npractical support estimation procedure. Simulated and real life numerical\nexperiments assert our new methodology. \n\n"}
{"id": "1603.08236", "contents": "Title: Improving the Performance of Nested Lattice Codes Using Concatenation Abstract: A fundamental problem in coding theory is the design of an efficient coding\nscheme that achieves the capacity of the additive white Gaussian (AWGN)\nchannel. The main objective of this short note is to point out that by\nconcatenating a capacity-achieving nested lattice code with a suitable\nhigh-rate linear code over an appropriate finite field, we can achieve the\ncapacity of the AWGN channel with polynomial encoding and decoding complexity.\nSpecifically, we show that using inner Construction-A lattice codes and outer\nReed-Solomon codes, we can obtain capacity-achieving codes whose encoding and\ndecoding complexities grow as $O(N^2)$, while the probability of error decays\nexponentially in $N$, where $N$ denotes the blocklength. Replacing the outer\nReed-Solomon code by an expander code helps us further reduce the decoding\ncomplexity to $O(N\\log^2N)$. This also gives us a recipe for converting a\nhigh-complexity nested lattice code for a Gaussian channel to a low-complexity\nconcatenated code without any loss in the asymptotic rate. As examples, we\ndescribe polynomial-time coding schemes for the wiretap channel, and the\ncompute-and-forward scheme for computing integer linear combinations of\nmessages. \n\n"}
{"id": "1603.08387", "contents": "Title: Post-processing procedure for industrial quantum key distribution\n  systems Abstract: We present algorithmic solutions aimed on post-processing for industrial\nquantum key distribution systems with hardware sifting. The main steps of the\nprocedure are error correction, parameter estimation, and privacy\namplification. Authentication of a classical public communication channel is\nalso considered. \n\n"}
{"id": "1603.08578", "contents": "Title: Analysis of k-Nearest Neighbor Distances with Application to Entropy\n  Estimation Abstract: Estimating entropy and mutual information consistently is important for many\nmachine learning applications. The Kozachenko-Leonenko (KL) estimator\n(Kozachenko & Leonenko, 1987) is a widely used nonparametric estimator for the\nentropy of multivariate continuous random variables, as well as the basis of\nthe mutual information estimator of Kraskov et al. (2004), perhaps the most\nwidely used estimator of mutual information in this setting. Despite the\npractical importance of these estimators, major theoretical questions regarding\ntheir finite-sample behavior remain open. This paper proves finite-sample\nbounds on the bias and variance of the KL estimator, showing that it achieves\nthe minimax convergence rate for certain classes of smooth functions. In\nproving these bounds, we analyze finite-sample behavior of k-nearest neighbors\n(k-NN) distance statistics (on which the KL estimator is based). We derive\nconcentration inequalities for k-NN distances and a general expectation bound\nfor statistics of k-NN distances, which may be useful for other analyses of\nk-NN methods. \n\n"}
{"id": "1603.08817", "contents": "Title: Compressive Sensing Based Design of Sparse Tripole Arrays Abstract: This paper considers the problem of designing sparse linear tripole arrays.\nIn such arrays at each antenna location there are three orthogonal dipoles,\nallowing full measurement of both the horizontal and vertical components of the\nreceived waveform. We formulate this problem from the viewpoint of Compressive\nSensing (CS). However, unlike for isotropic array elements (single antenna), we\nnow have three complex valued weight coefficients associated with each\npotential location (due to the three dipoles), which have to be simultaneously\nminimised. If this is not done, we may only set the weight coefficients of\nindividual dipoles to be zero valued, rather than complete tripoles, meaning\nsome dipoles may remain at each location. Therefore, the contributions of this\npaper are to formulate the design of sparse tripole arrays as an optimisation\nproblem, and then we obtain a solution based on the minimisation of a modified\nl1 norm or a series of iteratively solved reweighted minimisations, which\nensure a truly sparse solution. Design examples are provided to verify the\neffectiveness of the proposed methods and show that a good approximation of a\nreference pattern can be achieved using fewer tripoles than a Uniform Linear\nArray (ULA) of equivalent length. \n\n"}
{"id": "1604.00565", "contents": "Title: A Statistical Block Fading Channel Model for Multiuser Massive MIMO\n  System Abstract: This paper presents a statistical block fading channel model for multiuser\nmassive MIMO system. The proposed channel model is evolved from correlation\nbased stochastic channel model (CBSCM) but in addition to the properties of\nCBSCM, it has capability of capturing channel variations along time or\nfrequency and along space simultaneously. It has a simplified analytical\nexpression, still being able to simulate underlying physical phenomena which\notherwise need a complex geometry based stochastic channel model (GBSCM). The\nchannel model is verified with reported measurement data of channel for massive\nMIMO. Spatial determinism in channel, the basic cause of unfavorable\npropagation, is modeled into controlling parameters of channel model. Channel\nmodel uses only three controlling parameters; one parameter describes variation\nin channel along resource block (along time or frequency) and remaining two\nparameters describe spatial variation in channel. Modeling of simultaneous\nvariation along time and space belongs to a very common scenario where mobility\nof mobile terminal and angular power distribution at base station receiver, are\nkey parameters. Additionally, simulation results reveal the hidden advantages\nof spatial determinism in channel for multiuser massive MIMO. \n\n"}
{"id": "1604.00635", "contents": "Title: Quantum-inspired secure wireless communication protocol under spatial\n  and local Gaussian noise assumptions Abstract: Inspired from quantum key distribution, we consider wireless communication\nbetween Alice and Bob when the intermediate space between Alice and Bob is\ncontrolled by Eve. That is, our model divides the channel noise into two parts,\nthe noise generated during the transmission and the noise generated in the\ndetector. Eve is allowed to control the former, but is not allowed to do the\nlatter. While the latter is assumed to be a Gaussian random variable, the\nformer is not assumed to be a Gaussian random variable. In this situation,\nusing backward reconciliation and the random sampling, we propose a protocol to\ngenerate secure keys between Alice and Bob under the assumption that Eve's\ndetector has a Gaussian noise and Eve is out of Alice's neighborhood. In our\nprotocol, the security criteria are quantitatively guaranteed even with finite\nblock-length code based on the evaluation of error of the estimation of\nchannel. \n\n"}
{"id": "1604.00700", "contents": "Title: From compressed sensing to compressed bit-streams: practical encoders,\n  tractable decoders Abstract: Compressed sensing is now established as an effective method for dimension\nreduction when the underlying signals are sparse or compressible with respect\nto some suitable basis or frame. One important, yet under-addressed problem\nregarding the compressive acquisition of analog signals is how to perform\nquantization. This is directly related to the important issues of how\n\"compressed\" compressed sensing is (in terms of the total number of bits one\nends up using after acquiring the signal) and ultimately whether compressed\nsensing can be used to obtain compressed representations of suitable signals.\nBuilding on our recent work, we propose a concrete and practicable method for\nperforming \"analog-to-information conversion\". Following a compressive signal\nacquisition stage, the proposed method consists of a quantization stage, based\non $\\Sigma\\Delta$ (sigma-delta) quantization, and a subsequent encoding\n(compression) stage that fits within the framework of compressed sensing\nseamlessly. We prove that, using this method, we can convert analog compressive\nsamples to compressed digital bitstreams and decode using tractable algorithms\nbased on convex optimization. We prove that the proposed AIC provides a nearly\noptimal encoding of sparse and compressible signals. Finally, we present\nnumerical experiments illustrating the effectiveness of the proposed\nanalog-to-information converter. \n\n"}
{"id": "1604.02333", "contents": "Title: Information Theoretic Caching: The Multi-User Case Abstract: In this paper, we consider a cache aided network in which each user is\nassumed to have individual caches, while upon users' requests, an update\nmessage is sent though a common link to all users. First, we formulate a\ngeneral information theoretic setting that represents the database as a\ndiscrete memoryless source, and the users' requests as side information that is\navailable everywhere except at the cache encoder. The decoders' objective is to\nrecover a function of the source and the side information. By viewing cache\naided networks in terms of a general distributed source coding problem and\nthrough information theoretic arguments, we present inner and outer bounds on\nthe fundamental tradeoff of cache memory size and update rate. Then, we\nspecialize our general inner and outer bounds to a specific model of content\ndelivery networks: File selection networks, in which the database is a\ncollection of independent equal-size files and each user requests one of the\nfiles independently. For file selection networks, we provide an outer bound and\ntwo inner bounds (for centralized and decentralized caching strategies). For\nthe case when the user request information is uniformly distributed, we\ncharacterize the rate vs. cache size tradeoff to within a multiplicative gap of\n4. By further extending our arguments to the framework of Maddah-Ali and\nNiesen, we also establish a new outer bound and two new inner bounds in which\nit is shown to recover the centralized and decentralized strategies, previously\nestablished by Maddah-Ali and Niesen. Finally, in terms of rate vs. cache size\ntradeoff, we improve the previous multiplicative gap of 72 to 4.7 for the\naverage case with uniform requests. \n\n"}
{"id": "1604.02517", "contents": "Title: Throughput Maximization for Mobile Relaying Systems Abstract: Relaying is an effective technique to achieve reliable wireless connectivity\nin harsh communication environment. However, most of the existing relaying\nschemes are based on relays with fixed locations, or \\emph{static relaying}. In\nthis paper, we consider a novel \\emph{mobile relaying} technique, where the\nrelay nodes are assumed to be capable of moving at high speed. Compared to\nstatic relaying, mobile relaying offers a new degree of freedom for performance\nenhancement via careful relay trajectory design. We study the throughput\nmaximization problem in mobile relaying systems by optimizing the source/relay\ntransmit power along with the relay trajectory, subject to practical mobility\nconstraints (on the relay speed and initial/final relay locations), as well as\nthe \\emph{information-causality constraint} at the relay owing to its\ndecode-store-and-forward (DSF) strategy. It is shown that for fixed relay\ntrajectory, the throughput-optimal source/relay power allocations over time\nfollow a \"staircase\" water filling (WF) structure, with \\emph{non-increasing}\nand \\emph{non-decreasing} water levels at the source and relay, respectively.\nOn the other hand, with given power allocations, the throughput can be further\nimproved by optimizing the relay trajectory via successive convex optimization.\nAn iterative algorithm is thus proposed to optimize the power allocations and\nrelay trajectory alternately. Furthermore, for the special case with free\ninitial and final relay locations, the jointly optimal power allocation and\nrelay trajectory are derived. Numerical results show that by optimizing the\ntrajectory of the relay and power allocations adaptive to its induced channel\nvariation, mobile relaying is able to achieve significant throughput gains over\nthe conventional static relaying. \n\n"}
{"id": "1604.03089", "contents": "Title: Different quantum f-divergences and the reversibility of quantum\n  operations Abstract: The concept of classical $f$-divergences gives a unified framework to\nconstruct and study measures of dissimilarity of probability distributions;\nspecial cases include the relative entropy and the R\\'enyi divergences. Various\nquantum versions of this concept, and more narrowly, the concept of R\\'enyi\ndivergences, have been introduced in the literature with applications in\nquantum information theory; most notably Petz' quasi-entropies (standard\n$f$-divergences), Matsumoto's maximal $f$-divergences, measured\n$f$-divergences, and sandwiched and $\\alpha$-$z$-R\\'enyi divergences.\n  In this paper we give a systematic overview of the various concepts of\nquantum $f$-divergences with a main focus on their monotonicity under quantum\noperations, and the implications of the preservation of a quantum\n$f$-divergence by a quantum operation. In particular, we compare the standard\nand the maximal $f$-divergences regarding their ability to detect the\nreversibility of quantum operations. We also show that these two quantum\n$f$-divergences are strictly different for non-commuting operators unless $f$\nis a polynomial, and obtain some analogous partial results for the relation\nbetween the measured and the standard $f$-divergences.\n  We also study the monotonicity of the $\\alpha$-$z$-R\\'enyi divergences under\nthe special class of bistochastic maps that leave one of the arguments of the\nR\\'enyi divergence invariant, and determine domains of the parameters\n$\\alpha,z$ where monotonicity holds, and where the preservation of the\n$\\alpha$-$z$-R\\'enyi divergence implies the reversibility of the quantum\noperation. \n\n"}
{"id": "1604.03183", "contents": "Title: A Primer on Cellular Network Analysis Using Stochastic Geometry Abstract: This tutorial is intended as an accessible but rigorous first reference for\nsomeone interested in learning how to model and analyze cellular network\nperformance using stochastic geometry. In particular, we focus on computing the\nsignal-to-interference-plus-noise ratio (SINR) distribution, which can be\ncharacterized by the coverage probability (the SINR CCDF) or the outage\nprobability (its CDF). We model base stations (BSs) in the network as a\nrealization of a homogeneous Poisson point process of density $\\lambda$, and\ncompute the SINR for three main cases: the downlink, uplink, and finally the\nmulti-tier downlink, which is characterized by having $k$ tiers of BSs each\nwith a unique density $\\lambda_i$ and transmit power $p_i$. These three\nbaseline results have been extensively extended to many different scenarios,\nand we conclude with a brief summary of some of those extensions. \n\n"}
{"id": "1604.03204", "contents": "Title: Distributed Index Coding Abstract: In this paper, we study the capacity region of the general distributed index\ncoding. In contrast to the traditional centralized index coding where a single\nserver contains all $n$ messages requested by the receivers, in the distributed\nindex coding there are $2^n-1$ servers, each containing a unique non-empty\nsubset $J$ of the messages and each is connected to all receivers via a\nnoiseless independent broadcast link with an arbitrary capacity $C_J \\ge 0$.\nFirst, we generalize the existing polymatroidal outer bound on the capacity\nregion of the centralized problem to the distributed case. Next, building upon\nthe existing centralized composite coding scheme, we propose three distributed\ncomposite coding schemes and derive the corresponding inner bounds on the\ncapacity region. We present a number of interesting numerical examples, which\nhighlight the subtleties and challenges of dealing with the distributed index\ncoding, even for very small problem sizes of $n=3$ and $n=4$. \n\n"}
{"id": "1604.04457", "contents": "Title: A 3D Spatial Fluid Model for Wireless Networks Abstract: In this article we develop a three dimensional (3D) analytical model of\nwireless networks. We establish an analytical expression of the SINR (Signal to\nInterference plus Noise Ratio) of user equipments (UE), by using a 3D fluid\nmodel approach of the network. This model enables to evaluate in a simple way\nthe cumulative distribution function of the SINR, and therefore the\nperformance, the quality of service and the coverage of wireless networks, with\na high accuracy. The use of this 3D wireless network model, instead of a\nstandard two-dimensional one, in order to analyze wireless networks, is\nparticularly interesting. Indeed, this 3D model enables to establish more\naccurate performance and quality of services results than a 2D one. \n\n"}
{"id": "1604.04826", "contents": "Title: On the Non-existence of certain classes of generalized bent functions Abstract: We obtain new non-existence results of generalized bent functions from\n\\ZZ^n_q to \\ZZ_q (called type [n,q]). The first case is a class of types where\nq=2p_1^{r_1}p_2^{r_2}. The second case contains two types [1 <= n <= 3, 2 *\n31^e]$ and [1 <= n <= 7,2 * 151^e]. \n\n"}
{"id": "1604.05483", "contents": "Title: SWIPT in 3-D Bipolar Ad Hoc Networks with Sectorized Antennas Abstract: In this letter, we study the simultaneous wireless information and power\ntransfer (SWIPT) concept in 3-D bipolar ad hoc networks with spatial\nrandomness. Due to three spatial dimensions of the network, we introduce a 3-D\nantenna sectorization that exploits the horizontal and the vertical spatial\nseparation. The impact of 3-D antenna sectorization on SWIPT performance is\nevaluated for the power-splitting technique by using stochastic geometry tools.\nTheoretical and numerical results show that 3-D sectorization achieves a more\naccurate beam steering in the 3-D space, which can be beneficial for both the\ninformation and the power transfer. \n\n"}
{"id": "1604.05622", "contents": "Title: Understanding Noise and Interference Regimes in 5G Millimeter-Wave\n  Cellular Networks Abstract: With the severe spectrum shortage in conventional cellular bands,\nmillimeter-wave (mmWave) frequencies have been attracting growing attention for\nnext-generation micro- and picocellular wireless networks. A fundamental and\nopen question is whether mmWave cellular networks are likely to be noise- or\ninterference-limited. Identifying in which regime a network is operating is\ncritical for the design of MAC and physical-layer procedures and to provide\ninsights on how transmissions across cells should be coordinated to cope with\ninterference. This work uses the latest measurement-based statistical channel\nmodels to accurately assess the Interference-to-Noise Ratio (INR) in a wide\nrange of deployment scenarios. In addition to cell density, we also study\nantenna array size and antenna patterns, whose effects are critical in the\nmmWave regime. The channel models also account for blockage, line-of-sight and\nnon-line-of-sight regimes as well as local scattering, that significantly\naffect the level of spatial isolation. \n\n"}
{"id": "1604.07234", "contents": "Title: Blind Identification of Graph Filters Abstract: Network processes are often represented as signals defined on the vertices of\na graph. To untangle the latent structure of such signals, one can view them as\noutputs of linear graph filters modeling underlying network dynamics. This\npaper deals with the problem of joint identification of a graph filter and its\ninput signal, thus broadening the scope of classical blind deconvolution of\ntemporal and spatial signals to the less-structured graph domain. Given a graph\nsignal $\\mathbf{y}$ modeled as the output of a graph filter, the goal is to\nrecover the vector of filter coefficients $\\mathbf{h}$, and the input signal\n$\\mathbf{x}$ which is assumed to be sparse. While $\\mathbf{y}$ is a bilinear\nfunction of $\\mathbf{x}$ and $\\mathbf{h}$, the filtered graph signal is also a\nlinear combination of the entries of the lifted rank-one, row-sparse matrix\n$\\mathbf{x} \\mathbf{h}^T$. The blind graph-filter identification problem can\nthus be tackled via rank and sparsity minimization subject to linear\nconstraints, an inverse problem amenable to convex relaxations offering\nprovable recovery guarantees under simplifying assumptions. Numerical tests\nusing both synthetic and real-world networks illustrate the merits of the\nproposed algorithms, as well as the benefits of leveraging multiple signals to\naid the blind identification task. \n\n"}
{"id": "1604.07918", "contents": "Title: Fundamental Green Tradeoffs: Progresses, Challenges, and Impacts on 5G\n  Networks Abstract: With years of tremendous traffic and energy consumption growth, green radio\nhas been valued not only for theoretical research interests but also for the\noperational expenditure reduction and the sustainable development of wireless\ncommunications. Fundamental green tradeoffs, served as an important framework\nfor analysis, include four basic relationships: spectrum efficiency (SE) versus\nenergy efficiency (EE), deployment efficiency (DE) versus energy efficiency\n(EE), delay (DL) versus power (PW), and bandwidth (BW) versus power (PW). In\nthis paper, we first provide a comprehensive overview on the extensive on-going\nresearch efforts and categorize them based on the fundamental green tradeoffs.\nWe will then focus on research progresses of 4G and 5G communications, such as\northogonal frequency division multiplexing (OFDM) and non-orthogonal\naggregation (NOA), multiple input multiple output (MIMO), and heterogeneous\nnetworks (HetNets). We will also discuss potential challenges and impacts of\nfundamental green tradeoffs, to shed some light on the energy efficient\nresearch and design for future wireless networks. \n\n"}
{"id": "1605.00319", "contents": "Title: Edge Caching for Coverage and Capacity-aided Heterogeneous Networks Abstract: A two-tier heterogeneous cellular network (HCN) with intra-tier and\ninter-tier dependence is studied. The macro cell deployment follows a Poisson\npoint process (PPP) and two different clustered point processes are used to\nmodel the cache-enabled small cells. Under this model, we derive approximate\nexpressions in terms of finite integrals for the average delivery rate\nconsidering inter-tier and intra-tier dependence. On top of the fact that cache\nsize drastically improves the performance of small cells in terms of average\ndelivery rate, we show that rate splitting of limited-backhaul induces\nnon-linear performance variations, and therefore has to be adjusted for rate\nfairness among users of different tiers. \n\n"}
{"id": "1605.01690", "contents": "Title: Fog-Aided Wireless Networks for Content Delivery: Fundamental Latency\n  Trade-Offs Abstract: A fog-aided wireless network architecture is studied in which edge-nodes\n(ENs), such as base stations, are connected to a cloud processor via dedicated\nfronthaul links, while also being endowed with caches. Cloud processing enables\nthe centralized implementation of cooperative transmission strategies at the\nENs, albeit at the cost of an increased latency due to fronthaul transfer. In\ncontrast, the proactive caching of popular content at the ENs allows for the\nlow-latency delivery of the cached files, but with generally limited\nopportunities for cooperative transmission among the ENs. The interplay between\ncloud processing and edge caching is addressed from an information-theoretic\nviewpoint by investigating the fundamental limits of a high\nSignal-to-Noise-Ratio (SNR) metric, termed normalized delivery time (NDT),\nwhich captures the worst-case coding latency for delivering any requested\ncontent to the users. The NDT is defined under the assumptions of either serial\nor pipelined fronthaul-edge transmission, and is studied as a function of\nfronthaul and cache capacity constraints. Placement and delivery strategies\nacross both fronthaul and wireless, or edge, segments are proposed with the aim\nof minimizing the NDT. Information-theoretic lower bounds on the NDT are also\nderived. Achievability arguments and lower bounds are leveraged to characterize\nthe minimal NDT in a number of important special cases, including systems with\nno caching capabilities, as well as to prove that the proposed schemes achieve\noptimality within a constant multiplicative factor of 2 for all values of the\nproblem parameters. \n\n"}
{"id": "1605.01930", "contents": "Title: Context Information Based Initial Cell Search for Millimeter Wave 5G\n  Cellular Networks Abstract: Millimeter wave (mmWave) communication is envisioned as a cornerstone to\nfulfill the data rate requirements for fifth generation (5G) cellular networks.\nIn mmWave communication, beamforming is considered as a key technology to\ncombat the high path-loss, and unlike in conventional microwave communication,\nbeamforming may be necessary even during initial access/cell search. Among the\nproposed beamforming schemes for initial cell search, analog beamforming is a\npower efficient approach but suffers from its inherent search delay during\ninitial access. In this work, we argue that analog beamforming can still be a\nviable choice when context information about mmWave base stations (BS) is\navailable at the mobile station (MS). We then study how the performance of\nanalog beamforming degrades in case of angular errors in the available context\ninformation. Finally, we present an analog beamforming receiver architecture\nthat uses multiple arrays of Phase Shifters and a single RF chain to combat the\neffect of angular errors, showing that it can achieve the same performance as\nhybrid beamforming. \n\n"}
{"id": "1605.02238", "contents": "Title: Latency Analysis of Systems with Multiple Interfaces for Ultra-Reliable\n  M2M Communication Abstract: One of the ways to satisfy the requirements of ultra-reliable low latency\ncommunication for mission critical Machine-type Communications (MTC)\napplications is to integrate multiple communication interfaces. In order to\nestimate the performance in terms of latency and reliability of such an\nintegrated communication system, we propose an analysis framework that combines\ntraditional reliability models with technology-specific latency probability\ndistributions. In our proposed model we demonstrate how failure correlation\nbetween technologies can be taken into account. We show for the considered\nscenario with fiber and different cellular technologies how up to 5-nines\nreliability can be achieved and how packet splitting can be used to reduce\nlatency substantially while keeping 4-nines reliability. The model has been\nvalidated through simulation. \n\n"}
{"id": "1605.02899", "contents": "Title: Revisited Design Criteria For STBCs With Reduced Complexity ML Decoding Abstract: The design of linear STBCs offering a low-complexity ML decoding using the\nwell known Sphere Decoder (SD) has been extensively studied in last years. The\nfirst considered approach to derive design criteria for the construction of\nsuch codes is based on the Hurwitz-Radon (HR) Theory for mutual orthogonality\nbetween the weight matrices defining the linear code. This appproach served to\nconstruct new families of codes admitting fast sphere decoding such as\nmulti-group decodable, fast decodable, and fast-group decodable codes. In a\nsecond Quadratic Form approach, the Fast Sphere Decoding (FSD) complexity of\nlinear STBCs is captured by a Hurwitz Radon Quadratic Form (HRQF) matrix based\nin its essence on the HR Theory. In this work, we revisit the structure of\nweight matrices for STBCs to admit Fast Sphere decoding. We first propose novel\nsufficient conditions and design criteria for reduced-complexity ML decodable\nlinear STBCs considering an arbitrary number of antennas and linear STBCs of an\narbitrary coding rate. Then we apply the derived criteria to the three families\nof codes mentioned above and provide analytical proofs showing that the FSD\ncomplexity depends only on the weight matrices and their ordering and not on\nthe channel gains or the number of antennas and explain why the so far used HR\ntheory-based approaches are suboptimal. \n\n"}
{"id": "1605.07046", "contents": "Title: Phase retrieval from multiple-window short-time Fourier measurements Abstract: In this paper, we introduce two symmetric directed graphs depending on\nsupports of signals and windows, and we show that the connectivity of those\ngraphs provides either necessary and sufficient conditions to phase retrieval\nof a signal from magnitude measurements of its multiple-window short-time\nFourier transform. Also we propose an algebraic reconstruction algorithm, and\nprovide an error estimate to our algorithm when magnitude measurements are\ncorrupted by deterministic/random noises. \n\n"}
{"id": "1605.08513", "contents": "Title: Stochastic Online Control for Energy-Harvesting Wireless Networks with\n  Battery Imperfections Abstract: In energy harvesting (EH) network, the energy storage devices (i.e.,\nbatteries) are usually not perfect. In this paper, we consider a practical\nbattery model with finite battery capacity, energy (dis-)charging loss, and\nenergy dissipation. Taking into account such battery imperfections, we rely on\nthe Lyapunov optimization technique to develop a stochastic online control\nscheme that aims to maximize the utility of data rates for EH multi-hop\nwireless networks. It is established that the proposed algorithm can provide a\nfeasible and efficient data admission, power allocation, routing and scheduling\nsolution, without requiring any statistical knowledge of the stochastic\nchannel, data-traffic, and EH processes. Numerical results demonstrate the\nmerit of the proposed scheme. \n\n"}
{"id": "1605.09124", "contents": "Title: Minimax Rate-Optimal Estimation of Divergences between Discrete\n  Distributions Abstract: We study the minimax estimation of $\\alpha$-divergences between discrete\ndistributions for integer $\\alpha\\ge 1$, which include the Kullback--Leibler\ndivergence and the $\\chi^2$-divergences as special examples. Dropping the usual\ntheoretical tricks to acquire independence, we construct the first minimax\nrate-optimal estimator which does not require any Poissonization, sample\nsplitting, or explicit construction of approximating polynomials. The estimator\nuses a hybrid approach which solves a problem-independent linear program based\non moment matching in the non-smooth regime, and applies a problem-dependent\nbias-corrected plug-in estimator in the smooth regime, with a soft decision\nboundary between these regimes. \n\n"}
{"id": "1605.09493", "contents": "Title: A Multiway Relay Channel with Balanced Sources Abstract: We consider a joint source-channel coding problem on a finite-field multiway\nrelay channel, and we give closed-form lower and upper bounds on the optimal\nsource-channel rate. These bounds are shown to be tight for all discrete\nmemoryless sources in a certain class $\\mathcal{P}^*$, and we demonstrate that\nstrict source-channel separation is optimal within this class. We show how to\ntest whether a given source belongs to $\\mathcal{P}^*$, we give a\nbalanced-information regularity condition for $\\mathcal{P}^*$, and we express\n$\\mathcal{P}^*$ in terms of conditional multiple-mutual informations. Finally,\nwe show that $\\mathcal{P}^*$ is useful for a centralised storage problem. \n\n"}
{"id": "1606.00933", "contents": "Title: Multipair Massive MIMO Relaying with Pilot-Data Transmission Overlay Abstract: We propose a pilot-data transmission overlay scheme for multipair massive\nmultiple-input multiple-output (MIMO) relaying systems employing either half-\nor full-duplex (HD or FD) communications at the relay station (RS). In the\nproposed scheme, pilots are transmitted in partial overlap with data to\ndecrease the channel estimation overhead. The RS can detect the source data\nwith minimal destination pilot interference by exploiting the asymptotic\northogonality of massive MIMO channels. Then pilot-data interference can be\neffectively suppressed with assistance of the detected source data in the\ndestination channel estimation. Due to the transmission overlay, the effective\ndata period is extended, hence improving system throughput. Both theoretical\nand simulation results confirm that the proposed pilot-data overlay scheme\noutperforms the conventional separate pilot-data design in the limited\ncoherence time interval scenario. Moreover, asymptotic analyses at high and low\nSNR regions demonstrate the superiority of the proposed scheme regardless of\nthe coherence interval length. Because of simultaneous transmission, the proper\nallocation of source data transmission and relay data forwarding power can\nfurther improve the system performance. Hence a power allocation problem is\nformulated and a successive convex approximation approach is proposed to solve\nthe non-convex optimization problem with the FD pilot-data transmission\noverlay. \n\n"}
{"id": "1606.00963", "contents": "Title: Optimal quantization for a probability measure on a nonuniform stretched\n  Sierpi\\'{n}ski triangle Abstract: Quantization for a Borel probability measure refers to the idea of estimating\na given probability by a discrete probability with support containing a finite\nnumber of elements. In this paper, we have considered a Borel probability\nmeasure $P$ on $\\mathbb R^2$, which has support a nonuniform stretched\nSierpi\\'{n}ski triangle generated by a set of three contractive similarity\nmappings on $\\mathbb R^2$. For this probability measure, we investigate the\noptimal sets of $n$-means and the $n$th quantization errors for all positive\nintegers $n$. \n\n"}
{"id": "1606.01505", "contents": "Title: Basis entropy: A useful physical quantity about projective measurement Abstract: Projective measurement can increase the entropy of a state $\\rho$, the\nincreased entropy is not only up to the basis of projective measurement, but\nalso has something to do with the properties of the state itself. In this paper\nwe define this increased entropy as basis entropy. And then we discuss the\nusefulness of this new concept by showing its application in deciding whether a\nstate is pure or not and detecting the existence of quantum discord. And as\nshown in the paper, this new concept can also be used to describe decoherence. \n\n"}
{"id": "1606.02080", "contents": "Title: Random Access Protocols for Massive MIMO Abstract: 5G wireless networks are expected to support new services with stringent\nrequirements on data rates, latency and reliability. One novel feature is the\nability to serve a dense crowd of devices, calling for radically new ways of\naccessing the network. This is the case in machine-type communications, but\nalso in urban environments and hotspots. In those use cases, the high number of\ndevices and the relatively short channel coherence interval do not allow\nper-device allocation of orthogonal pilot sequences. This article motivates the\nneed for random access by the devices to pilot sequences used for channel\nestimation, and shows that Massive MIMO is a main enabler to achieve fast\naccess with high data rates, and delay-tolerant access with different data rate\nlevels. Three pilot access protocols along with data transmission protocols are\ndescribed, fulfilling different requirements of 5G services. \n\n"}
{"id": "1606.02337", "contents": "Title: Random Access in C-RAN for User Activity Detection with Limited-Capacity\n  Fronthaul Abstract: Cloud-Radio Access Network (C-RAN) is characterized by a hierarchical\nstructure in which the baseband processing functionalities of remote radio\nheads (RRHs) are implemented by means of cloud computing at a Central Unit\n(CU). A key limitation of C-RANs is given by the capacity constraints of the\nfronthaul links connecting RRHs to the CU. In this letter, the impact of this\narchitectural constraint is investigated for the fundamental functions of\nrandom access and active User Equipment (UE) identification in the presence of\na potentially massive number of UEs. In particular, the standard C-RAN approach\nbased on quantize-and-forward and centralized detection is compared to a scheme\nbased on an alternative CU-RRH functional split that enables local detection.\nBoth techniques leverage Bayesian sparse detection. Numerical results\nillustrate the relative merits of the two schemes as a function of the system\nparameters. \n\n"}
{"id": "1606.02786", "contents": "Title: Maximum Selection and Sorting with Adversarial Comparators and an\n  Application to Density Estimation Abstract: We study maximum selection and sorting of $n$ numbers using pairwise\ncomparators that output the larger of their two inputs if the inputs are more\nthan a given threshold apart, and output an adversarially-chosen input\notherwise. We consider two adversarial models. A non-adaptive adversary that\ndecides on the outcomes in advance based solely on the inputs, and an adaptive\nadversary that can decide on the outcome of each query depending on previous\nqueries and outcomes.\n  Against the non-adaptive adversary, we derive a maximum-selection algorithm\nthat uses at most $2n$ comparisons in expectation, and a sorting algorithm that\nuses at most $2n \\ln n$ comparisons in expectation. These numbers are within\nsmall constant factors from the best possible. Against the adaptive adversary,\nwe propose a maximum-selection algorithm that uses $\\Theta(n\\log\n(1/{\\epsilon}))$ comparisons to output a correct answer with probability at\nleast $1-\\epsilon$. The existence of this algorithm affirmatively resolves an\nopen problem of Ajtai, Feldman, Hassadim, and Nelson.\n  Our study was motivated by a density-estimation problem where, given samples\nfrom an unknown underlying distribution, we would like to find a distribution\nin a known class of $n$ candidate distributions that is close to underlying\ndistribution in $\\ell_1$ distance. Scheffe's algorithm outputs a distribution\nat an $\\ell_1$ distance at most 9 times the minimum and runs in time\n$\\Theta(n^2\\log n)$. Using maximum selection, we propose an algorithm with the\nsame approximation guarantee but run time of $\\Theta(n\\log n)$. \n\n"}
{"id": "1606.03768", "contents": "Title: New Permutation Trinomials From Niho Exponents over Finite Fields with\n  Even Characteristic Abstract: In this paper, a class of permutation trinomials of Niho type over finite\nfields with even characteristic is further investigated. New permutation\ntrinomials from Niho exponents are obtained from linear fractional polynomials\nover finite fields, and it is shown that the presented results are the\ngeneralizations of some earlier works. \n\n"}
{"id": "1606.03878", "contents": "Title: Device-independent dimension tests in the prepare-and-measure scenario Abstract: Analyzing the dimension of an unknown quantum system in a device-independent\nmanner, i.e., using only the measurement statistics, is a fundamental task in\nquantum physics and quantum information theory. In this paper, we consider this\nproblem in the prepare-and-measure scenario. Specifically, we provide a lower\nbound on the dimension of the prepared quantum systems which is a function that\nonly depends on the measurement statistics. Furthermore, we show that our bound\nperforms well on several examples. {In particular}, we show that our bound\nprovides new insights into the notion of dimension witness, and we also use it\nto show that the sets of restricted-dimensional prepare-and-measure\ncorrelations are not always convex. \n\n"}
{"id": "1606.04202", "contents": "Title: Improved Approximation of Storage-Rate Tradeoff for Caching with\n  Multiple Demands Abstract: Caching at the network edge has emerged as a viable solution for alleviating\nthe severe capacity crunch in modern content centric wireless networks by\nleveraging network load-balancing in the form of localized content storage and\ndelivery. In this work, we consider a cache-aided network where the cache\nstorage phase is assisted by a central server and users can demand multiple\nfiles at each transmission interval. To service these demands, we consider two\ndelivery models - $(1)$ centralized content delivery where user demands at each\ntransmission interval are serviced by the central server via multicast\ntransmissions; and $(2)$ device-to-device (D2D) assisted distributed delivery\nwhere users multicast to each other in order to service file demands. For such\ncache-aided networks, we present new results on the fundamental cache storage\nvs. transmission rate tradeoff. Specifically, we develop a new technique for\ncharacterizing information theoretic lower bounds on the storage-rate tradeoff\nand show that the new lower bounds are strictly tighter than cut-set bounds\nfrom literature. Furthermore, using the new lower bounds, we establish the\noptimal storage-rate tradeoff to within a constant multiplicative gap. We show\nthat, for multiple demands per user, achievable schemes based on repetition of\nschemes for single demands are order-optimal under both delivery models. \n\n"}
{"id": "1606.04405", "contents": "Title: Fundamentals of Modeling Finite Wireless Networks using Binomial Point\n  Process Abstract: Modeling the locations of nodes as a uniform binomial point process (BPP), we\npresent a generic mathematical framework to characterize the performance of an\narbitrarily-located reference receiver in a finite wireless network. Different\nfrom most of the prior works where the serving transmitter (TX) node is located\nat the fixed distance from the reference receiver, we consider two general\nTX-selection policies: i) uniform TX-selection: the serving node is chosen\nuniformly at random amongst transmitting nodes, and ii) k-closest TX-selection:\nthe serving node is the k-th closest node out of transmitting nodes to the\nreference receiver. The key intermediate step in our analysis is the derivation\nof a new set of distance distributions that lead not only to the tractable\nanalysis of coverage probability but also enable the analyses of wide range of\nclassical and currently trending problems in wireless networks. Using this new\nset of distance distributions, we first investigate the diversity loss due to\nSIR correlation in a finite network. We then obtain the optimal number of links\nthat can be simultaneously activated to maximize network spectral efficiency.\nFinally, we evaluate optimal caching probability to maximize the total hit\nprobability in cache-enabled finite networks. \n\n"}
{"id": "1606.04678", "contents": "Title: Strong Converse Theorems for Multimessage Networks with Tight Cut-Set\n  Bound Abstract: This paper considers a multimessage network where each node may send a\nmessage to any other node in the network. Under the discrete memoryless model,\nwe prove the strong converse theorem for any network whose cut-set bound is\ntight, i.e., achievable. Our result implies that for any fixed rate vector that\nresides outside the capacity region, the average error probabilities of any\nsequence of length-$n$ codes operated at the rate vector must tend to $1$ as\n$n$ approaches infinity. The proof is based on the method of types and is\ninspired by the work of Csisz\\'{a}r and K\\\"{o}rner in 1982 which fully\ncharacterized the reliability function of any discrete memoryless channel (DMC)\nwith feedback for rates above capacity. In addition, we generalize the strong\nconverse theorem to the Gaussian model where each node is subject to an\nalmost-sure power constraint. Important consequences of our results are new\nstrong converses for the Gaussian multiple access channel (MAC) with feedback\nand the following relay channels under both models: The degraded relay channel\n(RC), the RC with orthogonal sender components, and the general RC with\nfeedback. \n\n"}
{"id": "1606.04760", "contents": "Title: Adapting to unknown noise level in sparse deconvolution Abstract: In this paper, we study sparse spike deconvolution over the space of\ncomplex-valued measures when the input measure is a finite sum of Dirac masses.\nWe introduce a modified version of the Beurling Lasso (BLasso), a semi-definite\nprogram that we refer to as the Concomitant Beurling Lasso (CBLasso). This new\nprocedure estimates the target measure and the unknown noise level\nsimultaneously. Contrary to previous estimators in the literature, theory holds\nfor a tuning parameter that depends only on the sample size, so that it can be\nused for unknown noise level problems. Consistent noise level estimation is\nstandardly proved. As for Radon measure estimation, theoretical guarantees\nmatch the previous state-of-the-art results in Super-Resolution regarding\nminimax prediction and localization. The proofs are based on a bound on the\nnoise level given by a new tail estimate of the supremum of a stationary\nnon-Gaussian process through the Rice method. \n\n"}
{"id": "1606.05673", "contents": "Title: User-Centric Mobility Management in Ultra-Dense Cellular Networks under\n  Spatio-Temporal Dynamics Abstract: This article investigates the mobility management of an ultra dense cellular\nnetwork (UDN) from an energy-efficiency (EE) point of view. Many dormant base\nstations (BSs) in a UDN do not transmit signals, and thus a received power\nbased handover (HO) approach as in traditional cellular networks is hardly\napplicable. In addition, the limited front/backhaul capacity compared to a huge\nnumber of BSs makes it difficult to implement a centralized HO and power\ncontrol. For these reasons, a novel user-centric association rule is proposed,\nwhich jointly optimizes HO and power control for maximizing EE. The proposed\nmobility management is able to cope not only with the spatial randomness of\nuser movement but also with temporally correlated wireless channels. The\nproposed approach is implemented over a HO time window and tractable power\ncontrol policy by exploiting mean-field game (MFG) and stochastic geometry\n(SG). Compared to a baseline with a fixed HO interval and transmit power, the\nproposed approach achieves the 1.2 times higher long-term average EE at a\ntypical active BS. \n\n"}
{"id": "1606.06032", "contents": "Title: Design and Performance Analysis of Non-Coherent Detection Systems with\n  Massive Receiver Arrays Abstract: Harvesting the gain of a large number of antennas in a mmWave band has mainly\nbeen relying on the costly operation of channel state information (CSI)\nacquisition and cumbersome phase shifters. Recent works have started to\ninvestigate the possibility to use receivers based on energy detection (ED),\nwhere a single data stream is decoded based on the channel and noise energy.\nThe asymptotic features of the massive receiver array lead to a system where\nthe impact of the noise becomes predictable due to a noise hardening effect.\nThis in effect extends the communication range compared to the receiver with a\nsmall number of antennas, as the latter is limited by the unpredictability of\nthe additive noise. When the channel has a large number of spatial degrees of\nfreedom, the system becomes robust to imperfect channel knowledge due to\nchannel hardening. We propose two detection methods based on the instantaneous\nand average channel energy, respectively. Meanwhile, we design the detection\nthresholds based on the asymptotic properties of the received energy.\nDifferently from existing works, we analyze the scaling law behavior of the\nsymbol-error-rate (SER). When the instantaneous channel energy is known, the\nperformance of ED approaches that of the coherent detection in high SNR\nscenarios. When the receiver relies on the average channel energy, our\nperformance analysis is based on the exact SER, rather than an approximation.\nIt is shown that the logarithm of SER decreases linearly as a function of the\nnumber of antennas. Additionally, a saturation appears at high SNR for PAM\nconstellations of order larger than two, due to the uncertainty on the channel\nenergy. Simulation results show that ED, with a much lower complexity, achieves\npromising performance both in Rayleigh fading channels and in sparse channels. \n\n"}
{"id": "1606.06794", "contents": "Title: A Delay-Optimal Packet Scheduler for M2M Uplink Abstract: In this paper, we present a delay-optimal packet scheduler for processing the\nM2M uplink traffic at the M2M application server (AS). Due to the\ndelay-heterogeneity in uplink traffic, we classify it broadly into\ndelay-tolerant and delay-sensitive traffic. We then map the diverse delay\nrequirements of each class to sigmoidal functions of packet delay and formulate\na utility-maximization problem that results in a proportionally fair\ndelay-optimal scheduler. We note that solving this optimization problem is\nequivalent to solving for the optimal fraction of time each class is served\nwith (preemptive) priority such that it maximizes the system utility. Using\nMonte-Carlo simulations for the queuing process at AS, we verify the\ncorrectness of the analytical result for optimal scheduler and show that it\noutperforms other state-of-the-art packet schedulers such as weighted round\nrobin, max-weight scheduler, fair scheduler and priority scheduling. We also\nnote that at higher traffic arrival rate, the proposed scheduler results in a\nnear-minimal delay variance for the delay-sensitive traffic which is highly\ndesirable. This comes at the expense of somewhat higher delay variance for\ndelay-tolerant traffic which is usually acceptable due to its delay-tolerant\nnature. \n\n"}
{"id": "1606.06802", "contents": "Title: Quantum Probability as an Application of Data Compression Principles Abstract: Realist, no-collapse interpretations of quantum mechanics, such as Everett's,\nface the probability problem: how to justify the norm-squared (Born) rule from\nthe wavefunction alone. While any basis-independent measure can only be\nnorm-squared (due to the Gleason-Busch Theorem) this fact conflicts with\nvarious popular, non-wavefunction-based phenomenological measures - such as\nobserver, outcome or world counting - that are frequently demanded of\nEverettians. These alternatives conflict, however, with the wavefunction\nrealism upon which Everett's approach rests, which seems to call for an\nobjective, basis-independent measure based only on wavefunction amplitudes. The\nability of quantum probabilities to destructively interfere with each other,\nhowever, makes it difficult to see how probabilities can be derived solely from\namplitudes in an intuitively appealing way. I argue that the use of algorithmic\nprobability can solve this problem, since the objective, single-case\nprobability measure that wavefunction realism demands is exactly what\nalgorithmic information theory was designed to provide. The result is an\nintuitive account of complex-valued amplitudes, as coefficients in an optimal\nlossy data compression, such that changes in algorithmic information content\n(entropy deltas) are associated with phenomenal transitions. \n\n"}
{"id": "1606.08135", "contents": "Title: Phaseless Rcovery using Gauss-Newton Method Abstract: In this paper, we develop a concrete algorithm for phase retrieval, which we\nrefer to as Gauss-Newton algorithm. In short, this algorithm starts with a good\ninitial estimation, which is obtained by a modified spectral method, and then\nupdate the iteration point by a Gauss-Newton iteration step. We prove that a\nre-sampled version of this algorithm quadratically converges to the solution\nfor the real case with the number of random measurements being nearly minimal.\nNumerical experiments also show that Gauss-Newton method has better performance\nover the other algorithms. \n\n"}
{"id": "1606.08545", "contents": "Title: A H-ARQ scheme for polar codes Abstract: We consider the problem of supporting H-ARQ with polar codes. For supporting\nH-ARQ, we propose to create redundancy versions based on different, but\nequivalent, subsets of a polar code. The equivalent subsets are created from an\ninitial subset of a polar code using an inherent symmetry in polar code\nconstruction. A greedy construction is used to create the initial subset of a\npolar code. We demonstrate performance of proposed constructions via\nsimulations for binary input AWGN channel. We demonstrate that a (4096, 1024)\npolar code can be divided into two disjoint (2048, 1024) subset polar codes,\nwhich when decoded individually are within 0.2 dB (at $1 \\%$ BLER) of a (2048,\n1024) polar code, and achieve performance of a (4096, 1024) polar code when\ndecoded jointly. \n\n"}
{"id": "1606.08950", "contents": "Title: Cross-layer design for downlink multi-hop cloud radio access networks\n  with network coding Abstract: There are two fundamentally different fronthaul techniques in the downlink\ncommunication of cloud radio access network (C-RAN): the data-sharing strategy\nand the compression-based strategy. Under the former strategy, each user's\nmessage is multicast from the central processor (CP) to all the serving remote\nradio heads (RRHs) over the fronthaul network, which then cooperatively serve\nthe users through joint beamforming; while under the latter strategy, the user\nmessages are first beamformed then quantized at the CP, and the compressed\nsignal is unicast to the corresponding RRH, which then decompresses its\nreceived signal for wireless transmission. Previous works show that in general\nthe compression-based strategy outperforms the data-sharing strategy. This\npaper, on the other hand, point s out that in a C-RAN model where the RRHs are\nconnected to the CP via multi-hop routers, data-sharing can be superior to\ncompression if the network coding technique is adopted for multicasting user\nmessages to the cooperating RRHs, and the RRH's beamforming vectors, the\nuser-RRH association, and the network coding design over the fronthaul network\nare jointly optimized based on the techniques of sparse optimization an d\nsuccessive convex approximation. This is in comparison to the compression-based\nstrategy, where information is unicast over the fronthaul network by simple\nrouting, and the RRH's compression noise covariance and beamforming vectors, as\nwell as the routing strategy over the fronthaul network are jointly optimized\nbased on the successive convex approximation technique. The observed gain in\noverall network throughput is due to that information multicast is more\nefficient than information unicast over the multi-hop fronthaul of a C-RAN. \n\n"}
{"id": "1607.00500", "contents": "Title: Spatio-Temporal Network Dynamics Framework for Energy-Efficient\n  Ultra-Dense Cellular Networks Abstract: This article investigates the performance of an ultra-dense network (UDN)\nfrom an energy-efficiency (EE) standpoint leveraging the interplay between\nstochastic geometry (SG) and mean-field game (MFG) theory. In this setting,\nbase stations (BSs) (resp. users) are uniformly distributed over a\ntwo-dimensional plane as two independent homogeneous Poisson point processes\n(PPPs), where users associate to their nearest BSs. The goal of every BS is to\nmaximize its own energy efficiency subject to channel uncertainty, random BS\nlocation, and interference levels. Due to the coupling in interference, the\nproblem is solved in the mean-field (MF) regime where each BS interacts with\nthe whole BS population via time-varying MF interference. As a main\ncontribution, the asymptotic convergence of MF interference to zero is\nrigorously proved in a UDN with multiple transmit antennas. It allows us to\nderive a closed-form EE representation, yielding a tractable EE optimal power\ncontrol policy. This proposed power control achieves more than 1.5 times higher\nEE compared to a fixed power baseline. \n\n"}
{"id": "1607.01827", "contents": "Title: Compressive Spectral Estimation with Single-Snapshot ESPRIT: Stability\n  and Resolution Abstract: In this paper Estimation of Signal Parameters via Rotational Invariance\nTechniques (ESPRIT) is developed for spectral estimation with single-snapshot\nmeasurement. Stability and resolution analysis with performance guarantee for\nSingle-Snapshot ESPRIT (SS-ESPRIT) is the main focus. In the noise-free case,\nexact reconstruction is guaranteed for any arbitrary set of frequencies as long\nas the number of measurement data is at least twice the number of distinct\nfrequencies to be recovered. In the presence of noise and under the assumption\nthat the true frequencies are separated by at least two times Rayleigh's\nResolution Length, an explicit error bound for frequency reconstruction is\ngiven in terms of the dynamic range and the separation of the frequencies. The\nseparation and sparsity constraint compares favorably with those of the leading\napproaches to compressed sensing in the continuum. \n\n"}
{"id": "1607.02259", "contents": "Title: Maximum Entropy and Sufficiency Abstract: The notion of Bregman divergence and sufficiency will be defined on general\nconvex state spaces. It is demonstrated that only spectral sets can have a\nBregman divergence that satisfies a sufficiency condition. Positive elements\nwith trace 1 in a Jordan algebra are examples of spectral sets, and the most\nimportant example is the set of density matrices with complex entries. It is\nconjectured that information theoretic considerations lead directly to the\nnotion of Jordan algebra under some regularity conditions. \n\n"}
{"id": "1607.02385", "contents": "Title: Finite Length Performance of Random Slotted ALOHA Strategies Abstract: Multiple connected devices sharing common wireless resources might create\ninterference if they access the channel simultaneously. Medium access control\n(MAC) protocols gener- ally regulate the access of the devices to the shared\nchannel to limit signal interference. In particular, irregular repetition\nslotted ALOHA (IRSA) techniques can achieve high-throughput performance when\ninterference cancellation methods are adopted to recover from collisions. In\nthis work, we study the finite length performance for IRSA schemes by building\non the analogy between successive interference cancellation and iterative\nbelief- propagation on erasure channels. We use a novel combinatorial\nderivation based on the matrix-occupancy theory to compute the error\nprobability and we validate our method with simulation results. \n\n"}
{"id": "1607.03571", "contents": "Title: Traffic Management for Heterogeneous Networks with Opportunistic\n  Unlicensed Spectrum Sharing Abstract: This paper studies how to maximize the per-user-based throughput in an M-tier\nheterogeneous wireless network (HetNet) by optimally managing traffic flows\nbetween the access points (APs) in the HetNet. The APs in the first M-1 tiers\ncan use the licensed spectrum at the same time whereas they share the\nunlicensed spectrum with the APs in the Mth tier by the proposed opportunistic\ncarrier sense multiple access with collision avoidance (CSMA/CA) protocol. The\nAPs that access the licensed and unlicensed spectra simultaneously are able to\nintegrate their spectrum resources by the carrier aggregation technique. We\nfirst characterize the distribution of the cell load and the channel access\nprobability of each AP using a generalized AP association scheme. For an AP in\neach tier, the tight lower bounds on its mean spectrum efficiencies in the\nlicensed and unlicensed spectra are derived for the general random models of\nthe channel gain and AP association weights. We define the per-user link\nthroughput and per-user network throughput based on the derived the mean\nspectrum efficiencies and maximize them by proposing the decentralized and\ncentralized traffic management schemes for the APs in the first M-1 tiers under\nthe constraint that the per-user link throughput of the tier-M APs must be\nabove some minimum required value. Finally, a numerical example of coexisting\nLTE and WiFi networks is provided to validate our derived results and findings. \n\n"}
{"id": "1607.03581", "contents": "Title: Encoding and Indexing of Lattice Codes Abstract: Encoding and indexing of lattice codes is generalized from self-similar\nlattice codes to a broader class of lattices. If coding lattice\n$\\Lambda_{\\textrm{c}}$ and shaping lattice $\\Lambda_{\\textrm{s}}$ satisfy\n$\\Lambda_{\\textrm{s}} \\subseteq \\Lambda_{\\textrm{c}}$, then\n$\\Lambda_{\\textrm{c}} / \\Lambda_{\\textrm{s}}$ is a quotient group that can be\nused to form a (nested) lattice code $\\mathcal{C}$. Conway and Sloane's method\nof encoding and indexing does not apply when the lattices are not self-similar.\nResults are provided for two classes of lattices. (1) If $\\Lambda_{\\textrm{c}}$\nand $\\Lambda_{\\textrm{s}}$ both have generator matrices in triangular form,\nthen encoding is always possible. (2) When $\\Lambda_{\\textrm{c}}$ and\n$\\Lambda_{\\textrm{s}}$ are described by full generator matrices, if a solution\nto a linear diophantine equation exists, then encoding is possible. In\naddition, special cases where $\\mathcal{C}$ is a cyclic code are also\nconsidered. A condition for the existence of a group homomorphism between the\ninformation and $\\mathcal{C}$ is given. The results are applicable to a variety\nof coding lattices, including Construction A, Construction D and LDLCs. The\n$D_4$, $E_8$ and convolutional code lattices are shown to be good choices for\nthe shaping lattice. Thus, a lattice code $\\mathcal{C}$ can be designed by\nselecting $\\Lambda_{\\textrm{c}}$ and $\\Lambda_{\\textrm{s}}$ separately,\navoiding competing design requirements of self-similar lattice codes. \n\n"}
{"id": "1607.03671", "contents": "Title: On The Use of Conjugate Teager-Kaiser Energy Operators with Matched\n  Filters Abstract: This work presents the proof of concept of using energy operator theory based\non the conjugate Teager-Kaiser energy operators in matched filters for signal\ndetection in multipath fading channels. To do so, we consider signals in the\nspace $\\mathcal{S}(\\mathbb{R})$ a subspace of the Schwartz space\n$\\mathbf{S}^-(\\mathbb{R})$ in order to approximate the received signal. These\nfunctions obey to some specific properties as shown in this work. It allows to\ndecompose the received signals into subchannels with their own\nSignal-to-Noise-Ratio. \n\n"}
{"id": "1607.04525", "contents": "Title: Secure Analog Network Coding in Layered Networks Abstract: We consider a class of Gaussian layered networks where a source communicates\nwith a destination through $L$ intermediate relay layers with $N$ nodes in each\nlayer in the presence of a single eavesdropper which can overhear the\ntransmissions of the nodes in any one layer. The problem of maximum secrecy\nrate achievable with analog network coding for a unicast communication over\nsuch layered wireless relay networks with directed links is considered. A relay\nnode performing analog network coding scales and forwards the signals received\nat its input. The key contribution of this work is a lemma that provides the\nglobally optimal set of scaling factors for the nodes that maximizes the\nend-to-end secrecy rate for a class of layered networks. We also show that in\nthe high-SNR regime, ANC achieves secrecy rates within a constant gap of the\ncutset upper bound on the secrecy capacity. To the best of our knowledge, this\nwork offers the first characterization of the performance of secure ANC in\nmulti-layered networks in the presence of an eavesdropper. \n\n"}
{"id": "1607.05490", "contents": "Title: Parity Oblivious d-Level Random Access Codes and Class of\n  Noncontextuality Inequalities Abstract: One of the fundamental results in quantum foundations is the Kochen-Specker\nno-go theorem. For the quantum theory, the no-go theorem excludes the\npossibility of a class of hidden variable models where value attribution is\ncontext independent. Recently, the notion of contextuality has been generalized\nfor different operational procedures and it has been shown that preparation\ncontextuality of mixed quantum states can be a useful resource in an\ninformation-processing task called parity-oblivious multiplexing. Here, we\nintroduce a new class of information processing tasks, namely d-level parity\noblivious random access codes and obtain bounds on the success probabilities of\nperforming such tasks in any preparation noncontextual theory. These bounds\nconstitute noncontextuality inequalities for any value of d. For d=3, using a\nset of mutually asymmetric biased bases we show that the corresponding\nnoncontextual bound is violated by quantum theory. We also show quantum\nviolation of the inequalities for some other higher values of d. This reveals\noperational usefulness of preparation contextuality of higher level quantum\nsystems. \n\n"}
{"id": "1607.07674", "contents": "Title: Secret Key Generation Through a Relay Abstract: We consider problems of two-user secret key generation through an\nintermediate relay. Each user observes correlated source sequences and\ncommunicates to the relay over rate-limited noiseless links. The relay\nprocesses and broadcasts information to the two users over another rate-limited\nlink. The users then generate a common secret key based on their sources and\ninformation from the relay. In the untrusted relay setting, the goal is to\nestablish key agreement between the two users at the highest key rate without\nleaking information about the key to the relay. We characterize inner and outer\nbounds to the optimal tradeoff between communication and key rates. The inner\nbound is based on the scheme which involves a combination of binning, network\ncoding, and key aggregation techniques. For the trusted relay setting with a\npublic broadcast link, the optimal communication-key rate tradeoff is provided\nfor a special case where the two sources are available losslessly at the relay.\nThe results can be relevant for cloud-based secret key generation services. \n\n"}
{"id": "1607.08335", "contents": "Title: Reverse Data-Processing Theorems and Computational Second Laws Abstract: Drawing on an analogy with the second law of thermodynamics for adiabatically\nisolated systems, Cover argued that data-processing inequalities may be seen as\nsecond laws for \"computationally isolated systems,\" namely, systems evolving\nwithout an external memory. Here we develop Cover's idea in two ways: on the\none hand, we clarify its meaning and formulate it in a general framework able\nto describe both classical and quantum systems. On the other hand, we prove\nthat also the reverse holds: the validity of data-processing inequalities is\nnot only necessary, but also sufficient to conclude that a system is\ncomputationally isolated. This constitutes an information-theoretic analogue of\nLieb's and Yngvason's entropy principle. We finally speculate about the\npossibility of employing Maxwell's demon to show that adiabaticity and\nmemorylessness are in fact connected in a deeper way than what the formal\nanalogy proposed here prima facie seems to suggest. \n\n"}
{"id": "1608.02866", "contents": "Title: Optimal Relay Selection for the Parallel Hybrid RF/FSO Relay Channel:\n  Non-Buffer-Aided and Buffer-Aided Designs Abstract: Hybrid radio frequency (RF)/free space optical (FSO) systems are among the\ncandidate enabling technologies for the next generation of wireless networks\nsince they benefit from both the high data rates of the FSO subsystem and the\nhigh reliability of the RF subsystem. In this paper, we focus on the problem of\nthroughput maximization in the parallel hybrid RF/FSO relay channel. In the\nparallel hybrid RF/FSO relay channel, a source node sends its data to a\ndestination node with the help of multiple relay nodes. Thereby, for a given\nrelay, the source-relay and the relay-destination FSO links are orthogonal with\nrespect to each other due to the narrow beam employed for FSO transmission,\nwhereas, due to the broadcast nature of the RF channel, half-duplex operation\nis required for the RF links if self-interference is to be avoided. Moreover,\nwe consider the two cases where the relays are and are not equipped with\nbuffers. For both cases, we derive the optimal relay selection policies for the\nRF and FSO links and the optimal time allocation policy for transmission and\nreception for the RF links. The proposed optimal protocols provide important\ninsights for optimal system design. Since the optimal buffer-aided (BA) policy\nintroduces an unbounded end-to-end delay, we also propose a suboptimal BA\npolicy which ensures certain target average delays. Moreover, we present\ndistributed implementations for both proposed optimal protocols. Simulation\nresults demonstrate that a considerable gain can be achieved by the proposed\nadaptive protocols in comparison with benchmark schemes from the literature. \n\n"}
{"id": "1608.03710", "contents": "Title: Joint 3D Positioning and Network Synchronization in 5G Ultra-Dense\n  Networks Using UKF and EKF Abstract: It is commonly expected that future fifth generation (5G) networks will be\ndeployed with a high spatial density of access nodes (ANs) in order to meet the\nenvisioned capacity requirements of the upcoming wireless networks.\nDensification is beneficial not only for communications but it also creates a\nconvenient infrastructure for highly accurate user node (UN) positioning.\nDespite the fact that positioning will play an important role in future\nnetworks, thus enabling a huge amount of location-based applications and\nservices, this great opportunity has not been widely explored in the existing\nliterature. Therefore, this paper proposes an unscented Kalman filter\n(UKF)-based method for estimating directions of arrival (DoAs) and times of\narrival (ToA) at ANs as well as performing joint 3D positioning and network\nsynchronization in a network-centric manner. In addition to the proposed\nUKF-based solution, the existing 2D extended Kalman filter (EKF)-based solution\nis extended to cover also realistic 3D positioning scenarios. Building on the\npremises of 5G ultra-dense networks (UDNs), the performance of both methods is\nevaluated and analysed in terms of DoA and ToA estimation as well as\npositioning and clock offset estimation accuracy, using the METIS map-based\nray-tracing channel model and 3D trajectories for vehicles and unmanned aerial\nvehicles (UAVs) through the Madrid grid. Based on the comprehensive numerical\nevaluations, both proposed methods can provide the envisioned one meter 3D\npositioning accuracy even in the case of unsynchronized 5G network while\nsimultaneously tracking the clock offsets of network elements with a\nnanosecond-scale accuracy. \n\n"}
{"id": "1608.03825", "contents": "Title: Coded Network Function Virtualization: Fault Tolerance via In-Network\n  Coding Abstract: Network Function Virtualization (NFV) prescribes the instantiation of network\nfunctions on general-purpose network devices, such as servers and switches.\nWhile yielding a more flexible and cost-effective network architecture, NFV is\npotentially limited by the fact that commercial off-the-shelf hardware is less\nreliable than the dedicated network elements used in conventional cellular\ndeployments. The typical solution for this problem is to duplicate network\nfunctions across geographically distributed hardware in order to ensure\ndiversity. In contrast, this letter proposes to leverage channel coding in\norder to enhance the robustness on NFV to hardware failure. The proposed\napproach targets the network function of uplink channel decoding, and builds on\nthe algebraic structure of the encoded data frames in order to perform\nin-network coding on the signals to be processed at different servers. The key\nprinciples underlying the proposed coded NFV approach are presented for a\nsimple embodiment and extensions are discussed. Numerical results demonstrate\nthe potential gains obtained with the proposed scheme as compared to the\nconventional diversity-based fault-tolerant scheme in terms of error\nprobability. \n\n"}
{"id": "1608.04460", "contents": "Title: Microcanonical thermodynamics in general physical theories Abstract: Microcanonical thermodynamics studies the operations that can be performed on\nsystems with well-defined energy. So far, this approach has been applied to\nclassical and quantum systems. Here we extend it to arbitrary physical\ntheories, proposing two requirements for the development of a general\nmicrocanonical framework. We then formulate three resource theories,\ncorresponding to three different sets of basic operations: i) random reversible\noperations, resulting from reversible dynamics with fluctuating parameters, ii)\nnoisy operations, generated by the interaction with ancillas in the\nmicrocanonical state, and iii) unital operations, defined as the operations\nthat preserve the microcanonical state. We focus our attention on a class of\nphysical theories, called sharp theories with purification, where these three\nsets of operations exhibit remarkable properties. Firstly, each set is\ncontained into the next. Secondly, the convertibility of states by unital\noperations is completely characterised by a majorisation criterion. Thirdly,\nthe three sets are equivalent in terms of state convertibility if and only if\nthe dynamics allowed by theory satisfy a suitable condition, which we call\nunrestricted reversibility. Under this condition, we derive a duality between\nthe resource theory of microcanonical thermodynamics and the resource theory of\npure bipartite entanglement. \n\n"}
{"id": "1608.05317", "contents": "Title: R\\'enyi divergences as weighted non-commutative vector valued\n  $L_p$-spaces Abstract: We show that Araki and Masuda's weighted non-commutative vector valued\n$L_p$-spaces [Araki \\& Masuda, Publ. Res. Inst. Math. Sci., 18:339 (1982)]\ncorrespond to an algebraic generalization of the sandwiched R\\'enyi divergences\nwith parameter $\\alpha = \\frac{p}{2}$. Using complex interpolation theory, we\nprove various fundamental properties of these divergences in the setup of von\nNeumann algebras, including a data-processing inequality and monotonicity in\n$\\alpha$. We thereby also give new proofs for the corresponding\nfinite-dimensional properties. We discuss the limiting cases $\\alpha\\to\n\\{\\frac{1}{2},1,\\infty\\}$ leading to minus the logarithm of Uhlmann's fidelity,\nUmegaki's relative entropy, and the max-relative entropy, respectively. As a\ncontribution that might be of independent interest, we derive a Riesz-Thorin\ntheorem for Araki-Masuda $L_p$-spaces and an Araki-Lieb-Thirring inequality for\nstates on von Neumann algebras. \n\n"}
{"id": "1608.06409", "contents": "Title: Learning to Communicate: Channel Auto-encoders, Domain Specific\n  Regularizers, and Attention Abstract: We address the problem of learning efficient and adaptive ways to communicate\nbinary information over an impaired channel. We treat the problem as\nreconstruction optimization through impairment layers in a channel autoencoder\nand introduce several new domain-specific regularizing layers to emulate common\nchannel impairments. We also apply a radio transformer network based attention\nmodel on the input of the decoder to help recover canonical signal\nrepresentations. We demonstrate some promising initial capacity results from\nthis architecture and address several remaining challenges before such a system\ncould become practical. \n\n"}
{"id": "1608.07857", "contents": "Title: Optimizing Content Caching to Maximize the Density of Successful\n  Receptions in Device-to-Device Networking Abstract: Device-to-device (D2D) communication is a promising approach to optimize the\nutilization of air interface resources in 5G networks, since it allows\ndecentralized opportunistic short-range communication. For D2D to be useful,\nmobile nodes must possess content that other mobiles want. Thus, intelligent\ncaching techniques are essential for D2D. In this paper we use results from\nstochastic geometry to derive the probability of successful content delivery in\nthe presence of interference and noise. We employ a general transmission\nstrategy where multiple files are cached at the users and different files can\nbe transmitted simultaneously throughout the network. We then formulate an\noptimization problem, and find the caching distribution that maximizes the\ndensity of successful receptions (DSR) under a simple transmission strategy\nwhere a single file is transmitted at a time throughout the network. We model\nfile requests by a Zipf distribution with exponent $\\gamma_r$, which results in\nan optimal caching distribution that is also a Zipf distribution with exponent\n$\\gamma_c$, which is related to $\\gamma_r$ through a simple expression\ninvolving the path loss exponent. We solve the optimal content placement\nproblem for more general demand profiles under Rayleigh, Ricean and Nakagami\nsmall-scale fading distributions. Our results suggest that it is required to\nflatten the request distribution to optimize the caching performance. We also\ndevelop strategies to optimize content caching for the more general case with\nmultiple files, and bound the DSR for that scenario. \n\n"}
{"id": "1609.03363", "contents": "Title: CONDENSE: A Reconfigurable Knowledge Acquisition Architecture for Future\n  5G IoT Abstract: In forthcoming years, the Internet of Things (IoT) will connect billions of\nsmart devices generating and uploading a deluge of data to the cloud. If\nsuccessfully extracted, the knowledge buried in the data can significantly\nimprove the quality of life and foster economic growth. However, a critical\nbottleneck for realising the efficient IoT is the pressure it puts on the\nexisting communication infrastructures, requiring transfer of enormous data\nvolumes. Aiming at addressing this problem, we propose a novel architecture\ndubbed Condense, which integrates the IoT-communication infrastructure into\ndata analysis. This is achieved via the generic concept of network function\ncomputation: Instead of merely transferring data from the IoT sources to the\ncloud, the communication infrastructure should actively participate in the data\nanalysis by carefully designed en-route processing. We define the Condense\narchitecture, its basic layers, and the interactions among its constituent\nmodules. Further, from the implementation side, we describe how Condense can be\nintegrated into the 3rd Generation Partnership Project (3GPP) Machine Type\nCommunications (MTC) architecture, as well as the prospects of making it a\npractically viable technology in a short time frame, relying on Network\nFunction Virtualization (NFV) and Software Defined Networking (SDN). Finally,\nfrom the theoretical side, we survey the relevant literature on computing\n\"atomic\" functions in both analog and digital domains, as well as on function\ndecomposition over networks, highlighting challenges, insights, and future\ndirections for exploiting these techniques within practical 3GPP MTC\narchitecture. \n\n"}
{"id": "1609.03498", "contents": "Title: LTE in Unlicensed Bands is neither Friend nor Foe to Wi-Fi Abstract: Proponents of deploying LTE in the 5 GHz band for providing additional\ncellular network capacity have claimed that LTE would be a better neighbour to\nWi-Fi in the unlicensed band, than Wi-Fi is to itself. On the other side of the\ndebate, the Wi-Fi community has objected that LTE would be highly detrimental\nto Wi-Fi network performance. However, there is a lack of transparent and\nsystematic engineering evidence supporting the contradicting claims of the two\ncamps, which is essential for ascertaining whether regulatory intervention is\nin fact required to protect the Wi-Fi incumbent from the new LTE entrant. To\nthis end, we present a comprehensive coexistence study of Wi-Fi and\nLTE-in-unlicensed, surveying a large parameter space of coexistence mechanisms\nand a range of representative network densities and deployment scenarios. Our\nresults show that, typically, harmonious coexistence between Wi-Fi and LTE is\nensured by the large number of 5 GHz channels. For the worst-case scenario of\nforced co-channel operation, LTE is sometimes a better neighbour to Wi-Fi -\nwhen effective node density is low - but sometimes worse - when density is\nhigh. We find that distributed interference coordination is only necessary to\nprevent a \"tragedy of the commons\" in regimes where interference is very\nlikely. We also show that in practice it does not make a difference to the\nincumbent what kind of coexistence mechanism is added to LTE-in-unlicensed, as\nlong as one is in place. We therefore conclude that LTE is neither friend nor\nfoe to Wi-Fi in the unlicensed bands in general. We submit that the systematic\nengineering analysis exemplified by our case study is a best-practice approach\nfor supporting evidence-based rulemaking by the regulator. \n\n"}
{"id": "1609.05384", "contents": "Title: Spatiotemporal Stochastic Modeling of IoT Enabled Cellular Networks:\n  Scalability and Stability Analysis Abstract: The Internet of Things (IoT) is large-scale by nature, which is manifested by\nthe massive number of connected devices as well as their vast spatial\nexistence. Cellular networks, which provide ubiquitous, reliable, and efficient\nwireless access, are natural candidates to provide the first-mile access for\nthe data tsunami to be generated by the IoT. However, cellular networks may\nhave scalability problems to provide uplink connectivity to massive numbers of\nconnected things. To characterize the scalability of cellular uplink in the\ncontext of IoT networks, this paper develops a traffic-aware spatiotemporal\nmathematical model for IoT devices supported by cellular uplink connectivity.\nThe developed model is based on stochastic geometry and queueing theory to\naccount for the traffic requirement per IoT device, the different transmission\nstrategies, and the mutual interference between the IoT devices. To this end,\nthe developed model is utilized to characterize the extent to which cellular\nnetworks can accommodate IoT traffic as well as to assess and compare three\ndifferent transmission strategies that incorporate a combination of\ntransmission persistency, backoff, and power-ramping. The analysis and the\nresults clearly illustrate the scalability problem imposed by IoT on cellular\nnetwork and offer insights into effective scenarios for each transmission\nstrategy. \n\n"}
{"id": "1610.02680", "contents": "Title: Minimax Optimality of Shiryaev-Roberts Procedure for Quickest Drift\n  Change Detection of a Brownian motion Abstract: The problem of detecting a change in the drift of a Brownian motion is\nconsidered. The change point is assumed to have a modified exponential prior\ndistribution with unknown parameters. A worst-case analysis with respect to\nthese parameters is adopted leading to a min-max problem formulation.\nAnalytical and numerical justifications are provided towards establishing that\nthe Shiryaev-Roberts procedure with a specially designed starting point is\nexactly optimal for the proposed mathematical setup. \n\n"}
{"id": "1610.04924", "contents": "Title: An interleaver design for polar codes over slow fading channels Abstract: We consider the problem of using polar codes over slow fading wireless\nchannels. For design, we focus on a parallel slow fading channel with 2 blocks,\nand polar codes with rate <= 1/2. Motivated by Arikan's systematic polar code\nconstruction, we propose an interleaver design for a general polar code. The\ninterleaver comprises of using the bit reversal of the order of polarized bit\nchannels. This interleaver is called a diversity interleaver. In addition to\nthe diversity interleaver, a diversity polar code is proposed to further\nincrease the diversity gain.\n  The proposed designs are evaluated via link simulations for AWGN and fading\nchannels. The simulation results show a performance close to the outage\nprobability (within 2 dB) and significant gains over using a random\ninterleaver. \n\n"}
{"id": "1610.05961", "contents": "Title: Proximity-Aware Balanced Allocations in Cache Networks Abstract: We consider load balancing in a network of caching servers delivering\ncontents to end users. Randomized load balancing via the so-called power of two\nchoices is a well-known approach in parallel and distributed systems that\nreduces network imbalance. In this paper, we propose a randomized load\nbalancing scheme which simultaneously considers cache size limitation and\nproximity in the server redirection process.\n  Since the memory limitation and the proximity constraint cause correlation in\nthe server selection process, we may not benefit from the power of two choices\nin general. However, we prove that in certain regimes, in terms of memory\nlimitation and proximity constraint, our scheme results in the maximum load of\norder $\\Theta(\\log\\log n)$ (here $n$ is the number of servers and requests),\nand at the same time, leads to a low communication cost. This is an exponential\nimprovement in the maximum load compared to the scheme which assigns each\nrequest to the nearest available replica. Finally, we investigate our scheme\nperformance by extensive simulations. \n\n"}
{"id": "1610.06050", "contents": "Title: A 9.52 dB NCG FEC scheme and 164 bits/cycle low-complexity product\n  decoder architecture Abstract: Powerful Forward Error Correction (FEC) schemes are used in optical\ncommunications to achieve bit-error rates below $10^{-15}$. These FECs follow\none of two approaches: concatenation of simpler hard-decision codes or usage of\ninherently powerful soft-decision codes. The first approach yields lower Net\nCoding Gains (NCGs), but can usually work at higher code rates and have lower\ncomplexity decoders. In this work, we propose a novel FEC scheme based on a\nproduct code and a post-processing technique. It can achieve an NCG of 9.52~dB\nat a BER of $10^{-15}$ and 9.96~dB at a BER of $10^{-18}$, an error-correction\nperformance that sits between that of current hard-decision and soft-decision\nFECs. A decoder architecture is designed, tested on FPGA and synthesized in 65\nnm CMOS technology: its 164 bits/cycle worst-case information throughput can\nreach 100 Gb/s at the achieved frequency of 609~MHz. Its complexity is shown to\nbe lower than that of hard-decision decoders in literature, and an order of\nmagnitude lower than the estimated complexity of soft-decision decoders. \n\n"}
{"id": "1610.06995", "contents": "Title: Modeling and Analysis of Uplink Non-Orthogonal Multiple Access (NOMA) in\n  Large-Scale Cellular Networks Using Poisson Cluster Processes Abstract: Non-orthogonal multiple access (NOMA) serves multiple users by superposing\ntheir distinct message signals. The desired message signal is decoded at the\nreceiver by applying successive interference cancellation (SIC). Using the\ntheory of Poisson cluster process (PCP), we provide a framework to analyze\nmulti-cell uplink NOMA systems. Specifically, we characterize the rate coverage\nprobability of a NOMA user who is at rank $m$ (in terms of the distance from\nits serving BS) among all users in a cell and the mean rate coverage\nprobability of all users in a cell. Since the signal-to-interference-plus-noise\nratio (SINR) of $m$-th user relies on efficient SIC, we consider three\nscenarios, i.e., perfect SIC (in which the signals of $m-1$ interferers who are\nstronger than $m$-th user are decoded successfully), imperfect SIC (in which\nthe signals of of $m-1$ interferers who are stronger than $m$-th user may or\nmay not be decoded successfully), and imperfect worst case SIC (in which the\ndecoding of the signal of $m$-th user is always unsuccessful whenever the\ndecoding of its relative $m-1$ stronger users is unsuccessful). The derived\nexpressions are customized to capture the performance of a user at rank $m$ in\nan equivalent orthogonal multiple access (OMA) system. Finally, numerical\nresults are presented to validate the derived expressions. \n\n"}
{"id": "1610.07497", "contents": "Title: Analyzing the structure of multidimensional compressed sensing problems\n  through coherence Abstract: Recently it has been established that asymptotic incoherence can be used to\nfacilitate subsampling, in order to optimize reconstruction quality, in a\nvariety of continuous compressed sensing problems, and the coherence structure\nof certain one-dimensional Fourier sampling problems was determined. This paper\nextends the analysis of asymptotic incoherence to cover multidimensional\nreconstruction problems. It is shown that Fourier sampling and separable\nwavelet sparsity in any dimension can yield the same optimal asymptotic\nincoherence as in one dimensional case. Moreover in two dimensions the\ncoherence structure is compatible with many standard two dimensional sampling\nschemes that are currently in use. However, in higher dimensional problems with\npoor wavelet smoothness we demonstrate that there are considerable restrictions\non how one can subsample from the Fourier basis with optimal incoherence. This\ncan be remedied by using a sufficiently smooth generating wavelet. It is also\nshown that using tensor bases will always provide suboptimal decay marred by\nproblems associated with dimensionality. The impact of asymptotic incoherence\non the ability to subsample is demonstrated with some simple two dimensional\nnumerical experiments. \n\n"}
{"id": "1610.07736", "contents": "Title: Construction of MDS self-dual codes from orthogonal matrices Abstract: In this paper, we give algorithms and methods of construction of self-dual\ncodes over finite fields using orthogonal matrices. Randomization in the\northogonal group, and code extension are the main tools. Some optimal, almost\nMDS, and MDS self-dual codes over both small and large prime fields are\nconstructed. \n\n"}
{"id": "1610.07740", "contents": "Title: MIMO Multiway Distributed-Relay Channel with Full Data Exchange: An\n  Achievable Rate Perspective Abstract: We consider efficient communications over the multiple-input multiple-output\n(MIMO) multiway distributed relay channel (MDRC) with full data exchange, where\neach user, equipped with multiple antennas, broadcasts its message to all the\nother users via the help of a number of distributive relays. We propose a\nphysical-layer network coding (PNC) based scheme involving linear precoding for\nchannel alignment nested lattice coding for PNC, and lattice-based precoding\nfor interference mitigation, We show that, with the proposed scheme,\ndistributed relaying achieves the same sum-rate as cooperative relaying in the\nhigh SNR regime. We also show that the proposed scheme achieve the asymptotic\nsum capacity of the MIMO MDRC within a constant gap at high SNR. Numerical\nresults demonstrate that the proposed scheme considerably outperforms the\nexisting schemes including decode-and-forward and amplify-and-forward. \n\n"}
{"id": "1610.08026", "contents": "Title: Improved Upper Bounds on Systematic-Length for Linear Minimum Storage\n  Regenerating Codes Abstract: In this paper, we revisit the problem of finding the longest\nsystematic-length $k$ for a linear minimum storage regenerating (MSR) code with\noptimal repair of only systematic part, for a given per-node storage capacity\n$l$ and an arbitrary number of parity nodes $r$. We study the problem by\nfollowing a geometric analysis of linear subspaces and operators. First, a\nsimple quadratic bound is given, which implies that $k=r+2$ is the largest\nnumber of systematic nodes in the \\emph{scalar} scenario. Second, an\n$r$-based-log bound is derived, which is superior to the upper bound on\nlog-base $2$ in the prior work. Finally, an explicit upper bound depending on\nthe value of $\\frac{r^2}{l}$ is introduced, which further extends the\ncorresponding result in the literature. \n\n"}
{"id": "1610.08223", "contents": "Title: A New Piggybacking Design for Systematic MDS Storage Codes Abstract: Distributed storage codes have important applications in the design of modern\nstorage systems. In a distributed storage system, every storage node has a\nprobability to fail and once an individual storage node fails, it must be\nreconstructed using data stored in the surviving nodes. Computation load and\nnetwork bandwidth are two important issues we need to concern when repairing a\nfailed node. The traditional maximal distance separable (MDS) storage codes\nhave low repair complexity but high repair bandwidth. On the contrary, minimal\nstorage regenerating (MSR) codes have low repair bandwidth but high repair\ncomplexity. Fortunately, the newly introduced piggyback codes combine the\nadvantages of both ones.\n  In this paper, by introducing a novel piggybacking design framework for\nsystematic MDS codes, we construct a storage code whose average repair\nbandwidth rate, i.e., the ratio of average repair bandwidth and the amount of\nthe original data, can be as low as $\\frac{\\sqrt{2r-1}}{r}$, which\nsignificantly improves the ratio $\\frac{r-1}{2r-1}$ of the previous result. In\nthe meanwhile, every failed systematic node of the new code can be\nreconstructed quickly using the decoding algorithm of an MDS code, only with\nsome additional additions over the underlying finite field. This is very fast\ncompared with the complex matrix multiplications needed in the repair of a\nfailed node of an MSR code. \n\n"}
{"id": "1611.00297", "contents": "Title: Generalized Entropy Concentration for Counts Abstract: The phenomenon of entropy concentration provides strong support for the\nmaximum entropy method, MaxEnt, for inferring a probability vector from\ninformation in the form of constraints. Here we extend this phenomenon, in a\ndiscrete setting, to non-negative integral vectors not necessarily summing to\n1. We show that linear constraints that simply bound the allowable sums suffice\nfor concentration to occur even in this setting. This requires a new,\n`generalized' entropy measure in which the sum of the vector plays a role. We\nmeasure the concentration in terms of deviation from the maximum generalized\nentropy value, or in terms of the distance from the maximum generalized entropy\nvector. We provide non-asymptotic bounds on the concentration in terms of\nvarious parameters, including a tolerance on the constraints which ensures that\nthey are always satisfied by an integral vector. Generalized entropy\nmaximization is not only compatible with ordinary MaxEnt, but can also be\nconsidered an extension of it, as it allows us to address problems that cannot\nbe formulated as MaxEnt problems. \n\n"}
{"id": "1611.01042", "contents": "Title: Multi-Way Massive MIMO with Maximum-Ratio Processing and Imperfect CSI Abstract: This paper considers a multi-way massive multiple-input multiple-output\nrelaying system, where single-antenna users exchange their information-bearing\nsignals with the help of one relay station equipped with unconventionally many\nantennas. The relay first estimates the channels to all users through the pilot\nsignals transmitted from them. Then, the relay uses maximum-ratio processing\n(i.e. maximum-ratio combining in the multiple-access phase and maximum-ratio\ntransmission in the broadcast phase) to process the signals. A rigorous\nclosed-form expression for the spectral efficiency is derived. The effects of\nthe channel estimation error, the channel estimation overhead, the length of\nthe training duration, and the randomness of the user locations are analyzed.\nWe show that by deploying massive antenna arrays at the relay and simple\nmaximum-ratio processing, we can serve many users in the same time-frequency\nresource, while maintaining a given quality-of-service for each user. \n\n"}
{"id": "1611.01704", "contents": "Title: End-to-end Optimized Image Compression Abstract: We describe an image compression method, consisting of a nonlinear analysis\ntransformation, a uniform quantizer, and a nonlinear synthesis transformation.\nThe transforms are constructed in three successive stages of convolutional\nlinear filters and nonlinear activation functions. Unlike most convolutional\nneural networks, the joint nonlinearity is chosen to implement a form of local\ngain control, inspired by those used to model biological neurons. Using a\nvariant of stochastic gradient descent, we jointly optimize the entire model\nfor rate-distortion performance over a database of training images, introducing\na continuous proxy for the discontinuous loss function arising from the\nquantizer. Under certain conditions, the relaxed loss function may be\ninterpreted as the log likelihood of a generative model, as implemented by a\nvariational autoencoder. Unlike these models, however, the compression model\nmust operate at any given point along the rate-distortion curve, as specified\nby a trade-off parameter. Across an independent set of test images, we find\nthat the optimized method generally exhibits better rate-distortion performance\nthan the standard JPEG and JPEG 2000 compression methods. More importantly, we\nobserve a dramatic improvement in visual quality for all images at all bit\nrates, which is supported by objective quality estimates using MS-SSIM. \n\n"}
{"id": "1611.02989", "contents": "Title: Bayesian data assimilation based on a family of outer measures Abstract: A flexible representation of uncertainty that remains within the standard\nframework of probabilistic measure theory is presented along with a study of\nits properties. This representation relies on a specific type of outer measure\nthat is based on the measure of a supremum, hence combining additive and highly\nsub-additive components. It is shown that this type of outer measure enables\nthe introduction of intuitive concepts such as pullback and general data\nassimilation operations. \n\n"}
{"id": "1611.06458", "contents": "Title: A Class of Two-Weight and Three-Weight Linear Codes and Their Duals Abstract: The objective of this paper is to construct a class of linear codes with two\nnonzero weights and three nonzero weights by using the general trace functions,\nwhich weight distributions has been determined. These linear codes contain some\noptimal codes, which meets certain bound on linear codes. The dual codes are\nalso studied and proved to be optimal or almost optimal. These codes may have\napplications in authentication codes, secret sharing schemes and strongly\nregular graphs. \n\n"}
{"id": "1611.06487", "contents": "Title: A Sequence Construction of Cyclic Codes over Finite Fields Abstract: Cyclic codes over finite fields are widely implemented in data storage\nsystems, communication systems, and consumer electronics, as they have very\nefficient encoding and decoding algorithms. They are also important in theory,\nas they are closely connected to several areas in mathematics. There are a few\nfundamental ways of constructing all cyclic codes over finite fields, including\nthe generator matrix approach, the generator polynomial approach, the\ngenerating idempotent approach, and the $q$-polynomial approach. Another one is\na sequence approach, which has been intensively investigated in the past\ndecade. The objective of this paper is to survey the progress in the past\ndecade in this direction. \n\n"}
{"id": "1611.06591", "contents": "Title: Coded Caching with Distributed Storage Abstract: Content delivery networks store information distributed across multiple\nservers, so as to balance the load and avoid unrecoverable losses in case of\nnode or disk failures. Coded caching has been shown to be a useful technique\nwhich can reduce peak traffic rates by pre-fetching popular content at the end\nusers and encoding transmissions so that different users can extract different\ninformation from the same packet. On one hand, distributed storage limits the\ncapability of combining content from different servers into a single message,\ncausing performance losses in coded caching schemes. But, on the other hand,\nthe inherent redundancy existing in distributed storage systems can be used to\nimprove the performance of those schemes through parallelism.\n  This paper designs a scheme combining distributed storage of the content in\nmultiple servers and an efficient coded caching algorithm for delivery to the\nusers. This scheme is shown to reduce the peak transmission rate below that of\nstate-of-the-art algorithms. \n\n"}
{"id": "1611.07216", "contents": "Title: What to Expect When You Are Expecting on the Grassmannian Abstract: Consider an incoming sequence of vectors, all belonging to an unknown\nsubspace $\\operatorname{S}$, and each with many missing entries. In order to\nestimate $\\operatorname{S}$, it is common to partition the data into blocks and\niteratively update the estimate of $\\operatorname{S}$ with each new incoming\nmeasurement block.\n  In this paper, we investigate a rather basic question: Is it possible to\nidentify $\\operatorname{S}$ by averaging the column span of the partially\nobserved incoming measurement blocks on the Grassmannian?\n  We show that in general the span of the incoming blocks is in fact a biased\nestimator of $\\operatorname{S}$ when data suffers from erasures, and we find an\nupper bound for this bias. We reach this conclusion by examining the defining\noptimization program for the Fr\\'{e}chet expectation on the Grassmannian, and\nwith the aid of a sharp perturbation bound and standard large deviation\nresults. \n\n"}
{"id": "1612.00410", "contents": "Title: Deep Variational Information Bottleneck Abstract: We present a variational approximation to the information bottleneck of\nTishby et al. (1999). This variational approach allows us to parameterize the\ninformation bottleneck model using a neural network and leverage the\nreparameterization trick for efficient training. We call this method \"Deep\nVariational Information Bottleneck\", or Deep VIB. We show that models trained\nwith the VIB objective outperform those that are trained with other forms of\nregularization, in terms of generalization performance and robustness to\nadversarial attack. \n\n"}
{"id": "1612.01133", "contents": "Title: Novel Delivery Schemes for Decentralized Coded Caching in the Finite\n  File Size Regime Abstract: This paper analyzes the achievable tradeoff between cache~size and\ndownload~rate in decentralized caching systems with the uncoded cache placement\noriginally proposed by Maddah-Ali and Niesen. It proposes two novel delivery\nschemes that take advantage of the multicasting opportunities that arise when a\nfile is demanded by multiple users. These delivery schemes are extensions of\nknown ones to the regime where the file size is finite. Numerical evaluations\nfor the case of file uniform popularity show that the proposed schemes\noutperform previous ones for all value of the cache size. \n\n"}
{"id": "1612.02574", "contents": "Title: Optimal Pilot and Payload Power Control in Single-Cell Massive MIMO\n  Systems Abstract: This paper considers the jointly optimal pilot and data power allocation in\nsingle-cell uplink massive multiple-input-multiple-output (MIMO) systems. Using\nthe spectral efficiency (SE) as performance metric and setting a total energy\nbudget per coherence interval, the power control is formulated as optimization\nproblems for two different objective functions: the weighted minimum SE among\nthe users and the weighted sum SE. A closed form solution for the optimal\nlength of the pilot sequence is derived. The optimal power control policy for\nthe former problem is found by solving a simple equation with a single\nvariable. Utilizing the special structure arising from imperfect channel\nestimation, a convex reformulation is found to solve the latter problem to\nglobal optimality in polynomial time. The gain of the optimal joint power\ncontrol is theoretically justified, and is proved to be large in the low SNR\nregime. Simulation results also show the advantage of optimizing the power\ncontrol over both pilot and data power, as compared to the cases of using full\npower and of only optimizing the data powers as done in previous work. \n\n"}
{"id": "1612.03164", "contents": "Title: Square Hellinger Subadditivity for Bayesian Networks and its\n  Applications to Identity Testing Abstract: We show that the square Hellinger distance between two Bayesian networks on\nthe same directed graph, $G$, is subadditive with respect to the neighborhoods\nof $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two\nBayesian networks on the same DAG, our inequality states that the square\nHellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the\nsum, $\\sum_v H^2(P_{\\{v\\} \\cup \\Pi_v}, Q_{\\{v\\} \\cup \\Pi_v})$, of the square\nHellinger distances between the marginals of $P$ and $Q$ on every node $v$ and\nits parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the\nconditionals but the marginals of $P$ and $Q$. We derive a similar inequality\nfor more general Markov Random Fields.\n  As an application of our inequality, we show that distinguishing whether two\nBayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy\n$P=Q$ vs $d_{\\rm TV}(P,Q)>\\epsilon$ can be performed from\n$\\tilde{O}(|\\Sigma|^{3/4(d+1)} \\cdot n/\\epsilon^2)$ samples, where $d$ is the\nmaximum in-degree of the DAG and $\\Sigma$ the domain of each variable of the\nBayesian networks. If $P$ and $Q$ are defined on potentially different and\npotentially unknown trees, the sample complexity becomes\n$\\tilde{O}(|\\Sigma|^{4.5} n/\\epsilon^2)$, whose dependence on $n, \\epsilon$ is\noptimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product\ndistributions over $\\{0,1\\}^n$ and $Q$ is known, the sample complexity becomes\n$O(\\sqrt{n}/\\epsilon^2)$, which is optimal up to constant factors. \n\n"}
{"id": "1612.04065", "contents": "Title: Green OFDMA Resource Allocation in Cache-Enabled CRAN Abstract: Cloud radio access network (CRAN), in which remote radio heads (RRHs) are\ndeployed to serve users in a target area, and connected to a central processor\n(CP) via limited-capacity links termed the fronthaul, is a promising candidate\nfor the next-generation wireless communication systems. Due to the\ncontent-centric nature of future wireless communications, it is desirable to\ncache popular contents beforehand at the RRHs, to reduce the burden on the\nfronthaul and achieve energy saving through cooperative transmission. This\nmotivates our study in this paper on the energy efficient transmission in an\northogonal frequency division multiple access (OFDMA)-based CRAN with multiple\nRRHs and users, where the RRHs can prefetch popular contents. We consider a\njoint optimization of the user-SC assignment, RRH selection and transmit power\nallocation over all the SCs to minimize the total transmit power of the RRHs,\nsubject to the RRHs' individual fronthaul capacity constraints and the users'\nminimum rate constraints, while taking into account the caching status at the\nRRHs. Although the problem is non-convex, we propose a Lagrange duality based\nsolution, which can be efficiently computed with good accuracy. We compare the\nminimum transmit power required by the proposed algorithm with different\ncaching strategies against the case without caching by simulations, which show\nthe significant energy saving with caching. \n\n"}
{"id": "1612.06339", "contents": "Title: Randomized Learning of the Second-Moment Matrix of a Smooth Function Abstract: Consider an open set $\\mathbb{D}\\subseteq\\mathbb{R}^n$, equipped with a\nprobability measure $\\mu$. An important characteristic of a smooth function\n$f:\\mathbb{D}\\rightarrow\\mathbb{R}$ is its \\emph{second-moment matrix}\n$\\Sigma_{\\mu}:=\\int \\nabla f(x) \\nabla f(x)^* \\mu(dx) \\in\\mathbb{R}^{n\\times\nn}$, where $\\nabla f(x)\\in\\mathbb{R}^n$ is the gradient of $f(\\cdot)$ at\n$x\\in\\mathbb{D}$ and $*$ stands for transpose. For instance, the span of the\nleading $r$ eigenvectors of $\\Sigma_{\\mu}$ forms an \\emph{active subspace} of\n$f(\\cdot)$, which contains the directions along which $f(\\cdot)$ changes the\nmost and is of particular interest in \\emph{ridge approximation}. In this work,\nwe propose a simple algorithm for estimating $\\Sigma_{\\mu}$ from random point\nevaluations of $f(\\cdot)$ \\emph{without} imposing any structural assumptions on\n$\\Sigma_{\\mu}$. Theoretical guarantees for this algorithm are established with\nthe aid of the same technical tools that have proved valuable in the context of\ncovariance matrix estimation from partial measurements. \n\n"}
{"id": "1612.07289", "contents": "Title: Full-Duplex MIMO Small-Cell Networks with Interference Cancellation Abstract: Full-duplex (FD) technology is envisaged as a key component for future mobile\nbroadband networks due to its ability to boost the spectral efficiency. FD\nsystems can transmit and receive simultaneously on the same frequency at the\nexpense of residual self-interference (SI) and additional interference to the\nnetwork compared with half-duplex (HD) transmission. This paper analyzes the\nperformance of wireless networks with FD multi-antenna base stations (BSs) and\nHD user equipments (UEs) using stochastic geometry. Our analytical results\nquantify the success probability and the achievable spectral efficiency and\nindicate the amount of SI cancellation needed for beneficial FD operation. The\nadvantages of multi-antenna BSs/UEs are shown and the performance gains\nachieved by balancing desired signal power increase and interference\ncancellation are derived. The proposed framework aims at shedding light on the\nsystem-level gains of FD mode with respect to HD mode in terms of network\nthroughput, and provides design guidelines for the practical implementation of\nFD technology in large small-cell networks. \n\n"}
{"id": "1612.07902", "contents": "Title: LSE Precoders for Massive MIMO with Signal Constraints: Fundamental\n  Limits Abstract: This paper proposes the nonlinear Least Square Error (LSE) precoders for\nmultiuser MIMO broadcast channels. The output signals of LSE Precoders are\nlimited to be chosen from a predefined set which let these precoders address\nseveral constraints such as peak power limitation, constant envelope\ntransmission and discrete constellations. We study the large-system performance\nof these precoders via the replica method from statistical physics, and derive\na closed-form expression for the asymptotic distortion. Our results demonstrate\nthat an LSE precoder with the output peak-to-average power ratio of $3~{\\rm\ndB}$ can track the performance of the Regularized Zero Forcing (RZF) precoder\nclosely. As the peak-to-average power ratio reduces to one, the constant\nenvelope precoder is recovered. The investigations depict that the performance\nof the RZF precoder is achieved by the constant envelope precoder with $20\\%$\nof more transmit antennas. For $M$-PSK constellations, our analysis gives a\nlower-bound on the asymptotic distortion which is tight for moderate\nantenna-to-user ratios and deviates as the ratio grows. We improve this bound\nby deriving the replica solution under one-step of replica symmetry breaking.\nOur numerical investigations for this case show that the bound is tight for\nantenna-to-user ratios less than $5$. \n\n"}
{"id": "1612.08785", "contents": "Title: Non-Linear Programming: Maximize SNR for Designing Spreading Sequence -\n  Part II: Conditions for Optimal Spreading Sequences Abstract: Signal to Noise Ratio (SNR) is an important index for wireless\ncommunications. In CDMA systems, spreading sequences are utilized. This series\nof papers show the method to derive spreading sequences as the solutions of\nnon-linear programming: maximize SNR. In this paper, we derive the optimization\nproblems with the expression SNR derived in Part I and the necessary conditions\nfor the global solutions. We numerically solve the problems and evaluate the\nsolutions with two factors, mean-square correlations and maximum mean-square\ncorrelations. \n\n"}
{"id": "1612.09169", "contents": "Title: Weighted information and entropy rates Abstract: The weighted entropy $H^{\\rm w}_\\phi (X)=H^{\\rm w}_\\phi (f)$ of a random\nvariable $X$ with values $x$ and a probability-mass/density function $f$ is\ndefined as the mean value ${\\mathbb E} I^{\\rm w}_\\phi(X)$ of the weighted\ninformation $I^{\\rm w}_\\phi (x)=-\\phi (x)\\log\\,f(x)$. Here $x\\mapsto\\phi\n(x)\\in{\\mathbb R}$ is a given weight function (WF) indicating a 'value' of\noutcome $x$. For an $n$-component random vector\n${\\mathbf{X}}_0^{n-1}=(X_0,\\ldots ,X_{n-1})$ produced by a random process\n${\\mathbf{X}}=(X_i,i\\in{\\mathbb Z})$, the weighted information $I^{\\rm\nw}_{\\phi_n}({\\mathbf x}_0^{n-1})$ and weighted entropy $H^{\\rm\nw}_{\\phi_n}({\\mathbf{X}}_0^{n-1})$ are defined similarly, with an WF\n$\\phi_n({\\mathbf x}_0^{n-1})$. Two types of WFs $\\phi_n$ are considered, based\non additive and a multiplicative forms ($\\phi_n({\\mathbf\nx}_0^{n-1})=\\sum\\limits_{i=0}^{n-1}{\\varphi} (x_i)$ and $\\phi_n({\\mathbf\nx}_0^{n-1})=\\prod\\limits_{i=0}^{n-1}{\\varphi} (x_i)$, respectively). The focus\nis upon ${\\it rates}$ of the weighted entropy and information, regarded as\nparameters related to ${\\mathbf{X}}$. We show that, in the context of\nergodicity, a natural scale for an asymptotically additive/multiplicative WF is\n$\\frac{1}{n^2}H^{\\rm w}_{\\phi_n}({\\mathbf{X}}_0^{n-1})$ and\n$\\frac{1}{n}\\log\\;H^{\\rm w}_{\\phi_n}({\\mathbf{X}}_0^{n-1})$, respectively. This\ngives rise to ${\\it primary}$ ${\\it rates}$. The next-order terms can also be\nidentified, leading to ${\\it secondary}$ ${\\it rates}$. We also consider\nemerging generalisations of the Shannon-McMillan-Breiman theorem. \n\n"}
{"id": "1701.01212", "contents": "Title: Downlink Coverage Analysis for a Finite 3D Wireless Network of Unmanned\n  Aerial Vehicles Abstract: In this paper, we consider a finite network of unmanned aerial vehicles\n(UAVs) serving a given region. Modeling this network as a uniform binomial\npoint process (BPP), we derive the downlink coverage probability of a reference\nreceiver located at an arbitrary position on the ground assuming Nakagami-$m$\nfading for all wireless links. The reference receiver is assumed to connect to\nits closest transmitting node as is usually the case in cellular systems. After\nderiving the distribution of distances from the reference receiver to the\nserving and interfering nodes, we derive an exact expression for downlink\ncoverage probability in terms of the derivative of Laplace transform of\ninterference power distribution. In the downlink of this system, it is not\nunusual to encounter scenarios in which the line-of-sight (LOS) component is\nsignificantly stronger than the reflected multipath components. To emulate such\nscenarios, we also derive the coverage probability in the absence of fading\nfrom the results of Nakagami-$m$ fading by taking the limit $m \\to \\infty$.\nUsing asymptotic expansion of incomplete gamma function, we concretely show\nthat this limit reduces to a redundant condition. Consequently, we derive an\naccurate coverage probability approximation for this case using dominant\ninterferer-based approach in which the effect of dominant interferer is exactly\ncaptured and the residual interference from other interferers is carefully\napproximated. We then derive the bounds of the approximate coverage probability\nusing Berry-Esseen theorem. Our analyses reveal several useful trends in\ncoverage probability as a function of height of the transmitting nodes and the\nlocation of reference receiver on the ground. \n\n"}
{"id": "1701.01981", "contents": "Title: Guessing Attacks on Distributed-Storage Systems Abstract: The secrecy of a distributed-storage system for passwords is studied. The\nencoder, Alice, observes a length-n password and describes it using two hints,\nwhich she stores in different locations. The legitimate receiver, Bob, observes\nboth hints. In one scenario the requirement is that the expected number of\nguesses it takes Bob to guess the password approach one as n tends to infinity,\nand in the other that the expected size of the shortest list that Bob must form\nto guarantee that it contain the password approach one. The eavesdropper, Eve,\nsees only one of the hints. Assuming that Alice cannot control which hints Eve\nobserves, the largest normalized (by n) exponent that can be guaranteed for the\nexpected number of guesses it takes Eve to guess the password is characterized\nfor each scenario. Key to the proof are new results on Arikan's guessing and\nBunte and Lapidoth's task-encoding problem; in particular, the paper\nestablishes a close relation between the two problems. A rate-distortion\nversion of the model is also discussed, as is a generalization that allows for\nAlice to produce {\\delta} (not necessarily two) hints, for Bob to observe {\\nu}\n(not necessarily two) of the hints, and for Eve to observe {\\eta} (not\nnecessarily one) of the hints. The generalized model is robust against {\\delta}\n- {\\nu} disk failures. \n\n"}
{"id": "1701.02345", "contents": "Title: Sliding-Window Superposition Coding:Two-User Interference Channels Abstract: A low-complexity coding scheme is developed to achieve the rate region of\nmaximum likelihood decoding for interference channels. As in the classical\nrate-splitting multiple access scheme by Grant, Rimoldi, Urbanke, and Whiting,\nthe proposed coding scheme uses superposition of multiple codewords with\nsuccessive cancellation decoding, which can be implemented using standard\npoint-to-point encoders and decoders. Unlike rate-splitting multiple access,\nwhich is not rate-optimal for multiple receivers, the proposed coding scheme\ntransmits codewords over multiple blocks in a staggered manner and recovers\nthem successively over sliding decoding windows, achieving the single-stream\noptimal rate region as well as the more general Han--Kobayashi inner bound for\nthe two-user interference channel. The feasibility of this scheme in practice\nis verified by implementing it using commercial channel codes over the two-user\nGaussian interference channel. \n\n"}
{"id": "1701.02979", "contents": "Title: Multi-Antenna Coded Caching Abstract: In this paper we consider a single-cell downlink scenario where a\nmultiple-antenna base station delivers contents to multiple cache-enabled user\nterminals. Based on the multicasting opportunities provided by the so-called\nCoded Caching technique, we investigate three delivery approaches. Our baseline\nscheme employs the coded caching technique on top of max-min fair multicasting.\nThe second one consists of a joint design of Zero-Forcing (ZF) and coded\ncaching, where the coded chunks are formed in the signal domain (complex\nfield). The third scheme is similar to the second one with the difference that\nthe coded chunks are formed in the data domain (finite field). We derive\nclosed-form rate expressions where our results suggest that the latter two\nschemes surpass the first one in terms of Degrees of Freedom (DoF). However, at\nthe intermediate SNR regime forming coded chunks in the signal domain results\nin power loss, and will deteriorate throughput of the second scheme. The main\nmessage of our paper is that the schemes performing well in terms of DoF may\nnot be directly appropriate for intermediate SNR regimes, and modified schemes\nshould be employed. \n\n"}
{"id": "1701.03023", "contents": "Title: On the Tradeoff Region of Secure Exact-Repair Regenerating Codes Abstract: We consider the $(n,k,d,\\ell)$ secure exact-repair regenerating code problem,\nwhich generalizes the $(n,k,d)$ exact-repair regenerating code problem with the\nadditional constraint that the stored file needs to be kept\ninformation-theoretically secure against an eavesdropper, who can access the\ndata transmitted to regenerate a total of $\\ell$ different failed nodes. For\nall known results on this problem, the achievable tradeoff regions between the\nnormalized storage capacity and repair bandwidth have a single corner point,\nachieved by a scheme proposed by Shah, Rashmi and Kumar (the SRK point). Since\nthe achievable tradeoff regions of the exact-repair regenerating code problem\nwithout any secrecy constraints are known to have multiple corner points in\ngeneral, these existing results suggest a phase-change-like behavior, i.e.,\nenforcing a secrecy constraint ($\\ell\\geq 1$) immediately reduces the tradeoff\nregion to one with a single corner point. In this work, we first show that when\nthe secrecy parameter $\\ell$ is sufficiently large, the SRK point is indeed the\nonly corner point of the tradeoff region. However, when $\\ell$ is small, we\nshow that the tradeoff region can in fact have multiple corner points. In\nparticular, we establish a precise characterization of the tradeoff region for\nthe $(7,6,6,1)$ problem, which has exactly two corner points. Thus, a smooth\ntransition, instead of a phase-change-type of transition, should be expected as\nthe secrecy constraint is gradually strengthened. \n\n"}
{"id": "1701.03135", "contents": "Title: Guaranteed recovery of quantum processes from few measurements Abstract: Quantum process tomography is the task of reconstructing unknown quantum\nchannels from measured data. In this work, we introduce compressed\nsensing-based methods that facilitate the reconstruction of quantum channels of\nlow Kraus rank. Our main contribution is the analysis of a natural measurement\nmodel for this task: We assume that data is obtained by sending pure states\ninto the channel and measuring expectation values on the output. Neither\nancillary systems nor coherent operations across multiple channel uses are\nrequired. Most previous results on compressed process reconstruction reduce the\nproblem to quantum state tomography on the channel's Choi matrix. While this\nansatz yields recovery guarantees from an essentially minimal number of\nmeasurements, physical implementations of such schemes would typically involve\nancillary systems. A priori, it is unclear whether a measurement model tailored\ndirectly to quantum process tomography might require more measurements. We\nestablish that this is not the case. Technically, we prove recovery guarantees\nfor three different reconstruction algorithms. The reconstructions are based on\na trace, diamond, and $\\ell_2$-norm minimization, respectively. Our recovery\nguarantees are uniform in the sense that with one random choice of measurement\nsettings all quantum channels can be recovered equally well. Moreover,\nstability against arbitrary measurement noise and robustness against violations\nof the low-rank assumption is guaranteed. Numerical studies demonstrate the\nfeasibility of the approach. \n\n"}
{"id": "1701.03195", "contents": "Title: Moderate Deviation Analysis for Classical-Quantum Channels and Quantum\n  Hypothesis Testing Abstract: In this work, we study the tradeoffs between the error probabilities of\nclassical-quantum channels and the blocklength $n$ when the transmission rates\napproach the channel capacity at a rate slower than $1/\\sqrt{n}$, a research\ntopic known as moderate deviation analysis. We show that the optimal error\nprobability vanishes under this rate convergence. Our main technical\ncontributions are a tight quantum sphere-packing bound, obtained via Chaganty\nand Sethuraman's concentration inequality in strong large deviation theory, and\nasymptotic expansions of error-exponent functions. Moderate deviation analysis\nfor quantum hypothesis testing is also established. The converse directly\nfollows from our channel coding result, while the achievability relies on a\nmartingale inequality. \n\n"}
{"id": "1701.03247", "contents": "Title: Scalable Spectrum Allocation and User Association in Networks with Many\n  Small Cells Abstract: A scalable framework is developed to allocate radio resources across a large\nnumber of densely deployed small cells with given traffic statistics on a slow\ntimescale. Joint user association and spectrum allocation is first formulated\nas a convex optimization problem by dividing the spectrum among all possible\ntransmission patterns of active access points (APs). To improve scalability\nwith the number of APs, the problem is reformulated using local patterns of\ninterfering APs. To maintain global consistency among local patterns,\ninter-cluster interaction is characterized as hyper-edges in a hyper-graph with\nnodes corresponding to neighborhoods of APs. A scalable solution is obtained by\niteratively solving a convex optimization problem for bandwidth allocation with\nreduced complexity and constructing a global spectrum allocation using\nhyper-graph coloring. Numerical results demonstrate the proposed solution for a\nnetwork with 100 APs and several hundred user equipments. For a given quality\nof service (QoS), the proposed scheme can increase the network capacity several\nfold compared to assigning each user to the strongest AP with full-spectrum\nreuse. \n\n"}
{"id": "1701.03397", "contents": "Title: Polar Codes for Arbitrary Classical-Quantum Channels and Arbitrary\n  cq-MACs Abstract: We prove polarization theorems for arbitrary classical-quantum (cq) channels.\nThe input alphabet is endowed with an arbitrary Abelian group operation and an\nAr{\\i}kan-style transformation is applied using this operation. It is shown\nthat as the number of polarization steps becomes large, the synthetic\ncq-channels polarize to deterministic homomorphism channels which project their\ninput to a quotient group of the input alphabet. This result is used to\nconstruct polar codes for arbitrary cq-channels and arbitrary classical-quantum\nmultiple access channels (cq-MAC). The encoder can be implemented in $O(N\\log\nN)$ operations, where $N$ is the blocklength of the code. A quantum successive\ncancellation decoder for the constructed codes is proposed. It is shown that\nthe probability of error of this decoder decays faster than $2^{-N^{\\beta}}$\nfor any $\\beta<\\frac{1}{2}$. \n\n"}
{"id": "1701.04466", "contents": "Title: Continuity of Channel Parameters and Operations under Various DMC\n  Topologies Abstract: We study the continuity of many channel parameters and operations under\nvarious topologies on the space of equivalent discrete memoryless channels\n(DMC). We show that mutual information, channel capacity, Bhattacharyya\nparameter, probability of error of a fixed code, and optimal probability of\nerror for a given code rate and blocklength, are continuous under various DMC\ntopologies. We also show that channel operations such as sums, products,\ninterpolations, and Ar{\\i}kan-style transformations are continuous. \n\n"}
{"id": "1701.04901", "contents": "Title: Multi-channel Sensing And Resource Allocation in Energy Constrained\n  Cognitive Radio Networks Abstract: We consider a cognitive radio network in a multi-channel licensed\nenvironment. Secondary user transmits in a channel if the channel is sensed to\nbe vacant. This results in a tradeoff between sensing time and transmission\ntime. When secondary users are energy constrained, energy available for\ntransmission is less if more energy is used in sensing. This gives rise to an\nenergy tradeoff. For multiple primary channels, secondary users must decide\nappropriate sensing time and transmission power in each channel to maximize\naverage aggregate-bit throughput in each frame duration while ensuring\nquality-of-service of primary users. Considering time and energy as limited\nresources, we formulate this problem as a resource allocation problem.\nInitially a single secondary user scenario is considered and solution is\nobtained using decomposition and alternating optimization techniques. Later we\nextend the analysis for the case of multiple secondary users. Simulation\nresults are presented to study effect of channel occupancy, fading and energy\navailability on performance of proposed method. \n\n"}
{"id": "1701.05943", "contents": "Title: Structure of optimal strategies for remote estimation over\n  Gilbert-Elliott channel with feedback Abstract: We investigate remote estimation over a Gilbert-Elliot channel with feedback.\nWe assume that the channel state is observed by the receiver and fed back to\nthe transmitter with one unit delay. In addition, the transmitter gets ACK/NACK\nfeedback for successful/unsuccessful transmission. Using ideas from team\ntheory, we establish the structure of optimal transmission and estimation\nstrategies and identify a dynamic program to determine optimal strategies with\nthat structure. We then consider first-order autoregressive sources where the\nnoise process has unimodal and symmetric distribution. Using ideas from\nmajorization theory, we show that the optimal transmission strategy has a\nthreshold structure and the optimal estimation strategy is Kalman-like. \n\n"}
{"id": "1701.06304", "contents": "Title: A New Combination of Message Passing Techniques for Receiver Design in\n  MIMO-OFDM Systems Abstract: In this paper, we propose a new combined message passing algorithm which\nallows belief propagation (BP) and mean filed (MF) applied on a same factor\nnode, so that MF can be applied to hard constraint factors. Based on the\nproposed message passing algorithm, a iterative receiver is designed for\nMIMO-OFDM systems. Both BP and MF are exploited to deal with the hard\nconstraint factor nodes involving the multiplication of channel coefficients\nand data symbols to reduce the complexity of the only BP used. The numerical\nresults show that the BER performance of the proposed low complexity receiver\nclosely approach that of the state-of-the-art receiver, where only BP is used\nto handled the hard constraint factors, in the high SNRs. \n\n"}
{"id": "1701.06342", "contents": "Title: Bayesian definition of random sequences with respect to conditional\n  probabilities Abstract: We study Martin-L\\\"{o}f random (ML-random) points on computable probability\nmeasures on sample and parameter spaces (Bayes models). We consider variants of\nconditional randomness defined by ML-randomness on Bayes models and those of\nconditional blind randomness. We show that variants of conditional blind\nrandomness are ill-defined from the Bayes statistical point of view. We prove\nthat if the sets of random sequences of uniformly computable parametric models\nare pairwise disjoint then there is a consistent estimator for the model.\nFinally, we present an algorithmic solution to a classical problem in Bayes\nstatistics, i.e., the posterior distributions converge weakly to almost all\nparameters if and only if the posterior distributions converge weakly to all\nML-random parameters. \n\n"}
{"id": "1701.06969", "contents": "Title: Error correction based on partial information Abstract: We consider the decoding of linear and array codes from errors when we are\nonly allowed to download a part of the codeword. More specifically, suppose\nthat we have encoded $k$ data symbols using an $(n,k)$ code with code length\n$n$ and dimension $k.$ During storage, some of the codeword coordinates might\nbe corrupted by errors. We aim to recover the original data by reading the\ncorrupted codeword with a limit on the transmitting bandwidth, namely, we can\nonly download an $\\alpha$ proportion of the corrupted codeword. For a given\n$\\alpha,$ our objective is to design a code and a decoding scheme such that we\ncan recover the original data from the largest possible number of errors. A\nnaive scheme is to read $\\alpha n$ coordinates of the codeword. This method\nused in conjunction with MDS codes guarantees recovery from any $\\lfloor(\\alpha\nn-k)/2\\rfloor$ errors. In this paper we show that we can instead read an\n$\\alpha$ proportion from each of the codeword's coordinates. For a\nwell-designed MDS code, this method can guarantee recovery from $\\lfloor\n(n-k/\\alpha)/2 \\rfloor$ errors, which is $1/\\alpha$ times more than the naive\nmethod, and is also the maximum number of errors that an $(n,k)$ code can\ncorrect by downloading only an $\\alpha$ proportion of the codeword. We present\ntwo families of such optimal constructions and decoding schemes. One is a\nReed-Solomon code with evaluation points in a subfield and the other is based\non Folded Reed-Solomon codes. We further show that both code constructions\nattain asymptotically optimal list decoding radius when downloading only a part\nof the corrupted codeword. We also construct an ensemble of random codes that\nwith high probability approaches the upper bound on the number of correctable\nerrors when the decoder downloads an $\\alpha$ proportion of the corrupted\ncodeword. \n\n"}
{"id": "1701.07153", "contents": "Title: Throughput Maximization for Wireless Powered Communications Harvesting\n  from Non-dedicated Sources Abstract: We consider the wireless powered communications where users harvest energy\nfrom non-dedicated sources. The user follows a harvest-then-transmit protocol:\nin first phase of a slot time the source node harvests energy from a nearby\nconventional Access Point, then transmit information to its destination node or\nrelay node in the second phase. We obtain the optimal\\textit{ harvesting ratio}\nto maximize the expected throughput for direct transmission (DT )and decode\nforward (DF) relay under outage constraint, respectively. Our results reveal\nthat the optimal harvest ratio for DT is dominated by the outage constraint\nwhile for DF relay, by the data causality . \n\n"}
{"id": "1701.07371", "contents": "Title: Divergence Scaling of Fixed-Length, Binary-Output, One-to-One\n  Distribution Matching Abstract: Distribution matching is the process of invertibly mapping a uniformly\ndistributed input sequence onto sequences that approximate the output of a\ndesired discrete memoryless source. The special case of a binary output\nalphabet and one-to-one mapping is studied. A fixed-length distribution matcher\nis proposed that is optimal in the sense of minimizing the unnormalized\ninformational divergence between its output distribution and a binary\nmemoryless target distribution. Upper and lower bounds on the unnormalized\ndivergence are computed that increase logarithmically in the output block\nlength $n$. It follows that a recently proposed constant composition\ndistribution matcher performs within a constant gap of the minimal achievable\ninformational divergence. \n\n"}
{"id": "1701.07730", "contents": "Title: Alpha Fair Coded Caching Abstract: The performance of existing \\emph{coded caching} schemes is sensitive to\nworst channel quality, a problem which is exacerbated when communicating over\nfading channels. In this paper we address this limitation in the following\nmanner: \\emph{in short-term}, we allow transmissions to subsets of users with\ngood channel quality, avoiding users with fades, while \\emph{in long-term} we\nensure fairness across the different users.Our online scheme combines (i) joint\nscheduling and power control for the broadcast channel with fading, and (ii)\ncongestion control for ensuring the optimal long-term average performance. We\nrestrict the caching operations to the decentralized scheme of\n\\cite{maddah2013decentralized}, and subject to this restriction we prove that\nour scheme has near-optimal overall performance with respect to the convex\nalpha-fairness coded caching optimization. By tuning the coefficient alpha, the\noperator can differentiate user performance with respect to video delivery\nrates achievable by coded caching.\n  We demonstrate via simulations our scheme's superiority over legacy coded\ncaching and unicast opportunistic scheduling, which are identified as special\ncases of our general framework. \n\n"}
{"id": "1702.00606", "contents": "Title: Joint Offloading and Computing Optimization in Wireless Powered\n  Mobile-Edge Computing Systems Abstract: Mobile-edge computing (MEC) and wireless power transfer (WPT) have been\nrecognized as promising techniques in the Internet of Things (IoT) era to\nprovide massive low-power wireless devices with enhanced computation capability\nand sustainable energy supply. In this paper, we propose a unified MEC-WPT\ndesign by considering a wireless powered multiuser MEC system, where a\nmulti-antenna access point (AP) (integrated with an MEC server) broadcasts\nwireless power to charge multiple users and each user node relies on the\nharvested energy to execute computation tasks. With MEC, these users can\nexecute their respective tasks locally by themselves or offload all or part of\nthem to the AP based on a time division multiple access (TDMA) protocol.\nBuilding on the proposed model, we develop an innovative framework to improve\nthe MEC performance, by jointly optimizing the energy transmit beamformer at\nthe AP, the central processing unit (CPU) frequencies and the numbers of\noffloaded bits at the users, as well as the time allocation among users. Under\nthis framework, we address a practical scenario where latency-limited\ncomputation is required. In this case, we develop an optimal resource\nallocation scheme that minimizes the AP's total energy consumption subject to\nthe users' individual computation latency constraints. Leveraging the\nstate-of-the-art optimization techniques, we derive the optimal solution in a\nsemi-closed form. Numerical results demonstrate the merits of the proposed\ndesign over alternative benchmark schemes. \n\n"}
{"id": "1702.01864", "contents": "Title: The Meta Distribution of the SIR for Cellular Networks with Power\n  Control Abstract: The meta distribution of the signal-to-interference ratio (SIR) provides\nfine-grained information about the performance of individual links in a\nwireless network. This paper focuses on the analysis of the meta distribution\nof the SIR for both the cellular network uplink and downlink with fractional\npower control. For the uplink scenario, an approximation of the interfering\nuser point process with a non-homogeneous Poisson point process is used. The\nmoments of the meta distribution for both scenarios are calculated. Some\nbounds, the analytical expression, the mean local delay, and the beta\napproximation of the meta distribution are provided. The results give\ninteresting insights into the effect of the power control in both the uplink\nand downlink. Detailed simulations show that the approximations made in the\nanalysis are well justified. \n\n"}
{"id": "1702.03051", "contents": "Title: Density Functional Estimators with k-Nearest Neighbor Bandwidths Abstract: Estimating expected polynomials of density functions from samples is a basic\nproblem with numerous applications in statistics and information theory.\nAlthough kernel density estimators are widely used in practice for such\nfunctional estimation problems, practitioners are left on their own to choose\nan appropriate bandwidth for each application in hand. Further, kernel density\nestimators suffer from boundary biases, which are prevalent in real world data\nwith lower dimensional structures. We propose using the fixed-k nearest\nneighbor distances for the bandwidth, which adaptively adjusts to local\ngeometry. Further, we propose a novel estimator based on local likelihood\ndensity estimators, that mitigates the boundary biases. Although such a choice\nof fixed-k nearest neighbor distances to bandwidths results in inconsistent\nestimators, we provide a simple debiasing scheme that precomputes the\nasymptotic bias and divides off this term. With this novel correction, we show\nconsistency of this debiased estimator. We provide numerical experiments\nsuggesting that it improves upon competing state-of-the-art methods. \n\n"}
{"id": "1702.03507", "contents": "Title: Sense-and-Predict: Opportunistic MAC Based on Spatial Interference\n  Correlation for Cognitive Radio Networks Abstract: Opportunity detection at secondary transmitters (TXs) is a key technique\nenabling cognitive radio (CR) networks. Such detection however cannot guarantee\nreliable communication at secondary receivers (RXs), especially when their\nassociation distance is long. To cope with the issue, this paper proposes a\nnovel MAC called sense-and-predict (SaP), where each secondary TX decides\nwhether to access or not based on the prediction of the interference level at\nRX. Firstly, we provide the spatial interference correlation in a probabilistic\nform using stochastic geometry, and utilize it to maximize the area spectral\nefficiency (ASE) for secondary networks while guaranteeing the service quality\nof primary networks. Through simulations and testbed experiments using USRP,\nSaP is shown to always achieve ASE improvement compared with the conventional\nTX based sensing. \n\n"}
{"id": "1702.03589", "contents": "Title: Subspace-Aware Index Codes Abstract: In this paper, we generalize the well-known index coding problem to exploit\nthe structure in the source-data to improve system throughput. In many\napplications, the data to be transmitted may lie (or can be well approximated)\nin a low-dimensional subspace. We exploit this low-dimensional structure of the\ndata using an algebraic framework to solve the index coding problem (referred\nto as subspace-aware index coding) as opposed to the traditional index coding\nproblem which is subspace-unaware. Also, we propose an efficient algorithm\nbased on the alternating minimization approach to obtain near optimal index\ncodes for both subspace-aware and -unaware cases. Our simulations indicate that\nunder certain conditions, a significant throughput gain (about 90%) can be\nachieved by subspace-aware index codes over conventional subspace-unaware index\ncodes. \n\n"}
{"id": "1702.03656", "contents": "Title: Information and estimation in Fokker-Planck channels Abstract: We study the relationship between information- and estimation-theoretic\nquantities in time-evolving systems. We focus on the Fokker-Planck channel\ndefined by a general stochastic differential equation, and show that the time\nderivatives of entropy, KL divergence, and mutual information are characterized\nby estimation-theoretic quantities involving an appropriate generalization of\nthe Fisher information. Our results vastly extend De Bruijn's identity and the\nclassical I-MMSE relation. \n\n"}
{"id": "1702.04834", "contents": "Title: Improved Converses and Gap Results for Coded Caching Abstract: Improved lower bounds on the average and the worst-case rate-memory tradeoffs\nfor the Maddah-Ali&Niesen coded caching scenario are presented. For any number\nof users and files and for arbitrary cache sizes, the multiplicative gap\nbetween the exact rate-memory tradeoff and the new lower bound is less than\n2.315 in the worst-case scenario and less than 2.507 in the average-case\nscenario. \n\n"}
{"id": "1702.05309", "contents": "Title: Mobile Edge Computing: A Survey on Architecture and Computation\n  Offloading Abstract: Technological evolution of mobile user equipments (UEs), such as smartphones\nor laptops, goes hand-in-hand with evolution of new mobile applications.\nHowever, running computationally demanding applications at the UEs is\nconstrained by limited battery capacity and energy consumption of the UEs.\nSuitable solution extending the battery life-time of the UEs is to offload the\napplications demanding huge processing to a conventional centralized cloud\n(CC). Nevertheless, this option introduces significant execution delay\nconsisting in delivery of the offloaded applications to the cloud and back plus\ntime of the computation at the cloud. Such delay is inconvenient and make the\noffloading unsuitable for real-time applications. To cope with the delay\nproblem, a new emerging concept, known as mobile edge computing (MEC), has been\nintroduced. The MEC brings computation and storage resources to the edge of\nmobile network enabling to run the highly demanding applications at the UE\nwhile meeting strict delay requirements. The MEC computing resources can be\nexploited also by operators and third parties for specific purposes. In this\npaper, we first describe major use cases and reference scenarios where the MEC\nis applicable. After that we survey existing concepts integrating MEC\nfunctionalities to the mobile networks and discuss current advancement in\nstandardization of the MEC. The core of this survey is, then, focused on\nuser-oriented use case in the MEC, i.e., computation offloading. In this\nregard, we divide the research on computation offloading to three key areas: i)\ndecision on computation offloading, ii) allocation of computing resource within\nthe MEC, and iii) mobility management. Finally, we highlight lessons learned in\narea of the MEC and we discuss open research challenges yet to be addressed in\norder to fully enjoy potentials offered by the MEC. \n\n"}
{"id": "1702.07737", "contents": "Title: Decoding Generalized Reed-Solomon Codes and Its Application to RLCE\n  Encryption Schemes Abstract: This paper compares the efficiency of various algorithms for implementing\nquantum resistant public key encryption scheme RLCE on 64-bit CPUs. By\noptimizing various algorithms for polynomial and matrix operations over finite\nfields, we obtained several interesting (or even surprising) results. For\nexample, it is well known (e.g., Moenck 1976 \\cite{moenck1976practical}) that\nKaratsuba's algorithm outperforms classical polynomial multiplication algorithm\nfrom the degree 15 and above (practically, Karatsuba's algorithm only\noutperforms classical polynomial multiplication algorithm from the degree 35\nand above ). Our experiments show that 64-bit optimized Karatsuba's algorithm\nwill only outperform 64-bit optimized classical polynomial multiplication\nalgorithm for polynomials of degree 115 and above over finite field\n$GF(2^{10})$. The second interesting (surprising) result shows that 64-bit\noptimized Chien's search algorithm ourperforms all other 64-bit optimized\npolynomial root finding algorithms such as BTA and FFT for polynomials of all\ndegrees over finite field $GF(2^{10})$. The third interesting (surprising)\nresult shows that 64-bit optimized Strassen matrix multiplication algorithm\nonly outperforms 64-bit optimized classical matrix multiplication algorithm for\nmatrices of dimension 750 and above over finite field $GF(2^{10})$. It should\nbe noted that existing literatures and practices recommend Strassen matrix\nmultiplication algorithm for matrices of dimension 40 and above. All our\nexperiments are done on a 64-bit MacBook Pro with i7 CPU and single thread C\ncodes. It should be noted that the reported results should be appliable to 64\nor larger bits CPU architectures. For 32 or smaller bits CPUs, these results\nmay not be applicable. The source code and library for the algorithms covered\nin this paper are available at http://quantumca.org/. \n\n"}
{"id": "1702.08079", "contents": "Title: Topological Interference Management with Decoded Message Passing Abstract: The topological interference management (TIM) problem studies\npartially-connected interference networks with no channel state information\nexcept for the network topology (i.e., connectivity graph) at the transmitters.\nIn this paper, we consider a similar problem in the uplink cellular networks,\nwhile message passing is enabled at the receivers (e.g., base stations), so\nthat the decoded messages can be routed to other receivers via backhaul links\nto help further improve network performance. For this TIM problem with decoded\nmessage passing (TIM-MP), we model the interference pattern by conflict\ndigraphs, connect orthogonal access to the acyclic set coloring on conflict\ndigraphs, and show that one-to-one interference alignment boils down to\northogonal access because of message passing. With the aid of polyhedral\ncombinatorics, we identify the structural properties of certain classes of\nnetwork topologies where orthogonal access achieves the optimal\ndegrees-of-freedom (DoF) region in the information-theoretic sense. The\nrelation to the conventional index coding with simultaneous decoding is also\ninvestigated by formulating a generalized index coding problem with successive\ndecoding as a result of decoded message passing. The properties of reducibility\nand criticality are also studied, by which we are able to prove the linear\noptimality of orthogonal access in terms of symmetric DoF for the networks up\nto four users with all possible network topologies (218 instances). Practical\nissues of the tradeoff between the overhead of message passing and the\nachievable symmetric DoF are also discussed, in the hope of facilitating\nefficient backhaul utilization. \n\n"}
{"id": "1702.08130", "contents": "Title: Multiuser Precoding and Channel Estimation for Hybrid Millimeter Wave\n  MIMO Systems Abstract: In this paper, we develop a low-complexity channel estimation for hybrid\nmillimeter wave (mmWave) systems, where the number of radio frequency (RF)\nchains is much less than the number of antennas equipped at each transceiver.\nThe proposed channel estimation algorithm aims to estimate the strongest\nangle-of-arrivals (AoAs) at both the base station (BS) and the users. Then all\nthe users transmit orthogonal pilot symbols to the BS via these estimated\nstrongest AoAs to facilitate the channel estimation. The algorithm does not\nrequire any explicit channel state information (CSI) feedback from the users\nand the associated signalling overhead of the algorithm is only proportional to\nthe number of users, which is significantly less compared to various existing\nschemes. Besides, the proposed algorithm is applicable to both non-sparse and\nsparse mmWave channel environments. Based on the estimated CSI, zero-forcing\n(ZF) precoding is adopted for multiuser downlink transmission. In addition, we\nderive a tight achievable rate upper bound of the system. Our analytical and\nsimulation results show that the proposed scheme offer a considerable\nachievable rate gain compared to fully digital systems, where the number of RF\nchains equipped at each transceiver is equal to the number of antennas.\nFurthermore, the achievable rate performance gap between the considered hybrid\nmmWave systems and the fully digital system is characterized, which provides\nuseful system design insights. \n\n"}
{"id": "1702.08565", "contents": "Title: Nearly Maximally Predictive Features and Their Dimensions Abstract: Scientific explanation often requires inferring maximally predictive features\nfrom a given data set. Unfortunately, the collection of minimal maximally\npredictive features for most stochastic processes is uncountably infinite. In\nsuch cases, one compromises and instead seeks nearly maximally predictive\nfeatures. Here, we derive upper-bounds on the rates at which the number and the\ncoding cost of nearly maximally predictive features scales with desired\npredictive power. The rates are determined by the fractal dimensions of a\nprocess' mixed-state distribution. These results, in turn, show how widely-used\nfinite-order Markov models can fail as predictors and that mixed-state\npredictive features offer a substantial improvement. \n\n"}
{"id": "1703.01092", "contents": "Title: Zero-Delay Source-Channel Coding with a One-Bit ADC Front End and\n  Correlated Side Information at the Receiver Abstract: Zero-delay transmission of a Gaussian source over an additive white Gaussian\nnoise (AWGN) channel is considered with a one-bit analog-to-digital converter\n(ADC) front end and a correlated side information at the receiver. The design\nof the optimal encoder and decoder is studied for two performance criteria,\nnamely, the mean squared error (MSE) distortion and the distortion outage\nprobability (DOP), under an average power constraint on the channel input. For\nboth criteria, necessary optimality conditions for the encoder and the decoder\nare derived. Using these conditions, it is observed that the numerically\noptimized encoder (NOE) under the MSE distortion criterion is periodic, and its\nperiod increases with the correlation between the source and the receiver side\ninformation. For the DOP, it is instead seen that the NOE mappings periodically\nacquire positive and negative values, which decay to zero with increasing\nsource magnitude, and the interval over which the mapping takes non-zero\nvalues, becomes wider with the correlation between the source and the side\ninformation. \n\n"}
{"id": "1703.01208", "contents": "Title: Preserving Confidentiality in The Gaussian Broadcast Channel Using\n  Compute-and-Forward Abstract: We study the transmission of confidential messages across a wireless\nbroadcast channel with K>2 receivers and K helpers. The goal is to transmit all\nmessages reliably to their intended receivers while keeping them confidential\nfrom the unintended receivers. We design a codebook based on nested lattice\nstructure, cooperative jamming, lattice alignment, and i.i.d. coding. Moreover,\nwe exploit the asymmetric compute-and-forward decoding strategy to handle\nfinite SNR regimes. Unlike previous alignment schemes, our achievable rates are\nattainable at any finite SNR value. Also, we show that our scheme achieves the\noptimal sum secure degrees of freedom of 1 for the K-receiver Gaussian\nbroadcast channel with K confidential messages and K helpers. \n\n"}
{"id": "1703.01441", "contents": "Title: Algebraic geometry codes with complementary duals exceed the asymptotic\n  Gilbert-Varshamov bound Abstract: It was shown by Massey that linear complementary dual (LCD for short) codes\nare asymptotically good. In 2004, Sendrier proved that LCD codes meet the\nasymptotic Gilbert-Varshamov (GV for short) bound. Until now, the GV bound\nstill remains to be the best asymptotical lower bound for LCD codes. In this\npaper, we show that an algebraic geometry code over a finite field of even\ncharacteristic is equivalent to an LCD code and consequently there exists a\nfamily of LCD codes that are equivalent to algebraic geometry codes and exceed\nthe asymptotical GV bound. \n\n"}
{"id": "1703.01733", "contents": "Title: Position-based coding and convex splitting for private communication\n  over quantum channels Abstract: The classical-input quantum-output (cq) wiretap channel is a communication\nmodel involving a classical sender $X$, a legitimate quantum receiver $B$, and\na quantum eavesdropper $E$. The goal of a private communication protocol that\nuses such a channel is for the sender $X$ to transmit a message in such a way\nthat the legitimate receiver $B$ can decode it reliably, while the eavesdropper\n$E$ learns essentially nothing about which message was transmitted. The\n$\\varepsilon $-one-shot private capacity of a cq wiretap channel is equal to\nthe maximum number of bits that can be transmitted over the channel, such that\nthe privacy error is no larger than $\\varepsilon\\in(0,1)$. The present paper\nprovides a lower bound on the $\\varepsilon$-one-shot private classical\ncapacity, by exploiting the recently developed techniques of Anshu,\nDevabathini, Jain, and Warsi, called position-based coding and convex\nsplitting. The lower bound is equal to a difference of the hypothesis testing\nmutual information between $X$ and $B$ and the \"alternate\" smooth\nmax-information between $X$ and $E$. The one-shot lower bound then leads to a\nnon-trivial lower bound on the second-order coding rate for private classical\ncommunication over a memoryless cq wiretap channel. \n\n"}
{"id": "1703.02799", "contents": "Title: A Low-Complexity Adaptive Multisine Waveform Design for Wireless Power\n  Transfer Abstract: Far-field Wireless Power Transfer (WPT) has attracted significant attention\nin the last decade. Recently, channel-adaptive waveforms have been shown to\nsignificantly increase the DC power level at the output of the rectifier.\nHowever the design of those waveforms is generally computationally complex and\ndoes not lend itself easily to practical implementation. We here propose a\nlow-complexity channel-adaptive multisine waveform design whose performance is\nvery close to that of the optimal design. Performance evaluations confirm the\nbenefits of the new design in various rectifier topologies. \n\n"}
{"id": "1703.04925", "contents": "Title: Heralded Channel Holevo Superadditivity Bounds from Entanglement\n  Monogamy Abstract: We show that for a particular class of quantum channels, which we call\nheralded channels, monogamy of squashed entanglement limits the superadditivity\nof Holevo capacity. Heralded channels provide a means to understand the quantum\nerasure channel composed with an arbitrary other quantum channel, as well as\ncommon situations in experimental quantum information that involve frequent\nloss of qubits or failure of trials. We also show how entanglement monogamy\napplies to non-classicality in quantum games, and we consider how faithful,\nmonogamous entanglement measures may bound other entanglement-dependent\nquantities in many-party scenarios. \n\n"}
{"id": "1703.05024", "contents": "Title: Tail asymptotics of signal-to-interference ratio distribution in spatial\n  cellular network models Abstract: We consider a spatial stochastic model of wireless cellular networks, where\nthe base stations (BSs) are deployed according to a simple and stationary point\nprocess on $\\mathbb{R}^d$, $d\\ge2$. In this model, we investigate tail\nasymptotics of the distribution of signal-to-interference ratio (SIR), which is\na key quantity in wireless communications. In the case where the path-loss\nfunction representing signal attenuation is unbounded at the origin, we derive\nthe exact tail asymptotics of the SIR distribution under an appropriate\nsufficient condition. While we show that widely-used models based on a Poisson\npoint process and on a determinantal point process meet the sufficient\ncondition, we also give a counterexample violating it. In the case of bounded\npath-loss functions, we derive a logarithmically asymptotic upper bound on the\nSIR tail distribution for the Poisson-based and $\\alpha$-Ginibre-based models.\nA logarithmically asymptotic lower bound with the same order as the upper bound\nis also obtained for the Poisson-based model. \n\n"}
{"id": "1703.05307", "contents": "Title: On decoding algorithms for polar codes Abstract: We survey the known list decoding algorithms for polar codes and compare\ntheir complexity.\n  Index terms: Polar codes; Reed-Muller codes; successive cancellation\ndecoding. \n\n"}
{"id": "1703.05536", "contents": "Title: A Compressive Method for Centralized PSD Map Construction with Imperfect\n  Reporting Channel Abstract: Spectrum resources management of growing demands is a challenging problem and\nCognitive Radio (CR) known to be capable of improving the spectrum utilization.\nRecently, Power Spectral Density (PSD) map is defined to enable the CR to reuse\nthe frequency resources regarding to the area. For this reason, the sensed PSDs\nare collected by the distributed sensors in the area and fused by a Fusion\nCenter (FC). But, for a given zone, the sensed PSDs by neighbor CR sensors may\ncontain a shared common component for a while. This component can be exploited\nin the theory of the Distributed Source Coding (DSC) to make the sensors\ntransmission data more compressed. However, uncertain channel fading and random\nshadowing would lead to varying signal strength at different CRs, even placed\nclose to each other. Hence, existence of some perturbations in the transmission\nprocedure yields to some imperfection in the reporting channel and as a result\nit degrades the performance remarkably. The main focus of this paper is to be\nable to reconstruct the PSDs of sensors \\textit{robustly} based on the\nDistributed Compressive Sensing (DCS) when the data transmission is slightly\nimperfect. Simulation results verify the robustness of the proposed scheme. \n\n"}
{"id": "1703.06700", "contents": "Title: Independence clustering (without a matrix) Abstract: The independence clustering problem is considered in the following\nformulation: given a set $S$ of random variables, it is required to find the\nfinest partitioning $\\{U_1,\\dots,U_k\\}$ of $S$ into clusters such that the\nclusters $U_1,\\dots,U_k$ are mutually independent. Since mutual independence is\nthe target, pairwise similarity measurements are of no use, and thus\ntraditional clustering algorithms are inapplicable. The distribution of the\nrandom variables in $S$ is, in general, unknown, but a sample is available.\nThus, the problem is cast in terms of time series. Two forms of sampling are\nconsidered: i.i.d.\\ and stationary time series, with the main emphasis being on\nthe latter, more general, case. A consistent, computationally tractable\nalgorithm for each of the settings is proposed, and a number of open directions\nfor further research are outlined. \n\n"}
{"id": "1703.06810", "contents": "Title: The geometry of hypothesis testing over convex cones: Generalized\n  likelihood tests and minimax radii Abstract: We consider a compound testing problem within the Gaussian sequence model in\nwhich the null and alternative are specified by a pair of closed, convex cones.\nSuch cone testing problem arise in various applications, including detection of\ntreatment effects, trend detection in econometrics, signal detection in radar\nprocessing, and shape-constrained inference in non-parametric statistics. We\nprovide a sharp characterization of the GLRT testing radius up to a universal\nmultiplicative constant in terms of the geometric structure of the underlying\nconvex cones. When applied to concrete examples, this result reveals some\ninteresting phenomena that do not arise in the analogous problems of estimation\nunder convex constraints. In particular, in contrast to estimation error, the\ntesting error no longer depends purely on the problem complexity via a\nvolume-based measure (such as metric entropy or Gaussian complexity), other\ngeometric properties of the cones also play an important role. To address the\nissue of optimality, we prove information-theoretic lower bounds for minimax\ntesting radius again in terms of geometric quantities. Our general theorems are\nillustrated by examples including the cases of monotone and orthant cones, and\ninvolve some results of independent interest. \n\n"}
{"id": "1703.09204", "contents": "Title: On period polynomials of degree $2^m$ and weight distributions of\n  certain irreducible cyclic codes Abstract: We explicitly determine the values of reduced cyclotomic periods of order\n$2^m$, $m\\ge 4$, for finite fields of characteristic $p\\equiv 3$ or\n$5\\pmod{8}$. These evaluations are applied to obtain explicit factorizations of\nthe corresponding reduced period polynomials. As another application, the\nweight distributions of certain irreducible cyclic codes are described. \n\n"}
{"id": "1703.10500", "contents": "Title: Free Energy Approximations for CSMA networks Abstract: In this paper we study how to estimate the back-off rates in an idealized\nCSMA network consisting of $n$ links to achieve a given throughput vector using\nfree energy approximations. More specifically, we introduce the class of\nregion-based free energy approximations with clique belief and present a closed\nform expression for the back-off rates based on the zero gradient points of the\nfree energy approximation (in terms of the conflict graph, target throughput\nvector and counting numbers). Next we introduce the size $k_{max}$ clique free\nenergy approximation as a special case and derive an explicit expression for\nthe counting numbers, as well as a recursion to compute the back-off rates. We\nsubsequently show that the size $k_{max}$ clique approximation coincides with a\nKikuchi free energy approximation and prove that it is exact on chordal\nconflict graphs when $k_{max} = n$. As a by-product these results provide us\nwith an explicit expression of a fixed point of the inverse generalized belief\npropagation algorithm for CSMA networks. Using numerical experiments we compare\nthe accuracy of the novel approximation method with existing methods. \n\n"}
{"id": "1704.00455", "contents": "Title: Joint Design of Digital and Analog Processing for Downlink C-RAN with\n  Large-Scale Antenna Arrays Abstract: In millimeter-wave communication systems with large-scale antenna arrays,\nconventional digital beamforming may not be cost-effective. A promising\nsolution is the implementation of hybrid beamforming techniques, which consist\nof low-dimensional digital beamforming followed by analog radio frequency (RF)\nbeamforming. This work studies the optimization of hybrid beamforming in the\ncontext of a cloud radio access network (C-RAN) architecture. In a C-RAN\nsystem, digital baseband signal processing functionalities are migrated from\nremote radio heads (RRHs) to a baseband processing unit (BBU) in the \"cloud\" by\nmeans of finite-capacity fronthaul links. Specifically, this work tackles the\nproblem of jointly optimizing digital beamforming and fronthaul quantization\nstrategies at the BBU, as well as RF beamforming at the RRHs, with the goal of\nmaximizing the weighted downlink sum-rate. Fronthaul capacity and per-RRH power\nconstraints are enforced along with constant modulus constraints on the RF\nbeamforming matrices. An iterative algorithm is proposed that is based on\nsuccessive convex approximation and on the relaxation of the constant modulus\nconstraint. The effectiveness of the proposed scheme is validated by numerical\nsimulation results. \n\n"}
{"id": "1704.01177", "contents": "Title: Combinatorial Entropy Power Inequalities: A Preliminary Study of the\n  Stam region Abstract: We initiate the study of the Stam region, defined as the subset of the\npositive orthant in $\\mathbb{R}^{2^n-1}$ that arises from considering entropy\npowers of subset sums of $n$ independent random vectors in a Euclidean space of\nfinite dimension. We show that the class of fractionally superadditive set\nfunctions provides an outer bound to the Stam region, resolving a conjecture of\nA. R. Barron and the first author. On the other hand, the entropy power of a\nsum of independent random vectors is not supermodular in any dimension. We also\ndevelop some qualitative properties of the Stam region, showing for instance\nthat its closure is a logarithmically convex cone. \n\n"}
{"id": "1704.01244", "contents": "Title: Dynamic Base Station Repositioning to Improve Spectral Efficiency of\n  Drone Small Cells Abstract: With recent advancements in drone technology, researchers are now considering\nthe possibility of deploying small cells served by base stations mounted on\nflying drones. A major advantage of such drone small cells is that the\noperators can quickly provide cellular services in areas of urgent demand\nwithout having to pre-install any infrastructure. Since the base station is\nattached to the drone, technically it is feasible for the base station to\ndynamic reposition itself in response to the changing locations of users for\nreducing the communication distance, decreasing the probability of signal\nblocking, and ultimately increasing the spectral efficiency. In this paper, we\nfirst propose distributed algorithms for autonomous control of drone movements,\nand then model and analyse the spectral efficiency performance of a drone small\ncell to shed new light on the fundamental benefits of dynamic repositioning. We\nshow that, with dynamic repositioning, the spectral efficiency of drone small\ncells can be increased by nearly 100\\% for realistic drone speed, height, and\nuser traffic model and without incurring any major increase in drone energy\nconsumption. \n\n"}
{"id": "1704.01799", "contents": "Title: Prototyping and Experimentation of a Closed-Loop Wireless Power\n  Transmission with Channel Acquisition and Waveform Optimization Abstract: A systematic design of adaptive waveform for Wireless Power Transfer (WPT)\nhas recently been proposed and shown through simulations to lead to significant\nperformance benefits compared to traditional non-adaptive and heuristic\nwaveforms. In this study, we design the first prototype of a closed-loop\nwireless power transfer system with adaptive waveform optimization based on\nChannel State Information acquisition. The prototype consists of three\nimportant blocks, namely the channel estimator, the waveform optimizer, and the\nenergy harvester. Software Defined Radio (SDR) prototyping tools are used to\nimplement a wireless power transmitter and a channel estimator, and a voltage\ndoubler rectenna is designed to work as an energy harvester. A channel adaptive\nwaveform with 8 sinewaves is shown through experiments to improve the average\nharvested DC power at the rectenna output by 9.8% to 36.8% over a non-adaptive\ndesign with the same number of sinewaves. \n\n"}
{"id": "1704.02262", "contents": "Title: A Converse Bound on Wyner-Ahlswede-K\\\"orner Network via Gray-Wyner\n  Network Abstract: We show a reduction method to construct a code for the Gray-Wyner (GW)\nnetwork from a given code for the Wyner-Ahlswede-K\\\"orner (WAK) network. By\ncombining this reduction with a converse bound on the GW network, we derive a\nconverse bound on the WAK network. The derived bound gives an alternative proof\nof the strong converse theorem for the WAK network. \n\n"}
{"id": "1704.03611", "contents": "Title: Hybrid Beamforming via the Kronecker Decomposition for the\n  Millimeter-Wave Massive MIMO Systems Abstract: Despite its promising performance gain, the realization of mmWave massive\nMIMO still faces several practical challenges. In particular, implementing\nmassive MIMO in the digital domain requires hundreds of RF chains matching the\nnumber of antennas. Furthermore, designing these components to operate at the\nmmWave frequencies is challenging and costly. These motivated the recent\ndevelopment of hybrid-beamforming where MIMO processing is divided for separate\nimplementation in the analog and digital domains, called the analog and digital\nbeamforming, respectively. Analog beamforming using a phase array introduces\nuni-modulus constraints on the beamforming coefficients, rendering the\nconventional MIMO techniques unsuitable and call for new designs. In this\npaper, we present a systematic design framework for hybrid beamforming for\nmulti-cell multiuser massive MIMO systems over mmWave channels characterized by\nsparse propagation paths. The framework relies on the decomposition of analog\nbeamforming vectors and path observation vectors into Kronecker products of\nfactors being uni-modulus vectors. Exploiting properties of Kronecker mixed\nproducts, different factors of the analog beamformer are designed for either\nnulling interference paths or coherently combining data paths. Furthermore, a\nchannel estimation scheme is designed for enabling the proposed hybrid\nbeamforming. The scheme estimates the AoA of data and interference paths by\nanalog beam scanning and data-path gains by analog beam steering. The\nperformance of the channel estimation scheme is analyzed. In particular, the\nAoA spectrum resulting from beam scanning, which displays the magnitude\ndistribution of paths over the AoA range, is derived in closed-form. It is\nshown that the inter-cell interference level diminishes inversely with the\narray size, the square root of pilot sequence length and the spatial separation\nbetween paths. \n\n"}
{"id": "1704.04365", "contents": "Title: Limited Feedback in Single and Multi-user MIMO Systems with Finite-Bit\n  ADCs Abstract: Communication systems with low-resolution analog-to-digital-converters (ADCs)\ncan exploit channel state information at the transmitter and receiver. This\npaper presents codebook designs and performance analyses for limited feedback\nMIMO systems with finite-bit ADCs. A point-to-point single-user channel is\nfirstly considered. When the received signal is sliced by 1-bit ADCs, the\nabsolute phase at the receiver is important to align the phase of the received\nsignals. A new codebook design for beamforming, which separately quantizes the\nchannel direction and the residual phase, is therefore proposed. For the\nmulti-bit case where the optimal transmission method is unknown, suboptimal\nGaussian signaling and eigenvector beamforming is assumed to obtain a lower\nbound of the achievable rate. It is found that to limit the rate loss, more\nfeedback bits are needed in the medium SNR regime than the low and high SNR\nregimes, which is quite different from the conventional infinite-bit ADC case.\nSecond, a multi-user system where a multiple-antenna transmitter sends signals\nto multiple single-antenna receivers with finite-bit ADCs is considered. Based\non the derived performance loss due to finite-bit ADCs and finite-bit CSI\nfeedback, the number of bits per feedback should increase linearly with the ADC\nresolution in order to restrict the rate loss. \n\n"}
{"id": "1704.05007", "contents": "Title: Low Complexity Coefficient Selection Algorithms for Compute-and-Forward Abstract: Compute-and-Forward (C&F) has been proposed as an efficient strategy to\nreduce the backhaul load for the distributed antenna systems. Finding the\noptimal coefficients in C&F has commonly been treated as a shortest vector\nproblem (SVP), which is N-P hard. The point of our work and of Sahraei's recent\nwork is that the C&F coefficient problem can be much simpler. Due to the\nspecial structure of C&F, some low polynomial complexity optimal algorithms\nhave recently been developed. However these methods can be applied to real\nvalued channels and integer based lattices only. In this paper, we consider the\ncomplex valued channel with complex integer based lattices. For the first time,\nwe propose a low polynomial complexity algorithm to find the optimal solution\nfor the complex scenario. Then we propose a simple linear search algorithm\nwhich is conceptually suboptimal, however numerical results show that the\nperformance degradation is negligible compared to the optimal method. Both\nalgorithms are suitable for lattices over any algebraic integers, and\nsignificantly outperform the lattice reduction algorithm. The complexity of\nboth algorithms are investigated both theoretically and numerically. The\nresults show that our proposed algorithms achieve better performance-complexity\ntrade-offs compared to the existing algorithms. \n\n"}
{"id": "1704.05334", "contents": "Title: On Low Complexity Detection for QAM Isomorphic Constellations Abstract: Despite of the known gap from the Shannon's capacity, several standards are\nstill employing QAM or star shape constellations, mainly due to the existing\nlow complexity detectors. In this paper, we investigate the low complexity\ndetection for a family of QAM isomorphic constellations. These constellations\nare known to perform very close to the peak-power limited capacity,\noutperforming the DVB-S2X standard constellations. The proposed strategy is to\nfirst remap the received signals to the QAM constellation using the existing\nisomorphism and then break the log likelihood ratio computations to two one\ndimensional PAM constellations. Gains larger than 0.6 dB with respect to QAM\ncan be obtained over the peak power limited channels without any increase in\ndetection complexity. Our scheme also provides a systematic way to design\nconstellations with low complexity one dimensional detectors. Several open\nproblems are discussed at the end of the paper. \n\n"}
{"id": "1704.06426", "contents": "Title: Massive MIMO Downlink 1-Bit Precoding with Linear Programming for PSK\n  Signaling Abstract: Quantized massive multiple-input-multiple-output (MIMO) systems are gaining\nmore interest due to their power efficiency. We present a new precoding\ntechnique to mitigate the multi-user interference and the quantization\ndistortions in a downlink multi-user (MU) multiple-input-single-output (MISO)\nsystem with 1-bit quantization at the transmitter. This work is restricted to\nPSK modulation schemes. The transmit signal vector is optimized for every\ndesired received vector taking into account the 1-bit quantization. The\noptimization is based on maximizing the safety margin to the decision\nthresholds of the PSK modulation. Simulation results show a significant gain in\nterms of the uncoded bit-error-ratio (BER) compared to the existing linear\nprecoding techniques. \n\n"}
{"id": "1704.06785", "contents": "Title: A general private information retrieval scheme for MDS coded databases\n  with colluding servers Abstract: The problem of private information retrieval gets renewed attentions in\nrecent years due to its information-theoretic reformulation and applications in\ndistributed storage systems. PIR capacity is the maximal number of bits\nprivately retrieved per one bit of downloaded bit. The capacity has been fully\nsolved for some degenerating cases. For a general case where the database is\nboth coded and colluded, the exact capacity remains unknown. We build a general\nprivate information retrieval scheme for MDS coded databases with colluding\nservers. Our scheme achieves the rate $(1+R+R^2+\\cdots+R^{M-1})$, where\n$R=1-\\frac{{{N-T}\\choose K}}{{N\\choose K}}$. Compared to existing PIR schemes,\nour scheme performs better for a certain range of parameters and is suitable\nfor any underlying MDS code used in the distributed storage system. \n\n"}
{"id": "1704.06864", "contents": "Title: On the Trade-Off between Computational Load and Reliability for Network\n  Function Virtualization Abstract: Network Function Virtualization (NFV) enables the \"softwarization\" of network\nfunctions, which are implemented on virtual machines hosted on Commercial\noff-the-shelf (COTS) servers. Both the composition of the virtual network\nfunctions (VNFs) into a forwarding graph (FG) at the logical layer and the\nembedding of the FG on the servers need to take into account the\nless-than-carrier-grade reliability of COTS components. This work investigates\nthe trade-off between end-to-end reliability and computational load per server\nvia the joint design of VNF chain composition (CC) and FG embedding (FGE) under\nthe assumption of a bipartite FG that consists of controller and regular VNFs.\nEvaluating the reliability criterion within a probabilistic model, analytical\ninsights are first provided for a simplified disconnected FG. Then, a block\ncoordinate descent method based on mixed-integer linear programming is proposed\nto tackle the joint optimization of CC and FGE. Via simulation results, it is\nobserved that a joint design of CC and FGE leads to substantial performance\ngains compared to separate optimization approaches. \n\n"}
{"id": "1704.07461", "contents": "Title: Denoising Linear Models with Permuted Data Abstract: The multivariate linear regression model with shuffled data and additive\nGaussian noise arises in various correspondence estimation and matching\nproblems. Focusing on the denoising aspect of this problem, we provide a\ncharacterization the minimax error rate that is sharp up to logarithmic\nfactors. We also analyze the performance of two versions of a computationally\nefficient estimator, and establish their consistency for a large range of input\nparameters. Finally, we provide an exact algorithm for the noiseless problem\nand demonstrate its performance on an image point-cloud matching task. Our\nanalysis also extends to datasets with outliers. \n\n"}
{"id": "1704.08572", "contents": "Title: Frequency-domain Compressive Channel Estimation for Frequency-Selective\n  Hybrid mmWave MIMO Systems Abstract: Channel estimation is useful in millimeter wave (mmWave) MIMO communication\nsystems. Channel state information allows optimized designs of precoders and\ncombiners under different metrics such as mutual information or\nsignal-to-interference-noise (SINR) ratio. At mmWave, MIMO precoders and\ncombiners are usually hybrid, since this architecture provides a means to\ntrade-off power consumption and achievable rate. Channel estimation is\nchallenging when using these architectures, however, since there is no direct\naccess to the outputs of the different antenna elements in the array. The MIMO\nchannel can only be observed through the analog combining network, which acts\nas a compression stage of the received signal. Most of prior work on channel\nestimation for hybrid architectures assumes a frequency-flat mmWave channel\nmodel. In this paper, we consider a frequency-selective mmWave channel and\npropose compressed-sensing-based strategies to estimate the channel in the\nfrequency domain. We evaluate different algorithms and compute their complexity\nto expose trade-offs in complexity-overhead-performance as compared to those of\nprevious approaches. \n\n"}
{"id": "1705.01235", "contents": "Title: Non-Orthogonal Random Access (NORA) for 5G Networks Abstract: The massive amounts of machine-type user equipments (UEs) will be supported\nin the future fifth generation (5G) networks. However, the potential large\nrandom access (RA) delay calls for a new RA scheme and for a detailed\nassessment of its performance. Motivated by the key idea of non-orthogonal\nmultiple access, the non-orthogonal random access (NORA) scheme based on\nsuccessive interference cancellation (SIC) is proposed in this paper to\nalleviate the access congestion problem. Specifically, NORA utilizes the\ndifference of time of arrival to identify multiple UEs with the identical\npreamble, and enables power domain multiplexing of collided UEs in the\nfollowing access process, while the base station performs SIC based on the\nchannel conditions obtained through preamble detection. Our analysis show that\nthe performance of NORA is superior to the conventional orthogonal random\naccess (ORA) scheme in terms of the preamble collision probability, access\nsuccess probability and throughput of random access. Simulation results verify\nour analysis and further show that our NORA scheme can improve the number of\nthe supported UEs by more than 30%. Moreover, the number of preamble\ntransmissions and the access delay for successfully accessed UEs are also\nreduced significantly by using the proposed random access scheme. \n\n"}
{"id": "1705.01733", "contents": "Title: On the Design of Matched Filters for Molecule Counting Receivers Abstract: In this paper, we design matched filters for diffusive molecular\ncommunication systems taking into account the following impairments:\nsignal-dependent diffusion noise, inter-symbol interference (ISI), and external\ninterfering molecules. The receiver counts the number of observed molecules\nseveral times within one symbol interval and employs linear filtering to detect\nthe transmitted data. We derive the optimal matched filter by maximizing the\nexpected signal-to-interference-plus-noise ratio of the decision variable.\nMoreover, we show that for the special case of an ISI-free channel, the matched\nfilter reduces to a simple sum detector and a correlator for the channel\nimpulse response for the diffusion noise-limited and (external)\ninterference-limited regimes, respectively. Our simulation results reveal that\nthe proposed matched filter considerably outperforms the benchmark schemes\navailable in literature, especially when ISI is severe. \n\n"}
{"id": "1705.03064", "contents": "Title: Optimal User Scheduling and Power Allocation for Millimeter Wave NOMA\n  Systems Abstract: This paper investigates the application of non-orthogonal multiple access\n(NOMA) in millimeter wave (mmWave) communications by exploiting beamforming,\nuser scheduling and power allocation. Random beamforming is invoked for\nreducing the feedback overhead of considered systems. A nonconvex optimization\nproblem for maximizing the sum rate is formulated, which is proved to be\nNP-hard. The branch and bound (BB) approach is invoked to obtain the optimal\npower allocation policy, which is proved to converge to a global optimal\nsolution. To elaborate further, low complexity suboptimal approach is developed\nfor striking a good computational complexity-optimality tradeoff, where\nmatching theory and successive convex approximation (SCA) techniques are\ninvoked for tackling the user scheduling and power allocation problems,\nrespectively. Simulation results reveal that: i) the proposed low complexity\nsolution achieves a near-optimal performance; and ii) the proposed mmWave NOMA\nsystems is capable of outperforming conventional mmWave orthogonal multiple\naccess (OMA) systems in terms of sum rate and the number of served users. \n\n"}
{"id": "1705.03852", "contents": "Title: Caching with Partial Adaptive Matching Abstract: We study the caching problem when we are allowed to match each user to one of\na subset of caches after its request is revealed. We focus on non-uniformly\npopular content, specifically when the file popularities obey a Zipf\ndistribution. We study two extremal schemes, one focusing on coded server\ntransmissions while ignoring matching capabilities, and the other focusing on\nadaptive matching while ignoring potential coding opportunities. We derive the\nrates achieved by these schemes and characterize the regimes in which one\noutperforms the other. We also compare them to information-theoretic outer\nbounds, and finally propose a hybrid scheme that generalizes ideas from the two\nschemes and performs at least as well as either of them in most memory regimes. \n\n"}
{"id": "1705.06558", "contents": "Title: Robust Chance-Constrained Optimization for Power-Efficient and Secure\n  SWIPT Systems Abstract: In this paper, we propose beamforming schemes to simultaneously transmit data\nsecurely to multiple information receivers (IRs) while transferring power\nwirelessly to multiple energy-harvesting receivers (ERs). Taking into account\nthe imperfection of the instantaneous channel state information (CSI), we\nintroduce a chance-constrained optimization problem to minimize the total\ntransmit power while guaranteeing data transmission reliability, data\ntransmission security, and power transfer reliability. As the proposed\noptimization problem is non-convex due to the chance constraints, we propose\ntwo robust reformulations of the original problem based on\nsafe-convex-approximation techniques. Subsequently, applying semidefinite\nprogramming relaxation (SDR), the derived robust reformulations can be\neffectively solved by standard convex optimization packages. We show that the\nadopted SDR is tight and thus the globally optimal solutions of the\nreformulated problems can be recovered. Simulation results confirm the\nsuperiority of the proposed methods in guaranteeing transmission security\ncompared to a baseline scheme. Furthermore, the performance of proposed methods\ncan closely follow that of a benchmark scheme where perfect CSI is available\nfor resource allocation. \n\n"}
{"id": "1705.06860", "contents": "Title: Beyond Massive-MIMO: The Potential of Positioning with Large Intelligent\n  Surfaces Abstract: We consider the potential for positioning with a system where antenna arrays\nare deployed as a large intelligent surface (LIS), which is a newly proposed\nconcept beyond massive-MIMO where future man-made structures are electronically\nactive with integrated electronics and wireless communication making the entire\nenvironment \\lq\\lq{}intelligent\\rq\\rq{}. In a first step, we derive\nFisher-information and Cram\\'{e}r-Rao lower bounds (CRLBs) in closed-form for\npositioning a terminal located perpendicular to the center of the LIS, whose\nlocation we refer to as being on the central perpendicular line (CPL) of the\nLIS. For a terminal that is not on the CPL, closed-form expressions of the\nFisher-information and CRLB seem out of reach, and we alternatively find\napproximations of them which are shown to be accurate. Under mild conditions,\nwe show that the CRLB for all three Cartesian dimensions ($x$, $y$ and $z$)\ndecreases quadratically in the surface-area of the LIS, except for a terminal\nexactly on the CPL where the CRLB for the $z$-dimension (distance from the LIS)\ndecreases linearly in the same. In a second step, we analyze the CRLB for\npositioning when there is an unknown phase $\\varphi$ presented in the analog\ncircuits of the LIS. We then show that the CRLBs are dramatically increased for\nall three dimensions but decrease in the third-order of the surface-area.\nMoreover, with an infinitely large LIS the CRLB for the $z$-dimension with an\nunknown $\\varphi$ is 6 dB higher than the case without phase uncertainty, and\nthe CRLB for estimating $\\varphi$ converges to a constant that is independent\nof the wavelength $\\lambda$. At last, we extensively discuss the impact of\ncentralized and distributed deployments of LIS, and show that a distributed\ndeployment of LIS can enlarge the coverage for terminal-positioning and improve\nthe overall positioning performance. \n\n"}
{"id": "1705.08572", "contents": "Title: Joint Rate Control and Power Allocation for Non-Orthogonal Multiple\n  Access Systems Abstract: This paper investigates the optimal resource allocation of a downlink\nnon-orthogonal multiple access (NOMA) system consisting of one base station and\nmultiple users. Unlike existing short-term NOMA designs that focused on the\nresource allocation for only the current transmission timeslot, we aim to\nmaximize a long-term network utility by jointly optimizing the data rate\ncontrol at the network layer and the power allocation among multiple users at\nthe physical layer, subject to practical constraints on both the short-term and\nlong-term power consumptions. To solve this problem, we leverage the\nrecently-developed Lyapunov optimization framework to convert the original\nlong-term optimization problem into a series of online rate control and power\nallocation problems in each timeslot. The power allocation problem, however, is\nshown to be non-convex in nature and thus cannot be solved with a standard\nmethod. However, we explore two structures of the optimal solution and develop\na dynamic programming based power allocation algorithm, which can derive a\nglobally optimal solution, with a polynomial computational complexity.\nExtensive simulation results are provided to evaluate the performance of the\nproposed joint rate control and power allocation framework for NOMA systems,\nwhich demonstrate that the proposed NOMA design can significantly outperform\nmultiple benchmark schemes, including orthogonal multiple access (OMA) schemes\nwith optimal power allocation and NOMA schemes with non-optimal power\nallocation, in terms of average throughput and data delay. \n\n"}
{"id": "1705.10305", "contents": "Title: Near Optimal Online Distortion Minimization for Energy Harvesting Nodes Abstract: We consider online scheduling for an energy harvesting communication system\nwhere a sensor node collects samples from a Gaussian source and sends them to a\ndestination node over a Gaussian channel. The sensor is equipped with a\nfinite-sized battery that is recharged by an independent and identically\ndistributed (i.i.d.) energy harvesting process over time. The goal is to\nminimize the long term average distortion of the source samples received at the\ndestination. We study two problems: the first is when sampling is cost-free,\nand the second is when there is a sampling cost incurred whenever samples are\ncollected. We show that fixed fraction policies [Shaviv-Ozgur], in which a\nfixed fraction of the battery state is consumed in each time slot, are\nnear-optimal in the sense that they achieve a long term average distortion that\nlies within a constant additive gap from the optimal solution for all energy\narrivals and battery sizes. For the problem with sampling costs, the\ntransmission policy is bursty; the sensor can collect samples and transmit for\nonly a portion of the time. \n\n"}
{"id": "1705.10407", "contents": "Title: Solving Almost all Systems of Random Quadratic Equations Abstract: This paper deals with finding an $n$-dimensional solution $x$ to a system of\nquadratic equations of the form $y_i=|\\langle{a}_i,x\\rangle|^2$ for $1\\le i \\le\nm$, which is also known as phase retrieval and is NP-hard in general. We put\nforth a novel procedure for minimizing the amplitude-based least-squares\nempirical loss, that starts with a weighted maximal correlation initialization\nobtainable with a few power or Lanczos iterations, followed by successive\nrefinements based upon a sequence of iteratively reweighted (generalized)\ngradient iterations. The two (both the initialization and gradient flow) stages\ndistinguish themselves from prior contributions by the inclusion of a fresh\n(re)weighting regularization technique. The overall algorithm is conceptually\nsimple, numerically scalable, and easy-to-implement. For certain random\nmeasurement models, the novel procedure is shown capable of finding the true\nsolution $x$ in time proportional to reading the data $\\{(a_i;y_i)\\}_{1\\le i\n\\le m}$. This holds with high probability and without extra assumption on the\nsignal $x$ to be recovered, provided that the number $m$ of equations is some\nconstant $c>0$ times the number $n$ of unknowns in the signal vector, namely,\n$m>cn$. Empirically, the upshots of this contribution are: i) (almost) $100\\%$\nperfect signal recovery in the high-dimensional (say e.g., $n\\ge 2,000$) regime\ngiven only an information-theoretic limit number of noiseless equations,\nnamely, $m=2n-1$ in the real-valued Gaussian case; and, ii) (nearly) optimal\nstatistical accuracy in the presence of additive noise of bounded support.\nFinally, substantial numerical tests using both synthetic data and real images\ncorroborate markedly improved signal recovery performance and computational\nefficiency of our novel procedure relative to state-of-the-art approaches. \n\n"}
{"id": "1706.00092", "contents": "Title: Inexact Gradient Projection and Fast Data Driven Compressed Sensing Abstract: We study convergence of the iterative projected gradient (IPG) algorithm for\narbitrary (possibly nonconvex) sets and when both the gradient and projection\noracles are computed approximately. We consider different notions of\napproximation of which we show that the Progressive Fixed Precision (PFP) and\nthe $(1+\\epsilon)$-optimal oracles can achieve the same accuracy as for the\nexact IPG algorithm. We show that the former scheme is also able to maintain\nthe (linear) rate of convergence of the exact algorithm, under the same\nembedding assumption. In contrast, the $(1+\\epsilon)$-approximate oracle\nrequires a stronger embedding condition, moderate compression ratios and it\ntypically slows down the convergence. We apply our results to accelerate\nsolving a class of data driven compressed sensing problems, where we replace\niterative exhaustive searches over large datasets by fast approximate nearest\nneighbour search strategies based on the cover tree data structure. For\ndatasets with low intrinsic dimensions our proposed algorithm achieves a\ncomplexity logarithmic in terms of the dataset population as opposed to the\nlinear complexity of a brute force search. By running several numerical\nexperiments we conclude similar observations as predicted by our theoretical\nanalysis. \n\n"}
{"id": "1706.00307", "contents": "Title: Energy Harvesting Networks with General Utility Functions: Near Optimal\n  Online Policies Abstract: We consider online scheduling policies for single-user energy harvesting\ncommunication systems, where the goal is to characterize online policies that\nmaximize the long term average utility, for some general concave and\nmonotonically increasing utility function. In our setting, the transmitter\nrelies on energy harvested from nature to send its messages to the receiver,\nand is equipped with a finite-sized battery to store its energy. Energy packets\nare independent and identically distributed (i.i.d.) over time slots, and are\nrevealed causally to the transmitter. Only the average arrival rate is known a\npriori. We first characterize the optimal solution for the case of Bernoulli\narrivals. Then, for general i.i.d. arrivals, we first show that fixed fraction\npolicies [Shaviv-Ozgur] are within a constant multiplicative gap from the\noptimal solution for all energy arrivals and battery sizes. We then derive a\nset of sufficient conditions on the utility function to guarantee that fixed\nfraction policies are within a constant additive gap as well from the optimal\nsolution. \n\n"}
{"id": "1706.00399", "contents": "Title: Benchmark problems for phase retrieval Abstract: In recent years, the mathematical and algorithmic aspects of the phase\nretrieval problem have received considerable attention. Many papers in this\narea mention crystallography as a principal application. In crystallography,\nthe signal to be recovered is periodic and comprised of atomic distributions\narranged homogeneously in the unit cell of the crystal. The crystallographic\nproblem is both the leading application and one of the hardest forms of phase\nretrieval. We have constructed a graded set of benchmark problems for\nevaluating algorithms that perform this type of phase retrieval. The data,\npublicly available online, is provided in an easily interpretable format. We\nalso propose a simple and unambiguous success/failure criterion based on the\nactual needs in crystallography. Baseline runtimes were obtained with an\niterative algorithm that is similar but more transparent than those used in\ncrystallography. Empirically, the runtimes grow exponentially with respect to a\nnew hardness parameter: the sparsity of the signal autocorrelation. We also\nreview the algorithms used by the leading software packages. This set of\nbenchmark problems, we hope, will encourage the development of new algorithms\nfor the phase retrieval problem in general, and crystallography in particular. \n\n"}
{"id": "1706.00904", "contents": "Title: X-TCP: A Cross Layer Approach for TCP Uplink Flows in mmWave Networks Abstract: Millimeter wave frequencies will likely be part of the fifth generation of\nmobile networks and of the 3GPP New Radio (NR) standard. MmWave communication\nindeed provides a very large bandwidth, thus an increased cell throughput, but\nhow to exploit these resources at the higher layers is still an open research\nquestion. A very relevant issue is the high variability of the channel, caused\nby the blockage from obstacles and the human body. This affects the design of\ncongestion control mechanisms at the transport layer, and state-of-the-art TCP\nschemes such as TCP CUBIC present suboptimal performance. In this paper, we\npresent a cross layer approach for uplink flows that adjusts the congestion\nwindow of TCP at the mobile equipment side using an estimation of the available\ndata rate at the mmWave physical layer, based on the actual resource allocation\nand on the Signal to Interference plus Noise Ratio. We show that this approach\nreduces the latency, avoiding to fill the buffers in the cellular stack, and\nhas a quicker recovery time after RTO events than several other TCP congestion\ncontrol algorithms. \n\n"}
{"id": "1706.02731", "contents": "Title: Capacity Comparison between MIMO-NOMA and MIMO-OMA with Multiple Users\n  in a Cluster Abstract: In this paper, the performance of multiple-input multiple-output\nnon-orthogonal multiple access (MIMO-NOMA) is investigated when multiple users\nare grouped into a cluster. The superiority of MIMO-NOMA over MIMO orthogonal\nmultiple access (MIMO-OMA) in terms of both sum channel capacity and ergodic\nsum capacity is proved analytically. Furthermore, it is demonstrated that the\nmore users are admitted to a cluster, the lower is the achieved sum rate, which\nillustrates the tradeoff between the sum rate and maximum number of admitted\nusers. On this basis, a user admission scheme is proposed, which is optimal in\nterms of both sum rate and number of admitted users when the\nsignal-to-interference-plus-noise ratio thresholds of the users are equal. When\nthese thresholds are different, the proposed scheme still achieves good\nperformance in balancing both criteria. Moreover, under certain conditions,it\nmaximizes the number of admitted users. In addition, the complexity of the\nproposed scheme is linear to the number of users per cluster. Simulation\nresults verify the superiority of MIMO-NOMA over MIMO-OMA in terms of both sum\nrate and user fairness, as well as the effectiveness of the proposed user\nadmission scheme. \n\n"}
{"id": "1706.03444", "contents": "Title: Secret-Key-Aided Scheme for Securing Untrusted DF Relaying Networks Abstract: This paper proposes a new scheme to secure the transmissions in an untrusted\ndecode-and-forward (DF) relaying network. A legitimate source node, Alice,\nsends her data to a legitimate destination node, Bob, with the aid of an\nuntrusted DF relay node, Charlie. To secure the transmissions from Charlie\nduring relaying time slots, each data codeword is secured using a secret-key\ncodeword that has been previously shared between Alice and Bob during the\nperfectly secured time slots (i.e., when the channel secrecy rate is positive).\nThe secret-key bits exchanged between Alice and Bob are stored in a\nfinite-length buffer and are used to secure data transmission whenever needed.\nWe model the secret-key buffer as a queueing system and analyze its Markov\nchain. Our numerical results show the gains of our proposed scheme relative to\nbenchmarks. Moreover, the proposed scheme achieves an upper bound on the secure\nthroughput. \n\n"}
{"id": "1706.06451", "contents": "Title: Control-Data Separation with Decentralized Edge Control in Fog-Assisted\n  Uplink Communications Abstract: Fog-aided network architectures for 5G systems encompass wireless edge nodes,\nreferred to as remote radio systems (RRSs), as well as remote cloud center\n(RCC) processors, which are connected to the RRSs via a fronthaul access\nnetwork. RRSs and RCC are operated via Network Functions Virtualization (NFV),\nenabling a flexible split of network functionalities that adapts to network\nparameters such as fronthaul latency and capacity. This work focuses on uplink\ncommunications and investigates the cloud-edge allocation of two important\nnetwork functions, namely the control functionality of rate selection and the\ndata-plane function of decoding. Three functional splits are considered: (i)\nDistributed Radio Access Network (D-RAN), in which both functions are\nimplemented in a decentralized way at the RRSs, (ii) Cloud RAN (C-RAN), in\nwhich instead both functions are carried out centrally at the RCC, and (iii) a\nnew functional split, referred to as Fog RAN (F-RAN), with separate\ndecentralized edge control and centralized cloud data processing. The model\nunder study consists of a time-varying uplink channel in which the RCC has\nglobal but delayed channel state information (CSI) due to fronthaul latency,\nwhile the RRSs have local but more timely CSI. Using the adaptive sum-rate as\nthe performance criterion, it is concluded that the F-RAN architecture can\nprovide significant gains in the presence of user mobility. \n\n"}
{"id": "1706.09918", "contents": "Title: User Activity Detection in Massive Random Access: Compressed Sensing vs.\n  Coded Slotted ALOHA Abstract: Machine-type communication services in mobile cel- lular systems are\ncurrently evolving with an aim to efficiently address a massive-scale user\naccess to the system. One of the key problems in this respect is to efficiently\nidentify active users in order to allocate them resources for the subsequent\ntransmissions. In this paper, we examine two recently suggested approaches for\nuser activity detection: compressed-sensing (CS) and coded slotted ALOHA (CSA),\nand provide their comparison in terms of performance vs resource utilization.\nOur preliminary results show that CS-based approach is able to provide the\ntarget user activity detection performance with less overall system resource\nutilization. However, this comes at a price of lower energy- efficiency per\nuser, as compared to CSA-based approach. \n\n"}
{"id": "1707.00475", "contents": "Title: Reconstruction Error Bounds for Compressed Sensing under Poisson or\n  Poisson-Gaussian Noise Using Variance Stabilization Transforms Abstract: Most existing bounds for signal reconstruction from compressive measurements\nmake the assumption of additive signal-independent noise. However in many\ncompressive imaging systems, the noise statistics are more accurately\nrepresented by Poisson or Poisson-Gaussian noise models. In this paper, we\nderive upper bounds for signal reconstruction error from compressive\nmeasurements which are corrupted by Poisson or Poisson-Gaussian noise. The\nfeatures of our bounds are as follows: (1) The bounds are derived for a\nprobabilistically motivated, computationally tractable convex estimator with\nprincipled parameter selection. The estimator penalizes signal sparsity subject\nto a constraint that imposes an upper bound on a term based on variance\nstabilization transforms to approximate the Poisson or Poisson-Gaussian\nnegative log-likelihoods. (2) They are applicable to signals that are sparse as\nwell as compressible in any orthonormal basis, and are derived for compressive\nsystems obeying realistic constraints such as non-negativity and\nflux-preservation. We present extensive numerical results for signal\nreconstruction under varying number of measurements and varying signal\nintensity levels. \n\n"}
{"id": "1707.00549", "contents": "Title: A new class of permutation trinomials constructed from Niho exponents Abstract: Permutation polynomials over finite fields are an interesting subject due to\ntheir important applications in the areas of mathematics and engineering. In\nthis paper we investigate the trinomial $f(x)=x^{(p-1)q+1}+x^{pq}-x^{q+(p-1)}$\nover the finite field $\\mathbb{F}_{q^2}$, where $p$ is an odd prime and $q=p^k$\nwith $k$ being a positive integer. It is shown that when $p=3$ or $5$, $f(x)$\nis a permutation trinomial of $\\mathbb{F}_{q^2}$ if and only if $k$ is even.\nThis property is also true for more general class of polynomials\n$g(x)=x^{(q+1)l+(p-1)q+1}+x^{(q+1)l+pq}-x^{(q+1)l+q+(p-1)}$, where $l$ is a\nnonnegative integer and $\\gcd(2l+p,q-1)=1$. Moreover, we also show that for\n$p=5$ the permutation trinomials $f(x)$ proposed here are new in the sense that\nthey are not multiplicative equivalent to previously known ones of similar\nform. \n\n"}
{"id": "1707.00808", "contents": "Title: Deconvolution of Point Sources: A Sampling Theorem and Robustness\n  Guarantees Abstract: In this work we analyze a convex-programming method for estimating\nsuperpositions of point sources or spikes from nonuniform samples of their\nconvolution with a known kernel. We consider a one-dimensional model where the\nkernel is either a Gaussian function or a Ricker wavelet, inspired by\napplications in geophysics and imaging. Our analysis establishes that\nminimizing a continuous counterpart of the $\\ell_1$ norm achieves exact\nrecovery of the original spikes as long as (1) the signal support satisfies a\nminimum-separation condition and (2) there are at least two samples close to\nevery spike. In addition, we derive theoretical guarantees on the robustness of\nthe approach to both dense and sparse additive noise. \n\n"}
{"id": "1707.03495", "contents": "Title: Lengthening and Extending Binary Private Information Retrieval Codes Abstract: It was recently shown by Fazeli et al. that the storage overhead of a\ntraditional $t$-server private information retrieval (PIR) protocol can be\nsignificantly reduced using the concept of a $t$-server PIR code. In this work,\nwe show that a family of $t$-server PIR codes (with increasing dimensions and\nblocklengths) can be constructed from an existing $t$-server PIR code through\nlengthening by a single information symbol and code extension by at most\n$\\bigl\\lceil t/2\\bigr\\rceil$ code symbols. Furthermore, by extending a code\nconstruction notion from Steiner systems by Fazeli et al., we obtain a specific\nfamily of $t$-server PIR codes. Based on a code construction technique that\nlengthens and extends a $t$-server PIR code simultaneously, a basic algorithm\nto find good (i.e., small blocklength) $t$-server PIR codes is proposed. For\nthe special case of $t=5$, we find provably optimal PIR codes for code\ndimensions $k\\leq 6$, while for all $7\\leq k\\leq 32$ we find codes of smaller\nblocklength than the best known codes from the literature. Furthermore, in the\ncase of $t = 8$, we also find better codes for $k = 5, 6, 11, 12$. Numerical\nresults show that most of the best found $5$-server PIR codes can be\nconstructed from the proposed family of codes connected to Steiner systems. \n\n"}
{"id": "1707.04088", "contents": "Title: Robust Geometry-Based User Scheduling for Large MIMO Systems Under\n  Realistic Channel Conditions Abstract: The problem of user scheduling with reduced overhead of channel estimation in\nthe uplink of Massive multiple-input multiple-output (MIMO) systems has been\nconsidered. A geometry-based stochastic channel model (GSCM), called the COST\n2100 channel model has been used for realistic analysis of channels. In this\npaper, we propose a new user selection algorithm based on knowledge of the\ngeometry of the service area and location of clusters, without having full\nchannel state information (CSI) at the base station (BS). The multi-user link\ncorrelation in the GSCMs arises from the common clusters in the area. The\nthroughput depends on the position of clusters in the GSCMs and users in the\nsystem. Simulation results show that although the BS does not require the\nchannel information of all users, by the proposed geometry-based user\nscheduling algorithm the sum-rate of the system is only slightly less than the\nwell-known greedy weight clique scheme. Finally, the robustness of the proposed\nalgorithm to the inaccuracy of cluster localization is verified by the\nsimulation results. \n\n"}
{"id": "1707.04875", "contents": "Title: Coding sets with asymmetric information Abstract: We study the following one-way asymmetric transmission problem, also a\nvariant of model-based compressed sensing: a resource-limited encoder has to\nreport a small set $S$ from a universe of $N$ items to a more powerful decoder\n(server). The distinguishing feature is asymmetric information: the subset $S$\nis comprised of i.i.d. samples from a prior distribution $\\mu$, and $\\mu$ is\nonly known to the decoder. The goal for the encoder is to encode $S$\nobliviously, while achieving the information-theoretic bound of $|S| \\cdot\nH(\\mu)$, i.e., the Shannon entropy bound.\n  We first show that any such compression scheme must be {\\em randomized}, if\nit gains non-trivially from the prior $\\mu$. This stands in contrast to the\nsymmetric case (when both the encoder and decoder know $\\mu$), where the\nHuffman code provides a near-optimal deterministic solution. On the other hand,\na rather simple argument shows that, when $|S|=k$, a random linear code\nachieves near-optimal communication rate of about $k\\cdot H(\\mu)$ bits. Alas,\nthe resulting scheme has prohibitive decoding time: about ${N\\choose k} \\approx\n(N/k)^k$.\n  Our main result is a computationally efficient and linear coding scheme,\nwhich achieves an $O(\\lg\\lg N)$-competitive communication ratio compared to the\noptimal benchmark, and runs in $\\text{poly}(N,k)$ time. Our \"multi-level\"\ncoding scheme uses a combination of hashing and syndrome-decoding of\nReed-Solomon codes, and relies on viewing the (unknown) prior $\\mu$ as a rather\nsmall convex combination of uniform (\"flat\") distributions. \n\n"}
{"id": "1707.05487", "contents": "Title: Green Base Station Placement for Microwave Backhaul Links Abstract: Wireless mobile backhaul networks have been proposed as a substitute in cases\nin which wired alternatives are not available due to economical or geographical\nreasons. In this work, we study the location problem of base stations in a\ngiven region where mobile terminals are distributed according to a certain\nprobability density function and the base stations communicate through\nmicrowave backhaul links. Using results of optimal transport theory, we provide\nthe optimal asymptotic distribution of base stations in the considered setting\nby minimizing the total power over the whole network. \n\n"}
{"id": "1707.05869", "contents": "Title: The Benefit of Encoder Cooperation in the Presence of State Information Abstract: In many communication networks, the availability of channel state information\nat various nodes provides an opportunity for network nodes to work together, or\n\"cooperate.\" This work studies the benefit of cooperation in the multiple\naccess channel with a cooperation facilitator, distributed state information at\nthe encoders, and full state information available at the decoder. Under\nvarious causality constraints, sufficient conditions are obtained such that\nencoder cooperation through the facilitator results in a gain in sum-capacity\nthat has infinite slope in the information rate shared with the encoders. This\nresult extends the prior work of the authors on cooperation in networks where\nnone of the nodes have access to state information. \n\n"}
{"id": "1707.07146", "contents": "Title: Structural Properties of Uncoded Placement Optimization for Coded\n  Delivery Abstract: A centralized coded caching scheme has been proposed by Maddah-Ali and Niesen\nto reduce the worst-case load of a network consisting of a server with access\nto N files and connected through a shared link to K users, each equipped with a\ncache of size M. However, this centralized coded caching scheme is not able to\ntake advantage of a non-uniform, possibly very skewed, file popularity\ndistribution. In this work, we consider the same network setting but aim to\nreduce the average load under an arbitrary (known) file popularity\ndistribution. First, we consider a class of centralized coded caching schemes\nutilizing general uncoded placement and a specific coded delivery strategy,\nwhich are specified by a general file partition parameter. Then, we formulate\nthe coded caching design optimization problem over the considered class of\nschemes with 2^K2^N variables to minimize the average load by optimizing the\nfile partition parameter under an arbitrary file popularity. Furthermore, we\nshow that the optimization problem is convex, and the resulting optimal\nsolution generally improves upon known schemes. Next, we analyze structural\nproperties of the optimization problem to obtain design insights and reduce the\ncomplexity. Specifically, we obtain an equivalent linear optimization problem\nwith (K+1)N variables under an arbitrary file popularity and an equivalent\nlinear optimization problem with K+1 variables under the uniform file\npopularity. Under the uniform file popularity, we also obtain the closed form\noptimal solution, which corresponds to Maddah-Ali-Niesen's centralized coded\ncaching scheme. Finally, we present an information-theoretic converse bound on\nthe average load under an arbitrary file popularity. \n\n"}
{"id": "1707.07816", "contents": "Title: Small-Scale, Local Area, and Transitional Millimeter Wave Propagation\n  for 5G Communications Abstract: This paper studies radio propagation mechanisms that impact handoffs, air\ninterface design, beam steering, and MIMO for 5G mobile communication systems.\nKnife edge diffraction (KED) and a creeping wave linear model are shown to\npredict diffraction loss around typical building objects from 10 to 26 GHz, and\nhuman blockage measurements at 73 GHz are shown to fit a double knife-edge\ndiffraction (DKED) model which incorporates antenna gains. Small-scale spatial\nfading of millimeter wave received signal voltage amplitude is generally\nRicean-distributed for both omnidirectional and directional receive antenna\npatterns under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions\nin most cases, although the log-normal distribution fits measured data better\nfor the omnidirectional receive antenna pattern in the NLOS environment.\nSmall-scale spatial autocorrelations of received voltage amplitudes are shown\nto fit sinusoidal exponential and exponential functions for LOS and NLOS\nenvironments, respectively, with small decorrelation distances of 0.27 cm to\n13.6 cm (smaller than the size of a handset) that are favorable for spatial\nmultiplexing. Local area measurements using cluster and route scenarios show\nhow the received signal changes as the mobile moves and transitions from LOS to\nNLOS locations, with reasonably stationary signal levels within clusters.\nWideband mmWave power levels are shown to fade from 0.4 dB/ms to 40 dB/s,\ndepending on travel speed and surroundings. \n\n"}
{"id": "1707.08621", "contents": "Title: Communication versus Computation: Duality for multiple access channels\n  and source coding Abstract: Computation codes in network information theory are designed for the\nscenarios where the decoder is not interested in recovering the information\nsources themselves, but only a function thereof. K\\\"orner and Marton showed for\ndistributed source coding that such function decoding can be achieved more\nefficiently than decoding the full information sources. Compute-and-forward has\nshown that function decoding, in combination with network coding ideas, is a\nuseful building block for end-to-end communication. In both cases, good\ncomputation codes are the key component in the coding schemes. In this work, we\nexpose the fact that good computation codes could undermine the capability of\nthe codes for recovering the information sources individually, e.g., for the\npurpose of multiple access and distributed source coding. Particularly, we\nestablish duality results between the codes which are good for computation and\nthe codes which are good for multiple access or distributed compression. \n\n"}
{"id": "1707.08926", "contents": "Title: Non-Coherent Detection for Diffusive Molecular Communications Abstract: We study non-coherent detection schemes for molecular communication (MC)\nsystems that do not require knowledge of the channel state information (CSI).\nIn particular, we first derive the optimal maximum likelihood (ML)\nmultiple-symbol (MS) detector for MC systems. As a special case of the optimal\nMS detector, we show that the optimal ML symbol-by-symbol (SS) detector can be\nequivalently written in the form of a threshold-based detector, where the\noptimal decision threshold is constant and depends only on the statistics of\nthe MC channel. The main challenge of the MS detector is the complexity\nassociated with the calculation of the optimal detection metric. To overcome\nthis issue, we propose an approximate MS detection metric which can be\nexpressed in closed form. To reduce complexity even further, we develop a\nnon-coherent decision-feedback (DF) detector and a suboptimal blind detector.\nFinally, we derive analytical expressions for the bit error rate (BER) of the\noptimal SS detector, as well as upper and lower bounds for the BER of the\noptimal MS detector. Simulation results confirm the analysis and reveal the\neffectiveness of the proposed optimal and suboptimal detection schemes compared\nto a benchmark scheme that assumes perfect CSI knowledge, particularly when the\nnumber of observations used for detection is sufficiently large. \n\n"}
{"id": "1707.09334", "contents": "Title: Compressive Sensing with Cross-Validation and Stop-Sampling for Sparse\n  Polynomial Chaos Expansions Abstract: Compressive sensing is a powerful technique for recovering sparse solutions\nof underdetermined linear systems, which is often encountered in uncertainty\nquantification analysis of expensive and high-dimensional physical models. We\nperform numerical investigations employing several compressive sensing solvers\nthat target the unconstrained LASSO formulation, with a focus on linear systems\nthat arise in the construction of polynomial chaos expansions. With core\nsolvers of l1_ls, SpaRSA, CGIST, FPC_AS, and ADMM, we develop techniques to\nmitigate overfitting through an automated selection of regularization constant\nbased on cross-validation, and a heuristic strategy to guide the stop-sampling\ndecision. Practical recommendations on parameter settings for these techniques\nare provided and discussed. The overall method is applied to a series of\nnumerical examples of increasing complexity, including large eddy simulations\nof supersonic turbulent jet-in-crossflow involving a 24-dimensional input.\nThrough empirical phase-transition diagrams and convergence plots, we\nillustrate sparse recovery performance under structures induced by polynomial\nchaos, accuracy and computational tradeoffs between polynomial bases of\ndifferent degrees, and practicability of conducting compressive sensing for a\nrealistic, high-dimensional physical application. Across test cases studied in\nthis paper, we find ADMM to have demonstrated empirical advantages through\nconsistent lower errors and faster computational times. \n\n"}
{"id": "1707.09441", "contents": "Title: A compressive channel estimation technique robust to synchronization\n  impairments Abstract: Initial access at millimeter wave frequencies is a challenging problem due to\nhardware non-idealities and low SNR measurements prior to beamforming. Prior\nwork has exploited the observation that mmWave MIMO channels are sparse in the\nspatial angle domain and has used compressed sensing based algorithms for\nchannel estimation. Most of them, however, ignore hardware impairments like\ncarrier frequency offset and phase noise, and fail to perform well when such\nimpairments are considered. In this paper, we develop a compressive channel\nestimation algorithm for narrowband mmWave systems, which is robust to such non\nidealities. We address this problem by constructing a tensor that models both\nthe mmWave channel and CFO, and estimate the tensor while still exploiting the\nsparsity of the mmWave channel. Simulation results show that under the same\nsettings, our method performs better than comparable algorithms that are robust\nto phase errors. \n\n"}
{"id": "1708.03066", "contents": "Title: Design and Optimization of VoD schemes with Client Caching in Wireless\n  Multicast Networks Abstract: Due to the explosive growth in multimedia traffic, the scalability of\nvideo-on-demand (VoD) services becomes increasingly important. By exploiting\nthe potential cache ability at the client side, the performance of VoD\nmulticast delivery can be improved through video segment pre-caching. In this\npaper, we address the performance limits of client caching enabled VoD schemes\nin wireless multicast networks with asynchronous requests. Both reactive and\nproactive systems are investigated. Specifically, for the reactive system where\nvideos are transmitted on demand, we propose a joint cache allocation and\nmulticast delivery scheme to minimize the average bandwidth consumption under\nthe zero-delay constraint. For the proactive system where videos are\nperiodically broadcasted, a joint design of the cache-bandwidth allocation\nalgorithm and the delivery mechanism is developed to minimize the average\nwaiting time under the total bandwidth constraint. In addition to the full\naccess pattern where clients view videos in their entirety, we further consider\nthe access patterns with random endpoints, fixed-size intervals and downloading\ndemand, respectively. The impacts of different access patterns on the\nresource-allocation algorithm and the delivery mechanism are elaborated.\nSimulation results validate the accuracy of the analytical results and also\nprovide useful insights in designing VoD networks with client caching. \n\n"}
{"id": "1708.04283", "contents": "Title: Key and Message Semantic-Security over State-Dependent Channels Abstract: We study the trade-off between secret message (SM) and secret key (SK) rates,\nsimultaneously achievable over a state-dependent (SD) wiretap channel (WTC)\nwith non-causal channel state information (CSI) at the encoder. This model\nsubsumes other instances of CSI availability as special cases, and calls for\nefficient utilization of the state sequence for both reliability and security\npurposes. An inner bound on the semantic-security (SS) SM-SK capacity region is\nderived based on a superposition coding scheme inspired by a past work of the\nauthors. The region is shown to attain capacity for a certain class of SD-WTCs.\nSS is established by virtue of two versions of the strong soft-covering lemma.\nThe derived region yields an improvement upon the previously best known SM-SK\ntrade-off result reported by Prabhakaran et al., and, to the best of our\nknowledge, upon all other existing lower bounds for either SM or SK for this\nsetup, even if the semantic security requirement is relaxed to weak secrecy. It\nis demonstrated that our region can be strictly larger than those reported in\nthe preceding works. \n\n"}
{"id": "1708.05281", "contents": "Title: Resource Optimization with Load Coupling in Multi-cell NOMA Abstract: Optimizing non-orthogonal multiple access (NOMA) in multi-cell scenarios is\nmuch more challenging than the single-cell case because inter-cell interference\nmust be considered. Most papers addressing NOMA consider a single cell. We take\na significant step of analyzing NOMA in multi-cell scenarios. We explore the\npotential of NOMA networks in achieving optimal resource utilization with\narbitrary topologies. Towards this goal, we investigate a broad class of\nproblems consisting in optimizing power allocation and user pairing for any\ncost function that is monotonically increasing in time-frequency resource\nconsumption. We propose an algorithm that achieves global optimality for this\nproblem class. The basic idea is to prove that solving the joint optimization\nproblem of power allocation, user pair selection, and time-frequency resource\nallocation amounts to solving a so-called iterated function without a closed\nform. We prove that the algorithm approaches optimality with fast convergence.\nNumerically, we evaluate and demonstrate the performance of NOMA for multi-cell\nscenarios in terms of resource efficiency and load balancing. \n\n"}
{"id": "1708.06012", "contents": "Title: Product Matrix Minimum Storage Regenerating Codes with Flexible Number\n  of Helpers Abstract: In coding for distributed storage systems, efficient data reconstruction and\nrepair through accessing a predefined number of arbitrarily chosen storage\nnodes is guaranteed by regenerating codes. Traditionally, code parameters,\nspecially the number of helper nodes participating in a repair process, are\npredetermined. However, depending on the state of the system and network\ntraffic, it is desirable to adapt such parameters accordingly in order to\nminimize the cost of repair. In this work a class of regenerating codes with\nminimum storage is introduced that can simultaneously operate at the optimal\nrepair bandwidth, for a wide range of exact repair mechanisms, based on\ndifferent number of helper nodes. \n\n"}
{"id": "1708.06498", "contents": "Title: A Novel Network NOMA Scheme for Downlink Coordinated Three-Point Systems Abstract: In this paper, we propose a network non-orthogonal multiple access (N-NOMA)\ntechnique for the downlink coordinated multipoint (CoMP) communication scenario\nof a cellular network, with randomly deployed users. In the considered N-NOMA\nscheme, superposition coding (SC) is employed to serve cell-edge users as well\nas users close to base stations (BSs) simultaneously, and distributed analog\nbeamforming by the BSs to meet the cell-edge user's quality of service (QoS)\nrequirements. The combination of SC and distributed analog beamforming\nsignificantly complicates the expressions for the\nsignal-to-interference-plus-noise ratio (SINR) at the reveiver, which makes the\nperformance analysis particularly challenging. However, by using rational\napproximations, insightful analytical results are obtained in order to\ncharacterize the outage performance of the considered N-NOMA scheme. Computer\nsimulation results are provided to show the superior performance of the\nproposed scheme as well as to demonstrate the accuracy of the analytical\nresults. \n\n"}
{"id": "1708.07691", "contents": "Title: Aggregation and Resource Scheduling in Machine-type Communication\n  Networks: A Stochastic Geometry Approach Abstract: Data aggregation is a promising approach to enable massive machine-type\ncommunication (mMTC). This paper focuses on the aggregation phase where a\nmassive number of machine-type devices (MTDs) transmit to aggregators. By using\nnon-orthogonal multiple access (NOMA) principles, we allow several MTDs to\nshare the same orthogonal channel in our proposed hybrid access scheme. We\ndevelop an analytical framework based on stochastic geometry to investigate the\nsystem performance in terms of average success probability and average number\nof simultaneously served MTDs, under imperfect successive interference\ncancellation (SIC) at the aggregators, for two scheduling schemes: random\nresource scheduling (RRS) and channel-aware resource scheduling (CRS). We\nidentify the power constraints on the MTDs sharing the same channel to attain a\nfair coexistence with purely orthogonal multiple access (OMA) setups, then\npower control coefficients are found so that these MTDs perform with similar\nreliability. We show that under high access demand, the hybrid scheme with CRS\noutperforms the OMA setup by simultaneously serving more MTDs with reduced\npower consumption. \n\n"}
{"id": "1708.07862", "contents": "Title: Wireless Access for Ultra-Reliable Low-Latency Communication (URLLC):\n  Principles and Building Blocks Abstract: Ultra-reliable low latency communication (URLLC) is an important new feature\nbrought by 5G, with a potential to support a vast set of applications that rely\non mission-critical links. In this article, we first discuss the principles for\nsupporting URLLC from the perspective of the traditional assumptions and models\napplied in communication/information theory. We then discuss how these\nprinciples are applied in various elements of the system design, such as use of\nvarious diversity sources, design of packets and access protocols. The\nimportant messages are that there is a need to optimize the transmission of\nsignaling information, as well as a need for a lean use of various sources of\ndiversity. \n\n"}
{"id": "1708.08438", "contents": "Title: Nearest-Neighbor and Contact Distance Distributions for Matern Cluster\n  Process Abstract: In this letter, we derive the cumulative density function (CDF) of the\nnearest neighbor and contact distance distributions of the Matern cluster\nprocess (MCP) in R2. These results will be useful in the performance analysis\nof many real-world wireless networks that exhibit inter-node attraction. Using\nthese results, we concretely demonstrate that the contact distance of the MCP\nstochastically dominates its nearest-neighbor distance as well as the contact\ndistance of the homogeneous Poisson point process (PPP) with the same density. \n\n"}
{"id": "1708.09354", "contents": "Title: Quantum-enhanced reinforcement learning for finite-episode games with\n  discrete state spaces Abstract: Quantum annealing algorithms belong to the class of metaheuristic tools,\napplicable for solving binary optimization problems. Hardware implementations\nof quantum annealing, such as the quantum annealing machines produced by D-Wave\nSystems, have been subject to multiple analyses in research, with the aim of\ncharacterizing the technology's usefulness for optimization and sampling tasks.\nHere, we present a way to partially embed both Monte Carlo policy iteration for\nfinding an optimal policy on random observations, as well as how to embed (n)\nsub-optimal state-value functions for approximating an improved state-value\nfunction given a policy for finite horizon games with discrete state spaces on\na D-Wave 2000Q quantum processing unit (QPU). We explain how both problems can\nbe expressed as a quadratic unconstrained binary optimization (QUBO) problem,\nand show that quantum-enhanced Monte Carlo policy evaluation allows for finding\nequivalent or better state-value functions for a given policy with the same\nnumber episodes compared to a purely classical Monte Carlo algorithm.\nAdditionally, we describe a quantum-classical policy learning algorithm. Our\nfirst and foremost aim is to explain how to represent and solve parts of these\nproblems with the help of the QPU, and not to prove supremacy over every\nexisting classical policy evaluation algorithm. \n\n"}
{"id": "1708.09410", "contents": "Title: Secure Communications for the Two-user Broadcast Channel with Random\n  Traffic Abstract: In this work, we study the stability region of the two-user broadcast channel\n(BC) with bursty data arrivals and security constraints. We consider the\nscenario, where one of the receivers has a secrecy constraint and its packets\nneed to be kept secret from the other receiver. This is achieved by employing\nfull-duplexing at the receiver with the secrecy constraint, so that it\ntransmits a jamming signal to impede the reception of the other receiver. In\nthis context, the stability region of the two-user BC is characterized for the\ngeneral decoding case. Then, assuming two different decoding schemes the\nrespective stability regions are derived. The effect of self-interference due\nto the full-duplex operation on the stability region is also investigated. The\nstability region of the BC with a secrecy constraint, where the receivers do\nnot have full duplex capability can be obtained as a special case of the\nresults derived in this paper. In addition, the paper considers the problem of\nmaximizing the saturated throughput of the queue, whose packets does not\nrequire to be kept secret under minimum service guarantees for the other queue.\nThe results provide new insights on the effect of the secrecy constraint on the\nstability region of the BC. In particular, it is shown that the stability\nregion with secrecy constraint is sensitive to the coefficient of\nself-interference cancelation under certain cases. \n\n"}
{"id": "1709.00132", "contents": "Title: A Secure Approach for Caching Contents in Wireless Ad Hoc Networks Abstract: Caching aims to store data locally in some nodes within the network to be\nable to retrieve the contents in shorter time periods. However, caching in the\nnetwork did not always consider secure storage (due to the compromise between\ntime performance and security). In this paper, a novel decentralized secure\ncoded caching approach is proposed. In this solution, nodes only transmit coded\nfiles to avoid eavesdropper wiretapping and protect the user contents. In this\ntechnique random vectors are used to combine the contents using XOR operation.\nWe modeled the proposed coded caching scheme by a Shannon cipher system to show\nthat coded caching achieves asymptotic perfect secrecy. The proposed coded\ncaching scheme significantly simplifies the routing protocol in cached networks\nwhile it reduces over-caching and achieves a higher throughput capacity\ncompared to uncoded caching in reactive routing. It is shown that with the\nproposed coded caching scheme any content can be retrieved by selecting a\nrandom path while achieving asymptotic optimum solution. We have also studied\nthe cache hit probability and shown that the coded cache hit probability is\nsignificantly higher than uncoded caching. A secure caching update algorithm is\nalso presented. \n\n"}
{"id": "1709.01746", "contents": "Title: Information-theoretic analysis of the directional influence between\n  cellular processes Abstract: Inferring the directionality of interactions between cellular processes is a\nmajor challenge in systems biology. Time-lagged correlations allow to\ndiscriminate between alternative models, but they still rely on assumed\nunderlying interactions. Here, we use the transfer entropy (TE), an\ninformation-theoretic quantity that quantifies the directional influence\nbetween fluctuating variables in a model-free way. We present a theoretical\napproach to compute the transfer entropy, even when the noise has an extrinsic\ncomponent or in the presence of feedback. We re-analyze the experimental data\nfrom Kiviet et al. (2014) where fluctuations in gene expression of metabolic\nenzymes and growth rate have been measured in single cells of E. coli. We\nconfirm the formerly detected modes between growth and gene expression, while\nprescribing more stringent conditions on the structure of noise sources. We\nfurthermore point out practical requirements in terms of length of time series\nand sampling time which must be satisfied in order to infer optimally transfer\nentropy from times series of fluctuations. \n\n"}
{"id": "1709.02427", "contents": "Title: Status Updates Through Multicast Networks Abstract: Using age of information as the freshness metric, we examine a multicast\nnetwork in which real-time status updates are generated by the source and sent\nto a group of $n$ interested receivers. We show that in order to keep the\ninformation freshness at each receiver, the source should terminate the\ntransmission of the current update and start sending a new update packet as\nsoon as it receives the acknowledgements back from any $k$ out of $n$ nodes. As\nthe source stopping threshold $k$ increases, a node is more likely to get the\nlatest generated update, but the age of the most recent update is more likely\nto become outdated. We derive the age minimized stopping threshold $k$ that\nbalances the likelihood of getting the latest update and the freshness of the\nlatest update for shifted exponential link delay. Through numerical evaluations\nfor different stopping strategies, we find that waiting for the\nacknowledgements from the earliest $k$ out of $n$ nodes leads to lower average\nage than waiting for a pre-selected group of $k$ nodes. We also observe that a\nproperly chosen threshold $k$ can prevent information staleness for increasing\nnumber of nodes $n$ in the multicast network. \n\n"}
{"id": "1709.02917", "contents": "Title: Sublinear-Time Algorithms for Compressive Phase Retrieval Abstract: In the compressive phase retrieval problem, or phaseless compressed sensing,\nor compressed sensing from intensity only measurements, the goal is to\nreconstruct a sparse or approximately $k$-sparse vector $x \\in \\mathbb{R}^n$\ngiven access to $y= |\\Phi x|$, where $|v|$ denotes the vector obtained from\ntaking the absolute value of $v\\in\\mathbb{R}^n$ coordinate-wise. In this paper\nwe present sublinear-time algorithms for different variants of the compressive\nphase retrieval problem which are akin to the variants considered for the\nclassical compressive sensing problem in theoretical computer science. Our\nalgorithms use pure combinatorial techniques and near-optimal number of\nmeasurements. \n\n"}
{"id": "1709.03541", "contents": "Title: Robust period estimation using mutual information for multi-band light\n  curves in the synoptic survey era Abstract: The Large Synoptic Survey Telescope (LSST) will produce an unprecedented\namount of light curves using six optical bands. Robust and efficient methods\nthat can aggregate data from multidimensional sparsely-sampled time series are\nneeded. In this paper we present a new method for light curve period estimation\nbased on the quadratic mutual information (QMI). The proposed method does not\nassume a particular model for the light curve nor its underlying probability\ndensity and it is robust to non-Gaussian noise and outliers. By combining the\nQMI from several bands the true period can be estimated even when no\nsingle-band QMI yields the period. Period recovery performance as a function of\naverage magnitude and sample size is measured using 30,000 synthetic multi-band\nlight curves of RR Lyrae and Cepheid variables generated by the LSST Operations\nand Catalog simulators. The results show that aggregating information from\nseveral bands is highly beneficial in LSST sparsely-sampled time series,\nobtaining an absolute increase in period recovery rate up to 50%. We also show\nthat the QMI is more robust to noise and light curve length (sample size) than\nthe multiband generalizations of the Lomb Scargle and Analysis of Variance\nperiodograms, recovering the true period in 10-30% more cases than its\ncompetitors. A python package containing efficient Cython implementations of\nthe QMI and other methods is provided. \n\n"}
{"id": "1709.04846", "contents": "Title: Linear Precoding with Low-Resolution DACs for Massive MU-MIMO-OFDM\n  Downlink Abstract: We consider the downlink of a massive multiuser (MU) multiple-input\nmultiple-output (MIMO) system in which the base station (BS) is equipped with\nlow-resolution digital-to-analog converters (DACs). In contrast to most\nexisting results, we assume that the system operates over a frequency-selective\nwideband channel and uses orthogonal frequency division multiplexing (OFDM) to\nsimplify equalization at the user equipments (UEs). Furthermore, we consider\nthe practically relevant case of oversampling DACs. We theoretically analyze\nthe uncoded bit error rate (BER) performance with linear precoders (e.g., zero\nforcing) and quadrature phase-shift keying using Bussgang's theorem. We also\ndevelop a lower bound on the information-theoretic sum-rate throughput\nachievable with Gaussian inputs, which can be evaluated in closed form for the\ncase of 1-bit DACs. For the case of multi-bit DACs, we derive approximate, yet\naccurate, expressions for the distortion caused by low-precision DACs, which\ncan be used to establish lower bounds on the corresponding sum-rate throughput.\nOur results demonstrate that, for a massive MU-MIMO-OFDM system with a\n128-antenna BS serving 16 UEs, only 3--4 DAC bits are required to achieve an\nuncoded BER of 10^-4 with a negligible performance loss compared to the\ninfinite-resolution case at the cost of additional out-of-band emissions.\nFurthermore, our results highlight the importance of taking into account the\ninherent spatial and temporal correlations caused by low-precision DACs. \n\n"}
{"id": "1709.05733", "contents": "Title: The Stochastic Geometry Analyses of Cellular Networks with\n  {\\alpha}-Stable Self-Similarity Abstract: To understand the spatial deployment of base stations (BSs) is the first step\nto analyze the performance of cellular networks and further design efficient\nnetworking protocols. Poisson point process (PPP), which has been widely\nadopted to characterize the deployment of BSs and established the reputation to\ngive tractable results in the stochastic geometry analyses, usually assumes a\nstatic BS deployment density in homogeneous PPP (HPPP) models or delicately\ndesigned location-dependent density functions in in-homogeneous PPP (IPPP)\nmodels. However, the simultaneous existence of attractiveness and repulsiveness\namong BSs practically deployed in a large-scale area defies such an assumption,\nand the $\\alpha$-stable distribution, one kind of heavy-tailed distributions,\nhas recently demonstrated superior accuracy to statistically model the varying\nBS density in different areas. In this paper, we start with these new findings\nand investigate the intrinsic feature (i.e., the spatial self-similarity)\nembedded in the BSs. Afterwards, we refer to a generalized PPP setup with\n$\\alpha$-stable distributed density and theoretically derive the related\ncoverage probability. In particular, we give an upper bound of the derived\ncoverage probability for high signal-to-interference-plus-noise ratio (SINR)\nthresholds and show the monotonically decreasing property of this bound with\nrespect to the variance of BS density. Besides, we prove that our model could\nreduce to the single-tier HPPP for some special cases, and demonstrate the\nsuperior accuracy of the $\\alpha$-stable model to approach the real\nenvironment. \n\n"}
{"id": "1709.05907", "contents": "Title: A Generalized Framework for Kullback-Leibler Markov Aggregation Abstract: This paper proposes an information-theoretic cost function for aggregating a\nMarkov chain via a (possibly stochastic) mapping. The cost function is\nmotivated by two objectives: 1) The process obtained by observing the Markov\nchain through the mapping should be close to a Markov chain, and 2) the\naggregated Markov chain should retain as much of the temporal dependence\nstructure of the original Markov chain as possible. We discuss properties of\nthis parameterized cost function and show that it contains the cost functions\npreviously proposed by Deng et al., Xu et al., and Geiger et al. as special\ncases. We moreover discuss these special cases providing a better understanding\nand highlighting potential shortcomings: For example, the cost function\nproposed by Geiger et al. is tightly connected to approximate probabilistic\nbisimulation, but leads to trivial solutions if optimized without\nregularization. We furthermore propose a simple heuristic to optimize our cost\nfunction for deterministic aggregations and illustrate its performance on a set\nof synthetic examples. \n\n"}
{"id": "1709.08265", "contents": "Title: Any strongly controllable group system or group shift or any linear\n  block code is a linear system whose input is a generator group Abstract: Consider any sequence of finite groups $A^t$, where $t$ takes values in an\ninteger index set $\\mathbf{Z}$. A group system $A$ is a set of sequences with\ncomponents in $A^t$ that forms a group under componentwise addition in $A^t$,\nfor each $t\\in\\mathbf{Z}$. In the setting of group systems, a natural\ndefinition of a linear system is a homomorphism from a group of inputs to an\noutput group system $A$. We show that any group can be the input group of a\nlinear system and some group system. In general the kernel of the homomorphism\nis nontrivial. We show that any $\\ell$-controllable complete group system $A$\nis a linear system whose input group is a generator group\n$({\\mathcal{U}},\\circ)$, deduced from $A$, and then the kernel is always\ntrivial. The input set ${\\mathcal{U}}$ is a set of tensors, a double Cartesian\nproduct space of sets $R_{0,k}^t$, with indices $k$, for $0\\le k\\le\\ell$, and\ntime $t$, for $t\\in\\mathbf{Z}$. $R_{0,k}^t$ is a set of unique generator labels\nfor the generators in $A$ with nontrivial span for the time interval $[t,t+k]$.\nWe show the generator group contains an elementary system, an infinite\ncollection of elementary groups, one for each $k$ and $t$, defined on small\nsubsets of ${\\mathcal{U}}$, in the shape of triangles, which form a tile like\nstructure over ${\\mathcal{U}}$. There is a homomorphism from each elementary\ngroup to any elementary group defined on smaller tiles of the former group. Any\nelementary system is sufficient to define a unique generator group up to\nisomorphism, and therefore is sufficient to construct a linear system and group\nsystem as well. Any linear block code is a strongly controllable group system.\nThen we can obtain new results on the structure of block codes using the\ngenerator group. There is a harmonic theory of group systems which we study\nusing the generator group. \n\n"}
{"id": "1709.08577", "contents": "Title: Coverage Analysis of a Vehicular Network Modeled as Cox Process Driven\n  by Poisson Line Process Abstract: In this paper, we consider a vehicular network in which the wireless nodes\nare located on a system of roads. We model the roadways, which are\npredominantly straight and randomly oriented, by a Poisson line process (PLP)\nand the locations of nodes on each road as a homogeneous 1D Poisson point\nprocess (PPP). Assuming that each node transmits independently, the locations\nof transmitting and receiving nodes are given by two Cox processes driven by\nthe same PLP. For this setup, we derive the coverage probability of a typical\nreceiver, which is an arbitrarily chosen receiving node, assuming independent\nNakagami-$m$ fading over all wireless channels. Assuming that the typical\nreceiver connects to its closest transmitting node in the network, we first\nderive the distribution of the distance between the typical receiver and the\nserving node to characterize the desired signal power. We then characterize\ncoverage probability for this setup, which involves two key technical\nchallenges. First, we need to handle several cases as the serving node can\npossibly be located on any line in the network and the corresponding\ninterference experienced at the typical receiver is different in each case.\nSecond, conditioning on the serving node imposes constraints on the spatial\nconfiguration of lines, which require careful analysis of the conditional\ndistribution of the lines. We address these challenges in order to accurately\ncharacterize the interference experienced at the typical receiver. We then\nderive an exact expression for coverage probability in terms of the derivative\nof Laplace transform of interference power distribution. We analyze the trends\nin coverage probability as a function of the network parameters: line density\nand node density. We also study the asymptotic behavior of this model and\ncompare the coverage performance with that of a homogeneous 2D PPP model with\nthe same node density. \n\n"}
{"id": "1709.10119", "contents": "Title: Distributed Join-the-Idle-Queue for Low Latency Cloud Services Abstract: Low latency is highly desirable for cloud services. To achieve low response\ntime, stringent timing requirements are needed for task scheduling in a\nlarge-scale server farm spanning thousands of servers. In this paper, we\nconduct an in-depth analysis for distributed Join-the-Idle-Queue (JIQ), a\npromising new approximation of an idealized task-scheduling algorithm. In\nparticular, we derive semi-closed form expressions for the delay performance of\ndistributed JIQ, and we propose a new variant of distributed JIQ that offers\nclear advantages over alternative algorithms for large systems. \n\n"}
{"id": "1710.00395", "contents": "Title: Channel Hardening and Favorable Propagation in Cell-Free Massive MIMO\n  with Stochastic Geometry Abstract: Cell-Free (CF) Massive MIMO is an alternative topology for future wireless\nnetworks, where a large number of single-antenna access points (APs) are\ndistributed over the coverage area. There are no cells but all users are\njointly served by the APs using network MIMO methods. Prior works have claimed\nthat CF Massive MIMO inherits the basic properties of cellular Massive MIMO,\nnamely channel hardening and favorable propagation. In this paper, we evaluate\nif one can rely on these properties when having a realistic stochastic AP\ndeployment. Our results show that channel hardening only appears in special\ncases, for example, when the pathloss exponent is small. However, by using\n5--10 antennas per AP, instead of one, we can substantially improve the\nhardening. Only spatially well-separated users will exhibit favorable\npropagation, but when adding more antennas and/or reducing the pathloss\nexponent, it becomes more likely for favorable propagation to occur. The\nconclusion is that we cannot rely on channel hardening and favorable\npropagation when analyzing and designing CF Massive MIMO networks, but we need\nto use achievable rate expressions and resource allocation schemes that work\nwell also in the absence of these properties. Some options are reviewed in this\npaper. \n\n"}
{"id": "1710.03109", "contents": "Title: Skew and linearized Reed-Solomon codes and maximum sum rank distance\n  codes over any division ring Abstract: Reed-Solomon codes and Gabidulin codes have maximum Hamming distance and\nmaximum rank distance, respectively. A general construction using skew\npolynomials, called skew Reed-Solomon codes, has already been introduced in the\nliterature. In this work, we introduce a linearized version of such codes,\ncalled linearized Reed-Solomon codes. We prove that they have maximum sum-rank\ndistance. Such distance is of interest in multishot network coding or in\nsingleshot multi-network coding. To prove our result, we introduce new metrics\ndefined by skew polynomials, which we call skew metrics, we prove that skew\nReed-Solomon codes have maximum skew distance, and then we translate this\nscenario to linearized Reed-Solomon codes and the sum-rank metric. The theories\nof Reed-Solomon codes and Gabidulin codes are particular cases of our theory,\nand the sum-rank metric extends both the Hamming and rank metrics. We develop\nour theory over any division ring (commutative or non-commutative field). We\nalso consider non-zero derivations, which give new maximum rank distance codes\nover infinite fields not considered before. \n\n"}
{"id": "1710.03287", "contents": "Title: One-bit compressed sensing with partial Gaussian circulant matrices Abstract: In this paper we consider memoryless one-bit compressed sensing with randomly\nsubsampled Gaussian circulant matrices. We show that in a small sparsity regime\nand for small enough accuracy $\\delta$, $m\\sim \\delta^{-4} s\\log(N/s\\delta)$\nmeasurements suffice to reconstruct the direction of any $s$-sparse vector up\nto accuracy $\\delta$ via an efficient program. We derive this result by proving\nthat partial Gaussian circulant matrices satisfy an $\\ell_1/\\ell_2$\nRIP-property. Under a slightly worse dependence on $\\delta$, we establish\nstability with respect to approximate sparsity, as well as full vector recovery\nresults. \n\n"}
{"id": "1710.05063", "contents": "Title: A Distributed Auction Policy for User Association in Device-to-Device\n  Caching Networks Abstract: We propose a distributed bidding-aided Matern carrier sense multiple access\n(CSMA) policy for device-to-device (D2D) content distribution. The network is\ncomposed of D2D receivers and potential D2D transmitters, i.e., transmitters\nare turned on or off by the scheduling algorithm. Each D2D receiver determines\nthe value of its request, by bidding on the set of potential transmitters in\nits communication range. Given a medium access probability, a fraction of the\npotential transmitters are jointly scheduled, i.e., turned on, determined\njointly by the auction policy and the power control scheme. The bidding-aided\nscheduling algorithm exploits (i) the local demand distribution, (ii) spatial\ndistribution of D2D node locations, and (iii) the cache configurations of the\npotential transmitters. We contrast the performance of the bidding-aided CSMA\npolicy with other well-known CSMA schemes that do not take into account\n(i)-(iii), demonstrate that our algorithm achieves a higher spectral efficiency\nin terms of the number of bits transmitted per unit time per unit bandwidth per\nuser. The gain becomes even more visible under randomized configurations and\nrequests rather than more skewed placement configurations and deterministic\ndemand distributions. \n\n"}
{"id": "1710.06094", "contents": "Title: Multi-Tenant C-RAN With Spectrum Pooling: Downlink Optimization Under\n  Privacy Constraints Abstract: Spectrum pooling allows multiple operators, or tenants, to share the same\nfrequency bands. This work studies the optimization of spectrum pooling for the\ndownlink of a multi-tenant Cloud Radio Access Network (C-RAN) system in the\npresence of inter-tenant privacy constraints. The spectrum available for\ndownlink transmission is partitioned into private and shared subbands, and the\nparticipating operators cooperate to serve the user equipments (UEs) on the\nshared subband. The network of each operator consists of a cloud processor (CP)\nthat is connected to proprietary radio units (RUs) by means of finite-capacity\nfronthaul links. In order to enable interoperator cooperation, the CPs of the\nparticipating operators are also connected by finite-capacity backhaul links.\nInter-operator cooperation may hence result in loss of privacy. Fronthaul and\nbackhaul links are used to transfer quantized baseband signals. Standard\nquantization is considered first. Then, a novel approach based on the idea of\ncorrelating quantization noise signals across RUs of different operators is\nproposed to control the trade-off between distortion at UEs and inter-operator\nprivacy. The problem of optimizing the bandwidth allocation, precoding, and\nfronthaul/backhaul compression strategies is tackled under constraints on\nbackhaul and fronthaul capacity, as well as on per-RU transmit power and\ninter-operator privacy. For both cases, the optimization problems are tackled\nusing the concave convex procedure (CCCP), and extensive numerical results are\nprovided. \n\n"}
{"id": "1710.06255", "contents": "Title: Integrated mmWave Access and Backhaul in 5G: Bandwidth Partitioning and\n  Downlink Analysis Abstract: With the increasing network densification, it has become exceedingly\ndifficult to provide traditional fiber backhaul access to each cell site, which\nis especially true for small cell base stations (SBSs). The increasing maturity\nof millimeter wave (mmWave) communication has opened up the possibility of\nproviding high-speed wireless backhaul to such cell sites. Since mmWave is also\nsuitable for access links, the third generation partnership project (3GPP) is\nenvisioning an integrated access and backhaul (IAB) architecture for the fifth\ngeneration (5G) cellular networks in which the same infrastructure and spectral\nresources will be used for both access and backhaul. In this paper, we develop\nan analytical framework for IAB-enabled cellular network using which we provide\nan accurate characterization of its downlink rate coverage probability. Using\nthis, we study the performance of two backhaul bandwidth (BW) partition\nstrategies, (i) equal partition: when all SBSs obtain equal share of the\nbackhaul BW, and (ii) load-based partition: when the backhaul BW share of an\nSBS is proportional to its load. Our analysis shows that depending on the\nchoice of the partition strategy, there exists an optimal split of access and\nbackhaul BW for which the rate coverage is maximized. Further, there exists a\ncritical volume of cell-load (total number of users) beyond which the gains\nprovided by the IAB-enabled network disappear and its performance converges to\nthat of the traditional macro-only network with no SBSs. \n\n"}
{"id": "1710.07153", "contents": "Title: Generalized Water-filling for Source-aware Energy-efficient SRAMs Abstract: Conventional low-power static random access memories (SRAMs) reduce read\nenergy by decreasing the bit-line voltage swings uniformly across the bit-line\ncolumns. This is because the read energy is proportional to the bit-line\nswings. On the other hand, bit-line swings are limited by the need to avoid\ndecision errors especially in the most significant bits. We propose an\ninformation-theoretic approach to determine optimal non-uniform bit-line swings\nby formulating convex optimization problems. For a given constraint on mean\nsquared error of retrieved words, we consider criteria to minimize energy (for\nlow-power SRAMs), maximize speed (for high-speed SRAMs), and minimize\nenergy-delay product. These optimization problems can be interpreted as\nclassical water-filling, ground-flattening and water-filling, and sand-pouring\nand water-filling, respectively. By leveraging these interpretations, we also\npropose greedy algorithms to obtain optimized discrete swings. Numerical\nresults show that energy-optimal swing assignment reduces energy consumption by\nhalf at a peak signal-to-noise ratio of 30dB for an 8-bit accessed word. The\nenergy savings increase to four times for a 16-bit accessed word. \n\n"}
{"id": "1710.07319", "contents": "Title: Atypicality for Heart Rate Variability Using a Pattern-Tree Weighting\n  Method Abstract: Heart rate variability (HRV) is a vital measure of the autonomic nervous\nsystem functionality and a key indicator of cardiovascular condition. This\npaper proposes a novel method, called pattern tree which is an extension of\nWillem's context tree to real-valued data, to investigate HRV via an\natypicality framework. In a previous paper atypicality was developed as method\nfor mining and discovery in \"Big Data,\" which requires a universal approach.\nUsing the proposed pattern tree as a universal source coder in this framework\nled to discovery of arrhythmias and unknown patterns in HRV Holter Monitoring. \n\n"}
{"id": "1710.08214", "contents": "Title: Parametric channel estimation for massive MIMO Abstract: Channel state information is crucial to achieving the capacity of\nmulti-antenna (MIMO) wireless communication systems. It requires estimating the\nchannel matrix. This estimation task is studied, considering a sparse channel\nmodel particularly suited to millimeter wave propagation, as well as a general\nmeasurement model taking into account hybrid architectures. The contribution is\ntwofold. First, the Cram{\\'e}r-Rao bound in this context is derived. Second,\ninterpretation of the Fisher Information Matrix structure allows to assess the\nrole of system parameters, as well as to propose asymptotically optimal and\ncomputationally efficient estimation algorithms. \n\n"}
{"id": "1710.11370", "contents": "Title: Capacity-Achieving PIR Schemes with Optimal Sub-Packetization Abstract: Suppose a database containing $M$ records is replicated across $N$ servers,\nand a user wants to privately retrieve one record by accessing the servers such\nthat identity of the retrieved record is secret against any up to $T$ servers.\nA scheme designed for this purpose is called a private information retrieval\n(PIR) scheme. In practice, capacity-achieving and small sub-packetization are\nboth desired for PIR schemes, because the former implies the highest download\nrate and the latter usually means simple realization.\n  For general values of $N,T,M$, the only known capacity-achieving PIR scheme\nwas designed by Sun and Jafar in 2016 with sub-packetization $N^M$. In this\npaper, we design a linear capacity-achieving PIR scheme with much smaller\nsub-packetization $dn^{M-1}$, where $d={\\rm gcd}(N,T)$ and $n=N/d$.\nFurthermore, we prove that for any linear capacity-achieving PIR scheme it must\nhave sub-packetization no less than $dn^{M-1}$, implying our scheme has the\noptimal sub-packetization. Moreover, comparing with Sun and Jafar's scheme, our\nscheme reduces the field size by a factor of $\\frac{1}{Nd^{M-2}}$. \n\n"}
{"id": "1711.01110", "contents": "Title: A Rudimentary Model for Low-Latency Anonymous Communication Systems Abstract: In this paper we present a rudimentary model for low-latency anonymous\ncommunication systems. Specifically, we study distributed OR algorithm as an\nabstract of the system. Based on our model, we give several satisfactory lower\nbounds of anonymity leakage of a deterministic OR algorithm. Some of them\nreveal a trade-off between anonymity and communication complexity. For the\nrandomized OR algorithm, we only give a relatively trivial but possibly tight\nlower bound when leaving out communication complexity. And we find the\nrelationship between our model and some open case in the study of secret\nsharing scheme, if considering communication complexity. \n\n"}
{"id": "1711.01938", "contents": "Title: Single-Carrier Modulation versus OFDM for Millimeter-Wave Wireless MIMO Abstract: This paper presents results on the achievable spectral efficiency and on the\nenergy efficiency for a wireless multiple-input-multiple-output (MIMO) link\noperating at millimeter wave frequencies (mmWave) in a typical 5G scenario. Two\ndifferent single-carrier modem schemes are considered, i.e., a traditional\nmodulation scheme with linear equalization at the receiver, and a\nsingle-carrier modulation with cyclic prefix, frequency-domain equalization and\nFFT-based processing at the receiver; these two schemes are compared with a\nconventional MIMO-OFDM transceiver structure. Our analysis jointly takes into\naccount the peculiar characteristics of MIMO channels at mmWave frequencies,\nthe use of hybrid (analog-digital) pre-coding and post-coding beamformers, the\nfinite cardinality of the modulation structure, and the non-linear behavior of\nthe transmitter power amplifiers. Our results show that the best performance is\nachieved by single-carrier modulation with time-domain equalization, which\nexhibits the smallest loss due to the non-linear distortion, and whose\nperformance can be further improved by using advanced equalization schemes.\nResults also confirm that performance gets severely degraded when the link\nlength exceeds 90-100 meters and the transmit power falls below 0 dBW. \n\n"}
{"id": "1711.02030", "contents": "Title: Towards Optimal Energy Harvesting Receiver Design in MIMO Systems Abstract: In this paper, we investigate a multiple-input multiple-output (MIMO) system\nwith simultaneous information detection (ID) and energy harvesting (EH)\nreceiver. This point-to-point system operates in the vicinity of active\ninterfering nodes. The receiver performs power splitting where a portion of\nreceived signal undergoes analog energy harvesting circuitry. Further, the\ninformation content of the other portion is extracted after performing digital\nbeamforming. In this MIMO system, information carrier eigen-modes are not\nnecessarily the eigen-modes with the strongest energy level. Hence, it is\nbeneficial to perform independent beamforming at the receiver of MIMO-P2P\nchannel. Here, we utilize a hybrid analog/digital beamforming for the purpose\nof simultaneous ID and EH in such scenarios. This design, provides extra design\ndegrees-of-freedom in eigen-mode selection for ID and EH purposes\nindependently. Worst-case performance of this receiver structure is discussed.\nFinally, its benefits is compared to the classical receiver structure and the\ngains are highlighted. \n\n"}
{"id": "1711.02056", "contents": "Title: Throughput Maximization for Delay-Sensitive Random Access Communication Abstract: Future 5G cellular networks supporting ultra-reliable, low-latency\ncommunications (URLLC) could employ random access communication to reduce the\noverhead compared to scheduled access techniques used in 4G networks. We\nconsider a wireless communication system where multiple devices transmit\npayloads of a given fixed size in a random access fashion over shared radio\nresources to a common receiver. We allow retransmissions and assume Chase\ncombining at the receiver. The radio resources are partitioned in the time and\nfrequency dimensions, and we determine the optimal partition granularity to\nmaximize throughput, subject to given constraints on latency and outage. In the\nregime of high and low signal-to-noise ratio (SNR), we derive explicit\nexpressions for the granularity and throughput, first using a Shannon capacity\napproximation and then using finite block length analysis. Numerical results\nshow that the throughput scaling results are applicable over a range of SNRs.\nThe proposed analytical framework can provide insights for resource allocation\nstrategies in general random access systems and in specific 5G use cases for\nmassive URLLC uplink access. \n\n"}
{"id": "1711.04819", "contents": "Title: Uncertainty quantification for radio interferometric imaging: II. MAP\n  estimation Abstract: Uncertainty quantification is a critical missing component in radio\ninterferometric imaging that will only become increasingly important as the\nbig-data era of radio interferometry emerges. Statistical sampling approaches\nto perform Bayesian inference, like Markov Chain Monte Carlo (MCMC) sampling,\ncan in principle recover the full posterior distribution of the image, from\nwhich uncertainties can then be quantified. However, for massive data sizes,\nlike those anticipated from the Square Kilometre Array (SKA), it will be\ndifficult if not impossible to apply any MCMC technique due to its inherent\ncomputational cost. We formulate Bayesian inference problems with\nsparsity-promoting priors (motivated by compressive sensing), for which we\nrecover maximum a posteriori (MAP) point estimators of radio interferometric\nimages by convex optimisation. Exploiting recent developments in the theory of\nprobability concentration, we quantify uncertainties by post-processing the\nrecovered MAP estimate. Three strategies to quantify uncertainties are\ndeveloped: (i) highest posterior density credible regions; (ii) local credible\nintervals (cf. error bars) for individual pixels and superpixels; and (iii)\nhypothesis testing of image structure. These forms of uncertainty\nquantification provide rich information for analysing radio interferometric\nobservations in a statistically robust manner. Our MAP-based methods are\napproximately $10^5$ times faster computationally than state-of-the-art MCMC\nmethods and, in addition, support highly distributed and parallelised\nalgorithmic structures. For the first time, our MAP-based techniques provide a\nmeans of quantifying uncertainties for radio interferometric imaging for\nrealistic data volumes and practical use, and scale to the emerging big-data\nera of radio astronomy. \n\n"}
{"id": "1711.06600", "contents": "Title: On optimal coding of non-linear dynamical systems Abstract: We consider the problem of zero-delay coding of a dynamical system over a\ndiscrete noiseless channel under three estimation criteria concerned with the\nlow-distortion regime. For these three criteria, formulated stochastically in\nterms of a probability distribution for the initial state, we characterize the\nsmallest channel capacities above which the estimation objectives can be\nachieved. The results establish further connections between topological and\nmetric entropy of dynamical systems and information theory. \n\n"}
{"id": "1711.07457", "contents": "Title: Unimodality-Constrained Matrix Factorization for Non-Parametric Source\n  Localization Abstract: Herein, the problem of simultaneous localization of multiple sources given a\nnumber of energy samples at different locations is examined. The strategies do\nnot require knowledge of the signal propagation models, nor do they exploit the\nspatial signatures of the source. A non-parametric source localization\nframework based on a matrix observation model is developed. It is shown that\nthe source location can be estimated by localizing the peaks of a pair of\nlocation signature vectors extracted from the incomplete energy observation\nmatrix. A robust peak localization algorithm is developed and shown to decrease\nthe source localization mean squared error (MSE) faster than O(1/M^1.5) with M\nsamples, when there is no measurement noise. To extract the source signature\nvectors from a matrix with mixed energy from multiple sources, a\nunimodality-constrained matrix factorization (UMF) problem is formulated, and\ntwo rotation techniques are developed to solve the UMF efficiently. Our\nnumerical experiments demonstrate that the proposed scheme achieves similar\nperformance as the kernel regression baseline using only 1/5 energy measurement\nsamples in detecting a single source, and the performance gain is more\nsignificant in the cases of detecting multiple sources. \n\n"}
{"id": "1711.07805", "contents": "Title: Approaching Miscorrection-free Performance of Product and Generalized\n  Product Codes Abstract: Product codes (PCs) protect a two-dimensional array of bits using short\ncomponent codes. Assuming transmission over the binary symmetric channel, the\ndecoding is commonly performed by iteratively applying bounded-distance\ndecoding to the component codes. For this coding scheme, undetected errors in\nthe component decoding-also known as miscorrections-significantly degrade the\nperformance. In this paper, we propose a novel iterative decoding algorithm for\nPCs which can detect and avoid most miscorrections. The algorithm can also be\nused to decode many recently proposed classes of generalized PCs such as\nstaircase, braided, and half-product codes. Depending on the component code\nparameters, our algorithm significantly outperforms the conventional iterative\ndecoding method. As an example, for double-error-correcting\nBose-Chaudhuri-Hocquenghem component codes, the net coding gain can be\nincreased by up to 0.4 dB. Moreover, the error floor can be lowered by orders\nof magnitude, up to the point where the decoder performs virtually identical to\na genie-aided decoder that avoids all miscorrections. We also discuss\npost-processing techniques that can be used to reduce the error floor even\nfurther. \n\n"}
{"id": "1711.08408", "contents": "Title: Hybrid Analog and Digital Beamforming for mmWave OFDM Large-Scale\n  Antenna Arrays Abstract: Hybrid analog and digital beamforming is a promising candidate for\nlarge-scale mmWave MIMO systems because of its ability to significantly reduce\nthe hardware complexity of the conventional fully-digital beamforming schemes\nwhile being capable of approaching the performance of fully-digital schemes.\nMost of the prior work on hybrid beamforming considers narrowband channels.\nHowever, broadband systems such as mmWave systems are frequency-selective. In\nbroadband systems, it is desirable to design common analog beamformer for the\nentire band while employing different digital beamformers in different\nfrequency sub-bands. This paper considers hybrid beamforming design for systems\nwith OFDM modulation. First, for a SU-MIMO system where the hybrid beamforming\narchitecture is employed at both transmitter and receiver, we show that hybrid\nbeamforming with a small number of RF chains can asymptotically approach the\nperformance of fully-digital beamforming for a sufficiently large number of\ntransceiver antennas due to the sparse nature of the mmWave channels. For\nsystems with a practical number of antennas, we then propose a unified\nheuristic design for two different hybrid beamforming structures, the\nfully-connected and the partially-connected structures, to maximize the overall\nspectral efficiency of a mmWave MIMO system. Numerical results are provided to\nshow that the proposed algorithm outperforms the existing hybrid beamforming\nmethods and for the fully-connected architecture the proposed algorithm can\nachieve spectral efficiency very close to that of the optimal fully-digital\nbeamforming but with much fewer RF chains. Second, for the MU-MISO case, we\npropose a heuristic hybrid percoding design to maximize the weighted sum rate\nin the downlink and show numerically that the proposed algorithm with practical\nnumber of RF chains can already approach the performance of fully-digital\nbeamforming. \n\n"}
{"id": "1711.09888", "contents": "Title: Distributed Convergence Verification for Gaussian Belief Propagation Abstract: Gaussian belief propagation (BP) is a computationally efficient method to\napproximate the marginal distribution and has been widely used for inference\nwith high dimensional data as well as distributed estimation in large-scale\nnetworks. However, the convergence of Gaussian BP is still an open issue.\nThough sufficient convergence conditions have been studied in the literature,\nverifying these conditions requires gathering all the information over the\nwhole network, which defeats the main advantage of distributed computing by\nusing Gaussian BP. In this paper, we propose a novel sufficient convergence\ncondition for Gaussian BP that applies to both the pairwise linear Gaussian\nmodel and to Gaussian Markov random fields. We show analytically that this\nsufficient convergence condition can be easily verified in a distributed way\nthat satisfies the network topology constraint. \n\n"}
{"id": "1711.10783", "contents": "Title: Partial Consensus and Conservative Fusion of Gaussian Mixtures for\n  Distributed PHD Fusion Abstract: We propose a novel consensus notion, called \"partial consensus\", for\ndistributed GM-PHD (Gaussian mixture probability hypothesis density) fusion\nbased on a peer-to-peer (P2P) sensor network, in which only highly-weighted\nposterior Gaussian components (GCs) are disseminated in the P2P communication\nfor fusion while the insignificant GCs are not involved. The partial consensus\ndoes not only enjoy high efficiency in both network communication and local\nfusion computation, but also significantly reduces the affect of potential\nfalse data (clutter) to the filter, leading to increased signal-to-noise ratio\nat local sensors. Two \"conservative\" mixture reduction schemes are advocated\nfor fusing the shared GCs in a fully distributed manner. One is given by\npairwise averaging GCs between sensors based on Hungarian assignment and the\nother is merging close GCs based a new GM merging scheme. The proposed\napproaches have a close connection to the conservative fusion approaches known\nas covariance union and arithmetic mean density. In parallel, average consensus\nis sought on the cardinality distribution (namely the GM weight sum) among\nsensors. Simulations for tracking either a single target or multiple targets\nthat simultaneously appear are presented based on a sensor network where each\nsensor operates a GM-PHD filter, in order to compare our approaches with the\nbenchmark generalized covariance intersection approach. The results demonstrate\nthat the partial, arithmetic average, consensus outperforms the complete,\ngeometric average, consensus. \n\n"}
{"id": "1712.00703", "contents": "Title: Diffusion Adaptation Framework for Compressive Sensing Reconstruction Abstract: Compressive sensing(CS) has drawn much attention in recent years due to its\nlow sampling rate as well as high recovery accuracy. As an important procedure,\nreconstructing a sparse signal from few measurement data has been intensively\nstudied. Many reconstruction algorithms have been proposed and shown good\nreconstruction performance. However, when dealing with large-scale sparse\nsignal reconstruction problem, the storage requirement will be high, and many\nalgorithms also suffer from high computational cost. In this paper, we propose\na novel diffusion adaptation framework for CS reconstruction, where the\nreconstruction is performed in a distributed network. The data of measurement\nmatrix are partitioned into small parts and are stored in each node, which\nassigns the storage load in a decentralized manner. The local information\ninteraction provides the reconstruction ability. Then, a simple and efficient\ngradient-descend based diffusion algorithm has been proposed to collaboratively\nrecover the sparse signal over network. The convergence of the proposed\nalgorithm is analyzed. To further increase the convergence speed, a mini-batch\nbased diffusion algorithm is also proposed. Simulation results show that the\nproposed algorithms can achieve good reconstruction accuracy as well as fast\nconvergence speed. \n\n"}
{"id": "1712.02466", "contents": "Title: On Sub-Packetization and Access Number of Capacity-Achieving PIR Schemes\n  for MDS Coded Non-Colluding Servers Abstract: Consider the problem of private information retrieval (PIR) over a\ndistributed storage system where $M$ records are stored across $N$ servers by\nusing an $[N,K]$ MDS code. For simplicity, this problem is usually referred as\nthe coded PIR problem. In 2016, Banawan and Ulukus designed the first\ncapacity-achieving coded PIR scheme with sub-packetization $KN^{M}$ and access\nnumber $MKN^{M}$, where capacity characterizes the minimal download size for\nretrieving per unit of data, and sub-packetization and access number are two\nmetrics closely related to implementation complexity. In this paper, we focus\non minimizing the sub-packetization and the access number for linear\ncapacity-achieving coded PIR schemes. We first determine the lower bounds on\nsub-packetization and access number, which are $Kn^{M-1}$ and $MKn^{M-1}$,\nrespectively, in the nontrivial cases (i.e. $N\\!>\\!K\\!\\geq\\!1$ and $M\\!>\\!1$),\nwhere $n\\!=\\!N/{\\rm gcd}(N,K)$. We then design a general linear\ncapacity-achieving coded PIR scheme to simultaneously attain these two bounds,\nimplying tightness of both bounds. \n\n"}
{"id": "1712.03310", "contents": "Title: Maximum entropy low-rank matrix recovery Abstract: We propose in this paper a novel, information-theoretic method, called\nMaxEnt, for efficient data acquisition for low-rank matrix recovery. This\nproposed method has important applications to a wide range of problems,\nincluding image processing and text document indexing. Fundamental to our\ndesign approach is the so-called maximum entropy principle, which states that\nthe measurement masks which maximize the entropy of observations, also maximize\nthe information gain on the unknown matrix $\\mathbf{X}$. Coupled with a\nlow-rank stochastic model for $\\mathbf{X}$, such a principle (i) reveals novel\nconnections between information-theoretic sampling and subspace packings, and\n(ii) yields efficient mask construction algorithms for matrix recovery, which\nsignificantly outperforms random measurements. We illustrate the effectiveness\nof MaxEnt in simulation experiments, and demonstrate its usefulness in two\nreal-world applications on image recovery and text document indexing. \n\n"}
{"id": "1712.03314", "contents": "Title: Efficient Data Collection Over Multiple Access Wireless Sensors Network Abstract: Data collection in Wireless Sensor Networks (WSN) draws significant\nattention, due to emerging interest in technologies raging from Internet of\nThings (IoT) networks to simple \"Presence\" applications, which identify the\nstatus of the devices (active or inactive). Numerous Medium Access Control\n(MAC) protocols for WSN, which can address the challenge of data collection in\ndense networks, were suggested over the years. Most of these protocols utilize\nthe traditional layering approach, in which the MAC layer is unaware of the\nencapsulated packet payload, and therefore there is no connection between the\ndata collected, the physical layer and the signaling mechanisms. Nonetheless,\nin many of the applications that intend to utilize such protocols, nodes may\nneed to exchange very little information, and do so only sporadically, that is,\nwhile the number of devices in the network can be very large, only a subset\nwishes to transmit at any given time. Thus, a tailored protocol, which matches\nthe signaling, physical layer and access control to traffic patterns is\nrequired.\n  In this work, we design and analyze a data collection protocol based on\ninformation theoretic principles. In the suggested protocol, the sink collects\nmessages from up to K sensors simultaneously, out of a large population of\nsensors, without knowing in advance which sensors will transmit, and without\nrequiring any synchronization, coordination or management overhead. In other\nwords, neither the sink nor the other sensors need to know who are the actively\ntransmitting sensors, and this data is decoded directly from the channel\noutput. We provide a simple codebook construction with very simple encoding and\ndecoding procedures. We further design a secure version of the protocol. \n\n"}
{"id": "1712.03433", "contents": "Title: Caching and Coded Delivery over Gaussian Broadcast Channels for Energy\n  Efficiency Abstract: A cache-aided $K$-user Gaussian broadcast channel (BC) is considered. The\ntransmitter has a library of $N$ equal-rate files, from which each user demands\none. The impact of the equal-capacity receiver cache memories on the minimum\nrequired transmit power to satisfy all user demands is studied. Considering\nuniformly random demands across the library, both the minimum average power\n(averaged over all demand combinations) and the minimum peak power (minimum\npower required to satisfy all demand combinations) are studied. Upper bounds\nare presented on the minimum required average and peak transmit power as a\nfunction of the cache capacity considering both centralized and decentralized\ncaching. The lower bounds on the minimum required average and peak power values\nare also derived assuming uncoded cache placement. The bounds for both the peak\nand average power values are shown to be tight in the centralized scenario\nthrough numerical simulations. The results in this paper show that proactive\ncaching and coded delivery can provide significant energy savings in wireless\nnetworks. \n\n"}
{"id": "1712.04462", "contents": "Title: Online radio interferometric imaging: assimilating and discarding\n  visibilities on arrival Abstract: The emerging generation of radio interferometric (RI) telescopes, such as the\nSquare Kilometre Array (SKA), will acquire massive volumes of data and\ntransition radio astronomy to a big-data era. The ill-posed inverse problem of\nimaging the raw visibilities acquired by RI telescopes will become\nsignificantly more computationally challenging, particularly in terms of data\nstorage and computational cost. Current RI imaging methods, such as CLEAN, its\nvariants, and compressive sensing approaches (sparse regularisation), have\nyielded excellent reconstruction fidelity. However, scaling these methods to\nbig-data remains difficult if not impossible in some cases. All\nstate-of-the-art methods in RI imaging lack the ability to process data streams\nas they are acquired during the data observation stage. Such approaches are\nreferred to as online processing methods. We present an online sparse\nregularisation methodology for RI imaging. Image reconstruction is performed\nsimultaneously with data acquisition, where observed visibilities are\nassimilated into the reconstructed image as they arrive and then discarded.\nSince visibilities are processed online, good reconstructions are recovered\nmuch faster than standard (offline) methods which cannot start until the data\nacquisition stage completes. Moreover, the online method provides additional\ncomputational savings and, most importantly, dramatically reduces data storage\nrequirements. Theoretically, the reconstructed images are of the same fidelity\nas those recovered by the equivalent offline approach and, in practice, very\nsimilar reconstruction fidelity is achieved. We anticipate online imaging\ntechniques, as proposed here, will be critical in scaling RI imaging to the\nemerging big-data era of radio astronomy. \n\n"}
{"id": "1712.04687", "contents": "Title: Can Balloons Produce Li-Fi? A Disaster Management Perspective Abstract: Natural calamities and disasters disrupt the conventional communication\nsetups and the wireless bandwidth becomes constrained. A safe and\ncost-effective solution for communication and data access in such scenarios is\nlong needed. Light-Fidelity (Li-Fi) which promises wireless access to data at\nhigh speeds using visible light can be a good option. Visible light being safe\nto use for wireless access in such affected environments also provides\nillumination. Importantly, when a Li-Fi unit is attached to an air balloon and\na network of such Li-Fi balloons are coordinated to form a Li-Fi balloon\nnetwork, data can be accessed anytime and anywhere required and hence many\nlives can be tracked and saved. We propose this idea of a Li-Fi balloon and\ngive an overview of its design using the Philips Li-Fi hardware. Further, we\npropose the concept of a balloon network and coin it with an acronym, the\nLiBNet. We consider the balloons to be arranged as a homogeneous Poisson point\nprocess in the LiBNet and we derive the mean co-channel interference for such\nan arrangement. \n\n"}
{"id": "1712.06745", "contents": "Title: Efficient Algorithms for Searching the Minimum Information Partition in\n  Integrated Information Theory Abstract: The ability to integrate information in the brain is considered to be an\nessential property for cognition and consciousness. Integrated Information\nTheory (IIT) hypothesizes that the amount of integrated information ($\\Phi$) in\nthe brain is related to the level of consciousness. IIT proposes that to\nquantify information integration in a system as a whole, integrated information\nshould be measured across the partition of the system at which information loss\ncaused by partitioning is minimized, called the Minimum Information Partition\n(MIP). The computational cost for exhaustively searching for the MIP grows\nexponentially with system size, making it difficult to apply IIT to real neural\ndata. It has been previously shown that if a measure of $\\Phi$ satisfies a\nmathematical property, submodularity, the MIP can be found in a polynomial\norder by an optimization algorithm. However, although the first version of\n$\\Phi$ is submodular, the later versions are not. In this study, we empirically\nexplore to what extent the algorithm can be applied to the non-submodular\nmeasures of $\\Phi$ by evaluating the accuracy of the algorithm in simulated\ndata and real neural data. We find that the algorithm identifies the MIP in a\nnearly perfect manner even for the non-submodular measures. Our results show\nthat the algorithm allows us to measure $\\Phi$ in large systems within a\npractical amount of time. \n\n"}
{"id": "1712.07863", "contents": "Title: On the Information Dimension of Multivariate Gaussian Processes Abstract: The authors have recently defined the R\\'enyi information dimension rate\n$d(\\{X_t\\})$ of a stationary stochastic process $\\{X_t,\\,t\\in\\mathbb{Z}\\}$ as\nthe entropy rate of the uniformly-quantized process divided by minus the\nlogarithm of the quantizer step size $1/m$ in the limit as $m\\to\\infty$ (B.\nGeiger and T. Koch, \"On the information dimension rate of stochastic\nprocesses,\" in Proc. IEEE Int. Symp. Inf. Theory (ISIT), Aachen, Germany, June\n2017). For Gaussian processes with a given spectral distribution function\n$F_X$, they showed that the information dimension rate equals the Lebesgue\nmeasure of the set of harmonics where the derivative of $F_X$ is positive. This\npaper extends this result to multivariate Gaussian processes with a given\nmatrix-valued spectral distribution function $F_{\\mathbf{X}}$. It is\ndemonstrated that the information dimension rate equals the average rank of the\nderivative of $F_{\\mathbf{X}}$. As a side result, it is shown that the scale\nand translation invariance of information dimension carries over from random\nvariables to stochastic processes. \n\n"}
{"id": "1801.00222", "contents": "Title: Limitation of SDMA in Ultra-Dense Small Cell Networks Abstract: Benefitting from multi-user gain brought by multi-antenna techniques, space\ndivision multiple access (SDMA) is capable of significantly enhancing spatial\nthroughput (ST) in wireless networks. Nevertheless, we show in this letter\nthat, even when SDMA is applied, ST would diminish to be zero in ultra-dense\nnetworks (UDN), where small cell base stations (BSs) are fully densified. More\nimportantly, we compare the performance of SDMA, single-user beamforming\n(SU-BF) (one user is served in each cell) and full SDMA (the number of served\nusers equals the number of equipped antennas). Surprisingly, it is shown that\nSU-BF achieves the highest ST and critical density, beyond which ST starts to\ndegrade, in UDN. The results in this work could shed light on the fundamental\nlimitation of SDMA in UDN. \n\n"}
{"id": "1801.02020", "contents": "Title: Decentralized Base-Graph Routing for the Quantum Internet Abstract: Quantum repeater networks are a fundamental of any future quantum Internet\nand long-distance quantum communications. The entangled quantum nodes can\ncommunicate through several different levels of entanglement, leading to a\nheterogeneous, multi-level network structure. The level of entanglement between\nthe quantum nodes determines the hop distance and the probability of the\nexistence of an entangled link in the network. Here, we define a decentralized\nrouting for entangled quantum networks. The proposed method allows an efficient\nrouting to find the shortest paths in entangled quantum networks by using only\nlocal knowledge of the quantum nodes. We give bounds on the maximum value of\nthe total number of entangled links of a path. The proposed scheme can be\ndirectly applied in practical quantum communications and quantum networking\nscenarios. \n\n"}
{"id": "1801.02781", "contents": "Title: Minimum Throughput Maximization in UAV-Aided Wireless Powered\n  Communication Networks Abstract: This paper investigates unmanned aerial vehicle (UAV)-aided wireless powered\ncommunication network (WPCN) systems where a mobile access point (AP) at the\nUAV serves multiple energy-constrained ground terminals (GTs). Specifically,\nthe UAVs first charge the GTs by transmitting the wireless energy transfer\n(WET) signals in the downlink. Then, by utilizing the harvested wireless energy\nfrom the UAVs, the GTs send their uplink wireless information transmission\n(WIT) signals to the UAVs. In this paper, depending on the operations of the\nUAVs, we adopt two different scenarios, namely integrated UAV and separated UAV\nWPCNs. First, in the integrated UAV WPCN, a UAV acts as a hybrid AP in which\nboth energy transfer and information reception are processed at a single UAV.\nIn contrast, for the separated UAV WPCN, we consider two UAVs each of which\nbehaves as an energy AP and an information AP independently, and thus the\nenergy transfer and the information decoding are separately performed at two\ndifferent UAVs. For both systems, we jointly optimize the trajectories of the\nUAVs, the uplink power control, and the time resource allocation for the WET\nand the WIT to maximize the minimum throughput of the GTs. Since the formulated\nproblems are non-convex, we apply the concave-convex procedure by deriving\nappropriate convex bounds for non-convex constraints. As a result, we propose\niterative algorithms which efficiently identify a local optimal solution for\nthe minimum throughput maximization problems. Simulation results verify the\nefficiency of the proposed algorithms compared to conventional schemes. \n\n"}
{"id": "1801.02987", "contents": "Title: Multiplexing Analysis of Millimeter-Wave Massive MIMO Systems Abstract: This paper is concerned with spatial multiplexing analysis for\nmillimeter-wave (mmWave) massive MIMO systems. For a single-user mmWave system\nemploying distributed antenna subarray architecture in which the transmitter\nand receiver consist of Kt and Kr subarrays, respectively, an asymptotic\nmultiplexing gain formula is firstly derived when the numbers of antennas at\nsubarrays go to infinity. Specifically, assuming that all subchannels have the\nsame average number of propagation paths L, the formula implies that by\nemploying such a distributed antenna-subarray architecture, an exact average\nmaximum multiplexing gain of KrKtL can be achieved. This result means that\ncompared to the co-located antenna architecture, using the distributed\nantenna-subarray architecture can scale up the maximum multiplexing gain\nproportionally to KrKt. In order to further reveal the relation between\ndiversity gain and multiplexing gain, a simple characterization of the\ndiversity-multiplexing tradeoff is also given. The multiplexing gain analysis\nis then extended to the multiuser scenario. Moreover, simulation results\nobtained with the hybrid analog/digital processing corroborate the analysis\nresults. \n\n"}
{"id": "1801.03655", "contents": "Title: Can Negligible Cooperation Increase Network Capacity? The Average-Error\n  Case Abstract: In communication networks, cooperative strategies are coding schemes where\nnetwork nodes work together to improve network performance metrics such as\nsum-rate. This work studies encoder cooperation in the setting of a discrete\nmultiple access channel with two encoders and a single decoder. A node in the\nnetwork that is connected to both encoders via rate-limited links, referred to\nas the cooperation facilitator (CF), enables the cooperation strategy.\nPreviously, the authors presented a class of multiple access channels where the\naverage-error sum-capacity has an infinite derivative in the limit where CF\noutput link capacities approach zero. The authors also demonstrated that for\nsome channels, the maximal-error sum-capacity is not continuous at the point\nwhere the output link capacities of the CF equal zero. This work shows that the\nthe average-error sum-capacity is continuous when CF output link capacities\nconverge to zero; that is, the infinite derivative of the average-error\nsum-capacity is not a result of its discontinuity as in the maximal-error case. \n\n"}
{"id": "1801.03688", "contents": "Title: Repairing the Faure-Loidreau Public-Key Cryptosystem Abstract: A repair of the Faure-Loidreau (FL) public-key code-based cryptosystem is\nproposed. The FL cryptosystem is based on the hardness of list decoding\nGabidulin codes which are special rank-metric codes. We prove that the recent\nstructural attack on the system by Gaborit et al. is equivalent to decoding an\ninterleaved Gabidulin code. Since all known polynomial-time decoders for these\ncodes fail for a large constructive class of error patterns, we are able to\nconstruct public keys that resist the attack. It is also shown that all other\nknown attacks fail for our repair and parameter choices. Compared to other\ncode-based cryptosystems, we obtain significantly smaller key sizes for the\nsame security level. \n\n"}
{"id": "1801.03892", "contents": "Title: Privacy in Index Coding: Improved Bounds and Coding Schemes Abstract: It was recently observed in [1], that in index coding, learning the coding\nmatrix used by the server can pose privacy concerns: curious clients can\nextract information about the requests and side information of other clients.\nOne approach to mitigate such concerns is the use of $k$-limited-access schemes\n[1], that restrict each client to learn only part of the index coding matrix,\nand in particular, at most $k$ rows. These schemes transform a linear index\ncoding matrix of rank $T$ to an alternate one, such that each client needs to\nlearn at most $k$ of the coding matrix rows to decode its requested message.\nThis paper analyzes $k$-limited-access schemes. First, a worst-case scenario,\nwhere the total number of clients $n$ is $2^T-1$ is studied. For this case, a\nnovel construction of the coding matrix is provided and shown to be\norder-optimal in the number of transmissions. Then, the case of a general $n$\nis considered and two different schemes are designed and analytically and\nnumerically assessed in their performance. It is shown that these schemes\nperform better than the one designed for the case $n=2^T-1$. \n\n"}
{"id": "1801.04556", "contents": "Title: Poisson Cox Point Processes for Vehicular Networks Abstract: This paper analyzes statistical properties of the Poisson line Cox point\nprocess useful in the modeling of vehicular networks. The point process is\ncreated by a two-stage construction: a Poisson line process to model road\ninfrastructure and independent Poisson point processes, conditionally on the\nPoisson lines, to model vehicles on the roads. We derive basic properties of\nthe point process, including the general quadratic position of the points, the\nnearest distance distribution, the Laplace functional, the densities of facets\nof the Cox-Voronoi tessellation, and the asymptotic behavior of the typical\nVoronoi cell under vehicular densification. These properties are closely linked\nto features that are important in vehicular networks. \n\n"}
{"id": "1801.04920", "contents": "Title: Secrecy Amplification for Distributed Encrypted Sources with Correlated\n  Keys using Affine Encoders Abstract: This paper proposed the application of post-encryption-compression (PEC) to\nstrengthen the secrecy in the case of distributed encryption where the\nencryption keys are correlated to each other. We derive the universal code\nconstruction for the compression and the rate region where codes with\nachievability and secrecy are obtainable. Our main technique is to use affine\nencoders which are constructed from certain linear encoders to encode the\nciphertexts before sending them to public communication channels. We show that\nif the rates of linear codes are within a certain rate region:(1) information\nleakage on the original sources from the encoded ciphertexts without the keys\nis negligible, while (2) one who has legitimate keys is able to retrieve the\noriginal source data with negligible error probability. \n\n"}
{"id": "1801.05089", "contents": "Title: Reed-Muller Sequences for 5G Grant-free Massive Access Abstract: We propose to use second order Reed-Muller (RM) sequence for user\nidentification in 5G grant-free access. The benefits of RM sequences mainly lie\nin two folds, (i) support of much larger user space, hence lower collision\nprobability and (ii) lower detection complexity. These two features are\nessential to meet the massive connectivity ($10^7$ links/km$^2$),\nultra-reliable and low-latency requirements in 5G, e.g., one-shot transmission\n($\\leq 1$ms) with $\\leq 10^{-4}$ packet error rate. However, the\nnon-orthogonality introduced during sequence space expansion leads to worse\ndetection performance. In this paper, we propose a noise-resilient detection\nalgorithm along with a layered sequence construction to meet the harsh\nrequirements. Link-level simulations in both narrow-band and OFDM-based\nscenarios show that RM sequences are suitable for 5G. \n\n"}
{"id": "1801.05112", "contents": "Title: Exact Error and Erasure Exponents for the Asymmetric Broadcast Channel Abstract: Consider the asymmetric broadcast channel with a random superposition\ncodebook, which may be comprised of constant composition or \\iid codewords. By\napplying Forney's optimal decoder for individual messages and the message pair\nfor the receiver that decodes both messages, exact (ensemble-tight) error and\nerasure exponents are derived. It is shown that the optimal decoder designed to\ndecode the pair of messages achieves the optimal trade-off between the total\nand undetected exponents associated with the optimal decoder for the private\nmessage. Convex optimization-based procedures to evaluate the exponents\nefficiently are proposed. Finally, numerical examples are presented to\nillustrate the results. \n\n"}
{"id": "1801.05870", "contents": "Title: Quantized Compressive Sensing with RIP Matrices: The Benefit of\n  Dithering Abstract: Quantized compressive sensing (QCS) deals with the problem of coding\ncompressive measurements of low-complexity signals with quantized, finite\nprecision representations, i.e., a mandatory process involved in any practical\nsensing model. While the resolution of this quantization clearly impacts the\nquality of signal reconstruction, there actually exist incompatible\ncombinations of quantization functions and sensing matrices that proscribe\narbitrarily low reconstruction error when the number of measurements increases.\nThis work shows that a large class of random matrix constructions known to\nrespect the restricted isometry property (RIP) is \"compatible\" with a simple\nscalar and uniform quantization if a uniform random vector, or a random dither,\nis added to the compressive signal measurements before quantization. In the\ncontext of estimating low-complexity signals (e.g., sparse or compressible\nsignals, low-rank matrices) from their quantized observations, this\ncompatibility is demonstrated by the existence of (at least) one signal\nreconstruction method, the projected back projection (PBP), whose\nreconstruction error decays when the number of measurements increases.\nInterestingly, given one RIP matrix and a single realization of the dither, a\nsmall reconstruction error can be proved to hold uniformly for all signals in\nthe considered low-complexity set. We confirm these observations numerically in\nseveral scenarios involving sparse signals, low-rank matrices, and compressible\nsignals, with various RIP matrix constructions such as sub-Gaussian random\nmatrices and random partial discrete cosine transform (DCT) matrices. \n\n"}
{"id": "1801.06623", "contents": "Title: Promises and Caveats of Uplink IoT Ultra-Dense Networks Abstract: In this paper, by means of simulations, we evaluate the uplink (UL)\nperformance of an Internet of Things (IoT) capable ultra-dense network (UDN) in\nterms of the coverage probability and the density of reliably working user\nequipments (UEs). From our study, we show the benefits and challenges that UL\nIoT UDNs will bring about in the future. In more detail, for a low-reliability\ncriterion, such as achieving a UL signal-to-interference-plus-noise ratio\n(SINR) above 0 dB, the density of reliably working UEs grows quickly with the\nnetwork densification, showing the potential of UL IoT UDNs. In contrast, for a\nhigh-reliability criterion, such as achieving a UL SINR above 10 dB, the\ndensity of reliably working UEs remains to be low in UDNs due to excessive\ninter-cell interference, which should be considered when operating UL IoT UDNs.\nMoreover, considering the existence of a non-zero antenna height difference\nbetween base stations (BSs) and UEs, the density of reliably working UEs could\neven decrease as we deploy more BSs. This calls for the usage of sophisticated\ninterference management schemes and/or beam steering/shaping technologies in UL\nIoT UDNs. \n\n"}
{"id": "1801.08560", "contents": "Title: A Tractable Analysis of the Blind-spot Probability in Localization\n  Networks under Correlated Blocking Abstract: In localization applications, the line-of-sight between anchors and targets\nmay be blocked by obstacles in the environment. A target that is invisible\n(i.e., without line-of-sight) to a sufficient number of anchors cannot be\nunambiguously localized and is, therefore, said to be in a blind spot. In this\npaper, we analyze the blind spot probability of a typical target by using\nstochastic geometry to model the randomness in the obstacle and anchor\nlocations. In doing so, we handle correlated anchor blocking induced by the\nobstacles, unlike previous works that assume independent anchor blocking. We\nfirst characterize the regime over which the independent blocking assumption\nunderestimates the blind spot probability of the typical target, which in turn,\nis characterized as a function of the distribution of the visible area,\nsurrounding the target location. Since this distribution is difficult to\ncharacterize exactly, we formulate the nearest two-obstacle approximation,\nwhich is equivalent to considering correlated blocking for only the nearest two\nobstacles from the target and assuming independent blocking for the remaining\nobstacles. Based on this, we derive an approximate expression for the blind\nspot probability, which helps determine the anchor deployment intensity needed\nfor the blind spot probability of a typical target to be at most a threshold,\n$\\mu$. \n\n"}
{"id": "1801.09109", "contents": "Title: Spectral and Energy Efficient Wireless Powered IoT Networks: NOMA or\n  TDMA? Abstract: Wireless powered communication networks (WPCNs), where multiple\nenergy-limited devices first harvest energy in the downlink and then transmit\ninformation in the uplink, have been envisioned as a promising solution for the\nfuture Internet-of-Things (IoT). Meanwhile, non-orthogonal multiple access\n(NOMA) has been proposed to improve the system spectral efficiency (SE) of the\nfifth-generation (5G) networks by allowing concurrent transmissions of multiple\nusers in the same spectrum. As such, NOMA has been recently considered for the\nuplink of WPCNs based IoT networks with a massive number of devices. However,\nsimultaneous transmissions in NOMA may also incur more transmit energy\nconsumption as well as circuit energy consumption in practice which is critical\nfor energy constrained IoT devices. As a result, compared to orthogonal\nmultiple access schemes such as time-division multiple access (TDMA), whether\nthe SE can be improved and/or the total energy consumption can be reduced with\nNOMA in such a scenario still remains unknown. To answer this question, we\nfirst derive the optimal time allocations for maximizing the SE of a TDMA-based\nWPCN (T-WPCN) and a NOMA-based WPCN (N-WPCN), respectively. Subsequently, we\nanalyze the total energy consumption as well as the maximum SE achieved by\nthese two networks. Surprisingly, it is found that N-WPCN not only consumes\nmore energy, but also is less spectral efficient than T-WPCN. Simulation\nresults verify our theoretical findings and unveil the fundamental performance\nbottleneck, i.e., \"worst user bottleneck problem\", in multiuser NOMA systems. \n\n"}
{"id": "1801.09678", "contents": "Title: Algorithms for the Construction of Incoherent Frames Under Various\n  Design Constraints Abstract: Unit norm finite frames are generalizations of orthonormal bases with many\napplications in signal processing. An important property of a frame is its\ncoherence, a measure of how close any two vectors of the frame are to each\nother. Low coherence frames are useful in compressed sensing applications. When\nused as measurement matrices, they successfully recover highly sparse solutions\nto linear inverse problems. This paper describes algorithms for the design of\nvarious low coherence frame types: real, complex, unital (constant magnitude)\ncomplex, sparse real and complex, nonnegative real and complex, and harmonic\n(selection of rows from Fourier matrices). The proposed methods are based on\nsolving a sequence of convex optimization problems that update each vector of\nthe frame. This update reduces the coherence with the other frame vectors,\nwhile other constraints on its entries are also imposed. Numerical experiments\nshow the effectiveness of the methods compared to the Welch bound, as well as\nother competing algorithms, in compressed sensing applications. \n\n"}
{"id": "1801.10282", "contents": "Title: Stochastic Optimization and Control Framework for 5G Network Slicing\n  with Effective Isolation Abstract: Network slicing is an emerging technique for providing resources to diverse\nwireless services with heterogeneous quality-of-service needs. However, beyond\nsatisfying end-to-end requirements of network users, network slicing needs to\nalso provide isolation between slices so as to prevent one slice's faults and\ncongestion from affecting other slices. In this paper, the problem of network\nslicing is studied in the context of a wireless system having a time-varying\nnumber of users that require two types of slices: reliable low latency (RLL)\nand self-managed (capacity limited) slices. To address this problem, a novel\ncontrol framework for stochastic optimization is proposed based on the Lyapunov\ndrift-plus-penalty method. This new framework enables the system to minimize\npower, maintain slice isolation, and provide reliable and low latency\nend-to-end communication for RLL slices. Simulation results show that the\nproposed approach can maintain the system's reliability while providing\neffective slice isolation in the event of sudden changes in the network\nenvironment. \n\n"}
{"id": "1801.10500", "contents": "Title: Analysis of Coded Selective-Repeat ARQ via Matrix Signal-Flow Graphs Abstract: We propose two schemes for selective-repeat ARQ protocols over packet erasure\nchannels with unreliable feedback: (i) a hybrid ARQ protocol with soft\ncombining at the receiver, and (ii) a coded ARQ protocol, by building on the\nuncoded baseline scheme for ARQ, developed by Ausavapattanakun and Nosratinia.\nOur method leverages discrete-time queuing and coding theory to analyze the\nperformance of the proposed data transmission methods. We incorporate forward\nerror-correction to reduce in-order delivery delay, and exploit a matrix\nsignal-flow graph approach to analyze the throughput and delay of the\nprotocols. We demonstrate and contrast the performance of the coded protocols\nwith that of the uncoded scheme, illustrating the benefits of coded\ntransmissions. \n\n"}
{"id": "1802.02049", "contents": "Title: A Distance Between Channels: the average error of mismatched channels Abstract: Two channels are equivalent if their maximum likelihood (ML) decoders\ncoincide for every code. We show that this equivalence relation partitions the\nspace of channels into a generalized hyperplane arrangement. With this, we\ndefine a coding distance between channels in terms of their ML-decoders which\nis meaningful from the decoding point of view, in the sense that the closer two\nchannels are, the larger is the probability of them sharing the same\nML-decoder. We give explicit formulas for these probabilities. \n\n"}
{"id": "1802.03837", "contents": "Title: Integrated Millimeter Wave and Sub-6 GHz Wireless Networks: A Roadmap\n  for Joint Mobile Broadband and Ultra-Reliable Low-Latency Communications Abstract: Next-generation wireless networks must enable emerging technologies such as\naugmented reality and connected autonomous vehicles via wide range of wireless\nservices that span enhanced mobile broadband (eMBB), as well as ultra-reliable\nlow-latency communication (URLLC). Existing wireless systems that solely rely\non the scarce sub-6 GHz, microwave ($\\mu$W) frequency bands will be unable to\nmeet such stringent and mixed service requirements for future wireless services\ndue to spectrum scarcity. Meanwhile, operating at high-frequency millimeter\nwave (mmWave) bands is seen as an attractive solution, primarily due to the\nbandwidth availability and possibility of large-scale multi-antenna\ncommunication. However, mmWave communication is inherently unreliable due to\nits susceptibility to blockage, high path loss, and channel uncertainty. Hence,\nto provide URLLC and high-speed wireless access, it is desirable to seamlessly\nintegrate the reliability of $\\mu$W networks with the high capacity of mmWave\nnetworks. To this end, in this paper, the first comprehensive tutorial for\n\\emph{integrated mmWave-$\\mu$W} communications is introduced. This envisioned\nintegrated design will enable wireless networks to achieve URLLC along with\neMBB by leveraging the best of two worlds: reliable, long-range communications\nat the $\\mu$W bands and directional high-speed communications at the mmWave\nfrequencies. To achieve this goal, key solution concepts are discussed that\ninclude new architectures for the radio interface, URLLC-aware frame structure\nand resource allocation methods along with mobility management, to realize the\npotential of integrated mmWave-$\\mu$W communications. The opportunities and\nchallenges of each proposed scheme are discussed and key results are presented\nto show the merits of the developed integrated mmWave-$\\mu$W framework. \n\n"}
{"id": "1802.04769", "contents": "Title: Edge Caching in Delay-Constrained Virtualized Cellular Networks:\n  Analysis and Market Abstract: Caching of popular contents at cellular base stations, i.e., edge caching, in\norder to eliminate duplicate transmission through the backhaul can reduce the\nlatency of data delivery in $5$G networks. However, since caching can only\nreduce the backhaul delay, techniques such as base station densification will\nalso need to be used to reduce the fronthaul delay. In this paper, using\nresults from stochastic geometry, we first model the effects of base station\ndensification and cache size on the latency of the system. We then derive a\ntight approximation for the cache hit probability. To optimize the network cost\ndue to the deployment of base station (BS) and cache storage, a minimization\nproblem for the product of the BS intensity and cache size is formulated under\nprobabilistic delay constraint, which is converted into a geometric program and\nsolved analytically. The results are then used to analyze the economics of a\ncache-enabled virtualized cellular network where the network infrastructure,\ni.e., BSs and cache storage, owned by an infrastructure provider (InP) is\nshared among multiple mobile network operators (MNOs). For the pricing between\nthe InP and the MNOs, we formulate a Stackelberg game with the InP as the\nleader and multiple MNOs as the followers. In this virtualized scenario, the\ncommon cost of renting the infrastructure is shared in a fair manner among the\nMNOs by using the Shapely value. An efficient algorithm is provided to divide\nthe rent among MNOs. \n\n"}
{"id": "1802.04923", "contents": "Title: Beamforming with Multiple One-Bit Wireless Transceivers Abstract: Classical beamforming techniques rely on highly linear transmitters and\nreceivers to allow phase-coherent combining at the transmitter and receiver.\nThe transmitter uses beamforming to steer signal power towards the receiver,\nand the receiver uses beamforming to gather and coherently combine the signals\nfrom multiple receiver antennas. When the transmitters and receivers are\ninstead constrained for power and cost reasons to be non-linear one-bit\ndevices, the potential advantages and performance metrics associated with\nbeamforming are not as well understood. We define beamforming at the\ntransmitter as a codebook design problem to maximize the minimum distance\nbetween codewords. We define beamforming at the receiver as the maximum\nlikelihood detector of the transmitted codeword. We show that beamforming with\none-bit transceivers is a constellation design problem, and that we can come\nwithin a few dB SNR of the capacity attained by linear transceivers. \n\n"}
{"id": "1802.05209", "contents": "Title: Sum Secrecy Rate Maximization in a Multi-Carrier MIMO Wiretap Channel\n  with Full-Duplex Jamming Abstract: In this paper we address a sum secrecy rate maximization problem for a\nmulti-carrier and MIMO communication system. We consider the case that the\nreceiver is capable of full-duplex (FD) operation and simultaneously sends\njamming signal to a potential eavesdropper. In particular, we simultaneously\ntake advantage of the spatial and frequency diversity in the system in order to\nobtain a higher level of security in the physical layer. Due to the non-convex\nnature of the resulting mathematical problem, we propose an iterative solution\nwith a guaranteed convergence, based on block coordinate descent method, by\nre-structuring our problem as a separately convex program. Moreover, for the\nspecial case that the transmitter is equipped with a single antenna, an optimal\ntransmit power allocation strategy is obtained analytically, assuming a known\njamming strategy. We also study a FD bidirectional secure communication system,\nwhere the jamming power can be reused to enhance the sum secrecy rate. The\nperformance of the proposed design is then numerically evaluated compared to\nthe other design strategies, and under different system assumptions. \n\n"}
{"id": "1802.06054", "contents": "Title: Learning Patterns for Detection with Multiscale Scan Statistics Abstract: This paper addresses detecting anomalous patterns in images, time-series, and\ntensor data when the location and scale of the pattern is unknown a priori. The\nmultiscale scan statistic convolves the proposed pattern with the image at\nvarious scales and returns the maximum of the resulting tensor. Scale corrected\nmultiscale scan statistics apply different standardizations at each scale, and\nthe limiting distribution under the null hypothesis---that the data is only\nnoise---is known for smooth patterns. We consider the problem of simultaneously\nlearning and detecting the anomalous pattern from a dictionary of smooth\npatterns and a database of many tensors. To this end, we show that the\nmultiscale scan statistic is a subexponential random variable, and prove a\nchaining lemma for standardized suprema, which may be of independent interest.\nThen by averaging the statistics over the database of tensors we can learn the\npattern and obtain Bernstein-type error bounds. We will also provide a\nconstruction of an $\\epsilon$-net of the location and scale parameters,\nproviding a computationally tractable approximation with similar error bounds. \n\n"}
{"id": "1802.06670", "contents": "Title: Frequency-Selective Hybrid Beamforming Based on Implicit CSI for\n  Millimeter Wave Systems Abstract: Hybrid beamforming is a promising concept to achieve high data rate\ntransmission at millimeter waves. To implement it in a transceiver, many\nreferences optimally adapt to a high-dimensional multi-antenna channel but more\nor less ignore the complexity of the channel estimation. Realizing that\nreceived coupling coefficients of the channel and pairs of possible analog\nbeamforming vectors can be used for analog beam selection, we further propose a\nlow-complexity scheme that exploits the coupling coefficients to implement\nhybrid beamforming. Essentially, the coupling coefficients can be regarded as\nimplicit channel state information (CSI), and the estimates of these coupling\ncoefficients yield alternatives of effective channel matrices of much lower\ndimension. After calculating the Frobenius norm of these effective channel\nmatrices, it turns out that the effective channel having the largest value of\nthe Frobenius norm provides the solution to hybrid beamforming problem. \n\n"}
{"id": "1802.06910", "contents": "Title: Single or Multiple Frames Content Delivery for Next-Generation Networks? Abstract: This paper addresses the four enabling technologies, namely multi-user sparse\ncode multiple access (SCMA), content caching, energy harvesting, and physical\nlayer security for proposing an energy and spectral efficient resource\nallocation algorithm for the access and backhaul links in heterogeneous\ncellular networks. Although each of the above mentioned issues could be a topic\nof research, in a real situation, we would face a complicated scenario where\nthey should be considered jointly, and hence, our target is to consider these\ntechnologies jointly in a unified framework. Moreover, we propose two novel\ncontent delivery scenarios: 1) single frame content delivery (SFCD), and 2)\nmultiple frames content delivery (MFCD), where the time duration of serving\nuser requests is divided into several frames. In the first scenario, the\nrequested content by each user is served over one frame. However, in the second\nscenario, the requested content by each user can be delivered over several\nframes. We formulate the resource allocation for the proposed scenarios as\noptimization problems where our main aim is to maximize the energy efficiency\nof access links subject to the transmit power and rate constraints of access\nand backhaul links, caching and energy harvesting constraints, and SCMA\ncodebook allocation limitations. Due to the practical limitations, we assume\nthat the channel state information values between eavesdroppers and base\nstations are uncertain and design the network for the worst case scenario.\nSince the corresponding optimization problems are mixed integer non-linear and\nnonconvex programming, NP-hard, and intractable, we propose an iterative\nalgorithm based on the well-known alternate and successive convex approximation\nmethods. \n\n"}
{"id": "1802.07458", "contents": "Title: Non-Asymptotic Bounds and a General Formula for the Rate-Distortion\n  Region of the Successive Refinement Problem Abstract: In the successive refinement problem, a fixed-length sequence emitted from an\ninformation source is encoded into two codewords by two encoders in order to\ngive two reconstructions of the sequence. One of two reconstructions is\nobtained by one of two codewords, and the other reconstruction is obtained by\nall two codewords. For this coding problem, we give non-asymptotic inner and\nouter bounds on pairs of numbers of codewords of two encoders such that each\nprobability that a distortion exceeds a given distortion level is less than a\ngiven probability level. We also give a general formula for the rate-distortion\nregion for general sources, where the rate-distortion region is the set of rate\npairs of two encoders such that each maximum value of possible distortions is\nless than a given distortion level. \n\n"}
{"id": "1802.08223", "contents": "Title: Achievable Rate of Private Function Retrieval from MDS Coded Databases Abstract: We study the problem of private function retrieval (PFR) in a distributed\nstorage system. In PFR the user wishes to retrieve a linear combination of $M$\nmessages stored in non-colluding $(N,K)$ MDS coded databases while revealing no\ninformation about the coefficients of the intended linear combination to any of\nthe individual databases. We present an achievable scheme for MDS coded PFR\nwith a rate that matches the capacity for coded private information retrieval\nderived recently, $R=(1+R_c+R_c^2+\\dots+R_c^{M-1})^{-1}=\\frac{1-R_c}{1-R_c^M}$,\nwhere $R_c=\\frac{K}{N}$ is the rate of the MDS code. This achievable rate is\ntight in some special cases. \n\n"}
{"id": "1802.08276", "contents": "Title: Quantum entropy and polarization measurements of the two-photon system Abstract: We consider the bipartite state of a two-photon polarization system and\nobtain the exact analytical expression for the von Neumann entropy in the\nparticular case of a 5-parameter polarization density matrix. We investigate\nand graphically illustrate the dependence of the entropy on these five\nparameters, in particular, the existence of exotic, transition from exotic to\nnon-exotic, and non-exotic states, where the quantum conditional entropy is\nnegative, both positive and negative, and positive, respectively. We study the\n\"cooling\" or \"heating\" effect that follows from the reduced density of photon 2\nwhen a measurement is performed on photon 1. \n\n"}
{"id": "1802.08941", "contents": "Title: Gradient Primal-Dual Algorithm Converges to Second-Order Stationary\n  Solutions for Nonconvex Distributed Optimization Abstract: In this work, we study two first-order primal-dual based algorithms, the\nGradient Primal-Dual Algorithm (GPDA) and the Gradient Alternating Direction\nMethod of Multipliers (GADMM), for solving a class of linearly constrained\nnon-convex optimization problems. We show that with random initialization of\nthe primal and dual variables, both algorithms are able to compute second-order\nstationary solutions (ss2) with probability one. This is the first result\nshowing that primal-dual algorithm is capable of finding ss2 when only using\nfirst-order information, it also extends the existing results for first-order,\nbut primal-only algorithms.\n  An important implication of our result is that it also gives rise to the\nfirst global convergence result to the ss2, for two classes of unconstrained\ndistributed non-convex learning problems over multi-agent networks. \n\n"}
{"id": "1803.00983", "contents": "Title: Power Control and Channel Allocation for D2D Underlaid Cellular Networks Abstract: Device-to-Device (D2D) communications underlaying cellular networks is a\nviable network technology that can potentially increase spectral utilization\nand improve power efficiency for proximitybased wireless applications and\nservices. However, a major challenge in such deployment scenarios is the\ninterference caused by D2D links when sharing the same resources with cellular\nusers. In this work, we propose a channel allocation (CA) scheme together with\na set of three power control (PC) schemes to mitigate interference in a D2D\nunderlaid cellular system modeled as a random network using the mathematical\ntool of stochastic geometry. The novel aspect of the proposed CA scheme is that\nit enables D2D links to share resources with multiple cellular users as opposed\nto one as previously considered in the literature. Moreover, the accompanying\ndistributed PC schemes further manage interference during link establishment\nand maintenance. The first two PC schemes compensate for large-scale path-loss\neffects and maximize the D2D sum rate by employing distance-dependent pathloss\nparameters of the D2D link and the base station, including an error estimation\nmargin. The third scheme is an adaptive PC scheme based on a variable target\nsignal-to-interference-plus-noise ratio, which limits the interference caused\nby D2D users and provides sufficient coverage probability for cellular users.\nClosed-form expressions for the coverage probability of cellular links, D2D\nlinks, and sum rate of D2D links are derived in terms of the allocated power,\ndensity of D2D links, and path-loss exponent. The impact of these key system\nparameters on network performance is analyzed and compared with previous work.\nSimulation results demonstrate an enhancement in cellular and D2D coverage\nprobabilities, and an increase in spectral and power efficiency. \n\n"}
{"id": "1803.02261", "contents": "Title: User-Centric 5G Cellular Networks: Resource Allocation and Comparison\n  with the Cell-Free Massive MIMO Approach Abstract: Recently, the so-called cell-free (CF) Massive MIMO architecture has been\nintroduced, wherein a very large number of distributed access points (APs)\nsimultaneously and jointly serve a much smaller number of mobile stations\n(MSs). The paper extends the CF approach to the case in which both the APs and\nthe MSs are equipped with multiple antennas, proposing a beamfoming scheme\nthat, relying on the channel hardening effect, does not require channel\nestimation at the MSs. We contrast the CF massive MIMO approach with a\nuser-centric (UC) approach wherein each MS is served only by a limited number\nof APs. Since far APs experience a bad SINR, it turns out that they are quite\nunhelpful in serving far users, and so, the UC approach, while requiring less\nbackhaul overhead with respect to the CF approach, is shown here to achieve\nbetter performance results, in terms of achievable rate-per-user, for the vast\nmajority of the MSs in the network. Furthermore, in the paper we propose two\npower allocation strategy for the uplink and downlink, one aimed at maximizing\nthe overall data-rate and another aimed at maximizing system fairness. \n\n"}
{"id": "1803.02562", "contents": "Title: Energy Efficiency of an Unlicensed Wireless Network in the Presence of\n  Retransmissions Abstract: This paper analysis the energy efficiency of an unlicensed wireless network\nin which retransmission is possible if the transmitted message is decoded in\noutage. A wireless sensor network is considered in which the sensor nodes are\nunlicensed users of a wireless network which transmit its data in the uplink\nchannel used by the licensed users. Poisson point process is used to model the\ndistributions of the nodes and the interference caused by the licensed users\nfor the sensor nodes. After finding the optimal throughput in the presence of\nretransmissions, we focus on analyzing the total power consumption and energy\nefficiency of the network and how retransmissions, network density and outage\nthreshold affects the energy efficiency of the network. \n\n"}
{"id": "1803.05844", "contents": "Title: Iterative Turbo Receiver for LDPC-Coded MIMO Systems Based on\n  Semi-definite Relaxation Abstract: In this work, we develop a new iterative turbo receiver for LDPC-coded\nmulti-antenna systems based on semidefinite relaxation (SDR). For a classical\nturbo receiver, forward error correction (FEC) code is only used at decoder.\nNonetheless, by taking advantage of FEC code in the detection stage, our\nproposed SDR detector can output extrinsic information with much improved\nreliability to the decoder. We also propose a simplified SDR turbo receiver\nthat solves only one SDR problem per codeword instead of solving multiple SDR\nproblems in the iterative turbo processing. This scheme significantly reduces\nthe time complexity of SDR turbo receiver, while the error performance remains\nsimilar as before. In fact, our simplified scheme is generic in the sense that\nit is applicable to any list-based iterative receivers. \n\n"}
{"id": "1803.07505", "contents": "Title: Non-Asymptotic Classical Data Compression with Quantum Side Information Abstract: In this paper, we analyze classical data compression with quantum side\ninformation (also known as the classical-quantum Slepian-Wolf protocol) in the\nso-called large and moderate deviation regimes. In the non-asymptotic setting,\nthe protocol involves compressing classical sequences of finite length $n$ and\ndecoding them with the assistance of quantum side information. In the large\ndeviation regime, the compression rate is fixed, and we obtain bounds on the\nerror exponent function, which characterizes the minimal probability of error\nas a function of the rate. Devetak and Winter showed that the asymptotic data\ncompression limit for this protocol is given by a conditional entropy. For any\nprotocol with a rate below this quantity, the probability of error converges to\none asymptotically and its speed of convergence is given by the strong converse\nexponent function. We obtain finite blocklength bounds on this function, and\ndetermine exactly its asymptotic value. In the moderate deviation regime for\nthe compression rate, the latter is no longer considered to be fixed. It is\nallowed to depend on the blocklength $n$, but assumed to decay slowly to the\nasymptotic data compression limit. Starting from a rate above this limit, we\ndetermine the speed of convergence of the error probability to zero and show\nthat it is given in terms of the conditional information variance. Our results\ncomplement earlier results obtained by Tomamichel and Hayashi, in which they\nanalyzed the so-called small deviation regime of this protocol. \n\n"}
{"id": "1803.07993", "contents": "Title: Age of Information in a Network of Preemptive Servers Abstract: A source submits status updates to a network for delivery to a destination\nmonitor. Updates follow a route through a series of network nodes. Each node is\na last-come-first-served queue supporting preemption in service. We\ncharacterize the average age of information at the input and output of each\nnode in the route induced by the updates passing through. For Poisson arrivals\nto a line network of preemptive memoryless servers, we show that average age\naccumulates through successive network nodes. \n\n"}
{"id": "1803.08178", "contents": "Title: Boosted Density Estimation Remastered Abstract: There has recently been a steady increase in the number iterative approaches\nto density estimation. However, an accompanying burst of formal convergence\nguarantees has not followed; all results pay the price of heavy assumptions\nwhich are often unrealistic or hard to check. The Generative Adversarial\nNetwork (GAN) literature --- seemingly orthogonal to the aforementioned pursuit\n--- has had the side effect of a renewed interest in variational divergence\nminimisation (notably $f$-GAN). We show that by introducing a weak learning\nassumption (in the sense of the classical boosting framework) we are able to\nimport some recent results from the GAN literature to develop an iterative\nboosted density estimation algorithm, including formal convergence results with\nrates, that does not suffer the shortcomings other approaches. We show that the\ndensity fit is an exponential family, and as part of our analysis obtain an\nimproved variational characterisation of $f$-GAN. \n\n"}
{"id": "1803.08189", "contents": "Title: Can Decentralized Status Update Achieve Universally Near-Optimal\n  Age-of-Information in Wireless Multiaccess Channels? Abstract: In an Internet-of-Things system where status data are collected from sensors\nand actuators for time-critical applications, the freshness of data is vital\nand can be quantified by the recently proposed age-of-information (AoI) metric.\nIn this paper, we first consider a general scenario where multiple terminals\nshare a common channel to transmit or receive randomly generated status\npackets. The optimal scheduling problem to minimize AoI is formulated as a\nrestless multi-armed bandit problem. To solve the problem efficiently, we\nderive the Whittle's index in closed-form and establish the indexability\nthereof. Compared with existing work, we extend the index policy for AoI\noptimization to incorporate stochastic packet arrivals and optimal packet\nmanagement (buffering the latest packet). Inspired by the index policy which\nhas near-optimal performance but is centralized by nature, a decentralized\nstatus update scheme, i.e., the index-prioritized random access policy (IPRA),\nis further proposed, achieving universally near-optimal AoI performance and\noutperforming state-of-the-arts in the literature. \n\n"}
{"id": "1803.09467", "contents": "Title: A Switch to the Concern of User: Importance Coefficient in Utility\n  Distribution and Message Importance Measure Abstract: This paper mainly focuses on the utilization frequency in receiving end of\ncommunication systems, which shows the inclination of the user about different\nsymbols. When the average number of use is limited, a specific utility\ndistribution is proposed on the best effort in term of fairness, which is also\nthe closest one to occurring probability in the relative entropy. Similar to a\nswitch, its parameter can be selected to make it satisfy different users'\nrequirements: negative parameter means the user focus on high-probability\nevents and positive parameter means the user is interested in small-probability\nevents. In fact, the utility distribution is a measure of message importance in\nessence. It illustrates the meaning of message importance measure (MIM), and\nextend it to the general case by selecting the parameter. Numerical results\nshow that this utility distribution characterizes the message importance like\nMIM and its parameter determines the concern of users. \n\n"}
{"id": "1803.10623", "contents": "Title: Stability and Dynamic Control of Underlay Mobile Edge Networks Abstract: This paper studies the stability and dynamic control of underlay mobile edge\nnetworks. First, the stability region for a multiuser edge network is obtained\nunder the assumption of full channel state information. This result provides a\nbenchmark figure for comparing performance of the proposed algorithms. Second,\na centralized joint flow control and scheduling algorithm is proposed to\nstabilize the queues of edge devices while respecting the average and\ninstantaneous interference power constraints at the core access point. This\nalgorithm is proven to converge to a utility point arbitrarily close to the\nmaximum achievable utility within the stability region. Finally, more practical\nimplementation issues such as distributed scheduling are examined by designing\nefficient scheduling algorithms taking advantage of communications diversity.\nThe proposed distributed solutions utilize mini slots for contention resolution\nand achieve a certain fraction of the utility optimal point. The performance\nlower bounds for distributed algorithms are determined analytically. The\ndetailed simulation study is performed to pinpoint the cost of distributed\ncontrol for mobile edge networks with respect to centralized control. \n\n"}
{"id": "1803.11335", "contents": "Title: On the classification of linear complementary dual codes Abstract: We give a complete classification of binary linear complementary dual codes\nof lengths up to $13$ and ternary linear complementary dual codes of lengths up\nto $10$. \n\n"}
{"id": "1804.00807", "contents": "Title: Full Characterization of Optimal Uncoded Placement for the Structured\n  Clique Cover Delivery of Nonuniform Demands Abstract: We investigate the problem of coded caching for nonuniform demands when the\nstructured clique cover algorithm proposed by Maddah-Ali and Niesen for\ndecentralized caching is used for delivery. We apply this algorithm to all user\ndemands regardless of their request probabilities. This allows for coding among\nthe files that have different request probabilities but makes the allocation of\nmemory to different files challenging during the content placement phase. As\nour main contribution, we analytically characterize the optimal placement\nstrategy that minimizes the expected delivery rate under a storage capacity\nconstraint. It is shown that the optimal placement follows either a two or a\nthree group strategy, where a set of less popular files are not cached at all\nand the files within each of the other sets are allocated identical amounts of\nstorage as if they had the same request probabilities. We show that for a\nfinite set of storage capacities, that we call the base-cases of the problem,\nthe two group strategy is always optimal. For other storage capacities, optimal\nplacement is achieved by memory sharing between certain base-cases and the\nresulting placement either follows a two or a three group strategy depending on\nthe corresponding base-cases used. We derive a polynomial time algorithm that\ndetermines the base-cases of the problem given the number of caches and\npopularity distribution of files. Given the base-cases of the problem, the\noptimal memory allocation parameters for any storage capacity are derived\nanalytically. \n\n"}
{"id": "1804.02729", "contents": "Title: Distributed Non-Convex First-Order Optimization and Information\n  Processing: Lower Complexity Bounds and Rate Optimal Algorithms Abstract: We consider a class of popular distributed non-convex optimization problems,\nin which agents connected by a network $\\mathcal{G}$ collectively optimize a\nsum of smooth (possibly non-convex) local objective functions. We address the\nfollowing question: if the agents can only access the gradients of local\nfunctions, what are the fastest rates that any distributed algorithms can\nachieve, and how to achieve those rates.\n  First, we show that there exist difficult problem instances, such that it\ntakes a class of distributed first-order methods at least\n$\\mathcal{O}(1/\\sqrt{\\xi(\\mathcal{G})} \\times \\bar{L} /{\\epsilon})$\ncommunication rounds to achieve certain $\\epsilon$-solution [where\n$\\xi(\\mathcal{G})$ denotes the spectral gap of the graph Laplacian matrix, and\n$\\bar{L}$ is some Lipschitz constant]. Second, we propose (near) optimal\nmethods whose rates match the developed lower rate bound (up to a polylog\nfactor). The key in the algorithm design is to properly embed the classical\npolynomial filtering techniques into modern first-order algorithms. To the best\nof our knowledge, this is the first time that lower rate bounds and optimal\nmethods have been developed for distributed non-convex optimization problems. \n\n"}
{"id": "1804.04826", "contents": "Title: On Deep Learning-based Massive MIMO Indoor User Localization Abstract: We examine the usability of deep neural networks for multiple-input\nmultiple-output (MIMO) user positioning solely based on the orthogonal\nfrequency division multiplex (OFDM) complex channel coefficients. In contrast\nto other indoor positioning systems (IPSs), the proposed method does not\nrequire any additional piloting overhead or any other changes in the\ncommunications system itself as it is deployed on top of an existing OFDM MIMO\nsystem. Supported by actual measurements, we are mainly interested in the more\nchallenging non-line of sight (NLoS) scenario. However, gradient descent\noptimization is known to require a large amount of data-points for training,\ni.e., the required database would be too large when compared to conventional\nmethods. Thus, we propose a twostep training procedure, with training on\nsimulated line of sight (LoS) data in the first step, and finetuning on\nmeasured NLoS positions in the second step. This turns out to reduce the\nrequired measured training positions and thus, reduces the effort for data\nacquisition. \n\n"}
{"id": "1804.05057", "contents": "Title: 5G Wireless Network Slicing for eMBB, URLLC, and mMTC: A\n  Communication-Theoretic View Abstract: The grand objective of 5G wireless technology is to support three generic\nservices with vastly heterogeneous requirements: enhanced mobile broadband\n(eMBB), massive machine-type communications (mMTC), and ultra-reliable\nlow-latency communications (URLLC). Service heterogeneity can be accommodated\nby network slicing, through which each service is allocated resources to\nprovide performance guarantees and isolation from the other services. Slicing\nof the Radio Access Network (RAN) is typically done by means of orthogonal\nresource allocation among the services. This work studies the potential\nadvantages of allowing for non-orthogonal sharing of RAN resources in uplink\ncommunications from a set of eMBB, mMTC and URLLC devices to a common base\nstation. The approach is referred to as Heterogeneous Non-Orthogonal Multiple\nAccess (H-NOMA), in contrast to the conventional NOMA techniques that involve\nusers with homogeneous requirements and hence can be investigated through a\nstandard multiple access channel. The study devises a communication-theoretic\nmodel that accounts for the heterogeneous requirements and characteristics of\nthe three services. The concept of reliability diversity is introduced as a\ndesign principle that leverages the different reliability requirements across\nthe services in order to ensure performance guarantees with non-orthogonal RAN\nslicing. This study reveals that H-NOMA can lead, in some regimes, to\nsignificant gains in terms of performance trade-offs among the three generic\nservices as compared to orthogonal slicing. \n\n"}
{"id": "1804.06543", "contents": "Title: Average Peak Age-of-Information Minimization in UAV-assisted IoT\n  Networks Abstract: Motivated by the need to ensure timely delivery of information (e.g., status\nupdates) in the Internet-of-things (IoT) paradigm, this paper investigates the\nrole of an Unmanned aerial vehicle (UAV) as a mobile relay to minimize the\naverage Peak Age-of-information (PAoI) for a source-destination pair. For this\nsetup, we formulate an optimization problem to jointly optimize the UAV's\nflight trajectory as well as energy and service time allocations for packet\ntransmissions. In order to solve this non-convex problem, we propose an\nefficient iterative algorithm and establish its convergence analytically.\nClosed-form solutions for some sub-problems are also provided. One of the\nsub-problems we solve in this procedure is to jointly optimize the energy and\nservice time allocations for a given trajectory of the UAV. This problem is of\ninterest on its own right because in some cases we may not be able to alter the\nUAV's trajectory based on the locations of the IoT devices (especially when its\nprimary mission is something else). Our numerical results quantify the gains\nthat can be achieved by additionally optimizing the UAV's trajectory. \n\n"}
{"id": "1804.07394", "contents": "Title: QoS Provisioning in Large Wireless Networks Abstract: Quality of service (QoS) provisioning in next-generation mobile\ncommunications systems entails a deep understanding of the delay performance.\nThe delay in wireless networks is strongly affected by the traffic arrival\nprocess and the service process, which in turn depends on the medium access\nprotocol and the signal-to-interference-plus-noise ratio (SINR) distribution.\nIn this work, we characterize the conditional distribution of the service\nprocess given the point process in Poisson bipolar networks. We then provide an\nupper bound on the delay violation probability combining tools from stochastic\nnetwork calculus and stochastic geometry. Furthermore, we analyze the delay\nperformance under statistical queueing constraints using the effective capacity\nformulation. The impact of QoS requirements, network geometry and link distance\non the delay performance is identified. Our results provide useful insights for\nguaranteeing stringent delay requirements in large wireless networks. \n\n"}
{"id": "1804.07642", "contents": "Title: On the Effects of Subpacketization in Content-Centric Mobile Networks Abstract: A large-scale content-centric mobile ad hoc network employing\nsubpacketization is studied in which each mobile node having finite-size cache\nmoves according to the reshuffling mobility model and requests a content object\nfrom the library independently at random according to the Zipf popularity\ndistribution. Instead of assuming that one content object is transferred in a\nsingle time slot, we consider a more challenging scenario where the size of\neach content object is considerably large and thus only a subpacket of a file\ncan be delivered during one time slot, which is motivated by a fast mobility\nscenario. Under our mobility model, we consider a single-hop-based content\ndelivery and characterize the fundamental trade-offs between throughput and\ndelay. The order-optimal throughput-delay trade-off is analyzed by presenting\nthe following two content reception strategies: the sequential reception for\nuncoded caching and the random reception for maximum distance separable\n(MDS)-coded caching. We also perform numerical evaluation to validate our\nanalytical results. In particular, we conduct performance comparisons between\nthe uncoded caching and the MDS-coded caching strategies by identifying the\nregimes in which the performance difference between the two caching strategies\nbecomes prominent with respect to system parameters such as the Zipf exponent\nand the number of subpackets. In addition, we extend our study to the random\nwalk mobility scenario and show that our main results are essentially the same\nas those in the reshuffling mobility model. \n\n"}
{"id": "1804.09120", "contents": "Title: On Optimal Index Codes for Interlinked Cycle Structures with Outer\n  Cycles Abstract: For index coding problems with special structure on the side-information\ngraphs called Interlinked Cycle (IC) structures index codes have been proposed\nin the literature (C. Thapa, L. Ong, and S. Johnson, \"Interlinked Cycles for\nIndex Coding: Generalizing Cycles and Cliques\", in \\textit{IEEE Trans. Inf.\nTheory, vol. 63, no. 6, Jun. 2017} with a correction in \"Interlinked Cycles for\nIndex Coding: Generalizing Cycles and Cliques\", in arxiv (arxiv:1603.00092v2\n[cs.IT] 25 Feb 2018)). In this paper we consider a generalization of IC\nstructures called {\\it IC structures with interlocked outer cycles}. For IC\nstructures with interlocked outer cycles we show that the optimal length (also\nknown as the minrank of the index coding problem) depends on the maximum number\nof disjoint outer cycles. We give two sufficient conditions such that if any of\nthese is satisfied then we provide explicit optimal index code construction.\nThe conditions mentioned above are shown to be not necessary by an explicit\nexample. \n\n"}
{"id": "1804.10298", "contents": "Title: Success Probability and Area Spectral Efficiency of a VANET Modeled as a\n  Cox Process Abstract: This paper analyzes the performance of a vehicular ad hoc network (VANET)\nmodeled as a Cox process, where the spatial layout of the roads is modeled by a\nPoisson line process (PLP) and the locations of nodes on each line are modeled\nas a 1D Poisson point process (PPP). For this setup, we characterize the\nsuccess probability of a typical link and the area spectral efficiency (ASE) of\nthe network assuming slotted ALOHA as the channel access scheme. We then\nconcretely establish that the success probability of a typical link in a VANET\nmodeled using a Cox process converges to that of a 1D and 2D PPP for some\nextreme values of the line and node densities. We also study the trends in\nsuccess probability as a function of the system parameters and show that the\noptimum transmission probability that maximizes the ASE for this Cox process\nmodel differs significantly from those of the relatively-simpler 1D and 2D PPP\nmodels used commonly in the literature to model vehicular networks. \n\n"}
{"id": "1804.10778", "contents": "Title: Hidden Vehicle Sensing via Asynchronous V2V Transmission: A\n  Multi-Path-Geometry Approach Abstract: Accurate vehicular sensing is a basic and important operation in autonomous\ndriving. Unfortunately, the existing techniques have their own limitations. For\ninstance, the communication-based approach (e.g., transmission of GPS\ninformation) has high latency and low reliability while the reflection-based\napproach (e.g., RADAR) is incapable of detecting hidden vehicles (HVs) without\nline-of-sight. This is arguably the reason behind some recent fatal accidents\ninvolving autonomous vehicles. To address this issue, this paper presents a\nnovel HV-sensing technology that exploits multi-path transmission from a HV to\na sensing vehicle (SV). The powerful technology enables the SV to detect\nmultiple HV-state parameters including position, orientation of driving\ndirection, and size. Its implementation does not even require\ntransmitter-receiver synchronization like conventional mobile positioning\ntechniques. Our design approach leverages estimated information on multi-path\n(AoA/AoD/ToA) and their geometric relations. As a result, a complex system of\nequations or optimization problems, where the desired HV-state parameters are\nvariables, can be formulated for different channel-noise conditions. The\ndevelopment of intelligent solution methods ranging from least-square estimator\nto disk/box minimization yields a set of practical HV-sensing techniques. We\nstudy their feasibility conditions in terms of the required number of paths.\nFurthermore, practical solutions, including sequential path combining and\nrandom directional beamforming, are proposed to enable HV-sensing given\ninsufficient paths. Last, realistic simulation of driving in both highway and\nrural scenarios demonstrates the effectiveness of the proposed techniques. In\nsummary, the proposed technique will enhance the capabilities of existing\nvehicular sensing technologies by enabling HV-sensing. \n\n"}
{"id": "1804.10856", "contents": "Title: Efficient Calculation of Meta Distributions and the Performance of User\n  Percentiles Abstract: Meta distributions (MDs) are refined performance metrics in wireless networks\nmodeled using point processes. While there is no known method to directly\ncalculate MDs, the moments of the underlying conditional distributions (given\nthe point process) can often be expressed in exact analytical form. The problem\nof finding the MD given the moments has several solutions, but the standard\napproaches are inefficient and sensitive to the choices of a number of\nparameters. Here we propose and explore the use of a method based on binomial\nmixtures, which has several key advantages over other methods, since it is\nbased on a simple linear transform of the moments. \n\n"}
{"id": "1804.11136", "contents": "Title: Proof of spending in block-chain systems Abstract: We introduce proof of spending in a block-chain system. In this system the\nprobability for a node to create a legal block is proportional to the total\namount of coins it has spent in history. \n\n"}
{"id": "1805.00599", "contents": "Title: Placement Delivery Array Design via Attention-Based Deep Neural Network Abstract: A decentralized coded caching scheme has been proposed by Maddah-Ali and\nNiesen, and has been shown to alleviate the load of networks. Recently,\nplacement delivery array (PDA) was proposed to characterize the coded caching\nscheme. In this paper, a neural architecture is first proposed to learn the\nconstruction of PDAs. Our model solves the problem of variable size PDAs using\nmechanism of neural attention and reinforcement learning. It differs from the\nprevious attempts in that, instead of using combined optimization algorithms to\nget PDAs, it uses sequence-to-sequence model to learn construct PDAs. Numerical\nresults are given to demonstrate that the proposed method can effectively\nimplement coded caching. We also show that the complexity of our method to\nconstruct PDAs is low. \n\n"}
{"id": "1805.00706", "contents": "Title: On the Structure of Interlinked Cycle Structures with Interlocked Outer\n  Cycles Abstract: For index coding problems with special structure on the side-information\ngraphs called Interlinked Cycle (IC) structures index codes have been proposed\nin the literature (C. Thapa, L. Ong, and S. Johnson, \"Interlinked Cycles for\nIndex Coding: Generalizing Cycles and Cliques\", in IEEE Trans. Inf. Theory,\nvol. 63, no. 6, Jun. 2017, with a correction in \"Interlinked Cycles for Index\nCoding: Generalizing Cycles and Cliques\", in arxiv (arxiv:1603.00092v2 [cs.IT]\n25 Feb 2018)). Recently (S. Sasi and B.S. Rajan, \"On Optimal Index Codes for\nInterlinked Cycle Structures with Outer Cycles,\" in arxiv (arXiv:1804.09120v1\n[cs.IT]), 24 Apr 2018) for a generalization of IC structures called IC\nstructures with interlocked outer cycles optimal length index codes have been\nreported and it is shown that the optimal length depends on the maximum number\nof disjoint outer cycles. In this paper we discuss certain structural\nproperties of IC structures with interlocked outer cycles and provide a simple\nalgorithm to find the maximum number of disjoint outer cycles. \n\n"}
{"id": "1805.01808", "contents": "Title: Stochastic Geometry-based Uplink Analysis of Massive MIMO Systems with\n  Fractional Pilot Reuse Abstract: In this work, we analyze the performance of the uplink (UL) of a massive MIMO\nnetwork considering an asymptotically large number of antennas at base stations\n(BSs). We model the locations of BSs as a homogeneous Poisson point process\n(PPP) and assume that their service regions are limited to their respective\nPoisson-Voronoi cells (PVCs). Further, for each PVC, based on a threshold\nradius, we model the cell center (CC) region as the Johnson-Mehl (JM) cell of\nits BS while rest of the PVC is deemed as the cell edge (CE) region. The CC and\nCE users are located uniformly at random independently of each other in the JM\ncell and CE region, respectively. In addition, we consider a fractional pilot\nreuse (FPR) scheme where two different sets of pilot sequences are used for CC\nand CE users with the objective of reducing the interference due to pilot\ncontamination for CE users. Based on the above system model, we derive\nanalytical expressions for the UL signal-to-interference-and-noise ratio (SINR)\ncoverage probability and average spectral efficiency (SE) for randomly selected\nCC and CE users. In addition, we present an approximate expression for the\naverage cell SE. One of the key intermediate results in our analysis is the\napproximate but accurate characterization of the distributions of the CC and CE\nareas of a typical cell. Another key intermediate step is the accurate\ncharacterization of the pair correlation functions of the point processes\nformed by the interfering CC and CE users that subsequently enables the\ncoverage probability analysis. From our system analysis, we present a\npartitioning rule for the number of pilot sequences to be used for CC and CE\nusers as a function of threshold radius that improves the average CE user SE\nwhile achieving similar CC user SE with respect to unity pilot reuse. \n\n"}
{"id": "1805.03785", "contents": "Title: Deep Learning of Geometric Constellation Shaping including Fiber\n  Nonlinearities Abstract: A new geometric shaping method is proposed, leveraging unsupervised machine\nlearning to optimize the constellation design. The learned constellation\nmitigates nonlinear effects with gains up to 0.13 bit/4D when trained with a\nsimplified fiber channel model. \n\n"}
{"id": "1805.07222", "contents": "Title: Deep Reinforcement Learning based Resource Allocation for V2V\n  Communications Abstract: In this paper, we develop a decentralized resource allocation mechanism for\nvehicle-to-vehicle (V2V) communications based on deep reinforcement learning,\nwhich can be applied to both unicast and broadcast scenarios. According to the\ndecentralized resource allocation mechanism, an autonomous agent', a V2V link\nor a vehicle, makes its decisions to find the optimal sub-band and power level\nfor transmission without requiring or having to wait for global information.\nSince the proposed method is decentralized, it incurs only limited transmission\noverhead. From the simulation results, each agent can effectively learn to\nsatisfy the stringent latency constraints on V2V links while minimizing the\ninterference to vehicle-to-infrastructure (V2I) communications. \n\n"}
{"id": "1805.07784", "contents": "Title: Adaptive Recovery of Dictionary-sparse Signals using Binary Measurements Abstract: One-bit compressive sensing (CS) is an advanced version of sparse recovery in\nwhich the sparse signal of interest can be recovered from extremely quantized\nmeasurements. Namely, only the sign of each measurement is available to us. In\nmany applications, the ground-truth signal is not sparse itself, but can be\nrepresented in a redundant dictionary. A strong line of research has addressed\nconventional CS in this signal model including its extension to one-bit\nmeasurements. However, one-bit CS suffers from the extremely large number of\nrequired measurements to achieve a predefined reconstruction error level. A\ncommon alternative to resolve this issue is to exploit adaptive schemes.\nAdaptive sampling acts on the acquired samples to trace the signal in an\nefficient way. In this work, we utilize an adaptive sampling strategy to\nrecover dictionary-sparse signals from binary measurements. For this task, a\nmulti-dimensional threshold is proposed to incorporate the previous signal\nestimates into the current sampling procedure. This strategy substantially\nreduces the required number of measurements for exact recovery. Our proof\napproach is based on the recent tools in high dimensional geometry in\nparticular random hyperplane tessellation and Gaussian width. We show through\nrigorous and numerical analysis that the proposed algorithm considerably\noutperforms state of the art approaches. Further, our algorithm reaches an\nexponential error decay in terms of the number of quantized measurements. \n\n"}
{"id": "1805.08144", "contents": "Title: On Universally Good Flower Codes Abstract: For a Distributed Storage System (DSS), the \\textit{Fractional Repetition}\n(FR) code is a class in which replicas of encoded data packets are stored on\ndistributed chunk servers, where the encoding is done using the Maximum\nDistance Separable (MDS) code. The FR codes allow for exact uncoded repair with\nminimum repair bandwidth. In this paper, FR codes are constructed using finite\nbinary sequences. The condition for universally good FR codes is calculated on\nsuch sequences. For some sequences, the universally good FR codes are explored. \n\n"}
{"id": "1805.08955", "contents": "Title: Coded Caching via Line Graphs of Bipartite Graphs Abstract: We present a coded caching framework using line graphs of bipartite graphs. A\nclique cover of the line graph describes the uncached subfiles at users. A\nclique cover of the complement of the square of the line graph gives a\ntransmission scheme that satisfies user demands. We then define a specific\nclass of such caching line graphs, for which the subpacketization, rate, and\nuncached fraction of the coded caching problem can be captured via its graph\ntheoretic parameters. We present a construction of such caching line graphs\nusing projective geometry. The presented scheme has a rate bounded from above\nby a constant with subpacketization level $q^{O((log_qK)^2)}$ and uncached\nfraction $\\Theta(\\frac{1}{\\sqrt{K}})$, where $K$ is the number of users and $q$\nis a prime power. We also present a subpacketization-dependent lower bound on\nthe rate of coded caching schemes for a given broadcast setup. \n\n"}
{"id": "1805.09066", "contents": "Title: Asymptotic Performance Analysis of GSVD-NOMA Systems with a Large-Scale\n  Antenna Array Abstract: This paper considers a multiple-input multiple-output (MIMO) downlink\ncommunication scenario with one base station and two users, where each user is\nequipped with m antennas and the base station is equipped with n antennas. To\nefficiently exploit the spectrum resources, we propose a transmission protocol\nwhich combines generalized singular value decomposition (GSVD) and\nnon-orthogonal multiple access (NOMA). The average data rates achieved by the\ntwo users are adopted as performance metrics for evaluation of the proposed\nGSVD-NOMA scheme. In particular, we first characterize the limiting\ndistribution of the squared generalized singular values of the two users'\nchannel matrices for the asymptotic case where the numbers of transmit and\nreceive antennas approach infinity. Then, we calculate the normalized average\nindividual rates of the users in the considered asymptotic regime. Furthermore,\nwe extend the proposed GSVD-NOMA scheme to the MIMO downlink communication\nscenario with more than two users by using a hybrid multiple access (MA)\napproach, where the base station first divides the users into different groups,\nthen the proposed GSVD-NOMA scheme is implemented within each group, and\ndifferent groups are allocated with orthogonal bandwidth resources. Finally,\nnumerical results are provided to validate the effectiveness of the proposed\nGSVD-NOMA protocol, and the accuracy of the developed analytical results. \n\n"}
{"id": "1805.09785", "contents": "Title: Entropy and mutual information in models of deep neural networks Abstract: We examine a class of deep learning models with a tractable method to compute\ninformation-theoretic quantities. Our contributions are three-fold: (i) We show\nhow entropies and mutual informations can be derived from heuristic statistical\nphysics methods, under the assumption that weight matrices are independent and\northogonally-invariant. (ii) We extend particular cases in which this result is\nknown to be rigorously exact by providing a proof for two-layers networks with\nGaussian random weights, using the recently introduced adaptive interpolation\nmethod. (iii) We propose an experiment framework with generative models of\nsynthetic datasets, on which we train deep neural networks with a weight\nconstraint designed so that the assumption in (i) is verified during learning.\nWe study the behavior of entropies and mutual informations throughout learning\nand conclude that, in the proposed setting, the relationship between\ncompression and generalization remains elusive. \n\n"}
{"id": "1805.09871", "contents": "Title: Confidence Region of Singular Subspaces for Low-rank Matrix Regression Abstract: Low-rank matrix regression refers to the instances of recovering a low-rank\nmatrix based on specially designed measurements and the corresponding noisy\noutcomes. In the last decade, numerous statistical methodologies have been\ndeveloped for efficiently recovering the unknown low-rank matrices. However, in\nsome applications, the unknown singular subspace is scientifically more\nimportant than the low-rank matrix itself. In this article, we revisit the\nlow-rank matrix regression model and introduce a two-step procedure to\nconstruct confidence regions of the singular subspace. The procedure involves\nthe de-biasing for the typical low-rank estimators after which we calculate the\nempirical singular vectors. We investigate the distribution of the joint\nprojection distance between the empirical singular subspace and the unknown\ntrue singular subspace. We specifically prove the asymptotical normality of the\njoint projection distance with data-dependent centering and normalization when\n$r^{3/2}(m_1+m_2)^{3/2}=o(n/\\log n)$ where $m_1, m_2$ denote the matrix row and\ncolumn sizes, $r$ is the rank and $n$ is the number of independent random\nmeasurements. Consequently, we propose data-dependent confidence regions of the\ntrue singular subspace which attains any pre-determined confidence level\nasymptotically. In addition, non-asymptotical convergence rates are also\nestablished. Numerical results are presented to demonstrate the merits of our\nmethods. \n\n"}
{"id": "1805.10025", "contents": "Title: The Error Probability of Generalized Perfect Codes via the Meta-Converse Abstract: We introduce a definition of perfect and quasi-perfect codes for symmetric\nchannels parametrized by an auxiliary output distribution. This notion\ngeneralizes previous definitions of perfect and quasi-perfect codes and\nencompasses maximum distance separable codes. The error probability of these\ncodes, whenever they exist, is shown to coincide with the estimate provided by\nthe meta-converse lower bound. We illustrate how the proposed definition\nnaturally extends to cover almost-lossless source-channel coding and lossy\ncompression. \n\n"}
{"id": "1805.11895", "contents": "Title: RLS Recovery with Asymmetric Penalty: Fundamental Limits and Algorithmic\n  Approaches Abstract: This paper studies regularized least square recovery of signals whose\nsamples' prior distributions are nonidentical, e.g., signals with time-variant\nsparsity. For this model, Bayesian framework suggests to regularize the least\nsquares term with an asymmetric penalty. We investigate this problem in two\nrespects: First, we characterize the asymptotic performance via the replica\nmethod and then discuss algorithmic approaches to the problem. Invoking the\nasymptotic characterization of the performance, we propose a tuning strategy to\noptimally tune the algorithmic approaches for recovery. To demonstrate\napplications of the results, the particular example of BPSK recovery is\ninvestigated and the efficiency of the proposed strategy is depicted in the\nshadow of results available in the literature \n\n"}
{"id": "1806.00063", "contents": "Title: Privacy Under Hard Distortion Constraints Abstract: We study the problem of data disclosure with privacy guarantees, wherein the\nutility of the disclosed data is ensured via a \\emph{hard distortion}\nconstraint. Unlike average distortion, hard distortion provides a deterministic\nguarantee of fidelity. For the privacy measure, we use a tunable information\nleakage measure, namely \\textit{maximal $\\alpha$-leakage}\n($\\alpha\\in[1,\\infty]$), and formulate the privacy-utility tradeoff problem.\nThe resulting solution highlights that under a hard distortion constraint, the\nnature of the solution remains unchanged for both local and non-local privacy\nrequirements. More precisely, we show that both the optimal mechanism and the\noptimal tradeoff are invariant for any $\\alpha>1$; i.e., the tunable leakage\nmeasure only behaves as either of the two extrema, i.e., mutual information for\n$\\alpha=1$ and maximal leakage for $\\alpha=\\infty$. \n\n"}
{"id": "1806.00118", "contents": "Title: Statistical Problems with Planted Structures: Information-Theoretical\n  and Computational Limits Abstract: Over the past few years, insights from computer science, statistical physics,\nand information theory have revealed phase transitions in a wide array of\nhigh-dimensional statistical problems at two distinct thresholds: One is the\ninformation-theoretical (IT) threshold below which the observation is too noisy\nso that inference of the ground truth structure is impossible regardless of the\ncomputational cost; the other is the computational threshold above which\ninference can be performed efficiently, i.e., in time that is polynomial in the\ninput size. In the intermediate regime, inference is information-theoretically\npossible, but conjectured to be computationally hard.\n  This article provides a survey of the common techniques for determining the\nsharp IT and computational limits, using community detection and submatrix\ndetection as illustrating examples. For IT limits, we discuss tools including\nthe first and second moment method for analyzing the maximum likelihood\nestimator, information-theoretic methods for proving impossibility results\nusing mutual information and rate-distortion theory, and methods originated\nfrom statistical physics such as interpolation method. To investigate\ncomputational limits, we describe a common recipe to construct a randomized\npolynomial-time reduction scheme that approximately maps instances of the\nplanted clique problem to the problem of interest in total variation distance. \n\n"}
{"id": "1806.00661", "contents": "Title: Capacity of Single-Server Single-Message Private Information Retrieval\n  with Coded Side Information Abstract: This paper considers the problem of single-server single-message private\ninformation retrieval with coded side information (PIR-CSI). In this problem,\nthere is a server storing a database, and a user which knows a linear\ncombination of a subset of messages in the database as a side information. The\nnumber of messages contributing to the side information is known to the server,\nbut the indices and the coefficients of these messages are unknown to the\nserver. The user wishes to download a message from the server privately, i.e.,\nwithout revealing which message it is requesting, while minimizing the download\ncost. In this work, we consider two different settings for the PIR-CSI problem\ndepending on the demanded message being or not being one of the messages\ncontributing to the side information. For each setting, we prove an upper bound\non the maximum download rate as a function of the size of the database and the\nsize of the side information, and propose a protocol that achieves the rate\nupper-bound. \n\n"}
{"id": "1806.00990", "contents": "Title: Time-Fractional User Association in Millimeter Wave MIMO Networks Abstract: User association determines which base stations a user connects to, hence\naffecting the amount of network interference and consequently the network\nthroughput. Conventional user association schemes, however, assume that user\ninstantaneous rates are independent of user association. In this paper, we\nintroduce a new load-aware user association scheme for millimeter wave (mmWave)\nMIMO networks which takes into account the dependency of network interference\non user association. This consideration is well suited for mmWave\ncommunications, where the links are highly directional and vulnerable to small\nchannel variations. We formulate our user association problem as a mixed\ninteger nonlinear programming (MINLP) and solve it using the genetic algorithm.\nWe show that the proposed method can improve network performance by moving the\ntraffic of congested base stations to lightly-loaded base stations and\nadjusting the interference accordingly. Our simulations confirm that our scheme\nresults in a higher network throughput compared to conventional user\nassociation techniques. \n\n"}
{"id": "1806.01799", "contents": "Title: Survey and Taxonomy of Lossless Graph Compression and Space-Efficient\n  Graph Representations Abstract: Various graphs such as web or social networks may contain up to trillions of\nedges. Compressing such datasets can accelerate graph processing by reducing\nthe amount of I/O accesses and the pressure on the memory subsystem. Yet,\nselecting a proper compression method is challenging as there exist a plethora\nof techniques, algorithms, domains, and approaches in compressing graphs. To\nfacilitate this, we present a survey and taxonomy on lossless graph compression\nthat is the first, to the best of our knowledge, to exhaustively analyze this\ndomain. Moreover, our survey does not only categorize existing schemes, but\nalso explains key ideas, discusses formal underpinning in selected works, and\ndescribes the space of the existing compression schemes using three dimensions:\nareas of research (e.g., compressing web graphs), techniques (e.g., gap\nencoding), and features (e.g., whether or not a given scheme targets dynamic\ngraphs). Our survey can be used as a guide to select the best lossless\ncompression scheme in a given setting. \n\n"}
{"id": "1806.01991", "contents": "Title: The stabilizer for $n$-qubit symmetric states Abstract: The stabilizer group for an $n$-qubit state $\\ket{\\phi}$ is the set of all\ninvertible local operators (ILO) $g=g_1\\otimes g_2\\otimes \\cdots\\otimes g_n,$ $\ng_i\\in \\mathcal{GL}(2,\\mathbb{C})$ such that $\\ket{\\phi}=g\\ket{\\phi}.$\nRecently, G. Gour $et$ $al.$ \\cite{GKW} presented that almost all $n$-qubit\nstate $\\ket{\\psi}$ own a trivial stabilizer group when $n\\ge 5.$ In this\narticle, we consider the case when the stabilizer group of an $n$-qubit\nsymmetric pure state $\\ket{\\psi}$ is trivial. First we show that the stabilizer\ngroup for an n-qubit symmetric pure state $\\ket{\\phi}$ is nontrivial when $n\\le\n4$. Then we present a class of $n$-qubit symmetric states $\\ket{\\phi}$ with the\ntrivial stabilizer group. At last, we prove that an $n$-qubit symmetric pure\nstate owns a trivial stabilizer group when its diversity number is bigger than\n5, which confirms the main result of \\cite{GKW} partly. \n\n"}
{"id": "1806.02015", "contents": "Title: Distributed Hypothesis Testing with Privacy Constraints Abstract: We revisit the distributed hypothesis testing (or hypothesis testing with\ncommunication constraints) problem from the viewpoint of privacy. Instead of\nobserving the raw data directly, the transmitter observes a sanitized or\nrandomized version of it. We impose an upper bound on the mutual information\nbetween the raw and randomized data. Under this scenario, the receiver, which\nis also provided with side information, is required to make a decision on\nwhether the null or alternative hypothesis is in effect. We first provide a\ngeneral lower bound on the type-II exponent for an arbitrary pair of\nhypotheses. Next, we show that if the distribution under the alternative\nhypothesis is the product of the marginals of the distribution under the null\n(i.e., testing against independence), then the exponent is known exactly.\nMoreover, we show that the strong converse property holds. Using ideas from\nEuclidean information theory, we also provide an approximate expression for the\nexponent when the communication rate is low and the privacy level is high.\nFinally, we illustrate our results with a binary and a Gaussian example. \n\n"}
{"id": "1806.02937", "contents": "Title: Coverage Probability of 3D Mobile UAV Networks Abstract: In this paper, we consider a network of multiple unmanned aerial vehicles\n(UAVs) where a given number of UAVs are placed at three-dimensional (3D)\nlocations in a finite circular disk shaped region to serve a reference ground\nuser equipment (UE) located at its center. Herein, a serving UAV is assumed to\nbe located at fixed altitude which communicates with the reference UE. All the\nother UAVs in the network are designated as interfering UAVs to the UE and are\nassumed to have 3D mobility. To characterize the 3D UAV movement process, we\nhereby propose an effective 3D mobility model based on the mixed random\nwaypoint mobility (RWPM) and uniform mobility (UM) models in the vertical and\nspatial directions. Further, considering the proposed 3D mobility model, we\nfirst characterize the interference received at reference UE, and then evaluate\nits coverage probability under Nakagami-m fading. We quantify the achievable\nperformance gains for the ground UE under various system and channel\nconditions. Moreover, we corroborate our analytical results through\nsimulations. \n\n"}
{"id": "1806.03227", "contents": "Title: An Information-Percolation Bound for Spin Synchronization on General\n  Graphs Abstract: This paper considers the problem of reconstructing $n$ independent uniform\nspins $X_1,\\dots,X_n$ living on the vertices of an $n$-vertex graph $G$, by\nobserving their interactions on the edges of the graph. This captures instances\nof models such as (i) broadcasting on trees, (ii) block models, (iii)\nsynchronization on grids, (iv) spiked Wigner models. The paper gives an\nupper-bound on the mutual information between two vertices in terms of a bond\npercolation estimate. Namely, the information between two vertices' spins is\nbounded by the probability that these vertices are connected in a bond\npercolation model, where edges are opened with a probability that \"emulates\"\nthe edge-information. Both the information and the open-probability are based\non the Chi-squared mutual information. The main results allow us to re-derive\nknown results for information-theoretic non-reconstruction in models (i)-(iv),\nwith more direct or improved bounds in some cases, and to obtain new results,\nsuch as for a spiked Wigner model on grids. The main result also implies a new\nsubadditivity property for the Chi-squared mutual information for symmetric\nchannels and general graphs, extending the subadditivity property obtained by\nEvans-Kenyon-Peres-Schulman [EKPS00] for trees. \n\n"}
{"id": "1806.03803", "contents": "Title: Chaining Mutual Information and Tightening Generalization Bounds Abstract: Bounding the generalization error of learning algorithms has a long history,\nwhich yet falls short in explaining various generalization successes including\nthose of deep learning. Two important difficulties are (i) exploiting the\ndependencies between the hypotheses, (ii) exploiting the dependence between the\nalgorithm's input and output. Progress on the first point was made with the\nchaining method, originating from the work of Kolmogorov, and used in the\nVC-dimension bound. More recently, progress on the second point was made with\nthe mutual information method by Russo and Zou '15. Yet, these two methods are\ncurrently disjoint. In this paper, we introduce a technique to combine the\nchaining and mutual information methods, to obtain a generalization bound that\nis both algorithm-dependent and that exploits the dependencies between the\nhypotheses. We provide an example in which our bound significantly outperforms\nboth the chaining and the mutual information bounds. As a corollary, we tighten\nDudley's inequality when the learning algorithm chooses its output from a small\nsubset of hypotheses with high probability. \n\n"}
{"id": "1806.04589", "contents": "Title: Computation Rate Maximization in UAV-Enabled Wireless Powered\n  Mobile-Edge Computing Systems Abstract: Mobile edge computing (MEC) and wireless power transfer (WPT) are two\npromising techniques to enhance the computation capability and to prolong the\noperational time of low-power wireless devices that are ubiquitous in Internet\nof Things. However, the computation performance and the harvested energy are\nsignificantly impacted by the severe propagation loss. In order to address this\nissue, an unmanned aerial vehicle (UAV)-enabled MEC wireless powered system is\nstudied in this paper. The computation rate maximization problems in a\nUAV-enabled MEC wireless powered system are investigated under both partial and\nbinary computation offloading modes, subject to the energy harvesting causal\nconstraint and the UAV's speed constraint. These problems are non-convex and\nchallenging to solve. A two-stage algorithm and a three-stage alternative\nalgorithm are respectively proposed for solving the formulated problems. The\nclosed-form expressions for the optimal central processing unit frequencies,\nuser offloading time, and user transmit power are derived. The optimal\nselection scheme on whether users choose to locally compute or offload\ncomputation tasks is proposed for the binary computation offloading mode.\nSimulation results show that our proposed resource allocation schemes\noutperforms other benchmark schemes. The results also demonstrate that the\nproposed schemes converge fast and have low computational complexity. \n\n"}
{"id": "1806.05005", "contents": "Title: Proactive Resource Allocation with Predictable Channel Statistics Abstract: The behavior of users in relatively predictable, both in terms of the data\nthey request and the wireless channels they observe. In this paper, we consider\nthe statistics of such predictable patterns of the demand and channel jointly\nacross multiple users, and develop a novel predictive resource allocation\nmethod. This method is shown to provide performance benefits over a reactive\napproach, which ignores these patterns and instead aims to satisfy the\ninstantaneous demands, irrespective of cost to the system. In particular, we\nshow that our proposed method is able to attain a novel fundamental bound on\nthe achievable cost, as the service window grows. Through numerical evaluation,\nwe gain insights into how different uncertainty sources affect the decisions\nand the cost. \n\n"}
{"id": "1806.05533", "contents": "Title: Distributed Hypothesis Testing based on Unequal-Error Protection Codes Abstract: Coding and testing schemes for binary hypothesis testing over noisy networks\nare proposed and their corresponding type-II error exponents are derived. When\ncommunication is over a discrete memoryless channel (DMC), our scheme combines\nShimokawa-Han-Amari's hypothesis testing scheme with Borade's unequal error\nprotection (UEP) for channel coding. A separate source channel coding\narchitecture is employed. The resulting exponent is optimal for the newly\nintroduced class of \\emph{generalized testing against conditional\nindependence}. When communication is over a MAC or a BC, our scheme combines\nhybrid coding with UEP. The resulting error exponent over the MAC is optimal in\nthe case of generalized testing against conditional independence with\nindependent observations at the two sensors, when the MAC decomposes into two\nindividual DMCs. In this case, separate source-channel coding is sufficient;\nthis same conclusion holds also under arbitrarily correlated sensor\nobservations when testing is against independence. For the BC, the error\nexponents region of hybrid coding with UEP exhibits a tradeoff between the\nexponents attained at the two decision centers. When both receivers aim at\nmaximizing the error exponents under different hypotheses and the marginal\ndistributions of the sensors' observations are different under these\nhypotheses, then this tradeoff can be mitigated with the following strategy.\nThe sensor makes a tentative guess on the hypothesis, submits this guess, and\napplies our coding and testing scheme for the DMC only for the decision center\nthat is not interested in maximizing the exponent under the guessed hypothesis. \n\n"}
{"id": "1806.05712", "contents": "Title: Permutation polynomials and complete permutation polynomials over\n  $\\mathbb{F}_{q^{3}}$ Abstract: Motivated by many recent constructions of permutation polynomials over\n$\\mathbb{F}_{q^2}$, we study permutation polynomials over $\\mathbb{F}_{q^3}$ in\nterms of their coefficients. Based on the multivariate method and resultant\nelimination, we construct several new classes of sparse permutation polynomials\nover $\\mathbb{F}_{q^3}$, $q=p^{k}$, $p\\geq3$. Some of them are complete\nmappings. \n\n"}
{"id": "1806.07800", "contents": "Title: Full Coded Caching Gains for Cache-less Users Abstract: Within the context of coded caching, the work reveals the interesting\nconnection between having multiple transmitters and having heterogeneity in the\ncache sizes of the receivers. Our work effectively shows that having multiple\ntransmit antennas -- while providing full multiplexing gains -- can also\nsimultaneously completely remove the performance penalties that are typically\nassociated to cache-size unevenness. Focusing on the multiple-input\nsingle-output Broadcast Channel, the work first identifies the performance\nlimits of the extreme case where cache-aided users coincide with users that do\nnot have caches, and then expands the analysis to the case where both user\ngroups are cache-aided but with heterogeneous cache-sizes. In the first case,\nthe main contribution is a new algorithm that employs perfect matchings on a\nbipartite graph to offer full multiplexing as well as full coded-caching gains\nto both cache-aided as well as cache-less users. An interesting conclusion is\nthat, starting from a single-stream centralized coded caching setting with\nnormalized cache size $\\gamma$, then adding $L$ antennas allows for the\naddition of {up to} approximately $L/\\gamma$ extra cache-less users, at no\nadded delay costs. Similarly surprising is the finding that, {beginning} with a\nsingle-antenna hybrid system (with both cache-less and cache-aided users), then\nadding {$L-1$} antennas to the transmitter, as well as endowing the cache-less\nusers with a cumulative normalized cache size $\\Gamma_2$, increases the Degrees\nof Freedom by a \\emph{multiplicative} factor of up to $\\Gamma_{2}+L$. \n\n"}
{"id": "1806.08690", "contents": "Title: Is the 1-norm the best convex sparse regularization? Abstract: The 1-norm is a good convex regularization for the recovery of sparse vectors\nfrom under-determined linear measurements. No other convex regularization seems\nto surpass its sparse recovery performance. How can this be explained? To\nanswer this question, we define several notions of \"best\" (convex)\nregulariza-tion in the context of general low-dimensional recovery and show\nthat indeed the 1-norm is an optimal convex sparse regularization within this\nframework. \n\n"}
{"id": "1806.08698", "contents": "Title: To Skip or to Switch? Minimizing Age of Information under Link Capacity\n  Constraint Abstract: Consider a scenario where a source continuously monitors an object and sends\ntime-stamped status updates to a destination through a rate-limited link. In\norder to measure the \"freshness\" of the status information available at the\ndestination, we adopt the metric called Age of Information (AoI). We assume all\nupdates are of the same size, and arrive randomly at the source according to a\nBernoulli process. Due to the link capacity constraint, it takes $d$ ($d\\geq\n2$) time slots for the source to complete the transmission of an update.\nTherefore, when a new update when arrives at the source and it is transmitting\nanother update, the source needs to decide whether to skip the new arrival or\nto switch to it, in order to minimize the expected average AoI at the\ndestination. We prove that within a broadly defined class of online policies,\nthe optimal policy should be a renewal policy, and has a sequential switching\nproperty. We then show that the optimal decision the source should take in any\ntime slot has a multiple-threshold structure, and only depends on the age of\nthe update being transmitted and the AoI in the system. The thresholds are then\nnumerically identified by formulating the problem as a Markov Decision Process\n(MDP). \n\n"}
{"id": "1806.09619", "contents": "Title: Novel Decentralized Coded Caching through Coded Prefetching Abstract: We propose a new decentralized coded caching scheme for a two-phase caching\nnetwork, where the data placed in user caches in the prefetching phase are\nrandom portions of a maximal distance separable (MDS) coded version of the\noriginal files. The proposed scheme achieves a better rate memory trade-off by\nutilizing the reconstruction property of MDS codes which reduces the number of\ntransmissions that are useful only for a small subset of users in the delivery\nphase. Unlike the previously available coded prefetching schemes, the proposed\nscheme does not require to have more users than files. The proposed scheme can\nbe viewed as a generalization of the original uncoded prefetching based\ndecentralized coded caching scheme, and likewise, is applicable to various\nnetwork topologies. \n\n"}
{"id": "1806.09768", "contents": "Title: Optimal Streaming Erasure Codes over the Three-Node Relay Network Abstract: This paper investigates low-latency streaming codes for a three-node relay\nnetwork. The source transmits a sequence of messages (streaming messages) to\nthe destination through the relay between them, where the first-hop channel\nfrom the source to the relay and the second-hop channel from the relay to the\ndestination are subject to packet erasures. Every source message must be\nrecovered perfectly at the destination subject to a fixed decoding delay of $T$\ntime slots. In any sliding window of $T+1$ time slots, we assume no more than\n$N_1$ and $N_2$ erasures are introduced by the first-hop channel and second-hop\nchannel respectively. Under this channel loss assumption, we fully characterize\nthe maximum achievable rate in terms of $T$, $N_1$ and $N_2$. The achievability\nis proved by using a symbol-wise decode-forward strategy where the source\nsymbols within the same message are decoded by the relay with different delays.\nThe converse is proved by analyzing the maximum achievable rate for each\nchannel when the erasures in the other channel are consecutive (bursty). In\naddition, we show that traditional message-wise decode-forward strategies,\nwhich require the source symbols within the same message to be decoded by the\nrelay with the same delay, are sub-optimal in general. \n\n"}
{"id": "1807.00655", "contents": "Title: On the Tradeoff Between Accuracy and Complexity in Blind Detection of\n  Polar Codes Abstract: Polar codes are a recent family of error-correcting codes with a number of\ndesirable characteristics. Their disruptive nature is illustrated by their\nrapid adoption in the $5^{th}$-generation mobile-communication standard, where\nthey are used to protect control messages. In this work, we describe a\ntwo-stage system tasked with identifying the location of control messages that\nconsists of a detection and selection stage followed by a decoding one. The\nfirst stage spurs the need for polar-code detection algorithms with variable\neffort to balance complexity between the two stages. We illustrate this idea of\nvariable effort for multiple detection algorithms aimed at the first stage. We\npropose three novel blind detection methods based on belief-propagation\ndecoding inspired by early-stopping criteria. Then we show how their\nreliability improves with the number of decoding iterations to highlight the\npossible tradeoffs between accuracy and complexity. Additionally, we show\nsimilar tradeoffs for a detection method from previous work. In a setup where\nonly one block encoded with the polar code of interest is present among many\nother blocks, our results notably show that, depending on the complexity\nbudget, a variable number of undesirable blocks can be dismissed while\nachieving a missed-detection rate in line with the block-error rate of a\ncomplex decoding algorithm. \n\n"}
{"id": "1807.00682", "contents": "Title: Dynamic Power Allocation and User Scheduling for Power-Efficient and\n  Low-Latency Communications Abstract: In this paper, we propose a joint dynamic power control and user pairing\nalgorithm for power-efficient and low-latency hybrid multiple access systems.\nIn a hybrid multiple access system, user pairing determines whether the\ntransmitter should serve a certain user by orthogonal multiple access (OMA) or\nnon-orthogonal multiple access (NOMA). The proposed optimization framework\nminimizes the long-term time-average transmit power expenditure while reducing\nthe queueing delay and satisfying time-average data rate requirements. The\nproposed technique observes channel and queue state information and adjusts\nqueue backlogs to avoid an excessive queueing delay by appropriate user pairing\nand power allocation. Further, user scheduling for determining the activation\nof a given user link as well as flexible use of resources are captured in the\nproposed algorithm. Data-intensive simulation results show that the proposed\nscheme guarantees an end-to-end delay smaller than 1 ms with high\npower-efficiency and high reliability, based on the short frame structure\ndesigned for ultra-reliable low-latency communications (URLLC). \n\n"}
{"id": "1807.01251", "contents": "Title: Training behavior of deep neural network in frequency domain Abstract: Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization. \n\n"}
{"id": "1807.02494", "contents": "Title: Joint Channel-Estimation/Decoding with Frequency-Selective Channels and\n  Few-Bit ADCs Abstract: We propose a fast and near-optimal approach to joint channel-estimation,\nequalization, and decoding of coded single-carrier (SC) transmissions over\nfrequency-selective channels with few-bit analog-to-digital converters (ADCs).\nOur approach leverages parametric bilinear generalized approximate message\npassing (PBiGAMP) to reduce the implementation complexity of joint channel\nestimation and (soft) symbol decoding to that of a few fast Fourier transforms\n(FFTs). Furthermore, it learns and exploits sparsity in the channel impulse\nresponse. Our work is motivated by millimeter-wave systems with bandwidths on\nthe order of Gsamples/sec, where few-bit ADCs, SC transmissions, and fast\nprocessing all lead to significant reductions in power consumption and\nimplementation cost. We numerically demonstrate our approach using signals and\nchannels generated according to the IEEE 802.11ad wireless local area network\n(LAN) standard, in the case that the receiver uses analog beamforming and a\nsingle ADC. \n\n"}
{"id": "1807.03525", "contents": "Title: On the minimum weights of binary linear complementary dual codes Abstract: Linear complementary dual codes (or codes with complementary duals) are codes\nwhose intersections with their dual codes are trivial. We study the largest\nminimum weight $d(n,k)$ among all binary linear complementary dual $[n,k]$\ncodes. We determine $d(n,4)$ for $n \\equiv 2,3,4,5,6,9,10,13 \\pmod{15}$, and\n$d(n,5)$ for $n \\equiv 3,4,5,7,11,19,20,22,26 \\pmod{31}$. Combined with known\nresults, the values $d(n,k)$ are also determined for $n \\le 24$. \n\n"}
{"id": "1807.04848", "contents": "Title: Modeling and Analysis of D2D Millimeter-Wave Networks with Poisson\n  Cluster Processes Abstract: This paper investigates the performance of millimeter wave (mmWave)\ncommunications in clustered device-to-device (D2D) networks. The locations of\nD2D transceivers are modeled as a Poisson Cluster Process (PCP). In each\ncluster, devices are equipped with multiple antennas, and the active D2D\ntransmitter (D2D-Tx) utilizes mmWave to serve one of the proximate D2D\nreceivers (D2D-Rxs). Specifically, we introduce three user association\nstrategies: 1) Uniformly distributed D2D-Tx model; 2) Nearest D2D-Tx model; 3)\nClosest line-of-site (LOS) D2D-Tx model. To characterize the performance of the\nconsidered scenarios, we derive new analytical expressions for the coverage\nprobability and area spectral efficiency (ASE). Additionally, in order to\nefficiently illustrating the general trends of our system, a closed-form lower\nbound for the special case interfered by intra-cluster LOS links is derived. We\nprovide Monte Carlo simulations to corroborate the theoretical results and show\nthat: 1) The coverage probability is mainly affected by the intra-cluster\ninterference with LOS links; 2) There exists an optimum number of\nsimultaneously active D2D-Txs in each cluster for maximizing ASE; and 3)\nClosest LOS model outperforms the other two scenarios but at the cost of extra\nsystem overhead. \n\n"}
{"id": "1807.05152", "contents": "Title: Information theory with finite vector spaces Abstract: Whereas Shannon entropy is related to the growth rate of multinomial\ncoefficients, we show that the quadratic entropy (Tsallis 2-entropy) is\nconnected to their $q$-deformation; when $q$ is a prime power, these\n$q$-multinomial coefficients count flags of finite vector spaces with\nprescribed length and dimensions. In particular, the $q$-binomial coefficients\ncount vector subspaces of given dimension. We obtain this way a combinatorial\nexplanation for the nonadditivity of the quadratic entropy, which arises from a\nrecursive counting of flags. We show that statistical systems whose\nconfigurations are described by flags provide a frequentist justification for\nthe maximum entropy principle with Tsallis statistics. We introduce then a\ndiscrete-time stochastic process associated to the $q$-binomial probability\ndistribution, that generates at time $n$ a vector subspace of $\\mathbb{F}_q^n$\n(here $\\mathbb{F}_q$ is the finite field of order $q$). The concentration of\nmeasure on certain \"typical subspaces\" allows us to extend the asymptotic\nequipartition property to this setting. The size of the typical set is\nquantified by the quadratic entropy. We discuss the applications to Shannon\ntheory, particularly to source coding, when messages correspond to vector\nspaces. \n\n"}
{"id": "1807.06143", "contents": "Title: Quickest Detection of Dynamic Events in Networks Abstract: The problem of quickest detection of dynamic events in networks is studied.\nAt some unknown time, an event occurs, and a number of nodes in the network are\naffected by the event, in that they undergo a change in the statistics of their\nobservations. It is assumed that the event is dynamic, in that it can propagate\nalong the edges in the network, and affect more and more nodes with time. The\nevent propagation dynamics is assumed to be unknown. The goal is to design a\nsequential algorithm that can detect a \"significant\" event, i.e., when the\nevent has affected no fewer than $\\eta$ nodes, as quickly as possible, while\ncontrolling the false alarm rate. Fully connected networks are studied first,\nand the results are then extended to arbitrarily connected networks. The\ndesigned algorithms are shown to be adaptive to the unknown propagation\ndynamics, and their first-order asymptotic optimality is demonstrated as the\nfalse alarm rate goes to zero. The algorithms can be implemented with linear\ncomputational complexity in the network size at each time step, which is\ncritical for online implementation. Numerical simulations are provided to\nvalidate the theoretical results. \n\n"}
{"id": "1807.06846", "contents": "Title: Practical MIMO-NOMA: Low Complexity & Capacity-Approaching Solution Abstract: MIMO-NOMA combines Multiple-Input Multiple-Output (MIMO) and Non-Orthogonal\nMultiple Access (NOMA), which can address heterogeneous challenges, such as\nmassive connectivity, low latency, and high reliability. In this paper, a\npractical coded MIMO-NOMA system with capacityapproaching performance as well\nas low implementation complexity is proposed. Specifically, the employed\nreceiver consists of a multi-user Linear Minimum Mean-Square Error (LMMSE)\ndetector and a bank of single-user message-passing decoders, which decompose\nthe overall signal recovery into distributed low-complexity calculations. An\nasymptotic extrinsic information transfer analysis is proposed to estimate the\nperformance of iterative receiver, where practical channel codes that match\nwith the LMMSE detector in the iterative decoding perspective are constructed.\nAs a result, the proposed coded MIMO-NOMA system achieves asymptotic\nperformances within 0.2 dB from the theoretical capacity. Simulation results\nvalidate the reliability and robustness of the proposed system in practical\nsettings, including various system loads, iteration numbers, code lengths, and\nchannel conditions. \n\n"}
{"id": "1807.11190", "contents": "Title: Distributed Stochastic Optimization in Networks with Low Informational\n  Exchange Abstract: We consider a distributed stochastic optimization problem in networks with\nfinite number of nodes. Each node adjusts its action to optimize the global\nutility of the network, which is defined as the sum of local utilities of all\nnodes. Gradient descent method is a common technique to solve the optimization\nproblem, while the computation of the gradient may require much information\nexchange. In this paper, we consider that each node can only have a noisy\nnumerical observation of its local utility, of which the closed-form expression\nis not available. This assumption is quite realistic, especially when the\nsystem is too complicated or constantly changing. Nodes may exchange the\nobservation of their local utilities to estimate the global utility at each\ntimeslot. We propose stochastic perturbation based distributed algorithms under\nthe assumptions whether each node has collected local utilities of all or only\npart of the other nodes. We use tools from stochastic approximation to prove\nthat both algorithms converge to the optimum. The convergence rate of the\nalgorithms is also derived. Although the proposed algorithms can be applied to\ngeneral optimization problems, we perform simulations considering power control\nin wireless networks and present numerical results to corroborate our claim. \n\n"}
{"id": "1807.11250", "contents": "Title: Fast Analog Transmission for High-Mobility Wireless Data Acquisition in\n  Edge Learning Abstract: By implementing machine learning at the network edge, edge learning trains\nmodels by leveraging rich data distributed at edge devices (e.g., smartphones\nand sensors) and in return endow on them capabilities of seeing, listening, and\nreasoning. In edge learning, the need of high-mobility wireless data\nacquisition arises in scenarios where edge devices (or even servers) are\nmounted on the ground or aerial vehicles. In this paper, we present a novel\nsolution, called fast analog transmission (FAT), for high- mobility data\nacquisition in edge-learning systems, which has several key features. First,\nFAT incurs low-latency. Specifically, FAT requires no source-and-channel coding\nand no channel training via the proposed technique of Grassmann analog encoding\n(GAE) that encodes data samples into subspace matrices. Second, FAT supports\nspatial multiplexing by directly transmitting analog vector data over an\nantenna array. Third, FAT can be seamlessly integrated with edge learning\n(i.e., training of a classifier model in this work). In particular, by applying\na Grassmannian-classification algorithm from computer vision, the received GAE\nencoded data can be directly applied to training the model without decoding and\nconversion. This design is found by simulation to outperform conventional\nschemes in learning accuracy due to its robustness against data distortion\ninduced by fast fading. \n\n"}
{"id": "1807.11317", "contents": "Title: Utility-Optimized Local Differential Privacy Mechanisms for Distribution\n  Estimation Abstract: LDP (Local Differential Privacy) has been widely studied to estimate\nstatistics of personal data (e.g., distribution underlying the data) while\nprotecting users' privacy. Although LDP does not require a trusted third party,\nit regards all personal data equally sensitive, which causes excessive\nobfuscation hence the loss of utility. In this paper, we introduce the notion\nof ULDP (Utility-optimized LDP), which provides a privacy guarantee equivalent\nto LDP only for sensitive data. We first consider the setting where all users\nuse the same obfuscation mechanism, and propose two mechanisms providing ULDP:\nutility-optimized randomized response and utility-optimized RAPPOR. We then\nconsider the setting where the distinction between sensitive and non-sensitive\ndata can be different from user to user. For this setting, we propose a\npersonalized ULDP mechanism with semantic tags to estimate the distribution of\npersonal data with high utility while keeping secret what is sensitive for each\nuser. We show theoretically and experimentally that our mechanisms provide much\nhigher utility than the existing LDP mechanisms when there are a lot of\nnon-sensitive data. We also show that when most of the data are non-sensitive,\nour mechanisms even provide almost the same utility as non-private mechanisms\nin the low privacy regime. \n\n"}
{"id": "1807.11939", "contents": "Title: Entanglement cost and quantum channel simulation Abstract: This paper proposes a revised definition for the entanglement cost of a\nquantum channel $\\mathcal{N}$. In particular, it is defined here to be the\nsmallest rate at which entanglement is required, in addition to free classical\ncommunication, in order to simulate $n$ calls to $\\mathcal{N}$, such that the\nmost general discriminator cannot distinguish the $n$ calls to $\\mathcal{N}$\nfrom the simulation. The most general discriminator is one who tests the\nchannels in a sequential manner, one after the other, and this discriminator is\nknown as a quantum tester [Chiribella et al., Phys. Rev. Lett., 101, 060401\n(2008)] or one who is implementing a quantum co-strategy [Gutoski et al., Symp.\nTh. Comp., 565 (2007)]. As such, the proposed revised definition of\nentanglement cost of a quantum channel leads to a rate that cannot be smaller\nthan the previous notion of a channel's entanglement cost [Berta et al., IEEE\nTrans. Inf. Theory, 59, 6779 (2013)], in which the discriminator is limited to\ndistinguishing parallel uses of the channel from the simulation. Under this\nrevised notion, I prove that the entanglement cost of certain\nteleportation-simulable channels is equal to the entanglement cost of their\nunderlying resource states. Then I find single-letter formulas for the\nentanglement cost of some fundamental channel models, including dephasing,\nerasure, three-dimensional Werner--Holevo channels, epolarizing channels\n(complements of depolarizing channels), as well as single-mode pure-loss and\npure-amplifier bosonic Gaussian channels. These examples demonstrate that the\nresource theory of entanglement for quantum channels is not reversible.\nFinally, I discuss how to generalize the basic notions to arbitrary resource\ntheories. \n\n"}
{"id": "1808.00189", "contents": "Title: Multi-Beam UAV Communication in Cellular Uplink: Cooperative\n  Interference Cancellation and Sum-Rate Maximization Abstract: Integrating unmanned aerial vehicles (UAVs) into the cellular network as new\naerial users is a promising solution to meet their ever-increasing\ncommunication demands in a plethora of applications. Due to the high UAV\naltitude, the channels between UAVs and the ground base stations (GBSs) are\ndominated by the strong line-of-sight (LoS) links, thus severe interference may\nbe generated to/from the GBSs in the uplink/downlink, which renders the\ninterference management with coexisting terrestrial and aerial users a more\nchallenging problem to solve. In this paper, we study the uplink communication\nfrom a multi-antenna UAV to a set of GBSs in its signal coverage region. Among\nthese GBSs, we denote available GBSs as the ones that do not serve any\nterrestrial users at the assigned resource block (RB) of the UAV, and occupied\nGBSs as the rest that are serving their respectively associated terrestrial\nusers in the same RB. We propose a new cooperative interference cancellation\nstrategy for the multi-beam UAV uplink communication, which aims to eliminate\nthe co-channel interference at each of the occupied GBSs and in the meanwhile\nmaximize the sum-rate to the available GBSs. Specifically, the multi-antenna\nUAV sends multiple data streams to selected available GBSs, which in turn\nforward their decoded data streams to their backhaul-connected occupied GBSs\nfor interference cancellation. To draw useful insights, the maximum\ndegrees-of-freedom (DoF) achievable by the multi-beam UAV communication for\nsum-rate maximization in the high signal-to-noise ratio (SNR) regime is first\ncharacterized, subject to the stringent constraint that all the occupied GBSs\ndo not suffer from any interference in the UAV's uplink transmission. Then,\nbased on the DoF-optimal design, the achievable sum-rate at finite SNR is\nmaximized, subject to given maximum allowable interference power constraints at\neach occupied GBS. \n\n"}
{"id": "1808.00277", "contents": "Title: Non-Orthogonal Multiple Access for 5G and Beyond Abstract: Driven by the rapid escalation of the wireless capacity requirements imposed\nby advanced multimedia applications (e.g., ultra-high-definition video, virtual\nreality etc.), as well as the dramatically increasing demand for user access\nrequired for the Internet of Things (IoT), the fifth generation (5G) networks\nface challenges in terms of supporting large-scale heterogeneous data traffic.\nNon-orthogonal multiple access (NOMA), which has been recently proposed for the\n3rd generation partnership projects long-term evolution advanced (3GPP-LTE-A),\nconstitutes a promising technology of addressing the above-mentioned challenges\nin 5G networks by accommodating several users within the same orthogonal\nresource block. By doing so, significant bandwidth efficiency enhancement can\nbe attained over conventional orthogonal multiple access (OMA) techniques. This\nmotivated numerous researchers to dedicate substantial research contributions\nto this field. In this context, we provide a comprehensive overview of the\nstate-of-the-art in power-domain multiplexing aided NOMA, with a focus on the\ntheoretical NOMA principles, multiple antenna aided NOMA design, on the\ninterplay between NOMA and cooperative transmission, on the resource control of\nNOMA, on the co-existence of NOMA with other emerging potential 5G techniques\nand on the comparison with other NOMA variants. We highlight the main\nadvantages of power-domain multiplexing NOMA compared to other existing NOMA\ntechniques. We summarize the challenges of existing research contributions of\nNOMA and provide potential solutions. Finally, we offer some design guidelines\nfor NOMA systems and identify promising research opportunities for the future. \n\n"}
{"id": "1808.00519", "contents": "Title: Orthogonal Time Frequency Space Modulation Abstract: This paper introduces a new two-dimensional modulation technique called\nOrthogonal Time Frequency Space (OTFS) modulation. OTFS has the novel and\nimportant feature of being designed in the delay-Doppler domain. When coupled\nwith a suitable equalizer, OTFS modulation is able to exploit the full channel\ndiversity over both time and frequency. Moreover, it converts the fading,\ntime-varying wireless channel experienced by modulated signals such as OFDM\ninto a time-independent channel with a complex channel gain that is essentially\nconstant for all symbols.\n  This design obviates the need for transmitter adaptation, and greatly\nsimplifies system operation. The paper describes the basic operating principles\nof OTFS as well as a possible implementation as an overlay to current or\nanticipated standardized systems. OTFS is shown to provide significant\nperformance improvement in systems with high Doppler, short packets, and/or\nlarge antenna array. In particular, simulation results indicate at least\nseveral dB of block error rate performance improvement for OTFS over OFDM in\nall of these settings. \n\n"}
{"id": "1808.01933", "contents": "Title: On the Duality and File Size Hierarchy of Fractional Repetition Codes Abstract: Distributed storage systems that deploy erasure codes can provide better\nfeatures such as lower storage overhead and higher data reliability. In this\npaper, we focus on fractional repetition (FR) codes, which are a class of\nstorage codes characterized by the features of uncoded exact repair and minimum\nrepair bandwidth. We study the duality of FR codes, and investigate the\nrelationship between the supported file size of an FR code and its dual code.\nBased on the established relationship, we derive an improved dual bound on the\nsupported file size of FR codes. We further show that FR codes constructed from\n$t$-designs are optimal when the size of the stored file is sufficiently large.\nMoreover, we present the tensor product technique for combining FR codes, and\nelaborate on the file size hierarchy of resulting codes. \n\n"}
{"id": "1808.02342", "contents": "Title: A Very Brief Introduction to Machine Learning With Applications to\n  Communication Systems Abstract: Given the unprecedented availability of data and computing resources, there\nis widespread renewed interest in applying data-driven machine learning methods\nto problems for which the development of conventional engineering solutions is\nchallenged by modelling or algorithmic deficiencies. This tutorial-style paper\nstarts by addressing the questions of why and when such techniques can be\nuseful. It then provides a high-level introduction to the basics of supervised\nand unsupervised learning. For both supervised and unsupervised learning,\nexemplifying applications to communication networks are discussed by\ndistinguishing tasks carried out at the edge and at the cloud segments of the\nnetwork at different layers of the protocol stack. \n\n"}
{"id": "1808.03880", "contents": "Title: Parallelization does not Accelerate Convex Optimization: Adaptivity\n  Lower Bounds for Non-smooth Convex Minimization Abstract: In this paper we study the limitations of parallelization in convex\noptimization. A convenient approach to study parallelization is through the\nprism of \\emph{adaptivity} which is an information theoretic measure of the\nparallel runtime of an algorithm [BS18]. Informally, adaptivity is the number\nof sequential rounds an algorithm needs to make when it can execute\npolynomially-many queries in parallel at every round. For combinatorial\noptimization with black-box oracle access, the study of adaptivity has recently\nled to exponential accelerations in parallel runtime and the natural question\nis whether dramatic accelerations are achievable for convex optimization.\n  For the problem of minimizing a non-smooth convex function $f:[0,1]^n\\to\n\\mathbb{R}$ over the unit Euclidean ball, we give a tight lower bound that\nshows that even when $\\texttt{poly}(n)$ queries can be executed in parallel,\nthere is no randomized algorithm with $\\tilde{o}(n^{1/3})$ rounds of adaptivity\nthat has convergence rate that is better than those achievable with a\none-query-per-round algorithm. A similar lower bound was obtained by Nemirovski\n[Nem94], however that result holds for the $\\ell_{\\infty}$-setting instead of\n$\\ell_2$. In addition, we also show a tight lower bound that holds for\nLipschitz and strongly convex functions.\n  At the time of writing this manuscript we were not aware of Nemirovski's\nresult. The construction we use is similar to the one in [Nem94], though our\nanalysis is different. Due to the close relationship between this work and\n[Nem94], we view the research contribution of this manuscript limited and it\nshould serve as an instructful approach to understanding lower bounds for\nparallel optimization. \n\n"}
{"id": "1808.04618", "contents": "Title: On Robustness of Massive MIMO Systems Against Passive Eavesdropping\n  under Antenna Selection Abstract: In massive MIMO wiretap settings, the base station can significantly suppress\neavesdroppers by narrow beamforming toward legitimate terminals. Numerical\ninvestigations show that by this approach, secrecy is obtained at no\nsignificant cost. We call this property of massive MIMO systems `secrecy for\nfree' and show that it not only holds when all the transmit antennas at the\nbase station are employed, but also when only a single antenna is set active.\nUsing linear precoding, the information leakage to the eavesdroppers can be\nsufficiently diminished, when the total number of available transmit antennas\nat the base station grows large, even when only a fixed number of them are\nselected. This result indicates that passive eavesdropping has no significant\nimpact on massive MIMO systems, regardless of the number of active transmit\nantennas. \n\n"}
{"id": "1808.04905", "contents": "Title: Multi-Sector and Multi-Panel Performance in 5G mmWave Cellular Networks Abstract: The next generation of cellular networks (5G) will exploit the mmWave\nspectrum to increase the available capacity. Communication at such high\nfrequencies, however, suffers from high path loss and blockage, therefore\ndirectional transmissions using antenna arrays and dense deployments are\nneeded. Thus, when evaluating the performance of mmWave mobile networks, it is\nnecessary to accurately model the complex channel, the directionality of the\ntransmission, but also the interplay that these elements can have with the\nwhole protocol stack, both in the radio access and in the higher layers. In\nthis paper, we improve the channel model abstraction of the mmWave module for\nns-3, by introducing the support of a more realistic antenna array model,\ncompliant with 3GPP NR requirements, and of multiple antenna arrays at the base\nstations and mobile handsets. We then study the end-to-end performance of a\nmmWave cellular network by varying the channel and antenna array\nconfigurations, and show that increasing the number of antenna arrays and,\nconsequently, the number of sectors is beneficial for both throughput and\nlatency. \n\n"}
{"id": "1808.05678", "contents": "Title: Optimization of MIMO Device-to-Device Networks via Matrix Fractional\n  Programming: A Minorization-Maximization Approach Abstract: Interference management is a fundamental issue in device-to-device (D2D)\ncommunications whenever the transmitter-and-receiver pairs are located in close\nproximity and frequencies are fully reused, so active links may severely\ninterfere with each other. This paper devises an optimization strategy named\nFPLinQ to coordinate the link scheduling decisions among the interfering links,\nalong with power control and beamforming. The key enabler is a novel\noptimization method called matrix fractional programming (FP) that generalizes\nprevious scalar and vector forms of FP in allowing multiple data streams per\nlink. From a theoretical perspective, this paper provides a deeper\nunderstanding of FP by showing a connection to the minorization-maximization\n(MM) algorithm. From an application perspective, this paper shows that as\ncompared to the existing methods for coordinating scheduling in the D2D\nnetwork, such as FlashLinQ, ITLinQ, and ITLinQ+, the proposed FPLinQ approach\nis more general in allowing multiple antennas at both the transmitters and the\nreceivers, and further in allowing arbitrary and multiple possible associations\nbetween the devices via matching. Numerical results show that FPLinQ\nsignificantly outperforms the previous state-of-the-art in a typical D2D\ncommunication environment. \n\n"}
{"id": "1808.07139", "contents": "Title: Low-Complexity Reconfigurable MIMO for Millimeter Wave Communications Abstract: The performance of millimeter wave (mmWave) multiple-input multiple-output\n(MIMO) systems is limited by the sparse nature of propagation channels and the\nrestricted number of radio frequency (RF) chains at transceivers. The\nintroduction of reconfigurable antennas offers an additional degree of freedom\non designing mmWave MIMO systems. This paper provides a theoretical framework\nfor studying the mmWave MIMO with reconfigurable antennas. Based on the virtual\nchannel model, we present an architecture of reconfigurable mmWave MIMO with\nbeamspace hybrid analog-digital beamformers and reconfigurable antennas at both\nthe transmitter and the receiver. We show that employing reconfigurable\nantennas can provide throughput gain for the mmWave MIMO. We derive the\nexpression for the average throughput gain of using reconfigurable antennas in\nthe system, and further derive the expression for the outage throughput gain\nfor the scenarios where the channels are (quasi) static. Moreover, we propose a\nlow-complexity algorithm for reconfiguration state selection and beam\nselection. Our numerical results verify the derived expressions for the\nthroughput gains and demonstrate the near-optimal throughput performance of the\nproposed low-complexity algorithm. \n\n"}
{"id": "1808.08019", "contents": "Title: Linear complexity of generalized cyclotomic sequences of period $2p^{m}$ Abstract: In this paper, we construct two generalized cyclotomic binary sequences of\nperiod $2p^{m}$ based on the generalized cyclotomy and compute their linear\ncomplexity, showing that they are of high linear complexity when $m\\geq 2$. \n\n"}
{"id": "1808.08520", "contents": "Title: No lattice tiling of $\\mathbb{Z}^n$ by Lee Sphere of radius 2 Abstract: We prove the nonexistence of lattice tilings of $\\mathbb{Z}^n$ by Lee spheres\nof radius $2$ for all dimensions $n\\geq 3$. This implies that the Golomb-Welch\nconjecture is true when the common radius of the Lee spheres equals $2$ and\n$2n^2+2n+1$ is a prime. As a direct consequence, we also answer an open\nquestion in the degree-diameter problem of graph theory: the order of any\nabelian Cayley graph of diameter $2$ and degree larger than $5$ cannot meet the\nabelian Cayley Moore bound. \n\n"}
{"id": "1808.08926", "contents": "Title: Opportunistic Treating Interference as Noise Abstract: We consider a $K$-user interference network with $M$ states, where each\ntransmitter has $M$ messages and over State $m$, Receiver $k$ wishes to decode\nthe first $\\pi_k(m) \\in \\{1,2,\\cdots,M\\}$ messages from its desired\ntransmitter. This problem of channel with states models opportunistic\ncommunications, where more messages are sent for better channel states. The\nfirst message from each transmitter has the highest priority as it is required\nto be decoded regardless of the state of the receiver; the second message is\nopportunistically decoded if the state allows a receiver to decode 2 messages;\nand the $M$-th message has the lowest priority as it is decoded if and only if\nthe receiver wishes to decode all $M$ messages. For this interference network\nwith states, we show that if any possible combination of the channel states\nsatisfies a condition under which power control and treating interference as\nnoise (TIN) are sufficient to achieve the entire generalized degrees of freedom\n(GDoF) region of this channel state by itself, then a simple layered\nsuperposition encoding scheme with power control and a successive decoding\nscheme with TIN achieves the entire GDoF region of the network with $M$ states\nfor all $KM$ messages. \n\n"}
{"id": "1808.10506", "contents": "Title: Maximum Entropy Principle Analysis in Network Systems with Short-time\n  Recordings Abstract: In many realistic systems, maximum entropy principle (MEP) analysis provides\nan effective characterization of the probability distribution of network\nstates. However, to implement the MEP analysis, a sufficiently long-time data\nrecording in general is often required, e.g., hours of spiking recordings of\nneurons in neuronal networks. The issue of whether the MEP analysis can be\nsuccessfully applied to network systems with data from short recordings has yet\nto be fully addressed. In this work, we investigate relationships underlying\nthe probability distributions, moments, and effective interactions in the MEP\nanalysis and then show that, with short recordings of network dynamics, the MEP\nanalysis can be applied to reconstructing probability distributions of network\nstates under the condition of asynchronous activity of nodes in the network.\nUsing spike trains obtained from both Hodgkin-Huxley neuronal networks and\nelectrophysiological experiments, we verify our results and demonstrate that\nMEP analysis provides a tool to investigate the neuronal population coding\nproperties, even for short recordings. \n\n"}
{"id": "1809.04380", "contents": "Title: Binary MDS Array Codes with Optimal Repair Abstract: Consider a binary maximum distance separable (MDS) array code composed of an\n$m\\times (k+r)$ array of bits with $k$ information columns and $r$ parity\ncolumns, such that any $k$ out of $k+r$ columns suffice to reconstruct the $k$\ninformation columns. Our goal is to provide {\\em optimal repair access} for\nbinary MDS array codes, meaning that the bandwidth triggered to repair any\nsingle failed information or parity column is minimized. In this paper, we\npropose a generic transformation framework for binary MDS array codes, using\nEVENODD codes as a motivating example, to support optimal repair access for\n$k+1\\le d \\le k+r-1$, where $d$ denotes the number of non-failed columns that\nare connected for repair; note that when $d<k+r-1$, some of the chosen $d$\ncolumns in repairing a failed column are specific. In addition, we show how our\ntransformation framework applies to an example of binary MDS array codes with\nasymptotically optimal repair access of any single information column and\nenables asymptotically or exactly optimal repair access for any column.\nFurthermore, we present a new transformation for EVENODD codes with two parity\ncolumns such that the existing efficient repair property of any information\ncolumn is preserved and the repair access of parity column is optimal. \n\n"}
{"id": "1809.08365", "contents": "Title: A Unified Framework for the Tractable Analysis of Multi-Antenna Wireless\n  Networks Abstract: Densifying networks and deploying more antennas at each access point are two\nprincipal ways to boost the capacity of wireless networks. However, the\ncomplicated distributions of the signal power and the accumulated interference\npower, largely induced by various space-time processing techniques, make it\nhighly challenging to quantitatively characterize the performance of\nmulti-antenna networks. In this paper, using tools from stochastic geometry, a\nunified framework is developed for the analysis of such networks. The major\nresults are two innovative representations of the coverage probability, which\nmake the analysis of multi-antenna networks almost as tractable as the\nsingle-antenna case. One is expressed as an $\\ell_1$-induced norm of a Toeplitz\nmatrix, and the other is given in a finite sum form. With a compact\nrepresentation, the former incorporates many existing analytical results on\nsingle- and multi-antenna networks as special cases, and leads to tractable\nexpressions for evaluating the coverage probability in both ad hoc and cellular\nnetworks. While the latter is more complicated for numerical evaluation, it\nhelps analytically gain key design insights. In particular, it helps prove that\nthe coverage probability of ad hoc networks is a monotonically decreasing\nconvex function of the transmitter density and that there exists a peak value\nof the coverage improvement when increasing the number of transmit antennas. On\nthe other hand, in multi-antenna cellular networks, it is shown that the\ncoverage probability is independent of the transmitter density and that the\noutage probability decreases exponentially as the number of transmit antennas\nincreases. \n\n"}
{"id": "1809.09231", "contents": "Title: Tunable Measures for Information Leakage and Applications to\n  Privacy-Utility Tradeoffs Abstract: We introduce a tunable measure for information leakage called maximal\nalpha-leakage. This measure quantifies the maximal gain of an adversary in\ninferring any (potentially random) function of a dataset from a release of the\ndata. The inferential capability of the adversary is, in turn, quantified by a\nclass of adversarial loss functions that we introduce as $\\alpha$-loss,\n$\\alpha\\in[1,\\infty]$. The choice of $\\alpha$ determines the specific\nadversarial action and ranges from refining a belief (about any function of the\ndata) for $\\alpha=1$ to guessing the most likely value for $\\alpha=\\infty$\nwhile refining the $\\alpha^{th}$ moment of the belief for $\\alpha$ in between.\nMaximal alpha-leakage then quantifies the adversarial gain under $\\alpha$-loss\nover all possible functions of the data. In particular, for the extremal values\nof $\\alpha=1$ and $\\alpha=\\infty$, maximal alpha-leakage simplifies to mutual\ninformation and maximal leakage, respectively. For $\\alpha\\in(1,\\infty)$ this\nmeasure is shown to be the Arimoto channel capacity of order $\\alpha$. We show\nthat maximal alpha-leakage satisfies data processing inequalities and a\nsub-additivity property thereby allowing for a weak composition result.\nBuilding upon these properties, we use maximal alpha-leakage as the privacy\nmeasure and study the problem of data publishing with privacy guarantees,\nwherein the utility of the released data is ensured via a hard distortion\nconstraint. Unlike average distortion, hard distortion provides a deterministic\nguarantee of fidelity. We show that under a hard distortion constraint, for\n$\\alpha>1$ the optimal mechanism is independent of $\\alpha$, and therefore, the\nresulting optimal tradeoff is the same for all values of $\\alpha>1$. Finally,\nthe tunability of maximal alpha-leakage as a privacy measure is also\nillustrated for binary data with average Hamming distortion as the utility\nmeasure. \n\n"}
{"id": "1809.09237", "contents": "Title: Nonconvex Robust Low-rank Matrix Recovery Abstract: In this paper we study the problem of recovering a low-rank matrix from a\nnumber of random linear measurements that are corrupted by outliers taking\narbitrary values. We consider a nonsmooth nonconvex formulation of the problem,\nin which we explicitly enforce the low-rank property of the solution by using a\nfactored representation of the matrix variable and employ an $\\ell_1$-loss\nfunction to robustify the solution against outliers. We show that even when a\nconstant fraction (which can be up to almost half) of the measurements are\narbitrarily corrupted, as long as certain measurement operators arising from\nthe measurement model satisfy the so-called $\\ell_1/\\ell_2$-restricted isometry\nproperty, the ground-truth matrix can be exactly recovered from any global\nminimum of the resulting optimization problem. Furthermore, we show that the\nobjective function of the optimization problem is sharp and weakly convex.\nConsequently, a subgradient Method (SubGM) with geometrically diminishing step\nsizes will converge linearly to the ground-truth matrix when suitably\ninitialized. We demonstrate the efficacy of the SubGM for the nonconvex robust\nlow-rank matrix recovery problem with various numerical experiments. \n\n"}
{"id": "1809.09983", "contents": "Title: On recovery of signals with single point spectrum degeneracy Abstract: The paper study recovery problem for discrete time signals with a finite\nnumber of missing values. The paper establishes recoverability of these missing\nvalues for signals with Z-transform vanishing with a certain rate at a single\npoint.\n  The transfer functions for the corresponding recovering kernels are presented\nexplicitly.\n  Some robustness of the recovery with respect to data truncation or noise\ncontamination is established. \n\n"}
{"id": "1810.00276", "contents": "Title: Wireless Powered Cooperative Relaying using NOMA with Imperfect CSI Abstract: The impact of imperfect channel state (CSI) information in an energy\nharvesting (EH) cooperative non-orthogonal multiple access (NOMA) network,\nconsisting of a source, two users, and an EH relay is investigated in this\npaper. The relay is not equipped with a fixed power source and acts as a\nwireless powered node to help signal transmission to the users. Closed-form\nexpressions for the outage probability of both users are derived under\nimperfect CSI for two different power allocation strategies namely fixed and\ndynamic power allocation. Monte Carlo simulations are used to numerically\nevaluate the effect of imperfect CSI. These results confirm the theoretical\noutage analysis and show that NOMA can outperform orthogonal multiple access\neven with imperfect CSI. \n\n"}
{"id": "1810.00295", "contents": "Title: On Exact and $\\infty$-R\\'enyi Common Informations Abstract: Recently, two extensions of Wyner's common information\\textemdash exact and\nR\\'enyi common informations\\textemdash were introduced respectively by Kumar,\nLi, and El Gamal (KLE), and the present authors. The class of common\ninformation problems involves determining the minimum rate of the common input\nto two independent processors needed to exactly or approximately generate a\ntarget joint distribution. For the exact common information problem, exact\ngeneration of the target distribution is required, while for Wyner's and\n$\\alpha$-R\\'enyi common informations, the relative entropy and R\\'enyi\ndivergence with order $\\alpha$ were respectively used to quantify the\ndiscrepancy between the synthesized and target distributions. The exact common\ninformation is larger than or equal to Wyner's common information. However, it\nwas hitherto unknown whether the former is strictly larger than the latter for\nsome joint distributions. In this paper, we first establish the equivalence\nbetween the exact and $\\infty$-R\\'enyi common informations, and then provide\nsingle-letter upper and lower bounds for these two quantities. For doubly\nsymmetric binary sources, we show that the upper and lower bounds coincide,\nwhich implies that for such sources, the exact and $\\infty$-R\\'enyi common\ninformations are completely characterized. Interestingly, we observe that for\nsuch sources, these two common informations are strictly larger than Wyner's.\nThis answers an open problem posed by KLE. Furthermore, we extend Wyner's,\n$\\infty$-R\\'enyi, and exact common informations to sources with countably\ninfinite or continuous alphabets, including Gaussian sources. \n\n"}
{"id": "1810.00774", "contents": "Title: Geometric Constellation Shaping for Fiber Optic Communication Systems\n  via End-to-end Learning Abstract: In this paper, an unsupervised machine learning method for geometric\nconstellation shaping is investigated. By embedding a differentiable fiber\nchannel model within two neural networks, the learning algorithm is optimizing\nfor a geometric constellation shape. The learned constellations yield improved\nperformance to state-of-the-art geometrically shaped constellations, and\ninclude an implicit trade-off between amplification noise and nonlinear\neffects. Further, the method allows joint optimization of system parameters,\nsuch as the optimal launch power, simultaneously with the constellation shape.\nAn experimental demonstration validates the findings. Improved performances are\nreported, up to 0.13 bit/4D in simulation and experimentally up to 0.12 bit/4D. \n\n"}
{"id": "1810.03427", "contents": "Title: Distributed Hypothesis Testing with Collaborative Detection Abstract: A detection system with a single sensor and two detectors is considered,\nwhere each of the terminals observes a memoryless source sequence, the sensor\nsends a message to both detectors and the first detector sends a message to the\nsecond detector. Communication of these messages is assumed to be error-free\nbut rate-limited. The joint probability mass function (pmf) of the source\nsequences observed at the three terminals depends on an $\\mathsf{M}$-ary\nhypothesis $(\\mathsf{M} \\geq 2)$, and the goal of the communication is that\neach detector can guess the underlying hypothesis. Detector $k$, $k=1,2$, aims\nto maximize the error exponent \\textit{under hypothesis} $i_k$, $i_k \\in\n\\{1,\\ldots,\\mathsf{M}\\}$, while ensuring a small probability of error under all\nother hypotheses. We study this problem in the case in which the detectors aim\nto maximize their error exponents under the \\textit{same} hypothesis (i.e.,\n$i_1=i_2$) and in the case in which they aim to maximize their error exponents\nunder \\textit{distinct} hypotheses (i.e., $i_1 \\neq i_2$). For the setting in\nwhich $i_1=i_2$, we present an achievable exponents region for the case of\npositive communication rates, and show that it is optimal for a specific case\nof testing against independence. We also characterize the optimal exponents\nregion in the case of zero communication rates. For the setting in which $i_1\n\\neq i_2$, we characterize the optimal exponents region in the case of zero\ncommunication rates. \n\n"}
{"id": "1810.06741", "contents": "Title: Achieving Covert Wireless Communications Using a Full-Duplex Receiver Abstract: Covert communications hide the transmission of a message from a watchful\nadversary while ensuring a certain decoding performance at the receiver. In\nthis work, a wireless communication system under fading channels is considered\nwhere covertness is achieved by using a full-duplex (FD) receiver. More\nprecisely, the receiver of covert information generates artificial noise with a\nvarying power causing uncertainty at the adversary, Willie, regarding the\nstatistics of the received signals. Given that Willie's optimal detector is a\nthreshold test on the received power, we derive a closed-form expression for\nthe optimal detection performance of Willie averaged over the fading channel\nrealizations. Furthermore, we provide guidelines for the optimal choice of\nartificial noise power range, and the optimal transmission probability of\ncovert information to maximize the detection errors at Willie. Our analysis\nshows that the transmission of artificial noise, although causes\nself-interference, provides the opportunity of achieving covertness but its\ntransmit power levels need to be managed carefully. We also demonstrate that\nthe prior transmission probability of 0.5 is not always the best choice for\nachieving the maximum possible covertness, when the covert transmission\nprobability and artificial noise power can be jointly optimized. \n\n"}
{"id": "1810.06938", "contents": "Title: Wireless Access in Ultra-Reliable Low-Latency Communication (URLLC) Abstract: The future connectivity landscape and, notably, the 5G wireless systems will\nfeature Ultra-Reliable Low Latency Communication (URLLC). The coupling of high\nreliability and low latency requirements in URLLC use cases makes the wireless\naccess design very challenging, in terms of both the protocol design and of the\nassociated transmission techniques. This paper aims to provide a broad\nperspective on the fundamental tradeoffs in URLLC as well as the principles\nused in building access protocols. Two specific technologies are considered in\nthe context of URLLC: massive MIMO and multi-connectivity, also termed\ninterface diversity. The paper also touches upon the important question of the\nproper statistical methodology for designing and assessing extremely high\nreliability levels. \n\n"}
{"id": "1810.07014", "contents": "Title: Bregman Divergence Bounds and Universality Properties of the Logarithmic\n  Loss Abstract: A loss function measures the discrepancy between the true values and their\nestimated fits, for a given instance of data. In classification problems, a\nloss function is said to be proper if a minimizer of the expected loss is the\ntrue underlying probability. We show that for binary classification, the\ndivergence associated with smooth, proper, and convex loss functions is upper\nbounded by the Kullback-Leibler (KL) divergence, to within a normalization\nconstant. This implies that by minimizing the logarithmic loss associated with\nthe KL divergence, we minimize an upper bound to any choice of loss from this\nset. As such the logarithmic loss is universal in the sense of providing\nperformance guarantees with respect to a broad class of accuracy measures.\nImportantly, this notion of universality is not problem-specific, enabling its\nuse in diverse applications, including predictive modeling, data clustering and\nsample complexity analysis. Generalizations to arbitrary finite alphabets are\nalso developed. The derived inequalities extend several well-known\n$f$-divergence results. \n\n"}
{"id": "1810.13068", "contents": "Title: Symbiotic Radio: A New Communication Paradigm for Passive\n  Internet-of-Things Abstract: In this paper, a novel technique, called symbiotic radio (SR), is proposed\nfor passive Internet-of-Things (IoT), in which a backscatter device (BD) is\nintegrated with a primary transmission. The primary transmitter is designed to\nassist the primary and BD transmissions, and the primary receiver decodes the\ninformation from the primary transmitter as well as the BD. We consider a\nmultiple-input single-output (MISO) SR and the symbol period for BD\ntransmission is designed to be either the same as or much longer than that of\nthe primary system, resulting in parasitic or commensal relationship between\nthe primary and BD transmissions. We first derive the achievable rates for the\nprimary system and the BD transmission. Then, we formulate two transmit\nbeamforming optimization problems, i.e., the weighted sum-rate maximization\nproblem and the transmit power minimization problem, and solve these non-convex\nproblems by applying semi-definite relaxation technique. In addition, a novel\ntransmit beamforming structure is proposed to reduce the computational\ncomplexity of the solutions. Simulation results show that when the BD\ntransmission rate is properly designed, the proposed SR not only enables the\nopportunistic transmission for the BD via energy-efficient passive\nbackscattering, but also enhances the achievable rate of the primary system by\nproperly exploiting the additional signal path from the BD. \n\n"}
{"id": "1811.03269", "contents": "Title: Hardware-Constrained Millimeter Wave Systems for 5G: Challenges,\n  Opportunities, and Solutions Abstract: Although millimeter wave (mmWave) systems promise to offer larger bandwidth\nand unprecedented peak data rates, their practical implementation faces several\nhardware challenges compared to sub-6 GHz communication systems. These hardware\nconstraints can seriously undermine the performance and deployment progress of\nmmWave systems and, thus, necessitate disruptive solutions in the cross-design\nof analog and digital modules. In this article, we discuss the importance of\ndifferent hardware constraints and propose a novel system architecture, which\nis able to release these hardware constraints while achieving better\nperformance for future millimeter wave communication systems. The\ncharacteristics of the proposed architecture are articulated in detail, and a\nrepresentative example is provided to demonstrate its validity and efficacy. \n\n"}
{"id": "1811.04611", "contents": "Title: Subspace Packings Abstract: The Grassmannian ${\\mathcal G}_q(n,k)$ is the set of all $k$-dimensional\nsubspaces of the vector space $\\mathbb{F}_q^n$. It is well known that codes in\nthe Grassmannian space can be used for error-correction in random network\ncoding. On the other hand, these codes are $q$-analogs of codes in the Johnson\nscheme, i.e. constant dimension codes. These codes of the Grassmannian\n${\\mathcal G}_q(n,k)$ also form a family of $q$-analogs of block designs and\nthey are called \\emph{subspace designs}. The application of subspace codes has\nmotivated extensive work on the $q$-analogs of block designs.\n  In this paper, we examine one of the last families of $q$-analogs of block\ndesigns which was not considered before. This family called \\emph{subspace\npackings} is the $q$-analog of packings. This family of designs was considered\nrecently for network coding solution for a family of multicast networks called\nthe generalized combination networks. A \\emph{subspace packing}\n$t$-$(n,k,\\lambda)^m_q$ is a set $\\mathcal{S}$ of $k$-subspaces from ${\\mathcal\nG}_q(n,k)$ such that each $t$-subspace of ${\\mathcal G}_q(n,t)$ is contained in\nat most $\\lambda$ elements of $\\mathcal{S}$. The goal of this work is to\nconsider the largest size of such subspace packings. \n\n"}
{"id": "1811.05626", "contents": "Title: A framework for covert and secret key expansion over quantum channels Abstract: Covert and secret quantum key distribution aims at generating\ninformation-theoretically secret bits between distant legitimate parties in a\nmanner that remains provably undetectable by an adversary. We propose a\nframework in which to precisely define and analyze such an operation, and we\nshow that covert and secret key expansion is possible. For fixed and known\nclassical-quantum channels, we develop and analyze protocols based on forward\nand reverse reconciliation. When the adversary applies the same quantum channel\nindependently on each transmitted quantum state, akin to a collective attack in\nthe quantum key distribution literature, we propose a protocol that achieves\ncovert and secret key expansion under mild restrictions. The crux of our\napproach is the use of information reconciliation and privacy amplification\ntechniques that are able to process the sparse signals required for covert\noperation and whose Shannon entropy scales as the square root of their length.\n% diffuse information content quantified through Shannon entropy induced by the\nsparse signaling required for covert operation. In particular, our results show\nthat the coordination required between legitimate parties to achieve covert\ncommunication can be achieved with a negligible number of secret key bits. \n\n"}
{"id": "1811.09652", "contents": "Title: Generalised Entropies and Metric-Invariant Optimal Countermeasures for\n  Information Leakage under Symmetric Constraints Abstract: We introduce a novel generalization of entropy and conditional entropy from\nwhich most definitions from the literature can be derived as particular cases.\nWithin this general framework, we investigate the problem of designing\ncountermeasures for information leakage. In particular, we seek\nmetric-invariant solutions, i.e., they are robust against the choice of entropy\nfor quantifying the leakage. The problem can be modelled as an information\nchannel from the system to an adversary, and the countermeasures can be seen as\nmodifying this channel in order to minimise the amount of information that the\noutputs reveal about the inputs. Our main result is to fully solve the problem\nunder the highly symmetrical design constraint that the number of inputs that\ncan produce the same output is capped. Our proof is constructive and the\noptimal channels and the minimum leakage are derived in closed form. \n\n"}
{"id": "1811.09923", "contents": "Title: Average-Case Information Complexity of Learning Abstract: How many bits of information are revealed by a learning algorithm for a\nconcept class of VC-dimension $d$? Previous works have shown that even for\n$d=1$ the amount of information may be unbounded (tend to $\\infty$ with the\nuniverse size). Can it be that all concepts in the class require leaking a\nlarge amount of information? We show that typically concepts do not require\nleakage. There exists a proper learning algorithm that reveals $O(d)$ bits of\ninformation for most concepts in the class. This result is a special case of a\nmore general phenomenon we explore. If there is a low information learner when\nthe algorithm {\\em knows} the underlying distribution on inputs, then there is\na learner that reveals little information on an average concept {\\em without\nknowing} the distribution on inputs. \n\n"}
{"id": "1811.10315", "contents": "Title: Investigation of Nonlinear Communication Channel with Small Dispersion\n  via Stochastic Correlator Approach Abstract: We consider the optical fiber channel modelled by the nonlinear\nSchr\\\"{o}dinger equation with additive white Gaussian noise and with large\nsignal-to-noise ratio. For the small dispersion case we present the approach to\nanalyze the stochastic nonlinear Schr\\\"{o}dinger equation. Taking into account\nthe averaging procedure (frequency filtering) of the output signal detector we\nfind the first corrections in small dispersion parameter to the correlators of\nthe input signal recovered by the backward propagation. These correlators are\nthe important ingredients for the calculation of the channel capacity and the\noptimal input signal distribution. We assert that the information channel\ncharacteristics essentially depend on the procedures of the output signal\nfiltering and the recovery of the transmitted signal. \n\n"}
{"id": "1812.00752", "contents": "Title: Sharma-Mittal Quantum Discord Abstract: We demonstrate a generalization of quantum discord using a generalized\ndefinition of von-Neumann entropy, which is Sharma-Mittal entropy; and the new\ndefinition of discord is called Sharma-Mittal quantum discord. Its analytic\nexpressions are worked out for two qubit quantum states as well as Werner,\nisotropic, and pointer states as special cases. The R{\\'e}nyi, Tsallis, and\nvon-Neumann entropy based quantum discords can be expressed as limiting cases\nfor of Sharma-Mittal quantum discord. We also numerically compare all these\ndiscords and entanglement negativity. \n\n"}
{"id": "1812.00819", "contents": "Title: Fast and Reliable Initial Access with Random Beamforming for mmWave\n  Networks Abstract: Millimeter-wave (mmWave) communications rely on directional transmissions to\novercome severe path loss. Nevertheless, the use of narrow beams complicates\nthe initial access procedure and increase the latency as the transmitter and\nreceiver beams should be aligned for a proper link establishment. In this\npaper, we investigate the feasibility of random beamforming for the cell-search\nphase of initial access. We develop a stochastic geometry framework to analyze\nthe performance in terms of detection failure probability and expected latency\nof initial access as well as total data transmission. Meanwhile, we compare our\nscheme with the widely used exhaustive search and iterative search schemes, in\nboth control plane and data plane. Our numerical results show that, compared to\nthe other two schemes, random beamforming can substantially reduce the latency\nof initial access with comparable failure probability in dense networks. We\nshow that the gain of the random beamforming is more prominent in light\ntraffics and low-latency services. Our work demonstrates that developing\ncomplex cell-discovery algorithms may be unnecessary in dense mmWave networks\nand thus shed new lights on mmWave network design. \n\n"}
{"id": "1812.02502", "contents": "Title: A Tight Rate Bound and Matching Construction for Locally Recoverable\n  Codes with Sequential Recovery From Any Number of Multiple Erasures Abstract: By a locally recoverable code (LRC), we will in this paper, mean a linear\ncode in which a given code symbol can be recovered by taking a linear\ncombination of at most $r$ other code symbols with $r << k$. A natural\nextension is to the local recovery of a set of $t$ erased symbols. There have\nbeen several approaches proposed for the handling of multiple erasures. The\napproach considered here, is one of sequential recovery meaning that the $t$\nerased symbols are recovered in succession, each time contacting at most $r$\nother symbols for assistance in recovery. Under the constraint that each erased\nsymbol be recoverable by contacting at most $r$ other code symbols, this\napproach is the most general and hence offers maximum possible code rate. We\ncharacterize the maximum possible rate of an LRC with sequential recovery for\nany $r \\geq 3$ and $t$. We do this by first deriving an upper bound on code\nrate and then going on to construct a {\\em binary} code that achieves this\noptimal rate. The upper bound derived here proves a conjecture made earlier\nrelating to the structure (but not the exact form) of the rate bound. Our\napproach also permits us to deduce the structure of the parity-check matrix of\na rate-optimal LRC with sequential recovery.\n  The parity-check matrix in turn, leads to a graphical description of the\ncode. The construction of a binary code having rate achieving the upper bound\nderived here makes use of this description. Interestingly, it turns out that a\nsubclass of binary codes that are both rate and block-length optimal,\ncorrespond to graphs known as Moore graphs that are regular graphs having the\nsmallest number of vertices for a given girth. A connection with Tornado codes\nis also made in the paper. \n\n"}
{"id": "1812.02936", "contents": "Title: Coding over Sets for DNA Storage Abstract: In this paper we study error-correcting codes for the storage of data in\nsynthetic deoxyribonucleic acid (DNA). We investigate a storage model where a\ndata set is represented by an unordered set of $M$ sequences, each of length\n$L$. Errors within that model are a loss of whole sequences and point errors\ninside the sequences, such as insertions, deletions and substitutions. We\nderive Gilbert-Varshamov lower bounds and sphere packing upper bounds on\nachievable cardinalities of error-correcting codes within this storage model.\nWe further propose explicit code constructions than can correct errors in such\na storage system that can be encoded and decoded efficiently. Comparing the\nsizes of these codes to the upper bounds, we show that many of the\nconstructions are close to optimal. \n\n"}
{"id": "1812.05670", "contents": "Title: When to Preempt? Age of Information Minimization under Link Capacity\n  Constraint Abstract: In this paper, we consider a scenario where a source continuously monitors an\nobject and sends time-stamped status updates to a destination through a\nrate-limited link. We assume updates arrive randomly at the source according to\na Bernoulli process. Due to the link capacity constraint, it takes multiple\ntime slots for the source to complete the transmission of an update. Therefore,\nwhen a new update arrives at the source during the transmission of another\nupdate, the source needs to decide whether to skip the new arrival or to switch\nto it, in order to minimize the expected average age of information (AoI) at\nthe destination. We start with the setting where all updates are of the same\nsize, and prove that within a broadly defined class of online policies, the\noptimal policy should be a renewal policy, and has a sequential switching\nproperty. We then show that the optimal decision of the source in any time slot\nhas threshold structures, and only depends on the age of the update being\ntransmitted and the AoI at the destination. We then consider the setting where\nupdates are of different sizes, and show that the optimal Markovian policy also\nhas a multiple-threshold structure. For each of the settings, we explicitly\nidentify the thresholds by formulating the problem as a Markov Decision Process\n(MDP), and solve it through value iteration. Special structural properties of\nthe corresponding optimal policy are utilized to reduce the computational\ncomplexity of the value iteration algorithm. \n\n"}
{"id": "1812.06885", "contents": "Title: Optimizing Throughput Performance in Distributed MIMO Wi-Fi Networks\n  using Deep Reinforcement Learning Abstract: This paper explores the feasibility of leveraging concepts from deep\nreinforcement learning (DRL) to enable dynamic resource management in Wi-Fi\nnetworks implementing distributed multi-user MIMO (D-MIMO). D-MIMO is a\ntechnique by which a set of wireless access points are synchronized and grouped\ntogether to jointly serve multiple users simultaneously. This paper addresses\ntwo dynamic resource management problems pertaining to D-MIMO Wi-Fi networks:\n(i) channel assignment of D-MIMO groups, and (ii) deciding how to cluster\naccess points to form D-MIMO groups, in order to maximize user throughput\nperformance. These problems are known to be NP-Hard and only heuristic\nsolutions exist in literature. We construct a DRL framework through which a\nlearning agent interacts with a D-MIMO Wi-Fi network, learns about the network\nenvironment, and is successful in converging to policies which address the\naforementioned problems. Through extensive simulations and on-line training\nbased on D-MIMO Wi-Fi networks, this paper demonstrates the efficacy of DRL in\nachieving an improvement of 20% in user throughput performance compared to\nheuristic solutions, particularly when network conditions are dynamic. This\nwork also showcases the effectiveness of DRL in meeting multiple network\nobjectives simultaneously, for instance, maximizing throughput of users as well\nas fairness of throughput among them. \n\n"}
{"id": "1812.08286", "contents": "Title: On the Role of Age of Information in the Internet of Things Abstract: In this article, we provide an accessible introduction to the emerging idea\nof Age of Information (AoI) that quantifies freshness of information and\nexplore its possible role in the efficient design of freshness-aware Internet\nof Things (IoT). We start by summarizing the concept of AoI and its variants\nwith emphasis on the differences between AoI and other well-known performance\nmetrics in the literature, such as throughput and delay. Building on this, we\nexplore freshness-aware IoT design for a network in which IoT devices sense\npotentially different physical processes and are supposed to frequently update\nthe status of these processes at a destination node (such as a cellular base\nstation). Inspired by the recent interest, we also assume that these IoT\ndevices are powered by wireless energy transfer by the destination node. For\nthis setting, we investigate the optimal sampling policy that jointly optimizes\nwireless energy transfer and scheduling of update packet transmissions from IoT\ndevices with the goal of minimizing long-term weighted sum-AoI. Using this, we\ncharacterize the achievable AoI region. We also compare this AoI-optimal policy\nwith the one that maximizes average throughput (throughput-optimal policy), and\ndemonstrate the impact of system state on their structures. Several promising\ndirections for future research are also presented. \n\n"}
{"id": "1812.10862", "contents": "Title: Secure Modulo Sum via Multiple Access Channel Abstract: We discuss secure computation of modular sum when multiple access channel\nfrom distinct players $A_1, \\ldots, A_c$ to a third party (Receiver) is given.\nThen, we define the secure modulo sum capacity as the supremum of the\ntransmission rate of modulo sum without information leakage of other\ninformation. We derive its useful lower bound, which is numerically calculated\nunder a realistic model that can be realizable as a Gaussian multiple access\nchannel (MAC). \n\n"}
{"id": "1901.00798", "contents": "Title: Scalable Information-Flow Analysis of Secure Three-Party Affine\n  Computations Abstract: Elaborate protocols in Secure Multi-party Computation enable several\nparticipants to compute a public function of their own private inputs while\nensuring that no undesired information leaks about the private inputs, and\nwithout resorting to any trusted third party. However, the public output of the\ncomputation inevitably leaks some information about the private inputs. Recent\nworks have introduced a framework and proposed some techniques for quantifying\nsuch information flow. Yet, owing to their complexity, those methods do not\nscale to practical situations that may involve large input spaces. The main\ncontribution of the work reported here is to formally investigate the\ninformation flow captured by the min-entropy in the particular case of secure\nthree-party computations of affine functions in order to make its\nquantification scalable to realistic scenarios. To this end, we mathematically\nderive an explicit formula for this entropy under uniform prior beliefs about\nthe inputs. We show that this closed-form expression can be computed in time\nconstant in the inputs sizes and logarithmic in the coefficients of the affine\nfunction. Finally, we formulate some theoretical bounds for this privacy leak\nin the presence of non-uniform prior beliefs. \n\n"}
{"id": "1901.00963", "contents": "Title: Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:\n  Delay-Optimal Scheduling Abstract: Millimeter wave (mmWave) technologies have the potential to achieve very high\ndata rates, but suffer from intermittent connectivity. In this paper, we\nprovision an architecture to integrate sub-6 GHz and mmWave technologies, where\nwe incorporate the sub-6 GHz interface as a fallback data transfer mechanism to\ncombat blockage and intermittent connectivity of the mmWave communications. To\nthis end, we investigate the problem of scheduling data packets across the\nmmWave and sub-6 GHz interfaces such that the average delay of system is\nminimized. This problem can be formulated as Markov Decision Process. We first\ninvestigate the problem of discounted delay minimization, and prove that the\noptimal policy is of the threshold-type, i.e., data packets should always be\nrouted to the mmWave interface as long as the number of packets in the system\nis smaller than a threshold. Then, we show that the results of the discounted\ndelay problem hold for the average delay problem as well. Through numerical\nresults, we demonstrate that under heavy traffic, integrating sub-6 GHz with\nmmWave can reduce the average delay by up to 70%. Further, our scheduling\npolicy substantially reduces the delay over the celebrated MaxWeight policy. \n\n"}
{"id": "1901.04167", "contents": "Title: Age-Delay Tradeoffs in Single Server Systems Abstract: Information freshness and low latency communication is important to many\nemerging applications. While Age of Information (AoI) serves as a metric of\ninformation freshness, packet delay is a traditional metric of communication\nlatency. We prove that there is a natural tradeoff between the AoI and packet\ndelay. We consider a single server system, in which at most one update packet\ncan be serviced at a time. The system designer controls the order in which the\npackets get serviced and the service time distribution, with a given service\nrate. We analyze two tradeoff problems that minimize packet delay and the\nvariance in packet delay, respectively, subject to an average age constraint.\nWe prove a strong age-delay and age-delay variance tradeoff, wherein, as the\naverage age approaches its minimum, the delay and its variance approach\ninfinity. We show that the service time distribution that mininizes average\nage, must necessarily have an unbounded-second moment. \n\n"}
{"id": "1901.04654", "contents": "Title: Reducing Age-of-Information for Computation-Intensive Messages via\n  Packet Replacement Abstract: Freshness of data is an important performance metric for real-time\napplications, which can be measured by age-of-information. For\ncomputation-intensive messages, the embedded information is not available until\nbeing computed. In this paper, we study the age-of-information for\ncomputation-intensive messages, which are firstly transmitted to a mobile edge\nserver, and then processed in the edge server to extract the embedded\ninformation. The packet generation follows zero-wait policy, by which a new\npacket is generated when the last one is just delivered to the edge server. The\nqueue in front of the edge server adopts one-packet-buffer replacement policy,\nmeaning that only the latest received packet is preserved. We derive the\nexpression of average age-of-information for exponentially distributed\ntransmission time and computing time. With packet replacement, the average age\nis reduced compared with the case without packet replacement, especially when\nthe transmission rate is close to or greater than the computing rate. \n\n"}
{"id": "1901.05096", "contents": "Title: Status from a Random Field: How Densely Should One Update? Abstract: In many applications, status information of a general spatial process, in\ncontrast to a point information source, is of interest. In this paper, we\nconsider a system where status information is drawn from a random field and\ntransmitted to a fusion center through a wireless multiaccess channel. The\noptimal density of spatial sampling points to minimize the remote status\nestimation error is investigated. Assuming a one-dimensional Gauss Markov\nrandom field and an exponential correlation function, closed-form expressions\nof remote estimation error are obtained for First-Come First-Served (FCFS) and\nLast-Come First-Served (LCFS) service disciplines. The optimal spatial sampling\ndensity for the LCFS case is given explicitly. Simulation results are presented\nwhich agree with our analysis. \n\n"}
{"id": "1901.05428", "contents": "Title: Relative Age of Information: A New Metric for Status Update Systems Abstract: In this paper, we introduce a new data freshness metric, relative Age of\nInformation (rAoI), and examine it in a single server system with various\npacket management schemes. The (classical) AoI metric was introduced to measure\nthe staleness of status updates at the receiving end with respect to their\ngeneration at the source. This metric addresses systems where the timings of\nupdate generation at the source are absolute and can be designed separately or\njointly with the transmission schedules. In many decentralized applications,\ntransmission schedules are blind to update generation timing, and the\ntransmitter can know the timing of an update packet only after it arrives. As\nsuch, an update becomes stale after a new one arrives. The rAoI metric measures\nhow fresh the data is at the receiver with respect to the data at the\ntransmitter. It introduces a particularly explicit dependence on the arrival\nprocess in the evaluation of age. We investigate several queuing disciplines\nand provide closed form expressions for rAoI and numerical comparisons. \n\n"}
{"id": "1901.05732", "contents": "Title: On Coded Caching with Correlated Files Abstract: This paper studies the fundamental limits of the shared-link coded caching\nproblem with correlated files, where a server with a library of $N$ files\ncommunicates with $K$ users who can locally cache $M$ files. Given an integer\n$r \\in [N]$, correlation is modeled as follows: each r-subset of files contains\na unique common block. The tradeoff between the cache size and the average\ntransmitted load is considered. First, a converse bound under the constraint of\nuncoded cache placement (i.e., each user directly stores a subset of the\nlibrary bits) is derived. Then, a caching scheme for the case where every user\ndemands a distinct file (possible for $N \\geq K$) is shown to be optimal under\nthe constraint of uncoded cache placement. This caching scheme is further\nproved to be decodable and optimal under the constraint of uncoded cache\nplacement when (i) $KrM \\leq 2N$ or $KrM \\geq (K - 1)N $or $r \\in \\{1,2,N-\n1,N\\}$ for every demand type (i.e., when the demanded file are not necessarily\ndistinct), and (ii) when the number of distinct demanded files is no larger\nthan four. Finally, a two-phase delivery scheme based on interference alignment\nis shown to be optimal to within a factor of 2 under the constraint of uncoded\ncache placement for every possible demands. As a by-product, the proposed\ninterference alignment scheme is shown to reduce the (worst-case or average)\nload of state-of-the-art schemes for the coded caching problem where the users\ncan request multiple files. \n\n"}
{"id": "1901.05778", "contents": "Title: Joint Source-Channel Coding for the Multiple-Access Channel with\n  Correlated Sources Abstract: This paper studies the random-coding exponent of joint source-channel coding\nfor the multiple-access channel with correlated sources. For each user, by\ndefining a threshold, the messages of each source are partitioned into two\nclasses. The achievable exponent for correlated sources with two\nmessage-dependent input distributions for each user is determined and shown to\nbe larger than that achieved using only one input distribution for each user. A\nsystem of equations is presented to determine the optimal thresholds maximizing\nthe achievable exponent. The obtained exponent is compared with the one derived\nfor the MAC with independent sources. \n\n"}
{"id": "1901.06010", "contents": "Title: Degrees of Freedom Region of the $(M,N_1,N_2)$ MIMO Broadcast Channel\n  with Partial CSIT: An Application of Sum-set Inequalities Based on Aligned\n  Image Sets Abstract: The degrees of freedom (DoF) region is characterized for the $2$-user\nmultiple input multiple output (MIMO) broadcast channel (BC), where the\ntransmitter is equipped with $M$ antennas, the two receivers are equipped with\n$N_1$ and $N_2$ antennas, and the levels of channel state information at the\ntransmitter (CSIT) for the two users are parameterized by $\\beta_1, \\beta_2$,\nrespectively. The achievability of the DoF region was established by Hao,\nRassouli and Clerckx, but no proof of optimality was heretofore available. The\nproof of optimality is provided in this work with the aid of sum-set\ninequalities based on the aligned image sets (AIS) approach. \n\n"}
{"id": "1901.06089", "contents": "Title: An ADMM-Based Approach to Robust Array Pattern Synthesis Abstract: In most existing robust array beam pattern synthesis studies, the\nbounded-sphere model is used to describe the steering vector (SV)\nuncertainties. In this letter, instead of bounding the norm of SV perturbations\nas a whole, we explore the amplitude and phase perturbations of each SV element\nseparately, thereby obtaining a tighter SV uncertainty model. Based on this\nmodel, we formulate the robust array pattern synthesis problem from the\nperspective of the min-max optimization, which aims to minimize the maximum\nside lobe response, while preserving the main lobe response. However, this\nproblem is difficult due to the infinitely many non-convex constraints. As a\nremedy, we employ the worst-case criterion and recast the problem as a convex\nsecond-order cone program (SOCP). To solve the SOCP, we further develop an\nalternating direction method of multipliers (ADMM)-based algorithm, which is\ncomputationally efficient with each step being computed in closed form.\nNumerical simulations demonstrate the efficacy and efficiency of the proposed\nalgorithm. \n\n"}
{"id": "1901.06234", "contents": "Title: SPARCs for Unsourced Random Access Abstract: Unsourced random-access (U-RA) is a type of grant-free random access with a\nvirtually unlimited number of users, of which only a certain number $K_a$ are\nactive on the same time slot. Users employ exactly the same codebook, and the\ntask of the receiver is to decode the list of transmitted messages. We present\na concatenated coding construction for U-RA on the AWGN channel, in which a\nsparse regression code (SPARC) is used as an inner code to create an effective\nouter OR-channel. Then an outer code is used to resolve the multiple-access\ninterference in the OR-MAC. We propose a modified version of the approximate\nmessage passing (AMP) algorithm as an inner decoder and give a precise\nasymptotic analysis of the error probabilities of the AMP decoder and of a\nhypothetical optimal inner MAP decoder. This analysis shows that the\nconcatenated construction can achieve a vanishing per-user error probability in\nthe limit of large blocklength and a large number of active users at sum-rates\nup to the symmetric Shannon capacity, i.e. as long as $K_aR <\n0.5\\log_2(1+K_a\\SNR)$. This extends previous point-to-point optimality results\nabout SPARCs to the unsourced multiuser scenario. Furthermore, we give an\noptimization algorithm to find the power allocation for the inner SPARC code\nthat minimizes the required $\\SNR$. \n\n"}
{"id": "1901.06587", "contents": "Title: Fitting ReLUs via SGD and Quantized SGD Abstract: In this paper we focus on the problem of finding the optimal weights of the\nshallowest of neural networks consisting of a single Rectified Linear Unit\n(ReLU). These functions are of the form $\\mathbf{x}\\rightarrow\n\\max(0,\\langle\\mathbf{w},\\mathbf{x}\\rangle)$ with $\\mathbf{w}\\in\\mathbb{R}^d$\ndenoting the weight vector. We focus on a planted model where the inputs are\nchosen i.i.d. from a Gaussian distribution and the labels are generated\naccording to a planted weight vector. We first show that mini-batch stochastic\ngradient descent when suitably initialized, converges at a geometric rate to\nthe planted model with a number of samples that is optimal up to numerical\nconstants. Next we focus on a parallel implementation where in each iteration\nthe mini-batch gradient is calculated in a distributed manner across multiple\nprocessors and then broadcast to a master or all other processors. To reduce\nthe communication cost in this setting we utilize a Quanitzed Stochastic\nGradient Scheme (QSGD) where the partial gradients are quantized. Perhaps\nunexpectedly, we show that QSGD maintains the fast convergence of SGD to a\nglobally optimal model while significantly reducing the communication cost. We\nfurther corroborate our numerical findings via various experiments including\ndistributed implementations over Amazon EC2. \n\n"}
{"id": "1901.06878", "contents": "Title: Polarization-ring-switching for nonlinearity-tolerant\n  geometrically-shaped four-dimensional formats maximizing generalized mutual\n  information Abstract: In this paper, a new four-dimensional 64-ary polarization ring switching\n(4D-64PRS) modulation format with a spectral efficiency of 6 bit/4D-sym is\nintroduced. The format is designed by maximizing the generalized mutual\ninformation (GMI) and by imposing a constant-modulus on the 4D structure. The\nproposed format yields an improved performance with respect to state-of-the-art\ngeometrically shaped modulation formats for bit-interleaved coded modulation\nsystems at the same spectral efficiency. Unlike previously published results,\nthe coordinates of the constellation points and the binary labeling of the\nconstellation are jointly optimized. When compared with\npolarization-multiplexed 8-ary quadrature-amplitude modulation (PM-8QAM), gains\nof up to 0.7 dB in signal-to-noise ratio are observed in the additive white\nGaussian noise (AWGN) channel. For a long-haul nonlinear optical fiber system\nof 8,000 km, gains of up to 0.27 bit/4D-sym (5.5% data capacity increase) are\nobserved. These gains translate into a reach increase of approximately 16%\n(1,100 km). The proposed modulation format is also shown to be more tolerant to\nnonlinearities than PM-8QAM. Results with LDPC codes are also presented, which\nconfirm the gains predicted by the GMI. \n\n"}
{"id": "1901.07013", "contents": "Title: Achievable Rates of Attack Detection Strategies in Echo-Assisted\n  Communication Abstract: We consider an echo-assisted communication model wherein block-coded\nmessages, when transmitted across several frames, reach the destination as\nmultiple noisy copies. We address adversarial attacks on such models wherein a\nsubset of the noisy copies are vulnerable to manipulation by an adversary.\nParticularly, we study a non-persistent attack model with the adversary\nattacking 50% of the frames on the vulnerable copies in an i.i.d. fashion. We\nshow that this adversarial model drives the destination to detect the attack\nlocally within every frame, thereby resulting in degraded performance due to\nfalse-positives and miss-detection. Our main objective is to characterize the\nmutual information of this adversarial echo-assisted channel by incorporating\nthe performance of attack-detection strategies. With the use of an imperfect\ndetector, we show that the compound channel comprising the adversarial\necho-assisted channel and the attack detector exhibits memory-property, and as\na result, obtaining closed-form expressions on mutual information is\nintractable. To circumvent this problem, we present a new framework to\napproximate the mutual information by deriving sufficient conditions on the\nchannel parameters and also the performance of the attack detectors. Finally,\nwe propose two attack-detectors, which are inspired by traditional as well as\nneural-network ideas, and show that the mutual information offered by these\ndetectors is close to that of the Genie detector for short frame-lengths. \n\n"}
{"id": "1901.07069", "contents": "Title: Minimum Age of Information in the Internet of Things with Non-uniform\n  Status Packet Sizes Abstract: In this paper, a real-time Internet of Things (IoT) monitoring system is\nconsidered in which the IoT devices are scheduled to sample underlying physical\nprocesses and send the status updates to a common destination. In a real-world\nIoT, due to the possibly different dynamics of each physical process, the sizes\nof the status updates for different devices are often different and each status\nupdate typically requires multiple transmission slots. By taking into account\nsuch multi-time slot transmissions with non-uniform sizes of the status updates\nunder noisy channels, the problem of joint device scheduling and status\nsampling is studied in order to minimize the average age of information (AoI)\nat the destination. This stochastic problem is formulated as an infinite\nhorizon average cost Markov decision process (MDP). The monotonicity of the\nvalue function of the MDP is characterized and then used to show that the\noptimal scheduling and sampling policy is threshold-based with respect to the\nAoI at each device. To overcome the curse of dimensionality, a low-complexity\nsuboptimal policy is proposed through a semi-randomized base policy and linear\napproximated value functions. The proposed suboptimal policy is shown to\nexhibit a similar structure to the optimal policy, which provides a structural\nbase for its effective performance. A structure-aware algorithm is then\ndeveloped to obtain the suboptimal policy. The analytical results are further\nextended to the IoT monitoring system with random status update arrivals, for\nwhich, the optimal scheduling and sampling policy is also shown to be\nthreshold-based with the AoI at each device. Simulation results illustrate the\nstructures of the optimal policy and show a near-optimal AoI performance\nresulting from the proposed suboptimal solution approach. \n\n"}
{"id": "1901.07303", "contents": "Title: Hybrid Precoder Design for Cache-enabled Millimeter Wave Radio Access\n  Networks Abstract: In this paper, we study the design of a hybrid precoder, consisting of an\nanalog and a digital precoder, for the delivery phase of downlink cache-enabled\nmillimeter wave (mmWave) radio access networks (CeMm-RANs). In CeMm-RANs,\nenhanced remote radio heads (eRRHs), which are equipped with local cache and\nbaseband signal processing capabilities in addition to the basic\nfunctionalities of conventional RRHs, are connected to the baseband processing\nunit via fronthaul links. Two different fronthaul information transfer\nstrategies are considered, namely, hard fronthaul information transfer, where\nhard information of uncached requested files is transmitted via the fronthaul\nlinks to a subset of eRRHs, and soft fronthaul information transfer, where the\nfronthaul links are used to transmit quantized baseband signals of uncached\nrequested files. The hybrid precoder is optimized for maximization of the\nminimum user rate under a fronthaul capacity constraint, an eRRH transmit power\nconstraint, and a constant-modulus constraint on the analog precoder. The\nresulting optimization problem is non-convex, and hence the global optimal\nsolution is difficult to obtain. Therefore, convex approximation methods are\nemployed to tackle the non-convexity of the achievable user rate, the fronthaul\ncapacity constraint, and the constant modulus constraint on the analog\nprecoder. Then, an effective algorithm with provable convergence is developed\nto solve the approximated optimization problem. Simulation results are provided\nto evaluate the performance of the proposed algorithms, where fully digital\nprecoding is used as benchmark. The results reveal that except for the case of\na large fronthaul link capacity, soft fronthaul information transfer is\npreferable for CeMm-RANs. \n\n"}
{"id": "1901.07509", "contents": "Title: Single-Server Multi-Message Individually-Private Information Retrieval\n  with Side Information Abstract: We consider a multi-user variant of the private information retrieval problem\ndescribed as follows. Suppose there are $D$ users, each of which wants to\nprivately retrieve a distinct message from a server with the help of a trusted\nagent. We assume that the agent has a random subset of $M$ messages that is not\nknown to the server. The goal of the agent is to collectively retrieve the\nusers' requests from the server. For protecting the privacy of users, we\nintroduce the notion of individual-privacy -- the agent is required to protect\nthe privacy only for each individual user (but may leak some correlations among\nuser requests). We refer to this problem as Individually-Private Information\nRetrieval with Side Information (IPIR-SI).\n  We first establish a lower bound on the capacity, which is defined as the\nmaximum achievable download rate, of the IPIR-SI problem by presenting a novel\nachievability protocol. Next, we characterize the capacity of IPIR-SI problem\nfor $M = 1$ and $D = 2$. In the process of characterizing the capacity for\narbitrary $M$ and $D$ we present a novel combinatorial conjecture, that may be\nof independent interest. \n\n"}
{"id": "1901.07769", "contents": "Title: Bit Flipping Moment Balancing Schemes for Insertion, Deletion and\n  Substitution Error Correction Abstract: In this paper, two moment balancing schemes, namely a variable index scheme\nand a fixed index scheme, for either single insertion/deletion error correction\nor multiple substitution error correction are introduced for coded sequences\noriginally developed for correcting substitution errors only. By judiciously\nflipping bits of the original substitution error correcting code word, the\nresulting word is able to correct either a reduced number of substitution\nerrors or a single insertion/deletion error. The number of flips introduced by\nthe two schemes can be kept small compared to the code length. It shows a\npractical value of applying the schemes to a long substitution error correcting\ncode for a severe channel where substitution errors dominate but\ninsertion/deletion errors can occur with a low probability. The new schemes can\nbe more easily implemented in an existing coding system than any previously\npublished moment balancing templates since no additional parity bits are\nrequired which also means the code rate remains same and the existing\nsubstitution error correcting decoder requires no changes. Moreover, the work\nextends the class of Levenshtein codes capable of correcting either single\nsubstitution or single insertion/deletion errors to codes capable of correcting\neither multiple substitution errors or single insertion/deletion error. \n\n"}
{"id": "1901.09308", "contents": "Title: Energy-Efficient Resource Allocation for Secure UAV Communication\n  Systems Abstract: In this paper, we study the resource allocation and trajectory design for\nenergy-efficient secure unmanned aerial vehicle (UAV) communication systems\nwhere a UAV base station serves multiple legitimate ground users in the\nexistence of a potential eavesdropper. We aim to maximize the energy efficiency\nof the UAV by jointly optimizing its transmit power, user scheduling,\ntrajectory, and velocity. The design is formulated as a non-convex optimization\nproblem taking into account the maximum tolerable signal-to-noise ratio (SNR)\nleakage, the minimum data rate requirement of each user, and the location\nuncertainty of the eavesdropper. An iterative algorithm is proposed to obtain\nan efficient suboptimal solution. Simulation results demonstrate that the\nproposed algorithm can achieve a significant improvement of the system energy\nefficiency while satisfying communication security constraint, compared to some\nsimple scheme adopting straight flight trajectory with a constant speed. \n\n"}
{"id": "cond-mat/0608312", "contents": "Title: On Cavity Approximations for Graphical Models Abstract: We reformulate the Cavity Approximation (CA), a class of algorithms recently\nintroduced for improving the Bethe approximation estimates of marginals in\ngraphical models. In our new formulation, which allows for the treatment of\nmultivalued variables, a further generalization to factor graphs with arbitrary\norder of interaction factors is explicitly carried out, and a message passing\nalgorithm that implements the first order correction to the Bethe approximation\nis described. Furthermore we investigate an implementation of the CA for\npairwise interactions. In all cases considered we could confirm that CA[k] with\nincreasing $k$ provides a sequence of approximations of markedly increasing\nprecision. Furthermore in some cases we could also confirm the general\nexpectation that the approximation of order $k$, whose computational complexity\nis $O(N^{k+1})$ has an error that scales as $1/N^{k+1}$ with the size of the\nsystem. We discuss the relation between this approach and some recent\ndevelopments in the field. \n\n"}
{"id": "cs/0411014", "contents": "Title: Rate Distortion and Denoising of Individual Data Using Kolmogorov\n  complexity Abstract: We examine the structure of families of distortion balls from the perspective\nof Kolmogorov complexity. Special attention is paid to the canonical\nrate-distortion function of a source word which returns the minimal Kolmogorov\ncomplexity of all distortion balls containing that word subject to a bound on\ntheir cardinality. This canonical rate-distortion function is related to the\nmore standard algorithmic rate-distortion function for the given distortion\nmeasure. Examples are given of list distortion, Hamming distortion, and\nEuclidean distortion. The algorithmic rate-distortion function can behave\ndifferently from Shannon's rate-distortion function. To this end, we show that\nthe canonical rate-distortion function can and does assume a wide class of\nshapes (unlike Shannon's); we relate low algorithmic mutual information to low\nKolmogorov complexity (and consequently suggest that certain aspects of the\nmutual information formulation of Shannon's rate-distortion function behave\ndifferently than would an analogous formulation using algorithmic mutual\ninformation); we explore the notion that low Kolmogorov complexity distortion\nballs containing a given word capture the interesting properties of that word\n(which is hard to formalize in Shannon's theory) and this suggests an approach\nto denoising; and, finally, we show that the different behavior of the\nrate-distortion curves of individual source words to some extent disappears\nafter averaging over the source words. \n\n"}
{"id": "cs/0503064", "contents": "Title: Minimum-Cost Multicast over Coded Packet Networks Abstract: We consider the problem of establishing minimum-cost multicast connections\nover coded packet networks, i.e. packet networks where the contents of outgoing\npackets are arbitrary, causal functions of the contents of received packets. We\nconsider both wireline and wireless packet networks as well as both static\nmulticast (where membership of the multicast group remains constant for the\nduration of the connection) and dynamic multicast (where membership of the\nmulticast group changes in time, with nodes joining and leaving the group).\n  For static multicast, we reduce the problem to a polynomial-time solvable\noptimization problem, and we present decentralized algorithms for solving it.\nThese algorithms, when coupled with existing decentralized schemes for\nconstructing network codes, yield a fully decentralized approach for achieving\nminimum-cost multicast. By contrast, establishing minimum-cost static multicast\nconnections over routed packet networks is a very difficult problem even using\ncentralized computation, except in the special cases of unicast and broadcast\nconnections.\n  For dynamic multicast, we reduce the problem to a dynamic programming problem\nand apply the theory of dynamic programming to suggest how it may be solved. \n\n"}
{"id": "cs/0510009", "contents": "Title: Tree-Based Construction of LDPC Codes Having Good Pseudocodeword Weights Abstract: We present a tree-based construction of LDPC codes that have minimum\npseudocodeword weight equal to or almost equal to the minimum distance, and\nperform well with iterative decoding. The construction involves enumerating a\n$d$-regular tree for a fixed number of layers and employing a connection\nalgorithm based on permutations or mutually orthogonal Latin squares to close\nthe tree. Methods are presented for degrees $d=p^s$ and $d = p^s+1$, for $p$ a\nprime. One class corresponds to the well-known finite-geometry and finite\ngeneralized quadrangle LDPC codes; the other codes presented are new. We also\npresent some bounds on pseudocodeword weight for $p$-ary LDPC codes. Treating\nthese codes as $p$-ary LDPC codes rather than binary LDPC codes improves their\nrates, minimum distances, and pseudocodeword weights, thereby giving a new\nimportance to the finite geometry LDPC codes where $p > 2$. \n\n"}
{"id": "cs/0510044", "contents": "Title: Belief Propagation Based Multi--User Detection Abstract: We apply belief propagation (BP) to multi--user detection in a spread\nspectrum system, under the assumption of Gaussian symbols. We prove that BP is\nboth convergent and allows to estimate the correct conditional expectation of\nthe input symbols. It is therefore an optimal --minimum mean square error--\ndetection algorithm. This suggests the possibility of designing BP detection\nalgorithms for more general systems. As a byproduct we rederive the Tse-Hanly\nformula for minimum mean square error without any recourse to random matrix\ntheory. \n\n"}
{"id": "cs/0603007", "contents": "Title: Complete Enumeration of Stopping Sets of Full-Rank Parity-Check Matrices\n  of Hamming Codes Abstract: Stopping sets, and in particular their numbers and sizes, play an important\nrole in determining the performance of iterative decoders of linear codes over\nbinary erasure channels. In the 2004 Shannon Lecture, McEliece presented an\nexpression for the number of stopping sets of size three for a full-rank\nparity-check matrix of the Hamming code. In this correspondence, we derive an\nexpression for the number of stopping sets of any given size for the same\nparity-check matrix. \n\n"}
{"id": "cs/0605067", "contents": "Title: Efficient Operation of Coded Packet Networks Abstract: A fundamental problem faced in the design of almost all packet networks is\nthat of efficient operation--of reliably communicating given messages among\nnodes at minimum cost in resource usage. We present a solution to the efficient\noperation problem for coded packet networks, i.e., packet networks where the\ncontents of outgoing packets are arbitrary, causal functions of the contents of\nreceived packets. Such networks are in contrast to conventional, routed packet\nnetworks, where outgoing packets are restricted to being copies of received\npackets and where reliability is provided by the use of retransmissions.\n  This thesis introduces four considerations to coded packet networks: 1.\nefficiency, 2. the lack of synchronization in packet networks, 3. the\npossibility of broadcast links, and 4. packet loss. We take these\nconsiderations and give a prescription for operation that is novel and general,\nyet simple, useful, and extensible. \n\n"}
{"id": "cs/0606026", "contents": "Title: Generating parity check equations for bounded-distance iterative erasure\n  decoding Abstract: A generic $(r,m)$-erasure correcting set is a collection of vectors in\n$\\bF_2^r$ which can be used to generate, for each binary linear code of\ncodimension $r$, a collection of parity check equations that enables iterative\ndecoding of all correctable erasure patterns of size at most $m$.\n  That is to say, the only stopping sets of size at most $m$ for the generated\nparity check equations are the erasure patterns for which there is more than\none manner to fill in theerasures to obtain a codeword.\n  We give an explicit construction of generic $(r,m)$-erasure correcting sets\nof cardinality $\\sum_{i=0}^{m-1} {r-1\\choose i}$. Using a random-coding-like\nargument, we show that for fixed $m$, the minimum size of a generic\n$(r,m)$-erasure correcting set is linear in $r$.\n  Keywords: iterative decoding, binary erasure channel, stopping set \n\n"}
{"id": "cs/0610047", "contents": "Title: Capacity of the Trapdoor Channel with Feedback Abstract: We establish that the feedback capacity of the trapdoor channel is the\nlogarithm of the golden ratio and provide a simple communication scheme that\nachieves capacity. As part of the analysis, we formulate a class of dynamic\nprograms that characterize capacities of unifilar finite-state channels. The\ntrapdoor channel is an instance that admits a simple analytic solution. \n\n"}
{"id": "cs/0610160", "contents": "Title: A Non-Orthogonal Distributed Space-Time Coded Protocol Part II-Code\n  Construction and DM-G Tradeoff Abstract: This is the second part of a two-part series of papers. In this paper, for\nthe generalized non-orthogonal amplify and forward (GNAF) protocol presented in\nPart-I, a construction of a new family of distributed space-time codes based on\nCo-ordinate Interleaved Orthogonal Designs (CIOD) which result in reduced\nMaximum Likelihood (ML) decoding complexity at the destination is proposed.\nFurther, it is established that the recently proposed Toeplitz space-time codes\nas well as space-time block codes (STBCs) from cyclic division algebras can be\nused in GNAF protocol. Finally, a lower bound on the optimal\nDiversity-Multiplexing Gain (DM-G) tradeoff for the GNAF protocol is\nestablished and it is shown that this bound approaches the transmit diversity\nbound asymptotically as the number of relays and the number of channels uses\nincreases. \n\n"}
{"id": "cs/0701120", "contents": "Title: Algorithmic Complexity Bounds on Future Prediction Errors Abstract: We bound the future loss when predicting any (computably) stochastic sequence\nonline. Solomonoff finitely bounded the total deviation of his universal\npredictor $M$ from the true distribution $mu$ by the algorithmic complexity of\n$mu$. Here we assume we are at a time $t>1$ and already observed $x=x_1...x_t$.\nWe bound the future prediction performance on $x_{t+1}x_{t+2}...$ by a new\nvariant of algorithmic complexity of $mu$ given $x$, plus the complexity of the\nrandomness deficiency of $x$. The new complexity is monotone in its condition\nin the sense that this complexity can only decrease if the condition is\nprolonged. We also briefly discuss potential generalizations to Bayesian model\nclasses and to classification problems. \n\n"}
{"id": "cs/0701123", "contents": "Title: Feasible Depth Abstract: This paper introduces two complexity-theoretic formulations of Bennett's\nlogical depth: finite-state depth and polynomial-time depth. It is shown that\nfor both formulations, trivial and random infinite sequences are shallow, and a\nslow growth law holds, implying that deep sequences cannot be created easily\nfrom shallow sequences. Furthermore, the E analogue of the halting language is\nshown to be polynomial-time deep, by proving a more general result: every\nlanguage to which a nonnegligible subset of E can be reduced in uniform\nexponential time is polynomial-time deep. \n\n"}
{"id": "cs/0702059", "contents": "Title: Redundancy-Related Bounds on Generalized Huffman Codes Abstract: This paper presents new lower and upper bounds for the compression rate of\nbinary prefix codes optimized over memoryless sources according to various\nnonlinear codeword length objectives. Like the most well-known redundancy\nbounds for minimum average redundancy coding - Huffman coding - these are in\nterms of a form of entropy and/or the probability of an input symbol, often the\nmost probable one. The bounds here, some of which are tight, improve on known\nbounds of the form L in [H,H+1), where H is some form of entropy in bits (or,\nin the case of redundancy objectives, 0) and L is the length objective, also in\nbits. The objectives explored here include exponential-average length, maximum\npointwise redundancy, and exponential-average pointwise redundancy (also called\ndth exponential redundancy). The first of these relates to various problems\ninvolving queueing, uncertainty, and lossless communications; the second\nrelates to problems involving Shannon coding and universal modeling. For these\ntwo objectives we also explore the related problem of the necessary and\nsufficient conditions for the shortest codeword of a code being a specific\nlength. \n\n"}
{"id": "cs/0702130", "contents": "Title: Syndrome Decoding of Reed-Solomon Codes Beyond Half the Minimum Distance\n  based on Shift-Register Synthesis Abstract: In this paper, a new approach for decoding low-rate Reed-Solomon codes beyond\nhalf the minimum distance is considered and analyzed. Unlike the Sudan\nalgorithm published in 1997, this new approach is based on multi-sequence\nshift-register synthesis, which makes it easy to understand and simple to\nimplement. The computational complexity of this shift-register based algorithm\nis of the same order as the complexity of the well-known Berlekamp-Massey\nalgorithm. Moreover, the error correcting radius coincides with the error\ncorrecting radius of the original Sudan algorithm, and the practical decoding\nperformance observed on a q-ary symmetric channel (QSC) is virtually identical\nto the decoding performance of the Sudan algorithm. Bounds for the failure and\nerror probability as well as for the QSC decoding performance of the new\nalgorithm are derived, and the performance is illustrated by means of examples. \n\n"}
{"id": "cs/0703129", "contents": "Title: A theorem on the quantum evaluation of Weight Enumerators for a certain\n  class of Cyclic Codes with a note on Cyclotomic cosets Abstract: This note is a stripped down version of a published paper on the Potts\npartition function, where we concentrate solely on the linear coding aspect of\nour approach. It is meant as a resource for people interested in coding theory\nbut who do not know much of the mathematics involved and how quantum\ncomputation may provide a speed up in the computation of a very important\nquantity in coding theory. We provide a theorem on the quantum computation of\nthe Weight Enumerator polynomial for a restricted family of cyclic codes. The\ncomplexity of obtaining an exact evaluation is $O(k^{2s}(\\log q)^{2})$, where\n$s$ is a parameter which determines the class of cyclic codes in question, $q$\nis the characteristic of the finite field over which the code is defined, and\n$k$ is the dimension of the code. We also provide an overview of cyclotomic\ncosets and discuss applications including how they can be used to speed up the\ncomputation of the weight enumerator polynomial (which is related to the Potts\npartition function). We also give an algorithm which returns the coset leaders\nand the size of each coset from the list $\\{0,1,2,...,N-1\\}$, whose time\ncomplexity is soft-O(N). This algorithm uses standard techniques but we include\nit as a resource for students. Note that cyclotomic cosets do not improve the\nasymptotic complexity of the computation of weight enumerators. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "math/9910175", "contents": "Title: Polynomial method in coding and information theory Abstract: Polynomial, or Delsarte's, method in coding theory accounts for a variety of\nstructural results on, and bounds on the size of, extremal configurations\n(codes and designs) in various metric spaces. In recent works of the authors\nthe applicability of the method was extended to cover a wider range of problems\nin coding and information theory. In this paper we present a general framework\nfor the method which includes previous results as particular cases. We explain\nhow this generalization leads to new asymptotic bounds on the performance of\ncodes in binary-input memoryless channels and the Gaussian channel, which\nimprove the results of Shannon et al. of 1959-67, and to a number of other\nresults in combinatorial coding theory. \n\n"}
