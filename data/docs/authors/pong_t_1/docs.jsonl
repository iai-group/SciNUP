{"id": "0704.3875", "contents": "Title: Controlled Lagrangians and Stabilization of Discrete Mechanical Systems\n  I Abstract: Controlled Lagrangian and matching techniques are developed for the\nstabilization of relative equilibria and equilibria of discrete mechanical\nsystems with symmetry as well as broken symmetry. Interesting new phenomena\narise in the controlled Lagrangian approach in the discrete context that are\nnot present in the continuous theory. In particular, to make the discrete\ntheory effective, one can make an appropriate selection of momentum levels or,\nalternatively, introduce a new parameter into the controlled Lagrangian to\ncomplete the kinetic matching procedure. Specifically, new terms in the\ncontrolled shape equation that are necessary for potential matching in the\ndiscrete setting are introduced. The theory is illustrated with the problem of\nstabilization of the cart-pendulum system on an incline. The paper also\ndiscusses digital and model predictive controllers. \n\n"}
{"id": "0710.2912", "contents": "Title: Updating Probabilities: An Econometric Example Abstract: We demonstrate how information in the form of observable data and moment\nconstraints are introduced into the method of Maximum relative Entropy (ME). A\ngeneral example of updating with data and moments is shown. A specific\neconometric example is solved in detail which can then be used as a template\nfor real world problems. A numerical example is compared to a large deviation\nsolution which illustrates some of the advantages of the ME method. \n\n"}
{"id": "0711.1709", "contents": "Title: Cooperative Robot Control and Concurrent Synchronization of Lagrangian\n  Systems Abstract: Concurrent synchronization is a regime where diverse groups of fully\nsynchronized dynamic systems stably coexist. We study global exponential\nsynchronization and concurrent synchronization in the context of Lagrangian\nsystems control. In a network constructed by adding diffusive couplings to\nrobot manipulators or mobile robots, a decentralized tracking control law\nglobally exponentially synchronizes an arbitrary number of robots, and\nrepresents a generalization of the average consensus problem. Exact nonlinear\nstability guarantees and synchronization conditions are derived by contraction\nanalysis. The proposed decentralized strategy is further extended to adaptive\nsynchronization and partial-state coupling. \n\n"}
{"id": "0712.0152", "contents": "Title: Necessary Optimality Conditions for Fractional Action-Like Problems with\n  Intrinsic and Observer Times Abstract: We prove higher-order Euler-Lagrange and DuBois-Reymond stationary conditions\nto fractional action-like variational problems. More general fractional\naction-like optimal control problems are also considered. \n\n"}
{"id": "0801.3185", "contents": "Title: Synchronizing continuous-time neutrally stable linear systems via\n  partial-state coupling Abstract: Synchronization of coupled continuous-time linear systems is studied in a\ngeneral setting. For identical neutrally-stable linear systems that are\ndetectable from their outputs, it is shown that a linear output feedback law\nexists under which the coupled systems globally asymptotically synchronize\nunder all fixed (directed) connected network topologies. An algorithm is\nprovided to compute one such feedback law based on individual system\nparameters. The dual case, where individual systems are neutrally stable and\nstabilizable from their inputs, is also considered and parallel results are\nestablished. \n\n"}
{"id": "0802.1375", "contents": "Title: Autoconjugate representers for linear monotone operators Abstract: Monotone operators are of central importance in modern optimization and\nnonlinear analysis. Their study has been revolutionized lately, due to the\nsystematic use of the Fitzpatrick function. Pioneered by Penot and Svaiter, a\ntopic of recent interest has been the representation of maximal monotone\noperators by so-called autoconjugate functions. Two explicit constructions were\nproposed, the first by Penot and Zalinescu in 2005, and another by Bauschke and\nWang in 2007. The former requires a mild constraint qualification while the\nlatter is based on the proximal average.\n  We show that these two autoconjugate representers must coincide for\ncontinuous linear monotone operators on reflexive spaces. The continuity and\nthe linearity assumption are both essential as examples of discontinuous linear\noperators and of subdifferential operators illustrate. Furthermore, we also\nconstruct an infinite family of autoconjugate representers for the identity\noperator on the real line. \n\n"}
{"id": "0802.3250", "contents": "Title: Valuation of Mortality Risk via the Instantaneous Sharpe Ratio:\n  Applications to Life Annuities Abstract: We develop a theory for valuing non-diversifiable mortality risk in an\nincomplete market. We do this by assuming that the company issuing a\nmortality-contingent claim requires compensation for this risk in the form of a\npre-specified instantaneous Sharpe ratio. We apply our method to value life\nannuities. One result of our paper is that the value of the life annuity is\n{\\it identical} to the upper good deal bound of Cochrane and Sa\\'{a}-Requejo\n(2000) and of Bj\\\"{o}rk and Slinko (2006) applied to our setting. A second\nresult of our paper is that the value per contract solves a {\\it linear}\npartial differential equation as the number of contracts approaches infinity.\nOne can represent the limiting value as an expectation with respect to an\nequivalent martingale measure (as in Blanchet-Scalliet, El Karoui, and\nMartellini (2005)), and from this representation, one can interpret the\ninstantaneous Sharpe ratio as an annuity market's price of mortality risk. \n\n"}
{"id": "0804.0934", "contents": "Title: Analysis of Discrete and Hybrid Stochastic Systems by Nonlinear\n  Contraction Theory Abstract: We investigate the stability properties of discrete and hybrid stochastic\nnonlinear dynamical systems. More precisely, we extend the stochastic\ncontraction theorems (which were formulated for continuous systems) to the case\nof discrete and hybrid resetting systems. In particular, we show that the mean\nsquare distance between any two trajectories of a discrete (or hybrid\nresetting) contracting stochastic system is upper-bounded by a constant after\nexponential transients. Using these results, we study the synchronization of\nnoisy nonlinear oscillators coupled by discrete noisy interactions. \n\n"}
{"id": "0805.0910", "contents": "Title: Lyapunov control of a quantum particle in a decaying potential Abstract: A Lyapunov-based approach for the trajectory generation of an $N$-dimensional\nSchr{\\\"o}dinger equation in whole $\\RR^N$ is proposed. For the case of a\nquantum particle in an $N$-dimensional decaying potential the convergence is\nprecisely analyzed. The free system admitting a mixed spectrum, the dispersion\nthrough the absolutely continuous part is the main obstacle to ensure such a\nstabilization result. Whenever, the system is completely initialized in the\ndiscrete part of the spectrum, a Lyapunov strategy encoding both the distance\nwith respect to the target state and the penalization of the passage through\nthe continuous part of the spectrum, ensures the approximate stabilization. \n\n"}
{"id": "0805.3602", "contents": "Title: Marginal Likelihood Integrals for Mixtures of Independence Models Abstract: Inference in Bayesian statistics involves the evaluation of marginal\nlikelihood integrals. We present algebraic algorithms for computing such\nintegrals exactly for discrete data of small sample size. Our methods apply to\nboth uniform priors and Dirichlet priors. The underlying statistical models are\nmixtures of independent distributions, or, in geometric language, secant\nvarieties of Segre-Veronese varieties. \n\n"}
{"id": "0811.3709", "contents": "Title: A simple intrinsic reduced-observer for geodesic flow Abstract: Aghannan and Rouchon proposed a new design method of asymptotic observers for\na class of nonlinear mechanical systems: Lagrangian systems with configuration\n(position) measurements. The observer is based on the Riemannian structure of\nthe configuration manifold endowed with the kinetic energy metric and is\nintrinsic. They proved local convergence. When the system is conservative, we\npropose a globally convergent intrinsic reduced-observer based on the Jacobi\nmetric. For non-conservative systems the observer can be used as a complement\nto the one of Aghannan and Rouchon. More generally the reduced-observer\nprovides velocity estimation for geodesic flow with position measurements. Thus\nit can be (formally) used as a fluid flow soft sensor in the case of a perfect\nincompressible fluid. When the curvature is negative in all planes the geodesic\nflow is sensitive to initial conditions. Surprisingly this instability yields\nfaster convergence. \n\n"}
{"id": "0901.1477", "contents": "Title: Semi - Riemannian Geometry with Nonholonomic Constraints Abstract: In the present article the geometry of semi-Riemannian manifolds with\nnonholonomic constraints is studied. These manifolds can be considered as\nanalogues to the sub-Riemannian manifolds, where the positively definite metric\nis substituted by a nondegenerate metric. To study properties of the\nexponential map the Christoffel symbols and other differential operators were\nintroduced. We study solutions of the Hamiltonian system and their projections\ninto the underlying manifold. The explicit formulae were found for a specific\nexample of a semi-Riemannian manifold with nonholonomic constraints. \n\n"}
{"id": "0901.2269", "contents": "Title: An Excursion-Theoretic Approach to Stability of Discrete-Time Stochastic\n  Hybrid Systems Abstract: We address stability of a class of Markovian discrete-time stochastic hybrid\nsystems. This class of systems is characterized by the state-space of the\nsystem being partitioned into a safe or target set and its exterior, and the\ndynamics of the system being different in each domain. We give conditions for\n$L_1$-boundedness of Lyapunov functions based on certain negative drift\nconditions outside the target set, together with some more minor assumptions.\nWe then apply our results to a wide class of randomly switched systems (or\niterated function systems), for which we give conditions for global asymptotic\nstability almost surely and in $L_1$. The systems need not be time-homogeneous,\nand our results apply to certain systems for which functional-analytic or\nmartingale-based estimates are difficult or impossible to get. \n\n"}
{"id": "0903.5332", "contents": "Title: On Gossez type (D) maximal monotone operators Abstract: Gossez type (D) operators are defined in non-reflexive Banach spaces and\nshare with the subdifferential a topological related property, characterized by\nbounded nets. In this work we present new properties and characterizations of\nthese operators. The class (NI) was defined after Gossez defined the class (D)\nand seemed to generalize the class (D). One of our main results is the proof\nthat these classes, type (D) and (NI), are identical. \n\n"}
{"id": "0904.0068", "contents": "Title: Verifiable conditions of $\\ell_1$-recovery of sparse signals with sign\n  restrictions Abstract: We propose necessary and sufficient conditions for a sensing matrix to be\n\"s-semigood\" -- to allow for exact $\\ell_1$-recovery of sparse signals with at\nmost $s$ nonzero entries under sign restrictions on part of the entries. We\nexpress the error bounds for imperfect $\\ell_1$-recovery in terms of the\ncharacteristics underlying these conditions. Furthermore, we demonstrate that\nthese characteristics, although difficult to evaluate, lead to verifiable\nsufficient conditions for exact sparse $\\ell_1$-recovery and to efficiently\ncomputable upper bounds on those $s$ for which a given sensing matrix is\n$s$-semigood. We concentrate on the properties of proposed verifiable\nsufficient conditions of $s$-semigoodness and describe their limits of\nperformance. \n\n"}
{"id": "0905.2979", "contents": "Title: Extreme deconvolution: Inferring complete distribution functions from\n  noisy, heterogeneous and incomplete observations Abstract: We generalize the well-known mixtures of Gaussians approach to density\nestimation and the accompanying Expectation--Maximization technique for finding\nthe maximum likelihood parameters of the mixture to the case where each data\npoint carries an individual $d$-dimensional uncertainty covariance and has\nunique missing data properties. This algorithm reconstructs the\nerror-deconvolved or \"underlying\" distribution function common to all samples,\neven when the individual data points are samples from different distributions,\nobtained by convolving the underlying distribution with the heteroskedastic\nuncertainty distribution of the data point and projecting out the missing data\ndirections. We show how this basic algorithm can be extended with conjugate\npriors on all of the model parameters and a \"split-and-merge\" procedure\ndesigned to avoid local maxima of the likelihood. We demonstrate the full\nmethod by applying it to the problem of inferring the three-dimensional\nvelocity distribution of stars near the Sun from noisy two-dimensional,\ntransverse velocity measurements from the Hipparcos satellite. \n\n"}
{"id": "0905.3478", "contents": "Title: Control and Stabilization of the Korteweg-de Vries Equation on a\n  Periodic Domain Abstract: This paper aims at completing an earlier work of Russell and Zhang to study\ninternal control problems for the distributed parameter system described by the\nKorteweg-de Vries equation on a periodic domain T^1. In their article, Russell\nand Zhang showed that the system is locally exactly controllable and locally\nexponentially stabilizable when the control acts on an arbitrary nonempty\nsubdomain of T^1. In this paper, we show that the system is in fact globally\nexactly controllable and globally exponentially stabilizable. The global\nexponential stabilizability corresponding to a natural feedback law is first\nestablished with the aid of certain properties of propagation of compactness\nand propagation of regularity in Bourgain spaces for solutions of the\nassociated linear system. Then, using a different feedback law, the resulting\nclosed-loop system is shown to be locally exponentially stable with an\narbitrarily large decay rate. A time-varying feedback law is further designed\nto ensure a global exponential stability with an arbitrary large decay rate. \n\n"}
{"id": "0909.0588", "contents": "Title: Receding horizon decoding of convolutional codes Abstract: Decoding of convolutional codes poses a significant challenge for coding\ntheory. Classical methods, based on e.g. Viterbi decoding, suffer from being\ncomputationally expensive and are restricted therefore to codes of small\ncomplexity. Based on analogies with model predictive optimal control, we\npropose a new iterative method for convolutional decoding that is cheaper to\nimplement than established algorithms, while still offering significant error\ncorrection capabilities. The algorithm is particularly well-suited for decoding\nspecial types of convolutional codes, such as e.g. cyclic convolutional codes. \n\n"}
{"id": "0910.0651", "contents": "Title: A Simpler Approach to Matrix Completion Abstract: This paper provides the best bounds to date on the number of randomly sampled\nentries required to reconstruct an unknown low rank matrix. These results\nimprove on prior work by Candes and Recht, Candes and Tao, and Keshavan,\nMontanari, and Oh. The reconstruction is accomplished by minimizing the nuclear\nnorm, or sum of the singular values, of the hidden matrix subject to agreement\nwith the provided entries. If the underlying matrix satisfies a certain\nincoherence condition, then the number of entries required is equal to a\nquadratic logarithmic factor times the number of parameters in the singular\nvalue decomposition. The proof of this assertion is short, self contained, and\nuses very elementary analysis. The novel techniques herein are based on recent\nwork in quantum information theory. \n\n"}
{"id": "0912.3033", "contents": "Title: When is multidimensional screening a convex program? Abstract: A principal wishes to transact business with a multidimensional distribution\nof agents whose preferences are known only in the aggregate. Assuming a twist\n(= generalized Spence-Mirrlees single-crossing) hypothesis and that agents can\nchoose only pure strategies, we identify a structural condition on the\npreference b(x,y) of agent type x for product type y -- and on the principal's\ncosts c(y) -- which is necessary and sufficient for reducing the profit\nmaximization problem faced by the principal to a convex program. This is a key\nstep toward making the principal's problem theoretically and computationally\ntractable; in particular, it allows us to derive uniqueness and stability of\nthe principal's optimum strategy -- and similarly of the strategy maximizing\nthe expected welfare of the agents when the principal's profitability is\nconstrained. We call this condition non-negative cross-curvature: it is also\n(i) necessary and sufficient to guarantee convexity of the set of b-convex\nfunctions, (ii) invariant under reparametrization of agent and/or product types\nby diffeomorphisms, and (iii) a strengthening of Ma, Trudinger and Wang's\nnecessary and sufficient condition (A3w) for continuity of the correspondence\nbetween an exogenously prescribed distribution of agents and of products. We\nderive the persistence of economic effects such as the desirability for a\nmonopoly to establish prices so high they effectively exclude a positive\nfraction of its potential customers, in nearly the full range of non-negatively\ncross-curved models. \n\n"}
{"id": "1002.1829", "contents": "Title: On isoperimetric sets of radially symmetric measures Abstract: We study the isoperimetric problem for the radially symmetric measures.\nApplying the spherical symmetrization procedure and variational arguments we\nreduce this problem to a one-dimensional ODE of the second order. Solving\nnumerically this ODE we get an empirical description of isoperimetric regions\nof the planar radially symmetric exponential power laws. We also prove some\nisoperimetric inequalities for the log-convex measures. We show, in particular,\nthat the symmetric balls of large size are isoperimetric sets for strictly\nlog-convex and radially symmetric measures. In addition, we establish some\ncomparison results for general log-convex measures. \n\n"}
{"id": "1003.1771", "contents": "Title: Data Driven Computing by the Morphing Fast Fourier Transform Ensemble\n  Kalman Filter in Epidemic Spread Simulations Abstract: The FFT EnKF data assimilation method is proposed and applied to a stochastic\ncell simulation of an epidemic, based on the S-I-R spread model. The FFT EnKF\ncombines spatial statistics and ensemble filtering methodologies into a\nlocalized and computationally inexpensive version of EnKF with a very small\nensemble, and it is further combined with the morphing EnKF to assimilate\nchanges in the position of the epidemic. \n\n"}
{"id": "1003.3133", "contents": "Title: Generalized Euler-Lagrange equations for variational problems with scale\n  derivatives Abstract: We obtain several Euler-Lagrange equations for variational functionals\ndefined on a set of H\\\"older curves. The cases when the Lagrangian contains\nmultiple scale derivatives, depends on a parameter, or contains higher-order\nscale derivatives are considered. \n\n"}
{"id": "1003.5819", "contents": "Title: A unified controllability/observability theory for some stochastic and\n  deterministic partial differential equations Abstract: The purpose of this paper is to present a universal approach to the study of\ncontrollability/observability problems for infinite dimensional systems\ngoverned by some stochastic/deterministic partial differential equations. The\ncrucial analytic tool is a class of fundamental weighted identities for\nstochastic/deterministic partial differential operators, via which one can\nderive the desired global Carleman estimates. This method can also give a\nunified treatment of the stabilization, global unique continuation, and inverse\nproblems for some stochastic/deterministic partial differential equations. \n\n"}
{"id": "1006.3002", "contents": "Title: Free energy Sequential Monte Carlo, application to mixture modelling Abstract: We introduce a new class of Sequential Monte Carlo (SMC) methods, which we\ncall free energy SMC. This class is inspired by free energy methods, which\noriginate from Physics, and where one samples from a biased distribution such\nthat a given function $\\xi(\\theta)$ of the state $\\theta$ is forced to be\nuniformly distributed over a given interval. From an initial sequence of\ndistributions $(\\pi_t)$ of interest, and a particular choice of $\\xi(\\theta)$,\na free energy SMC sampler computes sequentially a sequence of biased\ndistributions $(\\tilde{\\pi}_{t})$ with the following properties: (a) the\nmarginal distribution of $\\xi(\\theta)$ with respect to $\\tilde{\\pi}_{t}$ is\napproximatively uniform over a specified interval, and (b) $\\tilde{\\pi}_{t}$\nand $\\pi_{t}$ have the same conditional distribution with respect to $\\xi$. We\napply our methodology to mixture posterior distributions, which are highly\nmultimodal. In the mixture context, forcing certain hyper-parameters to higher\nvalues greatly faciliates mode swapping, and makes it possible to recover a\nsymetric output. We illustrate our approach with univariate and bivariate\nGaussian mixtures and two real-world datasets. \n\n"}
{"id": "1006.4046", "contents": "Title: Online Identification and Tracking of Subspaces from Highly Incomplete\n  Information Abstract: This work presents GROUSE (Grassmanian Rank-One Update Subspace Estimation),\nan efficient online algorithm for tracking subspaces from highly incomplete\nobservations. GROUSE requires only basic linear algebraic manipulations at each\niteration, and each subspace update can be performed in linear time in the\ndimension of the subspace. The algorithm is derived by analyzing incremental\ngradient descent on the Grassmannian manifold of subspaces. With a slight\nmodification, GROUSE can also be used as an online incremental algorithm for\nthe matrix completion problem of imputing missing entries of a low-rank matrix.\nGROUSE performs exceptionally well in practice both in tracking subspaces and\nas an online algorithm for matrix completion. \n\n"}
{"id": "1006.4895", "contents": "Title: On the complexity of nonlinear mixed-integer optimization Abstract: This is a survey on the computational complexity of nonlinear mixed-integer\noptimization. It highlights a selection of important topics, ranging from\nincomputability results that arise from number theory and logic, to recently\nobtained fully polynomial time approximation schemes in fixed dimension, and to\nstrongly polynomial-time algorithms for special cases. \n\n"}
{"id": "1007.0743", "contents": "Title: Fractional variational calculus in terms of a combined Caputo derivative Abstract: We generalize the fractional Caputo derivative to the fractional derivative\n${^CD^{\\alpha,\\beta}_{\\gamma}}$, which is a convex combination of the left\nCaputo fractional derivative of order $\\alpha$ and the right Caputo fractional\nderivative of order $\\beta$. The fractional variational problems under our\nconsideration are formulated in terms of ${^CD^{\\alpha,\\beta}_{\\gamma}}$. The\nEuler-Lagrange equations for the basic and isoperimetric problems, as well as\ntransversality conditions, are proved. \n\n"}
{"id": "1007.1345", "contents": "Title: Improved approximation bounds for Vector Bin Packing Abstract: In this paper we propose an improved approximation scheme for the Vector Bin\nPacking problem (VBP), based on the combination of (near-)optimal solution of\nthe Linear Programming (LP) relaxation and a greedy (modified first-fit)\nheuristic. The Vector Bin Packing problem of higher dimension (d \\geq 2) is not\nknown to have asymptotic polynomial-time approximation schemes (unless P = NP).\n  Our algorithm improves over the previously-known guarantee of (ln d + 1 +\nepsilon) by Bansal et al. [1] for higher dimensions (d > 2). We provide a\n{\\theta}(1) approximation scheme for certain set of inputs for any dimension d.\nMore precisely, we provide a 2-OPT algorithm, a result which is irrespective of\nthe number of dimensions d. \n\n"}
{"id": "1008.1355", "contents": "Title: Control Variates for Reversible MCMC Samplers Abstract: A general methodology is introduced for the construction and effective\napplication of control variates to estimation problems involving data from\nreversible MCMC samplers. We propose the use of a specific class of functions\nas control variates, and we introduce a new, consistent estimator for the\nvalues of the coefficients of the optimal linear combination of these\nfunctions. The form and proposed construction of the control variates is\nderived from our solution of the Poisson equation associated with a specific\nMCMC scenario. The new estimator, which can be applied to the same MCMC sample,\nis derived from a novel, finite-dimensional, explicit representation for the\noptimal coefficients. The resulting variance-reduction methodology is primarily\napplicable when the simulated data are generated by a conjugate random-scan\nGibbs sampler. MCMC examples of Bayesian inference problems demonstrate that\nthe corresponding reduction in the estimation variance is significant, and that\nin some cases it can be quite dramatic. Extensions of this methodology in\nseveral directions are given, including certain families of Metropolis-Hastings\nsamplers and hybrid Metropolis-within-Gibbs algorithms. Corresponding\nsimulation examples are presented illustrating the utility of the proposed\nmethods. All methodological and asymptotic arguments are rigorously justified\nunder easily verifiable and essentially minimal conditions. \n\n"}
{"id": "1008.4220", "contents": "Title: Structured sparsity-inducing norms through submodular functions Abstract: Sparse methods for supervised learning aim at finding good linear predictors\nfrom as few variables as possible, i.e., with small cardinality of their\nsupports. This combinatorial selection problem is often turned into a convex\noptimization problem by replacing the cardinality function by its convex\nenvelope (tightest convex lower bound), in this case the L1-norm. In this\npaper, we investigate more general set-functions than the cardinality, that may\nincorporate prior knowledge or structural constraints which are common in many\napplications: namely, we show that for nondecreasing submodular set-functions,\nthe corresponding convex envelope can be obtained from its \\lova extension, a\ncommon tool in submodular analysis. This defines a family of polyhedral norms,\nfor which we provide generic algorithmic tools (subgradients and proximal\noperators) and theoretical results (conditions for support recovery or\nhigh-dimensional inference). By selecting specific submodular functions, we can\ngive a new interpretation to known norms, such as those based on\nrank-statistics or grouped norms with potentially overlapping groups; we also\ndefine new norms, in particular ones that can be used as non-factorial priors\nfor supervised learning. \n\n"}
{"id": "1009.1185", "contents": "Title: Toward the Universal Rigidity of General Frameworks Abstract: Let (G,P) be a bar framework of n vertices in general position in R^d, d <=\nn-1, where G is a (d+1)-lateration graph. In this paper, we present a\nconstructive proof that (G,P) admits a positive semi-definite stress matrix\nwith rank n-d-1. We also prove a similar result for a sensor network where the\ngraph consists of m(>= d+1) anchors. \n\n"}
{"id": "1012.2643", "contents": "Title: Geometry of maximum likelihood estimation in Gaussian graphical models Abstract: We study maximum likelihood estimation in Gaussian graphical models from a\ngeometric point of view. An algebraic elimination criterion allows us to find\nexact lower bounds on the number of observations needed to ensure that the\nmaximum likelihood estimator (MLE) exists with probability one. This is applied\nto bipartite graphs, grids and colored graphs. We also study the ML degree, and\nwe present the first instance of a graph for which the MLE exists with\nprobability one, even when the number of observations equals the treewidth. \n\n"}
{"id": "1101.0955", "contents": "Title: Approximate Bayesian Computational methods Abstract: Also known as likelihood-free methods, approximate Bayesian computational\n(ABC) methods have appeared in the past ten years as the most satisfactory\napproach to untractable likelihood problems, first in genetics then in a\nbroader spectrum of applications. However, these methods suffer to some degree\nfrom calibration difficulties that make them rather volatile in their\nimplementation and thus render them suspicious to the users of more traditional\nMonte Carlo methods. In this survey, we study the various improvements and\nextensions made to the original ABC algorithm over the recent years. \n\n"}
{"id": "1103.0542", "contents": "Title: Optimal scaling and diffusion limits for the Langevin algorithm in high\n  dimensions Abstract: The Metropolis-adjusted Langevin (MALA) algorithm is a sampling algorithm\nwhich makes local moves by incorporating information about the gradient of the\nlogarithm of the target density. In this paper we study the efficiency of MALA\non a natural class of target measures supported on an infinite dimensional\nHilbert space. These natural measures have density with respect to a Gaussian\nrandom field measure and arise in many applications such as Bayesian\nnonparametric statistics and the theory of conditioned diffusions. We prove\nthat, started in stationarity, a suitably interpolated and scaled version of\nthe Markov chain corresponding to MALA converges to an infinite dimensional\ndiffusion process. Our results imply that, in stationarity, the MALA algorithm\napplied to an N-dimensional approximation of the target will take\n$\\mathcal{O}(N^{1/3})$ steps to explore the invariant measure, comparing\nfavorably with the Random Walk Metropolis which was recently shown to require\n$\\mathcal{O}(N)$ steps when applied to the same class of problems. \n\n"}
{"id": "1103.2952", "contents": "Title: Data sets of very large linear feasibility problems solved by projection\n  methods Abstract: We give a link to a page on the Web on which we deposited a set of eight huge\nLinear Programming (LP) problems for Intensity-Modulated Proton Therapy (IMPT)\ntreatment planning. These huge LP problems were employed in our recent research\nand we were asked to make them public. \n\n"}
{"id": "1103.4296", "contents": "Title: Randomized Smoothing for Stochastic Optimization Abstract: We analyze convergence rates of stochastic optimization procedures for\nnon-smooth convex optimization problems. By combining randomized smoothing\ntechniques with accelerated gradient methods, we obtain convergence rates of\nstochastic optimization procedures, both in expectation and with high\nprobability, that have optimal dependence on the variance of the gradient\nestimates. To the best of our knowledge, these are the first variance-based\nrates for non-smooth optimization. We give several applications of our results\nto statistical estimation problems, and provide experimental results that\ndemonstrate the effectiveness of the proposed algorithms. We also describe how\na combination of our algorithm with recent work on decentralized optimization\nyields a distributed stochastic optimization algorithm that is order-optimal. \n\n"}
{"id": "1103.6250", "contents": "Title: Symplectic groupoids and discrete constrained Lagrangian mechanics Abstract: In this article, we generalize the theory of discrete Lagrangian mechanics\nand variational integrators in two principal directions. First, we show that\nLagrangian submanifolds of symplectic groupoids give rise to discrete dynamical\nsystems, and we study the properties of these systems, including their\nregularity and reversibility, from the perspective of symplectic and Poisson\ngeometry. Next, we use this framework -- along with a generalized notion of\ngenerating function due to Sniatycki and Tulczyjew -- to develop a theory of\ndiscrete constrained Lagrangian mechanics. This allows for systems with\narbitrary constraints, including those which are non-integrable (in an\nappropriate discrete, variational sense). In addition to characterizing the\ndynamics of these constrained systems, we also develop a theory of reduction\nand Noether symmetries, and study the relationship between the dynamics and\nvariational principles. Finally, we apply this theory to discretize several\nconcrete examples of constrained systems in mechanics and optimal control. \n\n"}
{"id": "1104.1436", "contents": "Title: Efficient First Order Methods for Linear Composite Regularizers Abstract: A wide class of regularization problems in machine learning and statistics\nemploy a regularization term which is obtained by composing a simple convex\nfunction \\omega with a linear transformation. This setting includes Group Lasso\nmethods, the Fused Lasso and other total variation methods, multi-task learning\nmethods and many more. In this paper, we present a general approach for\ncomputing the proximity operator of this class of regularizers, under the\nassumption that the proximity operator of the function \\omega is known in\nadvance. Our approach builds on a recent line of research on optimal first\norder optimization methods and uses fixed point iterations for numerically\ncomputing the proximity operator. It is more general than current approaches\nand, as we show with numerical simulations, computationally more efficient than\navailable first order methods which do not achieve the optimal rate. In\nparticular, our method outperforms state of the art O(1/T) methods for\noverlapping Group Lasso and matches optimal O(1/T^2) methods for the Fused\nLasso and tree structured Group Lasso. \n\n"}
{"id": "1104.5525", "contents": "Title: Distributed Delayed Stochastic Optimization Abstract: We analyze the convergence of gradient-based optimization algorithms that\nbase their updates on delayed stochastic gradient information. The main\napplication of our results is to the development of gradient-based distributed\noptimization algorithms where a master node performs parameter updates while\nworker nodes compute stochastic gradients based on local information in\nparallel, which may give rise to delays due to asynchrony. We take motivation\nfrom statistical problems where the size of the data is so large that it cannot\nfit on one computer; with the advent of huge datasets in biology, astronomy,\nand the internet, such problems are now common. Our main contribution is to\nshow that for smooth stochastic problems, the delays are asymptotically\nnegligible and we can achieve order-optimal convergence results. In application\nto distributed optimization, we develop procedures that overcome communication\nbottlenecks and synchronization requirements. We show $n$-node architectures\nwhose optimization error in stochastic problems---in spite of asynchronous\ndelays---scales asymptotically as $\\order(1 / \\sqrt{nT})$ after $T$ iterations.\nThis rate is known to be optimal for a distributed system with $n$ nodes even\nin the absence of delays. We additionally complement our theoretical results\nwith numerical experiments on a statistical machine learning task. \n\n"}
{"id": "1105.0728", "contents": "Title: Structured Sparsity via Alternating Direction Methods Abstract: We consider a class of sparse learning problems in high dimensional feature\nspace regularized by a structured sparsity-inducing norm which incorporates\nprior knowledge of the group structure of the features. Such problems often\npose a considerable challenge to optimization algorithms due to the\nnon-smoothness and non-separability of the regularization term. In this paper,\nwe focus on two commonly adopted sparsity-inducing regularization terms, the\noverlapping Group Lasso penalty $l_1/l_2$-norm and the $l_1/l_\\infty$-norm. We\npropose a unified framework based on the augmented Lagrangian method, under\nwhich problems with both types of regularization and their variants can be\nefficiently solved. As the core building-block of this framework, we develop\nnew algorithms using an alternating partial-linearization/splitting technique,\nand we prove that the accelerated versions of these algorithms require\n$O(\\frac{1}{\\sqrt{\\epsilon}})$ iterations to obtain an $\\epsilon$-optimal\nsolution. To demonstrate the efficiency and relevance of our algorithms, we\ntest them on a collection of data sets and apply them to two real-world\nproblems to compare the relative merits of the two norms. \n\n"}
{"id": "1105.2126", "contents": "Title: Fast First-Order Methods for Stable Principal Component Pursuit Abstract: The stable principal component pursuit (SPCP) problem is a non-smooth convex\noptimization problem, the solution of which has been shown both in theory and\nin practice to enable one to recover the low rank and sparse components of a\nmatrix whose elements have been corrupted by Gaussian noise. In this paper, we\nshow how several fast first-order methods can be applied to this problem very\nefficiently. Specifically, we show that the subproblems that arise when\napplying optimal gradient methods of Nesterov, alternating linearization\nmethods and alternating direction augmented Lagrangian methods to the SPCP\nproblem either have closed-form solutions or have solutions that can be\nobtained with very modest effort. All but one of the methods analyzed require\nat least one of the non-smooth terms in the objective function to be smoothed\nand obtain an eps-optimal solution to the SPCP problem in O(1/eps) iterations.\nThe method that works directly with the fully non-smooth objective function, is\nproved to be convergent under mild conditions on the sequence of parameters it\nuses. Our preliminary computational tests show that the latter method, although\nits complexity is not known, is fastest and substantially outperforms existing\nmethods for the SPCP problem. To best of our knowledge, an algorithm for the\nSPCP problem that has O(1/eps) iteration complexity and has a per iteration\ncomplexity equal to that of a singular value decomposition is given for the\nfirst time. \n\n"}
{"id": "1105.3631", "contents": "Title: A majorization method for localizing graph topological indices Abstract: This paper presents a unified approach for localizing some relevant graph\ntopological indices via majorization techniques. Through this method, old and\nnew bounds are derived and numerical examples are provided, showing how former\nresults in the literature could be improved. \n\n"}
{"id": "1106.0090", "contents": "Title: Multigrid preconditioning of linear systems for semismooth Newton\n  methods applied to optimization problems constrained by smoothing operators Abstract: This article is concerned with the question of constructing effcient\nmultigrid preconditioners for the linear systems arising when applying\nsemismooth Newton methods to large-scale linear-quadratic optimization problems\nconstrained by smoothing operators with box-constraints on the controls. It is\nshown that, for certain discretizations of the optimization problem, the linear\nsystems to be solved at each semismooth Newton iteration reduce to inverting\nprincipal minors of the Hessian of the associated unconstrained problem. As in\nthe case when box-constraints on the controls are absent, the multigrid\npreconditioner introduced here is shown to increase in quality as the mesh-size\ndecreases, resulting in a number of iterations that decreases with mesh-size.\nHowever, unlike the unconstrained case, the spectral distance between the\npreconditioners and the Hessian is shown to be of suboptimal order in general. \n\n"}
{"id": "1106.0322", "contents": "Title: Bayesian Sparsity-Path-Analysis of Genetic Association Signal using\n  Generalized t Priors Abstract: We explore the use of generalized t priors on regression coefficients to help\nunderstand the nature of association signal within \"hit regions\" of genome-wide\nassociation studies. The particular generalized t distribution we adopt is a\nStudent distribution on the absolute value of its argument. For low degrees of\nfreedom we show that the generalized t exhibits 'sparsity-prior' properties\nwith some attractive features over other common forms of sparse priors and\nincludes the well known double-exponential distribution as the degrees of\nfreedom tends to infinity. We pay particular attention to graphical\nrepresentations of posterior statistics obtained from sparsity-path-analysis\n(SPA) where we sweep over the setting of the scale (shrinkage / precision)\nparameter in the prior to explore the space of posterior models obtained over a\nrange of complexities, from very sparse models with all coefficient\ndistributions heavily concentrated around zero, to models with diffuse priors\nand coefficients distributed around their maximum likelihood estimates. The SPA\nplots are akin to LASSO plots of maximum a posteriori (MAP) estimates but they\ncharacterise the complete marginal posterior distributions of the coefficients\nplotted as a function of the precision of the prior. Generating posterior\ndistributions over a range of prior precisions is computationally challenging\nbut naturally amenable to sequential Monte Carlo (SMC) algorithms indexed on\nthe scale parameter. We show how SMC simulation on graphic-processing-units\n(GPUs) provides very efficient inference for SPA. We also present a\nscale-mixture representation of the generalized t prior that leads to an EM\nalgorithm to obtain MAP estimates should only these be required. \n\n"}
{"id": "1106.5850", "contents": "Title: Markov Chain Monte Carlo Based on Deterministic Transformations Abstract: In this article we propose a novel MCMC method based on deterministic\ntransformations T: X x D --> X where X is the state-space and D is some set\nwhich may or may not be a subset of X. We refer to our new methodology as\nTransformation-based Markov chain Monte Carlo (TMCMC). One of the remarkable\nadvantages of our proposal is that even if the underlying target distribution\nis very high-dimensional, deterministic transformation of a one-dimensional\nrandom variable is sufficient to generate an appropriate Markov chain that is\nguaranteed to converge to the high-dimensional target distribution. Apart from\nclearly leading to massive computational savings, this idea of\ndeterministically transforming a single random variable very generally leads to\nexcellent acceptance rates, even though all the random variables associated\nwith the high-dimensional target distribution are updated in a single block.\nSince it is well-known that joint updating of many random variables using\nMetropolis-Hastings (MH) algorithm generally leads to poor acceptance rates,\nTMCMC, in this regard, seems to provide a significant advance. We validate our\nproposal theoretically, establishing the convergence properties. Furthermore,\nwe show that TMCMC can be very effectively adopted for simulating from doubly\nintractable distributions.\n  TMCMC is compared with MH using the well-known Challenger data, demonstrating\nthe effectiveness of of the former in the case of highly correlated variables.\nMoreover, we apply our methodology to a challenging posterior simulation\nproblem associated with the geostatistical model of Diggle et al. (1998),\nupdating 160 unknown parameters jointly, using a deterministic transformation\nof a one-dimensional random variable. Remarkable computational savings as well\nas good convergence properties and acceptance rates are the results. \n\n"}
{"id": "1107.0360", "contents": "Title: Barrier methods for critical exponent problems in geometric analysis and\n  mathematical physics Abstract: We consider the design and analysis of numerical methods for approximating\npositive solutions to nonlinear geometric elliptic partial differential\nequations containing critical exponents. This class of problems includes the\nYamabe problem and the Einstein constraint equations, which simultaneously\ncontain several challenging features: high spatial dimension n >= 3, varying\n(potentially non-smooth) coefficients, critical (even super-critical)\nnonlinearity, non-monotone nonlinearity (arising from a non-convex energy), and\nspatial domains that are typically Riemannian manifolds rather than simply open\nsets in Rn. These problems may exhibit multiple solutions, although only\npositive solutions typically have meaning. This creates additional complexities\nin both the theory and numerical treatment of such problems, as this feature\nintroduces both non-uniqueness as well as the need to incorporate an inequality\nconstraint into the formulation. In this work, we consider numerical methods\nbased on Galerkin-type discretization, covering any standard bases construction\n(finite element, spectral, or wavelet), and the combination of a barrier method\nfor nonconvex optimization and global inexact Newton-type methods for dealing\nwith nonconvexity and the presence of inequality constraints. We first give an\noverview of barrier methods in non-convex optimization, and then develop and\nanalyze both a primal barrier energy method for this class of problems. We then\nconsider a sequence of numerical experiments using this type of barrier method,\nbased on a particular Galerkin method, namely the piecewise linear finite\nelement method, leverage the FETK modeling package. We illustrate the behavior\nof the primal barrier energy method for several examples, including the Yamabe\nproblem and the Hamiltonian constraint. \n\n"}
{"id": "1107.4142", "contents": "Title: Asymptotics of the Invariant Measure in Mean Field Models with Jumps Abstract: We consider the asymptotics of the invariant measure for the process of the\nempirical spatial distribution of $N$ coupled Markov chains in the limit of a\nlarge number of chains. Each chain reflects the stochastic evolution of one\nparticle. The chains are coupled through the dependence of the transition rates\non this spatial distribution of particles in the various states. Our model is a\ncaricature for medium access interactions in wireless local area networks. It\nis also applicable to the study of spread of epidemics in a network. The\nlimiting process satisfies a deterministic ordinary differential equation\ncalled the McKean-Vlasov equation. When this differential equation has a unique\nglobally asymptotically stable equilibrium, the spatial distribution\nasymptotically concentrates on this equilibrium. More generally, its limit\npoints are supported on a subset of the $\\omega$-limit sets of the\nMcKean-Vlasov equation. Using a control-theoretic approach, we examine the\nquestion of large deviations of the invariant measure from this limit. \n\n"}
{"id": "1107.4623", "contents": "Title: A Unifying Analysis of Projected Gradient Descent for\n  $\\ell_p$-constrained Least Squares Abstract: In this paper we study the performance of the Projected Gradient Descent(PGD)\nalgorithm for $\\ell_{p}$-constrained least squares problems that arise in the\nframework of Compressed Sensing. Relying on the Restricted Isometry Property,\nwe provide convergence guarantees for this algorithm for the entire range of\n$0\\leq p\\leq1$, that include and generalize the existing results for the\nIterative Hard Thresholding algorithm and provide a new accuracy guarantee for\nthe Iterative Soft Thresholding algorithm as special cases. Our results suggest\nthat in this group of algorithms, as $p$ increases from zero to one, conditions\nrequired to guarantee accuracy become stricter and robustness to noise\ndeteriorates. \n\n"}
{"id": "1108.2018", "contents": "Title: Resource allocation with costly participation Abstract: We propose a new all-pay auction format in which risk-loving bidders pay a\nconstant fee each time they bid for an object whose monetary value is common\nknowledge among the bidders, and bidding fees are the only source of benefit\nfor the seller. We show that for the proposed model there exists a {unique}\nSymmetric Subgame Perfect Equilibrium (SSPE). The characterized SSPE is\nstationary when re-entry in the auction is allowed, and it is Markov perfect\nwhen re-entry is forbidden. Furthermore, we fully characterize the expected\nrevenue of the seller. Generally, with or without re-entry, it is more\nbeneficial for the seller to choose $v$ (value of the object), $s$ (sale\nprice), and $c$ (bidding fee) such that $\\frac{v-s}{c}$ becomes sufficiently\nlarge. In particular, when re-entry is permitted: the expected revenue of the\nseller is \\emph{independent} of the number of bidders, decreasing in the sale\nprice, increasing in the value of the object, and decreasing in the bidding\nfee; Moreover, the seller's revenue is equal to the value of the object when\nplayers are risk neutral, and it is strictly greater than the value of the\nobject when bidders are risk-loving. We further show that allowing re-entry can\nbe important in practice. Because, if the seller were to run such an auction\nwithout allowing re-entry, the auction would last a long time, and for almost\nall of its duration have only two remaining players. Thus, the seller's revenue\nrelies on those two players being willing to participate, without any breaks,\nin an auction that might last for thousands of rounds \n\n"}
{"id": "1108.4216", "contents": "Title: Coordination of passive systems under quantized measurements Abstract: In this paper we investigate a passivity approach to collective coordination\nand synchronization problems in the presence of quantized measurements and show\nthat coordination tasks can be achieved in a practical sense for a large class\nof passive systems. \n\n"}
{"id": "1109.0258", "contents": "Title: Nonconvex proximal splitting: batch and incremental algorithms Abstract: Within the unmanageably large class of nonconvex optimization, we consider\nthe rich subclass of nonsmooth problems that have composite objectives---this\nalready includes the extensively studied convex, composite objective problems\nas a special case. For this subclass, we introduce a powerful, new framework\nthat permits asymptotically non-vanishing perturbations. In particular, we\ndevelop perturbation-based batch and incremental (online like) nonconvex\nproximal splitting algorithms. To our knowledge, this is the first time that\nsuch perturbation-based nonconvex splitting algorithms are being proposed and\nanalyzed. While the main contribution of the paper is the theoretical\nframework, we complement our results by presenting some empirical results on\nmatrix factorization. \n\n"}
{"id": "1109.1649", "contents": "Title: Reachability in Biochemical Dynamical Systems by Quantitative Discrete\n  Approximation (extended abstract) Abstract: In this paper, a novel computational technique for finite discrete\napproximation of continuous dynamical systems suitable for a significant class\nof biochemical dynamical systems is introduced. The method is parameterized in\norder to affect the imposed level of approximation provided that with\nincreasing parameter value the approximation converges to the original\ncontinuous system. By employing this approximation technique, we present\nalgorithms solving the reachability problem for biochemical dynamical systems.\nThe presented method and algorithms are evaluated on several exemplary\nbiological models and on a real case study. \n\n"}
{"id": "1109.2415", "contents": "Title: Convergence Rates of Inexact Proximal-Gradient Methods for Convex\n  Optimization Abstract: We consider the problem of optimizing the sum of a smooth convex function and\na non-smooth convex function using proximal-gradient methods, where an error is\npresent in the calculation of the gradient of the smooth term or in the\nproximity operator with respect to the non-smooth term. We show that both the\nbasic proximal-gradient method and the accelerated proximal-gradient method\nachieve the same convergence rate as in the error-free case, provided that the\nerrors decrease at appropriate rates.Using these rates, we perform as well as\nor better than a carefully chosen fixed error level on a set of structured\nsparsity problems. \n\n"}
{"id": "1109.4184", "contents": "Title: A (k+1)-Slope Theorem for the k-Dimensional Infinite Group Relaxation Abstract: We prove that any minimal valid function for the k-dimensional infinite group\nrelaxation that is piecewise linear with at most k+1 slopes and does not factor\nthrough a linear map with non-trivial kernel is extreme. This generalizes a\ntheorem of Gomory and Johnson for k=1, and Cornuejols and Molinaro for k=2. \n\n"}
{"id": "1111.1926", "contents": "Title: Performance Analysis of Sequential Method for Handover in Cognitive\n  Radio Systems Abstract: Powerful spectrum handover schemes enable cognitive radios (CRs) to use\ntransmission opportunities in primary users' channels appropriately. In this\npaper, we consider the cognitive access of primary channels by a secondary\nuser. We evaluate the average detection time and the maximum achievable average\nthroughput of the secondary user when the sequential method for hand-over\n(SMHO) is used. We assume that a prior knowledge of the primary users' presence\nand absence probabilities are available. When investigating the maximum\nachievable throughput of the secondary user, we end into an optimization\nproblem, in which the optimum value of sensing time must be selected. In our\noptimization problem, we take into account the spectrum hand over due to false\ndetection of the primary user. We also propose a weighted based hand-over\n(WBHO) scheme in which the impacts of channels conditions and primary users'\npresence probability are considered. This Spectrum handover scheme provides\nhigher average throughput for the SU than the SMHO method. The tradeoff between\nthe maximum achievable throughput and consumed energy is discussed, and finally\nan energy efficient optimization formulation for finding a proper sensing time\nis provided. \n\n"}
{"id": "1111.2546", "contents": "Title: Accuracy guaranties for $\\ell_1$ recovery of block-sparse signals Abstract: We introduce a general framework to handle structured models (sparse and\nblock-sparse with possibly overlapping blocks). We discuss new methods for\ntheir recovery from incomplete observation, corrupted with deterministic and\nstochastic noise, using block-$\\ell_1$ regularization. While the current theory\nprovides promising bounds for the recovery errors under a number of different,\nyet mostly hard to verify conditions, our emphasis is on verifiable conditions\non the problem parameters (sensing matrix and the block structure) which\nguarantee accurate recovery. Verifiability of our conditions not only leads to\nefficiently computable bounds for the recovery error but also allows us to\noptimize these error bounds with respect to the method parameters, and\ntherefore construct estimators with improved statistical properties. To justify\nour approach, we also provide an oracle inequality, which links the properties\nof the proposed recovery algorithms and the best estimation performance.\nFurthermore, utilizing these verifiable conditions, we develop a\ncomputationally cheap alternative to block-$\\ell_1$ minimization, the\nnon-Euclidean Block Matching Pursuit algorithm. We close by presenting a\nnumerical study to investigate the effect of different block regularizations\nand demonstrate the performance of the proposed recoveries. \n\n"}
{"id": "1111.2667", "contents": "Title: A note on the lack of symmetry in the graphical lasso Abstract: The graphical lasso (glasso) is a widely-used fast algorithm for estimating\nsparse inverse covariance matrices. The glasso solves an L1 penalized maximum\nlikelihood problem and is available as an R library on CRAN. The output from\nthe glasso, a regularized covariance matrix estimate a sparse inverse\ncovariance matrix estimate, not only identify a graphical model but can also\nserve as intermediate inputs into multivariate procedures such as PCA, LDA,\nMANOVA, and others. The glasso indeed produces a covariance matrix estimate\nwhich solves the L1 penalized optimization problem in a dual sense; however,\nthe method for producing the inverse covariance matrix estimator after this\noptimization is inexact and may produce asymmetric estimates. This problem is\nexacerbated when the amount of L1 regularization that is applied is small,\nwhich in turn is more likely to occur if the true underlying inverse covariance\nmatrix is not sparse. The lack of symmetry can potentially have consequences.\nFirst, it implies that the covariance and inverse covariance estimates are not\nnumerical inverses of one another, and second, asymmetry can possibly lead to\nnegative or complex eigenvalues,rendering many multivariate procedures which\nmay depend on the inverse covariance estimator unusable. We demonstrate this\nproblem, explain its causes, and propose possible remedies. \n\n"}
{"id": "1111.4118", "contents": "Title: Analog Sparse Approximation with Applications to Compressed Sensing Abstract: Recent research has shown that performance in signal processing tasks can\noften be significantly improved by using signal models based on sparse\nrepresentations, where a signal is approximated using a small number of\nelements from a fixed dictionary. Unfortunately, inference in this model\ninvolves solving non-smooth optimization problems that are computationally\nexpensive. While significant efforts have focused on developing digital\nalgorithms specifically for this problem, these algorithms are inappropriate\nfor many applications because of the time and power requirements necessary to\nsolve large optimization problems. Based on recent work in computational\nneuroscience, we explore the potential advantages of continuous time dynamical\nsystems for solving sparse approximation problems if they were implemented in\nanalog VLSI. Specifically, in the simulated task of recovering synthetic and\nMRI data acquired via compressive sensing techniques, we show that these\nsystems can potentially perform recovery at time scales of 10-20{\\mu}s,\nsupporting datarates of 50-100 kHz (orders of magnitude faster that digital\nalgorithms). Furthermore, we show analytically that a wide range of sparse\napproximation problems can be solved in the same basic architecture, including\napproximate $\\ell^p$ norms, modified $\\ell^1$ norms, re-weighted $\\ell^1$ and\n$\\ell^2$, the block $\\ell^1$ norm and classic Tikhonov regularization. \n\n"}
{"id": "1111.6453", "contents": "Title: Learning with Submodular Functions: A Convex Optimization Perspective Abstract: Submodular functions are relevant to machine learning for at least two\nreasons: (1) some problems may be expressed directly as the optimization of\nsubmodular functions and (2) the lovasz extension of submodular functions\nprovides a useful set of regularization functions for supervised and\nunsupervised learning. In this monograph, we present the theory of submodular\nfunctions from a convex analysis perspective, presenting tight links between\ncertain polyhedra, combinatorial optimization and convex optimization problems.\nIn particular, we show how submodular function minimization is equivalent to\nsolving a wide variety of convex optimization problems. This allows the\nderivation of new efficient algorithms for approximate and exact submodular\nfunction minimization with theoretical guarantees and good practical\nperformance. By listing many examples of submodular functions, we review\nvarious applications to machine learning, such as clustering, experimental\ndesign, sensor placement, graphical model structure learning or subset\nselection, as well as a family of structured sparsity-inducing norms that can\nbe derived and used from submodular functions. \n\n"}
{"id": "1111.6453", "contents": "Title: Learning with Submodular Functions: A Convex Optimization Perspective Abstract: Submodular functions are relevant to machine learning for at least two\nreasons: (1) some problems may be expressed directly as the optimization of\nsubmodular functions and (2) the lovasz extension of submodular functions\nprovides a useful set of regularization functions for supervised and\nunsupervised learning. In this monograph, we present the theory of submodular\nfunctions from a convex analysis perspective, presenting tight links between\ncertain polyhedra, combinatorial optimization and convex optimization problems.\nIn particular, we show how submodular function minimization is equivalent to\nsolving a wide variety of convex optimization problems. This allows the\nderivation of new efficient algorithms for approximate and exact submodular\nfunction minimization with theoretical guarantees and good practical\nperformance. By listing many examples of submodular functions, we review\nvarious applications to machine learning, such as clustering, experimental\ndesign, sensor placement, graphical model structure learning or subset\nselection, as well as a family of structured sparsity-inducing norms that can\nbe derived and used from submodular functions. \n\n"}
{"id": "1112.2797", "contents": "Title: Low Power Dynamic Scheduling for Computing Systems Abstract: This paper considers energy-aware control for a computing system with two\nstates: \"active\" and \"idle.\" In the active state, the controller chooses to\nperform a single task using one of multiple task processing modes. The\ncontroller then saves energy by choosing an amount of time for the system to be\nidle. These decisions affect processing time, energy expenditure, and an\nabstract attribute vector that can be used to model other criteria of interest\n(such as processing quality or distortion). The goal is to optimize time\naverage system performance. Applications of this model include a smart phone\nthat makes energy-efficient computation and transmission decisions, a computer\nthat processes tasks subject to rate, quality, and power constraints, and a\nsmart grid energy manager that allocates resources in reaction to a time\nvarying energy price. The solution methodology of this paper uses the theory of\noptimization for renewal systems developed in our previous work. This paper is\nwritten in tutorial form and develops the main concepts of the theory using\nseveral detailed examples. It also highlights the relationship between online\ndynamic optimization and linear fractional programming. Finally, it provides\nexercises to help the reader learn the main concepts and apply them to their\nown optimizations. This paper is an arxiv technical report, and is a\npreliminary version of material that will appear as a book chapter in an\nupcoming book on green communications and networking. \n\n"}
{"id": "1112.4755", "contents": "Title: Approximate Bayesian computation and Bayes linear analysis: Towards\n  high-dimensional ABC Abstract: Bayes linear analysis and approximate Bayesian computation (ABC) are\ntechniques commonly used in the Bayesian analysis of complex models. In this\narticle we connect these ideas by demonstrating that regression-adjustment ABC\nalgorithms produce samples for which first and second order moment summaries\napproximate adjusted expectation and variance for a Bayes linear analysis. This\ngives regression-adjustment methods a useful interpretation and role in\nexploratory analysis in high-dimensional problems. As a result, we propose a\nnew method for combining high-dimensional, regression-adjustment ABC with\nlower-dimensional approaches (such as using MCMC for ABC). This method first\nobtains a rough estimate of the joint posterior via regression-adjustment ABC,\nand then estimates each univariate marginal posterior distribution separately\nin a lower-dimensional analysis. The marginal distributions of the initial\nestimate are then modified to equal the separately estimated marginals, thereby\nproviding an improved estimate of the joint posterior. We illustrate this\nmethod with several examples. Supplementary materials for this article are\navailable online. \n\n"}
{"id": "1112.4923", "contents": "Title: Compositions and convex combinations of asymptotically regular firmly\n  nonexpansive mappings are also asymptotically regular Abstract: Because of Minty's classical correspondence between firmly nonexpansive\nmappings and maximally monotone operators, the notion of a firmly nonexpansive\nmapping has proven to be of basic importance in fixed point theory, monotone\noperator theory, and convex optimization. In this note, we show that if\nfinitely many firmly nonexpansive mappings defined on a real Hilbert space are\ngiven and each of these mappings is asymptotically regular, which is equivalent\nto saying that they have or \"almost have\" fixed points, then the same is true\nfor their composition. This significantly generalizes the result by Bauschke\nfrom 2003 for the case of projectors (nearest point mappings). The proof\nresides in a Hilbert product space and it relies upon the Brezis-Haraux range\napproximation result. By working in a suitably scaled Hilbert product space, we\nalso establish the asymptotic regularity of convex combinations. \n\n"}
{"id": "1112.6212", "contents": "Title: Diffusion Adaptation over Networks under Imperfect Information Exchange\n  and Non-stationary Data Abstract: Adaptive networks rely on in-network and collaborative processing among\ndistributed agents to deliver enhanced performance in estimation and inference\ntasks. Information is exchanged among the nodes, usually over noisy links. The\ncombination weights that are used by the nodes to fuse information from their\nneighbors play a critical role in influencing the adaptation and tracking\nabilities of the network. This paper first investigates the mean-square\nperformance of general adaptive diffusion algorithms in the presence of various\nsources of imperfect information exchanges, quantization errors, and model\nnon-stationarities. Among other results, the analysis reveals that link noise\nover the regression data modifies the dynamics of the network evolution in a\ndistinct way, and leads to biased estimates in steady-state. The analysis also\nreveals how the network mean-square performance is dependent on the combination\nweights. We use these observations to show how the combination weights can be\noptimized and adapted. Simulation results illustrate the theoretical findings\nand match well with theory. \n\n"}
{"id": "1201.0256", "contents": "Title: Multitime controlled linear PDE systems Abstract: We derive new results regarding the controllability and the reachability of\nmultitime controlled linear PDE systems of first order. These systems describe\nsome important multitime evolution in engineering, economics and biology. Some\nof them come from evolution PDEs of superior order. The original results\ninclude a refinement and a supplement of multitime optimal control theory,\ndeveloped in some recent papers by the second author. They refer to the\ncomplete integrability conditions, conditions for the existence of solutions,\npath independent curvilinear integrals, the multitime fundamental matrix,\nmultitime adjoint Cauchy problems, control space, controllability and\nreachability of phases, controllability gramian, reachability gramian,\ncontrollability matrix, counter-examples and commentaries. \n\n"}
{"id": "1201.1314", "contents": "Title: Some discussions of D. Fearnhead and D. Prangle's Read Paper\n  \"Constructing summary statistics for approximate Bayesian computation:\n  semi-automatic approximate Bayesian computation\" Abstract: This report is a collection of comments on the Read Paper of Fearnhead and\nPrangle (2011), to appear in the Journal of the Royal Statistical Society\nSeries B, along with a reply from the authors. \n\n"}
{"id": "1203.4523", "contents": "Title: On the Equivalence between Herding and Conditional Gradient Algorithms Abstract: We show that the herding procedure of Welling (2009) takes exactly the form\nof a standard convex optimization algorithm--namely a conditional gradient\nalgorithm minimizing a quadratic moment discrepancy. This link enables us to\ninvoke convergence results from convex optimization and to consider faster\nalternatives for the task of approximating integrals in a reproducing kernel\nHilbert space. We study the behavior of the different variants through\nnumerical simulations. The experiments indicate that while we can improve over\nherding on the task of approximating integrals, the original herding algorithm\ntends to approach more often the maximum entropy distribution, shedding more\nlight on the learning bias behind herding. \n\n"}
{"id": "1204.3275", "contents": "Title: General Pontryagin-Type Stochastic Maximum Principle and Backward\n  Stochastic Evolution Equations in Infinite Dimensions Abstract: The main purpose of this paper is to give a solution to a long-standing\nunsolved problem in stochastic control theory, i.e., to establish the\nPontryagin-type maximum principle for optimal controls of general infinite\ndimensional nonlinear stochastic evolution equations. Both drift and diffusion\nterms can contain the control variables, and the control domains are allowed to\nbe nonconvex. The key to reach it is to provide a suitable formulation of\noperator-valued backward stochastic evolution equations (BSEEs for short), as\nwell as a way to define their solutions. Besides, both vector-valued and\noperator-valued BSEEs, with solutions in the sense of transposition, are\nstudied. As a crucial preliminary, some weakly sequential Banach-Alaoglu-type\ntheorems are established for uniformly bounded linear operators between Banach\nspaces. \n\n"}
{"id": "1204.4717", "contents": "Title: Energy-Efficient Building HVAC Control Using Hybrid System LBMPC Abstract: Improving the energy-efficiency of heating, ventilation, and air-conditioning\n(HVAC) systems has the potential to realize large economic and societal\nbenefits. This paper concerns the system identification of a hybrid system\nmodel of a building-wide HVAC system and its subsequent control using a hybrid\nsystem formulation of learning-based model predictive control (LBMPC). Here,\nthe learning refers to model updates to the hybrid system model that\nincorporate the heating effects due to occupancy, solar effects, outside air\ntemperature (OAT), and equipment, in addition to integrator dynamics inherently\npresent in low-level control. Though we make significant modeling\nsimplifications, our corresponding controller that uses this model is able to\nexperimentally achieve a large reduction in energy usage without any\ndegradations in occupant comfort. It is in this way that we justify the\nmodeling simplifications that we have made. We conclude by presenting results\nfrom experiments on our building HVAC testbed, which show an average of 1.5MWh\nof energy savings per day (p = 0.002) with a 95% confidence interval of 1.0MWh\nto 2.1MWh of energy savings. \n\n"}
{"id": "1204.5459", "contents": "Title: Inference for SDE models via Approximate Bayesian Computation Abstract: Models defined by stochastic differential equations (SDEs) allow for the\nrepresentation of random variability in dynamical systems. The relevance of\nthis class of models is growing in many applied research areas and is already a\nstandard tool to model e.g. financial, neuronal and population growth dynamics.\nHowever inference for multidimensional SDE models is still very challenging,\nboth computationally and theoretically. Approximate Bayesian computation (ABC)\nallow to perform Bayesian inference for models which are sufficiently complex\nthat the likelihood function is either analytically unavailable or\ncomputationally prohibitive to evaluate. A computationally efficient ABC-MCMC\nalgorithm is proposed, halving the running time in our simulations. Focus is on\nthe case where the SDE describes latent dynamics in state-space models; however\nthe methodology is not limited to the state-space framework. Simulation studies\nfor a pharmacokinetics/pharmacodynamics model and for stochastic chemical\nreactions are considered and a MATLAB package implementing our ABC-MCMC\nalgorithm is provided. \n\n"}
{"id": "1205.0047", "contents": "Title: $QD$-Learning: A Collaborative Distributed Strategy for Multi-Agent\n  Reinforcement Learning Through Consensus + Innovations Abstract: The paper considers a class of multi-agent Markov decision processes (MDPs),\nin which the network agents respond differently (as manifested by the\ninstantaneous one-stage random costs) to a global controlled state and the\ncontrol actions of a remote controller. The paper investigates a distributed\nreinforcement learning setup with no prior information on the global state\ntransition and local agent cost statistics. Specifically, with the agents'\nobjective consisting of minimizing a network-averaged infinite horizon\ndiscounted cost, the paper proposes a distributed version of $Q$-learning,\n$\\mathcal{QD}$-learning, in which the network agents collaborate by means of\nlocal processing and mutual information exchange over a sparse (possibly\nstochastic) communication network to achieve the network goal. Under the\nassumption that each agent is only aware of its local online cost data and the\ninter-agent communication network is \\emph{weakly} connected, the proposed\ndistributed scheme is almost surely (a.s.) shown to yield asymptotically the\ndesired value function and the optimal stationary control policy at each\nnetwork agent. The analytical techniques developed in the paper to address the\nmixed time-scale stochastic dynamics of the \\emph{consensus + innovations}\nform, which arise as a result of the proposed interactive distributed scheme,\nare of independent interest. \n\n"}
{"id": "1205.0121", "contents": "Title: Approximation Bounds for Sparse Principal Component Analysis Abstract: We produce approximation bounds on a semidefinite programming relaxation for\nsparse principal component analysis. These bounds control approximation ratios\nfor tractable statistics in hypothesis testing problems where data points are\nsampled from Gaussian models with a single sparse leading component. \n\n"}
{"id": "1205.0482", "contents": "Title: On the Generalized Ratio of Uniforms as a Combination of Transformed\n  Rejection and Extended Inverse of Density Sampling Abstract: In this work we investigate the relationship among three classical sampling\ntechniques: the inverse of density (Khintchine's theorem), the transformed\nrejection (TR) and the generalized ratio of uniforms (GRoU). Given a monotonic\nprobability density function (PDF), we show that the transformed area obtained\nusing the generalized ratio of uniforms method can be found equivalently by\napplying the transformed rejection sampling approach to the inverse function of\nthe target density. Then we provide an extension of the classical inverse of\ndensity idea, showing that it is completely equivalent to the GRoU method for\nmonotonic densities. Although we concentrate on monotonic probability density\nfunctions (PDFs), we also discuss how the results presented here can be\nextended to any non-monotonic PDF that can be decomposed into a collection of\nintervals where it is monotonically increasing or decreasing. In this general\ncase, we show the connections with transformations of certain random variables\nand the generalized inverse PDF with the GRoU technique. Finally, we also\nintroduce a GRoU technique to handle unbounded target densities. \n\n"}
{"id": "1205.1076", "contents": "Title: Adaptive parallel tempering algorithm Abstract: Parallel tempering is a generic Markov chain Monte Carlo sampling method\nwhich allows good mixing with multimodal target distributions, where\nconventional Metropolis-Hastings algorithms often fail. The mixing properties\nof the sampler depend strongly on the choice of tuning parameters, such as the\ntemperature schedule and the proposal distribution used for local exploration.\nWe propose an adaptive algorithm which tunes both the temperature schedule and\nthe parameters of the random-walk Metropolis kernel automatically. We prove the\nconvergence of the adaptation and a strong law of large numbers for the\nalgorithm. We illustrate the performance of our method with examples. Our\nempirical findings indicate that the algorithm can cope well with different\nkind of scenarios without prior tuning. \n\n"}
{"id": "1205.2046", "contents": "Title: Multiset Estimates and Combinatorial Synthesis Abstract: The paper addresses an approach to ordinal assessment of alternatives based\non assignment of elements into an ordinal scale. Basic versions of the\nassessment problems are formulated while taking into account the number of\nlevels at a basic ordinal scale [1,2,...,l] and the number of assigned elements\n(e.g., 1,2,3). The obtained estimates are multisets (or bags) (cardinality of\nthe multiset equals a constant). Scale-posets for the examined assessment\nproblems are presented. 'Interval multiset estimates' are suggested. Further,\noperations over multiset estimates are examined: (a) integration of multiset\nestimates, (b) proximity for multiset estimates, (c) comparison of multiset\nestimates, (d) aggregation of multiset estimates, and (e) alignment of multiset\nestimates. Combinatorial synthesis based on morphological approach is examined\nincluding the modified version of the approach with multiset estimates of\ndesign alternatives. Knapsack-like problems with multiset estimates are briefly\ndescribed as well. The assessment approach, multiset-estimates, and\ncorresponding combinatorial problems are illustrated by numerical examples. \n\n"}
{"id": "1205.2881", "contents": "Title: On implicational bases of closure systems with unique critical sets Abstract: We show that every optimum basis of a finite closure system, in D.Maier's\nsense, is also right-side optimum, which is a parameter of a minimum CNF\nrepresentation of a Horn Boolean function. New parameters for the size of the\nbinary part are also established. We introduce a K-basis of a general closure\nsystem, which is a refinement of the canonical basis of Duquenne and Guigues,\nand discuss a polynomial algorithm to obtain it. We study closure systems with\nthe unique criticals and some of its subclasses, where the K-basis is unique. A\nfurther refinement in the form of the E-basis is possible for closure systems\nwithout D-cycles. There is a polynomial algorithm to recognize the D-relation\nfrom a K-basis. Thus, closure systems without D-cycles can be effectively\nrecognized. While E-basis achieves an optimum in one of its parts, the\noptimization of the others is an NP-complete problem. \n\n"}
{"id": "1205.3269", "contents": "Title: Characterization and Moment Stability Analysis of Quasilinear Quantum\n  Stochastic Systems with Quadratic Coupling to External Fields Abstract: The paper is concerned with open quantum systems whose Heisenberg dynamics\nare described by quantum stochastic differential equations driven by external\nboson fields. The system-field coupling operators are assumed to be quadratic\npolynomials of the system observables, with the latter satisfying canonical\ncommutation relations. In combination with a cubic system Hamiltonian, this\nleads to a class of quasilinear quantum stochastic systems which retain\nalgebraic closedness in the evolution of mixed moments of the observables.\nAlthough such a system is nonlinear and its quantum state is no longer\nGaussian, the dynamics of the moments of any order are amenable to exact\nanalysis, including the computation of their steady-state values. In\nparticular, a generalized criterion is developed for quadratic stability of the\nquasilinear systems. The results of the paper are applicable to the generation\nof non-Gaussian quantum states with manageable moments and an optimal design of\nlinear quantum controllers for quasilinear quantum plants. \n\n"}
{"id": "1206.0338", "contents": "Title: Poisson noise reduction with non-local PCA Abstract: Photon-limited imaging arises when the number of photons collected by a\nsensor array is small relative to the number of detector elements. Photon\nlimitations are an important concern for many applications such as spectral\nimaging, night vision, nuclear medicine, and astronomy. Typically a Poisson\ndistribution is used to model these observations, and the inherent\nheteroscedasticity of the data combined with standard noise removal methods\nyields significant artifacts. This paper introduces a novel denoising algorithm\nfor photon-limited images which combines elements of dictionary learning and\nsparse patch-based representations of images. The method employs both an\nadaptation of Principal Component Analysis (PCA) for Poisson noise and recently\ndeveloped sparsity-regularized convex optimization algorithms for\nphoton-limited images. A comprehensive empirical evaluation of the proposed\nmethod helps characterize the performance of this approach relative to other\nstate-of-the-art denoising methods. The results reveal that, despite its\nconceptual simplicity, Poisson PCA-based denoising appears to be highly\ncompetitive in very low light regimes. \n\n"}
{"id": "1206.3781", "contents": "Title: Reduction of Stokes-Dirac structures and gauge symmetry in\n  port-Hamiltonian systems Abstract: Stokes-Dirac structures are infinite-dimensional Dirac structures defined in\nterms of differential forms on a smooth manifold with boundary. These Dirac\nstructures lay down a geometric framework for the formulation of Hamiltonian\nsystems with a nonzero boundary energy flow. Simplicial triangulation of the\nunderlaying manifold leads to the so-called simplicial Dirac structures,\ndiscrete analogues of Stokes-Dirac structures, and thus provides a natural\nframework for deriving finite-dimensional port-Hamiltonian systems that emulate\ntheir infinite-dimensional counterparts. The port-Hamiltonian systems defined\nwith respect to Stokes-Dirac and simplicial Dirac structures exhibit gauge and\na discrete gauge symmetry, respectively. In this paper, employing Poisson\nreduction we offer a unified technique for the symmetry reduction of a\ngeneralized canonical infinite-dimensional Dirac structure to the Poisson\nstructure associated with Stokes-Dirac structures and of a fine-dimensional\nDirac structure to simplicial Dirac structures. We demonstrate this Poisson\nscheme on a physical example of the vibrating string. \n\n"}
{"id": "1207.2515", "contents": "Title: Incentive Design for Efficient Building Quality of Service Abstract: Buildings are a large consumer of energy, and reducing their energy usage may\nprovide financial and societal benefits. One challenge in achieving efficient\nbuilding operation is the fact that few financial motivations exist for\nencouraging low energy configuration and operation of buildings. As a result,\nincentive schemes for managers of large buildings are being proposed for the\npurpose of saving energy. This paper focuses on incentive design for the\nconfiguration and operation of building-wide heating, ventilation, and\nair-conditioning (HVAC) systems, because these systems constitute the largest\nportion of energy usage in most buildings. We begin with an empirical model of\na building-wide HVAC system, which describes the tradeoffs between energy\nconsumption, quality of service (as defined by occupant satisfaction), and the\namount of work required for maintenance and configuration. The model has\nsignificant non-convexities, and so we derive some results regarding\nqualitative properties of non-convex optimization problems with certain\npartial-ordering features. These results are used to show that \"baselining\"\nincentive schemes suffer from moral hazard problems, and they also encourage\nenergy reductions at the expense of also decreasing occupant satisfaction. We\npropose an alternative incentive scheme that has the interpretation of a\nperformance-based bonus. A theoretical analysis shows that this encourages\nenergy and monetary savings and modest gains in occupant satisfaction and\nquality of service, which is confirmed by our numerical simulations. \n\n"}
{"id": "1207.4747", "contents": "Title: Block-Coordinate Frank-Wolfe Optimization for Structural SVMs Abstract: We propose a randomized block-coordinate variant of the classic Frank-Wolfe\nalgorithm for convex optimization with block-separable constraints. Despite its\nlower iteration cost, we show that it achieves a similar convergence rate in\nduality gap as the full Frank-Wolfe algorithm. We also show that, when applied\nto the dual structural support vector machine (SVM) objective, this yields an\nonline algorithm that has the same low iteration complexity as primal\nstochastic subgradient methods. However, unlike stochastic subgradient methods,\nthe block-coordinate Frank-Wolfe algorithm allows us to compute the optimal\nstep-size and yields a computable duality gap guarantee. Our experiments\nindicate that this simple algorithm outperforms competing structural SVM\nsolvers. \n\n"}
{"id": "1208.3549", "contents": "Title: Explicit Simplicial Discretization of Distributed-Parameter\n  Port-Hamiltonian Systems Abstract: Simplicial Dirac structures as finite analogues of the canonical Stokes-Dirac\nstructure, capturing the topological laws of the system, are defined on\nsimplicial manifolds in terms of primal and dual cochains related by the\ncoboundary operators. These finite-dimensional Dirac structures offer a\nframework for the formulation of standard input-output finite-dimensional\nport-Hamiltonian systems that emulate the behavior of distributed-parameter\nport-Hamiltonian systems. This paper elaborates on the matrix representations\nof simplicial Dirac structures and the resulting port-Hamiltonian systems on\nsimplicial manifolds. Employing these representations, we consider the\nexistence of structural invariants and demonstrate how they pertain to the\nenergy shaping of port-Hamiltonian systems on simplicial manifolds. \n\n"}
{"id": "1208.5600", "contents": "Title: A population Monte Carlo scheme with transformed weights and its\n  application to stochastic kinetic models Abstract: This paper addresses the problem of Monte Carlo approximation of posterior\nprobability distributions. In particular, we have considered a recently\nproposed technique known as population Monte Carlo (PMC), which is based on an\niterative importance sampling approach. An important drawback of this\nmethodology is the degeneracy of the importance weights when the dimension of\neither the observations or the variables of interest is high. To alleviate this\ndifficulty, we propose a novel method that performs a nonlinear transformation\non the importance weights. This operation reduces the weight variation, hence\nit avoids their degeneracy and increases the efficiency of the importance\nsampling scheme, specially when drawing from a proposal functions which are\npoorly adapted to the true posterior.\n  For the sake of illustration, we have applied the proposed algorithm to the\nestimation of the parameters of a Gaussian mixture model. This is a very simple\nproblem that enables us to clearly show and discuss the main features of the\nproposed technique. As a practical application, we have also considered the\npopular (and challenging) problem of estimating the rate parameters of\nstochastic kinetic models (SKM). SKMs are highly multivariate systems that\nmodel molecular interactions in biological and chemical problems. We introduce\na particularization of the proposed algorithm to SKMs and present numerical\nresults. \n\n"}
{"id": "1209.2388", "contents": "Title: On the Complexity of Bandit and Derivative-Free Stochastic Convex\n  Optimization Abstract: The problem of stochastic convex optimization with bandit feedback (in the\nlearning community) or without knowledge of gradients (in the optimization\ncommunity) has received much attention in recent years, in the form of\nalgorithms and performance upper bounds. However, much less is known about the\ninherent complexity of these problems, and there are few lower bounds in the\nliterature, especially for nonlinear functions. In this paper, we investigate\nthe attainable error/regret in the bandit and derivative-free settings, as a\nfunction of the dimension d and the available number of queries T. We provide a\nprecise characterization of the attainable performance for strongly-convex and\nsmooth functions, which also imply a non-trivial lower bound for more general\nproblems. Moreover, we prove that in both the bandit and derivative-free\nsetting, the required number of queries must scale at least quadratically with\nthe dimension. Finally, we show that on the natural class of quadratic\nfunctions, it is possible to obtain a \"fast\" O(1/T) error rate in terms of T,\nunder mild assumptions, even without having access to gradients. To the best of\nour knowledge, this is the first such rate in a derivative-free stochastic\nsetting, and holds despite previous results which seem to imply the contrary. \n\n"}
{"id": "1209.4199", "contents": "Title: Discrete State Transition Algorithm for Unconstrained Integer\n  Optimization Problems Abstract: A recently new intelligent optimization algorithm called discrete state\ntransition algorithm is considered in this study, for solving unconstrained\ninteger optimization problems. Firstly, some key elements for discrete state\ntransition algorithm are summarized to guide its well development. Several\nintelligent operators are designed for local exploitation and global\nexploration. Then, a dynamic adjustment strategy ``risk and restoration in\nprobability\" is proposed to capture global solutions with high probability.\nFinally, numerical experiments are carried out to test the performance of the\nproposed algorithm compared with other heuristics, and they show that the\nsimilar intelligent operators can be applied to ranging from traveling salesman\nproblem, boolean integer programming, to discrete value selection problem,\nwhich indicates the adaptability and flexibility of the proposed intelligent\nelements. \n\n"}
{"id": "1209.5684", "contents": "Title: \\epsilon-Nash Mean Field Game Theory for Nonlinear Stochastic Dynamical\n  Systems with Major and Minor Agents Abstract: This paper studies a large population dynamic game involving nonlinear\nstochastic dynamical systems with agents of the following mixed types: (i) a\nmajor agent, and (ii) a population of $N$ minor agents where $N$ is very large.\nThe major and minor (MM) agents are coupled via both: (i) their individual\nnonlinear stochastic dynamics, and (ii) their individual finite time horizon\nnonlinear cost functions. This problem is approached by the so-called\n$\\epsilon$-Nash Mean Field Game ($\\epsilon$-NMFG) theory. A distinct feature of\nthe mixed agent MFG problem is that even asymptotically (as the population size\n$N$ approaches infinity) the noise process of the major agent causes random\nfluctuation of the mean field behaviour of the minor agents. To deal with this,\nthe overall asymptotic ($N \\rightarrow \\infty$) mean field game problem is\ndecomposed into: (i) two non-standard stochastic optimal control problems with\nrandom coefficient processes which yield forward adapted stochastic best\nresponse control processes determined from the solution of (backward in time)\nstochastic Hamilton-Jacobi-Bellman (SHJB) equations, and (ii) two stochastic\ncoefficient McKean-Vlasov (SMV) equations which characterize the state of the\nmajor agent and the measure determining the mean field behaviour of the minor\nagents. Existence and uniqueness of the solution to the Stochastic Mean Field\nGame (SMFG) system (SHJB and SMV equations) is established by a fixed point\nargument in the Wasserstein space of random probability measures. In the case\nthat minor agents are coupled to the major agent only through their cost\nfunctions, the $\\epsilon_N$-Nash equilibrium property of the SMFG best\nresponses is shown for a finite $N$ population system where\n$\\epsilon_N=O(1/\\sqrt N)$. \n\n"}
{"id": "1210.0056", "contents": "Title: Convergence and Applications of a Gossip-based Gauss-Newton Algorithm Abstract: The Gauss-Newton algorithm is a popular and efficient centralized method for\nsolving non-linear least squares problems. In this paper, we propose a\nmulti-agent distributed version of this algorithm, named Gossip-based\nGauss-Newton (GGN) algorithm, which can be applied in general problems with\nnon-convex objectives. Furthermore, we analyze and present sufficient\nconditions for its convergence and show numerically that the GGN algorithm\nachieves performance comparable to the centralized algorithm, with graceful\ndegradation in case of network failures. More importantly, the GGN algorithm\nprovides significant performance gains compared to other distributed first\norder methods. \n\n"}
{"id": "1210.5225", "contents": "Title: On two relaxations of quadratically-constrained cardinality minimization Abstract: This paper considers a quadratically-constrained cardinality minimization\nproblem with applications to digital filter design, subset selection for linear\nregression, and portfolio selection. Two relaxations are investigated: the\ncontinuous relaxation of a mixed integer formulation, and an optimized diagonal\nrelaxation that exploits a simple special case of the problem. For the\ncontinuous relaxation, an absolute upper bound on the optimal cost is derived,\nsuggesting that the continuous relaxation tends to be a relatively poor\napproximation. In computational experiments, diagonal relaxations often provide\nstronger bounds than continuous relaxations and can greatly reduce the\ncomplexity of a branch-and-bound solution, even in instances that are not\nparticularly close to diagonal. Similar gains are observed with respect to the\nmixed integer programming solver CPLEX. Motivated by these results, the\napproximation properties of the diagonal relaxation are analyzed. In\nparticular, bounds on the approximation ratio are established in terms of the\neigenvalues of the matrix defining the quadratic constraint, and also in the\ndiagonally dominant and nearly coordinate-aligned cases. \n\n"}
{"id": "1210.6280", "contents": "Title: On the convergence of the affine hull of the Chv\\'atal-Gomory closures Abstract: Given an integral polyhedron P and a rational polyhedron Q living in the same\nn-dimensional space and containing the same integer points as P, we investigate\nhow many iterations of the Chv\\'atal-Gomory closure operator have to be\nperformed on Q to obtain a polyhedron contained in the affine hull of P. We\nshow that if P contains an integer point in its relative interior, then such a\nnumber of iterations can be bounded by a function depending only on n. On the\nother hand, we prove that if P is not full-dimensional and does not contain any\ninteger point in its relative interior, then no finite bound on the number of\niterations exists. \n\n"}
{"id": "1210.7070", "contents": "Title: A Multiscale Framework for Challenging Discrete Optimization Abstract: Current state-of-the-art discrete optimization methods struggle behind when\nit comes to challenging contrast-enhancing discrete energies (i.e., favoring\ndifferent labels for neighboring variables). This work suggests a multiscale\napproach for these challenging problems. Deriving an algebraic representation\nallows us to coarsen any pair-wise energy using any interpolation in a\nprincipled algebraic manner. Furthermore, we propose an energy-aware\ninterpolation operator that efficiently exposes the multiscale landscape of the\nenergy yielding an effective coarse-to-fine optimization scheme. Results on\nchallenging contrast-enhancing energies show significant improvement over\nstate-of-the-art methods. \n\n"}
{"id": "1210.7362", "contents": "Title: Discrete Energy Minimization, beyond Submodularity: Applications and\n  Approximations Abstract: In this thesis I explore challenging discrete energy minimization problems\nthat arise mainly in the context of computer vision tasks. This work motivates\nthe use of such \"hard-to-optimize\" non-submodular functionals, and proposes\nmethods and algorithms to cope with the NP-hardness of their optimization.\nConsequently, this thesis revolves around two axes: applications and\napproximations. The applications axis motivates the use of such\n\"hard-to-optimize\" energies by introducing new tasks. As the energies become\nless constrained and structured one gains more expressive power for the\nobjective function achieving more accurate models. Results show how\nchallenging, hard-to-optimize, energies are more adequate for certain computer\nvision applications. To overcome the resulting challenging optimization tasks\nthe second axis of this thesis proposes approximation algorithms to cope with\nthe NP-hardness of the optimization. Experiments show that these new methods\nyield good results for representative challenging problems. \n\n"}
{"id": "1211.2365", "contents": "Title: Discrete Dubins Paths Abstract: A Dubins path is a shortest path with bounded curvature. The seminal result\nin non-holonomic motion planning is that (in the absence of obstacles) a Dubins\npath consists either from a circular arc followed by a segment followed by\nanother arc, or from three circular arcs [Dubins, 1957]. Dubins original proof\nuses advanced calculus; later, Dubins result was reproved using control theory\ntechniques [Reeds and Shepp, 1990], [Sussmann and Tang, 1991], [Boissonnat,\nC\\'er\\'ezo, and Leblond, 1994].\n  We introduce and study a discrete analogue of curvature-constrained motion.\nWe show that shortest \"bounded-curvature\" polygonal paths have the same\nstructure as Dubins paths. The properties of Dubins paths follow from our\nresults as a limiting case---this gives a new, \"discrete\" proof of Dubins\nresult. \n\n"}
{"id": "1211.3831", "contents": "Title: Objective Improvement in Information-Geometric Optimization Abstract: Information-Geometric Optimization (IGO) is a unified framework of stochastic\nalgorithms for optimization problems. Given a family of probability\ndistributions, IGO turns the original optimization problem into a new\nmaximization problem on the parameter space of the probability distributions.\nIGO updates the parameter of the probability distribution along the natural\ngradient, taken with respect to the Fisher metric on the parameter manifold,\naiming at maximizing an adaptive transform of the objective function. IGO\nrecovers several known algorithms as particular instances: for the family of\nBernoulli distributions IGO recovers PBIL, for the family of Gaussian\ndistributions the pure rank-mu CMA-ES update is recovered, and for exponential\nfamilies in expectation parametrization the cross-entropy/ML method is\nrecovered. This article provides a theoretical justification for the IGO\nframework, by proving that any step size not greater than 1 guarantees monotone\nimprovement over the course of optimization, in terms of q-quantile values of\nthe objective function f. The range of admissible step sizes is independent of\nf and its domain. We extend the result to cover the case of different step\nsizes for blocks of the parameters in the IGO algorithm. Moreover, we prove\nthat expected fitness improves over time when fitness-proportional selection is\napplied, in which case the RPP algorithm is recovered. \n\n"}
{"id": "1211.6302", "contents": "Title: Duality between subgradient and conditional gradient methods Abstract: Given a convex optimization problem and its dual, there are many possible\nfirst-order algorithms. In this paper, we show the equivalence between mirror\ndescent algorithms and algorithms generalizing the conditional gradient method.\nThis is done through convex duality, and implies notably that for certain\nproblems, such as for supervised machine learning problems with non-smooth\nlosses or problems regularized by non-smooth regularizers, the primal\nsubgradient method and the dual conditional gradient method are formally\nequivalent. The dual interpretation leads to a form of line search for mirror\ndescent, as well as guarantees of convergence for primal-dual certificates. \n\n"}
{"id": "1212.0122", "contents": "Title: Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm Abstract: Markov Chain Monte Carlo methods are widely used in signal processing and\ncommunications for statistical inference and stochastic optimization. In this\nwork, we introduce an efficient adaptive Metropolis-Hastings algorithm to draw\nsamples from generic multi-modal and multi-dimensional target distributions.\nThe proposal density is a mixture of Gaussian densities with all parameters\n(weights, mean vectors and covariance matrices) updated using all the\npreviously generated samples applying simple recursive rules. Numerical results\nfor the one and two-dimensional cases are provided. \n\n"}
{"id": "1212.0912", "contents": "Title: Sparse seismic imaging using variable projection Abstract: We consider an important class of signal processing problems where the signal\nof interest is known to be sparse, and can be recovered from data given\nauxiliary information about how the data was generated. For example, a sparse\nGreen's function may be recovered from seismic experimental data using sparsity\noptimization when the source signature is known. Unfortunately, in practice\nthis information is often missing, and must be recovered from data along with\nthe signal using deconvolution techniques.\n  In this paper, we present a novel methodology to simultaneously solve for the\nsparse signal and auxiliary parameters using a recently proposed variable\nprojection technique. Our main contribution is to combine variable projection\nwith sparsity promoting optimization, obtaining an efficient algorithm for\nlarge-scale sparse deconvolution problems. We demonstrate the algorithm on a\nseismic imaging example. \n\n"}
{"id": "1212.1788", "contents": "Title: Approximate discrete-time schemes for the estimation of diffusion\n  processes from complete observations Abstract: In this paper, a modification of the conventional approximations to the\nquasi-maximum likelihood method is introduced for the parameter estimation of\ndiffusion processes from discrete observations. This is based on a convergent\napproximation to the first two conditional moments of the diffusion process\nthrough discrete-time schemes. It is shown that, for finite samples, the\nresulting approximate estimators converge to the quasi-maximum likelihood one\nwhen the error between the discrete-time approximation and the diffusion\nprocess decreases. For an increasing number of observations, the approximate\nestimators are asymptotically normal distributed and their bias decreases when\nthe mentioned error does it. A simulation study is provided to illustrate the\nperformance of the new estimators. The results show that, with respect to the\nconventional approximate estimators, the new ones significantly enhance the\nparameter estimation of the test equations. The proposed estimators are\nintended for the recurrent practical situation where a nonlinear stochastic\nsystem should be identified from a reduced number of complete observations\ndistant in time. \n\n"}
{"id": "1212.1824", "contents": "Title: Stochastic Gradient Descent for Non-smooth Optimization: Convergence\n  Results and Optimal Averaging Schemes Abstract: Stochastic Gradient Descent (SGD) is one of the simplest and most popular\nstochastic optimization methods. While it has already been theoretically\nstudied for decades, the classical analysis usually required non-trivial\nsmoothness assumptions, which do not apply to many modern applications of SGD\nwith non-smooth objective functions such as support vector machines. In this\npaper, we investigate the performance of SGD without such smoothness\nassumptions, as well as a running average scheme to convert the SGD iterates to\na solution with optimal optimization accuracy. In this framework, we prove that\nafter T rounds, the suboptimality of the last SGD iterate scales as\nO(log(T)/\\sqrt{T}) for non-smooth convex objective functions, and O(log(T)/T)\nin the non-smooth strongly convex case. To the best of our knowledge, these are\nthe first bounds of this kind, and almost match the minimax-optimal rates\nobtainable by appropriate averaging schemes. We also propose a new and simple\naveraging scheme, which not only attains optimal rates, but can also be easily\ncomputed on-the-fly (in contrast, the suffix averaging scheme proposed in\nRakhlin et al. (2011) is not as simple to implement). Finally, we provide some\nexperimental illustrations. \n\n"}
{"id": "1212.1862", "contents": "Title: On the response of quantum linear systems to single photon input fields Abstract: The purpose of this paper is to extend linear systems and signals theory to\ninclude single photon quantum signals. We provide detailed results describing\nhow quantum linear systems respond to multichannel single photon quantum\nsignals. In particular, we characterize the class of states (which we call {\\em\nphoton-Gaussian} states) that result when multichannel photons are input to a\nquantum linear system. We show that this class of quantum states is preserved\nby quantum linear systems. Multichannel photon-Gaussian states are defined via\nthe action of certain creation and annihilation operators on Gaussian states.\nOur results show how the output states are determined from the input states\nthrough a pair of transfer function relations. We also provide equations from\nwhich output signal intensities can be computed. Examples from quantum optics\nare provided to illustrate the results. \n\n"}
{"id": "1212.2002", "contents": "Title: A simpler approach to obtaining an O(1/t) convergence rate for the\n  projected stochastic subgradient method Abstract: In this note, we present a new averaging technique for the projected\nstochastic subgradient method. By using a weighted average with a weight of t+1\nfor each iterate w_t at iteration t, we obtain the convergence rate of O(1/t)\nwith both an easy proof and an easy implementation. The new scheme is compared\nempirically to existing techniques, with similar performance behavior. \n\n"}
{"id": "1212.2243", "contents": "Title: On the construction of 1-dimensional MDS convolutional Goppa codes Abstract: We show that the free distance, as a function on a space parameterizing a\nfamily of convolutional codes, is a lower-semicontinuous function and that,\ntherefore, the property of being Maximum Distance Separable (MDS) is an open\ncondition. For a class of convolutional codes, an algorithm is offered to\ncompute the free distance. The behaviour of the free distance by enlargements\nof the alphabet and by increasing the length is also studied. As an\napplication, the algebraic equations characterizing the subfamily of MDS codes\nis explicitly computed for families of 1-dimensional convolutional Goppa codes\n(CGC). \n\n"}
{"id": "1212.2834", "contents": "Title: Dictionary Subselection Using an Overcomplete Joint Sparsity Model Abstract: Many natural signals exhibit a sparse representation, whenever a suitable\ndescribing model is given. Here, a linear generative model is considered, where\nmany sparsity-based signal processing techniques rely on such a simplified\nmodel. As this model is often unknown for many classes of the signals, we need\nto select such a model based on the domain knowledge or using some exemplar\nsignals. This paper presents a new exemplar based approach for the linear model\n(called the dictionary) selection, for such sparse inverse problems. The\nproblem of dictionary selection, which has also been called the dictionary\nlearning in this setting, is first reformulated as a joint sparsity model. The\njoint sparsity model here differs from the standard joint sparsity model as it\nconsiders an overcompleteness in the representation of each signal, within the\nrange of selected subspaces. The new dictionary selection paradigm is examined\nwith some synthetic and realistic simulations. \n\n"}
{"id": "1212.3696", "contents": "Title: A Stochastic Kaczmarz Algorithm for Network Tomography Abstract: We develop a stochastic approximation version of the classical Kaczmarz\nalgorithm that is incremental in nature and takes as input noisy real time\ndata. Our analysis shows that with probability one it mimics the behavior of\nthe original scheme: starting from the same initial point, our algorithm and\nthe corresponding deterministic Kaczmarz algorithm converge to precisely the\nsame point. The motivation for this work comes from network tomography where\nnetwork parameters are to be estimated based upon end-to-end measurements.\nNumerical examples via Matlab based simulations demonstrate the efficacy of the\nalgorithm. \n\n"}
{"id": "1301.0154", "contents": "Title: Completely monotonic degree of a function involving the tri- and\n  tetra-gamma functions Abstract: Let $\\psi(x)$ be the di-gamma function, the logarithmic derivative of the\nclassical Euler's gamma function $\\Gamma(x)$. In the paper, the author shows\nthat the completely monotonic degree of the function $[\\psi'(x)]^2+\\psi''(x)$\nis $4$, surveys the history and motivation of the topic, supplies a proof for\nthe claim that a function $f(x)$ is strongly completely monotonic if and only\nif the function $xf(x)$ is completely monotonic, conjectures the completely\nmonotonic degree of a function involving $[\\psi'(x)]^2+\\psi''(x)$, presents the\nlogarithmic concavity and monotonicity of an elementary function, and poses an\nopen problem on convolution of logarithmically concave functions. \n\n"}
{"id": "1301.0465", "contents": "Title: An Optimal Affine Invariant Smooth Minimization Algorithm Abstract: We formulate an affine invariant implementation of the accelerated\nfirst-order algorithm in Nesterov (1983). Its complexity bound is proportional\nto an affine invariant regularity constant defined with respect to the\nMinkowski gauge of the feasible set. We extend these results to more general\nproblems, optimizing H\\\"older smooth functions using $p$-uniformly convex prox\nterms, and derive an algorithm whose complexity better fits the geometry of the\nfeasible set and adapts to both the best H\\\"older smoothness parameter and the\nbest gradient Lipschitz constant. Finally, we detail matching complexity lower\nbounds when the feasible set is an $\\ell_p$ ball. In this setting, our upper\nbounds on iteration complexity for the algorithm in Nesterov (1983) are thus\noptimal in terms of target precision, smoothness and problem dimension. \n\n"}
{"id": "1301.1082", "contents": "Title: On the Hybrid Minimum Principle On Lie Groups and the Exponential\n  Gradient HMP Algorithm Abstract: This paper provides a geometrical derivation of the Hybrid Minimum Principle\n(HMP) for autonomous hybrid systems whose state manifolds constitute Lie groups\n$(G,\\star)$ which are left invariant under the controlled dynamics of the\nsystem, and whose switching manifolds are defined as smooth embedded time\ninvariant submanifolds of $G$. The analysis is expressed in terms of extremal\n(i.e. optimal) trajectories on the cotangent bundle of the state manifold $G$.\nThe Hybrid Maximum Principle (HMP) algorithm introduced in \\cite{Shaikh} is\nextended to the so-called Exponential Gradient algorithm. The convergence\nanalysis for the algorithm is based upon the LaSalle Invariance Principle and\nsimulation results illustrate their efficacy. \n\n"}
{"id": "1301.4587", "contents": "Title: Consensus Networks over Finite Fields Abstract: This work studies consensus strategies for networks of agents with limited\nmemory, computation, and communication capabilities. We assume that agents can\nprocess only values from a finite alphabet, and we adopt the framework of\nfinite fields, where the alphabet consists of the integers {0,...,p-1}, for\nsome prime number p, and operations are performed modulo p. Thus, we define a\nnew class of consensus dynamics, which can be exploited in certain applications\nsuch as pose estimation in capacity and memory constrained sensor networks. For\nconsensus networks over finite fields, we provide necessary and sufficient\nconditions on the network topology and weights to ensure convergence. We show\nthat consensus networks over finite fields converge in finite time, a feature\nthat can be hardly achieved over the field of real numbers. For the design of\nfinite-field consensus networks, we propose a general design method, with high\ncomputational complexity, and a network composition rule to generate large\nconsensus networks from smaller components. Finally, we discuss the application\nof finite-field consensus networks to distributed averaging and pose estimation\nin sensor networks. \n\n"}
{"id": "1301.4777", "contents": "Title: Contraction of Riccati flows applied to the convergence analysis of a\n  max-plus curse of dimensionality free method Abstract: Max-plus based methods have been recently explored for solution of\nfirst-order Hamilton-Jacobi-Bellman equations by several authors. In\nparticular, McEneaney's curse-of-dimensionality free method applies to the\nequations where the Hamiltonian takes the form of a (pointwise) maximum of\nlinear/quadratic forms.\n  In previous works of McEneaney and Kluberg, the approximation error of the\nmethod was shown to be $O(1/(N\\tau))+O(\\sqrt{\\tau})$ where $\\tau$ is the time\ndiscretization step and $N$ is the number of iterations. Here we use a recently\nestablished contraction result for the indefinite Riccati flow in Thompson's\nmetric to show that under different technical assumptions, still covering an\nimportant class of problems, the error is only of order $O(e^{-\\alpha\nN\\tau})+O(\\tau)$. This also allows us to obtain improved estimates of the\nexecution time and to tune the precision of the pruning procedure, which in\npractice is a critical element of the method. \n\n"}
{"id": "1302.4385", "contents": "Title: Robust Near-Separable Nonnegative Matrix Factorization Using Linear\n  Optimization Abstract: Nonnegative matrix factorization (NMF) has been shown recently to be\ntractable under the separability assumption, under which all the columns of the\ninput data matrix belong to the convex cone generated by only a few of these\ncolumns. Bittorf, Recht, R\\'e and Tropp (`Factoring nonnegative matrices with\nlinear programs', NIPS 2012) proposed a linear programming (LP) model, referred\nto as Hottopixx, which is robust under any small perturbation of the input\nmatrix. However, Hottopixx has two important drawbacks: (i) the input matrix\nhas to be normalized, and (ii) the factorization rank has to be known in\nadvance. In this paper, we generalize Hottopixx in order to resolve these two\ndrawbacks, that is, we propose a new LP model which does not require\nnormalization and detects the factorization rank automatically. Moreover, the\nnew LP model is more flexible, significantly more tolerant to noise, and can\neasily be adapted to handle outliers and other noise models. Finally, we show\non several synthetic datasets that it outperforms Hottopixx while competing\nfavorably with two state-of-the-art methods. \n\n"}
{"id": "1303.1988", "contents": "Title: Optimal switching control design for polynomial systems: an LMI approach Abstract: We propose a new LMI approach to the design of optimal switching sequences\nfor polynomial dynamical systems with state constraints. We formulate the\nswitching design problem as an optimal control problem which is then relaxed to\na linear programming (LP) problem in the space of occupation measures. This\ninfinite-dimensional LP can be solved numerically and approximately with a\nhierarchy of convex finite-dimensional LMIs. In contrast with most of the\nexisting work on LMI methods, we have a guarantee of global optimality, in the\nsense that we obtain an asympotically converging (i.e. with vanishing\nconservatism) hierarchy of lower bounds on the achievable performance. We also\nexplain how to construct an almost optimal switching sequence. \n\n"}
{"id": "1303.3320", "contents": "Title: On the preservation of commutation and anticommutation relations of\n  N-level quantum systems Abstract: The goal of this paper is to provide conditions under which a quantum\nstochastic differential equation (QSDE) preserves the commutation and\nanticommutation relations of the SU(n) algebra, and thus describes the\nevolution of an open n-level quantum system. One of the challenges in the\napproach lies in the handling of the so-called anomaly coefficients of SU(n).\nThen, it is shown that the physical realizability conditions recently developed\nby the authors for open n-level quantum systems also imply preservation of\ncommutation and anticommutation relations. \n\n"}
{"id": "1303.5457", "contents": "Title: Explicit solution of a tropical optimization problem with application to\n  project scheduling Abstract: A new multidimensional optimization problem is considered in the tropical\nmathematics setting. The problem is to minimize a nonlinear function defined on\na finite-dimensional semimodule over an idempotent semifield and given by a\nconjugate transposition operator. A special case of the problem, which arises\nin just-in-time scheduling, serves as a motivation for the study. To solve the\ngeneral problem, we derive a sharp lower bound for the objective function and\nthen find vectors that yield the bound. Under general conditions, an explicit\nsolution is obtained in a compact vector form. This result is applied to\nprovide new solutions for scheduling problems under consideration. To\nillustrate, numerical examples are also presented. \n\n"}
{"id": "1304.0004", "contents": "Title: Linear under-determined systems with sparse solutions: Redirecting a\n  challenge? Abstract: Seminal works \\cite{CRT,DonohoUnsigned,DonohoPol} generated a massive\ninterest in studying linear under-determined systems with sparse solutions. In\nthis paper we give a short mathematical overview of what was accomplished in\nlast 10 years in a particular direction of such a studying. We then discuss\nwhat we consider were the main challenges in last 10 years and give our own\nview as to what are the main challenges that lie ahead. Through the\npresentation we arrive to a point where the following natural rhetoric question\narises: is it a time to redirect the main challenges? While we can not provide\nthe answer to such a question we hope that our small discussion will stimulate\nfurther considerations in this direction. \n\n"}
{"id": "1304.1014", "contents": "Title: A Novel Frank-Wolfe Algorithm. Analysis and Applications to Large-Scale\n  SVM Training Abstract: Recently, there has been a renewed interest in the machine learning community\nfor variants of a sparse greedy approximation procedure for concave\noptimization known as {the Frank-Wolfe (FW) method}. In particular, this\nprocedure has been successfully applied to train large-scale instances of\nnon-linear Support Vector Machines (SVMs). Specializing FW to SVM training has\nallowed to obtain efficient algorithms but also important theoretical results,\nincluding convergence analysis of training algorithms and new characterizations\nof model sparsity.\n  In this paper, we present and analyze a novel variant of the FW method based\non a new way to perform away steps, a classic strategy used to accelerate the\nconvergence of the basic FW procedure. Our formulation and analysis is focused\non a general concave maximization problem on the simplex. However, the\nspecialization of our algorithm to quadratic forms is strongly related to some\nclassic methods in computational geometry, namely the Gilbert and MDM\nalgorithms.\n  On the theoretical side, we demonstrate that the method matches the\nguarantees in terms of convergence rate and number of iterations obtained by\nusing classic away steps. In particular, the method enjoys a linear rate of\nconvergence, a result that has been recently proved for MDM on quadratic forms.\n  On the practical side, we provide experiments on several classification\ndatasets, and evaluate the results using statistical tests. Experiments show\nthat our method is faster than the FW method with classic away steps, and works\nwell even in the cases in which classic away steps slow down the algorithm.\nFurthermore, these improvements are obtained without sacrificing the predictive\naccuracy of the obtained SVM model. \n\n"}
{"id": "1304.2129", "contents": "Title: A gentle introduction to the discrete Laplace method for estimating\n  Y-STR haplotype frequencies Abstract: Y-STR data simulated under a Fisher-Wright model of evolution with a\nsingle-step mutation model turns out to be well predicted by a method using\ndiscrete Laplace distributions. \n\n"}
{"id": "1304.4373", "contents": "Title: Jump-sparse and sparse recovery using Potts functionals Abstract: We recover jump-sparse and sparse signals from blurred incomplete data\ncorrupted by (possibly non-Gaussian) noise using inverse Potts energy\nfunctionals. We obtain analytical results (existence of minimizers, complexity)\non inverse Potts functionals and provide relations to sparsity problems. We\nthen propose a new optimization method for these functionals which is based on\ndynamic programming and the alternating direction method of multipliers (ADMM).\nA series of experiments shows that the proposed method yields very satisfactory\njump-sparse and sparse reconstructions, respectively. We highlight the\ncapability of the method by comparing it with classical and recent approaches\nsuch as TV minimization (jump-sparse signals), orthogonal matching pursuit,\niterative hard thresholding, and iteratively reweighted $\\ell^1$ minimization\n(sparse signals). \n\n"}
{"id": "1304.5530", "contents": "Title: Inexact Coordinate Descent: Complexity and Preconditioning Abstract: In this paper we consider the problem of minimizing a convex function using a\nrandomized block coordinate descent method. One of the key steps at each\niteration of the algorithm is determining the update to a block of variables.\nExisting algorithms assume that in order to compute the update, a particular\nsubproblem is solved exactly. In his work we relax this requirement, and allow\nfor the subproblem to be solved inexactly, leading to an inexact block\ncoordinate descent method. Our approach incorporates the best known results for\nexact updates as a special case. Moreover, these theoretical guarantees are\ncomplemented by practical considerations: the use of iterative techniques to\ndetermine the update as well as the use of preconditioning for further\nacceleration. \n\n"}
{"id": "1304.5620", "contents": "Title: Isomorphic Strategy Spaces in Game Theory Abstract: This book summarizes ongoing research introducing probability space\nisomorphic mappings into the strategy spaces of game theory. This approach is\nmotivated by discrepancies between probability theory and game theory when\napplied to the same strategic situation. In particular, probability theory and\ngame theory can disagree on calculated values of the Fisher information, the\nlog likelihood function, entropy gradients, the rank and Jacobian of variable\ntransforms, and even the dimensionality and volume of the underlying\nprobability parameter spaces. These differences arise as probability theory\nemploys structure preserving isomorphic mappings when constructing strategy\nspaces to analyze games. In contrast, game theory uses weaker mappings which\nchange some of the properties of the underlying probability distributions\nwithin the mixed strategy space. Here, we explore how using strong isomorphic\nmappings to define game strategy spaces can alter rational outcomes in simple\ngames . Specific example games considered are the chain store paradox, the\ntrust game, the ultimatum game, the public goods game, the centipede game, and\nthe iterated prisoner's dilemma. In general, our approach provides rational\noutcomes which are consistent with observed human play and might thereby\nresolve some of the paradoxes of game theory. \n\n"}
{"id": "1304.7735", "contents": "Title: Phase retrieval for imaging problems Abstract: We study convex relaxation algorithms for phase retrieval on imaging\nproblems. We show that structural assumptions on the signal and the\nobservations, such as sparsity, smoothness or positivity, can be exploited to\nboth speed-up convergence and improve recovery performance. We detail\nexperimental results in molecular imaging problems simulated from PDB data. \n\n"}
{"id": "1305.2524", "contents": "Title: Corrupted Sensing: Novel Guarantees for Separating Structured Signals Abstract: We study the problem of corrupted sensing, a generalization of compressed\nsensing in which one aims to recover a signal from a collection of corrupted or\nunreliable measurements. While an arbitrary signal cannot be recovered in the\nface of arbitrary corruption, tractable recovery is possible when both signal\nand corruption are suitably structured. We quantify the relationship between\nsignal recovery and two geometric measures of structure, the Gaussian\ncomplexity of a tangent cone and the Gaussian distance to a subdifferential. We\ntake a convex programming approach to disentangling signal and corruption,\nanalyzing both penalized programs that trade off between signal and corruption\ncomplexity, and constrained programs that bound the complexity of signal or\ncorruption when prior information is available. In each case, we provide\nconditions for exact signal recovery from structured corruption and stable\nsignal recovery from structured corruption with added unstructured noise. Our\nsimulations demonstrate close agreement between our theoretical recovery bounds\nand the sharp phase transitions observed in practice. In addition, we provide\nnew interpretable bounds for the Gaussian complexity of sparse vectors,\nblock-sparse vectors, and low-rank matrices, which lead to sharper guarantees\nof recovery when combined with our results and those in the literature. \n\n"}
{"id": "1305.4952", "contents": "Title: A Statistical Learning Theory Approach for Uncertain Linear and Bilinear\n  Matrix Inequalities Abstract: In this paper, we consider the problem of minimizing a linear functional\nsubject to uncertain linear and bilinear matrix inequalities, which depend in a\npossibly nonlinear way on a vector of uncertain parameters. Motivated by recent\nresults in statistical learning theory, we show that probabilistic guaranteed\nsolutions can be obtained by means of randomized algorithms. In particular, we\nshow that the Vapnik-Chervonenkis dimension (VC-dimension) of the two problems\nis finite, and we compute upper bounds on it. In turn, these bounds allow us to\nderive explicitly the sample complexity of these problems. Using these bounds,\nin the second part of the paper, we derive a sequential scheme, based on a\nsequence of optimization and validation steps. The algorithm is on the same\nlines of recent schemes proposed for similar problems, but improves both in\nterms of complexity and generality. The effectiveness of this approach is shown\nusing a linear model of a robot manipulator subject to uncertain parameters. \n\n"}
{"id": "1305.5879", "contents": "Title: Statistical Significance of Clustering using Soft Thresholding Abstract: Clustering methods have led to a number of important discoveries in\nbioinformatics and beyond. A major challenge in their use is determining which\nclusters represent important underlying structure, as opposed to spurious\nsampling artifacts. This challenge is especially serious, and very few methods\nare available, when the data are very high in dimension. Statistical\nSignificance of Clustering (SigClust) is a recently developed cluster\nevaluation tool for high dimensional low sample size data. An important\ncomponent of the SigClust approach is the very definition of a single cluster\nas a subset of data sampled from a multivariate Gaussian distribution. The\nimplementation of SigClust requires the estimation of the eigenvalues of the\ncovariance matrix for the null multivariate Gaussian distribution. We show that\nthe original eigenvalue estimation can lead to a test that suffers from severe\ninflation of type-I error, in the important case where there are a few very\nlarge eigenvalues. This paper addresses this critical challenge using a novel\nlikelihood based soft thresholding approach to estimate these eigenvalues,\nwhich leads to a much improved SigClust. Major improvements in SigClust\nperformance are shown by both mathematical analysis, based on the new notion of\nTheoretical Cluster Index, and extensive simulation studies. Applications to\nsome cancer genomic data further demonstrate the usefulness of these\nimprovements. \n\n"}
{"id": "1306.0036", "contents": "Title: Optimal Decentralized State-Feedback Control with Sparsity and Delays Abstract: This work presents the solution to a class of decentralized linear quadratic\nstate-feedback control problems, in which the plant and controller must satisfy\nthe same combination of delay and sparsity constraints. Using a novel\ndecomposition of the noise history, the control problem is split into\nindependent subproblems that are solved using dynamic programming. The approach\npresented herein both unifies and generalizes many existing results. \n\n"}
{"id": "1306.0404", "contents": "Title: Iterative Grassmannian Optimization for Robust Image Alignment Abstract: Robust high-dimensional data processing has witnessed an exciting development\nin recent years, as theoretical results have shown that it is possible using\nconvex programming to optimize data fit to a low-rank component plus a sparse\noutlier component. This problem is also known as Robust PCA, and it has found\napplication in many areas of computer vision. In image and video processing and\nface recognition, the opportunity to process massive image databases is\nemerging as people upload photo and video data online in unprecedented volumes.\nHowever, data quality and consistency is not controlled in any way, and the\nmassiveness of the data poses a serious computational challenge. In this paper\nwe present t-GRASTA, or \"Transformed GRASTA (Grassmannian Robust Adaptive\nSubspace Tracking Algorithm)\". t-GRASTA iteratively performs incremental\ngradient descent constrained to the Grassmann manifold of subspaces in order to\nsimultaneously estimate a decomposition of a collection of images into a\nlow-rank subspace, a sparse part of occlusions and foreground objects, and a\ntransformation such as rotation or translation of the image. We show that\nt-GRASTA is 4 $\\times$ faster than state-of-the-art algorithms, has half the\nmemory requirement, and can achieve alignment for face images as well as\njittered camera surveillance images. \n\n"}
{"id": "1306.1129", "contents": "Title: Duality and interval analysis over idempotent semirings Abstract: In this paper semirings with an idempotent addition are considered. These\nalgebraic structures are endowed with a partial order. This allows to consider\nresiduated maps to solve systems of inequalities $A \\otimes X \\preceq B$. The\npurpose of this paper is to consider a dual product, denoted $\\odot$, and the\ndual residuation of matrices, in order to solve the following inequality $ A\n\\otimes X \\preceq X \\preceq B \\odot X$. Sufficient conditions ensuring the\nexistence of a non-linear projector in the solution set are proposed. The\nresults are extended to semirings of intervals. \n\n"}
{"id": "1306.1202", "contents": "Title: A note on QUBO instances defined on Chimera graphs Abstract: McGeoch and Wang (2013) recently obtained optimal or near-optimal solutions\nto some quadratic unconstrained boolean optimization (QUBO) problem instances\nusing a 439 qubit D-Wave Two quantum computing system in much less time than\nwith the IBM ILOG CPLEX mixed-integer quadratic programming (MIQP) solver. The\nproblems studied by McGeoch and Wang are defined on subgraphs -- with up to 439\nnodes -- of Chimera graphs. We observe that after a standard reformulation of\nthe QUBO problem as a mixed-integer linear program (MILP), the specific\ninstances used by McGeoch and Wang can be solved to optimality with the CPLEX\nMILP solver in much less time than the time reported in McGeoch and Wang for\nthe CPLEX MIQP solver. However, the solution time is still more than the time\ntaken by the D-Wave computer in the McGeoch-Wang tests. \n\n"}
{"id": "1306.1875", "contents": "Title: Semidefinite relaxations for semi-infinite polynomial programming Abstract: This paper studies how to solve semi-infinite polynomial programming (SIPP)\nproblems by semidefinite relaxation method. We first introduce two SDP\nrelaxation methods for solving polynomial optimization problems with finitely\nmany constraints. Then we propose an exchange algorithm with SDP relaxations to\nsolve SIPP problems with compact index set. At last, we extend the proposed\nmethod to SIPP problems with noncompact index set via homogenization. Numerical\nresults show that the algorithm is efficient in practice. \n\n"}
{"id": "1306.2665", "contents": "Title: Precisely Verifying the Null Space Conditions in Compressed Sensing: A\n  Sandwiching Algorithm Abstract: In this paper, we propose new efficient algorithms to verify the null space\ncondition in compressed sensing (CS). Given an $(n-m) \\times n$ ($m>0$) CS\nmatrix $A$ and a positive $k$, we are interested in computing $\\displaystyle\n\\alpha_k = \\max_{\\{z: Az=0,z\\neq 0\\}}\\max_{\\{K: |K|\\leq k\\}}$ ${\\|z_K\n\\|_{1}}{\\|z\\|_{1}}$, where $K$ represents subsets of $\\{1,2,...,n\\}$, and $|K|$\nis the cardinality of $K$. In particular, we are interested in finding the\nmaximum $k$ such that $\\alpha_k < {1}{2}$. However, computing $\\alpha_k$ is\nknown to be extremely challenging. In this paper, we first propose a series of\nnew polynomial-time algorithms to compute upper bounds on $\\alpha_k$. Based on\nthese new polynomial-time algorithms, we further design a new sandwiching\nalgorithm, to compute the \\emph{exact} $\\alpha_k$ with greatly reduced\ncomplexity. When needed, this new sandwiching algorithm also achieves a smooth\ntradeoff between computational complexity and result accuracy. Empirical\nresults show the performance improvements of our algorithm over existing known\nmethods; and our algorithm outputs precise values of $\\alpha_k$, with much\nlower complexity than exhaustive search. \n\n"}
{"id": "1306.2672", "contents": "Title: R3MC: A Riemannian three-factor algorithm for low-rank matrix completion Abstract: We exploit the versatile framework of Riemannian optimization on quotient\nmanifolds to develop R3MC, a nonlinear conjugate-gradient method for low-rank\nmatrix completion. The underlying search space of fixed-rank matrices is\nendowed with a novel Riemannian metric that is tailored to the least-squares\ncost. Numerical comparisons suggest that R3MC robustly outperforms\nstate-of-the-art algorithms across different problem instances, especially\nthose that combine scarcely sampled and ill-conditioned data. \n\n"}
{"id": "1306.3331", "contents": "Title: Sparse Recovery of Streaming Signals Using L1-Homotopy Abstract: Most of the existing methods for sparse signal recovery assume a static\nsystem: the unknown signal is a finite-length vector for which a fixed set of\nlinear measurements and a sparse representation basis are available and an\nL1-norm minimization program is solved for the reconstruction. However, the\nsame representation and reconstruction framework is not readily applicable in a\nstreaming system: the unknown signal changes over time, and it is measured and\nreconstructed sequentially over small time intervals.\n  In this paper, we discuss two such streaming systems and a homotopy-based\nalgorithm for quickly solving the associated L1-norm minimization programs: 1)\nRecovery of a smooth, time-varying signal for which, instead of using block\ntransforms, we use lapped orthogonal transforms for sparse representation. 2)\nRecovery of a sparse, time-varying signal that follows a linear dynamic model.\nFor both the systems, we iteratively process measurements over a sliding\ninterval and estimate sparse coefficients by solving a weighted L1-norm\nminimization program. Instead of solving a new L1 program from scratch at every\niteration, we use an available signal estimate as a starting point in a\nhomotopy formulation. Starting with a warm-start vector, our homotopy algorithm\nupdates the solution in a small number of computationally inexpensive steps as\nthe system changes. The homotopy algorithm presented in this paper is highly\nversatile as it can update the solution for the L1 problem in a number of\ndynamical settings. We demonstrate with numerical experiments that our proposed\nstreaming recovery framework outperforms the methods that represent and\nreconstruct a signal as independent, disjoint blocks, in terms of quality of\nreconstruction, and that our proposed homotopy-based updating scheme\noutperforms current state-of-the-art solvers in terms of the computation time\nand complexity. \n\n"}
{"id": "1306.3933", "contents": "Title: Direct leaf trajectory optimization for volumetric modulated arc therapy\n  planning with sliding window delivery Abstract: We propose a novel optimization model for volumetric modulated arc therapy\n(VMAT) planning that directly optimizes deliverable leaf trajectories in the\ntreatment plan optimization problem, and eliminates the need for a separate\narc-sequencing step. In this model, a 360-degree arc is divided into a given\nnumber of arc segments in which the leaves move unidirectionally. This\nfacilitates an algorithm that determines the optimal piecewise linear leaf\ntrajectories for each arc segment, which are deliverable in a given treatment\ntime. Multi-leaf collimator (MLC) constraints, including maximum leaf speed and\ninterdigitation, are accounted for explicitly. The algorithm is customized to\nallow for VMAT delivery using constant gantry speed and dose rate, however, the\nalgorithm generalizes to variable gantry speed if beneficial. We demonstrate\nthe method for three different tumor sites: a head-and-neck case, a prostate\ncase, and a paraspinal case. For that purpose, we first obtain a reference plan\nfor intensity modulated radiotherapy (IMRT) using fluence map optimization and\n20 equally spaced beam directions. Subsequently, VMAT plans are optimized by\ndividing the 360-degree arc into 20 corresponding arc segments. Assuming\ntypical machine parameters (a dose rate of 600 MU/min, and a maximum leaf speed\nof 3 cm/sec), it is demonstrated that the quality of the optimized VMAT plans\napproaches the quality of the IMRT benchmark plan for delivery times between 3\nand 4 minutes. \n\n"}
{"id": "1306.3976", "contents": "Title: Lifting $\\ell_q$-optimization thresholds Abstract: In this paper we look at a connection between the $\\ell_q,0\\leq q\\leq 1$,\noptimization and under-determined linear systems of equations with sparse\nsolutions. The case $q=1$, or in other words $\\ell_1$ optimization and its a\nconnection with linear systems has been thoroughly studied in last several\ndecades; in fact, especially so during the last decade after the seminal works\n\\cite{CRT,DOnoho06CS} appeared. While current understanding of $\\ell_1$\noptimization-linear systems connection is fairly known, much less so is the\ncase with a general $\\ell_q,0<q<1$, optimization. In our recent work\n\\cite{StojnicLqThrBnds10} we provided a study in this direction. As a result we\nwere able to obtain a collection of lower bounds on various $\\ell_q,0\\leq q\\leq\n1$, optimization thresholds. In this paper, we provide a substantial conceptual\nimprovement of the methodology presented in \\cite{StojnicLqThrBnds10}.\nMoreover, the practical results in terms of achievable thresholds are also\nencouraging. As is usually the case with these and similar problems, the\nmethodology we developed emphasizes their a combinatorial nature and attempts\nto somehow handle it. Although our results' main contributions should be on a\nconceptual level, they already give a very strong suggestion that $\\ell_q$\noptimization can in fact provide a better performance than $\\ell_1$, a fact\nlong believed to be true due to a tighter optimization relaxation it provides\nto the original $\\ell_0$ sparsity finding oriented original problem\nformulation. As such, they in a way give a solid boost to further exploration\nof the design of the algorithms that would be able to handle $\\ell_q,0<q<1$,\noptimization in a reasonable (if not polynomial) time. \n\n"}
{"id": "1307.3214", "contents": "Title: An Accurate Method for Determining the Pre-Change Run-Length\n  Distribution of the Generalized Shiryaev--Roberts Detection Procedure Abstract: Change-of-measure is a powerful technique used across statistics, probability\nand analysis. Particularly known as Wald's likelihood ratio identity, the\ntechnique enabled the proof of a number of exact and asymptotic optimality\nresults pertaining to the problem of quickest change-point detection. Within\nthe latter problem's context we apply the technique to develop a numerical\nmethod to compute the Generalized Shiryaev--Roberts (GSR) detection procedure's\npre-change Run-Length distribution. Specifically, the method is based on the\nintegral-equations approach and uses the collocation framework with the basis\nfunctions chosen so as to exploit a certain change-of-measure identity and a\nspecific martingale property of the GSR procedure's detection statistic. As a\nresult, the method's accuracy and robustness improve substantially, even though\nthe method's theoretical rate of convergence is shown to be merely quadratic. A\ntight upper bound on the method's error is supplied as well. The method is not\nrestricted to a particular data distribution or to a specific value of the GSR\ndetection statistic's \"headstart\". To conclude, we offer a case study to\ndemonstrate the proposed method at work, drawing particular attention to the\nmethod's accuracy and its robustness with respect to three factors: (a)\npartition size, (b) change magnitude, and (c) Average Run Length (ARL) to false\nalarm level. Specifically, assuming independent standard Gaussian observations\nundergoing a surge in the mean, we employ the method to study the GSR\nprocedure's Run-Length's pre-change distribution, its average (i.e., the usual\nARL to false alarm) and standard deviation. As expected from the theoretical\nanalysis, the method's high accuracy and robustness with respect to the\nforegoing three factors are confirmed experimentally. We also comment on\nextending the method to handle other performance measures and other procedures. \n\n"}
{"id": "1307.4047", "contents": "Title: Convex relaxation for finding planted influential nodes in a social\n  network Abstract: We consider the problem of maximizing influence in a social network. We focus\non the case that the social network is a directed bipartite graph whose arcs\njoin senders to receivers. We consider both the case of deterministic networks\nand probabilistic graphical models, that is, the so-called \"cascade\" model. The\nproblem is to find the set of the $k$ most influential senders for a given\ninteger $k$. Although this problem is NP-hard, there is a polynomial-time\napproximation algorithm due to Kempe, Kleinberg and Tardos. In this work we\nconsider convex relaxation for the problem. We prove that convex optimization\ncan recover the exact optimizer in the case that the network is constructed\naccording to a generative model in which influential nodes are planted but then\nobscured with noise. We also demonstrate computationally that the convex\nrelaxation can succeed on a more realistic generative model called the \"forest\nfire\" model. \n\n"}
{"id": "1307.4258", "contents": "Title: Complexity and Approximation of the Continuous Network Design Problem Abstract: We revisit a classical problem in transportation, known as the continuous\n(bilevel) network design problem, CNDP for short. We are given a graph for\nwhich the latency of each edge depends on the ratio of the edge flow and the\ncapacity installed. The goal is to find an optimal investment in edge\ncapacities so as to minimize the sum of the routing cost of the induced Wardrop\nequilibrium and the investment cost. While this problem is considered as\nchallenging in the literature, its complexity status was still unknown. We\nclose this gap showing that CNDP is strongly NP-complete and APX-hard, both on\ndirected and undirected networks and even for instances with affine latencies.\n  As for the approximation of the problem, we first provide a detailed analysis\nfor a heuristic studied by Marcotte for the special case of monomial latency\nfunctions (Mathematical Programming, Vol.~34, 1986). Specifically, we derive a\nclosed form expression of its approximation guarantee for arbitrary sets S of\nallowed latency functions. Second, we propose a different approximation\nalgorithm and show that it has the same approximation guarantee. As our final\n-- and arguably most interesting -- result regarding approximation, we show\nthat using the better of the two approximation algorithms results in a strictly\nimproved approximation guarantee for which we give a closed form expression.\nFor affine latencies, e.g., this algorithm achieves a 1.195-approximation which\nimproves on the 5/4 that has been shown before by Marcotte. We finally discuss\nthe case of hard budget constraints on the capacity investment. \n\n"}
{"id": "1307.4502", "contents": "Title: Universally Elevating the Phase Transition Performance of Compressed\n  Sensing: Non-Isometric Matrices are Not Necessarily Bad Matrices Abstract: In compressed sensing problems, $\\ell_1$ minimization or Basis Pursuit was\nknown to have the best provable phase transition performance of recoverable\nsparsity among polynomial-time algorithms. It is of great theoretical and\npractical interest to find alternative polynomial-time algorithms which perform\nbetter than $\\ell_1$ minimization. \\cite{Icassp reweighted l_1}, \\cite{Isit\nreweighted l_1}, \\cite{XuScaingLaw} and \\cite{iterativereweightedjournal} have\nshown that a two-stage re-weighted $\\ell_1$ minimization algorithm can boost\nthe phase transition performance for signals whose nonzero elements follow an\namplitude probability density function (pdf) $f(\\cdot)$ whose $t$-th derivative\n$f^{t}(0) \\neq 0$ for some integer $t \\geq 0$. However, for signals whose\nnonzero elements are strictly suspended from zero in distribution (for example,\nconstant-modulus, only taking values `$+d$' or `$-d$' for some nonzero real\nnumber $d$), no polynomial-time signal recovery algorithms were known to\nprovide better phase transition performance than plain $\\ell_1$ minimization,\nespecially for dense sensing matrices. In this paper, we show that a\npolynomial-time algorithm can universally elevate the phase-transition\nperformance of compressed sensing, compared with $\\ell_1$ minimization, even\nfor signals with constant-modulus nonzero elements. Contrary to conventional\nwisdoms that compressed sensing matrices are desired to be isometric, we show\nthat non-isometric matrices are not necessarily bad sensing matrices. In this\npaper, we also provide a framework for recovering sparse signals when sensing\nmatrices are not isometric. \n\n"}
{"id": "1307.6134", "contents": "Title: Modeling Human Decision-making in Generalized Gaussian Multi-armed\n  Bandits Abstract: We present a formal model of human decision-making in explore-exploit tasks\nusing the context of multi-armed bandit problems, where the decision-maker must\nchoose among multiple options with uncertain rewards. We address the standard\nmulti-armed bandit problem, the multi-armed bandit problem with transition\ncosts, and the multi-armed bandit problem on graphs. We focus on the case of\nGaussian rewards in a setting where the decision-maker uses Bayesian inference\nto estimate the reward values. We model the decision-maker's prior knowledge\nwith the Bayesian prior on the mean reward. We develop the upper credible limit\n(UCL) algorithm for the standard multi-armed bandit problem and show that this\ndeterministic algorithm achieves logarithmic cumulative expected regret, which\nis optimal performance for uninformative priors. We show how good priors and\ngood assumptions on the correlation structure among arms can greatly enhance\ndecision-making performance, even over short time horizons. We extend to the\nstochastic UCL algorithm and draw several connections to human decision-making\nbehavior. We present empirical data from human experiments and show that human\nperformance is efficiently captured by the stochastic UCL algorithm with\nappropriate parameters. For the multi-armed bandit problem with transition\ncosts and the multi-armed bandit problem on graphs, we generalize the UCL\nalgorithm to the block UCL algorithm and the graphical block UCL algorithm,\nrespectively. We show that these algorithms also achieve logarithmic cumulative\nexpected regret and require a sub-logarithmic expected number of transitions\namong arms. We further illustrate the performance of these algorithms with\nnumerical examples. NB: Appendix G included in this version details minor\nmodifications that correct for an oversight in the previously-published proofs.\nThe remainder of the text reflects the published work. \n\n"}
{"id": "1308.6718", "contents": "Title: Reduced-Complexity Semidefinite Relaxations of Optimal Power Flow\n  Problems Abstract: We propose a new method for generating semidefinite relaxations of optimal\npower flow problems. The method is based on chordal conversion techniques: by\ndropping some equality constraints in the conversion, we obtain semidefinite\nrelaxations that are computationally cheaper, but potentially weaker, than the\nstandard semidefinite relaxation. Our numerical results show that the new\nrelaxations often produce the same results as the standard semidefinite\nrelaxation, but at a lower computational cost. \n\n"}
{"id": "1309.0209", "contents": "Title: Optimal stochastic control and optimal consumption and portfolio with\n  G-Brownian motion Abstract: By the calculus of Peng's G-sublinear expectation and G-Brownian motion on a\nsublinear expectation space $(\\Omega, {\\cal H}, \\hat{\\mathbb{E}})$, we first\nset up an optimality principle of stochastic control problem. Then we\ninvestigate an optimal consumption and portfolio decision with a volatility\nambiguity by the derived verification theorem. Next the two-fund separation\ntheorem is explicitly obtained. And an illustrative example is provided. \n\n"}
{"id": "1309.1501", "contents": "Title: Improvements to deep convolutional neural networks for LVCSR Abstract: Deep Convolutional Neural Networks (CNNs) are more powerful than Deep Neural\nNetworks (DNN), as they are able to better reduce spectral variation in the\ninput signal. This has also been confirmed experimentally, with CNNs showing\nimprovements in word error rate (WER) between 4-12% relative compared to DNNs\nacross a variety of LVCSR tasks. In this paper, we describe different methods\nto further improve CNN performance. First, we conduct a deep analysis comparing\nlimited weight sharing and full weight sharing with state-of-the-art features.\nSecond, we apply various pooling strategies that have shown improvements in\ncomputer vision to an LVCSR speech task. Third, we introduce a method to\neffectively incorporate speaker adaptation, namely fMLLR, into log-mel\nfeatures. Fourth, we introduce an effective strategy to use dropout during\nHessian-free sequence training. We find that with these improvements,\nparticularly with fMLLR and dropout, we are able to achieve an additional 2-3%\nrelative improvement in WER on a 50-hour Broadcast News task over our previous\nbest CNN baseline. On a larger 400-hour BN task, we find an additional 4-5%\nrelative improvement over our previous best CNN baseline. \n\n"}
{"id": "1309.1823", "contents": "Title: On Limits to the Scope of the Extended Formulations \"Barriers\" Abstract: In this paper, we introduce the notion of augmentation for polytopes and use\nit to show the error in two presumptions that have been key in arriving at\nover-reaching/over-scoped claims of \"impossibility\" in recent extended\nformulations (EF) developments. One of these presumptions is that: \"If\nPolytopes P and Q are described in the spaces of variables x and y\nrespectively, and there exists a linear map x=Ay between the feasible sets of P\nand Q, then Q is an EF of P\". The other is: \"(An augmentation of Polytope A\nprojects to Polytope B) ==> (The external descriptions of A and B are\nrelated)\". We provide counter-examples to these presumptions, and show that in\ngeneral: (1) If polytopes can always be arbitrarily augmented for the purpose\nof establishing EF relations, then the notion of EF becomes\ndegenerate/meaningless in some cases, and that: (2) The statement: \"(Polytope B\nis the projection of an augmentation of Polytope A) ==> (Polytope B is the\nprojection of Polytope A)\" is not true in general (although, as we show, the\nconverse statement, \"(B is the projection of A) ==> (B is the projection of\nevery augmentation of A)\", is true in general). We illustrate some of the ideas\nusing the minimum spanning tree problem, as well as the \"lower bounds\"\ndevelopments in Fiorini et al. (2011; 2012), in particular. \n\n"}
{"id": "1309.2350", "contents": "Title: Exponentially Fast Parameter Estimation in Networks Using Distributed\n  Dual Averaging Abstract: In this paper we present an optimization-based view of distributed parameter\nestimation and observational social learning in networks. Agents receive a\nsequence of random, independent and identically distributed (i.i.d.) signals,\neach of which individually may not be informative about the underlying true\nstate, but the signals together are globally informative enough to make the\ntrue state identifiable. Using an optimization-based characterization of\nBayesian learning as proximal stochastic gradient descent (with\nKullback-Leibler divergence from a prior as a proximal function), we show how\nto efficiently use a distributed, online variant of Nesterov's dual averaging\nmethod to solve the estimation with purely local information. When the true\nstate is globally identifiable, and the network is connected, we prove that\nagents eventually learn the true parameter using a randomized gossip scheme. We\ndemonstrate that with high probability the convergence is exponentially fast\nwith a rate dependent on the KL divergence of observations under the true state\nfrom observations under the second likeliest state. Furthermore, our work also\nhighlights the possibility of learning under continuous adaptation of network\nwhich is a consequence of employing constant, unit stepsize for the algorithm. \n\n"}
{"id": "1309.5124", "contents": "Title: Multi-layer graph analysis for dynamic social networks Abstract: Modern social networks frequently encompass multiple distinct types of\nconnectivity information; for instance, explicitly acknowledged friend\nrelationships might complement behavioral measures that link users according to\ntheir actions or interests. One way to represent these networks is as\nmulti-layer graphs, where each layer contains a unique set of edges over the\nsame underlying vertices (users). Edges in different layers typically have\nrelated but distinct semantics; depending on the application multiple layers\nmight be used to reduce noise through averaging, to perform multifaceted\nanalyses, or a combination of the two. However, it is not obvious how to extend\nstandard graph analysis techniques to the multi-layer setting in a flexible\nway. In this paper we develop latent variable models and methods for mining\nmulti-layer networks for connectivity patterns based on noisy data. \n\n"}
{"id": "1310.1147", "contents": "Title: A Unified Primal Dual Active Set Algorithm for Nonconvex Sparse Recovery Abstract: In this paper, we consider the problem of recovering a sparse signal based on\npenalized least squares formulations. We develop a novel algorithm of\nprimal-dual active set type for a class of nonconvex sparsity-promoting\npenalties, including $\\ell^0$, bridge, smoothly clipped absolute deviation,\ncapped $\\ell^1$ and minimax concavity penalty. First we establish the existence\nof a global minimizer for the related optimization problems. Then we derive a\nnovel necessary optimality condition for the global minimizer using the\nassociated thresholding operator. The solutions to the optimality system are\ncoordinate-wise minimizers, and under minor conditions, they are also local\nminimizers. Upon introducing the dual variable, the active set can be\ndetermined using the primal and dual variables together. Further, this relation\nlends itself to an iterative algorithm of active set type which at each step\ninvolves first updating the primal variable only on the active set and then\nupdating the dual variable explicitly. When combined with a continuation\nstrategy on the regularization parameter, the primal dual active set method is\nshown to converge globally to the underlying regression target under certain\nregularity conditions. Extensive numerical experiments with both simulated and\nreal data demonstrate its superior performance in efficiency and accuracy\ncompared with the existing sparse recovery methods. \n\n"}
{"id": "1310.1297", "contents": "Title: Spectral Clustering for Divide-and-Conquer Graph Matching Abstract: We present a parallelized bijective graph matching algorithm that leverages\nseeds and is designed to match very large graphs. Our algorithm combines\nspectral graph embedding with existing state-of-the-art seeded graph matching\nprocedures. We justify our approach by proving that modestly correlated, large\nstochastic block model random graphs are correctly matched utilizing very few\nseeds through our divide-and-conquer procedure. We also demonstrate the\neffectiveness of our approach in matching very large graphs in simulated and\nreal data examples, showing up to a factor of 8 improvement in runtime with\nminimal sacrifice in accuracy. \n\n"}
{"id": "1310.1351", "contents": "Title: New Conditions for Sparse Phase Retrieval Abstract: We consider the problem of sparse phase retrieval, where a $k$-sparse signal\n${\\bf x} \\in {\\mathbb R}^n \\textrm{ (or } {\\mathbb C}^n\\textrm{)}$ is measured\nas ${\\bf y} = |{\\bf Ax}|,$ where ${\\bf A} \\in {\\mathbb R}^{m \\times n} \\textrm{\n(or } {\\mathbb C}^{m \\times n}\\textrm{ respectively)}$ is a measurement matrix\nand $|\\cdot|$ is the element-wise absolute value. For a real signal and a real\nmeasurement matrix ${\\bf A}$, we show that $m = 2k$ measurements are necessary\nand sufficient to recover ${\\bf x}$ uniquely. For complex signal ${\\bf x} \\in\n{\\mathbb C}^n$ and ${\\bf A} \\in {\\mathbb C}^{m \\times n}$, we show that $m =\n4k-2$ phaseless measurements are sufficient to recover ${\\bf x}$. It is known\nthat the multiplying constant $4$ in $m = 4k-2$ cannot be improved. \n\n"}
{"id": "1310.1840", "contents": "Title: Parallel coordinate descent for the Adaboost problem Abstract: We design a randomised parallel version of Adaboost based on previous studies\non parallel coordinate descent. The algorithm uses the fact that the logarithm\nof the exponential loss is a function with coordinate-wise Lipschitz continuous\ngradient, in order to define the step lengths. We provide the proof of\nconvergence for this randomised Adaboost algorithm and a theoretical\nparallelisation speedup factor. We finally provide numerical examples on\nlearning problems of various sizes that show that the algorithm is competitive\nwith concurrent approaches, especially for large scale problems. \n\n"}
{"id": "1310.2887", "contents": "Title: An Accelerated Randomized Kaczmarz Algorithm Abstract: The randomized Kaczmarz ($\\RK$) algorithm is a simple but powerful approach\nfor solving consistent linear systems $Ax=b$. This paper proposes an\naccelerated randomized Kaczmarz ($\\ARK$) algorithm with better convergence than\nthe standard $\\RK$ algorithm on ill conditioned problems. The per-iteration\ncost of $\\RK$ and $\\ARK$ are similar if $A$ is dense, but $\\RK$ is much more\nable to exploit sparsity in $A$ than is $\\ARK$. To deal with the sparse case,\nan efficient implementation for $\\ARK$, called $\\SARK$, is proposed. A\ncomparison of convergence rates and average per-iteration complexities among\n$\\RK$, $\\ARK$, and $\\SARK$ is given, taking into account different levels of\nsparseness and conditioning. Comparisons with the leading deterministic\nalgorithm --- conjugate gradient applied to the normal equations --- are also\ngiven. Finally, the analysis is validated via computational testing. \n\n"}
{"id": "1310.5715", "contents": "Title: Stochastic Gradient Descent, Weighted Sampling, and the Randomized\n  Kaczmarz algorithm Abstract: We obtain an improved finite-sample guarantee on the linear convergence of\nstochastic gradient descent for smooth and strongly convex objectives,\nimproving from a quadratic dependence on the conditioning $(L/\\mu)^2$ (where\n$L$ is a bound on the smoothness and $\\mu$ on the strong convexity) to a linear\ndependence on $L/\\mu$. Furthermore, we show how reweighting the sampling\ndistribution (i.e. importance sampling) is necessary in order to further\nimprove convergence, and obtain a linear dependence in the average smoothness,\ndominating previous results. We also discuss importance sampling for SGD more\nbroadly and show how it can improve convergence also in other scenarios. Our\nresults are based on a connection we make between SGD and the randomized\nKaczmarz algorithm, which allows us to transfer ideas between the separate\nbodies of literature studying each of the two methods. In particular, we recast\nthe randomized Kaczmarz algorithm as an instance of SGD, and apply our results\nto prove its exponential convergence, but to the solution of a weighted least\nsquares problem rather than the original least squares problem. We then present\na modified Kaczmarz algorithm with partially biased sampling which does\nconverge to the original least squares solution with the same exponential\nconvergence rate. \n\n"}
{"id": "1310.7300", "contents": "Title: Relax but stay in control: from value to algorithms for online Markov\n  decision processes Abstract: Online learning algorithms are designed to perform in non-stationary\nenvironments, but generally there is no notion of a dynamic state to model\nconstraints on current and future actions as a function of past actions.\nState-based models are common in stochastic control settings, but commonly used\nframeworks such as Markov Decision Processes (MDPs) assume a known stationary\nenvironment. In recent years, there has been a growing interest in combining\nthe above two frameworks and considering an MDP setting in which the cost\nfunction is allowed to change arbitrarily after each time step. However, most\nof the work in this area has been algorithmic: given a problem, one would\ndevelop an algorithm almost from scratch. Moreover, the presence of the state\nand the assumption of an arbitrarily varying environment complicate both the\ntheoretical analysis and the development of computationally efficient methods.\nThis paper describes a broad extension of the ideas proposed by Rakhlin et al.\nto give a general framework for deriving algorithms in an MDP setting with\narbitrarily changing costs. This framework leads to a unifying view of existing\nmethods and provides a general procedure for constructing new ones. Several new\nmethods are presented, and one of them is shown to have important advantages\nover a similar method developed from scratch via an online version of\napproximate dynamic programming. \n\n"}
{"id": "1310.7529", "contents": "Title: Successive Nonnegative Projection Algorithm for Robust Nonnegative Blind\n  Source Separation Abstract: In this paper, we propose a new fast and robust recursive algorithm for\nnear-separable nonnegative matrix factorization, a particular nonnegative blind\nsource separation problem. This algorithm, which we refer to as the successive\nnonnegative projection algorithm (SNPA), is closely related to the popular\nsuccessive projection algorithm (SPA), but takes advantage of the nonnegativity\nconstraint in the decomposition. We prove that SNPA is more robust than SPA and\ncan be applied to a broader class of nonnegative matrices. This is illustrated\non some synthetic data sets, and on a real-world hyperspectral image. \n\n"}
{"id": "1310.7991", "contents": "Title: Learning Sparsely Used Overcomplete Dictionaries via Alternating\n  Minimization Abstract: We consider the problem of sparse coding, where each sample consists of a\nsparse linear combination of a set of dictionary atoms, and the task is to\nlearn both the dictionary elements and the mixing coefficients. Alternating\nminimization is a popular heuristic for sparse coding, where the dictionary and\nthe coefficients are estimated in alternate steps, keeping the other fixed.\nTypically, the coefficients are estimated via $\\ell_1$ minimization, keeping\nthe dictionary fixed, and the dictionary is estimated through least squares,\nkeeping the coefficients fixed. In this paper, we establish local linear\nconvergence for this variant of alternating minimization and establish that the\nbasin of attraction for the global optimum (corresponding to the true\ndictionary and the coefficients) is $\\order{1/s^2}$, where $s$ is the sparsity\nlevel in each sample and the dictionary satisfies RIP. Combined with the recent\nresults of approximate dictionary estimation, this yields provable guarantees\nfor exact recovery of both the dictionary elements and the coefficients, when\nthe dictionary elements are incoherent. \n\n"}
{"id": "1311.0442", "contents": "Title: Extremal properties of tropical eigenvalues and solutions to tropical\n  optimization problems Abstract: An unconstrained optimization problem is formulated in terms of tropical\nmathematics to minimize a functional that is defined on a vector set by a\nmatrix and calculated through multiplicative conjugate transposition. For some\nparticular cases, the minimum in the problem is known to be equal to the\ntropical spectral radius of the matrix. We examine the problem in the common\nsetting of a general idempotent semifield. A complete direct solution in a\ncompact vector form is obtained to this problem under fairly general\nconditions. The result is extended to solve new tropical optimization problems\nwith more general objective functions and inequality constraints. Applications\nto real-world problems that arise in project scheduling are presented. To\nillustrate the results obtained, numerical examples are also provided. \n\n"}
{"id": "1311.0830", "contents": "Title: The Squared-Error of Generalized LASSO: A Precise Analysis Abstract: We consider the problem of estimating an unknown signal $x_0$ from noisy\nlinear observations $y = Ax_0 + z\\in R^m$. In many practical instances, $x_0$\nhas a certain structure that can be captured by a structure inducing convex\nfunction $f(\\cdot)$. For example, $\\ell_1$ norm can be used to encourage a\nsparse solution. To estimate $x_0$ with the aid of $f(\\cdot)$, we consider the\nwell-known LASSO method and provide sharp characterization of its performance.\nWe assume the entries of the measurement matrix $A$ and the noise vector $z$\nhave zero-mean normal distributions with variances $1$ and $\\sigma^2$\nrespectively. For the LASSO estimator $x^*$, we attempt to calculate the\nNormalized Square Error (NSE) defined as $\\frac{\\|x^*-x_0\\|_2^2}{\\sigma^2}$ as\na function of the noise level $\\sigma$, the number of observations $m$ and the\nstructure of the signal. We show that, the structure of the signal $x_0$ and\nchoice of the function $f(\\cdot)$ enter the error formulae through the summary\nparameters $D(cone)$ and $D(\\lambda)$, which are defined as the Gaussian\nsquared-distances to the subdifferential cone and to the $\\lambda$-scaled\nsubdifferential, respectively. The first LASSO estimator assumes a-priori\nknowledge of $f(x_0)$ and is given by $\\arg\\min_{x}\\{{\\|y-Ax\\|_2}~\\text{subject\nto}~f(x)\\leq f(x_0)\\}$. We prove that its worst case NSE is achieved when\n$\\sigma\\rightarrow 0$ and concentrates around $\\frac{D(cone)}{m-D(cone)}$.\nSecondly, we consider $\\arg\\min_{x}\\{\\|y-Ax\\|_2+\\lambda f(x)\\}$, for some\n$\\lambda\\geq 0$. This time the NSE formula depends on the choice of $\\lambda$\nand is given by $\\frac{D(\\lambda)}{m-D(\\lambda)}$. We then establish a mapping\nbetween this and the third estimator $\\arg\\min_{x}\\{\\frac{1}{2}\\|y-Ax\\|_2^2+\n\\lambda f(x)\\}$. Finally, for a number of important structured signal classes,\nwe translate our abstract formulae to closed-form upper bounds on the NSE. \n\n"}
{"id": "1311.1098", "contents": "Title: Mirror Prox Algorithm for Multi-Term Composite Minimization and\n  Semi-Separable Problems Abstract: In the paper, we develop a composite version of Mirror Prox algorithm for\nsolving convex-concave saddle point problems and monotone variational\ninequalities of special structure, allowing to cover saddle point/variational\nanalogies of what is usually called \"composite minimization\" (minimizing a sum\nof an easy-to-handle nonsmooth and a general-type smooth convex functions \"as\nif\" there were no nonsmooth component at all). We demonstrate that the\ncomposite Mirror Prox inherits the favourable (and unimprovable already in the\nlarge-scale bilinear saddle point case) $O(1/\\epsilon)$ efficiency estimate of\nits prototype. We demonstrate that the proposed approach can be naturally\napplied to Lasso-type problems with several penalizing terms (e.g. acting\ntogether $\\ell_1$ and nuclear norm regularization) and to problems of the\nstructure considered in the alternating directions methods, implying in both\ncases methods with the $O(\\epsilon^{-1})$ complexity bounds. \n\n"}
{"id": "1311.1129", "contents": "Title: Discussion of \"Geodesic Monte Carlo on Embedded Manifolds\" Abstract: Contributed discussion and rejoinder to \"Geodesic Monte Carlo on Embedded\nManifolds\" (arXiv:1301.6064) \n\n"}
{"id": "1311.1644", "contents": "Title: The Maximum Entropy Relaxation Path Abstract: The relaxed maximum entropy problem is concerned with finding a probability\ndistribution on a finite set that minimizes the relative entropy to a given\nprior distribution, while satisfying relaxed max-norm constraints with respect\nto a third observed multinomial distribution. We study the entire relaxation\npath for this problem in detail. We show existence and a geometric description\nof the relaxation path. Specifically, we show that the maximum entropy\nrelaxation path admits a planar geometric description as an increasing,\npiecewise linear function in the inverse relaxation parameter. We derive fast\nalgorithms for tracking the path. In various realistic settings, our algorithms\nrequire $O(n\\log(n))$ operations for probability distributions on $n$ points,\nmaking it possible to handle large problems. Once the path has been recovered,\nwe show that given a validation set, the family of admissible models is reduced\nfrom an infinite family to a small, discrete set. We demonstrate the merits of\nour approach in experiments with synthetic data and discuss its potential for\nthe estimation of compact n-gram language models. \n\n"}
{"id": "1311.1756", "contents": "Title: An Inexact Proximal Path-Following Algorithm for Constrained Convex\n  Minimization Abstract: Many scientific and engineering applications feature nonsmooth convex\nminimization problems over convex sets. In this paper, we address an important\ninstance of this broad class where we assume that the nonsmooth objective is\nequipped with a tractable proximity operator and that the convex constraint set\naffords a self-concordant barrier. We provide a new joint treatment of proximal\nand self-concordant barrier concepts and illustrate that such problems can be\nefficiently solved, without the need of lifting the problem dimensions, as in\ndisciplined convex optimization approach. We propose an inexact path-following\nalgorithmic framework and theoretically characterize the worst-case analytical\ncomplexity of this framework when the proximal subproblems are solved\ninexactly. To show the merits of our framework, we apply its instances to both\nsynthetic and real-world applications, where it shows advantages over standard\ninterior point methods. As a by-product, we describe how our framework can\nobtain points on the Pareto frontier of regularized problems with\nself-concordant objectives in a tuning free fashion. \n\n"}
{"id": "1311.2335", "contents": "Title: A First-Order Algorithm for the A-Optimal Experimental Design Problem: A\n  Mathematical Programming Approach Abstract: We develop and analyse a first-order algorithm for the A-optimal experimental\ndesign problem. The problem is first presented as a special case of a\nparametric family of optimal design problems for which duality results and\noptimality conditions are given. Then, two first-order (Frank-Wolfe type)\nalgorithms are presented, accompanied by a detailed time-complexity analysis of\nthe algorithms and computational results on various sized problems. \n\n"}
{"id": "1311.2745", "contents": "Title: Sparse Phase Retrieval: Uniqueness Guarantees and Recovery Algorithms Abstract: The problem of signal recovery from its Fourier transform magnitude is of\nparamount importance in various fields of engineering and has been around for\nover 100 years. Due to the absence of phase information, some form of\nadditional information is required in order to be able to uniquely identify the\nsignal of interest. In this work, we focus our attention on discrete-time\nsparse signals (of length $n$). We first show that, if the DFT dimension is\ngreater than or equal to $2n$, almost all signals with {\\em aperiodic} support\ncan be uniquely identified by their Fourier transform magnitude (up to\ntime-shift, conjugate-flip and global phase).\n  Then, we develop an efficient Two-stage Sparse Phase Retrieval algorithm\n(TSPR), which involves: (i) identifying the support, i.e., the locations of the\nnon-zero components, of the signal using a combinatorial algorithm (ii)\nidentifying the signal values in the support using a convex algorithm. We show\nthat TSPR can {\\em provably} recover most $O(n^{1/2-\\eps})$-sparse signals (up\nto a time-shift, conjugate-flip and global phase). We also show that, for most\n$O(n^{1/4-\\eps})$-sparse signals, the recovery is {\\em robust} in the presence\nof measurement noise. Numerical experiments complement our theoretical analysis\nand verify the effectiveness of TSPR. \n\n"}
{"id": "1311.5871", "contents": "Title: Finding sparse solutions of systems of polynomial equations via\n  group-sparsity optimization Abstract: The paper deals with the problem of finding sparse solutions to systems of\npolynomial equations possibly perturbed by noise. In particular, we show how\nthese solutions can be recovered from group-sparse solutions of a derived\nsystem of linear equations. Then, two approaches are considered to find these\ngroup-sparse solutions. The first one is based on a convex relaxation resulting\nin a second-order cone programming formulation which can benefit from efficient\nreweighting techniques for sparsity enhancement. For this approach, sufficient\nconditions for the exact recovery of the sparsest solution to the polynomial\nsystem are derived in the noiseless setting, while stable recovery results are\nobtained for the noisy case. Though lacking a similar analysis, the second\napproach provides a more computationally efficient algorithm based on a greedy\nstrategy adding the groups one-by-one. With respect to previous work, the\nproposed methods recover the sparsest solution in a very short computing time\nwhile remaining at least as accurate in terms of the probability of success.\nThis probability is empirically analyzed to emphasize the relationship between\nthe ability of the methods to solve the polynomial system and the sparsity of\nthe solution. \n\n"}
{"id": "1311.6107", "contents": "Title: Off-policy reinforcement learning for $ H_\\infty $ control design Abstract: The $H_\\infty$ control design problem is considered for nonlinear systems\nwith unknown internal system model. It is known that the nonlinear $ H_\\infty $\ncontrol problem can be transformed into solving the so-called\nHamilton-Jacobi-Isaacs (HJI) equation, which is a nonlinear partial\ndifferential equation that is generally impossible to be solved analytically.\nEven worse, model-based approaches cannot be used for approximately solving HJI\nequation, when the accurate system model is unavailable or costly to obtain in\npractice. To overcome these difficulties, an off-policy reinforcement leaning\n(RL) method is introduced to learn the solution of HJI equation from real\nsystem data instead of mathematical system model, and its convergence is\nproved. In the off-policy RL method, the system data can be generated with\narbitrary policies rather than the evaluating policy, which is extremely\nimportant and promising for practical systems. For implementation purpose, a\nneural network (NN) based actor-critic structure is employed and a least-square\nNN weight update algorithm is derived based on the method of weighted\nresiduals. Finally, the developed NN-based off-policy RL method is tested on a\nlinear F16 aircraft plant, and further applied to a rotational/translational\nactuator system. \n\n"}
{"id": "1311.7198", "contents": "Title: ADMM Algorithm for Graphical Lasso with an $\\ell_{\\infty}$ Element-wise\n  Norm Constraint Abstract: We consider the problem of Graphical lasso with an additional $\\ell_{\\infty}$\nelement-wise norm constraint on the precision matrix. This problem has\napplications in high-dimensional covariance decomposition such as in\n\\citep{Janzamin-12}. We propose an ADMM algorithm to solve this problem. We\nalso use a continuation strategy on the penalty parameter to have a fast\nimplemenation of the algorithm. \n\n"}
{"id": "1312.0418", "contents": "Title: Stability of continuous-time quantum filters with measurement\n  imperfections Abstract: The fidelity between the state of a continuously observed quantum system and\nthe state of its associated quantum filter, is shown to be always a\nsubmartingale. The observed system is assumed to be governed by a\ncontinuous-time Stochastic Master Equation (SME), driven simultaneously by\nWiener and Poisson processes and that takes into account incompleteness and\nerrors in measurements. This stability result is the continuous-time\ncounterpart of a similar stability result already established for discrete-time\nquantum systems and where the measurement imperfections are modeled by a left\nstochastic matrix. \n\n"}
{"id": "1312.0485", "contents": "Title: Precise Semidefinite Programming Formulation of Atomic Norm Minimization\n  for Recovering d-Dimensional ($d\\geq 2$) Off-the-Grid Frequencies Abstract: Recent research in off-the-grid compressed sensing (CS) has demonstrated\nthat, under certain conditions, one can successfully recover a spectrally\nsparse signal from a few time-domain samples even though the dictionary is\ncontinuous. In particular, atomic norm minimization was proposed in\n\\cite{tang2012csotg} to recover $1$-dimensional spectrally sparse signal.\nHowever, in spite of existing research efforts \\cite{chi2013compressive}, it\nwas still an open problem how to formulate an equivalent positive semidefinite\nprogram for atomic norm minimization in recovering signals with $d$-dimensional\n($d\\geq 2$) off-the-grid frequencies. In this paper, we settle this problem by\nproposing equivalent semidefinite programming formulations of atomic norm\nminimization to recover signals with $d$-dimensional ($d\\geq 2$) off-the-grid\nfrequencies. \n\n"}
{"id": "1312.1085", "contents": "Title: Explicit Convergence Rate of a Distributed Alternating Direction Method\n  of Multipliers Abstract: Consider a set of N agents seeking to solve distributively the minimization\nproblem $\\inf_{x} \\sum_{n = 1}^N f_n(x)$ where the convex functions $f_n$ are\nlocal to the agents. The popular Alternating Direction Method of Multipliers\nhas the potential to handle distributed optimization problems of this kind. We\nprovide a general reformulation of the problem and obtain a class of\ndistributed algorithms which encompass various network architectures. The rate\nof convergence of our method is considered. It is assumed that the infimum of\nthe problem is reached at a point $x_\\star$, the functions $f_n$ are twice\ndifferentiable at this point and $\\sum \\nabla^2 f_n(x_\\star) > 0$ in the\npositive definite ordering of symmetric matrices. With these assumptions, it is\nshown that the convergence to the consensus $x_\\star$ is linear and the exact\nrate is provided. Application examples where this rate can be optimized with\nrespect to the ADMM free parameter $\\rho$ are also given. \n\n"}
{"id": "1312.3012", "contents": "Title: Improving Fast Dual Ascent for MPC - Part I: The Distributed Case Abstract: In dual decomposition, the dual to an optimization problem with a specific\nstructure is solved in distributed fashion using (sub)gradient and recently\nalso fast gradient methods. The traditional dual decomposition suffers from two\nmain short-comings. The first is that the convergence is often slow, although\nfast gradient methods have significantly improved the situation. The second is\nthat computation of the optimal step-size requires centralized computations,\nwhich hinders a fully distributed implementation of the algorithm. In this\npaper, the first issue is addressed by providing a tighter characterization of\nthe dual function than what has previously been reported in the literature.\nThen a distributed and a parallel algorithm are presented in which the provided\ndual function approximation is minimized in each step. Since the approximation\nis more accurate than the approximation used in standard and fast dual\ndecomposition, the convergence properties are improved. For the second issue,\nwe extend a recent result to allow for a fully distributed parameter selection\nin the algorithm. Further, we show how to apply the proposed algorithms to\noptimization problems arising in distributed model predictive control (DMPC)\nand show that the proposed distributed algorithm enjoys distributed\nreconfiguration, i.e. plug-and-play, in the DMPC context. \n\n"}
{"id": "1312.4883", "contents": "Title: A Riemannian approach to low-rank algebraic Riccati equations Abstract: We propose a Riemannian optimization approach for computing low-rank\nsolutions of the algebraic Riccati equation. The scheme alternates between\nfixed-rank optimization and rank-one updates. The fixed-rank optimization is on\nthe set of fixed-rank symmetric positive definite matrices which is endowed\nwith a particular Riemannian metric (and geometry) that is tuned to the\nstructure of the objective function. We specifically discuss the implementation\nof a Riemannian trust-region algorithm that is potentially scalable to\nlarge-scale problems. The rank-one update is based on a descent direction that\nensures a monotonic decrease of the cost function. Preliminary numerical\nresults on standard small-scale benchmarks show that we obtain solutions to the\nRiccati equation at lower ranks than the standard approaches. \n\n"}
{"id": "1312.4885", "contents": "Title: Rolling Manifolds of Different Dimensions Abstract: If $(M,g)$ and $(\\hM,\\hg)$ are two smooth connected complete oriented\nRiemannian manifolds of dimensions $n$ and $\\hn$ respectively, we model the\nrolling of $(M,g)$ onto $(\\hM,\\hg)$ as a driftless control affine systems\ndescribing two possible constraints of motion: the first rolling motion\n$\\Sigma_{NS}$ captures the no-spinning condition only and the second rolling\nmotion $\\Sigma_{R}$ corresponds to rolling without spinning nor slipping. Two\ndistributions of dimensions $(n + \\hn)$ and $n$, respectively, are then\nassociated to the rolling motions $\\Sigma_{NS}$ and $\\Sigma_{R}$ respectively.\nThis generalizes the rolling problems considered in \\cite{ChitourKokkonen1}\nwhere both manifolds had the same dimension. The controllability issue is then\naddressed for both $\\Sigma_{NS}$ and $\\Sigma_{R}$ and completely solved for\n$\\Sigma_{NS}$. As regards to $\\Sigma_{R}$, basic properties for the reachable\nsets are provided as well as the complete study of the case $(n,\\hn)=(3,2)$ and\nsome sufficient conditions for non-controllability. \n\n"}
{"id": "1312.5681", "contents": "Title: On local convergence of the method of alternating projections Abstract: The method of alternating projections is a classical tool to solve\nfeasibility problems. Here we prove local convergence of alternating\nprojections between subanalytic sets $A,B$ under a mild regularity hypothesis\non one of the sets. We show that the speed of convergence is O$(k^{-\\rho})$ for\nsome $\\rho\\in (0,\\infty)$. \n\n"}
{"id": "1312.6643", "contents": "Title: Conic approach to quantum graph parameters using linear optimization\n  over the completely positive semidefinite cone Abstract: We investigate the completely positive semidefinite cone $\\mathcal{CS}_+^n$,\na new matrix cone consisting of all $n\\times n$ matrices that admit a Gram\nrepresentation by positive semidefinite matrices (of any size). In particular\nwe study relationships between this cone and the completely positive and doubly\nnonnegative cones, and between its dual cone and trace positive non-commutative\npolynomials.\n  We use this new cone to model quantum analogues of the classical independence\nand chromatic graph parameters $\\alpha(G)$ and $\\chi(G)$, which are roughly\nobtained by allowing variables to be positive semidefinite matrices instead of\n$0/1$ scalars in the programs defining the classical parameters. We can\nformulate these quantum parameters as conic linear programs over the cone\n$\\mathcal{CS}_+^n$. Using this conic approach we can recover the bounds in\nterms of the theta number and define further approximations by exploiting the\nlink to trace positive polynomials. \n\n"}
{"id": "1312.7035", "contents": "Title: Shape-constrained Estimation of Value Functions Abstract: We present a fully nonparametric method to estimate the value function, via\nsimulation, in the context of expected infinite-horizon discounted rewards for\nMarkov chains. Estimating such value functions plays an important role in\napproximate dynamic programming and applied probability in general. We\nincorporate \"soft information\" into the estimation algorithm, such as knowledge\nof convexity, monotonicity, or Lipchitz constants. In the presence of such\ninformation, a nonparametric estimator for the value function can be computed\nthat is provably consistent as the simulated time horizon tends to infinity. As\nan application, we implement our method on price tolling agreement contracts in\nenergy markets. \n\n"}
{"id": "1312.7853", "contents": "Title: Communication Efficient Distributed Optimization using an Approximate\n  Newton-type Method Abstract: We present a novel Newton-type method for distributed optimization, which is\nparticularly well suited for stochastic optimization and learning problems. For\nquadratic objectives, the method enjoys a linear rate of convergence which\nprovably \\emph{improves} with the data size, requiring an essentially constant\nnumber of iterations under reasonable assumptions. We provide theoretical and\nempirical evidence of the advantages of our method compared to other\napproaches, such as one-shot parameter averaging and ADMM. \n\n"}
{"id": "1401.0604", "contents": "Title: Particle Gibbs with Ancestor Sampling Abstract: Particle Markov chain Monte Carlo (PMCMC) is a systematic way of combining\nthe two main tools used for Monte Carlo statistical inference: sequential Monte\nCarlo (SMC) and Markov chain Monte Carlo (MCMC). We present a novel PMCMC\nalgorithm that we refer to as particle Gibbs with ancestor sampling (PGAS).\nPGAS provides the data analyst with an off-the-shelf class of Markov kernels\nthat can be used to simulate the typically high-dimensional and highly\nautocorrelated state trajectory in a state-space model. The ancestor sampling\nprocedure enables fast mixing of the PGAS kernel even when using seemingly few\nparticles in the underlying SMC sampler. This is important as it can\nsignificantly reduce the computational burden that is typically associated with\nusing SMC. PGAS is conceptually similar to the existing PG with backward\nsimulation (PGBS) procedure. Instead of using separate forward and backward\nsweeps as in PGBS, however, we achieve the same effect in a single forward\nsweep. This makes PGAS well suited for addressing inference problems not only\nin state-space models, but also in models with more complex dependencies, such\nas non-Markovian, Bayesian nonparametric, and general probabilistic graphical\nmodels. \n\n"}
{"id": "1401.3229", "contents": "Title: Principal Component Analysis in an Asymmetric Norm Abstract: Principal component analysis (PCA) is a widely used dimension reduction tool\nin the analysis of many kind of high-dimensional data. It is used in signal\nprocessing, mechanical engineering, psychometrics, and other fields under\ndifferent names. It still bears the same mathematical idea: the decomposition\nof variation of a high dimensional object into uncorrelated factors or\ncomponents. However, in many of the above applications, one is interested in\ncapturing the tail variables of the data rather than variation around the mean.\nSuch applications include weather related event curves, expected shortfalls,\nand speeding analysis among others. These are all high dimensional tail objects\nwhich one would like to study in a PCA fashion. The tail character though\nrequires to do the dimension reduction in an asymmetric norm rather than the\nclassical $L_2$-type orthogonal projection. We develop an analogue of PCA in an\nasymmetric norm. These norms cover both quantiles and expectiles, another tail\nevent measure. The difficulty is that there is no natural basis, no `principal\ncomponents', to the $k$-dimensional subspace found. We propose two definitions\nof principal components and provide algorithms based on iterative least\nsquares. We prove upper bounds on their convergence times, and compare their\nperformances in a simulation study. We apply the algorithms to a Chinese\nweather dataset with a view to weather derivative pricing \n\n"}
{"id": "1401.6476", "contents": "Title: Adaptive Video Streaming in MU-MIMO Networks Abstract: We consider extensions and improvements on our previous work on dynamic\nadaptive video streaming in a multi-cell multiuser ``small cell'' wireless\nnetwork. Previously, we treated the case of single-antenna base stations and,\nstarting from a network utility maximization (NUM) formulation, we devised a\n``push'' scheduling policy, where users place requests to sequential video\nchunks to possibly different base stations with adaptive video quality, and\nbase stations schedule their downlink transmissions in order to stabilize their\ntransmission queues. In this paper we consider a ``pull'' strategy, where every\nuser maintains a request queue, such that users keep track of the video chunks\nthat are effectively delivered. The pull scheme allows to download the chunks\nin the playback order without skipping or missing them. In addition, motivated\nby the recent/forthcoming progress in small cell networks (e.g., in wave-2 of\nthe recent IEEE 802.11ac standard), we extend our dynamic streaming approach to\nthe case of base stations capable of multiuser MIMO downlink, i.e., serving\nmultiple users on the same time-frequency slot by spatial multiplexing. By\nexploiting the ``channel hardening'' effect of high dimensional MIMO channels,\nwe devise a low complexity user selection scheme to solve the underlying\nmax-weighted rate scheduling, which can be easily implemented and runs\nindependently at each base station. Through simulations, we show MIMO gains in\nterms of video streaming QoE metrics like the pre-buffering and re-buffering\ntimes. \n\n"}
{"id": "1401.7625", "contents": "Title: RES: Regularized Stochastic BFGS Algorithm Abstract: RES, a regularized stochastic version of the Broyden-Fletcher-Goldfarb-Shanno\n(BFGS) quasi-Newton method is proposed to solve convex optimization problems\nwith stochastic objectives. The use of stochastic gradient descent algorithms\nis widespread, but the number of iterations required to approximate optimal\narguments can be prohibitive in high dimensional problems. Application of\nsecond order methods, on the other hand, is impracticable because computation\nof objective function Hessian inverses incurs excessive computational cost.\nBFGS modifies gradient descent by introducing a Hessian approximation matrix\ncomputed from finite gradient differences. RES utilizes stochastic gradients in\nlieu of deterministic gradients for both, the determination of descent\ndirections and the approximation of the objective function's curvature. Since\nstochastic gradients can be computed at manageable computational cost RES is\nrealizable and retains the convergence rate advantages of its deterministic\ncounterparts. Convergence results show that lower and upper bounds on the\nHessian egeinvalues of the sample functions are sufficient to guarantee\nconvergence to optimal arguments. Numerical experiments showcase reductions in\nconvergence time relative to stochastic gradient descent algorithms and\nnon-regularized stochastic versions of BFGS. An application of RES to the\nimplementation of support vector machines is developed. \n\n"}
{"id": "1401.7838", "contents": "Title: Dynamic Stride Length Adaptation According to Utility And Personal Space Abstract: Pedestrians adjust both speed and stride length when they navigate difficult\nsituations such as tight corners or dense crowds. They try to avoid collisions\nand to preserve their personal space. State-of-the-art pedestrian motion models\nautomatically reduce speed in dense crowds simply because there is no space\nwhere the pedestrians could go. The stride length and its correct adaptation,\nhowever, are rarely considered. This leads to artefacts that impact macroscopic\nobservation parameters such as densities in front of bottlenecks and, through\nthis, flow. Hence modelling stride adaptation is important to increase the\npredictive power of pedestrian models. To achieve this we reformulate the\nproblem as an optimisation problem on a disk around the pedestrian. Each\npedestrian seeks the position that is most attractive in a sense of balanced\ngoals between the search for targets, the need for individual space and the\nneed to keep a distance from obstacles. The need for space is modelled\naccording to findings from psychology defining zones around a person that, when\ninvaded, cause unease. The result is a fully automatic adjustment that allows\ncalibration through meaningful social parameters and that gives visually\nnatural results with an excellent fit to measured experimental data. \n\n"}
{"id": "1402.1010", "contents": "Title: Maximum work extraction and implementation costs for non-equilibrium\n  Maxwell's demons Abstract: In this theoretical study, we determine the maximum amount of work\nextractable in finite time by a demon performing continuous measurements on a\nquadratic Hamiltonian system subjected to thermal fluctuations, in terms of the\ninformation extracted from the system. This is in contrast to many recent\nstudies that focus on demons' maximizing the extracted work over received\ninformation, and operate close to equilibrium. The maximum work demon is found\nto apply a high-gain continuous feedback using a Kalman-Bucy estimate of the\nsystem state. A simple and concrete electrical implementation of the feedback\nprotocol is proposed, which allows for analytic expressions of the flows of\nenergy and entropy inside the demon. This let us show that any implementation\nof the demon must necessarily include an external power source, which we prove\nboth from classical thermodynamics arguments and from a version of Landauer's\nmemory erasure argument extended to non-equilibrium linear systems. \n\n"}
{"id": "1402.1473", "contents": "Title: Near-Optimal Joint Object Matching via Convex Relaxation Abstract: Joint matching over a collection of objects aims at aggregating information\nfrom a large collection of similar instances (e.g. images, graphs, shapes) to\nimprove maps between pairs of them. Given multiple matches computed between a\nfew object pairs in isolation, the goal is to recover an entire collection of\nmaps that are (1) globally consistent, and (2) close to the provided maps ---\nand under certain conditions provably the ground-truth maps. Despite recent\nadvances on this problem, the best-known recovery guarantees are limited to a\nsmall constant barrier --- none of the existing methods find theoretical\nsupport when more than $50\\%$ of input correspondences are corrupted. Moreover,\nprior approaches focus mostly on fully similar objects, while it is practically\nmore demanding to match instances that are only partially similar to each\nother.\n  In this paper, we develop an algorithm to jointly match multiple objects that\nexhibit only partial similarities, given a few pairwise matches that are\ndensely corrupted. Specifically, we propose to recover the ground-truth maps\nvia a parameter-free convex program called MatchLift, following a spectral\nmethod that pre-estimates the total number of distinct elements to be matched.\nEncouragingly, MatchLift exhibits near-optimal error-correction ability, i.e.\nin the asymptotic regime it is guaranteed to work even when a dominant fraction\n$1-\\Theta\\left(\\frac{\\log^{2}n}{\\sqrt{n}}\\right)$ of the input maps behave like\nrandom outliers. Furthermore, MatchLift succeeds with minimal input complexity,\nnamely, perfect matching can be achieved as soon as the provided maps form a\nconnected map graph. We evaluate the proposed algorithm on various benchmark\ndata sets including synthetic examples and real-world examples, all of which\nconfirm the practical applicability of MatchLift. \n\n"}
{"id": "1402.1697", "contents": "Title: Geodesic Density Tracking with Applications to Data Driven Modeling Abstract: Many problems in dynamic data driven modeling deals with distributed rather\nthan lumped observations. In this paper, we show that the Monge-Kantorovich\noptimal transport theory provides a unifying framework to tackle such problems\nin the systems-control parlance. Specifically, given distributional\nmeasurements at arbitrary instances of measurement availability, we show how to\nderive dynamical systems that interpolate the observed distributions along the\ngeodesics. We demonstrate the framework in the context of three specific\nproblems: (i) \\emph{finding a feedback control} to track observed ensembles\nover finite-horizon, (ii) \\emph{finding a model} whose prediction matches the\nobserved distributional data, and (iii) \\emph{refining a baseline model} that\nresults a distribution-level prediction-observation mismatch. We emphasize how\nthe three problems can be posed as variants of the optimal transport problem,\nbut lead to different types of numerical methods depending on the problem\ncontext. Several examples are given to elucidate the ideas. \n\n"}
{"id": "1402.2467", "contents": "Title: A model problem for Mean Field Games on networks Abstract: In [14], Gueant, Lasry and Lions considered the model problem ``What time\ndoes meeting start?'' as a prototype for a general class of optimization\nproblems with a continuum of players, called Mean Field Games problems. In this\npaper we consider a similar model, but with the dynamics of the agents defined\non a network. We discuss appropriate transition conditions at the vertices\nwhich give a well posed problem and we present some numerical results. \n\n"}
{"id": "1402.3466", "contents": "Title: Kernel density estimates in particle filter Abstract: The paper deals with kernel density estimates of filtering densities in the\nparticle filter. The convergence of the estimates is investigated by means of\nFourier analysis. It is shown that the estimates converge to the theoretical\nfiltering densities in the mean integrated squared error under a certain\nassumption on the Sobolev character of the filtering densities. A sufficient\ncondition is presented for the persistence of this Sobolev character over time.\nBoth results are extended to partial derivatives of the estimates and filtering\ndensities. \n\n"}
{"id": "1402.5131", "contents": "Title: Multi-Step Stochastic ADMM in High Dimensions: Applications to Sparse\n  Optimization and Noisy Matrix Decomposition Abstract: We propose an efficient ADMM method with guarantees for high-dimensional\nproblems. We provide explicit bounds for the sparse optimization problem and\nthe noisy matrix decomposition problem. For sparse optimization, we establish\nthat the modified ADMM method has an optimal convergence rate of\n$\\mathcal{O}(s\\log d/T)$, where $s$ is the sparsity level, $d$ is the data\ndimension and $T$ is the number of steps. This matches with the minimax lower\nbounds for sparse estimation. For matrix decomposition into sparse and low rank\ncomponents, we provide the first guarantees for any online method, and prove a\nconvergence rate of $\\tilde{\\mathcal{O}}((s+r)\\beta^2(p) /T) +\n\\mathcal{O}(1/p)$ for a $p\\times p$ matrix, where $s$ is the sparsity level,\n$r$ is the rank and $\\Theta(\\sqrt{p})\\leq \\beta(p)\\leq \\Theta(p)$. Our\nguarantees match the minimax lower bound with respect to $s,r$ and $T$. In\naddition, we match the minimax lower bound with respect to the matrix dimension\n$p$, i.e. $\\beta(p)=\\Theta(\\sqrt{p})$, for many important statistical models\nincluding the independent noise model, the linear Bayesian network and the\nlatent Gaussian graphical model under some conditions. Our ADMM method is based\non epoch-based annealing and consists of inexpensive steps which involve\nprojections on to simple norm balls. Experiments show that for both sparse\noptimization and matrix decomposition problems, our algorithm outperforms the\nstate-of-the-art methods. In particular, we reach higher accuracy with same\ntime complexity. \n\n"}
{"id": "1402.7291", "contents": "Title: Optimal subgradient algorithms with application to large-scale linear\n  inverse problems Abstract: This study addresses some algorithms for solving structured unconstrained\nconvex optimiza- tion problems using first-order information where the\nunderlying function includes high-dimensional data. The primary aim is to\ndevelop an implementable algorithmic framework for solving problems with multi-\nterm composite objective functions involving linear mappings using the optimal\nsubgradient algorithm, OSGA, proposed by Neumaier in [49]. To this end, we\npropose some prox-functions for which the cor- responding subproblem of OSGA is\nsolved in a closed form. Considering various inverse problems arising in signal\nand image processing, machine learning, statistics, we report extensive\nnumerical and compar- isons with several state-of-the-art solvers proposing\nfavourably performance of our algorithm. We also compare with the most widely\nused optimal first-order methods for some smooth and nonsmooth con- vex\nproblems. Surprisingly, when some Nesterov-type optimal methods originally\nproposed for smooth problems are adapted for solving nonsmooth problems by\nsimply passing a subgradient instead of the gradient, the results of these\nsubgradient-based algorithms are competitive and totally interesting for\nsolving nonsmooth problems. Finally, the OSGA software package is available. \n\n"}
{"id": "1403.1341", "contents": "Title: Decentralized Optimal Dispatch of Photovoltaic Inverters in Residential\n  Distribution Systems Abstract: Decentralized methods for computing optimal real and reactive power setpoints\nfor residential photovoltaic (PV) inverters are developed in this paper. It is\nknown that conventional PV inverter controllers, which are designed to extract\nmaximum power at unity power factor, cannot address secondary performance\nobjectives such as voltage regulation and network loss minimization. Optimal\npower flow techniques can be utilized to select which inverters will provide\nancillary services, and to compute their optimal real and reactive power\nsetpoints. Leveraging advances in semidefinite relaxation techniques and\nsparsity-promoting regularizations, such problems can be solved with reduced\ncomputational burden and with optimality guarantees. To enable large-scale\nimplementation, a novel algorithmic framework is introduced - based on the\nso-called alternating direction method of multipliers - by which the optimal\npower flow problem in this setting can be systematically decomposed into\nsub-problems that can be solved in a decentralized fashion by the utility and\ncustomer-owned PV systems with limited exchanges of information. Since the\ncomputational burden is shared among multiple devices and the requirement of\nall-to-all communication can be circumvented, the proposed optimization\napproach scales to large distribution networks. \n\n"}
{"id": "1403.4699", "contents": "Title: A Proximal Stochastic Gradient Method with Progressive Variance\n  Reduction Abstract: We consider the problem of minimizing the sum of two convex functions: one is\nthe average of a large number of smooth component functions, and the other is a\ngeneral convex function that admits a simple proximal mapping. We assume the\nwhole objective function is strongly convex. Such problems often arise in\nmachine learning, known as regularized empirical risk minimization. We propose\nand analyze a new proximal stochastic gradient method, which uses a multi-stage\nscheme to progressively reduce the variance of the stochastic gradient. While\neach iteration of this algorithm has similar cost as the classical stochastic\ngradient method (or incremental gradient method), we show that the expected\nobjective value converges to the optimum at a geometric rate. The overall\ncomplexity of this method is much lower than both the proximal full gradient\nmethod and the standard proximal stochastic gradient method. \n\n"}
{"id": "1403.5536", "contents": "Title: A practical sequential stopping rule for high-dimensional MCMC and its\n  application to spatial-temporal Bayesian models Abstract: A current challenge for many Bayesian analyses is determining when to\nterminate high-dimensional Markov chain Monte Carlo simulations. To this end,\nwe propose using an automated sequential stopping procedure that terminates the\nsimulation when the computational uncertainty is small relative to the\nposterior uncertainty. Such a stopping rule has previously been shown to work\nwell in settings with posteriors of moderate dimension. In this paper, we\nillustrate its utility in high-dimensional simulations while overcoming some\ncurrent computational issues. Further, we investigate the relationship between\nthe stopping rule and effective sample size. As examples, we consider two\ncomplex Bayesian analyses on spatially and temporally correlated datasets. The\nfirst involves a dynamic space-time model on weather station data and the\nsecond a spatial variable selection model on fMRI brain imaging data. Our\nresults show the sequential stopping rule is easy to implement, provides\nuncertainty estimates, and performs well in high-dimensional settings. \n\n"}
{"id": "1403.5899", "contents": "Title: Certification of Real Inequalities -- Templates and Sums of Squares Abstract: We consider the problem of certifying lower bounds for real-valued\nmultivariate transcendental functions. The functions we are dealing with are\nnonlinear and involve semialgebraic operations as well as some transcendental\nfunctions like $\\cos$, $\\arctan$, $\\exp$, etc. Our general framework is to use\ndifferent approximation methods to relax the original problem into polynomial\noptimization problems, which we solve by sparse sums of squares relaxations. In\nparticular, we combine the ideas of the maxplus estimators (originally\nintroduced in optimal control) and of the linear templates (originally\nintroduced in static analysis by abstract interpretation). The nonlinear\ntemplates control the complexity of the semialgebraic relaxations at the price\nof coarsening the maxplus approximations. In that way, we arrive at a new -\ntemplate based - certified global optimization method, which exploits both the\nprecision of sums of squares relaxations and the scalability of abstraction\nmethods. We analyze the performance of the method on problems from the global\noptimization literature, as well as medium-size inequalities issued from the\nFlyspeck project. \n\n"}
{"id": "1403.6281", "contents": "Title: Exponential decay properties of a mathematical model for a certain\n  fluid-structure interaction Abstract: In this work, we derive a result of exponential stability for a coupled\nsystem of partial differential equations (PDEs) which governs a certain\nfluid-structure interaction. In particular, a three-dimensional Stokes flow\ninteracts across a boundary interface with a two-dimensional mechanical plate\nequation. In the case that the PDE plate component is rotational inertia-free,\none will have that solutions of this fluid-structure PDE system exhibit an\nexponential rate of decay. By way of proving this decay, an estimate is\nobtained for the resolvent of the associated semigroup generator, an estimate\nwhich is uniform for frequency domain values along the imaginary axis.\nSubsequently, we proceed to discuss relevant point control and boundary control\nscenarios for this fluid-structure PDE model, with an ultimate view to optimal\ncontrol studies on both finite and infinite horizon. (Because of said\nexponential stability result, optimal control of the PDE on time interval\n$(0,\\infty)$ becomes a reasonable problem for contemplation.) \n\n"}
{"id": "1403.6324", "contents": "Title: A characterization of sub-game perfect Nash equilibria for SDEs of mean\n  field type Abstract: We study a class of dynamic decision problems of mean field type with time\ninconsistent cost functionals, and derive a stochastic maximum principle to\ncharacterize subgame perfect Nash equilibrium points. Subsequently, this\napproach is extended to a mean field game to construct decentralized strategies\nand obtain an estimate of their performance. \n\n"}
{"id": "1403.6399", "contents": "Title: Reconstruction of Support of a Measure From Its Moments Abstract: In this paper, we address the problem of reconstruction of support of a\nmeasure from its moments. More precisely, given a finite subset of the moments\nof a measure, we develop a semidefinite program for approximating the support\nof measure using level sets of polynomials. To solve this problem, a sequence\nof convex relaxations is provided, whose optimal solution is shown to converge\nto the support of measure of interest. Moreover, the provided approach is\nmodified to improve the results for uniform measures. Numerical examples are\npresented to illustrate the performance of the proposed approach. \n\n"}
{"id": "1404.2458", "contents": "Title: r-Extreme Signalling for Congestion Control Abstract: In many \"smart city\" applications, congestion arises in part due to the\nnature of signals received by individuals from a central authority. In the\nmodel of Marecek et al. [arXiv:1406.7639, Int. J. Control 88(10), 2015], each\nagent uses one out of multiple resources at each time instant. The per-use cost\nof a resource depends on the number of concurrent users. A central authority\nhas up-to-date knowledge of the congestion across all resources and uses\nrandomisation to provide a scalar or an interval for each resource at each\ntime. In this paper, the interval to broadcast per resource is obtained by\ntaking the minima and maxima of costs observed within a time window of length\nr, rather than by randomisation. We show that the resulting distribution of\nagents across resources also converges in distribution, under plausible\nassumptions about the evolution of the population over time. \n\n"}
{"id": "1404.2553", "contents": "Title: Noisy Optimization: Convergence with a Fixed Number of Resamplings Abstract: It is known that evolution strategies in continuous domains might not\nconverge in the presence of noise. It is also known that, under mild\nassumptions, and using an increasing number of resamplings, one can mitigate\nthe effect of additive noise and recover convergence. We show new sufficient\nconditions for the convergence of an evolutionary algorithm with constant\nnumber of resamplings; in particular, we get fast rates (log-linear\nconvergence) provided that the variance decreases around the optimum slightly\nfaster than in the so-called multiplicative noise model. Keywords: Noisy\noptimization, evolutionary algorithm, theory. \n\n"}
{"id": "1404.5222", "contents": "Title: Self-Averaging Property of Minimal Investment Risk of Mean-Variance\n  Model Abstract: In portfolio optimization problems, the minimum expected investment risk is\nnot always smaller than the expected minimal investment risk. That is, using a\nwell-known approach from operations research, it is possible to derive a\nstrategy that minimizes the expected investment risk, but this strategy does\nnot always result in the best rate of return on assets. Prior to making\ninvestment decisions, it is important to an investor to know the potential\nminimal investment risk (or the expected minimal investment risk) and to\ndetermine the strategy that will maximize the return on assets. We use the\nself-averaging property to analyze the potential minimal investment risk and\nthe concentrated investment level for the strategy that gives the best rate of\nreturn. We compare the results from our method with the results obtained by the\noperations research approach and with those obtained by a numerical simulation\nusing the optimal portfolio. The results of our method and the numerical\nsimulation are in agreement, but they differ from that of the operations\nresearch approach. \n\n"}
{"id": "1404.5692", "contents": "Title: Forward - Backward Greedy Algorithms for Atomic Norm Regularization Abstract: In many signal processing applications, the aim is to reconstruct a signal\nthat has a simple representation with respect to a certain basis or frame.\nFundamental elements of the basis known as \"atoms\" allow us to define \"atomic\nnorms\" that can be used to formulate convex regularizations for the\nreconstruction problem. Efficient algorithms are available to solve these\nformulations in certain special cases, but an approach that works well for\ngeneral atomic norms, both in terms of speed and reconstruction accuracy,\nremains to be found. This paper describes an optimization algorithm called\nCoGEnT that produces solutions with succinct atomic representations for\nreconstruction problems, generally formulated with atomic-norm constraints.\nCoGEnT combines a greedy selection scheme based on the conditional gradient\napproach with a backward (or \"truncation\") step that exploits the quadratic\nnature of the objective to reduce the basis size. We establish convergence\nproperties and validate the algorithm via extensive numerical experiments on a\nsuite of signal processing applications. Our algorithm and analysis also allow\nfor inexact forward steps and for occasional enhancements of the current\nrepresentation to be performed. CoGEnT can outperform the basic conditional\ngradient method, and indeed many methods that are tailored to specific\napplications, when the enhancement and truncation steps are defined\nappropriately. We also introduce several novel applications that are enabled by\nthe atomic-norm framework, including tensor completion, moment problems in\nsignal processing, and graph deconvolution. \n\n"}
{"id": "1405.0736", "contents": "Title: Boltzmann type control of opinion consensus through leaders Abstract: The study of formations and dynamics of opinions leading to the so called\nopinion consensus is one of the most important areas in mathematical modeling\nof social sciences. Following the Boltzmann type control recently introduced in\n[G. Albi, M. Herty, L. Pareschi arXiv:1401.7798], we consider a group of\nopinion leaders which modify their strategy accordingly to an objective\nfunctional with the aim to achieve opinion consensus. The main feature of the\nBoltzmann type control is that, thanks to an instantaneous binary control\nformulation, it permits to embed the minimization of the cost functional into\nthe microscopic leaders interactions of the corresponding Boltzmann equation.\nThe related Fokker-Planck asymptotic limits are also derived which allow to\ngive explicit expressions of stationary solutions. The results demonstrate the\nvalidity of the Boltzmann type control approach and the capability of the\nleaders control to strategically lead the followers opinion. \n\n"}
{"id": "1405.2363", "contents": "Title: A sampling-based approach to scalable constraint satisfaction in linear\n  sampled-data systems---Part I: Computation Abstract: Sampled-data (SD) systems, which are composed of both discrete- and\ncontinuous-time components, are arguably one of the most common classes of\ncyberphysical systems in practice; most modern controllers are implemented on\ndigital platforms while the plant dynamics that are being controlled evolve\ncontinuously in time. As with all cyberphysical systems, ensuring hard\nconstraint satisfaction is key in the safe operation of SD systems. A powerful\nanalytical tool for guaranteeing such constraint satisfaction is the viability\nkernel: the set of all initial conditions for which a safety-preserving control\nlaw (that is, a control law that satisfies all input and state constraints)\nexists. In this paper we present a novel sampling-based algorithm that tightly\napproximates the viability kernel for high-dimensional sampled-data linear\ntime-invariant (LTI) systems. Unlike prior work in this area, our algorithm\nformally handles both the discrete and continuous characteristics of SD\nsystems. We prove the correctness and convergence of our approximation\ntechnique, provide discussions on heuristic methods to optimally bias the\nsampling process, and demonstrate the results on a twelve-dimensional flight\nenvelope protection problem. \n\n"}
{"id": "1405.3034", "contents": "Title: G-AMA: Sparse Gaussian graphical model estimation via alternating\n  minimization Abstract: Several methods have been recently proposed for estimating sparse Gaussian\ngraphical models using $\\ell_{1}$ regularization on the inverse covariance\nmatrix. Despite recent advances, contemporary applications require methods that\nare even faster in order to handle ill-conditioned high dimensional modern day\ndatasets. In this paper, we propose a new method, G-AMA, to solve the sparse\ninverse covariance estimation problem using Alternating Minimization Algorithm\n(AMA), that effectively works as a proximal gradient algorithm on the dual\nproblem. Our approach has several novel advantages over existing methods.\nFirst, we demonstrate that G-AMA is faster than the previous best algorithms by\nmany orders of magnitude and is thus an ideal approach for modern high\nthroughput applications. Second, global linear convergence of G-AMA is\ndemonstrated rigorously, underscoring its good theoretical properties. Third,\nthe dual algorithm operates on the covariance matrix, and thus easily\nfacilitates incorporating additional constraints on pairwise/marginal\nrelationships between feature pairs based on domain specific knowledge. Over\nand above estimating a sparse inverse covariance matrix, we also illustrate how\nto (1) incorporate constraints on the (bivariate) correlations and, (2)\nincorporate equality (equisparsity) or linear constraints between individual\ninverse covariance elements. Fourth, we also show that G-AMA is better adept at\nhandling extremely ill-conditioned problems, as is often the case with real\ndata. The methodology is demonstrated on both simulated and real datasets to\nillustrate its superior performance over recently proposed methods. \n\n"}
{"id": "1405.4980", "contents": "Title: Convex Optimization: Algorithms and Complexity Abstract: This monograph presents the main complexity theorems in convex optimization\nand their corresponding algorithms. Starting from the fundamental theory of\nblack-box optimization, the material progresses towards recent advances in\nstructural optimization and stochastic optimization. Our presentation of\nblack-box optimization, strongly influenced by Nesterov's seminal book and\nNemirovski's lecture notes, includes the analysis of cutting plane methods, as\nwell as (accelerated) gradient descent schemes. We also pay special attention\nto non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror\ndescent, and dual averaging) and discuss their relevance in machine learning.\nWe provide a gentle introduction to structural optimization with FISTA (to\noptimize a sum of a smooth and a simple non-smooth term), saddle-point mirror\nprox (Nemirovski's alternative to Nesterov's smoothing), and a concise\ndescription of interior point methods. In stochastic optimization we discuss\nstochastic gradient descent, mini-batches, random coordinate descent, and\nsublinear algorithms. We also briefly touch upon convex relaxation of\ncombinatorial problems and the use of randomness to round solutions, as well as\nrandom walks based methods. \n\n"}
{"id": "1405.5576", "contents": "Title: On the Theoretical Guarantees for Parameter Estimation of Gaussian\n  Random Field Models: A Sparse Precision Matrix Approach Abstract: Iterative methods for fitting a Gaussian Random Field (GRF) model via maximum\nlikelihood (ML) estimation requires solving a nonconvex optimization problem.\nThe problem is aggravated for anisotropic GRFs where the number of covariance\nfunction parameters increases with the dimension. Even evaluation of the\nlikelihood function requires $O(n^3)$ floating point operations, where $n$\ndenotes the number of data locations. In this paper, we propose a new two-stage\nprocedure to estimate the parameters of second-order stationary GRFs. First, a\nconvex likelihood problem regularized with a weighted $\\ell_1$-norm, utilizing\nthe available distance information between observation locations, is solved to\nfit a sparse precision (inverse covariance) matrix to the observed data.\nSecond, the parameters of the covariance function are estimated by solving a\nleast squares problem. Theoretical error bounds for the solutions of stage I\nand II problems are provided, and their tightness are investigated. \n\n"}
{"id": "1405.5960", "contents": "Title: LASS: a simple assignment model with Laplacian smoothing Abstract: We consider the problem of learning soft assignments of $N$ items to $K$\ncategories given two sources of information: an item-category similarity\nmatrix, which encourages items to be assigned to categories they are similar to\n(and to not be assigned to categories they are dissimilar to), and an item-item\nsimilarity matrix, which encourages similar items to have similar assignments.\nWe propose a simple quadratic programming model that captures this intuition.\nWe give necessary conditions for its solution to be unique, define an\nout-of-sample mapping, and derive a simple, effective training algorithm based\non the alternating direction method of multipliers. The model predicts\nreasonable assignments from even a few similarity values, and can be seen as a\ngeneralization of semisupervised learning. It is particularly useful when items\nnaturally belong to multiple categories, as for example when annotating\ndocuments with keywords or pictures with tags, with partially tagged items, or\nwhen the categories have complex interrelations (e.g. hierarchical) that are\nunknown. \n\n"}
{"id": "1406.0808", "contents": "Title: Robust improper maximum likelihood: tuning, computation, and a\n  comparison with other methods for robust Gaussian clustering Abstract: The two main topics of this paper are the introduction of the \"optimally\ntuned improper maximum likelihood estimator\" (OTRIMLE) for robust clustering\nbased on the multivariate Gaussian model for clusters, and a comprehensive\nsimulation study comparing the OTRIMLE to Maximum Likelihood in Gaussian\nmixtures with and without noise component, mixtures of t-distributions, and the\nTCLUST approach for trimmed clustering. The OTRIMLE uses an improper constant\ndensity for modelling outliers and noise. This can be chosen optimally so that\nthe non-noise part of the data looks as close to a Gaussian mixture as\npossible. Some deviation from Gaussianity can be traded in for lowering the\nestimated noise proportion. Covariance matrix constraints and computation of\nthe OTRIMLE are also treated. In the simulation study, all methods are\nconfronted with setups in which their model assumptions are not exactly\nfulfilled, and in order to evaluate the experiments in a standardized way by\nmisclassification rates, a new model-based definition of \"true clusters\" is\nintroduced that deviates from the usual identification of mixture components\nwith clusters. In the study, every method turns out to be superior for one or\nmore setups, but the OTRIMLE achieves the most satisfactory overall\nperformance. The methods are also applied to two real datasets, one without and\none with known \"true\" clusters. \n\n"}
{"id": "1406.0942", "contents": "Title: SDPNAL$+$: A Majorized Semismooth Newton-CG Augmented Lagrangian Method\n  for Semidefinite Programming with Nonnegative Constraints Abstract: In this paper, we present a majorized semismooth Newton-CG augmented\nLagrangian method, called SDPNAL$+$, for semidefinite programming (SDP) with\npartial or full nonnegative constraints on the matrix variable. SDPNAL$+$ is a\nmuch enhanced version of SDPNAL introduced by Zhao, Sun and Toh [SIAM Journal\non Optimization, 20 (2010), pp.~1737--1765] for solving generic SDPs. SDPNAL\nworks very efficiently for nondegenerate SDPs but may encounter numerical\ndifficulty for degenerate ones. Here we tackle this numerical difficulty by\nemploying a majorized semismooth Newton-CG augmented Lagrangian method coupled\nwith a convergent 3-block alternating direction method of multipliers\nintroduced recently by Sun, Toh and Yang [arXiv preprint arXiv:1404.5378,\n(2014)]. Numerical results for various large scale SDPs with or without\nnonnegative constraints show that the proposed method is not only fast but also\nrobust in obtaining accurate solutions. It outperforms, by a significant\nmargin, two other competitive publicly available first order methods based\ncodes: (1) an alternating direction method of multipliers based solver called\nSDPAD by Wen, Goldfarb and Yin [Mathematical Programming Computation, 2 (2010),\npp.~203--230] and (2) a two-easy-block-decomposition hybrid proximal\nextragradient method called 2EBD-HPE by Monteiro, Ortiz and Svaiter\n[Mathematical Programming Computation, (2013), pp.~1--48]. In contrast to these\ntwo codes, we are able to solve all the 95 difficult SDP problems arising from\nthe relaxations of quadratic assignment problems tested in SDPNAL to an\naccuracy of $10^{-6}$ efficiently, while SDPAD and 2EBD-HPE successfully solve\n30 and 16 problems, respectively. \n\n"}
{"id": "1406.1089", "contents": "Title: A variational approach to stable principal component pursuit Abstract: We introduce a new convex formulation for stable principal component pursuit\n(SPCP) to decompose noisy signals into low-rank and sparse representations. For\nnumerical solutions of our SPCP formulation, we first develop a convex\nvariational framework and then accelerate it with quasi-Newton methods. We\nshow, via synthetic and real data experiments, that our approach offers\nadvantages over the classical SPCP formulations in scalability and practical\nparameter selection. \n\n"}
{"id": "1406.2572", "contents": "Title: Identifying and attacking the saddle point problem in high-dimensional\n  non-convex optimization Abstract: A central challenge to many fields of science and engineering involves\nminimizing non-convex error functions over continuous, high dimensional spaces.\nGradient descent or quasi-Newton methods are almost ubiquitously used to\nperform such minimizations, and it is often thought that a main source of\ndifficulty for these local methods to find the global minimum is the\nproliferation of local minima with much higher error than the global minimum.\nHere we argue, based on results from statistical physics, random matrix theory,\nneural network theory, and empirical evidence, that a deeper and more profound\ndifficulty originates from the proliferation of saddle points, not local\nminima, especially in high dimensional problems of practical interest. Such\nsaddle points are surrounded by high error plateaus that can dramatically slow\ndown learning, and give the illusory impression of the existence of a local\nminimum. Motivated by these arguments, we propose a new approach to\nsecond-order optimization, the saddle-free Newton method, that can rapidly\nescape high dimensional saddle points, unlike gradient descent and quasi-Newton\nmethods. We apply this algorithm to deep or recurrent neural network training,\nand provide numerical evidence for its superior optimization performance. \n\n"}
{"id": "1406.5281", "contents": "Title: Exploiting Symmetries in Polyhedral Computations Abstract: In this note we give a short overview on symmetry exploiting techniques in\nthree different branches of polyhedral computations: The representation\nconversion problem, integer linear programming and lattice point counting. We\ndescribe some of the future challenges and sketch some directions of potential\ndevelopments. \n\n"}
{"id": "1406.5403", "contents": "Title: A Primal-Dual Algorithmic Framework for Constrained Convex Minimization Abstract: We present a primal-dual algorithmic framework to obtain approximate\nsolutions to a prototypical constrained convex optimization problem, and\nrigorously characterize how common structural assumptions affect the numerical\nefficiency. Our main analysis technique provides a fresh perspective on\nNesterov's excessive gap technique in a structured fashion and unifies it with\nsmoothing and primal-dual methods. For instance, through the choices of a dual\nsmoothing strategy and a center point, our framework subsumes decomposition\nalgorithms, augmented Lagrangian as well as the alternating direction\nmethod-of-multipliers methods as its special cases, and provides optimal\nconvergence rates on the primal objective residual as well as the primal\nfeasibility gap of the iterates for all. \n\n"}
{"id": "1406.5839", "contents": "Title: Control of MTDC Transmission Systems under Local Information Abstract: High-voltage direct current (HVDC) is a commonly used technology for\nlong-distance electric power transmission, mainly due to its low resistive\nlosses. In this paper a distributed controller for multi-terminal high-voltage\ndirect current (MTDC) transmission systems is considered. Sufficient conditions\nfor when the proposed controller renders the closed-loop system asymptotically\nstable are provided. Provided that the closed loop system is asymptotically\nstable, it is shown that in steady-state a weighted average of the deviations\nfrom the nominal voltages is zero. Furthermore, a quadratic cost of the current\ninjections is minimized asymptotically. \n\n"}
{"id": "1406.7648", "contents": "Title: Bayesian Network Constraint-Based Structure Learning Algorithms:\n  Parallel and Optimised Implementations in the bnlearn R Package Abstract: It is well known in the literature that the problem of learning the structure\nof Bayesian networks is very hard to tackle: its computational complexity is\nsuper-exponential in the number of nodes in the worst case and polynomial in\nmost real-world scenarios.\n  Efficient implementations of score-based structure learning benefit from past\nand current research in optimisation theory, which can be adapted to the task\nby using the network score as the objective function to maximise. This is not\ntrue for approaches based on conditional independence tests, called\nconstraint-based learning algorithms. The only optimisation in widespread use,\nbacktracking, leverages the symmetries implied by the definitions of\nneighbourhood and Markov blanket.\n  In this paper we illustrate how backtracking is implemented in recent\nversions of the bnlearn R package, and how it degrades the stability of\nBayesian network structure learning for little gain in terms of speed. As an\nalternative, we describe a software architecture and framework that can be used\nto parallelise constraint-based structure learning algorithms (also implemented\nin bnlearn) and we demonstrate its performance using four reference networks\nand two real-world data sets from genetics and systems biology. We show that on\nmodern multi-core or multiprocessor hardware parallel implementations are\npreferable over backtracking, which was developed when single-processor\nmachines were the norm. \n\n"}
{"id": "1407.0202", "contents": "Title: SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly\n  Convex Composite Objectives Abstract: In this work we introduce a new optimisation method called SAGA in the spirit\nof SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient\nalgorithms with fast linear convergence rates. SAGA improves on the theory\nbehind SAG and SVRG, with better theoretical convergence rates, and has support\nfor composite objectives where a proximal operator is used on the regulariser.\nUnlike SDCA, SAGA supports non-strongly convex problems directly, and is\nadaptive to any inherent strong convexity of the problem. We give experimental\nresults showing the effectiveness of our method. \n\n"}
{"id": "1407.0753", "contents": "Title: Global convergence of splitting methods for nonconvex composite\n  optimization Abstract: We consider the problem of minimizing the sum of a smooth function $h$ with a\nbounded Hessian, and a nonsmooth function. We assume that the latter function\nis a composition of a proper closed function $P$ and a surjective linear map\n$\\cal M$, with the proximal mappings of $\\tau P$, $\\tau > 0$, simple to\ncompute. This problem is nonconvex in general and encompasses many important\napplications in engineering and machine learning. In this paper, we examined\ntwo types of splitting methods for solving this nonconvex optimization problem:\nalternating direction method of multipliers and proximal gradient algorithm.\nFor the direct adaptation of the alternating direction method of multipliers,\nwe show that, if the penalty parameter is chosen sufficiently large and the\nsequence generated has a cluster point, then it gives a stationary point of the\nnonconvex problem. We also establish convergence of the whole sequence under an\nadditional assumption that the functions $h$ and $P$ are semi-algebraic.\nFurthermore, we give simple sufficient conditions to guarantee boundedness of\nthe sequence generated. These conditions can be satisfied for a wide range of\napplications including the least squares problem with the $\\ell_{1/2}$\nregularization. Finally, when $\\cal M$ is the identity so that the proximal\ngradient algorithm can be efficiently applied, we show that any cluster point\nis stationary under a slightly more flexible constant step-size rule than what\nis known in the literature for a nonconvex $h$. \n\n"}
{"id": "1407.1537", "contents": "Title: Linear Coupling: An Ultimate Unification of Gradient and Mirror Descent Abstract: First-order methods play a central role in large-scale machine learning. Even\nthough many variations exist, each suited to a particular problem, almost all\nsuch methods fundamentally rely on two types of algorithmic steps: gradient\ndescent, which yields primal progress, and mirror descent, which yields dual\nprogress.\n  We observe that the performances of gradient and mirror descent are\ncomplementary, so that faster algorithms can be designed by LINEARLY COUPLING\nthe two. We show how to reconstruct Nesterov's accelerated gradient methods\nusing linear coupling, which gives a cleaner interpretation than Nesterov's\noriginal proofs. We also discuss the power of linear coupling by extending it\nto many other settings that Nesterov's methods cannot apply to. \n\n"}
{"id": "1407.4261", "contents": "Title: Mixed Integer Programming to Globally Minimize the Economic Load\n  Dispatch Problem With Valve-Point Effect Abstract: Optimal distribution of power among generating units to meet a specific\ndemand subject to system constraints is an ongoing research topic in the power\nsystem community. The problem, even in a static setting, turns out to be hard\nto solve with conventional optimization methods owing to the consideration of\nvalve-point effects which make the cost function nonsmooth and nonconvex. This\ndifficulty gave rise to the proliferation of population-based global heuristics\nin order to address the multi-extremal and nonsmooth problem. In this paper, we\naddress the economic load dispatch problem (ELDP) with valve-point effect in\nits classic formulation where the cost function for each generator is expressed\nas the sum of a quadratic term and a rectified sine term. We propose two\nmethods that resort to piecewise-quadratic surrogate cost functions, yielding\nsurrogate problems that can be handled by mixed-integer quadratic programming\n(MIQP) solvers. The first method shows that the global solution of the ELDP can\noften be found by using a fixed and very limited number of quadratic pieces in\nthe surrogate cost function. The second method adaptively builds\npiecewise-quadratic surrogate under-estimations of the ELDP cost function,\nyielding a sequence of surrogate MIQP problems. It is shown that any limit\npoint of the sequence of MIQP solutions is a global solution of the ELDP.\nMoreover, numerical experiments indicate that the proposed methods outclass the\nstate-of-the-art algorithms in terms of minimization value and computation time\non practical instances. \n\n"}
{"id": "1407.4760", "contents": "Title: What Makes a Good Plan? An Efficient Planning Approach to Control\n  Diffusion Processes in Networks Abstract: In this paper, we analyze the quality of a large class of simple dynamic\nresource allocation (DRA) strategies which we name priority planning. Their aim\nis to control an undesired diffusion process by distributing resources to the\ncontagious nodes of the network according to a predefined priority-order. In\nour analysis, we reduce the DRA problem to the linear arrangement of the nodes\nof the network. Under this perspective, we shed light on the role of a\nfundamental characteristic of this arrangement, the maximum cutwidth, for\nassessing the quality of any priority planning strategy. Our theoretical\nanalysis validates the role of the maximum cutwidth by deriving bounds for the\nextinction time of the diffusion process. Finally, using the results of our\nanalysis, we propose a novel and efficient DRA strategy, called Maximum\nCutwidth Minimization, that outperforms other competing strategies in our\nsimulations. \n\n"}
{"id": "1407.5144", "contents": "Title: Lower Bounds on the Oracle Complexity of Nonsmooth Convex Optimization\n  via Information Theory Abstract: We present an information-theoretic approach to lower bound the oracle\ncomplexity of nonsmooth black box convex optimization, unifying previous lower\nbounding techniques by identifying a combinatorial problem, namely string\nguessing, as a single source of hardness. As a measure of complexity we use\ndistributional oracle complexity, which subsumes randomized oracle complexity\nas well as worst-case oracle complexity. We obtain strong lower bounds on\ndistributional oracle complexity for the box $[-1,1]^n$, as well as for the\n$L^p$-ball for $p \\geq 1$ (for both low-scale and large-scale regimes),\nmatching worst-case upper bounds, and hence we close the gap between\ndistributional complexity, and in particular, randomized complexity, and\nworst-case complexity. Furthermore, the bounds remain essentially the same for\nhigh-probability and bounded-error oracle complexity, and even for combination\nof the two, i.e., bounded-error high-probability oracle complexity. This\nconsiderably extends the applicability of known bounds. \n\n"}
{"id": "1407.5470", "contents": "Title: Applying a phase field approach for shape optimization of a stationary\n  Navier-Stokes flow Abstract: We apply a phase field approach for a general shape optimization problem of a\nstationary Navier-Stokes flow. To be precise we add a multiple of the\nGinzburg--Landau energy as a regularization to the objective functional and\nrelax the non-permeability of the medium outside the fluid region. The\nresulting diffuse interface problem can be shown to be well-posed and\noptimality conditions are derived. We state suitable assumptions on the problem\nin order to derive a sharp interface limit for the minimizers and the\noptimality conditions. Additionally, we can derive a necessary optimality\nsystem for the sharp interface problem by geometric variations without stating\nadditional regularity assumptions on the minimizing set. \n\n"}
{"id": "1407.7024", "contents": "Title: Second order mean field games with degenerate diffusion and local\n  coupling Abstract: We analyze a (possibly degenerate) second order mean field games system of\npartial differential equations. The distinguishing features of the model\nconsidered are (1) that it is not uniformly parabolic, including the first\norder case as a possibility, and (2) the coupling is a local operator on the\ndensity. As a result we look for weak, not smooth, solutions. Our main result\nis the existence and uniqueness of suitably defined weak solutions, which are\ncharacterized as minimizers of two optimal control problems. We also show that\nsuch solutions are stable with respect to the data, so that in particular the\ndegenerate case can be approximated by a uniformly parabolic (viscous)\nperturbation. \n\n"}
{"id": "1407.7422", "contents": "Title: An inequality \\`a la Szeg\\H{o}-Weinberger for the $p-$Laplacian on\n  convex sets Abstract: In this paper we prove a sharp inequality of Szeg\\H{o}-Weinberger type for\nthe first nontrivial eigenvalue of the $p-$Laplacian with Neumann boundary\nconditions. This applies to convex sets with given diameter. Some variants,\nextensions and limit cases are investigated as well. \n\n"}
{"id": "1407.7810", "contents": "Title: Models and Feedback Stabilization of Open Quantum Systems Abstract: At the quantum level, feedback-loops have to take into account measurement\nback-action. We present here the structure of the Markovian models including\nsuch back-action and sketch two stabilization methods: measurement-based\nfeedback where an open quantum system is stabilized by a classical controller;\ncoherent or autonomous feedback where a quantum system is stabilized by a\nquantum controller with decoherence (reservoir engineering). We begin to\nexplain these models and methods for the photon box experiments realized in the\ngroup of Serge Haroche (Nobel Prize 2012). We present then these models and\nmethods for general open quantum systems. \n\n"}
{"id": "1407.8380", "contents": "Title: Sufficient Lie Algebraic Conditions for Sampled-Data Feedback\n  Stabilizability of Affine in the Control Nonlinear Systems Abstract: For general nonlinear autonomous systems, a Lyapunov characterization for the\npossibility of semi-global asymptotic stabilizability by means of a\ntime-varying sampled-data feedback is established. We exploit this result in\norder to derive a Lie algebraic sufficient condition for sampled-data feedback\nsemi-global stabilizability of affine in the control nonlinear systems with\nnon-zero drift terms. The corresponding proposition constitutes an extension of\nthe \"Artstein-Sontag\" theorem on feedback stabilization. \n\n"}
{"id": "1408.1324", "contents": "Title: Unit balls of constant volume: which one has optimal representation? Abstract: In the family of unit balls with constant volume we look at the ones whose\nalgebraic representation has some extremal property. We consider the family of\nnonnegative homogeneous polynomials of even degree $d$ whose sublevel set\n$\\G=\\{\\x: g(\\x)\\leq 1\\}$ (a unit ball) has same fixed volume and want to find\nin this family the one that minimizes either the $\\ell_1$-norm or the\n$\\ell_2$-norm of its vector of coefficients. Equivalently, among all degree-$d$\npolynomials of constant $\\ell_1-$ or $\\ell_2$-norm, which one minimizes the\nvolume of its level set $\\G$. We first show that in both cases this is a convex\noptimization problem with a unique optimal solution $g^*_1$ and $g^*_2$\nrespectively. We also show that $g^*_1$ is the $L_p$-norm polynomial\n$\\x\\mapsto\\sum_{i=1}^n x_i^{p}$, thus recovering a parsimony property of the\n$L_p$-norm via $\\ell_1$-norm minimization. (Indeed $n=\\Vert g^*_1\\Vert_0$ is\nthe minimum number of non-zero coefficient for $\\G$ to have finite volume.)\nThis once again illustrates the power and versatility of the $\\ell_1$-norm\nrelaxation strategy in optimization when one searches for an optimal solution\nwith parsimony properties. Next we show that $g^*_2$ is not sparse at all (and\nso differs from $g^*_1$) but is still a sum of $p$-powers of linear forms. We\nalso characterize the unique optimal solution of the same problem where one\nsearches for an SOS homogeneous polynomial that minimizes the trace of its\nassociated (psd) Gram matrix, hence aiming at finding a solution which is a sum\nof a few squares only. Finally, we also extend these results to generalized\nhomogeneous polynomials, which includes $L_p$-norms when $0 \n\n"}
{"id": "1408.3907", "contents": "Title: On average control generating families for singularly perturbed optimal\n  control problems with long run average optimality criteria Abstract: The paper aims at the development of tools for analysis and construction of\nnear optimal solutions of singularly perturbed (SP) optimal controls problems\nwith long run average optimality criteria. The idea that we exploit is to first\nasymptotically approximate a given problem of optimal control of the SP system\nby a certain averaged optimal control problem, then reformulate this averaged\nproblem as an infinite-dimensional (ID) linear programming (LP) problem, and\nthen approximate the latter by semi-infinite LP problems. We show that the\noptimal solution of these semi-infinite LP problems and their duals (that can\nbe found with the help of a modification of an available LP software) allow one\nto construct near optimal controls of the SP system. We demonstrate the\nconstruction with a numerical example. \n\n"}
{"id": "1408.4213", "contents": "Title: Reflection methods for inverse problems with application to protein\n  conformation determination Abstract: The Douglas-Rachford reflection method is a general purpose algorithm useful\nfor solving the feasibility problem of finding a point in the intersection of\nfinitely many sets. In this chapter we demonstrate that applied to a specific\nproblem, the method can benefit from heuristics specific to said problem which\nexploit its special structure. In particular, we focus on the problem of\nprotein conformation determination formulated within the framework of matrix\ncompletion, as was considered in a recent paper of the present authors. \n\n"}
{"id": "1408.4266", "contents": "Title: On the Global Linear Convergence of the ADMM with Multi-Block Variables Abstract: The alternating direction method of multipliers (ADMM) has been widely used\nfor solving structured convex optimization problems. In particular, the ADMM\ncan solve convex programs that minimize the sum of $N$ convex functions with\n$N$-block variables linked by some linear constraints. While the convergence of\nthe ADMM for $N=2$ was well established in the literature, it remained an open\nproblem for a long time whether or not the ADMM for $N \\ge 3$ is still\nconvergent. Recently, it was shown in [3] that without further conditions the\nADMM for $N\\ge 3$ may actually fail to converge. In this paper, we show that\nunder some easily verifiable and reasonable conditions the global linear\nconvergence of the ADMM when $N\\geq 3$ can still be assured, which is important\nsince the ADMM is a popular method for solving large scale multi-block\noptimization models and is known to perform very well in practice even when\n$N\\ge 3$. Our study aims to offer an explanation for this phenomenon. \n\n"}
{"id": "1408.4622", "contents": "Title: A new integral loss function for Bayesian optimization Abstract: We consider the problem of maximizing a real-valued continuous function $f$\nusing a Bayesian approach. Since the early work of Jonas Mockus and Antanas\n\\v{Z}ilinskas in the 70's, the problem of optimization is usually formulated by\nconsidering the loss function $\\max f - M_n$ (where $M_n$ denotes the best\nfunction value observed after $n$ evaluations of $f$). This loss function puts\nemphasis on the value of the maximum, at the expense of the location of the\nmaximizer. In the special case of a one-step Bayes-optimal strategy, it leads\nto the classical Expected Improvement (EI) sampling criterion. This is a\nspecial case of a Stepwise Uncertainty Reduction (SUR) strategy, where the risk\nassociated to a certain uncertainty measure (here, the expected loss) on the\nquantity of interest is minimized at each step of the algorithm. In this\narticle, assuming that $f$ is defined over a measure space $(\\mathbb{X},\n\\lambda)$, we propose to consider instead the integral loss function\n$\\int_{\\mathbb{X}} (f - M_n)_{+}\\, d\\lambda$, and we show that this leads, in\nthe case of a Gaussian process prior, to a new numerically tractable sampling\ncriterion that we call $\\rm EI^2$ (for Expected Integrated Expected\nImprovement). A numerical experiment illustrates that a SUR strategy based on\nthis new sampling criterion reduces the error on both the value and the\nlocation of the maximizer faster than the EI-based strategy. \n\n"}
{"id": "1408.4685", "contents": "Title: Partial facial reduction: simplified, equivalent SDPs via approximations\n  of the PSD cone Abstract: We develop a practical semidefinite programming (SDP) facial reduction\nprocedure that utilizes computationally efficient approximations of the\npositive semidefinite cone. The proposed method simplifies SDPs with no\nstrictly feasible solution (a frequent output of parsers) by solving a sequence\nof easier optimization problems and could be a useful pre-processing technique\nfor SDP solvers. We demonstrate effectiveness of the method on SDPs arising in\npractice, and describe our publicly-available software implementation. We also\nshow how to find maximum rank matrices in our PSD cone approximations (which\nhelps us find maximal simplifications), and we give a post-processing procedure\nfor dual solution recovery that generally applies to facial-reduction-based\npre-processing techniques. Finally, we show how approximations can be chosen to\npreserve problem sparsity. \n\n"}
{"id": "1408.5621", "contents": "Title: Multinomial and empirical likelihood under convex constraints:\n  directions of recession, Fenchel duality, perturbations Abstract: The primal problem of multinomial likelihood maximization restricted to a\nconvex closed subset of the probability simplex is studied. Contrary to widely\nheld belief, a solution of this problem may assign a positive mass to an\noutcome with zero count. Related flaws in the simplified Lagrange and Fenchel\ndual problems, which arise because the recession directions are ignored, are\nidentified and corrected.\n  A solution of the primal problem can be obtained by the PP (perturbed primal)\nalgorithm, that is, as the limit of a sequence of solutions of perturbed primal\nproblems. The PP algorithm may be implemented by the simplified Fenchel dual.\n  The results permit us to specify linear sets and data such that the empirical\nlikelihood-maximizing distribution exists and is the same as the multinomial\nlikelihood-maximizing distribution. The multinomial likelihood ratio reaches,\nin general, a different conclusion than the empirical likelihood ratio.\n  Implications for minimum discrimination information, compositional data\nanalysis, Lindsay geometry, bootstrap with auxiliary information, and Lagrange\nmultiplier tests are discussed. \n\n"}
{"id": "1408.5785", "contents": "Title: The variational structure of the space of holonomic measures Abstract: Roughly speaking, holonomic measures are parametric varifolds without\nboundary. They provide a setting appropriate for the analysis of many\nvariational problems. In this paper, we characterize the space of variations\nfor these objects, and we use the characterization to formulate stability\nconditions that are strictly more general than the Euler-Lagrange equations. We\nalso use this characterization to deduce higher-dimensional analogues of energy\nconservation and weak KAM.\n  Along the way, we characterize the distributions that arise as derivatives of\nfamilies of Borel probability measures on smooth manifolds. \n\n"}
{"id": "1408.6070", "contents": "Title: Time Consistent Behavior Portfolio Policy for Dynamic Mean-Variance\n  Formulation Abstract: When we implement a portfolio selection methodology under a mean-risk\nformulation, it is essential to correctly model investors' risk aversion which\nmay be time-dependent, or even state-dependent during the investment procedure.\nIn this paper, we propose a behavior risk aversion model, which is a piecewise\nlinear function of the current wealth level with a reference point at a preset\ninvestment target. Due to the time inconsistency of the resulting multi-period\nmean-variance model with an adaptive risk aversion, we investigate in this\npaper the time consistent behavior portfolio policy by solving a nested\nmean-variance game formulation. We derive semi-analytical time consistent\nbehavior portfolio policy which takes a piecewise linear feedback form of the\ncurrent wealth level with respect to the discounted investment target. \n\n"}
{"id": "1409.0699", "contents": "Title: Symmetric semi-algebraic sets and non-negativity of symmetric\n  polynomials Abstract: The question of how to certify the non-negativity of a polynomial function\nlies at the heart of Real Algebra and it also has important applications to\nOptimization. In the setting of symmetric polynomials Timofte provided a useful\nway of certifying non-negativity of symmetric polynomials that are of a fixed\ndegree. In this note we present more general results which naturally generalize\nTimofte's setting. We investigate families of polynomials that allow special\nrepresentations in terms of power-sum polynomials.These in particular also\ninclude the case of symmetric polynomials of fixed degree. Therefore, we\nrecover the consequences of Timofte's original statements as a corollary. Thus,\nthis note also provides an alternative and simple proof of Timofte's original\nstatements. \n\n"}
{"id": "1409.1458", "contents": "Title: Communication-Efficient Distributed Dual Coordinate Ascent Abstract: Communication remains the most significant bottleneck in the performance of\ndistributed optimization algorithms for large-scale machine learning. In this\npaper, we propose a communication-efficient framework, CoCoA, that uses local\ncomputation in a primal-dual setting to dramatically reduce the amount of\nnecessary communication. We provide a strong convergence rate analysis for this\nclass of algorithms, as well as experiments on real-world distributed datasets\nwith implementations in Spark. In our experiments, we find that as compared to\nstate-of-the-art mini-batch versions of SGD and SDCA algorithms, CoCoA\nconverges to the same .001-accurate solution quality on average 25x as quickly. \n\n"}
{"id": "1409.2162", "contents": "Title: Lipschitz regularity for local minimizers of some widely degenerate\n  problems Abstract: We consider local minimizers of the functional \\[ \\sum_{i=1}^N \\int\n(|u_{x_i}|-\\delta_i)^p_+\\, dx+\\int f\\, u\\, dx, \\] where\n$\\delta_1,\\dots,\\delta_N\\ge 0$ and $(\\,\\cdot\\,)_+$ stands for the positive\npart. Under suitable assumptions on $f$, we prove that local minimizers are\nLipschitz continuous functions if $N=2$ and $p\\ge 2$, or if $N\\ge 2$ and $p\\ge\n4$. \n\n"}
{"id": "1409.2617", "contents": "Title: Large-scale randomized-coordinate descent methods with non-separable\n  linear constraints Abstract: We develop randomized (block) coordinate descent (CD) methods for linearly\nconstrained convex optimization. Unlike most CD methods, we do not assume the\nconstraints to be separable, but let them be coupled linearly. To our\nknowledge, ours is the first CD method that allows linear coupling constraints,\nwithout making the global iteration complexity have an exponential dependence\non the number of constraints. We present algorithms and analysis for four key\nproblem scenarios: (i) smooth; (ii) smooth + nonsmooth separable; (iii)\nasynchronous parallel; and (iv) stochastic. We illustrate empirical behavior of\nour algorithms by simulation experiments. \n\n"}
{"id": "1409.2848", "contents": "Title: A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate Abstract: We describe and analyze a simple algorithm for principal component analysis\nand singular value decomposition, VR-PCA, which uses computationally cheap\nstochastic iterations, yet converges exponentially fast to the optimal\nsolution. In contrast, existing algorithms suffer either from slow convergence,\nor computationally intensive iterations whose runtime scales with the data\nsize. The algorithm builds on a recent variance-reduced stochastic gradient\ntechnique, which was previously analyzed for strongly convex optimization,\nwhereas here we apply it to an inherently non-convex problem, using a very\ndifferent analysis. \n\n"}
{"id": "1409.3383", "contents": "Title: Weak Minimizers, Minimizers and Variational Inequalities for set valued\n  Functions. A blooming wreath? Abstract: In the literature, necessary and sufficient conditions in terms of\nvariational inequalities are introduced to characterize minimizers of convex\nset valued functions with values in a conlinear space. Similar results are\nproved for a weaker concept of minimizers and weaker variational inequalities.\nThe implications are proved using scalarization techniques that eventually\nprovide original problems, not fully equivalent to the set-valued counterparts.\nTherefore, we try, in the course of this note, to close the network among the\nvarious notions proposed. More specifically, we prove that a minimizer is\nalways a weak minimizer, and a solution to the stronger variational inequality\nalways also a solution to the weak variational inequality of the same type. As\na special case we obtain a complete characterization of efficiency and weak\nefficiency in vector optimization by set-valued variational inequalities and\ntheir scalarizations. Indeed this might eventually prove the usefulness of the\nset-optimization approach to renew the study of vector optimization. \n\n"}
{"id": "1409.5319", "contents": "Title: Duality for the left and right fractional derivatives Abstract: We prove duality between the left and right fractional derivatives,\nindependently on the type of fractional operator. Main result asserts that the\nright derivative of a function is the dual of the left derivative of the dual\nfunction or, equivalently, the left derivative of a function is the dual of the\nright derivative of the dual function. Such duality between left and right\nfractional operators is useful to obtain results for the left operators from\nanalogous results on the right operators and vice versa. We illustrate the\nusefulness of our duality theory by proving a fractional integration by parts\nformula for the right Caputo derivative and by proving a Tonelli-type theorem\nthat ensures the existence of minimizer for fractional variational problems\nwith right fractional operators. \n\n"}
{"id": "1409.6019", "contents": "Title: Robust Clustering in Regression Analysis via the Contaminated Gaussian\n  Cluster-Weighted Model Abstract: The Gaussian cluster-weighted model (CWM) is a mixture of regression models\nwith random covariates that allows for flexible clustering of a random vector\ncomposed of response variables and covariates. In each mixture component, it\nadopts a Gaussian distribution for both the covariates and the responses given\nthe covariates. To robustify the approach with respect to possible elliptical\nheavy tailed departures from normality, due to the presence of atypical\nobservations, the contaminated Gaussian CWM is here introduced. In addition to\nthe parameters of the Gaussian CWM, each mixture component of our contaminated\nCWM has a parameter controlling the proportion of outliers, one controlling the\nproportion of leverage points, one specifying the degree of contamination with\nrespect to the response variables, and one specifying the degree of\ncontamination with respect to the covariates. Crucially, these parameters do\nnot have to be specified a priori, adding flexibility to our approach.\nFurthermore, once the model is estimated and the observations are assigned to\nthe groups, a finer intra-group classification in typical points, outliers,\ngood leverage points, and bad leverage points - concepts of primary importance\nin robust regression analysis - can be directly obtained. Relations with other\nmixture-based contaminated models are analyzed, identifiability conditions are\nprovided, an expectation-conditional maximization algorithm is outlined for\nparameter estimation, and various implementation and operational issues are\ndiscussed. Properties of the estimators of the regression coefficients are\nevaluated through Monte Carlo experiments and compared to the estimators from\nthe Gaussian CWM. A sensitivity study is also conducted based on a real data\nset. \n\n"}
{"id": "1409.6573", "contents": "Title: Metamorphosis of Images in Reproducing Kernel Hilbert Spaces Abstract: Metamorphosis is a method for diffeomorphic matching of shapes, with many\npotential applications for anatomical shape comparison in medical imagery, a\nproblem which is central to the field of computational anatomy. An important\ntool for the practical application of metamorphosis is a numerical method based\non shooting from the initial momentum, as this would enable the use of\nstatistical methods based on this momentum, as well as the estimation of\ntemplates from hyper-templates using morphing. In this paper we introduce a\nshooting method, in the particular case of morphing images that lie in a\nreproducing kernel Hilbert space (RKHS). We derive the relevant shooting\nequations from a Lagrangian frame of reference, present the details of the\nnumerical approach, and illustrate the method through morphing of some simple\nimages. \n\n"}
{"id": "1409.8378", "contents": "Title: Sub-Riemannian structures on groups of diffeomorphisms Abstract: In this paper, we define and study strong right-invariant sub-Riemannian\nstructures on the group of diffeomorphisms of a manifold with bounded geometry.\nWe derive the Hamiltonian geodesic equations for such structures, and we\nprovide examples of normal and of abnormal geodesics in that\ninfinite-dimensional context. The momentum formulation gives a sub-Riemannian\nversion of the Euler-Arnol'd equation. Finally, we establish some approximate\nand exact reachability properties for diffeomorphisms, and we give some\nconsequences for Moser theorems. \n\n"}
{"id": "1410.0949", "contents": "Title: Tight Regret Bounds for Stochastic Combinatorial Semi-Bandits Abstract: A stochastic combinatorial semi-bandit is an online learning problem where at\neach step a learning agent chooses a subset of ground items subject to\nconstraints, and then observes stochastic weights of these items and receives\ntheir sum as a payoff. In this paper, we close the problem of computationally\nand sample efficient learning in stochastic combinatorial semi-bandits. In\nparticular, we analyze a UCB-like algorithm for solving the problem, which is\nknown to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$\nand $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is\nthe number of ground items, $K$ is the maximum number of chosen items, and\n$\\Delta$ is the gap between the expected returns of the optimal and best\nsuboptimal solutions. The gap-dependent bound is tight up to a constant factor\nand the gap-free bound is tight up to a polylogarithmic factor. \n\n"}
{"id": "1410.2724", "contents": "Title: Compressed Sensing With Side Information: Geometrical Interpretation and\n  Performance Bounds Abstract: We address the problem of Compressed Sensing (CS) with side information.\nNamely, when reconstructing a target CS signal, we assume access to a similar\nsignal. This additional knowledge, the side information, is integrated into CS\nvia L1-L1 and L1-L2 minimization. We then provide lower bounds on the number of\nmeasurements that these problems require for successful reconstruction of the\ntarget signal. If the side information has good quality, the number of\nmeasurements is significantly reduced via L1-L1 minimization, but not so much\nvia L1-L2 minimization. We provide geometrical interpretations and experimental\nresults illustrating our findings. \n\n"}
{"id": "1410.4812", "contents": "Title: Inference and Mixture Modeling with the Elliptical Gamma Distribution Abstract: We study modeling and inference with the Elliptical Gamma Distribution (EGD).\nWe consider maximum likelihood (ML) estimation for EGD scatter matrices, a task\nfor which we develop new fixed-point algorithms. Our algorithms are efficient\nand converge to global optima despite nonconvexity. Moreover, they turn out to\nbe much faster than both a well-known iterative algorithm of Kent & Tyler\n(1991) and sophisticated manifold optimization algorithms. Subsequently, we\ninvoke our ML algorithms as subroutines for estimating parameters of a mixture\nof EGDs. We illustrate our methods by applying them to model natural image\nstatistics---the proposed EGD mixture model yields the most parsimonious model\namong several competing approaches. \n\n"}
{"id": "1410.6392", "contents": "Title: The Principal-Agent Problem; A Stochastic Maximum Principle Approach Abstract: We study a general class of Principal-Agent problems in continuous time under\nhidden action. By formulating the model as a coupled stochastic optimal control\nproblem we are able to find a set of necessary conditions characterizing\noptimal contracts, using the stochastic maximum principle. An example is\ncarried out to illustrate the proposed approach to the Principal-Agent problem\nunder linear stochastic dynamics with a quadratic performance function. \n\n"}
{"id": "1410.6718", "contents": "Title: Optimal control for a phase field system with a possibly singular\n  potential Abstract: In this paper we study a distributed control problem for a phase field system\nof Caginalp type with logarithmic potential. The main aim of this work would be\nto force the location of the diffuse interface to be as close as possible to a\nprescribed set. However, due to the discontinuous character of the cost\nfunctional, we have to approximate it by a regular one and, in this case, we\nsolve the associated control problem and derive the related first order\nnecessary optimality conditions. \n\n"}
{"id": "1411.0589", "contents": "Title: Modular proximal optimization for multidimensional total-variation\n  regularization Abstract: We study \\emph{TV regularization}, a widely used technique for eliciting\nstructured sparsity. In particular, we propose efficient algorithms for\ncomputing prox-operators for $\\ell_p$-norm TV. The most important among these\nis $\\ell_1$-norm TV, for whose prox-operator we present a new geometric\nanalysis which unveils a hitherto unknown connection to taut-string methods.\nThis connection turns out to be remarkably useful as it shows how our geometry\nguided implementation results in efficient weighted and unweighted 1D-TV\nsolvers, surpassing state-of-the-art methods. Our 1D-TV solvers provide the\nbackbone for building more complex (two or higher-dimensional) TV solvers\nwithin a modular proximal optimization approach. We review the literature for\nan array of methods exploiting this strategy, and illustrate the benefits of\nour modular design through extensive suite of experiments on (i) image\ndenoising, (ii) image deconvolution, (iii) four variants of fused-lasso, and\n(iv) video denoising. To underscore our claims and permit easy reproducibility,\nwe provide all the reviewed and our new TV solvers in an easy to use\nmulti-threaded C++, Matlab and Python library. \n\n"}
{"id": "1411.0944", "contents": "Title: The cost of getting local monotonicity Abstract: Manfred Holler introduced the Public Good index as a proposal to divide a\npublic good among players. In its unnormalized version, i.e., the raw measure,\nit counts the number of times that a player belongs to a minimal winning\ncoalition. Unlike the Banzhaf index, it does not count the remaining winning\ncoalitions in which the player is crucial. Holler noticed that his index does\nnot satisfy local monotonicity, a fact that can be seen either as a major\ndrawback or as an advantage. \n\n"}
{"id": "1411.1134", "contents": "Title: Global Convergence of Stochastic Gradient Descent for Some Non-convex\n  Matrix Problems Abstract: Stochastic gradient descent (SGD) on a low-rank factorization is commonly\nemployed to speed up matrix problems including matrix completion, subspace\ntracking, and SDP relaxation. In this paper, we exhibit a step size scheme for\nSGD on a low-rank least-squares problem, and we prove that, under broad\nsampling conditions, our method converges globally from a random starting point\nwithin $O(\\epsilon^{-1} n \\log n)$ steps with constant probability for\nconstant-rank problems. Our modification of SGD relates it to stochastic power\niteration. We also show experiments to illustrate the runtime and convergence\nof the algorithm. \n\n"}
{"id": "1411.1314", "contents": "Title: Computation of Gaussian orthant probabilities in high dimension Abstract: We study the computation of Gaussian orthant probabilities, i.e. the\nprobability that a Gaussian falls inside a quadrant. The\nGeweke-Hajivassiliou-Keane (GHK) algorithm [Genz, 1992; Geweke, 1991;\nHajivassiliou et al., 1996; Keane, 1993], is currently used for integrals of\ndimension greater than 10. In this paper we show that for Markovian covariances\nGHK can be interpreted as the estimator of the normalizing constant of a state\nspace model using sequential importance sampling (SIS). We show for an AR(1)\nthe variance of the GHK, properly normalized, diverges exponentially fast with\nthe dimension. As an improvement we propose using a particle filter (PF). We\nthen generalize this idea to arbitrary covariance matrices using Sequential\nMonte Carlo (SMC) with properly tailored MCMC moves. We show empirically that\nthis can lead to drastic improvements on currently used algorithms. We also\nextend the framework to orthants of mixture of Gaussians (Student, Cauchy\netc.), and to the simulation of truncated Gaussians. \n\n"}
{"id": "1411.4338", "contents": "Title: Conditional extragradient algorithms for solving variational\n  inequalities Abstract: In this paper, we generalize the classical extragradient algorithm for\nsolving variational inequality problems by utilizing nonzero normal vectors of\nthe feasible set. In particular, conceptual algorithms are proposed with two\ndifferent linesearchs. We then establish convergence results for these\nalgorithms under mild assumptions. Our study suggests that nonzero normal\nvectors may significantly improve convergence if chosen appropriately. \n\n"}
{"id": "1411.5735", "contents": "Title: Minimization of Transformed $L_1$ Penalty: Theory, Difference of Convex\n  Function Algorithm, and Robust Application in Compressed Sensing Abstract: We study the minimization problem of a non-convex sparsity promoting penalty\nfunction, the transformed $l_1$ (TL1), and its application in compressed\nsensing (CS). The TL1 penalty interpolates $l_0$ and $l_1$ norms through a\nnonnegative parameter $a \\in (0,+\\infty)$, similar to $l_p$ with $p \\in (0,1]$,\nand is known to satisfy unbiasedness, sparsity and Lipschitz continuity\nproperties. We first consider the constrained minimization problem and discuss\nthe exact recovery of $l_0$ norm minimal solution based on the null space\nproperty (NSP). We then prove the stable recovery of $l_0$ norm minimal\nsolution if the sensing matrix $A$ satisfies a restricted isometry property\n(RIP). Next, we present difference of convex algorithms for TL1 (DCATL1) in\ncomputing TL1-regularized constrained and unconstrained problems in CS. The\ninner loop concerns an $l_1$ minimization problem on which we employ the\nAlternating Direction Method of Multipliers (ADMM). For the unconstrained\nproblem, we prove convergence of DCATL1 to a stationary point satisfying the\nfirst order optimality condition. In numerical experiments, we identify the\noptimal value $a=1$, and compare DCATL1 with other CS algorithms on two classes\nof sensing matrices: Gaussian random matrices and over-sampled discrete cosine\ntransform matrices (DCT). We find that for both classes of sensing matrices,\nthe performance of DCATL1 algorithm (initiated with $l_1$ minimization) always\nranks near the top (if not the top), and is the most robust choice insensitive\nto the conditioning of the sensing matrix $A$. DCATL1 is also competitive in\ncomparison with DCA on other non-convex penalty functions commonly used in\nstatistics with two hyperparameters. \n\n"}
{"id": "1412.0156", "contents": "Title: Constant Step Size Least-Mean-Square: Bias-Variance Trade-offs and\n  Optimal Sampling Distributions Abstract: We consider the least-squares regression problem and provide a detailed\nasymptotic analysis of the performance of averaged constant-step-size\nstochastic gradient descent (a.k.a. least-mean-squares). In the strongly-convex\ncase, we provide an asymptotic expansion up to explicit exponentially decaying\nterms. Our analysis leads to new insights into stochastic approximation\nalgorithms: (a) it gives a tighter bound on the allowed step-size; (b) the\ngeneralization error may be divided into a variance term which is decaying as\nO(1/n), independently of the step-size $\\gamma$, and a bias term that decays as\nO(1/$\\gamma$ 2 n 2); (c) when allowing non-uniform sampling, the choice of a\ngood sampling density depends on whether the variance or bias terms dominate.\nIn particular, when the variance term dominates, optimal sampling densities do\nnot lead to much gain, while when the bias term dominates, we can choose larger\nstep-sizes that leads to significant improvements. \n\n"}
{"id": "1412.1911", "contents": "Title: A Majorized ADMM with Indefinite Proximal Terms for Linearly Constrained\n  Convex Composite Optimization Abstract: This paper presents a majorized alternating direction method of multipliers\n(ADMM) with indefinite proximal terms for solving linearly constrained\n$2$-block convex composite optimization problems with each block in the\nobjective being the sum of a non-smooth convex function and a smooth convex\nfunction, i.e., $\\min_{x \\in {\\cal X}, \\; y \\in {\\cal Y}}\\{p(x)+f(x) +\nq(y)+g(y)\\mid A^* x+B^* y = c\\}$.\n  By choosing the indefinite proximal terms properly, we establish the global\nconvergence and $O(1/k)$ ergodic iteration-complexity of the proposed method\nfor the step-length $\\tau \\in (0, (1+\\sqrt{5})/2)$. The computational benefit\nof using indefinite proximal terms within the ADMM framework instead of the\ncurrent requirement of positive semidefinite ones is also demonstrated\nnumerically. This opens up a new way to improve the practical performance of\nthe ADMM and related methods. \n\n"}
{"id": "1412.2841", "contents": "Title: Optimization Methods on Riemannian Manifolds via Extremum Seeking\n  Algorithms Abstract: This paper formulates the problem of Extremum Seeking for optimization of\ncost functions defined on Riemannian manifolds. We extend the conventional\nextremum seeking algorithms for optimization problems in Euclidean spaces to\noptimization of cost functions defined on smooth Riemannian manifolds. This\nproblem falls within the category of online optimization methods. We introduce\nthe notion of geodesic dithers which is a perturbation of the optimizing\ntrajectory in the tangent bundle of the ambient state manifolds and obtain the\nextremum seeking closed loop as a perturbation of the averaged gradient system.\nThe main results are obtained by applying closeness of solutions and averaging\ntheory on Riemannian manifolds. The main results are further extended for\noptimization on Lie groups. Numerical examples on Riemannian manifolds (Lie\ngroups) SO(3) and SE(3) are presented at the end of the paper. \n\n"}
{"id": "1412.3868", "contents": "Title: Input Selection for Performance and Controllability of Structured Linear\n  Descriptor Systems Abstract: A common approach to controlling complex networks is to directly control a\nsubset of input nodes, which then controls the remaining nodes via network\ninteractions. While techniques have been proposed for selecting input nodes\nbased on either performance metrics or controllability, a unifying approach\nbased on joint consideration of performance and controllability is an open\nproblem. In this paper, we develop a submodular optimization framework for\nselecting input nodes based on joint performance and controllability in\nstructured linear descriptor systems. We develop our framework for arbitrary\nlinear descriptor systems. In developing our framework, we first prove that\nselecting a minimum-size set of input nodes for controllability is a matroid\nintersection problem that can be solved in polynomial-time in the network size.\nWe then prove that input selection to maximize a performance metric with\ncontrollability as a constraint is equivalent to maximizing a monotone\nsubmodular function with two matroid basis constraints, and derive efficient\napproximation algorithms with provable optimality bounds for input selection.\nFinally, we present a graph controllability index metric, which characterizes\nthe largest controllable subgraph of a given complex network, and prove its\nsubmodular structure, leading to input selection algorithms that trade-off\nperformance and controllability. We provide improved optimality guarantees for\nknown systems such as strongly connected networks, consensus networks, networks\nof double integrators, and networks where all system parameters (e.g., link\nweights) are chosen independently and at random. \n\n"}
{"id": "1412.5492", "contents": "Title: Transport map accelerated Markov chain Monte Carlo Abstract: We introduce a new framework for efficient sampling from complex probability\ndistributions, using a combination of optimal transport maps and the\nMetropolis-Hastings rule. The core idea is to use continuous transportation to\ntransform typical Metropolis proposal mechanisms (e.g., random walks, Langevin\nmethods) into non-Gaussian proposal distributions that can more effectively\nexplore the target density. Our approach adaptively constructs a lower\ntriangular transport map-an approximation of the Knothe-Rosenblatt\nrearrangement-using information from previous MCMC states, via the solution of\nan optimization problem. This optimization problem is convex regardless of the\nform of the target distribution. It is solved efficiently using a Newton method\nthat requires no gradient information from the target probability distribution;\nthe target distribution is instead represented via samples. Sequential updates\nenable efficient and parallelizable adaptation of the map even for large\nnumbers of samples. We show that this approach uses inexact or truncated maps\nto produce an adaptive MCMC algorithm that is ergodic for the exact target\ndistribution. Numerical demonstrations on a range of parameter inference\nproblems show order-of-magnitude speedups over standard MCMC techniques,\nmeasured by the number of effectively independent samples produced per target\ndensity evaluation and per unit of wallclock time. \n\n"}
{"id": "1412.6095", "contents": "Title: Theoretical and Numerical Analysis of Approximate Dynamic Programming\n  with Approximation Errors Abstract: This study is aimed at answering the famous question of how the approximation\nerrors at each iteration of Approximate Dynamic Programming (ADP) affect the\nquality of the final results considering the fact that errors at each iteration\naffect the next iteration. To this goal, convergence of Value Iteration scheme\nof ADP for deterministic nonlinear optimal control problems with undiscounted\ncost functions is investigated while considering the errors existing in\napproximating respective functions. The boundedness of the results around the\noptimal solution is obtained based on quantities which are known in a general\noptimal control problem and assumptions which are verifiable. Moreover, since\nthe presence of the approximation errors leads to the deviation of the results\nfrom optimality, sufficient conditions for stability of the system operated by\nthe result obtained after a finite number of value iterations, along with an\nestimation of its region of attraction, are derived in terms of a calculable\nupper bound of the control approximation error. Finally, the process of\nimplementation of the method on an orbital maneuver problem is investigated\nthrough which the assumptions made in the theoretical developments are verified\nand the sufficient conditions are applied for guaranteeing stability and near\noptimality. \n\n"}
{"id": "1412.6980", "contents": "Title: Adam: A Method for Stochastic Optimization Abstract: We introduce Adam, an algorithm for first-order gradient-based optimization\nof stochastic objective functions, based on adaptive estimates of lower-order\nmoments. The method is straightforward to implement, is computationally\nefficient, has little memory requirements, is invariant to diagonal rescaling\nof the gradients, and is well suited for problems that are large in terms of\ndata and/or parameters. The method is also appropriate for non-stationary\nobjectives and problems with very noisy and/or sparse gradients. The\nhyper-parameters have intuitive interpretations and typically require little\ntuning. Some connections to related algorithms, on which Adam was inspired, are\ndiscussed. We also analyze the theoretical convergence properties of the\nalgorithm and provide a regret bound on the convergence rate that is comparable\nto the best known results under the online convex optimization framework.\nEmpirical results demonstrate that Adam works well in practice and compares\nfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,\na variant of Adam based on the infinity norm. \n\n"}
{"id": "1501.00756", "contents": "Title: Hashing with binary autoencoders Abstract: An attractive approach for fast search in image databases is binary hashing,\nwhere each high-dimensional, real-valued image is mapped onto a\nlow-dimensional, binary vector and the search is done in this binary space.\nFinding the optimal hash function is difficult because it involves binary\nconstraints, and most approaches approximate the optimization by relaxing the\nconstraints and then binarizing the result. Here, we focus on the binary\nautoencoder model, which seeks to reconstruct an image from the binary code\nproduced by the hash function. We show that the optimization can be simplified\nwith the method of auxiliary coordinates. This reformulates the optimization as\nalternating two easier steps: one that learns the encoder and decoder\nseparately, and one that optimizes the code for each image. Image retrieval\nexperiments, using precision/recall and a measure of code utilization, show the\nresulting hash function outperforms or is competitive with state-of-the-art\nmethods for binary hashing. \n\n"}
{"id": "1501.02931", "contents": "Title: Smart Procurement Of Naturally Generated Energy (SPONGE) for PHEV's Abstract: In this paper we propose a new engine management system for hybrid vehicles\nto enable energy providers and car manufacturers to provide new services.\nEnergy forecasts are used to collaboratively orchestrate the behaviour of\nengine management systems of a fleet of PHEV's to absorb oncoming energy in an\nsmart manner. Cooperative algorithms are suggested to manage the energy\nabsorption in an optimal manner for a fleet of vehicles, and the mobility\nsimulator SUMO is used to show simple simulations to support the efficacy of\nthe proposed idea. \n\n"}
{"id": "1502.00362", "contents": "Title: Designing Networks: A Mixed-Integer Linear Optimization Approach Abstract: Designing networks with specified collective properties is useful in a\nvariety of application areas, enabling the study of how given properties affect\nthe behavior of network models, the downscaling of empirical networks to\nworkable sizes, and the analysis of network evolution. Despite the importance\nof the task, there currently exists a gap in our ability to systematically\ngenerate networks that adhere to theoretical guarantees for the given property\nspecifications. In this paper, we propose the use of Mixed-Integer Linear\nOptimization modeling and solution methodologies to address this Network\nGeneration Problem. We present a number of useful modeling techniques and apply\nthem to mathematically express and constrain network properties in the context\nof an optimization formulation. We then develop complete formulations for the\ngeneration of networks that attain specified levels of connectivity, spread,\nassortativity and robustness, and we illustrate these via a number of\ncomputational case studies. \n\n"}
{"id": "1502.01527", "contents": "Title: Some comments about A. Ronald Gallant's \"Reflections on the Probability\n  Space Induced by Moment Conditions with Implications for Bayesian Inference\" Abstract: This note is commenting on Ronald Gallant's (2015) reflections on the\nconstruction of Bayesian prior distributions from moment conditions. The main\nconclusion is that the paper does not deliver a working principle that could\njustify inference based on such priors. \n\n"}
{"id": "1502.02842", "contents": "Title: On the closure of the completely positive semidefinite cone and linear\n  approximations to quantum colorings Abstract: We investigate structural properties of the completely positive semidefinite\ncone $\\mathcal{CS}_+^n$, consisting of all the $n \\times n$ symmetric matrices\nthat admit a Gram representation by positive semidefinite matrices of any size.\nThis cone has been introduced to model quantum graph parameters as conic\noptimization problems. Recently it has also been used to characterize the set\n$\\mathcal Q$ of bipartite quantum correlations, as projection of an affine\nsection of it. We have two main results concerning the structure of the\ncompletely positive semidefinite cone, namely about its interior and about its\nclosure. On the one hand we construct a hierarchy of polyhedral cones which\ncovers the interior of $\\mathcal{CS}_+^n$, which we use for computing some\nvariants of the quantum chromatic number by way of a linear program. On the\nother hand we give an explicit description of the closure of the completely\npositive semidefinite cone, by showing that it consists of all matrices\nadmitting a Gram representation in the tracial ultraproduct of matrix algebras. \n\n"}
{"id": "1502.03475", "contents": "Title: Combinatorial Bandits Revisited Abstract: This paper investigates stochastic and adversarial combinatorial multi-armed\nbandit problems. In the stochastic setting under semi-bandit feedback, we\nderive a problem-specific regret lower bound, and discuss its scaling with the\ndimension of the decision space. We propose ESCB, an algorithm that efficiently\nexploits the structure of the problem and provide a finite-time analysis of its\nregret. ESCB has better performance guarantees than existing algorithms, and\nsignificantly outperforms these algorithms in practice. In the adversarial\nsetting under bandit feedback, we propose \\textsc{CombEXP}, an algorithm with\nthe same regret scaling as state-of-the-art algorithms, but with lower\ncomputational complexity for some combinatorial problems. \n\n"}
{"id": "1502.04635", "contents": "Title: Parameter estimation in softmax decision-making models with linear\n  objective functions Abstract: With an eye towards human-centered automation, we contribute to the\ndevelopment of a systematic means to infer features of human decision-making\nfrom behavioral data. Motivated by the common use of softmax selection in\nmodels of human decision-making, we study the maximum likelihood parameter\nestimation problem for softmax decision-making models with linear objective\nfunctions. We present conditions under which the likelihood function is convex.\nThese allow us to provide sufficient conditions for convergence of the\nresulting maximum likelihood estimator and to construct its asymptotic\ndistribution. In the case of models with nonlinear objective functions, we show\nhow the estimator can be applied by linearizing about a nominal parameter\nvalue. We apply the estimator to fit the stochastic UCL (Upper Credible Limit)\nmodel of human decision-making to human subject data. We show statistically\nsignificant differences in behavior across related, but distinct, tasks. \n\n"}
{"id": "1502.05107", "contents": "Title: Norm Bounds and Underestimators for Unconstrained Polynomial Integer\n  Minimization Abstract: We consider the problem of minimizing a polynomial function over the integer\nlattice. Though impossible in general, we use a known sufficient condition for\nthe existence of continuous minimizers to guarantee the existence of integer\nminimizers as well. In case this condition holds, we use sos programming to\ncompute the radius of a p-norm ball which contains all integer minimizers. We\nprove that this radius is smaller than the radius known from the literature.\nFurthermore, we derive a new class of underestimators of the polynomial\nfunction. Using a Stellensatz from real algebraic geometry and again sos\nprogramming, we optimize over this class to get a strong lower bound on the\ninteger minimum. Our radius and lower bounds are evaluated experimentally. They\nshow a good performance, in particular within a branch and bound framework. \n\n"}
{"id": "1502.06681", "contents": "Title: Arbitrage, hedging and utility maximization using semi-static trading\n  strategies with American options Abstract: We consider a financial market where stocks are available for dynamic\ntrading, and European and American options are available for static trading\n(semi-static trading strategies). We assume that the American options are\ninfinitely divisible, and can only be bought but not sold. In the first part of\nthe paper, we work within the framework without model ambiguity. We first get\nthe fundamental theorem of asset pricing (FTAP). Using the FTAP, we get the\ndualities for the hedging prices of European and American options. Based on the\nhedging dualities, we also get the duality for the utility maximization. In the\nsecond part of the paper, we consider the market which admits non-dominated\nmodel uncertainty. We first establish the hedging result, and then using the\nhedging duality we further get the FTAP. Due to the technical difficulty\nstemming from the non-dominancy of the probability measure set, we use a\ndiscretization technique and apply the minimax theorem. \n\n"}
{"id": "1502.06742", "contents": "Title: Variable density sampling based on physically plausible gradient\n  waveform. Application to 3D MRI angiography Abstract: Performing k-space variable density sampling is a popular way of reducing\nscanning time in Magnetic Resonance Imaging (MRI). Unfortunately, given a\nsampling trajectory, it is not clear how to traverse it using gradient\nwaveforms. In this paper, we actually show that existing methods [1, 2] can\nyield large traversal time if the trajectory contains high curvature areas.\nTherefore, we consider here a new method for gradient waveform design which is\nbased on the projection of unrealistic initial trajectory onto the set of\nhardware constraints. Next, we show on realistic simulations that this\nalgorithm allows implementing variable density trajectories resulting from the\npiecewise linear solution of the Travelling Salesman Problem in a reasonable\ntime. Finally, we demonstrate the application of this approach to 2D MRI\nreconstruction and 3D angiography in the mouse brain. \n\n"}
{"id": "1502.07039", "contents": "Title: Markov Interacting Importance Samplers Abstract: We introduce a new Markov chain Monte Carlo (MCMC) sampler called the Markov\nInteracting Importance Sampler (MIIS). The MIIS sampler uses conditional\nimportance sampling (IS) approximations to jointly sample the current state of\nthe Markov Chain and estimate conditional expectations, possibly by\nincorporating a full range of variance reduction techniques. We compute\nRao-Blackwellized estimates based on the conditional expectations to construct\ncontrol variates for estimating expectations under the target distribution. The\ncontrol variates are particularly efficient when there are substantial\ncorrelations between the variables in the target distribution, a challenging\nsetting for MCMC. An important motivating application of MIIS occurs when the\nexact Gibbs sampler is not available because it is infeasible to directly\nsimulate from the conditional distributions. In this case the MIIS method can\nbe more efficient than a Metropolis-within-Gibbs approach. We also introduce\nthe MIIS random walk algorithm, designed to accelerate convergence and improve\nupon the computational efficiency of standard random walk samplers. Simulated\nand empirical illustrations for Bayesian analysis show that the method\nsignificantly reduces the variance of Monte Carlo estimates compared to\nstandard MCMC approaches, at equivalent implementation and computational\neffort. \n\n"}
{"id": "1503.00021", "contents": "Title: Mercer kernels and integrated variance experimental design: connections\n  between Gaussian process regression and polynomial approximation Abstract: This paper examines experimental design procedures used to develop surrogates\nof computational models, exploring the interplay between experimental designs\nand approximation algorithms. We focus on two widely used approximation\napproaches, Gaussian process (GP) regression and non-intrusive polynomial\napproximation. First, we introduce algorithms for minimizing a posterior\nintegrated variance (IVAR) design criterion for GP regression. Our formulation\ntreats design as a continuous optimization problem that can be solved with\ngradient-based methods on complex input domains, without resorting to greedy\napproximations. We show that minimizing IVAR in this way yields point sets with\ngood interpolation properties, and that it enables more accurate GP regression\nthan designs based on entropy minimization or mutual information maximization.\nSecond, using a Mercer kernel/eigenfunction perspective on GP regression, we\nidentify conditions under which GP regression coincides with pseudospectral\npolynomial approximation. Departures from these conditions can be understood as\nchanges either to the kernel or to the experimental design itself. We then show\nhow IVAR-optimal designs, while sacrificing discrete orthogonality of the\nkernel eigenfunctions, can yield lower approximation error than orthogonalizing\npoint sets. Finally, we compare the performance of adaptive Gaussian process\nregression and adaptive pseudospectral approximation for several classes of\ntarget functions, identifying features that are favorable to the GP + IVAR\napproach. \n\n"}
{"id": "1503.02101", "contents": "Title: Escaping From Saddle Points --- Online Stochastic Gradient for Tensor\n  Decomposition Abstract: We analyze stochastic gradient descent for optimizing non-convex functions.\nIn many cases for non-convex functions the goal is to find a reasonable local\nminimum, and the main concern is that gradient updates are trapped in saddle\npoints. In this paper we identify strict saddle property for non-convex problem\nthat allows for efficient optimization. Using this property we show that\nstochastic gradient descent converges to a local minimum in a polynomial number\nof iterations. To the best of our knowledge this is the first work that gives\nglobal convergence guarantees for stochastic gradient descent on non-convex\nfunctions with exponentially many local minima and saddle points. Our analysis\ncan be applied to orthogonal tensor decomposition, which is widely used in\nlearning a rich class of latent variable models. We propose a new optimization\nformulation for the tensor decomposition problem that has strict saddle\nproperty. As a result we get the first online algorithm for orthogonal tensor\ndecomposition with global convergence guarantee. \n\n"}
{"id": "1503.03517", "contents": "Title: Switching to Learn Abstract: A network of agents attempt to learn some unknown state of the world drawn by\nnature from a finite set. Agents observe private signals conditioned on the\ntrue state, and form beliefs about the unknown state accordingly. Each agent\nmay face an identification problem in the sense that she cannot distinguish the\ntruth in isolation. However, by communicating with each other, agents are able\nto benefit from side observations to learn the truth collectively. Unlike many\ndistributed algorithms which rely on all-time communication protocols, we\npropose an efficient method by switching between Bayesian and non-Bayesian\nregimes. In this model, agents exchange information only when their private\nsignals are not informative enough; thence, by switching between the two\nregimes, agents efficiently learn the truth using only a few rounds of\ncommunications. The proposed algorithm preserves learnability while incurring a\nlower communication cost. We also verify our theoretical findings by simulation\nexamples. \n\n"}
{"id": "1503.05238", "contents": "Title: Limit value for optimal control with general means Abstract: We consider optimal control problem with an integral cost which is a mean of\na given function. As a particular case, the cost concerned is the Ces\\`aro\naverage. The limit of the value with Ces\\`aro mean when the horizon tends to\ninfinity is widely studied in the literature. We address the more general\nquestion of the existence of a limit when the averaging parameter converges,\nfor values defined with means of general types.\n  We consider a given function and a family of costs defined as the mean of the\nfunction with respect to a family of probability measures -- the evaluations --\non R_+. We provide conditions on the evaluations in order to obtain the uniform\nconvergence of the associated value function (when the parameter of the family\nconverges).\n  Our main result gives a necessary and sufficient condition in term of the\ntotal variation of the family of probability measures on R_+. As a byproduct,\nwe obtain the existence of a limit value (for general means) for control\nsystems having a compact invariant set and satisfying suitable nonexpansive\nproperty. \n\n"}
{"id": "1503.06014", "contents": "Title: Optimal estimation with missing observations via balanced time-symmetric\n  stochastic models Abstract: We consider data fusion for the purpose of smoothing and interpolation based\non observation records with missing data. Stochastic processes are generated by\nlinear stochastic models. The paper begins by drawing a connection between time\nreversal in stochastic systems and all-pass extensions. A particular\nnormalization (choice of basis) between the two time-directions allows the two\nto share the same orthonormalized state process and simplifies the mathematics\nof data fusion. In this framework we derive symmetric and balanced\nMayne-Fraser-like formulas that apply simultaneously to smoothing and\ninterpolation. \n\n"}
{"id": "1503.06058", "contents": "Title: Sequential Monte Carlo Methods for System Identification Abstract: One of the key challenges in identifying nonlinear and possibly non-Gaussian\nstate space models (SSMs) is the intractability of estimating the system state.\nSequential Monte Carlo (SMC) methods, such as the particle filter (introduced\nmore than two decades ago), provide numerical solutions to the nonlinear state\nestimation problems arising in SSMs. When combined with additional\nidentification techniques, these algorithms provide solid solutions to the\nnonlinear system identification problem. We describe two general strategies for\ncreating such combinations and discuss why SMC is a natural tool for\nimplementing these strategies. \n\n"}
{"id": "1503.08366", "contents": "Title: Parameter Selection and Pre-Conditioning for a Graph Form Solver Abstract: In a recent paper, Parikh and Boyd describe a method for solving a convex\noptimization problem, where each iteration involves evaluating a proximal\noperator and projection onto a subspace. In this paper we address the critical\npractical issues of how to select the proximal parameter in each iteration, and\nhow to scale the original problem variables, so as the achieve reliable\npractical performance. The resulting method has been implemented as an\nopen-source software package called POGS (Proximal Graph Solver), that targets\nmulti-core and GPU-based systems, and has been tested on a wide variety of\npractical problems. Numerical results show that POGS can solve very large\nproblems (with, say, more than a billion coefficients in the data), to modest\naccuracy in a few tens of seconds. As just one example, a radiation treatment\nplanning problem with around 100 million coefficients in the data can be solved\nin a few seconds, as compared to around one hour with an interior-point method. \n\n"}
{"id": "1503.08641", "contents": "Title: Iterated quasi-reversibility method applied to elliptic and parabolic\n  data completion problems Abstract: We study the iterated quasi-reversibility method to regularize ill-posed\nelliptic and parabolic problems: data completion problems for Poisson's and\nheat equations. We define an abstract setting to treat both equations at once.\nWe demonstrate the convergence of the regularized solution to the exact one,\nand propose a strategy to deal with noise on the data. We present numerical\nexperiments for both problems: a two-dimensional corrosion detection problem\nand the one-dimensional heat equation with lateral data. In both cases, the\nmethod prove to be efficient even with highly corrupted data. \n\n"}
{"id": "1504.00057", "contents": "Title: Optimal Power Flow with Weighted Chance Constraints and General Policies\n  for Generation Control Abstract: Due to the increasing amount of electricity generated from renewable sources,\nuncertainty in power system operation will grow. This has implications for\ntools such as Optimal Power Flow (OPF), an optimization problem widely used in\npower system operations and planning, which should be adjusted to account for\nthis uncertainty. One way to handle the uncertainty is to formulate a Chance\nConstrained OPF (CC-OPF) which limits the probability of constraint violation\nto a predefined value. However, existing CC-OPF formulations and solutions are\nnot immune to drawbacks. On one hand, they only consider affine policies for\ngeneration control, which are not always realistic and may be sub-optimal. On\nthe other hand, the standard CC-OPF formulations do not distinguish between\nlarge and small violations, although those might carry significantly different\nrisk. In this paper, we introduce the Weighted CC-OPF (WCC-OPF) that can handle\ngeneral control policies while preserving convexity and allowing for efficient\ncomputation. The weighted chance constraints account for the size of violations\nthrough a weighting function, which assigns a higher risk to a higher\noverloads. We prove that the problem remains convex for any convex weighting\nfunction, and for very general generation control policies. In a case study, we\ncompare the performance of the new WCC-OPF and the standard CC-OPF and\ndemonstrate that WCC-OPF effectively reduces the number of severe overloads.\nFurthermore, we compare an affine generation control policy with a more general\npolicy, and show that the additional flexibility allow for a lower cost while\nmaintaining the same level of risk. \n\n"}
{"id": "1504.01070", "contents": "Title: Sync-Rank: Robust Ranking, Constrained Ranking and Rank Aggregation via\n  Eigenvector and Semidefinite Programming Synchronization Abstract: We consider the classic problem of establishing a statistical ranking of a\nset of n items given a set of inconsistent and incomplete pairwise comparisons\nbetween such items. Instantiations of this problem occur in numerous\napplications in data analysis (e.g., ranking teams in sports data), computer\nvision, and machine learning. We formulate the above problem of ranking with\nincomplete noisy information as an instance of the group synchronization\nproblem over the group SO(2) of planar rotations, whose usefulness has been\ndemonstrated in numerous applications in recent years. Its least squares\nsolution can be approximated by either a spectral or a semidefinite programming\n(SDP) relaxation, followed by a rounding procedure. We perform extensive\nnumerical simulations on both synthetic and real-world data sets, showing that\nour proposed method compares favorably to other algorithms from the recent\nliterature. Existing theoretical guarantees on the group synchronization\nproblem imply lower bounds on the largest amount of noise permissible in the\nranking data while still achieving exact recovery. We propose a similar\nsynchronization-based algorithm for the rank-aggregation problem, which\nintegrates in a globally consistent ranking pairwise comparisons given by\ndifferent rating systems on the same set of items. We also discuss the problem\nof semi-supervised ranking when there is available information on the ground\ntruth rank of a subset of players, and propose an algorithm based on SDP which\nrecovers the ranks of the remaining players. Finally, synchronization-based\nranking, combined with a spectral technique for the densest subgraph problem,\nallows one to extract locally-consistent partial rankings, in other words, to\nidentify the rank of a small subset of players whose pairwise comparisons are\nless noisy than the rest of the data, which other methods are not able to\nidentify. \n\n"}
{"id": "1504.01438", "contents": "Title: Convergence Time of Quantized Metropolis Consensus Over Time-Varying\n  Networks Abstract: We consider the quantized consensus problem on undirected time-varying\nconnected graphs with n nodes, and devise a protocol with fast convergence time\nto the set of consensus points. Specifically, we show that when the edges of\neach network in a sequence of connected time-varying networks are activated\nbased on Poisson processes with Metropolis rates, the expected convergence time\nto the set of consensus points is at most O(n^2 log^2 n), where each node\nperforms a constant number of updates per unit time. \n\n"}
{"id": "1504.01515", "contents": "Title: Simultaneously sparse and low-rank abundance matrix estimation for\n  hyperspectral image unmixing Abstract: In a plethora of applications dealing with inverse problems, e.g. in image\nprocessing, social networks, compressive sensing, biological data processing\netc., the signal of interest is known to be structured in several ways at the\nsame time. This premise has recently guided the research to the innovative and\nmeaningful idea of imposing multiple constraints on the parameters involved in\nthe problem under study. For instance, when dealing with problems whose\nparameters form sparse and low-rank matrices, the adoption of suitably combined\nconstraints imposing sparsity and low-rankness, is expected to yield\nsubstantially enhanced estimation results. In this paper, we address the\nspectral unmixing problem in hyperspectral images. Specifically, two novel\nunmixing algorithms are introduced, in an attempt to exploit both spatial\ncorrelation and sparse representation of pixels lying in homogeneous regions of\nhyperspectral images. To this end, a novel convex mixed penalty term is first\ndefined consisting of the sum of the weighted $\\ell_1$ and the weighted nuclear\nnorm of the abundance matrix corresponding to a small area of the image\ndetermined by a sliding square window. This penalty term is then used to\nregularize a conventional quadratic cost function and impose simultaneously\nsparsity and row-rankness on the abundance matrix. The resulting regularized\ncost function is minimized by a) an incremental proximal sparse and low-rank\nunmixing algorithm and b) an algorithm based on the alternating minimization\nmethod of multipliers (ADMM). The effectiveness of the proposed algorithms is\nillustrated in experiments conducted both on simulated and real data. \n\n"}
{"id": "1504.02146", "contents": "Title: Discrete Stochastic Submodular Maximization: Adaptive vs. Non-Adaptive\n  vs. Offline Abstract: We consider the problem of stochastic monotone submodular function\nmaximization, subject to constraints. We give results on adaptivity gaps, and\non the gap between the optimal offline and online solutions. We present a\nprocedure that transforms a decision tree (adaptive algorithm) into a\nnon-adaptive chain. We prove that this chain achieves at least ${\\tau}$ times\nthe utility of the decision tree, over a product distribution and binary state\nspace, where ${\\tau} = \\min_{i,j} \\Pr[x_i=j]$. This proves an adaptivity gap of\n$1/{\\tau}$ (which is $2$ in the case of a uniform distribution) for the problem\nof stochastic monotone submodular maximization subject to state-independent\nconstraints. For a cardinality constraint, we prove that a simple adaptive\ngreedy algorithm achieves an approximation factor of $(1-1/e^{\\tau})$ with\nrespect to the optimal offline solution; previously, it has been proven that\nthe algorithm achieves an approximation factor of $(1-1/e)$ with respect to the\noptimal adaptive online solution. Finally, we show that there exists a\nnon-adaptive solution for the stochastic max coverage problem that is within a\nfactor $(1-1/e)$ of the optimal adaptive solution and within a factor of\n${\\tau}(1-1/e)$ of the optimal offline solution. \n\n"}
{"id": "1504.02206", "contents": "Title: A Multiphase Image Segmentation Based on Fuzzy Membership Functions and\n  L1-norm Fidelity Abstract: In this paper, we propose a variational multiphase image segmentation model\nbased on fuzzy membership functions and L1-norm fidelity. Then we apply the\nalternating direction method of multipliers to solve an equivalent problem. All\nthe subproblems can be solved efficiently. Specifically, we propose a fast\nmethod to calculate the fuzzy median. Experimental results and comparisons show\nthat the L1-norm based method is more robust to outliers such as impulse noise\nand keeps better contrast than its L2-norm counterpart. Theoretically, we prove\nthe existence of the minimizer and analyze the convergence of the algorithm. \n\n"}
{"id": "1504.06785", "contents": "Title: Complete Dictionary Recovery over the Sphere Abstract: We consider the problem of recovering a complete (i.e., square and\ninvertible) matrix $\\mathbf A_0$, from $\\mathbf Y \\in \\mathbb R^{n \\times p}$\nwith $\\mathbf Y = \\mathbf A_0 \\mathbf X_0$, provided $\\mathbf X_0$ is\nsufficiently sparse. This recovery problem is central to the theoretical\nunderstanding of dictionary learning, which seeks a sparse representation for a\ncollection of input signals, and finds numerous applications in modern signal\nprocessing and machine learning. We give the first efficient algorithm that\nprovably recovers $\\mathbf A_0$ when $\\mathbf X_0$ has $O(n)$ nonzeros per\ncolumn, under suitable probability model for $\\mathbf X_0$. In contrast, prior\nresults based on efficient algorithms provide recovery guarantees when $\\mathbf\nX_0$ has only $O(n^{1-\\delta})$ nonzeros per column for any constant $\\delta\n\\in (0, 1)$.\n  Our algorithmic pipeline centers around solving a certain nonconvex\noptimization problem with a spherical constraint, and hence is naturally\nphrased in the language of manifold optimization. To show this apparently hard\nproblem is tractable, we first provide a geometric characterization of the\nhigh-dimensional objective landscape, which shows that with high probability\nthere are no \"spurious\" local minima. This particular geometric structure\nallows us to design a Riemannian trust region algorithm over the sphere that\nprovably converges to one local minimizer with an arbitrary initialization,\ndespite the presence of saddle points. The geometric approach we develop here\nmay also shed light on other problems arising from nonconvex recovery of\nstructured signals. \n\n"}
{"id": "1504.07235", "contents": "Title: Sign Stable Random Projections for Large-Scale Learning Abstract: We study the use of \"sign $\\alpha$-stable random projections\" (where\n$0<\\alpha\\leq 2$) for building basic data processing tools in the context of\nlarge-scale machine learning applications (e.g., classification, regression,\nclustering, and near-neighbor search). After the processing by sign stable\nrandom projections, the inner products of the processed data approximate\nvarious types of nonlinear kernels depending on the value of $\\alpha$. Thus,\nthis approach provides an effective strategy for approximating nonlinear\nlearning algorithms essentially at the cost of linear learning. When $\\alpha\n=2$, it is known that the corresponding nonlinear kernel is the arc-cosine\nkernel. When $\\alpha=1$, the procedure approximates the arc-cos-$\\chi^2$ kernel\n(under certain condition). When $\\alpha\\rightarrow0+$, it corresponds to the\nresemblance kernel.\n  From practitioners' perspective, the method of sign $\\alpha$-stable random\nprojections is ready to be tested for large-scale learning applications, where\n$\\alpha$ can be simply viewed as a tuning parameter. What is missing in the\nliterature is an extensive empirical study to show the effectiveness of sign\nstable random projections, especially for $\\alpha\\neq 2$ or 1. The paper\nsupplies such a study on a wide variety of classification datasets. In\nparticular, we compare shoulder-by-shoulder sign stable random projections with\nthe recently proposed \"0-bit consistent weighted sampling (CWS)\" (Li 2015). \n\n"}
{"id": "1504.07245", "contents": "Title: Approximate Bayesian Computation for Forward Modeling in Cosmology Abstract: Bayesian inference is often used in cosmology and astrophysics to derive\nconstraints on model parameters from observations. This approach relies on the\nability to compute the likelihood of the data given a choice of model\nparameters. In many practical situations, the likelihood function may however\nbe unavailable or intractable due to non-gaussian errors, non-linear\nmeasurements processes, or complex data formats such as catalogs and maps. In\nthese cases, the simulation of mock data sets can often be made through forward\nmodeling. We discuss how Approximate Bayesian Computation (ABC) can be used in\nthese cases to derive an approximation to the posterior constraints using\nsimulated data sets. This technique relies on the sampling of the parameter\nset, a distance metric to quantify the difference between the observation and\nthe simulations and summary statistics to compress the information in the data.\nWe first review the principles of ABC and discuss its implementation using a\nPopulation Monte-Carlo (PMC) algorithm and the Mahalanobis distance metric. We\ntest the performance of the implementation using a Gaussian toy model. We then\napply the ABC technique to the practical case of the calibration of image\nsimulations for wide field cosmological surveys. We find that the ABC analysis\nis able to provide reliable parameter constraints for this problem and is\ntherefore a promising technique for other applications in cosmology and\nastrophysics. Our implementation of the ABC PMC method is made available via a\npublic code release. \n\n"}
{"id": "1505.00768", "contents": "Title: Analysis and Control of Epidemics: A survey of spreading processes on\n  complex networks Abstract: This article reviews and presents various solved and open problems in the\ndevelopment, analysis, and control of epidemic models. We are interested in\npresenting a relatively concise report for new engineers looking to enter the\nfield of spreading processes on complex networks. \n\n"}
{"id": "1505.02827", "contents": "Title: On Markov chain Monte Carlo methods for tall data Abstract: Markov chain Monte Carlo methods are often deemed too computationally\nintensive to be of any practical use for big data applications, and in\nparticular for inference on datasets containing a large number $n$ of\nindividual data points, also known as tall datasets. In scenarios where data\nare assumed independent, various approaches to scale up the Metropolis-Hastings\nalgorithm in a Bayesian inference context have been recently proposed in\nmachine learning and computational statistics. These approaches can be grouped\ninto two categories: divide-and-conquer approaches and, subsampling-based\nalgorithms. The aims of this article are as follows. First, we present a\ncomprehensive review of the existing literature, commenting on the underlying\nassumptions and theoretical guarantees of each method. Second, by leveraging\nour understanding of these limitations, we propose an original\nsubsampling-based approach which samples from a distribution provably close to\nthe posterior distribution of interest, yet can require less than $O(n)$ data\npoint likelihood evaluations at each iteration for certain statistical models\nin favourable scenarios. Finally, we have only been able so far to propose\nsubsampling-based methods which display good performance in scenarios where the\nBernstein-von Mises approximation of the target posterior distribution is\nexcellent. It remains an open challenge to develop such methods in scenarios\nwhere the Bernstein-von Mises approximation is poor. \n\n"}
{"id": "1505.04243", "contents": "Title: A New Perspective on Boosting in Linear Regression via Subgradient\n  Optimization and Relatives Abstract: In this paper we analyze boosting algorithms in linear regression from a new\nperspective: that of modern first-order methods in convex optimization. We show\nthat classic boosting algorithms in linear regression, namely the incremental\nforward stagewise algorithm (FS$_\\varepsilon$) and least squares boosting\n(LS-Boost($\\varepsilon$)), can be viewed as subgradient descent to minimize the\nloss function defined as the maximum absolute correlation between the features\nand residuals. We also propose a modification of FS$_\\varepsilon$ that yields\nan algorithm for the Lasso, and that may be easily extended to an algorithm\nthat computes the Lasso path for different values of the regularization\nparameter. Furthermore, we show that these new algorithms for the Lasso may\nalso be interpreted as the same master algorithm (subgradient descent), applied\nto a regularized version of the maximum absolute correlation loss function. We\nderive novel, comprehensive computational guarantees for several boosting\nalgorithms in linear regression (including LS-Boost($\\varepsilon$) and\nFS$_\\varepsilon$) by using techniques of modern first-order methods in convex\noptimization. Our computational guarantees inform us about the statistical\nproperties of boosting algorithms. In particular they provide, for the first\ntime, a precise theoretical description of the amount of data-fidelity and\nregularization imparted by running a boosting algorithm with a prespecified\nlearning rate for a fixed but arbitrary number of iterations, for any dataset. \n\n"}
{"id": "1505.05118", "contents": "Title: Almost sure convergence of the forward-backward-forward splitting\n  algorithm Abstract: In this paper, we propose a stochastic forward-backward-forward splitting\nalgorithm and prove its almost sure weak convergence in real separable Hilbert\nspaces. Applications to composite monotone inclusion and minimization problems\nare demonstrated. \n\n"}
{"id": "1505.05216", "contents": "Title: Convergence Analysis of Policy Iteration Abstract: Adaptive optimal control of nonlinear dynamic systems with deterministic and\nknown dynamics under a known undiscounted infinite-horizon cost function is\ninvestigated. Policy iteration scheme initiated using a stabilizing initial\ncontrol is analyzed in solving the problem. The convergence of the iterations\nand the optimality of the limit functions, which follows from the established\nuniqueness of the solution to the Bellman equation, are the main results of\nthis study. Furthermore, a theoretical comparison between the speed of\nconvergence of policy iteration versus value iteration is presented. Finally,\nthe convergence results are extended to the case of multi-step look-ahead\npolicy iteration. \n\n"}
{"id": "1505.06356", "contents": "Title: Particle ancestor sampling for near-degenerate or intractable state\n  transition models Abstract: We consider Bayesian inference in sequential latent variable models in\ngeneral, and in nonlinear state space models in particular (i.e., state\nsmoothing). We work with sequential Monte Carlo (SMC) algorithms, which provide\na powerful inference framework for addressing this problem. However, for\ncertain challenging and common model classes the state-of-the-art algorithms\nstill struggle. The work is motivated in particular by two such model classes:\n(i) models where the state transition kernel is (nearly) degenerate, i.e.\n(nearly) concentrated on a low-dimensional manifold, and (ii) models where\npoint-wise evaluation of the state transition density is intractable. Both\ntypes of models arise in many applications of interest, including tracking,\nepidemiology, and econometrics. The difficulties with these types of models is\nthat they essentially rule out forward-backward-based methods, which are known\nto be of great practical importance, not least to construct computationally\nefficient particle Markov chain Monte Carlo (PMCMC) algorithms. To alleviate\nthis, we propose a \"particle rejuvenation\" technique to enable the use of the\nforward-backward strategy for (nearly) degenerate models and, by extension, for\nintractable models. We derive the proposed method specifically within the\ncontext of PMCMC, but we emphasise that it is applicable to any\nforward-backward-based Monte Carlo method. \n\n"}
{"id": "1506.03125", "contents": "Title: Controllability of random systems: Universality and minimal\n  controllability Abstract: For a large class of random matrices $A$ and vectors $b$, we show that linear\nsystems formed from the pair $(A,b)$ are controllable with high probability.\nDespite the fact that minimal controllability problems are, in general,\nNP-hard, we establish universality results for the minimal controllability of\nrandom systems. Our proof relies on the recent developments of Nguyen-Tao-Vu\nconcerning gaps between eigenvalues of random matrices. \n\n"}
{"id": "1506.03662", "contents": "Title: Variance Reduced Stochastic Gradient Descent with Neighbors Abstract: Stochastic Gradient Descent (SGD) is a workhorse in machine learning, yet its\nslow convergence can be a computational bottleneck. Variance reduction\ntechniques such as SAG, SVRG and SAGA have been proposed to overcome this\nweakness, achieving linear convergence. However, these methods are either based\non computations of full gradients at pivot points, or on keeping per data point\ncorrections in memory. Therefore speed-ups relative to SGD may need a minimal\nnumber of epochs in order to materialize. This paper investigates algorithms\nthat can exploit neighborhood structure in the training data to share and\nre-use information about past stochastic gradients across data points, which\noffers advantages in the transient optimization phase. As a side-product we\nprovide a unified convergence analysis for a family of variance reduction\nalgorithms, which we call memorization algorithms. We provide experimental\nresults supporting our theory. \n\n"}
{"id": "1506.04838", "contents": "Title: Spectral Sparsification and Regret Minimization Beyond Matrix\n  Multiplicative Updates Abstract: In this paper, we provide a novel construction of the linear-sized spectral\nsparsifiers of Batson, Spielman and Srivastava [BSS14]. While previous\nconstructions required $\\Omega(n^4)$ running time [BSS14, Zou12], our\nsparsification routine can be implemented in almost-quadratic running time\n$O(n^{2+\\varepsilon})$.\n  The fundamental conceptual novelty of our work is the leveraging of a strong\nconnection between sparsification and a regret minimization problem over\ndensity matrices. This connection was known to provide an interpretation of the\nrandomized sparsifiers of Spielman and Srivastava [SS11] via the application of\nmatrix multiplicative weight updates (MWU) [CHS11, Vis14]. In this paper, we\nexplain how matrix MWU naturally arises as an instance of the\nFollow-the-Regularized-Leader framework and generalize this approach to yield a\nlarger class of updates. This new class allows us to accelerate the\nconstruction of linear-sized spectral sparsifiers, and give novel insights on\nthe motivation behind Batson, Spielman and Srivastava [BSS14]. \n\n"}
{"id": "1506.04972", "contents": "Title: A Unified Successive Pseudo-Convex Approximation Framework Abstract: In this paper, we propose a successive pseudo-convex approximation algorithm\nto efficiently compute stationary points for a large class of possibly\nnonconvex optimization problems. The stationary points are obtained by solving\na sequence of successively refined approximate problems, each of which is much\neasier to solve than the original problem. To achieve convergence, the\napproximate problem only needs to exhibit a weak form of convexity, namely,\npseudo-convexity. We show that the proposed framework not only includes as\nspecial cases a number of existing methods, for example, the gradient method\nand the Jacobi algorithm, but also leads to new algorithms which enjoy easier\nimplementation and faster convergence speed. We also propose a novel line\nsearch method for nondifferentiable optimization problems, which is carried out\nover a properly constructed differentiable function with the benefit of a\nsimplified implementation as compared to state-of-the-art line search\ntechniques that directly operate on the original nondifferentiable objective\nfunction. The advantages of the proposed algorithm are shown, both\ntheoretically and numerically, by several example applications, namely, MIMO\nbroadcast channel capacity computation, energy efficiency maximization in\nmassive MIMO systems and LASSO in sparse signal recovery. \n\n"}
{"id": "1506.07719", "contents": "Title: Network Aggregative Games and Distributed Mean Field Control via\n  Consensus Theory Abstract: We consider network aggregative games to model and study multi-agent\npopulations in which each rational agent is influenced by the aggregate\nbehavior of its neighbors, as specified by an underlying network. Specifically,\nwe examine systems where each agent minimizes a quadratic cost function, that\ndepends on its own strategy and on a convex combination of the strategies of\nits neighbors, and is subject to personalized convex constraints. We analyze\nthe best response dynamics and we propose alternative distributed algorithms to\nsteer the strategies of the rational agents to a Nash equilibrium\nconfiguration. The convergence of these schemes is guaranteed under different\nsufficient conditions, depending on the matrices defining the cost and on the\nnetwork. Additionally, we propose an extension to the network aggregative game\nsetting that allows for multiple rounds of communications among the agents, and\nwe illustrate how it can be combined with consensus theory to recover a\nsolution to the mean field control problem in a distributed fashion, that is,\nwithout requiring the presence of a central coordinator. Finally, we apply our\ntheoretical findings to study a novel multi-dimensional, convex-constrained\nmodel of opinion dynamics and a hierarchical demand-response scheme for energy\nmanagement in smart buildings, extending literature results. \n\n"}
{"id": "1506.08170", "contents": "Title: Finding Linear Structure in Large Datasets with Scalable Canonical\n  Correlation Analysis Abstract: Canonical Correlation Analysis (CCA) is a widely used spectral technique for\nfinding correlation structures in multi-view datasets. In this paper, we tackle\nthe problem of large scale CCA, where classical algorithms, usually requiring\ncomputing the product of two huge matrices and huge matrix decomposition, are\ncomputationally and storage expensive. We recast CCA from a novel perspective\nand propose a scalable and memory efficient Augmented Approximate Gradient\n(AppGrad) scheme for finding top $k$ dimensional canonical subspace which only\ninvolves large matrix multiplying a thin matrix of width $k$ and small matrix\ndecomposition of dimension $k\\times k$. Further, AppGrad achieves optimal\nstorage complexity $O(k(p_1+p_2))$, compared with classical algorithms which\nusually require $O(p_1^2+p_2^2)$ space to store two dense whitening matrices.\nThe proposed scheme naturally generalizes to stochastic optimization regime,\nespecially efficient for huge datasets where batch algorithms are prohibitive.\nThe online property of stochastic AppGrad is also well suited to the streaming\nscenario, where data comes sequentially. To the best of our knowledge, it is\nthe first stochastic algorithm for CCA. Experiments on four real data sets are\nprovided to show the effectiveness of the proposed methods. \n\n"}
{"id": "1507.00843", "contents": "Title: Optimal linear Bernoulli factories for small mean problems Abstract: Suppose a coin with unknown probability $p$ of heads can be flipped as often\nas desired. A Bernoulli factory for a function $f$ is an algorithm that uses\nflips of the coin together with auxiliary randomness to flip a single coin with\nprobability $f(p)$ of heads. Applications include near perfect sampling from\nthe stationary distribution of regenerative processes. When $f$ is analytic,\nthe problem can be reduced to a Bernoulli factory of the form $f(p) = Cp$ for\nconstant $C$. Presented here is a new algorithm where for small values of $Cp$,\nrequires roughly only $C$ coin flips to generate a $Cp$ coin. From information\ntheory considerations, this is also conjectured to be (to first order) the\nminimum number of flips needed by any such algorithm.\n  For $Cp$ large, the new algorithm can also be used to build a new Bernoulli\nfactory that uses only 80\\% of the expected coin flips of the older method, and\napplies to the more general problem of a multivariate Bernoulli factory, where\nthere are $k$ coins, the $k$th coin has unknown probability $p_k$ of heads, and\nthe goal is to simulate a coin flip with probability $C_1 p_1 + \\cdots + C_k\np_k$ of heads. \n\n"}
{"id": "1507.01614", "contents": "Title: Fast sampling in a linear-Gaussian inverse problem Abstract: We solve the inverse problem of deblurring a pixelized image of Jupiter using\nregularized deconvolution and by sample-based Bayesian inference. By\nefficiently sampling the marginal posterior distribution for hyperparameters,\nthen the full conditional for the deblurred image, we find that we can evaluate\nthe posterior mean faster than regularized inversion, when selection of the\nregularizing parameter is considered. To our knowledge, this is the first\ndemonstration of sampling and inference that takes less compute time than\nregularized inversion in an inverse problems. Comparison to random-walk\nMetropolis-Hastings and block Gibbs MCMC shows that marginal then conditional\nsampling also outperforms these more common sampling algorithms, having better\nscaling with problem size. When problem-specific computations are feasible the\nasymptotic cost of an independent sample is one linear solve, implying that\nsample-based Bayesian inference may be performed directly over function spaces,\nwhen that limit exists. \n\n"}
{"id": "1507.03266", "contents": "Title: Inverse Optimization with Noisy Data Abstract: Inverse optimization refers to the inference of unknown parameters of an\noptimization problem based on knowledge of its optimal solutions. This paper\nconsiders inverse optimization in the setting where measurements of the optimal\nsolutions of a convex optimization problem are corrupted by noise. We first\nprovide a formulation for inverse optimization and prove it to be NP-hard. In\ncontrast to existing methods, we show that the parameter estimates produced by\nour formulation are statistically consistent. Our approach involves combining a\nnew duality-based reformulation for bilevel programs with a regularization\nscheme that smooths discontinuities in the formulation. Using epi-convergence\ntheory, we show the regularization parameter can be adjusted to approximate the\noriginal inverse optimization problem to arbitrary accuracy, which we use to\nprove our consistency results. Next, we propose two solution algorithms based\non our duality-based formulation. The first is an enumeration algorithm that is\napplicable to settings where the dimensionality of the parameter space is\nmodest, and the second is a semiparametric approach that combines nonparametric\nstatistics with a modified version of our formulation. These numerical\nalgorithms are shown to maintain the statistical consistency of the underlying\nformulation. Lastly, using both synthetic and real data, we demonstrate that\nour approach performs competitively when compared with existing heuristics. \n\n"}
{"id": "1507.03734", "contents": "Title: Smooth Alternating Direction Methods for Nonsmooth Constrained Convex\n  Optimization Abstract: We propose two new alternating direction methods to solve \"fully\" nonsmooth\nconstrained convex problems. Our algorithms have the best known worst-case\niteration-complexity guarantee under mild assumptions for both the objective\nresidual and feasibility gap. Through theoretical analysis, we show how to\nupdate all the algorithmic parameters automatically with clear impact on the\nconvergence performance. We also provide a representative numerical example\nshowing the advantages of our methods over the classical alternating direction\nmethods using a well-known feasibility problem. \n\n"}
{"id": "1507.04544", "contents": "Title: Practical Bayesian model evaluation using leave-one-out cross-validation\n  and WAIC Abstract: Leave-one-out cross-validation (LOO) and the widely applicable information\ncriterion (WAIC) are methods for estimating pointwise out-of-sample prediction\naccuracy from a fitted Bayesian model using the log-likelihood evaluated at the\nposterior simulations of the parameter values. LOO and WAIC have various\nadvantages over simpler estimates of predictive error such as AIC and DIC but\nare less used in practice because they involve additional computational steps.\nHere we lay out fast and stable computations for LOO and WAIC that can be\nperformed using existing simulation draws. We introduce an efficient\ncomputation of LOO using Pareto-smoothed importance sampling (PSIS), a new\nprocedure for regularizing importance weights. Although WAIC is asymptotically\nequal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case\nwith weak priors or influential observations. As a byproduct of our\ncalculations, we also obtain approximate standard errors for estimated\npredictive errors and for comparing of predictive errors between two models. We\nimplement the computations in an R package called 'loo' and demonstrate using\nmodels fit with the Bayesian inference package Stan. \n\n"}
{"id": "1507.05154", "contents": "Title: Diffusion LMS Strategies in Sensor Networks with Noisy Input Data Abstract: We investigate the performance of distributed least-mean square (LMS)\nalgorithms for parameter estimation over sensor networks where the regression\ndata of each node are corrupted by white measurement noise. Under this\ncondition, we show that the estimates produced by distributed LMS algorithms\nwill be biased if the regression noise is excluded from consideration. We\npropose a bias-elimination technique and develop a novel class of diffusion LMS\nalgorithms that can mitigate the effect of regression noise and obtain an\nunbiased estimate of the unknown parameter vector over the network. In our\ndevelopment, we first assume that the variances of the regression noises are\nknown a-priori. Later, we relax this assumption by estimating these variances\nin real-time. We analyze the stability and convergence of the proposed\nalgorithms and derive closed-form expressions to characterize their mean-square\nerror performance in transient and steady-state regimes. We further provide\ncomputer experiment results that illustrate the efficiency of the proposed\nalgorithms and support the analytical findings. \n\n"}
{"id": "1507.06370", "contents": "Title: Sum-of-Squares Lower Bounds for Sparse PCA Abstract: This paper establishes a statistical versus computational trade-off for\nsolving a basic high-dimensional machine learning problem via a basic convex\nrelaxation method. Specifically, we consider the {\\em Sparse Principal\nComponent Analysis} (Sparse PCA) problem, and the family of {\\em\nSum-of-Squares} (SoS, aka Lasserre/Parillo) convex relaxations. It was well\nknown that in large dimension $p$, a planted $k$-sparse unit vector can be {\\em\nin principle} detected using only $n \\approx k\\log p$ (Gaussian or Bernoulli)\nsamples, but all {\\em efficient} (polynomial time) algorithms known require $n\n\\approx k^2$ samples. It was also known that this quadratic gap cannot be\nimproved by the the most basic {\\em semi-definite} (SDP, aka spectral)\nrelaxation, equivalent to a degree-2 SoS algorithms. Here we prove that also\ndegree-4 SoS algorithms cannot improve this quadratic gap. This average-case\nlower bound adds to the small collection of hardness results in machine\nlearning for this powerful family of convex relaxation algorithms. Moreover,\nour design of moments (or \"pseudo-expectations\") for this lower bound is quite\ndifferent than previous lower bounds. Establishing lower bounds for higher\ndegree SoS algorithms for remains a challenging problem. \n\n"}
{"id": "1507.06738", "contents": "Title: Linear Contextual Bandits with Knapsacks Abstract: We consider the linear contextual bandit problem with resource consumption,\nin addition to reward generation. In each round, the outcome of pulling an arm\nis a reward as well as a vector of resource consumptions. The expected values\nof these outcomes depend linearly on the context of that arm. The\nbudget/capacity constraints require that the total consumption doesn't exceed\nthe budget for each resource. The objective is once again to maximize the total\nreward. This problem turns out to be a common generalization of classic linear\ncontextual bandits (linContextual), bandits with knapsacks (BwK), and the\nonline stochastic packing problem (OSPP). We present algorithms with\nnear-optimal regret bounds for this problem. Our bounds compare favorably to\nresults on the unstructured version of the problem where the relation between\nthe contexts and the outcomes could be arbitrary, but the algorithm only\ncompetes against a fixed set of policies accessible through an optimization\noracle. We combine techniques from the work on linContextual, BwK, and OSPP in\na nontrivial manner while also tackling new difficulties that are not present\nin any of these special cases. \n\n"}
{"id": "1507.08092", "contents": "Title: Linear programs and convex hulls over fields of Puiseux fractions Abstract: We describe the implementation of a subfield of the field of formal Puiseux\nseries in polymake. This is employed for solving linear programs and computing\nconvex hulls depending on a real parameter. Moreover, this approach is also\nuseful for computations in tropical geometry. \n\n"}
{"id": "1507.08322", "contents": "Title: Distributed Mini-Batch SDCA Abstract: We present an improved analysis of mini-batched stochastic dual coordinate\nascent for regularized empirical loss minimization (i.e. SVM and SVM-type\nobjectives). Our analysis allows for flexible sampling schemes, including where\ndata is distribute across machines, and combines a dependence on the smoothness\nof the loss and/or the data spread (measured through the spectral norm). \n\n"}
{"id": "1508.02324", "contents": "Title: Adaptive Sampling of RF Fingerprints for Fine-grained Indoor\n  Localization Abstract: Indoor localization is a supporting technology for a broadening range of\npervasive wireless applications. One promis- ing approach is to locate users\nwith radio frequency fingerprints. However, its wide adoption in real-world\nsystems is challenged by the time- and manpower-consuming site survey process,\nwhich builds a fingerprint database a priori for localization. To address this\nproblem, we visualize the 3-D RF fingerprint data as a function of locations\n(x-y) and indices of access points (fingerprint), as a tensor and use tensor\nalgebraic methods for an adaptive tubal-sampling of this fingerprint space. In\nparticular using a recently proposed tensor algebraic framework in [1] we\ncapture the complexity of the fingerprint space as a low-dimensional\ntensor-column space. In this formulation the proposed scheme exploits\nadaptivity to identify reference points which are highly informative for\nlearning this low-dimensional space. Further, under certain incoherency\nconditions we prove that the proposed scheme achieves bounded recovery error\nand near-optimal sampling complexity. In contrast to several existing work that\nrely on random sampling, this paper shows that adaptivity in sampling can lead\nto significant improvements in localization accuracy. The approach is validated\non both data generated by the ray-tracing indoor model which accounts for the\nfloor plan and the impact of walls and the real world data. Simulation results\nshow that, while maintaining the same localization accuracy of existing\napproaches, the amount of samples can be cut down by 71% for the high SNR case\nand 55% for the low SNR case. \n\n"}
{"id": "1508.02766", "contents": "Title: FFT-Based Fast Computation of Multivariate Kernel Estimators with\n  Unconstrained Bandwidth Matrices Abstract: The problem of fast computation of multivariate kernel density estimation\n(KDE) is still an open research problem. In our view, the existing solutions do\nnot resolve this matter in a satisfactory way. One of the most elegant and\nefficient approach utilizes the fast Fourier transform. Unfortunately, the\nexisting FFT-based solution suffers from a serious limitation, as it can\naccurately operate only with the constrained (i.e., diagonal) multivariate\nbandwidth matrices. In this paper we describe the problem and give a\nsatisfactory solution. The proposed solution may be successfully used also in\nother research problems, for example for the fast computation of the optimal\nbandwidth for KDE. \n\n"}
{"id": "1508.03884", "contents": "Title: A simple sampler for the horseshoe estimator Abstract: In this note we derive a simple Bayesian sampler for linear regression with\nthe horseshoe hierarchy. A new interpretation of the horseshoe model is\npresented, and extensions to logistic regression and alternative hierarchies,\nsuch as horseshoe$+$, are discussed. Due to the conjugacy of the proposed\nhierarchy, Chib's algorithm may be used to easily compute the marginal\nlikelihood of the model. \n\n"}
{"id": "1508.05047", "contents": "Title: Rare Event Simulation Abstract: Rare events are events that are expected to occur infrequently, or more\ntechnically, those that have low probabilities (say, order of $10^{-3}$ or\nless) of occurring according to a probability model. In the context of\nuncertainty quantification, the rare events often correspond to failure of\nsystems designed for high reliability, meaning that the system performance\nfails to meet some design or operation specifications. As reviewed in this\nsection, computation of such rare-event probabilities is challenging.\nAnalytical solutions are usually not available for non-trivial problems and\nstandard Monte Carlo simulation is computationally inefficient. Therefore, much\nresearch effort has focused on developing advanced stochastic simulation\nmethods that are more efficient. In this section, we address the problem of\nestimating rare-event probabilities by Monte Carlo simulation, Importance\nSampling and Subset Simulation for highly reliable dynamic systems. \n\n"}
{"id": "1508.05631", "contents": "Title: A new convergence analysis and perturbation resilience of some\n  accelerated proximal forward-backward algorithms with errors Abstract: Many problems in science and engineering involve, as part of their solution\nprocess, the consideration of a separable function which is the sum of two\nconvex functions, one of them possibly non-smooth. Recently a few works have\ndiscussed inexact versions of several accelerated proximal methods aiming at\nsolving this minimization problem. This paper shows that inexact versions of a\nmethod of Beck and Teboulle (FISTA) preserve, in a Hilbert space setting, the\nsame (non-asymptotic) rate of convergence under some assumptions on the decay\nrate of the error terms. The notion of inexactness discussed here seems to be\nrather simple, but, interestingly, when comparing to related works, closely\nrelated decay rates of the errors terms yield closely related convergence\nrates. The derivation sheds some light on the somewhat mysterious origin of\nsome parameters which appear in various accelerated methods. A consequence of\nthe analysis is that the accelerated method is perturbation resilient, making\nit suitable, in principle, for the superiorization methodology. By taking this\ninto account, we re-examine the superiorization methodology and significantly\nextend its scope. \n\n"}
{"id": "1508.06884", "contents": "Title: Moments and Legendre-Fourier Series for Measures Supported on Curves Abstract: Some important problems (e.g., in optimal transport and optimal control) have\na relaxed (or weak) formulation in a space of appropriate measures whichis much\neasier to solve. However, an optimal solution $\\mu$ of the latter solves the\nformer if and only if the measure $\\mu$ is supported on a \"trajectory\"\n$\\{(t,x(t))\\colon t\\in [0,T]\\}$ for some measurable function $x(t)$. We provide\nnecessary and sufficient conditions on moments $(\\gamma\\_{ij})$ of a measure\n$d\\mu(x,t)$ on $[0,1]^2$ to ensure that $\\mu$ is supported on a trajectory\n$\\{(t,x(t))\\colon t\\in [0,1]\\}$. Those conditions are stated in terms of\nLegendre-Fourier coefficients ${\\mathbf f}\\_j=({\\mathbf f}\\_j(i))$ associated\nwith some functions $f\\_j\\colon [0,1]\\to {\\mathbb R}$, $j=1,\\ldots$, where each\n${\\mathbf f}\\_j$ is obtained from the moments $\\gamma\\_{ji}$, $i=0,1,\\ldots$,\nof $\\mu$. \n\n"}
{"id": "1509.00681", "contents": "Title: Locally upper Lipschitz of the perturbed KKT system of Ky Fan $k$-norm\n  matrix conic optimization problems Abstract: This note is concerned with the nonlinear Ky Fan $k$-norm matrix conic\noptimization problems, which include the nuclear norm regularized minimization\nproblem as a special case. For this class of nonpolyhedral matrix conic\noptimization problems, under the assumption that a stationary solution\nsatisfies the second-order sufficient condition and the associated Lagrange\nmultiplier satisfies the strict Robinson's CQ, we show that two classes of\nperturbed KKT systems are locally upper Lipschitz at the origin, which implies\na local error bound for the distance from any point in a neighborhood of the\ncorresponding KKT point to the whole set of KKT points. \n\n"}
{"id": "1509.01404", "contents": "Title: Coordinate Descent Methods for Symmetric Nonnegative Matrix\n  Factorization Abstract: Given a symmetric nonnegative matrix $A$, symmetric nonnegative matrix\nfactorization (symNMF) is the problem of finding a nonnegative matrix $H$,\nusually with much fewer columns than $A$, such that $A \\approx HH^T$. SymNMF\ncan be used for data analysis and in particular for various clustering tasks.\nIn this paper, we propose simple and very efficient coordinate descent schemes\nto solve this problem, and that can handle large and sparse input matrices. The\neffectiveness of our methods is illustrated on synthetic and real-world data\nsets, and we show that they perform favorably compared to recent\nstate-of-the-art methods. \n\n"}
{"id": "1509.01628", "contents": "Title: A contact covariant approach to optimal control with applications to\n  sub-Riemannian geometry Abstract: We discuss contact geometry naturally related with optimal control problems\n(and Pontryagin Maximum Principle). We explore and expand the observations of\n[Ohsawa, 2015], providing simple and elegant characterizations of normal and\nabnormal sub-Riemannian extremals. \n\n"}
{"id": "1509.04332", "contents": "Title: Learning without Recall by Random Walks on Directed Graphs Abstract: We consider a network of agents that aim to learn some unknown state of the\nworld using private observations and exchange of beliefs. At each time, agents\nobserve private signals generated based on the true unknown state. Each agent\nmight not be able to distinguish the true state based only on her private\nobservations. This occurs when some other states are observationally equivalent\nto the true state from the agent's perspective. To overcome this shortcoming,\nagents must communicate with each other to benefit from local observations. We\npropose a model where each agent selects one of her neighbors randomly at each\ntime. Then, she refines her opinion using her private signal and the prior of\nthat particular neighbor. The proposed rule can be thought of as a Bayesian\nagent who cannot recall the priors based on which other agents make inferences.\nThis learning without recall approach preserves some aspects of the Bayesian\ninference while being computationally tractable. By establishing a\ncorrespondence with a random walk on the network graph, we prove that under the\ndescribed protocol, agents learn the truth exponentially fast in the almost\nsure sense. The asymptotic rate is expressed as the sum of the relative\nentropies between the signal structures of every agent weighted by the\nstationary distribution of the random walk. \n\n"}
{"id": "1509.04879", "contents": "Title: Adapting the Number of Particles in Sequential Monte Carlo Methods\n  through an Online Scheme for Convergence Assessment Abstract: Particle filters are broadly used to approximate posterior distributions of\nhidden states in state-space models by means of sets of weighted particles.\nWhile the convergence of the filter is guaranteed when the number of particles\ntends to infinity, the quality of the approximation is usually unknown but\nstrongly dependent on the number of particles. In this paper, we propose a\nnovel method for assessing the convergence of particle filters online manner,\nas well as a simple scheme for the online adaptation of the number of particles\nbased on the convergence assessment. The method is based on a sequential\ncomparison between the actual observations and their predictive probability\ndistributions approximated by the filter. We provide a rigorous theoretical\nanalysis of the proposed methodology and, as an example of its practical use,\nwe present simulations of a simple algorithm for the dynamic and online\nadaption of the number of particles during the operation of a particle filter\non a stochastic version of the Lorenz system. \n\n"}
{"id": "1509.05001", "contents": "Title: Solving constrained quadratic binary problems via quantum adiabatic\n  evolution Abstract: Quantum adiabatic evolution is perceived as useful for binary quadratic\nprogramming problems that are a priori unconstrained. For constrained problems,\nit is a common practice to relax linear equality constraints as penalty terms\nin the objective function. However, there has not yet been proposed a method\nfor efficiently dealing with inequality constraints using the quantum adiabatic\napproach. In this paper, we give a method for solving the Lagrangian dual of a\nbinary quadratic programming (BQP) problem in the presence of inequality\nconstraints and employ this procedure within a branch-and-bound framework for\nconstrained BQP (CBQP) problems. \n\n"}
{"id": "1509.05064", "contents": "Title: Exact simultaneous recovery of locations and structure from known\n  orientations and corrupted point correspondences Abstract: Let $t_1,\\ldots,t_{n_l} \\in \\mathbb{R}^d$ and $p_1,\\ldots,p_{n_s} \\in\n\\mathbb{R}^d$ and consider the bipartite location recovery problem: given a\nsubset of pairwise direction observations $\\{(t_i - p_j) / \\|t_i -\np_j\\|_2\\}_{i,j \\in [n_l] \\times [n_s]}$, where a constant fraction of these\nobservations are arbitrarily corrupted, find $\\{t_i\\}_{i \\in [n_ll]}$ and\n$\\{p_j\\}_{j \\in [n_s]}$ up to a global translation and scale. We study the\nrecently introduced ShapeFit algorithm as a method for solving this bipartite\nlocation recovery problem. In this case, ShapeFit consists of a simple convex\nprogram over $d(n_l + n_s)$ real variables. We prove that this program recovers\na set of $n_l+n_s$ i.i.d. Gaussian locations exactly and with high probability\nif the observations are given by a bipartite Erd\\H{o}s-R\\'{e}nyi graph, $d$ is\nlarge enough, and provided that at most a constant fraction of observations\ninvolving any particular location are adversarially corrupted. This recovery\ntheorem is based on a set of deterministic conditions that we prove are\nsufficient for exact recovery. Finally, we propose a modified pipeline for the\nStructure for Motion problem, based on this bipartite location recovery\nproblem. \n\n"}
{"id": "1509.05715", "contents": "Title: MAGMA: Multi-level accelerated gradient mirror descent algorithm for\n  large-scale convex composite minimization Abstract: Composite convex optimization models arise in several applications, and are\nespecially prevalent in inverse problems with a sparsity inducing norm and in\ngeneral convex optimization with simple constraints. The most widely used\nalgorithms for convex composite models are accelerated first order methods,\nhowever they can take a large number of iterations to compute an acceptable\nsolution for large-scale problems. In this paper we propose to speed up first\norder methods by taking advantage of the structure present in many applications\nand in image processing in particular. Our method is based on multi-level\noptimization methods and exploits the fact that many applications that give\nrise to large scale models can be modelled using varying degrees of fidelity.\nWe use Nesterov's acceleration techniques together with the multi-level\napproach to achieve $\\mathcal{O}(1/\\sqrt{\\epsilon})$ convergence rate, where\n$\\epsilon$ denotes the desired accuracy. The proposed method has a better\nconvergence rate than any other existing multi-level method for convex\nproblems, and in addition has the same rate as accelerated methods, which is\nknown to be optimal for first-order methods. Moreover, as our numerical\nexperiments show, on large-scale face recognition problems our algorithm is\nseveral times faster than the state of the art. \n\n"}
{"id": "1509.06075", "contents": "Title: Inferring phylogenetic networks with maximum pseudolikelihood under\n  incomplete lineage sorting Abstract: Phylogenetic networks are necessary to represent the tree of life expanded by\nedges to represent events such as horizontal gene transfers, hybridizations or\ngene flow. Not all species follow the paradigm of vertical inheritance of their\ngenetic material. While a great deal of research has flourished into the\ninference of phylogenetic trees, statistical methods to infer phylogenetic\nnetworks are still limited and under development. The main disadvantage of\nexisting methods is a lack of scalability. Here, we present a statistical\nmethod to infer phylogenetic networks from multi-locus genetic data in a\npseudolikelihood framework. Our model accounts for incomplete lineage sorting\nthrough the coalescent model, and for horizontal inheritance of genes through\nreticulation nodes in the network. Computation of the pseudolikelihood is fast\nand simple, and it avoids the burdensome calculation of the full likelihood\nwhich can be intractable with many species. Moreover, estimation at the\nquartet-level has the added computational benefit that it is easily\nparallelizable. Simulation studies comparing our method to a full likelihood\napproach show that our pseudolikelihood approach is much faster without\ncompromising accuracy. We applied our method to reconstruct the evolutionary\nrelationships among swordtails and platyfishes ($Xiphophorus$: Poeciliidae),\nwhich is characterized by widespread hybridizations. \n\n"}
{"id": "1509.07394", "contents": "Title: Dynamic State Estimation for Multi-Machine Power System by Unscented\n  Kalman Filter with Enhanced Numerical Stability Abstract: In this paper, in order to enhance the numerical stability of the unscented\nKalman filter (UKF) used for power system dynamic state estimation, a new UKF\nwith guaranteed positive semidifinite estimation error covariance (UKF-GPS) is\nproposed and compared with five existing approaches, including UKF-schol,\nUKF-$\\kappa$, UKF-modified, UKF-$\\Delta Q$, and the square-root unscented\nKalman filter (SR-UKF). These methods and the extended Kalman filter (EKF) are\ntested by performing dynamic state estimation on WSCC 3-machine 9-bus system\nand NPCC 48-machine 140-bus system. For WSCC system, all methods obtain good\nestimates. However, for NPCC system, both EKF and the classic UKF fail. It is\nfound that UKF-schol, UKF-$\\kappa$, and UKF-$\\Delta Q$ do not work well in some\nestimations while UKF-GPS works well in most cases. UKF-modified and SR-UKF can\nalways work well, indicating their better scalability mainly due to the\nenhanced numerical stability. \n\n"}
{"id": "1509.08206", "contents": "Title: A Decentralized Multi-block ADMM for Demand-side Primary Frequency\n  Control using Local Frequency Measurements Abstract: We consider demand-side primary frequency control in the power grid provided\nby smart and flexible loads: loads change consumption to match generation and\nhelp the grid while minimizing disutility for consumers incurred by consumption\nchanges. The dual formulation of this problem has been solved previously by\nZhao et al. in a decentralized manner for consumer disutilities that are twice\ncontinuously differentiable with respect to consumption changes. In this work,\nwe propose a decentralized multi-block\nalternating-direction-method-of-multipliers (DM-ADMM) algorithm to solve this\nproblem. In contrast to the dual ascent algorithm of Zhao et al., the proposed\nDM-ADMM algorithm does not require the disutilities to be continuously\ndifferentiable; this allows disutility functions that model consumer behavior\nthat may be quite common. In this work, we prove convergence of the DM-ADMM\nalgorithm in the deterministic setting (i.e., when loads may estimate the\nconsumption-generation mismatch from frequency measurements exactly). We test\nthe performance of the DM-ADMM algorithm in simulations, and we compare (when\napplicable) with the previously proposed solution for the dual formulation. We\nalso present numerical results for a previously proposed ADMM algorithm, whose\nresults were not previously reported. \n\n"}
{"id": "1509.08990", "contents": "Title: Learning without Recall: A Case for Log-Linear Learning Abstract: We analyze a model of learning and belief formation in networks in which\nagents follow Bayes rule yet they do not recall their history of past\nobservations and cannot reason about how other agents' beliefs are formed. They\ndo so by making rational inferences about their observations which include a\nsequence of independent and identically distributed private signals as well as\nthe beliefs of their neighboring agents at each time. Fully rational agents\nwould successively apply Bayes rule to the entire history of observations. This\nleads to forebodingly complex inferences due to lack of knowledge about the\nglobal network structure that causes those observations. To address these\ncomplexities, we consider a Learning without Recall model, which in addition to\nproviding a tractable framework for analyzing the behavior of rational agents\nin social networks, can also provide a behavioral foundation for the variety of\nnon-Bayesian update rules in the literature. We present the implications of\nvarious choices for time-varying priors of such agents and how this choice\naffects learning and its rate. \n\n"}
{"id": "1509.09259", "contents": "Title: Distributionally Robust Logistic Regression Abstract: This paper proposes a distributionally robust approach to logistic\nregression. We use the Wasserstein distance to construct a ball in the space of\nprobability distributions centered at the uniform distribution on the training\nsamples. If the radius of this ball is chosen judiciously, we can guarantee\nthat it contains the unknown data-generating distribution with high confidence.\nWe then formulate a distributionally robust logistic regression model that\nminimizes a worst-case expected logloss function, where the worst case is taken\nover all distributions in the Wasserstein ball. We prove that this optimization\nproblem admits a tractable reformulation and encapsulates the classical as well\nas the popular regularized logistic regression problems as special cases. We\nfurther propose a distributionally robust approach based on Wasserstein balls\nto compute upper and lower confidence bounds on the misclassification\nprobability of the resulting classifier. These bounds are given by the optimal\nvalues of two highly tractable linear programs. We validate our theoretical\nout-of-sample guarantees through simulated and empirical experiments. \n\n"}
{"id": "1510.01497", "contents": "Title: Optimal Placement of Virtual Inertia in Power Grids Abstract: A major transition in the operation of electric power grids is the\nreplacement of synchronous machines by distributed generation connected via\npower electronic converters. The accompanying \"loss of rotational inertia\" and\nthe fluctuations by renewable sources jeopardize the system stability, as\ntestified by the ever-growing number of frequency incidents. As a remedy,\nnumerous studies demonstrate how virtual inertia can be emulated through\nvarious devices, but few of them address the question of \"where\" to place this\ninertia. It is however strongly believed that the placement of virtual inertia\nhugely impacts system efficiency, as demonstrated by recent case studies. In\nthis article, we carry out a comprehensive analysis in an attempt to address\nthe optimal inertia placement problem. We consider a linear network-reduced\npower system model along with an H2 performance metric accounting for the\nnetwork coherency. The optimal inertia placement problem turns out to be\nnon-convex, yet we provide a set of closed-form global optimality results for\nparticular problem instances as well as a computational approach resulting in\nlocally optimal solutions. Further, we also consider the robust inertia\nallocation problem, wherein the optimization is carried out accounting for the\nworst-case disturbance location. We illustrate our results with a three-region\npower grid case study and compare our locally optimal solution with different\nplacement heuristics in terms of different performance metrics. \n\n"}
{"id": "1510.04214", "contents": "Title: LQG Control with Minimum Directed Information: Semidefinite Programming\n  Approach Abstract: We consider a discrete-time Linear-Quadratic-Gaussian (LQG) control problem\nin which Massey's directed information from the observed output of the plant to\nthe control input is minimized while required control performance is\nattainable. This problem arises in several different contexts, including joint\nencoder and controller design for data-rate minimization in networked control\nsystems. We show that the optimal control law is a Linear-Gaussian randomized\npolicy. We also identify the state space realization of the optimal policy,\nwhich can be synthesized by an efficient algorithm based on semidefinite\nprogramming. Our structural result indicates that the filter-controller\nseparation principle from the LQG control theory, and the sensor-filter\nseparation principle from the zero-delay rate-distortion theory for\nGauss-Markov sources hold simultaneously in the considered problem. A\nconnection to the data-rate theorem for mean-square stability by Nair and Evans\nis also established. \n\n"}
{"id": "1510.04330", "contents": "Title: Convex Relaxations of Optimal Power Flow Problems: An Illustrative\n  Example Abstract: Recently, there has been significant interest in convex relaxations of the\noptimal power flow (OPF) problem. A semidefinite programming (SDP) relaxation\nglobally solves many OPF problems. However, there exist practical problems for\nwhich the SDP relaxation fails to yield the global solution. Conditions for the\nsuccess or failure of the SDP relaxation are valuable for determining whether\nthe relaxation is appropriate for a given OPF problem. To move beyond existing\nconditions, which only apply to a limited class of problems, a typical\nconjecture is that failure of the SDP relaxation can be related to physical\ncharacteristics of the system. By presenting an example OPF problem with two\nequivalent formulations, this paper demonstrates that physically based\nconditions cannot universally explain algorithm behavior. The SDP relaxation\nfails for one formulation but succeeds in finding the global solution to the\nother formulation. Since these formulations represent the same system, success\n(or otherwise) of the SDP relaxation must involve factors beyond just the\nnetwork physics. The lack of universal physical conditions for success of the\nSDP relaxation motivates the development of tighter convex relaxations capable\nof solving a broader class of problems. Tools from polynomial optimization\ntheory provide a means of developing tighter relaxations. We use the example\nOPF problem to illustrate relaxations from the Lasserre hierarchy for\npolynomial optimization and a related \"mixed semidefinite/second-order cone\nprogramming\" hierarchy. \n\n"}
{"id": "1510.05417", "contents": "Title: Piecewise-Linear Approximation for Feature Subset Selection in a\n  Sequential Logit Model Abstract: This paper concerns a method of selecting a subset of features for a\nsequential logit model. Tanaka and Nakagawa (2014) proposed a mixed integer\nquadratic optimization formulation for solving the problem based on a quadratic\napproximation of the logistic loss function. However, since there is a\nsignificant gap between the logistic loss function and its quadratic\napproximation, their formulation may fail to find a good subset of features. To\novercome this drawback, we apply a piecewise-linear approximation to the\nlogistic loss function. Accordingly, we frame the feature subset selection\nproblem of minimizing an information criterion as a mixed integer linear\noptimization problem. The computational results demonstrate that our\npiecewise-linear approximation approach found a better subset of features than\nthe quadratic approximation approach. \n\n"}
{"id": "1510.06567", "contents": "Title: Generalized conditional gradient: analysis of convergence and\n  applications Abstract: The objectives of this technical report is to provide additional results on\nthe generalized conditional gradient methods introduced by Bredies et al.\n[BLM05]. Indeed , when the objective function is smooth, we provide a novel\ncertificate of optimality and we show that the algorithm has a linear\nconvergence rate. Applications of this algorithm are also discussed. \n\n"}
{"id": "1510.06823", "contents": "Title: Convergence rate analysis for averaged fixed point iterations in the\n  presence of H\\\"older regularity Abstract: In this paper, we establish sublinear and linear convergence of fixed point\niterations generated by averaged operators in a Hilbert space. Our results are\nachieved under a bounded H\\\"older regularity assumption which generalizes the\nwell-known notion of bounded linear regularity. As an application of our\nresults, we provide a convergence rate analysis for Krasnoselskii-Mann\niterations, the cyclic projection algorithm, and the Douglas-Rachford\nfeasibility algorithm along with some variants. In the important case in which\nthe underlying sets are convex sets described by convex polynomials in a finite\ndimensional space, we show that the H\\\"older regularity properties are\nautomatically satisfied, from which sublinear convergence follows. \n\n"}
{"id": "1510.08439", "contents": "Title: Stochastic control for a class of nonlinear kernels and applications Abstract: We consider a stochastic control problem for a class of nonlinear kernels.\nMore precisely, our problem of interest consists in the optimisation, over a\nset of possibly non-dominated probability measures, of solutions of backward\nstochastic differential equations (BSDEs). Since BSDEs are nonlinear\ngeneralisations of the traditional (linear) expectations, this problem can be\nunderstood as stochastic control of a family of nonlinear expectations, or\nequivalently of nonlinear kernels. Our first main contribution is to prove a\ndynamic programming principle for this control problem in an abstract setting,\nwhich we then use to provide a semi-martingale characterisation of the value\nfunction. We next explore several applications of our results. We first obtain\na wellposedness result for second order BSDEs (as introduced in [86]) which\ndoes not require any regularity assumption on the terminal condition and the\ngenerator. Then we prove a nonlinear optional decomposition in a robust\nsetting, extending recent results of [71], which we then use to obtain a\nsuper-hedging duality in uncertain, incomplete and nonlinear financial markets.\nFinally, we relate, under additional regularity assumptions, the value function\nto a viscosity solution of an appropriate path-dependent partial differential\nequation (PPDE). \n\n"}
{"id": "1511.01821", "contents": "Title: Fault-Tolerant Distributed Optimization (Part IV): Constrained\n  Optimization with Arbitrary Directed Networks Abstract: We study the problem of constrained distributed optimization in multi-agent\nnetworks when some of the computing agents may be faulty. In this problem, the\nsystem goal is to have all the non-faulty agents collectively minimize a global\nobjective given by weighted average of local cost functions, each of which is\ninitially known to a non-faulty agent only. In particular, we are interested in\nthe scenario when the computing agents are connected by an arbitrary directed\ncommunication network, some of the agents may suffer from crash faults or\nByzantine faults, and the estimate of each agent is restricted to lie in a\ncommon constraint set. This problem finds its applications in social computing\nand distributed large-scale machine learning.\n  The fault-tolerant multi-agent optimization problem was first formulated by\nSu and Vaidya, and is solved when the local functions are defined over the\nwhole real line, and the networks are fully-connected. In this report, we\nconsider arbitrary directed communication networks and focus on the scenario\nwhere, local estimates at the non-faulty agents are constrained, and only local\ncommunication and minimal memory carried across iterations are allowed. In\nparticular, we generalize our previous results on fully-connected networks and\nunconstrained optimization to arbitrary directed networks and constrained\noptimization. As a byproduct, we provide a matrix representation for iterative\napproximate crash consensus. The matrix representation allows us to\ncharacterize the convergence rate for crash iterative consensus. \n\n"}
{"id": "1511.04815", "contents": "Title: Convex programming with fast proximal and linear operators Abstract: We present Epsilon, a system for general convex programming using fast linear\nand proximal operators. As with existing convex programming frameworks, users\nspecify convex optimization problems using a natural grammar for mathematical\nexpressions, composing functions in a way that is guaranteed to be convex by\nthe rules of disciplined convex programming. Given such an input, the Epsilon\ncompiler transforms the optimization problem into a mathematically equivalent\nform consisting only of functions with efficient proximal operators---an\nintermediate representation we refer to as prox-affine form. By reducing\nproblems to this form, Epsilon enables solving general convex problems using a\nlarge library of fast proximal and linear operators; numerical examples on many\npopular problems from statistics and machine learning show that this often\nimproves running times by an order of magnitude or more vs. existing approaches\nbased on conic solvers. \n\n"}
{"id": "1511.05864", "contents": "Title: Fast Saddle-Point Algorithm for Generalized Dantzig Selector and FDR\n  Control with the Ordered l1-Norm Abstract: In this paper we propose a primal-dual proximal extragradient algorithm to\nsolve the generalized Dantzig selector (GDS) estimation problem, based on a new\nconvex-concave saddle-point (SP) reformulation. Our new formulation makes it\npossible to adopt recent developments in saddle-point optimization, to achieve\nthe optimal $O(1/k)$ rate of convergence. Compared to the optimal non-SP\nalgorithms, ours do not require specification of sensitive parameters that\naffect algorithm performance or solution quality. We also provide a new\nanalysis showing a possibility of local acceleration to achieve the rate of\n$O(1/k^2)$ in special cases even without strong convexity or strong smoothness.\nAs an application, we propose a GDS equipped with the ordered $\\ell_1$-norm,\nshowing its false discovery rate control properties in variable selection.\nAlgorithm performance is compared between ours and other alternatives,\nincluding the linearized ADMM, Nesterov's smoothing, Nemirovski's mirror-prox,\nand the accelerated hybrid proximal extragradient techniques. \n\n"}
{"id": "1511.07293", "contents": "Title: Sparse Recovery via Partial Regularization: Models, Theory and\n  Algorithms Abstract: In the context of sparse recovery, it is known that most of existing\nregularizers such as $\\ell_1$ suffer from some bias incurred by some leading\nentries (in magnitude) of the associated vector. To neutralize this bias, we\npropose a class of models with partial regularizers for recovering a sparse\nsolution of a linear system. We show that every local minimizer of these models\nis sufficiently sparse or the magnitude of all its nonzero entries is above a\nuniform constant depending only on the data of the linear system. Moreover, for\na class of partial regularizers, any global minimizer of these models is a\nsparsest solution to the linear system. We also establish some sufficient\nconditions for local or global recovery of the sparsest solution to the linear\nsystem, among which one of the conditions is weaker than the best known\nrestricted isometry property (RIP) condition for sparse recovery by $\\ell_1$.\nIn addition, a first-order feasible augmented Lagrangian (FAL) method is\nproposed for solving these models, in which each subproblem is solved by a\nnonmonotone proximal gradient (NPG) method. Despite the complication of the\npartial regularizers, we show that each proximal subproblem in NPG can be\nsolved as a certain number of one-dimensional optimization problems, which\nusually have a closed-form solution. We also show that any accumulation point\nof the sequence generated by FAL is a first-order stationary point of the\nmodels. Numerical results on compressed sensing and sparse logistic regression\ndemonstrate that the proposed models substantially outperform the widely used\nones in the literature in terms of solution quality. \n\n"}
{"id": "1511.07293", "contents": "Title: Sparse Recovery via Partial Regularization: Models, Theory and\n  Algorithms Abstract: In the context of sparse recovery, it is known that most of existing\nregularizers such as $\\ell_1$ suffer from some bias incurred by some leading\nentries (in magnitude) of the associated vector. To neutralize this bias, we\npropose a class of models with partial regularizers for recovering a sparse\nsolution of a linear system. We show that every local minimizer of these models\nis sufficiently sparse or the magnitude of all its nonzero entries is above a\nuniform constant depending only on the data of the linear system. Moreover, for\na class of partial regularizers, any global minimizer of these models is a\nsparsest solution to the linear system. We also establish some sufficient\nconditions for local or global recovery of the sparsest solution to the linear\nsystem, among which one of the conditions is weaker than the best known\nrestricted isometry property (RIP) condition for sparse recovery by $\\ell_1$.\nIn addition, a first-order feasible augmented Lagrangian (FAL) method is\nproposed for solving these models, in which each subproblem is solved by a\nnonmonotone proximal gradient (NPG) method. Despite the complication of the\npartial regularizers, we show that each proximal subproblem in NPG can be\nsolved as a certain number of one-dimensional optimization problems, which\nusually have a closed-form solution. We also show that any accumulation point\nof the sequence generated by FAL is a first-order stationary point of the\nmodels. Numerical results on compressed sensing and sparse logistic regression\ndemonstrate that the proposed models substantially outperform the widely used\nones in the literature in terms of solution quality. \n\n"}
{"id": "1511.08138", "contents": "Title: Uniformly hyperbolic control theory Abstract: This paper gives a summary of a body of work at the intersection of control\ntheory and smooth nonlinear dynamics. The main idea is to transfer the concept\nof uniform hyperbolicity, central to the theory of smooth dynamical systems, to\ncontrol-affine systems. Combining the strength of geometric control theory and\nthe hyperbolic theory of dynamical systems, it is possible to deduce\ncontrol-theoretic results of non-local nature that reveal remarkable analogies\nto the classical hyperbolic theory of dynamical systems. This includes results\non controllability, robustness, and practical stabilizability in a networked\ncontrol framework. \n\n"}
{"id": "1511.08609", "contents": "Title: Centerpoints: A link between optimization and convex geometry Abstract: We introduce a concept that generalizes several different notions of a\n\"centerpoint\" in the literature. We develop an oracle-based algorithm for\nconvex mixed-integer optimization based on centerpoints. Further, we show that\nalgorithms based on centerpoints are \"best possible\" in a certain sense.\nMotivated by this, we establish several structural results about this concept\nand provide efficient algorithms for computing these points. Our main\nmotivation is to understand the complexity of oracle based convex mixed-integer\noptimization. \n\n"}
{"id": "1512.00298", "contents": "Title: On Optical Flow Models for Variational Motion Estimation Abstract: The aim of this paper is to discuss and evaluate total variation based\nregularization methods for motion estimation, with particular focus on optical\nflow models. In addition to standard $L^2$ and $L^1$ data fidelities we give an\noverview of different variants of total variation regularization obtained from\ncombination with higher order models and a unified computational optimization\napproach based on primal-dual methods. Moreover, we extend the models by\nBregman iterations and provide an inverse problems perspective to the analysis\nof variational optical flow models. A particular focus of the paper is the\nquantitative evaluation of motion estimation, which is a difficult and often\nunderestimated task. We discuss several approaches for quality measures of\nmotion estimation and apply them to compare the previously discussed\nregularization approaches. \n\n"}
{"id": "1512.00792", "contents": "Title: Microclustering: When the Cluster Sizes Grow Sublinearly with the Size\n  of the Data Set Abstract: Most generative models for clustering implicitly assume that the number of\ndata points in each cluster grows linearly with the total number of data\npoints. Finite mixture models, Dirichlet process mixture models, and\nPitman--Yor process mixture models make this assumption, as do all other\ninfinitely exchangeable clustering models. However, for some tasks, this\nassumption is undesirable. For example, when performing entity resolution, the\nsize of each cluster is often unrelated to the size of the data set.\nConsequently, each cluster contains a negligible fraction of the total number\nof data points. Such tasks therefore require models that yield clusters whose\nsizes grow sublinearly with the size of the data set. We address this\nrequirement by defining the \\emph{microclustering property} and introducing a\nnew model that exhibits this property. We compare this model to several\ncommonly used clustering models by checking model fit using real and simulated\ndata sets. \n\n"}
{"id": "1512.01708", "contents": "Title: Variance Reduction for Distributed Stochastic Gradient Descent Abstract: Variance reduction (VR) methods boost the performance of stochastic gradient\ndescent (SGD) by enabling the use of larger, constant stepsizes and preserving\nlinear convergence rates. However, current variance reduced SGD methods require\neither high memory usage or an exact gradient computation (using the entire\ndataset) at the end of each epoch. This limits the use of VR methods in\npractical distributed settings. In this paper, we propose a variance reduction\nmethod, called VR-lite, that does not require full gradient computations or\nextra storage. We explore distributed synchronous and asynchronous variants\nthat are scalable and remain stable with low communication frequency. We\nempirically compare both the sequential and distributed algorithms to\nstate-of-the-art stochastic optimization methods, and find that our proposed\nalgorithms perform favorably to other stochastic methods. \n\n"}
{"id": "1512.03107", "contents": "Title: RSG: Beating Subgradient Method without Smoothness and Strong Convexity Abstract: In this paper, we study the efficiency of a {\\bf R}estarted {\\bf S}ub{\\bf\nG}radient (RSG) method that periodically restarts the standard subgradient\nmethod (SG). We show that, when applied to a broad class of convex optimization\nproblems, RSG method can find an $\\epsilon$-optimal solution with a lower\ncomplexity than the SG method. In particular, we first show that RSG can reduce\nthe dependence of SG's iteration complexity on the distance between the initial\nsolution and the optimal set to that between the $\\epsilon$-level set and the\noptimal set {multiplied by a logarithmic factor}. Moreover, we show the\nadvantages of RSG over SG in solving three different families of convex\noptimization problems. (a) For the problems whose epigraph is a polyhedron, RSG\nis shown to converge linearly. (b) For the problems with local quadratic growth\nproperty in the $\\epsilon$-sublevel set, RSG has an\n$O(\\frac{1}{\\epsilon}\\log(\\frac{1}{\\epsilon}))$ iteration complexity. (c) For\nthe problems that admit a local Kurdyka-\\L ojasiewicz property with a power\nconstant of $\\beta\\in[0,1)$, RSG has an\n$O(\\frac{1}{\\epsilon^{2\\beta}}\\log(\\frac{1}{\\epsilon}))$ iteration complexity.\nThe novelty of our analysis lies at exploiting the lower bound of the\nfirst-order optimality residual at the $\\epsilon$-level set. It is this novelty\nthat allows us to explore the local properties of functions (e.g., local\nquadratic growth property, local Kurdyka-\\L ojasiewicz property, more generally\nlocal error bound conditions) to develop the improved convergence of RSG. { We\nalso develop a practical variant of RSG enjoying faster convergence than the SG\nmethod, which can be run without knowing the involved parameters in the local\nerror bound condition.} We demonstrate the effectiveness of the proposed\nalgorithms on several machine learning tasks including regression,\nclassification and matrix completion. \n\n"}
{"id": "1512.04680", "contents": "Title: Improved Iteration Complexity Bounds of Cyclic Block Coordinate Descent\n  for Convex Problems Abstract: The iteration complexity of the block-coordinate descent (BCD) type algorithm\nhas been under extensive investigation. It was recently shown that for convex\nproblems the classical cyclic BCGD (block coordinate gradient descent) achieves\nan $\\mathcal{O}(1/r)$ complexity ($r$ is the number of passes of all blocks).\nHowever, such bounds are at least linearly depend on $K$ (the number of\nvariable blocks), and are at least $K$ times worse than those of the gradient\ndescent (GD) and proximal gradient (PG) methods. In this paper, we aim to close\nsuch theoretical performance gap between cyclic BCD and GD/PG. First we show\nthat for a family of quadratic nonsmooth problems, the complexity bounds for\ncyclic Block Coordinate Proximal Gradient (BCPG), a popular variant of BCD, can\nmatch those of the GD/PG in terms of dependency on $K$ (up to a $\\log^2(K)$\nfactor). For the same family of problems, we also improve the bounds of the\nclassical BCD (with exact block minimization) by an order of $K$. Second, we\nestablish an improved complexity bound of Coordinate Gradient Descent (CGD) for\ngeneral convex problems which can match that of GD in certain scenarios. Our\nbounds are sharper than the known bounds as they are always at least $K$ times\nworse than GD. Our analyses do not depend on the update order of block\nvariables inside each cycle, thus our results also apply to BCD methods with\nrandom permutation (random sampling without replacement, another popular\nvariant). \n\n"}
{"id": "1512.06427", "contents": "Title: Towards Integrated Glance To Restructuring in Combinatorial Optimization Abstract: The paper focuses on a new class of combinatorial problems which consists in\nrestructuring of solutions (as sets/structures) in combinatorial optimization.\nTwo main features of the restructuring process are examined: (i) a cost of the\nrestructuring, (ii) a closeness to a goal solution. Three types of the\nrestructuring problems are under study: (a) one-stage structuring, (b)\nmulti-stage structuring, and (c) structuring over changed element set.\nOne-criterion and multicriteria problem formulations can be considered. The\nrestructuring problems correspond to redesign (improvement, upgrade) of modular\nsystems or solutions. The restructuring approach is described and illustrated\n(problem statements, solving schemes, examples) for the following combinatorial\noptimization problems: knapsack problem, multiple choice problem, assignment\nproblem, spanning tree problems, clustering problem, multicriteria ranking\n(sorting) problem, morphological clique problem. Numerical examples illustrate\nthe restructuring problems and solving schemes. \n\n"}
{"id": "1512.06516", "contents": "Title: Local exact controllability for the 2 and 3-d compressible Navier-Stokes\n  equations Abstract: The goal of this article is to present a local exact controllability result\nfor the 2 and 3-dimensional compressible Navier-Stokes equations on a constant\ntarget trajectory when the controls act on the whole boundary. Our study is\nthen based on the observability of the adjoint system of some linearized\nversion of the system, which is analyzed thanks to a subsystem for which the\ncoupling terms are somewhat weaker. In this step, we strongly use Carleman\nestimates in negative Sobolev spaces. \n\n"}
{"id": "1512.06888", "contents": "Title: On Distributed Cooperative Decision-Making in Multiarmed Bandits Abstract: We study the explore-exploit tradeoff in distributed cooperative\ndecision-making using the context of the multiarmed bandit (MAB) problem. For\nthe distributed cooperative MAB problem, we design the cooperative UCB\nalgorithm that comprises two interleaved distributed processes: (i) running\nconsensus algorithms for estimation of rewards, and (ii)\nupper-confidence-bound-based heuristics for selection of arms. We rigorously\nanalyze the performance of the cooperative UCB algorithm and characterize the\ninfluence of communication graph structure on the decision-making performance\nof the group. \n\n"}
{"id": "1512.06929", "contents": "Title: Facility Deployment Decisions through Warp Optimizaton of Regressed\n  Gaussian Processes Abstract: A method for quickly determining deployment schedules that meet a given fuel\ncycle demand is presented here. This algorithm is fast enough to perform in\nsitu within low-fidelity fuel cycle simulators. It uses Gaussian process\nregression models to predict the production curve as a function of time and the\nnumber of deployed facilities. Each of these predictions is measured against\nthe demand curve using the dynamic time warping distance. The minimum distance\ndeployment schedule is evaluated in a full fuel cycle simulation, whose\ngenerated production curve then informs the model on the next optimization\niteration. The method converges within five to ten iterations to a distance\nthat is less than one percent of the total deployable production. A\nrepresentative once-through fuel cycle is used to demonstrate the methodology\nfor reactor deployment. \n\n"}
{"id": "1512.07569", "contents": "Title: Accelerated First-Order Methods for Hyperbolic Programming Abstract: A framework is developed for applying accelerated methods to general\nhyperbolic programming, including linear, second-order cone, and semidefinite\nprogramming as special cases. The approach replaces a hyperbolic program with a\nconvex optimization problem whose smooth objective function is explicit, and\nfor which the only constraints are linear equations (one more linear equation\nthan for the original problem). Virtually any first-order method can be\napplied. Iteration bounds for a representative accelerated method are derived. \n\n"}
{"id": "1512.07638", "contents": "Title: Satisficing in multi-armed bandit problems Abstract: Satisficing is a relaxation of maximizing and allows for less risky decision\nmaking in the face of uncertainty. We propose two sets of satisficing\nobjectives for the multi-armed bandit problem, where the objective is to\nachieve reward-based decision-making performance above a given threshold. We\nshow that these new problems are equivalent to various standard multi-armed\nbandit problems with maximizing objectives and use the equivalence to find\nbounds on performance. The different objectives can result in qualitatively\ndifferent behavior; for example, agents explore their options continually in\none case and only a finite number of times in another. For the case of Gaussian\nrewards we show an additional equivalence between the two sets of satisficing\nobjectives that allows algorithms developed for one set to be applied to the\nother. We then develop variants of the Upper Credible Limit (UCL) algorithm\nthat solve the problems with satisficing objectives and show that these\nmodified UCL algorithms achieve efficient satisficing performance. \n\n"}
{"id": "1512.09235", "contents": "Title: A primal-dual fixed-point algorithm for minimization of the sum of three\n  convex separable functions Abstract: Many problems arising in image processing and signal recovery with\nmulti-regularization can be formulated as minimization of a sum of three convex\nseparable functions. Typically, the objective function involves a smooth\nfunction with Lipschitz continuous gradient, a linear composite nonsmooth\nfunction and a nonsmooth function. In this paper, we propose a primal-dual\nfixed-point (PDFP) scheme to solve the above class of problems. The proposed\nalgorithm for three block problems is a fully splitting symmetric scheme, only\ninvolving explicit gradient and linear operators without inner iteration, when\nthe nonsmooth functions can be easily solved via their proximity operators,\nsuch as $\\ell_1$ type regularization. We study the convergence of the proposed\nalgorithm and illustrate its efficiency through examples on fused LASSO and\nimage restoration with non-negative constraint and sparse regularization. \n\n"}
{"id": "1601.00605", "contents": "Title: Computational Methods For Extremal Steklov Problems Abstract: We develop a computational method for extremal Steklov eigenvalue problems\nand apply it to study the problem of maximizing the $p$-th Steklov eigenvalue\nas a function of the domain with a volume constraint. In contrast to the\noptimal domains for several other extremal Dirichlet- and Neumann-Laplacian\neigenvalue problems, computational results suggest that the optimal domains for\nthis problem are very structured. We reach the conjecture that the domain\nmaximizing the $p$-th Steklov eigenvalue is unique (up to dilations and rigid\ntransformations), has p-fold symmetry, and an axis of symmetry. The $p$-th\nSteklov eigenvalue has multiplicity 2 if $p$ is even and multiplicity 3 if\n$p\\geq3$ is odd. \n\n"}
{"id": "1601.00630", "contents": "Title: Approximating the Distribution of the Median and other Robust Estimators\n  on Uncertain Data Abstract: Robust estimators, like the median of a point set, are important for data\nanalysis in the presence of outliers. We study robust estimators for\nlocationally uncertain points with discrete distributions. That is, each point\nin a data set has a discrete probability distribution describing its location.\nThe probabilistic nature of uncertain data makes it challenging to compute such\nestimators, since the true value of the estimator is now described by a\ndistribution rather than a single point. We show how to construct and estimate\nthe distribution of the median of a point set. Building the approximate support\nof the distribution takes near-linear time, and assigning probability to that\nsupport takes quadratic time. We also develop a general approximation technique\nfor distributions of robust estimators with respect to ranges with bounded VC\ndimension. This includes the geometric median for high dimensions and the\nSiegel estimator for linear regression. \n\n"}
{"id": "1601.01738", "contents": "Title: Spectral projected gradient methods for generalized tensor eigenvalue\n  complementarity problem Abstract: This paper looks at the tensor eigenvalue complementarity problem (TEiCP)\nwhich arises from the stability analysis of finite dimensional mechanical\nsystems and is closely related to the optimality conditions for polynomial\noptimization. We investigate two monotone ascent spectral projected gradient\n(SPG) methods for TEiCP. We also present a shifted scaling-and-projection\nalgorithm (SPA), which is a great improvement of the original SPA method\nproposed by Ling, He and Qi [Comput. Optim. Appl., DOI\n10.1007/s10589-015-9767-z]. Numerical comparisons with some existed gradient\nmethods in the literature are reported to illustrate the efficiency of the\nproposed methods. \n\n"}
{"id": "1601.02510", "contents": "Title: Bifurcation Thresholds and Optimal Control in Transmission Dynamics of\n  Arboviral Diseases Abstract: In this paper, we derive and analyse a model for the control of arboviral\ndiseases which takes into account an imperfect vaccine combined with some other\nmechanisms of control already studied in the literature. We begin by analyse\nthe basic model without controls. We prove the existence of two disease-free\nequilibrium points and the possible existence of up to two endemic equilibrium\npoints (where the disease persists in the population). We show the existence of\na transcritical bifurcation and a possible saddle-node bifurcation and\nexplicitly derive threshold conditions for both, including defining the basic\nreproduction number, R 0 , which determines whether the disease can persist in\nthe population or not. The epidemiological consequence of saddle-node\nbifurcation (backward bifurcation) is that the classical requirement of having\nthe reproduction number less than unity, while necessary, is no longer\nsufficient for disease elimination from the population. It is further shown\nthat in the absence of disease--induced death, the model does not exhibit this\nphenomenon. We perform the sensitivity analysis to determine the model\nrobustness to parameter values. That is to help us to know the parameters that\nare most influential in determining disease dynamics. The model is extended by\nreformulating the model as an optimal control problem, with the use of five\ntime dependent controls, to assess the impact of vaccination combined with\ntreatment, individual protection and vector control strategies (killing adult\nvectors, reduction of eggs and larvae). By using optimal control theory, we\nestablish optimal conditions under which the disease can be eradicated and we\nexamine the impact of a possible combined control tools on the disease\ntransmission. The Pontryagin's maximum principle is used to characterize the\noptimal control. Numerical simulations, efficiency analysis and cost\neffectiveness analysis show that, vaccination combined with other control\nmechanisms, would reduce the spread of the disease appreciably, and this at low\ncost. \n\n"}
{"id": "1601.03249", "contents": "Title: Optimal trajectory tracking Abstract: This thesis investigates optimal trajectory tracking of nonlinear dynamical\nsystems with affine controls. The control task is to enforce the system state\nto follow a prescribed desired trajectory as closely as possible. The concept\nof so-called exactly realizable trajectories is proposed. For exactly\nrealizable desired trajectories exists a control signal which enforces the\nstate to exactly follow the desired trajectory. For a given affine control\nsystem, these trajectories are characterized by the so-called constraint\nequation. This approach does not only yield an explicit expression for the\ncontrol signal in terms of the desired trajectory, but also identifies a\nparticularly simple class of nonlinear control systems. Based on that insight,\nthe regularization parameter is used as the small parameter for a perturbation\nexpansion. This results in a reinterpretation of affine optimal control\nproblems with small regularization term as singularly perturbed differential\nequations. The small parameter originates from the formulation of the control\nproblem and does not involve simplifying assumptions about the system dynamics.\nCombining this approach with the linearizing assumption, approximate and partly\nlinear equations for the optimal trajectory tracking of arbitrary desired\ntrajectories are derived. For vanishing regularization parameter, the state\ntrajectory becomes discontinuous and the control signal diverges. On the other\nhand, the analytical treatment becomes exact and the solutions are exclusively\ngoverned by linear differential equations. Thus, the possibility of linear\nstructures underlying nonlinear optimal control is revealed. This fact enables\nthe derivation of exact analytical solutions to an entire class of nonlinear\ntrajectory tracking problems with affine controls. This class comprises\nmechanical control systems in one spatial dimension and the FitzHugh-Nagumo\nmodel. \n\n"}
{"id": "1601.04308", "contents": "Title: On Neumann problems for nonlocal Hamilton-Jacobi equations with\n  dominating gradient terms Abstract: We are concerned with the well-posedness of Neumann boundary value problems\nfor nonlocal Hamilton-Jacobi equations related to jump processes in general\nsmooth domains. We consider a nonlocal diffusive term of censored type of order\nless than 1 and Hamiltonians both in coercive form and in noncoercive Bellman\nform, whose growth in the gradient make them the leading term in the equation.\nWe prove a comparison principle for bounded sub-and supersolutions in the\ncontext of viscosity solutions with generalized boundary conditions, and\nconsequently by Perron's method we get the existence and uniqueness of\ncontinuous solutions. We give some applications in the evolutive setting,\nproving the large time behaviour of the associated evolutive problem under\nsuitable assumptions on the data. \n\n"}
{"id": "1601.05102", "contents": "Title: Monotone Order Properties for Control of Nonlinear Parabolic PDE on\n  Graphs Abstract: We derive conditions for the propagation of monotone ordering properties for\na class of nonlinear parabolic partial differential equation (PDE) systems on\nmetric graphs. For such systems, PDE equations with a general nonlinear\ndissipation term define evolution on each edge, and balance laws create\nKirchhoff-Neumann boundary conditions at the vertices. Initial conditions, as\nwell as time-varying parameters in the coupling conditions at vertices, provide\nan initial value problem (IVP). We first prove that ordering properties of the\nsolution to the IVP are preserved when the initial conditions and time-varying\ncoupling law parameters at vertices are appropriately ordered. In addition, we\nprove that when monotone ordering is not preserved, the first crossing of\nsolutions occurs at a graph vertex. We consider the implications for robust\noptimal control formulations and real-time monitoring involving uncertain\ndynamic flows on networks, and discuss application to subsonic compressible\nfluid flow with energy dissipation on physical networks. \n\n"}
{"id": "1601.07071", "contents": "Title: Adaptive Leader-Following Consensus for a Class of Higher-Order\n  Nonlinear Multi-Agent Systems with Directed Switching Networks Abstract: In this paper, we study the leader-following consensus problem for a class of\nuncertain nonlinear multi-agent systems under jointly connected directed\nswitching networks. The uncertainty includes constant unbounded parameters and\nexternal disturbances. We first extend the recent result on the adaptive\ndistributed observer from global asymptotical convergence to global exponential\nconvergence. Then, by integrating the conventional adaptive control technique\nwith the adaptive distributed observer, we present our solution by a\ndistributed adaptive state feedback control law. Our result is illustrated by\nthe leader-following consensus problem for a group of van der Pol oscillators. \n\n"}
{"id": "1601.07592", "contents": "Title: Non-asymptotic confidence bounds for the optimal value of a stochastic\n  program Abstract: We discuss a general approach to building non-asymptotic confidence bounds\nfor stochastic optimization problems. Our principal contribution is the\nobservation that a Sample Average Approximation of a problem supplies upper and\nlower bounds for the optimal value of the problem which are essentially better\nthan the quality of the corresponding optimal solutions. At the same time, such\nbounds are more reliable than \"standard\" confidence bounds obtained through the\nasymptotic approach. We also discuss bounding the optimal value of MinMax\nStochastic Optimization and stochastically constrained problems. We conclude\nwith a simulation study illustrating the numerical behavior of the proposed\nbounds. \n\n"}
{"id": "1602.00079", "contents": "Title: Unit Commitment with N-1 Security and Wind Uncertainty Abstract: As renewable wind energy penetration rates continue to increase, one of the\nmajor challenges facing grid operators is the question of how to control\ntransmission grids in a reliable and a cost-efficient manner. The stochastic\nnature of wind forces an alteration of traditional methods for solving\nday-ahead and look-ahead unit commitment and dispatch. In particular,\nuncontrollable wind generation increases the risk of random component failures.\nTo address these questions, we present an N-1 Security and Chance-Constrained\nUnit Commitment (SCCUC) that includes the modeling of generation reserves that\nrespond to wind fluctuations and tertiary reserves to account for single\ncomponent outages. The basic formulation is reformulated as a mixed-integer\nsecond-order cone problem to limit the probability of failure. We develop three\ndifferent algorithms to solve the problem to optimality and present a detailed\ncase study on the IEEE RTS-96 single area system. The case study assesses the\neconomic impacts due to contingencies and various degrees of wind power\npenetration into the system and also corroborates the effectiveness of the\nalgorithms. \n\n"}
{"id": "1602.00382", "contents": "Title: Distributed Constrained Recursive Nonlinear Least-Squares Estimation:\n  Algorithms and Asymptotics Abstract: This paper focuses on the problem of recursive nonlinear least squares\nparameter estimation in multi-agent networks, in which the individual agents\nobserve sequentially over time an independent and identically distributed\n(i.i.d.) time-series consisting of a nonlinear function of the true but unknown\nparameter corrupted by noise. A distributed recursive estimator of the\n\\emph{consensus} + \\emph{innovations} type, namely $\\mathcal{CIWNLS}$, is\nproposed, in which the agents update their parameter estimates at each\nobservation sampling epoch in a collaborative way by simultaneously processing\nthe latest locally sensed information~(\\emph{innovations}) and the parameter\nestimates from other agents~(\\emph{consensus}) in the local neighborhood\nconforming to a pre-specified inter-agent communication topology. Under rather\nweak conditions on the connectivity of the inter-agent communication and a\n\\emph{global observability} criterion, it is shown that at every network agent,\nthe proposed algorithm leads to consistent parameter estimates. Furthermore,\nunder standard smoothness assumptions on the local observation functions, the\ndistributed estimator is shown to yield order-optimal convergence rates, i.e.,\nas far as the order of pathwise convergence is concerned, the local parameter\nestimates at each agent are as good as the optimal centralized nonlinear least\nsquares estimator which would require access to all the observations across all\nthe agents at all times. In order to benchmark the performance of the proposed\ndistributed $\\mathcal{CIWNLS}$ estimator with that of the centralized nonlinear\nleast squares estimator, the asymptotic normality of the estimate sequence is\nestablished and the asymptotic covariance of the distributed estimator is\nevaluated. Finally, simulation results are presented which illustrate and\nverify the analytical findings. \n\n"}
{"id": "1602.02283", "contents": "Title: Importance Sampling for Minibatches Abstract: Minibatching is a very well studied and highly popular technique in\nsupervised learning, used by practitioners due to its ability to accelerate\ntraining through better utilization of parallel processing power and reduction\nof stochastic variance. Another popular technique is importance sampling -- a\nstrategy for preferential sampling of more important examples also capable of\naccelerating the training process. However, despite considerable effort by the\ncommunity in these areas, and due to the inherent technical difficulty of the\nproblem, there is no existing work combining the power of importance sampling\nwith the strength of minibatching. In this paper we propose the first {\\em\nimportance sampling for minibatches} and give simple and rigorous complexity\nanalysis of its performance. We illustrate on synthetic problems that for\ntraining data of certain properties, our sampling can lead to several orders of\nmagnitude improvement in training time. We then test the new sampling on\nseveral popular datasets, and show that the improvement can reach an order of\nmagnitude. \n\n"}
{"id": "1602.02338", "contents": "Title: Stratified Bayesian Optimization Abstract: We consider derivative-free black-box global optimization of expensive noisy\nfunctions, when most of the randomness in the objective is produced by a few\ninfluential scalar random inputs. We present a new Bayesian global optimization\nalgorithm, called Stratified Bayesian Optimization (SBO), which uses this\nstrong dependence to improve performance. Our algorithm is similar in spirit to\nstratification, a technique from simulation, which uses strong dependence on a\ncategorical representation of the random input to reduce variance. We\ndemonstrate in numerical experiments that SBO outperforms state-of-the-art\nBayesian optimization benchmarks that do not leverage this dependence. \n\n"}
{"id": "1602.02823", "contents": "Title: Poor starting points in machine learning Abstract: Poor (even random) starting points for learning/training/optimization are\ncommon in machine learning. In many settings, the method of Robbins and Monro\n(online stochastic gradient descent) is known to be optimal for good starting\npoints, but may not be optimal for poor starting points -- indeed, for poor\nstarting points Nesterov acceleration can help during the initial iterations,\neven though Nesterov methods not designed for stochastic approximation could\nhurt during later iterations. The common practice of training with nontrivial\nminibatches enhances the advantage of Nesterov acceleration. \n\n"}
{"id": "1602.04679", "contents": "Title: Optimal curing policy for epidemic spreading over a community network\n  with heterogeneous population Abstract: The design of an efficient curing policy, able to stem an epidemic process at\nan affordable cost, has to account for the structure of the population contact\nnetwork supporting the contagious process. Thus, we tackle the problem of\nallocating recovery resources among the population, at the lowest cost possible\nto prevent the epidemic from persisting indefinitely in the network.\nSpecifically, we analyze a susceptible-infected-susceptible epidemic process\nspreading over a weighted graph, by means of a first-order mean-field\napproximation. First, we describe the influence of the contact network on the\ndynamics of the epidemics among a heterogeneous population, that is possibly\ndivided into communities. For the case of a community network, our\ninvestigation relies on the graph-theoretical notion of equitable partition; we\nshow that the epidemic threshold, a key measure of the network robustness\nagainst epidemic spreading, can be determined using a lower-dimensional\ndynamical system. Exploiting the computation of the epidemic threshold, we\ndetermine a cost-optimal curing policy by solving a convex minimization\nproblem, which possesses a reduced dimension in the case of a community\nnetwork. Lastly, we consider a two-level optimal curing problem, for which an\nalgorithm is designed with a polynomial time complexity in the network size. \n\n"}
{"id": "1602.06664", "contents": "Title: A Geometric Analysis of Phase Retrieval Abstract: Can we recover a complex signal from its Fourier magnitudes? More generally,\ngiven a set of $m$ measurements, $y_k = |\\mathbf a_k^* \\mathbf x|$ for $k = 1,\n\\dots, m$, is it possible to recover $\\mathbf x \\in \\mathbb{C}^n$ (i.e.,\nlength-$n$ complex vector)? This **generalized phase retrieval** (GPR) problem\nis a fundamental task in various disciplines, and has been the subject of much\nrecent investigation. Natural nonconvex heuristics often work remarkably well\nfor GPR in practice, but lack clear theoretical explanations. In this paper, we\ntake a step towards bridging this gap. We prove that when the measurement\nvectors $\\mathbf a_k$'s are generic (i.i.d. complex Gaussian) and the number of\nmeasurements is large enough ($m \\ge C n \\log^3 n$), with high probability, a\nnatural least-squares formulation for GPR has the following benign geometric\nstructure: (1) there are no spurious local minimizers, and all global\nminimizers are equal to the target signal $\\mathbf x$, up to a global phase;\nand (2) the objective function has a negative curvature around each saddle\npoint. This structure allows a number of iterative optimization methods to\nefficiently find a global minimizer, without special initialization. To\ncorroborate the claim, we describe and analyze a second-order trust-region\nalgorithm. \n\n"}
{"id": "1603.00570", "contents": "Title: Without-Replacement Sampling for Stochastic Gradient Methods:\n  Convergence Results and Application to Distributed Optimization Abstract: Stochastic gradient methods for machine learning and optimization problems\nare usually analyzed assuming data points are sampled \\emph{with} replacement.\nIn practice, however, sampling \\emph{without} replacement is very common,\neasier to implement in many cases, and often performs better. In this paper, we\nprovide competitive convergence guarantees for without-replacement sampling,\nunder various scenarios, for three types of algorithms: Any algorithm with\nonline regret guarantees, stochastic gradient descent, and SVRG. A useful\napplication of our SVRG analysis is a nearly-optimal algorithm for regularized\nleast squares in a distributed setting, in terms of both communication\ncomplexity and runtime complexity, when the data is randomly partitioned and\nthe condition number can be as large as the data size per machine (up to\nlogarithmic factors). Our proof techniques combine ideas from stochastic\noptimization, adversarial online learning, and transductive learning theory,\nand can potentially be applied to other stochastic optimization and learning\nproblems. \n\n"}
{"id": "1603.02074", "contents": "Title: Optimal dictionary for least squares representation Abstract: Dictionaries are collections of vectors used for representations of random\nvectors in Euclidean spaces. Recent research on optimal dictionaries is focused\non constructing dictionaries that offer sparse representations, i.e.,\n$\\ell_0$-optimal representations. Here we consider the problem of finding\noptimal dictionaries with which representations of samples of a random vector\nare optimal in an $\\ell_2$-sense: optimality of representation is defined as\nattaining the minimal average $\\ell_2$-norm of the coefficients used to\nrepresent the random vector. With the help of recent results on rank-$1$\ndecompositions of symmetric positive semidefinite matrices, we provide an\nexplicit description of $\\ell_2$-optimal dictionaries as well as their\nalgorithmic constructions in polynomial time. \n\n"}
{"id": "1603.03799", "contents": "Title: $\\ell_1$ Adaptive Trend Filter via Fast Coordinate Descent Abstract: Identifying the unknown underlying trend of a given noisy signal is extremely\nuseful for a wide range of applications. The number of potential trends might\nbe exponential, which can be computationally exhaustive even for short signals.\nAnother challenge, is the presence of abrupt changes and outliers at unknown\ntimes which impart resourceful information regarding the signal's\ncharacteristics. In this paper, we present the $\\ell_1$ Adaptive Trend Filter,\nwhich can consistently identify the components in the underlying trend and\nmultiple level-shifts, even in the presence of outliers. Additionally, an\nenhanced coordinate descent algorithm which exploit the filter design is\npresented. Some implementation details are discussed and a version in the Julia\nlanguage is presented along with two distinct applications to illustrate the\nfilter's potential. \n\n"}
{"id": "1603.04064", "contents": "Title: A Grothendieck-type inequality for local maxima Abstract: A large number of problems in optimization, machine learning, signal\nprocessing can be effectively addressed by suitable semidefinite programming\n(SDP) relaxations. Unfortunately, generic SDP solvers hardly scale beyond\ninstances with a few hundreds variables (in the underlying combinatorial\nproblem). On the other hand, it has been observed empirically that an effective\nstrategy amounts to introducing a (non-convex) rank constraint, and solving the\nresulting smooth optimization problem by ascent methods. This non-convex\nproblem has --generically-- a large number of local maxima, and the reason for\nthis success is therefore unclear.\n  This paper provides rigorous support for this approach. For the problem of\nmaximizing a linear functional over the elliptope, we prove that all local\nmaxima are within a small gap from the SDP optimum. In several problems of\ninterest, arbitrarily small relative error can be achieved by taking the rank\nconstraint $k$ to be of order one, independently of the problem size. \n\n"}
{"id": "1603.04128", "contents": "Title: Optimal Event-Driven Multi-Agent Persistent Monitoring of a Finite Set\n  of Targets Abstract: We consider the problem of controlling the movement of multiple cooperating\nagents so as to minimize an uncertainty metric associated with a finite number\nof targets. In a one-dimensional mission space, we adopt an optimal control\nframework and show that the solution is reduced to a simpler parametric\noptimization problem: determining a sequence of locations where each agent may\ndwell for a finite amount of time and then switch direction. This amounts to a\nhybrid system which we analyze using Infinitesimal Perturbation Analysis (IPA)\nto obtain a complete on-line solution through an event-driven gradient-based\nalgorithm which is also robust with respect to the uncertainty model used. The\nresulting controller depends on observing the events required to excite the\ngradient-based algorithm, which cannot be guaranteed. We solve this problem by\nproposing a new metric for the objective function which creates a potential\nfield guaranteeing that gradient values are non-zero. This approach is compared\nto an alternative graph-based task scheduling algorithm for determining an\noptimal sequence of target visits. Simulation examples are included to\ndemonstrate the proposed methods. \n\n"}
{"id": "1603.04245", "contents": "Title: A Variational Perspective on Accelerated Methods in Optimization Abstract: Accelerated gradient methods play a central role in optimization, achieving\noptimal rates in many settings. While many generalizations and extensions of\nNesterov's original acceleration method have been proposed, it is not yet clear\nwhat is the natural scope of the acceleration concept. In this paper, we study\naccelerated methods from a continuous-time perspective. We show that there is a\nLagrangian functional that we call the \\emph{Bregman Lagrangian} which\ngenerates a large class of accelerated methods in continuous time, including\n(but not limited to) accelerated gradient descent, its non-Euclidean extension,\nand accelerated higher-order gradient methods. We show that the continuous-time\nlimit of all of these methods correspond to traveling the same curve in\nspacetime at different speeds. From this perspective, Nesterov's technique and\nmany of its generalizations can be viewed as a systematic way to go from the\ncontinuous-time curves generated by the Bregman Lagrangian to a family of\ndiscrete-time accelerated algorithms. \n\n"}
{"id": "1603.05296", "contents": "Title: Exact Clustering of Weighted Graphs via Semidefinite Programming Abstract: As a model problem for clustering, we consider the densest k-disjoint-clique\nproblem of partitioning a weighted complete graph into k disjoint subgraphs\nsuch that the sum of the densities of these subgraphs is maximized. We\nestablish that such subgraphs can be recovered from the solution of a\nparticular semidefinite relaxation with high probability if the input graph is\nsampled from a distribution of clusterable graphs. Specifically, the\nsemidefinite relaxation is exact if the graph consists of k large disjoint\nsubgraphs, corresponding to clusters, with weight concentrated within these\nsubgraphs, plus a moderate number of outliers. Further, we establish that if\nnoise is weakly obscuring these clusters, i.e, the between-cluster edges are\nassigned very small weights, then we can recover significantly smaller\nclusters. For example, we show that in approximately sparse graphs, where the\nbetween-cluster weights tend to zero as the size n of the graph tends to\ninfinity, we can recover clusters of size polylogarithmic in n. Empirical\nevidence from numerical simulations is also provided to support these\ntheoretical phase transitions to perfect recovery of the cluster structure. \n\n"}
{"id": "1603.05305", "contents": "Title: Near-Optimal Stochastic Approximation for Online Principal Component\n  Estimation Abstract: Principal component analysis (PCA) has been a prominent tool for\nhigh-dimensional data analysis. Online algorithms that estimate the principal\ncomponent by processing streaming data are of tremendous practical and\ntheoretical interests. Despite its rich applications, theoretical convergence\nanalysis remains largely open. In this paper, we cast online PCA into a\nstochastic nonconvex optimization problem, and we analyze the online PCA\nalgorithm as a stochastic approximation iteration. The stochastic approximation\niteration processes data points incrementally and maintains a running estimate\nof the principal component. We prove for the first time a nearly optimal\nfinite-sample error bound for the online PCA algorithm. Under the subgaussian\nassumption, we show that the finite-sample error bound closely matches the\nminimax information lower bound. \n\n"}
{"id": "1603.06313", "contents": "Title: Convex block-sparse linear regression with expanders -- provably Abstract: Sparse matrices are favorable objects in machine learning and optimization.\nWhen such matrices are used, in place of dense ones, the overall complexity\nrequirements in optimization can be significantly reduced in practice, both in\nterms of space and run-time. Prompted by this observation, we study a convex\noptimization scheme for block-sparse recovery from linear measurements. To\nobtain linear sketches, we use expander matrices, i.e., sparse matrices\ncontaining only few non-zeros per column. Hitherto, to the best of our\nknowledge, such algorithmic solutions have been only studied from a non-convex\nperspective. Our aim here is to theoretically characterize the performance of\nconvex approaches under such setting.\n  Our key novelty is the expression of the recovery error in terms of the\nmodel-based norm, while assuring that solution lives in the model. To achieve\nthis, we show that sparse model-based matrices satisfy a group version of the\nnull-space property. Our experimental findings on synthetic and real\napplications support our claims for faster recovery in the convex setting -- as\nopposed to using dense sensing matrices, while showing a competitive recovery\nperformance. \n\n"}
{"id": "1603.08094", "contents": "Title: A Decentralized Second-Order Method for Dynamic Optimization Abstract: This paper considers decentralized dynamic optimization problems where nodes\nof a network try to minimize a sequence of time-varying objective functions in\na real-time scheme. At each time slot, nodes have access to different summands\nof an instantaneous global objective function and they are allowed to exchange\ninformation only with their neighbors. This paper develops the application of\nthe Exact Second-Order Method (ESOM) to solve the dynamic optimization problem\nin a decentralized manner. The proposed dynamic ESOM algorithm operates by\nprimal descending and dual ascending on a quadratic approximation of an\naugmented Lagrangian of the instantaneous consensus optimization problem. The\nconvergence analysis of dynamic ESOM indicates that a Lyapunov function of the\nsequence of primal and dual errors converges linearly to an error bound when\nthe local functions are strongly convex and have Lipschitz continuous\ngradients. Numerical results demonstrate the claim that the sequence of\niterates generated by the proposed method is able to track the sequence of\noptimal arguments. \n\n"}
{"id": "1603.08274", "contents": "Title: First and second order necessary conditions for stochastic optimal\n  controls Abstract: The main purpose of this paper is to establish the first and second order\nnecessary optimality conditions for stochastic optimal controls using the\nclassical variational analysis approach. The control system is governed by a\nstochastic differential equation, in which both drift and diffusion terms may\ncontain the control variable and the set of controls is allowed to be\nnonconvex. Only one adjoint equation is introduced to derive the first order\nnecessary condition; while only two adjoint equations are needed to state the\nsecond order necessary conditions for stochastic optimal controls. \n\n"}
{"id": "1603.09501", "contents": "Title: Null boundary controllability of a one-dimensional heat equation with an\n  internal point mass and variable coefficients Abstract: In this paper we consider a linear hybrid system which composed by two\nnon-homogeneous rods connected by a point mass and generated by the\nequation\\bea\\left\\{\n  \\begin{array}{ll}\n  \\rho_{1}(x)u_{t}=(\\sigma_{1}(x)u_{x})_{x}-q_{1}(x)u,& x\\in(-1,0),~t>0,\n  \\rho_{2}(x)v_{t}=(\\sigma_{2}(x)v_{x})_{x}-q_{2}(x)v,& x\\in(0,1), ~~~t>0,\n  M z_{t}(t)=\\sigma_{2}(0)v_{x}(0,t)-\\sigma_{1}(0)u_{x}(0,t), &t>0, \\end{array}\n  \\right. \\eea with Dirichlet boundary condition on the left end $x=-1$ and a\nboundary control acts on the right end $x=1$. We prove that this system is null\ncontrollable with Dirichlet or Neumann boundary controls. Our approach is\nmainly based on a detailed spectral analysis together with the moment method.\nIn particular, we show that the associated spectral gap in both cases\n(Dirichlet or Neumann boundary controls) are positive without further\nconditions on the coefficients $\\rho_{i}$, $\\sigma_{i}$ and $q_{i}$ $(i=1,2)$\nother than the regularities. \n\n"}
{"id": "1603.09620", "contents": "Title: Online Optimization with Costly and Noisy Measurements using Random\n  Fourier Expansions Abstract: This paper analyzes DONE, an online optimization algorithm that iteratively\nminimizes an unknown function based on costly and noisy measurements. The\nalgorithm maintains a surrogate of the unknown function in the form of a random\nFourier expansion (RFE). The surrogate is updated whenever a new measurement is\navailable, and then used to determine the next measurement point. The algorithm\nis comparable to Bayesian optimization algorithms, but its computational\ncomplexity per iteration does not depend on the number of measurements. We\nderive several theoretical results that provide insight on how the\nhyper-parameters of the algorithm should be chosen. The algorithm is compared\nto a Bayesian optimization algorithm for a benchmark problem and three\napplications, namely, optical coherence tomography, optical beam-forming\nnetwork tuning, and robot arm control. It is found that the DONE algorithm is\nsignificantly faster than Bayesian optimization in the discussed problems,\nwhile achieving a similar or better performance. \n\n"}
{"id": "1604.00391", "contents": "Title: A Primal-Dual Algorithm for Link Dependent Origin Destination Matrix\n  Estimation Abstract: Origin-Destination Matrix (ODM) estimation is a classical problem in\ntransport engineering aiming to recover flows from every Origin to every\nDestination from measured traffic counts and a priori model information. In\naddition to traffic counts, the present contribution takes advantage of probe\ntrajectories, whose capture is made possible by new measurement technologies.\nIt extends the concept of ODM to that of Link dependent ODM (LODM), keeping the\ninformation about the flow distribution on links and containing inherently the\nODM assignment. Further, an original formulation of LODM estimation, from\ntraffic counts and probe trajectories is presented as an optimisation problem,\nwhere the functional to be minimized consists of five convex functions, each\nmodelling a constraint or property of the transport problem: consistency with\ntraffic counts, consistency with sampled probe trajectories, consistency with\ntraffic conservation (Kirchhoff's law), similarity of flows having close\norigins and destinations, positivity of traffic flows. A primal-dual algorithm\nis devised to minimize the designed functional, as the corresponding objective\nfunctions are not necessarily differentiable. A case study, on a simulated\nnetwork and traffic, validates the feasibility of the procedure and details its\nbenefits for the estimation of an LODM matching real-network constraints and\nobservations. \n\n"}
{"id": "1604.00526", "contents": "Title: The Asynchronous PALM Algorithm for Nonsmooth Nonconvex Problems Abstract: We introduce the Asynchronous PALM algorithm, a new extension of the Proximal\nAlternating Linearized Minimization (PALM) algorithm for solving nonsmooth,\nnonconvex optimization problems. Like the PALM algorithm, each step of the\nAsynchronous PALM algorithm updates a single block of coordinates; but unlike\nthe PALM algorithm, the Asynchronous PALM algorithm eliminates the need for\nsequential updates that occur one after the other. Instead, our new algorithm\nallows each of the coordinate blocks to be updated asynchronously and in any\norder, which means that any number of computing cores can compute updates in\nparallel without synchronizing their computations. In practice, this\nasynchronization strategy often leads to speedups that increase linearly with\nthe number of computing cores.\n  We introduce two variants of the Asynchronous PALM algorithm, one stochastic\nand one deterministic. In the stochastic \\textit{and} deterministic cases, we\nshow that cluster points of the algorithm are stationary points. In the\ndeterministic case, we show that the algorithm converges globally whenever the\nKurdyka-{\\L}ojasiewicz property holds for a function closely related to the\nobjective function, and we derive its convergence rate in a common special\ncase. Finally, we provide a concrete case in which our assumptions hold. \n\n"}
{"id": "1604.00543", "contents": "Title: Decomposing Linearly Constrained Nonconvex Problems by a Proximal Primal\n  Dual Approach: Algorithms, Convergence, and Applications Abstract: In this paper, we propose a new decomposition approach named the proximal\nprimal dual algorithm (Prox-PDA) for smooth nonconvex linearly constrained\noptimization problems. The proposed approach is primal-dual based, where the\nprimal step minimizes certain approximation of the augmented Lagrangian of the\nproblem, and the dual step performs an approximate dual ascent. The\napproximation used in the primal step is able to decompose the variable blocks,\nmaking it possible to obtain simple subproblems by leveraging the problem\nstructures. Theoretically, we show that whenever the penalty parameter in the\naugmented Lagrangian is larger than a given threshold, the Prox-PDA converges\nto the set of stationary solutions, globally and in a sublinear manner (i.e.,\ncertain measure of stationarity decreases in the rate of $\\mathcal{O}(1/r)$,\nwhere $r$ is the iteration counter). Interestingly, when applying a variant of\nthe Prox-PDA to the problem of distributed nonconvex optimization (over a\nconnected undirected graph), the resulting algorithm coincides with the popular\nEXTRA algorithm [Shi et al 2014], which is only known to work in convex cases.\nOur analysis implies that EXTRA and its variants converge globally sublinearly\nto stationary solutions of certain nonconvex distributed optimization problem.\nThere are many possible extensions of the Prox-PDA, and we present one\nparticular extension to certain nonconvex distributed matrix factorization\nproblem. \n\n"}
{"id": "1604.02432", "contents": "Title: On small-time local controllability Abstract: In this paper, we study small-time local controllability of real analytic\ncontrol-affine systems under small perturbations of their vector fields.\nConsider a real analytic control system $\\mathcal{X}$ which is small-time\nlocally controllable and whose reachable sets shrink with the polynomial rate\nof order $N$ with respect to time. We will prove a general theorem which states\nthat any real analytic control-affine system whose vector fields are\nperturbations of the vector fields of $\\mathcal{X}$ with polynomials of order\nhigher than $N$ is again small-time locally controllable. In particular, we\nshow that this result connects two long-standing open conjectures about\nsmall-time local controllability of systems. \n\n"}
{"id": "1604.03257", "contents": "Title: Unified Convergence Analysis of Stochastic Momentum Methods for Convex\n  and Non-convex Optimization Abstract: Recently, {\\it stochastic momentum} methods have been widely adopted in\ntraining deep neural networks. However, their convergence analysis is still\nunderexplored at the moment, in particular for non-convex optimization. This\npaper fills the gap between practice and theory by developing a basic\nconvergence analysis of two stochastic momentum methods, namely stochastic\nheavy-ball method and the stochastic variant of Nesterov's accelerated gradient\nmethod. We hope that the basic convergence results developed in this paper can\nserve the reference to the convergence of stochastic momentum methods and also\nserve the baselines for comparison in future development of stochastic momentum\nmethods. The novelty of convergence analysis presented in this paper is a\nunified framework, revealing more insights about the similarities and\ndifferences between different stochastic momentum methods and stochastic\ngradient method. The unified framework exhibits a continuous change from the\ngradient method to Nesterov's accelerated gradient method and finally the\nheavy-ball method incurred by a free parameter, which can help explain a\nsimilar change observed in the testing error convergence behavior for deep\nlearning. Furthermore, our empirical results for optimizing deep neural\nnetworks demonstrate that the stochastic variant of Nesterov's accelerated\ngradient method achieves a good tradeoff (between speed of convergence in\ntraining error and robustness of convergence in testing error) among the three\nstochastic methods. \n\n"}
{"id": "1604.03763", "contents": "Title: A General Distributed Dual Coordinate Optimization Framework for\n  Regularized Loss Minimization Abstract: In modern large-scale machine learning applications, the training data are\noften partitioned and stored on multiple machines. It is customary to employ\nthe \"data parallelism\" approach, where the aggregated training loss is\nminimized without moving data across machines. In this paper, we introduce a\nnovel distributed dual formulation for regularized loss minimization problems\nthat can directly handle data parallelism in the distributed setting. This\nformulation allows us to systematically derive dual coordinate optimization\nprocedures, which we refer to as Distributed Alternating Dual Maximization\n(DADM). The framework extends earlier studies described in (Boyd et al., 2011;\nMa et al., 2015a; Jaggi et al., 2014; Yang, 2013) and has rigorous theoretical\nanalyses. Moreover with the help of the new formulation, we develop the\naccelerated version of DADM (Acc-DADM) by generalizing the acceleration\ntechnique from (Shalev-Shwartz and Zhang, 2014) to the distributed setting. We\nalso provide theoretical results for the proposed accelerated version and the\nnew result improves previous ones (Yang, 2013; Ma et al., 2015a) whose runtimes\ngrow linearly on the condition number. Our empirical studies validate our\ntheory and show that our accelerated approach significantly improves the\nprevious state-of-the-art distributed dual coordinate optimization algorithms. \n\n"}
{"id": "1604.03887", "contents": "Title: Algorithms for stochastic optimization with functional or expectation\n  constraints Abstract: This paper considers the problem of minimizing an expectation function over a\nclosed convex set, coupled with a {\\color{black} functional or expectation}\nconstraint on either decision variables or problem parameters. We first present\na new stochastic approximation (SA) type algorithm, namely the cooperative SA\n(CSA), to handle problems with the constraint on devision variables. We show\nthat this algorithm exhibits the optimal ${\\cal O}(1/\\epsilon^2)$ rate of\nconvergence, in terms of both optimality gap and constraint violation, when the\nobjective and constraint functions are generally convex, where $\\epsilon$\ndenotes the optimality gap and infeasibility. Moreover, we show that this rate\nof convergence can be improved to ${\\cal O}(1/\\epsilon)$ if the objective and\nconstraint functions are strongly convex. We then present a variant of CSA,\nnamely the cooperative stochastic parameter approximation (CSPA) algorithm, to\ndeal with the situation when the constraint is defined over problem parameters\nand show that it exhibits similar optimal rate of convergence to CSA. It is\nworth noting that CSA and CSPA are primal methods which do not require the\niterations on the dual space and/or the estimation on the size of the dual\nvariables. To the best of our knowledge, this is the first time that such\noptimal SA methods for solving functional or expectation constrained stochastic\noptimization are presented in the literature. \n\n"}
{"id": "1604.03930", "contents": "Title: Efficient Algorithms for Large-scale Generalized Eigenvector Computation\n  and Canonical Correlation Analysis Abstract: This paper considers the problem of canonical-correlation analysis (CCA)\n(Hotelling, 1936) and, more broadly, the generalized eigenvector problem for a\npair of symmetric matrices. These are two fundamental problems in data analysis\nand scientific computing with numerous applications in machine learning and\nstatistics (Shi and Malik, 2000; Hardoon et al., 2004; Witten et al., 2009).\n  We provide simple iterative algorithms, with improved runtimes, for solving\nthese problems that are globally linearly convergent with moderate dependencies\non the condition numbers and eigenvalue gaps of the matrices involved.\n  We obtain our results by reducing CCA to the top-$k$ generalized eigenvector\nproblem. We solve this problem through a general framework that simply requires\nblack box access to an approximate linear system solver. Instantiating this\nframework with accelerated gradient descent we obtain a running time of\n$O(\\frac{z k \\sqrt{\\kappa}}{\\rho} \\log(1/\\epsilon) \\log\n\\left(k\\kappa/\\rho\\right))$ where $z$ is the total number of nonzero entries,\n$\\kappa$ is the condition number and $\\rho$ is the relative eigenvalue gap of\nthe appropriate matrices.\n  Our algorithm is linear in the input size and the number of components $k$ up\nto a $\\log(k)$ factor. This is essential for handling large-scale matrices that\nappear in practice. To the best of our knowledge this is the first such\nalgorithm with global linear convergence. We hope that our results prompt\nfurther research and ultimately improve the practical running time for\nperforming these important data analysis procedures on large data sets. \n\n"}
{"id": "1604.04569", "contents": "Title: Kantorovich's theorem on Newton's method for solving strongly regular\n  generalized equation Abstract: In this paper we consider the Newton's method for solving the generalized\nequation of the form $ f(x) +F(x) \\ni 0, $ where $f:{\\Omega}\\to Y$ is a\ncontinuously differentiable mapping, $X$ and $Y$ are Banach spaces,\n$\\Omega\\subseteq X$ an open set and $F:X \\rightrightarrows Y$ be a set-valued\nmapping with nonempty closed graph. We show that, under strong regularity of\nthe generalized equation, concept introduced by S.M.Robinson in [27], and\nstarting point satisfying the Kantorovich's assumptions, the Newton's method is\nquadratically convergent to a solution, which is unique in a suitable\nneighborhood of the starting point. The analysis presented based on Banach\nPerturbation Lemma for generalized equation and the majorant technique, allow\nto unify some results pertaining the Newton's method theory. \n\n"}
{"id": "1604.05517", "contents": "Title: Robust pricing--hedging duality for American options in discrete time\n  financial markets Abstract: We investigate pricing-hedging duality for American options in discrete time\nfinancial models where some assets are traded dynamically and others, e.g. a\nfamily of European options, only statically. In the first part of the paper we\nconsider an abstract setting, which includes the classical case with a fixed\nreference probability measure as well as the robust framework with a\nnon-dominated family of probability measures. Our first insight is that by\nconsidering a (universal) enlargement of the space, we can see American options\nas European options and recover the pricing-hedging duality, which may fail in\nthe original formulation. This may be seen as a weak formulation of the\noriginal problem. Our second insight is that lack of duality is caused by the\nlack of dynamic consistency and hence a different enlargement with dynamic\nconsistency is sufficient to recover duality: it is enough to consider\n(fictitious) extensions of the market in which all the assets are traded\ndynamically. In the second part of the paper we study two important examples of\nrobust framework: the setup of Bouchard and Nutz (2015) and the martingale\noptimal transport setup of Beiglb\\\"ock et al. (2013), and show that our general\nresults apply in both cases and allow us to obtain pricing-hedging duality for\nAmerican options. \n\n"}
{"id": "1604.06543", "contents": "Title: An optimal first order method based on optimal quadratic averaging Abstract: In a recent paper, Bubeck, Lee, and Singh introduced a new first order method\nfor minimizing smooth strongly convex functions. Their geometric descent\nalgorithm, largely inspired by the ellipsoid method, enjoys the optimal linear\nrate of convergence. We show that the same iterate sequence is generated by a\nscheme that in each iteration computes an optimal average of quadratic\nlower-models of the function. Indeed, the minimum of the averaged quadratic\napproaches the true minimum at an optimal rate. This intuitive viewpoint\nreveals clear connections to the original fast-gradient methods and cutting\nplane ideas, and leads to limited-memory extensions with improved performance. \n\n"}
{"id": "1604.07177", "contents": "Title: On the Use of Penalty MCMC for Differential Privacy Abstract: We view the penalty algorithm of Ceperley and Dewing (1999), a Markov chain\nMonte Carlo (MCMC) algorithm for Bayesian inference, in the context of data\nprivacy. Specifically, we study differential privacy of the penalty algorithm\nand advocate its use for data privacy. We show that in the simple model of\nindependent observations the algorithm has desirable convergence and privacy\nproperties that scale with data size. Two special cases are also investigated\nand privacy preserving schemes are proposed for those cases: (i) Data are\ndistributed among several data owners who are interested in the inference of a\ncommon parameter while preserving their data privacy. (ii) The data likelihood\nbelongs to an exponential family. \n\n"}
{"id": "1605.00076", "contents": "Title: Asynchronous Optimization Over Heterogeneous Networks via Consensus ADMM Abstract: This paper considers the distributed optimization of a sum of locally\nobservable, non-convex functions. The optimization is performed over a\nmulti-agent networked system, and each local function depends only on a subset\nof the variables. An asynchronous and distributed alternating directions method\nof multipliers (ADMM) method that allows the nodes to defer or skip the\ncomputation and transmission of updates is proposed in the paper. The proposed\nalgorithm utilizes different approximations in the update step, resulting in\nproximal and majorized ADMM variants. Both variants are shown to converge to a\nlocal minimum, under certain regularity conditions. The proposed asynchronous\nalgorithms are also applied to the problem of cooperative localization in\nwireless ad hoc networks, where it is shown to outperform the other\nstate-of-the-art localization algorithms. \n\n"}
{"id": "1605.00125", "contents": "Title: Efficiency of minimizing compositions of convex functions and smooth\n  maps Abstract: We consider global efficiency of algorithms for minimizing a sum of a convex\nfunction and a composition of a Lipschitz convex function with a smooth map.\nThe basic algorithm we rely on is the prox-linear method, which in each\niteration solves a regularized subproblem formed by linearizing the smooth map.\nWhen the subproblems are solved exactly, the method has efficiency\n$\\mathcal{O}(\\varepsilon^{-2})$, akin to gradient descent for smooth\nminimization. We show that when the subproblems can only be solved by\nfirst-order methods, a simple combination of smoothing, the prox-linear method,\nand a fast-gradient scheme yields an algorithm with complexity\n$\\widetilde{\\mathcal{O}}(\\varepsilon^{-3})$. The technique readily extends to\nminimizing an average of $m$ composite functions, with complexity\n$\\widetilde{\\mathcal{O}}(m/\\varepsilon^{2}+\\sqrt{m}/\\varepsilon^{3})$ in\nexpectation. We round off the paper with an inertial prox-linear method that\nautomatically accelerates in presence of convexity. \n\n"}
{"id": "1605.00201", "contents": "Title: Further properties of the forward-backward envelope with applications to\n  difference-of-convex programming Abstract: In this paper, we further study the forward-backward envelope first\nintroduced in [28] and [30] for problems whose objective is the sum of a proper\nclosed convex function and a twice continuously differentiable possibly\nnonconvex function with Lipschitz continuous gradient. We derive sufficient\nconditions on the original problem for the corresponding forward-backward\nenvelope to be a level-bounded and Kurdyka-{\\L}ojasiewicz function with an\nexponent of $\\frac12$; these results are important for the efficient\nminimization of the forward-backward envelope by classical optimization\nalgorithms. In addition, we demonstrate how to minimize some\ndifference-of-convex regularized least squares problems by minimizing a\nsuitably constructed forward-backward envelope. Our preliminary numerical\nresults on randomly generated instances of large-scale $\\ell_{1-2}$ regularized\nleast squares problems [37] illustrate that an implementation of this approach\nwith a limited-memory BFGS scheme usually outperforms standard first-order\nmethods such as the nonmonotone proximal gradient method in [35]. \n\n"}
{"id": "1605.00267", "contents": "Title: Distributed Algorithms for Aggregative Games on Graphs Abstract: We consider a class of Nash games, termed as aggregative games, being played\nover a networked system. In an aggregative game, a player's objective is a\nfunction of the aggregate of all the players' decisions. Every player maintains\nan estimate of this aggregate, and the players exchange this information with\ntheir local neighbors over a connected network. We study distributed\nsynchronous and asynchronous algorithms for information exchange and\nequilibrium computation over such a network. Under standard conditions, we\nestablish the almost-sure convergence of the obtained sequences to the\nequilibrium point. We also consider extensions of our schemes to aggregative\ngames where the players' objectives are coupled through a more general form of\naggregate function. Finally, we present numerical results that demonstrate the\nperformance of the proposed schemes. \n\n"}
{"id": "1605.00988", "contents": "Title: Matrices with high completely positive semidefinite rank Abstract: A real symmetric matrix $M$ is completely positive semidefinite if it admits\na Gram representation by (Hermitian) positive semidefinite matrices of any size\n$d$. The smallest such $d$ is called the (complex) completely positive\nsemidefinite rank of $M$, and it is an open question whether there exists an\nupper bound on this number as a function of the matrix size. We construct\ncompletely positive semidefinite matrices of size $4k^2+2k+2$ with complex\ncompletely positive semidefinite rank $2^k$ for any positive integer $k$. This\nshows that if such an upper bound exists, it has to be at least exponential in\nthe matrix size. For this we exploit connections to quantum information theory\nand we construct extremal bipartite correlation matrices of large rank. We also\nexhibit a class of completely positive matrices with quadratic (in terms of the\nmatrix size) completely positive rank, but with linear completely positive\nsemidefinite rank, and we make a connection to the existence of Hadamard\nmatrices. \n\n"}
{"id": "1605.01608", "contents": "Title: Optimal control of PDEs in a complex space setting; application to the\n  Schr\\\"odinger equation Abstract: In this paper we discuss optimality conditions for abstract optimization\nproblems over complex spaces. We then apply these results to optimal control\nproblems with a semigroup structure. As an application we detail the case when\nthe state equation is the Schr\\\"{o}dinger one, with pointwise constraints on\nthe \"bilinear\" control. We derive first and second order optimality conditions\nand address in particular the case that the control enters the state equation\nand cost function linearly. \n\n"}
{"id": "1605.02408", "contents": "Title: Structured Nonconvex and Nonsmooth Optimization: Algorithms and\n  Iteration Complexity Analysis Abstract: Nonconvex and nonsmooth optimization problems are frequently encountered in\nmuch of statistics, business, science and engineering, but they are not yet\nwidely recognized as a technology in the sense of scalability. A reason for\nthis relatively low degree of popularity is the lack of a well developed system\nof theory and algorithms to support the applications, as is the case for its\nconvex counterpart. This paper aims to take one step in the direction of\ndisciplined nonconvex and nonsmooth optimization. In particular, we consider in\nthis paper some constrained nonconvex optimization models in block decision\nvariables, with or without coupled affine constraints. In the case of without\ncoupled constraints, we show a sublinear rate of convergence to an\n$\\epsilon$-stationary solution in the form of variational inequality for a\ngeneralized conditional gradient method, where the convergence rate is shown to\nbe dependent on the H\\\"olderian continuity of the gradient of the smooth part\nof the objective. For the model with coupled affine constraints, we introduce\ncorresponding $\\epsilon$-stationarity conditions, and apply two proximal-type\nvariants of the ADMM to solve such a model, assuming the proximal ADMM updates\ncan be implemented for all the block variables except for the last block, for\nwhich either a gradient step or a majorization-minimization step is\nimplemented. We show an iteration complexity bound of $O(1/\\epsilon^2)$ to\nreach an $\\epsilon$-stationary solution for both algorithms. Moreover, we show\nthat the same iteration complexity of a proximal BCD method follows\nimmediately. Numerical results are provided to illustrate the efficacy of the\nproposed algorithms for tensor robust PCA. \n\n"}
{"id": "1605.02711", "contents": "Title: Nonconvex Sparse Learning via Stochastic Optimization with Progressive\n  Variance Reduction Abstract: We propose a stochastic variance reduced optimization algorithm for solving\nsparse learning problems with cardinality constraints. Sufficient conditions\nare provided, under which the proposed algorithm enjoys strong linear\nconvergence guarantees and optimal estimation accuracy in high dimensions. We\nfurther extend the proposed algorithm to an asynchronous parallel variant with\na near linear speedup. Numerical experiments demonstrate the efficiency of our\nalgorithm in terms of both parameter estimation and computational performance. \n\n"}
{"id": "1605.04027", "contents": "Title: Adaptive finite element methods for an optimal control problem involving\n  Dirac measures Abstract: The purpose of this work is the design and analysis of a reliable and\nefficient a posteriori error estimator for the so-called pointwise tracking\noptimal control problem. This linear-quadratic optimal control problem entails\nthe minimization of a cost functional that involves point evaluations of the\nstate, thus leading to an adjoint problem with Dirac measures on the right hand\nside; control constraints are also considered. The proposed error estimator\nrelies on a posteriori error estimates in the maximum norm for the state and in\nMuckenhoupt weighted Sobolev spaces for the adjoint state. We present an\nanalysis that is valid for two and three-dimensional domains. We conclude by\npresenting several numerical experiments which reveal the competitive\nperformance of adaptive methods based on the devised error estimator. \n\n"}
{"id": "1605.04029", "contents": "Title: Simple, Scalable and Accurate Posterior Interval Estimation Abstract: There is a lack of simple and scalable algorithms for uncertainty\nquantification. Bayesian methods quantify uncertainty through posterior and\npredictive distributions, but it is difficult to rapidly estimate summaries of\nthese distributions, such as quantiles and intervals. Variational Bayes\napproximations are widely used, but may badly underestimate posterior\ncovariance. Typically, the focus of Bayesian inference is on point and interval\nestimates for one-dimensional functionals of interest. In small scale problems,\nMarkov chain Monte Carlo algorithms remain the gold standard, but such\nalgorithms face major problems in scaling up to big data. Various modifications\nhave been proposed based on parallelization and approximations based on\nsubsamples, but such approaches are either highly complex or lack theoretical\nsupport and/or good performance outside of narrow settings. We propose a very\nsimple and general posterior interval estimation algorithm, which is based on\nrunning Markov chain Monte Carlo in parallel for subsets of the data and\naveraging quantiles estimated from each subset. We provide strong theoretical\nguarantees and illustrate performance in several applications. \n\n"}
{"id": "1605.04638", "contents": "Title: Tracking Slowly Moving Clairvoyant: Optimal Dynamic Regret of Online\n  Learning with True and Noisy Gradient Abstract: This work focuses on dynamic regret of online convex optimization that\ncompares the performance of online learning to a clairvoyant who knows the\nsequence of loss functions in advance and hence selects the minimizer of the\nloss function at each step. By assuming that the clairvoyant moves slowly\n(i.e., the minimizers change slowly), we present several improved\nvariation-based upper bounds of the dynamic regret under the true and noisy\ngradient feedback, which are {\\it optimal} in light of the presented lower\nbounds. The key to our analysis is to explore a regularity metric that measures\nthe temporal changes in the clairvoyant's minimizers, to which we refer as {\\it\npath variation}. Firstly, we present a general lower bound in terms of the path\nvariation, and then show that under full information or gradient feedback we\nare able to achieve an optimal dynamic regret. Secondly, we present a lower\nbound with noisy gradient feedback and then show that we can achieve optimal\ndynamic regrets under a stochastic gradient feedback and two-point bandit\nfeedback. Moreover, for a sequence of smooth loss functions that admit a small\nvariation in the gradients, our dynamic regret under the two-point bandit\nfeedback matches what is achieved with full information. \n\n"}
{"id": "1605.06593", "contents": "Title: Online Influence Maximization under Independent Cascade Model with\n  Semi-Bandit Feedback Abstract: We study the online influence maximization problem in social networks under\nthe independent cascade model. Specifically, we aim to learn the set of \"best\ninfluencers\" in a social network online while repeatedly interacting with it.\nWe address the challenges of (i) combinatorial action space, since the number\nof feasible influencer sets grows exponentially with the maximum number of\ninfluencers, and (ii) limited feedback, since only the influenced portion of\nthe network is observed. Under a stochastic semi-bandit feedback, we propose\nand analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our\nbounds on the cumulative regret are polynomial in all quantities of interest,\nachieve near-optimal dependence on the number of interactions and reflect the\ntopology of the network and the activation probabilities of its edges, thereby\ngiving insights on the problem complexity. To the best of our knowledge, these\nare the first such results. Our experiments show that in several representative\ngraph topologies, the regret of IMLinUCB scales as suggested by our upper\nbounds. IMLinUCB permits linear generalization and thus is both statistically\nand computationally suitable for large-scale problems. Our experiments also\nshow that IMLinUCB with linear generalization can lead to low regret in\nreal-world online influence maximization. \n\n"}
{"id": "1605.06892", "contents": "Title: Accelerated Randomized Mirror Descent Algorithms For Composite\n  Non-strongly Convex Optimization Abstract: We consider the problem of minimizing the sum of an average function of a\nlarge number of smooth convex components and a general, possibly\nnon-differentiable, convex function. Although many methods have been proposed\nto solve this problem with the assumption that the sum is strongly convex, few\nmethods support the non-strongly convex case. Adding a small quadratic\nregularization is a common devise used to tackle non-strongly convex problems;\nhowever, it may cause loss of sparsity of solutions or weaken the performance\nof the algorithms. Avoiding this devise, we propose an accelerated randomized\nmirror descent method for solving this problem without the strongly convex\nassumption. Our method extends the deterministic accelerated proximal gradient\nmethods of Paul Tseng and can be applied even when proximal points are computed\ninexactly. We also propose a scheme for solving the problem when the component\nfunctions are non-smooth. \n\n"}
{"id": "1605.07112", "contents": "Title: Harnessing Smoothness to Accelerate Distributed Optimization Abstract: There has been a growing effort in studying the distributed optimization\nproblem over a network. The objective is to optimize a global function formed\nby a sum of local functions, using only local computation and communication.\nLiterature has developed consensus-based distributed (sub)gradient descent\n(DGD) methods and has shown that they have the same convergence rate\n$O(\\frac{\\log t}{\\sqrt{t}})$ as the centralized (sub)gradient methods (CGD)\nwhen the function is convex but possibly nonsmooth. However, when the function\nis convex and smooth, under the framework of DGD, it is unclear how to harness\nthe smoothness to obtain a faster convergence rate comparable to CGD's\nconvergence rate. In this paper, we propose a distributed algorithm that,\ndespite using the same amount of communication per iteration as DGD, can\neffectively harnesses the function smoothness and converge to the optimum with\na rate of $O(\\frac{1}{t})$. If the objective function is further strongly\nconvex, our algorithm has a linear convergence rate. Both rates match the\nconvergence rate of CGD. The key step in our algorithm is a novel gradient\nestimation scheme that uses history information to achieve fast and accurate\nestimation of the average gradient. To motivate the necessity of history\ninformation, we also show that it is impossible for a class of distributed\nalgorithms like DGD to achieve a linear convergence rate without using history\ninformation even if the objective function is strongly convex and smooth. \n\n"}
{"id": "1605.07367", "contents": "Title: Riemannian stochastic variance reduced gradient on Grassmann manifold Abstract: Stochastic variance reduction algorithms have recently become popular for\nminimizing the average of a large, but finite, number of loss functions. In\nthis paper, we propose a novel Riemannian extension of the Euclidean stochastic\nvariance reduced gradient algorithm (R-SVRG) to a compact manifold search\nspace. To this end, we show the developments on the Grassmann manifold. The key\nchallenges of averaging, addition, and subtraction of multiple gradients are\naddressed with notions like logarithm mapping and parallel translation of\nvectors on the Grassmann manifold. We present a global convergence analysis of\nthe proposed algorithm with decay step-sizes and a local convergence rate\nanalysis under fixed step-size with some natural assumptions. The proposed\nalgorithm is applied on a number of problems on the Grassmann manifold like\nprincipal components analysis, low-rank matrix completion, and the Karcher mean\ncomputation. In all these cases, the proposed algorithm outperforms the\nstandard Riemannian stochastic gradient descent algorithm. \n\n"}
{"id": "1605.07747", "contents": "Title: NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and\n  Stochastic Optimization Abstract: We study a stochastic and distributed algorithm for nonconvex problems whose\nobjective consists of a sum of $N$ nonconvex $L_i/N$-smooth functions, plus a\nnonsmooth regularizer. The proposed NonconvEx primal-dual SpliTTing (NESTT)\nalgorithm splits the problem into $N$ subproblems, and utilizes an augmented\nLagrangian based primal-dual scheme to solve it in a distributed and stochastic\nmanner. With a special non-uniform sampling, a version of NESTT achieves\n$\\epsilon$-stationary solution using\n$\\mathcal{O}((\\sum_{i=1}^N\\sqrt{L_i/N})^2/\\epsilon)$ gradient evaluations,\nwhich can be up to $\\mathcal{O}(N)$ times better than the (proximal) gradient\ndescent methods. It also achieves Q-linear convergence rate for nonconvex\n$\\ell_1$ penalized quadratic problems with polyhedral constraints. Further, we\nreveal a fundamental connection between primal-dual based methods and a few\nprimal only methods such as IAG/SAG/SAGA. \n\n"}
{"id": "1605.07950", "contents": "Title: On Fast Convergence of Proximal Algorithms for SQRT-Lasso Optimization:\n  Don't Worry About Its Nonsmooth Loss Function Abstract: Many machine learning techniques sacrifice convenient computational\nstructures to gain estimation robustness and modeling flexibility. However, by\nexploring the modeling structures, we find these \"sacrifices\" do not always\nrequire more computational efforts. To shed light on such a \"free-lunch\"\nphenomenon, we study the square-root-Lasso (SQRT-Lasso) type regression\nproblem. Specifically, we show that the nonsmooth loss functions of SQRT-Lasso\ntype regression ease tuning effort and gain adaptivity to inhomogeneous noise,\nbut is not necessarily more challenging than Lasso in computation. We can\ndirectly apply proximal algorithms (e.g. proximal gradient descent, proximal\nNewton, and proximal Quasi-Newton algorithms) without worrying the\nnonsmoothness of the loss function. Theoretically, we prove that the proximal\nalgorithms combined with the pathwise optimization scheme enjoy fast\nconvergence guarantees with high probability. Numerical results are provided to\nsupport our theory. \n\n"}
{"id": "1605.08023", "contents": "Title: Online Placement of Multi-Component Applications in Edge Computing\n  Environments Abstract: Mobile edge computing is a new cloud computing paradigm which makes use of\nsmall-sized edge-clouds to provide real-time services to users. These mobile\nedge-clouds (MECs) are located in close proximity to users, thus enabling users\nto seamlessly access applications running on MECs. Due to the co-existence of\nthe core (centralized) cloud, users, and one or multiple layers of MECs, an\nimportant problem is to decide where (on which computational entity) to place\ndifferent components of an application. This problem, known as the application\nor workload placement problem, is notoriously hard, and therefore, heuristic\nalgorithms without performance guarantees are generally employed in common\npractice, which may unknowingly suffer from poor performance as compared to the\noptimal solution. In this paper, we address the application placement problem\nand focus on developing algorithms with provable performance bounds. We model\nthe user application as an application graph and the physical computing system\nas a physical graph, with resource demands/availabilities annotated on these\ngraphs. We first consider the placement of a linear application graph and\npropose an algorithm for finding its optimal solution. Using this result, we\nthen generalize the formulation and obtain online approximation algorithms with\npolynomial-logarithmic (poly-log) competitive ratio for tree application graph\nplacement. We jointly consider node and link assignment, and incorporate\nmultiple types of computational resources at nodes. \n\n"}
{"id": "1605.08122", "contents": "Title: On the Mixing Time of Kac's Walk and Other High-Dimensional Gibbs\n  Samplers with Constraints Abstract: Determining the total variation mixing time of Kac's random walk on the\nspecial orthogonal group $\\mathrm{SO}(n)$ has been a long-standing open\nproblem. In this paper, we construct a novel non-Markovian coupling for\nbounding this mixing time. The analysis of our coupling entails controlling the\nsmallest singular value of a certain random matrix with highly dependent\nentries. The dependence of the entries in our matrix makes it not-amenable to\nexisting techniques in random matrix theory. To circumvent this difficulty, we\nextend some recent bounds on the smallest singular values of matrices with\nindependent entries to our setting. These bounds imply that the mixing time of\nKac's walk on the group $\\mathrm{SO}(n)$ is between $C_{1} n^{2}$ and $C_{2}\nn^{4} \\log(n)$ for some explicit constants $0 < C_{1}, C_{2} < \\infty$,\nsubstantially improving on the bound of $O(n^{5} \\log(n)^{2})$ by Jiang. Our\nmethods may also be applied to other high dimensional Gibbs samplers with\nconstraints and thus are of independent interest. In addition to giving\nanalytical bounds on the mixing time, our approach allows us to compute\nrigorous estimates of the mixing time by simulating the eigenvalues of a random\nmatrix. \n\n"}
{"id": "1605.08370", "contents": "Title: Provable Efficient Online Matrix Completion via Non-convex Stochastic\n  Gradient Descent Abstract: Matrix completion, where we wish to recover a low rank matrix by observing a\nfew entries from it, is a widely studied problem in both theory and practice\nwith wide applications. Most of the provable algorithms so far on this problem\nhave been restricted to the offline setting where they provide an estimate of\nthe unknown matrix using all observations simultaneously. However, in many\napplications, the online version, where we observe one entry at a time and\ndynamically update our estimate, is more appealing. While existing algorithms\nare efficient for the offline setting, they could be highly inefficient for the\nonline setting.\n  In this paper, we propose the first provable, efficient online algorithm for\nmatrix completion. Our algorithm starts from an initial estimate of the matrix\nand then performs non-convex stochastic gradient descent (SGD). After every\nobservation, it performs a fast update involving only one row of two tall\nmatrices, giving near linear total runtime. Our algorithm can be naturally used\nin the offline setting as well, where it gives competitive sample complexity\nand runtime to state of the art algorithms. Our proofs introduce a general\nframework to show that SGD updates tend to stay away from saddle surfaces and\ncould be of broader interests for other non-convex problems to prove tight\nrates. \n\n"}
{"id": "1605.08882", "contents": "Title: Optimal Rates for Multi-pass Stochastic Gradient Methods Abstract: We analyze the learning properties of the stochastic gradient method when\nmultiple passes over the data and mini-batches are allowed. We study how\nregularization properties are controlled by the step-size, the number of passes\nand the mini-batch size. In particular, we consider the square loss and show\nthat for a universal step-size choice, the number of passes acts as a\nregularization parameter, and optimal finite sample bounds can be achieved by\nearly-stopping. Moreover, we show that larger step-sizes are allowed when\nconsidering mini-batches. Our analysis is based on a unifying approach,\nencompassing both batch and stochastic gradient methods as special cases. As a\nbyproduct, we derive optimal convergence results for batch gradient methods\n(even in the non-attainable cases). \n\n"}
{"id": "1605.09114", "contents": "Title: ParMAC: distributed optimisation of nested functions, with application\n  to learning binary autoencoders Abstract: Many powerful machine learning models are based on the composition of\nmultiple processing layers, such as deep nets, which gives rise to nonconvex\nobjective functions. A general, recent approach to optimise such \"nested\"\nfunctions is the method of auxiliary coordinates (MAC). MAC introduces an\nauxiliary coordinate for each data point in order to decouple the nested model\ninto independent submodels. This decomposes the optimisation into steps that\nalternate between training single layers and updating the coordinates. It has\nthe advantage that it reuses existing single-layer algorithms, introduces\nparallelism, and does not need to use chain-rule gradients, so it works with\nnondifferentiable layers. With large-scale problems, or when distributing the\ncomputation is necessary for faster training, the dataset may not fit in a\nsingle machine. It is then essential to limit the amount of communication\nbetween machines so it does not obliterate the benefit of parallelism. We\ndescribe a general way to achieve this, ParMAC. ParMAC works on a cluster of\nprocessing machines with a circular topology and alternates two steps until\nconvergence: one step trains the submodels in parallel using stochastic\nupdates, and the other trains the coordinates in parallel. Only submodel\nparameters, no data or coordinates, are ever communicated between machines.\nParMAC exhibits high parallelism, low communication overhead, and facilitates\ndata shuffling, load balancing, fault tolerance and streaming data processing.\nWe study the convergence of ParMAC and propose a theoretical model of its\nruntime and parallel speedup. We develop ParMAC to learn binary autoencoders\nfor fast, approximate image retrieval. We implement it in MPI in a distributed\nsystem and demonstrate nearly perfect speedups in a 128-processor cluster with\na training set of 100 million high-dimensional points. \n\n"}
{"id": "1605.09232", "contents": "Title: Tradeoffs between Convergence Speed and Reconstruction Accuracy in\n  Inverse Problems Abstract: Solving inverse problems with iterative algorithms is popular, especially for\nlarge data. Due to time constraints, the number of possible iterations is\nusually limited, potentially affecting the achievable accuracy. Given an error\none is willing to tolerate, an important question is whether it is possible to\nmodify the original iterations to obtain faster convergence to a minimizer\nachieving the allowed error without increasing the computational cost of each\niteration considerably. Relying on recent recovery techniques developed for\nsettings in which the desired signal belongs to some low-dimensional set, we\nshow that using a coarse estimate of this set may lead to faster convergence at\nthe cost of an additional reconstruction error related to the accuracy of the\nset approximation. Our theory ties to recent advances in sparse recovery,\ncompressed sensing, and deep learning. Particularly, it may provide a possible\nexplanation to the successful approximation of the l1-minimization solution by\nneural networks with layers representing iterations, as practiced in the\nlearned iterative shrinkage-thresholding algorithm (LISTA). \n\n"}
{"id": "1605.09346", "contents": "Title: Minding the Gaps for Block Frank-Wolfe Optimization of Structured SVMs Abstract: In this paper, we propose several improvements on the block-coordinate\nFrank-Wolfe (BCFW) algorithm from Lacoste-Julien et al. (2013) recently used to\noptimize the structured support vector machine (SSVM) objective in the context\nof structured prediction, though it has wider applications. The key intuition\nbehind our improvements is that the estimates of block gaps maintained by BCFW\nreveal the block suboptimality that can be used as an adaptive criterion.\nFirst, we sample objects at each iteration of BCFW in an adaptive non-uniform\nway via gapbased sampling. Second, we incorporate pairwise and away-step\nvariants of Frank-Wolfe into the block-coordinate setting. Third, we cache\noracle calls with a cache-hit criterion based on the block gaps. Fourth, we\nprovide the first method to compute an approximate regularization path for\nSSVM. Finally, we provide an exhaustive empirical evaluation of all our methods\non four structured prediction datasets. \n\n"}
{"id": "1606.01016", "contents": "Title: On Coupling Particle Filter Trajectories Abstract: Particle filters are a powerful and flexible tool for performing inference on\nstate-space models. They involve a collection of samples evolving over time\nthrough a combination of sampling and re-sampling steps. The re-sampling step\nis necessary to ensure that weight degeneracy is avoided. In several situations\nof statistical interest, it is important to be able to compare the estimates\nproduced by two different particle filters; consequently, being able to\nefficiently couple two particle filter trajectories is often of paramount\nimportance. In this text, we propose several ways to do so. In particular, we\nleverage ideas from the optimal transportation literature. In general, though,\ncomputing the optimal transport map is extremely computationally expensive; to\ndeal with this, we introduce computationally tractable approximations to\noptimal transport couplings. We demonstrate that our resulting algorithms for\ncoupling two particle filter trajectories often perform orders of magnitude\nmore efficiently than more standard approaches. \n\n"}
{"id": "1606.01245", "contents": "Title: Scalable Algorithms for Tractable Schatten Quasi-Norm Minimization Abstract: The Schatten-p quasi-norm $(0<p<1)$ is usually used to replace the standard\nnuclear norm in order to approximate the rank function more accurately.\nHowever, existing Schatten-p quasi-norm minimization algorithms involve\nsingular value decomposition (SVD) or eigenvalue decomposition (EVD) in each\niteration, and thus may become very slow and impractical for large-scale\nproblems. In this paper, we first define two tractable Schatten quasi-norms,\ni.e., the Frobenius/nuclear hybrid and bi-nuclear quasi-norms, and then prove\nthat they are in essence the Schatten-2/3 and 1/2 quasi-norms, respectively,\nwhich lead to the design of very efficient algorithms that only need to update\ntwo much smaller factor matrices. We also design two efficient proximal\nalternating linearized minimization algorithms for solving representative\nmatrix completion problems. Finally, we provide the global convergence and\nperformance guarantees for our algorithms, which have better convergence\nproperties than existing algorithms. Experimental results on synthetic and\nreal-world data show that our algorithms are more accurate than the\nstate-of-the-art methods, and are orders of magnitude faster. \n\n"}
{"id": "1606.02566", "contents": "Title: A moment-matching Ferguson and Klass algorithm Abstract: Completely random measures (CRM) represent the key building block of a wide\nvariety of popular stochastic models and play a pivotal role in modern Bayesian\nNonparametrics. A popular representation of CRMs as a random series with\ndecreasing jumps is due to Ferguson and Klass (1972). This can immediately be\nturned into an algorithm for sampling realizations of CRMs or more elaborate\nmodels involving transformed CRMs. However, concrete implementation requires to\ntruncate the random series at some threshold resulting in an approximation\nerror. The goal of this paper is to quantify the quality of the approximation\nby a moment-matching criterion, which consists in evaluating a measure of\ndiscrepancy between actual moments and moments based on the simulation output.\nSeen as a function of the truncation level, the methodology can be used to\ndetermine the truncation level needed to reach a certain level of precision.\nThe resulting moment-matching \\FK algorithm is then implemented and illustrated\non several popular Bayesian nonparametric models. \n\n"}
{"id": "1606.03504", "contents": "Title: Incoherent Tensor Norms and Their Applications in Higher Order Tensor\n  Completion Abstract: In this paper, we investigate the sample size requirement for a general class\nof nuclear norm minimization methods for higher order tensor completion. We\nintroduce a class of tensor norms by allowing for different levels of\ncoherence, which allows us to leverage the incoherence of a tensor. In\nparticular, we show that a $k$th order tensor of rank $r$ and dimension\n$d\\times\\cdots\\times d$ can be recovered perfectly from as few as\n$O((r^{(k-1)/2}d^{3/2}+r^{k-1}d)(\\log(d))^2)$ uniformly sampled entries through\nan appropriate incoherent nuclear norm minimization. Our results demonstrate\nsome key differences between completing a matrix and a higher order tensor:\nThey not only point to potential room for improvement over the usual nuclear\nnorm minimization but also highlight the importance of explicitly accounting\nfor incoherence, when dealing with higher order tensors. \n\n"}
{"id": "1606.03841", "contents": "Title: Efficient Learning with a Family of Nonconvex Regularizers by\n  Redistributing Nonconvexity Abstract: The use of convex regularizers allows for easy optimization, though they\noften produce biased estimation and inferior prediction performance. Recently,\nnonconvex regularizers have attracted a lot of attention and outperformed\nconvex ones. However, the resultant optimization problem is much harder. In\nthis paper, for a large class of nonconvex regularizers, we propose to move the\nnonconvexity from the regularizer to the loss. The nonconvex regularizer is\nthen transformed to a familiar convex regularizer, while the resultant loss\nfunction can still be guaranteed to be smooth. Learning with the convexified\nregularizer can be performed by existing efficient algorithms originally\ndesigned for convex regularizers (such as the proximal algorithm, Frank-Wolfe\nalgorithm, alternating direction method of multipliers and stochastic gradient\ndescent). Extensions are made when the convexified regularizer does not have\nclosed-form proximal step, and when the loss function is nonconvex, nonsmooth.\nExtensive experiments on a variety of machine learning application scenarios\nshow that optimizing the transformed problem is much faster than running the\nstate-of-the-art on the original problem. \n\n"}
{"id": "1606.03954", "contents": "Title: Cross-Gramian-Based Model Reduction: A Comparison Abstract: As an alternative to the popular balanced truncation method, the cross\nGramian matrix induces a class of balancing model reduction techniques. Besides\nthe classical computation of the cross Gramian by a Sylvester matrix equation,\nan empirical cross Gramian can be computed based on simulated trajectories.\nThis work assesses the cross Gramian and its empirical Gramian variant for\nstate-space reduction on a procedural benchmark based to the cross Gramian\nitself. \n\n"}
{"id": "1606.04991", "contents": "Title: A Class of Parallel Doubly Stochastic Algorithms for Large-Scale\n  Learning Abstract: We consider learning problems over training sets in which both, the number of\ntraining examples and the dimension of the feature vectors, are large. To solve\nthese problems we propose the random parallel stochastic algorithm (RAPSA). We\ncall the algorithm random parallel because it utilizes multiple parallel\nprocessors to operate on a randomly chosen subset of blocks of the feature\nvector. We call the algorithm stochastic because processors choose training\nsubsets uniformly at random. Algorithms that are parallel in either of these\ndimensions exist, but RAPSA is the first attempt at a methodology that is\nparallel in both the selection of blocks and the selection of elements of the\ntraining set. In RAPSA, processors utilize the randomly chosen functions to\ncompute the stochastic gradient component associated with a randomly chosen\nblock. The technical contribution of this paper is to show that this minimally\ncoordinated algorithm converges to the optimal classifier when the training\nobjective is convex. Moreover, we present an accelerated version of RAPSA\n(ARAPSA) that incorporates the objective function curvature information by\npremultiplying the descent direction by a Hessian approximation matrix. We\nfurther extend the results for asynchronous settings and show that if the\nprocessors perform their updates without any coordination the algorithms are\nstill convergent to the optimal argument. RAPSA and its extensions are then\nnumerically evaluated on a linear estimation problem and a binary image\nclassification task using the MNIST handwritten digit dataset. \n\n"}
{"id": "1606.07380", "contents": "Title: Variable-Sized Uncertainty and Inverse Problems in Robust Optimization Abstract: In robust optimization, the general aim is to find a solution that performs\nwell over a set of possible parameter outcomes, the so-called uncertainty set.\nIn this paper, we assume that the uncertainty size is not fixed, and instead\naim at finding a set of robust solutions that covers all possible uncertainty\nset outcomes. We refer to these problems as robust optimization with\nvariable-sized uncertainty. We discuss how to construct smallest possible sets\nof min-max robust solutions and give bounds on their size.\n  A special case of this perspective is to analyze for which uncertainty sets a\nnominal solution ceases to be a robust solution, which amounts to an inverse\nrobust optimization problem. We consider this problem with a min-max regret\nobjective and present mixed-integer linear programming formulations that can be\napplied to construct suitable uncertainty sets.\n  Results on both variable-sized uncertainty and inverse problems are further\nsupported with experimental data. \n\n"}
{"id": "1606.08939", "contents": "Title: Distributed Optimization Under Adversarial Nodes Abstract: We investigate the vulnerabilities of consensus-based distributed\noptimization protocols to nodes that deviate from the prescribed update rule\n(e.g., due to failures or adversarial attacks). We first characterize certain\nfundamental limitations on the performance of any distributed optimization\nalgorithm in the presence of adversaries. We then propose a resilient\ndistributed optimization algorithm that guarantees that the non-adversarial\nnodes converge to the convex hull of the minimizers of their local functions\nunder certain conditions on the graph topology, regardless of the actions of a\ncertain number of adversarial nodes. In particular, we provide sufficient\nconditions on the graph topology to tolerate a bounded number of adversaries in\nthe neighborhood of every non-adversarial node, and necessary and sufficient\nconditions to tolerate a globally bounded number of adversaries. For situations\nwhere there are up to F adversaries in the neighborhood of every node, we use\nthe concept of maximal F-local sets of graphs to provide lower bounds on the\ndistance-to-optimality of achievable solutions under any algorithm. We show\nthat finding the size of such sets is NP-hard. \n\n"}
{"id": "1607.00559", "contents": "Title: Sub-sampled Newton Methods with Non-uniform Sampling Abstract: We consider the problem of finding the minimizer of a convex function $F:\n\\mathbb R^d \\rightarrow \\mathbb R$ of the form $F(w) := \\sum_{i=1}^n f_i(w) +\nR(w)$ where a low-rank factorization of $\\nabla^2 f_i(w)$ is readily available.\nWe consider the regime where $n \\gg d$. As second-order methods prove to be\neffective in finding the minimizer to a high-precision, in this work, we\npropose randomized Newton-type algorithms that exploit \\textit{non-uniform}\nsub-sampling of $\\{\\nabla^2 f_i(w)\\}_{i=1}^{n}$, as well as inexact updates, as\nmeans to reduce the computational complexity. Two non-uniform sampling\ndistributions based on {\\it block norm squares} and {\\it block partial leverage\nscores} are considered in order to capture important terms among $\\{\\nabla^2\nf_i(w)\\}_{i=1}^{n}$. We show that at each iteration non-uniformly sampling at\nmost $\\mathcal O(d \\log d)$ terms from $\\{\\nabla^2 f_i(w)\\}_{i=1}^{n}$ is\nsufficient to achieve a linear-quadratic convergence rate in $w$ when a\nsuitable initial point is provided. In addition, we show that our algorithms\nachieve a lower computational complexity and exhibit more robustness and better\ndependence on problem specific quantities, such as the condition number,\ncompared to similar existing methods, especially the ones based on uniform\nsampling. Finally, we empirically demonstrate that our methods are at least\ntwice as fast as Newton's methods with ridge logistic regression on several\nreal datasets. \n\n"}
{"id": "1607.00696", "contents": "Title: Variational limits of k-NN graph based functionals on data clouds Abstract: This paper studies the large sample asymptotics of data analysis procedures\nbased on the optimization of functionals defined on $k$-NN graphs on point\nclouds. The paper is framed in the context of minimization of balanced cut\nfunctionals, but our techniques, ideas and results can be adapted to other\nfunctionals of relevance. We rigorously show that provided the number of\nneighbors in the graph $k:=k_n$ scales with the number of points in the cloud\nas $n \\gg k_n \\gg \\log(n)$, then with probability one, the solution to the\ngraph cut optimization problem converges towards the solution of an analogue\nvariational problem at the continuum level. \n\n"}
{"id": "1607.01027", "contents": "Title: Accelerate Stochastic Subgradient Method by Leveraging Local Growth\n  Condition Abstract: In this paper, a new theory is developed for first-order stochastic convex\noptimization, showing that the global convergence rate is sufficiently\nquantified by a local growth rate of the objective function in a neighborhood\nof the optimal solutions. In particular, if the objective function $F(\\mathbf\nw)$ in the $\\epsilon$-sublevel set grows as fast as $\\|\\mathbf w - \\mathbf\nw_*\\|_2^{1/\\theta}$, where $\\mathbf w_*$ represents the closest optimal\nsolution to $\\mathbf w$ and $\\theta\\in(0,1]$ quantifies the local growth rate,\nthe iteration complexity of first-order stochastic optimization for achieving\nan $\\epsilon$-optimal solution can be $\\widetilde O(1/\\epsilon^{2(1-\\theta)})$,\nwhich is optimal at most up to a logarithmic factor. To achieve the faster\nglobal convergence, we develop two different accelerated stochastic subgradient\nmethods by iteratively solving the original problem approximately in a local\nregion around a historical solution with the size of the local region gradually\ndecreasing as the solution approaches the optimal set. Besides the theoretical\nimprovements, this work also includes new contributions towards making the\nproposed algorithms practical: (i) we present practical variants of accelerated\nstochastic subgradient methods that can run without the knowledge of\nmultiplicative growth constant and even the growth rate $\\theta$; (ii) we\nconsider a broad family of problems in machine learning to demonstrate that the\nproposed algorithms enjoy faster convergence than traditional stochastic\nsubgradient method. We also characterize the complexity of the proposed\nalgorithms for ensuring the gradient is small without the smoothness\nassumption. \n\n"}
{"id": "1607.02624", "contents": "Title: Beating level-set methods for 3D seismic data interpolation: a\n  primal-dual alternating approach Abstract: Acquisition cost is a crucial bottleneck for seismic workflows, and low-rank\nformulations for data interpolation allow practitioners to `fill in' data\nvolumes from critically subsampled data acquired in the field. Tremendous size\nof seismic data volumes required for seismic processing remains a major\nchallenge for these techniques.\n  We propose a new approach to solve residual constrained formulations for\ninterpolation. We represent the data volume using matrix factors, and build a\nblock-coordinate algorithm with constrained convex subproblems that are solved\nwith a primal-dual splitting scheme. The new approach is competitive with state\nof the art level-set algorithms that interchange the role of objectives with\nconstraints. We use the new algorithm to successfully interpolate a large scale\n5D seismic data volume, generated from the geologically complex synthetic 3D\nCompass velocity model, where 80% of the data has been removed. \n\n"}
{"id": "1607.02633", "contents": "Title: Bayesian inference for stochastic differential equation mixed effects\n  models of a tumor xenography study Abstract: We consider Bayesian inference for stochastic differential equation mixed\neffects models (SDEMEMs) exemplifying tumor response to treatment and regrowth\nin mice. We produce an extensive study on how a SDEMEM can be fitted using both\nexact inference based on pseudo-marginal MCMC and approximate inference via\nBayesian synthetic likelihoods (BSL). We investigate a two-compartments SDEMEM,\nthese corresponding to the fractions of tumor cells killed by and survived to a\ntreatment, respectively. Case study data considers a tumor xenography study\nwith two treatment groups and one control, each containing 5-8 mice. Results\nfrom the case study and from simulations indicate that the SDEMEM is able to\nreproduce the observed growth patterns and that BSL is a robust tool for\ninference in SDEMEMs. Finally, we compare the fit of the SDEMEM to a similar\nordinary differential equation model. Due to small sample sizes, strong prior\ninformation is needed to identify all model parameters in the SDEMEM and it\ncannot be determined which of the two models is the better in terms of\npredicting tumor growth curves. In a simulation study we find that with a\nsample of 17 mice per group BSL is able to identify all model parameters and\ndistinguish treatment groups. \n\n"}
{"id": "1607.03195", "contents": "Title: Multi-Step Bayesian Optimization for One-Dimensional Feasibility\n  Determination Abstract: Bayesian optimization methods allocate limited sampling budgets to maximize\nexpensive-to-evaluate functions. One-step-lookahead policies are often used,\nbut computing optimal multi-step-lookahead policies remains a challenge. We\nconsider a specialized Bayesian optimization problem: finding the superlevel\nset of an expensive one-dimensional function, with a Markov process prior. We\ncompute the Bayes-optimal sampling policy efficiently, and characterize the\nsuboptimality of one-step lookahead. Our numerical experiments demonstrate that\nthe one-step lookahead policy is close to optimal in this problem, performing\nwithin 98% of optimal in the experimental settings considered. \n\n"}
{"id": "1607.03255", "contents": "Title: A Variational Model for Joint Motion Estimation and Image Reconstruction Abstract: The aim of this paper is to derive and analyze a variational model for the\njoint estimation of motion and reconstruction of image sequences, which is\nbased on a time-continuous Eulerian motion model. The model can be set up in\nterms of the continuity equation or the brightness constancy equation. The\nanalysis in this paper focuses on the latter for robust motion estimation on\nsequences of two-dimensional images. We rigorously prove the existence of a\nminimizer in a suitable function space setting. Moreover, we discuss the\nnumerical solution of the model based on primal-dual algorithms and investigate\nseveral examples. Finally, the benefits of our model compared to existing\ntechniques, such as sequential image reconstruction and motion estimation, are\nshown. \n\n"}
{"id": "1607.03463", "contents": "Title: LazySVD: Even Faster SVD Decomposition Yet Without Agonizing Pain Abstract: We study $k$-SVD that is to obtain the first $k$ singular vectors of a matrix\n$A$. Recently, a few breakthroughs have been discovered on $k$-SVD: Musco and\nMusco [1] proved the first gap-free convergence result using the block Krylov\nmethod, Shamir [2] discovered the first variance-reduction stochastic method,\nand Bhojanapalli et al. [3] provided the fastest $O(\\mathsf{nnz}(A) +\n\\mathsf{poly}(1/\\varepsilon))$-time algorithm using alternating minimization.\n  In this paper, we put forward a new and simple LazySVD framework to improve\nthe above breakthroughs. This framework leads to a faster gap-free method\noutperforming [1], and the first accelerated and stochastic method\noutperforming [2]. In the $O(\\mathsf{nnz}(A) + \\mathsf{poly}(1/\\varepsilon))$\nrunning-time regime, LazySVD outperforms [3] in certain parameter regimes\nwithout even using alternating minimization. \n\n"}
{"id": "1607.03815", "contents": "Title: Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than\n  $O(1/\\epsilon)$ Abstract: In this paper, we develop a novel {\\bf ho}moto{\\bf p}y {\\bf s}moothing (HOPS)\nalgorithm for solving a family of non-smooth problems that is composed of a\nnon-smooth term with an explicit max-structure and a smooth term or a simple\nnon-smooth term whose proximal mapping is easy to compute. The best known\niteration complexity for solving such non-smooth optimization problems is\n$O(1/\\epsilon)$ without any assumption on the strong convexity. In this work,\nwe will show that the proposed HOPS achieved a lower iteration complexity of\n$\\widetilde O(1/\\epsilon^{1-\\theta})$\\footnote{$\\widetilde O()$ suppresses a\nlogarithmic factor.} with $\\theta\\in(0,1]$ capturing the local sharpness of the\nobjective function around the optimal solutions. To the best of our knowledge,\nthis is the lowest iteration complexity achieved so far for the considered\nnon-smooth optimization problems without strong convexity assumption. The HOPS\nalgorithm employs Nesterov's smoothing technique and Nesterov's accelerated\ngradient method and runs in stages, which gradually decreases the smoothing\nparameter in a stage-wise manner until it yields a sufficiently good\napproximation of the original function. We show that HOPS enjoys a linear\nconvergence for many well-known non-smooth problems (e.g., empirical risk\nminimization with a piece-wise linear loss function and $\\ell_1$ norm\nregularizer, finding a point in a polyhedron, cone programming, etc).\nExperimental results verify the effectiveness of HOPS in comparison with\nNesterov's smoothing algorithm and the primal-dual style of first-order\nmethods. \n\n"}
{"id": "1607.04579", "contents": "Title: Learning from Conditional Distributions via Dual Embeddings Abstract: Many machine learning tasks, such as learning with invariance and policy\nevaluation in reinforcement learning, can be characterized as problems of\nlearning from conditional distributions. In such problems, each sample $x$\nitself is associated with a conditional distribution $p(z|x)$ represented by\nsamples $\\{z_i\\}_{i=1}^M$, and the goal is to learn a function $f$ that links\nthese conditional distributions to target values $y$. These learning problems\nbecome very challenging when we only have limited samples or in the extreme\ncase only one sample from each conditional distribution. Commonly used\napproaches either assume that $z$ is independent of $x$, or require an\noverwhelmingly large samples from each conditional distribution.\n  To address these challenges, we propose a novel approach which employs a new\nmin-max reformulation of the learning from conditional distribution problem.\nWith such new reformulation, we only need to deal with the joint distribution\n$p(z,x)$. We also design an efficient learning algorithm, Embedding-SGD, and\nestablish theoretical sample complexity for such problems. Finally, our\nnumerical experiments on both synthetic and real-world datasets show that the\nproposed approach can significantly improve over the existing algorithms. \n\n"}
{"id": "1607.07329", "contents": "Title: Accelerating Stochastic Composition Optimization Abstract: Consider the stochastic composition optimization problem where the objective\nis a composition of two expected-value functions. We propose a new stochastic\nfirst-order method, namely the accelerated stochastic compositional proximal\ngradient (ASC-PG) method, which updates based on queries to the sampling oracle\nusing two different timescales. The ASC-PG is the first proximal gradient\nmethod for the stochastic composition problem that can deal with nonsmooth\nregularization penalty. We show that the ASC-PG exhibits faster convergence\nthan the best known algorithms, and that it achieves the optimal sample-error\ncomplexity in several important special cases. We further demonstrate the\napplication of ASC-PG to reinforcement learning and conduct numerical\nexperiments. \n\n"}
{"id": "1608.01264", "contents": "Title: Fast and Simple Optimization for Poisson Likelihood Models Abstract: Poisson likelihood models have been prevalently used in imaging, social\nnetworks, and time series analysis. We propose fast, simple,\ntheoretically-grounded, and versatile, optimization algorithms for Poisson\nlikelihood modeling. The Poisson log-likelihood is concave but not\nLipschitz-continuous. Since almost all gradient-based optimization algorithms\nrely on Lipschitz-continuity, optimizing Poisson likelihood models with a\nguarantee of convergence can be challenging, especially for large-scale\nproblems.\n  We present a new perspective allowing to efficiently optimize a wide range of\npenalized Poisson likelihood objectives. We show that an appropriate saddle\npoint reformulation enjoys a favorable geometry and a smooth structure.\nTherefore, we can design a new gradient-based optimization algorithm with\n$O(1/t)$ convergence rate, in contrast to the usual $O(1/\\sqrt{t})$ rate of\nnon-smooth minimization alternatives. Furthermore, in order to tackle problems\nwith large samples, we also develop a randomized block-decomposition variant\nthat enjoys the same convergence rate yet more efficient iteration cost.\n  Experimental results on several point process applications including social\nnetwork estimation and temporal recommendation show that the proposed algorithm\nand its randomized block variant outperform existing methods both on synthetic\nand real-world datasets. \n\n"}
{"id": "1608.01274", "contents": "Title: Which Findings from the Functional Neuromaging Literature Can We Trust? Abstract: In their recent \"Cluster Failure\" paper, Eklund and colleagues cast doubt on\nthe accuracy of a widely used statistical test in functional neuroimaging.\nHere, we leverage nonparametric methods that control the false discovery rate\nto offer more nuanced, quantitative guidance about which findings in the\nexisting literature can be trusted. We show that, in the task studies examined\nby Eklund et al., most clusters originally reported to be significant are\nindeed trustworthy by the false discovery rate benchmark. \n\n"}
{"id": "1608.02148", "contents": "Title: Randomized Matrix Decompositions using R Abstract: Matrix decompositions are fundamental tools in the area of applied\nmathematics, statistical computing, and machine learning. In particular,\nlow-rank matrix decompositions are vital, and widely used for data analysis,\ndimensionality reduction, and data compression. Massive datasets, however, pose\na computational challenge for traditional algorithms, placing significant\nconstraints on both memory and processing power. Recently, the powerful concept\nof randomness has been introduced as a strategy to ease the computational load.\nThe essential idea of probabilistic algorithms is to employ some amount of\nrandomness in order to derive a smaller matrix from a high-dimensional data\nmatrix. The smaller matrix is then used to compute the desired low-rank\napproximation. Such algorithms are shown to be computationally efficient for\napproximating matrices with low-rank structure. We present the \\proglang{R}\npackage rsvd, and provide a tutorial introduction to randomized matrix\ndecompositions. Specifically, randomized routines for the singular value\ndecomposition, (robust) principal component analysis, interpolative\ndecomposition, and CUR decomposition are discussed. Several examples\ndemonstrate the routines, and show the computational advantage over other\nmethods implemented in R. \n\n"}
{"id": "1608.03622", "contents": "Title: Optimal steering of a linear stochastic system to a final probability\n  distribution, Part III Abstract: The subject of this work has its roots in the so called Schroedginer Bridge\nProblem (SBP) which asks for the most likely distribution of Brownian particles\nin their passage between observed empirical marginal distributions at two\ndistinct points in time. Renewed interest in this problem was sparked by a\nreformulation in the language of stochastic control. In earlier works,\npresented as Part I and Part II, we explored a generalization of the original\nSBP that amounts to optimal steering of linear stochastic dynamical systems\nbetween state-distributions, at two points in time, under full state feedback.\nIn these works the cost was quadratic in the control input. The purpose of the\npresent work is to detail the technical steps in extending the framework to the\ncase where a quadratic cost in the state is also present. In the zero-noise\nlimit, we obtain the solution of a (deterministic) mass transport problem with\ngeneral quadratic cost. \n\n"}
{"id": "1608.06159", "contents": "Title: Total-variation regularization strategies in full-waveform inversion Abstract: We propose an extended full-waveform inversion formulation that includes\ngeneral convex constraints on the model. Though the full problem is highly\nnonconvex, the overarching optimization scheme arrives at geologically\nplausible results by solving a sequence of relaxed and warm-started constrained\nconvex subproblems. The combination of box, total-variation, and successively\nrelaxed asymmetric total-variation constraints allows us to steer free from\nparasitic local minima while keeping the estimated physical parameters\nlaterally continuous and in a physically realistic range. For accurate starting\nmodels, numerical experiments carried out on the challenging 2004 BP velocity\nbenchmark demonstrate that bound and total-variation constraints improve the\ninversion result significantly by removing inversion artifacts, related to\nsource encoding, and by clearly improved delineation of top, bottom, and flanks\nof a high-velocity high-contrast salt inclusion. The experiments also show that\nfor poor starting models these two constraints by themselves are insufficient\nto detect the bottom of high-velocity inclusions such as salt. Inclusion of the\none-sided asymmetric total-variation constraint overcomes this issue by\ndiscouraging velocity lows to buildup during the early stages of the inversion.\nTo the author's knowledge the presented algorithm is the first to successfully\nremove the imprint of local minima caused by poor starting models and\nband-width limited finite aperture data. \n\n"}
{"id": "1608.06198", "contents": "Title: Quantum Control Landscapes Are Almost Always Trap Free Abstract: A proof that almost all quantum systems have trap free (that is, free from\nlocal optima) landscapes is presented for a large and physically general class\nof quantum system. This result offers an explanation for why gradient methods\nsucceed so frequently in quantum control in both theory and practice. The role\nof singular controls is analyzed using geometric tools in the case of the\ncontrol of the propagator of closed finite dimension systems. This type of\ncontrol field has been implicated as a source of landscape traps. The\nconditions under which singular controls can introduce traps, and thus\ninterrupt the progress of a control optimization, are discussed and a\ngeometrical characterization of the issue is presented. It is shown that a\ncontrol being singular is not sufficient to cause a control optimization\nprogress to halt and sufficient conditions for a trap free landscape are\npresented. It is further shown that the local surjectivity axiom of landscape\nanalysis can be refined to the condition that the end-point map is transverse\nto each of the level sets of the fidelity function. This novel condition is\nshown to be sufficient for a quantum system's landscape to be trap free. The\ncontrol landscape for a quantum system is shown to be trap free for all but a\nnull set of Hamiltonians using a novel geometric technique based on the\nparametric transversality theorem. Numerical evidence confirming this is also\npresented. This result is the analogue of the work of Altifini, wherein it is\nshown that controllability holds for all but a null set of quantum systems in\nthe dipole approximation. The presented results indicate that by-and-large\nlimited control resources are the most physically relevant source of landscape\ntraps. \n\n"}
{"id": "1608.07498", "contents": "Title: On the dynamic representation of some time-inconsistent risk measures in\n  a Brownian filtration Abstract: It is well-known from the work of Kupper and Schachermayer that most\nlaw-invariant risk measures do not admit a time-consistent representation. In\nthis work we show that in a Brownian filtration the \"Optimized Certainty\nEquivalent\" risk measures of Ben-Tal and Teboulle can be computed through PDE\ntechniques, i.e. dynamically. This can be seen as a substitute of sorts\nwhenever they lack time consistency, and covers the cases of conditional\nvalue-at-risk and monotone mean-variance. Our method consists of focusing on\nthe convex dual representation, which suggests extending the state space. With\nthis we can obtain a dynamic programming principle and use stochastic control\ntechniques, along with the theory of viscosity solutions, which we must adapt\nto cover the present singular situation. \n\n"}
{"id": "1609.02501", "contents": "Title: A Computationally Efficient Projection-Based Approach for Spatial\n  Generalized Linear Mixed Models Abstract: Inference for spatial generalized linear mixed models (SGLMMs) for\nhigh-dimensional non-Gaussian spatial data is computationally intensive. The\ncomputational challenge is due to the high-dimensional random effects and\nbecause Markov chain Monte Carlo (MCMC) algorithms for these models tend to be\nslow mixing. Moreover, spatial confounding inflates the variance of fixed\neffect (regression coefficient) estimates. Our approach addresses both the\ncomputational and confounding issues by replacing the high-dimensional spatial\nrandom effects with a reduced-dimensional representation based on random\nprojections. Standard MCMC algorithms mix well and the reduced-dimensional\nsetting speeds up computations per iteration. We show, via simulated examples,\nthat Bayesian inference for this reduced-dimensional approach works well both\nin terms of inference as well as prediction, our methods also compare favorably\nto existing \"reduced-rank\" approaches. We also apply our methods to two real\nworld data examples, one on bird count data and the other classifying rock\ntypes. \n\n"}
{"id": "1609.03784", "contents": "Title: A Fast Proximal Gradient Algorithm for Decentralized Composite\n  Optimization over Directed Networks Abstract: This paper proposes a fast decentralized algorithm for solving a consensus\noptimization problem defined in a directed networked multi-agent system, where\nthe local objective functions have the smooth+nonsmooth composite form, and are\npossibly nonconvex. Examples of such problems include decentralized compressed\nsensing and constrained quadratic programming problems, as well as many\ndecentralized regularization problems. We extend the existing algorithms\nPG-EXTRA and ExtraPush to a new algorithm PG-ExtraPush for composite consensus\noptimization over a directed network. This algorithm takes advantage of the\nproximity operator like in PG-EXTRA to deal with the nonsmooth term, and\nemploys the push-sum protocol like in ExtraPush to tackle the bias introduced\nby the directed network. With a proper step size, we show that PG-ExtraPush\nconverges to an optimal solution at a linear rate under some regular\nassumptions. We conduct a series of numerical experiments to show the\neffectiveness of the proposed algorithm. Specifically, with a proper step size,\nPG-ExtraPush performs linear rates in most of cases, even in some nonconvex\ncases, and is significantly faster than Subgradient-Push, even if the latter\nuses a hand-optimized step size. The established theoretical results are also\nverified by the numerical results. \n\n"}
{"id": "1609.03984", "contents": "Title: Structure of Optimal Solutions to Periodic-Review Total-Cost Inventory\n  Control Models with Convex Costs and Backorders for all Values of Discount\n  Factors Abstract: This paper describes the structure of optimal policies for discounted\nperiodic-review single-commodity total-cost inventory control problems with\nfixed ordering costs for finite and infinite horizons. There are known\nconditions in the literature for optimality of $(s_t,S_t)$ policies for\nfinite-horizon problems and the optimality of $(s,S)$ policies for\ninfinite-horizon problems. The results of this paper cover the situation, when\nsuch assumption may not hold. This paper describes a parameter, which, together\nwith the value of the discount factor and the horizon length, defines the\nstructure of an optimal policy. For the infinite horizon, depending on the\nvalues of this parameter and the discount factor, an optimal policy either is\nan $(s,S)$ policy or never orders inventory. For a finite horizon, depending on\nthe values of this parameter, the discount factor, and the horizon length,\nthere are three possible structures of an optimal policy: (i) it is an\n$(s_t,S_t)$ policy, (ii) it is an $(s_t,S_t)$ policy at earlier stages and then\ndoes not order inventory, or (iii) it never orders inventory. The paper also\nestablishes continuity of optimal value functions and describes alternative\noptimal actions at states $s_t$ and $s.$ \n\n"}
{"id": "1609.05043", "contents": "Title: Linear representations of convolutional codes over rings Abstract: In this paper we extend the relation between convolutional codes and linear\nsystems over finite fields to certain commutative rings through first order\nrepresentations . We introduce the definition of rings with representations as\nthose for which these representations always exist, and we show that finite\nproducts of finite fields belong to this class. We develop the\ninput/state/output representations for convolutional codes over these rings,\nand we show how to use them to construct observable convolutional codes as in\nthe classical case. \n\n"}
{"id": "1609.05167", "contents": "Title: Improving the semidefinite programming bound for the kissing number by\n  exploiting polynomial symmetry Abstract: The kissing number of $\\mathbb{R}^n$ is the maximum number of\npairwise-nonoverlapping unit spheres that can simultaneously touch a central\nunit sphere. Mittelmann and Vallentin (2010), based on the semidefinite\nprogramming bound of Bachoc and Vallentin (2008), computed the best known upper\nbounds for the kissing number for several values of $n \\leq 23$. In this paper,\nwe exploit the symmetry present in the semidefinite programming bound to\nprovide improved upper bounds for $n = 9, \\ldots, 23$. \n\n"}
{"id": "1609.05820", "contents": "Title: The Projected Power Method: An Efficient Algorithm for Joint Alignment\n  from Pairwise Differences Abstract: Various applications involve assigning discrete label values to a collection\nof objects based on some pairwise noisy data. Due to the discrete---and hence\nnonconvex---structure of the problem, computing the optimal assignment\n(e.g.~maximum likelihood assignment) becomes intractable at first sight. This\npaper makes progress towards efficient computation by focusing on a concrete\njoint alignment problem---that is, the problem of recovering $n$ discrete\nvariables $x_i \\in \\{1,\\cdots, m\\}$, $1\\leq i\\leq n$ given noisy observations\nof their modulo differences $\\{x_i - x_j~\\mathsf{mod}~m\\}$. We propose a\nlow-complexity and model-free procedure, which operates in a lifted space by\nrepresenting distinct label values in orthogonal directions, and which attempts\nto optimize quadratic functions over hypercubes. Starting with a first guess\ncomputed via a spectral method, the algorithm successively refines the iterates\nvia projected power iterations. We prove that for a broad class of statistical\nmodels, the proposed projected power method makes no error---and hence\nconverges to the maximum likelihood estimate---in a suitable regime. Numerical\nexperiments have been carried out on both synthetic and real data to\ndemonstrate the practicality of our algorithm. We expect this algorithmic\nframework to be effective for a broad range of discrete assignment problems. \n\n"}
{"id": "1609.06369", "contents": "Title: Generalized Kalman Smoothing: Modeling and Algorithms Abstract: State-space smoothing has found many applications in science and engineering.\nUnder linear and Gaussian assumptions, smoothed estimates can be obtained using\nefficient recursions, for example Rauch-Tung-Striebel and Mayne-Fraser\nalgorithms. Such schemes are equivalent to linear algebraic techniques that\nminimize a convex quadratic objective function with structure induced by the\ndynamic model.\n  These classical formulations fall short in many important circumstances. For\ninstance, smoothers obtained using quadratic penalties can fail when outliers\nare present in the data, and cannot track impulsive inputs and abrupt state\nchanges. Motivated by these shortcomings, generalized Kalman smoothing\nformulations have been proposed in the last few years, replacing quadratic\nmodels with more suitable, often nonsmooth, convex functions. In contrast to\nclassical models, these general estimators require use of iterated algorithms,\nand these have received increased attention from control, signal processing,\nmachine learning, and optimization communities.\n  In this survey we show that the optimization viewpoint provides the control\nand signal processing community great freedom in the development of novel\nmodeling and inference frameworks for dynamical systems. We discuss general\nstatistical models for dynamic systems, making full use of nonsmooth convex\npenalties and constraints, and providing links to important models in signal\nprocessing and machine learning. We also survey optimization techniques for\nthese formulations, paying close attention to dynamic problem structure.\nModeling concepts and algorithms are illustrated with numerical examples. \n\n"}
{"id": "1609.07180", "contents": "Title: Low Rank Independence Samplers in Bayesian Inverse Problems Abstract: In Bayesian inverse problems, the posterior distribution is used to quantify\nuncertainty about the reconstructed solution. In practice, Markov chain Monte\nCarlo algorithms often are used to draw samples from the posterior\ndistribution. However, implementations of such algorithms can be\ncomputationally expensive. We present a computationally efficient scheme for\nsampling high-dimensional Gaussian distributions in ill-posed Bayesian linear\ninverse problems. Our approach uses Metropolis-Hastings independence sampling\nwith a proposal distribution based on a low-rank approximation of the\nprior-preconditioned Hessian. We show the dependence of the acceptance rate on\nthe number of eigenvalues retained and discuss conditions under which the\nacceptance rate is high. We demonstrate our proposed sampler by using it with\nMetropolis-Hastings-within-Gibbs sampling in numerical experiments in image\ndeblurring, computerized tomography, and NMR relaxometry. \n\n"}
{"id": "1609.07195", "contents": "Title: Balancing Statistical and Computational Precision: A General Theory and\n  Applications to Sparse Regression Abstract: Modern technologies are generating ever-increasing amounts of data. Making\nuse of these data requires methods that are both statistically sound and\ncomputationally efficient. Typically, the statistical and computational aspects\nare treated separately. In this paper, we propose an approach to entangle these\ntwo aspects in the context of regularized estimation. Applying our approach to\nsparse and group-sparse regression, we show that it can improve on standard\npipelines both statistically and computationally. \n\n"}
{"id": "1609.07237", "contents": "Title: Decentralized Nonlinear Feedback Design with Separable Control\n  Contraction Metrics Abstract: The problem under consideration is the synthesis of a distributed controller\nfor a nonlinear network composed of input affine systems. The objective is to\nachieve exponential convergence of the solutions. To design such a feedback\nlaw, methods based on contraction theory are employed to render the\ncontroller-synthesis problem scalable and suitable to use distributed\noptimization. The nature of the proposed approach is constructive, because the\ncomputation of the desired feedback law is obtained by solving a convex\noptimization problem. An example illustrates the proposed methodology. \n\n"}
{"id": "1609.07402", "contents": "Title: A Copositive Approach for Two-Stage Adjustable Robust Optimization with\n  Uncertain Right-Hand Sides Abstract: We study two-stage adjustable robust linear programming in which the\nright-hand sides are uncertain and belong to a convex, compact uncertainty set.\nThis problem is NP-hard, and the affine policy is a popular, tractable\napproximation. We prove that under standard and simple conditions, the\ntwo-stage problem can be reformulated as a copositive optimization problem,\nwhich in turn leads to a class of tractable, semidefinite-based approximations\nthat are at least as strong as the affine policy. We investigate several\nexamples from the literature demonstrating that our tractable approximations\nsignificantly improve the affine policy. In particular, our approach solves\nexactly in polynomial time a class of instances of increasing size for which\nthe affine policy admits an arbitrarily large gap. \n\n"}
{"id": "1609.08262", "contents": "Title: Distributed Regularized Primal-Dual Method: Convergence Analysis and\n  Trade-offs Abstract: We study deterministic and stochastic primal-dual sub-gradient algorithms for\ndistributed optimization of a separable objective function with global\ninequality constraints. In both algorithms, the norm of the Lagrangian\nmultipliers are controlled by augmenting the corresponding Lagrangian function\nwith a quadratic regularization term. Specifically, we show that when the\nstepsize of each algorithm satisfies a certain restriction, the norm of the\nLagrangian multipliers is upper bounded by an expression that is inversely\nproportional to the parameter of the regularization. We use this result to\ncompute upper bounds on the sub-gradients of the Lagrangian function. For the\ndeterministic algorithm, we prove a convergence rate for attaining the optimal\nobjective value. In the stochastic optimization case, we similarly prove\nconvergence rates both in the expectation and with a high probability, using\nthe method of bounded martingale difference. For both algorithms, we\ndemonstrate a trade-off between the convergence rate and the decay rate of the\nconstraint violation, in the sense that improving the convergence rate slows\nthe decay rate of the constraint violation and vice versa. We demonstrate the\nconvergence of our proposed algorithms numerically for distributed regression\nwith the hinge and logistic loss functions over different graph structures. \n\n"}
{"id": "1609.08502", "contents": "Title: Exact and Inexact Subsampled Newton Methods for Optimization Abstract: The paper studies the solution of stochastic optimization problems in which\napproximations to the gradient and Hessian are obtained through subsampling. We\nfirst consider Newton-like methods that employ these approximations and discuss\nhow to coordinate the accuracy in the gradient and Hessian to yield a\nsuperlinear rate of convergence in expectation. The second part of the paper\nanalyzes an inexact Newton method that solves linear systems approximately\nusing the conjugate gradient (CG) method, and that samples the Hessian and not\nthe gradient (the gradient is assumed to be exact). We provide a complexity\nanalysis for this method based on the properties of the CG iteration and the\nquality of the Hessian approximation, and compare it with a method that employs\na stochastic gradient iteration instead of the CG method. We report preliminary\nnumerical results that illustrate the performance of inexact subsampled Newton\nmethods on machine learning applications based on logistic regression. \n\n"}
{"id": "1609.09286", "contents": "Title: Surrogate models for oscillatory systems using sparse polynomial chaos\n  expansions and stochastic time warping Abstract: Polynomial chaos expansions (PCE) have proven efficiency in a number of\nfields for propagating parametric uncertainties through computational models of\ncomplex systems, namely structural and fluid mechanics, chemical reactions and\nelectromagnetism, etc. For problems involving oscillatory, time-dependent\noutput quantities of interest, it is well-known that reasonable accuracy of\nPCE-based approaches is difficult to reach in the long term. In this paper, we\npropose a fully non-intrusive approach based on stochastic time warping to\naddress this issue: each realization (trajectory) of the model response is\nfirst rescaled to its own time scale so as to put all sampled trajectories in\nphase in a common virtual time line. Principal component analysis is introduced\nto compress the information contained in these transformed trajectories and\nsparse PCE representations using least angle regression are finally used to\napproximate the components. The approach shows remarkably small prediction\nerror for particular trajectories as well as for second-order statistics of the\nlatter. It is illustrated on different benchmark problems well known in the\nliterature on time-dependent PCE problems, ranging from rigid body dynamics,\nchemical reactions to forced oscillations of a non linear system. \n\n"}
{"id": "1610.00040", "contents": "Title: A Primer on Coordinate Descent Algorithms Abstract: This monograph presents a class of algorithms called coordinate descent\nalgorithms for mathematicians, statisticians, and engineers outside the field\nof optimization. This particular class of algorithms has recently gained\npopularity due to their effectiveness in solving large-scale optimization\nproblems in machine learning, compressed sensing, image processing, and\ncomputational statistics. Coordinate descent algorithms solve optimization\nproblems by successively minimizing along each coordinate or coordinate\nhyperplane, which is ideal for parallelized and distributed computing. Avoiding\ndetailed technicalities and proofs, this monograph gives relevant theory and\nexamples for practitioners to effectively apply coordinate descent to modern\nproblems in data science and engineering. \n\n"}
{"id": "1610.00168", "contents": "Title: Learning Optimized Risk Scores Abstract: Risk scores are simple classification models that let users make quick risk\npredictions by adding and subtracting a few small numbers. These models are\nwidely used in medicine and criminal justice, but are difficult to learn from\ndata because they need to be calibrated, sparse, use small integer\ncoefficients, and obey application-specific operational constraints. In this\npaper, we present a new machine learning approach to learn risk scores. We\nformulate the risk score problem as a mixed integer nonlinear program, and\npresent a cutting plane algorithm for non-convex settings to efficiently\nrecover its optimal solution. We improve our algorithm with specialized\ntechniques to generate feasible solutions, narrow the optimality gap, and\nreduce data-related computation. Our approach can fit risk scores in a way that\nscales linearly in the number of samples, provides a certificate of optimality,\nand obeys real-world constraints without parameter tuning or post-processing.\nWe benchmark the performance benefits of this approach through an extensive set\nof numerical experiments, comparing to risk scores built using heuristic\napproaches. We also discuss its practical benefits through a real-world\napplication where we build a customized risk score for ICU seizure prediction\nin collaboration with the Massachusetts General Hospital. \n\n"}
{"id": "1610.00362", "contents": "Title: An Optimal Treatment Assignment Strategy to Evaluate Demand Response\n  Effect Abstract: Demand response is designed to motivate electricity customers to modify their\nloads at critical time periods. The accurate estimation of impact of demand\nresponse signals to customers' consumption is central to any successful\nprogram. In practice, learning these response is nontrivial because operators\ncan only send a limited number of signals. In addition, customer behavior also\ndepends on a large number of exogenous covariates. These two features lead to a\nhigh dimensional inference problem with limited number of observations. In this\npaper, we formulate this problem by using a multivariate linear model and adopt\nan experimental design approach to estimate the impact of demand response\nsignals. We show that randomized assignment, which is widely used to estimate\nthe average treatment effect, is not efficient in reducing the variance of the\nestimator when a large number of covariates is present. In contrast, we present\na tractable algorithm that strategically assigns demand response signals to\ncustomers. This algorithm achieves the optimal reduction in estimation\nvariance, independent of the number of covariates. The results are validated\nfrom simulations on synthetic data. \n\n"}
{"id": "1610.02588", "contents": "Title: Iterative proportional scaling revisited: a modern optimization\n  perspective Abstract: This paper revisits the classic iterative proportional scaling (IPS) from a\nmodern optimization perspective. In contrast to the criticisms made in the\nliterature, we show that based on a coordinate descent characterization, IPS\ncan be slightly modified to deliver coefficient estimates, and from a\nmajorization-minimization standpoint, IPS can be extended to handle log-affine\nmodels with features not necessarily binary-valued or nonnegative. Furthermore,\nsome state-of-the-art optimization techniques such as block-wise computation,\nrandomization and momentum-based acceleration can be employed to provide more\nscalable IPS algorithms, as well as some regularized variants of IPS for\nconcurrent feature selection. \n\n"}
{"id": "1610.02617", "contents": "Title: Time-Average Optimization with Non-Convex Decision Set and Its\n  Convergence Abstract: This paper considers time-average optimization, where a decision vector is\nchosen every time step within a (possibly non-convex) set, and the goal is to\nminimize a convex function of the time averages subject to convex constraints\non these averages. Such problems have applications in networking, multi-agent\nsystems, and operations research, where decisions are constrained to a discrete\nset and the decision average can represent average bit rates or average agent\nactions. This time-average optimization extends traditional convex formulations\nto allow a non-convex decision set. This class of problems can be solved by\nLyapunov optimization. A simple drift-based algorithm, related to a classical\ndual subgradient algorithm, converges to an $\\epsilon$-optimal solution within\n$O(1/\\epsilon^2)$ time steps. Further, the algorithm is shown to have a\ntransient phase and a steady state phase which can be exploited to improve\nconvergence rates to $O(1/\\epsilon)$ and $O(1/{\\epsilon^{1.5}})$ when vectors\nof Lagrange multipliers satisfy locally-polyhedral and locally-smooth\nassumptions respectively. Practically, this improved convergence suggests that\ndecisions should be implemented after the transient period. \n\n"}
{"id": "1610.02758", "contents": "Title: Stochastic Alternating Direction Method of Multipliers with Variance\n  Reduction for Nonconvex Optimization Abstract: In the paper, we study the stochastic alternating direction method of\nmultipliers (ADMM) for the nonconvex optimizations, and propose three classes\nof the nonconvex stochastic ADMM with variance reduction, based on different\nreduced variance stochastic gradients. Specifically, the first class called the\nnonconvex stochastic variance reduced gradient ADMM (SVRG-ADMM), uses a\nmulti-stage scheme to progressively reduce the variance of stochastic\ngradients. The second is the nonconvex stochastic average gradient ADMM\n(SAG-ADMM), which additionally uses the old gradients estimated in the previous\niteration. The third called SAGA-ADMM is an extension of the SAG-ADMM method.\nMoreover, under some mild conditions, we establish the iteration complexity\nbound of $O(1/\\epsilon)$ of the proposed methods to obtain an\n$\\epsilon$-stationary solution of the nonconvex optimizations. In particular,\nwe provide a general framework to analyze the iteration complexity of these\nnonconvex stochastic ADMM methods with variance reduction. Finally, some\nnumerical experiments demonstrate the effectiveness of our methods. \n\n"}
{"id": "1610.03045", "contents": "Title: Sketching Meets Random Projection in the Dual: A Provable Recovery\n  Algorithm for Big and High-dimensional Data Abstract: Sketching techniques have become popular for scaling up machine learning\nalgorithms by reducing the sample size or dimensionality of massive data sets,\nwhile still maintaining the statistical power of big data. In this paper, we\nstudy sketching from an optimization point of view: we first show that the\niterative Hessian sketch is an optimization process with preconditioning, and\ndevelop accelerated iterative Hessian sketch via the searching the conjugate\ndirection; we then establish primal-dual connections between the Hessian sketch\nand dual random projection, and apply the preconditioned conjugate gradient\napproach on the dual problem, which leads to the accelerated iterative dual\nrandom projection methods. Finally to tackle the challenges from both large\nsample size and high-dimensionality, we propose the primal-dual sketch, which\niteratively sketches the primal and dual formulations. We show that using a\nlogarithmic number of calls to solvers of small scale problem, primal-dual\nsketch is able to recover the optimum of the original problem up to arbitrary\nprecision. The proposed algorithms are validated via extensive experiments on\nsynthetic and real data sets which complements our theoretical results. \n\n"}
{"id": "1610.03701", "contents": "Title: Localization in High-Dimensional Monte Carlo Filtering Abstract: The high dimensionality and computational constraints associated with\nfiltering problems in large-scale geophysical applications are particularly\nchallenging for the Particle Filter (PF). Approximate but efficient methods\nsuch as the Ensemble Kalman Filter (EnKF) are therefore usually preferred. A\nkey element of these approximate methods is localization, which is in principle\na general technique to avoid the curse of dimensionality and consists in\nlimiting the influence of observations to neighboring sites. However, while it\nworks effectively with the EnKF, localization introduces harmful\ndiscontinuities in the estimated physical fields when applied blindly to the\nPF. In the present paper, we explore two possible local algorithms based on the\nEnKPF, a hybrid method combining the EnKF and the PF. A simulation study in a\nconjugate normal setup allows to highlight the trade-offs involved when\napplying localization to PF type of algorithms in the high-dimensional setting.\nExperiments with the Lorenz96 model demonstrate the ability of the local EnKPF\nalgorithms to perform well even with a small number of particles compared to\nthe problem size. \n\n"}
{"id": "1610.03871", "contents": "Title: Preconditioning via Diagonal Scaling Abstract: Interior point methods solve small to medium sized problems to high accuracy\nin a reasonable amount of time. However, for larger problems as well as\nstochastic problems, one needs to use first-order methods such as stochastic\ngradient descent (SGD), the alternating direction method of multipliers (ADMM),\nand conjugate gradient (CG) in order to attain a modest accuracy in a\nreasonable number of iterations. In this report, we first discuss heuristics\nfor diagonal scaling. Next, we motivate preconditioning by an example, and then\nwe study preconditioning for a specific splitting form in ADMM called graph\nprojection splitting. Finally we examine the performance of our methods by some\nnumerical examples. \n\n"}
{"id": "1610.04583", "contents": "Title: Message-passing algorithms for synchronization problems over compact\n  groups Abstract: Various alignment problems arising in cryo-electron microscopy, community\ndetection, time synchronization, computer vision, and other fields fall into a\ncommon framework of synchronization problems over compact groups such as Z/L,\nU(1), or SO(3). The goal of such problems is to estimate an unknown vector of\ngroup elements given noisy relative observations. We present an efficient\niterative algorithm to solve a large class of these problems, allowing for any\ncompact group, with measurements on multiple 'frequency channels' (Fourier\nmodes, or more generally, irreducible representations of the group). Our\nalgorithm is a highly efficient iterative method following the blueprint of\napproximate message passing (AMP), which has recently arisen as a central\ntechnique for inference problems such as structured low-rank estimation and\ncompressed sensing. We augment the standard ideas of AMP with ideas from\nrepresentation theory so that the algorithm can work with distributions over\ncompact groups. Using standard but non-rigorous methods from statistical\nphysics we analyze the behavior of our algorithm on a Gaussian noise model,\nidentifying phases where the problem is easy, (computationally) hard, and\n(statistically) impossible. In particular, such evidence predicts that our\nalgorithm is information-theoretically optimal in many cases, and that the\nremaining cases show evidence of statistical-to-computational gaps. \n\n"}
{"id": "1610.04584", "contents": "Title: The Chow form of a reciprocal linear space Abstract: A reciprocal linear space is the image of a linear space under\ncoordinate-wise inversion. These fundamental varieties describe the analytic\ncenters of hyperplane arrangements and appear as part of the defining equations\nof the central path of a linear program. Their structure is controlled by an\nunderlying matroid. This provides a large family of hyperbolic varieties,\nrecently introduced by Shamovich and Vinnikov. Here we give a definite\ndeterminantal representation to the Chow form of a reciprocal linear space. One\nconsequence is the existence of symmetric rank-one Ulrich sheaves on reciprocal\nlinear spaces. Another is a representation of the entropic discriminant as a\nsum of squares. For generic linear spaces, the determinantal formulas obtained\nare closely related to the Laplacian of the complete graph and generalizations\nto simplicial matroids. This raises interesting questions about the\ncombinatorics of hyperbolic varieties and connections with the positive\nGrassmannian. \n\n"}
{"id": "1610.05350", "contents": "Title: How Well Do Local Algorithms Solve Semidefinite Programs? Abstract: Several probabilistic models from high-dimensional statistics and machine\nlearning reveal an intriguing --and yet poorly understood-- dichotomy. Either\nsimple local algorithms succeed in estimating the object of interest, or even\nsophisticated semi-definite programming (SDP) relaxations fail.\n  In order to explore this phenomenon, we study a classical SDP relaxation of\nthe minimum graph bisection problem, when applied to Erd\\H{o}s-Renyi random\ngraphs with bounded average degree $d>1$, and obtain several types of results.\nFirst, we use a dual witness construction (using the so-called non-backtracking\nmatrix of the graph) to upper bound the SDP value. Second, we prove that a\nsimple local algorithm approximately solves the SDP to within a factor\n$2d^2/(2d^2+d-1)$ of the upper bound. In particular, the local algorithm is at\nmost $8/9$ suboptimal, and $1+O(1/d)$ suboptimal for large degree.\n  We then analyze a more sophisticated local algorithm, which aggregates\ninformation according to the harmonic measure on the limiting Galton-Watson\n(GW) tree. The resulting lower bound is expressed in terms of the conductance\nof the GW tree and matches surprisingly well the empirically determined SDP\nvalues on large-scale Erd\\H{o}s-Renyi graphs.\n  We finally consider the planted partition model. In this case, purely local\nalgorithms are known to fail, but they do succeed if a small amount of side\ninformation is available. Our results imply quantitative bounds on the\nthreshold for partial recovery using SDP in this model. \n\n"}
{"id": "1610.05792", "contents": "Title: Big Batch SGD: Automated Inference using Adaptive Batch Sizes Abstract: Classical stochastic gradient methods for optimization rely on noisy gradient\napproximations that become progressively less accurate as iterates approach a\nsolution. The large noise and small signal in the resulting gradients makes it\ndifficult to use them for adaptive stepsize selection and automatic stopping.\nWe propose alternative \"big batch\" SGD schemes that adaptively grow the batch\nsize over time to maintain a nearly constant signal-to-noise ratio in the\ngradient approximation. The resulting methods have similar convergence rates to\nclassical SGD, and do not require convexity of the objective. The high fidelity\ngradients enable automated learning rate selection and do not require stepsize\ndecay. Big batch methods are thus easily automated and can run with little or\nno oversight. \n\n"}
{"id": "1610.06538", "contents": "Title: A general double-proximal gradient algorithm for d.c. programming Abstract: The possibilities of exploiting the special structure of d.c. programs, which\nconsist of optimizing the difference of convex functions, are currently more or\nless limited to variants of the DCA proposed by Pham Dinh Tao and Le Thi Hoai\nAn in 1997. These assume that either the convex or the concave part, or both,\nare evaluated by one of their subgradients.\n  In this paper we propose an algorithm which allows the evaluation of both the\nconcave and the convex part by their proximal points. Additionally, we allow a\nsmooth part, which is evaluated via its gradient. In the spirit of primal-dual\nsplitting algorithms, the concave part might be the composition of a concave\nfunction with a linear operator, which are, however, evaluated separately.\n  For this algorithm we show that every cluster point is a solution of the\noptimization problem. Furthermore, we show the connection to the Toland dual\nproblem and prove a descent property for the objective function values of a\nprimal-dual formulation of the problem. Convergence of the iterates is shown if\nthis objective function satisfies the Kurdyka--\\L ojasiewicz property. In the\nlast part, we apply the algorithm to an image processing model. \n\n"}
{"id": "1610.09005", "contents": "Title: Fast and Consistent Algorithm for the Latent Block Model Abstract: The latent block model is used to simultaneously rank the rows and columns of\na matrix to reveal a block structure. The algorithms used for estimation are\noften time consuming. However, recent work shows that the log-likelihood ratios\nare equivalent under the complete and observed (with unknown labels) models and\nthe groups posterior distribution to converge as the size of the data increases\nto a Dirac mass located at the actual groups configuration. Based on these\nobservations, the algorithm $Largest$ $Gaps$ is proposed in this paper to\nperform clustering using only the marginals of the matrix, when the number of\nblocks is very small with respect to the size of the whole matrix in the case\nof binary data. In addition, a model selection method is incorporated with a\nproof of its consistency. Thus, this paper shows that studying simplistic\nconfigurations (few blocks compared to the size of the matrix or very\ncontrasting blocks) with complex algorithms is useless since the marginals\nalready give very good parameter and classification estimates. \n\n"}
{"id": "1610.09028", "contents": "Title: Through the Haze: a Non-Convex Approach to Blind Gain Calibration for\n  Linear Random Sensing Models Abstract: Computational sensing strategies often suffer from calibration errors in the\nphysical implementation of their ideal sensing models. Such uncertainties are\ntypically addressed by using multiple, accurately chosen training signals to\nrecover the missing information on the sensing model, an approach that can be\nresource-consuming and cumbersome. Conversely, blind calibration does not\nemploy any training signal, but corresponds to a bilinear inverse problem whose\nalgorithmic solution is an open issue. We here address blind calibration as a\nnon-convex problem for linear random sensing models, in which we aim to recover\nan unknown signal from its projections on sub-Gaussian random vectors, each\nsubject to an unknown positive multiplicative factor (or gain). To solve this\noptimisation problem we resort to projected gradient descent starting from a\nsuitable, carefully chosen initialisation point. An analysis of this algorithm\nallows us to show that it converges to the exact solution provided a sample\ncomplexity requirement is met, i.e., relating convergence to the amount of\ninformation collected during the sensing process. Interestingly, we show that\nthis requirement grows linearly (up to log factors) in the number of unknowns\nof the problem. This sample complexity is found both in absence of prior\ninformation, as well as when subspace priors are available for both the signal\nand gains, allowing a further reduction of the number of observations required\nfor our recovery guarantees to hold. Moreover, in the presence of noise we show\nhow our descent algorithm yields a solution whose accuracy degrades gracefully\nwith the amount of noise affecting the measurements. Finally, we present some\nnumerical experiments in an imaging context, where our algorithm allows for a\nsimple solution to blind calibration of the gains in a sensor array. \n\n"}
{"id": "1610.09540", "contents": "Title: Solving Large-scale Systems of Random Quadratic Equations via Stochastic\n  Truncated Amplitude Flow Abstract: A novel approach termed \\emph{stochastic truncated amplitude flow} (STAF) is\ndeveloped to reconstruct an unknown $n$-dimensional real-/complex-valued signal\n$\\bm{x}$ from $m$ `phaseless' quadratic equations of the form\n$\\psi_i=|\\langle\\bm{a}_i,\\bm{x}\\rangle|$. This problem, also known as phase\nretrieval from magnitude-only information, is \\emph{NP-hard} in general.\nAdopting an amplitude-based nonconvex formulation, STAF leads to an iterative\nsolver comprising two stages: s1) Orthogonality-promoting initialization\nthrough a stochastic variance reduced gradient algorithm; and, s2) A series of\niterative refinements of the initialization using stochastic truncated gradient\niterations. Both stages involve a single equation per iteration, thus rendering\nSTAF a simple, scalable, and fast approach amenable to large-scale\nimplementations that is useful when $n$ is large. When $\\{\\bm{a}_i\\}_{i=1}^m$\nare independent Gaussian, STAF provably recovers exactly any\n$\\bm{x}\\in\\mathbb{R}^n$ exponentially fast based on order of $n$ quadratic\nequations. STAF is also robust in the presence of additive noise of bounded\nsupport. Simulated tests involving real Gaussian $\\{\\bm{a}_i\\}$ vectors\ndemonstrate that STAF empirically reconstructs any $\\bm{x}\\in\\mathbb{R}^n$\nexactly from about $2.3n$ magnitude-only measurements, outperforming\nstate-of-the-art approaches and narrowing the gap from the\ninformation-theoretic number of equations $m=2n-1$. Extensive experiments using\nsynthetic data and real images corroborate markedly improved performance of\nSTAF over existing alternatives. \n\n"}
{"id": "1610.09641", "contents": "Title: Auxiliary gradient-based sampling algorithms Abstract: We introduce a new family of MCMC samplers that combine auxiliary variables,\nGibbs sampling and Taylor expansions of the target density. Our approach\npermits the marginalisation over the auxiliary variables yielding marginal\nsamplers, or the augmentation of the auxiliary variables, yielding auxiliary\nsamplers. The well-known Metropolis-adjusted Langevin algorithm (MALA) and\npreconditioned Crank-Nicolson Langevin (pCNL) algorithm are shown to be special\ncases. We prove that marginal samplers are superior in terms of asymptotic\nvariance and demonstrate cases where they are slower in computing time compared\nto auxiliary samplers. In the context of latent Gaussian models we propose new\nauxiliary and marginal samplers whose implementation requires a single tuning\nparameter, which can be found automatically during the transient phase.\nExtensive experimentation shows that the increase in efficiency (measured as\neffective sample size per unit of computing time) relative to (optimised\nimplementations of) pCNL, elliptical slice sampling and MALA ranges from\n10-fold in binary classification problems to 25-fold in log-Gaussian Cox\nprocesses to 100-fold in Gaussian process regression, and it is on par with\nRiemann manifold Hamiltonian Monte Carlo in an example where the latter has the\nsame complexity as the aforementioned algorithms. We explain this remarkable\nimprovement in terms of the way alternative samplers try to approximate the\neigenvalues of the target. We introduce a novel MCMC sampling scheme for\nhyperparameter learning that builds upon the auxiliary samplers. The MATLAB\ncode for reproducing the experiments in the article is publicly available and a\nSupplement to this article contains additional experiments and implementation\ndetails. \n\n"}
{"id": "1610.09651", "contents": "Title: Generic uniqueness of the bias vector of finite stochastic games with\n  perfect information Abstract: Mean-payoff zero-sum stochastic games can be studied by means of a nonlinear\nspectral problem. When the state space is finite, the latter consists in\nfinding an eigenpair $(u,\\lambda)$ solution of $T(u)=\\lambda e + u$, where\n$T:\\mathbb{R}^n \\to \\mathbb{R}^n$ is the Shapley (or dynamic programming)\noperator, $\\lambda$ is a scalar, $e$ is the unit vector, and $u \\in\n\\mathbb{R}^n$. The scalar $\\lambda$ yields the mean payoff per time unit, and\nthe vector $u$, called the bias, allows one to determine optimal stationary\nstrategies. The existence of the eigenpair $(u,\\lambda)$ is generally related\nto ergodicity conditions. A basic issue is to understand for which classes of\ngames the bias vector is unique (up to an additive constant). In this paper, we\nconsider perfect-information zero-sum stochastic games with finite state and\naction spaces, thinking of the transition payments as variable parameters,\ntransition probabilities being fixed. We show that the bias vector, thought of\nas a function of the transition payments, is generically unique (up to an\nadditive constant). The proof uses techniques of max-plus (or tropical) algebra\nand nonlinear Perron-Frobenius theory. As an application of our results, we\nobtain a perturbation scheme allowing one to solve degenerate instances of\nstochastic games by policy iteration. \n\n"}
{"id": "1611.00328", "contents": "Title: Variational Inference via $\\chi$-Upper Bound Minimization Abstract: Variational inference (VI) is widely used as an efficient alternative to\nMarkov chain Monte Carlo. It posits a family of approximating distributions $q$\nand finds the closest member to the exact posterior $p$. Closeness is usually\nmeasured via a divergence $D(q || p)$ from $q$ to $p$. While successful, this\napproach also has problems. Notably, it typically leads to underestimation of\nthe posterior variance. In this paper we propose CHIVI, a black-box variational\ninference algorithm that minimizes $D_{\\chi}(p || q)$, the $\\chi$-divergence\nfrom $p$ to $q$. CHIVI minimizes an upper bound of the model evidence, which we\nterm the $\\chi$ upper bound (CUBO). Minimizing the CUBO leads to improved\nposterior uncertainty, and it can also be used with the classical VI lower\nbound (ELBO) to provide a sandwich estimate of the model evidence. We study\nCHIVI on three models: probit regression, Gaussian process classification, and\na Cox process model of basketball plays. When compared to expectation\npropagation and classical VI, CHIVI produces better error rates and more\naccurate estimates of posterior variance. \n\n"}
{"id": "1611.01626", "contents": "Title: Combining policy gradient and Q-learning Abstract: Policy gradient is an efficient technique for improving a policy in a\nreinforcement learning setting. However, vanilla online variants are on-policy\nonly and not able to take advantage of off-policy data. In this paper we\ndescribe a new technique that combines policy gradient with off-policy\nQ-learning, drawing experience from a replay buffer. This is motivated by\nmaking a connection between the fixed points of the regularized policy gradient\nalgorithm and the Q-values. This connection allows us to estimate the Q-values\nfrom the action preferences of the policy, to which we apply Q-learning\nupdates. We refer to the new technique as 'PGQL', for policy gradient and\nQ-learning. We also establish an equivalency between action-value fitting\ntechniques and actor-critic algorithms, showing that regularized policy\ngradient techniques can be interpreted as advantage function learning\nalgorithms. We conclude with some numerical examples that demonstrate improved\ndata efficiency and stability of PGQL. In particular, we tested PGQL on the\nfull suite of Atari games and achieved performance exceeding that of both\nasynchronous advantage actor-critic (A3C) and Q-learning. \n\n"}
{"id": "1611.02431", "contents": "Title: Distributed recovery of jointly sparse signals under communication\n  constraints Abstract: The problem of the distributed recovery of jointly sparse signals has\nattracted much attention recently. Let us assume that the nodes of a network\nobserve different sparse signals with common support; starting from linear,\ncompressed measurements, and exploiting network communication, each node aims\nat reconstructing the support and the non-zero values of its observed signal.\nIn the literature, distributed greedy algorithms have been proposed to tackle\nthis problem, among which the most reliable ones require a large amount of\ntransmitted data, which barely adapts to realistic network communication\nconstraints. In this work, we address the problem through a reweighted $\\ell_1$\nsoft thresholding technique, in which the threshold is iteratively tuned based\non the current estimate of the support. The proposed method adapts to\nconstrained networks, as it requires only local communication among neighbors,\nand the transmitted messages are indices from a finite set. We analytically\nprove the convergence of the proposed algorithm and we show that it outperforms\nthe state-of-the-art greedy methods in terms of balance between recovery\naccuracy and communication load. \n\n"}
{"id": "1611.04831", "contents": "Title: The Power of Normalization: Faster Evasion of Saddle Points Abstract: A commonly used heuristic in non-convex optimization is Normalized Gradient\nDescent (NGD) - a variant of gradient descent in which only the direction of\nthe gradient is taken into account and its magnitude ignored. We analyze this\nheuristic and show that with carefully chosen parameters and noise injection,\nthis method can provably evade saddle points. We establish the convergence of\nNGD to a local minimum, and demonstrate rates which improve upon the fastest\nknown first order algorithm due to Ge e al. (2015).\n  The effectiveness of our method is demonstrated via an application to the\nproblem of online tensor decomposition; a task for which saddle point evasion\nis known to result in convergence to global minima. \n\n"}
{"id": "1611.05673", "contents": "Title: Shape Optimization Using the Cut Finite Element Method Abstract: We present a cut finite element method for shape optimization in the case of\nlinear elasticity. The elastic domain is defined by a level-set function, and\nthe evolution of the domain is obtained by moving the level-set along a\nvelocity field using a transport equation. The velocity field is the largest\ndecreasing direction of the shape derivative that satisfies a certain\nregularity requirement and the computation of the shape derivative is based on\na volume formulation. Using the cut finite element method no re--meshing is\nrequired when updating the domain and we may also use higher order finite\nelement approximations. To obtain a stable method, stabilization terms are\nadded in the vicinity of the cut elements at the boundary, which provides\ncontrol of the variation of the solution in the vicinity of the boundary. We\nimplement and illustrate the performance of the method in the two--dimensional\ncase, considering both triangular and quadrilateral meshes as well as finite\nelement spaces of different order. \n\n"}
{"id": "1611.06626", "contents": "Title: On the notions of facets, weak facets, and extreme functions of the\n  Gomory-Johnson infinite group problem Abstract: We investigate three competing notions that generalize the notion of a facet\nof finite-dimensional polyhedra to the infinite-dimensional Gomory-Johnson\nmodel. These notions were known to coincide for continuous piecewise linear\nfunctions with rational breakpoints. We show that two of the notions, extreme\nfunctions and facets, coincide for the case of continuous piecewise linear\nfunctions, removing the hypothesis regarding rational breakpoints. We then\nseparate the three notions using discontinuous examples. \n\n"}
{"id": "1611.07056", "contents": "Title: The Recycling Gibbs Sampler for Efficient Learning Abstract: Monte Carlo methods are essential tools for Bayesian inference. Gibbs\nsampling is a well-known Markov chain Monte Carlo (MCMC) algorithm, extensively\nused in signal processing, machine learning, and statistics, employed to draw\nsamples from complicated high-dimensional posterior distributions. The key\npoint for the successful application of the Gibbs sampler is the ability to\ndraw efficiently samples from the full-conditional probability density\nfunctions. Since in the general case this is not possible, in order to speed up\nthe convergence of the chain, it is required to generate auxiliary samples\nwhose information is eventually disregarded. In this work, we show that these\nauxiliary samples can be recycled within the Gibbs estimators, improving their\nefficiency with no extra cost. This novel scheme arises naturally after\npointing out the relationship between the standard Gibbs sampler and the chain\nrule used for sampling purposes. Numerical simulations involving simple and\nreal inference problems confirm the excellent performance of the proposed\nscheme in terms of accuracy and computational efficiency. In particular we give\nempirical evidence of performance in a toy example, inference of Gaussian\nprocesses hyperparameters, and learning dependence graphs through regression. \n\n"}
{"id": "1611.07110", "contents": "Title: Implementation of Bilinear Hamiltonian Interactions between Linear\n  Quantum Stochastic Systems via Feedback Abstract: A number of recent works employ bilinear Hamiltonian interactions between\nLinear Quantum Stochastic Systems (LQSSs). Contrary to naturally occurring\nHamiltonian interactions between physical systems, such interactions must be\nengineered. In this work, we propose a simple model for the implementation of\nan arbitrary bilinear interaction between two given LQSSs via a feedback\ninterconnection. \n\n"}
{"id": "1611.07609", "contents": "Title: Adaptive Accelerated Gradient Converging Methods under Holderian Error\n  Bound Condition Abstract: Recent studies have shown that proximal gradient (PG) method and accelerated\ngradient method (APG) with restarting can enjoy a linear convergence under a\nweaker condition than strong convexity, namely a quadratic growth condition\n(QGC). However, the faster convergence of restarting APG method relies on the\npotentially unknown constant in QGC to appropriately restart APG, which\nrestricts its applicability. We address this issue by developing a novel\nadaptive gradient converging methods, i.e., leveraging the magnitude of\nproximal gradient as a criterion for restart and termination. Our analysis\nextends to a much more general condition beyond the QGC, namely the\nH\\\"{o}lderian error bound (HEB) condition. {\\it The key technique} for our\ndevelopment is a novel synthesis of {\\it adaptive regularization and a\nconditional restarting scheme}, which extends previous work focusing on\nstrongly convex problems to a much broader family of problems. Furthermore, we\ndemonstrate that our results have important implication and applications in\nmachine learning: (i) if the objective function is coercive and semi-algebraic,\nPG's convergence speed is essentially $o(\\frac{1}{t})$, where $t$ is the total\nnumber of iterations; (ii) if the objective function consists of an $\\ell_1$,\n$\\ell_\\infty$, $\\ell_{1,\\infty}$, or huber norm regularization and a convex\nsmooth piecewise quadratic loss (e.g., squares loss, squared hinge loss and\nhuber loss), the proposed algorithm is parameter-free and enjoys a {\\it faster\nlinear convergence} than PG without any other assumptions (e.g., restricted\neigen-value condition). It is notable that our linear convergence results for\nthe aforementioned problems are global instead of local. To the best of our\nknowledge, these improved results are the first shown in this work. \n\n"}
{"id": "1611.09252", "contents": "Title: Fast Mixing Random Walks and Regularity of Incompressible Vector Fields Abstract: We show sufficient conditions under which the \\textsc{BallWalk} algorithm\nmixes fast in a bounded connected subset of $\\Real^n$. In particular, we show\nfast mixing if the space is the transformation of a convex space under a smooth\nincompressible flow. Construction of such smooth flows is in turn reduced to\nthe study of the regularity of the solution of the Dirichlet problem for\nLaplace's equation. \n\n"}
{"id": "1612.00156", "contents": "Title: Global and fixed-terminal cuts in digraphs Abstract: The computational complexity of multicut-like problems may vary significantly\ndepending on whether the terminals are fixed or not. In this work we present a\ncomprehensive study of this phenomenon in two types of cut problems in directed\ngraphs: double cut and bicut.\n  1. The fixed-terminal edge-weighted double cut is known to be solvable\nefficiently. We show a tight approximability factor of $2$ for the\nfixed-terminal node-weighted double cut. We show that the global node-weighted\ndouble cut cannot be approximated to a factor smaller than $3/2$ under the\nUnique Games Conjecture (UGC).\n  2. The fixed-terminal edge-weighted bicut is known to have a tight\napproximability factor of $2$. We show that the global edge-weighted bicut is\napproximable to a factor strictly better than $2$, and that the global\nnode-weighted bicut cannot be approximated to a factor smaller than $3/2$ under\nUGC.\n  3. In relation to these investigations, we also prove two results on\nundirected graphs which are of independent interest. First, we show\nNP-completeness and a tight inapproximability bound of $4/3$ for the\nnode-weighted $3$-cut problem. Second, we show that for constant $k$, there\nexists an efficient algorithm to solve the minimum $\\{s,t\\}$-separating $k$-cut\nproblem.\n  Our techniques for the algorithms are combinatorial, based on LPs and based\non enumeration of approximate min-cuts. Our hardness results are based on\ncombinatorial reductions and integrality gap instances. \n\n"}
{"id": "1612.00414", "contents": "Title: Distributed Nash Equilibrium Seeking via the Alternating Direction\n  Method of Multipliers Abstract: In this paper, the problem of finding a Nash equilibrium of a multi-player\ngame is considered. The players are only aware of their own cost functions as\nwell as the action space of all players. We develop a relatively fast algorithm\nwithin the framework of inexact-ADMM. It requires a communication graph for the\ninformation exchange between the players as well as a few mild assumptions on\ncost functions. The convergence proof of the algorithm to a Nash equilibrium of\nthe game is then provided. Moreover, the convergence rate is investigated via\nsimulations. \n\n"}
{"id": "1612.02803", "contents": "Title: The Physical Systems Behind Optimization Algorithms Abstract: We use differential equations based approaches to provide some {\\it\n\\textbf{physics}} insights into analyzing the dynamics of popular optimization\nalgorithms in machine learning. In particular, we study gradient descent,\nproximal gradient descent, coordinate gradient descent, proximal coordinate\ngradient, and Newton's methods as well as their Nesterov's accelerated variants\nin a unified framework motivated by a natural connection of optimization\nalgorithms to physical systems. Our analysis is applicable to more general\nalgorithms and optimization problems {\\it \\textbf{beyond}} convexity and strong\nconvexity, e.g. Polyak-\\L ojasiewicz and error bound conditions (possibly\nnonconvex). \n\n"}
{"id": "1612.03054", "contents": "Title: DERGMs: Degeneracy-restricted exponential random graph models Abstract: Exponential random graph models, or ERGMs, are a flexible and general class\nof models for modeling dependent data. While the early literature has shown\nthem to be powerful in capturing many network features of interest, recent work\nhighlights difficulties related to the models' ill behavior, such as most of\nthe probability mass being concentrated on a very small subset of the parameter\nspace. This behavior limits both the applicability of an ERGM as a model for\nreal data and inference and parameter estimation via the usual Markov chain\nMonte Carlo algorithms.\n  To address this problem, we propose a new exponential family of models for\nrandom graphs that build on the standard ERGM framework. Specifically, we solve\nthe problem of computational intractability and `degenerate' model behavior by\nan interpretable support restriction. We introduce a new parameter based on the\ngraph-theoretic notion of degeneracy, a measure of sparsity whose value is\ncommonly low in real-worlds networks. The new model family is supported on the\nsample space of graphs with bounded degeneracy and is called\ndegeneracy-restricted ERGMs, or DERGMs for short. Since DERGMs generalize ERGMs\n-- the latter is obtained from the former by setting the degeneracy parameter\nto be maximal -- they inherit good theoretical properties, while at the same\ntime place their mass more uniformly over realistic graphs.\n  The support restriction allows the use of new (and fast) Monte Carlo methods\nfor inference, thus making the models scalable and computationally tractable.\nWe study various theoretical properties of DERGMs and illustrate how the\nsupport restriction improves the model behavior. We also present a fast Monte\nCarlo algorithm for parameter estimation that avoids many issues faced by\nMarkov Chain Monte Carlo algorithms used for inference in ERGMs. \n\n"}
{"id": "1612.03225", "contents": "Title: Optimal Generalized Decision Trees via Integer Programming Abstract: Decision trees have been a very popular class of predictive models for\ndecades due to their interpretability and good performance on categorical\nfeatures. However, they are not always robust and tend to overfit the data.\nAdditionally, if allowed to grow large, they lose interpretability. In this\npaper, we present a mixed integer programming formulation to construct optimal\ndecision trees of a prespecified size. We take the special structure of\ncategorical features into account and allow combinatorial decisions (based on\nsubsets of values of features) at each node. Our approach can also handle\nnumerical features via thresholding. We show that very good accuracy can be\nachieved with small trees using moderately-sized training sets. The\noptimization problems we solve are tractable with modern solvers. \n\n"}
{"id": "1612.04093", "contents": "Title: Modified Cholesky Riemann Manifold Hamiltonian Monte Carlo: Exploiting\n  Sparsity for Fast Sampling of High-dimensional Targets Abstract: Riemann manifold Hamiltonian Monte Carlo (RMHMC) has the potential to produce\nhigh-quality Markov chain Monte Carlo-output even for very challenging target\ndistributions. To this end, a symmetric positive definite scaling matrix for\nRMHMC, which derives, via a modified Cholesky factorization, from the\npotentially indefinite negative Hessian of the target log-density is proposed.\nThe methodology is able to exploit the sparsity of the Hessian, stemming from\nconditional independence modeling assumptions, and thus admit fast\nimplementation of RMHMC even for high-dimensional target distributions.\nMoreover, the methodology can exploit log-concave conditional target densities,\noften encountered in Bayesian hierarchical models, for faster sampling and more\nstraight forward tuning. The proposed methodology is compared to alternatives\nfor some challenging targets, and is illustrated by applying a state space\nmodel to real data. \n\n"}
{"id": "1612.04694", "contents": "Title: Stochastic Second-Order Optimization via von Neumann Series Abstract: A stochastic iterative algorithm approximating second-order information using\nvon Neumann series is discussed. We present convergence guarantees for\nstrongly-convex and smooth functions. Our analysis is much simpler in contrast\nto a similar algorithm and its analysis, LISSA. The algorithm is primarily\nsuitable for training large scale linear models, where the number of data\npoints is very large. Two novel analyses, one showing space independent linear\nconvergence, and one showing conditional quadratic convergence are discussed.\nIn numerical experiments, the behavior of the error is similar to the\nsecond-order algorithm L-BFGS, and improves the performance of LISSA for\nquadratic objective function. \n\n"}
{"id": "1612.05356", "contents": "Title: Projected Semi-Stochastic Gradient Descent Method with Mini-Batch Scheme\n  under Weak Strong Convexity Assumption Abstract: We propose a projected semi-stochastic gradient descent method with\nmini-batch for improving both the theoretical complexity and practical\nperformance of the general stochastic gradient descent method (SGD). We are\nable to prove linear convergence under weak strong convexity assumption. This\nrequires no strong convexity assumption for minimizing the sum of smooth convex\nfunctions subject to a compact polyhedral set, which remains popular across\nmachine learning community. Our PS2GD preserves the low-cost per iteration and\nhigh optimization accuracy via stochastic gradient variance-reduced technique,\nand admits a simple parallel implementation with mini-batches. Moreover, PS2GD\nis also applicable to dual problem of SVM with hinge loss. \n\n"}
{"id": "1612.05612", "contents": "Title: Asymptotic Optimality in Stochastic Optimization Abstract: We study local complexity measures for stochastic convex optimization\nproblems, providing a local minimax theory analogous to that of H\\'{a}jek and\nLe Cam for classical statistical problems. We give complementary optimality\nresults, developing fully online methods that adaptively achieve optimal\nconvergence guarantees. Our results provide function-specific lower bounds and\nconvergence results that make precise a correspondence between statistical\ndifficulty and the geometric notion of tilt-stability from optimization. As\npart of this development, we show how variants of Nesterov's dual averaging---a\nstochastic gradient-based procedure---guarantee finite time identification of\nconstraints in optimization problems, while stochastic gradient procedures\nfail. Additionally, we highlight a gap between problems with linear and\nnonlinear constraints: standard stochastic-gradient-based procedures are\nsuboptimal even for the simplest nonlinear constraints, necessitating the\ndevelopment of asymptotically optimal Riemannian stochastic gradient methods. \n\n"}
{"id": "1612.05812", "contents": "Title: Decentralized Robust Inverter-based Control in Power Systems Abstract: This paper develops a novel framework for power system stability analysis,\nthat allows for the decentralized design of inverter based controllers. The\nmethod requires that each individual inverter satisfies a standard $H^\\infty$\ndesign requirement. Critically each requirement depends only on the dynamics of\nthe components and inverters at each individual bus and the aggregate\nsusceptance of the transmission lines connected to it. The method is both\nrobust to network and delay uncertainties, as well as heterogeneous network\ncomponents, and when no network information is available it reduces to the\nstandard decentralized passivity sufficient condition for stability. We\nillustrate the novelty and strength of our approach by studying the design of\ninverter-based control laws in the presence of delays. \n\n"}
{"id": "1612.06265", "contents": "Title: A proximal difference-of-convex algorithm with extrapolation Abstract: We consider a class of difference-of-convex (DC) optimization problems whose\nobjective is level-bounded and is the sum of a smooth convex function with\nLipschitz gradient, a proper closed convex function and a continuous concave\nfunction. While this kind of problems can be solved by the classical\ndifference-of-convex algorithm (DCA) [26], the difficulty of the subproblems of\nthis algorithm depends heavily on the choice of DC decomposition. Simpler\nsubproblems can be obtained by using a specific DC decomposition described in\n[27]. This decomposition has been proposed in numerous work such as [18], and\nwe refer to the resulting DCA as the proximal DCA. Although the subproblems are\nsimpler, the proximal DCA is the same as the proximal gradient algorithm when\nthe concave part of the objective is void, and hence is potentially slow in\npractice. In this paper, motivated by the extrapolation techniques for\naccelerating the proximal gradient algorithm in the convex settings, we\nconsider a proximal difference-of-convex algorithm with extrapolation to\npossibly accelerate the proximal DCA. We show that any cluster point of the\nsequence generated by our algorithm is a stationary point of the DC\noptimization problem for a fairly general choice of extrapolation parameters:\nin particular, the parameters can be chosen as in FISTA with fixed restart\n[15]. In addition, by assuming the Kurdyka-{\\L}ojasiewicz property of the\nobjective and the differentiability of the concave part, we establish global\nconvergence of the sequence generated by our algorithm and analyze its\nconvergence rate. Our numerical experiments on two difference-of-convex\nregularized least squares models show that our algorithm usually outperforms\nthe proximal DCA and the general iterative shrinkage and thresholding algorithm\nproposed in [17]. \n\n"}
{"id": "1612.06724", "contents": "Title: Convergence rates for regularization functionals with polyconvex\n  integrands Abstract: Convergence rates results for variational regularization methods typically\nassume the regularization functional to be convex. While this assumption is\nnatural for scalar-valued functions, it can be unnecessarily strong for\nvector-valued ones. In this paper we focus on regularization functionals with\npolyconvex integrands. Even though such functionals are nonconvex in general,\nit is possible to derive linear convergence rates with respect to a generalized\nBregman distance, an idea introduced by Grasmair in 2010. As a case example we\nconsider the image registration problem. \n\n"}
{"id": "1612.07002", "contents": "Title: A subset multicanonical Monte Carlo method for simulating rare failure\n  events Abstract: Estimating failure probabilities of engineering systems is an important\nproblem in many engineering fields. In this work we consider such problems\nwhere the failure probability is extremely small (e.g $\\leq10^{-10}$). In this\ncase, standard Monte Carlo methods are not feasible due to the extraordinarily\nlarge number of samples required. To address these problems, we propose an\nalgorithm that combines the main ideas of two very powerful failure probability\nestimation approaches: the subset simulation (SS) and the multicanonical Monte\nCarlo (MMC) methods. Unlike the standard MMC which samples in the entire domain\nof the input parameter in each iteration, the proposed subset MMC algorithm\nadaptively performs MMC simulations in a subset of the state space and thus\nimproves the sampling efficiency. With numerical examples we demonstrate that\nthe proposed method is significantly more efficient than both of the SS and the\nMMC methods. Moreover, the proposed algorithm can reconstruct the complete\ndistribution function of the parameter of interest and thus can provide more\ninformation than just the failure probabilities of the systems. \n\n"}
{"id": "1612.07471", "contents": "Title: Efficient Bayesian computation by proximal Markov chain Monte Carlo:\n  when Langevin meets Moreau Abstract: Modern imaging methods rely strongly on Bayesian inference techniques to\nsolve challenging imaging problems. Currently, the predominant Bayesian\ncomputation approach is convex optimisation, which scales very efficiently to\nhigh dimensional image models and delivers accurate point estimation results.\nHowever, in order to perform more complex analyses, for example image\nuncertainty quantification or model selection, it is necessary to use more\ncomputationally intensive Bayesian computation techniques such as Markov chain\nMonte Carlo methods. This paper presents a new and highly efficient Markov\nchain Monte Carlo methodology to perform Bayesian computation for high\ndimensional models that are log-concave and non-smooth, a class of models that\nis central in imaging sciences. The methodology is based on a regularised\nunadjusted Langevin algorithm that exploits tools from convex analysis, namely\nMoreau-Yoshida envelopes and proximal operators, to construct Markov chains\nwith favourable convergence properties. In addition to scaling efficiently to\nhigh dimensions, the method is straightforward to apply to models that are\ncurrently solved by using proximal optimisation algorithms. We provide a\ndetailed theoretical analysis of the proposed methodology, including asymptotic\nand non-asymptotic convergence results with easily verifiable conditions, and\nexplicit bounds on the convergence rates. The proposed methodology is\ndemonstrated with four experiments related to image deconvolution and\ntomographic reconstruction with total-variation and $\\ell_1$ priors, where we\nconduct a range of challenging Bayesian analyses related to uncertainty\nquantification, hypothesis testing, and model selection in the absence of\nground truth. \n\n"}
{"id": "1612.08321", "contents": "Title: Generalized Optimal Matching Methods for Causal Inference Abstract: We develop an encompassing framework for matching, covariate balancing, and\ndoubly-robust methods for causal inference from observational data called\ngeneralized optimal matching (GOM). The framework is given by generalizing a\nnew functional-analytical formulation of optimal matching, giving rise to the\nclass of GOM methods, for which we provide a single unified theory to analyze\ntractability, consistency, and efficiency. Many commonly used existing methods\nare included in GOM and, using their GOM interpretation, can be extended to\noptimally and automatically trade off balance for variance and outperform their\nstandard counterparts. As a subclass, GOM gives rise to kernel optimal matching\n(KOM), which, as supported by new theoretical and empirical results, is notable\nfor combining many of the positive properties of other methods in one. KOM,\nwhich is solved as a linearly-constrained convex-quadratic optimization\nproblem, inherits both the interpretability and model-free consistency of\nmatching but can also achieve the $\\sqrt{n}$-consistency of well-specified\nregression and the efficiency and robustness of doubly robust methods. In\nsettings of limited overlap, KOM enables a very transparent method for interval\nestimation for partial identification and robust coverage. We demonstrate these\nbenefits in examples with both synthetic and real data \n\n"}
{"id": "1612.09296", "contents": "Title: Symmetry, Saddle Points, and Global Optimization Landscape of Nonconvex\n  Matrix Factorization Abstract: We propose a general theory for studying the \\xl{landscape} of nonconvex\n\\xl{optimization} with underlying symmetric structures \\tz{for a class of\nmachine learning problems (e.g., low-rank matrix factorization, phase\nretrieval, and deep linear neural networks)}. In specific, we characterize the\nlocations of stationary points and the null space of Hessian matrices \\xl{of\nthe objective function} via the lens of invariant groups\\removed{for associated\noptimization problems, including low-rank matrix factorization, phase\nretrieval, and deep linear neural networks}. As a major motivating example, we\napply the proposed general theory to characterize the global \\xl{landscape} of\nthe \\xl{nonconvex optimization in} low-rank matrix factorization problem. In\nparticular, we illustrate how the rotational symmetry group gives rise to\ninfinitely many nonisolated strict saddle points and equivalent global minima\nof the objective function. By explicitly identifying all stationary points, we\ndivide the entire parameter space into three regions: ($\\cR_1$) the region\ncontaining the neighborhoods of all strict saddle points, where the objective\nhas negative curvatures; ($\\cR_2$) the region containing neighborhoods of all\nglobal minima, where the objective enjoys strong convexity along certain\ndirections; and ($\\cR_3$) the complement of the above regions, where the\ngradient has sufficiently large magnitudes. We further extend our result to the\nmatrix sensing problem. Such global landscape implies strong global convergence\nguarantees for popular iterative algorithms with arbitrary initial solutions. \n\n"}
{"id": "1701.00021", "contents": "Title: Distributed Finite Time Termination of Consensus in the Presence of\n  Delays Abstract: Linear consensus iterations guarantee asymptotic convergence, thereby,\nlimiting their applicability in applications where consensus value needs to be\nused in real time to perform a system level task. It also leads to wastage of\npower and communication resources. In this article, an algorithm is proposed\nwhich enables each node to detect in a distributed manner and in finite number\nof iterations, when every agent in the network is within a user specified\nthreshold of the consensus value (approximate consensus) and hence terminate\nfurther communications and computations associated with consensus iterations.\nThis article develops a distributed algorithm for achieving this approximate\nconsensus in presence of random time-varying bounded communication delays.\nMoreover, the article instantiates the algorithm developed to distributively\ndetermine the average of the initial values held by agents in finite number of\niterations. Specifically, this algorithm relies on distributively determining\nthe maximum and minimum of values held by the agents. The approach presented\nhere offers several advantages, including reduced computational complexity, and\nhence, is suited for hardware implementation. An experimental test bed of\nRaspberry-Pi agents that communicate wirelessly over neighborhoods is employed\nas a platform to demonstrate the effectiveness of the developed algorithm. \n\n"}
{"id": "1701.00857", "contents": "Title: Bayesian Computation for Log-Gaussian Cox Processes--A Comparative\n  Analysis of Methods Abstract: The Log-Gaussian Cox Process is a commonly used model for the analysis of\nspatial point patterns. Fitting this model is difficult because of its\ndoubly-stochastic property, i.e., it is an hierarchical combination of a\nPoisson process at the first level and a Gaussian Process at the second level.\nDifferent methods have been proposed to estimate such a process, including\ntraditional likelihood-based approaches as well as Bayesian methods. We focus\nhere on Bayesian methods and several approaches that have been considered for\nmodel fitting within this framework, including Hamiltonian Monte Carlo, the\nIntegrated nested Laplace approximation, and Variational Bayes. We consider\nthese approaches and make comparisons with respect to statistical and\ncomputational efficiency. These comparisons are made through several\nsimulations studies as well as through applications examining both ecological\ndata and neuroimaging data. \n\n"}
{"id": "1701.01207", "contents": "Title: Learning Semidefinite Regularizers Abstract: Regularization techniques are widely employed in optimization-based\napproaches for solving ill-posed inverse problems in data analysis and\nscientific computing. These methods are based on augmenting the objective with\na penalty function, which is specified based on prior domain-specific expertise\nto induce a desired structure in the solution. We consider the problem of\nlearning suitable regularization functions from data in settings in which\nprecise domain knowledge is not directly available. Previous work under the\ntitle of `dictionary learning' or `sparse coding' may be viewed as learning a\nregularization function that can be computed via linear programming. We\ndescribe generalizations of these methods to learn regularizers that can be\ncomputed and optimized via semidefinite programming. Our framework for learning\nsuch semidefinite regularizers is based on obtaining structured factorizations\nof data matrices, and our algorithmic approach for computing these\nfactorizations combines recent techniques for rank minimization problems along\nwith an operator analog of Sinkhorn scaling. Under suitable conditions on the\ninput data, our algorithm provides a locally linearly convergent method for\nidentifying the correct regularizer that promotes the type of structure\ncontained in the data. Our analysis is based on the stability properties of\nOperator Sinkhorn scaling and their relation to geometric aspects of\ndeterminantal varieties (in particular tangent spaces with respect to these\nvarieties). The regularizers obtained using our framework can be employed\neffectively in semidefinite programming relaxations for solving inverse\nproblems. \n\n"}
{"id": "1701.01672", "contents": "Title: Detecting changes in slope with an $L_0$ penalty Abstract: Whilst there are many approaches to detecting changes in mean for a\nunivariate time-series, the problem of detecting multiple changes in slope has\ncomparatively been ignored. Part of the reason for this is that detecting\nchanges in slope is much more challenging. For example, simple binary\nsegmentation procedures do not work for this problem, whilst efficient dynamic\nprogramming methods that work well for the change in mean problem cannot be\ndirectly used for detecting changes in slope. We present a novel dynamic\nprogramming approach, CPOP, for finding the \"best\" continuous piecewise-linear\nfit to data. We define best based on a criterion that measures fit to data\nusing the residual sum of squares, but penalises complexity based on an $L_0$\npenalty on changes in slope. We show that using such a criterion is more\nreliable at estimating changepoint locations than approaches that penalise\ncomplexity using an $L_1$ penalty. Empirically CPOP has good computational\nproperties, and can analyse a time-series with over 10,000 observations and\nover 100 changes in a few minutes. Our method is used to analyse data on the\nmotion of bacteria, and provides fits to the data that both have substantially\nsmaller residual sum of squares and are more parsimonious than two competing\napproaches. \n\n"}
{"id": "1701.01722", "contents": "Title: Follow the Compressed Leader: Faster Online Learning of Eigenvectors and\n  Faster MMWU Abstract: The online problem of computing the top eigenvector is fundamental to machine\nlearning. In both adversarial and stochastic settings, previous results (such\nas matrix multiplicative weight update, follow the regularized leader, follow\nthe compressed leader, block power method) either achieve optimal regret but\nrun slow, or run fast at the expense of loosing a $\\sqrt{d}$ factor in total\nregret where $d$ is the matrix dimension.\n  We propose a $\\textit{follow-the-compressed-leader (FTCL)}$ framework which\nachieves optimal regret without sacrificing the running time. Our idea is to\n\"compress\" the matrix strategy to dimension 3 in the adversarial setting, or\ndimension 1 in the stochastic setting. These respectively resolve two open\nquestions regarding the design of optimal and efficient algorithms for the\nonline eigenvector problem. \n\n"}
{"id": "1701.01801", "contents": "Title: Stochastic Control of Memory Mean-Field Processes Abstract: By a memory mean-field process we mean the solution $X(\\cdot)$ of a\nstochastic mean-field equation involving not just the current state $X(t)$ and\nits law $\\mathcal{L}(X(t))$ at time $t$, but also the state values $X(s)$ and\nits law $\\mathcal{L}(X(s))$ at some previous times $s<t$. Our purpose is to\nstudy stochastic control problems of memory mean-field processes.\n  - We consider the space $\\mathcal{M}$ of measures on $\\mathbb{R}$ with the\nnorm $|| \\cdot||_{\\mathcal{M}}$ introduced by Agram and {\\O}ksendal in\n\\cite{AO1}, and prove the existence and uniqueness of solutions of memory\nmean-field stochastic functional differential equations.\n  - We prove two stochastic maximum principles, one sufficient (a verification\ntheorem) and one necessary, both under partial information. The corresponding\nequations for the adjoint variables are a pair of \\emph{(time-) advanced\nbackward stochastic differential equations}, one of them with values in the\nspace of bounded linear functionals on path segment spaces.\n  - As an application of our methods, we solve a memory mean-variance problem\nas well as a linear-quadratic problem of a memory process. \n\n"}
{"id": "1701.05986", "contents": "Title: Distributed Random-Fixed Projected Algorithm for Constrained\n  Optimization Over Digraphs Abstract: This paper is concerned with a constrained optimization problem over a\ndirected graph (digraph) of nodes, in which the cost function is a sum of local\nobjectives, and each node only knows its local objective and constraints. To\ncollaboratively solve the optimization, most of the existing works require the\ninteraction graph to be balanced or \"doubly-stochastic\", which is quite\nrestrictive and not necessary as shown in this paper. We focus on an epigraph\nform of the original optimization to resolve the \"unbalanced\" problem, and\ndesign a novel two-step recursive algorithm with a simple structure. Under\nstrongly connected digraphs, we prove that each node asymptotically converges\nto some common optimal solution. Finally, simulations are performed to\nillustrate the effectiveness of the proposed algorithms. \n\n"}
{"id": "1701.08498", "contents": "Title: Efficient DC Algorithm for Constrained Sparse Optimization Abstract: We address the minimization of a smooth objective function under an\n$\\ell_0$-constraint and simple convex constraints. When the problem has no\nconstraints except the $\\ell_0$-constraint, some efficient algorithms are\navailable; for example, Proximal DC (Difference of Convex functions) Algorithm\n(PDCA) repeatedly evaluates closed-form solutions of convex subproblems,\nleading to a stationary point of the $\\ell_0$-constrained problem. However,\nwhen the problem has additional convex constraints, they become inefficient\nbecause it is difficult to obtain closed-form solutions of the associated\nsubproblems. In this paper, we reformulate the problem by employing a new DC\nrepresentation of the $\\ell_0$-constraint, so that PDCA can retain the\nefficiency by reducing its subproblems to the projection operation onto a\nconvex set. Moreover, inspired by the Nesterov's acceleration technique for\nproximal methods, we propose the Accelerated PDCA (APDCA), which attains the\noptimal convergence rate if applied to convex programs, and performs well in\nnumerical experiments. \n\n"}
{"id": "1702.00204", "contents": "Title: Bayesian model selection for the latent position cluster model for\n  Social Networks Abstract: The latent position cluster model is a popular model for the statistical\nanalysis of network data. This model assumes that there is an underlying latent\nspace in which the actors follow a finite mixture distribution. Moreover,\nactors which are close in this latent space are more likely to be tied by an\nedge. This is an appealing approach since it allows the model to cluster actors\nwhich consequently provides the practitioner with useful qualitative\ninformation. However, exploring the uncertainty in the number of underlying\nlatent components in the mixture distribution is a complex task. The current\nstate-of-the-art is to use an approximate form of BIC for this purpose, where\nan approximation of the log-likelihood is used instead of the true\nlog-likelihood which is unavailable. The main contribution of this paper is to\nshow that through the use of conjugate prior distributions it is possible to\nanalytically integrate out almost all of the model parameters, leaving a\nposterior distribution which depends on the allocation vector of the mixture\nmodel. This enables posterior inference over the number of components in the\nlatent mixture distribution without using trans- dimensional MCMC algorithms\nsuch as reversible jump MCMC. Our approach is compared with the\nstate-of-the-art latentnet (Krivitsky & Handcock 2015) and VBLPCM\n(Salter-Townshend & Murphy 2013) packages. \n\n"}
{"id": "1702.00763", "contents": "Title: Natasha: Faster Non-Convex Stochastic Optimization Via Strongly\n  Non-Convex Parameter Abstract: Given a nonconvex function that is an average of $n$ smooth functions, we\ndesign stochastic first-order methods to find its approximate stationary\npoints. The convergence of our new methods depends on the smallest (negative)\neigenvalue $-\\sigma$ of the Hessian, a parameter that describes how nonconvex\nthe function is.\n  Our methods outperform known results for a range of parameter $\\sigma$, and\ncan be used to find approximate local minima. Our result implies an interesting\ndichotomy: there exists a threshold $\\sigma_0$ so that the currently fastest\nmethods for $\\sigma>\\sigma_0$ and for $\\sigma<\\sigma_0$ have different\nbehaviors: the former scales with $n^{2/3}$ and the latter scales with\n$n^{3/4}$. \n\n"}
{"id": "1702.00841", "contents": "Title: Distributed Optimization Using the Primal-Dual Method of Multipliers Abstract: In this paper, we propose the primal-dual method of multipliers (PDMM) for\ndistributed optimization over a graph. In particular, we optimize a sum of\nconvex functions defined over a graph, where every edge in the graph carries a\nlinear equality constraint. In designing the new algorithm, an augmented\nprimal-dual Lagrangian function is constructed which smoothly captures the\ngraph topology. It is shown that a saddle point of the constructed function\nprovides an optimal solution of the original problem. Further under both the\nsynchronous and asynchronous updating schemes, PDMM has the convergence rate of\nO(1/K) (where K denotes the iteration index) for general closed, proper and\nconvex functions. Other properties of PDMM such as convergence speeds versus\ndifferent parameter- settings and resilience to transmission failure are also\ninvestigated through the experiments of distributed averaging. \n\n"}
{"id": "1702.01903", "contents": "Title: Robust Stability of Optimization-based State Estimation Abstract: Optimization-based state estimation is useful for nonlinear or constrained\ndynamic systems for which few general methods with established properties are\navailable. The two fundamental forms are moving horizon estimation (MHE) which\nuses the nearest measurements within a moving time horizon, and its theoretical\nideal, full information estimation (FIE) which uses all measurements up to the\ntime of estimation. Despite extensive studies, the stability analyses of FIE\nand MHE for discrete-time nonlinear systems with bounded process and\nmeasurement disturbances, remain an open challenge. This work aims to provide a\nsystematic solution for the challenge. First, we prove that FIE is robustly\nglobally asymptotically stable (RGAS) if the cost function admits a property\nmimicking the incremental input/output-to-state stability (i-IOSS) of the\nsystem and has a sufficient sensitivity to the uncertainty in the initial\nstate. Second, we establish an explicit link from the RGAS of FIE to that of\nMHE, and use it to show that MHE is RGAS under enhanced conditions if the\nmoving horizon is long enough to suppress the propagation of uncertainties. The\ntheoretical results imply flexible MHE designs with assured robust stability\nfor a broad class of i-IOSS systems. Numerical experiments on linear and\nnonlinear systems are used to illustrate the designs and support the findings. \n\n"}
{"id": "1702.02750", "contents": "Title: Optimal control on distributions Abstract: This paper studies (single-time and multitime) optimal control problems on a\nnonholonomic manifold (described either by the kernel of a Gibbs-Pfaff form or\nby the span of appropriate vector fields). For both descriptions we analyse:\ninfinitesimal deformations and adjointness, single-time optimal control\nproblems, multitime optimal control problem of maximizing a multiple integral\nfunctional, multitime optimal control problem of maximizing a curvilinear\nintegral functional, Curvilinear functionals depending on curves, optimization\nof mechanical work on Riemannian manifolds. Also we prove that a nonholonomic\nsystem can be always controlled by uni-temporal or bi-temporal bang-bang\ncontrols. \n\n"}
{"id": "1702.03146", "contents": "Title: Analysis of a nonlinear importance sampling scheme for Bayesian\n  parameter estimation in state-space models Abstract: The Bayesian estimation of the unknown parameters of state-space (dynamical)\nsystems has received considerable attention over the past decade, with a\nhandful of powerful algorithms being introduced. In this paper we tackle the\ntheoretical analysis of the recently proposed {\\it nonlinear} population Monte\nCarlo (NPMC). This is an iterative importance sampling scheme whose key\nfeatures, compared to conventional importance samplers, are (i) the approximate\ncomputation of the importance weights (IWs) assigned to the Monte Carlo samples\nand (ii) the nonlinear transformation of these IWs in order to prevent the\ndegeneracy problem that flaws the performance of conventional importance\nsamplers. The contribution of the present paper is a rigorous proof of\nconvergence of the nonlinear IS (NIS) scheme as the number of Monte Carlo\nsamples, $M$, increases. Our analysis reveals that the NIS approximation errors\nconverge to 0 almost surely and with the optimal Monte Carlo rate of\n$M^{-\\frac{1}{2}}$. Moreover, we prove that this is achieved even when the mean\nestimation error of the IWs remains constant, a property that has been termed\n{\\it exact approximation} in the Markov chain Monte Carlo literature. We\nillustrate these theoretical results by means of a computer simulation example\ninvolving the estimation of the parameters of a state-space model typically\nused for target tracking. \n\n"}
{"id": "1702.03908", "contents": "Title: A convex formulation of traffic dynamics on transportation networks Abstract: This article proposes a numerical scheme for computing the evolution of\nvehicular traffic on a road network over a finite time horizon. The traffic\ndynamics on each link is modeled by the Hamilton-Jacobi (HJ) partial\ndifferential equation (PDE), which is an equivalent form of the\nLighthill-Whitham-Richards PDE. The main contribution of this article is the\nconstruction of a single convex optimization program which computes the traffic\nflow at a junction over a finite time horizon and decouples the PDEs on\nconnecting links. Compared to discretization schemes which require the\ncomputation of all traffic states on a time-space grid, the proposed convex\noptimization approach computes the boundary flows at the junction using only\nthe initial condition on links and the boundary conditions of the network. The\ncomputed boundary flows at the junction specify the boundary condition for the\nHJ PDE on connecting links, which then can be separately solved using an\nexisting semi-explicit scheme for single link HJ PDE. As demonstrated in a\nnumerical example of ramp metering control, the proposed convex optimization\napproach also provides a natural framework for optimal traffic control\napplications. \n\n"}
{"id": "1702.05327", "contents": "Title: Solving Equations of Random Convex Functions via Anchored Regression Abstract: We consider the question of estimating a solution to a system of equations\nthat involve convex nonlinearities, a problem that is common in machine\nlearning and signal processing. Because of these nonlinearities, conventional\nestimators based on empirical risk minimization generally involve solving a\nnon-convex optimization program. We propose anchored regression, a new approach\nbased on convex programming that amounts to maximizing a linear functional\n(perhaps augmented by a regularizer) over a convex set. The proposed convex\nprogram is formulated in the natural space of the problem, and avoids the\nintroduction of auxiliary variables, making it computationally favorable.\nWorking in the native space also provides great flexibility as structural\npriors (e.g., sparsity) can be seamlessly incorporated.\n  For our analysis, we model the equations as being drawn from a fixed set\naccording to a probability law. Our main results provide guarantees on the\naccuracy of the estimator in terms of the number of equations we are solving,\nthe amount of noise present, a measure of statistical complexity of the random\nequations, and the geometry of the regularizer at the true solution. We also\nprovide recipes for constructing the anchor vector (that determines the linear\nfunctional to maximize) directly from the observed data. \n\n"}
{"id": "1702.05575", "contents": "Title: A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics Abstract: We study the Stochastic Gradient Langevin Dynamics (SGLD) algorithm for\nnon-convex optimization. The algorithm performs stochastic gradient descent,\nwhere in each step it injects appropriately scaled Gaussian noise to the\nupdate. We analyze the algorithm's hitting time to an arbitrary subset of the\nparameter space. Two results follow from our general theory: First, we prove\nthat for empirical risk minimization, if the empirical risk is point-wise close\nto the (smooth) population risk, then the algorithm achieves an approximate\nlocal minimum of the population risk in polynomial time, escaping suboptimal\nlocal minima that only exist in the empirical risk. Second, we show that SGLD\nimproves on one of the best known learnability results for learning linear\nclassifiers under the zero-one loss. \n\n"}
{"id": "1702.05594", "contents": "Title: Riemannian stochastic variance reduced gradient algorithm with\n  retraction and vector transport Abstract: In recent years, stochastic variance reduction algorithms have attracted\nconsiderable attention for minimizing the average of a large but finite number\nof loss functions. This paper proposes a novel Riemannian extension of the\nEuclidean stochastic variance reduced gradient (R-SVRG) algorithm to a manifold\nsearch space. The key challenges of averaging, adding, and subtracting multiple\ngradients are addressed with retraction and vector transport. For the proposed\nalgorithm, we present a global convergence analysis with a decaying step size\nas well as a local convergence rate analysis with a fixed step size under some\nnatural assumptions. In addition, the proposed algorithm is applied to the\ncomputation problem of the Riemannian centroid on the symmetric positive\ndefinite (SPD) manifold as well as the principal component analysis and\nlow-rank matrix completion problems on the Grassmann manifold. The results show\nthat the proposed algorithm outperforms the standard Riemannian stochastic\ngradient descent algorithm in each case. \n\n"}
{"id": "1702.06219", "contents": "Title: An Online Optimization Approach for Multi-Agent Tracking of Dynamic\n  Parameters in the Presence of Adversarial Noise Abstract: This paper addresses tracking of a moving target in a multi-agent network.\nThe target follows a linear dynamics corrupted by an adversarial noise, i.e.,\nthe noise is not generated from a statistical distribution. The location of the\ntarget at each time induces a global time-varying loss function, and the global\nloss is a sum of local losses, each of which is associated to one agent. Agents\nnoisy observations could be nonlinear. We formulate this problem as a\ndistributed online optimization where agents communicate with each other to\ntrack the minimizer of the global loss. We then propose a decentralized version\nof the Mirror Descent algorithm and provide the non-asymptotic analysis of the\nproblem. Using the notion of dynamic regret, we measure the performance of our\nalgorithm versus its offline counterpart in the centralized setting. We prove\nthat the bound on dynamic regret scales inversely in the network spectral gap,\nand it represents the adversarial noise causing deviation with respect to the\nlinear dynamics. Our result subsumes a number of results in the distributed\noptimization literature. Finally, in a numerical experiment, we verify that our\nalgorithm can be simply implemented for multi-agent tracking with nonlinear\nobservations. \n\n"}
{"id": "1702.06429", "contents": "Title: Stochastic Composite Least-Squares Regression with convergence rate\n  O(1/n) Abstract: We consider the minimization of composite objective functions composed of the\nexpectation of quadratic functions and an arbitrary convex function. We study\nthe stochastic dual averaging algorithm with a constant step-size, showing that\nit leads to a convergence rate of O(1/n) without strong convexity assumptions.\nThis thus extends earlier results on least-squares regression with the\nEuclidean geometry to (a) all convex regularizers and constraints, and (b) all\ngeome-tries represented by a Bregman divergence. This is achieved by a new\nproof technique that relates stochastic and deterministic recursions. \n\n"}
{"id": "1702.06971", "contents": "Title: Online Ranking with Constraints: A Primal-Dual Algorithm and\n  Applications to Web Traffic-Shaping Abstract: We study the online constrained ranking problem motivated by an application\nto web-traffic shaping: an online stream of sessions arrive in which, within\neach session, we are asked to rank items. The challenge involves optimizing the\nranking in each session so that local vs. global objectives are controlled:\nwithin each session one wishes to maximize a reward (local) while satisfying\ncertain constraints over the entire set of sessions (global). A typical\napplication of this setup is that of page optimization in a web portal. We wish\nto rank items so that not only is user engagement maximized in each session,\nbut also other business constraints (such as the number of views/clicks\ndelivered to various publishing partners) are satisfied.\n  We describe an online algorithm for performing this optimization. A novel\nelement of our approach is the use of linear programming duality and\nconnections to the celebrated Hungarian algorithm. This framework enables us to\ndetermine a set of \\emph{shadow prices} for each traffic-shaping constraint\nthat can then be used directly in the final ranking function to assign\nnear-optimal rankings. The (dual) linear program can be solved off-line\nperiodically to determine the prices. At serving time these prices are used as\nweights to compute weighted rank-scores for the items, and the simplicity of\nthe approach facilitates scalability to web applications. We provide rigorous\ntheoretical guarantees for the performance of our online algorithm and validate\nour approach using numerical experiments on real web-traffic data from a\nprominent internet portal. \n\n"}
{"id": "1702.07615", "contents": "Title: Information Management for Decentralized Energy Storages under Market\n  Uncertainties Abstract: In this paper, we propose a model of decentralized energy storages, who serve\nas instruments to shift energy supply intertemporally. From storages'\nperspective, we investigate their optimal buying or selling decisions under\nmarket uncertainty. The goal of this paper is to understand the economic value\nof future market information, as energy storages mitigate market uncertainty by\nforward-looking strategies.\n  At a system level, we evaluate different information management policies to\ncoordinate storages' actions and improve their aggregate profitability: (1)\nproviding a publicly available market forecasting channel; (2) encouraging\ndecentralized storages to share their private forecasts with each other; (3)\nreleasing additional market information to a targeted subset of storages\nexclusively. We highlight the perils of too much market information provision\nand advice on exclusiveness of market forecast channel. \n\n"}
{"id": "1702.07754", "contents": "Title: Multi-Competitive Viruses over Static and Time--Varying Networks Abstract: Epidemic processes are used commonly for modeling and analysis of biological\nnetworks, computer networks, and human contact networks. The idea of competing\nviruses has been explored recently, motivated by the spread of different ideas\nalong different social networks. Previous studies of competitive viruses have\nfocused only on two viruses and on static graph structures. In this paper, we\nconsider multiple competing viruses over static and dynamic graph structures,\nand investigate the eradication and propagation of diseases in these systems.\nStability analysis for the class of models we consider is performed and an\nantidote control technique is proposed. \n\n"}
{"id": "1702.07944", "contents": "Title: Stochastic Variance Reduction Methods for Policy Evaluation Abstract: Policy evaluation is a crucial step in many reinforcement-learning\nprocedures, which estimates a value function that predicts states' long-term\nvalue under a given policy. In this paper, we focus on policy evaluation with\nlinear function approximation over a fixed dataset. We first transform the\nempirical policy evaluation problem into a (quadratic) convex-concave saddle\npoint problem, and then present a primal-dual batch gradient method, as well as\ntwo stochastic variance reduction methods for solving the problem. These\nalgorithms scale linearly in both sample size and feature dimension. Moreover,\nthey achieve linear convergence even when the saddle-point problem has only\nstrong concavity in the dual variables but no strong convexity in the primal\nvariables. Numerical experiments on benchmark problems demonstrate the\neffectiveness of our methods. \n\n"}
{"id": "1702.07966", "contents": "Title: Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs Abstract: Deep learning models are often successfully trained using gradient descent,\ndespite the worst case hardness of the underlying non-convex optimization\nproblem. The key question is then under what conditions can one prove that\noptimization will succeed. Here we provide a strong result of this kind. We\nconsider a neural net with one hidden layer and a convolutional structure with\nno overlap and a ReLU activation function. For this architecture we show that\nlearning is NP-complete in the general case, but that when the input\ndistribution is Gaussian, gradient descent converges to the global optimum in\npolynomial time. To the best of our knowledge, this is the first global\noptimality guarantee of gradient descent on a convolutional neural network with\nReLU activations. \n\n"}
{"id": "1703.00441", "contents": "Title: Learning to Optimize Neural Nets Abstract: Learning to Optimize is a recently proposed framework for learning\noptimization algorithms using reinforcement learning. In this paper, we explore\nlearning an optimization algorithm for training shallow neural nets. Such\nhigh-dimensional stochastic optimization problems present interesting\nchallenges for existing reinforcement learning algorithms. We develop an\nextension that is suited to learning optimization algorithms in this setting\nand demonstrate that the learned optimization algorithm consistently\noutperforms other known optimization algorithms even on unseen tasks and is\nrobust to changes in stochasticity of gradients and the neural net\narchitecture. More specifically, we show that an optimization algorithm trained\nwith the proposed method on the problem of training a neural net on MNIST\ngeneralizes to the problems of training neural nets on the Toronto Faces\nDataset, CIFAR-10 and CIFAR-100. \n\n"}
{"id": "1703.00443", "contents": "Title: OptNet: Differentiable Optimization as a Layer in Neural Networks Abstract: This paper presents OptNet, a network architecture that integrates\noptimization problems (here, specifically in the form of quadratic programs) as\nindividual layers in larger end-to-end trainable deep networks. These layers\nencode constraints and complex dependencies between the hidden states that\ntraditional convolutional and fully-connected layers often cannot capture. We\nexplore the foundations for such an architecture: we show how techniques from\nsensitivity analysis, bilevel optimization, and implicit differentiation can be\nused to exactly differentiate through these layers and with respect to layer\nparameters; we develop a highly efficient solver for these layers that exploits\nfast GPU-based batch solves within a primal-dual interior point method, and\nwhich provides backpropagation gradients with virtually no additional cost on\ntop of the solve; and we highlight the application of these approaches in\nseveral problems. In one notable example, the method is learns to play\nmini-Sudoku (4x4) given just input and output games, with no a-priori\ninformation about the rules of the game; this highlights the ability of OptNet\nto learn hard constraints better than other neural architectures. \n\n"}
{"id": "1703.01969", "contents": "Title: Exploiting Sparsity in the Coefficient Matching Conditions in\n  Sum-of-Squares Programming using ADMM Abstract: This paper introduces an efficient first-order method based on the\nalternating direction method of multipliers (ADMM) to solve semidefinite\nprograms (SDPs) arising from sum-of-squares (SOS) programming. We exploit the\nsparsity of the \\emph{coefficient matching conditions} when SOS programs are\nformulated in the usual monomial basis to reduce the computational cost of the\nADMM algorithm. Each iteration of our algorithm requires one projection onto\nthe positive semidefinite cone and the solution of multiple quadratic programs\nwith closed-form solutions free of any matrix inversion. Our techniques are\nimplemented in the open-source MATLAB solver SOSADMM. Numerical experiments on\nSOS problems arising from unconstrained polynomial minimization and from\nLyapunov stability analysis for polynomial systems show speed-ups compared to\nthe interior-point solver SeDuMi, and the first-order solver CDCS. \n\n"}
{"id": "1703.02624", "contents": "Title: Exploiting Strong Convexity from Data with Primal-Dual First-Order\n  Algorithms Abstract: We consider empirical risk minimization of linear predictors with convex loss\nfunctions. Such problems can be reformulated as convex-concave saddle point\nproblems, and thus are well suitable for primal-dual first-order algorithms.\nHowever, primal-dual algorithms often require explicit strongly convex\nregularization in order to obtain fast linear convergence, and the required\ndual proximal mapping may not admit closed-form or efficient solution. In this\npaper, we develop both batch and randomized primal-dual algorithms that can\nexploit strong convexity from data adaptively and are capable of achieving\nlinear convergence even without regularization. We also present dual-free\nvariants of the adaptive primal-dual algorithms that do not require computing\nthe dual proximal mapping, which are especially suitable for logistic\nregression. \n\n"}
{"id": "1703.02998", "contents": "Title: A note on quickly sampling a sparse matrix with low rank expectation Abstract: Given matrices $X,Y \\in R^{n \\times K}$ and $S \\in R^{K \\times K}$ with\npositive elements, this paper proposes an algorithm fastRG to sample a sparse\nmatrix $A$ with low rank expectation $E(A) = XSY^T$ and independent Poisson\nelements. This allows for quickly sampling from a broad class of stochastic\nblockmodel graphs (degree-corrected, mixed membership, overlapping) all of\nwhich are specific parameterizations of the generalized random product graph\nmodel defined in Section 2.2. The basic idea of fastRG is to first sample the\nnumber of edges $m$ and then sample each edge. The key insight is that because\nof the the low rank expectation, it is easy to sample individual edges. The\nnaive \"element-wise\" algorithm requires $O(n^2)$ operations to generate the\n$n\\times n$ adjacency matrix $A$. In sparse graphs, where $m = O(n)$, ignoring\nlog terms, fastRG runs in time $O(n)$. An implementation in fastRG is available\non github. A computational experiment in Section 2.4 simulates graphs up to\n$n=10,000,000$ nodes with $m = 100,000,000$ edges. For example, on a graph with\n$n=500,000$ and $m = 5,000,000$, fastRG runs in less than one second on a 3.5\nGHz Intel i5. \n\n"}
{"id": "1703.03680", "contents": "Title: Strong convergence rates of probabilistic integrators for ordinary\n  differential equations Abstract: Probabilistic integration of a continuous dynamical system is a way of\nsystematically introducing model error, at scales no larger than errors\nintroduced by standard numerical discretisation, in order to enable thorough\nexploration of possible responses of the system to inputs. It is thus a\npotentially useful approach in a number of applications such as forward\nuncertainty quantification, inverse problems, and data assimilation. We extend\nthe convergence analysis of probabilistic integrators for deterministic\nordinary differential equations, as proposed by Conrad et al.\\ (\\textit{Stat.\\\nComput.}, 2017), to establish mean-square convergence in the uniform norm on\ndiscrete- or continuous-time solutions under relaxed regularity assumptions on\nthe driving vector fields and their induced flows. Specifically, we show that\nrandomised high-order integrators for globally Lipschitz flows and randomised\nEuler integrators for dissipative vector fields with polynomially-bounded local\nLipschitz constants all have the same mean-square convergence rate as their\ndeterministic counterparts, provided that the variance of the integration noise\nis not of higher order than the corresponding deterministic integrator. These\nand similar results are proven for probabilistic integrators where the random\nperturbations may be state-dependent, non-Gaussian, or non-centred random\nvariables. \n\n"}
{"id": "1703.04010", "contents": "Title: Data-Driven Estimation of Travel Latency Cost Functions via Inverse\n  Optimization in Multi-Class Transportation Networks Abstract: We develop a method to estimate from data travel latency cost functions in\nmulti-class transportation networks, which accommodate different types of\nvehicles with very different characteristics (e.g., cars and trucks).\nLeveraging our earlier work on inverse variational inequalities, we develop a\ndata-driven approach to estimate the travel latency cost functions. Extensive\nnumerical experiments using benchmark networks, ranging from moderate-sized to\nlarge-sized, demonstrate the effectiveness and efficiency of our approach. \n\n"}
{"id": "1703.04561", "contents": "Title: Drone Squadron Optimization: a Self-adaptive Algorithm for Global\n  Numerical Optimization Abstract: This paper proposes Drone Squadron Optimization, a new self-adaptive\nmetaheuristic for global numerical optimization which is updated online by a\nhyper-heuristic. DSO is an artifact-inspired technique, as opposed to many\nalgorithms used nowadays, which are nature-inspired. DSO is very flexible\nbecause it is not related to behaviors or natural phenomena. DSO has two core\nparts: the semi-autonomous drones that fly over a landscape to explore, and the\nCommand Center that processes the retrieved data and updates the drones'\nfirmware whenever necessary. The self-adaptive aspect of DSO in this work is\nthe perturbation/movement scheme, which is the procedure used to generate\ntarget coordinates. This procedure is evolved by the Command Center during the\nglobal optimization process in order to adapt DSO to the search landscape. DSO\nwas evaluated on a set of widely employed benchmark functions. The statistical\nanalysis of the results shows that the proposed method is competitive with the\nother methods in the comparison, the performance is promising, but several\nfuture improvements are planned. \n\n"}
{"id": "1703.04599", "contents": "Title: Generalized Self-Concordant Functions: A Recipe for Newton-Type Methods Abstract: We study the smooth structure of convex functions by generalizing a powerful\nconcept so-called self-concordance introduced by Nesterov and Nemirovskii in\nthe early 1990s to a broader class of convex functions, which we call\ngeneralized self-concordant functions. This notion allows us to develop a\nunified framework for designing Newton-type methods to solve convex optimiza-\ntion problems. The proposed theory provides a mathematical tool to analyze both\nlocal and global convergence of Newton-type methods without imposing\nunverifiable assumptions as long as the un- derlying functionals fall into our\ngeneralized self-concordant function class. First, we introduce the class of\ngeneralized self-concordant functions, which covers standard self-concordant\nfunctions as a special case. Next, we establish several properties and key\nestimates of this function class, which can be used to design numerical\nmethods. Then, we apply this theory to develop several Newton-type methods for\nsolving a class of smooth convex optimization problems involving the\ngeneralized self- concordant functions. We provide an explicit step-size for\nthe damped-step Newton-type scheme which can guarantee a global convergence\nwithout performing any globalization strategy. We also prove a local quadratic\nconvergence of this method and its full-step variant without requiring the\nLipschitz continuity of the objective Hessian. Then, we extend our result to\ndevelop proximal Newton-type methods for a class of composite convex\nminimization problems involving generalized self-concordant functions. We also\nachieve both global and local convergence without additional assumption.\nFinally, we verify our theoretical results via several numerical examples, and\ncompare them with existing methods. \n\n"}
{"id": "1703.06131", "contents": "Title: Inference via low-dimensional couplings Abstract: We investigate the low-dimensional structure of deterministic transformations\nbetween random variables, i.e., transport maps between probability measures. In\nthe context of statistics and machine learning, these transformations can be\nused to couple a tractable \"reference\" measure (e.g., a standard Gaussian) with\na target measure of interest. Direct simulation from the desired measure can\nthen be achieved by pushing forward reference samples through the map. Yet\ncharacterizing such a map---e.g., representing and evaluating it---grows\nchallenging in high dimensions. The central contribution of this paper is to\nestablish a link between the Markov properties of the target measure and the\nexistence of low-dimensional couplings, induced by transport maps that are\nsparse and/or decomposable. Our analysis not only facilitates the construction\nof transformations in high-dimensional settings, but also suggests new\ninference methodologies for continuous non-Gaussian graphical models. For\ninstance, in the context of nonlinear state-space models, we describe new\nvariational algorithms for filtering, smoothing, and sequential parameter\ninference. These algorithms can be understood as the natural\ngeneralization---to the non-Gaussian case---of the square-root\nRauch-Tung-Striebel Gaussian smoother. \n\n"}
{"id": "1703.06303", "contents": "Title: A Fast Algorithm for a Weighted Low Rank Approximation Abstract: Matrix low rank approximation including the classical PCA and the robust PCA\n(RPCA) method have been applied to solve the background modeling problem in\nvideo analysis. Recently, it has been demonstrated that a special weighted low\nrank approximation of matrices can be made robust to the outliers similar to\nthe $\\ell_1$-norm in RPCA method. In this work, we propose a new algorithm that\ncan speed up the existing algorithm for solving the special weighted low rank\napproximation and demonstrate its use in background estimation problem. \n\n"}
{"id": "1703.06807", "contents": "Title: Guaranteed Sufficient Decrease for Variance Reduced Stochastic Gradient\n  Descent Abstract: In this paper, we propose a novel sufficient decrease technique for variance\nreduced stochastic gradient descent methods such as SAG, SVRG and SAGA. In\norder to make sufficient decrease for stochastic optimization, we design a new\nsufficient decrease criterion, which yields sufficient decrease versions of\nvariance reduction algorithms such as SVRG-SD and SAGA-SD as a byproduct. We\nintroduce a coefficient to scale current iterate and satisfy the sufficient\ndecrease property, which takes the decisions to shrink, expand or move in the\nopposite direction, and then give two specific update rules of the coefficient\nfor Lasso and ridge regression. Moreover, we analyze the convergence properties\nof our algorithms for strongly convex problems, which show that both of our\nalgorithms attain linear convergence rates. We also provide the convergence\nguarantees of our algorithms for non-strongly convex problems. Our experimental\nresults further verify that our algorithms achieve significantly better\nperformance than their counterparts. \n\n"}
{"id": "1703.07539", "contents": "Title: On a frame theoretic measure of quality of LTI systems Abstract: It is of practical significance to define the notion of a measure of quality\nof a control system, i.e., a quantitative extension of the classical notion of\ncontrollability. In this article we demonstrate that the three standard\nmeasures of quality involving the trace, minimum eigenvalue, and the\ndeterminant of the controllability grammian achieve their optimum values when\nthe columns of the controllability matrix from a tight frame. Motivated by\nthis, and in view of some recent developments in frame theoretic signal\nprocessing, we provide a measure of quality for LTI systems based on a measure\nof tightness of the columns of the reachability matrix . \n\n"}
{"id": "1703.07802", "contents": "Title: Optimizing Curbside Parking Resources Subject to Congestion Constraints Abstract: To gain theoretical insight into the relationship between parking scarcity\nand congestion, we describe block-faces of curbside parking as a network of\nqueues. Due to the nature of this network, canonical queueing network results\nare not available to us. We present a new kind of queueing network subject to\ncustomer rejection due to the lack of available servers. We provide conditions\nfor such networks to be stable, a computationally tractable \"single node\" view\nof such a network, and show that maximizing the occupancy through price control\nof such queues, and subject to constraints on the allowable congestion between\nqueues searching for an available server, is a convex optimization problem. We\ndemonstrate an application of this method in the Mission District of San\nFrancisco; our results suggest congestion due to drivers searching for parking\nstems from an inefficient spatial utilization of parking resources. \n\n"}
{"id": "1703.08729", "contents": "Title: Solving SDPs for synchronization and MaxCut problems via the\n  Grothendieck inequality Abstract: A number of statistical estimation problems can be addressed by semidefinite\nprograms (SDP). While SDPs are solvable in polynomial time using interior point\nmethods, in practice generic SDP solvers do not scale well to high-dimensional\nproblems. In order to cope with this problem, Burer and Monteiro proposed a\nnon-convex rank-constrained formulation, which has good performance in practice\nbut is still poorly understood theoretically.\n  In this paper we study the rank-constrained version of SDPs arising in MaxCut\nand in synchronization problems. We establish a Grothendieck-type inequality\nthat proves that all the local maxima and dangerous saddle points are within a\nsmall multiplicative gap from the global maximum. We use this structural\ninformation to prove that SDPs can be solved within a known accuracy, by\napplying the Riemannian trust-region method to this non-convex problem, while\nconstraining the rank to be of order one. For the MaxCut problem, our\ninequality implies that any local maximizer of the rank-constrained SDP\nprovides a $ (1 - 1/(k-1)) \\times 0.878$ approximation of the MaxCut, when the\nrank is fixed to $k$.\n  We then apply our results to data matrices generated according to the\nGaussian ${\\mathbb Z}_2$ synchronization problem, and the two-groups stochastic\nblock model with large bounded degree. We prove that the error achieved by\nlocal maximizers undergoes a phase transition at the same threshold as for\ninformation-theoretically optimal methods. \n\n"}
{"id": "1703.08881", "contents": "Title: Solvability regions of affinely parameterized quadratic equations Abstract: Quadratic systems of equations appear in several applications. The results in\nthis paper are motivated by quadratic systems of equations that describe\nequilibrium behavior of physical infrastructure networks like the power and gas\ngrids. The quadratic systems in infrastructure networks are parameterized- the\nparameters can represent uncertainty (estimation error in resistance/inductance\nof a power transmission line, for example)or controllable decision variables\n(power outputs of generators,for example). It is then of interest to understand\nconditions on the parameters under which the quadratic system is guaranteed to\nhave a solution within a specified set (for example, bounds on voltages and\nflows in a power grid). Given nominal values of the parameters at which the\nquadratic system has a solution and the Jacobian of the quadratic system at the\nsolution i snon-singular, we develop a general framework to construct convex\nregions around the nominal value such that the system is guaranteed to have a\nsolution within a given distance of the nominal solution. We show that several\nresults from recen tliterature can be recovered as special cases of our\nframework,and demonstrate our approach on several benchmark power systems. \n\n"}
{"id": "1703.10705", "contents": "Title: Scaling, Proximity, and Optimization of Integrally Convex Functions Abstract: In discrete convex analysis, the scaling and proximity properties for the\nclass of L$^\\natural$-convex functions were established more than a decade ago\nand have been used to design efficient minimization algorithms. For the larger\nclass of integrally convex functions of $n$ variables, we show here that the\nscaling property only holds when $n \\leq 2$, while a proximity theorem can be\nestablished for any $n$, but only with a superexponential bound. This is,\nhowever, sufficient to extend the classical logarithmic complexity result for\nminimizing a discrete convex function of one variable to the case of integrally\nconvex functions of any fixed number of variables. \n\n"}
{"id": "1704.00117", "contents": "Title: A Multi-Index Markov Chain Monte Carlo Method Abstract: In this article we consider computing expectations w.r.t.~probability laws\nassociated to a certain class of stochastic systems. In order to achieve such a\ntask, one must not only resort to numerical approximation of the expectation,\nbut also to a biased discretization of the associated probability. We are\nconcerned with the situation for which the discretization is required in\nmultiple dimensions, for instance in space and time. In such contexts, it is\nknown that the multi-index Monte Carlo (MIMC) method can improve upon\ni.i.d.~sampling from the most accurate approximation of the probability law.\nIndeed by a non-trivial modification of the multilevel Monte Carlo (MLMC)\nmethod and it can reduce the work to obtain a given level of error, relative to\nthe afore mentioned i.i.d.~sampling and relative even to MLMC. In this article\nwe consider the case when such probability laws are too complex to sampled\nindependently. We develop a modification of the MIMC method which allows one to\nuse standard Markov chain Monte Carlo (MCMC) algorithms to replace independent\nand coupled sampling, in certain contexts. We prove a variance theorem which\nshows that using our MIMCMC method is preferable, in the sense above, to\ni.i.d.~sampling from the most accurate approximation, under assumptions. The\nmethod is numerically illustrated on a problem associated to a stochastic\npartial differential equation (SPDE). \n\n"}
{"id": "1704.02836", "contents": "Title: The quadratic M-convexity testing problem Abstract: M-convex functions, which are a generalization of valuated matroids, play a\ncentral role in discrete convex analysis. Quadratic M-convex functions\nconstitute a basic and important subclass of M-convex functions, which has a\nclose relationship with phylogenetics as well as valued constraint satisfaction\nproblems. In this paper, we consider the quadratic M-convexity testing problem\n(QMCTP), which is the problem of deciding whether a given quadratic function on\n$\\{0,1\\}^n$ is M-convex. We show that QMCTP is co-NP-complete in general, but\nis polynomial-time solvable under a natural assumption. Furthermore, we propose\nan $O(n^2)$-time algorithm for solving QMCTP in the polynomial-time solvable\ncase. \n\n"}
{"id": "1704.03338", "contents": "Title: Continuously tempered Hamiltonian Monte Carlo Abstract: Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC)\nmethod for performing approximate inference in complex probabilistic models of\ncontinuous variables. In common with many MCMC methods, however, the standard\nHMC approach performs poorly in distributions with multiple isolated modes. We\npresent a method for augmenting the Hamiltonian system with an extra continuous\ntemperature control variable which allows the dynamic to bridge between\nsampling a complex target distribution and a simpler unimodal base\ndistribution. This augmentation both helps improve mixing in multimodal targets\nand allows the normalisation constant of the target distribution to be\nestimated. The method is simple to implement within existing HMC code,\nrequiring only a standard leapfrog integrator. We demonstrate experimentally\nthat the method is competitive with annealed importance sampling and simulating\ntempering methods at sampling from challenging multimodal distributions and\nestimating their normalising constants. \n\n"}
{"id": "1704.04966", "contents": "Title: Larger is Better: The Effect of Learning Rates Enjoyed by Stochastic\n  Optimization with Progressive Variance Reduction Abstract: In this paper, we propose a simple variant of the original stochastic\nvariance reduction gradient (SVRG), where hereafter we refer to as the variance\nreduced stochastic gradient descent (VR-SGD). Different from the choices of the\nsnapshot point and starting point in SVRG and its proximal variant, Prox-SVRG,\nthe two vectors of each epoch in VR-SGD are set to the average and last iterate\nof the previous epoch, respectively. This setting allows us to use much larger\nlearning rates or step sizes than SVRG, e.g., 3/(7L) for VR-SGD vs 1/(10L) for\nSVRG, and also makes our convergence analysis more challenging. In fact, a\nlarger learning rate enjoyed by VR-SGD means that the variance of its\nstochastic gradient estimator asymptotically approaches zero more rapidly.\nUnlike common stochastic methods such as SVRG and proximal stochastic methods\nsuch as Prox-SVRG, we design two different update rules for smooth and\nnon-smooth objective functions, respectively. In other words, VR-SGD can tackle\nnon-smooth and/or non-strongly convex problems directly without using any\nreduction techniques such as quadratic regularizers. Moreover, we analyze the\nconvergence properties of VR-SGD for strongly convex problems, which show that\nVR-SGD attains a linear convergence rate. We also provide the convergence\nguarantees of VR-SGD for non-strongly convex problems. Experimental results\nshow that the performance of VR-SGD is significantly better than its\ncounterparts, SVRG and Prox-SVRG, and it is also much better than the best\nknown stochastic method, Katyusha. \n\n"}
{"id": "1704.07291", "contents": "Title: Minimal Controllability of Conjunctive Boolean Networks is NP-Complete Abstract: Given a conjunctive Boolean network (CBN) with $n$ state-variables, we\nconsider the problem of finding a minimal set of state-variables to directly\naffect with an input so that the resulting conjunctive Boolean control network\n(CBCN) is controllable. We give a necessary and sufficient condition for\ncontrollability of a CBCN; an $O(n^2)$-time algorithm for testing\ncontrollability; and prove that nonetheless the minimal controllability problem\nfor CBNs is NP-hard. \n\n"}
{"id": "1704.08623", "contents": "Title: Asymptotic control theory for a closed string Abstract: We develop an asymptotical control theory for one of the simplest distributed\noscillating systems, namely, for a closed string under a bounded load applied\nto a single distinguished point. We find exact classes of string states that\nadmit complete damping and an asymptotically exact value of the required time.\nBy using approximate reachable sets instead of exact ones, we design a\ndry-friction like feedback control, which turns out to be asymptotically\noptimal. We prove the existence of motion under the control using a rather\nexplicit solution of a nonlinear wave equation. Remarkably, the solution is\ndetermined via purely algebraic operations. The main result is a proof of\nasymptotic optimality of the control thus constructed. \n\n"}
{"id": "1705.00166", "contents": "Title: On the convergence of Hamiltonian Monte Carlo Abstract: This paper discusses the irreducibility and geometric ergodicity of the\nHamiltonian Monte Carlo (HMC) algorithm. We consider cases where the number of\nsteps of the symplectic integrator is either fixed or random. Under mild\nconditions on the potential $\\F$ associated with target distribution $\\pi$, we\nfirst show that the Markov kernel associated to the HMC algorithm is\nirreducible and recurrent. Under more stringent conditions, we then establish\nthat the Markov kernel is Harris recurrent. Finally, we provide verifiable\nconditions on $\\F$ under which the HMC sampler is geometrically ergodic. \n\n"}
{"id": "1705.01024", "contents": "Title: A projection pursuit framework for testing general high-dimensional\n  hypothesis Abstract: This article develops a framework for testing general hypothesis in\nhigh-dimensional models where the number of variables may far exceed the number\nof observations. Existing literature has considered less than a handful of\nhypotheses, such as testing individual coordinates of the model parameter.\nHowever, the problem of testing general and complex hypotheses remains widely\nopen. We propose a new inference method developed around the hypothesis\nadaptive projection pursuit framework, which solves the testing problems in the\nmost general case. The proposed inference is centered around a new class of\nestimators defined as $l_1$ projection of the initial guess of the unknown onto\nthe space defined by the null. This projection automatically takes into account\nthe structure of the null hypothesis and allows us to study formal inference\nfor a number of long-standing problems. For example, we can directly conduct\ninference on the sparsity level of the model parameters and the minimum signal\nstrength. This is especially significant given the fact that the former is a\nfundamental condition underlying most of the theoretical development in\nhigh-dimensional statistics, while the latter is a key condition used to\nestablish variable selection properties. Moreover, the proposed method is\nasymptotically exact and has satisfactory power properties for testing very\ngeneral functionals of the high-dimensional parameters. The simulation studies\nlend further support to our theoretical claims and additionally show excellent\nfinite-sample size and power properties of the proposed test. \n\n"}
{"id": "1705.02762", "contents": "Title: Integral and measure-turnpike properties for infinite-dimensional\n  optimal control systems Abstract: We first derive a general integral-turnpike property around a set for\ninfinite-dimensional non-autonomous optimal control problems with any possible\nterminal state constraints, under some appropriate assumptions. Roughly\nspeaking, the integral-turnpike property means that the time average of the\ndistance from any optimal trajectory to the turnpike set con- verges to zero,\nas the time horizon tends to infinity. Then, we establish the measure-turnpike\nproperty for strictly dissipative optimal control systems, with state and\ncontrol constraints. The measure-turnpike property, which is slightly stronger\nthan the integral-turnpike property, means that any optimal (state and control)\nsolution remains essentially, along the time frame, close to an optimal\nsolution of an associated static optimal control problem, except along a subset\nof times that is of small relative Lebesgue measure as the time horizon is\nlarge. Next, we prove that strict strong duality, which is a classical notion\nin optimization, implies strict dissipativity, and measure-turnpike. Finally,\nwe conclude the paper with several comments and open problems. \n\n"}
{"id": "1705.02766", "contents": "Title: \"Convex Until Proven Guilty\": Dimension-Free Acceleration of Gradient\n  Descent on Non-Convex Functions Abstract: We develop and analyze a variant of Nesterov's accelerated gradient descent\n(AGD) for minimization of smooth non-convex functions. We prove that one of two\ncases occurs: either our AGD variant converges quickly, as if the function was\nconvex, or we produce a certificate that the function is \"guilty\" of being\nnon-convex. This non-convexity certificate allows us to exploit negative\ncurvature and obtain deterministic, dimension-free acceleration of convergence\nfor non-convex functions. For a function $f$ with Lipschitz continuous gradient\nand Hessian, we compute a point $x$ with $\\|\\nabla f(x)\\| \\le \\epsilon$ in\n$O(\\epsilon^{-7/4} \\log(1/ \\epsilon) )$ gradient and function evaluations.\nAssuming additionally that the third derivative is Lipschitz, we require only\n$O(\\epsilon^{-5/3} \\log(1/ \\epsilon) )$ evaluations. \n\n"}
{"id": "1705.03615", "contents": "Title: Analysis of Optimization Algorithms via Integral Quadratic Constraints:\n  Nonstrongly Convex Problems Abstract: In this paper, we develop a unified framework able to certify both\nexponential and subexponential convergence rates for a wide range of iterative\nfirst-order optimization algorithms. To this end, we construct a family of\nparameter-dependent nonquadratic Lyapunov functions that can generate\nconvergence rates in addition to proving asymptotic convergence. Using Integral\nQuadratic Constraints (IQCs) from robust control theory, we propose a Linear\nMatrix Inequality (LMI) to guide the search for the parameters of the Lyapunov\nfunction in order to establish a rate bound. Based on this result, we formulate\na Semidefinite Programming (SDP) whose solution yields the best convergence\nrate that can be certified by the class of Lyapunov functions under\nconsideration. We illustrate the utility of our results by analyzing the\ngradient method, proximal algorithms and their accelerated variants for\n(strongly) convex problems. We also develop the continuous-time counterpart,\nwhereby we analyze the gradient flow and the continuous-time limit of\nNesterov's accelerated method. \n\n"}
{"id": "1705.04133", "contents": "Title: Quasi-Steady Model of a Pumping Kite Power System Abstract: The traction force of a kite can be used to drive a cyclic motion for\nextracting wind energy from the atmosphere. This paper presents a novel\nquasi-steady modelling framework for predicting the power generated over a full\npumping cycle. The cycle is divided into traction, retraction and transition\nphases, each described by an individual set of analytic equations. The effect\nof gravity on the airborne system components is included in the framework. A\ntrade-off is made between modelling accuracy and computation speed such that\nthe model is specifically useful for system optimisation and scaling in\neconomic feasibility studies. Simulation results are compared to experimental\nmeasurements of a 20 kW kite power system operated up to a tether length of 720\nm. Simulation and experiment agree reasonably well, both for moderate and for\nstrong wind conditions, indicating that the effect of gravity has to be taken\ninto account for a predictive performance simulation. \n\n"}
{"id": "1705.04374", "contents": "Title: Optimal fidelity multi-level Monte Carlo for quantification of\n  uncertainty in simulations of cloud cavitation collapse Abstract: We quantify uncertainties in the location and magnitude of extreme pressure\nspots revealed from large scale multi-phase flow simulations of cloud\ncavitation collapse. We examine clouds containing 500 cavities and quantify\nuncertainties related to their initial spatial arrangement. The resulting\n2000-dimensional space is sampled using a non-intrusive and computationally\nefficient Multi-Level Monte Carlo (MLMC) methodology. We introduce novel\noptimal control variate coefficients to enhance the variance reduction in MLMC.\nThe proposed optimal fidelity MLMC leads to more than two orders of magnitude\nspeedup when compared to standard Monte Carlo methods. We identify large\nuncertainties in the location and magnitude of the peak pressure pulse and\npresent its statistical correlations and joint probability density functions\nwith the geometrical characteristics of the cloud. Characteristic properties of\nspatial cloud structure are identified as potential causes of significant\nuncertainties in exerted collapse pressures. \n\n"}
{"id": "1705.04591", "contents": "Title: Learning ReLUs via Gradient Descent Abstract: In this paper we study the problem of learning Rectified Linear Units (ReLUs)\nwhich are functions of the form $max(0,<w,x>)$ with $w$ denoting the weight\nvector. We study this problem in the high-dimensional regime where the number\nof observations are fewer than the dimension of the weight vector. We assume\nthat the weight vector belongs to some closed set (convex or nonconvex) which\ncaptures known side-information about its structure. We focus on the realizable\nmodel where the inputs are chosen i.i.d.~from a Gaussian distribution and the\nlabels are generated according to a planted weight vector. We show that\nprojected gradient descent, when initialization at 0, converges at a linear\nrate to the planted model with a number of samples that is optimal up to\nnumerical constants. Our results on the dynamics of convergence of these very\nshallow neural nets may provide some insights towards understanding the\ndynamics of deeper architectures. \n\n"}
{"id": "1705.05933", "contents": "Title: Sub-sampled Cubic Regularization for Non-convex Optimization Abstract: We consider the minimization of non-convex functions that typically arise in\nmachine learning. Specifically, we focus our attention on a variant of trust\nregion methods known as cubic regularization. This approach is particularly\nattractive because it escapes strict saddle points and it provides stronger\nconvergence guarantees than first- and second-order as well as classical trust\nregion methods. However, it suffers from a high computational complexity that\nmakes it impractical for large-scale learning. Here, we propose a novel method\nthat uses sub-sampling to lower this computational cost. By the use of\nconcentration inequalities we provide a sampling scheme that gives sufficiently\naccurate gradient and Hessian approximations to retain the strong global and\nlocal convergence guarantees of cubically regularized methods. To the best of\nour knowledge this is the first work that gives global convergence guarantees\nfor a sub-sampled variant of cubic regularization on non-convex functions.\nFurthermore, we provide experimental results supporting our theory. \n\n"}
{"id": "1705.06431", "contents": "Title: Vehicle Routing with Drones Abstract: We introduce a package service model where trucks as well as drones can\ndeliver packages. Drones can travel on trucks or fly; but while flying, drones\ncan only carry one package at a time and have to return to a truck to charge\nafter each delivery. We present a heuristic algorithm to solve the problem of\nfinding a good schedule for all drones and trucks. The algorithm is based on\ntwo nested local searches, thus the definition of suitable neighbourhoods of\nsolutions is crucial for the algorithm. Empirical tests show that our algorithm\nperforms significantly better than a natural Greedy algorithm. Moreover, the\nsavings compared to solutions without drones turn out to be substantial,\nsuggesting that delivery systems might considerably benefit from using drones\nin addition to trucks. \n\n"}
{"id": "1705.06693", "contents": "Title: Limited-Memory Matrix Adaptation for Large Scale Black-box Optimization Abstract: The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is a popular\nmethod to deal with nonconvex and/or stochastic optimization problems when the\ngradient information is not available. Being based on the CMA-ES, the recently\nproposed Matrix Adaptation Evolution Strategy (MA-ES) provides a rather\nsurprising result that the covariance matrix and all associated operations\n(e.g., potentially unstable eigendecomposition) can be replaced in the CMA-ES\nby a updated transformation matrix without any loss of performance. In order to\nfurther simplify MA-ES and reduce its $\\mathcal{O}\\big(n^2\\big)$ time and\nstorage complexity to $\\mathcal{O}\\big(n\\log(n)\\big)$, we present the\nLimited-Memory Matrix Adaptation Evolution Strategy (LM-MA-ES) for efficient\nzeroth order large-scale optimization. The algorithm demonstrates\nstate-of-the-art performance on a set of established large-scale benchmarks. We\nexplore the algorithm on the problem of generating adversarial inputs for a\n(non-smooth) random forest classifier, demonstrating a surprising vulnerability\nof the classifier. \n\n"}
{"id": "1705.07256", "contents": "Title: Learning Feature Nonlinearities with Non-Convex Regularized Binned\n  Regression Abstract: For various applications, the relations between the dependent and independent\nvariables are highly nonlinear. Consequently, for large scale complex problems,\nneural networks and regression trees are commonly preferred over linear models\nsuch as Lasso. This work proposes learning the feature nonlinearities by\nbinning feature values and finding the best fit in each quantile using\nnon-convex regularized linear regression. The algorithm first captures the\ndependence between neighboring quantiles by enforcing smoothness via\npiecewise-constant/linear approximation and then selects a sparse subset of\ngood features. We prove that the proposed algorithm is statistically and\ncomputationally efficient. In particular, it achieves linear rate of\nconvergence while requiring near-minimal number of samples. Evaluations on\nsynthetic and real datasets demonstrate that algorithm is competitive with\ncurrent state-of-the-art and accurately learns feature nonlinearities. Finally,\nwe explore an interesting connection between the binning stage of our algorithm\nand sparse Johnson-Lindenstrauss matrices. \n\n"}
{"id": "1705.07477", "contents": "Title: Statistical inference using SGD Abstract: We present a novel method for frequentist statistical inference in\n$M$-estimation problems, based on stochastic gradient descent (SGD) with a\nfixed step size: we demonstrate that the average of such SGD sequences can be\nused for statistical inference, after proper scaling. An intuitive analysis\nusing the Ornstein-Uhlenbeck process suggests that such averages are\nasymptotically normal. From a practical perspective, our SGD-based inference\nprocedure is a first order method, and is well-suited for large scale problems.\nTo show its merits, we apply it to both synthetic and real datasets, and\ndemonstrate that its accuracy is comparable to classical statistical methods,\nwhile requiring potentially far less computation. \n\n"}
{"id": "1705.07576", "contents": "Title: Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk Abstract: We examine the theoretical properties of enforcing priors provided by\ngenerative deep neural networks via empirical risk minimization. In particular\nwe consider two models, one in which the task is to invert a generative neural\nnetwork given access to its last layer and another in which the task is to\ninvert a generative neural network given only compressive linear observations\nof its last layer. We establish that in both cases, in suitable regimes of\nnetwork layer sizes and a randomness assumption on the network weights, that\nthe non-convex objective function given by empirical risk minimization does not\nhave any spurious stationary points. That is, we establish that with high\nprobability, at any point away from small neighborhoods around two scalar\nmultiples of the desired solution, there is a descent direction. Hence, there\nare no local minima, saddle points, or other stationary points outside these\nneighborhoods. These results constitute the first theoretical guarantees which\nestablish the favorable global geometry of these non-convex optimization\nproblems, and they bridge the gap between the empirical success of enforcing\ndeep generative priors and a rigorous understanding of non-linear inverse\nproblems. \n\n"}
{"id": "1705.07646", "contents": "Title: An approximate empirical Bayesian method for large-scale linear-Gaussian\n  inverse problems Abstract: We study Bayesian inference methods for solving linear inverse problems,\nfocusing on hierarchical formulations where the prior or the likelihood\nfunction depend on unspecified hyperparameters. In practice, these\nhyperparameters are often determined via an empirical Bayesian method that\nmaximizes the marginal likelihood function, i.e., the probability density of\nthe data conditional on the hyperparameters. Evaluating the marginal\nlikelihood, however, is computationally challenging for large-scale problems.\nIn this work, we present a method to approximately evaluate marginal likelihood\nfunctions, based on a low-rank approximation of the update from the prior\ncovariance to the posterior covariance. We show that this approximation is\noptimal in a minimax sense. Moreover, we provide an efficient algorithm to\nimplement the proposed method, based on a combination of the randomized SVD and\na spectral approximation method to compute square roots of the prior covariance\nmatrix. Several numerical examples demonstrate good performance of the proposed\nmethod. \n\n"}
{"id": "1705.07881", "contents": "Title: Online Factorization and Partition of Complex Networks From Random Walks Abstract: Finding the reduced-dimensional structure is critical to understanding\ncomplex networks. Existing approaches such as spectral clustering are\napplicable only when the full network is explicitly observed. In this paper, we\nfocus on the online factorization and partition of implicit large-scale\nnetworks based on observations from an associated random walk. We formulate\nthis into a nonconvex stochastic factorization problem and propose an efficient\nand scalable stochastic generalized Hebbian algorithm. The algorithm is able to\nprocess dependent state-transition data dynamically generated by the underlying\nnetwork and learn a low-dimensional representation for each vertex. By applying\na diffusion approximation analysis, we show that the continuous-time limiting\nprocess of the stochastic algorithm converges globally to the \"principal\ncomponents\" of the Markov chain and achieves a nearly optimal sample\ncomplexity. Once given the learned low-dimensional representations, we further\napply clustering techniques to recover the network partition. We show that when\nthe associated Markov process is lumpable, one can recover the partition\nexactly with high probability. We apply the proposed approach to model the\ntraffic flow of Manhattan as city-wide random walks. By using our algorithm to\nanalyze the taxi trip data, we discover a latent partition of the Manhattan\ncity that closely matches the traffic dynamics. \n\n"}
{"id": "1705.08941", "contents": "Title: Dual Dynamic Programming with cut selection: convergence proof and\n  numerical experiments Abstract: We consider convex optimization problems formulated using dynamic programming\nequations. Such problems can be solved using the Dual Dynamic Programming\nalgorithm combined with the Level 1 cut selection strategy or the Territory\nalgorithm to select the most relevant Benders cuts. We propose a limited memory\nvariant of Level 1 and show the convergence of DDP combined with the Territory\nalgorithm, Level 1 or its variant for nonlinear optimization problems. In the\nspecial case of linear programs, we show convergence in a finite number of\niterations. Numerical simulations illustrate the interest of our variant and\nshow that it can be much quicker than a simplex algorithm on some large\ninstances of portfolio selection and inventory problems. \n\n"}
{"id": "1705.09383", "contents": "Title: Uniqueness of optimal solutions for semi-discrete transport with p-norm\n  cost functions Abstract: Semi-discrete transport can be characterized in terms of real-valued shifts.\nOften, but not always, the solution to the shift-characterized problem\npartitions the continuous region. This paper gives examples of when\npartitioning fails, and offers a large class of semi-discrete transport\nproblems where the shift-characterized solution is always a partition. \n\n"}
{"id": "1705.09396", "contents": "Title: Approximate and Stochastic Greedy Optimization Abstract: We consider two greedy algorithms for minimizing a convex function in a\nbounded convex set: an algorithm by Jones [1992] and the Frank-Wolfe (FW)\nalgorithm. We first consider approximate versions of these algorithms. For\nsmooth convex functions, we give sufficient conditions for convergence, a\nunified analysis for the well-known convergence rate of O(1/k) together with a\nresult showing that this rate is the best obtainable from the proof technique,\nand an equivalence result for the two algorithms. We also consider approximate\nstochastic greedy algorithms for minimizing expectations. We show that\nreplacing the full gradient by a single stochastic gradient can fail even on\nsmooth convex functions. We give a convergent approximate stochastic Jones\nalgorithm and a convergent approximate stochastic FW algorithm for smooth\nconvex functions. In addition, we give a convergent approximate stochastic FW\nalgorithm for nonsmooth convex functions. Convergence rates for these\nalgorithms are given and proved. \n\n"}
{"id": "1705.10499", "contents": "Title: Online to Offline Conversions, Universality and Adaptive Minibatch Sizes Abstract: We present an approach towards convex optimization that relies on a novel\nscheme which converts online adaptive algorithms into offline methods. In the\noffline optimization setting, our derived methods are shown to obtain\nfavourable adaptive guarantees which depend on the harmonic sum of the queried\ngradients. We further show that our methods implicitly adapt to the objective's\nstructure: in the smooth case fast convergence rates are ensured without any\nprior knowledge of the smoothness parameter, while still maintaining guarantees\nin the non-smooth setting. Our approach has a natural extension to the\nstochastic setting, resulting in a lazy version of SGD (stochastic GD), where\nminibathces are chosen \\emph{adaptively} depending on the magnitude of the\ngradients. Thus providing a principled approach towards choosing minibatch\nsizes. \n\n"}
{"id": "1706.00229", "contents": "Title: ${\\mathcal L}^1$ limit solutions in impulsive control Abstract: We consider a nonlinear control system depending on two controls u and v,\nwith dynamics affine in the (unbounded) derivative of u, and v appearing\ninitially only in the drift term. Recently, motivated by applications to\noptimization problems lacking coercivity, [1] proposed a notion of generalized\nsolution x for this system, called {\\it limit solution,} associated to\nmeasurable u and v, and with u of possibly unbounded variation in [0,T]. As\nshown in [1], when u and x have bounded variation, such a solution (called in\nthis case BV simple limit solution) coincides with the most used graph\ncompletion solution (see e.g. [6]). This correspondence has been extended in\n[24] to BV_loc u and trajectories (with bounded variation just on any [0,t]\nwith t<T). Starting with an example of optimal control where the minimum does\nnot exist in the class of limit solutions, we propose a notion of extended\nlimit solution x, for which such a minimum exists. As a first result, we prove\nthat extended and original limit solutions coincide in the special cases of BV\nand BV_loc inputs u (and solutions). Then we consider dynamics where the\nordinary control v also appears in the non-drift terms. For the associated\nsystem we prove that, in the BV case, extended limit solutions coincide with\ngraph completion solutions. \n\n"}
{"id": "1706.00764", "contents": "Title: Hyperparameter Optimization: A Spectral Approach Abstract: We give a simple, fast algorithm for hyperparameter optimization inspired by\ntechniques from the analysis of Boolean functions. We focus on the\nhigh-dimensional regime where the canonical example is training a neural\nnetwork with a large number of hyperparameters. The algorithm --- an iterative\napplication of compressed sensing techniques for orthogonal polynomials ---\nrequires only uniform sampling of the hyperparameters and is thus easily\nparallelizable.\n  Experiments for training deep neural networks on Cifar-10 show that compared\nto state-of-the-art tools (e.g., Hyperband and Spearmint), our algorithm finds\nsignificantly improved solutions, in some cases better than what is attainable\nby hand-tuning. In terms of overall running time (i.e., time required to sample\nvarious settings of hyperparameters plus additional computation time), we are\nat least an order of magnitude faster than Hyperband and Bayesian Optimization.\nWe also outperform Random Search 8x.\n  Additionally, our method comes with provable guarantees and yields the first\nimprovements on the sample complexity of learning decision trees in over two\ndecades. In particular, we obtain the first quasi-polynomial time algorithm for\nlearning noisy decision trees with polynomial sample complexity. \n\n"}
{"id": "1706.01665", "contents": "Title: Stochastic Multi-objective Optimization on a Budget: Application to\n  multi-pass wire drawing with quantified uncertainties Abstract: Design optimization of engineering systems with multiple competing objectives\nis a painstakingly tedious process especially when the objective functions are\nexpensive-to-evaluate computer codes with parametric uncertainties. The\neffectiveness of the state-of-the-art techniques is greatly diminished because\nthey require a large number of objective evaluations, which makes them\nimpractical for problems of the above kind. Bayesian global optimization (BGO),\nhas managed to deal with these challenges in solving single-objective\noptimization problems and has recently been extended to multi-objective\noptimization (MOO). BGO models the objectives via probabilistic surrogates and\nuses the epistemic uncertainty to define an information acquisition function\n(IAF) that quantifies the merit of evaluating the objective at new designs.\nThis iterative data acquisition process continues until a stopping criterion is\nmet. The most commonly used IAF for MOO is the expected improvement over the\ndominated hypervolume (EIHV) which in its original form is unable to deal with\nparametric uncertainties or measurement noise. In this work, we provide a\nsystematic reformulation of EIHV to deal with stochastic MOO problems. The\nprimary contribution of this paper lies in being able to filter out the noise\nand reformulate the EIHV without having to observe or estimate the stochastic\nparameters. An addendum of the probabilistic nature of our methodology is that\nit enables us to characterize our confidence about the predicted Pareto front.\nWe verify and validate the proposed methodology by applying it to synthetic\ntest problems with known solutions. We demonstrate our approach on an\nindustrial problem of die pass design for a steel wire drawing process. \n\n"}
{"id": "1706.02808", "contents": "Title: A randomized Halton algorithm in R Abstract: Randomized quasi-Monte Carlo (RQMC) sampling can bring orders of magnitude\nreduction in variance compared to plain Monte Carlo (MC) sampling. The extent\nof the efficiency gain varies from problem to problem and can be hard to\npredict. This article presents an R function rhalton that produces scrambled\nversions of Halton sequences. On some problems it brings efficiency gains of\nseveral thousand fold. On other problems, the efficiency gain is minor. The\ncode is designed to make it easy to determine whether a given integrand will\nbenefit from RQMC sampling. An RQMC sample of n points in $[0,1]^d$ can be\nextended later to a larger n and/or d. \n\n"}
{"id": "1706.04846", "contents": "Title: A Lyapunov-type approach to convergence of the Douglas-Rachford\n  algorithm Abstract: The Douglas-Rachford projection algorithm is an iterative method used to find\na point in the intersection of closed constraint sets. The algorithm has been\nexperimentally observed to solve various nonconvex feasibility problems which\ncurrent theory cannot sufficiently explain. In this paper, we prove convergence\nof the Douglas-Rachford algorithm in a potentially nonconvex setting. Our\nanalysis relies on the existence of a Lyapunov-type functional whose convexity\nproperties are not tantamount to convexity of the original constraint sets.\nMoreover, we provide various nonconvex examples in which our framework proves\nglobal convergence of the algorithm. \n\n"}
{"id": "1706.04957", "contents": "Title: Stochastic Primal-Dual Hybrid Gradient Algorithm with Arbitrary Sampling\n  and Imaging Applications Abstract: We propose a stochastic extension of the primal-dual hybrid gradient\nalgorithm studied by Chambolle and Pock in 2011 to solve saddle point problems\nthat are separable in the dual variable. The analysis is carried out for\ngeneral convex-concave saddle point problems and problems that are either\npartially smooth / strongly convex or fully smooth / strongly convex. We\nperform the analysis for arbitrary samplings of dual variables, and obtain\nknown deterministic results as a special case. Several variants of our\nstochastic method significantly outperform the deterministic variant on a\nvariety of imaging tasks. \n\n"}
{"id": "1706.06348", "contents": "Title: Frank-Wolfe Optimization for Symmetric-NMF under Simplicial Constraint Abstract: Symmetric nonnegative matrix factorization has found abundant applications in\nvarious domains by providing a symmetric low-rank decomposition of nonnegative\nmatrices. In this paper we propose a Frank-Wolfe (FW) solver to optimize the\nsymmetric nonnegative matrix factorization problem under a simplicial\nconstraint, which has recently been proposed for probabilistic clustering.\nCompared with existing solutions, this algorithm is simple to implement, and\nhas no hyperparameters to be tuned. Building on the recent advances of FW\nalgorithms in nonconvex optimization, we prove an $O(1/\\varepsilon^2)$\nconvergence rate to $\\varepsilon$-approximate KKT points, via a tight bound\n$\\Theta(n^2)$ on the curvature constant, which matches the best known result in\nunconstrained nonconvex setting using gradient methods. Numerical results\ndemonstrate the effectiveness of our algorithm. As a side contribution, we\nconstruct a simple nonsmooth convex problem where the FW algorithm fails to\nconverge to the optimum. This result raises an interesting question about\nnecessary conditions of the success of the FW algorithm on convex problems. \n\n"}
{"id": "1706.06569", "contents": "Title: A Unified Approach to Adaptive Regularization in Online and Stochastic\n  Optimization Abstract: We describe a framework for deriving and analyzing online optimization\nalgorithms that incorporate adaptive, data-dependent regularization, also\ntermed preconditioning. Such algorithms have been proven useful in stochastic\noptimization by reshaping the gradients according to the geometry of the data.\nOur framework captures and unifies much of the existing literature on adaptive\nonline methods, including the AdaGrad and Online Newton Step algorithms as well\nas their diagonal versions. As a result, we obtain new convergence proofs for\nthese algorithms that are substantially simpler than previous analyses. Our\nframework also exposes the rationale for the different preconditioned updates\nused in common stochastic optimization methods. \n\n"}
{"id": "1706.07105", "contents": "Title: Improved Conic Reformulations for K-means Clustering Abstract: In this paper, we show that the popular K-means clustering problem can\nequivalently be reformulated as a conic program of polynomial size. The arising\nconvex optimization problem is NP-hard, but amenable to a tractable\nsemidefinite programming (SDP) relaxation that is tighter than the current SDP\nrelaxation schemes in the literature. In contrast to the existing schemes, our\nproposed SDP formulation gives rise to solutions that can be leveraged to\nidentify the clusters. We devise a new approximation algorithm for K-means\nclustering that utilizes the improved formulation and empirically illustrate\nits superiority over the state-of-the-art solution schemes. \n\n"}
{"id": "1706.07832", "contents": "Title: Growing Linear Consensus Networks Endowed by Spectral Systemic\n  Performance Measures Abstract: We propose an axiomatic approach for design and performance analysis of noisy\nlinear consensus networks by introducing a notion of systemic performance\nmeasure. This class of measures are spectral functions of Laplacian eigenvalues\nof the network that are monotone, convex, and orthogonally invariant with\nrespect to the Laplacian matrix of the network. It is shown that several\nexisting gold-standard and widely used performance measures in the literature\nbelong to this new class of measures. We build upon this new notion and\ninvestigate a general form of combinatorial problem of growing a linear\nconsensus network via minimizing a given systemic performance measure. Two\nefficient polynomial-time approximation algorithms are devised to tackle this\nnetwork synthesis problem: a linearization-based method and a simple greedy\nalgorithm based on rank-one updates. Several theoretical fundamental limits on\nthe best achievable performance for the combinatorial problem is derived that\nassist us to evaluate optimality gaps of our proposed algorithms. A detailed\ncomplexity analysis confirms the effectiveness and viability of our algorithms\nto handle large-scale consensus networks. \n\n"}
{"id": "1706.08748", "contents": "Title: Hamilton-Jacobi equations for optimal control on networks with entry or\n  exit costs Abstract: We consider an optimal control on networks in the spirit of the works of\nAchdou et al. (2013) and Imbert et al. (2013). The main new feature is that\nthere are entry (or exit) costs at the edges of the network leading to a\npossible discontinuous value function. We characterize the value function as\nthe unique viscosity solution of a new Hamilton-Jacobi system. The uniqueness\nis a consequence of a comparison principle for which we give two different\nproofs, one with arguments from the theory of optimal control inspired by\nAchdou et al. (2014) and one based on partial differential equations techniques\ninspired by a recent work of Lions and Souganidis (2016). \n\n"}
{"id": "1707.01041", "contents": "Title: Convex regularization of discrete-valued inverse problems Abstract: This work is concerned with linear inverse problems where a distributed\nparameter is known a priori to only take on values from a given discrete set.\nThis property can be promoted in Tikhonov regularization with the aid of a\nsuitable convex but nondifferentiable regularization term. This allows applying\nstandard approaches to show well-posedness and convergence rates in Bregman\ndistance. Using the specific properties of the regularization term, it can be\nshown that convergence (albeit without rates) actually holds pointwise.\nFurthermore, the resulting Tikhonov functional can be minimized efficiently\nusing a semi-smooth Newton method. Numerical examples illustrate the properties\nof the regularization term and the numerical solution. \n\n"}
{"id": "1707.01146", "contents": "Title: Data-driven discovery of Koopman eigenfunctions for control Abstract: Data-driven transformations that reformulate nonlinear systems in a linear\nframework have the potential to enable the prediction, estimation, and control\nof strongly nonlinear dynamics using linear systems theory. The Koopman\noperator has emerged as a principled linear embedding of nonlinear dynamics,\nand its eigenfunctions establish intrinsic coordinates along which the dynamics\nbehave linearly. Previous studies have used finite-dimensional approximations\nof the Koopman operator for model-predictive control approaches. In this work,\nwe illustrate a fundamental closure issue of this approach and argue that it is\nbeneficial to first validate eigenfunctions and then construct reduced-order\nmodels in these validated eigenfunctions. These coordinates form a\nKoopman-invariant subspace by design and, thus, have improved predictive power.\nWe show then how the control can be formulated directly in these intrinsic\ncoordinates and discuss potential benefits and caveats of this perspective. The\nresulting control architecture is termed Koopman Reduced Order Nonlinear\nIdentification and Control (KRONIC). It is demonstrated that these\neigenfunctions can be approximated with data-driven regression and power series\nexpansions, based on the partial differential equation governing the\ninfinitesimal generator of the Koopman operator. Validating discovered\neigenfunctions is crucial and we show that lightly damped eigenfunctions may be\nfaithfully extracted from EDMD or an implicit formulation. These lightly damped\neigenfunctions are particularly relevant for control, as they correspond to\nnearly conserved quantities that are associated with persistent dynamics, such\nas the Hamiltonian. KRONIC is then demonstrated on a number of relevant\nexamples, including 1) a nonlinear system with a known linear embedding, 2) a\nvariety of Hamiltonian systems, and 3) a high-dimensional double-gyre model for\nocean mixing. \n\n"}
{"id": "1707.01209", "contents": "Title: Model compression as constrained optimization, with application to\n  neural nets. Part I: general framework Abstract: Compressing neural nets is an active research problem, given the large size\nof state-of-the-art nets for tasks such as object recognition, and the\ncomputational limits imposed by mobile devices. We give a general formulation\nof model compression as constrained optimization. This includes many types of\ncompression: quantization, low-rank decomposition, pruning, lossless\ncompression and others. Then, we give a general algorithm to optimize this\nnonconvex problem based on the augmented Lagrangian and alternating\noptimization. This results in a \"learning-compression\" algorithm, which\nalternates a learning step of the uncompressed model, independent of the\ncompression type, with a compression step of the model parameters, independent\nof the learning task. This simple, efficient algorithm is guaranteed to find\nthe best compressed model for the task in a local sense under standard\nassumptions.\n  We present separately in several companion papers the development of this\ngeneral framework into specific algorithms for model compression based on\nquantization, pruning and other variations, including experimental results on\ncompressing neural nets and other models. \n\n"}
{"id": "1707.03505", "contents": "Title: Proximally Guided Stochastic Subgradient Method for Nonsmooth, Nonconvex\n  Problems Abstract: In this paper, we introduce a stochastic projected subgradient method for\nweakly convex (i.e., uniformly prox-regular) nonsmooth, nonconvex functions---a\nwide class of functions which includes the additive and convex composite\nclasses. At a high-level, the method is an inexact proximal point iteration in\nwhich the strongly convex proximal subproblems are quickly solved with a\nspecialized stochastic projected subgradient method. The primary contribution\nof this paper is a simple proof that the proposed algorithm converges at the\nsame rate as the stochastic gradient method for smooth nonconvex problems. This\nresult appears to be the first convergence rate analysis of a stochastic (or\neven deterministic) subgradient method for the class of weakly convex\nfunctions. \n\n"}
{"id": "1707.04926", "contents": "Title: Theoretical insights into the optimization landscape of\n  over-parameterized shallow neural networks Abstract: In this paper we study the problem of learning a shallow artificial neural\nnetwork that best fits a training data set. We study this problem in the\nover-parameterized regime where the number of observations are fewer than the\nnumber of parameters in the model. We show that with quadratic activations the\noptimization landscape of training such shallow neural networks has certain\nfavorable characteristics that allow globally optimal models to be found\nefficiently using a variety of local search heuristics. This result holds for\nan arbitrary training data of input/output pairs. For differentiable activation\nfunctions we also show that gradient descent, when suitably initialized,\nconverges at a linear rate to a globally optimal model. This result focuses on\na realizable model where the inputs are chosen i.i.d. from a Gaussian\ndistribution and the labels are generated according to planted weight\ncoefficients. \n\n"}
{"id": "1707.05947", "contents": "Title: Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical\n  Viewpoints Abstract: Algorithm-dependent generalization error bounds are central to statistical\nlearning theory. A learning algorithm may use a large hypothesis space, but the\nlimited number of iterations controls its model capacity and generalization\nerror. The impacts of stochastic gradient methods on generalization error for\nnon-convex learning problems not only have important theoretical consequences,\nbut are also critical to generalization errors of deep learning.\n  In this paper, we study the generalization errors of Stochastic Gradient\nLangevin Dynamics (SGLD) with non-convex objectives. Two theories are proposed\nwith non-asymptotic discrete-time analysis, using Stability and PAC-Bayesian\nresults respectively. The stability-based theory obtains a bound of\n$O\\left(\\frac{1}{n}L\\sqrt{\\beta T_k}\\right)$, where $L$ is uniform Lipschitz\nparameter, $\\beta$ is inverse temperature, and $T_k$ is aggregated step sizes.\nFor PAC-Bayesian theory, though the bound has a slower $O(1/\\sqrt{n})$ rate,\nthe contribution of each step is shown with an exponentially decaying factor by\nimposing $\\ell^2$ regularization, and the uniform Lipschitz constant is also\nreplaced by actual norms of gradients along trajectory. Our bounds have no\nimplicit dependence on dimensions, norms or other capacity measures of\nparameter, which elegantly characterizes the phenomenon of \"Fast Training\nGuarantees Generalization\" in non-convex settings. This is the first\nalgorithm-dependent result with reasonable dependence on aggregated step sizes\nfor non-convex learning, and has important implications to statistical learning\naspects of stochastic gradient methods in complicated models such as deep\nlearning. \n\n"}
{"id": "1707.06360", "contents": "Title: Common and Individual Structure of Brain Networks Abstract: This article focuses on the problem of studying shared- and\nindividual-specific structure in replicated networks or graph-valued data. In\nparticular, the observed data consist of $n$ graphs, $G_i, i=1,\\ldots,n$, with\neach graph consisting of a collection of edges between $V$ nodes. In brain\nconnectomics, the graph for an individual corresponds to a set of\ninterconnections among brain regions. Such data can be organized as a $V \\times\nV$ binary adjacency matrix $A_i$ for each $i$, with ones indicating an edge\nbetween a pair of nodes and zeros indicating no edge. When nodes have a shared\nmeaning across replicates $i=1,\\ldots,n$, it becomes of substantial interest to\nstudy similarities and differences in the adjacency matrices. To address this\nproblem, we propose a method to estimate a common structure and low-dimensional\nindividual-specific deviations from replicated networks. The proposed Multiple\nGRAph Factorization (M-GRAF) model relies on a logistic regression mapping\ncombined with a hierarchical eigenvalue decomposition. We develop an efficient\nalgorithm for estimation and study basic properties of our approach. Simulation\nstudies show excellent operating characteristics and we apply the method to\nhuman brain connectomics data. \n\n"}
{"id": "1707.08261", "contents": "Title: Positive Semidefinite Univariate Matrix Polynomials Abstract: We study sum-of-squares representations of symmetric univariate real matrix\npolynomials that are positive semidefinite along the real line. We give a new\nproof of the fact that every positive semidefinite univariate matrix polynomial\nof size $n\\times n$ can be written as a sum of squares $M=Q^TQ$, where $Q$ has\nsize $(n+1)\\times n$, which was recently proved by\nBlekherman-Plaumann-Sinn-Vinzant. Our new approach using the theory of\nquadratic forms allows us to prove the conjecture made by these authors that\nthese minimal representations $M=Q^TQ$ are generically in one-to-one\ncorrespondence with the representations of the nonnegative univariate\npolynomial $\\det(M)$ as sums of two squares.\n  In parallel, we will use our methods to prove the more elementary hermitian\nanalogue that every hermitian univariate matrix polynomial $M$ that is positive\nsemidefinite along the real line, is a square, which is known as the matrix\nFej\\'er-Riesz Theorem. \n\n"}
{"id": "1707.08423", "contents": "Title: Non-Stationary Bandits with Habituation and Recovery Dynamics Abstract: Many settings involve sequential decision-making where a set of actions can\nbe chosen at each time step, each action provides a stochastic reward, and the\ndistribution for the reward of each action is initially unknown. However,\nfrequent selection of a specific action may reduce its expected reward, while\nabstaining from choosing an action may cause its expected reward to increase.\nSuch non-stationary phenomena are observed in many real world settings such as\npersonalized healthcare-adherence improving interventions and targeted online\nadvertising. Though finding an optimal policy for general models with\nnon-stationarity is PSPACE-complete, we propose and analyze a new class of\nmodels called ROGUE (Reducing or Gaining Unknown Efficacy) bandits, which we\nshow in this paper can capture these phenomena and are amenable to the design\nof effective policies. We first present a consistent maximum likelihood\nestimator for the parameters of these models. Next, we construct finite sample\nconcentration bounds that lead to an upper confidence bound policy called the\nROGUE Upper Confidence Bound (ROGUE-UCB) algorithm. We prove that under proper\nconditions the ROGUE-UCB algorithm achieves logarithmic in time regret, unlike\nexisting algorithms which result in linear regret. We conclude with a numerical\nexperiment using real data from a personalized healthcare-adherence improving\nintervention to increase physical activity. In this intervention, the goal is\nto optimize the selection of messages (e.g., confidence increasing vs.\nknowledge increasing) to send to each individual each day to increase adherence\nand physical activity. Our results show that ROGUE-UCB performs better in terms\nof regret and average reward as compared to state of the art algorithms, and\nthe use of ROGUE-UCB increases daily step counts by roughly 1,000 steps a day\n(about a half-mile more of walking) as compared to other algorithms. \n\n"}
{"id": "1707.09169", "contents": "Title: An application of proof mining to the proximal point algorithm in CAT(0)\n  spaces Abstract: We compute, using techniques originally introduced by Kohlenbach, the first\nauthor and Nicolae, uniform rates of metastability for the proximal point\nalgorithm in the context of CAT(0) spaces (as first considered by Bacak),\nspecifically for the case where the ambient space is totally bounded. This\nresult is part of the program of proof mining, which aims to apply methods of\nmathematical logic with the purpose of extracting quantitative information out\nof ordinary mathematical proofs, which may not be necessarily constructive. \n\n"}
{"id": "1707.09285", "contents": "Title: Simplified Energy Landscape for Modularity Using Total Variation Abstract: Networks capture pairwise interactions between entities and are frequently\nused in applications such as social networks, food networks, and protein\ninteraction networks, to name a few. Communities, cohesive groups of nodes,\noften form in these applications, and identifying them gives insight into the\noverall organization of the network. One common quality function used to\nidentify community structure is modularity. In Hu et al. [SIAM J. App. Math.,\n73(6), 2013], it was shown that modularity optimization is equivalent to\nminimizing a particular nonconvex total variation (TV) based functional over a\ndiscrete domain. They solve this problem, assuming the number of communities is\nknown, using a Merriman, Bence, Osher (MBO) scheme.\n  We show that modularity optimization is equivalent to minimizing a convex\nTV-based functional over a discrete domain, again, assuming the number of\ncommunities is known. Furthermore, we show that modularity has no convex\nrelaxation satisfying certain natural conditions. We therefore, find a\nmanageable non-convex approximation using a Ginzburg Landau functional, which\nprovably converges to the correct energy in the limit of a certain parameter.\nWe then derive an MBO algorithm with fewer hand-tuned parameters than in Hu et\nal. and which is 7 times faster at solving the associated diffusion equation\ndue to the fact that the underlying discretization is unconditionally stable.\nOur numerical tests include a hyperspectral video whose associated graph has\n2.9x10^7 edges, which is roughly 37 times larger than was handled in the paper\nof Hu et al. \n\n"}
{"id": "1708.00707", "contents": "Title: ELFI: Engine for Likelihood-Free Inference Abstract: Engine for Likelihood-Free Inference (ELFI) is a Python software library for\nperforming likelihood-free inference (LFI). ELFI provides a convenient syntax\nfor arranging components in LFI, such as priors, simulators, summaries or\ndistances, to a network called ELFI graph. The components can be implemented in\na wide variety of languages. The stand-alone ELFI graph can be used with any of\nthe available inference methods without modifications. A central method\nimplemented in ELFI is Bayesian Optimization for Likelihood-Free Inference\n(BOLFI), which has recently been shown to accelerate likelihood-free inference\nup to several orders of magnitude by surrogate-modelling the distance. ELFI\nalso has an inbuilt support for output data storing for reuse and analysis, and\nsupports parallelization of computation from multiple cores up to a cluster\nenvironment. ELFI is designed to be extensible and provides interfaces for\nwidening its functionality. This makes the adding of new inference methods to\nELFI straightforward and automatically compatible with the inbuilt features. \n\n"}
{"id": "1708.00842", "contents": "Title: Latent Parameter Estimation in Fusion Networks Using Separable\n  Likelihoods Abstract: Multi-sensor state space models underpin fusion applications in networks of\nsensors. Estimation of latent parameters in these models has the potential to\nprovide highly desirable capabilities such as network self-calibration.\nConventional solutions to the problem pose difficulties in scaling with the\nnumber of sensors due to the joint multi-sensor filtering involved when\nevaluating the parameter likelihood. In this article, we propose a separable\npseudo-likelihood which is a more accurate approximation compared to a\npreviously proposed alternative under typical operating conditions. In\naddition, we consider using separable likelihoods in the presence of many\nobjects and ambiguity in associating measurements with objects that originated\nthem. To this end, we use a state space model with a hypothesis based\nparameterisation, and, develop an empirical Bayesian perspective in order to\nevaluate separable likelihoods on this model using local filtering. Bayesian\ninference with this likelihood is carried out using belief propagation on the\nassociated pairwise Markov random field. We specify a particle algorithm for\nlatent parameter estimation in a linear Gaussian state space model and\ndemonstrate its efficacy for network self-calibration using measurements from\nnon-cooperative targets in comparison with alternatives. \n\n"}
{"id": "1708.01072", "contents": "Title: A Sparse Completely Positive Relaxation of the Modularity Maximization\n  for Community Detection Abstract: In this paper, we consider the community detection problem under either the\nstochastic block model (SBM) assumption or the degree-correlated stochastic\nblock model (DCSBM) assumption. The modularity maximization formulation for the\ncommunity detection problem is NP-hard in general. In this paper, we propose a\nsparse and low-rank completely positive relaxation for the modularity\nmaximization problem, we then develop an efficient row-by-row (RBR) type block\ncoordinate descent (BCD) algorithm to solve the relaxation and prove an\n$\\mathcal{O}(1/\\sqrt{N})$ convergence rate to a stationary point where $N$ is\nthe number of iterations. A fast rounding scheme is constructed to retrieve the\ncommunity structure from the solution. Non-asymptotic high probability bounds\non the misclassification rate are established to justify our approach. We\nfurther develop an asynchronous parallel RBR algorithm to speed up the\nconvergence. Extensive numerical experiments on both synthetic and real world\nnetworks show that the proposed approach enjoys advantages in both clustering\naccuracy and numerical efficiency. Our numerical results indicate that the\nnewly proposed method is a quite competitive alternative for community\ndetection on sparse networks with over 50 million nodes. \n\n"}
{"id": "1708.02079", "contents": "Title: The discrete moment problem with nonconvex shape constraints Abstract: The discrete moment problem is a foundational problem in distribution-free\nrobust optimization, where the goal is to find a worst-case distribution that\nsatisfies a given set of moments. This paper studies the discrete moment\nproblems with additional \"shape constraints\" that guarantee the worst case\ndistribution is either log-concave or has an increasing failure rate. These\nclasses of shape constraints have not previously been studied in the\nliterature, in part due to their inherent nonconvexities. Nonetheless, these\nclasses of distributions are useful in practice. We characterize the structure\nof optimal extreme point distributions by developing new results in reverse\nconvex optimization, a lesser-known tool previously employed in designing\nglobal optimization algorithms. We are able to show, for example, that an\noptimal extreme point solution to a moment problem with $m$ moments and\nlog-concave shape constraints is piecewise geometric with at most $m$ pieces.\nMoreover, this structure allows us to design an exact algorithm for computing\noptimal solutions in a low-dimensional space of parameters. Moreover, We\ndescribe a computational approach to solving these low-dimensional problems,\nincluding numerical results for a representative set of instances. \n\n"}
{"id": "1708.02105", "contents": "Title: Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls Abstract: We propose a rank-$k$ variant of the classical Frank-Wolfe algorithm to solve\nconvex optimization over a trace-norm ball. Our algorithm replaces the top\nsingular-vector computation ($1$-SVD) in Frank-Wolfe with a top-$k$\nsingular-vector computation ($k$-SVD), which can be done by repeatedly applying\n$1$-SVD $k$ times. Alternatively, our algorithm can be viewed as a rank-$k$\nrestricted version of projected gradient descent. We show that our algorithm\nhas a linear convergence rate when the objective function is smooth and\nstrongly convex, and the optimal solution has rank at most $k$. This improves\nthe convergence rate and the total time complexity of the Frank-Wolfe method\nand its variants. \n\n"}
{"id": "1708.02544", "contents": "Title: Stochastic Optimization with Bandit Sampling Abstract: Many stochastic optimization algorithms work by estimating the gradient of\nthe cost function on the fly by sampling datapoints uniformly at random from a\ntraining set. However, the estimator might have a large variance, which\ninadvertently slows down the convergence rate of the algorithms. One way to\nreduce this variance is to sample the datapoints from a carefully selected\nnon-uniform distribution. In this work, we propose a novel non-uniform sampling\napproach that uses the multi-armed bandit framework. Theoretically, we show\nthat our algorithm asymptotically approximates the optimal variance within a\nfactor of 3. Empirically, we show that using this datapoint-selection technique\nresults in a significant reduction in the convergence time and variance of\nseveral stochastic optimization algorithms such as SGD, SVRG and SAGA. This\napproach for sampling datapoints is general, and can be used in conjunction\nwith any algorithm that uses an unbiased gradient estimation -- we expect it to\nhave broad applicability beyond the specific examples explored in this work. \n\n"}
{"id": "1708.02659", "contents": "Title: Gramian Tensor Decomposition via Semidefinite Programming Abstract: In this paper we examine a symmetric tensor decomposition problem, the\nGramian decomposition, posed as a rank minimization problem. We study the\nrelaxation of the problem and consider cases when the relaxed solution is a\nsolution to the original problem. In some instances of tensor rank and order,\nwe prove generically that the solution to the relaxation will be optimal in the\noriginal. In other cases, we present interesting examples and approaches that\ndemonstrate the intricacy of this problem. \n\n"}
{"id": "1708.03272", "contents": "Title: Fast and accurate Bayesian model criticism and conflict diagnostics\n  using R-INLA Abstract: Bayesian hierarchical models are increasingly popular for realistic modelling\nand analysis of complex data. This trend is accompanied by the need for\nflexible, general, and computationally efficient methods for model criticism\nand conflict detection. Usually, a Bayesian hierarchical model incorporates a\ngrouping of the individual data points, for example individuals in repeated\nmeasurement data. In such cases, the following question arises: Are any of the\ngroups \"outliers\", or in conflict with the remaining groups? Existing general\napproaches aiming to answer such questions tend to be extremely computationally\ndemanding when model fitting is based on MCMC. We show how group-level model\ncriticism and conflict detection can be done quickly and accurately through\nintegrated nested Laplace approximations (INLA). The new method is implemented\nas a part of the open source R-INLA package for Bayesian computing\n(http://r-inla.org). \n\n"}
{"id": "1708.03288", "contents": "Title: Subset Selection with Shrinkage: Sparse Linear Modeling when the SNR is\n  low Abstract: We study a seemingly unexpected and relatively less understood overfitting\naspect of a fundamental tool in sparse linear modeling - best subset selection,\nwhich minimizes the residual sum of squares subject to a constraint on the\nnumber of nonzero coefficients. While the best subset selection procedure is\noften perceived as the \"gold standard\" in sparse learning when the signal to\nnoise ratio (SNR) is high, its predictive performance deteriorates when the SNR\nis low. In particular, it is outperformed by continuous shrinkage methods, such\nas ridge regression and the Lasso. We investigate the behavior of best subset\nselection in the high-noise regimes and propose an alternative approach based\non a regularized version of the least-squares criterion. Our proposed\nestimators (a) mitigate, to a large extent, the poor predictive performance of\nbest subset selection in the high-noise regimes; and (b) perform favorably,\nwhile generally delivering substantially sparser models, relative to the best\npredictive models available via ridge regression and the Lasso. We conduct an\nextensive theoretical analysis of the predictive properties of the proposed\napproach and provide justification for its superior predictive performance\nrelative to best subset selection when the noise-level is high. Our estimators\ncan be expressed as solutions to mixed integer second order conic optimization\nproblems and, hence, are amenable to modern computational tools from\nmathematical optimization. \n\n"}
{"id": "1708.03625", "contents": "Title: Unbiased Markov chain Monte Carlo with couplings Abstract: Markov chain Monte Carlo (MCMC) methods provide consistent of integrals as\nthe number of iterations goes to infinity. MCMC estimators are generally biased\nafter any fixed number of iterations. We propose to remove this bias by using\ncouplings of Markov chains together with a telescopic sum argument of Glynn and\nRhee (2014). The resulting unbiased estimators can be computed independently in\nparallel. We discuss practical couplings for popular MCMC algorithms. We\nestablish the theoretical validity of the proposed estimators and study their\nefficiency relative to the underlying MCMC algorithms. Finally, we illustrate\nthe performance and limitations of the method on toy examples, on an Ising\nmodel around its critical temperature, on a high-dimensional variable selection\nproblem, and on an approximation of the cut distribution arising in Bayesian\ninference for models made of multiple modules. \n\n"}
{"id": "1708.03741", "contents": "Title: Online Convex Optimization with Stochastic Constraints Abstract: This paper considers online convex optimization (OCO) with stochastic\nconstraints, which generalizes Zinkevich's OCO over a known simple fixed set by\nintroducing multiple stochastic functional constraints that are i.i.d.\ngenerated at each round and are disclosed to the decision maker only after the\ndecision is made. This formulation arises naturally when decisions are\nrestricted by stochastic environments or deterministic environments with noisy\nobservations. It also includes many important problems as special cases, such\nas OCO with long term constraints, stochastic constrained convex optimization,\nand deterministic constrained convex optimization. To solve this problem, this\npaper proposes a new algorithm that achieves $O(\\sqrt{T})$ expected regret and\nconstraint violations and $O(\\sqrt{T}\\log(T))$ high probability regret and\nconstraint violations. Experiments on a real-world data center scheduling\nproblem further verify the performance of the new algorithm. \n\n"}
{"id": "1708.05978", "contents": "Title: Stochastic Primal-Dual Proximal ExtraGradient Descent for Compositely\n  Regularized Optimization Abstract: We consider a wide range of regularized stochastic minimization problems with\ntwo regularization terms, one of which is composed with a linear function. This\noptimization model abstracts a number of important applications in artificial\nintelligence and machine learning, such as fused Lasso, fused logistic\nregression, and a class of graph-guided regularized minimization. The\ncomputational challenges of this model are in two folds. On one hand, the\nclosed-form solution of the proximal mapping associated with the composed\nregularization term or the expected objective function is not available. On the\nother hand, the calculation of the full gradient of the expectation in the\nobjective is very expensive when the number of input data samples is\nconsiderably large. To address these issues, we propose a stochastic variant of\nextra-gradient type methods, namely \\textsf{Stochastic Primal-Dual Proximal\nExtraGradient descent (SPDPEG)}, and analyze its convergence property for both\nconvex and strongly convex objectives. For general convex objectives, the\nuniformly average iterates generated by \\textsf{SPDPEG} converge in expectation\nwith $O(1/\\sqrt{t})$ rate. While for strongly convex objectives, the uniformly\nand non-uniformly average iterates generated by \\textsf{SPDPEG} converge with\n$O(\\log(t)/t)$ and $O(1/t)$ rates, respectively. The order of the rate of the\nproposed algorithm is known to match the best convergence rate for first-order\nstochastic algorithms. Experiments on fused logistic regression and\ngraph-guided regularized logistic regression problems show that the proposed\nalgorithm performs very efficiently and consistently outperforms other\ncompeting algorithms. \n\n"}
{"id": "1708.06302", "contents": "Title: A general framework for Vecchia approximations of Gaussian processes Abstract: Gaussian processes (GPs) are commonly used as models for functions, time\nseries, and spatial fields, but they are computationally infeasible for large\ndatasets. Focusing on the typical setting of modeling data as a GP plus an\nadditive noise term, we propose a generalization of the Vecchia (1988) approach\nas a framework for GP approximations. We show that our general Vecchia approach\ncontains many popular existing GP approximations as special cases, allowing for\ncomparisons among the different methods within a unified framework.\nRepresenting the models by directed acyclic graphs, we determine the sparsity\nof the matrices necessary for inference, which leads to new insights regarding\nthe computational properties. Based on these results, we propose a novel sparse\ngeneral Vecchia approximation, which ensures computational feasibility for\nlarge spatial datasets but can lead to considerable improvements in\napproximation accuracy over Vecchia's original approach. We provide several\ntheoretical results and conduct numerical comparisons. We conclude with\nguidelines for the use of Vecchia approximations in spatial statistics. \n\n"}
{"id": "1708.07164", "contents": "Title: Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian\n  Information Abstract: We consider variants of trust-region and cubic regularization methods for\nnon-convex optimization, in which the Hessian matrix is approximated. Under\nmild conditions on the inexact Hessian, and using approximate solution of the\ncorresponding sub-problems, we provide iteration complexity to achieve $\n\\epsilon $-approximate second-order optimality which have shown to be tight.\nOur Hessian approximation conditions constitute a major relaxation over the\nexisting ones in the literature. Consequently, we are able to show that such\nmild conditions allow for the construction of the approximate Hessian through\nvarious random sampling methods. In this light, we consider the canonical\nproblem of finite-sum minimization, provide appropriate uniform and non-uniform\nsub-sampling strategies to construct such Hessian approximations, and obtain\noptimal iteration complexity for the corresponding sub-sampled trust-region and\ncubic regularization methods. \n\n"}
{"id": "1708.07827", "contents": "Title: Second-Order Optimization for Non-Convex Machine Learning: An Empirical\n  Study Abstract: While first-order optimization methods such as stochastic gradient descent\n(SGD) are popular in machine learning (ML), they come with well-known\ndeficiencies, including relatively-slow convergence, sensitivity to the\nsettings of hyper-parameters such as learning rate, stagnation at high training\nerrors, and difficulty in escaping flat regions and saddle points. These issues\nare particularly acute in highly non-convex settings such as those arising in\nneural networks. Motivated by this, there has been recent interest in\nsecond-order methods that aim to alleviate these shortcomings by capturing\ncurvature information. In this paper, we report detailed empirical evaluations\nof a class of Newton-type methods, namely sub-sampled variants of trust region\n(TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex\nML problems. In doing so, we demonstrate that these methods not only can be\ncomputationally competitive with hand-tuned SGD with momentum, obtaining\ncomparable or better generalization performance, but also they are highly\nrobust to hyper-parameter settings. Further, in contrast to SGD with momentum,\nwe show that the manner in which these Newton-type methods employ curvature\ninformation allows them to seamlessly escape flat regions and saddle points. \n\n"}
{"id": "1708.07953", "contents": "Title: Lyapunov characterization of input-to-state stability for semilinear\n  control systems over Banach spaces Abstract: We prove that input-to-state stability (ISS) of nonlinear systems over Banach\nspaces is equivalent to existence of a coercive Lipschitz continuous ISS\nLyapunov function for this system. For linear infinite-dimensional systems, we\nshow that ISS is equivalent to existence of a non-coercive ISS Lyapunov\nfunction and provide two simpler constructions of coercive and non-coercive ISS\nLyapunov functions for input-to-state stable linear systems. \n\n"}
{"id": "1708.09096", "contents": "Title: Transfer-Entropy-Regularized Markov Decision Processes Abstract: We consider the framework of transfer-entropy-regularized Markov Decision\nProcess (TERMDP) in which the weighted sum of the classical state-dependent\ncost and the transfer entropy from the state random process to the control\nrandom process is minimized. Although TERMDPs are generally formulated as\nnonconvex optimization problems, we derive an analytical necessary optimality\ncondition expressed as a finite set of nonlinear equations, based on which an\niterative forward-backward computational procedure similar to the\nArimoto-Blahut algorithm is proposed. It is shown that every limit point of the\nsequence generated by the proposed algorithm is a stationary point of the\nTERMDP. Applications of TERMDPs are discussed in the context of networked\ncontrol systems theory and non-equilibrium thermodynamics. The proposed\nalgorithm is applied to an information-constrained maze navigation problem,\nwhereby we study how the price of information qualitatively alters the optimal\ndecision polices. \n\n"}
{"id": "1709.00005", "contents": "Title: Mesh Independence of an Accelerated Block Coordinate Descent Method for\n  Sparse Optimal Control Problems Abstract: An accelerated block coordinate descent (ABCD) method in Hilbert space is\nanalyzed to solve the sparse optimal control problem via its dual. The finite\nelement approximation of this method is investigated and convergence results\nare presents. Based on the second order growth condition of the dual objective\nfunction, we show that iteration sequence of dual variables has the iteration\ncomplexity of $O(1/k)$. Moreover, we also prove iteration complexity for the\nprimal problem. Two types of mesh-independence for ABCD method are proved,\nwhich asserts that asymptotically the infinite dimensional ABCD method and\nfinite dimensional discretizations have the same convergence property, and the\niterations of ABCD method remain nearly constant as the discretization is\nrefined. \n\n"}
{"id": "1709.00291", "contents": "Title: Asymptotic Bias of Stochastic Gradient Search Abstract: The asymptotic behavior of the stochastic gradient algorithm with a biased\ngradient estimator is analyzed. Relying on arguments based on the dynamic\nsystem theory (chain-recurrence) and the differential geometry (Yomdin theorem\nand Lojasiewicz inequality), tight bounds on the asymptotic bias of the\niterates generated by such an algorithm are derived. The obtained results hold\nunder mild conditions and cover a broad class of high-dimensional nonlinear\nalgorithms. Using these results, the asymptotic properties of the\npolicy-gradient (reinforcement) learning and adaptive population Monte Carlo\nsampling are studied. Relying on the same results, the asymptotic behavior of\nthe recursive maximum split-likelihood estimation in hidden Markov models is\nanalyzed, too. \n\n"}
{"id": "1709.00483", "contents": "Title: Iteratively Linearized Reweighted Alternating Direction Method of\n  Multipliers for a Class of Nonconvex Problems Abstract: In this paper, we consider solving a class of nonconvex and nonsmooth\nproblems frequently appearing in signal processing and machine learning\nresearch. The traditional alternating direction method of multipliers\nencounters troubles in both mathematics and computations in solving the\nnonconvex and nonsmooth subproblem. In view of this, we propose a reweighted\nalternating direction method of multipliers. In this algorithm, all subproblems\nare convex and easy to solve. We also provide several guarantees for the\nconvergence and prove that the algorithm globally converges to a critical point\nof an auxiliary function with the help of the Kurdyka-{\\L}ojasiewicz property.\nSeveral numerical results are presented to demonstrate the efficiency of the\nproposed algorithm. \n\n"}
{"id": "1709.01303", "contents": "Title: Hamiltonian Flow Simulation of Rare Events Abstract: Hamiltonian Flow Monte Carlo(HFMC) methods have been implemented in\nengineering, biology and chemistry. HFMC makes large gradient based steps to\nrapidly explore the state space. The application of the Hamiltonian dynamics\nallows to estimate rare events and sample from target distributions defined as\nthe change of measures. The estimates demonstrated a variance reduction of the\npresented algorithm and its efficiency with respect to a standard Monte Carlo\nand interacting particle based system(IPS). We tested the algorithm on the case\nof the barrier option pricing. \n\n"}
{"id": "1709.02490", "contents": "Title: Exploiting Problem Structure in Optimization under Uncertainty via\n  Online Convex Optimization Abstract: In this paper, we consider two paradigms that are developed to account for\nuncertainty in optimization models: robust optimization (RO) and joint\nestimation-optimization (JEO). We examine recent developments on efficient and\nscalable iterative first-order methods for these problems, and show that these\niterative methods can be viewed through the lens of online convex optimization\n(OCO). The standard OCO framework has seen much success for its ability to\nhandle decision-making in dynamic, uncertain, and even adversarial\nenvironments. Nevertheless, our applications of interest present further\nflexibility in OCO via three simple modifications to standard OCO assumptions:\nwe introduce two new concepts of weighted regret and online saddle point\nproblems and study the possibility of making lookahead (anticipatory)\ndecisions. Our analyses demonstrate that these flexibilities introduced into\nthe OCO framework have significant consequences whenever they are applicable.\nFor example, in the strongly convex case, minimizing unweighted regret has a\nproven optimal bound of $O(\\log(T)/T)$, whereas we show that a bound of\n$O(1/T)$ is possible when we consider weighted regret. Similarly, for the\nsmooth case, considering $1$-lookahead decisions results in a $O(1/T)$ bound,\ncompared to $O(1/\\sqrt{T})$ in the standard OCO setting. Consequently, these\nOCO tools are instrumental in exploiting structural properties of functions and\nresulting in improved convergence rates for RO and JEO. In certain cases, our\nresults for RO and JEO match the best known or optimal rates in the\ncorresponding problem classes without data uncertainty. \n\n"}
{"id": "1709.02726", "contents": "Title: A Modular Analysis of Adaptive (Non-)Convex Optimization: Optimism,\n  Composite Objectives, and Variational Bounds Abstract: Recently, much work has been done on extending the scope of online learning\nand incremental stochastic optimization algorithms. In this paper we contribute\nto this effort in two ways: First, based on a new regret decomposition and a\ngeneralization of Bregman divergences, we provide a self-contained, modular\nanalysis of the two workhorses of online learning: (general) adaptive versions\nof Mirror Descent (MD) and the Follow-the-Regularized-Leader (FTRL) algorithms.\nThe analysis is done with extra care so as not to introduce assumptions not\nneeded in the proofs and allows to combine, in a straightforward way, different\nalgorithmic ideas (e.g., adaptivity, optimism, implicit updates) and learning\nsettings (e.g., strongly convex or composite objectives). This way we are able\nto reprove, extend and refine a large body of the literature, while keeping the\nproofs concise. The second contribution is a byproduct of this careful\nanalysis: We present algorithms with improved variational bounds for smooth,\ncomposite objectives, including a new family of optimistic MD algorithms with\nonly one projection step per round. Furthermore, we provide a simple extension\nof adaptive regret bounds to practically relevant non-convex problem settings\nwith essentially no extra effort. \n\n"}
{"id": "1709.02999", "contents": "Title: Balancing Communication and Computation in Distributed Optimization Abstract: Methods for distributed optimization have received significant attention in\nrecent years owing to their wide applicability in various domains. A\ndistributed optimization method typically consists of two key components:\ncommunication and computation. More specifically, at every iteration (or every\nseveral iterations) of a distributed algorithm, each node in the network\nrequires some form of information exchange with its neighboring nodes\n(communication) and the computation step related to a (sub)-gradient\n(computation). The standard way of judging an algorithm via only the number of\niterations overlooks the complexity associated with each iteration. Moreover,\nvarious applications deploying distributed methods may prefer a different\ncomposition of communication and computation.\n  Motivated by this discrepancy, in this work we propose an adaptive cost\nframework which adjusts the cost measure depending on the features of various\napplications. We present a flexible algorithmic framework, where communication\nand computation steps are explicitly decomposed to enable algorithm\ncustomization for various applications. We apply this framework to the\nwell-known distributed gradient descent (DGD) method, and show that the\nresulting customized algorithms, which we call DGD$^t$, NEAR-DGD$^t$ and\nNEAR-DGD$^+$, compare favorably to their base algorithms, both theoretically\nand empirically. The proposed NEAR-DGD$^+$ algorithm is an exact first-order\nmethod where the communication and computation steps are nested, and when the\nnumber of communication steps is adaptively increased, the method converges to\nthe optimal solution. We test the performance and illustrate the flexibility of\nthe methods, as well as practical variants, on quadratic functions and\nclassification problems that arise in machine learning, in terms of iterations,\ngradient evaluations, communications and the proposed cost framework. \n\n"}
{"id": "1709.03528", "contents": "Title: GIANT: Globally Improved Approximate Newton Method for Distributed\n  Optimization Abstract: For distributed computing environment, we consider the empirical risk\nminimization problem and propose a distributed and communication-efficient\nNewton-type optimization method. At every iteration, each worker locally finds\nan Approximate NewTon (ANT) direction, which is sent to the main driver. The\nmain driver, then, averages all the ANT directions received from workers to\nform a {\\it Globally Improved ANT} (GIANT) direction. GIANT is highly\ncommunication efficient and naturally exploits the trade-offs between local\ncomputations and global communications in that more local computations result\nin fewer overall rounds of communications. Theoretically, we show that GIANT\nenjoys an improved convergence rate as compared with first-order methods and\nexisting distributed Newton-type methods. Further, and in sharp contrast with\nmany existing distributed Newton-type methods, as well as popular first-order\nmethods, a highly advantageous practical feature of GIANT is that it only\ninvolves one tuning parameter. We conduct large-scale experiments on a computer\ncluster and, empirically, demonstrate the superior performance of GIANT. \n\n"}
{"id": "1709.03594", "contents": "Title: Lower Bound for Randomized First Order Convex Optimization Abstract: We provide an explicit construction and direct proof for the lower bound on\nthe number of first order oracle accesses required for a randomized algorithm\nto minimize a convex Lipschitz function. \n\n"}
{"id": "1709.03668", "contents": "Title: Branch-and-bound for biobjective mixed-integer linear programming Abstract: We present a generic branch-and-bound algorithm for finding all the Pareto\nsolutions of a biobjective mixed-integer linear program. The main contributions\nare new algorithms for obtaining dual bounds at a node, for checking node\nfathoming, presolve and duality gap measurement. Our branch-and-bound is\npredominantly a decision space search method since the branching is performed\non the decision variables, akin to single objective problems, although we also\nsometimes split gaps and branch in the objective space. The various algorithms\nare implemented using a data structure for storing Pareto sets. Computational\nexperiments are carried out on literature instances and also on a new set of\ninstances that we generate using the MIPLIB benchmark library for single\nobjective problems. We also perform comparisons against the triangle splitting\nmethod from literature, which is an objective space search algorithm. \n\n"}
{"id": "1709.04451", "contents": "Title: Alternating minimization and alternating descent over nonconvex sets Abstract: We analyze the performance of alternating minimization for loss functions\noptimized over two variables, where each variable may be restricted to lie in\nsome potentially nonconvex constraint set. This type of setting arises\nnaturally in high-dimensional statistics and signal processing, where the\nvariables often reflect different structures or components within the signals\nbeing considered. Our analysis relies on the notion of local concavity\ncoefficients, which has been proposed in Barber and Ha to measure and quantify\nthe concavity of a general nonconvex set. Our results further reveal important\ndistinctions between alternating and non-alternating methods. Since computing\nthe alternating minimization steps may not be tractable for some problems, we\nalso consider an inexact version of the algorithm and provide a set of\nsufficient conditions to ensure fast convergence of the inexact algorithms. We\ndemonstrate our framework on several examples, including low rank + sparse\ndecomposition and multitask regression, and provide numerical experiments to\nvalidate our theoretical results. \n\n"}
{"id": "1709.05380", "contents": "Title: The Uncertainty Bellman Equation and Exploration Abstract: We consider the exploration/exploitation problem in reinforcement learning.\nFor exploitation, it is well known that the Bellman equation connects the value\nat any time-step to the expected value at subsequent time-steps. In this paper\nwe consider a similar \\textit{uncertainty} Bellman equation (UBE), which\nconnects the uncertainty at any time-step to the expected uncertainties at\nsubsequent time-steps, thereby extending the potential exploratory benefit of a\npolicy beyond individual time-steps. We prove that the unique fixed point of\nthe UBE yields an upper bound on the variance of the posterior distribution of\nthe Q-values induced by any policy. This bound can be much tighter than\ntraditional count-based bonuses that compound standard deviation rather than\nvariance. Importantly, and unlike several existing approaches to optimism, this\nmethod scales naturally to large systems with complex generalization.\nSubstituting our UBE-exploration strategy for $\\epsilon$-greedy improves DQN\nperformance on 51 out of 57 games in the Atari suite. \n\n"}
{"id": "1709.06129", "contents": "Title: When is a Convolutional Filter Easy To Learn? Abstract: We analyze the convergence of (stochastic) gradient descent algorithm for\nlearning a convolutional filter with Rectified Linear Unit (ReLU) activation\nfunction. Our analysis does not rely on any specific form of the input\ndistribution and our proofs only use the definition of ReLU, in contrast with\nprevious works that are restricted to standard Gaussian input. We show that\n(stochastic) gradient descent with random initialization can learn the\nconvolutional filter in polynomial time and the convergence rate depends on the\nsmoothness of the input distribution and the closeness of patches. To the best\nof our knowledge, this is the first recovery guarantee of gradient-based\nalgorithms for convolutional filter on non-Gaussian input distributions. Our\ntheory also justifies the two-stage learning rate strategy in deep neural\nnetworks. While our focus is theoretical, we also present experiments that\nillustrate our theoretical findings. \n\n"}
{"id": "1709.06597", "contents": "Title: varbvs: Fast Variable Selection for Large-scale Regression Abstract: We introduce varbvs, a suite of functions written in R and MATLAB for\nregression analysis of large-scale data sets using Bayesian variable selection\nmethods. We have developed numerical optimization algorithms based on\nvariational approximation methods that make it feasible to apply Bayesian\nvariable selection to very large data sets. With a focus on examples from\ngenome-wide association studies, we demonstrate that varbvs scales well to data\nsets with hundreds of thousands of variables and thousands of samples, and has\nfeatures that facilitate rapid data analyses. Moreover, varbvs allows for\nextensive model customization, which can be used to incorporate external\ninformation into the analysis. We expect that the combination of an easy-to-use\ninterface and robust, scalable algorithms for posterior computation will\nencourage broader use of Bayesian variable selection in areas of applied\nstatistics and computational biology. The most recent R and MATLAB source code\nis available for download at Github (https://github.com/pcarbo/varbvs), and the\nR package can be installed from CRAN\n(https://cran.r-project.org/package=varbvs). \n\n"}
{"id": "1709.06849", "contents": "Title: Rbox: an integrated R package for ATOM Editor Abstract: R is a programming language and environment that is a central tool in the\napplied sciences for writing program. Its impact on the development of modern\nstatistics is inevitable. Current research, especially for big data may not be\ndone solely using R and will likely use different programming languages; hence,\nhaving a modern integrated development environment (IDE) is very important.\nAtom editor is modern IDE that is developed by GitHub, it is described as \"A\nhackable text editor for the 21st Century\". This report is intended to present\na package deployed entitled Rbox that allows Atom Editor to write and run codes\nprofessionally in R. \n\n"}
{"id": "1709.07286", "contents": "Title: Alternating least squares as moving subspace correction Abstract: In this note we take a new look at the local convergence of alternating\noptimization methods for low-rank matrices and tensors. Our abstract\ninterpretation as sequential optimization on moving subspaces yields insightful\nreformulations of some known convergence conditions that focus on the interplay\nbetween the contractivity of classical multiplicative Schwarz methods with\noverlapping subspaces and the curvature of low-rank matrix and tensor\nmanifolds. While the verification of the abstract conditions in concrete\nscenarios remains open in most cases, we are able to provide an alternative and\nconceptually simple derivation of the asymptotic convergence rate of the\ntwo-sided block power method of numerical algebra for computing the dominant\nsingular subspaces of a rectangular matrix. This method is equivalent to an\nalternating least squares method applied to a distance function. The\ntheoretical results are illustrated and validated by numerical experiments. \n\n"}
{"id": "1709.07356", "contents": "Title: User Association and Bandwidth Allocation for Terrestrial and Aerial\n  Base Stations with Backhaul Considerations Abstract: Drone base stations (DBSs) can enhance network coverage and area capacity by\nmoving supply towards demand when required. This degree of freedom could be\nespecially useful for future applications with extreme demands, such as ultra\nreliable and low latency communications (uRLLC). However, deployment of DBSs\ncan face several challenges. One issue is finding the 3D placement of such BSs\nto satisfy dynamic requirements of the system. Second, the availability of\nreliable wireless backhaul links and the related resource allocation are\nprincipal issues that should be considered. Finally, association of the users\nwith BSs becomes an involved problem due to mobility of DBSs. In this paper, we\nconsider a macro-BS (MBS) and several DBSs that rely on the wireless links to\nthe MBS for backhauling. Considering regular and uRLLC users, we propose an\nalgorithm to find efficient 3D locations of DBSs in addition to the user-BS\nassociations and wireless backhaul bandwidth allocations to maximize the sum\nlogarithmic rate of the users. To this end, a decomposition method is employed\nto first find the user-BS association and bandwidth allocations. Then DBS\nlocations are updated using a heuristic particle swarm optimization algorithm.\nSimulation results show the effectiveness of the proposed method and provide\nuseful insights on the effects of traffic distributions and antenna beamwidth. \n\n"}
{"id": "1709.08238", "contents": "Title: Counterparty Credit Limits: The Impact of a Risk-Mitigation Measure on\n  Everyday Trading Abstract: A counterparty credit limit (CCL) is a limit that is imposed by a financial\ninstitution to cap its maximum possible exposure to a specified counterparty.\nCCLs help institutions to mitigate counterparty credit risk via selective\ndiversification of their exposures. In this paper, we analyze how CCLs impact\nthe prices that institutions pay for their trades during everyday trading. We\nstudy a high-quality data set from a large electronic trading platform in the\nforeign exchange spot market, which enables institutions to apply CCLs. We find\nempirically that CCLs had little impact on the vast majority of trades in this\ndata. We also study the impact of CCLs using a new model of trading. By\nsimulating our model with different underlying CCL networks, we highlight that\nCCLs can have a major impact in some situations. \n\n"}
{"id": "1709.08571", "contents": "Title: On Noisy Negative Curvature Descent: Competing with Gradient Descent for\n  Faster Non-convex Optimization Abstract: The Hessian-vector product has been utilized to find a second-order\nstationary solution with strong complexity guarantee (e.g., almost linear time\ncomplexity in the problem's dimensionality). In this paper, we propose to\nfurther reduce the number of Hessian-vector products for faster non-convex\noptimization. Previous algorithms need to approximate the smallest eigen-value\nwith a sufficient precision (e.g., $\\epsilon_2\\ll 1$) in order to achieve a\nsufficiently accurate second-order stationary solution (i.e.,\n$\\lambda_{\\min}(\\nabla^2 f(\\x))\\geq -\\epsilon_2)$. In contrast, the proposed\nalgorithms only need to compute the smallest eigen-vector approximating the\ncorresponding eigen-value up to a small power of current gradient's norm. As a\nresult, it can dramatically reduce the number of Hessian-vector products during\nthe course of optimization before reaching first-order stationary points (e.g.,\nsaddle points). The key building block of the proposed algorithms is a novel\nupdating step named the NCG step, which lets a noisy negative curvature descent\ncompete with the gradient descent. We show that the worst-case time complexity\nof the proposed algorithms with their favorable prescribed accuracy\nrequirements can match the best in literature for achieving a second-order\nstationary point but with an arguably smaller per-iteration cost. We also show\nthat the proposed algorithms can benefit from inexact Hessian by developing\ntheir variants accepting inexact Hessian under a mild condition for achieving\nthe same goal. Moreover, we develop a stochastic algorithm for a finite or\ninfinite sum non-convex optimization problem. To the best of our knowledge, the\nproposed stochastic algorithm is the first one that converges to a second-order\nstationary point in {\\it high probability} with a time complexity independent\nof the sample size and almost linear in dimensionality. \n\n"}
{"id": "1709.08841", "contents": "Title: Conic Optimization Theory: Convexification Techniques and Numerical\n  Algorithms Abstract: Optimization is at the core of control theory and appears in several areas of\nthis field, such as optimal control, distributed control, system\nidentification, robust control, state estimation, model predictive control and\ndynamic programming. The recent advances in various topics of modern\noptimization have also been revamping the area of machine learning. Motivated\nby the crucial role of optimization theory in the design, analysis, control and\noperation of real-world systems, this tutorial paper offers a detailed overview\nof some major advances in this area, namely conic optimization and its emerging\napplications. First, we discuss the importance of conic optimization in\ndifferent areas. Then, we explain seminal results on the design of hierarchies\nof convex relaxations for a wide range of nonconvex problems. Finally, we study\ndifferent numerical algorithms for large-scale conic optimization problems. \n\n"}
{"id": "1709.10219", "contents": "Title: Information Geometry Connecting Wasserstein Distance and\n  Kullback-Leibler Divergence via the Entropy-Relaxed Transportation Problem Abstract: Two geometrical structures have been extensively studied for a manifold of\nprobability distributions. One is based on the Fisher information metric, which\nis invariant under reversible transformations of random variables, while the\nother is based on the Wasserstein distance of optimal transportation, which\nreflects the structure of the distance between random variables. Here, we\npropose a new information-geometrical theory that is a unified framework\nconnecting the Wasserstein distance and Kullback-Leibler (KL) divergence. We\nprimarily considered a discrete case consisting of $n$ elements and studied the\ngeometry of the probability simplex $S_{n-1}$, which is the set of all\nprobability distributions over $n$ elements. The Wasserstein distance was\nintroduced in $S_{n-1}$ by the optimal transportation of commodities from\ndistribution ${\\mathbf{p}}$ to distribution ${\\mathbf{q}}$, where\n${\\mathbf{p}}$, ${\\mathbf{q}} \\in S_{n-1}$. We relaxed the optimal\ntransportation by using entropy, which was introduced by Cuturi. The optimal\nsolution was called the entropy-relaxed stochastic transportation plan. The\nentropy-relaxed optimal cost $C({\\mathbf{p}}, {\\mathbf{q}})$ was\ncomputationally much less demanding than the original Wasserstein distance but\ndoes not define a distance because it is not minimized at\n${\\mathbf{p}}={\\mathbf{q}}$. To define a proper divergence while retaining the\ncomputational advantage, we first introduced a divergence function in the\nmanifold $S_{n-1} \\times S_{n-1}$ of optimal transportation plans. We fully\nexplored the information geometry of the manifold of the optimal transportation\nplans and subsequently constructed a new one-parameter family of divergences in\n$S_{n-1}$ that are related to both the Wasserstein distance and the\nKL-divergence. \n\n"}
{"id": "1710.01688", "contents": "Title: On the Sample Complexity of the Linear Quadratic Regulator Abstract: This paper addresses the optimal control problem known as the Linear\nQuadratic Regulator in the case when the dynamics are unknown. We propose a\nmulti-stage procedure, called Coarse-ID control, that estimates a model from a\nfew experimental trials, estimates the error in that model with respect to the\ntruth, and then designs a controller using both the model and uncertainty\nestimate. Our technique uses contemporary tools from random matrix theory to\nbound the error in the estimation procedure. We also employ a recently\ndeveloped approach to control synthesis called System Level Synthesis that\nenables robust control design by solving a convex optimization problem. We\nprovide end-to-end bounds on the relative error in control cost that are nearly\noptimal in the number of parameters and that highlight salient properties of\nthe system to be controlled such as closed-loop sensitivity and optimal control\nmagnitude. We show experimentally that the Coarse-ID approach enables efficient\ncomputation of a stabilizing controller in regimes where simple control schemes\nthat do not take the model uncertainty into account fail to stabilize the true\nsystem. \n\n"}
{"id": "1710.02236", "contents": "Title: Primal-Dual Optimization Algorithms over Riemannian Manifolds: an\n  Iteration Complexity Analysis Abstract: In this paper we study nonconvex and nonsmooth multi-block optimization over\nRiemannian manifolds with coupled linear constraints. Such optimization\nproblems naturally arise from machine learning, statistical learning,\ncompressive sensing, image processing, and tensor PCA, among others. We develop\nan ADMM-like primal-dual approach based on decoupled solvable subroutines such\nas linearized proximal mappings. First, we introduce the optimality conditions\nfor the afore-mentioned optimization models. Then, the notion of\n$\\epsilon$-stationary solutions is introduced as a result. The main part of the\npaper is to show that the proposed algorithms enjoy an iteration complexity of\n$O(1/\\epsilon^2)$ to reach an $\\epsilon$-stationary solution. For prohibitively\nlarge-size tensor or machine learning models, we present a sampling-based\nstochastic algorithm with the same iteration complexity bound in expectation.\nIn case the subproblems are not analytically solvable, a feasible curvilinear\nline-search variant of the algorithm based on retraction operators is proposed.\nFinally, we show specifically how the algorithms can be implemented to solve a\nvariety of practical problems such as the NP-hard maximum bisection problem,\nthe $\\ell_q$ regularized sparse tensor principal component analysis and the\ncommunity detection problem. Our preliminary numerical results show great\npotentials of the proposed methods. \n\n"}
{"id": "1710.02901", "contents": "Title: Response to \"Counterexample to global convergence of DSOS and SDSOS\n  hierarchies\" Abstract: In a recent note [8], the author provides a counterexample to the global\nconvergence of what his work refers to as \"the DSOS and SDSOS hierarchies\" for\npolynomial optimization problems (POPs) and purports that this refutes claims\nin our extended abstract [4] and slides in [3]. The goal of this paper is to\nclarify that neither [4], nor [3], and certainly not our full paper [5], ever\ndefined DSOS or SDSOS hierarchies as it is done in [8]. It goes without saying\nthat no claims about convergence properties of the hierarchies in [8] were ever\nmade as a consequence. What was stated in [4,3] was completely different: we\nstated that there exist hierarchies based on DSOS and SDSOS optimization that\nconverge. This is indeed true as we discuss in this response. We also emphasize\nthat we were well aware that some (S)DSOS hierarchies do not converge even if\ntheir natural SOS counterparts do. This is readily implied by an example in our\nprior work [5], which makes the counterexample in [8] superfluous. Finally, we\nprovide concrete counterarguments to claims made in [8] that aim to challenge\nthe scalability improvements obtained by DSOS and SDSOS optimization as\ncompared to sum of squares (SOS) optimization.\n  [3] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS: More tractable alternatives\nto SOS. Slides at the meeting on Geometry and Algebra of Linear Matrix\nInequalities, CIRM, Marseille, 2013. [4] A. A. Ahmadi and A. Majumdar. DSOS and\nSDSOS optimization: LP and SOCP-based alternatives to sum of squares\noptimization. In proceedings of the 48th annual IEEE Conference on Information\nSciences and Systems, 2014. [5] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS\noptimization: more tractable alternatives to sum of squares and semidefinite\noptimization. arXiv:1706.02586, 2017. [8] C. Josz. Counterexample to global\nconvergence of DSOS and SDSOS hierarchies. arXiv:1707.02964, 2017. \n\n"}
{"id": "1710.02970", "contents": "Title: Virtual-Voltage Partition-Based Approach to Optimal Transmission\n  Switching Abstract: This paper deals with optimal transmission switching (OTS) problems involving\ndiscrete binary decisions about network topology and non-convex power flow\nconstraints. We adopt a semidefinite programming formulation for the OPF\nproblem which, however, remains nonconvex due to the presence of discrete\nvariables and bilinear products between the decision variables. To tackle the\nlatter, we introduce a novel physically-inspired, virtual-voltage approximation\nthat leads to provable lower and upper bounds on the solution of the original\nproblem. To deal with the exponential complexity caused by the discrete\nvariables, we introduce a graph partition-based algorithm which breaks the\nproblem into several parallel mixed-integer subproblems of smaller size.\nSimulations demonstrate the high degree of accuracy and affordable\ncomputational requirements of our approach. \n\n"}
{"id": "1710.04093", "contents": "Title: Efficient MCMC for Gibbs Random Fields using pre-computation Abstract: Bayesian inference of Gibbs random fields (GRFs) is often referred to as a\ndoubly intractable problem, since the likelihood function is intractable. The\nexploration of the posterior distribution of such models is typically carried\nout with a sophisticated Markov chain Monte Carlo (MCMC) method, the exchange\nalgorithm (Murray et al., 2006), which requires simulations from the likelihood\nfunction at each iteration. The purpose of this paper is to consider an\napproach to dramatically reduce this computational overhead. To this end we\nintroduce a novel class of algorithms which use realizations of the GRF model,\nsimulated offline, at locations specified by a grid that spans the parameter\nspace. This strategy speeds up dramatically the posterior inference, as\nillustrated on several examples. However, using the pre-computed graphs\nintroduces a noise in the MCMC algorithm, which is no longer exact. We study\nthe theoretical behaviour of the resulting approximate MCMC algorithm and\nderive convergence bounds using a recent theoretical development on approximate\nMCMC methods. \n\n"}
{"id": "1710.05080", "contents": "Title: DSCOVR: Randomized Primal-Dual Block Coordinate Algorithms for\n  Asynchronous Distributed Optimization Abstract: Machine learning with big data often involves large optimization models. For\ndistributed optimization over a cluster of machines, frequent communication and\nsynchronization of all model parameters (optimization variables) can be very\ncostly. A promising solution is to use parameter servers to store different\nsubsets of the model parameters, and update them asynchronously at different\nmachines using local datasets. In this paper, we focus on distributed\noptimization of large linear models with convex loss functions, and propose a\nfamily of randomized primal-dual block coordinate algorithms that are\nespecially suitable for asynchronous distributed implementation with parameter\nservers. In particular, we work with the saddle-point formulation of such\nproblems which allows simultaneous data and model partitioning, and exploit its\nstructure by doubly stochastic coordinate optimization with variance reduction\n(DSCOVR). Compared with other first-order distributed algorithms, we show that\nDSCOVR may require less amount of overall computation and communication, and\nless or no synchronization. We discuss the implementation details of the DSCOVR\nalgorithms, and present numerical experiments on an industrial distributed\ncomputing system. \n\n"}
{"id": "1710.05133", "contents": "Title: Tracking Moving Agents via Inexact Online Gradient Descent Algorithm Abstract: Multi-agent systems are being increasingly deployed in challenging\nenvironments for performing complex tasks such as multi-target tracking,\nsearch-and-rescue, and intrusion detection. Notwithstanding the computational\nlimitations of individual robots, such systems rely on collaboration to sense\nand react to the environment. This paper formulates the generic target tracking\nproblem as a time-varying optimization problem and puts forth an inexact online\ngradient descent method for solving it sequentially. The performance of the\nproposed algorithm is studied by characterizing its dynamic regret, a notion\ncommon to the online learning literature. Building upon the existing results,\nwe provide improved regret rates that not only allow non-strongly convex costs\nbut also explicating the role of the cumulative gradient error. Two distinct\nclasses of problems are considered: one in which the objective function adheres\nto a quadratic growth condition, and another where the objective function is\nconvex but the variable belongs to a compact domain. For both cases, results\nare developed while allowing the error to be either adversarial or arising from\na white noise process. Further, the generality of the proposed framework is\ndemonstrated by developing online variants of existing stochastic gradient\nalgorithms and interpreting them as special cases of the proposed inexact\ngradient method. The efficacy of the proposed inexact gradient framework is\nestablished on a multi-agent multi-target tracking problem, while its\nflexibility is exemplified by generating online movie recommendations for\nMovielens $10$M dataset. \n\n"}
{"id": "1710.05778", "contents": "Title: A successive difference-of-convex approximation method for a class of\n  nonconvex nonsmooth optimization problems Abstract: We consider a class of nonconvex nonsmooth optimization problems whose\nobjective is the sum of a smooth function and a finite number of nonnegative\nproper closed possibly nonsmooth functions (whose proximal mappings are easy to\ncompute), some of which are further composed with linear maps. This kind of\nproblems arises naturally in various applications when different regularizers\nare introduced for inducing simultaneous structures in the solutions. Solving\nthese problems, however, can be challenging because of the coupled nonsmooth\nfunctions: the corresponding proximal mapping can be hard to compute so that\nstandard first-order methods such as the proximal gradient algorithm cannot be\napplied efficiently. In this paper, we propose a successive\ndifference-of-convex approximation method for solving this kind of problems. In\nthis algorithm, we approximate the nonsmooth functions by their Moreau\nenvelopes in each iteration. Making use of the simple observation that Moreau\nenvelopes of nonnegative proper closed functions are continuous {\\em\ndifference-of-convex} functions, we can then approximately minimize the\napproximation function by first-order methods with suitable majorization\ntechniques. These first-order methods can be implemented efficiently thanks to\nthe fact that the proximal mapping of {\\em each} nonsmooth function is easy to\ncompute. Under suitable assumptions, we prove that the sequence generated by\nour method is bounded and any accumulation point is a stationary point of the\nobjective. We also discuss how our method can be applied to concrete\napplications such as nonconvex fused regularized optimization problems and\nsimultaneously structured matrix optimization problems, and illustrate the\nperformance numerically for these two specific applications. \n\n"}
{"id": "1710.05778", "contents": "Title: A successive difference-of-convex approximation method for a class of\n  nonconvex nonsmooth optimization problems Abstract: We consider a class of nonconvex nonsmooth optimization problems whose\nobjective is the sum of a smooth function and a finite number of nonnegative\nproper closed possibly nonsmooth functions (whose proximal mappings are easy to\ncompute), some of which are further composed with linear maps. This kind of\nproblems arises naturally in various applications when different regularizers\nare introduced for inducing simultaneous structures in the solutions. Solving\nthese problems, however, can be challenging because of the coupled nonsmooth\nfunctions: the corresponding proximal mapping can be hard to compute so that\nstandard first-order methods such as the proximal gradient algorithm cannot be\napplied efficiently. In this paper, we propose a successive\ndifference-of-convex approximation method for solving this kind of problems. In\nthis algorithm, we approximate the nonsmooth functions by their Moreau\nenvelopes in each iteration. Making use of the simple observation that Moreau\nenvelopes of nonnegative proper closed functions are continuous {\\em\ndifference-of-convex} functions, we can then approximately minimize the\napproximation function by first-order methods with suitable majorization\ntechniques. These first-order methods can be implemented efficiently thanks to\nthe fact that the proximal mapping of {\\em each} nonsmooth function is easy to\ncompute. Under suitable assumptions, we prove that the sequence generated by\nour method is bounded and any accumulation point is a stationary point of the\nobjective. We also discuss how our method can be applied to concrete\napplications such as nonconvex fused regularized optimization problems and\nsimultaneously structured matrix optimization problems, and illustrate the\nperformance numerically for these two specific applications. \n\n"}
{"id": "1710.05895", "contents": "Title: Spectral Algorithms for Computing Fair Support Vector Machines Abstract: Classifiers and rating scores are prone to implicitly codifying biases, which\nmay be present in the training data, against protected classes (i.e., age,\ngender, or race). So it is important to understand how to design classifiers\nand scores that prevent discrimination in predictions. This paper develops\ncomputationally tractable algorithms for designing accurate but fair support\nvector machines (SVM's). Our approach imposes a constraint on the covariance\nmatrices conditioned on each protected class, which leads to a nonconvex\nquadratic constraint in the SVM formulation. We develop iterative algorithms to\ncompute fair linear and kernel SVM's, which solve a sequence of relaxations\nconstructed using a spectral decomposition of the nonconvex constraint. Its\neffectiveness in achieving high prediction accuracy while ensuring fairness is\nshown through numerical experiments on several data sets. \n\n"}
{"id": "1710.07702", "contents": "Title: On the Consistency of Graph-based Bayesian Learning and the Scalability\n  of Sampling Algorithms Abstract: A popular approach to semi-supervised learning proceeds by endowing the input\ndata with a graph structure in order to extract geometric information and\nincorporate it into a Bayesian framework. We introduce new theory that gives\nappropriate scalings of graph parameters that provably lead to a well-defined\nlimiting posterior as the size of the unlabeled data set grows. Furthermore, we\nshow that these consistency results have profound algorithmic implications.\nWhen consistency holds, carefully designed graph-based Markov chain Monte Carlo\nalgorithms are proved to have a uniform spectral gap, independent of the number\nof unlabeled inputs. Several numerical experiments corroborate both the\nstatistical consistency and the algorithmic scalability established by the\ntheory. \n\n"}
{"id": "1710.07886", "contents": "Title: Iteratively reweighted $\\ell_1$ algorithms with extrapolation Abstract: Iteratively reweighted $\\ell_1$ algorithm is a popular algorithm for solving\na large class of optimization problems whose objective is the sum of a\nLipschitz differentiable loss function and a possibly nonconvex sparsity\ninducing regularizer. In this paper, motivated by the success of extrapolation\ntechniques in accelerating first-order methods, we study how widely used\nextrapolation techniques such as those in [4,5,22,28] can be incorporated to\npossibly accelerate the iteratively reweighted $\\ell_1$ algorithm. We consider\nthree versions of such algorithms. For each version, we exhibit an explicitly\ncheckable condition on the extrapolation parameters so that the sequence\ngenerated provably clusters at a stationary point of the optimization problem.\nWe also investigate global convergence under additional Kurdyka-$\\L$ojasiewicz\nassumptions on certain potential functions. Our numerical experiments show that\nour algorithms usually outperform the general iterative shrinkage and\nthresholding algorithm in [21] and an adaptation of the iteratively reweighted\n$\\ell_1$ algorithm in [23, Algorithm 7] with nonmonotone line-search for\nsolving random instances of log penalty regularized least squares problems in\nterms of both CPU time and solution quality. \n\n"}
{"id": "1710.08234", "contents": "Title: Generalized incompressible flows, multi-marginal transport and Sinkhorn\n  algorithm Abstract: Starting from Brenier's relaxed formulation of the incompressible Euler\nequation in terms of geodesics in the group of measure-preserving\ndiffeomorphisms, we propose a numerical method based on Sinkhorn's algorithm\nfor the entropic regularization of optimal transport. We also make a detailed\ncomparison of this entropic regularization with the so-called Bredinger\nentropic interpolation problem. Numerical results in dimension one and two\nillustrate the feasibility of the method. \n\n"}
{"id": "1710.08976", "contents": "Title: A class of multi-resolution approximations for large spatial datasets Abstract: Gaussian processes are popular and flexible models for spatial, temporal, and\nfunctional data, but they are computationally infeasible for large datasets. We\ndiscuss Gaussian-process approximations that use basis functions at multiple\nresolutions to achieve fast inference and that can (approximately) represent\nany spatial covariance structure. We consider two special cases of this\nmulti-resolution-approximation framework, a taper version and a\ndomain-partitioning (block) version. We describe theoretical properties and\ninference procedures, and study the computational complexity of the methods.\nNumerical comparisons and an application to satellite data are also provided. \n\n"}
{"id": "1710.09997", "contents": "Title: Zeroth Order Nonconvex Multi-Agent Optimization over Networks Abstract: In this paper, we consider distributed optimization problems over a\nmulti-agent network, where each agent can only partially evaluate the objective\nfunction, and it is allowed to exchange messages with its immediate neighbors.\nDifferently from all existing works on distributed optimization, our focus is\ngiven to optimizing a class of non-convex problems, and under the challenging\nsetting where each agent can only access the zeroth-order information (i.e.,\nthe functional values) of its local functions. For different types of network\ntopologies such as undirected connected networks or star networks, we develop\nefficient distributed algorithms and rigorously analyze their convergence and\nrate of convergence (to the set of stationary solutions). Numerical results are\nprovided to demonstrate the efficiency of the proposed algorithms. \n\n"}
{"id": "1710.10329", "contents": "Title: Lower Bounds for Higher-Order Convex Optimization Abstract: State-of-the-art methods in convex and non-convex optimization employ\nhigher-order derivative information, either implicitly or explicitly. We\nexplore the limitations of higher-order optimization and prove that even for\nconvex optimization, a polynomial dependence on the approximation guarantee and\nhigher-order smoothness parameters is necessary. As a special case, we show\nNesterov's accelerated cubic regularization method to be nearly tight. \n\n"}
{"id": "1710.10770", "contents": "Title: Riemannian Optimization via Frank-Wolfe Methods Abstract: We study projection-free methods for constrained Riemannian optimization. In\nparticular, we propose the Riemannian Frank-Wolfe (RFW) method. We analyze\nnon-asymptotic convergence rates of RFW to an optimum for (geodesically) convex\nproblems, and to a critical point for nonconvex objectives. We also present a\npractical setting under which RFW can attain a linear convergence rate. As a\nconcrete example, we specialize RFW to the manifold of positive definite\nmatrices and apply it to two tasks: (i) computing the matrix geometric mean\n(Riemannian centroid); and (ii) computing the Bures-Wasserstein barycenter.\nBoth tasks involve geodesically convex interval constraints, for which we show\nthat the Riemannian \"linear\" oracle required by RFW admits a closed-form\nsolution; this result may be of independent interest. We further specialize RFW\nto the special orthogonal group and show that here too, the Riemannian \"linear\"\noracle can be solved in closed form. Here, we describe an application to the\nsynchronization of data matrices (Procrustes problem). We complement our\ntheoretical results with an empirical comparison of RFW against\nstate-of-the-art Riemannian optimization methods and observe that RFW performs\ncompetitively on the task of computing Riemannian centroids. \n\n"}
{"id": "1710.10928", "contents": "Title: Optimization Landscape and Expressivity of Deep CNNs Abstract: We analyze the loss landscape and expressiveness of practical deep\nconvolutional neural networks (CNNs) with shared weights and max pooling\nlayers. We show that such CNNs produce linearly independent features at a\n\"wide\" layer which has more neurons than the number of training samples. This\ncondition holds e.g. for the VGG network. Furthermore, we provide for such wide\nCNNs necessary and sufficient conditions for global minima with zero training\nerror. For the case where the wide layer is followed by a fully connected layer\nwe show that almost every critical point of the empirical loss is a global\nminimum with zero training error. Our analysis suggests that both depth and\nwidth are very important in deep learning. While depth brings more\nrepresentational power and allows the network to learn high level features,\nwidth smoothes the optimization landscape of the loss function in the sense\nthat a sufficiently wide network has a well-behaved loss surface with almost no\nbad local minima. \n\n"}
{"id": "1711.00501", "contents": "Title: Learning One-hidden-layer Neural Networks with Landscape Design Abstract: We consider the problem of learning a one-hidden-layer neural network: we\nassume the input $x\\in \\mathbb{R}^d$ is from Gaussian distribution and the\nlabel $y = a^\\top \\sigma(Bx) + \\xi$, where $a$ is a nonnegative vector in\n$\\mathbb{R}^m$ with $m\\le d$, $B\\in \\mathbb{R}^{m\\times d}$ is a full-rank\nweight matrix, and $\\xi$ is a noise vector. We first give an analytic formula\nfor the population risk of the standard squared loss and demonstrate that it\nimplicitly attempts to decompose a sequence of low-rank tensors simultaneously.\n  Inspired by the formula, we design a non-convex objective function $G(\\cdot)$\nwhose landscape is guaranteed to have the following properties: 1. All local\nminima of $G$ are also global minima.\n  2. All global minima of $G$ correspond to the ground truth parameters.\n  3. The value and gradient of $G$ can be estimated using samples.\n  With these properties, stochastic gradient descent on $G$ provably converges\nto the global minimum and learn the ground-truth parameters. We also prove\nfinite sample complexity result and validate the results by simulations. \n\n"}
{"id": "1711.00946", "contents": "Title: Learning Linear Dynamical Systems via Spectral Filtering Abstract: We present an efficient and practical algorithm for the online prediction of\ndiscrete-time linear dynamical systems with a symmetric transition matrix. We\ncircumvent the non-convex optimization problem using improper learning:\ncarefully overparameterize the class of LDSs by a polylogarithmic factor, in\nexchange for convexity of the loss functions. From this arises a\npolynomial-time algorithm with a near-optimal regret guarantee, with an\nanalogous sample complexity bound for agnostic learning. Our algorithm is based\non a novel filtering technique, which may be of independent interest: we\nconvolve the time series with the eigenvectors of a certain Hankel matrix. \n\n"}
{"id": "1711.00987", "contents": "Title: Analysis of Biased Stochastic Gradient Descent Using Sequential\n  Semidefinite Programs Abstract: We present a convergence rate analysis for biased stochastic gradient descent\n(SGD), where individual gradient updates are corrupted by computation errors.\nWe develop stochastic quadratic constraints to formulate a small linear matrix\ninequality (LMI) whose feasible points lead to convergence bounds of biased\nSGD. Based on this LMI condition, we develop a sequential minimization approach\nto analyze the intricate trade-offs that couple stepsize selection, convergence\nrate, optimization accuracy, and robustness to gradient inaccuracy. We also\nprovide feasible points for this LMI and obtain theoretical formulas that\nquantify the convergence properties of biased SGD under various assumptions on\nthe loss functions. \n\n"}
{"id": "1711.01396", "contents": "Title: Separation-Free Super-Resolution from Compressed Measurements is\n  Possible: an Orthonormal Atomic Norm Minimization Approach Abstract: We consider the problem of recovering the superposition of $R$ distinct\ncomplex exponential functions from compressed non-uniform time-domain samples.\nTotal Variation (TV) minimization or atomic norm minimization was proposed in\nthe literature to recover the $R$ frequencies or the missing data. However, it\nis known that in order for TV minimization and atomic norm minimization to\nrecover the missing data or the frequencies, the underlying $R$ frequencies are\nrequired to be well-separated, even when the measurements are noiseless. This\npaper shows that the Hankel matrix recovery approach can super-resolve the $R$\ncomplex exponentials and their frequencies from compressed non-uniform\nmeasurements, regardless of how close their frequencies are to each other. We\npropose a new concept of orthonormal atomic norm minimization (OANM), and\ndemonstrate that the success of Hankel matrix recovery in separation-free\nsuper-resolution comes from the fact that the nuclear norm of a Hankel matrix\nis an orthonormal atomic norm. More specifically, we show that, in traditional\natomic norm minimization, the underlying parameter values $\\textbf{must}$ be\nwell separated to achieve successful signal recovery, if the atoms are changing\ncontinuously with respect to the continuously-valued parameter. In contrast,\nfor the OANM, it is possible the OANM is successful even though the original\natoms can be arbitrarily close.\n  As a byproduct of this research, we provide one matrix-theoretic inequality\nof nuclear norm, and give its proof from the theory of compressed sensing. \n\n"}
{"id": "1711.01761", "contents": "Title: AdaBatch: Efficient Gradient Aggregation Rules for Sequential and\n  Parallel Stochastic Gradient Methods Abstract: We study a new aggregation operator for gradients coming from a mini-batch\nfor stochastic gradient (SG) methods that allows a significant speed-up in the\ncase of sparse optimization problems. We call this method AdaBatch and it only\nrequires a few lines of code change compared to regular mini-batch SGD\nalgorithms. We provide a theoretical insight to understand how this new class\nof algorithms is performing and show that it is equivalent to an implicit\nper-coordinate rescaling of the gradients, similarly to what Adagrad methods\ncan do. In theory and in practice, this new aggregation allows to keep the same\nsample efficiency of SG methods while increasing the batch size.\nExperimentally, we also show that in the case of smooth convex optimization,\nour procedure can even obtain a better loss when increasing the batch size for\na fixed number of samples. We then apply this new algorithm to obtain a\nparallelizable stochastic gradient method that is synchronous but allows\nspeed-up on par with Hogwild! methods as convergence does not deteriorate with\nthe increase of the batch size. The same approach can be used to make\nmini-batch provably efficient for variance-reduced SG methods such as SVRG. \n\n"}
{"id": "1711.02838", "contents": "Title: Stochastic Cubic Regularization for Fast Nonconvex Optimization Abstract: This paper proposes a stochastic variant of a classic algorithm---the\ncubic-regularized Newton method [Nesterov and Polyak 2006]. The proposed\nalgorithm efficiently escapes saddle points and finds approximate local minima\nfor general smooth, nonconvex functions in only\n$\\mathcal{\\tilde{O}}(\\epsilon^{-3.5})$ stochastic gradient and stochastic\nHessian-vector product evaluations. The latter can be computed as efficiently\nas stochastic gradients. This improves upon the\n$\\mathcal{\\tilde{O}}(\\epsilon^{-4})$ rate of stochastic gradient descent. Our\nrate matches the best-known result for finding local minima without requiring\nany delicate acceleration or variance-reduction techniques. \n\n"}
{"id": "1711.03439", "contents": "Title: Smooth Primal-Dual Coordinate Descent Algorithms for Nonsmooth Convex\n  Optimization Abstract: We propose a new randomized coordinate descent method for a convex\noptimization template with broad applications. Our analysis relies on a novel\ncombination of four ideas applied to the primal-dual gap function: smoothing,\nacceleration, homotopy, and coordinate descent with non-uniform sampling. As a\nresult, our method features the first convergence rate guarantees among the\ncoordinate descent methods, that are the best-known under a variety of common\nstructure assumptions on the template. We provide numerical evidence to support\nthe theoretical results with a comparison to state-of-the-art algorithms. \n\n"}
{"id": "1711.04965", "contents": "Title: Near-optimal sample complexity for convex tensor completion Abstract: We analyze low rank tensor completion (TC) using noisy measurements of a\nsubset of the tensor. Assuming a rank-$r$, order-$d$, $N \\times N \\times \\cdots\n\\times N$ tensor where $r=O(1)$, the best sampling complexity that was achieved\nis $O(N^{\\frac{d}{2}})$, which is obtained by solving a tensor nuclear-norm\nminimization problem. However, this bound is significantly larger than the\nnumber of free variables in a low rank tensor which is $O(dN)$. In this paper,\nwe show that by using an atomic-norm whose atoms are rank-$1$ sign tensors, one\ncan obtain a sample complexity of $O(dN)$. Moreover, we generalize the matrix\nmax-norm definition to tensors, which results in a max-quasi-norm (max-qnorm)\nwhose unit ball has small Rademacher complexity. We prove that solving a\nconstrained least squares estimation using either the convex atomic-norm or the\nnonconvex max-qnorm results in optimal sample complexity for the problem of\nlow-rank tensor completion. Furthermore, we show that these bounds are nearly\nminimax rate-optimal. We also provide promising numerical results for max-qnorm\nconstrained tensor completion, showing improved recovery results compared to\nmatricization and alternating least squares. \n\n"}
{"id": "1711.06673", "contents": "Title: Neon2: Finding Local Minima via First-Order Oracles Abstract: We propose a reduction for non-convex optimization that can (1) turn an\nstationary-point finding algorithm into an local-minimum finding one, and (2)\nreplace the Hessian-vector product computations with only gradient\ncomputations. It works both in the stochastic and the deterministic settings,\nwithout hurting the algorithm's performance.\n  As applications, our reduction turns Natasha2 into a first-order method\nwithout hurting its performance. It also converts SGD, GD, SCSG, and SVRG into\nalgorithms finding approximate local minima, outperforming some best known\nresults. \n\n"}
{"id": "1711.06831", "contents": "Title: Proximal Gradient Method with Extrapolation and Line Search for a Class\n  of Nonconvex and Nonsmooth Problems Abstract: In this paper, we consider a class of possibly nonconvex, nonsmooth and\nnon-Lipschitz optimization problems arising in many contemporary applications\nsuch as machine learning, variable selection and image processing. To solve\nthis class of problems, we propose a proximal gradient method with\nextrapolation and line search (PGels). This method is developed based on a\nspecial potential function and successfully incorporates both extrapolation and\nnon-monotone line search, which are two simple and efficient accelerating\ntechniques for the proximal gradient method. Thanks to the line search, this\nmethod allows more flexibilities in choosing the extrapolation parameters and\nupdates them adaptively at each iteration if a certain line search criterion is\nnot satisfied. Moreover, with proper choices of parameters, our PGels reduces\nto many existing algorithms. We also show that, under some mild conditions, our\nline search criterion is well defined and any cluster point of the sequence\ngenerated by PGels is a stationary point of our problem. In addition, by\nassuming the Kurdyka-${\\L}$ojasiewicz exponent of the objective in our problem,\nwe further analyze the local convergence rate of two special cases of PGels,\nincluding the widely used non-monotone proximal gradient method as one case.\nFinally, we conduct some numerical experiments for solving the $\\ell_1$\nregularized logistic regression problem and the $\\ell_{1\\text{-}2}$ regularized\nleast squares problem. Our numerical results illustrate the efficiency of PGels\nand show the potential advantage of combining two accelerating techniques. \n\n"}
{"id": "1711.11181", "contents": "Title: Strategic Topology Switching for Security-Part II: Detection & Switching\n  Topologies Abstract: This two-part paper considers strategic topology switching for security in\nthe second-order multi-agent system. In Part II, we propose a strategy on\nswitching topologies to detect zero-dynamics attack (ZDA), whose\nattack-starting time is allowed to be not the initial time. We first\ncharacterize the sufficient and necessary condition for detectability of ZDA,\nin terms of the network topologies to be switched to and the set of agents to\nbe monitored. We then propose an attack detection algorithm based on the\nLuenberger observer, using the characterized detectability condition. Employing\nthe strategy on switching times proposed in Part I and the strategy on\nswitching topologies proposed here, a strategic topology-switching algorithm is\nderived. Its primary advantages are threefold: (i) in achieving consensus in\nthe absence of attacks, the control protocol does not need velocity\nmeasurements and the algorithm has no constraint on the magnitudes of coupling\nweights; (ii) in tracking system in the absence of attacks, the Luenberger\nobserver has no constraint on the magnitudes of observer gains and the number\nof monitored agents, i.e., only one monitored agent's output is sufficient;\n(iii) in detecting ZDA, the algorithm allows the defender to have no knowledge\nof the attack-starting time and the number of misbehaving agents (i.e., agents\nunder attack). Simulations are provided to verify the effectiveness of the\nstrategic topology-switching algorithm. \n\n"}
{"id": "1712.00301", "contents": "Title: Towards Time-Limited $\\mathcal H_2$-Optimal Model Order Reduction Abstract: In order to solve partial differential equations numerically and accurately,\na high order spatial discretization is usually needed. Model order reduction\n(MOR) techniques are often used to reduce the order of spatially-discretized\nsystems and hence reduce computational complexity. A particular class of MOR\ntechniques are $\\mathcal H_2$-optimal methods such as the iterative rational\nKrylov subspace algorithm (IRKA) and related schemes. However, these methods\nare used to obtain good approximations on a infinite time-horizon. Thus, in\nthis work, our main goal is to discuss MOR schemes for time-limited linear\nsystems. For this, we propose an alternative time-limited $\\mathcal H_2$-norm\nand show its connection with the time-limited Gramians. We then provide\nfirst-order optimality conditions for an optimal reduced order model (ROM) with\nrespect to the time-limited $\\mathcal H_2$-norm. Based on these optimality\nconditions, we propose an iterative scheme, which, upon convergence, aims at\nsatisfying these conditions approximately. Then, we analyze how far away the\nobtained ROM due to the proposed algorithm is from satisfying the optimality\nconditions. We test the efficiency of the proposed iterative scheme using\nvarious numerical examples and illustrate that the newly proposed iterative\nmethod can lead to a better reduced-order compared to the unrestricted IRKA in\nthe finite time interval of interest. \n\n"}
{"id": "1712.00424", "contents": "Title: The reparameterization trick for acquisition functions Abstract: Bayesian optimization is a sample-efficient approach to solving global\noptimization problems. Along with a surrogate model, this approach relies on\ntheoretically motivated value heuristics (acquisition functions) to guide the\nsearch process. Maximizing acquisition functions yields the best performance;\nunfortunately, this ideal is difficult to achieve since optimizing acquisition\nfunctions per se is frequently non-trivial. This statement is especially true\nin the parallel setting, where acquisition functions are routinely non-convex,\nhigh-dimensional, and intractable. Here, we demonstrate how many popular\nacquisition functions can be formulated as Gaussian integrals amenable to the\nreparameterization trick and, ensuingly, gradient-based optimization. Further,\nwe use this reparameterized representation to derive an efficient Monte Carlo\nestimator for the upper confidence bound acquisition function in the context of\nparallel selection. \n\n"}
{"id": "1712.00716", "contents": "Title: Convolutional Phase Retrieval via Gradient Descent Abstract: We study the convolutional phase retrieval problem, of recovering an unknown\nsignal $\\mathbf x \\in \\mathbb C^n $ from $m$ measurements consisting of the\nmagnitude of its cyclic convolution with a given kernel $\\mathbf a \\in \\mathbb\nC^m $. This model is motivated by applications such as channel estimation,\noptics, and underwater acoustic communication, where the signal of interest is\nacted on by a given channel/filter, and phase information is difficult or\nimpossible to acquire. We show that when $\\mathbf a$ is random and the number\nof observations $m$ is sufficiently large, with high probability $\\mathbf x$\ncan be efficiently recovered up to a global phase shift using a combination of\nspectral initialization and generalized gradient descent. The main challenge is\ncoping with dependencies in the measurement operator. We overcome this\nchallenge by using ideas from decoupling theory, suprema of chaos processes and\nthe restricted isometry property of random circulant matrices, and recent\nanalysis of alternating minimization methods. \n\n"}
{"id": "1712.00779", "contents": "Title: Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of\n  Spurious Local Minima Abstract: We consider the problem of learning a one-hidden-layer neural network with\nnon-overlapping convolutional layer and ReLU activation, i.e., $f(\\mathbf{Z},\n\\mathbf{w}, \\mathbf{a}) = \\sum_j a_j\\sigma(\\mathbf{w}^T\\mathbf{Z}_j)$, in which\nboth the convolutional weights $\\mathbf{w}$ and the output weights $\\mathbf{a}$\nare parameters to be learned. When the labels are the outputs from a teacher\nnetwork of the same architecture with fixed weights $(\\mathbf{w}^*,\n\\mathbf{a}^*)$, we prove that with Gaussian input $\\mathbf{Z}$, there is a\nspurious local minimizer. Surprisingly, in the presence of the spurious local\nminimizer, gradient descent with weight normalization from randomly initialized\nweights can still be proven to recover the true parameters with constant\nprobability, which can be boosted to probability $1$ with multiple restarts. We\nalso show that with constant probability, the same procedure could also\nconverge to the spurious local minimum, showing that the local minimum plays a\nnon-trivial role in the dynamics of gradient descent. Furthermore, a\nquantitative analysis shows that the gradient descent dynamics has two phases:\nit starts off slow, but converges much faster after several iterations. \n\n"}
{"id": "1712.01033", "contents": "Title: NEON+: Accelerated Gradient Methods for Extracting Negative Curvature\n  for Non-Convex Optimization Abstract: Accelerated gradient (AG) methods are breakthroughs in convex optimization,\nimproving the convergence rate of the gradient descent method for optimization\nwith smooth functions. However, the analysis of AG methods for non-convex\noptimization is still limited. It remains an open question whether AG methods\nfrom convex optimization can accelerate the convergence of the gradient descent\nmethod for finding local minimum of non-convex optimization problems. This\npaper provides an affirmative answer to this question. In particular, we\nanalyze two renowned variants of AG methods (namely Polyak's Heavy Ball method\nand Nesterov's Accelerated Gradient method) for extracting the negative\ncurvature from random noise, which is central to escaping from saddle points.\nBy leveraging the proposed AG methods for extracting the negative curvature, we\npresent a new AG algorithm with double loops for non-convex\noptimization~\\footnote{this is in contrast to a single-loop AG algorithm\nproposed in a recent manuscript~\\citep{AGNON}, which directly analyzed the\nNesterov's AG method for non-convex optimization and appeared online on\nNovember 29, 2017. However, we emphasize that our work is an independent work,\nwhich is inspired by our earlier work~\\citep{NEON17} and is based on a\ndifferent novel analysis.}, which converges to second-order stationary point\n$\\x$ such that $\\|\\nabla f(\\x)\\|\\leq \\epsilon$ and $\\nabla^2 f(\\x)\\geq\n-\\sqrt{\\epsilon} I$ with $\\widetilde O(1/\\epsilon^{1.75})$ iteration\ncomplexity, improving that of gradient descent method by a factor of\n$\\epsilon^{-0.25}$ and matching the best iteration complexity of second-order\nHessian-free methods for non-convex optimization. \n\n"}
{"id": "1712.02009", "contents": "Title: On the nonparametric maximum likelihood estimator for Gaussian location\n  mixture densities with application to Gaussian denoising Abstract: We study the Nonparametric Maximum Likelihood Estimator (NPMLE) for\nestimating Gaussian location mixture densities in $d$-dimensions from\nindependent observations. Unlike usual likelihood-based methods for fitting\nmixtures, NPMLEs are based on convex optimization. We prove finite sample\nresults on the Hellinger accuracy of every NPMLE. Our results imply, in\nparticular, that every NPMLE achieves near parametric risk (up to logarithmic\nmultiplicative factors) when the true density is a discrete Gaussian mixture\nwithout any prior information on the number of mixture components. NPMLEs can\nnaturally be used to yield empirical Bayes estimates of the Oracle Bayes\nestimator in the Gaussian denoising problem. We prove bounds for the accuracy\nof the empirical Bayes estimate as an approximation to the Oracle Bayes\nestimator. Here our results imply that the empirical Bayes estimator performs\nat nearly the optimal level (up to logarithmic multiplicative factors) for\ndenoising in clustering situations without any prior knowledge of the number of\nclusters. \n\n"}
{"id": "1712.02083", "contents": "Title: A Local Analysis of Block Coordinate Descent for Gaussian Phase\n  Retrieval Abstract: While convergence of the Alternating Direction Method of Multipliers (ADMM)\non convex problems is well studied, convergence on nonconvex problems is only\npartially understood. In this paper, we consider the Gaussian phase retrieval\nproblem, formulated as a linear constrained optimization problem with a\nbiconvex objective. The particular structure allows for a novel application of\nthe ADMM. It can be shown that the dual variable is zero at the global\nminimizer. This motivates the analysis of a block coordinate descent algorithm,\nwhich is equivalent to the ADMM with the dual variable fixed to be zero. We\nshow that the block coordinate descent algorithm converges to the global\nminimizer at a linear rate, when starting from a deterministically achievable\ninitialization point. \n\n"}
{"id": "1712.02164", "contents": "Title: On the Singular Control of Exchange Rates Abstract: Consider the problem of a central bank that wants to manage the exchange rate\nbetween its domestic currency and a foreign one. The central bank can purchase\nand sell the foreign currency, and each intervention on the exchange market\nleads to a proportional cost whose instantaneous marginal value depends on the\ncurrent level of the exchange rate. The central bank aims at minimizing the\ntotal expected costs of interventions on the exchange market, plus a total\nexpected holding cost. We formulate this problem as an infinite time-horizon\nstochastic control problem with controls that have paths which are locally of\nbounded variation. The exchange rate evolves as a general linearly controlled\none-dimensional diffusion, and the two nondecreasing processes giving the\nminimal decomposition of a bounded-variation control model the cumulative\namount of foreign currency that has been purchased and sold by the central\nbank. We provide a complete solution to this problem by finding the explicit\nexpression of the value function and a complete characterization of the optimal\ncontrol. At each instant of time, the optimally controlled exchange rate is\nkept within a band whose size is endogenously determined as part of the\nsolution to the problem. We also study the expected exit time from the band,\nand the sensitivity of the width of the band with respect to the model's\nparameters in the case when the exchange rate evolves (in absence of any\nintervention) as an Ornstein-Uhlenbeck process, and the marginal costs of\ncontrols are constant. The techniques employed in the paper are those of the\ntheory of singular stochastic control and of one-dimensional diffusions. \n\n"}
{"id": "1712.02249", "contents": "Title: Online and Batch Supervised Background Estimation via L1 Regression Abstract: We propose a surprisingly simple model for supervised video background\nestimation. Our model is based on $\\ell_1$ regression. As existing methods for\n$\\ell_1$ regression do not scale to high-resolution videos, we propose several\nsimple and scalable methods for solving the problem, including iteratively\nreweighted least squares, a homotopy method, and stochastic gradient descent.\nWe show through extensive experiments that our model and methods match or\noutperform the state-of-the-art online and batch methods in virtually all\nquantitative and qualitative measures. \n\n"}
{"id": "1712.03010", "contents": "Title: Coordinate Descent with Bandit Sampling Abstract: Coordinate descent methods usually minimize a cost function by updating a\nrandom decision variable (corresponding to one coordinate) at a time. Ideally,\nwe would update the decision variable that yields the largest decrease in the\ncost function. However, finding this coordinate would require checking all of\nthem, which would effectively negate the improvement in computational\ntractability that coordinate descent is intended to afford. To address this, we\npropose a new adaptive method for selecting a coordinate. First, we find a\nlower bound on the amount the cost function decreases when a coordinate is\nupdated. We then use a multi-armed bandit algorithm to learn which coordinates\nresult in the largest lower bound by interleaving this learning with\nconventional coordinate descent updates except that the coordinate is selected\nproportionately to the expected decrease. We show that our approach improves\nthe convergence of coordinate descent methods both theoretically and\nexperimentally. \n\n"}
{"id": "1712.06047", "contents": "Title: Avoiding Synchronization in First-Order Methods for Sparse Convex\n  Optimization Abstract: Parallel computing has played an important role in speeding up convex\noptimization methods for big data analytics and large-scale machine learning\n(ML). However, the scalability of these optimization methods is inhibited by\nthe cost of communicating and synchronizing processors in a parallel setting.\nIterative ML methods are particularly sensitive to communication cost since\nthey often require communication every iteration. In this work, we extend\nwell-known techniques from Communication-Avoiding Krylov subspace methods to\nfirst-order, block coordinate descent methods for Support Vector Machines and\nProximal Least-Squares problems. Our Synchronization-Avoiding (SA) variants\nreduce the latency cost by a tunable factor of $s$ at the expense of a factor\nof $s$ increase in flops and bandwidth costs. We show that the SA-variants are\nnumerically stable and can attain large speedups of up to $5.1\\times$ on a Cray\nXC30 supercomputer. \n\n"}
{"id": "1712.06050", "contents": "Title: Wasserstein Distributionally Robust Optimization and Variation\n  Regularization Abstract: Wasserstein distributionally robust optimization (DRO) has recently achieved\nempirical success for various applications in operations research and machine\nlearning, owing partly to its regularization effect. Although connection\nbetween Wasserstein DRO and regularization has been established in several\nsettings, existing results often require restrictive assumptions, such as\nsmoothness or convexity, that are not satisfied for many problems. In this\npaper, we develop a general theory on the variation regularization effect of\nthe Wasserstein DRO - a new form of regularization that generalizes\ntotal-variation regularization, Lipschitz regularization and gradient\nregularization. Our results cover possibly non-convex and non-smooth losses and\nlosses on non-Euclidean spaces. Examples include multi-item newsvendor,\nportfolio selection, linear prediction, neural networks, manifold learning, and\nintensity estimation for Poisson processes, etc. As an application of our\ntheory of variation regularization, we derive new generalization guarantees for\nadversarial robust learning. \n\n"}
{"id": "1712.06659", "contents": "Title: Stable Optimal Control and Semicontractive Dynamic Programming Abstract: We consider discrete-time infinite horizon deterministic optimal control\nproblems with nonnegative cost per stage, and a destination that is cost-free\nand absorbing. The classical linear-quadratic regulator problem is a special\ncase. Our assumptions are very general, and allow the possibility that the\noptimal policy may not be stabilizing the system, e.g., may not reach the\ndestination either asymptotically or in a finite number of steps. We introduce\na new unifying notion of stable feedback policy, based on perturbation of the\ncost per stage, which in addition to implying convergence of the generated\nstates to the destination, quantifies the speed of convergence. We consider the\nproperties of two distinct cost functions: $\\jstar$, the overall optimal, and\n$\\hat J$, the restricted optimal over just the stable policies. Different\nclasses of stable policies (with different speeds of convergence) may yield\ndifferent values of $\\hat J$. We show that for any class of stable policies,\n$\\hat J$ is a solution of Bellman's equation, and we characterize the smallest\nand the largest solutions: they are $\\jstar$, and $J^+$, the restricted optimal\ncost function over the class of (finitely) terminating policies. We also\ncharacterize the regions of convergence of various modified versions of value\nand policy iteration algorithms, as substitutes for the standard algorithms,\nwhich may not work in general. \n\n"}
{"id": "1712.07806", "contents": "Title: Optimal Equilibria for Time-Inconsistent Stopping Problems in Continuous\n  Time Abstract: For an infinite-horizon continuous-time optimal stopping problem under\nnon-exponential discounting, we look for an optimal equilibrium, which\ngenerates larger values than any other equilibrium does on the entire state\nspace. When the discount function is log sub-additive and the state process is\none-dimensional, an optimal equilibrium is constructed in a specific form,\nunder appropriate regularity and integrability conditions. While there may\nexist other optimal equilibria, we show that they can differ from the\nconstructed one in very limited ways. This leads to a sufficient condition for\nthe uniqueness of optimal equilibria, up to some closedness condition. To\nillustrate our theoretic results, comprehensive analysis is carried out for\nthree specific stopping problems, concerning asset liquidation and real options\nvaluation. For each one of them, an optimal equilibrium is characterized\nthrough an explicit formula. \n\n"}
{"id": "1712.08480", "contents": "Title: Convergence of the Exponentiated Gradient Method with Armijo Line Search Abstract: Consider the problem of minimizing a convex differentiable function on the\nprobability simplex, spectrahedron, or set of quantum density matrices. We\nprove that the exponentiated gradient method with Armjo line search always\nconverges to the optimum, if the sequence of the iterates possesses a strictly\npositive limit point (element-wise for the vector case, and with respect to the\nLowner partial ordering for the matrix case). To the best our knowledge, this\nis the first convergence result for a mirror descent-type method that only\nrequires differentiability. The proof exploits self-concordant likeness of the\nlog-partition function, which is of independent interest. \n\n"}
{"id": "1712.09203", "contents": "Title: Algorithmic Regularization in Over-parameterized Matrix Sensing and\n  Neural Networks with Quadratic Activations Abstract: We show that the gradient descent algorithm provides an implicit\nregularization effect in the learning of over-parameterized matrix\nfactorization models and one-hidden-layer neural networks with quadratic\nactivations. Concretely, we show that given $\\tilde{O}(dr^{2})$ random linear\nmeasurements of a rank $r$ positive semidefinite matrix $X^{\\star}$, we can\nrecover $X^{\\star}$ by parameterizing it by $UU^\\top$ with $U\\in \\mathbb\nR^{d\\times d}$ and minimizing the squared loss, even if $r \\ll d$. We prove\nthat starting from a small initialization, gradient descent recovers\n$X^{\\star}$ in $\\tilde{O}(\\sqrt{r})$ iterations approximately. The results\nsolve the conjecture of Gunasekar et al.'17 under the restricted isometry\nproperty. The technique can be applied to analyzing neural networks with\none-hidden-layer quadratic activations with some technical modifications. \n\n"}
{"id": "1712.09443", "contents": "Title: Dynamic Game-based Maintenance Scheduling of Integrated Electric and\n  Natural Gas Grids with a Bilevel Approach Abstract: This paper proposes a dynamic game-based maintenance scheduling mechanism for\nthe asset owners of the natural gas grid and the power grid by using a bilevel\napproach. In the upper level, the asset owners of the natural gas grid and the\npower grid schedule maintenance to maximize their own revenues. This level is\nmodeled as a dynamic game problem, which is solved by the backward induction\nalgorithm. In the lower level, the independent system operator (ISO) dispatches\nthe system to minimize the loss of power load and natural gas load in\nconsideration of the system operating conditions under maintenance plans from\nthe asset owners in the upper level. This is modeled as a mixed integer linear\nprogramming problem. For the model of the natural gas grid, a piecewise linear\napproximation associated with the big-M approach is used to transform the\noriginal nonlinear model into the mixed integer linear model. Numerical tests\non a 6-bus system with a 4-node gas grid show the effectiveness of the proposed\nmodel. \n\n"}
{"id": "1712.09705", "contents": "Title: Regress-Later Monte Carlo for optimal control of Markov processes Abstract: We develop two Regression Monte Carlo algorithms (value and performance\niteration) to solve general problems of optimal stochastic control of\ndiscrete-time Markov processes. We formulate our method within an innovative\nframework that allow us to prove the speed of convergence of our numerical\nschemes. We rely on the Regress Later approach unlike other attempts which\nemploy the Regress Now technique. We exploit error bounds obtained in our\nproofs, along with numerical experiments, to investigate differences between\nthe value and performance iteration approaches. Introduced in Tsitsiklis and\nVanRoy [2001] and Longstaff and Schwartz [2001] respectively, their\ncharacteristics have gone largely unnoticed in the literature; we show however\nthat their differences are paramount in practical solution of stochastic\ncontrol problems. Finally, we provide some guidelines for the tuning of our\nalgorithms. \n\n"}
{"id": "1712.10275", "contents": "Title: Time-periodic Evans approach to weak KAM theory Abstract: We study the time-periodic version of Evans approach to weak KAM theory.\nEvans minimization problem is equivalent to a first oder mean field game\nsystem. For the mechanical Hamiltonian we prove the existence of smooth\nsolutions. We introduce the corresponding effective Lagrangian and Hamiltonian\nand prove that they are smooth. We also consider the limiting behavior of the\neffective Lagrangian and Hamiltonian, Mather measures and minimizers. \n\n"}
{"id": "1801.00261", "contents": "Title: First-Order Primal-Dual Method for Nonlinear Convex Cone Programming Abstract: Nonlinear Convex Cone Programming (NCCP) problems are important and have many\npractical applications. In this paper, we introduces a flexible first-order\nprimal-dual algorithm called the Variant Auxiliary Problem Principle (VAPP) for\nsolving NCCP problems when the objective function and constraints are smooth\nand may be nonsmooth. Each iteration of VAPP generates a nonlinear\napproximation to the primal problem of an augmented Lagrangian method. The\napproximation incorporates both linearization and a variable distance-like\nfunction, and then the iterations of VAPP provide one decomposition property\nfor NCCP. Motivated by recent applications in big data analysis, there has been\nan explosive growth in interest in the convergence rate analysis of parallel\ncomputing algorithms for large scale optimization problem. This paper proposes\nan iteration-based error bound and linear convergence of VAPP. Some verifiable\nsufficient conditions of this error bound are also discussed. For the general\nconvex case (without error bound), we establish $O(1/t)$ convergence rate for\nprimal suboptimality, feasibility and dual suboptimality. By adaptively setting\nin parameters at different iterations, we show an $O(1/t^2)$ rate for the\nstrongly convex case. We further present Forward-Backward Splitting (FBS)\nformulation of VAPP method and establish the connection between VAPP and other\nprimal-dual splitting methods. Finally, we discuss some issues in the\nimplementation of VAPP. \n\n"}
{"id": "1801.00718", "contents": "Title: Selective review of offline change point detection methods Abstract: This article presents a selective survey of algorithms for the offline\ndetection of multiple change points in multivariate time series. A general yet\nstructuring methodological strategy is adopted to organize this vast body of\nwork. More precisely, detection algorithms considered in this review are\ncharacterized by three elements: a cost function, a search method and a\nconstraint on the number of changes. Each of those elements is described,\nreviewed and discussed separately. Implementations of the main algorithms\ndescribed in this article are provided within a Python package called ruptures. \n\n"}
{"id": "1801.00885", "contents": "Title: Gradient-based Optimization for Regression in the Functional\n  Tensor-Train Format Abstract: We consider the task of low-multilinear-rank functional regression, i.e.,\nlearning a low-rank parametric representation of functions from scattered\nreal-valued data. Our first contribution is the development and analysis of an\nefficient gradient computation that enables gradient-based optimization\nprocedures, including stochastic gradient descent and quasi-Newton methods, for\nlearning the parameters of a functional tensor-train (FT). The functional\ntensor-train uses the tensor-train (TT) representation of low-rank arrays as an\nansatz for a class of low-multilinear-rank functions. The FT is represented by\na set of matrix-valued functions that contain a set of univariate functions,\nand the regression task is to learn the parameters of these univariate\nfunctions. Our second contribution demonstrates that using nonlinearly\nparameterized univariate functions, e.g., symmetric kernels with moving\ncenters, within each core can outperform the standard approach of using a\nlinear expansion of basis functions. Our final contributions are new rank\nadaptation and group-sparsity regularization procedures to minimize\noverfitting. We use several benchmark problems to demonstrate at least an order\nof magnitude lower accuracy with gradient-based optimization methods than\nstandard alternating least squares procedures in the low-sample number regime.\nWe also demonstrate an order of magnitude reduction in accuracy on a test\nproblem resulting from using nonlinear parameterizations over linear\nparameterizations. Finally we compare regression performance with 22 other\nnonparametric and parametric regression methods on 10 real-world data sets. We\nachieve top-five accuracy for seven of the data sets and best accuracy for two\nof the data sets. These rankings are the best amongst parametric models and\ncompetetive with the best non-parametric methods. \n\n"}
{"id": "1801.01221", "contents": "Title: Bounded-Velocity Stochastic Control for Dynamic Resource Allocation Abstract: We consider a general class of dynamic resource allocation problems within a\nstochastic optimal control framework. This class of problems arises in a wide\nvariety of applications, each of which intrinsically involves resources of\ndifferent types and demand with uncertainty and/or variability. The goal\ninvolves dynamically allocating capacity for every resource type in order to\nserve the uncertain/variable demand, modeled as Brownian motion, and maximize\nthe discounted expected net-benefit over an infinite time horizon based on the\nrewards and costs associated with the different resource types, subject to\nflexibility constraints on the rate of change of each type of resource\ncapacity. We derive the optimal control policy within a bounded-velocity\nstochastic control setting, which includes efficient and easily implementable\nalgorithms for governing the dynamic adjustments to resource allocation\ncapacities over time. Computational experiments investigate various issues of\nboth theoretical and practical interest, quantifying the benefits of our\napproach over recent alternative optimization approaches. \n\n"}
{"id": "1801.02982", "contents": "Title: How To Make the Gradients Small Stochastically: Even Faster Convex and\n  Nonconvex SGD Abstract: Stochastic gradient descent (SGD) gives an optimal convergence rate when\nminimizing convex stochastic objectives $f(x)$. However, in terms of making the\ngradients small, the original SGD does not give an optimal rate, even when\n$f(x)$ is convex.\n  If $f(x)$ is convex, to find a point with gradient norm $\\varepsilon$, we\ndesign an algorithm SGD3 with a near-optimal rate\n$\\tilde{O}(\\varepsilon^{-2})$, improving the best known rate\n$O(\\varepsilon^{-8/3})$ of [18].\n  If $f(x)$ is nonconvex, to find its $\\varepsilon$-approximate local minimum,\nwe design an algorithm SGD5 with rate $\\tilde{O}(\\varepsilon^{-3.5})$, where\npreviously SGD variants only achieve $\\tilde{O}(\\varepsilon^{-4})$ [6, 15, 33].\nThis is no slower than the best known stochastic version of Newton's method in\nall parameter regimes [30]. \n\n"}
{"id": "1801.03017", "contents": "Title: Stochastic Optimization of Braking Energy Storage and Ventilation in a\n  Subway Station Abstract: In the Paris subway system, stations represent about one third of the overall\nenergy consumption. Within stations, ventilation is among the top consuming\ndevices; it is operated at maximum airflow all day long, for air quality\nreasons. In this paper, we present a concept of energy system that displays\ncomparable air quality while consuming much less energy. The system comprises a\nbattery that makes it possible to recover the trains braking energy, arriving\nunder the form of erratic and strong peaks. We propose an energy management\nsystem (EMS) that, at short time scale, controls energy flows and ventilation\nairflow. By using proper optimization algorithms, we manage to match supply\nwith demand, while minimizing energy daily costs. For this purpose, we have\ndesigned algorithms that take into account the braking variability. They are\nbased on the so-called Stochastic Dynamic Programming (SDP) mathematical\nframework. We fairly compare SDP based algorithms with the widespread Model\nPredictive Control (MPC) ones. First, both SDP and MPC yield energy/money\noperating savings of the order of one third, compared to the current management\nwithout battery (our figure does not include the cost of the battery). Second,\ndepending on the specific design, we observe that SDP outperforms MPC by a few\npercent, with an easier online numerical implementation. \n\n"}
{"id": "1801.03184", "contents": "Title: Known Boundary Emulation of Complex Computer Models Abstract: Computer models are now widely used across a range of scientific disciplines\nto describe various complex physical systems, however to perform full\nuncertainty quantification we often need to employ emulators. An emulator is a\nfast statistical construct that mimics the complex computer model, and greatly\naids the vastly more computationally intensive uncertainty quantification\ncalculations that a serious scientific analysis often requires. In some cases,\nthe complex model can be solved far more efficiently for certain parameter\nsettings, leading to boundaries or hyperplanes in the input parameter space\nwhere the model is essentially known. We show that for a large class of\nGaussian process style emulators, multiple boundaries can be formally\nincorporated into the emulation process, by Bayesian updating of the emulators\nwith respect to the boundaries, for trivial computational cost. The resulting\nupdated emulator equations are given analytically. This leads to emulators that\npossess increased accuracy across large portions of the input parameter space.\nWe also describe how a user can incorporate such boundaries within standard\nblack box GP emulation packages that are currently available, without altering\nthe core code. Appropriate designs of model runs in the presence of known\nboundaries are then analysed, with two kinds of general purpose designs\nproposed. We then apply the improved emulation and design methodology to an\nimportant systems biology model of hormonal crosstalk in Arabidopsis Thaliana. \n\n"}
{"id": "1801.03720", "contents": "Title: Viable Insider Markets Abstract: We consider the problem of optimal inside portfolio $\\pi(t)$ in a financial\nmarket with a corresponding wealth process $X(t)=X^{\\pi}(t)$ modelled by\n\\begin{align}\\label{eq0.1} \\begin{cases}\ndX(t)&=\\pi(t)X(t)[\\alpha(t)dt+\\beta(t)dB(t)]; \\quad t\\in[0, T] X(0)&=x_0>0,\n\\end{cases} \\end{align} where $B(\\cdot)$ is a Brownian motion. We assume that\nthe insider at time $t$ has access to market information $\\varepsilon_t>0$\nunits ahead of time, in addition to the history of the market up to time $t$.\nThe problem is to find an insider portfolio $\\pi^{*}$ which maximizes the\nexpected logarithmic utility $J(\\pi)$ of the terminal wealth, i.e. such that\n$$\\sup_{\\pi}J(\\pi)= J(\\pi^{*}), \\text {where } J(\\pi)=\n\\mathbb{E}[\\log(X^{\\pi}(T))].$$ The insider market is called \\emph{viable} if\nthis value is finite. We study under what inside information flow $\\mathbb{H}$\nthe insider market is viable or not. For example, assume that for all $t<T$ the\ninsider knows the value of $B(t+\\epsilon_t)$, where $t + \\epsilon_t \\geq T$\nconverges monotonically to $T$ from above as $t$ goes to $T$ from below. Then\n(assuming that the insider has a perfect memory) at time $t$ she has the inside\ninformation $\\mathcal{H}_t$, consisting of the history $\\mathcal{F}_t$ of\n$B(s); 0 \\leq s \\leq t$ plus all the values of Brownian motion in the interval\n$[t+\\epsilon_t, \\epsilon_0]$, i.e. we have the enlarged filtration\n\\begin{equation}\\label{eq0.2} \\mathbb{H}=\\{\\mathcal{H}_t\\}_{t\\in[0.T]},\\quad\n\\mathcal{H}_t=\\mathcal{F}_t\\vee\\sigma(B(t+\\epsilon_t+r),0\\leq r \\leq\n\\epsilon_0-t-\\epsilon_t), \\forall t\\in [0,T]. \\end{equation} Using forward\nintegrals, Hida-Malliavin calculus and Donsker delta functionals we show that\nif $$\\int_0^T\\frac{1}{\\varepsilon_t}dt=\\infty,$$ then the insider market is not\nviable. \n\n"}
{"id": "1801.04050", "contents": "Title: Communication Optimality Trade-offs For Distributed Estimation Abstract: This paper proposes $\\mathbf{C}$ommunication efficient $\\mathbf{RE}$cursive\n$\\mathbf{D}$istributed estimati$\\mathbf{O}$n algorithm, $\\mathcal{CREDO}$, for\nnetworked multi-worker setups without a central master node. $\\mathcal{CREDO}$\nis designed for scenarios in which the worker nodes aim to collaboratively\nestimate a vector parameter of interest using distributed online time-series\ndata at the individual worker nodes. The individual worker nodes iteratively\nupdate their estimate of the parameter by assimilating latest locally sensed\ninformation and estimates from neighboring worker nodes exchanged over a\n(possibly sparse) time-varying communication graph. The underlying inter-worker\ncommunication protocol is adaptive, making communications increasingly\n(probabilistically) sparse as time progresses. Under minimal conditions on the\ninter-worker information exchange network and the sensing models, almost sure\nconvergence of the estimate sequences at the worker nodes to the true parameter\nis established. Further, the paper characterizes the performance of\n$\\mathcal{CREDO}$ in terms of asymptotic covariance of the estimate sequences\nand specifically establishes the achievability of optimal asymptotic\ncovariance. The analysis reveals an interesting interplay between the\nalgorithm's communication cost~$\\mathcal{C}_{t}$ (over $t$ time-steps) and the\nasymptotic covariance. Most notably, it is shown that $\\mathcal{CREDO}$ may be\ndesigned to achieve a $\\Theta\\left(\\mathcal{C}_{t}^{-2+\\zeta}\\right)$ decay of\nthe mean square error~($\\zeta>0$, arbitrarily small) at each worker node, which\nsignificantly improves over the existing $\n\\Theta\\left(\\mathcal{C}_{t}^{-1}\\right)$ rates. Simulation examples on both\nsynthetic and real data sets demonstrate $\\mathcal{CREDO}$'s communication\nefficiency. \n\n"}
{"id": "1801.04322", "contents": "Title: Corner cases, singularities, and dynamic factoring Abstract: In Eikonal equations, rarefaction is a common phenomenon known to degrade the\nrate of convergence of numerical methods. The `factoring' approach alleviates\nthis difficulty by deriving a PDE for a new (locally smooth) variable while\ncapturing the rarefaction-related singularity in a known (non-smooth) `factor'.\nPreviously this technique was successfully used to address rarefaction fans\narising at point sources. In this paper we show how similar ideas can be used\nto factor the 2D rarefactions arising due to nonsmoothness of domain boundaries\nor discontinuities in PDE coefficients. Locations and orientations of such\nrarefaction fans are not known in advance and we construct a `just-in-time\nfactoring' method that identifies them dynamically. The resulting algorithm is\na generalization of the Fast Marching Method originally introduced for the\nregular (unfactored) Eikonal equations. We show that our approach restores the\nfirst-order convergence and illustrate it using a range of maze navigation\nexamples with non-permeable and `slowly permeable' obstacles. \n\n"}
{"id": "1801.04987", "contents": "Title: On the Complexity of the Weighted Fused Lasso Abstract: The solution path of the 1D fused lasso for an $n$-dimensional input is\npiecewise linear with $\\mathcal{O}(n)$ segments (Hoefling et al. 2010 and\nTibshirani et al 2011). However, existing proofs of this bound do not hold for\nthe weighted fused lasso. At the same time, results for the generalized lasso,\nof which the weighted fused lasso is a special case, allow $\\Omega(3^n)$\nsegments (Mairal et al. 2012). In this paper, we prove that the number of\nsegments in the solution path of the weighted fused lasso is\n$\\mathcal{O}(n^2)$, and that, for some instances, it is $\\Omega(n^2)$. We also\ngive a new, very simple, proof of the $\\mathcal{O}(n)$ bound for the fused\nlasso. \n\n"}
{"id": "1801.07389", "contents": "Title: Non-ergodic Complexity of Convex Proximal Inertial Gradient Descents Abstract: The proximal inertial gradient descent is efficient for the composite\nminimization and applicable for broad of machine learning problems. In this\npaper, we revisit the computational complexity of this algorithm and present\nother novel results, especially on the convergence rates of the objective\nfunction values. The non-ergodic O(1/k) rate is proved for proximal inertial\ngradient descent with constant stepzise when the objective function is\ncoercive. When the objective function fails to promise coercivity, we prove the\nsublinear rate with diminishing inertial parameters. In the case that the\nobjective function satisfies optimal strong convexity condition (which is much\nweaker than the strong convexity), the linear convergence is proved with much\nlarger and general stepsize than previous literature. We also extend our\nresults to the multi-block version and present the computational complexity.\nBoth cyclic and stochastic index selection strategies are considered. \n\n"}
{"id": "1801.10048", "contents": "Title: Analysis and optimal control of an intracellular delayed HIV model with\n  CTL immune response Abstract: A delayed model describing the dynamics of HIV (Human Immunodeficiency Virus)\nwith CTL (Cytotoxic T Lymphocytes) immune response is investigated. The model\nincludes four nonlinear differential equations describing the evolution of\nuninfected, infected, free HIV viruses, and CTL immune response cells. It\nincludes also intracellular delay and two treatments (two controls). While the\naim of first treatment consists to block the viral proliferation, the role of\nthe second is to prevent new infections. Firstly, we prove the well-posedness\nof the problem by establishing some positivity and boundedness results. Next,\nwe give some conditions that insure the local asymptotic stability of the\nendemic and disease-free equilibria. Finally, an optimal control problem,\nassociated with the intracellular delayed HIV model with CTL immune response,\nis posed and investigated. The problem is shown to have an unique solution,\nwhich is characterized via Pontryagin's minimum principle for problems with\ndelays. Numerical simulations are performed, confirming stability of the\ndisease-free and endemic equilibria and illustrating the effectiveness of the\ntwo incorporated treatments via optimal control. \n\n"}
{"id": "1802.00828", "contents": "Title: Comparing multiple networks using the Co-expression Differential Network\n  Analysis (CoDiNA) Abstract: Biomedical sciences are increasingly recognising the relevance of gene\nco-expression-networks for analysing complex-systems, phenotypes or diseases.\nWhen the goal is investigating complex-phenotypes under varying conditions, it\ncomes naturally to employ comparative network methods. While approaches for\ncomparing two networks exist, this is not the case for multiple networks. Here\nwe present a method for the systematic comparison of an unlimited number of\nnetworks: Co-expression Differential Network Analysis (CoDiNA) for detecting\nlinks and nodes that are common, specific or different to the networks.\nApplying CoDiNA to a neurogenesis study identified genes for neuron\ndifferentiation. Experimentally overexpressing one candidate resulted in\nsignificant disturbance in the underlying neurogenesis' gene regulatory\nnetwork. We compared data from adults and children with active tuberculosis to\ntest for signatures of HIV. We also identified common and distinct network\nfeatures for particular cancer types with CoDiNA. These studies show that\nCoDiNA successfully detects genes associated with the diseases. \n\n"}
{"id": "1802.01223", "contents": "Title: Learning Compact Neural Networks with Regularization Abstract: Proper regularization is critical for speeding up training, improving\ngeneralization performance, and learning compact models that are cost\nefficient. We propose and analyze regularized gradient descent algorithms for\nlearning shallow neural networks. Our framework is general and covers\nweight-sharing (convolutional networks), sparsity (network pruning), and\nlow-rank constraints among others. We first introduce covering dimension to\nquantify the complexity of the constraint set and provide insights on the\ngeneralization properties. Then, we show that proposed algorithms become\nwell-behaved and local linear convergence occurs once the amount of data\nexceeds the covering dimension. Overall, our results demonstrate that\nnear-optimal sample complexity is sufficient for efficient learning and\nillustrate how regularization can be beneficial to learn over-parameterized\nnetworks. \n\n"}
{"id": "1802.01499", "contents": "Title: An extreme function which is nonnegative and discontinuous everywhere Abstract: We consider Gomory and Johnson's infinite group model with a single row.\nValid inequalities for this model are expressed by valid functions and it has\nbeen recently shown that any valid function is dominated by some nonnegative\nvalid function, modulo the affine hull of the model. Within the set of\nnonnegative valid functions, extreme functions are the ones that cannot be\nexpressed as convex combinations of two distinct valid functions. In this paper\nwe construct an extreme function $\\pi:\\mathbb{R} \\to [0,1]$ whose graph is\ndense in $\\mathbb{R} \\times [0,1]$. Therefore, $\\pi$ is discontinuous\neverywhere. \n\n"}
{"id": "1802.01504", "contents": "Title: Linear Convergence of the Primal-Dual Gradient Method for Convex-Concave\n  Saddle Point Problems without Strong Convexity Abstract: We consider the convex-concave saddle point problem $\\min_{x}\\max_{y}\nf(x)+y^\\top A x-g(y)$ where $f$ is smooth and convex and $g$ is smooth and\nstrongly convex. We prove that if the coupling matrix $A$ has full column rank,\nthe vanilla primal-dual gradient method can achieve linear convergence even if\n$f$ is not strongly convex. Our result generalizes previous work which either\nrequires $f$ and $g$ to be quadratic functions or requires proximal mappings\nfor both $f$ and $g$. We adopt a novel analysis technique that in each\niteration uses a \"ghost\" update as a reference, and show that the iterates in\nthe primal-dual gradient method converge to this \"ghost\" sequence. Using the\nsame technique we further give an analysis for the primal-dual stochastic\nvariance reduced gradient (SVRG) method for convex-concave saddle point\nproblems with a finite-sum structure. \n\n"}
{"id": "1802.02538", "contents": "Title: Yes, but Did It Work?: Evaluating Variational Inference Abstract: While it's always possible to compute a variational approximation to a\nposterior distribution, it can be difficult to discover problems with this\napproximation. We propose two diagnostic algorithms to alleviate this problem.\nThe Pareto-smoothed importance sampling (PSIS) diagnostic gives a goodness of\nfit measurement for joint distributions, while simultaneously improving the\nerror in the estimate. The variational simulation-based calibration (VSBC)\nassesses the average performance of point estimates. \n\n"}
{"id": "1802.03099", "contents": "Title: Blockchain-Assisted Crowdsourced Energy Systems Abstract: Crowdsourcing relies on people's contributions to meet product- or\nsystem-level objectives. Crowdsourcing-based methods have been implemented in\nvarious cyber-physical systems and realtime markets. This paper explores a\nframework for Crowdsourced Energy Systems (CES), where small-scale energy\ngeneration or energy trading is crowdsourced from distributed energy resources,\nelectric vehicles, and shapable loads. The merits/pillars of energy\ncrowdsourcing are discussed. Then, an operational model for CESs in\ndistribution networks with different types of crowdsourcees is proposed. The\nmodel yields a market equilibrium depicting traditional and distributed\ngenerator and load setpoints. Given these setpoints, crowdsourcing incentives\nare designed to steer crowdsourcees to the equilibrium. As the number of\ncrowdsourcees and energy trading transactions scales up, a secure energy\ntrading platform is required. To that end, the presented framework is\nintegrated with a lightweight Blockchain implementation and smart contracts.\nNumerical tests are provided to showcase the overall implementation. \n\n"}
{"id": "1802.03337", "contents": "Title: Large Scale Constrained Linear Regression Revisited: Faster Algorithms\n  via Preconditioning Abstract: In this paper, we revisit the large-scale constrained linear regression\nproblem and propose faster methods based on some recent developments in\nsketching and optimization. Our algorithms combine (accelerated) mini-batch SGD\nwith a new method called two-step preconditioning to achieve an approximate\nsolution with a time complexity lower than that of the state-of-the-art\ntechniques for the low precision case. Our idea can also be extended to the\nhigh precision case, which gives an alternative implementation to the Iterative\nHessian Sketch (IHS) method with significantly improved time complexity.\nExperiments on benchmark and synthetic datasets suggest that our methods indeed\noutperform existing ones considerably in both the low and high precision cases. \n\n"}
{"id": "1802.03487", "contents": "Title: Small nonlinearities in activation functions create bad local minima in\n  neural networks Abstract: We investigate the loss surface of neural networks. We prove that even for\none-hidden-layer networks with \"slightest\" nonlinearity, the empirical risks\nhave spurious local minima in most cases. Our results thus indicate that in\ngeneral \"no spurious local minima\" is a property limited to deep linear\nnetworks, and insights obtained from linear networks may not be robust.\nSpecifically, for ReLU(-like) networks we constructively prove that for almost\nall practical datasets there exist infinitely many local minima. We also\npresent a counterexample for more general activations (sigmoid, tanh, arctan,\nReLU, etc.), for which there exists a bad local minimum. Our results make the\nleast restrictive assumptions relative to existing results on spurious local\noptima in neural networks. We complete our discussion by presenting a\ncomprehensive characterization of global optimality for deep linear networks,\nwhich unifies other results on this topic. \n\n"}
{"id": "1802.03825", "contents": "Title: Decentralized Submodular Maximization: Bridging Discrete and Continuous\n  Settings Abstract: In this paper, we showcase the interplay between discrete and continuous\noptimization in network-structured settings. We propose the first fully\ndecentralized optimization method for a wide class of non-convex objective\nfunctions that possess a diminishing returns property. More specifically, given\nan arbitrary connected network and a global continuous submodular function,\nformed by a sum of local functions, we develop Decentralized Continuous Greedy\n(DCG), a message passing algorithm that converges to the tight (1-1/e)\napproximation factor of the optimum global solution using only local\ncomputation and communication. We also provide strong convergence bounds as a\nfunction of network size and spectral characteristics of the underlying\ntopology. Interestingly, DCG readily provides a simple recipe for decentralized\ndiscrete submodular maximization through the means of continuous relaxations.\nFormally, we demonstrate that by lifting the local discrete functions to\ncontinuous domains and using DCG as an interface we can develop a consensus\nalgorithm that also achieves the tight (1-1/e) approximation guarantee of the\nglobal discrete solution once a proper rounding scheme is applied. \n\n"}
{"id": "1802.03866", "contents": "Title: Katyusha X: Practical Momentum Method for Stochastic Sum-of-Nonconvex\n  Optimization Abstract: The problem of minimizing sum-of-nonconvex functions (i.e., convex functions\nthat are average of non-convex ones) is becoming increasingly important in\nmachine learning, and is the core machinery for PCA, SVD, regularized Newton's\nmethod, accelerated non-convex optimization, and more.\n  We show how to provably obtain an accelerated stochastic algorithm for\nminimizing sum-of-nonconvex functions, by $\\textit{adding one additional line}$\nto the well-known SVRG method. This line corresponds to momentum, and shows how\nto directly apply momentum to the finite-sum stochastic minimization of\nsum-of-nonconvex functions. As a side result, our method enjoys linear parallel\nspeed-up using mini-batch. \n\n"}
{"id": "1802.03900", "contents": "Title: Q-learning with Nearest Neighbors Abstract: We consider model-free reinforcement learning for infinite-horizon discounted\nMarkov Decision Processes (MDPs) with a continuous state space and unknown\ntransition kernel, when only a single sample path under an arbitrary policy of\nthe system is available. We consider the Nearest Neighbor Q-Learning (NNQL)\nalgorithm to learn the optimal Q function using nearest neighbor regression\nmethod. As the main contribution, we provide tight finite sample analysis of\nthe convergence rate. In particular, for MDPs with a $d$-dimensional state\nspace and the discounted factor $\\gamma \\in (0,1)$, given an arbitrary sample\npath with \"covering time\" $ L $, we establish that the algorithm is guaranteed\nto output an $\\varepsilon$-accurate estimate of the optimal Q-function using\n$\\tilde{O}\\big(L/(\\varepsilon^3(1-\\gamma)^7)\\big)$ samples. For instance, for a\nwell-behaved MDP, the covering time of the sample path under the purely random\npolicy scales as $ \\tilde{O}\\big(1/\\varepsilon^d\\big),$ so the sample\ncomplexity scales as $\\tilde{O}\\big(1/\\varepsilon^{d+3}\\big).$ Indeed, we\nestablish a lower bound that argues that the dependence of $\n\\tilde{\\Omega}\\big(1/\\varepsilon^{d+2}\\big)$ is necessary. \n\n"}
{"id": "1802.04866", "contents": "Title: Local Descent For Temporal Logic Falsification of Cyber-Physical Systems\n  (Extended Technical Report) Abstract: One way to analyze Cyber-Physical Systems is by modeling them as hybrid\nautomata. Since reachability analysis for hybrid nonlinear automata is a very\nchallenging and computationally expensive problem, in practice, engineers try\nto solve the requirements falsification problem. In one method, the\nfalsification problem is solved by minimizing a robustness metric induced by\nthe requirements. This optimization problem is usually a non-convex non-smooth\nproblem that requires heuristic and analytical guidance to be solved. In this\npaper, functional gradient descent for hybrid systems is utilized for locally\ndecreasing the robustness metric. The local descent method is combined with\nSimulated Annealing as a global optimization method to search for unsafe\nbehaviors. \n\n"}
{"id": "1802.05155", "contents": "Title: A Diffusion Approximation Theory of Momentum SGD in Nonconvex\n  Optimization Abstract: Momentum Stochastic Gradient Descent (MSGD) algorithm has been widely applied\nto many nonconvex optimization problems in machine learning, e.g., training\ndeep neural networks, variational Bayesian inference, and etc. Despite its\nempirical success, there is still a lack of theoretical understanding of\nconvergence properties of MSGD. To fill this gap, we propose to analyze the\nalgorithmic behavior of MSGD by diffusion approximations for nonconvex\noptimization problems with strict saddle points and isolated local optima. Our\nstudy shows that the momentum helps escape from saddle points, but hurts the\nconvergence within the neighborhood of optima (if without the step size\nannealing or momentum annealing). Our theoretical discovery partially\ncorroborates the empirical success of MSGD in training deep neural networks. \n\n"}
{"id": "1802.05249", "contents": "Title: Distributionally Robust Submodular Maximization Abstract: Submodular functions have applications throughout machine learning, but in\nmany settings, we do not have direct access to the underlying function $f$. We\nfocus on stochastic functions that are given as an expectation of functions\nover a distribution $P$. In practice, we often have only a limited set of\nsamples $f_i$ from $P$. The standard approach indirectly optimizes $f$ by\nmaximizing the sum of $f_i$. However, this ignores generalization to the true\n(unknown) distribution. In this paper, we achieve better performance on the\nactual underlying function $f$ by directly optimizing a combination of bias and\nvariance. Algorithmically, we accomplish this by showing how to carry out\ndistributionally robust optimization (DRO) for submodular functions, providing\nefficient algorithms backed by theoretical guarantees which leverage several\nnovel contributions to the general theory of DRO. We also show compelling\nempirical evidence that DRO improves generalization to the unknown stochastic\nsubmodular function. \n\n"}
{"id": "1802.05374", "contents": "Title: A Progressive Batching L-BFGS Method for Machine Learning Abstract: The standard L-BFGS method relies on gradient approximations that are not\ndominated by noise, so that search directions are descent directions, the line\nsearch is reliable, and quasi-Newton updating yields useful quadratic models of\nthe objective function. All of this appears to call for a full batch approach,\nbut since small batch sizes give rise to faster algorithms with better\ngeneralization properties, L-BFGS is currently not considered an algorithm of\nchoice for large-scale machine learning applications. One need not, however,\nchoose between the two extremes represented by the full batch or highly\nstochastic regimes, and may instead follow a progressive batching approach in\nwhich the sample size increases during the course of the optimization. In this\npaper, we present a new version of the L-BFGS algorithm that combines three\nbasic components - progressive batching, a stochastic line search, and stable\nquasi-Newton updating - and that performs well on training logistic regression\nand deep neural networks. We provide supporting convergence theory for the\nmethod. \n\n"}
{"id": "1802.06903", "contents": "Title: Generalization Error Bounds with Probabilistic Guarantee for SGD in\n  Nonconvex Optimization Abstract: The success of deep learning has led to a rising interest in the\ngeneralization property of the stochastic gradient descent (SGD) method, and\nstability is one popular approach to study it. Existing works based on\nstability have studied nonconvex loss functions, but only considered the\ngeneralization error of the SGD in expectation. In this paper, we establish\nvarious generalization error bounds with probabilistic guarantee for the SGD.\nSpecifically, for both general nonconvex loss functions and gradient dominant\nloss functions, we characterize the on-average stability of the iterates\ngenerated by SGD in terms of the on-average variance of the stochastic\ngradients. Such characterization leads to improved bounds for the\ngeneralization error for SGD. We then study the regularized risk minimization\nproblem with strongly convex regularizers, and obtain improved generalization\nerror bounds for proximal SGD. With strongly convex regularizers, we further\nestablish the generalization error bounds for nonconvex loss functions under\nproximal SGD with high-probability guarantee, i.e., exponential concentration\nin probability. \n\n"}
{"id": "1802.06966", "contents": "Title: Computing the Cumulative Distribution Function and Quantiles of the\n  One-sided Kolmogorov-Smirnov Statistic Abstract: The cumulative distribution and quantile functions for the one-sided one\nsample Kolmogorov-Smirnov probability distributions are used for\ngoodness-of-fit testing. While the Smirnov-Birnbaum-Tingey formula for the CDF\nappears straight forward, its numerical evaluation generates intermediate\nresults spanning many hundreds of orders of magnitude and at times requires\nvery precise accurate representations. Computing the quantile function for any\nspecific probability may require evaluating both the CDF and its derivative,\nboth of which are computationally expensive. To work around avoid these issues,\ndifferent algorithms can be used across different parts of the domain, and\napproximations can be used to reduce the computational requirements. We show\nhere that straight forward implementation incurs accuracy loss for sample sizes\nof well under 1000. Further the approximations in use inside the open source\nSciPy python software often result in increased computation, not just reduced\naccuracy, and at times suffer catastrophic loss of accuracy for any sample\nsize. Then we provide alternate algorithms which restore accuracy and\nefficiency across the whole domain. \n\n"}
{"id": "1802.07148", "contents": "Title: Correlated pseudo-marginal schemes for time-discretised stochastic\n  kinetic models Abstract: The challenging problem of conducting fully Bayesian inference for the\nreaction rate constants governing stochastic kinetic models (SKMs) is\nconsidered. Given the challenges underlying this problem, the Markov jump\nprocess representation is routinely replaced by an approximation based on a\nsuitable time discretisation of the system of interest. Improving the accuracy\nof these schemes amounts to using an ever finer discretisation level, which in\nthe context of the inference problem, requires integrating over the uncertainty\nin the process at a predetermined number of intermediate times between\nobservations. Pseudo-marginal Metropolis-Hastings schemes are increasingly\nused, since for a given discretisation level, the observed data likelihood can\nbe unbiasedly estimated using a particle filter. When observations are\nparticularly informative an auxiliary particle filter can be implemented, by\nemploying an appropriate construct to push the state particles towards the\nobservations in a sensible way. Recent work in state-space settings has shown\nhow the pseudo-marginal approach can be made much more efficient by correlating\nthe underlying pseudo-random numbers used to form the likelihood estimate at\nthe current and proposed values of the unknown parameters. We extend this\napproach to the time-discretised SKM framework by correlating the innovations\nthat drive the auxiliary particle filter. We find that the resulting approach\noffers substantial gains in efficiency over a standard implementation. \n\n"}
{"id": "1802.08318", "contents": "Title: Proportional Volume Sampling and Approximation Algorithms for A-Optimal\n  Design Abstract: We study the optimal design problems where the goal is to choose a set of\nlinear measurements to obtain the most accurate estimate of an unknown vector\nin $d$ dimensions. We study the $A$-optimal design variant where the objective\nis to minimize the average variance of the error in the maximum likelihood\nestimate of the vector being measured. The problem also finds applications in\nsensor placement in wireless networks, sparse least squares regression, feature\nselection for $k$-means clustering, and matrix approximation. In this paper, we\nintroduce proportional volume sampling to obtain improved approximation\nalgorithms for $A$-optimal design. Our main result is to obtain improved\napproximation algorithms for the $A$-optimal design problem by introducing the\nproportional volume sampling algorithm. Our results nearly optimal bounds in\nthe asymptotic regime when the number of measurements done, $k$, is\nsignificantly more than the dimension $d$. We also give first approximation\nalgorithms when $k$ is small including when $k=d$. The proportional\nvolume-sampling algorithm also gives approximation algorithms for other optimal\ndesign objectives such as $D$-optimal design and generalized ratio objective\nmatching or improving previous best known results. Interestingly, we show that\na similar guarantee cannot be obtained for the $E$-optimal design problem. We\nalso show that the $A$-optimal design problem is NP-hard to approximate within\na fixed constant when $k=d$. \n\n"}
{"id": "1802.08757", "contents": "Title: Fully Decentralized Multi-Agent Reinforcement Learning with Networked\n  Agents Abstract: We consider the problem of \\emph{fully decentralized} multi-agent\nreinforcement learning (MARL), where the agents are located at the nodes of a\ntime-varying communication network. Specifically, we assume that the reward\nfunctions of the agents might correspond to different tasks, and are only known\nto the corresponding agent. Moreover, each agent makes individual decisions\nbased on both the information observed locally and the messages received from\nits neighbors over the network. Within this setting, the collective goal of the\nagents is to maximize the globally averaged return over the network through\nexchanging information with their neighbors. To this end, we propose two\ndecentralized actor-critic algorithms with function approximation, which are\napplicable to large-scale MARL problems where both the number of states and the\nnumber of agents are massively large. Under the decentralized structure, the\nactor step is performed individually by each agent with no need to infer the\npolicies of others. For the critic step, we propose a consensus update via\ncommunication over the network. Our algorithms are fully incremental and can be\nimplemented in an online fashion. Convergence analyses of the algorithms are\nprovided when the value functions are approximated within the class of linear\nfunctions. Extensive simulation results with both linear and nonlinear function\napproximations are presented to validate the proposed algorithms. Our work\nappears to be the first study of fully decentralized MARL algorithms for\nnetworked agents with function approximation, with provable convergence\nguarantees. \n\n"}
{"id": "1802.08898", "contents": "Title: Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo Abstract: Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from\nhigh-dimensional distributions in Statistics and Machine learning. HMC is known\nto run very efficiently in practice and its popular second-order \"leapfrog\"\nimplementation has long been conjectured to run in $d^{1/4}$ gradient\nevaluations. Here we show that this conjecture is true when sampling from\nstrongly log-concave target distributions that satisfy a weak third-order\nregularity property associated with the input data. Our regularity condition is\nweaker than the Lipschitz Hessian property and allows us to show faster\nconvergence bounds for a much larger class of distributions than would be\npossible with the usual Lipschitz Hessian constant alone. Important\ndistributions that satisfy our regularity condition include posterior\ndistributions used in Bayesian logistic regression for which the data satisfies\nan \"incoherence\" property. Our result compares favorably with the best\navailable bounds for the class of strongly log-concave distributions, which\ngrow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our\nsimulations on synthetic data suggest that, when our regularity condition is\nsatisfied, leapfrog HMC performs better than its competitors -- both in terms\nof accuracy and in terms of the number of gradient evaluations it requires. \n\n"}
{"id": "1802.09128", "contents": "Title: Averaging Stochastic Gradient Descent on Riemannian Manifolds Abstract: We consider the minimization of a function defined on a Riemannian manifold\n$\\mathcal{M}$ accessible only through unbiased estimates of its gradients. We\ndevelop a geometric framework to transform a sequence of slowly converging\niterates generated from stochastic gradient descent (SGD) on $\\mathcal{M}$ to\nan averaged iterate sequence with a robust and fast $O(1/n)$ convergence rate.\nWe then present an application of our framework to geodesically-strongly-convex\n(and possibly Euclidean non-convex) problems. Finally, we demonstrate how these\nideas apply to the case of streaming $k$-PCA, where we show how to accelerate\nthe slow rate of the randomized power method (without requiring knowledge of\nthe eigengap) into a robust algorithm achieving the optimal rate of\nconvergence. \n\n"}
{"id": "1802.09188", "contents": "Title: Analysis of Langevin Monte Carlo via convex optimization Abstract: In this paper, we provide new insights on the Unadjusted Langevin Algorithm.\nWe show that this method can be formulated as a first order optimization\nalgorithm of an objective functional defined on the Wasserstein space of order\n$2$. Using this interpretation and techniques borrowed from convex\noptimization, we give a non-asymptotic analysis of this method to sample from\nlogconcave smooth target distribution on $\\mathbb{R}^d$. Based on this\ninterpretation, we propose two new methods for sampling from a non-smooth\ntarget distribution, which we analyze as well. Besides, these new algorithms\nare natural extensions of the Stochastic Gradient Langevin Dynamics (SGLD)\nalgorithm, which is a popular extension of the Unadjusted Langevin Algorithm.\nSimilar to SGLD, they only rely on approximations of the gradient of the target\nlog density and can be used for large-scale Bayesian inference. \n\n"}
{"id": "1802.09568", "contents": "Title: Shampoo: Preconditioned Stochastic Tensor Optimization Abstract: Preconditioned gradient methods are among the most general and powerful tools\nin optimization. However, preconditioning requires storing and manipulating\nprohibitively large matrices. We describe and analyze a new structure-aware\npreconditioning algorithm, called Shampoo, for stochastic optimization over\ntensor spaces. Shampoo maintains a set of preconditioning matrices, each of\nwhich operates on a single dimension, contracting over the remaining\ndimensions. We establish convergence guarantees in the stochastic convex\nsetting, the proof of which builds upon matrix trace inequalities. Our\nexperiments with state-of-the-art deep learning models show that Shampoo is\ncapable of converging considerably faster than commonly used optimizers.\nAlthough it involves a more complex update rule, Shampoo's runtime per step is\ncomparable to that of simple gradient methods such as SGD, AdaGrad, and Adam. \n\n"}
{"id": "1802.10155", "contents": "Title: Volume of small balls and sub-Riemannian curvature in 3D contact\n  manifolds Abstract: We compute the asymptotic expansion of the volume of small sub-Riemannian\nballs in a contact 3-dimensional manifold, and we express the first meaningful\ngeometric coefficients in terms of geometric invariants of the sub-Riemannian\nstructure \n\n"}
{"id": "1802.10551", "contents": "Title: A Variational Inequality Perspective on Generative Adversarial Networks Abstract: Generative adversarial networks (GANs) form a generative modeling approach\nknown for producing appealing samples, but they are notably difficult to train.\nOne common way to tackle this issue has been to propose new formulations of the\nGAN objective. Yet, surprisingly few studies have looked at optimization\nmethods designed for this adversarial training. In this work, we cast GAN\noptimization problems in the general variational inequality framework. Tapping\ninto the mathematical programming literature, we counter some common\nmisconceptions about the difficulties of saddle point optimization and propose\nto extend techniques designed for variational inequalities to the training of\nGANs. We apply averaging, extrapolation and a computationally cheaper variant\nthat we call extrapolation from the past to the stochastic gradient method\n(SGD) and Adam. \n\n"}
{"id": "1803.00301", "contents": "Title: (Sub)Optimal feedback control of mean field multi-population dynamics Abstract: We study a multiscale approach for the control of agent-based, two-population\nmodels. The control variable acts over one population of leaders, which\ninfluence the population of followers via the coupling generated by their\ninteraction. We cast a quadratic optimal control problem for the large-scale\nmicroscale model, which is approximated via a Boltzmann approach. By sampling\nsolutions of the optimal control problem associated to binary two-population\ndynamics, we generate sub-optimal control laws for the kinetic limit of the\nmulti-population model. We present numerical experiments related to opinion\ndynamics assessing the performance of the proposed control design. \n\n"}
{"id": "1803.00420", "contents": "Title: Tractable and Scalable Schatten Quasi-Norm Approximations for Rank\n  Minimization Abstract: The Schatten quasi-norm was introduced to bridge the gap between the trace\nnorm and rank function. However, existing algorithms are too slow or even\nimpractical for large-scale problems. Motivated by the equivalence relation\nbetween the trace norm and its bilinear spectral penalty, we define two\ntractable Schatten norms, i.e.\\ the bi-trace and tri-trace norms, and prove\nthat they are in essence the Schatten-$1/2$ and $1/3$ quasi-norms,\nrespectively. By applying the two defined Schatten quasi-norms to various rank\nminimization problems such as MC and RPCA, we only need to solve much smaller\nfactor matrices. We design two efficient linearized alternating minimization\nalgorithms to solve our problems and establish that each bounded sequence\ngenerated by our algorithms converges to a critical point. We also provide the\nrestricted strong convexity (RSC) based and MC error bounds for our algorithms.\nOur experimental results verified both the efficiency and effectiveness of our\nalgorithms compared with the state-of-the-art methods. \n\n"}
{"id": "1803.01454", "contents": "Title: Fast Best Subset Selection: Coordinate Descent and Local Combinatorial\n  Optimization Algorithms Abstract: The $L_0$-regularized least squares problem (a.k.a. best subsets) is central\nto sparse statistical learning and has attracted significant attention across\nthe wider statistics, machine learning, and optimization communities. Recent\nwork has shown that modern mixed integer optimization (MIO) solvers can be used\nto address small to moderate instances of this problem. In spite of the\nusefulness of $L_0$-based estimators and generic MIO solvers, there is a steep\ncomputational price to pay when compared to popular sparse learning algorithms\n(e.g., based on $L_1$ regularization). In this paper, we aim to push the\nfrontiers of computation for a family of $L_0$-regularized problems with\nadditional convex penalties. We propose a new hierarchy of necessary optimality\nconditions for these problems. We develop fast algorithms, based on coordinate\ndescent and local combinatorial optimization, that are guaranteed to converge\nto solutions satisfying these optimality conditions. From a statistical\nviewpoint, an interesting story emerges. When the signal strength is high, our\ncombinatorial optimization algorithms have an edge in challenging statistical\nsettings. When the signal is lower, pure $L_0$ benefits from additional convex\nregularization. We empirically demonstrate that our family of $L_0$-based\nestimators can outperform the state-of-the-art sparse learning algorithms in\nterms of a combination of prediction, estimation, and variable selection\nmetrics under various regimes (e.g., different signal strengths, feature\ncorrelations, number of samples and features). Our new open-source sparse\nlearning toolkit L0Learn (available on CRAN and Github) reaches up to a\nthree-fold speedup (with $p$ up to $10^6$) when compared to competing toolkits\nsuch as glmnet and ncvreg. \n\n"}
{"id": "1803.02312", "contents": "Title: Dimensionality Reduction for Stationary Time Series via Stochastic\n  Nonconvex Optimization Abstract: Stochastic optimization naturally arises in machine learning. Efficient\nalgorithms with provable guarantees, however, are still largely missing, when\nthe objective function is nonconvex and the data points are dependent. This\npaper studies this fundamental challenge through a streaming PCA problem for\nstationary time series data. Specifically, our goal is to estimate the\nprinciple component of time series data with respect to the covariance matrix\nof the stationary distribution. Computationally, we propose a variant of Oja's\nalgorithm combined with downsampling to control the bias of the stochastic\ngradient caused by the data dependency. Theoretically, we quantify the\nuncertainty of our proposed stochastic algorithm based on diffusion\napproximations. This allows us to prove the asymptotic rate of convergence and\nfurther implies near optimal asymptotic sample complexity. Numerical\nexperiments are provided to support our analysis. \n\n"}
{"id": "1803.02615", "contents": "Title: A Novel Canonical Duality Theory for Solving 3-D Topology Optimization\n  Problems Abstract: This paper demonstrates a mathematically correct and computationally powerful\nmethod for solving 3D topology optimization problems. This method is based on\ncanonical duality theory (CDT) developed by Gao in nonconvex mechanics and\nglobal optimization. It shows that the so-called NP-hard knapsack problem in\ntopology optimization can be solved deterministically in polynomial time via a\ncanonical penalty-duality (CPD) method to obtain precise 0-1 global optimal\nsolution at each volume evolution. The relation between this CPD method and\nGao's pure complementary energy principle is revealed for the first time. A CPD\nalgorithm is proposed for 3-D topology optimization of linear elastic\nstructures. Its novelty is demonstrated by benchmark problems. Results show\nthat without using any artificial technique, the CPD method can provide\nmechanically sound optimal design, also it is much more powerful than the\nwell-known BESO and SIMP methods. Additionally, computational complexity and\nconceptual/mathematical mistakes in topology optimization modeling and popular\nmethods are explicitly addressed. \n\n"}
{"id": "1803.03466", "contents": "Title: A Stochastic Semismooth Newton Method for Nonsmooth Nonconvex\n  Optimization Abstract: In this work, we present a globalized stochastic semismooth Newton method for\nsolving stochastic optimization problems involving smooth nonconvex and\nnonsmooth convex terms in the objective function. We assume that only noisy\ngradient and Hessian information of the smooth part of the objective function\nis available via calling stochastic first and second order oracles. The\nproposed method can be seen as a hybrid approach combining stochastic\nsemismooth Newton steps and stochastic proximal gradient steps. Two inexact\ngrowth conditions are incorporated to monitor the convergence and the\nacceptance of the semismooth Newton steps and it is shown that the algorithm\nconverges globally to stationary points in expectation. Moreover, under\nstandard assumptions and utilizing random matrix concentration inequalities, we\nprove that the proposed approach locally turns into a pure stochastic\nsemismooth Newton method and converges r-superlinearly with high probability.\nWe present numerical results and comparisons on $\\ell_1$-regularized logistic\nregression and nonconvex binary classification that demonstrate the efficiency\nof our algorithm. \n\n"}
{"id": "1803.04912", "contents": "Title: Data-Driven Distributionally Robust Optimal Power Flow for Distribution\n  Systems Abstract: Increasing penetration of distributed energy resources complicate operations\nof electric power distribution systems by amplifying volatility of nodal power\ninjections. On the other hand, these resources can provide additional control\nmeans to the distribution system operator (DSO). This paper takes the DSO\nperspective and leverages a data-driven distributionally robust decision-making\nframework to overcome the uncertainty of these injections and its impact on the\ndistribution system operations. We develop an AC OPF formulation for radial\ndistribution systems based on the LinDistFlow AC power flow approximation and\nexploit distributionally robust optimization to immunize the optimized\ndecisions against uncertainty in the probabilistic models of forecast errors\nobtained from the available observations. The model is reformulated to be\ncomputationally tractable and tested on multiple IEEE distribution test\nsystems. We also release the code supplement that implements the proposed model\nin Julia and can be used to reproduce our numerical results. \n\n"}
{"id": "1803.05591", "contents": "Title: On the insufficiency of existing momentum schemes for Stochastic\n  Optimization Abstract: Momentum based stochastic gradient methods such as heavy ball (HB) and\nNesterov's accelerated gradient descent (NAG) method are widely used in\npractice for training deep networks and other supervised learning models, as\nthey often provide significant improvements over stochastic gradient descent\n(SGD). Rigorously speaking, \"fast gradient\" methods have provable improvements\nover gradient descent only for the deterministic case, where the gradients are\nexact. In the stochastic case, the popular explanations for their wide\napplicability is that when these fast gradient methods are applied in the\nstochastic case, they partially mimic their exact gradient counterparts,\nresulting in some practical gain. This work provides a counterpoint to this\nbelief by proving that there exist simple problem instances where these methods\ncannot outperform SGD despite the best setting of its parameters. These\nnegative problem instances are, in an informal sense, generic; they do not look\nlike carefully constructed pathological instances. These results suggest (along\nwith empirical evidence) that HB or NAG's practical performance gains are a\nby-product of mini-batching.\n  Furthermore, this work provides a viable (and provable) alternative, which,\non the same set of problem instances, significantly improves over HB, NAG, and\nSGD's performance. This algorithm, referred to as Accelerated Stochastic\nGradient Descent (ASGD), is a simple to implement stochastic algorithm, based\non a relatively less popular variant of Nesterov's Acceleration. Extensive\nempirical results in this paper show that ASGD has performance gains over HB,\nNAG, and SGD. \n\n"}
{"id": "1803.05885", "contents": "Title: Identifiability of dynamical networks with partial node measurements Abstract: Much recent research has dealt with the identifiability of a dynamical\nnetwork in which the node signals are connected by causal linear transfer\nfunctions and are excited by known external excitation signals and/or unknown\nnoise signals. A major research question concerns the identifiability of the\nwhole network - topology and all transfer functions - from the measured node\nsignals and external excitation signals. So far all results on this topic have\nassumed that all node signals are measured. This paper presents the first\nresults for the situation where not all node signals are measurable, under the\nassumptions that (1) the topology of the network is known, and (2) each node is\nexcited by a known external excitation. Using graph theoretical properties, we\nshow that the transfer functions that can be identified depend essentially on\nthe topology of the paths linking the corresponding vertices to the measured\nnodes. A practical outcome is that, under those assumptions, a network can\noften be identified using only a small subset of node measurements. \n\n"}
{"id": "1803.05999", "contents": "Title: Escaping Saddles with Stochastic Gradients Abstract: We analyze the variance of stochastic gradients along negative curvature\ndirections in certain non-convex machine learning models and show that\nstochastic gradients exhibit a strong component along these directions.\nFurthermore, we show that - contrary to the case of isotropic noise - this\nvariance is proportional to the magnitude of the corresponding eigenvalues and\nnot decreasing in the dimensionality. Based upon this observation we propose a\nnew assumption under which we show that the injection of explicit, isotropic\nnoise usually applied to make gradient descent escape saddle points can\nsuccessfully be replaced by a simple SGD step. Additionally - and under the\nsame condition - we derive the first convergence rate for plain SGD to a\nsecond-order stationary point in a number of iterations that is independent of\nthe problem dimension. \n\n"}
{"id": "1803.06010", "contents": "Title: Ridge Regression and Provable Deterministic Ridge Leverage Score\n  Sampling Abstract: Ridge leverage scores provide a balance between low-rank approximation and\nregularization, and are ubiquitous in randomized linear algebra and machine\nlearning. Deterministic algorithms are also of interest in the moderately big\ndata regime, because deterministic algorithms provide interpretability to the\npractitioner by having no failure probability and always returning the same\nresults.\n  We provide provable guarantees for deterministic column sampling using ridge\nleverage scores. The matrix sketch returned by our algorithm is a column subset\nof the original matrix, yielding additional interpretability. Like the\nrandomized counterparts, the deterministic algorithm provides (1 + {\\epsilon})\nerror column subset selection, (1 + {\\epsilon}) error projection-cost\npreservation, and an additive-multiplicative spectral bound. We also show that\nunder the assumption of power-law decay of ridge leverage scores, this\ndeterministic algorithm is provably as accurate as randomized algorithms.\n  Lastly, ridge regression is frequently used to regularize ill-posed linear\nleast-squares problems. While ridge regression provides shrinkage for the\nregression coefficients, many of the coefficients remain small but non-zero.\nPerforming ridge regression with the matrix sketch returned by our algorithm\nand a particular regularization parameter forces coefficients to zero and has a\nprovable (1 + {\\epsilon}) bound on the statistical risk. As such, it is an\ninteresting alternative to elastic net regularization. \n\n"}
{"id": "1803.06087", "contents": "Title: A Globally Asymptotically Stable Polynomial Vector Field with Rational\n  Coefficients and no Local Polynomial Lyapunov Function Abstract: We give an explicit example of a two-dimensional polynomial vector field of\ndegree seven that has rational coefficients, is globally asymptotically stable,\nbut does not admit an analytic Lyapunov function even locally. \n\n"}
{"id": "1803.06531", "contents": "Title: Topology Estimation using Graphical Models in Multi-Phase Power\n  Distribution Grids Abstract: Distribution grid is the medium and low voltage part of a large power system.\nStructurally, the majority of distribution networks operate radially, such that\nenergized lines form a collection of trees, i.e. forest, with a substation\nbeing at the root of any tree. The operational topology/forest may change from\ntime to time, however tracking these changes, even though important for the\ndistribution grid operation and control, is hindered by limited real-time\nmonitoring. This paper develops a learning framework to reconstruct radial\noperational structure of the distribution grid from synchronized voltage\nmeasurements in the grid subject to the exogenous fluctuations in nodal power\nconsumption. To detect operational lines our learning algorithm uses\nconditional independence tests for continuous random variables that is\napplicable to a wide class of probability distributions of the nodal\nconsumption and Gaussian injections in particular. Moreover, our algorithm\napplies to the practical case of unbalanced three-phase power flow. Algorithm\nperformance is validated on AC power flow simulations over IEEE distribution\ngrid test cases. \n\n"}
{"id": "1803.06804", "contents": "Title: Stochastic maximum principle, dynamic programming principle, and their\n  relationship for fully coupled forward-backward stochastic control systems Abstract: Within the framework of viscosity solution, we study the relationship between\nthe maximum principle (MP) in [9] and the dynamic programming principle (DPP)\nin [10] for a fully coupled forward-backward stochastic controlled system\n(FBSCS) with a nonconvex control domain. For a fully coupled FBSCS, both the\ncorresponding MP and the corresponding Hamilton-Jacobi-Bellman (HJB) equation\ncombine an algebra equation respectively. So this relationship becomes more\ncomplicated and almost no work involves this issue. With the help of a new\ndecoupling technique, we obtain the desirable estimates for the fully coupled\nforward-backward variational equations and establish the relationship.\nFurthermore, for the smooth case, we discover the connection between the\nderivatives of the solution to the algebra equation and some terms in the first\nand second-order adjoint equations. Finally, we study the local case under the\nmonotonicity conditions as in [14,27] and obtain the relationship between the\nMP in [27] and the DPP in [14]. \n\n"}
{"id": "1803.07055", "contents": "Title: Simple random search provides a competitive approach to reinforcement\n  learning Abstract: A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms. \n\n"}
{"id": "1803.07300", "contents": "Title: Risk and parameter convergence of logistic regression Abstract: Gradient descent, when applied to the task of logistic regression, outputs\niterates which are biased to follow a unique ray defined by the data. The\ndirection of this ray is the maximum margin predictor of a maximal linearly\nseparable subset of the data; the gradient descent iterates converge to this\nray in direction at the rate $\\mathcal{O}(\\ln\\ln t / \\ln t)$. The ray does not\npass through the origin in general, and its offset is the bounded global\noptimum of the risk over the remaining data; gradient descent recovers this\noffset at a rate $\\mathcal{O}((\\ln t)^2 / \\sqrt{t})$. \n\n"}
{"id": "1803.07617", "contents": "Title: Online Learning: Sufficient Statistics and the Burkholder Method Abstract: We uncover a fairly general principle in online learning: If regret can be\n(approximately) expressed as a function of certain \"sufficient statistics\" for\nthe data sequence, then there exists a special Burkholder function that 1) can\nbe used algorithmically to achieve the regret bound and 2) only depends on\nthese sufficient statistics, not the entire data sequence, so that the online\nstrategy is only required to keep the sufficient statistics in memory. This\ncharacterization is achieved by bringing the full power of the Burkholder\nMethod --- originally developed for certifying probabilistic martingale\ninequalities --- to bear on the online learning setting.\n  To demonstrate the scope and effectiveness of the Burkholder method, we\ndevelop a novel online strategy for matrix prediction that attains a regret\nbound corresponding to the variance term in matrix concentration inequalities.\nWe also present a linear-time/space prediction strategy for parameter free\nsupervised learning with linear classes and general smooth norms. \n\n"}
{"id": "1803.07725", "contents": "Title: Semidefinite Outer Approximation of the Backward Reachable Set of\n  Discrete-time Autonomous Polynomial Systems Abstract: We approximate the backward reachable set of discrete-time autonomous\npolynomial systems using the recently developed occupation measure approach. We\nformulate the problem as an infinite-dimensional linear programming (LP)\nproblem on measures and its dual on continuous functions. Then we approximate\nthe LP by a hierarchy of finite-dimensional semidefinite programming (SDP)\nprograms on moments of measures and their duals on sums-of-squares polynomials.\nFinally we solve the SDP's and obtain a sequence of outer approximations of the\nbackward reachable set. We demonstrate our approach on three dynamical systems.\nAs a special case, we also show how to approximate the preimage of a compact\nsemi-algebraic set under a polynomial map. \n\n"}
{"id": "1803.07964", "contents": "Title: Stochastic Learning under Random Reshuffling with Constant Step-sizes Abstract: In empirical risk optimization, it has been observed that stochastic gradient\nimplementations that rely on random reshuffling of the data achieve better\nperformance than implementations that rely on sampling the data uniformly.\nRecent works have pursued justifications for this behavior by examining the\nconvergence rate of the learning process under diminishing step-sizes. This\nwork focuses on the constant step-size case and strongly convex loss function.\nIn this case, convergence is guaranteed to a small neighborhood of the\noptimizer albeit at a linear rate. The analysis establishes analytically that\nrandom reshuffling outperforms uniform sampling by showing explicitly that\niterates approach a smaller neighborhood of size $O(\\mu^2)$ around the\nminimizer rather than $O(\\mu)$. Furthermore, we derive an analytical expression\nfor the steady-state mean-square-error performance of the algorithm, which\nhelps clarify in greater detail the differences between sampling with and\nwithout replacement. We also explain the periodic behavior that is observed in\nrandom reshuffling implementations. \n\n"}
{"id": "1803.08198", "contents": "Title: SUCAG: Stochastic Unbiased Curvature-aided Gradient Method for\n  Distributed Optimization Abstract: We propose and analyze a new stochastic gradient method, which we call\nStochastic Unbiased Curvature-aided Gradient (SUCAG), for finite sum\noptimization problems. SUCAG constitutes an unbiased total gradient tracking\ntechnique that uses Hessian information to accelerate con- vergence. We analyze\nour method under the general asynchronous model of computation, in which each\nfunction is selected infinitely often with possibly unbounded (but sublinear)\ndelay. For strongly convex problems, we establish linear convergence for the\nSUCAG method. When the initialization point is sufficiently close to the\noptimal solution, the established convergence rate is only dependent on the\ncondition number of the problem, making it strictly faster than the known rate\nfor the SAGA method. Furthermore, we describe a Markov-driven approach of\nimplementing the SUCAG method in a distributed asynchronous multi-agent\nsetting, via gossiping along a random walk on an undirected communication\ngraph. We show that our analysis applies as long as the graph is connected and,\nnotably, establishes an asymptotic linear convergence rate that is robust to\nthe graph topology. Numerical results demonstrate the merits of our algorithm\nover existing methods. \n\n"}
{"id": "1803.08558", "contents": "Title: On Data-Driven Computation of Information Transfer for Causal Inference\n  in Dynamical Systems Abstract: In this paper, we provide a novel approach to capture causal interaction in a\ndynamical system from time-series data. In \\cite{sinha_IT_CDC2016}, we have\nshown that the existing measures of information transfer, namely directed\ninformation, granger causality and transfer entropy fail to capture true causal\ninteraction in dynamical system and proposed a new definition of information\ntransfer that captures true causal interaction. The main contribution of this\npaper is to show that the proposed definition of information transfer in\n\\cite{sinha_IT_CDC2016}\\cite{sinha_IT_ICC} can be computed from time-series\ndata. We use transfer operator theoretic framework involving Perron-Frobenius\nand Koopman operators for the data-driven approximation of the system dynamics\nand for the computation of information transfer. Several examples involving\nlinear and nonlinear system dynamics are presented to verify the efficiency of\nthe developed algorithm. \n\n"}
{"id": "1803.08783", "contents": "Title: Secant and Popov-like Conditions in Power Network Stability Abstract: The problem of decentralized frequency control in power networks has received\nan increasing attention in recent years due to its significance in modern power\nsystems and smart grids. Nevertheless, generation dynamics including\nturbine-governor dynamics, in conjunction with nonlinearities associated with\ngeneration and power flow, increase significantly the complexity in the\nanalysis, and are not adequately addressed in the literature. In this paper we\nshow how incremental secant gain conditions can be used in this context to\ndeduce decentralized stability conditions with reduced conservatism.\nFurthermore, for linear generation dynamics, we establish Popov-like conditions\nthat are able to reduce the conservatism even further by incorporating\nadditional local information associated with the coupling strength among the\nbus dynamics. Various examples are discussed throughout the paper to\ndemonstrate the significance of the results presented. \n\n"}
{"id": "1803.08951", "contents": "Title: Contract theory in a VUCA world Abstract: In this paper we investigate a Principal-Agent problem with moral hazard\nunder Knightian uncertainty. We extend the seminal framework of Holmstr\\\"om and\nMilgrom by combining a Stackelberg equilibrium with a worst-case approach. We\ninvestigate a general model in the spirit of Cvitani\\'c, Possama\\\"i and Touzi\n(2018). We show that optimal contracts depend on the output and its quadratic\nvariation, as an extension of the works of Mastrolia and Possama\\\"i (2016) (by\ndropping all the restrictive assumptions) and Sung (2015) (by considering a\ngeneral class of admissible contracts). We characterize the best reaction\neffort of the agent through the solution to a second order BSDE and we show\nthat the value of the problem of the Principal is the viscosity solution of an\nHamilton-Jacobi-Bellman-Isaacs equation, without needing a dynamic programming\nprinciple, by using stochastic Perron's method. \n\n"}
{"id": "1803.09357", "contents": "Title: On the Local Minima of the Empirical Risk Abstract: Population risk is always of primary interest in machine learning; however,\nlearning algorithms only have access to the empirical risk. Even for\napplications with nonconvex nonsmooth losses (such as modern deep networks),\nthe population risk is generally significantly more well-behaved from an\noptimization point of view than the empirical risk. In particular, sampling can\ncreate many spurious local minima. We consider a general framework which aims\nto optimize a smooth nonconvex function $F$ (population risk) given only access\nto an approximation $f$ (empirical risk) that is pointwise close to $F$ (i.e.,\n$\\|F-f\\|_{\\infty} \\le \\nu$). Our objective is to find the\n$\\epsilon$-approximate local minima of the underlying function $F$ while\navoiding the shallow local minima---arising because of the tolerance\n$\\nu$---which exist only in $f$. We propose a simple algorithm based on\nstochastic gradient descent (SGD) on a smoothed version of $f$ that is\nguaranteed to achieve our goal as long as $\\nu \\le O(\\epsilon^{1.5}/d)$. We\nalso provide an almost matching lower bound showing that our algorithm achieves\noptimal error tolerance $\\nu$ among all algorithms making a polynomial number\nof queries of $f$. As a concrete example, we show that our results can be\ndirectly used to give sample complexities for learning a ReLU unit. \n\n"}
{"id": "1803.10928", "contents": "Title: Design of First-Order Optimization Algorithms via Sum-of-Squares\n  Programming Abstract: In this paper, we propose a framework based on sum-of-squares programming to\ndesign iterative first-order optimization algorithms for smooth and strongly\nconvex problems. Our starting point is to develop a polynomial matrix\ninequality as a sufficient condition for exponential convergence of the\nalgorithm. The entries of this matrix are polynomial functions of the unknown\nparameters (exponential decay rate, stepsize, momentum coefficient, etc.). We\nthen formulate a polynomial optimization, in which the objective is to optimize\nthe exponential decay rate over the parameters of the algorithm. Finally, we\nuse sum-of-squares programming as a tractable relaxation of the proposed\npolynomial optimization problem. We illustrate the utility of the proposed\nframework by designing a first-order algorithm that shares the same structure\nas Nesterov's accelerated gradient method. \n\n"}
{"id": "1803.11030", "contents": "Title: Exploiting Weak Supermodularity for Coalition-Proof Mechanisms Abstract: Under the incentive-compatible Vickrey-Clarke-Groves mechanism, coalitions of\nparticipants can influence the auction outcome to obtain higher collective\nprofit. These manipulations were proven to be eliminated if and only if the\nmarket objective is supermodular. Nevertheless, several auctions do not satisfy\nthe stringent conditions for supermodularity. These auctions include\nelectricity markets, which are the main motivation of our study. To\ncharacterize nonsupermodular functions, we introduce the supermodularity ratio\nand the weak supermodularity. We show that these concepts provide us with tight\nbounds on the profitability of collusion and shill bidding. We then derive an\nanalytical lower bound on the supermodularity ratio. Our results are verified\nwith case studies based on the IEEE test systems. \n\n"}
{"id": "1804.00325", "contents": "Title: Aggregated Momentum: Stability Through Passive Damping Abstract: Momentum is a simple and widely used trick which allows gradient-based\noptimizers to pick up speed along low curvature directions. Its performance\ndepends crucially on a damping coefficient $\\beta$. Large $\\beta$ values can\npotentially deliver much larger speedups, but are prone to oscillations and\ninstability; hence one typically resorts to small values such as 0.5 or 0.9. We\npropose Aggregated Momentum (AggMo), a variant of momentum which combines\nmultiple velocity vectors with different $\\beta$ parameters. AggMo is trivial\nto implement, but significantly dampens oscillations, enabling it to remain\nstable even for aggressive $\\beta$ values such as 0.999. We reinterpret\nNesterov's accelerated gradient descent as a special case of AggMo and analyze\nrates of convergence for quadratic objectives. Empirically, we find that AggMo\nis a suitable drop-in replacement for other momentum methods, and frequently\ndelivers faster convergence. \n\n"}
{"id": "1804.00445", "contents": "Title: On the Computation of Kantorovich-Wasserstein Distances between\n  2D-Histograms by Uncapacitated Minimum Cost Flows Abstract: In this work, we present a method to compute the Kantorovich-Wasserstein\ndistance of order one between a pair of two-dimensional histograms. Recent\nworks in Computer Vision and Machine Learning have shown the benefits of\nmeasuring Wasserstein distances of order one between histograms with $n$ bins,\nby solving a classical transportation problem on very large complete bipartite\ngraphs with $n$ nodes and $n^2$ edges. The main contribution of our work is to\napproximate the original transportation problem by an uncapacitated min cost\nflow problem on a reduced flow network of size $O(n)$ that exploits the\ngeometric structure of the cost function. More precisely, when the distance\namong the bin centers is measured with the 1-norm or the $\\infty$-norm, our\napproach provides an optimal solution. When the distance among bins is measured\nwith the 2-norm: (i) we derive a quantitative estimate on the error between\noptimal and approximate solution; (ii) given the error, we construct a reduced\nflow network of size $O(n)$. We numerically show the benefits of our approach\nby computing Wasserstein distances of order one on a set of grey scale images\nused as benchmark in the literature. We show how our approach scales with the\nsize of the images with 1-norm, 2-norm and $\\infty$-norm ground distances, and\nwe compare it with other two methods which are largely used in the literature. \n\n"}
{"id": "1804.00934", "contents": "Title: A Constant Step Stochastic Douglas-Rachford Algorithm with Application\n  to Non Separable Regularizations Abstract: The Douglas Rachford algorithm is an algorithm that converges to a minimizer\nof a sum of two convex functions. The algorithm consists in fixed point\niterations involving computations of the proximity operators of the two\nfunctions separately. The paper investigates a stochastic version of the\nalgorithm where both functions are random and the step size is constant. We\nestablish that the iterates of the algorithm stay close to the set of solution\nwith high probability when the step size is small enough. Application to\nstructured regularization is considered. \n\n"}
{"id": "1804.01189", "contents": "Title: Real-Time Prediction of the Duration of Distribution System Outages Abstract: This paper addresses the problem of predicting duration of unplanned power\noutages, using historical outage records to train a series of neural network\npredictors. The initial duration prediction is made based on environmental\nfactors, and it is updated based on incoming field reports using natural\nlanguage processing to automatically analyze the text. Experiments using 15\nyears of outage records show good initial results and improved performance\nleveraging text. Case studies show that the language processing identifies\nphrases that point to outage causes and repair steps. \n\n"}
{"id": "1804.01221", "contents": "Title: Tight Query Complexity Lower Bounds for PCA via Finite Sample Deformed\n  Wigner Law Abstract: We prove a \\emph{query complexity} lower bound for approximating the top $r$\ndimensional eigenspace of a matrix. We consider an oracle model where, given a\nsymmetric matrix $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$, an algorithm\n$\\mathsf{Alg}$ is allowed to make $\\mathsf{T}$ exact queries of the form\n$\\mathsf{w}^{(i)} = \\mathbf{M} \\mathsf{v}^{(i)}$ for $i$ in\n$\\{1,...,\\mathsf{T}\\}$, where $\\mathsf{v}^{(i)}$ is drawn from a distribution\nwhich depends arbitrarily on the past queries and measurements\n$\\{\\mathsf{v}^{(j)},\\mathsf{w}^{(i)}\\}_{1 \\le j \\le i-1}$. We show that for\nevery $\\mathtt{gap} \\in (0,1/2]$, there exists a distribution over matrices\n$\\mathbf{M}$ for which 1) $\\mathrm{gap}_r(\\mathbf{M}) = \\Omega(\\mathtt{gap})$\n(where $\\mathrm{gap}_r(\\mathbf{M})$ is the normalized gap between the $r$ and\n$r+1$-st largest-magnitude eigenvector of $\\mathbf{M}$), and 2) any algorithm\n$\\mathsf{Alg}$ which takes fewer than $\\mathrm{const} \\times \\frac{r \\log\nd}{\\sqrt{\\mathtt{gap}}}$ queries fails (with overwhelming probability) to\nidentity a matrix $\\widehat{\\mathsf{V}} \\in \\mathbb{R}^{d \\times r}$ with\northonormal columns for which $\\langle \\widehat{\\mathsf{V}}, \\mathbf{M}\n\\widehat{\\mathsf{V}}\\rangle \\ge (1 - \\mathrm{const} \\times\n\\mathtt{gap})\\sum_{i=1}^r \\lambda_i(\\mathbf{M})$. Our bound requires only that\n$d$ is a small polynomial in $1/\\mathtt{gap}$ and $r$, and matches the upper\nbounds of Musco and Musco '15. Moreover, it establishes a strict separation\nbetween convex optimization and \\emph{randomized}, \"strict-saddle\" non-convex\noptimization of which PCA is a canonical example: in the former, first-order\nmethods can have dimension-free iteration complexity, whereas in PCA, the\niteration complexity of gradient-based methods must necessarily grow with the\ndimension. \n\n"}
{"id": "1804.02507", "contents": "Title: A fully non-linear optimization approach to acousto-electric tomography Abstract: This paper considers the non-linear inverse problem of reconstructing an\nelectric conductivity distribution from the interior power density in a bounded\ndomain. Applications include the novel tomographic method known as\nacousto-electric tomography, in which the measurement setup in Electrical\nImpedance Tomography is modulated by ultrasonic waves thus giving rise to a\nmethod potentially having both high contrast and high resolution. We formulate\nthe inverse problem as a regularized non-linear optimization problem, show the\nexistence of a minimizer, and derive optimality conditions. We propose a\nnon-linear conjugate gradient scheme for finding a minimizer based on the\noptimality conditions. All our numerical experiments are done in\ntwo-dimensions. The experiments reveal new insight into the non-linear effects\nin the reconstruction. One of the interesting features we observe is that,\ndepending on the choice of regularization, there is a trade-off between high\nresolution and high contrast in the reconstructed images. Our proposed\nnon-linear optimization framework can be generalized to other hybrid imaging\nmodalities. \n\n"}
{"id": "1804.03954", "contents": "Title: A Variable Neighborhood Search for Flying Sidekick Traveling Salesman\n  Problem Abstract: The efficiency and dynamism of Unmanned Aerial Vehicles (UAVs), or drones,\npresent substantial application opportunities in several industries in the last\nyears. Notably, the logistic companies gave close attention to these vehicles\nenvisioning reduce delivery time and operational cost. A variant of the\nTraveling Salesman Problem (TSP) called Flying Sidekick Traveling Salesman\nProblem (FSTSP) was introduced involving drone-assisted parcel delivery. The\ndrone is launched from the truck, proceeds to deliver parcels to a customer and\nthen is recovered by the truck in a third location. While the drone travels\nthrough a trip, the truck delivers parcels to other customers as long as the\ndrone has enough battery to hover waiting for the truck. This work proposes a\nhybrid heuristic that the initial solution is created from the optimal TSP\nsolution reached by a TSP solver. Next, an implementation of the General\nVariable Neighborhood Search is used to obtain the delivery routes of truck and\ndrone. Computational experiments show the potential of the algorithm to improve\nthe delivery time significantly. Furthermore, we provide a new set of instances\nbased on well-known TSPLIB instances. \n\n"}
{"id": "1804.04272", "contents": "Title: Deep Neural Networks Motivated by Partial Differential Equations Abstract: Partial differential equations (PDEs) are indispensable for modeling many\nphysical phenomena and also commonly used for solving image processing tasks.\nIn the latter area, PDE-based approaches interpret image data as\ndiscretizations of multivariate functions and the output of image processing\nalgorithms as solutions to certain PDEs. Posing image processing problems in\nthe infinite dimensional setting provides powerful tools for their analysis and\nsolution. Over the last few decades, the reinterpretation of classical image\nprocessing problems through the PDE lens has been creating multiple celebrated\napproaches that benefit a vast area of tasks including image segmentation,\ndenoising, registration, and reconstruction.\n  In this paper, we establish a new PDE-interpretation of a class of deep\nconvolutional neural networks (CNN) that are commonly used to learn from\nspeech, image, and video data. Our interpretation includes convolution residual\nneural networks (ResNet), which are among the most promising approaches for\ntasks such as image classification having improved the state-of-the-art\nperformance in prestigious benchmark challenges. Despite their recent\nsuccesses, deep ResNets still face some critical challenges associated with\ntheir design, immense computational costs and memory requirements, and lack of\nunderstanding of their reasoning.\n  Guided by well-established PDE theory, we derive three new ResNet\narchitectures that fall into two new classes: parabolic and hyperbolic CNNs. We\ndemonstrate how PDE theory can provide new insights and algorithms for deep\nlearning and demonstrate the competitiveness of three new CNN architectures\nusing numerical experiments. \n\n"}
{"id": "1804.04529", "contents": "Title: Online convex optimization and no-regret learning: Algorithms,\n  guarantees and applications Abstract: Spurred by the enthusiasm surrounding the \"Big Data\" paradigm, the\nmathematical and algorithmic tools of online optimization have found widespread\nuse in problems where the trade-off between data exploration and exploitation\nplays a predominant role. This trade-off is of particular importance to several\nbranches and applications of signal processing, such as data mining,\nstatistical inference, multimedia indexing and wireless communications (to name\nbut a few). With this in mind, the aim of this tutorial paper is to provide a\ngentle introduction to online optimization and learning algorithms that are\nasymptotically optimal in hindsight - i.e., they approach the performance of a\nvirtual algorithm with unlimited computational power and full knowledge of the\nfuture, a property known as no-regret. Particular attention is devoted to\nidentifying the algorithms' theoretical performance guarantees and to establish\nlinks with classic optimization paradigms (both static and stochastic). To\nallow a better understanding of this toolbox, we provide several examples\nthroughout the tutorial ranging from metric learning to wireless resource\nallocation problems. \n\n"}
{"id": "1804.06021", "contents": "Title: Model-Free Linear Quadratic Control via Reduction to Expert Prediction Abstract: Model-free approaches for reinforcement learning (RL) and continuous control\nfind policies based only on past states and rewards, without fitting a model of\nthe system dynamics. They are appealing as they are general purpose and easy to\nimplement; however, they also come with fewer theoretical guarantees than\nmodel-based RL. In this work, we present a new model-free algorithm for\ncontrolling linear quadratic (LQ) systems, and show that its regret scales as\n$O(T^{\\xi+2/3})$ for any small $\\xi>0$ if time horizon satisfies $T>C^{1/\\xi}$\nfor a constant $C$. The algorithm is based on a reduction of control of Markov\ndecision processes to an expert prediction problem. In practice, it corresponds\nto a variant of policy iteration with forced exploration, where the policy in\neach phase is greedy with respect to the average of all previous value\nfunctions. This is the first model-free algorithm for adaptive control of LQ\nsystems that provably achieves sublinear regret and has a polynomial\ncomputation cost. Empirically, our algorithm dramatically outperforms standard\npolicy iteration, but performs worse than a model-based approach. \n\n"}
{"id": "1804.06321", "contents": "Title: Robust Kalman Filtering: Asymptotic Analysis of the Least Favorable\n  Model Abstract: We consider a robust filtering problem where the robust filter is designed\naccording to the least favorable model belonging to a ball about the nominal\nmodel. In this approach, the ball radius specifies the modeling error tolerance\nand the least favorable model is computed by performing a Riccati-like backward\nrecursion. We show that this recursion converges provided that the tolerance is\nsufficiently small. \n\n"}
{"id": "1804.07213", "contents": "Title: A refined convergence analysis of pDCA$_e$ with applications to\n  simultaneous sparse recovery and outlier detection Abstract: We consider the problem of minimizing a difference-of-convex (DC) function,\nwhich can be written as the sum of a smooth convex function with Lipschitz\ngradient, a proper closed convex function and a continuous possibly nonsmooth\nconcave function. We refine the convergence analysis in [38] for the proximal\nDC algorithm with extrapolation (pDCA$_e$) and show that the whole sequence\ngenerated by the algorithm is convergent when the objective is level-bounded,\n{\\em without} imposing differentiability assumptions in the concave part. Our\nanalysis is based on a new potential function and we assume such a function is\na Kurdyka-{\\L}ojasiewicz (KL) function. We also establish a relationship\nbetween our KL assumption and the one used in [38]. Finally, we demonstrate how\nthe pDCA$_e$ can be applied to a class of simultaneous sparse recovery and\noutlier detection problems arising from robust compressed sensing in signal\nprocessing and least trimmed squares regression in statistics. Specifically, we\nshow that the objectives of these problems can be written as level-bounded DC\nfunctions whose concave parts are {\\em typically nonsmooth}. Moreover, for a\nlarge class of loss functions and regularizers, the KL exponent of the\ncorresponding potential function are shown to be 1/2, which implies that the\npDCA$_e$ is locally linearly convergent when applied to these problems. Our\nnumerical experiments show that the pDCA$_e$ usually outperforms the proximal\nDC algorithm with nonmonotone linesearch [24, Appendix A] in both CPU time and\nsolution quality for this particular application. \n\n"}
{"id": "1804.09554", "contents": "Title: Stochastic Conditional Gradient Methods: From Convex Minimization to\n  Submodular Maximization Abstract: This paper considers stochastic optimization problems for a large class of\nobjective functions, including convex and continuous submodular. Stochastic\nproximal gradient methods have been widely used to solve such problems;\nhowever, their applicability remains limited when the problem dimension is\nlarge and the projection onto a convex set is costly. Instead, stochastic\nconditional gradient methods are proposed as an alternative solution relying on\n(i) Approximating gradients via a simple averaging technique requiring a single\nstochastic gradient evaluation per iteration; (ii) Solving a linear program to\ncompute the descent/ascent direction. The averaging technique reduces the noise\nof gradient approximations as time progresses, and replacing projection step in\nproximal methods by a linear program lowers the computational complexity of\neach iteration. We show that under convexity and smoothness assumptions, our\nproposed method converges to the optimal objective function value at a\nsublinear rate of $O(1/t^{1/3})$. Further, for a monotone and continuous\nDR-submodular function and subject to a general convex body constraint, we\nprove that our proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with\n$O(1/\\eps^3)$ stochastic gradient computations. This guarantee matches the\nknown hardness results and closes the gap between deterministic and stochastic\ncontinuous submodular maximization. Additionally, we obtain $((1/e)OPT -\\eps)$\nguarantee after using $O(1/\\eps^3)$ stochastic gradients for the case that the\nobjective function is continuous DR-submodular but non-monotone and the\nconstraint set is down-closed. By using stochastic continuous optimization as\nan interface, we provide the first $(1-1/e)$ tight approximation guarantee for\nmaximizing a monotone but stochastic submodular set function subject to a\nmatroid constraint and $(1/e)$ approximation guarantee for the non-monotone\ncase. \n\n"}
{"id": "1804.09559", "contents": "Title: Feedback Synthesis For Underactuated Systems Using Sequential\n  Second-Order Needle Variations Abstract: This paper derives nonlinear feedback control synthesis for general control\naffine systems using second-order actions---the second-order needle variations\nof optimal control---as the basis for choosing each control response to the\ncurrent state. A second result of the paper is that the method provably\nexploits the nonlinear controllability of a system by virtue of an explicit\ndependence of the second-order needle variation on the Lie bracket between\nvector fields. As a result, each control decision necessarily decreases the\nobjective when the system is nonlinearly controllable using first-order Lie\nbrackets. Simulation results using a differential drive cart, an underactuated\nkinematic vehicle in three dimensions, and an underactuated dynamic model of an\nunderwater vehicle demonstrate that the method finds control solutions when the\nfirst-order analysis is singular. Lastly, the underactuated dynamic underwater\nvehicle model demonstrates convergence even in the presence of a velocity\nfield. \n\n"}
{"id": "1804.09629", "contents": "Title: Convergence guarantees for a class of non-convex and non-smooth\n  optimization problems Abstract: We consider the problem of finding critical points of functions that are\nnon-convex and non-smooth. Studying a fairly broad class of such problems, we\nanalyze the behavior of three gradient-based methods (gradient descent,\nproximal update, and Frank-Wolfe update). For each of these methods, we\nestablish rates of convergence for general problems, and also prove faster\nrates for continuous sub-analytic functions. We also show that our algorithms\ncan escape strict saddle points for a class of non-smooth functions, thereby\ngeneralizing known results for smooth functions. Our analysis leads to a\nsimplification of the popular CCCP algorithm, used for optimizing functions\nthat can be written as a difference of two convex functions. Our simplified\nalgorithm retains all the convergence properties of CCCP, along with a\nsignificantly lower cost per iteration. We illustrate our methods and theory\nvia applications to the problems of best subset selection, robust estimation,\nmixture density estimation, and shape-from-shading reconstruction. \n\n"}
{"id": "1804.10328", "contents": "Title: Scalable Bilinear $\\pi$ Learning Using State and Action Features Abstract: Approximate linear programming (ALP) represents one of the major algorithmic\nfamilies to solve large-scale Markov decision processes (MDP). In this work, we\nstudy a primal-dual formulation of the ALP, and develop a scalable, model-free\nalgorithm called bilinear $\\pi$ learning for reinforcement learning when a\nsampling oracle is provided. This algorithm enjoys a number of advantages.\nFirst, it adopts (bi)linear models to represent the high-dimensional value\nfunction and state-action distributions, using given state and action features.\nIts run-time complexity depends on the number of features, not the size of the\nunderlying MDPs. Second, it operates in a fully online fashion without having\nto store any sample, thus having minimal memory footprint. Third, we prove that\nit is sample-efficient, solving for the optimal policy to high precision with a\nsample complexity linear in the dimension of the parameter space. \n\n"}
{"id": "1804.10483", "contents": "Title: A Graph-Theoretic Approach to the $\\mathcal{H}_{\\infty}$ Performance of\n  Dynamical Systems on Directed and Undirected Networks Abstract: We study a graph-theoretic approach to the $\\mathcal{H}_{\\infty}$ performance\nof leader following consensus dynamics on directed and undirected graphs. We\nfirst provide graph-theoretic bounds on the system $\\mathcal{H}_{\\infty}$ norm\nof the leader following dynamics and show the tightness of the proposed bounds.\nThen, we discuss the relation between the system $\\mathcal{H}_{\\infty}$ norm\nfor directed and undirected networks for specific classes of graphs, i.e.,\nbalanced digraphs and directed trees. Moreover, we investigate the effects of\nadding directed edges to a directed tree on the resulting system\n$\\mathcal{H}_{\\infty}$ norm. In the end, we apply these theoretical results to\na reference velocity tracking problem in a platoon of connected vehicles and\ndiscuss the effect of the location of the leading vehicle on the overall\n$\\mathcal{H}_{\\infty}$ performance of the system. \n\n"}
{"id": "1804.10554", "contents": "Title: Random Asynchronous Iterations in Distributed Coordination Algorithms Abstract: Distributed coordination algorithms (DCA) carry out information processing\nprocesses among a group of networked agents without centralized information\nfusion. Though it is well known that DCA characterized by an SIA (stochastic,\nindecomposable, aperiodic) matrix generate consensus asymptotically via\nsynchronous iterations, the dynamics of DCA with asynchronous iterations have\nnot been studied extensively, especially when viewed as stochastic processes.\nThis paper aims to show that for any given irreducible stochastic matrix, even\nnon-SIA, the corresponding DCA lead to consensus successfully via random\nasynchronous iterations under a wide range of conditions on the transition\nprobability. Particularly, the transition probability is neither required to be\nindependent and identically distributed, nor characterized by a Markov chain. \n\n"}
{"id": "1804.10635", "contents": "Title: Extended Euler-Lagrange and Hamiltonian Conditions in Optimal Control of\n  Sweeping Processes with Controlled Moving Sets Abstract: This paper concerns optimal control problems for a class of sweeping\nprocesses governed by discontinuous unbounded differential inclusions that are\ndescribed via normal cone mappings to controlled moving sets. Largely motivated\nby applications to hysteresis, we consider a general setting where moving sets\nare given as inverse images of closed subsets of finite-dimensional spaces\nunder nonlinear differentiable mappings dependent on both state and control\nvariables. Developing the method of discrete approximations and employing\ngeneralized differential tools of first-order and second-order variational\nanalysis allow us to derive nondegenerated necessary optimality conditions for\nsuch problems in extended Euler-Lagrange and Hamiltonian forms involving the\nHamiltonian maximization. The latter conditions of the Pontryagin Maximum\nPrinciple type are the first in the literature for optimal control of sweeping\nprocesses with control-dependent moving sets. \n\n"}
{"id": "1805.00521", "contents": "Title: Direct Runge-Kutta Discretization Achieves Acceleration Abstract: We study gradient-based optimization methods obtained by directly\ndiscretizing a second-order ordinary differential equation (ODE) related to the\ncontinuous limit of Nesterov's accelerated gradient method. When the function\nis smooth enough, we show that acceleration can be achieved by a stable\ndiscretization of this ODE using standard Runge-Kutta integrators.\nSpecifically, we prove that under Lipschitz-gradient, convexity and\norder-$(s+2)$ differentiability assumptions, the sequence of iterates generated\nby discretizing the proposed second-order ODE converges to the optimal solution\nat a rate of $\\mathcal{O}({N^{-2\\frac{s}{s+1}}})$, where $s$ is the order of\nthe Runge-Kutta numerical integrator. Furthermore, we introduce a new local\nflatness condition on the objective, under which rates even faster than\n$\\mathcal{O}(N^{-2})$ can be achieved with low-order integrators and only\ngradient information. Notably, this flatness condition is satisfied by several\nstandard loss functions used in machine learning. We provide numerical\nexperiments that verify the theoretical rates predicted by our results. \n\n"}
{"id": "1805.00871", "contents": "Title: Undersampled dynamic X-ray tomography with dimension reduction Kalman\n  filter Abstract: In this paper, we consider prior-based dimension reduction Kalman filter for\nundersampled dynamic X-ray tomography. With this method, the X-ray\nreconstructions are parameterized by a low-dimensional basis. Thus, the\nproposed method is a) computationally very light; and b) extremely robust as\nall the computations can be done explicitly. With real and simulated\nmeasurement data, we show that the method provides accurate reconstructions\neven with very limited number of angular directions. \n\n"}
{"id": "1805.01916", "contents": "Title: Analysis of nonsmooth stochastic approximation: the differential\n  inclusion approach Abstract: In this paper we address the convergence of stochastic approximation when the\nfunctions to be minimized are not convex and nonsmooth. We show that the\n\"mean-limit\" approach to the convergence which leads, for smooth problems, to\nthe ODE approach can be adapted to the non-smooth case. The limiting dynamical\nsystem may be shown to be, under appropriate assumption, a differential\ninclusion. Our results expand earlier works in this direction by Benaim et al.\n(2005) and provide a general framework for proving convergence for\nunconstrained and constrained stochastic approximation problems, with either\nexplicit or implicit updates. In particular, our results allow us to establish\nthe convergence of stochastic subgradient and proximal stochastic gradient\ndescent algorithms arising in a large class of deep learning and\nhigh-dimensional statistical inference with sparsity inducing penalties. \n\n"}
{"id": "1805.01967", "contents": "Title: Estimation of Power System Inertia Using Nonlinear Koopman Modes Abstract: We report a new approach to estimating power system inertia directly from\ntime-series data on power system dynamics. The approach is based on the\nso-called Koopman Mode Decomposition (KMD) of such dynamic data, which is a\nnonlinear generalization of linear modal decomposition through spectral\nanalysis of the Koopman operator for nonlinear dynamical systems. The KMD-based\napproach is thus applicable to dynamic data that evolve in nonlinear regime of\npower system characteristics. Its effectiveness is numerically evaluated with\ntransient stability simulations of the IEEE New England test system. \n\n"}
{"id": "1805.01969", "contents": "Title: Exploiting timing information in event-triggered stabilization of linear\n  systems with disturbances Abstract: In the same way that subsequent pauses in spoken language are used to convey\ninformation, it is also possible to transmit information in communication\nnetworks not only by message content, but also with its timing. This paper\npresents an event-triggering strategy that utilizes timing information by\ntransmitting in a state-dependent fashion. We consider the stabilization of a\ncontinuous-time, time-invariant, linear plant over a digital communication\nchannel with bounded delay and subject to bounded plant disturbances and\nestablish two main results. On the one hand, we design an encoding-decoding\nscheme that guarantees a sufficient information transmission rate for\nstabilization. On the other hand, we determine a lower bound on the information\ntransmission rate necessary for stabilization by any control policy. \n\n"}
{"id": "1805.02338", "contents": "Title: Implementation of Stochastic Quasi-Newton's Method in PyTorch Abstract: In this paper, we implement the Stochastic Damped LBFGS (SdLBFGS) for\nstochastic non-convex optimization. We make two important modifications to the\noriginal SdLBFGS algorithm. First, by initializing the Hessian at each step\nusing an identity matrix, the algorithm converges better than original\nalgorithm. Second, by performing direction normalization we could gain stable\noptimization procedure without line search. Experiments on minimizing a 2D\nnon-convex function shows that our improved algorithm converges better than\noriginal algorithm, and experiments on the CIFAR10 and MNIST datasets show that\nour improved algorithm works stably and gives comparable or even better testing\naccuracies than first order optimizers SGD, Adagrad, and second order\noptimizers LBFGS in PyTorch. \n\n"}
{"id": "1805.02782", "contents": "Title: Theoretical challenges towards cutting-plane selection Abstract: While many classes of cutting-planes are at the disposal of integer\nprogramming solvers, our scientific understanding is far from complete with\nregards to cutting-plane selection, i.e., the task of selecting a portfolio of\ncutting-planes to be added to the LP relaxation at a given node of the\nbranch-and-bound tree. In this paper we review the different classes of\ncutting-planes available, known theoretical results about their relative\nstrength, important issues pertaining to cut selection, and discuss some\npossible new directions to be pursued in order to accomplish cutting-plane\nselection in a more principled manner. Finally, we review some lines of work\nthat we undertook to provide a preliminary theoretical underpinning for some of\nthe issues related to cut selection. \n\n"}
{"id": "1805.03588", "contents": "Title: Distributionally robust optimization with polynomial densities: theory,\n  models and algorithms Abstract: In distributionally robust optimization the probability distribution of the\nuncertain problem parameters is itself uncertain, and a fictitious adversary,\ne.g., nature, chooses the worst distribution from within a known ambiguity set.\nA common shortcoming of most existing distributionally robust optimization\nmodels is that their ambiguity sets contain pathological discrete distribution\nthat give nature too much freedom to inflict damage. We thus introduce a new\nclass of ambiguity sets that contain only distributions with sum-of-squares\npolynomial density functions of known degrees. We show that these ambiguity\nsets are highly expressive as they conveniently accommodate distributional\ninformation about higher-order moments, conditional probabilities, conditional\nmoments or marginal distributions. Exploiting the theoretical properties of a\nmeasure-based hierarchy for polynomial optimization due to Lasserre [SIAM J.\nOptim. 21(3) (2011), pp. 864--885], we prove that certain worst-case\nexpectation constraints are computationally tractable under these new ambiguity\nsets. We showcase the practical applicability of the proposed approach in the\ncontext of a stylized portfolio optimization problem and a risk aggregation\nproblem of an insurance company. \n\n"}
{"id": "1805.05411", "contents": "Title: Accelerated Stochastic Algorithms for Nonconvex Finite-sum and\n  Multi-block Optimization Abstract: In this paper, we present new stochastic methods for solving two important\nclasses of nonconvex optimization problems. We first introduce a randomized\naccelerated proximal gradient (RapGrad) method for solving a class of nonconvex\noptimization problems consisting of the sum of $m$ component functions, and\nshow that it can significantly reduce the number of gradient computations\nespecially when the condition number $L/\\mu$ (i.e., the ratio between the\nLipschitz constant and negative curvature) is large. More specifically, RapGrad\ncan save up to ${\\cal O}(\\sqrt{m})$ gradient computations than existing\ndeterministic nonconvex accelerated gradient methods. Moreover, the number of\ngradient computations required by RapGrad can be ${\\cal O}(m^\\frac{1}{6}\nL^\\frac{1}{2} / \\mu^\\frac{1}{2})$ (at least ${\\cal O}(m^\\frac{2}{3})$) times\nsmaller than the best-known randomized nonconvex gradient methods when $L/\\mu\n\\ge m$. Inspired by RapGrad, we also develop a new randomized accelerated\nproximal dual (RapDual) method for solving a class of multi-block nonconvex\noptimization problems coupled with linear constraints. We demonstrate that\nRapDual can also save up to a factor of ${\\cal O}(\\sqrt{m})$ projection\nsubproblems than its deterministic counterpart, where $m$ denotes the number of\nblocks. To the best of our knowledge, all these complexity results associated\nwith RapGrad and RapDual seem to be new in the literature. We also illustrate\npotential advantages of these algorithms through our preliminary numerical\nexperiments. \n\n"}
{"id": "1805.05751", "contents": "Title: Local Saddle Point Optimization: A Curvature Exploitation Approach Abstract: Gradient-based optimization methods are the most popular choice for finding\nlocal optima for classical minimization and saddle point problems. Here, we\nhighlight a systemic issue of gradient dynamics that arise for saddle point\nproblems, namely the presence of undesired stable stationary points that are no\nlocal optima. We propose a novel optimization approach that exploits curvature\ninformation in order to escape from these undesired stationary points. We prove\nthat different optimization methods, including gradient method and Adagrad,\nequipped with curvature exploitation can escape non-optimal stationary points.\nWe also provide empirical results on common saddle point problems which confirm\nthe advantage of using curvature exploitation. \n\n"}
{"id": "1805.05876", "contents": "Title: Observability Analysis of Aided INS with Heterogeneous Features of\n  Points, Lines and Planes Abstract: In this paper, we perform a thorough observability analysis for linearized\ninertial navigation systems (INS) aided by exteroceptive range and/or bearing\nsensors (such as cameras, LiDAR and sonars) with different geometric features\n(points, lines and planes). While the observability of vision-aided INS (VINS)\nwith point features has been extensively studied in the literature, we\nanalytically show that the general aided INS with point features preserves the\nsame observability property: that is, 4 unobservable directions, corresponding\nto the global yaw and the global position of the sensor platform. We further\nprove that there are at least 5 (and 7) unobservable directions for the\nlinearized aided INS with a single line (and plane) feature; and, for the first\ntime, analytically derive the unobservable subspace for the case of multiple\nlines/planes. Building upon this, we examine the system observability of the\nlinearized aided INS with different combinations of points, lines and planes,\nand show that, in general, the system preserves at least 4 unobservable\ndirections, while if global measurements are available, as expected, some\nunobservable directions diminish. In particular, when using plane features, we\npropose to use a minimal, closest point (CP) representation; and we also study\nin-depth the effects of 5 degenerate motions identified on observability. To\nnumerically validate our analysis, we develop and evaluate both EKF-based\nvisual-inertial SLAM and visual-inertial odometry (VIO) using heterogeneous\ngeometric features in Monte Carlo simulations. \n\n"}
{"id": "1805.06498", "contents": "Title: Utility maximization with proportional transaction costs under model\n  uncertainty Abstract: We consider a discrete time financial market with proportional transaction\ncosts under model uncertainty, and study a num\\'eraire-based semi-static\nutility maximization problem with an exponential utility preference. The\nrandomization techniques recently developed in \\cite{BDT17} allow us to\ntransform the original problem into a frictionless counterpart on an enlarged\nspace. By suggesting a different dynamic programming argument than in\n\\cite{bartl2016exponential}, we are able to prove the existence of the optimal\nstrategy and the convex duality theorem in our context with transaction costs.\nIn the frictionless framework, this alternative dynamic programming argument\nalso allows us to generalize the main results in \\cite{bartl2016exponential} to\na weaker market condition. Moreover, as an application of the duality\nrepresentation, some basic features of utility indifference prices are\ninvestigated in our robust setting with transaction costs. \n\n"}
{"id": "1805.06523", "contents": "Title: End-to-end Learning of a Convolutional Neural Network via Deep Tensor\n  Decomposition Abstract: In this paper we study the problem of learning the weights of a deep\nconvolutional neural network. We consider a network where convolutions are\ncarried out over non-overlapping patches with a single kernel in each layer. We\ndevelop an algorithm for simultaneously learning all the kernels from the\ntraining data. Our approach dubbed Deep Tensor Decomposition (DeepTD) is based\non a rank-1 tensor decomposition. We theoretically investigate DeepTD under a\nrealizable model for the training data where the inputs are chosen i.i.d. from\na Gaussian distribution and the labels are generated according to planted\nconvolutional kernels. We show that DeepTD is data-efficient and provably works\nas soon as the sample size exceeds the total number of convolutional weights in\nthe network. We carry out a variety of numerical experiments to investigate the\neffectiveness of DeepTD and verify our theoretical findings. \n\n"}
{"id": "1805.06579", "contents": "Title: ADMM and Accelerated ADMM as Continuous Dynamical Systems Abstract: Recently, there has been an increasing interest in using tools from dynamical\nsystems to analyze the behavior of simple optimization algorithms such as\ngradient descent and accelerated variants. This paper strengthens such\nconnections by deriving the differential equations that model the continuous\nlimit of the sequence of iterates generated by the alternating direction method\nof multipliers, as well as an accelerated variant. We employ the direct method\nof Lyapunov to analyze the stability of critical points of the dynamical\nsystems and to obtain associated convergence rates. \n\n"}
{"id": "1805.07272", "contents": "Title: Fast Multivariate Log-Concave Density Estimation Abstract: A novel computational approach to log-concave density estimation is proposed.\nPrevious approaches utilize the piecewise-affine parametrization of the density\ninduced by the given sample set. The number of parameters as well as non-smooth\nsubgradient-based convex optimization for determining the maximum likelihood\ndensity estimate cause long runtimes for dimensions $d \\geq 2$ and large sample\nsets. The presented approach is based on mildly non-convex smooth\napproximations of the objective function and \\textit{sparse}, adaptive\npiecewise-affine density parametrization. Established memory-efficient\nnumerical optimization techniques enable to process larger data sets for\ndimensions $d \\geq 2$. While there is no guarantee that the algorithm returns\nthe maximum likelihood estimate for every problem instance, we provide\ncomprehensive numerical evidence that it does yield near-optimal results after\nsignificantly shorter runtimes. For example, 10000 samples in $\\mathbb{R}^2$\nare processed in two seconds, rather than in $\\approx 14$ hours required by the\nprevious approach to terminate. For higher dimensions, density estimation\nbecomes tractable as well: Processing $10000$ samples in $\\mathbb{R}^6$\nrequires 35 minutes. The software is publicly available as CRAN R package\nfmlogcondens. \n\n"}
{"id": "1805.07957", "contents": "Title: Stochastic maximum principle for equations with delay: the non-convex\n  case Abstract: In this paper we develop necessary conditions for optimality, in the form of\nthe stochastic Pontryagin maximum principle, for controlled equations with\npointwise delay in the state and with control dependent noise, in the general\ncase of controls $u \\in U$ with $U$ not necessarily convex. The maximum\nprinciple is formulated by means of first and second order adjoint BSDEs. We\nalso outline how to deal with control problems with pointwise delay both in the\nstate and in the control. \n\n"}
{"id": "1805.07962", "contents": "Title: A Nonconvex Projection Method for Robust PCA Abstract: Robust principal component analysis (RPCA) is a well-studied problem with the\ngoal of decomposing a matrix into the sum of low-rank and sparse components. In\nthis paper, we propose a nonconvex feasibility reformulation of RPCA problem\nand apply an alternating projection method to solve it. To the best of our\nknowledge, we are the first to propose a method that solves RPCA problem\nwithout considering any objective function, convex relaxation, or surrogate\nconvex constraints. We demonstrate through extensive numerical experiments on a\nvariety of applications, including shadow removal, background estimation, face\ndetection, and galaxy evolution, that our approach matches and often\nsignificantly outperforms current state-of-the-art in various ways. \n\n"}
{"id": "1805.08380", "contents": "Title: Optimal transport natural gradient for statistical manifolds with\n  continuous sample space Abstract: We study the Wasserstein natural gradient in parametric statistical models\nwith continuous sample spaces. Our approach is to pull back the\n$L^2$-Wasserstein metric tensor in the probability density space to a parameter\nspace, equipping the latter with a positive definite metric tensor, under which\nit becomes a Riemannian manifold, named the Wasserstein statistical manifold.\nIn general, it is not a totally geodesic sub-manifold of the density space, and\ntherefore its geodesics will differ from the Wasserstein geodesics, except for\nthe well-known Gaussian distribution case, a fact which can also be validated\nunder our framework. We use the sub-manifold geometry to derive a gradient flow\nand natural gradient descent method in the parameter space. When parametrized\ndensities lie in $\\bR$, the induced metric tensor establishes an explicit\nformula. In optimization problems, we observe that the natural gradient descent\noutperforms the standard gradient descent when the Wasserstein distance is the\nobjective function. In such a case, we prove that the resulting algorithm\nbehaves similarly to the Newton method in the asymptotic regime. The proof\ncalculates the exact Hessian formula for the Wasserstein distance, which\nfurther motivates another preconditioner for the optimization process. To the\nend, we present examples to illustrate the effectiveness of the natural\ngradient in several parametric statistical models, including the Gaussian\nmeasure, Gaussian mixture, Gamma distribution, and Laplace distribution. \n\n"}
{"id": "1805.08890", "contents": "Title: Step Size Matters in Deep Learning Abstract: Training a neural network with the gradient descent algorithm gives rise to a\ndiscrete-time nonlinear dynamical system. Consequently, behaviors that are\ntypically observed in these systems emerge during training, such as convergence\nto an orbit but not to a fixed point or dependence of convergence on the\ninitialization. Step size of the algorithm plays a critical role in these\nbehaviors: it determines the subset of the local optima that the algorithm can\nconverge to, and it specifies the magnitude of the oscillations if the\nalgorithm converges to an orbit. To elucidate the effects of the step size on\ntraining of neural networks, we study the gradient descent algorithm as a\ndiscrete-time dynamical system, and by analyzing the Lyapunov stability of\ndifferent solutions, we show the relationship between the step size of the\nalgorithm and the solutions that can be obtained with this algorithm. The\nresults provide an explanation for several phenomena observed in practice,\nincluding the deterioration in the training error with increased depth, the\nhardness of estimating linear mappings with large singular values, and the\ndistinct performance of deep residual networks. \n\n"}
{"id": "1805.09077", "contents": "Title: Accelerated Gradient Methods with Memory Abstract: A set of accelerated first order algorithms with memory are proposed for\nminimising strongly convex functions. The algorithms are differentiated by\ntheir use of the iterate history for the gradient step. The increased\nconvergence rate of the proposed algorithms comes at the cost of robustness, a\nproblem that is resolved by a switching controller based upon adaptive\nrestarting. Several numerical examples highlight the benefits of the proposed\napproach over the fast gradient method. For example, it is shown that these\ngradient based methods can minimise the Rosenbrock banana function to $7.58\n\\times 10^{-12}$ in 43 iterations from an initial condition of $(-1,1)$. \n\n"}
{"id": "1805.09185", "contents": "Title: Alternating Randomized Block Coordinate Descent Abstract: Block-coordinate descent algorithms and alternating minimization methods are\nfundamental optimization algorithms and an important primitive in large-scale\noptimization and machine learning. While various block-coordinate-descent-type\nmethods have been studied extensively, only alternating minimization -- which\napplies to the setting of only two blocks -- is known to have convergence time\nthat scales independently of the least smooth block. A natural question is\nthen: is the setting of two blocks special?\n  We show that the answer is \"no\" as long as the least smooth block can be\noptimized exactly -- an assumption that is also needed in the setting of\nalternating minimization. We do so by introducing a novel algorithm AR-BCD,\nwhose convergence time scales independently of the least smooth (possibly\nnon-smooth) block. The basic algorithm generalizes both alternating\nminimization and randomized block coordinate (gradient) descent, and we also\nprovide its accelerated version -- AAR-BCD. As a special case of AAR-BCD, we\nobtain the first nontrivial accelerated alternating minimization algorithm. \n\n"}
{"id": "1805.09261", "contents": "Title: Online shortest paths with confidence intervals for routing in a time\n  varying random network Abstract: The increase in the world's population and rising standards of living is\nleading to an ever-increasing number of vehicles on the roads, and with it\never-increasing difficulties in traffic management. This traffic management in\ntransport networks can be clearly optimized by using information and\ncommunication technologies referred as Intelligent Transport Systems (ITS).\nThis management problem is usually reformulated as finding the shortest path in\na time varying random graph. In this article, an online shortest path\ncomputation using stochastic gradient descent is proposed. This routing\nalgorithm for ITS traffic management is based on the online Frank-Wolfe\napproach. Our improvement enables to find a confidence interval for the\nshortest path, by using the stochastic gradient algorithm for approximate\nBayesian inference. \n\n"}
{"id": "1805.09293", "contents": "Title: Learning to Optimize Contextually Constrained Problems for Real-Time\n  Decision-Generation Abstract: The topic of learning to solve optimization problems has received interest\nfrom both the operations research and machine learning communities. In this\nwork, we combine techniques from both fields to address the problem of learning\nto generate decisions to instances of continuous optimization problems where\nthe feasible set varies with contextual features. We propose a novel framework\nfor training a generative model to estimate optimal decisions by combining\ninterior point methods and adversarial learning, which we further embed within\nan data generation algorithm. Decisions generated by our model satisfy\nin-sample and out-of-sample optimality guarantees. Finally, we investigate case\nstudies in portfolio optimization and personalized treatment design,\ndemonstrating that our approach yields advantages over predict-then-optimize\nand supervised deep learning techniques, respectively. \n\n"}
{"id": "1805.09315", "contents": "Title: A Graphical Measure of Aggregate Flexibility for Energy-Constrained\n  Distributed Resources Abstract: We consider the problem of dispatching a fleet of heterogeneous energy\nstorage units to provide grid support. Under the restriction that recharging is\nnot possible during the time frame of interest, we develop an aggregate measure\nof fleet flexibility with an intuitive graphical interpretation. This\nanalytical expression summarises the full set of demand traces that the fleet\ncan satisfy, and can be used for immediate and straightforward determination of\nthe feasibility of any service request. This representation therefore\nfacilitates a wide range of capability assessments, such as flexibility\ncomparisons between fleets or the determination of a fleet's ability to deliver\nancillary services. Examples are shown of applications to fleet flexibility\ncomparisons, signal feasibility assessment and the optimisation of ancillary\nservice provision. \n\n"}
{"id": "1805.09386", "contents": "Title: Predictive Local Smoothness for Stochastic Gradient Methods Abstract: Stochastic gradient methods are dominant in nonconvex optimization especially\nfor deep models but have low asymptotical convergence due to the fixed\nsmoothness. To address this problem, we propose a simple yet effective method\nfor improving stochastic gradient methods named predictive local smoothness\n(PLS). First, we create a convergence condition to build a learning rate which\nvaries adaptively with local smoothness. Second, the local smoothness can be\npredicted by the latest gradients. Third, we use the adaptive learning rate to\nupdate the stochastic gradients for exploring linear convergence rates. By\napplying the PLS method, we implement new variants of three popular algorithms:\nPLS-stochastic gradient descent (PLS-SGD), PLS-accelerated SGD (PLS-AccSGD),\nand PLS-AMSGrad. Moreover, we provide much simpler proofs to ensure their\nlinear convergence. Empirical results show that the variants have better\nperformance gains than the popular algorithms, such as, faster convergence and\nalleviating explosion and vanish of gradients. \n\n"}
{"id": "1805.09388", "contents": "Title: Regret Bounds for Robust Adaptive Control of the Linear Quadratic\n  Regulator Abstract: We consider adaptive control of the Linear Quadratic Regulator (LQR), where\nan unknown linear system is controlled subject to quadratic costs. Leveraging\nrecent developments in the estimation of linear systems and in robust\ncontroller synthesis, we present the first provably polynomial time algorithm\nthat provides high probability guarantees of sub-linear regret on this problem.\nWe further study the interplay between regret minimization and parameter\nestimation by proving a lower bound on the expected regret in terms of the\nexploration schedule used by any algorithm. Finally, we conduct a numerical\nstudy comparing our robust adaptive algorithm to other methods from the\nadaptive LQR literature, and demonstrate the flexibility of our proposed method\nby extending it to a demand forecasting problem subject to state constraints. \n\n"}
{"id": "1805.09464", "contents": "Title: Simple and practical algorithms for $\\ell_p$-norm low-rank approximation Abstract: We propose practical algorithms for entrywise $\\ell_p$-norm low-rank\napproximation, for $p = 1$ or $p = \\infty$. The proposed framework, which is\nnon-convex and gradient-based, is easy to implement and typically attains\nbetter approximations, faster, than state of the art.\n  From a theoretical standpoint, we show that the proposed scheme can attain\n$(1 + \\varepsilon)$-OPT approximations. Our algorithms are not\nhyperparameter-free: they achieve the desiderata only assuming algorithm's\nhyperparameters are known a priori---or are at least approximable. I.e., our\ntheory indicates what problem quantities need to be known, in order to get a\ngood solution within polynomial time, and does not contradict to recent\ninapproximabilty results, as in [46]. \n\n"}
{"id": "1805.09480", "contents": "Title: Optimal Algorithms for Continuous Non-monotone Submodular and\n  DR-Submodular Maximization Abstract: In this paper we study the fundamental problems of maximizing a continuous\nnon-monotone submodular function over the hypercube, both with and without\ncoordinate-wise concavity. This family of optimization problems has several\napplications in machine learning, economics, and communication systems. Our\nmain result is the first $\\frac{1}{2}$-approximation algorithm for continuous\nsubmodular function maximization; this approximation factor of $\\frac{1}{2}$ is\nthe best possible for algorithms that only query the objective function at\npolynomially many points. For the special case of DR-submodular maximization,\ni.e. when the submodular functions is also coordinate wise concave along all\ncoordinates, we provide a different $\\frac{1}{2}$-approximation algorithm that\nruns in quasilinear time. Both of these results improve upon prior work [Bian\net al, 2017, Soma and Yoshida, 2017].\n  Our first algorithm uses novel ideas such as reducing the guaranteed\napproximation problem to analyzing a zero-sum game for each coordinate, and\nincorporates the geometry of this zero-sum game to fix the value at this\ncoordinate. Our second algorithm exploits coordinate-wise concavity to identify\na monotone equilibrium condition sufficient for getting the required\napproximation guarantee, and hunts for the equilibrium point using binary\nsearch. We further run experiments to verify the performance of our proposed\nalgorithms in related machine learning applications. \n\n"}
{"id": "1805.11792", "contents": "Title: Tight Regret Bounds for Bayesian Optimization in One Dimension Abstract: We consider the problem of Bayesian optimization (BO) in one dimension, under\na Gaussian process prior and Gaussian sampling noise. We provide a theoretical\nanalysis showing that, under fairly mild technical assumptions on the kernel,\nthe best possible cumulative regret up to time $T$ behaves as\n$\\Omega(\\sqrt{T})$ and $O(\\sqrt{T\\log T})$. This gives a tight characterization\nup to a $\\sqrt{\\log T}$ factor, and includes the first non-trivial lower bound\nfor noisy BO. Our assumptions are satisfied, for example, by the squared\nexponential and Mat\\'ern-$\\nu$ kernels, with the latter requiring $\\nu > 2$.\nOur results certify the near-optimality of existing bounds (Srinivas {\\em et\nal.}, 2009) for the SE kernel, while proving them to be strictly suboptimal for\nthe Mat\\'ern kernel with $\\nu > 2$. \n\n"}
{"id": "1805.12514", "contents": "Title: Scaling provable adversarial defenses Abstract: Recent work has developed methods for learning deep network classifiers that\nare provably robust to norm-bounded adversarial perturbation; however, these\nmethods are currently only possible for relatively small feedforward networks.\nIn this paper, in an effort to scale these approaches to substantially larger\nmodels, we extend previous work in three main directions. First, we present a\ntechnique for extending these training procedures to much more general\nnetworks, with skip connections (such as ResNets) and general nonlinearities;\nthe approach is fully modular, and can be implemented automatically (analogous\nto automatic differentiation). Second, in the specific case of $\\ell_\\infty$\nadversarial perturbations and networks with ReLU nonlinearities, we adopt a\nnonlinear random projection for training, which scales linearly in the number\nof hidden units (previous approaches scaled quadratically). Third, we show how\nto further improve robust error through cascade models. On both MNIST and CIFAR\ndata sets, we train classifiers that improve substantially on the state of the\nart in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST\n(with $\\ell_\\infty$ perturbations of $\\epsilon=0.1$), and from 80% to 36.4% on\nCIFAR (with $\\ell_\\infty$ perturbations of $\\epsilon=2/255$). Code for all\nexperiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial/. \n\n"}
{"id": "1806.00202", "contents": "Title: Online Learning with Inexact Proximal Online Gradient Descent Algorithms Abstract: We consider non-differentiable dynamic optimization problems such as those\narising in robotics and subspace tracking. Given the computational constraints\nand the time-varying nature of the problem, a low-complexity algorithm is\ndesirable, while the accuracy of the solution may only increase slowly over\ntime. We put forth the proximal online gradient descent (OGD) algorithm for\ntracking the optimum of a composite objective function comprising of a\ndifferentiable loss function and a non-differentiable regularizer. An online\nlearning framework is considered and the gradient of the loss function is\nallowed to be erroneous. Both, the gradient error as well as the dynamics of\nthe function optimum or target are adversarial and the performance of the\ninexact proximal OGD is characterized in terms of its dynamic regret, expressed\nin terms of the cumulative error and path length of the target. The proposed\ninexact proximal OGD is generalized for application to large-scale problems\nwhere the loss function has a finite sum structure. In such cases, evaluation\nof the full gradient may not be viable and a variance reduced version is\nproposed that allows the component functions to be sub-sampled. The efficacy of\nthe proposed algorithms is tested on the problem of formation control in\nrobotics and on the dynamic foreground-background separation problem in video. \n\n"}
{"id": "1806.00319", "contents": "Title: Learning convex bounds for linear quadratic control policy synthesis Abstract: Learning to make decisions from observed data in dynamic environments remains\na problem of fundamental importance in a number of fields, from artificial\nintelligence and robotics, to medicine and finance. This paper concerns the\nproblem of learning control policies for unknown linear dynamical systems so as\nto maximize a quadratic reward function. We present a method to optimize the\nexpected value of the reward over the posterior distribution of the unknown\nsystem parameters, given data. The algorithm involves sequential convex\nprograming, and enjoys reliable local convergence and robust stability\nguarantees. Numerical simulations and stabilization of a real-world inverted\npendulum are used to demonstrate the approach, with strong performance and\nrobustness properties observed in both. \n\n"}
{"id": "1806.00338", "contents": "Title: Structured Local Optima in Sparse Blind Deconvolution Abstract: Blind deconvolution is a ubiquitous problem of recovering two unknown signals\nfrom their convolution. Unfortunately, this is an ill-posed problem in general.\nThis paper focuses on the {\\em short and sparse} blind deconvolution problem,\nwhere the one unknown signal is short and the other one is sparsely and\nrandomly supported. This variant captures the structure of the unknown signals\nin several important applications. We assume the short signal to have unit\n$\\ell^2$ norm and cast the blind deconvolution problem as a nonconvex\noptimization problem over the sphere. We demonstrate that (i) in a certain\nregion of the sphere, every local optimum is close to some shift truncation of\nthe ground truth, and (ii) for a generic short signal of length $k$, when the\nsparsity of activation signal $\\theta\\lesssim k^{-2/3}$ and number of\nmeasurements $m\\gtrsim poly(k)$, a simple initialization method together with a\ndescent algorithm which escapes strict saddle points recovers a near shift\ntruncation of the ground truth kernel. \n\n"}
{"id": "1806.00406", "contents": "Title: New Gramians for Linear Switched Systems: Reachability, Observability,\n  and Model Reduction Abstract: In this paper, we propose new algebraic Gramians for continuous-time linear\nswitched systems, which satisfy generalized Lyapunov equations. The main\ncontribution of this work is twofold. First, we show that the ranges of those\nGramians encode the reachability and observability spaces of a linear switched\nsystem. As a consequence, a simple Gramian-based criterion for reachability and\nobservability is established. Second, a balancing-based model order reduction\ntechnique is proposed and, under some sufficient conditions, stability\npreservation and an error bound are shown. Finally, the efficiency of the\nproposed method is illustrated by means of numerical examples. \n\n"}
{"id": "1806.00534", "contents": "Title: Provably convergent acceleration in factored gradient descent with\n  applications in matrix sensing Abstract: We present theoretical results on the convergence of \\emph{non-convex}\naccelerated gradient descent in matrix factorization models with $\\ell_2$-norm\nloss. The purpose of this work is to study the effects of acceleration in\nnon-convex settings, where provable convergence with acceleration should not be\nconsidered a \\emph{de facto} property. The technique is applied to matrix\nsensing problems, for the estimation of a rank $r$ optimal solution $X^\\star\n\\in \\mathbb{R}^{n \\times n}$. Our contributions can be summarized as follows.\n$i)$ We show that acceleration in factored gradient descent converges at a\nlinear rate; this fact is novel for non-convex matrix factorization settings,\nunder common assumptions. $ii)$ Our proof technique requires the acceleration\nparameter to be carefully selected, based on the properties of the problem,\nsuch as the condition number of $X^\\star$ and the condition number of objective\nfunction. $iii)$ Currently, our proof leads to the same dependence on the\ncondition number(s) in the contraction parameter, similar to recent results on\nnon-accelerated algorithms. $iv)$ Acceleration is observed in practice, both in\nsynthetic examples and in two real applications: neuronal multi-unit activities\nrecovery from single electrode recordings, and quantum state tomography on\nquantum computing simulators. \n\n"}
{"id": "1806.00664", "contents": "Title: Robust Seriation and Applications to Cancer Genomics Abstract: The seriation problem seeks to reorder a set of elements given pairwise\nsimilarity information, so that elements with higher similarity are closer in\nthe resulting sequence. When a global ordering consistent with the similarity\ninformation exists, an exact spectral solution recovers it in the noiseless\ncase and seriation is equivalent to the combinatorial 2-SUM problem over\npermutations, for which several relaxations have been derived. However, in\napplications such as DNA assembly, similarity values are often heavily\ncorrupted, and the solution of 2-SUM may no longer yield an approximate serial\nstructure on the elements. We introduce the robust seriation problem and show\nthat it is equivalent to a modified 2-SUM problem for a class of similarity\nmatrices modeling those observed in DNA assembly. We explore several\nrelaxations of this modified 2-SUM problem and compare them empirically on both\nsynthetic matrices and real DNA data. We then introduce the problem of\nseriation with duplications, which is a generalization of Seriation motivated\nby applications to cancer genome reconstruction. We propose an algorithm\ninvolving robust seriation to solve it, and present preliminary results on\nsynthetic data sets. \n\n"}
{"id": "1806.00877", "contents": "Title: Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual\n  Optimization Abstract: Despite the success of single-agent reinforcement learning, multi-agent\nreinforcement learning (MARL) remains challenging due to complex interactions\nbetween agents. Motivated by decentralized applications such as sensor\nnetworks, swarm robotics, and power grids, we study policy evaluation in MARL,\nwhere agents with jointly observed state-action pairs and private local rewards\ncollaborate to learn the value of a given policy. In this paper, we propose a\ndouble averaging scheme, where each agent iteratively performs averaging over\nboth space and time to incorporate neighboring gradient information and local\nreward information, respectively. We prove that the proposed algorithm\nconverges to the optimal solution at a global geometric rate. In particular,\nsuch an algorithm is built upon a primal-dual reformulation of the mean squared\nprojected Bellman error minimization problem, which gives rise to a\ndecentralized convex-concave saddle-point problem. To the best of our\nknowledge, the proposed double averaging primal-dual optimization algorithm is\nthe first to achieve fast finite-time convergence on decentralized\nconvex-concave saddle-point problems. \n\n"}
{"id": "1806.00900", "contents": "Title: Algorithmic Regularization in Learning Deep Homogeneous Models: Layers\n  are Automatically Balanced Abstract: We study the implicit regularization imposed by gradient descent for learning\nmulti-layer homogeneous functions including feed-forward fully connected and\nconvolutional deep neural networks with linear, ReLU or Leaky ReLU activation.\nWe rigorously prove that gradient flow (i.e. gradient descent with\ninfinitesimal step size) effectively enforces the differences between squared\nnorms across different layers to remain invariant without any explicit\nregularization. This result implies that if the weights are initially small,\ngradient flow automatically balances the magnitudes of all layers. Using a\ndiscretization argument, we analyze gradient descent with positive step size\nfor the non-convex low-rank asymmetric matrix factorization problem without any\nregularization. Inspired by our findings for gradient flow, we prove that\ngradient descent with step sizes $\\eta_t = O\\left(t^{-\\left(\n\\frac12+\\delta\\right)} \\right)$ ($0<\\delta\\le\\frac12$) automatically balances\ntwo low-rank factors and converges to a bounded global optimum. Furthermore,\nfor rank-$1$ asymmetric matrix factorization we give a finer analysis showing\ngradient descent with constant step size converges to the global minimum at a\nglobally linear rate. We believe that the idea of examining the invariance\nimposed by first order algorithms in learning homogeneous models could serve as\na fundamental building block for studying optimization for learning deep\nmodels. \n\n"}
{"id": "1806.02927", "contents": "Title: Lightweight Stochastic Optimization for Minimizing Finite Sums with\n  Infinite Data Abstract: Variance reduction has been commonly used in stochastic optimization. It\nrelies crucially on the assumption that the data set is finite. However, when\nthe data are imputed with random noise as in data augmentation, the perturbed\ndata set be- comes essentially infinite. Recently, the stochastic MISO (S-MISO)\nalgorithm is introduced to address this expected risk minimization problem.\nThough it converges faster than SGD, a significant amount of memory is\nrequired. In this pa- per, we propose two SGD-like algorithms for expected risk\nminimization with random perturbation, namely, stochastic sample average\ngradient (SSAG) and stochastic SAGA (S-SAGA). The memory cost of SSAG does not\ndepend on the sample size, while that of S-SAGA is the same as those of\nvariance reduction methods on un- perturbed data. Theoretical analysis and\nexperimental results on logistic regression and AUC maximization show that SSAG\nhas faster convergence rate than SGD with comparable space requirement, while\nS-SAGA outperforms S-MISO in terms of both iteration complexity and storage. \n\n"}
{"id": "1806.02958", "contents": "Title: Efficient Full-Matrix Adaptive Regularization Abstract: Adaptive regularization methods pre-multiply a descent direction by a\npreconditioning matrix. Due to the large number of parameters of machine\nlearning problems, full-matrix preconditioning methods are prohibitively\nexpensive. We show how to modify full-matrix adaptive regularization in order\nto make it practical and effective. We also provide a novel theoretical\nanalysis for adaptive regularization in non-convex optimization settings. The\ncore of our algorithm, termed GGT, consists of the efficient computation of the\ninverse square root of a low-rank matrix. Our preliminary experiments show\nimproved iteration-wise convergence rates across synthetic tasks and standard\ndeep learning benchmarks, and that the more carefully-preconditioned steps\nsometimes lead to a better solution. \n\n"}
{"id": "1806.03667", "contents": "Title: Approximate Capture in Gromov-Hausdorff Closed Spaces Abstract: We consider the Lion and Man game, i.e., a two-person pursuit-evasion game\nwith equal players' top speeds. We assume that capture radius is positive and\nchosen in advance. The main aim of the paper is describing pursuer's winning\nstrategies in general compact metric spaces that are close to the given one in\nthe sense of Gromov-Hausdorff distance. We prove that the existence of\n$\\alpha$-capture by a time $T$ in one compact geodesic space implies the\nexistence of $(\\alpha + (20T +8)\\sqrt{\\varepsilon})$-capture by this time $T$\nin any compact geodesic space that is $\\varepsilon$-close to the given space.\nIt means that capture radii (in a nearby spaces) tends to the given one as the\ndistance between spaces tends to zero. Thus, this result justifies calculations\non graphs instead of complicated spaces. \n\n"}
{"id": "1806.05151", "contents": "Title: On Landscape of Lagrangian Functions and Stochastic Search for\n  Constrained Nonconvex Optimization Abstract: We study constrained nonconvex optimization problems in machine learning,\nsignal processing, and stochastic control. It is well-known that these problems\ncan be rewritten to a minimax problem in a Lagrangian form. However, due to the\nlack of convexity, their landscape is not well understood and how to find the\nstable equilibria of the Lagrangian function is still unknown. To bridge the\ngap, we study the landscape of the Lagrangian function. Further, we define a\nspecial class of Lagrangian functions. They enjoy two properties: 1.Equilibria\nare either stable or unstable (Formal definition in Section 2); 2.Stable\nequilibria correspond to the global optima of the original problem. We show\nthat a generalized eigenvalue (GEV) problem, including canonical correlation\nanalysis and other problems, belongs to the class. Specifically, we\ncharacterize its stable and unstable equilibria by leveraging an invariant\ngroup and symmetric property (more details in Section 3). Motivated by these\nneat geometric structures, we propose a simple, efficient, and stochastic\nprimal-dual algorithm solving the online GEV problem. Theoretically, we provide\nsufficient conditions, based on which we establish an asymptotic convergence\nrate and obtain the first sample complexity result for the online GEV problem\nby diffusion approximations, which are widely used in applied probability and\nstochastic control. Numerical results are provided to support our theory. \n\n"}
{"id": "1806.05358", "contents": "Title: Defending Against Saddle Point Attack in Byzantine-Robust Distributed\n  Learning Abstract: We study robust distributed learning that involves minimizing a non-convex\nloss function with saddle points. We consider the Byzantine setting where some\nworker machines have abnormal or even arbitrary and adversarial behavior. In\nthis setting, the Byzantine machines may create fake local minima near a saddle\npoint that is far away from any true local minimum, even when robust gradient\nestimators are used. We develop ByzantinePGD, a robust first-order algorithm\nthat can provably escape saddle points and fake local minima, and converge to\nan approximate true local minimizer with low iteration complexity. As a\nby-product, we give a simpler algorithm and analysis for escaping saddle points\nin the usual non-Byzantine setting. We further discuss three robust gradient\nestimators that can be used in ByzantinePGD, including median, trimmed mean,\nand iterative filtering. We characterize their performance in concrete\nstatistical settings, and argue for their near-optimality in low and high\ndimensional regimes. \n\n"}
{"id": "1806.05722", "contents": "Title: Non-asymptotic Identification of LTI Systems from a Single Trajectory Abstract: We consider the problem of learning a realization for a linear time-invariant\n(LTI) dynamical system from input/output data. Given a single input/output\ntrajectory, we provide finite time analysis for learning the system's Markov\nparameters, from which a balanced realization is obtained using the classical\nHo-Kalman algorithm. By proving a stability result for the Ho-Kalman algorithm\nand combining it with the sample complexity results for Markov parameters, we\nshow how much data is needed to learn a balanced realization of the system up\nto a desired accuracy with high probability. \n\n"}
{"id": "1806.06573", "contents": "Title: Distributed learning with compressed gradients Abstract: Asynchronous computation and gradient compression have emerged as two key\ntechniques for achieving scalability in distributed optimization for\nlarge-scale machine learning. This paper presents a unified analysis framework\nfor distributed gradient methods operating with staled and compressed\ngradients. Non-asymptotic bounds on convergence rates and information exchange\nare derived for several optimization algorithms. These bounds give explicit\nexpressions for step-sizes and characterize how the amount of asynchrony and\nthe compression accuracy affect iteration and communication complexity\nguarantees. Numerical results highlight convergence properties of different\ngradient compression algorithms and confirm that fast convergence under limited\ninformation exchange is indeed possible. \n\n"}
{"id": "1806.06761", "contents": "Title: Optimal Subsampling Algorithms for Big Data Regressions Abstract: To fast approximate maximum likelihood estimators with massive data, this\npaper studies the Optimal Subsampling Method under the A-optimality Criterion\n(OSMAC) for generalized linear models. The consistency and asymptotic normality\nof the estimator from a general subsampling algorithm are established, and\noptimal subsampling probabilities under the A- and L-optimality criteria are\nderived. Furthermore, using Frobenius norm matrix concentration inequalities,\nfinite sample properties of the subsample estimator based on optimal\nsubsampling probabilities are also derived. Since the optimal subsampling\nprobabilities depend on the full data estimate, an adaptive two-step algorithm\nis developed. Asymptotic normality and optimality of the estimator from this\nadaptive algorithm are established. The proposed methods are illustrated and\nevaluated through numerical experiments on simulated and real datasets. \n\n"}
{"id": "1806.06790", "contents": "Title: Towards Distributed Energy Services: Decentralizing Optimal Power Flow\n  with Machine Learning Abstract: The implementation of optimal power flow (OPF) methods to perform voltage and\npower flow regulation in electric networks is generally believed to require\nextensive communication. We consider distribution systems with multiple\ncontrollable Distributed Energy Resources (DERs) and present a data-driven\napproach to learn control policies for each DER to reconstruct and mimic the\nsolution to a centralized OPF problem from solely locally available\ninformation. Collectively, all local controllers closely match the centralized\nOPF solution, providing near optimal performance and satisfaction of system\nconstraints. A rate distortion framework enables the analysis of how well the\nresulting fully decentralized control policies are able to reconstruct the OPF\nsolution. The methodology provides a natural extension to decide what nodes a\nDER should communicate with to improve the reconstruction of its individual\npolicy. The method is applied on both single- and three-phase test feeder\nnetworks using data from real loads and distributed generators, focusing on\nDERs that do not exhibit inter-temporal dependencies. It provides a framework\nfor Distribution System Operators to efficiently plan and operate the\ncontributions of DERs to achieve Distributed Energy Services in distribution\nnetworks. \n\n"}
{"id": "1806.07137", "contents": "Title: Large-Scale Stochastic Sampling from the Probability Simplex Abstract: Stochastic gradient Markov chain Monte Carlo (SGMCMC) has become a popular\nmethod for scalable Bayesian inference. These methods are based on sampling a\ndiscrete-time approximation to a continuous time process, such as the Langevin\ndiffusion. When applied to distributions defined on a constrained space the\ntime-discretization error can dominate when we are near the boundary of the\nspace. We demonstrate that because of this, current SGMCMC methods for the\nsimplex struggle with sparse simplex spaces; when many of the components are\nclose to zero. Unfortunately, many popular large-scale Bayesian models, such as\nnetwork or topic models, require inference on sparse simplex spaces. To avoid\nthe biases caused by this discretization error, we propose the stochastic\nCox-Ingersoll-Ross process (SCIR), which removes all discretization error and\nwe prove that samples from the SCIR process are asymptotically unbiased. We\ndiscuss how this idea can be extended to target other constrained spaces. Use\nof the SCIR process within a SGMCMC algorithm is shown to give substantially\nbetter performance for a topic model and a Dirichlet process mixture model than\nexisting SGMCMC approaches. \n\n"}
{"id": "1806.07811", "contents": "Title: Stochastic Nested Variance Reduction for Nonconvex Optimization Abstract: We study finite-sum nonconvex optimization problems, where the objective\nfunction is an average of $n$ nonconvex functions. We propose a new stochastic\ngradient descent algorithm based on nested variance reduction. Compared with\nconventional stochastic variance reduced gradient (SVRG) algorithm that uses\ntwo reference points to construct a semi-stochastic gradient with diminishing\nvariance in each iteration, our algorithm uses $K+1$ nested reference points to\nbuild a semi-stochastic gradient to further reduce its variance in each\niteration. For smooth nonconvex functions, the proposed algorithm converges to\nan $\\epsilon$-approximate first-order stationary point (i.e., $\\|\\nabla\nF(\\mathbf{x})\\|_2\\leq \\epsilon$) within $\\tilde O(n\\land\n\\epsilon^{-2}+\\epsilon^{-3}\\land n^{1/2}\\epsilon^{-2})$ number of stochastic\ngradient evaluations. This improves the best known gradient complexity of SVRG\n$O(n+n^{2/3}\\epsilon^{-2})$ and that of SCSG $O(n\\land\n\\epsilon^{-2}+\\epsilon^{-10/3}\\land n^{2/3}\\epsilon^{-2})$. For gradient\ndominated functions, our algorithm also achieves better gradient complexity\nthan the state-of-the-art algorithms. Thorough experimental results on\ndifferent nonconvex optimization problems back up our theory. \n\n"}
{"id": "1806.07857", "contents": "Title: RUDDER: Return Decomposition for Delayed Rewards Abstract: We propose RUDDER, a novel reinforcement learning approach for delayed\nrewards in finite Markov decision processes (MDPs). In MDPs the Q-values are\nequal to the expected immediate reward plus the expected future rewards. The\nlatter are related to bias problems in temporal difference (TD) learning and to\nhigh variance problems in Monte Carlo (MC) learning. Both problems are even\nmore severe when rewards are delayed. RUDDER aims at making the expected future\nrewards zero, which simplifies Q-value estimation to computing the mean of the\nimmediate reward. We propose the following two new concepts to push the\nexpected future rewards toward zero. (i) Reward redistribution that leads to\nreturn-equivalent decision processes with the same optimal policies and, when\noptimal, zero expected future rewards. (ii) Return decomposition via\ncontribution analysis which transforms the reinforcement learning task into a\nregression task at which deep learning excels. On artificial tasks with delayed\nrewards, RUDDER is significantly faster than MC and exponentially faster than\nMonte Carlo Tree Search (MCTS), TD({\\lambda}), and reward shaping approaches.\nAt Atari games, RUDDER on top of a Proximal Policy Optimization (PPO) baseline\nimproves the scores, which is most prominent at games with delayed rewards.\nSource code is available at \\url{https://github.com/ml-jku/rudder} and\ndemonstration videos at \\url{https://goo.gl/EQerZV}. \n\n"}
{"id": "1806.08834", "contents": "Title: Smart Inverter Grid Probing for Learning Loads: Part I - Identifiability\n  Analysis Abstract: Distribution grids currently lack comprehensive real-time metering.\nNevertheless, grid operators require precise knowledge of loads and renewable\ngeneration to accomplish any feeder optimization task. At the same time, new\ngrid technologies, such as solar photovoltaics and energy storage units are\ninterfaced via inverters with advanced sensing and actuation capabilities. In\nthis context, this two-part work puts forth the idea of engaging power\nelectronics to probe an electric grid and record its voltage response at\nactuated and metered buses, to infer non-metered loads. Probing can be\naccomplished by commanding inverters to momentarily perturb their power\ninjections. Multiple probing actions can be induced within a few tens of\nseconds. In Part I, load inference via grid probing is formulated as an\nimplicit nonlinear system identification task, which is shown to be\ntopologically observable under certain conditions. The conditions can be\nreadily checked upon solving a max-flow problem on a bipartite graph derived\nfrom the feeder topology and the placement of actuated and non-metered buses.\nThe analysis holds for single- and multi-phase grids, radial or meshed, and\napplies to phasor or magnitude-only voltage data. The topological observability\nof distribution systems using smart meter or phasor data is cast and analyzed a\nspecial case. \n\n"}
{"id": "1806.08836", "contents": "Title: Smart Inverter Grid Probing for Learning Loads: Part II - Probing\n  Injection Design Abstract: This two-part work puts forth the idea of engaging power electronics to probe\nan electric grid to infer non-metered loads. Probing can be accomplished by\ncommanding inverters to perturb their power injections and record the induced\nvoltage response. Once a probing setup is deemed topologically observable by\nthe tests of Part I, Part II provides a methodology for designing probing\ninjections abiding by inverter and network constraints to improve load\nestimates. The task is challenging since system estimates depend on both\nprobing injections and unknown loads in an implicit nonlinear fashion. The\nmethodology first constructs a library of candidate probing vectors by sampling\nover the feasible set of inverter injections. Leveraging a linearized grid\nmodel and a robust approach, the candidate probing vectors violating voltage\nconstraints for any anticipated load value are subsequently rejected. Among the\nqualified candidates, the design finally identifies the probing vectors\nyielding the most diverse system states. The probing task under noisy phasor\nand non-phasor data is tackled using a semidefinite-program (SDP) relaxation.\nNumerical tests using synthetic and real-world data on a benchmark feeder\nvalidate the conditions of Part I; the SDP-based solver; the importance of\nprobing design; and the effects of probing duration and noise. \n\n"}
{"id": "1806.08838", "contents": "Title: Bayesian Optimization of Combinatorial Structures Abstract: The optimization of expensive-to-evaluate black-box functions over\ncombinatorial structures is an ubiquitous task in machine learning, engineering\nand the natural sciences. The combinatorial explosion of the search space and\ncostly evaluations pose challenges for current techniques in discrete\noptimization and machine learning, and critically require new algorithmic\nideas. This article proposes, to the best of our knowledge, the first algorithm\nto overcome these challenges, based on an adaptive, scalable model that\nidentifies useful combinatorial structure even when data is scarce. Our\nacquisition function pioneers the use of semidefinite programming to achieve\nefficiency and scalability. Experimental evaluations demonstrate that this\nalgorithm consistently outperforms other methods from combinatorial and\nBayesian optimization. \n\n"}
{"id": "1806.09091", "contents": "Title: An Input-Output Approach to Structured Stochastic Uncertainty in\n  Continuous Time Abstract: We consider the continuous-time setting of linear time-invariant (LTI)\nsystems in feedback with multiplicative stochastic uncertainties. The objective\nof the paper is to characterize the conditions of Mean-Square Stability (MSS)\nusing a purely input-output approach, i.e. without having to resort to state\nspace realizations. This has the advantage of encompassing a wider class of\nmodels (such as infinite dimensional systems and systems with delays). The\ninput-output approach leads to uncovering new tools such as stochastic block\ndiagrams that have an intimate connection with the more general Stochastic\nIntegral Equations (SIE), rather than Stochastic Differential Equations (SDE).\nVarious stochastic interpretations are considered, such as It\\=o and\nStratonovich, and block diagram conversion schemes between different\ninterpretations are devised. The MSS conditions are given in terms of the\nspectral radius of a matrix operator that takes different forms when different\nstochastic interpretations are considered. \n\n"}
{"id": "1806.09429", "contents": "Title: A Distributed Flexible Delay-tolerant Proximal Gradient Algorithm Abstract: We develop and analyze an asynchronous algorithm for distributed convex\noptimization when the objective writes a sum of smooth functions, local to each\nworker, and a non-smooth function. Unlike many existing methods, our\ndistributed algorithm is adjustable to various levels of communication cost,\ndelays, machines computational power, and functions smoothness. A unique\nfeature is that the stepsizes do not depend on communication delays nor number\nof machines, which is highly desirable for scalability. We prove that the\nalgorithm converges linearly in the strongly convex case, and provide\nguarantees of convergence for the non-strongly convex case. The obtained rates\nare the same as the vanilla proximal gradient algorithm over some introduced\nepoch sequence that subsumes the delays of the system. We provide numerical\nresults on large-scale machine learning problems to demonstrate the merits of\nthe proposed method. \n\n"}
{"id": "1806.09571", "contents": "Title: Asymptotic Properties of Recursive Maximum Likelihood Estimation in\n  Non-Linear State-Space Models Abstract: Using stochastic gradient search and the optimal filter derivative, it is\npossible to perform recursive (i.e., online) maximum likelihood estimation in a\nnon-linear state-space model. As the optimal filter and its derivative are\nanalytically intractable for such a model, they need to be approximated\nnumerically. In [Poyiadjis, Doucet and Singh, Biometrika 2018], a recursive\nmaximum likelihood algorithm based on a particle approximation to the optimal\nfilter derivative has been proposed and studied through numerical simulations.\nHere, this algorithm and its asymptotic behavior are analyzed theoretically. We\nshow that the algorithm accurately estimates maxima to the underlying (average)\nlog-likelihood when the number of particles is sufficiently large. We also\nderive (relatively) tight bounds on the estimation error. The obtained results\nhold under (relatively) mild conditions and cover several classes of non-linear\nstate-space models met in practice. \n\n"}
{"id": "1806.09595", "contents": "Title: Stability of Optimal Filter Higher-Order Derivatives Abstract: In many scenarios, a state-space model depends on a parameter which needs to\nbe inferred from data. Using stochastic gradient search and the optimal filter\n(first-order) derivative, the parameter can be estimated online. To analyze the\nasymptotic behavior of online methods for parameter estimation in non-linear\nstate-space models, it is necessary to establish results on the existence and\nstability of the optimal filter higher-order derivatives. The existence and\nstability properties of these derivatives are studied here. We show that the\noptimal filter higher-order derivatives exist and forget initial conditions\nexponentially fast. We also show that the optimal filter higher-order\nderivatives are geometrically ergodic. The obtained results hold under\n(relatively) mild conditions and apply to state-space models met in practice. \n\n"}
{"id": "1806.10077", "contents": "Title: Random Shuffling Beats SGD after Finite Epochs Abstract: A long-standing problem in the theory of stochastic gradient descent (SGD) is\nto prove that its without-replacement version RandomShuffle converges faster\nthan the usual with-replacement version. We present the first (to our\nknowledge) non-asymptotic solution to this problem, which shows that after a\n\"reasonable\" number of epochs RandomShuffle indeed converges faster than SGD.\nSpecifically, we prove that under strong convexity and second-order smoothness,\nthe sequence generated by RandomShuffle converges to the optimal solution at\nthe rate O(1/T^2 + n^3/T^3), where n is the number of components in the\nobjective, and T is the total number of iterations. This result shows that\nafter a reasonable number of epochs RandomShuffle is strictly better than SGD\n(which converges as O(1/T)). The key step toward showing this better dependence\non T is the introduction of n into the bound; and as our analysis will show, in\ngeneral a dependence on n is unavoidable without further changes to the\nalgorithm. We show that for sparse data RandomShuffle has the rate O(1/T^2),\nagain strictly better than SGD. Furthermore, we discuss extensions to nonconvex\ngradient dominated functions, as well as non-strongly convex settings. \n\n"}
{"id": "1806.10773", "contents": "Title: Successive Convex Approximation Algorithms for Sparse Signal Estimation\n  with Nonconvex Regularizations Abstract: In this paper, we propose a successive convex approximation framework for\nsparse optimization where the nonsmooth regularization function in the\nobjective function is nonconvex and it can be written as the difference of two\nconvex functions. The proposed framework is based on a nontrivial combination\nof the majorization-minimization framework and the successive convex\napproximation framework proposed in literature for a convex regularization\nfunction. The proposed framework has several attractive features, namely, i)\nflexibility, as different choices of the approximate function lead to different\ntype of algorithms; ii) fast convergence, as the problem structure can be\nbetter exploited by a proper choice of the approximate function and the\nstepsize is calculated by the line search; iii) low complexity, as the\napproximate function is convex and the line search scheme is carried out over a\ndifferentiable function; iv) guaranteed convergence to a stationary point. We\ndemonstrate these features by two example applications in subspace learning,\nnamely, the network anomaly detection problem and the sparse subspace\nclustering problem. Customizing the proposed framework by adopting the\nbest-response type approximation, we obtain soft-thresholding with exact line\nsearch algorithms for which all elements of the unknown parameter are updated\nin parallel according to closed-form expressions. The attractive features of\nthe proposed algorithms are illustrated numerically. \n\n"}
{"id": "1806.11536", "contents": "Title: An Exact Quantized Decentralized Gradient Descent Algorithm Abstract: We consider the problem of decentralized consensus optimization, where the\nsum of $n$ smooth and strongly convex functions are minimized over $n$\ndistributed agents that form a connected network. In particular, we consider\nthe case that the communicated local decision variables among nodes are\nquantized in order to alleviate the communication bottleneck in distributed\noptimization. We propose the Quantized Decentralized Gradient Descent (QDGD)\nalgorithm, in which nodes update their local decision variables by combining\nthe quantized information received from their neighbors with their local\ninformation. We prove that under standard strong convexity and smoothness\nassumptions for the objective function, QDGD achieves a vanishing mean solution\nerror under customary conditions for quantizers. To the best of our knowledge,\nthis is the first algorithm that achieves vanishing consensus error in the\npresence of quantization noise. Moreover, we provide simulation results that\nshow tight agreement between our derived theoretical convergence rate and the\nnumerical results. \n\n"}
{"id": "1807.00755", "contents": "Title: LeapsAndBounds: A Method for Approximately Optimal Algorithm\n  Configuration Abstract: We consider the problem of configuring general-purpose solvers to run\nefficiently on problem instances drawn from an unknown distribution. The goal\nof the configurator is to find a configuration that runs fast on average on\nmost instances, and do so with the least amount of total work. It can run a\nchosen solver on a random instance until the solver finishes or a timeout is\nreached. We propose LeapsAndBounds, an algorithm that tests configurations on\nrandomly selected problem instances for longer and longer time. We prove that\nthe capped expected runtime of the configuration returned by LeapsAndBounds is\nclose to the optimal expected runtime, while our algorithm's running time is\nnear-optimal. Our results show that LeapsAndBounds is more efficient than the\nrecent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the\nonly other algorithm configuration method with non-trivial theoretical\nguarantees. Experimental results on configuring a public SAT solver on a new\nbenchmark dataset also stand witness to the superiority of our method. \n\n"}
{"id": "1807.01778", "contents": "Title: Uncertainty Quantification of Electronic and Photonic ICs with\n  Non-Gaussian Correlated Process Variations Abstract: Since the invention of generalized polynomial chaos in 2002, uncertainty\nquantification has impacted many engineering fields, including variation-aware\ndesign automation of integrated circuits and integrated photonics. Due to the\nfast convergence rate, the generalized polynomial chaos expansion has achieved\norders-of-magnitude speedup than Monte Carlo in many applications. However,\nalmost all existing generalized polynomial chaos methods have a strong\nassumption: the uncertain parameters are mutually independent or Gaussian\ncorrelated. This assumption rarely holds in many realistic applications, and it\nhas been a long-standing challenge for both theorists and practitioners.\n  This paper propose a rigorous and efficient solution to address the challenge\nof non-Gaussian correlation. We first extend generalized polynomial chaos, and\npropose a class of smooth basis functions to efficiently handle non-Gaussian\ncorrelations. Then, we consider high-dimensional parameters, and develop a\nscalable tensor method to compute the proposed basis functions. Finally, we\ndevelop a sparse solver with adaptive sample selections to solve\nhigh-dimensional uncertainty quantification problems. We validate our theory\nand algorithm by electronic and photonic ICs with 19 to 57 non-Gaussian\ncorrelated variation parameters. The results show that our approach outperforms\nMonte Carlo by $2500\\times$ to $3000\\times$ in terms of efficiency. Moreover,\nour method can accurately predict the output density functions with multiple\npeaks caused by non-Gaussian correlations, which is hard to handle by existing\nmethods.\n  Based on the results in this paper, many novel uncertainty quantification\nalgorithms can be developed and can be further applied to a broad range of\nengineering domains. \n\n"}
{"id": "1807.01914", "contents": "Title: A multiple-try Metropolis-Hastings algorithm with tailored proposals Abstract: We present a new multiple-try Metropolis-Hastings algorithm designed to be\nespecially beneficial when a tailored proposal distribution is available. The\nalgorithm is based on a given acyclic graph $G$, where one of the nodes in $G$,\n$k$ say, contains the current state of the Markov chain and the remaining nodes\ncontain proposed states generated by applying the tailored proposal\ndistribution. The Metropolis-Hastings algorithm alternates between two types of\nupdates. The first update type is using the tailored proposal distribution to\ngenerate new states in all nodes in $G$ except in node $k$. The second update\ntype is generating a new value for $k$, thereby changing the value of the\ncurrent state. We evaluate the effectiveness of the proposed scheme in an\nexample with previously defined target and proposal distributions. \n\n"}
{"id": "1807.02176", "contents": "Title: A stochastic Levenberg-Marquardt method using random models with\n  complexity results Abstract: Globally convergent variants of the Gauss-Newton algorithm are often the\nmethods of choice to tackle nonlinear least-squares problems. Among such\nframeworks, Levenberg-Marquardt and trust-region methods are two\nwell-established, similar paradigms. Both schemes have been studied when the\nGauss-Newton model is replaced by a random model that is only accurate with a\ngiven probability. Trust-region schemes have also been applied to problems\nwhere the objective value is subject to noise: this setting is of particular\ninterest in fields such as data assimilation, where efficient methods that can\nadapt to noise are needed to account for the intrinsic uncertainty in the input\ndata.\n  In this paper, we describe a stochastic Levenberg-Marquardt algorithm that\nhandles noisy objective function values and random models, provided sufficient\naccuracy is achieved in probability. Our method relies on a specific scaling of\nthe regularization parameter, that allows us to leverage existing results for\ntrust-region algorithms. Moreover, we exploit the structure of our objective\nthrough the use of a family of stationarity criteria tailored to least-squares\nproblems. Provided the probability of accurate function estimates and models is\nsufficiently large, we bound the expected number of iterations needed to reach\nan approximate stationary point, which generalizes results based on using\ndeterministic models or noiseless function values. We illustrate the link\nbetween our approach and several applications related to inverse problems and\nmachine learning. \n\n"}
{"id": "1807.02629", "contents": "Title: Optimistic mirror descent in saddle-point problems: Going the extra\n  (gradient) mile Abstract: Owing to their connection with generative adversarial networks (GANs),\nsaddle-point problems have recently attracted considerable interest in machine\nlearning and beyond. By necessity, most theoretical guarantees revolve around\nconvex-concave (or even linear) problems; however, making theoretical inroads\ntowards efficient GAN training depends crucially on moving beyond this classic\nframework. To make piecemeal progress along these lines, we analyze the\nbehavior of mirror descent (MD) in a class of non-monotone problems whose\nsolutions coincide with those of a naturally associated variational inequality\n- a property which we call coherence. We first show that ordinary, \"vanilla\" MD\nconverges under a strict version of this condition, but not otherwise; in\nparticular, it may fail to converge even in bilinear models with a unique\nsolution. We then show that this deficiency is mitigated by optimism: by taking\nan \"extra-gradient\" step, optimistic mirror descent (OMD) converges in all\ncoherent problems. Our analysis generalizes and extends the results of\nDaskalakis et al. (2018) for optimistic gradient descent (OGD) in bilinear\nproblems, and makes concrete headway for establishing convergence beyond\nconvex-concave games. We also provide stochastic analogues of these results,\nand we validate our analysis by numerical experiments in a wide array of GAN\nmodels (including Gaussian mixture models, as well as the CelebA and CIFAR-10\ndatasets). \n\n"}
{"id": "1807.02994", "contents": "Title: Finite-State Approximations to Discounted and Average Cost Constrained\n  Markov Decision Processes Abstract: In this paper, we consider the finite-state approximation of a discrete-time\nconstrained Markov decision process (MDP) under the discounted and average cost\ncriteria. Using the linear programming formulation of the constrained\ndiscounted cost problem, we prove the asymptotic convergence of the optimal\nvalue of the finite-state model to the optimal value of the original model.\nWith further continuity condition on the transition probability, we also\nestablish a method to compute approximately optimal policies. For the average\ncost, instead of using the finite-state linear programming approximation\nmethod, we use the original problem definition to establish the finite-state\nasymptotic approximation of the constrained problem and compute approximately\noptimal policies. Under Lipschitz type regularity conditions on the components\nof the MDP, we also obtain explicit rate of convergence bounds quantifying how\nthe approximation improves as the size of the approximating finite state space\nincreases. \n\n"}
{"id": "1807.03091", "contents": "Title: Computer Assisted Localization of a Heart Arrhythmia Abstract: We consider the problem of locating a point-source heart arrhythmia using\ndata from a standard diagnostic procedure, where a reference catheter is placed\nin the heart, and arrival times from a second diagnostic catheter are recorded\nas the diagnostic catheter moves around within the heart. We model this\nsituation as a nonconvex feasibility problem, where given a set of arrival\ntimes, we look for a source location that is consistent with the available\ndata. We develop a new optimization approach and fast algorithm to obtain\nonline proposals for the next location to suggest to the operator as she\ncollects data. We validate the procedure using a Monte Carlo simulation based\non patients' electrophysiological data. The proposed procedure robustly and\nquickly locates the source of arrhythmias without any prior knowledge of heart\nanatomy. \n\n"}
{"id": "1807.03223", "contents": "Title: Entropy Maximization for Markov Decision Processes Under Temporal Logic\n  Constraints Abstract: We study the problem of synthesizing a policy that maximizes the entropy of a\nMarkov decision process (MDP) subject to a temporal logic constraint. Such a\npolicy minimizes the predictability of the paths it generates, or dually,\nmaximizes the exploration of different paths in an MDP while ensuring the\nsatisfaction of a temporal logic specification. We first show that the maximum\nentropy of an MDP can be finite, infinite or unbounded. We provide necessary\nand sufficient conditions under which the maximum entropy of an MDP is finite,\ninfinite or unbounded. We then present an algorithm which is based on a convex\noptimization problem to synthesize a policy that maximizes the entropy of an\nMDP. We also show that maximizing the entropy of an MDP is equivalent to\nmaximizing the entropy of the paths that reach a certain set of states in the\nMDP. Finally, we extend the algorithm to an MDP subject to a temporal logic\nspecification. In numerical examples, we demonstrate the proposed method on\ndifferent motion planning scenarios and illustrate the relation between the\nrestrictions imposed on the paths by a specification, the maximum entropy, and\nthe predictability of paths. \n\n"}
{"id": "1807.03765", "contents": "Title: Is Q-learning Provably Efficient? Abstract: Model-free reinforcement learning (RL) algorithms, such as Q-learning,\ndirectly parameterize and update value functions or policies without explicitly\nmodeling the environment. They are typically simpler, more flexible to use, and\nthus more prevalent in modern deep RL than model-based approaches. However,\nempirical work has suggested that model-free algorithms may require more\nsamples to learn [Deisenroth and Rasmussen 2011, Schulman et al. 2015]. The\ntheoretical question of \"whether model-free algorithms can be made sample\nefficient\" is one of the most fundamental questions in RL, and remains unsolved\neven in the basic scenario with finitely many states and actions.\n  We prove that, in an episodic MDP setting, Q-learning with UCB exploration\nachieves regret $\\tilde{O}(\\sqrt{H^3 SAT})$, where $S$ and $A$ are the numbers\nof states and actions, $H$ is the number of steps per episode, and $T$ is the\ntotal number of steps. This sample efficiency matches the optimal regret that\ncan be achieved by any model-based approach, up to a single $\\sqrt{H}$ factor.\nTo the best of our knowledge, this is the first analysis in the model-free\nsetting that establishes $\\sqrt{T}$ regret without requiring access to a\n\"simulator.\" \n\n"}
{"id": "1807.03769", "contents": "Title: Kernel-Based Learning for Smart Inverter Control Abstract: Distribution grids are currently challenged by frequent voltage excursions\ninduced by intermittent solar generation. Smart inverters have been advocated\nas a fast-responding means to regulate voltage and minimize ohmic losses. Since\noptimal inverter coordination may be computationally challenging and preset\nlocal control rules are subpar, the approach of customized control rules\ndesigned in a quasi-static fashion features as a golden middle. Departing from\naffine control rules, this work puts forth non-linear inverter control\npolicies. Drawing analogies to multi-task learning, reactive control is posed\nas a kernel-based regression task. Leveraging a linearized grid model and given\nanticipated data scenarios, inverter rules are jointly designed at the feeder\nlevel to minimize a convex combination of voltage deviations and ohmic losses\nvia a linearly-constrained quadratic program. Numerical tests using real-world\ndata on a benchmark feeder demonstrate that nonlinear control rules driven also\nby a few non-local readings can attain near-optimal performance. \n\n"}
{"id": "1807.05177", "contents": "Title: A collisionless singular Cucker-Smale model with decentralized formation\n  control Abstract: We address the design of decentralized feedback control laws inducing\nconsensus and prescribed spatial patterns over a singular interacting particle\nsystem of Cucker-Smale type. The control design consists of a feedback term\nregulating the distance between each agent and pre-assigned subset of\nneighbours. Such a design represents a multidimensional extension of existing\ncontrol laws for 1d platoon formation control. For the proposed controller we\nstudy consensus emergence, collision-avoidance and formation control features\nin terms of energy estimates for the closed-loop system. Numerical experiments\nin 1, 2 and 3 dimensions assess the different features of the proposed design. \n\n"}
{"id": "1807.05328", "contents": "Title: On the Acceleration of L-BFGS with Second-Order Information and\n  Stochastic Batches Abstract: This paper proposes a framework of L-BFGS based on the (approximate)\nsecond-order information with stochastic batches, as a novel approach to the\nfinite-sum minimization problems. Different from the classical L-BFGS where\nstochastic batches lead to instability, we use a smooth estimate for the\nevaluations of the gradient differences while achieving acceleration by\nwell-scaling the initial Hessians. We provide theoretical analyses for both\nconvex and nonconvex cases. In addition, we demonstrate that within the popular\napplications of least-square and cross-entropy losses, the algorithm admits a\nsimple implementation in the distributed environment. Numerical experiments\nsupport the efficiency of our algorithms. \n\n"}
{"id": "1807.05421", "contents": "Title: Piecewise Deterministic Markov Processes and their invariant measures Abstract: Piecewise Deterministic Markov Processes (PDMPs) are studied in a general\nframework. First, different constructions are proven to be equivalent. Second,\nwe introduce a coupling between two PDMPs following the same differential flow\nwhich implies quantitative bounds on the total variation between the marginal\ndistributions of the two processes. Finally two results are established\nregarding the invariant measures of PDMPs. A practical condition to show that a\nprobability measure is invariant for the associated PDMP semi-group is\npresented. In a second time, a bound on the invariant probability measures in\n$V$-norm of two PDMPs following the same differential flow is established. This\nlast result is then applied to study the asymptotic bias of some non-exact PDMP\nMCMC methods. \n\n"}
{"id": "1807.06766", "contents": "Title: Convergence guarantees for RMSProp and ADAM in non-convex optimization\n  and an empirical comparison to Nesterov acceleration Abstract: RMSProp and ADAM continue to be extremely popular algorithms for training\nneural nets but their theoretical convergence properties have remained unclear.\nFurther, recent work has seemed to suggest that these algorithms have worse\ngeneralization properties when compared to carefully tuned stochastic gradient\ndescent or its momentum variants. In this work, we make progress towards a\ndeeper understanding of ADAM and RMSProp in two ways. First, we provide proofs\nthat these adaptive gradient algorithms are guaranteed to reach criticality for\nsmooth non-convex objectives, and we give bounds on the running time.\n  Next we design experiments to empirically study the convergence and\ngeneralization properties of RMSProp and ADAM against Nesterov's Accelerated\nGradient method on a variety of common autoencoder setups and on VGG-9 with\nCIFAR-10. Through these experiments we demonstrate the interesting sensitivity\nthat ADAM has to its momentum parameter $\\beta_1$. We show that at very high\nvalues of the momentum parameter ($\\beta_1 = 0.99$) ADAM outperforms a\ncarefully tuned NAG on most of our experiments, in terms of getting lower\ntraining and test losses. On the other hand, NAG can sometimes do better when\nADAM's $\\beta_1$ is set to the most commonly used value: $\\beta_1 = 0.9$,\nindicating the importance of tuning the hyperparameters of ADAM to get better\ngeneralization performance.\n  We also report experiments on different autoencoders to demonstrate that NAG\nhas better abilities in terms of reducing the gradient norms, and it also\nproduces iterates which exhibit an increasing trend for the minimum eigenvalue\nof the Hessian of the loss function at the iterates. \n\n"}
{"id": "1807.07680", "contents": "Title: Generalized Stochastic Frank-Wolfe Algorithm with Stochastic\n  \"Substitute\" Gradient for Structured Convex Optimization Abstract: The stochastic Frank-Wolfe method has recently attracted much general\ninterest in the context of optimization for statistical and machine learning\ndue to its ability to work with a more general feasible region. However, there\nhas been a complexity gap in the guaranteed convergence rate for stochastic\nFrank-Wolfe compared to its deterministic counterpart. In this work, we present\na new generalized stochastic Frank-Wolfe method which closes this gap for the\nclass of structured optimization problems encountered in statistical and\nmachine learning characterized by empirical loss minimization with a certain\ntype of ``linear prediction'' property (formally defined in the paper), which\nis typically present loss minimization problems in practice. Our method also\nintroduces the notion of a ``substitute gradient'' that is a\nnot-necessarily-unbiased sample of the gradient. We show that our new method is\nequivalent to a particular randomized coordinate mirror descent algorithm\napplied to the dual problem, which in turn provides a new interpretation of\nrandomized dual coordinate descent in the primal space. Also, in the special\ncase of a strongly convex regularizer our generalized stochastic Frank-Wolfe\nmethod (as well as the randomized dual coordinate descent method) exhibits\nlinear convergence. Furthermore, we present computational experiments that\nindicate that our method outperforms other stochastic Frank-Wolfe methods\nconsistent with the theory developed herein. \n\n"}
{"id": "1807.08140", "contents": "Title: On the Analysis of Trajectories of Gradient Descent in the Optimization\n  of Deep Neural Networks Abstract: Theoretical analysis of the error landscape of deep neural networks has\ngarnered significant interest in recent years. In this work, we theoretically\nstudy the importance of noise in the trajectories of gradient descent towards\noptimal solutions in multi-layer neural networks. We show that adding noise (in\ndifferent ways) to a neural network while training increases the rank of the\nproduct of weight matrices of a multi-layer linear neural network. We thus\nstudy how adding noise can assist reaching a global optimum when the product\nmatrix is full-rank (under certain conditions). We establish theoretical\nfoundations between the noise induced into the neural network - either to the\ngradient, to the architecture, or to the input/output to a neural network - and\nthe rank of product of weight matrices. We corroborate our theoretical findings\nwith empirical results. \n\n"}
{"id": "1807.09048", "contents": "Title: Transient Performance of Electric Power Networks under Colored Noise Abstract: New classes of performance measures have been recently introduced to quantify\nthe transient response to external disturbances of coupled dynamical systems on\ncomplex networks. These performance measures are time-integrated quadratic\nforms in the system's coordinates or their time derivative. So far,\ninvestigations of these performance measures have been restricted to\nDirac-$\\delta$ impulse disturbances, in which case they can be alternatively\ninterpreted as giving the long time output variances for stochastic white noise\npower demand/generation fluctuations. Strictly speaking, the approach is\ntherefore restricted to power fluctuating on time scales shorter than the\nshortest time scales in the swing equations. To account for power productions\nfrom new renewable energy sources, we extend these earlier works to the\nrelevant case of colored noise power fluctuations, with a finite correlation\ntime $\\tau > 0$. We calculate a closed-form expression for generic quadratic\nperformance measures. Applied to specific cases, this leads to a spectral\nrepresentation of performance measures as a sum over the non-zero modes of the\nnetwork Laplacian. Our results emphasize the competition between inertia,\ndamping and the Laplacian modes, whose balance is determined to a large extent\nby the noise correlation time scale $\\tau$. \n\n"}
{"id": "1807.11880", "contents": "Title: Stochastic Gradient Descent with Biased but Consistent Gradient\n  Estimators Abstract: Stochastic gradient descent (SGD), which dates back to the 1950s, is one of\nthe most popular and effective approaches for performing stochastic\noptimization. Research on SGD resurged recently in machine learning for\noptimizing convex loss functions and training nonconvex deep neural networks.\nThe theory assumes that one can easily compute an unbiased gradient estimator,\nwhich is usually the case due to the sample average nature of empirical risk\nminimization. There exist, however, many scenarios (e.g., graphs) where an\nunbiased estimator may be as expensive to compute as the full gradient because\ntraining examples are interconnected. Recently, Chen et al. (2018) proposed\nusing a consistent gradient estimator as an economic alternative. Encouraged by\nempirical success, we show, in a general setting, that consistent estimators\nresult in the same convergence behavior as do unbiased ones. Our analysis\ncovers strongly convex, convex, and nonconvex objectives. We verify the results\nwith illustrative experiments on synthetic and real-world data. This work opens\nseveral new research directions, including the development of more efficient\nSGD updates with consistent estimators and the design of efficient training\nalgorithms for large-scale graphs. \n\n"}
{"id": "1808.00232", "contents": "Title: Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error\n  Reduction via Surrogate Policy Abstract: When learning from a batch of logged bandit feedback, the discrepancy between\nthe policy to be learned and the off-policy training data imposes statistical\nand computational challenges. Unlike classical supervised learning and online\nlearning settings, in batch contextual bandit learning, one only has access to\na collection of logged feedback from the actions taken by a historical policy,\nand expect to learn a policy that takes good actions in possibly unseen\ncontexts. Such a batch learning setting is ubiquitous in online and interactive\nsystems, such as ad platforms and recommendation systems. Existing approaches\nbased on inverse propensity weights, such as Inverse Propensity Scoring (IPS)\nand Policy Optimizer for Exponential Models (POEM), enjoy unbiasedness but\noften suffer from large mean squared error. In this work, we introduce a new\napproach named Maximum Likelihood Inverse Propensity Scoring (MLIPS) for batch\nlearning from logged bandit feedback. Instead of using the given historical\npolicy as the proposal in inverse propensity weights, we estimate a maximum\nlikelihood surrogate policy based on the logged action-context pairs, and then\nuse this surrogate policy as the proposal. We prove that MLIPS is\nasymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared\nerror than IPS. Such an error reduction phenomenon is somewhat surprising as\nthe estimated surrogate policy is less accurate than the given historical\npolicy. Results on multi-label classification problems and a large- scale ad\nplacement dataset demonstrate the empirical effectiveness of MLIPS.\nFurthermore, the proposed surrogate policy technique is complementary to\nexisting error reduction techniques, and when combined, is able to consistently\nboost the performance of several widely used approaches. \n\n"}
{"id": "1808.01181", "contents": "Title: Robust Spectral Filtering and Anomaly Detection Abstract: We consider a setting, where the output of a linear dynamical system (LDS)\nis, with an unknown but fixed probability, replaced by noise. There, we present\na robust method for the prediction of the outputs of the LDS and identification\nof the samples of noise, and prove guarantees on its statistical performance.\nOne application lies in anomaly detection: the samples of noise, unlikely to\nhave been generated by the dynamics, can be flagged to operators of the system\nfor further study. \n\n"}
{"id": "1808.02941", "contents": "Title: On the Convergence of A Class of Adam-Type Algorithms for Non-Convex\n  Optimization Abstract: This paper studies a class of adaptive gradient based momentum algorithms\nthat update the search directions and learning rates simultaneously using past\ngradients. This class, which we refer to as the \"Adam-type\", includes the\npopular algorithms such as the Adam, AMSGrad and AdaGrad. Despite their\npopularity in training deep neural networks, the convergence of these\nalgorithms for solving nonconvex problems remains an open question. This paper\nprovides a set of mild sufficient conditions that guarantee the convergence for\nthe Adam-type methods. We prove that under our derived conditions, these\nmethods can achieve the convergence rate of order $O(\\log{T}/\\sqrt{T})$ for\nnonconvex stochastic optimization. We show the conditions are essential in the\nsense that violating them may make the algorithm diverge. Moreover, we propose\nand analyze a class of (deterministic) incremental adaptive gradient\nalgorithms, which has the same $O(\\log{T}/\\sqrt{T})$ convergence rate. Our\nstudy could also be extended to a broader class of adaptive gradient methods in\nmachine learning and optimization. \n\n"}
{"id": "1808.03198", "contents": "Title: Estimation of Location and Orientation for Underwater Vehicles from\n  Range Measurements Abstract: Localization is an important required task for enabling vehicle autonomy for\nunderwater vehicles. Localization entails the determination of position of the\ncenter of mass and orientation of a vehicle from the available measurements. In\nthis paper, we focus on localization by using One-Way Travel Time (OWTT)\nmeasurements available to a vehicle from the communication of its multiple\non-board receivers with acoustic beacons, more specifically, long baseline\n(LBL) beacons. Range can be inferred by multiplying the OWTT with speed of\nsound; however, water conditions can change spatially and temporally resulting\nin uncertainty in range measurement. The farther a beacon is from a receiver,\nthe larger is the uncertainty. The proposed method for localization accounts\ncaptures this uncertainty by bounding the true distance with an increasing\n(calibrating) function of the range measurement. Determination of this\ncalibration function is formulated as polynomial optimization problem and is a\ncrucial step for localization. The proposed two-step procedure for localization\nis as follows: based on the range measurements specific to a receiver from the\nbeacons, a convex optimization problem is proposed to estimate the location of\nthe receiver. The estimate is essentially a center of the set of possible\nlocations of the receiver. In the second step, the location estimates of the\nvehicle are corrected using rigid body motion constraints and the orientation\nof the rigid body is thus determined. Numerical examples and experimental\nresults provided at the end corroborate the procedures developed in this paper. \n\n"}
{"id": "1808.03239", "contents": "Title: Simple Conditions for Metastability of Continuous Markov Chains Abstract: A family $\\{Q_{\\beta}\\}_{\\beta \\geq 0}$ of Markov chains is said to exhibit\n$\\textit{metastable mixing}$ with $\\textit{modes}$\n$S_{\\beta}^{(1)},\\ldots,S_{\\beta}^{(k)}$ if its spectral gap (or some other\nmixing property) is very close to the worst conductance\n$\\min(\\Phi_{\\beta}(S_{\\beta}^{(1)}), \\ldots, \\Phi_{\\beta}(S_{\\beta}^{(k)}))$ of\nits modes. We give simple sufficient conditions for a family of Markov chains\nto exhibit metastability in this sense, and verify that these conditions hold\nfor a prototypical Metropolis-Hastings chain targeting a mixture distribution.\nOur work differs from existing work on metastability in that, for the class of\nexamples we are interested in, it gives an asymptotically exact formula for the\nspectral gap (rather than a bound that can be very far from sharp) while at the\nsame time giving technical conditions that are easier to verify for many\nstatistical examples. Our bounds from this paper are used in a companion paper\nto compare the mixing times of the Hamiltonian Monte Carlo algorithm and a\nrandom walk algorithm for multimodal target distributions. \n\n"}
{"id": "1808.03620", "contents": "Title: Ensemble Kalman Inversion: A Derivative-Free Technique For Machine\n  Learning Tasks Abstract: The standard probabilistic perspective on machine learning gives rise to\nempirical risk-minimization tasks that are frequently solved by stochastic\ngradient descent (SGD) and variants thereof. We present a formulation of these\ntasks as classical inverse or filtering problems and, furthermore, we propose\nan efficient, gradient-free algorithm for finding a solution to these problems\nusing ensemble Kalman inversion (EKI). Applications of our approach include\noffline and online supervised learning with deep neural networks, as well as\ngraph-based semi-supervised learning. The essence of the EKI procedure is an\nensemble based approximate gradient descent in which derivatives are replaced\nby differences from within the ensemble. We suggest several modifications to\nthe basic method, derived from empirically successful heuristics developed in\nthe context of SGD. Numerical results demonstrate wide applicability and\nrobustness of the proposed algorithm. \n\n"}
{"id": "1808.04162", "contents": "Title: A Forward-Backward Splitting Method for Monotone Inclusions Without\n  Cocoercivity Abstract: In this work, we propose a simple modification of the forward-backward\nsplitting method for finding a zero in the sum of two monotone operators. Our\nmethod converges under the same assumptions as Tseng's forward-backward-forward\nmethod, namely, it does not require cocoercivity of the single-valued operator.\nMoreover, each iteration only requires one forward evaluation rather than two\nas is the case for Tseng's method. Variants of the method incorporating a\nlinesearch, relaxation and inertia, or a structured three operator inclusion\nare also discussed. \n\n"}
{"id": "1808.05274", "contents": "Title: Frank-Wolfe Style Algorithms for Large Scale Optimization Abstract: We introduce a few variants on Frank-Wolfe style algorithms suitable for\nlarge scale optimization. We show how to modify the standard Frank-Wolfe\nalgorithm using stochastic gradients, approximate subproblem solutions, and\nsketched decision variables in order to scale to enormous problems while\npreserving (up to constants) the optimal convergence rate\n$\\mathcal{O}(\\frac{1}{k})$. \n\n"}
{"id": "1808.05671", "contents": "Title: On the Convergence of Adaptive Gradient Methods for Nonconvex\n  Optimization Abstract: Adaptive gradient methods are workhorses in deep learning. However, the\nconvergence guarantees of adaptive gradient methods for nonconvex optimization\nhave not been thoroughly studied. In this paper, we provide a fine-grained\nconvergence analysis for a general class of adaptive gradient methods including\nAMSGrad, RMSProp and AdaGrad. For smooth nonconvex functions, we prove that\nadaptive gradient methods in expectation converge to a first-order stationary\npoint. Our convergence rate is better than existing results for adaptive\ngradient methods in terms of dimension. In addition, we also prove high\nprobability bounds on the convergence rates of AMSGrad, RMSProp as well as\nAdaGrad, which have not been established before. Our analyses shed light on\nbetter understanding the mechanism behind adaptive gradient methods in\noptimizing nonconvex objectives. \n\n"}
{"id": "1808.05889", "contents": "Title: Data Consistency Approach to Model Validation Abstract: In scientific inference problems, the underlying statistical modeling\nassumptions have a crucial impact on the end results. There exist, however,\nonly a few automatic means for validating these fundamental modelling\nassumptions. The contribution in this paper is a general criterion to evaluate\nthe consistency of a set of statistical models with respect to observed data.\nThis is achieved by automatically gauging the models' ability to generate data\nthat is similar to the observed data. Importantly, the criterion follows from\nthe model class itself and is therefore directly applicable to a broad range of\ninference problems with varying data types, ranging from independent univariate\ndata to high-dimensional time-series. The proposed data consistency criterion\nis illustrated, evaluated and compared to several well-established methods\nusing three synthetic and two real data sets. \n\n"}
{"id": "1808.05933", "contents": "Title: Decentralized Dictionary Learning Over Time-Varying Digraphs Abstract: This paper studies Dictionary Learning problems wherein the learning task is\ndistributed over a multi-agent network, modeled as a time-varying directed\ngraph. This formulation is relevant, for instance, in Big Data scenarios where\nmassive amounts of data are collected/stored in different locations (e.g.,\nsensors, clouds) and aggregating and/or processing all data in a fusion center\nmight be inefficient or unfeasible, due to resource limitations, communication\noverheads or privacy issues. We develop a unified decentralized algorithmic\nframework for this class of nonconvex problems, which is proved to converge to\nstationary solutions at a sublinear rate. The new method hinges on Successive\nConvex Approximation techniques, coupled with a decentralized tracking\nmechanism aiming at locally estimating the gradient of the smooth part of the\nsum-utility. To the best of our knowledge, this is the first provably\nconvergent decentralized algorithm for Dictionary Learning and, more generally,\nbi-convex problems over (time-varying) (di)graphs. \n\n"}
{"id": "1808.06296", "contents": "Title: Universal Stagewise Learning for Non-Convex Problems with Convergence on\n  Averaged Solutions Abstract: Although stochastic gradient descent (SGD) method and its variants (e.g.,\nstochastic momentum methods, AdaGrad) are the choice of algorithms for solving\nnon-convex problems (especially deep learning), there still remain big gaps\nbetween the theory and the practice with many questions unresolved. For\nexample, there is still a lack of theories of convergence for SGD and its\nvariants that use stagewise step size and return an averaged solution in\npractice. In addition, theoretical insights of why adaptive step size of\nAdaGrad could improve non-adaptive step size of {\\sgd} is still missing for\nnon-convex optimization. This paper aims to address these questions and fill\nthe gap between theory and practice. We propose a universal stagewise\noptimization framework for a broad family of {\\bf non-smooth non-convex}\n(namely weakly convex) problems with the following key features: (i) at each\nstage any suitable stochastic convex optimization algorithms (e.g., SGD or\nAdaGrad) that return an averaged solution can be employed for minimizing a\nregularized convex problem; (ii) the step size is decreased in a stagewise\nmanner; (iii) an averaged solution is returned as the final solution that is\nselected from all stagewise averaged solutions with sampling probabilities {\\it\nincreasing} as the stage number. Our theoretical results of stagewise AdaGrad\nexhibit its adaptive convergence, therefore shed insights on its faster\nconvergence for problems with sparse stochastic gradients than stagewise SGD.\nTo the best of our knowledge, these new results are the first of their kind for\naddressing the unresolved issues of existing theories mentioned earlier.\nBesides theoretical contributions, our empirical studies show that our\nstagewise SGD and ADAGRAD improve the generalization performance of existing\nvariants/implementations of SGD and ADAGRAD. \n\n"}
{"id": "1808.07181", "contents": "Title: Efficient sparse semismooth Newton methods for the clustered lasso\n  problem Abstract: We focus on solving the clustered lasso problem, which is a least squares\nproblem with the $\\ell_1$-type penalties imposed on both the coefficients and\ntheir pairwise differences to learn the group structure of the regression\nparameters. Here we first reformulate the clustered lasso regularizer as a\nweighted ordered-lasso regularizer, which is essential in reducing the\ncomputational cost from $O(n^2)$ to $O(n\\log (n))$. We then propose an inexact\nsemismooth Newton augmented Lagrangian ({\\sc Ssnal}) algorithm to solve the\nclustered lasso problem or its dual via this equivalent formulation, depending\non whether the sample size is larger than the dimension of the features. An\nessential component of the {\\sc Ssnal} algorithm is the computation of the\ngeneralized Jacobian of the proximal mapping of the clustered lasso\nregularizer. Based on the new formulation, we derive an efficient procedure for\nits computation. Comprehensive results on the global convergence and local\nlinear convergence of the {\\sc Ssnal} algorithm are established. For the\npurpose of exposition and comparison, we also summarize/design several\nfirst-order methods that can be used to solve the problem under consideration,\nbut with the key improvement from the new formulation of the clustered lasso\nregularizer. As a demonstration of the applicability of our algorithms,\nnumerical experiments on the clustered lasso problem are performed. The\nexperiments show that the {\\sc Ssnal} algorithm substantially outperforms the\nbest alternative algorithm for the clustered lasso problem. \n\n"}
{"id": "1808.07263", "contents": "Title: Exponential synchronization of the high-dimensional Kuramoto model with\n  identical oscillators under digraphs Abstract: For the Kuramoto model and its variations, it is difficult to analyze the\nexponential synchronization under the general digraphs due to the lack of\nsymmetry. %due to the asymmetry of the adjacency matrices. In this paper, for\nthe high-dimensional Kuramoto model of identical oscillators, a matrix Riccati\ndifferential equation (MRDE) is proposed to describe the error dynamics. Based\non the MRDE, the exponential synchronization is proved by constructing a total\nerror function for the case of digraphs admitting spanning trees. Finally, some\nnumerical simulations are given to illustrate the obtained theoretical results. \n\n"}
{"id": "1808.08136", "contents": "Title: Partial-fraction Expansion of Lossless Negative Imaginary Property and A\n  Generalized Lossless Negative Imaginary Lemma Abstract: This paper studies a partial-fraction expansion for lossless negative\nimaginary systems and presents a generalized lossless negative imaginary lemma\nby allowing poles at zero. First, a necessary and sufficient condition for a\nsystem to be non-proper lossless negative imaginary is developed, and a minor\npartial-fraction expansion of lossless negative imaginary property is studied.\nSecond, according to the minor decomposition properties, two different and new\nrelationships between lossless positive real and lossless negative imaginary\nsystems are established. Third, according to one of the relationships, a\ngeneralized lossless negative imaginary lemma in terms of a minimal state-space\nrealization is derived by allowing poles at zero. Some important properties of\nlossless negative imaginary systems are also studied in this paper, and three\nnumerical examples are provided to illustrate the developed theory \n\n"}
{"id": "1808.10340", "contents": "Title: A Coordinate-Free Construction of Scalable Natural Gradient Abstract: Most neural networks are trained using first-order optimization methods,\nwhich are sensitive to the parameterization of the model. Natural gradient\ndescent is invariant to smooth reparameterizations because it is defined in a\ncoordinate-free way, but tractable approximations are typically defined in\nterms of coordinate systems, and hence may lose the invariance properties. We\nanalyze the invariance properties of the Kronecker-Factored Approximate\nCurvature (K-FAC) algorithm by constructing the algorithm in a coordinate-free\nway. We explicitly construct a Riemannian metric under which the natural\ngradient matches the K-FAC update; invariance to affine transformations of the\nactivations follows immediately. We extend our framework to analyze the\ninvariance properties of K-FAC applied to convolutional networks and recurrent\nneural networks, as well as metrics other than the usual Fisher metric. \n\n"}
{"id": "1809.00761", "contents": "Title: Adaptive Douglas-Rachford splitting algorithm for the sum of two\n  operators Abstract: The Douglas-Rachford algorithm is a classical and powerful splitting method\nfor minimizing the sum of two convex functions and, more generally, finding a\nzero of the sum of two maximally monotone operators. Although this algorithm is\nwell understood when the involved operators are monotone or strongly monotone,\nthe convergence theory for weakly monotone settings is far from being complete.\nIn this paper, we propose an adaptive Douglas-Rachford splitting algorithm for\nthe sum of two operators, one of which is strongly monotone while the other one\nis weakly monotone. With appropriately chosen parameters, the algorithm\nconverges globally to a fixed point from which we derive a solution of the\nproblem. When one operator is Lipschitz continuous, we prove global linear\nconvergence, which sharpens recent known results. \n\n"}
{"id": "1809.01931", "contents": "Title: An unexpected connection between Bayes $A-$optimal designs and the Group\n  Lasso Abstract: We show that the $A$-optimal design optimization problem over $m$ design\npoints in $\\mathbb{R}^n$ is equivalent to minimizing a quadratic function plus\na group lasso sparsity inducing term over $n\\times m$ real matrices. This\nobservation allows to describe several new algorithms for $A$-optimal design\nbased on splitting and block coordinate decomposition. These techniques are\nwell known and proved powerful to treat large scale problems in machine\nlearning and signal processing communities. The proposed algorithms come with\nrigorous convergence guaranties and convergence rate estimate stemming from the\noptimization literature. Performances are illustrated on synthetic benchmarks\nand compared to existing methods for solving the optimal design problem. \n\n"}
{"id": "1809.02007", "contents": "Title: Inexact cuts in Stochastic Dual Dynamic Programming Abstract: We introduce an extension of Stochastic Dual Dynamic Programming (SDDP) to\nsolve stochastic convex dynamic programming equations. This extension applies\nwhen some or all primal and dual subproblems to be solved along the forward and\nbackward passes of the method are solved with bounded errors (inexactly). This\ninexact variant of SDDP is described both for linear problems (the\ncorresponding variant being denoted by ISDDP-LP) and nonlinear problems (the\ncorresponding variant being denoted by ISDDP-NLP). We prove convergence\ntheorems for ISDDP-LP and ISDDP-NLP both for bounded and asymptotically\nvanishing errors. Finally, we present the results of numerical experiments\ncomparing SDDP and ISDDP-LP on portfolio problem with direct transaction costs\nmodelled as a multistage stochastic linear optimization problem. On these\nexperiments, ISDDP-LP allows us to obtain a good policy faster than SDDP. \n\n"}
{"id": "1809.02341", "contents": "Title: A Fast Anderson-Chebyshev Acceleration for Nonlinear Optimization Abstract: Anderson acceleration (or Anderson mixing) is an efficient acceleration\nmethod for fixed point iterations $x_{t+1}=G(x_t)$, e.g., gradient descent can\nbe viewed as iteratively applying the operation $G(x) \\triangleq x-\\alpha\\nabla\nf(x)$. It is known that Anderson acceleration is quite efficient in practice\nand can be viewed as an extension of Krylov subspace methods for nonlinear\nproblems. In this paper, we show that Anderson acceleration with Chebyshev\npolynomial can achieve the optimal convergence rate\n$O(\\sqrt{\\kappa}\\ln\\frac{1}{\\epsilon})$, which improves the previous result\n$O(\\kappa\\ln\\frac{1}{\\epsilon})$ provided by (Toth and Kelley, 2015) for\nquadratic functions. Moreover, we provide a convergence analysis for minimizing\ngeneral nonlinear problems. Besides, if the hyperparameters (e.g., the\nLipschitz smooth parameter $L$) are not available, we propose a guessing\nalgorithm for guessing them dynamically and also prove a similar convergence\nrate. Finally, the experimental results demonstrate that the proposed\nAnderson-Chebyshev acceleration method converges significantly faster than\nother algorithms, e.g., vanilla gradient descent (GD), Nesterov's Accelerated\nGD. Also, these algorithms combined with the proposed guessing algorithm\n(guessing the hyperparameters dynamically) achieve much better performance. \n\n"}
{"id": "1809.02385", "contents": "Title: Mixtures of Skewed Matrix Variate Bilinear Factor Analyzers Abstract: In recent years, data have become increasingly higher dimensional and,\ntherefore, an increased need has arisen for dimension reduction techniques for\nclustering. Although such techniques are firmly established in the literature\nfor multivariate data, there is a relative paucity in the area of matrix\nvariate, or three-way, data. Furthermore, the few methods that are available\nall assume matrix variate normality, which is not always sensible if cluster\nskewness or excess kurtosis is present. Mixtures of bilinear factor analyzers\nusing skewed matrix variate distributions are proposed. In all, four such\nmixture models are presented, based on matrix variate skew-t, generalized\nhyperbolic, variance-gamma, and normal inverse Gaussian distributions,\nrespectively. \n\n"}
{"id": "1809.02864", "contents": "Title: Online Adaptive Methods, Universality and Acceleration Abstract: We present a novel method for convex unconstrained optimization that, without\nany modifications, ensures: (i) accelerated convergence rate for smooth\nobjectives, (ii) standard convergence rate in the general (non-smooth) setting,\nand (iii) standard convergence rate in the stochastic optimization setting. To\nthe best of our knowledge, this is the first method that simultaneously applies\nto all of the above settings. At the heart of our method is an adaptive\nlearning rate rule that employs importance weights, in the spirit of adaptive\nonline learning algorithms (Duchi et al., 2011; Levy, 2017), combined with an\nupdate that linearly couples two sequences, in the spirit of (Allen-Zhu and\nOrecchia, 2017). An empirical examination of our method demonstrates its\napplicability to the above mentioned scenarios and corroborates our theoretical\nfindings. \n\n"}
{"id": "1809.03019", "contents": "Title: Stochastic Gradient Descent Learns State Equations with Nonlinear\n  Activations Abstract: We study discrete time dynamical systems governed by the state equation\n$h_{t+1}=\\phi(Ah_t+Bu_t)$. Here $A,B$ are weight matrices, $\\phi$ is an\nactivation function, and $u_t$ is the input data. This relation is the backbone\nof recurrent neural networks (e.g. LSTMs) which have broad applications in\nsequential learning tasks. We utilize stochastic gradient descent to learn the\nweight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We\nprove that SGD estimate linearly converges to the ground truth weights while\nusing near-optimal sample size. Our results apply to increasing activations\nwhose derivatives are bounded away from zero. The analysis is based on i) a\nnovel SGD convergence result with nonlinear activations and ii) careful\nstatistical characterization of the state vector. Numerical experiments verify\nthe fast convergence of SGD on ReLU and leaky ReLU in consistence with our\ntheory. \n\n"}
{"id": "1809.04129", "contents": "Title: Rethinking the Effective Sample Size Abstract: The effective sample size (ESS) is widely used in sample-based simulation\nmethods for assessing the quality of a Monte Carlo approximation of a given\ndistribution and of related integrals. In this paper, we revisit the\napproximation of the ESS in the specific context of importance sampling (IS).\nThe derivation of this approximation, that we will denote as\n$\\widehat{\\text{ESS}}$, is partially available in Kong (1992). This\napproximation has been widely used in the last 25 years due to its simplicity\nas a practical rule of thumb in a wide variety of importance sampling methods.\nHowever, we show that the multiple assumptions and approximations in the\nderivation of $\\widehat{\\text{ESS}}$, makes it difficult to be considered even\nas a reasonable approximation of the ESS. We extend the discussion of the\n$\\widehat{\\text{ESS}}$ in the multiple importance sampling (MIS) setting, we\ndisplay numerical examples, and we discuss several avenues for developing\nalternative metrics. This paper does not cover the use of ESS for MCMC\nalgorithms. \n\n"}
{"id": "1809.04153", "contents": "Title: Joint Chance Constraints in AC Optimal Power Flow: Improving Bounds\n  through Learning Abstract: This paper considers distribution systems with a high penetration of\ndistributed, renewable generation and addresses the problem of incorporating\nthe associated uncertainty into the optimal operation of these networks. Joint\nchance constraints, which satisfy multiple constraints simultaneously with a\nprescribed probability, are one way to incorporate uncertainty across sets of\nconstraints, leading to a chance-constrained optimal power flow problem.\nDeparting from the computationally-heavy scenario-based approaches or\napproximations that transform the joint constraint into conservative\ndeterministic constraints, this paper develops a scalable, data-driven approach\nwhich learns operational trends in a power network, eliminates zero-probability\nevents (e.g., inactive constraints), and accurately and efficiently\napproximates bounds on the joint chance constraint iteratively. In particular,\nthe proposed framework improves upon the classic methods based on the union\nbound (or Boole's inequality) by generating a much less conservative set of\nsingle chance constraints that also guarantees the satisfaction of the original\njoint constraint. The proposed framework is evaluated numerically using the\nIEEE 37-node test feeder, focusing on the problem of voltage regulation in\ndistribution grids. \n\n"}
{"id": "1809.04198", "contents": "Title: Optimization with Non-Differentiable Constraints with Applications to\n  Fairness, Recall, Churn, and Other Goals Abstract: We show that many machine learning goals, such as improved fairness metrics,\ncan be expressed as constraints on the model's predictions, which we call rate\nconstraints. We study the problem of training non-convex models subject to\nthese rate constraints (or any non-convex and non-differentiable constraints).\nIn the non-convex setting, the standard approach of Lagrange multipliers may\nfail. Furthermore, if the constraints are non-differentiable, then one cannot\noptimize the Lagrangian with gradient-based methods. To solve these issues, we\nintroduce the proxy-Lagrangian formulation. This new formulation leads to an\nalgorithm that produces a stochastic classifier by playing a two-player\nnon-zero-sum game solving for what we call a semi-coarse correlated\nequilibrium, which in turn corresponds to an approximately optimal and feasible\nsolution to the constrained optimization problem. We then give a procedure\nwhich shrinks the randomized solution down to one that is a mixture of at most\n$m+1$ deterministic solutions, given $m$ constraints. This culminates in\nalgorithms that can solve non-convex constrained optimization problems with\npossibly non-differentiable and non-convex constraints with theoretical\nguarantees. We provide extensive experimental results enforcing a wide range of\npolicy goals including different fairness metrics, and other goals on accuracy,\ncoverage, recall, and churn. \n\n"}
{"id": "1809.04221", "contents": "Title: Constrained optimization as ecological dynamics with applications to\n  random quadratic programming in high dimensions Abstract: Quadratic programming (QP) is a common and important constrained optimization\nproblem. Here, we derive a surprising duality between constrained optimization\nwith inequality constraints -- of which QP is a special case -- and consumer\nresource models describing ecological dynamics. Combining this duality with a\nrecent `cavity solution', we analyze high-dimensional, random QP where the\noptimization function and constraints are drawn randomly. Our theory shows\nremarkable agreement with numerics and points to a deep connection between\noptimization, dynamical systems, and ecology. \n\n"}
{"id": "1809.04249", "contents": "Title: A Fast Globally Linearly Convergent Algorithm for the Computation of\n  Wasserstein Barycenters Abstract: We consider the problem of computing a Wasserstein barycenter for a set of\ndiscrete probability distributions with finite supports, which finds many\napplications in areas such as statistics, machine learning and image\nprocessing. When the support points of the barycenter are pre-specified, this\nproblem can be modeled as a linear programming (LP) problem whose size can be\nextremely large. To handle this large-scale LP, we analyse the structure of its\ndual problem, which is conceivably more tractable and can be reformulated as a\nwell-structured convex problem with 3 kinds of block variables and a coupling\nlinear equality constraint. We then adapt a symmetric Gauss-Seidel based\nalternating direction method of multipliers (sGS-ADMM) to solve the resulting\ndual problem and establish its global convergence and global linear convergence\nrate. As a critical component for efficient computation, we also show how all\nthe subproblems involved can be solved exactly and efficiently. This makes our\nmethod suitable for computing a Wasserstein barycenter on a large-scale data\nset, without introducing an entropy regularization term as is commonly\npracticed. In addition, our sGS-ADMM can be used as a subroutine in an\nalternating minimization method to compute a barycenter when its support points\nare not pre-specified. Numerical results on synthetic data sets and image data\nsets demonstrate that our method is highly competitive for solving large-scale\nWasserstein barycenter problems, in comparison to two existing representative\nmethods and the commercial software Gurobi. \n\n"}
{"id": "1809.05933", "contents": "Title: Day-to-day dynamic traffic assignment model with variable message signs\n  and endogenous user compliance Abstract: This paper proposes a dual-time-scale, day-to-day dynamic traffic assignment\nmodel that takes into account variable message signs (VMS) and its interactions\nwith drivers' travel choices and adaptive learning processes. The within-day\ndynamic is captured by a dynamic network loading problem with en route update\nof path choices influenced by the VMS; the day-to-day dynamic is captured by a\nsimultaneous route-and-departure-time adjustment process that employs bounded\nuser rationality. Moreover, we describe the evolution of the VMS compliance\nrate by modeling drivers' learning processes. We endogenize traffic dynamics,\nroute and departure time choices, travel delays, and VMS compliance, and\nthereby captur their interactions and interdependencies in a holistic manner. A\ncase study in the west end of Glasgow is carried out to understand the impact\nof VMS has on road congestion and route choices in both the short and long run.\nOur main findings include an adverse effect of the VMS on the network\nperformance in the long run (the 'rebound' effect), and existence of an\nequilibrium state where both traffic and VMS compliance are stabilized. \n\n"}
{"id": "1809.06360", "contents": "Title: The Parallelization of Riccati Recursion Abstract: A method is presented for parallelizing the computation of solutions to\ndiscrete-time, linear-quadratic, finite-horizon optimal control problems, which\nwe will refer to as LQR problems. This class of problem arises frequently in\nrobotic trajectory optimization. For very complicated robots, the size of these\nresulting problems can be large enough that computing the solution is\nprohibitively slow when using a single processor. Fortunately, approaches to\nsolving these type of problems based on numerical solutions to the KKT\nconditions of optimality offer a parallel solution method and can leverage\nmultiple processors to compute solutions faster. However, these methods do not\nproduce the useful feedback control policies that are generated as a by-product\nof the dynamic-programming solution method known as Riccati recursion. In this\npaper we derive a method which is able to parallelize the computation of\nRiccati recursion, allowing for super-fast solutions to the LQR problem while\nstill generating feedback control policies. We demonstrate empirically that our\nmethod is faster than existing parallel methods. \n\n"}
{"id": "1809.06784", "contents": "Title: Adversarial Reinforcement Learning for Observer Design in Autonomous\n  Systems under Cyber Attacks Abstract: Complex autonomous control systems are subjected to sensor failures,\ncyber-attacks, sensor noise, communication channel failures, etc. that\nintroduce errors in the measurements. The corrupted information, if used for\nmaking decisions, can lead to degraded performance. We develop a framework for\nusing adversarial deep reinforcement learning to design observer strategies\nthat are robust to adversarial errors in information channels. We further show\nthrough simulation studies that the learned observation strategies perform\nremarkably well when the adversary's injected errors are bounded in some sense.\nWe use neural network as function approximator in our studies with the\nunderstanding that any other suitable function approximating class can be used\nwithin our framework. \n\n"}
{"id": "1809.06904", "contents": "Title: Non-Stationary Covariance Estimation using the Stochastic Score\n  Approximation for Large Spatial Data Abstract: We introduce computational methods that allow for effective estimation of a\nflexible, parametric non-stationary spatial model when the field size is too\nlarge to compute the multivariate normal likelihood directly. In this method,\nthe field is defined as a weighted spatially varying linear combination of a\nglobally stationary process and locally stationary processes. Often in such a\nmodel, the difficulty in its practical use is in the definition of the\nboundaries for the local processes, and therefore we describe one such\nselection procedure that generally captures complex non-stationary\nrelationships. We generalize the use of stochastic approximation to the score\nequations for data on a partial grid in this non-stationary case and provide\ntools for evaluating the approximate score in $O(n\\log n)$ operations and\n$O(n)$ storage. We perform various simulations to explore the effectiveness and\nspeed of the proposed methods and conclude by making inference on the\naccumulation behavior of arsenic applied to a sand grain. \n\n"}
{"id": "1809.07180", "contents": "Title: Projective Splitting with Forward Steps only Requires Continuity Abstract: A recent innovation in projective splitting algorithms for monotone operator\ninclusions has been the development of a procedure using two forward steps\ninstead of the customary proximal steps for operators that are Lipschitz\ncontinuous. This paper shows that the Lipschitz assumption is unnecessary when\nthe forward steps are performed in finite-dimensional spaces: a backtracking\nlinesearch yields a convergent algorithm for operators that are merely\ncontinuous with full domain. \n\n"}
{"id": "1809.07192", "contents": "Title: Unbalanced Multi-Phase Distribution Grid Topology Estimation and Bus\n  Phase Identification Abstract: There is an increasing need for monitoring and controlling uncertainties\nbrought by distributed energy resources in distribution grids. For such goal,\naccurate multi-phase topology is the basis for correlating measurements in\nunbalanced distribution networks. Unfortunately, such topology knowledge is\noften unavailable due to limited investment, especially for \\revv{low-voltage}\ndistribution grids. Also, the bus phase labeling information is inaccurate due\nto human errors or outdated records. For this challenge, this paper utilizes\nsmart meter data for an information-theoretic approach to learn the topology of\ndistribution grids. Specifically, multi-phase unbalanced systems are converted\ninto symmetrical components, namely positive, negative, and zero sequences.\nThen, this paper proves that the Chow-Liu algorithm finds the topology by\nutilizing power flow equations and the conditional independence relationships\nimplied by the radial multi-phase structure of distribution grids with the\npresence of incorrect bus phase labels. At last, by utilizing Carson's\nequation, this paper proves that the bus phase connection can be correctly\nidentified using voltage measurements. For validation, IEEE systems are\nsimulated using three real data sets. The simulation results demonstrate that\nthe algorithm is highly accurate for finding multi-phase topology even with\nstrong load unbalancing condition and DERs. This ensures close monitoring and\ncontrolling DERs in distribution grids. \n\n"}
{"id": "1809.07279", "contents": "Title: Feedback Control of a Cassie Bipedal Robot: Walking, Standing, and\n  Riding a Segway Abstract: The Cassie bipedal robot designed by Agility Robotics is providing academics\na common platform for sharing and comparing algorithms for locomotion,\nperception, and navigation. This paper focuses on feedback control for standing\nand walking using the methods of virtual constraints and gait libraries. The\ndesigned controller was implemented six weeks after the robot arrived at the\nUniversity of Michigan and allowed it to stand in place as well as walk over\nsidewalks, grass, snow, sand, and burning brush. The controller for standing\nalso enables the robot to ride a Segway. A model of the Cassie robot has been\nplaced on GitHub and the controller will also be made open source if the paper\nis accepted. \n\n"}
{"id": "1809.08587", "contents": "Title: Exponential Convergence Time of Gradient Descent for One-Dimensional\n  Deep Linear Neural Networks Abstract: We study the dynamics of gradient descent on objective functions of the form\n$f(\\prod_{i=1}^{k} w_i)$ (with respect to scalar parameters $w_1,\\ldots,w_k$),\nwhich arise in the context of training depth-$k$ linear neural networks. We\nprove that for standard random initializations, and under mild assumptions on\n$f$, the number of iterations required for convergence scales exponentially\nwith the depth $k$. We also show empirically that this phenomenon can occur in\nhigher dimensions, where each $w_i$ is a matrix. This highlights a potential\nobstacle in understanding the convergence of gradient-based methods for deep\nlinear neural networks, where $k$ is large. \n\n"}
{"id": "1809.08926", "contents": "Title: Finite Sample Analysis of the GTD Policy Evaluation Algorithms in Markov\n  Setting Abstract: In reinforcement learning (RL) , one of the key components is policy\nevaluation, which aims to estimate the value function (i.e., expected long-term\naccumulated reward) of a policy. With a good policy evaluation method, the RL\nalgorithms will estimate the value function more accurately and find a better\npolicy. When the state space is large or continuous \\emph{Gradient-based\nTemporal Difference(GTD)} policy evaluation algorithms with linear function\napproximation are widely used. Considering that the collection of the\nevaluation data is both time and reward consuming, a clear understanding of the\nfinite sample performance of the policy evaluation algorithms is very important\nto reinforcement learning. Under the assumption that data are i.i.d. generated,\nprevious work provided the finite sample analysis of the GTD algorithms with\nconstant step size by converting them into convex-concave saddle point\nproblems. However, it is well-known that, the data are generated from Markov\nprocesses rather than i.i.d. in RL problems.. In this paper, in the realistic\nMarkov setting, we derive the finite sample bounds for the general\nconvex-concave saddle point problems, and hence for the GTD algorithms. We have\nthe following discussions based on our bounds. (1) With variants of step size,\nGTD algorithms converge. (2) The convergence rate is determined by the step\nsize, with the mixing time of the Markov process as the coefficient. The faster\nthe Markov processes mix, the faster the convergence. (3) We explain that the\nexperience replay trick is effective by improving the mixing property of the\nMarkov process. To the best of our knowledge, our analysis is the first to\nprovide finite sample bounds for the GTD algorithms in Markov setting. \n\n"}
{"id": "1809.09219", "contents": "Title: Fast Signal Recovery from Saturated Measurements by Linear Loss and\n  Nonconvex Penalties Abstract: Sign information is the key to overcoming the inevitable saturation error in\ncompressive sensing systems, which causes information loss and results in bias.\nFor sparse signal recovery from saturation, we propose to use a linear loss to\nimprove the effectiveness from existing methods that utilize hard\nconstraints/hinge loss for sign consistency. Due to the use of linear loss, an\nanalytical solution in the update progress is obtained, and some nonconvex\npenalties are applicable, e.g., the minimax concave penalty, the $\\ell_0$ norm,\nand the sorted $\\ell_1$ norm. Theoretical analysis reveals that the estimation\nerror can still be bounded. Generally, with linear loss and nonconvex\npenalties, the recovery performance is significantly improved, and the\ncomputational time is largely saved, which is verified by the numerical\nexperiments. \n\n"}
{"id": "1809.10121", "contents": "Title: Safely Learning to Control the Constrained Linear Quadratic Regulator Abstract: We study the constrained linear quadratic regulator with unknown dynamics,\naddressing the tension between safety and exploration in data-driven control\ntechniques. We present a framework which allows for system identification\nthrough persistent excitation, while maintaining safety by guaranteeing the\nsatisfaction of state and input constraints. This framework involves a novel\nmethod for synthesizing robust constraint-satisfying feedback controllers,\nleveraging newly developed tools from system level synthesis. We connect\nstatistical results with cost sub-optimality bounds to give non-asymptotic\nguarantees on both estimation and controller performance. \n\n"}
{"id": "1809.10330", "contents": "Title: Variance reduction properties of the reparameterization trick Abstract: The reparameterization trick is widely used in variational inference as it\nyields more accurate estimates of the gradient of the variational objective\nthan alternative approaches such as the score function method. Although there\nis overwhelming empirical evidence in the literature showing its success, there\nis relatively little research exploring why the reparameterization trick is so\neffective. We explore this under the idealized assumptions that the variational\napproximation is a mean-field Gaussian density and that the log of the joint\ndensity of the model parameters and the data is a quadratic function that\ndepends on the variational mean. From this, we show that the marginal variances\nof the reparameterization gradient estimator are smaller than those of the\nscore function gradient estimator. We apply the result of our idealized\nanalysis to real-world examples. \n\n"}
{"id": "1809.10477", "contents": "Title: Fast Stochastic Algorithms for Low-rank and Nonsmooth Matrix Problems Abstract: Composite convex optimization problems which include both a nonsmooth term\nand a low-rank promoting term have important applications in machine learning\nand signal processing, such as when one wishes to recover an unknown matrix\nthat is simultaneously low-rank and sparse. However, such problems are highly\nchallenging to solve in large-scale: the low-rank promoting term prohibits\nefficient implementations of proximal methods for composite optimization and\neven simple subgradient methods. On the other hand, methods which are tailored\nfor low-rank optimization, such as conditional gradient-type methods, which are\noften applied to a smooth approximation of the nonsmooth objective, are slow\nsince their runtime scales with both the large Lipshitz parameter of the\nsmoothed gradient vector and with $1/\\epsilon$. In this paper we develop\nefficient algorithms for \\textit{stochastic} optimization of a strongly-convex\nobjective which includes both a nonsmooth term and a low-rank promoting term.\nIn particular, to the best of our knowledge, we present the first algorithm\nthat enjoys all following critical properties for large-scale problems: i)\n(nearly) optimal sample complexity, ii) each iteration requires only a single\n\\textit{low-rank} SVD computation, and iii) overall number of thin-SVD\ncomputations scales only with $\\log{1/\\epsilon}$ (as opposed to\n$\\textrm{poly}(1/\\epsilon)$ in previous methods). We also give an algorithm for\nthe closely-related finite-sum setting. At the heart of our results lie a novel\ncombination of a variance-reduction technique and the use of a\n\\textit{weak-proximal oracle} which is key to obtaining all above three\nproperties simultaneously. \n\n"}
{"id": "1809.10491", "contents": "Title: On the Regret Minimization of Nonconvex Online Gradient Ascent for\n  Online PCA Abstract: In this paper we focus on the problem of Online Principal Component Analysis\nin the regret minimization framework. For this problem, all existing regret\nminimization algorithms for the fully-adversarial setting are based on a\npositive semidefinite convex relaxation, and hence require quadratic memory and\nSVD computation (either thin of full) on each iteration, which amounts to at\nleast quadratic runtime per iteration. This is in stark contrast to a\ncorresponding stochastic i.i.d. variant of the problem, which was studied\nextensively lately, and admits very efficient gradient ascent algorithms that\nwork directly on the natural non-convex formulation of the problem, and hence\nrequire only linear memory and linear runtime per iteration. This raises the\nquestion: can non-convex online gradient ascent algorithms be shown to minimize\nregret in online adversarial settings? In this paper we take a step forward\ntowards answering this question. We introduce an\n\\textit{adversarially-perturbed spiked-covariance model} in which, each data\npoint is assumed to follow a fixed stochastic distribution with a non-zero\nspectral gap in the covariance matrix, but is then perturbed with some\nadversarial vector. This model is a natural extension of a well studied\nstandard stochastic setting that allows for non-stationary (adversarial)\npatterns to arise in the data and hence, might serve as a significantly better\napproximation for real-world data-streams. We show that in an interesting\nregime of parameters, when the non-convex online gradient ascent algorithm is\ninitialized with a \"warm-start\" vector, it provably minimizes the regret with\nhigh probability. We further discuss the possibility of computing such a\n\"warm-start\" vector, and also the use of regularization to obtain fast regret\nrates. Our theoretical findings are supported by empirical experiments on both\nsynthetic and real-world data. \n\n"}
{"id": "1810.00257", "contents": "Title: Computational Convergence Analysis of Distributed Gradient Tracking for\n  Smooth Convex Optimization Using Dissipativity Theory Abstract: We present a computational analysis that establishes the $O(1/K)$ convergence\nof the distributed gradient tracking method when the objective function is\nsmooth and convex but not strongly convex. The analysis is inspired by recent\nwork on applying dissipativity theory to the analysis of centralized\noptimization algorithms, in which convergence is proved by searching for a\nnumerical certificate consisting of a storage function and a supply rate. We\nderive a base supply rate that can be used to analyze distributed optimization\nwith non-strongly convex objective functions. The base supply rate is then used\nto create a class of supply rates by combining with integral quadratic\nconstraints. Provided that the class of supply rates is rich enough, a\nnumerical certificate of convergence can be automatically generated following a\nstandard procedure that involves solving a linear matrix inequality. Our\ncomputational analysis is found capable of certifying convergence under a\nbroader range of step sizes than what is given by the original analytic result. \n\n"}
{"id": "1810.01340", "contents": "Title: Majorization by Hemispheres & Quadratic Isoperimetric Constants Abstract: Let $X$ be a Banach space or more generally a complete metric space admitting\na conical geodesic bicombing. We prove that every closed $L$-Lipschitz curve\n$\\gamma:S^1\\rightarrow X$ may be extended to an $L$-Lipschitz map defined on\nthe hemisphere $f:H^2\\rightarrow X$. This implies that $X$ satisfies a\nquadratic isoperimetric inequality (for curves) with constant $\\frac{1}{2\\pi}$.\nWe discuss how this fact controls the regularity of minimal discs in Finsler\nmanifolds when applied to the work of Alexander Lytchak and Stefan Wenger. \n\n"}
{"id": "1810.01761", "contents": "Title: Simulation of elliptic and hypo-elliptic conditional diffusions Abstract: Suppose $X$ is a multidimensional diffusion process. Assume that at time zero\nthe state of $X$ is fully observed, but at time $T>0$ only linear combinations\nof its components are observed. That is, one only observes the vector $L X_T$\nfor a given matrix $L$. In this paper we show how samples from the conditioned\nprocess can be generated. The main contribution of this paper is to prove that\nguided proposals, introduced in Schauer et al. (2017), can be used in a unified\nway for both uniformly and hypo-elliptic diffusions, also when $L$ is not the\nidentity matrix. This is illustrated by excellent performance in two\nchallenging cases: a partially observed twice integrated diffusion with\nmultiple wells and the partially observed FitzHugh-Nagumo model. \n\n"}
{"id": "1810.01920", "contents": "Title: Generalized Inverse Optimization through Online Learning Abstract: Inverse optimization is a powerful paradigm for learning preferences and\nrestrictions that explain the behavior of a decision maker, based on a set of\nexternal signal and the corresponding decision pairs. However, most inverse\noptimization algorithms are designed specifically in batch setting, where all\nthe data is available in advance. As a consequence, there has been rare use of\nthese methods in an online setting suitable for real-time applications. In this\npaper, we propose a general framework for inverse optimization through online\nlearning. Specifically, we develop an online learning algorithm that uses an\nimplicit update rule which can handle noisy data. Moreover, under additional\nregularity assumptions in terms of the data and the model, we prove that our\nalgorithm converges at a rate of $\\mathcal{O}(1/\\sqrt{T})$ and is statistically\nconsistent. In our experiments, we show the online learning approach can learn\nthe parameters with great accuracy and is very robust to noises, and achieves a\ndramatic improvement in computational efficacy over the batch learning\napproach. \n\n"}
{"id": "1810.02032", "contents": "Title: Gradient descent aligns the layers of deep linear networks Abstract: This paper establishes risk convergence and asymptotic weight matrix\nalignment --- a form of implicit regularization --- of gradient flow and\ngradient descent when applied to deep linear networks on linearly separable\ndata. In more detail, for gradient flow applied to strictly decreasing loss\nfunctions (with similar results for gradient descent with particular decreasing\nstep sizes): (i) the risk converges to 0; (ii) the normalized i-th weight\nmatrix asymptotically equals its rank-1 approximation $u_iv_i^{\\top}$; (iii)\nthese rank-1 matrices are aligned across layers, meaning\n$|v_{i+1}^{\\top}u_i|\\to1$. In the case of the logistic loss (binary cross\nentropy), more can be said: the linear function induced by the network --- the\nproduct of its weight matrices --- converges to the same direction as the\nmaximum margin solution. This last property was identified in prior work, but\nonly under assumptions on gradient descent which here are implied by the\nalignment phenomenon. \n\n"}
{"id": "1810.02054", "contents": "Title: Gradient Descent Provably Optimizes Over-parameterized Neural Networks Abstract: One of the mysteries in the success of neural networks is randomly\ninitialized first order methods like gradient descent can achieve zero training\nloss even though the objective function is non-convex and non-smooth. This\npaper demystifies this surprising phenomenon for two-layer fully connected ReLU\nactivated neural networks. For an $m$ hidden node shallow neural network with\nReLU activation and $n$ training data, we show as long as $m$ is large enough\nand no two inputs are parallel, randomly initialized gradient descent converges\nto a globally optimal solution at a linear convergence rate for the quadratic\nloss function.\n  Our analysis relies on the following observation: over-parameterization and\nrandom initialization jointly restrict every weight vector to be close to its\ninitialization for all iterations, which allows us to exploit a strong\nconvexity-like property to show that gradient descent converges at a global\nlinear rate to the global optimum. We believe these insights are also useful in\nanalyzing deep models and other first order methods. \n\n"}
{"id": "1810.02660", "contents": "Title: Accelerated Decentralized Optimization with Local Updates for Smooth and\n  Strongly Convex Objectives Abstract: In this paper, we study the problem of minimizing a sum of smooth and\nstrongly convex functions split over the nodes of a network in a decentralized\nfashion. We propose the algorithm $ESDACD$, a decentralized accelerated\nalgorithm that only requires local synchrony. Its rate depends on the condition\nnumber $\\kappa$ of the local functions as well as the network topology and\ndelays. Under mild assumptions on the topology of the graph, $ESDACD$ takes a\ntime $O((\\tau_{\\max} +\n\\Delta_{\\max})\\sqrt{{\\kappa}/{\\gamma}}\\ln(\\epsilon^{-1}))$ to reach a precision\n$\\epsilon$ where $\\gamma$ is the spectral gap of the graph, $\\tau_{\\max}$ the\nmaximum communication delay and $\\Delta_{\\max}$ the maximum computation time.\nTherefore, it matches the rate of $SSDA$, which is optimal when $\\tau_{\\max} =\n\\Omega\\left(\\Delta_{\\max}\\right)$. Applying $ESDACD$ to quadratic local\nfunctions leads to an accelerated randomized gossip algorithm of rate $O(\n\\sqrt{\\theta_{\\rm gossip}/n})$ where $\\theta_{\\rm gossip}$ is the rate of the\nstandard randomized gossip. To the best of our knowledge, it is the first\nasynchronous gossip algorithm with a provably improved rate of convergence of\nthe second moment of the error. We illustrate these results with experiments in\nidealized settings. \n\n"}
{"id": "1810.02893", "contents": "Title: Optimization on Spheres: Models and Proximal Algorithms with\n  Computational Performance Comparisons Abstract: We present a unified treatment of the abstract problem of finding the best\napproximation between a cone and spheres in the image of affine\ntransformations. Prominent instances of this problem are phase retrieval and\nsource localization. The common geometry binding these problems permits a\ngeneric application of algorithmic ideas and abstract convergence results for\nnonconvex optimization. We organize variational models for this problem into\nthree different classes and derive the main algorithmic approaches within these\nclasses (13 in all). We identify the central ideas underlying these methods and\nprovide thorough numerical benchmarks comparing their performance on synthetic\nand laboratory data. The software and data of our experiments are all publicly\naccessible. We also introduce one new algorithm, a cyclic relaxed\nDouglas-Rachford algorithm, which outperforms all other algorithms by every\nmeasure: speed, stability and accuracy. The analysis of this algorithm remains\nopen. \n\n"}
{"id": "1810.03218", "contents": "Title: Principled Deep Neural Network Training through Linear Programming Abstract: Deep learning has received much attention lately due to the impressive\nempirical performance achieved by training algorithms. Consequently, a need for\na better theoretical understanding of these problems has become more evident in\nrecent years. In this work, using a unified framework, we show that there\nexists a polyhedron which encodes simultaneously all possible deep neural\nnetwork training problems that can arise from a given architecture, activation\nfunctions, loss function, and sample-size. Notably, the size of the polyhedral\nrepresentation depends only linearly on the sample-size, and a better\ndependency on several other network parameters is unlikely (assuming $P\\neq\nNP$). Additionally, we use our polyhedral representation to obtain new and\nbetter computational complexity results for training problems of well-known\nneural network architectures. Our results provide a new perspective on training\nproblems through the lens of polyhedral theory and reveal a strong structure\narising from these problems. \n\n"}
{"id": "1810.03370", "contents": "Title: Empirical Bounds on Linear Regions of Deep Rectifier Networks Abstract: We can compare the expressiveness of neural networks that use rectified\nlinear units (ReLUs) by the number of linear regions, which reflect the number\nof pieces of the piecewise linear functions modeled by such networks. However,\nenumerating these regions is prohibitive and the known analytical bounds are\nidentical for networks with same dimensions. In this work, we approximate the\nnumber of linear regions through empirical bounds based on features of the\ntrained network and probabilistic inference. Our first contribution is a method\nto sample the activation patterns defined by ReLUs using universal hash\nfunctions. This method is based on a Mixed-Integer Linear Programming (MILP)\nformulation of the network and an algorithm for probabilistic lower bounds of\nMILP solution sets that we call MIPBound, which is considerably faster than\nexact counting and reaches values in similar orders of magnitude. Our second\ncontribution is a tighter activation-based bound for the maximum number of\nlinear regions, which is particularly stronger in networks with narrow layers.\nCombined, these bounds yield a fast proxy for the number of linear regions of a\ndeep neural network. \n\n"}
{"id": "1810.04723", "contents": "Title: Tight Dimension Independent Lower Bound on the Expected Convergence Rate\n  for Diminishing Step Sizes in SGD Abstract: We study the convergence of Stochastic Gradient Descent (SGD) for strongly\nconvex objective functions. We prove for all $t$ a lower bound on the expected\nconvergence rate after the $t$-th SGD iteration; the lower bound is over all\npossible sequences of diminishing step sizes. It implies that recently proposed\nsequences of step sizes at ICML 2018 and ICML 2019 are {\\em universally} close\nto optimal in that the expected convergence rate after {\\em each} iteration is\nwithin a factor $32$ of our lower bound. This factor is independent of\ndimension $d$. We offer a framework for comparing with lower bounds in\nstate-of-the-art literature and when applied to SGD for strongly convex\nobjective functions our lower bound is a significant factor $775\\cdot d$ larger\ncompared to existing work. \n\n"}
{"id": "1810.05580", "contents": "Title: Strong Structural Controllability of Systems on Colored Graphs Abstract: This paper deals with structural controllability of leader-follower networks.\nThe system matrix defining the network dynamics is a pattern matrix in which a\npriori given entries are equal to zero, while the remaining entries take\nnonzero values. The network is called strongly structurally controllable if for\nall choices of real values for the nonzero entries in the pattern matrix, the\nsystem is controllable in the classical sense. In this paper we introduce a\nmore general notion of strong structural controllability which deals with the\nsituation that given nonzero entries in the system's pattern matrix are\nconstrained to take identical nonzero values. The constraint of identical\nnonzero entries can be caused by symmetry considerations or physical\nconstraints on the network. The aim of this paper is to establish graph\ntheoretic conditions for this more general property of strong structural\ncontrollability. \n\n"}
{"id": "1810.05633", "contents": "Title: Stochastic (Approximate) Proximal Point Methods: Convergence,\n  Optimality, and Adaptivity Abstract: We develop model-based methods for solving stochastic convex optimization\nproblems, introducing the approximate-proximal point, or aProx, family, which\nincludes stochastic subgradient, proximal point, and bundle methods. When the\nmodeling approaches we propose are appropriately accurate, the methods enjoy\nstronger convergence and robustness guarantees than classical approaches, even\nthough the model-based methods typically add little to no computational\noverhead over stochastic subgradient methods. For example, we show that\nimproved models converge with probability 1 and enjoy optimal asymptotic\nnormality results under weak assumptions; these methods are also adaptive to a\nnatural class of what we term easy optimization problems, achieving linear\nconvergence under appropriate strong growth conditions on the objective. Our\nsubstantial experimental investigation shows the advantages of more accurate\nmodeling over standard subgradient methods across many smooth and non-smooth\noptimization problems. \n\n"}
{"id": "1810.06001", "contents": "Title: Minimal time for the continuity equation controlled by a localized\n  perturbation of the velocity vector field Abstract: In this work, we study the minimal time to steer a given crowd to a desired\nconfiguration. The control is a vector field, representing a perturbation of\nthe crowd velocity, localized on a fixed control set. We will assume that there\nis no interaction between the agents. We give a characterization of the minimal\ntime both for microscopic and macroscopic descriptions of a crowd. We show that\nthe minimal time to steer one initial configuration to another is related to\nthe condition of having enough mass in the control region to feed the desired\nfinal configuration. The construction of the control is explicit, providing a\nnumerical algorithm for computing it. We finally give some numerical\nsimulations. \n\n"}
{"id": "1810.06064", "contents": "Title: Schr\\\"odinger Approach to Optimal Control of Large-Size Populations Abstract: Large-size populations consisting of a continuum of identical and\nnon-cooperative agents with stochastic dynamics are useful in modeling various\nbiological and engineered systems. This paper addresses the stochastic control\nproblem of designing optimal state-feedback controllers which guarantee the\nclosed-loop stability of the stationary density of such agents with nonlinear\nLangevin dynamics, under the action of their individual steady state controls.\nWe represent the corresponding coupled forward-backward PDEs as decoupled\nSchr\\\"odinger equations, by applying two variable transforms. Spectral\nproperties of the linear Schr\\\"odinger operator which underlie the stability\nanalysis are used to obtain explicit control design constraints. Our\ninterpretation of the Schr\\\"odinger potential as the cost function of a closely\nrelated optimal control problem motivates a quadrature based algorithm to\ncompute the finite-time optimal control. \n\n"}
{"id": "1810.06175", "contents": "Title: An Optimal Control Approach to Sequential Machine Teaching Abstract: Given a sequential learning algorithm and a target model, sequential machine\nteaching aims to find the shortest training sequence to drive the learning\nalgorithm to the target model. We present the first principled way to find such\nshortest training sequences. Our key insight is to formulate sequential machine\nteaching as a time-optimal control problem. This allows us to solve sequential\nteaching by leveraging key theoretical and computational tools developed over\nthe past 60 years in the optimal control community. Specifically, we study the\nPontryagin Maximum Principle, which yields a necessary condition for optimality\nof a training sequence. We present analytic, structural, and numerical\nimplications of this approach on a case study with a least-squares loss\nfunction and gradient descent learner. We compute optimal training sequences\nfor this problem, and although the sequences seem circuitous, we find that they\ncan vastly outperform the best available heuristics for generating training\nsequences. \n\n"}
{"id": "1810.08918", "contents": "Title: Multiple Scaled Contaminated Normal Distribution and Its Application in\n  Clustering Abstract: The multivariate contaminated normal (MCN) distribution represents a simple\nheavy-tailed generalization of the multivariate normal (MN) distribution to\nmodel elliptical contoured scatters in the presence of mild outliers, referred\nto as \"bad\" points. The MCN can also automatically detect bad points. The price\nof these advantages is two additional parameters, both with specific and useful\ninterpretations: proportion of good observations and degree of contamination.\nHowever, points may be bad in some dimensions but good in others. The use of an\noverall proportion of good observations and of an overall degree of\ncontamination is limiting. To overcome this limitation, we propose a multiple\nscaled contaminated normal (MSCN) distribution with a proportion of good\nobservations and a degree of contamination for each dimension. Once the model\nis fitted, each observation has a posterior probability of being good with\nrespect to each dimension. Thanks to this probability, we have a method for\nsimultaneous directional robust estimation of the parameters of the MN\ndistribution based on down-weighting and for the automatic directional\ndetection of bad points by means of maximum a posteriori probabilities. The\nterm \"directional\" is added to specify that the method works separately for\neach dimension. Mixtures of MSCN distributions are also proposed as an\napplication of the proposed model for robust clustering. An extension of the EM\nalgorithm is used for parameter estimation based on the maximum likelihood\napproach. Real and simulated data are used to show the usefulness of our\nmixture with respect to well-established mixtures of symmetric distributions\nwith heavy tails. \n\n"}
{"id": "1810.09126", "contents": "Title: Risk-Sensitive Reinforcement Learning via Policy Gradient Search Abstract: The objective in a traditional reinforcement learning (RL) problem is to find\na policy that optimizes the expected value of a performance metric such as the\ninfinite-horizon cumulative discounted or long-run average cost/reward. In\npractice, optimizing the expected value alone may not be satisfactory, in that\nit may be desirable to incorporate the notion of risk into the optimization\nproblem formulation, either in the objective or as a constraint. Various risk\nmeasures have been proposed in the literature, e.g., exponential utility,\nvariance, percentile performance, chance constraints, value at risk (quantile),\nconditional value-at-risk, prospect theory and its later enhancement,\ncumulative prospect theory. In this book, we consider risk-sensitive RL in two\nsettings: one where the goal is to find a policy that optimizes the usual\nexpected value objective while ensuring that a risk constraint is satisfied,\nand the other where the risk measure is the objective. We survey some of the\nrecent work in this area specifically where policy gradient search is the\nsolution approach. In the first risk-sensitive RL setting, we cover popular\nrisk measures based on variance, conditional value-at-risk, and chance\nconstraints, and present a template for policy gradient-based risk-sensitive RL\nalgorithms using a Lagrangian formulation. For the setting where risk is\nincorporated directly into the objective function, we consider an exponential\nutility formulation, cumulative prospect theory, and coherent risk measures.\nThis non-exhaustive survey aims to give a flavor of the challenges involved in\nsolving risk-sensitive RL problems using policy gradient methods, as well as\noutlining some potential future research directions. \n\n"}
{"id": "1810.10132", "contents": "Title: Smoothed Online Optimization for Regression and Control Abstract: We consider Online Convex Optimization (OCO) in the setting where the costs\nare $m$-strongly convex and the online learner pays a switching cost for\nchanging decisions between rounds. We show that the recently proposed Online\nBalanced Descent (OBD) algorithm is constant competitive in this setting, with\ncompetitive ratio $3 + O(1/m)$, irrespective of the ambient dimension.\nAdditionally, we show that when the sequence of cost functions is\n$\\epsilon$-smooth, OBD has near-optimal dynamic regret and maintains strong\nper-round accuracy. We demonstrate the generality of our approach by showing\nthat the OBD framework can be used to construct competitive algorithms for a\nvariety of online problems across learning and control, including online\nvariants of ridge regression, logistic regression, maximum likelihood\nestimation, and LQR control. \n\n"}
{"id": "1810.10207", "contents": "Title: First-order Convergence Theory for Weakly-Convex-Weakly-Concave Min-max\n  Problems Abstract: In this paper, we consider first-order convergence theory and algorithms for\nsolving a class of non-convex non-concave min-max saddle-point problems, whose\nobjective function is weakly convex in the variables of minimization and weakly\nconcave in the variables of maximization. It has many important applications in\nmachine learning including training Generative Adversarial Nets (GANs). We\npropose an algorithmic framework motivated by the inexact proximal point\nmethod, where the weakly monotone variational inequality (VI) corresponding to\nthe original min-max problem is solved through approximately solving a sequence\nof strongly monotone VIs constructed by adding a strongly monotone mapping to\nthe original gradient mapping. We prove first-order convergence to a nearly\nstationary solution of the original min-max problem of the generic algorithmic\nframework and establish different rates by employing different algorithms for\nsolving each strongly monotone VI. Experiments verify the convergence theory\nand also demonstrate the effectiveness of the proposed methods on training\nGANs. \n\n"}
{"id": "1810.10702", "contents": "Title: Subgradient Descent Learns Orthogonal Dictionaries Abstract: This paper concerns dictionary learning, i.e., sparse coding, a fundamental\nrepresentation learning problem. We show that a subgradient descent algorithm,\nwith random initialization, can provably recover orthogonal dictionaries on a\nnatural nonsmooth, nonconvex $\\ell_1$ minimization formulation of the problem,\nunder mild statistical assumptions on the data. This is in contrast to previous\nprovable methods that require either expensive computation or delicate\ninitialization schemes. Our analysis develops several tools for characterizing\nlandscapes of nonsmooth functions, which might be of independent interest for\nprovable training of deep networks with nonsmooth activations (e.g., ReLU),\namong numerous other applications. Preliminary experiments corroborate our\nanalysis and show that our algorithm works well empirically in recovering\northogonal dictionaries. \n\n"}
{"id": "1810.10735", "contents": "Title: Numerical approximation of optimal convex shapes Abstract: This article investigates the numerical approximation of shape optimization\nproblems with PDE constraint on classes of convex domains. The convexity\nconstraint provides a compactness property which implies well posedness of the\nproblem. Moreover, we prove the convergence of discretizations in\ntwo-dimensional situations. A numerical algorithm is devised that iteratively\nsolves the discrete formulation. Numerical experiments show that optimal convex\nshapes are generally non-smooth and that three-dimensional problems require an\nappropriate relaxation of the convexity condition. \n\n"}
{"id": "1810.10985", "contents": "Title: Random Sampling: Practice Makes Imperfect Abstract: The pseudo-random number generators (PRNGs), sampling algorithms, and\nalgorithms for generating random integers in some common statistical packages\nand programming languages are unnecessarily inaccurate, by an amount that may\nmatter for statistical inference. Most use PRNGs with state spaces that are too\nsmall for contemporary sampling problems and methods such as the bootstrap and\npermutation tests. The random sampling algorithms in many packages rely on the\nfalse assumption that PRNGs produce IID $U[0, 1)$ outputs. The discreteness of\nPRNG outputs and the limited state space of common PRNGs cause those algorithms\nto perform poorly in practice. Statistics packages and scientific programming\nlanguages should use cryptographically secure PRNGs by default (not for their\nsecurity properties, but for their statistical ones), and offer weaker PRNGs\nonly as an option. Software should not use methods that assume PRNG outputs are\nIID $U[0,1)$ random variables, such as generating a random sample by permuting\nthe population and taking the first $k$ items or generating random integers by\nmultiplying a pseudo-random binary fraction or float by a constant and rounding\nthe result. More accurate methods are available. \n\n"}
{"id": "1810.11335", "contents": "Title: Outlier Detection using Generative Models with Theoretical Performance\n  Guarantees Abstract: This paper considers the problem of recovering signals from compressed\nmeasurements contaminated with sparse outliers, which has arisen in many\napplications. In this paper, we propose a generative model neural network\napproach for reconstructing the ground truth signals under sparse outliers. We\npropose an iterative alternating direction method of multipliers (ADMM)\nalgorithm for solving the outlier detection problem via $\\ell_1$ norm\nminimization, and a gradient descent algorithm for solving the outlier\ndetection problem via squared $\\ell_1$ norm minimization. We establish the\nrecovery guarantees for reconstruction of signals using generative models in\nthe presence of outliers, and give an upper bound on the number of outliers\nallowed for recovery. Our results are applicable to both the linear generator\nneural network and the nonlinear generator neural network with an arbitrary\nnumber of layers. We conduct extensive experiments using variational\nauto-encoder and deep convolutional generative adversarial networks, and the\nexperimental results show that the signals can be successfully reconstructed\nunder outliers using our approach. Our approach outperforms the traditional\nLasso and $\\ell_2$ minimization approach. \n\n"}
{"id": "1810.12036", "contents": "Title: Small noise limit and convexity for generalized incompressible flows,\n  Schr\\\"odinger problems, and optimal transport Abstract: This paper is concerned with six variational problems and their mutual\nconnections: The quadratic Monge-Kantorovich optimal transport, the\nSchr\\\"odinger problem, Brenier's relaxed model for incompressible fluids, the\nso-called Br\\\"odinger problem recently introduced by M. Arnaudon & al. [3], the\nmultiphase Brenier model, and the multiphase Br\\\"odinger problem. All of them\ninvolve the minimization of a kinetic action and/or a relative entropy of some\npath measures with respect to the reversible Brownian motion. As the viscosity\nparameter $\\nu\\to 0$ we establish Gamma-convergence relations between the\ncorresponding problems, and prove the convergence of the associated pressures\narising from the incompressibility constraints. We also present new results on\nthe time-convexity of the entropy for some of the dynamical interpolations.\nAlong the way we extend previous results by H. Lavenant [30] and J-D. Benamou &\nal. [10]. \n\n"}
{"id": "1810.12167", "contents": "Title: Exhaustion approximation for the control problem of the heat or\n  Schr\\\"odinger semigroup on unbounded domains Abstract: We consider the control problem of the heat equation on bounded and unbounded\ndomains, and more generally the corresponding inhomogeneous equation for the\nSchr\\\"odinger semigroup. We show that if the sequence of null-controls\nassociated to an exhaustion of an unbounded domain converges, then the\nsolutions do in the same way, and that the control cost estimate carries over\nto the limiting problem on the unbounded domain. This allows to infer the\ncontrollability on unbounded domains by studying the control problem on a\nsequence of bounded domains. \n\n"}
{"id": "1810.12817", "contents": "Title: Nonlocal $p$-Laplacian Variational problems on graphs Abstract: In this paper, we study a nonlocal variational problem which consists of\nminimizing in $L^2$ the sum of a quadratic data fidelity and a regularization\nterm corresponding to the $L^p$-norm of the nonlocal gradient. In particular,\nwe study convergence of the numerical solution to a discrete version of this\nnonlocal variational problem to the unique solution of the continuum one. To do\nso, we derive an error bound and highlight the role of the initial data and the\nkernel governing the nonlocal interactions. When applied to variational problem\non graphs, this error bound allows us to show the consistency of the\ndiscretized variational problem as the number of vertices goes to infinity.\nMore precisely, for networks in convergent graph sequences (simple and weighted\ndeterministic dense graphs as well as random inhomogeneous graphs), we prove\nconvergence and provide rate of convergence of solutions for the discrete\nmodels to the solution of the continuum problem as the number of vertices\ngrows. \n\n"}
{"id": "1810.13400", "contents": "Title: Differentiable MPC for End-to-end Planning and Control Abstract: We present foundations for using Model Predictive Control (MPC) as a\ndifferentiable policy class for reinforcement learning in continuous state and\naction spaces. This provides one way of leveraging and combining the advantages\nof model-free and model-based approaches. Specifically, we differentiate\nthrough MPC by using the KKT conditions of the convex approximation at a fixed\npoint of the controller. Using this strategy, we are able to learn the cost and\ndynamics of a controller via end-to-end learning. Our experiments focus on\nimitation learning in the pendulum and cartpole domains, where we learn the\ncost and dynamics terms of an MPC policy class. We show that our MPC policies\nare significantly more data-efficient than a generic neural network and that\nour method is superior to traditional system identification in a setting where\nthe expert is unrealizable. \n\n"}
{"id": "1811.00444", "contents": "Title: A Polyhedral Model for Enumeration and Optimization over the Set of\n  Circuits Abstract: Circuits play a fundamental role in polyhedral theory and linear programming.\nFor instance, circuits are used as step directions in various augmentation\nschemes for solving linear programs or to leave degenerate vertices while\nrunning the simplex method. However, there are significant challenges when\nimplementing these approaches: The set of circuits of a polyhedron may be of\nexponential size and is highly sensitive to the representation of the\npolyhedron.\n  In this paper, we provide a universal framework for enumerating the set of\ncircuits and optimizing over sets of circuits of a polyhedron in any\nrepresentation - we propose a polyhedral model in which the circuits of the\noriginal polyhedron are encoded as extreme rays or vertices. Many methods in\nthe literature and software assume that a polyhedron is in standard form; our\nframework is a direct generalization. We demonstrate its value by showing that\nthe conversion of a general representation to standard form may introduce\nexponentially many new circuits.\n  We then discuss the main advantages of the generalized polyhedral model. It\nenables the direct enumeration of useful subsets of circuits such as strictly\nfeasible circuits or sign-compatible circuits, as well as optimization over\nthese sets. In particular, this leads to the efficient computation of a\nsteepest-descent circuit, which can be used in an augmentation scheme for\nsolving linear programs or the construction of sign-compatible circuit walks\nwith additional \n\n"}
{"id": "1811.00522", "contents": "Title: Linear Quadratic Mean Field Games -- Part I: The Asymptotic Solvability\n  Problem Abstract: This paper investigates the so-called asymptotic solvability problem in\nlinear quadratic (LQ) mean field games. The model has asymptotic solvability if\nfor all sufficiently large population sizes, the corresponding game has a set\nof feedback Nash strategies subject to a mild regularity requirement. We\nprovide a necessary and sufficient condition and show that in this case the\nsolution converges to a mean field limit. This is accomplished by developing a\nre-scaling method to derive a low dimensional ordinary differential equation\n(ODE) system, where a non-symmetric Riccati ODE has a central role. \n\n"}
{"id": "1811.00577", "contents": "Title: Functional Nonlinear Sparse Models Abstract: Signal processing is rich in inherently continuous and often nonlinear\napplications, such as spectral estimation, optical imaging, and\nsuper-resolution microscopy, in which sparsity plays a key role in obtaining\nstate-of-the-art results. Coping with the infinite dimensionality and\nnon-convexity of these problems typically involves discretization and convex\nrelaxations, e.g., using atomic norms. Nevertheless, grid mismatch and other\ncoherence issues often lead to discretized versions of sparse signals that are\nnot sparse. Even if they are, recovering sparse solutions using convex\nrelaxations requires assumptions that may be hard to meet in practice. What is\nmore, problems involving nonlinear measurements remain non-convex even after\nrelaxing the sparsity objective. We address these issues by directly tackling\nthe continuous, nonlinear problem cast as a sparse functional optimization\nprogram. We prove that when these problems are non-atomic, they have no duality\ngap and can therefore be solved efficiently using duality and~(stochastic)\nconvex optimization methods. We illustrate the wide range of applications of\nthis approach by formulating and solving problems from nonlinear spectral\nestimation and robust classification. \n\n"}
{"id": "1811.00980", "contents": "Title: Proximal Gradient Method for Nonsmooth Optimization over the Stiefel\n  Manifold Abstract: We consider optimization problems over the Stiefel manifold whose objective\nfunction is the summation of a smooth function and a nonsmooth function.\nExisting methods for solving this kind of problems can be classified into three\nclasses. Algorithms in the first class rely on information of the subgradients\nof the objective function and thus tend to converge slowly in practice.\nAlgorithms in the second class are proximal point algorithms, which involve\nsubproblems that can be as difficult as the original problem. Algorithms in the\nthird class are based on operator-splitting techniques, but they usually lack\nrigorous convergence guarantees. In this paper, we propose a retraction-based\nproximal gradient method for solving this class of problems. We prove that the\nproposed method globally converges to a stationary point. Iteration complexity\nfor obtaining an $\\epsilon$-stationary solution is also analyzed. Numerical\nresults on solving sparse PCA and compressed modes problems are reported to\ndemonstrate the advantages of the proposed method. \n\n"}
{"id": "1811.01501", "contents": "Title: Lifted Proximal Operator Machines Abstract: We propose a new optimization method for training feed-forward neural\nnetworks. By rewriting the activation function as an equivalent proximal\noperator, we approximate a feed-forward neural network by adding the proximal\noperators to the objective function as penalties, hence we call the lifted\nproximal operator machine (LPOM). LPOM is block multi-convex in all layer-wise\nweights and activations. This allows us to use block coordinate descent to\nupdate the layer-wise weights and activations in parallel. Most notably, we\nonly use the mapping of the activation function itself, rather than its\nderivatives, thus avoiding the gradient vanishing or blow-up issues in gradient\nbased training methods. So our method is applicable to various non-decreasing\nLipschitz continuous activation functions, which can be saturating and\nnon-differentiable. LPOM does not require more auxiliary variables than the\nlayer-wise activations, thus using roughly the same amount of memory as\nstochastic gradient descent (SGD) does. We further prove the convergence of\nupdating the layer-wise weights and activations. Experiments on MNIST and\nCIFAR-10 datasets testify to the advantages of LPOM. \n\n"}
{"id": "1811.02540", "contents": "Title: Regret Circuits: Composability of Regret Minimizers Abstract: Regret minimization is a powerful tool for solving large-scale problems; it\nwas recently used in breakthrough results for large-scale extensive-form game\nsolving. This was achieved by composing simplex regret minimizers into an\noverall regret-minimization framework for extensive-form game strategy spaces.\nIn this paper we study the general composability of regret minimizers. We\nderive a calculus for constructing regret minimizers for composite convex sets\nthat are obtained from convexity-preserving operations on simpler convex sets.\nWe show that local regret minimizers for the simpler sets can be combined with\nadditional regret minimizers into an aggregate regret minimizer for the\ncomposite set. As one application, we show that the CFR framework can be\nconstructed easily from our framework. We also show ways to include curtailing\n(constraining) operations into our framework. For one, they enables the\nconstruction of CFR generalization for extensive-form games with general convex\nstrategy constraints that can cut across decision points. \n\n"}
{"id": "1811.02693", "contents": "Title: Deep Reinforcement Learning via L-BFGS Optimization Abstract: Reinforcement Learning (RL) algorithms allow artificial agents to improve\ntheir action selections so as to increase rewarding experiences in their\nenvironments. Deep Reinforcement Learning algorithms require solving a\nnonconvex and nonlinear unconstrained optimization problem. Methods for solving\nthe optimization problems in deep RL are restricted to the class of first-order\nalgorithms, such as stochastic gradient descent (SGD). The major drawback of\nthe SGD methods is that they have the undesirable effect of not escaping saddle\npoints and their performance can be seriously obstructed by ill-conditioning.\nFurthermore, SGD methods require exhaustive trial and error to fine-tune many\nlearning parameters. Using second derivative information can result in improved\nconvergence properties, but computing the Hessian matrix for large-scale\nproblems is not practical. Quasi-Newton methods require only first-order\ngradient information, like SGD, but they can construct a low rank approximation\nof the Hessian matrix and result in superlinear convergence. The limited-memory\nBroyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular\nquasi-Newton methods that construct positive definite Hessian approximations.\nIn this paper, we introduce an efficient optimization method, based on the\nlimited memory BFGS quasi-Newton method using line search strategy -- as an\nalternative to SGD methods. Our method bridges the disparity between first\norder methods and second order methods by continuing to use gradient\ninformation to calculate a low-rank Hessian approximations. We provide formal\nconvergence analysis as well as empirical results on a subset of the classic\nATARI 2600 games. Our results show a robust convergence with preferred\ngeneralization characteristics, as well as fast training time and no need for\nthe experience replaying mechanism. \n\n"}
{"id": "1811.03570", "contents": "Title: Dynamics and stationary configurations of heterogeneous foams Abstract: We consider the variational foam model, where the goal is to minimize the\ntotal surface area of a collection of bubbles subject to the constraint that\nthe volume of each bubble is prescribed. We apply sharp interface methods to\ndevelop an efficient computational method for this problem. In addition to\nsimulating time dynamics, we also report on stationary states of this flow for\n<22 bubbles in two dimensions and <18 bubbles in three dimensions. For small\nnumbers of bubbles, we recover known analytical results, which we briefly\ndiscuss. In two dimensions, we also recover the previous numerical results of\nCox et. al. (2003), computed using other methods. Particular attention is given\nto locally optimal foam configurations and heterogeneous foams, where the\nvolumes of the bubbles are not equal. Configurational transitions are reported\nfor the quasi-stationary flow where the volume of one of the bubbles is varied\nand, for each volume, the stationary state is computed. The results from these\nnumerical experiments are described and accompanied by many figures and videos. \n\n"}
{"id": "1811.03962", "contents": "Title: A Convergence Theory for Deep Learning via Over-Parameterization Abstract: Deep neural networks (DNNs) have demonstrated dominating performance in many\nfields; since AlexNet, networks used in practice are going wider and deeper. On\nthe theoretical side, a long line of works has been focusing on training neural\nnetworks with one hidden layer. The theory of multi-layer networks remains\nlargely unsettled.\n  In this work, we prove why stochastic gradient descent (SGD) can find\n$\\textit{global minima}$ on the training objective of DNNs in\n$\\textit{polynomial time}$. We only make two assumptions: the inputs are\nnon-degenerate and the network is over-parameterized. The latter means the\nnetwork width is sufficiently large: $\\textit{polynomial}$ in $L$, the number\nof layers and in $n$, the number of samples.\n  Our key technique is to derive that, in a sufficiently large neighborhood of\nthe random initialization, the optimization landscape is almost-convex and\nsemi-smooth even with ReLU activations. This implies an equivalence between\nover-parameterized neural networks and neural tangent kernel (NTK) in the\nfinite (and polynomial) width setting.\n  As concrete examples, starting from randomly initialized weights, we prove\nthat SGD can attain 100% training accuracy in classification tasks, or minimize\nregression loss in linear convergence speed, with running time polynomial in\n$n,L$. Our theory applies to the widely-used but non-smooth ReLU activation,\nand to any smooth and possibly non-convex loss functions. In terms of network\narchitectures, our theory at least applies to fully-connected neural networks,\nconvolutional neural networks (CNN), and residual neural networks (ResNet). \n\n"}
{"id": "1811.03982", "contents": "Title: Robust Asynchronous Stochastic Gradient-Push: Asymptotically Optimal and\n  Network-Independent Performance for Strongly Convex Functions Abstract: We consider the standard model of distributed optimization of a sum of\nfunctions $F(\\bz) = \\sum_{i=1}^n f_i(\\bz)$, where node $i$ in a network holds\nthe function $f_i(\\bz)$. We allow for a harsh network model characterized by\nasynchronous updates, message delays, unpredictable message losses, and\ndirected communication among nodes. In this setting, we analyze a modification\nof the Gradient-Push method for distributed optimization, assuming that\n\\begin{enumerate*}[label=(\\roman*)] \\item node $i$ is capable of generating\ngradients of its function $f_i(\\bz)$ corrupted by zero-mean bounded-support\nadditive noise at each step, \\item $F(\\bz)$ is strongly convex, and \\item each\n$f_i(\\bz)$ has Lipschitz gradients. We show that our proposed method\nasymptotically performs as well as the best bounds on centralized gradient\ndescent that takes steps in the direction of the sum of the noisy gradients of\nall the functions $f_1(\\bz), \\ldots, f_n(\\bz)$ at each step. \n\n"}
{"id": "1811.04063", "contents": "Title: On convexity and solution concepts in cooperative interval games Abstract: Cooperative interval game is a cooperative game in which every coalition gets\nassigned some closed real interval. This models uncertainty about how much the\nmembers of a coalition get for cooperating together.\n  In this paper we study convexity, core and the Shapley value of games with\ninterval uncertainty.\n  Our motivation to do so is twofold. First, we want to capture which\nproperties are preserved when we generalize concepts from classical cooperative\ngame theory to interval games. Second, since these generalizations can be done\nin different ways, mainly with regard to the resulting level of uncertainty, we\ntry to compare them and show their relation to each other. \n\n"}
{"id": "1811.04918", "contents": "Title: Learning and Generalization in Overparameterized Neural Networks, Going\n  Beyond Two Layers Abstract: The fundamental learning theory behind neural networks remains largely open.\nWhat classes of functions can neural networks actually learn? Why doesn't the\ntrained network overfit when it is overparameterized?\n  In this work, we prove that overparameterized neural networks can learn some\nnotable concept classes, including two and three-layer networks with fewer\nparameters and smooth activations. Moreover, the learning can be simply done by\nSGD (stochastic gradient descent) or its variants in polynomial time using\npolynomially many samples. The sample complexity can also be almost independent\nof the number of parameters in the network.\n  On the technique side, our analysis goes beyond the so-called NTK (neural\ntangent kernel) linearization of neural networks in prior works. We establish a\nnew notion of quadratic approximation of the neural network (that can be viewed\nas a second-order variant of NTK), and connect it to the SGD theory of escaping\nsaddle points. \n\n"}
{"id": "1811.06350", "contents": "Title: Temporal viability regulation for control affine systems with\n  applications to mobile vehicle coordination under time-varying motion\n  constraints Abstract: Controlled invariant set and viability regulation of dynamical control\nsystems have played important roles in many control and coordination\napplications. In this paper we develop a temporal viability regulation theory\nfor general dynamical control systems, and in particular for control affine\nsystems. The time-varying viable set is parameterized by time-varying\nconstraint functions, with the aim to regulate a dynamical control system to be\ninvariant in the time-varying viable set so that temporal state-dependent\nconstraints are enforced. We consider both time-varying equality and inequality\nconstraints in defining a temporal viable set. We also present sufficient\nconditions for the existence of feasible control input for the control affine\nsystems. The developed temporal viability regulation theory is applied to\nmobile vehicle coordination. \n\n"}
{"id": "1811.07783", "contents": "Title: Optimal medication for tumors modeled by a Cahn-Hilliard-Brinkman\n  equation Abstract: In this paper, we study a distributed optimal control problem for a diffuse\ninterface model for tumor growth. The model consists of a Cahn-Hilliard type\nequation for the phase field variable coupled to a reaction diffusion equation\nfor the nutrient and a Brinkman type equation for the velocity. The system is\nequipped with homogeneous Neumann boundary conditions for the tumor variable\nand the chemical potential, Robin boundary conditions for the nutrient and a\n\"no-friction\" boundary condition for the velocity. The control acts as a\nmedication by cytotoxic drugs and enters the phase field equation. The cost\nfunctional is of standard tracking type and is designed to track the variables\nof the state equation during the evolution and the distribution of tumor cells\nat some fixed final time. We prove that the model satisfies the basics for\ncalculus of variations and we establish first-order necessary optimality\nconditions for the optimal control problem. \n\n"}
{"id": "1811.08150", "contents": "Title: Effect of Depth and Width on Local Minima in Deep Learning Abstract: In this paper, we analyze the effects of depth and width on the quality of\nlocal minima, without strong over-parameterization and simplification\nassumptions in the literature. Without any simplification assumption, for deep\nnonlinear neural networks with the squared loss, we theoretically show that the\nquality of local minima tends to improve towards the global minimum value as\ndepth and width increase. Furthermore, with a locally-induced structure on deep\nnonlinear neural networks, the values of local minima of neural networks are\ntheoretically proven to be no worse than the globally optimal values of\ncorresponding classical machine learning models. We empirically support our\ntheoretical observation with a synthetic dataset as well as MNIST, CIFAR-10 and\nSVHN datasets. When compared to previous studies with strong\nover-parameterization assumptions, the results in this paper do not require\nover-parameterization, and instead show the gradual effects of\nover-parameterization as consequences of general results. \n\n"}
{"id": "1811.08820", "contents": "Title: Trajectory PHD and CPHD filters Abstract: This paper presents the probability hypothesis density filter (PHD) and the\ncardinality PHD (CPHD) filter for sets of trajectories, which are referred to\nas the trajectory PHD (TPHD) and trajectory CPHD (TCPHD) filters. Contrary to\nthe PHD/CPHD filters, the TPHD/TCPHD filters are able to produce trajectory\nestimates from first principles. The TPHD filter is derived by recursively\nobtaining the best Poisson multitrajectory density approximation to the\nposterior density over the alive trajectories by minimising the\nKullback-Leibler divergence. The TCPHD is derived in the same way but\npropagating an independent identically distributed (IID) cluster\nmultitrajectory density approximation. We also propose the Gaussian mixture\nimplementations of the TPHD and TCPHD recursions, the Gaussian mixture TPHD\n(GMTPHD) and the Gaussian mixture TCPHD (GMTCPHD), and the L-scan\ncomputationally efficient implementations, which only update the density of the\ntrajectory states of the last L time steps. \n\n"}
{"id": "1811.08888", "contents": "Title: Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU\n  Networks Abstract: We study the problem of training deep neural networks with Rectified Linear\nUnit (ReLU) activation function using gradient descent and stochastic gradient\ndescent. In particular, we study the binary classification problem and show\nthat for a broad family of loss functions, with proper random weight\ninitialization, both gradient descent and stochastic gradient descent can find\nthe global minima of the training loss for an over-parameterized deep ReLU\nnetwork, under mild assumption on the training data. The key idea of our proof\nis that Gaussian random initialization followed by (stochastic) gradient\ndescent produces a sequence of iterates that stay inside a small perturbation\nregion centering around the initial weights, in which the empirical loss\nfunction of deep ReLU networks enjoys nice local curvature properties that\nensure the global convergence of (stochastic) gradient descent. Our theoretical\nresults shed light on understanding the optimization for deep learning, and\npave the way for studying the optimization dynamics of training modern deep\nneural networks. \n\n"}
{"id": "1811.08937", "contents": "Title: Acceleration of Primal-Dual Methods by Preconditioning and Simple\n  Subproblem Procedures Abstract: Primal-Dual Hybrid Gradient (PDHG) and Alternating Direction Method of\nMultipliers (ADMM) are two widely-used first-order optimization methods. They\nreduce a difficult problem to simple subproblems, so they are easy to implement\nand have many applications. As first-order methods, however, they are sensitive\nto problem conditions and can struggle to reach the desired accuracy. To\nimprove their performance, researchers have proposed techniques such as\ndiagonal preconditioning and inexact subproblems. This paper realizes\nadditional speedup about one order of magnitude.\n  Specifically, we choose non-diagonal preconditioners that are much more\neffective than diagonal ones. Because of this, we lose closed-form solutions to\nsome subproblems, but we found simple procedures to replace them such as a few\nproximal-gradient iterations or a few epochs of proximal block-coordinate\ndescent, which are in closed forms. We show global convergence while fixing the\nnumber of those steps in every outer iteration. Therefore, our method is\nreliable and straightforward.\n  Our method opens the choices of preconditioners and maintains both low\nper-iteration cost and global convergence. Consequently, on several typical\napplications of primal-dual first-order methods, we obtain 4-95$\\times$ speedup\nover the existing state-of-the-art. \n\n"}
{"id": "1811.09313", "contents": "Title: Applying FISTA to optimization problems (with or) without minimizers Abstract: Beck and Teboulle's FISTA method for finding a minimizer of the sum of two\nconvex functions, one of which has a Lipschitz continuous gradient whereas the\nother may be nonsmooth, is arguably the most important optimization algorithm\nof the past decade. While research activity on FISTA has exploded ever since,\nthe mathematically challenging case when the original optimization problem has\nno minimizer has found only limited attention. In this work, we systematically\nstudy FISTA and its variants. We present general results that are applicable,\nregardless of the existence of minimizers. \n\n"}
{"id": "1811.09469", "contents": "Title: Parallel sequential Monte Carlo for stochastic gradient-free nonconvex\n  optimization Abstract: We introduce and analyze a parallel sequential Monte Carlo methodology for\nthe numerical solution of optimization problems that involve the minimization\nof a cost function that consists of the sum of many individual components. The\nproposed scheme is a stochastic zeroth order optimization algorithm which\ndemands only the capability to evaluate small subsets of components of the cost\nfunction. It can be depicted as a bank of samplers that generate particle\napproximations of several sequences of probability measures. These measures are\nconstructed in such a way that they have associated probability density\nfunctions whose global maxima coincide with the global minima of the original\ncost function. The algorithm selects the best performing sampler and uses it to\napproximate a global minimum of the cost function. We prove analytically that\nthe resulting estimator converges to a global minimum of the cost function\nalmost surely and provide explicit convergence rates in terms of the number of\ngenerated Monte Carlo samples and the dimension of the search space. We show,\nby way of numerical examples, that the algorithm can tackle cost functions with\nmultiple minima or with broad \"flat\" regions which are hard to minimize using\ngradient-based techniques. \n\n"}
{"id": "1811.09550", "contents": "Title: Multifidelity Approximate Bayesian Computation Abstract: A vital stage in the mathematical modelling of real-world systems is to\ncalibrate a model's parameters to observed data. Likelihood-free parameter\ninference methods, such as Approximate Bayesian Computation, build Monte Carlo\nsamples of the uncertain parameter distribution by comparing the data with\nlarge numbers of model simulations. However, the computational expense of\ngenerating these simulations forms a significant bottleneck in the practical\napplication of such methods. We identify how simulations of cheap, low-fidelity\nmodels have been used separately in two complementary ways to reduce the\ncomputational expense of building these samples, at the cost of introducing\nadditional variance to the resulting parameter estimates. We explore how these\napproaches can be unified so that cost and benefit are optimally balanced, and\nwe characterise the optimal choice of how often to simulate from cheap,\nlow-fidelity models in place of expensive, high-fidelity models in Monte Carlo\nABC algorithms. The resulting early accept/reject multifidelity ABC algorithm\nthat we propose is shown to give improved performance over existing\nmultifidelity and high-fidelity approaches. \n\n"}
{"id": "1811.10105", "contents": "Title: Inexact SARAH Algorithm for Stochastic Optimization Abstract: We develop and analyze a variant of the SARAH algorithm, which does not\nrequire computation of the exact gradient. Thus this new method can be applied\nto general expectation minimization problems rather than only finite sum\nproblems. While the original SARAH algorithm, as well as its predecessor, SVRG,\nrequire an exact gradient computation on each outer iteration, the inexact\nvariant of SARAH (iSARAH), which we develop here, requires only stochastic\ngradient computed on a mini-batch of sufficient size. The proposed method\ncombines variance reduction via sample size selection and iterative stochastic\ngradient updates. We analyze the convergence rate of the algorithms for\nstrongly convex and non-strongly convex cases, under smooth assumption with\nappropriate mini-batch size selected for each case. We show that with an\nadditional, reasonable, assumption iSARAH achieves the best known complexity\namong stochastic methods in the case of non-strongly convex stochastic\nfunctions. \n\n"}
{"id": "1811.11733", "contents": "Title: orthoDr: Semiparametric Dimension Reduction via Orthogonality\n  Constrained Optimization Abstract: orthoDr is a package in R that solves dimension reduction problems using\northogonality constrained optimization approach. The package serves as a\nunified framework for many regression and survival analysis dimension reduction\nmodels that utilize semiparametric estimating equations. The main computational\nmachinery of orthoDr is a first-order algorithm developed by\n\\cite{wen2013feasible} for optimization within the Stiefel manifold. We\nimplement the algorithm through Rcpp and OpenMP for fast computation. In\naddition, we developed a general-purpose solver for such constrained problems\nwith user-specified objective functions, which works as a drop-in version of\noptim(). The package also serves as a platform for future methodology\ndevelopments along this line of work. \n\n"}
{"id": "1812.00151", "contents": "Title: Discrete Adversarial Attacks and Submodular Optimization with\n  Applications to Text Classification Abstract: Adversarial examples are carefully constructed modifications to an input that\ncompletely change the output of a classifier but are imperceptible to humans.\nDespite these successful attacks for continuous data (such as image and audio\nsamples), generating adversarial examples for discrete structures such as text\nhas proven significantly more challenging. In this paper we formulate the\nattacks with discrete input on a set function as an optimization task. We prove\nthat this set function is submodular for some popular neural network text\nclassifiers under simplifying assumption. This finding guarantees a $1-1/e$\napproximation factor for attacks that use the greedy algorithm. Meanwhile, we\nshow how to use the gradient of the attacked classifier to guide the greedy\nsearch. Empirical studies with our proposed optimization scheme show\nsignificantly improved attack ability and efficiency, on three different text\nclassification tasks over various baselines. We also use a joint sentence and\nword paraphrasing technique to maintain the original semantics and syntax of\nthe text. This is validated by a human subject evaluation in subjective metrics\non the quality and semantic coherence of our generated adversarial text. \n\n"}
{"id": "1812.00404", "contents": "Title: An equivalence between critical points for rank constraints versus\n  low-rank factorizations Abstract: Two common approaches in low-rank optimization problems are either working\ndirectly with a rank constraint on the matrix variable, or optimizing over a\nlow-rank factorization so that the rank constraint is implicitly ensured. In\nthis paper, we study the natural connection between the rank-constrained and\nfactorized approaches. We show that all second-order stationary points of the\nfactorized objective function correspond to fixed points of projected gradient\ndescent run on the original problem (where the projection step enforces the\nrank constraint). This result allows us to unify many existing optimization\nguarantees that have been proved specifically in either the rank-constrained or\nthe factorized setting, and leads to new results for certain settings of the\nproblem. We demonstrate application of our results to several concrete low-rank\noptimization problems arising in matrix inverse problems. \n\n"}
{"id": "1812.01871", "contents": "Title: spGARCH: An R-Package for Spatial and Spatiotemporal ARCH models Abstract: In this paper, a general overview on spatial and spatiotemporal ARCH models\nis provided. In particular, we distinguish between three different spatial\nARCH-type models. In addition to the original definition of Otto et al. (2016),\nwe introduce an exponential spatial ARCH model in this paper. For this new\nmodel, maximum-likelihood estimators for the parameters are proposed. In\naddition, we consider a new complex-valued definition of the spatial ARCH\nprocess. From a practical point of view, the use of the R-package spGARCH is\ndemonstrated. To be precise, we show how the proposed spatial ARCH models can\nbe simulated and summarize the variety of spatial models, which can be\nestimated by the estimation functions provided in the package. Eventually, we\napply all procedures to a real-data example. \n\n"}
{"id": "1812.03046", "contents": "Title: Rank optimality for the Burer-Monteiro factorization Abstract: When solving large scale semidefinite programs that admit a low-rank\nsolution, an efficient heuristic is the Burer-Monteiro factorization: instead\nof optimizing over the full matrix, one optimizes over its low-rank factors.\nThis reduces the number of variables to optimize, but destroys the convexity of\nthe problem, thus possibly introducing spurious second-order critical points.\nThe article [Boumal, Voroninski, and Bandeira, 2018] shows that when the size\nof the factors is of the order of the square root of the number of linear\nconstraints, this does not happen: for almost any cost matrix, second-order\ncritical points are global solutions. In this article, we show that this result\nis essentially tight: for smaller values of the size, second-order critical\npoints are not generically optimal, even when the global solution is rank 1. \n\n"}
{"id": "1812.03565", "contents": "Title: The Gap Between Model-Based and Model-Free Methods on the Linear\n  Quadratic Regulator: An Asymptotic Viewpoint Abstract: The effectiveness of model-based versus model-free methods is a long-standing\nquestion in reinforcement learning (RL). Motivated by recent empirical success\nof RL on continuous control tasks, we study the sample complexity of popular\nmodel-based and model-free algorithms on the Linear Quadratic Regulator (LQR).\nWe show that for policy evaluation, a simple model-based plugin method requires\nasymptotically less samples than the classical least-squares temporal\ndifference (LSTD) estimator to reach the same quality of solution; the sample\ncomplexity gap between the two methods can be at least a factor of state\ndimension. For policy evaluation, we study a simple family of problem instances\nand show that nominal (certainty equivalence principle) control also requires\nseveral factors of state and input dimension fewer samples than the policy\ngradient method to reach the same level of control performance on these\ninstances. Furthermore, the gap persists even when employing commonly used\nbaselines. To the best of our knowledge, this is the first theoretical result\nwhich demonstrates a separation in the sample complexity between model-based\nand model-free methods on a continuous control task. \n\n"}
{"id": "1812.04300", "contents": "Title: Deep neural networks algorithms for stochastic control problems on\n  finite horizon: convergence analysis Abstract: This paper develops algorithms for high-dimensional stochastic control\nproblems based on deep learning and dynamic programming. Unlike classical\napproximate dynamic programming approaches, we first approximate the optimal\npolicy by means of neural networks in the spirit of deep reinforcement\nlearning, and then the value function by Monte Carlo regression. This is\nachieved in the dynamic programming recursion by performance or hybrid\niteration, and regress now methods from numerical probabilities. We provide a\ntheoretical justification of these algorithms. Consistency and rate of\nconvergence for the control and value function estimates are analyzed and\nexpressed in terms of the universal approximation error of the neural networks,\nand of the statistical error when estimating network function, leaving aside\nthe optimization error. Numerical results on various applications are presented\nin a companion paper (arxiv.org/abs/1812.05916) and illustrate the performance\nof the proposed algorithms. \n\n"}
{"id": "1812.04634", "contents": "Title: On the Curved Geometry of Accelerated Optimization Abstract: In this work we propose a differential geometric motivation for Nesterov's\naccelerated gradient method (AGM) for strongly-convex problems. By considering\nthe optimization procedure as occurring on a Riemannian manifold with a natural\nstructure, The AGM method can be seen as the proximal point method applied in\nthis curved space. This viewpoint can also be extended to the continuous time\ncase, where the accelerated gradient method arises from the natural\nblock-implicit Euler discretization of an ODE on the manifold. We provide an\nanalysis of the convergence rate of this ODE for quadratic objectives. \n\n"}
{"id": "1812.04983", "contents": "Title: Graph-Based Modeling and Simulation of Complex Systems Abstract: We present graph-based modeling abstractions to represent cyber-physical\ndependencies arising in complex systems. Specifically, we propose an algebraic\ngraph abstraction to capture physical connectivity in complex optimization\nmodels and a computing graph abstraction to capture communication connectivity\nin computing architectures. The proposed abstractions are scalable and are used\nas the backbone of a Julia -based software package that we call Plasmo.jl . We\nshow how the algebraic graph abstraction facilitates the implementation,\nanalysis, and decomposition of optimization problems and we show how the\ncomputing graph abstraction facilitates the implementation of optimization and\ncontrol algorithms and their simulation in virtual environments that involve\ndistributed, centralized, and hierarchical computing architectures. \n\n"}
{"id": "1812.05012", "contents": "Title: Second-order derivative of domain-dependent functionals along Nehari\n  manifold trajectories Abstract: Assume that a family of domain-dependent functionals $E_{\\Omega_t}$ possesses\na corresponding family of least energy critical points $u_t$ which can be found\nas (possibly nonunique) minimizers of $E_{\\Omega_t}$ over the associated Nehari\nmanifold $\\mathcal{N}(\\Omega_t)$. We obtain a formula for the second-order\nderivative of $E_{\\Omega_t}$ with respect to $t$ along Nehari manifold\ntrajectories of the form $\\alpha_t(u_0(\\Phi_t^{-1}(y)) + t v\n(\\Phi_t^{-1}(y)))$, $y \\in \\Omega_t$, where $\\Phi_t$ is a diffeomorphism such\nthat $\\Phi_t(\\Omega_0) = \\Omega_t$, $\\alpha_t \\in \\mathbb{R}$ is a\n$\\mathcal{N}(\\Omega_t)$-normalization coefficient, and $v$ is a corrector\nfunction whose choice is fairly general. Since $E_{\\Omega_t}[u_t]$ is not\nnecessarily twice differentiable with respect to $t$ due to the possible\nnonuniqueness of $u_t$, the obtained formula represents an upper bound for the\ncorresponding second superdifferential, thereby providing a convenient way to\nstudy various domain optimization problems related to $E_{\\Omega_t}$. An\nanalogous formula is also obtained for the first eigenvalue of the\n$p$-Laplacian. As an application of our results, we investigate the behaviour\nof the first eigenvalue of the Laplacian with respect to particular\nperturbations of rectangles. \n\n"}
{"id": "1812.05217", "contents": "Title: Tight Analyses for Non-Smooth Stochastic Gradient Descent Abstract: Consider the problem of minimizing functions that are Lipschitz and strongly\nconvex, but not necessarily differentiable. We prove that after $T$ steps of\nstochastic gradient descent, the error of the final iterate is $O(\\log(T)/T)$\nwith high probability. We also construct a function from this class for which\nthe error of the final iterate of deterministic gradient descent is\n$\\Omega(\\log(T)/T)$. This shows that the upper bound is tight and that, in this\nsetting, the last iterate of stochastic gradient descent has the same general\nerror rate (with high probability) as deterministic gradient descent. This\nresolves both open questions posed by Shamir (2012).\n  An intermediate step of our analysis proves that the suffix averaging method\nachieves error $O(1/T)$ with high probability, which is optimal (for any\nfirst-order optimization method). This improves results of Rakhlin (2012) and\nHazan and Kale (2014), both of which achieved error $O(1/T)$, but only in\nexpectation, and achieved a high probability error bound of $O(\\log\n\\log(T)/T)$, which is suboptimal.\n  We prove analogous results for functions that are Lipschitz and convex, but\nnot necessarily strongly convex or differentiable. After $T$ steps of\nstochastic gradient descent, the error of the final iterate is\n$O(\\log(T)/\\sqrt{T})$ with high probability, and there exists a function for\nwhich the error of the final iterate of deterministic gradient descent is\n$\\Omega(\\log(T)/\\sqrt{T})$. \n\n"}
{"id": "1812.05243", "contents": "Title: A New Homotopy Proximal Variable-Metric Framework for Composite Convex\n  Minimization Abstract: This paper suggests two novel ideas to develop new proximal variable-metric\nmethods for solving a class of composite convex optimization problems. The\nfirst idea is a new parameterization of the optimality condition which allows\nus to develop a class of homotopy proximal variable-metric methods. We show\nthat under appropriate assumptions such as strong convexity-type and\nsmoothness, or self-concordance, our new schemes can achieve finite global\niteration-complexity bounds. Our second idea is a primal-dual-primal framework\nfor proximal-Newton methods which can lead to some useful computational\nfeatures for a subclass of nonsmooth composite convex optimization problems.\nStarting from the primal problem, we formulate its dual problem, and use our\nhomotopy proximal Newton method to solve this dual problem. Instead of solving\nthe subproblem directly in the dual space, we suggest to dualize this\nsubproblem to go back to the primal space. The resulting subproblem shares some\nsimilarity promoted by the regularizer of the original problem and leads to\nsome computational advantages. As a byproduct, we specialize the proposed\nalgorithm to solve covariance estimation problems. Surprisingly, our new\nalgorithm does not require any matrix inversion or Cholesky factorization, and\nfunction evaluation, while it works in the primal space with sparsity\nstructures that are promoted by the regularizer. Numerical examples on several\napplications are given to illustrate our theoretical development and to compare\nwith state-of-the-arts. \n\n"}
{"id": "1812.05786", "contents": "Title: Low-rank Matrix Completion in a General Non-orthogonal Basis Abstract: This paper considers theoretical analysis of recovering a low rank matrix\ngiven a few expansion coefficients with respect to any basis. The current\napproach generalizes the existing analysis for the low-rank matrix completion\nproblem with sampling under entry sensing or with respect to a symmetric\northonormal basis. The analysis is based on dual certificates using a dual\nbasis approach and does not assume the restricted isometry property (RIP). We\nintroduce a condition on the basis called the correlation condition. This\ncondition can be computed in time $O(n^3)$ and holds for many cases of\ndeterministic basis where RIP might not hold or is NP hard to verify. If the\ncorrelation condition holds and the underlying low rank matrix obeys the\ncoherence condition with parameter $\\nu$, under additional mild assumptions,\nour main result shows that the true matrix can be recovered with very high\nprobability from $O(nr\\nu\\log^2n)$ uniformly random expansion coefficients. \n\n"}
{"id": "1812.06362", "contents": "Title: Low-rank semidefinite programming for the MAX2SAT problem Abstract: This paper proposes a new algorithm for solving MAX2SAT problems based on\ncombining search methods with semidefinite programming approaches. Semidefinite\nprogramming techniques are well-known as a theoretical tool for approximating\nmaximum satisfiability problems, but their application has traditionally been\nvery limited by their speed and randomized nature. Our approach overcomes this\ndifficult by using a recent approach to low-rank semidefinite programming,\nspecialized to work in an incremental fashion suitable for use in an exact\nsearch algorithm. The method can be used both within complete or incomplete\nsolver, and we demonstrate on a variety of problems from recent competitions.\nOur experiments show that the approach is faster (sometimes by orders of\nmagnitude) than existing state-of-the-art complete and incomplete solvers,\nrepresenting a substantial advance in search methods specialized for MAX2SAT\nproblems. \n\n"}
{"id": "1812.07042", "contents": "Title: Robustness of the Sobol' indices to marginal distribution uncertainty Abstract: Global sensitivity analysis (GSA) quantifies the influence of uncertain\nvariables in a mathematical model. The Sobol' indices, a commonly used tool in\nGSA, seek to do this by attributing to each variable its relative contribution\nto the variance of the model output. In order to compute Sobol' indices, the\nuser must specify a probability distribution for the uncertain variables. This\ndistribution is typically unknown and must be chosen using limited data and/or\nknowledge. The usefulness of the Sobol' indices depends on their robustness to\nthis distributional uncertainty. This article presents a novel method which\nuses \"optimal perturbations\" of the marginal probability density functions to\nanalyze the robustness of the Sobol' indices. The method is illustrated through\nsynthetic examples and a model for contaminant transport. \n\n"}
{"id": "1812.07066", "contents": "Title: A stochastic approximation method for approximating the efficient\n  frontier of chance-constrained nonlinear programs Abstract: We propose a stochastic approximation method for approximating the efficient\nfrontier of chance-constrained nonlinear programs. Our approach is based on a\nbi-objective viewpoint of chance-constrained programs that seeks solutions on\nthe efficient frontier of optimal objective value versus risk of constraint\nviolation. To this end, we construct a reformulated problem whose objective is\nto minimize the probability of constraints violation subject to deterministic\nconvex constraints (which includes a bound on the objective function value). We\nadapt existing smoothing-based approaches for chance-constrained problems to\nderive a convergent sequence of smooth approximations of our reformulated\nproblem, and apply a projected stochastic subgradient algorithm to solve it. In\ncontrast with exterior sampling-based approaches (such as sample average\napproximation) that approximate the original chance-constrained program with\none having finite support, our proposal converges to stationary solutions of a\nsmooth approximation of the original problem, thereby avoiding poor local\nsolutions that may be an artefact of a fixed sample. Our proposal also includes\na tailored implementation of the smoothing-based approach that chooses key\nalgorithmic parameters based on problem data. Computational results on four\ntest problems from the literature indicate that our proposed approach can\nefficiently determine good approximations of the efficient frontier. \n\n"}
{"id": "1812.07394", "contents": "Title: Decentralized Computation Offloading for Multi-User Mobile Edge\n  Computing: A Deep Reinforcement Learning Approach Abstract: Mobile edge computing (MEC) emerges recently as a promising solution to\nrelieve resource-limited mobile devices from computation-intensive tasks, which\nenables devices to offload workloads to nearby MEC servers and improve the\nquality of computation experience. Nevertheless, by considering a MEC system\nconsisting of multiple mobile users with stochastic task arrivals and wireless\nchannels in this paper, the design of computation offloading policies is\nchallenging to minimize the long-term average computation cost in terms of\npower consumption and buffering delay. A deep reinforcement learning (DRL)\nbased decentralized dynamic computation offloading strategy is investigated to\nbuild a scalable MEC system with limited feedback. Specifically, a continuous\naction space-based DRL approach named deep deterministic policy gradient (DDPG)\nis adopted to learn efficient computation offloading policies independently at\neach mobile user. Thus, powers of both local execution and task offloading can\nbe adaptively allocated by the learned policies from each user's local\nobservation of the MEC system. Numerical results are illustrated to demonstrate\nthat efficient policies can be learned at each user, and performance of the\nproposed DDPG based decentralized strategy outperforms the conventional deep\nQ-network (DQN) based discrete power control strategy and some other greedy\nstrategies with reduced computation cost. Besides, the power-delay tradeoff is\nalso analyzed for both the DDPG based and DQN based strategies. \n\n"}
{"id": "1812.07534", "contents": "Title: Value of Information in Feedback Control: Quantification Abstract: Although transmission of a data packet containing sensory information in a\nnetworked control system improves the quality of regulation, it has indeed a\nprice from the communication perspective. It is, therefore, rational that such\na data packet be transmitted only if it is valuable in the sense of a\ncost-benefit analysis. Yet, the fact is that little is known so far about this\nvaluation of information and its connection with traditional event-triggered\ncommunication. In the present article, we study this intrinsic property of\nnetworked control systems by formulating a rate-regulation tradeoff between the\npacket rate and the regulation cost with an event trigger and a controller as\ntwo distributed decision makers, and show that the valuation of information is\nconceivable and quantifiable grounded on this tradeoff. In particular, we\ncharacterize an equilibrium in the rate-regulation tradeoff, and quantify the\nvalue of information $\\text{VoI}_k$ there as the variation in a so-called value\nfunction with respect to a piece of sensory information that can be\ncommunicated to the controller at each time $k$. We prove that, for a\nmulti-dimensional Gauss-Markov process, $\\text{VoI}_k$ is a symmetric function\nof the discrepancy between the state estimates at the event trigger and the\ncontroller, and that a data packet containing sensory information at time $k$\nshould be transmitted to the controller only if $\\text{VoI}_k$ is nonnegative.\nMoreover, we discuss that $\\text{VoI}_k$ can be computed with arbitrary\naccuracy, and that it can be approximated by a closed-form quadratic function\nwith a performance guarantee. \n\n"}
{"id": "1812.08148", "contents": "Title: Minimizing Age of Information with Soft Updates Abstract: We consider an information updating system where an information provider and\nan information receiver engage in an update process over time. Different from\nthe existing literature where updates are countable (hard) and take effect\neither immediately or after a delay, but $instantaneously$ in both cases, here\nupdates start taking effect right away but $gradually$ over time. We coin this\nsetting $soft$ $updates$. When the updating process starts, the age decreases\nuntil the soft update period ends. We constrain the number of times the\ninformation provider and the information receiver meet (number of update\nperiods) and the total duration of the update periods. We consider two models\nfor the decrease of age during an update period: In the first model, the rate\nof decrease of age is proportional to the current age, and in the second model,\nthe rate of decrease of age is constant. The first model results in an\nexponentially decaying age, and the second model results in a linearly decaying\nage. In both cases, we determine the optimum updating schemes, by determining\nthe optimum start times and optimum durations of the updates, subject to the\nconstraints on the number of update periods and the total update duration. \n\n"}
{"id": "1812.08305", "contents": "Title: Derivative-Free Methods for Policy Optimization: Guarantees for Linear\n  Quadratic Systems Abstract: We study derivative-free methods for policy optimization over the class of\nlinear policies. We focus on characterizing the convergence rate of these\nmethods when applied to linear-quadratic systems, and study various settings of\ndriving noise and reward feedback. We show that these methods provably converge\nto within any pre-specified tolerance of the optimal policy with a number of\nzero-order evaluations that is an explicit polynomial of the error tolerance,\ndimension, and curvature properties of the problem. Our analysis reveals some\ninteresting differences between the settings of additive driving noise and\nrandom initialization, as well as the settings of one-point and two-point\nreward feedback. Our theory is corroborated by extensive simulations of\nderivative-free methods on these systems. Along the way, we derive convergence\nrates for stochastic zero-order optimization algorithms when applied to a\ncertain class of non-convex problems. \n\n"}
{"id": "1812.08413", "contents": "Title: Compressed sensing and Sequential Monte Carlo for solar hard X-ray\n  imaging Abstract: We describe two inversion methods for the reconstruction of hard X-ray solar\nimages. The methods are tested against experimental visibilities recorded by\nthe Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI) and synthetic\nvisibilities based on the design of the Spectrometer/Telescope for Imaging\nX-rays (STIX). \n\n"}
{"id": "1812.08714", "contents": "Title: Sharp semi-concavity in a non-autonomous control problem and $L^p$\n  estimates in an optimal-exit MFG Abstract: This paper studies a mean field game inspired by crowd motion in which agents\nevolve in a compact domain and want to reach its boundary minimizing the sum of\ntheir travel time and a given boundary cost. Interactions between agents occur\nthrough their dynamic, which depends on the distribution of all agents.\n  We start by considering the associated optimal control problem, showing that\nsemi-concavity in space of the corresponding value function can be obtained by\nrequiring as time regularity only a lower Lipschitz bound on the dynamics. We\nalso prove differentiability of the value function along optimal trajectories\nunder extra regularity assumptions.\n  We then provide a Lagrangian formulation for our mean field game and use\nclassical techniques to prove existence of equilibria, which are shown to\nsatisfy a MFG system. Our main result, which relies on the semi-concavity of\nthe value function, states that an absolutely continuous initial distribution\nof agents with an $L^p$ density gives rise to an absolutely continuous\ndistribution of agents at all positive times with a uniform bound on its $L^p$\nnorm. This is also used to prove existence of equilibria under fewer regularity\nassumptions on the dynamics thanks to a limit argument. \n\n"}
{"id": "1812.09017", "contents": "Title: Corporative Stochastic Approximation with Random Constraint Sampling for\n  Semi-Infinite Programming Abstract: We developed a corporative stochastic approximation (CSA) type algorithm for\nsemi-infinite programming (SIP), where the cut generation problem is solved\ninexactly. First, we provide general error bounds for inexact CSA. Then, we\npropose two specific random constraint sampling schemes to approximately solve\nthe cut generation problem. When the objective and constraint functions are\ngenerally convex, we show that our randomized CSA algorithms achieve an\n$\\mathcal{O}(1/\\sqrt{N})$ rate of convergence in expectation (in terms of\noptimality gap as well as SIP constraint violation). When the objective and\nconstraint functions are all strongly convex, this rate can be improved to\n$\\mathcal{O}(1/N)$. \n\n"}
{"id": "1812.09701", "contents": "Title: Nonlinear Robust Filtering of Sampled-Data Dynamical Systems Abstract: This work is concerned with robust filtering of nonlinear sampled-data\nsystems with and without exact discrete-time models. A linear matrix inequality\n(LMI) based approach is proposed for the design of robust $H_{\\infty}$\nobservers for a class of Lipschitz nonlinear systems. Two type of systems are\nconsidered, Lipschitz nonlinear discrete-time systems and Lipschitz nonlinear\nsampled-data systems with Euler approximate discrete-time models. Observer\nconvergence when the exact discrete-time model of the system is available is\nshown. Then, practical convergence of the proposed observer is proved using the\nEuler approximate discrete-time model. As an additional feature, maximizing the\nadmissible Lipschitz constant, the solution of the proposed LMI optimization\nproblem guaranties robustness against some nonlinear uncertainty. The robust\nH_infty observer synthesis problem is solved for both cases. The maximum\ndisturbance attenuation level is achieved through LMI optimization. At the end,\na path to extending the results to higher-order approximate discretizations is\nprovided. \n\n"}
{"id": "1812.11689", "contents": "Title: K-nearest Neighbor Search by Random Projection Forests Abstract: K-nearest neighbor (kNN) search has wide applications in many areas,\nincluding data mining, machine learning, statistics and many applied domains.\nInspired by the success of ensemble methods and the flexibility of tree-based\nmethodology, we propose random projection forests (rpForests), for kNN search.\nrpForests finds kNNs by aggregating results from an ensemble of random\nprojection trees with each constructed recursively through a series of\ncarefully chosen random projections. rpForests achieves a remarkable accuracy\nin terms of fast decay in the missing rate of kNNs and that of discrepancy in\nthe kNN distances. rpForests has a very low computational complexity. The\nensemble nature of rpForests makes it easily run in parallel on multicore or\nclustered computers; the running time is expected to be nearly inversely\nproportional to the number of cores or machines. We give theoretical insights\nby showing the exponential decay of the probability that neighboring points\nwould be separated by ensemble random projection trees when the ensemble size\nincreases. Our theory can be used to refine the choice of random projections in\nthe growth of trees, and experiments show that the effect is remarkable. \n\n"}
{"id": "1812.11893", "contents": "Title: Some new characterizations of intrinsic transversality in Hilbert spaces Abstract: Motivated by a number of research questions concerning transversality-type\nproperties of pairs of sets recently raised by Ioffe and Kruger, this paper\nreports several new characterizations of the intrinsic transversality property\nin Hilbert spaces. Our dual space results clarify the picture of intrinsic\ntransversality, its variants and the only existing sufficient dual condition\nfor subtransversality, and actually unify them. New primal space\ncharacterizations of the intrinsic transversality which is originally a dual\nspace condition lead to new understanding of the property in terms of primal\nspace elements for the first time. As a consequence, the obtained analysis\nallows us to address a number of research questions asked by the two\naforementioned researchers about the intrinsic transversality property in the\nHilbert space setting. \n\n"}
{"id": "1901.00137", "contents": "Title: A Theoretical Analysis of Deep Q-Learning Abstract: Despite the great empirical success of deep reinforcement learning, its\ntheoretical foundation is less well understood. In this work, we make the first\nattempt to theoretically understand the deep Q-network (DQN) algorithm (Mnih et\nal., 2015) from both algorithmic and statistical perspectives. In specific, we\nfocus on a slight simplification of DQN that fully captures its key features.\nUnder mild assumptions, we establish the algorithmic and statistical rates of\nconvergence for the action-value functions of the iterative policy sequence\nobtained by DQN. In particular, the statistical error characterizes the bias\nand variance that arise from approximating the action-value function using deep\nneural network, while the algorithmic error converges to zero at a geometric\nrate. As a byproduct, our analysis provides justifications for the techniques\nof experience replay and target network, which are crucial to the empirical\nsuccess of DQN. Furthermore, as a simple extension of DQN, we propose the\nMinimax-DQN algorithm for zero-sum Markov game with two players. Borrowing the\nanalysis of DQN, we also quantify the difference between the policies obtained\nby Minimax-DQN and the Nash equilibrium of the Markov game in terms of both the\nalgorithmic and statistical rates of convergence. \n\n"}
{"id": "1901.00214", "contents": "Title: Clustering with Distributed Data Abstract: We consider $K$-means clustering in networked environments (e.g., internet of\nthings (IoT) and sensor networks) where data is inherently distributed across\nnodes and processing power at each node may be limited. We consider a\nclustering algorithm referred to as networked $K$-means, or $NK$-means, which\nrelies only on local neighborhood information exchange. Information exchange is\nlimited to low-dimensional statistics and not raw data at the agents. The\nproposed approach develops a parametric family of multi-agent clustering\nobjectives (parameterized by $\\rho$) and associated distributed $NK$-means\nalgorithms (also parameterized by $\\rho$). The $NK$-means algorithm with\nparameter $\\rho$ converges to a set of fixed points relative to the associated\nmulti-agent objective (designated as `generalized minima'). By appropriate\nchoice of $\\rho$, the set of generalized minima may be brought arbitrarily\nclose to the set of Lloyd's minima. Thus, the $NK$-means algorithm may be used\nto compute Lloyd's minima of the collective dataset up to arbitrary accuracy. \n\n"}
{"id": "1901.00765", "contents": "Title: Analysis and Control of a Continuous-Time Bi-Virus Model Abstract: This paper studies a distributed continuous-time bi-virus model in which two\ncompeting viruses spread over a network consisting of multiple groups of\nindividuals. Limiting behaviors of the network are characterized by analyzing\nthe equilibria of the system and their stability. Specifically, when the two\nviruses spread over possibly different directed infection graphs, the system\nmay have (1) a unique equilibrium, the healthy state, which is globally stable,\nimplying that both viruses will eventually be eradicated, (2) two equilibria\nincluding the healthy state and a dominant virus state, which is almost\nglobally stable, implying that one virus will pervade the entire network\ncausing a single-virus epidemic while the other virus will be eradicated, or\n(3) at least three equilibria including the healthy state and two dominant\nvirus states, depending on certain conditions on the healing and infection\nrates. When the two viruses spread over the same directed infection graph, the\nsystem may have zero or infinitely many coexisting epidemic equilibria, which\nrepresents the pervasion of the two viruses. Sensitivity properties of some\nnontrivial equilibria are investigated in the context of a decentralized\ncontrol technique, and an impossibility result is given for a certain type of\ndistributed feedback controller. \n\n"}
{"id": "1901.00838", "contents": "Title: On Finding Local Nash Equilibria (and Only Local Nash Equilibria) in\n  Zero-Sum Games Abstract: We propose local symplectic surgery, a two-timescale procedure for finding\nlocal Nash equilibria in two-player zero-sum games. We first show that previous\ngradient-based algorithms cannot guarantee convergence to local Nash equilibria\ndue to the existence of non-Nash stationary points. By taking advantage of the\ndifferential structure of the game, we construct an algorithm for which the\nlocal Nash equilibria are the only attracting fixed points. We also show that\nthe algorithm exhibits no oscillatory behaviors in neighborhoods of equilibria\nand show that it has the same per-iteration complexity as other recently\nproposed algorithms. We conclude by validating the algorithm on two numerical\nexamples: a toy example with multiple Nash equilibria and a non-Nash\nequilibrium, and the training of a small generative adversarial network (GAN). \n\n"}
{"id": "1901.01631", "contents": "Title: Sharp Restricted Isometry Bounds for the Inexistence of Spurious Local\n  Minima in Nonconvex Matrix Recovery Abstract: Nonconvex matrix recovery is known to contain no spurious local minima under\na restricted isometry property (RIP) with a sufficiently small RIP constant\n$\\delta$. If $\\delta$ is too large, however, then counterexamples containing\nspurious local minima are known to exist. In this paper, we introduce a proof\ntechnique that is capable of establishing sharp thresholds on $\\delta$ to\nguarantee the inexistence of spurious local minima. Using the technique, we\nprove that in the case of a rank-1 ground truth, an RIP constant of\n$\\delta<1/2$ is both necessary and sufficient for exact recovery from any\narbitrary initial point (such as a random point). We also prove a local\nrecovery result: given an initial point $x_{0}$ satisfying\n$f(x_{0})\\le(1-\\delta)^{2}f(0)$, any descent algorithm that converges to\nsecond-order optimality guarantees exact recovery. \n\n"}
{"id": "1901.03161", "contents": "Title: Harnessing the Power of Serverless Runtimes for Large-Scale Optimization Abstract: The event-driven and elastic nature of serverless runtimes makes them a very\nefficient and cost-effective alternative for scaling up computations. So far,\nthey have mostly been used for stateless, data parallel and ephemeral\ncomputations. In this work, we propose using serverless runtimes to solve\ngeneric, large-scale optimization problems. Specifically, we build a\nmaster-worker setup using AWS Lambda as the source of our workers, implement a\nparallel optimization algorithm to solve a regularized logistic regression\nproblem, and show that relative speedups up to 256 workers and efficiencies\nabove 70% up to 64 workers can be expected. We also identify possible\nalgorithmic and system-level bottlenecks, propose improvements, and discuss the\nlimitations and challenges in realizing these improvements. \n\n"}
{"id": "1901.03317", "contents": "Title: Accelerated Flow for Probability Distributions Abstract: This paper presents a methodology and numerical algorithms for constructing\naccelerated gradient flows on the space of probability distributions. In\nparticular, we extend the recent variational formulation of accelerated\ngradient methods in (wibisono, et. al. 2016) from vector valued variables to\nprobability distributions. The variational problem is modeled as a mean-field\noptimal control problem. The maximum principle of optimal control theory is\nused to derive Hamilton's equations for the optimal gradient flow. The\nHamilton's equation are shown to achieve the accelerated form of density\ntransport from any initial probability distribution to a target probability\ndistribution. A quantitative estimate on the asymptotic convergence rate is\nprovided based on a Lyapunov function construction, when the objective\nfunctional is displacement convex. Two numerical approximations are presented\nto implement the Hamilton's equations as a system of $N$ interacting particles.\nThe continuous limit of the Nesterov's algorithm is shown to be a special case\nwith $N=1$. The algorithm is illustrated with numerical examples. \n\n"}
{"id": "1901.03674", "contents": "Title: On the Global Convergence of Imitation Learning: A Case for Linear\n  Quadratic Regulator Abstract: We study the global convergence of generative adversarial imitation learning\nfor linear quadratic regulators, which is posed as minimax optimization. To\naddress the challenges arising from non-convex-concave geometry, we analyze the\nalternating gradient algorithm and establish its Q-linear rate of convergence\nto a unique saddle point, which simultaneously recovers the globally optimal\npolicy and reward function. We hope our results may serve as a small step\ntowards understanding and taming the instability in imitation learning as well\nas in more general non-convex-concave alternating minimax optimization that\narises from reinforcement learning and generative adversarial learning. \n\n"}
{"id": "1901.05675", "contents": "Title: Convexification of box-constrained polynomial optimization problems via\n  monomial patterns Abstract: Convexification is a core technique in global polynomial optimization.\nCurrently, there are two main approaches competing in theory and practice: the\napproach of nonlinear programming and the approach based on positivity\ncertificates from real algebra. The former are comparatively cheap from a\ncomputational point of view, but typically do not provide tight relaxations\nwith respect to bounds for the original problem. The latter are typically\ncomputationally expensive, but do provide tight relaxations. We embed both\nkinds of approaches into a unified framework of monomial relaxations. We\ndevelop a convexification strategy that allows to trade off the quality of the\nbounds against computational expenses. Computational experiments show very\nencouraging results. \n\n"}
{"id": "1901.06048", "contents": "Title: Decomposition of games: some strategic considerations Abstract: Candogan et al. (2011) provide an orthogonal direct-sum decomposition of\nfinite games into potential, harmonic and nonstrategic components. In this\npaper we study the issue of decomposing games that are strategically equivalent\nfrom a game-theoretical point of view, for instance games obtained via\ntransformations such as duplications of strategies or positive affine mappings\nof of payoffs. We show the need to define classes of decompositions to achieve\ncommutativity of game transformations and decompositions. \n\n"}
{"id": "1901.06995", "contents": "Title: Distributed Nesterov gradient methods over arbitrary graphs Abstract: In this letter, we introduce a distributed Nesterov method, termed as\n$\\mathcal{ABN}$, that does not require doubly-stochastic weight matrices.\nInstead, the implementation is based on a simultaneous application of both row-\nand column-stochastic weights that makes this method applicable to arbitrary\n(strongly-connected) graphs. Since constructing column-stochastic weights needs\nadditional information (the number of outgoing neighbors at each agent), not\navailable in certain communication protocols, we derive a variation, termed as\nFROZEN, that only requires row-stochastic weights but at the expense of\nadditional iterations for eigenvector learning. We numerically study these\nalgorithms for various objective functions and network parameters and show that\nthe proposed distributed Nesterov methods achieve acceleration compared to the\ncurrent state-of-the-art methods for distributed optimization. \n\n"}
{"id": "1901.07090", "contents": "Title: Spectral Graph Analysis: A Unified Explanation and Modern Perspectives Abstract: Complex networks or graphs are ubiquitous in sciences and engineering:\nbiological networks, brain networks, transportation networks, social networks,\nand the World Wide Web, to name a few. Spectral graph theory provides a set of\nuseful techniques and models for understanding `patterns of interconnectedness'\nin a graph. Our prime focus in this paper is on the following question: Is\nthere a unified explanation and description of the fundamental spectral graph\nmethods? There are at least two reasons to be interested in this question.\nFirstly, to gain a much deeper and refined understanding of the basic\nfoundational principles, and secondly, to derive rich consequences with\npractical significance for algorithm design. However, despite half a century of\nresearch, this question remains one of the most formidable open issues, if not\nthe core problem in modern network science. The achievement of this paper is to\ntake a step towards answering this question by discovering a simple, yet\nuniversal statistical logic of spectral graph analysis. The prescribed\nviewpoint appears to be good enough to accommodate almost all existing spectral\ngraph techniques as a consequence of just one single formalism and algorithm. \n\n"}
{"id": "1901.07610", "contents": "Title: Efficient Load Flow Techniques Based on Holomorphic Embedding for\n  Distribution Networks Abstract: The Holomorphic Embedding Load flow Method (HELM) employs complex analysis to\nsolve the load flow problem. It guarantees finding the correct solution when it\nexists, and identifying when a solution does not exist. The method, however, is\nusually computationally less efficient than the traditional Newton-Raphson\nalgorithm, which is generally considered to be a slow method in distribution\nnetworks. In this paper, we present two HELM modifications that exploit the\nradial and weakly meshed topology of distribution networks and significantly\nreduce computation time relative to the original HELM implementation. We also\npresent comparisons with several popular load flow algorithms applied to\nvarious test distribution networks. \n\n"}
{"id": "1901.07935", "contents": "Title: Predicting Tactical Solutions to Operational Planning Problems under\n  Imperfect Information Abstract: This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict tactical solutions to a given operational problem. In this\ncontext, the tactical solution is less detailed than the operational one but it\nhas to be computed in very short time and under imperfect information. The\nproblem is of importance in various applications where tactical and operational\nplanning problems are interrelated and information about the operational\nproblem is revealed over time. This is for instance the case in certain\ncapacity planning and demand management systems.\n  We formulate the problem as a two-stage optimal prediction stochastic program\nwhose solution we predict with a supervised machine learning algorithm. The\ntraining data set consists of a large number of deterministic (second stage)\nproblems generated by controlled probabilistic sampling. The labels are\ncomputed based on solutions to the deterministic problems (solved independently\nand offline) employing appropriate aggregation and subselection methods to\naddress uncertainty. Results on our motivating application in load planning for\nrail transportation show that deep learning algorithms produce highly accurate\npredictions in very short computing time (milliseconds or less). The prediction\naccuracy is comparable to solutions computed by sample average approximation of\nthe stochastic program. \n\n"}
{"id": "1901.08170", "contents": "Title: A Fully Stochastic Primal-Dual Algorithm Abstract: A new stochastic primal--dual algorithm for solving a composite optimization\nproblem is proposed. It is assumed that all the functions/operators that enter\nthe optimization problem are given as statistical expectations. These\nexpectations are unknown but revealed across time through i.i.d. realizations.\nThe proposed algorithm is proven to converge to a saddle point of the\nLagrangian function. In the framework of the monotone operator theory, the\nconvergence proof relies on recent results on the stochastic Forward Backward\nalgorithm involving random monotone operators. An example of convex\noptimization under stochastic linear constraints is considered. \n\n"}
{"id": "1901.08659", "contents": "Title: Projected Stein Variational Newton: A Fast and Scalable Bayesian\n  Inference Method in High Dimensions Abstract: We propose a fast and scalable variational method for Bayesian inference in\nhigh-dimensional parameter space, which we call projected Stein variational\nNewton (pSVN) method. We exploit the intrinsic low-dimensional geometric\nstructure of the posterior distribution in the high-dimensional parameter space\nvia its Hessian (of the log posterior) operator and perform a parallel update\nof the parameter samples projected into a low-dimensional subspace by an SVN\nmethod. The subspace is adaptively constructed using the eigenvectors of the\naveraged Hessian at the current samples. We demonstrate fast convergence of the\nproposed method and its scalability with respect to the number of parameters,\nsamples, and processor cores. \n\n"}
{"id": "1901.08669", "contents": "Title: SAGA with Arbitrary Sampling Abstract: We study the problem of minimizing the average of a very large number of\nsmooth functions, which is of key importance in training supervised learning\nmodels. One of the most celebrated methods in this context is the SAGA\nalgorithm. Despite years of research on the topic, a general-purpose version of\nSAGA---one that would include arbitrary importance sampling and minibatching\nschemes---does not exist. We remedy this situation and propose a general and\nflexible variant of SAGA following the {\\em arbitrary sampling} paradigm. We\nperform an iteration complexity analysis of the method, largely possible due to\nthe construction of new stochastic Lyapunov functions. We establish linear\nconvergence rates in the smooth and strongly convex regime, and under a\nquadratic functional growth condition (i.e., in a regime not assuming strong\nconvexity). Our rates match those of the primal-dual method Quartz for which an\narbitrary sampling analysis is available, which makes a significant step\ntowards closing the gap in our understanding of complexity of primal and dual\nmethods for finite sum problems. \n\n"}
{"id": "1901.08689", "contents": "Title: Don't Jump Through Hoops and Remove Those Loops: SVRG and Katyusha are\n  Better Without the Outer Loop Abstract: The stochastic variance-reduced gradient method (SVRG) and its accelerated\nvariant (Katyusha) have attracted enormous attention in the machine learning\ncommunity in the last few years due to their superior theoretical properties\nand empirical behaviour on training supervised machine learning models via the\nempirical risk minimization paradigm. A key structural element in both of these\nmethods is the inclusion of an outer loop at the beginning of which a full pass\nover the training data is made in order to compute the exact gradient, which is\nthen used to construct a variance-reduced estimator of the gradient. In this\nwork we design {\\em loopless variants} of both of these methods. In particular,\nwe remove the outer loop and replace its function by a coin flip performed in\neach iteration designed to trigger, with a small probability, the computation\nof the gradient. We prove that the new methods enjoy the same superior\ntheoretical convergence properties as the original methods. However, we\ndemonstrate through numerical experiments that our methods have substantially\nsuperior practical behavior. \n\n"}
{"id": "1901.08958", "contents": "Title: Perturbed Proximal Descent to Escape Saddle Points for Non-convex and\n  Non-smooth Objective Functions Abstract: We consider the problem of finding local minimizers in non-convex and\nnon-smooth optimization. Under the assumption of strict saddle points, positive\nresults have been derived for first-order methods. We present the first known\nresults for the non-smooth case, which requires different analysis and a\ndifferent algorithm. \n\n"}
{"id": "1901.09068", "contents": "Title: Surrogate Losses for Online Learning of Stepsizes in Stochastic\n  Non-Convex Optimization Abstract: Stochastic Gradient Descent (SGD) has played a central role in machine\nlearning. However, it requires a carefully hand-picked stepsize for fast\nconvergence, which is notoriously tedious and time-consuming to tune. Over the\nlast several years, a plethora of adaptive gradient-based algorithms have\nemerged to ameliorate this problem. They have proved efficient in reducing the\nlabor of tuning in practice, but many of them lack theoretic guarantees even in\nthe convex setting. In this paper, we propose new surrogate losses to cast the\nproblem of learning the optimal stepsizes for the stochastic optimization of a\nnon-convex smooth objective function onto an online convex optimization\nproblem. This allows the use of no-regret online algorithms to compute optimal\nstepsizes on the fly. In turn, this results in a SGD algorithm with self-tuned\nstepsizes that guarantees convergence rates that are automatically adaptive to\nthe level of noise. \n\n"}
{"id": "1901.09109", "contents": "Title: DADAM: A Consensus-based Distributed Adaptive Gradient Method for Online\n  Optimization Abstract: Adaptive gradient-based optimization methods such as \\textsc{Adagrad},\n\\textsc{Rmsprop}, and \\textsc{Adam} are widely used in solving large-scale\nmachine learning problems including deep learning. A number of schemes have\nbeen proposed in the literature aiming at parallelizing them, based on\ncommunications of peripheral nodes with a central node, but incur high\ncommunications cost. To address this issue, we develop a novel consensus-based\ndistributed adaptive moment estimation method (\\textsc{Dadam}) for online\noptimization over a decentralized network that enables data parallelization, as\nwell as decentralized computation. The method is particularly useful, since it\ncan accommodate settings where access to local data is allowed. Further, as\nestablished theoretically in this work, it can outperform centralized adaptive\nalgorithms, for certain classes of loss functions used in applications. We\nanalyze the convergence properties of the proposed algorithm and provide a\ndynamic regret bound on the convergence rate of adaptive moment estimation\nmethods in both stochastic and deterministic settings. Empirical results\ndemonstrate that \\textsc{Dadam} works also well in practice and compares\nfavorably to competing online optimization methods. \n\n"}
{"id": "1901.09515", "contents": "Title: Black Box Submodular Maximization: Discrete and Continuous Settings Abstract: In this paper, we consider the problem of black box continuous submodular\nmaximization where we only have access to the function values and no\ninformation about the derivatives is provided. For a monotone and continuous\nDR-submodular function, and subject to a bounded convex body constraint, we\npropose Black-box Continuous Greedy, a derivative-free algorithm that provably\nachieves the tight $[(1-1/e)OPT-\\epsilon]$ approximation guarantee with\n$O(d/\\epsilon^3)$ function evaluations. We then extend our result to the\nstochastic setting where function values are subject to stochastic zero-mean\nnoise. It is through this stochastic generalization that we revisit the\ndiscrete submodular maximization problem and use the multi-linear extension as\na bridge between discrete and continuous settings. Finally, we extensively\nevaluate the performance of our algorithm on continuous and discrete submodular\nobjective functions using both synthetic and real data. \n\n"}
{"id": "1901.09671", "contents": "Title: ErasureHead: Distributed Gradient Descent without Delays Using\n  Approximate Gradient Coding Abstract: We present ErasureHead, a new approach for distributed gradient descent (GD)\nthat mitigates system delays by employing approximate gradient coding. Gradient\ncoded distributed GD uses redundancy to exactly recover the gradient at each\niteration from a subset of compute nodes. ErasureHead instead uses approximate\ngradient codes to recover an inexact gradient at each iteration, but with\nhigher delay tolerance. Unlike prior work on gradient coding, we provide a\nperformance analysis that combines both delay and convergence guarantees. We\nestablish that down to a small noise floor, ErasureHead converges as quickly as\ndistributed GD and has faster overall runtime under a probabilistic delay\nmodel. We conduct extensive experiments on real world datasets and distributed\nclusters and demonstrate that our method can lead to significant speedups over\nboth standard and gradient coded GD. \n\n"}
{"id": "1901.10374", "contents": "Title: Optimal Trajectory Tracking of Nonholonomic Mechanical Systems: a\n  geometric approach Abstract: We study the tracking of a trajectory for a nonholonomic system by recasting\nthe problem as an optimal control problem. The cost function is chosen to\nminimize the error in positions and velocities between the trajectory of a\nnonholonomic system and the desired reference trajectory evolving on the\ndistribution which defines the nonholonomic constraints. We prepose a geometric\nframework since it describes the class of nonlinear systems under study in a\ncoordinate-free framework. Necessary conditions for the existence of extrema\nare determined by the Pontryagin Minimum Principle. A nonholonomic fully\nactuated particle is used as a benchmark example to show how the proposed\nmethod is applied. \n\n"}
{"id": "1901.10568", "contents": "Title: Stochastic Gradient MCMC for Nonlinear State Space Models Abstract: State space models (SSMs) provide a flexible framework for modeling complex\ntime series via a latent stochastic process. Inference for nonlinear,\nnon-Gaussian SSMs is often tackled with particle methods that do not scale well\nto long time series. The challenge is two-fold: not only do computations scale\nlinearly with time, as in the linear case, but particle filters additionally\nsuffer from increasing particle degeneracy with longer series. Stochastic\ngradient MCMC methods have been developed to scale Bayesian inference for\nfinite-state hidden Markov models and linear SSMs using buffered stochastic\ngradient estimates to account for temporal dependencies. We extend these\nstochastic gradient estimators to nonlinear SSMs using particle methods. We\npresent error bounds that account for both buffering error and particle error\nin the case of nonlinear SSMs that are log-concave in the latent process. We\nevaluate our proposed particle buffered stochastic gradient using stochastic\ngradient MCMC for inference on both long sequential synthetic and\nminute-resolution financial returns data, demonstrating the importance of this\nclass of methods. \n\n"}
{"id": "math/0005281", "contents": "Title: Connections between Linear Systems and Convolutional Codes Abstract: The article reviews different definitions for a convolutional code which can\nbe found in the literature. The algebraic differences between the definitions\nare worked out in detail. It is shown that bi-infinite support systems are dual\nto finite-support systems under Pontryagin duality. In this duality the dual of\na controllable system is observable and vice versa. Uncontrollability can occur\nonly if there are bi-infinite support trajectories in the behavior, so finite\nand half-infinite-support systems must be controllable. Unobservability can\noccur only if there are finite support trajectories in the behavior, so\nbi-infinite and half-infinite-support systems must be observable. It is shown\nthat the different definitions for convolutional codes are equivalent if one\nrestricts attention to controllable and observable codes. \n\n"}
{"id": "math/0108163", "contents": "Title: Interval straight line fitting Abstract: I consider the task of experimental data fitting. Unlike the traditional\napproach I do not try to minimize any functional based on available\nexperimental information, instead the minimization problem is replaced with\nconstraint satisfaction procedure, which produces the interval hull of\nsolutions of desired type. The method, called 'box slicing algorithm', is\ndescribed in details. The results obtained this way need not to be labeled with\nconfidence level of any kind, they are simply certain (guaranteed). The method\neasily handles the case with uncertainties in one or both variables. There is\nno need for, always more or less arbitrary, weighting the experimental data.\nThe approach is directly applicable to other experimental data processing\nproblems like outliers detection or finding the straight line, which is tangent\nto the experimental curve. \n\n"}
{"id": "math/0301266", "contents": "Title: Computing the Integer Programming Gap Abstract: We determine the maximal gap between the optimal values of an integer program\nand its linear programming relaxation, where the matrix and cost function are\nfixed but the right hand side is unspecified. Our formula involves irreducible\ndecomposition of monomial ideals. The gap can be computed in polynomial time\nwhen the dimension is fixed. \n\n"}
{"id": "math/0304184", "contents": "Title: Control in the presence of a black box Abstract: We apply the ``black box'' scattering theory to problems in control theory\nand in high energy eigenvalue scarring. \n\n"}
{"id": "math/0404184", "contents": "Title: A max-plus finite element method for solving finite horizon\n  deterministic optimal control problems Abstract: We introduce a max-plus analogue of the Petrov-Galerkin finite element\nmethod, to solve finite horizon deterministic optimal control problems. The\nmethod relies on a max-plus variational formulation, and exploits the\nproperties of projectors on max-plus semimodules. We obtain a nonlinear\ndiscretized semigroup, corresponding to a zero-sum two players game. We give an\nerror estimate of order $(\\Delta t)^{1/2}+\\Delta x(\\Delta t)^{-1}$, for a\nsubclass of problems in dimension 1. We compare our method with a max-plus\nbased discretization method previously introduced by Fleming and McEneaney. \n\n"}
{"id": "math/0404474", "contents": "Title: Combinatorial and algorithmic aspects of hyperbolic polynomials Abstract: Let $p(x_1,...,x_n) =\\sum_{(r_1,...,r_n) \\in I_{n,n}} a_{(r_1,...,r_n)}\n\\prod_{1 \\leq i \\leq n} x_{i}^{r_{i}}$ be homogeneous polynomial of degree $n$\nin $n$ real variables with integer nonnegative coefficients. The support of\nsuch polynomial $p(x_1,...,x_n)$ is defined as $supp(p) = \\{(r_1,...,r_n) \\in\nI_{n,n} : a_{(r_1,...,r_n)} \\neq 0 \\}$ . The convex hull $CO(supp(p))$ of\n$supp(p)$ is called the Newton polytope of $p$ . We study the following\ndecision problems, which are far-reaching generalizations of the classical\nperfect matching problem : {itemize} {\\bf Problem 1 .} Consider a homogeneous\npolynomial $p(x_1,...,x_n)$ of degree $n$ in $n$ real variables with\nnonnegative integer coefficients given as a black box (oracle) . {\\it Is it\ntrue that $(1,1,..,1) \\in supp(p)$ ?} {\\bf Problem 2 .} Consider a homogeneous\npolynomial $p(x_1,...,x_n)$ of degree $n$ in $n$ real variables with\nnonnegative integer coefficients given as a black box (oracle) . {\\it Is it\ntrue that $(1,1,..,1) \\in CO(supp(p))$ ?} {itemize} We prove that for\nhyperbolic polynomials these two problems are equivalent and can be solved by\ndeterministic polynomial-time oracle algorithms . This result is based on a\n\"hyperbolic\" generalization of Rado theorem . \n\n"}
{"id": "math/0502078", "contents": "Title: Finiteness theorems in stochastic integer programming Abstract: We study Graver test sets for families of linear multi-stage stochastic\ninteger programs with varying number of scenarios. We show that these test sets\ncan be decomposed into finitely many ``building blocks'', independent of the\nnumber of scenarios, and we give an effective procedure to compute these\nbuilding blocks. The paper includes an introduction to Nash-Williams' theory of\nbetter-quasi-orderings, which is used to show termination of our algorithm. We\nalso apply this theory to finiteness results for Hilbert functions. \n\n"}
{"id": "math/0502361", "contents": "Title: Stability of Planar Nonlinear Switched Systems Abstract: We consider the time-dependent nonlinear system $\\dot\nq(t)=u(t)X(q(t))+(1-u(t))Y(q(t))$, where $q\\in\\R^2$, $X$ and $Y$ are two\n%$C^\\infty$ smooth vector fields, globally asymptotically stable at the origin\nand $u:[0,\\infty)\\to\\{0,1\\}$ is an arbitrary measurable function. Analysing the\ntopology of the set where $X$ and $Y$ are parallel, we give some sufficient and\nsome necessary conditions for global asymptotic stability, uniform with respect\nto $u(.)$. Such conditions can be verified without any integration or\nconstruction of a Lyapunov function, and they are robust under small\nperturbations of the vector fields. \n\n"}
{"id": "math/0506124", "contents": "Title: Relative entropy and the multi-variable multi-dimensional moment problem Abstract: Entropy-like functionals on operator algebras have been studied since the\npioneering work of von Neumann, Umegaki, Lindblad, and Lieb. The most\nwell-known are the von Neumann entropy $trace (\\rho\\log \\rho)$ and a\ngeneralization of the Kullback-Leibler distance $trace (\\rho \\log \\rho - \\rho\n\\log \\sigma)$, refered to as quantum relative entropy and used to quantify\ndistance between states of a quantum system. The purpose of this paper is to\nexplore these as regularizing functionals in seeking solutions to\nmulti-variable and multi-dimensional moment problems. It will be shown that\nextrema can be effectively constructed via a suitable homotopy. The homotopy\napproach leads naturally to a further generalization and a description of all\nthe solutions to such moment problems. This is accomplished by a\nrenormalization of a Riemannian metric induced by entropy functionals. As an\napplication we discuss the inverse problem of describing power spectra which\nare consistent with second-order statistics, which has been the main motivation\nbehind the present work. \n\n"}
{"id": "math/0606476", "contents": "Title: Sparse SOS Relaxations for Minimizing Functions that are Summations of\n  Small Polynomials Abstract: This paper discusses how to find the global minimum of functions that are\nsummations of small polynomials (``small'' means involving a small number of\nvariables). Some sparse sum of squares (SOS) techniques are proposed. We\ncompare their computational complexity and lower bounds with prior SOS\nrelaxations. Under certain conditions, we also discuss how to extract the\nglobal minimizers from these sparse relaxations. The proposed methods are\nespecially useful in solving sparse polynomial system and nonlinear least\nsquares problems. Numerical experiments are presented, which show that the\nproposed methods significantly improve the computational performance of prior\nmethods for solving these problems. Lastly, we present applications of this\nsparsity technique in solving polynomial systems derived from nonlinear\ndifferential equations and sensor network localization. \n\n"}
{"id": "math/0608178", "contents": "Title: A regularity theory for multiple-valued Dirichlet minimizing maps Abstract: This paper discusses the regularity of multiple-valued Dirichlet minimizing\nmaps into the sphere. It shows that even at branched point, as long as the\nnormalized energy is small enough, we have the energy decay estimate. Combined\nwith the previous work by Chun-Chi Lin, we get our first estimate that m-2\ndimensional Hausdorff measure of singular set is zero. Furthermore, by looking\nat the tangent map and using dimension reduction argument, we show that the\nsingular set is at least of codimension 3. \n\n"}
{"id": "math/0609038", "contents": "Title: A variational problem on Stiefel manifolds Abstract: In their paper on discrete analogues of some classical systems such as the\nrigid body and the geodesic flow on an ellipsoid, Moser and Veselov introduced\ntheir analysis in the general context of flows on Stiefel manifolds. We\nconsider here a general class of continuous time, quadratic cost, optimal\ncontrol problems on Stiefel manifolds, which in the extreme dimensions again\nyield these classical physical geodesic flows. We have already shown that this\noptimal control setting gives a new symmetric representation of the rigid body\nflow and in this paper we extend this representation to the geodesic flow on\nthe ellipsoid and the more general Stiefel manifold case. The metric we choose\non the Stiefel manifolds is the same as that used in the symmetric\nrepresentation of the rigid body flow and that used by Moser and Veselov. In\nthe extreme cases of the ellipsoid and the rigid body, the geodesic flows are\nknown to be integrable. We obtain the extremal flows using both variational and\noptimal control approaches and elucidate the structure of the flows on general\nStiefel manifolds. \n\n"}
{"id": "math/0611498", "contents": "Title: A note on the representation of positive polynomials with structured\n  sparsity Abstract: We consider real polynomials in finitely many variables. Let the variables\nconsist of finitely many blocks that are allowed to overlap in a certain way.\nLet the solution set of a finite system of polynomial inequalities be given\nwhere each inequality involves only variables of one block. We investigate\npolynomials that are positive on such a set and sparse in the sense that each\nmonomial involves only variables of one block. In particular, we derive a short\nand direct proof for Lasserre's theorem of the existence of sums of squares\ncertificates respecting the block structure. The motivation for the results can\nbe found in the literature and stems from numerical methods using semidefinite\nprogramming to simulate or control discrete-time behaviour of systems. \n\n"}
{"id": "math/0703714", "contents": "Title: Delta Hedging without the Black-Scholes Formula Abstract: We introduce a new method of delta hedging. In many cases, this method\nresults in a lower cost than the Black-Scholes method. To calculate the cost of\nhedging, we develop a Mathematica program that include the two-dimensional\nNewton-Raphson method. \n\n"}
